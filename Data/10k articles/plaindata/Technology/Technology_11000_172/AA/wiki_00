{"id": "47333891", "url": "https://en.wikipedia.org/wiki?curid=47333891", "title": "All American Turbo-Cat", "text": "All American Turbo-Cat\n\nThe Turbo-Cat was a jet aircraft catapult launch system powered by six jet engines. It was invented by Don Doolittle, and manufactured by the All American Engineering Co. of Wilmington, Delaware, USA. Six Allison J33 engines in a capstan arrangement provided 50,000 horsepower directly to the launching cable.\nIt was developed for expeditionary use by the U.S. Marine Corps, and it was to be air transportable.\n\nSix jet engines are arranged in a circle with the exhausts facing the center where the mass flow of hot exhaust gasses is vented through a diffuser into a pair of large launching turbines. The launching turbines are connected by a main shaft to a cable drum from which an endless tensioned cable shunts underground to a launching track. Then down the track and around a pulley and back to the cable drum. By diverting the flow of exhaust gasses into a launching turbine, the cable drum and its tensioned cable can be accelerated to very high speeds.\n\n"}
{"id": "32480401", "url": "https://en.wikipedia.org/wiki?curid=32480401", "title": "Arc fault", "text": "Arc fault\n\nAn arc fault is a high power discharge of electricity between two or more conductors. This discharge translates into heat, which can break down the wire's insulation and possibly trigger an electrical fire. These arc faults can range in power from a few amps up to thousands of amps high and are highly variable in terms of strength and duration. Common causes of arc faults include faulty connections due to corrosion and faulty initial installation.\n\nTwo types of wiring protection are standard thermal breakers and arc fault circuit breakers. Thermal breakers require an overload condition long enough that a heating element in the breaker trips the breaker off. In contrast, arc fault circuit breakers use magnetic or other means to detect increases in current draw much more quickly. Without such protection, visually detecting arc faults in defective wiring is very difficult, as the arc fault occurs in a very small area. A problem with arc fault circuit breaker is they are more likely to produce false positives due to normal circuit behaviors appearing to be arc faults. For instance, lightning strikes on the outside of an aircraft mimic arc faults in their voltage and current profiles. Research has been able to largely eliminate such false positives, however, providing the ability to quickly identify and locate repairs that need to be done.\n\nIn simple wiring systems visual inspection can lead to finding the fault location, but in complex wiring systems, for instance aircraft wiring, devices such as a time-domain reflectometer are helpful, even on live wires.\n\n"}
{"id": "4981609", "url": "https://en.wikipedia.org/wiki?curid=4981609", "title": "Automatic document feeder", "text": "Automatic document feeder\n\nIn multifunction or all-in-one printers, fax machines, photocopiers and scanners, an automatic document feeder or ADF is a feature which takes several pages and feeds the paper one page at a time into a scanner or copier, allowing the user to scan, and thereby copy, print, or fax, multiple-page documents without having to manually replace each page.\n\nMost copiers allow scanning on the flatbed or platen (the \"glass\") or through a document feeder. The vast majority of fax machines have an ADF, allowing the unattended sending of multi-page faxes. Due to the ubiquity of ADF in fax machines, some fax machine owners use the fax machine as a scanner, faxing multi-page documents to themselves. Document feeders are described by speed, in pages per minute or ppm, and capacity, usually in a range from 10 sheets to 200.\n\nThere are two kinds of document feeders capable of two-sided (duplex) scanning: a reversing automatic document feeder or RADF scans one side of a page, then flips it and scans the other side. A duplexing automatic document feeder or DADF scans both sides in one pass. The advantage of the DADF is faster speed for two-sided originals. RADFs and DADFs are rated in images per minute (IPM), the number of sides they can scan each minute; this may depend upon the resolution being used (rather than the maximum resolution supported).\n\n"}
{"id": "7588022", "url": "https://en.wikipedia.org/wiki?curid=7588022", "title": "Background debug mode interface", "text": "Background debug mode interface\n\nBackground debug mode (BDM) interface is an electronic interface that allows debugging of embedded systems. Specifically, it provides in-circuit debugging functionality in microcontrollers. It requires a single wire and specialized electronics in the system being debugged.\nIt appears in many Freescale Semiconductor products.\n\nThe interface allows a \"Host\" to manage and query a \"target\". Specialized hardware is required in the target device. No special hardware is required in the host; a simple bidirectional I/O pin is sufficient.\n\nThe signals used by BDM to communicate data to and from the target are initiated by the host processor. The host negates the transmission line, and then either\n\n\nAt the start of the next bit time, the host negates the transmission line, and the process repeats. Each bit is communicated in this manner.\n\nIn other words, the increasing complexity of today’s software and hardware designs is leading to some fresh approaches to debugging. \"Silicon manufacturers offer more and more on-chip debugging features for emulation of new processors\".\n\nThis capability, implemented in various processors under such names as background debug mode (BDM), JTAG and on-chip in-circuit emulation, puts basic debugging functions on the chip itself. With a BDM (1 wire interface) or JTAG (standard JTAG) debug port, you control and monitor the microcontroller solely through the stable on-chip debugging services.\n\nThis debugging mode runs even when the target system crashes and enables developers to continue investigating the cause of the crash.\n\nA good development tool environment is important to reduce total development time and cost. Users want to debug their application program under conditions that imitate the actual setup of their system. Because of that, the capability to debug a user program in an actual target system is required. This is known as in-circuit debugging. Furthermore, most new MCUs have nonvolatile memory such as flash memory so that programming code on the target system is also required. This is known as in-circuit programming.\n\nTo support in-circuit debugging and programming requirements, the HC08 Family has the monitor mode and the HCS08 and RS08 utilize a background debug mode (BDM). The background debug hardware on the HCS08 consists of a background debug controller (BDC) and debug module (DBG). The background debug hardware on the RS08 consists of the background debug controller (BDC) only.\n\nThe BDM host can issue commands with parameters to the target. Some commands allow reading or writing of blocks of the target's memory, individual registers in the CPU, or registers not available to the target.\n\nExamples include:\n\nDepending on the target part, the BDM controller may feature a hardware breakpoint register. The register holds a value indicating an address in memory. When the target part's CPU accesses that location in memory, the BDM hardware can take control of the target part, stop program execution, and begin operating in background mode.\n\n"}
{"id": "40772", "url": "https://en.wikipedia.org/wiki?curid=40772", "title": "Barrage jamming", "text": "Barrage jamming\n\nBarrage jamming is an electronic warfare technique that attempts to blind radar systems by filling the display with noise, rendering the broadcaster's \"blip\" invisible on the display, and often those in the nearby area as well. \"Barrage\" refers to systems that send signals in many bands of frequencies compared to the bandwidth of any single radar. This allows the jammer to jam multiple radars at once, and reduces or eliminates the need for adjustments to respond to any single radar.\n\nEarly radar systems typically operated on a single frequency, and could only change that frequency by changing internal electronics. Against these radars, it was possible to use conventional radio sets to send out signals on the same band, causing the radar display to be filled with noise whenever the antenna was pointed in the general direction of the jammer. However, given that each individual radar would be operating on different frequencies, this \"spot jamming\" technique required multiple radio sets in order to jam more than one radar at a time, and true wide-band barrage jamming was very difficult.\n\nEarly barrage jammers in World War II used photomultiplier tubes to amplify a wideband noise source, But the technique became practical with the introduction of the carcinotron in the early 1950s, a vacuum tube that generates microwaves who's frequency can be adjusted across a very wide band simply by changing the input voltage. A single carcinotron could be swept through the entire bandwidth of any potential radar network, jamming all of the radars in such rapid sequence that it appeared to be constant noise on all frequencies at all times. A downside to this approach is that the signal only spends a brief period of time at any one radar's frequency; depending on the scanning rate, the radar may only be jammed during certain periods, but if the rate is increased to offset this, the amount of noise in any one pulse period is reduced. More complex jammers can scan only the bands it sees being used, improving its effectiveness.\n\nBarrage jamming was extremely effective against 1950s radars, to the point where there was some belief that the carcinotron might render ground-based radars useless, especially in the early warning radar role. By the 1960s a number of techniques had been introduced to combat barrage jamming. Frequency agile radars, which change their frequency from pulse to pulse, force the jammer spread its signal across the entire bandwidth, ensuring the signal is diluted. Combining this with extremely powerful signals and highly focused antennas allowed new radars to overpower the jammers, \"burning through\" the jamming. Simple techniques, like turning off the receivers when the antenna was pointed close to the jammer, allowed the radar to continue tracking other targets. The use of phased array antennas and signal processing techniques that reduced sidelobes also improved performance.\n\nBarrage jammers also have the disadvantage that they are very easy to detect using a wideband receiver. This can be used to track the jammer using a variety of techniques. A well developed instance of this was deployed by the RAF in their RX12874 network, which could track jammer-carrying aircraft with accuracy equal to a radar. More generally, a barrage jammer's signal is so easy to receive that it makes an excellent early warning signal on its own.\n\n"}
{"id": "10836446", "url": "https://en.wikipedia.org/wiki?curid=10836446", "title": "Bartercard", "text": "Bartercard\n\nBartercard is the operator of the world’s largest barter trading exchange. Bartercard enables businesses to exchange goods and services without the use of cash or cash equivalents, or without a direct swap.\n\nBartercard was founded on the Gold Coast, Australia in 1991 by Wayne Sharpe and has a presence in eight countries (Australia, New Zealand, South Africa, United Kingdom, United States, Thailand, United Arab Emirates and Cyprus) where 75 offices service approximately 54,000 cardholders worldwide who collectively barter-trade over $600m each year. \n\nIn 2007, Bartercard Australia was sold in a management buyout.\n\nBartercard provides members with an interest free line of credit which they can use to make purchases. Members earn Bartercard Trade Dollars / Pounds for the goods and services they sell and this value is recorded electronically in the member’s account database, or goes towards repaying the credit that the member may have used.\n\nFor taxation purposes, that is, for calculating taxation liability, the Australian Taxation Office (ATO) treats one Bartercard Trade Dollar the same way that it treats one Australian Dollar.\n\nBartercard offers an infrastructure that allows members to transact using EFTPOS as well as an online trading platform and a smart phone application. Bartercard trade dollars can be transacted via a number of methods. Members find each other via an online directory, Bartercard's online trading portal MYBC.\n\n"}
{"id": "1181779", "url": "https://en.wikipedia.org/wiki?curid=1181779", "title": "CMS-2 (programming language)", "text": "CMS-2 (programming language)\n\nCMS-2 is an embedded systems programming language used by the United States Navy. It was an early attempt to develop a standardized high-level computer programming language intended to improve code portability and reusability. CMS-2 was developed primarily for the US Navy’s tactical data systems (NTDS).\n\nCMS-2 was developed by RAND Corporation in the early 1970s and stands for \"Compiler Monitor System\". The name \"CMS-2\" is followed in literature by a letter designating the type of target system. For example, CMS-2M targets Navy 16-bit processors, such as the AN/AYK-14.\n\nCMS-2 was developed for FCPCPAC (Fleet Computer Programming Center - Pacific) in San Diego, CA. It was implemented by Computer Sciences Corporation in 1968 with design assistance from Intermetrics. The language continued to be developed, eventually supporting a number of computers including the AN/UYK-7 and AN/UYK-43 and UYK-20 and UYK-44 computers.\n\nCMS-2 was designed to encourage program modularization, permitting independent compilation of portions of a total system. The language is statement oriented. The source is free-form and may be arranged for programming convenience. Data types include fixed-point, floating-point, boolean, character and status. Direct reference to, and manipulation of character and bit strings is permitted. Symbolic machine code may be included, known as direct code.\n\nA CMS-2 program is composed of statements. Statements are made up of symbols separated by delimiters. The categories of symbols include operators, identifiers, and constants. The operators are language primitives assigned by the compiler for specific operations or definitions in a program. Identifiers are unique names assigned by the programmer to data units, program elements and statement labels. Constants are known values that may be numeric, Hollerith strings, status values or Boolean.\n\nCMS-2 statements are free form and terminated by a dollar sign. A statement label may be placed at the beginning of a statement for reference purposes.\n\nA CMS-2 source program is composed of two basic types of statement. Declarative statements provide basic control information to the compiler and define the structure of the data associated with a particular program. Dynamic statements cause the compiler to generate executable machine instructions (object code).\n\nDeclarative statements defining the data for a program are grouped into units called data designs. Data designs consist of precise definitions for temporary and permanent data storage areas, input areas, output areas and special data units. The dynamic statements that act on data or perform calculations are grouped into procedures. Data designs and procedures are further grouped to form system elements of a CMS-2 program. The compiler combines system elements into a compile time system. A compile time system may stand alone or be part of a larger program.\n\nData declarative statements provide the compiler with information about data element definitions. They define the format, structure and order of data elements in a compile-time system. The three major kinds of data are switches, variables and aggregates.\n\nSwitches provide for the transfer of program control to a specific location in a compile-time system. They contain a set of identifiers or switch points to facilitate program transfers and branches. The switch represents a program address of a statement label or procedure name.\n\nA variable is a single piece of data. It may consist of one bit, multiple bits or words. A value may be assigned in the variable definition. Variables may hold a constant or changing value. Data types include integers, fix point, floating point, Hollerith character strings, status or Booleans.\n\nTables hold ordered sets of identically structured information. The common unit of data in a table is an item. Items may be subdivided into fields, the smallest subdivision of a table. Allowable data types contained in fields include integer, fixed point, floating point, Hollerith character string, status or Boolean. An array is an extension of the table concept. The basic structural unit of an array is an item. Array items contain fields as defined by the programmer.\n\nDynamic statements specify processing operations and result in executable code generation by the compiler. A dynamic statement consists of an operator followed by a list of operands and additional operators. An operand may be a single name, a constant, a data-element reference or an expression.\n\nMajor CMS-2 operators are summarized below.\nSpecial operators facilitate references to data structures and operations on them.\nThe dynamic statements that describe the processing operations of a program are grouped into blocks of statements called procedures.\n\nInput/output statements provide communication with hardware devices while running in a non-realtime environment under a monitor system.\nThe Compiler Monitor System 2 (CMS-2) was a system that ran on the UNIVAC CP-642B (AN/USQ-20). The system software included the monitor, compiler, librarian, CP-642 Loader, tape utility and flow charter.\n\nA batch processing operating system that controls execution of CMS-2 components and user jobs run on the CP-642 computer. It provides input/output, software library facilities and debugging tools. Job accounting is also provided.\n\nA compiler for the CS-1 and CMS-2 languages that generates object code for the CP-642, L-304, AN/UYK-7, 1830A and 1218/1219 computers. During the 1970s there were different versions of the CMS-2 compiler, depending on which computer was used to compile the code. Some source code had to be rewritten to work around some functions. And the different versions of CMS-2 had problems with the debugging tools.\n\nAn extended CMS-2 compiler, adding language features for the AN/UYK-7 computer. It only generates AN/UYK-7 object code.\n\nA file management system that provides storage and access to source and object code.\n\nTwo object code loaders for loading absolute or relocatable object code.\n\nA set of utilities for managing data on magnetic tape.\n\nThe flowcharter software processes flowcharter statements in CMS-2 source code and outputs a flowchart to a high-speed printer.\n\n\n"}
{"id": "32715643", "url": "https://en.wikipedia.org/wiki?curid=32715643", "title": "Caudalie", "text": "Caudalie\n\nCaudalie is a French skincare company, its trademark is grape-oriented skincare products.\n\nGraduated from Skema Business School, Mathilde Thomas's first job specialized in Perfume Series in Grasse.\n\nIn 1993, during the harvest of Château Smith Haut Lafitte, French husband and wife Mathilde and Bertrand Thomas met Professor Joseph Vercauteren of Pharmacy in Bordeaux, a polyphenols specialist, and his research team. Mr.Vercauteren shared one of his discoveries with them - that PCOs (procyanidolic oligomers) extracted from grape-seeds, are significantly more effective than vitamin E against free radicals.\n\nIn 1995, Mathilde and Bertrand Thomas launched Caudalie by developing a range of three products containing stabilized grape-seed polyphenols with anti-ageing properties. The name Caudalie means \"the haunting scent of wine\". The image of grape is always on the packages, it is also nicknamed as \"Big Grape\".\n\nIn 1999, Mathilde and Bertrand Thomas created their first Vinothérapie Spa in the grounds of Château Smith Haut Lafitte. Caudalie USA, a subsidiary, was founded in 2001.\n\nNowadays, Caudalie is a multi-channel French skincare company, specialising in anti-ageing, skincare, body care, fragrance & masks. Ingredients are derived from the grapevine.\n\nThe company is active in toxicology and ecology. It refuses to use artificial preservatives, mineral oil and animal by-products.\n\nMoreover, Caudalie is very eco-friendly. As a keen member of some eco organizations such as \"WWF\", \"Cœur de Forêt\", \"1% for the planet\", it donates the part revenue for animal and forest.\n\n"}
{"id": "23933118", "url": "https://en.wikipedia.org/wiki?curid=23933118", "title": "Complete Genomics", "text": "Complete Genomics\n\nComplete Genomics is a life sciences company that has developed and commercialized a DNA sequencing platform for human genome sequencing and analysis. This solution combines the company’s proprietary human genome sequencing technology with its informatics and data management software to provide finished variant reports and assemblies at Complete Genomics’ own commercial genome center in Mountain View, California. In March 2013 Complete Genomics was acquired by BGI-Shenzhen, a genomics services company in Shenzhen, Guangdong, China.\n\nComplete Genomics was founded in March 2006 by Clifford Reid, Radoje (Rade) Drmanac, and John Curson. Clifford Reid was the chairman, president and chief executive officer of Complete Genomics.\n\nIn February 2009, Complete Genomics announced that it had sequenced its first human genome and submitted the resulting variant data to the National Center for Biotechnology Information database. Then, in November 2009, Complete Genomics published sequence data for three human genomes in the journal Science. By the end of 2009, Complete Genomics had sequenced 50 human genomes. To date, the company has sequenced more than 20,000 genomes.\n\nThe resulting data has supported research in diverse areas such as screening of embryos, detection of genetic relationships, neurology, aging, a novel Mendelian disease with neuromuscular and cardiac involvement, eating disorders, Prader-Willi syndrome and autism, ophthalmology, and oncology. In 2014, a collaboration among Radboud University (The Netherlands), Maastricht University Medical Centre (The Netherlands), Central South University (China) and Complete Genomics identified major causes of intellectual disability using whole genome sequencing.\n\nComplete Genomics’ proprietary human genome sequencing technology is optimized for the exclusive study of human DNA, providing assembled sequences and variation files. The technology relies on DNA nanoball sequencing, which assembles short sequences of DNA into a full genome. It is designed to use lower volumes and concentrations of reagents than existing systems, and have large numbers of base reads per image.\n"}
{"id": "6901398", "url": "https://en.wikipedia.org/wiki?curid=6901398", "title": "Conrad Heyer", "text": "Conrad Heyer\n\nConrad Heyer (1749–1856) was an American farmer and veteran of the Revolutionary War who is notable for possibly being the earliest-born American to have been photographed.\n\nHeyer was born in the village of Waldoboro, Maine, then known as \"Broad Bay\" and part of the Province of Massachusetts Bay. The settlement had been sacked and depopulated by Wabanaki attacks and resettled with German immigrants recruited from the Rhineland. Among these settlers were the parents of Conrad Heyer, who also may have been the first white child born in the settlement.\n\nDuring the American Revolution, Heyer fought for the Continental Army under the command of George Washington and participated in Washington's famous crossing of the Delaware before the Battle of Trenton in December 1776. He was discharged in December 1777. After the war, he returned to Waldoboro, where he made a living as a farmer until his death in 1856. He was buried with full military honors.\n\nIn 1852, at the age of 103, Heyer posed for a daguerreotype portrait. He thereby became the earliest-born person of whom a photograph is known to exist. The claim is not without dispute, as the following men were also photographed: a shoemaker named John Adams, who claimed to be born in 1745; a Revolutionary War veteran named Baltus Stone, with a claim of 1744; and a slave named Caesar, with a claim of 1738.\n"}
{"id": "31166375", "url": "https://en.wikipedia.org/wiki?curid=31166375", "title": "David Karger", "text": "David Karger\n\nDavid Ron Karger (born May 1, 1967) is a professor of computer science and a member of the Computer Science and Artificial Intelligence Laboratory (CSAIL) at the Massachusetts Institute of Technology.\n\nKarger received a Bachelor of Arts degree from Harvard University and a PhD in computer science from Stanford University.\n\nKarger's work in algorithms has focused on applications of randomization to optimization problems and led to significant progress on several core problems. He is responsible for Karger's algorithm, a Monte Carlo method to compute the minimum cut of a connected graph. Karger developed the fastest minimum spanning tree algorithm to date, with Philip Klein and Robert Tarjan. They found a linear time randomized algorithm based on a combination of Borůvka's algorithm and the reverse-delete algorithm. With Ion Stoica, Robert Morris, Frans Kaashoek, and Hari Balakrishnan, he also developed Chord, one of the four original distributed hash table protocols.\n\nKarger has conducted research in the area of information retrieval and personal information management. This work has focused on new interfaces and algorithms for helping people sift effectively through large masses of information. While at Xerox PARC, he worked on the Scatter/Gather system, which hierarchically clustered a document collection and allow the user to gather clusters at different levels and rescatter them. More recently he has been researching retrieval systems that personalize themselves to best fit their individual users' needs and behaviors, leading the Haystack project. David Karger is also part of Confer: a tool for conference attendees used by many research conferences.\n\nKarger's dissertation received the 1994 ACM doctoral dissertation award and the Mathematical Programming Society's 1997 Tucker Prize. He also received the National Academy of Science's 2004 Award for Initiative in Research.\n\nKarger is married to Allegra Goodman, an American author. The couple live in Cambridge, Massachusetts and have four children, three boys and a girl.\n"}
{"id": "11060935", "url": "https://en.wikipedia.org/wiki?curid=11060935", "title": "Doom9", "text": "Doom9\n\nDoom9 is a website featuring information on digital audio and video manipulation (mostly video) and digital copyrights. It is also the forum username of the author of the page, an Austrian who was a college student at the time of the creation of the site. The site's tagline is \"The Definitive DVD Backup Resource\".\n\nStarted in March 2000, the site has expanded to contain a wide range of information on the subject of digital video encoding and DVD backup (or ripping). The most popular sections of the site were the guides to DVD ripping and the annual codec comparisons, where popular digital video codecs were compared on the basis of quality, speed, and compression. The forum is frequented by many developers of the tools and codecs featured on the site, such as FairUse4WM. The site has been criticized, as the techniques described by it can be used for copyright infringement, but it maintains that its guides should only be used for fair use. In some cases, users suspected of illegally copying media are refused help on the forums.\n\nThe VirtualDubMod project began after many modifications to VirtualDub were posted on the Doom9 forums.\n\nDoom9 gained notoriety as a result of its involvement in the AACS encryption key controversy. The utility BackupHDDVD was first posted by a Doom9 poster using the alias \"muslix64\". The earliest information on how to find title and volume keys was also first revealed on Doom9 forums, by other users. The key that set off the controversy was also first posted by a user using the name \"arnezami\".\n\nDoom9 is also known for being the main discussion forum for many major video encoding tools, such as x264, AviSynth and MeGUI.\n\nDue to the concentration of forum members who have technical backgrounds, there have been various software projects developed and maintained by forum members. These include:\n\nDoom9 members have also contributed significantly to various software projects, including:\n\n\n"}
{"id": "29723359", "url": "https://en.wikipedia.org/wiki?curid=29723359", "title": "Enterprise bus matrix", "text": "Enterprise bus matrix\n\nThe Enterprise Bus Matrix is a data Warehouse planning tool and model created by Ralph Kimball, and is part of the Data Warehouse Bus Architecture. The Matrix is the logical definition of one of the core concepts of Kimball’s approach to Dimensional Modeling – Conformed dimensions.\n\nThe Bus Matrix defines part of the Data Warehouse Bus Architecture and is an output of the Business Requirements phase in The Kimball Lifecycle. It is applied in the following phases of dimensional modeling and development of the Data Warehouse . The matrix can be categorized as a hybrid model, being part technical design tool, part project management tool and part communication tool\n\nThe Enterprise Bus Matrix stems from the issue of how one goes about creating the overall Data Warehouse environment. Historically there has been the structure of the centralized and planned approach and the more loosely defined, department specific, solutions developed in a more independent matter. Autonomous projects can result in a range of isolated stove pipe data marts. Naturally each approach has its issues; the overall visionary approach often struggles with long delivery cycles and lack of reaction time as the formalities and scope issues is evident. On the other hand, the development of isolated data marts, leading to Stovepipe systems that lacks synergy in development. Over time this approach will lead to a so-called data-mart-in-a-box architecture where interoperability and lack of cohesion is apparent, and can hinder the realization of an overall enterprise Data Warehouse. As an attempt to handle this matter Ralph Kimball introduced the enterprise bus.\n\nThe bus matrix purpose is one of high abstraction and visionary planning on the Data Warehouse architectural level. By dictating coherency in the development and implementation of an overall Data Warehouse the Bus Architecture approach enables an overall vision of the broader enterprise integration and consistency while at the same time dividing the problem into more manageable parts – all in a technology and software independent manner .\n\nThe bus matrix and architecture builds upon the concept of conformed dimensions - creating a structure of common dimensions that ideally can be used across the enterprise by all business processes related to the DW and the corresponding fact tables from which they derive their context. According to Kimball and Margy Ross's article “Differences of Opinion” \"\"The Enterprise Data warehouse built on the bus architecture ”identifies and enforces the relationship between business process metrics (facts) and descriptive attributes (dimensions)\"”.\n\nThe concept of a bus is well known in the language of Information Technology, and is what reflects the conformed dimension concept in the Data Warehouse, creating the skeletal structure where all parts of a system connect, ensuring interoperability and consistency of data, and at the same time considers future expansion. This makes the conformed dimensions act as the integration ‘glue’, creating a robust backbone of the enterprise Data Warehouse.\n\nFigure 1 shows the base for a single document planning tool for the whole of the DW implementation - a graphical overview of the enterprises core business processes or events each correspond to a measurement table of facts, that typically is complemented by a major source system in the horizontal rows. In the vertical columns the groups of contextual data is found as the common, conformed dimensions.\n\nIn this way the shared dimensions are defined, as each process indicates what dimensions it applies to through the cells figure 2. By this definition and coordination of conformed dimensions and processes the development of the overall data DW bus architecture is realized. The matrix identifies the shared dimensions related to processes and fact tables, and can be a tool for planning, prioritizing what needs to be approached, coordinating implementation and communicating the importance for conformed dimensions .\n\nKimball extends the matrix bus in detail as seen in figure 3 by introducing the other steps of the Datawarehouse Methodology; The Fact tables, Granularity, and at last the description of the needed facts. description of the fact tables, granularity and fact instances of each process, structuring and specifying what is needed across the enterprise in a more specific matter, further exemplifying how the matrix can be used as a planning tool.\n"}
{"id": "25644116", "url": "https://en.wikipedia.org/wiki?curid=25644116", "title": "Environmental chamber", "text": "Environmental chamber\n\nAn environmental chamber, also called a climatic chamber or climate chamber, is an enclosure used to test the effects of specified environmental conditions on biological items, industrial products, materials, and electronic devices and components.\n\nSuch a chamber can be used:\n\nAn environmental test chamber artificially replicates conditions which machinery, materials, devices or components might be exposed to. It is also used to accelerate the effects of exposure to the environment, sometimes at conditions not actually expected.\n\nChamber testing involves testing and exposing products to various environmental conditions in a controlled setting. Climatic Chamber testing and Thermal Shock testing are part of chamber testing. Climatic Chamber testing is a broad term used to describe different ways of simulating climate or excessive ambient conditions exposure for a product or a material under laboratory controlled yet accelerated conditions. On the other hand, Thermal Shock testing is used to simulate how materials will react when exposed to changes in extreme climatic conditions, such as going from extremely cold to extremely hot conditions in a very short period of time (usually only few seconds). \n\nThese conditions may include:\n\nManufactured samples, specimens, or components are placed inside the chamber and subjected to one or more of these environmental parameters to determine reliability or measure after-effects such as corrosion. In the case of machinery such as internal combustion engines, byproducts such as emissions are monitored.\n\nAn environmental chamber can be a small room used both to condition test specimens and to conduct the test. It can be a smaller unit that's used for conditioning test items. Also, some chambers are small enough to be placed onto a universal testing machine or other test apparatus.\n\nMany chambers are set at a certain set of conditions. Others can be programmed to cycle through specified sequences of conditions.\n\nAs test requirements may be relatively simple or complex, environmental test chambers vary widely in size, ranging from small units designed for placement on bench tops to large walk-in chambers. Test chambers generally have viewports or video feeds to allow for visual inspection of the sample during the test. Reach-in chambers provide an opening that technicians may use to handle test samples. Chambers providing interior visual lighting must take into account the heat generated and compensate accordingly.\n\nAs with the wide variance in size, a number of user control options are available, ranging from simple analog indicators up to more modern digital readouts with LCD displays. Chambers may be computer programmable, and networked or Web-enabled test chambers are also available.\n\n\nSeveral standards organizations provide standards and guidance on environmental test chamber construction, temperature control standards, and engineering tolerances.\n\n"}
{"id": "5827657", "url": "https://en.wikipedia.org/wiki?curid=5827657", "title": "F-14 Tomcat operational history", "text": "F-14 Tomcat operational history\n\nThe Grumman F-14 Tomcat has served with the United States Navy and the Islamic Republic of Iran Air Force (IRIAF) It operated aboard U.S. aircraft carriers from 1974 to 2006 and remains in service with Iran. In-depth knowledge of its service with Iran is relatively limited.\n\nThe F-14 primarily conducted air-to-air and reconnaissance missions with the U.S. Navy until the 1990s, when it was also employed as a long-range strike fighter. It saw considerable action in the Mediterranean Sea and Persian Gulf and was used as a strike platform in the Balkans, Afghanistan and Iraq until its final deployment with the United States in 2006.\n\nThe Tomcat made its combat debut during Operation Frequent Wind, the evacuation of American citizens from Saigon, in April 1975. F-14As from Fighter Squadron 1 (VF-1) and VF-2, operating from the , flew combat air patrols over South Vietnam to provide fighter cover for the evacuation route.\n\nVF-142 became the first Atlantic Fleet F-14 squadron to intercept a Soviet Tu-95 \"Bear\" on 23 April 1976. One of the routine tasks U.S. Navy F-14s performed was intercepting aircraft that approached U.S. carrier groups too closely. Soviet strategic bombers and maritime reconnaissance aircraft regularly patrolled near U.S. carriers during the Cold War and were often escorted away by F-14s. \n\nF-14 Tomcats were the primary interceptors of Tu-95 Bear D aircraft that flew anywhere in the vicinity of U.S. aircraft carriers during the Cold War. U.S. policy was not to let the Bear D come within several hundred miles of an aircraft carrier without an armed escort. During the height of the Cold War, a pair of Bear D aircraft would fly from the Kola peninsula to Cuba every week resulting in frequent intercepts as they passed along the Eastern coast of the United States. During the same time period, annual North Atlantic Treaty Organization (NATO) exercise in the North Sea area elicited daily flights of Bear D aircraft operating in pairs to locate the aircraft carrier(s) in the area. Operations Northern Wedding and Ocean Safari typically brought at least one U.S. Navy carrier into the Greenland–Iceland–United Kingdom (GIUK) gap during the exercise prompting considerable monitoring by Soviet surface ships, submarines, and aircraft. Tomcats were utilized to provide around-the-clock fleet air defense intercepting not only Soviet Bear D aircraft, but also Tu-16 \"Badger\" maritime strike and M-4 \"Bison\", An-12 \"Cub\", and Il-38 \"May\" surveillance aircraft which routinely attempted to target aircraft carrier battle groups.\n\nIn 1976 an F-14 operating from the was lost overboard near Scapa Flow sinking in water deep. The U.S. Navy, concerned that the Soviets might recover the wreckage and its AIM-54 Phoenix missiles, launched an underwater recovery operation costing several million dollars to salvage the wreckage.\n\nF-14s provided combat air patrols during Operation Fluid Drive, the evacuation of U.S. citizens from Beirut, Lebanon in 1976.\n\nBetween 1982 and 1986, F-14s performed combat air patrols and photo-reconnaissance in support of the Multinational Force in Lebanon and U.S. naval operations near the country's coast. Tactical Airborne Reconnaissance Pod System (TARPS) missions were used to identify artillery batteries firing on the peacekeeping force and provided target intelligence for naval gunfire support offshore.\n\nFrom November 1983 to the Spring of 1984, F-14s from carriers with VF-142 and VF-143, with VF-11 and VF-31 and with VF-14 and VF-32 flew almost daily TARPS missions over Lebanon. On 3 December 1983, two VF-31 F-14As from the \"Kennedy\" came under fire from Syrian anti-aircraft artillery and at least 10 surface-to-air missiles while conducting a TARPS mission. The F-14s were not hit and returned safely to the carrier. The next day, Tomcats provided fighter cover for a retaliatory air strike on Syrian positions. On 14 December 1983, Syrian anti-aircraft units fired surface-to-air missiles at another flight of F-14s. The missiles missed and the U.S. responded with naval gunfire from the , destroying several anti-aircraft sites.\n\nThe Syrian Air Force avoided direct confrontation with U.S. forces, although there was at least one instance when F-14s engaged, but did not open fire on, Syrian aircraft. Two F-14As from VF-11 engaged eight Syrian MiGs over Lebanon; the section flew cover for a TARPS F-14 and was ready to open fire when the four MiGs that were being targeted flew back toward Syria. The other MiGs flew through without engaging.\n\nIn April 1980, F-14s from VF-41 and VF-84 participated in an effort to free American hostages in Iran. The attempted rescue was called off during the early stages of execution.\n\nF-14s were involved in multiple U.S. military operations directed at Libya between 1980 and 1989. During this period, F-14s shot down four Libyan Air Force aircraft in two aerial engagements over the Mediterranean Sea.\n\nOn 21 September 1980, three F-14s from the \"Kennedy\" challenged eight Libyan fighters attempting to intercept a U.S. Air Force RC-135 reconnaissance plane two hundred miles from the Libyan coast. The Libyans disengaged once confronted by the U.S. fighters.\n\nIn the summer of 1981, F-14s from VF-41 and VF-84 performed combat air patrols in support of Freedom of Navigation operations in the Gulf of Sidra. Thirty-five pairs of Libyan Air Force fighters and fighter-bombers were intercepted and driven away from the U.S. fleet by F-14s from the and F-4 \"Phantom IIs\" from the on the first day of operations. The following day, on 19 August 1981, two Libyan Su-22 \"Fitters\" opened fire on two VF-41 F-14As with an AA-2 \"Atoll\" missile. The missile failed to hit either of the F-14s and the American pilots destroyed both Libyan aircraft with AIM-9L \"Sidewinder\" missiles. These were the first aerial combat victories in U.S. Navy F-14s and the first for the U.S. since the Vietnam War.\n\nFrom 24 July to 14 August 1983, F-14s assigned to the USS \"Dwight D. Eisenhower\" were involved in Operation Arid Farmer, the code-name for U.S. military assistance to Sudan, Egypt and the government of Hissène Habré of Chad during the Chadian-Libyan conflict. F-14s performed combat air patrols over waters in and near the Gulf of Sidra during the operation. Several flights of Libyan fighters were intercepted with neither side opening fire.\n\nF-14As from VF-102 came under fire from Libyan SA-5 surface-to-air missiles over the Gulf of Sidra during Freedom of Navigation exercises as part of Operation Attain Document on 24 March 1986. The missiles did not hit the F-14s. Later the same day, F-14As from VF-33 intercepted two Libyan MiG-25 \"Foxbats\" heading toward the U.S. naval force. The Libyans were outmaneuvered by the Tomcats, which got behind the MiG-25s, but the Americans did not receive permission to open fire. These events and several more surface-to-air missile launches prompted the U.S. Navy to initiate Operation Prairie Fire. F-14 Tomcats provided fighter cover during the operation.\n\nOn 15 April 1986, F-14s from VF-33, VF-102, VF-74 and VF-103 participated in Operation El Dorado Canyon, providing fighter cover for a series of air strikes against targets within Libya.\n\nOn 4 January 1989, two F-14As from VF-32 assigned to the USS \"John F. Kennedy\" shot down two Libyan MiG-23 \"Floggers\" off the coast of Libya. The Libyan fighters appeared to be maneuvering for a missile firing position when the Americans concluded they were under attack. The MiG-23s were shot down with AIM-7 \"Sparrow\" and AIM-9 Sidewinder missiles.\n\nIn April 1983, two F-14As from VF-102, operating from the , were fired on by Somali anti-aircraft units with an SA-2 Guideline while on a photo-reconnaissance mission over the port of Berbera in the Gulf of Aden. The Tomcats were on a prearranged mission at the request of the Somali government but were mistaken for attacking Ethiopian MiG-23s. The F-14s were not hit and were able to complete the mission.\n\nF-14s from VF-14 and VF-32, operating from the USS \"Independence\", flew combat air patrols and reconnaissance missions in support of Operation Urgent Fury, the U.S. invasion of Grenada in 1983. Tomcats from both squadrons provided fighter cover for Navy attack aircraft. TARPS-equipped F-14s from VF-32 also performed photo-mapping and post-strike damage assessment missions.\n\nFrom 8 to 10 October 1985, F-14s from the participated in operations involving the hijacked Italian cruise liner, MS \"Achille Lauro\". F-14As from VF-74 and VF-103 performed combat air patrols with the additional task of monitoring activity on the sea around the \"Achille Lauro\". Members of the U.S. National Security Council devised a plan that involved using the \"Saratoga's\" F-14s to intercept an aircraft that was to carry the hijackers to safety after U.S. intelligence discovered Egyptian authorities were preparing to put the hijackers on an EgyptAir 737 being flown to Tunisia.\n\nOn 10 October 1985, F-14As were launched from the \"Saratoga\" to perform the intercept. The 737’s exact takeoff time, route and altitude were unknown; so the plan involved crisscrossing the airliners's expected flight path over the Mediterranean Sea with an E-2C identifying contacts for the F-14s to perform positive identification on. The F-14s positively identified the correct airliner after four interceptions at night. The Tomcats formed up on the EgyptAir 737 and a U.S. Navy EA-6B jammed all of the airliner's communications except to the F-14s and E-2C. With the implied threat of a shoot-down, the 737's pilot chose to land at the NATO base in Sigonella, Sicily, where the airliner was quickly surrounded by U.S. and Italian security personnel.\n\nFrom July 1987 to September 1988, F-14s performed combat air patrols and escort missions in support of Operation Earnest Will during the \"Tanker War\". On 8 August 1987, the first shots by the U.S. at Iranian forces took place when two VF-21 F-14As from the opened fire on two Iranian F-4s that flew toward an American P-3C reconnaissance plane. The U.S. pilots observed two of the three AIM-7 Sparrows that were launched guiding toward one of the F-4s. The F-14 flight leader ordered an egress from the area after seeing one of the missiles explode but before any of the American aircrew could confirm whether the F-4 was actually shot down. U.S. spokesmen downplayed the incident, possibly to avoid public and Congressional backlash in the United States to the then-recent operations in the Persian Gulf. Some official statements suggested the F-14s fired warning shots or that the radar contacts were not real.\n\nF-14s from the provided fighter cover during Operation Nimble Archer in October 1987. Six months later, F-14s from the \"Enterprise\" provided fighter cover and escort for U.S. naval vessels and strike aircraft involved in Operation Praying Mantis in April 1988.\n\nTomcats performed combat air patrols in protection of U.S. carrier battle groups and coalition forces deploying to Saudi Arabia during Operation Desert Shield. The and battle groups, both of which had four F-14 squadrons between them, were the only U.S. assets capable of immediately responding to the Iraqi invasion of Kuwait and deterring any incursions into Saudi Arabia in August 1990. U.S. forces deploying to the theater did so initially under the protection of naval air cover.\n\nTen F-14 squadrons participated in the war against Iraq from 17 January to 28 February 1991 during Operation Desert Storm. Tomcats provided escort protection for attack aircraft, long range defense of ships, combat air patrols and performed tactical reconnaissance missions with TARPS. A total of 4,124 sorties were flown by the 99 F-14s in theater. The greater part of the sorties were air-to-air missions, although Tomcats were left with few aerial targets to contend with due in part to the rapid disintegration of Iraq's air defense system by coalition attacks, which grounded the majority of Iraq's air force.\nCompared to its U.S. Air Force counterpart, the F-15, there were greater limitations on the use of beyond visual range missiles for the F-14 during Operation Desert Storm. This was the result of the U.S. Navy not having developed the systems and procedures required to integrate its carrier air groups into a joint air component command, as Cold War-era tactics had the Navy operating on its own. Navy fighters were not able to solve the strict rules of engagement (ROE) using most of their on-board sensors and relied on outside clearance such as U.S. Air Force E-3 Sentries to receive permission to fire. In contrast, U.S. Air Force F-15s had the systems necessary to independently identify enemy aircraft from beyond visual range and were given the primary overland combat air patrol stations to intercept Iraqi aircraft that made it into the air.\n\nPolitical reasons have also been attributed to limiting aerial engagements involving F-14s during the Gulf War. According to accounts from Navy pilots, Navy fighters were called off from Iraqi aircraft so that other coalition fighters could engage them. One event used to support this notion occurred on 24 January 1991, when a U.S. Air force E-3 Sentry did not inform U.S. naval units of a pair of Iraqi Mirage F-1EQs that flew into the Persian Gulf. Saudi F-15s were vectored instead of F-14s that were in a better position to shoot down the Iraqi fighters. Another explanation for why the F-14s did not intercept the Mirage F-1s stems from some of the procedural and technical difficulties U.S. Air Force and U.S. Navy assets had in passing tactical information to each other. The E-3 could not directly contact the F-14s in a timely manner since they were under the control of the , which was not able to get a clear radar picture to accurately vector the F-14s.\n\nTomcat aircrews that encountered Iraqi fighters found that the Iraqis would disengage and flee once tracked by the F-14's radar and pursued. On the first day of \"Desert Storm\", two Iraqi MiG-21s attempting to escape from four VF-103 F-14Bs flew directly into a flight of four F/A-18s that shot down both MiGs. According to interviewed F-15 pilots, several kills by F-15s were made in a similar manner, with Iraqi aircraft being downed after retreating from Tomcats.\n\nIn addition to the air-to-air duties, Tomcats supported the coalition's need for battle damage assessments (BDA) and locating Scud missile launch sites by performing tactical reconnaissance missions utilizing TARPS. These missions helped fill in intelligence gathering gaps when cloudy skies prevented the use of space-based surveillance systems.\n\nOn 21 January 1991, an F-14B with its pilot, Lieutenant Devon Jones, and Radar Intercept Officer, Lieutenant Lawrence Slade, of VF-103 was shot down by an SA-2 surface-to-air missile while on an escort mission over Al Asad Air Base. Jones was recovered the following day, but Slade was captured and held as a prisoner of war until his release on 4 March 1991. This incident marked the only time a U.S. Navy F-14 was lost to hostile fire.\n\nOne air-to-air kill was credited to the F-14 during the war. An Iraqi Mil Mi-8 helicopter was shot down by a VF-1 F-14A using an AIM-9 Sidewinder on 6 February 1991.\n\nThe Tomcat faced an early retirement due to budget cuts following the end of both the Persian Gulf and Cold Wars in 1991. However, the retirement of the Grumman A-6 Intruder was impetus for the U.S. Navy to continue to use the F-14 by upgrading it with a precision strike capability.\n\nFollowing Operation Desert Storm, F-14s patrolled the no-fly zones that were established over Iraq for Operations Provide Comfort, Southern Watch and Northern Watch. F-14s performed combat air patrol, fighter escort, aerial reconnaissance and air interdiction missions in support of these operations until the 2003 Invasion of Iraq. TARPS-equipped F-14s provided Joint Task Force Southwest Asia with the ability to monitor Iraqi military activity on a daily basis in southern Iraq, making the Tomcat a primary asset in Operation Southern Watch.\n\nF-14s were often part of strike packages when conducting missions in support of Operation Southern Watch. During many of these missions, the Tomcat's long range allowed it to stay on station for twice as long as other U.S. Navy tactical aircraft. F-14s were able to remain on station after other Navy aircraft that made the ingress with them had to be replaced. The Tomcats would depart with the strike package after the pilots of the second set of aircraft declared that they needed fuel.\n\nOn 16 December 1998, F-14Bs from VF-32 took part in a 33-aircraft strike package that spearheaded Operation Desert Fox. The first night of the four-day operation was conducted by the U.S. Navy only. On 19 December, the last day of the operation, the arrived in the Persian Gulf and VF-213 joined the air strikes, taking the F-14D into combat for the first time. In addition to performing strike missions, F-14s from both squadrons conducted escort combat air patrols for U.S. Air Force B-1B bombers that were committed to the operation beginning on 17 December. Many firsts for the F-14 were achieved during \"Desert Fox\", including the first GBU-24 \"Paveway III\" laser-guided bombs dropped in combat by the U.S. Navy, the first multiple GBU-24 drop by any platform in combat, the first combat use of the Low Altitude Navigation and Targeting Infrared for Night (LANTIRN) targeting pod system, the first autonomous delivery of a GBU-10/16/24 laser-guided bomb by an F-14, and the first use of night vision devices in combat. VF-32 alone dropped of munitions during 16 strike missions and 38 sorties during the operation.\n\nTwo F-14Ds from VF-213 engaged several Iraqi aircraft challenging the no-fly zone on 5 January 1999. During the engagement, the F-14s were approached by a pair of MiG-23s that turned away before they were fired on. The F-14 aircrews then focused on a MiG-25 that continued to advance and launched two AIM-54C Phoenix missiles at it from very long distance. Both AIM-54s' rocket motors failed and the missiles did not hit their target. All of the Iraqi aircraft were able fly back out of the no-fly zone, although a MiG-23 was reported to have run out of fuel and crashed before reaching its base. This engagement marked the first time the U.S. Navy launched AIM-54s in combat. At the conclusion of VF-213's 1998–1999 cruise, the squadron had executed 19 strikes, dropped 20 laser-guided bombs with a 64-percent success rate, supported 11 combined strikes, flown 70 missions, logged 230 sorties with over 615 combat hours, and performed 45 reconnaissance missions imaging more than 580 targets.\n\nOn 9 September 1999, a VF-2 F-14 engaged an Iraqi MiG-23 with an AIM-54 Phoenix missile. Neither aircraft was damaged. F-14s also patrolled the no-fly zones in Iraq during Operation Northern Watch and Operation Southern Watch from the 1990s until 2003.\n\nIn August and September 1995, NATO launched Operation Deliberate Force, and the and its air wing supported the operation. F-14s from VF-14 and VF-41 participated in strikes. VF-41 is credited with being the first F-14 unit to drop laser-guided bombs in combat when, on 5 September 1995, two F-14As attacked an ammunition dump in eastern Bosnia. The bomb's targets were identified by laser indicators from F/A-18s because the F-14 was not yet cleared to carry the LANTIRN pod. VF-41 alone logged 600 combat hours and 530 sorties during this cruise.\n\nVF-14 and VF-41 took part in Operation Allied Force, NATO's aerial campaign against Serbian operations in Kosovo, between 9 April 1999 and 9 June 1999. F-14s of VF-14 dropped 350 laser-guided bombs, in addition to other air-to-ground ordnance. F-14s flew combat air patrol, escort, and strike missions; acted as Forward Air Controllers; and performed TARPS missions. VF-41 dropped the last bombs of the war on a dummy SA-9 surface-to-air missile launcher inside the Kosovo border near the peace-signing site on 9 June 1999.\n\nAfter the September 11, 2001 attacks, no fewer than eight F-14 squadrons participated in Operation Enduring Freedom, flying long-range missions from the Indian Ocean to strike targets around Afghanistan and conducting reconnaissance and ground support missions. From the start of Operation Enduring Freedom to the end of Operation Anaconda, F-14s from VF-14, VF-41, VF-102, VF-211, and VF-213 dropped more than of ordnance on targets. VF-11 and VF-143, alongside CVW-7, dropped of ordnance, both the \"Red Rippers\" and the \"Pukin' Dogs\" making history as they dropped JDAM bombs from the F-14 for the first time during combat. VF-103 arrived in Afghanistan in June 2002 when combat was scarce, and the \"Jolly Rogers\" did not get the opportunity to drop any bombs during the operation.\n\nDuring the war, VF-213 logged over 500 combat sorties, 2,600 combat hours, and dropped of ordnance (452 bombs) during their 10 weeks over Afghanistan; the \"Black Lions\" also had the distinct honor of dropping the first bombs of Operation Enduring Freedom. VF-102 dropped more bombs—680 of them, totaling —and logged more combat hours (more than 5,000) than any other F-14 unit that took part in the operation, and the unit dropped an additional of ordnance. VF-211 flew 1,250 combat sorties, logging 4,200 combat hours and dropping of ordnance. VF-14 led more strikes than any other squadron in CVW-8, and dropped 174 laser-guided bombs, totaling and buddy-lased 28 AGM-65 Maverick missiles and 23 laser-guided bombs, and like their sister squadron VF-41, they flew the oldest jets in the fleet. VF-41 dropped more than of bombs (202 laser-guided bombs) with an 82 percent hit rate, which was a level of accuracy that had never previously been achieved in the U.S. Navy.\n\nF-14s from VF-2, VF-31, VF-32, VF-154, and VF-213 participated in Operation Iraqi Freedom. The F-14s flew 2,547 combat sorties and dropped 1,452 GBU, JDAM, and MK-82 bombs with just one lost jet (from engine failure). F-14s led strikes on Baghdad, attacking targets such as the Iraqi Ministry of Information's Salman Pak radio relay transmitter facility at Al Hurriyah (southwest of central Baghdad) with JDAM bombs. Another notable mission involved TARPS-equipped F-14Ds dropping four Mark 82 bombs on Saddam Hussein's Presidential yacht \"Al-Mansur\" (The Victor). F-14s also supported ground troops during the war and acted as Forward Air Controllers for other aircraft. An aircrew from VF-32 was involved in the worst friendly-fire incident in the war when the crew attacked a U.S. Special Forces convoy in northern Iraq, believing they were Iraqi forces.\n\nDuring the F-14's last three years in service, the remaining units all deployed to the Persian Gulf region in support of the U.S. forces in Iraq. The final deployment for the F-14 was between September 2005 and March 2006 with VF-31 and VF-213. These two units collectively completed 1,163 combat sorties, totaling 6,876 flight hours. They dropped of ordnance during reconnaissance, surveillance, and close air support missions in support of the war in Iraq.\n\nBefore the Islamic Revolution the Shah of Iran, Mohammad Reza Pahlavi arranged to arm the Iranian Air Force with 80 Grumman F-14A Tomcats and 633 AIM-54 Phoenix missiles in a deal of $2 billion USD., in the 1970s Iran looked for an air superiority fighter counter Soviet air incursions of MiG-25 fighters.. In October 1978, two IIAF F-14As intercepted a high-and-fast–flying Soviet MiG-25 over the Caspian sea tracking it for two minutes and forcing it to abort a reconnaissance run over Iran.\n\nBy September 1980, the Islamic Republic of Iran Air Force (IRIAF) managed to make an increasing number of airframes operational, despite immense problems due to repeated purges of its officers. Some of those officers were executed; others were imprisoned, forced into exile, or forced to take early retirement. The IRIAF survived these times, and its Tomcats were to become involved in the war against Iraq, scoring their first kill on 7 September 1980.\n\nThere is limited information available about the service of F-14s in the Iran–Iraq War. Western intelligence indicates that the IRIAF was in decline at the onset of the war in September 1980, and it is rumored that some level of sabotage was committed on the F-14s by either Americans or Iranians loyal to the Shah, during the Iranian Revolution. Following the overthrow of the Shah, most Iranian F-14 pilots and technicians trained in the United States fled from Iran, fearing their association with the Shah's regime, and their time in the United States would endanger them. Only two pilots out of the original flight class chose to remain in Iran. Their fears proved correct, and many of the original Iranian F-14 crews and technicians who remained were jailed or executed by the new regime. Eventually, several jailed F-14 pilots were released when war broke out with Iraq.\n\nThe United States estimated that the IRIAF was able to keep between 15 and 20 F-14s operational by cannibalizing parts from other examples. The IRIAF claims a higher figure, and was able to assemble 25 aircraft for an 11 February 1985 fly-over of Tehran. Despite the U.S embargo following the Islamic Revolution, Iran was able to acquire parts for its F-14, these came via the Iran-Contra arms deal, collusion with Israel and the Kingdom of Saudi Arabia.\n\n\"GlobalSecurity\" indicates that Iran flew the F-14 in an AWACS-type role. To counter, Iraqi Mirage F1-EQs flew low-altitude profiles, popping up briefly to illuminate and launch missiles against the F-14s; several Tomcats were lost in this manner. GlobalSecurity also reports that less than 20 aircraft were still airworthy as of 2000, and cited one report that only seven can be airborne at one time.\n\nIt was thought for many years that Iran used the fighter primarily as an airborne radar controller, escorted and protected by other fighters, but later information indicates this was incorrect. While the IRIAF did husband its fleet of F-14s, the aircraft were used aggressively when needed, even escorting strike packages deep into Iraqi airspace. Initially, the IRIAF F-14s flew intensive CAP patrols, some lasting nine hours, over main bases. IRIAF Tomcats often escorted tankers supporting strike packages heading into Iraq, scanning over the border with their radars and intercepting inbound Iraqi aircraft. With the AWG-9 radar and long range AIM-54 and medium range AIM-7 missiles, the Tomcats could be used as offensive weapons without leaving Iranian airspace.\n\nUnited States AWACS aircraft observed the downing of an Iraqi Tupolev Tu-22 \"Blinder\" bomber, and the downing of at least one F-14. Western sources estimate four kills against four to five losses; the official Iranian estimate is 35-45 kills, and 12 losses, all reportedly due to engine failure during combat.\n\nAlso unresolved is the extent of usage of the AIM-54 Phoenix missile. Most Western sources indicate that sabotage prevented their use, although other sources claim that up to 25 planes were downed by AIM-54s before Iran's supply ran out. The Iranian F-14s used the AIM-7 Sparrow and AIM-9 Sidewinder air-to-air missiles as primary armament; Iran is reportedly developing a domestic copy of the Sparrow, as well as the Phoenix.\n\nIn 2004, Tom Cooper published \"Iranian F-14 Tomcat Units in Combat\", based mainly on primary interviews with Iranian pilots. The book makes many claims that contradict previous reports. In particular, Cooper claims that Iran's F-14s had up to 159 kills, and that in one incident, four Iraqi aircraft were shot down with one AIM-54 (The missile's warhead exploded between them and severely damaged them).\nThe first confirmed kill by an F-14A during the Iran–Iraq War occurred before the formal start of hostilities: on 7 September 1980, an IRIAF F-14A destroyed an Iraqi Mil Mi-25 (export variant of the Mil Mi-24) Hind helicopter using its 20mm Vulcan cannon. Six days later, Major Mohammad-Reza Attaie shot down an Iraqi MiG-21 with an AIM-54 Phoenix while flying a border patrol. A single AIM-54 fired in July 1982 by Captain Hashemi may have destroyed two Iraqi MiG-23s flying in close formation.\n\nCooper claims the AIM-54s were used only sporadically during the start of the war, most likely because of a shortage of qualified radar intercept officers, and then more frequently in 1981 and 1982—until the lack of thermal batteries suspended the missiles' use in 1986. There were also rumors that suggested that Iran's Tomcat fleet would be upgraded with avionics derived from the MiG-31 \"Foxhound\". However, IRIAF officials and pilots insist that the Soviets were never allowed near the F-14s, and never received any F-14 or AIM-54 technology. Also, the AIM-54 missile was never out of service in the IRIAF, though the stocks of operational missiles were low at times. Clandestine deliveries from US sources and black market purchases supplied spares to top up the Phoenix reserves during the war, and spares deliveries from the USA in the 1990s have also helped. Furthermore, an attempt was made to adapt the MIM-23 Hawk surface-to-air missiles that were also a carry-over from the pre-revolution period, to be used as air-to-air missiles for the F-14; at least two F-14s have been successfully modified to carry the hybrid weaponry.\n\nAll in all, the IRIAF was said to have launched possibly 70 to 90 AIM-54A missiles, and 60–70 of those scored. Of those, almost 90 percent of the AIM-54A missiles fired were used against Iraqi fighters and fighter-bombers. Only about a dozen victories by AIM-54s were claimed to be against fast, high-flying targets such as the MiG-25 or Tu-22 'Blinder'.\n\nBy the close of the war, both sides were unable to obtain new aircraft or parts, and aerial combat had become rare, since neither side could afford to lose aircraft they could not replace. In particular, the IRIAF F-14 fleet suffered from a lack of trained technicians, and by 1984 only 40 F-14s were still in service. By 1986, that number had dropped to just 25. The F-14 was relegated to protecting Iran's vital oil refining and export infrastructure; in this role, they often encountered French-built, Iraqi Dassault Mirage F1EQ fighters attempting to attack Iranian oil pipelines.\n\nOne IRIAF pilot distinguished himself in combat by becoming the all-time top scoring F-14 ace. Major Jalil Zandi is credited with shooting down eight Iraqi aircraft. He is additionally credited with three probable kills, bringing his total to 11 air victories. These include four MiG-23s, two Su-22s, two MiG-21 and three Mirage F1s.\n\nAnother notable Iranian pilot was Major Rahnavard, who on 16 February 1982 is reputed to have shot down four Iraqi fighter jets in two separate encounters over Kharg Island. Records indicate that two of his confirmed kills were Mirage F1s.\n\nIn the fall of 2015, a video surfaced of Iranian F-14s escorting Russian Tu-95 Bear bombers as they performed air strikes against the Islamic State of Iraq and the Levant.\n\n\n"}
{"id": "40319749", "url": "https://en.wikipedia.org/wiki?curid=40319749", "title": "First transcontinental telephone call", "text": "First transcontinental telephone call\n\nA telephone call, which for marketing purposes is claimed to be the first transcontinental telephone call, occurred on Jan. 25, 1915, a day timed to coincide with the Panama–Pacific International Exposition celebrations. However, the transcontinental telephone line was first completed on June 17, 1914, and successfully first voice tested in July 1914. A 1998 U.S. postage stamp commemorates the completion of the line in 1914.\n\nThe original long distance telephone network actually started in 1885, in New York City. By 1892 this line reached Chicago. After introducing loading coils in 1899, the long distance line continued west, and by 1911 it reached Denver, Colorado. The president of AT&T, Theodore Vail, committed the company to a transcontinental line in 1909.\n\nOn June 17, 1914, after affixing of telephone line, workers raised the final pole at Wendover, Utah, actually on the border between Nevada and Utah state lines. Then, Theodore Vail, the president of AT&T, succeeded in transmitting his voice across the continental U.S. in July 1914.\n\nSix months later, amidst the celebrations surrounding the Panama–Pacific International Exposition, on January 25, 1915, Alexander Graham Bell, in New York City, repeated his famous statement \"Mr. Watson, come here. I want you,\" into the telephone, which was heard by his assistant Dr. Watson in San Francisco, for a long distance call of . Dr. Watson replied, \"It will take me five days to get there now!\" The Alexander Graham Bell call officially initiated AT&T's transcontinental service. The phone call was merely symbolic. Dr. Watson was at 333 Grant Avenue in San Francisco to receive the call, placed by Bell from the Telephone Building at 15 Dey Street in New York City. President Woodrow Wilson and the mayors of both cities were also involved in the call.\n\nLater, President Woodrow Wilson spoke to an audience in San Francisco from the White House and is quoted as saying \"It appeals to the imagination to speak across the continent.\" However, President Wilson was concerned with the \"devaluation of the individual\" as AT&T celebrated the achievement of the company rather than distinguishing individual inventors, contributors, and innovators.\n\n"}
{"id": "3428805", "url": "https://en.wikipedia.org/wiki?curid=3428805", "title": "Food and Allied Workers Union", "text": "Food and Allied Workers Union\n\nThe Food and Allied Workers Union (FAWU) is a trade union in South Africa. It was formed through the amalgamation of the Food and Canning Workers' Union, the Sweet, Food and Allied Workers' Union and the Retail and Allied Workers' Union.\n\nFAWU is a founding affiliate of the South African Federation of Trade Unions (SAFTU).\n"}
{"id": "53741687", "url": "https://en.wikipedia.org/wiki?curid=53741687", "title": "Garrett Wade", "text": "Garrett Wade\n\nGarrett Wade is a family-owned business, established in 1975 and based in DUMBO, Brooklyn and Cincinnati, Ohio. It sources and sells a range of high quality hand tools, primarily for woodworking, gardening, and outdoor work, based on traditional designs. It is best known for its tools used for woodworking. Garry Chinn is the founder and CEO of Garrett Wade.\n\nIn the spring of 1975, Garretson Wade Chinn mailed the first Garrett Wade catalog. It contained primarily woodworking tools sourced from around the world, with particular focus on Europe. The goal of the catalog, along with media like Fine Woodworking Magazine, was to reconnect men to the experience of using their hands, as they had done in shop class as boys.\nIn 1995, responding to decreasing demand for woodworking tools, the company expanded its product line to hand tools for homeowners, with particular focus on gardening and outdoor tools. Recently, Garrett Wade also began researching, developing and manufacturing tools in-house.\n\nGarrett Wade was involved in the early success of other woodworking companies such as Lie Nielsen Toolworks and Lee Valley.\n\nToday, Garrett Wade products compete with mass-produced tools from companies such as Stanley and Craftsman although their tools are generally more unique than mainstream. They have sales of more than $10 million (USD) a year and approximately 220,000 customers. It continues to publish a catalog but has also developed a substantial online business.\n"}
{"id": "5775550", "url": "https://en.wikipedia.org/wiki?curid=5775550", "title": "Google Pay Send", "text": "Google Pay Send\n\nGoogle Pay Send (formerly Google Wallet) is a peer-to-peer payments service developed by Google that allows people to send and receive money from a mobile device or desktop computer at no cost to either sender or receiver. When set up, a Google Pay account must be linked to an existing debit card or bank account in the United States or United Kingdom. Google Pay Send can be used through the Google Pay Send app and Gmail. The app is available for Android devices running Android 4.0 and above, and for iOS devices running iOS 7.0 and above. \n\nSince 2018, Android Pay and Google Wallet has unified into a single pay system called Google Pay. Google Pay Send, a feature included inside Google Pay, has replaced the Google Wallet service.\n\nGoogle Pay is structured to allow its patrons to send money to each other. To send money, a Google Pay user enters the email address or phone number of the recipient. The recipient must then link that phone number or email address to a bank account in order to access those funds. If the recipient also has a Google Pay account, the funds will post to that account directly.\n\nUsers can link up to two bank accounts when the Wallet account is created. Received money goes to the Google Pay Balance and stays there until the user decides to cash out to a linked account.\n\nThe Google Pay app is available for free from either Google Play or the App Store. After downloading the app, the user creates a four-digit personal identification number (PIN) for managing everything within their Google Pay account. The PIN verifies access to the Wallet app on the user’s mobile device.\n\nBefore it was discontinued on June 30, 2016, the Google Wallet Card was recognized by the Cirrus network operated by MasterCard (rather than the Plus network operated by Visa).\n\nIn September 2017, Google launched its first major payments service outside the United States, Tez, in India.\n\nGoogle Pay Send is available only in the US and the UK.\n\nGoogle demonstrated the original version of the service at a press conference on May 26, 2011. The first app was released in the US only on September 19, 2011.\n\nOn May 15, 2013, Google announced the integration of Google Wallet and Gmail, allowing users to send money through Gmail attachments. While Google Wallet is available only in the United States, the Gmail integration is currently available in the U.S. and the United Kingdom.The physical Google Wallet Card was an optional addition to the app which allowed users to make purchases at point-of-sale (in stores or online) drawing from funds in their Google Wallet account, attached debit card account, or bank account. The card could also be used to withdraw cash at ATMs with no Google-associated fee, and could be used like a debit card for virtually any purpose, including such things as renting a car. The Wallet Card was discontinued on June 30, 2016, and replaced with Android Pay.\n\nThe original version of Google Wallet allowed users to make point-of-sale purchases with their mobile devices using near-field communication (NFC) technology. As of September 2015, however, Google dropped NFC from Google Wallet, offering the technology only through Android Pay, which is a separate application available only to Android users. As a result, any gift cards, loyalty programs, and promotional offers stored in an older version of Google Wallet could no longer be used. For Android users, those outstanding offers and gift cards were automatically transferred to Android Pay. For iOS users, instructions were provided to export the offers for alternative use. There were no reported security problems with the NFC technology.\n\nOn February 23, 2015, Google announced that it would acquire the intellectual property of the carrier-backed competitor Softcard and integrate it into Google Wallet, and that American mobile network operators AT&T Mobility, T-Mobile US, and Verizon Wireless would bundle the Google Wallet app on their compatible devices. The effective merger resulted in the new service known as Android Pay, a competitor to Apple Pay and similar NFC mobile payment service.\n\nSeparate from Android Pay, Google Wallet now allows peer-to-peer transactions for cases such as when people want to split the cost of shared expenses, reimburse each other, keep track of joint spending, or give money as a gift or loan.\n\nWhile Android Pay is only available to Android users, Google Wallet is available on iOS and via Gmail as well. For those using Android, the two products together (Android Pay and Google Wallet) offer a comprehensive payments management system, a “tool for staying in charge of the bank account.” Users can link their bank accounts or debit cards to Android Pay and to their Google Wallet app. With this approach, users can manage their money from one source, with the ability to:\n\nGoogle does not charge users for access to Google Wallet. Sending and receiving money is free, as is adding money to a Wallet Card through a linked bank account. There are limits on how much money users can add to their Wallet Balance, withdraw from the linked account or card, or send and receive to other individuals. These limits are set per transaction and within certain time periods. Previously, a 2.9% fee applied to funds added via debit card, although Google dropped that ability as of May 2, 2016.\n\nFunds sent from a Wallet balance, debit card, or linked bank account are generally available to the recipient immediately, and if the recipient has his or her own Wallet account and card, he or she can make an immediate withdrawal of those funds from an ATM. If the funds are drawn on the sender's Wallet balance, the balance will also reflect this change immediately. Any portion of funds drawn via a linked bank account will take two or three days to actually post to that account, though these funds will show as \"pending\" withdrawals on that account within 24 hours.\n\nWhile Google does not have revenue coming in from the Wallet ecosystem (the web service, app, and the Wallet Card), the product is part of a larger suite of e-commerce products, including Android Pay, which integrates loyalty programs and promotions from other businesses.\n\nGoogle Wallet protects payment credentials by storing user data on secure servers and encrypting all payment information with industry-standard SSL (secure socket layer) technology. Full credit and debit card information is never shown in the app. All Google Wallet users are also required to have a PIN to protect access to their Wallet account. The payments PIN is used for:\nGoogle also recommends having a general passcode on mobile devices for additional security.\n\nIn some cases, users have to verify their identity in order to make certain transactions. If prompted to do so, the user will visit the Wallet website and follow steps to ensure their accurate identity. This is in adherence with US Federal Deposit Insurance Corporation financial regulations that require payment providers to ensure customer identity.\n\nIf a Google Wallet Card is lost or stolen, users can immediately cancel access to it by signing into myaccount.google.com. Google also offers the additional flexibility of temporarily locking the card if a user suspects that the card has simply been misplaced. In the event of unauthorized transactions, Google Wallet Fraud Protection covers 100% of verified unauthorized transactions made in the US reported within 120 days of the transaction. Only US residents who have Wallet accounts associated with a US address are eligible for coverage under this policy.\n\nRegarding an earlier version of Google Wallet (in 2012), an analysis by security company Nowsecure revealed that some card information stored by Google Wallet was accessible outside of the application. It is suggested that hackers could create a way to intercept data by eavesdropping on Google Analytics, which monitors apps used on the Android OS. A previous analysis by the same firm revealed a number of other exploits that have since been fixed.\n\nPrivacy concerns include the storing of data regarding payment information, transaction details, payment attempts and other information stored by Google indefinitely. The privacy policy for Google Wallet, called the Google Payments Privacy Notice, indicates that much of the data is stored but may not be shared outside Google except under certain circumstances. Information that may be collected upon signing up includes credit or debit card number and expiration date, address, phone number, date of birth, social security number, or taxpayer ID number. Information that may be collected about a transaction made through Google Wallet includes date, time, and amount of transaction, merchant’s location and description, a description of goods or services purchased, any photo the user associates with the transaction, the names and email addresses of sender and recipient, the type of payment method used, and a description of the reason for the transaction if included.\n\nThe storage of such personal information about users' transactions is of significant financial value to a company that earns much of its revenue from data, but may be controversial to users aware of the policies. Information collected is shared with Google’s affiliates, meaning other companies owned and controlled by Google Inc., which can be used for their everyday business purposes. They provide the option to opt out of certain sharing capacities with these affiliates. Google states that it will only share personal information with other companies or individuals outside of Google in the following circumstances:\n\nShortly after the launch of Google Wallet's first iteration in 2011, PayPal filed a lawsuit against Google and two former employees of PayPal – Osama Bedier and Stephanie Tilenius. The complaint alleges \"misappropriation of trade secrets\" and \"breach of fiduciary duty\". The lawsuit revealed that Google had been negotiating with PayPal for two years to power payments on mobile devices. But just as the deal was about to be signed, Google backed off and instead hired the PayPal executive negotiating the deal, Bedier. The lawsuit noted that Bedier knew all of PayPal's future plans for mobile payments, as well as an internal detailed analysis of Google’s weaknesses in the area. Not only that, it accused him of storing \"confidential information in locations such as his non-PayPal computers, non-PayPal e-mail account, and an account on the remote computing service called 'Dropbox'.\"\n\nGoogle ran a competitor to PayPal, Google Checkout, from 2006 to 2013. In 2011, Google Wallet replaced Checkout's services, and development on Checkout was discontinued in 2013.\n\n"}
{"id": "52480700", "url": "https://en.wikipedia.org/wiki?curid=52480700", "title": "Graphotype (machine)", "text": "Graphotype (machine)\n\nThe Graphotype platemaker, is a type of metal marking machine originally used to create address plates for the Addressograph system and mark military style identity tags and other industrial nameplates.\n\nThese machines were manufactured by the Addressograph-Multigraph Company.\n\nThe machines came in a number of variants with sliding, hand wheel or keyboard selected letters. The keyboard models and some rotary select units were motorised to allow faster operation. Modern units are usually electronically controlled with computer interfaces.\n\nThe machines used in making Addressograph plates would deboss (pressed into the plate) the letters into the plate resulting in a well defined printing surface resembling the typewriter fonts of the day on the reverse side that would be used to transfer the details (usually customer addresses) onto envelopes or form letters. The same style was used in the early 40's to 80's for the US military identification tags and the tag details could be transferred onto medical charts using a hand held imprinter in field hospital conditions.\n\nThese same machines also found use in marking other nameplates and rating plates in industry and for this an embossed (raised letters in the style found on contemporary credit cards) marking style was preferred for ease of reading and maintaining a flat surface on the back of the plate. Military tags moved over to this style when the imprinting use was deprecated in the late 60's and new machines would only be supplied as embossing units as the address plate market had been taken over by the computer revolution.\n\nIn the Smithsonian Air and Space Museum in Washington DC the graphotype machine is mistakenly named a 'qraphotype machine'.\n"}
{"id": "41776913", "url": "https://en.wikipedia.org/wiki?curid=41776913", "title": "Gustav Ecke", "text": "Gustav Ecke\n\nGustav Emil Wilhelm Ecke (13 June 1896 – 17 December 1971) was a German and later American historian of art best known for his book \"Chinese Domestic Furniture\", first published in wartime China in 1944. The book presented the aesthetic of a neglected art form for scholars and connoisseurs and described the techniques of construction for cabinet-makers. It was the first book in any language on Chinese classic hardwood furniture.\n\nEcke was born in Bonn, Germany, a center of German Expressionism and Russian Constructivism and made lively by refugees from their home countries. His father, also Gustav Ecke (1855–1920) was a professor of theology at Bonn University. Ecke wrote his doctoral thesis on French Surrealism in 1922, and accepted an offer to be Professor of European Philosophy at University of Amoy in Fujian in 1923, then after five years moved to Tsinghua University in Beijing. In a brief return to Paris to conduct research, the prospects of fascism daunted him and he returned to China. He taught at Fujen University (Catholic University) and was a researcher at the National Institute of Architecture, both in Beijing. He was one of the founding editors of the scholarly journal Monumenta Serica. In 1945 he married the artist and scholar Tseng Yu-ho. The couple left China for Hawai’i in 1949. He was curator of Asian Art at the Honolulu Academy of Arts until he died in 1971.\n\nSoon after arriving in China in the early 1920s, Ecke turned his attention to China’s architectural history. Since there were few surviving wooden structures, he initially photographed and recorded stone buildings in Fujian, where he then taught. After moving to Beijing, he researched as many stone pagodas as he could find in nearby Hebei and Shandong before the outbreak of war in 1937. His book \"Twin Pagodas of Zayton\", published by the Harvard-Yenching Institute in 1935, and articles in \"Monumenta Serica\", presented some but by no means all of his findings.\n\nIn Beijing he joined a group of foreign residents, such as George Kates, Laurence Sickman, and the German photographer Hedda Morrison, who were the first to collect and catalog classic Chinese furniture. Few Chinese scholars had done research on the subject and Chinese collectors showed interest only in ornate carved and lacquered pieces. The hard times of the 1920s and 1930s forced many families to sell their finest pieces, and many were lost or even burned for fuel. Ecke and Sickman walked or rode by donkey through many parts of China in search of architecture and furniture. Ecke’s taste had been shaped by the Bauhaus movement in the Germany of his youth and its call for utilitarian beauty. One historian of art notes that he was “naturally attracted to the minimally decorated geometric forms and subtle beauty of what has become known as Ming-style furniture or classical Chinese furniture,” that is, hardwood pieces in the “Ming-style,” not necessarily furniture made in the Ming dynasty. These foreign scholars wrote the first books on what came to be known as Chinese “classic furniture.”\n\nEcke faced significant problems preparing his research in wartime. There were few reference works to rely on, little money for research assistance, travel was dangerous, and printing resources few. Ecke took apart and measured the furniture in his own collection to give detailed drawings of its construction. Photographs, some full-page, and drawings by Ecke’s collaborator Professor Yang Yue, show the construction of beds, chairs, tables, wardrobes, wash stands, clothes racks and other domestic items. \"Chinese Domestic Furniture in Photographs and Measured Drawings\" was published in a limited portfolio edition of 200 copies in Beijing in 1944, then reprinted as a standard book by Tuttle in 1962 and Dover Publications in 1985. Kirkus Review The book was influential in its choice of topic and manner of treatment. The classical style of furniture came to dominate the tastes of American collectors after the war partly because of this Bauhaus influence which Ecke and other scholars trained in Europe conveyed.\n\nEcke’s final book, \"Chinese Painting in Hawai’i\", written with his wife, said one scholar, was far more than a catalog of the museums holdings, but what another reviewer called a “monumental work” and in itself an “introduction to the study of Chinese painting.”\n\nIn 1991, the First International Symposium on Chinese Ming Domestic Furniture was held in Beijing in Ecke’s memory.\n\n\n\n"}
{"id": "47761", "url": "https://en.wikipedia.org/wiki?curid=47761", "title": "Hitchhiking", "text": "Hitchhiking\n\nHitchhiking (also known as thumbing or hitching) is a means of transportation that is gained by asking people, usually strangers, for a ride in their automobile or other vehicle. A ride is usually, but not always, free.\n\nItinerants have also used hitchhiking as a primary mode of travel for the better part of the last century, and continue to do so today.\n\nThe hand signals hitchhikers use to signal to drivers that they need a ride differ around the world. Indicators can be physical gestures or displays including written signs. In North America, the United Kingdom and in most of Europe, most hitchhikers stand with their back facing the direction of travel facing oncoming vehicles. The hitchhiker typically extends the arm towards the road with the thumb of the closed hand pointing upward or in the direction of vehicle travel. In some African countries, the hitchhiker's hand is held with the palm facing upwards. In other parts of the world, such as Australia, it is more common to use the index finger to point at the road. In 1971, during the Vietnam War, drivers invented methods to communicate various messages to hitchhikers (frequently soldiers in those areas of the U.S. near military bases). To indicate to a hitchhiking soldier that their vehicle has no additional space to accommodate them, a driver could indicate this by tapping on the vehicle roofs. Another common message that drivers could signal to hitchhikers—who usually sought to travel long distances, distances too far to walk in a reasonable amount of time—was that the driver's destinations were located nearby—and of little use to the hitchhiker—by pointing at the ground for a few seconds.\n\nHitchhiking is a historically common (autonomous) practice worldwide and hence there are very few places in the world where laws exist to restrict it. However, a minority of countries have laws that restrict hitchhiking at certain locations. In the United States, for example, some local governments have laws outlawing hitchhiking, on the basis of drivers' and hitchhikers' safety. In 1946, New Jersey arrested and imprisoned a hitchhiker, leading to intervention by the American Civil Liberties Union. In Canada, several highways have restrictions on hitchhiking, particularly in British Columbia and the 400-series highways in Ontario. In all countries in Europe, it is legal to hitchhike and in some places even encouraged. However, worldwide, even where hitchhiking is permitted, laws forbid hitchhiking where pedestrians are banned, such as the Autobahn (Germany), Autostrade (Italy), motorways (United Kingdom and continental Europe) or interstate highways (United States), although hitchhikers often obtain rides at entrances and truck stops where it is legal at least throughout Europe with the exception of Italy.\n\nIn 2011, Freakonomics Radio reviewed sparse data about hitchhiking, and identified a decline in hitchhiking in the US since the 1970s, which it attributed to a number of factors, including lower air travel costs due to deregulation, the presence of more money in the economy to pay for travel, more numerous and more reliable cars, and a lack of trust of strangers. Fear of hitchhiking is thought to have been spurred by movies such as \"The Texas Chain Saw Massacre\" and a few real stories of imperiled passengers, notably the kidnapping of Colleen Stan in California. See , below.\n\nJulian Portis points out that the rise of faster highways, such as freeways, motorways, and expressways, has made hitchhiking more difficult. He adds:\n\nSome British researchers discuss reasons for hitchhiking's decline in the UK, and possible means of reviving it in safer and more-organized forms.\n\nIn recent years, hitchhikers themselves have started efforts to strengthen their community. One example is the annual Hitchgathering, an event organized by the hitchhikers, for the hitchhikers. Websites such as hitchwiki and hitchbase are platforms for hitchhikers to share tips and provide a way of looking up good hitchhiking spots around the world.\n\nLimited data is available regarding the safety of hitchhiking. Compiling good safety data requires counting hitchhikers, counting rides, and counting problems: a difficult task.\n\nTwo studies on the topic include a 1974 California Highway Patrol study and a 1989 German federal police study. The California study found that hitchhikers were not disproportionately likely to be victims of crime. The German study concluded that the actual risk is much lower than the publicly-perceived risk; the authors did not advise against hitchhiking in general. They found that in some cases there were verbal disputes or inappropriate comments, but physical attacks were very rare.\n\nRecommended safety practices include:\n\n\nIn Cuba, picking up hitchhikers is mandatory for government vehicles, if passenger space is available. Hitchhiking is encouraged, as Cuba has few cars, and hitch hikers use designated spots. Drivers pick up waiting riders on a first come, first served basis.\n\nIn Israel, hitchhiking is commonplace at designated locations called \"trempiyadas\" ( in Hebrew, derived from the “German” \"trampen\"). Travelers soliciting rides, called \"trempists\", wait at trempiyadas, typically junctions of highways or main roads outside of a city.\n\nIn Nepal, hitchhiking is very common in rural areas. Many do not own cars so hitchhiking is a common practice especially in and around villages.\n\nIn the Netherlands, hitchhiking is legal and official signs indicate where one may wait for a ride. These designated hitchhiking locations are called \"liftershalte\" or \"liftplaats\" in Dutch, and they are particularly common in university towns.\n\nHitchhiking in Poland has a long history and is still popular. It was legalised and formalised in 1957 so hitchhikers could buy booklets including coupons from travel agencies. These coupons were given to drivers who took hitchhikers. By the end of each season drivers who collected the highest number of coupons could exchange them for prizes, and others took part in a lottery. This so-called \"Akcja Autostop\" was popular till the end of the 1970s, but the sale of the booklet was discontinued in 1995.\n\nHitchhiking in Ireland is legal, unless it takes place on motorways. A backpacker will most likely still get a lift if the car has enough space to park. Local police (Gardai) usually let backpackers get away with a verbal warning.\n\nHitchhiking became a common method of traveling during the Great Depression.\n\nWarnings of the potential dangers of picking up hitchhikers were publicized to drivers, who were advised that some hitchhikers would rob drivers and, in some cases, sexually assault or murder them. Other warnings were publicized to the hitchhikers themselves, alerting them to the same types of crimes being carried out by drivers. Still, hitchhiking was part of the American psyche and many people continued to stick out their thumbs, even in states where the practice had been outlawed.\n\nToday, hitchhiking is legal in 44 of the 50 states, provided that the hitchhiker is not standing in the roadway or otherwise hindering the normal flow of traffic. Even in states where hitchhiking is illegal, hitchhikers are rarely ticketed. For example, the Wyoming Highway Patrol approached 524 hitchhikers in 2010, but only eight of them were cited (hitchhiking was subsequently legalized in Wyoming in 2013).\n\nIn several urban areas, a variation of hitchhiking called slugging occurs, motivated by HOV lanes.\n\nFilm\n\n\nLiterature\nMusic\n\n\nTelevision\n\n\nFictional characters\n\n\nNotes\nBibliography\n\n"}
{"id": "44174713", "url": "https://en.wikipedia.org/wiki?curid=44174713", "title": "HostDime", "text": "HostDime\n\nHostDime, Inc is a global data center provider offering an array of cloud products including managed services for scalable cloud storage, dedicated servers, VPS, and colocation services. HostDime owns and operates infrastructure and networks in eight countries: the United States, Mexico, Brazil, United Kingdom, Netherlands, India, Colombia, and Hong Kong. Its flagship facility is in Orlando, Florida. In 2012, Inc.com reported that the company posted an annual revenue of more than $13.8 million USD with a 3-year growth rate of 74%.\n\nHostDime.com Inc. was founded in 2001 by Manny Vivar in Daytona Beach, Florida. It became a legal Florida corporation in November 2003 in Orlando, Florida. Due to continued quick growth, HostDime opened its first own datacenter in Downtown Orlando in December 2003 and moved its servers from a New Jersey Colocation facility.\n\nAs of 2017, HostDime is a privately held and self-funded company with no outside equity investors, and its internal company shareholders maintain full ownership of the company.\n\nHostDime operates one of the largest networks in the Central Florida region. In 2016, HostDime broke ground on a new seven-story headquarters in Eatonville, combining their administrative offices and their data center. Along with the Orlando flagship data center, HostDime owns and operates data centers in Mexico and Brazil, with network facilities in Colombia, Hong Kong, India, the United Kingdom, and the Netherlands.\n\nIt claimed to have over 5 million domains hosted in the entire fleet of data centers operated by HostDime and its subsidiaries globally, with a client base of over 50,000.\n\nIn November 2012, a report by human rights and digital media research lab Citizen Lab found that HostDime was among a handful of American companies selling hosting services to the Syrian government in direct opposition of an executive order from President Barack Obama. This sanctions order expressly prohibits transactions with certain governments without United States Treasury Department approval. The story was picked up by \"The New York Times\" in late November. Dennis Henry, the Vice President of HostDime Operations, revealed in \"The New York Times\" story that the website in question, Syria’s Ministry of Religious Affairs, was hosted by a customer who leased a server in their data center. Immediate steps were taken to sever ties from Syria and that matter was quickly resolved.\n\n"}
{"id": "24976623", "url": "https://en.wikipedia.org/wiki?curid=24976623", "title": "Hydrogen pinch", "text": "Hydrogen pinch\n\nHydrogen pinch analysis (HPA) is a hydrogen management method that originates from the concept of heat pinch analysis. HPA is a systematic technique for reducing hydrogen consumption and hydrogen generation through integration of hydrogen-using activities or processes in the petrochemical industry, petroleum refineries hydrogen distribution networks and hydrogen purification.\n\nA mass analysis is done by representing the purity and flowrate for each stream from the hydrogen consumers (sinks), such as hydrotreaters, hydrocrackers, isomerization units and lubricant plants and the hydrogen producers (sources), such as hydrogen plants and naphtha reformers, streams from hydrogen purifiers, membrane reactors, pressure swing adsorption and continuous distillation and off-gas streams from low- or high-pressure separators. The source-demand diagram shows bottlenecks, surplus or shortages. The hydrogen pinch is the purity at which the hydrogen network has neither hydrogen surplus nor deficit.\n\nAfter the analysis REFOPT from the Centre for Process Integration at The University of Manchester is used as a tool for process integration with which the process is optimized. The methodology was also developed into commercial software by companies such as Linnhoff March and AspenTech. The Aspen product incorporated the work of Nick Hallale (formerly a lecturer at University of Manchester) and was the first method to consider multiple components, rather than a pseudo-binary mixture of hydrogen and methane.\n\nThe first assessment based on cost and value composite curves of hydrogen resources of a hydrogen network was proposed by Tower et al. (1996). Alves developed the hydrogen pinch analysis approach based on the concept of heat pinch analysis in 1999. Nick Hallale and Fang Liu extended this original work, adding pressure constraints and mathematical programming for optimisation. This was followed by developments at AspenTech, producing commercial software for industrial application.\n\n\nNick Hallale, Ian Moore, Dennis Vauk, \"Hydrogen optimization at minimal investment\", Petroleum Technology Quarterly (PTQ), Spring (2003)\n\n"}
{"id": "210545", "url": "https://en.wikipedia.org/wiki?curid=210545", "title": "Industrialisation", "text": "Industrialisation\n\nIndustrialisation or industrialization is the period of social and economic change that transforms a human group from an agrarian society into an industrial society, involving the extensive re-organisation of an economy for the purpose of manufacturing.\n\nAs industrial workers' incomes rise, markets for consumer goods and services of all kinds tend to expand and provide a further stimulus to industrial investment and economic growth.\n\nThe first transformation to an industrial economy from an agricultural one, known as the Industrial Revolution, took place from the mid-18th to early 19th century in certain areas in Europe and North America; starting in Great Britain, followed by Belgium, Germany, and France. Characteristics of this early industrialisation were technological progress, a shift from rural work to industrial labor, financial investments in new industrial structure, and early developments in class consciousness and theories related to this. Later commentators have called this the First Industrial Revolution.\n\nThe \"Second Industrial Revolution\" labels the later changes that came about in the mid-19th century after the refinement of the steam engine, the invention of the internal combustion engine, the harnessing of electricity and the construction of canals, railways and electric-power lines. The invention of the assembly line gave this phase a boost.\nCoal mines, steelworks, and textile factories replaced homes as the place of work.\nBy the end of the 20th century, East Asia had become one of the most recently industrialised regions of the world. The BRICS states (Brazil, Russia, India, China and South Africa) are undergoing the process of industrialisation.\n\nThere is considerable literature on the factors facilitating industrial modernisation and enterprise development.\n\nAs the Industrial Revolution was a shift from the agrarian society, hence people migrated from villages in search of jobs to places where factories were set up. This shifting of rural people led to urbanisation and rise in the population of the towns. The concentration of labour into factories has increased urbanisation and the size of settlements, to serve and house the factory workers.\n\nWorkers have to either leave their families or bring them along in order to work in the towns and cities where these industries are found.\n\nThe family structure changes with industrialisation. The sociologist Talcott Parsons noted that in pre-industrial societies there is an extended family structure spanning many generations who probably remained in the same location for generations. In industrialised societies the nuclear family, consisting of only parents and their growing children, predominates. Families and children reaching adulthood are more mobile and tend to relocate to where jobs exist. Extended family bonds become more tenuous.\n\n the \"international development community\" (World Bank, Organisation for Economic Co-Operation and Development (OECD), many United Nations departments, and some other organisations) endorses development policies like water purification or primary education and co-operation amongst third world communities. Some members of the economic communities do not consider contemporary industrialisation policies as being adequate to the global south (Third World countries) or beneficial in the longer term, with the perception that they may only create inefficient local industries unable to compete in the free-trade dominated political order which industrialisation has fostered. Environmentalism and Green politics may represent more visceral reactions to industrial growth. Nevertheless, repeated examples in history of apparently successful industrialisation (Britain, Soviet Union, South Korea, China, etc) may make conventional industrialisation seem like an attractive or even natural path forward, especially as populations grow, consumerist expectations rise and agricultural opportunities diminish.\n\nThe relationships among economic growth, employment, and poverty reduction are complex. Higher productivity, it is argued, may lead to lower employment (see jobless recovery).\nThere are differences across sectors, whereby manufacturing is less able than the tertiary sector to accommodate both increased productivity and employment opportunities; more than 40% of the world's employees are \"working poor\", whose incomes fail to keep themselves and their families above the $2-a-day poverty line. There is also a phenomenon of deindustrialisation, as in the former USSR countries' transition to market economies, and the agriculture sector is often the key sector in absorbing the resultant unemployment.\n\n"}
{"id": "13512537", "url": "https://en.wikipedia.org/wiki?curid=13512537", "title": "Itautec", "text": "Itautec\n\nItautec is a Brazilian electronics company that was founded in 1979. The company is part of Itaúsa, which is one of the largest private Brazilian business group by sales volume.\n\nItautec makes consumer electronics, banking and retail automation. The company has the tenth largest base of ATMs in the world, and the second in Latin America. Headquartered in São Paulo and with a manufacturing plant in the city of Jundiaí (SP), Itautec has 5,709 direct employees - 5,285 in Brazil and 424 abroad.\n\nItautec is a well-known ATM, kiosk and computer manufacturer in the Brazilian and South American markets, and also has a key role in project deployment and IT services.\n\nPresently the company's product lines include:\n\n\n\n\n\n\n\n1979 – Itaú Tecnologia S.A. is created in Brazil\n\n1980 – First online presence as GRI \"Gerenciador de Redes Itautec\" \"Itautec Network Services Provider\" and Banktec Mainframes.\n\n1981 – Central agency of Itaú is founded, including an automation system developed by Itautec.\n\n1982 – Bank of Brazil installs GRI and Banktec\n\n1983 – Itautec automates Citibank\n\n1985 – PC/XT microcomputer launched\n\n1986 – Itautec installs the first compact Automated teller machine (ATM)\n\n1989 – Itautec links GRI to CICS, enabling integration between Banco Itaú with the Credicard network\n\n1989 – GRIP (\"Gerenciamento de Redes Itautec para PC\" \"Itautec Network Management for PCs\") is launched\n\n1990 – Launch of first Notebook computer, IS 386 Note\n\n1992 – Partnership with Intel for server distribution in Brazil\n\n1993 – First producer in Brazil to sell PCs with Windows 3.1 pre-installed and localized in Portuguese.\n\n1994 – Itautec launches a second-generation ATM in Brazil\n\n1995 – First version of Banktec Multicanal in Banco Itaú Argentina\n\n1996 – ATM with check dispenser\n\n1998 – Contract for 10,000 Bank of Brazil ATMs to be installed in 120 days, largest sale of ATMs in a single contract\n\n1999 – Moves into providing corporate services and applications, including development of web sites and maintenance\n\n2000 – AutoManager is installed in Banco Itaú, Argentina\n\n2001 – First ATMs exported to United States/Europe\n\n2002 – Itautec acquires technology from NMD for DelaRue, and insalls the first WEB system in Banco Itaú Buen Ayre.\n\n2005 – Itautec sells its holdings in Philco to Gradiente\n\n2007 – Itautec consolidates position as a large services and equipment provider in America and Europe\n\n2009 – Itautec expand international operations and consolidates its position in banking Automation in Brazil. Itautec also ranks in the 24th position in Fintech ranking, that lists the world's largest IT providers.\n\n2011 – Itautec debuts world’s first touchless 3D ATM.\n\nAmerican Banker article: \"ATM's Hologram Interface Deters Theft\"\n\nCredit Union Journal article: \"First Touchscreen 3D ATM Launched for CUMarket\"\n\n"}
{"id": "40690130", "url": "https://en.wikipedia.org/wiki?curid=40690130", "title": "LabWare", "text": "LabWare\n\nLabWare is a company that develops and implements Laboratory Information Management Systems (LIMS) and Electronic Laboratory Notebooks (ELN). The company is based in Wilmington, DE, and uses Smalltalk to develop both its LIMS and ELN.\n\nLabWare was founded in 1987 by Vance Kershner, who is the company's current president and CEO. It has offices in fifteen countries with customers in ninety. The company is headquartered in Wilmington, DE, with a training facility at Oberod Estate, a French-style Chateau in Centreville, DE built for Jane du Pont Lunger. LabWare pharmaceutical clients include Wyeth, Teva, AstraZeneca, Pfizer, Merck, and Bristol Myers Squibb. They also produce software for other industries, such as food and beverage, forensics, nuclear power, environmental and water testing. Their software is used to test for water, soil, food and air quality in the US, Ireland, Australia, and South Africa.\n\nLabWare uses Visual Smalltalk Enterprise to develop its products. In October 2014, LabWare joined the Pharo Consortium.\n\nLabWare LIMS automates laboratory processes and logs samples, tests, and results. It was created to automate clerical activities involved in processing analytical results in a lab environment and other lab processes. Lab settings in which LabWare LIMS has been used include forensics, pharmaceutical, food and beverage testing, and chemical manufacturing laboratories.\n\nLabWare also develops Electronic Laboratory Notebooks (ELN), a digital version of paper lab notebooks. Their ELN include search capabilities, a duplication function, and collaboration applications Labware ELN also make it possible to add images and multimedia observations directly to the notebook.\n\nLabWare won the \"Scientific Computing and Instrumentation’s\" Readers’ Choice Award in the Laboratory Information Management System (LIMS) category each year between 2000 and 2008. LabWare LIMS won a Frost & Sullivan Product Quality Leadership Award in 2004, and the company won Frost and Sullivan's European Laboratory Information Management Systems (LIMS) Company of the Year Award in 2008.\n\n"}
{"id": "33133270", "url": "https://en.wikipedia.org/wiki?curid=33133270", "title": "Lightbulb socket", "text": "Lightbulb socket\n\nA lightbulb socket, light socket, lamp socket or lampholder is a device which mechanically supports and provides electrical connections for a compatible electric lamp. Sockets allow lamps to be safely and conveniently replaced (re-lamping). There are many different standards for lampholders, including early \"de facto\" standards and later standards created by various standards bodies. Many of the later standards conform to a general coding system in which a socket type is designated by a letter or abbreviation followed by a number.\n\nThe most common type of sockets for mains electricity are Edison screws, used in continental Europe and North America, while bayonet mounts dominate in the Commonwealth countries and in the automotive industry. Fluorescent lamps typically require a two-pin, unthreaded socket.\n\nNot all lamps require a socket. For example, some miniature lamps have wire leads suitable for direct connection to screw terminals or other wires, and some reflector lamps provide screw terminals for electrical connections.\n\nEarly experimental incandescent lamps employed wire leads which had to be connected to screw terminals, but this was inconvenient for commercial use. The Edison organization used simple wooden receptacles with internal copper strips for lamps on the commercial steamship \"SS Columbia\", the first ship to use electric light bulbs. These sockets included key switches, but required bulbs to be mounted upright.\n\nThe Edison organization developed a screw-base in 1880 which was initially made of wood but later made of plaster of Paris. Many competitive designs of lamps and sockets appeared in the early era of incandescent lighting, which often were incompatible with other designs.\n\nThe construction of a lampholder socket defines and limits its intended use. Ceramic insulation can withstand considerably higher operating temperatures than bakelite or other plastics. The electrical components and wires must be designed to carry the intended current plus a safety factor.\n\nThe contact surface area, thickness and conductivity of the metal, connection methods and maximum operating temperature must all be considered in the design of a new socket. In addition, mechanical factors such as shape of the socket, fixture mounting and attachment, lamp support, ease of re-lamping and total cost of manufacture must be considered. Sockets designed for ordinary household and industrial use have much more design leeway than those used in precision applications.\n\nThe lampholder must be located far enough from the filament that the metals with the lowest melting point will remain solid. Historically this metal was a tin/lead solder whose melting point might be as low as 180 °C (360 °F). Due to the thermal changes from ambient temperature to full operating temperature, the design of a socket must allow for a considerable amount of expansion and contraction. Spring elements are required to accommodate these dimensional changes. However, the temperature at which a metal loses its spring is far below the melting point. This is why some older sockets that no longer work can be restored by prying up the base spring slightly.\n\nLampholder failures are usually caused by mechanical abuse or by overheating. A socket with a built-in switch is far more likely to fail in normal use as the switch parts wear out. Insulation failures are usually caused by impacts or by difficulty inserting or removing a lamp. Sockets used outdoors or in damp areas often suffer from corrosion which can cause the lamp to \"stick\" in the socket and attempts to change a lamp can result in breakage of either the lamp or the lampholder. The corrosion is not only environmentally produced but may be a result of the current flowing through the parts when there is appreciable resistance between the parts. Fixtures in such environments may require gaskets or other waterproofing methods to prevent buildup of moisture in the socket area.\n\n\nThe light bulb commonly used since the early 20th century for general-purpose lighting applications, with a pear-like shape and an Edison screw base, is referred to as an \"A-series light bulb.\" This most common general purpose bulb type would be classed as \"A19/E26\" or the metric version \"A60/E27\".\n\n\nWith bi-post bases, lamp orientation is fixed so filament will always be in the focal plane. Filament configurations such as the C13D (coiled, zig-zagged) emit far more light perpendicular to the zig-zag than parallel to it.\n\nCommon types:\n\n\nThe two-pin socket is an update of the bi-post design with smaller pins designed to reduce the cost of manufacture. The 1000-watt FEL medium two-pin base halogen lamp allows designers to insert the lamp into the end of the ellipsoidal reflector through a smaller hole than previously possible with conventional incandescent lamps. This improves efficiency compared to the older side-inserted lamp or a double-ended lamp which requires two holes. One variation is the polarized two-pin socket – used primarily in projectors, which defines the exact positioning of the filament on one side. This improves the \"point source\" characteristic necessary for building complex optical systems.\n\nAnother facet of the two-pin design is that many new designs of lamps use baseless glass envelopes. The wire leads are thickened and crimped in the glass envelope of the lamp base. The MR16 is an example of this design; the actual lamp is inserted into the reflector with the leads sticking out and a ceramic paste used to glue it in.\n\nMiniature lamps may have a wedge base made of glass or plastic. The base may be an extension of the glass envelope of the bulb, with the wire leads of the lamp folded up at the base. Some wedge bases are made of plastic and slipped over the wire leads. A wedge base holds the lamp by spring compression in the socket. The lamp is inserted and removed without twisting. Wedge base lamps are widely used in automotive applications, and many Christmas lights strings use plastic wedge-based bulbs.\n\nFluorescent Linear Tube Light bulbs are measured in ⅛s of inches. So a T12 fluorescent is 12 ⅛s of an inch in diameter or 12/8 = 1.50\"\n\nSome of the above base styles are now obsolete. The trend in recent years has been to design newer bases to reduce waste of raw materials and simplify the replacement process.\n\nThe United States standard for lamp sockets is published by ANSI and developed by NEMA. It is standard number C81.64, titled \"Guidelines and General Information for Electric Lamp Bases, Lampholders, and Gauges\" and outlines the dimensions and tolerances of standardized lamp sockets. Lamp bases are standardized in C81.61 \"Standard for Electrical Lamp Bases - Specifications for Bases (Caps) for Electric Lamps\". Both standards are harmonized with IEC standard 600061 and include dimensional data sheets as printed in the IEC standard.\n\n"}
{"id": "43679190", "url": "https://en.wikipedia.org/wiki?curid=43679190", "title": "List of Academicians of the Philippines", "text": "List of Academicians of the Philippines\n\nAcademicians are distinguished members of the National Academy of Science and Technology(\"abbreviated as\" NAST), the highest recognition and scientific advisory body of the Philippines. The first Academicians were appointed in 1978 by President Ferdinand E. Marcos. Possible members are distinguished scientists in their own field which are nominated by members of the scientific community. The current NAST members deliberate on the membership of an individual following strict rules and regulations. From their ranks, the next National Scientist of the Philippines would be nominated and approved by the President of the Philippines.\n\nNotes:\n"}
{"id": "319094", "url": "https://en.wikipedia.org/wiki?curid=319094", "title": "List of discoveries", "text": "List of discoveries\n\nThis article presents a list of discoveries and includes famous observations. \"Discovery\" observations form acts of detecting and learning something. Discovery observations are acts in which something is found and given a productive insight. The observation assimilates the knowledge of a phenomenon or the recording of data using instruments.\n\n\"Century of discovery and item\"\n\n\"Century of discovery, item and discoverer\"\n\n\n\n\n\n"}
{"id": "2238883", "url": "https://en.wikipedia.org/wiki?curid=2238883", "title": "Manifold System", "text": "Manifold System\n\nManifold System is a geographic information system (GIS) software package developed by Manifold Software Limited that runs on Microsoft Windows. Manifold System handles both vector and raster data, includes spatial SQL, a built-in Internet Map Server (IMS), and other general GIS features. Manifold System Release 8.00 was the first commercial product to include massively parallel GPGPU functionality utilizing NVIDIA GPUs, implemented within approximately 35 functions used in the raster transformation system. Manifold System has an active user community with a mailing list and online forums.\n\nThe development team for Manifold was created in 1993 to optimize mathematics libraries for a massively-parallel supercomputer created in a joint venture between Intel Corporation and the US Department of Defense. The team subsequently embarked on a plan to create and sell mathematics libraries, including the General Graph Facilities library (GGF) and the Computational Geometry Library (CGL), under the name of the Center for Digital Algorithms.\n\nA series of \"workbench\" products were created to help teach customers the operation of algorithms in the libraries using visual means. Road networks and geometric data in geographic contexts were used to provide visual familiarity and interest, in effect creating a GIS-like product. In 1997 and 1998 customers asked for a true GIS product based on the workbench products and development of Manifold System was launched. The company soon changed its name to Manifold Software Limited to match the new product's name.\n\nManifold System was first sold in January 1998 as Release 3.00. Releases 3.00 and 4.00 were heavily weighted to analytics, with many tools for abstract graph theory analysis but a very limited GIS toolset. At the request of GIS users and resellers, Release 4.50 emphasized general GIS features of broader interest and emerged as Manifold's first commercial GIS, a typical vector GIS more or less equivalent to classic vector GIS packages such as ArcView 3.x or MapInfo Professional.\n\nThe Release 5.00 series in 2001 and 2002 integrated display and editing of raster images and surfaces, including terrain elevation surfaces, and both 2D and 3D rendering. The 5.x series also introduced an integrated Internet Map Server (IMS) and the first Enterprise editions of Manifold System allowing collaboration by teams using shared components. The 5.x series also introduced a new spatial SQL and fuzzy logic using the Decision Support System.\n\nReleases since 2003 include 5.50, 6.00 (two major feature upgrades via service pack), 6.50, 7.00 and 7x. 6.50 introduced image tiling from Terraserver and OGC WMS image servers using Manifold as a client and extended IMS support to include OGC WMS when using Manifold as a server. 7.00 further extended IMS to include OGC WFS-T and image server functionality as well.\n\nRelease 7.00 was issued in May 2006 and followed up by Release 7x in the next three months. 7x was released in two flavors: 32-bit and 64-bit.\n\nRelease 7.00 introduced direct support for Oracle Spatial (vector drawings, raster images and raster surfaces) and included concurrent multiuser editing capability for Oracle and a variety of other databases, including DB2 and Microsoft SQL Server. 7.00 introduced multiprocessor support with multithreaded rendering of image libraries, multithreaded connections to DBMS providers and use of multiple processors in other areas as well.\n\n7.00 also introduced the Manifold Image Server interface API, allowing users to create modules that enable usage within Manifold of image servers such as Virtual Earth, Google Maps, Yahoo, Ask and others. Open source image server modules have been published by the user community in both 32-bit and 64-bit versions that enable automatic fetching and tiling of either satellite images or street map images from various image servers.\n\nRelease 8.00 was issued in the summer of 2007 and introduced 420 improvements. 8.00 expanded support for direct use of spatial DBMS beyond Oracle to include IBM DB2 with Spatial Extender, PostgreSQL / PostGIS and pre-releases of Microsoft's SQL Server 2008 spatial product available in 2007. 8.00 also introduced a Manifold-written spatial extender for Microsoft SQL Server 2005 as well as generic spatial DBMS capability from Manifold enabling spatial DBMS storage of vectors and rasters in any DBMS providing binary storage capability.\n\nRelease 8.00 became the first GIS product to include support for NVIDIA CUDA technology, in which massively-parallel architectures utilized in NVIDIA GPU cards, employing up to hundreds of stream processors per card, can be utilized to execute general purpose GIS code for computations on rasters. Typical speed increases when using NVIDIA CUDA reduce the time required for complex surface calculations in Manifold from minutes to seconds. For its use of NVIDIA CUDA Manifold System won the 2008 Geospatial Innovator Award at the GeoTec 2008 conference.\n\n8.00 was updated through 2008 to improve support for PostgreSQL/PostGIS, to support final production releases of Microsoft SQL Server 2008 and to support new Windows releases through Windows Server 2008 x64. As new Windows were issued Manifold verified compatibility for Release 8 through all Windows editions up to current Windows 10 and related Windows server editions, both in 32 bit and x64. \n\nIn December 2015 Manifold.net announced that Manifold's parallel database engine for OEMs, Radian, would be the foundation for future releases of Manifold System GIS, and provided a road map for Radian Studio and Manifold Release 9 implementations in 2016. Beta testing for Radian commenced in 2016 with a first release of Radian Studio in February 2017. \n\nA series of updates for 8.00 were issued in 2017 to add integration with ODBC access to Radian data sources. This gave Release 8 the ability to connect, through Radian, to any data source Radian can use, expanding Release 8 connectivity to data sources 8.00 previously could not access, such as MrSID, ESRI file geodatabases, numerous GDAL/OGR sources and similar.\n\nLater versions have benefited greatly from community involvement via online discussion and beta testing. From July 2002 to May 2017 over 4000 new items have been cited in release notes, many of which originated in the user community.\n\nThe online Georeference forum was started by David Brubacher and William Howell in 2004 and incorporated into the manifold.net site in January 2006 at forum.manifold.net\n\n"}
{"id": "2063352", "url": "https://en.wikipedia.org/wiki?curid=2063352", "title": "Mechanised agriculture", "text": "Mechanised agriculture\n\nMechanised agriculture is the process of using agricultural machinery to mechanise the work of agriculture, greatly increasing farm worker productivity. In modern times, powered machinery has replaced many farm jobs formerly carried out by manual labour or by working animals such as oxen, horses and mules.\n\nThe entire history of agriculture contains many examples of the use of tools, such as the hoe and the plough. But the ongoing integration of machines since the Industrial Revolution has allowed farming to become much less labour-intensive.\n\nCurrent mechanised agriculture includes the use of tractors, trucks, combine harvesters, countless types of farm implements, aeroplanes and helicopters (for aerial application), and other vehicles. Precision agriculture even uses computers in conjunction with satellite imagery and satellite navigation (GPS guidance) to increase yields.\n\nMechanisation was one of the large factors responsible for urbanisation and industrial economies. Besides improving production efficiency, mechanisation encourages large scale production and sometimes can improve the quality of farm produce. On the other hand, it can displace unskilled farm labour and can cause environmental degradation (such as pollution, deforestation, and soil erosion), especially if it is applied shortsightedly rather than holistically.\n\nJethro Tull's seed drill (ca. 1701) was a mechanical seed spacing and depth placing device that increased crop yields and saved seed. It was an important factor in the British Agricultural Revolution.\n\nSince the beginning of agriculture threshing was done by hand with a flail, requiring a great deal of labour. The threshing machine, which was invented in 1794 but not widely used for several more decades, simplified the operation and allowed the use of animal power. Before the invention of the grain cradle (ca. 1790) an able bodied labourer could reap about one quarter acre of wheat in a day using a sickle. It was estimated that for each of Cyrus McCormick's horse-pulled reapers (ca. 1830s) freed up five men for military service in the US Civil War. Later innovations included raking and binding machines. By 1890 two men and two horses could cut, rake and bind 20 acres of wheat per day.\n\nIn the 1880s the reaper and threshing machine were combined into the combine harvester. These machines required large teams of horses or mules to pull. Steam power was applied to threshing machines in the late 19th century. There were steam engines that moved around on wheels under their own power for supplying temporary power to stationary threshing machines. These were called \"road engines,\" and Henry Ford seeing one as a boy was inspired to build an automobile.\n\nWith internal combustion came the first modern tractors in the early 1900s, becoming more popular after the Fordson tractor (ca. 1917). At first reapers and combine harvesters were pulled by teams of horses or tractors, but in the 1930s self powered combines were developed. \n\nAdvertising for motorised equipment in farm journals during this era did its best to compete against horse-drawn methods with economic arguments, extolling common themes such as that a tractor \"eats only when it works\", that one tractor could replace many horses, and that mechanisation could allow one man to get more work done per day than he ever had before. The horse population in the US began to decline in the 1920s after the conversion of agriculture and transportation to internal combustion. Peak tractor sales in the US were around 1950. In addition to saving labour, this freed up much land previously used for supporting draft animals. The greatest period of growth in agricultural productivity in the US was from the 1940s to the 1970s, during which time agriculture was benefiting from internal combustion powered tractors and combine harvesters, chemical fertilisers and the green revolution.\n\nAlthough farmers of corn, wheat, soy, and other commodity crops had replaced most of their workers with harvesting machines and combines by the 1950s enabling them to efficiently cut and gather grains, growers of produce continued to rely on human pickers to avoid the bruising of the product in order to maintain the blemish-free appearance demanded of consumers. The continuous supply of illegal workers from Latin America that were willing to harvest the crops for low wages further suppressed the need for mechanisation. As the number of illegal workers has continued to decline since reaching its peak in 2007 due to increased border patrols and an improving Mexican economy, the industry is increasing the use of mechanisation. Proponents argue that mechanisation will boost productivity and help to maintain low food prices while farm worker advocates assert that it will eliminate jobs and will give an advantage to large growers who are able to afford the required equipment.\n\nAsparagus are presently harvested by hand with labour costs at 71% of production costs and 44% of selling costs. Asparagus is a difficult crop to harvest since each spear matures at a different speed making it difficult to achieve a uniform harvest. A prototype asparagus harvesting machine - using a light-beam sensor to identify the taller spears - is expected to be available for commercial use.\n\nMechanization of Maine's blueberry industry has reduced the number of migrant workers required from 5,000 in 2005 to 1,500 in 2015 even though production has increased from 50-60 million pounds per year in 2005 to 90 million pounds in 2015.\n\nAs of 2014, prototype chili pepper harvesters are being tested by New Mexico State University. The New Mexico green chile crop is currently hand-picked entirely by field workers as chili pods tend to bruise easily. The first commercial application commenced in 2015. The equipment is expected to increase yield per acre and help to offset a sharp decline in acreage planted due to the lack of available labour and drought conditions.\n\nAs of 2010, approximately 10% of the processing orange acreage in Florida is harvested mechanically, mainly with citrus canopy shaker machines. Mechanization has progressed slowly due to the uncertainty of future economic benefits due to competition from Brazil and the transitory damage to orange trees when they are harvested.\n\nThere has been an ongoing transition to mechanical harvesting of cling peaches (mostly used in canning) where the cost of labor is 70 percent of a grower's direct costs. In 2016, 12 percent of the cling peach tonnage from Yuba County and Sutter County in California will be mechanically harvested. Fresh peaches destined for direct consumer sales must still be hand-picked.\n\nAs of 2007, mechanised harvesting of raisins is at 45%; however the rate has slowed due to high raisin demand and prices making the conversion away from hand labour less urgent. A new strain of grape developed by the USDA that drys on the vine and is easily harvested mechanically is expected to reduce the demand for labour.\n\nStrawberries are a high cost-high value crop with the economics supporting mechanisation. In 2005, picking and hauling costs were estimated at $594 per ton or 51% of the total grower cost. However, the delicate nature of fruit make it an unlikely candidate for mechanisation in the near future. A strawberry harvester developed by Shibuya Seiki and unveiled in Japan in 2013 is able to pick a strawberry every eight seconds. The robot identifies which strawberries are ready to pick by using three separate cameras and then once identified as ready, a mechanised arm snips the fruit free and gently places it in a basket. The robot moves on rails between the rows of strawberries which are generally contained within elevated greenhouses. The machine costs 5 million yen. A new strawberry harvester made by Agrobot that will harvest strawberries on raised, hydroponic beds using 60 robotic arms is expected to be released in 2016.\n\nMechanical harvesting of tomatoes started in 1965 and as of 2010, nearly all processing tomatoes are mechanically harvested. As of 2010, 95% of the US processed tomato crop is produced in California. Although fresh market tomatoes have substantial hand harvesting costs (in 2007, the costs of hand picking and hauling were $86 per ton which is 19% of total grower cost), packing and selling costs were more of a concern (at 44% of total grower cost) making it likely that cost saving efforts would be applied there.\n\nAccording to a 1977 report by the California Agrarian Action Project, during the summer of 1976 in California, many harvest machines had been equipped with a photo-electric scanner that sorted out green tomatoes among the ripe red ones using infrared lights and colour sensors. It worked in lieu of 5,000 hand harvesters causing displacement of innumerable farm labourers as well as wage cuts and shorter work periods. Migrant workers were hit the hardest. To withstand the rigour of the machines, new crop varieties were bred to match the automated pickers. UC Davis Professor G.C. Hanna propagated a thick-skinned tomato called VF-145. But even still, millions were damaged with impact cracks and university breeders produced a tougher and juiceless \"square round\" tomato. Small farms were of insufficient size to obtain financing to purchase the equipment and within 10 years, 85% of the state's 4,000 cannery\ntomato farmers were out of the business. This led to a concentrated tomato industry in California that \"now packed 85% of the nation’s tomato products\". The monoculture fields fostered rapid pest growth, requiring the use of “more than four million pounds of pesticides each year” which greatly affected the health of the soil, the farm workers, and possibly the consumers.\n\n"}
{"id": "8073707", "url": "https://en.wikipedia.org/wiki?curid=8073707", "title": "Mole-Richardson", "text": "Mole-Richardson\n\nMole-Richardson, also known as Mole, is a stage lighting instrument and motion picture lighting manufacturing company originally based in Hollywood, California. The company was started in 1927 by Sicilian immigrant Pietro \"Peter\" Mule (changed to Mole). Born November 10, 1891, in the Italian town of Termini Imerese, Palermo, Sicily, he first worked for General Electric (GE) in New York.\n\nIn 1927 he began selling incandescent tungsten lighting to the film industry, which allowed a more natural lighting than the previous arc lights. The new lights were also silent, an advantage for the new sound films.\n\nMole-Richardson invented the Fresnel Solar Spot unit in 1935, adapting the fresnel lighthouse lens for use in motion pictures. It won the first of four technical Academy Awards the company has earned.\n\nDuring World War II, Mole-Richardson concentrated their efforts on developing searchlights for battleships, tanks and artillery units to aid the Allied Forces' battle in Europe and the Pacific. In 1945, Peter Mole was invited to light the first United Nations conference held in San Francisco.\n\nPeter Mole died on August 2, 1960, very suddenly. His son-in-law, Warren Parker, took over the company. Mole-Richardson Company is now run by two of Warren Parker's four sons and grandchildren of Peter Mole, Larry Mole Parker and Mike Parker.\n\nMole-Richardson is considered by many to be the staple of motion picture and television lighting in the movie industry today, setting the standard for tungsten fresnel fixtures. However, they do also manufacture HMI (Hydrargyrum Medium-arc Iodide) day-light lighting units. Their lighting is generally recognized by their maroon coloring and \"MR\" logos.\n\nIn August 2015, the company moved to Pacoima neighborhood of Los Angeles, California.\n\n"}
{"id": "42901970", "url": "https://en.wikipedia.org/wiki?curid=42901970", "title": "Nasal strip", "text": "Nasal strip\n\nA nasal strip, external nasal dilator strip or nasal dilator strip is a type of adhesive bandage with embedded plastic ribs or splints that is applied across the bridge of the nose and sides of the nostrils, to assist in keeping the airway open. They are believed to make breathing easier and for that reason are used during athletic exertion and as an aid to reduce congestion or to prevent snoring. Various studies have not indicated that they have a performance-enhancing effect. They are also used by race horse trainers on horses for similar reasons; they are thought to reduce airway resistance and lower the risk of exercise-induced pulmonary hemorrhage (EIPH), plus reduce fatigue and aid post-race recovery.\n\nIn humans, the nasal valve is the narrowest part of the nasal aperture and when exercising, this area is subjected to negative pressure and becomes smaller. Nasal strips adhere to the skin, holding open the anterior nasal aperture and prevent it from collapsing. When properly applied, they lift and widen the space in the nasal passage. They are a drug-free method to maintain airway flow and are available as an over the counter product. They have no reported side effects other than possible skin irritation from the adhesive.\n\nStudies indicate that they are useful in increasing nasal cavity volume in the front three centimeters of the human nose, and for that purpose could be an alternative to decongestive nose sprays, but nasal strips are not particularly helpful for congestion in the posterior nasal apertures. They also have been shown to reduce snoring loudness and improve quality of sleep. Subjects wearing the strips in tests indicated that they believed that the strips helped them breathe more easily, and they are of particular interest to those human athletes who have to wear a mouthguard and need to be able to breathe more through their nostrils than their mouths. Studies have not necessarily demonstrated that athletic performance is increased, but people wearing them seem to have far less dyspnea or shortness of breath while exercising.\n\nIn horses, they are viewed as helpful because the animals cannot breathe through their mouths, only through their nostrils. As with humans, the equine design helps keep the nasal valve from collapsing due to the negative pressure created by physical exertion. However, their primary benefit is to prevent bleeding in the lungs (EIPH), not to directly enhance performance. The equine version was invented by two veterinarians, James Chiapetta and Edward Blach. In the 1990s, they were inspired by the human product to attempt to create a similar device for horses. They had observed horses on treadmills and saw that, under exertion, the equine nasal passage also narrowed due to the tissue being sucked in. They worked out a licensing agreement with CNS, the company that manufactured the human \"Breathe Right\" brand of nasal strips in 1997 (now owned by GlaxoSmithKline) where the company manufactured the equine form of the nasal strip, and paid royalties to Chiapetta and Blach. The equine version was first used publicly at the 1999 Breeders' Cup horse races and the 2000 Summer Olympics. In 2001, they parted ways with CNS and formed their own company, Flair, and in 2008, Chiapetta bought out Blach.\n"}
{"id": "7531185", "url": "https://en.wikipedia.org/wiki?curid=7531185", "title": "Outline of space exploration", "text": "Outline of space exploration\n\nThe following outline is provided as an overview of and topical guide to space exploration:\n\nSpace exploration – use of astronomy and space technology to explore outer space. Physical exploration of space is conducted both by human spaceflights and by robotic spacecraft.\n\nSpace exploration\n\n\n\n\n\nLunar (the Moon)\nSun\nMercury\nVenus\nMars\nOuter Solar System\nBeyond the Solar System\n\n\n\n\n\n"}
{"id": "28224888", "url": "https://en.wikipedia.org/wiki?curid=28224888", "title": "Pottery gauge", "text": "Pottery gauge\n\nA pottery gauge is one of various tools used in pottery to ensure that pots thrown on a potter's wheel are uniform in size or shape. Some pottery gauges simply ensure that the height and diameter are consistent, others are templates or shapers.\n"}
{"id": "28689721", "url": "https://en.wikipedia.org/wiki?curid=28689721", "title": "Sachet", "text": "Sachet\n\nA sachet is a small cloth scented bag filled with herbs, potpourri, or aromatic ingredients. A sachet is also a small porous bag or packet containing a material intended to interact with its atmosphere; for example, desiccants are usually packed in sachets which are then placed in larger packages.\n\nA sachet can be defined as a small soft bag containing perfumed or sweet-smelling items also referred to as an \"ascent bag,\" \"scent bag\", \"sweet bag\", \"sachet bag\", \"sachet de senteurs\", \"spiced sachet\", \"potpourri sachet\", \"scented sachet\", \"perfume cushion\", \"smelling cushion\", \"scented cushion\", \"fragrant bag\", \"pomander\" and \"dream pillow.\"\n\nDuring the Chinese Warring States period a scented sachet was an ornament worn on the body and used to absorb sweat, repel insects and ward off evils. In the Han Dynasty both boys and girls wore sachets and in the Tang Dynasty and Song Dynasty scented bags gradually became preferred only by women. A scented sachet became a love token in the Qing Dynasty. \n\nIn medieval Europe the sachet was known as a \"plague-bag\". These were generally worn around the neck, or dangled from the waist. It was believed that they provided protection against parasites and miasmata. These \"sachets\" contained sweet powders, aromatic calamus, benzoin, storax, galingale, cloves, and other fragrances from a herb or flower garden.\n\nQueen Isabella of Spain used fragrant sachets consisting of dried rose and carnation petals, orris and calamus root, and other ingredients like powdered coriander seeds. In the nineteenth century a sachet filled with hops was called a \"Pulvinar Humuli\" and used by George III of Great Britain and Prince Albert of Saxe-Coburg to help induce sleep.\n\nIn modern times, a small cloth bag filled with potpourri may be laid among garments in a dresser.\n\nScented sachets are for containing odorous substances to be laid among handkerchiefs to perfume them. They are also used to make undergarments and outer garments sweet smelling as well as placed amongst linens. Scented sachets are also hung in closets and cupboards. They are also put into briefcases and luggage. Some are used in stationary packets and others are put under pillows to help one sleep. Scented sachets are \"sweet bags\" (an old name for a small sachet cloth bag) and are put in automobiles, clothes dryers, clothes closets, inside or about children's stuffed animals, on the backs of chairs, and on doorknobs.\nSachets with herbs like hops and lavender act as a sedative. These type of sachets are often put in closets and dresser drawers for their scents.\n\nSome \"dream pillow\" types of scented sachets (i.e. \"hop pillows\") are made with sleep inducing ingredients like hops, chamomile, valerian, skullcap, and lavender that help promote sleep. These scented sachets of aromatic herbs are also referred to as \"herb pillows\" or \"sleep pillows\" and are designed to overcome sleeplessness.\n\nRam's 1606 booklet \"Little Dodoen\" gave a sachet formula to take to bed to help one sleep:\nCertain herbs used in these type sachet \"sleep pillows\", like hops, have a soporific and a slight narcotic effect. These herb filled sachets are even called \"dreamtime pillows\". There are formulas using rosemary seeds to fill sachets and these are to be hung in a bedroom to promote sleep. The traditional method to treat insomnia with herb filled sachets of hops or lavender is to place them in, under or near your sleeping pillow. The \"dream pillow\" or \"sleep pillow\" sachet concept has been used for decades to help overcome sleeplessness. These \"sleep pillows\" have a therapeutic effect and hops as an ingredient to this type of sachet are considered best at inducing sleep. One type of \"sleep pillow\" sachet recipe by herb and flower author Penny Black calls for violets, rose petals, rosemary, tonka bean, vanilla bean, and a drop of lemon oil.\n\nScented sachets are many times homemade and come in many sizes, styles, shapes and fragrances. A typical size would be approximately 4 inches square or thereabouts - some as small as a one-inch ball and others as large as an 8 inch square. Many are in the shape of a plump little pillow. The potpourri mix put inside the sachet can be herbal items or flower parts. Some sachets that are made from spices like allspice, aniseed, cinnamon, cloves, nutmeg, and vanilla beans are referred to as \"spiced sachets.\" A scented sachet used as a pot holder that is stuffed with allspice, cinnamon and cloves will release an apple pie smell when a hot dish is put on it.\n\nOther scented sachets are made from the winter savory, lavender, rosemary, tops of hyssop, chippings of \"cassia ligna\", cedar, and sassafras. This type is not only used to make garments sweet smelling but keep away destructive insects and worms. Sachets with dried moth-repellent herbs like wormwood, southernwood, costmary, lavender, pennyroyal, lemon verbena rosemary, rue, sage and tansy are called \"moth bags.\"\n\nA sachet base can be made where you can add certain aromatic or perfumed oils later to make various sachets. Some types of sachets are called \"Patchouli Sachet\" (that goes with woolens and blankets); \"Florida Sachet\" (which ingredients are fruity); \"Oakasia Sachet\"; \"Orange-rose Sachet\"; and \"Sweet Bag of linen\". Some scented sachets even have names like \"\"Heliotrope Sachet\" and \"Tonka Bean Sachet.\" Others still are called \"Provencal pillows\", \"Country pillows\" and \"Pillows for Love\".\n\nSome are even made into Sweet Bag necklaces. Some are decorated with embroidery, beads, buttons, ribbons, and fancy cloth. The oldest formula printed for a list of ingredients in an America scented sacket comes from a Colonial Williamsburg book, The Compleat Housewife, published in 1742.\n\n"}
{"id": "10130426", "url": "https://en.wikipedia.org/wiki?curid=10130426", "title": "Safe Load Indicator", "text": "Safe Load Indicator\n\nA Safe Load Indicator (SLI) or an Automatic Safe Load Indicator (ASLI) is a device which is installed on mobile or portal cranes to alert the operator if the lift is exceeding the safe operating range of the machinery. In some cases, the device will physically lock the machinery in circumstances it determines to be unsafe. SLI systems are usually composed of a microprocessor connected to various sensors on the crane itself. The SLI measures the angle and extension of the boom along with the load weight and compares this with the manufacturer's specifications to determine if the lift is safe.\n\nA safe load indicator has the capability of detecting the angle, weight of load lifted, and ground radius of any lifting device. It controls the lifting equipment to the level that it tries to keep the machinery functioning as per the manufacturer's suggested safety charts.\n\nThe crane is fitted with multiple sensors, for each of the measured parameters, which are then further displayed in the operator's cabin for his benefit.\n"}
{"id": "10064136", "url": "https://en.wikipedia.org/wiki?curid=10064136", "title": "Separation principle", "text": "Separation principle\n\nIn control theory, a separation principle, more formally known as a principle of separation of estimation and control, states that under some assumptions the problem of designing an optimal feedback controller for a stochastic system can be solved by designing an optimal observer for the state of the system, which feeds into an optimal deterministic controller for the system. Thus the problem can be broken into two separate parts, which facilitates the design.\n\nThe first instance of such a principle is in the setting of deterministic linear systems, namely that if a stable observer and a stable state feedback are designed for a linear time-invariant system, then the combined observer and feedback is stable. The separation principle does not hold in general for non-linear systems in general. Another instance of the separation principle arises in the setting of linear stochastic systems, namely that state estimation (possibly nonlinear) together with an optimal state feedback controller designed to minimize a quadratic cost, is optimal for the stochastic control problem with output measurements. When process and observation noise are Gaussian, the optimal solution separates into a Kalman filter and a linear-quadratic regulator. This is known as linear-quadratic-Gaussian control. More generally, under suitable conditions and when the noise is a martingale (with possible jumps), again a separation principle applies and is known as the separation principle in stochastic control\n\n. A separation principle also exists for the control of quantum systems.\n\nConsider a deterministic LTI system:\n\nformula_1\n\nwhere\n\nWe can design an observer of the form\n\nand state feedback\n\nDefine the error \"e\":\n\nThen\n\nNow we can write the closed-loop dynamics as\n\nSince this is triangular, the eigenvalues are just those of \"A\" − \"BK\" together with those of \"A\" − \"LC\". Thus the stability of the observer and feedback are independent.\n\n"}
{"id": "33376157", "url": "https://en.wikipedia.org/wiki?curid=33376157", "title": "Signal analyzer", "text": "Signal analyzer\n\nA signal analyzer is an instrument that measures the magnitude and phase of the input signal at a single frequency within the IF bandwidth of the instrument. It employs digital techniques to extract useful information that is carried by an electrical signal. In common usage the term is related to both spectrum analyzers and vector signal analyzers. While spectrum analyzers measure the amplitude or magnitude of signals, a signal analyzer with appropriate software or programming can measure any aspect of the signal such as modulation. Today’s high-frequency signal analyzers achieve good performance by optimizing both the analog front end and the digital back end.\n\nModern signal analyzers use a superheterodyne receiver to downconvert a portion of the signal spectrum for analysis. As shown in the figure to the right, the signal is first converted to an intermediate frequency and then filtered in order to band-limit the signal and prevent aliasing. The downconversion can operate in a swept-tuned mode similar to a traditional spectrum analyzer, or in a fixed-tuned mode. In the fixed-tuned mode the range of frequencies downconverted does not change and the downconverter output is then digitized for further analysis. The digitizing process typically involves in-phase/quadrature (I/Q) or complex sampling so that all characteristics of the signal are preserved, as opposed to the magnitude-only processing of a spectrum analyzer. The sampling rate of the digitizing process may be varied in relation to the frequency span under consideration or (more typically) the signal may be digitally resampled.\n\nSignal analyzers can perform the operations of both spectrum analyzers and vector signal analyzers. A signal analyzer can be viewed as a measurement platform, with operations such as spectrum analysis (including phase noise, power, and distortion) and vector signal analysis (including demodulation or modulation quality analysis) performed as measurement applications. These measurement applications can be built into the analyzer platform as measurement firmware or installed as changeable application software.\n"}
{"id": "1231218", "url": "https://en.wikipedia.org/wiki?curid=1231218", "title": "Slate (writing)", "text": "Slate (writing)\n\nA slate is a thin piece of hard flat material, such as the rock also called slate, that is used as a medium for writing. The rock is “a metamorphic rock created by the recrystallization of the minerals in shale from clay to parallel-aligned, flat, flake-like minerals such as mica”. \n\nThe writing slate consisted of a piece of slate, typically either 4x6 inches or 7x10 inches, encased in a wooden frame. \n\nA precise date range for writing slates of this type has not been established. \n\nUsually, a piece of cloth or slate sponge was used to clean it and this was sometimes attached with a string to the bottom of the writing slate. \n\nThe writing slate was used by children in America in one-room schoolhouses to practice writing and arithmetic during classes or at home and in multi-room schools until the twentieth century. \n\nThe writing slate was sometimes used by industry workers to track goods and by sailors to calculate their geographical location at sea. Sometimes multiple pieces of slate were bound together into a “book” and horizontal lines were etched onto the slate surface as a guide for neat handwriting.\n\nThe exact origins of the writing slate remain unclear. References to its use can be found in the fourteenth century and evidence suggests that it was used in the sixteenth and seventeenth centuries. The central time period for the writing slate, however, “appears to begin in the later eighteenth century, when developments in sea and land transport permitted the gradual expansion of slate quarrying in Wales and the growth of a substantial slate workshop industry.” By the nineteenth century, writing slates were used around the world in nearly every school and were a central part of the slate industry. At the dawn of the twentieth century, writing slates were the primary tool in the classroom for students. In the 1930s (or later) writing slates began to be replaced by more modern methods. However, writing slates did not become obsolete. They are still made in the twenty-first century, though in small quantities.\n\nSlate itself had been in use as a building material long before it was used for writing. The use of slate as a roofing material can be traced back to at least the Roman era in Wales, from the first to the fourth century AD. The slate used in roofing had to be of very high quality, as the material is prone to cracking and can break if not handled with great care. Slate used for writing slates also had to be of good quality because of the thinness required. Mining slate of this quality is a straightforward process since slate splits into nearly perfectly flat surfaces. The difficult part of the mining process is sorting out the quality slate from slate with “cats” or flaws. Properly sorted slate can be made into any required size. Roofing slate is still in use, primarily for the restoration of eighteenth and nineteenth century buildings, as it is fairly expensive.\n\n\n"}
{"id": "9353706", "url": "https://en.wikipedia.org/wiki?curid=9353706", "title": "Spontaneous combustion", "text": "Spontaneous combustion\n\nSpontaneous combustion or spontaneous ignition is a type of combustion which occurs by self-heating (increase in temperature due to exothermic internal reactions), followed by thermal runaway (self heating which rapidly accelerates to high temperatures) and finally, autoignition.\n\n\n\nThere have been unconfirmed anecdotal reports of people spontaneously combusting. This alleged phenomenon is not considered true spontaneous combustion, as supposed cases have been largely attributed to the wick effect, whereby an external source of fire ignites nearby flammable materials and human fat or other sources.\n\nHay is one of the more studied materials in spontaneous combustion. As hay varies by the type of grass and location grown utilized in its preparation, it is very hard to establish a unified theory of what occurs in hay self-heating. It is anticipated that dangerous heating will occur in hay that contains more than 25% moisture. The largest number of fires occurs within 2 to 6 weeks of storage, with the majority occurring at 4 to 5 weeks.\n\nThe process may begin with microbiological activity (bacteria or mold), but at some point, the process has to become chemical. Microbiological activity will also limit the amount of oxygen available in the hay. Moisture appears to be quite important, no matter what process. At 100 °C, wet hay absorbed twice the amount of oxygen of dry hay. There has been conjecture that the complex carbohydrates present in hay break down to simpler sugars, which are more readily oxidized.\n\nCharcoal, when freshly prepared, can self-heat and catch fire. This is separate from hot spots which may have developed from the preparation of charcoal. Charcoal that has been exposed to air for a period of eight days is not considered to be hazardous. There are many factors involved, two being the type of wood and the temperature at which the charcoal was prepared.\n\nSelf-heating in coal has been extensively studied. The tendency to self-heat decreases with increasing rank of the coal. Lignite coals are more active than bituminous coals, which are more active than anthracite coals. Freshly mined coal consumes oxygen more rapidly than weathered coal, and freshly mined coal self-heats to a greater extent than weathered coal. The presence of water vapor may also be important, as the rate of heat generation accompanying the absorption of water in dry coal from saturated air can be an order of magnitude or more than the same amount of dry air.\n\nOil seeds and residue from oil extraction will self-heat if too moist. Typically, storage at 9–14% moisture is satisfactory, but limits are established for each individual variety of oil seed. In the presence of excess moisture just under levels required for germinating seed, the activity of mold fungi to generate heat is a likely candidate. This has been established for flax and sunflower seeds, as well as soy beans. Many of the oil seeds generate oils that are self-heating. Palm kernels, rapeseed, and cotton seed have also been studied. Rags soaked in linseed oil can spontaneously ignite if improperly stored or discarded.\n\nNotes\nBibliography\n\n"}
{"id": "89493", "url": "https://en.wikipedia.org/wiki?curid=89493", "title": "São Carlos", "text": "São Carlos\n\nSão Carlos (Saint Charles, in English, ; named after Saint Charles Borromeo) is a city of 246,088 inhabitants (IBGE/2017) in the state of São Paulo, Brazil. It is located at , at about 230 km from the city of São Paulo.\n\nThe region started to be settled in the end of the 18th century, with the opening of a road that led to the gold mines in Cuiabá and Goiás. Leaving from Piracicaba, passing through Rio Claro, the hills, fields and by typical vegetations of the Brazilian countryside, settlers established in the region. São Carlos' history started in 1831, when the \"Pinhal\" (Pines) allotment was demarcated.\n\nOn the city's foundation date, November 4, 1857, the population resided in some houses around the chapel and the inhabitants were mostly Arruda Botelho's family heirs, who were the first owners of the \"Pinhal\" alloments. Between 1831 and 1857 the pioneer coffee farms were formed, starting the first economic activity in the city. The coffee crops came to the \"Pinhal\" farm in 1840 and spread throughout the fertile lands around, becoming the main export item. The city foundation is credited to Antônio Carlos de Arruda Botelho, Count of Pinhal, an influent farmer and entrepreneur.\n\nSão Carlos was elevated to village in 1865, when a \"Câmara\", or ruling chamber, was created. In 1874, the village had 6,897 inhabitants, as a humble highlight of its fast growth and regional importance. It became a city in 1880 and in 1886, with a population of 16,104, its urban structure was settled.\n\nThe city arises on the coffee crops expansion context, which is relevant to the last two decades of the 19th century and to the first two of the 20th century. The arrival of the railway in 1884 provided an efficient system to transport the coffee production to the Santos harbor and boosted the economy of the region. The railway also contributed to the political and economic consolidation of the central area of the city.\n\nWhen slavery ended, government created incentives to bring in immigrants. São Carlos had already received German nationals brought by the Count of Pinhal in 1876. Between 1880 and 1904, the city was one of the most important immigration centers in São Paulo state, the majority of them being Italians - specifically, Northern Italians. They worked in coffee plantations and in manufacturing factories, as well as trading activities.\n\nIn the beginning of the 20th century, countless cultural societies developed social activities aiming to promote literacy. Vittorio Emanuele Society in 1900 and Dante Alighieri in 1902 were but a few of them. The Italian presence was so significant that during the first half of the 20th century, the Italian government had a consulate branch in São Carlos.\n\nWith the Wall Street crash of 1929, coffee production went through a crisis, which made many immigrants leave rural areas for factories, wood artifact production, pottery, and construction.\n\nFarmers had already applied the profits obtained with coffee in the constitution of several types of companies in São Carlos: banks, electricity, cable cars, telephones, water pumps, sewers, theaters, hospitals and schools. This established a foundation for industrialization in the city. With the arrival of immigrants from other urban centers from the 1930s - 1940s, their expertise was used to consolidate industrialization as the main economic activity in the city. Its peak years were the 1950s, when São Carlos became a manufacturing center, with relevant industrial expression in São Paulo state.\n\nThe industrial sector also developed through workshops that incorporated the coffee industry. The manufacture of processing machinery, shoes, fertilizers, hardware, furniture, pasta, cigars, as well as activities such as tailory, breweries, foundries, sawmills, weaving, pottery and pencil production expanded the economy of São Carlos in the 1930s. In the 1950s and 1960s, with the expansion of refrigeration, new factories of machinery and tractors arrived. Numerous small- and medium-sized companies which provided products and services were also established.\n\nIn the second half of the 20th century, the city received a boost of technological and higher educational development when in 1953 the Escola de Engenharia de São Carlos, or the Engineering School of the University of São Paulo, was created. In the 1970s, the Federal University of São Carlos was launched.\n\nSão Carlos is located on the geographic center of the São Paulo state, approximately from the city of São Paulo. The city is the center of a microregion with 308,777 inhabitants.\n\nIts altitude is over 856 m, offering a mild altitude climate. Most of the year the city is windy, sunny and with mild temperatures at night. For this reason the city is nicknamed \"\"Cidade do Clima\" (Weather City) and celebrates once a year an event called \"Festa do Clima\"\", or \"Weather Festival\".\n\nThe city has a total area of 1.141 km², which includes two districts to the north (\"Santa Eudóxia\" and \"Água Vermelha\"), one district to the west (\"Bela Vista São-carlense\"), and one district to the east (\"Vila Nery\").\n\nAccording to the Köppen Climate Classification, the city has an altitude tropical climate with dry winter, with minimum average temperatures of 15,3 °C and maximum of 27,0 °C.\n\nThe city has an active industrial profile with important national and international industries and certain agricultural importance, backed by technologies developed by Embrapa, owner of two research complexes in the city. Due to its increasing number of high technology industries, the city has been proclaimed \"The National Capital of Technology\" by Brazilian President Dilma Rousseff in 2011.\n\nThe city hosts several locally-grown technology-based companies, such as Opto Eletrônicos, and factories of multinational corporations such as Faber Castell, Electrolux, Husqvarna, Tecumseh and the Brazilian plant of Volkswagen engines, and national corporations such as TAM MRO - Technology Center, Toalhas São Carlos, Tapetes São Carlos, Papel São Carlos, Prominas Brasil and Latina.\n\nThe economic basis of São Carlos is the tertiary sector. Commerce and services corresponds to 65.9% of the city's GDP. Industry is also relevant. With 32.3% of the economy, the secondary sector has a bigger participation than the state of São Paulo's average. The primary sector corresponds to 1.7% of the GDP.\n\nSão Carlos is home to two Universidade de São Paulo campuses and the Universidade Federal de São Carlos (UFSCar), two of the most important higher learning centers in Brazil. Moreover, another minor and private university, Centro Universitário Central Paulista (UNICEP), is also based in São Carlos, and community colleges like SENAI, SESI, SESC, SENAC and the \"Escola Técnica Estadual Paulino Botelho\". This has turned São Carlos into a university-oriented town, with an abundance of student-focused commercial establishments. It is also known for its student parties.\n\nSão Carlos' cultural life is marked by a young audience that enjoys musical concerts of Brazilian contemporary alternative artists that usually include the city in their tours. Also, São Carlos has 3 theaters and 7 commercial movie-theaters rooms.\n\nThere are two important events celebrated every year in the city, the \"Climate Party\", which happens in April and has a traditional \"Orchid Exposition\" which features a craftwork fair and several food barracks. An Oktobertech fest is held yearly along with the São Carlos High Tech Fair (Fealtec).\n\nThe TAM Airlines Wings of a Dream Museum (\"Museu TAM\") was in São Carlos, from central São Carlos.\n\n\nThe city is served by Mário Pereira Lopes Airport, where one of the maintenance bases of TAM Airlines is located and well as the air and space TAM Museum, owned and maintained by the company.\n\nWere born in São Carlos:\n\n\n\n\n"}
{"id": "20959501", "url": "https://en.wikipedia.org/wiki?curid=20959501", "title": "Tanwater", "text": "Tanwater\n\nTanwater was a special water treatment project initiated by Elmo tannery in Sweden in 1992.\nThe aim was to reduce nitrogen effluent from the water treatment systems during the tanning of leathers. Previously tanneries in Europe have only been able to reduce nitrogen in the water by up to a maximum of 30%. The \"Tanwater\" project aimed at reducing nitrogen waste by up to 80% and finally were able to achieve 89% nitrogen waste reductions in the water. This was a major breakthrough for the tanning industry because nitrogen is a pollutant of ground water. \n\nElmo tannery received a grant for the project from LIFE (The Financial Instrument for the Environment). LIFE finances environmental projects in the European Union. Elmo tannery, although producing leathers predominantly for the car industry (upholstery leathers, also produces leathers for handbags and footwear. Since Elmo started this project there has been a number of tanneries that have followed in its steps of improving their water treatment systems in Sweden and Norway.\n\n"}
{"id": "21603604", "url": "https://en.wikipedia.org/wiki?curid=21603604", "title": "Technical peer review", "text": "Technical peer review\n\nIn engineering, technical peer review is a type of engineering review. Technical peer reviews are a well defined review process for finding and fixing defects, conducted by a team of peers with assigned roles. Technical peer reviews are carried out by peers representing areas of life cycle affected by material being reviewed (usually limited to 6 or fewer people). Technical peer reviews are held within development phases, between milestone reviews, on completed products or completed portions of products.\n\nA technical peer review may also be called a \"engineering peer review\", a \"product peer review\", a \"peer review/inspection\" or an \"inspection.\"\n\nThe purpose of technical peer reviews is to remove defects as early as possible in the development process. By removing defects at their origin (e.g., requirements and design documents, test plans and procedures, software code, etc.), technical peer reviews prevent defects from propagating through multiple phases and work products, and reduce the overall amount of rework necessary on projects.\n\nIn addition, improved team efficiency is a side effect of technical peer reviews (e.g., by improving team communication, integrating the viewpoints of various engineering specialty disciplines, more quickly bringing new members up to speed, and educating project members about effective development practices).\n\nIn CMMI, peer reviews are used as a principal means of verification in the Verification process area and as an objective evaluation method in the Process and Product Quality Assurance process area. The results of technical peer reviews can be reported at milestone reviews. (See Milestone (project management).)\n\nResponsible for conducting the technical peer review process and collecting inspection data. Plays key role in all stages of the technical peer review process except rework. Required to perform several duties during a technical peer review in addition to inspector’s tasks.\n\nResponsible for finding defects in work product from a general point of view, as well as defects that affect their area of expertise.\n\nProvides information about work product during all stages of process. Responsible for correcting all major defects and any minor and trivial defects that cost and schedule permit. Performs duties of an inspector.\n\nGuides team through work product during the technical peer review meeting. Reads or paraphrases work product in\ndetail. Performs duties of an inspector in addition to reader’s role.\n\nAccurately records each defect found during inspection meeting on the Inspection Defect List. Performs duties of an inspector in addition to recorder’s role.\n\nThere are two philosophies about the vested interest of the inspectors in the product under review. On one hand, project personnel who have a vested interest in the work product under review have the most knowledge of the product and are motivated to find and fix defects. On the other hand, personnel from outside the project\nwho do not have a vested interest in the work product bring objectivity and a fresh viewpoint to the technical peer review team. \n\nEach inspector is invited to disclose vested interests to the rest of the technical peer review panel so the Moderator can exercise sound judgement in evaluating the inspector's inputs.\n\nPeer reviews are distinct from management reviews, which are conducted by management representatives rather than by colleagues, and for management and control purposes rather than for technical evaluation. They are also distinct from software audit reviews, which are conducted by personnel external to the project, to evaluate compliance with specifications, standards, contractual agreements, or other criteria.\n\nA software peer review is a type of technical peer review. The IEEE defines formal structures, roles, and processes for software peer reviews.\n\nManagement representatives are typically not involved in the conduct of a peer review. This is especially true of line managers of the author or other participants in the review. A policy of encouraging management to stay out of peer reviews encourages the peer review team to concentrate on the product being reviewed and not on the people or personalities involved.\n\nFor detailed instructions on conducting a technical peer review/inspection, see NASA Systems Engineering Handbook, Appendix N.\n\n"}
{"id": "50644682", "url": "https://en.wikipedia.org/wiki?curid=50644682", "title": "Toast, Inc.", "text": "Toast, Inc.\n\nToast, Inc. is a cloud-based restaurant software company based in Boston, Massachusetts. The company provides a restaurant management and point of sale (POS) system built on the Android operating system. Toast was founded in Cambridge, Massachusetts in 2012 by Steve Fredette, Aman Narang, and Jonathan Grimm. In 2016, Toast received $30 million in a round of Series B funding from Bessemer Venture Partners and GV, formerly Google Ventures. Toast is used in a thousand restaurants, from small cafes to nationwide enterprises, across the U.S.\n\nToast founders Steve Fredette, Aman Narang, and Jonathan Grimm met at software company Endeca after graduating from MIT in Cambridge, MA. After Endeca was acquired by Oracle in 2011, they left to start Toast. Grimm, Narang, and Fredette initially created a consumer app centered for mobile payments, customer loyalty, promotions, and social aspects that integrated with restaurants’ existing POS systems.\n\nThe company started to realize that restaurants had far more needs than just being able to accept payments using a phone or tablet. The company pivoted to a full restaurant technology platform, with solutions for POS, online ordering, gift cards, analytics and other features. Two years later, the company signed over 1,000 merchants across the United States and grew to more than 120 employees, requiring the company to upgrade its space from 7,000 square feet in Cambridge to 40,000 square feet at the Hatch Fenway co-working space.\n\nIn 2013, Toast received investments from several Boston executives, including former CEO of Endeca Steve Papa, who now serves as a board member for the company.\n\nIn early 2015, Toast announced Chris Comparato as its chief executive officer. Comparato previously served as senior vice president of customer success at Acquia and senior vice president of worldwide customer solutions at Endeca. In August, Toast announced that they signed 1,000 customers in under two years, revealing 550% year-over-year growth. In November, Toast released its first restaurant report, which analyzed the market for restaurant technology as well as restaurant owners’ challenges and preferred technology features.\n\nIn January 2016, Toast received $30 million in a round of Series B funding from Bessemer Venture Partners and GV, previously known as Google Ventures and an Alphabet company. The funding was led by BVP partner Kent Bennett and general partner and Android co-founder Rich Miner. Several undisclosed investors also participated in the round.\n\nIn February 2018, Needham-based TripAdvisor partnered with Toast Inc.\n\nIn July, 2018 the company became one of the unicorn startup companies after a Series D round of financing raising $115 million, and valuing the company at $1.4 billion.\n\nToast's restaurant management system operates on the Android operating system. The backend can be managed via mobile device or via Web browser in real-time. Associated hardware includes a receipt printer, cash drawer, kitchen display screen, and magstripe card reader.\n\nIn 2015, Merchant Maverick named Toast one of the best POS systems for pizza parlors. In 2016, Toast was recognized as a \"notable player in the restaurant technology landscape\" by PYMNTS.com.\n\nIn May 2016, the New England Venture Capital Association (NEVCA) named Toast the winner of the Hottest Startup: A+ at the 2016 NEVY awards.\n\n"}
{"id": "50433452", "url": "https://en.wikipedia.org/wiki?curid=50433452", "title": "Waterless fracturing", "text": "Waterless fracturing\n\nWaterless fracturing is an alternative to hydraulic fracturing in which liquefied petroleum gas (LPG) which uses propane liquefied into gel. Propane is pumped into shale rock formation instead of water. The use of propane does not block all pathways and therefore more natural gas is released. In addition, it does not carry poisonous chemicals and underground radioactivity back to the surface, and when it does comes back to the surface it can have another usage or be used again for LPG. The only drawback is the cost as propane is more expensive than water. Another drawback is that the possible leak of propane may lead to flash fire, so fracturing with propane requires more safety instructions and monitoring equipments in order to reduce possible risks.\n\nAccording to Nathan Janiczek, the new era of waterless fracturing is growing and it is called Liquefied Petroleum Gas, or LPG fracturing. LPG is always pumped in a well and because of that pumping, rocks are destroyed and gas is released. Besides that, LPG is fully converted into gas when it is pumped up to the surface and that guarantees a one hundred percent retrieval rate. If we compare conventional fracking and fracking using propane gel, LPG fracking does not produce waste, nearly 100% of propane gas is pumped back while 50% of hydraulic frack fluid remains underground. It has lower viscosity, less surface tension and lower specific gravity, which makes the fluid more effective in transport and less dependent on pressure. LPG has many advantages; however, it is a new technique, which needs further research. Liquefied petroleum gas fracturing was developed by a GasFrac energy company, based in Calgary, Alberta. The Chief Technology Officer of the GasFrac company said that it is being used since 2008 in gas wells of Canada in Alberta, British Columbia, New Brunswick, Texas, Pennsylvania, Colorado, Oklahoma and New Mexico.\n\nThe pros of this are:\n- No use of water\n- no release of greenhouse gases"}
{"id": "30407516", "url": "https://en.wikipedia.org/wiki?curid=30407516", "title": "Woking Park", "text": "Woking Park\n\nWoking Park is a large park and leisure complex in Woking, Surrey, operated and maintained by Woking Borough Council. The park is in the Hoe Valley and will be affected by the Hoe Valley Scheme.\n\nIn 1902 the Brettell Family and associates, who were known as philanthropists, gave the land to the town on the condition \"said land shall not be used for any other purpose than a public park, public walks, gardens, recreation grounds, pleasure grounds, and baths.\"\n\nThe current Leisure Centre was opened in 1976\n\n1989: The main pool of what is now the Pool in the Park swimming complex was opened. Three years later in 1992 the leisure lagoon was opened.\n\n2003: A fuel cell based combined power and heating system was installed behind the Pool in the Park.\n\n2004: As part of a council project covering four ponds in the Hoe Valley area, a major restoration was undertaken to the duck pond area\n\n2008: It was proposed that the Woking College be relocated to Woking park in order to expand. This was opposed by local residents, who pointed out it was in breach of the original covenant gifting the land to the town.\n\n2010: Significant development work began on Woking Park as part of the Hoe Valley scheme. This included the felling of a large number of trees, clearance of waste land, derelict greenhouses and the construction of new facilities.\n\n2011: As part of a ten-year deal with Woking Borough Council, Freedom Leisure took over the running of all council run facilities at Woking Park.\n\nWoking Park has a number of facilities and sport pitches. There is also a large car park near Pool in the Park.\n\nPool in the Park is a purpose-built swimming complex in the middle of the park. It has three pools, the competition pool that is one to three metres deep, 25m long and 13m wide, with up to 6 swim lanes, which opened in 1989; a teaching pool 16 metres long x 8 metres and 0.8m - 1.0m depth and the leisure lagoon which includes three Water Slides which vary in speed (Fast, Medium and Slow). Other lagoon features include a 'river rapids' ride, a wave machine, water cannons and a \"mushroom\" water fountain. The outside design of Pool in the Park is based on an ancient Roman Coliseum. Pool in the Park offers a range of activities including a comprehensive swim school programme, toddler splash sessions, aqua fitness classes, adults and ladies only sessions, children's activities and parties and is home to local clubs including Woking Swimming Club, Woking Snorkelling, Surrey Aquanauts, Woking Snorkel and Scuba and Woking Lifesaving club\n\nThe Leisure Centre opened in 1976 and is accessed via a pedestrian bridge over a small river. It has a number of sports facilities, including 6 squash courts, a new state-of the art gym overlooking the park gym, three fitness studios, a dedicated Spinning (indoor cycling)studio and two halls. The main sports hall is used for badminton, football, basketball, trampolining, sporting events and also a number of non-sports related activities, including antiques fairs, flea markets, and the annual Woking Beer Festival. The second, smaller, hall is called the Wurlitzer hall and houses an American Theatre organ which offers regular concerts through The London and South of England American Theatre Society. There is also a kids' indoor softplay area, called the Pick'n'mix Playstore, creche, cafe, Heatwaves suite featuring sauna, Jacuzzi and steam room. Sensations Multi-Sensory Suite. Many clubs and groups use the centre including weightlifting, gymnastics, martial arts, and dance and drama and the faciliities are available for club/group/business hire.\n\nOutdoor sport pitches include a football/hockey pitch, cricket square, bowls lawn, and a number of tennis courts. The tennis courts are open to the public (book at Pool in the Park) although they're not floodlit so operating hours reduce according to the time of the year, whereas the bowls lawn is restricted to members of Woking Park Bowls Club. The cricket pitch is only used for cricket games, but is open for people to use at other times. There is clubhouse for the cricket players. There are four new 3g 7-a-side football pitches (opened June 2014) behind the leisure centre with additional parking underneath which are available for booking and leagues.\n\nNear the middle of the park there are two climbing boulders with a spider's web between them. The boulders contain several holds, on which hands or feet can be placed to move the body up the boulder. These are intended for 13- to 19-year-olds, though a lot of other age groups play on them. Use of this feature has declined as the erosion caused by footwear has made the walls difficult to climb. The spider was designed with several features in mind; to represent social mobility within Woking, promoting business and entrepreneurship within the town. Additionally, the eight legs of the spider celebrate Woking's multicultural heritage. There is also a playground for smaller children (Which had some improvement work), a crazy golf course and a skate park which is very popular with locals aged around 11-19.\n\n14 July The play area is currently being completely redeveloped and enlarged, due to open in the Autumn.\n\nIn the centre of the park is a set of three wildlife ponds with a timber decking viewing area. This was extensively renovated in 2004, as the two existing ponds were badly overgrown and in decay. This involved the removal of 300 tonnes of sediment, and architects Upton McGougan were awarded runner up in the Sustainable Designer of the Year competition in 2005 for the project.\n\nThroughout the park are a number of gardens with statues and similar decoration.\n\nWildlife\n\nIn the ponds and gardens there are many different types of wildlife-Some rare and some common. In the ponds the wildlife includes a family of swans, about 20 ducks, and many other different species in the pond. There are many other types of wildlife in the ponds. In the gardens there's not a much wildlife. There are many small species that live in the gardens, such as ants, wasps, spiders and flies. On occasion men can be seen urinating in these gardens, allowing their waste to fuel the rise of new life.\n\nAs part of the Hoe Valley scheme a new community centre is being built on land adjacent to the leisure centre. This will including facilities for the Scouts, Army and Air Cadets, Sea Rangers, Girl Guides, Westfield Football Club and Woking Boxing Club, who are currently located in Westfield Avenue. A number of derelict greenhouses are also to be demolished to provide space for new training pitches. Some of the other improvements consist of adding extra pathways, improving facilities there and also adding new ways of access to the park.\n\nWoking Borough Council started the annual Fireworks Display that was held in Woking Park. After a few years the organisation was passed to Woking Round Table who ran it for many years until 2014. From 2015 the Firework Display is being organised by Woking District Rotary Club.\n\nWoking District Rotary Club will be working with Fantastic Fireworks again for the 2015 display. This has been described as one of the best displays in Surrey.\n\nAs well as the Fireworks there is also a funfair and food-stalls available on the night.\n\nOn Saturday 3rd November a giant inflatable slide collapsed at the fairground. Eight children were treated in hospital with seven discharged overnight and the eighth under observation for injuries \"not believed to be significant\".\n\nThe Hoe Valley Scheme altered parking and provided opened up, accessible walks alongside and across the ravine of the Hoe Stream.\n\nA Sports Centre, Army Cadets, Sea Cadets and Boxing Club Headquarters moved to Woking Park in the first decade of the 21st century.\n\nBehind Pool in the Park is installed a fuel cell based combined power and heating system which was implemented in 2003 in a joint venture between Woking Borough Council and Thamesway Energy Ltd which is a company owned by Woking Borough Council.\n\nThe system chemically reforms natural gas into hydrogen using oxygen from the atmosphere. When converted to electricity in the fuel cell this produces 50% more energy than conventional means and produces pure water as a byproduct, which is reclaimed for other use. Heat is also produced, which is used to power the pool in the park air conditioning system. This provides for all of Woking Park's energy requirements, is self-sufficient in electricity and is a net exporter of power to other council sites.\n\nThe main component is a 200 kWe fuel cell along with four smaller 60 kW units and one 836 kW unit. Total combined heating and power capacity is 1.2 MWe and 1.6 MWth. The system is on display to the public with information and educational resources provided.\n\nWork began in 2001, and was the first system of its kind in the UK. It was part funded as part of a larger scheme to showcase how such technology could be used in the UK to meet environmental targets.\n\n"}
{"id": "57138652", "url": "https://en.wikipedia.org/wiki?curid=57138652", "title": "ZPEC", "text": "ZPEC\n\nThe Zhongman Petroleum and Natural Gas Group (or ZPEC) is a Chinese oilfield services company.\n\nThe company was founded in 2003. The company received backing from Sequoia Capital.\n\nReuters in December 2017 reported the company was in talks with Gazprom Neft to take a stake in the Chonsk oil fields development project in Siberia.\n\n"}
