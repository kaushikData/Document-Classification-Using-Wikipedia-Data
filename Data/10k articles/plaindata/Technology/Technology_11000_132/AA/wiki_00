{"id": "55192130", "url": "https://en.wikipedia.org/wiki?curid=55192130", "title": "40/4 Chair", "text": "40/4 Chair\n\nThe 40/4 chair, designed by David Rowland in 1964, is the first compactly stackable chair invented. Forty chairs can be stacked within a height of 4 feet (120 cm), hence its name \"40 in 4\". It is an all-purpose chair providing large-capacity movable seating, compact economical storage and comfort in sitting for long periods. It is considered a masterpiece of industrial design, and is in the permanent collection of the Museum of Modern Art in New York, as well as other museums internationally.\n\nThe frame of the chair is made of 7/16” solid steel rod. The seat and back are formed sheet metal with 3/16” rolled edges and coated in vinyl. Some models substitute wood veneers, plastic resin and upholstery over wood as components.\n\nChairs can be stacked on specially designed dollies for easy moving and storage. Forty chairs on a single dolly take up 5.1 ft / 0.47 m of floor space. The chairs can also be linked together horizontally to form movable and stackable rows. Linked chairs in rows of two, three or four can be stacked up to 40 chairs high on special double, triple, or quadruple dollies. One hundred sixty chairs on a quadruple dolly take up less than 21.5 ft / 2 m of floor space.\nIn 2004 Rowland worked with Howe a/s to introduce an expanded family of the 40/4 chair.\n\nRowland developed the 40/4 chair over a period of 8 years. In 1963 he was awarded a patent for the chair's design.\n\nInitially, Rowland showed the chair to many companies in an effort to license the design. In 1961, Florence Knoll licensed the chair for her company, Knoll Associates, however canceled a license after six months. Rowland later showed the chair to Davis Allen, head of interior design at the architectural firm of Skidmore, Owings & Merrill (SOM). Allen requested 17,000 chairs for the a campus SOM was designing for the University of Illinois at Chicago (UIC). To fulfill the request, Rowland licensed the design to General Fireproofing Co. (GF) in Youngstown, Ohio. In May 1965, While the first order for was still being produced, 250 chairs were hand assembled and installed in the Museum of Modern Art in New York City for the opening of its new wing.\n\nThe 40/4 was an immediate success. It won the grand prize at the prestigious 13th Milan Triennale, and has been included in museum collections and exhibitions internationally.\n\nIn the book \"the Modern Chair,\" Clement Meadmore described the chair as having “beautiful simplicity and total appropriateness.” Twenty five hundred 40/4s were installed in St. Paul’s Cathedral in London in 1973, site of Prince Charles and Princess Diana’s wedding, and remain in use. In 2001 it was named #1 of The Top 10 Commercial Interiors products of the Past 50 Years by Contract Design Magazine.\n\nThe chair has been in continuous production since its introduction and has sold over 8 million units.\n\nGeneral Fireproofing held the license for the chair from 1963 until 2002 when the company was taken over by OSI Furniture LLC. In 2013, Howe Europe, (now Howe a/s), of Denmark, which had had a sublicense to the chair in Europe, Africa, Australia, New Zealand and Asia (except for Indonesia) acquired the license for the 40/4 in the United States and Canada.\n\n\n\n\n"}
{"id": "9205207", "url": "https://en.wikipedia.org/wiki?curid=9205207", "title": "AENOR", "text": "AENOR\n\nThe Spanish Association for Standardization and Certification (AENOR) is an entity dedicated to the development of standardization and certification in all Spanish industrial and service sectors.\n\nAenor is a private, independent, non-profit-making (although they charge to access their standards) Spanish institution which contributes through standardization and certification to improve technology produced by companies.\nIt was created by order of the Ministry of Industry and Energy on 26 February 1986, in accordance with the Royal Decree 1614/1985 and was recognized as a standardization organization and as an entity of certification by Royal decree 2200/1995, following the law 21/1992 of industry.\n\nThe functions of AENOR are:\n\n\n\nCoinciding with the incorporation of Spain to the European Economic Community, in 1986 AENOR was constituted. Until that date, standardization work was the responsibility of the Institute for Rationalization and Standardization (IRANOR).\n\nIn the first year 24 technical standards committees were created. A year later, AENOR assumed the representation of Spain before the European organizations (CENELEC, ETSI) and international (ISO, IEC).\n\nNowadays, AENOR has more than 200 technical standards committees involving nearly 6,000 experts in the field.\n\nAenor contributes to improving the quality of companies, their products and services while protecting the environment and the welfare of society. Their commitments are five:\n\n\nCertification is an action carried out by an independent entity, which declares that an organization, product, process or service, meets the requirements that are defined in the standards or technical specifications. The brands of AENOR ensure that this certification is true and constitute a differentiating element in the market, improving the image of products and services offered and generating trust between customers and consumers. Through this certification, trust is created towards the organization, customers, shareholders, employees, public administrations and the social environment of the company. Also creating confidence regarding the quality and safety of the products or services, in the commitment with the environment, the safety of workers, as well as the bet on innovation. Given the current excess of information, organizations feel the need to simplify certain decisions, which is why they are looking for suppliers whose management and products already have this type of certification that provides confidence. AENOR offers its brands with the aim of granting this competitive advantage to organizations seeking excellence.\n\nAny entity that has interest in the develop of the standardization or certification can be member of AENOR, because of its associative character. Today, It has more than 800 members, among them are the main business associations, some of the first Spanish companies and a good representation of Public Administrations.\n\nTaking part in this entity allows:\n\n\nAENOR is a Spanish member of the following international standardization organizations:\n\n\nLikewise, at European level, AENOR is a Spanish member of the following recognized standardization organizations:\n\n\nAENOR is the official Spanish national standardization organisation according to (ETSI).\n\n\n"}
{"id": "55756692", "url": "https://en.wikipedia.org/wiki?curid=55756692", "title": "Adidas Telstar 18", "text": "Adidas Telstar 18\n\nThe Adidas Telstar 18 was the official match ball of the 2018 FIFA World Cup, which was held in the Russian Federation. It is designed by the company Adidas in Sialkot, Pakistan. A FIFA Partner and FIFA World Cup official match ball supplier since 1970, and based on the concept of the first Adidas's World Cup match ball.\n\nThe Telstar 18 was presented in Moscow on November 9, 2017 by Lionel Messi.\n\nRetired Brazilian footballer Ronaldo opened the 2018 FIFA World Cup by introducing a Telstar 18 that was sent into space to the International Space Station crew in March 2018, and returned to Earth in June.\n\nThe name of the ball was revealed on November 9, 2017 at the official presentation in Moscow by Lionel Messi, winner of the Golden Ball at the 2014 FIFA World Cup, and attended by winners of the World Cup in different years: Zinedine Zidane, Kaká, Alessandro Del Piero, Xabi Alonso and Lukas Podolski. The Telstar 18 pays homage to Adidas's first World Cup match ball, named the Telstar, which was itself named for its resemblance to the original Telstar communications satellite. The word \"Telstar\" is a combination of the words \"television\" and \"star\".\n\nThe original Telstar used in the 1970 FIFA World Cup was the first football to show a black and white pattern. This was done to ensure that television audiences would know where the ball was while games were in operation, due to many televisions at the time sporting a black and white screen (colour television was still rare in many parts of the world in this era). Although the Telstar had 32 panels, the Telstar 18 has six textured panels. They are not stitched, but seamlessly glued together.\n\nThe ball has an embedded near-field communication (NFC) chip. However, it is of no value to players, providing no information about their kicks or headers of the ball, although Adidas has provided this in a previous football. Consumers who purchase a Telstar 18 are able to connect to the chip using a smart phone to access content and information that is unique to that ball, personalized and localized, providing the consumer with interactivity themed on the upcoming World Cup competition. Speed Sports manufactured Adidas Telstar 18\n\nThe Telstar 18 balls are manufactured in Pakistan and China.\n\nAlthough Adidas stated that the Telstar 18 was scientifically designed to be predictable in flight and was \"the most perfect piece of equipment,\" international goalkeepers including Marc-André ter Stegen, Pepe Reina and David de Gea assessed prior to the tournament that the ball changed direction unpredictably and could be slippery due to the smooth coating and lack of seams. Dani Alves, full-back for Brazil, was quoted as believing that \"Telstar 18 is an absolute joy for those shooting with it, but a nightmare for those who have to second guess its trajectory and try and stop it\". According to Joaquín Maroto of \"Diario AS\", the ball \"encourages players to shoot from distance because if the ball is struck well, it fizzes through the air but loses none of its intensity on impact\", citing Thomas Müller's goal for Germany from range in a March 2018 friendly against Spain. Criticism of the Telstar 18's instability continued after several long-distance goals in early rounds of the World Cup. According to news channel Russia 24, this was part of an intentional shift in the balance of the game. \n\nFurther commentary on the ball's performance arose after two balls burst in a first-round game between France and Australia, and another ball failed in the match between Argentina and Iceland. A fourth Telstar 18 was found to have lost pressure in the match between Uruguay and Saudi Arabia on June 20.\n\nAt the end of the 2018 World Cup group stage, FIFA revealed a new design to be used in the knockout stage: the Telstar Mechta (Мечта). \"Mechta\" means \"dream\" or \"ambition\" in Russian.\n\nAt the 2018 Russia–United States summit, Russian President Vladimir Putin gifted a Telstar Мечта to U.S. President Donald Trump. The ball, which included the standard chip and transmission devices, incited a political controversy within the U.S. over fears of spying.\n\n\n"}
{"id": "35932439", "url": "https://en.wikipedia.org/wiki?curid=35932439", "title": "Advanced Technician in Aviation non civil servant", "text": "Advanced Technician in Aviation non civil servant\n\nIn France, the training of the Technicien supérieur de l'aviation (civilian) (TSA civilian, in English Advanced Technician in Aviation non civil servant) is performed by the \"École nationale de l'aviation civile\" (French civil aviation university).\n\nThe TSA civilian training is created in addition to the one of \"Technicien supérieur des études et de l'exploitation de l'aviation civile\" available since 1962.\n\nThe competitive examination is organized each year for students holder of a \"Baccalauréat\". 5 seats are available. After the application process, students are trained during two years at the \"École nationale de l'aviation civile\" (French civil aviation university) of Toulouse.\n\nThe TSA civilians can have different jobs in airports, airlines or manufacturers including:\n\nIn 2011 is done an amendment of the initial training of the \"Technicien supérieur des études et de l'exploitation de l'aviation civile\". This one will now be called TSA for \"Technicien supérieur de l'aviation\" and include, since 2011, two curriculum :\n\n\n\n"}
{"id": "3442359", "url": "https://en.wikipedia.org/wiki?curid=3442359", "title": "Australasian Journal of Educational Technology", "text": "Australasian Journal of Educational Technology\n\nThe Australasian Journal of Educational Technology is a peer-reviewed academic journal covering research in educational technology, instructional design, online and e-learning, educational design, multimedia, computer assisted learning, and related areas. It is published in 8 issues per year by the Australasian Society for Computers in Learning in Tertiary Education (ASCILITE) as an open access online-only journal. All previous issues, dating from 1985, are accessible online without charges.\n\nThe \"Australasian Journal of Educational Technology\" was established as the \"Australian Journal of Educational Technology\" by the Australian Society for Educational Technology (ASET) in 1985, with two issues per year. From 1997-2005, the journal was published jointly by ASCILITE and ASET, and from 2006 by ASCILITE. Publication frequency increased to three issues in 1999, to four issues in 2005, and to six issues in 2010. From 2004, the journal carried a new title containing \"Australasian\" instead of \"Australian\", in order to align it with its main sponsor, ASCILITE, and to make it more inclusive to authors from nearby countries.\n\nIn 2007, the journal merged with the \"International Journal of Educational Technology\" (), an online-only open access peer-reviewed journal that had been sponsored jointly by the University of Western Australia and the University of Illinois at Urbana–Champaign and that published five issues from 1999 to 2002. Its back issues are available on the website of the merged journal and copyright in all papers was restored to their original authors as part of the merger.\n\nIn 2008, the journal merged with the \"Journal of Instructional Science and Technology\", whose archives are also available on the merged journal's website.\n"}
{"id": "24744037", "url": "https://en.wikipedia.org/wiki?curid=24744037", "title": "Bamboo bicycle", "text": "Bamboo bicycle\n\nBamboo bicycles are pedal-and-chain-driven, human-powered, single-track vehicles that have two wheels attached to a bamboo frame. Because of its light weight, vibration damping, and sustainability, bamboo is slowly starting to be used in bicycle frame production, though the industry is still dominated by aluminium frames.\n\nBamboo bikes were first patented in England by the Bamboo Cycle Company and introduced to the general public on 26 April 1894. A US patent was applied for in 1895, by August Oberg and Andrew Gustafson, and granted in 1896. However, with the development of tougher industrial metals, such as steel and aluminium, large-scale usage of bamboo to build bicycles never happened.\n\nThough bicycles are a staple of human transportation, in both rural and urbanised areas, bamboo bicycles are not widely used. However, with the advent of the Green movement, bamboo is being used again, primarily for high-end racing and touring bicycles. Bamboo bikes are entering the market as low cost alternatives to relatively expensive and unsustainable aluminium and metal bikes.\n\nSeveral aspects of bamboo are extremely valuable to both cyclists and bicycle manufacturers: high strength-to-weight ratio, vibration control, and sustainable growth. Because of bamboo's tendency to grow straight, it does not exhibit \"knots\" and \"turns\" in its wood, unlike other types of wood. As a result, bamboo has a higher specific tensile strength than steel, as well as a higher specific compressive strength than concrete. This tendency also allows for excellent vibration control, which, in turn, provides for a smoother ride and increased stability on rough terrain.\n\nThe bamboo poles can be joined in a number of different ways. The earliest models used metal joints which were then tightened around the bamboo. Another approach is to wrap the joints with resin saturated fibers to make composite lugs around the bamboo frame members. For modernised track bicycles, carbon fibre is used for the remainder of the parts that are not made of bamboo due to its light weight - for example, the fork, because it is difficult to find a perfect piece of bamboo that fits into the fork socket of the frame.\n\nBamboo could be used as an alternative to traditional steel and aluminium bikes in many rural areas because of its potential sustainability. \n\nA \"Bamboo Bike Project\", started by engineers at Columbia University, created a small number of bamboo bikes from 2007 to 2011. This was done with the intention of providing low cost bikes for Africans in rural areas, and stimulating local bike building industries, without major assistance from outside sources.\n\nThe United Nations and the United States have invested in the Ghana Bamboo Bike Initiative, which was created by Bernice Dapaah. This business markets itself as addressing climate change, poverty, youth unemployment, rural-urban migration and by creating jobs for women. As of 2015 over 1000 of these bikes had been sold in Ghana, Europe and the United States.\n\nAs of 2016 few bicycles have also been made in Bangladesh.\n\nThe most expensive bamboo bikes cost thousands of dollars. Conversely, the bikes sold in Ghana for the Ghana Bamboo Bike Initiative have been said to cost about $120, which is significantly more expensive than conventional bicycles. The cheapest for adults retail at $350 as of 2018, thus the bikes are retailed specifically for the export market.<ref>\n"}
{"id": "42767013", "url": "https://en.wikipedia.org/wiki?curid=42767013", "title": "Bicycling and feminism", "text": "Bicycling and feminism\n\nWomen gained a significant amount of independence with the invention of the bicycle. This device gave them the freedom to travel outside the home of their own power. Some opponents felt threatened by this newfound freedom, arguing that cycling would encourage women into prostitution, promiscuity, and lesbianism.\n\nBicycle riding also necessitated more practical clothing for women and led to significant changes to female attire in society. This inspired innovations among Victorian female inventors, who were inspired to create cycling-friendly designs like convertible cycling garments. One individual from the time period watching female cyclists remarked, \"It is hard to believe, that they were the same women who went out in the afternoon for the formal carriage parade.\"\n\nBikes in Space is a series of sci-fi books themed around bicycling and feminism.\n\nElizabeth Cady Stanton wrote that the bicycle was a tool which motivated women to gain strength and take on increased roles in society. Susan B. Anthony stated in 1896: \"Let me tell you what I think of bicycling. I think it has done more to emancipate women than anything else in the world. I stand and rejoice every time I see a woman ride by on a wheel.\"\n\nBeatrice Grimshaw, who went on to a life of travel and adventure, describes a girlhood of Victorian propriety, in which she was: \"the Revolting Daughter–as they called them then. I bought a bicycle, with difficulty. I rode it unchaperoned, mile and miles beyond the limits possible to the soberly trotting horses. The world opened before me. And as soon as my twenty-first birthday dawned, I went away from home, to see what the world might to give to daughters who revolted.\"\n\nAn 1895 article in \"The Literary Digest\" reviewed literature from the time period which discussed the bicycle face, and noted that \"The Springfield Republican\" warned against excessive cycling by \"women, girls, and middle-aged men\". Concerns about bicycle face with regard to female cyclists were detailed by medical doctor A. Shadwell in an 1897 article for the \"National Review\" in London titled \"The hidden dangers of cycling\". His article was subsequently discussed and analyzed in \"The Advertiser\". \n\nBicycle enthusiasts disagreed with this medical assessment, and asserted that the physical activity was good to improve one's health and vitality.\n\n\n"}
{"id": "15718450", "url": "https://en.wikipedia.org/wiki?curid=15718450", "title": "Clostridium beijerinckii", "text": "Clostridium beijerinckii\n\nClostridium beijerinckii is a gram positive, rod shaped, motile bacterium of the genus \"Clostridium\". It has been isolated from feces and soil. Produces oval to subterminal spores. it is named after Martinus Beijerinck who is a Dutch bacteriologist.\n\nFormerly Clostridium acetobutylicum.\n\nIndustrially interesting for its ability to produce butanol, acetone and/or isopropanol at strictly anaerobic conditions at 37 °C using a wide range of substrates including (but not limited to) pentoses, hexoses and starch. Its ability to grow in simple, inexpensive media, stability in regard to strain degeneration, good adaptability to continuous processes and sustained production of solvents well into the log phase are other advantages of this bacterium.\n\nRecent developments have shown it is a possible candidate for efficient hydrogen production.\n\n\n"}
{"id": "54305815", "url": "https://en.wikipedia.org/wiki?curid=54305815", "title": "Communication in Distributed Software Development", "text": "Communication in Distributed Software Development\n\nCommunication in Distributed Software Development is an area of study that considers communication processes and their effects when applied to software development in a globally distributed development process. The importance of communication and coordination in software development is widely studied and organizational communication studies these implications at an organizational level. This also applies to a setting where teams and team members work in separate physical locations. The imposed distance introduces new challenges in communication, which is no longer a face to face process, and may also be subjected to other constraints such as teams in opposing time zones with a small overlap in working hours.\n\nThere are several reasons that force elements from the same project to work in geographically separated areas, ranging from different teams in the same company to outsourcing and offshoring, to which different constraints and necessities in communication apply. The added communication challenges result in the adoption of a wide range of different communication methods usually used in combination. They can either be in real time as in the case of a video conference, or in an asynchronous way such as email. While a video conference might allow the developers to be more efficient with regards to their time spent communicating, it is more difficult to accomplish when teams work in different time zones, in which case using an email or a messaging service might be more useful.\n\nThe history of communication in distributed software development is tied to the historical setting of distributed development itself. Communication tools helped in advancing the distributed development process, since communication was the principal missing component in early attempts for distributed software development . One of the main factors in the creation of new tools and making distributed development a viable methodology is the introduction of the Internet as an accessible platform for developers and researchers, facilitating the exchange of both code and information in a team.\n\nOne of the first manifestations of distributed development is the open-source community, where developers are joined together not by an enterprise and its resources but by voluntarily participating in the same project, resulting in diverse teams from different geographical locations. In these projects there is a surging need for communication and collaboration tools. The history of free and open-source software shows that as time progressed, the complexity of the projects and the number of involved people increased. Better communication and collaboration tools had an important role on this increase. Initially the available methods were mostly asynchronous forms of communication such as the email and mailing lists or even relying on periodical written publications to spread information. Synchronous and efficient communication would be mostly limited to telephone calls .\n\nIn this early stage there aren't many accounts of this kind of distributed development on an enterprise setting . However, the developments and tools of previous years pioneered the necessary means for companies to start investigating and adopting these practices when advantages could be obtained. More tools such as Audio conferencing and Instant messaging appeared mostly for other purposes but were quickly adopted, and continued to push forward the idea of distributed development. This new movement created an interest in the area of study that is Communication in Distributed Software Development to further improve the effectiveness and quality of the development process.\n\nSoftware development, in general, requires a great deal of information exchange and studies show that a great percentage of a developer's time is spent on collaborative/communication activities. While formal communication is used for essential tasks such as updating a project status or determining who has responsibility for any particular work, informal communication is also crucial for the development process. Informal communication, or \"corridor talk”, helps developers stay aware of what is going on around them, what other employees are working on, who has expertise in what area, and many other essential pieces of background information that enables them to work together efficiently and create the \"spirit of a team\". Studies also show that the more uncertain a project is, the more important is this kind of communication.\n\nIn a Global Software engineering (GSE) environment, informal communication is hard to recreate. The lack of this type of communication can lead to surprises, resulting in misalignment and rework. For this reason, Communication in Distributed Software Development is important for any company that is applying GSE. This area of study, among other things, tries to recreate informal communication in a GSE environment, in order to develop software without the loss of development speed that is characteristic to this environment.\n\nCommunication can be hindered by several barriers, such as socio-cultural, linguistic, knowledge, geographical and temporal barriers.\n\nSocio-cultural barriers can manifest themselves as the means of communication. In fact, a study shows that U.S. and Japanese clients have distinct preferences with regards to them. U.S. clients prefer to communicate frequently via informal telephone and email contacts, while Japanese clients prefer verbal communication and less frequent but formal use of electronic media.\n\nLinguistic barriers typically manifest themselves when at least one of the actors in a conversation is not speaking its native language. Aside from the fact that one should be able to express himself better in his native language, there are other obstacles. Idiomatic expressions and slang are an examples of such obstacles that difficult informal communication.\n\nAccording to Allen's Curve, the frequency of communication between engineers drops at an exponential rate as the distance between them increases. In case of coworkers in a company, communication is often triggered by random encounters between coworkers. When there is a significant distance between the latter, their communication decreases. In fact, an empirical study was conducted that compared the frequency of communication between coworkers from local and remote sites. Most of the inquired answered that they speak to the majority of their local colleagues at least once a day, while speaking less than once a week with their remote ones.\n\nTemporal barriers are closely related to geographical barriers. Temporal barriers are typically present on a scenario where two or more coworkers are in different time zones and often times in different geographic locations. Developers mostly communicate during work hours, and while they can use asynchronous communication which doesn't require overlapping work hours, it inherently delays the communication process. As an alternative they can use synchronous communication if they need to communicate in real time, however it introduces the complication of finding overlapping work hours. Follow-the-sun is a common approach taken by software companies to mitigate the latter issue.\n\nResearch on Communication in Distributed Software Development is conducted in order to improve the understanding of the implications of different communication methods on the success of the development process and the final product.\n\nCommunication is an essential process in coordinating a software development project and sharing knowledge between the team members. Previous studies claim that sharing knowledge is important to building trust and even improving the performance of the whole team, which also applies in a distributed software development process.\n\nIt can also bring challenges, as referred in the section above, that when improperly dealt with can delay a team project or even cost money to the company. A great deal of studies tries to find ways to mitigate these problems and avoid miscommunication.\n\nThe tools used for communication are within the scope of some studies. They show the advantages and disadvantages of some different types of tools, and also which kind of tools the developers like to use for certain situations.\n\nThe interest of researchers in how a globally distributed development influences the success of the project is noted in publications such as where the author mentions the need for more empirical studies on the subject. Another study tried to find more direct relations between time zones and language barriers without significant results, which as suggested by the author, might be due to low sample size. However it was shown that there is indeed a relationship between distributed development and longer response times between collaborators. There are also studies that correlate the frequency of communication and the geographical distance, such as Allen curve.\n\nThe research done so far points to the need of improving the methodologies and tools used by companies and that communication is a big factor in the success of a company. \n\nCommunication in a collaboration setting can be achieved either synchronously or asynchronously, differing in how agents interact with each other. The different communication forms create analogous communication systems and tools depending on the type of communication supported, which serve different purposes in a distributed development setting. Even inside a company, the tasks and responsibilities of different members reflect in their usage in the tools used in the work environment.\n\nIn synchronous systems, the participants simultaneously receive and send information in \"real time\", and a message is usually followed by a response in a short time span. This type of communication is used for communication that requires an immediate response when the other participant is promptly available or for more informal communication in a direct setting. It can be used in an enterprise to answer questions quickly, discuss ideas, convey important developments that need attention or any other important message.\n\nAsynchronous systems provide a mechanism for submission and retrieval of messages, where the sender can send information whenever he likes and the recipient will only retrieve it and reply when he is available. This form of communication can be used to have a discussion or convey information about less urgent matters, since no answer is guaranteed promptly. It is useful in a distributed development process specially because most of the times the different teams working on a project don't do so simultaneously, and matters that are not urgent can be discussed asynchronously.\n\nThere is also another possible approach in which a system provides both forms of communication in the same environment to allow more flexibility in communication. These systems can be referred to as Hybrid systems where messages exchanged usually have the characteristics of asynchronous messages, but the systems are also conceived in order to use these messages as a form of synchronous communication. They present a middle ground between asynchronous and synchronous communication.\n\nCommunication tools for Globally Distributed Software Engineering can be of various types that vary with the communication form used, the interface provided to the user, among others. Also, different categories can use different sensory information to improve the communication. The tools available include instant messaging, email, audio and video conference, virtual office and virtual reality. This section provides an overview of different types of tools and some popular examples that are in use currently, however it is not a thorough collection and listing of available tools. More complete listings can be found in other resources.\n\nEmail is a method of exchanging digital messages between people using digital devices such as computers, mobile phones and other electronics. Unlike the most instant messaging tools, on email neither the users nor their computers are required to be online simultaneously. The cost of using email in company varies, since, for example, the company might have its own email server.\n\nEmpirical studies demonstrated that all team members on a software development team used this tool effectively. Unlike instant messaging, email messages are intended to be more stand-alone and less sensitive to the context of communication, and thus producing email messages requires more time than traditional IM messages.\n\nSome email providers are Gmail, Outlook.com and ProtonMail.\n\nAudio and video conference are the technologies for the reception and transmission of audio-video signals by users at different locations, for communication between people in real-time. These type of tools attempts to replicate the rich interaction present in face-to-face meetings. Rich synchronous communication technology such as video-conferencing is appropriate for highly interactive discussions where body language and intonation can convey the degree of understanding or agreement among participants.\n\nVideo conference is also a good way to develop trust among global software developers, since it allows team members to form personal relationships.\n\nInvestigators found out that team members who are not confident with their English language skills prefer to use email or instant messaging over audio and video conferencing, as text-based media provide more time to comprehend and compose a response. This becomes a problem, since text-based media doesn't use neither auditory nor visual features, which can hinder the process of understanding important information and lead to misunderstandings.\n\nZoom, GoToMeeting and Highfive are examples of these type of tools.\n\nVirtual Offices recreate the personal proximity and functionality of a physical office needed by teams in a global distributed software engineering environment. Instead of having \"channels\" or \"messages threads\", virtual offices have rooms on a virtual office space.\n\nProfessor Thomas J. Allen in the late 1970's discovered that the increase of distance between engineers reduces exponentially the frequency of communication between them. Virtual offices are a way to virtually reduce that distance, in order to increase the communication among them.\n\nFurthermore, other studies show that virtual offices make work coordination easier and improve the performance in a team.\n\nSome tools that belong to this subset are Sococo, 8x8 and Skype for Business.\n\nVirtual Reality has gained increased interest over the years. It has grew from an industry of 129 million USD in 2015 to over 1 billion USD by the end of 2016. It is estimated that the industry will reach 4.6 billion USD by the end of 2018.\n\nThe content exchanged during the act of communication is merely the interpretations of the situations in which the actors are involved. The latter, in turn, depend on the context. The motivation for using virtual reality as a communication tool is based on the premise that one's perception of context is proportional to the sensorial information available.\n\nIn a virtual reality communication setup, each of its participants is under sensorial immersion. This improves the perception of the context in which the actor is in, which in turn improves the communication experience itself.\n\nEven though the concept is not recent, the technology only started to be significantly developed as of 2010.\n\nAltspaceVR is an example of a virtual reality platform which was recently used as a communication tool. \n\nInstant messaging (IM) allows the transmission of messages between two parties or more in case of a \"chat room\". It can be synchronous or asynchronous and it's considered to be the less intrusive communication type. Researches show that developers like to use this type of tools to ask quick questions to their peers or superiors.\n\nWhatsApp, Facebook Messenger and HipChat are examples for this type of tool.\n\nMixing Agile software development and Distributed Software Development brings a lot of challenges to the team communication. On one hand, Agile software development demands an increase for informal communication and lacks formal communication, like documentation. On the other hand, Distributed Software Development makes it difficult to initiate communication, can lead to misunderstandings and increases the communication cost (time, money, etc) as explained previously #Challenges, which can lead to a decrease on the frequency of communication. This makes the area of study presented of utter importance in Agile Distributed Software Development. One of its core principles emphasizes the relationships between individuals and their interactions, entailing constant communication.\n\nExtreme programming (XP) was designed for a environment where all developers were co-located, which is not the case for Distributed Software Development. Furthermore, XP is heavily reliant on continuous communication between stakeholders and developers, which makes communication one of the five core values of XP. Consequently, communication on distributed environment is of utter importance for a XP development environment and should be taken into account when applying this methodology on a distributed environment.\n\n"}
{"id": "30476777", "url": "https://en.wikipedia.org/wiki?curid=30476777", "title": "Console television", "text": "Console television\n\nA console television is a type of CRT television most popular in, but not exclusive to, the United States and Canada. Console CRT televisions are distinguished from standard CRT televisions by their factory-built, non-removable, wooden cabinets and speakers, which form an integral part of the television's design.\n\nBest suited to television sizes of under 30 inches, they eventually became obsolete due to the increasing popularity of ever larger televisions in the late 1980s onward. However, they were manufactured and used well into the early 2000s.\n\nConsole televisions were originally accommodated in approximately rectangular radiogram style cabinets and included radio and record player facilities. However, from approximately the mid-1970s onwards, as radiograms decreased and Hi-fi equipment increased in popularity, console televisions became more cuboid in shape and contained most commonly television, and radio receiving features, and less commonly the addition of an eight track player.\n\nSome models included a feature whereby the viewer/operator could answer the telephone, by pressing a specific button on the remote control, and could then proceed to engage in a telephone conversation by means of a speakerphone built into the cabinet of the television, thus eliminating the need to use a traditional telephone receiver.\n\nCompanies that made these types of television included Zenith, RCA, Panasonic, Sony, Magnavox, Mitsubishi, Sylvania, and Quasar.\n"}
{"id": "47889052", "url": "https://en.wikipedia.org/wiki?curid=47889052", "title": "Crown Maple Syrup", "text": "Crown Maple Syrup\n\nCrown Maple Syrup is a certified organic maple syrup company based in Dover Plains, NY. The company was established by Robb Turner in 2010. The sap used to produce maple syrup comes from tapped maple trees in areas ranging from the Hudson Valley to Western Vermont. The syrup is processed and bottled at Madava Farms on an 800-acre site.<ref name=\"6/Newsday\"></ref> The farm is considered to be the largest maple syrup production facility in North America.<ref name=\"1/Edible Hudson Valley\"></ref>\n\nThe 800-acre piece of land, located on the town borders of Unionvale, Millbrook, and Dover Plains, was farmland during the Civil War. Afterwards, farming on the property came to a halt, and an unusually high concentration of maples sprung up. Initially purchased for vacation purposes in 2006, Turner was informed by neighbors that the 800 acre property contained approximately 20,000 maple trees. Having no prior knowledge of maple syrup production, Turner consulted the Cornell Cooperative Extension and learned methods for sustainable syrup production. The area was left untouched until 2007, when the property was bought by Robb Turner, a former Wall Street banker, and his wife, Lydia. The couple decided to use the land to found a maple syrup company.<ref name=\"4/HV Reporter\"></ref> The company was called \"Crown Maple,\" and the farm was named Madava Farms, after the Turners' daughters, Ava and Maddie.<ref name=\"2/NY Times\"></ref> The Turners tapped their first trees in 2011 and opened the farm to the public in 2012. The property has at least 40,000 maple trees and a 27,000-square-foot sugarhouse.\n\nIn January 2013, Madava Farms received state grant award money for the purpose of creating a \"tourist destination\" in the Mid-Hudson Valley. Lincoln Ristorante chef Jonathan Benno designed a kitchen for Madava Farms' cafe.\n\nThe 27,000-square foot sugar house on Madava Farms houses the equipment for syrup production, a café and special events dining room, and a store selling crown maple products and other goods. Crown Maple is the only syrup producer that uses a reverse osmosis filtration system, which removes 80% of the water content from the sap and filters out impurities. The facility also contains one of the largest maple syrup evaporators ever built. In an effort to ensure that the syrup production process has a minimized environmental impact, the equipment is cleaned using steam from the evaporation process. This reduces the amount of water used, which is both ecologically and financially beneficial The finished syrup rates a 67 on the Brix scale, higher than the standard 66%, but below the legal limit of 68%.\n\nCrown Maple's current machinery can handle the sap from up to 400,000 tapped trees. With approximately 100,000 trees currently tapped, the planned expansion to tap up to 400,000 trees would make Crown Maple the world's largest single producer of maple syrup.\n\nCrown Maple’s syrup is categorized based on color and flavor: Golden, Amber, Dark, Very Dark, and Bourbon Barrel-Aged. The flavor of a particular batch of maple syrup is determined entirely by the condition of the sap as it flows from the trees. This is based on a variety of climatic factors. In addition to maple syrup, the company also sells maple sugar.\n\nIts products are now used at restaurants like Le Bernadin, Eleven Madison Park, and Lincoln Ristorante. Crown Maple syrup is also an ingredient in a Mast Brothers chocolate bar, Early Bird granola, Nuts & Bolts Brooklyn Gluten-free Granola, and Steve’s and Blue Marble ice creams. The syrup is also available at West Elm, Dean & DeLuca, and limited Whole Foods retailers.\n\nTurner received consultation from the Cornell Cooperative Extension when buying technology and equipment for the operation. The farm prides itself in its technology and environmental sustainability.<ref name=\"3/Schumer\"></ref> To reduce the likeliness of tree infection, thin polymer plastic tubes are used to carry sap to the collection house. The farm also aims to save fuel by not boiling the syrup initially and instead using osmosis machines. As well as eliminating bacteria and cellulose material, the reverse osmosis machines remove up to 75% of the water from the sap. Extracted water is used for watering the property and cleaning the machinery.\n"}
{"id": "1760301", "url": "https://en.wikipedia.org/wiki?curid=1760301", "title": "Data stream mining", "text": "Data stream mining\n\nData Stream Mining is the process of extracting knowledge structures from continuous, rapid data records. A data stream is an ordered sequence of instances that in many applications of data stream mining can be read only once or a small number of times using limited computing and storage capabilities.\n\nIn many data stream mining applications, the goal is to predict the class or value of new instances in the data stream given some knowledge about the class membership or values of previous instances in the data stream.\nMachine learning techniques can be used to learn this prediction task from labeled examples in an automated fashion.\nOften, concepts from the field of incremental learning are applied to cope with structural changes, on-line learning and real-time demands. \nIn many applications, especially operating within non-stationary environments, the distribution underlying the instances or the rules underlying their labeling may change over time, i.e. the goal of the prediction, the class to be predicted or the target value to be predicted, may change over time. This problem is referred to as concept drift.\n\nExamples of data streams include computer network traffic, phone conversations, ATM transactions, web searches, and sensor data.\nData stream mining can be considered a subfield of data mining, machine learning, and knowledge discovery.\n\n\n\n\n\n"}
{"id": "4368047", "url": "https://en.wikipedia.org/wiki?curid=4368047", "title": "Debit card cashback", "text": "Debit card cashback\n\nDebit card cashback (also known as cash out in Australia and New Zealand) is a service offered to retail customers whereby an amount is added to the total purchase price of a transaction paid by debit card and the customer receives that amount in cash along with the purchase. Debit card cashback is offered either by various banks only to some card holders or by companies like VISA, Mastercard or American Express. \nFor example, a customer purchasing $18.99 worth of goods at a supermarket might ask for twenty dollars cashback. They would pay a total of $38.99 ($18.99 + $20.00) with their debit card and receive $20 in cash along with their goods.\n\nThis benefits the store as it reduces the amount of cash banking the store has to do. Many customers find it a useful way to obtain cash as it avoids them having to use a cash machine, which may incur additional fees.\n\nThe idea was originally that of British retail chain Tesco in order to reduce the amount of cash banking the stores needed to carry out, the customer service aspect being a side effect of this.\n\nThe service is offered by both banks and merchants in countries such as the United States, United Kingdom, Republic of Ireland, Belgium, Germany, Sweden, Norway, Canada, Poland, the Netherlands and Australia because of the fee structures in use in these countries:\n\n\nThe combination of these two factors means that the retailer can save money by offering the cashback service. It does not cost the retailer more in commission to add cashback to a debit card purchase, but in the process of giving cashback, the retailer can \"offload\" cash which they would otherwise have to pay to deposit at the bank.\n\nThe services are restricted to debit cards where the merchant pays a fixed fee for the transaction, it is not offered on payments by credit card because they would pay a percentage commission on the additional cash amount to their bank or merchant service provider.\n\nSome vendors enforce a minimum purchase amount or add a fixed fee when providing cashback to a customer.\n\nIn many cases, retailers require customers to initial the cashback entry on the till receipt to confirm they have received the cash. This system is used to prevent cashiers surreptitiously adding cashback amounts to a transaction and keeping the money for themselves (or accusations of same), but more importantly, to ensure that customers cannot return to the store with allegations that the attendant \"forgot\" to hand over the requested cash.\n\nCashback can have benefits for the customer in many scenarios. In locations where there are no cash machines nearby, or the nearby machines are out of order or empty, a local retailer may be able to supply the required cash instead and to offer more flexibility in note denominations. Sometimes it is simply more convenient to combine the transactions at the retailer and ATM into a single cashback transaction with the retailer.\n\nAdditionally, although fees for debit card ATM usage are very rare in countries such as the UK, where cashback originated, this is not the case in some other countries. In Canada and the United States, fees of $1~2 are typical when using an ATM from a different bank than the one with which the customer has an account. The fees in some other countries are even higher. In Germany, for instance, usual fees are €4~5 when using an ATM of another bank network than the one of his bank. This gives rise to another potential cashback advantage for the consumer: by making use of the cashback procedure, this ATM fee can be avoided for the cardholder.\n\nPoland: For standard payment transactions merchants have to pay interest fees as a percentage of payment value, not as a fixed tax. In opposite, for cashback service the merchant receive the fixed fee from the card issuer (~$0.15-0.30), but the one time cashback withdrawal cannot be higher than 300zł (~$80). The cashback service is available at ~1/6 of POS in Poland (2014).\n"}
{"id": "3430567", "url": "https://en.wikipedia.org/wiki?curid=3430567", "title": "Diazodinitrophenol", "text": "Diazodinitrophenol\n\nDiazodinitrophenol (DDNP) was the first diazo compound produced; it was subsequently used to make dyes and explosives. It forms yellow crystals in pure form; however, the color of impure forms may vary from dark yellow to green to dark brown. It is soluble in acetic acid, acetone, concentrated hydrochloric acid, most non-polar solvents and is slightly soluble in water.\nA solution of cold sodium hydroxide may be used to destroy it. DDNP may be desensitized by immersing it in water, as it does not react in water at normal temperature. It is less sensitive to impact but more powerful than mercury fulminate and almost as powerful as lead azide. The sensitivity of DDNP to friction is much less than that of mercury fulminate and lead azide.\n\nDDNP is used with other materials to form priming mixtures, particularly where a high sensitivity to flame or heat is desired. DDNP is often used as an initiating explosive in propellant primer devices and is a substitute for lead styphnate in what are termed \"green\" or \"non-toxic\" (lead free) priming explosive compositions. Lead free primers have been judged as inadequate for service use in firearms due to weak and uneven initiation compared to lead based primers.\n\nDiazodinitrophenol was first prepared in 1858 by the German chemist Peter Griess. It was among the first diazo compounds and for a long time thereafter it was \nused as a starting material for dyes. Although Griess had mentioned in 1859 that diazodinitrophenol exploded upon heating, it was not until 1892 that diazodinitrophenol was first used as an explosive – when Wilhelm Will and Friedrich Lenze, German chemists at the \"Militär-Versuchsamt\" (military research office) in Spandau, Germany, began to investigate azides as potential initiators of explosives. The research was conducted secretly. After a fatal accident, the work was discontinued.\n"}
{"id": "36284579", "url": "https://en.wikipedia.org/wiki?curid=36284579", "title": "Doffer", "text": "Doffer\n\nA doffer is someone who removes (\"doffs\") bobbins, pirns or spindles holding spun fiber such as cotton or wool from a spinning frame and replaces them with empty ones. Historically, spinners, doffers, and sweepers each had separate tasks that were required in the manufacture of spun textiles. From the early days of the industrial revolution, this work, which requires speed and dexterity rather than strength, was often done by children. After World War I, the practice of employing children declined, ending in the United States in 1933. In modern textile mills, doffing machines have now replaced humans.\n\nThe Industrial Revolution created growing demand for child labor in the mills and factories, since children were easier to supervise than adults and good at monotonous, repetitive tasks that often required little physical strength, \nbut where small bodies and nimble fingers were an advantage. \n\nChildren were employed in the mills as spinners, sweepers and doffers, with girls usually starting as spinners and boys as doffers and sweepers. When the bobbins on the spinning frames were full, the machinery stopped. The doffers would swarm into the mill and, as quickly as possible, change all the bobbins, after which the machinery would be restarted and the doffers were free to amuse themselves until the next change-over. On the newer and taller frames, the doffers often had to climb to reach the bobbins.\n\nIn Lancashire the doffing boys were free to do what they liked once they had completed a doffing, as long as they stayed within earshot of the \"throstle jobber,\" who would whistle when they were next needed. They were motivated to do the work as fast as possible, since this gave them as long as possible to play. Between ten and twelve boys could handle a factory with about ten thousand throstle spindles, depending on the amount of yarn being spun.\nThe doffers were usually the sons of poor people, and were small and skinny. They were sometimes called \"The Devil's Own\" for the tricks that they would get up to. As a rule they would go barefoot except at the coldest times of year.\n\nAt Quarry Bank Mill in Styal, England, near Manchester, a doffer earned 1s/6d a day in 1790, and by 1831 was earning from 2s. to 3s. a day. An overlooker's wage in the same period rose from 15s. to 17s. In Leeds in the 1830s a doffer could earn 4s. to 5s. In the textile industry in Britain, wages for children continued to rise steadily compared to those for adults during the period from 1830 to 1860, indicating that demand was outstripping supply. In Belfast linen factories in 1890 girls were employed as doffers, earning the equivalent of US $1.43 daily (about 6s. at the time.)\n\nIn the United States in the first part of the 19th century, although the day was long the doffers only worked for about four hours each day. Memoirs from writers such as Lucy Larcom and Harriet Hanson Robinson describe the long hours, but also the leisurely pace of work and the opportunities for social interactions. In Massachusetts in 1830 a doffer boy earned 25 cents a day. An overseer of rooms would make $1.25 a day, and the superintendent of a mill earned $2.00 a day, considered an excellent wage at the time. In the southern cotton mills it was customary to employ only whites for most jobs in the mill, although blacks had outside jobs and some inside jobs such as firing the boilers. This persisted well into the 20th century.\n\nDuring the later part of the 19th century, working conditions in the U.S. textile industry deteriorated. Immigrant textile workers coming from Yorkshire and Lancashire to New England found the mills poorly run, with the managers cheating on measurements of cuts of cloth and time worked, and arbitrarily cutting wages without warning. These workers were often skilled, accustomed to being well-treated in their home country, and accustomed to taking industrial action if they were not. There were a series of strikes from the 1870s onward.\n\nAn 1889 Royal Commission of Inquiry into the Relations of Capital and Labor in Canada recorded a statement by the assistant superintendent of St. Croix Cotton Mills in St. Stephen, New Brunswick. He said the mill employed some young boys around fifteen years old as doffers, but the average doffer was aged thirty. Wages were from 65 to 80 cents a day. In the summer hours were from 6:30 am to 6 pm, with a half day on Saturday. Winter hours were slightly longer.\nAn employee who had worked in both countries reported that wages were better than in the United States and working conditions better, although the hours were about the same.\n\nDoffers in 1887 in a large mill in Cabarrus County, North Carolina, both boys and girls, earned 40 cents a day. In New England in the 1890s, the doffers, piecers and back boys had their own union, and were not admitted to the mule spinners' union, even though they often aspired to become mule spinners. Many left the industry rather than tolerate the conditions. William Madison Wood, the manager at the Washington Mill in Lawrence, Massachusetts instituted a system in 1895 where employees gained bonuses for meeting production quotas, as long as they missed no more than one day per month. The effect was that weavers drove spinners to produce, spinners drove doffers and so on, and that workers came in even when sick or injured. Wood then used the increased pay to justify running the looms at ever faster speeds.\n\nA doffer could achieve success if he had enough energy and ability. Stephen Davol, born in November 1807, joined his elder brothers as a doffer in the Troy mill in Fall River, Massachusetts in 1818. After rising through the ranks, in 1833 he became superintendent of the Pocasset Mill at the age of twenty-six. He drew up the plans for building a giant new mill for the Pocasset company, by and rising to five stories. The mill was unusual for its time in being built as a whole to plans that considered both the structure and the arrangement of the machinery, belts and gearing.\nFrom 1842 to 1860 Davol was agent, or chief executive, of the Troy Mill. By the 1870s he was a member of the board of ten different companies.\n\nGeorge Alexander Gray (1851–1912) is another example. Gray started work as a doffer before the Civil War when aged eight, earning ten cents a day in a mill at Pinhook, North Carolina. He had little education, but rose to the position of overseer in the mill, and then was given the job of supervising installation of machinery in new plants. He moved to Gastonia, North Carolina, where he built the first mill with his own capital. By the time he died, there were eleven mills in Gastonia, of which Gray had been involved in establishing nine. Carl Augustus Rudisill (1884–1979) began work as a doffer boy in Cherryville, North Carolina, at ten cents a day. He was superintendent of the Indian Creek Manufacturing Company by 1907, and later developed the Carlton Yarn Mills into a major operation. He was a member of the North Carolina legislature from 1937 to 1941.\n\nTowards the end of the 19th century, doffers in the Netherlands were mostly boys of about 12 years of age, who in 1890 had to go to school for a few hours each day. They were part of a team headed by a \"minder\", who was responsible for running two mules, and including a \"big piecer\" and a \"little piecer\", whose main job was to rejoin broken threads.\nAround 1916, self-acting mules were introduced from Germany, which were simpler to operate. The team was reduced to one spinner and one piecer, with the position of doffer eliminated. The pace of modernization and mechanization was faster than in Lancashire, where the unions were more powerful.\n\nA report on conditions in the Bombay mills in India between 1891 and 1917 noted that laws had been passed in response to agitation in England by which no child under nine years old could be employed.\nIn theory, children under fourteen could not work more than seven hours per day, broken into two work periods with a long rest period in between. In practice, much younger children were working longer hours at jobs such as doffing. A man working in the mills would be paid Rs.7 to Rs.9 for the least skilled jobs to as much as Rs18 to Rs22 on a piece-work basis for a mule's minder or spinner. Doffer boys working full-time would earn Rs.4 to Rs.6. As of 1912 about 4,000 boys and girls were employed in the Indian mills, each doffing about 350 ring spindles.\n\nBy 1900 in Crown Mills, Whitfield County, Georgia, the average doffer was fourteen years old.\nA doffer in North Carolina in 1904 would earn $2.40 per week, while a head doffer would earn $3.50. Skilled workers would earn more. A drawing-in girl could make $6.00, a warper $7.50 and an engineer up to $9.00, while the weave boss made as much as $15.00. The working week would be ten hours a day from Monday to Saturday. In 1907, a doffer in North Carolina only had to work about half the time, being able to play baseball, swim in the local river or otherwise relax until the whistle of the head doffer called them back to the mill. If a rural mill depended on a water wheel for power, a drought could provide more free time as the mill would only run a few hours each day.\nLewis Hine obtained a job with the National Child Labor Committee in the United States in 1908, and over the next decade took many photographs that documented children at work. Many of the children worked barefoot, which made it easier to climb the machinery to reach bobbins or broken threads. Children met with accidents more often than adults.\nHines was told by the overseer of one mill \"We don't have any accidents in this mill ... Once in a while a finger is mashed, or a foot, but it don't amount to anything.\" Conditions were demanding. There was a constant racket of machinery. The mill windows were kept closed, creating a hot and humid atmosphere in which cotton threads were less likely to break. The air was filled with lint and dust, making breathing difficult, and often leading to diseases such as tuberculosis and chronic bronchitis. Some workers suffered from Byssinosis, or brown lung, caused by prolonged exposure to cotton dust.\n\nAt that time boys might start to work as doffers before the age of seven. However, as Hines reported, \"In every case, the youngsters told me their age as 12 years, even to the little Hop-o'-My-Thumb, whom the others dubbed 'our baby doffer.' They would hesitate when I asked them, but always succeeded in remembering that they were twelve.\"\nA photograph by Hine of an evidently very young doffer at the Melville Manufacturing Company in Cherryville, North Carolina appeared on the cover of a National Child Labor Committee report around 1912. Hine's photographs of child workers such as doffers were influential in driving reform of child employment laws in the United States, an early example of the power of photo journalism. New laws were introduced, so that by 1914 very few children under 12 were working in the mills, and most were over 14.\n\nAfter World War I ended in 1918, the US textile industry was left with surplus capacity and went into a slump, not recovering until after the 1930s Great Depression. In response, mill owners cut wages and laid off workers, or put them on short hours, while mechanizing further to improve efficiency. New laws made child labor more expensive, and children could not handle the new machinery. The practice of using child labor in the mills declined, finally ending completely when the NIRA Cotton Textile Code was adopted in 1933. Changes to the Factories Act in 1922 reduced formal child labor in the textile factories in India. By the 1940s there were negligible numbers of children in the Kanpur mills.\nMost of the remaining child workers were doffer boys. Elsewhere the change was slower. In Kenya in 1967 \"doffer boy\" was still listed as a job position in the Kisumu Cotton Mills, one of the lowest paid.\n\nImprovements in working conditions were gradually introduced. In 1940 the British recognized byssinosis, or brown lung disease, and started to compensate victims. Due to lack of research and industry resistance, nothing was done about the disease in the United States until the 1970s. Activists organized brown lung screening clinics in Piedmont in 1975. The Carolina Brown Lung Association had 7,000 members by 1981.\nIn 1984 the Occupational Health and Safety Administration responded to pressure from this group and implemented a new cotton dust standard.\n\nIn modern mills the doffing process is relatively automated. with a mechanical doffer fitted to the winder that cuts and aspirates the yarn, removes the packages and places them in a yarn buggy, fits the empty tubes and transfers the yarn so winding can continue.\nThe song \"The Doffing Mistress\" is about flax spinning in Northern Ireland and describes the doffers respect for their mistress. The line \"she hangs her coat on the highest pin\" is because the doffer's work could lead to deformity of the spine.\n\nEdwin Waugh is the author of the dialect poem \"The Little Doffer\" about a doffer in a Lancashire mill who obtained work despite his unsatisfactory replies to the overlooker (foreman).\n\n\n"}
{"id": "23584243", "url": "https://en.wikipedia.org/wiki?curid=23584243", "title": "E-Home Automation", "text": "E-Home Automation\n\ne-Home AUTOMATION () is an Arabic company that develops software and manufactures systems for home automation, home security and audio/video control. Systems created by e-Home include servers, touchscreens, keypads, and lighting control systems.\n\ne-Home produce home automation systems for installation into large real estate developments, particularly in the Middle East.\nThe company has its headquarters in Dubai, and has branches in Saudi Arabia, Kuwait, Egypt, South Africa and China. e-Home's development is conducted in the United Kingdom.\n\ne-Home products are designed to give control of electronic and motorized devices. A variety of interfaces, including Windows Media Center, voice control and smartphones allow the control of audio and video equipment, lighting, heating, ventilation and air conditioning, motorized curtains and irrigation systems around the property.\n\ne-Home has partnerships with several companies, including Intel Corporation, to develop and deploy its systems.\n\n\n"}
{"id": "43604383", "url": "https://en.wikipedia.org/wiki?curid=43604383", "title": "Eko (company)", "text": "Eko (company)\n\nEko, formerly known as Interlude, is a media and technology company that enables production and web distribution of selectable, interactive multimedia videos. It is widely known for the Sony interactive music video for Bob Dylan's \"Like A Rolling Stone\". Eko was founded as Interlude in 2010, and rebranded itself in December 2016.\n\nInterlude software constructs audiovisual multimedia within which users have selection options for seamlessly streaming choices from a traversable video tree. This process is explained and exemplified by actual use examples including the interactive video made for Bob Dylan's \"Like a Rolling Stone\".\n\nThe availability of different video streams allows for a change in viewer perspective or for narrative-branching. For example, a decision tree based on 174 individual film segments results in users controlling an extremely large (98,304) number of permutations. This interactivity increases user engagement.\n\nWithin industry, companies in the advertising and marketing sectors have used Interlude technology. Treehouse, a free HTML5 web-app version of the suite, enables self-authored publishing directly to websites, blogs, Facebook, iOS, and Android.\n\nInterlude was founded by Israeli rock musician Yoni Bloch. Interlude is based in New York, Los Angeles and Tel Aviv, and is backed by Sequoia Capital, Intel Capital, New Enterprise Associates, Marker LLC, Innovation Endeavors, Warner Music Group, Sony Pictures, Samsung, and Walmart.\n\n\n"}
{"id": "26983835", "url": "https://en.wikipedia.org/wiki?curid=26983835", "title": "Electrically detected magnetic resonance", "text": "Electrically detected magnetic resonance\n\nElectrically detected magnetic resonance (EDMR) is a materials characterisation technique that improves upon electron spin resonance. It involves measuring the change in electrical resistance of a sample when exposed to certain microwave frequencies. It can be used to identify very small numbers (down to a few hundred atoms) of impurities in semiconductors.\n\nTo perform a pulsed EDMR experiment, the system is first initialised by placing it in a magnetic field. This orients the spins of the electrons occupying the donor and acceptor in the direction of the magnetic field. To study the donor, we apply a microwave pulse (\"γ\" in the diagram) at a resonant frequency of the donor. This flips the spin of the electron on the donor. The donor electron can then decay to the acceptor energy state (it was forbidden from doing that before it was flipped due to the Pauli exclusion principle) and from there to the valence band, where it recombines with a hole. With more recombination, there will be fewer conduction electrons in the conduction band and a corresponding increase in the resistance, which can be directly measured. Above-bandgap light is used throughout the experiment to ensure that there are lots of electrons in the conduction band.\n\nBy scanning the frequency of the microwave pulse, we can find which frequencies are resonant, and with knowledge of the strength of the magnetic field, we can identify the donor's energy levels from the resonant frequency and knowledge of the Zeeman effect. The donor's energy levels act as a 'fingerprint' by which we can identify the donor and its local electronic environment. By changing the frequency slightly, we can study the acceptor instead.\n\nEDMR has been demonstrated on a single electron from a quantum dot. Measurements of less than 100 donors and theoretical analyses of such a measurement have been published, relying on the P interface defect to act as the acceptor.\n"}
{"id": "708581", "url": "https://en.wikipedia.org/wiki?curid=708581", "title": "Foil bearing", "text": "Foil bearing\n\nFoil bearings, also known as foil-air bearings, are a type of air bearing. A shaft is supported by a compliant, spring-loaded foil journal lining. Once the shaft is spinning fast enough, the working fluid (usually air) pushes the foil away from the shaft so that no contact occurs. The shaft and foil are separated by the air's high pressure, which is generated by the rotation that pulls gas into the bearing via viscosity effects. A high speed of the shaft with respect to the foil is required to initiate the air gap, and once this has been achieved, no wear occurs. Unlike aerostatic or hydrostatic bearings, foil bearings require no external pressurisation system for the working fluid, so the hydrodynamic bearing is self-starting.\n\nFoil bearings were first developed in the late 1950s by AiResearch Mfg. Co. of the Garrett Corporation using independent R&D funds to serve military and space applications. They were first tested for commercial use in United Airlines Boeing 727 and Boeing 737 cooling turbines in the early and mid-1960s. Garrett AiResearch air cycle machine foil bearings were first installed as original equipment in 1969 in the DC-10's environmental control systems. Garrett AiResearch foil bearings were installed on all US military aircraft to replace existing oil-lubricated rolling-contact bearings. The ability to operate at cryogenic gas temperatures and at very high temperatures gave foil bearings many other potential applications.\n\nCurrent-generation foil bearings with advanced coatings have greatly exceeded the limitations of earlier designs. Antiwear coatings exist that allow over 100,000 start/stop cycles for typical applications.\n\nTurbomachinery is the most common application because foil bearings operate at high speed. The main advantage of foil bearings is the elimination of the oil systems required by traditional bearing designs. Other advantages are:\n\nAreas of current research are:\n\nThe main disadvantages are:\n\n\n"}
{"id": "37684687", "url": "https://en.wikipedia.org/wiki?curid=37684687", "title": "Gordon McClymont", "text": "Gordon McClymont\n\nGordon Lee (Bill) McClymont, AO (8 May 1920 – 6 May 2000), was an Australian agricultural scientist, ecologist, and educationist. The originator of the term \"sustainable agriculture\", McClymont is known for his multidisciplinary approach to farm ecology. McClymont was the foundation chair of the Faculty of Rural Science at the University of New England, the first degree program of its kind to integrate animal husbandry, veterinary science, agronomy, and other disciplines into the field of livestock and agricultural production. In 1978, in recognition of his work and contributions to his field, he was appointed Officer of the Order of Australia.\n\nBorn in Australia, McClymont entered the University of Sydney under the sponsorship of the New South Wales Department of Agriculture. After graduating with a bachelor's degree in veterinary science from Sydney and a PhD from the University of Cambridge, he worked as an animal nutrition researcher for the state of New South Wales. Believing that his education had not adequately prepared him for his work, McClymont designed a broader, multi-disciplinary educational approach to the field of livestock and agricultural production. Impressed with his ideas, the University of New England hired McClymont in 1955 to chair its new department of rural science.\n\nWhile at the university, McClymont championed his approach to farm and livestock production and sustainability of agricultural ecosystems. Under his direction, the University of New England became a leader in ruminant research. The Australian poultry industry recognized McClymont's contributions to poultry production with a special award in 1967. After his retirement in 1980, McClymont continued to work with the agricultural industry in Australia and consulted with the United Nations and the World Bank on farm issues. In 1996, he expounded his approach to livestock and farm production in the book \"Rural Science: Philosophy and Application\".\n\nMcClymont was born on 8 May 1920. His father was one of seven sons of a Scottish immigrant to Australia. McClymont's father greeted him as a newborn with, \"G'day Bill\" and Bill stuck with him as a nickname for the rest of his life. McClymont's father's brothers resided in rural areas, including in the Orange, New South Wales, region. Thus, although McClymont grew up in the Sydney metropolitan area, he spent much holiday time as a youth in a rural environment. His activities at his relatives' farms included lamb marking, fruit picking, horse breaking, and pig shooting. McClymont also became familiar with the local animals and plants.\n\nMcClymont attended Chatswood Intermediate High School, where he became interested in science. In his fourth year, he transferred to North Sydney Boys High School. In his Leaving Certificate Exam, taken in 1936, McClymont earned First Class Honours in physics and chemistry, which placed him third and fourth respectively on the New South Wales state honours list. While in high school, he participated in the Australian Army Cadets in a horse-drawn field artillery unit.\n\nLacking funds to attend university, a family friend who worked for the New South Wales Department of Agriculture suggested that McClymont apply for a department traineeship. In spite of his lack of formal agricultural training, McClymont passed the exam and interview and was assigned to the University of Sydney's veterinary science program. Provided with a salary of £110 a year, he entered the university in 1937.\n\nWhen World War II began in 1939, McClymont joined the Australian Army Veterinary Corps in the 2nd Cavalry Mobile Veterinary Section assigned to his university. His unit volunteered for overseas duty, but was refused. McClymont joined the Royal Australian Air Force as an aircrew reservist, but was again denied an overseas assignment and ordered to complete his education at Sydney while serving the military in a scientific advisory role. He joined the Volunteer Defence Corps at the rank of sergeant and served weekend duty during the war years at anti-aircraft and radar installations in Australia.\n\nBecause of the war, McClymont's final two years of undergraduate study were compressed into 16 months. He graduated in 1941 with a bachelor of veterinary science, First Class Honours, and a gold university medal.\n\nImmediately after graduation in 1941, McClymont was appointed as a specialist in animal nutrition at the New South Wales Department of Agriculture. In that position, he was responsible for all extension, advisory work, and policy advice on animal nutrition for the state government. In one instance during the war, McClymont had to respond to a swine influenza outbreak caused by pig meat imported by American troops stationed in Australia. While participating in an operation to kill and burn potentially infected suidae in a local piggery, he met his future wife, Vivienne Pecover, sister of the farmer whose pigs were being slaughtered. The two married in 1946.\n\nFrom 1947 to 1949, under a Walter and Eliza Hall Veterinary Research Fellowship, he attended the University of Cambridge from which he earned a doctor of philosophy. His thesis, called \"Interrelationships between the digestive and mammary physiology of ruminants\", was based on research he had conducted in 1947 in which he discovered that green oat consumption by dairy cows produced milk with less butterfat. In the thesis, he explained how the complex interaction between environment, climate, soil, plant, and animal physiology and metabolism had combined to produce the lowered milkfat.\n\nAfter completion of his term at Cambridge, McClymont toured agricultural research centres and colleges in the United States. While in the US, he gave 15 lectures on his doctoral research. A number of American agricultural scientists told him later that his lectures had caused them to change their fields of research. McClymont was not impressed by the agricultural education he observed in Britain or the US, saying that the British focused on estate management while the Americans concentrated on descriptive evaluations of livestock quality.\n\nUpon his return to Australia in 1950, McClymont was reassigned as Officer in Charge of the department's Animal Nutrition Research Laboratory at Glenfield Veterinary Research Station. At Glenfield, he developed research programs on drought feeding and pregnancy toxaemia in sheep and established a nutritional diagnostic service.\n\nBetween 1945 and 1953, McClymont participated in adult education activities to rural areas around New South Wales for the Sydney University Extension Board and New England University College. New England University College was an extension college of the University of Sydney located in Armidale, New South Wales. The activities included holding seminars on animal husbandry and agriculture for farmers and graziers. From 1951 to 1953, McClymont helped New England University College establish facilities and adult classes in animal husbandry and agricultural economics in Walcha, Tamworth, Moree, and Dubbo.\n\nMcClymont's work experiences caused him to feel disastified with the quality of education he had received in his degree program at Sydney. He felt the veterinary science specialization was too narrow, especially in the area of animal husbandry and livestock production. Moreover, he felt the specialization of the discipline did not provide sufficient knowledge in how the overall farm animal production process worked. For example, as an undergraduate, he received only three lectures on statistics, a skill he had to teach himself during his first few years as an animal nutritionist advisor. As a result, he took an interest in education and curriculum development. McClymont later said that he had \"seen the educational deficiencies of narrow specialization, whether of veterinary graduates as specialists in animal health and disease or of agricultural science graduates as specialists in aspects of soil and plants. I had seen the problems created by such specialized knowledge when exercised without overall understanding.\"\n\nIn June 1952, two lecturers in veterinary science at the University of Sydney, Doug Blood and Jim Steel, wrote a letter to the \"Australian Veterinary Journal\" complaining of their university's placement of animal husbandry as a subordinate topic within veterinary science. They argued that the field of animal husbandry included \"the procurement of maximum production from the available animals, compatible with their continued health and the maintenance of the natural resources of the land on which they live\" and was worthy of its own profession. McClymont saw the letter and responded with his own missive to the journal in June 1953. In his letter, McClymont opined that the field in question should instead be called \"animal production\" and that it should, \"be defined as the integration of animal husbandry and agronomy (the science of pasture and crop production), or in more general terms, manipulation of the soil-plant-animal complex, for the purpose of economic production of animal products.\" He added that the university-level training in the field should include, \"extension work, research, and commercial applications.\" McClymont concluded that university graduates in such a field of study would be prepared to blend veterinary (animal) and agricultural (plant) production sciences to optimize farm animal output.\n\nJames Belshaw, Deputy Warden of New England University College, saw the letter and brought it to the attention of the school's advisory council's Special Committee on Animal Husbandry. At that time, the college was preparing to become an independent university and was looking to differentiate itself with a farm-based degree program that was different from what the University of Sydney had to offer, but which would also be applicable and beneficial to the rural New England area.\n\nWith approval from the committee, Belshaw asked McClymont in July 1953 to prepare a paper further explaining his ideas on the topic of educational curricula related to farm animal production. McClymont's paper, submitted on 8 September 1953, was titled, \"Planning Rural Science and Possible Curriculum\". In the paper, McClymont further expounded his views and, as the title indicated, suggested that a better name for the prospective faculty would be \"rural science.\" In February 1954, Robert Madgwick, vice-chancellor of the newly independent university, reviewed McClymont's paper. Convinced by McClymont's reasoning, Madgwick recommended to the university council the establishment of a faculty of rural science. On 16 October 1954 the University of New England offered McClymont the position of Chair of the soon-to-be established Department of Rural Science.\n\nMcClymont's appointment to the University of New England Faculty of Rural Science took effect in March 1955, one year after the university's independence. Upon arrival, McClymont was surprised by the school's humble facilities. He had to borrow a chair since his office did not have one. Madgwick had assumed that it would take at least two years to get the new department up and running. McClymont, however, pointed out to Madgwick that the program could begin accepting enrollments in 1956 because the existing faculty of science could already offer first-year courses in several basic science topics needed for the degree program.\n\nOn 11 July 1955, McClymont gave the degree program's inaugural address in the auditorium of nearby Armidale Teachers' College, titled \"All Flesh is Grass\" after a passage in the Biblical Book of Isaiah. In the speech, McClymont explained his vision for the goals of the rural science program, saying, \"The economic health of this country, and so the standard of civilization which it will support, rests on the fertility of its soils and on the resultant productivity of its pastures, livestock and crops.\"\n\nThe degree program was the first of its kind to implement a multi-disciplinary approach to farm animal production science. It combined elements of agronomy, biochemistry, physiology, veterinary science, soil and agricultural ecology (agricultural science), biology, economics, social sciences, and animal nutrition and husbandry to teach students how all these elements interacted to create a productive agricultural ecosystem. Graduates from the new program were more generalists than specialists in order to help them find and implement original solutions to varied problems with Australia's livestock production, then still struggling with output and sustainability issues. The impact of the resulting improvements in Australia's livestock production was seen in Australians becoming among the world's biggest per capita meat consumers.\n\nClasses in the degree program began in March 1956 with an initial enrollment of 17 students. Five hundred students had graduated with bachelors in rural science by the early 1980s. One hundred sixty graduated with honours. Seventy had attained master's degrees in the discipline. Graduates included Bridget Ogilvie, director of the Wellcome Trust, Hugh Beggs, Life Governor of the Australian Sheep Breeders Association and Chair of both the Australian Wool Corporation and the International Wool Secretariat, I Made Nits, Professor of Nutrition and Tropical Forage at Udayana University, and Robert Clements, Director of the Australian Centre for International Agricultural Research. As of 2005, approximately 1,700 students had passed through the rural science program.\n\nAs chair of the department, McClymont advocated and helped establish functionally autonomous agricultural education community centres around the New England area. The centres, supported by both the Departments of Rural Science and Agricultural Economics, were patterned after university external agricultural centres in the United States. The centres were financially independent and so avoided control by the university's central administration.\n\nMcClymont's writings and lectures while at the university emphasized the importance of sustainability in agricultural ecosystems. He is considered to be the originator of the term \"sustainable agriculture.\" McClymont diagrammed the key elements of agricultural ecosystems into a series of flowcharts which were often used by other agricultural instructors. He alerted the agricultural community to the issues involved with feeding grain to livestock while the world was experiencing a shortage of grain.\n\nDuring the 1960s and 1970s, the University of New England became a prominent international centre in ruminant research. McClymont published a series of articles in academic journals on biochemistry and animal nutrition, including pregnancy toxaemia in sheep, poultry nutrition, and mineral deficiencies in dairy cattle. He promoted an original approach to researching metabolic diseases in livestock, utilizing radioactive tracer methods to identify \"the quantitative importance of various metabolites including glucose, volatile fatty acids, B-hydroxybutyrate and long chain fatty acids in ruminant metabolism, and the metabolic interactions between these materials.\"\n\nMcClymont and Professor R. B. Cumming established the Poultry Research Fund Group at the Tamworth Adult Education Centre to facilitate the exchange of ideas between the university's rural science and agricultural economics departments and the poultry industry. The group first met on 1 July 1963. In 1967 McClymont was awarded the Australian Poultry Award for his work in poultry nutrition and with the poultry industry, particularly in the Namoi River region.\n\nIn 1967, McClymont proposed the establishment of a School of Biological Sciences at the university because of expansion of the topic within the Department of Rural Science. The school was founded the next year.\n\nMcClymont served on the advisory standing committee of eight for the independent but university-affiliated Kellogg Rural Adjustment Unit. The formal commencement for the unit was on 1 July 1976, with operations beginning the next year. The name of the organization was later changed to Rural Development Centre. The purpose of the centre, among other objectives, was to provide education on rural issues and policies, play a role in the development of rural policies, and assist rural communities in adjusting to changes in their cultural and economic environments.\n\nWhile at the university, McClymont consulted to the Food and Agriculture Organization of the United Nations. In 1975 the organization published a booklet he authored, titled \"Formal Education and Rural Development\". On 26 January 1978, citing his \"service to veterinary science and to agricultural research,\" the Commonwealth of Australia designated McClymont an Officer in the Order of Australia.\n\nMcClymont retired from the university in 1980 and was appointed an emeritus professor. Professor J. S. Ryan said, \"Fifty years on, he is widely recognized – and acclaimed – as being so far ahead of his time in recognizing the vital interaction between animal and plant production and in the importance of a healthy ecosystem.\"\n\nIn retirement, McClymont continued to consult with the Food and Agriculture Organization of the United Nations in its Department of Agricultural Education, Research, and Rural Matters. In addition, he consulted on agricultural issues with the World Bank.\n\nAs an emeritus professor, McClymont observed and commented on issues with the rural science curriculum at New England. An external review, began in 1979 by the university with help from an independent committee of agricultural specialists from the Australian Academy of Science, recommended curriculum changes, which were implemented in 1982. The most significant change was increased freedom given to students to choose electives in the fourth year of study, allowing limited specialization in certain subject areas. McClymont lamented the changes, feeling that they damaged the quality and standing of the rural science degree program.\n\nIn 1994, McClymont and New England professor J. S. Ryan began work on the book \"Rural Science: Philosophy and Application\". In 1996 a special conference was held at the University of New England to commemorate the 40th anniversary of the establishment of the rural science curriculum. Although he was in failing health, McClymont attended as a guest of honour. \"Rural Science\" was formally presented at the conference. Said Ryan of the book, \"This work is less of a respective chronicle, but is one arising from a more reflective, forward-looking, questioning, and nationally and globally focused essays\".\n\nAfter years of struggling with Parkinson's disease, McClymont died on 6 May 2000. A building on New England's Armidale campus was named after him. He was survived by his wife, Vivienne, and their four children, daughter Vicky and sons Kim, Glen, and Rod.\n\nMcClymont believed in challenging dogma, which sometimes earned him enmity from colleagues and associates. J. S. Ryan described McClymont as \"devastatingly honest,\" but \"always likeable and compassionate.\" He reportedly placed emphasis on the welfare of his students. For example, McClymont criticized the 1963 decision by the University Council to abolish room-visiting between female and male students.\n\nMcClymont's personal interests included acting, singing, and landscape gardening. He sang bass in New England's University Choir.\n\n\n\n"}
{"id": "62982", "url": "https://en.wikipedia.org/wiki?curid=62982", "title": "Gulf of Tonkin incident", "text": "Gulf of Tonkin incident\n\nThe Gulf of Tonkin incident (), also known as the USS \"Maddox\" incident, was an international confrontation that led to the United States engaging more directly in the Vietnam War. It involved either one or two separate confrontations involving North Vietnam and the United States in the waters of the Gulf of Tonkin. The original American report blamed North Vietnam for both incidents, but eventually became very controversial with widespread belief that at least one, and possibly both incidents were false, and possibly deliberately so. On August 2, 1964, the destroyer , while performing a signals intelligence patrol as part of DESOTO operations, was pursued by three North Vietnamese Navy torpedo boats of the 135th Torpedo Squadron. \"Maddox\" fired three warning shots and the North Vietnamese boats then attacked with torpedoes and machine gun fire. \"Maddox\" expended over 280 3-inch (76.2 mm) and 5-inch (127 mm) shells in a sea battle. One U.S. aircraft was damaged, three North Vietnamese torpedo boats were damaged, and four North Vietnamese sailors were killed, with six more wounded. There were no U.S. casualties. \"Maddox\" \"was unscathed except for a single bullet hole from a Vietnamese machine gun round.\"\n\nIt was originally claimed by the National Security Agency that a Second Gulf of Tonkin incident occurred on August 4, 1964, as another sea battle, but instead evidence was found of \"Tonkin ghosts\" (false radar images) and not actual North Vietnamese torpedo boats. In the 2003 documentary \"The Fog of War\", the former United States Secretary of Defense Robert S. McNamara admitted that the August 2 USS \"Maddox\" attack happened with no Defense Department response, but the August 4 Gulf of Tonkin attack never happened. In 1995, McNamara met with former Vietnam People's Army General Võ Nguyên Giáp to ask what happened on August 4, 1964 in the second Gulf of Tonkin Incident. \"Absolutely nothing\", Giáp replied. Giáp claimed that the attack had been imaginary.\n\nThe outcome of these two incidents was the passage by Congress of the Gulf of Tonkin Resolution, which granted President Lyndon B. Johnson the authority to assist any Southeast Asian country whose government was considered to be jeopardized by \"communist aggression\". The resolution served as Johnson's legal justification for deploying U.S. conventional forces and the commencement of open warfare against North Vietnam.\n\nIn 2005, an internal National Security Agency historical study was declassified; it concluded that \"Maddox\" had engaged the North Vietnamese Navy on August 2, but that there were no North Vietnamese naval vessels present during the incident of August 4. The report stated, regarding the first incident on August 2:\n\nat 1500G, Captain Herrick ordered Ogier's gun crews to open fire if the boats approached within ten thousand yards (9,150 m). At about 1505G, \"Maddox\" fired three rounds to warn off the communist [North Vietnamese] boats. This initial action was never reported by the Johnson administration, which insisted that the Vietnamese boats fired first.\n\nAlthough the United States attended the Geneva Conference (1954), which was intended to end hostilities between France and the Vietnamese at the end of the First Indochina War, it refused to sign the Geneva Accords (1954). The accords mandated, among other measures, a temporary ceasefire line, intended to separate Vietnamese and French forces, and elections to determine the future political fate of the Vietnamese within two years. It also forbade the political interference of other countries in the area, the creation of new governments without the stipulated elections, and foreign military presence. By 1961, President Ngo Dinh Diem faced significant discontent among some quarters of the southern population, including some Buddhists who were opposed to the rule of Diem's Catholic supporters. After suppressing Vietminh political cadres who were legally campaigning between 1955 and 1959 for the promised elections, Diem faced a growing communist-led uprising that intensified by 1961, headed by the National Front for the Liberation of South Vietnam (NLF, or Viet Cong).\n\nThe Gulf of Tonkin Incident occurred during the first year of the Johnson administration. While Kennedy had originally supported the policy of sending military advisers to Diem, he had begun to alter his thinking due to what he perceived to be the ineptitude of the Saigon government and its inability and unwillingness to make needed reforms (which led to a U.S.-supported coup which resulted in the death of Diem). Shortly before Kennedy was assassinated in November 1963, he had begun a limited recall of U.S. forces. Johnson's views were likewise complex, but he had supported military escalation as a means of challenging what was perceived to be the Soviet Union's expansionist policies. The Cold War policy of containment was to be applied to prevent the fall of Southeast Asia to communism under the precepts of the domino theory. After Kennedy's assassination, Johnson ordered in more U.S. forces to support the Saigon government, beginning a protracted United States presence in Southeast Asia.\n\nA highly classified program of covert actions against North Vietnam known as Operation Plan 34-Alpha, in conjunction with the DESOTO operations, had begun under the Central Intelligence Agency (CIA) in 1961. In 1964 the program was transferred to the Defense Department and conducted by the Military Assistance Command, Vietnam Studies and Observations Group (MACV-SOG).\n\nFor the maritime portion of the covert operation, a set of fast patrol boats had been purchased quietly from Norway and sent to South Vietnam. In 1963 three young Norwegian skippers traveled on a mission in South Vietnam. They were recruited for the job by the Norwegian intelligence officer Alf Martens Meyer. Martens Meyer, who was head of department at the military intelligence staff, operated on behalf of U.S. intelligence. The three skippers did not know who Meyer really was when they agreed to a job that involved them in sabotage missions against North Vietnam. Although the boats were crewed by South Vietnamese naval personnel, approval for each mission conducted under the plan came directly from Admiral U.S. Grant Sharp, Jr., CINCPAC in Honolulu, who received his orders from the White House. After the coastal attacks began, Hanoi lodged a complaint with the International Control Commission (ICC), which had been established in 1954 to oversee the terms of the Geneva Accords, but the U.S. denied any involvement. Four years later, Secretary McNamara admitted to Congress that the U.S. ships had in fact been cooperating in the South Vietnamese attacks against North Vietnam. \"Maddox\", although aware of the operations, was not directly involved.\n\nWhat was generally not considered by U.S. politicians at the time were the other actions taken under Operations Plan 34-Alpha just prior to the incident. The night before the launching of the actions against North Vietnamese facilities on Hòn Mê and Hòn Ngư islands, the SOG had launched a covert long-term agent team into North Vietnam, which was promptly captured. That night (for the second evening in a row), two flights of CIA-sponsored Laotian fighter-bombers (piloted by Thai mercenaries) attacked border outposts well within southwestern North Vietnam. The Hanoi government (which, unlike the U.S. government, had to give permission at the highest levels for the conduct of such missions) probably assumed that they were all a coordinated effort to escalate military actions against North Vietnam.\n\nDaniel Ellsberg, who was on duty in the Pentagon the night of August 4, receiving messages from the ship, reported that the ship was on a secret electronic warfare support measures mission (codenamed \"DESOTO\") near Northern Vietnamese territorial waters. On July 31, 1964, had begun her intelligence collection mission in the Gulf of Tonkin. Captain George Stephen Morrison was in command of local American forces from his flagship . \"Maddox\" was under orders not to approach closer than eight miles (13 km) from the North's coast and four miles (6 km) from Hon Nieu island. When the SOG commando raid was being carried out against Hon Nieu, the ship was away from the attacked area.\n\nIn July 1964, \"the situation along North Vietnam's territorial waters had reached a near boil,\" due to South Vietnamese commando raids and airborne operations that inserted intelligence teams into North Vietnam, as well as North Vietnam's military response to these operations. On the night of July 30, 1964, South Vietnamese commandos attacked a North Vietnamese radar station on Hòn Mê island. According to Hanyok, \"it would be attacks on these islands, especially Hòn Mê, by South Vietnamese commandos, along with the proximity of the Maddox, that would set off the confrontation,\" although the Maddox did not participate in the commando attacks. In this context, on July 31, \"Maddox\" began patrols of the North Vietnamese coast to collect intelligence, coming within a few miles of Hòn Mê island. A U.S. aircraft carrier, the USS Ticonderoga, was also stationed nearby.\n\nBy August 1, North Vietnamese patrol boats were tracking \"Maddox\", and several intercepted communications indicated that they were preparing to attack. \"Maddox\" retreated, but the next day, August 2, \"Maddox\", which had a top speed of 28 knots, resumed her routine patrol, and three North Vietnamese P-4 torpedo boats with a top speed of 50 knots began to follow \"Maddox\". Intercepted communications indicated that the vessels intended to attack \"Maddox\". As the ships approached from the southwest, \"Maddox\" changed course from northeasterly to southeasterly and increased speed to 25 knots. On the afternoon of August 2, as the torpedo boats neared, \"Maddox\" fired three warning shots. The North Vietnamese boats then attacked and \"Maddox\" radioed she was under attack from the three boats, closing to within , while located away from the North Vietnamese coast in international waters. \"Maddox\" stated she had evaded a torpedo attack and opened fire with its five-inch (127 mm) guns, forcing the torpedo boats away. Two of the torpedo boats had come as close as and released one torpedo each, but neither one was effective, coming no closer than about after \"Maddox\" evaded them. Another P-4 received a direct hit from a five-inch shell from \"Maddox\"; its torpedo malfunctioned at launch. Four USN F-8 Crusader jets launched from the aircraft carrier and 15 minutes after \"Maddox\" had fired her initial warning shots, attacked the retiring P-4s, claiming one was sunk and one heavily damaged. \"Maddox\" suffered only minor damage from a single 14.5 mm bullet from a P-4's KPV heavy machine gun into her superstructure. Retiring to South Vietnamese waters, \"Maddox\" was joined by the destroyer . The North Vietnamese claimed that \"Maddox\" was hit by one torpedo, and one of the American aircraft had been shot down.\n\nThe original account from the \"Pentagon Papers\" has been revised in light of a 2005 internal NSA historical study, which stated on page 17:\n\n\"Maddox\", when confronted, was approaching Hòn Mê Island, three to four nautical miles (nmi) (6 to 7 km) inside the limit claimed by North Vietnam. This territorial limit was unrecognized by the United States. After the skirmish, President Johnson ordered \"Maddox\" and \"Turner Joy\" to stage daylight runs into North Vietnamese waters, testing the limit and North Vietnamese resolve. These runs into North Vietnamese territorial waters coincided with South Vietnamese coastal raids and were interpreted as coordinated operations by the North, which officially acknowledged the engagements of August 2, 1964.\n\nOthers, such as Admiral Sharp, maintained that U.S. actions did not provoke the August 2 incident. He claimed that the North Vietnamese had tracked \"Maddox\" along the coast by radar, and were thus aware that the destroyer had not actually attacked North Vietnam and that Hanoi (or the local commander) had ordered its craft to engage \"Maddox\" anyway. North Vietnamese general Phùng Thế Tài later claimed that \"Maddox\" had been tracked since July 31 and that she had attacked fishing boats on August 2 forcing the North Vietnamese Navy to \"fight back\".\n\nSharp also noted that orders given to \"Maddox\" to stay off the North Vietnamese coast put the ship in international waters, as North Vietnam claimed only a limit as its territory (or off of its off-shore islands). In addition, many nations had previously carried out similar missions all over the world, and the destroyer had earlier conducted an intelligence-gathering mission in similar circumstances without incident. \n\nHowever Sharp's claims include some factually incorrect statements. North Vietnam never claimed an 8-kilometer (5 mi) limit for its territorial waters, instead it adhered to a limit claimed by French Indochina in 1936. Moreover it officially claimed a 12 nm limit, which is practically identical to the old 20 km French claim, after the incidents of August, in September 1964. The North Vietnamese stance is that they always considered a 12 nautical mile limit, consistently with the positions regarding the law of the sea of both the Soviet Union and China, their main allies.\n\nOn August 4, another DESOTO patrol off the North Vietnamese coast was launched by \"Maddox\" and \"Turner Joy\", in order to \"show the flag\" after the first incident. This time their orders indicated that the ships were to close to no less than from the coast of North Vietnam. During an evening and early morning of rough weather and heavy seas, the destroyers received radar, sonar, and radio signals that they believed signaled another attack by the North Vietnamese navy. For some four hours the ships fired on radar targets and maneuvered vigorously amid electronic and visual reports of enemies. Despite the Navy's claim that two attacking torpedo boats had been sunk, there was no wreckage, bodies of dead North Vietnamese sailors, or other physical evidence present at the scene of the alleged engagement.\n\nSecretary McNamara at the White House told President Johnson that a U.S. Navy vessel had been attacked and urged retaliation. The President agreed.\n\nAt 01:27, Washington time, Herrick sent a cable in which he acknowledged that the second attack may not have happened and that there may actually have been no Vietnamese craft in the area: \"Review of action makes many reported contacts and torpedoes fired appear doubtful. Freak weather effects on radar and overeager sonarmen may have accounted for many reports. No actual visual sightings by \"Maddox\". Suggest complete evaluation before any further action taken\".\n\nOne hour later, Herrick sent another cable, stating, \"Entire action leaves many doubts except for apparent ambush at beginning. Suggest thorough reconnaissance in daylight by aircraft.\" In response to requests for confirmation, at around 16:00 Washington time, Herrick cabled, \"Details of action present a confusing picture although certain that the original ambush was bona fide.\" Secretary McNamara decided against informing the president that a new report had been received casting grave doubt on the existence of the incident that was the premise of the president's decision earlier that day to retaliate, and McNamara continued making plans for U.S. military retaliation.\n\nAt 18:00 Washington time (05:00 in the Gulf of Tonkin), Herrick cabled yet again, this time stating, \"the first boat to close the \"Maddox\" probably launched a torpedo at the \"Maddox\" which was heard but not seen. All subsequent \"Maddox\" torpedo reports are doubtful in that it is suspected that sonarman was hearing the ship's own propeller beat\".\n\nWithin thirty minutes of August 4 incident, President Johnson had decided on retaliatory attacks. That same day he used the \"hot line\" to Moscow, and assured the Soviets he had no intent in opening a broader war in Vietnam. Early on August 5, Johnson publicly ordered retaliatory measures stating, \"The determination of all Americans to carry out our full commitment to the people and to the government of South Vietnam will be redoubled by this outrage.\" One hour and forty minutes after his speech, aircraft launched from U.S. carriers reached North Vietnamese targets. On August 5, at 10:40, these planes bombed four torpedo boat bases and an oil-storage facility in Vinh.\n\nShortly before midnight, on August 4, President Johnson interrupted national television to make an announcement in which he described an attack by North Vietnamese vessels on two U.S. Navy warships, \"Maddox\" and \"Turner Joy\" requested authority to undertake a military response. Johnson's speech repeated the theme that \"dramatized Hanoi/Ho Chi Minh as the aggressor and which put the United States into a more acceptable defensive posture.\" Johnson also referred to the attacks as having taken place \"on the high seas,\" suggesting that they had occurred in international waters.\n\nHe emphasized commitment to both the American people, and the South Vietnamese government. He also reminded Americans that there was no desire for war. \"A close scrutiny of Johnson's public statements ... reveals no mention of preparations for overt warfare and no indication of the nature and extent of covert land and air measures that already were operational.\" Johnson's statements were short to \"minimize the U.S. role in the conflict; a clear inconsistency existed between Johnson's actions and his public discourse.\"\n\nWhile President Johnson's final resolution was being drafted, Senator Wayne Morse attempted to hold a fundraiser to raise awareness about possible faulty records of the incident involving \"Maddox\". Morse supposedly received a call from an informant who has remained anonymous urging Morse to investigate official logbooks of \"Maddox\". These logs were not available before President Johnson's resolution was presented to Congress.\n\nAfter urging Congress that they should be wary of President Johnson's coming attempt to convince Congress of his resolution, Morse failed to gain enough cooperation and support from his colleagues to mount any sort of movement to stop it. Immediately after the resolution was read and presented to Congress, Morse began to fight it. He contended in speeches to Congress that the actions taken by the United States were actions outside the constitution and were \"acts of war rather than acts of defense.\"\n\nMorse's efforts were not immediately met with support, largely because he revealed no sources and was working with very limited information. It was not until after the United States became more involved in the war that his claim began to gain support throughout the United States government. Morse was defeated when he ran for re-election in 1968.\n\nEvidence was still being sought on the night of August 4 when Johnson gave his address to the American public on the incident. Messages recorded that day indicate that neither President Johnson nor Secretary McNamara was certain of an attack.\n\nVarious news sources, including \"Time\", \"Life\" and \"Newsweek\", ran articles throughout August on the Tonkin Gulf incident. \"Time\" reported: \"Through the darkness, from the West and south ... intruders boldly sped ... at least six of them ... they opened fire on the destroyers with automatic weapons, this time from as close as 2,000 yards.\" \"Time\" stated that there was \"no doubt in Sharp's mind that the US would now have to answer this attack\", and that there was no debate or confusion within the administration regarding the incident.\n\nThe use of the set of incidents as a pretext for escalation of U.S. involvement follows the issuance of public threats against North Vietnam, as well as calls from American politicians in favor of escalating the war. On May 4, 1964, William Bundy called for the U.S. to \"drive the communists out of South Vietnam\", even if that meant attacking both North Vietnam and communist China. Even so, the Johnson administration in the second half of 1964 focused on convincing the American public that there was no chance of war between the United States and North Vietnam.\n\nNorth Vietnam's General Giap suggested that the DESOTO patrol had been sent into the gulf to provoke North Vietnam into giving an excuse for escalation of the war. Various government officials and men aboard \"Maddox\" have suggested similar theories. American politicians and strategists had been planning provocative actions against North Vietnam for some time. George Ball told a British journalist after the war that \"at that time ... many people ... were looking for any excuse to initiate bombing\".\n\nAccording to Raymond McGovern, a retired CIA officer (CIA analyst from 1963 to 1990, and in the 1980s, chairman of the National Intelligence Estimates), the CIA, \"not to mention President Lyndon Johnson, Defense Secretary Robert McNamara and National Security Adviser McGeorge Bundy all knew full well that the evidence of any armed attack on the evening of Aug. 4, 1964, the so-called \"second\" Tonkin Gulf incident, was highly dubious. ... During the summer of 1964, President Johnson and the Joint Chiefs of Staff were eager to widen the war in Vietnam. They stepped up sabotage and hit-and-run attacks on the coast of North Vietnam.\" \"Maddox\", carrying electronic spying gear, was to collect signals intelligence from the North Vietnamese coast, and the coastal attacks were seen as a helpful way to get the North Vietnamese to turn on their coastal radars. For this purpose, it was authorized to approach the coast as close as 13 kilometers (8 mi) and the offshore islands as close as four; the latter had already been subjected to shelling from the sea.\n\nIn his book, \"Body of Secrets\", James Bamford, who spent three years in the United States Navy as an intelligence analyst, writes, that the primary purpose of the \"Maddox\" \"was to act as a seagoing provocateur—to poke its sharp gray bow and the American flag as close to the belly of North Vietnam as possible, in effect shoving its five-inch cannons up the nose of the communist navy. ... The Maddox mission was made even more provocative by being timed to coincide with commando raids, creating the impression that the Maddox was directing those missions ...\" Thus, the North Vietnamese had every reason to believe that \"Maddox\" was involved in these actions.\n\nProvocative action against North Vietnam was considered after the August 1964 incidents. John McNaughton suggested in September 1964, that the U.S. prepare to take actions to provoke a North Vietnamese military reaction, including plans to use DESOTO patrols North. William Bundy's paper dated September 8, 1964, suggested more DESOTO patrols as well.\n\nSecretary McNamara failed to inform President Johnson that the U.S. Naval task group commander in the Tonkin Gulf, Captain John J. Herrick, had changed his mind about the alleged North Vietnamese torpedo attack on U.S. warships he had reported earlier that day.\n\nBy early afternoon of August 4, Washington time, Herrick had reported to the Commander in Chief Pacific in Honolulu that \"freak weather effects\" on the ship's radar had made such an attack questionable. In fact, Herrick was now saying, in a message sent at 1:27 pm Washington time, that no North Vietnamese patrol boats had actually been sighted. Herrick now proposed a \"complete evaluation before any further action taken.\"\n\nMcNamara later testified that he had read the message after his return to the Pentagon that afternoon. But he did not immediately call Johnson to tell him that the whole premise of his decision at lunch to approve McNamara's recommendation for retaliatory air strikes against North Vietnam was now highly questionable. Had Johnson been accurately informed about the Herrick message, he might have demanded fuller information before proceeding with a broadening of the war. Johnson had fended off proposals from McNamara and other advisers for a policy of bombing the North on four separate occasions since becoming president.\n\nPresident Johnson, who was up for election that year, ordered retaliatory air strikes and went on national television on August 4. Although \"Maddox\" had been involved in providing intelligence support for South Vietnamese attacks at Hòn Mê and Hòn Ngư, Johnson denied, in his testimony before Congress, that the U.S. Navy had supported South Vietnamese military operations in the Gulf. He thus characterized the attack as \"unprovoked\" since the ship had been in international waters.\n\nAs a result of his testimony, on August 7, Congress passed a joint resolution (H.J. RES 1145), titled the Southeast Asia Resolution, which granted President Johnson the authority to conduct military operations in Southeast Asia without the benefit of a declaration of war. The resolution gave President Johnson approval \"to take all necessary steps, including the use of armed force, to assist any member or protocol state of the Southeast Asia Collective Defense Treaty requesting assistance in defense of its freedom.\"\n\nIn 1965, President Johnson commented privately: \"For all I know, our navy was shooting at whales out there.\"\n\nIn 1967, former naval officer, John White, wrote a letter to the editor of the \"New Haven (CT) Register\". He asserted \"I maintain that President Johnson, Secretary McNamara and the Joint Chiefs of Staff gave false information to Congress in their report about US destroyers being attacked in the Gulf of Tonkin.\" White continued his whistleblowing activities in the 1968 documentary \"In the Year of the Pig\". White soon arrived in Washington to meet with Senator Fulbright to discuss his concerns, particularly the faulty sonar reports.\n\nIn 1981, Captain Herrick and journalist Robert Scheer re-examined Herrick's ship's log and determined that the first torpedo report from August 4, which Herrick had maintained had occurred—the \"apparent ambush\"—was in fact unfounded.\n\nAlthough information obtained well after the fact supported Captain Herrick's statements about the inaccuracy of the later torpedo reports as well as the 1981 Herrick and Scheer conclusion about the inaccuracy of the first, indicating that there was no North Vietnamese attack that night, at the time U.S. authorities and all of the \"Maddox\"s crew stated that they were convinced that an attack had taken place. As a result, planes from the aircraft carriers and were sent to hit North Vietnamese torpedo boat bases and fuel facilities during Operation Pierce Arrow.\nSquadron Commander James Stockdale was one of the U.S. pilots flying overhead during the second alleged attack. Stockdale wrote in his 1984 book \"Love and War\": \"[I] had the best seat in the house to watch that event, and our destroyers were just shooting at phantom targets—there were no PT boats there ... There was nothing there but black water and American fire power.\" Stockdale at one point recounts seeing pointing her guns at \"Maddox\". Stockdale said his superiors ordered him to keep quiet about this. After he was captured, this knowledge became a heavy burden. He later said he was concerned that his captors would eventually force him to reveal what he knew about the second incident.\n\nIn 1995, retired Vietnamese Defense Minister, Võ Nguyên Giáp, meeting with former Secretary McNamara, denied that Vietnamese gunboats had attacked American destroyers on August 4, while admitting to the attack on August 2. A taped conversation of a meeting several weeks after passage of the Gulf of Tonkin Resolution was released in 2001, revealing that McNamara expressed doubts to President Johnson that the attack had even occurred.\n\nIn the fall of 1999, retired Senior CIA Engineering Executive S. Eugene Poteat wrote that he was asked in early August 1964 to determine if the radar operator's report showed a real torpedo boat attack or an imagined one. He asked for further details on time, weather and surface conditions. No further details were forthcoming. In the end he concluded that there were no torpedo boats on the night in question, and that the White House was interested only in confirmation of an attack, not that there was no such attack.\n\nIn October 2012 retired Rear Admiral, Lloyd \"Joe\" Vasey, was interviewed by David Day on Asia Review and gave a detailed account of the August 4 incident. According to Admiral Vasey, who was aboard , a guided missile cruiser, in the Gulf of Tonkin and serving as chief of staff to Commander Seventh Fleet, \"Turner Joy\" intercepted an NVA radio transmission ordering a torpedo boat attack on \"Turner Joy\" and \"Maddox\". Shortly thereafter, radar contact of \"several high speed contacts closing in on them\" was acquired by the USS \"Turner Joy\", which locked on to one of the contacts, fired and struck the torpedo boat. There were 18 witnesses, both enlisted and officers, who reported various aspects of the attack; smoke from the stricken torpedo boat, torpedo wakes (reported by four separate individuals on each destroyer), sightings of the torpedo boats moving through the water and searchlights. All 18 of the witnesses testified at a hearing in Olongapo, Philippines, and their testimony is a matter of public record.\n\nIn 2014, as the incident's 50th anniversary approached, John White wrote \"The Gulf of Tonkin Events—Fifty Years Later: A Footnote to the History of the Vietnam War\". In the foreword, he notes \"Among the many books written on the Vietnamese war, half a dozen note a 1967 letter to the editor of a Connecticut newspaper which was instrumental in pressuring the Johnson administration to tell the truth about how the war started. The letter was mine.\" The story discusses Lt. White reading Admiral Stockdale's \"In Love and War\" in the mid-80s, then contacting Stockdale who connected White with Joseph Schaperjahn, chief sonarman on \"Turner Joy\". Schaperjahn confirmed White's assertions that \"Maddox\"s sonar reports were faulty and the Johnson administration knew it prior to going to Congress to request support for the Gulf of Tonkin Resolution. White's book explains the difference between lies of commission and lies of omission. Johnson was guilty of willful lies of omission. White was featured in the August 2014 issue of \"Connecticut Magazine\".\n\nIn October 2005 \"The New York Times\" reported that Robert J. Hanyok, a historian for the U.S. National Security Agency, concluded that the NSA distorted intelligence reports passed to policy makers regarding the August 4, 1964 incident. The NSA historian agency staff \"deliberately skewed\" the evidence to make it appear that an attack had occurred.\n\nHanyok's conclusions were initially published in the Winter 2000/Spring 2001 Edition of \"Cryptologic Quarterly\" about five years before the \"Times\" article. According to intelligence officials, the view of government historians that the report should become public was rebuffed by policy makers concerned that comparisons might be made to intelligence used to justify the Iraq War (Operation Iraqi Freedom) which commenced in 2003. Reviewing the NSA's archives, Hanyok concluded that the incident began at Phu Bai Combat Base, where intelligence analysts mistakenly believed the destroyers would soon be attacked. This would have been communicated back to the NSA along with evidence supporting such a conclusion, but in fact the evidence did not do that. Hanyok attributed this to the deference that the NSA would have likely given to the analysts who were closer to the event. As the evening progressed, further signals intelligence (SIGINT) did not support any such ambush, but the NSA personnel were apparently so convinced of an attack that they ignored the 90% of SIGINT that did not support that conclusion, and that was also excluded from any reports they produced for the consumption by the President. There was no political motive to their action.\n\nOn November 30, 2005, the NSA released a first installment of previously classified information regarding the Gulf of Tonkin incident, including a moderately sanitized version of Mr. Hanyok's article. The Hanyok article stated that intelligence information was presented to the \"in such a manner as to preclude responsible decision makers in the Johnson administration from having the complete and objective narrative of events.\" Instead, \"only information that supported the claim that the communists had attacked the two destroyers was given to Johnson administration officials.\"\n\nWith regard to why this happened, Hanyok wrote:\n\nHanyok included his study of Tonkin Gulf as one chapter in an overall history of NSA involvement and American SIGINT, in the Indochina Wars. A moderately sanitized version of the overall history was released in January 2008 by the National Security Agency and published by the Federation of American Scientists.\n\n\n\n"}
{"id": "57169", "url": "https://en.wikipedia.org/wiki?curid=57169", "title": "HVAC", "text": "HVAC\n\nHeating, ventilation, and air conditioning (HVAC) is the technology of indoor and vehicular environmental comfort. Its goal is to provide thermal comfort and acceptable indoor air quality. HVAC system design is a subdiscipline of mechanical engineering, based on the principles of thermodynamics, fluid mechanics and heat transfer. \"Refrigeration\" is sometimes added to the field's abbreviation, as HVAC&R or HVACR or \"ventilation\" is dropped, as in HACR (as in the designation of HACR-rated circuit breakers).\n\nHVAC is an important part of residential structures such as single family homes, apartment buildings, hotels and senior living facilities, medium to large industrial and office buildings such as skyscrapers and hospitals, on ships and submarines, and in marine environments, where safe and healthy building conditions are regulated with respect to temperature and humidity, using fresh air from outdoors.\n\nVentilating or ventilation (the \"V\" in HVAC) is the process of exchanging or replacing air in any space to provide high indoor air quality which involves temperature control, oxygen replenishment, and removal of moisture, odors, smoke, heat, dust, airborne bacteria, carbon dioxide, and other gases. Ventilation removes unpleasant smells and excessive moisture, introduces outside air, keeps interior building air circulating, and prevents stagnation of the interior air.\n\nVentilation includes both the exchange of air to the outside as well as circulation of air within the building. It is one of the most important factors for maintaining acceptable indoor air quality in buildings. Methods for ventilating a building may be divided into \"mechanical/forced\" and \"natural\" types.\n\nThe three major functions of heating, ventilation, and air conditioning are interrelated, especially with the need to provide thermal comfort and acceptable indoor air quality within reasonable installation, operation, and maintenance costs. HVAC systems can be used in both domestic and commercial environments. HVAC systems can provide ventilation, and maintain pressure relationships between spaces. The means of air delivery and removal from spaces is known as room air distribution.\n\nIn modern buildings, the design, installation, and control systems of these functions are integrated into one or more HVAC systems. For very small buildings, contractors normally estimate the capacity and type of system needed and then design the system, selecting the appropriate refrigerant and various components needed. For larger buildings, building service designers, mechanical engineers, or building services engineers analyze, design, and specify the HVAC systems. Specialty mechanical contractors then fabricate and commission the systems. Building permits and code-compliance inspections of the installations are normally required for all sizes of building.\n\nAlthough HVAC is executed in individual buildings or other enclosed spaces (like NORAD's underground headquarters), the equipment involved is in some cases an extension of a larger district heating (DH) or district cooling (DC) network, or a combined DHC network. In such cases, the operating and maintenance aspects are simplified and metering becomes necessary to bill for the energy that is consumed, and in some cases energy that is returned to the larger system. For example, at a given time one building may be utilizing chilled water for air conditioning and the warm water it returns may be used in another building for heating, or for the overall heating-portion of the DHC network (likely with energy added to boost the temperature).\n\nBasing HVAC on a larger network helps provide an economy of scale that is often not possible for individual buildings, for utilizing renewable energy sources such as solar heat, winter's cold, the cooling potential in some places of lakes or seawater for free cooling, and the enabling function of seasonal thermal energy storage.\n\nHVAC is based on inventions and discoveries made by Nikolay Lvov, Michael Faraday, Willis Carrier, Edwin Ruud, Reuben Trane, James Joule, William Rankine, Sadi Carnot, and many others.\n\nMultiple inventions within this time frame preceded the beginnings of first comfort air conditioning system, which was designed in 1902 by Alfred Wolff (Cooper, 2003) for the New York Stock Exchange, while Willis Carrier equipped the Sacketts-Wilhems Printing Company with the process AC unit the same year. Coyne College was the first school to offer HVAC training in 1899.\n\nThe invention of the components of HVAC systems went hand-in-hand with the industrial revolution, and new methods of modernization, higher efficiency, and system control are constantly being introduced by companies and inventors worldwide.\n\nHeaters are appliances whose purpose is to generate heat (i.e. warmth) for the building. This can be done via central heating. Such a system contains a boiler, furnace, or heat pump to heat water, steam, or air in a central location such as a furnace room in a home, or a mechanical room in a large building. The heat can be transferred by convection, conduction, or radiation.\n\nHeaters exist for various types of fuel, including solid fuels, liquids, and gases. Another type of heat source is electricity, normally heating ribbons composed of high resistance wire (see Nichrome). This principle is also used for baseboard heaters and portable heaters. Electrical heaters are often used as backup or supplemental heat for heat pump systems.\n\nThe heat pump gained popularity in the 1950s in Japan and the United States. Heat pumps can extract heat from various sources, such as environmental air, exhaust air from a building, or from the ground. Initially, heat pump HVAC systems were only used in moderate climates, but with improvements in low temperature operation and reduced loads due to more efficient homes, they are increasing in popularity in cooler climates.\n\nIn the case of heated water or steam, piping is used to transport the heat to the rooms. Most modern hot water boiler heating systems have a circulator, which is a pump, to move hot water through the distribution system (as opposed to older gravity-fed systems). The heat can be transferred to the surrounding air using radiators, hot water coils (hydro-air), or other heat exchangers. The radiators may be mounted on walls or installed within the floor to produce floor heat.\n\nThe use of water as the heat transfer medium is known as hydronics. The heated water can also supply an auxiliary heat exchanger to supply hot water for bathing and washing.\n\nWarm air systems distribute heated air through duct work systems of supply and return air through metal or fiberglass ducts. Many systems use the same ducts to distribute air cooled by an evaporator coil for air conditioning. The air supply is normally filtered through air cleaners to remove dust and pollen particles.\n\nThe use of furnaces, space heaters, and boilers as a method of indoor heating could result in incomplete combustion and the emission of carbon monoxide, nitrogen oxides, formaldehyde, volatile organic compounds, and other combustion byproducts. Incomplete combustion occurs when there is insufficient oxygen; the inputs are fuels containing various contaminants and the outputs are harmful byproducts, most dangerously carbon monoxide, which is a tasteless and odorless gas with serious adverse health effects.\n\nWithout proper ventilation, carbon monoxide can be lethal at concentrations of 1000 ppm (0.1%). However, at several hundred ppm, carbon monoxide exposure induces headaches, fatigue, nausea, and vomiting. Carbon monoxide binds with hemoglobin in the blood, forming carboxyhemoglobin, reducing the blood's ability to transport oxygen. The primary health concerns associated with carbon monoxide exposure are its cardiovascular and neurobehavioral effects. Carbon monoxide can cause atherosclerosis (the hardening of arteries) and can also trigger heart attacks. Neurologically, carbon monoxide exposure reduces hand to eye coordination, vigilance, and continuous performance. It can also affect time discrimination.\n\nVentilation is the process of changing or replacing air in any space to control temperature or remove any combination of moisture, odors, smoke, heat, dust, airborne bacteria, or carbon dioxide, and to replenish oxygen. Ventilation includes both the exchange of air with the outside as well as circulation of air within the building. It is one of the most important factors for maintaining acceptable indoor air quality in buildings. Methods for ventilating a building may be divided into \"mechanical/forced\" and \"natural\" types.\n\nMechanical, or forced, ventilation is provided by an air handler (AHU) and used to control indoor air quality. Excess humidity, odors, and contaminants can often be controlled via dilution or replacement with outside air. However, in humid climates more energy is required to remove excess moisture from ventilation air.\n\nKitchens and bathrooms typically have mechanical exhausts to control odors and sometimes humidity. Factors in the design of such systems include the flow rate (which is a function of the fan speed and exhaust vent size) and noise level. Direct drive fans are available for many applications, and can reduce maintenance needs.\n\nCeiling fans and table/floor fans circulate air within a room for the purpose of reducing the perceived temperature by increasing evaporation of perspiration on the skin of the occupants. Because hot air rises, ceiling fans may be used to keep a room warmer in the winter by circulating the warm stratified air from the ceiling to the floor.\n\nNatural ventilation is the ventilation of a building with outside air without using fans or other mechanical systems. It can be via operable windows, louvers, or trickle vents when spaces are small and the architecture permits. In more complex schemes, warm air is allowed to rise and flow out high building openings to the outside (stack effect), causing cool outside air to be drawn into low building openings. Natural ventilation schemes can use very little energy, but care must be taken to ensure comfort. In warm or humid climates, maintaining thermal comfort solely via natural ventilation might not be possible. Air conditioning systems are used, either as backups or supplements. Air-side economizers also use outside air to condition spaces, but do so using fans, ducts, dampers, and control systems to introduce and distribute cool outdoor air when appropriate.\n\nAn important component of natural ventilation is air change rate or air changes per hour: the hourly rate of ventilation divided by the volume of the space. For example, six air changes per hour means an amount of new air, equal to the volume of the space, is added every ten minutes. For human comfort, a minimum of four air changes per hour is typical, though warehouses might have only two. Too high of an air change rate may be uncomfortable, akin to a wind tunnel which have thousands of changes per hour. The highest air change rates are for crowded spaces, bars, night clubs, commercial kitchens at around 30 to 50 air changes per hour.\n\nRoom pressure can be either positive or negative with respect to outside the room. Positive pressure occurs when there is more air being supplied than exhausted, and is common to reduce the infiltration of outside contaminants.\n\nNatural ventilation is a key factor in reducing the spread of airborne illnesses such as tuberculosis, the common cold, influenza and meningitis. Opening doors, windows, and using ceiling fans are all ways to maximize natural ventilation and reduce the risk of airborne contagion. Natural ventilation requires little maintenance and is inexpensive.\n\nAn air conditioning system, or a standalone air conditioner, provides cooling and humidity control for all or part of a building. Air conditioned buildings often have sealed windows, because open windows would work against the system intended to maintain constant indoor air conditions. Outside, fresh air is generally drawn into the system by a vent into the indoor heat exchanger section, creating positive air pressure. The percentage of return air made up of fresh air can usually be manipulated by adjusting the opening of this vent. Typical fresh air intake is about 10%.\n\nAir conditioning and refrigeration are provided through the removal of heat. Heat can be removed through radiation, convection, or conduction. Refrigeration conduction media such as water, air, ice, and chemicals are referred to as refrigerants. A refrigerant is employed either in a heat pump system in which a compressor is used to drive thermodynamic refrigeration cycle, or in a free cooling system which uses pumps to circulate a cool refrigerant (typically water or a glycol mix).\n\nThe refrigeration cycle uses four essential elements to cool.\n\nIn variable climates, the system may include a reversing valve that switches from heating in winter to cooling in summer. By reversing the flow of refrigerant, the heat pump refrigeration cycle is changed from cooling to heating or vice versa. This allows a facility to be heated and cooled by a single piece of equipment by the same means, and with the same hardware.\n\nFree cooling systems can have very high efficiencies, and are sometimes combined with seasonal thermal energy storage so that the cold of winter can be used for summer air conditioning. Common storage mediums are deep aquifers or a natural underground rock mass accessed via a cluster of small-diameter, heat-exchanger-equipped boreholes. Some systems with small storages are hybrids, using free cooling early in the cooling season, and later employing a heat pump to chill the circulation coming from the storage. The heat pump is added-in because the storage acts as a heat sink when the system is in cooling (as opposed to charging) mode, causing the temperature to gradually increase during the cooling season.\n\nSome systems include an \"economizer mode\", which is sometimes called a \"free-cooling mode\". When economizing, the control system will open (fully or partially) the outside air damper and close (fully or partially) the return air damper. This will cause fresh, outside air to be supplied to the system. When the outside air is cooler than the demanded cool air, this will allow the demand to be met without using the mechanical supply of cooling (typically chilled water or a direct expansion \"DX\" unit), thus saving energy. The control system can compare the temperature of the outside air vs. return air, or it can compare the enthalpy of the air, as is frequently done in climates where humidity is more of an issue. In both cases, the outside air must be less energetic than the return air for the system to enter the economizer mode.\n\nCentral, \"all-air\" air-conditioning systems (or package systems) with a combined outdoor condenser/evaporator unit are often installed in North American residences, offices, and public buildings, but are difficult to retrofit (install in a building that was not designed to receive it) because of the bulky air ducts required. (Minisplit ductless systems are used in these situations.) Outside of North America, packaged systems are only used in limited applications involving large indoor space such as stadiums, theatres or exhibition halls.\n\nAn alternative to packaged systems is the use of separate indoor and outdoor coils in split systems. Split systems are preferred and widely used worldwide except in the North America. In the North America, split systems are most often seen in residential applications, but they are gaining popularity in small commercial buildings.\n\nWith the split system, the evaporator coil is connected to a remote condenser unit using refrigerant piping between an indoor and outdoor unit instead of ducting air directly from the outdoor unit. Indoor units with directional vents mount onto walls, suspended from ceilings, or fit into the ceiling. Other indoor units mount inside the ceiling cavity, so that short lengths of duct handle air from the indoor unit to vents or diffusers around the rooms.\n\nSplit systems are more efficient and the footprint is typically smaller than the package systems. On the other hand, package systems tend to have slightly lower indoor noise level compared to split system since the fan motor is located outside.\n\nDehumidification (air drying) in an air conditioning system is provided by the evaporator. Since the evaporator operates at a temperature below the dew point, moisture in the air condenses on the evaporator coil tubes. This moisture is collected at the bottom of the evaporator in a pan and removed by piping to a central drain or onto the ground outside.\n\nA dehumidifier is an air-conditioner-like device that controls the humidity of a room or building. It is often employed in basements which have a higher relative humidity because of their lower temperature (and propensity for damp floors and walls). In food retailing establishments, large open chiller cabinets are highly effective at dehumidifying the internal air. Conversely, a humidifier increases the humidity of a building.\n\nAll modern air conditioning systems, even small window package units, are equipped with internal air filters. These are generally of a lightweight gauzy material, and must be replaced or washed as conditions warrant. For example, a building in a high dust environment, or a home with furry pets, will need to have the filters changed more often than buildings without these dirt loads. Failure to replace these filters as needed will contribute to a lower heat exchange rate, resulting in wasted energy, shortened equipment life, and higher energy bills; low air flow can result in iced-over evaporator coils, which can completely stop air flow. Additionally, very dirty or plugged filters can cause overheating during a heating cycle, and can result in damage to the system or even fire.\n\nBecause an air conditioner moves heat between the indoor coil and the outdoor coil, both must be kept clean. This means that, in addition to replacing the air filter at the evaporator coil, it is also necessary to regularly clean the condenser coil. Failure to keep the condenser clean will eventually result in harm to the compressor, because the condenser coil is responsible for discharging both the indoor heat (as picked up by the evaporator) and the heat generated by the electric motor driving the compressor.\n\nSince the 1980s, manufacturers of HVAC equipment have been making an effort to make the systems they manufacture more efficient. This was originally driven by rising energy costs, and has more recently been driven by increased awareness of environmental issues. Additionally, improvements to the HVAC system efficiency can also help increase occupant health and productivity. In the US, the EPA has imposed tighter restrictions over the years. There are several methods for making HVAC systems more efficient.\n\nIn the past, water heating was more efficient for heating buildings and was the standard in the United States. Today, forced air systems can double for air conditioning and are more popular.\n\nSome benefits of forced air systems, which are now widely used in churches, schools and high-end residences, are\nA drawback is the installation cost, which can be slightly higher than traditional HVAC systems.\n\nEnergy efficiency can be improved even more in central heating systems by introducing zoned heating. This allows a more granular application of heat, similar to non-central heating systems. Zones are controlled by multiple thermostats. In water heating systems the thermostats control zone valves, and in forced air systems they control zone dampers inside the vents which selectively block the flow of air. In this case, the control system is very critical to maintaining a proper temperature.\n\nForecasting is another method of controlling building heating by calculating demand for heating energy that should be supplied to the building in each time unit.\n\nGround source, or geothermal, heat pumps are similar to ordinary heat pumps, but instead of transferring heat to or from outside air, they rely on the stable, even temperature of the earth to provide heating and air conditioning. Many regions experience seasonal temperature extremes, which would require large-capacity heating and cooling equipment to heat or cool buildings. For example, a conventional heat pump system used to heat a building in Montana's low temperature or cool a building in the highest temperature ever recorded in the US— in Death Valley, California, in 1913 would require a large amount of energy due to the extreme difference between inside and outside air temperatures. A few feet below the earth's surface, however, the ground remains at a relatively constant temperature. Utilizing this large source of relatively moderate temperature earth, a heating or cooling system's capacity can often be significantly reduced. Although ground temperatures vary according to latitude, at underground, temperatures generally only range from .\n\nAn example of a geothermal heat pump that uses a body of water as the heat sink, is the system used by the Trump International Hotel and Tower in Chicago, Illinois. This building is situated on the Chicago River, and uses cold river water by pumping it into a recirculating cooling system, where heat exchangers transfer heat from the building into the water, and then the now-warmed water is pumped back into the Chicago River.\n\nWhile they may be more costly to install than regular heat pumps, geothermal heat pumps can produce markedly lower energy bills – 30 to 40 percent lower, according to estimates from the US Environmental Protection Agency.\n\nGeothermal heat pumps still provide higher efficiency than air source heat pumps. Some models provide 70% saving compared to electric resistance heaters.\n\nEnergy recovery systems sometimes utilize heat recovery ventilation or energy recovery ventilation systems that employ heat exchangers or enthalpy wheels to recover sensible or latent heat from exhausted air. This is done by transfer of energy to the incoming outside fresh air.\n\nThe performance of vapor compression refrigeration cycles is limited by thermodynamics. These air conditioning and heat pump devices \"move\" heat rather than convert it from one form to another, so \"thermal efficiencies\" do not appropriately describe the performance of these devices. The Coefficient-of-Performance (COP) measures performance, but this dimensionless measure has not been adopted. Instead, the Energy Efficiency Ratio (\"EER\") has traditionally been used to characterize the performance of many HVAC systems. EER is the Energy Efficiency Ratio based on a outdoor temperature. To more accurately describe the performance of air conditioning equipment over a typical cooling season a modified version of the EER, the Seasonal Energy Efficiency Ratio (\"SEER\"), or in Europe the ESEER, is used. SEER ratings are based on seasonal temperature averages instead of a constant outdoor temperature. The current industry minimum SEER rating is 14 SEER.\n\nEngineers have pointed out some areas where efficiency of the existing hardware could be improved. For example, the fan blades used to move the air are usually stamped from sheet metal, an economical method of manufacture, but as a result they are not aerodynamically efficient. A well-designed blade could reduce electrical power required to move the air by a third.\n\nAir cleaning and filtration removes particles, contaminants, vapors and gases from the air. The filtered and cleaned air then is used in heating, ventilation and air conditioning. Air cleaning and filtration should be taken in account when protecting our building environments.\n\nClean air delivery rate is the amount of clean air an air cleaner provides to a room or space. When determining CADR, the amount of airflow in a space is taken into account. For example, an air cleaner with a flow rate of 100 cfm (cubic feet per minute) and an efficiency of 50% has a CADR of 50 cfm. Along with CADR, filtration performance is very important when it comes to the air in our indoor environment. Filter performance depends on the size of the particle or fiber, the filter packing density and depth and also the air flow rate.\n\nThe HVAC industry is a worldwide enterprise, with roles including operation and maintenance, system design and construction, equipment manufacturing and sales, and in education and research. The HVAC industry was historically regulated by the manufacturers of HVAC equipment, but regulating and standards organizations such as HARDI, ASHRAE, SMACNA, ACCA, Uniform Mechanical Code, International Mechanical Code, and AMCA have been established to support the industry and encourage high standards and achievement.\n\nThe starting point in carrying out an estimate both for cooling and heating depends on the exterior climate and interior specified conditions. However, before taking up the heat load calculation, it is necessary to find fresh air requirements for each area in detail, as pressurization is an important consideration.\n\nISO 16813:2006 is one of the ISO building environment standards. It establishes the general principles of building environment design. It takes into account the need to provide a healthy indoor environment for the occupants as well as the need to protect the environment for future generations and promote collaboration among the various parties involved in building environmental design for sustainability. ISO16813 is applicable to new construction and the retrofit of existing buildings.\n\nThe building environmental design standard aims to:\n\n\nIn the United States, HVAC engineers generally are members of the American Society of Heating, Refrigerating, and Air-Conditioning Engineers (ASHRAE), EPA Universal CFC certified (for installation and service of CFC HVAC devices), or locally engineer certified such as a Special to Chief Boilers License issued by the state or, in some jurisdictions, the city. ASHRAE is an international technical society for all individuals and organizations interested in HVAC. The Society, organized into regions, chapters, and student branches, allows exchange of HVAC knowledge and experiences for the benefit of the field's practitioners and the public. ASHRAE provides many opportunities to participate in the development of new knowledge via, for example, research and its many technical committees. These committees typically meet twice per year at the ASHRAE Annual and Winter Meetings. A popular product show, the AHR Expo, is held in conjunction with each winter meeting. The Society has approximately 50,000 members and has headquarters in Atlanta, Georgia.\n\nThe most recognized standards for HVAC design are based on ASHRAE data. The most general of four volumes of the ASHRAE Handbook is Fundamentals; it includes heating and cooling calculations. Each volume of the ASHRAE Handbook is updated every four years. The design professional must consult ASHRAE data for the standards of design and care as the typical building codes provide little to no information on HVAC design practices; codes such as the UMC and IMC do include much detail on installation requirements, however. Other useful reference materials include items from SMACNA, ACGIH, and technical trade journals.\n\nAmerican design standards are legislated in the Uniform Mechanical Code or International Mechanical Code. In certain states, counties, or cities, either of these codes may be adopted and amended via various legislative processes. These codes are updated and published by the International Association of Plumbing and Mechanical Officials (IAPMO) or the International Code Council (ICC) respectively, on a 3-year code development cycle. Typically, local building permit departments are charged with enforcement of these standards on private and certain public properties.\n\nHVAC professionals in the US can receive training through formal training institutions, where most earn associate degrees. Training for HVAC technicians includes classroom lectures and hands-on tasks, and can be followed by an apprenticeship wherein the recent graduate works alongside a professional HVAC technician for a temporary period. HVAC techs who have been trained can also be certified in areas such as air conditioning, heat pumps, gas heating, and commercial refrigeration.\n\nThe Chartered Institution of Building Services Engineers is a body that covers the essential Service (systems architecture) that allow buildings to operate. It includes the electrotechnical, heating, ventilating, air conditioning, refrigeration and plumbing industries. To train as a building services engineer, the academic requirements are GCSEs (A-C) / Standard Grades (1-3) in Maths and Science, which are important in measurements, planning and theory. Employers will often want a degree in a branch of engineering, such as building environment engineering, electrical engineering or mechanical engineering. To become a full member of CIBSE, and so also to be registered by the Engineering Council UK as a chartered engineer, engineers must also attain an Honours Degree and a master's degree in a relevant engineering subject.\n\nCIBSE publishes several guides to HVAC design relevant to the UK market, and also the Republic of Ireland, Australia, New Zealand and Hong Kong. These guides include various recommended design criteria and standards, some of which are cited within the UK building regulations, and therefore form a legislative requirement for major building services works. The main guides are:\n\nWithin the construction sector, it is the job of the building services engineer to design and oversee the installation and maintenance of the essential services such as gas, electricity, water, heating and lighting, as well as many others. These all help to make buildings comfortable and healthy places to live and work in. Building Services is part of a sector that has over 51,000 businesses and employs represents 2%-3% of the GDP.\n\nThe Air Conditioning and Mechanical Contractors Association of Australia (AMCA), Australian Institute of Refrigeration, Air Conditioning and Heating (AIRAH), Australian Refrigeration Mechanical Association and CIBSE are responsible.\n\nAsian architectural temperature-control have different priorities than European methods. For example, Asian heating traditionally focuses on maintaining temperatures of objects such as the floor or furnishings such as Kotatsu tables and directly warming people, as opposed to the Western focus, in modern periods, on designing air systems.\n\nThe Philippine Society of Ventilating, Air Conditioning and Refrigerating Engineers (PSVARE) along with Philippine Society of Mechanical Engineers (PSME) govern on the codes and standards for HVAC / MVAC (MVAC means \"mechanical ventilation and air conditioning\") in the Philippines.\n\nThe Indian Society of Heating, Refrigerating and Air Conditioning Engineers (ISHRAE) was established to promote the HVAC industry in India. ISHRAE is an associate of ASHRAE. ISHRAE was started at Delhi in 1981 and a chapter was started in Bangalore in 1989. Between 1989 & 1993, ISHRAE chapters were formed in all major cities in India.\n\n"}
{"id": "20178252", "url": "https://en.wikipedia.org/wiki?curid=20178252", "title": "Hydrogenography", "text": "Hydrogenography\n\nHydrogenography is a combinatorial method based on the observation of optical changes on the metal surface by hydrogen absorption. The method allows the examination of thousands of combinations of alloy samples in a single batch.\n\nIn the 1996 report of the method, thin films were coated with yttrium and lanthanum topped with a layer of palladium for the diffusion of hydrogen. The rate of absorption of hydrogen resulted in typical optical properties. In the 2008 report magnesium, titanium and nickel are eroded and sputtering deposited in different ratios onto a transparent film in a thin layer of 100 nanometres following exposure to hydrogen in different amounts resulting in optical differences,\n\n\n"}
{"id": "9472254", "url": "https://en.wikipedia.org/wiki?curid=9472254", "title": "Institute of Software Engineers", "text": "Institute of Software Engineers\n\nThe Institute of Software Engineers (ISE) is a member-funded professional organization of individuals with certified software engineering skills for the advancement of the practice of software engineering. It was incorporated in 2006.\n\nISE has student chapters at accredited higher education institutions and also professional chapters. ISE recommends and establishes standards for practicing software engineers and engineering managers. ISE pursues research in sub-areas of software engineering activities with the goal of creating actionable guidance and recommendations for practitioners. All ISE members have at least successfully completed a bachelor's degree in the engineering discipline or are actively pursuing such a degree.\n\n\n"}
{"id": "54231803", "url": "https://en.wikipedia.org/wiki?curid=54231803", "title": "Janet Iwasa", "text": "Janet Iwasa\n\nJanet Iwasa is a data visualization expert and assistant professor of biochemistry at the University of Utah, renowned for her contributions to molecular and cellular visualizations.\n\nJanet Iwasa was born in 1978 in Bloomington, Indiana. When her father joined the National Institutes of Health, her family moved to Maryland. Iwasa was the youngest child in the family, and she grew up determined to be different from her two older brothers. Her father's career in physics inspired her to become a scientist herself. In high school, she participated in a summer internship at the Institute for Genomic Research.\n\nIn 1999, she graduated \"magna cum laude\" from Williams college with bachelor's degrees in Biology and Asian Studies. In her junior year at Williams, she joined Professor Robert Savage's lab, studying the formation of segmented patterns in leeches on a cellular level. In 2006, she received her PhD in cell biology from the University of California, San Francisco for her research on the actin cytoskeleton.\n\nIwasa became invested in microscopy during her first year at UCSF. In Dyche Mullins' lab, she studied actin networks in motile cells. During lab meetings with Ron Vale's group, she gained knowledge about kinesin structure and function. When she viewed a kinesin animation by Graham Johnson, she was inspired to pursue 3D animation. With Dyche's approval, Iwasa began taking animation classes at San Francisco State University. After graduation, she studied animation at the Gnomon School for Visual Effects in Hollywood, California. She was the oldest student in her Gnomon animation course, as well as the only woman. She applied her skills in animation to biology, bringing cellular functions and interactions to life.\n\nIn 2006, Iwasa began working as a postdoctoral fellow under Jack Szostak with Harvard University and the Massachusetts General Hospital. In 2007, Iwasa gained teaching experience at Harvard Medical School with a course named \"Visualizing Molecular Processes with Maya.\" In this course, she worked as a teaching assistant, writing tutorials and supervising projects. She also worked with another software platform at Harvard called Massive, adapting a program designed for video game animation to depict the process of nucleation elongation.\n\nIn 2008, Iwasa created and presented a multimedia exhibit for the Boston Museum of Science titled \"Exploring Life's Origins\".\n\nIn 2008, she became a lecturer in Molecular Visualization for the Department of Cell Biology at Harvard Medical School. Her position at Harvard was modeled around her own research interests and her contributions to the scientists at the university. Her work with Joan Brugge and Michael Overholtzer furthered understanding of a newly discovered cellular process called endosis. Endosis involves the invasion of one cell into another, where the intruder proliferates inside the host cell until it is digested by the host or forcibly pushes its way back out. Iwasa's questions and requirements for the model forced researchers to investigate the endosis mechanism in greater detail to accurately engineer an animation of this process.\n\nWhile working with Tomas Kirchausen, she created an animation on clathrin-mediated endocytosis, researching how clathrin triskelions operated and assembled on the inner surface of the plasma membrane to invaginate an extracellular particle.\n\nIn 2010, Iwasa organized and taught a course on visualizing molecular and cellular processes with 3D animation in Porto, Portugal. In 2013, she joined the University of Utah School of Medicine as a research assistant professor for the Department of Cell Biology. She returned to Portugal in 2014 to teach a 3D animation workshop for scientific animation. In 2014, she also completed a project called Molecular Flipbook, a free, open-source software program designed to animate molecules. In 2016, Iwasa released a life-cycle animation on HIV. Her project used animation to illustrate the molecular mechanisms the virus utilizes to enter into and exit target cells.\n\nIn addition to her university work, Iwasa's renowned molecular and cellular visualizations have been featured in numerous scientific journals including \"Nature\", \"Science\", and \"Cell\", as well as the \"New York Times\".\n\nIwasa's knowledge of cellular animation has also led her to publish several different works of scientific literature. Her work with Robert Savage's Lab led to her first publication in 2000 in \"Development Genes and Evolution\", \"The leech hunchback protein is expressed in the epithelium and CNS but not in the segmental precursor lineages\", with co-authors Suver and Savage. Iwasa's work with Savage focused on identifying regulatory genes engaged in the formation of segment patterns in annelids, investigating a gene in leeches called Leech Zinc Finger II (LZF2), considered to be an orthologue of the \"hunchback (hb)\" gene in \"Drosophila\". Iwasa, Savage, and Suver concluded that LZF2 likely plays an important part in the morphological progressions of gastrulation and the specification of the central nervous system in leeches but does not contribute to the formation of anteroposterior patterns.\n\nIn 2007, she published an article on her research at the University of California with Mullins, \"Spatial and temporal relationships between actin-filament nucleation, capping, and disassembly.\" Her study with Mullins focused on the lamellipodial network. They concluded that the lamellipodial network incorporates the Arp 2/3 complex and capping proteins during initial assembly, but dismisses these complexes long before the lamellipodial network is actually disassembled. They also reported that the network does not use cofilin, twinfilin, and tropomyosin in assembly. Instead these factors play a role in the network's size.\n\nIn 2010, Iwasa published \"Animating the model figure\" in \"Trends Cell Biol.\" In this article, she points out the importance of animations in revealing and teaching scientific concepts, explaining that students are shown to retain more information and show more interest in the material when animations are incorporated into the curriculum. She also pushed the invention of ananimation software engineered exclusively for the scientific research community.\n\nIn 2015, she released her textbook, \"Karp's Cell and Molecular Biology: Concepts and Experiments\", with co-authors Gerald Karp and Wallace Marshal.\n\nIn 2016, Iwasa published \"The Scientist as Illustrator\" in \"Trends Immunol.\" In this article, she elaborates on the roles of animation in science. She explains that animations help people to understand and process new ideas, communicate their theories and findings to their colleagues, and present information to the public in an engaging manner. She also explains that it is important for biologists to learn how to communicate visually so they can avoid borrowing old models to convey new concepts and ideas.\n\nFrom 1999 to 2004, Iwasa was honored as a member of the NSF Graduate Fellowship. From 2006 to 2008, she was a member of the NSF Discpery Corps Postgraduate Fellowship. In 2008, she earned an honorable mention for her entry in the AAAS International Science & Engineering Visualization Challenge. In 2012, she was listed as one of \"Fast Company\"s \"100 Most Creative People.\" In 2014, she was recognized as a TED Fellow, a FASEB BioArt Winner, and one of \"Foreign Policy Magazine\"s \"100 Leading Global Thinkers.\" In 2016, the University of Utah credited Iwasa as an Entrepreneurial Faculty Scholar. In 2017, she was honored as a TED Senior Fellow.\n\n"}
{"id": "18937712", "url": "https://en.wikipedia.org/wiki?curid=18937712", "title": "John Safer", "text": "John Safer\n\nJohn Safer (born September 6, 1922) is an American sculptor. Safer's varied career spans work in theater lighting, television, real estate, politics and banking.\n\nSafer is best known for his monumental sculptures, but he has also created many smaller works. These include award sculptures for organizations such as the National Air and Space Museum, the PGA Tour, the Georgetown University Lombardi Cancer Center, the World Peace Foundation, and the Shakespeare Guild.\n\nSafer's works stand in museums, galleries and embassies throughout the world. In 1972 and in 1989 the U.S. Department of State sent a group of Safer sculptures abroad to be exhibited as examples of America's finest art.\n\nSafer's earliest sculptures in the 1950s and 1960s were small works of Lucite. Over time he also began to work in bronze and stainless steel. The pieces became larger and in 1979 his first public commission, \"Judgment\", a multi-ton patinated bronze, was installed at Harvard Law School in Cambridge,Massachusetts.\n\nThis was the first in a long string of public installations.\n\nAs the commissions grew in number they grew in size as well. \"Interplay\", created in 1987, is high. \"Leading Edge\", created in 1989, is high. His hallmark work, \"Ascent\", which stands at the entrance of the Smithsonian Institution's Udvar-Hazy Center at Dulles Airport in Virginia, is high.\n\n\"Through his work, John has tried to capture the essence ... and reduce the subject to the pure line in space that Aristotle believed to be the basis of sculpture.\"\n\nJohn Safer was born and raised in Washington, D.C., the only child of John and Rebecca Safer. His father, who operated a moving and storage business, was a lawyer who graduated from Georgetown University Law School at the head of his class. His mother Rebecca was a social activist, suffragette and intellectual. John learned to read and write by the age of four. At this time his mother entered him into first grade at the Maret French School.\n\nSafer continued as a precocious student. Fluent in French, he entered high school at the age of eleven and graduated when he was fourteen. He was pressured by his mother to enroll at Harvard University. Safer, uncomfortable at the thought of being a fourteen-year-old college student, deliberately failed the Harvard entrance exam by handing in blank pages. \n\nSafer instead attended Woodward Prep School. There he discovered his love for and ability in athletics. This theme would greatly influence his art and his life. Until then, his age and size had prevented him from participating in sports and left him with the sense that he was a misfit.\n\nAt the age of sixteen, Safer entered George Washington University where he majored in economics. He became an assistant to Professor Edward Acheson –– brother of the United States Secretary of State Dean Acheson –– who became a mentor. At the beginning of World War II, Safer enlisted in the United States Air Force to become a flying cadet.\n\nSafer became a first lieutenant and served in India, Burma and China. When the war ended in 1945 he opted for an additional year in the Air Force hoping to fulfill a dream of seeing Europe's great works of art while he was stationed there. His new assignment allowed him to visit the Parthenon, the Tate, and the Louvre. While in Rome, he learned that he was suddenly to be transferred to Athens. Unwilling to leave Italy without visiting the Accademia in Florence, Safer \"borrowed\" a jeep to make the drive to see Michelangelo's \"David\". The Accademia was closed but he convinced the caretaker to let him in. The two hours Safer spent alone with the masterpiece resulted in a seminal experience, but it was Michelangelo's other sculptures in the Gallery, \"The Prisoners\", which gave Safer an insight that was to impact his entire life and transform his artistic career.\n\n\"The Prisoners\" are heroic figures rising from rough hewn stone. The upper portion of the figures are finished while the lower part remains uncarved. As Safer studied \"The Prisoners\" he realized the power of the abstract –– a realization that gave direction to his future work.\n\nAfter Safer graduated from Harvard Law School in 1949 his fascination with the emerging technology and promise of television prompted him to take a job as a handyman at WXEL in Cleveland, Ohio. He quickly rose to the position of program director. During this time his innovations led the new independent station to \"beat the ratings of all the network affiliates.\"\n\nIn 1953 Safer's father became terminally ill and he returned to Washington, D.C. to take over his father's affairs. Although Safer successfully parlayed these into a major real estate development business he did not find his commercial life a rewarding one.\n\nIn 1974 Safer entered the world of banking, becoming Chairman of the Executive Committee of Financial General Bankshares, and in 1981 the Chairman of the Board of DC National Bank which later became part of Bank of America.\n\nIn 1999 Safer became Chairman of the Board of Materia, Inc. Materia specializes in Olefin metathesis, and is noted for its Nobel Prize–winning Green chemistry.\n\nSafer never formally studied art. His first forays into sculpture were experiments with plastic swizzle sticks. In 1957 he made his first creations, and he continued to experiment, eventually beginning to carve Lucite. In 1969 Safer had his first show in Pittsburgh, Pennsylvania at the Michael Berger Gallery. Several shows in private galleries followed with a major exhibition at the Pyramid Gallery in Washington, D.C.\n\nIn 1971 the renowned art collector and U.S. Ambassador to Great Britain, Walter Annenberg, invited Safer to have an exhibition at the American Embassy in London.\n\nIn 1972 President Gerald Ford presented Safer's \"Limits of Infinity\" to King Juan Carlos of Spain as a gift of state. This in turn led to several major events in Safer's sculptural career. As a result of a news report of President Ford's gift, the Dean of Harvard Law School sought to acquire a Safer sculpture for the school. This culminated in 1979 with the installation of \"Judgment\", a monumental bronze work which was presented to Harvard Law School as a gift of Safer's class of 1949. This was Safer's first monumental public work.\n\nJohn McArthur, the Dean of Harvard Business School visited the palace at Zarzuela where King Juan Carlos had installed \"Limits of Infinity\". Moved by the sculpture, Dean McArthur returned to America and commissioned Safer's \"Search\" for Harvard Business School. The patinated bronze was installed on the Business School grounds in 1984 adjacent to the spot where Safer's daughter, Janine, received her MBA five days later.\n\nIn 1985 Safer was invited to exhibit sculpture in the Pioneers of Flight Hall at the Smithsonian Institution's National Air and Space Museum, in Washington, D.C. He has the distinction of being the only artist to have ever had an exhibition in the central gallery of the most visited museum in the\nworld.\n\nIn 1989 the U.S. Department of State again sent Safer sculptures to Europe. As of 2008, the Department has exhibited Safer sculpture in London, Paris, Beijing, Dublin, Bern, Lisbon, Brussels, Bucharest, Belgrade, Nassau, Washington, and New Deli. Both public and private exhibitions of Safer sculpture can be seen in venues throughout the world.\n\nSafer continues to create sculpture. He works with his stepdaughter Kathryn Scott, to whom he taught his trade and offered his mantle. In 2007, they began work on a monumental sculpture, Quest, for the Johns Hopkins Wilmer Eye Institute. The stainless steel fabricated sculpture and state of the art research center, the Robert H. and Clarice Smith Building, was dedicated two years later, on October 16, 2009, 80 years to the day after the pioneering institute's first building made its debut. Safer, a patient, donated the multi-ton sculpture as a gift of appreciation. It is one of the largest gifts of art that Johns Hopkins has received. In December 2011, Scott and Safer began work on a model for a monumental sculpture for the Marine Aviation Memorial.\n\nOver the next ten years the Safer-Scott partners continued to collaborate on private and public projects. The eleven foot-high (3.4 m) mirror finished, \"Interplay\", was commissioned for the LEED wing of the $340M Kimmel Cancer Center expansion at Sibley Memorial Hospital in Washington, DC. In 2014 Scott began negotiations with MGM Resorts International for a centerpiece at MGM National Harbor in Maryland. The 60 foot high (18.3 m) stainless steel sculpture, \"Unity\", weighting eighteen thousand pounds and unprecedented in its scale, was installed two years later on November 12, 2016—one month before the opening of the $1.4B resort.\n\nSafer explains the motivation behind his sculpture:\n\nSafer credits his wife, Joy, with giving him \"a new perspective on the world ... which lifted my sculpture to a level I had not previously attained.\"\n\nSafer's interest in sports has provided the inspiration behind many of his sculptures. \"Dancer and the Dance\", \"Serve\", \"Before the Wind\", and \"Line of Flight\" are works that capture a line of athletic motion.\n\nAs a youngster, Safer was ahead of, and therefore smaller than his classmates in school, so it was later that he discovered his own athletic prowess. Safer has awards in marksmanship, baseball and bowling. Safer, now ninety, still plays competitive golf. In November 2012, Safer and his partner Jack Frazee won the Lyford Cay Shootout. Later that week, Safer and his team won the \"B\" flight in the Lyford Cay Four-Ball Invitational tournament, a tournament they won in 2007, when Safer was 85.\n\nSafer has been awarded two honorary degrees: Doctor of Philosophy from Daniel Webster College and Doctor of Literature from Lees-McRae College. In May 2009, Safer received a third honorary degree– Doctor of Fine Arts from George Washington University. Along with Rahm Emanuel and Jeanne L. Narum, Safer delivered a commencement speech, from the National Mall, to the graduating class of 2009.\n\nSafer explains the motivation behind his career:\n\nThere is one other basic principle that guides my work, my business career, and my life in general, and that is balance. I believe that the Aristotelian golden mean is as good a guiding philosophy for life as you can find. In business, I adhere to it continually, trying to balance the necessity for a successful business always to move forward with the caveat that too much motion can be counterproductive or unnecessarily dangerous. In art, the human spirit is gratified by balance, by a tonic note. And so I try to express a sense of balance and completeness in my work.\n\nDigitized Nov 13, 2007 , \nContributor David Finn Published by Hudson Hills Press, 1992 Original from the University of Michigan\nDigitized Nov 13, 2007 , \nPublished by The Galleries, 1975\n\n"}
{"id": "28568108", "url": "https://en.wikipedia.org/wiki?curid=28568108", "title": "Keyboard computer", "text": "Keyboard computer\n\nA keyboard computer is a computer which contains all of the regular components of a personal computer, except for a screen, in the same housing as the keyboard. The power supply is typically external and connects to the computer via an adapter cable. The motherboard is specially designed to fit inside, and the device is larger than most standard keyboards. Additional peripheral components such as a monitor are connected to the computer via external ports. Usually no or only a minimum of storage devices is built in.\n\nMost home computers of the late 1970s and during the 1980s were keyboard computers, the Commodore VIC-20 and the Atari ST being prime examples. While this form factor went out of style around 1990 in favour for more standard PC setups, some notable x86 keyboard computers have been built, like the Olivetti Prodest PC1 in 1988 and the Schneider EuroPC Series between 1988 and 1995. Cybernet Manufacturing is still producing similar devices, using Intel Quad Core processors.\n\nNewer developments include the Commodore 64 WebIt by Tulip, the Asus Eee Keyboard, which uses an Intel Atom processor, and optionally solid state hard drives. Or designs like the Commodore Invictus PC.\n"}
{"id": "17186", "url": "https://en.wikipedia.org/wiki?curid=17186", "title": "Klerer-May System", "text": "Klerer-May System\n\nThe Klerer-May System is a programming language developed in the mid-1960s, oriented to numerical scientific programming, whose most notable feature is its two-dimensional syntax based on traditional mathematical notation.\n\nFor input and output, the Klerer-May system used a Friden Flexowriter modified to allow half-line motions for subscripts and superscripts. The character set included digits, upper-case letters, subsets of 14 lower-case Latin letters and 18 Greek letters, arithmetic operators (codice_1 codice_2 codice_3 codice_4 codice_5) and punctuation (codice_6 codice_7 codice_8 codice_9), and eight special line-drawing characters (resembling codice_10 codice_11 codice_12 codice_13 codice_14 codice_15 codice_16 codice_17) used to construct multi-line brackets and symbols for summation, products, roots, and for multi-line division or fractions.\nThe system was intended to be forgiving of input mistakes, and easy to learn; its reference manual was only two pages.\n\nThe system was developed by Melvin Klerer and Jack May at Columbia University's Hudson Laboratories in Dobbs Ferry, New York, for the Office of Naval Research, and ran on GE-200 series computers.\n\n"}
{"id": "881048", "url": "https://en.wikipedia.org/wiki?curid=881048", "title": "List of mergers and acquisitions by Symantec", "text": "List of mergers and acquisitions by Symantec\n\nSymantec is an American computer software company founded on March 1, 1982. It is an international corporation that specializes in selling security and information management software, and is listed on the NASDAQ-100 stock market index and Fortune 1000 list of the largest American companies. Gary Hendrix founded the company in 1982 with the help of a National Science Foundation grant. Symantec was originally focused on artificial intelligence-related projects, and Hendrix hired several Stanford University natural language processing researchers as the company's first employees. After the company's initial public offering in 1989, Hendrix left the company in 1991 and moved to Texas. The company has acquired 57 companies, purchased stakes in 2 firms, and divested 26 companies, in which parts of the company are sold to another company. Of the companies that Symantec has acquired, 50 were based in the United States. Symantec has not released the financial details for most of these mergers and acquisitions.\n\nSymantec's first acquisition was C&E Software on January 1, 1984, and the founder of C&E Software, Gordon Eubanks, became the new chief executive officer of Symantec. The company has made three acquisitions with a value greater than $1 billion: VeriSign was acquired on May 19, 2010 for $1.250 billion, Altiris was acquired on April 6, 2007 for $1.038 billion, and Symantec purchased Veritas Software on July 2, 2005 for $13 billion. The deal with Veritas was Symantec's largest acquisition and made Symantec the fifth-largest software company in the world. The company made the most acquisitions in 2004 with six: ON Technology, Brightmail, TurnTide, @stake, LIRIC Associates, and Platform Logic.\n\n"}
{"id": "21558724", "url": "https://en.wikipedia.org/wiki?curid=21558724", "title": "List of military rockets", "text": "List of military rockets\n\nThis is a list of unguided rockets and missiles used for military purposes.\n\n"}
{"id": "53378986", "url": "https://en.wikipedia.org/wiki?curid=53378986", "title": "MIMETAS", "text": "MIMETAS\n\nMimetas is a privately owned biotechnology company developing human organ-on-a-chip tissue models and products for drug development. The company also is involved in the testing of chemicals along with food and personalized medicine applications. The company is based in Leiden and Enschede, The Netherlands and in Rockville (MD), USA. Mimetas was founded in 2011 by Paul Vulto, Jos Joore, Bas Trietsch and Thomas Hankemeier. The company is co-led by Joore and Vulto as Managing Directors.\n\nMimetas develops microfluidic tissue culture technology based on its proprietary OrganoPlate platform that supports 3-dimensional tissue culture under continuous perfusion, with membrane-free co-culture in a standard 384-well plate format. This renders the technology suitable for low- to high-throughput screening applications. Mimetas develops a range of tissue- and disease models, including kidney toxicity and disease models, iPSC-derived neuronal brain tissue models and liver models.\n\nThe original idea for the foundation of Mimetas was raised in 2010 by Vulto and Joore, who envisioned creating the tissue equivalent of a microarray for massive parallel testing of therapeutic compounds. The idea was based on meniscus pinning technology, originally developed by Vulto, during his affiliations with Silicon Biosystems (Bologna, IT), now part of the Menarini Group and the Institute for Microsystems Engineering (IMTEK) of the University of Freiburg (GER). Mimetas was established in close collaboration with the group of Thomas Hankemeier of the Leiden University, with essential contributions of Bas Trietsch who serves as Director of Research. Since its official incorporation in 2013, the company collaborates with a range of pharmaceutical companies on the development of tissue- and disease models, including Roche, BASF, GlaxoSmithKline, Pfizer, Abbvie, Janssen and Biogen.\n"}
{"id": "44367046", "url": "https://en.wikipedia.org/wiki?curid=44367046", "title": "Metal profiles", "text": "Metal profiles\n\nMetal profile sheet systems are used to build efficient, reliable and cost-efficient envelopes of mostly commercial buildings. They have evolved from the single skin metal cladding often associated with agricultural buildings to multi-layer systems for industrial and leisure application. \n\nTrapezoidal profiles and cassettes have been known in Europe for around 100 years. Today's characteristic profile shape came to Europe from the USA in the 50s and has gained relevance since about 1960. At present the proportion of load bearing, room sealing trapezoidal profiles used in the overall area of new and slightly sloping roofs amounts to 90%. Above all else the wide acceptance has resulted from the simple constructive training, fast assembly, and the low costs of the trapezoidal profile construction.\n\nMetal profile sheets are metal structural members that due to the fact they can have different profiles, with different heights and different thickness, engineers and architects can use them for a huge variety of buildings, from a simple industrial building to a high demand design building. \nTrapezoidal profiles are large metal structural members, which, thanks to the profiling and its thickness, retain their high load bearing capability. They have been developed from the corrugated profile. The profile programme offered by specific manufacturers covers a total of approx. 60 profile shapes with different heights.\nCassettes are components that are mainly used as the inner shell in dual-shell wall constructions. They are mainly used in walls today, even though they were originally designed for use in roofs.\n\nThe primary function of the cladding system is to provide a weathertight building envelope, suitable for the intended use of the building.\nTrapezoidal metal roof sheets with through fix fasteners are generally suitable for slopes of 4% or steeper. This limit is critical to the performance of the cladding. For shallower pitches, down to 1.5%, a fix system with no exposed through fasteners, special side laps and preferably no end laps should be used. For low pitch roof, ponding is a potential problem that must be considered at the design stage in order to avoid the deleterious effects of prolonged soaking and the increased loading, due to the weight of the water.\n\nBuilding envelope made from metal sheet provide builders and architects with products, which meet all of the highest demand regarding construction characteristics and design. The steel from which profiled cladding sheets are made is available pre-coated in a wide range of colors and textures, allowing architects to choose a finish that best suits the location and function of the building. Profile shape is also a characteristic that can be adapted to the demand of the architects.\n\nBuildings are responsible of the 40% of European energy consumption, consequently, improving the thermal performance of the cladding and associated components is very important. The elemental U-value (thermal transmittance, W/m2K) of a cladding panel, depends on the conductivity and thickness of the insulation which is added, the profile shape and the presence of thermal bridges. \nSo, metal profile sheets can achieve thermal performance regulations thanks of insulations and profile shape.\nIt is very important to analyze and avoid all possible thermal bridges within the roof and wall cladding assembly, to minimize local heat/cold losses.\n\nRoofs constructed with trapezoidal profiles have excellent sound suppression characteristics. The sound reduction assessments of up to 53 dB have been realised. \nThe measured sound reduction for wall constructions using cassettes has been assessed at an RW of 57 dB. \nThe acoustic performance of a particular cladding system will depend on the insulation material, the weather sheet and liner sheet profiles and the method of assembly.\nTo minimize reverberation architects may take advantage of the sound absorbing properties of the cladding insulation layer by replacing the standard liner sheet with a perforated liner.\n\nIn order to ensure that the building envelope remains fully functional throughout its design life, it is important that it receives regular maintenance, including inspection, removal of debris, cleaning and repair of damage. Inspection can include man-made or natural wear. Weather exposure, natural movement, installation error and manufacturing defects are examples. The need of maintenance may be greatly reduced using specific coating depending on the weather conditions, this coating guarantee the expected design life of the cladding. The commonly used 302 stainless steel alone is resistant to acetic acid, acetone and boric acid, among others.\n\nMetal profiles sheets have a high recycled scrap steel content and all steel is recyclable. Many steel components can be unbolted and even reused for future applications. The possibility of reusing building elements makes steel construction even more sustainable than the already significant contribution of today’s simple material recycling. Steel can be repeatedly recycled because it does not lose any of its inherent physical properties as a result of the recycling process. Stainless steel fasteners have excellent corrosion resistance and durability, as well as being a sustainable material. Custom fasteners in this material make for the utmost of sustainability with high recyclability.\n\nMetal cladding systems are required to carry externally applied loads, such as snow and wind loading without deflecting excessively or compromising the other performance requirements. The individual characteristic loads (actions) should be obtained from the appropriate part of EN 1991, taking into account the building geometry and location as applicable. These individual actions should then be combined using the appropriate safety factors from EN 1990 to obtain the load cases used in design. \nFor most application of metal cladding technology, the only permanent action which the roof cladding needs to be designed is its own self-weight.\nFor wall cladding, it is not normally necessary to consider permanent actions, since the self-weight acts in the plan of the cladding. \nIn addition to its self-weight, the roof cladding must also be designed for the following variable actions as specified in the appropriate parts of EN 1991:\n-Access for cleaning and maintenance. \n-A uniformly distributed load due to snow over the complete roof area. The value of this load will depend on the building’s location.\n-Asymmetric snow load and loading due to snow drifts.\n-Wind loading due to pressure and suction. \nCare must be taken on site to avoid excessive local deflection. Typical deflection limits imposed on the cladding are depend on the loading regime considered, the location of the structural component and whether a brittle material is present. Deflection limits may be specifies by National regulation.\n\nMetal profile sheets due to their versatility mechanical and design properties can be used as roof and roof cladding, as external walls and wall cladding and also as floors. They are used in industry and in residential sector, and the two sectors can be used in both new construction and rehabilitation. Some of the applications where metal profile sheets are used are:\n\n\n"}
{"id": "674329", "url": "https://en.wikipedia.org/wiki?curid=674329", "title": "Method stub", "text": "Method stub\n\nA method stub or simply stub in software development is a piece of code used to stand in for some other programming functionality. A stub may simulate the behavior of existing code (such as a procedure on a remote machine, such methods are often called mocks) or be a temporary substitute for yet-to-be-developed code. Stubs are therefore most useful in porting, distributed computing as well as general software development and testing.\n\nAn example of a stub in pseudocode might be as follows:\n\nThe above pseudocode utilises the function ThermometerRead, which returns a temperature. While ThermometerRead would be intended to read some hardware device, this function currently does not contain the necessary code. So ThermometerRead does not, in essence, simulate any process, yet it \"does\" return a legal value, allowing the main program to be at least partially tested. Also note that although it accepts the parameter of type Source, which determines whether inside or outside temperature is needed, it does not use the actual value passed (argument insideOrOutside) by the caller in its logic.\n\nA stub is a routine that doesn't actually do anything other than declaring itself and the parameters it accepts and returning something that is usually the values expected in one of the \"happy scenarios\" for the caller. Stubs are used commonly as placeholders for implementation of a known interface, where the interface is finalized/known but the implementation is not yet known/finalized. The stub contains just enough code to allow it to be compiled and linked with the rest of the program. In RMI nomenclature, a stub communicates on the server-side with a skeleton.\n\nIn the context of DOS and Windows, the term \"stub\" is also used in a fashion like shim to describe the small areas of interface code left in conventional memory by self-relocating resident drivers which move most of themselves into upper memory, the high memory area, expanded or extended memory as well as similar stubs to allow the relocated code to communicate with real-mode DOS in conjunction with DOS extenders (like DPMI, DPMS, CLOAKING or NIOS).\n\nThe small pieces of dummy code branched into to allow a graceful exit when invoking a fat binary in the wrong environment are also called (code) stubs.\n\n\n"}
{"id": "4504149", "url": "https://en.wikipedia.org/wiki?curid=4504149", "title": "Microchip Technology", "text": "Microchip Technology\n\nMicrochip Technology Inc. is an American publicly-listed corporation that is a manufacturer of microcontroller, mixed-signal, analog and Flash-IP integrated circuits. Its products include microcontrollers (PIC, dsPIC, AVR and SAM), Serial EEPROM devices, Serial SRAM devices, embedded security devices, radio frequency (RF) devices, thermal, power and battery management analog devices, as well as linear, interface and wireless solutions.\nExamples of these solutions include USB, zigbee, MiWi, LoRa, SIGFOX and Ethernet.\n\nCorporate headquarters are located in Chandler, Arizona, with wafer fabs in Tempe, Arizona, Gresham, Oregon, and Colorado Springs, Colorado, assembly/test facilities in Chachoengsao, Thailand and Calamba, Philippines. Sales for the fiscal year ending on March 31, 2018 were $3.981 billion.\n\nMicrochip Technology was founded in 1987 when General Instrument spun off its microelectronics division as a wholly owned subsidiary.\nMicrochip Technology became an independent company in 1989 when it was acquired by a group of venture capitalists, and went public in 1993.\n\nIn April 2009, Microchip Technology announced the nanoWatt XLP Microcontrollers, claiming the world's lowest sleep current. Microchip Technology had sold more than 6 billion microcontrollers as of 2009.\n\nIn April 2010, Microchip acquired Silicon Storage Technology (SST),\nand sold several SST flash memory assets to Greenliant Systems in May that year.\n\nAs of 2011, Microchip Technology ships over a billion processors every year. In September 2011, Microchip Technology shipped the 10 billionth PIC microcontroller.\n\nIn August 2012, Microchip acquired Standard Microsystems Corporation (SMSC). Among SMSC's assets were those it had previously acquired from Symwave, a start-up that specialized in USB 3.0 chips, and two hi-fi wireless audio companies — Kleer Semiconductor and Wireless Audio IP BV.\n\nIn January 2016, Microchip agreed to buy Atmel for $3.56 billion. JPMorgan Chase advised Microchip while Qatalyst Partners advised Atmel.\n\nIn March 2018, Microchip acquired Microsemi Corporation (NASDAQ: MSCC). The acquisition price represents a total equity value of about $8.35 billion, and a total enterprise value of about $10.15 billion, after accounting for Microsemi’s cash and investments, net of debt, on its balance sheet at December 31, 2017.\n\nMicrochip develops a wide range of microcontrollers and integrated circuits (ICs), for the hobbyist and professional markets.\n\nMicrochip is widely known for their line of PIC microcontrollers, and their MCU-related product line includes:\n\nThe Microchip product line of integrated circuits include:\n\nChief Executive Officer, Microchip Technology Inc.\n\nPresident & Chief Operating Officer, Microchip Technology Inc.\n\nVice President and Chief Financial Officer, Microchip Technology Inc.\n\nVice President, MCU8 Division, Microchip Technology Inc.\n\nVice President, Worldwide Sales and Applications, Microchip Technology Inc.\n\nVice President, Analog Power and Interface Division, Microchip Technology Inc.\n\nMathew B. Bunker, \"Vice President, Back-End Operations\"\n\nStephen T. Caldwell, \"Vice President, Wireless Products Division\"\n\nLauren A. Carr, \"Vice President, Human Resources\"\n\nKathryn A. Clevenger, \"Vice President, Fab 4 Operations\"\n\nNuri Dagdeviren, \"Vice President, Security Products Group\"\n\nRod Drake, \"Vice President, MCU32 Division\"\n\nRandall L. Drwinga, \"Vice President, Memory Products Division\"\n\nFanie Duvenhage, \"Vice President, Human Machine Interface Division\"\n\nMichael A. Finley, \"Vice President, Fab Operations\"\n\nThomas J. Grune, \"Vice President, Americas Sales\"\n\nIan F. Harris, \"Vice President, Computing Products Group\"\n\nSudarshan Iyengar, \"Vice President, India Development Center\"\n\nPatrick Johnson, \"Vice President, Mixed Signal and Linear Division\"\n\nMatthias Kaestner, \"Vice President, Automotive\"\n\nRami Kanama, \"Vice President, Timing and Communication Group\"\n\nJoseph R. Krawczyk, \"Vice President, Asia Sales\"\n\nBryan J. Liddiard, \"Vice President, Marketing for Mixed Signal and Linear Division\"\n\nDan Malinaric, \"Vice President, Fab 5 Operations\"\n\nGary P. Marsh, \"Vice President, European Sales\"\n\nSumit K. Mitra, \"Vice President, Wireless Solution Group & MCU32 Division\"\n\nMitchel Obolsky, \"Vice President, USB and Networking Group & MCU16 Division\"\n\nGreg Perzanowski, \"Vice President, Quality & Reliability Systems\"\n\nKenneth N. Pye, \"Vice President, Worldwide Applications Engineering\"\n\nMark W. Reiten, \"Vice President, Licensing\"\n\nDavid Sadler, \"Vice President, Finance & Corporate Controller\"\n\nNawaz Sharif, \"Vice President, Europe Finance\"\n\nJoseph Thomsen, \"Vice President, MCU16 Division\"\n\nAlfredo Vadillo, \"Vice President, MPU32 & Aerospace\"\n\nKimberly van Herk, \"Vice President, General Counsel and Corporate Secretary\"\n\nRobert Williams, \"Vice President, Global Information Services\"\n\nIan (Kai Man) Yue, \"Vice President, SuperFLASH Design\"\n\nHI-TECH Software was an Australian-based company that provides ANSI C compilers and development tools. Founded in 1984, the company is best known for its HI-TECH C PRO compilers with whole-program compilation technology, or Omniscient Code Generation (OCG). HI-TECH Software was bought by Microchip on 20 February 2009, whereupon it refocused its development effort exclusively on supporting Microchip products.\n\nSupported manufacturers and architectures :\n\nSilicon Storage Technology, Inc. (SST) was a Sunnyvale, California, United States, technology company producing non-volatile memory devices and related products.\nSST supplied NOR flash and other integrated circuits for high-volume applications.\n\nBing Yeh co-founded SST in August 1989, and served as its chief executive.\n\nAt the 1992 Fall COMDEX trade show, SST introduced the first single-board 30 MB 2.5\" solid-state drive with standard hard-disk ATA interface and a 5 MB PC Card memory card with built-in controller and firmware.\n\nIn 1993, SST moved its headquarters to Sunnyvale. That same year, SST introduced its first SuperFlash technology products, with lower costs and faster write speeds. By the end of 1995, more than 90% of the PC motherboards produced in Taiwan had adopted SST's 1 Mbit SuperFlash EEPROM product for the BIOS storage. \nThe company had its initial public offering November 21, 1995, trading on the NASDAQ market under the symbol SSTI.\nAnalytical models of SuperFlash were published.\nA five-year licensing agreement was announced in January 1999 with Acer Inc..\nA 1997 lawsuit filed by Intel was settled in May 1999 after mediation.\n\nIn 2004, SST began to diversify beyond flash memory products, targeting consumer and industrial products with embedded solid-state data storage and RF wireless communication.\nIn September 2004 SST purchased a majority stake in Emosyn, which designed products for SIM cards. In October it announced the acquisition of G-Plus, based in Santa Monica, California.\n\nIn 2006, SST announced a joint development agreement with Taiwan Semiconductor Manufacturing Company (TSMC) to develop 90 nm SuperFlash technology.\n\nSST had its stock option grant practices investigated by the US Securities and Exchange Commission, ending in June 2008.\nIt determined it needed to restate earnings, and was given a de-listing notice by NASDAQ for filing late reports from 2006 through 2007.\nBusiness slowed in the Great Recession.The company announced a loss on reduced revenues, reducing its workforce by 17% in December 2008.\n\nIn November 2009, Technology Resource Holdings offered to acquire the company for about $200 million, but a group of shareholders thought it was undervalued.\nStarting in February 2010, private equity firm Cerberus Capital Management and public company Microchip Technology both made offers to acquire SST.\nIn April 2010, Microchip completed the acquisition for about $292 million.\nMicrochip sold several SST flash memory assets to Greenliant Systems (founded by Yeh) in May of that year.\n\n\n"}
{"id": "37702288", "url": "https://en.wikipedia.org/wiki?curid=37702288", "title": "Mini Xplus", "text": "Mini Xplus\n\nThe Mini Xplus is a small computer that runs Android 4.0 and is based on the AllWinner A10 SoC. It is sold together with a remote control and is therefore suitable for use as an HTPC.\n"}
{"id": "1886340", "url": "https://en.wikipedia.org/wiki?curid=1886340", "title": "Mixer (cooking)", "text": "Mixer (cooking)\n\nA mixer is a kitchen device that uses a gear-driven mechanism to rotate a set of \"beaters\" in a bowl containing the food or liquids to be prepared by mixing them. \n\nMixers help automate the repetitive tasks of stirring, whisking or beating. \n\nWhen the beaters are replaced by a \"dough hook\", a mixer may also be used to knead.\n\nA mixer may be a handheld mechanism known as an eggbeater, a handheld motorized beater, or a drill mixer. Stand mixers vary in size from small counter top models for home use to large capacity commercial machines. Stand mixers create the mixing action by rotating the mixing device vertically (planetary mixers), or by rotating the mixing container (spiral mixers).\n\nMixers for the kitchen first came into use midway through the nineteenth century; the earliest were mechanical devices. The demand from commercial bakers for large-scale uniform mixing resulted in the development of the electric stand mixer. Smaller counter-top stand mixers for home kitchen use soon followed.\n\nThe mixer with rotating parts was patented in 1856 by Baltimore, Maryland tinner Ralph Collier. This was followed by E.P. Griffith's whisk patented in England in 1857. Another hand-turned rotary egg beater was patented by J.F. and E.P. Monroe in 1859 in the US. Their egg beater patent was one of the earliest bought up by the Dover Stamping Company, whose Dover egg beaters became a classic American brand. The Monroe design was also manufactured in England. In 1870, Turner Williams of Providence, R.I., invented another Dover egg beater model. In 1894, Willis Johnson of Cincinnati, Ohio invented new improvements to the egg beater. \nThe first mixer with electric motor is thought to be the one invented by American Rufus Eastman in 1885. The Hobart Manufacturing Company was an early manufacturer of large commercial mixers, and they say a new model introduced in 1914 played a key role in the mixer part of their business. The Hobart KitchenAid and Sunbeam Mixmaster (first produced 1910) were two very early US brands of electric mixer. Domestic electric mixers were rarely used before the 1920s, when they were adopted more widely for home use.\n\nIn 1908 Herbert Johnson, an engineer for the Hobart Manufacturing Company, invented an electric standing mixer. His inspiration came from observing a baker mixing bread dough with a metal spoon; soon he was toying with a mechanical counterpart. By 1915, his 20 gallon (80 l) mixer was standard equipment for most large bakeries. In 1919, Hobart introduced the Kitchen Aid Food Preparer (stand mixer) for the home.\n\nOlder models of mixers originally listed each speed by name of operation (ex: Beat-Whip would be high speed if it is a 3-speed mixer); they are now listed by number.\n\nAn eggbeater is a handheld device with a crank on the side geared to one or more beaters. The user grips the handle with one hand and operates the crank with the other, creating the rotary action.\n\nA mixer is a kitchen utensil which uses a gear-driven mechanism to rotate a set of beaters in a bowl containing the food to be prepared. It automates the repetitive tasks of stirring, whisking or beating. When the beaters are replaced by a dough hook, a mixer may also be used to knead.\n\nA mixer may be a handheld mechanism known as an eggbeater, a handheld motorized beater, or a stand mixer. Stand mixers vary in size from small counter top models for home use to large capacity commercial machines. Stand mixers create the mixing action by rotating the mixing device vertically (planetary mixers), or by rotating the mixing container (spiral mixers).\n\nMixers for the kitchen first came into use midway through the nineteenth century; the earliest were mechanical devices. The demand from commercial bakers for large-scale uniform mixing resulted in the development of the electric stand mixer. Smaller counter-top stand mixers for home kitchen use soon followed.\n\nWhen selecting a mixer, the purchaser should consider how the mixer will be used. Electric mixers with more speed options give the user more control over the development of the mixture.\n\nStand mixers mount the motor driving the rotary action in a frame or stand which bears the weight of the device. Stand mixers are larger and have more powerful motors than their hand-held counterparts. They generally have a special bowl that is locked in place while the mixer is operating. A typical home stand mixer will include a wire whisk for whipping creams and egg whites; a flat beater for mixing batters; and a dough hook for kneading.\n\nStand mixers are generally available in either \"counter top\" (also called bench) or \"floor\" models. Heavy duty commercial models can have bowl capacities well in excess of 25 gallons (95 l) and weigh thousands of pounds (kilograms) but more typical home and light commercial models are equipped with bowls of around 1 gallon (4 l). Whether a mixer is a counter top or floor model depends on its size. Mixers that are 5 gallons (20 l) in size or smaller tend to be counter top mixers, while larger mixers tend to be floor models due to their size and weight.\n\nSpiral mixers are specialist tools for mixing dough. A spiral-shaped agitator remains stationary while the bowl rotates. This method enables spiral mixers to mix the same size dough batch much quicker and with less under-mixed dough than a similarly powered planetary mixer. Spiral mixers can mix dough with less agitator friction than planetary mixers. This allows the dough to be mixed without increasing its temperature, ensuring the dough can rise properly.\n\nPlanetary mixers consist of a bowl and an agitator. The bowl remains static, whilst the agitator is rapidly moved around the bowl to mix its contents. With the ability to mix a wide variety of ingredients, planetary mixers are more versatile than their spiral counterparts. Planetary mixers can be used to whip and blend, whereas spiral mixers cannot. They are normally used in Australia, India and \nEurope too. The mixers are used all over world.\n\nA hand mixer is a hand-held mixing device. A handle is mounted over an enclosure containing the motor. The motor drives the beaters which are immersed in the food to perform the mixing action. The motor must be lightweight as it is supported by the user during use. The user may use any suitable kitchen container to hold the ingredients while mixing.\n\nThe electric hand-mixer was invented in 1964 by Dynamic, sited in western France. Its products are essentially the same design it has always produced.\n\nA dough mixer is used for household or industrial purposes. It is used for kneading large quantities of dough. It is electrical, having timers and various controls to suit the user's needs. Some features of dough blenders include high speed, low speed and bowl reverse (these can be combined into a programme) and a kneading bar in the centre of the bowl.\n\n\nList of Best Mixer Grander\n"}
{"id": "191646", "url": "https://en.wikipedia.org/wiki?curid=191646", "title": "OLED", "text": "OLED\n\nAn organic light-emitting diode (OLED) is a light-emitting diode (LED) in which the emissive electroluminescent layer is a film of organic compound that emits light in response to an electric current. This organic layer is situated between two electrodes; typically, at least one of these electrodes is transparent. OLEDs are used to create digital displays in devices such as television screens, computer monitors, portable systems such as smartphones, handheld game consoles and PDAs. A major area of research is the development of white OLED devices for use in solid-state lighting applications.\n\nThere are two main families of OLED: those based on small molecules and those employing polymers. Adding mobile ions to an OLED creates a light-emitting electrochemical cell (LEC) which has a slightly different mode of operation. An OLED display can be driven with a passive-matrix (PMOLED) or active-matrix (AMOLED) control scheme. In the PMOLED scheme, each row (and line) in the display is controlled sequentially, one by one, whereas AMOLED control uses a thin-film transistor backplane to directly access and switch each individual pixel on or off, allowing for higher resolution and larger display sizes.\n\nAn OLED display works without a backlight because it emits visible light. Thus, it can display deep black levels and can be thinner and lighter than a liquid crystal display (LCD). In low ambient light conditions (such as a dark room), an OLED screen can achieve a higher contrast ratio than an LCD, regardless of whether the LCD uses cold cathode fluorescent lamps or an LED backlight.\n\nAndré Bernanose and co-workers at the Nancy-Université in France made the first observations of electroluminescence in organic materials in the early 1950s. They applied high alternating voltages in air to materials such as acridine orange, either deposited on or dissolved in cellulose or cellophane thin films. The proposed mechanism was either direct excitation of the dye molecules or excitation of electrons.\n\nIn 1960 Martin Pope and some of his co-workers at New York University developed ohmic dark-injecting electrode contacts to organic crystals. They further described the necessary energetic requirements (work functions) for hole and electron injecting electrode contacts. These contacts are the basis of charge injection in all modern OLED devices. Pope's group also first observed direct current (DC) electroluminescence under vacuum on a single pure crystal of anthracene and on anthracene crystals doped with tetracene in 1963 using a small area silver electrode at 400 volts. The proposed mechanism was field-accelerated electron excitation of molecular fluorescence.\n\nPope's group reported in 1965 that in the absence of an external electric field, the electroluminescence in anthracene crystals is caused by the recombination of a thermalized electron and hole, and that the conducting level of anthracene is higher in energy than the exciton energy level. Also in 1965, W. Helfrich and W. G. Schneider of the National Research Council in Canada produced double injection recombination electroluminescence for the first time in an anthracene single crystal using hole and electron injecting electrodes, the forerunner of modern double-injection devices. In the same year, Dow Chemical researchers patented a method of preparing electroluminescent cells using high-voltage (500–1500 V) AC-driven (100–3000 Hz) electrically insulated one millimetre thin layers of a melted phosphor consisting of ground anthracene powder, tetracene, and graphite powder. Their proposed mechanism involved electronic excitation at the contacts between the graphite particles and the anthracene molecules.\n\nRoger Partridge made the first observation of electroluminescence from polymer films at the National Physical Laboratory in the United Kingdom. The device consisted of a film of poly(N-vinylcarbazole) up to 2.2 micrometers thick located between two charge injecting electrodes. The results of the project were patented in 1975 and published in 1983.\n\nAmerican physical chemist Ching W. Tang and Steven Van Slyke at Eastman Kodak built the first practical OLED device in 1987. This device used a two-layer structure with separate hole transporting and electron transporting layers such that recombination and light emission occurred in the middle of the organic layer; this resulted in a reduction in operating voltage and improvements in efficiency.\n\nResearch into polymer electroluminescence culminated in 1990 with J. H. Burroughes \"et al.\" at the Cavendish Laboratory at Cambridge University, UK, reporting a high-efficiency green light-emitting polymer-based device using 100 nm thick films of poly(p-phenylene vinylene). Moving from molecular to macromolecular materials solved the problems previously encountered with the long-term stability of the organic films and enabled high-quality films to be easily made. Subsequent research developed multilayer polymers and the new field of plastic electronics and OLED research and device production grew rapidly.\n\nUniversal Display Corporation a developer and manufacturer based in the United States holds the majority of patents concerning the commercialization of OLEDs.\n\nA typical OLED is composed of a layer of organic materials situated between two electrodes, the anode and cathode, all deposited on a substrate. The organic molecules are electrically conductive as a result of delocalization of pi electrons caused by conjugation over part or all of the molecule. These materials have conductivity levels ranging from insulators to conductors, and are therefore considered organic semiconductors. The highest occupied and lowest unoccupied molecular orbitals (HOMO and LUMO) of organic semiconductors are analogous to the valence and conduction bands of inorganic semiconductors.\n\nOriginally, the most basic polymer OLEDs consisted of a single organic layer. One example was the first light-emitting device synthesised by J. H. Burroughes \"et al.\", which involved a single layer of poly(p-phenylene vinylene). However multilayer OLEDs can be fabricated with two or more layers in order to improve device efficiency. As well as conductive properties, different materials may be chosen to aid charge injection at electrodes by providing a more gradual electronic profile, or block a charge from reaching the opposite electrode and being wasted. Many modern OLEDs incorporate a simple bilayer structure, consisting of a conductive layer and an emissive layer. More recent developments in OLED architecture improves quantum efficiency (up to 19%) by using a graded heterojunction. In the graded heterojunction architecture, the composition of hole and electron-transport materials varies continuously within the emissive layer with a dopant emitter. The graded heterojunction architecture combines the benefits of both conventional architectures by improving charge injection while simultaneously balancing charge transport within the emissive region.\n\nDuring operation, a voltage is applied across the OLED such that the anode is positive with respect to the cathode. Anodes are picked based upon the quality of their optical transparency, electrical conductivity, and chemical stability. A current of electrons flows through the device from cathode to anode, as electrons are injected into the LUMO of the organic layer at the cathode and withdrawn from the HOMO at the anode. This latter process may also be described as the injection of electron holes into the HOMO. Electrostatic forces bring the electrons and the holes towards each other and they recombine forming an exciton, a bound state of the electron and hole. This happens closer to the emissive layer, because in organic semiconductors holes are generally more mobile than electrons. The decay of this excited state results in a relaxation of the energy levels of the electron, accompanied by emission of radiation whose frequency is in the visible region. The frequency of this radiation depends on the band gap of the material, in this case the difference in energy between the HOMO and LUMO.\n\nAs electrons and holes are fermions with half integer spin, an exciton may either be in a singlet state or a triplet state depending on how the spins of the electron and hole have been combined. Statistically three triplet excitons will be formed for each singlet exciton. Decay from triplet states (phosphorescence) is spin forbidden, increasing the timescale of the transition and limiting the internal efficiency of fluorescent devices. Phosphorescent organic light-emitting diodes make use of spin–orbit interactions to facilitate intersystem crossing between singlet and triplet states, thus obtaining emission from both singlet and triplet states and improving the internal efficiency.\n\nIndium tin oxide (ITO) is commonly used as the anode material. It is transparent to visible light and has a high work function which promotes injection of holes into the HOMO level of the organic layer. A typical conductive layer may consist of as the HOMO level of this material generally lies between the work function of ITO and the HOMO of other commonly used polymers, reducing the energy barriers for hole injection. Metals such as barium and calcium are often used for the cathode as they have low work functions which promote injection of electrons into the LUMO of the organic layer. Such metals are reactive, so they require a capping layer of aluminium to avoid degradation.\n\nExperimental research has proven that the properties of the anode, specifically the anode/hole transport layer (HTL) interface topography plays a major role in the efficiency, performance, and lifetime of organic light-emitting diodes. Imperfections in the surface of the anode decrease anode-organic film interface adhesion, increase electrical resistance, and allow for more frequent formation of non-emissive dark spots in the OLED material adversely affecting lifetime. Mechanisms to decrease anode roughness for ITO/glass substrates include the use of thin films and self-assembled monolayers. Also, alternative substrates and anode materials are being considered to increase OLED performance and lifetime. Possible examples include single crystal sapphire substrates treated with gold (Au) film anodes yielding lower work functions, operating voltages, electrical resistance values, and increasing lifetime of OLEDs.\n\nSingle carrier devices are typically used to study the kinetics and charge transport mechanisms of an organic material and can be useful when trying to study energy transfer processes. As current through the device is composed of only one type of charge carrier, either electrons or holes, recombination does not occur and no light is emitted. For example, electron only devices can be obtained by replacing ITO with a lower work function metal which increases the energy barrier of hole injection. Similarly, hole only devices can be made by using a cathode made solely of aluminium, resulting in an energy barrier too large for efficient electron injection.\n\nBalanced charge injection and transfer are required to get high internal efficiency, pure emission of luminance layer without contaminated emission from charge transporting layers, and high stability. A common way to balance charge is optimizing the thickness of the charge transporting layers but is hard to control. Another way is using the exciplex. Exciplex formed between hole-transporting (p-type) and electron-transporting (n-type) side chains to localize electron-hole pairs. Energy is then transferred to luminophore and provide high efficiency. An example of using exciplex is grafting Oxadiazole and carbazole side units in red diketopyrrolopyrrole-doped Copolymer main chain shows improved external quantum efficiency and color purity in no optimized OLED.\n\nEfficient OLEDs using small molecules were first developed by Ching W. Tang \"et al.\" at Eastman Kodak. The term OLED traditionally refers specifically to this type of device, though the term SM-OLED is also in use.\n\nMolecules commonly used in OLEDs include organometallic chelates (for example Alq, used in the organic light-emitting device reported by Tang \"et al.\"), fluorescent and phosphorescent dyes and conjugated dendrimers. A number of materials are used for their charge transport properties, for example triphenylamine and derivatives are commonly used as materials for hole transport layers. Fluorescent dyes can be chosen to obtain light emission at different wavelengths, and compounds such as perylene, rubrene and quinacridone derivatives are often used. Alq has been used as a green emitter, electron transport material and as a host for yellow and red emitting dyes.\n\nThe production of small molecule devices and displays usually involves thermal evaporation in a vacuum. This makes the production process more expensive and of limited use for large-area devices, than other processing techniques. However, contrary to polymer-based devices, the vacuum deposition process enables the formation of well controlled, homogeneous films, and the construction of very complex multi-layer structures. This high flexibility in layer design, enabling distinct charge transport and charge blocking layers to be formed, is the main reason for the high efficiencies of the small molecule OLEDs.\n\nCoherent emission from a laser dye-doped tandem SM-OLED device, excited in the pulsed regime, has been demonstrated. The emission is nearly diffraction limited with a spectral width similar to that of broadband dye lasers.\n\nResearchers report luminescence from a single polymer molecule, representing the smallest possible organic light-emitting diode (OLED) device. Scientists will be able to optimize substances to produce more powerful light emissions. Finally, this work is a first step towards making molecule-sized components that combine electronic and optical properties. Similar components could form the basis of a molecular computer.\n\nPolymer light-emitting diodes (PLED, P-OLED), also light-emitting polymers (LEP), involve an electroluminescent conductive polymer that emits light when connected to an external voltage. They are used as a thin film for full-spectrum colour displays. Polymer OLEDs are quite efficient and require a relatively small amount of power for the amount of light produced.\n\nVacuum deposition is not a suitable method for forming thin films of polymers. However, polymers can be processed in solution, and spin coating is a common method of depositing thin polymer films. This method is more suited to forming large-area films than thermal evaporation. No vacuum is required, and the emissive materials can also be applied on the substrate by a technique derived from commercial inkjet printing. However, as the application of subsequent layers tends to dissolve those already present, formation of multilayer structures is difficult with these methods. The metal cathode may still need to be deposited by thermal evaporation in vacuum. An alternative method to vacuum deposition is to deposit a Langmuir-Blodgett film.\n\nTypical polymers used in pleaded displays include derivatives of poly(\"p\"-phenylene vinylene) and polyfluorene. Substitution of side chains onto the polymer backbone may determine the colour of emitted light or the stability and solubility of the polymer for performance and ease of processing.\nWhile unsubstituted poly(p-phenylene vinylene) (PPV) is typically insoluble, a number of PPVs and related poly(naphthalene vinylene)s (PNVs) that are soluble in organic solvents or water have been prepared via ring opening metathesis polymerization. These water-soluble polymers or conjugated poly electrolytes (CPEs) also can be used as hole injection layers alone or in combination with nanoparticles like graphene.\n\nPhosphorescent organic light-emitting diodes use the principle of electrophosphorescence to convert electrical energy in an OLED into light in a highly efficient manner, with the internal quantum efficiencies of such devices approaching 100%.\n\nTypically, a polymer such as poly(N-vinylcarbazole) is used as a host material to which an organometallic complex is added as a dopant. Iridium complexes such as Ir(mppy) are currently the focus of research, although complexes based on other heavy metals such as platinum have also been used.\n\nThe heavy metal atom at the centre of these complexes exhibits strong spin-orbit coupling, facilitating intersystem crossing between singlet and triplet states. By using these phosphorescent materials, both singlet and triplet excitons will be able to decay radiatively, hence improving the internal quantum efficiency of the device compared to a standard OLED where only the singlet states will contribute to emission of light.\n\nApplications of OLEDs in solid state lighting require the achievement of high brightness with good CIE coordinates (for white emission). The use of macromolecular species like polyhedral oligomeric silsesquioxanes (POSS) in conjunction with the use of phosphorescent species such as Ir for printed OLEDs have exhibited brightnesses as high as 10,000 cd/m.\n\n\nMost commonly used patterning method for organic light-emitting display is shadow masking during film deposition. Also called as \"RGB side-by-side\" method or \"RGB pixelation\" method. Metal sheet with multiple apertures made of low thermal expansion material, such as nickel alloy, is placed between heated evaporation source and substrate, so that the organic or inorganic material from evaporation source is deposited only to the desired location on the substrate. Almost all small OLED displays for smartphones have been manufactured using this method.\n\nAlthough shadow-mask patterning method is mature technology used from the first OLED manufacturing, it causes many issues like dark spot formation due to mask-substrate contact or misalignment of the pattern due to the deformation of shadow mask. Such defect formation can be regarded as trivial when the display size is small, however it causes serious issues when a large display is manufactured, which brings significant production yield loss. To circumvent such issues, white emission device with 4-sub-pixel color filter (white, red, green and blue) has been used for large television. In spite of the light absorption by color filter, state-of-art OLED television can make high color reproduction, such as 100% NTSC, and low power consumption happen at the same time, using emission spectrum with high human-eye sensitivity, special color filters with low spectrum overlap and performance tuning with color statistic into consideration. \nThis approach is also called as \"Color-by-white\" method.\n\nThere are other type of emerging patterning technologies to increase the manufacturabiltiy of OLED. \nPatternable organic light-emitting devices use a light or heat activated electroactive layer. A latent material (PEDOT-TMA) is included in this layer that, upon activation, becomes highly efficient as a hole injection layer. Using this process, light-emitting devices with arbitrary patterns can be prepared.\n\nColour patterning can be accomplished by means of laser, such as radiation-induced sublimation transfer (RIST).\n\nOrganic vapour jet printing (OVJP) uses an inert carrier gas, such as argon or nitrogen, to transport evaporated organic molecules (as in organic vapour phase deposition). The gas is expelled through a micrometre-sized nozzle or nozzle array close to the substrate as it is being translated. This allows printing arbitrary multilayer patterns without the use of solvents.\n\nLike ink jet material depositioning, inkjet etching (IJE) deposits precise amounts of solvent onto a substrate designed to selectively dissolve the substrate material and induce a structure or pattern. Inkjet etching of polymer layers in OLED's can be used to increase the overall out-coupling efficiency. In OLEDs, light produced from the emissive layers of the OLED is partially transmitted out of the device and partially trapped inside the device by total internal reflection (TIR). This trapped light is wave-guided along the interior of the device until it reaches an edge where it is dissipated by either absorption or emission. Inkjet etching can be used to selectively alter the polymeric layers of OLED structures to decrease overall TIR and increase out-coupling efficiency of the OLED. Compared to a non-etched polymer layer, the structured polymer layer in the OLED structure from the IJE process helps to decrease the TIR of the OLED device. IJE solvents are commonly organic instead of water-based due to their non-acidic nature and ability to effectively dissolve materials at temperatures under the boiling point of water.\nTransfer-printing is an emerging technology to assemble large numbers of parallel OLED and AMOLED devices efficiently. It takes advantage of standard metal deposition, photolithography, and etching to create alignment marks commonly on glass or other device substrates. Thin polymer adhesive layers are applied to enhance resistance to particles and surface defects. Microscale ICs are transfer-printed onto the adhesive surface and then baked to fully cure adhesive layers. An additional photosensitive polymer layer is applied to the substrate to account for the topography caused by the printed ICs, reintroducing a flat surface. Photolithography and etching removes some polymer layers to uncover conductive pads on the ICs. Afterwards, the anode layer is applied to the device backplane to form bottom electrode. OLED layers are applied to the anode layer with conventional vapor deposition, and covered with a conductive metal electrode layer. transfer-printing was capable to print onto target substrates up to 500mm X 400mm. This size limit needs to expand for transfer-printing to become a common process for the fabrication of large OLED/AMOLED displays.\n\nFor a high resolution display like a TV, a TFT backplane is necessary to drive the pixels correctly. Currently, low temperature polycrystalline silicon (LTPS) – thin-film transistor (TFT) is used for commercial AMOLED displays. LTPS-TFT has variation of the performance in a display, so various compensation circuits have been reported.\nDue to the size limitation of the excimer laser used for LTPS, the AMOLED size was limited. To cope with the hurdle related to the panel size, amorphous-silicon/microcrystalline-silicon backplanes have been reported with large display prototype demonstrations.\n\nThe different manufacturing process of OLEDs lends itself to several advantages over flat panel displays made with LCD technology.\n\n\nThe biggest technical problem for OLEDs was the limited lifetime of the organic materials. One 2008 technical report on an OLED TV panel found that \"After 1,000 hours the blue luminance degraded by 12%, the red by 7% and the green by 8%.\" In particular, blue OLEDs historically have had a lifetime of around 14,000 hours to half original brightness (five years at 8 hours a day) when used for flat-panel displays. This is lower than the typical lifetime of LCD, LED or PDP technology. Each currently is rated for about 25,000–40,000 hours to half brightness, depending on manufacturer and model. Degradation occurs because of the accumulation of nonradiative recombination centers and luminescence quenchers in the emissive zone. It is said that the chemical breakdown in the semiconductors occurs in four steps: 1) recombination of charge carriers through the absorption of UV light, 2) homolytic dissociation, 3) subsequent radical addition reactions that form radicals, and 4) disproportionation between two radicals resulting in hydrogen-atom transfer reactions. However, some manufacturers' displays aim to increase the lifespan of OLED displays, pushing their expected life past that of LCD displays by improving light outcoupling, thus achieving the same brightness at a lower drive current. In 2007, experimental OLEDs were created which can sustain 400 cd/m of luminance for over 198,000 hours for green OLEDs and 62,000 hours for blue OLEDs.\nAdditionally, as the OLED material used to produce blue light degrades significantly more rapidly than the materials that produce other colors, blue light output will decrease relative to the other colors of light. This variation in the differential color output will change the color balance of the display and is much more noticeable than a decrease in overall luminance. This can be avoided partially by adjusting color balance, but this may require advanced control circuits and interaction with the user, which is unacceptable for users. More commonly, though, manufacturers optimize the size of the R, G and B subpixels to reduce the current density through the subpixel in order to equalize lifetime at full luminance. For example, a blue subpixel may be 100% larger than the green subpixel. The red subpixel may be 10% smaller than the green.\nImprovements to the efficiency and lifetime of blue OLEDs is vital to the success of OLEDs as replacements for LCD technology. Considerable research has been invested in developing blue OLEDs with high external quantum efficiency as well as a deeper blue color. External quantum efficiency values of 20% and 19% have been reported for red (625 nm) and green (530 nm) diodes, respectively. However, blue diodes (430 nm) have only been able to achieve maximum external quantum efficiencies in the range of 4% to 6%.\nWater can instantly damage the organic materials of the displays. Therefore, improved sealing processes are important for practical manufacturing. Water damage especially may limit the longevity of more flexible displays.\nAs an emissive display technology, OLEDs rely completely upon converting electricity to light, unlike most LCDs which are to some extent reflective. E-paper leads the way in efficiency with ~ 33% ambient light reflectivity, enabling the display to be used without any internal light source. The metallic cathode in an OLED acts as a mirror, with reflectance approaching 80%, leading to poor readability in bright ambient light such as outdoors. However, with the proper application of a circular polarizer and antireflective coatings, the diffuse reflectance can be reduced to less than 0.1%. With 10,000 fc incident illumination (typical test condition for simulating outdoor illumination), that yields an approximate photopic contrast of 5:1. Recent advances in OLED technologies, however, enable OLEDs to become actually better than LCDs in bright sunlight. The Super AMOLED display in the Galaxy S5, for example, was found to outperform all LCD displays on the market in terms of brightness and reflectance.\nWhile an OLED will consume around 40% of the power of an LCD displaying an image that is primarily black, for the majority of images it will consume 60–80% of the power of an LCD. However, an OLED can use more than three times as much power to display an image with a white background, such as a document or web site. This can lead to reduced battery life in mobile devices when white backgrounds are used.\n\nOLED technology is used in commercial applications such as displays for mobile phones and portable digital media players, car radios and digital cameras among others, as well as lighting. Such portable display applications favor the high light output of OLEDs for readability in sunlight and their low power drain. Portable displays are also used intermittently, so the lower lifespan of organic displays is less of an issue. Prototypes have been made of flexible and rollable displays which use OLEDs' unique characteristics. Applications in flexible signs and lighting are also being developed. OLED lighting offers several advantages over LED lighting, such as higher quality illumination, more diffuse light source, and panel shapes. Philips Lighting have made OLED lighting samples under the brand name \"Lumiblade\" available online and Novaled AG based in Dresden, Germany, introduced a line of OLED desk lamps called \"Victory\" in September, 2011.\n\nNokia introduced OLED mobile phones including the N85 and the N86 8MP, both of which feature an AMOLED display. OLEDs have also been used in most Motorola and Samsung color cell phones, as well as some HTC, LG and Sony Ericsson models. OLED technology can also be found in digital media players such as the Creative ZEN V, the iriver clix, the Zune HD and the Sony Walkman X Series.\n\nThe Google and HTC Nexus One smartphone includes an AMOLED screen, as does HTC's own Desire and Legend phones. However, due to supply shortages of the Samsung-produced displays, certain HTC models will use Sony's SLCD displays in the future, while the Google and Samsung Nexus S smartphone will use \"Super Clear LCD\" instead in some countries.\n\nOLED displays were used in watches made by Fossil (JR-9465) and Diesel (DZ-7086).\n\nOther manufacturers of OLED panels include Anwell Technologies Limited (Hong Kong), AU Optronics (Taiwan), Chimei Innolux Corporation (Taiwan), LG (Korea), and others.\n\nIn 2009, Shearwater Research introduced the Predator as the first color OLED diving computer available with a user replaceable battery.\n\nDuPont stated in a press release in May 2010 that they can produce a 50-inch OLED TV in two minutes with a new printing technology. If this can be scaled up in terms of manufacturing, then the total cost of OLED TVs would be greatly reduced. DuPont also states that OLED TVs made with this less expensive technology can last up to 15 years if left on for a normal eight-hour day.\n\nThe use of OLEDs may be subject to patents held by Universal Display Corporation, Eastman Kodak, DuPont, General Electric, Royal Philips Electronics, numerous universities and others. There are by now thousands of patents associated with OLEDs, both from larger corporations and smaller technology companies.\n\nBlackBerry Limited, the maker of BlackBerry smartphones, uses OLED displays in their BlackBerry 10 devices.\n\nFlexible OLED displays are already being produced and these are used by manufacturers to create curved displays such as the Galaxy S7 Edge but so far there they are not in devices that can be flexed by the consumer. Apart from the screen itself the circuit boards and batteries would need to be flexible. Samsung demonstrated a roll-out display in 2016.\n\nTextiles incorporating OLEDs are an innovation in the fashion world and pose for a way to integrate lighting to bring inert objects to a whole new level of fashion. The hope is to combine the comfort and low cost properties of textile with the OLEDs properties of illumination and low energy consumption. Although this scenario of illuminated clothing is highly plausible, challenges are still a road block. Some issues include: the lifetime of the OLED, rigidness of flexible foil substrates, and the lack of research in making more fabric like photonic textiles.\n\nBy 2004 Samsung, South Korea's largest conglomerate, was the world's largest OLED manufacturer, producing 40% of the OLED displays made in the world, and as of 2010 has a 98% share of the global AMOLED market. The company is leading the world of OLED industry, generating $100.2 million out of the total $475 million revenues in the global OLED market in 2006. As of 2006, it held more than 600 American patents and more than 2800 international patents, making it the largest owner of AMOLED technology patents.\n\nSamsung SDI announced in 2005 the world's largest OLED TV at the time, at . This OLED featured the highest resolution at the time, of 6.22 million pixels. In addition, the company adopted active matrix-based technology for its low power consumption and high-resolution qualities. This was exceeded in January 2008, when Samsung showcased the world's largest and thinnest OLED TV at the time, at 31 inches (78 cm) and 4.3 mm.\n\nIn May 2008, Samsung unveiled an ultra-thin 12.1 inch (30 cm) laptop OLED display concept, with a 1,280×768 resolution with infinite contrast ratio. According to Woo Jong Lee, Vice President of the Mobile Display Marketing Team at Samsung SDI, the company expected OLED displays to be used in notebook PCs as soon as 2010.\n\nIn October 2008, Samsung showcased the world's thinnest OLED display, also the first to be \"flappable\" and bendable. It measures just 0.05 mm (thinner than paper), yet a Samsung staff member said that it is \"technically possible to make the panel thinner\". To achieve this thickness, Samsung etched an OLED panel that uses a normal glass substrate. The drive circuit was formed by low-temperature polysilicon TFTs. Also, low-molecular organic EL materials were employed. The pixel count of the display is 480 × 272. The contrast ratio is 100,000:1, and the luminance is 200 cd/m. The colour reproduction range is 100% of the NTSC standard.\n\nIn the same month, Samsung unveiled what was then the world's largest OLED Television at 40-inch with a Full HD resolution of pixels. In the FPD International, Samsung stated that its 40-inch OLED Panel is the largest size currently possible. The panel has a contrast ratio of 1,000,000:1, a colour gamut of 107% NTSC, and a luminance of 200 cd/m (peak luminance of 600 cd/m).\n\nAt the Consumer Electronics Show (CES) in January 2010, Samsung demonstrated a laptop computer with a large, transparent OLED display featuring up to 40% transparency and an animated OLED display in a photo ID card.\n\nSamsung's latest AMOLED smartphones use their Super AMOLED trademark, with the Samsung Wave S8500 and Samsung i9000 Galaxy S being launched in June 2010. In January 2011 Samsung announced their Super AMOLED Plus displays, which offer several advances over the older Super AMOLED displays: real stripe matrix (50% more sub pixels), thinner form factor, brighter image and an 18% reduction in energy consumption.\n\nAt CES 2012, Samsung introduced the first 55\" TV screen that uses Super OLED technology.\n\nOn January 8, 2013, at CES Samsung unveiled a unique curved 4K Ultra S9 OLED television, which they state provides an \"IMAX-like experience\" for viewers.\n\nOn August 13, 2013, Samsung announced availability of a 55-inch curved OLED TV (model KN55S9C) in the US at a price point of $8999.99.\n\nOn September 6, 2013, Samsung launched its 55-inch curved OLED TV (model KE55S9C) in the United Kingdom with John Lewis.\n\nSamsung introduced the \"Galaxy Round\" smartphone in the Korean market in October 2013. The device features a 1080p screen, measuring , that curves on the vertical axis in a rounded case. The corporation has promoted the following advantages: A new feature called \"Round Interaction\" that allows users to look at information by tilting the handset on a flat surface with the screen off, and the feel of one continuous transition when the user switches between home screens.\n\nThe Sony CLIÉ PEG-VZ90 was released in 2004, being the first PDA to feature an OLED screen. Other Sony products to feature OLED screens include the MZ-RH1 portable minidisc recorder, released in 2006 and the Walkman X Series.\n\nAt the 2007 Las Vegas Consumer Electronics Show (CES), Sony showcased 11-inch (28 cm, resolution 960×540) and 27-inch (68.5 cm), full HD resolution at OLED TV models. Both claimed 1,000,000:1 contrast ratios and total thicknesses (including bezels) of 5 mm. In April 2007, Sony announced it would manufacture 1000 11-inch (28 cm) OLED TVs per month for market testing purposes. On October 1, 2007, Sony announced that the 11-inch (28 cm) model, now called the XEL-1, would be released commercially; the XEL-1 was first released in Japan in December 2007.\n\nIn May 2007, Sony publicly unveiled a video of a 2.5-inch flexible OLED screen which is only 0.3 millimeters thick. At the Display 2008 exhibition, Sony demonstrated a 0.2 mm thick 3.5 inch (9 cm) display with a resolution of 320×200 pixels and a 0.3 mm thick 11 inch (28 cm) display with 960×540 pixels resolution, one-tenth the thickness of the XEL-1.\n\nIn July 2008, a Japanese government body said it would fund a joint project of leading firms, which is to develop a key technology to produce large, energy-saving organic displays. The project involves one laboratory and 10 companies including Sony Corp. NEDO said the project was aimed at developing a core technology to mass-produce 40 inch or larger OLED displays in the late 2010s.\n\nIn October 2008, Sony published results of research it carried out with the Max Planck Institute over the possibility of mass-market bending displays, which could replace rigid LCDs and plasma screens. Eventually, bendable, see-through displays could be stacked to produce 3D images with much greater contrast ratios and viewing angles than existing products.\n\nSony exhibited a 24.5\" (62 cm) prototype OLED 3D television during the Consumer Electronics Show in January 2010.\n\nIn January 2011, Sony announced the PlayStation Vita handheld game console (the successor to the PSP) will feature a 5-inch OLED screen.\n\nOn February 17, 2011, Sony announced its 25\" (63.5 cm) OLED Professional Reference Monitor aimed at the Cinema and high end Drama Post Production market.\n\nOn June 25, 2012, Sony and Panasonic announced a joint venture for creating low cost mass production OLED televisions by 2013.\n\nAs of 2010, LG Electronics produced one model of OLED television, the 15 inch 15EL9500 and had announced a 31\" (78 cm) OLED 3D television for March 2011. On December 26, 2011, LG officially announced the \"world's largest 55\" OLED panel\" and featured it at CES 2012. In late 2012, LG announces the launch of the 55EM9600 OLED television in Australia.\n\nIn January 2015, LG Display signed a long term agreement with Universal Display Corporation for the supply of OLED materials and the right to use their patented OLED emitters.\n\nBy 2017 brands using LG OLED panels include Panasonic, Sony, Toshiba, Philips and Loewe.\n\nLumiotec is the first company in the world developing and selling, since January 2011, mass-produced OLED lighting panels with such brightness and long lifetime. Lumiotec is a joint venture of Mitsubishi Heavy Industries, ROHM, Toppan Printing, and Mitsui & Co.\nOn June 1, 2011, Mitsubishi installed a 6-meter OLED 'sphere' in Tokyo's Science Museum.\n\nOn January 6, 2011, Los Angeles-based technology company Recom Group introduced the first small screen consumer application of the OLED at the Consumer Electronics Show in Las Vegas. This was a 2.8\" (7 cm) OLED display being used as a wearable video name tag. At the Consumer Electronics Show in 2012, Recom Group introduced the world's first video mic flag incorporating three 2.8\" (7 cm) OLED displays on a standard broadcaster's mic flag. The video mic flag allowed video content and advertising to be shown on a broadcasters standard mic flag.\n\nThe number of automakers using OLEDs is still rare and limited to the high-end of the market. For example, the 2010 Lexus RX features an OLED display instead of a thin film transistor (TFT-LCD) display.\n\nThe Aston Martin DB9 incorporated the first automotive application of the OLED display, namely PMOLED, followed by the 2004 Jeep Grand Cherokee and the Chevrolet Corvette C6.\n\nJapanese manufacturer Pioneer Electronics produced the first car stereos with monochrome OLED displays.\n\nThe 2015 Hyundai Sonata and Kia Soul EV use a 3.5\" white PMOLED display.\n\nBMW plans to use OLEDs in tail lights and interior lights in their future cars; however, OLEDs are currently too dim to be used for brake lights, headlights and indicators.\n\nOn January 6, 2016, Dell announced the Ultrasharp UP3017Q OLED monitor at the Consumer Electronics Show in Las Vegas. The monitor was announced to feature a 30\" 4K UHD OLED panel with a 120 Hz refresh rate, 0.1 millisecond response time, and a contrast ratio of 400,000:1. The monitor was set to sell at a price of $4,999 and release in March, 2016, just a few months later. As the end of March rolled around, the monitor was not released to the market and Dell did not speak on reasons for the delay. Reports suggested that Dell canceled the monitor as the company was unhappy with the image quality of the OLED panel, especially the amount of color drift that it displayed when you viewed the monitor from the sides. On April 13, 2017, Dell finally released the UP3017Q OLED monitor to the market at a price of $3,499 ($1,500 less than its original spoken price of $4,999 at CES 2016). In addition to the price drop, the monitor featured a 60 Hz refresh rate and a contrast ratio of 1,000,000:1. As of June, 2017, the monitor is no longer available to purchase from Dell's website.\n\nApple began using OLED panels in its watches in 2015 and in its laptops in 2016 with the introduction of an OLED touchbar to the MacBook Pro. In 2017, Apple announced the introduction of their tenth anniversary iPhone X with their own optimized OLED display licensed from Universal Display Corporation. Apple has continued the use of the technology in the iPhone X's successors, the iPhone XS and iPhone XS Max.\n\nThe sheer number of OLED manufacturers in the world today seems to guarantee a steady OLED supply. This, however, might not be the case since almost all of the manufacturers rely on a fabrication equipment that is only manufactured by a single company called Canon Tokki. This small company of 343 - a unit of Canon Inc. and located amidst rice fields in a Japanese countryside - is reported to have a near monopoly of the giant OLED-manufacturing vacuum machines capable of producing screens with organic light-emitting diodes. This particular technology allows sharp and vibrant displays that use less energy. Apple has solely relied on Canon Tokki in its bid to introduce its own OLED displays for the iPhones released in 2017.\n\nThe technology itself is a closely guarded secret and is said to have been developed by the father of Teruhisa Tsugami, the current CEO of Canon Tokki. The word \"tokki\" means \"special equipment\" or \"specialized equipment.\" The machine is notable for its 100-meter size and it features a uniquely automated process of OLED display production analogous to making a supercar that is custom-crafted rather than produced in an assembly line.\n\nIn 2014, Mitsubishi Chemical Corporation (MCC), a subsidiary of the Mitsubishi Chemical Holdings developed an OLED panel with a life of 30,000 hours, twice that of conventional OLED panels.\n\nThe search for efficient OLED materials has been extensively supported by simulation methods. By now it is possible to calculate important properties completely computationally, independent of experimental input. This allows cost-efficient pre-screening of materials, prior to expensive synthesis and experimental characterisation.\n\n\n\n"}
{"id": "22219", "url": "https://en.wikipedia.org/wiki?curid=22219", "title": "Ottawa", "text": "Ottawa\n\nOttawa (, ; ) is the capital city of Canada. It stands on the south bank of the Ottawa River in the eastern portion of southern Ontario. Ottawa borders Gatineau, Quebec; the two form the core of the Ottawa–Gatineau census metropolitan area (CMA) and the National Capital Region (NCR). As of 2016, Ottawa had a city population of 964,743 and a metropolitan population of 1,323,783 making it the fourth-largest city and the fifth-largest CMA in Canada.\n\nFounded in 1826 as Bytown, and incorporated as Ottawa in 1855, the city has evolved into the political centre of Canada. Its original boundaries were expanded through numerous annexations and were ultimately replaced by a new city incorporation and amalgamation in 2001 which significantly increased its land area. The city name \"Ottawa\" was chosen in reference to the Ottawa River, the name of which is derived from the Algonquin \"Odawa\", meaning \"to trade\".\n\nOttawa has the most educated population among Canadian cities and is home to a number of post-secondary, research, and cultural institutions, including the National Arts Centre, the National Gallery, and numerous national museums. Ottawa has the highest standard of living in the nation and low unemployment.\n\nWith the draining of the Champlain Sea around ten thousand years ago, the Ottawa Valley became habitable. Local populations used the area for wild edible harvesting, hunting, fishing, trade, travel, and camps for over 6500 years. The Ottawa river valley has archaeological sites with arrow heads, pottery, and stone tools. Three major rivers meet within Ottawa, making it an important trade and travel area for thousands of years. The Algonquins called the Ottawa River \"Kichi Sibi\" or \"Kichissippi\" meaning \"Great River\" or \"Grand River\".\n\nÉtienne Brûlé, widely regarded as the first European to travel up the Ottawa River, passed by Ottawa in 1610 on his way to the Great Lakes. Three years later, Samuel de Champlain wrote about the waterfalls in the area and about his encounters with the Algonquins, who had been using the Ottawa River for centuries. Many missionaries would follow the early explorers and traders. The first maps of the area used the word Ottawa, derived from the Algonquin word \"adawe\" (\"to trade\", used in reference to the area's importance to First Nations traders), to name the river. Philemon Wright, a New Englander, created the first settlement in the area on 7 March 1800 on the north side of the river, across from the present day city of Ottawa in Hull. He, with five other families and twenty-five labourers, set about to create an agricultural community called Wrightsville. Wright pioneered the Ottawa Valley timber trade (soon to be the area's most significant economic activity) by transporting timber by river from the Ottawa Valley to Quebec City. Bytown, Ottawa's original name, was founded as a community in 1826 when hundreds of land speculators were attracted to the south side of the river when news spread that British authorities were immediately constructing the northerly end of the Rideau Canal military project at that location. The following year, the town was named after British military engineer Colonel John By who was responsible for the entire Rideau Waterway construction project.\n\nThe canal's military purpose was to provide a secure route between Montreal and Kingston on Lake Ontario, bypassing a particularly vulnerable stretch of the St. Lawrence River bordering the state of New York that had left re-supply ships bound for southwestern Ontario easily exposed to enemy fire during the War of 1812. Colonel By set up military barracks on the site of today's Parliament Hill. He also laid out the streets of the town and created two distinct neighbourhoods named \"Upper Town\" west of the canal and \"Lower Town\" east of the canal. Similar to its Upper Canada and Lower Canada namesakes, historically \"Upper Town\" was predominantly English speaking and Protestant whereas \"Lower Town\" was predominantly French, Irish and Catholic. Bytown's population grew to 1,000 as the Rideau Canal was being completed in 1832. Bytown encountered some impassioned and violent times in her early pioneer period that included Irish labour unrest that attributed to the Shiners' War from 1835 to 1845 and political dissension that was evident from the 1849 Stony Monday Riot. In 1855 Bytown was renamed \"Ottawa\" and incorporated as a city. William Pittman Lett was installed as the first city clerk guiding it through 36 years of development.\nOn New Year's Eve 1857, Queen Victoria, as a symbolic and political gesture, was presented with the responsibility of selecting a location for the permanent capital of the Province of Canada. In reality, Prime Minister John A. Macdonald had assigned this selection process to the Executive Branch of the Government, as previous attempts to arrive at a consensus had ended in deadlock. The \"Queen's choice\" turned out to be the small frontier town of Ottawa for two main reasons: Firstly, Ottawa's isolated location in a back country surrounded by dense forest far from the Canada–US border and situated on a cliff face would make it more defensible from attack. Secondly, Ottawa was approximately midway between Toronto and Kingston (in Canada West) and Montreal and Quebec City (in Canada East). Additionally, despite Ottawa's regional isolation it had seasonal water transportation access to Montreal over the Ottawa River and to Kingston via the Rideau Waterway. By 1854 it also had a modern all season Bytown and Prescott Railway that carried passengers, lumber and supplies the 82-kilometres to Prescott on the Saint Lawrence River and beyond. Ottawa's small size, it was thought, would make it less prone to rampaging politically motivated mobs, as had happened in the previous Canadian capitals. The government already owned the land that would eventually become Parliament Hill which they thought would be an ideal location for building the Parliament Buildings. Ottawa was the only settlement of any substantial size that was already directly on the border of French populated former Lower Canada and English populated former Upper Canada thus additionally making the selection an important political compromise. Queen Victoria made her \"Queen's choice\" very quickly just before welcoming in the New Year.\n\nStarting in the 1850s, entrepreneurs known as lumber barons began to build large sawmills, which became some of the largest mills in the world. Rail lines built in 1854 connected Ottawa to areas south and to the transcontinental rail network via Hull and Lachute, Quebec in 1886. The original Parliament buildings which included the Centre, East and West Blocks were constructed between 1859 and 1866 in the Gothic Revival style. At the time, this was the largest North American construction project ever attempted and Public Works Canada and its architects were not initially well prepared. The Library of Parliament and Parliament Hill landscaping would not be completed until 1876. By 1885 Ottawa was the only city in Canada whose downtown street lights were powered entirely by electricity. In 1889 the Government developed and distributed 60 \"water leases\" (still currently in use) to mainly local industrialists which gave them permission to generate electricity and operate hydroelectric generators at Chaudière Falls. Public transportation began in 1870 with a horsecar system, overtaken in the 1890s by a vast electric streetcar system that lasted until 1959.\n\nThe Hull–Ottawa fire of 1900 destroyed two-thirds of Hull, including 40 per cent of its residential buildings and most of its largest employers along the waterfront. It also spread across the Ottawa River and destroyed about one fifth of Ottawa from the Lebreton Flats south to Booth Street and down to Dow's Lake. On 1 June 1912 the Grand Trunk Railway opened both the Château Laurier hotel and its neighbouring downtown Union Station. On 3 February 1916 the Centre Block of the Parliament buildings was destroyed by a fire. The House of Commons and Senate was temporarily relocated to the then recently constructed Victoria Memorial Museum, now the Canadian Museum of Nature until the completion of the new Centre Block in 1922, the centrepiece of which is a dominant Gothic revival styled structure known as the Peace Tower. The current location of what is now Confederation Square was a former commercial district centrally located in a triangular area downtown surrounded by historically significant heritage buildings which includes the Parliament buildings. It was redeveloped as a ceremonial centre in 1938 as part of the City Beautiful Movement and became the site of the National War Memorial in 1939 and designated a National Historic Site in 1984. A new Central Post Office (now the Privy Council of Canada) was constructed in 1939 beside the War Memorial because the original post office building on the proposed Confederation Square grounds had to be demolished.\n\nOttawa's former industrial appearance was vastly altered by the 1950 Greber Plan. Prime Minister Mackenzie King hired French architect-planner Jacques Greber to design an urban plan for managing development in the National Capital Region, to make it more aesthetically pleasing and more befitting a location for Canada's political centre. Greber's plan included the creation of the National Capital Greenbelt, the Parkway, the Queensway highway system, the relocation of downtown Union Station (now the Government Conference Centre) to the suburbs, the removal of the street car system, the decentralization of selected government offices, the relocation of industries and removal of substandard housing from the downtown and the creation of the Rideau Canal and Ottawa River pathways to name just a few of its recommendations. In 1958 the National Capital Commission was established as a Crown Corporation from the passing of the National Capital Act to implement the Greber Plan recommendations-which it accomplished during the 1960s and 1970s.\n\nIn the previous 50 years, other commissions, plans and projects had failed to implement plans to improve the capital such as the 1899 Ottawa Improvement Commission (OIC), The Todd Plan in 1903, The Holt Report in 1915 and The Federal District Commission (FDC) established in 1927. In 1958 a new City Hall opened on Green Island near Rideau falls where urban renewal had recently transformed this former industrial location into green space. Until then, City Hall had temporarily been located for 27 years (1931–1958) at the Transportation Building adjacent to Union Station and now part of the Rideau Centre. In 2001, Ottawa City Hall returned downtown to a relatively new building (1990) on 110 Laurier Avenue West, the prior home of the now defunct Regional Municipality of Ottawa-Carleton. This new location was close to Ottawa's first (1849–1877) and second (1877–1931) City Halls. This new city hall complex also contained an adjacent 19th century restored heritage building formerly known as the Ottawa Normal School.\n\nFrom the 1960s until the 1980s, the National Capital Region experienced a building boom, which was followed by large growth in the high-tech industry during the 1990s and 2000s. Ottawa became one of Canada's largest high tech cities and was nicknamed Silicon Valley North. By the 1980s, Bell Northern Research (later Nortel) employed thousands, and large federally assisted research facilities such as the National Research Council contributed to an eventual technology boom. The early adopters led to offshoot companies such as Newbridge Networks, Mitel and Corel.\n\nOttawa's city limits had been increasing over the years, but it acquired the most territory on 1 January 2001, when it amalgamated all the municipalities of the Regional Municipality of Ottawa–Carleton into one single city. Regional Chair Bob Chiarelli was elected as the new city's first mayor in the 2000 municipal election, defeating Gloucester mayor Claudette Cain. The city's growth led to strains on the public transit system and on road bridges. On 15 October 2001, a diesel-powered light rail transit (LRT) line was introduced on an experimental basis. Known today as the Trillium Line, it was dubbed the O-Train and connected downtown Ottawa to the southern suburbs via Carleton University. The decision to extend the O-Train, and to replace it with an electric light rail system was a major issue in the 2006 municipal elections where Chiarelli was defeated by businessman Larry O'Brien. After O'Brien's election transit plans were changed to establish a series of light rail stations from the east side of the city into downtown, and for using a tunnel through the downtown core. Jim Watson, the last mayor of Ottawa prior to amalgamation, was re-elected in the 2010 election.\n\nIn October 2012, City Council approved the final Lansdowne Park plan, an agreement with the Ottawa Sports and Entertainment Group that saw a new stadium, increased green space, and housing and retail added to the site. In December 2012, City Council voted unanimously to move forward with the Confederation Line, a 12.5 km light rail transit line, to be fully operational by early 2019.\n\nOttawa is on the south bank of the Ottawa River and contains the mouths of the Rideau River and Rideau Canal. The older part of the city (including what remains of Bytown) is known as \"Lower Town\", and occupies an area between the canal and the rivers. Across the canal to the west lies \"Centretown\" and \"Downtown Ottawa\", which is the city's financial and commercial hub and home to the Parliament of Canada and numerous federal government department headquarters, notably the Privy Council Office. On 29 June 2007, the Rideau Canal, which stretches to Kingston, Fort Henry and four Martello towers in the Kingston area, was recognized as a UNESCO World Heritage Site.\n\nLocated within the major, yet mostly dormant Western Quebec Seismic Zone, Ottawa is occasionally struck by earthquakes. Examples include the 2000 Kipawa earthquake, a magnitude-4.5 earthquake on 24 February 2006, the 2010 Central Canada earthquake, and a magnitude-5.2 earthquake on 17 May 2013.\n\nOttawa sits at the confluence of three major rivers: the Ottawa River, the Gatineau River and the Rideau River. The Ottawa and Gatineau rivers were historically important in the logging and lumber industries and the Rideau as part of the Rideau Canal system for military, commercial and, subsequently, recreational purposes. The Rideau Canal (Rideau Waterway) first opened in 1832 and is 202 km long. It connects the Saint Lawrence River on Lake Ontario at Kingston to the Ottawa River near Parliament Hill. It was able to bypass the unnavigable sections of the Cataraqui and Rideau rivers and various small lakes along the waterway due to flooding techniques and the construction of 47 water transport locks.The Rideau River got its name from early French explorers who thought that the waterfalls located at the point where the Rideau River empties into the Ottawa River resembled a \"curtain\". Hence they began naming the falls and river \"rideau\" which is the French equivalent of the English word for curtain. During part of the winter season the Ottawa section of the canal forms the world's largest skating rink, thereby providing both a recreational venue and a transportation path to downtown for ice skaters (from Carleton University and Dow's Lake to the Rideau Centre and National Arts Centre).\n\nAcross the Ottawa River, which forms the border between Ontario and Quebec, lies the city of Gatineau, itself the result of amalgamation of the former Quebec cities of Hull and Aylmer together with Gatineau. Although formally and administratively separate cities in two separate provinces, Ottawa and Gatineau (along with a number of nearby municipalities) collectively constitute the National Capital Region, which is considered a single metropolitan area. One federal crown corporation, the National Capital Commission, or NCC, has significant land holdings in both cities, including sites of historical and touristic importance. The NCC, through its responsibility for planning and development of these lands, is an important contributor to both cities. Around the main urban area is an extensive greenbelt, administered by the NCC for conservation and leisure, and comprising mostly forest, farmland and marshland.\n\nOttawa has a humid continental climate (Köppen \"Dfb\") with four distinct seasons and is between Zones 5a and 5b on the Canadian Plant Hardiness Scale. The average July maximum temperature is . The average January minimum temperature is \n\nSummers are warm and humid in Ottawa. On average 11 days of the three summer months have temperatures exceeding , or 37 days if the humidex is considered. Average relative humidity averages 54% in the afternoon and 84% by morning.\n\nSnow and ice are dominant during the winter season. On average Ottawa receives of snowfall annually but maintains an average of snowpack throughout the three winter months. An average 16 days of the three winter months experience temperatures below , or 41 days if the wind chill is considered.\n\nSpring and fall are variable, prone to extremes in temperature and unpredictable swings in conditions. Hot days above have occurred as early as April or as late as October. Annual precipitation averages around .\n\nOttawa experiences about 2,130 hours of average sunshine annually (46% of possible). Winds in Ottawa are generally Westerlies averaging 13 km/h but tend to be slightly more dominant during the winter.\n\nThe highest temperature ever recorded in Ottawa was on 4 July 1913, 1 August 1917 and 11 August 1944. The coldest temperature ever recorded was on 29 December 1933.\n\nOttawa is bounded on the east by the United Counties of Prescott and Russell; by Renfrew County and Lanark County in the west; on the south by the United Counties of Leeds and Grenville and the United Counties of Stormont, Dundas and Glengarry; and on the north by the Regional County Municipality of Les Collines-de-l'Outaouais and the City of Gatineau. Modern Ottawa is made up of eleven historic townships, ten of which are from Carleton County and one from Russell.\n\nThe city has a main urban area but many other urban, suburban and rural areas exist within the modern city's limits. The main suburban area extends a considerable distance to the east, west and south of the centre, and it includes the former cities of Gloucester, Nepean and Vanier, the former village of Rockcliffe Park (a high-income neighbourhood which is adjacent to the Prime Minister's official residence at 24 Sussex and the Governor General's residence), and the communities of Blackburn Hamlet and Orléans. The Kanata suburban area includes the former village of Stittsville to the southwest. Nepean is another major suburb which also includes Barrhaven. The communities of Manotick and Riverside South are located on the other side of the Rideau River, and Greely, southeast of Riverside South.\nA number of rural communities (villages and hamlets) lie beyond the greenbelt but are administratively part of the Ottawa municipality. Some of these communities are Burritts Rapids; Ashton; Fallowfield; Kars; Fitzroy Harbour; Munster; Carp; North Gower; Metcalfe; Constance Bay and Osgoode and Richmond. Several towns are located within the federally defined National Capital Region but outside the city of Ottawa municipal boundaries, these include the urban communities of Almonte, Carleton Place, Embrun, Kemptville, Rockland, and Russell.\nIn 2011, the populations of the City of Ottawa and the Ottawa–Gatineau census metropolitan area (CMA) were 883,391 and 1,236,324 respectively. The city had a population density of 316.6 persons per km in 2006, while the CMA had a population density of 196.6 persons per km. It is the second-largest city in Ontario, fourth-largest city in the country, and the fourth-largest CMA in the country.\n\nOttawa's median age of 39.2 is both below the provincial and national averages . Youths under 15 years constituted 16.8% of the total population , while those of retirement age (65 years and older) made up 13.2%. In 2011, females made up 51.5% of the amalgamated Ottawa population.\n\nBetween 1987 and 2002, 131,816 individuals relocated to the city, which represents 75% of the population growth for that period. Over 20 percent of the city's population is foreign-born, with the most common non-Canadian countries of origin being the United Kingdom (8.8% of those foreign-born), China (8.0%), and Lebanon (4.8%). About 6.1% of residents are not Canadian citizens.\n\nMembers of visible minority groups (non-white/European) constitute 23.7%, while those of Aboriginal origin make up 2.1% of the total population. The largest visible minority groups are: Black Canadians: 5.7%, Chinese Canadians: 4.0%, South Asians: 3.9%, and Arabs: 3.7%. Smaller groups include Latin Americans, Southeast Asians, Filipinos, and West Asians.\n\nAround 65% of Ottawa residents describe themselves as Christian , with Catholics accounting for 38.5% of the population and members of Protestant churches 25%. Non-Christian religions are also very well established in Ottawa, the largest being Islam (6.7%), Hinduism (1.4%), Buddhism (1.3%), and Judaism (1.2%). Those with no religious affiliation represent 22.8%.\n\nBilingualism became official policy for the conduct of municipal business in 2002, and 37% of the population can speak both languages , making it the largest city in Canada with both English and French as co-official languages. Those who identify their mother tongue as English constitute 62.4 percent, while those with French as their mother tongue make up 14.2 percent of the population. In terms of respondents' knowledge of one or both official languages, 59.9 percent and 1.5 percent of the population have knowledge of English only and French only, respectively; while 37.2 percent have a \nknowledge of both official languages. The overall Ottawa–Gatineau census metropolitan area (CMA) has a larger proportion of French speakers than Ottawa itself, since Gatineau is overwhelmingly French speaking. An additional 20.4 percent of the population list languages other than English and French as their mother tongue. These include Arabic (3.2%), Chinese (3.0%), Spanish (1.2%), Italian (1.1%), and many others.\n\nOttawa has a high standard of living, low unemployment, and the fourth highest GDP growth rate among major Canadian cities in 2007 at 2.7%, which exceeded the Canadian average of 2.4%. The region of Ottawa-Gatineau has the third highest income of all major Canadian cities. The average gross income in the region amounted to $40,078, an increase of 4.9% compared to the previous year. The annual cost of living rate in 2007 grew 1.9%. Mercer ranks Ottawa with the third highest quality of living of any large city in the Americas, and 16th highest in the world. It is also rated the second cleanest city in Canada, and third cleanest city in the world.\n\nOttawa's primary employers are the Public Service of Canada and the high-tech industry, although tourism and healthcare also represent increasingly sizeable economic activities. The Federal government is the city's largest employer, employing over 110,000 individuals from the National Capital region. The national headquarters for many federal departments are located in Ottawa, particularly throughout Centretown and in the Terrasses de la Chaudière and Place du Portage complexes in Hull. The National Defence Headquarters located in Ottawa is the main command centre for the Canadian Armed Forces and hosts the Department of National Defence. The Ottawa area includes CFS Leitrim, CFB Uplands, and the former CFB Rockcliffe. During the summer, the city hosts the Ceremonial Guard, which performs functions such as the Changing the Guard. As the national capital of Canada, tourism is an important part of Ottawa's economy, particularly after the 150th anniversary of Canada which was centred in Ottawa. The lead-up to the festivities saw much investment in civic infrastructure, upgrades to tourist infrastructure and increases in national cultural attractions. The National Capital Region annually attracts an estimated 7.3 million tourists, who spend about 1.18 billion dollars.\n\nIn addition to the economic activities that come with being the national capital, Ottawa is an important technology centre; in 2015, its 1800 companies employed approximately 63,400 people. The concentration of companies in this industry earned the city the nickname of \"Silicon Valley North\". Most of these companies specialize in telecommunications, software development and environmental technology. Large technology companies such as Nortel, Corel, Mitel, Cognos, Halogen Software, Shopify and JDS Uniphase were founded in the city. Ottawa also has regional locations for Nokia, 3M, Adobe Systems, Bell Canada, IBM and Hewlett-Packard. Many of the telecommunications and new technology are located in the western part of the city (formerly Kanata). The \"tech sector\" was doing particularly well in 2015/2016. \n\nAnother major employer is the health sector, which employs over 18,000 people. Four active general hospitals are in the Ottawa area: Queensway Carleton Hospital, The Ottawa Hospital, Montfort Hospital, and Children's Hospital of Eastern Ontario. Several specialized hospital facilities are also present, such as the University of Ottawa Heart Institute and the Royal Ottawa Mental Health Centre. Nordion, i-Stat and the National Research Council of Canada and OHRI are part of the growing life science sector. Business, finance, administration, and sales and service rank high among types of occupations. Approximately ten percent of Ottawa's GDP is derived from finance, insurance and real estate whereas employment in goods-producing industries is only half the national average. The City of Ottawa is the second largest employer with over 15,000 employees.\n\nIn 2006, Ottawa experienced an increase of 40,000 jobs over 2001 with a five-year average growth that was relatively slower than in the late 1990s. While the number of employees in the federal government stagnated, the high-technology industry grew by 2.4%. The overall growth of jobs in Ottawa-Gatineau was 1.3% compared to the previous year, down to sixth place among Canada's largest cities. The unemployment rate in Ottawa-Gatineau was 5.2% (only in Ottawa: 5.1%), which was below the national average of 6.0%. The economic downturn resulted in an increase in the unemployment rate between April 2008 and April 2009 from 4.7 to 6.3%. In the province, however, this rate increased over the same period from 6.4 to 9.1%.\n\nTraditionally the ByWard Market (in Lower Town), Parliament Hill and the Golden Triangle (both in Centretown – Downtown) have been the focal points of the cultural scenes in Ottawa. Modern thoroughfares such as Wellington Street, Rideau Street, Sussex Drive, Elgin Street, Bank Street, Somerset Street, Preston Street, Richmond Road in Westboro, and Sparks Street are home to many boutiques, museums, theatres, galleries, landmarks and memorials in addition to eating establishments, cafes, bars and nightclubs.\n\nOttawa hosts a variety of annual seasonal activities—such as Winterlude, the largest festival in Canada, and Canada Day celebrations on Parliament Hill and surrounding downtown area, as well as Bluesfest, Canadian Tulip Festival, Ottawa Dragon Boat Festival, Ottawa International Jazz Festival, Fringe Festival and Folk Music Festival, that have grown to become some of the largest festivals of their kind in the world. In 2010, Ottawa's Festival industry received the IFEA \"World Festival and Event City Award\" for the category of North American cities with a population between 500,000 and 1,000,000.\n\nAs Canada's capital, Ottawa has played host to a number of significant cultural events in Canadian history, including the first visit of the reigning Canadian sovereign—King George VI, with his consort, Queen Elizabeth—to his parliament, on 19 May 1939. VE Day was marked with a large celebration on 8 May 1945, the first raising of the country's new national flag took place on 15 February 1965, and the centennial of Confederation was celebrated on 1 July 1967. Elizabeth II was in Ottawa on 17 April 1982, to issue a royal proclamation of the enactment of the Constitution Act. In 1983, Prince Charles and Diana Princess of Wales came to Ottawa for a state dinner hosted by then Prime Minister Pierre Trudeau. In 2011, Ottawa was selected as the first city to receive Prince William, Duke of Cambridge, and Catherine, Duchess of Cambridge during their tour of Canada.\n\nInfluenced by government structures, much of the city's architecture tends to be formalistic and functional; however, the city is also marked by Romantic and Picturesque styles of architecture such as the Parliament Buildings' gothic revival architecture. Ottawa's domestic architecture is dominated by single family homes, but also includes smaller numbers of semi-detached houses, rowhouses, and apartment buildings. Many domestic buildings are clad in brick, with small numbers covered in wood, stone, or siding of different materials; variations are common, depending on neighbourhoods and the age of dwellings within them.\n\nThe skyline has been controlled by building height restrictions originally implemented to keep Parliament Hill and the Peace Tower at visible from most parts of the city. Today, several buildings are slightly taller than the Peace Tower, with the tallest located on Albert Street being the 29-storey Place de Ville (Tower C) at . Federal buildings in the National Capital Region are managed by Public Works Canada, while most of the federal land in the region is managed by the National Capital Commission; its control of much undeveloped land gives the NCC a great deal of influence over the city's development.\n\nAmongst the city's national museums and galleries is the National Gallery of Canada; designed by famous architect Moshe Safdie, it is a permanent home to the Maman sculpture. The Canadian War Museum houses over 3.75 million artifacts and was moved to an expanded facility in 2005. The Canadian Museum of Nature was built in 1905, and underwent a major renovation between 2004 and 2010. Across the Ottawa river in Gatineau is the most visited museum in Canada, the Canadian Museum of History. Designed by Canadian Aboriginal architect Douglas Cardinal, the curving-shaped complex, built at a cost of 340 million USD, also houses the Canadian Children's Museum, the Canadian Postal Museum and a 3D IMAX theatre.\n\nThe city is also home to the Canada Agriculture Museum, the Canada Aviation and Space Museum, the Canada Science and Technology Museum, Billings Estate Museum, Bytown Museum, Canadian Museum of Contemporary Photography, the Bank of Canada Museum, and the Portrait Gallery of Canada.\n\nThe Ottawa Little Theatre, originally called the Ottawa Drama League at its inception in 1913, is the longest-running community theatre company in Ottawa. Since 1969, Ottawa has been the home of the National Arts Centre, a major performing arts venue that houses four stages and is home to the National Arts Centre Orchestra, the Ottawa Symphony Orchestra and Opera Lyra Ottawa. Established in 1975, the Great Canadian Theatre Company specializes in the production of Canadian plays at a local level.\n\nThe Rideau Canal is the oldest continuously operated canal system in North America, and in 2007, it was registered as a UNESCO World Heritage Site. In addition, 24 other National Historic Sites of Canada are in Ottawa, including: the Central Chambers, the Central Experimental Farm, the Château Laurier, Confederation Square, the former Ottawa Teachers' College, Office of the Prime Minister and Privy Council, Laurier House and the Parliament Buildings. Many other properties of cultural value have been designated as having \"heritage elements\" by the City of Ottawa under Part IV of the \"Ontario Heritage Act\".\n\nSport in Ottawa has a history dating back to the 19th century. Ottawa is currently home to four professional sports teams. The Ottawa Senators are a professional ice hockey team playing in the National Hockey League. The Senators play their home games at the Canadian Tire Centre. The Ottawa Redblacks are a professional Canadian Football team playing in the Canadian Football League. Professional soccer club Ottawa Fury FC play in the United Soccer League, the second division in North American pro soccer after Major League Soccer. Both Ottawa Fury FC and the Ottawa Redblacks play their home games at TD Place Stadium. The Ottawa Champions play professional baseball in the Can-Am League at Raymond Chabot Grant Thornton Park, following the departure of the Lynx International League franchise. Several non-professional teams also play in Ottawa, including the Ottawa 67's junior ice hockey team. The city was previously home to a professional basketball team, the Ottawa SkyHawks, of the National Basketball League of Canada\n\nCollegiate teams in various sports compete in Canadian Interuniversity Sport. The Carleton Ravens are nationally ranked in basketball, and the Ottawa Gee-Gees are nationally ranked in football and basketball. Algonquin College has also won numerous national championships. The city is home to an assortment of amateur organized team sports such as soccer, basketball, baseball, curling, rowing, hurling and horse racing. Casual recreational activities, such as skating, cycling, hiking, sailing, golfing, skiing, and fishing/ice fishing are also popular.\n\nThe City of Ottawa is a single-tier municipality, meaning it is in itself a census division and has no county or regional municipality government above it. As a single-tier municipality, Ottawa has responsibility for all municipal services, including fire, emergency medical services, police, parks, roads, sidewalks, public transit, drinking water, storm water, sanitary sewage and solid waste. Ottawa is governed by the 24-member Ottawa City Council consisting of 23 councillors each representing one ward and the mayor, currently Jim Watson, elected in a citywide vote.\n\nAlong with being the capital of Canada, Ottawa is politically diverse in local politics. Most of the city has traditionally supported the Liberal Party. Perhaps the safest areas for the Liberals are the ones dominated by Francophones, especially in Vanier and central Gloucester. Central Ottawa is usually more left-leaning, and the New Democratic Party have won ridings there. Some of Ottawa's suburbs are swing areas, notably central Nepean and, despite its francophone population, Orléans. The southern and western parts of the old city of Ottawa are generally moderate and swing to the Conservative Party. The farther one goes outside the city centre like to Kanata and Barrhaven and rural areas, the voters tend to be increasingly conservative, both fiscally and socially. This is especially true in the former Townships of West Carleton, Goulbourn, Rideau and Osgoode, which are more in line with the conservative areas in the surrounding counties. However, not all rural areas support the Conservative Party. Rural parts of the former township of Cumberland, with a large number of Francophones, traditionally support the Liberal Party, though their support has recently weakened.\n\nAt present, Ottawa is host to 130 embassies. A further 49 countries accredit their embassies and missions in the United States to Canada.\n\nOttawa is served by a number of airlines that fly into the Ottawa Macdonald–Cartier International Airport, as well as two main regional airports Gatineau-Ottawa Executive Airport, and Ottawa/Carp Airport. The city is also served by inter-city passenger rail service at the Ottawa Train Station by Via Rail, located near the Alta Vista neighbourhood, and inter-city bus service operating out of the Ottawa Bus Central Station.\n\nOC Transpo, a department of the city, operates the public transit system. An integrated hub-and-spoke system of services consists of: regular buses traveling on fixed routes in mixed traffic, typical of most urban transit systems; a bus rapid transit (BRT) system which is a high-frequency bus service operating on the transitway (a network of mostly grade-separated dedicated bus lanes within their own right of way) and having full stations with Park & Ride facilities, further supported by on-road reserved bus lanes and priority traffic signal controls; a light rail transit (LRT) system known as the \"O-Train\" operating on one north-south route (the Trillium Line); and a door-to-door bus service for the disabled known as ParaTranspo. Both OC Transpo and the Quebec-based \"Société de transport de l'Outaouais (STO)\" operate bus services between Ottawa and Gatineau.\n\nConstruction is underway on the Confederation Line, a light-rail transit line (LRT), which includes a tunnel through the downtown area featuring three underground stations. The project broke ground in 2013, with operation scheduled to start in 2018. A further 30 kilometers and 19 stations will be built by 2023, referred to as the Stage 2 plan.\n\nThe city is served by two freeway corridors. The primary corridor is east-west and consists of provincial Highway 417 (designated as The Queensway) and Ottawa-Carleton Regional Road 174 (formerly Provincial Highway 17); a north-south corridor, Highway 416 (designated as Veterans' Memorial Highway), connects Ottawa to the rest of the 400-Series Highway network in Ontario at the 401. Highway 417 is also the Ottawa portion of the Trans-Canada Highway. The city also has several scenic parkways (promenades), such as Colonel By Drive, Queen Elizabeth Driveway, the Sir John A. Macdonald Parkway, Rockcliffe Parkway and the Aviation Parkway and has a freeway connection to Autoroute 5 and Autoroute 50, in Gatineau. In 2006, the National Capital Commission completed aesthetic enhancements to Confederation Boulevard, a ceremonial route of existing roads linking key attractions on both sides of the Ottawa River.\n\nNumerous paved multi-use trails wind their way through much of the city, including along the Ottawa River, Rideau River, and Rideau Canal. These pathways are used for transportation, tourism, and recreation. Because many streets either have wide curb lanes or bicycle lanes, cycling is a popular mode of transportation throughout the year. As of 31 December 2015, 900 km of cycling facilities are found in Ottawa, including 435 km of multi use pathways, 8 km of cycle tracks, 200 km of on-road bicycle lanes, and 257 km of paved shoulders. 204 km of new cycling facilities were added between 2011 and 2014. A downtown street that is restricted to pedestrians only, Sparks Street was turned into a pedestrian mall in 1966. On Sundays (since 1960) and selected holidays and events additional avenues and streets are reserved for pedestrian and/or bicycle uses only. In May 2011, The NCC introduced the Capital Bixi bicycle-sharing system.\n\nOttawa is known as one of the most educated cities in Canada, with over half the population having graduated from college and/or university. Ottawa has the highest per capita concentration of engineers, scientists, and residents with PhDs in Canada.\n\nThe city has two main public universities:\n\n\nOttawa also has two main public colleges – Algonquin College and La Cité collégiale. It also has two Catholic universities – Dominican University College and Saint Paul University. Other colleges and universities in nearby areas (namely, the neighbouring city of Gatineau) include the University of Quebec en Outaouais, Cégep de l'Outaouais, and Heritage College.\n\nFour main public school boards exist in Ottawa: English, English-Catholic, French, and French-Catholic. The English-language Ottawa-Carleton District School Board (OCDSB) is the largest board with 147 schools, followed by the English-Catholic Ottawa Catholic School Board with 85 schools. The two French-language boards are the French-Catholic \"Conseil des écoles catholiques du Centre-Est\" with 49 schools, and the French \"Conseil des écoles publiques de l'Est de l'Ontario\" with 37 schools. Ottawa also has numerous private schools which are not part of a board.\n\nThe Ottawa Public Library was created in 1906 as part of the famed Carnegie library system. The library system had 2.3 million items .\n\nThree main daily local newspapers are printed in Ottawa: two English newspapers, the \"Ottawa Citizen\" established as \"the Bytown Packet\" in 1845 and the \"Ottawa Sun\", with weekly circulation of 900,197 and 274,628, respectively, and one French newspaper, \"Le Droit\". Another free commuter daily paper, \"Metro Ottawa\", was added in the 2000s. Several weekly and monthly community papers are also published, including the \"Kitchissippi Times\". Multiple Canadian television broadcast networks and systems, and an extensive number of radio stations, broadcast in both English and French.\n\nIn addition to the market's local media services, Ottawa is home to several national media operations, including CPAC (Canada's national legislature broadcaster) and the parliamentary bureau staff of virtually all of Canada's major newsgathering organizations in television, radio and print. The city is also home to the head office of the Canadian Broadcasting Corporation, although it is not the primary production location of most CBC radio or television programming.\n\nOttawa is twinned with:\n\n"}
{"id": "53307360", "url": "https://en.wikipedia.org/wiki?curid=53307360", "title": "Payability", "text": "Payability\n\nPayability is an American FinTech company based in New York City. Payability provides finance solutions to suppliers of digital marketplaces.\n\nPayability's platform integrates with digital marketplaces, most notably Amazon's. The company offers customers invoice factoring: It purchases suppliers’ accounts receivable, allowing suppliers to get paid for their sales on an expedited schedule.\n\nScott Lynn and Keith Smith founded Payability in 2014.\n\nAccording to Smith, the idea for Payability came when he saw a recurring pain point for the suppliers of online marketplaces like Amazon: Marketplaces often withhold payments from sellers for a number of weeks, creating cash flow challenges for suppliers. In a 2015 interview, Smith pointed out that being unable to access cash from their sales frustrates sellers and limits their ability to replenish inventory or fund marketing campaigns.\n\nPayability began working with mobile app developers in 2015. In 2016 the company expanded to focus on Amazon sellers and vendors on other online marketplaces.\n\nIn August 2016, Payability partnered with Amazon Launchpad to offer financing for startups through Amazon Launchpad Services Hub.\n\nSmith is the founder of BigDoor, a gamification startup that he exited in 2014. He was previously the founder of two other companies, CyberMortgage and Zango.\n\nLynn is the founder of advertising technology company AdKnowledge.\n\n"}
{"id": "34972710", "url": "https://en.wikipedia.org/wiki?curid=34972710", "title": "Perdido (oil platform)", "text": "Perdido (oil platform)\n\nPerdido is the deepest floating oil platform in the world at a water depth of about 2450 meters (8000 feet) operated by the Shell Oil Company in the Gulf of Mexico.\n\nThe Perdido is located in the Perdido fold belt which is a rich discovery of crude oil and natural gas that lies in water that is nearly 8000 feet deep. The platform's peak production will be 100,000 barrels of oil equivalent per day. At 267 meters, the Perdido is nearly as tall as the Eiffel Tower.\n\nThe spar and the topsides of the Perdido were constructed separately and then assembled in its final position in the Gulf of Mexico.\n\nThe Perdido's hull or spar was constructed by Technip in Pori, Finland. A barge shipped the 22,000 tonne spar 13,200 kilometres (8,200 miles) from the Baltic Sea to the Gulf of Mexico. After floating the spar, it was towed to its final home above the Alaminos canyon 320 kilometres (120 miles) from the shore. The spar was rotated by the \"Balder\" from a horizontal to a vertical floating position by pumping water through hoses attached to the spar. It was then anchored by the \"Balder\" to piles in the seafloor.\n\nThe platform has three decks or topsides which support the oil and gas processing units, a drilling rig and living quarters for the workers. The temperature difference between Finland and Texas posed a challenge in assembling the pieces as the components built in cold of northern Europe expand in the heat of the Gulf of Mexico. Computer-guided lasers marked out the measurements to ensure precision. After the decks were constructed, in March 2009 the \"Thialf\" lifted the 9,500 tonne topsides onto four posts on the spar and slotted it into position.\n\nOperated by Shell, with JV partners Chevron (37.5%) and BP (27.5%), the spar acts as a hub for and enables development of three fields Great White, Tobago, and Silvertip. The oil and gas fields beneath the platform lie in a geological formation holding resources estimated at 3-15 billion barrels of oil equivalent according to a report by the BSEE, formerly known as the MMS.\nAt peak production, Perdido processes 100,000 barrels of oil equivalent a day, and 200 million cubic feet of gas.\n\nThe twenty-two oil wells that the Perdido extracts oil from are connected to a 44 kilometre (27 mile) network of pipelines on the ocean floor that link it to five flexible pipes called risers. A workforce of 172 people keep it up and running. They work in 12-hour shifts for 2 weeks followed by 2 weeks off, back on land.\n\nThe platform has extensive safety equipment to protect workers in this remote location.\nIt has the largest rescue boat used on any Shell facility, which has room for 24 people. The living quarters are blast-resistant and the number of fire and gas detectors used is ten times more than any other installations in the Gulf. Perdido's helipad can accommodate two Sikorsky S-92 helicopters that can carry 19 passengers each. This is more than twice the capacity of helicopters usually used in the Gulf. This makes it possible to evacuate the workers faster during an emergency.\n\n\n"}
{"id": "4061679", "url": "https://en.wikipedia.org/wiki?curid=4061679", "title": "Pieter Van den Abeele", "text": "Pieter Van den Abeele\n\nPieter Van den Abeele is a computer programmer, and the founder of the PowerPC-version of Gentoo Linux, a foundation connected with a distribution of the Linux computer operating system. He founded Gentoo for OS X, for which he received a scholarship by Apple Computer. In 2004 Pieter was invited to the OpenSolaris pilot program and assisted Sun Microsystems with building a development eco-system around Solaris. Pieter was nominated for the OpenSolaris Community Advisory Board and managed a team of developers to make Gentoo available on the Solaris operating system as well. Pieter is a co-author of the Gentoo handbook.\n\nThe teams managed by Pieter Van den Abeele have shaped the PowerPC landscape with several \"firsts\". Gentoo/PowerPC was the first distribution to introduce PowerPC Live CDs. Gentoo also beat Apple to releasing a full 64-bit PowerPC userland environment for the IBM PowerPC 970 (G5) processor.\n\nHis Gentoo-based Home Media and Communication System, based on a Freescale Semiconductor PowerPC 7447 processor won the Best of Show award at the inaugural 2005 Freescale Technology Forum in Orlando, Florida. Pieter is also a member of the Power.org consortium and participates in committees and workgroups focusing on disruptive business plays around the Power Architecture.\n"}
{"id": "53108519", "url": "https://en.wikipedia.org/wiki?curid=53108519", "title": "Plant Information Management System", "text": "Plant Information Management System\n\nA Plant Information Management System (PIMS) collects and integrates information about a production process from different sources.\n\nImportant tasks of a PIMS are:\n\n\nManufacturers are:\n\nThere are the following subdivisions:\n\n"}
{"id": "26162030", "url": "https://en.wikipedia.org/wiki?curid=26162030", "title": "Public transport", "text": "Public transport\n\nPublic transport (also known as public transportation, public transit, or mass transit) is transport of passengers by group travel systems available for use by the general public, typically managed on a schedule, operated on established routes, and that charge a posted fee for each trip. Examples of public transport include city buses, trolleybuses, trams (or light rail) and passenger trains, rapid transit (metro/subway/underground, etc.) and ferries. Public transport between cities is dominated by airlines, coaches, and intercity rail. High-speed rail networks are being developed in many parts of the world.\n\nMost public transport systems run along fixed routes with set embarkation/disembarkation points to a prearranged timetable, with the most frequent services running to a headway (e.g.: \"every 15 minutes\" as opposed to being scheduled for any specific time of the day). However, most public transport trips include other modes of travel, such as passengers walking or catching bus services to access train stations. Share taxis offer on-demand services in many parts of the world, which may compete with fixed public transport lines, or compliment them, by bringing passengers to interchanges. Paratransit is sometimes used in areas of low demand and for people who need a door-to-door service. \n\nUrban public transit differs distinctly among Asia, North America, and Europe. In Asia, profit-driven, privately-owned and publicly traded mass transit and real estate conglomerates predominantly operate public transit systems In North America, municipal transit authorities most commonly run mass transit operations. In Europe, both state-owned and private companies predominantly operate mass transit systems, Public transport services can be profit-driven by use of pay-by-the-distance fares or funded by government subsidies in which flat rate fares are charged to each passenger. Services can be fully profitable through high usership numbers and high farebox recovery ratios, or can be regulated and possibly subsidised from local or national tax revenue. Fully subsidised, free of charge services operate in some towns and cities.\n\nFor geographical, historical and economic reasons, differences exist internationally regarding use and extent of public transport. While countries in the Old World tend to have extensive and frequent systems serving their old and dense cities, many cities of the New World have more sprawl and much less comprehensive public transport. The International Association of Public Transport (UITP) is the international network for public transport authorities and operators, policy decision-makers, scientific institutes and the public transport supply and service industry. It has 3,400 members from 92 countries from all over the globe.\n\nConveyances designed for public hire are as old as the first ferries, and the earliest public transport was water transport: on land people walked (sometimes in groups and on pilgrimages, as noted in sources such as the Bible and \"The Canterbury Tales\") or (at least in Eurasia and Africa) rode an animal. Ferries appear in Greek mythology—corpses in ancient Greece were buried with a coin underneath their tongue to pay the ferryman Charon to take them to Hades.\n\nSome historical forms of public transport include the stagecoach, traveling a fixed route between coaching inns, and the horse-drawn boat carrying paying passengers, which was a feature of European canals from their 17th-century origins. The canal itself as a form of infrastructure dates back to antiquity – ancient Egyptians certainly used a canal for freight transportation to bypass the Aswan cataract – and the Chinese also built canals for water transportation as far back as the Warring States period which began in the 5th century BCE. Whether or not those canals were used for for-hire public transport remains unknown; the Grand Canal in China (begun in 486 BCE) served primarily for shipping grain.\n\nThe omnibus, the first organized public transit system within a city, appears to have originated in Paris, France, in 1662, although the service in question failed a few months after its founder, Blaise Pascal, died in August 1662; omnibuses are next known to have appeared in Nantes, France, in 1826. The omnibus was introduced to London in July 1829.\n\nThe first passenger horse-drawn railway opened in 1806: it ran between Swansea and Mumbles in southwest Wales in the United Kingdom.\nIn 1825 George Stephenson built the \"Locomotion\" for the Stockton and Darlington Railway in northeast England, the first public steam railway in the world.\n\nThe first successful electric streetcar was built for 12 miles of track for the Union Passenger Railway in Richmond, Virginia in 1888. Electric streetcars could carry heavier passenger loads than predecessors, which reduced fares and stimulated greater transit use.\nTwo years after the Richmond success, over thirty two thousand electric streetcars were operating in America. Electric streetcars also paved the way for the first subway system in America. Before electric streetcars, steam powered subways were considered. However, most people believed that riders would avoid the smoke filled subway tunnels from the steam engines. In 1894, Boston built the first subway in the United States, an electric streetcar line in a 1.5 mile tunnel under Tremont Street’s retail district. Other cities such as New York quickly followed, constructing hundreds of miles of subway in the following decades.\n\n\nSeven criteria measure the usability of different types of public transport and its overall appeal. The criteria are speed, comfort, safety, cost, proximity, timeliness and directness. Speed is calculated from total journey time including transfers. Proximity means how far passengers must walk or otherwise travel before they can begin the public transport leg of their journey and how close it leaves them to their desired destination. Timeliness is how long they must wait for the vehicle. Directness records how far a journey using public transport deviates from the route.\n\nIn selecting between competing modes of transport, many individuals are strongly motivated by direct cost (travel fare/ ticket price to them) and convenience, as well as being informed by habit. The same individual may accept the lost time and statistically higher risk of accident in private transport, together with the initial, running and parking costs. Loss of control, spatial constriction, overcrowding, high speeds/accelerations, height and other phobias may discourage use of public transport.\n\nActual travel time on public transport becomes a lesser consideration when predictable and when travel itself is reasonably comfortable (seats, toilets, services), and can thus be scheduled and used pleasurably, productively or for (overnight) rest. Chauffeured movement is enjoyed by many people when it is relaxing, safe but not too monotonous. Waiting, interchanging, stops and holdups, for example due to traffic or for security, are discomforting. Jet lag is a human constraint discouraging frequent rapid long-distance East-West commuting, favoring modern telecommunications and VR technologies.\n\nAn airline provides scheduled service with aircraft between airports. Air travel has high speeds, but incurs large waiting times prior to and after travel, and is therefore often only feasible over longer distances or in areas where a lack of ground infrastructure makes other modes of transport impossible. Bush airlines work more similarly to bus stops; an aircraft waits for passengers and takes off when the aircraft is full.\n\nBus services use buses on conventional roads to carry numerous passengers on shorter journeys. Buses operate with low capacity (compared with trams or trains), and can operate on conventional roads, with relatively inexpensive bus stops to serve passengers. Therefore, buses are commonly used in smaller cities, towns, and rural areas, and for shuttle services supplementing other means of transit in large cities. Bus rapid transit is an ambiguous term used for buses operating on dedicated right-of-way, much like a light rail. Trolleybuses are electric buses that receive power from overhead wires for mobility. Online Electric Vehicles are buses that run on a conventional battery, but are recharged frequently at certain points via underground wires.\n\nCoach services use coaches (long-distance buses) for suburb-to-CBD or longer-distance transportation. The vehicles are normally equipped with more comfortable seating, a separate luggage compartment, video and possibly also a toilet. They have higher standards than city buses, but a limited stopping pattern.\n\nPassenger rail transport is the conveyance of passengers by means of wheeled vehicles specially designed to run on railways. Trains allow high capacity on short or long distance, but require track, signalling, infrastructure and stations to be built and maintained. Urban rail transit consists of trams, light rail, rapid transit, people movers, commuter rail, monorail, suspension railways and funiculars.\n\nCommuter rail is part of an urban area's public transport; it provides faster services to outer suburbs and neighboring towns and villages. Trains stop at stations that are located to serve a smaller suburban or town center. The stations are often combined with shuttle bus or park and ride systems. Frequency may be up to several times per hour, and commuter rail systems may either be part of the national railway or operated by local transit agencies.\n\nIntercity rail is long-haul passenger services that connect multiple urban areas. They have few stops, and aim at high average speeds, typically only making one of a few stops per city. These services may also be international.\n\nHigh-speed rail is passenger trains operating significantly faster than conventional rail—typically defined as at least . The most predominant systems have been built in Europe and East Asia, and compared with air travel, offer long-distance rail journeys as quick as air services, have lower prices to compete more effectively and use electricity instead of combustion.\n\nA rapid transit railway system (also called a metro, underground, or subway) operates in an urban area with high capacity and frequency, and grade separation from other traffic.\n\nSystems are able to transport large numbers of people quickly over short distances with little land use. Variations of rapid transit include people movers, small-scale light metro and the commuter rail hybrid S-Bahn. More than 160 cities have rapid transit systems, totalling more than of track and 7,000 stations. Twenty-five cities have systems under construction.\n\nTrams are railborne vehicles that run in city streets or dedicated tracks. They have higher capacity than buses, but must follow dedicated infrastructure with rails and wires either above or below the track, limiting their flexibility.\n\nLight rail is a modern development (and use) of the tram, with dedicated right-of-way not shared with other traffic, (often) step-free access and increased speed. Light rail lines are, thus, essentially modernized interurbans.\n\nPersonal rapid transit is an automated cab service that runs on rails or a guideway. This is an uncommon mode of transportation (excluding elevators) due to the complexity of automation. A fully implemented system might provide most of the convenience of individual automobiles with the efficiency of public transit. The crucial innovation is that the automated vehicles carry just a few passengers, turn off the guideway to pick up passengers (permitting other PRT vehicles to continue at full speed), and drop them off to the location of their choice (rather than at a stop). Conventional transit simulations show that PRT might attract many auto users in problematic medium-density urban areas. A number of experimental systems are in progress. One might compare personal rapid transit to the more labor-intensive taxi or paratransit modes of transportation, or to the (by now automated) elevators common in many publicly accessible areas.\n\nCable-propelled transit (CPT) is a transit technology that moves people in motor-less, engine-less vehicles that are propelled by a steel cable. There are two sub-groups of CPT – gondola lifts and cable cars (railway). Gondola lifts are supported and propelled from above by cables, whereas cable cars are supported and propelled from below by cables.\n\nWhile historically associated with usage in ski resorts, gondola lifts are now finding increased consumption and utilization in many urban areas – built specifically for the purposes of mass transit. Many, if not all, of these systems are implemented and fully integrated within existing public transportation networks. Examples include Metrocable (Medellín), Metrocable (Caracas), Portland Aerial Tram, Roosevelt Island Tramway in New York City, and London's Emirates Air Line.\n\nA ferry is a boat used to carry (or \"ferry\") passengers, and sometimes their vehicles, across a body of water. A foot-passenger ferry with many stops is sometimes called a water bus. Ferries form a part of the public transport systems of many waterside cities and islands, allowing direct transit between points at a capital cost much lower than bridges or tunnels, though at a lower speed. Ship connections of much larger distances (such as over long distances in water bodies like the Mediterranean Sea) may also be called ferry services.\n\nA report published by the UK National Infrastructure Commission in 2018 states that 'cycling is mass transit and must be treated as such'. Cycling infrastructure is normally provided without charge to users because it is cheaper to operate than mechanised transit systems that use sophisticated equipment and do not use human power.. \n\nAll public transport runs on infrastructure, either on roads, rail, airways or seaways. The infrastructure can be shared with other modes, freight and private transport, or it can be dedicated to public transport. The latter is especially valuable in cases where there are capacity problems for private transport. Investments in infrastructure are expensive and make up a substantial part of the total costs in systems that are new or expanding. Once built, the infrastructure will require operating and maintenance costs, adding to the total cost of public transport. Sometimes governments subsidize infrastructure by providing it free of charge, just as is common with roads for automobiles. \n\nInterchanges are locations where passengers can switch from one public transport route to another. This may be between vehicles of the same mode (like a bus interchange), or e.g. between bus and train. It can be between local and intercity transport (such as at a central station or airport).\n\nTimetables (or 'schedules' in North American English) are provided by the transport operator to allow users to plan their journeys. They are often supplemented by maps and fare schemes to help travelers coordinate their travel. Online public transport route planners help make planning easier. Mobile apps are available for multiple transit systems that provide timetables and other service information and, in some cases, allow ticket purchase, some allowing to plan your journey, with time fares zones eg.\n\nServices are often arranged to operate at regular intervals throughout the day or part of the day (known as clock-face scheduling). Often, more frequent services or even extra routes are operated during the morning and evening rush hours. Coordination between services at interchange points is important to reduce the total travel time for passengers. This can be done by coordinating shuttle services with main routes, or by creating a fixed time (for instance twice per hour) when all bus and rail routes meet at a station and exchange passengers. There is often a potential conflict between this objective and optimising the utilisation of vehicles and drivers.\n\nThe main sources of financing are ticket revenue, government subsidies and advertising. The percentage of revenue from passenger charges is known as the farebox recovery ratio. A limited amount of income may come from land development and rental income from stores and vendors, parking fees, and leasing tunnels and rights-of-way to carry fiber optic communication lines.\n\nMost—but not all—public transport requires the purchase of a ticket to generate revenue for the operators. Tickets may be bought either in advance, or at the time of the journey, or the carrier may allow both methods. Passengers may be issued with a paper ticket, a metal or plastic token, or a magnetic or electronic card (smart card, contactless smart card). Sometimes a ticket has to be validated, e.g. a paper ticket has to be stamped, or an electronic ticket has to be checked in.\n\nTickets may be valid for a single (or return) trip, or valid within a certain area for a period of time (see transit pass). The fare is based on the travel class, either depending on the traveled distance, or based on zone pricing.\n\nThe tickets may have to be shown or checked automatically at the station platform or when boarding, or during the ride by a conductor. Operators may choose to control all riders, allowing sale of the ticket at the time of ride. Alternatively, a proof-of-payment system allows riders to enter the vehicles without showing the ticket, but riders may or may not be controlled by a ticket controller; if the rider fails to show proof of payment, the operator may fine the rider at the magnitude of the fare.\n\nMulti-use tickets allow travel more than once. In addition to return tickets, this includes period cards allowing travel within a certain area (for instance month cards), or during a given number of days that can be chosen within a longer period of time (for instance eight days within a month). Passes aimed at tourists, allowing free or discounted entry at many tourist attractions, typically include zero-fare public transport within the city. Period tickets may be for a particular route (in both directions), or for a whole network. A free travel pass allowing free and unlimited travel within a system is sometimes granted to particular social sectors, for example students, elderly, children, employees (\"job ticket\") and the physically or mentally disabled.\n\nZero-fare public transport services are funded in full by means other than collecting a fare from passengers, normally through heavy subsidy or commercial sponsorship by businesses. Several mid-size European cities and many smaller towns around the world have converted their entire bus networks to zero-fare. The only European capital with free public transport is Tallinn. Local zero-fare shuttles or inner-city loops are far more common than city-wide systems. There are also zero-fare airport circulators and university transportation systems.\n\nGovernments frequently opt to subsidize public transport for social, environmental or economic reasons. Common motivations include the desire to provide transport to people who are unable to use an automobile and to reduce congestion, land use and automobile emissions.\n\nSubsidies may take the form of direct payments for financially unprofitable services, but support may also include indirect subsidies. For example, the government may allow free or reduced-cost use of state-owned infrastructure such as railways and roads, to stimulate public transport's economic competitiveness over private transport, that normally also has free infrastructure (subsidized through such things as gas taxes). Other subsidies include tax advantages (for instance aviation fuel is typically not taxed), bailouts if companies that are likely to collapse (often applied to airlines) and reduction of competition through licensing schemes (often applied to taxis and airlines). Private transport is normally subsidized indirectly through free roads and infrastructure, as well as incentives to build car factories and, on occasion, directly via bailouts of automakers.\n\nLand development schemes may be initialized, where operators are given the rights to use lands near stations, depots, or tracks for property development. For instance, in Hong Kong, MTR Corporation Limited and KCR Corporation generate additional profits from land development to partially cover the cost of the construction of the urban rail system.\n\nSome supporters of mass transit believe that use of taxpayer capital to fund mass transit will ultimately save taxpayer money in other ways, and therefore, state-funded mass transit is a benefit to the taxpayer. Some research has supported this position, but the measurement of benefits and costs is a complex and controversial issue. A lack of mass transit results in more traffic, pollution, and road construction to accommodate more vehicles, all costly to taxpayers; providing mass transit will therefore alleviate these costs. (Perhaps, although right-wing think tanks disagree)\n\nIn the United States expansion of public transportation systems is often opposed by critics who see them as vehicles for violent criminals and homeless persons to expand into new areas (to which they would otherwise have to walk). According to the Transportation Research Board, \"[v]iolent crime is perceived as pandemic ... Personal security affects many peoples' [sic] decisions to use public transportation.\" Despite the occasional highly publicized incident, the vast majority of modern public transport systems are well designed and patrolled and generally have low crime rates. Many systems are monitored by CCTV, mirrors, or patrol.\n\nNevertheless, some systems attract vagrants who use the stations or trains as sleeping shelters, though most operators have practices that discourage this.\n\nThough public transit accidents attract far more publicity than car wrecks, public transport has much lower accident rates. Annually, public transit prevents 200,000 deaths, injuries, and accidents had equivalent trips been made by car. The National Safety Council estimates that riding the bus is over 170 times safer than private car.\n\nAlthough there is continuing debate as to the true efficiency of different modes of transportation, mass transit is generally regarded as significantly more energy efficient than other forms of travel. A 2002 study by the Brookings Institution and the American Enterprise Institute found that public transportation in the U.S uses approximately half the fuel required by cars, SUV's and light trucks. In addition, the study noted that \"private vehicles emit about 95 percent more carbon monoxide, 92 percent more volatile organic compounds and about twice as much carbon dioxide and nitrogen oxide than public vehicles for every passenger mile traveled\".\n\nA 2004 study from Lancaster University concluded that there was no environmental benefit to be gained from persuading car or plane travelers to switch to trains. Environmental group Friends of the Earth were skeptical of the findings, claiming the results are not in line with previous studies. The study showed that trains had failed to keep up with the advances that the automotive and aviation industries had made in improved fuel efficiency. Express trains travelling from London to Edinburgh consumed 11.5 litres more fuel per seat than a modern diesel car.\n\nStudies have shown that there is a strong inverse correlation between urban population density and energy consumption per capita, and that public transport could facilitate increased urban population densities, and thus reduce travel distances and fossil fuel consumption.\n\nSupporters of the green movement usually advocate public transportation, because it offers decreased airborne pollution compared to automobiles. A study conducted in Milan, Italy, in 2004 during and after a transportation strike serves to illustrate the impact that mass transportation has on the environment. Air samples were taken between 2 and 9 January, and then tested for methane, carbon monoxide, non-methane hydrocarbons (NMHCs), and other gases identified as harmful to the environment. The figure below is a computer simulation showing the results of the study \"with 2 January showing the lowest concentrations as a result of decreased activity in the city during the holiday season. 9 January showed the highest NMHC concentrations because of increased vehicular activity in the city due to a public transportation strike.\"\n\nBased on the benefits of public transport, the green movement has impacted public policy. For example, the state of New Jersey released \"Getting to Work: Reconnecting Jobs with Transit\". This initiative attempts to relocate new jobs into areas with higher public transportation accessibility. The initiative cites the use of public transportation as being a means of reducing traffic congestion, providing an economic boost to the areas of job relocation, and most importantly, contributing to a green environment by reducing carbon dioxide (CO) emissions.\n\nUsing public transportation can result in a reduction of an individual's carbon footprint. A single person, round trip by car can be replaced using public transportation and result in a net CO emissions reduction of per year. Using public transportation saves CO emissions in more ways than simply travel as public transportation can help to alleviate traffic congestion as well as promote more efficient land use. When all three of these are considered, it is estimated that 37 million metric tons of CO will be saved annually. Another study claims that using public transit instead of private in the U.S. in 2005 would have reduced CO emissions by 3.9 million metric tons and that the resulting traffic congestion reduction accounts for an additional 3.0 million metric tons of CO saved. This is a total savings of about 6.9 million metric tons per year given the 2005 values.\n\nIn order to compare energy impact of public transportation to private transportation, the amount of energy per passenger mile must be calculated. The reason that comparing the energy expenditure per person is necessary is to normalize the data for easy comparison. Here, the units are in per 100 p-km (read as person kilometer or passenger kilometer). In terms of energy consumption, public transportation is better than individual transport in a personal vehicle. In England, bus and rail are popular methods of public transportation, especially in London. Rail provides rapid movement into and out of the city of London while busing helps to provide transport within the city itself. As of 2006–2007, the total energy cost of London's trains was 15 kWh per 100 p-km, about 5 times better than a personal car. For busing in London, it was 32 kWh per 100 p-km, or about 2.5 times that of a personal car. This includes lighting, depots, inefficiencies due to capacity (i.e., the train or bus may not be operating at full capacity at all times), and other inefficiencies. Efficiencies of transport in Japan in 1999 were 68 kWh per 100 p-km for a personal car, 19 kWh per 100 p-km for a bus, 6 kWh per 100 p-km for rail, 51 kWh per 100 p-km for air, and 57 kWh per 100 p-km for sea. These numbers from either country can be used in energy comparison calculations or life cycle assessment calculations.\n\nPublic transportation also provides an arena to test environmentally friendly fuel alternatives, such as hydrogen-powered vehicles. Swapping out materials to create lighter public transportation vehicles with the same or better performance will increase environmental friendliness of public transportation vehicles while maintaining current standards or improving them. Informing the public about the positive environmental effects of using public transportation in addition to pointing out the potential economic benefit is an important first step towards making a difference.\n\nUrban space is a precious commodity and public transport utilises it more efficiently than a car dominant society, allowing cities to be built more compactly than if they were dependent on automobile transport. If public transport planning is at the core of urban planning, it will also force cities to be built more compactly to create efficient feeds into the stations and stops of transport. This will at the same time allow the creation of centers around the hubs, serving passengers' daily commercial needs and public services. This approach significantly reduces urban sprawl. Public land planning for public transportation can be difficult but it is the State and Regional organizations that are responsible to planning and improving public transportation roads and routes. With public land prices booming, there must be a plan to using the land most efficiently for public transportation in order to create better transportation systems. Inefficient land use and poor planning leads to a decrease in accessibility to jobs, education, and health care. \n\nAn important social role played by public transport is to ensure that all members of society are able to travel, not just those with a driving license and access to an automobile—which include groups such as the young, the old, the poor, those with medical conditions, and people banned from driving. Automobile dependency is a name given by policy makers to places where those without access to a private vehicle do not have access to independent mobility.\n\nAbove that, public transportation opens to its users the possibility of meeting other people, as no concentration is diverted from interacting with fellow-travelers due to any steering activities. Adding to the above-said, public transport becomes a location of inter-social encounters across all boundaries of social, ethnic and other types of affiliation.\n\nIn the past, public transport allowed transport at an economy of scale not available through private transport. Nowadays there is considerable debate on the advantages and disadvantages of mass transit. According to the OECD, the advantages of carsharing networks could very well obviate the need for traditional public transport. Advocates of public transport claim that investing in mass transit will ultimately reduce the total transport cost for the public. Time saved can also be significant, as fewer cars can translate to less congestion, and faster speeds for remaining motorists.\n\nTransit-oriented development can both improve the usefulness and efficiency of the public transit system as well as result in increased business for commercial developments.\n\nBecause of the increased traffic and access to transit systems, putting in public transit frequently has a positive effect on real estate prices. For example, the Washington DC Metro system has increased land desirability around its stations, and The Hong Kong metro MTR generates a profit by redeveloping land around and above its stations. Much public opposition to new transit construction can be based on the concern about the impact on neighborhoods of this new economic development. Few localities have the ability to seize and reassign development rights to a private transit operator, as Hong Kong has done.\n\nInvestment in public transport also has secondary positive effects on the local economy, with between $4 and $9 of economic activity resulting from every dollar spent. Many businesses rely on access to a transit system, in particular in cities and countries where access to cars is less widespread, businesses which require large numbers of people going to a same place may not be able to accommodate a large number of cars (concert venues, sport stadia, airports, exhibitions centres...), or businesses where people are not able to use a car (bars, hospitals, or industries in the tourism sector whose customers may not have their cars). Transit systems also have an effect on derived businesses: commercial websites have been founded, such as Hopstop.com, that give directions through mass transit systems; in some cities, such as London, products themed on the local transport system are a popular tourist souvenir. Research in the Washington, DC area shows that public transport does a better job of providing high-skill residents with access to high-skill jobs than it does mid-skill residents to mid-skill jobs and low-skill residents to low-skill jobs.\n\nHowever, public transport projects frequently have very large upfront costs, requiring large investments from either local government or private investors. Initial estimates of project cost and timescale are frequently underestimated, and nearly all public transport requires government subsidies or direct government support in order to remain operational.\n\nThe existence of a transit system can lower land values in some cases, either through influence on a region's demographics and crime rate (actual or perceived), or simply through the ambient noise and other discomforts the system creates.\n\nLonger distance public transport sometimes sell food and drinks on board, or have a dedicated buffet car or dining car. However, some urban transport systems forbid the consumption of food, drink, or even chewing gum when riding on public transport. Sometimes only certain types of food are forbidden with a higher risk of making a mess, e.g. ice creams and chips, and sometimes crisps.\n\nSome systems prohibit carrying open food or beverage containers, even if the food or beverage is not being consumed during the journey.\n\nIn Australia, Canada, India, New Zealand, Norway, Botswana, South Africa, Switzerland, the United States, and most of the European Union, smoking is prohibited in all, or some parts of most public transportation systems due to health and safety issues. Generally smoking is not allowed on buses and trains, while rules concerning stations and waiting platforms differ from system to system. The situation in other countries varies widely, due to varying smoking laws.\n\nMany mass transit systems prohibit the use of audio devices, such as radios, CD players, and MP3 players unless used with earphones through which only the user can hear the audio transmitted.\n\nSome mass transit systems have restricted the use of mobile phones. Long distance train services, such as the Amtrak system in the United States, have \"quiet cars\" where mobile phone usage is prohibited.\n\nSome systems forbid passengers from engaging in conversation with the operator. Others require that passengers who engage in any conversation must keep the noise level low enough that it not be audible to other passengers.\n\nSome systems have regulations on the use of profanity. In the United States, this has been challenged as a free speech issue.\n\nCertain items considered to be problematic are prohibited or regulated on many mass transit systems. These include firearms and other weapons (unless licensed to carry), explosives, flammable items, or hazardous chemicals and substances.\n\nMany systems prohibit live animals, but allow those that are in carrying cases or other closed containers. Additionally, guide dogs for the blind or disabled are usually exempt from these rules.\n\nSome systems prohibit items of a large size that may take up a lot of space, such as non-folding bicycles. But more systems in recent years have been permitting passengers to bring bicycles onboard public transport.\n\nIn Sydney, it is illegal to carry spray cans or permanent markers on board public transport, as they can be used to cause vandalism to the vehicles and stations. This rule also applies to sharp instruments that could damage on the train; such as screwdrivers that could be used to make \"scratchitti\", a form of vandalism where tags are carved into a window.\n\nMany systems have regulations against behavior deemed to be unruly or otherwise disturbing to other passengers. In such cases, it is usually at the discretion of the operator, police officers, or other transit employees to determine what behaviors fit this description.\n\nSome systems have regulations against photography or videography of the system's vehicles, stations, or other property. Those seen holding a mobile phone in a manner consistent with photography are considered to be suspicious for breaking this rule. This is another issue that is challenged in the courts in the United States as a \"Free Speech\" issue. Almost all riders are equipped with cell phones which can take pictures or record what is happening on the lines. Riders are able to record the actions of transit police and transportation system employees.\n\nIn the era when long distance trips took several days, sleeping accommodations were an essential part of transportation. (On land, the lodging involved was often part of the infrastructure: the inn or ryokan, which did not move, sheltered travellers. People also slept on ships at sea.) Today, most airlines, inter-city trains and coaches offer reclining seats and many provide pillows and blankets for overnight travellers. Better sleeping arrangements are commonly offered for a premium fare and include sleeping cars on overnight trains, larger private cabins on ships and aircraft seats that convert into beds. Budget-conscious tourists sometimes plan their trips using overnight train or bus journeys instead of paying for a hotel. The ability to get additional sleep on the way to work is attractive to many commuters using public transport.\n\nBecause night trains or coaches can be cheaper than motels, homeless persons often use these as overnight shelters, as with the famous Line 22 (\"Hotel 22\") in Silicon Valley. Specifically, a local transit route with a long overnight segment and which accepts inexpensive multi-use passes will acquire a reputation as a \"moving hotel\" for people with limited funds. Most transportation agencies actively discourage this. For this and other reasons passengers are often required to exit the vehicle at the end of the line; they can board again in the same or another vehicle, after some waiting. Even a low fare in some cases often deters the poorest individuals, including homeless people.\n\n\n\n"}
{"id": "23831274", "url": "https://en.wikipedia.org/wiki?curid=23831274", "title": "Quobject Designer", "text": "Quobject Designer\n\nQuobject® Designer is a freeware computer software running on MS Windows. It enables easy creation of question object files (quox). Exam questions in the quox format can easily be shared among teachers and quickly combined for rapid creation of worksheets, exams and online quizzes within Quobject Explorer.\n\nThe question object file contains all information for an exam question i.e. question text, pictures, math formulas, number of marks, number of dotted lines for student answer (used when creating a paper version of quiz). The question object file contains also the answer to the question, which is used to create a separate answer sheet when creating a paper version of the quiz/exam. \nOnce the quox file of a question is written the question can easily be configured with other questions to create a written paper containing this question. This configuration occurs by drag and drop within Quobject Explorer. Worksheets created within Quobject Explorer can be exported to a \"quiz\" file which is an ordered zip package of quox files.\n"}
{"id": "2909744", "url": "https://en.wikipedia.org/wiki?curid=2909744", "title": "Radiolysis", "text": "Radiolysis\n\nRadiolysis is the dissociation of molecules by ionizing radiation. It is the cleavage of one or several chemical bonds resulting from exposure to high-energy flux. The radiation in this context is associated with ionizing radiation; radiolysis is therefore distinguished from, for example, photolysis of the Cl molecule into two Cl-radicals, where (ultraviolet or visible) light is used.\n\nFor example, water dissociates under alpha radiation into a hydrogen radical and a hydroxyl radical, unlike ionization of water which produces a hydrogen ion and a hydroxide ion. The chemistry of concentrated solutions under ionizing radiation is extremely complex. Radiolysis can locally modify redox conditions, and therefore the speciation and the solubility of the compounds.\n\nOf all the radiation-chemical reactions that have been studied, the most important is the decomposition of water. When exposed to radiation, water undergoes a breakdown sequence into hydrogen peroxide, hydrogen radicals, and assorted oxygen compounds, such as ozone, which when converted back into oxygen releases great amounts of energy. Some of these are explosive. This decomposition is produced mainly by the alpha particles, which can be entirely absorbed by very thin layers of water.\n\nIt is believed that the enhanced concentration of hydroxyl present in irradiated water in the inner coolant loops of a light-water reactor must be taken into account when designing nuclear power plants, to prevent coolant loss resulting from corrosion.\n\nThe current interest in nontraditional methods for the generation of hydrogen has prompted a revisit of radiolytic splitting of water, where the interaction of various types of ionizing radiation (α, β, and γ) with water produces molecular hydrogen. This reevaluation was further prompted by the current availability of large amounts of radiation sources contained in the fuel discharged from nuclear reactors. This spent fuel is usually stored in water pools, awaiting permanent disposal or reprocessing. The yield of hydrogen resulting from the irradiation of water with β and γ radiation is low (G-values = <1 molecule per 100 electronvolts of absorbed energy) but this is largely due to the rapid reassociation of the species arising during the initial radiolysis. If impurities are present or if physical conditions are created that prevent the establishment of a chemical equilibrium, the net production of hydrogen can be greatly enhanced.\n\nAnother approach uses radioactive waste as an energy source for regeneration of spent fuel by converting sodium borate into sodium borohydride. By applying the proper combination of controls, stable borohydride compounds may be produced and used as hydrogen fuel storage medium.\n\nGas generation by radiolytic decomposition of hydrogen-containing materials, has been an area of concern for the transport and storage of radioactive materials and waste for a number of years. Potentially combustible and corrosive gases can be generated while at the same time, chemical reactions can remove hydrogen, and these reactions can be enhanced by the presence of radiation. The balance between these competing reactions is not well known at this time.\n\nA suggestion has been made that in the early stages of the Earth's development when its radioactivity was almost two orders of magnitude higher than at present, radiolysis could have been the principal source of atmospheric oxygen, which ensured the conditions for the origin and development of life. Molecular hydrogen and oxidants produced by the radiolysis of water may also provide a continuous source of energy to subsurface microbial communities (Pedersen, 1999). Such speculation is supported by a discovery in the Mponeng Gold Mine in South Africa, where the researchers found a community dominated by a new phylotype of \"Desulfotomaculum\", feeding on primarily radiolytically produced H.\n\nPulse radiolysis is a recent method of initiating fast reactions to study reactions occurring on a timescale faster than approximately one hundred microseconds, when simple mixing of reagents is too slow and other methods of initiating reactions have to be used.\n\nThe technique involves exposing a sample of material to a beam of highly accelerated electrons, where the beam is generated by a linac. It has many applications. It was developed in the late 1950s and early 1960s by John Keene in Manchester and Jack W. Boag in London.\n\nFlash photolysis is an alternative to pulse radiolysis that uses high-power light pulses (e.g. from an excimer laser) rather than beams of electrons to initiate chemical reactions. Typically ultraviolet light is used which requires less radiation shielding than required for the X-rays emitted in pulse radiolysis.\n\n\n\n"}
{"id": "41114247", "url": "https://en.wikipedia.org/wiki?curid=41114247", "title": "Stanley Electric", "text": "Stanley Electric\n\nStanley Electric Co., Ltd. (, \"Sutanrē Denki Kabushiki-gaisha\") is a Japanese company, producing electric light sources. Stanley has 36 consolidated subsidiaries, three associated companies, 23 factories in eight countries, offices in 17 countries and over 16,000 employees.\n\nThe main customers for its core business (automotive lighting) are Honda and Nissan. Other customers using Stanley's products include Toyota, Mazda, Suzuki, Mitsubishi, Ford and Chrysler. Stanley is listed in the TOPIX of the Tokyo Stock Exchange.\n\nThe company was founded in 1920 by Takaharu Kitano, who named the company after the British-American explorer Henry Morton Stanley famous for exploring Africa. As the company states, Kitano was impressed by Stanley's vision, courage and pioneering spirit. At that time, only about 8,000 cars were present in Japan, all of them imported.\n\n\nStanley's products include standard headlights (HID) as well as LED headlights. Stanley developed the world's first LED high-mount stop lamp.\n\nStanley also produces all types of automotive lighting, backlighted LED displays, camera flashes, automotive interior displays, sensors, light fixtures and streetlights, as used in Shanghai and Tokyo.\nFrom 2013 onward, Stanley will concentrate more on the development of LED headlights and plans to raise the LED share from 1% to 20% by 2017.\n\nStanley does R&D at 5 research centers in Japan, where new light sources are explored, present light sources are optimized and new products are developed. One of those centers is located in the city of Tsukuba. Besides that, picoprojectors with MEMS and biotechnology are explored. Research results are regularly published in scientific journals.\n\nStanley sells its products under the brand name Raybrig directly to customers and also sponsors Team Kunimitsu in the Super GT.\n\nFounder Kitano also established the Kitano foundation for lifelong education, which awards scholarships to people who can not afford education. The foundation is active in China, Vietnam, the Philippines, India and other countries.\n\nStanley takes part in illumination events worldwide. At festivities marking 150 years of Japanese-German friendship, the Brandenburg gate in Berlin was illuminated with LED floodlights. The Kabuki-za in the Ginza is illuminated every evening by Stanley's LEDs. Both events were conducted in cooperation with lighting artist Makoto Ishii.\n\n"}
{"id": "34911137", "url": "https://en.wikipedia.org/wiki?curid=34911137", "title": "Teller system", "text": "Teller system\n\nA teller system is the integrated hardware and software used for retail or wholesale banking transactions, most systems communicate with a core banking system or mainframe over a secured network. The hardware may include a computer or terminal, Cash Drawers, Receipt and Passbook Validator/Printers, magnetic strip readers, pin keypads, bill counters, and bill/coin dispensers. The software is usually based on client/server where several clients (teller stations) are networked to a server which communicates to the mainframe via a dedicated line or satellite.\n\n\n"}
{"id": "49105", "url": "https://en.wikipedia.org/wiki?curid=49105", "title": "Vacuum cleaner", "text": "Vacuum cleaner\n\nA vacuum cleaner, also known as a sweeper or hoover, is a device that uses an air pump (a centrifugal fan in all but some of the very oldest models), to create a partial vacuum to suck up dust and dirt, usually from floors, and from other surfaces such as upholstery and draperies.\n\nThe dirt is collected by either a dustbag or a cyclone for later disposal. Vacuum cleaners, which are used in homes as well as in industry, exist in a variety of sizes and models—small battery-powered hand-held devices, wheeled canister models for home use, domestic central vacuum cleaners, huge stationary industrial appliances that can handle several hundred litres of dust before being emptied, and self-propelled vacuum trucks for recovery of large spills or removal of contaminated soil. Specialized shop vacuums can be used to suck up both dust and liquids.\n\nAlthough \"vacuum cleaner\" and the short form \"vacuum\" are neutral names, in some countries (UK, Ireland) \"hoover\" is used instead as a genericized trademark, and as a verb. The name comes from the Hoover Company, one of the first and more influential companies in the development of the device. The device is also sometimes called a \"sweeper\" although the same term also refers to a carpet sweeper, a similar invention.\n\nThe vacuum cleaner evolved from the carpet sweeper via manual vacuum cleaners. The first manual models, using bellows, were developed in the 1860s, and the first motorized designs appeared at the turn of the 20th century, with the first decade being the boom decade.\n\nIn 1860 a carpet sweeper was invented by Daniel Hess of West Union, Iowa that gathered dust with a rotating brush and a bellows for generating suction.\nAnother early model (1869) was the \"Whirlwind\", invented in Chicago in 1868 by Ives W. McGaffey. The bulky device worked with a belt driven fan cranked by hand that made it awkward to operate, although it was commercially marketed with mixed success.\n\nA similar model was constructed by Melville R. Bissell of Grand Rapids, Michigan in 1876, who also manufactured carpet sweepers. The company later added portable vacuum cleaners to its line of cleaning tools.\n\nThe end of the 19th century saw the introduction of powered cleaners, although early types used some variation of blowing air to clean instead of suction. One appeared in 1898 when John S. Thurman of St. Louis, Missouri submitted a patent (US No. 634,042) for a \"pneumatic carpet renovator\" which blew dust into a receptacle. Thurman's system, powered by an internal combustion engine, traveled to the customers residence on a horse-drawn wagon as part of a door to door cleaning service. Corrine Dufour of Savannah, Georgia received two patents in 1899 and 1900 for another blown air system that seems to have featured the first use of an electric motor.\n\nIn 1901 powered vacuum cleaners using suction were invented independently by British engineer Hubert Cecil Booth and American inventor David T. Kenney. Booth also may have coined the word \"vacuum cleaner\". Booth's horse drawn combustion engine powered \"Puffing Billy\", maybe derived from Thurman's blown air design,\" relied upon just suction with air pumped through a cloth filter and was offered as part of his cleaning services. Kenney's was a stationary 4,000 lb. steam engine powered system with pipes and hoses reaching into all parts of the building.\n\nThe first vacuum-cleaning device to be portable and marketed at the domestic market was built in 1905 by Walter Griffiths, a manufacturer in Birmingham, England. His \"Griffith's Improved Vacuum Apparatus for Removing Dust from Carpets\" resembled modern-day cleaners; – it was portable, easy to store, and powered by \"any one person (such as the ordinary domestic servant)\", who would have the task of compressing a bellows-like contraption to suck up dust through a removable, flexible pipe, to which a variety of shaped nozzles could be attached.\nIn 1906 James B. Kirby developed his first of many vacuums called the \"Domestic Cyclone\". It used water for dirt separation. Later revisions came to be known as the Kirby Vacuum Cleaner. In 1907 department store janitor James Murray Spangler (1848-1915) of Canton, Ohio invented the first portable electric vacuum cleaner, obtaining a patent for the Electric Suction Sweeper on June 2, 1908. Crucially, in addition to suction from an electric fan that blew the dirt and dust into a soap box and one of his wife's pillow cases, Spangler's design utilized a rotating brush to loosen debris. Unable to produce the design himself due to lack of funding, he sold the patent in 1908 to local leather goods manufacturer William Henry Hoover (1849-1932), who had Spangler's machine redesigned with a steel casing, casters, and attachments, founding the company that in 1922 was renamed the Hoover Company. Their first vacuum was the 1908 Model O, which sold for $60. Subsequent innovations included the beater bar in 1919 (\"It beats as it sweeps as it cleans\"), disposal filter bags in the 1920s, and an upright vacuum cleaner in 1926.\n\nIn Continental Europe, the Fisker and Nielsen company in Denmark was the first to sell vacuum cleaners in 1910. The design weighed just and could be operated by a single person. The Swedish company Electrolux launched their Model V in 1921 with the innovation of being able to lie on the floor on two thin metal runners. In the 1930s the Germany company Vorwerk started marketing vacuum cleaners of their own design which they sold through direct sales.\n\nFor many years after their introduction, vacuum cleaners remained a luxury item, but after the Second World War, they became common among the middle classes. Vacuums tend to be more common in Western countries because in most other parts of the world, wall-to-wall carpeting is uncommon and homes have tile or hardwood floors, which are easily swept, wiped or mopped manually without power assist.\n\nThe last decades of the 20th century saw the more widespread use of technologies developed earlier, including filterless cyclonic dirt separation, central vacuum systems and rechargeable hand-held vacuums. In addition, miniaturized computer technology and improved batteries allowed the development of a new type of machine — the autonomous robotic vacuum cleaner. In 1997 Electrolux of Sweden demonstrated the Electrolux Trilobite, the first autonomous cordless robotic vacuum cleaner on the BBC-TV program \"Tomorrow' World\", introducing it to the consumer market in 2001.\n\nIn 2004 a British company released Airider, a hovering vacuum cleaner that floats on a cushion of air, similar to a hovercraft. It has claimed to be light-weight and easier to maneuver (compared to using wheels), although it is not the first vacuum cleaner to do this — the Hoover Constellation predated it by at least 35 years.\n\nA British inventor has developed a new cleaning technology known as Air Recycling Technology, which, instead of using a vacuum, uses an air stream to collect dust from the carpet. This technology was tested by the Market Transformation Programme (MTP) and shown to be more energy-efficient than the vacuum method. Although working prototypes exist, Air Recycling Technology is not currently used in any production cleaner.\n\nA wide variety of technologies, designs, and configurations are available for both domestic and commercial cleaning jobs.\n\nUpright vacuum cleaners are popular in the United States, Britain and numerous Commonwealth countries, but unusual in some Continental European countries. They take the form of a cleaning head, onto which a handle and bag are attached. Upright designs generally employ a rotating brushroll or beater bar, which removes dirt through a combination of sweeping and vibration. There are two types of upright vacuums; dirty-air/direct fan (found mostly on commercial vacuums), or clean-air/fan-bypass (found on most of today's domestic vacuums).\n\nThe older of the two designs, direct-fan cleaners have a large impeller (fan) mounted close to the suction opening, through which the dirt passes directly, before being blown into a bag. The motor is often cooled by a separate cooling fan. Because of their large-bladed fans, and comparatively short airpaths, direct-fan cleaners create a very efficient airflow from a low amount of power, and make effective carpet cleaners. Their \"above-floor\" cleaning power is less efficient, since the airflow is lost when it passes through a long hose, and the fan has been optimized for airflow volume and not suction.\n\nFan-bypass uprights have their motor mounted after the filter bag. Dust is removed from the airstream by the bag, and usually a filter, before it passes through the fan. The fans are smaller, and are usually a combination of several moving and stationary turbines working in sequence to boost power. The motor is cooled by the airstream passing through it. Fan-bypass vacuums are good for both carpet and above-floor cleaning, since their suction does not significantly diminish over the distance of a hose, as it does in direct-fan cleaners. However, their air-paths are much less efficient, and can require more than twice as much power as direct-fan cleaners to achieve the same results.\n\nThe most common upright vacuum cleaners use a drive-belt powered by the suction motor to rotate the brush-roll. However, a more common design of dual motor upright is available. In these cleaners, the suction is provided via a large motor, while the brushroll is powered by a separate, smaller motor, which does not create any suction. The brush-roll motor can sometimes be switched off, so hard floors can be cleaned without the brush-roll scattering the dirt. It may also have an automatic cut-off feature which shuts the motor off if the brush-roll becomes jammed, protecting it from damage.\n\nCanister models (in the UK also often called cylinder models) dominate the European market. They have the motor and dust collector (using a bag or bagless) in a separate unit, usually mounted on wheels, which is connected to the vacuum head by a flexible hose. Their main advantage is flexibility, as the user can attach different heads for different tasks, and maneuverability (the head can reach under furniture and makes it very easy to vacuum stairs and vertical surfaces). Many cylinder models have power heads as standard or add-on equipment containing the same sort of mechanical beaters as in upright units, making them as efficient on carpets as upright models. Such beaters are driven by a separate electric motor or a turbine which uses the suction power to spin the brushroll via a drive belt.\n\nDrum or shop vac models are essentially heavy-duty industrial versions of cylinder vacuum cleaners, where the canister consists of a large vertically positioned drum which can be stationary or on wheels. Smaller versions, for use in garages or small workshops, are usually electrically powered. Larger models, which can store over , are often hooked up to compressed air, utilizing the Venturi effect to produce a partial vacuum. Built-in dust collection systems are also used in many workshops.\n\nWet or wet/dry vacuum cleaners are a specialized form of the cylinder/drum models that can be used to clean up wet or liquid spills. They are generally designed to be used both indoors and outdoors and to accommodate both wet and dry debris; some are also equipped with an exhaust port or detachable blower for reversing the airflow, a useful function for everything from clearing a clogged hose to blowing dust into a corner for easy collection.\n\nPneumatic or pneumatic wet/dry vacuum cleaners are a specialized form of wet/dry models that hook up to compressed air. They commonly can accommodate both wet and dry soilage, a useful feature in industrial plants and manufacturing facilities.\n\nBackpack vacuum cleaners are commonly used for commercial cleaning: they allow the user to move rapidly about a large area. They are essentially small canister vacuums strapped onto the user's back.\n\nLightweight hand-held vacuum cleaners, either powered from rechargeable batteries or mains power, are also popular for cleaning up smaller spills. Frequently seen examples include the Black & Decker DustBuster, which was introduced in 1979, and numerous handheld models by Dirt Devil, which were first introduced in 1984. Some battery-powered handheld vacuums are wet/dry rated; the appliance must be partially disassembled and cleaned after picking up wet materials, to avoid developing unpleasant odors.\n\nIn the late 1990s and early 2000s, several companies developed robotic vacuum cleaners, a form of carpet sweeper usually equipped with limited suction power. Some prominent brands are Roomba, Neato, and bObsweep. These machines move autonomously while collecting surface dust and debris into a dustbin. They can usually navigate around furniture and come back to a docking station to charge their batteries, and a few are able to empty their dust containers into the dock as well. Most models are equipped with motorized brushes and a vacuum motor to collect dust and debris. While most robotic vacuum cleaners are designed for home use, some models are appropriate for operation in offices, hotels, hospitals, etc.\n\nIn December 2009, Neato Robotics launched the world's first robotic vacuum cleaner which uses a rotating laser-based range-finder (a form of lidar) to scan and map its surrounding. It uses this map to clean the floor methodically, even if it requires the robot to return to its base multiple times to recharge itself. In many cases it will notice when an area of the floor that was previously inaccessible becomes reachable, such as when a dog wakes up from a nap, and return to vacuum that area. It also has the strongest impeller among robotic vacuum cleaners, pulling in 35 CFM (1 m/min) of air.\n\nPortable vacuum cleaners working on the cyclonic separation principle became popular in the 1990s. This dirt separation principle was well known and often used in central vacuum systems. Cleveland's P.A. Geier Company had obtained a patent on a cyclonic vacuum cleaner as early as 1928, which was later sold to Health-Mor in 1939, introducing the Filter Queen cyclonic canister vacuum cleaner.\n\nIn 1979, James Dyson introduced a portable unit with cyclonic separation, adapting this design from industrial saw mills. He launched his cyclone cleaner first in Japan in the 1980s at a cost of about US$1800 and in 1993 released the Dyson DC01 upright in the UK for £200. Critics expected that people would not buy a vacuum cleaner at twice the price of a conventional unit, but the Dyson design later became the most popular cleaner in the UK.\n\nCyclonic cleaners do not use filtration bags. Instead, the dust is separated in a detachable cylindrical collection vessel or bin. Air and dust are sucked at high speed into the collection vessel at a direction tangential to the vessel wall, creating a fast-spinning vortex. The dust particles and other debris move to the outside of the vessel by centrifugal force, where they fall due to gravity.\n\nIn fixed-installation central vacuum cleaners, the cleaned air may be exhausted directly outside without need for further filtration. A well-designed cyclonic filtration system loses suction power due to airflow restriction only when the collection vessel is almost full. This is in marked contrast to filter bag systems, which lose suction when pores in the filter become clogged as dirt and dust are collected.\n\nIn portable cyclonic models, the cleaned air from the center of the vortex is expelled from the machine after passing through a number of successively finer filters at the top of the container. The first filter is intended to trap particles which could damage the subsequent filters that remove fine dust particles. The filters must regularly be cleaned or replaced to ensure that the machine continues to perform efficiently.\n\nSince Dyson's success in raising public awareness of cyclonic separation, several other companies have introduced cyclone models. Competing manufacturers include Hoover, Bissell, Shark, Eureka, Electrolux, Filter Queen, etc., and the cheapest models are no more expensive than a conventional cleaner.\n\nCentral vacuum cleaners, also known as built-in or ducted, are a type of canister/cylinder model which has the motor and dirt filtration unit located in a central location in a building, and connected by pipes to fixed vacuum inlets installed throughout the building. Only the hose and cleaning head need be carried from room to room, and the hose is commonly 8 m (25 ft) long, allowing a large range of movement without changing vacuum inlets. Plastic or metal piping connects the inlets to the central unit. The vacuum head may be unpowered, or have beaters operated by an electric motor or by an air-driven turbine.\n\nThe dirt bag or collection bin in a central vacuum system is usually so large that emptying or changing needs to be done less often, perhaps a few times per year for an ordinary household. The central unit usually stays in stand-by, and is turned on by a switch on the handle of the hose. Alternately, the unit powers up when the hose is plugged into the wall inlet, when the metal hose connector makes contact with two prongs in the wall inlet and control current is transmitted through low voltage wires to the main unit.\n\nA central vacuum typically produces greater suction than common portable vacuum cleaners because a larger fan and more powerful motor can be used when they are not required to be portable. A cyclonic separation system, if used, does not lose suction as the collection container fills up, until the container is nearly full. This is in marked contrast to filter-bag designs, which start losing suction immediately as pores in the filter become clogged by accumulated dirt and dust.\n\nA benefit to allergy sufferers is that unlike a standard vacuum cleaner, which must blow some of the dirt collected back into the room being cleaned (no matter how efficient its filtration), a central vacuum removes all the dirt collected to the central unit. Since this central unit is usually located outside the living area, no dust is recirculated back into the room being cleaned. Also it is possible on most newer models to vent the exhaust entirely outside, even with the unit inside the living quarters.\n\nAnother benefit of the central vacuum is, because of the remote location of the motor unit, there is much less noise in the room being cleaned than with a standard vacuum cleaner.\n\nThe Hoover Company marketed an unusual vacuum cleaner, called the \"Constellation\", in the 1960s. The cylinder type lacked wheels, and instead the vacuum cleaner floated on its exhaust, operating as a hovercraft, although this is not true of the earliest models. They had a rotating hose with the intention being that the user would place the unit in the center of the room, and work around the cleaner. Introduced in 1954, they are collectible, and are easily identified by their spherical shape. But they remain an interesting machine; restored, they work well in homes with lots of hardwood floors.\n\nThe Constellations were changed and updated over the years until discontinued in 1975. These Constellations route all of the exhaust under the vacuum using a different airfoil. The updated design is quiet even by modern standards, particularly on carpet as it muffles the sound. These models float on carpet or bare floor—although on hard flooring, the exhaust air tends to scatter any fluff or debris around.\n\nHoover re-released an updated version of this later model Constellation in the US (model # S3341 in Pearl White and # S3345 in stainless steel). Changes include a HEPA filtration bag, a 12-amp motor, a turbine-powered brush roll, and a redesigned version of the handle. This same model was marketed in the UK under the Maytag brand as the \"Satellite\" because of licensing restrictions. It was sold from 2006 to 2009.\n\nSee vacuum truck for very big vacuum cleaners mounted on vehicles.\n\nSome other vacuum cleaners include an electric mop in the same machine: for a dry and a later wet clean.\n\nThe iRobot company developed the Scooba, a robotic wet vacuum cleaner that carries its own cleaning solution, applies it and scrubs the floor, and vacuums the dirty water into a collection tank.\n\nA vacuum's suction is caused by a difference in air pressure. A fan driven by an electric motor (often a universal motor) reduces the pressure inside the machine. Atmospheric pressure then pushes the air through the carpet and into the nozzle, and so the dust is literally pushed into the bag.\n\nTests have shown that vacuuming can kill 100% of young fleas and 96% of adult fleas.\n\nVacuums by their nature cause dust to become airborne, by exhausting air that is not completely filtered. This can cause health problems since the operator ends up inhaling respirable dust, which is also redeposited into the area being cleaned. There are several methods manufacturers use to control this problem, some of which may be combined together in a single appliance. Typically a filter is positioned so that the incoming air passes through it before it reaches the motor, and then the filtered air passes through the motor for cooling purposes. Some other designs use a completely separate air intake for cooling.\n\nIt is nearly impossible for a practical air filter to completely remove all ultrafine particles from a dirt-laden airstream. An ultra-efficient air filter will immediately clog up and become ineffective during everyday use, and practical filters are a compromise between filtering effectiveness and restriction of airflow. One way to sidestep this problem is to exhaust partially filtered air to the outdoors, which is a design feature of some central vacuum systems. Specially engineered portable vacuums may also utilize this design, but are more awkward to set up and use, requiring temporary installation of a separate exhaust hose to an exterior window.\n\n\nOrdinary vacuum cleaners should never be used to clean up asbestos fibers, even if fitted with a HEPA filter. Specially-designed machines are required to safely clean up asbestos.\n\nMost vacuum cleaners are supplied with numerous specialized attachments, such as tools, brushes and extension wands, which allow them to reach otherwise inaccessible places or to be used for cleaning a variety of surfaces. The most common of these tools are:\n\n\nThe performance of a vacuum cleaner can be measured by several parameters:\n\n\nOther specifications of a vacuum cleaner are:\n\nThe suction is the maximum pressure difference that the pump can create. For example, a typical domestic model has a suction of about negative 20 kPa. This means that it can lower the pressure inside the hose from normal atmospheric pressure (about 100 kPa) by 20 kPa. The higher the suction rating, the more powerful the cleaner. One inch of water is equivalent to about 249 Pa; hence, the typical suction is of water.\n\nThe power consumption of a vacuum cleaner, in watts, is often the only figure stated. Many North American vacuum manufacturers give the current only in amperes (e.g. \"6 amps\"), and the consumer is left to multiply that by the line voltage of 120 volts to get the approximate power ratings in watts. The rated input power does not indicate the effectiveness of the cleaner, only how much electricity it consumes.\n\nAfter 1 September 2014, due to EU rules, manufacture of vacuum cleaners with a power consumption greater than 1600 watts will be banned, and from 2017 no vacuum cleaner with a wattage greater than 900 watts will be permitted.\n\nThe amount of input power that is converted into airflow at the end of the cleaning hose is sometimes stated, and is measured in \"airwatts\": the measurement units are simply watts. The word \"air\" is used to clarify that this is output power, not input electrical power.\n\nThe airwatt is derived from English units. ASTM International defines the airwatt as 0.117354 × F × S, where F is the rate of air flow in ft/min and S is the pressure in inches of water. This makes one airwatt equal to 0.9983 watts.\n\n\n\n"}
{"id": "3937853", "url": "https://en.wikipedia.org/wiki?curid=3937853", "title": "Wadley loop", "text": "Wadley loop\n\nThe Wadley loop circuit was designed by Dr. Trevor Wadley in the 1940s in South Africa and was first used for a stable Wavemeter.\n\nIn a traditional superheterodyne radio receiver, most oscillator drift and instability occurs in the first frequency converter stage, because it is tunable and operating at a high frequency. In theory, if one can eliminate this drift, the receiver will be stable.\n\nUnlike other drift-reducing techniques (such as crystal control or frequency synthesis), the Wadley Loop does not attempt to stabilize the oscillator. Instead, it cancels the drift mathematically.\n\nThe Wadley loop works by:\n\n\nSince the high-IF of part 1 drifts in the same direction, and the same amount, as the \"synthetic oscillator\" of part 3, when they are mixed in part 4 the drift terms cancel out and the result is a crystal-stable signal at a second intermediate frequency.\n\nBut the drift makes it impossible to use high-IF selectivity to reject undesired signals. Instead, the high IF is designed with a bandpass characteristic. Also, since the first oscillator is cancelled out, it cannot be used to tune a particular signal. Instead, it selects an entire band of signals - which one depends on which harmonic was chosen in part 3 above. The size of the band is equal to the spacing of the crystal harmonics. A conventionally tuned \"back end\" selects the desired signal from the band of signals presented at the second IF.\n\nLet say we want to pick up signals from 0 to 30 MHz. This is divided into 30 1 MHz bands, which are then translated to a band at 44-45 MHz. To convert 0-1 MHz, the first oscillator must be 45 MHz, to convert 1-2 MHz it must be 46 MHz, and so on. Meanwhile, the first oscillator is also mixed with harmonics from a 1 MHz crystal and put the result through a 42 MHz filter. Only one harmonic gets through. When the first oscillator is 45 MHz, it is the third harmonic, because 45 - 3 = 42. At 46 MHz, it is the fourth harmonic, and so on. The oscillator does not have to be exactly 45, 46, and so on, only close enough to get through the 42 MHz bandpass filter. Let's say it is 45.1 . Then we get 42.1 from the filter, and 45.1 - 42.1 is still 3. When the high IF is mixed with the 42 MHz, the result is a band of signals from 3 MHz to 2 MHz, from which the desired signal is selected, perhaps with a conventional superheterodyne back-end converting 3-2 MHz to 455 kHz and finally demodulating the signal back to audio. The overall receiver drift consists of the crystal's drift plus the 3 MHz back-end, so when we're listening to a 30 MHz signal, this receiver is about ten times as stable as one using a high-frequency tunable VFO.\n\nTo a new user, the feel of the first oscillator tuning control is counterintuitive. Although the knob moves in a continuous, analog fashion, its effect on receiver operation is discrete, that is, the tuning advances in 1 MHz jumps.\n\nAn example is Yaesu's FRG-7 communications receiver, which uses the system to remove local oscillator drift. The Racal RA17 and Realistic DX-302 also used the Wadley Loop in their design.\n\nAn optical implementation of a Wadley Loop has recently been proposed. This allows a compact relatively unstable laser to be used as a local oscillator, with the system stability being obtained from a master 'comb source' (usually a pulsed laser, such as a mode-locked laser), possibly common to many receivers within an exchange.\n"}
{"id": "3797009", "url": "https://en.wikipedia.org/wiki?curid=3797009", "title": "Étienne Lenoir", "text": "Étienne Lenoir\n\nJean Joseph Étienne Lenoir also known as Jean J. Lenoir (12 January 1822 – 4 August 1900) was a Belgian engineer who developed the internal combustion engine in 1858. Prior designs for such engines were patented as early as 1807 (De Rivaz engine), but none were commercially successful. Lenoir's engine was commercialized in sufficient quantities to be considered a success, a first for the internal combustion engine.\n\nHe was born in Mussy-la-Ville (then in Luxembourg, part of the Belgian Province of Luxembourg since 1839). In 1838, he emigrated to France, taking up residence in Paris, where he developed an interest in electroplating. His interest in the subject led him to make several electrical inventions, including an improved electric telegraph.\n\nBy 1859, Lenoir's experimentation with electricity led him to develop the first internal combustion engine which burned a mixture of coal gas and air ignited by a \"jumping sparks\" ignition system by Ruhmkorff coil, and which he patented in 1860. The engine was a steam engine converted to burn gaseous fuel and thus pushed in both directions. The fuel mixture was not compressed before ignition (a system invented in 1801 by Philippe LeBon who developed the use of illuminating gas to light Paris), and the engine was quiet but inefficient, with a power stroke at each end of the cylinder. In 1863, the Hippomobile, with a hydrogen gas fueled, one cylinder, internal combustion engine, made a test drive from Paris to Joinville-le-Pont: top speed about 9 km in ~3 hours.\n\nLenoir was an engineer at Petiene et Cie (Petiene & Company), who supported him in his founding of the companies of \"Corporation Lenoir-Gautier et Cie engines Paris\" and \"Société des Moteurs Lenoir \" in Paris in 1859, with a capitalization of two million \"franc\"s and a factory in the \"Rue de la Roquette\", to develop the engine, and a three-wheeled carriage constructed to use it. Although it ran reasonably well, the engine was fuel inefficient, extremely noisy, tended to overheat, and, if sufficient cooling water was not applied, seize up. Nevertheless, \"Scientific American\" reported, in September 1860, that the Parisian newspaper \"Cosmos\" had pronounced the steam age over. By 1865, 143 had been sold in Paris alone, and production of Lenoir Gas Engines, by Reading Gas Works in London, had begun.\n\nLenoir had completed work on his engine in 1859 and had a grand unveiling on January 23, 1860, for twenty guests. In his speech he said, \"If it works, I will add carburetor heating, at a constant level, which will allow the use of petrol, or gasoline, or tar, or any resin\". He turned on the illuminating gas valve, pushed the flywheel, and the engine came to life. In 1860, Lenoir received a patent for \"an air motor expanded by gas combustion\" from Conservatoire National Des Arts Et Métiers, no. N.43624 \n\nDates vary from 1860 to 1863 on when Lenoir built his automobiles. It is apparent that he built a small carriage with his engine around 1860. His automobile of 1862 was capable of 3 kilometers per hour.\n\nIn 1861, he put one of his engines in a boat.\nIn 1863, Lenoir demonstrated a second three-wheeled carriage, the Hippomobile, little more than a wagon body set atop a tricycle platform. It was powered by a 2543 cc (155 in; 180×100 mm, 7.1×3.9in) 1.5 hp, \"liquid hydrocarbon\" (petroleum) engine with a primitive carburettor which was patented in 1886. It successfully covered the 11 km (7 mi) from Paris to Joinville-le-Pont and back in about ninety minutes each way, an average speed less than that of a walking man (though doubtless there were breakdowns). This succeeded in attracting the attention of Tsar Alexander II, and one was sent to Russia, where it vanished; Lenoir was not pleased. In 1863, he sold his patents to and turned to motorboats, instead, building a naptha (Ligroin) fueled four-cycle in 1888. Jules Verne wrote in his 1863 novel Paris in the Twentieth Century of boulevards crowded with horseless carriages, \"the Lenoir machine applied to locomotion.\"\n\nMost applications of the Lenoir engine were as a stationary power plant powering printing presses, water pumps, and machine tools. They \"proved to be rough and noisy after prolonged use\", however. Other engineers, especially Nikolaus Otto, began making improvements on internal combustion technology, which soon rendered the Lenoir design obsolete. Less than 500 Lenoir engines of between 6 and 20 hp were built, including some under license in Germany.\n\nIn 1865, Lenoir returned to electrical engineering. He developed a new type of automatic telegraph device that could send information in written form. This device was of great value during the Franco-Prussian War. He also installed an improved version of his engine in a 12 meter long boat for a Mr. Dalloz who used it on the Seine for two years.\n\nLenoir was granted French citizenship in 1870 for assistance during the Franco-Prussian War, and awarded the \"Légion d'honneur\" in 1881 (not for the engine, but for developments in telegraphy). Lenoir's later years were impoverished despite his engine's success.\n\nOn July 16, 1900, not long before his death, Lenoir received an award from the ACF (Automobile Club de France), which was a vermeil plate with the inscription, \"In recognition of his great merits as an inventor of the gas engine and builder of the first car in the world.\"\n\nLenoir died in La Varenne-Sainte-Hilaire on 4 August 1900.\n\n\n\n"}
