{"id": "36675591", "url": "https://en.wikipedia.org/wiki?curid=36675591", "title": "1829 braille", "text": "1829 braille\n\nLouis Braille's original publication, \"Procedure for Writing Words, Music, and Plainsong in Dots\" (1829), credits Barbier's night writing as being the basis for the braille script. It differed in a fundamental way from modern braille: It contained nine decades (series) of characters rather than the modern five, utilizing dashes as well as dots. Braille recognized, however, that the dashes were problematic, being difficult to distinguish from the dots in practice, and those characters were abandoned in the second edition of the book.\n\nThe first four decades indicated the 40 letters of the alphabet (39 letters of the French alphabet, plus English \"w\"); the fifth the digits; the sixth punctuation; the seventh and part of the eighth mathematical symbols. The seventh decade was also used for musical notes. Most of the remaining characters were unassigned.\n\nAs in modern braille, most of the higher decades were derived from the first:\n\nThus the 1st and 5th decades occupied only the top half of the cell, while all characters in the other decades had a dot or dash in the bottom row.\n\nThe supplemental signs were and a top dash with . Of the 125 (5³) possible patterns, 97 were used. The modern 5th decade and other supplemental signs do not appear in the 1829 version of braille, apart from and in plainsong notation.\n\nPunctuation differed slightly from today, even accounting for the shift downward when the dash was dropped from the bottom row of the cell. was used for both parentheses, as in modern English braille. was used for either quotation mark; was a pipe. was the question mark, as in modern French braille, while was the asterisk, which is used doubled in English braille.\n\nAnticipating that the dashes might prove problematic, Braille provided that the supplemental sign (now known as the number sign) would shift the decade by four. That is, adding it to the first four decades would produce substitutes for the fifth through eighth. Only its use to replace the old fifth decade has been retained; the old sixth decade survives as the modern fifth, with the dash removed and the dots shifted down to replace it. The original proposal was as follows:\n\nThe book allots a great deal of space to the representation of music. Instrumental notation was largely a one-to-one transcription of the system already in use for the blind. The durations of the notes and the accidentals, however, had to be replaced; for these the 7th decade was used, as shown in the table above.\n\nA simplified system for plainsong was provided. The twelve notes are the twelve characters of the upper half of the cell (the first and fifth decades) which do not have dashes. By themselves (1st decade), they indicate half notes. Quarter notes are 2nd decade, dotted quarter notes 3rd, and eighth notes 4th. Dotted half notes are indicated by a dash below (6th decade), whole notes by a dash above (7th decade), and dotted whole notes by a mid dash (8th decade). The alto, bass, treble, and tenor clefs were indicated by the 5th–8th characters of the fifth decade. is the sharp-note prefix, the bass-note prefix, and the equivalent with a dash the natural prefix. are the repetition sign and 'star'.\n\nThe book finishes with a proposal for braille shorthand, utilizing the first decade for vowels, and the fifth for consonants (without a voicing distinction). That is, Braille's shorthand used a 4-dot cell rather than the standard 6-dot cell, taking two-thirds the space of normal braille, and one-third the space of Barbier's night writing.\n\nIn the classroom, Braille's students found the characters with dashes to be impractical, as the dashes were not easily distinguishable from pairs of dots, and they were quickly abandoned. The second edition of the \"Procédé\", published in 1837, sets out French Braille essentially as we know it today. According to Henri (1952), at right, the numerical sign was used with the new fifth decade, plus one of the supplementary characters, for mathematical notation: +, −, ×, /, =, √. Several of these values continue today in Antoine notation.\n\n"}
{"id": "8321871", "url": "https://en.wikipedia.org/wiki?curid=8321871", "title": "ATM SafetyPIN software", "text": "ATM SafetyPIN software\n\nATM SafetyPIN software is a software application that would allow users of automated teller machines (ATMs) to alert the police of a forced cash withdrawal by entering their personal identification number (PIN) in reverse order. The system was patented by Illinois lawyer Joseph Zingher ().\n\nSafetyPIN is not currently used in ATM systems, despite widely circulated rumors originating from a chain letter e-mail, mainly due to issues regarding reversible PINs being incompatible with the system and potential security vulnerabilities that could arise if implemented.\n\nThe concept of a backup emergency PIN system, or duress code, for ATM systems has been around since at least July 30, 1986, when Representative Mario Biaggi, a former police officer, proposed it in the U.S. Congressional Record, pp. 18232 et seq. Biaggi then proposed House Resolution 785 in 1987 which would have had the FBI track the problem of express kidnappings and evaluate the idea of an emergency PIN system. HR785 died in committee without debate.\n\nZingher has not been successful in marketing licenses for his patent. \nPolice in New York, New Jersey, Ohio, Illinois, and Kansas have supported the concept.\nPolice support prompted the Illinois legislature to pass a law making it mandatory on all ATMs in Illinois. The law was changed shortly after it was passed by a \"follow-on\" bill that changed the meaning to the exact opposite of what they were seeking.\n\nIn 2006, an e-mail chain letter hoax circulated that claimed a reverse PIN duress code system is in place universally. \"American Banker\" reported on January 2, 2007 that no PIN-reversal duress code is used on any ATM as of that date. \nIn September 2013 the hoax was still circulating in Australia with the text:\n\nThe same kind of e-mail chain letter hoax is still circulated on Tumblr and Facebook, as well as in India and other parts of the world.\n\nWere the system implemented, palindromic PINs such as 5555 or 2112 then would be unavailable so that false alarms would not occur. Moreover, PINs that are semi-reversible such as 5255 or 1241, where the first and last numbers are the same, would be something to avoid as well so that accidental alarms would not be triggered by mistakenly switching the middle numbers.\n\nDiebold, a manufacturer of ATMs, states on their website that no such emergency alerting system is currently in use. They cite an article in the St. Louis Post-Dispatch which claims bankers oppose the reverse-PIN system out of concerns that \"ATM users might hesitate or fumble while trying to enter their PINs backwards under duress, possibly increasing the chances of violence.\" Diebold further states that they would be willing to support such technology if their customers (presumably banks) request it.\n\nA bill making the reverse emergency PIN system mandatory on all ATMs in the state of Illinois was proposed on February 10, 2009. Subsection (i) is the new bill.\ni) A terminal operated in this State must be designed and programmed so that when a consumer enters his or her personal identification number in reverse order, the terminal automatically sends an alarm to the local law enforcement agency having jurisdiction over the terminal location. The Commissioner shall promulgate rules necessary for the implementation of this subsection (i).\nIn 2009, Los Angeles City Councilman Greig Smith announced his intention to make the ReversePIN system mandatory on all ATMs in the city.\n"}
{"id": "1983995", "url": "https://en.wikipedia.org/wiki?curid=1983995", "title": "Adobe Captivate", "text": "Adobe Captivate\n\nAdobe Captivate is an authoring tool that is used for creating elearning content such as software demonstrations, software simulations, branched scenarios, and randomized quizzes in Small Web Formats (.swf) and HTML5 formats.\n\nIt can also convert Adobe Captivate-generated file formats (.swf) to digital MP4 (.mp4) formats which can be played with media players or uploaded to video hosting websites. For software simulations, Captivate can use left or right mouse clicks, key presses and rollover images.\n\nIt can also be used to create screencasts, and to convert Microsoft PowerPoint presentations to .swf and HTML5 formats.\n\nWhile the product started out as a pure screen recording utility known as Flashcam (Nexus Concepts 2002), it evolved into an E-learning authoring tool after San Diego-based eHelp Corporation acquired Flashcam and released it as RoboDemo. Eventually, software firm Macromedia acquired eHelp to gain RoboDemo. Shortly before Adobe Systems acquired Macromedia, they changed the name of the product to Captivate.\n\n\n\n\n\n"}
{"id": "22337471", "url": "https://en.wikipedia.org/wiki?curid=22337471", "title": "Aiken tube", "text": "Aiken tube\n\nThe Aiken tube was the first successful flat panel black and white television. Originally designed in the early 1950s, a small number of tubes were built in 1958 for military use in a collaboration with Kaiser Industries. An extended patent battle followed with a similar technology developed in the United Kingdom and planned commercial production for the home market never started. Further development was carried out by a number of companies, including Sinclair Electronics and RCA after the patents had expired.\n\nWilliam Ross Aiken was an electrical engineering undergraduate student at UC Berkeley in 1941. Originally expecting to graduate in the Class of 1942, he decided to take a year off and work in industry. He got a job at the Kaiser Shipyards plant number 2 in Richmond, California, and was promoted to head of the electrical department. When the US entered World War II, Aiken's selective service status was declared as category 1-B. He was one of seven people in the country \"frozen\" in their jobs by Admiral Land and unable to leave their job under any circumstances.\n\nWhen the war ended Aiken was drafted, but declared 4-F due to asthma, and was instead sent to work in industry in a variety of jobs. He spent the next six years working for the University of California Radiation Laboratory, today's Lawrence Livermore National Laboratory, designing controls for the cyclotrons being built there. He was then put in charge of developing an x-ray spectrometer for measuring the temperature of the fireballs from nuclear weapons. While working on these developments he was sent to Eniwetok during a series of nuclear tests.\n\nIt was during this time that he came up with the idea for a new type of thin cathode ray tube (CRT) while he was working with oscilloscopes. He thought the display tubes in use at the time were too long, and a shorter tube would be much more practical. Aiken was not the first to consider the possibility of a compact CRT with a thin display screen, but no-one had been successful in developing one at that point. There were any number of problems, especially with focusing arrangements, but Aiken kept attacking them one by one until he developed what he felt was a workable solution.\n\nHaving sketched out the idea, he went to the U.S. Atomic Energy Commission, his employer at the time, but they didn't find the concept interesting. Returning from Eniwetok he next approached the Radiation Laboratory, but they too declined to take up development. He decided to build a thin CRT prototype on his own. He rented space in the basement of a post office, and developed a working tube that could draw and move a dot around the screen.\n\nIt was one thing to draw a dot on the screen and move it around, it is another entirely to make a working television. Looking for development capital, Aiken started shopping the concept around to anyone who expressed an interest. Warner Brothers sent an engineer to examine it, but declined to fund development believing it was being faked. Walter Baker, the head of General Electric's research labs, called Aiken to set up a meeting, but Aiken demanded they sign a non-disclosure agreement and Baker refused.\n\nAiken then approached some of his old contacts at Kaiser, and they proved much more interested and happy to sign the non-disclosure agreement. After seeing the unit and how it worked they decided to fund development using profits from another division. When they discovered that the profits were due to an accounting error, development almost ended.\n\nBy this time the United States Naval Research Laboratory had heard about his work and were very interested in developing it as an interactive plotting table for displaying the data from sonobuoys in anti-submarine helicopters. They later added an additional role as a heads up display for the T-2 Buckeye trainer, which required a transparent phosphor so the pilot could look through the display and out of the canopy. With their funding secure, Kaiser set up a new laboratory in Palo Alto, California. Shockley Semiconductor collaborated on the development of a small transistorized computer to display basic navigation information, while Corning was brought in to develop the super-flat glass plates needed to front the display. \n\nWhile development continued, Kaiser started looking for partners in the consumer electronics space that might be able to help fund the effort of taking the tube into commercial production. At the time, the NTSC was in the process of introducing its color television standard and enormous amounts of funding were being spent on developing a wide array of technologies in the color market. Kaiser was unable to find anyone interested in developing another black and white system, and after the government contracts ran out, stopped funding development.\n\nIt was about this time that the similar tube developed by Dennis Gabor (better known as the developer of holograms) first came to their attention. Gabor's design was similar in that it used an offset gun and deflection plates behind the phosphor, but differed in having the electron gun arranged under the display area rather than to the side. Aiken had also filed similar patents after his early attempts. A patent battle followed, with Gabor eventually winning UK rights and Aiken U.S. rights. By this point active development of both had ended, and the two became friends.\n\nAiken went on to develop a number of unrelated display technologies, similar to the flip-disc display eventually forming \"Display Technology Corporation\" to produce them.\n\nAiken developed a number of different tube designs while working with Kaiser, a number of which were described in U.S. Patent 2,795,731.\n\nThe primary design used an electron gun arranged to the side of the screen, either firing horizontally across the top of the display tube, or firing vertically towards the top and then bent through 90 degrees to travel along the top. Across the top of the tube were a series of C-shaped plates and a matching set of parallel bars below it. The plates were charged relative to the bars to provide deflection, bending the beam to travel between the bars and down the face of the tube.\n\nBehind the tube was a series of wide metal plates running horizontally along the back face of the display. These were used to bend the beam through an angle and cause it to hit the front face of the screen. 2D scanning was accomplished by charging two of the horizontal plates to select a vertical location on the display, and then quickly charging the deflection plates at the top in turn to select a horizontal location. Each vertical and horizontal plate addressed many locations on the screen, with the locations within each plate's area selected by charging it relative to its neighbors.\n\nThe patents describe a number of different systems for constructing the deflection plates, including both electrostatic and electromagnetic circuits. Switching the plates on and off at high frequencies and high voltages is a major problem, even today, and a number of different systems were described to accomplish this, including an optical-mechanical system similar to the Nipkow disk.\n\nThe second design, described in U.S. Patent 2,837,691, was similar to the first for vertical addressing, but used a conventional horizontal scanning system. The gun was moved to the lower middle of the display, firing upward, scanned horizontally by a single pair of deflection plates arranged just above the gun. Horizontal scanning is much faster than vertical, so this change greatly reduced the complexity of the driver electronics. At the top of the screen was a single wire charged to very high voltages, which bent the beam through 180 degrees back towards the bottom of the display. The vertical deflection plates were mounted on a plate arranged to lie between the path of the beam as it traveled upwards at the back of the tube and back down at the front.\n\n"}
{"id": "10846132", "url": "https://en.wikipedia.org/wiki?curid=10846132", "title": "Avalanche transceiver", "text": "Avalanche transceiver\n\nAvalanche transceivers or avalanche beacons are a class of active radio transceivers operating at 457 kHz and specialized for the purpose of finding people or equipment buried under snow. When the owner sets out on a skiing descent, the transceiver is activated, causing the device to emit a low-power pulsed transceiver signal during the trip. Following an avalanche, and if the holder of the transceiver is safe and has not themselves been caught by the avalanche, they may switch the transceiver from transmit into receive mode, allowing use as a radio direction finding device to search for signals coming from other skiers' transceiver who may be trapped. A 457 kHz transceiver is an active device that requires batteries. A ski suit may also contain a passive RECCO transponder sewn into the clothing.\n\nEarly avalanche transceivers transmitted at 2.275 kHz (2275 Hz). In 1986, the international frequency standard of 457 kHz was adopted, and this remains the standard today. Many companies manufacture transceivers that comply with this standard.\n\nAn avalanche transceiver is not considered a preventive measure against possible avalanche burial, but rather it is a way to reduce the amount of time buried.\n\nIn 1968, Dr. John Lawton invented the first effective avalanche transceiver at Cornell Aeronautical Laboratory in Buffalo, New York, with the first units being sold in 1971 under the “Skadi” brand name (from the mythological Skaði). This unit, functioning at 2.275 kHz, converted the radio frequency to a simple tone audible to the human ear. By following the tone to where it was loudest, the transceiver operator could use it to locate the buried transceiver by using a grid searching technique.\n\nIn 1986, IKAR adopted the frequency of 457 kHz. In 1996 ASTM adopted the 457 kHz standard.\n\nThe following are the currently accepted international standards for Avalanche Transceivers operating on the 457 kHz frequency.\n\nNow that the frequency 457 kHz had become an international standard, and the problems of range had been discussed and analyzed, everyone was most interested in ease of use. With a new generation of entirely automatic apparatuses existing on the market containing a microprocessor that analyzed the beacon's signals or pulses to determine both the direction and distance of the victim, a new digital age was born. In 1997, the first digital beacon was introduced at the Winter Outdoor Retailer show by Backcountry Access under the brand name \"Tracker\". The Tracker DTS soon became the most widely used beacon in North America, and is still sold and used by many backcountry enthusiasts. Today, consumers have a wide range of choices for digital beacons from companies like Ortovox, Arva, Pieps, Mammut, and Backcountry Access. Although beacon technology is constantly evolving and improving, practicing and being familiar with your beacon remains the most important aspect for performing timely rescues and preventing avalanche fatalities.\n\nThere are two types of avalanche beacons: digital and analog. They both adhere to the international standard as described above, and only differ in the method(s) used to indicate to the user where the buried beacon is located. Most beacons currently being sold are digital, because of their enhanced ease of use and higher recovery rates.\n\nThe original avalanche beacon was an analog beacon which transmitted the pulsed signal as an audible tone to the user. The tone gets louder when the user is closer to the transmitting beacon. These beacons have also been augmented with LEDs that provide a visual indication of signal strength, and earpieces to increase the ability of the listener to hear the tone.\n\nDigital transceivers take the strength of the signal and the emitted dipole flux pattern and compute distance and direction to the buried transceiver. In order to calculate the emitted dipole flux pattern, a digital transceiver must have at least two antennas, although most modern transceivers have three. The digital beacons will then indicate the direction to the victim's beacon as an arrow on the display, and provide audio cues such as varying pitch or frequency. Most low- to mid-range beacons have a segmented arrow capable of pointing in five to eight forward directions only, displaying a 'U-Turn' indicator if the user is traveling away from the victim. Higher end beacons such as the Mammut® Pulse Barryvox and Arva® Link are equipped with a digital compass and free-flowing arrow, facilitating more exact direction finding, even rotating to maintain direction between pulses of the transmitting beacon (a feature that is impossible without a digital compass or sophisticated accelerometer). In addition, many higher end beacons can point to victims 360°, including behind the user if the user is moving in the wrong direction. Many digital beacons are also capable of being used in analog mode for more advanced rescuers, or to enhance reception range.\n\nSeveral high-end digital beacons are also equipped with a secondary \"supplementary\" frequency referred to as W-Link. This frequency broadcasts additional details to other transceivers capable of receiving the W-Link signal. Advertised brand-independent features of W-Link include:\n\n\nBeacons transmitting on the W-Link frequency send a specific device code to assist in isolating and pinpointing multiple signals, and facilitate all of the above features. Certain beacons like the Mammut® Pulse Barryvox also detect micro-movements in the user, including the minuscule movement generated by a heart beat. These beacons will transmit this information across the W-Link frequency, so that any user with another W-Link capable transceiver can determine whether or not a buried victim is alive, and formulate rescue triage based on that situation. The idea behind this is that if everyone in a group is wearing a vitals-capable W-Link transceiver and some group members are buried in an avalanche, the remaining group members will be able to determine which of the buried victims are still alive, and focus rescue efforts on those members.\n\nTo compensate for group members without vitals-capable beacons (including lower-end beacons without W-Link and W-Link capable beacons without vitals detection), the rescuer's W-Link beacon will often display two indicators on the display for each victim. One indicator shows that a victim's beacon is transmitting on the W-Link frequency while another shows that the victim is moving. This helps mitigate the potential risk of mis-categorizing an alive victim as dead because their beacon is not transmitting vitals data, and thus the rescuer does not see the \"alive\" indicator on their transceiver.\n\nAs a universal rule, W-Link capable transceivers do not display personally identifiable characteristics of the buried victims, although they are capable of doing this. This is to eliminate conflicts of interest in rescue situations where a rescuer may choose to save one person before (or instead of) another, even if another person is closer or easier to rescue. By not identifying any buried victims, the rescuer is not left with a decision of which person to save, and are spared the moral implications and consequences of his or her choices. Critics of the W-Link system, especially of the vitals-detecting transceivers, argue that even without offering personally identifiable information, the W-Link transceivers still present moral implications, and complicate rescue efforts because these transceivers will distinguish between W-Link capable and incapable victims with an indicator on the display, further segregating victims with a vitals-data capable beacons. Critics argue that this leads to an unfair distribution of rescue resources and personnel to persons with higher-end or newer transceivers, and deprives everyone of an equal chance for rescue. For this reason transceiver manufacturer Arva Equipment has elected to omit received vitals data from being displayed on their Link transceiver, although the beacon does transmit them. A scenario that W-Link critics will use to exemplify their point is as follows:\n\nA four-person group goes on a backcountry tour into avalanche terrain. A husband and his wife are both equipped with the same W-Link, vitals-sensing transceiver. They just met the other two group members the day before. One of them has a basic digital beacon, and the other has a modern, digital W-Link beacon that does not transmit vitals data. Along their tour, three of the group members are caught in an avalanche, leaving only the husband to rescue them. He quickly activates his transceiver and it gets a lock on all three victims. The display shows two beacons 10 and 12 meters directly in front of him, one with W-Link signal and one with regular signal only. It also shows one beacon 33 meters behind him transmitting W-Link and vitals data saying the victim is alive. \n\nIn this scenario, it is clear to distinguish between all three victims even though the transceiver does not display their names; his wife is 33 meters behind him, while the other two people he just met are much closer, and close together, as well. The moral implications are that the man will either choose to save his wife, likely at the expense of the other two group members' lives, or he will rescue one or both of the other group members, allowing his wife to die. In a rescue situation without the additional information, a competent rescuer would triage and initially rescue the two closer victims. If the husband chooses this path, he will have to live with the knowledge that he could have saved his wife but choose not to, for the rest of his life.\n\nThe W-Link frequency in use varies based on geographical location. Currently the frequencies are 869.8 MHz in Region A and 916-926 MHz in Region B. Region A consists of the majority of the European Union, Sweden, Norway, Greenland, Iceland, and other countries in that vicinity. Region B consists of Canada and the United States. W-Link frequencies are not permitted for use in Russia, China, India, Australia, New Zealand, Japan, and other various countries in Asia and Eastern Europe. Users may disable W-Link capabilities on their individual beacon when traveling to these countries, although switching between Regions B and A may require servicing by an authorized retailer.\n\nDue to the highly directional nature of the 457 kHz signal at the ranges common for avalanche burial (and the range specified in the standards), there have been many techniques developed to search for buried beacons. Good beacon search abilities are considered a required skill for recreational backcountry skiers, mountaineers as well as avalanche professionals such as ski guides, ski patrollers, search and rescue volunteers and professionals. Recreationalists and professionals alike take part in drills, practice and scenarios as a regular part of avalanche skills training.\n\nThe burial of a single beacon may involve search using one of several methods:\n\nThese search methods are adapted and extrapolated to scenarios where there is more than one burial.\n\n"}
{"id": "4572695", "url": "https://en.wikipedia.org/wiki?curid=4572695", "title": "Berlin key", "text": "Berlin key\n\nThe Berlin key (also known as, German, \"Schließzwangschlüssel\", or, English, \"forced locking key\") is a key for a type of door lock. It was designed to force people to close and lock their doors (usually a main entrance door or gate leading into a common yard or tenement block). Its particularity comes from the fact that it has two key blades (the part which activates the bolt), one at each end of the key, rather than the usual single blade. After unlocking the lock, the key must be pushed all the way through the lock and retrieved on the other side of the door after it has been closed and locked again. The mechanism makes the retrieval of the key impossible when the door is unlocked. Also, locking an open door is usually not possible.\n\nInvented by the Berliner locksmith Johannes Schweiger, the Berlin key was massively produced by the Albert Kerfin & Co company starting in 1912. With the advent of more recent locking technologies, this kind of lock and key is becoming less common, but it can still be widely found in the tenement buildings of Berlin, Germany. \n\nThe key is subject of the book \"The Berlin Key\" by Science and Technology studies professor Bruno Latour. \n\n"}
{"id": "8510720", "url": "https://en.wikipedia.org/wiki?curid=8510720", "title": "Bus-holder", "text": "Bus-holder\n\nA bus-holder (or Bus-keeper) is a weak latch circuit which holds last value on a tri-state bus.\n\nThe circuit is basically a delay element with the output connected back to the input through a relatively high impedance. This is usually achieved with two inverters connected back to back. The resistor drives the bus weakly; therefore other circuits can override the value of the bus when they are not in tri-state mode.\n\nBus-holders are used to prevent CMOS gate inputs from getting floating values when they are connected to tri-stated nets. Otherwise both transistors in the gate could get turned on, thus shorting the power supply and ground, which would destroy the CMOS gate. This is prevented by the bus-holder pulling the input to the last valid logic level (0 or 1) on the net. The circuit is usually placed in parallel with the tri-stated net.\n\n"}
{"id": "536197", "url": "https://en.wikipedia.org/wiki?curid=536197", "title": "Can opener", "text": "Can opener\n\nA can opener (in North American English and Australian English) or tin opener (in British and Commonwealth English) is a device used to open tin cans (metal cans). Although preservation of food using tin cans had been practiced since at least 1772 in the Netherlands, the first can openers were not patented until 1855 in England and 1858 in the United States. These early openers were basically variations of a knife, though the 1855 design continues to be produced. The first can opener consisting of the now familiar sharp rotating cutting wheel was invented in 1870 but was considered too difficult to operate for the ordinary consumer. A breakthrough design came in 1925 when a second, serrated wheel was added to hold the cutting wheel on the ring of the can. This easy-to-use design has become one of the most popular can opener models.\n\nAround the time of World War II, several can openers were developed for military use, such as the American P-38 and P-51. These featured a robust and compact design with a folding cutting blade and no handle. Electric can openers were introduced in the late 1950s and met with success. The development of new can opener types continues with the recent addition of a side-cutting model.\n\nFood preserved in tin cans was in use by the Dutch Navy from at least 1772. Before 1800, there was already a small industry of canned salmon in the Netherlands. Freshly caught salmon were cleaned, boiled in brine, smoked and placed in tin-plated iron boxes. This canned salmon was known outside the Netherlands, and in 1797 a British company supplied one of their clients with 13 cans. Preservation of food in tin cans was patented by Peter Durand in 1810. The patent was acquired in 1812 by Bryan Donkin, who would later set up the world's first canning factory in London in 1813. By 1820, canned food was a recognized article in Britain and France and by 1822 in the United States. The first cans were robust containers, which weighed more than the food they contained and required ingenuity to open, using whatever tools available. The instruction on those cans read \"Cut round the top near the outer edge with a chisel and hammer.\" The gap of decades between the invention of the can and can opener may be attributed to the functionality of existing tools versus the cost and effort of a new tool.\n\nDedicated can openers appeared in the 1850s and were of a primitive claw-shaped or \"lever-type\" design. In 1855, Robert Yeates, a cutlery and surgical instrument maker of Trafalgar Place West, Hackney Road, Middlesex, UK, devised the first claw-ended can opener with a hand-operated tool that haggled its way around the top of metal cans.\n\nIn 1858, another lever-type opener of a more complex shape was patented in the United States by Ezra Warner of Waterbury, Connecticut. It consisted of a sharp sickle, which was pushed into the can and sawed around its edge. A guard kept the sickle from penetrating too far into the can. The opener consisted of several parts which could be replaced if worn out, especially the sickle. This opener was adopted by the United States Army during the American Civil War (1861–1865); however, its unprotected knife-like sickle was too dangerous for domestic use. A home-use opener named the \"Bull's head opener\" was designed in 1865 and was supplied with cans of pickled beef named \"Bully beef\". The opener was made of cast iron and had a very similar construction to the Yeates opener, but featured a more artistic shape and was the first move towards improving the look of the can opener. The bull-headed design was produced until the 1930s and was also offered with a fish-head shape.\n\nThe first rotating wheel can opener was patented in July 1870 by William Lyman of Meriden, Connecticut and produced by the firm Baumgarten in the 1890s. The can was to be pierced in its center with the sharp metal rod of the opener. Then, the length of the lever had to be adjusted to fit the can size, and the lever fixed with the wingnut. The top of the can was cut by pressing the cutting wheel into the can near the edge and rotating it along the can's rim.\n\nThe necessity to pierce the can first was a nuisance, and this can opener design did not survive. In 1925, the Star Can Opener Company of San Francisco, California had improved Lyman's design by adding a second, serrated wheel, called a \"feed wheel\", which allowed a firm grip of the can edge. This addition was so efficient that the design is still in use today.\n\nWhereas all previous openers required using one hand or other means to hold the can, can-holding openers simultaneously grip the can and open it. The first such opener was patented in 1931 by the Bunker Clancey Company of Kansas City, Missouri and was, therefore, called the \"Bunker\". It featured the now standard pliers-type handles, when squeezed would tightly grip the can rim, while turning the key would rotate the cutting wheel, progressively cutting the lid along the rim. The cutting wheel is coupled to a serrated feed wheel via a set of gears, as in the Star design. The Bunker company was absorbed by the Rival Manufacturing Company, also of Kansas City, in 1938.\n\nChurch key initially referred to a simple hand-operated device for prying the cap (called a \"crown cork\" or \"bottle cap\") off a glass bottle; this kind of closure was invented in 1892. The first of these church key style openers was patented in Canada in 1900. The shape and design of some of these openers did resemble a large simple key. In 1935, steel beer cans with flat tops appeared, and a device to pierce the lids was needed. The same opener was used for piercing those cans. Made from a single piece of pressed metal, with a sharp point at one end, it was devised by D. F. Sampson, for the American Can Company, who depicted operating instructions on the cans. The church key opener is still being produced, sometimes as part of another opener. For example, a \"butterfly\" opener is often a combination of the church key and a serrated-wheel opener.\nThere is sparse, and often contradictory, documentation on the origin of the term \"church key\". The phrase is likely an ironic euphemism, as the opener was obviously not designed to access churches. One explanation is that in Medieval Europe, most brewers were monks. Lager cellars in the monasteries were locked to protect aging beers, and the monks carried keys to these lager cellars. It may have been those keys, which remotely resembled the early church key openers, that gave the \"church key\" opener its name. Another motive for assigning the device such an ironic name could have been the fact beer was first canned (for test marketing) in 1933, the same year president Franklin Delano Roosevelt signed the Cullen-Harrison Bill. This act, which predated Repeal of Prohibition, amended the Volstead Act, making 3.2% low-alcohol beer legal. Some experts have posited the term \"church key\" was in mockery of the religious organizations which had supported Prohibition.\n\nAnother key-type opener with completely different design was patented by J. Osterhoudt in 1866. Instead of piercing the can, it was used to tear off and roll up a pre-scored strip on the side of the can, just below the lid. It was also called \"key\", because of resemblance to a door key. Such openers are spot-welded or soldered to many small, thin-walled cans nowadays and are separated prior to use by prying the key up and bending it back and forth a few times until it breaks loose.\n\nSeveral can openers with a simple and robust design have been specifically developed for military use. The P-38 and P-51 are small can openers with a cutter hinged to the main body. They were also known as a \"John Wayne\" because the actor was shown in a training film opening a can of K-rations. The P-38 can opener is keychain-sized, about 1.5 inches (38 mm) long, and consists of a short metal blade that serves as a handle (and can also be used as a screwdriver), with a small, hinged metal tooth that folds out to pierce the can lid. A notch just under the hinge point keeps the opener hooked around the rim of the can as the device is \"walked\" around the rim to cut the lid out. A larger version, called P-51, is somewhat easier to operate. P-38 was developed in 1942 and was issued in the canned field rations of the United States Armed Forces from World War II to the 1980s. The P-38 and P-51 are cheaper to manufacture and are smaller and lighter to carry than most other can openers. The device can be easily attached to a keyring or dog tag chain using the small punched hole.\n\nOfficial military designations for the P-38 include \"US Army pocket can opener\" and \"Opener, can, hand, folding, type I\". As with some other military terms (e.g., \"jeep\"), the origin of the term is not known with certainty. The P-38 and P-51 openers share a designation with the Lockheed P-38 Lightning and North American P-51 Mustang fighters, however this is coincidental. The most likely origin of the name is much more pedestrian; the P-38 and P-51 measure and in length respectively.\n\nP-38s are no longer used for individual rations by the United States Armed Forces, as canned C-rations were replaced by soft-pack MREs in the 1980s. They are, however, included with United States military \"Tray Rations\" (canned bulk meals). They are also still seen in disaster recovery efforts and have been handed out alongside canned food by rescue organizations, both in America and abroad in Afghanistan. The original US-contract P-38 can openers were manufactured by J. W. Speaker Corp. (stamped \"US Speaker\") and by Washburn Corp. (marked \"US Androck\"), they were later made by Mallin Hardware (now defunct) of Shelby, Ohio and were variously stamped \"US Mallin Shelby O.\" or \"U.S. Shelby Co.\"\nA similar device that incorporates a small spoon at one end and a bottle opener at the other is currently employed by the Australian Defence Force and New Zealand Army in its ration kits. The Field Ration Eating Device is known by the acronym \"FRED\". It is also known as the \"Fucking Ridiculous Eating Device\".\n\nAnother similar device was included with British Army \"Operational Ration Pack, General Purpose\" 24-hour ration pack and \"Composite Ration Pack\" rations. At one time they were manufactured by W. P. Warren Engineering Co., Ltd. The instructions printed on the miniature, greaseproof paper bag in which they were packed read: \"Their design is similar, but not identical, to the P-38 and P-51 can openers.\"\n\nMost military ration can openers have a very simple design and have also been produced for civilian use in many countries. For example, small folding openers similar to the P-38 and P-51 were designed in 1924 and were widely distributed in the Eastern European countries.\n\nIn Slovenia a somewhat rounded version of a P-38 is known as \"sardine can opener\", because in the 1990s such openers were usually packed with cans that did not feature the pull-top pre-scored lid. A non-folding version of the P-38 used to be very common in Israeli kitchens, and can still be found in stores, often sold in packs of five.\n\nThe first electric can opener was patented in 1931 and modeled after the cutting-wheel design. Those openers were produced in the 1930s and advertised as capable of removing lids from more than 20 cans per minute without risk of injury. Nevertheless, they found little success. Electric openers were re-introduced in 1956 by two Californian companies. Klassen Enterprises of Centreville brought out a wall-mounted electric model, but this complex design was unpopular too.\n\nThe same year, Walter Hess Bodle invented a freestanding device, combining an electric can opener and knife sharpener. He and his family members built their prototype in his garage, with daughter Elizabeth sculpting the body design. It was manufactured under the \"Udico\" brand of the Union Die Casting Co. in Los Angeles, California and was offered in Flamingo Pink, Avocado Green, and Aqua Blue, popular colors of the era. These openers were introduced to the market for Christmas sales and found immediate success.\n\nA new style of the can opener emerged in the 1980s. Whereas most other openers remove the lid by cutting down through the lid from the top just inside the rim, removing the top and leaving the rim attached to the can, these use a roller and cutting wheel to cut round the side of the can just below the rim, removing the top and rim. The can is left with a relatively safe, non-jagged edge. The feed wheel teeth have a somewhat finer pitch than those of earlier designs and reside at the bottom of a V-shaped groove, which surrounds the rim on three sides at the point of action.\nHenry Kuttner's 1943 short story \"The Proud Robot\" is about a fancy narcissistic robot which turns out to be \"a bigger and better opener\" created by a drunk inventor, and is described by a reviewer as \"the most beautiful can opener in the world\".\n\n"}
{"id": "55383663", "url": "https://en.wikipedia.org/wiki?curid=55383663", "title": "Colliery viewer", "text": "Colliery viewer\n\nA colliery viewer or coal viewer was the manager of a or . The term was mostly used in the late eighteenth to nineteenth centuries, in the UK. In modern use, the viewer would be the senior and responsible mining engineer at a site.\n\nThe role began as a person to represent the owner of the land, often an aristocrat, who had leased the rights to mine there to another who would 'work' the mine. Land at this time was rarely sold, the aristocratic estates were intent on preserving themselves intact, and so mining rights would usually be in terms of a long-term lease. As both of these gentlemen were affluent, if not titled, they would not be familiar with mining themselves and would not generally wish to become so. As mines grew larger and more complex into the nineteenth century, the role of the viewer shifted to representing the safe technical management of the mine, on behalf of the owner. Later, as mine safety laws were passed, the viewer had a duty to represent the interests of the miners as well.\n\nThe viewer was usually employed by the owner, but in some cases was also the owner, or part-owner, themselves. The New Hartley Pit, of the , was owned by the Carr brothers, where one brother acted as viewer.\n\nAn experienced viewer, known for their good judgement, was recognised as a skilled profession and in the North East they often became an independent contractor or consultant who would advise a number of mines on particular issues, such as sinking a new shaft, or making a new investment. This represented the shift from the viewer as manager or agent, to the development of the modern mining engineer. Even at the time, the distinction between managers, or 'agents', for the day-to-day operation of collieries, and consultant viewers, who advised on the development of new aspects, was never a clear one.\n\nThe viewer would be responsible for deciding major expenditures, such as the purchase of a pumping engine or construction of a tramroad or railway. These new technical innovations were described in advisory guide books such as John Curr's \"The Coal Viewer and Engine Builder's Practical Companion\" (1797).\n\nThe overman is a deputy to the viewer and involved more directly with the daily work of the pit. When a colliery has a number of pits under a viewer, there is an overman to each pit. The overman has responsibilities for daily and hands-on tasks, such as inspecting the pit's safety each day and recording the work performed for systems.\n\nAn overman would be an experienced miner who has been promoted on the basis of experience. \nA viewer in the early years, in contrast, would often be a 'gentleman' from a social class comparable to that of the owner. In later years, from the mid-19th century, it became more common for viewers to be skilled miners who had risen through the ranks.\n\nWages in 1849 for an overman were 26 shillings to 28s. per week. This was twice that of other skilled trades, such as blacksmiths, indicative of the responsibility. As for most jobs, down to the lowliest colliers, a house and free small coal were also provided.\n\nThere was a distinction in a colliery between 'day wagemen', those such as overmen and engine drivers, who were paid a daily or weekly wage and 'oncostmen', those such as coal cutters and loaders, who were paid according to a 'bargain', a form of piecework. The overman would keep the records of work done underground, so that on the Wednesday before a Friday payday he could 'reckon' with the men and agree the totals of work done.\n\nThe overman would also have regular roles underground, whereas the viewer would spend most of their time on the surface.\n\nPits in the 19th century worked a two shift system, with a morning or 'fore' shift (6am-2pm) and an afternoon or 'back' shift (2-10pm). Having an overman permanently on site was considered so important that a second deputy or 'back-overman' would work the second shift. Depending on pit conditions, the fore shift might concentrate on winning coal and the back shift on the 'dead work' of timbering and propping roadways etc.\n\nThe viewer's role, particularly with the development of parliamentary mining regulations in the mid-nineteenth century, was ultimately that of responsibility. Although not necessarily owning the mine or being the engineer engaged to direct it technically, the viewer would be held responsible for any accident.\n\nThe under-viewer, under-looker or steward, was a deputy to the viewer. As well as being an assistant to them, their main role was to act as a if the viewer is away from the colliery, and to ensure that the responsible person was always present.\n\nA viewer employed by the to see that the provisions of the are duly observed.\n\nThese provisions would include that the area being mined did not exceed the boundaries contracted for in the lease, that the amount of support left by working would be sufficient to avoid surface collapse, and sometimes also that surface waters were not polluted by run-off from mine drainage.\n\n"}
{"id": "1461261", "url": "https://en.wikipedia.org/wiki?curid=1461261", "title": "Common drain", "text": "Common drain\n\nIn electronics, a common-drain amplifier, also known as a source follower, is one of three basic single-stage field effect transistor (FET) amplifier topologies, typically used as a voltage buffer. In this circuit (NMOS) the gate terminal of the transistor serves as the input, the source is the output, and the drain is \"common\" to both (input and output), hence its name. The analogous bipolar junction transistor circuit is the common-collector amplifier. This circuit is also commonly called a \"stabilizer.\"\n\nIn addition, this circuit is used to transform impedances. For example, the Thévenin resistance of a combination of a voltage follower driven by a voltage source with high Thévenin resistance is reduced to only the output resistance of the voltage follower (a small resistance). That resistance reduction makes the combination a more ideal voltage source. Conversely, a voltage follower inserted between a driving stage and a high load (i.e. a low resistance) presents an infinite resistance (low load) to the driving stage—an advantage in coupling a voltage signal to a large load.\n\nAt low frequencies, the source follower pictured at right has the following small signal characteristics.\n\nThe variable \"g\" that is not listed in the schematic is the transconductance of the device (usually given in units of siemens).\n"}
{"id": "52146428", "url": "https://en.wikipedia.org/wiki?curid=52146428", "title": "Computer Center Corporation", "text": "Computer Center Corporation\n\nThis small Washington state company offered time-sharing on a PDP-10 and is most famous for the people who passed through its doors, among them being Bill Gates, Paul Allen.\n\nNicknamed C-Cubed, this company was founded in 1968 and closed its doors in 1970.\n\nTwo other companies, both based in New Jersey, used similar names.\n"}
{"id": "6574577", "url": "https://en.wikipedia.org/wiki?curid=6574577", "title": "Conditioner (farming)", "text": "Conditioner (farming)\n\nA conditioner (or \"hay conditioner\") is a farm implement that crimps and crushes newly cut hay to promote faster and more even drying. Drying the hay efficiently is most important for first cutting of the hay crop, which consists of coarse stalks that take a longer period of time to draw out moisture than finer textured hays, such as second and subsequent cuttings.\n\nA conditioner is made up of two grooved rollers which the hay is forced through, causing the stalks to split, thus allowing the liquid trapped behind cell walls (sap and cell sap) to leak out and also giving more surface area for evaporation. The stand-alone conditioner is no longer used on most farms, since the conditioner has been incorporated into mower-conditioners, which combine the mower and conditioner into a single machine. The names Haybine and Discbine are brand names of mower-conditioners, although some farmers use these names somewhat generically.\n\nMower-conditioners are a staple of large-scale hay making. Mower-conditioners are defined by the mechanisms that accomplish mowing and conditioning.\n\nThere are three types of mowers: sickle bar mowers, disc mowers, and drum mowers. Sickle bar mowers use a reciprocating blade to cut the grass and typically use a reel to fold the grass over the knife. Disc mowers have a number of hubs across the cutting width, each hub having a small (18\") rotating disc with knives. Drum mowers use two or three large plates (called the drums, about 36\" across) which ride over the ground as they are spinning. A sickle bar mower's main advantage over disc mowers and drum mowers is the reduced horsepower requirements. Its disadvantage is the extra maintenance required due to the high number of moving parts and wear items. Disc mowers were historically considered an \"all the eggs in one basket\" kind of mower because all the mower hubs were in one large gearbox. If one blade hit something and a gear tooth broke, the whole gearbox would suffer a catastrophic failure, and there would be nothing worth fixing. If anything broke, everything broke. Drum mowers prevented this by having typically two belt-driven drums compared to six or more gear-driven hubs. Modern disc mowers use isolated gearboxes, and if one fails it can be swapped out without rebuilding the entire machine.\n\nConditioners come in three main types: rubber-roller conditioners, steel-roller, and flail. The roller conditioners consist of two opposing rolls that have a raised, interlocking pattern. The rollers have either a rubber or steel pattern and a steel main shaft. The crop is crimped between the rollers, decreasing the drying time. The flail conditioner is an arrangement of steel V's on a main shaft that beat the crop against the top of the mower-conditioner. The flail conditioner reduces drying time by removing the waxy coating on the crop.\n\nEven though conditioners can shorten the dry time of the hay, they can come with problems in the hayfield. The space between the two opposing rolls can decrease or increase by the users needs, but there is a max area of opening. This can cause a break down or problem in the machine. If the hay is wet or lay downed in the field it can bunch together when pushed into the conditioner rolls. This can jam the rolls, even causing the hay to wrap completely around them. If caught early, the user can shut down the machine and cut the hay free by hand. If it is not caught early this can stop the bars from rolling, thus stopping the belts from turning the machine, then stopping the tractor. If this happens, one is looking at major problems with their machinery. Not only can this damage the rolls, but also the belts on the mower-conditioner can snap and the tractor itself will be receiving considerable amounts of stress on its engine. Even though this can be a major money and time consuming problem, if the user is alert and constantly aware of their equipment's performance, this issue should never go further than a small stoppage. \n\n\"Haybine\" is the brand name of the first mower-conditioner. It combined the sickle bar mower and the hay conditioner to promote faster drying hay all in one process. The current versions produced by New Holland are branded the \"Discbine,\" since they now feature faster disc mowers.\n\n\n"}
{"id": "39653365", "url": "https://en.wikipedia.org/wiki?curid=39653365", "title": "Convention on the Marking of Plastic Explosives", "text": "Convention on the Marking of Plastic Explosives\n\nThe Convention on the Marking of Plastic Explosives for the Purpose of Detection is a multilateral anti-terrorism treaty that aims to prohibit and prevent the manufacture or storage of unmarked plastic explosives.\n\nA state that ratifies the Convention agrees to prohibit the manufacture, storage, transport, or entry of unmarked plastic explosives in its territory. Plastic explosives are not prohibited by the treaty, but it mandates that when they are produced they are marked with a chemical taggant (specified in the treaty's Technical Annex) which can facilitate future identification purposes.\n\nThe Convention also establishes an International Explosives Technical Commission, which is composed of experts in the field explosives manufacturing and detection. The Commission can propose amendments to the Technical Annex of the treaty.\n\nThe Convention was concluded at the ICAO International Conference on Air Law in Montreal on 1 March 1991. It entered into force on 21 June 1998 after it had been ratified by 35 signatory states.\n\nAs of October 2018, the Convention has been ratified by 155 states, made up of 154 United Nations member states plus Niue.\n\n"}
{"id": "37629890", "url": "https://en.wikipedia.org/wiki?curid=37629890", "title": "Dornier DO-960", "text": "Dornier DO-960\n\nThe Dornier DO-960 was a hybrid computer designed for the Dornier Do 31 experimental VTOL aircraft.\n\nThe hybrid approach was necessary because the computations for controlling VTOL were not feasible with digital computers available at that time. Vertical take-off requires solving complex differential equations in real-time. The DO-960 incorporates both digital computer and analog computer elements. The analog units are fit for solving computationally challenging differential equations, while the digital units are responsible for controlling the overall program flow. \n\nAlthough known primarily for aircraft, Dornier had been building analog and hybrid computers as soon as it started engineering vertical takeoff aircraft. The Dornier DO-960 was the last known hybrid computer of this series.\n\n"}
{"id": "43785137", "url": "https://en.wikipedia.org/wiki?curid=43785137", "title": "EBeam", "text": "EBeam\n\neBeam is an interactive whiteboard system developed by Luidia, Inc. that transforms any standard whiteboard or other surface into an interactive display and writing surface.\n\nLuidia's eBeam hardware and software products allow text, images and video to be projected onto a variety of surfaces, where an interactive stylus or marker can be used to add notes, access control menus, manipulate images and create diagrams and drawings. The presentations, notes and images can be saved and emailed to class or meeting participants, as well as shared in real time on local networks or over the Internet.\n\neBeam technology has been incorporated into other manufacturers' interactive whiteboard systems, such as the 3M \"Wall Display\" / Digital Board, Hitachi Starboard, Legamaster eBoard, and NEC's WT615 short throw projection unit.\n\neBeam technology uses infrared and ultrasound receivers to track the location of a transmitter-equipped pen, called a stylus, or a standard dry-erase marker in a transmitter-equipped sleeve. A separate receiver unit attaches to the edge of the whiteboard, wall or other writing surface, and determines the distance and direction of the transmitter pen using the known quantities and differences of the speed of light and the speed of sound.\n\nLuidia's eBeam technology was originally developed and patented by engineers at Electronics for Imaging Inc. (Nasdaq: EFII), a Foster City, Calif. developer of digital print server technology. Luidia was spun off from EFI in July 2003 with venture funding from Globespan Capital Partners and Silicom Ventures.\n\nSince then, Luidia has continued to update and expand its eBeam product line, while adding numerous manufacturing partners, including Hitachi, NEC and Uchida.\n\nLuidia offers a variety of eBeam hardware and software products, including:\n\nInteractive Whiteboard Systems\n\nInteractive software:\n\nAdditional products\n\n\n"}
{"id": "48538870", "url": "https://en.wikipedia.org/wiki?curid=48538870", "title": "Emergency eyewash and safety shower station", "text": "Emergency eyewash and safety shower station\n\nAn emergency eyewash and safety shower station are essential equipment for every laboratory that uses chemicals and hazardous substances needs. Emergency eyewash and safety shower stations serve the purpose of reducing workplace injury and keeping workers away from various dangers. Also, to avoid the chemicals that can cause further harm to the body.\n\nThere are several types of emergency eyewash station and safety shower station systems, including safety showers, eyewash stations, drench hoses, combination units, and eyewash bottles.\n\nA safety shower is a unit designed to wash an individual's head and body which has come into contact with hazardous chemicals. Large volumes of water are used and a user may need to take off any clothing that has been contaminated with hazardous chemicals. Safety showers cannot be used for flushing our eyes, due to the high pressure of water from the shower, which can damage a user's eyes.\n\nAn eyewash station is a unit for washing chemicals or substances that might splash into an individual's eyes before he or she can seek further medical attention. The user needs to wash their eyes for at least 5 minutes.\nA drench hose is an equipment that can spray water to a specific spot of the chemical exposure on individual's body. The benefit of a drench hose is that it can be applied to an individual who cannot reach a normal eyewash or shower station or in the case where the eyewash and shower station are unavailable.\n\nA combination unit is where other units such as a shower station, eyewash station, and drench hose share the same water supply plumbing. This unit is useful in laboratory where hazardous chemicals with different properties are used.\n\nAlso known as a personal eyewash unit, it is a supplementary for eyewash stations. However, eyewash stations cannot be replaced by eyewash bottles since they do not meet safety standards. Eyewash bottles allow an individual to flush the injured area immediately, or until the individual can reach the fixed eyewash station. Early eyewashes were designed with a single rinsing stream, but recent advancements have made eyewashes capable of flushing both eyes simultaneously. A pH neutral solution for emergency eyewash may also be chosen to reduce the danger from contaminants if strong acids or alkali chemicals are presented.\n\nIn the United States, Occupational Safety and Health Administration (OSHA) regulations on emergency eyewash and shower station are contained in 29 C.F.R. 1910.151 (c), which provides that \"Where the eyes or body of any person may be exposed to injurious corrosive materials, suitable facilities for quick drenching or flushing of the eyes and body shall be provided within the work area for immediate emergency use.\" However, OSHA regulation is unclear defining what facility is required. From this reason, American National Standards Institute (ANSI) has developed a standard (ANSI/ISEA Z358.1-2014) for emergency eyewash and shower stations, including the design of such stations.\n\n\n\nSafety showers and eyewash stations should be within 10 seconds walking distance or 55 feet (appendix B) from the hazard and must be located on the same level as the hazard so the victim does not have to go up or down the stairs when an accident occurs. Moreover, the path way should be clear and free of obstructions.\n"}
{"id": "16624258", "url": "https://en.wikipedia.org/wiki?curid=16624258", "title": "Enhanced GPS", "text": "Enhanced GPS\n\nEnhanced GPS (or E-GPS, EGPS, trademarked as eGPS) is a technology designed for mobile phones on GSM and W-CDMA networks, to augment GPS signals to deliver faster location fixes, lower cost implementations and reduced power and processing requirements. It is being developed by CSR who has partnered with Motorola – together they intend to create an open industry forum.\n\nAccording to CSR, EGPS delivers a \"universal positioning capability that will not only work reliably indoors and in zero GPS signal conditions, but greatly speed time to fix in poor GPS reception areas where most handsets are used.\" More specifically, it can \"exploit data available from the cellular network to speed GPS fixes and provide complementary, fast, and reliable location sensing when GPS signals are weak or unavailable.\" CSR is hoping to add eGPS capabilities to handsets for less than $1 per unit.\n\nE-GPS combines CSR's \"Matrix\" technology with GPS – when a user initiates a location request they get a Matrix location instantly using cell tower information, accurate to within 100m. Then CSR's \"Fine Time Aiding\" helps the device know where to look for a GPS signal, to quickly acquire satellite information within seconds. Fine Time Aiding enables a more aggressive search and is claimed to be equivalent to 6 dB more sensitivity than can be achieved by any GPS hardware correlator in the terminal.\n\nCSR claim that this enables software-only GPS solutions to operate reliably in all environments, and that eGPS is superior to Assisted GPS. EGPS technologies are due in 2008.\n\neGPS is much advanced than conventional GPS system provided with enhanced location search and integrated cellular connectivity. \n\n"}
{"id": "24974201", "url": "https://en.wikipedia.org/wiki?curid=24974201", "title": "Fatigue damage spectrum", "text": "Fatigue damage spectrum\n\nThe Fatigue Damage Spectrum (FDS) of a vibration is obtained by tracing the fatigue damage experienced by a linear Single Degree of Freedom System (SDOF) according to its natural frequency, for given damping ratio and for a given value of parameter b (this parameter comes from the Basquin law representing the Wöhler curve of the material constituting the structure).\n\nRegardless of the vibratory signal studied (sinusoidal vibration, shock, random or composite vibration); the FDS can be obtained directly from the time history signal. The method consists of :\n\n\nIn the case of stationary random vibration, the Power spectral density (PSD) of the vibration can be directly used for the FDS calculation.\n\nVibrations can damage a mechanical system as a result of several processes, among which are:\n\nFDS is used according to the second criterion. The first criterion is considered with the \"Extreme response spectrum\" (ERS).\n\nFatigue (material)\n\n"}
{"id": "7901142", "url": "https://en.wikipedia.org/wiki?curid=7901142", "title": "Fluorescence interference contrast microscopy", "text": "Fluorescence interference contrast microscopy\n\nFluorescence interference contrast (FLIC) microscopy is a microscopic technique developed to achieve z-resolution on the nanometer scale. \n\nFLIC occurs whenever fluorescent objects are in the vicinity of a reflecting surface (e.g. Si wafer). The resulting interference between the direct and the reflected light leads to a double sin modulation of the intensity, I, of a fluorescent object as a function of distance, h, above the reflecting surface. This allows for the \"nanometer height measurements\".\n\nFLIC microscope is well suited to measuring the topography of a membrane that contains fluorescent\nprobes e.g. an artificial lipid bilayer, or a living cell membrane or the structure of fluorescently labeled proteins on a surface.\n\nThe optical theory underlying FLIC was developed by Armin Lambacher and Peter Fromherz. They derived a relationship between the observed fluorescence intensity and the distance of the fluorophore from a reflective silicon surface.\n\nThe observed fluorescence intensity, formula_1, is the product of the excitation probability per unit time, formula_2, and the probability of measuring an emitted photon per unit time, formula_3. Both probabilities are a function of the fluorophore height above the silicon surface, so the observed intensity will also be a function of the fluorophore height. The simplest arrangement to consider is a fluorophore embedded in silicon dioxide (refractive index formula_4) a distance \"d\" from an interface with silicon (refractive index formula_5). The fluorophore is excited by light of wavelength formula_6 and emits light of wavelength formula_7. The unit vector formula_8 gives the orientation of the transition dipole of excitation of the fluorophore. formula_2 is proportional to the squared projection of the local electric field, formula_10, which includes the effects of interference, on the direction of the transition dipole. \n\nformula_11 \n\nThe local electric field, formula_10, at the fluorophore is affected by interference between the direct incident light and the light reflecting off the silicon surface. The interference is quantified by the phase difference formula_13 given by\n\nformula_14\n\nformula_15 is the angle of the incident light with respect to the silicon plane normal. Not only does interference modulate formula_10, but the silicon surface does not perfectly reflect the incident light. Fresnel coefficients give the change in amplitude between an incident and reflected wave. The Fresnel coefficients depend on the angles of incidence, formula_17 and formula_18, the indices of refraction of the two mediums and the polarization direction. The angles formula_17 and formula_18 can be related by Snell's Law. The expressions for the reflection coefficients are:\n\nformula_21\n\nTE refers to the component of the electric field perpendicular to the plane of incidence and TM to the parallel component (The incident plane is defined by the plane normal and the propagation direction of the light). In cartesian coordinates, the local electric field is \n\nformula_22\n\nformula_23 is the polarization angle of the incident light with respect to the plane of incidence. The orientation of the excitation dipole is a function of its angle formula_24 to the normal and formula_25 azimuthal to the plane of incidence. \n\nformula_26\n\nThe above two equations for formula_10 and formula_28 can be combined to give the probability of exciting the fluorophore per unit time formula_2.\nMany of the parameters used above would vary in a normal experiment. The variation in the five following parameters should be included in this theoretical description.\nThe squared projection formula_34 must be averaged over these quantities to give the probability of excitation formula_2. Averaging over the first 4 parameters gives\nformula_36\nformula_37\nNormalization factors are not included. formula_38 is a distribution of the orientation angle of the fluorophore dipoles. The azimuthal angle formula_25 and the polarization angle formula_23 are integrated over analytically, so they no longer appear in the above equation. To finally obtain the probability of excitation per unit time, the above equation is integrated over the spread in excitation wavelength, accounting for the intensity formula_41 and the extinction coefficient of the fluorophore formula_42.\nformula_43\nThe steps to calculate formula_3 are equivalent to those above in calculating formula_2 except that the parameter labels \"em\" are replaced with \"ex\" and \"in\" is replaced with \"out\".\nformula_46\nThe resulting fluorescence intensity measured is proportional to the product of the excitation probability and emission probability\n\nformula_47\nIt is important to note that this theory determines a proportionality relation between the measured fluorescence intensity formula_1 and the distance of the fluorophore above the reflective surface. The fact that it is not an equality relation will have a significant effect on the experimental procedure.\n\nA silicon wafer is typically used as the reflective surface in a FLIC experiment. An oxide layer is then thermally grown on top of the silicon wafer to act as a spacer. On top of the oxide is placed the fluorescently labeled specimen, such as a lipid membrane, a cell or membrane bound proteins. \nWith the sample system built, all that is needed is an epifluorescence microscope and a CCD camera to make quantitative intensity measurements. \nThe silicon dioxide thickness is very important in making accurate FLIC measurements. As mentioned before, the theoretical model describes the \"relative\" fluorescence intensity measured versus the fluorophore height. The fluorophore position cannot be simply read off of a single measured FLIC curve. The basic procedure is to manufacture the oxide layer with at least two known thicknesses (the layer can be made with photolithographic techniques and the thickness measured by ellipsometry). The thicknesses used depends on the sample being measured. For a sample with fluorophore height in the range of 10 nm, oxide thickness around 50 nm would be best because the FLIC intensity curve is steepest here and would produce the greatest contrast between fluorophore heights. Oxide thickness above a few hundred nanometers could be problematic because the curve begins to get smeared out by polychromatic light and a range of incident angles. A ratio of measured fluorescence intensities at different oxide thicknesses is compared to the predicted ratio to calculate the fluorophore height above the oxide (formula_49). \nformula_50\nThe above equation can then be solved numerically to find formula_51.\nImperfections of the experiment, such as imperfect reflection, nonnormal incidence of light and polychromatic light tend to smear out the sharp fluorescence curves. The spread in incidence angle can be controlled by the numerical aperture (N.A.). However, depending on the numerical aperture used, the experiment will yield good lateral resolution (x-y) or good vertical resolution (z), but not both. A high N.A. (~1.0) gives good lateral resolution which is best if the goal is to determine long range topography. Low N.A. (~0.001), on the other hand, provides accurate z-height measurement to determine the height of a fluorescently labeled molecule in a system.\n\nThe basic analysis involves fitting the intensity data with the theoretical model allowing the distance of the fluorophore above the oxide surface (formula_51) to be a free parameter.\nThe FLIC curves shift to the left as the distance of the fluorophore above the oxide increases. formula_51 is usually the parameter of interest, but several other free parameters are often included to optimize the fit. Normally an amplitude factor (a) and a constant additive term for the background (b) are included. The amplitude factor scales the relative model intensity and the constant background shifts the curve up or down to account for fluorescence coming from out of focus areas, such as the top side of a cell. Occasionally the numerical aperture (N.A.) of the microscope is allowed to be a free parameter in the fitting. The other parameters entering the optical theory, such as different indices of refraction, layer thicknesses and light wavelengths, are assumed constant with some uncertainty.\nA FLIC chip may be made with oxide terraces of 9 or 16 different heights arranged in blocks. After a fluorescence image is captured, each 9 or 16 terrace block yields a separate FLIC curve that defines a unique formula_51. The average formula_51 is found by compiling all the formula_51 values into a histogram.\n\nThe statistical error in the calculation of formula_51 comes from two sources: the error in fitting of the optical theory to the data and the uncertainty in the thickness of the oxide layer. Systematic error comes from three sources: the measurement of the oxide thickness (usually by ellipsometer), the fluorescence intensity measurement with the CCD, and the uncertainty in the parameters used in the optical theory. The systematic error has been estimated to be formula_58.\n\n"}
{"id": "1491805", "url": "https://en.wikipedia.org/wiki?curid=1491805", "title": "Gas stove", "text": "Gas stove\n\nIn cooking, a gas stove is a cooker/stove which uses syngas, natural gas, propane, butane, liquefied petroleum gas or other flammable gas as a fuel source. Prior to the advent of gas, cooking stoves relied on solid fuel such as coal or wood. The first gas stoves were developed in the 1820s, and a gas stove factory was established in England in 1836. This new cooking technology had the advantage that it was easily adjustable and could be turned off when not in use. However the gas stove did not become a commercial success until the 1880s, by which time a supply of piped gas was available in large towns in Britain. The stoves became widespread on the European Continent and in the United States in the early 20th century.\n\nGas stoves became less unwieldy when the oven was integrated into the base and the size was reduced to fit in better with the rest of the kitchen furniture. By the 1910s, producers started to enamel their gas stoves for easier cleaning. Ignition of the gas was originally by match and this was followed by the more convenient pilot light. This had the disadvantage of a continual consumption of gas. The oven still needed to be lit by match, and accidentally turning on the gas without igniting it could lead to an explosion. To prevent these types of accidents, oven manufacturers developed and installed a safety valve called a flame failure device for gas hobs (cooktops) and ovens. Most modern gas stoves have electronic ignition, automatic timers for the oven and extractor hoods to remove fumes.\n\nThe first gas stove was developed in 1802 by Zachäus Winzler (), but this along with other attempts remained isolated experiments. James Sharp patented a gas stove in Northampton, England in 1826 and opened a gas stove factory in 1836. His invention was marketed by the firm Smith & Philips from 1828. An important figure in the early acceptance of this new technology, was Alexis Soyer, the renowned chef at the Reform Club in London. From 1841, he converted his kitchen to consume piped gas, arguing that gas was cheaper overall because the supply could be turned off when the stove was not in use.\n\nA gas stove was shown at the World Fair in London in 1851, but it was only in the 1880s that the technology became a commercial success in England. By that stage a large and reliable network for gas pipeline transport had spread over much of the country, making gas relatively cheap and efficient for domestic use. Gas stoves only became widespread on the European Continent and in the United States in the early 20th century.\n\nEarly gas stoves were rather unwieldy, but soon the oven was integrated into the base and the size was reduced to fit in better with the rest of the kitchen furniture. In the 1910s, producers started to enamel their gas stoves for easier cleaning.\n\nGas stoves today use two basic types of ignition sources, standing pilot and electric. A stove with a standing pilot has a small, continuously burning gas flame (called a pilot light) under the cooktop. The flame is between the front and back burners. When the stove is turned on, this flame lights the gas flowing out of the burners. The advantage of the standing pilot system is that it is simple and completely independent of any outside power source. A minor drawback is that the flames continuously consume fuel even when the stove is not in use. Early gas ovens did not have a pilot. One had to light these manually with a match. If one accidentally left the gas on, gas would fill the oven and eventually the room. A small spark, such as an arc from a light switch being turned on, could ignite the gas, triggering a violent explosion. To prevent these types of accidents, oven manufacturers developed and installed a safety valve called a flame failure device for gas hobs (cooktops) and ovens. The safety valve depends on a thermocouple that sends a signal to the valve to stay open. Although most modern gas stoves have electronic ignition, many households have gas cooking ranges and ovens that need to be lit with a flame. Electric ignition stoves use electric sparks to ignite the surface burners. This is the \"clicking sound\" audible just before the burner actually lights. The sparks are initiated by turning the gas burner knob to a position typically labeled \"LITE\" or by pressing the 'ignition' button. Once the burner lights, the knob is turned further to modulate the flame size. Auto reignition is an elegant refinement: the user need not know or understand the wait-then-turn sequence. They simply turn the burner knob to the desired flame size and the sparking is turned off automatically when the flame lights. Auto reignition also provides a safety feature: the flame will be automatically reignited if the flame goes out while the gas is still on—for example by a gust of wind. If the power fails, surface burners must be manually match-lit.\n\nElectric ignition for ovens uses a \"hot surface\" or \"glow bar\" ignitor. Basically it is a heating element that heats up to gas's ignition temperature. A sensor detects when the glow bar is hot enough and opens the gas valve.\n\nAlso stoves with electric ignition must be connected with gas protection mechanisms such as gas control breaker. Because of this many manufactureres supply stoves without electricity plug.\n\n"}
{"id": "19614239", "url": "https://en.wikipedia.org/wiki?curid=19614239", "title": "General Administration of Quality Supervision, Inspection and Quarantine", "text": "General Administration of Quality Supervision, Inspection and Quarantine\n\nThe General Administration of Quality Supervision, Inspection and Quarantine of the People's Republic of China (, abbreviated AQSIQ) is a ministerial-level department under the State Council of the People's Republic of China that is in charge of national quality, metrology, entry-exit commodity inspection, entry-exit health quarantine, entry-exit animal and plant quarantine, import-export food safety, certification and accreditation, standardization, as well as administrative law enforcement.\n\nAQSIQ directly administers provincial Entry-Exit Inspection and Quarantine Bureaus and Bureaus of Quality and Technical Supervision. For example, the Beijing Entry-Exit Inspection and Quarantine Bureau is responsible for collecting health declaration forms, and used thermal imaging to spot passengers with fever due to the 2009 flu pandemic prior to July 16, 2009.\n\n\n"}
{"id": "18586618", "url": "https://en.wikipedia.org/wiki?curid=18586618", "title": "Grace Bio-Labs", "text": "Grace Bio-Labs\n\nGrace Bio-Labs is a global supplier of pharmaceutical, biomedical, and biochemical research products based in Bend, Oregon, United States. They develop the thin-cast nitrocellulose biochip (aka: nitrocellulose slide, nitrocellulose film slide) and the modern hybridization and incubation chambers for glass microscope slides.\n\nOriginally based near Detroit, Michigan, and founded by Charles McGrath in 1986, Grace Bio Labs relocated to Bend, Oregon in May, 1990.\n\nWith the aid of SBIR funding, Grace Bio-Labs was built on two main product types. The first is the incubation chamber for cell culture and analysis; the second is the ONCYTE Nitrocellulose Film Slide. Their incubation and hybridization chambers are fluid delivery and containment products that increase sensitivity and efficiency in fluorescence and color-based protein and cell analyte assays.\nThe ONCYTE Nitrocellulose microporous film (nitrocellulose slide) is a biochip platform that captures and protects the 3-dimensional (tertiary) structure of biological material. Originally designed for tissue printing and cell lysate capture, the film has flourished in proteomics. It is commonly used in automated and manual protein microarrays, and continues to increase throughput in proteomics research.\n\nGrace Bio-Labs sells to university research laboratories, biotech companies, private researchers and pharmaceutical companies. They mainly distribute to North America, Western and Central Europe, East Asia, and Southeast Asia.\n\n"}
{"id": "23398150", "url": "https://en.wikipedia.org/wiki?curid=23398150", "title": "IT energy management", "text": "IT energy management\n\nIT energy management or Green IT as per International Federation of Global & Green ICT \"IFGICT\" is the analysis and management of energy demand within the Information Technology department in any organization. IT energy demand accounts for approximately 2% of global emissions, approximately the same level as aviation, and represents over 10% of all the global energy consumption (over 50% of aviation's energy consumption). IT can account for 25% of a modern office building’s energy cost.\n\nAt one point, the main sources of manageable IT energy demand were PCs and Monitors, accounting for 39% of energy use, followed by data centers and servers, accounting for 23% of energy use. In 2006, US IT infrastructures consumed an estimated 61 billion kWh of energy, totaling to a cost of $4.5 billion. Significant opportunities exist for Enterprises to optimise their IT energy usage. Computers, data centers and networks consume 10% of the world’s electricity. 30% of this electricity goes to power terminal equipment (computers, mobiles and other devices), 30% goes to data centers and 40% goes to the network. A router consumes 10 kW and a large data center consumes nearly 100MW.\n\nData centers can consume up to 100 times more energy than a standard office building. Often, less than 15% of original source energy is used for the information technology equipment within a data center. With the introduction of new technologies and products, energy management of several IT equipments has been greatly improved.\n\nServers and data centers account for 23% of IT energy demand. As hardware becomes smaller and less expensive, energy costs constitute a larger portion of server or data center costs.\n\nThese allow gains to be made through optimisation of servers. This is typically done by doing diagnostic tests on individual servers and developing a model for a data center’s energy demand using these measurements. By analysing every server in a data centre, server power management software can identify servers that can be removed. It also enables servers to be virtualized, processes to be consolidated to a smaller number of servers, and servers with a predictable cyclical power demand to be fully powered down when not in use. Active power management features are also included which put remaining servers into their lowest power state that allows instant wake-up on demand when required.\n\nEnergy efficiency benchmarks, such as SPECpower, or specifications, like Average CPU power, can be used for comparing server efficiency and performance per watt.\n\nA research study shows that in the US, 50% of PCs are left on overnight, resulting in an estimated annual energy waste of 28.8 billion kWh, and a cost of $2.8 billion per year. User behaviour is slightly different in Europe, with approximately 28% of PCs being left on overnight in the UK, resulting in an estimated energy loss of 2.5 billion kWh, costing £300 million per year. In Germany, with approximately 30% of PCs left on overnight, it is estimated 4.8 billion kWh of energy are wasted each year, costing €919 million There is a significant market in third-party Power Management Software offering features beyond those present in the Windows operating system.\n\nMost products offer Active Directory integration and per-user/per-machine settings with the more advanced offering multiple power plans, scheduled power plans, anti-insomnia features and enterprise power usage reporting.\n\nEnergy Efficient Ethernet (IEEE 802.3az) could reduce the energy use of networking equipment. In 2005, all the network-interface controllers in the United States (in computers, switches, and routers) used an estimated 5.3 terawatt-hours of electricity. According to a researcher at the Lawrence Berkeley Laboratory, Energy Efficient Ethernet could save an estimated $450 million a year in energy costs in the U.S. With most of the savings from home computers ($200 million), and offices ($170 million), and the remaining $80 million from data centers. Energy efficient Ethernet saves energy by allowing network links to either go into a low power sleep mode or run at a slower rate when there is no data. It also defines lower power signaling for use on higher quality cables.\n\nThere are a number of industry associations and policy organisations whose work on promoting energy efficiency includes providing resources and information on IT energy management. These include:\n\n"}
{"id": "42181888", "url": "https://en.wikipedia.org/wiki?curid=42181888", "title": "Index of home automation articles", "text": "Index of home automation articles\n\nThis is a list of home automation topics on Wikipedia. Home automation is the residential extension of building automation. It is automation of the home, housework or household activity. Home automation may include centralized control of lighting, HVAC (heating, ventilation and air conditioning), appliances, security locks of gates and doors and other systems, to provide improved convenience, comfort, energy efficiency and security.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "50765105", "url": "https://en.wikipedia.org/wiki?curid=50765105", "title": "Koruza (technology)", "text": "Koruza (technology)\n\nKoruza is a Slovenian open source and open hardware project providing equipment for low-cost free-space wireless optical connections. One can use 3D printing to create their own equipment. It is based on use of existing SFP optical modules which brings the costs of manufacturing down. Because it uses infrared light it is an alternative to Wi-Fi and does not have issues with spectrum congestion and radio interference. It is available in 1 Gbit/s and 10 Gbit/s forms. Connection can be established at up to 100 m.\n\nIt is one of the projects funded by Shuttleworth Foundation through their fellows program.\n\n\n"}
{"id": "54006122", "url": "https://en.wikipedia.org/wiki?curid=54006122", "title": "Lieberman Software", "text": "Lieberman Software\n\nLieberman Software Corporation is a cyber security software firm that develops automated privileged identity management and secure privileged access management software.\n\nIn January 2018, Lieberman Software got acquired by Bomgar Corporation.\n\nThe company was first formed as Lieberman and Associates in 1978 by Philip Lieberman. It became an Independent software vendor in 2004 under the name, \"Lieberman Software Corporation\".\n\nOn February 1, 2018 Lieberman Software announced that it was acquired by Bomgar.\n\nOn July 28, 2017 at Black Hat in Las Vegas, Lieberman Software announced a partnership with VeriClouds.\n\nOn July 17, 2017, Lieberman Software announced its Lieberman RED - Rapid Enterprise Defense™ Suite.\n\nOn April 3, 2017, Lieberman Software announced a new partner integration with SailPoint IdentityIQ.\n\nOn February 27, 2017, Lieberman Software won Info Security Products Guide Global Excellence Award for Best Identity Management. \n\nOn October 26, 2016, Lieberman Software was awarded American Security Today 2016 Homeland Security Award.\n\nOn April 21, 2016, Lieberman Software was awarded the 2016 Cybersecurity Excellence Award.\n\nOn June 2, 2015, Lieberman Software was deemed Microsoft 2015 Application Development Partner of the Year\n\nOn May 13, 2014, Lieberman Software Privileged User Management (PUM) capabilities in the Enterprise Random Password Manager™ (ERPM) at Microsoft TechEd 2014 in Houston, TX. \n\nAs explained in Handbook of Research on Emerging Developments in Data Privacy by Manish Gupta, \"Enterprise Random Password Manager: Enterprise Random Password Generator (ERPG) is a privileged identity management product that can discover, track, secure and audit privileged accounts across an enterprise. Some of the features ERPG provides are super-user login accounts for that are used for configuration settings and other administrative tasks, service accounts that require privileged login ID and password, and application to application passwords that are used to connect databases, middleware and more. ERPM also has a feature called True Discovery™ that on addition of new hardware or software, continuously discovers and secures new privileged identities. With the help of real time visualization ERPM provides dashboards that help organizations identity security and productivity issues.\"\n\n\n\n\n\n\n"}
{"id": "8454722", "url": "https://en.wikipedia.org/wiki?curid=8454722", "title": "Lobster hook", "text": "Lobster hook\n\nA lobster hook or lobsterhook is a hook with a handle (often home-made from a length of thick stiff wire) used to pull crabs and lobsters out of their holes, when scuba diving or when searching among rocks in the dry at low tide.\n"}
{"id": "35581201", "url": "https://en.wikipedia.org/wiki?curid=35581201", "title": "Mechanical tree shaker", "text": "Mechanical tree shaker\n\nA mechanical tree shaker is a device that uses an hydraulic cylinder to squeeze a tree. It is used in the harvesting of some fruit trees, especially pecans.\n"}
{"id": "3563744", "url": "https://en.wikipedia.org/wiki?curid=3563744", "title": "Moving image formats", "text": "Moving image formats\n\nThis article discusses moving image capture, transmission and presentation from today's technical and creative points of view; concentrating on aspects of frame rates.\n\nThe essential parameters of any moving image sequence as a visual presentation are: presence or absence of colour, aspect ratio, resolution and image change rate.\n\nThere are several standard image-change rates (or frame rates) used today: 24 Hz, 25 Hz, 30 Hz, 50 Hz, and 60 Hz. Technical details related to the backward-compatible addition of color to the NTSC signal caused other variants to appear: 24000/1001 Hz, 30000/1001 Hz, and 60000/1001 Hz.\n\nThe image change rate fundamentally affects how \"fluid\" the motion it captures will look on the screen. Moving image material, based on this, is sometimes divided into two groups: \"film-based\" material, where the image of the scene is captured by camera 24 times a second (24 Hz), and \"video-based\" material, where the image is captured roughly 50 or 60 times a second.\n\nThe roughly 50 and 60 Hz material captures motion very well, and it looks very fluid on the screen. In principle, the 24 Hz material conveys motion satisfactorily; but, because it is usually displayed at least twice the capture rate in cinema and on CRT TV (to avoid flicker), it is not considered capable of transmitting \"fluid\" motion. Nevertheless, it still is used to film movies, because of the unique artistic impression arising exactly from the slow image-change rate.\n\n25 Hz material, for all practical purposes, looks and feels the same as 24 Hz material. 30 Hz material is in the middle, between 24 and 50 Hz material, in terms of \"fluidity\" of the motion it captures; but, in TV systems, it is handled similarly to 24 Hz material (i.e. displayed at least twice the capture rate).\n\nThe capture process fixes the \"natural\" frame rate of the image sequence. Moving image sequence can be captured at the rate which is different from presentation rate, however this is usually only done for the sake of artistic effect, or for studying fast-pace or slow processes. In order to faithfully reproduce familiar movements of persons, animals, or natural processes, and to faithfully reproduce accompanying sound, the capture rate must be equal to, or at least very close to the presentation rate.\n\nAll modern moving image capture systems either use a mechanical or an electronic shutter. Shutter allows the image for a single frame to be integrated over a shorter period of time than the image change period. Another important function of the shutter in raster-based systems is to make sure that the part of frame scanned first (e.g. the topmost part) contains image of the scene integrated over exactly the same period of time as the part of frame scanned last.\n\nEarly TV cameras, such as the video camera tube, did not have a shutter. Not using shutter in raster systems may alter the shape of the moving objects on the screen. On the other hand, the video from such a camera looks shockingly \"live\" when displayed on a CRT display in its native format.\n\nAnalog broadcasting systems—PAL/SECAM and NTSC—were historically limited in the set of moving image formats they could transmit and present. PAL/SECAM can transmit 25 Hz and 50 Hz material, and NTSC can only transmit 30 Hz and 60 Hz material (later replaced by 30/1.001 and 60/1.001 Hz). Both systems were also limited to an aspect ratio of 4:3 and fixed resolution (limited by the available bandwidth). While the wider aspect ratios were relatively straightforward to adapt to 4:3 frame (for instance by letterboxing), the frame rate conversion is not straightforward, and in many cases degrades the \"fluidity\" of motion, or quality of individual frames (especially when either the source or the target of the frame rate conversion is interlaced or inter-frame mixing is involved in the rate conversion).\n\nMaterial for local TV markets is usually captured at 25 Hz or 50 Hz. Many broadcasters have film archives of 24 frame/s (film speed) content related to news gathering or television production.\n\nLive broadcasts (news, sports, important events) are usually captured at 50 Hz. Using 25 Hz (de-interlacing essentially) for live broadcasts makes them look like they are taken from an archive, so the practice is usually avoided unless there is a motion processor in the transmission chain.\n\nUsually 24 Hz material from film is usually sped up by 4%, when it is of feature film origin. The sound is also raised in pitch slightly as a result of the 4% speedup but pitch correction circuits are typically used.\n\nWith roughly 30 or 60 Hz material, imported from 60 Hz systems, is usually adapted for presentation at 50 Hz by adding duplicate frames or dropping excessive frames, sometimes also involving intermixing consecutive frames. Nowadays, digital motion analysis, although complex and expensive, can produce a superior-looking conversion (though not absolutely perfect).\n\nBecause of higher television production budgets in the US, and a preference for the look of film, many prerecoded TV shows were, in fact, captured onto film at 24 Hz.\n\nSource material filmed at 24 Hz is converted to roughly 60 Hz using the technique called , which includes inserting variable number of duplicate frames, with additional slowdown by the factor of 1.001, if needed. Occasionally, inter-frame mixing is used to smooth the judder.\n\nLive programs are captured at roughly 60 Hz. In the last 15 years, 30 Hz has also become a feasible capture rate when a more \"film like\" look is desired, but ordinary video cameras are used. Capture on video at the film rate of 24 Hz is an even more recent development, and mostly accompanies HDTV production. Unlike 30 Hz capture, 24 Hz cannot be simulated in post production. The camera must be natively capable of capturing at 24 Hz during recording. Because the ~30 Hz material is more \"fluid\" than 24 Hz material, the choice between ~30 and ~60 rate is not as obvious as that between 25 Hz and 50 Hz. When printing 60 Hz video to film, it has always been necessary to convert it to 24 Hz using the reverse 3:2 pulldown. The look of the finished product can resemble that of film, however it is not as smooth, (particularly if the result is returned to video) and a badly done deinterlacing causes image to noticeably shake in vertical direction and lose detail.\n\nReferences to \"60 Hz\" and \"30 Hz\" in this context are shorthand, and always refer to the 59.94 Hz or 60 x 1000/1001 rate. Only black and white video and certain HDTV prototypes ever ran at true 60.000 Hz. The US HDTV standard supports both true 60 Hz and 59.94 Hz; the latter is almost always used for better compatibility with NTSC.\n\n25 or 50 Hz material, imported from 50 Hz systems, can be adapted to 60 Hz similarly, by dropping or adding frames and intermixing consecutive frames. The best quality for 50 Hz material is provided by digital motion analysis.\n\nDigital video is free of many of the limitations of analog transmission formats and presentation mechanisms (e.g. CRT display) because it decouples the behavior of the capture process from the presentation process. As a result, digital video provides the means to capture, convey and present moving images in their original format, as intended by directors (see article about purists), regardless of variations in video standards.\n\nFrame grabbers that employ MPEG or other compression formats are able to encode moving image sequences in their original aspect ratios, resolution and frame capture rates (24/1.001, 24, 25, 30/1.001, 30, 50, 60/1.001, 60 Hz). MPEG—and other compressed video formats that employ motion analysis—help to mitigate the incompatibilities among the various video formats used around the world.\n\nAt the receiving end, a digital display is free to independently present the image sequence at a multiple of its capture rate, thus reducing visible flicker. Most modern displays are \"multisync,\" meaning that they can refresh the image display at a rate most suitable for the image sequence being presented. For example, a multisync display may support a range of vertical refresh rates from 50 to 72 Hz, or from 96 to 120 Hz, so that it can display all standard capture rates by means of an integer rate conversion.\n\nThere are two kinds of displays on the market today: those which \"flash\" a picture for a short part of the refresh period (CRT, cinema projector), and those which display an essentially static image between the moments of refreshing it (LCD, DLP).\n\nThe \"flashing\" displays must be driven at least 48 Hz, although today, a rate significantly below 85 Hz is not considered ergonomic.\n\nFor these displays, the 24–30 Hz material is usually displayed at 2x, 3x, or 4x the capture rate. 50 and ~60 Hz material is usually displayed at its native rate, where it delivers a very accurate motion without any smearing. It can also be displayed at twice the capture rate, although moving objects will look smeared or trailed, unless intermediate frames are calculated using the motion analysis and are not just simply duplicated.\n\nThe \"continuous\" display can be driven at any integer multiple of the capture rate - it won't matter for the viewer, nor can it be visually discriminated. However, in general, \"continuous\" displays show noticeable smear over quickly-moving objects in 50 and ~60 Hz video material (even if their response time is instant). However, there are two emerging techniques to combat smearing of the video-based material in LCD display: it can be effectively converted into the \"flashing\" display by appropriately modulating its backlight; and/or it can be driven at double the capture rate while calculating intermediate frames using the motion analysis (see LCD television).\n\nObviously, when presentation rate is not an integer multiple of the capture rate, the \"fluidity\" of the motion on the screen will suffer to a varying degree (terribly for video-, unpleasantly for film-based material). This is usually the case with computer-based DVD players and PAL PC TVs, where the user does not switch the refresh rate either out of ignorance, or due to technical constraints; which sometimes are, in fact, artificial, made by manufacturers counting on that user's ignorance. For instance some laptop LCD panels cannot be (easily) switched to anything but a 60 Hz refresh rate, and some LCD displays with DVI input refuse to accept digital input signal if its vertical refresh rate does not fit between 58 and 62 Hz.\n\nMost software DVD players do not assist with switching display modes, and even if it is switched manually, they hardly synchronize frame updating with the display's vertical retrace periods. (There is only soft synchronization using hardware double buffering, which is not enough to match hardware players in the stability of playback.)\n\n60 Hz material captures motion a bit more \"smoother\" than 50 Hz material. The drawback is that it takes approximately 1/5 more bandwidth to transmit, if all other parameters of the image (resolution, aspect ratio) are equal. \"Approximately\", because interframe compression techniques, such as MPEG, are a bit more efficient with higher frame rates, because the consecutive frames also become a bit more similar.\n\nThere are, however, technical and political obstacles for adopting a single worldwide video format. The most important technical problem is that quite often the lighting of the scene is achieved with lamps which flicker at a rate related to the local mains frequency. For instance the mercury lighting used in stadiums (twice the mains frequency). Capturing video under such conditions must be done at a matching rate, or the colours will flicker badly on the screen. Even an AC incandescent light may be a problem for a camera if it is underpowered or near the end of its useful life.\n\nThe necessity to select a single universal video format (for the sake of the global material interchange) should anyway become irrelevant in the digital age. The director of video production would then be free to select the most appropriate format for the job, and a video camera would become a global instrument (currently the market is very fragmented).\n\n\n"}
{"id": "1496209", "url": "https://en.wikipedia.org/wiki?curid=1496209", "title": "Multistorey car park", "text": "Multistorey car park\n\nA multistorey car park (UK English) or parking garage (US English; also called a multistorey, parkade (mainly Canadian), parking structure, parking ramp, parking deck or indoor parking) is a building designed for car parking and where there are a number of floors or levels on which parking takes place. It is essentially an indoor, stacked parking lot. Parking structures may be heated if they are enclosed.\n\nDesign of parking structures can add considerable cost for planning new developments, and can be mandated by cities or states in new building parking requirements. Some cities such as London have abolished previously enacted minimum parking requirements.\n\nThe earliest known multi-storey car park was opened in May 1901 by City & Suburban Electric Carriage Company at 6 Denman Street, central London. The location had space for 100 vehicles over seven floors, totaling 19,000 square feet. The same company opened a second location in 1902 for 230 vehicles. The company specialized in the sale, storage, valeting and on-demand delivery of electric vehicles that could travel about 40 miles and had a top speed of 20 miles per hour.\n\nThe earliest known multi-storey car park in the United States was built in 1918 for the Hotel La Salle at 215 West Washington Street in the West Loop area of downtown Chicago, Illinois. It was designed by Holabird and Roche. The Hotel La Salle was demolished in 1976, but the parking structure remained because it had been designated as preliminary landmark status and the structure was several blocks from the hotel. It was demolished in 2005 after failing to receive landmark status from the city of Chicago. A 49-storey apartment tower, 215 West, has taken its place, also featuring a multi-tiered parking garage.\n\nThe movement of vehicles between floors can take place by means of:\n\n\nWhere the car park is built on sloping land, it may be split-level or have sloped parking.\n\nMany car parks are independent buildings dedicated exclusively to that use. The design loads for car parks are often less than the office building they serve (50 psf versus 80 psf), leading to long floor spans of 55–60 feet that permit cars to park in rows without supporting columns in between. The most common structural systems in the United States for these structures are either prestressed concrete double-tee floor systems or post-tensioned cast-in-place concrete floor systems.\n\nIn recent times, car parks built to serve residential and some business properties have been built as part of a larger building, often underground as part of the basement, such as at the Atlantic Station redevelopment in Atlanta. This saves land for other uses (as opposed to a parking lot), is cheaper and more practical in most cases than a separate structure, and is hidden from view. It protects customers and their cars from weather such as rain, snow, or hot summer sunshine that raises a vehicle's interior temperature to extremely high levels. Underground parking of only two levels was considered an innovative concept in 1964, when developer Louis Lesser developed a two-level underground parking structure under six 10-storey high-rise residential halls at California State University, Los Angeles, which lacked space for horizontal expansion in the university. The simple two-level parking structure was considered unusual enough in 1964 that a separate newspaper section entitled \"Parking Underground\" described the garage as an innovative \"concept\" and as \"subterranean spaces\". In Toronto, a 2,400 space parking lot below Nathan Phillips Square is one of the world's largest.\n\nCar parks which serve shopping centres can be built adjacent to the centre for easier access at each floor between shops and parking. One example is Mall of America in Bloomington, Minnesota, USA, which has two large car parks attached to the building, at the eastern and western ends. A common position for car parks within shopping centres in the UK is on the roof, around the various utility systems, enabling customers to take lifts straight down into the centre. Examples of such are The Oracle in Reading and Festival Place in Basingstoke.\n\nThese garages often have low ceiling clearances, which restrict access by full-size vans and other large vehicles. On 15 December 2013, a man was killed during a robbery in the garage at The Mall at Short Hills in Millburn, New Jersey. The paramedics responding to the shooting were delayed because their ambulance was too large to enter the garage.\n\nIn the United States, costs for multi-storey parking structures are estimated to cost between $25,000 per space, with underground parking costing around $35,000 per space.\n\nParking structures are subjected to the heavy and shifting loads of moving vehicles, and must bear the associated physical stresses. Expansion joints are used between sections not only for thermal expansion but to accommodate the flexing of the structure's sections due to vehicle traffic. Seismic retrofits can be applied where earthquakes are an issue.\n\nSome parking structures have partly collapsed, either during construction or years later. In July 2009 a fourth-floor section failed at the Centergy building in midtown Atlanta, pancaking down and destroying more than 30 vehicles but injuring no-one. In December 2007, a car crashed into the wall of the deck at the SouthPark Mall in Charlotte, North Carolina, weakening it and causing a small collapse which destroyed two cars below. On the same day, one under construction in Jacksonville, Florida collapsed as concrete was being poured on the sixth floor. In November 2008, the sudden collapse of the middle level of a deck in Montreal was preceded by warning signs some weeks before, including cracks and water leaks. Parking structures are generally not subject to building inspections after being checked for their initial occupancy permit.\n\nIn October 2012 four people were killed and nine more injured when a parking structure under construction at a campus of Miami-Dade College in Florida collapsed, purportedly due to an unfinished column.\n\nWith the growth of multi-storey car parks since the middle of the twentieth century, many constructions of such structures have been using precast concrete to reduce the construction time. The design involves putting parking structure parts together. The parts of precast concrete include multi-storey structural wall panels, interior and exterior columns, structural floors, girders, wall panels, stairs and slabs. The precast concrete parts are transported using flatbed semi-trailers to the sites. The structural floor modules may need to be laid tilted during the transportation in order to cover as large floor area as possible while they can be easily transported on the roadways. The modules are lifted using precast concrete lifting anchor systems at the sites for assembly. Decorations may include using of covers to close the holes in the precast concrete that contains the lifting anchors, and installing facades to the exterior of the structures.\n\nIn modern construction of the precast modules, there are other features to improve the strength of the structure. An example is to use prestressed strands on post-tensioned concrete for the construction of the shear walls. Another example is the use of carbon-fiber-reinforced polymer to replace steel wire mesh to lighten the load and yield more corrosion resistant especially for the cold-climate areas which use salt for melting snow.\n\nThese structures are not usually known for their architectural value. As \"Architectural Record\" has noted, \"In the Pantheon of Building Types, the parking garage lurks somewhere in the vicinity of prisons and toll plazas.\" \"The New York Times\" has labeled parking structures as \"the grim afterthought of American design\".\n\nA handful of parking garages have received considerable praise for their design, including\n\nThe term \"multistorey car park\" (often abbreviated to \"multistorey\" or \"multistory\") is used in the United Kingdom, Hong Kong, and many Commonwealth of Nations countries, and it is nowadays most commonly spelled without a hyphen. In the western United States, the term \"parking structure\" is used, especially when it is necessary to distinguish such a structure from the \"garage\" connected with a house. In some places in North America, \"parking garage\" refers only to an indoor, often underground, structure. Outdoor, multi-level parking facilities are referred to by a number of regional terms:\n\nArchitects and civil engineers in the USA are likely to call it a parking structure since their work is all about structures and since that term is the vernacular in some of the western United States. When attached to a high-rise of another use, it is sometimes called a parking podium. United States building codes use the term open parking garage to refer to a structure designed for car storage that has openings along at least 40% of the perimeter, as opposed to an enclosed parking garage that requires mechanical ventilation. Natural or mechanical ventilation provides fresh air flow to disperse car exhaust in normal conditions, or hot gas and smoke in case of fire.\n\nTypically car park experts describe the number of car park floors in terms of \"G+x\". G stands for ground and x for the number of floors above ground. For example, G+5 is a multi-story car park structure with a ground floor and 5 floors above that, i.e. a total of 6 floors.\n\n\nStructure car parks are car parks made of structural steel components connected to each other to carry the loads and provide full structural rigidity.\n\nSteel is a high-strength material requiring less material than other types of structures like concrete and timber. Steel construction features:\n\nThe ceiling slab of the steel structure car park is typically made of composite material such as corrugated steel sheets and concrete. The surface of the first-floor parking can be left bare or covered with epoxy or tarmac.\n\nDemand, steel features, and innovation have led to the development of a foundationless, modular, removable steel car park structure.\n\nParking demand often grows quickly, significantly and sometimes unexpectedly. Modular steel car parks could be the proper solution if the surface area available is not sufficient and can be expanded upwards, or whenever it is not feasible to build up a multi-story parking.\nThe development of the building concept of modular car parks came about by using the modular assembling method of vertical and horizontal elements (such as columns and beams)\nModular car park structures are versatile and can be built in phases or in different sizes and shape.\nThe solution makes it possible to develop a parking structure even in case of particular conditions or constraints, such as archaeological sites or city centres, because it allows:\n\nThese parking structures are generally demountable and can be relocated to avoid making the choice of converting a surface to parking area irrevocably. They could be used as permanent structures or are conceived as temporary parking facilities for temporary parking demand needs. A number of parking decks have been demounted after a few years – to make room for the development of a permanent structure – and relocated to respond to local parking demand.\n\nThe earliest use of an automated parking system (APS) was in Paris in 1905 at the Garage Rue de Ponthieu. The APS consisted of a groundbreaking multi-story concrete structure with an internal elevator to transport cars to upper levels where attendants parked the cars. \nA 1931 \"Popular Mechanics\" article speculated an underground garage where the car was taken to a parking area by a conveyor then an elevator to shuttles mounted on rails.\n\nThe total cost of ownership of automated car parks needs to be carefully considered.\n\nThe actual cost of construction of automated car parks is typically higher than conventional car park structures, however, this can be offset by the higher space efficiency of automated car parks. The cost of the mechanical equipment needed to transport the cars needs to be added to the building cost. In addition, operation and maintenance costs of the mechanical equipment need to be added in order to determine the total cost of ownership. Other costs could be saved, for example, there is no need for an energy-intensive ventilating system, since cars are not driven inside and human cashiers or security personnel may not be needed. For naturally ventilated car parks structures, the ventilation equipment is not needed.\n\nAutomated car parks rely on similar technology to that used for mechanical handling and document retrieval. The driver leaves the car in an entrance module, and it is then transported to a parking slot by a robotic trolley. For the driver, the process of parking is reduced to leaving the car inside an entrance module.\n\nAt peak periods a wait may occur before entering or leaving, because loading passengers and luggage occurs at the entrance and exit rather than at the parking stall. This loading blocks the entrance or exit from being available to others. It is generally not recommended to use automated car parks for high peak hour volume facilities.\n\nAdditional factors that need to be taken into consideration are:\n\nModern parking lots utilize a variety of technologies to help motorists find unoccupied parking spaces, car location when returning to the vehicle and improve their experience. This includes adaptive lighting, sensors and parking space LED indicators (red for occupied, green for available and blue is reserved for the disabled; above every parking space), indoor positioning system (IPS), including QR code, and mobile payment options. The Santa Monica Place shopping mall in California has cameras on each stall that can help count the lot occupancy and find lost cars.\n\nOnline booking technology service providers have been created to helped drivers find long-term parking in an automated manner, while also providing significant savings for those who book parking spaces ahead of time. They use real-time inventory management checking technology to display parking lots with availability, sorted by price and distance from the airport.\n\nIn October 2009, the National Building Museum opened an exhibition solely devoted to the study of parking garages (multi-storey car parks) and their impact on the built environment. This exhibition, titled \"House of Cars: Innovation and the Parking Garage\", was on view until 11 July 2010.\n\n\n"}
{"id": "35825797", "url": "https://en.wikipedia.org/wiki?curid=35825797", "title": "Muqeem Khan", "text": "Muqeem Khan\n\nMuqeem Khan () (born 1968) is the first Pakistani who started working in the Hollywood visual effects industry in 1996. He is an animator, artist, interaction designer, percussionist, filmmaker and academician. As a student at National College of Arts (NCA), Muqeem developed passion for computer graphics nearly twenty-five years ago in his early student life by doing some compositions and screen credits in BASIC language on IBM XT, ZX Spectrum and Commodore 64 computers.\n\n\"\" – July 2001 (USA) Visual Effects, Square USA, Honolulu, Hawaii • Visual effects, Rigid/Soft body dynamics and Deformations\n\n\"Armageddon\"- December 1998 (USA) Visual effects, Dream Quest Images, The Walt Disney Company, California • Sparks, fire and debris for the exploding shuttle\n• Effect animation for the debris and rocks• Gases and asteroids\n\n\"Deep Rising\" – January 1998 (USA) Visual effects, Dream Quest Images, The Walt Disney Company, California • Digital rain and tracking of digital cameras\n\n\"George of the Jungle\" – July 1997 (USA) Visual effects, Dream Quest Images, The Walt Disney Company, California • Visual effects and elephant's interaction with the ground\n\n\"Flubber\"- November 1997 (USA) Visual effects, Dream Quest Images, The Walt Disney Company, California• Visual effects for clouds and wisps • Compositing and digital elements for the 3D environment\n\nBeside filmmaking and other creative genres such as poetry, calligraphy and painting, Khan also loves music and as a percussionist, he has been performing Tabla with various musicians around the world. He is a frequent presenter and speaker on VFX in motion pictures, animation and emerging technologies\n\nHe has presented his research in conferences such as 'ACM Graphite' in Singapore, 'Information Visualization' in London, VIEW Conferences in Italy, ascilite conference in Australia, TED@Doha Summit, 'Computers in Education' in New Zealand and International Games Innovation Conference (IGIC) in New York. Muqeem has also served as a member of technical committee, IASTED, The International Association of Science and Technology Development, Alberta, Canada and member of the Editorial Board for \"Design Behaviors\", the College of Design, Hanyang University and Design Research & Education Lab, Korea. He has also served as a program committee member for IGIC 2012 – International Games Innovation Conference.\n\nHe has received his Master of Arts (MDes) in industrial design in 1996 with specialisation in computer graphics and animation from Advanced Computing Center for Arts and Design (ACCAD) and the Department of Industrial, Interior, and Visual Communication at Ohio State University, Columbus Ohio. He also obtained his Bachelor of Science degree in Industrial Design from the same university in 1994. His research interests include the use of emerging haptic and motion detecting techniques in the context of Intangible Cultural Heritage (ICH) and Digital Intangible Heritage. Besides teaching interactive design, graphic design, interior design and concepts for emerging technologies at Virginia Commonwealth University and Northwestern University in Qatar, Khan has been teaching predominantly 2D and 3D animation classes for over 12 years in the Persian Gulf region. As a PhD researcher, his research interests include the use of emerging motion-detecting techniques in the context of Intangible Cultural Heritage (ICH). He has been awarded research grants such as Undergraduate Research Experience Program (UREP) in 2011 and in 2013 National Priorities Research Program (NPRP) from Qatar National Research Funds (QNRF).\n\n"}
{"id": "6794062", "url": "https://en.wikipedia.org/wiki?curid=6794062", "title": "NXP Semiconductors", "text": "NXP Semiconductors\n\nNXP Semiconductors N.V. is a Dutch global semiconductor manufacturer headquartered in Eindhoven, Netherlands. The company employs approximately 31,000 people in more than 35 countries, including 11,200 engineers in 33 countries. NXP reported revenue of $6.1 billion in 2015, including one month of revenue contribution from recently merged Freescale Semiconductor.\n\nOn October 27, 2016, it was announced that Qualcomm would try to buy NXP, but because the Chinese merger authority did not approve the acquisition before the deadline set by Qualcomm, it was effectively canceled on 26 July 2018.\n\nNXP said it was the fifth-largest non-memory semiconductor supplier in 2016, and the leading semiconductor supplier for the secure identification, automotive and digital networking industries. The company was founded in 1953 as part of the electronics firm Philips, with manufacturing and development in Nijmegen, Netherlands. Known then as Philips Semiconductors, the company was sold to a consortium of private equity investors in 2006, at which point the company's name was changed to NXP.\n\nOn August 6, 2010, NXP completed its initial public offering, with shares trading on NASDAQ under the ticker symbol NXPI. On December 23, 2013, NXP Semiconductors was added to the NASDAQ 100. Finally, on March 2, 2015, it was announced that NXP Semiconductors would merge with chip designer and manufacturer Freescale Semiconductor in a $40 billion US-dollar deal. The merger was closed on December 7, 2015.\n\nNXP Semiconductors provides mixed signal and standard products based on its security, identification, automotive, networking, radio frequency, analog signal, and power management expertise. With an emphasis on security of the connected vehicle and the Internet of things, the company's products are used in automotive, identification, wired and wireless infrastructure, lighting, industrial, consumer, mobile and computing applications. For example, in order to protect against potential hackers, NXP offers gateways to automotive manufacturers that prevent communication with every network within a car independently.\n\nNXP is the co-inventor of near field communication (NFC) technology along with Sony and supplies NFC chip sets that enable mobile phones to be used to pay for goods, and store and exchange data securely. NXP manufactures chips for eGovernment applications such as electronic passports; RFID tags and labels; and transport and access management, with the chip set and contactless card for MIFARE used by many major public transit systems worldwide.\n\nIn addition, NXP manufactures automotive chips for in-vehicle networking, passive keyless entry and immobilization, and car radios. NXP invented the I²C interface over 30 years ago and has since supplied products using it. Before the divestiture of Nexperia, NXP was also a volume supplier of standard logic devices, and celebrated its 50 years in logic (via its history as both Signetics and Philips Semiconductors) in March 2012.\n\nNXP owns over 9,000 issued or pending patents.\n\n\n\n\n\nBoth have deep roots stretching back to when they were part of Philips NV (in the case of NXP), and Motorola (Freescale). Each has comparable revenue figures; US$4.8B and US$4.2B for NXP and Freescale respectively in 2013. NXP primarily focuses on near field communication (NFC) and high-performance mixed signal (HPMS) hardware. Freescale focuses on its microprocessor and microcontroller. Both companies possess roughly equal patent portfolios.\n\nCertainly, each company brings core strengths to the combined organization, NFC from NXP and microcontrollers from Freescale. Also, both companies have been actively involved in litigation over the years as both plaintiff and defendant, so a larger and, more importantly, a more geographically diverse patent portfolio could likely prove useful in such matters. Chipworks' analysts suggest the newly merged company will divest itself of many properties as the merger progresses.\n\nSome analysts believe cost savings after the two companies merge are expected to be about $500M dollars. Customers are ultimately divided over the consolidation of their product families and how it may affect their own development and end-products.\n\nNXP Semiconductors is headquartered in Eindhoven, Netherlands. The company has operations in more than 35 countries, with engineering design teams in 23 countries.\n\nNXP currently has 14 manufacturing sites, with seven test and assembly sites and seven wafer fabs:\n\n\n\n\n\n"}
{"id": "44978016", "url": "https://en.wikipedia.org/wiki?curid=44978016", "title": "NeTEx", "text": "NeTEx\n\nNeTEx (formally Network Exchange \"PD CEN/TS 16614-1:2014', PD CEN/TS 16614-2:2014 and PD CEN/TS 16614-3:2014\") is the CEN Technical standard for exchanging Public Transport Information as XML documents. it provides a W3C XML schema based on the Transmodel abstract model of common public transport concepts and data structures and can be used to exchange many different kinds of data between passenger information systems, including data describing for stops, facilities, timetabling and fares. Such data can be used by both operational management systems and customer facing systems for journey planning etc.\n\nNeTEx provides a modular XML schema for public transport information data including passenger information systems, with coverage of a number of different subdomains of PT information, including transport network infrastructure and topology, public transport schedules, journey planning, fares, fare validation. It includes uniform mechanisms for versioning and identifying entity instances within a global context. It provides protocols for exchanging NeTEx XML documents using either asynchronous bulk exchange and any file transfer protocol, or dynamic messaging using http and a set of protocols that make use of the common framework of the Service Interface for Real Time Information. Like Transmodel, on which it is closely based (using [Model Driven Design] concepts), NeTEx provides reusable abstractions to represent data elements of public transport.\n\n\nNeTEx is an evolution and offspring of the Transmodel project, which developed a conceptual model to harmonise and systemise the data formats of a number of European countries. It represents a harmonisation of a number of different European standards such as Bison (Netherlands), Trident (France) TransXChange (UK), VDV 452 (Germany), TAP TSI, for all of which a mapping to NeTEx exists. There is also a mapping to Google's GTFS.\n\nV1.0 of NeTEx was published by CEN in 2014. V1.1 is under development for completion in 2018/2019. \n\nIn 2017, under the Intelligent Transport Systems Priority Action A Directive (2010/40/E), the European Commission recognized NeTEx as a strategic standard for the cross-border exchange of data to enable the provision of EU-wide multi-modal travel information services, with the aim of making public transport data available in NeTEx format at National Access Points in all European countries by 2019.\n\n\n\n"}
{"id": "50491390", "url": "https://en.wikipedia.org/wiki?curid=50491390", "title": "Networked Help Desk", "text": "Networked Help Desk\n\nNetworked Help Desk is an open standard initiative to provide a common API for sharing customer support tickets between separate instances of issue tracking, bug tracking, customer relationship management (CRM) and project management systems to improve customer service and reduce vendor lock-in. The initiative was created by Zendesk in June 2011 in collaboration with eight other founding member organizations including Atlassian, New Relic, OTRS, Pivotal Tracker, ServiceNow and SugarCRM. The first integration, between Zendesk and Atlassian's issue tracking product, JIRA, was announced at the 2011 Atlassian Summit. By August 2011, 34 member companies had joined the initiative. A year after launching, over 50 organizations had joined. Within Zendesk instances this feature is branded as ticket sharing.\n\nSupport tools are generally built around a common paradigm that begins with a customer making a request or an incident report, these create a ticket. Each ticket has a progress status and is updated with annotations and attachments. These annotations and attachments may be visible to the customer (public) or only visible to analysts (private). Customers are notified of progress made on their ticket until it is complete. If the people necessary to complete a ticket are using separate support tools, additional overhead is introduced in maintaining the relevant information in the ticket in each tool while notifying the customer of progress made by each group in completing their ticket. For example, if a customer support issue is caused by a software bug and reported to a help desk using one system, and then the fix is documented by the developers in another, and analyzed in a customer relationship management tool, keeping the records in each system up-to-date and notifying the customer manually using a swivel chair approach is unnecessarily time-consuming and error-prone. If information is not transferred correctly, a customer may have to re-explain their problem each time their ticket is transferred.\n\nFor systems with the Networked Help Desk API implemented, it is possible for several different applications related to a customer's support experience to synchronize data in one uniquely identified shared ticket. While many applications in these domains have implemented APIs that allow data to be imported, exported and modified, Network Help Desk provides a common standard for customer support information to automatically synchronize between several systems. Once implemented two systems can quickly share tickets with just a configuration change as they both understand the same interface.\n\nCommunication between two instances on a specific ticket occurs in three steps, an invitation agreement, sharing of ticket data and continued synchronization of tickets. The standard allows for \"full delegation\" (analysts in both systems each make public and private comments and synchronize status) as well as \"partial delegation\" where the instance receiving the ticket can only make private comments and status changes are not synchronized. Tickets may be shared with multiple instances.\n\nHarvey Kandola of Countersoft suggested that it would be preferable to have a single application that consolidates all tracking related functions, rather than using multiple tools and \"connecting the dots\" with initiatives like the Networked Help Desk.\n\n\n"}
{"id": "364456", "url": "https://en.wikipedia.org/wiki?curid=364456", "title": "PSOLA", "text": "PSOLA\n\nPSOLA (Pitch Synchronous Overlap and Add) is a digital signal processing technique used for speech processing and more specifically speech synthesis. It can be used to modify the pitch and duration of a speech signal. It was invented around 1986.\n\nPSOLA works by dividing the speech waveform in small overlapping segments. To change the pitch of the signal, the segments are moved further apart (to decrease the pitch) or closer together (to increase the pitch). To change the duration of the signal, the segments are then repeated multiple times (to increase the duration) or some are eliminated (to decrease the duration). The segments are then combined using the overlap add technique.\n\nPSOLA can be used to change the prosody of a speech signal.\n\n\n"}
{"id": "56392989", "url": "https://en.wikipedia.org/wiki?curid=56392989", "title": "Philippine Scientific Earth Observation Microsatellite program", "text": "Philippine Scientific Earth Observation Microsatellite program\n\nThe Philippine Scientific Earth Observation Microsatellite (PHL-Microsat) program is a satellite program carried by the Department of Science and Technology (DOST) of the Philippines in cooperation with the Tohoku and Hokkaido Universities of Japan.\n\nHokkaido University and Tohoku University of Japan initiated a project to send 50 microsatellites into space by 2050. The project will photograph aftermaths of natural disasters, partnering with governments, universities and other organizations based in Bangladesh, Indonesia, Malaysia, Myanmar, Mongolia, Philippines, Thailand, and Vietnam. Two satellites are commissioned for the Philippine government.\n\nDiwata-1 is the first satellite of the venture and is also a part of the Department of Science and Technology's Philippine Scientific Earth Observation Micro-Satellite (PHL-Microsat) Program which was initiated in December 2014 by the government agency. The satellite is an updated version of the Raijin-2, which was developed by the two Japanese universities. The satellite was deployed from the International Space Station on April 27, 2016. Diwata-1 will be replaced by Diwata-2 sometime in 2018.\n\nThe Philippine Department of Science and Technology (DOST) announced on June 29, 2017 that two CubeSats or nanosatellites will be launch in 2018. One of these satellites was Maya-1, a nanosatellite developed under the Kyushu Institute of Technology-led Birds-2 project, was launched to space. The equipment is the first nanosatellite of the Philippines and is also placed under the PHL-Microsat program. It is to be deployed from the ISS sometime in August 2018, On August 10, Maya-1 was deployed from the ISS along with satellites from Bhutan and Malaysia.\n\nPart of the program also includes training Filipinos on satellite building capabilities.\n\nIt is planned that within the period of 2017 to 2022, that there will be no single moment that the Philippines has no operating microsatelite in orbit.\n\nThe project is divided into five sub-projects or phases.\n"}
{"id": "2428325", "url": "https://en.wikipedia.org/wiki?curid=2428325", "title": "Potentiostat", "text": "Potentiostat\n\nA potentiostat is the electronic hardware required to control a three electrode cell and run most electroanalytical experiments. A \"Bipotentiostat\" and \"polypotentiostat\" are potentiostats capable of controlling two working electrodes and more than two working electrodes, respectively. \n\nThe system functions by maintaining the potential of the working electrode at a constant level with respect to the reference electrode by adjusting the current at an auxiliary electrode. It consists of an electric circuit which is usually described in terms of simple op amps.\n\nThis equipment is fundamental to modern electrochemical studies using three electrode systems for investigations of reaction mechanisms related to redox chemistry and other chemical phenomena. The dimensions of the resulting data depend on the experiment. In voltammetry, electric current in amps is plotted against electric potential in voltage. In a bulk electrolysis total coulombs passed (total electric charge) is plotted against time in seconds even though the experiment measures electric current (amperes) over time. This is done to show that the experiment is approaching an expected number of coulombs. \n\nMost early potentiostats could function independently, providing data output through a physical data trace. Modern potentiostats are designed to interface with a personal computer and operate through a dedicated software package. The automated software allows the user rapidly to shift between experiments and experimental conditions. The computer allows data to be stored and analyzed more effectively, rapidly, and accurately than historic methods.\n\nA potentiostat is a control and measuring device. It comprises an electric circuit which controls the potential across the cell by sensing changes in its resistance, varying accordingly the current supplied to the system: a higher resistance will result in a decreased current, while a lower resistance will result in an increased current, in order to keep the voltage constant as described by Ohm's law.\n\nAs a result, the variable system resistance and the controlled current are inversely proportional\n\nSince 1942, when Hickling built the first three electrode potentiostat, substantial progress has been made to improve the instrument. Hickling's device used a third electrode, the reference electrode to control the cell potential automatically. Up until the present day his principle has remained in use. At a glance, a potentiostat measures the potential difference between the working and the reference electrode, applies the current through the counter electrode and measures the current as an formula_6 formula_7 voltage drop over a series resistor (formula_8 in Fig. 1).\n\nThe control amplifier (CA) is responsible for maintaining the voltage between the reference and the working electrode as closely as possible to the voltage of the input source formula_9. It adjusts its output to automatically control the cell current so that a condition of equilibrium is satisfied. The theory of operation is best understood using the equations below.\n\nPrior to observing the following equations, one may note that, from an electrical point of view, the electrochemical cell and the current measurement resistor formula_8 may be regarded as two impedances (Fig. 2). formula_11 includes formula_12 in series with the interfacial impedance of the counter electrode and the solution resistance between the counter and the reference. formula_13\nrepresents the interfacial impedance of the working electrode in series with the solution resistance between the working and the reference\nelectrodes. \nThe role of the control amplifier is to amplify the potential difference between the positive (or noninverting) input and the negative (or inverting) input. This may be translated mathematically into the following equation:\n\nwhere formula_15 is the amplification factor of the CA. At this point the assumption may be made that a negligible amount of current is flowing through the reference electrode. This correlates to physical phenomenon since the reference electrode is connected to a high impedance electrometer. Thus, the cell current may be described in two ways:\n\nand\n\nCombining Eqs. (2) and (3) yields Eq. (4):\n\nwhere formula_19 is the fraction of the output voltage of the control amplifier returned to its negative input; namely the feedback factor:\n\nCombining Eqs. (1) and (4) yields Eq. (6):\n\nWhen the quantity formula_19 formula_15 becomes very large with respect to one, Eq. (6) reduces to Eq. (7), which is one of the negative feedback equations:\n\nEq. (7) proves that the control amplifier works to keep the voltage between the reference and the working close to the input source voltage.\n\nReplacing the CA, a control algorithm can maintain a constant voltage formula_25 between the reference electrode and the working electrode. This algorithm is based on the rule of proportion:\n\nIf the measurement intervals of Eq. (8) are kept constant, the control algorithm sets the cell voltage formula_27 so to keep formula_25 as close as possible to the setpoint formula_30. The algorithm requires software-controllable hardware such as a digital multimeter, a power supply, and a double-pull double-though relay. The relay is necessary to switch polarity.\n\nIn electrochemical experiments the electrodes are the pieces of equipment that comes in immediate contact with the analyte. For this reason the electrodes are very important for determining the experimental result. The electrode surface may or may not catalyze chemical reactions. The size of the electrodes affects the magnitude of the currents passed which can affect signal to noise. But electrodes are not the only limiting factor for electrochemical experiments, the potentiostat also has a limited range of operation. The following are a few significant features that vary between instruments.\n\n\n\n"}
{"id": "26921669", "url": "https://en.wikipedia.org/wiki?curid=26921669", "title": "Process analysis", "text": "Process analysis\n\nProcess analysis is a form of technical writing and expository writing \"designed to convey to the reader how a change takes place through a series of stages\". \n\nWhile the traditional process analysis and a set of instructions are both organized chronologically, the reader of a process analysis is typically interested in understanding the chronological components of a system that operates largely without the reader's direct actions (such as how the body digests an apple), while the reader of a set of instructions intends to use the instructions in order to accomplish a specific, limited task (such as how to bake an apple pie). By contrast, the reader of a mechanism description is more interested in an object in space (such as the form and nutritional value of a particular kind of apple).\n"}
{"id": "47020788", "url": "https://en.wikipedia.org/wiki?curid=47020788", "title": "Project Alpha (non-proliferation effort)", "text": "Project Alpha (non-proliferation effort)\n\nProject Alpha is an academic research project working to counter nuclear proliferation-related trade. It was founded in 2011 with funding from the British Government and is housed in the Centre for Science and Security Studies at King's College London. Its primary mission is to publish independent research findings on illicit trade activities and to support the private and the public sectors with the implementation of international trade controls in order to deter the proliferation of nuclear weapons. \n\nProject Alpha has three main strands of work: understanding illicit trade, countering illicit trade and supporting international efforts of non-proliferation. This includes conducting research of proliferation-related case studies for publication on the Alpha website promoting industry engagement with authorities and providing training and consultancy to businesses in order to encourage good practices of compliance with international regulations governing the export of sensitive goods and technologies. It also supports the work of the International Atomic Energy Agency and the implementation of relevant UN Security Council resolutions, including United Nations Security Council Resolution 1540, aimed at preventing the spread of weapons of mass destruction to non-state actors, and sanctions resolutions adopted against Iran and North Korea. \n\nFrom September 2015, Project Alpha has been central to the EU's outreach program on dual-use export controls (the EU's P2P program on dual-use goods). \n\nIn 2016 Project Alpha published a report on Pakistan's nuclear weapons program which identified a large number of front companies and a suspected new uranium enrichment facility. The report received a great deal of media attention, particularly in South Asia. \n\n"}
{"id": "3302238", "url": "https://en.wikipedia.org/wiki?curid=3302238", "title": "Proview International Holdings Ltd", "text": "Proview International Holdings Ltd\n\nProview International Holdings (; ) is a Hong Kong-based manufacturer of computer monitors and other media devices. The company markets its products under its own and other brand name through its extensive distribution network over the world. Proview manufactures CRT and LCD monitors, LCD TVs, Plasma TVs and DVD players. Proview has production facilities located in Shenzhen, Wuhan in China, and in Brazil and Taiwan.\n\nProview holds the \"iPad\" trademark for China and has sued Apple for US$1.6 billion in damages. Apple has countered that the suit is a shakedown to prop up the company due to its significant debt and impending collapse. Apple ended the dispute paying $60 million to Proview.\n"}
{"id": "51684387", "url": "https://en.wikipedia.org/wiki?curid=51684387", "title": "Renewables.ninja", "text": "Renewables.ninja\n\nRenewables.ninja is a web tool developed by Imperial College London and ETH Zürich that shows the estimate amount of energy that could be generated by wind or solar farms at any location. The model has been tested by Iain Staffell who is the codeveloper of renewables.ninja, from the Centre for Environmental Policy at Imperial College London, and Stefan Pfenninger from ETH Zürich to estimate the productivity of all wind farms planned or under construction in Europe for the next 20 years. German electrical supplier RWE are using it to test their own models of output.\n"}
{"id": "25462546", "url": "https://en.wikipedia.org/wiki?curid=25462546", "title": "RioCard", "text": "RioCard\n\nThe RioCard (\"Bilhete Único\") is a smartcard system used in the transport system of Rio de Janeiro state, Brazil. The card is contactless and uses MIFARE technology. It is a form of electronic payment produced and distributed by the Fetranspor company, in cooperation with Itaú bank. Its installation was seen as strengthening Brazil's connection with the Open Standard for Public Transport (OSPT) Alliance.\n\nIn October 2013, Rio de Janeiro launched a trial run for this ticket to be run on smartphones, using near field communication (NFC) technology. Around 200 users of the ticket on buses, trains and ferries were selected for the trial, which involves putting a Motorola Razr D3 within a few inches of the reader terminal. Users can then check the balance of their card. Soon, one will be able to prepay fares by using one's phone.\n\nCreated for commuters (home-work-home), this card can be requested over the Internet or in person and is free of charge, with the minimum credits value of R$40.00 (approximately US $17). This card can be used for any mode of transportation (bus, ferry, subway, train) but can only be used once per trip at a maximum of eight times per day. Requests to add value to the card can only be done online or in RioCard stores, or in RioCard ATMs. Use of the card is limited to the city in which the card was activated or used at least three times in the past 30 days.\n\nThis card is intended for infrequent commutes or people who want to acquire their card more quickly. It is sold at Unibanco locations and can only be purchased with cash. It can be loaded with only fixed amounts of R$40 or R$80 (approximately US $17 or US $34) and cannot be re-loaded; repeat users must purchase a new card once the balance is zero or the remaining credit is insufficient for passage. This card is only intended for use on the most inexpensive form of transportation available. Use in other modes of transportation will require complementary payment in another form. It can be used toward any mode of transportation (bus, ferry, subway, train) but can only be used once per trip at a maximum of eight times per day.\n\nThis monetary card is intended for passengers who want more flexibility for their transport options. It is accepted on buses, ferries, and SuperVia trains but it is only accepted on subways if the RioCard (Bilhete Único) is activated. Express cards are available for purchase at Itaú locations, banks, pharmacies, and online. Cards come pre-filled with either R$40 or R$80 and value can be re-added online on a card with a zero balance or with insufficient funds for passage. This card is only intended for use on the most inexpensive form of transportation available. Use in other modes of transportation will require complementary payment in another form.\n\nCreated exclusively for commuters who travel using multiple modes of transportation and don't possess other forms of the RioCard, the integrated card allows the combination of several modes of transit into one route. This card can be used in up to three kinds of transportation while only deducting a single, fixed price.\n\nRoute options include:\n\nBus lines include: Central, São Cristovão, Cascadura, Madureira, Mercadão de Madureira, Nova Iguaçu, Belford Roxo, Bangu, Campo Grande and Santa Cruz\n\n\nOn December 29, 2009, Law 5628 established the Bilhete Único in the metropolitan region of Rio de Janeiro. The \"Bilhete Único RJ\" costs R$5.25 (US $2.19) and allows the purchaser to utilize up to two different modes of transportation—bus,van, train, ferry, or subway—within three hours as long as one of them is \"integrated\" with other municipalities. This program also benefits those using inter-municipal transportation that costs more than the standard fare. The Bilhete Único RJ can be incorporated with any form of the RioCard. Purchase of the Bilhete Único RJ can be made at any ticketing area for trains, subways, and ferries, as well as in Fetranspor locations and Loja Virtual do Bilhete Único RJ. However, the Bilhete Único RJ cannot be used immediately after purchase. Activation requires a verification of the user's CPF and 48 hours before it is enabled. Air-conditioned buses are not included in this program.\n\nThe Bilhete Único Carioca offers a rate that \"integrates\" the use of two municipal bus lines within the city of Rio de Janeiro. Users can ride up to two municipal buses within two hours for R$3.00 (US $1.25). The card can be used on municipal bus lines within the city of Rio de Janeiro operated by: Internorte, Intersul, Transcarioca e Santa Cruz. Air-conditioned buses are not included in this program. For trips that are not integrated, the card can be used without restriction, enabling the user to pay for various passages on the same vehicle and the normal fare will be discounted. It can be used in any bus line within the state of Rio de Janeiro, regardless of the cost of the fare.\n\nAccording to the Law 2851 enacted in 2011, the Bilhete Único Niterói offers a discounted rate for the integration of municipal buses in the city of Niterói. The electronic card allows users to ride up to two municipal buses within two hours for R$3.90 (US $1.25). Return trips should be made at a minimum of two hours after the card is first scanned in order to utilize the discounted rate. This card can only be used two times per day. Since 2012 air-conditioned buses are included in this program. If used two times in a row on the same bus line, the card will be debited two normal fares. It is now accepted in other modes of transportation, including the Ferry and the Rio de Janeiro Subway.\n\n"}
{"id": "47391798", "url": "https://en.wikipedia.org/wiki?curid=47391798", "title": "Sensibo", "text": "Sensibo\n\nSensibo is a manufacturer of air conditioning controllers.\n\nSensibo was founded in November 2013 by Omer Enbar and Ran Roth.\n\nThe idea originated around 2004 when Omer Enbar had built a personal control system to activate his air conditioner via email prior to biking home from work. The system connected an IR blaster to a laptop that would send a signal to the AC every time he sent an email with the title \"AC on\" or \"AC off\".\n\nDuring 2013, Omer Enbar and Ran Roth manually built and deployed several prototypes to friends and family. They later proceeded to found the company.\n\nIn May 2014, Sensibo launched a successful crowdfunding campaign on Indiegogo. The campaign has raised $165,000 in July 20, 2014. Its campaign video was later selected by Indiegogo as the funniest pitch video of 2014. The video, created by Tross Media and starring Michael Harpaz, has been often compared to Dollar Shave Club and the TV series House of Cards.\n\nSensibo delivered on its crowdfunding campaign during the summer of 2015, shipping thousands of units worldwide, according to the company. In May 2015, Sensibo launched an IFTTT channel, allowing its system to interface with other apps and devices. The devices are being distributed in many countries.\n\nIn January 2017 the company launched its 2nd generation device, Sensibo Sky. Features include: 7-day scheduling, Location based on/off, Multiple users controlling a single device, integration with Amazon Echo and IFTTT.\n"}
{"id": "39675386", "url": "https://en.wikipedia.org/wiki?curid=39675386", "title": "Stressed member engine", "text": "Stressed member engine\n\nA stressed member engine is a vehicle engine used as an active structural element of the chassis to transmit forces and torques, rather than being passively contained by the chassis with anti-vibration mounts. Automotive engineers use the method for weight reduction and mass centralization in vehicles. Applications are found in several vehicles where mass reduction is critical for performance reasons, usually after several iterations of conventional frame/chassis designs have been employed.\n\nStressed member engines was patented in 1900 by Joah (\"John\") Carver Phelon and his nephew Harry Rayner. and were pioneered at least as early as the 1916 Harley-Davidson 8-valve racer, and incorporated in the production Harley-Davidson Model W by 1919. The technique was developed in the 20th century by Vincent and others, and by the end of the century was common feature of chassis built by Ducati, BMW and others.\n\nMany mid-engine sport cars have used stressed engine design.\n\nThe 1967 Lotus 49 is credited for establishing a solution copied by \"everyone\" in Formula One. This requirement is cited as a reason the rules committee changed from an inline-four to a V-6 configuration for the 2014 Formula One season.\n\nThe limited-production De Tomaso Vallelunga mid-engine car prototyped in 1963 used the engine as a stressed member.\n\nIn GM's Chevrolet Bolt and Tesla Motors Model S and Roadster electric cars, the battery pack is a stressed member to increase rigidity.\n\nThe Fordson tractor Model F, designed during World War I, eliminated the frame to reduce cost of materials and assembly, and was probably influenced by the similar design of the 1913 Wallis Cub.\n"}
{"id": "1831255", "url": "https://en.wikipedia.org/wiki?curid=1831255", "title": "This Week in Tech", "text": "This Week in Tech\n\nThis Week in Tech–casually referred to as TWiT, and briefly known as Revenge of the Screen Savers–is the weekly flagship podcast and namesake of the TWiT.tv network. It is hosted by Leo Laporte and many other former TechTV employees and currently produced by Karsten Bondy. It features round-table discussions and debates surrounding current technology news and reviews, with a particular focus on consumer electronics and the Internet. TWiT is produced in the TWiT \"eastside\" studios in Petaluma, California, United States, as of 27 August 2016, a few miles away from the former \"brickhouse\" studios where it was produced for 5 years, and earlier TWiT \"cottage\", where it was produced for over 6 years. The podcast is streamed live on Sundays at 3:00 P.M. PST.\n\nFollowing the show's number, title, sponsors and theme tune, Leo Laporte typically begins an episode of \"TWiT\" by introducing the week's panelists, allowing each of them to discuss his or her recent projects or work. The main portion of the show consists of a round-table discussion and debate, pegged loosely to a selection of the week's major technology headlines. The format of the show encourages spontaneity and the conversation often diverges wildly from technology topics. This causes the length of each episode to vary, sometimes considerably, from show to show, although most episodes run approximately two hours. Each episode typically features three or four commercial breaks, usually in the form of a \"live read\" from Laporte that may include interaction with the panelists (e.g., Laporte usually prompts guests for recommended audiobooks during spots for frequent advertiser Audible.com). The show closes with each panelist giving a personal \"plug\" for their affiliated website or Twitter account.\n\nThe most frequently recurring guests on TWiT include John C. Dvorak, Patrick Norton, Wil Harris, Kevin Rose, Robert Heron, David Prager, Tom Merritt, Roger Chang, Dwight Silverman and Jason Calacanis. Other guests include Becky Worley, Steve Gibson, Xeni Jardin, Alex Lindsay, Owen Stone, Veronica Belmont and Molly Wood.\n\nThe show has had a number of famous guests, including Steve Wozniak, Kevin Mitnick, John Hodgman, Lawrence Lessig, artist Roger McGuinn, as well as \"\" cast members LeVar Burton (Geordi La Forge) and Wil Wheaton (Wesley Crusher).\n\nIn September 2015, Leo Laporte famously \"banned\" his long-time friend and frequent TWiT guest John C. Dvorak from the show for various comments Dvorak made on Twitter. In reply to Dvorak's comments that Laporte was biased, Laporte told Dvorak \"you won't ever have to worry about it again\", insinuating that he never wanted Dvorak back on TWiT. Laporte apologized a few days later, but continued to berate Dvorak publicly. Dvorak has yet to return to the show.\n\nThe program began when Laporte recorded a one-off round-table discussion between himself, Patrick Norton, Sarah Norton, Kevin Rose, David Prager, and Roger Chang at the 2005 Macworld Expo in San Francisco.\n\nAfter publishing the show on his blog to an enthusiastic public reception, Laporte decided to rename this discussion \"episode 0\" and turned the round-table concept into a weekly downloadable audio file, or \"podcast,\" featuring more cast members from his former TechTV program \"The Screen Savers\". The first episode was posted on Monday, April 18, 2005 as \"Revenge of the Screen Savers\", but it was temporarily renamed \"Return of the [BEEP]\" and shortly thereafter changed in response to a cease and desist letter sent to Laporte from Comcast, owners of TechTV's intellectual property rights, arguing it too closely resembled the defunct show's name. (TWiT started using the Screen Savers trademark after Comcast allowed it to expire, and \"The New Screen Savers\" was launched as a separate weekly program on May 2, 2015.) In episode 2, Laporte announced a contest in which listeners could suggest a new name for the show. One listener suggested \"This Week in Geek\", which inspired Laporte to create the eventual name, \"This Week in Tech\", or \"TWiT\".\n\nThe weekly show was originally recorded with all of the hosts staying at their respective homes and talking via Voice over IP (mostly using Skype). Starting around episode 10, Norton began physically coming to Leo's Petaluma office during the taping. Upon Rose's announcement that he was moving to San Francisco, Laporte started to gather the panelists for public live tapings in the San Francisco area, with most episodes being videotaped and released as a video podcast download.\n\nDuring the fall of 2005, several of the previously regular hosts began to move on to other projects, resulting in the format of the show changing from being a show with a core group of hosts and occasional guests, into Laporte being the only regular host, and inviting in a variety of different guests each show. Around the same time, the people responsible for filming the shows, the Pixel Corps and their leader, Alex Lindsay became more involved with the show, with many also contributing.\n\nDuring the first few years TWiT episodes were made available in a variety of file formats for individual download or RSS subscription. These included a standard 64 kbit/s MP3, a low-bandwidth 16 kbit/s MP3, Advanced Audio Coding (AAC), and open source Ogg Vorbis. However, the Ogg Vorbis version of the show ceased to be offered in August 2009 with the AAC and low bandwidth MP3 versions ending in early November 2009. In response, Leo Laporte stated that he was a believer that his content should be made available to the widest audience possible in the format of their choice, as well as philosophically agreeing with the open source nature of Ogg Vorbis. However the time and effort the TWiT Staff needed to encode, upload, and distribute alternate audio formats in the limited time between recording and release each Sunday evening was not justified by the number of people choosing to listen to them.\n\nThe show recording is usually posted every Sunday evening.\n\nAs well as being ranked #1 on Podcast Alley, Yahoo Podcasts, and the iTunes Podcast Directory (where it averages around 315,000 downloads a week), \"TWiT\" has also won two Podcast Awards, as both the \"People's Choice\" and as \"Best Technology Podcast\". This Week in Tech also made Time Magazine's Top 10 Podcasts of 2006, ranked 9th.\nIt also won Podcast of the Year from the 2007 Weblog Awards.\n\nTWiT began as an audio podcast, although several video episodes were filmed in the first few years of the show. Starting in 2008, the show was made available for live streaming in both audio and video formats. Since episode 215 in October 2009, the show has been available weekly as both an audio and video download as well as on YouTube.\n\nAll episodes are licensed under the Creative Commons attribution share-alike noncommercial license, and are distributed via direct download from the TWiT.tv website, from Apple's iTunes Store, or as a subscription on any device with the necessary internet connection and podcasting software. There is no charge to download current or past shows.\n\nThe show is typically available in three formats: 64 kbit/s MP3, 32 kbit/s MP3, and 64 kbit/s AAC. Occasionally, other bitrates are used for episodes produced in stereo, however most episodes are monaural. The files are available as direct downloads, with bandwidth provided by Cachefly. On 23 February 2014, before recording TWiT 446, Laporte stated that episode bandwidth for the entire network is around 950 terabytes per month.\n\nA sponsorship deal with America Online was announced on July 4, 2005, following the server demand that resulted from the release of iTunes 4.9's built-in podcasting directory. Since the new TWiT website was launched, the TWiT Torrent server initially preferred by Laporte has ceased operation. In several episodes, Laporte has noted that the distributed nature of BitTorrent makes it impossible to accurately gauge the popularity of the show, decreasing the likelihood of attracting advertisers. As of episode 174, TWiT began being hosted from AOL Radio. AOL hosting ended in the summer of 2013.\n\nLaporte stated in episode 3 that the show would always remain free and without advertising. However, due to ongoing costs as a result of TWiT.tv's constant expansion, a roadmap for the introduction of podcast and web-based advertising was announced during episode 45 of This WEEK in TECH. On 5 September 2006, TWiT.tv officially became one of the first major advertising-supported podcast networks, sponsored initially by both Visa and Dell.\n\nListeners have always been invited to support the network by means of an automatic PayPal subscription or one-time payment. In the past, this granted access to an exclusive TWiT forum which no longer exists, yet donations are still accepted. Listener funding has been used for the operational costs of the network including improvements to Laporte's recording studio and to purchase radio-quality microphones and digital audio-recording devices for the hosts. Financial compensation for the network mostly comes from the network's sponsors. Sponsors of the network include Ford, Audible, Lantronix, Squarespace, Hulu, Rackspace, Hover, Carbonite, Stamps.com and more.\n\nBefore recording started for This Week in Tech 268 on 3 October 2010, while discussing the sale of TechCrunch to AOL, Laporte mentioned that his network would \"do three to four [million ]\" in advertising revenue for 2010. Based on the increase in the number of sponsored programs as well as the increase in sponsors, the 2013 gross revenue is estimated to be in the eight million dollar range. This Week in Tech Episode 561 on 5/08/2016 had extensive talk about podcast revenue. In the episode, Leo Laporte said a recent NY York Times article stated that podcasts ad revenue was $57 million per year and \"If that's true, than I actually own 25% of all of the podcasting revenue in the world.\" This would put TWIT ad revenue around $13–14 million per year.\n\n\n"}
{"id": "9888705", "url": "https://en.wikipedia.org/wiki?curid=9888705", "title": "Uniform Resource Characteristic", "text": "Uniform Resource Characteristic\n\nIn computer science, a Uniform Resource Characteristic (URC) is a string of characters representing the metadata of a Uniform Resource Identifier (URI), a string identifying a Web resource. A URC binds a URI's associated Uniform Resource Name (URN), a unique name for a Web resource, to its Uniform Resource Locator (URL), the location at which a Web resource can be found. URCs were proposed as a specification in the mid-1990s, but were never adopted.\n\nThe use of a URC would allow the location of a Web resource to be obtained from its standard name, via the use of a resolving service. It was also to be possible to obtain a URC from a URN by the use of a resolving service. The design goals of URCs were that they should be simple to use, easy to extend, and compatible with a wide range of technological systems. The URC syntax was intended to be easily understood by both humans and software.\n\nDuring the early to mid-1990s, basic Web technologies were still in their infancy. Naming documents was, according to Tim Berners-Lee, the inventor of the Web, \"probably the most crucial aspect of design and standardization in an open hypertext system\". In most discussion, naming was partitioned into location (URLs) and identification (URNs) as independent applications of an URI. URCs were a third identifier type, intended to provide a standardized representation of document properties, such as owner, encoding, access restrictions or cost. \n\nURCs were the subject of an IETF working group around 1994/1995. However, the working group never produced a final standard and URCs were never widely adopted in practice. Even so, the concepts on which URCs were based influenced subsequent technologies such as the Dublin Core and Resource Description Framework.\n\n"}
{"id": "41849", "url": "https://en.wikipedia.org/wiki?curid=41849", "title": "Viewdata", "text": "Viewdata\n\nViewdata is a Videotex implementation. It is a type of information retrieval service in which a subscriber can access a remote database via a common carrier channel, request data and receive requested data on a video display over a separate channel. Samuel Fedida, who had the idea for Viewdata in 1968, was credited as inventor of the system. The first prototype became operational in 1974. The access, request and reception are usually via common carrier broadcast channels. This is in contrast with teletext.\n\nOriginally Viewdata was accessed with a special purpose terminal (or emulation software) and a modem running at ITU-T V.23 speed (1200 bit/s down, 75 bit/s up). By 2004 it was normally accessed over TCP/IP using Viewdata client software on a personal computer running Microsoft Windows, or using a Web-based emulator.\n\nAs of 2015, Viewdata was still in use in the United Kingdom, mainly by the travel industry. Travel agents use it to look up the price and availability of package holidays and flights. Once they find what the customer is looking for they can place a booking. \n\nThere are a number of factors still holding up a move to a Web-based standard. Viewdata is regarded within the industry as low-cost and reliable, travel consultants have been trained to use Viewdata and would need training to book holidays on the Internet, and tour operators cannot agree on a Web-based standard. \nIt was made in the late 1970s and early 1980s to make it easier for travel consultants to check availability and make bookings for holidays.\nA number of Viewdata bulletin board systems existed in the 1980s, predominantly in the UK due to the proliferation of the BBC Micro, and a short-lived \"Viewdata Revival\" appeared in the late 1990s fuelled by the retrocomputing vogue. Some Viewdata boards still exist, with accessibility in the form of Java Telnet clients.\n\n\n"}
{"id": "3775889", "url": "https://en.wikipedia.org/wiki?curid=3775889", "title": "Virtual patient", "text": "Virtual patient\n\nThe term virtual patient is used to describe interactive computer simulations used in health care education. The special focus is targeted on the simulation of clinical processes with virtual patients. Virtual patients combine scientific excellence, modern technologies and the innovative concept of game-based learning. Virtual patients allow the learner to take the role of a health care professional and develop clinical skills such as making diagnoses and therapeutic decisions. Virtual patients have also been considered computer-based simulations designed to complement clinical training. The use of virtual patient programmes is increasing in healthcare, partly in response to increasing demands on health care professionals and education of students but also because they allow opportunity for students to practice in a safe environment.\nThere are many different formats a virtual patient may take. However the overarching principle is that of interactivity—a virtual patient will have mechanisms for the learner to interact with the case and material or information is made available to the learner as they complete a range of learning activities. Interactivity is often included with questions, specific decision-making tasks, text-composition etc. and is non-sequential. Most systems provide quantitative and qualitative feedback.\n\nVirtual patients may take a number of different forms:\n\n\nA number of different modes of virtual patient delivery have been defined:\n\nVirtual patients have been shown to be a time-efficient and cost-effective method of developing clinical reasoning skills in students through independent and repeated practice of physician tasks in a safe environment without the risk of harm to the patient or learner, which can significantly increase the mental pool of learned cases in students. Unlike simulated or real patients, virtual patients can be accessed on demand, and the user may monitor a case over several months while spending less than an hour in real-time. Furthermore, virtual patients can be endlessly replayable and can be easily modified to allow the user to explore different clinical scenarios and patient outcomes.  In comparison to simulated patients, virtual patients can also be used as a method of standardized assessment that minimizes variance. Despite their efficacy, simulated patients are still a tangent and prosthesis to reality. They should be viewed as educational tools that augment existing modes and methods of clinical teaching.\n\nThe MedBiquitous consortium established a working group in 2005 to create a free and open data standard for expressing and exchanging virtual patients between different authoring and delivery systems. This was in part to address the problem of exchanging and reusing virtual patients and in part to encourage and support easier and wider use of virtual patients in general.\n\nThis standard has been very successful and is now widely adopted, e.g. in major projects like eViP.\n\nIn 2010, this standard attained status as an ANSI standard.\n"}
{"id": "54449264", "url": "https://en.wikipedia.org/wiki?curid=54449264", "title": "Vogelheimer Klinge", "text": "Vogelheimer Klinge\n\nThe Vogelheimer Klinge (German: Vogelheim Blade) is an approximately 280,000 year old flint tool, discovered in 1926 during the construction of the Rhine-Herne Canal in Vogelheim, north of the city of Essen. In older publications it is also known as the Klingenschaber von Vogelheim. It was long considered to be the oldest accurately dated artifact in North Rhine-Westphalia and can be found in the .\n\n\n"}
