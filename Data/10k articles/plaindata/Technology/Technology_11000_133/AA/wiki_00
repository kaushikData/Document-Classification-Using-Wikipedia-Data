{"id": "33892674", "url": "https://en.wikipedia.org/wiki?curid=33892674", "title": "Alexia Bonatsos", "text": "Alexia Bonatsos\n\nAlexia Bonatsos, , is a venture capitalist and former co-editor of \"TechCrunch\", a technology news website. In 2011, she was listed by \"Forbes\" magazine as among the top 30 under 30 in the Media category.\n\nAlexia Tsotsis was born in 1982. She attended the University of Southern California in Los Angeles, California, and then worked in New York for four years trying to enter the media business, also attending classes at New York University on the side. She then worked at \"LA Weekly\" (in Los Angeles) and after that at \"SF Weekly\" (in San Francisco, California). \n\nIn 2010, she joined \"TechCrunch\". On February 27, 2012, Tsotsis became co-editor of \"TechCrunch\" along with Eric Eldon. The pair of them replaced Erick Schonfeld. This was one of the last of a string of departures that rocked the publication for the months since Michael Arrington's departure in late September 2011.\n\nTsotsis was named among the \"Forbes\" 30 Under 30 in the media category in 2011. In August 2012, \"Business Insider\" published a detailed look at a day in the life of Tsotsis in her role as co-editor of \"TechCrunch\". A video interview of Tsotsis by David Prager was broadcast on Revision3. Her approach to news coverage was also discussed in an article on the website of the Poynter Institute.\n\nIn 2015, she left TechCrunch to complete an accelerated 1 year Masters in Management program at Stanford University. She married Niko Bonatsos, a venture capitalist at General Catalyst, with whom she had cooperated on encouraging Greek technology startups in 2012.\n\nIn late 2017 and early 2018, now using the name Bonatsos, she founded her own venture capital fund, called Dream Machine, based in San Francisco and investing in techology companies.\n"}
{"id": "33959261", "url": "https://en.wikipedia.org/wiki?curid=33959261", "title": "Ancient furniture", "text": "Ancient furniture\n\nThere are few survivals of ancient Greek and Roman furniture, but a number of images in reliefs, painted pottery and other media. It was normally made of wood, but expensive examples were often fitted with metalwork elements, which have a better chance of survival. The styles were generally rather light and elegant in upper-class furniture, and by modern standards apparently not heavily upholstered. Some items entirely in metal, such as lampstands, braziers and stands for sacrifice, have survived, and some covered by the eruption of Mount Vesuvius have either been carbonized or left hollows in the volcanic rock that can be used as moulds for plaster of Paris, allowing a clear idea of their original form. The rich had tables and chairs supported by marble, and some of these have survived. Wicker was widely used for armchairs.\n\nAncient Greek furniture was typically constructed out of wood, though it might also be made of stone or metal, such as bronze, iron, gold and silver. Little wood survives from ancient Greece, though varieties mentioned in texts concerning Greece and Rome include maple, oak, beech, yew, and willow. Pieces were assembled using mortise-and-tenon joinery, held together with lashings, pegs, metal nails, and glue. Wood was shaped by carving, steam treatment, and the lathe, and furniture is known to have been decorated with ivory, tortoise shell, glass, gold or other precious materials. Similarly, furniture could be veneered with expensive types of wood in order to make the object appear more costly, though classical furniture was often pared down in comparison to objects attested in the East, or those from earlier periods in Greece.\n\nExtensive research was done on the forms of Greek furniture by Gisela Richter, who utilized a typological approach based primarily on illustrated examples depicted in Greek art, and it is from Richter’s account that the main types can be delineated.\n\nThe modern word “throne” is derived from the ancient Greek \"thronos\" (Greek singular: θρόνος), which was a seat designated for deities or individuals of high status or honor. The colossal chryselephantine statue of Zeus at Olympia, constructed by Phidias and lost in antiquity, featured the god Zeus seated on an elaborate throne, which was decorated with gold, precious stones, ebony and ivory, according to Pausanias. Less extravagant though more influential in later periods is the \"klismos\" (Greek singular: κλισμός), an elegant Greek chair with a curved backrest and legs whose form was copied by the Romans and is now part of the vocabulary of furniture design. A fine example is shown on the grave stele of Hegeso, dating to the late fifth century B.C.E. As with earlier furniture from the east, the \"klismos\" and \"thronos\" could be accompanied by footstools. There are three types of footstools outlined by Richter – those with plain straight legs, those with curved legs, and those shaped like boxes that would have sat directly on the ground.\n\nThe most common form of Greek seat was the backless stool, which must have been found in every Greek home. These were apparently known as \"diphroi\" (Greek singular: δίφρος), and were easily portable. The Parthenon frieze displays numerous examples, upon which the gods are seated. Several fragments of a stool were discovered in a fourth-century B.C.E. tomb in Thessaloniki, including two of the legs and four transverse stretchers. Once made of wood and covered in silver foil, all that remains of this piece are the parts made of precious metal. \nThe folding stool, known as the \"diphros okladias\" (Greek singular: δίφρος ὀκλαδίας), was practical and portable. The Greek folding stool survives in numerous depictions, indicating its popularity in the Archaic and Classical periods; the type may have been derived from earlier Minoan and Mycenaean examples, which in turn were likely based on Egyptian models. Greek folding stools might have plain straight legs or curved legs that typically ended in animal feet.\n\nA couch or \"kline\" (Roman singular: κλίνη) was a form used in Greece as early as the late seventh century B.C.E. The \"kline\" was rectangular and supported on four legs, two of which could be longer than the other, providing support for an armrest or headboard. Three types are distinguished by Richter – those with animal legs, those with “turned” legs, and those with “rectangular” legs, although this terminology is somewhat problematic. Fabric would have been draped over the woven platform of the couch, and cushions would have been placed against the arm or headrest, making the Greek couch an item well suited for a symposium gathering. The foot of a bronze bed discovered in situ in the House of the Seals at Delos provides an indication of how the “turned” legs of a \"kline\" might have appeared. Numerous images of \"klinai\" are displayed on vases, topped by layers of intricately woven fabrics and pillows. These furnishings would have been made of leather, wool, or linen, though silk could also have been used. Stuffing for pillows, cushions, and beds could have been made of wool, feathers, leaves, or hay.\n\nIn general, Greek tables (Greek singular: τράπεζα, τρἰπους, τετράπους, φάτνη, ὲλεóς) were low and often appear in depictions alongside \"klinai\" and could perhaps fit underneath. The most common type of Greek table had a rectangular top supported on three legs, though numerous configurations exist. Tables could have circular tops, and four legs or even one central leg instead of three. Tables in ancient Greece were used mostly for dining purposes – in depictions of banquets, it appears as though each participant would have utilized a single table, rather than a collective use of a larger piece. On such occasions, tables would have been moved according to one's needs.\n\nTables also would have figured prominently in religious contexts, as indicated in vase paintings. One example by the Chicago Painter from The Art Institute of Chicago, dating to around 450 B.C.E., shows an image of three women performing a Dionysian ritual, in which a table functions as an appropriate place to rest a \"kantharos\" – a wine vessel associated with Dionysus. Other images indicate that tables could range in style from the highly ornate to the relatively unadorned.\n\nTo a large extent, the types and styles of ancient Roman furniture followed those of their Classical and Hellenistic Greek predecessors. Because of this it is difficult to differentiate Roman forms from earlier Hellenistic ones in many cases. Gisela Richter’s typological approach is useful in tracing developments of Greek furniture into Roman expressions. Knowledge of Roman furniture is derived mainly from depictions in frescoes and representations in sculpture, along with actual pieces of furniture, fragments, and fittings, several of which were preserved by the eruption of Vesuvius in AD 79. The most well-known archaeological sites with preserved images and fragments from the eruption are Pompeii and Herculaneum in Italy. There are fine examples of reconstructed Roman furniture at the Metropolitan Museum of Art in New York City as well as the Capitoline Museum in Rome.\n\nThe \"sella\", or stool or chair, was the most common type of seating in the Roman period, probably because of its easy portability. In addition, the \"sella\" in its simplest form was inexpensive to make. Both slaves and emperors used it, although those of the poor were surely plain, while the wealthy had access to precious woods, ornamented with inlay, metal fittings, ivory, and silver and gold leaf. Bronze \"sellae\" from Herculaneum were square in form and had straight legs, decorative stretchers, and a dished seat. The \"sella curulis\", or folding stool, was an important indicator of power in the Roman period. There were \"sellae\" resembling both stools and chairs that folded in a scissor fashion to facilitate transport. \n\nThe Roman \"cathedra\" was a chair with a back, although there is disagreement as to the exact meaning of the Latin term. Richter defines the \"cathedra\" as a later version of the Greek \"klismos\", which she says was never as popular as its Greek predecessor. A. T. Croom, however, considers the \"cathedra\" to be a high-backed wickerwork chair that was typically associated with women. They have also been seen being used as early school teachers, pupils would sit around him in this chair while he taught. It showed who held the seat of power in the classroom. As with Greek furniture, the names of various Roman types as found in texts cannot always be associated with known furniture forms with certainty.\n\nThe Latin \"solium\" is considered to be equivalent to the Greek term \"thronos\" and thus is often translated as “throne.” These were like modern chairs, with backs and arm rests. Three types of \"solia\" based on Greek prototypes are distinguished by Richter: thrones with “turned” and “rectangular” legs and grandiose thrones with solid sides, of which several examples remain in stone. In addition, a type with a high back and arms, resting upon a cylindrical or conical base, is said to derive from Etruscan prototypes.\n\nFew actual Roman couches survive, although sometimes the bronze fittings do, which help with the reconstruction of the original forms. While in wealthy households beds were used for sleeping in the bedrooms (\"lectus cubicularis\"), and couches for banqueting while reclining were used in the dining rooms (\"lectus tricliniaris\"), the less well off might use the same piece of furniture for both functions. The two types might be used interchangeably even in richer households, and it is not always easy to differentiate between sleeping and dining furniture. The most common type of Roman bed took the form of a three-sided, open rectangular box, with the fourth (long) side of the bed open for access. While some beds were framed with boards, others had slanted structures at the ends, called \"fulcra\", to better accommodate pillows. The \"fulcra\" of elaborate dining couches often had sumptuous decorative attachments featuring ivory, bronze, copper, gold or silver ornamentation.\n\nThe bench, or \"subsellium\", was an elongated stool for two or more users. Benches were considered to be “seats of the humble,” and were used in peasant houses, farms, and bathhouses. However, they were also found in lecture halls, in the vestibules of temples, and served as the seats of senators and judges. Roman benches, like their Greek precedents, were practical for the seating of large groups of people and were common in theaters, amphitheaters, odeons and auctions. The \"scamnum\", related to the \"subsellium\" but smaller, was used as both a bench and a footstool.\n\nTypes of Roman tables include the \"abacus\" and the \"mensa\", which are distinguished from one another in Latin texts. The term \"abacus\" might be used for utilitarian tables, such as those for making shoes or kneading dough, as well as high-status tables, such as sideboards for the display of silver. A low, three-legged table, thought to represent the \"mensa delphica\", was often depicted next to reclining banqueters in Roman paintings. This table has a round tabletop supported by three legs configured like those of a tripod. Several wooden tables of this type were recovered from Herculaneum.\n\nThe most important source for wooden furniture of the Roman period is the collection of carbonized furniture from Herculaneum. While the eruption of Vesuvius in 79 C.E. was tremendously destructive to the region, the hot liquid lava that engulfed the town of Herculaneum ultimately preserved the wooden furniture, shelves, doors, and shutters in carbonized form. Their preservation, however, is imperiled, as some of the pieces remain in situ in their houses and shops, encased in unprotected glass or entirely open and accessible. Upon excavation, much of the furniture was conserved with paraffin wax mixed with carbon powder, which coats the wood and obscures important details such as decorations and joinery. It is now impossible to remove the wax coating without further damaging the furniture. Several wooden pieces were found with bone and metal fittings.\n\nWooden shelving and racks are fund in shops and kitchens in the Vesuvian sites, and one house has elaborate wooden room dividers.\n"}
{"id": "4867808", "url": "https://en.wikipedia.org/wiki?curid=4867808", "title": "Andante ticket", "text": "Andante ticket\n\nAndante is a public transport ticketing system used in and around Porto, Portugal. \nIt started operation in November 2002 at Metro do Porto stations and is now a cross-network ticket used on the Porto Metro, selected bus and train routes and the Funicular dos Guindais cable railway.\n\nTwo types of card are currently in use:\n\nOccasional tickets can be bought at the terminals in stations. Ticket machines can recharge both kinds of ticket, although Gold tickets can only be purchased in \"Lojas Andante\" (Andante Shops). Tickets can also be recharged at MultiBanco ATMs. When purchasing tickets, passengers must select how many zones the card will allow travel within. The minimum Z2 (2 zone) ticket allows travel for 1 hour after validation, with allowed travel time increasing for each valid zone purchased.\n\nUnlike others ticket zoning systems, Andante zones are not concentric. This makes the system slightly fairer, but also slightly more complicated. To travel within the same zone or up to one neighbouring zone you need Z2 ticket, the more zones you need to cross, the higher the Z ticket you need. Although with Andante Occasional you can use your tickets in any zones, with Andante Gold you must choose in advance which zones you will be travelling in.\n\nThe system uses ISO/IEC 14443 type B for communication between card readers (check-in points, automatic vending machines, vending stores and controller handsets) and the card itself. The system is entirely contactless, with validation activated by holding the ticket a short distance in front of the reader for about a second. Teams of ticket inspectors make random checks across the network with hand-held ticket readers.\n\n"}
{"id": "16737449", "url": "https://en.wikipedia.org/wiki?curid=16737449", "title": "Card association", "text": "Card association\n\nA card association is a network of issuing banks and acquiring banks that process payment cards of a specific brand.\n\nFamiliar payment card association brands include China UnionPay, RuPay, Visa, MasterCard, American Express, Discover, Diner's Club, and JCB. Visa, MasterCard and American Express issuers co-brand with their card association. for example, Wells Fargo Visa\" and \"Citi MasterCard\".\n\nCard associations Visa and MasterCard each comprise over 20,000 card issuing banks.\n\nAmong United States consumers alone, over 600 million payment cards are in circulation.\n\nWorldwide, Visa issuers have over 1.5 billion payment cards in circulation.\n"}
{"id": "19372206", "url": "https://en.wikipedia.org/wiki?curid=19372206", "title": "Community design", "text": "Community design\n\nA Community design is a unitary industrial design right that covers the European Union. It has both unregistered and registered forms. The unregistered Community design came into effect on 6 March 2002 and the registered Community design was available from 1 April 2003.\n\nCouncil Regulation (EC) No 6/2002, as implemented by Commission Regulation (EC) No 2245/2002, created both unregistered and registered European Community designs. The Community design is a unitary right that has equal effect across the European Union. The unregistered form of the right has existed since 6 March 2002 while the registered form came into effect on 1 April 2003.\n\nA design is defined as \"the appearance of the whole or a part of a product resulting from the features of, in particular, the lines, contours, colours, shape, texture and/or materials of the product itself and/or its ornamentation\".\n\nDesigns may be protected if:\n\nThe scope of protection conferred by a Community design includes any design which does not produce a different overall impression on an informed user, taking the degree of freedom of the designer into consideration. A Community design further confers on its holder the exclusive right to use it and to prevent any third party not having his consent from using it. For an unregistered Community design, however, the contested use must have resulted from copying the protected design.\n\nAn unregistered Community design lasts for a period of 3 years from the date on which the design was first\nmade available to the public within the Community. A design shall be deemed to have been made available to the public within the Community if \"it has been published, exhibited, used in trade or otherwise disclosed in such a way that, in the normal course of business, these events could reasonably have become known to the circles specialised in the sector concerned, operating within the Community. The design shall not, however, be deemed to have been made available to the public \"for the sole reason that it has been disclosed to a third person under explicit or implicit conditions of confidentiality.\" \n\nA registered Community design (RCD) lasts for up to 25 years from the date on which an application for registration was filed, subject to the payment of maintenance fees. The registration process is administered by the EUIPO in Alicante.\n\nThe unregistered Community design provides useful, short-term protection for items of short market duration. The registered Community design provides substantial cost savings compared to obtaining national registrations in individual European countries. The Community design also permits those having business in a number of European countries to protect their designs in all of those countries more simply.\n"}
{"id": "14795559", "url": "https://en.wikipedia.org/wiki?curid=14795559", "title": "Condominial sewerage", "text": "Condominial sewerage\n\nCondominial sewerage is the application of simplified sewerage coupled with consultations and ongoing interactions between users and agencies during planning and implementation. The term is used primarily in Latin America, particularly in Brazil, and is derived from the term \"condominio\", which means housing block.\n\nFrom a pure engineering perspective there is no difference between designing a regular sewage system and a condominial one. However, bureaucratically a condominial system includes the participation of the individuals and owners who will be served and can often result in lower costs due to shorter runs of piping. This is achieved by local concentration of sewage from a single \"housing block\". Thus a number of dwellings are grouped into a \"block\" known as a condominium. The condominium may share no other aspects of ownership or relation except geographic proximity. In addition, individuals and owners may share a role in the maintenance of the sewers at the block level.\n"}
{"id": "3562951", "url": "https://en.wikipedia.org/wiki?curid=3562951", "title": "Crown glass (window)", "text": "Crown glass (window)\n\nCrown glass was an early type of window glass. In this process, glass was blown into a \"crown\" or hollow globe. This was then transferred from the blowpipe to a punty and then flattened by reheating and spinning out the bowl-shaped piece of glass (bullion) into a flat disk by centrifugal force, up to 5 or 6 feet (1.5 to 1.8 metres) in diameter. The glass was then cut to the size required.\n\nThe thinnest glass was in a band at the edge of the disk, with the glass becoming thicker and more opaque toward the center. Known as a bullseye, the thicker center area around the pontil mark was used for less expensive windows. In order to fill large window spaces with the best glass, many small diamond shapes would be cut from the edge of the disk and these would be mounted in a lead lattice work and fitted into the window frame. \n\nCrown glass was one of the two most common processes for making window glass until the 19th century. The other was blown plate. The process was first perfected by French glassmakers in the 1320s, notably around Rouen, and was a trade secret. As a result, crown glass was not made in London until 1678.\n\nCrown glass is one of many types of hand-blown glass. Other methods include: broad sheet, blown plate, polished plate and cylinder blown sheet. These methods of manufacture lasted at least until the end of the 19th century. The early 20th century marks the move away from hand-blown to machine manufactured glass such as rolled plate, machine drawn cylinder sheet, flat drawn sheet, single and twin ground polished plate and float glass.\n"}
{"id": "3678714", "url": "https://en.wikipedia.org/wiki?curid=3678714", "title": "Crystal detector", "text": "Crystal detector\n\nA crystal detector is an obsolete electronic component in some early 20th century radio receivers that used a piece of crystalline mineral as a detector (demodulator) to rectify the alternating current radio signal to extract the audio modulation which produced the sound in the earphones. It was the first type of semiconductor diode, and one of the first semiconductor electronic devices. The most common type was the so-called cat whisker detector, which consisted of a piece of crystalline mineral, usually galena (lead sulfide), with a fine wire touching its surface. The \"asymmetric conduction\" of electric current across electrical contacts between a crystal and a metal was discovered in 1874 by Karl Ferdinand Braun. Crystals were first used as a radio wave detector in 1894 by Jagadish Chandra Bose in his microwave experiments. and crystal detectors were first patented by Bose in 1901. The crystal detector was developed into a practical radio component mainly by G. W. Pickard, who began research on detector materials in 1902 and found hundreds of substances that could be used in forming rectifying junctions. The physical principles by which they worked were not understood at the time they were used, but subsequent research into these primitive point contact semiconductor junctions in the 1930s and 1940s led to the development of modern semiconductor electronics.\n\nThe unamplified radio receivers that used crystal detectors were called crystal radios. The crystal radio was the first type of radio receiver that was used by the general public, and became the most widely used type of radio until the 1920s. It became obsolete with the development of vacuum tube receivers around 1920, but continued to be used until World War 2.\n\nThe contact between two dissimilar materials at the surface of the detector's semiconducting crystal forms a crude semiconductor diode, which acts as a rectifier, conducting electric current in only one direction and resisting current flowing in the other direction. In a crystal radio, it was connected between the tuned circuit, which passed on the oscillating current induced in the antenna from the desired radio station, and the earphone. Its function was to act as a demodulator, rectifying the radio signal, converting it from alternating current to a pulsing direct current, to extract the audio signal (modulation) from the radio frequency carrier wave. The audio frequency current produced by the detector passed through the earphone causing the earphone's diaphragm to vibrate, pushing on the air to create sound waves. This diagram shows a simplified explanation of how it works:\nCrystal radios had no amplifying components to increase the loudness of the radio signal; the sound power produced by the earphone came solely from the radio waves of the radio station being received, intercepted by the antenna. Therefore, the sensitivity of the detector was a major factor determining the sensitivity and reception range of the receiver, motivating much research into finding sensitive detectors. \n\nIn addition to its main use in crystal radios, crystal detectors were also used as radio wave detectors in scientific experiments, in which the DC output current of the detector was registered by a sensitive galvanometer, and in test instruments such as wavemeters used to calibrate the frequency of radio transmitters.\nThe crystal detector consisted of an electrical contact between the surface of a semiconducting crystalline mineral and either a metal or another crystal. The construction of the detector depended on the type of crystal used, as different minerals varied in how much contact area and pressure on the crystal surface was needed to make a sensitive rectifying contact. Crystals that required a light pressure like galena were used with the wire cat whisker contact; silicon was used with a heavier point contact, while silicon carbide (carborundum) required the heaviest pressure. Another type used two crystals of different minerals with their surfaces touching, the most common being the \"Perikon\" detector. Since the detector would only function when the contact was made at certain spots on the crystal surface, the contact point was almost always made adjustable. Below are the major categories of crystal detectors used during the early 20th century:\n\nPatented by Pickard in 1906 this was the most common type of crystal detector, mainly used with galena but also other crystals. It consisted of a pea-size piece of crystalline mineral in a metal holder, with its surface touched by a fine metal wire or needle (the \"cat whisker\").\n\nOnly certain sites on the crystal surface functioned as rectifying junctions. The device was very sensitive to the exact geometry and pressure of contact between wire and crystal, and the contact could be disrupted by the slightest vibration. Therefore, a usable point of contact had to be found by trial and error before each use. The wire was suspended from a moveable arm and was dragged across the crystal face by the user until the device began functioning. In a crystal radio, the user would tune the radio to a strong local station if possible and then adjust the cat whisker until the station or radio noise (a static hissing noise) was heard in the radio's earphones. This required some skill and a lot of patience. An alternative method of adjustment was to use a battery-operated buzzer connected to the radio's ground wire or inductively coupled to the tuning coil, to generate a test signal. The spark produced by the buzzer's contacts functioned as a weak radio transmitter whose radio waves could be received by the detector, so when a rectifying spot had been found on the crystal the buzz could be heard in the earphones, at which time the buzzer was turned off. \n\nThe detector consisted of two parts mounted next to each other on a flat nonconductive base:\n\nInvented in 1906 by Henry H. C. Dunwoody, this consisted of a piece of silicon carbide (SiC, then known by the trade name \"carborundum\"), either clamped between two flat metal contacts, or mounted in fusible alloy in a metal cup with a contact consisting of a hardened steel point pressed firmly against it with a spring. Carborundum, an artificial product of electric furnaces produced in 1893, required a heavier pressure than the cat whisker contact. The carborundum detector was popular because its sturdy contact did not require readjustment each time it was used, like the delicate cat whisker devices. Some carborundum detectors were adjusted at the factory and then sealed and did not require adjustment by the user. It was not sensitive to vibration and so was used in shipboard wireless stations where the ship was rocked by waves, and military stations where vibration from gunfire could be expected. Another advantage was that it was tolerant of high currents, and could not be \"burned out\" by atmospheric electricity from the antenna. Therefore, it was the most common type used in commercial radiotelegraphy stations.\n\nCarborundum is a semiconductor with a wide band gap of 3 eV, so to make the detector more sensitive a forward bias voltage of several volts was usually applied across the junction by a battery and potentiometer. The voltage was adjusted with the potentiometer until the sound was loudest in the earphone. The bias moved the operating point to the curved \"knee\" of the device's current-voltage curve, which produced the largest rectified current.\n\nPatented and first manufactured in 1906 by Pickard, this was the first type of crystal detector to be commercially produced. Silicon required more pressure than the cat whisker contact, although not as much as carborundum. A flat piece of silicon was embedded in fusible alloy in a metal cup, and a metal point, usually brass or gold, was pressed against it with a spring. The surface of the silicon was usually ground flat and polished. Silicon was also used with antimony and arsenic contacts. The silicon detector had some of the same advantages as carborundum; its firm contact could not be jarred loose by vibration, so it was used in commercial and military radiotelegraphy stations.\nThe \"Perikon\" detector, invented 1908 by Pickard consisted of two crystals in metal holders, mounted face to face with their surfaces touching, forming a crystal-to-crystal contact. One crystal was zincite (zinc oxide, ZnO), the other was a copper iron sulfide, either bornite (CuFeS) or chalcopyrite (CuFeS). In Pickard's commercial detector \"(see picture)\", multiple zincite crystals were mounted in a fusible alloy in a round cup \"(on right)\", while the chalcopyrite crystal was mounted in a cup on an adjustable arm facing it \"(on left)\". The chalcopyrite crystal was moved forward until it touched the surface of one of the zincite crystals. When a sensitive spot was located, the arm was locked in place with the setscrew. Multiple zincite pieces were provided because the fragile zincite crystal could be damaged by excessive currents and tended to \"burn out\" due to atmospheric electricity from the wire antenna or currents leaking into the receiver from the powerful spark transmitters used at the time. This detector was also sometimes used with a small forward bias voltage of around 0.2V from a battery to make it more sensitive.\n\nAlthough the zincite-chalcopyrite \"Perikon\" was the most widely used crystal-to-crystal detector, other crystal pairs were also used. Zincite was also used with carbon, galena, and tellurium. Silicon was used with arsenic, antimony and tellurium crystals.\nDuring the first three decades of radio, from 1888 to 1918, called the \"wireless telegraphy\" or \"spark\" era, primitive radio transmitters called spark gap transmitters were used, which generated radio waves by an electric spark. These transmitters were unable to produce the continuous sinusoidal waves which are used to transmit audio (sound) in modern AM or FM radio transmission. Instead spark gap transmitters transmitted information by wireless telegraphy; the user turned the transmitter on and off rapidly by tapping on a telegraph key, producing pulses of radio waves which spelled out text messages in Morse code. Therefore, the radio receivers of this era did not have to demodulate the radio wave, extract an audio signal from it as modern receivers do, they merely had to detect the presence or absence of the radio waves, to make a sound in the earphone when the radio wave was present to represent the \"dots\" and \"dashes\" of Morse code. The device which did this was called a \"detector\". The crystal detector was the most successful of many detector devices invented during this era. \n\nThe crystal detector evolved from an earlier device, the first primitive radio wave detector, called a \"coherer\", developed in 1890 by Édouard Branly and used in the first radio receivers in 1894–96 by Marconi and Oliver Lodge. Made in many forms, the coherer consisted of a high resistance electrical contact, composed of conductors touching with a thin resistive surface film, usually oxidation, between them. Radio waves changed the resistance of the contact, causing it to conduct a DC current. The most common form consisted of a glass tube with electrodes at each end, containing loose metal filings in contact with the electrodes. Before a radio wave was applied, this device had a high electrical resistance, in the megohm range. When a radio wave from the antenna was applied across the electrodes it caused the filings to \"cohere\" or clump together and the coherer's resistance fell, causing a DC current from a battery to pass through it, which rang a bell or produced a mark on a paper tape representing the \"dots\" and \"dashes\" of Morse code. Most coherers had to be tapped mechanically between each pulse of radio waves to return them to a nonconductive state.\n\nThe coherer was a very poor detector, motivating much research to find better detectors. It worked by complicated thin film surface effects, so scientists of the time didn't understand how it worked, except for a vague idea that radio wave detection depended on some mysterious property of \"imperfect\" electrical contacts. Researchers investigating the effect of radio waves on various types of \"imperfect\" contacts to develop better coherers, invented crystal detectors.\n\nThe \"unilateral conduction\" of crystals was discovered by Karl Ferdinand Braun, a German physicist, in 1874 at the University of Würzburg. He studied copper pyrite (CuFeS), iron pyrite (iron sulfide, FeS), galena (PbS) and copper antimony sulfide (CuSSb).\nBraun did not use these as radio detectors, as radio waves had not been discovered yet, but was interested in the nonlinear current–voltage characteristic that these sulfides exhibited. Graphing the current as a function of voltage across a contact made by a piece of mineral touched by a wire cat whisker he found the result was a line that curved upward, instead of a straight line, showing that these substances did not obey Ohm's law. Due to this characteristic the crystal had up to twice as much resistance to current in one direction as it did to current in the other. In 1877 and 1878 he reported further experiments with psilomelane, (Ba,HO)MnO). Braun did investigations which ruled out several possible causes of asymmetric conduction, such as electrolytic action and some types of thermoelectric effects.\n\nThe first person to use crystals for radio wave detection was Indian physicist Jagadish Chandra Bose of the University of Calcutta in his landmark 60 GHz microwave optics experiments from 1894 to 1900.\nLike other scientists since Hertz, Bose was investigating the similarity between radio waves and light by duplicating classic optics experiments with radio waves. He first used a coherer consisting of a steel spring pressing against a metal surface with a current passing through it. Unsatisfied with this detector, around 1897 Bose measured the change in resistivity of dozens of metals and metal compounds exposed to microwaves, finding that in some the resistivity increased and in some it decreased.\nHe experimented with many substances as contact detectors, focusing on galena. His detectors consisted of a small galena crystal with a metal point contact pressed against it with a thumbscrew, mounted inside a closed waveguide ending in a horn antenna to collect the microwaves. Bose passed a current from a battery through the crystal, and used a galvanometer to measure it. When microwaves struck the crystal the galvanometer registered a drop in resistance of the detector. He found these detectors were also sensitive to visible light and ultraviolet, leading him to call them an \"artificial retina\". Lee has pointed out that Bose's detectors did not function as diodes, rectifying the radio waves as later galena detectors did, but as thermal bolometer detectors. Most sources do not make this distinction and credit Bose with inventing the galena detector. He patented the detector 30 September 1901. This is often considered the first patent on a semiconductor device.\n\nGreenleaf Whittier Pickard may be the person most responsible for making the crystal detector a practical device. Pickard, an engineer with the American Wireless Telephone and Telegraph Co. invented the rectifying contact detector, discovering rectification of radio waves in 1902 while experimenting with a coherer detector consisting of a carbon block resting across two steel knife edge contacts. On 29 May 1902 he was operating this device, listening to a radiotelegraphy station. Coherers required an external current source to operate, so he had the coherer and telephone earphone connected in series with a 3 cell battery to provide power to operate the earphone. Annoyed by background \"frying\" noise caused by the current through the carbon, he reached over to cut two of the battery cells out of the circuit to reduce the current\nThe generation of an audio signal without a DC bias battery made Pickard realize the device was acting as a rectifier. During the next four years, Pickard conducted an exhaustive search to find which substances formed the most sensitive detecting contacts, eventually testing thousands of minerals, and discovered about 250 rectifying crystals. In 1906 he obtained a sample of fused silicon, an artificial product recently synthesized in electric furnaces, and it outperformed all other substances. He patented the silicon detector 30 August 1906. In 1907 he formed a company to manufacture his detectors, Wireless Specialty Products Co., and the silicon detector was the first crystal detector to be sold commercially. Pickard went on to produce other detectors using the crystals he had discovered; the more popular being the iron pyrite \"Pyron\" detector and the zincite–chalcopyrite crystal-to-crystal \"Perikon\" detector in 1908, which stood for \"PERfect pIcKard cONtact\".\n\n \nGuglielmo Marconi developed the first practical wireless telegraphy transmitters and receivers in 1896, and radio began to be used for communication around 1899. The coherer was used as detector for the first 10 years, until around 1906. During the wireless telegraphy era prior to 1920, there was virtually no broadcasting; radio served as a point-to-point text messaging service. Until the triode vacuum tube began to be used around World War 1, radio receivers had no amplification and were powered only by the radio waves picked up by their antennae. Long distance radio communication depended on high power transmitters (up to 1 MW), huge wire antennas, and a receiver with a sensitive detector. \n\nCrystal detectors were invented by several researchers at about the same time. Braun began to experiment with crystal detectors around 1899, around when Bose patented his galena detector.\nPickard invented his silicon detector in 1906. Also in 1906 Henry Harrison Chase Dunwoody,\na retired general in the U.S. Army Signal Corps, patented the silicon carbide (carborundum) detector, Braun patented a galena cat whisker detector in Germany,\nand L. W. Austin invented a silicon–tellurium detector.\n\nAround 1907 crystal detectors replaced the coherer and electrolytic detector to become the most widely used form of radio detector. Until the triode vacuum tube began to be used during World War 1, crystals were the best radio reception technology, used in sophisticated receivers in wireless telegraphy stations, as well as in homemade crystal radios. In transoceanic radiotelegraphy stations elaborate inductively coupled crystal receivers fed by mile long wire antennas were used to receive transatlantic telegram traffic. Much research went into finding better detectors and many types of crystals were tried. The goal of researchers was to find rectifying crystals that were less fragile and sensitive to vibration than galena and pyrite. Another desired property was tolerance of high currents; many crystals would become insensitive when subjected to discharges of atmospheric electricity from the outdoor wire antenna, or current from the powerful spark transmitter leaking into the receiver. Carborundum proved to be the best of these; it could rectify when clamped firmly between flat contacts. Therefore, carborundum detectors were used in shipboard wireless stations where waves caused the floor to rock, and military stations where gunfire was expected. \n\nIn 1907–1909, George Washington Pierce at Harvard conducted research into how crystal detectors worked. Using the new cathode ray tube, he produced the first pictures of the waveforms in a working detector, proving that it did rectify the radio wave. During this era, before modern solid-state physics, most scientists believed that crystal detectors operated by some thermoelectric effect. Although Pierce didn't discover the mechanism by which it worked, he did prove that the existing theories were wrong; his oscilloscope waveforms showed there was no phase delay between the voltage and current in the detector, ruling out thermal explanations. Pierce originated the name \"crystal rectifier\".\n\nBetween about 1905 and 1915 new types of radio transmitters were developed which produced continuous sinusoidal waves: the arc converter (Poulsen arc) and the Alexanderson alternator. These slowly replaced the old damped wave spark transmitters. Besides having a longer transmission range, these transmitters could be modulated with an audio signal to transmit sound by amplitude modulation (AM). It was found that, unlike the coherer, the rectifying action of the crystal detector allowed it to demodulate an AM radio signal, producing audio (sound). Although other detectors used at the time, the electrolytic detector, Fleming valve and the triode could also rectify AM signals, crystals were the simplest, cheapest AM detector. As more and more radio stations began experimenting with transmitting sound after World War 1, a growing community of radio listeners built or bought crystal radios to listen to them.\nUse continued to grow until the 1920s when vacuum tube radios replaced them.\n\nSome semiconductor diodes have a property called \"negative resistance\" which means the current through them decreases as the voltage increases over a part of their I–V curve. This allows a diode, normally a passive device, to function as an amplifier or oscillator. For example, when connected to a resonant circuit and biased with a DC voltage, the negative resistance of the diode can cancel the positive resistance of the circuit, creating a circuit with zero AC resistance, in which spontaneous oscillating currents arise. \n\nThis property was first observed in crystal detectors around 1909 by William Henry Eccles\nand Pickard.\nThey noticed that when their detectors were biased with a DC voltage to improve their sensitivity, they would sometimes break into spontaneous oscillations. However these researchers just published brief accounts and didn't pursue the effect.\n\nThe first person to exploit negative resistance practically was self-taught Russian physicist Oleg Losev, who devoted his career to the study of crystal detectors. In 1922 working at the new Nizhny Novgorod Radio Laboratory he discovered negative resistance in biased zincite (zinc oxide) point contact junctions. \nHe realized that amplifying crystals could be an alternative to the fragile, expensive, energy-wasting vacuum tube. He used biased negative resistance crystal junctions to build solid-state amplifiers, oscillators, and amplifying and regenerative radio receivers, 25 years before the invention of the transistor.\nLater he even built a superheterodyne receiver. However his achievements were overlooked because of the success of vacuum tubes. His technology was dubbed \"Crystodyne\" by science publisher Hugo Gernsback one of the few people in the West who paid attention to it. After ten years he abandoned research into this technology and it was forgotten.\n\nThe negative resistance diode was rediscovered with the invention of the tunnel diode in 1957, for which Leo Esaki won the 1973 Nobel Prize in Physics. Today, negative resistance diodes such as the Gunn diode and IMPATT diode are widely used as microwave oscillators in such devices as radar speed guns and garage door openers.\n\nIn 1907 British Marconi engineer Henry Joseph Round noticed that when direct current was passed through a silicon carbide (carborundum) point contact junction, a spot of greenish, bluish, or yellowish light was given off at the contact point. Round had constructed a light emitting diode (LED). However he just published a brief two paragraph note about it and did no further research.\n\nWhile investigating crystal detectors in the mid-1920s at Nizhny Novgorod, Oleg Losev independently discovered that biased carborundum and zincite junctions emitted light.\nLosev was the first to analyze this device, investigate the source of the light, propose a theory of how it worked, and envision practical applications. He published his experiments in 1927 in a Russian journal,\nand the 16 papers he published on LEDs between 1924 and 1930 constitute a comprehensive study of this device. Losev did extensive research into the mechanism of light emission.\nHe measured rates of evaporation of benzine from the crystal surface and found it was not accelerated when light was emitted, concluding that the luminescence was a \"cold\" light not caused by thermal effects. He theorized correctly that the explanation of the light emission was in the new science of quantum mechanics, speculating that it was the inverse of the photoelectric effect discovered by Albert Einstein in 1905.\nHe wrote to Einstein about it, but did not receive a reply. Losev designed practical carborundum electroluminescent lights, but found no one interested in commercially producing these weak light sources.\n\nLosev died in World War 2. Due partly to the fact that his papers were published in Russian and German, and partly to his lack of reputation (his upper class birth barred him from a college education or career advancement in Soviet society, so he never held an official position higher than technician) his work is not well known in the West.\n\nIn the 1920s, the amplifying triode vacuum tube, invented in 1907 by Lee De Forest, replaced earlier technology in both radio transmitters and receivers.\nAM radio broadcasting spontaneously arose around 1920, and radio listening exploded to become a hugely popular pastime. The initial listening audience for the new broadcasting stations was probably largely owners of crystal radios. But lacking amplification, crystal radios had to be listened to with earphones, and could only receive nearby local stations. The amplifying vacuum tube radios which began to be mass-produced in 1921 had greater reception range, did not require the fussy adjustment of a cat whisker, and produced enough audio output power to drive loudspeakers, allowing the entire family to listen comfortably together, or dance to Jazz Age music. \n\nSo during the 1920s vacuum tube receivers replaced crystal radios in all except poor households.\nCommercial and military wireless telegraphy stations had already switched to more sensitive vacuum tube receivers. Vacuum tubes temporarily put an end to crystal detector research. The temperamental, unreliable action of the crystal detector had always been a barrier to its acceptance as a standard component in commercial radio equipment and was one reason for its rapid replacement. Frederick Seitz, an early semiconductor researcher, wrote:\nThe crystal radio became a cheap alternative receiver for people who couldn't afford tube radios: teenagers, the poor, and those in developing countries. Building a crystal set remained an educational project to introduce people to radio. The galena detector, the most widely used type among amateurs, became virtually the only detector used in crystal radios from this point on. The carborundum junction saw some use as a detector in early vacuum tube radios because it was more sensitive than the triode grid-leak detector. Crystal radios were kept as emergency backup radios on ships. During World War 2 in Nazi-occupied Europe the radio saw use as an easily concealed, easily constructed clandestine radio by Resistance groups. After World War 2, the development of modern semiconductor diodes finally made the galena cat whisker detector obsolete.\n\nSemiconductor devices like the crystal detector work by quantum mechanical principles; their operation cannot be explained by classical physics. The birth of quantum mechanics in the 1920s was the necessary foundation for the development of semiconductor physics in the 1930s, during which physicists arrived at an understanding of how the crystal detector worked.\nThe German word \"halbleiter\", translated into English as \"semiconductor\", was first used in 1911 to describe substances whose conductivity fell between conductors and insulators, such as the crystals in crystal detectors.\nFelix Bloch and Rudolf Peierls around 1930 applied quantum mechanics to create a theory of how electrons move through a crystal. In 1931, Alan Wilson created quantum band theory which explains the electrical conductivity of solids. Werner Heisenberg conceived the idea of a \"hole\", a vacancy in a crystal lattice where an electron should be, which can move about the lattice like a positive particle; both electrons and holes conduct current in semiconductors. \n\nA breakthrough came when it was realized that the rectifying action of crystalline semiconductors was not due to the crystal alone but to the presence of impurity atoms in the crystal lattice.\nIn 1930 Bernhard Gudden and Wilson established that electrical conduction in semiconductors was due to trace impurities in the crystal, a \"pure\" semiconductor did not act as a semiconductor, but as an insulator (at low temperatures). The maddeningly variable activity of different pieces of crystal when used in a detector, and the presence of \"active sites\" on the surface, was due to natural variations in the concentration of these impurities throughout the crystal. Nobel Laureate Walter Brattain, coinventor of the transistor, noted:\nThe \"metallurgical purity\" chemicals used by scientists to make synthetic experimental detector crystals had about 1% impurities which were responsible for such inconsistent results. During the 1930s progressively better refining methods were developed, allowing scientists to create ultrapure semiconductor crystals into which they introduced precisely controlled amounts of trace elements (called doping). This for the first time created semiconductor junctions with reliable, repeatable characteristics, allowing scientists to test their theories, and later making manufacture of modern diodes possible. \nThe theory of rectification in a metal-semiconductor junction, the type used in a cat whisker detector, was developed in 1938 independently by Walter Schottky\nat Siemens & Halske research laboratory in Germany and Nevill Mott\nat Bristol University, UK. Mott received the 1977 Nobel Prize for Physics. In 1949 at Bell Labs William Shockley derived the Shockley diode equation which gives the nonlinear exponential current-voltage curve of a crystal detector, observed by scientists since Braun and Bose, which is responsible for rectification .\nThe development of microwave technology during the 1930s run up to World War 2 for use in radar led to the resurrection of the point contact crystal detector.\nMicrowave radar receivers required a nonlinear device that could act as a mixer, to mix the incoming microwave signal with a local oscillator signal, to shift the microwave signal down to a lower intermediate frequency (IF) at which it could be amplified. The vacuum tubes used as mixers at lower frequencies in superheterodyne receivers could not function at microwave frequencies due to excessive capacitance. In the mid-1930s George Southworth at Bell Labs, working on this problem, bought an old cat whisker detector and found it worked at microwave frequencies. Hans Hollmann in Germany made the same discovery. The MIT Radiation Laboratory launched a project to develop microwave detector diodes, focusing on silicon, which had the best detecting properties. By about 1942 point-contact silicon crystal detectors for radar receivers such as the 1N21 and 1N23 were being mass-produced, consisting of a slice of boron-doped silicon crystal with a tungsten wire point pressed firmly against it. The cat whisker contact did not require adjustment, and these were sealed units. A second parallel development program at Purdue University produced germanium diodes. Such point-contact diodes are still being manufactured, and may be considered the first modern diodes. \n\nAfter the war, germanium diodes replaced galena cat whisker detectors in the few crystal radios being made. Germanium diodes are more sensitive than silicon diodes as detectors, because germanium has a lower forward voltage drop than silicon (0.3 vs 0.7 volts). Today a few galena cat whisker detectors are still being made, but only as antique replicas or devices for science education.\n\n\n\n\n"}
{"id": "55761682", "url": "https://en.wikipedia.org/wiki?curid=55761682", "title": "Cuvva", "text": "Cuvva\n\nCuvva is a London based fintech start up using software to offer car insurance over flexible time periods. The company sells hourly insurance through its app in a move designed to appeal to infrequent drivers. The company was founded by James Billingham and Freddy Macnamara. As of April 2017, the app had over 100,000 downloads.\n\nMacnamara has said that the company was inspired by a 2013 conversation in a bar where he commented to a friend that \"It was ridiculous that you couldn’t borrow a car for an hour, because of the difficulty of getting short-term cover [...] I could order an Uber or a Deliveroo to my house, but I couldn’t buy insurance for a short period quickly.\" \n\nThe company's business strategy is designed to offer an alternative to annual insurance to drivers who cover fewer than 4,000 miles per year. \n\nThe company raised over £2 million in funding since 2014 from various investors including Techstars Ventures, Tekton Ventures, Seedcamp, Nick Hungerford (founder of Nutmeg) and Ian Hogarth (founder of SongKick). \n\nCity A.M. awarded the business Fintech Company of the Year in November 2017.\n\n"}
{"id": "8172769", "url": "https://en.wikipedia.org/wiki?curid=8172769", "title": "Differential sticking", "text": "Differential sticking\n\nDifferential sticking is a problem that occurs when drilling a well with a greater well bore pressure than formation pressure, as is usually the case. The drill pipe is pressed against the wellbore wall so that part of its circumference will see only reservoir pressure, while the rest will continue to be pushed by wellbore pressure. As a result, the pipe becomes stuck to the wall, and can require millions of pounds of force to remove, which may prove impossible. In many cases the drilling fluid (mud) weight is reduced, thus relieving the pressure difference and releasing the stuck pipe string. Should this option be unavailable, as in sour gas wells, a specialty fishing company is called to retrieve the stuck pipe or 'fish'. Many options exist once a fishing company is on site: oil or nitrogen may be pumped down the well, or the fish may be 'washed over' using a carbide shoe on a string of washpipe. Jarring is not usually attempted with differential sticking due to the massive amount of pressure that holds the pipe in place.\n\n<br>\n"}
{"id": "32810809", "url": "https://en.wikipedia.org/wiki?curid=32810809", "title": "Drum handler", "text": "Drum handler\n\nDrum handler is a mechanical equipment that is used to handle and transport cylindrical module such as steel drums, barrels, plastic drums and fiber drums. It has spring-loaded metal arms for a tight and secure grip. This equipment is commonly used in chemical and petroleum industries, as well as industries that require shipping and storing cylindrical modules.\n\nThe drum handler is usually used for handling standard size 55-gallon drum container. However, there are models that can handle smaller and bigger capacity drums. This equipment can be used to lift, stack, move, weigh, pour and rack drums and barrels. Drum handlers are usually made of heavy duty metals with smooth coating.\n\nThere are different types of Drum Handlers available in today's market; forklift attachment, mobile drum handler, below-hook drum handler and drum rotator.\n\n\"Forklift Attachment\" is a type of drum handler that is designed to easily slide into a forklift truck. This type of drum handler is used to efficiently and safely load and unload different sizes and types of drums. Once inserted into forklift trucks, operators can easily clamp, lift and transport drums anywhere. Forklift drum handlers are available in different models such as forklift mounted, carrier with tilt function, carrier without tilt function, waist type, rim type and multi-drum carrier.\n\n\"Mobile Drum Handler\" is a stand-alone type of drum handler. Unlike the forklift attachments, mobile drum handlers have built in wheels so you can easily maneuver it anywhere. This type of drum handlers is made with stainless steel and also has a wide heavy duty jaw that can grip the top rim of standard drums. There are two types of mobile drum handler; manual and hydraulic powered. Drum dollies, palletizer, vertical lift pourer and spotter are good examples of mobile drum handler.\n\n\"Below-hook drum handler\" is commonly used to lift, tilt and pour drums. It is made with premium grade stainless steel and features hydraulic powered lifting mechanism with chain puller. It features a grip which holds the drum below the third ribbing or underneath. It also has lifting eyes or fork packets for added support. Examples of below-hook drum handler are drum pourers and drum lift carriers.\n\n\"Drum rotator\" is used to invert and rotate drums as well as transfer contents from one container to another. This type of drum handler features ring gear and rotator that can either be electric powered or hydraulic powered. Examples of drum rotators are tumblers, drum rollers, portable rollers and stationary drum rollers.\n"}
{"id": "12122248", "url": "https://en.wikipedia.org/wiki?curid=12122248", "title": "Erythritol tetranitrate", "text": "Erythritol tetranitrate\n\nErythritol tetranitrate (ETN) is an explosive compound chemically similar to PETN, though it is thought to be a third more sensitive to friction and impact. ETN is not well known, but in recent years has been used by amateur experimenters to replace PETN in improvised detonation cord or in boosters to initiate larger, less sensitive explosive charges. Due to the availability of erythritol as a natural sweetener and its relative ease of production in relation to PETN, ETN is a favoured homemade explosive compound to the amateur experimenter.\n\nLike many nitrate esters, ETN acts as a vasodilator, and was the active ingredient in the original \"sustained release\" tablets, made under a process patent in the early 1950s, called \"nitroglyn\". Ingesting ETN or prolonged skin contact can lead to absorption and what is known as a \"nitro headache\".\n\nETN has a relatively high velocity of detonation of 8000–8100 m/s at a density of 1.7219 (±0.0025) g/cm. It is white in color and odorless. ETN is commonly cast into mixtures with other high explosives. It is somewhat sensitive to shock and friction, so care should be taken while handling. ETN dissolves readily in acetone and other ketone solvents. The impact and friction sensitivity is slightly higher than the sensitivity of pentaerythritol tetranitrate\n(PETN). The sensitivity of melt cast and pressed ETN is comparable. Lower nitrates of erythritol, such as erythritol trinitrate, are soluble in water, so they do not contaminate most ETN samples.\n\nMuch like PETN, ETN is known for having a very long shelf life. Studies that directly observed the crystalline structure saw no signs of decomposition after four years of storage at room temperature. ETN has a melting point of 61°C, compared to PETN which has a melting point of 141.3°C. Recent studies of ETN decomposition suggested a unimolecular rate-limiting step in which the O-NO2 bond is cleaved and begins the decomposition sequence.\n\nETN can and should be recrystalized, as to remove the trapped acids from synthesis. Warm ethanol or methanol is a viable solvent (close to 10 g of ETN/100 ml EtOH). ETN will precitipate as big platelets with bulk density of about 0.3 g/cm (fluffy material) when crashed into several liters of cold water. Smaller, fine crystals are produced by slow addition of water in said ETN/ethanol solution with intense mixing. ETN can be easily hand pressed to about 1.2 g/cm (with a slight risk of accidental detonation).\n\nETN can be melt-cast in warm (about 65°C) water. Slight decomposition is possible (often betrayed by change in color from white to very light yellow). Nonetheless, no reports of runaway reactions leading to explosion have been confirmed (when melt casting using only a bucket of warm water and recrystalized ETN). Melt cast ETN, if cooled down slowly over a period of 10 - 30 minutes, has density of 1.70 g/cm, detonation velocity of 8040 m/s, and P detonation pressure of about 300 kbar. Its brisance is far higher than that of Semtex (about 220 kbar, depending on brand)\n\nETN is often plasticized using PIB/synthethic oil binders (very comparable to the binder system in C4) or using liquid nitric esters. The PIB-based plastic explosives are nontoxic and completely comparable to C4 or Semtex with P between 200 and 250 kbar, depending on density (influenced by crystal size, binder amount, and amount of final rolling). EGDN/ETN/NC systems are toxic to touch, quite sensitive to friction, and impact but generally slightly more powerful than C4 (P of about 250 kbar na E = 5.3 MJ/Kg) and more powerful than Semtex (P of about 220 kbar and E = below 5 MJ/kg)- with P of about 250 - 270 kbar and E around 6 MJ/kg. Note that different explosive softwares and different experimental tests will yield absolute detonation pressures that can vary by 5 % or more with the relative proportions being maintained.\n\nOne quality this explosive has, that PETN does not, is a positive oxygen balance, which means that ETN possesses more than enough oxygen in its structure to fully oxidize all of its carbon and hydrogen upon detonation. This can be seen in the schematic chemical equation below.\n\nWhereas PETN decomposes to:\n\nThe carbon monoxide (CO) still requires oxygen to complete oxidation to carbon dioxide (CO). A detailed study of the decomposition chemistry of ETN has been recently elucidated.\n\nThus, for every two moles of ETN that decompose, one free mole of O is released. This could be used to oxidize an added metal dust or an oxygen-deficient explosive such as TNT or PETN.\n\nLike other nitrated polyols, ETN is made by nitrating erythritol through the mixing of concentrated sulfuric acid and a nitrate salt. Thoroughly dried ammonium nitrate or potassium nitrate is commonly used for this type of reaction. Ammonium nitrate is superior in terms of yields and ease of manufacture. The erythritol is added to the mixture to begin its nitration. Much better yields can be obtained by using concentrated nitric acid in place of the nitrate salt, in which case the sulfuric acid is used simply to absorb water and act as a catalyst from the resulting esterification, driving the reaction. The first part of the reaction requires significant cooling in an ice bath, the KNO/sulfuric acid route needs about an hour of cooling, conc. HNO/sulfuric acid route requires about 25 minutes. It is important to perform the last step at about 20°C - for about an hour in the case of KNO/sulfuric route or for about 5 minutes in the case of concentrated nitric acid/sulfuric acid mix. Lower final temperature is going to yield only the trinitrate and lower esters and these are soluble in water. The reaction times for ammonium nitrate route are intermediate between these two. Using a closed, glass container with a plastic lid is a common amateur practice, that limits the amount of escaping NOx fumes. Constant mixing via shaking, glass rod, or a magnetic stirrer is required.\n\n"}
{"id": "7209369", "url": "https://en.wikipedia.org/wiki?curid=7209369", "title": "Fiber-reinforced concrete", "text": "Fiber-reinforced concrete\n\nFiber-reinforced concrete (FRC) is concrete containing fibrous material which increases its structural integrity. It contains short discrete fibers that are uniformly distributed and randomly oriented. Fibers include steel fibers, glass fibers, synthetic fibers and natural fibers – each of which lend varying properties to the concrete. In addition, the character of fiber-reinforced concrete changes with varying concretes, fiber materials, geometries, distribution, orientation, and densities.\n\nThe concept of using fibers as reinforcement is not new. Fibers have been used as reinforcement since ancient times. Historically, horsehair was used in mortar and straw in mudbricks. In the 1900s, asbestos fibers were used in concrete. In the 1950s, the concept of composite materials came into being and fiber-reinforced concrete was one of the topics of interest. Once the health risks associated with asbestos were discovered, there was a need to find a replacement for the substance in concrete and other building materials. By the 1960s, steel, glass (GFRC), and synthetic (such as polypropylene) fibers were used in concrete. Research into new fiber-reinforced concretes continues today.\n\nFibers are usually used in concrete to control cracking due to plastic shrinkage and to drying shrinkage. They also reduce the permeability of concrete and thus reduce bleeding of water. Some types of fibers produce greater impact–, abrasion–, and shatter–resistance in concrete. Generally fibers do not increase the flexural strength of concrete, and so cannot replace moment–resisting or structural steel reinforcement. Indeed, some fibers actually reduce the strength of concrete.\n\nThe amount of fibers added to a concrete mix is expressed as a percentage of the total volume of the composite (concrete and fibers), termed \"volume fraction\" (V). V typically ranges from 0.1 to 3%. The aspect ratio (l/d) is calculated by dividing fiber length (l) by its diameter (d). Fibers with a non-circular cross section use an equivalent diameter for the calculation of aspect ratio. If the fiber's modulus of elasticity is higher than the matrix (concrete or mortar binder), they help to carry the load by increasing the tensile strength of the material. Increasing the aspect ratio of the fiber usually segments the flexural strength and toughness of the matrix. However, fibers that are too long tend to \"ball\" in the mix and create workability problems.\n\nSome recent research indicated that using fibers in concrete has limited effect on the impact resistance of the materials. This finding is very important since traditionally, people think that ductility increases when concrete is reinforced with fibers. The results also indicated that the use of micro fibers offers better impact resistance to that of longer fibers.\n\nThe High Speed 1 tunnel linings incorporated concrete containing 1 kg/m³ of polypropylene fibers, of diameter 18 & 32 μm, giving the benefits noted below.\n\nPolypropylene and nylon fibers can:\n\nSteel fibers can:\n\nBlends of both steel and polymeric fibers are often used in construction projects in order to combine the benefits of both products; structural improvements provided by steel fibers and the resistance to explosive spalling and plastic shrinkage improvements provided by polymeric fibers.\n\nIn certain specific circumstances, steel fiber or macro synthetic fibers can entirely replace traditional steel reinforcement bar (\"rebar\") in reinforced concrete. This is most common in industrial flooring but also in some other precasting applications. Typically, these are corroborated with laboratory testing to confirm that performance requirements are met. Care should be taken to ensure that local design code requirements are also met, which may impose minimum quantities of steel reinforcement within the concrete. There are increasing numbers of tunnelling projects using precast lining segments reinforced only with steel fibers.\n\nMicro-Rebar has also been recently tested and approved to replace traditional reinforcement in vertical walls designed in accordance with ACI 318 Chapter 14. \n\nAn FRC sub-category named High-Performance Fiber Reinforced Concrete (HPFRC) claims 500 times more resistance to cracking and 40 percent lighter than traditional concrete. HPFRC claims it can sustain strain-hardening up to several percent strain, resulting in a material ductility of at least two orders of magnitude higher when compared to normal concrete or standard fiber-reinforced concrete. HPFRC also claims a unique cracking behavior. When loaded to beyond the elastic range, HPFRC maintains crack width to below 100 µm, even when deformed to several percent tensile strains. Field results with HPFRC and The Michigan Department of Transportation resulted in early-age cracking.\n\nRecent studies performed on a high-performance fiber-reinforced concrete in a bridge deck found that adding fibers provided residual strength and controlled cracking. There were fewer and narrower cracks in the FRC even though the FRC had more shrinkage than the control. Residual strength is directly proportional to the fiber content.\n\nSome studies were performed using waste carpet fibers in concrete as an environmentally friendly use of recycled carpet waste. A carpet typically consists of two layers of backing (usually fabric from polypropylene tape yarns), joined by CaCO filled styrene-butadiene latex rubber (SBR), and face fibers (majority being nylon 6 and nylon 66 textured yarns). Such nylon and polypropylene fibers can be used for concrete reinforcement. Other ideas are emerging to use recycled materials as fibers: recycled Polyethylene terephthalate (PET) fiber, for example.\n\n\n"}
{"id": "21380680", "url": "https://en.wikipedia.org/wiki?curid=21380680", "title": "Global Alliance for EcoMobility", "text": "Global Alliance for EcoMobility\n\nThe EcoMobility Alliance is a global, cross-sectoral partnership for the affirmation of EcoMobility i.e. the \"integrated promotion of walking, cycling, wheeling and passenging\". The Alliance promotes EcoMobility for the purpose of mobility and accessibility for all, health, clean air, noise avoidance, energy efficiency, greenhouse gas emission reduction and individual cost savings, and thus as an opportunity for sustainable urban development.\n\nThe EcoMobility Alliance was created in October 2011 in Changwon, Korea. It is a transformation of the earlier \"Global Alliance for EcoMobility\",which is a non-governmental organization founded and launched in Bali on 10 December 2007, on the occasion of the 2007 United Nations Climate Change Conference (UNFCCC-COP-13).\n\nThe EcoMobility Alliance has defined itself as a \"global\" actor because of both the origin and nature of its members and its geographical scope. It aims at engaging public and private actors from different sectors and segments from all over the world, as well as promoting and advocating for EcoMobility at a global level, both in industrialized and developing countries.\n\nThe EcoMobility Alliance defines 'EcoMobility' as an integrated form of environmentally sustainable mobility that combines the use of non motorized means of transport with the use of public transport to allow people to move in their local environments without utilizing privately owned motor vehicles.\n\nNon motorized means of transport include:\"walking - cycling - wheeling\": walking, using the bicycles, tricycle, velomobile, wheelchairs, mobility scooter, walking aids, scooters, skates, push scooters, trailer, hand carts, shopping carts/trolleys, carrying aids and the above vehicles with supporting electrical drive (preferably powered by renewables);\n\nThe use of public transport is referred to as \"“passenging”\" and includes:the use of buses, trams, subways, light rail, trains, ferries, collective taxis and taxis (if low-emission)\n\nThe word EcoMobility was first coined by , Secretary General of ICLEI and of the Global Alliance for EcoMobility, in February 2007. It is the English equivalent of the German word , first used by Otto-Zimmermann at the end of the 1980s while working on a project promoting the integrated use of \"environmentally friendly\" modes of transport, and more specifically walking, cycling and public transport.\n\nThe word 'Umweltverbund' quickly caught the attention of transport professionals and gained prominence within the field. With over several years of experience in the field of environmental protection, urban planning and sustainable transport, Otto-Zimmermann was determined that a new word was needed to define collectively compound means of transport, excluding cars, lorries and planes. Subsequently, the word 'EcoMobility' was created with the intent of being self-explanatory and aiming to catch the attention of stakeholders in various sectors and becoming part of their daily activities and vocabulary.\n\nCurrently the word 'EcoMobility' is still a rarely used term, with the notable exception of the Government of Canada, which has engaged in the reduction of emissions from urban passenger transport, launching an \"ecoMobility Program\". The Government of Canada is one of the few actors who have used the word \"EcoMobility\" in the context and with the connotation originally meant by Otto-Zimmermann. The French Railway company SNCF has also engaged in the affirmation of Ecomobility, intending it as 'environmentally-friendly, sustainable travel' that is cheaper, easier, more accessible and more efficient thanks to door-to-door travel involving train + tram, bike, car-sharing or 'segway' electric two-wheelers. The promotion of EcoMobility is also at the core of the activities of the Global Alliance for EcoMobility, which aims at spreading the idea and practice of EcoMobility amongst users, the business, policy makers and experts.\n\nThe EcoMobility Alliance membership consists of leading global and regional-level organizations representing four different categories of stakeholders, that is policy makers, professional expertise, production-trade-services, users. The four different segments in which the EcoMobility Alliance is active - walking, cycling, wheeling and passenging – are represented in its membership. The different nature of the members is considered by them as a crucial element to secure a balanced and fair representation, a deeper exchange of ideas and expertise and real integration among the various segments.\n\nCurrently, the Global Alliance for EcoMobility includes the following members:\nThe governing structure of the EcoMobility Alliance is constituted by four bodies:\n\n1) Alliance Assembly;2) Steering Group;3) Secretariat;4) Working Groups.\n\nThe Alliance Assembly is the EcoMobility Alliance's supreme body and all Members are represented. Its role is: a) to establish and modify the terms of Reference; b) to approve the composition of the Steering Group; c) to approve the annual budget; d) to approve the annual Financial Report; e) to approve the five-year strategy proposed by the Steering Group; f) to approve progress reports submitted by the Working Groups.\n\nThe Alliance Assembly normally convenes once a year, but an extraordinary meeting is contemplated if requested by at least one quarter of the Full Members. Decisions within the Alliance Assembly are taken by absolute majority and each Full Member has a vote. Associate Members and Individual Members may only participate in the Assembly in an advisory role, without voting status.\n\nThe Steering Group is the EcoMobility Alliance's decision making body between the Alliance Assembly meetings. It is constituted by five to fifteen delegates of the Full Members, representing the various segments of EcoMobility and the action sectors in a balanced proportion. The Secretary General of the Alliance is a Member of the Steering Group ex officio, while the chairperson is elected amongst the Steering Group Members.\n\nIts role is: a) to decide on the Membership dues schedule; b) to appoint the Secretary General; c) to supervise the Secretary General; d) to endorse a five-year strategy and submit it to the Alliance Assembly for approval; e) to approve an annual workplan based on the Strategy; f) to monitor and review the implementation of the Workplan; g) to establish Working Groups after consultation of all Members; h) to review the annual Financial Report and submit it to the Alliance Assembly for approval; i) to review new membership applications to the Alliance and admit new members; j) to terminate memberships; k) to resolve conflicts arising between Members.\n\nThe Steering Group meets at least twice a year and decisions are taken by absolute majority. Each member has a vote, but in case of a tie the Chairperson can cast a second vote. Full Members that are not part of the Steering Group can still participate to its meetings as observers, but they are not entitled to vote.\n\nThe Secretariat is the operative body of the EcoMobility Alliance. It is operated through and legally represented by its host, ICLEI - Local Governments for Sustainability. The Secretariat office is in Bonn, Germany. The Secretariat is headed by the Secretary General, supported by an international staff.\n\nThe Secretary General is the Alliance's leading representative and executive agent. He is appointed by the Steering Group on a permanent basis. His role is: a) to represent the Alliance and be its primary spokesperson; b) to coordinate the Alliance's advocacy activities; c) to organise activities and events; d) to provide Members with information about the Alliance; e) to manage the Alliance's Secretariat; f) to administer the working groups; g) to coordinate product development consortia amongst the Members; h) to prepare the five-year strategy; i) to prepare the annual Workplan; j) to prepare the annual Activity Report; k) to prepare and manage the annual budget; l) to prepare the annual Financial Report; m) to ensure the implementation of the five-year Strategy and the annual Workplan; n) to organise and manage the Alliance Assembly's meetings.\n\nThe Working Groups are the Alliance's mechanism to undertake substantive work and implement the Strategy. Working Groups are established by the Steering Group for a certain period of time with a definite mandate and cease to exist once their objectives are achieved. The Steering Group defines also the purpose, goals and mandate of each Working Group, after consultation with all Members. All types of Members can take part in the Working Groups, after having notified the Secretary General of their participation.\n\nThe role of the Working Groups consists in: a) implementing one or several goals of the five-year Strategy, in line with the objectives of the annual Workplan; b) to implement additional projects mandated by the Steering Group or the Alliance Assembly.\n\n"}
{"id": "2145881", "url": "https://en.wikipedia.org/wiki?curid=2145881", "title": "Heptachlor", "text": "Heptachlor\n\nHeptachlor is an organochlorine compound that was used as an insecticide. Usually sold as a white or tan powder, heptachlor is one of the cyclodiene insecticides. In 1962, Rachel Carson's \"Silent Spring\" questioned the safety of heptachlor and other chlorinated insecticides. Due to its highly stable structure, heptachlor can persist in the environment for decades. The US EPA has limited the sale of heptachlor products to the specific application of fire ant control in underground transformers. The amount that can be present in different foods is regulated.\n\nAnalogous to the synthesis of other cyclodienes, heptachlor is produced via the Diels-Alder reaction of hexachlorocyclopentadiene and cyclopentadiene. The resulting adduct is chlorinated followed by treatment with hydrogen chloride in nitromethane in the presence of aluminum trichloride or with iodine monochloride.\n\nCompared to chlordane, it is about 3–5 times more active as an insecticide, but more inert chemically, being resistant to water and caustic alkalies.\n\nSoil microorganisms transform heptachlor by epoxidation, hydrolysis, and reduction. When the compound was incubated with a mixed culture of organisms, chlordene (hexachlorocyclopentadine, its precursor) formed, which was further metabolized to chlordene epoxide. Other metabolites include 1-hydroxychlordene, 1-hydroxy-2,3-epoxychlordene, and heptachlor epoxide. Soil microorganisms hydrolyze heptachlor to give ketochlordene. Rats metabolize heptachlor to the epoxide 1-exo-1-hydroxyheptachlor epoxide and 1,2-dihydrooxydihydrochlordene. When heptachlor epoxide was incubated with microsomal preparations form liver of pigs and from houseflies, the products found were diol and 1-hydroxy-2,3-epoxychlordene. Metabolic scheme in rats shows two pathways with the same metabolite. The first involves following scheme: heptachlor → heptachlor epoxide → dehydrogenated derivative of 1-exo-hydroxy-2,3-exo-epoxychlordene → 1,2-dihydrooxydihydrochlordene. The second involves: Heptachlor → 1-exo-hydroxychlordene → 1-exo-hydroxy, 2,3-exo-epoxychlordene → 1,2-dihydrooxydihydrochlordene.\n\nHeptachlor is persistent organic pollutant (POP). It has a half life of ~1.3-4.2 days (air),~0.03-0.11 years (water),~0.11-0.34 years (soil). One study described its half life to be 2 years and claimed that its residues could be found in soil 14 years after its initial application. Like other POPs, heptachlor is lipophilic and poorly soluble in water (0.056 mg/L at 25 °C), thus it tends to accumulate in the body fat of humans and animals. \n\nHeptachlor epoxide is more likely to be found in the environment than its parent compound. The epoxide also dissolves more easily in water than its parent compound and is more persistent. Heptachlor and its epoxide absorb to soil particles and evaporate.\n\nThe range of oral rat values are 40 mg/kg to 162 mg/kg. Daily oral doses of heptachlor at 50 and 100 mg/kg were found to be lethal to rats after 10 days. For heptachlor epoxide, the oral LD values ranging from 46.5 to 60 mg/kg. With rat oral of LD47mg/kg, heptachlor epoxide is more toxic. A product of hydrogenation of heptachlor, β-dihydroheptachlor, has high insecticidal activity and low mammalian toxicity, rat oral LD>5,000mg/kg.\n\nHumans are exposed to heptachlor through drinking water and foods, including breast milk. Heptachlor epoxide is derived from a pesticide that was banned in the U.S. in the 1980s. It is still found in soil and water supplies and can turn up in food and be passed along in breast milk. High levels of it seemed to increase type 2 diabetes risk to about 7 percent (Harmon 2010).\n\nThe International Agency for Research on Cancer and the EPA have classified the compound as a possible human carcinogen. Animals exposed to Heptachlor epoxide during gestation and infancy are found to have changes in nervous system and immune function. Higher doses of Heptachlor when exposed to newborn animals caused decrease in body weight and death.\n\nThe U.S. EPA MCL for drinking water is 0.0004 mg/L for Heptachlor and 0.0002 mg/L for Heptachlor epoxide. The U.S. FDA limit on food crops is 0.01 ppm, in milk 0.1 ppm, and on edible seafoods 0.3 ppm. The Occupational Safety and Health Administration has limit of 0.5 mg/m (cubic meter of workplace air) for 8-hour shifts and 40-hour work weeks.\n\nAn ATSDR report in 1993 found no studies with respect to death in humans after oral exposure to heptachlor or heptachlor epoxide.\n\nIts octanol water coefficient (K) is ~10. Henry's Law Constant is 2.3 · 10atm-m/mol and the vapour pressure is 3 · 10mmHg at 20 °C.\n\n"}
{"id": "37188939", "url": "https://en.wikipedia.org/wiki?curid=37188939", "title": "ITAD Subscriber Numbers", "text": "ITAD Subscriber Numbers\n\nITAD Subscriber Numbers, or ISNs, provide a way of interconnecting VOIP PBXs by adding a number to the internal phone number of the target phone. The ITAD number is added to the target phone number preceded by an asterisk. Therefore, only numbers and symbols which appear on a telephone keypad are used.\n"}
{"id": "1842942", "url": "https://en.wikipedia.org/wiki?curid=1842942", "title": "IT Service Management Forum", "text": "IT Service Management Forum\n\nThe IT Service Management Forum (\"it\"SMF) is an independent, international, not-for-profit organization of IT Service Management (ITSM) professionals worldwide. Around the operation of IT services the \"it\"SMF collects, develops and publishes “best practice”, supports education and training, discusses the development of ITSM tools, initiates advisory ideas about ITSM and held conventions. The \"it\"SMF is concerned with promoting ITIL (IT Infrastructure Library), Best Practice in IT Service Management and has a strong interest in the international ISO/IEC 20000 standard. The \"it\"SMF publishes books covering various aspects of Service Management through a process of endorsing them as part of the \"it\"SMF Library. \n\nThe \"it\"SMF UK takes at this time the international coordination. With a growing number of national chapters a real international umbrella was needed. The \"it\"SMF International was created in 2004.\n\nTypical activities in the national chapters were:\n\"it\"SMF chapters were partner of conferences of other organizations (e.g. Gartner “Business Intelligence & Information Management Summit 2013” in Australia ). There were own studies or together with other, well known research organizations (e.g. “Drive Service Management Adjustments With Peer Comparisons” from the \"it\"SMF USA together with Forrester Research, Inc.)\n\nThere were three books about “ITIL in the Public Sector” (“ITIL in der Öffentlichen Verwaltung”), “Organization Model for the IT in the Public Sector” (“Organizationsmodell für die IT in der Öffentlichen Verwaltung”)) and “Service Level Management in the Public Sector” (“Service Level Management in der Öffentlichen Verwaltung”)). \n\nAnnually in December the German chapter celebrates a two-day congress. Topics were provided in different formats with typical keynotes, four or five parallel user sessions, which presents three 20-minute-speeches in a row and a joint discussion, and some open world café discussions.\n\nDuring the year typical two one day meetings were held – name \"it\"SMF Live! - with different, actual topics. A special event for the Public Sector is the event \"FIT-ÖV\".\n\nThe chapter award since 2009 the ITSM project of the year. The first awarded project was “ITIL 2010” of the \" Federal Employment Agency\" (\"Bundesagentur für Arbeit\", Germany).\n\n"}
{"id": "38602523", "url": "https://en.wikipedia.org/wiki?curid=38602523", "title": "Industrialised building system (IBS)", "text": "Industrialised building system (IBS)\n\nIndustrialised building system (IBS) is a term used in Malaysia for a technique of construction where by components are manufactured in a controlled environment, either at site or off site, placed and assembled into construction works. Worldwide, IBS is also known as Pre-fabricated/Pre-fab Construction, Modern Method of Construction (MMC) and Off-site Construction. CIDB Malaysia, through IBS Centre is promoting the usage of IBS to increase productivity and quality at construction sites through various promotion programmes, training and incentives. The content of IBS (IBS Score) is determined based on the Construction Industry Standard 18 (CIS 18: 2010); either manually, web application or fully automated CAD-based IBS Score calculator.For example,using in Forest City project.\n"}
{"id": "817354", "url": "https://en.wikipedia.org/wiki?curid=817354", "title": "Innovation system", "text": "Innovation system\n\nThe concept of the innovation system stresses that the flow of technology and information among people, enterprises, and institutions is key to an innovative process. It contains the interactions between the actors needed in order to turn an idea into a process, product, or service on the market.\n\nSystems of Innovation are frameworks for understanding innovation which have become popular particularly among policy makers and innovation researchers first in Europe, but now anywhere in the world as in the 90's the World Bank and other UN affiliated institutions accepted. The concept of a 'system of innovation' was introduced by B.-Å. Lundvall in 1985 “however, as he and his colleagues would be the first to agree (and as Lundvall himself points out), the idea actually goes back at least to the Friedrich List´s conception of “The National System of Political Economy” (1841), which might just as well have been called “The National System of Innovation” (Freeman, 1995). Christopher Freeman coined the expression \"National Innovation System\" or in his 1988 study of the success of the Japanese economy.\nThe concept, similarly used as \"National System of Innovation\" or \"National Innovation System\" was later applied to regions and sectors. According to innovation system theory, innovation and technology development are results of a complex set of relationships among actors in the system, which includes enterprises, universities and research institutes.\n\nInnovation systems have been categorized into national innovation systems, regional innovation systems, local innovation systems, technological innovation systems and sectoral innovation systems.\n\nThere is no consensus on the exact definition of an innovation system, and the concept is still emerging. Innovation is often the result of the interaction among an ecology of actors, and the term 'innovation ecosystem' is occasionally used to emphasize this. For some, the expression 'innovation ecosystem' is a subset or synonym of 'innovation system'. Others separate between the expressions, using the expression \"innovation system\" for labeling a planned innovation environment, and \"innovation ecosystem\" for an ecological innovation environment.\n\nRecently, the debate also started to study the problems that affect green innovation since in addition to the issues typical of innovation generally (such as market failures related to limited appropriability of economic benefits of knowledge), green growth innovation is also hindered by market failures related to the environment (pollution externalities). It is possible (and not uncommon) for an innovation system to successfully support innovation in many technology areas, but not in ones related to green growth. For this reason, it is necessary to focus on addressing both kinds of failures in order to drive innovation towards a green growth trajectory.\n\nA national system of innovation has been defined as follows:\n\n\n\n"}
{"id": "37631204", "url": "https://en.wikipedia.org/wiki?curid=37631204", "title": "Interactive Museum EPM", "text": "Interactive Museum EPM\n\nThe Interactive Museum EPM is in Medellín, Colombia. It is part of the Barefoot Park and receives about a 1,000 visitors a day, mostly students. The museum provides an educational tour of 22 rooms spread over four buildings with technology explained in an entertaining way and guests interacting with the physical principles of water, energy, gas and telecommunications. It is funded and managed by Empresas Públicas de Medellín.\n\n"}
{"id": "874649", "url": "https://en.wikipedia.org/wiki?curid=874649", "title": "Liahona (Book of Mormon)", "text": "Liahona (Book of Mormon)\n\nAccording to the Book of Mormon and other Latter Day Saint movement sources, the Liahona () is a brass ball that operated as a type of compass with two spindles. One of the spindles was said to point the direction Lehi and his party should travel after their escape from Jerusalem, but it only worked when they were faithful. The Book of Mormon states that the Liahona also contained periodic written instructions from God. According to some sources, the Liahona was among the Book of Mormon artifacts Joseph Smith said were found with the golden plates.\n\nIn the Book of Mormon, the Liahona was found one morning at Lehi's tent door. It is described as a round brass ball of \"curious workmanship\" with \"two spindles,\" one of which indicated the direction that his party should travel (). It is sometimes referred to as a compass, although the context makes it clear that it did not function like a magnetic compass. On occasion there was also writing on the ball that displayed additional instructions from God (). Using the Liahona, Lehi and his party were directed through the wilderness and across the ocean to the Americas. The Liahona worked \"according to the faith and diligence\" () with which they heeded its direction, and ceased functioning at times when the members of the party demonstrated a loss of faith in God's commandments, notably when Nephi's brothers rebelled against Lehi during their ocean crossing ().\n\nThe only place in the Book of Mormon where the word \"Liahona\" is used is in the Book of Alma, when Alma, speaking to his son Helaman, explains \"our fathers called it Liahona, which is, being interpreted, a compass\" (). Alma tells his son that \"it is as easy to give heed to the word of Christ ... to eternal bliss, as it was for our fathers to give heed to this compass ... to the promised land\" ().\n\nAccording to the Book of Mormon, the word \"Liahona\" means \"a compass\" (). Latter-day Saint scholar Hugh Nibley also provided two additional possibilities for the meaning based on perceived Hebrew roots. He attributed the theory that it refers to a \"queen bee\" to a Hebrew University scholar named Shunary, and added his own speculation that \"Liyahhona\" might be translated \"To God is the guidance.\" \n\nJonathan Curci suggested that the word means \"the direction of the Lord\".\n"}
{"id": "57698112", "url": "https://en.wikipedia.org/wiki?curid=57698112", "title": "List of obsolete technology", "text": "List of obsolete technology\n\nThis is a list of obsolete technology which includes newer technologies that replaced the older ones. Many technologies that have newer alternatives have not been completely replaced.\n\nOlder technologies substantially co-existing with newer technologies include:\n\n"}
{"id": "15802153", "url": "https://en.wikipedia.org/wiki?curid=15802153", "title": "Luftwaffe radio equipment of World War II", "text": "Luftwaffe radio equipment of World War II\n\nDuring World War II, the German Luftwaffe relied on an increasingly diverse array of electronic communications, IFF and RDF equipment as avionics in its aircraft and also on the ground. Most of this equipment received the generic prefix FuG for Funkgerät, meaning \"radio equipment\". Most of the aircraft-mounted Radar equipment also used the FuG prefix. This article is a list and a description of the radio, IFF and RDF equipment.\n\nFuG I: An early receiver/transmitter set manufactured by Lorenz. It operated in the 600 to 1667 kHz range (generally the entire American AM radio broadcast band) at a power of 20 to 100 watts, depending on installation.\n\nFuG II: An update of the FuG 1, also manufactured by Lorenz, that operated in the 310 to 600 kHz frequency range, the lower end of the MF band.\n\nFuG 03: Codenamed Stuttgart, was an airborne receiver/transmitter set used in bombers. Was fitted in: Do 11, Do 17 E and F, Fw 58, He 114, Ju 52, Ar 66, Ar 96, Junkers W 33 and W 34. Set consists of: S 3a Transmitter; E 2a Receiver. Power source: G 3 Air-driven generator and 2 - 90 volt dry cells. The FuG 03 operated in the 1250 to 1400 kHz frequency range.\n\nFuG 7: A compact airborne receiver/transmitter used in fighters and dive bombers. Prior to 1943, it was fitted in the Bf 109C to G-2, and Fw 190 A-0 to A-3. After 1943, it was still fitted in the Ju 87 and Hs 129. The FuG 7 typically operated in the 2.5 to 7.5 MHz, with a power of approximately 7 watts. The range of the FuG 7 was approximately 50 km in good weather. Later versions of the FuG 7 included the FuG 7a, which included the S 6a Transmitter, E 5a Receiver and Junction Box VK 5 A.\nFuG 10 series: A family of transceivers for both R/T and W/T communications. The German FuG 10 panel, or rack, contained two transmitters and two receivers: One transmitter and its companion receiver operated in the MF or Longwave; 300 to 600 kHz (1,000 to 500 m) range and the other transmitter and its companion receiver operated in the HF or Shortwave range; 3 to 6 MHz (100 to 50 m). Most of the FuG 10 series used a fixed wire aerial between the fuselage and tailfin or a retractable trailing aerial wire. The FuG 10P replaced the standard E 10L longwave receiver with an EZ6 unit for a G6 direction finding set. The FuG 10ZY incorporated a fixed loop D/F aerial and a homing device for navigation to a ground station. This loop aerial, usually fitted on a small, \"teardrop\" shaped mounting, was standard equipment on most fighter aircraft from late 1943 on. Manufactured by Lorenz. Typical power was 70 watts.\n\nFuG 11: Developed as a replacement for the Fug 10 series. No MF mode, and of up to 3 kW output. Increased HF-only transceiving range to 3 - 30 MHz (the \"entire\" HF band). CW & AM voice. Reduced volume, cost & weight. Intended to be combined with the PeilG 6 & FuBL 2. It could be fitted with a remote control system that allowed the pilot to control it rather than the radio operator. Development completed but never deployed as there was little demand for long range bomber communications in 1944.\n\nFuG 13: Designed to supplement early versions of the Fug 10 to improve long range communications. Frequency range 3 MHz to 20 MHz 20 Watts output power. Deployed on long range aircraft such as the Fw 200 Condor. Improvements in the Fug 10 family resulted in no need for this additional radio and it was withdrawn from service.\n\nFuG 15 : Intended as the next standard aircraft transceiver to replace earlier series units. Unusual in using FM as well as AM for voice. Operating Frequency 37.8 to 47.7 MHz. It could be fitted with a remote control system that allowed the pilot to control it rather than the radio operator. Production planned to start in 1942 but service trails showed problems and deployment stopped. Replaced by the Fug16. Completed units rebuilt at BS 15 navigation radio beacons in 1945.\nFuG 16 Z, ZE and ZY: These sets were airborne VHF transceivers used in single-seat fighter aircraft for R/T and W/T communications, and were also used for ground fixes and DF homing on ground stations when used in conjunction with the FuG 10P or FuG 10ZY. Installed for Bf 109G-3/G-4 and later, Fw 190A-4 and later subtypes. Frequency Range was 38.5 to 42.3 MHz. The FuG 16ZY was also used for \"Y-Verfahren\" (\"Y-Control\"), in which aircraft were fitted up as \"Leitjäger\" or Fighter Formation Leaders that could be tracked and directed from the ground via special R/T equipment. Aircraft equipped with ZY were fitted with a Morane whip aerial array. Principal components:\nTransmitter, Receiver, Modulator in one case, S 16 Z Tx, E 16 Z Rcvr,\nNG 16 Z Modulator\nDynamotor U 17\nAntenna Matching unit AAG 16 Z\nModulator Unit MZ 16\nHoming Unit ZVG 16\nIndicator AFN - 2\n\nFuG 17 Z and ZY: These sets were airborne VHF transceivers used in Close Air Support aircraft for R/T and W/T communications with ground units. Frequency Range was 42 to 48.3 MHz. This matched the ground forces Fug 7 radio fitted to command tanks and reconnaissance units. The FuG 17 was identical to the Fug 16 with the exception of the frequency range and seems to have been deployed first. In the Fug 17ZY version it was also used for \"Y-Verfahren\" (\"Y-Control\"), though it seems to have superseded it this role by the FuG 16ZY when it became available.\n\nFuG 18: Developed in 1944 as an improvement to the Fug 15. Frequency range 24 - 75 MHz. FM & AM voice. FuG18Y included the ability for Y-control, blind landing and Hermione beacon receive.\n\nFuG 24: This set was developed from the Fug 16 as a simplified and cost reduced system. Intended for the Heinkel He 162 and later aircraft. Did not have a direction finder capability or a Y control interface. Frequency Range was 42 to 48.3 MHz, FM & AM voice only. FuG 24Z included Y-Control and blind landing and \"Hermine\" beacon-receiving capability.\n\nFuG 29: Development unit designed to replace the FuG16, FuG17 and later the FuG24 families of units. Presumably then AM and FM, with a frequency range of between 38 and 48 MHz but details lacking and development was never completed.\n\nPeilgerät (PeilG) 6: Codenamed \"Alex Sniatkowski\", this was a long and medium range D/F set and homing device used mainly on bombers: Ar 234, Do 217, Ju 87, Ju 88A-4 on, Ju 188, Ju 290, Ju 388; the He 177A heavy bombers (Germany's only \"heavy bomber\" design in service), and both the He 219A and Ju 88G night fighter series are some of the aircraft types to be fitted. Frequency range was 150 to 1,200 kHz. A \"flat\" equivalent of a D/F loop was used for the \"Peilgerät\" device to reduce drag over a protruding D/F loop antenna, and made up of a series of metal strips in a \"sunburst\" pattern. often being fitted under a round, flush fitting plexiglass cover. A small \"whip\" aerial was also fitted to the FuG 10 radiomast. Manufactured by Telefunken. Version PeilG 5 was of similar performance but used a manually controlled loop antenna. Control was via an electric servo motor. Versions 1 - 4 had manual control either via cable linkage or direct control via an attached handle.\n\nFuBL 2 Used the Knickebein beam navigation and bombing system. Consisted of the EBL 3 and EBL 2 receivers with display device ANF 2. The EBL 3 operated between 30 and 33 MHz and received 34 channels, The EBL 2 operated at 38 MHz and was unchanged from the FuBL 1 system. The AFN 2 provided the pilot with a left/right display and a signal strength. The unit was available in two versions FuBL 2 H for a unit operated by the radio operator and the FuBL 2 F for remote operation by the pilot in a single seat aircraft.`The primary difference between the EBL 1 and the EBL 3 was sensitivity to allow, what was basically a ILS system, to be used for bombing.\n\nFuG 28a: Y-Gerät transponder. Based on the Fug17 transceiver with additional components to send the response to the Y-Gerät ground station for the ground station to derive range. Also derived the azimuth signal and displayed the results on the ANF 2 display giving the pilot a left/right command. Operating frequency 24 - 28 MHz. 8 Watts transmit power. The unit also interfaced to the FuG 10 system in the aircraft so that voice communication with the pilot from the ground controllers via the Fug 28a was possible.\n\nHermine: This system was a VHF radio beacon. Originally developed in 1942 due to problems the design was suspended. When in 1944 the existing radio navigation systems were either being jammed or under physical attach the design was revisited. It consisted of a rotating radio beacon transmitting at 30 -33 MHz. The signal consisted of a tone and a robot voice using FM. The robot voice was encoded onto an optical disk. The voice spoke a number between 1 and 35, corresponding to 10 degrees of angle from the beacon. The pilot listened to the signal, when the tone disappeared the next number corresponded to the angle from the beacon. It was expected that this would give an angular resolution of about 5 degrees but when tested it was found that some pilots could estimate to within 3 degrees. The receiver was a modified EBL 3 which had had its bandwidth increased and fitted with a FM interface board. This board also connected to the pilots audio via the Fug16 to send the audio information to the pilot. In single-seater aircraft the radio fit was numbered FuG 125. The beacon identifier was transmitted instead of the number 0. This allowed a pilot to select a particular beacon. Between 10 -20 beacons were commissioned by May 1945. 30 channels were available with 2 more being reserved for airfield ILS. Beacons were usually placed 20 km from a runway, The pilot would over fly the beacon and then circle until he acquired the ILS landing beam on the FuBL 2 equipment. Ground units were BS 15 navigation radio beacons constructed from rebuilt FuG 15 sets.\n\nFug 126: By 1944 the Germans were aware of the operating concept of the British Rebecca/Eureka system and the Oboe and G-H systems via captured examples. From this they developed the Baldur system. This was a system or responder beacons working at 2-4 Meters wavelength. The airborne equipment FuG 126 was based on the SN2 radar. Accuracy was +- 100 meters. The system seems to have only deployed in small numbers as bomber operations were ceasing due to the air forces concentration just on fighters and CAS. A variant called FuG162k was produced for single seat fighter (reduced accuracy +- 500 meters) operation but it seems never to have been used.\n\nTwo variants of the system were also designed Baldur-Truhe, combined system and Baldur- Bernhardine again a combination. Neither of these systems seem to have achieved flight trials.\n\nThe Luftwaffe operationally deployed 3 beam navigation systems during the first part of the war. Knickebein, X-Gerät and Y-Gerät.\nFor more information see the main page Battle of the Beams\n\nKnickebein: Development started on this system in 1934 based on work done by Lorenz. The initial work was too develop their ILS system but further work investigated how far a beam of this frequency could be used to guide an aircraft. It was found that by using a combination of a large antenna, a powerful transmitter and maximum elevation of the antenna that ranger far in excess of those expected could be achieved. (probably being caused by ducting, a little understood propagation mode at the time). With an antenna at 1000m above sea level and an aircraft flying at 3000m ranges of 400 km could be achieved. Aircraft equipment was the EBL3 receiver. Frequency range 30 - 34 MHz.\n\nX-Gerät: The Knickebein system was even for its time very crude. As soon as it had proved itself development of an improved system called X-Gerät was started. This used higher frequencies 66-70 MHz to improve resolution and reduce the size of the antenna group. This allowed the system to be mobile (by standards of 1940s not today's standards for mobile). Additionally it used 4 beams rather than two, included was a system called the X-clock. This allowed much better accuracy, crews often achieved 300 x 300 meter target boxes.\n\nY-Gerät: This system was developed to allow one beam rather than the 2 or 4 of the other systems. The airborne component was the FuG 28, which was an FuG 17E with additional transponder systems. Essentially the system transmitted on one beam that indicated left/right on a pilot display and a range indication by using the FuG 28 transponder. System transmitted at the FuG 17 range of 42.1 to 47.7 MHz.\n\nY-Control for fighters: Developed from mid 1943 to guide fighters to intercept bomber streams. Radio equipment was a modified FuG 16 equipment.\n\nFuG 124 Komet: In 1942 with the He 177 and the \"Battle of the Atlantic\" in full swing the Germans started the development of a long range beacon system called Komet. This was based on pre-war work done by Lorenz. Its consisted or a rapidly rotating beam (electronic not mechanical) transmitting at 3Kw and at frequencies between 5 and 12 MHz. The signals were picked up using a FuG10K receiver and processed by the FuG 124 Komet processor which printed the results out on a paper strip.(The Kometscriber). Two test stations were built in 1944.<ref name=\"ADIK 364/1944\">ADIK 364/1944</ref> There were several problems which resulted in it never being used. The antenna array was vast using 127 aerials and 19 control huts. It was discovered that it would be easy to jam and as it was now 1944 with German forces falling back on all fronts there was no longer a requirement for it. The few Fug124 receivers built were only used on the ground for R&D work.<ref name=\"ADIK 357/1944\">ADIK 357/1944</ref>\n\nFuG 121 Erika : First deployed in 1942 it was used briefly before being replaced by Sonne and Bernard. Erika transmitted a VHF signal on 30-33 MHz which could be received by standard EBL 3 receivers. The signal was adjusted in phase between a ref point and a navigation point. After processing the FuG 121 displayed an angle from the beacon. Be using two beacons it was possible to achieve a fix. However this was a problem as four receivers were required, two listening to each station. On smaller aircraft there was not enough space and German industry was by now having trouble supplying enough radios to the air force without adding 4 more receivers per plane. The system was not deployed. Some sources indicate that there may have been a version called Electra that operated at 250 to 300 kHz but details are lacking or contradictory.\n\nSonne: This system transmitted on 270–480 kHz and could be received on a FuG 10. No special receiver was required as the pattern was discernable with the ear all that was required was the special charts. At least 6 stations were built providing coverage from the Bay of Biscay to Norway. Accuracy was reasonable during the day but errors up to 4 degrees occurred at night. The allies captured the maps with resulted in the being issued to allied units, because of this the allies left the Sonne system alone. After the war the stations were rebuilt and operated into the 1970s. The system was called Consol by that time.\n\nMond: Development work was done on \"Sonne\" (sun) to remove the night time errors, this system was called \"Mond\" (moon). Work was never completed.\n\nTruhe: This system was based on the British GEE system. After British units were captured the Germans set up a project to 'clone' the units. The first unit was the FuG 122 which allowed the reception of British GEE signals. Units in France received these units and were able to navigate using British signals. The Germans then developed the concept to produce FuG 123 receivers which would allow a wider turning range. This allowed the Germans to setup GEE chains of their own further inside Germany where the British GEE signals were unusable. There seems to have been some idea of using frequencies very close to the British frequencies to make jamming by the Allies hard to do without jamming their own GEE system. One chain became operational around Berlin.\n\nFuBL 1 Used the Lorenz landing beam system. Consisted of the EBL 1 and EBL 2 receivers with display device ANF 2. The EBL 1 operated between 30 and 33 MHz and received the azimuth signals from a transmitter at the far end of the runway, The EBL 2 operated at 38 MHz and received the two marker beacons as the aircraft approached the threshold to land. The AFN 2 provided the pilot with a left/right display and a signal strength. The pilot could also hear the azimuth signal and the marker beacons in his headset. When the aircraft passed over the beacons a light was also illuminated in the cockpit.` \n\nFuG 125 Hermine: Was a system designed for night fighters and single pilot aircraft in night/poor visibility conditions. It consisted of several sub systems. For navigation it used the \"Hermine\" VHF radio beacon signal system via the Fug 16ZY. For approach and landing it used the FuBL 1 or 2 blind landing receiver. For altitude it used the Fug 101 radio altimeter. Given the pilot workload in a single pilot aircraft it also included a simple auto pilot. Fitted in some types of Fw 190 and Bf 109s. Manufactured in small numbers by Lorenz in 1945.\n\nFuG 101: FM (Frequency Modulated) CW (Continuous Wave) Altimeter. Operating frequency 337 - 400 MHz. (75 – 89 cm) Selectable between two ranges, 0 - 150 Meters and 0 - 750 Meters. Units were small enough to be fitted to single-engine day fighters and night fighters. Fitted generally at first but later in the war only to aircraft expected to operate at night. In larger aircraft usually paired with Fug 102 due to its max height limitation.\n\nFuG 103: Pulse Modulated Altimeter. Improved version of Fug 102 with reduced min height limitation, therefore Fug 101 could be dispensed with. Small numbers produced in 1945.\n\nFuG 104: Improved Fug 103 by reducing its size. Development never completed.\n\nFuG 25z Zwilling : This was an early IFF set designed to respond to the \"Würzburg\". The reception frequency range was 600 MHz 50 cm. Transmitting frequency was also 600 MHz, 50 cm. When it responded the radar operator could hear a morse character in their headphones. This only worked with the Würzburg radars not Freya. It could be received at up to .\n\nFuG 25z Häuptling As experience was gained it was discovered that using the system above the radar operators were unable to identify which aircraft had responded to the interrogation pulse as the basic system did not provide range. In an attempt to resolve this question a modification was applied turning the Zwilling into the Häuptling.This retransmitted the receiving pulse on the 160 MHz frequency to a receiver on the radar. However, by the time that this modification had been developed jamming of the Würzburg had commenced and the radar had been modified to work on one of three bands called \"islands\". As the Häuptling could not cover these bands it was abandoned and the FuG 25z was replaced by the various versions of the FuG 25a system.\n\nOriginally IFF was only considered to be of use with Flak hence the limitation above. As the war progressed it was realised that IFF should also work with early warning radars hence a new version of the FuG 25 was developed.\n\nFuG 25a Erstling: This was an IFF set designed to respond to \"Freya\", \"Würzburg\" and the advanced, limited-deployment FuG 404 \"Jagdschloss\" system. The reception frequency range was 125 + or - 1.8 MHz. Transmitting frequency was 160 MHz. It could be received at up to .\n\nWürzburg radars as they worked on a different band required separate equipment to work with the FuG 25a. This was known under the name Kuckuck. It consisted of the interrogator transmitter Kur and the receiver Gemse. Dipoles were mounted inside the reflector to transmit and receive. A severe problem was encountered with the width of the resulting beam.\n\nFuG 25a Erstling-Grün: In anticipation of the allies jamming of the 125/160 MHz IFF frequency this modification changed the interrogation wavelength to 2.5 meters and the response to 2 meters. No other changes were made. Never deployed.\n\nFuG 225 Wobbelbiene This was a development of the FuG 25z to provide a wide band receiver which would respond to the Würzburg \"Island A\" & \"Island B\" frequencies. It was hoped by doing this that the beam width problems with Fug25a would be resolved. However, by the time this was ready for production in 1944 Flak Würzburg now included \"Island C' which could not be received. The unit was therefore never deployed. Further development of the basic Fug 25 was then abandoned.\n\nFuG 226 Neuling: Intended to incorporate all the lessons using the preceding systems. The objectives of the design were ; (a) Work with all anticipated service radars i.e. \"staring and PPI' (b) operate at 6, later 12 frequency pairs to defeat jamming (c) for the first time provide an air-to-air mode. Development never completed.\n\nFuG 228 Lichtenstein SN-3: The last-developed version of the \"Lichtenstein\" airborne intercept radar developed to allow night fighters fitted with it to identify one another. Transmitted and received on the same band (100 - 156 MHz). It may have been intended to use it as some sort of squadron control system. Never deployed.\n\nFuG 229 Frischling: With the deployment starting on 9 cm band radars such as the \"Jagdschloss Z\", a need for IFF was identified. The Frischling was an add on unit for either FuG 25a or FuG 226 that converted the 9 cm integration pulse to a standard 125 MHz pulse which was then passed it to the response unit. Development not completed.\n\nFuG 243 : By 1944 the Germans were aware of the operating concept of the British Rebecca/Eureka system via captured examples. From this a series of radar beacons were designed to respond to different frequencies and waveforms. The FuG243 seems to be the only one that entered service in small numbers in early 1945 in Norway with coastal units. It operated on the low-UHF band frequencies used by the FuG 200 Hohentwiel ASV airborne radar hardware. In modern terms it was a type of Radar beacon (racon)\n\nAs allied jamming of the fighter voice links became increasingly effective by 1944/45 attempts were made to find other ways of passing information and commands to fighter pilots.\n\nNachtlicht: The receiver for this was the FuG25a IFF system. When a ground station interrogated the unit it flashed a small light to indicate this had happened to the pilot. The system involved modifying the transmitter so that the light flashed Morse signals. This allowed a very primitive way of signaling the pilot. A development of this system was to include a unit called the Luftkurier which decoded the Morse and indicated commands on a pointer (left/right). The system was trialed but it was found to be too hard for pilots to watch the indicator while piloting their aircraft. Another issue was that the Luftkurier was found to be very easy to jam.\n\nFug 136 Nachtfee: A development of the Nachlicht system. Used the Fug25a receiver again. This time commands were decoded onto a small CRT, which allowed up to 16 commands to be issued to the fighter. Had the same problems as Nachlicht, too easy to jam and too hard to use in a single-seater plane. Abandoned.\n\nFug 138 Barbara: A further development of the Nachlicht system. This time an audio receiver was added to the system between the Fug25a and the Fug16ZY. This allowed the pilot to hear Morse commands sent up the data link. Unusable in practice and abandoned.\n\nAs German pilot training was cut back due to the war situation it was realised that the above systems would be unusable as pilots were no longer being trained in Morse. This led to the Fug 120 and Fug 139 systems.\n\nFuG 139 Barbarossa: This system again used the Fug25a receiver but fed it to a Hellschreiber printer. This removed the requirement to read Morse or continuously watch a display. Deployed in small numbers in 1945. An attempt was being made to use Pulse Modulation to also transmit voice but this was never completed.\n\nNS 2 : Single watertight box transmitter. Operated on the international distress frequency of 500 kHz. Powered by a hand generator. Sent Morse code, no receiver. Fitted to most German aircraft expected to operate over water at the start of the way. Range 120 – 250 miles. Transmit power 8 Watts.\n\nNS 4 : Single watertight box transmitter. Operated on a frequency of 53.5 to 61 MHz. Powered by a batteries. Sent Morse code, no receiver. Fitted to most German aircraft expected to operate over water from the middle of the war. Replaced NS2. Range 6 to 16 Miles. Easier to use than the NS2. Transmit power 1 to 2 watts.\n\nFuG 141: Receiver for signals from the NS4 emergency transmitter. Fitted to air-sea rescue units. Operated with a direction finding loop.\n\nFuG 142: Receiver to receive MW beacons. Battery powered to be used when other power had failed on an aircraft. Not deployed after service tests had revealed problems.\nDue to be replaced by the FuG 145\n\nFug 145: Replacement for the PeiGL 6 MF receiver. Development not completed.\n\nFug 301 & FuG 310 : Radio sonde, operated suspended from a barrage balloon. Transmit frequency 13.4 MHz.\n\nFuG 302: Radio Buoy. Dropped into the sea to mark a particular location for following aircraft. Initially transmitted at 45 MHz for detection by Fug 17, later modified to operate at 40 MHz for location by FuG 16. Used in late 1944 to guide He 111 launching V-1 over the North Sea.\n\nFuG 303: Overland version of FuG 302.\n\nFuG 304: Distress Radio Buoy.\n\nFuG 305: Jammer - details lacking\n\nFuG 308: Radio Sonde\n\nNumerous different Radio Sonde systems were deployed by both the Army, Air Force and Navy.\n\nAn example of a ground station would be the FuG 502 Mouse . This used a transponder system working at 300 MHZ to track the radio sonde and received values from it on 27 MHz. It was mounted in a trailer.\n\nFuG 23: Location transmitter installed in some Fieseler Fi 103 (V 1) cruise missiles. Transmitted at frequencies between 340 kHz and 3.5 MHz.\nAllowed the missiles to be tracked. Transmitted two signals, one while the motor was running and the second when it cut off, allowing its impact point to be calculated.\n\nFuG 230: Radio tracking beacon for various German missiles such as 'Waterfall', 'Enzian' and 'HS 117'. Operated at 600 MHz.\n\nThe Luftwaffe was known to have fitted small aluminum strips which frequently carried explosive self-destruct charges onto the outside of the equipment's aluminum housings. These explosives were linked then by a delay fuse attached onto any sensitive apparatus, which allowed it to be destroyed rather than be captured by the Allies.\n\n\n"}
{"id": "18506699", "url": "https://en.wikipedia.org/wiki?curid=18506699", "title": "Lynn Gladden", "text": "Lynn Gladden\n\nLynn Faith Gladden, (born 30 July 1961) is the Shell Professor of Chemical Engineering at the University of Cambridge. She served as Pro-vice-chancellor for research from 2010 to 2016.\n\nGladden was born on 30 July 1961. Her father is John Montague Gladden and her mother, Sheila Faith Deverell. Gladden was educated at the Heathfield School in Harrow. She obtained a Bachelor of Science degree in Chemical Physics at the University of Bristol in 1982 and a PhD in Physical Chemistry at Cambridge in 1987. She also holds a Postgraduate Certificate in Education (PGCE) in Physics from the University of Oxford.\n\nGladden began her career as a lecturer at the University of Cambridge from 1987 to 1991. She was appointed a Reader from 1995 to 1999, when she was promoted to professor. She was head of the Department of Chemical Engineering and Biotechnology, University of Cambridge until 1 October 2010. She was also a Pro-vice-chancellor from 1 January 2010 up until 1 January 2016. and has been a Fellow of Trinity College, Cambridge since 1999.\n\nGladden is the lead researcher at the university's magnetic resonance research centre (MRRC). She is also a member of the judging panel for the Queen Elizabeth Prize for Engineering. Gladden was appointed as a non-executive director of British Land in March 2015.\n\nShe is a Chartered Chemist and Chartered Engineer, a Fellow of the Institution of Chemical Engineers and a Fellow of the Institute of Physics (FInstP) and a Fellow of the Royal Society of Chemistry (FRSC).\n"}
{"id": "4253041", "url": "https://en.wikipedia.org/wiki?curid=4253041", "title": "MIL-STD-810", "text": "MIL-STD-810\n\nMIL-STD-810, \"Environmental Engineering Considerations and Laboratory Tests\", is a United States Military Standard that emphasizes tailoring an equipment's environmental design and test limits to the conditions that it will experience throughout its service life, and establishing chamber test methods that replicate the effects of environments on the equipment rather than imitating the environments themselves. Although prepared specifically for military applications, the standard is often used for commercial products as well. \n\nThe standard's guidance and test methods are intended to:\n\nThe document revision as of 2012 is MIL-STD-810G which was issued on October 31, 2008. It superseded MIL-STD-810F released on January 1, 2000 which was last updated on May 5, 2003.\n\nMIL-STD-810 is maintained by a Tri-Service partnership that includes the United States Air Force, Army, and Navy. The U.S. Army Test and Evaluation Command, or ATEC, serves as Lead Standardization Activity / Preparing Activity, and is chartered under the Defense Standardization Program (DSP) with maintaining the functional expertise and serving as the DoD-wide technical focal point for the standard. The Institute of Environmental Sciences and Technology is the Administrator for WG-DTE043: MIL-STD-810G, the Working Group that updates this constantly evolving standard. \n\nMIL-STD-810 addresses a broad range of environmental conditions that include: low pressure for altitude testing; exposure to high and low temperatures plus temperature shock (both operating and in storage); rain (including wind blown and freezing rain); humidity, fungus, salt fog for rust testing; sand and dust exposure; explosive atmosphere; leakage; acceleration; shock and transport shock; gunfire vibration; and random vibration. The standard describes environmental management and engineering processes that can be of enormous value to generate confidence in the environmental worthiness and overall durability of a system design. The standard contains military acquisition program planning and engineering direction to consider the influences that environmental stresses have on equipment throughout all phases of its service life. The document does not impose design or test specifications. Rather, it describes the environmental tailoring process that results in realistic materiel designs and test methods based on materiel system performance requirements.\n\nFinally, there are limitations inherent in laboratory testing that make it imperative to use proper engineering judgment to extrapolate laboratory results to results that may be obtained under actual service conditions. In many cases, real-world environmental stresses (singularly or in combination) cannot be duplicated in test laboratories. Therefore, users should not assume that an item that passes laboratory testing also will pass field/fleet verification tests.\n\nIn 1945, the Army Air Force (AAF) released the first specification providing a formal methodology for testing equipment under simulated environmental conditions. That document, entitled \"AAF Specification 41065, Equipment - General Specification for Environmental Test of\", is the direct ancestor of MIL-STD-810. In 1965, the USAF released a technical report with data and information on the origination and development of natural and induced environmental tests intended for aerospace and ground equipment. By using that document, the design engineer obtained a clearer understanding of the interpretation, application, and relationship of environmental testing to military equipment and materiel.\n\nThe Institute of Environmental Sciences and Technology (IEST), a non-profit technical society, released the publication \"History and Rationale of MIL-STD-810\" to capture the thought process behind the evolution of MIL-STD-810. It also provides a development history of test methods, rationale for many procedural changes, tailoring guidance for many test procedures, and insight into the future direction of the standard.\n\nThe MIL-STD-810 test series originally addressed generic laboratory environmental testing. The first edition of MIL-STD-810 in 1962 included only a single sentence allowing users to modify tests to reflect environmental conditions. Subsequent editions contained essentially the same phrase, but did not elaborate on the subject until MIL-STD-810D was issued marking one of the more significant revisions of the standard with its focus more on shock and vibration tests that closely mirrored real-world operating environments. MIL-STD-810F further defined test methods while continuing the concept of creating test chambers that simulate conditions likely to be encountered during a product's useful life rather than simply replicating the actual environments. More recently, MIL-STD-810G implements Test Method 527 calling for the use of multiple vibration exciters to perform multi-axis shaking that simultaneously excites all test article resonances and simulates real-world vibrations. This approach replaces the legacy approach of three distinct tests, that is, shaking a load first in its \"x\" axis, then its \"y\" axis, and finally in its \"z\" axis.\n\nA matrix of the tests and methods of MIL-STD-810 through Revision G is available on the web and quite useful in comparing the changes among the various revisions .\n\nThe following table traces the specification's evolution in terms of environmental tailoring to meet a specific user's needs.\n\nPart One of MIL-STD-810G describes management, engineering, and technical roles in the environmental design and test tailoring process. It focuses on the process of tailoring design and test criteria to the specific environmental conditions an equipment item is likely to encounter during its service life. New appendices support the succinctly presented text of Part One. It describes the tailoring process (i.e., systematically considering detrimental effects that various environmental factors may have on a specific equipment throughout its service life) and applies this process throughout the equipment's life cycle to meet user and interoperability needs.\n\nPart Two of MIL-STD-810G contains the environmental laboratory test methods to be applied using the test tailoring guidelines described in Part One of the document. With the exception of Test Method 528, these methods are not mandatory, but rather the appropriate method is selected and tailored to generate the most relevant test data possible. Each test method in Part Two contains some environmental data and references, and it identifies particular tailoring opportunities. Each test method supports the test engineer by describing preferred laboratory test facilities and methodologies. These environmental management and engineering processes can be of enormous value to generate confidence in the environmental worthiness and overall durability of equipment and materiel. Still, the user must recognize that there are limitations inherent in laboratory testing that make it imperative to use engineering judgment when extrapolating from laboratory results to results that may be obtained under actual service conditions. In many cases, real-world environmental stresses (singularly or in combination) cannot be duplicated practically or reliably in test laboratories. Therefore, users should not assume that a system or component that passes laboratory tests of this standard also would pass field/fleet verification trials.\n\nSpecific examples of Test Methods called out in MIL-STD-810G are listed below:\n\nPart Three contains a compendium of climatic data and guidance assembled from several sources, including \"AR 70-38, Research, Development, Test and Evaluation of Materiel for Extreme Climatic Conditions (1979)\", a draft version of \"AR 70-38 (1990)\" that was developed using Air Land Battlefield Environment (ALBE) report information, \"Environmental Factors and Standards for Atmospheric Obscurants, Climate, and Terrain (1987)\", and MIL-HDBK-310, \"Global Climatic Data for Developing Military Products\". It also provides planning guidance for realistic consideration (i.e., starting points) of climatic conditions in various regions throughout the world.\n\nMIL-STD-810 is a flexible standard that allows users to tailor test methods to fit the application. As a result, a vendor's claims of \"...compliance to MIL-STD-810...\" can be misleading. Because no commercial organization or agency certifies compliance, commercial vendors can create the test methods or approaches to fit their product. Suppliers can—and some do—take significant latitude with how they test their products, and how they report the test results. When queried, many manufacturers will admit no testing has actually been done and that the product is only designed/engineered/built-to comply with the standard. This is because many of the tests described can be expensive to perform and usually require special facilities. Consumers who require rugged products should verify which test methods that compliance is claimed against and which parameter limits were selected for testing. Also, if some testing was actually done they would have to specify: (i) against which test methods of the standard the compliance is claimed; (ii) to which parameter limits the items were actually tested; and (iii) whether the testing was done internally or externally by an independent testing facility.\n\n\n"}
{"id": "3614954", "url": "https://en.wikipedia.org/wiki?curid=3614954", "title": "Microducts", "text": "Microducts\n\nMicroducts are small ducts for the installation of small microduct fibre optic cables. They have a size ranging from typically 3 to 16 mm and are installed as bundles in larger ducts.\n\nMicroducts are typically small-diameter, flexible, or semi-flexible ducts designed to provide clean, continuous, low-friction paths for placing optical cables that have relatively low pulling tension limits. As stated in industry requirements document Telcordia GR-3155, \"Generic Requirements for Microducts for Fiber Optic Cables,\" microduct products are expected to:\n\nGR-3155 states that the basic types of duct are smoothwall, corrugated, and ribbed. The selection of a particular duct design is dependent on those characteristics that are important to the end-user. The need for a specific characteristic or combination of characteristics such as pulling strength, flexibility, or the lowest coefficient of friction will dictate the type of duct required.\n\nDucts can be purchased with a variety of options or features. One such enhancement is pre-lubrication. Pre-lubricated ducts may be either permanently impregnated with anti-friction compounds or coated with liquid lubricant during manufacture (see GR-3155). This may or may not eliminate the need for supplementary lubrication when pulling cable into the duct. Before using a supplementary lubricant with a pre-lubricated duct, the user should check with the manufacturer to determine if the added lubricant is compatible with the pre-lubricated surface of the duct. Failure to do this may result in the cable seizing up rather than reducing the friction coefficient of the duct.\n\nAs indicated in GR-3155, cable is typically placed into the duct in one of three ways:\n\nWhen cable is pre-installed, the duct manufacturer extrudes the duct directly over the optical cable. Tight control of the duct temperature during the manufacturing process is essential to ensure that the duct does not stick to the cable as it cools. At the completion of the process, all of the fibers in the optical cable must be tested to ensure that no damage has occurred.\n\nA common cable installation technique for fiber cables remains cable pulling. After the duct is placed, a high-strength pull line is blown into the duct (if one has not already been pre-installed by the duct manufacturer). The pull line is attached to one end of the cable and is used to pull the cable through the duct.\n\nTraditional cable pulling methods are very sensitive to the condition of the duct and to the number of bends and undulations throughout the duct route. Therefore, for microducts, Air-Blown (AB) cable installation techniques are expected to be the most useful. AB cable installation requires the use of a device that injects a high volume of air into the duct, at pressures as high as 20-25 psi. The viscous drag forces generated by the rushing air along the length of the cable act to reduce or overcome the friction between the cable and the duct.\n\nFor telecommunications, cables can be installed in water, in air or underground. In the latter case, the cables might be direct buried or installed in ducts. The first is more common for copper balanced cables; the latter for fibre optic cables. The ducts in which the fibre optic cables are installed are usually made of polyethylene. They have a size ranging from typically 25 mm to 100 mm. Sometimes they are installed as subducts in larger ducts. These larger ducts can also consist of other materials, like concrete. The installation of fibre optic cables in ducts can be done by pulling or by cable jetting.\n\nIt is more difficult to make branching fibre optic networks in the access network than it is for copper balanced cables. Splicing optical fibres is much more difficult than connecting copper wires. In Fibre to the Home (FTTH), where a lot of branches are present in the network, an Optical Distribution Network is used to branch the cables from a roadside cabinet or pit that contains optical equipment and is fed from the Central Office\n\nWith microduct cabling, bundles of small microducts are installed in larger protective ducts . This can be done by jetting for example. Bundles of microducts can also be factory pre-installed. The microducts can be branched very easily in the network. At any place of choice, a window cut is made in the protective duct and the microduct of choice is cut. This microduct is then connected, using a simple push/pull connector, to a microduct that branches to the desired location. After all connections are made, an individual microduct path has been created in the network. A microduct cable can then be jetted through the microduct, without the need to make a splice.\n\n\nToday the microduct cabling technology is used more and more, all over the world . The fibre counts have grown up to 96 per cable and can be installed in microducts of only 8 mm inner diameter. Bundles of microducts can be jetted over 1500 m or more. Microduct cables can even be jetted over 3.5 km in one single shot . More length without splice is reached by placing jetting equipment in tandem.\n\n"}
{"id": "27015236", "url": "https://en.wikipedia.org/wiki?curid=27015236", "title": "Microwave enhanced electrochemistry", "text": "Microwave enhanced electrochemistry\n\nMicrowave radiation was applied in electrochemical methods in 1998 when Frank Marken and Richard G. Compton in Oxford placed a piece of platinum wire inside a microwave cavity in small electrochemical cell.\n"}
{"id": "729148", "url": "https://en.wikipedia.org/wiki?curid=729148", "title": "Mobile virtual network operator", "text": "Mobile virtual network operator\n\nA mobile virtual network operator (MVNO), virtual network operator (VNO), or mobile other licensed operator (MOLO), is a wireless communications services provider that does not own the wireless network infrastructure over which it provides services to its customers. An MVNO enters into a business agreement with a mobile network operator to obtain bulk access to network services at wholesale rates, then sets retail prices independently. An MVNO may use its own customer service, billing support systems, marketing, and sales personnel, or it could employ the services of a mobile virtual network enabler (MVNE).\n\nMVNO agreements with network operators date back to the 1990s, when the European telecom market saw market liberalization, new regulatory frameworks, better 2G network technology, and a subsequent jump in wireless subscriber numbers. Though the new 2G networks more efficiently managed the limited frequency bands allocated to wireless service, new mobile entrants were still limited by their ability to access frequency bands in a restricted spectrum.\n\nWith European markets newly open to competition and new technology enabling better service and cheaper handsets, there was a massive surge in demand for cellular phones. In the midst of this swell, Sense Communications fought for access to mobile network operator (MNO) spectrum in Scandinavia in 1997. Sense was able to establish an MVNO agreement with Sonera in Finland, but it failed to persuade MNOs in Sweden, Denmark, and Norway. Sense then appealed to EU regulators, citing provisions that required certain MNOs to allow new entrants interconnection. While Sense's claim was denied, in November 1999, the company signed a service provider agreement with Telia/Telenor Mobile for GSM network capacity access, allowing Sense to offer services to its own customers in Sweden and Norway.\n\nDespite Sense's initial failure, the regulator in Denmark saw the promise in the MVNO model as a cost-effective route for telecom companies to enter the market and in May 2000, legislation passed that required network operators with significant market power to open up access to their infrastructure. By August of that same year, the MNO SONOFON had solidified the first viable MVNO agreement with Tele2. This agreement provided Tele2 with access to SONOFON's network for both mobile and roaming services, the latter of which had been requested by (and denied to) Sense Communications. With the new regulations in place, MVNOs in Scandinavia eventually grew to a market share of above 10%.\n\nBy 2008, US wireless subscribers had a choice between around 40 MVNOs. According to the FCC, approximately 7 percent of all U.S. mobile subscribers were served by resellers, including MVNOs, and analysts found that the 15.1 million wireless subscribers served by resellers by the end of 2006 had increased by 1.6 million over the previous year.\n\nMVNOs are distinguished by their commitment to owning and managing the operational components of the MVNO business model, consisting of: \n\nBecause MVNOs are effectively defined by their lack of spectrum licenses, an MVNO necessarily will need to have agreements in place to access the network of at least one MNO. The type of MVNO is determined by how \"thick\" or \"thin\" a technological layer an MVNO adds over its access to its host MVNO's network.\n\nBranded reseller\n\nSometimes referred to as a \"Skinny MVNO\", as the reseller almost totally relies on the MVNO's facilities. They do not own any network elements, but may own and operate their own customer care, marketing, and sales operations.\n\nService Provider\n\nSometimes referred to as a \"Light MVNO\". The service provider operates its own customer support, marketing, sales and distribution operations, and has the ability to set its tariffs independently from the retail prices set by the MVNO.\n\nEnhanced Service Provider\n\nSometimes referred to as a \"Thick MVNO\". The MVNO manages a more complete technical implementations with its own infrastructure which allows the MVNO more control over its offerings. These MVNOs have a heavier focus on branding, customer-ownership, and differentiation through added services like data and SIM applications.\n\nFull MVNO\n\nThese MVNOs have a network implementation operating essentially the same technology as a mobile network operator. Full MVNOs only lack their own radio networks.\n\nAs of June 2014, 943 MVNOs and 255 MNO sub-brands were active worldwide. This represents a total of almost 1,200 mobile service providers worldwide hosted by MNOs, up from 1,036 in 2012,\n\nAccording to GSMA Intelligence, between June 2010 and June 2015, the number of MVNOs worldwide increased by 70 percent, reaching 1,017 in June 2015. The report further noted that the 10 countries with the largest number of MVNOs in June 2015, was Germany with 129 MVNOs, the U.S. with 108, the UK 76, the Netherlands 56, France 49, Australia 43, Denmark 43, Spain 35, Poland 27, and Belgium with 26. Japan is next with 23 MVNOs.\n\nIn addition to traditional cellular voice and messaging services, in 2014, 120 MVNOs also were offering mobile broadband services. In Africa, Uganda has registered three MVNOs so far, some having their own network infrastructure within major cities, but acting as an MVNO out of these cities.\n\nMVNOs target both the consumer and enterprise markets. The majority of MVNOs are consumer-focused and most have a focus on price as their selling point; on average, customers of major carriers spend about 3.4 times as much money on their service as MVNO customers.\n\nIndian Market also opened up for VNOs - As per TRAI Govt regulations, VNO Policy has been rolled out and Multiple Cable Operators/ISP's/New Players have started Applying and 50+ companies received approval for a Virtual Network Operator (VNO) from the DoT, a majority of the VNO licenses were awarded to Tier 1, 2 & 3 cities. Plintron was awarded INDIA National VNO license.\n\nSome MVNOs have a presence in multiple countries, either as subsidies, joint ventures, or through brand licensing agreements with local partners. i.e. Lycamobile 25 countries, Virgin Mobile 12 countries, Lebara 9 countries, Tesco Mobile 5 countries.\n\nThere are about 300 MVNOs operating in the U.S., which are estimated to hold about 1 in 10 wireless subscriptions—36 million customers in all. That number has roughly doubled since 2009, thanks to a trend of the larger providers allowing customers to more easily switch networks, and a significant decrease in the cost of wholesale network capacity rates. MVNOs have tended to receive better customer service marks in the U.S. than the big carriers, with Consumer Cellular, Ting, and Republic Wireless topping the Consumer Reports industry customer service satisfaction rankings.\n\nTo better compete with MVNOs, which tend to offer service at lower rates than the major US wireless networks directly, some large American carriers also market wireless service using their own captive MVNOs or alternative brands such as Boost Mobile (Sprint), Cricket Wireless (AT&T) and Wal-Mart Family Mobile (Tracfone). Other notable MVNOs offering lower rates are Lycamobile, ChatSIM, Ultra Mobile, US Mobile, RedPocket and TracFone.\n\nThe UK has over 20 MVNOs but all use one of the four coverage providers: EE, O2, Three and Vodafone.\n\nIn 2003, the European Commission issued a recommendation to national telecom regulators to examine the competitiveness of the market for wholesale access and call origination on public mobile telephone networks. The study resulted in new regulations from regulators in several countries, including Ireland and France forcing operators to open up their networks to MVNOs.\n\nJordan's top watchdog issued its first MVNO regulations in 2008, facilitating the creation of the first MVNO in the Arab world in 2010.\n\nThe Saudi government is making preparations to permit MVNO services in the country.\n\nIn Brazil, MVNOs are regulated by Anatel, the Brazilian Agency of Telecommunications, in November 2010. As of September 2014 the combined market share of all Brazilian MVNOs was just 0.04%.\n\nIn Thailand, five MVNOs were given a Type II license to operate on the 2100 MHz 3G network of state telecom service TOT Public Company Limited (TOT) in 2009. As of January 2017, two of the original five MVNOs are still in service.\n\nIn India, the Telecom Department under the Ministry of Communications and Information Technology, accepted a recommendation from the national telecom regulator, Telecom Regulatory Authority of India, to permit VNOs in the country, and announced the grant of a unified license for Virtual Network Operators on 31 May 2016. VNOs have formed an association to represent current regulatory issues impacting their MVNO business viability. \n\n"}
{"id": "25926311", "url": "https://en.wikipedia.org/wiki?curid=25926311", "title": "Morse system", "text": "Morse system\n\nMORSE system is a unique communication system developed by RACOM. The system has been primarily designed for narrow band radio modems. However, it has been extended for the next communication channels afterwards: IP (any network using UDP/IP, e.g. Internet) and GPRS, EDGE, UMTS.\n\nThe system is used primarily for communication in SCADA & Telemetry, Fleet management and transaction & financial networks.\nThere are more than 70 automation protocols implemented in MORSE system. Some of them are implemented in “cache mode”, when there is a mirror of data from all RTU in central modem. So the response time for SCADA is really fast.\n\n"}
{"id": "13932283", "url": "https://en.wikipedia.org/wiki?curid=13932283", "title": "Multimedia extension connector", "text": "Multimedia extension connector\n\nA multimedia extension connector (MXC) is a method of connecting video cameras and other video inputs to video capture cards and the like.\n\nMXC is based on the 8-pin Mini-DIN connector. It is used by Winnov's range of Videum capture cards.\n\n"}
{"id": "2234056", "url": "https://en.wikipedia.org/wiki?curid=2234056", "title": "Natura &amp; Co", "text": "Natura &amp; Co\n\nNatura & Co or simply Natura is a Brazilian manufacturer and marketer of beauty products, household, and personal care, skin care, solar filters, cosmetics, perfume and hair care products the company that sells products through representatives and in more than 3.200 stores in 70 countries across the world. The company was founded in 1969 by Luiz Seabra, and became a public company listed on São Paulo Stock Exchange in 2004. Currently the company is the largest Brazilian cosmetics company by revenue. The Company is owned by Brazilian billionaires Antônio Luiz Seabra, Guilherme Peirão Leal and Pedro Passos.\n\nIn 1974, Natura adopted direct sales as sales model. In 2017 it had more than 1.8 million \"consultants\" (resellers) spread throughout Argentina, Brazil, Chile, Colombia, France, Mexico, Peru and among others, and since 2006 surpasses Avon's sales in Brazil.\n\nNatura is a founding member of the Union for Ethical BioTrade, gradually ensuring that its sourcing practices promote the conservation of biodiversity, respect traditional knowledge and assure the equitable sharing of benefits all along the supply chain. In the steps of their development and production of cosmetics, Natura does not test on animals and follows the most stringent international safety standards.\n\nBeing a public company since 2004, its shares are listed on Novo Mercado (the highest level of corporate governance or Stock Exchange [Ibovespa]). Natura's performance in 2007 shows a consolidated gross revenue of R$4.3 billion, a growth of 10.6% over the previous year. Its consolidated net income was R$462.3 million, generating a return on opening shareholders' equity of 72.1%.\n\nIn 2005 they opened their first boutique in Paris, France\n\nIn Brazil, the major competitors of Natura are O Boticário, Jequiti and the American company Avon.\n\nNatura promotes its image as an eco-friendly, sustainable company (using natural products, working toward sustainable environment and social support etc.). The company also uses ordinary women rather than supermodels in its advertisements.\n\nNatura operates more than 3.200 stores and works with direct sales models. The sales channel has more than 1.8 million consultants. The company also encourages personal development, material and professional consultants and advisors.\n"}
{"id": "38393818", "url": "https://en.wikipedia.org/wiki?curid=38393818", "title": "Netduino", "text": "Netduino\n\nNetduino is an open-source electronics prototyping platform based on the .NET Micro Framework. It uses the ARM Cortex-M 32-bit RISC ARM processor core as a 32-bit ARM-microcontroller. The Netduino boards (except the discontinued Mini and Go models) are designed to be pin-compatible with most Arduino shields. Applications can be built on Windows (with Visual Studio), or on Mac OS (with Xamarin Studio). The platform is similar in concept to the Arduino platform, but is generally more powerful and instead of writing applications in C/C++ or Wiring (essentially, C++ without header files), applications are written in C#, which brings powerful, high-level language constructs to the toolbox such as threading, event handling, automatic garbage collection, and more. \n\nNetduino was invented by Chris Walker, founder of Secret Labs.\n\nThe platform is now actively supported by Wilderness Labs and has an active open source community.\n\nThe Netduino family is based on the Cortex-M Micro Processor running the .NET Micro Framework (NETMF) v4.3. Development can be done on both Windows, with Visual Studio, or with Xamarin Studio on Mac OS X. IO includes 22 General Purpose Input/Output (GPIO) ports, 6 of which support hardware Pulse Width Modulation (PWM) generation, 4 UARTs (serial communication), I2C, and SPI (Serial Peripheral Interface Bus).\n\nThe Netduino family consists of the Netduino 3, Netduino 2, and the original Netduino 1 lines. The original Netduino (1st generation) and Netduino Mini (also 1st generation), have been replaced by the much more powerful Netduino 2 and 3 lines.\n\nThe Netduino 3 is based on a Cortex-M4 microcontroller running at 168 MHz with 384 KB of flash storage and 164 KB of RAM.\n\nNetduino 3 is offered in 3 different models, the N3 base model, N3 Ethernet model, and the N3 WiFi model; which vary by their internet connectivity mode and their code/flash storage size. All N3 models support persistent storage with SD cards up to 2GB. Both the Ethernet and WiFi models have a Micro SD slot built in to the board. The base model can use SD cards via most Arduino SD Card add-on shields.\n\nThe N3 technical specifications are as follows:\nNetduino 2 is offered in 2 different models, the N2 base model as well as the N2+, which adds 10Mb Ethernet.\nThe original Netduino forum is archived and contains historical and technical information about the original Netduino boards and development.\n\nThe original Netduino was based on an Atmel AT91SAM7X processor running at 48 MHz.\n\nThe Netduino Plus added an onboard Ethernet port and a microSD card reader.\n\nThe Netduino mini was a smaller breadboard mountable Netduino in a DIP package.\n\nWith Netduino Go, all the peripherals were virtualized, with 8 gobus ports replacing the Arduino headers. Additional modules could be added through these ports, and each module had a small microchip which works together with the mainboard.\n"}
{"id": "2054813", "url": "https://en.wikipedia.org/wiki?curid=2054813", "title": "One-hot", "text": "One-hot\n\nIn digital circuits and machine learning, one-hot is a group of bits among which the legal combinations of values are only those with a single high (1) bit and all the others low (0).\nA similar implementation in which all bits are '1' except one '0' is sometimes called one-cold.\nIn statistics, dummy variables represent a similar technique for representing categorical data.\n\nOne-hot encoding is often used for indicating the state of a state machine. When using binary or Gray code, a decoder is needed to determine the state. A one-hot state machine, however, does not need a decoder as the state machine is in the \"n\"th state if and only if the \"n\"th bit is high.\n\nA ring counter with 15 sequentially-ordered states is an example of a state machine. A 'one-hot' implementation would have 15 flip flops chained in series with the Q output of each flip flop connected to the D input of the next and the D input of the first flip flop connected to the Q output of the 15th flip flop. The first flip flop in the chain represents the first state, the second represents the second state, and so on to the 15th flip flop which represents the last state. Upon reset of the state machine all of the flip flops are reset to '0' except the first in the chain which is set to '1'. The next clock edge arriving at the flip flops advances the one 'hot' bit to the second flip flop. The 'hot' bit advances in this way until the 15th state, after which the state machine returns to the first state.\n\nAn address decoder converts from binary or Gray code to one-hot representation.\nA priority encoder converts from one-hot representation to binary or Gray code.\n\nIn natural language processing, a one-hot vector is a 1 × \"N\" matrix (vector) used to distinguish each word in a vocabulary from every other word in the vocabulary. The vector consists of 0s in all cells with the exception of a single 1 in a cell used uniquely to identify the word.\n\n\nUsing a one-hot implementation typically allows a state machine to run at a faster clock rate than any other encoding of that state machine.\n\n\n"}
{"id": "24458395", "url": "https://en.wikipedia.org/wiki?curid=24458395", "title": "Online memorial", "text": "Online memorial\n\nOnline memorials are virtual spaces created on the Internet for the purpose of remembering, celebrating, or commemorating those who have died. An online memorial may be a one-page HTML webpage document giving the name of the deceased and a few words of tribute, an extensive information source, or be part of a social media platform where users can add their own words and photos.\n\nA few individual online memorials started appearing on the Internet in the late 1990s. Many were websites created in response to the death of a person who was in the public eye, rather than for general members of the public. One example of this is the collective memorial website Find a Grave, which at that time was focused on publishing memorial information about famous people. Also during the 1990s, newspapers and funeral homes began contributing obituaries to permanent online databases, including Legacy.com. Online cemeteries, the first of which was launched in 1995 as the World Wide Cemetery (cemetery.org), also host online memorials.\n\nIn 1997, Carla Sofka, Professor of Social Work, in her article 'Social support \"Internetworks,\" caskets for sale, and more: Thanatology and the information superhighway', recognized the increasing use of this new form of memorialisation. Online memorials for public events, such as the one created by the National September 11 Memorial and Museum, also began to appear, allowing a collective response to events causing widespread grief.\n\nIn the 2000s, with the development of social media platforms and simplified website creation software, the numbers of individual online memorials has increased rapidly. Online memorial databases such as Find a Grave have also opened up to allow contributions from individual users.\n\nOnline memorials allow participation in the grieving process from a distance and at any time of the day or night; in the view of some sociologists, such public displays of grief are important for emotional recovery after bereavement. They provide a communications outlet for continued grieving when more formal events have ended. Availability of inexpensive or free online space allows grievers to include extensive content such as stories and discussions. Unlike some other types of memorials, they have little environmental impact. Facebook can give people the opportunity to keep the deceased apart of their lives by posting on their walls during the holidays, birthdays, and other important dates in their lives or the bereaved life. Online memorials also give the bereaved the ability to pull up the deceased page and go through the comments or pictures when they are having a particularly difficult time and want to remember good memories they once shared with the deceased. Continuing bonds and expressing feelings toward the deceased can be considered therapeutic to the bereaved. \n\nMany online memorial platforms, as well as individual memorials created on general social media sites and blogs, allow memorials to be built in a collaborative fashion by mourners, who share their expressions of grief in the form of comments or posts. \n\nSocial media pages created by people who have later died are sometimes converted into memorial sites. Facebook, for example, provides a process for transforming the profile of a deceased user into a memorial. Family members or friends can report an account to be memorialized upon presentation of proof of death. When the account is memorialized, Facebook removes sensitive information such as contact information and status updates, but still enables friends and family to leave posts on the profile wall in remembrance. However, only confirmed friends can see the memorialized profile or locate it in search. \n\nOnline memorials are sometimes used to collect donations to charitable or non-profit organizations, to fund medical research, hospices, or community activities and hobbies in which the deceased participated.\n"}
{"id": "39229", "url": "https://en.wikipedia.org/wiki?curid=39229", "title": "Open system (computing)", "text": "Open system (computing)\n\nOpen systems are computer systems that provide some combination of interoperability, portability, and open software standards. (It can also refer to specific installations that are configured to allow unrestricted access by people and/or other computers; this article does not discuss that meaning).\n\nThe term was popularized in the early 1980s, mainly to describe systems based on Unix, especially in contrast to the more entrenched mainframes and minicomputers in use at that time. Unlike older legacy systems, the newer generation of Unix systems featured standardized programming interfaces and peripheral interconnects; third party development of hardware and software was encouraged, a significant departure from the norm of the time, which saw companies such as Amdahl and Hitachi going to court for the right to sell systems and peripherals that were compatible with IBM's mainframes.\n\nThe definition of \"open system\" can be said to have become more formalized in the 1990s with the emergence of independently administered software standards such as The Open Group's Single UNIX Specification.\n\nAlthough computer users today are used to a high degree of both hardware and software interoperability, in the 20th century the open systems concept could be promoted by Unix vendors as a significant differentiator. IBM and other companies resisted the trend for decades, exemplified by a now-famous warning in 1991 by an IBM account executive that one should be \"careful about getting locked into open systems\".\n\nHowever, in the first part of the 21st century many of these same legacy system vendors, particularly IBM and Hewlett-Packard, began to adopt Linux as part of their overall sales strategy, with \"open source\" marketed as trumping \"open system\". Consequently, an IBM mainframe with Linux on z Systems is marketed as being more of an open system than commodity computers using closed-source Microsoft Windows—or even those using Unix, despite its open systems heritage. In response, more companies are opening the source code to their products, with a notable example being Sun Microsystems and their creation of the OpenOffice.org and OpenSolaris projects, based on their formerly closed-source StarOffice and Solaris software products.\n\n"}
{"id": "11284769", "url": "https://en.wikipedia.org/wiki?curid=11284769", "title": "Quad data rate", "text": "Quad data rate\n\nQuad data rate (QDR, or quad pumping) is a communication signaling technique wherein data are transmitted at four points in the clock cycle: on the rising and falling edges, and at two intermediate points between them. The intermediate points are defined by a second clock that is 90° out of phase from the first. The effect is to deliver four bits of data per signal line per clock cycle.\n\nIn a quad data rate system, the data lines operate at twice the frequency of the clock signal. This is in contrast to double data rate systems, in which the clock and data lines operate at the same frequency.\n\nQuad data rate technology was introduced by Intel in its Willamette-core Pentium 4 processor, and was subsequently employed in its Atom, Pentium 4, Celeron, Pentium D and Core 2 processor ranges. This technology has allowed Intel to produce chipsets and processors that can communicate with each other at data rates expected of the traditional front side bus (FSB) technology running from 400 MT/s to 1600 MT/s, while maintaining a lower and thus more stable actual clock frequency of 100 MHz to 400 MHz.\n\nThe reasons for operating in QDR rather than DDR are very different than those cited for operating in DDR rather than single data rate. Going to DDR allowed manufacturers of memory to send data at the same rate as the clock (one data-line transition for every clock-line transition), while SDR could only send data at half the rate of the clock (one data-line transition for every clock-line rising edge). A native implementation of QDR would result in the data rate being higher than the clock rate, negating any simple electrical advantage.\n\nThe advantages for QDR arise when dealing with bus contention. On a modern computer, there may be several CPUs and several I/O devices, all competing for accesses to the memory. To handle this contention properly, modern systems aim to enable signals to propagate between all connected components within a single clock cycle, while setting a firm limit on the maximum clock rate. However, once the contention has been dealt with, the data transfer can be treated as a simple point-to-point unidirectional transfer. In such a simple transfer, it is no longer essential for signals to fully propagate within a cycle; they merely need to arrive coherently, marshaled by a special signal called \"strobe\". This reduced requirement on signal integrity allows the QDR data transfer to occur at twice the speed of the clock, as opposed to at the same speed as the clock as in DDR.\n\n"}
{"id": "25676", "url": "https://en.wikipedia.org/wiki?curid=25676", "title": "Radar", "text": "Radar\n\nRadar is a detection system that uses radio waves to determine the range, angle, or velocity of objects. It can be used to detect aircraft, ships, spacecraft, guided missiles, motor vehicles, weather formations, and terrain. A radar system consists of a transmitter producing electromagnetic waves in the radio or microwaves domain, a transmitting antenna, a receiving antenna (often the same antenna is used for transmitting and receiving) and a receiver and processor to determine properties of the object(s). Radio waves (pulsed or continuous) from the transmitter reflect off the object and return to the receiver, giving information about the object's location and speed.\n\nRadar was developed secretly for military use by several nations in the period before and during World War II. A key development was the cavity magnetron in the UK, which allowed the creation of relatively small systems with sub-meter resolution. The term \"RADAR\" was coined in 1940 by the United States Navy as an acronym for RAdio Detection And Ranging or RAdio Direction And Ranging. The term \"radar\" has since entered English and other languages as a common noun, losing all capitalization.\n\nThe modern uses of radar are highly diverse, including air and terrestrial traffic control, radar astronomy, air-defence systems, antimissile systems, marine radars to locate landmarks and other ships, aircraft anticollision systems, ocean surveillance systems, outer space surveillance and rendezvous systems, meteorological precipitation monitoring, altimetry and flight control systems, guided missile target locating systems, ground-penetrating radar for geological observations, and range-controlled radar for public health surveillance. High tech radar systems are associated with digital signal processing, machine learning and are capable of extracting useful information from very high noise levels.\n\nOther systems similar to radar make use of other parts of the electromagnetic spectrum. One example is \"lidar\", which uses predominantly infrared light from lasers rather than radio waves.\n\nAs early as 1886, German physicist Heinrich Hertz showed that radio waves could be reflected from solid objects. In 1895, Alexander Popov, a physics instructor at the Imperial Russian Navy school in Kronstadt, developed an apparatus using a coherer tube for detecting distant lightning strikes. The next year, he added a spark-gap transmitter. In 1897, while testing this equipment for communicating between two ships in the Baltic Sea, he took note of an interference beat caused by the passage of a third vessel. In his report, Popov wrote that this phenomenon might be used for detecting objects, but he did nothing more with this observation.\n\nThe German inventor Christian Hülsmeyer was the first to use radio waves to detect \"the presence of distant metallic objects\". In 1904, he demonstrated the feasibility of detecting a ship in dense fog, but not its distance from the transmitter. He obtained a patent for his detection device in April 1904 and later a patent for a related amendment for estimating the distance to the ship. He also got a British patent on September 23, 1904 for a full radar system, that he called a \"telemobiloscope\". It operated on a 50 cm wavelength and the pulsed radar signal was created via a spark-gap. His system already used the classic antenna setup of horn antenna with parabolic reflector and was presented to German military officials in practical tests in Cologne and Rotterdam harbour but was rejected.\n\nIn 1915, Robert Watson-Watt used radio technology to provide advance warning to airmen and during the 1920s went on to lead the U.K. research establishment to make many advances using radio techniques, including the probing of the ionosphere and the detection of lightning at long distances. Through his lightning experiments, Watson-Watt became an expert on the use of radio direction finding before turning his inquiry to shortwave transmission. Requiring a suitable receiver for such studies, he told the \"new boy\" Arnold Frederic Wilkins to conduct an extensive review of available shortwave units. Wilkins would select a General Post Office model after noting its manual's description of a \"fading\" effect (the common term for interference at the time) when aircraft flew overhead.\n\nAcross the Atlantic in 1922, after placing a transmitter and receiver on opposite sides of the Potomac River, U.S. Navy researchers A. Hoyt Taylor and Leo C. Young discovered that ships passing through the beam path caused the received signal to fade in and out. Taylor submitted a report, suggesting that this phenomenon might be used to detect the presence of ships in low visibility, but the Navy did not immediately continue the work. Eight years later, Lawrence A. Hyland at the Naval Research Laboratory (NRL) observed similar fading effects from passing aircraft; this revelation led to a patent application as well as a proposal for further intensive research on radio-echo signals from moving targets to take place at NRL, where Taylor and Young were based at the time.\n\nBefore the Second World War, researchers in the United Kingdom, France, Germany, Italy, Japan, the Netherlands, the Soviet Union, and the United States, independently and in great secrecy, developed technologies that led to the modern version of radar. Australia, Canada, New Zealand, and South Africa followed prewar Great Britain's radar development, and Hungary generated its radar technology during the war.\n\nIn France in 1934, following systematic studies on the split-anode magnetron, the research branch of the Compagnie Générale de Télégraphie Sans Fil (CSF) headed by Maurice Ponte with Henri Gutton, Sylvain Berline and M. Hugon, began developing an obstacle-locating radio apparatus, aspects of which were installed on the ocean liner \"Normandie\" in 1935.\n\nDuring the same period, Soviet military engineer P.K. Oshchepkov, in collaboration with Leningrad Electrophysical Institute, produced an experimental apparatus, RAPID, capable of detecting an aircraft within 3 km of a receiver. The Soviets produced their first mass production radars RUS-1 and RUS-2 Redut in 1939 but further development was slowed following the arrest of Oshchepkov and his subsequent gulag sentence. In total, only 607 Redut stations were produced during the war. The first Russian airborne radar, Gneiss-2, entered into service in June 1943 on Pe-2 fighters. More than 230 Gneiss-2 stations were produced by the end of 1944. The French and Soviet systems, however, featured continuous-wave operation that did not provide the full performance ultimately synonymous with modern radar systems.\n\nFull radar evolved as a pulsed system, and the first such elementary apparatus was demonstrated in December 1934 by the American Robert M. Page, working at the Naval Research Laboratory. The following year, the United States Army successfully tested a primitive surface-to-surface radar to aim coastal battery searchlights at night. This design was followed by a pulsed system demonstrated in May 1935 by Rudolf Kühnhold and the firm GEMA in Germany and then another in June 1935 by an Air Ministry team led by Robert A. Watson-Watt in Great Britain.\n\nIn 1935, Watson-Watt was asked to judge recent reports of a German radio-based death ray and turned the request over to Wilkins. Wilkins returned a set of calculations demonstrating the system was basically impossible. When Watson-Watt then asked what such a system might do, Wilkins recalled the earlier report about aircraft causing radio interference. This revelation led to the Daventry Experiment of 26 February 1935, using a powerful BBC shortwave transmitter as the source and their GPO receiver setup in a field while a bomber flew around the site. When the plane was clearly detected, Hugh Dowding, the Air Member for Supply and Research was very impressed with their system's potential and funds were immediately provided for further operational development. Watson-Watt's team patented the device in GB593017.\n\nDevelopment of radar greatly expanded on 1 September 1936 when Watson-Watt became Superintendent of a new establishment under the British Air Ministry, Bawdsey Research Station located in Bawdsey Manor, near Felixstowe, Suffolk. Work there resulted in the design and installation of aircraft detection and tracking stations called \"Chain Home\" along the East and South coasts of England in time for the outbreak of World War II in 1939. This system provided the vital advance information that helped the Royal Air Force win the Battle of Britain; without it, significant numbers of fighter aircraft would always need to be in the air to respond quickly enough if enemy aircraft detection relied solely on the observations of ground-based individuals. Also vital was the \"Dowding system\" of reporting and coordination to make best use of the radar information during tests of early deployment of radar in 1936 and 1937.\n\nGiven all required funding and development support, the team produced working radar systems in 1935 and began deployment. By 1936, the first five Chain Home (CH) systems were operational and by 1940 stretched across the entire UK including Northern Ireland. Even by standards of the era, CH was crude; instead of broadcasting and receiving from an aimed antenna, CH broadcast a signal floodlighting the entire area in front of it, and then used one of Watson-Watt's own radio direction finders to determine the direction of the returned echoes. This fact meant CH transmitters had to be much more powerful and have better antennas than competing systems but allowed its rapid introduction using existing technologies.\n\nA key development was the cavity magnetron in the UK, which allowed the creation of relatively small systems with sub-meter resolution. Britain shared the technology with the U.S. during the 1940 Tizard Mission.\n\nIn April 1940, \"Popular Science\" showed an example of a radar unit using the Watson-Watt patent in an article on air defence. Also, in late 1941 \"Popular Mechanics\" had an article in which a U.S. scientist speculated about the British early warning system on the English east coast and came close to what it was and how it worked. Watson-Watt was sent to the U.S. in 1941 to advise on air defense after Japan’s attack on Pearl Harbor. Alfred Lee Loomis organized the secret MIT Radiation Laboratory at Massachusetts Institute of Technology, Cambridge, Massachusetts which developed microwave radar technology in the years 1941–45. Later, in 1943, Page greatly improved radar with the monopulse technique that was used for many years in most radar applications.\n\nThe war precipitated research to find better resolution, more portability, and more features for radar, including complementary navigation systems like Oboe used by the RAF's Pathfinder.\n\nThe information provided by radar includes the bearing and range (and therefore position) of the object from the radar scanner. It is thus used in many different fields where the need for such positioning is crucial. The first use of radar was for military purposes: to locate air, ground and sea targets. This evolved in the civilian field into applications for aircraft, ships, and roads.\n\nIn aviation, aircraft can be equipped with radar devices that warn of aircraft or other obstacles in or approaching their path, display weather information, and give accurate altitude readings. The first commercial device fitted to aircraft was a 1938 Bell Lab unit on some United Air Lines aircraft. Aircraft can land in fog at airports equipped with radar-assisted ground-controlled approach systems in which the plane's position is observed on radar screens by operators who radio landing instructions to the pilot, maintaining the aircraft on a defined approach path to the runway. Military fighter aircraft are usually fitted with air-to-air targeting radars, to detect and target enemy aircraft. In addition, larger specialized military aircraft carry powerful airborne radars to observe air traffic over a wide region and direct fighter aircraft towards targets.\n\nMarine radars are used to measure the bearing and distance of ships to prevent collision with other ships, to navigate, and to fix their position at sea when within range of shore or other fixed references such as islands, buoys, and lightships. In port or in harbour, vessel traffic service radar systems are used to monitor and regulate ship movements in busy waters.\n\nMeteorologists use radar to monitor precipitation and wind. It has become the primary tool for short-term weather forecasting and watching for severe weather such as thunderstorms, tornadoes, winter storms, precipitation types, etc. Geologists use specialized ground-penetrating radars to map the composition of Earth's crust. Police forces use radar guns to monitor vehicle speeds on the roads. Smaller radar systems are used to detect human movement. Examples are breathing pattern detection for sleep monitoring and hand and finger gesture detection for computer interaction. Automatic door opening, light activation and intruder sensing are also common.\n\nA radar system has a transmitter that emits radio waves called \"radar signals\" in predetermined directions. When these come into contact with an object they are usually reflected or scattered in many directions. But some of them absorb and penetrate into the target to some degree. Radar signals are reflected especially well by materials of considerable electrical conductivity—especially by most metals, by seawater and by wet ground. Some of these make the use of radar altimeters possible. The radar signals that are reflected back towards the transmitter are the desirable ones that make radar work. If the object is \"moving\" either toward or away from the transmitter, there is a slight equivalent change in the frequency of the radio waves, caused by the Doppler effect.\n\nRadar receivers are usually, but not always, in the same location as the transmitter. Although the reflected radar signals captured by the receiving antenna are usually very weak, they can be strengthened by electronic amplifiers. More sophisticated methods of signal processing are also used in order to recover useful radar signals.\n\nThe weak absorption of radio waves by the medium through which it passes is what enables radar sets to detect objects at relatively long ranges—ranges at which other electromagnetic wavelengths, such as visible light, infrared light, and ultraviolet light, are too strongly attenuated. Such weather phenomena as fog, clouds, rain, falling snow, and sleet that block visible light are usually transparent to radio waves. Certain radio frequencies that are absorbed or scattered by water vapour, raindrops, or atmospheric gases (especially oxygen) are avoided in designing radars, except when their detection is intended.\n\nRadar relies on its own transmissions rather than light from the Sun or the Moon, or from electromagnetic waves emitted by the objects themselves, such as infrared wavelengths (heat). This process of directing artificial radio waves towards objects is called \"illumination\", although radio waves are invisible to the human eye or optical cameras.\n\nIf electromagnetic waves travelling through one material meet another material, having a different dielectric constant or diamagnetic constant from the first,\nthe waves will reflect or scatter from the boundary between the materials. This means that a solid object in air or in a vacuum, or a significant change in atomic density between the object and what is surrounding it, will usually scatter radar (radio) waves from its surface. This is particularly true for electrically conductive materials such as metal and carbon fibre, making radar well-suited to the detection of aircraft and ships. Radar absorbing material, containing resistive and sometimes magnetic substances, is used on military vehicles to reduce radar reflection. This is the radio equivalent of painting something a dark colour so that it cannot be seen by the eye at night.\n\nRadar waves scatter in a variety of ways depending on the size (wavelength) of the radio wave and the shape of the target. If the wavelength is much shorter than the target's size, the wave will bounce off in a way similar to the way light is reflected by a mirror. If the wavelength is much longer than the size of the target, the target may not be visible because of poor reflection. Low-frequency radar technology is dependent on resonances for detection, but not identification, of targets. This is described by Rayleigh scattering, an effect that creates Earth's blue sky and red sunsets. When the two length scales are comparable, there may be resonances. Early radars used very long wavelengths that were larger than the targets and thus received a vague signal, whereas many modern systems use shorter wavelengths (a few centimetres or less) that can image objects as small as a loaf of bread.\n\nShort radio waves reflect from curves and corners in a way similar to glint from a rounded piece of glass. The most reflective targets for short wavelengths have 90° angles between the reflective surfaces. A corner reflector consists of three flat surfaces meeting like the inside corner of a box. The structure will reflect waves entering its opening directly back to the source. They are commonly used as radar reflectors to make otherwise difficult-to-detect objects easier to detect. Corner reflectors on boats, for example, make them more detectable to avoid collision or during a rescue. For similar reasons, objects intended to avoid detection will not have inside corners or surfaces and edges perpendicular to likely detection directions, which leads to \"odd\" looking stealth aircraft. These precautions do not completely eliminate reflection because of diffraction, especially at longer wavelengths. Half wavelength long wires or strips of conducting material, such as chaff, are very reflective but do not direct the scattered energy back toward the source. The extent to which an object reflects or scatters radio waves is called its radar cross section.\n\nThe power \"P\" returning to the receiving antenna is given by the equation:\n\nwhere\n\nIn the common case where the transmitter and the receiver are at the same location, \"R\" = \"R\" and the term \"R\"² \"R\"² can be replaced by \"R\", where \"R\" is the range.\nThis yields:\n\nAs an example, a Doppler weather radar with a pulse rate of 2 kHz and transmit frequency of 1 GHz can reliably measure weather speed up to at most , thus cannot reliably determine radial velocity of aircraft moving .\n\nIn all electromagnetic radiation, the electric field is perpendicular to the direction of propagation, and the electric field direction is the polarization of the wave. For a transmitted radar signal, the polarization can be controlled to yield different effects. Radars use horizontal, vertical, linear, and circular polarization to detect different types of reflections. For example, circular polarization is used to minimize the interference caused by rain. Linear polarization returns usually indicate metal surfaces. Random polarization returns usually indicate a fractal surface, such as rocks or soil, and are used by navigation radars.\n\nThe radar beam would follow a linear path in vacuum, but it really follows a somewhat curved path in the atmosphere because of the variation of the refractive index of air, that is called the radar horizon. Even when the beam is emitted parallel to the ground, it will rise above it as the Earth curvature sinks below the horizon. Furthermore, the signal is attenuated by the medium it crosses, and the beam disperses.\n\nThe maximum range of a conventional radar can be limited by a number of factors:\n\nSignal noise is an internal source of random variations in the signal, which is generated by all electronic components.\n\nReflected signals decline rapidly as distance increases, so noise introduces a radar range limitation. The noise floor and signal to noise ratio are two different measures of performance that affect range performance. Reflectors that are too far away produce too little signal to exceed the noise floor and cannot be detected. Detection requires a signal that exceeds the noise floor by at least the signal to noise ratio.\n\nNoise typically appears as random variations superimposed on the desired echo signal received in the radar receiver. The lower the power of the desired signal, the more difficult it is to discern it from the noise. Noise figure is a measure of the noise produced by a receiver compared to an ideal receiver, and this needs to be minimized.\n\nShot noise is produced by electrons in transit across a discontinuity, which occurs in all detectors. Shot noise is the dominant source in most receivers. There will also be flicker noise caused by electron transit through amplification devices, which is reduced using heterodyne amplification. Another reason for heterodyne processing is that for fixed fractional bandwidth, the instantaneous bandwidth increases linearly in frequency. This allows improved range resolution. The one notable exception to heterodyne (downconversion) radar systems is ultra-wideband radar. Here a single cycle, or transient wave, is used similar to UWB communications, see List of UWB channels.\n\nNoise is also generated by external sources, most importantly the natural thermal radiation of the background surrounding the target of interest. In modern radar systems, the internal noise is typically about equal to or lower than the external noise. An exception is if the radar is aimed upwards at clear sky, where the scene is so \"cold\" that it generates very little thermal noise. The thermal noise is given by \"k T B\", where \"T\" is temperature, \"B\" is bandwidth (post matched filter) and \"k\" is Boltzmann's constant. There is an appealing intuitive interpretation of this relationship in a radar. Matched filtering allows the entire energy received from a target to be compressed into a single bin (be it a range, Doppler, elevation, or azimuth bin). On the surface it would appear that then within a fixed interval of time one could obtain perfect, error free, detection. To do this one simply compresses all energy into an infinitesimal time slice. What limits this approach in the real world is that, while time is arbitrarily divisible, current is not. The quantum of electrical energy is an electron, and so the best one can do is match filter all energy into a single electron. Since the electron is moving at a certain temperature (Plank spectrum) this noise source cannot be further eroded. We see then that radar, like all macro-scale entities, is profoundly impacted by quantum theory.\n\nNoise is random and target signals are not. Signal processing can take advantage of this phenomenon to reduce the noise floor using two strategies. The kind of signal integration used with moving target indication can improve noise up to formula_5 for each stage. The signal can also be split among multiple filters for pulse-Doppler signal processing, which reduces the noise floor by the number of filters. These improvements depend upon coherence.\n\nRadar systems must overcome unwanted signals in order to focus on the targets of interest. These unwanted signals may originate from internal and external sources, both passive and active. The ability of the radar system to overcome these unwanted signals defines its signal-to-noise ratio (SNR). SNR is defined as the ratio of the signal power to the noise power within the desired signal; it compares the level of a desired target signal to the level of background noise (atmospheric noise and noise generated within the receiver). The higher a system's SNR the better it is at discriminating actual targets from noise signals.\n\nClutter refers to radio frequency (RF) echoes returned from targets which are uninteresting to the radar operators. Such targets include natural objects such as ground, sea, and when not being tasked for meteorological purposes, precipitation (such as rain, snow or hail), sand storms, animals (especially birds), atmospheric turbulence, and other atmospheric effects, such as ionosphere reflections, meteor trails, and Hail spike. Clutter may also be returned from man-made objects such as buildings and, intentionally, by radar countermeasures such as chaff.\n\nSome clutter may also be caused by a long radar waveguide between the radar transceiver and the antenna. In a typical plan position indicator (PPI) radar with a rotating antenna, this will usually be seen as a \"sun\" or \"sunburst\" in the centre of the display as the receiver responds to echoes from dust particles and misguided RF in the waveguide. Adjusting the timing between when the transmitter sends a pulse and when the receiver stage is enabled will generally reduce the sunburst without affecting the accuracy of the range, since most sunburst is caused by a diffused transmit pulse reflected before it leaves the antenna. Clutter is considered a passive interference source, since it only appears in response to radar signals sent by the radar.\n\nClutter is detected and neutralized in several ways. Clutter tends to appear static between radar scans; on subsequent scan echoes, desirable targets will appear to move, and all stationary echoes can be eliminated. Sea clutter can be reduced by using horizontal polarization, while rain is reduced with circular polarization (meteorological radars wish for the opposite effect, and therefore use linear polarization to detect precipitation). Other methods attempt to increase the signal-to-clutter ratio.\n\nClutter moves with the wind or is stationary. Two common strategies to improve measure or performance in a clutter environment are:\n\nThe most effective clutter reduction technique is pulse-Doppler radar. Doppler separates clutter from aircraft and spacecraft using a frequency spectrum, so individual signals can be separated from multiple reflectors located in the same volume using velocity differences. This requires a coherent transmitter. Another technique uses a moving target indicator that subtracts the receive signal from two successive pulses using phase to reduce signals from slow moving objects. This can be adapted for systems that lack a coherent transmitter, such as time-domain pulse-amplitude radar.\n\nConstant false alarm rate, a form of automatic gain control (AGC), is a method that relies on clutter returns far outnumbering echoes from targets of interest. The receiver's gain is automatically adjusted to maintain a constant level of overall visible clutter. While this does not help detect targets masked by stronger surrounding clutter, it does help to distinguish strong target sources. In the past, radar AGC was electronically controlled and affected the gain of the entire radar receiver. As radars evolved, AGC became computer-software controlled and affected the gain with greater granularity in specific detection cells.\n\nClutter may also originate from multipath echoes from valid targets caused by ground reflection, atmospheric ducting or ionospheric reflection/refraction (e.g., anomalous propagation). This clutter type is especially bothersome since it appears to move and behave like other normal (point) targets of interest. In a typical scenario, an aircraft echo is reflected from the ground below, appearing to the receiver as an identical target below the correct one. The radar may try to unify the targets, reporting the target at an incorrect height, or eliminating it on the basis of jitter or a physical impossibility. Terrain bounce jamming exploits this response by amplifying the radar signal and directing it downward. These problems can be overcome by incorporating a ground map of the radar's surroundings and eliminating all echoes which appear to originate below ground or above a certain height. Monopulse can be improved by altering the elevation algorithm used at low elevation. In newer air traffic control radar equipment, algorithms are used to identify the false targets by comparing the current pulse returns to those adjacent, as well as calculating return improbabilities.\n\nRadar jamming refers to radio frequency signals originating from sources outside the radar, transmitting in the radar's frequency and thereby masking targets of interest. Jamming may be intentional, as with an electronic warfare tactic, or unintentional, as with friendly forces operating equipment that transmits using the same frequency range. Jamming is considered an active interference source, since it is initiated by elements outside the radar and in general unrelated to the radar signals.\n\nJamming is problematic to radar since the jamming signal only needs to travel one way (from the jammer to the radar receiver) whereas the radar echoes travel two ways (radar-target-radar) and are therefore significantly reduced in power by the time they return to the radar receiver. Jammers therefore can be much less powerful than their jammed radars and still effectively mask targets along the line of sight from the jammer to the radar (\"mainlobe jamming\"). Jammers have an added effect of affecting radars along other lines of sight through the radar receiver's sidelobes (\"sidelobe jamming\").\n\nMainlobe jamming can generally only be reduced by narrowing the mainlobe solid angle and cannot fully be eliminated when directly facing a jammer which uses the same frequency and polarization as the radar. Sidelobe jamming can be overcome by reducing receiving sidelobes in the radar antenna design and by using an omnidirectional antenna to detect and disregard non-mainlobe signals. Other anti-jamming techniques are frequency hopping and polarization.\n\nOne way to obtain a distance measurement is based on the time-of-flight: transmit a short pulse of radio signal (electromagnetic radiation) and measure the time it takes for the reflection to return. The distance is one-half the product of the round trip time (because the signal has to travel to the target and then back to the receiver) and the speed of the signal. Since radio waves travel close to the speed of light, accurate distance measurement requires high-speed electronics.\nIn most cases, the receiver does not detect the return while the signal is being transmitted. Through the use of a duplexer, the radar switches between transmitting and receiving at a predetermined rate.\nA similar effect imposes a maximum range as well. In order to maximize range, longer times between pulses should be used, referred to as a pulse repetition time, or its reciprocal, pulse repetition frequency.\n\nThese two effects tend to be at odds with each other, and it is not easy to combine both good short range and good long range in a single radar. This is because the short pulses needed for a good minimum range broadcast have less total energy, making the returns much smaller and the target harder to detect. This could be offset by using more pulses, but this would shorten the maximum range. So each radar uses a particular type of signal. Long-range radars tend to use long pulses with long delays between them, and short range radars use smaller pulses with less time between them. As electronics have improved many radars now can change their pulse repetition frequency, thereby changing their range. The newest radars fire two pulses during one cell, one for short range (about ) and a separate signal for longer ranges (about ).\n\nThe distance resolution and the characteristics of the received signal as compared to noise depends on the shape of the pulse. The pulse is often modulated to achieve better performance using a technique known as pulse compression.\n\nDistance may also be measured as a function of time. The radar mile is the time it takes for a radar pulse to travel one nautical mile, reflect off a target, and return to the radar antenna. Since a nautical mile is defined as 1,852 m, then dividing this distance by the speed of light (299,792,458 m/s), and then multiplying the result by 2 yields a result of 12.36 μs in duration.\n\nAnother form of distance measuring radar is based on frequency modulation. Frequency comparison between two signals is considerably more accurate, even with older electronics, than timing the signal. By measuring the frequency of the returned signal and comparing that with the original, the difference can be easily measured.\n\nThis technique can be used in continuous wave radar and is often found in aircraft radar altimeters. In these systems a \"carrier\" radar signal is frequency modulated in a predictable way, typically varying up and down with a sine wave or sawtooth pattern at audio frequencies. The signal is then sent out from one antenna and received on another, typically located on the bottom of the aircraft, and the signal can be continuously compared using a simple \"beat frequency\" modulator that produces an audio frequency tone from the returned signal and a portion of the transmitted signal.\n\nSince the signal frequency is changing, by the time the signal returns to the aircraft the transmit frequency has changed. The frequency shift is used to measure distance.\n\nThe modulation index riding on the receive signal is proportional to the time delay between the radar and the reflector. The frequency shift becomes greater with greater time delay. The frequency shift is directly proportional to the distance travelled. That distance can be displayed on an instrument, and it may also be available via the transponder. This signal processing is similar to that used in speed detecting Doppler radar. Example systems using this approach are AZUSA, MISTRAM, and UDOP.\n\nA further advantage is that the radar can operate effectively at relatively low frequencies. This was important in the early development of this type when high frequency signal generation was difficult or expensive.\n\nTerrestrial radar uses low-power FM signals that cover a larger frequency range. The multiple reflections are analyzed mathematically for pattern changes with multiple passes creating a computerized synthetic image. Doppler effects are used which allows slow moving objects to be detected as well as largely eliminating \"noise\" from the surfaces of bodies of water.\n\nSpeed is the change in distance to an object with respect to time. Thus the existing system for measuring distance, combined with a memory capacity to see where the target last was, is enough to measure speed. At one time the memory consisted of a user making grease pencil marks on the radar screen and then calculating the speed using a slide rule. Modern radar systems perform the equivalent operation faster and more accurately using computers.\n\nIf the transmitter's output is coherent (phase synchronized), there is another effect that can be used to make almost instant speed measurements (no memory is required), known as the Doppler effect. Most modern radar systems use this principle into Doppler radar and pulse-Doppler radar systems (weather radar, military radar). The Doppler effect is only able to determine the relative speed of the target along the line of sight from the radar to the target. Any component of target velocity perpendicular to the line of sight cannot be determined by using the Doppler effect alone, but it can be determined by tracking the target's azimuth over time.\n\nIt is possible to make a Doppler radar without any pulsing, known as a continuous-wave radar (CW radar), by sending out a very pure signal of a known frequency. CW radar is ideal for determining the radial component of a target's velocity. CW radar is typically used by traffic enforcement to measure vehicle speed quickly and accurately where range is not important.\n\nWhen using a pulsed radar, the variation between the phase of successive returns gives the distance the target has moved between pulses, and thus its speed can be calculated.\nOther mathematical developments in radar signal processing include time-frequency analysis (Weyl Heisenberg or wavelet), as well as the chirplet transform which makes use of the change of frequency of returns from moving targets (\"chirp\").\n\nPulse-Doppler signal processing includes frequency filtering in the detection process. The space between each transmit pulse is divided into range cells or range gates. Each cell is filtered independently much like the process used by a spectrum analyzer to produce the display showing different frequencies. Each different distance produces a different spectrum. These spectra are used to perform the detection process. This is required to achieve acceptable performance in hostile environments involving weather, terrain, and electronic countermeasures.\n\nThe primary purpose is to measure both the amplitude and frequency of the aggregate reflected signal from multiple distances. This is used with weather radar to measure radial wind velocity and precipitation rate in each different volume of air. This is linked with computing systems to produce a real-time electronic weather map. Aircraft safety depends upon continuous access to accurate weather radar information that is used to prevent injuries and accidents. Weather radar uses a low PRF. Coherency requirements are not as strict as those for military systems because individual signals ordinarily do not need to be separated. Less sophisticated filtering is required, and range ambiguity processing is not normally needed with weather radar in comparison with military radar intended to track air vehicles.\n\nThe alternate purpose is \"look-down/shoot-down\" capability required to improve military air combat survivability. Pulse-Doppler is also used for ground based surveillance radar required to defend personnel and vehicles. Pulse-Doppler signal processing increases the maximum detection distance using less radiation in close proximity to aircraft pilots, shipboard personnel, infantry, and artillery. Reflections from terrain, water, and weather produce signals much larger than aircraft and missiles, which allows fast moving vehicles to hide using nap-of-the-earth flying techniques and stealth technology to avoid detection until an attack vehicle is too close to destroy. Pulse-Doppler signal processing incorporates more sophisticated electronic filtering that safely eliminates this kind of weakness. This requires the use of medium pulse-repetition frequency with phase coherent hardware that has a large dynamic range. Military applications require medium PRF which prevents range from being determined directly, and range ambiguity resolution processing is required to identify the true range of all reflected signals. Radial movement is usually linked with Doppler frequency to produce a lock signal that cannot be produced by radar jamming signals. Pulse-Doppler signal processing also produces audible signals that can be used for threat identification.\n\nSignal processing is employed in radar systems to reduce the radar interference effects. Signal processing techniques include moving target indication, Pulse-Doppler signal processing, moving target detection processors, correlation with secondary surveillance radar targets, space-time adaptive processing, and track-before-detect. Constant false alarm rate and digital terrain model processing are also used in clutter environments.\n\nA Track algorithm is a radar performance enhancement strategy. Tracking algorithms provide the ability to predict future position of multiple moving objects based on the history of the individual positions being reported by sensor systems.\n\nHistorical information is accumulated and used to predict future position for use with air traffic control, threat estimation, combat system doctrine, gun aiming, and missile guidance. Position data is accumulated radar sensors over the span of a few minutes.\n\nThere are four common track algorithms.\n\nRadar video returns from aircraft can be subjected to a plot extraction process whereby spurious and interfering signals are discarded. A sequence of target returns can be monitored through a device known as a plot extractor.\n\nThe non-relevant real time returns can be removed from the displayed information and a single plot displayed. In some radar systems, or alternatively in the command and control system to which the radar is connected, a radar tracker is used to associate the sequence of plots belonging to individual targets and estimate the targets' headings and speeds.\n\nA radar's components are:\n\nRadio signals broadcast from a single antenna will spread out in all directions, and likewise a single antenna will receive signals equally from all directions. This leaves the radar with the problem of deciding where the target object is located.\n\nEarly systems tended to use omnidirectional broadcast antennas, with directional receiver antennas which were pointed in various directions. For instance, the first system to be deployed, Chain Home, used two straight antennas at right angles for reception, each on a different display. The maximum return would be detected with an antenna at right angles to the target, and a minimum with the antenna pointed directly at it (end on). The operator could determine the direction to a target by rotating the antenna so one display showed a maximum while the other showed a minimum.\nOne serious limitation with this type of solution is that the broadcast is sent out in all directions, so the amount of energy in the direction being examined is a small part of that transmitted. To get a reasonable amount of power on the \"target\", the transmitting aerial should also be directional.\n\nMore modern systems use a steerable parabolic \"dish\" to create a tight broadcast beam, typically using the same dish as the receiver. Such systems often combine two radar frequencies in the same antenna in order to allow automatic steering, or \"radar lock\".\n\nParabolic reflectors can be either symmetric parabolas or spoiled parabolas:\nSymmetric parabolic antennas produce a narrow \"pencil\" beam in both the X and Y dimensions and consequently have a higher gain. The NEXRAD Pulse-Doppler weather radar uses a symmetric antenna to perform detailed volumetric scans of the atmosphere. Spoiled parabolic antennas produce a narrow beam in one dimension and a relatively wide beam in the other. This feature is useful if target detection over a wide range of angles is more important than target location in three dimensions. Most 2D surveillance radars use a spoiled parabolic antenna with a narrow azimuthal beamwidth and wide vertical beamwidth. This beam configuration allows the radar operator to detect an aircraft at a specific azimuth but at an indeterminate height. Conversely, so-called \"nodder\" height finding radars use a dish with a narrow vertical beamwidth and wide azimuthal beamwidth to detect an aircraft at a specific height but with low azimuthal precision.\n\nApplied similarly to the parabolic reflector, the slotted waveguide is moved mechanically to scan and is particularly suitable for non-tracking surface scan systems, where the vertical pattern may remain constant. Owing to its lower cost and less wind exposure, shipboard, airport surface, and harbour surveillance radars now use this approach in preference to a parabolic antenna.\n\nAnother method of steering is used in a phased array radar.\n\nPhased array antennas are composed of evenly spaced similar antenna elements, such as aerials or rows of slotted waveguide. Each antenna element or group of antenna elements incorporates a discrete phase shift that produces a phase gradient across the array. For example, array elements producing a 5 degree phase shift for each wavelength across the array face will produce a beam pointed 5 degrees away from the centreline perpendicular to the array face. Signals travelling along that beam will be reinforced. Signals offset from that beam will be cancelled. The amount of reinforcement is antenna gain. The amount of cancellation is side-lobe suppression.\n\nPhased array radars have been in use since the earliest years of radar in World War II (Mammut radar), but electronic device limitations led to poor performance. Phased array radars were originally used for missile defence (see for example Safeguard Program). They are the heart of the ship-borne Aegis Combat System and the Patriot Missile System. The massive redundancy associated with having a large number of array elements increases reliability at the expense of gradual performance degradation that occurs as individual phase elements fail. To a lesser extent, Phased array radars have been used in Weather Surveillance. As of 2017, NOAA plans to implement a national network of Multi-Function Phased array radars throughout the United States within 10 years, for meteorological studies and flight monitoring.\n\nPhased array antennas can be built to conform to specific shapes, like missiles, infantry support vehicles, ships, and aircraft.\n\nAs the price of electronics has fallen, phased array radars have become more common. Almost all modern military radar systems are based on phased arrays, where the small additional cost is offset by the improved reliability of a system with no moving parts. Traditional moving-antenna designs are still widely used in roles where cost is a significant factor such as air traffic surveillance and similar systems.\n\nPhased array radars are valued for use in aircraft since they can track multiple targets. The first aircraft to use a phased array radar was the B-1B Lancer. The first fighter aircraft to use phased array radar was the Mikoyan MiG-31. The MiG-31M's SBI-16 Zaslon Passive electronically scanned array radar was considered to be the world's most powerful fighter radar, until the AN/APG-77 Active electronically scanned array was introduced on the Lockheed Martin F-22 Raptor.\n\nPhased-array interferometry or aperture synthesis techniques, using an array of separate dishes that are phased into a single effective aperture, are not typical for radar applications, although they are widely used in radio astronomy. Because of the thinned array curse, such multiple aperture arrays, when used in transmitters, result in narrow beams at the expense of reducing the total power transmitted to the target. In principle, such techniques could increase spatial resolution, but the lower power means that this is generally not effective.\n\nAperture synthesis by post-processing motion data from a single moving source, on the other hand, is widely used in space and airborne radar systems.\n\nThe traditional band names originated as code-names during World War II and are still in military and aviation use throughout the world. They have been adopted in the United States by the Institute of Electrical and Electronics Engineers and internationally by the International Telecommunication Union. Most countries have additional regulations to control which parts of each band are available for civilian or military use.\n\nOther users of the radio spectrum, such as the broadcasting and electronic countermeasures industries, have replaced the traditional military designations with their own systems.\n\nModulators act to provide the waveform of the RF-pulse. There are two different radar modulator designs:\n\nCoherent microwave amplifiers operating above 1,000 watts microwave output, like travelling wave tubes and klystrons, require liquid coolant. The electron beam must contain 5 to 10 times more power than the microwave output, which can produce enough heat to generate plasma. This plasma flows from the collector toward the cathode. The same magnetic focusing that guides the electron beam forces the plasma into the path of the electron beam but flowing in the opposite direction. This introduces FM modulation which degrades Doppler performance. To prevent this, liquid coolant with minimum pressure and flow rate is required, and deionized water is normally used in most high power surface radar systems that utilize Doppler processing.\n\nCoolanol (silicate ester) was used in several military radars in the 1970s. However, it is hygroscopic, leading to hydrolysis and formation of highly flammable alcohol. The loss of a U.S. Navy aircraft in 1978 was attributed to a silicate ester fire. Coolanol is also expensive and toxic. The U.S. Navy has instituted a program named Pollution Prevention (P2) to eliminate or reduce the volume and toxicity of waste, air emissions, and effluent discharges. Because of this, Coolanol is used less often today.\n\n\"Radar\" (also: \"RADAR\") is defined by \"article 1.100\" of the International Telecommunication Union´s (ITU) ITU Radio Regulations (RR) as:\n\n\n\n\n\n"}
{"id": "47906830", "url": "https://en.wikipedia.org/wiki?curid=47906830", "title": "Rideshare advertising", "text": "Rideshare advertising\n\nRideshare advertising is a form of digital, out-of-home advertising that uses in-car advertisements in ridesharing vehicles.\n\nRideshare advertising is performed through digital display screens in the backseat of rideshare vehicles. Drivers contract with rideshare advertising companies and ad displays are controlled by the company. James Bellefeuille, founder of Vugo, coined the term \"Rideshare Advertising\".\n\nDrivers expressed support for the new opportunity to earn additional income. Some rideshare companies such as Uber disapprove of rideshare advertising of companies including Vugo, claiming that it does not add to the value of passenger experience. Uber has recommended that drivers do not participate in rideshare advertising, but stated that they recommend so as employees advising other employees due to drivers being independent contractors and not employees of the company.\n\n\n"}
{"id": "13677392", "url": "https://en.wikipedia.org/wiki?curid=13677392", "title": "Solar Energy Materials and Solar Cells", "text": "Solar Energy Materials and Solar Cells\n\nSolar Energy Materials and Solar Cells is a scientific journal published by Elsevier covering research related to solar energy materials and solar cells.\n\nA paper titled \"Ageing effects of perovskite solar cells under different environmental factors and electrical load conditions\" published in 2018 in the journal corresponded to a paper previously published in the journal \"Nature Energy\" as \"Systematic investigation of the impact of operation conditions on the degradation behaviour of perovskite solar cells\".\nIt let to an investigation of plagiarism.\n\n"}
{"id": "10385693", "url": "https://en.wikipedia.org/wiki?curid=10385693", "title": "Squirrel Systems", "text": "Squirrel Systems\n\nSquirrel Systems is a Burnaby-based point of sale vendor specializing in hospitality management systems. Squirrel is based in Burnaby, Canada.\n\nSquirrel Systems was founded in 1984, and released the first restaurant point of sale system to use an integrated diskless touchscreen terminal for order management. Originally a wholly owned subsidiary of Sulcus Hospitality Technologies Corporation, in 1998 Sulcus merged with Eltrax Systems, Incorporated (Nasdaq SmallCap: ELTX). Squirrel is currently a wholly owned subsidiary of Marin Investments Ltd.\n\nOne of the unique characteristics of Squirrel's original product was the use of hardened LCD touchscreen terminals. Unlike other systems that used keyboards and CRT monitors, Squirrel terminals had no moving parts and were easily adapted to any operating environment. The original Squirrel terminals reached over 35,000 installed units worldwide, and was the first to integrate an LCD panel, credit card reader, employee ID reader, and CPU inside a single unit. Later units would incorporate IP connectivity, remote booting of a customized Linux operating system, and a Java virtual machine.\n\nIn 1998 Squirrel Systems released \"Squirrel Embedded Linux\" (\"SEL\"), a customized distribution of Linux for \"thin client\" terminal architecture. \"SEL\" has several characteristics that were unique at the time of development, including primary support for diskless workstations, customized high-volume touchscreen drivers, integrated Java virtual machine with hardware control, and two-stage booting from a Windows server.\n\n\n\n"}
{"id": "45717906", "url": "https://en.wikipedia.org/wiki?curid=45717906", "title": "Suncore Photovoltaics", "text": "Suncore Photovoltaics\n\nSuncore Photovoltaic Technology Company Limited (\"Suncore\") is a solar energy company that specializes in concentrator photovoltaics (CPV), an emerging photovoltaic (PV) technology. The company manufactures, develops, and finances CPV systems for ground mounted applications. Its products include CPV solar power systems, receivers, trackers and turnkey service.\n\nSuncore Photovoltaics Technology Co, Ltd, was founded in 2010 as a joint-venture company by Chinese LED manufacturer San'an Optoelctronics Co, Ltd and U.S. semiconductor manufacturer EMCORE Corporation. In 2013, San’an became the sole owner of Suncore by purchasing stocks from Emcore.\n\nIn 2013 Suncore acquired Zenith Solar, the creator of a combined heat and power (CHP) technology which allows for the production of both electricity and hot water in a single system.\n\nSuncore's manufacturing capacity is around 300 megawatts (MW) with its manufacturing facility of over in China. In addition to system manufacturing, Suncore also supplies the solar receiver to labs and manufacturers around the world. Suncore has a portfolio of 120 MW of CPV systems deployed worldwide, including the largest CPV power plant in Golmud, China.\n"}
{"id": "17464548", "url": "https://en.wikipedia.org/wiki?curid=17464548", "title": "Swimbait", "text": "Swimbait\n\nSwimbaits are a loosely defined class of fishing lures that imitate fish and tend to be distinct in design from a typical crankbait.\n\nSwimbaits are usually different from crankbaits by the way they generate lure action. Some are rubber \"paddle tail\" lures that appear to swim when the tail flutters during retrieve. Some are jointed baits that wave like a flag in the water when retrieved, without any obvious mechanism to generate motion. Some are large jointed crankbaits or crankbait/plastic lure hybrids.\n\nSwimbaits originated as lures designed to imitate the planted\nrainbow trout in Southern California reservoirs that\nLargemouth Bass and Striped Bass\nfed on. They were larger and more lifelike imitations than most\navailable mass-produced lures.\n\nThe term swimbait is often used to indicate plastic \"paddle tail\" lures, regardless of size or appearance.\n\n"}
{"id": "8904738", "url": "https://en.wikipedia.org/wiki?curid=8904738", "title": "TN 71", "text": "TN 71\n\nThe TN 71 is a French-built thermonuclear warhead which was used on submarine-launched ballistic missiles in \"Redoutable\" class ballistic missile submarines.\n\nIt has a yield of 150 kt.\n\nEntering service in 1985 on M4-B ballistic missiles, it was replaced at the end of October 1996 by the TN 75, which equips M45 missiles for France's \"Triomphant\" class of \"new generation\" ballistic missile submarines (SNLE-NG).\n\nThere were 288 operational TN 71 warheads before its replacement in 1996, and 96 in 2001, but none were remaining by 2004, at which time it was withdrawn from service. \n\n"}
{"id": "21923388", "url": "https://en.wikipedia.org/wiki?curid=21923388", "title": "Techdirt", "text": "Techdirt\n\nTechdirt is an internet blog that reports on technology's legal challenges and related business and economic policy issues, in context of the digital revolution. It focusses on intellectual property, patent, information privacy and copyright reform in particular.\n\nThe website Masnick founded in 1997 was originally based on the weblog software Slash. Techblog's content is based on reader submissions as well as the editorial staff's picks. The website makes use of MySQL, Apache, and PHP, and is hosted at ActionWeb.\n\nThere is a guest editor section in techdirt, called \"Favorite Techdirt Posts of the Week\", where several high-profile personalities of politics and culture contributed articles over the years; for instance Marietje Schaake, European Parliament MEP for the Netherlands, Sen. Ron Wyden of Oregon or author Glyn Moody.\n\nOn Techdirt in January 2005 the \"Streisand effect\" was coined by founder Mike Masnick.\n\nIn 2003 Forbes named techdirt as one of the \"Best Tech Blogs\".\nIn 2006 techdirt has been praised for its \"sharp, pithy analysis of current tech issues\" by Bloomberg Businessweek. In 2007 techdirt was nominated for the Webby Award in the section \"Web Blog - Business\". Techdirt has been named among the favorite blogs of \"PC Magazine\" in 2008. In 2015 techdirt was positively mentioned for the bold step to allow readers to remove web ads.\n\nIn 2009, English singer Lily Allen created a blog critical of music piracy where she plagiarized an entire post from Techdirt. Following an exchange with Techdirt, debating hypocrisy in the musician's handling of copyright infringement, Allen shut down her blog.\n\nMarvin Ammori, a lawyer who advocates on network neutrality and Internet freedom issues, praised techdirt in the 2011s Stop Online Piracy Act controversy with: \"I’m not sure anyone did more to educate the public about SOPA than Techdirt.\"\n\nIn 2017, Shiva Ayyadurai filed suit against Techdirt for defamation in response to a series of articles critical of Ayyadurai's claims to have invented email. Techdirt announced its intention to fight the suit, describing it as a \"First Amendment fight for its life\". A federal judge dismissed the defamation claims on September 6, 2017.\n"}
{"id": "31240382", "url": "https://en.wikipedia.org/wiki?curid=31240382", "title": "Technology doping", "text": "Technology doping\n\nTechnology doping is a new term that has been becoming more popular recently in sports. Technology doping is the practice of gaining a competitive advantage using sports equipment. The World Anti-Doping Agency (WADA) considers prohibiting technologies if they are \"performance-enhancing\" or \"being against the spirit of the sport\". In 2006, WADA initiated a consultation on technology doping which is now officially recognised as a threat, whilst the decision to allow or ban a new technology, specifically relating to sports equipment, is the responsibility of each sport’s own governing body.\n\nSince most sports require equipment of some sort, it can be tricky to determine what is technology doping and what is not. The governing authorities of different sports usually make judgment calls about the technological advances in their sport’s equipment. Technological advancements are often allowed unless the governing authorities feel they threaten the integrity of the sport. \nA report released immediately before the 2012 Summer Olympics quotes an extensive public survey that shows that people fear that sports engineering could: overshadow the triumph of human spirit and effort, make certain sports easier, create unfairness so the \"best athletes\" might not win, and ensure that rich athletes and countries have an advantage over the poor ones.\n\nThe LZR Racer has been one of the most discussed technologies accused of being technology doping. The LZR Racer bodysuit by Speedo is a high-performance swimsuit. It is made with a material that was designed to mimic shark skin. The suit allows for better oxygen flow to the muscles, holds the body in a more hydrodynamic position, and traps air which adds buoyancy.\n\nAt the 2008 Beijing Olympics, this suit was worn by many swimmers. In fact, some swimmers wore two or more of these suits at once to increase buoyancy. In total, 23 out of the 25 swimming world records broken at the Beijing Olympics were broken by swimmers wearing this suit.\n\nSome people thought these suits might be so technologically advanced that using them in competition was essentially technology doping. After the Beijing Olympics and subsequent swimming events, at which many world records were broken by swimmers wearing the LZR suit, FINA (Fédération Internationale de Natation) banned all body-length swimsuits. Men's suits could only maximally cover from the waist to the knee. Women's suits could only cover from shoulder to knee. They also stipulated that the fabric used to make the suits must be a “textile” and the suit could not have fastening devices, such as zippers. These new rules took effect in January 2010.\n\nA New Zealand firm has created “IonX shirts” which are made of a material that claims to contain a negatively charged electromagnetic field. It further claims that the shirt helps increase blood flow, which in turn helps deliver more oxygen to the muscles and remove lactic acid from the muscles more quickly. For the moment, this technology is still legal. The World Anti-Doping Agency has ruled that since there is no scientific publication that confirms the material actually changes the body’s ion charges or enhances performance and also the material does not contain prohibited substances, this technology is not banned as of now.\n\nResearchers at the Commonwealth Scientific and Industrial Research Organisation, an Australian science agency, created a garment that can monitor movement and give feedback. For example, a basketball player can wear the material in the form of a sleeve. Then sensors in the material send information to a computer when the player takes shots and responds with audible tones. The material essentially gives the athlete real-time feedback on their movements. Athletes can learn patterns of tones that indicate successful or unsuccessful movements and use these to make improvements. The material helps correct the athlete’s movement and helps the athlete gain muscle memory so they can continue to perform well once the material is taken away.\n\nIn cycling, mechanical doping is the use of a secret motor to propel the bicycle. It is banned by the Union Cycliste Internationale. One of the first allegations of mechanical doping was in the 2010 Tour of Flanders. The first confirmed use of mechanical doping was at the 2016 UCI Cyclo-cross World Championships. Bike inspections have become commonplace in road racing since the 2015 season. Riders found guilty of mechanical doping are subject to a fine ranging from 20,000 to 200,000 Swiss Francs and a suspension of at least six months. In the 2016 Tour de France, French officials utilized thermal cameras to enforce their policy against mechanical doping.\n\nAmputees can compete in the Paralympic Games using artificial limbs. There has been significant debate on whether the artificial limbs confer an advantage over able-bodied athletes and whether athletes using them can participate in the Olympic Games. There has also been debate on the effect of the length of the artificial limbs in the Paralympic Games.\n\nMany sports set standards for equipment, to prevent unfair advantages between competitors. This often involves the types of materials the equipment is made from or dimensions/sizes. For example, tennis racquets must not exceed the maximum length and width limits. Soccer balls must not exceed weight limits. Golf clubs must fit shape regulations.\n\n\n"}
{"id": "770027", "url": "https://en.wikipedia.org/wiki?curid=770027", "title": "Telecom Corridor", "text": "Telecom Corridor\n\nThe Telecom Corridor is a technology business center in Richardson, Texas, a northern suburb of Dallas, which contains over 25 million square feet (2.3 million square meters) of office space and accounts for over 130,000 jobs. Located in the Dallas/Fort Worth area and home to the University of Texas at Dallas, the Corridor is a strip about long along U.S. Route 75 (US 75) (the North Central Expressway), between President George Bush Turnpike and Interstate 635 (I-635) and is often considered an area of the Silicon Prairie. More than 5,700 companies, including 600 technology companies are headquartered in the area, including significant players such as AT&T, Alcatel-Lucent, Ericsson, Verizon, Samsung, Texas Instruments, and MetroPCS. Some of these companies also have offices in Telecom Valley located in California. Although the Telecom Corridor was a booming area of Dallas's economy during the late 1990s, the dot-com bust of 2001 hit the region hard. However, it began recovering in 2004, and that recovery has since picked up momentum, gaining both the operations of many non-technology-related companies and a large number of previously non-existent residential units designed in the New Urbanist style. The name \"Telecom Corridor\" is a registered trademark and may technically only be used to describe the area mentioned in this article.\n\nThe Telecom Corridor Genealogy Project is a project to enable professionals in the Telcom Corridor to find out about their common history and thereby to enable them to network more easily.\n\n\n\n\n"}
{"id": "49068504", "url": "https://en.wikipedia.org/wiki?curid=49068504", "title": "Tethersonde", "text": "Tethersonde\n\nA tethersonde is a radiosonde attached to a fixed or tethered balloon, used in atmospheric science. The balloon is usually larger than a balloon used for upper-air soundings, and the tether usually limits the sounding to the boundary layer. The radiosonde is typically moved up and down the tether to get multiple, high-resolution profiles of the boundary layer.\n"}
{"id": "21963885", "url": "https://en.wikipedia.org/wiki?curid=21963885", "title": "World Reuse, Repair and Recycling Association", "text": "World Reuse, Repair and Recycling Association\n\nThe World Reuse, Repair and Recycling Association (WR3A) is a business consortium dedicated to the reform of the trade of e-waste. The WR3A is inspired by fair trade organizations.\n\nWR3A is a Fair Trade association (tradename Fair Trade Recycling reserved in 2013) established both to improve the export markets for surplus electronics and e-waste, and to defend them from biased reporting and racial profiling. WR3A was conceived in 2006 following a visit to China by a group including a USA electronics recycler (American Retroworks Inc.), a University of California Davis recycling program director, and a Seattle recycler with a zero-export policy. \n\nThe group was inspired by a visit to three of China's semi knock down factories. Those factories purchased USA computer monitors which still have functional CRTs. The CRTs are knocked down to the bare tube, which is inserted into a new TV or monitor case, complete with new tuner board, etc. WR3A founders observed that Western journalists reporting on the purchase and import of the used CRTs invariably described them as \"primitive\" wire burning operations, rather than re-manufacturers. These were often the same contract manufacturers who originally assembled brand new CRT monitors, and now rebuilt second-hand CRTs. The USA has its own CRT refurbishing factory, Video Display Corp of Tucker, Georgia.\n\nWR3A proposed to form a coalition of USA companies to export only functional CRT monitors directly to the reuse factories, removing imploded, damaged, screen-burned, older, or non-compliant raster (e.g. Trinitron) CRTs from loads destined for CRT factories. The USA companies which remove and recycle the bad 1/3 of CRTs would benefit from higher prices, and the Chinese factories would bypass the sorting villages such as Guiyu. The WR3A was swamped by orders from Asian factories that year.\n\nThe Chinese government, which took over most of the new CRT manufacturing capacity worldwide in the 1990s, eventually opposed the import of used CRTs. Many of the SKD factory owners relocated their businesses to countries such as Indonesia, Malaysia, and Thailand. Others relocated their used monitor sourcing operations only to Hong Kong and Vietnam, trucking the CRTs overland to Chinese factories. \n\nDuring this period, several anti-globalist NGOs began a campaign to end trade in used electronics, especially CRTs. CBS 60 Minutes, The Economist, BusinessWeek and others ran reports claiming that 80% of the displays exported were not reused but burned for copper in primitive scrapyards. The source of the 80% dumping claim later retracted it.\n\nEventually, reuse operations in Asia turned to re-export to Africa, and used local sources (urban Asian cities) for used CRTs used in remanufacturing new TV and monitor displays. With the decline of purchases of used displays from the USA in 2011, WR3A recognized organizational conflicts between cooperative suppliers competing for a declining market. The organization refined its mission in 2013 emphasize \"anti-defamation\" of overseas refurbishing companies, and promoted used electronics exports through peer-reviewed fair trade agreements. Importers of used equipment in Africa, Asia and Latin America consider the organization a defender of Tech Sector refurbishers. WR3A remains dedicated to the principle that if used computer exports are outlawed, only outlaws will export used computers.\n\nThe organization has members in South America, Africa, Asia, North America, and Europe, dedicated to defending legitimate used electronics exporters from what the organization considers false and defamatory declarations as \"e-waste\" and \"toxics externalization\".\n\nIn 2015, 2017, and 2018 WR3A led visits to the Agbogbloshie District in central Accra, bringing journalists from Al Jazeera, The Independent, Smithsonian, and others to meet with Dagbani speaking translators. The visit led the journalists to discredit allegations that Agbogbloshie was \"the largest e-waste dump in the world\", a \"former wetland on the outskirts of the city\", and that it received hundreds of sea containers full of junk electronics. WR3A found credible evidence that dumping at the site was being exaggerated by Accra Metropolitan Association representatives interested in relocating economic refugees to develop the property, three months before forced evictions. Used electronics processed at the site were shown to be delivered by carters with wheelbarrows, and to consist of devices, such as VCRs, which had been imported decades previously. WR3A provided reporters with World Bank statistics showing domestic Ghana generation more than accounted for the e-waste observed in Ghana, and recorded the organization's own interviews of Ghana Tech Sector representatives (uploaded to Youtube / WR3A).\nIn September 2013, the WR3A adapted the tradename \"Fair Trade Recycling\". The trademark was registered with the USPTO and registered as a supplemental certification on May 26, 2015. The organization does not claim to be recognized by \"fairtrade\" (one word).\n\nIn April 2013, WR3A held a \"Fair Trade Recycling Summit\" at Middlebury College in Vermont. The Summit brought together researchers from Memorial University (Canada), Pontificia Universidad Catholica de Peru, University of Southern California (USA), Massachusetts Institute of Technology (MIT), representatives of the USA International Trade Office, Basel Convention Secretariat, Interpol, and several used electronics importers from Africa, Asia, and Latin America. The group deliberated on beneficial development in emerging markets through electronics reuse and repair (labelled \"Tinkerer's Blessing\" after Yuzo Takahashi's 2000 technology history, A Network of Tinkerers.). The role of electronics repair and reverse engineering in development was contrasted with the so-called \"Resource Curse\" of economic development through natural resource exploitation. Middlebury students and presenters discussed whether a more balanced approach to recycling secondary materials may be warranted. A follow up meeting between WR3A and Interpol was held in July 2013. In November, 2013, Interpol announced a new research program to study the used electronics trade before continuing arrests of African importers (Project Eden).\n\nThe debate between Fair Trade Recycling advocates and the anti-export organization Basel Action Network was profiled in USA Today (September 26, 2013), in Discovery Magazine, and in NIH in 2006\n\nIn July 2012, Memorial University of Newfoundland, Canada, announced a 5-year research project to study and map the routes of used electronics, WEEE, and \"e-waste\" exports. WR3A is a partner in the research grant, along with researchers from universities in Peru and California. The first year, the group will document efforts to develop a \"Fair Trade Recycling\" model in Mexico (see NPR, PBS, AP, coverage), and then research the possible application of the model to Peru, Bangladesh, and China.\n\nWR3A formerly adapted and registered the tradename \"Fair Trade Recycling\" in 2012.\n\nWR3A collaborated with Massachusetts Institute of Technology for publication of MIT's January 2012 study on E-waste generation and exports. WR3A provided researchers with detailed reconciliations of 3 years of exports from WR3A members. MIT compared WR3A data to corroborating data from ISRI, USEPA, Basel Secretariat (Ghana, Nigeria) studies.\n\nIn May 2011, WR3A was interviewed as part of an \"e-waste\" by German news magazine ZDF.Kultur, which investigated the assumptions that African imports were \"primitive\" and linked exports to Egypt's Green Revolution.\n\nIn March, 2011. WR3A was profiled in Motherboard.tv, for the organization's case that reduced exports of used electronics by \"stewards\" was having unintended consequences.\n\nIn October, 2010, WR3A announced a partnership with Basel Action Network to reduce unnecessary breakage and destruction of working computer monitors in California, under California SB20 laws. This followed a report critical of California \"cancellation\" policies published in the Sacramento Bee on July 19, 2010.\n\nOn July 30, 2010, Discovery News presented an analysis contrasting WR3A's \"fair trade\" engagement approach with the Basel Action Network's (BAN) \"trade restriction\" approach, and abstained from choosing sides.,\n\nOn May 15, 2009, National Public Radio's (NPR) program \"Living On Earth\" profiled one of WR3A's members - a women's cooperative doing TV repair and recycling in Mexico.\n\nIn January 2009, the organization presented statistics and a film at the Keynote Address of the CES 2009 in Las Vegas. The statistics demonstrated that the rate of growth of internet access is much higher in countries with very low incomes. It is logically unlikely that this growth can be achieved with new computers. The WR3A also presented film of the reuse and refurbishing operations which demonstrate proper recycling practices and best available practices in these ten countries.\n\nThe WR3A was contracted as a consultant to the US Environmental Protection Agency for its July 2008 publication \"Electronic Waste Management in the United States\".\n\n"}
{"id": "36929728", "url": "https://en.wikipedia.org/wiki?curid=36929728", "title": "Xconomy", "text": "Xconomy\n"}
{"id": "33454300", "url": "https://en.wikipedia.org/wiki?curid=33454300", "title": "Xiaomi", "text": "Xiaomi\n\nXiaomi Corporation (; ) is a Chinese electronics company headquartered in Beijing. Xiaomi makes and invests in smartphones, mobile apps, laptops, and related consumer electronics.\n\nXiaomi released its first smartphone in August 2011 and rapidly gained market share in China to become the country's largest smartphone company in 2014. At the start of Q2 of 2018, Xiaomi was the world's fourth-largest smartphone manufacturer, leading in both the largest market, China, and the second-largest market, India. Xiaomi later developed a wider range of consumer electronics, including a smart home (IoT) device ecosystem.\n\nXiaomi has 15,000 employees in China, India, Malaysia, Singapore and is expanding to other countries including Indonesia, the Philippines, and South Africa. According to Forbes, Lei Jun, the founder and CEO, has an estimated net worth of US$12.5 billion. He is China's 11th richest person and 118th in the world. Xiaomi is the world's 4th most valuable technology start-up after receiving US$1.1 billion funding from investors, making Xiaomi's valuation more than US$46 billion.\n\nXiaomi produces many products. Notably, it produces smartphones which run on their own version of Android MIUI firmware. Observers suggest that part of Xiaomi's rapid success rests on its ability to differentiate itself within the Android universe. The company has increased its range of products; its smartphones include: Mi Series, Mi Note Series, Mi Max Series, Mi Mix Series and the Redmi Series. As well as mobile phones, Xiaomi has started selling wearables, mobile accessories, and appliances such as television and speakers. In 2018 it was selling tablets, laptops, and smart-home devices.\n\nXiaomi operates on a vertically-integrated model that enables the company to sell hardware at cost or below in order to attract users and earn money by selling content. Hugo Barra, a former Google executive who served Xiaomi's vice president from 2014 to 2017, characterized the organization as \"an Internet and a software company much more than a hardware company\".\n\nXiaomi also keeps its prices low or close to \"bill-of-material\" by keeping most of its products in the market longer, eighteen months rather than the six-month norm followed by many smartphone companies. This strategy allows Xiaomi to take advantage of price reductions in the prices of key components of its products. It enables the company to sell hardware with specifications comparable to high-end devices at a fraction of the cost.\n\nThe company's version of the Android operating system, the MIUI skin, with its design, app marketplace, and functionalities, has established a community of users who form a crucial part of Xiaomi's customer base and contribute to the company's drive for market awareness. This ecosystem is a massive source of revenue as indicated in 2015, when sales from the platform reached $750 million.\n\nThe company focuses on India, the world's second-largest smartphone market. Xiaomi announced on May 2, 2018, the launch of Mi Music and Mi Video to offer \"value-added internet services\" in India. On March 22, 2017, Xiaomi announced that it planned to set up a second manufacturing unit in India in partnership with contract manufacturer Foxconn. On August 7, 2018, Xiaomi announced on its blog that Holitech Technology Co. Ltd., Xiaomi's top supplier, would invest up to $200 million over the next three years to set up a major new plant in India.\n\n"}
