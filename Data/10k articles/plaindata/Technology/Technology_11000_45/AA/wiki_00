{"id": "33400623", "url": "https://en.wikipedia.org/wiki?curid=33400623", "title": "Alarm.com", "text": "Alarm.com\n\nAlarm.com, Inc is a US based technology company that provides cloud based services for remote control, home automation and monitoring services. Monitoring services can include contracts through third party contractors such as ADT. Services include interactive security, video monitoring, energy management and home automation, and are enabled through an ecosystem of integrated devices and hardware partnerships. Services are distributed exclusively through a network of authorized and licensed service providers. Alarm.com's common stock is traded on Nasdaq under the ticker symbol ALRM. \n\nAlarm.com was founded in 2000 as part of MicroStrategy's research and development unit, and launched an interactive security solution that enabled remote monitoring and arming for a disarmed security system in 2002. The company has since expanded its platform to offer integrated smart home and business solutions that include video monitoring, energy management and a range of home automation capabilities. \nIn February 2009, Alarm.com was acquired by venture capital firm ABS Capital Partners for $27.7 million. In 2015, Alarm.com filed for an initial public offering and went public that June.\n\nDistributed through a network of authorized service provider partners, Alarm.com provides a turnkey cloud-based platform that enables its partners to bring smart home and business solutions to market. Subscribers can secure and monitor their property through web-based and mobile applications, as well as through Apple TV, Amazon FireTV, Google Home and Amazon Alexa. The company expanded into energy management in early 2010, allowing users to remotely control heating and cooling on their property using mobile apps or via the company's website.\n\nAlarm.com reported revenues of $167.3 million and a user base of more than 2.3 million subscribers in 2014. In 2017, the company reported revenue of $236.3 million and a user base of more than 5.5 million subscribers.\n\nIn 2015, Alarm.com issued an IPO at $14 a share. ABS Capital Partners and Technology Crossover Ventures, which invested $136 million in the company, remained the majority shareholders.\n\nIn 2016, Alarm.com integrated its cloud-based connected home platform with Amazon's Echo wireless speaker and voice-command devices as well as the HomeKit-compatible Apple TV.\n"}
{"id": "4234762", "url": "https://en.wikipedia.org/wiki?curid=4234762", "title": "Artisan Sound Recorders", "text": "Artisan Sound Recorders\n\nArtisan Sound Recorders was one of Southern California's premier disk mastering facilities. It was founded by Robert M. MacLeod Jr. in the 1960s and acquired by Kent Duncan in 1979 when MacLeod retired. In the early 1990s it was sold to Jon Lowry and the mainly mastering operation ceased operation. Hit records by Bone Thugs in Harmony, Eminem, John B continues after 1993.\n\nMore than 500 Gold & Platinum recordings were mastered at Artisan. Its engineering staff was known for meticulous attention to detail in the tape to disk transfer. Later was known for recording and mixing many Hits and great records.\nArtisan's engineering staff included Bob MacLeod, John Golden, Kevin Gray, Jo Hansch, Jon Lowry, and Aaron Connor.\n\n"}
{"id": "27395982", "url": "https://en.wikipedia.org/wiki?curid=27395982", "title": "Automated Imaging Association", "text": "Automated Imaging Association\n\nAutomated Imaging Association (AIA) is the world's largest machine vision trade group. AIA has more than 350 members from 32 countries, including system integrators, camera, lighting and other vision components manufacturers, vision software providers, OEMs and distributors. The association's headquarters is located in Ann Arbor, Michigan. Now part of the A3; Association for Advancing Automation AIA joins RIA; Robotic Industries Association, MCMA, Motion Control & Motor Association and A3 Mexico to form one of the largest collaborative trade association. All organizations offer industry training, news and member benefits. \n\nThe Camera Link , Camera Link HS, GigE vision , USB3Vision and CoaXPress communication protocols are maintained and administered by the Automated Imaging Association (AIA).\n\nCamera Link , Camera Link HS, GigE vision , USB3Vision, CoaXPress are all available for public download on their Vision Online website. Manufacturers of vision products using the standard must license the standard.\n\nSony is among the multi-billion dollar member companies in the AIA. Cognex Corporation and National Instruments are also two big names in the machine vision industry that are members of the AIA. In 2010, 51% of the members are from North America, 30% are from Europe, 15% are from Eastern Asia, less than 1% are from South America, 2% are from Western Asia, less than 1% are from Southern Asia, 1% are from Southeastern Asia and less than 1% of the members are from Australia. \n"}
{"id": "14032635", "url": "https://en.wikipedia.org/wiki?curid=14032635", "title": "Automated airport weather station", "text": "Automated airport weather station\n\nAutomated airport weather stations are automated sensor suites which are designed to serve aviation and meteorological observing needs for safe and efficient aviation operations, weather forecasting and climatology. Automated airport weather stations have become part of the backbone of weather observing in the United States and Canada and are becoming increasingly more prevalent worldwide due to their efficiency and cost-savings.\n\nIn the United States, there are several varieties of automated weather stations that have somewhat subtle but important differences. These include the Automated Weather Observing System (AWOS) and the Automated Surface Observing System (ASOS).\n\nThe Automated Weather Observing System (AWOS) units are mostly operated, maintained and controlled by state or local governments and other non-Federal entities and are certified under the FAA Non-Federal AWOS Program. The FAA completed an upgrade of the 230 FAA owned AWOS and former Automated Weather Sensor Systems (AWSS) systems to the AWOS-C configuration in 2017. The AWOS-C is the most up-to-date FAA owned AWOS facility and can generate METAR/SPECI formatted Aviation Weather Reports. The AWOS-C is functionally equivalent to the ASOS . FAA owned AWOS-C units in Alaska are typically classified as AWOS-C IIIP units while all other AWOS-C units are typically classified as AWOS III P/T units. \n\nAWOS systems disseminate weather data in a variety of ways:\n\nThe following AWOS configurations are defined below in terms of what parameters they measure:\n\nAlso, custom configurations such as AWOS AV (AWOS A parameters plus visibility) are possible. Non-certified sensors may be attached to AWOS systems, but weather data derived from those sensors must be clearly identified as \"advisory\" in any voice messages and may not be included in any METAR observations.\n\nAs of January 31, 2015, the following manufacturers provide FAA-certified, non-Federal AWOS systems:\n\nThe Automated Surface Observing System (ASOS) units are operated and controlled cooperatively in the United States by the NWS, FAA, and DOD. After many years of research and development, the deployment of ASOS units began in 1991 and was completed in 2004.\n\nThese systems generally report at hourly intervals, but also report special observations if weather conditions change rapidly and cross aviation operation thresholds. They generally report all the parameters of the AWOS-III, while also having the additional capabilities of reporting temperature and dew point in degrees Fahrenheit, present weather, icing, lightning, sea level pressure and precipitation accumulation.\n\nBesides serving aviation needs, ASOS serves as a primary climatological observing network in the United States, making up the first-order network of climate stations. Because of this, not every ASOS is located at an airport; for example, one of these units is located at Belvedere Castle in Central Park, New York City; another is located at the Blue Hill Observatory near Boston, Massachusetts.\n\nThe FAA has converted all Automated Weather Sensor System (AWSS) units to AWOS IIIP/T units. There are no AWSS systems remaining in the National Airspace System (NAS). \n\nAutomated airport weather stations use a variety of sophisticated equipment to observe the weather.\n\nA majority of older automated airport weather stations are equipped with a mechanical wind vane and cup system to measure wind speed and direction. This system is simple in design: the wind spins three horizontally turned cups around the base of the wind vane, providing an estimation of the wind's speed, while the vane on top turns so that the face of the vane offers the least resistance to the wind, causing it to point in the direction the wind is coming from and thus providing the wind direction.\n\nThe new generation of sensors use sound waves to measure wind speed and direction. The measurement is based on the time it takes for an ultrasonic pulse to travel from one transducer to another, which varies depending on - among other factors - the wind speed. The transit time is measured in both directions for several (usually two or three) pairs of the transducer heads. Based on those results, the sensor computes wind speed and direction. Compared to mechanical sensors, the ultrasonic sensors offer several advantages such as no moving parts, advanced self-diagnostic capabilities and reduced maintenance requirements.\n\nNWS and FAA ASOS stations and most of new AWOS installations are currently equipped with ultrasonic wind sensors.\n\nUnlike all other measurements, which are made near between 3 and 9 feet (1 and 3 meters) above the ground, wind speed and direction are measured at 30 feet (10 meters).\n\nTo determine visibility, automated airport weather stations use one of two sensor types:\n\nThe forward scatter sensor uses a beam of infrared light which is sent from one end of the sensor toward the receiver, but offset from a direct line to the receiver by a certain angle. The amount of light scattered by particles in the air and received by the receiver determines the extinction coefficient. This is then converted to visibility using either Allard's or Koschmieder's law.\n\nIn a transmissometer, a beam of visible light is transmitted from its transmitter to receiver head. The extinction coefficient is derived from the amount of light lost in the air.\n\nThere also are sensors that, to a certain degree combine a transmissometer with a forward scatter sensor.\n\nForward scatter sensors are more popular due to their lower price, smaller size and lower maintenance requirements. However, transmissometers are still used at some airports as they are more accurate at low visibilities and are fail-safe, i.e. in case of failure report visibility lower than actual.\n\nCurrent sensors are capable of reporting visibility in a wide range. For aviation purposes, the reported values are rounded down to the nearest step in one of the following scales:\n\nAutomated airport weather stations use a Light Emitting Diode Weather Identifier (LEDWI) to determine if and what type of precipitation is falling. The LEDWI sensor measures the scintillation pattern of the precipitation falling through the sensor's infrared beam (approximately 50 millimeters in diameter) and determines from a pattern analysis of the particle size and fall velocity whether the precipitation is rain or snow. If precipitation is determined to be falling, but the pattern is not conclusively identified as either rain or snow, unknown precipitation is reported. Automated airport weather stations are not yet able to report hail, ice pellets, and various other intermediate forms of precipitation.\n\nAutomated airport weather stations do not have a separate sensor for detecting specific obscurations to vision. Instead, when visibility is reduced below 7 statute miles, the system uses the reported temperature and dew point to determine an obscuration to vision. If relative humidity is low (i.e., there is a large difference between the temperature and dew point), haze is reported. If relative humidity is high (i.e., there is a small difference between the temperature and the dew point), mist or fog is reported, depending on the exact visibility. Fog is reported when visibility is 1/2 mile or less; mist is reported for visibilities greater than but less than . If the temperature is below freezing, humidity is high and visibility is 1/2 mile or less, freezing fog is reported.\n\nAutomated airport weather stations use an upward-pointing laser beam ceilometer to detect the amount and height of clouds. The laser is pointed upward, and the time required for reflected light to return to the station allows for the calculation of the height of the cloud base. Because of the limited coverage area (the laser can only detect clouds directly overhead), the system computer calculates a time-averaged cloud cover and ceiling, which is reported to external users. To compensate for the danger of rapidly changing sky cover, the averaging is weighted toward the first 10 minutes of the 30-minute averaging period. The range of the ceilometer is up to depending on the model. Clouds above that height are not detectable by automated stations at present.\n\nAutomated airport weather stations use a temperature/dew point sensor (hygrothermometer) designed for continuous operation which normally remains on at all times, except during maintenance.\n\nThe measurement of temperature is simple compared to the dew point. Operating under the principle that electrical resistance varies with temperature, a platinum wire resistive temperature device measures the ambient air temperature. The current ASOS thermometer is designated the HO-1088, though some older systems still utilize the HO-83.\n\nIn contrast, the dew point measurement is considerably more complex. The original dew point sensor deployed on ASOS systems utilized a chilled mirror that is cooled to the point where a fine film of condensation forms on the mirror's surface. The temperature of the mirror at this condition is equal to the dew point temperature. The hygrometer measures the dew point by directing a light beam from a small infrared diode to the surface of the mirror at an angle of 45 degrees. Two photo transistors are mounted so they measure a high degree of reflected light when the mirror is clear (direct) and scattered light when the mirror is clouded with visible condensation (indirect). With the formation of condensation on the mirror, the degree of cloudiness of the mirror surface increases with the direct transistor receiving less light and the indirect transistor more light. The output from these photo transistors controls the mirror cooling module which is an electronic heat pump that operates much like a thermocouple in reverse, producing a heating or cooling effect. When the sensor is first activated, the mirror is clear. As the mirror surface temperature is cooled to the dew point temperature, condensations forms on the mirror. The electronics continuously tries to stabilize the signal levels to the power amplifier to maintain the mirror temperature at the dew point. If the dew point of the air changes or if the circuit is disturbed by noise, the loop makes the necessary corrections to restabilize at the dew point and maintaining continuous operation.\n\nDue to problems with the chilled mirror sensor, NWS ASOS sites now use Vaisala's DTS1 sensor, which measures humidity only via capacitance. The sensor is based on a solid state capacitive relative humidity element that incorporates a small heater so that the sensing element is always above the ambient temperature, eliminating the formation of dew or frost. The sensor reports directly in dew point through a calculation based on measured relative humidity and the measured temperature of the heated capacitive element.\n\nOlder AWOS systems used a lithium chloride dew point sensor. Current AWOS systems use capacitive relative humidity sensors, from which dew point is calculated.\n\nData from a barometric pressure sensor are used to calculate QNH altimeter setting. Pilots rely on this value to determine their altitude. To ensure safe separation from terrain and other obstructions, high degree of accuracy and reliability is required from a pressure sensor.\n\nMost aviation weather stations use two (required for an AWOS) or three independent pressure transducers. The transducers may or may not share their associated tubing and external ports (designed to minimize effect of wind/wind gusts). Should the reported pressures differ by more than a preset maximum, the pressure values are discarded and altimeter setting is not reported or is reported as \"missing.\"\n\nAltimeter setting is calculated based on barometric pressure, site elevation, sensor elevation and - optionally - air temperature.\n\nAltimeter setting is reported in inches of mercury (in steps of 0.01 inHg) or whole hectopascals, rounded down.\n\nThe original precipitation accumulation measuring device used for automated airport weather stations was the heated tipping bucket. The upper portion of this device consists of a diameter collector with an open top. The collector, which is heated to melt any frozen precipitation such as snow or hail, funnels water into a two-chamber, pivoting container called a bucket. Precipitation flows through the funnel into one compartment of the bucket until of water (18.5 grams) is accumulated. That amount of weight causes the bucket to tip on its pivots, dumping the collected water and moving the other chamber under the funnel. The tipping motion activates a switch (either a reed switch or a mercury switch), which sends one electrical pulse for each of precipitation collected.\n\nBecause of problems the heated tipping bucket has with properly measuring frozen precipitation (particularly snow), the All Weather Precipitation Accumulation Gauge (AWPAG) was developed. This sensor is essentially a weighing gauge where precipitation continuously accumulates within the collector, and as the weight increases, precipitation is recorded. Only select NWS ASOS units have been equipped with the AWPAG.\n\nAutomated airport weather stations report freezing rain via the resonant frequency of a vibrating rod. The resonant frequency decreases with increasing accretion (additional mass) of ice, hoarfrost, freezing fog, freezing drizzle, rime, or wet snow.\n\nTo report freezing rain, the system combines the sensor output from the freezing rain sensor with data from the LEDWI. The LEDWI must provide a positive indication of unknown precipitation or rain before the system can transmit a report of freezing rain. If the LEDWI reports either no precipitation or snow, the system will ignore the input from the freezing rain sensor. The sensor is designed to detect and report icing from all weather conditions.\n\nMany automated airport weather stations within the United States use the National Lightning Detection Network (NLDN) to detect lightning via the Automatic Lightning Detection and Reporting System (ALDARS). The NLDN uses 106 sensors nationwide to triangulate lightning strikes. Data from the detection grid is fed into ALDARS, which in turn sends messages to each automated airport station informing it of the proximity of any lightning strikes. Lightning strikes within of the station result in a report of a thunderstorm \"at\" the station (TS). Lightning strikes more than but less than from the station result in a report of a thunderstorm \"in the vicinity of\" the station (VCTS). Lightning more than but less than from the station results only in a remark of \"distant lightning\" (LTG DSNT).\n\nHowever, some stations now have their own lightning sensor to actually measure lightning strikes at the site rather than requiring an external service. This thunderstorm sensor works by detecting both the flash of light and momentary change in the electric field produced by lightning. When both of these are detected within a few milliseconds of each other, the station registers a possible lightning strike. When a second possible lightning strike is detected within 15 minutes of the first, the station records a thunderstorm.\n\nData dissemination is usually via an automated VHF airband radio frequency (108-137 MHz) at each airport, broadcasting the automated weather observation. This is often via the Automatic Terminal Information Service (ATIS). Most automated weather stations also have discrete phone numbers to retrieve real-time observations over the phone or through a modem.\n\nIn the United States, the AWOS/ASOS Data Acquisition System (ADAS), a computer system run by the FAA, polls the systems remotely, accessing the observations and disseminating them worldwide electronically in METAR format.\n\nAt present, automated airport weather stations are unable to report a variety of meteorological conditions. These include:\n\nBecause many of these can pose dangers to aircraft and all of these are of interest to the meteorological community, most of the busier airports also have part-time or full-time human observers who augment, or provide additional information to, the automated airport weather station's observations. Research is on-going to allow the automated stations to detect many of these phenomena.\n\nAutomated stations can also suffer from mechanical breakdown, requiring repair or replacement. This can be either due to physical damage (either natural or human caused), mechanical wear, or severe icing during winter weather. During system outages, human observers are often required to supplement missing or non-representative observations from the automated station. Research is also ongoing to produce more robust systems which are less vulnerable to natural damage, mechanical wear and icing.\n\n\n"}
{"id": "11614323", "url": "https://en.wikipedia.org/wiki?curid=11614323", "title": "Beatrice Shilling", "text": "Beatrice Shilling\n\nBeatrice (Tilly) Shilling OBE PhD MSc CEng (8 March 1909 – 18 November 1990) was a British aeronautical engineer and motor racer. During the Second World War, she invented \"Miss Shilling's orifice\", a small metal disc similar to a metal washer that restricted fuel flow to a carburetor. This helped prevent engine stall in the Rolls-Royce Merlin engines of the Hawker Hurricane and Supermarine Spitfire fighters, which could lose power or even completely cut out during certain manoeuvres and pose a significant disadvantage in active service.\n\nShilling raced motorbikes in the 1930s, and raced cars after World War II.\n\nShilling was born at Waterlooville, Hampshire, the daughter of a butcher. At age 14, she bought herself a motorbike, which she tinkered with; she was already determined to become an engineer. After completing secondary school, she worked for an electrical engineering company for three years, installing wiring and generators. Her employer, Margaret Partridge, encouraged her to study electrical engineering at the University of Manchester; she received a bachelor's degree in 1932 and stayed on for a year to get a Master of Science degree in mechanical engineering. Jobs were hard to find in the Depression; she worked as a research assistant for Professor G. F. Mucklow at the University of Birmingham. In 1936 she was recruited as a scientific officer by the Royal Aircraft Establishment (RAE), the research and development agency of the Royal Air Force (RAF) in Farnborough, Hampshire. She worked at Royal Aircraft Establishment until her retirement in 1969.\n\nShilling worked on many projects for RAE during World War II.\n\nDuring the Battle of France and Battle of Britain in 1940, RAF pilots discovered a serious problem in fighter planes with Merlin engines, such as the Hurricane and Spitfire. When the plane went nose-down to begin a dive, the resulting negative g-force would flood the engine's carburettor, causing the engine to stall.\n\nGerman fighters used fuel injection engines and did not have this problem. So in action, a German fighter could evade a pursuing RAF fighter by flying a negative g manoeuvre which the RAF plane could not follow.\n\nShilling devised the R.A.E. restrictor to solve this problem. It was a brass thimble with a hole in the middle (later further refined to a flat washer), which could be fitted into the engine's carburettor without taking the aircraft out of service. The restrictor limited maximum fuel flow and prevented flooding. By March 1941, she had led a small team on a tour of RAF fighter stations, installing the devices in their Merlin engines. The restrictor was immensely popular with pilots, who affectionately named it 'Miss Shilling's orifice' or simply the 'Tilly orifice.' It continued in use as a stop-gap until the introduction of the pressure carburetor in 1943.\n\nAfter the war, Shilling worked on a variety of projects including the Blue Streak missile and the effect of a wet runway upon braking. Shilling was once described by a fellow scientist as \"a flaming pathfinder of Women's Lib\"; she always rejected any suggestion that as a woman she might be inferior to a man in technical and scientific fields. However, her brusque manner and contempt for bureaucracy led to an uneasy relationship with management. Shilling worked for the RAE until 1969, rising to a senior post in the Mechanical Engineering Department.\n\nShe held an honorary doctorate from the University of Surrey, and was a CEng and member of the Institution of Mechanical Engineers and the Women's Engineering Society.\n\nIn the 1930s, Shilling raced motorbikes. She beat professional riders, such as Noel Pope, and was awarded the Gold Star for lapping the Brooklands circuit at on her Norton M30.\n\nAfter World War II, Beatrice and husband George turned to racing cars, which were tuned and modified extensively in their home workshop. Starting off their exploits with a much-lightened Lagonda Rapier, between 1959 and 1962 they raced an Austin-Healey Sebring Sprite, most frequently at Goodwood Members' Meetings, scoring a number of third places and even one race win. George's driving career became more serious with the 1961 acquisition of an Elva 200 Formula Junior single-seater, but there were accidents for both of them, and the Elva was converted into a Mk VI sports car. In 1967 Beatrice Shilling was brought in to help Dan Gurney solve over-heating problems with his Eagle Mk1 Formula 1 racing car.\n\nShilling married George Naylor in September 1938. He also worked at the RAE. According to anecdote, she refused to marry him until he also had been awarded the Brooklands Gold Star for lapping the circuit at over 100 mph. During the Second World War he was a bomber pilot with No. 625 Squadron RAF and reached the rank of Flight Lieutenant. He was awarded the Distinguished Flying Cross (DFC). He volunteered for an extra tour of bombing missions, over and above what was expected of him. He suffered tinnitus and other health problems in later life as a result of his wartime activities.\n\nIn 2011, the Wetherspoons chain of public houses opened a pub in Farnborough named the \"Tilly Shilling\" in her honour, though the nickname 'Tilly' was never used to her face and was probably an unflattering reference to her appearance being overly utilitarian: the wartime 'tillies' were low-powered pick-ups produced by British car manufacturers for use by the armed forces. In 2015, a collection of her racing badges and trophies was bought by the Brooklands Museum.\n\n\n\n"}
{"id": "49141743", "url": "https://en.wikipedia.org/wiki?curid=49141743", "title": "Bâtiment des Forces motrices", "text": "Bâtiment des Forces motrices\n\nThe Bâtiment des Forces motrices (BFM), French for \"Power plant building\", is the power house of a former hydro power plant and waterworks in Geneva called Usine des Forces Motrices, later Usine des Forces Motrices de la Coulouvrenière.\n\nThe structure is positioned near the point where the River Rhône flows out of Lake Geneva towards Lyon. It was created between 1883 and 1892 (and subjected to subsequent improvements) to exploit the flow of the river to provide water pressure to feed the city's water supply and a hydraulic power network. Furthermore, the weir of the structure was designed to regulate the level of the lake. The structure lost its original function as a power source in 1963, but it nevertheless continued to house pumping equipment to service Geneva's drinking water supply till 1988. The weir of the power plant was used some more years till it was taken over by the in 1995, which is located approximately fifty meters downstream from the BFM. Towards the end of the twentieth century the BFM was converted into an entertainment venue, reopening in 1997 as an opera house / concert hall designed by the architect Bernard Picenni in association with the acoustician Peutz and the scenographer dUCKS scéno.\n\nAt the time when the project was defined as a \"power plant\" there was no automatic correlation between a \"power plant\" and a public electricity supply. The idea in 1882 was to feed power in the form of pressurized water to local manufacturing businesses, who could use it to operate their own powered machinery, which might indeed include generators. Another objective involved using the pumped water to feed the reservoirs of the public drinking water supply. However, in 1887 electricity generation started in a building nearby the BFM, where generators were driven by pressurized water supplied from the BFM. The hydraulic power network needed a pressure valve to avoid the damage from excessive pressure within the network which was located beside the BFM and which was the precursor to Geneva's Jet d'Eau (fountain).\n\nBy 1880 it had become clear that the existing hydraulic structure, sited at the city's , was no longer sufficient for Geneva's growing needs, despite a succession of upgrades since the installation of the first structure back in 1709. The cantonal authorities therefore granted to the city a concession for exploitation of the \"motor power\" (in French \"forces motrice\") of the Rhône on 30 December 1882. The city committed to construct a new \"hydraulic factory\" (in French \"usine hydraulique\") which would provide drinking water to the city and energy in the form of pressurized water for the operation of machinery. At the same time they embarked on the work necessary to regulate the level of Lake Geneva, notably by construction of a curtain weir across the river.\n\nThe project as originally envisaged involved building the Bâtiment des Forces motrices on land administered by the then separate municipality of Plainpalais (later subsumed into Geneva) which was in financial difficulties. The therefore entered into negotiations to move the district frontiers in order to bring the proposed site within the Geneva city boundary. Plainpalais rejected the idea, however. It was therefore decided to reposition the site for the new building to an artificial island positioned in the middle of the river, after it had been agreed in 1882 that the river bed itself was part of Geneva. The river was divided into two parallel channels, called respectively the \"Canal d'alimentation\" (\"Supply [of public drinking and fountain water] channel\") on the left side and the \"Canal de régulation\" (\"Regulation [of the water level] channel\") on the right side. On the initiative of Jean-Daniel Colladon, the civil engineer Théodore Turrettini now embarked on a parallel career as a local politician, when he was elected to the . He went on to head up the construction project with energy and imagination.\n\nBefore 1882 the level of the lake surface varied with the seasons, rising to it highest level at the end of the winter when the snows melted and the lake was filled by streams and torrents from the surrounding mountains. Work on the structure began in November 1893, when the level of the lake and the flow of water through it was expected to remain relatively low for the next five to six months. Along the part of the river where the powerhouse was built the river was separated into two parallel channels and these were drained successively in order to permit the construction of the building, the hydraulic structures and of a curtain weir attached to the located a few hundred meters upstream.\n\nFive Jonval turbines were installed in the small wing of the powerhouse crossing the river and commissioned in May 1886, producing a combined power of 900 kW. Two of the turbines supplied water pressure to what is today the city's old town, and the other three supplied surrounding districts, some of them as far as away. The pressurized water network served, primarily, small businesses including, notably, clock and watchmakers.\n\nIn 1892 the larger main turbine hall was ready, with space for a further 15 turbines which were installed progressively over the next few years except the last two. The last of them was installed in 1897, by which time the full complement of 18 turbines was providing 3.3 MW of power.\n\nThe curtain weir was attached to the superstructure of the Pont de la Machine bridging the right arm of the river Rhône. The old superstructure was replaced during the construction of the power plant by a new superstructure for pedestrian use made from puddled iron. The chosen building material was strong enough to support the additional lateral forces introduced by the curtain weir into the structure. The curtain weir consisted of 39 single roller blinds made from larch wood. It was able to dam the Rhône to a height of maximal 3.3 meters.\n\nThe neo-classical powerhouse sat on an L-shaped floor plan, with the main hall aligned along the length of the river and a shorter hall connecting the main hall with the river bank at the western end of the building. The natural stone cladded concrete structure has large round arched glazed windows. The roof was supported by an iron truss structure without roof support pillars or dividing walls inside the building in a way that a vast open unencumbered space for the machinery inside the powerhouse was provided. The interior of the turbine hall was decorated in the flamboyant Beaux-Arts style fashionable at the time. Only the upper facade on the eastern end, facing the lake, reflected the extrovert decorated style of the interior, supplemented at the time by statues representing Neptune, Ceres and Mercury.\n\nIn order to avoid excessive pressure build-up in the hydraulic power network, a release valve was fitted beside the main hall of the powerhouse. A tall water fountain, the Jet d'Eau, was ejected by the device whenever it was activated. This happened typically at end of work when the factories switched off the machines one at the time, so that the pressure in the system was hard to control and the supply of pressurized water was difficult to adapt to the real demand. The tall fountain was visible from a long distance and became the landmark of the city. In 1891 it was moved to the current location in the lake where it is operated for the sole purpose of a tourist attraction without any other function.\n\nEscher Wyss & Cie. of Zurich delivered the Jonval turbines designed for submerged operation. They were capable to process a total runoff of 600–800 m³/s at a drop height of 2 to 4 m. Each had a maximal power of 210 hp. The three concentric arranged blade rings allowed to adjust the power of the turbine to the available drop height and the actual demand. The control was done by partially covering the guide vanes of the turbine.\n\nEach turbine powered two double-acting piston pumps in a lying V-configuration located in the hall of the powerhouse. The two pumps shared a vertical arranged common hydraulic accumulator.\n\nIn the 1960s the Jonval turbines were one by one replaced by Kaplan turbines.\n\nThe distribution network used three different pressure levels. The lowest pressure level served for the drinking water supply, the intermediate and the high pressure level served as hydraulic power network. The intermediate pressure level had an operating pressure of 6.5 bar and was reached 1896 a length of 82 km. It was used for powering 130 water engines type Schmid with a gross power of 230 hp. The high pressure network had an operating pressure of 14 bar and reached an extension of 93 km. It was used to power 207 turbines and motors, as well as elevator drives. The gross power was 3000 hp.\n\nMany turbines were used for driving generators for electric lighting. In 1887 an electricity generation plant was built next to the powerhouse, which generated 110 V DC with a maximal power of 800 hp and an AC network with a maximal power of 600 hp. The generators were driven by a water turbine supplied from the hydraulic power network.\n\nThe hydraulic power network was not in competition with the electric power supply, but was more considered a supplement to the electric power supply. Only during the economic crisis of the 1930s, the demand of pressurized water as energy supply declined. The last water engine was decommissioned in 1958.\n\nThe Le Bâtiment des Forces motrices lost its principal original functions during the 1960s, as manufacturing industry moved out to the edge of the city. It was classified as a historic monument in 1988, and then as a cultural asset of national importance. Meanwhile, various avenues were explored to find a new use for the building. After various meetings with the responsible city department, and thanks to the generosity of a locally based benefactor, the decision was taken to adapt the main building as a 1,000 seat auditorium suitable for theatrical uses. The buildings should be able to host productions from the city's Grand Theatre for a year, during that buildings major renovation of 1997/98, following which the Bâtiment des Forces motrices should continue to be available for theatrical events and other entertainment spectacles. Regarding the BFM's original functions, just two small pumps would be left in the side wing.\n\nThe conversion was based on plans drawn up by the Geneva-based architect Bernard Picenni The side wing linking to the left (south) bank of the Rhône was converted into a reception area, while the main turbine hall became the main theatre. The theatre, opened in September 1997, was constructed entirely of wood. It provided 801 seats in the main area and a further 144 on the balcony/gallery.\n\nIn December 1997 a pedestrian walkway was set up against the northern and western faces of the building, establishing a connection between the Promenade des Lavandières (the unbuilt strip of land to the east of the BFM and between the two channels of the Rhône) and the Place des Volontaires (\"le Place des Volontaires\" - on the bank of the river at the southern end of the side wing that connects the main turbine hall with the shore). At the Place des Volontaires is a small cultural centre associated with the BFM. Construction of the walkway used the piles and supports originally created for the inspection walkway along the outside of the turbine hall, below the windows on its side.\n"}
{"id": "224148", "url": "https://en.wikipedia.org/wiki?curid=224148", "title": "Cinerama", "text": "Cinerama\n\nCinerama is a widescreen process that originally projected images simultaneously from three synchronized 35 mm projectors onto a huge, deeply curved screen, subtending 146° of arc. The trademarked process was marketed by the Cinerama corporation. It was the first of a number of novel processes introduced during the 1950s, when the movie industry was reacting to competition from television. Cinerama was presented to the public as a theatrical event, with reserved seating and printed programs, and audience members often dressed in their best attire for the evening.\n\nThe Cinerama projection screen, rather than being a continuous surface like most screens, is made of hundreds of individual vertical strips of standard perforated screen material, each about  inch (~22 mm) wide, with each strip angled to face the audience, so as to prevent light scattered from one end of the deeply curved screen from reflecting across the screen and washing out the image on the opposite end. The display is accompanied by a high-quality, seven-track discrete, directional, surround-sound system.\n\nThe original system involved shooting with three synchronized cameras sharing a single shutter. This process was later abandoned in favor of a system using a single camera and 70mm prints. The latter system lost the 146° field of view of the original three-strip system, and its resolution was markedly lower. Three-strip Cinerama did not use anamorphic lenses, although two of the systems used to produce the 70mm prints (Ultra Panavision 70 and Super Technirama 70) \"did\" employ anamorphics. Later, 35mm anamorphic reduction prints were produced for exhibition in theatres with anamorphic CinemaScope-compatible projection lenses.\n\nCinerama was invented by Fred Waller (1886–1954) and languished in the laboratory for several years before Waller, joined by Hazard \"Buzz \" Reeves, brought it to the attention of Lowell Thomas who, first with Mike Todd and later Merian C. Cooper, produced a commercially viable demonstration of Cinerama which opened on Broadway on September 30, 1952. The film, titled \"This is Cinerama,\" was received with enthusiasm. It was the outgrowth of many years of development. A forerunner was the triple-screen final sequence in the silent \"Napoléon\" (1927) directed by Abel Gance; Gance's classic was considered lost in the 1950s, however, known of only by hearsay, and Waller could not have actually seen it. Waller had earlier developed an 11-projector system called \"Vitarama\" at the Petroleum Industry exhibit in the 1939 New York World's Fair. A five-camera version, the Waller Gunnery Trainer, was used during the Second World War.\n\nThe word \"Cinerama\" combines \"cinema\" with \"panorama\", the origin of all the \"-orama\" neologisms (the word \"panorama\" comes from the Greek words \"pan\", meaning \"all\", and \"orama\", which translates into \"that which is seen\", a \"sight\", or a \"spectacle\"). It has been suggested that \"Cinerama\" could have been an intentional anagram of the word \"American;\" but an online posting by Dick Babish, describing the meeting at which it was named, says that this is \"purely accidental, however delightful.\"\n\nThe photographic system used three interlocked 35 mm cameras equipped with 27 mm lenses, approximately the focal length of the human eye. Each camera photographed one third of the picture shooting in a crisscross pattern, the right camera shooting the left part of the image, the left camera shooting the right part of the image and the center camera shooting straight ahead. The three cameras were mounted as one unit, set at 48 degrees to each other. A single rotating shutter in front of the three lenses assured simultaneous exposure on each of the films. The three angled cameras photographed an image that was not only three times as wide as a standard film but covered 146 degrees of arc, close to the human field of vision, including peripheral vision. The image was photographed six sprocket holes high, rather than the usual four used in conventional 35 mm processes. The picture was photographed and projected at 26 frames per second rather than the usual 24.\n\nAccording to film historian Martin Hart, in the original Cinerama system \"the camera aspect ratio [was] 2.59:1\" with an \"optimum screen image, with no architectural constraints, [of] about 2.65:1, with the extreme top and bottom cropped slightly to hide anomalies\". He further comments on the unreliability of \"numerous websites and other resources that will tell you that Cinerama had an aspect ratio of up to 3:1.\"\n\nIn theaters, Cinerama film was projected from three projection booths arranged in the same crisscross pattern as the cameras. They projected onto a deeply curved screen, the outer thirds of which were made of over 1100 strips of material mounted on \"louvers\" like a vertical venetian blind, to prevent light projected to each end of the screen from reflecting to the opposite end and washing out the image. This was a big-ticket, reserved-seats spectacle, and the Cinerama projectors were adjusted carefully and operated skillfully. To prevent adjacent images from creating an overilluminated vertical band where they overlapped on the screen, vibrating combs in the projectors, called \"jiggolos,\" alternately blocked the image from one projector and then the other; the overlapping area thus received no more total illumination than the rest of the screen, and the rapidly alternating images within the overlap smoothed out the visual transition between adjacent image \"panels.\" Great care was taken to match color and brightness when producing the prints. Nevertheless, the seams between panels were usually noticeable. Optical limitations with the design of the camera itself meant that if distant scenes joined perfectly, closer objects did not (parallax error). A nearby object might split into two as it crossed the seams. To avoid calling attention to the seams, scenes were often composed with unimportant objects such as trees or posts at the seams, and action was blocked so as to center actors within panels. This gave a distinctly \"triptych-like\" appearance to the composition even when the seams themselves were not obvious. It was often necessary to have actors in different sections \"cheat\" where they looked in order to appear to be looking at each other in the final projected picture. Enthusiasts say the seams were not obtrusive; detractors disagree. Lowell Thomas, an investor in the company with Mike Todd, was still raving about the process in his memoirs thirty years later.\n\nIn addition to the visual impact of the image, Cinerama was one of the first processes to use multitrack magnetic sound. The system, developed by Hazard E. Reeves, one of the Cinerama investors, played back from a full coated 35 mm magnetic film with seven tracks of sound targeting a speaker layout similar to the more modern SDDS. There were five speakers behind the screen, two on the side and back of the auditorium with a sound engineer directing the sound between the surround speakers according to a script. The projectors and sound system were synchronized by a system using selsyn motors.\n\nThe Cinerama system had some obvious drawbacks. If one of the films should break, it had to be repaired with a black slug exactly equal to the missing footage. Otherwise, the corresponding frames would have had to be cut from the other three films (the other two picture films plus the soundtrack film) in order to preserve synchronization. The use of zoom lenses was impossible since the three images would no longer match. Perhaps the greatest limitation of the process is that the picture looks natural only from within a rather limited \"sweet spot.\" Viewed from outside the sweet spot, the picture can look distorted.\n\nThe system also required a bit of improvisation on the part of the film producers. It was not possible to film any scene where any part of the scene was close to the camera, as the fields of view no longer met exactly. Further, any close-up material had a noticeable bend in it at the joins. It was also difficult to film actors talking to each other where both were in shot, because when they looked at each other when filmed, the resultant image showed the actors appearing to look past each other, particularly if they appeared on different films. Early directors sidestepped this latter problem by only shooting one actor at a time and cutting between them. Later directors worked out where to have the actors looking to create a natural shot. Each actor was required not to look at his fellow actor, but at a cue placed where he needed to look.\n\nFinally, the three individual films would jitter and weave slightly as the films moved through the projectors. This normal frame-to-frame movement is typically imperceptible to cinema audiences where only a single projector is in use. However, in Cinerama, this resulted in the center picture constantly moving slightly relative to each of the side pictures. The shifting displacements were perceivable at the two points where the center picture met the side pictures, resulting in what appeared to many viewers to be jittering vertical lines at one-third and two-thirds of the way across the screen as the two touching images constantly moved around relative to each other. Cinerama projectors used a device to slightly blur the join lines to make the jitter less noticeable. Future systems such as Circle-Vision 360° would correct for this by having masked areas between the screens. The jitters continued, but viewers were less aware of them with the adjoining pictures no longer so close together.\n\nThe impact these films had on the big screen cannot be assessed from television or video, or even from 'scope prints, which marry the three images together with the seams clearly visible. Because they were designed to be seen on a curved screen, the geometry looks distorted on television; someone walking from left to right appears to approach the camera at an angle, move away at an angle, and then repeat the process on the other side of the screen.\n\nThe first Cinerama film, \"This Is Cinerama\", premiered on September 30, 1952, at the Broadway Theatre in New York. \"The New York Times\" judged it to be front-page news. Notables attending included: New York Governor Thomas E. Dewey; violinist Fritz Kreisler; James A. Farley; Metropolitan Opera manager Rudolf Bing; NBC chairman David Sarnoff; CBS chairman William S. Paley; Broadway composer Richard Rodgers; and Hollywood mogul Louis B. Mayer.\n\nWriting in \"The New York Times\" a few days after the system premiered, film critic Bosley Crowther wrote:\n\nWhile observing that the system \"may be hailed as providing a new and valid entertainment thrill,\" Crowther expressed some skeptical reserve, saying \"the very size and sweep of the Cinerama screen would seem to render it impractical for the story-telling techniques now employed in film... It is hard to see how Cinerama can be employed for intimacy. But artists found ways to use the movie. They may well give us something brand-new here.\"\n\nA technical review by Waldemar Kaempffert published in \"The New York Times\" on the same day hailed the system. He praised the stereophonic sound system and noted that \"the fidelity of the sounds was irreproachable. Applause in La Scala sounded like the clapping of hands and not like pieces of wood slapped together\". He noted, however that \"There is nothing new about these stereophonic sound effects. The Bell Telephone Laboratories and Prof. Harold Burris-Meyer of Stevens Institute of Technology demonstrated the underlying principles years ago.\" Kaempfert also noted:\n\nAlthough existing theatres were adapted to show Cinerama films, in 1961 and 1962 the non-profit Cooper Foundation of Lincoln, Nebraska, designed and built three near-identical circular \"super-Cinerama\" theaters in Denver, Colorado; St. Louis Park, Minnesota (a Minneapolis suburb); and Omaha, Nebraska. They were considered the finest venues to view Cinerama films. The theaters were designed by architect Richard L. Crowther of Denver, a Fellow of the American Institute of Architects.\n\nThe first such theater, the Cooper Theater, built in Denver, featured a 146-degree louvered screen (measuring 105 feet by 35 feet), 814 seats, courtesy lounges on the sides of the theatre for relaxation during intermission (including concessions and smoking facilities), and a ceiling which routed air and heating through small vent slots in order to inhibit noise from the building's ventilation equipment. It was demolished in 1994 to make way for a Barnes & Noble bookstore.\n\nThe second, also called the Cooper Theater, was built in St. Louis Park at 5755 Wayzata Blvd. The last film presented there was \"Dances with Wolves\" in January, 1991, and at that time the Cooper was considered the \"flagship\" in the Plitt theatre chain. Efforts were made to preserve the theatre, but at the time it did not qualify for national or state historical landmark status (as it was not more than fifty years old) nor were there local preservation laws. It was torn down in 1992. An office complex with a TGI Friday's on the west end of the property is there today.\n\nThe third super-Cinerama, the Indian Hills Theater, was built in Omaha, Nebraska. The Indian Hills theater closed on September 28, 2000 as a result of the bankruptcy of Carmike Cinemas, and the final film presented was the rap music-drama \"Turn It Up.\" The theater was demolished on August 20, 2001.\n\nA fourth, the Kachina Cinerama Theater, was built in Scottsdale, Arizona by Harry L. Nace Theatres on Scottsdale Road and opened on November 10, 1960. It seated 600 people. It later became a Harkins theater, then closed in 1989 to make way for the Scottsdale Galleria.\n\nVenues outside the USA included the Regent Plaza cinema in Melbourne, Australia, which was adapted for Cinerama in 1960 to show \"This is Cinerama\" and \"Seven Wonders of the World\". The Imperial Theatre in Montreal and the Glendale in Toronto were the Canadian homes for Cinerama.\n\"This is Cinerama\" received its London premiere on 30 September 1954 at the Casino Cinerama Theatre, Old Compton Street, formerly a live theatre. The film ran for 16 months and was followed by the other three strip travelogues. \"How the West Was Won\" had its World Premiere at the Casino on 1 November 1962 and ran until April 1965 after which the Casino switched to 70mm single lens Cinerama. London had two other three strip venues, making it the only city in the world with three Cinerama theatres. These were the Coliseum Cinerama, from July 1963 and the Royalty Cinerama from November 1963, like the Casino both converted live venues. The Coliseum played only one film in three strip (\"The Wonderful World of the Brothers Grimm\") before switching to 70mm single lens from December 1963, and the Royalty had two runs of Brothers Grimm separated by a run of \"The Best of Cinerama\" before also switching to 70mm single lens in mid 1964. These London venues were directly operated by Cinerama themselves, elsewhere in the UK three strip Cinerama venues were operated by the two main UK circuits, ABC at ABC Bristol Road, Birmingham and Coliseum, Glasgow, Rank at Gaumont, Birmingham and Queens, Newcastle and by independents at the Park Hall, Cardiff, Theatre Royal, Manchester and Abbey, Liverpool. Most of these conversions of existing cinemas came just as Cinerama was switching to single lens and thus had short lives as three strip venues before switching to 70mm.\n\nRoman Cinerama Theater (now Isetann Cinerama Recto) at Quezon Boulevard in Recto, Manila and Nation Cinerama Theater in Araneta Center, Quezon City were the only Cinerama theaters built in the Philippines in the 1960s. Both theaters are now defunct as Roman Super Cinerama burned down in the late 1970s and became Isetann Cinerama Recto in 1988 while Nation Cinerama closed down in the early 1970s it is now Manhattan Parkview Residences built by Megaworld Corporation.\n\nThe last Cinerama theater built was the Southcenter Theatre in 1970, opening near the Southcenter Mall of Tukwila, Washington. It closed in 2001.\n\nCinerama also purchased RKO-Stanley Warner (consisting of theaters formerly owned by Warner Bros. and RKO Pictures) in 1970.\n\nRising costs of making three-camera widescreen films caused Cinerama to stop making such films in their original form shortly after the first release of \"How the West Was Won\". The use of Ultra Panavision 70 for certain scenes (such as the river raft sequence) later printed onto the three Cinerama panels, proved that a more or less satisfactory wide screen image could be photographed without the three cameras. Consequently, Cinerama discontinued the three film process, with the exception of a single theater (McVickers' Cinerama Theatre in Chicago) showing \"Cinerama's Russian Adventure\", an American-Soviet co-production culled from footage of several Soviet films shot in the rival Soviet three-film format known as Kinopanorama in 1966.\n\nCinerama continued through the rest of the 1960s as a brand name used initially with the Ultra Panavision 70 widescreen process (which yielded a similar 2.76 aspect ratio to the original Cinerama, although it did not simulate the 146 degree field of view.) Optically \"rectified\" prints and special lenses were used to project the 70 mm prints onto the curved screen. The films shot in Ultra Panavision for single lens Cinerama presentation were \"It's a Mad, Mad, Mad, Mad World\" (1963), \"Battle of the Bulge\" (1965), \"The Greatest Story Ever Told\" (1965), \"The Hallelujah Trail\" (1965) and \"Khartoum\" (1966).\n\nThe less wide but still spectacular Super Panavision 70 was used to film the Cinerama presentations \"Grand Prix\" (1966); \"\" (1968), which also featured scenes shot in Todd-AO and MCS-70); \"Ice Station Zebra\" (1968); and \"Krakatoa, East of Java\" (1969), which also featured scenes shot in Todd-AO.\n\nThe other 70mm systems used for single film Cinerama (Sovscope 70 and MCS-70) were similar to Super Panavision 70. Some films were shot in the somewhat lower resolution Super Technirama 70 process for Cinerama release, including \"Circus World\" (1964) and \"Custer of the West\" (1967).\n\nIn the late 1960s and early 1970s, the Cinerama name was used as a film distribution company, ironically reissuing single strip 70 mm and 35 mm Cinemascope reduction prints of \"This Is Cinerama\" (1972).\n\nThe Cinerama company exists today as an entity of the Pacific Theatres chain. In recent years, surviving and new Cinerama prints have been screened at the following venues:\nIn 1998, Microsoft co-founder Paul Allen purchased Seattle's Martin Cinerama, which then underwent a major restoration/upgrade to become the Seattle Cinerama.\n\nAs of 2015, the Pictureville Cinema, Seattle Cinerama, and Cinerama Dome continue to hold periodic screenings of three-projector Cinerama movies. The Cinerama Dome was designed for the three-projector system but never actually had it installed until recent years as it opened with the first of the single film 70 mm Cinerama films, \"It's a Mad, Mad, Mad, Mad World\" (1963).\n\nThe documentary, \"Cinerama Adventure\" (2003) looked at the history of the Cinerama process, as well as digitally recreating the Cinerama experience via clips of true Cinerama films (using transfers from original Cinerama prints). And Turner Entertainment (via Warner Bros.) has struck new Cinerama prints of \"How the West Was Won\" (1962) for exhibition in true Cinerama theatres around the world.\n\nCinerama successors, Todd-AO, CinemaScope, and the various 70 mm formats, all attempted to equal or surpass its grandeur while avoiding its problems to greater or lesser degrees of success. In movie theaters today the large format IMAX system continues the tradition, although the screen is taller and often less wide.\n\nIn 2008, a Blu-ray disc of \"How The West Was Won\" was released, offering a recreation of Cinerama for home viewing. The three Cinerama images were digitally stitched together so that the resulting image does not have the visible seams of older copies. Furthermore, as a second viewing option, 3D mapping technology was used to produce an image that approximates the curved screen, called \"SmileBox\".\n\nOn January 14, 2012, an original Cinerama camera was used to film a sequence at the Lasky-DeMille Barn, the original home to Famous Players-Lasky, later to be renamed Paramount Pictures. This was the first film photographed in the Cinerama process in almost 50 years. This sequence is part of a new 12-minute production filmed entirely in the three panel process. The new film, \"In the Picture\", was presented at a Cinerama festival at the Cinerama Dome in Hollywood, California on September 30, 2012.\n\nAll but two of the feature-length films produced using the original three-strip Cinerama process were travelogues or episodic documentaries such as \"This Is Cinerama\" (1952), the first film shot in Cinerama. Other travelogues presented in Cinerama were \"Cinerama Holiday\" (1955), \"Seven Wonders of the World\" (1955), \"Search for Paradise\" (1957) and \"South Seas Adventure\" (1958). There was also one commercial short, \"Renault Dauphine\" (1960).\n\nEven as the Cinerama travelogues were beginning to lose audiences in the late 50s, the spectacular travelogue \"Windjammer\" (1958) was released in a competing process called Cinemiracle which claimed to have less noticeable dividing lines on the screen thanks to the reflection of the side images off of mirrors (this also allowed all three projectors to be in the same booth). Due to the small number of Cinemiracle theatres, specially converted prints of \"Windjammer\" were shown in Cinerama theaters in cities which did not have Cinemiracle theaters, and ultimately Cinerama bought up the process.\n\nOnly two films with traditional story lines were made, \"The Wonderful World of the Brothers Grimm\" and \"How the West Was Won\". In order to make these films compatible with single film systems for later standard releases, they were shot at 24 frames/s, not the 26 frames/s of traditional Cinerama.\n\nThe following feature films have been advertised as being presented \"in Cinerama\":\n\nRCA uses the word \"Cinerama\" to refer to a display mode which fills a 16:9 video screen with 4:3 video with, in the words of the manufacturer, \"little distortion.\" Manuals for products offering this mode give no detailed explanation. One online posting says it consists of \"a slight cropping at the top & bottom combined with a slight stretch at only the sides,\" and praises it. The posting suggests that other vendors provide a similar function under different names. Mitsubishi calls it \"stretch\" mode. The RCA Scenium TV also has a \"stretch mode\" as well it is a 4:3 picture stretched straight across.\n\nThere is no obvious connection between this video mode and any of the Cinerama motion picture processes. It is not clear why the name is used, unless the nonlinear stretch is vaguely evocative of a curved screen. (Ironically, some widescreen cinema processes—not Cinerama—displayed a fault known as \"anamorphic mumps,\" which consisted of a lateral stretch of objects closer to the camera).\n\nIn the U.S., RCA does not appear to have registered the word \"Cinerama\" as a trademark; conversely, a number of trademarks on \"Cinerama,\" e.g. SN 74270575, are still \"live\" and held by Cinerama, Inc.\n\n\n"}
{"id": "39316", "url": "https://en.wikipedia.org/wiki?curid=39316", "title": "Compass", "text": "Compass\n\nA compass is an instrument used for navigation and orientation that shows direction relative to the geographic cardinal directions (or points). Usually, a diagram called a compass rose shows the directions north, south, east, and west on the compass face as abbreviated initials. When the compass is used, the rose can be aligned with the corresponding geographic directions; for example, the \"N\" mark on the rose points northward. Compasses often display markings for angles in degrees in addition to (or sometimes instead of) the rose. North corresponds to 0°, and the angles increase clockwise, so east is 90° degrees, south is 180°, and west is 270°. These numbers allow the compass to show azimuths or bearings, which are commonly stated in this notation.\n\nAmong the Four Great Inventions, the magnetic compass was first invented as a device for divination as early as the Chinese Han Dynasty (since c. 206 BC), and later adopted for navigation by the Song Dynasty Chinese during the 11th century. The first usage of a compass recorded in Western Europe and the Islamic world occurred around 1190.\n\nThe magnetic compass is the most familiar compass type. It functions as a pointer to \"magnetic north\", the local magnetic meridian, because the magnetized needle at its heart aligns itself with the horizontal component of the Earth's magnetic field. The magnetic field exerts a torque on the needle, pulling the North end or \"pole\" of the needle approximately toward the Earth's North magnetic pole, and pulling the other toward the Earth's South magnetic pole. The needle is mounted on a low-friction pivot point, in better compasses a jewel bearing, so it can turn easily. When the compass is held level, the needle turns until, after a few seconds to allow oscillations to die out, it settles into its equilibrium orientation.\n\nIn navigation, directions on maps are usually expressed with reference to geographical or true north, the direction toward the Geographical North Pole, the rotation axis of the Earth. Depending on where the compass is located on the surface of the Earth the angle between true north and magnetic north, called magnetic declination can vary widely with geographic location. The local magnetic declination is given on most maps, to allow the map to be oriented with a compass parallel to true north. The location of the Earth's magnetic poles slowly change with time, which is referred to as geomagnetic secular variation. The effect of this means a map with the latest declination information should be used. Some magnetic compasses include means to manually compensate for the magnetic declination, so that the compass shows true directions.\n\nThere are other ways to find north than the use of magnetism, and from a navigational point of view a total of seven possible ways exist (where magnetism is one of the seven). Two sensors that utilize two of the remaining six principles are often also called compasses, i.e. gyrocompass and GPS-compass.\n\nA \"gyrocompass\" is similar to a gyroscope. It is a non-magnetic compass that finds true north by using an (electrically powered) fast-spinning wheel and friction forces in order to exploit the rotation of the Earth. Gyrocompasses are widely used on ships. They have two main advantages over magnetic compasses:\n\nLarge ships typically rely on a gyrocompass, using the magnetic compass only as a backup. Increasingly, electronic fluxgate compasses are used on smaller vessels. However, magnetic compasses are still widely in use as they can be small, use simple reliable technology, are comparatively cheap, are often easier to use than GPS, require no energy supply, and unlike GPS, are not affected by objects, e.g. trees, that can block the reception of electronic signals.\n\nGPS receivers using two or more antennae mounted separately and blending the data with an inertial motion unit (IMU) can now achieve 0.02° in heading accuracy and have startup times in seconds rather than hours for gyrocompass systems. The devices accurately determine the positions (latitudes, longitudes and altitude) of the antennae on the Earth, from which the cardinal directions can be calculated. Manufactured primarily for maritime and aviation applications, they can also detect pitch and roll of ships. Small, portable GPS receivers with only a single antenna can also determine directions if they are being moved, even if only at walking pace. By accurately determining its position on the Earth at times a few seconds apart, the device can calculate its speed and the true bearing (relative to \"true north\") of its direction of motion. Frequently, it is preferable to measure the direction in which a vehicle is actually moving, rather than its heading, i.e. the direction in which its nose is pointing. These directions may be different if there is a crosswind or tidal current.\n\nGPS compasses share the main advantages of gyrocompasses. They determine true North, as opposed to magnetic North, and they are unaffected by perturbations of the Earth's magnetic field. Additionally, compared with gyrocompasses, they are much cheaper, they work better in polar regions, they are less prone to be affected by mechanical vibration, and they can be initialized far more quickly. However, they depend on the functioning of, and communication with, the GPS satellites, which might be disrupted by an electronic attack or by the effects of a severe solar storm. Gyrocompasses remain in use for military purposes (especially in submarines, where magnetic and GPS compasses are useless), but have been largely superseded by GPS compasses, with magnetic backups, in civilian contexts.\n\nThe first compasses in ancient Han dynasty China were made of lodestone, a naturally magnetized ore of iron. The compass was later used for navigation during the Song Dynasty of the 11th century. Later compasses were made of iron needles, magnetized by striking them with a lodestone. Dry compasses began to appear around 1300 in Medieval Europe and the Islamic world. This was supplanted in the early 20th century by the liquid-filled magnetic compass.\n\nModern compasses usually use a magnetized needle or dial inside a capsule completely filled with a liquid (lamp oil, mineral oil, white spirits, purified kerosene, or ethyl alcohol are common). While older designs commonly incorporated a flexible rubber diaphragm or airspace inside the capsule to allow for volume changes caused by temperature or altitude, some modern liquid compasses utilize smaller housings and/or flexible capsule materials to accomplish the same result. The liquid inside the capsule serves to damp the movement of the needle, reducing oscillation time and increasing stability. Key points on the compass, including the north end of the needle are often marked with phosphorescent, photoluminescent, or self-luminous materials to enable the compass to be read at night or in poor light. As the compass fill liquid is noncompressible under pressure, many ordinary liquid-filled compasses will operate accurately underwater to considerable depths.\n\nMany modern compasses incorporate a baseplate and protractor tool, and are referred to variously as \"orienteering\", \"baseplate\", \"map compass\" or \"protractor\" designs. This type of compass uses a separate magnetized needle inside a rotating capsule, an orienting \"box\" or gate for aligning the needle with magnetic north, a transparent base containing map orienting lines, and a bezel (outer dial) marked in degrees or other units of angular measurement. The capsule is mounted in a transparent baseplate containing a \"direction-of-travel\" (DOT) indicator for use in taking bearings directly from a map.\nOther features found on modern orienteering compasses are map and romer scales for measuring distances and plotting positions on maps, luminous markings on the face or bezels, various sighting mechanisms (mirror, prism, etc.) for taking bearings of distant objects with greater precision, gimbal-mounted, \"global\" needles for use in differing hemispheres, special rare-earth magnets to stabilize compass needles, adjustable declination for obtaining instant true bearings without resorting to arithmetic, and devices such as inclinometers for measuring gradients. The sport of orienteering has also resulted in the development of models with extremely fast-settling and stable needles utilizing rare-earth magnets for optimal use with a topographic map, a land navigation technique known as \"terrain association\".\n\nThe military forces of a few nations, notably the United States Army, continue to issue field compasses with magnetized compass dials or cards instead of needles. A magnetic card compass is usually equipped with an optical, lensatic, or prismatic sight, which allows the user to read the bearing or azimuth off the compass card while simultaneously aligning the compass with the objective (see photo). Magnetic card compass designs normally require a separate protractor tool in order to take bearings directly from a map.\n\nThe U.S. M-1950 military lensatic compass does not use a liquid-filled capsule as a damping mechanism, but rather electromagnetic induction to control oscillation of its magnetized card. A \"deep-well\" design is used to allow the compass to be used globally with a card tilt of up to 8 degrees without impairing accuracy. As induction forces provide less damping than fluid-filled designs, a needle lock is fitted to the compass to reduce wear, operated by the folding action of the rear sight/lens holder. The use of air-filled induction compasses has declined over the years, as they may become inoperative or inaccurate in freezing temperatures or extremely humid environments due to condensation or water ingress.\n\nSome military compasses, like the U.S. M-1950 (Cammenga 3H) military lensatic compass, the Silva 4b \"Militaire\", and the Suunto M-5N(T) contain the radioactive material tritium () and a combination of phosphors. The U.S. M-1950 equipped with self-luminous lighting contains 120 mCi (millicuries) of tritium. The purpose of the tritium and phosphors is to provide illumination for the compass, via radioluminescent tritium illumination, which does not require the compass to be \"recharged\" by sunlight or artificial light. However, tritium has a half-life of only about 12 years, so a compass that contains 120 mCi of tritium when new will contain only 60 when it is 12 years old, 30 when it is 24 years old, and so on. Consequently, the illumination of the display will fade.\n\nMariners' compasses can have two or more magnets permanently attached to a compass card, which moves freely on a pivot. A \"lubber line\", which can be a marking on the compass bowl or a small fixed needle, indicates the ship's heading on the compass card. Traditionally the card is divided into thirty-two points (known as \"rhumbs\"), although modern compasses are marked in degrees rather than cardinal points. The glass-covered box (or bowl) contains a suspended gimbal within a binnacle. This preserves the horizontal position.\n\nA thumb compass is a type of compass commonly used in orienteering, a sport in which map reading and terrain association are paramount. Consequently, most thumb compasses have minimal or no degree markings at all, and are normally used only to orient the map to magnetic north. An oversized rectangular needle or north indicator aids visibility. Thumb compasses are also often transparent so that an orienteer can hold a map in the hand with the compass and see the map through the compass. The best models use rare-earth magnets to reduce needle settling time to 1 second or less.\n\nSmall compasses found in clocks, mobile phones, and other electronic devices are solid-state microelectromechanical systems (MEMS) compasses, usually built out of two or three magnetic field sensors that provide data for a microprocessor. Often, the device is a discrete component which outputs either a digital or analog signal proportional to its orientation. This signal is interpreted by a controller or microprocessor and either used internally, or sent to a display unit. The sensor uses highly calibrated internal electronics to measure the response of the device to the Earth's magnetic field.\n\nApart from navigational compasses, other specialty compasses have also been designed to accommodate specific uses. These include:\n\nThe magnetic compass is very reliable at moderate latitudes, but in geographic regions near the Earth's magnetic poles it becomes unusable. As the compass is moved closer to one of the magnetic poles, the magnetic declination, the difference between the direction to geographical north and magnetic north, becomes greater and greater. At some point close to the magnetic pole the compass will not indicate any particular direction but will begin to drift. Also, the needle starts to point up or down when getting closer to the poles, because of the so-called magnetic inclination. Cheap compasses with bad bearings may get stuck because of this and therefore indicate a wrong direction.\n\nMagnetic compasses are influenced by any fields other than Earth's. Local environments may contain magnetic mineral deposits and artificial sources such as MRIs, large iron or steel bodies, electrical engines or strong permanent magnets. Any electrically conductive body produces its own magnetic field when it is carrying an electric current. Magnetic compasses are prone to errors in the neighborhood of such bodies. Some compasses include magnets which can be adjusted to compensate for external magnetic fields, making the compass more reliable and accurate.\n\nA compass is also subject to errors when the compass is accelerated or decelerated in an airplane or automobile. Depending on which of the Earth's hemispheres the compass is located and if the force is acceleration or deceleration the compass will increase or decrease the indicated heading. Compasses that include compensating magnets are especially prone to these errors, since accelerations tilt the needle, bringing it closer or further from the magnets.\n\nAnother error of the mechanical compass is turning error. When one turns from a heading of east or west the compass will lag behind the turn or lead ahead of the turn. Magnetometers, and substitutes such as gyrocompasses, are more stable in such situations.\n\nA magnetic rod is required when constructing a compass. This can be created by aligning an iron or steel rod with Earth's magnetic field and then tempering or striking it. However, this method produces only a weak magnet so other methods are preferred. For example, a magnetised rod can be created by repeatedly rubbing an iron rod with a magnetic lodestone. This magnetised rod (or magnetic needle) is then placed on a low friction surface to allow it to freely pivot to align itself with the magnetic field. It is then labeled so the user can distinguish the north-pointing from the south-pointing end; in modern convention the north end is typically marked in some way.\n\nIf a needle is rubbed on a lodestone or other magnet, the needle becomes magnetized. When it is inserted in a cork or piece of wood, and placed in a bowl of water it becomes a compass. Such devices were universally used as compass until the invention of the box-like compass with a 'dry' pivoting needle sometime around 1300.\n\nOriginally, many compasses were marked only as to the direction of magnetic north, or to the four cardinal points (north, south, east, west). Later, these were divided, in China into 24, and in Europe into 32 equally spaced points around the compass card. For a table of the thirty-two points, see compass points.\n\nIn the modern era, the 360-degree system took hold. This system is still in use today for civilian navigators. The degree system spaces 360 equidistant points located clockwise around the compass dial. In the 19th century some European nations adopted the \"grad\" (also called grade or gon) system instead, where a right angle is 100 grads to give a circle of 400 grads. Dividing grads into tenths to give a circle of 4000 decigrades has also been used in armies.\n\nMost military forces have adopted the French \"millieme\" system. This is an approximation of a milli-radian (6283 per circle), in which the compass dial is spaced into 6400 units or \"mils\" for additional precision when measuring angles, laying artillery, etc. The value to the military is that one angular mil subtends approximately one metre at a distance of one kilometer. Imperial Russia used a system derived by dividing the circumference of a circle into chords of the same length as the radius. Each of these was divided into 100 spaces, giving a circle of 600. The Soviet Union divided these into tenths to give a circle of 6000 units, usually translated as \"mils\". This system was adopted by the former Warsaw Pact countries (e.g. Soviet Union, East Germany), often counterclockwise (see picture of wrist compass). This is still in use in Russia.\n\nBecause the Earth's magnetic field's inclination and intensity vary at different latitudes, compasses are often balanced during manufacture so that the dial or needle will be level, eliminating needle drag which can give inaccurate readings. Most manufacturers balance their compass needles for one of five zones, ranging from zone 1, covering most of the Northern Hemisphere, to zone 5 covering Australia and the southern oceans. This individual zone balancing prevents excessive dipping of one end of the needle which can cause the compass card to stick and give false readings.\n\nSome compasses feature a special needle balancing system that will accurately indicate magnetic north regardless of the particular magnetic zone. Other magnetic compasses have a small sliding counterweight installed on the needle itself. This sliding counterweight, called a 'rider', can be used for counterbalancing the needle against the dip caused by inclination if the compass is taken to a zone with a higher or lower dip.\n\nLike any magnetic device, compasses are affected by nearby ferrous materials, as well as by strong local electromagnetic forces. Compasses used for wilderness land navigation should not be used in proximity to ferrous metal objects or electromagnetic fields (car electrical systems, automobile engines, steel pitons, etc.) as that can affect their accuracy. Compasses are particularly difficult to use accurately in or near trucks, cars or other mechanized vehicles even when corrected for deviation by the use of built-in magnets or other devices. Large amounts of ferrous metal combined with the on-and-off electrical fields caused by the vehicle's ignition and charging systems generally result in significant compass errors.\n\nAt sea, a ship's compass must also be corrected for errors, called deviation, caused by iron and steel in its structure and equipment. The ship is \"swung\", that is rotated about a fixed point while its heading is noted by alignment with fixed points on the shore. A compass deviation card is prepared so that the navigator can convert between compass and magnetic headings. The compass can be corrected in three ways. First the lubber line can be adjusted so that it is aligned with the direction in which the ship travels, then the effects of permanent magnets can be corrected for by small magnets fitted within the case of the compass. The effect of ferromagnetic materials in the compass's environment can be corrected by two iron balls mounted on either side of the compass binnacle. The coefficient formula_1 representing the error in the lubber line, while formula_2 the ferromagnetic effects and formula_3 the non-ferromagnetic component.\n\nA similar process is used to calibrate the compass in light general aviation aircraft, with the compass deviation card often mounted permanently just above or below the magnetic compass on the instrument panel. Fluxgate electronic compasses can be calibrated automatically, and can also be programmed with the correct local compass variation so as to indicate the true heading.\n\nA magnetic compass points to magnetic north pole, which is approximately 1,000 miles from the true geographic North Pole. A magnetic compass's user can determine true North by finding the magnetic north and then correcting for variation and deviation. Variation is defined as the angle between the direction of true (geographic) north and the direction of the meridian between the magnetic poles. Variation values for most of the oceans had been calculated and published by 1914. Deviation refers to the response of the compass to local magnetic fields caused by the presence of iron and electric currents; one can partly compensate for these by careful location of the compass and the placement of compensating magnets under the compass itself. Mariners have long known that these measures do not completely cancel deviation; hence, they performed an additional step by measuring the compass bearing of a landmark with a known magnetic bearing. They then pointed their ship to the next compass point and measured again, graphing their results. In this way, correction tables could be created, which would be consulted when compasses were used when traveling in those locations.\n\nMariners are concerned about very accurate measurements; however, casual users need not be concerned with differences between magnetic and true North. Except in areas of extreme magnetic declination variance (20 degrees or more), this is enough to protect from walking in a substantially different direction than expected over short distances, provided the terrain is fairly flat and visibility is not impaired. By carefully recording distances (time or paces) and magnetic bearings traveled, one can plot a course and return to one's starting point using the compass alone.\n\nCompass navigation in conjunction with a map (\"terrain association\") requires a different method. To take a map bearing or \"true bearing\" (a bearing taken in reference to true, not magnetic north) to a destination with a protractor compass, the edge of the compass is placed on the map so that it connects the current location with the desired destination (some sources recommend physically drawing a line). The orienting lines in the base of the compass dial are then rotated to align with actual or true north by aligning them with a marked line of longitude (or the vertical margin of the map), ignoring the compass needle entirely. The resulting \"true bearing\" or map bearing may then be read at the degree indicator or direction-of-travel (DOT) line, which may be followed as an \"azimuth\" (course) to the destination. If a \"magnetic\" north bearing or \"compass bearing\" is desired, the compass must be adjusted by the amount of magnetic declination before using the bearing so that both map and compass are in agreement. In the given example, the large mountain in the second photo was selected as the target destination on the map. Some compasses allow the scale to be adjusted to compensate for the local magnetic declination; if adjusted correctly, the compass will give the true bearing instead of the magnetic bearing.\n\nThe modern hand-held protractor compass always has an additional direction-of-travel (DOT) arrow or indicator inscribed on the baseplate. To check one's progress along a course or azimuth, or to ensure that the object in view is indeed the destination, a new compass reading may be taken to the target if visible (here, the large mountain). After pointing the DOT arrow on the baseplate at the target, the compass is oriented so that the needle is superimposed over the orienting arrow in the capsule. The resulting bearing indicated is the magnetic bearing to the target. Again, if one is using \"true\" or map bearings, and the compass does not have preset, pre-adjusted declination, one must additionally add or subtract magnetic declination to convert the \"magnetic bearing\" into a \"true bearing\". The exact value of the magnetic declination is place-dependent and varies over time, though declination is frequently given on the map itself or obtainable on-line from various sites. If the hiker has been following the correct path, the compass' corrected (true) indicated bearing should closely correspond to the true bearing previously obtained from the map.\n\nA compass should be laid down on a level surface so that the needle only rests or hangs on the bearing fused to the compass casing – if used at a tilt, the needle might touch the casing on the compass and not move freely, hence not pointing to the magnetic north accurately, giving a faulty reading. To see if the needle is well leveled, look closely at the needle, and tilt it slightly to see if the needle is swaying side to side freely and the needle is not contacting the casing of the compass. If the needle tilts to one direction, tilt the compass slightly and gently to the opposing direction until the compass needle is horizontal, lengthwise. Items to avoid around compasses are magnets of any kind and any electronics. Magnetic fields from electronics can easily disrupt the needle, preventing it from aligning with the Earth's magnetic fields, causing inaccurate readings. The Earth's natural magnetic forces are considerably weak, measuring at 0.5 gauss and magnetic fields from household electronics can easily exceed it, overpowering the compass needle. Exposure to strong magnets, or magnetic interference can sometimes cause the magnetic poles of the compass needle to differ or even reverse. Avoid iron rich deposits when using a compass, for example, certain rocks which contain magnetic minerals, like Magnetite. This is often indicated by a rock with a surface which is dark and has a metallic luster, not all magnetic mineral bearing rocks have this indication. To see if a rock or an area is causing interference on a compass, get out of the area, and see if the needle on the compass moves. If it does, it means that the area or rock the compass was previously at is causing interference and should be avoided.\n\n\n"}
{"id": "20786042", "url": "https://en.wikipedia.org/wiki?curid=20786042", "title": "Cybernetics", "text": "Cybernetics\n\nCybernetics is a transdisciplinary approach for exploring regulatory systems—their structures, constraints, and possibilities. Norbert Wiener defined cybernetics in 1948 as \"the scientific study of control and communication in the animal and the machine.\" In the 21st century, the term is often used in a rather loose way to imply \"control of any system using technology.\" In other words, it is the scientific study of how humans, animals and machines control and communicate with each other.\n\nCybernetics is applicable when a system being analyzed incorporates a closed signaling loop—originally referred to as a \"circular causal\" relationship—that is, where action by the system generates some change in its environment and that change is reflected in the system in some manner (feedback) that triggers a system change. Cybernetics is relevant to, for example, mechanical, physical, biological, cognitive, and social systems. The essential goal of the broad field of cybernetics is to understand and define the functions and processes of systems that have goals and that participate in circular, causal chains that move from action to sensing to comparison with desired goal, and again to action. Its focus is how anything (digital, mechanical or biological) processes information, reacts to information, and changes or can be changed to better accomplish the first two tasks. Cybernetics includes the study of feedback, black boxes and derived concepts such as communication and control in living organisms, machines and organizations including self-organization.\n\nConcepts studied by cyberneticists include, but are not limited to: learning, cognition, adaptation, social control, emergence, convergence, communication, efficiency, efficacy, and connectivity. In cybernetics these concepts (otherwise already objects of study in other disciplines such as biology and engineering) are abstracted from the context of the specific organism or device.\n\nThe word \"cybernetics\" comes from Greek κυβερνητική (\"kybernētikḗ\"), meaning \"governance\", i.e., all that are pertinent to κυβερνάω (\"kybernáō\"), the latter meaning \"to steer, navigate or govern\", hence κυβέρνησις (\"kybérnēsis\"), meaning \"government\", is the government while κυβερνήτης (\"kybernḗtēs\") is the governor or \"helmperson\" of the \"ship\". Contemporary cybernetics began as an interdisciplinary study connecting the fields of control systems, electrical network theory, mechanical engineering, logic modeling, evolutionary biology, neuroscience, anthropology, and psychology in the 1940s, often attributed to the Macy Conferences. During the second half of the 20th century cybernetics evolved in ways that distinguish first-order cybernetics (about observed systems) from second-order cybernetics (about observing systems). More recently there is talk about a third-order cybernetics (doing in ways that embraces first and second-order).\n\nStudies in cybernetics provide a means for examining the design and function of any system, including social systems such as business management and organizational learning, including for the purpose of making them more efficient and effective. Fields of study which have influenced or been influenced by cybernetics include game theory, system theory (a mathematical counterpart to cybernetics), perceptual control theory, sociology, psychology (especially neuropsychology, behavioral psychology, cognitive psychology), philosophy, architecture, and organizational theory. System dynamics, originated with applications of electrical engineering control theory to other kinds of simulation models (especially business systems) by Jay Forrester at MIT in the 1950s, is a related field.\n\nCybernetics has been defined in a variety of ways, by a variety of people, from a variety of disciplines. \nCybernetician Stuart Umpleby reports some notable definitions:\n\nOther notable definitions include:\n\nThe term \"cybernetics\" stems from κυβερνήτης (\"cybernḗtēs\") \"steersman, governor, pilot, or rudder\". As with the ancient Greek pilot, independence of thought is important in cybernetics. French physicist and mathematician André-Marie Ampère first coined the word \"cybernetique\" in his 1834 essay \"Essai sur la philosophie des sciences\" to describe the science of civil government. The term was borrowed by Norbert Wiener, in his book \"\", to define the study of control and communication in the animal and the machine.\n\nThe word \"cybernetics\" was first used in the context of \"the study of self-governance\" by Plato in \"The Alcibiades\" to signify the governance of people. The word 'cybernétique' was also used in 1834 by the physicist André-Marie Ampère (1775–1836) to denote the sciences of government in his classification system of human knowledge.\n\nThe first artificial automatic regulatory system was a water clock, invented by the mechanician Ktesibios; based on a tank which poured water into a reservoir before using it to run the mechanism, it used a cone-shaped float to monitor the level of the water in its reservoir and adjust the rate of flow of the water accordingly to maintain a constant level of water in the reservoir. This was the first artificial truly automatic self-regulatory device that required no outside intervention between the feedback and the controls of the mechanism. Although they considered this part of engineering (the use of the term \"cybernetics\" is much posterior), Ktesibios and others such as Heron and Su Song are considered to be some of the first to study cybernetic principles.\n\nThe study of \"teleological mechanisms\" (from the Greek τέλος or \"télos\" for \"end\", \"goal\", or \"purpose\") in machines with \"corrective feedback\" dates from as far back as the late 18th century when James Watt's steam engine was equipped with a governor (1775–1800), a centrifugal feedback valve for controlling the speed of the engine. Alfred Russel Wallace identified this as the principle of evolution in his famous 1858 paper. In 1868 James Clerk Maxwell published a theoretical article on governors, one of the first to discuss and refine the principles of self-regulating devices. Jakob von Uexküll applied the feedback mechanism via his model of functional cycle (\"Funktionskreis\") in order to explain animal behaviour and the origins of meaning in general.\n\nContemporary cybernetics began as an interdisciplinary study connecting the fields of control systems, electrical network theory, mechanical engineering, logic modeling, evolutionary biology and neuroscience in the 1940s; the ideas are also related to the biological work of Ludwig von Bertalanffy in General Systems Theory. Electronic control systems originated with the 1927 work of Bell Telephone Laboratories engineer Harold S. Black on using negative feedback to control amplifiers.\n\nEarly applications of negative feedback in electronic circuits included the control of gun mounts and radar antenna during World War II. The founder of System Dynamics, Jay Forrester, worked with Gordon S. Brown during WWII as a graduate student at the Servomechanisms Laboratory at MIT to develop electronic control systems for the U.S. Navy. Forrester later applied these ideas to social organizations, such as corporations and cities and became an original organizer of the MIT School of Industrial Management at the MIT Sloan School of Management.\n\nW. Edwards Deming, the Total Quality Management guru for whom Japan named its top post-WWII industrial prize, was an intern at Bell Telephone Labs in 1927 and may have been influenced by network theory; Deming made \"Understanding Systems\" one of the four pillars of what he described as \"Profound Knowledge\" in his book \"The New Economics\".\n\nNumerous papers spearheaded the coalescing of the field. In 1935 Russian physiologist P. K. Anokhin published a book in which the concept of feedback (\"back afferentation\") was studied. The study and mathematical modelling of regulatory processes became a continuing research effort and two key articles were published in 1943: \"Behavior, Purpose and Teleology\" by Arturo Rosenblueth, Norbert Wiener, and Julian Bigelow; and the paper \"A Logical Calculus of the Ideas Immanent in Nervous Activity\" by Warren McCulloch and Walter Pitts.\n\nIn 1936, Ștefan Odobleja published \"Phonoscopy and the clinical semiotics\". In 1937, he participated in the IX International Congress of Military Medicine with \"Demonstration de phonoscopie\"; in the paper he disseminated a prospectus announcing his future work, \"Psychologie consonantiste\", the most important of his writings, where he lays the theoretical foundations of generalized cybernetics. The book, published in Paris by \"Librairie Maloine\" (vol. I in 1938 and vol. II in 1939), contains almost 900 pages and includes 300 figures in the text. The author wrote at the time that \"this book is ... a table of contents, an index or a dictionary of psychology, [for] a ... great Treatise of Psychology that should contain 20–30 volumes\". Due to the beginning of World War II, the publication went unnoticed (the first Romanian edition of this work did not appear until 1982).\n\nCybernetics as a discipline was firmly established by Norbert Wiener, McCulloch, Arturo Rosenblueth and others, such as W. Ross Ashby, mathematician Alan Turing, and W. Grey Walter (one of the first to build autonomous robots as an aid to the study of animal behaviour). In the spring of 1947, Wiener was invited to a congress on harmonic analysis, held in Nancy (France was an important geographical locus of early cybernetics together with the US and UK); the event was organized by the Bourbaki, a French scientific society, and mathematician Szolem Mandelbrojt (1899–1983), uncle of the world-famous mathematician Benoît Mandelbrot. During this stay in France, Wiener received the offer to write a manuscript on the unifying character of this part of applied mathematics, which is found in the study of Brownian motion and in telecommunication engineering. The following summer, back in the United States, Wiener decided to introduce the neologism \"cybernetics\", coined to denote the study of \"teleological mechanisms\", into his scientific theory: it was popularized through his book \"\" (MIT Press/John Wiley and Sons, NY, 1948). In the UK this became the focus for the Ratio Club.\n\nIn the early 1940s John von Neumann, although better known for his work in mathematics and computer science, did contribute a unique and unusual addition to the world of cybernetics: von Neumann cellular automata, and their logical follow up, the von Neumann Universal Constructor. The result of these deceptively simple thought-experiments was the concept of self replication, which cybernetics adopted as a core concept. The concept that the same properties of genetic reproduction applied to social memes, living cells, and even computer viruses is further proof of the somewhat surprising universality of cybernetic study.\n\nIn 1950, Wiener popularized the social implications of cybernetics, drawing analogies between automatic systems (such as a regulated steam engine) and human institutions in his best-selling \"The Human Use of Human Beings: Cybernetics and Society\" (Houghton-Mifflin).\n\nIn the Soviet Union \"bourgeois\" cybernetics was initially considered a \"pseudoscience\" and \"ideological weapon\" of \"imperialist reactionaries\" (Soviet Philosophical Dictionary, 1954) and later criticised as a narrow form of cybernetics. In the mid to late 1950s Viktor Glushkov and others salvaged the reputation of the field. Soviet cybernetics incorporated much of what became known as computer science in the West.\n\nWhile not the only instance of a research organization focused on cybernetics, the Biological Computer Lab at the University of Illinois at Urbana-Champaign, under the direction of Heinz von Foerster, was a major center of cybernetic research for almost 20 years, beginning in 1958.\n\nArtificial intelligence (AI) was founded as a distinct discipline at the Dartmouth workshop. After some uneasy coexistence, AI gained funding and prominence. Consequently, cybernetic sciences such as the study of artificial neural networks were downplayed; the discipline shifted into the world of social sciences and therapy.\n\nProminent cyberneticians during this period include Gregory Bateson and Aksel Berg.\n\nIn the 1970s, new cyberneticians emerged in multiple fields, but especially in biology. The ideas of Maturana, Varela and Atlan, according to Jean-Pierre Dupuy (1986) \"realized that the cybernetic metaphors of the program upon which molecular biology had been based rendered a conception of the autonomy of the living being impossible. Consequently, these thinkers were led to invent a new cybernetics, one more suited to the organizations which mankind discovers in nature - organizations he has not himself invented\". However, during the 1980s the question of whether the features of this new cybernetics could be applied to social forms of organization remained open to debate.\n\nIn political science, Project Cybersyn attempted to introduce a cybernetically controlled economy during the early 1970s. In the 1980s, according to Harries-Jones (1988) \"unlike its predecessor, the new cybernetics concerns itself with the interaction of autonomous political actors and subgroups, and the practical and reflexive consciousness of the subjects who produce and reproduce the structure of a political community. A dominant consideration is that of recursiveness, or self-reference of political action both with regards to the expression of political consciousness and with the ways in which systems build upon themselves\".\n\nOne characteristic of the emerging new cybernetics considered in that time by Felix Geyer and Hans van der Zouwen, according to Bailey (1994), was \"that it views information as constructed and reconstructed by an individual interacting with the environment. This provides an epistemological foundation of science, by viewing it as observer-dependent. Another characteristic of the new cybernetics is its contribution towards bridging the \"micro-macro gap\". That is, it links the individual with the society\". Another characteristic noted was the \"transition from classical cybernetics to the new cybernetics [that] involves a transition from classical problems to new problems. These shifts in thinking involve, among others, (a) a change from emphasis on the system being steered to the system doing the steering, and the factor which guides the steering decisions; and (b) new emphasis on communication between several systems which are trying to steer each other\".\n\nRecent endeavors into the true focus of cybernetics, systems of control and emergent behavior, by such related fields as game theory (the analysis of group interaction), systems of feedback in evolution, and metamaterials (the study of materials with properties beyond the Newtonian properties of their constituent atoms), have led to a revived interest in this increasingly relevant field.\n\nThe design of self-regulating control systems for a real-time planned economy was explored by Viktor Glushkov in the former Soviet Union during the 1960s. By the time information technology was developed enough to enable feasible economic planning based on computers, the Soviet Union and eastern bloc countries began moving away from planning and eventually collapsed.\n\nMore recent proposals for socialism involve \"New Socialism\", outlined by the computer scientists Paul Cockshott and Allin Cottrell, where computers determine and manage the flows and allocation of resources among socially-owned enterprises.\n\nOn the other hand, neoliberals such as Friedrich Hayek also mention cybernetics as a discipline that could help economists understand the \"self-organizing or self-generating systems\" called markets. Being a \"complex phenomena\", the best way to examine the market functioning is by using the feedback mechanism, explained by cybernetic theorists. That way, economists could make \"pattern predictions\".\n\nTherefore, the market for Hayek is a \"communication system\", an \"efficient mechanism for digesting dispersed information\". The economist and a cyberneticist are like garderners who are \"providing the appropriate environment\". \n\nFinally, Hayek also considers that Adam Smith's idea of the invisible hand is as anticipation of the operation of the feedback mechanism in cybernetics. In the same book, Law, Legislation and Liberty, Hayek mentions, along with cybernetics, that economists should rely on the scientific findings of Ludwig von Bertalanffy general systems theory, along with information and communication theory and semiotics.\n\nCybernetics is sometimes used as a generic term, which serves as an umbrella for many systems-related scientific fields.\n\nCybernetics studies systems of control as a concept, attempting to discover the basic principles underlying such things as\n\nCybernetics in biology is the study of cybernetic systems present in biological organisms, primarily focusing on how animals adapt to their environment, and how information in the form of genes is passed from generation to generation. There is also a secondary focus on combining artificial systems with biological systems. A notable application to the biology world would be that, in 1955, the physicist George Gamow published a prescient article in \"Scientific American\" called \"Information transfer in the living cell\", and cybernetics gave biologists Jacques Monod and François Jacob a language for formulating their early theory of gene regulatory networks in the 1960s.\n\nComputer science directly applies the concepts of cybernetics to the control of devices and the analysis of information.\n\nCybernetics in engineering is used to analyze cascading failures and system accidents, in which the small errors and imperfections in a system can generate disasters. Other topics studied include:\n\n\nMathematical Cybernetics focuses on the factors of information, interaction of parts in systems, and the structure of systems.\n\n\nBy examining group behavior through the lens of cybernetics, sociologists can seek the reasons for such spontaneous events as smart mobs and riots, as well as how communities develop rules such as etiquette by consensus without formal discussion. Affect Control Theory explains role behavior, emotions, and labeling theory in terms of homeostatic maintenance of sentiments associated with cultural categories. The most comprehensive attempt ever made in the social sciences to increase cybernetics in a generalized theory of society was made by Talcott Parsons. In this way, cybernetics establishes the basic hierarchy in Parsons' AGIL paradigm, which is the ordering system-dimension of his action theory. These and other cybernetic models in sociology are reviewed in a book edited by McClelland and Fararo.\n\nA model of cybernetics in Education was introduced by Gihan Sami Soliman; an educational consultant, as a project idea to be implemented with the help of two team members in Sinai. The Sinai Sustainability Cybernetics Center announced as a semi-finalist project by MIT annual competition 2013. \nThe project idea proposed relating education to sustainable development through an IMS project that applies a multiple educational program related to the original natural self-healing system of life on earth. Education, sustainable development, social justice disciplines interact in a causal circular relationship that education would contribute to the development of the local community in Sinai village, on both sustainability and social responsibility levels while the community itself provides a unique learning environment that will contribute to the development of the educational program in a closed signaling loop.\n\nNicolas Schöffer's \"CYSP I\" (1956) was perhaps the first artwork to explicitly employ cybernetic principles (CYSP is an acronym that joins the first two letters of the words \"CYbernetic\" and \"SPatiodynamic\"). \nThe prominent and influential Cybernetic Serendipity exhibition was held at the ICA in 1968 curated by Jasia Reichardt, including Schöffer's \"CYSP I\" and Gordon Pask's \"Colloquy of Mobiles\" installation. Pask's reflections on \"Colloquy\" connected it to his earlier \"Musicolour\" installation and to he what he termed \"aesthetically potent environments\", a concept that connected this artistic work to his concerns with teaching and learning.\nThe artist Roy Ascott elaborated an extensive theory of cybernetic art in \"Behaviourist Art and the Cybernetic Vision\" (\"Cybernetica\", Journal of the International Association for Cybernetics (Namur), Volume IX, No.4, 1966; Volume X No.1, 1967) and in \"The Cybernetic Stance: My Process and Purpose\" (\"Leonardo\" Vol 1, No 2, 1968). Art historian Edward A. Shanken has written about the history of art and cybernetics in essays including \"Cybernetics and Art: Cultural Convergence in the 1960s\" and \"From Cybernetics to Telematics: The Art, Pedagogy, and Theory of Roy Ascott\" (2003), which traces the trajectory of Ascott's work from cybernetic art to telematic art (art using computer networking as its medium, a precursor to net.art.)\n\nCybernetics was an influence on thinking in architecture and design in the decades after the Second World War. Ashby and Pask were drawn on by design theorists such as Horst Rittel, Christopher Alexander and Bruce Archer. Pask was a consultant to Nicholas Negroponte's Architecture Machine Group, forerunner of the MIT Media Lab, and collaborated with architect Cedric Price and theatre director Joan Littlewood on the influential Fun Palace project during the 1960s. Pask's 1950s Musicolour installation was the inspiration for John and Julia Frazer's work on Price's Generator project. There has been a resurgence of interest in cybernetics and systems thinking amongst designers in recent decades, in relation to developments in technology and increasingly complex design challenges. Figures such as Klaus Krippendorff, Paul Pangaro and Ranulph Glanville have made significant contributions to both cybernetics and design research. The connections between the two fields have come to be understood less in terms of application and more as reflections of each other.\n\nGeocybernetics aims to study and control the complex co-evolution of ecosphere and anthroposphere, for example, for dealing with planetary problems such as anthropogenic global warming. Geocybernetics applies a dynamical systems perspective to Earth system analysis. It provides a theoretical framework for studying the implications of following different sustainability paradigms on co-evolutionary trajectories of the planetary socio-ecological system to reveal attractors in this system, their stability, resilience and reachability. Concepts such as tipping points in the climate system, planetary boundaries, the safe operating space for humanity and proposals for manipulating Earth system dynamics on a global scale such as geoengineering have been framed in the language of geocybernetic Earth system analysis.\n\nA model of cybernetics in Sport was introduced by Yuri Verkhoshansky and Mel C. Siff in 1999 in their book \"Supertraining\".\n\nAs a form of regulation, cybernetics has been always close to law, specially in regulation and legal sciences, through the next topics:\n\nComplexity science attempts to understand the nature of complex systems.\n\nBiomechatronics relates to linking mechatronics to biological organisms, leading to systems that conform to A. N. Kolmogorov's definition of Cybernetics: \"Science concerned with the study of systems of any nature which are capable of receiving, storing and processing information so as to use it for control\". From this perspective mechatronics are considered technical cybernetics or engineering cybernetics.\n\n\n\n\n"}
{"id": "922164", "url": "https://en.wikipedia.org/wiki?curid=922164", "title": "Design research", "text": "Design research\n\nDesign research was originally constituted as primarily research into the process of design, developing from work in design methods, but the concept has been expanded to include research embedded within the process of design, including work concerned with the context of designing and research-based design practice. The concept retains a sense of generality, aimed at understanding and improving design processes and practices quite broadly, rather than developing domain-specific knowledge within any professional field of design.\n\nDesign Research emerged as a recognisable field of study in the 1960s, initially marked by a conference on Design methods at Imperial College London, in 1962. It led to the founding of the Design Research Society (DRS) in 1966. John Christopher Jones (one of the initiators of the 1962 conference) founded a postgraduate Design Research Laboratory at the University of Manchester Institute of Science and Technology, and L. Bruce Archer supported by Misha Black founded the postgraduate Department of Design Research at the Royal College of Art, London, becoming the first Professor of Design Research.\n\nThe Design Research Society has always stated its aim as: ‘to promote the study of and research into the process of designing in all its many fields’. Its purpose therefore is to act as a form of learned society, taking a scholarly and domain independent view of the process of designing.\n\nSome of the origins of design methods and design research lay in the emergence after the 2nd World War of operational research methods and management decision-making techniques, the development of creativity techniques in the 1950s, and the beginnings of computer programs for problem solving in the 1960s. A statement by Bruce Archer encapsulated what was going on: ‘The most fundamental challenge to conventional ideas on design has been the growing advocacy of systematic methods of problem solving, borrowed from computer techniques and management theory, for the assessment of design problems and the development of design solutions.’ Herbert A. Simon established the foundations for ‘a science of design’, which would be ‘a body of intellectually tough, analytic, partly formalizable, partly empirical, teachable doctrine about the design process.’\n\nEarly work was mainly within the domains of architecture and industrial design, but research in engineering design developed strongly in the 1980s; for example, through ICED—the series of International Conferences on Engineering Design, now run by The Design Society. These developments were especially strong in Germany and Japan. In the USA there were also some important developments in design theory and methodology, including the publications of the Design Methods Group and the series of conferences of the Environmental Design Research Association. The National Science Foundation initiative on design theory and methods led to substantial growth in engineering design research in the late-1980s. A particularly significant development was the emergence of the first journals of design research. DRS initiated \"Design Studies\" in 1979, \"Design Issues\" appeared in 1984, and \"Research in Engineering Design\" in 1989.\n\nThe development of design research has led to the establishment of design as a coherent discipline of study in its own right, based on the view that design has its own things to know and its own ways of knowing them. Bruce Archer again encapsulated the view in stating his new belief that ‘there exists a designerly way of thinking and communicating that is both different from scientific and scholarly ways of thinking and communicating, and as powerful as scientific and scholarly methods of enquiry when applied to its own kinds of problems’. This view was developed further in a series of papers by Nigel Cross, collected as a book on 'Designerly Ways of Knowing'. \nSignificantly, Donald Schön promoted the new view within his book The Reflective Practitioner, in which he challenged the technical rationality of Simon and sought to establish ‘an epistemology of practice implicit in the artistic, intuitive processes which [design and other] practitioners bring to situations of uncertainty, instability, uniqueness and value conflict’.\n\nDesign research ‘came of age’ in the 1980s, and has continued to expand. This was helped by the development of a research base, including doctoral programmes, within many of the design schools located within new institutions that were previously art colleges, and the emergence of new areas such as interaction design. More new journals have appeared, such as \"The Design Journal\", the\" Journal of Design Research\", \"CoDesign\" and more recently \"Design Science\". There has also been a major growth in conferences, with not only a continuing series by DRS, but also series such as Design Thinking, Doctoral Education in Design, Design Computing and Cognition, Design and Emotion, the European Academy, the Asian Design Conferences, etc. Design research now operates on an international scale, acknowledged in the cooperation of DRS with the Asian design research societies in the founding in 2005 of the International Association of Societies of Design Research.\n\n\n\n \n"}
{"id": "8736929", "url": "https://en.wikipedia.org/wiki?curid=8736929", "title": "Diablo Data Systems", "text": "Diablo Data Systems\n\nDiablo Data Systems was a division of Xerox created by the acquisition of Diablo Systems Inc. for US$29 million in 1972, a company which had been founded in 1969 by George E. Comstock, Charles L. Waggoner and others.\n\nThe company was best known for the HyType I, HyType II, and Diablo 630 daisywheel printers, but also produced the hard disk drives that were resold by DEC as the RK02 and RK03.\n\nThe removable disk drives were used in the Xerox manufactured Xerox Alto computer\n"}
{"id": "34738297", "url": "https://en.wikipedia.org/wiki?curid=34738297", "title": "Digital learning", "text": "Digital learning\n\nDigital learning is any type of learning that is accompanied by technology or by instructional practice that makes effective use of technology. It encompasses the application of a wide spectrum of practices including: blended and virtual learning. \n\nSometimes confused with online learning or e-learning, digital learning encompasses the aforementioned concepts.\n\nA digital learning strategy may include any of or a combination of any of the following:\n\nDigital learning is meant to enhance the learning experience rather than replace traditional methods altogether. Listed below are common pedagogies, or practices of teaching, that combine technology and learning:\n\nThere are a plethora of tools and resources online (many that are FREE!) that can be used to create and enhance a digital learning environment. Listed below are resources and tools 21st century teachers can use for digital learning:\n\n"}
{"id": "3780438", "url": "https://en.wikipedia.org/wiki?curid=3780438", "title": "Disc mill", "text": "Disc mill\n\nA disc mill is a type of crusher that can be used to grind, cut, shear, shred, fiberize, pulverize, granulate, crack, rub, curl, fluff, twist, hull, blend, or refine. It works in a similar manner to the ancient Buhrstone mill in that the feedstock is fed between opposing discs or plates. The discs may be grooved, serrated, or spiked.\n\nTypical applications for a single-disc mill are all three stages of the wet milling of field corn, manufacture of peanut butter, processing nut shells, ammonium nitrate, urea, producing chemical slurries and recycled paper slurries, and grinding chromium metal.\n\nDouble-disc mills are typically used for alloy powders, aluminum chips, bark, barley, borax, brake lining scrap, brass chips, sodium hydroxide, chemical salts, coconut shells, copper powder, cork, cottonseed hulls, pharmaceuticals, feathers, hops, leather, oilseed cakes, phosphates, rice, rosin, sawdust, and seeds. \n\nDisc mills are relatively expensive to run and maintain and they consume much more power than other shredding machines, and are not used where ball mills or hammermills produce the desired results at a lower cost.\n\nSubstances are crushed between the edge of a thick, spinning disk and something else. Some mills cover the edge of the disk in blades to chop up incoming matter rather than crush it.\n"}
{"id": "3115993", "url": "https://en.wikipedia.org/wiki?curid=3115993", "title": "Environmental stress screening", "text": "Environmental stress screening\n\nEnvironmental stress screening (ESS) refers to the process of exposing a newly manufactured or repaired product or component (typically electronic) to stresses such as thermal cycling and vibration in order to force latent defects to manifest themselves by permanent or catastrophic failure during the screening process. The surviving population, upon completion of screening, can be assumed to have a higher reliability than a similar unscreened population.\n\nDeveloped to help electronics manufacturers detect product defects and production flaws, ESS is widely used in military and aerospace applications, less so for commercial products. The tests need not be elaborate, for example, switching an electronic or electrical system on and off a few times may be enough to catch some simple defects that would otherwise be encountered by the end user very soon after the product was first used. Tests typically include the following:\n\n\nESS can be performed as part of the manufacturing process or it can be used in new product qualification testing.\n\nAn ESS system usually consists of a test chamber, controller, fixturing, interconnect and wiring, and a functional tester. These systems can be purchased from a variety of companies in the environmental test industry.\n\nThe stress screening from this process will help find infant mortality in the product. Finding these failures before the product reaches the customer yields better quality and lower warranty expenses. Associated military terminology includes an operational requirements document (ORD) and on-going reliability testing (ORT).\n\n'The following is extracted from a paper on ESS testing prepared by the U.S. Air Force to provide standardized definitions and methods. The paper is available for unrestricted distribution by writing to OO-ALC/ENR, Hill AFB, Ut. 84056. Ask for OO-ALC Technical Note 01-2002, Environmental Stress Screening of Replacement and Repaired Components, Standardized Definitions and Process, by David Franz.'\n\nThe purpose of this paper is to provide standardized definitions and a roadmap of test processes for the Environmental Stress Screening (ESS) of replacement and repaired components used on Air Force systems. The term “component” is used interchangeably with the term “unit” and includes Line-replaceable unit (LRU) and sub-units (SRU). A component selected for testing is a Unit Under Test (UUT). Operational Safety, Suitability, and Effectiveness (OSS&E) policy and instructions require consistency in the disciplined engineering process used to ensure that activities such as maintenance repairs and part substitutions do not degrade system or end-item baselined characteristics over their operational life. Baselined characteristics are highly dependent on reliability, which is verified and maintained by ESS testing. OSS&E policy and instructions also require consistent engineering processes to ensure manufacturing and repair entities are accountable for delivering quality products, and to provide selection and qualification criteria for new sources of supply. Determinations of product quality and source capabilities usually require ESS testing. While considerable information concerning ESS methods and procedures is available including United States Military Standards, handbooks, guides, and the original equipment manufacturer’s test plans, often these publications use differing and confusing definitions for the testing phases where ESS is applied. Lengthy explanations were needed to clarify contract clauses citing these publications. This paper ensures testing requirements are uniformly applied and clearly understood in writing source qualification requirements and contracts.\n\nTo ensure that good workmanship has been employed and that the UUT is free of obvious physical defects.\n\nVisually inspect UUT before and after each manufacturing, repair, and test operation.\n\nWorkmanship shall meet the applicable standards including T.O. 00-25-234 and shall be free of obvious physical defects. A unit that exhibits any sign that a part is stressed beyond its design limit (cracked circuit boards, loose connectors and/or screws, bent clamps and/or screws, worn parts, etc.) is considered to have failed even if the UUT passes the Functional Testing.\n\nDone before, during, and after ESS testing to verify that the UUT is functioning within design tolerances.\n\nApplying an input signal or stimulus and measuring the output.\n\nOutput responses/signals must be within technical data specifications, and the UUT must operate satisfactorily in the next higher assembly.\n\nTesting at the physical environmental conditions (shock, vibration, temperature, altitude, humidity, etc.) that simulate those encountered over the operational life of the component. Random vibration and temperature cycling have proven to be the most successful forms of ESS in terms of effective flaw precipitation.\n\nA stress profile is developed and applied to the UUT. The profile simulates the environmental conditions encountered during transportation, storage, handling, and operational use phases. The UUT is configured to match the phase, e.g. transportation shocks are applied with the UUT in the shipping container, operational use temperature cycles are applied with the UUT operating.\n\nThe UUT(Unit Under Test) must pass Functional Testing and Visual Inspection before, during, and after ESS.\n\nThe testing of a production-representative unit to demonstrate that the design, manufacturing, assembly, and repair processes have resulted in hardware that conforms to the specification. Satisfactory completion of Qualification Testing denotes readiness for further stages of testing. Limited flight testing may be acceptable before completion of all phases of Qualification Testing.\n\n\n\nFormal tests conducted to demonstrate acceptability of the individual unit for delivery. They demonstrate performance to purchase specification requirements and act as quality control screens to detect deficiencies of workmanship and materials. The successful completion of such tests denotes acceptance of the unit by the procurement agency.\n\n\n\nThis should be part of the Qualification and Acceptance ESS when verification of reliability is required.\n\n\n\n\n\n\n\nThis is the UUT for Qualification ESS (typically three UUT are required). The UUT must be representative of the design, production line processes, materials, and workmanship.\n\nAlso called First Article. This is the UUT (typically two are required) that demonstrates that the repair source has the capability and processes to perform a satisfactory repair.\n\n\nTailoring is the formal engineering task of using existing technical data (requirements, standards, specifications, test plans, etc.) and selecting or modifying applicable areas to meet the requirements unique to the type of unit undergoing test. Non-applicable requirements are deleted. Other requirements may be added due to changes in Federal standards, identification of new hazards, modifications to the item, or changes in the mission/ESS profile. All areas of non-compliance with the technical data shall be identified by the contractor and a Requirements Tailoring Request (RTR) shall be submitted to the Government for each area. The RTR shall include thorough justification. Only the Government Engineering Authority for the component can accept an RTR.\n\nTailoring generally is to select the applicable areas, best test methods, or for use of an equivalent requirement.\n\nTailoring generally is to change the test levels and durations, sequence of tests, or reporting requirements. Tailoring shall also identify any test requirements that are to be accomplished through analysis, similarity, or inspection.\n\nEach RTR shall be classified as a MIC, Waiver, or Deviation.\n\n\n"}
{"id": "22809372", "url": "https://en.wikipedia.org/wiki?curid=22809372", "title": "Fleet Radio Unit", "text": "Fleet Radio Unit\n\nFleet Radio Units (FRU) were the major centers for Allied cryptological and signals intelligence during the Pacific Campaign of World War II. Initially two FRUs were established in the Pacific, one at Pearl Harbor, Hawaii, called Station HYPO or FRUPAC (Fleet Radio Unit, Pacific), and the other, called Station CAST or Belconnen, at Cavite Naval Yard, then Corregidor, Philippines. With the fall of the Philippines to Imperial Japanese forces in April and May 1942, CAST personnel were evacuated to a newly established FRU at Melbourne, Australia, called FRUMEL (Fleet Radio Unit, Melbourne).\n\nHYPO and FRUMEL supervised detached field units scattered at various locations and aboard ships throughout the south, central, and north Pacific areas until the end of World War II. A third center, NEGAT, was based at OP-20-G headquarters in Washington DC. The entire cryptanalysis effort conducted by the units was called \"Operation Magic\". Liaison between the units and with the Far East Combined Bureau (FECB; the British signals intelligence center at Colombo, Ceylon in 1942) was titled \"Copek\".\n\n"}
{"id": "1047866", "url": "https://en.wikipedia.org/wiki?curid=1047866", "title": "Green mix", "text": "Green mix\n\nGreen mix is an early step in the manufacturing of black powder for explosives. It is a rough mixture of potassium nitrate, charcoal and sulfur in the correct proportions (75:15:10) for black powder, but is not milled, pressed or corned. It burns much more slowly than black powder, when it chooses to burn at all; the deflagration is usually characterized by short, uneven sizzling followed by relatively long periods of smoulder. Green mix is merely an unfinished product and not generally used itself in any pyrotechnic or projectile applications. \n\n\n"}
{"id": "8837155", "url": "https://en.wikipedia.org/wiki?curid=8837155", "title": "Hakon Haugnes", "text": "Hakon Haugnes\n\nHakon Haugnes is one of the founders of the .name top-level domain founded and launched by Global Name Registry (GNR) in 2000/2001. Previously Mr Haugnes was a co-founder of Nameplanet.com, which provided personalized email addresses to 1M users in March 2000.\n\nHakon Haugnes is CFO/COO of Andurand Capital and responsible for all operational and financial (non-investment) aspects of the company. Hakon was previously Risk Manager for BlueGold Capital (2010-2012), reporting to the CFO and CIO on all risk management aspects of the hedge fund which at its peak managed over $2 billion USD. Mr Haugnes also developed BlueGold’s information systems and headed up the in-house development team. Hakon was Business Analyst for BlueGold from 2009 to 2010. Prior to BlueGold, Haugnes was co-founder and president of Global Name Registry, a private company which was sold in Q4 2008 to VeriSign Inc (NASDAQ:VRSN).\n\nHe served with the Norwegian Armed Forces as Strategist and holds a masters degree (honours) in mathematical modelling from the Institute of Cybernetics at the Norwegian Institute of Science and Technology (NTNU) and studied engineering at Institut National des Sciences Appliquees (INSA) in Toulouse, France.\n\n"}
{"id": "3032314", "url": "https://en.wikipedia.org/wiki?curid=3032314", "title": "History of the camera", "text": "History of the camera\n\nThe history of the camera can be traced much further back than the introduction of photography. Cameras evolved from the camera obscura, and continued to change through many generations of photographic technology, including daguerreotypes, calotypes, dry plates, film, and to the modern day with digital cameras.\n\nThe forerunner to the photographic camera was the \"camera obscura\". Camera obscura (Latin for \"dark room\") is the natural optical phenomenon that occurs when an image of a scene at the other side of a screen (or for instance a wall) is projected through a small hole in that screen and forms an inverted image (left to right and upside down) on a surface opposite to the opening. The oldest known record of this principle is a description by Han Chinese philosopher Mozi (ca. 470 to ca. 391 BC). Mozi correctly asserted that the camera obscura image is inverted because light travels in straight lines from its source. In the 11th century Arab physicist Ibn al-Haytham (Alhazen)'s wrote very influential books about optics, including experiments with light through a small opening in a darkened room.\n\nThe use of a lens in the opening of a wall or closed window shutter of a darkened room to project images used as a drawing aid has been traced back to circa 1550. Since the late 17th century portable camera obscura devices in tents and boxes were used as a drawing aid.\nBefore the invention of photographic processes there was no way to preserve the images produced by these cameras apart from manually tracing them. The earliest cameras were room-sized, with space for one or more people inside; these gradually evolved into more and more compact models. By Niépce's time portable box camerae obscurae suitable for photography were readily available. The first camera that was small and portable enough to be practical for photography was envisioned by Johann Zahn in 1685, though it would be almost 150 years before such an application was possible.\n\nThe first partially successful photograph of a camera image was made in approximately 1816 by Nicéphore Niépce,\nusing a very small camera of his own making and a piece of paper coated with silver chloride, which darkened where it was exposed to light. No means of removing the remaining unaffected silver chloride was known to Niépce, so the photograph was not permanent, eventually becoming entirely darkened by the overall exposure to light necessary for viewing it. In the mid-1820s, Niépce used a sliding wooden box camera made by Parisian opticians Charles and Vincent Chevalier to experiment with photography on surfaces thinly coated with Bitumen of Judea. The bitumen slowly hardened in the brightest areas of the image. The unhardened bitumen was then dissolved away. One of those photographs has survived.\n\nAfter Niépce's death in 1833, his partner Louis Daguerre continued to experiment and by 1837 had created the first practical photographic process, which he named the daguerreotype and publicly unveiled in 1839. Daguerre treated a silver-plated sheet of copper with iodine vapor to give it a coating of light-sensitive silver iodide. After exposure in the camera, the image was developed by mercury vapor and fixed with a strong solution of ordinary salt (sodium chloride). Henry Fox Talbot perfected a different process, the calotype, in 1840. As commercialized, both processes used very simple cameras consisting of two nested boxes. The rear box had a removable ground glass screen and could slide in and out to adjust the focus. After focusing, the ground glass was replaced with a light-tight holder containing the sensitized plate or paper and the lens was capped. Then the photographer opened the front cover of the holder, uncapped the lens, and counted off as many minutes as the lighting conditions seemed to require before replacing the cap and closing the holder. Despite this mechanical simplicity, high-quality achromatic lenses were standard.\n\nCollodion dry plates had been available since 1857, thanks to the work of Désiré van Monckhoven, but it was not until the invention of the gelatin dry plate in 1871 by Richard Leach Maddox that the wet plate process could be rivaled in quality and speed. The 1878 discovery that heat-ripening a gelatin emulsion greatly increased its sensitivity finally made so-called \"instantaneous\" snapshot exposures practical. For the first time, a tripod or other support was no longer an absolute necessity. With daylight and a fast plate or film, a small camera could be hand-held while taking the picture. The ranks of amateur photographers swelled and informal \"candid\" portraits became popular. There was a proliferation of camera designs, from single- and twin-lens reflexes to large and bulky field cameras, simple box cameras, and even \"detective cameras\" disguised as pocket watches, hats, or other objects.\n\nThe short exposure times that made candid photography possible also necessitated another innovation, the mechanical shutter. The very first shutters were separate accessories, though built-in shutters were common by the end of the 19th century.\n\nThe use of photographic film was pioneered by George Eastman, who started manufacturing paper film in 1885 before switching to celluloid in 1888-1889. His first camera, which he called the \"Kodak,\" was first offered for sale in 1888. It was a very simple box camera with a fixed-focus lens and single shutter speed, which along with its relatively low price appealed to the average consumer. The Kodak came pre-loaded with enough film for 100 exposures and needed to be sent back to the factory for processing and reloading when the roll was finished. By the end of the 19th century Eastman had expanded his lineup to several models including both box and folding cameras.\n\nIn 1900, Eastman took mass-market photography one step further with the Brownie, a simple and very inexpensive box camera that introduced the concept of the snapshot. The Brownie was extremely popular and various models remained on sale until the 1960s.\n\nFilm also allowed the movie camera to develop from an expensive toy to a practical commercial tool.\n\nDespite the advances in low-cost photography made possible by Eastman, plate cameras still offered higher-quality prints and remained popular well into the 20th century. To compete with rollfilm cameras, which offered a larger number of exposures per loading, many inexpensive plate cameras from this era were equipped with magazines to hold several plates at once. Special backs for plate cameras allowing them to use film packs or rollfilm were also available, as were backs that enabled rollfilm cameras to use plates.\n\nExcept for a few special types such as Schmidt cameras, most professional astrographs continued to use plates until the end of the 20th century when electronic photography replaced them.\n\nA number of manufacturers started to use 35mm film for still photography between 1905 and 1913. The first 35mm cameras available to the public, and reaching significant numbers in sales were the Tourist Multiple, in 1913, and the Simplex, in 1914. \n\nOskar Barnack, who was in charge of research and development at Leitz, decided to investigate using 35 mm cine film for still cameras while attempting to build a compact camera capable of making high-quality enlargements. He built his prototype 35 mm camera (Ur-Leica) around 1913, though further development was delayed for several years by World War I. It wasn't until after World War I that Leica commercialized their first 35mm Cameras. Leitz test-marketed the design between 1923 and 1924, receiving enough positive feedback that the camera was put into production as the Leica I (for Leitz camera) in 1925. The Leica's immediate popularity spawned a number of competitors, most notably the Contax (introduced in 1932), and cemented the position of 35 mm as the format of choice for high-end compact cameras.\n\nKodak got into the market with the Retina I in 1934, which introduced the 135 cartridge used in all modern 35 mm cameras. Although the Retina was comparatively inexpensive, 35 mm cameras were still out of reach for most people and rollfilm remained the format of choice for mass-market cameras. This changed in 1936 with the introduction of the inexpensive Argus A and to an even greater extent in 1939 with the arrival of the immensely popular Argus C3. Although the cheapest cameras still used rollfilm, 35 mm film had come to dominate the market by the time the C3 was discontinued in 1966.\n\nThe fledgling Japanese camera industry began to take off in 1936 with the Canon 35 mm rangefinder, an improved version of the 1933 Kwanon prototype. Japanese cameras would begin to become popular in the West after Korean War veterans and soldiers stationed in Japan brought them back to the United States and elsewhere.\n\nThe first practical reflex camera was the Franke & Heidecke Rolleiflex medium format TLR of 1928. Though both single- and twin-lens reflex cameras had been available for decades, they were too bulky to achieve much popularity. The Rolleiflex, however, was sufficiently compact to achieve widespread popularity and the medium-format TLR design became popular for both high- and low-end cameras.\n\nA similar revolution in SLR design began in 1933 with the introduction of the Ihagee Exakta, a compact SLR which used 127 rollfilm. This was followed three years later by the first Western SLR to use 135 film, the Kine Exakta (World's first true 35mm SLR was Soviet \"Sport\" camera, marketed several months before Kine Exakta, though \"Sport\" used its own film cartridge). The 35mm SLR design gained immediate popularity and there was an explosion of new models and innovative features after World War II. There were also a few 35mm TLRs, the best-known of which was the Contaflex of 1935, but for the most part these met with little success.\n\nThe first major post-war SLR innovation was the eye-level viewfinder, which first appeared on the Hungarian Duflex in 1947 and was refined in 1948 with the Contax S, the first camera to use a pentaprism. Prior to this, all SLRs were equipped with waist-level focusing screens. The Duflex was also the first SLR with an instant-return mirror, which prevented the viewfinder from being blacked out after each exposure. This same time period also saw the introduction of the Hasselblad 1600F, which set the standard for medium format SLRs for decades.\n\nIn 1952 the Asahi Optical Company (which later became well known for its Pentax cameras) introduced the first Japanese SLR using 135 film, the Asahiflex. Several other Japanese camera makers also entered the SLR market in the 1950s, including Canon, Yashica, and Nikon. Nikon's entry, the Nikon F, had a full line of interchangeable components and accessories and is generally regarded as the first Japanese system camera. It was the F, along with the earlier S series of rangefinder cameras, that helped establish Nikon's reputation as a maker of professional-quality equipment.\n\nWhile conventional cameras were becoming more refined and sophisticated, an entirely new type of camera appeared on the market in 1948. This was the Polaroid Model 95, the world's first viable instant-picture camera. Known as a Land Camera after its inventor, Edwin Land, the Model 95 used a patented chemical process to produce finished positive prints from the exposed negatives in under a minute. The Land Camera caught on despite its relatively high price and the Polaroid lineup had expanded to dozens of models by the 1960s. The first Polaroid camera aimed at the popular market, the Model 20 Swinger of 1965, was a huge success and remains one of the top-selling cameras of all time.\n\nThe first camera to feature automatic exposure was the selenium light meter-equipped, fully automatic Super Kodak Six-20 pack of 1938, but its extremely high price (for the time) of $225 ($ in present terms) kept it from achieving any degree of success. By the 1960s, however, low-cost electronic components were commonplace and cameras equipped with light meters and automatic exposure systems became increasingly widespread.\n\nThe next technological advance came in 1960, when the German Mec 16 SB subminiature became the first camera to place the light meter behind the lens for more accurate metering. However, through-the-lens metering ultimately became a feature more commonly found on SLRs than other types of camera; the first SLR equipped with a TTL system was the Topcon RE Super of 1962.\n\nDigital cameras differ from their analog predecessors primarily in that they do not use film, but capture and save photographs on digital memory cards or internal storage instead. Their low operating costs have relegated chemical cameras to niche markets. Digital cameras now include wireless communication capabilities (for example Wi-Fi or Bluetooth) to transfer, print or share photos, and are commonly found on mobile phones.\n\nThe concept of digitizing images on scanners, and the concept of digitizing video signals, predate the concept of making still pictures by digitizing signals from an array of discrete sensor elements. Early spy satellites used the extremely complex and expensive method of de-orbit and airborne retrieval of film canisters. Technology was pushed to skip these steps through the use of in-satellite developing and electronic scanning of the film for direct transmission to the ground. The amount of film was still a major limitation, and this was overcome and greatly simplified by the push to develop an electronic image capturing array that could be used instead of film. The first electronic imaging satellite was the KH-11 launched by the NRO in late 1976. It had a charge-coupled device (CCD) array with a resolution of (0.64 megapixels). At Philips Labs in New York, Edward Stupp, Pieter Cath and Zsolt Szilagyi filed for a patent on \"All Solid State Radiation Imagers\" on 6 September 1968 and constructed a flat-screen target for receiving and storing an optical image on a matrix composed of an array of photodiodes connected to a capacitor to form an array of two terminal devices connected in rows and columns. Their US patent was granted on 10 November 1970. Texas Instruments engineer Willis Adcock designed a filmless camera that was not digital and applied for a patent in 1972, but it is not known whether it was ever built. The Cromemco CYCLOPS introduced as a hobbyist construction project in 1975 was the first digital camera to be interfaced to a microcomputer. \n\nThe first recorded attempt at building a self-contained digital camera was in 1975 by Steven Sasson, an engineer at Eastman Kodak. It used the then-new solid-state CCD image sensor chips developed by Fairchild Semiconductor in 1973. The camera weighed 8 pounds (3.6 kg), recorded black and white images to a compact cassette tape, had a resolution of 0.01 megapixels (10,000 pixels), and took 23 seconds to capture its first image in December 1975. The prototype camera was a technical exercise, not intended for production.\n\nHandheld electronic cameras, in the sense of a device meant to be carried and used like a handheld film camera, appeared in 1981 with the demonstration of the Sony Mavica (Magnetic Video Camera). This is not to be confused with the later cameras by Sony that also bore the Mavica name. This was an analog camera, in that it recorded pixel signals continuously, as videotape machines did, without converting them to discrete levels; it recorded television-like signals to a 2 × 2 inch \"video floppy\". \nIn essence it was a video movie camera that recorded single frames, 50 per disk in field mode and 25 per disk in frame mode. The image quality was considered equal to that of then-current televisions.\n\nAnalog electronic cameras do not appear to have reached the market until 1986 with the Canon RC-701. Canon demonstrated a prototype of this model at the 1984 Summer Olympics, printing the images in the \"Yomiuri Shinbun\", a Japanese newspaper. In the United States, the first publication to use these cameras for real reportage was USA Today, in its coverage of World Series baseball. Several factors held back the widespread adoption of analog cameras; the cost (upwards of $20,000), poor image quality compared to film, and the lack of quality affordable printers. Capturing and printing an image originally required access to equipment such as a frame grabber, which was beyond the reach of the average consumer. The \"video floppy\" disks later had several reader devices available for viewing on a screen, but were never standardized as a computer drive.\n\nThe early adopters tended to be in the news media, where the cost was negated by the utility and the ability to transmit images by telephone lines. The poor image quality was offset by the low resolution of newspaper graphics. This capability to transmit images without a satellite link was useful during the Tiananmen Square protests of 1989 and the first Gulf War in 1991.\n\nUS government agencies also took a strong interest in the still video concept, notably the US Navy for use as a real time air-to-sea surveillance system.\n\nThe first analog electronic camera marketed to consumers may have been the Casio VS-101 in 1987. A notable analog camera produced the same year was the Nikon QV-1000C, designed as a press camera and not offered for sale to general users, which sold only a few hundred units. It recorded images in greyscale, and the quality in newspaper print was equal to film cameras. In appearance it closely resembled a modern digital single-lens reflex camera. Images were stored on video floppy disks.\n\nSilicon Film, a proposed digital sensor cartridge for film cameras that would allow 35 mm cameras to take digital photographs without modification was announced in late 1998. Silicon Film was to work like a roll of 35 mm film, with a 1.3 megapixel sensor behind the lens and a battery and storage unit fitting in the film holder in the camera. The product, which was never released, became increasingly obsolete due to improvements in digital camera technology and affordability. Silicon Films' parent company filed for bankruptcy in 2001.\n\nBy the late 1980s, the technology required to produce truly commercial digital cameras existed. The first true portable digital camera that recorded images as a computerized file was likely the Fuji DS-1P of 1988, which recorded to a 2 MB SRAM memory card that used a battery to keep the data in memory. This camera was never marketed to the public.\n\nThe first digital camera of any kind ever sold commercially was possibly the MegaVision Tessera in 1987 though there is not extensive documentation of its sale known. The first \"portable\" digital camera that was actually marketed commercially was sold in December 1989 in Japan, the DS-X by\nFuji The first commercially available portable digital camera in the United States was the Dycam Model 1, first shipped in November 1990. It was originally a commercial failure because it was black and white, low in resolution, and cost nearly $1,000 (about $2000 in 2014). It later saw modest success when it was re-sold as the Logitech Fotoman in 1992. It used a CCD image sensor, stored pictures digitally, and connected directly to a computer for download.\n\nIn 1991, Kodak brought to market the Kodak DCS (Kodak Digital Camera System), the beginning of a long line of professional Kodak DCS SLR cameras that were based in part on film bodies, often Nikons. It used a 1.3 megapixel sensor, had a bulky external digital storage system and was priced at $13,000. At the arrival of the Kodak DCS-200, the Kodak DCS was dubbed Kodak DCS-100.\n\nThe move to digital formats was helped by the formation of the first JPEG and MPEG standards in 1988, which allowed image and video files to be compressed for storage. The first consumer camera with a liquid crystal display on the back was the Casio QV-10 developed by a team led by Hiroyuki Suetaka in 1995. The first camera to use CompactFlash was the Kodak DC-25 in 1996.. The first camera that offered the ability to record video clips may have been the Ricoh RDC-1 in 1995.\n\nIn 1995 Minolta introduced the RD-175, which was based on the Minolta 500si SLR with a splitter and three independent CCDs. This combination delivered 1.75M pixels. The benefit of using an SLR base was the ability to use any existing Minolta AF mount lens. 1999 saw the introduction of the Nikon D1, a 2.74 megapixel camera that was the first digital SLR developed entirely from the ground up by a major manufacturer, and at a cost of under $6,000 at introduction was affordable by professional photographers and high-end consumers. This camera also used Nikon F-mount lenses, which meant film photographers could use many of the same lenses they already owned.\n\nDigital camera sales continued to flourish, driven by technology advances. The digital market segmented into different categories, Compact Digital Still Cameras, Bridge Cameras, Mirrorless Compacts and Digital SLRs. One of the major technology advances was the development of CMOS sensors, which helped drive sensor costs low enough to enable the widespread adoption of camera phones.\n\nSince 2003, digital cameras have outsold film cameras and Kodak announced in January 2004 that they would no longer sell Kodak-branded film cameras in the developed world - and 2012 filed for bankruptcy after struggling to adapt to the changing industry. Smartphones now routinely include high resolution digital cameras.\n\n\nNotes\n"}
{"id": "4166493", "url": "https://en.wikipedia.org/wiki?curid=4166493", "title": "Hourglass", "text": "Hourglass\n\nAn hourglass (or sandglass, sand timer, or sand clock) is a device used to measure the passage of time. It comprises two glass bulbs connected vertically by a narrow neck that allows a regulated trickle of material (historically sand) from the upper bulb to the lower one. Factors affecting the time interval measured include sand quantity, sand coarseness, bulb size, and neck width. Hourglasses may be reused indefinitely by inverting the bulbs once the upper bulb is empty. Depictions of hourglasses in art survive in large numbers from antiquity to the present day, as a symbol for the passage of time. These were especially common sculpted as epitaphs on tombstones or other monuments, also in the form of the winged hourglass, a literal depiction of the well-known Latin epitaph \"tempus fugit\" (\"time flies\").\n\nThe origin of the hourglass is unclear. Its predecessor the clepsydra, or water clock, is known to have existed in Babylon and Egypt as early as the 16th century BCE. According to the \"Journal of the British Archaeological Association\" the so-called clepsammia were in use before the time of St. Jerome (335 CE), and the first potential representation of an hourglass is in a sarcophagus dated c. 350 CE, representing the wedding of Peleus and Thetis, discovered in Rome in the 18th century, and studied by Winckelmann in the 19th century, who remarked on the hourglass held by Morpheus in his hands However, it is disputed whether the object in question is a clepsammia or a similarly-shaped clepsydra; no other hourglass clearly appears in the historical record for another thousand years.\n\nThere are no records of the hourglass existing in Europe prior to the Early Middle Ages, such as invention by the Ancient Greeks; the first supported evidences appears from the 8th century CE, crafted by a Frankish monk named Liutprand who served at the cathedral in Chartres, France. But it was not until the 14th century that the hourglass was seen commonly, the earliest firm evidence being a depiction in the 1338 fresco \"Allegory of Good Government\" by Ambrogio Lorenzetti.\n\nUse of the marine sandglass has been recorded since the 14th century. The written records about it were mostly from logbooks of European ships. In the same period it appears in other records and lists of ships stores. The earliest recorded reference that can be said with certainty to refer to a marine sandglass dates from c. 1345, in a receipt of Thomas de Stetesham, clerk of the King's ship \"La George\", in the reign of Edward III of England; translated from the Latin, the receipt says: in 1345:\n\"The same Thomas accounts to have paid at Lescluse, in Flanders, for twelve glass horologes (\" pro xii. orlogiis vitreis \"), price of each 4½ gross', in sterling 9\"s.\" Item, For four horologes of the same sort (\" de eadem secta \"), bought there, price of each five gross', making in sterling 3\"s.\" 4\"d.\"\" \n\nMarine sandglasses were very popular on board ships, as they were the most dependable measurement of time while at sea. Unlike the clepsydra, the motion of the ship while sailing did not affect the hourglass. The fact that the hourglass also used granular materials instead of liquids gave it more accurate measurements, as the clepsydra was prone to get condensation inside it during temperature changes. Seamen found that the hourglass was able to help them determine longitude, distance east or west from a certain point, with reasonable accuracy.\n\nThe hourglass also found popularity on land. As the use of mechanical clocks to indicate the times of events like church services became more common, creating a \"need to keep track of time\", the demand for time-measuring devices increased. Hourglasses were essentially inexpensive, as they required no rare technology to make and their contents were not hard to come by, and as the manufacturing of these instruments became more common, their uses became more practical.\n\nHourglasses were commonly seen in use in churches, homes, and work places to measure sermons, cooking time, and time spent on breaks from labor. Because they were being used for more everyday tasks, the model of the hourglass began to shrink. The smaller models were more practical and very popular as they made timing more discreet.\n\nAfter 1500, the hourglass was not as widespread as it had been. This was due to the development of the mechanical clock, which became more accurate, smaller and cheaper, and made keeping time easier. The hourglass, however, did not disappear entirely. Although they became relatively less useful as clock technology advanced, hourglasses remained desirable in their design. The oldest known surviving hourglass resides in the British Museum in London.\n\nNot until the 18th century did John Harrison come up with a marine chronometer that significantly improved on the stability of the hourglass at sea. Taking elements from the design logic behind the hourglass, he made a marine chronometer in 1761 that was able to accurately measure the journey from England to Jamaica accurate within five seconds.\n\nLittle written evidence exists to explain why its external form is the shape that it is. The glass bulbs used, however, have changed in style and design over time. While the main designs have always been ampoule in shape, the bulbs were not always connected. The first hourglasses were two separate bulbs with a cord wrapped at their union that was then coated in wax to hold the piece together and let sand flow in between. It was not until 1760 that both bulbs were blown together to keep moisture out of the bulbs and regulate the pressure within the bulb that varied the flow.\n\nWhile some early hourglasses actually did use sand as the granular mixture to measure time, many did not use sand at all. The material used in most bulbs was a combination of \"powdered marble, tin/lead oxides, and pulverized, burnt eggshell\". Over time, different textures of granule matter were tested to see which gave the most constant flow within the bulbs. It was later discovered that for the perfect flow to be achieved the ratio of granule bead to the width of the bulb neck needed to be 1/12 or more but not greater than 1/2 the neck of the bulb.\n\nHourglasses were an early dependable and accurate measure of time. The rate of flow of the sand is independent of the depth in the upper reservoir, and the instrument will not freeze in cold weather. From the 15th century onwards, hourglasses were being used in a range of applications at sea, in the church, in industry, and in cookery.\nDuring the voyage of Ferdinand Magellan around the globe, 18 hourglasses from Barcelona were in the ship's inventory, after the trip had been authorized by King Charles I of Spain. It was the job of a ship's page to turn the hourglasses and thus provide the times for the ship's log. Noon was the reference time for navigation, which did not depend on the glass, as the sun would be at its zenith. A number of sandglasses could be fixed in a common frame, each with a different operating time, e.g. as in a four-way Italian sandglass likely from the 17th century, in the collections of the Science Museum, in South Kensington, London, which could measure intervals of quarter, half, three-quarters, and one hour (and which were also used in churches, for priests and ministers to measure lengths of sermons).\n\nWhile they are no longer widely used for keeping time, some institutions do maintain them. Both houses of the Australian Parliament use three hourglasses to time certain procedures, such as divisions.\n\nThe sandglass is still widely used as the kitchen egg timer; for cooking eggs, a three-minute timer is typical, hence the name \"egg timer\" for three-minute hourglasses. Egg timers are sold widely as souvenirs.\nSand timers are also sometimes used in games such as Pictionary and Boggle to implement a time constraint on rounds of play.\n\nUnlike most other methods of measuring time, the hourglass concretely represents the present as being between the past and the future, and this has made it an enduring symbol of time itself.\n\nThe hourglass, sometimes with the addition of metaphorical wings, is often depicted as a symbol that human existence is fleeting, and that the \"sands of time\" will run out for every human life. It was used thus on pirate flags, to strike fear into the hearts of the pirates' victims. In England, hourglasses were sometimes placed in coffins, and they have graced gravestones for centuries. The hourglass was also used in alchemy as a symbol for hour.\n\nThe former Metropolitan Borough of Greenwich in London used an hourglass on its coat of arms, symbolising Greenwich's role as the origin of GMT. The district's successor, the Royal Borough of Greenwich, uses two hourglasses on its coat of arms.\n\nRecognition of the hourglass as a symbol of time has survived its obsolescence as a timekeeper. For example, the American television soap opera \"Days of Our Lives\", since its first broadcast in 1965, has displayed an hourglass in its opening credits, with the narration, \"Like sands through the hourglass, so are the days of our lives,\" spoken by Macdonald Carey.\n\nVarious computer graphical user interfaces may change the pointer to an hourglass during a period when the program is in the middle of a task, and may not accept user input. During that period other programs, for example in different windows, may work normally. When such an hourglass does not disappear, it suggests a program is in an infinite loop and needs to be terminated, or is waiting for some external event (such as the user inserting a CD). Unicode has an symbol at codice_1 (⌛).\n\nBecause of its symmetry, graphic signs resembling an hourglass are seen in the art of cultures which never encountered such objects. Vertical pairs of triangles joined at the apex are common in Native American art; both in North America, where it can represent, for example, the body of the Thunderbird or (in more elongated form) an enemy scalp, and in South America, where it is believed to represent a Chuncho jungle dweller. In Zulu textiles they symbolise a married man, as opposed to a pair of triangles joined at the base, which symbolise a married woman. Neolithic examples can be seen among Spanish cave paintings. Observers have even given the name \"hourglass motif\" to shapes which have more complex symmetry, such as a repeating circle and cross pattern from the Solomon Islands. Both the members of Project Tic Toc,from television series the Time Tunnel and the Challengers of the Unknown use symbols of the hourglasse representing either time travel or time running out.\n\n\nBooks\n\nPeriodicals\n"}
{"id": "23094504", "url": "https://en.wikipedia.org/wiki?curid=23094504", "title": "IEEE 802.1aq", "text": "IEEE 802.1aq\n\nShortest Path Bridging (SPB), specified in the IEEE 802.1aq standard, is a computer networking technology intended to simplify the creation and configuration of networks, while enabling multipath routing.\n\nIt is the replacement for the older spanning tree protocols: IEEE 802.1D, IEEE 802.1w, IEEE 802.1s. These blocked any redundant paths that could result in a layer 2 loop, whereas SPB allows all paths to be active with multiple equal cost paths, provides much larger layer 2 topologies, supports faster convergence times, and improves the efficiency by allowing traffic to load share across all paths of a mesh network. It is designed to virtually eliminate human error during configuration and preserves the plug-and-play nature that established Ethernet as the de facto protocol at layer 2.\n\nThe technology provides logical Ethernet networks on native Ethernet infrastructures using a link state protocol to advertise both topology and logical network membership. Packets are encapsulated at the edge either in media access control-in-media access control (MAC-in-MAC) \"802.1ah\" or tagged \"802.1Q/802.1ad\" frames and transported only to other members of the logical network. Unicast, multicast, and broadcast are supported and all routing is on symmetric shortest paths.\n\nThe control plane is based on the Intermediate System to Intermediate System (IS-IS), leveraging a small number of extensions defined in RFC 6329.\n\nOn 4 March 2006 the working group posted 802.1aq draft 0.1.\n\nIn December 2011, Shortest Path Bridging (SPB) was evaluated by the JITC and approved for deployment within the US Department of Defense (DoD) because of the ease in integrated OA&M and interoperability with current protocols. On March 2012 the IEEE approved the 802.1aq standard.\n\nIn 2012, it was stated by David Allan and Nigel Bragg, in \"802.1aq Shortest Path Bridging Design and Evolution: The Architect's Perspective\" that shortest path bridging is one of the most significant enhancements in Ethernet's history.\n\nIn May 2013, the first public multi-vendor interoperability was demonstrated as SPB served as the backbone for Interop 2013 in Las Vegas.\n\nThe 2014 Winter Olympics were the first \"fabric-enabled\" Games using Shortest Path Bridging (SPB) \"IEEE 802.1aq\" technology. During the games this fabric network was capable of handling up to 54,000 Gbit/s (54 Tbit/s) of traffic. In 2013 and 2014 SPB was used to build the InteropNet backbone with only 1/10 the resources of prior years. During Interop 2014 SPB was used as the backbone protocol which can enable Software-defined networking (SDN) functionalities.\n\n\nShortest Path Bridging - VID (SPBV) and Shortest Path Bridging - MAC (SPBM) are two operating modes of 802.1aq, and are described in more detail below. Both inherit key benefits of link state routing:\n\nVirtualisation is becoming an increasingly important aspect of a number of key applications, in both carrier and enterprise space, and SPBM, with its MAC-in-MAC datapath providing complete separation between client and server layers, is uniquely suitable for these.\n\n\"Data Centre virtualisation\" articulates the desire to flexibly and efficiently harness available compute resources in a way that may rapidly be modified to respond to varying application demands, without the need to dedicate physical resources to a specific application. One aspect of this is server virtualisation. The other is connectivity virtualisation, because a physically distributed set of server resources must be attached to a single IP subnet, and modifiable in an operationally simple and robust way. SPBM delivers this; because of its client-server model, it offers a perfect emulation of a transparent Ethernet LAN segment, which is the IP subnet seen at layer 3. A key component of how it does this is implementing VLANs with scoped multicast trees, which means no egress discard of broadcast/unknown traffic, a feature common to approaches that use a small number of shared trees, hence the network does not simply degrade with size as the percentage of frames discarded goes up. It also supports \"single touch\" provisioning, so that configuration is simple and robust; the port of a virtual server must simply be bound locally to the SPBM I-SID identifying the LAN segment, after which IS-IS for SPB floods this binding, and all nodes that need to install forwarding state to implement the LAN segment do so automatically.\n\nThe carrier-space equivalent of this application is the delivery of Ethernet VPN services to Enterprises over common carrier infrastructure. The required attributes are fundamentally the same; complete transparency for customer Ethernet services (both point-to-point and LAN), and complete isolation between one customer's traffic and that of all other customers. The multiple virtual LAN segment model provides this, and the single-touch provisioning model eases carrier operations. Furthermore, the MAC-in-MAC datapath allows the carrier to deploy the \"best in class\" Ethernet OAM suit (IEEE 802.1ag, etc.), entirely transparently and independently from any OAM which a customer may choose to run.\n\nA further consequence of SPBM's transparency in both dataplane and control plane is that it provides a perfect, \"no compromise\" delivery of the complete MEF 6.1 service set. This includes not only E-LINE and E-LAN constructs, by also E-TREE (hub-and-spoke) connectivity. This latter is clearly very relevant to enterprise customers of carrier VPN/MPLS services which have this network structure internally. It also provides the carrier with the toolkit to support geo-redundant broadband backhaul; in this applications, many DSLAMs or other access equipments must be backhauled to multiple Broadband Remote Access Server (BRAS) sites, with application-determined binding of sessions to a BRAS. However, DSLAMs must not be allowed to communicate with each other, because carriers then lose the ability to control peer-to-peer connectivity. MEF E-TREE does just this, and further provides an efficient multicast fabric for the distribution of IP TV.\n\nSPBM offers both the ideal multicast replication model, where packets are replicated only at fork points in the shortest path tree that connects members, and also the less state intensive head end replication model where in essence serial unicast packets are sent to all other members along the same shortest path first tree. These two models are selected by specifying properties of the service at the edge which affect the transit node decisions on multicast state installation. This allows for a trade-off to be made between optimum transit replication points (with their larger state costs) v.s. reduced core state (but much more traffic) of the head end replication model. These selections can be different for different members of the same Individual Service ID (I-SID) allowing different trade-offs to be made for different members.\n\nFigure 5 below is a quick way to understand what SPBM is doing on the scale of the entire network. Figure 5 shows how a 7-member E-LAN is created from the edge membership information and the deterministic distributed calculation of per source, per service trees with transit replication. Head end replication is not shown as it is trivial and simply uses the existing unicast FIBs to forward copies serially to the known other receivers.\n\n802.1aq builds on all existing Ethernet Operations, administration and management (OA&M). Since 802.1aq ensures that its unicast and multicast packets for a given virtual lan (VLAN) follow the same forward and reverse path and use completely standard 802 encapsulations, all of the methods of 802.1ag and Y.1731 operate unchanged on an 802.1aq network.\n\nSee IEEE 802.1ag and ITU-recommendation Y.1731.\n\n802.1aq is the Institute of Electrical and Electronics Engineers (IEEE) sanctioned link state Ethernet control plane for all IEEE VLANs covered in IEEE 802.1Q. Shortest Path Bridging virtual local area network identifier (VLAN ID) or Shortest Path Bridging VID (SPBV) provides capability that is backwards compatible with spanning tree technologies. Shortest Path Bridging Media Access Control (MAC) or (SPBM), (previously known as Provider Backbone Bridge PBB) provides additional values which capitalize on Provider Backbone Bridge (PBB) capabilities. SPB (the generic term for both) combines an Ethernet data path (either IEEE 802.1Q in the case of SPBV, or Provider Backbone Bridges (PBBs) IEEE 802.1ah in the case of SPBM) with an IS-IS link state control protocol running between Shortest Path bridges (network-to-network interface (NNI) links). The link state protocol is used to discover and advertise the network topology and compute shortest path trees (SPT) from all bridges in the SPT Region.\n\nIn SPBM, the Backbone MAC (B-MAC) addresses of the participating nodes and also the service membership information for interfaces to non-participating devices (user network interface (UNI) ports) is distributed. Topology data is then input to a calculation engine which computes symmetric shortest path trees based on minimum cost from each participating node to all other participating nodes. In SPBV these trees provide a shortest path tree where individual MAC address can be learned and Group Address membership can be distributed. In SPBM the shortest path trees are then used to populate forwarding tables for each participating node's individual B-MAC addresses and for Group addresses; Group multicast trees are sub trees of the default shortest path tree formed by (Source, Group) pairing. Depending on the topology several different equal cost multi path trees are possible and SPB supports multiple algorithms per IS-IS instance.\n\nIn SPB as with other link state based protocols, the computations are done in a distributed fashion. Each node computes the Ethernet compliant forwarding behavior independently based on a normally synchronized common view of the network (at scales of about 1000 nodes or less) and the service attachment points (user network interface (UNI) ports). Ethernet filtering Database (or forwarding) tables are populated locally to independently and deterministically implement its portion of the network forwarding behavior.\n\nThe two different flavors of data path give rise to two slightly different versions of this protocol. One (SPBM) is intended where complete isolation of many separate instances of client LANs and their associated device MAC addresses is desired, and it therefore uses a full encapsulation (MAC-in-MAC a.k.a. IEEE 802.1ah). The other (SPBV) is intended where such isolation of client device MAC addresses is not necessary, and it reuses only the existing VLAN tag a.k.a. IEEE 802.1Q on participating network-to-network interface (NNI) links.\n\nChronologically SPBV came first, with the project originally being conceived to address scalability and convergence of MSTP.\n\nAt the time the specification of Provider Backbone bridging was progressing and it became apparent that leveraging both the PBB data plane and a link state control plane would significantly extend Ethernet's capabilities and applications. Provider Link State Bridging (PLSB) was a strawman proposal brought to the IEEE 802.1aq Shortest Path Bridging Working Group, in order to provide a concrete example of such a system. As IEEE 802.1aq standardization has progressed, some of the detailed mechanisms proposed by PLSB have been replaced by functional equivalents, but all of the key concepts embodied in PLSB are being carried forward into the standard.\n\nThe two flavors (SPBV and SPBM) will be described separately although the differences are almost entirely in the data plane.\n\nShortest Path bridging enables shortest path trees for VLAN Bridges all IEEE 802.1 data planes and SPB is the term used in general. Recently there has been a lot of focus on SPBM as explained due to its ability to control the new PBB data plane and leverage certain capabilities such as removing the need to do B-MAC learning and automatically creating individual (unicast) and group (multicast) Trees. SPBV was actually the original project that endeavored to enable Ethernet VLANs to better utilize mesh networks.\n\nA primary feature of Shortest Path bridging is the ability to use Link State IS-IS to learn network topology. In SPBV the mechanism used to identify the tree is to use a different Shortest Path VLAN ID (VID) for each source bridge. The IS-IS topology is leveraged both to allocate unique SPVIDs and to enable shortest path forwarding for individual and group addresses. Originally targeted for small low configuration networks SPB grew into a larger project encompassing the latest provider control plane for SPBV and harmonizing the concepts of Ethernet data plane. Proponents of SPB believe that Ethernet can leverage link state and maintain the attributes that have made Ethernet one of the most encompassing data plane transport technologies. When we refer to Ethernet it is the layer 2 frame format defined by IEEE 802.3 and IEEE 802.1. Ethernet VLAN bridging IEEE 802.1Q is the frame forwarding paradigm that fully supports higher level protocols such as IP.\n\nSPB defines a shortest path Region which is the boundary of the shortest path topology and the rest of the VLAN topology (which may be any number of legacy bridges.) SPB operates by learning the SPB capable bridges and growing the Region to include the SPB capable bridges that have the same Base VID and MSTID configuration digest (Allocation of VIDs for SPB purposes).\n\nSPBV builds shortest path trees that support Loop Prevention and optionally support loop mitigation on the SPVID. SPBV still allows learning of Ethernet MAC addresses but it can distribute multicast address that can be used to prune the shortest path trees according to the multicast membership either through Multiple MAC Registration Protocol (MMRP) or directly using IS-IS distribution of multicast membership.\n\nSPBV builds shortest path trees but also interworks with legacy bridges running Rapid Spanning Tree Protocol and Multiple Spanning Tree Protocol. SPBV uses techniques from MSTP Regions to interwork with non-SPT regions behaving logically as a large distributed bridge as viewed from outside the region.\n\nSPBV supports shortest path trees but SPBV also builds a spanning tree which is computed from the link state database and uses the Base VID. This means that SPBV can use this traditional spanning tree for computation of the Common and Internal Spanning Tree (CIST). The CIST is the default tree used to interwork with other legacy bridges. It also serves as a fall back spanning tree if there are configuration problems with SPBV.\n\nSPBV has been designed to manage a moderate number of bridges. SPBV differs from SPBM in that MAC addresses are learned on all bridges that lie on the shortest path and a shared VLAN learning is used since destination MACs may be associated with multiple SPVIDs. SPBV learns all MACs it forwards even outside the SPBV region.\n\nSPBM reuses the PBB data plane which does not require that the Backbone Core Bridges (BCB) learn encapsulated client addresses. At the edge of the network the C-MAC (client) addresses are learned. SPBM is very similar to PLSB (Provider Link State Bridging) using the same data and control planes but the format and contents of the control messages in PLSB are not compatible.\n\nIndividual MAC frames (unicast traffic) from an Ethernet attached device that are received at the SPBM edge are encapsulated in a PBB (mac-in-mac) IEEE 802.1ah header and then traverse the IEEE 802.1aq network unchanged until they are stripped of the encapsulation as they egress back to the non participating attached network at the far side of the participating network.\n\nEthernet destination addresses (from UNI port attached devices) perform learning over the logical LAN and are forwarded to the appropriate participating B-MAC address to reach the far end Ethernet destination. In this manner Ethernet MAC addresses are never looked up in the core of an IEEE 802.1aq network. When comparing SPBM to PBB, the behavior is almost identical to a PBB IEEE 802.1ah network. PBB does not specify how B-MAC addresses are learned and PBB may use a spanning tree to control the B-VLAN. In SPBM the main difference is that B-MAC address are distributed or computed in the control plane, eliminating the B-MAC learning in PBB. Also SPBM ensures that the route followed is shortest path tree.\n\nThe forward and reverse paths used for unicast and multicast traffic in an IEEE 802.1aq network are symmetric. This symmetry permits the normal Ethernet Continuity Fault Messages (CFM) IEEE 802.1ag to operate unchanged for SPBV and SPBM and has desirable properties with respect to time distribution protocols such as Precision Time Protocol (PTP Version 2). Also existing Ethernet loop prevention is augmented by loop mitigation to provide fast data plane convergence.\n\nGroup address and unknown destination individual frames are optimally transmitted to only members of the same Ethernet service. IEEE 802.1aq supports the creation of thousands of logical Ethernet services in the form of E-LINE, E-LAN or E-TREE constructs which are formed between non participating logical ports of the IEEE 802.1aq network. These group address packets are encapsulated with a PBB header which indicates the source participating address in the SA while the DA indicates the locally significant group address this frame should be forwarded on and which source bridge originated the frame. The IEEE 802.1aq multicast forwarding tables are created based on computations such that every bridge which is on the shortest path between a pair of bridges which are members of the same service group will create proper forwarding database (FDB) state to forward or replicate frames it receives to that members of that service group. Since the group address computation produce shortest path trees, there is only ever one copy of a multicast packet on any given link. Since only bridges on a shortest path between participating logical ports create forwarding database (FDB) state the multicast makes the efficient use of network resources.\n\nThe actual group address forwarding operation operates more or less identically to classical Ethernet, the backbone destination address (B-DA)+ backbone VLAN identifier (B-VID) combination are looked up to find the egress set of next hops. The only difference compared with classical Ethernet is that reverse learning is disabled for participating bridge backbone media access control (B-MAC) addresses and is replaced with an ingress check and discard (when the frame arrives on an incoming interface from an unexpected source). Learning is however implemented at the edges of the SPBM multicast tree to learn the B-MAC to MAC address relationship for correct individual frame encapsulation in the reverse direction (as packets arrive over the Interface).\n\nProperly implemented an IEEE 802.1aq network can support up to 1000 participating bridges and provide tens of thousands of layer 2 E-LAN services to Ethernet devices. This can be done by simply configuring the ports facing the Ethernet devices to indicate they are members of a given service. As new members come and go, the IS-IS protocol will advertise the I-SID membership changes and the computations will grow or shrink the trees in the participating node network as necessary to maintain the efficient multicast property for that service.\n\nIEEE 802.1aq has the property that only the point of attachment of a service needs configuration when a new attachment point comes or goes. The trees produced by the computations will automatically be extended or pruned as necessary to maintain connectivity. In some existing implementations this property is used to automatically (as opposed to through configuration) add or remove attachment points for dual-homed technologies such as rings to maintain optimum packet flow between a nonparticipating ring protocol and the IEEE 802.1aq network by activating a secondary attachment point and deactivating a primary attachment point.\n\nFailure recovery is as per normal IS-IS with the link failure being advertised and new computations being performed, resulting in new FDB tables. Since no Ethernet addresses are advertised or known by this protocol, there is no re-learning required by the SPBM core and its learned encapsulations are unaffected by a transit node or link failure.\n\nFast link failure detection may be performed using IEEE 802.1ag Continuity Check Messages (CCMs) which test link status and report a failure to the IS-IS protocol. This allows much faster failure detection than is possible using the IS-IS hello message loss mechanisms.\n\nBoth SPBV and SPBM inherit the rapid convergence of a link state control plane. A special attribute of SPBM is its ability to rebuild multicast trees in a similar time to unicast convergence, because it substitutes computation for signaling. When an SPBM bridge has performed the computations on a topology database, it knows whether it is on the shortest path between a root and one or more leaves of the SPT and can install state accordingly. Convergence is not gated by incremental discovery of a bridge’s place on a multicast tree by the use of separate signaling transactions. However, SPBM on a node does not operate completely independently of its peers, and enforces agreement on the current network topology with its peers. This very efficient mechanism uses exchange of a single digest of link state covering the entire network view, and does not need agreement on each path to each root individually. The result is that the volume of messaging exchanged to converge the network is in proportion to the incremental change in topology and not the number of multicast trees in the network. A simple link event that may change many trees is communicated by signaling the link event only; the consequent tree construction is performed by local computation at each node. The addition of a single service access point to a service instance involves only the announcement of the I-SID, regardless of the number of trees. Similarly the removal of a bridge, which might involve the rebuilding of hundreds to thousands of trees, is signaled only with a few link state updates.\n\nCommercial offerings will likely offer SPB over multi-chassis lag. In this environment multiple switch chassis appear as a single switch to the SPB control plane, and multiple links between pairs of chassis appear as an aggregate link. In this context a single link or node failure is not seen by the control plane and is handled locally resulting in sub 50ms recovery times.\n\nFollowing are three animated GIFs which help to show the behavior of 802.1aq.\n\nThe first of these gifs, shown in Figure 5, demonstrates the routing in a 66 node network where we have created a 7-member E-LAN using ISID 100. In this example we show the ECT tree created from each member to reach all of the other members. We cycle through each member to show the full set of trees created for this service. We pause at one point to show the symmetry of routing between two of the nodes and emphasize it with a red line. In each case the source of the tree is highlighted with a small purple V.\n\nThe second of these animated gifs, shown in Figure 6, demonstrates 8 ECT paths in the same 66 node network as Figure 4. In each subsequent animated frame the same source is used (in purple) but a different destination is shown (in yellow). For each frame, all of the shortest paths are shown superimposed between the source and destination. When two shortest paths traverse the same hop, the thickness of the lines being drawn is increased. In addition to the 66 node network, a small multi level Data Center style network is also shown with sources and destinations both within the servers (at the bottom) and from servers to the router layer at the top. This animation helps to show the diversity of the ECT being produced.\n\nThe last of these animated gifs, shown in Figure 7, demonstrates source destination ECT paths using all 16 of the standard algorithms currently defined.\n\nSixteen equal cost multi tree (ECMT) paths are initially defined, however there are many more possible. ECMT in an IEEE 802.1aq network is more predictable than with internet protocol (IP) or multiprotocol label switching (MPLS) because of symmetry between the forward and reverse paths. The choice as to which ECMT path will be used is therefore an operator assigned head end decision while it is a local / hashing decision with IP/MPLS.\n\nIEEE 802.1aq, when faced with a choice between two equal link cost paths, uses the following logic for its first ECMT tie breaking algorithm: first, if one path is shorter than the other in terms of hops, the shorter path is chosen, otherwise, the path with the minimum Bridge Identifier { BridgePriority concatenated with (IS-IS SysID) } is chosen. Other ECMT algorithms are created by simply using known permutations of the BridgePriority||SysIds. For example, the second defined ECMT algorithm uses the path with the minimum of the inverse of the BridgeIdentifier and can be thought of as taking the path with the maximum node identifier. For SPBM, each permutation is instantiated as a distinct B-VID. The upper limit of multipath permitations is gated by the number of B-VIDs delegated to 802.1aq operation, a maximum of 4094, although the number of useful path permutations would only require a fraction of the available B-VID space. Fourteen additional ECMT algorithms are defined with different bit masks applied to the BridgeIdentifiers. Since the BridgeIdentfier includes a priority field, it is possible to adjust the ECMT behavior by changing the BridgePriority up or down.\n\nA service is assigned to a given ECMT B-VID at the edge of the network by configuration. As a result, non participating packets associated with that service are encapsulated with the VID associated with the desired ECMT end to end path. All individual and group address traffic associated with this service will therefore use the proper ECMT B-VID and be carried symmetrically end to end on the proper equal cost multi path. Essentially the operator decides which services go in which ECMT paths, unlike a hashing solution used in other systems such as IP/MPLS. Trees can support link aggregation (LAG) groups within a tree \"branch\" segment where some form of hashing occurs.\n\nThis symmetric and end to end ECMT behavior gives IEEE 802.1aq a highly predictable behavior and off line engineering tools can accurately model exact data flows. The behavior is also advantageous to networks where one way delay measurements are important. This is because the one way delay can be accurately computed as 1/2 the round trip delay. Such computations are used by time distribution protocols such as IEEE 1588 for frequency and time of day synchronization as required between precision clock sources and wireless base stations.\n\nShown below are three figures [5,6,7] which show 8 and 16 equal cost tree (ECT) behavior in different network topologies. These are composites of screen captures of an 802.1aq network emulator and show the source in purple, the destination in yellow, and then all the computed and available shortest paths in pink. The thicker the line, the more shortest paths use that link. The animations shows three different networks and a variety of source and destination pairs which continually change to help visualize what is happening.\n\nThe equal cost tree (ECT) algorithms can be almost extended through the use of OPAQUE data which allows extensions beyond the base 16 algorithms more or less infinitely. It is expected that other standards groups or vendors will produce variations on the currently defined algorithms with behaviors suited for different networks styles. It is expected that numerous shared tree models will also be defined, as will hop by hop hash based equal-cost multi-path (ECMP) style behaviors .. all defined by a VID and an algorithm that every node agrees to run.\n\n802.1aq does not spread traffic on a hop by hop basis. Instead, 802.1aq allows assignment of a Service ID (ISID) to a Vlan ID (VID) at the edge of the network. A VID will correspond to exactly one of the possible sets of shortest paths in the network and will never stray from that routing. If there are 10 or so shortest paths between different nodes, it is possible to assign different services to different paths and to know that the traffic for a given service will follow exactly the given path. In this manner traffic can easily be assigned to the desired shortest path. In the event that one of the paths becomes overloaded it is possible to move some services off those shortest paths by reassigning the services ISID to a different, less loaded, VID at the edges of the network.\n\nThe deterministic nature of the routing makes offline prediction/computation/experimentation of the network loading much simpler since actual routes are not dependent on the contents of the packet headers with the exception of the VLAN identifier.\n\nFigure 4 shows four different equal cost paths between nodes 7 and 5. An operator can achieve relatively good balance of traffic across the cut between nodes [0 and 2] and [1 and 3] by assigning the services at nodes 7 and 5 to one of the four desired VIDs. Using more than 4 equal cost tree (ECT) paths in the network will likely allow all 4 of these paths to be used. Balance can also be achieved between nodes 6 and 4 in a similar manner.\n\nIn the event that an operator does not wish to manually assign services to shortest paths it is a simple matter for a switch vendor to allow a simple hash of the ISID to one of the available VIDS to give a degree of non-engineered spreading. For example, the ISID modulo the number of ECT-VIDs could be used to decide on the actual relative VID to use.\n\nIn the event that the ECT paths are not sufficiently diverse the operator has the option of adjusting the inputs to the distributed ECT algorithms to apply attraction or repulsion from a given node by adjusting that node's Bridge Priority. This can be experimented with via offline tools until the desired routes are achieved at which point the bias can be applied to the real network and then ISIDs can be moved to the resulting routes.\n\nLooking at the animations in Figure 6 shows the diversity available for traffic engineering in a 66 node network. In this animation there are 8 ECT paths available from each highlighted source to destination and therefore services could be assigned to 8 different pools based on the VID. One such initial assignment in Figure 6 could therefore be (ISID modulo 8) with subsequent fine tuning as required.\n\nWe will work through SPBM behavior on a small example, with emphasis on the shortest path trees for unicast and multicast.\n\nThe network shown in Figure 1 consists of 8 participating nodes numbered 0 through 7. These would be switches or routers running the IEEE 802.1aq protocol. Each of the 8 participating nodes has a number of adjacencies numbered 1..5. These would likely correspond to interface indexes, or possibly port numbers. Since 802.1aq does not support parallel interfaces each interface corresponds to an adjacency. The port / interface index numbers are of course local and are shown because the output of the computations produce an interface index (in the case of unicast) or a set of interface indexes (in the case of multicast) which are part of the forwarding information base (FIB) together with a destination MAC address and backbone VID.\n\nThe network has a fully meshed inner core of four nodes (0..3) and then four outer nodes (4,5,6 and 7), each dual-homed onto a pair of inner core nodes.\n\nNormally when nodes come from the factory they have a MAC address assigned which becomes a node identifier but for the purpose of this example we will assume that the nodes have MAC addresses of the form 00:00:00:00:N:00 where N is the node id (0..7) from Figure 1. Therefore, node 2 has a MAC address of 00:00:00:00:02:00. Node 2 is connected to node 7 (00:00:00:00:07:00) via node 2's interface/5.\n\nThe IS-IS protocol runs on all the links shown since they are between participating nodes. The IS-IS hello protocol has a few additions for 802.1aq including information about backbone VIDs to be used by the protocol. We will assume that the operator has chosen to use backbone VIDs 101 and 102 for this instance of 802.1aq on this network.\n\nThe node will use their MAC addresses as the IS-IS SysId and join a single IS-IS level and exchange link state packets (LSPs in IS-IS terminology). The LSPs will contain node information and link information such that every node will learn the full topology of the network. Since we have not specified any link weights in this example, the IS-IS protocol will pick a default link metric for all links, therefore all routing will be minimum hop count.\n\nAfter topology discovery the next step is distributed calculation of the unicast routes for both ECMP VIDs and population of the unicast forwarding tables (FIBs).\nConsider the route from Node 7 to Node 5: there are a number of equal cost paths. 802.1aq specifies how to choose two of them: the first is referred to as the Low PATH ID path. This is the path which has the minimum node id on it. In this case the Low PATH ID path is the 7->0->1->5 path (as shown in red in Figure 2). Therefore, each node on that path will create a forwarding entry toward the MAC address of node five using the first ECMP VID 101. Conversely, 802.1aq specifies a second ECMP tie breaking algorithm called High PATH ID. This is the path with the maximum node identifier on it and in the example is the 7->2->3->5 path (shown in blue in Figure 2).\n\nNode 7 will therefore have a FIB that among other things indicates:\n\n\nNode 5 will have exactly the inverse in its FIB:\n\n\nThe intermediate nodes will also produce consistent results so for example node 1 will have the following entries.\n\n\nAnd Node 2 will have entries as follows:\n\n\nIf we had an attached non participating device at Node 7 talking to a non participating device at Node 5 (for example Device A talks to Device C in Figure 3), they would communicate over one of these shortest paths with a MAC-in-MAC encapsulated frame. The MAC header on any of the NNI links would show an outer source address of 00:00:00:70:00, an outer destination address of 00:00:00:50:00 and a BVID of either 101 or 102 depending on which has been chosen for this set of non participating ports/vids. The header once inserted at node 7 when received from node A, would not change on any of the links until it egressed back to non participating Device C at Node 5. All participating devices would do a simple DA+VID lookup to determine the outgoing interface, and would also check that incoming interface is the proper next hop for the packet's SA+VID. The addresses of the participating nodes 00:00:00:00:00:00 ... 00:00:00:07:00 are never learned but are advertised by IS-IS as the node's SysId.\n\nUnicast forwarding to a non-participating client (e.g. A, B, C, D from Figure 3) address is of course only possible when the first hop participating node (e.g. 7) is able to know which last hop participating node (e.g. 5) is attached to the desired non participating node (e.g. C). Since this information is not advertised by IEEE 802.1aq it has to be learned. The mechanism for learning is identical to IEEE 802.1ah, in short, the corresponding outer MAC unicast DA, if not known is replaced by a multicast DA and when a response is received, the SA of that response now tells us the DA to use to reach the non participating node that sourced the response. e.g. node 7 learns that C is reached by node 5.\nSince we wish to group/scope sets of non participating ports into services and prevent them from multicasting to each other, IEEE 802.1aq provides mechanism for per source, per service multicast forwarding and defines a special multicast destination address format to provide this.\nSince the multicast address must uniquely identify the tree, and because there is a tree per source per unique service, the multicast address contains two components, a service component in the low order 24 bits and a network wide unique identifier in the upper 22 bits. Since this is a multicast address the multicast bit is set, and since we are not using the standard OUI space for these manufactured addresses, the Local 'L' bit is set to disambiguate these addresses. In Figure 3 above, this is represented with the DA=[7,O] where the 7 represents packets originating from node 7 and the colored O represents the E-LAN service we are scoped within.\n\nPrior to creating multicast forwarding for a service, nodes with ports that face that service must be told they are members. For example, nodes 7,4,5 and 6 are told they are members of the given service, for example service 200, and further that they should be using bvid 101. This is advertised by ISIS and all nodes then do the SPBM computation to determine if they are participating either as a head end or tail end, or a tandem point between other head and tail ends in the service. Since node 0 is a tandem between nodes 7 and 5 it creates a forwarding entry for packets from node 7 on this service, to node 5. Likewise, since it is a tandem between nodes 7 and 4 it creates forwarding state from node 7 for packets in this service to node 4 this results in a true multicast entry where the DA/VID have outputs on two interfaces 1 and 2. Node 2 on the other hand is only on one shortest path in this service and only creates a single forwarding entry from node 7 to node 6 for packets in this service.\n\nFigure 3 only shows a single E-LAN service and only the tree from one of the members, however very large numbers of E-LAN services with membership from 2 to every node in the network can be supported by advertising the membership, computing the tandem behaviors, manufacturing the known multicast addresses and populating the FIBs. The only real limiting factors are the FIB table sizes and computational power of the individual devices both of which are growing yearly in leaps and bounds.\n\n802.1aq takes IS-IS topology information augmented with service attachment (I-SID) information, does a series of computations and produces a forwarding table (filtering table) for unicast and multicast entries.\n\nThe IS-IS extensions that carry the information required by 802.1aq are given in the isis-layer2 IETF document listed below.\n\nAn implementation of 802.1aq will first modify the IS-IS hellos to include an NLPID (network layer protocol identifier) of 0xC01 in their Protocols-Supported Type-length-value (TLV) (type 129) which has been reserved for 802.1aq. The hellos also must include an MSTID (which gives the purpose of each VID) and finally each ECMT behavior must be assigned to a VID and exchanged in the hellos. The hellos would normally run untagged. Note that NLPID of IP is not required to form an adjacency for 802.1aq but also will not prevent an adjacency when present.\n\nThe links are assigned 802.1aq specific metrics which travel in their own TLV (Type Length Value) which is more or less identical to the IP link metrics. The calculations will always use the maximum of the two unidirectional link metrics to enforce symmetric route weights.\n\nThe node is assigned a mac address to identify it globally and this is used to form the IS-IS SYSID. A box mac would normally serve this purpose. The Area-Id is not directly used by 802.1aq but should, of course, be the same for nodes in the same 802.1aq network. Multiple areas/levels are not yet supported.\n\nThe node is further assigned an SPSourceID which is a 20 bit network wide unique identifier. This can often be the low 20 bits of the SYSID (if unique) or can be dynamically negotiated or manually configured.\n\nThe SPSourceID and the ECMT assignments to B-VIDs are then advertised into the IS-IS network in their own 802.1aq TLV.\n\nThe 802.1aq computations are restricted to links between nodes that have an 802.1aq link weight and which support the NLPID 0xC01. As previously discussed the link weights are forced to be symmetric for the purpose of computation by taking the min of two dissimilar values.\n\nWhen a service is configured in the form of an I-SID assignment to an ECMT behavior that I-SID is then advertised along with the desired ECMT behavior and an indication of its transmit, receive properties (a new Type-length-value is used for this purpose of course).\n\nWhen an 802.1aq node receives an IS-IS update it will compute the unique shortest path to all other IS-IS nodes that support 802.1aq. There will be one unique (symmetric) shortest path per ECMT behavior. The tie breaking used to enforce this uniqueness and ECMT is described below.\n\nThe unicast FDB/FIB will be populated based on this first shortest path computation. There will be one entry per ECMT behavior/B-VID produced.\n\nThe transit multicast computation (which only applies when transit replication is desired and not applicable to services that have chosen head end replication) can be implemented in many ways, care must be taken to keep this efficient, but in general a series of shortest path computations must be done. The basic requirement is to decide 'am I on the shortest path between two nodes one of which transmits an I-SID and the other receives that I-SID.'\n\nRather poor performing pseudo-code for this computation looks something like this:\n\nThe above pseudo code computes many more SPF's than strictly necessary in most cases and better algorithms are known to decide if a node is on a shortest path between two other nodes. A reference to a paper presented at the IEEE which gives a much faster algorithm that drastically reduces the number of outer iterations required is given below.\n\nIn general though even the exhaustive algorithm above is more than able to handle several hundred node networks in a few 10's of milliseconds on the 1 GHz or greater common CPUs when carefully crafted.\n\nFor ISIDs that have chosen head end replication the computation is trivial and involves simply finding the other attachment points that receive that ISID and creating a serial unicast table to replicate to them one by one.\n\n802.1aq must produce deterministic symmetric downstream congruent shortest paths. This means that not only must a given node compute the same path forward and reverse but all the other nodes downstream (and upstream) on that path must also produce the same result. This downstream congruence is a consequence of the hop by hop forwarding nature of Ethernet since only the destination address and VID are used to decide the next hop. It is important to keep this in mind when trying to design other ECMT algorithms for 802.1aq as this is an easy trap to fall into.\nIt begins by taking the unidirectional link metrics that are advertised by ISIS for 802.1aq and ensuring that they are symmetric. This is done by simply taking the MIN of the two values at both ends prior to doing any computations. This alone does not guarantee symmetry however.\n\nThe 802.1aq standard describes a mechanism called a PATHID which is a network-wide unique identifier for a path. This is a useful logical way to understand how to deterministically break ties but is not how one would implement such a tie-breaker in practice.\nThe PATHID is defined as just the sequence of SYSIDs that make up the path (not including the end points).. sorted. Every path in the network therefore has a unique PATHID independent of where in the network the path is discovered.\n\n802.1aq simply always picks the lowest PATHID path when a choice presents itself in the shortest path computations. This ensures that every node will make the same decision.\n\nFor example, in Figure 7 above, there are four equal-cost paths between node 7 and node 5 as shown by the colors blue, green, pink and brown. The PATHID for these paths are as follows:\n\n\nThe lowest PATHID is therefore the brown path {0,1}.\n\nThis low PATHID algorithm has very desirable properties. The first is that it can be done progressively by simply looking for the lowest SYSID along a path and secondly because an efficient implementation that operates stepwise is possible by simply back-tracking two competing paths and looking for the minimum of the two paths minimum SYSIDs.\n\nThe low PATHID algorithm is the basis of all 802.1aq tie breaking. ECMT is also based on the low PATHID algorithm by simply feeding it different SYSID permutations – one per ECMT algorithm. The most obvious permutation to pass is a complete inversion of the SYSID by XOR-ing it with 0xfff... prior to looking for the min of two minimums. This algorithm is referred to as high PATHID because it logically chooses the largest PATHID path when presented with two equal-cost choices.\n\nIn the example in figure 7, the path with the highest PATHID is therefore the blue path whose PATHID is {2,3}. Simply inverting all the SYSIDs and running the low PATHID algorithm will yield same result.\n\nThe other 14 defined ECMT algorithms use different permutations of the SYSID by XOR-ing it with different bit masks which are designed to create relatively good distribution of bits. It should be clear that different permutations will result in the purple and green paths being lowest in turn.\n\nThe 17 individual 64-bit masks used by the ECT algorithm are made up of the same byte value repeated eight times to fill each 64-bit mask. These 17 byte values are as follows:\n\nECT-MASK[0] is reserved for a common spanning tree algorithm, while ECT-MASK[1] creates the Low PATHID set of shortest path first trees, ECT-MASK[2] creates the High PATHID set of shortest path trees and the other indexes create other relatively diverse permutations of shortest path first trees.\n\nIn addition the ECMT tie-breaking algorithms also permit some degree of human override or tweaking. This is accomplished by including a BridgePriority field together with the SYSID such that the combination, called a BridgeIdentfier, becomes the input to the ECT algorithm. By adjusting the BridgePriority up or down a path's PATHID can be raised or lowered relative to others and a substantial degree of tunability is afforded.\n\nThe above description gives an easy to understand way to view the tie breaking; an actual implementation simply backtracks from the fork point to the join point in two competing equal-cost paths (usually during the Dijkstra shortest path computation) and picks the path traversing the lowest (after masking) BridgePriority|SysId.\n\nThe first public interoperability tests of IEEE 802.1aq were held in Ottawa in October 2010. Two vendors provided SPBM implementations and a total of 5 physical switches and 32 emulated switches were tested for control/data and OA&M.\n\nFurther events were held in Ottawa in January 2011 with 5 vendors and 6 implementations, at 2013's Interop event at Las Vegas where an SPBM network was used as a backbone.\n\nMC-LAG, VXLAN, and QFabric have all been proposed, but the IETF TRILL standard (Transparent Interconnect of Lots of Links) is considered the major competitor of IEEE 802.1aq, and: \"the evaluation of relative merits and difference of the two standards proposals is currently a hotly debated topic in the networking industry.\"\n\nDeployment considerations and interoperability best practices are documented in an IETF document titled \"SPB Deployment Considerations\"\n\nExtreme Networks, by virtue of their acquisition of the Avaya Networking business and assets, is currently the leading exponent of SPB-based deployments; their enhanced and extended implementation of SPB - including integrated Layer 3 IP Routing and IP Multicast functionality - is marketed under the banner of the \"Fabric Connect\" technology. Additionally, Extreme Networks is supporting an IETF Internet Draft Draft that defines a means of automatically extended SPBM-based services to end-devices via conventional Ethernet Switches, leveraging an 802.1AB LLDP-based communications protocol; this capability - marketing \"Fabric Attach\" technology - allows for the automatic attachment of end-devices, and includes dynamic configuration of VLAN/I-SID (VSN) mappings.\n\nAvaya have deployed SPB/Fabric Connect solutions for businesses operating across a number of industry verticals:\n\n\n\n\n\n"}
{"id": "32594714", "url": "https://en.wikipedia.org/wiki?curid=32594714", "title": "Infopulse Ukraine", "text": "Infopulse Ukraine\n\nInfopulse (also known as Infopulse Ukraine LLC) is an international software development, IT Operations and IT outsourcing company headquartered in Kiev, Ukraine. As of September 2018, the company has 1,900+ specialists and a number of software development centers, sales centers and branch offices in 10 countries across Western and Eastern Europe.\n\nThe company was founded in 1991 in Kiev, Ukraine by Olexiy Sihov and Andriy Anisimov.\n\nIn 2007 Infopulse became a part of Norwegian information technology company EDB Business Partner ASA. After a 2010 merger of EDB with a Nordic corporation ErgoGroup, in 2011 Infopulse became 100% owned subsidiary of the newly formed information technology company EDB ErgoGroup ASA, currently known as EVRY.\n\nInfopulse specializes in application management and IT infrastructure management, software research and development, software maintenance and ITO. The company also offers Business Process Outsourcing services, Application Packaging services, development of mobile applications and software as well as IT consulting services.\n\nInfopulse is an active member of the Ukrainian Hi-Tech Initiative, EBA and Lviv IT Cluster - non-profit organizations, uniting IT outsourcing companies, organizations and experts specializing in information technologies.\n\nMay, 1991 — Olexiy Sihov and Andriy Anisimov founded the company to develop computer-based monitoring systems for fire stations in Kiev, Moscow, and other cities of the former USSR.\n\nFebruary, 1992 — the management of the company signed its first contract with a French company. At that period the company provided outstaffing services, i.e. provided production staff for the projects of other companies, and did not develop software on-site.\n\nBy 1996 the company grew a team of professionals nearing 40 software developers.\n\n1996-1997, the company won the World Bank tender to develop an internal information system for the Kiev Tax Administration. The project became the first big independent project of the company.\n\n1999 — the Ukrainian team gets vast access to the western market of IT services by partnering with a Netherlands-based company.\n\nSpring 2000 was hallmarked by a new contract with Kyriba Corporation, France, which was the leader in the European IT market. The partnership provided Infopulse with stable annual turnover and staff growth by 30-35%.\n\nApril 2004 — Infopulse was certified as meeting the requirements of .\n\nSeptember 2006 — the management of the company carried on negotiations with nine potential partners, two of which, Bull Corporation (France), and EDB (Scandinavia), were chosen for final consideration.\n\nSeptember 2007 — 60.1% of Infopulse shares were announced to have been bought by EDB. Infopulse was introduced into the Scandinavian IT market and involved in IT projects for large banks, insurance and transport companies in Northern Europe.\n\nMarch 2009 — Infopulse retains more than 600 experts and had over 200 projects in its portfolio.\n\nOctober 2010 – Infopulse has become a part of one of the leading Nordic IT companies EDB ErgoGroup ASA with over 10,000 employees and annual turnover approaching NOK 13 billion.\nMarch 2012 — following the 2010 merger, EDB ErgoGroup has changed its name to EVRY.\n\nMarch 2013 – Infopulse opened a subsidiary in Germany.\n\nAugust 2015 – Infopulse strengthened its local presence in Europe by acquiring a delivery company in Varna, Bulgaria.\n\nJanuary 2016 – Infopulse opened a regional branch in France.\n\n2017 – Infopulse opened three local Ukrainian delivery centers in Lviv, Kharkiv and Odessa; the company had 1,600+ specialists on board.\n\n2018 – Infopulse expands its presence in the EU by opening a delivery center in Warsaw, Poland; the company now enlists 1,900+ experts.\n\nInfopulse offers a range of services in high tech area. Its main activities are:\n\nInfopulse serves clients in automotive, banking and finance, telecommunications, government, healthcare, insurance, manufacturing and other industries and subcategories. Most of its customers are located in Germany, Switzerland, the United Kingdom, Belgium, France, the Netherlands, Sweden, Denmark, Norway, and the USA.\n\nInfopulse takes active part in various Education Projects aiming to improve Public and IT Education in Ukraine.\n\nIn 2011 Infopulse partnered together with other companies in order to create BIONIC Hill Innovation Park - a Ukrainian innovation park constructed similarly to the Silicon Valley.\n\nIn 2012 Infopulse along with other Ukrainian and international IT-companies and institutions co-launched BIONIC University - the first inter-corporate IT university in Ukraine working on the premises of National University of Kyiv-Mohyla Academy. The University prepares IT specialists of a new formation, who are globally competitive yet aiming at professional fulfillment in Ukraine.\n\nIn 2014 Infopulse became a title partner of the International Championship of Computer Talents \"Golden Byte\".\n\nIn October 2014 Infopulse became a sponsor of \"АСМ-ІСРС\" (World Programming Contest) semi-finals\n\nIn 2014 Infopulse together with parent company EVRY started a sponsorship of the National University “The Kyiv-Mohyla Academy” program to open larger educational opportunities in IT sphere in Ukraine, including second education for people who have suffered due to various life circumstances.\n\nIn 2016-2017, Infopulse and Ukrainian Center for Educational Quality Assessment (UCEQA) in cooperation with United States Agency for International Development (USAID) restored and improved the External independent testing software system, which provides Ukrainian public education with a transparent school graduation and university admission process.\n\nInfopulse actively takes part in various charity projects by helping orphans, disabled military veterans, older people, people with Down syndrome and supporting national charity organizations.\n\nThe “Down Syndrome” project. Infopulse together with the Ukrainian Down Syndrome Organization (UDSO) and Down Syndrome Education International (DSEI) launched a long-term charity project in 2010 to help children and people with Down Syndrome in Ukraine. This project raises funds for early development programs and other charity causes through a series of charity events, and aims to spread information and improve public awareness about Down syndrome, by organizing Down syndrome conferences and other related events.\n\nPsychosocial Rehabilitation Centre for military. In December 2015 Infopulse with other international and Ukrainian institutions officially opened the Psychosocial Rehabilitation Centre which will help war heroes, relocated families, their children and all people, affected by the armed conflict in the Eastern Ukraine. Center’s premises were renovated, refurnished and equipped in accordance with modern WHO and UNICEF standards.\n\n"}
{"id": "7642113", "url": "https://en.wikipedia.org/wiki?curid=7642113", "title": "Joliet Army Ammunition Plant", "text": "Joliet Army Ammunition Plant\n\nJoliet Army Ammunition Plant (JOAAP, formerly known as the Joliet Arsenal) was a United States Army arsenal located in Will County, Illinois, near Elwood, Illinois, south of Joliet, Illinois. Opened in 1940 during World War II, the facility consisted of the Elwood Ordnance Plant (EOP) and the Kankakee Ordnance Works (KNK). In 1945, the two were deactivated and combined forming the Joliet Arsenal. The plant was reactivated for the Korean War and renamed Joliet Army Ammunition Plant during the Vietnam War. Production of TNT ended in 1976, and the major plant operations closed shortly after in the late 1970s. The facility briefly revived an automated load-assemble-pack (LAP) artillery shell operation that was managed by the Honeywell Corporation during the Reagan administration in the 1980s before it was finally closed.\n\nPortions of the site have been redeveloped forming the CenterPoint Intermodal Center, Abraham Lincoln National Cemetery and Midewin National Tallgrass Prairie.\n\nBefore the Second World War, the land in Jackson Township, Will County, Illinois, where the Joliet Arsenal was built consisted mostly of small family farms some of which were owned and managed by descendents of pioneer Illinois settlers. The federal government acquired some of the land in Jackson Township to build the Joliet Arsenal through eminent domain. Prior to the plant's construction, there were 450 farms that had to be vacated by March 1, 1941. Initially there was some resistance from local farmers relating to prices and moving problems, but 90% of the land was paid for through negotiated settlements. The entire land acquisition cost the government $5 million for the project. Ten preexisting farmhouses were moved from their original locations and used as staff housing. Six cemeteries were also on the property and they were maintained in place by the operating contractor.\n\nThe United States had very little capacity for manufacturing military munitions in 1939 when World War II broke out. Since the manufacture of munitions required specialized equipment and techniques there were no existing plants that could be converted. The solution to the lack of capacity was to create a large network of interlocking ammunition plants. They would be government-owned, but contractor-operated (GOCO). More than 60 plants would be constructed between June 1940 and December 1942.\n\nThe Elwood Ordnance Plant, named for Elwood, Illinois, and the Kankakee Ordnance Works, named for the Kankakee River, were two of the first five to be constructed. In September 1940, Stone and Webster Engineering of New York was awarded the contract to construct the Kankakee Ordnance Works. Another New York firm, Sanderson and Porter, received the contract for the Elwood Ordnance Plant soon after. Construction on both plants began November 1940, with Elwood beginning production July 12, 1941, followed by Kankakee in September. The plants were separate since they had different purposes, Kankakee manufactured various types of explosives for use at other plants and Elwood loaded artillery shells, bombs, mines and other munitions.\n\nE. I. du Pont de Nemours and Company, an experienced explosives manufacturer, was selected to operate the Kankakee plant while Sanderson and Porter would operate the Elwood facility. In April 1944, United States Rubber Company would replace DuPont as contractor at the Kankakee facility. TNT production at the Kankakee works occurred until August 1945 with a peak output of per week. In November 1945, Elwood and Kankakee were combined to form the Joliet Arsenal. Following the war the site was not completely inactive, DuPont leased space to manufacture ammonium nitrate for fertilizer. Over 10,425 people were employed at the two plants during the peak production of World War II. Elwood loaded more than 926 million bombs, shells, mines, detonators, fuzes, and boosters, and Kankakee produced over of TNT.\n\nThough both plants were designed with safety as a primary concern, at 2:45 a.m. on June 5, 1942, a large explosion on the assembly line at the Elwood facility resulted in 48 dead or missing and was felt as far as Waukegan, Illinois, over north. Assembly Lines were located in separate buildings which were separated by substantial distances limiting major damage to the facility as a whole.\n\nFrom a United Press newspaper article written at the time, \"Explosion shattered buildings of one of the units of the $30,000,000 Elwood Ordnance plant gave up the bodies of 21 workers Friday. Army officials said 36 more were missing from the blast that could be felt for a radius of 100 miles. Another 41 were injured, five of them critically, from the explosion that leveled a building... Not one of the 68 men inside the shipping unit when the blast occurred escaped death or injury.\"\n\n\"The explosion put one of the 12 production units out of action temporarily, but operations continued in the others.\"\n\nProduction resumed in 1952 after rehabilitation of the facility by the United States Army Corps of Engineers. The Kankakee portion was used to manufacture TNT under the control of contractor United States Rubber Company while Elwood operated under U.S. government control. Following the Korean war, Elwood would continue production in a limited capacity until deactivated in 1965. Kankakee production would end in 1957.\n\nThe Elwood unit was reopened in 1966 and would produce artillery rounds, supplementary charge assemblies and cluster bomb units. The Kankakee unit was reopened in 1965 and would manufacture TNT until 1976. During the Vietnam War the Joliet Arsenal was renamed Joliet Army Ammunition Plant. The majority of operations at the facility were terminated by the late 1970s.\n\nIn 1993, of land was declared to be excess. Remediation of the site occurred prior to the redevelopment. Redevelopment plans included around for two industrial parks, for the Will County Landfill, for the Abraham Lincoln National Cemetery, and for the Midewin National Tallgrass Prairie. The government retained a portion as the Joliet Army Training Area. The industrial parks are composed of the largest inland intermodal center in the country, CenterPoint Intermodal Center which is served by the Union Pacific Railroad and the BNSF Railway. and a Walmart distribution facility. along with several other prominent U.S. companies distribution warehouses.\n\nThe EPA maintains portions of the property on the Superfund National Priorities List. Cleanup includes composting by the Army Corps of Engineers. The cemetery and industrial parks were on the buffer portion of the facility, and there was little or no cleanup required. However, portions of the site that became Midewin National Tallgrass Prairie were heavily contaminated. Some of the clean-up included disposing of live explosive cartridges and shells using controlled explosions. The explosives to be cleaned up were buried by the army in unknown years. The residents of surrounding small towns could hear the controlled explosions being used in the disposal activity from 2-3 miles away.\n\nIn early 2008, site cleanup was finished three years ahead of schedule, while groundwater monitoring remains ongoing. Part of the prairie restoration at Midewin includes introducing American bison to graze on an experimental basis on approximately 1,200 acres of fenced pasture located within the Prairie’s 19,000 total acres. In October 2015, the U.S. Forest Service announced the arrival of 27 American bison to the prairie.\n\n\n"}
{"id": "41216408", "url": "https://en.wikipedia.org/wiki?curid=41216408", "title": "List of United Kingdom mobile virtual network operators", "text": "List of United Kingdom mobile virtual network operators\n\nMobile virtual network operators (MVNOs) in the United Kingdom lease wireless telephone and data spectrum from the four major carriers EE, O2, Three, and Vodafone for resale.\n\nSIM cards provided by MVNOs that are using Three's network will only work with 3G/4G devices, as Three do not operate 2G infrastructure in the UK.\n\n\n\n"}
{"id": "7666616", "url": "https://en.wikipedia.org/wiki?curid=7666616", "title": "List of computer hardware manufacturers", "text": "List of computer hardware manufacturers\n\nBelow is a list of notable computer hardware manufacturers:\n\nList of computer case manufacturers:\n\"Defunct\":\n\n\nTop motherboard manufacturers:\n\nList of motherboard manufacturers:\n\"Defunct\":\n\nTop CPU manufacturers:\n\nList of CPU manufacturers:\n\n\"Acquired or defunct\":\n\nList of current hard disk drive manufacturers:\n\n\nNote: the HDDs internal to these devices are manufactured only by the internal HDD manufacturers listed above.\n\nList of external hard disk drive manufacturers:\n\nOnly six companies actually manufacture the Nand Flash chips that are the storage element in SSDs and are so indicated on this list of solid-state drive (SSDs) manufacturers:\nList of optical disc drive manufacturers:\n\nList of cooling solutions manufacturers:\nList of non-refillable liquid cooling manufacturers:\nList of refillable liquid cooling kits manufacturers:\nList of water block manufacturers:\n\nList of graphics card cooling manufacturers:\nList of visual display unit manufacturers:\nList of video card manufacturers:\n\nList of keyboard manufacturers:\nList of mouse manufacturers:\nList of mouse pad manufacturers:\nList of Joystick manufacturers:\nList of computer speaker manufacturers:\nList of modem manufacturers:\nList of network card manufacturers:\n\nList of power supply unit (PSU) manufacturers:\nList of memory module manufacturers:\n\nList of headphone manufacturers:\n\nList of image scanner manufacturers:\nList of sound card manufacturers:\nList of TV tuner card manufacturers:\nList of USB flash drive manufacturers:\nList of webcam manufacturers:\n"}
{"id": "906358", "url": "https://en.wikipedia.org/wiki?curid=906358", "title": "List of defunct graphics chips and card companies", "text": "List of defunct graphics chips and card companies\n\nDuring the 1980s and 1990s a relatively large number of companies appeared selling primarily 2D graphics cards and later 3D. Most of those companies have subsequently disappeared, as the increasing complexity of GPUs substantially increased research and development costs. Many of these companies subsequently went bankrupt or were bought out. Intel and VIA Technologies remain as producers of primarily integrated solutions, while Matrox targets niche markets. Amongst the notable discrete graphics card vendors, ATI Technologies — acquired by AMD in 2006 and since renamed to AMD — and NVIDIA are the only ones that have lasted.\n\nThese companies designed graphics chips and cards.\n\n\n\nThe following companies are still in operation, but no longer design PC graphics chips:\n\n"}
{"id": "6490194", "url": "https://en.wikipedia.org/wiki?curid=6490194", "title": "List of surface-to-air missiles", "text": "List of surface-to-air missiles\n\nThis is a list of surface-to-air missiles (SAMs).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "15571581", "url": "https://en.wikipedia.org/wiki?curid=15571581", "title": "Looj", "text": "Looj\n\nThe Looj was a rain gutter (eavestrough) cleaning domestic robot made and sold by iRobot.\n\nThe Looj was not an autonomous robot, but rather a remote-controlled robot patterned after a toy tank with a power drill mounted on the front.\n\nThe Looj was a tall and wide robot that fit inside most gutters to clean out debris stuck inside them, such as leaves and pine needles. It had long treads on its side which allowed it to move inside the gutter, and an auger attached to its front. The auger, spinning flexible flaps at 500 RPM, dislodged and removed debris inside the gutter by flinging it sideways into the air. The device also had a detachable handle/remote, that was used to carry and operate the robot.\n\nThe first Looj models were powered by an internal 7.2 V NiCad rechargeable battery, which must be removed for charging. Later models use a Li-ion rechargeable battery instead.\n\nThe Looj was discontinued in 2017.\n\nThe Looj was received favourably by reviewers prior to release. Crunch Gear said \"If you place your ladder at a corner of the house – and your gutters are wide enough – you can easily clean out two sides of a house in a few minutes.\"\n\nLooj won the \"Best of CES Innovations Award: Home Appliances\" in 2008.\n\n"}
{"id": "5648613", "url": "https://en.wikipedia.org/wiki?curid=5648613", "title": "Meat cutter", "text": "Meat cutter\n\nA meat cutter prepares primal cuts into a variety of smaller cuts intended for sale in a retail environment. The duties of a meat cutter largely overlap those of the butcher, but butchers tend to specialize in pre-sale processing (reducing carcasses to primal cuts), whereas meat cutters further cut and process the primal cuts per individual customer request. \n\nThe job title of \"butcher\" has been mostly replaced in corporate storefronts in the last two decades after customer trends showed that modern (particularly urban) customers increasingly associated the term with animal slaughter and unsanitary conditions (regardless of the condition of the store). With the advent of off-premises pre-packaged supermarket meat, many supermarkets now avoid mention of either cutting or butchering and simply call their meat cutters \"Meat Department Associates\" or similar. In the UK the term butcher is still used to describe a person, who offers for retail sale, meat ready for cooking by the customer. They will also prepare cuts, joints etc, for the customer. Most corporate retailers still use the term butcher for their meat department operatives\n\nA meat cutter is responsible to prepare standard cuts of meat (including poultry and fish) to be sold in either a self-serve or specialty counter. In the UK the term used for retail meat cutter, is still butcher. Retail meat cutters are found in a customer-oriented, retail environment. This can be anything from a small family-owned meat shop to a large international supermarket chain. Meat cutters are a registered trade. Industrial meat cutters are found in production-oriented facilities, and generally perform fewer tasks, but repeatedly.\n\nThe term \"meat cutters\" typically deal with \"primal\" cuts - segments of the carcass broken down into smaller (but still unfinished) pieces to make them easier to handle.\n\nRetail meat cutters traditionally work indoors, in large, refrigerated rooms, with temperatures ranging between 2 and –4 degrees Celsius. These environments are kept sanitary, and are washed every day with powerful antibacterial cleaners. In larger retail outlets or plant-facilities, working environments are generally equipped with power tools such as band saws and circular slicers. Meat cutters are also generally required to be in good physical shape; the duties of a meat cutter include standing for long periods of time, regularly lifting over 50 lbs, and working in cold conditions. Retail meat cutters also often have to deal with customers.\n\nThe duties of a retail meat cutter often include the trimming of primal cuts, making ground meat out of trimmings from the primal cuts, ensuring meat cuts are displayed in an eye-catching manner and are of sufficient quality, and serving customized orders to customers. Retail meat cutters are also responsible to keep their working areas clean, and ensure that proper sanitization procedures are followed.\n\n"}
{"id": "20559", "url": "https://en.wikipedia.org/wiki?curid=20559", "title": "Mecha", "text": "Mecha\n\nThe term may refer to both scientific ideas and science fiction genres that center on giant robots or machines controlled by people. Mechas are typically depicted as humanoid mobile robots.\n\nThese machines vary greatly in size and shape, but are distinguished from vehicles by their humanoid or biomorphic appearance and size—bigger than a human. Different subgenres exist, with varying connotations of realism. The concept of Super Robot and Real Robot are two such examples found in Japanese anime. The term may also refer to real world piloted humanoid or non-humanoid robotic platforms, either currently in existence or still on the drawing board (i.e. at the planning or design stage). Alternatively, in the original Japanese context of the word, \"mecha\" may refer to mobile machinery/vehicles (including aircraft) in general, manned or otherwise.\n\nThe word is an abbreviation, first used in Japanese, of the word \"mechanical\". In Japanese, mecha encompasses all mechanical objects, including cars, guns, computers, and other devices, and the term or \"giant robot\" is used to distinguish limbed vehicles from other mechanical devices. Outside of this usage, it has become associated with large humanoid machines with limbs or other biological characteristics. Mechs differ from robots in that they are piloted from a cockpit, typically located in the chest or head of the mech.\n\nWhile the distinction is often hazy, mecha typically does not refer to form-fitting powered armor such as Iron Man's suit. They are usually much larger than the wearer, like Iron Man's enemy the Iron Monger, or the mobile suits depicted in the Gundam series.\n\nIn most cases, mecha are depicted as fighting machines, whose appeal comes from the combination of potent weaponry with a more stylish combat technique than a mere vehicle. Often, they are the primary means of combat, with conflicts sometimes being decided through gladiatorial matches. Other works represent mecha as one component of an integrated military force, supported by and fighting alongside tanks, fighter aircraft, and infantry, functioning as a mechanical cavalry. The applications often highlight the theoretical usefulness of such a device, combining a tank's resilience and firepower with infantry's ability to cross unstable terrain and a high degree of customization. In some continuities, special scenarios are constructed to make mecha more viable than current-day status. For example, in Gundam the fictional Minovsky particle inhibits the use of radar, making long-range ballistic strikes impractical, thus favouring relatively close range warfare of Mobile Suits.\n\nHowever, some stories, such as the manga/anime series \"Patlabor\" and the American wargame BattleTech universe, also encompass mecha used for civilian purposes such as heavy construction work, police functions or firefighting. Mecha also see roles as transporters, recreation, advanced hazmat suits and other R and D applications.\n\nMecha have been used in fantasy settings, for example in the anime series \"Aura Battler Dunbine\", \"The Vision of Escaflowne\", \"Panzer World Galient\" and \"Maze\". In those cases, the mecha designs are usually based on some alternative or \"lost\" science-fiction technology from ancient times. In case of anime series \"Zoids\", the machines resemble dinosaurs and animals, and have been shown to evolve from native metallic organisms.\n\nThe 1868 Edward S. Ellis novel \"The Steam Man of the Prairies\" featured a steam-powered, back piloted, mechanical man.\nThe 1880 Jules Verne novel \"La Maison à vapeur (The Steam House)\" featured a steam-powered, piloted, mechanical elephant. One of the first appearances of such machines in modern literature was the \"tripods\" of H. G. Wells' famous \"The War of the Worlds\" (1897). The novel does not contain a fully detailed description of the tripods' (or \"fighting-machine\", as they are known in the novel) mode of locomotion, however it is hinted at: \"Can you imagine a milking stool tilted and bowled violently along the ground? That was the impression those instant flashes gave. But instead of a milking stool imagine it a great body of machinery on a tripod stand.\"\n\n\"Ōgon Bat\", a kamishibai that debuted in 1931 (later adapted into an anime in 1967), featured the first piloted humanoid giant robot, , but as an enemy rather than a protagonist. The first humanoid giant robot piloted by the protagonist appeared in the manga in 1948. The manga and anime \"Tetsujin 28-Go\", introduced in 1956, featured a robot, Tetsujin, that was controlled externally by an operator via remote control. The manga and anime \"Astro Boy\", introduced in 1952, with its humanoid robot protagonist, was a key influence on the development of the giant robot genre in Japan. The first anime featuring a giant mecha being piloted by the protagonist from within a cockpit was the Super Robot show \"Mazinger Z\", written by Go Nagai and introduced in 1972.\n\nEarly uses of mech-like machines in the United States include Kimball Kinnison's battle suit in E. E. \"Doc\" Smith's \"Lensman\" novel \"Galactic Patrol\" (1950), the Mobile Infantry battle suits in Robert Heinlein's \"Starship Troopers\" (1958), and the film \"The King and the Mockingbird\" (1952).\n\nIn Japan, \"robot anime\" (known as \"mecha anime\" outside Japan) is one of the oldest genres in anime. Robot anime is often tied in with toy manufacturers. Large franchises such as Zoids and Gundam have hundreds of different model kits.\n\nThe size of mecha can vary according to the story and concepts involved. Some of them may not be considerably taller than a tank (\"Armored Trooper Votoms\", \"Megazone 23\", \"Code Geass\"), some may be a few stories tall (\"Gundam\", \"Escaflowne\", \"Bismark\", \"Gurren Lagann\"), others can be as tall as a skyscraper (\"Space Runaway Ideon\", \"Genesis of Aquarion\", \"Neon Genesis Evangelion\"), some are big enough to contain an entire city (\"Macross\"), some the size of a planet (\"Diebuster\"), galaxies (\"Getter Robo\", \"Tengen Toppa Gurren Lagann\"), or even as large as universes (\"Tengen Toppa Gurren Lagann: Lagann-hen\", \"Demonbane\").\n\nThe first giant robot seen was Mitsuteru Yokoyama's 1956 manga \"Tetsujin 28-go\". However, it wasn't until the advent of Go Nagai's \"Mazinger Z\" that the genre was established. \"Mazinger Z\" innovated by adding the inclusion of futuristic weapons, and the concept of being able to pilot from a cockpit (rather than via remote control, in the case of Tetsujin). According to Go Nagai:\n\n\"Mazinger Z\" featured giant robots which were \"piloted by means of a small flying car and command center that docked inside the head.\" It was also a pioneer in die-cast metal toys such as the Chogokin series in Japan and the Shogun Warriors in the U.S., that were (and still are) very popular with children and collectors.\n\nRobot/mecha anime and manga differ vastly in storytelling and animation quality from title to title, and content ranges all the way from children's shows to ones intended for an older teen or adult audience.\n\nSome robot mecha are capable of transformation (\"Macross\" and \"Zeta Gundam\") or combining to form even bigger ones (\"Beast King GoLion\" and \"Tengen Toppa Gurren Lagann\"). Go Nagai is also often credited with inventing this in 1974 with the television series \"Getter Robo\".\n\nNot all mecha need be completely mechanical. Some have biological components with which to interface with their pilots, and some are partially biological themselves, such as \"Neon Genesis Evangelion\", \"Eureka Seven\", and \"Zoids\".\n\nMecha based on anime have seen extreme cultural reception across the world. The personification of this popularity can be seen as 1:1 size \"Mazinger Z\", Tetsujin, and Gundam statues built across the world.\n\n\nMecha are often featured in computer and console video games. Because of their size and fictional power, mecha are quite popular subjects for games, both tabletop and electronic. They have been featured in video games since the 1980s, particularly in vehicular combat and shooter games, including Sesame Japan's side-scrolling shooter game \"Vastar\" in 1983, various \"Gundam\" games such as \"\" in 1984 and \"\" in 1986, the run and gun shooters \"Hover Attack\" in 1984 and \"Thexder\" in 1985, and Arsys Software's 3D role-playing shooters \"WiBArm\" in 1986 and \"Star Cruiser\" in 1988. Historically mecha-based games have been more popular in Japan than in other countries.\n\n\nThere are a few real prototypes of mecha-like vehicles. Currently almost all of these are highly specialized or just for concept purpose, and as such may not see mass production.\n\n\nIn the Western world, there are few examples of mecha, however, several machines have been constructed by both companies and private figures. Timberjack, a subsidiary of John Deere, built a practical hexapod walking harvester.\n\n\n"}
{"id": "9596708", "url": "https://en.wikipedia.org/wiki?curid=9596708", "title": "Mountain Locator Unit", "text": "Mountain Locator Unit\n\nA Mountain Locator Unit or MLU was a radio transmitter for use by mountain climbers as an emergency locator beacon when the wearer needs rescue.\n\nThe MLUs were simple radio beacons, and thus required search and rescuers to use traditional radio direction finding (RDF or DF) equipment to obtain a bearing, but not a precise location, to the beacon.\n\nUnique to Mount Hood, these devices could be rented for $5 at Portland-area outdoor shops and the Inn, open 24 hours a day. The units were available from the late 1980s until 2017, but advances in technology now provide superior locating information by devices such as a PLB, InReach or Spot.\n\nGroups scaling Mount Hood are recommended to carry an emergency signaling device and all climbers must register before climbing and sign out upon return.\n\nThe MLU was designed after a school group with two adults and seven children perished on Mount Hood in 1986. (See Mount Hood climbing accidents.) The bodies of some of the group were found in a snow cave a day after the searchers had passed within fifteen feet of their shelter without noticing them.\n\nAccording to Steve Rollins of Portland Mountain Rescue, the units could be worn on a sash across the chest and were relatively light. Renting MLU's was less expensive than either purchasing or renting a personal locator beacon, which typically cost several hundred dollars to buy, or rent from various sources for around $50 per week.\n\nThe Mount Hood MLU system was controlled and maintained by the U.S. Forest Service and Clackamas County Sheriff. Transmitters broadcast at 168.54 MHz and provided good signals even when buried in snow. They could be received at up to , though the signal travels in line of sight, so they could not be received from behind a ridge or deep in a canyon. The technology iasvery similar to wildlife tracking systems.\n\nA Mountain Locator Unit only transmitted a signal and did not initiate a rescue (when you activated an MLU beacon, there was no one monitoring for signals, the device only assisted rescuers in locating lost climbers once a rescue has been requested by other means and rescuers know to listen and search for the beacon's signal. They were also not designed to be used for avalanche safety (avalanche beacons are entirely different than what MLU's were designed for.)\n\nThe use of MLU Beacon technology was overtaken by availability of Personal Locator Beacons (PLBs) and other technologies such as \"SPOT Satellite GPS Messengers\". These newer technologies not only allow rescuers to determine your location, but they also have the ability to initiate a rescue by alerting authorities that you are in need of help.\n\nIn fact, most modern cell phones have built in GPS receivers. If a climber calls 911, the cell phone may automatically provide emergency services with the climber's GPS coordinates. Cell phones also allow the lost or injured climber to provide important information to rescuers, such as the nature of any injuries; however, cell phone coverage on Mount Hood can be spotty and they are therefore not necessarily a replacement for other technologies such as PLBs which leverage satellites overhead for communication.\n\nOregon State Representative John Lim (R) introduced House Bill 2509, which would require climbers to use an electronic signaling device when climbing above 10,000 feet between November and March. The Oregon House of Representatives passed an amended version of the bill 33 to 22 on March 28, 2007 after a lengthy floor debate and passed it onto the Oregon State Senate where it died in committee. The bill was widely opposed by mountain rescue organizations for fear that it would cause inexperienced climbers to rely on rescuers to save them rather than learning to become self-reliant.\n\n\n\n"}
{"id": "7271980", "url": "https://en.wikipedia.org/wiki?curid=7271980", "title": "NHT Loudspeakers", "text": "NHT Loudspeakers\n\nNHT Loudspeakers (Now Hear This), often colloquially referred to as NHT Audio, is an American loudspeaker and audio component company based in Benicia, California. The company was founded by Chris Byrne and Ken Kantor in December 1986. \n\nNHT home theater products have historically included loudspeakers, A/V processors, and amplifiers. NHT professional processors and speakers are used in recording and production studios. The current NHT lineup consists solely of acoustic suspension loudspeakers and in-wall/in-ceiling speakers.\n\nByrne primarily handled sales and marketing, while Kantor (introduced to Byrne by Michael Riggs, then at \"High Fidelity\" magazine) was responsible for design and engineering. \n\nIn 1987, NHT shipped its first product, the Model 1 loudspeaker.\n\nIn 2004, NHT unveiled its XdS line of speakers and supporting processors. XdS speakers are DSP corrected active speakers with digital amplifiers. The XdS line has since been discontinued.\n\nIn 2007, NHT introduced the Classic Three Bookshelf Speaker, which received critical acclaim. Theo Nicolakis of Audioholics wrote that \"what the Classic Threes do have is a total sonic package that’s nothing short of amazing\".\n\nIn 2016, NHT released its C Series line of speakers to replace the Classic Series. Secrets of Home Theater Hi-Fi praised the C 3 Bookshelf, saying the speakers \"look great, sound great, and measure superbly. And in true NHT tradition, they accomplish all that at a very reasonable price.\"\n\nAs of May 2018, NHT currently has 3 series of loudspeaker products: the C Series, Media Series, and Super Series.\n\nNHT utilizes Anti-Resonant Casting for their in-ceiling and in-wall speakers.\n\nNHT uses a patented three-way tweeter array design for their in-ceiling speaker line-up. \n\n"}
{"id": "58797296", "url": "https://en.wikipedia.org/wiki?curid=58797296", "title": "Nanocar race", "text": "Nanocar race\n\nNanocar Race is an international scientific competition with the aim of testing the performance of molecular machines and the scientific instruments used to control them. The race of the molecules is taking place on a 100 nanometer track and was held for the first time in Toulouse on 28 and 29 April 2017.\n\nThe idea for the race was formulated in January 2013 in the ACS Nano magazine by the Toulouse organizers of CEMES-CNRS, this way a call for applications was launched to give the participating teams time to prepare appropriate nanocars. The race is officially announced by the National Centre for Scientific Research in November 2015 in Toulouse during Futurapolis1. On this occasion, five teams presented their prototype projects on November 27, 2015.\n\nThe first race in the world of this type, between four vehicles, started on the 28 April 2017 at the CEMES-CNRS in Toulouse and lasted 36 hours. The Toulouse organizers also agreed on the competition of two more vehicles, which will then be remotely controlled via Internet from the CEMES-CNRS race room on the microscope of their own laboratory. These relates to the vehicles from Ohio and Graz-Rice.\n\nThe Nanocar race II, the second edition of this competition will take place in 2021 and is currently in the preparation stages with the support of the European project H2020: MEMO (2017-2021).\n\nThe track of the first competition is a gold surface, equipped with grooves to define race lanes in order to avoid losing vehicles. It is about 100 nanometres long, and includes two bends. It is located in a small enclosure cooled to -269°C under a primary vacuum of 10 mbar and is observed simultaneously by four scanning tunneling microscopes (STM) miniaturized for this event and operating on the same surface. Each microscope is responsible for driving a single vehicle (a single nanocar).\n\nDuring this competition, the nanocars should move as far as possible on the gold track during the 36 hours race. Speeds of 5 nanometers per hour were expected\n\nNanocars are a new class of molecular machines that can roll across solid surfaces with structurally defined direction. They are molecules essentially composed of a few tens or hundreds of hydrogen and carbon atoms and are measuring one to three nanometers.\n\nThe nanocar is propelled step by step by electrical impulses and electron transfer from the tip of the STM. The resulting tunnel current flows through the nanocar between the tip of the microscope and the common metal track. There is no direct mechanical contact with the tip. The nanocar is therefore neither pushed nor deformed by the tip of the microscope during the race. Some of the electrons that pass through the nanocar release energy as small intramolecular vibrations that activate the nanocar's motor.\n\n\nThe race on the gold surface was won by the Swiss team that crossed the finish line first after covering a distance of 133 nanometers.\n\nOn the silver track, the vehicle of the Austrian-American team from the Universities of Rice and Graz set the first speed record with a peak speed of 95 nanometers per hour, and was ranked equally with the Swiss team. This vehicle was remotely controlled from the Toulouse race hall on the University of Graz microscope.\n\nThe American team from Ohio University turned back for no apparent reason after 20 nanometers, the German team broke 2 vehicles without being able to restart, and the Japanese team ended up giving up. The French team lost sight of its vehicle on its surface area, and was also obliged to abandon, comforting itself with the symbolic prize of \"the most elegant car in the competition \".\n\nTo make this kind of race possible, a considerable number of problems had to be solved beforehand, such as the choice of the track and its preparation, the improvement of monitoring and control devices, in particular the sensitivity of current measurements, the evaporation of a large number of very different molecules on the same surface and microscope validation\n\nAmong the benefits, the CNRS cites the development molecular motors and Tech-Atoms, that will make possible in the future the preparation of quantum electronic circuits on the surface of an isolator, atom by atom, whose calculating parts will measure less than 1 nm.\n\nThe construction of molecule machines can also be mentioned, these would be capable of cleaning up industrial waste and household waste as described in science fiction novels of the 1960s under the term \"digesters\".\n\nA new surface science, called membrane science is also conceivable, where molecular machines controlled one by one (or in random exploration) would inspect transmembrane channels and eliminate virus intrusion attempts as they approach the membrane surface.\n"}
{"id": "42627137", "url": "https://en.wikipedia.org/wiki?curid=42627137", "title": "National Academy of Science and Technology", "text": "National Academy of Science and Technology\n\nThe National Academy of Science and Technology (\"abbreviated as \"NAST) is the highest recognition and scientific advisory body of the Philippines under the Department of Science and Technology. It was created through Presidential Decree 1003-A issued by President Ferdinand E. Marcos in 1976 to honor and recognize Filipino scientists who made worthy contributions in the advancement of science and technology in the country. It also recommends individuals to be conferred the Order of National Scientist upon approval of the President of the Philippines.\n\nThe establishment of the National Academy of Science and Technology was a proposal of several professors from the University of the Philippines. It was endorsed by the National Science Development Board (now Department of Science and Technology) to the President of the Philippines. NAST was created through Presidential Decree 1003-A issued by President Ferdinand E. Marcos in October 6, 1976. In 1978, President Marcos named the first ten members of the academy from members of the scientific community with three of them proclaimed as \"National Scientist\", namely: Juan S. Salcedo, Jr., Alfredo C. Santos and Gregorio Y. Zara. Through Executive Order 818 in 1982, the academy was tasked to give recommendations to the President of the Republic of the Philippines and the Cabinet on policies concerning science and technology in the country.\n\nThe National Academy of Science and Technology is mandated:\n\nThe Academy's function is divided into three components namely, advisory, recognition and scientific Linkages.\n\nMembers of the National Academy of Science and Technology are nominated by members of the scientific community. Current NAST members deliberate on the membership of an individual following strict rules and regulations. Once admitted to the organization, members are called \"Academicians \"(\"abbreviated as \"Acd.)\". \"The academy is divided into several divisions to which an academician is a member depending on his area of expertise. The following divisions are:\nFrom each division of the academy, a chair is elected to form the Executive Council. A president, vice-president and secretary is elected from the Executive Council. The secretariat of NAST is headed by an executive director which implements the decisions of the Executive Council, and attends to the day-to-day affairs of the Academy. \nSince 2012, the NAST Executive Council is composed of:\n\nMembers of the NAST are called academicians. As of 2014, there are 45 living academicians.\n\nAll National Scientist are members of the NAST. As of 2014, there are 17 living national scientists.\n\nThe academy conducts a scientific meeting every July since 1978. It gathers scientist from all over the country to discuss relevant issues related to science and technology and thus earning the distinction of the most prestigious Philippine scientific conference. At the end of the convention, NAST honors exemplary scientists from different fields and presents recommendations to the government through the secretary of the Department of Science and Technology.\n\nThe 2014 Edition of the Annual Scientific Meeting (ASM) focuses on three pillars of competitiveness as defined by the World Economic Forum (WEF), namely, \"infrastructure\", \"information\", and \"innovation\" with emphasis on the policy and governance aspects in energy, water, telecommunications, and transportation. Former Department of Trade and Industry Secretray Cesar B. Bautista gave the keynote address.\n\nNAST also recognizes worthy contributions of Filipino scientists in the advancement of science and technology in the country during its Annual Scientific Meeting. It includes the following recognitions: Outstanding Young Scientists (OYS), The World Academy of Sciences for Developing Countries (TWAS) Prize for Young Scientists in the Philippines, NAST Talent Search for Young Scientists, NAST Environmental Science Award, NAST-LELEDFI Award for Outstanding Research in Tropical Medicine, Outstanding Scientific Papers, Outstanding Books and Outstanding Monographs.\n\nAs a promoter of science and technology, NAST also publishes books and monographs based on studies of present academicians, members of the scientific community and world-renowned scientists. Conference proceedings of their annual scientific meeting is published as the \"NAST Transactions. \"\n\n"}
{"id": "21242", "url": "https://en.wikipedia.org/wiki?curid=21242", "title": "Nokia", "text": "Nokia\n\nNokia Corporation (commonly referred to as Nokia; , , ) is a Finnish multinational telecommunications, information technology, and consumer electronics company, founded in 1865. Nokia's headquarters are in Espoo, in the greater Helsinki metropolitan area. In 2017, Nokia employed approximately 102,000 people across over 100 countries, did business in more than 130 countries, and reported annual revenues of around €23 billion. Nokia is a public limited company listed on the Helsinki Stock Exchange and New York Stock Exchange. It is the world's 415th-largest company measured by 2016 revenues according to the \"Fortune Global 500,\" having peaked at 85th place in 2009. It is a component of the Euro Stoxx 50 stock market index.\n\nThe company has had various industries in over 150 years. It was founded as a pulp mill and had long been associated with rubber and cables, but since the 1990s focuses on large-scale telecommunications infrastructures, technology development, and licensing. Nokia is a notable major contributor to the mobile telephony industry, having assisted in the development of the GSM, 3G and LTE standards (and currently in 5G), and is best known for having been the largest worldwide vendor of mobile phones and smartphones for a period. After a partnership with Microsoft and market struggles, its mobile phone business was eventually bought by the former, creating Microsoft Mobile as its successor in 2014. After the sale, Nokia began to focus more extensively on its telecommunications infrastructure business and on the Internet of things, marked by the divestiture of its Here mapping division and the acquisition of Alcatel-Lucent, including its Bell Labs research organization. The company then also experimented with virtual reality and digital health, the latter through the purchase of Withings. The Nokia brand has since returned to the mobile and smartphone market through a licensing arrangement with HMD Global. Nokia continues to be a major patent licensor for most large mobile phone vendors. As of 2018 Nokia is the world's third largest network equipment manufacturer.\n\nThe company was viewed with national pride by Finns, as its successful mobile phone business made it by far the largest worldwide company and brand from Finland. At its peak in 2000, during the telecoms bubble, Nokia alone accounted for 4% of the country's GDP, 21% of total exports, and 70% of the Helsinki Stock Exchange market capital.\n\nNokia's history dates back to 1865, when Finnish-Swede mining engineer Fredrik Idestam established a pulp mill near the town of Tampere, Finland (then in the Russian Empire). A second pulp mill was opened in 1868 near the neighboring town of Nokia, offering better hydropower resources. In 1871, Idestam, together with friend Leo Mechelin, formed a shared company from it and called it \"Nokia Ab\" (in Swedish, \"Nokia Company\" being the English equivalent), after the site of the second pulp mill.\n\nIdestam retired in 1896, making Mechelin the company's chairman. Mechelin expanded into electricity generation by 1902 which Idestam had opposed. In 1904 Suomen Gummitehdas (\"Finnish Rubber Works\"), a rubber business founded by Eduard Polón, established a factory near the town of Nokia and used its name.\n\nIn 1922, Nokia Ab entered into a partnership with Finnish Rubber Works and Kaapelitehdas (\"the Cable Factory\"), all now jointly under the leadership of Polón. Finnish Rubber Works company grew rapidly when it moved to the Nokia region in the 1930s to take advantage of the electrical power supply, and the cable company soon did too.\n\nNokia at the time also made respirators for both civilian and military use, from the 1930s well into the early 1990s.\n\nIn 1967, the three companies - Nokia, Kaapelitehdas and Finnish Rubber Works - merged and created a new Nokia Corporation, a new restructured form divided into four major businesses: forestry, cable, rubber and electronics. In the early 1970s, it entered the networking and radio industry. Nokia also started making military equipment for Finland's defence forces (\"Puolustusvoimat\"), such as the Sanomalaite M/90 communicator in 1983, and the M61 gas mask first developed in the 1960s. Nokia was now also making professional mobile radios, telephone switches, capacitors and chemicals.\n\nAfter Finland's trade agreement with the Soviet Union in the 1960s, Nokia expanded into the Soviet market. It soon widened trade, ranging from automatic telephone exchanges to robotics among others; by the late 1970s the Soviet Union became a major market for Nokia, helping to yield high profits. Nokia also co-operated on scientific technology with the Soviet Union. The U.S. government became increasingly suspicious of that technologic co-operation after the end of the Cold War détente in the early 1980s. Nokia imported many US-made components and used them for the Soviets, and according to U.S. Deputy Minister of Defence, Richard Perle, Nokia had a secret co-operation with The Pentagon that allowed the U.S. to keep track in technologic developments in the Soviet Union through trading with Nokia. However this was a demonstration of Finland trading with both sides, as it was neutral during the Cold War.\n\nIn 1977, Kari Kairamo became CEO and he transformed the company's businesses. By this time Finland were becoming what has been called \"Nordic Japan\". Under his leadership Nokia acquired many companies. In 1984, Nokia acquired television maker Salora, followed by Swedish electronics and computer maker Luxor AB in 1985, and French television maker Oceanic in 1987. This made Nokia the third-largest television manufacturer of Europe (behind Philips and Thomson). The existing brands continued to be used until the end of the television business in 1996.\n\nIn 1987, Nokia acquired Schaub-Lorenz, the consumer operations of Germany's Standard Elektrik Lorenz (SEL), which included its \"Schaub-Lorenz\" and \"Graetz\" brands. It was originally part of American conglomerate International Telephone & Telegraph (ITT) and after the acquisition products were sold under the \"ITT Nokia\" brand, despite SEL's sale to Compagnie Générale d'Electricité (CGE), the predecessor of Alcatel, in 1986.\n\nOn 1 April 1988 Nokia bought the computer division of Ericsson's Information Systems, which originated as a computer division of Swedish aircraft and car manufacturer Saab called Datasaab. Ericsson Information Systems made Alfaskop terminals, typewriters, minicomputers and Ericsson IBM compatible PCs. The merge with Nokia's existing Information Systems division—which already had a line of personal computers called MikroMikko since 1981—resulted in the name Nokia Data.\n\nNokia also acquired Mobira, a mobile telephony company, which was the foundation of its future mobile phones business. In 1981, Mobira launched the Nordic Mobile Telephone (NMT) service, the world's first international cellular network and the first to allow international roaming. In 1982, Mobira launched the Mobira Senator car phone, Nokia's first mobile phone. At that time, the company had no interest in producing mobile phones, which the executive board regarded as akin to James Bond's gadgets - improbably futuristic and niche devices. After all these acquisitions Nokia's revenue base became US$2.7 billion. Tragically CEO Kairamo committed suicide on 11 December 1988.\n\nIn 1987, Kaapelitehdas discontinued production of cables at its Helsinki factory after 44 years, effectively shutting down the sub-company.\n\nFollowing Simo Vuorilehto's appointment as CEO, a major restructuring was planned. With 11 groups within the company, Vuorilehto divested industrial units he deemed as un-strategic. Nokian Tyres (\"Nokian Renkaat\"), a tyre producer originally formed as a division of Finnish Rubber Works in 1932, split away from Nokia Corporation in 1988. Two years later, in 1990, Finnish Rubber Works followed suit. In 1991 Nokia sold its computer division, Nokia Data, to UK-based International Computers Limited (ICL), the precursor of Fujitsu Siemens. Investors thought of this as financial trouble and Nokia's stock price sank as a result. Finland was now also experiencing its worst recession in living memory, and the collapse of the Soviet Union, a major customer, made matters worse.\n\nVuorilehto quit in January 1992 and was replaced by Jorma Ollila, who had been the head of the mobile phone business from 1990 and advised against selling that division. Ollila decided to turn Nokia into a 'telecom-oriented' company, and he eventually got rid of divisions like the power business. This strategy proved to be very successful and the company grew rapidly in the following years. Nokia's operating profit went from negative in 1991 to $1 billion in 1995 and almost $4 billion by 1999.\n\nNokia's first fully portable mobile phone after the Mobira Senator was the Mobira Cityman 900 in 1987. Nokia assisted in the development of the GSM mobile standard in the 1980s, and developed the first GSM network with Siemens, the predecessor to Nokia Siemens Network. The world's first GSM call was made by Finnish prime minister Harri Holkeri on 1 July 1991, using Nokia equipment on the 900 MHz band network built by Nokia and operated by Radiolinja. In November 1992, the Nokia 1011 launched, making it the first commercially available GSM mobile phone.\n\nSalora Oy as a Nokia subsidiary ended in 1989 when the division was merged into Nokia-Mobira Oy. The brand continued to be used for televisions until 1995.\n\nOn 12 June 1996, Nokia announced the sale of its television business to Canada/Hong Kong-based Semi-Tech Corporation. The television manufacturing plant in Germany closed down in September 1996. The sale included a factory in Turku, and the rights to use the Nokia, Finlux, Luxor, Salora, Schaub-Lorenz and Oceanic brands until the end of 1999. Some of these brands were later sold to other companies.\n\nNokia was the first to launch digital satellite receivers in the UK, announced in March 1997. In August 1997 Nokia introduced the first digital satellite receiver with Common Interface (CI) support. In 1998 Nokia became the chosen supplier to produce the world's first digital terrestrial television set-top boxes by British Digital Broadcasting (BDB), which was eventually launched as ONdigital.\nIn October 1998, Nokia overtook Motorola to become the best-selling mobile phone brand, and in December manufactured its 100 millionth mobile phone. A major reason why Nokia grew against its main competitors Motorola and Ericsson was that it managed to cater to the consumer youth market and fashion-oriented consumers, most significantly with the Nokia 5110 and 3210 handsets which featured a large range of colourful and replacable back-covers called Xpress-on. One of the earliest fashion phones in 1992, from Swiss watchmaker Swatch, was based on Nokia's 101 handset. The company would also form the Vertu division, creating luxury mobile handsets.\n\nNokia claimed in April 1996 its 447Xav and 447K monitors to be the first with stereo speakers and a sub-woofer. In May 1999 Nokia introduced their first wireless LAN products. In January 2000 ViewSonic acquired Nokia Display Products, the division making displays for personal computers. On 26 April 2001 Nokia partnered with Telefonica to supply DSL modems and routers in Spain.\n\nIn 1998, Nokia co-founded Symbian Ltd. led by Psion to create a new operating system for PDAs and smart mobile phones as a successor of EPOC32. They released the Nokia 9210 Communicator running Symbian OS in 2001 and later that year created the Symbian Series 60 platform, later introducing it with their first camera phone, the Nokia 7650. Both Nokia and Symbian eventually became the largest smartphone hardware and software maker respectively, and in February 2004 Nokia became the largest shareholder of Symbian Ltd. Nokia acquired the entire company in June 2008 and then formed the Symbian Foundation as its successor.\n\nIn 1998 alone, the company had sales revenue of $20 billion making $2.6 billion profit. By 2000 Nokia employed over 55,000 people, and had a market share of 30% in the mobile phone market, almost twice as large as its nearest competitor, Motorola. The company was operating in 140 countries as of 1999. It was reported at the time that some people believed Nokia to be a Japanese company. Between 1996 and 2001, Nokia's turnover increased fivefold, from €6.5 billion to €31 billion.\n\nThe company would then be known as a successful and innovative maker of camera phones. The Nokia 3600/3650 was the first camera phone on sale in North America in 2003. In April 2005 Nokia partnered with German camera optics maker Carl Zeiss AG. That same month Nokia introduced the Nseries, which would become its flagship line of smart phones for the next six years. The Nokia N95 introduced in September 2006 became highly successful and was also awarded as \"best mobile imaging device\" in Europe in 2007. Its successor the N82 featured a xenon flash, which helped it win the award of \"best mobile imaging\" device in Europe in 2008. The N93 in 2006 was known for its specialized camcorder and the twistable design that switches between clamshell and a camcorder-like position. They were also well known for the N8 with a high resolution 12-megapixel sensor in 2010; the 808 PureView in 2012 with a 41-megapixel sensor; and the Lumia 920 flagship in 2012 which implemented advanced PureView technologies.\n\nNokia was one of the pioneers of mobile gaming due to the popularity of \"Snake\", which came pre-loaded on many products. In 2002, Nokia attempted to break into the handheld gaming market with the N-Gage. Nokia's head of entertainment and media, Ilkka Raiskinen, once quoted \"Game Boy is for 10-year-olds\", stating that N-Gage is more suited to a mature audience. However, the device was a failure, unable to challenge the dominant market leader Nintendo. Nokia attempted to revive N-Gage as a platform for their S60 smartphones, which eventually launched in 2008.\n\nIn Q1 2004, Nokia's mobile phone handset market share steeply dropped to 28.9%, down from 34.6% a year earlier. However by 2006 the company was steadily gaining again and in Q4 2007 reached its all-time high figure of 40.4%. Its smartphone market share in that quarter was 51%. Nokia was the largest vendor at the time in all regions bar North America.\n\nNokia launched mobile TV trials in 2005 in Finland with content provided by public broadcaster Yle. The services are based on the DVB-H standard. It could be viewed with the widescreen Nokia 7710 smartphone with a special accessory enabling it to receive DVB-H signals. Nokia partnered with Arqiva and O2 to launch trials in the UK in September 2005.\n\nIn 2005 Nokia developed a Linux-based operating system called Maemo, which shipped that year on the Nokia 770 Internet Tablet.\n\nOn 1 June 2006, Jorma Ollila became the company's chairman and retired as CEO, replaced by Olli-Pekka Kallasvuo.\n\nIn August 2007, Nokia introduced Ovi, an umbrella name for the company's new Internet services which included the N-Gage platform and the Nokia Music Store. The Ovi Store faced stiff competition against Apple's App Store when it was introduced in 2008.\n\nIn October 2008 Nokia announced the Nokia 5800 XpressMusic, the first device to ship with the new touch-centric S60 5th Edition, also known as Symbian^1, the first iteration of the platform since the creation of the Symbian Foundation. In November 2008 Nokia announced it would end mobile phone sales in Japan because of low market share. Nokia's global mobile phone market share peaked in 2008 at 38.6 percent. The same year, Nokia announced the acquisition of Trolltech and its Qt software development. Qt was a central part of Nokia's strategy until 2011, and it was eventually sold in 2012.\n\nNokia briefly returned to the computer market with the Booklet 3G netbook in August 2009.\n\nIn late 2009 and in 2010, the music-focused Xseries and consumer-focused Cseries were introduced respectively. In April 2010 Nokia introduced its next flagship mobile device, the Nokia N8, which would be the first to run on Symbian^3. However it was delayed for many months which tarnished the company's image, especially after the failure of its previous flagship N97 and tougher competition from Apple and the rising Google. On 10 September 2010, Olli-Pekka Kallasvuo was fired as CEO and it was announced that Stephen Elop from Microsoft would take Nokia's CEO position, becoming the first non-Finnish director in Nokia's history. It as claimed that investors pressed Nokia's board to recruit an outsider to shake up management and break from the traditional \"Nokia way\". Ollila had also announced that he would step down as Nokia chairman by 2012. On 11 March 2011 Nokia announced that it had paid Elop a $6 million signing bonus as \"compensation for lost income from his prior employer\", on top of his $1.4 million annual salary.\nThe old Symbian OS became completely open source in February 2010. However, in November 2010 it was announced that the Symbian Foundation was closing and that Nokia would take back control of the Symbian operating system under closed licensing. By now Nokia was the only remaining company using the platform, along with carrier NTT DoCoMo in Japan, after both Samsung and Sony Ericsson moved to Android. Meanwhile, in 2010 for Nokia's Linux ambitions, Nokia collaborated with Intel to form the MeeGo project, after the merger of Nokia's own Maemo and Intel's Moblin.\n\nNokia's Symbian platform that had been the leading smartphone platform in Europe and Asia for many years was quickly becoming outdated and difficult for developers after the advent of iOS and Android. To counter this, Nokia planned to make their MeeGo Linux operating system, under development, the company's flagship on smartphones. Shortly after Elop's CEO tenure began, the Nokia board green-lit him the ability to change the company's mobile phones strategy, including changing operating systems. Veteran Anssi Vanjoki, head of the smartphones division, left the company around this time. His final appearance was at Nokia World 2010 when the Nokia E7 and other Symbian^3 devices were introduced. Eventually on 11 February 2011, a \"strategic partnership\" with Microsoft was announced which involves the use of Windows Phone as Nokia's primary operating system, relegating Symbian to a lower priority, as well as the combination of Microsoft services, such as Bing search and adCenter advertizing on Nokia devices, joint marketing and a \"shared roadmap\" between the two companies. This alliance, coupled with the CEO's \"Burning Platform\" memo, caused a great deal of media interest as well as divisions between analysts, fans and Nokia employees themselves. CEO Elop as well as chairman Ollila and the company's board of directors (which included future chairman Risto Siilasmaa) supported and defended the Microsoft deal. Vanjoki compared choosing Android to 'peeing in your pants for warmth in winter' (a Finnish proverb) shortly before his departure in September 2010. Former CEO Kallasvuo had already dismissed Android when Google announced it in 2007.\n\nAlthough the MeeGo \"Harmattan\"-based N9 was met with a highly positive reception in 2011, Nokia had already decided to end development on MeeGo and solely focus on its Microsoft partnership, although the CEO said that the N9's \"innovations\" will live on in the future, which eventually made their way on the Asha platform in 2013. After the announcement of the Microsoft partnership, Nokia's market share deteriorated; this was due to demand for Symbian dropping when consumers realized Nokia's focus and attention would be elsewhere. The company posted a large loss for the second quarter of 2011 - only their second quarterly loss in 19 years. Nokia's first Windows Phone flagship was the Lumia 800, which arrived in November 2011. Falling sales in 2011, which were not being improved significantly with the Lumia line in 2012, led to consecutive quarters of huge losses. By mid-2012 the company's stock price fell below $2. CEO Elop announced cost-cutting measures in June by shedding 10,000 employees by the end of the year and the closure of the Salo manufacturing plant. The Finnish prime minister also announced that the government won't save the company from an emergency state fund. Around this time Nokia started a new project codenamed \"Meltemi\", a platform for low-end smartphones. With the Microsoft alliance and under Elop's management, Nokia also had a renewed focus on the North American market where Nokia phones were, in stark contrast to the rest of the world, almost irrelevant for many years. This strategy began in January 2012 with the introduction of the Nokia Lumia 900 smartphone in partnership with U.S. carrier AT&T.\n\nIn March 2011, Nokia introduced a new corporate typeface called \"Pure\". On 1 August 2011, Nokia announced that it would adopt a new three-digit naming system for mobile phone products and stop using letters, effectively ending the Nseries, Eseries, and short-lived Cseries. That same day the Nokia 500 was introduced with the new system. Nokia last used three-digit names on analogue phones in the 1990s.\n\nWhen the Lumia 920 was announced in September 2012, it was seen by the press as the first high-end Windows Phone that could challenge rivals due to its advanced feature set. Elop said that the positive reaction to it had created a sense of hope and optimism in the company. The company was also making gains in developing countries with its Asha series, which were selling strongly. Although Nokia's smartphone sales and market share greatly increased throughout 2013, including in the North American market, it was still not enough to avoid financial losses. Ollila stepped down as chairman on 4 May 2012 and was replaced by Risto Siilasmaa.\nIn September 2013 Nokia announced the sale of its mobile and devices division to Microsoft. The sale was positive for Nokia to avoid further negative financial figures, as well as for Microsoft's CEO Steve Ballmer, who wanted Microsoft to produce more hardware and turn it into a devices and services company. The Nokia chairman, Risto Siilasmaa, described the deal as rationally correct (in the best interests of Nokia shareholders), but emotionally difficult - experts agree that Nokia would have been in a cash crisis had it not sold the division to Microsoft. Analysts believe that Ballmer pushed for the buyout because of fears that Nokia was close to adopting Android and abandoning their alliance with Microsoft. There had been speculation for long that Nokia was experimenting with Android at the time. Indeed, in January 2014 the Nokia X was introduced which ran on a customised version of Android. It was a surprising and somewhat odd launch coming just weeks away from the finalisation of the Microsoft buyout. Others, including Ballmer's successor Satya Nadella, felt that Microsoft thought merging their software teams with Nokia's hardware engineering and designs would \"accelerate\" growth of Windows Phone. The sale was completed in April 2014, with Microsoft Mobile becoming the successor to Nokia's mobile devices division. Nokia also moved from its headquarters to another building complex located at Karaportti. At the time, Ballmer himself was retiring as Microsoft CEO and was replaced by Satya Nadella, who opposed the Nokia mobile phones purchase, along with chairman Bill Gates. The purchased assets from Nokia were eventually written-off by Microsoft in 2015.\n\nBy 2014, Nokia's global brand value according to Interbrand fell to 98th place, a sharp slide from the 5th place it was in 2009. Nokia's downfall in the mobile phone market has had different explanations from analysts, with many split about the CEO's decision to abandon its in-house operating system and adopting Windows Phone in 2011. Many researchers have concluded that Nokia suffered from deep internal rivalries within the management. Former employees claimed that the management became so swollen by the early success that they grew complacent over time. Some from the Symbian developing team have claimed that the company's upper management rejected hundreds of potential innovations during the 2000s that they proposed, including entirely rewriting Symbian's code. One former Nokia employee claimed that the company was run as a \"Soviet-style bureaucracy\".\n\nIn July 2013, Nokia bought Siemens' stake in the Nokia Siemens Networks joint venture for $2.2 billion, turning it into a wholly owned subsidiary called Nokia Solutions and Networks, until being rebranded as Nokia Networks soon after. During Nokia's financial struggles, its profitable networking division with Siemens provided much of its income; thus, the purchase proved to be positive, particularly after the sale of its mobile devices unit.\n\nAfter the sale of its mobile devices division, Nokia focused on network equipment through Nokia Networks.\n\nIn October 2014, Nokia and China Mobile signed a US$970 million framework deal for delivery between 2014 and 2015.\n\nOn 17 November 2014, Nokia Technologies head Ramzi Haidamus disclosed that the company planned to re-enter the consumer electronics business as an original design manufacturer, licensing in-house hardware designs and technologies to third-party manufacturers. Haidamus stated that the Nokia brand was \"valuable\" but \"is diminishing in value, and that's why it is important that we reverse that trend very quickly, imminently.\" The next day, Nokia unveiled the N1, an Android tablet manufactured by Foxconn, as its first product following the Microsoft sale. Haidamus emphasized that devices released under these licensing agreements would be held to high standards in production quality, and would \"look and feel just like Nokia built it.\" Nokia CEO Rajeev Suri stated that the company planned to re-enter the mobile phone business in this manner in 2016, following the expiration of its non-compete clause with Microsoft.\n\nAccording to Robert Morlino, the spokesman of Nokia Technologies, Nokia planned follow the brand-licensing model rather than direct marketing of mobile devices due to the sale of its mobile devices division to Microsoft. The company took aggressive steps to revitalize itself, evident through its hiring of software experts, testing of new products and seeking of sales partners. On 14 July 2015, CEO Rajeev Suri confirmed that the company would make a return to the mobile phones market in 2016.\n\nOn 28 July 2015, Nokia announced OZO, a 360-degrees virtual reality camera, with eight 2K optical image sensors. The division behind the product, Nokia Technologies, claimed that OZO would be the most advanced VR film-making platform. Nokia's press release stated that OZO would be \"the first in a planned portfolio of digital media solutions,\" with more technologic products expected in the future. OZO was fully unveiled on 30 November in Los Angeles. The OZO, designed for professional use, was intended for retail for US$60,000; however, its price was decreased by $15,000 prior to release, and is listed on its official website as $40,000.\n\nOn 14 April 2015, Nokia confirmed that it was in talks with the French telecommunications equipment company Alcatel-Lucent regarding a potential merger. The next day, Nokia announced that it had agreed to purchase Alcatel-Lucent for €15.6 billion in an all-stock deal. CEO Rajeev Suri felt that the purchase would give Nokia a strategic advantage in the development of 5G wireless technologies. The acquisition created a stronger competitor to the rival firms Ericsson and Huawei, whom Nokia and Alcatel-Lucent had surpassed in terms of total combined revenue in 2014. Nokia shareholders hold 66.5% of the new combined company, while Alcatel-Lucent shareholders hold 33.5%. The Bell Labs division was to be maintained, but the Alcatel-Lucent brand would be replaced by Nokia. In October 2015, following approval of the deal by China's Ministry of Commerce, the merger awaited approval by French regulators. Despite the initial intent of selling the submarine cable division separately, Alcatel-Lucent later declared that it would not. The merger closed on 14 January 2016, but was not complete until 3 November 2016. From the acquisition Nokia is now also the owner of the Alcatel mobile phone brand, which continues to be licensed to TCL Corporation.\n\nOn 3 August 2015, Nokia announced that it had reached a deal to sell its Here digital maps division to a consortium of BMW, Daimler AG and Volkswagen Group for €2.8 billion. The deal closed on 3 December 2015.\n\nOn 26 April 2016, Nokia announced its intent to acquire French connected health device maker Withings for US$191 million. The company was integrated into a new Digital Health unit of Nokia Technologies. Nokia later wrote off the cost of the acquisition and in May 2018 the health unit was sold back to Éric Carreel, a Withings co-founder and former CEO.\n\nOn 18 May 2016, Microsoft Mobile sold its Nokia-branded feature phone business to HMD Global, a new company founded by former Nokia executive Jean-Francois Baril, and an associated factory in Vietnam to Foxconn's FIH Mobile subsidiary. Nokia subsequently entered into a long-term licensing deal to make HMD the exclusive manufacturer of Nokia-branded phones and tablets outside Japan, operating in conjunction with Foxconn. The deal also granted HMD the right to essential patents and featurephone software. HMD subsequently announced the Android-based Nokia 6 smartphone in January 2017. At Mobile World Congress, HMD additionally unveiled the Nokia 3 and Nokia 5 smartphones, as well as a re-imagining of Nokia's classic 3310 feature phone. While Nokia has no investment in the company, they do have some input in the new devices.\n\nOn 28 June 2016 Nokia demonstrated for the first time a 5G-ready network. In February 2017 Nokia carried out a 5G connection in Oulu, Finland using the 5GTF standard, backed by Verizon, on Intel architecture-based equipment.\n\nOn 5 July 2017, Nokia and Xiaomi announced that they have signed a business collaboration agreement and a multi-year patent agreement, including a cross license to each company's cellular standard essential patents.\n\nIn 2017, Nokia's brand value jumped 147 places to 188th place compared to 2016 in the Brand Finance ranking. Its rise was attributed to its health portfolio and new mobile phones developed by HMD Global.\n\nOn 19 January 2018, Nokia signed a deal with NTT Docomo, Japan's largest mobile operator, to provide 5G wireless radio base stations in the country by 2020.\n\nOn 29 January 2018, Nokia introduced the ReefShark line of 5G chipsets, claiming that it triples bandwidth to 84 Gbit/s. It will be released by Q3 2018. It also incorporates artificial intelligence technologies from Bell Labs.\n\nOn 13 March 2018, Solidium, the investment arm of the Finnish government, purchased a 3.3% stake in Nokia valued at €844 million.\n\nOn 7 May 2018, Nokia announced that it has acquired a California based IoT startup, SpaceTime Insight.\n\nNokia is a public limited-liability company listed on the Helsinki and New York stock exchanges. Nokia has played a very large role in the economy of Finland, and it is an important employer in the country, working with multiple local partners and subcontractors. Nokia contributed 1.6% to Finland's GDP and accounted for about 16% of the country's exports in 2006.\n\nNokia comprises two business groups along with further subsidiaries and affiliated firms.\n\nNokia Networks is Nokia Corporation's largest division. It is a multinational data networking and telecommunications equipment company headquartered in Espoo, Finland, and is the world's third-largest telecoms equipment manufacturer, measured by 2017 revenues (after Huawei and Cisco). In USA it competes with Ericsson on building 5G networks for operators, while Huawei Technologies and ZTE Corporation were effectively banned.\n\nIt has operations in around 150 countries.\n\nNokia Networks provides wireless and fixed network infrastructure, communications and networks service platforms and professional services to operators and service providers. It focuses on GSM, EDGE, 3G/W-CDMA, LTE and WiMAX radio access networks, supporting core networks with increasing IP and multiaccess capabilities and services.\n\nThe Nokia Siemens Networks (NSN) brand identity was launched at the 3GSM World Congress in Barcelona in February 2007 as a joint venture between Nokia (50.1%) and Siemens (49.9%), although it is now wholly owned by Nokia. In July 2013, Nokia bought back all shares in Nokia Siemens Networks for a sum of US$2.21 billion and renamed it to Nokia Solutions and Networks, shortly thereafter changed to simply Nokia Networks.\n\nNokia Technologies is a division of Nokia that develops consumer products and licenses technology including the \"Nokia\" brand. Its focuses are imaging, sensing, wireless connectivity, power management and materials, and other areas such as the IP licensing program. It consists of three labs: Radio Systems Lab, in areas of radio access, wireless local connectivity and radio implementation; Media Technologies Lab, in areas of multimedia and interaction; and Sensor and Material Technologies Lab, in areas of advanced sensing solutions, interaction methods, nanotechnologies and quantum technologies. Nokia Technologies also provides public participation in its development through the \"Invent with Nokia\" program. It was created in 2014 following a restructuring of Nokia Corporation.\n\nIn November 2014, Nokia Technologies launched its first product, the Nokia N1 tablet computer. In July 2015, Nokia Technologies introduced a VR camera called OZO, designed for professional content creators and developed in Tampere, Finland. With its 8 synchronized shutter sensors and 8 microphones, the product can capture stereoscopic 3D video and spatial audio.\n\nOn 31 August 2016, Ramzi Haidamus announced he would be stepping down from his position as president of Nokia Technologies. Brad Rodrigues, previously head of strategy and business development, assumed the role of interim president. On 30 June 2017, Gregory Lee, previously CEO of Samsung Electronics in North America, was appointed Nokia Technologies CEO and president.\n\nNokia Bell Labs is a research and scientific development firm that was once the R&D arm of the American Bell System. It became a subsidiary of Nokia Corporation after the takeover of Alcatel-Lucent in 2016.\n\nNGP Capital (formerly Nokia Growth Partners) is a global venture capital firm, focusing in investments on growth stage \"Internet of things\" (IoT) and mobile technology companies. NGP holds investments throughout the U.S., Europe, China and India. Their portfolio consists of companies in mobile technology including the sectors Connected Enterprise, Digital Health, Consumer IoT and Connected Car. Following a $350 million funding for IoT companies in 2016, NGP manages $1 billion worth of assets.\n\nNokia had previously promoted innovation through venture sponsorships dating back to 1998 with Nokia Venture Partners, which was renamed BlueRun Ventures and spun off in 2005. Nokia Growth Partners (NGP) was founded in 2005 as a growth stage venture fund as a continuation of the early successes of Nokia Venture Partners. In 2017, the company was renamed to NGP Capital.\n\nNGP's largest exits include GanJi, UCWeb, Whistle, Rocket Fuel, Swype, Summit Microelectronics and Netmagic.\n\nNuage Networks is a venture providing software-defined networking (SDN) solutions. It was formed by Alcatel-Lucent in 2013 to develop a software overlay for automating and orchestrating hybrid clouds. It has been part of Nokia following their acquisition of Alcatel-Lucent in 2016. Throughout 2017 Nuage sealed deals with Vodafone and Telefonica to provide its SD-WAN architecture to their servers. BT had already been a client since 2016. A deal with China Mobile in January 2017 also used Nuage's SDN technology for 2,000 public cloud servers at existing data centers in China, and another in October 2017 with China Pacific Insurance Company.\n\nThe company is based in Mountain View, California and the CEO is Sunil Khandekar.\n\nAlcatel Mobile is a mobile phone brand owned by Nokia since 2016. It has been licensed since 2005 to Chinese company TCL when it was under the ownership of Alcatel (later Alcatel-Lucent) in a contract until 2024.\n\nHMD Global is a mobile phone company based at the same building as Nokia's headquarters in Espoo, Finland. The Nokia brand has been licensed by former Nokia employees who founded HMD Global and introduced Nokia-branded Android-based devices to the market in 2017. Nokia has no investment in the company but retains some input in the development of its devices.\n\nAlcatel Submarine Networks (ASN) is a provider of turnkey undersea network solutions.The business unit develops technology and offers installation services for optical submarine cable network links across the world’s oceans. \n\nThe control and management of Nokia is divided among the shareholders at a general meeting and the Nokia Group Leadership Team (left), under the direction of the board of directors (right). The chairman and the rest of the Nokia Leadership Team members are appointed by the board of directors. Only the chairman of the Nokia Leadership Team can belong to both the board of directors and the Nokia Group Leadership Team. The Board of Directors' committees consist of the Audit Committee, the Personnel Committee, and the Corporate Governance and Nomination Committee.\n\nThe operations of the company are managed within the framework set by the Finnish Companies Act, Nokia's Articles of Association, and Corporate Governance Guidelines, supplemented by the board of directors' adopted charters.\n\nNokia is a public limited liability company and is the oldest company listed under the same name on the Helsinki Stock Exchange, beginning in 1915. Nokia has had a secondary listing on the New York Stock Exchange since 1994. Nokia shares were delisted from the London Stock Exchange in 2003, the Paris Stock Exchange in 2004, the Stockholm Stock Exchange in 2007 and the Frankfurt Stock Exchange in 2012. Due to the acquisition of Alcatel-Lucent in 2015, Nokia listed its shares again on the Paris Stock Exchange and was included in the CAC 40 index on 6 January 2016.\n\nIn 2007, Nokia had a market capitalization of €110 billion; by 17 July 2012 this had fallen to €6.28 billion, and by 23 February 2015, it increased to €26.07 billion.\n\nNokia's official corporate culture manifesto since the 1990s is called \"The Nokia Way\". It emphasizes the speed and flexibility of decision-making in a flat, networked organization.\n\nThe official business language of Nokia is English. All documentation is written in English, and is used in official intra-company communication.\n\nIn 1992, Nokia adopted values that were defined with the key words \"respect\", \"achievement\", \"renewal\" and \"challenge\". In May 2007, the company redefined its values after initiating a series of discussion across its worldwide branches regarding what the new values of the company should be. Based on the employee suggestions, the new values were defined as: \"Engaging You\", \"Achieving Together\", \"Passion for Innovation\" and \"Very Human\". In August 2014, Nokia redefined its values again after the sale of its Devices business, using the original 1992 values again.\n\nNokia are based at Karaportti in Espoo, Finland, just outside capital Helsinki. It has been their head office since 2014 after moving from the purpose-built Nokia House in Espoo as part of the sale of the mobile phone business to Microsoft. The building in Karaportti was previously the headquarters of NSN (now Nokia Networks).\n\nIn 2018, Nokia received the Leading Lights award for most innovative cable/video product and was named to Ethisphere's 2018 world's most ethical companies list.\n\nIn 2008, Nokia Siemens Networks, a joint venture between Nokia and Siemens AG, reportedly provided Iran's monopoly telecom company with technology that allowed it to intercept the Internet communications of its citizens. The technology reportedly allowed Iran to use deep packet inspection to read and change the content of emails, social media, and online phone calls. The technology \"enables authorities to not only block communication but to monitor it to gather information about individuals, as well as alter it for disinformation purposes\".\n\nDuring the post-election protests in Iran in June 2009, Iran's Internet access was reported to have slowed to less than a tenth of its normal speeds, which experts suspected was due to use of deep packet inspection.\n\nIn July 2009, Nokia began to experience a boycott of their products and services in Iran. The boycott was led by consumers sympathetic to the post-election protest movement and targeted companies deemed to be collaborating with the regime. Demand for handsets fell and users began shunning SMS messaging.\n\nNokia Siemens Networks asserted in a press release that it provided Iran only with a \"lawful intercept capability solely for monitoring of local voice calls\" and that it \"has not provided any deep packet inspection, web censorship, or Internet filtering capability to Iran\".\n\nIn 2009, Nokia heavily supported a law in Finland that allows companies to monitor their employees' electronic communications in cases of suspected information leaking. Nokia denied rumors that the company had considered moving its head office out of Finland if laws on electronic surveillance were not changed. The Finnish media dubbed the law \"Lex Nokia\" because it was implemented as a result of Nokia's pressure.\n\nThe law was enacted, but with strict requirements for implementation of its provisions. No company had used its provisions prior to 25 February 2013, when the Office of Data Protection Ombudsman confirmed that city of Hämeenlinna had recently given the required notice.\n\nIn October 2009, Nokia filed a lawsuit against Apple Inc. in the U.S. District Court of Delaware claiming that Apple infringed on 10 of its patents related to wireless communication including data transfer. Apple was quick to respond with a countersuit filed in December 2009 accusing Nokia of 11 patent infringements. Apple's general counsel, Bruce Sewell went a step further by stating, \"Other companies must compete with us by inventing their own technologies, not just by stealing ours.\" This resulted in a legal battle between the two telecom majors with Nokia filing another suit, this time with the U.S. International Trade Commission (ITC), alleging Apple of infringing its patents in \"virtually all of its mobile phones, portable music players and computers\". Nokia went on to ask the court to ban all U.S. imports of the Apple products, including the iPhone, Macintosh and iPod. Apple countersued by filing a complaint with the ITC in January 2010.\n\nIn June 2011, Apple settled with Nokia and agreed to an estimated one time payment of $600 million and royalties to Nokia. The two companies also agreed on a cross-licensing patents for some of their patented technologies.\n\nNokia's Indian subsidiary has been charged in January 2013 with non-payment of TDS and transgressing transfer pricing norms in India. The unpaid TDS of 30 billion, accrued during a course of six years, was due to royalty paid by the Indian subsidiary to its parent company.\n\n"}
{"id": "2376390", "url": "https://en.wikipedia.org/wiki?curid=2376390", "title": "Nuclear lightbulb", "text": "Nuclear lightbulb\n\nA nuclear lightbulb is a hypothetical type of spacecraft engine using a gaseous fission reactor to achieve nuclear propulsion. Specifically it would be a type of gas core reactor rocket that separates nuclear fuel from coolant/propellant with a quartz wall. It would be operated at such high temperature (approx. 25,000°C) that the vast majority of the electromagnetic emissions would be in the hard ultraviolet range. Fused silica is almost completely transparent to this light, so it would be used to contain the uranium hexafluoride and allow the light to heat reaction mass in a rocket or to generate electricity using a heat engine or photovoltaics. \n\nThis type of reactor shows great promise in both of these roles. As a rocket engine it, like all nuclear rocket designs, can greatly exceed the power density of a chemical rocket. However, it also does not involve the release of any radioactive material from the rocket, unlike open cycle designs which would cause nuclear fallout if used in a planetary atmosphere (e.g. Project Orion). As a method to generate electricity, nuclear lightbulbs are extremely efficient because higher-temperature heat contains more Gibbs free energy than the low-temperature heat produced in current fossil-fuel plants and water-cooled nuclear reactors. The theoretical specific impulse (\"I\") range from 1500 to 3000 seconds.\n\n"}
{"id": "855103", "url": "https://en.wikipedia.org/wiki?curid=855103", "title": "Olivetti", "text": "Olivetti\n\nOlivetti S.p.A. is an Italian manufacturer of typewriters, computers, tablets, smartphones, printers and other such business products as calculators and fax machines. Headquartered in Ivrea, in the Metropolitan City of Turin, the company has been part of the Telecom Italia Group since 2003. The first commercial programmable \"desktop computer\", the Programma 101, was produced by Olivetti in 1964 and was a commercial success.\n\nThe company was founded as a typewriter manufacturer by Camillo Olivetti in 1908 in Ivrea, Italy. The firm was mainly developed by his son Adriano Olivetti. Olivetti opened its first overseas manufacturing plant in 1930, and its Divisumma electric calculator was launched in 1948. Olivetti produced Italy's first electronic computer, the transistorised Elea 9003, in 1959, and purchased the Underwood Typewriter Company that year. In 1964 the company sold its electronics division to the American company General Electric. It continued to develop new computing products on its own; one of these was Programma 101, the first commercially produced personal computer. In the 1970s and 1980s they were the biggest manufacturer for office machines in Europe and 2nd biggest PC vendor behind IBM in Europe.\n\nIn 1980, Olivetti began distributing in Indonesia through Dragon Computer & Communication.\n\nIn 1981, Olivetti installed the electronic voting systems for the European Parliament in Strasburg and Luxembourg.\n\nIn September 1994, the company launched Olivetti Telemedia chaired by Elserino Piol.\n\nFrom 2003 is part of the TIM Group.\n\nOlivetti was famous for the attention it gave to design: In 1952, the Museum of Modern Art held an exhibit titled \"Olivetti: Design in Industry\"; today, many Olivetti products are still part of the museum's permanent collection. Another major show, mounted by the Musée des Arts Décoratifs in Paris in 1969, toured five other cities. Olivetti was also renowned for the caliber of the architects it engaged to design its factories and offices, including Le Corbusier, Louis Kahn, Gae Aulenti, Egon Eiermann, Figini-Pollini, Ignazio Gardella, Carlo Scarpa, BBPR, and many others.\n\nFrom the 1940s to the 1960s, Olivetti industrial design was led by Marcello Nizzoli, responsible for the Lexicon 80 (1948) and the portable Lettera 22 (1950). Later, Mario Bellini and Ettore Sottsass directed design. Bellini designed the Programma 101 (1965), Divisumma 18 (1973) and Logos 68 (1973) calculators and the TCV-250 video display terminal (1966), among others. Sottsass designed the Tekne 3 typewriter (1958), Elea 9003 computer (1959), the Praxis 48 typewriter (1964), the Valentine portable typewriter (1969), and others. Michele De Lucchi designed the Art Jet 10 inkjet printer (1999) (winner of the Compasso d'Oro) and the Gioconda calculator (2001). During the 1970s Olivetti manufactured and sold two ranges of minicomputers. The 'A' series started with the typewriter-sized A4 through to the large A8, and the desk-sized DE500 and DE700 series. George Sowden worked for Olivetti from 1970 until 1990, and designed their first desktop computer, Olivetti L1, in 1978 (following ergonomic research lasting two years). In 1991, Sowden won the prestigious ADI Compasso d'Oro Award for the design of the Olivetti fax OFX420.\n\nOlivetti paid attention to more than the importance of product design; graphic and architectural design were also considered pivotal to the company. Giovanni Pintori was hired by Adriano Olivetti in 1936 to work in the publicity department. Pintori was the creator of the Olivetti logo and many promotional posters used to advertise the company and its products. During his activity as Art Director from 1950, Olivetti's graphic design obtained several international awards, and he designed works that created the Olivetti image and became emblematic Italian reference in the history of 20th-century design.\n\nThose designers also created the Olivetti Synthesis office furniture series which mainly were used to be installed in Olivetti's own headquarters, worldwide branch offices and show rooms. Olivetti also produced some industrial production machinery, including metal working machines of the Horizon series.\n\nOlivetti began with mechanical typewriters when the company was founded in 1909, and produced them until the mid 1990s. Until the mid 1960s they were fully mechanical, and models such as the portable Olivetti Valentine were designed by Ettore Sottsass.\n\nWith the Tekne/Editor series and Praxis 48, some of the first electromechanical typewriters were introduced. The Editor series was used for speed typing championship competition. The Editor 5 from 1969 was the top model of that series, with proportional spacing and the ability to support justified text borders.\n\nIn 1972 the electromechanical typeball machines of the Lexicon 90 to 94C series were introduced, as competitors to the IBM Selectric typewriters, the top model 94c supported proportional spacing and justified text borders like the Editor 5, as well as lift-off correction.\n\nIn 1978 Olivetti was one of the first manufacturers to introduce electronic daisywheel printer-based word processing machines called TES 401 and TES 501. Later the ET series typewriters without (or with) LCD and different levels of text editing capabilities were popular in offices. Models in that line were ET 121, ET 201, ET 221, ET 225, ET 231, ET 351, ET 109, ET 110, ET 111, ET 112, ET 115, ET 116, ET 2000, ET 2100, ET 2200, ET 2250, ET 2300, Et 2400 and ET 2500. For home users in 1982 the Praxis 35, Praxis 40 and 45D were some of the first portable electronic typewriters. Later, Olivetti added the Praxis 20, ET Compact 50, ET Compact 60, ET Compact 70, ET Compact 65/66, the ET Personal series and Linea 101. The top models were 8 lines LCD based portables like Top 100 and Studio 801, with the possibility to save the text to 3.5 inch floppy disk.\n\nThe professional line was upgraded with the ETV series video typewriters based on CP/M operating system, ETV 240, ETV 250, ETV 300, ETV 350 and later MS-DOS operating system based ETV 260, ETV 500, ETV 2700, ETV 2900, ETV 4000s word processing systems having floppy drives or hard disks. Some of them (ETV 300, 350, 500, 2900) were external boxes which could be connected through optional serial interface to many of the ET series office typewriters, the others were fully integrated with an external monitor which could be installed on a holder over the desk. Most of the ET/ETV/Praxis series electronic typewriters were designed by Marion Bellini.\n\nBy 1994, Olivetti stopped production of typewriters, as most users had transitioned to Personal Computers.\n\nBetween 1955 and 1964 Olivetti developed some of the first transistorized mainframe computer systems, such as the Elea 9003. Although 40 large commercial 9003 and over 100 smaller 6001 scientific machines were completed and leased to customers to 1964, low sales, loss of two key managers (arguably killed by US intelligence services) and financial instability caused Olivetti to withdraw from the field in 1964.\n\nIn 1965 Olivetti released the Programma 101, considered the first commercial desktop personal computer. It was saved from the sale of the computer division to GE thanks to an employee, Gastone Garziera, who spent successive nights changing the internal categorization of the product from \"computer\" to \"calculator\", so leaving the small team in Olivetti and creating some awkward situations in the office, since that space was now owned by GE.\n\nIn 1974 Olivetti released the TC800, an intelligent terminal designed to be attached to a mainframe and used in the finance sector. It was followed in 1977 by the TC1800.\n\nOlivetti's first modern personal computer, the M20, featuring a Zilog Z8000 CPU, was released in 1982. In 1983 Olivetti introduced the M24, a clone of the IBM PC using DOS and the Intel 8086 processor (at 8 MHz) instead of the Intel 8088 used by IBM (at 4.77 MHz). The M24 was sold in North America as the AT&T 6300. Olivetti also manufactured the AT&T 6300 Plus, which could run both DOS and Unix. The M24 in the US also was sold as Xerox 6060. The M28 was Olivetti’s first PC to have the Intel 80286 processor.\n\nIn 1983 Olivetti produced its M10 laptop computer, a 8085-based workalike of the successful Radio Shack TRS-80 Model 100, which it marketed in Europe. These were the first laptops to sell in million-unit quantities, though the itself only attained sales figures in the tens of thousands and went out of production within two years.\n\nIn 1985 the company acquired a controlling share in the British computer manufacturer Acorn Computers Ltd; a third partner was Thomson SA. Olivetti sold the Thomson MO6 and Acorn BBC Master Compact with brand names Olivetti Prodest PC128 and PC128s respectively. At the same time Olivetti also tried to compete with with the MS-DOS based Prodest PC1, but without success.\n\nIn 1987 Olivetti introduced the LSX line of computers which was based on the Motorola 68k processor. They could run either MOS or Olivetti's Unix, X/OS. In 1989 Olivetti introduced the 80486 based next generation of LSX workstations with the LSX 5020 with EISA-Bus, it was shown in CeBit 1989 as \"Computing Platform CP486\".\n\nIn 1990, Olivetti had its own distribution network in New Zealand through Essentially Software Ltd. (owned by Gary McNabb) located at Mt. Eden in Auckland and Wellington, where an Olivetti M300-100 16 MHz PCs with 80386SX CPU were sold for NZ$7395 and used as graphical work station for design houses using Corel Draw as graphical program. The New Zealand distribution stopped in 1991 when Olivetti could not supply their PCs.\n\nOlivetti also sold quasi-portable 8086/8088-based PCs with an integrated keyboard and one or two integrated 3.5\" floppy disk drives, running DOS 3.27, an Olivetti OEM version of PC DOS 3.20 with minor improvements like the M21 portable (based on M24) and the M15. Also later Olivetti produced interesting laptops like M111, M211, S20, D33, Philos and Echos series. A very interesting subnotebook was the Olivetti Quaderno, about the same size as an A5 paper – it was the grandfather of the netbooks introduced 20 years later.\n\nOlivetti did attempt to recover its position by introducing the Envision in 1995, a full multimedia PC, to be used in the living room; this project was a failure. Packard Bell managed to successfully introduce a similar product in the U.S. but only some years later. The main problem of the company was its inability to conjugate innovation with the quality standards it had committed itself to, at a time when the margins on the PC market were diminishing as not only the market but also the number of PC clone producers grew. The company continued to develop personal computers until it sold its PC business in 1997.\n\n\nIn the 1990s, Olivetti's computer businesses were in great difficulty, reportedly because of the competition from US vendors and new cheap manufacturers for PC components in Taiwan like ASUS, MSI, Gigabyte and so on from which local system builders profited much to offer cheaper PCs than Olivetti did with their own designs. It was on the brink of collapse and had needed government support to stay afloat. A company in transition, it had moved out of the typewriter business into personal computers before embracing telecoms between 1997 and 1999. In the process it had lost around three-quarters of its staff.\n\nIn 1999, The Luxembourg-based company Bell S.A. acquired a controlling stake in Olivetti, but sold it to a consortium including the Pirelli and Benetton groups two years later. Olivetti then launched a hostile bid for Telecom Italia in February 1999, despite being less than a seventh of the size of its target. In a take-over battle against Deutsche Telekom, and other potential bidders, Olivetti won out and controlled 52.12% of former monopoly Telecom Italia, Italy's #1 fixed-line and mobile phone operator. However, the ownership structure of the merged Olivetti / Telecom Italia was complex and multi-layered with Olivetti took on around $16 billion of extra debt. It was then referred to as the \"Olivetti/Telecom Italia affair\" because of the unpleasant secret affairs behind.\n\nAfter a 2003 reorganization Olivetti became the office equipment and systems services subsidiary of Telecom Italia. In 2003 Olivetti was absorbed into the Telecom Italia group, maintaining a separate identity as Olivetti Tecnost.\n\nIn 2005, Telecom Italia re-launched the company in the information technology sector, investing €200 million; at first restoring the original Olivetti brand, then replacing it with Olivetti Tecnost in 2003. In 2007, Olivetti launched the \"LINEA_OFFICE\", designed by Jasper Morrison for Olivetti; a new line of PCs, notebooks, printers, fax machines and calculators. Olivetti today operates in Italy and Switzerland, and has sales associates in 83 countries. Research and development are located in Agliè, Carsoli and Scarmagno in Italy, and Yverdon, Switzerland.\n\nIn March 2011 Olivetti began producing the OliPad, its first tablet computer, featuring a ten-inch screen, 3G, WiFi, Bluetooth connectivity, Nvidia Tegra 2, Android 2.2.2 and a 1024 x 600 display. It also features an application store, with apps specifically designed by Olivetti for 'business & government'. In 2014 the R&D department in Arnad was sold to SICPA.\n\nIn 2013, Olivetti launched a series of smartphones called \"Oliphone\":\n\n"}
{"id": "7531440", "url": "https://en.wikipedia.org/wiki?curid=7531440", "title": "Outline of information technology", "text": "Outline of information technology\n\nThe following outline is provided as an overview of and topical guide to information technology:\n\nInformation technology (IT) – microelectronics based combination of computing and telecommunications technology to treat information, including in the acquisition, processing, storage and dissemination of vocal, pictorial, textual and numerical information. It is defined by the Information Technology Association of America (ITAA) as \"the study, design, development, implementation, support or management of computer-based information systems, particularly software applications and computer hardware.\"\n\nThere are different names for this at different periods or through fields. Some of these names are:\n\n\n\nThird-party commercial organizations and vendor neutral interest groups that sponsor certifications include:\n\nGeneral certification of software practitioners has struggled. The ACM had a professional certification program in the early 1980s, which was discontinued due to lack of interest. Today, the IEEE is certifying software professionals, but only about 500 people have passed the exam .\n\n\n\n\n"}
{"id": "41297406", "url": "https://en.wikipedia.org/wiki?curid=41297406", "title": "PX4 autopilot", "text": "PX4 autopilot\n\nArduPilot is an open-source, unmanned vehicle Autopilot Software Suite,Low cost and availability enable hobbyist use in small remotely piloted aircraft. The project PixHawk(Not Px4 Autopilot) started in 2009 as a Hardware platform for Ardupilot and is being further developed and used at Computer Vision and Geometry Lab of ETH Zurich (Swiss Federal Institute of Technology) and supported by the Autonomous Systems Lab and the Automatic Control Laboratory. The First vesrion of PX4 Autopilot was released in 2012.\nAn autopilot allows a remotely piloted aircraft to be flown out of sight. All hardware and software is open-source and freely available to anyone under a BSD license. Free software autopilots provide more flexible hardware and software. Users can modify the autopilot based on their own special requirements.\n\nThe PX4 Auto pilot was developed to support Pixhawk flight controller later they added support for few more hardware boards.\n\nThe open-source software suite contains everything to let airborne system fly including\n\n\nOther open-source robotics projects similar to PX4 include:\n\n\n"}
{"id": "42186289", "url": "https://en.wikipedia.org/wiki?curid=42186289", "title": "Parametric design", "text": "Parametric design\n\nParametric design is a process based on algorithmic thinking that enables the expression of parameters and rules that, together, define, encode and clarify the relationship between design intent and design response.\n\nParametric design is a paradigm in design where the relationship between elements is used to manipulate and inform the design of complex geometries and structures.\n\nThe term \"parametric\" originates from mathematics (parametric equation) and refers to the use of certain parameters or variables that can be edited to manipulate or alter the end result of an equation or system. While today the term is used in reference to computational design systems, there are precedents for these modern systems in the works of architects such as Antoni Gaudí, who used analog models to explore design space.\n\nParametric modeling systems can be divided into two main types:\n\nForm-finding is one of the strategies implemented through propagation-based systems. The idea behind form-finding is to optimize certain design goals against a set of design constraints.\n\nOne of the earliest examples of parametric design was the upside down model of churches by Antonio Gaudi. In his design for the Church of Colònia Güell he created a model of strings weighted down with birdshot to create complex vaulted ceilings and arches. By adjusting the position of the weights or the length of the strings he could alter the shape of each arch and also see how this change influenced the arches connected to it. He placed a mirror on the bottom of the model to see how it should look upside-down.\n\nGaudi's analogue method includes the main features of a computational of a parametric model (input parameters, equation, output):\n\nBy modifying individual parameters of these models Gaudi could generate different versions of his model while being certain the resulting structure would stand in pure compression.\nInstead of having to manually calculate the results of parametric equations he could automatically derive the shape of the catenary curves through the force of gravity acting on the strings.\n\nWhere Gaudi used physical laws to speed up his calculation of parametric equations, Ivan Sutherland looked to the processing power of digital computers.\n\nSutherland created an interactive computer-aided design program called Sketchpad. Using a light pen, users could draw lines and arcs that could be related to each other using constraints. These constraints contained all the essential properties of parametric equations. Users could experiment and explore different designs by altering the parameters of an entity and let Sketchpad do the calculations and redraw the geometry according to the constraints imposed upon it.\n\nNature has always served as inspiration for architects and designers. Computer technology has given designers and architects the tools to analyse and simulate the complexity observed in nature and apply it to structural building shapes and urban organizational patterns. In the 1980s architects and designers started using computers running software developed for the aerospace and moving picture industries to \"animate form\".\n\nOne of the first architects and theorists that used computers to generate architecture was Greg Lynn. His blob and fold architecture is some of the early examples of computer generated architecture. Shenzhen Bao'an International Airport's new Terminal 3, finished in 2013, designed by Italian architect Massimiliano Fuksas, with parametric design support by the engineering firm Knippers Helbig, is an example for the use of parametric design and production technologies in a large scale building.\n\nParametric urbanism is concerned with the study and prediction of settlement patterns. Architect Frei Otto distinguishes occupying and connecting as the two fundamental processes that are in involved with all urbanisation. Studies look at producing solutions that reduce overall path length in systems while maintaining low average detour factor or facade differentiation.\n\nCATIA (Computer Aided three-dimensional Interactive Application) was used by architect Frank Gehry to design some of his award-winning curvilinear buildings such as the Guggenheim Museum Bilbao. Gehry Technologies, the technology arm of his firm, have since created Digital Project, their own parametric design software based on their experience with CATIA.\n\nAutodesk 3ds Max is a parametric 3D modeling software which provides modeling, animation, simulation, and rendering functions for games, film, and motion graphics. 3ds Max uses the concept of modifiers and wired parameters to control its geometry and gives the user the ability to script its functionality. Max Creation Graph is a visual programming node-based tool creation environment in 3ds Max 2016 that is similar to Grasshopper and Dynamo.\n\nAutodesk Maya is a 3D computer graphics software originally developed by Alias Systems Corporation (formerly Alias|Wavefront) and currently owned and developed by Autodesk, Inc. It is used to create interactive 3D applications, including video games, animated film, TV series, or visual effects. Maya exposes a node graph architecture. Scene elements are node-based, each node having its own attributes and customization. As a result, the visual representation of a scene is based on a network of interconnecting nodes, depending on each other's information. Maya is equipped with a cross-platform scripting language, called Maya Embedded Language. MEL is provided for scripting and a means to customize the core functionality of the software, since many of the tools and commands used are written in it. MEL or Python can be used to engineer modifications, plug-ins or be injected into runtime. User interaction is recorded in MEL, allowing novice users to implement subroutines.\n\nGrasshopper 3d (originally Explicit History) is a plug-in for Rhinoceros 3D that presents the users with a visual programming language interface to create and edit geometry.\n\nComponents or nodes are dragged onto a canvas in order to build a grasshopper definition. Grasshopper is based on graphs (see Graph (discrete mathematics)) that map the flow of relations from parameters through user-defined functions (nodes), resulting in the generation of geometry. Changing parameters or geometry causes to changes to propagate throughout all functions, and the geometry to be redrawn.\n\nAutodesk Revit is building information modeling (BIM) software used by architects and other building professionals. Revit was developed in response to the need for software that could create three-dimensional parametric models that include both geometry and non-geometric design and construction information. Every change made to an element in Revit is automatically propagated through the model to keep all components, views and annotations consistent. This eases collaboration between teams and ensures that all information (floor areas, schedules, etc.) are updated dynamically when changes in the model are made.\n\nDynamo is an open source graphical programming environment for design. Dynamo extends building information modeling with the data and logic environment of a graphical algorithm editor.\n\nGenerativeComponents, parametric CAD software developed by Bentley Systems, was first introduced in 2003, became increasingly used in practice (especially by the London architectural community) by early 2005, and was commercially released in November 2007. GenerativeComponents has a strong traditional base of users in academia and at technologically advanced design firms. GenerativeComponents is often referred to by the nickname of 'GC'. GC epitomizes the quest to bring parametric modeling capabilities of 3D solid modeling into architectural design, seeking to provide greater fluidity and fluency than mechanical 3D solid modeling.\n\nUsers can interact with the software by either dynamically modeling and directly manipulating geometry, or by applying rules and capturing relationships among model elements, or by defining complex forms and systems through concisely expressed algorithms. The software supports many industry standard file input and outputs including DGN by Bentley Systems, DWG by Autodesk, STL (Stereo Lithography), Rhino, and others. The software can also integrate with Building Information Modeling systems.\n\nThe software has a published API and uses a simple scripting language, both allowing the integration with many different software tools, and the creation of custom programs by users.\n\nThis software is primarily used by architects and engineers in the design of buildings, but has also been used to model natural and biological structures and mathematical systems.\n\nGenerative Components runs exclusively on Microsoft Windows operating systems, and in English.\n\nBentley Systems, Incorporated is offering GC as a technology preview of GC as a free download. This is a version of GC that no longer requires Bentley's MicroStation software for it to run, and that has features and a user interface focused on computational design.\n\nMarionette is an open source graphical scripting tool (or visual programming environment) for the architecture, engineering, construction, landscape, and entertainment design industries that is built into the Mac and Windows versions of Vectorworks software. The tool was first made available in the Vectorworks 2016 line of software products. Marionette enables designers to create custom application algorithms that build interactive parametric objects and streamline complex workflows, as well as build automated 2D drawing, 3D modeling, and BIM workflows within Vectorworks software.\n\nBuilt in the Python programming language, everything in Marionette consists of nodes which are linked together in a flowchart arrangement. Each node contains a Python script with predefined inputs and outputs that can be accessed and modified with a built-in editor. Nodes are placed directly into the Vectorworks document and then connected to create complex algorithms. Since Marionette is fully integrated into Vectorworks software, it can also be used to create entirely self-contained parametric objects that can be inserted into new and existing designs.\n\nModelur is a parametric urban design software plug-in for Trimble SketchUp, developed by Agilicity d.o.o. (LLC).. Its primary goal is to help the users create conceptual urban massing. In contrast to common CAD applications, where the user designs buildings with usual dimensions such as width, depth and height, Modelur offers design of built environment through key urban parameters such as number of storeys and gross floor area of a building.\n\nModelur calculates key urban control parameters on the fly (e.g. floor area ratio or required number of parking lots), delivering urban design information while the development is still evolving. This way it helps taking well-informed decision during the earliest stages, when design decisions have the highest impact.\n\nArchimatix is a node-based parametric modeler extension for Unity 3D. It enables visual modeling of 3D models within the Unity 3D editor.\n\n"}
{"id": "18538126", "url": "https://en.wikipedia.org/wiki?curid=18538126", "title": "Payment Services Directive", "text": "Payment Services Directive\n\nThe Payment Services Directive (PSD, Directive 2007/64/EC, replaced by PSD 2, Directive (EU) 2015/2366) is an EU Directive, administered by the European Commission (Directorate General Internal Market) to regulate payment services and payment service providers throughout the European Union (EU) and European Economic Area (EEA). The Directive's purpose was to increase pan-European competition and participation in the payments industry also from non-banks, and to provide for a level playing field by harmonizing consumer protection and the rights and obligations for payment providers and users.\n\nThe SEPA (Single Euro Payments Area) is a self-regulatory initiative by the European banking sector represented in the European Payments Council, which defines the harmonization of payment products, infrastructures and technical standards (Rulebooks for credit transfer/direct debit, BIC, IBAN, ISO 20022 XML message format, EMV chip cards/terminals). The PSD provides the legal framework within which all payment service providers must operate.\n\nThe PSD's purpose in regard to the payments industry was to increase pan-European competition with participation also from non-banks, and to provide for a level playing field by harmonizing consumer protection and the rights and obligations for payment providers and users.\nThe PSD's purpose in regard to consumers was to increase customer rights, guarantee faster payments (no later than next day from 1 January 2012 on), describe refund rights, and give clearer information on payments. Although the PSD is a maximum harmonisation directive, certain elements allow for different options by individual countries.\n\nThe final adopted text of PSD went into force 25 December 2007 and was to be transposed into national legislation by all EU and EEA member states by 1 November 2009 at the latest.\n\nThe PSD contains two main sections:\n\n\nEach country had to designate a 'competent authority' for prudential supervision of the PIs and to monitor compliance with business conduct rules, as transposed into national legislation.\n\nThe PSD was updated in 2009 (EC Regulation 924/2009) and 2012 (EU Regulation 260/2012). An implementation report from 2013 found the PSD facilitated \"provision of uniform payment services across the EU\" and reduced legal and production costs for many payment service providers and that \"the expected benefits have not yet been fully realised\". The same report found the 2009 update \"... to be functioning well. For example, charges for 100 EUR transfers followed a further downward trend to 0.50 EUR euro-area average for transfers initiated online and remained low, at 3.10 EUR for transfers initiated at the bank counter\".\n\n\nOn October 8, 2015, the European Parliament adopted the European Commission proposal to create safer and more innovative European payments (PSD2, Directive (EU) 2015/2366). The new rules aim to better protect consumers when they pay online, promote the development and use of innovative online and mobile payments such as through open banking, and make cross-border European payment services safer.\n\nCommissioner Jonathan Hill, responsible for Financial Stability, Financial Services and Capital Markets Union, said, \"This legislation is a step towards a digital single market; it will benefit consumers and businesses, and help the economy grow.\"\n\nOn November 16, 2015, the Council of the European Union passed PSD2. Member states will have two years to incorporate the directive into their national laws and regulations. \n\nThe EU and many banks are pushing this development with the new Payments Service Directive 2 (PSD2), which has come into force on 13 January 2018. Banks need to adapt to these changes that open many technical challenges, but also many strategic opportunities, such as collaborating with fintech providers, for the future.\n\nPSD2 does not specify the actual machine-to-machine API standards and specification details to be used. The banks and other financial institutions had to agree upon such details to ensure interoperability. The 'Berlin Group', a pan-European payments interoperability standards and harmonisation initiative with the primary objective of defining open and common scheme- and processor-independent standards in the interbanking domain between Creditor Bank (Acquirer) and Debtor Bank (Issuer), has worked on complementing the work carried out by e.g. the European Payments Council. As such, the Berlin Group has been established as a pure technical standardisation body, focusing on detailed technical and organisational requirements to achieve this primary objective. \n\nThe Open Bank Project, established in 2010 by TESOBE, provides open standards and open source technology to support PSD2 and Open Banking. It provides public \"sandboxes\" such as https://psd2-api.openbankproject.com/ where developers can try APIs using simulated data.\n\n\n\n\n"}
{"id": "25678162", "url": "https://en.wikipedia.org/wiki?curid=25678162", "title": "RFIC", "text": "RFIC\n\nRFIC is an abbreviation of Radio Frequency Integrated Circuit. Applications for RFICs include radar and communications, although the term RFIC might be applied to any electrical integrated circuit operating in a frequency range suitable for wireless transmission.\n\nThere is considerable interest in RFIC research due to the cost benefit of shifting as much of the wireless transceiver as possible to a single technology, which in turn would allow for a system on a chip solution as opposed to the more common system-on-package. This interest is bolstered by the pervasiveness of wireless capabilities in electronics. Current research focuses on integrating the RF power amplifier (PA) with CMOS technology, either by using MOSFETs or SiGe HBTs.\n\nRFIC is also used to refer to the annual RFIC Symposium, a research conference held as part of Microwave Week, which is headlined by the International Microwave Symposium. Other peer-reviewed research conferences are listed in the table below.\n\nIEEE Journal of Solid State Circuits\n\nIEEE Transactions on Microwave Theory and Techniques\n\n"}
{"id": "49233467", "url": "https://en.wikipedia.org/wiki?curid=49233467", "title": "SensorThings API", "text": "SensorThings API\n\nSensorThings API is an Open Geospatial Consortium (OGC) standard providing an open and unified framework to interconnect IoT sensing devices, data, and applications over the Web. It is an open standard addressing the syntactic interoperability and semantic interoperability of the Internet of Things. It complements the existing IoT networking protocols such CoAP, MQTT, HTTP, 6LowPAN. While the above-mentioned IoT networking protocols are addressing the ability for different IoT systems to exchange information, OGC SensorThings API is addressing the ability for different IoT systems to use and understand the exchanged information. As an OGC standard, SensorThings API also allows easy integration into existing Spatial Data Infrastructures or Geographic Information Systems.\n\nOGC SensorThings API has two parts: (1) Part I - Sensing and (2) Part II - Tasking. OGC SensorThings API Part I - Sensing was released for public comment on June 18, 2015. The OGC Technical Committee (TC) approves start of electronic vote on December 3, 2015, and the SensorThings API Part I - Sensing passed the TC vote on February 1, 2016. The official OGC standard specification was published online on July 26, 2016.\n\nOGC SensorThings API Part II - Tasking Core was released for public comment on February 20, 2018.\n\nSensorThings API is designed specifically for resource-constrained IoT devices and the Web developer community. It follows REST principles, the JSON encoding, and the OASIS OData protocol and URL conventions. Also, it has an MQTT extension allowing users/devices to publish and subscribe updates from devices, and can use CoAP in addition to HTTP.\n\nThe foundation of the SensorThings API is its data model that is based on the ISO 19156 (ISO/OGC Observations and Measurements), that defines a conceptual model for observations, and for features involved in sampling when making observations. In the context of the SensorThings, the features are modelled as \"Things\", \"Sensors\" (\"i.e.\", Procedures in O&M), and \"Feature of Interests\". As a result, the SensorThings API provides an interoperable Observation-focus view, that is particularly useful to reconcile the differences between heterogeneous sensing systems (e.g., \"in-situ\" sensors and remote sensors).\n\nAn IoT device or system is modelled as a \"Thing\". A \"Thing\" has an arbitrary number of \"Location\"s (including 0 \"Location\"s) and an arbitrary number of \"Datastreams\" (including 0 \"Datastream\"s). Each \"Datastream\" observes one \"ObservedProperty\" with one \"Sensor\" and has many \"Observations\" collected by the \"Sensor\". Each \"Observation\" observes one particular \"FeatureOfInterest\". The O&M based model allows SensorThings to accommodate heterogeneous IoT devices and the data collected by the devices.\n\nSensorThings API provides two main functionalities, each handled by a part. The two profiles are the Sensing part and the Tasking part. The Sensing part provides a standard way to manage and retrieve observations and metadata from heterogeneous IoT sensor systems, and the Sensing part functions are similar to the OGC Sensor Observation Service. The Tasking part provides a standard way for parameterizing - also called tasking - of task-able IoT devices, such as sensors or actuators. The Tasking part functions are similar to the OGC Sensor Planning Service. The Sensing part is designed based on the ISO/OGC Observations and Measurements (O&M) model, and allows IoT devices and applications to CREATE, READ, UPDATE, and DELETE (\"i.e.\", HTTP POST, GET, PATCH, and DELETE) IoT data and metadata in a SensorThings service.\n\nSensorThings API Part I - Sensing defines the following resources. As SensorThings is a RESTful web service, each entity can be CREATE, READ, UPDATE, and DELETE with standard HTTP verbs (POST, GET, PATCH, and DELETE):\nIn addition to the above sensing resources, SensorThings API Part II - Tasking Core defines the following resources:\n\ncodice_12\n\nIn order to reduce the data size transmitted over the network, SensorThings API data array extension allows users to request for multiple Observation entities and format the entities in the dataArray format. When a SensorThings service returns a dataArray response, the service groups Observation entities by Datastream or MultiDatastream, which means the Observation entities that link to the same Datastream or the same MultiDatastream are aggregated in one dataArray.\n\ncodice_13\n\n \"value\": [\n\nInteroperability between OpenIoT and SensorThings\n\"We believe that the implementation of the SensorThing API will be a major improvement for the OpenIoT middleware. It will give OpenIoT a standardized and truly easy to use interface to sensor values.This will complement the rich semantic reasoning services with a simple resource based interface. And the consistent data model mapping gives both a common context to describe the internet of things\".\n\nEfficiency of SensorThings API\nA comprehensive evaluation of the SensorThings API is published in Jazayeri, Mohammad Ali, Steve HL Liang, and Chih-Yuan Huang. \"Implementation and Evaluation of Four Interoperable Open Standards for the Internet of Things.\" \"Sensors\" 15.9 (2015): 24343-24373.\n\nSensorThings API was demonstrated in a pilot project sponsored by the Department of Homeland Security Science and Technology Directorate. Dr. Reginald Brothers, the Undersecretary of the Homeland Security Science and Technology, was \"impressed with the ‘state of the practical’ where these various industry sensors can be integrated today using open standards that remove the stovepipe limitations of one-off technologies. \"\n\n\nIn March 2016 SensorUp and the GeoSensorWeb Lab at the University of Calgary submitted an open source software project proposal to the Eclipse Foundation and has been approved. The project is called Whiskers. Whiskers is an OGC SensorThings API framework. It will have a Javascript client and a light-weight server for IoT gateway devices (e.g., Raspberry Pi or BeagleBone). Whiskers aim to foster a healthy and open IoT ecosystem, as opposed to one dominated by proprietary information silos. Whiskers aims to make SensorThings development easy for the large and growing world of IoT developers.\n\nGOST is an open source implementation of the SensorThings API in the Go programming language initiated by Geodan. It contains easily deployable server software and a Javascript client. Currently (June 2016) it is in development but a first version can already be downloaded and deployed. The software can be installed on any device supporting Docker or Go (e.g. Windows, Linux, Mac OS and Raspberry Pi). By default sensor data is stored in a PostgreSQL database.\n\nFROST-Server is a server implementation of the OGC SensorThings API. FROST-Server implements the entire specification, including all extensions. It is written in Java and can run in Tomcat or Wildfly and is available as a Docker image. Among its many features is the ability to use String or UUID based entity IDs.\n\nFROST-Client is a Java client library for communicating with a SensorThings API compatible server.\n\nSensorThings HcDT is a javascript charting library for the OGC SensorThings API. It is based on the open source Highchart library and Datatable. It is a front-end charting library enable developers to connect to datastreams from any OGC SensorThings API service, and display the sensor observations in charts, tables, or dashboard widgets for web applications.\n\nMozilla developed a node implementation of the OGC SensorThings API.\n\nOn Oct 8th 2016, a group of volunteers (smart citizens) in Calgary gathered together, assembled their own sensors, installed at their houses, and formed a crowd-sourced air quality sensor network. All data are publicly available via OGC SensorThings API. This citizen sensing efforts increased the number of Calgary's air quality sensors from 3 to more than 50.\n\nSmart emission is an air quality monitoring project in the city of Nijmegen, NL. The project deployed multiple air quality sensors throughout the city. Data are published with open standards, including OGC SensorThings API. Part of the project is an open source ETL engine to load the project sensor data into an OGC SensorThings API.\n\nThis dashboard provides easy-to-use client-side visualisation of Internet-of-Things sensor data from OGC SensorThings API compatible servers. Various types of widgets can be arranged and configured on the dashboard. It is a web application and can be embedded into any website. A live demo is available on the project page.\nhttps://github.com/SensorThings-Dashboard/SensorThings-Dashboard\n\nGOST Dashboard v2 is an open source library of custom HTML elements (web components) supporting SensorThings API. These elements facilitate the development of HTML applications integrating functionality and data from SensorThings API compatible services. The components are developed with Predix-UI and Polymer.\n\nSensorThings API provides functions similar to the OGC Sensor Observation Service, an OGC specification approved in 2005. Both standard specifications are under the OGC Sensor Web Enablement standard suite. The following table summarizes the technical difference between the two specifications.\n\n"}
{"id": "37515", "url": "https://en.wikipedia.org/wiki?curid=37515", "title": "Shaped charge", "text": "Shaped charge\n\nA shaped charge is an explosive charge shaped to focus the effect of the explosive's energy. Various types are used to cut and form metal, initiate nuclear weapons, penetrate armor, and \"complete\" wells in the oil and gas industry.\n\nA typical modern shaped charge, with a metal liner on the charge cavity, can penetrate armor steel to a depth of seven or more times the diameter of the charge (charge diameters, CD), though greater depths of 10 CD and above have been achieved. Contrary to a widespread misconception (possibly resulting from the acronym HEAT) the shaped charge does not depend in any way on heating or melting for its effectiveness; that is, the jet from a shaped charge does not melt its way through armor, as its effect is purely kinetic in nature.\n\nThe Munroe or Neumann effect is the focusing of blast energy by a hollow or void cut on a surface of an explosive. The earliest mention of hollow charges occurred in 1792. Franz Xaver von Baader (1765–1841) was a German mining engineer at that time; in a mining journal, he advocated a conical space at the forward end of a blasting charge to increase the explosive's effect and thereby save powder. The idea was adopted, for a time, in Norway and in the mines of the Harz mountains of Germany, although the only available explosive at the time was gunpowder, which is not a high explosive and hence incapable of producing the shock wave that the shaped-charge effect requires.\n\nThe first true hollow charge effect was achieved in 1883, by Max von Foerster (1845–1905), chief of the nitrocellulose factory of Wolff & Co. in Walsrode, Germany.\n\nBy 1886, Gustav Bloem of Düsseldorf, Germany had filed for hemispherical cavity metal detonators to concentrate the effect of the explosion in an axial direction. The Munroe effect is named after Charles E. Munroe, who discovered it in 1888. As a civilian chemist working at the U.S. Naval Torpedo Station at Newport, Rhode Island, he noticed that when a block of explosive guncotton with the manufacturer's name stamped into it was detonated next to a metal plate, the lettering was cut into the plate. Conversely, if letters were raised in relief above the surface of the explosive, then the letters on the plate would also be raised above its surface. In 1894, Munroe constructed the first crude shaped charge:\n\nAmong the experiments made ... was one upon a safe twenty-nine inches cube, with walls four inches and three quarters thick, made up of plates of iron and steel ... [W]hen a hollow charge of dynamite nine pounds and a half in weight and untamped was detonated on it, a hole three inches in diameter was blown clear through the wall ... The hollow cartridge was made by tying the sticks of dynamite around a tin can, the open mouth of the latter being placed downward.\n\nAlthough Munroe's discovery of the shaped charge was widely publicized in 1900 in \"Popular Science Monthly\", the importance of the tin can \"liner\" of the hollow charge remained unrecognized for another 44 years. Part of that 1900 article was reprinted in the February 1945 issue of \"Popular Science\", describing how shaped-charge warheads worked. It was this article that at last revealed to the general public how the fabled \"Bazooka\" actually worked against armored vehicles during WWII.\n\nIn 1910, Egon Neumann of Germany discovered that a block of TNT, which would normally dent a steel plate, punched a hole through it if the explosive had a conical indentation. The military usefulness of Munroe's and Neumann's work was unappreciated for a long time. Between the world wars, academics in several countries Myron Yakovlevich Sukharevskii (Мирон Яковлевич Сухаревский) in the Soviet Union, William H. Payment and Donald Whitley Woodhead in Britain, and Robert Williams Wood in the U.S. recognized that projectiles could form during explosions. However, it was not until 1932 that Franz Rudolf Thomanek, a student of physics at Vienna's \"Technische Hochschule\", conceived an anti-tank round that was based on the hollow charge effect. When the Austrian government showed no interest in pursuing the idea, Thomanek moved to Berlin's \"Technische Hochschule\", where he continued his studies under the ballistics expert Carl Julius Cranz. There in 1935, he and Hellmuth von Huttern developed a prototype anti-tank round. Although the weapon's performance proved disappointing, Thomanek continued his developmental work, collaborating with Hubert Schardin at the \"Waffeninstitut der Luftwaffe\" (Air Force Weapons Institute) in Braunschweig. \n\nBy 1937, Schardin believed that hollow-charge effects were due to the interactions of shock waves. It was during the testing of this idea that, on February 4, 1938, Thomanek conceived the shaped-charge explosive (or \"Hohlladungs-Auskleidungseffekt\" (hollow-charge liner effect)). (It was Gustav Adolf Thomer who in 1938 first visualized, by flash radiography, the metallic jet produced by a shaped-charge explosion.) Meanwhile, Henry Hans Mohaupt, a chemical engineer in Switzerland, had independently developed a shaped-charge munition in 1935, which was demonstrated to the Swiss, French, British, and U.S. militaries.\n\nDuring World War II, shaped-charge munitions were developed by Germany (Panzerschreck, Panzerfaust, Panzerwurfmine, Mistel), Britain (PIAT, Beehive charge), the Soviet Union (RPG-43, RPG-6), and the U.S. (bazooka). The development of shaped charges revolutionized anti-tank warfare. Tanks faced a serious vulnerability from a weapon that could be carried by an infantryman or aircraft.\n\nOne of the earliest uses of shaped charges was by German glider-borne troops against the Belgian Fort Eben-Emael in 1940. These demolition charges – developed by Dr. Wuelfken of the German Ordnance Office – were \"unlined\" explosive charges and didn't produce a metal jet like the modern HEAT warheads.\nDue to the lack of metal liner they shook the turrets but they did not destroy them, and other airborne troops were forced to climb on the turrets and smash the gun barrels.\n\nThe common term in military terminology for shaped charge warheads is high explosive anti-tank (HEAT). HEAT warheads are frequently used in anti-tank guided missiles, unguided rockets, gun-fired projectiles (both spun and unspun), rifle grenades, land mines, bomblets, torpedoes, and various other weapons.\n\nIn non-military applications shaped charges are used in explosive demolition of buildings and structures, in particular for cutting through metal piles, columns and beams and for boring holes. In steelmaking, small shaped charges are often used to pierce taps that have become plugged with slag. They are also used in quarrying, breaking up ice, breaking log jams, felling trees, and drilling post holes.\n\nShaped charges are used most extensively in the petroleum and natural gas industries, in particular in the completion of oil and gas wells, in which they are detonated to perforate the metal casing of the well at intervals to admit the influx of oil and gas.\n\nA typical device consists of a solid cylinder of explosive with a metal-lined conical hollow in one end and a central detonator, array of detonators, or detonation wave guide at the other end. Explosive energy is released directly away from (normal to) the surface of an explosive, so shaping the explosive will concentrate the explosive energy in the void. If the hollow is properly shaped (usually conically), the enormous pressure generated by the detonation of the explosive drives the liner in the hollow cavity inward to collapse upon its central axis. The resulting collision forms and projects a high-velocity jet of metal particles forward along the axis. Most of the jet material originates from the innermost part of the liner, a layer of about 10% to 20% of the thickness. The rest of the liner forms a slower-moving slug of material, which, because of its appearance, is sometimes called a \"carrot\".\n\nBecause of the variation along the liner in its collapse velocity, the jet's velocity also varies along its length, decreasing from the front. This variation in jet velocity stretches it and eventually leads to its break-up into particles. Over time, the particles tend to fall out of alignment, which reduces the depth of penetration at long standoffs.\n\nAlso, at the apex of the cone, which forms the very front of the jet, the liner does not have time to be fully accelerated before it forms its part of the jet. This results in its small part of jet being projected at a lower velocity than jet formed later behind it. As a result, the initial parts of the jet coalesce to form a pronounced wider tip portion.\n\nMost of the jet travels at hypersonic speed. The tip moves at 7 to 14 km/s, the jet tail at a lower velocity (1 to 3 km/s), and the slug at a still lower velocity (less than 1 km/s). The exact velocities depend on the charge's configuration and confinement, explosive type, materials used, and the explosive-initiation mode. At typical velocities, the penetration process generates such enormous pressures that it may be considered hydrodynamic; to a good approximation, the jet and armor may be treated as inviscid, compressible fluids (see, for example,), with their material strengths ignored.\n\nA recent technique using magnetic diffusion analysis showed that the temperature of the outer 50% by volume of a copper jet tip while in flight was between 1100K and 1200K, much closer to the melting point of copper (1358 K) than previously assumed. This temperature is consistent with a hydrodynamic calculation that simulated the entire experiment. In comparison, two-color radiometry measurements from the late 1970s indicate lower temperatures for various shaped charge liner material, cone construction and type of explosive filler. A Comp-B loaded shaped charge with a copper liner and pointed cone apex had a jet tip temperature ranging from 668 K to 863 K over a five shot sampling. Octol-loaded charges with a rounded cone apex generally had higher surface temperatures with an average of 810 K, and the temperature of a tin-lead liner with Comp-B fill averaged 842 K. While the tin-lead jet was determined to be liquid, the copper jets are well below the melting point of copper. However, these temperatures are not completely consistent with evidence that soft recovered copper jet particles show signs of melting at the core while the outer portion remains solid and cannot be equated with bulk temperature.\n\nThe location of the charge relative to its target is critical for optimum penetration for two reasons. If the charge is detonated too close there is not enough time for the jet to fully develop. But the jet disintegrates and disperses after a relatively short distance, usually well under two meters. At such standoffs, it breaks into particles which tend to tumble and drift off the axis of penetration, so that the successive particles tend to widen rather than deepen the hole. At very long standoffs, velocity is lost to air drag, further degrading penetration.\n\nThe key to the effectiveness of the hollow charge is its diameter. As the penetration continues through the target, the width of the hole decreases leading to a characteristic \"fist to finger\" action, where the size of the eventual \"finger\" is based on the size of the original \"fist\". In general, shaped charges can penetrate a steel plate as thick as 150% to 700% of their diameter, depending on the charge quality. The figure is for basic steel plate, not for the composite armor, reactive armor, or other types of modern armor.\n\nThe most common shape of the liner is conical, with an internal apex angle of 40 to 90 degrees. Different apex angles yield different distributions of jet mass and velocity. Small apex angles can result in jet bifurcation, or even in the failure of the jet to form at all; this is attributed to the collapse velocity being above a certain threshold, normally slightly higher than the liner material's bulk sound speed. Other widely used shapes include hemispheres, tulips, trumpets, ellipses, and bi-conics; the various shapes yield jets with different velocity and mass distributions.\n\nLiners have been made from many materials, including various metals and glass. The deepest penetrations are achieved with a dense, ductile metal, and a very common choice has been copper. For some modern anti-armor weapons, molybdenum and pseudo-alloys of tungsten filler and copper binder (9:1, thus density is ≈18 Mg/m) have been adopted. Nearly every common metallic element has been tried, including aluminum, tungsten, tantalum, depleted uranium, lead, tin, cadmium, cobalt, magnesium, titanium, zinc, zirconium, molybdenum, beryllium, nickel, silver, and even gold and platinum. The selection of the material depends on the target to be penetrated; for example, aluminum has been found advantageous for concrete targets.\n\nIn early antitank weapons, copper was used as a liner material. Later, in the 1970s, it was found tantalum is superior to copper, due to its much higher density and very high ductility at high strain rates. Other high-density metals and alloys tend to have drawbacks in terms of price, toxicity, radioactivity, or lack of ductility.\n\nFor the deepest penetrations, pure metals yield the best results, because they display the greatest ductility, which delays the breakup of the jet into particles as it stretches. In charges for oil well completion, however, it is essential that a solid slug or \"carrot\" not be formed, since it would plug the hole just penetrated and interfere with the influx of oil. In the petroleum industry, therefore, liners are generally fabricated by powder metallurgy, often of pseudo-alloys which, if unsintered, yield jets that are composed mainly of dispersed fine metal particles.\n\nUnsintered cold pressed liners, however, are not waterproof and tend to be brittle, which makes them easy to damage during handling. Bimetallic liners, usually zinc-lined copper, can be used; during jet formation the zinc layer vaporizes and a slug is not formed; the disadvantage is an increased cost and dependency of jet formation on the quality of bonding the two layers. Low-melting-point (below 500 °C) solder/braze-like alloys (e.g., SnPb, ZnPb, or pure metals like lead, zinc or cadmium) can be used; these melt before reaching the well casing, and the molten metal does not obstruct the hole. Other alloys, binary eutectics (e.g. PbSb, SnPd, or AgCu), form a metal-matrix composite material with ductile matrix with brittle dendrites; such materials reduce slug formation but are difficult to shape.\n\nA metal-matrix composite with discrete inclusions of low-melting material is another option; the inclusions either melt before the jet reaches the well casing, weakening the material, or serve as crack nucleation sites, and the slug breaks up on impact. The dispersion of the second phase can be achieved also with castable alloys (e.g., copper) with a low-melting-point metal insoluble in copper, such as bismuth, 1–5% lithium, or up to 50% (usually 15–30%) lead; the size of inclusions can be adjusted by thermal treatment. Non-homogeneous distribution of the inclusions can also be achieved. Other additives can modify the alloy properties; tin (4–8%), nickel (up to 30% and often together with tin), up to 8% aluminium, phosphorus (forming brittle phosphides) or 1–5% silicon form brittle inclusions serving as crack initiation sites. Up to 30% zinc can be added to lower the material cost and to form additional brittle phases.\n\nOxide glass liners produce jets of low density, therefore yielding less penetration depth. Double-layer liners, with one layer of a less dense but pyrophoric metal (e.g. aluminum or magnesium), can be used to enhance incendiary effects following the armor-piercing action; explosive welding can be used for making those, as then the metal-metal interface is homogeneous, does not contain significant amount of intermetallics, and does not have adverse effects to the formation of the jet.\n\nThe penetration depth is proportional to the maximum length of the jet, which is a product of the jet tip velocity and time to particulation. The jet tip velocity depends on bulk sound velocity in the liner material, the time to particulation is dependent on the ductility of the material. The maximum achievable jet velocity is roughly 2.34 times the sound velocity in the material. The speed can reach 10 km/s, peaking some 40 microseconds after detonation; the cone tip is subjected to acceleration of about 25 million g. The jet tail reaches about 2–5 km/s. The pressure between the jet tip and the target can reach one terapascal. The immense pressure makes the metal flow like a liquid, though x-ray diffraction has shown the metal stays solid; one of the theories explaining this behavior proposes molten core and solid sheath of the jet. The best materials are face-centered cubic metals, as they are the most ductile, but even graphite and zero-ductility ceramic cones show significant penetration.\n\nFor optimal penetration, a high explosive with a high detonation velocity and pressure is normally chosen. The most common explosive used in high performance anti-armor warheads is HMX (octogen), although never in its pure form, as it would be too sensitive. It is normally compounded with a few percent of some type of plastic binder, such as in the polymer-bonded explosive (PBX) LX-14, or with another less-sensitive explosive, such as TNT, with which it forms Octol. Other common high-performance explosives are RDX-based compositions, again either as PBXs or mixtures with TNT (to form Composition B and the Cyclotols) or wax (Cyclonites). Some explosives incorporate powdered aluminum to increase their blast and detonation temperature, but this addition generally results in decreased performance of the shaped charge. There has been research into using the very high-performance but sensitive explosive CL-20 in shaped-charge warheads, but, at present, due to its sensitivity, this has been in the form of the PBX composite LX-19 (CL-20 and Estane binder).\n\nA 'waveshaper' is a body (typically a disc or cylindrical block) of an inert material (typically solid or foamed plastic, but sometimes metal, perhaps hollow) inserted within the explosive for the purpose of changing the path of the detonation wave. The effect is to modify the collapse of the cone and resulting jet formation, with the intent of increasing penetration performance. Waveshapers are often used to save space; a shorter charge with a waveshaper can achieve the same performance as a longer charge without a waveshaper.\n\nAnother useful design feature is \"sub-calibration\", the use of a liner having a smaller diameter (caliber) than the explosive charge. In an ordinary charge, the explosive near the base of the cone is so thin that it is unable to accelerate the adjacent liner to sufficient velocity to form an effective jet. In a sub-calibrated charge, this part of the device is effectively cut off, resulting in a shorter charge with the same performance.\n\nDuring World War II, the precision of the charge's construction and its detonation mode were both inferior to modern warheads. This lower precision caused the jet to curve and to break up at an earlier time and hence at a shorter distance. The resulting dispersion decreased the penetration depth for a given cone diameter and also shortened the optimum standoff distance. Since the charges were less effective at larger standoffs, side and turret skirts (known as \"Schürzen\") fitted to some German tanks to protect against ordinary anti-tank rifles were fortuitously found to give the jet room to disperse and hence also reduce HEAT penetration.\n\nThe use of add-on spaced armor skirts on armored vehicles may have the opposite effect and actually \"increase\" the penetration of some shaped charge warheads. Due to constraints in the length of the projectile/missile, the built-in stand-off on many warheads is less than the optimum distance. In such cases, the skirting effectively increases the distance between the armor and the target, and the warhead detonates closer to its optimum standoff. Skirting should not be confused with cage armor which is used to damage the fusing system of RPG-7 projectiles. The armor works by deforming the inner and outer ogives and shorting the firing circuit between the rocket's piezoelectric nose probe and rear fuse assembly. Cage armor can also cause the projectile to pitch up or down on impact, lengthening the penetration path for the shaped charge's penetration stream. If the nose probe strikes one of the cage armor slats, the warhead will function as normal.\n\nThere are several different forms of shaped charge.\n\nA linear shaped charge (LSC) has a lining with V-shaped profile and varying length. The lining is surrounded with explosive, the explosive then encased within a suitable material that serves to protect the explosive and to confine (tamp) it on detonation. \"At detonation, the focusing of the explosive high pressure wave as it becomes incident to the side wall causes the metal liner of the LSC to collapse–creating the cutting force.\" The detonation projects into the lining, to form a continuous, knife-like (planar) jet. The jet cuts any material in its path, to a depth depending on the size and materials used in the charge. For the cutting of complex geometries, there are also flexible versions of the linear shaped charge, these with a lead or high-density foam sheathing and a ductile/flexible lining material, which also is often lead. LSCs are commonly used in the cutting of rolled steel joists (RSJ) and other structural targets, such as in the controlled demolition of buildings. LSCs are also used to separate the stages of multistage rockets.\n\nThe explosively formed penetrator (EFP) is also known as the self-forging fragment (SFF), explosively formed projectile (EFP), self-forging projectile (SEFOP), plate charge, and Misznay-Schardin (MS) charge. An EFP uses the action of the explosive's detonation wave (and to a lesser extent the propulsive effect of its detonation products) to project and deform a plate or dish of ductile metal (such as copper, iron, or tantalum) into a compact high-velocity projectile, commonly called the slug. This slug is projected toward the target at about two kilometers per second. The chief advantage of the EFP over a conventional (e.g., conical) shaped charge is its effectiveness at very great standoffs, equal to hundreds of times the charge's diameter (perhaps a hundred meters for a practical device).\n\nThe EFP is relatively unaffected by first-generation reactive armor and can travel up to perhaps 1000 charge diameters (CD)s before its velocity becomes ineffective at penetrating armor due to aerodynamic drag, or successfully hitting the target becomes a problem. The impact of a ball or slug EFP normally causes a large-diameter but relatively shallow hole, of, at most, a couple of CDs. If the EFP perforates the armor, spalling and extensive behind armor effects (BAE, also called behind armor damage, BAD) will occur. The BAE is mainly caused by the high-temperature and high-velocity armor and slug fragments being injected into the interior space and the blast overpressure caused by this debris. More modern EFP warhead versions, through the use of advanced initiation modes, can also produce long-rods (stretched slugs), multi-slugs and finned rod/slug projectiles. The long-rods are able to penetrate a much greater depth of armor, at some loss to BAE, multi-slugs are better at defeating light or area targets and the finned projectiles are much more accurate.\n\nThe use of this warhead type is mainly restricted to lightly armored areas of main battle tanks (MBT) such as the top, belly and rear armored areas. It is well suited for the attack of other less heavily protected armored fighting vehicles (AFV) and in the breaching of material targets (buildings, bunkers, bridge supports, etc.). The newer rod projectiles may be effective against the more heavily armored areas of MBTs. Weapons using the EFP principle have already been used in combat; the \"smart\" submunitions in the CBU-97 cluster bomb used by the US Air Force and Navy in the 2003 Iraq war employed this principle, and the US Army is reportedly experimenting with precision-guided artillery shells under Project SADARM (Seek And Destroy ARMor). There are also various other projectile (BONUS, DM 642) and rocket submunitions (Motiv-3M, DM 642) and mines (MIFF, TMRP-6) that use EFP principle. Examples of EFP warheads are US patents 5038683 and US6606951.\n\nSome modern anti-tank rockets (RPG-27, RPG-29) and missiles (TOW 2B, ERYX, HOT, MILAN) use a tandem warhead shaped charge, consisting of two separate shaped charges, one in front of the other, typically with some distance between them. TOW-2A was the first to use tandem warheads in the mid-1980s, an aspect of the weapon which the US Army had to reveal under news media and Congressional pressure resulting from the concern that NATO antitank missiles were ineffective against Soviet tanks that were fitted with the new ERA boxes. The Army revealed that a 40 mm precursor shaped charge warhead was fitted on the tip of the TOW-2B collapsible probe. Usually, the front charge is somewhat smaller than the rear one, as it is intended primarily to disrupt ERA boxes or tiles. Examples of tandem warheads are US patents 7363862 and US 5561261. The US Hellfire antiarmor missile is one of the few that have accomplished the complex engineering feat of having two shaped charges of the same diameter stacked in one warhead. Recently, a Russian arms firm revealed a 125mm tank cannon round with two same diameter shaped charges one behind the other, but with the back one offset so its penetration stream will not interfere with the front shaped charge's penetration stream. The reasoning behind both the Hellfire and the Russian 125 mm munitions having tandem same diameter warheads is not to increase penetration, but to increase the beyond-armor effect.\n\nIn 1964 a Russian scientist proposed that a shaped charge originally developed for piercing thick steel armor be adapted to the task of accelerating shock waves. The resulting device, looking a little like a wind tunnel, is called a Voitenko compressor. The Voitenko compressor initially separates a test gas from a shaped charge with a malleable steel plate. When the shaped charge detonates, most of its energy is focused on the steel plate, driving it forward and pushing the test gas ahead of it. Ames translated this idea into a self-destroying shock tube. A 66-pound shaped charge accelerated the gas in a 3-cm glass-walled tube 2 meters in length. The velocity of the resulting shock wave was 220,000 feet per second (67 km/s). The apparatus exposed to the detonation was completely destroyed, but not before useful data was extracted. In a typical Voitenko compressor, a shaped charge accelerates hydrogen gas which in turn accelerates a thin disk up to about 40 km/s. A slight modification to the Voitenko compressor concept is a super-compressed detonation, a device that uses a compressible liquid or solid fuel in the steel compression chamber instead of a traditional gas mixture. A further extension of this technology is the explosive diamond anvil cell, utilizing multiple opposed shaped charge jets projected at a single steel encapsulated fuel, such as hydrogen. The fuels used in these devices, along with the secondary combustion reactions and long blast impulse, produce similar conditions to those encountered in fuel-air and thermobaric explosives.\n\nThe proposed Project Orion nuclear propulsion system would have required the development of nuclear shaped charges for reaction acceleration of spacecraft. Shaped charge effects driven by nuclear explosions have been discussed speculatively, but are not known to have been produced in fact. For example, the early nuclear weapons designer Ted Taylor was quoted as saying, in the context of shaped charges, \"A one-kiloton fission device, shaped properly, could make a hole ten feet in diameter a thousand feet into solid rock.\" Also, a nuclear driven explosively formed penetrator was apparently proposed for terminal ballistic missile defense in the 1960s.\n\n\n"}
{"id": "1324749", "url": "https://en.wikipedia.org/wiki?curid=1324749", "title": "Shaving cream", "text": "Shaving cream\n\nShaving cream or shaving foam is a frothy cosmetic cream applied to body hair, usually facial hair, to facilitate shaving. The use of cream achieves three effects: lubricates the cutting process; swells keratin; and desensitizes skin. Shaving creams commonly consist of an emulsion of oils, soaps or surfactants, and water. Blades with polymeric coating reduce the need for shaving creams.\n\nA rudimentary form of shaving cream was documented in Sumer around . This substance combined wood alkali and animal fat and was applied to a beard as a shaving preparation.\n\nUntil the early 20th century, bars or sticks of hard shaving soap were used. Later, tubes containing compounds of oils and soft soap were sold. Newer creams introduced in the 1940s (Burma-Shave) neither produced lather nor required brushes, often referred to as brushless creams.\n\nThe first can of pressurized shaving cream was Rise shaving cream, introduced in 1949. By the following decade this format attained two-thirds of the American market. Chlorofluorocarbons (CFCs) were used as propellants until they were banned in the late 1970s for destroying the ozone layer. Gaseous hydrocarbons such as mixtures of pentane, propane, butane and isobutane took their place.\n\nIn the 1970s, shaving gel was developed. In 1993, The Procter & Gamble Company patented a post-foaming gel composition, which turns the gel into a foam after application to the skin, combining properties of both foams and gels.\n\nShaving creams and soaps are available as solids (bars); creams, generally in tubes; or aerosols. All forms may be applied with a shaving brush.\n\nShaving creams contain 20–30% soap [potassium or triethanolamine (TEA)], up to about 10% glycerine, emollients, emulsifiers, and foaming agents. Aerosols are diluted creams dispensed from pressurized cans with the aid of hydrocarbon propellants (up to about 10%). The flammability of the hydrocarbons is offset by the large amounts of water in cream formulations.\n\nBeard-softening is due to hair hydration, which also depends on pH. In electric or dry shaving, swelling of the hairs is not desired, and such preparations use high amounts of alcohol (50–80%) to dry the skin and stiffen the hairs.\n\n"}
{"id": "47237357", "url": "https://en.wikipedia.org/wiki?curid=47237357", "title": "SolidRun", "text": "SolidRun\n\nSolidRun is an Israeli company producing Embedded systems components, mainly mini computers, Single-board computers and computer-on-module devices. It is specially known for their CuBox family of mini-computers (said to be the world's smallest desktop computer at the time of its launch), and for producing motherboards and processing components such as the HummingBoard motherboard.\n\nSituated in the Yokneam Illit Industrial Park, SolidRun develops and manufactures products aimed both for the private entertainment sector, and for companies developing processor based products, notably components of \"Internet of Things\" technology systems.\n\nWithin the scope of the IoT technology, SolidRun's mini computers are aimed to cover the intermediate sphere, between sensors and user devices, and between the larger network or Cloud framework. Within such a network, mini computers or system-on-module devices, act as mediators gathering and processing information from sensors or user devices and communicating with the network - this is also known as Edge computing.\n\nSolidRun was founded in 2010 by co-founders Rabeeh Khoury (formally an engineer at Marvell Technology Group) and Kossay Omary, today chairman and CTO respectively. The goal of SolidRun has been to develop, produce and market components aimed for integration with IoT systems.\n\nThe company today is situated in the Yokneam Illit HiTech Industrial Park in the Northern District of Israel, and headed by Dr. Atai Ziv (CEO).\n\nThe major product development line aimed at the consumer market is the CuBox family of mini-computers. The first of which was announced in December 2011, followed by the development of the CuBox-i series, announced in November 2013. The most recent addition to the CuBox line has been the CuBoxTV (announced in December 2014), which has been marketed primarily for the home entertainment market. A further primary product developed by SolidRun is the Hummingboard, an uncased single-board computer, marketed to developers as an integrated processing component.\n\nSolidRun develops all of its products using Open-source software (such as Linux and OpenELEC), identifying itself as a member of the OSS community and a promoter of Open-source software platforms.\n\nThe products developed by SolidRun are classed into three families, based upon the processor maker. Each family offers roughly the same range of mini-computers, SOM's & COM's - currently divided into NXP iMX-6, Marvell Armada & Intel Braswell families. Every processing family offering different advantages with different application capacities.\n\nAnnounced in December 2011, CuBox and CuBox-i are a series of fanless nettop-class mini computers, all cube shaped and approximate 2 × 2 × 2 inches in size, weighing around 91 g (3.2 oz).\n\nCuBox is a low-power ARM architecture CPU based computer, using the Marvell Armada 510 (88AP510) SoC with an ARM v6/v7-compliant superscalar processor core, Vivante GC600 OpenGL 3.0 and OpenGL ES 2.0 capable 2D/3D graphics processing unit, Marvell vMeta HD Video Decoder hardware engine, and TrustZone security extensions, Cryptographic Engines and Security Accelerator (CESA) co-processor.\n\nIn November 2013, SolidRun released a family of CuBox-i computers named CuBox-i1, i2, i2eX, and i4Pro, containing a range of different i.MX6 processors by Freescale Semiconductor.\n\nAnnounced in December 2014, CuBoxTV is a mid-range CuBox-i SOM device for running Kodi on an OpenELEC Operating system, developed for the home entertainment market.\n\nCuBoxTV is based on an ARM architecture Quad core CPU, 1 GB, 64 bit memory, GC2000 GPU with an OpenGL ES quad shader, and a host of video, audio and picture decoders and encoders supporting all major file type. The device has a number of connection ports including HDMI, 10/100/1000 Ethernet, USB 2.0, eSATA and optical audio.\n\nA compact computer-on-module ARM based mini computer, running a i.MX6 or iMX8M SoC. HummingBoard is marketed as a modular fanless mini computer, to be integrated with larger networks or systems, especially in the area of IoT development.\n\nA compact system-on-module ARM based processing board, with a Freescale i.MX6 system-on-chip & networking, power management and storage capabilities. At 47 × 30 mm big, the MicroSoM is aimed for device and system developing, as an all rounded modular processing component.\n\nThe SOM varies between 4 models ranging in performance, especially in regard to processing. The Single-core and Dual-Light-core SOMs house a Vivante GC880 GPU, 10/100 Mbit/s Ethernet network connection and a 2 Lane CSI camera interface port. The Single-core variant holds 32-bit DDR3, 512 MB memory, while the Dual-light variant holds 64-bit DDR3, 1 GB memory.\nThe Dual-core and Quad-core SOM's house a Vivante GC2000 GPU, 10/100/1000 Mbit/s Ethernet network connection and a 4 Lane CSI camera interface port, they also include a built in 802.1 b/g/n wireless and a 4.0 Bluetooth port. Both variants offer 64-bit DDR3 memory at a 1066 Mbit/s speed, the dual-core coming with 1 GB of memory, while the Quad-core comes with 2 GB of memory.\n\nModels & specifications:\n\nBased on the Marvell ARMADA 388 SoC, the MicroSoM features a Dual core ARM Cortex A9 with 1.6 GHz processing power (up to 1.3 GHz in industrial grade), and up to 2 GB, 32-bit DDR3L memory. At 30 mm × 50 mm the ARMADA MicroSoM is the basis for a number of SolidRun's products in this product family.\n\nAnnounced in November 2015, SolidRun's ClearFog Single-board computer (SBC) is based on Marvell's Armada 38x ARM Cortex-A9 Dual SoC and is marketed as a modular development integration SBC. The ClearFog is divided into two grades: Base and Pro, differing mainly in connectivity options and size.\n\nThe ClearFog is a fanless SBC based on a Marvell ARMADA A388 dual 1.6 GHz core SOM, with 1 GB memory, Mikroelektronika mikroBUS Click Board support, and various connection ports including USB 3.0, mPCIE & Ethenet ports.\n\nSolidRun has developed a range of products based on the Marvell ARMADA A8040 System-on-Chip, with its Quad core Cortex-A72 processor.\n\n\nSolidRun's family of Intel Braswell-based SOMs includes four SOMs based on two SoCs; the Atom E8000 & Pentium N3710.\n\n\n"}
{"id": "27921256", "url": "https://en.wikipedia.org/wiki?curid=27921256", "title": "Swedish Association of Graduate Engineers", "text": "Swedish Association of Graduate Engineers\n\nThe Swedish Association of Graduate Engineers, \"Sveriges ingenjörer\", is a professional association in Sweden, gathering 120,000 members.\n\nIt was created in 2007 by merger of \"Sveriges Civilingenjörsförbund\", which also used the name \"Swedish Association of Graduate Engineers\" in English, with the smaller \"Ingenjörsförbundet\".\n\n"}
{"id": "14485938", "url": "https://en.wikipedia.org/wiki?curid=14485938", "title": "Transmodel", "text": "Transmodel\n\nTransmodel (formally \"CEN TC278, Reference Data Model For Public Transport, EN12896\") is the CEN European Reference Data Model for Public Transport Information; it provides an conceptual model of common public transport concepts and data structures that can be used to build many different kinds of public transport information system, including for timetabling, fares, operational management, real time data, journey planning etc.\n\nTransmodel provides a comprehensive conceptual model for public transport (PT) information systems including passenger information systems, with coverage of a number of different subdomains of PT information, including transport network infrastructure and topology, public transport schedules, journey planning, fares, fare validation, real-time passenger information and operational aspects of public transport.\n\n\nTransmodel establishes a consistent terminology for describing public transport concepts, providing definitive equivalents for use in the National Languages of each participant nation. Where PT related words in vernacular use may span a number of different concepts and lead to differences of interpretation, it establishes a more precise technical terminology for unambiguous use by PT information system developers. For example the terms 'trip', 'journey', 'service', are overlapping concepts that in Transmodel are used only in a more specific usages.\n\nThe current version of Transmodel is 5.1 with a 6.0 in draft.\n\nTransmodel was originally developed within a range of European projects under several European Programmes (Drive I, Drive II, TAP) with the support of the European Commission (DGXIII), and national public institutions, in particular the French Ministry of Transport (Direction des Transports Terrestres) as well as several private companies.\n\n\nIn 2006 version 5.1 of Transmodel was formally adopted by CEN as a European standard, EN12896.\n\nTransmodel has been fundamental to the development of a number of concrete national data models and European Standards,including both European standards Service Interface for Real Time Information (SIRI: 2001-2005, now a CEN technical specification) for Real-time data exchange for buses, and Identification of Fixed Objects In Public Transport (2006-2007), now assimilated into Transmodel v6.0 Part2, and national standards such as TransXChange (2001-2005, now the UK standard for bus PT timetables), and the French Trident standard (1999-2003). Its provision of a uniform conceptual framework, consistent terminology and well grounded abstractions make it especially valuable for comparing, harmonising and modernising legacy standards and systems and for international cooperation.\n\n\n\n\n\n"}
{"id": "3860234", "url": "https://en.wikipedia.org/wiki?curid=3860234", "title": "Trap Door Forage Wagon", "text": "Trap Door Forage Wagon\n\nA Trap Door Forage Wagon is a type of wagon used in farming that can unload without the operator having to stop. It earned top honors in the American Farm Bureau Federation's 14th annual Farmer Idea Exchange in the annual convention.\n\nTwo doors are located at the bottom of the wagon. Normally these are locked at a 45 degree angle downward to hold the haylidge inside the wagon. When the farmer drives over the pile he releases the doors from inside the cab of the tractor to instantly unload the wagon. This design offers greater safety, less wear from moving parts and most importantly greater efficiency.\n\n"}
{"id": "24321692", "url": "https://en.wikipedia.org/wiki?curid=24321692", "title": "World Design Capital", "text": "World Design Capital\n\nThe World Design Capital (WDC) is a city promotion project by the International Council of Societies of Industrial Design to recognize and award accomplishments made by cities around the world in the field of design.\n\n"}
{"id": "46504669", "url": "https://en.wikipedia.org/wiki?curid=46504669", "title": "Zenith Flash-matic", "text": "Zenith Flash-matic\n\nThe Zenith Flash-Matic was the first wireless remote control invented by Eugene Polley in 1955. It had only one button that was used to power on and off, channel up, channel down, and mute. The Flash-matic's phototechnology was a significant innovation in television and allowed for wireless signal transfer previously exclusive to radio.\n\nEarlier remotes could turn sets on/off and change channels, but were connected to the TV with a cable. The Flash-matic came in response to consumer complaints about the inconvenience of these cables running from the transmitter to the TV monitor. Earlier remotes served as the central control system for transmitting complex signals to the receiving monitor. The Flash-matic instead placed the complexity in the receiver as opposed to the transmitter. It used a directional beam of light to control a television outfitted with four photo cells in the corners of the screen. The light signal would activate one of the four control functions, which turned the picture and sound on or off, and turned the channel tuner dial clockwise and counter-clockwise. The bottom receptors received the signal to mute and power on/off, and the upper cells received signals to channel up/down. In order for the various signals to be received by the monitor, the remote control had to be directed towards one of the four photocells. The system responded to full-spectrum light so could be activated or interfered with by other light sources including indoor light bulbs and the sun. Despite these defects, the Flash-matic remained in high demand. In September 1955, Zenith released an apology for its inability to meet the high demand of consumers. The Flash-matic was quickly replaced by new control systems. The \"Zenith Space Command\" remote control went into production in 1956 with aims to improve upon the Flash-matic's design.\n\nThe Flash-matic was marketed as an interactive technology for tuning device for the television. Muting was the first control feature to be included on a remote control while unavailable on the monitor. The advertisement campaign for the Flash-matic remote control noted its ability to \"shut off annoying commercials while the picture remains on the screen.” The mute button was explicitly designed for the purpose of tuning out of commercials. As a result of this new feature as well as the Flash-matic's pistol shape, the Flash-matic's ad campaigns invited viewers to \"shoot\" the annoying commercials or announcers that they were tired of listening to, while leaving the image present so that the viewer would know when to turn the sound back on.\n\n"}
