{"id": "2931056", "url": "https://en.wikipedia.org/wiki?curid=2931056", "title": "3Com Audrey", "text": "3Com Audrey\n\nThe 3Com Ergo Audrey is a discontinued internet appliance from 3Com. It was released to the public on October 17, 2000 for USD499 as the only device in the company's \"Ergo\" initiative to be sold. Once connected to an appropriate provider, users could access the internet, send and receive e-mail, play audio and video, and synchronize with up to two Palm OS-based devices.\n\n\"Audrey\" was the brainchild of Don Fotsch (formerly of Apple Computer and U.S. Robotics) and Ray Winninger. Don and Ray had a vision for a family of appliances, each designed for a specific room in the house. The brand \"Ergo\" was meant to convey that intent, as in \"it's in the kitchen, \"ergo\" it's designed that way\". There were plans to serve other rooms in the house as well. They considered the kitchen to be the heart of the home and the control room for the home manager. Don coined the phrase \"Internet Snacking\" to describe the lightweight web browsing done in this environment.\n\nThe name \"Audrey\" was given to this first product to honor Audrey Hepburn. It was meant to deliver the elegance that she exuded. The project codename was \"Kojak\", named after the Telly Savalas character. The follow-on product targeted for the family room was code named \"Mannix\".\n\n3Com discontinued the product on June 1, 2001, in the wake of the dot-com crash, after only seven and a half months on the market. Only 3Com direct customers received full refunds for the product and accessories. Customers who had bought Audrey devices through other vendors were not offered refunds and never even notified about the refunds. The remaining Audrey hardware was liquidated and embraced by the hardware hacker community.\n\nThe Audrey is a touchscreen, passive matrix LCD device and came equipped with a stylus. All applications were touch-enabled. Since the standard infrared keyboard was only needed for typing tasks, it could be hung out of the way on the rear of the unit. The stylus was to be placed in a receptacle on the top of the screen with an LED that flashed when email arrived. Buttons on the right side of the screen were used to access the web browser, email application, and calendar, and a wheel knob at the bottom selected different \"channels\" of push content.\n\nThe 3Com Audrey is powered by a 200 MHz Geode GX 1 CPU, with 16 MB of flash ROM and 32 MB of RAM. It measures 9 x 11.8 x 3.0 inches (22.86 x 29.97 x 7.62 cm), and weighs 4.1 pounds (1.86 kg). It is powered by the QNX operating system. The Audrey is equipped with a modem, two USB ports, and a CompactFlash socket. A USB Ethernet adapter was commonly used for broadband subscribers.\n\nThe Audrey was also available in such shades as \"linen\" (off-white), \"meadow\" (green), \"ocean\" (blue), \"slate\" (grey), and \"sunshine\" (light yellow).\n\nAfter the demise of official support, the Audrey drew the attention of computer enthusiasts. They quickly discovered an exploit to launch a pterm session. Using privilege escalation techniques, the root password in the passwd file could be edited, opening the box to further experimentation.\n\nMany of the tools for the QNX operating system development platform were quickly adapted for use in the Audrey, including an updated web browser (Voyager), an MP3 player, digital rotating photoframe, and other applications.\n\nThe CompactFlash slot was also investigated. Although it could not be used for storage expansion, the Audrey was set to flash its operating system from the slot. Soon, a variety of replacement OS images were distributed among enthusiasts. As the device could utilize an optional Ethernet connection, it was an easy task to mount a remote disk drive served up by a neighboring desktop system, thus allowing for virtually unlimited storage capability.\n\nDevices similar to the Audrey included the i-Opener, the Virgin Webplayer and the Gateway Touch Pad.\n"}
{"id": "9756141", "url": "https://en.wikipedia.org/wiki?curid=9756141", "title": "AN/SLQ-49 Chaff Buoy Decoy System", "text": "AN/SLQ-49 Chaff Buoy Decoy System\n\nThe AN/SLQ-49 Chaff Buoy Decoy System, commonly referred to as \"Rubber Duck\", consists of inflatable radar-reflecting decoy buoys. Used by the U.S. Navy, Royal Navy, and other NATO countries, the decoy is designed to seduce radar-guided anti-ship missiles by simulating the radar cross section of a ship. When deployed, the system launches into the water two octahedron-shaped inflatable decoy floats, connected by a cable.\n\nThe AN/SLQ-49 has been in operation since 1985. Originally designed to confuse or distract enemy radar operators, it has demonstrated effective missile seduction capabilities.\n\n\n"}
{"id": "5744692", "url": "https://en.wikipedia.org/wiki?curid=5744692", "title": "Anti-personnel mine", "text": "Anti-personnel mine\n\nAnti-personnel mines are a form of mine designed for use against humans, as opposed to anti-tank mines, which are designed for use against vehicles. Anti-personnel mines may be classified into blast mines or fragmentation mines, the latter may or may not be a bouncing mine.\n\nThe mines are often designed to injure, not kill, their victims in order to increase the logistical (mostly medical) support required by enemy forces that encounter them. Some types of anti-personnel mines can also damage the tracks on armoured vehicles or the tires of wheeled vehicles.\n\nThe International Campaign to Ban Landmines has sought to ban mines culminating in the 1997 Ottawa Treaty, although this treaty has not yet been accepted by a number of countries including the United States, Israel, Russia, the People's Republic of China, Pakistan and India.\n\nAnti-personnel mines are used in a similar manner to anti-tank mines, in static \"mine fields\" along national borders or in defense of strategic positions as described in greater detail in the land mine article. What makes them different from most anti-tank mines, however, is their smaller size, which enables large numbers to be simultaneously deployed over a large area. This process can be done manually, via dispensers on land vehicles, or from helicopters or aircraft. Alternatively, they can be dispensed by cargo-carrying artillery shells.\n\nOther uses specific to anti-personnel mines are where they are deployed on an ad hoc basis in the following situations:\n\n\nTypically, anti-personnel blast mines are triggered when the victim steps on them. Their primary purpose is to blow the victim's foot or leg off, disabling them. Injuring, rather than killing, the victim is viewed as preferable in order to increase the logistical (evacuation, medical) burden on the opposing force.\n\nWhen a person steps on a blast mine and activates it, the mine's main charge detonates, creating a blast shock wave consisting of hot gases travelling at extremely high velocity. The shock wave sends a huge compressive force upwards, ejecting the mine casing and any soil covering the mine along with it. When the blast wave hits the surface, it quickly transfers the force into the subject's footwear and foot. This results in a massive compression force being applied. In most cases, the victim's foot is blown off by the blast wave.\n\nThe resulting injuries to a human body depend on the size of the mine's main charge, the depth, type of soil it was laid in and how the victim contacted it, e.g. stepping on the mine, using all or part of the foot. Different types of soil will result in different amounts of energy being transferred upward into the subject's foot, with saturated \"clay-like\" soil transferring the most. Larger main charges result in a release of significantly more energy, driving the blast wave further up a target's foot and leg and causing greater injury, in some cases even described as severe as traumatic amputation of the leg up to the knee.\n\nSecondary injuries from a blast mine are often caused by the material that has been torn loose by the mine's explosion. This consists of the soil and stones that were on top of the mine, parts of the victim's footwear and the small bones in the victim's foot. This debris creates wounds typical of similar secondary blast effects or fragmentation. Special footwear, including combat boots or so-called \"blast boots\", is only moderately protective against the destructive effects of blast mines, and the loss of a foot is a typical outcome.\n\nBlast mines have little effect on armoured vehicles, but can damage a wheeled vehicle if it runs directly over the mine. Small blast mines will severely damage a tire, rendering it irreparable while some types could also damage adjacent running gear.\n\nThe mine casing houses the components of the mine and protects it from its environment. Early mines, such as the ones used in the World War II era, had casings made of steel or aluminium. However, by the middle of the conflict, the British Army was using the first, practical, portable metal detector—the Polish mine detector. The Germans responded with mines that had a wooden or glass casing to make detection harder.\n\nWooden mines had been used by the Russians in 1939, before the appearance of metal detectors, in order to save steel. Some, like the PP Mi-D mine, continued to be used into the 1980s as they were easy to make and hard to detect. Wood has the disadvantage of rotting and splitting, rendering the mine non-functional after a comparatively short time in the ground (or the advantage, in that the mine can be considered self-disabling, and will be less likely to cause unintended injuries years later).\n\nMines manufactured after the 1950s generally use plastic casings to hinder detection by electronic mine detectors. Some, referred to as minimum metal mines, are constructed with as little metal as possible – often around – to make them difficult to detect. Mines containing absolutely no metal have been produced, but are uncommon. By its nature, a mine without any metal components in it cannot be found using a metal detector.\n\nThe fuze mechanism is designed to set off the detonator, either by striking it with a spring-loaded firing pin, compressing a friction sensitive pyrotechnic composition, or by passing an electric charge through it. Most mines employ a spring-loaded striker that hits a stab detonator when activated by the victim. Typically, the detonator contains a tiny pellet of lead azide. The fuze is the most complicated component in any mine, although the amount of effort required to design and manufacture a simple fuze mechanism is quite low, similar to the retraction mechanism in a ballpoint pen. \nMore sophisticated examples, such as the Italian SB-33 mine have a fuze mechanism that detonates the mine if subject to gradual, steady pressure, but locks the fuze if subject to a sudden shock. This defeats one of the main methods of clearing a path through a minefield — detonating the mines with explosive devices, such as mine-clearing line charges.\n\nThe booster charge is a highly sensitive explosive that will activate easily when subjected to the shock of the detonator. Typically, a pea-sized pellet of RDX is used. The purpose of the booster is to amplify the shock of the detonator and initiate the main explosive charge.\n\nThe main charge consists of a stable explosive that is detonated by the booster charge. This is necessary, because making a mine out of a highly sensitive detonator or booster explosive would be more expensive, and make the device more sensitive and thereby susceptible to accidental detonation. In most AP blast mines TNT, Composition B or phlegmatized RDX are used. On a US M14 mine, 29 grams of tetryl is used, while 240 grams of TNT is used in a Russian PMN mine.\n\nAnti-personnel blast mines are the most common type and are typically deployed on the surface (hidden by leaves or rocks) or buried under soil at a depth of 10 – 20 mm. They are activated by pressure, i.e. when the victim steps on them, but it could also be a vehicle driving over them.\n\nThey were designed for use as area denial weapons. Weapons of this type are supposed to deny opposing military forces access to a specific area.\n\nWhile blast mines are designed to cause severe injury to one person, fragmentation mines (such as the World War II era German S-mine) are designed to project fragments across a wide area, causing fragmentation wounds to nearby personnel.\n\nFragmentation mines are generally much larger and heavier than blast mines, and contain a large amount (often several kilograms) of ferrous metal. As such, they are easy to detect if the environment is not too heavily contaminated with iron.\n\nThese mines are deemed to be more efficient than purely \"blast effect\" mines, because the shrapnel covers a greater area, potentially injuring more combatants.\n\nThe shrapnel from these mines can even disable some armoured vehicles, by puncturing their tires and—in the case of soft-skinned vehicles—also penetrating the skin and damaging internal components or injuring personnel. Because fragmentation mines generally contain a much larger charge than blast mines, they can cause severe damage to an unarmoured vehicle which runs directly over one.\n\nThese mines (such as the Russian POMZ) are entirely above ground, having a fragmenting warhead mounted on a stake at a suitable height, concealed by vegetation or rubbish and triggered by one or more tripwires.\n\nBounding mines have a small lifting charge that, when activated, launches the main body of the mine out of the ground before it detonates at around chest height. This produces a more lethal spray of shrapnel over a larger area. One such—the US M16 mine—can cause injuries up to away. The steel shrapnel makes bounding mines easy to detect, so they may be surrounded by minimum metal mines to make mine clearance harder.\n\nDirectional fragmentation weapons (such as the M18 Claymore) differ from other types in that they are designed to direct their fragments only in a limited arc. They are placed so that the blast will be directed at the target area and away from friendly forces. This design also allows forces to protect themselves by placing these types of mines near their own positions, but facing the enemy. They are triggered in a conventional manner with either tripwire or command detonation. They are generally referred to as \"claymore mines\" from the US mine of this type.\n\nIn the conflicts of the 21st century, anti-personnel improvised explosive devices (IED) have replaced conventional or military landmines as the source of injury to dismounted (pedestrian) soldiers and civilians. These injuries were recently reported in BMJ Open to be far worse with IEDs than with landmines resulting in multiple limb amputations and lower body mutilation. This combination of injuries has been given the name \"Dismounted Complex Blast Injury\" and is thought to be the worst survivable injury ever seen in war.\n\nDuring World War II, flame mines known as the flame fougasse were produced by the British during the invasion crisis of 1940. Later, the Russians produced a flame-mine, called the FOG-1. This was copied by the Germans to produce the Abwehrflammenwerfer 42, these devices were effectively disposable, trip-wire triggered flamethrowers.\n\nChemical mines have also been made. They were made by Britain, the US and the Soviet Union during World War II, but never deployed. During the Cold War, the US produced the M23 chemical mine containing VX (nerve agent). A small explosive charge burst the mine open and dispersed the chemical when the mine was triggered.\n\n\nAnti-personnel mines are a typical example of subject-matter excluded from patentability under the European Patent Convention, because the publication or exploitation of such inventions are contrary to the \"ordre public\" and/or morality ().\n\nThe author Rob Nixon has criticized the use of the adjective \"anti-personnel\" to describe mines, noting that the word \"personnel\" signifies people engaged in a particular organization, whereas in reality \"four-fifths of mine casualties are civilians\", in particular children. Thus, he argues, the name \"flatters their accuracy by implying that they target an organization, military or otherwise.\" \n\n\n"}
{"id": "7365812", "url": "https://en.wikipedia.org/wiki?curid=7365812", "title": "Babcock-Hart Award", "text": "Babcock-Hart Award\n\nThe Babcock-Hart Award has been awarded since 1948 by the Institute of Food Technologists. It is given for significant contributions in food technology that resulted in public health through some aspects of nutrition. It was first named the Stephan M. Babcock Award after the agricultural chemist Stephen M. Babcock of the University of Wisconsin–Madison for his \"single-grain experiment\" of 1907–1911, but renamed the Babcock-Hart Award following the death of Babcock's colleague Edwin B. Hart in 1953.\n\nAward winners receive a plaque from the International Life Sciences Institute-North America, headquartered in Washington, DC and a USD 3000 honorarium.\n\n"}
{"id": "31523315", "url": "https://en.wikipedia.org/wiki?curid=31523315", "title": "Beocenter 9500", "text": "Beocenter 9500\n\nThe BeoCenter 9500 is an integrated home music system by Bang & Olufsen. It consists of an AM/FM receiver, CD player and cassette recorder. Its award winning design features a mirrored exterior of polished aluminium and smoked glass. The BeoCenter 9500 has no buttons: it is controlled by touching the glass with one’s fingertip.\nThe BeoCenter 9500 was introduced in 1989 as the successor to the BeoCenter 9000 and sold until 1994 when it was replaced by its successor the BeoCenter 9300.\n\nThe BeoCenter 9500 featured B&O's unique sensi-touch control which works through a condenser effect. A graphite area is printed on the underside of the glass panel, and charged with a high frequency current. The proximity of a finger will invoke the control. The controls are illuminated by LEDs. Only the controls which have a function to the current activity are lit up.\nThe CD and cassette are hidden behind polished aluminium lids. A light touch on the display panel makes the lids glide to the side giving immediate access to disc or cassette.\n\nIts designer David Lewis was awarded the iF product design award in 1990 for the BeoCenter 9500\n\n\n"}
{"id": "56112052", "url": "https://en.wikipedia.org/wiki?curid=56112052", "title": "Blink Home", "text": "Blink Home\n\nBlink is a home automation company which produces battery-powered home security cameras and a video doorbell. The company was founded in 2009 by Peter Besen, Don Shulsinger and Stephen Gordon. The company was initially started as Immedia Semiconductor Inc in 2009, but pivoted into a consumer electronics company. In 2014, the company had a Kickstarter campaign for their indoor security camera, which raised over US$1 million. Subsequently, Blink later announced an outdoor security camera, home security system, and video doorbell.\n\nAmazon announced in December 2017 that they had acquired the company. Blink continues to operate as an independent subsidiary. It is anticipated that Blink's technology will be used for the Amazon Key service.\n"}
{"id": "31346700", "url": "https://en.wikipedia.org/wiki?curid=31346700", "title": "Camera stabilizer", "text": "Camera stabilizer\n\nA camera stabilizer, or camera–stabilizing mount, is a device designed to hold a camera in a manner that prevents or compensates for unwanted camera movement, such as \"camera shake\".\n\nFor small hand-held cameras, a harness or contoured frame steadies the camera against the photographer's body. In some models, the camera mount is on an arm that protrudes in front of the photographer; beneath the camera is a handle grip. Another variation positions the camera atop a fulcrum braced against the photographer's chest or abdomen.\n\nTo compensate for camera instability caused by the movement of the operator's body, camera operator Garrett Brown invented the Steadicam, a body-mounted stabilization apparatus for motion picture cameras, which uses springs as shock absorbers.\n\nIn 1991, Martin Philip Stevens (born in England in 1963) invented a hand-held camera stabilizer for motion-picture and video cameras, called the \"Glidecam\". \n\nSome camera stabilization machines use gyroscopes to sense disruptive motion. The Artemis Trinity system from Arri combines a mechanical and electronic stabilization.\n\nAlthough a tripod can hold a camera stably, stationary platforms are not regarded as camera stabilizers.\n\nA camera shoulder brace stabilizes by shifting the weight of the camera to the operator's shoulder. This allows for smoother shots than might be obtainable by handheld operation. Camera shoulder braces are typically padded for comfort and allow the attachment of zoom controllers, transmitters, and other devices.\n\nThe operator generally holds two handles while a third brace rests on the shoulder. A remote LANC zoom controller is usually placed on one of the handles.\n\nMost braces are made of PVC, carbon fiber or light-weight metals to keep the weight down. If the brace were too heavy it would defeat the purpose of using it, reduced camera shake and fluidity of movement.\n\nFor low shots, most braces can be used as a mini-tripod by setting the brace on flat surface.\n\nShoulder braces also reduce stress on the arms which reduces tiredness and muscle cramps during filming.\n\n"}
{"id": "31062931", "url": "https://en.wikipedia.org/wiki?curid=31062931", "title": "Chebyshev pseudospectral method", "text": "Chebyshev pseudospectral method\n\nThe Chebyshev pseudospectral method for optimal control problems is based on Chebyshev polynomials of the first kind. It is part of the larger theory of pseudospectral optimal control, a term coined by Ross. Unlike the Legendre pseudospectral method, the Chebyshev pseudospectral (PS) method does not immediately offer high-accuracy quadrature solutions. Consequently, two different versions of the method have been proposed: one by Elnagar et al., and another by Fahroo and Ross. The two versions differ in their quadrature techniques. The Fahroo–Ross method is more commonly used today due to the ease in implementation of the Clenshaw–Curtis quadrature technique (in contrast to Elnagar–Kazemi's cell-averaging method). In 2008, Trefethen showed that the Clenshaw–Curtis method was nearly as accurate as Gauss quadrature.\n\nThe Chebyshev PS method is frequently confused with other Chebyshev methods. Prior to the advent of PS methods, many authors proposed using Chebyshev polynomials to solve optimal control problems; however, none of these methods belong to the class of pseudospectral methods.\n\n"}
{"id": "30734646", "url": "https://en.wikipedia.org/wiki?curid=30734646", "title": "Cinetheodolite", "text": "Cinetheodolite\n\nA cinetheodolite (a.k.a. \"kinetheodolite\") is a photographic instrument for collection of trajectory data. It can be used to acquire data in the testing of missiles, rockets, projectiles, aircraft, and fire control systems; in the ripple firing of rockets, graze action tests, air burst fuze tests, and similar operations. Cinetheodolites provide angular measurements of the line of sight to the vehicle. This permits acquiring accurate position data. Together with timing systems, velocity and acceleration data can be developed from the position measurements. Cinetheodolites can serve as primary sources of position and velocity data to about 30 km slant range.\n\nThese instruments were developed from a family of optical devices known as theodolites by the addition of a movie camera, thus adding the ability to track the vehicle in flight and to obtain continuous trajectory data.\n\nOne of the objectives of testing missile and rocket systems is to determine the actual \"in-flight\" performance of the vehicles themselves. One of the prime requirements for establishing the performance of vehicles in flight is to obtain accurate data which will reveal the position in space and the attitude of the vehicle during its trajectory. The employment of optics at a missile range may become highly significant in obtaining these data, if the atmosphere permits reasonably unobstructed observation, and if, moreover, an all-land test area makes possible optimum siting of instruments for most desirable look angles. Under these conditions, optics in general, and photogrammetry in particular, correlated with other instrumentation systems, can provide effective and accurate data of target trajectory.\n\nThe cinetheodolite is a combination photo-recording and surveying instrument which tracks and photographs targets (in flight vehicles, etc.) at selectable frame rates. Some cinetheodolites have rate-aided tracking control, whereby an open loop servomechanism in conjunction with operator actuated hand wheels match the angular rates of the tracking axis with the angular rates of the target line of position.\n\nCinetheodolites consist of a stable base and bearing, a vertical gimbal or trunnion carrier which rotates about a vertical axis normal to the plane of the base; a central drum or housing which contains the system telescopic lenses, plus a camera and film assembly; a horizontal trunnion shaft on which the central drum is mounted so that it can rise or dip about the horizontal\naxis; and the sighting telescopes, which are also mounted on the horizontal trunnion shaft.\n\nNotable cinetheodolite manufacturers include J. W. Fecker Division, American Optical Co., Pittsburgh, Pa. (USA), iMAR Navigation GmbH, St. Ingbert (Germany), \"Askania Werke Rathenow\" (Germany), Rheinmetall Air Defence (formerly Contraves AG, Switzerland), and BELOMO (Belarus).\n\nCinetheodolites, Materiel Test Procedure 5-1-031, White Sands Missile Range, 31 March 1969\n"}
{"id": "14860424", "url": "https://en.wikipedia.org/wiki?curid=14860424", "title": "EKV MOSFET model", "text": "EKV MOSFET model\n\nThe EKV Mosfet model is a mathematical model of metal-oxide semiconductor field-effect transistors (MOSFET) which is intended for circuit simulation and analog circuit design. It was developed by C. C. Enz, F. Krummenacher and E. A. Vittoz (hence the initials EKV) around 1995 based in part on work they had done in the 1980s. Unlike simpler models like the Quadratic Model, the EKV Model is accurate even when the MOSFET is operating in the subthreshold region (e.g. when V=V then the MOSFET is subthreshold when V < V). In addition, it models many of the specialized effects seen in submicrometre CMOS IC design.\n\n\n"}
{"id": "311518", "url": "https://en.wikipedia.org/wiki?curid=311518", "title": "Ecash", "text": "Ecash\n\nEcash was conceived by David Chaum as an anonymous cryptographic electronic money or electronic cash system in 1982. It was realized through his corporation Digicash and used as micropayment system at one US bank from 1995 to 1998.\n\nChaum published the idea of anonymous electronic money in a 1982 paper; eCash software on the user's local computer stored money in a digital format, cryptographically signed by a bank. The user could spend the digital money at any shop accepting eCash, without having to open an account with the vendor first, or transmitting credit card numbers. Security was ensured by public key digital signature schemes. The RSA blind signatures achieved unlinkability between withdrawal and spend transactions. Depending on the payment transactions, one distinguishes between on-line and off-line electronic cash: If the payee has to contact a third party (e.g., the bank or the credit-card company acting as an acquirer) before accepting a payment, the system is called an on-line system. In 1990, Chaum together with Moni Naor proposed the first off-line e-cash system, which was also based on blind signatures.\n\nChaum started the company DigiCash in 1990 with \"ecash\" as its trademark. He raised $10 million from David Marquardt and by 1997 Nicholas Negroponte was its chairman. Yet, in the United States, only one bank -the Mark Twain bank in Saint Louis,MO- implemented ecash, testing it as micropayment system; Similar to credit cards, the system was free to purchasers, while merchants paid a transaction fee. After a three-year trial that signed up merely 5,000 customers, the system was dissolved in 1998, one year after the bank had been purchased by Mercantile Bank, a large issuer of credit cards. David Chaum opined then “As the Web grew, the average level of sophistication of users dropped. It was hard to explain the importance of privacy to them”.\n\nIn Europe, with fewer credit cards and more cash transactions, micropayment technologies made more sense. In June 1998, ecash became available through Credit Suisse in Switzerland, was available from Deutsche Bank in Germany, Bank Austria, Sweden's Posten AB, and Den norske Bank of Norway, while in Japan Nomura Research Institute marketed eCash to financial institutions.\nIn Australia, ecash was implemented by St.George Bank and Advance Bank, but transactions were not free to purchasers. In Finland Merita Bank/EUnet made ecash available.\n\nDigiCash went bankrupt in 1998, despite flourishing electronic commerce, but with credit cards as the \"currency of choice\".\n\nDigiCash was sold to eCash Technologies, including its eCash patents.\n\nIn 2000 eCash Technologies sued eCash.com, alleging trademark infringement and unfair competition. eCash.com counterclaimed that eCash Technologies' trademark registration was fraudulently obtained, because it failed to disclose eCash.com's registration of the \"ecash.com\" domain name to the U.S. Patent and Trademark Office. The court rejected eCash.com's counterclaim saying a trademark applicant must disclose a third party's rights only if they are \"clearly established.\" The court argued because the \"mere registration of a domain name does not confer trademark rights, let alone \"clearly established\" rights, ECash Technologies had no duty to disclose defendant's registration of the “ecash.com” domain name to the PTO, however eCash Technologies subsequently went bankrupt and the domain \"Ecash.com\" remained in possession of the original owner.\n\nIn 2002 eCash Technologies was acquired by InfoSpace, currently known as Blucora. As of 2015, the term eCash is used for the digital cash that can be stored on an electronically sensitive card including online or alternative payment portals and mobile applications. In 2016, Due Inc was granted the “ecash” trademark.\n\n\n\n"}
{"id": "22728734", "url": "https://en.wikipedia.org/wiki?curid=22728734", "title": "Echo 2", "text": "Echo 2\n\nThe Echo II was a plug-in expansion card, speech synthesizer card for the Apple II and Apple IIe personal computers that allowed applications to use speech synthesis. The Echo II used the TMS5220 speech synthesis chip to synthesize speech. The Echo II software could synthesize either unlimited text-to-speech using stitched phonemes, or play back raw LPC data for specific words, with resulting higher speech quality.\n\nLPC (linear predictive coding) was the speech synthesis technology used, which allowed applications to encode speech data in a compact form. The Echo II used the TMS 5220 LPC Speech Chip which was popular in other speech synthesizers\n\n"}
{"id": "727012", "url": "https://en.wikipedia.org/wiki?curid=727012", "title": "End-of-train device", "text": "End-of-train device\n\nThe end of train device (ETD), sometimes referred to as an EOT, flashing rear-end device (FRED) or sense and braking unit (SBU) is an electronic device mounted on the end of freight trains in lieu of a caboose. They are divided into three categories: \"dumb\" units, which only provide a visible indication of the rear of the train with a flashing red taillight; \"average intelligence\" units with a brake pipe pressure gauge; and \"smart\" units, which send back data to the crew in the locomotive via radio-based telemetry. They originated in North America, and are also used elsewhere in the world, where they may include complete End of Train Air System (ETAS) or Sense and Brake Unit (SBU) devices.\n\nA \"dumb\" ETD can be as simple as a red flag attached to the coupler on the last car of the train, whereas \"smart\" devices monitor functions such as brake line pressure and accidental separation of the train using a motion sensor, functions that were previously monitored by a crew in the caboose. The ETD transmits data via a telemetry link to the Head-of-Train Device (HTD) in the locomotive, known colloquially among railroaders as a \"Wilma,\" a play on the first name of the wife of cartoon character Fred Flintstone. In Canada, this device is known as a sense and braking unit (SBU).\n\nA typical HTD contains several lights indicating telemetry status and rear end movement, along with a digital readout of the brake line pressure from the ETD. It also contains a toggle switch used to initiate an emergency brake application from the rear end. In modern locomotives, the HTD is built into the locomotive's computer system, and the information is displayed on the engineer's computer screen.\n\nRailroads have strict government-approved air brake testing procedures for various circumstances when assembling trains or switching out cars en route. After a cut is made between cars in a train and the train is rejoined, in addition to other tests, the crew must verify that the brakes apply and release on the rear car (to ensure that all of the brake hoses are connected and the angle cocks, or valves, are opened). In most cases, the engineer is able to use information from the ETD to verify that the air pressure reduces and increases at the rear of the train accordingly, indicating proper brake pipe continuity. This device is said to constitute a fail-safe condition.\n\nThe ETD reduced labor costs, as well as the costs of the purchase and upkeep of cabooses. The Brotherhood of Conductors, and Brotherhood of Railroad Brakemen were also greatly affected by ETD, as this electronic unit replaced two crewmen per train. The widespread use of ETD's has made the caboose nearly obsolete. Some roads still use cabooses where the train must be backed up, on short local runs, as rolling offices, or railroad police stations and as transportation for right-of-way maintenance crews. In some cases (see photo) instead of hitching a caboose, an employee stands on the last car when the train is backing up.\n\nThe first ETD use is attributed to Florida East Coast Railway in 1969, soon after which other Class I railroads began using ETD's as well. By the mid-1980s they were common equipment. Early models were little more than a brake line connection / termination, a battery and flashing tail light. As their use became more widespread through the 1980s, ETD's were equipped with radio telemetry transmitters to send brake pressure data to a receiver in the locomotive. To reduce the cost of battery replacements, ambient light sensors were added so the flashing light on the ETD would illuminate only during dusk and after dark. Later models have a small turbine-powered electrical generator using air pressure from the brake line to power the ETD's radio and sensors.\n\nThe one-way communication of brake data from the ETD to the locomotive evolved into two-way communication that enables the engineer to apply the brakes from both ends of the train simultaneously in an emergency. This is useful in the event that a blockage (or an unopened valve) in the train's brake line is preventing dumping the air pressure and causing all of the brakes in the train going into an emergency application. Such a situation could be dangerous, as stopping distance increases with fewer functioning brakes. Dumping the brake line pressure from both the front and rear of the train simultaneously ensures that the entire train applies all of its brakes in emergency. Other electronics within the ETD were also enhanced, and many now include GPS receivers as well as the two-way radio communications.\n"}
{"id": "35276033", "url": "https://en.wikipedia.org/wiki?curid=35276033", "title": "European Transonic Wind Tunnel", "text": "European Transonic Wind Tunnel\n\nThe European transonic wind tunnel (ETW) is a high-Reynolds-number transonic wind tunnel using nitrogen as test gas.\n\nIt is one of the world's largest cryogenic wind tunnels. It is situated in Cologne, Germany. ETW was constructed and is operated by the four European countries France, Germany, Great Britain and The Netherlands. The ETW is in operation since 1994.\n\nETW provides real-flight Reynolds numbers by virtue of both increased pressure and decreased temperature. Independent variation of Reynolds number and aero elastic loading can be done there. They specialize in Flight Reynolds number testing for full-span and semi-span models at cruise conditions and extreme borders of flight envelope.\n\nThe tunnel parameters are as follows:\n\nOptical access to the test section for various cameras and light sources is provided through 90 special windows in all walls.\n\nETW has a closed aerodynamic circuit contained inside an internally insulated stainless steel pressure shell. The compressor with a drive power of up to 50 MW circulates the nitrogen gas around the circuit. To achieve the desired low temperature of the gas flow and to compensate for the heat input caused by viscous friction in the flow, liquid nitrogen with a temperature of minus 196°C is continuously injected into the tunnel flow through four rakes with some 270 spray nozzles in the short leg of the circuit upstream of the compressor. This liquid nitrogen vaporizes immediately and thus forms the cold gas flow. The corresponding gaseous nitrogen exhaust is located in the other short leg of the circuit upstream of the stilling chamber and is controlled by valves to maintain constant pressure inside the tunnel.\n\nTest section details:\n\nAn exchangeable model cart system is present to increase the productivity.\n\nThe instrumentation facilities include flange type strain gauge balances, servoaccelerometer inclinometer, Kulite measurement system, Deformation Measurement System, Temperature Sensitive Paint System and mini tufts.\n\n"}
{"id": "31348583", "url": "https://en.wikipedia.org/wiki?curid=31348583", "title": "Fire glass", "text": "Fire glass\n\nFire glass is tempered glass manufactured as a medium to retain and direct heat in fireplaces and gas fire pits. Fire glass does not burn, but retains heat and refracts light as a result of burning gas. Fire glass, like artificial logs and stones, is additionally used to obscure the gas plumbing inherent in gas fireplaces or stoves.\n\nA vast asortment of fire glass shapes, sizes and colors are available to match a wide variety of contemporary décors. During the manufacturing process, sheets of glass are tempered to withstand heat. This process prevents the glass from \"popping\" when used in a fire and negates the threat of sparking seen in traditional wood burning fireplaces or fire features. These tempered sheets of glass are then shattered. and professionally packaged. Although a variety of fire glass types exist, variations are purily aesthetic, and all varieties serve the same purpose within a fire feature.\n\nFire glass leaves no trace of ash, soot, grease or discernible odor when used as a medium. Flames produced using natural gas do not produce any smoke, produce less toxic gases and leave no trace of residual pollutants such as tar within the home. The combination is considered an eco-friendly burning solution. Additionally, fire glass is often made from recycled glass, making for a \"green\" fire media option.\n\nIn addition to being used as a fire pit and fireplace media, fire glass is often used as a crafting item (e.g. in a wedding centerpiece).\n"}
{"id": "144056", "url": "https://en.wikipedia.org/wiki?curid=144056", "title": "Fluorescent lamp", "text": "Fluorescent lamp\n\nA fluorescent lamp, or fluorescent tube, is a low-pressure mercury-vapor gas-discharge lamp that uses fluorescence to produce visible light. An electric current in the gas excites mercury vapor, which produces short-wave ultraviolet light that then causes a phosphor coating on the inside of the lamp to glow. A fluorescent lamp converts electrical energy into useful light much more efficiently than incandescent lamps. The typical luminous efficacy of fluorescent lighting systems is 50–100 lumens per watt, several times the efficacy of incandescent bulbs with comparable light output.\n\nFluorescent lamp fixtures are more costly than incandescent lamps because they require a ballast to regulate the current through the lamp, but the lower energy cost typically offsets the higher initial cost. Compact fluorescent lamps are now available in the same popular sizes as incandescents and are used as an energy-saving alternative in homes.\n\nBecause they contain mercury, many fluorescent lamps are classified as hazardous waste. The United States Environmental Protection Agency recommends that fluorescent lamps be segregated from general waste for recycling or safe disposal, and some jurisdictions require recycling of them.\n\nFluorescence of certain rocks and other substances had been observed for hundreds of years before its nature was understood. By the middle of the 19th century, experimenters had observed a radiant glow emanating from partially evacuated glass vessels through which an electric current passed. One of the first to explain it was the Irish scientist Sir George Stokes from the University of Cambridge in 1852, who named the phenomenon \"fluorescence\" after fluorite, a mineral many of whose samples glow strongly because of impurities. The explanation relied on the nature of electricity and light phenomena as developed by the British scientists Michael Faraday in the 1840s and James Clerk Maxwell in the 1860s.\n\nLittle more was done with this phenomenon until 1856 when German glassblower Heinrich Geissler created a mercury vacuum pump that evacuated a glass tube to an extent not previously possible. Geissler invented the first gas-discharge lamp, the Geissler tube, consisting of a partially evacuated glass tube with a metal electrode at either end. When a high voltage was applied between the electrodes, the inside of the tube lit up with a glow discharge. By putting different chemicals inside, the tubes could be made to produce a variety of colors, and elaborate Geissler tubes were sold for entertainment. More important, however, was its contribution to scientific research. One of the first scientists to experiment with a Geissler tube was Julius Plücker who systematically described in 1858 the luminescent effects that occurred in a Geissler tube. He also made the important observation that the glow in the tube shifted position when in proximity to an electromagnetic field. Alexandre Edmond Becquerel observed in 1859 that certain substances gave off light when they were placed in a Geissler tube. He went on to apply thin coatings of luminescent materials to the surfaces of these tubes. Fluorescence occurred, but the tubes were very inefficient and had a short operating life.\n\nInquiries that began with the Geissler tube continued as even better vacuums were produced. The most famous was the evacuated tube used for scientific research by William Crookes. That tube was evacuated by the highly effective mercury vacuum pump created by Hermann Sprengel. Research conducted by Crookes and others ultimately led to the discovery of the electron in 1897 by J. J. Thomson and X-rays in 1895 by Wilhelm Roentgen. But the Crookes tube, as it came to be known, produced little light because the vacuum in it was too good and thus lacked the trace amounts of gas that are needed for electrically stimulated luminescence.\n\nWhile Becquerel was interested primarily in conducting scientific research into fluorescence, Thomas Edison briefly pursued fluorescent lighting for its commercial potential. He invented a fluorescent lamp in 1896 that used a coating of calcium tungstate as the fluorescing substance, excited by X-rays, but although it received a patent in 1907, it was not put into production. As with a few other attempts to use Geissler tubes for illumination, it had a short operating life, and given the success of the incandescent light, Edison had little reason to pursue an alternative means of electrical illumination. Nikola Tesla made similar experiments in the 1890s, devising high-frequency powered fluorescent bulbs that gave a bright greenish light, but as with Edison's devices, no commercial success was achieved.\n\nAlthough Edison had lost interest in fluorescent lighting, one of his former employees was able to create a gas-based lamp that achieved a measure of commercial success. In 1895 Daniel McFarlan Moore demonstrated lamps in length that used carbon dioxide or nitrogen to emit white or pink light, respectively. As with future fluorescent lamps, they were considerably more complicated than an incandescent bulb.\nAfter years of work, Moore was able to extend the operating life of the lamps by inventing an electromagnetically controlled valve that maintained a constant gas pressure within the tube. Although Moore’s lamp was complicated, was expensive to install, and required very high voltages, it was considerably more efficient than incandescent lamps, and it produced a closer approximation to natural daylight than contemporary incandescent lamps. From 1904 onwards Moore’s lighting system was installed in a number of stores and offices. Its success contributed to General Electric’s motivation to improve the incandescent lamp, especially its filament. GE’s efforts came to fruition with the invention of a tungsten-based filament. The extended lifespan and improved efficacy of incandescent bulbs negated one of the key advantages of Moore’s lamp, but GE purchased the relevant patents in 1912. These patents and the inventive efforts that supported them were to be of considerable value when the firm took up fluorescent lighting more than two decades later.\n\nAt about the same time that Moore was developing his lighting system, another American was creating a means of illumination that also can be seen as a precursor to the modern fluorescent lamp. This was the mercury-vapor lamp, invented by Peter Cooper Hewitt and patented in 1901 (; this patent number is frequently misquoted as US 889,692). Hewitt’s lamp glowed when an electric current was passed through mercury vapor at a low pressure. Unlike Moore’s lamps, Hewitt's were manufactured in standardized sizes and operated at low voltages. The mercury-vapor lamp was superior to the incandescent lamps of the time in terms of energy efficiency, but the blue-green light it produced limited its applications. It was, however, used for photography and some industrial processes.\n\nMercury vapor lamps continued to be developed at a slow pace, especially in Europe, and by the early 1930s they received limited use for large-scale illumination. Some of them employed fluorescent coatings, but these were used primarily for color correction and not for enhanced light output. Mercury vapor lamps also anticipated the fluorescent lamp in their incorporation of a ballast to maintain a constant current.\n\nCooper-Hewitt had not been the first to use mercury vapor for illumination, as earlier efforts had been mounted by Way, Rapieff, Arons, and Bastian and Salisbury. Of particular importance was the mercury vapor lamp invented by Küch in Germany. This lamp used quartz in place of glass to allow higher operating temperatures, and hence greater efficiency. Although its light output relative to electrical consumption was better than that of other sources of light, the light it produced was similar to that of the Cooper-Hewitt lamp in that it lacked the red portion of the spectrum, making it unsuitable for ordinary lighting.\n\nThe next step in gas-based lighting took advantage of the luminescent qualities of neon, an inert gas that had been discovered in 1898 by isolation from the atmosphere. Neon glowed a brilliant red when used in Geissler tubes. By 1910, Georges Claude, a Frenchman who had developed a technology and a successful business for air liquefaction, was obtaining enough neon as a byproduct to support a neon lighting industry. While neon lighting was used around 1930 in France for general illumination, it was no more energy-efficient than conventional incandescent lighting. Neon tube lighting, which also includes the use of argon and mercury vapor as alternative gases, came to be used primarily for eye-catching signs and advertisements. Neon lighting was relevant to the development of fluorescent lighting, however, as Claude’s improved electrode (patented in 1915) overcame \"sputtering\", a major source of electrode degradation. Sputtering occurred when ionized particles struck an electrode and tore off bits of metal. Although Claude’s invention required electrodes with a lot of surface area, it showed that a major impediment to gas-based lighting could be overcome.\n\nThe development of the neon light also was significant for the last key element of the fluorescent lamp, its fluorescent coating. In 1926 Jacques Risler received a French patent for the application of fluorescent coatings to neon light tubes. The main use of these lamps, which can be considered the first commercially successful fluorescents, was for advertising, not general illumination. This, however, was not the first use of fluorescent coatings; Becquerel had earlier used the idea and Edison used calcium tungstate for his unsuccessful lamp. Other efforts had been mounted, but all were plagued by low efficiency and various technical problems. Of particular importance was the invention in 1927 of a low-voltage “metal vapor lamp” by Friedrich Meyer, Hans-Joachim Spanner, and Edmund Germer, who were employees of a German firm in Berlin. A German patent was granted but the lamp never went into commercial production.\n\nAll the major features of fluorescent lighting were in place at the end of the 1920s. Decades of invention and development had provided the key components of fluorescent lamps: economically manufactured glass tubing, inert gases for filling the tubes, electrical ballasts, long-lasting electrodes, mercury vapor as a source of luminescence, effective means of producing a reliable electrical discharge, and fluorescent coatings that could be energized by ultraviolet light. At this point, intensive development was more important than basic research.\n\nIn 1934, Arthur Compton, a renowned physicist and GE consultant, reported to the GE lamp department on successful experiments with fluorescent lighting at General Electric Co., Ltd. in Great Britain (unrelated to General Electric in the United States). Stimulated by this report, and with all of the key elements available, a team led by George E. Inman built a prototype fluorescent lamp in 1934 at General Electric’s Nela Park (Ohio) engineering laboratory. This was not a trivial exercise; as noted by Arthur A. Bright, \"A great deal of experimentation had to be done on lamp sizes and shapes, cathode construction, gas pressures of both argon and mercury vapor, colors of fluorescent powders, methods of attaching them to the inside of the tube, and other details of the lamp and its auxiliaries before the new device was ready for the public.\"\n\nIn addition to having engineers and technicians along with facilities for R&D work on fluorescent lamps, General Electric controlled what it regarded as the key patents covering fluorescent lighting, including the patents originally issued to Hewitt, Moore, and Küch. More important than these was a patent covering an electrode that did not disintegrate at the gas pressures that ultimately were employed in fluorescent lamps. Albert W. Hull of GE’s Schenectady Research Laboratory filed for a patent on this invention in 1927, which was issued in 1931. General Electric used its control of the patents to prevent competition with its incandescent lights and probably delayed the introduction of fluorescent lighting by 20 years. Eventually, war production required 24-hour factories with economical lighting and fluorescent lights became available.\n\nWhile the Hull patent gave GE a basis for claiming legal rights over the fluorescent lamp, a few months after the lamp went into production the firm learned of a U.S. patent application that had been filed in 1927 for the aforementioned \"metal vapor lamp\" invented in Germany by Meyer, Spanner, and Germer. The patent application indicated that the lamp had been created as a superior means of producing ultraviolet light, but the application also contained a few statements referring to fluorescent illumination. Efforts to obtain a U.S. patent had met with numerous delays, but were it to be granted, the patent might have caused serious difficulties for GE. At first, GE sought to block the issuance of a patent by claiming that priority should go to one of their employees, Leroy J. Buttolph, who according to their claim had invented a fluorescent lamp in 1919 and whose patent application was still pending. GE also had filed a patent application in 1936 in Inman’s name to cover the “improvements” wrought by his group. In 1939 GE decided that the claim of Meyer, Spanner, and Germer had some merit, and that in any event a long interference procedure was not in their best interest. They therefore dropped the Buttolph claim and paid $180,000 to acquire the Meyer, et al. application, which at that point was owned by a firm known as Electrons, Inc. The patent was duly awarded in December 1939. This patent, along with the Hull patent, put GE on what seemed to be firm legal ground, although it faced years of legal challenges from Sylvania Electric Products, Inc., which claimed infringement on patents that it held.\n\nEven though the patent issue was not completely resolved for many years, General Electric’s strength in manufacturing and marketing gave it a pre-eminent position in the emerging fluorescent light market. Sales of \"fluorescent lumiline lamps\" commenced in 1938 when four different sizes of tubes were put on the market. They were used in fixtures manufactured by three leading corporations, Lightolier, Artcraft Fluorescent Lighting Corporation, and Globe Lighting. The Slimline fluorescent ballast's public\nintroduction in 1946 was by Westinghouse and General Electric and Showcase/Display Case fixtures were introduced by Artcraft Fluorescent Lighting Corporation in 1946. During the following year, GE and Westinghouse publicized the new lights through exhibitions at the New York World’s Fair and the Golden Gate International Exposition in San Francisco. Fluorescent lighting systems spread rapidly during World War II as wartime manufacturing intensified lighting demand. By 1951 more light was produced in the United States by fluorescent lamps than by incandescent lamps.\n\nIn the first years zinc orthosilicate with varying content of beryllium was used as greenish phosphor. Small additions of magnesium tungstate improved the blue part of the spectrum yielding acceptable white. After it was discovered that beryllium was toxic, halophosphate based phosphors took over.\n\nThe fundamental means for conversion of electrical energy into radiant energy in a fluorescent lamp relies on inelastic scattering of electrons when an incident electron collides with an atom in the mercury gas. If the (incident) free electron has enough kinetic energy, it transfers energy to the atom's outer electron, causing that electron to temporarily jump up to a higher energy level. The collision is 'inelastic' because a loss of kinetic energy occurs.\n\nThis higher energy state is unstable, and the atom will emit an ultraviolet photon as the atom's electron reverts to a lower, more stable, energy level. Most of the photons that are released from the mercury atoms have wavelengths in the ultraviolet (UV) region of the spectrum, predominantly at wavelengths of 253.7 and 185 nanometers (nm). These are not visible to the human eye, so they must be converted into visible light. This is done by making use of fluorescence. Ultraviolet photons are absorbed by electrons in the atoms of the lamp's interior fluorescent coating, causing a similar energy jump, then drop, with emission of a further photon. The photon that is emitted from this second interaction has a lower energy than the one that caused it. The chemicals that make up the phosphor are chosen so that these emitted photons are at wavelengths visible to the human eye. The difference in energy between the absorbed ultra-violet photon and the emitted visible light photon goes toward heating up the phosphor coating.\n\nWhen the light is turned on, the electric power heats up the cathode enough for it to emit electrons (thermionic emission). These electrons collide with and ionize noble gas atoms inside the bulb surrounding the filament to form a plasma by the process of impact ionization. As a result of avalanche ionization, the conductivity of the ionized gas rapidly rises, allowing higher currents to flow through the lamp.\n\nThe fill gas helps determine the operating electrical characteristics of the lamp, but does not give off light itself. The fill gas effectively increases the distance that electrons travel through the tube, which allows an electron a greater chance of interacting with a mercury atom. Argon atoms, excited to a metastable state by impact of an electron, can impart this energy to a neutral mercury atom and ionize it, described as the Penning effect. This has the benefit of lowering the breakdown and operating voltage of the lamp, compared to other possible fill gases such as krypton.\n\nA fluorescent lamp tube is filled with a gas containing low-pressure mercury vapor and argon, xenon, neon, or krypton. The pressure inside the lamp is around 0.3% of atmospheric pressure. The inner surface of the lamp is coated with a fluorescent (and often slightly phosphorescent) coating made of varying blends of metallic and rare-earth phosphor salts. The lamp's electrodes are typically made of coiled tungsten and usually referred to as cathodes because of their prime function of emitting electrons. For this, they are coated with a mixture of barium, strontium and calcium oxides chosen to have a low thermionic emission temperature.\n\nFluorescent lamp tubes are typically straight and range in length from about for miniature lamps, to for high-output lamps. Some lamps have the tube bent into a circle, used for table lamps or other places where a more compact light source is desired. Larger U-shaped lamps are used to provide the same amount of light in a more compact area, and are used for special architectural purposes. Compact fluorescent lamps have several small-diameter tubes joined in a bundle of two, four, or six, or a small diameter tube coiled into a helix, to provide a high amount of light output in little volume.\n\nLight-emitting phosphors are applied as a paint-like coating to the inside of the tube. The organic solvents are allowed to evaporate, then the tube is heated to nearly the melting point of glass to drive off remaining organic compounds and fuse the coating to the lamp tube. Careful control of the grain size of the suspended phosphors is necessary; large grains, 35 micrometers or larger, lead to weak grainy coatings, whereas too many small particles 1 or 2 micrometers or smaller leads to poor light maintenance and efficiency. Most phosphors perform best with a particle size around 10 micrometers. The coating must be thick enough to capture all the ultraviolet light produced by the mercury arc, but not so thick that the phosphor coating absorbs too much visible light. The first phosphors were synthetic versions of naturally occurring fluorescent minerals, with small amounts of metals added as activators. Later other compounds were discovered, allowing differing colors of lamps to be made.\n\nFluorescent lamps are negative differential resistance devices, so as more current flows through them, the electrical resistance of the fluorescent lamp drops, allowing for even more current to flow. Connected directly to a constant-voltage power supply, a fluorescent lamp would rapidly self-destruct because of the uncontrolled current flow. To prevent this, fluorescent lamps must use an auxiliary device, a ballast, to regulate the current flow through the lamp.\n\nThe terminal voltage across an operating lamp varies depending on the arc current, tube diameter, temperature, and fill gas. A fixed part of the voltage drop is due to the electrodes. A general lighting service T12 lamp operates at 430 mA, with 100 volts drop. High output lamps operate at 800 mA, and some types operate up to 1.5 A. The power level varies from 33 to 82 watts per meter of tube length (10 to 25 W/ft) for T12 lamps.\n\nThe simplest ballast for alternating current (AC) use is an inductor placed in series, consisting of a winding on a laminated magnetic core. The inductance of this winding limits the flow of AC current. This type is still used, for example, in 120 volt operated desk lamps using relatively short lamps. Ballasts are rated for the size of lamp and power frequency. Where the AC voltage is insufficient to start long fluorescent lamps, the ballast is often a step-up autotransformer with substantial leakage inductance (so as to limit the current flow). Either form of inductive ballast may also include a capacitor for power factor correction.\nMany different circuits have been used to operate fluorescent lamps. The choice of circuit is based on AC voltage, tube length, initial cost, long term cost, instant versus non-instant starting, temperature ranges and parts availability, etc.\n\nFluorescent lamps can run directly from a direct current (DC) supply of sufficient voltage to strike an arc. The ballast must be resistive, and would consume about as much power as the lamp. When operated from DC, the starting switch is often arranged to reverse the polarity of the supply to the lamp each time it is started; otherwise, the mercury accumulates at one end of the tube. Fluorescent lamps are (almost) never operated directly from DC for those reasons. Instead, an inverter converts the DC into AC and provides the current-limiting function as described below for electronic ballasts.\n\nThe light output and performance of fluorescent lamps is critically affected by the temperature of the bulb wall and its effect on the partial pressure of mercury vapor within the lamp. Each lamp contains a small amount of mercury, which must vaporize to support the lamp current and generate light. At low temperatures, the mercury is in the form of dispersed liquid droplets. As the lamp warms, more of the mercury is in vapor form. At higher temperatures, self-absorption in the vapor reduces the yield of UV and visible light. Since mercury condenses at the coolest spot in the lamp, careful design is required to maintain that spot at the optimum temperature, around .\n\nUsing an amalgam with some other metal reduces the vapor pressure and extends the optimum temperature range upward; however, the bulb wall \"cold spot\" temperature must still be controlled to prevent migration of the mercury out of the amalgam and condensing on the cold spot. Fluorescent lamps intended for higher output will have structural features such as a deformed tube or internal heat-sinks to control cold spot temperature and mercury distribution. Heavily loaded small lamps, such as compact fluorescent lamps, also include heat-sink areas in the tube to maintain mercury vapor pressure at the optimum value.\n\nOnly a fraction of the electrical energy input into a lamp is converted to useful light. The ballast dissipates some heat; electronic ballasts may be around 90% efficient. A fixed voltage drop occurs at the electrodes, which also produces heat. Some of the energy in the mercury vapor column is also dissipated, but about 85% is turned into visible and ultraviolet light.\n\nThe UV light is absorbed by the lamp's fluorescent coating, which re-radiates the energy at longer wavelengths to emit visible light. Not all the UV energy striking the phosphor gets converted into visible light. In a modern lamp, for every 100 incident photons of UV impacting the phosphor, only 86 visible light photons are emitted (a quantum efficiency of 86%). The largest single loss in modern lamps is due to the lower energy of each photon of visible light, compared to the energy of the UV photons that generated them (a phenomenon called Stokes shift). Incident photons have an energy of 5.5 electron volts but produce visible light photons with energy around 2.5 electron volts, so only 45% of the UV energy is used; the rest is dissipated as heat. If a so-called \"two-photon\" phosphor could be developed, this would improve the efficiency but much research has not yet found such a system.\n\nMost fluorescent lamps use electrodes that operate by thermionic emission, meaning they are operated at a high enough temperature for the electrode material (usually aided by a special coating) to emit electrons into the tube by heat.\n\nHowever, there are also tubes that operate in cold cathode mode, whereby electrons are liberated into the tube only by the large potential difference (voltage) between the electrodes. This does not mean the electrodes are cold (indeed, they can be very hot), but it does mean they are operating below their thermionic emission temperature. Because cold cathode lamps have no thermionic emission coating to wear out, they can have much longer lives than hot cathode tubes. This quality makes them desirable for maintenance-free long-life applications (such as backlights in liquid crystal displays). Sputtering of the electrode may still occur, but electrodes can be shaped (e.g. into an internal cylinder) to capture most of the sputtered material so it is not lost from the electrode.\n\nCold cathode lamps are generally less efficient than thermionic emission lamps because the cathode fall voltage is much higher. The increased fall voltage results in more power dissipation at tube ends, which does not contribute to light output. However, this is less significant with longer tubes. The increased power dissipation at tube ends also usually means cold cathode tubes have to be run at a lower loading than their thermionic emission equivalents. Given the higher tube voltage required anyway, these tubes can easily be made long, and even run as series strings. They are better suited for bending into special shapes for lettering and signage, and can also be instantly switched on or off.\n\nThe noble gas used in the fluorescent tube (commonly argon) must be ionized before the arc can \"strike\" within the tube. For small lamps, it does not take much voltage to strike the arc and starting the lamp presents no problem, but larger tubes require a substantial voltage (in the range of a thousand volts).\n\nThis technique uses a combination filament–cathode at each end of the lamp in conjunction with a mechanical or automatic (bi-metallic) switch (see circuit diagram to the right) that initially connect the filaments in series with the ballast to preheat them; when the arc is struck the filaments are disconnected. This system is described as \"preheat\" in some countries and \"switchstart\" in others. These systems are standard equipment in 200–240 V countries (and for 100–120 V lamps up to about 30 watts).\nBefore the 1960s, four-pin thermal starters and manual switches were used. A mechanism then widely used for preheating, still in common use, is a glow switch starter (illustrated). It consists of a normally open bi-metallic switch in a small sealed gas-discharge lamp containing inert gas (neon or argon).\nWhen power is first applied to the circuit, there will be a glow discharge across the electrodes in the starter lamp. This heats the gas in the starter and causes one of the bi-metallic contacts to bend towards the other. When the contacts touch, the two filaments of the fluorescent lamp and the ballast will effectively be switched in series to the supply voltage. The current through the filaments causes them to heat up and emit electrons into the tube gas by thermionic emission. In the starter, the touching contacts short out the voltage sustaining the glow discharge, extinguishing it so the gas cools down and no longer heats the bi-metallic switch, which opens within a second or two. The current through the filaments and the inductive ballast is abruptly interrupted, leaving the full line voltage applied between the filaments at the ends of the tube and generating an inductive kick which provides the high voltage needed to start the lamp. The lamp will fail to strike if the filaments are not hot enough, in which case the cycle repeats; several cycles are usually needed, which causes flickering and clicking during starting (older thermal starters behaved better in this respect). A power factor correction (PFC) capacitor draws leading current from the mains to compensate for the lagging current drawn by the lamp circuit.\n\nOnce the tube strikes, the impinging main discharge keeps the cathodes hot, permitting continued electron emission without the need for the filaments to continue to be heated. The starter switch does not close again because the voltage across the lit tube is insufficient to start a glow discharge in the starter.\n\nWith automated starters such as glow starters, a failing tube will cycle endlessly, flickering as the lamp quickly goes out because the emission mix is insufficient to keep the lamp current high enough to keep the glow starter open. This runs the ballast at higher temperature. Some more advanced starters time out in this situation, and do not attempt repeated starts until power is reset. Some older systems used a thermal over-current trip to detect repeated starting attempts and disable the circuit until manually reset. The switch contacts in glow starters are subject to wear and inevitably fail eventually, so the starter is manufactured as a plug-in replaceable unit.\n\nMore recently introduced electronic starters use a different method to preheat the cathodes. They may be designed to be plug-in interchangeable with glow starters for use in standard fittings. They commonly use a purpose-designed semiconductor switch and \"soft start\" the lamp by preheating the cathodes before applying a controlled starting pulse which strikes the lamp first time without flickering; this dislodges a minimal amount of material from the cathodes during starting, giving longer lamp life than possible with the uncontrolled impulses to which the lamp is subjected in a switchstart. This is claimed to prolong lamp life by a factor of typically 3 to 4 times for a lamp frequently switched on as in domestic use, and to reduce the blackening of the ends of the lamp typical of fluorescent tubes. The circuit is typically complex, but the complexity is built into the IC. Electronic starters may be optimized for fast starting (typical start time of 0.3 seconds), or for most reliable starting even at low temperatures and with low supply voltages, with a startup time of 2–4 seconds. The faster-start units may produce audible noise during start-up.\n\nElectronic starters only attempt to start a lamp for a short time when power is initially applied, and do not repeatedly attempt to restrike a lamp that is dead and unable to sustain an arc; some automatically shut down a failed lamp. This eliminates the re-striking of a lamp and the continuous flickering of a failing lamp with a glow starter. Electronic starters are not subject to wear and do not need replacing periodically, although they may fail like any other electronic circuit. Manufacturers typically quote lives of 20 years, or as long as the light fitting. Starters are inexpensive, typically less than 50¢ for the short-lived glow type (depending upon lamp power), and perhaps ten times more for the electronic type .\n\nAnother type of tube does not have filaments to start it at all. \"Instant start\" fluorescent tubes simply use a high enough voltage to break down the gas and mercury column and thereby start arc conduction. These tubes can be identified by a single pin at each end of the tube. The lamp holders have a \"disconnect\" socket at the low-voltage end which disconnects the ballast when the tube is removed, to prevent electric shock. In North America, low-cost lighting fixtures with an integrated electronic ballast use instant start on lamps originally designed for preheating, although it shortens lamp life. This ballast technology isn't common outside North America.\n\nNewer \"rapid start\" ballast designs provide filament power windings within the ballast; these rapidly and continuously warm the filaments/cathodes using low-voltage AC. Usually operating at a lower arc voltage than the instant start design; no inductive voltage spike is produced for starting, so the lamps must be mounted near a grounded (earthed) reflector to allow the glow discharge to propagate through the tube and initiate the arc discharge. In some lamps a grounded \"starting aid\" strip is attached to the outside of the lamp glass. This ballast technology isn't used outside North America, where 220-240 V line voltage is common, and are incompatible with the European energy saver T8 fluorescent lamps because these lamps requires a higher starting voltage than that of the open circuit voltage of rapid start ballasts.\n\nQuick-start ballasts use a small auto-transformer to heat the filaments when power is first applied. When an arc strikes, the filament heating power is reduced and the tube will start within half a second. The auto-transformer is either combined with the ballast or may be a separate unit. Tubes need to be mounted near an earthed metal reflector in order for them to strike. Quick-start ballasts are more common in commercial installations because of lower maintenance costs. A quick-start ballast eliminates the need for a starter switch, a common source of lamp failures. Nonetheless, Quick-start ballasts are also used in domestic (residential) installations because of the desirable feature that a Quick-start ballast light turns on nearly immediately after power is applied (when a switch is turned on). Quick-start ballasts are used only on 240 V circuits and are designed for use with the older, less efficient T12 tubes.\n\nThe semi-resonant start circuit was invented by Thorn Lighting for use with T12 fluorescent tubes. This method uses a double wound transformer and a capacitor. With no arc current, the transformer and capacitor resonate at line frequency and generate about twice the supply voltage across the tube, and a small electrode heating current. This tube voltage is too low to strike the arc with cold electrodes, but as the electrodes heat up to thermionic emission temperature, the tube striking voltage falls below that of the ringing voltage, and the arc strikes. As the electrodes heat, the lamp slowly, over three to five seconds, reaches full brightness. As the arc current increases and tube voltage drops, the circuit provides current limiting.\n\nSemi-resonant start circuits are mainly restricted to use in commercial installations because of the higher initial cost of circuit components. However, there are no starter switches to be replaced and cathode damage is reduced during starting making lamps last longer, reducing maintenance costs. Because of the high open circuit tube voltage, this starting method is particularly good for starting tubes in cold locations. Additionally, the circuit power factor is almost 1.0, and no additional power factor correction is needed in the lighting installation. As the design requires that twice the supply voltage must be lower than the cold-cathode striking voltage (or the tubes would erroneously instant-start), this design cannot be used with AC power unless the tubes are at least length. Semi-resonant start fixtures are generally incompatible with energy saving T8 retrofit tubes, because such tubes have a higher starting voltage than T12 lamps and may not start reliably, especially in low temperatures. Recent proposals in some countries to phase out T12 tubes will reduce the application of this starting method.\n\nThis is used with electronic ballasts shown below. This ballast applies power to the filaments first, then after a short delay to allow the cathodes to preheat, applies voltage to the lamps to strike an arc. This ballast gives the best life and most starts from lamps, and so is preferred for applications with very frequent power cycling such as vision examination rooms and restrooms with a motion detector switch.\n\nElectronic ballasts employ transistors to change the supply frequency into high-frequency AC while also regulating the current flow in the lamp. Some still use an inductance to limit the current, but the higher frequency allows a much smaller inductance to be used. Others use a capacitor-transistor combination to replace the inductor, since a transistor and capacitor working together can . These ballasts take advantage of the higher efficacy of lamps operated with higher-frequency current, which rises by almost 10% at , compared to efficacy at normal power frequency. When the AC period is shorter than the relaxation time to de-ionize mercury atoms in the discharge column, the discharge stays closer to optimum operating condition. Electronic ballasts are commonly supplied with AC power, which is internally converted to DC and then back to a variable frequency AC waveform. Depending upon the capacitance and the quality of constant-current pulse-width modulation, this can largely eliminate modulation at 100 or 120 Hz.\n\nLow cost ballasts mostly contain only a simple oscillator and series resonant LC circuit. When turned on, the oscillator starts, and resonant current excites the LC circuit. This resonant current directly drives a switching transistor through a ring core transformer. This principle is called the current resonant inverter circuit. After a short time the voltage across the lamp reaches about 1 kV and the lamp ignites. The process is too fast to preheat the cathodes, so the lamp instant-starts in cold cathode mode. The cathode filaments are still used for protection of the ballast from overheating if the lamp does not ignite. A few manufacturers use positive temperature coefficient (PTC) thermistors to disable instant starting and give some time to preheat the filaments.\n\nMore complex electronic ballasts use programmed start. The output frequency is started above the resonance frequency of the output circuit of the ballast; and after the filaments are heated, the frequency is rapidly decreased. If the frequency approaches the resonant frequency of the ballast, the output voltage will increase so much that the lamp will ignite. If the lamp does not ignite, an electronic circuit stops the operation of the ballast.\n\nMany electronic ballasts are controlled by a microcontroller or similar, and these are sometimes called digital ballasts. Digital ballasts can apply quite complex logic to lamp starting and operation. This enables functions such as testing for broken electrodes and missing tubes before attempting to start, auto detect tube replacement, and auto detection of tube type, such that a single ballast can be used with several different tubes, even those that operate at different arc currents, etc. Once such fine grained control over the starting and arc current is achievable, features such as dimming, and having the ballast maintain a constant light level against changing sunlight contribution are all easily included in the embedded microcontroller software, and can be found in various manufacturers' products.\n\nSince introduction in the 1990s, high-frequency ballasts have been used in general lighting fixtures with either rapid start or pre-heat lamps. These ballasts convert the incoming power to an output frequency in excess of . This increases lamp efficiency. These are used in several applications, including new generation tanning lamp systems, whereby a 100 watt lamp (e.g., F71T12BP) can be lit using 90 watts of actual power while obtaining the same luminous flux (measured in lumens) as magnetic ballasts. These ballasts operate with voltages that can be almost 600 volts, requiring some consideration in housing design, and can cause a minor limitation in the length of the wire leads from the ballast to the lamp ends.\n\nThe end of life failure mode for fluorescent lamps varies depending on how they are used and their control gear type. Often the light will turn pink (see Loss of mercury), with black burns on the ends of the lamp due to sputtering of emission mix (see below). The lamp may also flicker at a noticeable rate (see Flicker problems).\n\nThe \"emission mix\" on the lamp filaments/cathodes is required to enable electrons to pass into the gas via thermionic emission at the lamp operating voltages used. The mix is slowly sputtered off by bombardment with electrons and mercury ions during operation, but a larger amount is sputtered off each time the lamp is started with cold cathodes. The method of starting the lamp has a significant impact on this. Lamps operated for typically less than 3 hours each switch-on will normally run out of the emission mix before other parts of the lamp fail. The sputtered emission mix forms the dark marks at the lamp ends seen in old lamps. When all the emission mix is gone, the cathode cannot pass sufficient electrons into the gas fill to maintain the gas discharge at the designed lamp operating voltage. Ideally, the control gear should shut down the lamp when this happens. However, some control gear will provide sufficient increased voltage to continue operating the lamp in cold cathode mode, which will cause overheating of the lamp end and rapid disintegration of the electrodes (filament goes open-circuit) and filament support wires until they are completely gone or the glass cracks, destroying the low pressure gas fill and stopping the gas discharge.\n\nThis may occur in compact fluorescent lamps with integral electrical ballasts or in linear lamps. Ballast electronics failure is a somewhat random process that follows the standard failure profile for any electronic device. There is an initial small peak of early failures, followed by a drop and steady increase over lamp life. Life of electronics is heavily dependent on operating temperature—it typically halves for each 10 °C temperature rise. The quoted average life of a lamp is usually at ambient (this may vary by country). The average life of the electronics at this temperature is normally greater than this, so at this temperature, not many lamps will fail because the electronics fail. In some fittings, the ambient temperature could be well above this, in which case failure of the electronics may become the predominant failure mechanism. Similarly, running a compact fluorescent lamp base-up will result in hotter electronics, which can cause shorter average life (particularly with higher power rated ones). Electronic ballasts should be designed to shut down the tube when the emission mix runs out as described above. In the case of integral electronic ballasts, since they never have to work again, this is sometimes done by having them deliberately burn out some component to permanently cease operation.\n\nIn most CFLs the filaments are connected in series, with a small capacitor between them. The discharge, once lit, is in parallel to the capacitor and presents a lower-resistance path, effectively shorting the capacitor out.\n\nThe phosphor drops off in efficiency during use. By around 25,000 operating hours, it will typically be half the brightness of a new lamp (although some manufacturers claim much longer half-lives for their lamps). Lamps that do not suffer failures of the emission mix or integral ballast electronics will eventually develop this failure mode. They still work, but have become dim and inefficient. The process is slow, and often becomes obvious only when a new lamp is operating next to an old one.\n\nAs in all mercury-based gas-filled tubes, mercury is slowly adsorbed onto the glass, phosphor, and tube electrodes throughout the life of the lamp, until it can no longer function. Loss of mercury will take over from failure of the phosphor in some lamps. The failure symptoms are similar, except loss of mercury initially causes an extended run-up time to full light output, and finally causes the lamp to glow a dim pink when the mercury runs out and the argon base gas takes over as the primary discharge.\nSubjecting the tube to asymmetric waveforms, where the total current flow through the tube does not cancel out and the tube effectively operates under a DC bias, causes asymmetric distribution of mercury ions along the tube due to cataphoresis. The localized depletion of mercury vapor pressure manifests as pink luminescence of the base gas in the vicinity of one of the electrodes, and the operating lifetime of the lamp may be dramatically shortened. This can be an issue with some poorly designed inverters.\n\nThe filaments can burn out (fail) at the end of the lamp's lifetime, opening the circuit and losing the capability to heat up. Both filaments lose function as they are connected in series, with just a simple switch start circuit a broken filament will render the lamp completely useless. Filaments rarely burn out or fail open circuit unless the filament becomes depleted of emitter and the control gear is able to supply a high enough voltage across the tube to operate it in cold cathode mode. Some digital electronic ballasts are capable of detecting broken filaments and can still strike an arc with one or both filaments broken providing there is still sufficient emitter. A broken filament in a lamp attached to a magnetic ballast often causes both lamps to burn out or flicker.\n\nThe spectrum of light emitted from a fluorescent lamp is the combination of light directly emitted by the mercury vapor, and light emitted by the phosphorescent coating. The spectral lines from the mercury emission and the phosphorescence effect give a combined spectral distribution of light that is different from those produced by incandescent sources. The relative intensity of light emitted in each narrow band of wavelengths over the visible spectrum is in different proportions compared to that of an incandescent source. Colored objects are perceived differently under light sources with differing spectral distributions. For example, some people find the color rendition produced by some fluorescent lamps to be harsh and displeasing. A healthy person can sometimes appear to have an unhealthy skin tone under fluorescent lighting. The extent to which this phenomenon occurs is related to the light's spectral composition, and may be gauged by its color rendering index (CRI).\n\nCorrelated color temperature (CCT) is a measure of the \"shade\" of whiteness of a light source compared with a blackbody. Typical incandescent lighting is 2700 K, which is yellowish-white. Halogen lighting is 3000 K. Fluorescent lamps are manufactured to a chosen CCT by altering the mixture of phosphors inside the tube. Warm-white fluorescents have CCT of 2700 K and are popular for residential lighting. Neutral-white fluorescents have a CCT of 3000 K or 3500 K. Cool-white fluorescents have a CCT of 4100 K and are popular for office lighting. Daylight fluorescents have a CCT of 5000 K to 6500 K, which is bluish-white.\n\nHigh CCT lighting generally requires higher light levels. At dimmer illumination levels, the human eye perceives lower color temperatures as more pleasant, as related through the Kruithof curve. So, a dim 2700 K incandescent lamp appears comfortable and a bright 5000 K lamp also appears natural, but a dim 5000 K fluorescent lamp appears too pale. Daylight-type fluorescents look natural only if they are very bright.\n\nColor rendering index (CRI) is a measure of how well colors can be perceived using light from a source, relative to light from a reference source such as daylight or a blackbody of the same color temperature. By definition, an incandescent lamp has a CRI of 100. Real-life fluorescent tubes achieve CRIs of anywhere from 50 to 98. Fluorescent lamps with low CRI have phosphors that emit too little red light. Skin appears less pink, and hence \"unhealthy\" compared with incandescent lighting. Colored objects appear muted. For example, a low CRI 6800 K halophosphate tube (an extreme example) will make reds appear dull red or even brown. Since the eye is relatively less efficient at detecting red light, an improvement in color rendering index, with increased energy in the red part of the spectrum, may reduce the overall luminous efficacy.\n\nLighting arrangements use fluorescent tubes in an assortment of tints of white. Mixing tube types within fittings can improve the color reproduction of lower quality tubes.\n\nSome of the least pleasant light comes from tubes containing the older, halophosphate-type phosphors (chemical formula Ca(PO)(F, Cl):Sb, Mn). This phosphor mainly emits yellow and blue light, and relatively little green and red. In the absence of a reference, this mixture appears white to the eye, but the light has an incomplete spectrum. The color rendering index (CRI) of such lamps is around 60.\n\nSince the 1990s, higher-quality fluorescent lamps use either a higher-CRI halophosphate coating, or a \"triphosphor\" mixture, based on europium and terbium ions, which have emission bands more evenly distributed over the spectrum of visible light. High-CRI halophosphate and triphosphor tubes give a more natural color reproduction to the human eye. The CRI of such lamps is typically 82–100.\n\nFluorescent lamps come in many shapes and sizes. The compact fluorescent lamp (CFL) is becoming more popular. Many compact fluorescent lamps integrate the auxiliary electronics into the base of the lamp, allowing them to fit into a regular light bulb socket.\n\nIn US residences, fluorescent lamps are mostly found in kitchens, basements, or garages, but schools and businesses find the cost savings of fluorescent lamps to be significant and rarely use incandescent lights. Tax incentives and building codes result in higher use in places such as California.\n\nIn other countries, residential use of fluorescent lighting varies depending on the price of energy, financial and environmental concerns of the local population, and acceptability of the light output. In East and Southeast Asia it is very rare to see incandescent bulbs in buildings anywhere.\n\nSome countries are encouraging the phase-out of incandescent light bulbs and substitution of incandescent lamps with fluorescent lamps or other types of energy-efficient lamps.\n\nIn addition to general lighting, special fluorescent lights are often used in stage lighting for film and video production. They are cooler than traditional halogen light sources, and use high-frequency ballasts to prevent video flickering and high color-rendition index lamps to approximate daylight color temperatures.\n\nFluorescent lamps convert more of the input power to visible light than incandescent lamps, though as of 2013 LEDs are sometimes even more efficient and are more rapidly increasing in efficiency. A typical 100 watt tungsten filament incandescent lamp may convert only 5% of its power input to visible white light (400–700 nm wavelength), whereas typical fluorescent lamps convert about 22% of the power input to visible white light.\n\nThe efficacy of fluorescent tubes ranges from about 16 lumens per watt for a 4 watt tube with an ordinary ballast to over 100 lumens per watt with a modern electronic ballast, commonly averaging 50 to 67 lm/W overall. Most compact fluorescents above 13 watts with integral electronic ballasts achieve about 60 lm/W. Lamps are rated by lumens after 100 hours of operation. For a given fluorescent tube, a high-frequency electronic ballast gives about a 10% efficacy improvement over an inductive ballast. It is necessary to include the ballast loss when evaluating the efficacy of a fluorescent lamp system; this can be about 25% of the lamp power with magnetic ballasts, and around 10% with electronic ballasts.\n\nFluorescent lamp efficacy is dependent on lamp temperature at the coldest part of the lamp. In T8 lamps this is in the center of the tube. In T5 lamps this is at the end of the tube with the text stamped on it. The ideal temperature for a T8 lamp is while the T5 lamp is ideally at .\n\nTypically a fluorescent lamp will last 10 to 20 times as long as an equivalent incandescent lamp when operated several hours at a time. Under standard test conditions general lighting lamps have 9,000 hours or longer service life.\n\nThe higher initial cost of a fluorescent lamp compared with an incandescent lamp is usually more than compensated for by lower energy consumption over its life.\n\nA few manufacturers are producing T8 lamps with 90,000 hour lamp lives, rivalling the life of LED lamps.\n\nCompared with an incandescent lamp, a fluorescent tube is a more diffuse and physically larger light source. In suitably designed lamps, light can be more evenly distributed without point source of glare such as seen from an undiffused incandescent filament; the lamp is large compared to the typical distance between lamp and illuminated surfaces.\n\nFluorescent lamps give off about one-fifth the heat of equivalent incandescent lamps. This greatly reduces the size, cost, and energy consumption devoted to air conditioning for office buildings that would typically have many lights and few windows.\n\nIf the lamp is installed where it is frequently switched on and off, it will age rapidly. Under extreme conditions, its lifespan may be much shorter than a cheap incandescent lamp. Each start cycle slightly erodes the electron-emitting surface of the cathodes; when all the emission material is gone, the lamp cannot start with the available ballast voltage. Fixtures intended for flashing of lights (such as for advertising) will use a ballast that maintains cathode temperature when the arc is off, preserving the life of the lamp.\n\nThe extra energy used to start a fluorescent lamp is equivalent to a few seconds of normal operation; it is more energy-efficient to switch off lamps when not required for several minutes.\n\nIf a fluorescent lamp is broken, a very small amount of mercury can contaminate the surrounding environment. About 99% of the mercury is typically contained in the phosphor, especially on lamps that are near the end of their life. The broken glass is usually considered a greater hazard than the small amount of spilled mercury. The EPA recommends airing out the location of a fluorescent tube break and using wet paper towels to help pick up the broken glass and fine particles. Any glass and used towels should be disposed of in a sealed plastic bag. Vacuum cleaners can cause the particles to become airborne, and should not be used.\n\nFluorescent lamps with magnetic ballasts flicker at a normally unnoticeable frequency of 100 or 120 Hz and this flickering can cause problems for some individuals with light sensitivity; they are listed as problematic for some individuals with autism, epilepsy, lupus, chronic fatigue syndrome, Lyme disease, and vertigo. Newer fluorescent lights without magnetic ballasts have essentially eliminated flicker.\n\nFluorescent lamps emit a small amount of ultraviolet (UV) light. A 1993 study in the US found that ultraviolet exposure from sitting under fluorescent lights for eight hours is equivalent to one minute of sun exposure. Ultraviolet radiation from compact fluorescent lamps may exacerbate symptoms in photosensitive individuals.\n\nThe ultraviolet light from a fluorescent lamp can degrade the pigments in paintings (especially watercolor pigments) and bleach the dyes used in textiles and some printing. Valuable art work must be protected from ultraviolet light by placing additional glass or transparent acrylic sheets between the lamp and the art work.\n\nFluorescent lamps require a ballast to stabilize the current through the lamp, and to provide the initial striking voltage required to start the arc discharge. This increases the cost of fluorescent light fixtures, though often one ballast is shared between two or more lamps. Electromagnetic ballasts with a minor fault can produce an audible humming or buzzing noise. Magnetic ballasts are usually filled with a tar-like potting compound to reduce emitted noise. Hum is eliminated in lamps with a high-frequency electronic ballast. Energy lost in magnetic ballasts was around 10% of lamp input power according to GE literature from 1978. Electronic ballasts reduce this loss.\n\nSimple inductive fluorescent lamp ballasts have a power factor of less than unity. Inductive ballasts include power factor correction capacitors. Simple electronic ballasts may also have low power factor due to their rectifier input stage.\n\nFluorescent lamps are a non-linear load and generate harmonic currents in the electrical power supply. The arc within the lamp may generate radio frequency noise, which can be conducted through power wiring. Suppression of radio interference is possible. Very good suppression is possible, but adds to the cost of the fluorescent fixtures.\n\nFluorescent lamps operate best around room temperature. At much lower or higher temperatures, efficacy decreases. At below-freezing temperatures standard lamps may not start. Special lamps may be needed for reliable service outdoors in cold weather. In applications such as road and railway signalling, fluorescent lamps which do not generate as much heat as incandescent lamps may not melt snow and ice build up around the lamp, leading to reduced visibility.\n\nFluorescent tubes are long, low-luminance sources compared with high pressure arc lamps, incandescent lamps and LEDs. However, low luminous intensity of the emitting surface is useful because it reduces glare. Lamp fixture design must control light from a long tube instead of a compact globe.\n\nThe compact fluorescent lamp (CFL) replaces regular incandescent bulbs. However, some CFLs will not fit some lamps, because the harp (heavy wire shade support bracket) is shaped for the narrow neck of an incandescent lamp, while CFLs tend to have a wide housing for their electronic ballast close to the lamp's base.\n\nFluorescent lamps using a magnetic power line frequency ballast do not give out a steady light; instead, they flicker at twice the supply frequency. This results in fluctuations not only with light output but color temperature as well, which may pose problems for photography and people who are sensitive to the flicker. Even among persons not sensitive to light flicker, a stroboscopic effect can be noticed, where something spinning at just the right speed may appear stationary if illuminated solely by a single fluorescent lamp. This effect is eliminated by paired lamps operating on a lead-lag ballast. Unlike a true strobe lamp, the light level drops in appreciable time and so substantial \"blurring\" of the moving part would be evident.\n\nIn some circumstances, fluorescent lamps operated at the power supply frequency (50 or 60 Hz) can also produce flicker at the same frequency itself, which is noticeable by more people. This can happen in the last few hours of tube life when the cathode emission coating at one end has almost run out or a filament is open circuit, and that cathode starts having difficulty emitting enough electrons into the gas fill, resulting in slight rectification and hence uneven light output in positive and negative going AC cycles. Power frequency flicker can also sometimes be emitted from the very ends of the tubes, if each tube electrode produces a slightly different light output pattern on each half-cycle. Flicker at power frequency is more noticeable in the peripheral vision than it is when viewed directly, as is all flicker (since the peripheral vision is faster—has a higher critical frequency—than the central vision).\n\nNear the end of life, fluorescent lamps can start flickering at a frequency lower than the power frequency. This is due to a dynamic instability inherent in the negative resistance of the plasma source, which can be from a bad lamp, a bad ballast, or a bad starter; or occasionally from a poor connection to power.\nNew fluorescent lamps may show a twisting spiral pattern of light in a part of the lamp. This effect is due to loose cathode material and usually disappears after a few hours of operation.\n\nElectromagnetic ballasts may also cause problems for video recording as there can be a so-called \"beat effect\" between the periodic reading of a camera's sensor and the fluctuations in intensity of the fluorescent lamp.\n\nFluorescent lamps using high-frequency electronic ballasts do not produce visible light flicker, since above about 5 kHz, the excited electron state half-life is longer than a half cycle, and light production becomes continuous. Operating frequencies of electronic ballasts are selected to avoid interference with infrared remote controls. Poor quality (or failing) electronic ballasts may have insufficient reservoir capacitance or have poor regulation, thereby producing considerable 100/120 Hz modulation of the light.\n\nFluorescent light fixtures cannot be connected to dimmer switches intended for incandescent lamps. Two effects are responsible for this: the waveform of the voltage emitted by a standard phase-control dimmer interacts badly with many ballasts, and it becomes difficult to sustain an arc in the fluorescent tube at low power levels. Dimming installations require a compatible dimming ballast. These systems keep the cathodes of the fluorescent tube fully heated even as the arc current is reduced, promoting easy thermionic emission of electrons into the arc stream. CFLs are available that work in conjunction with a suitable dimmer.\n\nThe disposal of phosphor and particularly the toxic mercury in the tubes is an environmental issue. Governmental regulations in many areas require special disposal of fluorescent lamps separate from general and household wastes. For large commercial or industrial users of fluorescent lights, recycling services are available in many nations, and may be required by regulation. In some areas, recycling is also available to consumers.\n\nSystematic nomenclature identifies mass-market lamps as to general shape, power rating, length, color, and other electrical and illuminating characteristics.\n\nBlacklights are a subset of fluorescent lamps that are used to provide near ultraviolet light (at about 360 nm wavelength). They are built in the same fashion as conventional fluorescent lamps but the glass tube is coated with a phosphor that converts the short-wave UV within the tube to long-wave UV rather than to visible light. They are used to provoke fluorescence (to provide dramatic effects using blacklight paint and to detect materials such as urine and certain dyes that would be invisible in visible light) as well as to attract insects to bug zappers. So-called \"blacklite blue\" lamps are also made from more expensive deep purple glass known as Wood's glass rather than clear glass. The deep purple glass filters out most of the visible colors of light directly emitted by the mercury-vapor discharge, producing proportionally less visible light compared with UV light. This allows UV-induced fluorescence to be seen more easily (thereby allowing blacklight posters to seem much more dramatic). The blacklight lamps used in bug zappers do not require this refinement so it is usually omitted in the interest of cost; they are called simply \"blacklite\" (and not blacklite blue).\n\nThe lamps used in tanning beds contain a different phosphor blend (typically 3 to 5 or more phosphors) that emits both UVA and UVB, provoking a tanning response in most human skin. Typically, the output is rated as 3–10% UVB (5% most typical) with the remaining UV as UVA. These are mainly F71, F72, or F73 HO (100 W) lamps, although 160 W VHO are somewhat common. One common phosphor used in these lamps is lead-activated barium disilicate, but a europium-activated strontium fluoroborate is also used. Early lamps used thallium as an activator, but emissions of thallium during manufacture were toxic.\n\nThe lamps used in phototherapy contain a phosphor that emits only UVB ultraviolet light. There are two types: broadband UVB that gives 290–320 nanometer with peak wavelength of 306 nm, and narrowband UVB that gives 311–313 nanometer. Because of the longer wavelength, the narrowband UVB bulbs do not cause erytherma in the skin like the broadband. They requires a 10-20 times higher dose to the skin and they require more bulbs and longer exposure time. The narrowband is good for psoriasis, eczema (atopic dermatitis), vitiligo, lichen planus, and some other skin diseases. The broadband is better for increasing Vitamin D3 in the body.\nPhilips narrowband lamps are PL-S9W/01, PL-L36W/01 and other powers where the \"/01\" means narrowband UVB.\n\nGrow lamps contain phosphor blends that encourage photosynthesis, growth, or flowering in plants, algae, photosynthetic bacteria, and other light-dependent organisms. These often emit light primarily in the red and blue color range, which is absorbed by chlorophyll and used for photosynthesis in plants.\n\nLamps can be made with a lithium metaluminate phosphor activated with iron. This phosphor has peak emissions between 675 and 875 nanometers, with lesser emissions in the deep red part of the visible spectrum.\n\nDeep blue light generated from a europium-activated phosphor is used in the light therapy treatment of jaundice; light of this color penetrates skin and helps in the breakup of excess bilirubin.\n\nSimilar structure but not fluorescent, germicidal lamps depend on the property that spectrum of 254 nm kills most germs. Germicidal lamps contain no phosphor at all (making them mercury vapor gas discharge lamps rather than fluorescent) and their tubes are made of fused quartz that is transparent to the UV light emitted by the mercury discharge. The 254 nm UV emitted by these tubes will kill germs and ionize oxygen to ozone. In addition it can cause eye and skin damage and should not be used or observed without eye and skin protection. Besides their uses to kill germs and create ozone, they are sometimes used by geologists to identify certain species of minerals by the color of their fluorescence. When used in this fashion, they are fitted with filters in the same way as blacklight-blue lamps are; the filter passes the short-wave UV and blocks the visible light produced by the mercury discharge. They are also used in some EPROM erasers. Germicidal lamps have designations beginning with G (meaning \"germicidal\"), rather than F, for example G30T8 for a 30-watt, diameter, long germicidal lamp (as opposed to an F30T8, which would be the fluorescent lamp of the same size and rating).\n\nElectrodeless induction lamps are fluorescent lamps without internal electrodes. They have been commercially available since 1990. A current is induced into the gas column using electromagnetic induction. Because the electrodes are usually the life-limiting element of fluorescent lamps, such electrodeless lamps can have a very long service life, although they also have a higher purchase price.\n\nCold-cathode fluorescent lamps were used as backlighting for LCDs in computer monitors and televisions before the use of LED-backlit LCDs. They are also popular with computer case modders in recent years.\n\nFluorescent lamps can be illuminated by means other than a proper electrical connection. These other methods, however, result in very dim or very short-lived illumination, and so are seen mostly in science demonstrations. Static electricity or a Van de Graaff generator will cause a lamp to flash momentarily as it discharges a high voltage capacitance. A Tesla coil will pass high-frequency current through the tube, and since it has a high voltage as well, the gases within the tube will ionize and emit light. This also works with plasma globes. Capacitive coupling with high-voltage power lines can light a lamp continuously at low intensity, depending on the intensity of the electrostatic field, as shown in the image on the right.\n\n\n"}
{"id": "9324487", "url": "https://en.wikipedia.org/wiki?curid=9324487", "title": "GRE (company)", "text": "GRE (company)\n\nGRE (株式会社　ゼネラル　リサ－チ　オブ　エレクトロニックス \"General Research of Electronics, Inc.\") was a Japan-based multinational manufacturer of electronics equipment, primarily in the fields of radio and other telecommunications. Their products included transceivers, radio scanners, antennas, GPS devices, and satellite equipment. They also produced OEM equipment for other companies, including Radio Shack, Uniden and Commtel.\n\nGRE was established in 1961, and its headquarters was located in Tokyo. GRE had a manufacturing facility in Chiba Prefecture which closed in October 2012. In late 1977, GRE established \"GRE America, Inc.\", its first overseas operation, with a head office in California. The company established its second overseas corporation, \"GRE (Hong Kong), Ltd.\", in 1986.\n\nIn October, 2012, their China factory was shuttered and they ceased all production. While there have been some reports that GRE intends to resume business, without hardware engineers, software engineers, or major customers, it is unlikely that they will ever be able to resume production. GRE America continues to service GRECOM products and to sell and service Alinco radio products for the North American market.\n\nIn May, 2013, GRE America Inc (USA Branch) moved from its Belmont, CA location after losing Alinco’s Distribution rights in North American market. GRE America relocated in the City of San Leandro, CA.\n\nIn January, 2014, Whistler Group took over production of GRE's scanner line. Due to several of GRE's engineers working with Whistler, the products produced by the overtaking company are very similar to that of GRE's at the time of operation cessation. Whistler later began selling radio scanners formerly produced for Radio Shack with separate product numbers but identical hardware.\n\nIn February, 2014, GRE (Japan) head office closed its Tokyo office and relocated to its Chiba location where they had once produced its product line when it first established back in 1961.\n\nIn September 2014 'General Research of Electronics' Japan (GRE) decided cease its USA business operations and closed its California office since there is no active business due to lack of financial resource and development capabilities at GRE Japan.\n\nCEO/President: Kazunori Imazeki (2006 - Current)\n\n"}
{"id": "3833695", "url": "https://en.wikipedia.org/wiki?curid=3833695", "title": "Human computer", "text": "Human computer\n\nThe term \"computer\", in use from the early 17th century (the first known written reference dates from 1613), meant \"one who computes\": a person performing mathematical calculations, before electronic computers became commercially available.\n\"The human computer is supposed to be following fixed rules; he has no authority to deviate from them in any detail.\"\nTeams of people were frequently used to undertake long and often tedious calculations; the work was divided so that this could be done in parallel. Frequently, the same calculations were performed independently by separate teams to check the correctness of the results.\n\nSince the end of the 20th century, the term \"human computer\" has also been applied to individuals with prodigious powers of mental arithmetic, also known as mental calculators.\n\nThe approach was taken for astronomical and other complex calculations. Perhaps the first example of organized human computing was by the Frenchman Alexis Claude Clairaut (1713–1765), when he divided the computation to determine the time of the return of Halley's Comet with two colleagues, Joseph Lalande and Nicole-Reine Lepaute. Human computers were also involved in plotting the future movements of astronomical objects to create celestial tables for almanacs in the late 1760s. The computers working on the \"Nautical Almanac\" for the British Admiralty included William Wales, Israel Lyons and Richard Dunthorne. The project was overseen by Nevil Maskelyne. Maskelyne would borrow tables from other sources as often as he could in order to reduce the number of calculations his team of computers had to make. For some men such as Johannes Kepler, assisting a scientist in computation was a temporary position until they moved on to greater advancements. Women were generally excluded, with some exceptions such as Mary Edwards who worked from the 1780s to 1815 as one of thirty-five computers for the British \"Nautical Almanac\" used for navigation at sea. The United States also worked on their own version of a nautical almanac in the 1840s, with Maria Mitchell being one of the best-known computers on the staff.\n\nOther innovations in human computing included the work done by a group of boys who worked in the Octagon Room of the Royal Greenwich Observatory for Astronomer Royal, George Airy. Airy's computers, hired after 1835, could be as young as fifteen and they were working on a backlog of astronomical data. The way that Airy organized the Octagon Room with a manager, pre-printed computing forms and standardized methods of calculating and checking results (similar to the way the \"Nautical Almanac\" computers operated) would remain a standard for computing operations for the next 80 years.\n\nIn the 1870s, the United States Signal Corps created a new way of organizing human computing to track weather patterns. This built on previous work from the US Navy and the Smithsonian meteorological project. The Signal Corps used a small computing staff that processed data that had to be collected quickly and finished in \"intensive two-hour shifts\". Each individual human computer was responsible for only part of the data.\n\nWomen were increasingly involved in computing after 1865. Private companies hired them for computing and to manage office staffs. \n\nIn the late nineteenth century Edward Charles Pickering organized the \"Harvard Computers\". The first woman to approach them, Anna Winlock, asked Harvard Observatory for a computing job in 1875. By 1880, all of the computers working at the Harvard Observatory were women. The standard computer pay started at twenty-five cents an hour. There would be such a huge demand to work there, that some women offered to work for the Harvard Computers for free. Many of the women astronomers from this era were computers with possibly the best-known being Florence Cushman, Henrietta Swan Leavitt, and Annie Jump Cannon, who worked with Pickering from 1888, 1893, and 1896 respectively. Cannon could classify stars at a rate of 3 per minute. Mina Fleming, one of the Harvard Computers, published \"The Draper Catalogue of Stellar Spectra\" in 1890. The catalogue organized stars by spectral lines. The catalogue continued to be expanded by the Harvard Computers and added new stars in successive volumes. \n\nIn 1893, Frances Galton created the Committee for Conducting Statistical Inquiries into the Measurable Characteristics of Plants and Animals which reported to the Royal Society. The committee used advanced techniques for scientific research and supported the work of several scientists. W.F. Raphael Weldon, the first scientist supported by the committee worked with his wife, Florence Tebb Weldon, who was his human computer. Weldon used logarithms and mathematical tables created by Crelle and had no calculating machine. Karl Pearson, who had a lab at the University of London, felt that the work Weldon did was \"hampered by the committee\". However, Pearson did create a mathematical formula that the committee was able to use which allowed for data correlation. Pearson brought his correlation formula to his own Biometrics Laboratory. Pearson had volunteer and salaried computers who were both men and women. Alice Lee was one of his salaried computers who worked with histograms and the \"chi-squared\" statistics. Pearson also worked with Beatrice and Frances Cave-Brown-Cave. Pearson's lab, by 1906, had mastered the art of mathematical table making.\n\nHuman computers were used to compile 18th and 19th century Western European mathematical tables, for example those for trigonometry and logarithms. Although these tables were most often known by the names of the principal mathematician involved in the project, such tables were often in fact the work of an army of unknown and unsung computers. Ever more accurate tables to a high degree of precision were needed for navigation and engineering. Approaches differed, but one was to break up the project into a form of long distance work from home piece work. The computers, often educated middle class women who society deemed it unseemly to engage in the professions or go out to work, would receive and send back packets of calculations by post. The Royal Astronomical Society eventually gave space to a new committee, the Mathematical Tables Committee, which was the only professional organization for human computers in 1925.\n\nHuman computers were used to predict the effects of building the Afsluitdijk in the Zuiderzee. The computer simulation was set up by Hendrik Lorentz.\n\nA visionary application to meteorology can be found in the scientific work of Lewis Fry Richardson who, in 1922, estimated that 64,000 humans could forecast the weather for the whole globe by solving the attending differential equations numerically. Around 1910 he had already used human computers to calculate the stresses inside a masonry dam.\nHuman computers, both men and women, were involved in calculating ballistics tables during World War I. In between the two world wars, computers were used in the Department of Agriculture in the United States and also at Iowa State College. The human computers in these places also used calculating machines and early electrical computers to aid in their work. In the 1930s, The Columbia University Statistical Bureau was created by Benjamin Wood. Organized computing was also established at Indiana University, the Cowles Commission and the National Research Council.\n\nHuman computers played integral roles in the World War II war effort in the United States, and because of the depletion of the male labor force due to the draft, many computers during World War II were women, frequently with degrees in mathematics. In the 1940s, women were hired to example nuclear and particle tracks left on photographic emulsions. In the Manhattan Project, human computers, working with a variety of mechanical aids, assisted numerical studies of the complex formulas related to nuclear fission.\n\nFollowing World War II, the NACA used human computers in flight research to transcribe raw data from celluloid film and oscillograph paper and then, using slide rules and electric calculators, reduced the data to standard engineering units. Margot Lee Shetterly's biographical book, \"Hidden Figures\", documents the contributions of African American women who served as human computers at NASA. NACA had begun hiring black women as computers as early as 1940. One such computer was Dorothy Vaughan who began her work in 1943 with the Langley Research Center as a special hire to aid the WWII effort.\n\nAs electrical computers became more available, human computers, especially women, were drafted as some of the first computer programmers. Because the six people responsible for setting up problems on the ENIAC (the premiere general-purpose electronic digital computer built at the University of Pennsylvania during World War II) were drafted from a corps of human computers, the world's first professional computer programmers were women including Kay McNulty, Betty Snyder, Marlyn Wescoff, Ruth Lichterman, Betty Jean Jennings, and Fran Bilas.\n\nThe term \"human computer\" has been recently used by a group of researchers who refer to their work as \"human computation\". In this usage, \"human computer\" refers to activities of humans in the context of human-based computation (HBC). \n\nThis usage is questionable for the following reason. HBC is a computational technique where a machine outsources certain (not necessarily algorithmic) tasks to humans. In fact, most of the time humans in the context of HBC are not provided with a sequence of exact steps that needs to be executed to yield an answer. HBC is agnostic about how humans solve the problem. This is why the term outsourcing is used in the definition. The use of humans as \"human computers\" in the context of HBC is very rare.\n\n\n\n"}
{"id": "5170132", "url": "https://en.wikipedia.org/wiki?curid=5170132", "title": "Inducement prize contest", "text": "Inducement prize contest\n\nAn inducement prize contest (IPC) is a competition that awards a cash prize for the accomplishment of a feat, usually of engineering. IPCs are typically designed to extend the limits of human ability. Some of the most famous IPCs include the Longitude prize (1714–1765), the Orteig Prize (1919–1927) and the prizes from the X Prize Foundation.\n\nIPCs are distinct from recognition prizes, such as the Nobel Prize, in that IPCs have prospectively defined criteria for what feat is to be achieved for winning the prize, while recognition prizes may be based on the beneficial effects of the feat.\n\nResearch has shown that IPCs can be extremely effective in pushing the advancement of technology.\n\nThroughout history, there have been instances where IPCs were successfully utilized to push the boundaries of what would have been considered state-of-the-art at the time.\n\nThe Longitude Prize was a reward offered by the British government for a simple and practical method for the precise determination of a ship's longitude. The prize, established through an Act of Parliament (the Longitude Act) in 1714, was administered by the Board of Longitude.\nAnother example happened during the first years of the Napoleonic Wars. The French government offered a hefty cash award of 12,000 francs to any inventor who could devise a cheap and effective method of preserving large amounts of food. The larger armies of the period required increased, regular supplies of quality food. Limited food availability was among the factors limiting military campaigns to the summer and autumn months. In 1809, a French confectioner and brewer, Nicolas Appert, observed that food cooked inside a jar did not spoil unless the seals leaked, and developed a method of sealing food in glass jars. The reason for lack of spoilage was unknown at the time, since it would be another 50 years before Louis Pasteur demonstrated the role of microbes in food spoilage.\nYet another example is the Orteig Prize which was a $25,000 reward offered on May 19, 1919, by New York hotel owner Raymond Orteig to the first allied aviator(s) to fly non-stop from New York City to Paris or vice versa. On offer for five years, it attracted no competitors. Orteig renewed the offer for another five years in 1924 when the state of aviation technology had advanced to the point that numerous competitors vied for the prize. Several famous aviators made unsuccessful attempts at the New York–Paris flight before relatively unknown American Charles Lindbergh won the prize in 1927 in his aircraft \"Spirit of St. Louis\".\nA leading organization in development and managing IPCs is the X PRIZE Foundation. Its mission is to bring about \"radical breakthroughs for the benefit of humanity\" through incentivized competition. It fosters high-profile competitions that motivate individuals, companies and organizations across all disciplines to develop innovative ideas and technologies that help solve the grand challenges that restrict humanity's progress. The most high-profile X PRIZE to date was the Ansari X PRIZE relating to spacecraft development awarded in 2004. This prize was intended to inspire research and development into technology for space exploration. Indeed, the X Prize has inspired other \"letter\" named inducement prize competitions such as the H-Prize, N-Prize, and so forth. In 2006, there was much interest in prizes for automotive achievement, such as the 250 mpg car.\n\nIn Europe there has been a re-emergence of challenge prizes that following in the tradition of the Longitude Prize for solutions which impact on social problems. The Centre for Challenge Prizes based in London is an example of this running prizes for innovations that for example reduce social isolation or make renewable energy generators accessible to off the grid refugees and returnees.\n\nIn some literature on the subject, it has been stated that well-designed IPCs can garner economic activity on the order of 10 to 20 times the amount of the prize face value.\n\n\n\n"}
{"id": "1727376", "url": "https://en.wikipedia.org/wiki?curid=1727376", "title": "Intake", "text": "Intake\n\nAn intake or (for aircraft) inlet is an opening on a car or aircraft body capturing air for operation of an internal combustion engine.\n\nBecause the modern ground vehicle internal combustion engine is in essence a powerful air pump, like the exhaust system on an engine, the intake must be carefully engineered and tuned to provide the greatest efficiency and power. An ideal intake system should increase the velocity of the air until it travels into the combustion chamber, while minimizing turbulence and restriction of flow.\n\nHowever, in aircraft, particularly supersonic aircraft, the purpose of the intake is to slow and increase the pressure of the air.\n\nEarly automobile intake systems were simple air inlets connected directly to carburetors. The first air filter was implemented on the 1915 Packard Twin Six.\n\nThe modern automobile air intake system has three main parts, an air filter, mass flow sensor, and throttle body. Some modern intake systems can be highly complex, and often include specially-designed intake manifolds to optimally distribute air and air/fuel mixture to each cylinder. Many cars today now include a silencer to minimize the noise entering the cabin. Silencers impede air flow and create turbulence which reduce total power, so performance enthusiasts often remove them.\n\nAll the above is usually accomplished by flow testing on a flow bench in the port design stage. Cars with turbochargers or superchargers which provide pressurized air to the engine usually have highly refined intake systems to improve performance dramatically.\n\nProduction cars have specific-length air intakes to cause the air to vibrate and buffet at a specific frequency to assist air flow into the combustion chamber. Aftermarket companies for cars have introduced larger throttle bodies and air filters to decrease restriction of flow at the cost of changing the harmonics of the air intake for a small net increase in power or torque.\n\nWith the development of jet engines and the subsequent ability of aircraft to travel at supersonic speeds, it was necessary to design inlets to provide the flow required by the engine over a wide operating envelope and to provide air with a high pressure recovery and low distortion. These designs became more complex as aircraft speeds increased to Mach 3.0 and Mach 3.2, design points for the XB-70 and SR-71 respectively. The inlet is part of the fuselage or part of the nacelle.\n\n"}
{"id": "52646767", "url": "https://en.wikipedia.org/wiki?curid=52646767", "title": "International Institute of Management and Technical Studies", "text": "International Institute of Management and Technical Studies\n\nInternational Institute of Management and Technical Studies (IIMT STUDIES) is an Indian-based educational outfit known for offering e-learning and distance education to working professionals.\n\nInternational Institute of Management and Technical Studies (IIMT Studies) was founded in 2009 by “Bharti Lokseva Charitable Trust” with its head office located in Ahmedabad, India. The institute is registered under the B.P.T. act of the Government of India.\n\nIIMT Studies is affiliated to Bharati Vidyapeeth Institute Of Management and Research, Navi Mumbai, India, which is approved by All India Council for Technical Education (AICTE), New Delhi. It is also affiliated to the Institution of Engineers, Gujarat State Certer and European Association for Distance Learning. It has branches in Ahmedabad and Surat, Gujarat State and international branch in Dubai, United Arab Emirates.\n\nIIMT Studies is a partner institute of the Directorate of Employment and Training for Conducting Virtual Classes and Gujarat Knowledge Society, Department of Technical Education, Government of India. The institute offers e-learning and part time certificate courses to working professionals who do not have much time to spend for studies. \n\n\n"}
{"id": "301398", "url": "https://en.wikipedia.org/wiki?curid=301398", "title": "Iolair", "text": "Iolair\n\nIolair (Gaelic for eagle) is a specialised semi-submersible offshore platform designed for BP to support and service oil platforms in the North Sea and served as an emergency support vessel (ESV) in the Forties Oil Field. Since 2000 it has been working in the Cantarell Field, Mexico as an offshore construction and maintenance service vessel operated by Cotemar S.A de C.V..\n\n\"Iolair\" is a self-propelled, twin hull, vessel and operates as a dynamically positioned (DP) construction support vessel. The vessel can operate up to a water depth of , is long and wide, and has 350 beds with single and double occupancy.\n\nThis unique vessel did not start as an ESV, but rather as the concept of a maintenance and support vessel (MSV). It was proposed for the Forties oil field, jointly owned by British National Oil Corporation and operated by BP Petroleum Development Company Ltd in the North Sea. A particular feature of the design by the Naval Architects was that there was no cross-bracing between the pontoons. Instead, the platform was given extra strength by a box-girder construction and diagonal bracing was arranged from the centre of the platform to the pontoons. This arrangement remained virtually unchanged to the build completion and offered exceptional speed when the vessel was de-ballasted on the surface. The intention was to achieve a rapid response to emergencies, wherever they might be experienced in the North Sea.\n\nAs an MSV, the vessel was always conceived to provide accommodation for about 220 persons, saturation diving facilities, a large workshop, craneage, and helicopter landing area with hangar and re-fueling. All were still featured in the eventual design but had been enhanced with other features and sophistication much of which was to support the emergency role. ESV incorporated novelty and ideas that were years ahead of their time. Indeed, part of the brief was that she should still be modern ten years after entering service.\n\nThe saturation diving system was equipped with an advanced launch and recovery system.\n\nShe was built by Scott Lithgow in Port Glasgow, and launched on 6 April 1981. In her early years, she was based in the BP Forties Oil Field.\n\nIn 1995, she was sold to U.S. drilling company Reading & Bates. She was to be converted to a workover/well intervention vessel and was stationed West of Shetland. The modifications included removal of some of the top structures, removal of the fire-fighting systems, closing of the dive tube and wave surge tank. However the intended conversion was never carried out and she was heavily involved in the installation of subsea production equipment using Remote Operated Vehicles. She was also heavily involved in the commissioning of the Foinaven and Schiehallion floating production vessels.\n\nIn 2000 she left the UK oilfields and went to the Bay of Campeche, Mexico, working in the Cantarell Field. There she carries out construction and platform support work. She was sold in 2001 by Transocean, who had taken over Reading and Bates, then sold to Exeter Marine Ltd. and since 2017 is owned by Iolair Offshore Pte Ltd. and registered in the Marshall Islands, a long way from her original registered port of Dundee in Scotland.\n\n\n\"Iolair\" is assured of its place in history by being the subject of a 28p commemorative stamp issued by Post Office Ltd. on 25 May 1983. This was one of a series of three stamps celebrating British Engineering Achievements.\n"}
{"id": "15745", "url": "https://en.wikipedia.org/wiki?curid=15745", "title": "Johannes Gutenberg", "text": "Johannes Gutenberg\n\nJohannes Gensfleisch zur Laden zum Gutenberg (; – February 3, 1468) was a German blacksmith, goldsmith, inventor, printer, and publisher who introduced printing to Europe with the printing press. His introduction of mechanical movable type printing to Europe started the Printing Revolution and is regarded as a milestone of the second millennium, ushering in the modern period of human history. It played a key role in the development of the Renaissance, Reformation, the Age of Enlightenment, and the scientific revolution and laid the material basis for the modern knowledge-based economy and the spread of learning to the masses.\n\nGutenberg in 1439 was the first European to use movable type. Among his many contributions to printing are: the invention of a process for mass-producing movable type; the use of oil-based ink for printing books; adjustable molds; mechanical movable type; and the use of a wooden printing press similar to the agricultural screw presses of the period. His truly epochal invention was the combination of these elements into a practical system that allowed the mass production of printed books and was economically viable for printers and readers alike. Gutenberg's method for making type is traditionally considered to have included a type metal alloy and a hand mould for casting type. The alloy was a mixture of lead, tin, and antimony that melted at a relatively low temperature for faster and more economical casting, cast well, and created a durable type.\n\nIn Renaissance Europe, the arrival of mechanical movable type printing introduced the era of mass communication which permanently altered the structure of society. The relatively unrestricted circulation of information—including revolutionary ideas—transcended borders, captured the masses in the Reformation and threatened the power of political and religious authorities; the sharp increase in literacy broke the monopoly of the literate elite on education and learning and bolstered the emerging middle class. Across Europe, the increasing cultural self-awareness of its people led to the rise of proto-nationalism, accelerated by the flowering of the European vernacular languages to the detriment of Latin's status as \"lingua franca\". In the 19th century, the replacement of the hand-operated Gutenberg-style press by steam-powered rotary presses allowed printing on an industrial scale, while Western-style printing was adopted all over the world, becoming practically the sole medium for modern bulk printing.\n\nThe use of movable type was a marked improvement on the handwritten manuscript, which was the existing method of book production in Europe, and upon woodblock printing, and revolutionized European book-making. Gutenberg's printing technology spread rapidly throughout Europe and later the world.\n\nHis major work, the Gutenberg Bible (also known as the 42-line Bible), has been acclaimed for its high aesthetic and technical quality.\n\nGutenberg was born in the German city of Mainz, the youngest son of the patrician merchant Friele Gensfleisch zur Laden, and his second wife, Else Wyrich, who was the daughter of a shopkeeper. It is assumed that he was baptized in the area close to his birthplace of St. Christoph. According to some accounts, Friele was a goldsmith for the bishop at Mainz, but most likely, he was involved in the cloth trade. Gutenberg's year of birth is not precisely known, but it was sometime between the years of 1394 and 1404. In the 1890s the city of Mainz declared his official and symbolic date of birth to be June 24, 1400.\n\nJohn Lienhard, technology historian, says \"Most of Gutenberg's early life is a mystery. His father worked with the ecclesiastic mint. Gutenberg grew up knowing the trade of goldsmithing.\" This is supported by historian Heinrich Wallau, who adds, \"In the 14th and 15th centuries his [ancestors] claimed a hereditary position as ... retainers of the household of the master of the archiepiscopal mint. In this capacity they doubtless acquired considerable knowledge and technical skill in metal working. They supplied the mint with the metal to be coined, changed the various species of coins, and had a seat at the assizes in forgery cases.\"\n\nWallau adds, \"His surname was derived from the house inhabited by his father and his paternal ancestors 'zu Laden, zu Gutenberg'. The house of Gänsfleisch was one of the patrician families of the town, tracing its lineage back to the thirteenth century.\" Patricians (the wealthy and political elite) in Mainz were often named after houses they owned. Around 1427, the name \"zu Gutenberg\", after the family house in Mainz, is documented to have been used for the first time.\n\nIn 1411, there was an uprising in Mainz against the patricians, and more than a hundred families were forced to leave. As a result, the Gutenbergs are thought to have moved to Eltville am Rhein (Alta Villa), where his mother had an inherited estate. According to historian Heinrich Wallau, \"All that is known of his youth is that he was not in Mainz in 1430. It is presumed that he migrated for political reasons to Strasbourg, where the family probably had connections.\" He is assumed to have studied at the University of Erfurt, where there is a record of the enrolment of a student called Johannes de Altavilla in 1418—Altavilla is the Latin form of Eltville am Rhein.\n\nNothing is now known of Gutenberg's life for the next fifteen years, but in March 1434, a letter by him indicates that he was living in Strasbourg, where he had some relatives on his mother's side. He also appears to have been a goldsmith member enrolled in the Strasbourg militia. In 1437, there is evidence that he was instructing a wealthy tradesman on polishing gems, but where he had acquired this knowledge is unknown. In 1436/37 his name also comes up in court in connection with a broken promise of marriage to a woman from Strasbourg, Ennelin. Whether the marriage actually took place is not recorded. Following his father's death in 1419, he is mentioned in the inheritance proceedings.\n\nAround 1439, Gutenberg was involved in a financial misadventure making polished metal mirrors (which were believed to capture holy light from religious relics) for sale to pilgrims to Aachen: in 1439 the city was planning to exhibit its collection of relics from Emperor Charlemagne but the event was delayed by one year due to a severe flood and the capital already spent could not be repaid. When the question of satisfying the investors came up, Gutenberg is said to have promised to share a \"secret\". It has been widely speculated that this secret may have been the idea of printing with movable type. Also around 1439–40, the Dutch Laurens Janszoon Coster came up with the idea of printing. Legend has it that the idea came to him \"like a ray of light\".\n\nUntil at least 1444 Gutenberg lived in Strasbourg, most likely in the St. Arbogast parish. It was in Strasbourg in 1440 that he is said to have perfected and unveiled the secret of printing based on his research, mysteriously entitled \"Aventur und Kunst\" (enterprise and art). It is not clear what work he was engaged in, or whether some early trials with printing from movable type may have been conducted there. After this, there is a gap of four years in the record. In 1448, he was back in Mainz, where he took out a loan from his brother-in-law Arnold Gelthus, quite possibly for a printing press or related paraphernalia. By this date, Gutenberg may have been familiar with intaglio printing; it is claimed that he had worked on copper engravings with an artist known as the Master of Playing Cards.\n\nBy 1450, the press was in operation, and a German poem had been printed, possibly the first item to be printed there. Gutenberg was able to convince the wealthy moneylender Johann Fust for a loan of 800 guilders. Peter Schöffer, who became Fust's son-in-law, also joined the enterprise. Schöffer had worked as a scribe in Paris and is believed to have designed some of the first typefaces.\n\nGutenberg's workshop was set up at Hof Humbrecht, a property belonging to a distant relative. It is not clear when Gutenberg conceived the Bible project, but for this he borrowed another 800 guilders from Fust, and work commenced in 1452. At the same time, the press was also printing other, more lucrative texts (possibly Latin grammars). There is also some speculation that there may have been two presses, one for the pedestrian texts, and one for the Bible. One of the profit-making enterprises of the new press was the printing of thousands of indulgences for the church, documented from 1454 to 1455.\n\nIn 1455 Gutenberg completed his \"42-line Bible\", known as the Gutenberg Bible. About 180 copies were printed, most on paper and some on vellum.\n\nSome time in 1456, there was a dispute between Gutenberg and Fust, and Fust demanded his money back, accusing Gutenberg of misusing the funds. Meanwhile the expenses of the Bible project had proliferated, and Gutenberg's debt now exceeded 20,000 guilders. Fust sued at the archbishop's court. A November 1455 legal document records that there was a partnership for a \"project of the books,\" the funds for which Gutenberg had used for other purposes, according to Fust. The court decided in favor of Fust, giving him control over the Bible printing workshop and half of all printed Bibles.\n\nThus Gutenberg was effectively bankrupt, but it appears he retained (or re-started) a small printing shop, and participated in the printing of a Bible in the town of Bamberg around 1459, for which he seems at least to have supplied the type. But since his printed books never carry his name or a date, it is difficult to be certain, and there is consequently a considerable scholarly debate on this subject. It is also possible that the large \"Catholicon\" dictionary, 300 copies of 754 pages, printed in Mainz in 1460, was executed in his workshop.\n\nMeanwhile, the Fust–Schöffer shop was the first in Europe to bring out a book with the printer's name and date, the \"Mainz Psalter\" of August 1457, and while proudly proclaiming the mechanical process by which it had been produced, it made no mention of Gutenberg.\n\nIn 1462, during the devastating Mainz Diocesan Feud, Mainz was sacked by archbishop Adolph von Nassau, and Gutenberg was exiled. An old man by now, he moved to Eltville where he may have initiated and supervised a new printing press belonging to the brothers Bechtermünze.\n\nIn January 1465, Gutenberg's achievements were recognized and he was given the title \"Hofmann\" (gentleman of the court) by von Nassau. This honor included a stipend, an annual court outfit, as well as 2,180 litres of grain and 2,000 litres of wine tax-free. It is believed he may have moved back to Mainz around this time, but this is not certain.\n\nGutenberg died in 1468 and was buried in the Franciscan church at Mainz, his contributions largely unknown. This church and the cemetery were later destroyed, and Gutenberg's grave is now lost.\n\nIn 1504, he was mentioned as the inventor of typography in a book by Professor Ivo Wittig. It was not until 1567 that the first portrait of Gutenberg, almost certainly an imaginary reconstruction, appeared in Heinrich Pantaleon's biography of famous Germans.\n\nBetween 1450 and 1455, Gutenberg printed several texts, some of which remain unidentified; his texts did not bear the printer's name or date, so attribution is possible only from typographical evidence and external references. Certainly several church documents including a papal letter and two indulgences were printed, one of which was issued in Mainz. In view of the value of printing in quantity, seven editions in two styles were ordered, resulting in several thousand copies being printed. Some printed editions of \"Ars Minor\", a schoolbook on Latin grammar by Aelius Donatus may have been printed by Gutenberg; these have been dated either 1451–52 or 1455.\n\nIn 1455, Gutenberg completed copies of a beautifully executed folio Bible (\"Biblia Sacra\"), with 42 lines on each page. Copies sold for 30 florins each, which was roughly three years' wages for an average clerk. Nonetheless, it was significantly cheaper than a manuscript Bible that could take a single scribe over a year to prepare. After printing, some copies were rubricated or hand-illuminated in the same elegant way as manuscript Bibles from the same period.\n\n48 substantially complete copies are known to survive, including two at the British Library that can be viewed and compared online. The text lacks modern features such as pagination, indentations, and paragraph breaks.\n\nAn undated 36-line edition of the Bible was printed, probably in Bamberg in 1458–60, possibly by Gutenberg. A large part of it was shown to have been set from a copy of Gutenberg's Bible, thus disproving earlier speculation that it was the earlier of the two.\n\nGutenberg's early printing process, and what texts he printed with movable type, are not known in great detail. His later Bibles were printed in such a way as to have required large quantities of type, some estimates suggesting as many as 100,000 individual sorts. Setting each page would take, perhaps, half a day, and considering all the work in loading the press, inking the type, pulling the impressions, hanging up the sheets, distributing the type, etc., it is thought that the Gutenberg–Fust shop might have employed as many as 25 craftsmen.\n\nGutenberg's technique of making movable type remains unclear. In the following decades, punches and copper matrices became standardized in the rapidly disseminating printing presses across Europe. Whether Gutenberg used this sophisticated technique or a somewhat primitive version has been the subject of considerable debate.\n\nIn the standard process of making type, a hard metal punch (made by punchcutting, with the letter carved back to front) is hammered into a softer copper bar, creating a \"matrix\". This is then placed into a hand-held mould and a piece of type, or \"sort\", is cast by filling the mould with molten type-metal; this cools almost at once, and the resulting piece of type can be removed from the mould. The matrix can be reused to create hundreds, or thousands, of identical sorts so that the same character appearing anywhere within the book will appear very uniform, giving rise, over time, to the development of distinct styles of typefaces or fonts. After casting, the sorts are arranged into type cases, and used to make up pages which are inked and printed, a procedure which can be repeated hundreds, or thousands, of times. The sorts can be reused in any combination, earning the process the name of \"movable type\". (For details, see Typography.)\n\nThe invention of the making of types with punch, matrix and mold has been widely attributed to Gutenberg. However, recent evidence suggests that Gutenberg's process was somewhat different. If he used the punch and matrix approach, all his letters should have been nearly identical, with some variation due to miscasting and inking. However, the type used in Gutenberg's earliest work shows other variations.\n\nIn 2001, the physicist Blaise Agüera y Arcas and Princeton librarian Paul Needham, used digital scans of a Papal bull in the Scheide Library, Princeton, to carefully compare the same letters (types) appearing in different parts of the printed text. The irregularities in Gutenberg's type, particularly in simple characters such as the hyphen, suggested that the variations could not have come either from ink smear or from wear and damage on the pieces of metal on the types themselves. Although some identical types are clearly used on other pages, other variations, subjected to detailed image analysis, suggested that they could not have been produced from the same matrix. Transmitted light pictures of the page also appeared to reveal substructures in the type that could not arise from traditional punchcutting techniques. They hypothesized that the method involved impressing simple shapes to create alphabets in \"cuneiform\" style in a matrix made of some soft material, perhaps sand. Casting the type would destroy the mould, and the matrix would need to be recreated to make each additional sort. This could explain the variations in the type, as well as the substructures observed in the printed images.\n\nThus, they speculated that \"the decisive factor for the birth of typography\", the use of reusable moulds for casting type, was a more progressive process than was previously thought. They suggested that the additional step of using the punch to create a mould that could be reused many times was not taken until twenty years later, in the 1470s. Others have not accepted some or all of their suggestions, and have interpreted the evidence in other ways, and the truth of the matter remains uncertain.\n\nA 1568 history by Hadrianus Junius of Holland claims that the basic idea of the movable type came to Gutenberg from Laurens Janszoon Coster via Fust, who was apprenticed to Coster in the 1430s and may have brought some of his equipment from Haarlem to Mainz. While Coster appears to have experimented with moulds and castable metal type, there is no evidence that he had actually printed anything with this technology. He was an inventor and a goldsmith. However, there is one indirect supporter of the claim that Coster might be the inventor. The author of the Cologne Chronicle of 1499 quotes Ulrich Zell, the first printer of Cologne, that printing was performed in Mainz in 1450, but that some type of printing of lower quality had previously occurred in the Netherlands. However, the chronicle does not mention the name of Coster, while it actually credits Gutenberg as the \"first inventor of printing\" in the very same passage (fol. 312). The first securely dated book by Dutch printers is from 1471, and the Coster connection is today regarded as a mere legend.\n\nThe 19th-century printer and typefounder Fournier Le Jeune suggested that Gutenberg was not using type cast with a reusable matrix, but wooden types that were carved individually. A similar suggestion was made by Nash in 2004. This remains possible, albeit entirely unproven.\n\nIt has also been questioned whether Gutenberg used movable types at all. In 2004, Italian professor Bruno Fabbiani claimed that examination of the 42-line Bible revealed an overlapping of letters, suggesting that Gutenberg did not in fact use movable type (individual cast characters) but rather used whole plates made from a system somewhat like a modern typewriter, whereby the letters were stamped successively into the plate and then printed. However, most specialists regard the occasional overlapping of type as caused by paper movement over pieces of type of slightly unequal height.\n\nAlthough Gutenberg was financially unsuccessful in his lifetime, the printing technologies spread quickly, and news and books began to travel across Europe much faster than before. It fed the growing Renaissance, and since it greatly facilitated scientific publishing, it was a major catalyst for the later scientific revolution.\n\nThe capital of printing in Europe shifted to Venice, where visionary printers like Aldus Manutius ensured widespread availability of the major Greek and Latin texts. The claims of an Italian origin for movable type have also focused on this rapid rise of Italy in movable-type printing. This may perhaps be explained by the prior eminence of Italy in the paper and printing trade. Additionally, Italy's economy was growing rapidly at the time, facilitating the spread of literacy. Christopher Columbus had a geographical book (printed by movable types) bought by his father. That book is in a Spanish museum. Finally, the city of Mainz was sacked in 1462, driving many (including a number of printers and punch cutters) into exile.\n\nPrinting was also a factor in the Reformation. Martin Luther's 95 Theses were printed and circulated widely; subsequently he issued broadsheets outlining his anti-indulgences position (certificates of indulgences were one of the first items Gutenberg had printed). The broadsheet contributed to development of the newspaper.\n\nIn the decades after Gutenberg, many conservative patrons looked down on cheap printed books; books produced by hand were considered more desirable.\n\nToday there is a large antique market for the earliest printed objects. Books printed prior to 1500 are known as \"incunabula\".\n\nThere are many statues of Gutenberg in Germany, including the famous one by Bertel Thorvaldsen (1837) in Mainz, home to the eponymous Johannes Gutenberg University of Mainz and the Gutenberg Museum on the history of early printing. The latter publishes the \"Gutenberg-Jahrbuch\", the leading periodical in the field.\n\nProject Gutenberg, the oldest digital library, commemorates Gutenberg's name. The Mainzer Johannisnacht commemorates the person Johannes Gutenberg in his native city since 1968.\n\nIn 1952, the United States Postal Service issued a five hundredth anniversary stamp commemorating Johannes Gutenberg invention of the movable-type printing press.\n\nIn 1961 the Canadian philosopher and scholar Marshall McLuhan entitled his pioneering study in the fields of print culture, cultural studies, and media ecology, \"The Gutenberg Galaxy: The Making of Typographic Man\".\n\nRegarded as one of the most influential people in human history, Gutenberg remains a towering figure in the popular image. In 1999, the A&E Network ranked Gutenberg the No. 1 most influential person of the second millennium on their \"Biographies of the Millennium\" countdown. In 1997, Time–Life magazine picked Gutenberg's invention as the most important of the second millennium.\n\nIn space, he is commemorated in the name of the asteroid 777 Gutemberga.\n\nTwo operas based on Gutenberg are \"G, Being the Confession and Last Testament of Johannes Gensfleisch, also known as Gutenberg, Master Printer, formerly of Strasbourg and Mainz\", from 2001 with music by Gavin Bryars; and \"La Nuit de Gutenberg\", with music by Philippe Manoury, premiered in 2011 in Strasbourg.\n\nIn 2018, WordPress, the open-source CMS platform, named it's new editing system Gutenberg in tribute to him.\n\n\n\n\n"}
{"id": "49261423", "url": "https://en.wikipedia.org/wiki?curid=49261423", "title": "Lamia Chafei Seghaier", "text": "Lamia Chafei Seghaier\n\nLamia Chafei Seghaier (born 4 May 1968 in Tunis) is a Tunisian engineer and politician. She was the Secretary of State to the Minister of Communication Technologies in charge of Information Technology, Internet and Free Software between 2008 and 2011. \n\nShe holds a master's degree in electrical engineering, obtained the National School of Engineering, Monastir as well University of Technology of Compiègne.\n\nIn 1993, she became a network engineer in a private company, and then in 1996 she began working at the Tunisian Internet Agency, where she was successively Head of Service in charge of e-commerce, Deputy Director in charge of Technology and Security, and then Director in charge of Technology.\n\nShe became CEO, replacing Adel Gaaloul, and held this position from September 2007 to 2 January 2008.\n\nShe also helped develop some university courses, from 2000 to 2002.\n\nBetween January 2008 and January 2011, she was Secretary of State to the Minister of Communication Technologies in charge of Information Technology, Internet and Free Software. She held this position in the first Ghannouchi government, and then with Minister Mohamed Naceur Ammar, from 2010 and until the 2011 revolution.\n\nShe is married and has one child.\n"}
{"id": "577817", "url": "https://en.wikipedia.org/wiki?curid=577817", "title": "Lamination", "text": "Lamination\n\nLamination is the technique of manufacturing a material in multiple layers, so that the composite material achieves improved strength, stability, sound insulation, appearance or other properties from the use of differing materials. A laminate is a permanently assembled object by heat, pressure, welding, or adhesives.\n\nThere are different lamination processes, depending on the type of materials to be laminated. The materials used in laminates can be the same or different, depending on the processes and the object to be laminated. An example of the type of laminate using different materials would be the application of a layer of plastic film—the \"laminate\"—on either side of a sheet of glass—the \"laminated\" subject.\n\nVehicle windshields are commonly made by laminating a tough plastic film between two layers of glass. This is to prevent shards of glass detaching from the windshield in case it breaks. Plywood is a common example of a laminate using the same material in each layer. Glued and laminated dimensioned timber is used in the construction industry to make wooden beams, Glulam, with sizes larger and stronger than can be obtained from single pieces of wood. Another reason to laminate wooden strips into beams is quality control, as with this method each and every strip can be inspected before it becomes part of a highly stressed component.\n\nElectrical equipment such as transformers and motors usually use steel laminations to form the core of coils used to produce magnetic fields. The thin laminations reduce the loss due to eddy currents.\n\nExamples of laminate materials include melamine adhesive countertop surfacing and plywood. Decorative laminates are produced with decorative papers with a layer of overlay on top of the decorative paper, set before pressing them with thermoprocessing into high-pressure decorative laminates. A new type of HPDL is produced using real wood veneer or multilaminar veneer as top surface. High-pressure laminates consists of laminates \"molded and cured at pressures not lower than 1,000 lb per sq in.(70 kg per sq cm) and more commonly in the range of 1,200 to 2,000 lb per sq in. (84 to 140 kg per sq cm). Meanwhile, low pressure laminate is defined as \"a plastic laminate molded and cured at pressures in general of 400 pounds per square inch (approximately 27 atmospheres or 2.8 × 106 pascals).\n\nCorrugated fiberboard boxes are examples of laminated structures, where an inner core provides rigidity and strength, and the outer layers provide a smooth surface.\n\nLaminating paper products, such as photographs, can prevent them from becoming creased, faded, water damaged, wrinkled, stained, smudged, abraded, or marked by grease or fingerprints. Photo identification cards and credit cards are almost always laminated with plastic film. Boxes and other containers are also laminated using a UV coating. Lamination is also used in sculpture using wood or resin. An example of an artist who used lamination in his work is the American Floyd Shaman.\n\nFurther, laminates can be used to add properties to a surface, usually printed paper, that would not have them otherwise. Sheets of vinyl impregnated with ferro-magnetic material can allow portable printed images to bond to magnets, such as for a custom bulletin board or a visual presentation. Specially surfaced plastic sheets can be laminated over a printed image to allow them to be safely written upon, such as with dry erase markers or chalk. Multiple translucent printed images may be laminated in layers to achieve certain visual effects or to hold holographic images. Many printing businesses that do commercial lamination keep a variety of laminates on hand, as the process for bonding many types is generally similar when working with arbitrarily thin material.\n\nThree types of laminators are used most often in digital imaging:\n\nLaminate plastic film is generally categorized into these five categories:\n\n"}
{"id": "36456677", "url": "https://en.wikipedia.org/wiki?curid=36456677", "title": "Language-agnostic", "text": "Language-agnostic\n\nLanguage-agnostic programming or scripting (also called language-neutral, language-independent, or cross-language) is a software development paradigm where a particular language is chosen because of its appropriateness for a particular task (taking into consideration all factors, including ecosystem, developer skill-sets, performance, etc.), and not purely because of the skill-set available within a development team.\n\nFor example, a language agnostic Java development team might choose to use Ruby or Perl for some development work, where Ruby or Perl would be more appropriate than Java.\n\n\"Cross-Language\" in programming and scripting describes a program in which two or more languages must be implemented into the program code alongside the core programming language chosen to write the program. Whether this means including a script as a source, to be used when needed, running code within Language-Independent Virtual Machines such as JVM, or Object Models such as COM to cooperate with each other, or choosing languages that work well together natively.\n\n\n"}
{"id": "12181134", "url": "https://en.wikipedia.org/wiki?curid=12181134", "title": "Magic eye tube", "text": "Magic eye tube\n\nA magic eye tube or tuning indicator, in technical literature called an electron-ray indicator tube, is a vacuum tube which gives a visual indication of the amplitude of an electronic signal, such as an audio output, radio-frequency signal strength, or other functions. The magic eye (also called a cat's eye, or tuning eye in North America) is a specific type of such a tube with a circular display similar to the EM34 illustrated. Its first broad application was as a tuning indicator in radio receivers, to give an indication of the relative strength of the received radio signal, to show when a radio station was properly tuned in.\n\nThe magic eye tube was the first in a line of development of cathode ray type tuning indicators developed as a cheaper alternative to the needle movement meters. It was not until the 1960s that needle meters were made economically enough in Japan to displace indicator tubes. Tuning indicator tubes were used in vacuum tube receivers from around 1936 to 1980 before vacuum tubes were replaced by transistors in radios. An earlier tuning aid which the magic eye replaced was the \"tuneon\" neon lamp.\n\nThe magic eye tube (or valve) for tuning radio receivers was invented in 1932 by Allen B. DuMont (who spent most of the 1930s improving the lifetime of cathode ray tubes, and ultimately formed the DuMont Television Network).\n\nThe RCA 6E5 from 1935 was the first commercial tube.\n\nThe earlier types were end-viewed (see the EM34), usually with an octal or side-contact base. Later developments featured a smaller side-viewed noval B9A based all-glass type with either a fan type display or a band display (see the EM84). The end-viewed version had a round cone-shaped fluorescent screen together with the black cap that shielded the red light from the cathode/heater assembly. This design prompted the contemporary advertisers to coin the term magic eye, a term still used.\n\nThere was also a sub-miniature version with wire ends (Mullard DM70/DM71, Mazda 1M1/1M3, GEC/Marconi Y25) intended for battery operation, used in one Ever Ready AM/FM battery receiver with push-pull output, as well as a small number of AM/FM mains receivers, which lit the valve from the 6.3V heater supply via a 220 ohm resistor or from the audio output valve's cathode bias. Some reel-to-reel tape recorders also used the DM70/DM71 to indicate recording level, including a transistorized model with the valve lit from the bias-oscillator voltage.\n\nThe function of a magic eye can be achieved with modern semiconductor circuitry and optoelectronic displays. The high voltages (100 Volts or more) required by these tubes are not present in modern devices, so the magic eye tube is now obsolete.\n\nMagic eye tubes are miniature cathode ray tube, usually with a built-in triode signal amplifier. It usually glows bright green, (occasionally yellow in some very old types, e.g., EM4) and the glowing ends grow to meet in the middle as the voltage on a control grid increases. It is used in a circuit that drives the grid with a voltage that changes with signal strength; as the tuning knob is turned, the gap in the eye becomes narrowest when a station is tuned in correctly.\n\nInternally, the device is a vacuum tube consisting of two plate electrode assemblies, one creating a triode amplifier and the other a display section consisting of a conical-shaped target anode coated with zinc-silicate or similar material. The display section's anode is usually directly connected to the receiver's full positive high tension (HT) voltage, whilst the triode-anode is usually (internally) connected to a control electrode mounted between the cathode and the target-anode, and externally connected to positive HT via a high-value resistor, typically 1 megaohm.\n\nWhen the receiver is switched on but not tuned to a station, the target-anode glows green due to electrons striking it, with the exception of the area by the internal control-electrode. This electrode is typically 150-200V negative with respect to the target-anode, repelling electrons from the target in this region, causing a dark sector to appear on the display.\n\nThe control-grid of the triode-amplifier section is connected to a point where a negative control voltage dependent on signal strength is available, e.g. the AGC line in an AM superheterodyne receiver, or the limiter stage or FM detector in an FM receiver. As a station is tuned in the triode-grid becomes more negative with respect to the common cathode.\n\nThe purpose of magic eye tubes in radio sets is to help with accurate tuning to a station; the tube makes peaks in signal strength more obvious by producing a visual indication, which is better than using the ear alone. The eye is especially useful because the automatic gain control (AGC) action tends to increase the audio volume of a mistuned station, so the volume varies relatively little as the tuning knob is turned. The tuning eye was driven by the AGC voltage rather than the audio signal.\n\nWhen, in the early 1950s, FM radio sets were made available on the UK market, many different types of magic eye tubes were made available, with differing displays, but they all worked the same way. Some had a separate small display to light up indicating a stereo signal on FM.\n\nThe British Leak company used an EM84 indicator as a very precise tuning-indicator in their Troughline FM tuner series, by mixing the AGC voltages from the two limiter valve grids at the indicator sensing-grid. By this means accurate tuning was indicated by a fully open sharp shadow, whilst off-tune the indicator produced a partially closed shadow.\n\nMagic eye tubes were used as the recording level indicator for tape recorders, and it is also possible to use them (in a specially adapted circuit) as a means of rough frequency comparison as a simpler alternative to Lissajous figures.\n\nA magic eye tube acts as an inexpensive uncalibrated (and not necessarily linear) voltage indicator, and can be used wherever an indication of voltage is needed, saving the cost of a more accurate calibrated meter.\n\nAt least one design of capacitance bridge uses this type of tube to indicate that the bridge is balanced.\n\nThe magic eye tube was also used on the cover of My Morning Jacket's 2011 album \"Circuital\". The tube was shown as being almost fully lit.\n\n\n"}
{"id": "24534010", "url": "https://en.wikipedia.org/wiki?curid=24534010", "title": "Med Flash", "text": "Med Flash\n\nMedFlash is a portable personal health record storage device developed and sold by Connectyx Technologies in the United States. Its primary purpose is for transporting and maintaining personal health records.\n\nMedFlash is currently produced as a USB flash drive, and is sold in all US states. MedFlash has special in case of emergency features on its members ID card so when you can't speak MedFlash speaks for you.\n\n"}
{"id": "44926227", "url": "https://en.wikipedia.org/wiki?curid=44926227", "title": "Mikron Group", "text": "Mikron Group\n\nMikron Group (), headed by JSC Mikron, is one of the largest manufacturers and exporters of microelectronics in Russia and the CIS. Its facilities are located in Zelenograd, Russia.\n\nDuring the period from 1960–1980 Mikron actively developed microelectronic technologies for the USSR. In 2010, Mikron obtained a license for a 90 nm process, with production starting around 2012–2013. The 90 nm production facilities and the design center were co-financed almost up to 50% by Rusnano, with a total cost of 16,57 billion Russian rubles. In 2014, due to the suspension of activities between Visa, MasterCard and certain Russian banks, Mikron hoped to receive orders related to the creation of the Russian national card payment system to be launched in 2015. In late 2014 it was announced that Mikron had started pilot production of a domestic microprocessor called Elbrus-2SM using a 90 nm process under the import substitution program in Russia. Domestic production of the Elbrus-2SM microprocessor was selected by the readers of the technical magazine CNews as the most significant event of 2014, while the creation of a national card payment system ranked at number 3 on the list.\n\n\n\n"}
{"id": "3602606", "url": "https://en.wikipedia.org/wiki?curid=3602606", "title": "Modern Inventions", "text": "Modern Inventions\n\nModern Inventions is a 1937 American animated short film produced by Walt Disney Productions and released by United Artists. The cartoon follows Donald Duck as he tours the fictional Museum of Modern Marvels. It was directed by Jack King, his first project at the Disney studio, and features original music by Oliver Wallace. The voice cast includes Clarence Nash as Donald, Billy Bletcher as the Robot Butler, Adriana Caselotti as the Robot Baby Carriage and Cliff Edwards as the Robot Barber.\n\n\"Modern Inventions\" pokes fun at modern conveniences. The scene of Donald in the barber's chair was submitted by Carl Barks as his first story contribution at Disney.\n\nDonald visits the \"Museum of Modern Marvels\" which showcases various futuristic electronic appliances and inventions. He uses a quarter on a line to get in (this allows him to keep his money and get in as well). Once inside, he is confronted with the \"Robot Butler\", a robot who takes hats (\"Your hat, sir.\") After Donald's hat is taken away from him, Donald uses a magic trick to produce another hat (similar to the way he produces flutes in \"The Band Concert\"). He says, \"So!\" and continues on his way. He first encounters a robotic hitch-hiker, which activates when he makes driving noises. However, when he laughs at it, it punches him in the face. Next he goes to the wrapping machine, which says \"Do not touch\" but Donald ignores the sign and hops on. When he pulls a lever, the machine proceeds to grab him in two robotic arms, put transparent wrapping paper around him, and put him in ribbons, like a package. He manages to break out by vigorously shaking, and continues exploring.\n\nAll the time, Donald has been losing hat after hat to the Robot Butler, making Donald angrier and angrier. Eventually, the Butler chases him through the museum to an automated baby carriage, which Donald hides inside. Donald is given a baby's hat to wear as is rocked as the song \"Rock-a-bye Baby\" is played. Donald then begins acting like a baby, sucking his feet, playing with toys offered to him and getting ticked under the chin, and having his feet counted \"This Little Piggy went to market.\" Donald then begins whining about not getting his milk. The machine gets out a bottle of milk but it hits him in the face instead of going into his mouth, making Donald agitated. The machine begins torturing him with toys and more milk in the face, turning him over and pinning a diaper on his bottom and powdering it.\n\nThe Robot Butler is again attracted by Donald's laughing and yanks the baby hat off his head. Donald produces one last hat and goes to the one exhibit he's not yet seen: a self-operating hair makeup chair. Using his \"cheat\" coin, Donald pays to get his hair done. However, instead of giving him a haircut, it flips him over, removes his hat, and given his bottom a cut, wrapping his rear end in a towel, cutting off his tail feathers, cleaning his bill, coating his face with shoe polish, sifting through his bottom feathers, applying a wet towel to it, slapping his blackened face with a cloth, combing his bottom with a comb, making a gap through it, smoothing it out and finally, giving him a pig tail design. The Robot Butler appears and removes Donald's last hat, which causes Donald to enter an explosive rage.\n\n\n\n\n"}
{"id": "12178327", "url": "https://en.wikipedia.org/wiki?curid=12178327", "title": "Ocean Surface Topography Mission", "text": "Ocean Surface Topography Mission\n\nThe Ocean Surface Topography Mission (OSTM) on the Jason-2 satellite is an international Earth observation satellite mission that continues the sea surface height measurements begun in 1992 by the joint NASA/CNES TOPEX/Poseidon mission and followed by the NASA/CNES Jason-1 mission launched in 2001.\n\nLike its two predecessors, OSTM/Jason-2 uses high-precision ocean altimetry to measure the distance between the satellite and the ocean surface to within a few centimeters. These very accurate observations of variations in sea surface height—also known as ocean topography—provide information about global sea level, the speed and direction of ocean currents, and heat stored in the ocean.\n\nJason-2 was built by Thales Alenia Space using a Proteus platform, under a contract from CNES, as well as the main Jason-2 instrument, the Poseidon-3 altimeter (successor to the Poseidon and Poseidon 2 altimeter on-board TOPEX/Poseidon and Jason-1)\n\nScientists consider the 15-plus-year climate data record that this mission will extend critical understanding how ocean circulation is linked to global climate change.\n\nOSTM/Jason-2 was launched at 07:46 UTC on June 20, 2008, from Space Launch Complex 2W at the Vandenberg Air Force Base in California, USA, by a Delta II 7320 rocket. The spacecraft separated from the rocket 55 minutes later.\n\nIt is now in a circular, non-sun-synchronous orbit at an inclination of 66 degrees to Earth's equator, allowing it to monitor 95 percent of Earth's ice-free ocean every 10 days. Jason-1 has been moved to the opposite side of Earth and now flies over the same region of the ocean that Jason-2 flew over five days earlier. Jason-1's ground tracks fall midway between those of Jason-2, which are about apart at the equator. This interleaved tandem mission provides twice the number of measurements of the ocean's surface, bringing smaller features such as ocean eddies into view. The tandem mission also helps pave the way for a future ocean altimeter mission that would collect much more detailed data with its single instrument than the two Jason satellites now do together.\n\nWith OSTM/Jason-2, ocean altimetry makes the transition from research into operational mode. Responsibility for collecting these measurements moves from the space agencies to the world’s weather and climate forecasting agencies, which use them for short-range, seasonal, and long-range weather and climate forecasting.\n\n\nSpaceborne radar altimeters have proven to be superb tools for mapping ocean-surface topography, the hills and valleys of the sea surface. These instruments send a microwave pulse to the ocean’s surface and time how long it takes to return. A microwave radiometer corrects any delay that may be caused by water vapor in the atmosphere. Other corrections are also required to account for the influence of electrons in the ionosphere and the dry air mass of the atmosphere. Combining these data with the precise location of the spacecraft makes it possible to determine sea-surface height to within a few centimetres (about one inch). The strength and shape of the returning signal also provides information on wind speed and the height of ocean waves. These data are used in ocean models to calculate the speed and direction of ocean currents and the amount and location of heat stored in the ocean, which, in turn, reveals global climate variations.\n\nAnother payload aboard Jason-2 is the T2L2 (Time Transfer by Laser Link) instrument. T2L2 is used to synchronize atomic clocks at ground stations, and to calibrate the on-board clock of the Jason-2 DORIS instrument. On 6 November 2008 CNES reported the T2L2 instrument was working well.\n\nOSTM/Jason-2 is a joint effort by four organizations. The mission participants are:\n\nCNES provided the spacecraft, NASA and CNES jointly provided the payload instruments and NASA's Launch Services Program at the Kennedy Space Center was responsible for the launch management and countdown operations. After completing the on-orbit commissioning of the spacecraft, CNES handed over operation and control of the spacecraft to NOAA in October 2008.\n\nCNES will process, distribute and archive the research-quality data products that will become available in 2009. EUMETSAT will process and distribute operational data received by its ground station to users in Europe and will archive the data. NOAA will process and distribute operational data received by its ground stations to non-European users and archive that data along with the CNES data products. NOAA and EUMETSAT will generate the near-real-time products and distribute them to users.\n\nNASA will evaluate the performance of its instruments: the advanced microwave radiometer, the Global Positioning System payload, and the laser retroreflector assembly. In addition, NASA and CNES will validate scientific data products. NASA's Jet Propulsion Laboratory in Pasadena, California, manages the mission for NASA's Science Mission Directorate in Washington.\n\nThe two previous altimetry missions TOPEX/Poseidon and Jason-1 have led to major advances in the science of physical oceanography and in climate studies. Their 15-year data record of ocean surface topography has provided the first opportunity to observe and understand the global change of ocean circulation and sea level. The results have improved the understanding of the role of the ocean in climate change and improved weather and climate predictions. Data from these missions are used to improve ocean models, forecast hurricane intensity, and identify and track large ocean/atmosphere phenomena such as El Niño and La Niña. The data are also used every day in applications as diverse as routing ships, improving the safety and efficiency of offshore industry operations, managing fisheries and tracking marine mammals.\n\nSome of the areas in which TOPEX/Poseidon and Jason 1-have made major contributions, and to which OSTM/Jason-2 will continue to add, are:\n\nThe missions revealed the surprising variability of the ocean, how much it changes from season to season, year to year, decade to decade and on even longer time scales. They ended the traditional notion of a quasi-steady, large-scale pattern of global ocean circulation by proving that the ocean is changing rapidly on all scales, from huge features such as El Nino and La Nina, which can cover the entire equatorial Pacific, to tiny eddies swirling off the large Gulf Stream in the Atlantic.\n\nMeasurements by TOPEX/Poseidon and Jason-1 show that mean sea level has been rising by about three millimeters (.12 inches) a year since 1993. This is about twice the estimates from tide gauges for the previous century, indicating a possible recent acceleration in the rate of sea level rise.\n\nThe data record from these altimetry missions has given scientists important insights into how global sea level is affected by natural climate variability, as well as by human activities.\n\nTOPEX/Poseidon and Jason-1 made clear the importance of planetary-scale waves, such as Rossby and Kelvin waves. No one had realized how widespread these waves are. Thousands of kilometers wide, these waves are driven by wind under the influence of Earth’s rotation and are important mechanisms for transmitting climate signals across the large ocean basins. At high latitudes, they travel twice as fast as scientists believed previously, showing the ocean responds much more quickly to climate changes than was known before these missions.\n\nThe precise measurements of TOPEX/Poseidon’s and Jason-1 have brought knowledge of ocean tides to an unprecedented level. The change of water level due to tidal motion in the deep ocean is known everywhere on the globe to within 2.5 centimeters (one inch). This new knowledge has revised notions about how tides dissipate. Instead of losing all their energy over shallow seas near the coasts, as previously believed, about one third of tidal energy is actually lost to the deep ocean. There, the energy is consumed by mixing water of different properties, a fundamental mechanism in the physics governing the general circulation of the ocean.\n\nTOPEX/Poseidon and Jason-1 observations provided the first global data for improving the performance of the numerical ocean models that are a key component of climate prediction models.\n\nThe mission's first validated data products in support of improved weather, climate and ocean forecasts are now being distributed to the public within a few hours of observation. Beginning in 2009, other data products for climate research will be available a few days to a few weeks after observations are taken by the satellite.\n\nAltimetry data have a wide variety of uses from basic scientific research on climate to ship routing. Applications include:\n\n\n\nThe fourth spacecraft to be part of the Ocean Surface Topography Mission is Jason-3. Like its predecessors, the primary instrument aboard Jason-3 is a radar altimeter. Additional instruments include:\n\nJason-3 launched from Vandenberg Air Force Base on board a SpaceX Falcon 9 v1.1 launch vehicle in 2016. The satellite was shipped to \nVandenberg Air Force Base on June 18, 2015, and after delays due to a June 2015 Falcon 9 launch failure, the mission was launched January 17, 2016 at 10:42:18 AM PST.\n\n\n"}
{"id": "799498", "url": "https://en.wikipedia.org/wiki?curid=799498", "title": "Paul Alfred Biefeld", "text": "Paul Alfred Biefeld\n\nDr. Paul Alfred (22 March 1867 – 21 June 1943) was a German-American electrical engineer, astronomer and teacher.\n\nPaul Alfred Biefeld was born in Jöhstadt, Saxony, Germany on March 22, 1867. He was the son of Heinrich and Wilhelmina (Glaeser) Biefeld, he moved to the United States in 1881. Biefeld received his B.S. in Electrical Engineering at the University of Wisconsin in 1894. He received his Ph.D. at the University of Zurich, Switzerland in 1900.\n\nHe married Emma Bausch, of Frankfurt am Main, on 11 April 1900. He was the Assistant Principal of Appleton Wisconsin high school 1894-1897. Paul was the lab assistant in Physics and Electrical Engineering at the ETH Zürich, 1899 – 1900. Biefeld was the professor of Physics and Electrical Engineering at the Hildburghausen Technikum, Germany 1900 – 1906. He was also the professor of Physics and Astronomy at the University of Akron, Akron, Ohio in 1906 and continued until 1911. He arrived at Denison University in 1911 where he was the professor and lecturer of Astronomy and the Director of the Warner and Swasey Observatory. He continued to teach at Denison University and lived in Granville, Ohio until his death in June 1943.\n\nBiefeld joined the Yerkes Eclipse Expedition to Denver, Colorado in 1918. He was the research assistant at the Yerkes Observatory for the summer of 1919. Biefeld was part of the Yerkes Eclipse Expedition to Catalina Island in September 1923.\n\nIn popular culture Biefeld's name has come to be associated with the Biefeld–Brown effect, an electrical effect where extremely high voltages can produce a type of propulsion, usually attributed an ionic wind but also associated with several anti-gravity theories. The effect was named by inventor Thomas Townsend Brown, a former student of Biefeld at Denison University in Ohio. Brown claimed Biefeld as his mentor and co-experimenter although he seems to have named this effect many years after his association with Biefeld. Brown only attended Denison University for one year and their records show no evidence of any research or experiments being carried out by Biefeld/Brown during Biefeld's professorship there.\n\nBrown himself seemed to think the effect demonstrated a connection between electricity and gravity, which he thought was being negated by the high voltage.\n\nPublications promoting the Biefeld–Brown effect/Electrogravitics/anti-gravity tend to emphasize Paul Biefeld's standing as a physicist via titling him a \"colleague of Albert Einstein\", based on the fact that Biefeld and Einstein attended ETH Zürich at the same time. Later in life Biefeld recounted that Einstein borrowed his class notes but there is little evidence of anything more than a passing acquaintance between the two students.\n\n\n"}
{"id": "949725", "url": "https://en.wikipedia.org/wiki?curid=949725", "title": "Photo booth", "text": "Photo booth\n\nA photo booth is a vending machine or modern kiosk that contains an automated, usually coin-operated, camera and film processor. Today, the vast majority of photo booths are digital.\n\nThe patent for the first automated photography machine was filed in 1888 by William Pope and Edward Poole of Baltimore. The first known really working photographic machine was a product of the French inventor T. E. Enjalbert (March 1889). It was shown at the 1889 World's Fair in Paris. The German-born photographer Mathew Steffens from Chicago filed a patent for such a machine in May 1889. These early machines were not reliable enough to be self-sufficient. The first commercially successful automatic photographic apparatus was the \"Bosco\" from inventor Conrad Bernitt of Hamburg (patented July 16, 1890). All of these early machines produced ferrotypes. The first photographic automate with negative and positive process was invented by Carl Sasse (1896) of Germany.\n\nThe modern concept of photo booth with (later) a curtain originated with Anatol Josepho (previously Josephewitz), who had arrived in the U.S. from Russia in 1923. with the first photo booth appearing 1925 on Broadway in New York City. For 25 cents, the booth took, developed and printed 8 photos, a process taking roughly 10 minutes. In the first six months after the booth was erected, it was used by 280,000 people. The Photomaton Company was created to place booths nationwide. On March 27, 1927, Josepho was paid $1 million and guaranteed future royalties for his invention.\n\nMost of the photo booths are used for passport photos. They are coin-operated automated machines that are designed to print photo in specific format that meets the passport photo requirements. Multiple copies can be printed so users can save some for future uses.\n\nTraditionally, photo booths contain a seat or bench designed to seat the one or two patrons being photographed. The seat is typically surrounded by a curtain of some sort to allow for some privacy and help avoid outside interference during the photo session. Once the payment is made, the photo booth will take a series of photographs, although most modern booths may only take a single photograph and print out a series of identical pictures. Before each photograph, there will be an indication, such as a light or a buzzer, that will signal the patron to prepare their pose. After the last photograph in the series (typically between 3 and 8) has been taken, the photo booth begins developing the film — a process that used to take several minutes in the old \"wet chemistry\" booths, but is now typically accomplished in about 30 seconds with digital technology. The prints are then delivered to the customer. Typical dimensions of these prints vary. The classic and most familiar arrangement from the old style photo booths is four pictures on a strip about 40 mm wide by 205 mm long; digital prints tend to have a square arrangement of two images above two images.\n\nBoth black and white and colour photo booths are common in the US, however in Europe the colour photo booth has almost entirely replaced black and white booths. However, newer digital booths now offer the customer the option of whether to print in colour or in black and white. Most modern photo booths use video or digital cameras instead of film cameras, and are under computer control. Some booths can also produce stickers, postcards, or other items with the photographs on them, rather or as well as simply a strip of pictures. These often include an option of novelty decorative borders around the photos.\n\nPhoto sticker booths or photo sticker machines originated from Japan, are a special type of photo booth that produce photo stickers. Still maintaining huge popularity in Japan, they have spread throughout Asia to Taiwan, South Korea, Hong Kong, Singapore, Malaysia, Philippines, China, Vietnam, and Thailand. They have also been imported to Australia. Some have also begun appearing in the United States and Canada although they failed to make any impression in Europe when introduced in the mid 1990s.\nIn Japan, refers to a photo sticker booth or the product of such a photo booth. The name is a shortened form of the registered trademark . The term derives from the English \"print club\". Jointly developed by Atlus and Sega, the first \"purikura\" machines were sold in July 1995. The booths were brought out in the U.S. and Europe in 1997. The \"purikura\" machines were developed in response to young women's interest in both photography and stickers.\n\nAfter money has been inserted in the machine, multiple customers can enter the booth and pose for a set number of exposures. Some common options include the ability to alter lighting and backdrops while the newest versions offer features such as cameras from a variety of angles, fans, seats, and blue screen effects. Some establishments even offer costumes and wigs for customers to borrow.\n\nOnce the pictures have been taken, the customers select the pictures that they wish to keep and customize them using a touch screen or pen-sensitive screen. The touch screen then displays a vast array of options such as virtual stamps, pictures, clip art, colorful backdrops, borders, and pens that can be superimposed on the photographs.\nFeatures that can be found in some sticker machines are customizing the beauty of the customers such as brightening the pictures, making the eyes sparkle more, changing the hair, bringing a more reddish color to the lips, and fixing any blemishes by having them blurred. Other features include cutting out the original background and replacing it with a different background. Certain backgrounds may be chosen so when the machine prints out the picture, the final sticker will be shiny with sparkles.\n\nFinally, the number and size of the pictures to be printed are chosen, and the pictures print out on a glossy full-color 10 × 15 cm sheet to be cut up and divided among the group of customers. Some photo booths also allow the pictures to be sent to customers' mobile phones. Other photo places have a scanner and laptop at the cashiers desk for customers to scan and copy their original picture before they cut and divide the pictures amongst their group.\n\nPhoto booth rental companies allow a person to rent a photo booth for a short period of time (usually in hours) for a fee. Photo booth rentals have become popular in the United States primarily for wedding receptions, sweet sixteen parties, Bar and Bat Mitzvah parties, along with a growing number of other public and private events. In addition to the photo booth and the printing of unlimited photo strips, rental companies usually include a photo booth attendant to service the photo booth and to help guests construct the guest book of photo strips. Online image hosting, compact disks containing the images and related merchandise are readily available. Celebrities are frequent users of photo booths in parties, \nApart from traditional photo printing, modern photo booths may also include the following new functions:\n\nAs digital cameras, compact photo printers, and flat screen computer monitors became widely available in the early 2000s, people connected these together using a personal computer and software and created their own photo booths. Entrepreneurs began renting machines built along these lines at weddings and parties and the idea spread. From 2005 to 2012, interest in the United States for photo booth rentals grew significantly. By 2016 more people were searching for photo booth rentals than DJ rentals in 15 of North America's largest cities. Photo booth rentals have also become popular in other countries such as Canada, Australia, and the UK. So far in 2016 there is an average of 226,000 monthly searches for a photo booth globally, this has risen by 48.9% since 2015 (In the UK alone this is nearly 20,000 searches a month) \n\nA 3D selfie photo booth such as the Fantasitron located at Madurodam, the miniature park, generates 3D selfie models from 2D pictures of customers. These selfies are often printed by dedicated 3D printing companies such as Shapeways. These models are also known as 3D portraits, 3D figurines or mini-me figurines.\n\n\n\n"}
{"id": "18824860", "url": "https://en.wikipedia.org/wiki?curid=18824860", "title": "Photosensitive glass", "text": "Photosensitive glass\n\nPhotosensitive glass, also known as photostructurable glass (PSG), or photomachinable glass, is a crystal-clear glass that belongs to the lithium-silicate family of glasses, in which an image of a mask can be captured by microscopic metallic particles in the glass when it is exposed to short wave radiations such as ultraviolet light. Photosensitive glass was first discovered by S. Donald Stookey in 1937.\n\nPhotosensitive glass was invented in November 1937 by Dr. Donald Stookey of the Corning Glass Works. It was not announced publicly until ten years later on June 1, 1947. It was officially patented in 1950 by Stookey as U.S. Pat. No. 2,515,937 and U.S. Pat. Nos. 2,515,943 with gold microscopic particles and marketed under the trade name PhotoCor(R).\n\nWhen the glass is exposed to UV light in the wavelength range 280–320 nm, a latent image is formed. The glass remains transparent at this stage, but its absorption in the uv range of the spectrum increases. This increased absorption is only detectable using uv transmission spectroscopy.\nThe reason behind this is suggested to be an oxidation reduction reaction that occurs inside the glass during exposure in which cerium ions are oxidized to a more stable state and silver ions are reduced to silver.\n\nWhen the glass is heated to temperatures in the range 550–560 °C for several hours the latent image is converted to a visible image through photoexcitation. Exposure through photographic negatives permits the development of three-dimensional color images and photographs. This heat treatment is done in two stages: the temperature is first raised to about 500 °C to allow for the completion of the oxidation-reduction reaction, and formation of silver nanoclusters. In the following stage, when the temperature is raised to 550–560 °C, a new material (lithium metasilicate) with the formula (LiSiO) forms on the silver nanoclustors, this material forms in the crystalline phase.\n\nThe lithium metasilicate that forms in the exposed regions of the glass has the unique property of being strongly etched in hydrofluoric acid (HF). Hence allowing a three-dimensional image of the mask to be produced, the resulting glass microstructures have a surface roughness in the range 5 μm to 0.7 μm.\n\nAs stated above radiation produces some direct and indirect measurable changes in the glasses. In some cases, the effect is readily observable immediately upon irradiation. In other cases, thermal treatment is required to bring about the observed changes. On the whole, the result of the mentioned reactions will be atomic silvers and/or silver clusters which act as nucleant for precipitation of lithium-meta-silicate during post heat-treatment of irradiated glass and Similar to other glass-ceramic systems, the more nucleation sites leads to more reduction of crystallization temperature and finer crystalline size. Therefore, to attain the above-mentioned condition, various energetic radiation such as UVand laser beam and x γ and proton and radiations have been used for different photosensitive glasses until now.\nImanieh et al. investigated the effect of X-ray irradiation on solarization of photosensitive lithium silicate based glasses containing cerium, antimony, tin and silver elements. They have shown that there is a possibility to use X-ray in photosensitive glasses. This will open new doors for nano machining of glasses in near future.\n\nPhotosensitive glass is used in printing and reproducing processes. Photosensitive glass is like traditional camera film except that it reacts to ultraviolet (UV) light, where camera film responds to visible light. The ideal wavelength to use for exposure should be between 300 and 350 nm, with 320 nm being optimum.\n\nPhotosensitive glass contains microscopic metallic particles. These microscopic metallic ion nanoparticles are made of gold or silver which is responsible for the refractive index change. Photosensitive glass is similar to photographic film. Photographic film uses chemicals, while photosensitive glass\nuses gold or silver ions in the material that will respond to the action of light. The process is to pass light of the ultraviolet wavelength through a negative on the glass. Photographic resolution can be obtained with adhesive polyester as a reverse negative, however anything which resists UV light can act as a \"negative.\"\n\nThe glass is sensitive to light that when passes through a mask can ultimately turn it into a permanent picture with a heat process \"fixing\" permanently the image. Silver glass \"latent images\" will develop in 3–4 hours at 886–976 °F.\nGold glass \"latent images\" require a higher temperature of 968–1058 °F and over a similar period of time for postbaking. Postbaking hastens the occurrence of the particles with the shadow areas of the negative, permitting deeper penetration into the glass than the highlighted areas. This gives the picture three dimensions and color.\n\nThe photograph is developed by heating the photosensitive glass around 1000 °F for several hours after exposure. The glass itself is photosensitive and produces a three-dimensional image. Particles that are invisible to the naked eye (i.e. gold or silver) are in the glass. These microscopic particles move and grow when heated to form the photographic image itself. The process is similar to camera film, however a \"negative\" is placed on top of the photosensitive glass and then exposed to ‘’’ultraviolet’’’ light. Camera film, of course, would be exposed to ordinary visible light. Then there is a special process for the exposed photosensitive glass. The glass is reheated then in a kiln and postbaked for several hours. The image then \"appears\" within the special exposed glass as if by magic. The heated piece of photosensitive glass is then allowed to cool down and the process is done. The positive images produced within photosensitive glass comes in a variety of colors.\n\nAs a material for the hot glass studio artist, an additional method of producing imagery in an object using photosensitive glass is to first blow an extremely thin rondel (cased or otherwise) which is annealed in the typical manner. That rondel is then cut into sections which are exposed under a negative. Next, those sections (containing the latent image) are warmed and applied to the surface of a gather of hot glass on the blowpipe. As the object is completed over several furnace reheats, the heat develops the image as the object is being created. This method specifically eliminates the need for the reheating of the object in a kiln for development, which consumes considerable oven time, energy, and the risk of loss or damage due to shattering on the way up to temperature, or more importantly, slumping while being held at temperature. The timing of the glassblower determines the final degree of development, and simple choices of form minimize distortion in the image.\n\nSince the image is inside and actually a part of the glass itself, photosensitive glass is the most durable photographic medium known. It is claimed that a photo image within photosensitive glass is the most durable form of photography and will last as long as the glass itself. The photographic image is not on the surface of the glass, but internally.\n\nFluorescent photosensitive glass makes it possible to make fluorescent photographs and fluorescence holography.\n\nPhotosensitive glass is different from photochromatic glass. Photochromatic glass is used in self-darkening sunglasses which darkens when exposed to bright daylight. It then returns to see-through transparency when strong daylight is removed and can then be used indoors as regular glasses.\n\nLittle has been done to develop the product since its patent. It is labor-intensive and has a high cost. Only large commercial glass factories produce it. In the 1980s photosensitive glass was created to a small degree to be used in \"hot glass\" work. Then individual artists owned smaller studios and created works in blown glass and began experimenting with photosensitive glass. Going into the Twenty-First Century only a few glass artists know the technique of achieving good results with photosensitive glass.\nIn the present time, the only photosensitive glasses produced are PhotoCor(R), Foturan and APEX. PhotoCor is produced by the inventor, Corning, Inc. Foturan is produced by SCHOTT Corporation and APEX by Life Bioscience. Photosensitive glass has been used as a holographic material to record diffractive optical elements for high power laser applications.\n\nOne of the reasons for the delay between the invention of photosensitive glass and its public announcement approximately ten years later was its potential use in military applications. It is possible to burn images and words that are hidden in photosensitive glass until heated at a high temperature. The military used this fact during World War II to send secret messages to allied troops in pieces of what looked like \"ordinary glass\". At the other hand, the person who received the \"ordinary glass\" just had to heat it up to read the hidden message. Because of this application photosensitive glass was kept secret until the end of World War II.\n\nThe United Nations Building is faced with hundreds of square feet of photosensitive glass.\n\n\n"}
{"id": "38138695", "url": "https://en.wikipedia.org/wiki?curid=38138695", "title": "Proto.io", "text": "Proto.io\n\nProto.io is an application prototyping platform launched in 2011 and developed by the Labs Division of SNQ Digital. Originally designed to prototype on mobile devices, Proto.io has expanded to allow users to prototype apps for anything with a screen interface, including Smart TV’s, digital camera interfaces, cars, airplanes, and gaming consoles. Proto.io utilizes a drag and drop user interface (UI) and does not require coding.\n\nSince its launch in 2011, there have been three versions of Proto.io released.\n\nIn 2011, SNQ made the 100% web-based Proto.io tool available online. The web-based environment allowed users to create a project for either the iPad or iPhone. After a user created a few screens for a developing app, Proto.io could then link those pages together with interactive actions that are custom to hand held devices, such as clicks, taps, tap and holds, and swipes. With the platform, users could also create reusable templates into which prepackaged and editable elements could be dragged. Once the user had completed the prototype, Proto.io could then publish and preview the finished product not only on the web browser but also on the actual mobile device.\n\nProto.io V2 was released in early 2012 and expanded the supported mobile devices to accommodate for the Android platform, to include the Android Smartphone and Tablet. The platform also came with a newer user interface. Proto.io V2 also added collaboration features like comments and annotations as well as export to HTML functionality.\n\nOn September 28, 2012, with the release of version 3 of the platform, Proto.io became the first prototyping tool to allow users to prototype on almost any device with a screen interface, and the first mobile prototyping tool to support full feature animations of user interface items within a prototype screen. The included icon gallery contains thousands of SVG icons for use as buttons, lists and tab bars. Proto.io V3 also supports web fonts, which allows the user to access all available online fonts.\n"}
{"id": "23133830", "url": "https://en.wikipedia.org/wiki?curid=23133830", "title": "Recuperative multi-tube cooler", "text": "Recuperative multi-tube cooler\n\nA recuperative multi-tube cooler is a rotary drum cooler used for continuous processes in chemical engineering.\n\nRecuperative multi-tube coolers essentially exist of a turning rotor which is mostly driven via chain. At the ends of the rotor are stiff cases for product feed and outlet. The rotor is supported on running treads, as it is typical for rotary drums.\nThe interior of the rotor exists of several tubes in a revolvertype (or planetary) arrangement. The tubes are completely surrounded by a jacket.\n\nAccording to requirements recuperative multi-tube coolers are built with diameters between 1.0 and 4.0 m and lengths from 10 to 40 m.\n\nRecuperative multi-tube coolers work with indirect air cooling. That means, that there is no direct contact between the product to be cooled and the cooling air. The heat is exchanged indirectly via thermal conduction.\nAmbient air is used as cooling air, which is drawn between the jacket and the tubes. Product and cooling air pass through the cooler in counterflow. \nThe product to be cooled falls directly into the product feed housing. By the rotary movement and a little slope of the rotor, the product is conveyed through the cooler. The rotation causes a permanent mixing of the product in the tubes and hence a good heat transfer.\n\nDue to the indirect method of operation, the coolers provide hot and clean air that can be reused as energy. This opportunity of recovering energy is where the term recuperative results from.\n\nThe coolers can be used for the cooling of free flowing, fine grained bulk material. They are especially used when consumers of the recovered hot air are close-by. Usual this is the case in calcination processes after hotgas fired rotary kilns in or similar. \nThe hot air is used as preheated supply of combustion air in the kilns. The consumption of primary energy can be reduced seriously.\n\nThe coolers are mostly used in the pigment industry, e.g. for cooling of titandioxide pigments after calcination.\nThe entry temperatures of the products can reach up to 1000 °C.\n\n"}
{"id": "45651130", "url": "https://en.wikipedia.org/wiki?curid=45651130", "title": "Regulation of UAVs in the United States", "text": "Regulation of UAVs in the United States\n\nThe US Federal Aviation Administration has adopted the name \"unmanned aircraft\" (UA) to describe aircraft systems without a flight crew on board. More common names include \"UAV\", \"drone\", \"remotely piloted vehicle\" (\"RPV\"), \"remotely piloted aircraft\" (\"RPA\"), and \"remotely operated aircraft\" (\"ROA\"). These \"limited-size\" (as defined by the \"Fédération Aéronautique Internationale\") unmanned aircraft flown in the USA's National Airspace System, flown solely for recreation and sport purposes, such as models, are generally flown under the voluntary safety standards of the Academy of Model Aeronautics, the United States' national aeromodeling organization. To operate a UA for non-recreational purposes in the United States, according to the FAA users must obtain a \"Certificate of Authorization\" (COA) to operate in national airspace. In December 2015 the FAA announced that all UAVs weighing more than 250 grams flown for any purpose must be registered with the FAA.\n\nThe FAA Modernization and Reform Act of 2012 sets a deadline of September 30, 2015, for the agency to establish regulations to allow the use of commercial drones. In the meantime, the agency claims it is illegal to operate commercial unmanned aerial vehicles, but approves non-commercial flights under 400 feet if they follow Advisory Circular 91-57, Model Aircraft Operating Standards, published in 1981. However, the FAA's attempt to fine a commercial drone operator for a 2011 flight were thrown out on March 6, 2014 by NTSB judge Patrick Geraghty, who found that the FAA had not followed the proper rulemaking procedures and therefore had no UAV regulations. The FAA will appeal the judgment. Texas EquuSearch, which performs volunteer search and rescue operations, was also challenging FAA rules in 2014.\n\nAs of August 2013, commercial unmanned aerial system (UAS) licenses were granted on a case-by-case basis, subject to approval by the Federal Aviation Administration (FAA). Previously, COAs required a public entity as a sponsor. For example, when BP needed to observe oil spills, they operated the Aeryon Scout UAVs under a COA granted to the University of Alaska Fairbanks. COAs have been granted for both land and shipborne operations. In 2014, the FAA approved at least ten applications from specific companies for commercial use of drones, including movie-makers and surveyors.\n\nIn December 2013, the FAA announced six operators it was authorizing to conduct research on drone technology, to inform its pending regulations and future developments. These were the University of Alaska (including locations in Hawaii and Oregon), the state of Nevada, Griffiss International Airport in New York State, the North Dakota Department of Commerce, Texas A&M University–Corpus Christi, and Virginia Tech.\n\nIn addition to FAA certification, the regulation of usage of UA systems by government authorities in the United States for law enforcement purposes is determined at a state level. As of September 2014, 20 U.S. states had enacted legislation addressing the use of UA systems and the handling of data collected by them. Nearly all enacted laws require a probable cause warrant to be issued before the use of a UA system for surveillance purposes is authorized.\n\nIn May 2014, a group of major news media companies filed an \"amicus\" brief in a case before the U.S.'s National Transportation Safety Board, asserting that the FAA's \"overly broad\" administrative limitations against private UAS operations cause an \"impermissible chilling effect on the First Amendment newsgathering rights of journalists\", the brief being filed three months before a scheduled rollout of FAA commercial operator regulations.\n\nThe FAA is required by Congress to come up with rules for commercial use of drones by 2015.\n\nOn January 12, 2015, CNN announced that their News Network has been cleared by the FAA, in the first program of its kind to test camera-equipped drones for news gathering and reporting purposes. CNN has partnered with the Georgia Tech Research Institute to collect data for the program. The FAA said it will analyze the information to develop rules about using drones for news gathering.\n\nOn February 15, 2015, The FAA announced that up to seven thousand businesses could get approval to fly drones two years from now under proposed rules by the FAA. On Sunday the White House also issued a presidential directive that mandates federal agencies for the first time to disclose publicly where they are flying drones and what they do with the data they acquire using aerial surveillance.\n\nIn December 2015 the FAA announced that all UAVs weighing more than 250 grams flown for any purpose must be registered with the FAA. The FAA's Interim Rule can be accessed here. This regulation went into effect on December 21, 2015 and requires that hobby type UAV's between 250 grams and 55 pounds need to be registered no later than February 19, 2016. The FAA's registration portal for drones can be accessed here.\n\nNotable requirements of the FAA UAV registration process include:\n\nThe new FAA rule provides that a single registration applies to as many UAVs as an owner/operator owns or operates. Failure to register can result in civil penalties of up to $27,500 and criminal penalties which could include fines up to $250,000 and/or imprisonment for up to three years.\n\nTo show problems with the FAA process, in August, 2015 an attorney was able to get FAA approval for a commercial drone that was actually a battery powered paper airplane toy. Its controllable range is 120 feet (37 meters) and maximum flight time is 10 minutes. It is too underpowered to carry a camera.\n\nIn February 2016, the FAA established a committee to develop guidelines for regulating safe UAV flight over populated areas, to the end of allowing commercial drone operation, in response to requests from companies involved in commercial drone development such as Amazon and Google.\n\nOn May 19, 2017, the United States Court of Appeals for the District of Columbia Circuit, in ruling on Taylor v. Huerta\n\nreversed the Dec. 2015 UAV registration rule, commenting that \"the FAA may not\npromulgate any rule or regulation regarding a model aircraft.\" Specifically, the FAA’s Registration Rule for model aircraft (a/k/a drones) violates Section 336 of the FAA Modernization and Reform Act, and the FAA's Registration Rule to the extent it applied to model aircraft was vacated. The FAA began the process of refunding the registration fees.\n\nOn December 12, 2017, President Donald Trump signed into law the immediately-effective National Defense Authorization Act for Fiscal Year 2018, reinstating the FAA’s drone registration requirement.\nUnder 49 U.S. Code § 40103, \"The United States Government has exclusive sovereignty of airspace of the United States\" and U.S. citizens have \"a public right of transit through the navigable airspace.\" The FAA is invested with the authority to control traffic in navigable airspace and create operational and safety regulations on aircraft in navigable airspace. According to the FAA, \"[a] navigable airspace free from inconsistent state and local restrictions is essential to the maintenance of a safe and sound air transportation system.\" With respect to navigable airspace and the aircraft operating in that airspace, federal regulations have preempted the field and the ability of state and local laws to regulate use of UAVs is limited.\n\nExamples of state and local laws that, according to the FAA, conflict with the FAA's federal legal authority and require consultation with the FAA before being enacted:\n\nExamples of state and local laws that, according to the FAA, are generally permissible under the state's police powers:\n\nIn 2014, the California State Senate passed rules imposing strict regulations on how law enforcement and other government agencies can use drones. The legislation would require law enforcement agencies to obtain a warrant before using an unmanned aircraft, or drone, except in emergencies. In 2015, Virginia passed legislation that a drone may only be used in law enforcement if a warrant has been issued; excluding emergencies. New Jersey's drone legislation passed in 2015 states that not only are you required to provide a warrant for drone use in law enforcement, but the information collected must be disposed within two weeks. Other states that have drone regulation are Florida, Idaho, Illinois, Indiana, Iowa, Montana, Oregon, Tennessee, Texas, and Wisconsin.\n\nThe first landmark court case on state and municipal drone regulation was \"Singer v. City of Newton\", No. 17-10071-WGY (D. Mass. Sept. 21, 2017). Dr. Michael Singer, a physician, technology advocate, and FAA-certificated drone operator, sued the City of Newton, Massachusetts challenging four provisions in the city's recently enacted drone ordinance.\" \" These provisions required drone operators to register with the Newton city clerk; prohibited drone flights over the city without prior permission of all landowners below; and prohibited beyond-visual-line-of-sight (BVLOS) operations. Singer, who represented himself in court, argued that these provisions were preempted by the FAA Modernization and Reform Act of 2012 and the Federal Aviation Act of 1958 (as recodified). U.S. District Judge William G. Young agreed, striking down the challenged parts of the ordinance due to conflict preemption. The City of Newton appealed the decision to the United States Court of Appeals for the First Circuit, but later withdrew its appeal. \"Singer v. Newton\" is widely regarded as the first court case to examine the intersection of federal and state powers over drone operations.\n\nSome locations, such as Charlottesville, Virginia, Iowa City, Iowa and St. Bonifacius, Minnesota have passed legislation that limits use of UAVs. In New York state, the city of Syracuse considered declaring the city a \"Warrantless Surveillance Drone Free Zone\" but put the legislation on hold after city counsellors became aware of a memorandum of understanding between the Justice Department and the Federal Aviation Administration.\n\nIn 2016, the Connecticut House of Representatives considered legislation to impose restrictions on drone weaponization. The legislation came after a man named Austin Haughwout, then an engineering student at Central Connecticut State University (CCSU), posted a video on YouTube showing a drone carrying a semi-automatic handgun, which he had assembled, and which was seen to fire the gun several times.\n\nIn 2013, a UAV flying over Manhattan collided with several buildings and crashed onto the pavement. It was reported that a man had been arrested days after the incident and that he had been charged with reckless endangerment. He was identified because he was seen in the video recorded by the drone. The Federal Aviation Administration fined the man $2,200. The FAA said that his operation of the UAV was \"flying in restricted airspace without getting permission from controllers and flying in a \"careless or reckless manner\" and \"endangered the safety of the national airspace system\". This was the first FAA attempt to penalise a non-commercial flight.\n\nIn 2015, a drone operated by a civilian flew into the White House property. As a result, the drone manufacturer, DJI, issued a statement saying that they will now require that all of their drones would contain built-in geofencing limits.\n\n\"Movie makers, real-estate agents, criminal-defense lawyers and farmers are among at least 68 groups with a newfound political interest in drones according to Center for Responsive Politics data compiled by Bloomberg\". At least 28 universities and local government agencies as well as Amazon hope to use drones civilly someday. Limited commercial operations for drones weighing less than 55 pounds (25 kilograms) is a proposal due to be decided upon by the end of the year.\n\nIn June 2014, the Motion Picture Association of America stated its support of an FAA exemption for the use of small drones in limited low risk scenarios in film and television productions.\n\n"}
{"id": "417749", "url": "https://en.wikipedia.org/wiki?curid=417749", "title": "Resistor–transistor logic", "text": "Resistor–transistor logic\n\nResistor–transistor logic (RTL) (sometimes also transistor–resistor logic (TRL)) is a class of digital circuits built using resistors as the input network and bipolar junction transistors (BJTs) as switching devices. RTL is the earliest class of transistorized digital logic circuit used; other classes include diode–transistor logic (DTL) and transistor–transistor logic (TTL). RTL circuits were first constructed with discrete components, but in 1961 it became the first digital logic family to be produced as a monolithic integrated circuit. RTL integrated circuits were used in the Apollo Guidance Computer, whose design was begun in 1961 and which first flew in 1966.\n\nA bipolar transistor switch is the simplest RTL gate (inverter or NOT gate) implementing logical negation. It consists of a common-emitter stage with a base resistor connected between the base and the input voltage source. The role of the base resistor is to expand the very small transistor input voltage range (about 0.7 V) to the logical \"1\" level (about 3.5 V) by converting the input voltage into current. Its resistance is settled by a compromise: it is chosen low enough to saturate the transistor and high enough to obtain high input resistance. The role of the collector resistor is to convert the collector current into voltage; its resistance is chosen high enough to saturate the transistor and low enough to obtain low output resistance (high fan-out).\n\nWith two or more base resistors (R and R) instead of one, the inverter becomes a two-input RTL NOR gate (see the figure on the right). The logical operation OR is performed by applying consecutively the two arithmetic operations addition and comparison (the input resistor network acts as a parallel \"voltage summer\" with equally weighted inputs and the following common-emitter transistor stage as a \"voltage comparator\" with a threshold about 0.7 V). The equivalent resistance of all the resistors connected to logical \"1\" and the equivalent resistance of all the resistors connected to logical \"0\" form the two legs of a composed voltage divider driving the transistor. The base resistances and the number of the inputs are chosen (limited) so that only one logical \"1\" is sufficient to create base-emitter voltage exceeding the threshold and, as a result, saturating the transistor. If all the input voltages are low (logical \"0\"), the transistor is cut-off. The pull-down resistor R biases the transistor to the appropriate on-off threshold. The output is inverted since the collector-emitter voltage of transistor Q is taken as output, and is high when the inputs are low. Thus, the analog resistive network and the analog transistor stage perform the logic function NOR.\n\nThe limitations of the one-transistor RTL NOR gate are overcome by the multi-transistor RTL implementation. It consists of a set of parallel-connected transistor switches driven by the logic inputs (see the figure on the right). In this configuration, the inputs are completely separated and the number of inputs is limited only by the small leakage current of the cut-off transistors at output logical \"1\". The same idea was used later for building DCTL, ECL, some TTL (7450, 7460), NMOS and CMOS gates.\n\nThe primary advantage of RTL technology was that it used a minimum number of transistors. In circuits using discrete components, before integrated circuits, transistors were the most expensive component to produce. Early IC logic production (such as Fairchild's in 1961) used the same approach briefly, but quickly transitioned to higher-performance circuits such as diode–transistor logic and then transistor–transistor logic (starting 1963 at Sylvania), since diodes and transistors were no more expensive than resistors in the IC.\n\nThe disadvantage of RTL is its high power dissipation when the transistor is switched on, by current flowing in the collector and base resistors. This requires that more current be supplied to and heat be removed from RTL circuits. In contrast, TTL circuits with \"totem-pole\" output stage minimize both of these requirements.\n\nAnother limitation of RTL is its limited fan-in: 3 inputs being the limit for many circuit designs, before it completely loses usable noise immunity. It has a low noise margin. Lancaster says that integrated circuit RTL NOR gates (which have one transistor per input) may be constructed with \"any reasonable number\" of logic inputs, and gives an example of an 8-input NOR gate.\n\nA standard integrated circuit RTL NOR gate can drive up to 3 other similar gates.\nAlternatively, it has enough output to drive up to 2 standard integrated circuit RTL \"buffers\", each of which can drive up to 25 other standard RTL NOR gates.\n\nVarious companies applied the following speed-up methods to discrete RTL.\n\nTransistor switching speed has increased steadily from the first transistorized computers through the present. The \"GE Transistor Manual\" (7th ed., p. 181, or 3rd ed., p. 97 or intermediate editions) recommends gaining speed by using higher-frequency transistors, or capacitors, or a diode from base to collector (parallel negative feedback) to prevent saturation.\n\nPlacing a capacitor in parallel with each input resistor decreases the time needed for a driving stage to forward-bias a driven stage's base-emitter junction. Engineers and technicians use \"RCTL\" (resistor capacitor transistor logic) to designate gates equipped with \"speed-up capacitors\". The Lincoln Laboratory TX-0 computer's circuits included some RCTL. However, methods involving capacitors were unsuitable for integrated circuits.\n\nUsing a high collector supply voltage and diode clamping decreased collector-base and wiring capacitance charging time. This arrangement required diode clamping the collector to the design logic level. This method was also applied to discrete DTL (diode–transistor logic).\n\nAnother method that was familiar in discrete-device logic circuits used a diode and a resistor, a germanium and a silicon diode, or three diodes in a negative feedback arrangement. These diode networks known as various Baker clamps reduced the voltage applied to the base as the collector approached saturation. Because the transistor went less deeply into saturation, the transistor accumulated fewer stored charge carriers. Therefore, less time was required to clear stored charge during transistor turn off. A low-voltage diode arranged to prevent saturation of the transistor was applied to integrated logic families by using Schottky diodes, as in Schottky TTL.\n\n"}
{"id": "1811814", "url": "https://en.wikipedia.org/wiki?curid=1811814", "title": "SATURN Development Group", "text": "SATURN Development Group\n\nThe SATURN Development Group was an important industry forum that enabled the specification of chip-to-chip interfaces for the communications industry. It was co-founded in 1992 by PMC-Sierra and Sun Microsystems. Several significant specifications were completed through its actions including PL-2, PL-3, and PL-4. Many important semiconductor devices were developed to these specifications. SATURN was also influential in the specification of the ATM Forum's physical layer \"UTOPIA\" standards.\n\nInitial members included SynOptics and Interphase. The first meeting was held in April 1992. By August 1993, the SATURN group had 28 members.\n\nAfter the formation of the Optical Internetworking Forum (OIF), two of the SATURN group's interfaces were successfully adopted by OIF. The PL-3 specification became SPI-3 and the PL-4 specification became SPI-4.2. The existence of the OIF also eliminated the need for the SATURN Development Group, and it was wound down around 2002.\n\n"}
{"id": "796650", "url": "https://en.wikipedia.org/wiki?curid=796650", "title": "Sawfiler", "text": "Sawfiler\n\nA saw filer or saw doctor is a person who maintains and repairs saws in a saw mill. A saw filer's work area in the mill is called the filing room.\n\nSaws used in timber mills are very large and expensive. They need careful maintenance for safe operation. Repair of damaged saws requires a high degree of skill. It takes many years of full-time saw filing to become proficient in the trade.\n\nBandsaws in timber mills range in size from about (4\" x 22ga x 10') to (16\" x 11ga x 62') and can use any of the three main different saw band types: \n\nThe saw filer inspects the saw for needed repairs then gums, fits and benches the saw as necessary. \n\nGumming involves grinding the gullets of the saw teeth to a particular shape. The saw filer uses a semi or fully automatic grinding machine for this. Saw bands operate under high stress and heat and in the presence of wood chips. Carbon migrates into the steel from the wood. Gumming prevents case hardening and fatigue cracking of the saw band gullets. Resaw Bandsaws (teeth on one side only) may be left or right-handed, depending on which way the teeth are pointing and which way the plank falls from the log when cutting. Double cut saws (teeth on both sides) are always gummed right hand teeth first.\n\nA precise profile of the tooth (including gullet area, hook angle and top clearance angle) must be maintained for proper saw operation and wood chip removal. Ease of cutting greatly depends on this. The shape is determined by the type of wood and cutting conditions. A saw filer will maintain the gullet shape by manually shaping the grinding wheel with a dressing stone, and the set up of his grinding machine. Variations include face angle, face length, back angle, gullet width and depth, and a frost notch (if necessary). Typical bandsaw tooth dimensions are 1-3/4\" tooth space x 3/4\" gullet depth x 3/4\" gullet width (grinding wheel width) x 30deg face angle x 16deg back angle.\n\nFitting means tooth dressing and involves swaging, shaping, gauging, and grinding. The tip of the saw tooth is swaged to a flare, then the sides are compressed in slightly with a shaper tool to an exact kerf. Then a final grinding pass is made. The usual gauged tolerance is +/- .005\" in kerf, and < .003\" side to side variation. The same grinding machinery used for gumming is used for fitting.\n\nThe saw kerf is usually made this way from the base saw metal. Sometimes, however, the kerf is made with stellite or carbide tips, in which case swaging and shaping isn't needed, although gumming is still required. The kerf may also be 'set' with a punch and hammer, with the teeth bent left, right, left... Set teeth are rarely used.\n\nBenching is the leveling and tensioning of the saw. When a saw band is run on a mill it is stretched with thousands of pounds of force, and during operation the cutting edge heats up. These forces and temperatures cause the saw to deform. Benching deforms an un-mounted saw in a way that counteracts the operating stresses, and allows the saw to pull flat and cut straight when in use. It takes months to learn benching.\n\nBenching is done in a dark room with a stretcher-roller machine and flat anvil. A single light at the benchman’s work station, along with ground gauges, allows the saw filer to measure level and tension. \n\nLeveling is done with a crossface hammer and stretcher-roller adjustments. Cross face hammers are available in left and right hand versions. Each filer has his own hammer which he carefully dresses.\n\nTensioning is done with the stretcher-roll. This machine has hardened rollers above and below the saw. They rotate slowly (one is powered, while one runs free) and pinch the saw when a lever is cranked, rolling a thin strip through the length of the saw, stretching the metal where it was rolled. Careful placement and force of the rolls deform the metal in a way that counteracts the forces the saw sees during operation. More rolls are placed in the midsection of the saw. Resaws have the back pulled to counteract the uneven heating of the cutting edge. This is done by rolling the back (non cutting edge) of the saw. The back is measured with a three pin gauge, and is usually around .003\" per three feet curved. \n\nBenching involves the simultaneous solution of multiple deformations introduced to the saw to counteract the predicted stresses of the saw in operation. Benchman can easily recognize variations in steel batches.\n\nOther bandsaw duties include welding broken teeth, fixing cracks, and trouble shooting operating problems.\n\nCNC equipment has evolved to the point of being able to do significant benching and fitting tasks.\n\nMost of the above terms are North American and are called different things in Australia, New Zealand as well as else where in the world. \nA Sawdoctor does both the tasks of the Benchman and Filler at the same time, with no distinction between the tasks as well as having to do both circular saws and bandsaws.\nThis like filing rooms are called Saw Shops in Australia. Most Saw Mills in Australia and New Zealand run a stellite tipped bandsaw in which the majority of what is stated above becomes redundant as it is specifically for sharpening and making the swaged tipped saws.\n\nSaw filers have the same maintenance duties with circular saws as they do with band saws, with a few exceptions;\n\n"}
{"id": "58721191", "url": "https://en.wikipedia.org/wiki?curid=58721191", "title": "Simulate Loam Substrate", "text": "Simulate Loam Substrate\n\nSimulate Loam Substrate, or mechanism-based Loam Substrate() is an ecological environment green governance technology, based upon the concept of restoring Nature in a natural way, developed and put into operation by Zhang Bo, general manager of Jiangsu Lvyan Ecological Technology Co., Ltd.\n\nRestore Nature in a Natural way is the technical concept of \"Simulate Loam Substrate\", and this technology is applied to form the ideal soil structure, select suitable plant species to ensure the proportion of trees and shrubs in the later plant communities, so as to restore Nature.\nAs the ecological environment green governance technology, the core of \"Simulate Loam Substrate\" is to combine the engineering, botany, soil science and other disciplines to simulate the loam matrix structure suitable for plant growth through biomimetic technology, which is beneficial to plant seeds, root development, microbial activity and nutrient transformation.\n\nSimulate Loam Substrate can remold soil layer structure, resist erosion and control the growth ratio of trees and shrubs.\n\nSimulate Loam Substrate can be used in real estate development surrounding landscape mountain management, high and steep slope treatment of highway and railway and open pit slope environmental treatment.\n"}
{"id": "18650595", "url": "https://en.wikipedia.org/wiki?curid=18650595", "title": "StarDraw", "text": "StarDraw\n\nFounded in 1993 by ex-Microsoft development manager David Snipp Stardraw is a company that makes audio/visual system integration and design software.\n\nStardraw has two different but related sets of software both for the Audio-visual (A/V) market\n\nStardraw's design software is for creating documentation of audio/visual systems. This includes A/V schematics (similar to a Computer network diagram), Rack Layouts, Presentation Drawings (Pictorial Schematics), Panel Layouts for custom metalwork, Plan View drawings, and associated reports such as Bills of Materials, Quotations and Cable Schedules.\n\nThe software includes preset equipment icons to make it quick to create an illustrations of a A/V system design.\n\nTheir software of this type includes\n\n\nStardraw control is their Integrated development environment for creating Touchscreen remote control of a wide variety of equipment.\n\nTypical uses include room automation in boardrooms, auditoriums, museums or home theaters, where users use fixed and wireless touch-screens to control devices such as video projectors and displays, PCs, DVD and VCR players and recorders, cameras, teleconferencing systems, audio/video switchers and processing equipment, motorized projection screens, drapes, lighting, HVAC systems, and a wide variety of other types of equipment. Other common uses include entertainment systems, industrial command and control centers, security systems, hotels and restaurants.\n\nWhat separates their software from rivals AMX and Crestron is that it does not require any special hardware instead it runs on any machine running Microsoft Windows, further more the drivers and scripts for it are written in the general programming language C# rather than a proprietary language and designed in a graphical environment similar to that used by Microsoft's programming languages.\n\nThe software also present a Web service interface which enables non-windows devices to control the software for example Tablet computers such as Apples iPad\n\n\nSound & Communications Magazine - 20 Years with Stardraw.com\n\n"}
{"id": "479889", "url": "https://en.wikipedia.org/wiki?curid=479889", "title": "The Land Institute", "text": "The Land Institute\n\nThe Land Institute is a non-profit research, education, and policy organization dedicated to sustainable agriculture based in Salina, Kansas, United States. Their goal is to develop an agricultural system based on perennial crops that \"has the ecological stability of the prairie and a grain yield comparable to that from annual crops\". The organization has trademarked Kernza perennial grain, an intermediate wheatgrass grain in development.\n\nThe institute was founded on 28 acres in 1976 by plant geneticist and MacArthur \"genius grant\" recipient Wes Jackson and Dana Jackson, who has worked with the Land Stewardship Project in Minnesota. As of 2014, the organization owns at least 879 acres of land.\n\nThe Land Institute promotes \"natural systems agriculture\" through plant breeding. Land Institute scientists are cross breeding the annual crop plants wheat, sorghum, sunflower, and legume with wild, perennial relatives to create perennial varieties. Using selective breeding and other techniques, they also are working to domesticate wild perennials. The organization's concept of developing perennial crops is modeled after the ecological design of prairies, which are known for their soil quality, deep root systems, and self-sufficiency. In an interview, Wes Jackson called the concept \"an inversion of industrial agriculture.\" Perennial polyculture systems may have a variety of benefits over conventional annual monocultures such as increased biodiversity, reduced soil erosion, and reduced inputs of irrigation, fossil fuels, fertilizers, and pesticides. Perennial crops also show promise in root-based carbon sequestration. The organization's achievement of productive and genetically stable perennial crop plants for use by farmers is expected to take several decades. Critics note the future economic challenge in profitably harvesting perennial polyculture.\n\nSince 1979, The Land Institute has annually hosted its Prairie Festival, which includes lectures, art displays, tours, and music performances.\n\nThe Land Institute has developed an intermediate wheatgrass (\"Thinopyrum intermedium\") grain through its breeding program under Dr. Lee DeHaan, trademarked as Kernza® perennial grain. A perennial grain is a grain crop that lives and remains productive for two or more years. Rather than growing for only one season before harvest, like most grains and annual crops, perennial grains grow year after year. As the first perennial grain crop grown across the northern United States, Kernza is expected to dramatically change agriculture, making croplands multifunctional through the production of both food and ecosystem services.\n\nProducts\n\nKernza breeding has dramatically increased seed size and production, hastening the timeline of commercialization, and resulting in the release of the first widely-available Kernza product, Long Root Ale from Patagonia Provisions, in 2016.\n\nThe initiative and investment on the part of Patagonia Provisions to bring Long Root Ale to market helped pave the way for other partnerships and potential Kernza® products becoming more widely available to consumers.\n\nCurrently, there are a number of restaurants serving products made with Kernza®, including Birchwood Cafe in Minneapolis, The Perennial in San Francisco, Cafe Gratitude in the Los Angeles metro, and Avalanche Pizza in Athens, OH.\n\nHopworks Urban Brewery in Portland, OR and Vancouver, WA brewed Long Root Ale for Patagonia Provisions and has it on tap, in addition to the ale in four-pack cans being sold in Whole Foods in California. Bang! Brewing in St. Paul, MN has a Kernza® beer available, as does Blue Skye Brewery near us in Salina, KS.\n\nInnovative Dumpling & Strand produces Kernza® pasta that they retail through Twin Cities-area farmers’ markets. \n\nAdditionally, Cascadian Farm plans to incorporate Kernza® into some of its foods, with expectations for products made with Kernza® available in retail markets by late 2019. Cascadian Farm has agreed to purchase an initial amount of the perennial grain, which is driving farmers to plant on commercial-scale fields versus the test sized plots currently being grown.\n\nEcological Benefits \n\nWith perennial soil cover such as that provided by Kernza, farmers stand to greatly reduce soil erosion, potentially turning agriculture into a soil-forming ecosystem, much like the natural ecosystems it replaced. Initial research suggests that due to extensive perennial roots, Kernza and other perennial crops may nurture beneficial soil microbiomes. The frequent soil disturbance required in annual crop production is disruptive to these microbiomes.\n\nDeeper and more abundant root systems drive healthy soil. Scientific evidence documenting the ecosystem benefits of Kernza is accumulating. Research from other perennial systems such as pastures and perennial biofuel crops provide robust evidence of the potential benefits of a perennial grain like Kernza. \n\nFor example, Paustian and colleagues recently published a paper in Nature titled “Climate-Smart Soils” that compares different landscape management approaches for increasing soil carbon sequestration. It is clear from their analysis that perennial grains would be a game-changer, as they could sequester carbon and maintain more cropland in production better than any alternative.\n\nPerennial Grains Story Project\n\nThe Perennial Grains Story Project is a strategic communications collaborative whose goal is to sustain enthusiasm and support for perennial grain polyculture development, and Kernza use in particular, as part of a holistic vision for more truly sustainable food production. The partnership is enhancing internal communications among Kernza users and breeders, while working to create communications products that serve the diversity of partner goals and interest.\n\nThe Land Institute's work was featured in Michael Pollan's \"New York Times\" best-seller \"The Omnivore’s Dilemma: A Natural History of Four Meals\". The general modus operandi of developing a sustainable, high yield, low labor, agricultural model based on the culturation of crop polycultures, developed by The Land Institute forms the substance of the chapter \"How Will We Feed Ourselves?\" in Janine Benyus's book, \"Biomimicry: Innovation Inspired by Nature\".\n\n\n"}
{"id": "36179328", "url": "https://en.wikipedia.org/wiki?curid=36179328", "title": "Transgenerational design", "text": "Transgenerational design\n\nTransgenerational design is the practice of making products and environments compatible with those physical and sensory impairments associated with human aging and which limit major activities of daily living. The term \"transgenerational design\" was coined in 1986, by Syracuse University industrial design professor James J. Pirkl to describe and identify products and environments that accommodate, and appeal to, the widest spectrum of those who would use them—the young, the old, the able, the disabled—without penalty to any group.\nThe transgenerational design concept emerged from his federally funded design-for-aging research project, \"Industrial design Accommodations: A Transgenerational Perspective\". The project's two seminal 1988 publications provided detailed information about the aging process; informed and sensitized industrial design professionals and design students about the realities of human aging; and offered a useful set of guidelines and strategies for designing products that accommodate the changing needs of people of all ages and abilities.\n\nThe transgenerational design concept establishes a common ground for those who are committed to integrating age and ability within the consumer population. Its underlying principle is that people, including those who are aged or impaired, have an equal right to live in a unified society.\n\nTransgenerational design practice recognizes that human aging is a continuous, dynamic process that starts at birth and ends with death, and that throughout the aging process, people normally experience occurrences of illness, accidents and declines in physical and sensory abilities that impair one’s independence and lifestyle. But most injuries, impairments and disabilities typically occur more frequently as one grows older and experiences the effects of senescence (biological aging). Four facts clarify the interrelationship of age with physical and sensory vulnerability:\n\n\nWithin each situation, consumers expect products and services to fulfill and enhance their lifestyle, both physically and symbolically. Transgenerational design focuses on serving their needs through what Cagan and Vogel call “a value oriented product development process”. They note that a product is “deemed of value to a customer if it offers a strong effect on lifestyle, enabling features, and meaningful ergonomics” resulting in products that are “\"useful\", \"usable\", and \"desirable\"” during both short and long term use by people of all ages and abilities.\n\nTransgenerational design is “framed as a market-aware response to population aging that fulfills the need for products and environments that can be used by both young and old people living and working in the same environment”.\n\nTransgenerational design benefits all ages and abilities by creating a harmonious bond between products and the people that use them. It satisfies the psychological, physiological, and sociological factors desired—and anticipated—by users of all ages and abilities:\n\n\nTransgenerational design addresses each element and accommodates the user—regardless of age or ability—by providing a sympathetic fit and unencumbered ease of use. Such designs provide greater accessibility by offering wider options and more choices, thereby preserving and extending one’s independence, and enhancing the quality of life for all ages and abilities—at no group’s expense.\n\nTransgenerational designs accommodate rather than discriminate and sympathize rather than stigmatize. They do this by:\n\n\nTransgenerational design emerged during the mid-1980s coincident with the conception of universal design, an outgrowth of the disability rights movement and earlier barrier-free concepts. In contrast, transgenerational design grew out of the Age Discrimination Act of 1975 (ADA), which prohibited “discrimination on the basis of age in programs and activities receiving Federal financial assistance”, or excluding, denying or providing different or lesser services on the basis of age. The ensuing political interest and debate over the Act’s 1978 amendments, which abolished mandatory retirement at age 65, made the issues of aging a major public policy concern by injecting it into the mainstream of societal awareness.\n\nAt the start of the 1980s, the oldest members of the population, having matured during the great depression, were being replaced by a generation of Baby Boomers, steadily reaching middle age and approaching the threshold of retirement. Their swelling numbers signaled profound demographic changes ahead that would steadily expand the aging population throughout the world.\n\nAdvancements in medical research were also changing the image of old age—from a social problem of the sick, poor, and senile, whose solutions depend on public policy—to the emerging reality of an active aging population having vigor, resources, and time to apply both.\n\nResponding to the public’s growing awareness, the media, public policy, and some institutions began to recognize the impending implications. \"Time\" and \"Newsweek\" devoted cover stories to the \"Greying of America\". Local radio stations began replacing their rock-and-roll formats with music targeted to more mature tastes. The \"Collegiate Forum\" (Dow Jones & Co., Inc.) devoted its Fall 1982 issue entirely to articles on the aging work force. A \"National Research Conference on Technology and Aging\", and the \"Office of Technological Assessment of the House of Representatives\", initiated a major examination of the impact of science and technology on older Americans”.\n\nIn 1985, the National Endowment for the Arts, the Administration on Aging, the Farmer’s Home Administration, and the Department of Housing and Urban Development signed an agreement to improve building, landscape, product and graphic design for older Americans, which included new research applications for old age that recognized the potential for making products easier to use by the elderly, and therefore more appealing and profitable.\n\nIn 1987, recognizing the implications of population aging, Syracuse University’s \"Department of Design\", \"All-University Gerontology Center\", and \"Center for Instructional Development\" initiated and collaborated on an interdisciplinary project, \"Industrial Design Accommodations: A Transgenerational Perspective\". The year-long project, supported by a Federal grant, joined the knowledge base of gerontology with the professional practice of industrial design.\n\nThe project defined “the three aspects of aging as physiological, sociological, and psychological; and divided the designer’s responsibility into aesthetic, technological, and humanistic concerns”.\nThe strong interrelationship between the physiological aspects of aging and industrial design’s humanistic aspects established the project’s instructional focus and categorized the physiological aspects of aging as the sensory and physical factors of \"vision\", \"hearing\", \"touch\", and \"movement\". This interrelationship was translated into a series of reference tables, which related specific physical and sensory factors of aging, and were included in the resulting set of design guidelines to:\n\n\nThe project produced and published two instructional manuals—one for instructors and one for design professionals—each containing a detailed set of \"design guidelines and strategies for designing transgenerationalproducts\". Under terms of the grant, instructional manuals were distributed to all academic programs of industrial design recognized by the National Association of Schools of Art and Design (NASAD).\n\n\nContinuing to emerge as a growing strategy for developing products, services and environments that accommodate people of all ages and abilities, \"transgenerational design has been adopted by major corporations, like Intel, Microsoft and Kodak” who are “looking at product development the same way as designing products for people with visual, hearing and physical impairments,” so that people of any age can use them.\n\nDiscussions between designers and marketers are indicating that successful transgenerational design “requires the right balance of upfront research work, solid human factors analysis, extensive design exploration, testing and a lot of thought to get it right”, and that “transgenerational design is applicable to any consumer products company—from appliance manufacturers to electronics companies, furniture makers, kitchen and bath and mainstream consumer products companies”.\n"}
{"id": "1118718", "url": "https://en.wikipedia.org/wiki?curid=1118718", "title": "Transit-oriented development", "text": "Transit-oriented development\n\nIn urban planning, a transit-oriented development (TOD) is a type of urban development that maximizes the amount of residential, business and leisure space within walking distance of public transport. In doing so, TOD aims to increase public transport ridership by reducing the use of private cars and by promoting sustainable urban growth.\n\nA TOD typically includes a central transit stop (such as a train station, or light rail or bus stop) surrounded by a high-density mixed-use area, with lower-density areas spreading out from this center. A TOD is also typically designed to be more walkable than other built-up areas, through using smaller block sizes and reducing the land area dedicated to automobiles.\n\nThe densest areas of a TOD are normally located within a radius of ¼ to ½ mile (400 to 800 m) around the central transit stop, as this is considered to be an appropriate scale for pedestrians, thus solving the last mile problem.\n\nMany of the new towns created after World War II in Japan, Sweden, and France have many of the characteristics of TOD communities. In a sense, nearly all communities built on reclaimed land in the Netherlands or as exurban developments in Denmark have had the local equivalent of TOD principles integrated in their planning, including the promotion of bicycles for local use.\n\nIn the United States, a half-mile-radius circle has become the de facto standard for rail-transit catchment areas for TODs. A half mile (800 m) corresponds to the distance someone can walk in 10 minutes at and is a common estimate for the distance people will walk to get to a rail station. The half-mile ring is a little more than in size.\n\nTransit-oriented development is sometimes distinguished by some planning officials from \"transit-proximate development\" (see, e.g., comments made during a Congressional hearing ) because it contains specific features that are designed to encourage public transport use and differentiate the development from urban sprawl. A few examples of these features include mixed-use development that will use transit at all times of day, excellent pedestrian facilities such as high quality pedestrian crossings, narrow streets, and tapering of buildings as they become more distant from the public transport node. Another key feature of transit-oriented development that differentiates it from \"transit-proximate development\" is reduced amounts of parking for personal vehicles.\n\nOpponents of compact, or transit oriented development typically argue that Americans, and persons throughout the world, prefer low-density living, and that any policies that encourage compact development will result in substantial utility decreases and hence large social welfare costs. Proponents of compact development argue that there are large, often unmeasured benefits of compact development or that the American preference for low-density living is a misinterpretation made possible in part by substantial local government interference in the land market.\n\nMany cities throughout the world are developing TOD policy. Toronto, Portland, Montreal, San Francisco, and Vancouver among many other cities have developed, and continue to write policies and strategic plans, which aim to reduce automobile dependency and increase the use of public transit.\n\nOne of the earliest and most successful examples of TOD is Curitiba, Brazil.\nCuritiba was organized into transport corridors very early on in its history. Over the years, it has integrated its zoning laws and transportation planning to place high-density development adjacent to high-capacity transportation systems, particularly its BRT corridors. Since the failure of its first, rather grandiose, city plan due to lack of funding, Curitiba has focused on working with economical forms of infrastructure, so it has arranged unique adaptations, such as bus routes (inexpensive infrastructure) with routing systems, limited access and speeds similar to subway systems. The source of innovation in Curitiba has been a unique form of participatory city planning that emphasizes public education, discussion and agreement.\n\nIn an attempt to control rapid growth of Guatemala City, the long-time Mayor of Guatemala City Álvaro Arzú implemented a plan to control growth based on transects along important arterial roads and exhibiting transit-oriented development (TOD) characteristics. This plan adopted POT (Plan de Ordenamiento Territorial) aims to allow the construction of taller, mixed-use building structures right by large arterial roads; the buildings would gradually decrease in height and density the farther they are from arterial roads. This is simultaneously being implemented along with a bus rapid transit (BRT) system called Transmetro.\n\nMexico City has battled pollution for years. Many attempts have been made to orient citizens towards public transportation. Expansion of metro line, both subway and bus, have been instrumental. Following the example of Curtiba, many bus-lines were created on many of Mexico City's most important streets. The bus-line has taken two lanes from cars to be used only by the bus-line, increasing the flow for bus transit.\n\nThe city has also made great attempts at increasing the number of bikelanes, including shutting down entire roads on certain days to be used only by bikers. \n\nCar regulations have also increased in the city. New regulations prevent old cars from driving in the city, other cars from driving on certain days. Electric cars are allowed to be driven everyday and have free parking. Decreasing the public space allocated to cars and increasing regulations have become a great annoyance among daily car users. The city hopes to push people to use more public transport.\n\nMost of the suburban high rises were not along major rail lines like other cities until recently, when there has been incentive to do so. Century Park is a growing condo community in southern Edmonton at the south end of Edmonton's LRT. It will include low to high rise condos, recreational services, shops, restaurants, and a fitness centre. Edmonton has also had a transit-proximate development for some time in the northeastern suburbs at Clareview which includes a large park and ride, and low rise apartments among big box stores and associated power center parking. Edmonton is also looking into some new TODs in various parts of the city. In the northeast, there are plans to redevelop underutilized land at two sites around existing LRT, Fort Road and Stadium station. In the west, there is plans to have some medium density condos in the Glenora neighbourhood along a future LRT route as well as a TOD in the southeast in the Strathearn neighbourhood along the same future LRT on existing low rise apartments.\n\nAccording to the Metropolitan Development and Planning Regulation of late 2011, 40% of new households will be built as TOD neighbourhoods.\n\nOttawa's City Council has established transit-oriented development (TOD) priority areas in proximity to Ottawa's Light Rail Transit. These priority areas are a mix of moderate to high-density transit-supportive developments within a 600-metre walking distance of rapid transit stations.\n\nToronto has a longstanding policy of encouraging new construction along the route of its primary Yonge Street subway line. Most notable are the development of the Yonge and Eglinton area in the 1960s and 1970s; and the present development of the 2 km of the Yonge Street corridor north of Sheppard Avenue, which began in the late 1980s. In the period since 1997 alone the latter stretch has seen the appearance of a major new shopping centre and the building and occupation of over twenty thousand new units of condominium housing. Since the opening of the Sheppard subway line in 2002, there is a condominium construction boom along the route on Sheppard Avenue East between Yonge Street and Don Mills Road.\nVancouver has a strong history of creating new development around its SkyTrain lines and building regional town centres at major stations and transit corridors. Of note is the Metrotown area of the suburb of Burnaby, British Columbia near the Metrotown SkyTrain Station. The areas around stations have spurred the development of billions of dollars of high-density real estate, with multiple highrises near the many stations, prompting concerns about rapid gentrification.\n\nThere is currently one TOD being built in Winnipeg beside the rapid transit corridor. It is known as The Yards at Fort Rouge, and was spearheaded by the developer Gem Equities. In phase two of the southwest rapid transit corridor, there will be four more TODs. This phase is an interesting example of the use of fine arts in parallel with transit planning, making several of the stations sites for public art related to the social history of the area. \n\nFor over 30 years, the government has pursued a development strategy of concentrating much of its new development within from the County's Washington Metro rapid transit stations and the high-volume bus lines of Columbia Pike. Within the transit areas, the government has a policy of encouraging mixed-use and pedestrian- and transit-oriented development. Some of these \"urban village\" communities include: Rosslyn, Ballston, Clarendon, Courthouse, Pentagon City, Crystal City, Lyon Village, Shirlington, Virginia Square, and Westover\n\nIn 2002, Arlington received the EPA's National Award for Smart Growth Achievement for \"Overall Excellence in Smart Growth\" — the first ever granted by the agency.\n\nIn September 2010, Arlington County, Virginia, in partnership with Washington, D.C., opened Capital Bikeshare, a bicycle sharing system. By February 2011, Capital Bikeshare had 14 stations in the Pentagon City, Potomac Yard, and Crystal City neighborhoods in Arlington. Arlington County also announced plans to add 30 stations in fall 2011, primarily along the densely populated corridor between the Rosslyn and Ballston neighborhoods, and 30 more in 2012.\n\nThe city has developed within its plan as of 2007 standardization measures. For instance, streets' width has been set according to the position of the site.\n\nNew Jersey has become a national leader in promoting transit oriented development. The New Jersey Department of Transportation established the Transit Village Initiative in 1999, offering multi-agency assistance and grants from the annual $1 million fund to any municipality with a ready-to-go project specifying appropriate mixed land-use strategy, available property, station-area management, and commitment to affordable housing, job growth, and culture. Transit village development must also preserve the architectural integrity of historically significant buildings. Since 1999 the state has made 30 Transit Village designations, which are in different stages of development:\n\nPleasantville (1999), Morristown (1999), Rutherford (1999), South Amboy (1999), South Orange (1999), Riverside (2001), Rahway (2002), Metuchen (2003), Belmar (2003), Bloomfield (2003), Bound Brook (2003), Collingswood (2003), Cranford (2003) Matawan (2003), New Brunswick (2005), Journal Square/Jersey City (2005), Netcong (2005), Midtown Elizabeth (2007), Burlington City (2007), Orange (2009), Montclair (2010), Somerville (2010), Linden (2010), West Windsor (2012), Dunellen (2012), Plainfield (2014), Park Ridge (2015), and Irvington (2015).\n\nThe East Liberty neighborhood is nearing completion of a $150 million Transit Oriented Development centered around the reconfigured East Liberty Station on the city's Martin Luther King Jr. East Busway. The development included improved access to the station with a new pedestrian bridge and pedestrian walkways that increase the effective walkshed of the station. The East Busway is a fixed guideway route that offers riders an 8-minute ride from East Liberty to Pittsburgh's Downtown.\n\nThe Salt Lake City Metro Area has seen a strong proliferation of transit-oriented developments due to the construction of new transit lines within the Utah Transit Authority's TRAX, \"FrontRunner\" and streetcar lines. New developments in West Valley, Farmington, Murray, Provo, Kaysville, Sugarhouse and downtown Salt Lake City have seen rapid growth and construction despite the economic downturn. The population along the Wasatch Front has reached 1.7 million and is expected to grow 50% over the next two decades. At 29.8%, Utah's population growth more than doubled the population growth of the nation (13.2%), with a vast majority of this growth occurring along the Wasatch Front.\n\nTransportation infrastructure has been vastly upgraded in the past decade as a result of the 2002 Olympic Winter Games and the need to support the growth in population. This has created a number of transit-oriented commercial and residential projects to be proposed and completed.\n\nThe San Francisco Bay Area includes nine counties and 101 cities, including San Jose, San Francisco, Oakland and Fremont. Local and regional governments encourage transit-oriented development to decrease traffic congestion, protect natural areas, promote public health and increase housing options. The region has designated Priority Development Areas and Priority Conservation Areas. Current population forecasts for the region predict that it will grow by 2 million people by 2035 due to both the natural birth rate and job creation, and estimate that 50% of this growth can be accommodated in Priority Development Areas through transit-oriented development.\n\nMajor transit village projects have been developed over the past 20 years at several stations linked to the Bay Area Rapid Transit (BART) system. In their 1996 book, \"Transit Villages in the 21st Century\", Michael Bernick and Robert Cervero identified emerging transit villages at several BART stations, including Pleasant Hill / Contra Costa Centre, Fruitvale, Hayward and Richmond. MacArthur Station is a relatively new development, with construction beginning in 2011 and scheduled for completion after 2019.\n\nCompared to other developed economies, the car ownership rate in Hong Kong is very low, and approximately 90% of all trips are made by public transport.\n\nIn the mid-20th century, no railway was built until an area was well developed. However, in recent decades, Hong Kong has started to have some TODs, where a railway is built simultaneously with residential development above or nearby, dubbed the \"Rail plus Property\" (R+P) Model. Examples include:\n\n\nBandar Malaysia is an upcoming development by 1Malaysia Development Berhad (1MDB).\n\nMelbourne, Victoria is expected to reach a population of 5 million by 2030 with the overwhelming majority of its residents relying on private automobiles. Since the turn of the century, sporadic efforts have been made by various levels of government to implement transit-oriented development principles. However, a lack of commitment to funding public transport infrastructure, resulting to overcrowding and amending zoning laws has dramatically slowed progress toward sustainable development for the city.\n\nMilton, an inner suburb of Brisbane, has been identified as Queensland's first transit-oriented development under the Queensland Government's South East Queensland Regional Plan. Milton railway station will undergo a multimillion-dollar revamp as part of the development of The Milton Residences to promote and encourage residents to embrace rail travel. This will include a new ticketing office, new public amenities, increased visibility across platforms and new and improved access points off Milton Road and Railway Terrace.\n\nThe term transit-oriented development, as a US-born concept, is rarely used in Europe, although many of the measures advocated in transit-oriented development are also stressed here. Many European cities have long been built around transit systems and there has thus often been little or no need to differentiate this type of development with a special term as has been the case in the US. An example of this is Copenhagen's Finger Plan from 1947, which embodied many transit-oriented development aspects and is still used as an overall planning framework today. Recently, scholars and technicians have taken interest in the concept, however.\n\nWhereas the city of Paris has a centuries-long history, its main frame dates to the 19th century. The subway network was made to solve both linkage between the five main train stations and local transportation assets for citizens. The whole area of Paris City has metro stations no more than 500 metres apart. Recent bicycle and car rental systems (Velib and Autolib) also ease travel, in the very same way that TOD emphasizes.So do the new trams linking suburbs close to Paris proper, and tramline 3 around the edge of the city of Paris.\n\nIn the Southern part of the Randstad will be built a neighbourhood according to the principles of TOD.\n\nOne criticism of transit-oriented development is that it has the potential to spur gentrification in low-income areas. In some cases, TOD can raise the housing costs of formerly affordable neighborhoods, pushing low- and moderate-income residents farther away from jobs and transit. When this happens, TOD projects can disrupt low-income neighborhoods.\n\nWhen executed with equity in mind, however, TOD has the potential to benefit low- and moderate-income (LMI) communities: it can link workers to employment centers, create construction and maintenance jobs, and has the potential to encourage investment in areas that have suffered neglect and economic depression. Moreover, it is well recognized that neighborhood development restrictions, while potentially in the immediate neighborhood's best interest, contribute to regional undersupply of housing and drive up the cost of housing in general across a region. TOD reduces the overall cost of housing in a region by contributing to the housing supply, and therefore generally improves equity in the housing market. TOD also reduces transportation costs, which can have a greater impact on LMI households since they spend a larger share of their income on transportation relative to higher-income households. This frees up household income that can be used on food, education, or other necessary expenses. Low-income people are also less likely to own personal vehicles and therefore more likely to depend exclusively on public transportation to get to and from work, making reliable access to transit a necessity for their economic success.\n\n\n"}
{"id": "172761", "url": "https://en.wikipedia.org/wiki?curid=172761", "title": "Tricycle", "text": "Tricycle\n\nA tricycle, often abbreviated to trike, is a human-powered (or gravity-powered) three-wheeled vehicle.\n\nSome tricycles, such as cycle rickshaws (for passenger transport) and freight trikes, are used for commercial purposes, especially in the developing world, particularly Africa and Asia.\n\nIn the West, adult-sized tricycles are used primarily for recreation, shopping, and exercise. Tricycles are favoured by children and senior adults for their apparent stability versus a bicycle; however a conventional trike has poor dynamic lateral stability, and the rider must take care when cornering to avoid tipping the trike over. Unconventional designs such as recumbents have a lower centre of gravity so require less care.\n\nA three-wheeled wheelchair was built in 1655 or 1680 by a disabled German man, Stephan Farffler, who wanted to be able to maintain his mobility. Since he was a watch-maker, he was able to create a vehicle that was powered by hand cranks.\n\nIn 1789, two French inventors developed a three-wheeled vehicle, powered by pedals; They called it the tricycle.\n\nIn 1818, British inventor Denis Johnson patented his approach to designing tricycles. In 1876, James Starley developed the Coventry Lever Tricycle, which used two small wheels on the right side and a large drive wheel on the left side; power was supplied by hand levers. In 1877, Starley developed a new vehicle he called the Coventry Rotary, which was \"one of the first rotary chain drive tricycles.\" Starley's inventions started a tricycling craze in Britain; by 1879, there were \"twenty types of tricycles and multi-wheel cycles ... produced in Coventry, England, and by 1884, there were over 120 different models produced by 20 manufacturers.\" The first front steering tricycle was manufactured in 1881 by The Leicester Safety Tricycle Company of Leicester, England, which was brought to the market in 1882 costing £18. They also developed a folding tricycle at the same time.\n\nTricycles were used by riders who did not feel comfortable on the high wheelers, such as women who wore long, flowing dresses (see rational dress).\n\nIn the UK, upright tricycles are sometimes referred to as \"barrows\". Many trike enthusiasts in the UK belong to the Tricycle Association, formed in 1929. They participate in day rides, tours, time trials, and a criterium (massed start racing) series. \n\nA delta tricycle has one front wheel and two rear wheels.\n\nA tadpole tricycle has two front wheels and one rear wheel. Rear wheel steering is sometimes used, although this increases the turning circle and can affect handling (the geometry is similar to a regular tricycle operating in reverse, but with a steering damper added).\n\nSome early pedal tricycles from the late 19th century used two wheels in tandem on one side and a larger driving wheel on the other.\n\nAn in-line three-wheeled vehicle has two steered wheels, one at the front and the other in the middle or at the rear.\n\nUpright resembles a two-wheeled bicycle, traditionally diamond frame, or open frame, but with either two widely spaced wheels at the back (called \"delta\") or two wheels at the front (called \"tadpole\"). The rider straddles the frame in both delta and tadpole configurations. Steering is through a handlebar directly connected to the front wheel via a conventional bicycle fork in delta, or via a form of Ackermann steering geometry in the case of the upright tadpole.\n\nAll non-tilting trikes have stability issues and great care must be used when riding a non tilting upright trike. The center of gravity is quite high compared to recumbent trikes. Because of this, non-tilting trikes are more prone to tipping over in corners and on uneven or sloping terrain. Conversely, the rider enjoys better visibility than on a recumbent because their head is higher.\n\nRecumbent trikes' advantages (over conventional trikes) include stability (through low centre of gravity) and low aerodynamic drag. Disadvantages (compared to bicycles) include greater cost, weight, and width. The very low seat may make entry difficult, and on the road they may be less visible to other traffic.\n\nRecumbent delta is similar to an upright, with two wheels at the back and one at the front, but has a recumbent layout in which the rider is seated in a chair-like seat. One or both rear wheels can be driven, while the front is used for steering (the usual layout). Steering is either through a linkage, with the handlebars under the seat (under seat steering) or directly to the front wheel with a large handlebar (over seat steering). Some delta trikes can be stored upright by lifting the front wheel and resting the top of the seat on the ground.\n\nDelta trikes generally have higher seats and a tighter turning radius than tadpole trikes. The tight turning radius is necessary if riding on trails with offset barriers, or navigating around closely placed obstacles. The higher seat makes mounting and dismounting easier. Even with the higher seat a delta trike can be quite stable provided most of the weight (including the rider) is shifted back towards the rear wheels. Many delta trikes place the seat too far forward and that takes weight off the two rear wheels and puts more weight onto the front wheel making the trike more unstable. The Hase Kettwiesel delta trike has an high seat that is placed to put most of the weight onto the cambered rear wheels making it more stable.\n\nDelta trikes are suitable to be used as manual scooters for mobility, rehab and/or exercise. The Hase Lepus Comfort is an example of a rehab delta trike designed mainly for comfort and ease of use. It has a lowered front boom and the seat can be adjusted to a height of , which aids in mounting and dismounting. It also has rear wheel suspension for comfort. The Lepus can be folded for easier storage and transportation.\n\nThe weight of a delta trike can be quite close to the weight of a tadpole trike if they are both of a similar quality and similar materials are used. The Hase Kettwiesel Allround delta trike has an aluminium frame and weighs 39.4 lbs (17.9 kg). The Catrike Road tadpole trike has an aluminium frame and weighs 37.5 lbs (17 kg).\n\nRecumbent tadpole or reverse trike is a recumbent design with two steered wheels at the front and one driven wheel at the back, though one model has the front wheels driven while the rear wheel steers. Steering is either through a single handlebar linked with tie rods to the front wheels' stub axle assemblies (indirect) or with two handlebars (rather, two half-handlebars) each bolted to a steerer tube, usually through a bicycle-type headset and connected to a stub axle assembly (direct). A single tie rod connects the left and right axle assemblies.\n\nThe tadpole trike is often used by middle-aged or retiree-age former bicyclists who are tired of the associated pains from normal upright bikes. With its extremely low center of gravity, aerodynamic layout and light weight (for trikes), tadpoles are considered the highest performance trikes.\n\nMost Velomobiles are built in a tadpole trike configuration since a wide front and narrow rear offer superior aerodynamics to a delta trike configuration.\n\nHand-crank trikes use a hand-operated crank, either as a sole source of power or a double drive with footpower from pedals and hand-power from the hand crank. The hand-power only trikes can be used by individuals who do not have the use of their legs due to a disability or an injury. They are made by companies including Greenspeed, Invacare, Quickie and Druzin.\n\nIn case of paralysis of the legs, more speed and range of distance can be obtained by adding functional electrical stimulation to the legs. The large leg muscles are activated by electrical impulses synchronized with the hand cranking movement.\n\nRecumbent tandem trikes allow two people to ride in a recumbent position with an extra-strong backbone frame to hold the extra weight. Some allow the \"captain\" (the rider who steers) and \"stoker\" (the rider who only pedals) to pedal at different speeds. They are often made with couplers so the frames can be broken down into pieces for easier transport. Manufacturers of recumbent trikes include Greenspeed, WhizWheelz and Inspired Cycle Engineering (ICE).\n\nSome tricycles (such as the Christiania and the Pashley load trike) are designed for load carrying. Others are designed for racing or for comfort. Some recumbent tricycles are fully enclosed for all weather use as well as for aerodynamic benefits; these are known as velomobiles. Some tricycles, such as the Zigo Leader, are designed to transport children.\n\nMost cycle rickshaws, used for carrying passengers for hire, are tricycles with one steering wheel in the front and two wheels in the back supporting a seating area for one or two passengers. Cycle rickshaws often have a parasol or canopy to protect the passengers from sun and rain. These vehicles are widely used in South Asia and Southeast Asia, where rickshaw driving provides essential employment for recent immigrants from rural areas, generally impoverished men. In the 1990s and first decade of the 21st century, rickshaws became increasingly popular in big cities in Britain, Europe and the United States, where they provide urban transportation, novelty rides, and serve as advertising media.\nSpidertrike is a recumbent cycle rickshaw that is used in central London and operated by Eco Chariots. The trike pictured is called the SUV (Sensible Utility Vehicle) and is produced by the company Organic Engines, which operates in Florida in the United States. It is a front wheel drive tricycle, articulated behind the driver seat, and has hydraulic double disc brakes and internal hub gears. The passenger is protected from rain and sun with a canopy.\n\nUrban delivery trikes are designed and constructed for transporting large loads. These trikes include a cargo area consisting of a steel tube carrier, an open or enclosed box, a flat platform, or a large, heavy-duty wire basket. These are usually mounted over one or both wheels, low behind the front wheel, or between parallel wheels at either the front or rear of the vehicle, to keep the center of gravity low. The frame and drivetrain must be constructed to handle loads several times that of an ordinary bicycle; as such, extra low gears may be added. Other specific design considerations include operator visibility and load suspension. Many, but not all, cycles used for the purpose of vending goods such as ice cream cart trikes or hot dog vending trikes are cargo bicycles.\n\nMany freight trikes are of the tadpole configuration, with the cargo box (platform, etc.) mounted between the front wheels. India and China are significant strongholds of the rear-loading \"delta\" carrier trike. Freight trikes are also designed for indoor use in large warehouses or industrial plants. The advantage of using freight trikes rather than a motor vehicle is that there is no exhaust, which means that the trike can be used inside warehouses. While another option is electric golf cart-style vehicles, freight trikes are human-powered, so they do not have the maintenance required to keep batteries on golf carts charged up.\n\nCommon uses include:\n\nCompared to adult trikes, children's model are simpler, without brakes or gears, and often with crude front-drive. Tricycles are typically used by children between the ages of two and five, after which point they usually switch to a bicycle, often with training wheels (stabilisers). Child trikes can be unstable, particularly if the wheelbase or track are insufficient. Some trikes have a push bar so adults can control the trike. Child trikes may have frames made of metal, plastic, or even bamboo.\n\n\"Budget\" child trikes have pedals directly driving the front wheels, for better control of the bike and braking issues but better models (such as the Pashley Pickle) have chain drive to a single rear wheel. Children's rear-drive trikes lack a differential, so one rear wheel spins free. Rear-drive is preferable to front-drive as most of the rider's weight is on the rear wheels; indeed most front drive trikes are prone to skidding when force is applied to the pedals.\n\nUnlike adult bikes, children's trikes do not always have pneumatic tires, having instead wheels of solid rubber or hollow plastic. While this may add to the weight of the tricycle and reduces the shock-absorbing qualities, it eliminates the possibility of punctures. Pull brakes are rarely fitted to front-drive trikes, but the child can slow the trike down by resisting the forward motion through the pedals.\n\nA peculiar design, called \"grillo\" (\"cricket\" in Italian), with a half chain, has been popular in Italy among children for decades, especially for rental in parks.\n\nDrift trikes are a variety of tricycle with slick rear wheels, enabling them to drift, being countersteered round corners. They are commonly used for gravity-powered descents of paved roads with steep gradients.\n\nWith hand and foot trikes, the rider makes a pair of front wheels change directions by shifting the center of weight and moves forward by rotating the rear wheel. The hand and foot trike can be also converted into a manual tricycle designed to be driven with both hands and both feet. There are also new hybrids between a handcycle, a recumbent bike and a tricycle, these bikes make it even possible to cycle with legs despite a spinal cord injury.\n\nTricycle conversion sets or kits convert a bicycle to an upright tricycle. Tricycle kit can remove the front wheel and mounts two wheels under the handlebars for a quick and easy conversion.\n\nThe advantages of a trike conversion set include lower cost compared with new hand built tricycles and the freedom to choose almost any donor bicycle frame. Tricycle conversion sets tend to be heavier than a high quality, hand built, sports, touring or racing tricycle. Conversion sets can give the would-be serious tricyclist a taste of triking before making the final decision to purchase a complete tricycle. Conversion sets can also supplied ready to be brazed onto a lightweight, steel bicycle frame to form a complete trike.\n\nSome trike conversion sets can also be used with recumbent bicycles to form recumbent trikes.\n\nAdults may find upright tricycles difficult to ride because of familiarity with the counter-steering required to balance a bicycle. The variation in the camber of the road is the principal difficulty to be overcome once basic tricycle handling is mastered. Recumbent trikes are less affected by camber and, depending on track width and riding position, capable of very fast cornering. Some trikes are tilting three-wheelers, which lean into corners much as bicycles do.\n\nIn the case of delta tricycles, the drive is often to just one of the rear wheels, though in some cases both wheels are driven through a differential. A double freewheel, preferably using no-backlash roller clutches, is considered superior. Trikes with a differential often use an internally geared hub as a gearbox in a 'mid drive' system. A jackshaft drive permits either single or two-wheel drive. Tadpoles generally use a bicycle's rear wheel drive and for that reason are usually lighter, cheaper and easier to replace and repair.\n\nSome trikes use a geometry (also called center point steering) with the kingpin axis intersecting the ground directly ahead of the tire contact point, producing a normal amount of trail. This arrangement, elsewhere called \"zero scrub radius\" is used to mitigate the effects of one-sided braking on steering. While zero scrub can reduce steering feel and increase wandering it can also protect novices from spinning out and/or flipping.\n\nTadpole trikes tend also to use Ackermann steering geometry, perhaps with both front brakes operated by the stronger hand. While the KMX Kart stunt trike with this setup allows the rear brake to be operated separately, letting the rider do \"bootlegger turns\", the standard setup for most trikes has the front brake for each side operated by each hand. The center-of-mass of most tadpole trikes is close to the front wheels, making the rear brake less useful. The rear brake may instead be connected to a latching brake lever for use as a parking brake when stopped on a hill.\n\nRecumbent trikes often brake one wheel with each hand, allowing the rider to brake one side alone to pull the trike in that direction.\n\nSpecialist makers of upright trikes in the UK include Longstaff Cycles, Higgins (which ceased trading in the 1960s), Trykit and Pashley Cycles. Italian company Di Blasi make a folding upright trike.\n\nMakers of recumbent trikes include KMX; Hase (who make the Kettwiesel delta, improbably named after the British children's programme Catweazle); Inspired Cycle Engineering, who make the Trice range of tadpole trikes; AVD, who build the record-holding Burrows Windcheetah or Speedy, now exhibited in the Metropolitan Museum of Modern Art (MoMA); Australia's Greenspeed, one of the oldest manufacturers; Michigan-based WhizWheelz, whose ten models include a tadpole and a tandem; Big Cat HPV, which builds the eight Catrike models in Florida; and Sidewinder Cycle, which has a front wheel drive system with rear wheel steering builds 3 models all with Electric assist capability located in California.\n\nThe largest manufacturer of recumbent trikes is Sun Bicycles of Taiwan who make both tadpole and delta trikes. The deltas are built from designs licensed from Gardner Martin's EasyRacers, a leading builder of recumbent bicycles.\n\nOn 1 July 2005, Sudhakar Yadav from India rode the largest tricycle in Hyderabad which had an overall height of . The tricycle exhibited at the Sudha Cars Museum entered the \"Guinness World Records\" and had wheel diameter of and length of .\n\n"}
{"id": "13320206", "url": "https://en.wikipedia.org/wiki?curid=13320206", "title": "Vapor–liquid separator", "text": "Vapor–liquid separator\n\nA vapor–liquid separator is a device used in several industrial applications to separate a vapor–liquid mixture.\n\nA vapor–liquid separator may also be referred to as a \"flash drum\", \"breakpot\", \"knock-out drum\" or \"knock-out pot\", \"compressor suction drum\" or \"compressor inlet drum\". When used to remove suspended water droplets from streams of air, it is often called a thermister.\n\nFor the common variety, gravity is utilized in a vertical vessel to cause the liquid to settle to the bottom of the vessel, where it is withdrawn.\n\nIn low gravity environments such as a space station, a common liquid separator will not function because gravity is not usable as a separation mechanism. In this case, centrifugal force needs to be utilised in a spinning centrifugal separator to drive liquid towards the outer edge of the chamber for removal. Gaseous components migrate towards the center.\n\nFor both varieties of separator, the gas outlet may itself be surrounded by a spinning mesh screen or grating, so that any liquid that does approach the outlet strikes the grating, is accelerated, and thrown away from the outlet. \n\nThe vapor travels through the gas outlet at a design velocity which minimises the entrainment of any liquid droplets in the vapor as it exits the vessel.\n\nThe feed to a vapor–liquid separator may also be a liquid that is being partially or totally \"flashed\" into a vapor and liquid as it enters the separator.\n\nThe separator is only effective as long as there is an air space inside the chamber. The separator can fail if either the mixed inlet is overwhelmed with supply material, or the liquid drain is unable to handle the volume of liquid being collected. The separator may therefore be combined with some other liquid level sensing mechanism such as a sight glass or float sensor. In this manner, both the supply and drain flow can be regulated to prevent the separator from becoming overloaded. (Agastya, Bayu)\n\nVapor–liquid separators are very widely used in a great many industries and applications, such as:\n\n\nIn refrigeration systems, it is common for the system to contain a mixture of liquid and gas, but for the mechanical gas compressor to be intolerant of liquid.\n\nSome compressor types such as the scroll compressor use a continuously shrinking compression volume. Once liquid completely fills this volume the pump may either stall and overload, or the pump chamber may be warped or otherwise damaged by the fluid that can not fit into a smaller space.\n\n\n"}
{"id": "86585", "url": "https://en.wikipedia.org/wiki?curid=86585", "title": "Wilhelm Maybach", "text": "Wilhelm Maybach\n\nFrom the late 19th century Wilhelm Maybach, together with Gottlieb Daimler, developed light, high-speed internal combustion engines suitable for land, water, and air use. These were fitted to the world's first motorcycle, motorboat, and after Daimler's death, a new automobile introduced in late 1902, the Mercedes model, built to the specifications of Emil Jellinek.\n\nMaybach rose to become technical director of the Daimler Motoren Gesellschaft (DMG) but did not get on well with its chairmen. As a result, Maybach left DMG in 1907 to found Maybach-Motorenbau GmbH together with his son Karl in 1909; they manufactured Zeppelin engines. After the signing of the Versailles Treaty in 1919 the company started producing large luxury vehicles, branded as \"Maybach\". The company joined the German war effort in 1940, ceasing automotive production in favour of tank engines, including those for the Tiger I and Tiger II heavy tanks.\n\nRevived after the war Maybach Motorenbau which remained a subsidiary of Luftschiffbau Zeppelin was making diesel engines. During the 1960s Maybach came under the control of Daimler-Benz and was renamed MTU Friedrichshafen.\n\nIn 2002 the \"Maybach\" brand name was revived for a luxury make but it was not successful. On 25 November 2011 Daimler-Benz announced they would cease producing automobiles under the \"Maybach\" brand name in 2013.\nIn 2014, Daimler announced production of an ultra-luxury edition of the Mercedes-Benz S-Class under the new Mercedes-Maybach brand.\n\nWilhelm Maybach was born in Heilbronn, Baden-Württemberg in 1846, the son of a carpenter and his wife Luise. He had four brothers. When he was eight years old the family moved from Löwenstein near Heilbronn to Stuttgart. His mother died in 1856 and his father in 1859.\n\nAfter his relatives published an announcement in the \"Stuttgarter Anzeiger\" newspaper, a philanthropic institution at Reutlingen took in Maybach as a student. Its founder and director, , discovered Maybach's technical inclination and helped to stimulate his career by sending him to the school's engineering workshop. At 15 years old (1861), Maybach was heading for a career in Industrial design and took extra classes in physics and mathematics at Reutlingen's public high school.\n\nBy the time he was 19 years old, he was a qualified designer working on stationary engines. His workshop manager, Gottlieb Daimler, then 29, noticed his efforts and took him on as his main assistant, a post he held until Daimler's death in 1900.\n\nIn 1869, Maybach followed Daimler to Maschinenbau-Gesellschaft Karlsruhe AG in Karlsruhe, a manufacturer of heavy locomotives. Daimler was on the Executive Committee and they spent long nights discussing new designs for engines, pumps, lumber machinery, and metalworking.\n\nIn 1872, Daimler moved to Deutz-AG-Gasmotorenfabrik in Cologne, then the world's largest manufacturer of stationary gas engines. Nikolaus Otto, part owner of the company, focused on engine development with Daimler. Maybach joined them as Chief Designer.\n\nIn 1876, Nikolaus Otto patented the Otto cycle engine. It was a four-stroke cycle gas internal combustion engine with intake, compression, power, and exhaust strokes. One of Otto's more than 25 patents on this engine was later challenged and overturned, allowing Daimler and Maybach to produce their high-speed engine.\n\nAlso in 1876, Maybach was sent to show Deutz's engines at the Philadelphia World's Fair (USA). On returning to Cologne in 1877, he concentrated on improving the four-stroke design to prepare it for its impending commercial launch.\n\nIn 1878, Maybach married Bertha Wilhelmine Habermaas, a friend of Daimler's wife, Emma Kunz. Her family members were landowners who ran the post office in Maulbronn. On 6 July 1879 Karl Maybach was born, the first of their three children.\n\nIn 1880, Daimler and Otto had serious disagreements, resulting in Daimler's leaving Deutz-AG. Daimler received 112,000 goldmarks in Deutz-AG shares as compensation for patents granted to him and Maybach. Maybach also left shortly afterwards, and followed his friend to found a new company in Cannstatt.\n\nIn 1882, Maybach moved to Taubenheimstrasse in Cannstatt, Stuttgart, where Daimler had purchased a house with 75,000 goldmarks from his Deutz compensation. They added a brick extension to the glass-fronted summer house in the garden, which became their workshop.\n\nTheir activities alarmed the neighbours, who suspected they were engaged in counterfeiting. The police raided the property in their absence using the gardener's key, but found only engines.\n\nPhoto of Maybach, Daimler and the 1883 engine and the 1885 Reitwagen\n\nIn late 1883, Daimler and Maybach patented the first of their engines fueled by Ligroin. This engine was patented on December 16, 1883. It achieved Daimler's goal of being small and running fast enough to be useful at 750 rpm (soon after up to 900). Daimler had three engines built in 1884. Maybach persuaded him to put one in a vehicle, the result being the Reitwagen.\n\nThe 1883 Daimler Maybach engine. The first compression engine which ran on liquid Petroleum.\n\nIn 1884, Maybach's second son Adolf was born.\n\nBy the end of 1885, Maybach and Daimler developed the first of their engines, which is regarded as a precursor to all modern petrol engines. It featured:\n\nIn 1885, they created the first carburetor, which mixed evaporated gasoline with air to allow its efficient use as fuel. It was used that year on a larger but still compact version of the engine, now with a vertical cylinder, that featured:\nDaimler baptized it the \"Standuhr\" (Grandfather Clock) because of its resemblance to a pendulum clock.\n\nIn November 1885, Daimler installed a smaller version of the engine into a wooden bicycle, creating the first motorcycle (patent 36-423 - Vehicle with gas or petroleum engine), and Maybach drove it three kilometers from Cannstatt to Untertürkheim, reaching . It became known as the \"Reitwagen\".\n\nOn 8 March 1886, the inventors bought an American model coach built by Wilhelm Wimpff & Sohn, telling the neighbors that it was a birthday gift for Mrs. Daimler. Maybach supervised the installation of an enlarged 1.5 hp Grandfather Clock engine into the coach, and installed a belt drive to the wheels. The vehicle reached when tested on the road to Untertürkheim.\n\nMaybach and Daimler went on to prove the engine in many other ways, including:\n\nBy 1887 they were licensing their first patents abroad, and Maybach represented the company at the great Paris Exposition Universelle (1889).\n\nSales increased, mostly from the Neckar motorboat. In June 1887, Daimler bought land in the Seelberg Hills of Cannstatt. The workshop was some distance from the town on Ludwig Route 67, because Cannstatt's mayor objected to the presence of the workshop in the town. It covered 2,903 square meters and cost 30,200 goldmarks. They initially employed 23 people. Daimler managed the commercial issues and Maybach the design department.\n\nIn 1889 they built their first automobile to be designed from scratch rather than as an adaptation of a stagecoach. It was publicly launched by both inventors in Paris in October 1889.\n\nDaimler's engine licenses began to be taken up throughout the world, starting the modern car industry in:\n\nResources were scant to keep the business going, as neither the engine sales nor the worldwide proceeds from their patents were yielding enough money. Fresh capital was injected by bringing in the financiers Max von Duttenhofer and William Lorenz, former munitions makers, who were associated with Kilian von Steiner, the owner of a German investment bank. The company was taken public.\n\nIn 1890, Daimler and Maybach together founded the Daimler Motoren Gesellschaft, the Daimler Motor Corporation or DMG for short, which was dedicated to the construction of small high-speed internal combustion engines for land, water, or air transport. Maybach was Chief Designer. After spending long hours debating which fuel was best to use in Otto's four-stroke engine, which had normally used methane gas as a fuel, they turned to petroleum which until then had been used mainly as a cleaner and sold in pharmacies.\n\nThe company's re-foundation took place on 28 November 1890. This has been regarded as a \"pact with the devil\" by some German historians,\nas the following decade was chaotic for Daimler and Maybach. DMG continued to expand, selling engines from Moscow to New York, and additional stationary engine-making capacity was added, but the belief continued that automobile production would not be profitable. The new chairmen planned to merge \"DMG\" and \"Deutz-AG\", in spite of Daimler's disagreement with Nikolaus Otto.\n\nGottlieb Daimler and Chief Engineer Maybach preferred to produce automobiles and reacted against Duttenhofer and Lorenz in particular. Maybach was rejected as a member of the Board of Management and left the company on 11 February 1891, and continued his design work from his own house, financed by Daimler. In late 1892, he set up a shop in the ballroom of the former Hermann Hotel and Winter Garden where he employed 17 workers, five of which were paid by Daimler.\n\nIn 1894 Maybach designed his third engine model, together with Daimler and his son Paul. Used in the Phoenix, it gained worldwide attention, pioneering the use of four cylinders in the automobile and featuring:\n\nMaybach's creations are considered among the finest motors of the late 19th century. His inventions became indispensable for any model by any automaker in the world. He became recognised as the backbone of France's early automobile industry, where he was hailed as the \"King of Designers\".\n\nDaimler was forced out of his post as Technical Director at DMG and resigned in 1893, which damaged DMG's prestige. However, in 1894, a British industrialist, Frederick Simms, purchased the rights to the Phoenix engine for 350,000 marks and stabilised the company's finances. He also made it a condition that Daimler be re-employed. In 1895 DMG assembled its 1,000th engine, and Maybach also returned as Chief Engineer, obtaining 30,000 goldmarks worth of shares through his original contract with Gottlieb Daimler.\n\nMaybach patented more automobile inventions, including:\n\nAround this time though Maybach suffered two setbacks. His teenage second son, Adolf, suffered a schizophrenia attack and spent the rest of his life in various mental institutions. (In 1940, his son was murdered by the Nazis as part of the Euthanasia Program.) In 1900, Gottlieb Daimler died of heart disease.\n\nBetween April and October 1900, Maybach designed a completely new kind of car inspired by racing which would be called the Mercedes 35 hp when released in 1902. It featured:\nEmil Jellinek, a successful Austrian dealer and racing driver on the French Riviera who greatly admired Maybach's work, promised to buy a shipment of 36 automobiles for 550,000 goldmarks if Maybach could design a great race car for him following his specifications.\n\nThe prototype was finished in December 1900 and, in 1901 went on to have a string of racing successes. Its engine was baptized Daimler-Mercedes (Spanish for mercy) after Mercedes Jellinek, Emil's 10–year–old daughter. European high society bought the car in large numbers making it the commercial success that convinced the company directors there was a future in automobiles. Production increased greatly and DMG rapidly increased in size and number of employees. DMG officially registered the Mercedes trademark in June 1902.\n\nIn 1902, a fire destroyed DMG's Cannstatt facilities and the company moved to Stuttgart-Untertürkheim. Maybach continued with his innovations: \n\nDMG demoted him to an \"Inventor's Office\" causing him to leave the company again in 1907. DMG replaced him with Paul Daimler. That same year, the German Engineers Association (VDI) recognized Wilhelm Maybach as an honorary member.\n\nIn 1900, Maybach had had his first contact with Count Ferdinand von Zeppelin who sought to improve the engines of the Zeppelin LZ1 airship. Maybach built some engines for him based on sketches of a 150 hp unit created by his son, Karl, while at DMG.\n\nIn 1908, Count Zeppelin attempted to sell his models \"LZ3\" and \"LZ4\" to the government. On 5 August, \"LZ4\" exploded against a row of trees after attempting an emergency landing when its engines failed. This was far from being the end for the airship project as 6.25 million goldmarks were raised in a donation campaign after the accident. Count Zeppelin founded the Luftschiffbau Zeppelin GmbH, the company that built the Zeppelin airships.\n\nMaybach had to hold off joining the new company for a while as he was still in litigation with DMG, so Karl took his place. On 23 March 1909, a deal was finally signed, creating an engine subsidiary to Luftschiffbau Zeppelin at Bissingen/Enz, in Württemberg. Wilhelm Maybach was Technical Assistant and Karl was Technical Manager. Their first designs reached 72 km/h (45 mph).\n\nWilhelm Maybach moved his company to Friedrichshafen and renamed it \"Luftfahrzeug-Motoren-GmbH\". Karl and Wilhem held 20% of the shares with an arrangement for Karl to inherit. They kept supplying \"Zeppelin\", but worked on other airship engines too. In 1912, the company adopted the name Maybach-Motorenbau GmbH (Maybach Engine Construction Company). In 1916, they developed a 160 hp aircraft engine which sold 2000 units before the end of World War I. In 1916, Wilhelm Maybach was awarded an Honorary Doctorate by the Technical University of Stuttgart.\n\nAfter the First World War, the Versailles Treaty of 1919 prohibited airship production in Germany, so Maybach turned to making high-speed diesel engines for naval and railroad use, and petrol engines for automobiles, but not complete automobiles.\n\nMany of the small automakers in Germany built their own engines for cost reasons and only the Dutch Spyker company was interested in taking Maybach engines. Wilhelm Maybach turned down the contract because he could not agree to its conditions. Instead, he opted to build complete automobiles and the factory began to produce Maybach limousines in 1921.\n\nThe first model, the Maybach W3, was shown at the 1921 Automobile Exposition in Berlin and featured\nIt was produced until 1928, selling 300 units, mostly with sedan bodies; the two-seat sport version was less successful. The Maybach W5 followed, with the top speed increased to ; 250 units sold in 1927 and 1929.\n\nNext Maybach produced the V12 car:\nOnly a few dozen were sold due to the German postwar economic crisis. In 1930, its successor, the DS7-Zeppelin, also featured a 12-cylinder engine of 7 liters.\n\nIn August 1929, the Zeppelin LZ-127 used five Maybach-V12 petrol engines of each.\n\nNeither Wilhelm nor Karl owned a Maybach automobile. Wilhelm never even owned a car. \"He, who created the basics for the modern automobilism, rarely utilized a car for his personal purposes. He walked or took the tram. Although he could have afforded one, he did not own a car.\"\n\nWilhelm Maybach died at the age of 83 in Stuttgart on 29 December 1929.\n\nHis business, Maybach Motorenbau GmbH continued in Friedrichshafen. After 1945 it manufactured a full range of diesel engines. In the early 1960s Maybach began to construct large Daimler-Benz engines in Friedrichshafen under a licence agreement and entered close collaboration with Daimler-Benz.\n\nDuring the mid 1960s Maybach Motorenbau GmbH became Maybach Mercedes-Benz Motorenbau GmbH and 83 percent owned by Daimler-Benz.\n\nIn 1998 Mercedes-Benz announced what would prove to be a temporary revival of the Maybach brand for automobiles. Daimler currently produces an ultra luxury edition of the Mercedes-Benz S-Class under the Mercedes-Maybach brand.\n\n\n\n\n"}
{"id": "31563108", "url": "https://en.wikipedia.org/wiki?curid=31563108", "title": "Wiring (development platform)", "text": "Wiring (development platform)\n\nWiring is an open-source electronics prototyping platform composed of a programming language, an integrated development environment (IDE), and a single-board microcontroller. It was developed starting in 2003 by Hernando Barragán.\n\nBarragán started the project at the Interaction Design Institute Ivrea. The project is currently developed at the School of Architecture and Design at the Universidad de Los Andes in Bogotá, Colombia.\n\nWiring builds on Processing, an open project initiated by Casey Reas and Benjamin Fry, both formerly of the Aesthetics and Computation Group at the MIT Media Lab.\n\nThe documentation was created with software designers and artists in mind. Project experts, intermediate developers, and beginners from around the world share ideas, knowledge and their collective experience as a project community. Wiring makes it easy to create software for controlling devices attached to the electronics board to create all kinds of interactive devices. The concept of developing is to write a few lines of code, connect a few electronic components to the Wiring hardware and observe, for example, that a motion sensor controls a light when a person approaches it, write a few more lines, add another sensor, and see how this light changes when the illumination level in a room decreases. This process is called sketching with hardware; explore ideas quickly, select the more interesting ones, refine and produce prototypes in an iterative process.\n\nThe Wiring IDE is a cross-platform application written in Java which is derived from the IDE made for the Processing programming language. It is designed to introduce programming and sketching with electronics to artists and designers. It includes a code editor with features such as syntax highlighting, brace matching, and automatic indentation capable of compiling and uploading programs to the board with a single click.\n\nThe Wiring IDE includes a C/C++ library called \"Wiring\", which makes common input/output operations much easier. Wiring programs are written in a dialect of C and C++. A minimal program requires only two functions:\n\nA typical first program for a developer using a microcontroller is to blink a light-emitting diode (LED) on and off. In the Wiring environment, the user might write a program like this:\n\nWhen the user clicks the \"Upload to Wiring hardware\" button in the IDE, a copy of the code is written to a temporary file including a standard header file at the file beginning, and a simple main function appended.\n\nThe Wiring IDE uses the GNU toolchain and AVR Libc to compile programs, and uses avrdude to upload programs to the board.\n\nThe Wiring hardware reference designs are distributed under a Creative Commons Attribution Share-Alike 2.5 license and are available on the Wiring Web site. Layout and production files for the Wiring hardware are also available. The source code for the IDE and the hardware library are available and released under the GPLv2\n\nWiring was based on the original work done on Processing project in MIT.\n\nWiring and Processing have spawned another project, Arduino, which uses the Processing IDE, with a simplified version of the C++ language, as a way to teach artists and designers how to program microcontrollers. There are now two separate hardware projects, Wiring and Arduino, using the Wiring environment and language.\n\nFritzing is another software environment within this family, which supports designers and artists to document their interactive prototypes and to take the step from physical prototyping to actual product.\n\n\n\n"}
