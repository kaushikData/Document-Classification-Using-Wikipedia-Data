{"id": "57138844", "url": "https://en.wikipedia.org/wiki?curid=57138844", "title": "Activation energy asymptotics", "text": "Activation energy asymptotics\n\nActivation energy asymptotics (AEA or also known as Large activation energy asymptotics) is an asymptotic analysis used in the combustion field utilizing the fact that the reaction rate is extremely sensitive to temperature changes due to the large activation energy of the chemical reaction. \n\nThe techniques were pioneered by the Russian scientists Yakov Borisovich Zel'dovich, David A. Frank-Kamenetskii and co-workers in the 30s, in their study on premixed flames and thermal explosions (Frank-Kamenetskii theory), but not popular to western scientists until the 70s. In the early 70s, due to the pioneering work of Williams B. Bush, Francis E. Fendell, Forman A. Williams and Amable Liñán, it became popular in western community and since then it was widely used to explain more complicated problems in combustion.\n\nIn combustion processes, the reaction rate formula_1 is dependent on temperature formula_2 in the following form (Arrhenius law),\n\nwhere formula_4 is the activation energy, and formula_5 is the universal gas constant. In general, the condition formula_6 is satisfied, where formula_7 is the burnt gas temperature. This condition forms the basis for activation energy asymptotics. Denoting formula_8 for unburnt gas temperature, one can define the Zel'dovich number and heat release parameter as follows\n\nIn addition, if we define a non-dimensional temperature \n\nsuch that formula_11 approaching zero in the unburnt region and approaching unity in the burnt gas region (in other words, formula_12), then the ratio of reaction rate at any temperature to reaction rate at burnt gas temperature is given by\n\nNow in the limit of formula_14 (large activation energy) with formula_15, the reaction rate is exponentially small i.e., formula_16 and negligible everywhere, but non-negligible when formula_17. In other words, the reaction rate is negligible everywhere, except in a small region very close to burnt gas temperature, where formula_18. Thus, in solving the conservation equations, one identifies two different regimes, at leading order,\n\n\nwhere in the convective-diffusive zone, reaction term will be neglected and in the thin reactive-diffusive layer, convective terms can be neglected and the solutions in these two regions are stitched together by matching slopes using method of matched asymptotic expansions. The above mentioned two regime are true only at leading order since the next order corrections may involve all the three transport mechanisms.\n\n"}
{"id": "10132401", "url": "https://en.wikipedia.org/wiki?curid=10132401", "title": "Adam Ty Dean Smith", "text": "Adam Ty Dean Smith\n\nAdam Ty Dean Smith (better known as Adam Dean Smith) is an automobile designer. He has worked with Ford Motor Company and HSV (Holden Special Vehicles). He became \"Wheels Magazine's\" Young Designer of the Year in October 2005 with his winning entry, the Hybrid SUV 'Ford Punk' (WADA: Wheels Automoitive Design Awards, part of the ADA: Australian Design Award).\n\n"}
{"id": "3594326", "url": "https://en.wikipedia.org/wiki?curid=3594326", "title": "Backpack helicopter", "text": "Backpack helicopter\n\nA backpack helicopter is a helicopter motor and rotor and controls assembly that can be strapped to a person's back, so he can walk about on the ground wearing it, and can use it to fly. It uses a harness like a parachute harness and should have a strap between the legs (so the pilot does not fall out of the harness during flight). Some designs may use a ducted fan design to increase upward thrust. Several inventors have tried to make backpack helicopters, with mixed results.\n\nTypically, a backpack helicopter differs from a conventional helicopter in two main ways:\n\nFirst, there is no tail rotor, and the main rotors are contra-rotating. Yaw is controlled by fine adjustment of a differential gear in the rotor drive transmission. When one rotor is adjusted to spin slightly faster than the other, it induces yaw (turning motion).\n\nSecond, the rotors are fixed pitch, which assists with simplicity; this means, however, that in the event of engine failure autorotation is impossible. Usually, a ballistic parachute would be incorporated for safety.\n\nAn edition of \"Popular Science\" magazine in 1969 featured a backpack helicopter that used small jet engines in a tip jet configuration instead of contra-rotating rotors. This design could function in autorotation. Related are devices like a backpack helicopter which also include a seat and leg supports, which are small, open-topped helicopters. In theory, a helicopter would be more efficient than a rocket-powered jetpack, possessing a greater specific impulse, and being more suited to hovering, due to the lower velocities of the propelled gases.\n\n\n\n\nIn recent years \"Heli Backpack\" has become a tradename for a make of ordinary walkers' backpacks.\n"}
{"id": "9792866", "url": "https://en.wikipedia.org/wiki?curid=9792866", "title": "Bruker", "text": "Bruker\n\nBruker Corporation is a manufacturer of scientific instruments for molecular and materials research, as well as for industrial and applied analysis. It is headquartered in Billerica, Massachusetts and is the publicly traded parent company of Bruker Scientific Instruments (Bruker AXS, Bruker BioSpin, Bruker Daltonics and Bruker Optics) and Bruker Energy & Supercon Technologies (BEST) divisions.\n\nIn April 2010, Bruker created a Chemical Analysis Division (headquartered in Fremont, CA) under the Bruker Daltonics subsidiary. This division contains three former Varian product lines: ICPMS systems, laboratory gas chromatography (GC), and GC-triple quadrupole mass spectrometer (originally designed by Bear Instruments and acquired by Varian in 2001).\n\nIn 2012 it sponsored the Fritz Feigl Prize, and since 1999 the company has also sponsored the Günther Laukien Prize.\n\nThe company was founded on September 7, 1960, in Karlsruhe, Germany as \"Bruker-Physik AG\" by five people, one of them being Günther Laukien, who was a professor at the University of Karlsruhe at the time. The name \"Bruker\" originates from co-founder Emil Bruker, as Günther Laukien himself was formally not allowed to commercialize his research whilst being a professor. Bruker produced Nuclear Magnetic Resonance Spectroscopy (NMR) and EMR spectroscopy equipment then. In the early 1960s, the company had around 60 employees and was growing rapidly. One of the early success products was the HFX 90 NMR spectroscopy system, with three independent channels and which was also the first NMR system using only semiconductor transistors. In 1969, Bruker launched the first commercial Fourier transform NMR spectroscopy system (FT-NMR) and in the 1970s the company was the first to commercialize a superconducting FT-NMR. Later, the company would expand their product range with MRI, FTIR and FT-Raman spectrometers and with mass spectrometers.\n\nIn 1968, Bruker shipped NMR systems to Yale University in Connecticut. After that, demand from the US grew, so Bruker opened an office in Elmsford, New York which marked the start of their US activities. In 2008 after a corporate reorganization lasting 8 years, all divisions were merged in a unified Bruker Corporation.\n\nGünther Laukien died in 1997, his son Frank Laukien, is currently the CEO of Bruker. His son Jörg C. Laukien, also works for the company. His son Dirk D. Laukien is a former company executive.\nBruker acquisitions include Siemens AXS (1997), Nonius (2001), MacScience (2002), Vacuumschmelze Hanau (2003), Röntec (2005), SOCABIM (2005), PGT (2005), Keymaster (2006), Quantron (2006), JuWe (2008), SIS (2008), ACCEL (2009), Michrom Bioresources (2011), Skyscan (2012), Prairie Technologies (2013) Oncovision (Preclinical PET imaging business, 2016), Oxford Instruments Superconducting Technology (2016), Hysitron Inc. (2017), XGLab (2017) and Alicona (2018).\n\nIn 1964, the company bought the NMR division of the Swiss Trüb-Täuber.\n\nBruker made several offers to take over its supplier Oxford Instruments during the 1970s, but after almost a decade of negotiations, an acquisition was eventually rejected by Oxford Instruments.\n\nIn 1997, the analytical X-ray division of Siemens was acquired by Bruker.\n\nIn 2010 Bruker bought 3 product lines from Agilent, which Agilent had acquired from Varian. These included mass spectrometry and gas chromatography instruments. They have since divested these products to Scion Instruments with the exception of the triple quadrupole\n\nIn 2012 Bruker bought parts of Carestream Health, including their in-vivo imaging portfolio and related aspects.\n\nBruker develops and delivers a wide variety of professional and scientific analysis devices including mass spectrometers, X-ray diffractometers, X-ray tomography devices, NMR spectroscopy devices, fluorescence microscopes, raman spectroscopes, atomic-force microscopes, and profilometers\n\nBruker products are used globally in a variety of situations. The National High Magnetic Field Laboratory at Florida State University selected Bruker to build the world's first 21.0 tesla FT-ICR MS.\n\nThe Total Carbon Column Observing Network uses high resolution FT spectrometers made by Bruker to measure various greenhouse gases across the globe.\n\nIn May, 2004, Frost & Sullivan selected the Company's Bruker Daltonics subsidiary for their 2004 Product Line Innovation Award for the Life Sciences. Bruker Daltonics received this award for its innovative development of sophisticated mass spectrometers.\n\n"}
{"id": "39850629", "url": "https://en.wikipedia.org/wiki?curid=39850629", "title": "CLARIN", "text": "CLARIN\n\nCLARIN is a European research network working in the field of archiving and processing of language-related resources in the humanities and social sciences. \n\nCLARIN is an acronym for \"Common Language Resources and Technology Infrastructure\". CLARIN is a community of scholars of various disciplines and a network of institutions. The scholars use CLARIN as a forum for joined developments and exchange of resources. They also exchange information on standards and procedures for long time archiving of research data. The institutions of CLARIN offer services in the same field. \n\nOn the European level, CLARIN is an independent body operating under European law as a European Research Infrastructure Community (ERIC). CLARIN ERIC represents the CLARIN community in the public and coordinates individual efforts in the field.\n\nCLARIN is listed in the Registry of Research Data Repositories re3data.org.\n\nFor published literature on CLARIN, see (and please cite!) the following publications:\n\n\nCLARIN's objective is to provide a research infrastructure for researchers of the humanities and social sciences working with language related material. The network should allow the persistent storage and access to the data in an archive, to disseminate the material and to reuse it in other research contexts. By exchanging material, effects of synergy are achieved by not duplicating work and participating at each other's development. Additionally new research questions can follow and the material can be used for quality assurance in the research process. \nBy offering depositing services, tutorials and support for archiving, special search engines for language resources and web based analysis systems the infrastructure becomes usable for the research community.\n\nCLARIN Vision\n\nAll digital language resources and tools from all over Europe and beyond are accessible through a single sign-on online environment for the support of researchers in the humanities and social sciences.\n\nCLARIN Mission\n\nCreate and maintain an infrastructure to support the sharing, use and sustainability of language data and tools for research in the humanities and social sciences.\n\nCLARIN Value proposition\n\nCLARIN makes digital language resources available to scholars, researchers, students, and citizen-scientists from all disciplines, especially in the humanities and social sciences, through single sign-on access. CLARIN offers long-term solutions and technology services for deploying, connecting, analysing and sustaining digital language data and tools. CLARIN supports scholars who want to engage in cutting edge data-driven research, contributing to a truly multilingual European Research Area.\n\nFor details please see: CLARIN Value proposition, 2017.\n\nCLARIN offers a wide range of services to the research community, for example:\n\nIn addition to such technical services, tutorials are prepared, standards and processes developed and implemented. Researchers receive support in the archiving process, for example by reference material.\n\nThe majority of operations, services and centres of the CLARIN infrastructure is provided and funded by CLARIN ERICmembers (and observers). Members and observers can be countries or intergovernmental organizations. They set up a national consortium, typically consisting of universities, research institutions, libraries and public archives, of which at least one has the status of CLARIN centre (see overview of CLARIN centres). The contribution expected from members and observers is to create and provide access to digital language data collections, and digital tools and expertise for researchers to work with them.\n\nBelow is the list of current CLARIN ERIC members, observers and third parties:\n\nMembers:\n\nThe Dutch Language Union (DLU) is an intergovernmental organization and member of CLARIN as well.\n\nObservers:\n\nThird party:\n\nThe CLARIN consortium is organized as a European Research Infrastructure Consortium (ERIC) under European law, which is a special type of organization created for research infrastructures.\nIt is hence part of the activities in the European Strategy Forum on Research Infrastructures (ESFRI) context.\n\nOn the European level CLARIN is governed by the following structures:\n\n\nThe seat of CLARIN ERIC is at the University of Utrecht with the office of the Executive Director. The staff of the office and all other institutions works distributed, the participants can be from all EU countries, and the staff may work from their home institutions.\n\nEvery member has a national CLARIN partner organization, often organized as national project networks. Every member supports at least one CLARIN centre, providing a repository for the humanities and social sciences scholar working with language oriented research data. Often these centres offer additional technical services and some webservices beyond the national community.\n\nScholars of the CLARIN community meet every year for the CLARIN Annual Meeting. For this every member may send delegates, experts from CLARIN centres. These meetings are also used for the committees to report on their progress and inform about new developments.\n\n"}
{"id": "8207762", "url": "https://en.wikipedia.org/wiki?curid=8207762", "title": "Chartplotter", "text": "Chartplotter\n\nA Chartplotter is a device used in marine navigation that integrates GPS data with an electronic navigational chart (ENC). \n\nThe chartplotter displays the ENC along with the position, heading and speed of the ship, and may display additional information from radar, automatic information systems (AIS) or other sensors.\n\nAs appropriate to particular marine applications, chartplotters may also display data from other sensors, such as echolocators/sonar.\n\nElectronic chartplotters are by nature CPU (and GPU) intensive applications. Chartplotters need to retrieve the Navigation Signal (Galileo, GPS, GLONASS, WAAS etc) signal and overlay that on a map. Map updates on dedicated hardware typically have screen refresh rates from 5hz to 30hz.\n\nSome navigation software can run on standard computers (and mobile phones, etc) but most higher end systems are dedicated hardware. Especially when the chartplotter generates three-dimensional displays, as used for fishing, considerable processing power and video memory may be required.\n\nAs with all marine systems, chart-plotters generally are not used alone. In commercial ships, they are integrated into a full system of marine instruments that can guide the ship under any conditions. These other instruments include Sonar transducers, integration with 2 Way Radio communication devices and emergency locators (EPIRB).\n\nThe integration of these devices is very important as it becomes quite distracting to look at several different screens. Therefore, displays can often overlay charting, radar, sonar into a single system. This gives the captain unprecedented instrumentation to maneuver the ship. With digital backbones, these devices have advanced greatly in the last years. For example, the newer ones have 3D displays that allow you to see above, below and all around the ship, including overlays of satellite imaging.\n\nAn individual electronic chart, or, more commonly, a database of charts, is the heart of a chartplotter. The chartplotter system can be no more accurate than its charts. While there are different formats for electronic charts, there are even more important quality and legal aspects.\n\nWithout charts that are accredited by appropriate governmental organizations, a chartplotter is an example of an Electronic Charting System (ECS). When the charts meet the technical requirements of the International Maritime Organization (IMO) and national hydrographic bodies, the chartplotter can qualify as an Electronic Chart Display and Information System (ECDIS). ECDIS legally can be substituted for paper charts while navigating in active waterways, but vessels are required to maintain paper charts if their chartplotter does not use ECDIS.\n\nECDIS will use IMO-standardized formats, but some chartplotters require specific data formats. A charter may use one or both types of ENC:\n\nA basic navigational display is common to all chartplotters. Depending on intended use and characteristics of the specific chartplotter, they may have options to present such displays as three-dimensional fish-finding and bottom characteristics useful in fishing. \n\nThese optional displays can be presented by commands to a single screen, causing the main display to be replaced with the one requested. Alternatively, chartplotters may offer split-screen modes on a single physical screen, or may support multiple physical displays.\n\nChartplotters may be programmable, and can be set to generate audible and visual alarms for conditions such as a potential collision, deviating significantly from the planned course, etc.\n\nThe principal function of a classic chartplotter is assisting a human pilot to plot and follow a course.\n\nSafety-related Automatic identification systems (AIS), required on all passenger vessels and vessels of 300 tons and over, also assist in piloting, and can display on the chartplotter. AIS have collision avoidance, and avoidance of known hazards such as reefs, as their primary function. AIS depend on cooperative data communications among ships. \n\nVessel traffic services (VTS) go even farther as safety systems, being analogous to the proactive function of air traffic control systems. VTS assist vessel traffic control in routing vessels in busy waters. Other vessel-based safety collision avoidance functions are Automatic Radar Plotting Aids (ARPA), usually a component of the radar system or an accessory to it, and coupled with the radar system input to the chartplotter.\n\n"}
{"id": "9488298", "url": "https://en.wikipedia.org/wiki?curid=9488298", "title": "CyberQuery", "text": "CyberQuery\n\nCyberquery is a software product of Cyberscience Corporation Inc. Originally developed for data handling and analysis on Data General AOS and AOS/VS minicomputers, then the available platforms for Cyberquery were extended to all major UNIX platforms, VAX/VMS, Digital Equipment Corporation, personal computers and Microsoft Windows. \n\nInvented in 1980, Cyberquery is a declarative \"4GL\" fourth-generation programming language. Its early design was slightly influenced by RAMIS and other data access and analysis languages such as the query language on GE time sharing systems. Cyberquery automates the process of accessing files or tables and reading records or rows. This basic operation allows the user/developer to concentrate on the details of working with the data within each record, in effect working almost entirely within an implicit program loop that runs for each record. Compared to general-purpose programming languages, this automation allows the user/developer to ignore the technical details of the data and how it is stored, and concentrate on the information contained in the data.\n\nCyberquery has a data dictionary to describe the datasets users wish to access. This removes all the physical details of the file structure from each program and from the user/developer. The original target customers for Cyberquery were personnel departments, so ease of use by non computer specialists was an early design goal. This architecture had the advantage that Cyberquery is portable, reports written for one database run unmodified on any other provided the underlying data is logically similar. Differences are hidden in the data dictionary. Cyberquery is now widely deployed in Industries including Manufacturing, Finance, Medical and Retail.\n\n"}
{"id": "43555890", "url": "https://en.wikipedia.org/wiki?curid=43555890", "title": "Cyber geography", "text": "Cyber geography\n\nCyber geography is mapping the physical network of broadband cables.\n\nFurther, cyber geography relates to Papadimitriou’s “Geography of Notopia”, that is a geographic explanation and analysis of hacking, as well as to cyber-psychology.\n\n"}
{"id": "28844498", "url": "https://en.wikipedia.org/wiki?curid=28844498", "title": "Cyberwarfare in the United States", "text": "Cyberwarfare in the United States\n\nAs a major developed economy, the United States is highly dependent on the Internet and therefore greatly exposed to cyber attacks. At the same time, the United States has substantial capabilities in both defense and power projection thanks to its advanced technology and large military budget. Cyber warfare continues to be a growing threat to more physical systems and infrastructures that are linked to the internet. Malicious hacking from domestic or foreign enemies remains a constant threat to the United States. In response to these growing threats, the United States has developed significant cyber capabilities.\n\nThe United States Department of Defense recognizes the use of computers and the Internet to conduct warfare in cyberspace as a threat to national security, but also as a platform for attack.\n\nThe United States Cyber Command centralizes command of cyberspace operations, organizes existing cyber resources and synchronizes defense of U.S. military networks. It is an armed forces Unified Combatant Command.\n\nIn April 2015, the U.S. Department of Defense (DoD) published its latest Cyber Strategy building upon the previous DoD Strategy for Operating in Cyberspace published in July 2011. The DoD Cyber strategy focuses on building capabilities to protect, secure, and defend its own DoD networks, systems and information; defend the nation against cyber attacks; and support contingency plans. This includes being prepared to operate and continue to carry out missions in environments impacted by cyber attacks.\n\nThe DoD outlines three cyber missions:\nIn addition, the Cyber Strategy emphasizes the need to build bridges to the private sector, so that the best talent and technology the United States has to offer is at disposal to the DoD.\n\nThe five pillars is the base of the Department of Defense's strategy for cyber warfare. The first pillar is to recognize that the new domain for warfare is cyberspace and that it is similar to the other elements in the battlespace. The key objectives of this pillar are to build up technical capabilities and accelerate research and development to provide the United States with a technological advantage. The second pillar is proactive defenses as opposed to passive defense. Two examples of passive defense are computer hygiene and firewalls. The balance of the attacks requires active defense using sensors to provide a rapid response to detect and stop a cyber attack on a computer network. This would provide military tactics to backtrace, hunt down and attack an enemy intruder. The third pillar is critical infrastructure protection (CIP) to ensure the protection of critical infrastructure by developing warning systems to anticipate threats. The fourth pillar is the use of collective defense which would provide the ability of early detection, and incorporate it into the cyber warfare defense structure. The goal of this pillar is to explore all options in the face of a conflict, and to minimize loss of life and destruction of property. The fifth pillar is building and maintaining international alliances and partnerships to deter shared threats, and to remain adaptive and flexible to build new alliances as required. This is focused on \"priority regions, to include the Middle East, Asia-Pacific, and Europe\".\n\nShortly after his election, U.S. President Donald Trump pledged to deliver an extensive plan to improve U.S. cybersecurity within 90 days of his inauguration. Three weeks after the designated 90-day mark, he signed an executive order that aim to strengthen government networks. By the new executive order, federal-agency leaders are to be held responsible for breaches on their networks and federal agencies are to follow the National Institute of Standards and Technology Framework for Improving Critical Infrastructure Cybersecurity in consolidating risk management practices. In addition, the federal departments were to examine cybersecurity defense abilities of agencies within 90 days, focusing on \"risk mitigation and acceptance choices\" and evaluating needs for funding and sharing technology across departments.\n\nIn September, President Trump finally signed the National Cyber Strategy- \"the first fully articulated cyber strategy for the United States since 2003.\" John Bolton, the National Security Advisor, claimed in September 2018 that the Trump administration's new \"National Cyber Strategy\" has replaced restrictions on the use of offensive cyber operations with a legal regime that enables the Defense Department and other relevant agencies to operate with a greater authority to penetrate foreign networks to deter hacks on U.S. systems. Describing the new strategy as an endeavor to \"create powerful deterrence structures that persuade the adversary not to strike in the first place,\" Bolton added that decision-making for launching attacks will be moved down the chain of command from requiring the president's approval.\n\nThe Defense Department, in its strategy document released in September 2018, further announced that it would \"defend forward\" U.S. networks by disrupting \"malicious cyber activity at its source\" and endeavor to \"ensure there are consequences for irresponsible cyber behavior\" by \"preserving peace through strength.\"\n\nThe Trump administration was long criticized for delaying the release of a comprehensive cybersecurity strategy. The executive order on which the administration relied was complained to be absent of emphasis on securing the software supply chain and of adequate personnel to implement the cybersecurity guidelines.\n\nThe new National Cyber Strategy has also garnered criticisms that evaluating acts of cyberwarfare against the United States still remains ambiguous, as the current U.S. law does not specifically define what constitutes an illegal cyberact that transcends a justifiable computer activity. The legal status of most information security research in the United States is governed by 1986 Computer Freud and Abuse Act (CFAA), which was derided to be \"poorly drafted and arbitrarily enforced\" by enabling prosecution of useful information security research methods such as Nmap or Shodan. As even the needed services fall into prohibition, top-level information security experts find it challenging to improve the infrastructure of cyberdefense.\n\nIn 2011, The White House published an \"International Strategy for Cyberspace\" that reserved the right to use military force in response to a cyberattack:\n\nIn 2013, the Defense Science Board, an independent advisory committee to the U.S. Secretary of Defense, went further, stating that \"The cyber threat is serious, with potential consequences similar in some ways to the nuclear threat of the Cold War,\" and recommending, in response to the \"most extreme case\" (described as a \"catastrophic full spectrum cyber attack\"), that \"Nuclear weapons would remain the ultimate response and anchor the deterrence ladder.\"\n\nIn June 2010, Iran was the victim of a cyber attack when its nuclear facility in Natanz was infiltrated by the cyber-worm 'Stuxnet', said to be the most advanced piece of malware ever discovered and significantly increases the profile of cyberwarfare. It destroyed perhaps over 1,000 nuclear centrifuges and, according to a Business Insider article, \"[set] Tehran's atomic program back by at least two years.\"\n\nDespite a lack of official confirmation, Gary Samore, White House Coordinator for Arms Control and Weapons of Mass Destruction, made a public statement, in which he said, \"we're glad they [the Iranians] are having trouble with their centrifuge machine and that we—the US and its allies—are doing everything we can to make sure that we complicate matters for them\", offering \"winking acknowledgement\" of US involvement in Stuxnet.\n\nIn 2013, Edward Snowden, a former systems administrator for the Central Intelligence Agency (CIA) and a counterintelligence trainer at the Defense Intelligence Agency (DIA), revealed that the United States government had hacked into Chinese mobile phone companies to collect text messages and had spied on Tsinghua University, one of China's biggest research institutions, as well as home to one of China's six major backbone networks, the China Education and Research Network (CERNET), from where internet data from millions of Chinese citizens could be mined. He said U.S. spy agencies have been watching China and Hong Kong for years.\n\nAccording to classified documents provided by Edward Snowden, the National Security Agency (NSA) has also infiltrated the servers in the headquarters of Huawei, China's largest telecommunications company and the largest telecommunications equipment maker in the world. The plan is to exploit Huawei's technology so that when the company sold equipment to other countries—including both allies and nations that avoid buying American products—the NSA could roam through their computer and telephone networks to conduct surveillance and, if ordered by the president, offensive cyberoperations.\n\n\nThe Pentagon has had an information sharing arrangement, the Defense Industrial Base Cybersecurity and Information Assurance (DIBCIA) program, in place with some private defense contractors since 2007 to which access was widened in 2012.\n\nA number of other information sharing initiatives such as the Cyber Intelligence Sharing and Protection Act (CISPA) and Cybersecurity Information Sharing Act (CISA) have been proposed, but failed for various reasons including over fears that they have too few limits, and could be used to spy on the general public.\n\nThe United States Cyber Command (USCYBERCOM) is a United States Armed Forces Unified Combatant Command. USCYBERCOM plans, coordinates, integrates, synchronizes and conducts activities to: defend Department of Defense information networks and; prepare to conduct \"full spectrum military cyberspace operations\" to ensure US/Allied freedom of action in cyberspace and deny the same to adversaries.\n\nThe Army Cyber Command (ARCYBER) is an Army component command for the U.S. Cyber Command. ARCYBER has the following components:\n\nUnited States Marine Corps Forces Cyberspace Command is a functional formation of the United States Marine Corps to protect infrastructure from cyberwarfare.\n\nThe Twenty-Fourth Air Force (24 AF) will be the United States Air Force component of United States Cyber Command (USCYBER). It has the following components:\n\nThe Navy Cyber Forces (CYBERFOR) is the type commander for the U.S. Navy's global cyber workforce. The headquarters is located at Joint Expeditionary Base Little Creek-Fort Story. CYBERFOR provides forces and equipment in cryptology/signals intelligence, cyber, electronic warfare, information operations, intelligence, networks, and space. In September 2013, the United States Naval Academy will offer undergraduate students the opportunity to major in Cyber Operations.\n\nFleet Cyber Command is an operating force of the United States Navy responsible for the Navy's cyber warfare programs. Tenth Fleet is a force provider for Fleet Cyber Command. The fleet components are:\n\n\n\n"}
{"id": "18938049", "url": "https://en.wikipedia.org/wiki?curid=18938049", "title": "DVD-Video", "text": "DVD-Video\n\nDVD-Video is a consumer video format used to store digital video on DVD discs. DVD-Video was the dominant consumer home video format in Asia, North America, Europe, and Australia in the 2000s until it was supplanted by the high-definition Blu-ray disc. Discs using the DVD-Video specification require a DVD drive and an MPEG-2 decoder (e. g., a DVD player, or a computer DVD drive with a software DVD player). Commercial DVD movies are encoded using a combination MPEG-2 compressed video and audio of varying formats (often multi-channel formats as described below). Typically, the data rate for DVD movies ranges from 3 Mbit/s to 9.5 Mbit/s, and the bit rate is usually adaptive. DVD-Video was first available in Japan on November 1, 1996.\n\nThe DVD-Video specification was created by DVD Forum and can be obtained from DVD Format/Logo Licensing Corporation for a fee of $5,000. The specification is not publicly available and every subscriber must sign a non-disclosure agreement. Certain information in the DVD Book is proprietary and confidential.\n\nTo record moving pictures, DVD-Video uses either H.262/MPEG-2 Part 2 compression at up to 9.8 Mbit/s (9,800 kbit/s) or compression at up to 1.856 Mbit/s (1,856 kbit/s). DVD-Video supports video with a bit depth of 8-bits per color YCbCr with 4:2:0 chroma subsampling.\n\nThe following formats are allowed for H.262/MPEG-2 Part 2 video:\n\nThe following formats are allowed for MPEG-1 video:\n\nVideo with frame aspect ratio is supported in all video modes. Widescreen video is supported only in D-1 resolutions.\n\nThe MPEG-1 Part 2 format does not support interlaced video. The H.262/MPEG-2 Part 2 format supports both interlaced and progressive-scan content. Content with a frame rate different from one of the rates shown above can be encoded to H.262/MPEG-2 Part 2 by using pulldown. This is most commonly used to encode 23.976 frame/s content for playback at 29.97 frame/s. Pulldown can be implemented directly while the disc is mastered, by actually encoding the data on the disc at 29.97 frames/s; however this practice is uncommon for most commercial film releases, which provide content optimized for display on progressive scan television sets.\n\nAlternately, the content can be encoded on the disc itself at one of several alternate frame rates, and use flags that identify scanning type, field order and field repeating pattern. Such flags can be added in video stream by the H.262/MPEG-2 Part 2 encoder. A DVD player uses these flags to convert progressive content into interlaced video in real-time during playback, producing a signal suitable for interlaced TV sets. These flags also allow reproducing progressive content at their original, non-interlaced format when used with compatible DVD players and progressive-scan television sets.\n\nThe audio data on a DVD movie can be PCM, DTS, MPEG-1 Audio Layer II (MP2), or Dolby Digital (AC-3) format. In countries using the PAL system standard DVD-Video releases must contain at least one audio track using the PCM, MP2, or AC-3 format, and all standard PAL players must support all three of these formats. A similar standard exists in countries using the NTSC system, though with no requirement mandating the use of or support for the MP2 format. DTS audio is optional for all players, as DTS was not part of the initial draft standard and was added later; thus, many early players are unable to play DTS audio tracks. Only PCM and DTS support 96 kHz sampling rate. Because PCM, being uncompressed, requires a lot of bandwidth and DTS is not universally supported by players, 96 kHz sampling rate is rare for DVDs. The official allowed formats for the audio tracks on a DVD Video are:\n\nDVDs can contain more than one channel of audio to go together with the video content, supporting a maximum of eight simultaneous audio tracks per video. This is most commonly used for different audio formats DTS 5.1, AC-3 2.0 etc. as well as for commentary and audio tracks in different languages.\n\nDVD-Video discs have a raw bitrate of 11.08 Mbit/s, with a 1.0 Mbit/s overhead, leaving a payload bitrate of 10.08 Mbit/s. Of this, up to 3.36 Mbit/s can be used for subtitles, a maximum of 10.08 Mbit/s can be split amongst audio and video, and a maximum of 9.80 Mbit/s can be used for video alone. In the case of multiple angles the data is stored interleaved, and so there is a bitrate penalty leading to a max bitrate of 8 Mbit/s per angle to compensate for additional seek time. This limit is not cumulative, so each additional angle can still have up to 8 Mbit/s of bitrate available.\n\nProfessionally encoded videos average a bitrate of 4–5 Mbit/s with a maximum of 7–8 Mbit/s in high-action scenes. Encoding at less than the max bitrate (like this) is typically done to allow greater compatibility among players, and to help prevent buffer underruns in the case of dirty or scratched discs\n\nAiming to improve picture quality over standard editions, Columbia TriStar Home Entertainment offered \"Superbit\" a premium line of DVD-Video titles having average bitrates closer to 6 Mbit/s. Audio quality was also improved by the mandatory inclusion of both Dolby Digital and DTS 5.1 surround audio tracks. Multiple languages, angles, and extra audio tracks were eliminated to free up more space for the main title and thereby to ensure the highest data rate possible. In January 2007 the Superbit line was discontinued.\n\nSome DVD hardware or software players may play discs whose MPEG files do not conform to the above standards; commonly this is used to support discs authored with formats such as VCD and SVCD. While VCD and CVD video is supported by the DVD standard, neither SVCD video nor VCD, CVD, or SVCD audio is compatible with the DVD standard.\n\nSome hardware players will also play DVD-ROMs or CD-ROMs containing \"raw\" MPEG video files; these are \"unauthored\" and lack the file and header structure that defines DVD-Video. Standard DVD-Video files contain extra information (such as the number of video tracks, chapters and links to extra features) that DVD players use to navigate the disc.\n\nThe maximum chapters allowed per title is 99 and the maximum titles allowed per DVD is 99.\n\nAlmost all DVD-Video discs use the \"UDF bridge\" format, which is a combination of the DVD MicroUDF (a subset of UDF 1.02) and ISO 9660 file systems.\nThe UDF bridge format provides backwards compatibility for operating systems that support only ISO 9660. Most DVD players read the UDF filesystem from a DVD-Video disc and ignore the ISO9660 filesystem.\n\nA DVD volume for the DVD-Video format has the following structure of directories and files:\n\nIFO files store control and playback information – e. g. information about chapters, subtitles and audio tracks. They do not store any video or audio data or subtitles.\n\nBUP files are only backups of the IFO files.\n\nData structures recorded on a DVD-compliant disc are components of one of the four data groups called domains:\n\nVideo, audio, subtitle and navigation streams are multiplexed and stored on a DVD-Video disc in the VOB container format (Video Object). VOB is based on the MPEG program stream format, but with additional limitations and specifications in the private streams. The MPEG program stream has provisions for non-standard data (as AC-3, DTS, LPCM or subtitles used in VOB files) in the form of so-called private streams. VOB files are a very strict subset of the MPEG program stream standard. While all VOB files are MPEG program streams, not all MPEG program streams comply with the definition for a VOB file.\n\nDVD recorders can use DVD-VR or DVD+VR format instead of DVD-Video. DVD-VR format store multiplexed audiovisual content in VRO containers. VRO file is an equivalent to a collection of DVD-Video VOB files. Fragmented VRO files are not widely supported by hardware or software players and video editing software. DVD+VR standard defines a logical format for DVD-Video compliant recording on optical discs and is commonly used on DVD+R/RW media.\nDVD Video may also include up to 32 subtitle or \"subpicture\" tracks. Subtitles are usually intended as a visual help for the deaf and hearing impaired and for translating dialogs.\n\nSubtitles can serve other purposes as well. For example, in the DVD release of \"Thirteen Days\" one of the subtitle tracks includes history notes, giving additional information timed to the events depicted in the film. In the release of \"For All Mankind\" subtitles display names of the NASA missions and names of the people shown on the screen. \"Shaun of the Dead\" also features trivia facts about the making of the film on its subtitles menu.\n\nSubtitles are stored as bitmap images and therefore can contain messages in any language. Subtitles are restricted to four colors, including transparent \"color\", and thus tend to look cruder than permanent subtitles on film. Transparency allows laying subtitles over the video during playback. The subtitle tracks are contained within the VOB file of the DVD.\n\nDVD Video may also contain closed captioning material which can only be viewed on a television set with a decoder.\n\nDVD Video may contain chapters for easy navigation, and continuation of a partially watched film. If space permits, it is also possible to include several versions of certain scenes, called \"angles.\" Today, the multi-angle feature is mostly used for internationalization. For example, it can be used to supply different language versions of images containing written text when subtitles would not do (e. g., the Queen's spell book in \"Snow White\", and the scrolling text in the openings of the \"Star Wars\" films). Multiple angles have found a niche in markets such as yoga, erotica and live performances.\n\nA significant selling point of DVD Video is that the storage capacity allows for a wide variety of extra, or bonus, features in addition to the feature film. These extra features can include audio commentary; documentary features, commonly about the making of the main title; interviews; deleted footage; outtakes; photo galleries; storyboards; isolated music scores; trivia text commentary; simple games; film shorts; TV spots; radio spots; theatrical trailers which were used to promote the main title; and teaser trailers advertising related movies or DVDs.\n\nExtra features often provide entertainment or add depth and understanding to the film. Games, bloopers, and galleries provide entertainment. Deleted scenes and alternative endings allow the audience to view additional content which was not included in a theatrical release. Directors cuts allow the audience to see how the director envisioned the main title without the constraints which are placed on a theatrical release.\n\nOther extras that can be included on DVDs are motion menus, still pictures, up to 32 selectable subtitles, seamless branching for multiple storylines, up to 9 camera angles, and DVD-ROM / data files that can be accessed on a computer.\n\nExtra features require additional storage space, which often means encoding the main title with lower than possible data rate to fit both the main title and the extras on one disc. Lower data rate may decrease visual and sound quality, which manifests itself in various compression artifacts. To maintain quality the main title and the extras may be released on several discs, or the extras may be omitted completely like in the \"Superbit\" line of DVDs.\n\nDVD-Video has four complementary systems designed to restrict the DVD user in various ways: Macrovision, Content Scramble System (CSS), region codes, and disabled user operations (UOPs). There are also anti-ripping techniques intended to foil ripping software.\n\nMany DVD-Video titles use Content Scramble System (CSS) encryption, which is intended to discourage people from copying the disc. Usually, users need to install software provided on the DVD or downloaded from the Internet such as MPlayer, TotalMedia Theatre, PowerDVD, VLC or WinDVD to be able to view the disc in a computer system.\n\nCSS does not make it difficult (any more) to copy the digital content now that a decoder (DeCSS) has been released, nor is it possible to distinguish between legal and illegal copies of a work, but CSS does restrict the playback software that may be used.\n\nCSS has caused major problems for the inclusion of DVD players in any open source operating systems, since open source player implementations are not officially given access to the decryption keys or license to the patents involved in CSS. Proprietary software players were also difficult to find on some platforms. However, a successful effort has been made to write a decoder by reverse engineering, resulting in DeCSS. This has led to long-running legal battles and the arrest of some of those involved in creating or distributing the DeCSS code, through the use of the controversial U.S. Digital Millennium Copyright Act (DMCA), on the grounds that such software could also be used to facilitate unauthorized copying of the data on the discs. The Videolan team, however, went on to make the libdvdcss library. Unlike DeCSS, libdvdcss can access a CSS-encrypted DVD without the need of a cracked key, thus enabling playback of such discs on opensource players without legal restraints (although DVD rippers using this library may still be subject to restrictions).\n\nThe DMCA currently affects only the United States, however many other countries are signatories to the similar WIPO Treaty. In some countries it is not illegal to use de-scrambling software to bypass the DVD restrictions. A number of software programs have since appeared on the Web to view DVDs on a number of different platforms.\n\nOther measures such as anti-ripping, as well as U.S. and non-U.S. copyright law, may be used to prevent making unauthorized copies of DVDs. CSS decrypting software, or ripping software, such as DVD Decrypter, AnyDVD, MacTheRipper, and DVD Shrink allows a disc to be copied to hard disk unscrambled. Some DeCSS applications also remove Macrovision, region codes, and disabled user operations (UOPs).\n\nAfter DeCSS ripping software became available, companies developed techniques to introduce errors in DVD-Video discs that do not normally affect playback and navigation of a disc, but can cause problems in software that attempts to copy the entire disc. These approaches, which are not part of the official DVD-Video specification, include Sony ARccOS Protection, Macrovision RipGuard, X-protect, ProtectDisc SecureBurn, Anaho, Fortium, and others. All of these methods have been circumvented (as might have been expected, since all standard DVD players naturally circumvent them to play and navigate the discs normally). Riplock is a feature that reduces drive noise during playback but inadvertently reduces ripping speed.\n\nDVD-Video allows the disc to specify whether or not the user may perform any operation, such as selecting a menu, skipping chapters, forwarding or rewinding essentially any function on the remote control. This is known as User Operation Prohibitions, or Prohibited User Operations (UOPs or PUOs). Most DVD players respect these commands (e. g., by preventing skipping or fast-forwarding through a copyright message or an advertisement at the beginning of a disc). However, grey market players ignore UOPs and some DVD \"re-authoring\" software packages allow the user to produce a copy without these restrictions. The legality of these activities varies by jurisdiction and is the subject of debate. (See fair use.)\n\nEach DVD-Video disc contains one or more region codes, denoting the area(s) of the world in which distribution and playback are intended. The commercial DVD player specification dictates that a player must only play discs that contain its region code. In theory, this allows the motion picture studios to control the various aspects of a release (including content, date and price) on a region-by-region basis, or ensure the success of \"staggered\" or delayed cinema releases from country to country. For example, the British movie \"28 Days Later\" was released on DVD in Europe several months prior to the film's release in North American movie theaters. Regional coding kept the European DVD unplayable for most North American consumers, thereby ensuring that ticket sales would be relatively unaffected. \n\nIn practice, many DVD players allow playback of any disc, or can be modified to do so. Entirely independent of encryption, region coding pertains to regional lockout, which originated in the video game industry.\n\nFrom a worldwide perspective regional coding may be seen as a failure. A huge percentage of players outside of North America can be easily modified (and are even sold pre-modified by mainstream stores such as Amazon.co.uk) to ignore the regional codes on a disc. This, coupled with the fact that almost all televisions in Europe and Australasia are capable of displaying NTSC video (at the very least, in black and white), means that consumers in these regions have a huge choice of discs. Contrary to popular belief, this practice is not illegal and in some countries that strongly support free trade it is encouraged.\n\nA normal DVD player can only play region-coded discs designated for the player's own particular region. However, a code-free or region-free DVD player is capable of playing DVDs from any of the six regions around the world.\n\nThe CSS license prohibits manufacturing of DVD players that are not set to a single region by default. While the same license prohibits manufacturers from including prominent interfaces to change the region setting it does not clearly prevent them from including \"hidden\" menus that enable the player's region to be changed; as such, many high-end models in the U.S. include password-protected or otherwise hidden methods to enable multi-region playback. Conversely in the UK and Ireland many cheap DVD players are multi-region while more expensive systems, including the majority of home cinema systems, are preset to play only region 2 discs.\n\nIn China, DVD-Videos for television series are usually released in MPEG-1 video, with MP2 audio. By forgoing Dolby standards, manufacturers cut costs considerably; encoding in lower bit-rates also allows a TV series to be squeezed onto fewer discs. There is no region coding in such cases.\n\nThere are also two additional region codes, region 7, which is reserved, and region 8, which is used exclusively for passenger transport such as airlines and cruise ships.\n\nA virtual machine implemented by the DVD player runs bytecode contained on the DVD. This is used to control playback and display special effects on the menus. The instruction set is called the Virtual Machine (VM) DVD command set. There are 16 general parameter registers (GPRM) to hold temporary values and 24 system parameters (SPRM). As a result of a moderately flexible programming interface, DVD players can be used to play games, such as the DVD re-release of \"Dragon's Lair\", along with more sophisticated and advanced games such as \"Scene It\", all of which can be run on standard DVD players.\n\nModern DVD recorders often support additional formats, including DVD+/-R/RW, CD-R/RW, MP3, WMA, SVCD, JPEG, PNG, SVG, KAR and MPEG-4 (DivX/Xvid). Some also include USB ports or flash memory readers. Player prices range from as low as US$ 20 (GB£ 10) to as high as US$2,700 (GB£1,350).\n\nDVD drives for computers usually come with one of two kinds of Regional Playback Control (RPC), either RPC-1 or RPC-2. This is used to enforce the publisher's restrictions on what regions of the world the DVD can be played. (See Regional lockout and DVD region codes.) While Open source software DVD players allow everything, commercial ones (both standalone models and software players) come further encumbered with restrictions forbidding the viewer from skipping (or in some cases fast-forwarding) certain content such as copyright warnings or advertisements. (See User operation prohibition.)\n\nVideo game systems with DVD-Video playback functionality include: Panasonic Q, PlayStation 2, PlayStation 3, PlayStation 4, Wii (with an unsupported hack), Xbox (additional remote required), Xbox 360, and Xbox One.\n\nIn April 2000, Sonic Solutions and Ravisent announced hDVD, a high-definition extension to DVD. However hDVD failed to gain much popularity.\n\nOn November 18, 2003, the Chinese news agency Xinhua reported the final standard of the Chinese government-sponsored Enhanced Versatile Disc (EVD) which is another extension of standard DVD. Shortly thereafter the development of the format was halted by a licensing dispute between Chinese companies and On2 Technologies, but on December 6, 2006, 20 Chinese electronic firms unveiled 54 prototype EVD players and announced their intention for the format to completely replace DVDs in China by 2008. However, due to a lack of sales, support for EVD has recently been dropped by the Xinhua Bookstore in Wuhan, which was a major supporter of the format.\n\nTwo competing high-definition (HD) optical-disc formats, HD DVD and Blu-ray, were introduced in 2006. The HD DVD format, promoted by Toshiba, had the backing by the DVD Forum, which voted to make it the official successor to DVD. Opposing HD DVD was the Blu-ray format, led by the Blu-ray Disc Association, which shares many members with the DVD forum.\n\nWith HD DVD launched in March 2006 and Blu-ray launched in June of the same year, a format war started. Industry analysts likened the situation to the VHS/Betamax format war of the 1980s. At the time of their launch, consumer awareness of either high-definition format was severely limited, with the end result that most consumers avoided both formats, already content with DVD. In February 2008, Toshiba capitulated, citing low demand for HD DVD and the faster growth of Blu-ray, and the inclusion of the format in the video game system PlayStation 3 (PS3), among other reasons. Toshiba ended production of their HD DVD players and discontinued promotion of the format, while the HD DVD movie release schedule concluded by June 2008.\n\nAfter HD DVD was discontinued, Blu-ray became the \"de facto\" high-definition optical disc format. However, sales figures suggest that DVD is in no immediate danger of disappearing. All standard DVDs will play on existing Blu-ray players, making the switch to Blu-ray much easier than the switch from VHS to DVD. Moreover, some labels are cutting back on Blu-ray Disc releases in favor of DVD-Video, claiming that low sales do not justify the more expensive Blu-ray Disc format. In addition, a growing number of hardware vendors are enhancing their Blu-ray players with Internet connectivity for subscription-based video downloads.\n\nChina Blue High-definition Disc (CBHD) was introduced in September 2007. This format is based on HD DVD. While the Blu-ray format is marketed internationally, CBHDs have sold significantly in the Chinese market.\n\n\n"}
{"id": "52770475", "url": "https://en.wikipedia.org/wiki?curid=52770475", "title": "Ed Parsons", "text": "Ed Parsons\n\nEd Parsons (born September 26, 1965) is a London-based Geospatial Technologist and tech evangelist at Google. He is working to evangelise geospatial data for commercial application and consequently, to improve the usability and efficiency of location based tools at Google. He is credited as being one of the core proponents of Google Street View.\n\nParsons is a registered member of the Royal Geographical Society and he has been employed at Google since 2007. He is a supporter of the relatively new concept of Neogeography.\nIn 2015, he was appointed co-chair of the W3C/OGC Spatial Data on the Web Working Group, a collaboration between the Open Geospatial Consortium and World Wide Web Consortium along with Kerry Taylor from the Australian National University.\n\nParsons is a British citizen who graduated from the Kingston Polytechnic (now Kingston University) in 1987 with a BSc (hons) in Geography. In 1989, he was a part of the team that established the world's first undergraduate course in Geographic information system at Kingston University. He completed his master's degree from the Cranfield Institute of Technology with an M.S. in Applied Remote sensing in 1991.\n\nAfter completing his M.S., Parsons began teaching GIS at the Kingston University. He continued teaching there until 1998. During his tenure, he is credited with having created the first online map of general election results of 1997.\n\nIn 1998, he moved to Autodesk as an EMEA Applications Manager for the Geographical Information Systems Division. He joined Ordnance Survey in 2001 as the organization’s first Chief Technology Officer and played an instrumental role in moving the course of the organization from mapping to geographical information and went on to become the youngest director of IT.\n\nWhen Google Maps was launched in 2005, Parsons was quite excited, as a technology enthusiast and a geography aficionado. In his blog he described the event as ‘’In a few months Google Maps has done more to allow the individual to develop mapping based websites than the traditional GIS industry has done in 10 years. However, in June 2005, he was one of the first observers of the typing error that Belgium had swapped places with Netherlands on Google Maps.\n\nParsons left Ordnance Survey in December 2006 and he was offered a job by Google. Parsons began working at the London office of Google. He also set up his own company Open Goematics, a strategic consultancy firm focused on the geospatial technology tracking and Neogeography. In 2010, Parsons received an honorary PhD in Science from the Kingston University in recognition of his contributions to the field of GIS and to the university.\n\nParsons oversaw the coordination of Google Maps and Historypin in 2012 in an initiative to recover lost photographs and document the Royal appearances of the Queen on an interactive map of the world provided by Google Maps.\n\nIn December, 2015, Parsons was invited to deliver a keynote address at the GSDI World Conference in Taiwan.\n\nParsons is a member of the Board of Directors of the Open Geospatial Consortium.\n\nIn 2017 Parsons was appointed as Visiting Professor at University College London in the Department of Civil Environmental and Geomatic Engineering.\n\n"}
{"id": "21733398", "url": "https://en.wikipedia.org/wiki?curid=21733398", "title": "Energy &amp; Fuels", "text": "Energy &amp; Fuels\n\nEnergy & Fuels is a peer-reviewed scientific journal published by the American Chemical Society. It was established in 1987. Its publication frequency switched from bimonthly to monthly in 2009. The editor-in-chief is Michael T. Klein (University of Delaware).\n\nThe journal is abstracted and indexed in:\n\nAccording to the \"Journal Citation Reports\", the journal has a 2014 impact factor of 2.790.\n"}
{"id": "453019", "url": "https://en.wikipedia.org/wiki?curid=453019", "title": "Enhanced-definition television", "text": "Enhanced-definition television\n\nEnhanced-definition television, or extended-definition television (EDTV) is an American Consumer Electronics Association (CEA) marketing shorthand term for certain digital television (DTV) formats and devices. Specifically, this term defines formats that deliver a picture superior to that of standard-definition television (SDTV) but not as detailed as high-definition television (HDTV).\n\nThe term refers to devices capable of displaying 480-line or 576-line signals in progressive scan, commonly referred to as 480p (NTSC-HQ) and 576p (PAL) respectively, as opposed to interlaced scanning, commonly referred to as 480i (NTSC) or 576i (PAL). High-motion is optional for EDTV.\n\nIn other countries definitions may vary.\n\nAs EDTV signals require more bandwidth (due to frame doubling) than is feasible with SDTV connection standards (such as composite video, SCART or S-Video), higher bandwidth media must be used to accommodate the additional data transfer. To achieve EDTV, consumer electronic devices such as a progressive scan DVD player or modern video game consoles must be connected through at least a component video cable (typically using 3 RCA cables for video), a VGA connector, or a DVI or HDMI connector. For over-the-air television broadcasts, EDTV content uses the same connectors as HDTV.\n\nEDTV broadcasts use less digital bandwidth than HDTV, so TV stations can broadcast several EDTV stations at once. Like SDTV, EDTV signals are broadcast with non-square pixels. Since the same number of horizontal pixels are used in 4:3 and 16:9 broadcasts, the 16:9 mode is sometimes referred to as anamorphic widescreen. Most EDTV displays use square pixels, yielding a resolution of 852 × 480. However, since no broadcasts use this pixel count, such displays always scale anything they show. The only sources of 852 × 480 video are Internet downloads, such as some video games. Unlike 1080i and SDTV formats, progressive displays (such as plasma displays and LCDs) can show EDTV signals without the need to de-interlace them first. This can result in a reduction of motion artifacts. However to achieve this most progressive displays require the broadcast to be frame doubled (i.e., 25 to 50 and 30 to 60) to avoid the same motion flicker issues that interlacing fixes.\n\nThe progressive output of a DVD player can be considered the baseline for EDTV. Movies shot at 24 frames-per-second (fps) are often encoded onto a DVD at 24 fps progressive, and most DVD players do the 2:2 or 3:2 pulldown conversion internally, before feeding the output to (usually) an interlaced display, or here, a progressive 576p or 480p.\n\nThe progressive 24 fps DVD will have a unifying effect on PAL and NTSC, just as film does, perhaps requiring conversion of the number of lines but without a conflict between field and frame rate. The player converts the video to the more-conventional video formats, on the fly, by simply repeating each field. It converts for PAL (referring here to 625 line 575 active line used with PAL as well as the chrominance aspects), by repeating each frame twice with a corresponding interlace, or for NTSC, by repeating some 480p frames 2 times and others 3 times (3:2 pulldown), to make 24 fps material play at 30fps, or 60 \"fields\" per second.\n\nOn an EDTV display, or on HDTVs in 480p mode, DVD players can display progressive disc content without needing to convert it to interlaced format. Various signal processing tricks are then used to fake the progressive scan; the quality of this depends on the quality of the upconversion process.\n\nBlu-ray Disc and HD DVD formats can encode all EDTV forms, but because HDTV is a primary selling point of Blu-ray/HD DVDs, to date, this has been used only on certain bonus content.\n\nThe video resolution of video game consoles reached EDTV specifications starting with the Sega Dreamcast, becoming the first mainstream console with a VGA output, supporting EDTV. The PlayStation 2, Nintendo GameCube, Microsoft Xbox and Wii are also EDTV compatible with a component connection. The Xbox 360 can output 480p via YPP component, VGA and HDMI (newer models only) cables. The PlayStation 3 outputs EDTV via its HDMI and component video (YPP) connections; 480p is only available on NTSC consoles while 576p is only available on PAL consoles.\n"}
{"id": "4947153", "url": "https://en.wikipedia.org/wiki?curid=4947153", "title": "Experiments in Art and Technology", "text": "Experiments in Art and Technology\n\nExperiments in Art and Technology (E.A.T.) was a non-profit and tax-exempt organization established to develop collaborations between artists and engineers. The group operated by facilitating person-to-person contacts between artists and engineers, rather than defining a formal process for cooperation. E.A.T. initiated and carried out projects that expanded the role of the artist in contemporary society and helped explore the separation of the individual from technological change.\n\nE.A.T. was officially launched in 1967 by the engineers Billy Klüver and Fred Waldhauer and the artists Robert Rauschenberg and Robert Whitman. These men had previously collaborated in 1966 when they together organized \"\", a series of performance art presentations that united artists and engineers. 10 New York artists worked with 30 engineers and scientists from the world-renowned Bell Telephone Laboratories to create groundbreaking performances that incorporated new technology. Artists involved with \"9 Evenings: Theatre and Engineering\" include: John Cage, Lucinda Childs, Öyvind Fahlström, Alex Hay, Deborah Hay, Steve Paxton, Yvonne Rainer, Robert Rauschenberg, David Tudor, and Robert Whitman. Notable engineers involved include: Bela Julesz, Billy Klüver, Max Mathews, John Pierce, Manfred Schroeder, and Fred Waldhauer.\n\nVideo projection, wireless sound transmission, and Doppler sonar had never been seen in the art of the 1960s. These art performances still resonate today as forerunners of the close and rapidly evolving relationship between artists and technology. The performances were held in New York City's 69th Regiment Armory, on Lexington Avenue between 25th and 26th Streets as an homage to the original and historical 1913 Armory show.\n\nThe pinnacle of E.A.T. activity is generally considered to be the Pepsi Pavilion at Expo '70 at Osaka Japan where E.A.T. artists and engineers collaborated to design and program an immersive dome that included a fog sculpture by Fujiko Nakaya. Organized by E.A.T. founders Billy Klüver and Robert Whitman, the project was led by a core design team that also included Robert Breer, Frosty Myers, David Tudor, and a group of over 75 artists and engineers from the US and Japan. The original structure consisted of a Buckminster Fuller-style geodesic dome covered by a water vapor cloud sculpture, designed by Fujiko Nakaya, to which the architect John Pearce had devised a way to fit a Mylar mirror inside the structure.\n\nThe optical effect in the spherical mirror produced real images resembling that of a hologram. Due to the size of the mirror, a spectator looking at an image could walk around it and see it from all sides. On the terrace surrounding the Pepsi Pavilion were seven of Robert Breer’s \"Floats\", six-foot high kinetic sculptures that moved around at less than 2 feet per minute, while emitting sounds. When a \"Float\" hit an obstacle or was pushed it would reverse direction. \n\nTwenty-eight regional E.A.T. chapters were established throughout the U.S. in the late 1960s to promote collaborations between artists and engineers and expand the artist’s role in social developments related to new technologies. In 2002 the University of Washington hosted a reunion to celebrate the history of these regional liaisons and consider the legacy of E.A.T. for artists working with new technologies in the 21st century.\n\nE.A.T. activity has entered the canons of performance art, experimental noise music and theater, bridging the gap from the eras of Dada, Fluxus and the Happenings/Actions of the 1960s, through the current generation of digital artists for whom multimedia and technology are the norm. The lineage from E.A.T. experimentations in the 1960s which led to media-art explorations of the 1990s and beyond, is the same historical pathway that has led to the ArtScience movement of the 2000s -- the latter an amalgamation of E.A.T., the environmental/ecology movements, and the expanding ontological impact scientific practice has on society. Most recently, E.A.T. included a collaboration with singer songwriter Beatie Wolfe for its 50 year anniversary, which involved the artist releasing her album as the world's first live 360˚ Augmented reality stream, from the Bell Labs anechoic chamber.\n\nIn 1972 Billy Klüver, Barbara Rose and Julie Martin edited the book \"Pavilion\", that documented the design and construction of the E.A.T. Pepsi Pavilion for Expo '70 in Osaka, Japan.\n\nIn 2001 Billy Klüver produced an exhibition of photo and text panels entitled \"The Story of E.A.T.: Experiments in Art and Technology, 1960 – 2001 by Billy Klüver.\" It was first shown in Rome and then again at Sonnabend Gallery in 2002. The exhibition went to Lafayette College in the spring 2002, then to the Evolution Festival in Leeds, England, and University of Washington, in Seattle. In 2003 it traveled to San Diego State University in San Diego, California and then to a gallery in Santa Maria, California run by Ardison Phillips – who was the artist who managed the Pepsi Pavilion in 1970. From April to June 2003 a Japanese version was shown at a large exhibition at the NTT Intercommunication Center (ICC) in Tokyo which also included a number of object/artifacts and documents and E.A.T. posters, as well as works of art that Klüver and E.A.T. were involved in. A similar showing took place in Norrköping Museum of Art, Norrköping, Sweden in September 2004; and a small version of the panels were presented in 2008 at Stevens Institute of Technology as part of a celebration of Experiments in Art and Technology. \nIn November 2017, the E.A.T. projects were part of the \"VARIATION ArtJaws media art fair and exhibition\" at the Cité Internationale des Arts in Paris: All the panels and some of the below mentioned documentaries were exhibited.\n\nThe DVD Series (director: Barbro Schultz Lundestam) is an important documentation of the collaborations between the artists and engineers that produced innovative works using these emerging technologies.\n\n\n\n\n"}
{"id": "41667831", "url": "https://en.wikipedia.org/wiki?curid=41667831", "title": "Financial software", "text": "Financial software\n\nFinancial software or financial system software is special application software that records all the financial activity within a business organization. Basic features of this system not only includes all the modules of accounting software like accounts payable, accounts receivable, ledger, reporting modules and payroll but also to explore alternative investment choices and calculate statistical relationships. Features of the system may vary depending on what type of business it is being used for. Primarily, the goal of the financial software is to record, categorize, analyze, compile, interpret and then present an accurate and updated financial dates for every transaction of the business.\n\nPipeline tracking is one of the key features of an accounting system and software for asset management. This provides summarized information on all the details pertaining to the potential investments that are being monitored. The system and software will organize the pipeline and record the source, execution status, approval status, feasible investment capital and the targeted purchase price. It provides an efficient analysis of the best deals, timing and price for the utilization of the investment team. Pipeline tracking provides tracking of the source, history and status. It also provides customized classifications and categories. The system can easily execute a cash flow model and create return assumptions.\n\nAsset management is another important feature of a financial software. It uses the updated status of the investment to provide the necessary tools in creating every possible outcome, such as future payments that are distressed, conversions for debt to equity and maturity of loans. It also provides an efficient tracking of payment dates and rates. Updated financial statements are readily available, which makes it very easy to determine credit standing and as a result make proper adjustments on the projections. Asset management can modify dates of payment, conversion of floating to fixed rates, deferred payments, interest rates, maturity extensions and change schedules for repayment. It also uses various assumptions to store and run multiple cases such as downside, base and upside.\n\nThe next feature is fund management, which provides an accurate projection of all the investments as well as factors of the borrowing and operating cost of the fund in order to create a view of the cash levels in the future and investment returns. This system aids in the evaluation and structuring of any fund. Fund management provides a combination of the projections of the cash flow on all investments in order to create a monthly summary. It provides customized assumptions on the leverage cost, interest income, taxes and expenses. The system also creates several scenarios concerning the cash allocation such as reinvestments, distribution of investors and fresh investments. It also creates an analysis of the leverage and call of the capital. Income statements and anticipated balance sheets can also be efficiently created with the use of the system.\n\nAnother feature of the financial software, is the data warehousing. This feature syncs the accounting system and retrieves investment transactions. It also uses a customizable category or name. This key feature allows an effortless re-categorization of the investments. The calculation of investment statistics will depend on the computation of the user at any given moment. Customized reports on the performance of the investment can be created using any of the calculations programmed in the database of the system. There are approximately more than 100 various calculations programmed in the system. If there is a need for more calculations, then it can easily be provided for the user. Several investments can be categorized into subgroups or groups and they will be used for the creation of totals. It identifies the total price of the fixed income in comparison to the equity investments.\n\nPipeline tracking has multiple benefits and one of them is that it provides a standard layout for possible deals. It also detects the deals that have been approved but are still awaiting execution. It provides an accurate comparison of the cost of investment with the expected returns. The system can easily provide a recycle plan for investment opportunities. It also creates a manifold portfolio with potential returns by utilizing information on the target industries or regions. Pipeline tracking speeds up the decision-making of the committee for financial investment.\n\nThere are many benefits of the fund management feature of the financial software. Fund management can determine which specific investments are creating returns. It also pinpoints the availability or shortage of cash. It provides an evaluation of the leverage options as well as determines the effect on the returns. The system also creates a central and systematic modelling, management and analysis of the funds.\n\nThe benefits of asset management include the creation of a platform for maintaining the projection of cash flow on investments. Excel models also eliminate the possibility of manual errors. Asset management increases the scale and adds investments without the loss of analytic perspective. Through this software managers of portfolios have a better grasp on the performance level of the investment. It also provides accurate information on whether the prediction of the analysts was close to the actual performance of the investment.\n\n"}
{"id": "1198197", "url": "https://en.wikipedia.org/wiki?curid=1198197", "title": "Function generator", "text": "Function generator\n\nA function generator is usually a piece of electronic test equipment or software used to generate different types of electrical waveforms over a wide range of frequencies. Some of the most common waveforms produced by the function generator are the sine wave , square wave, triangular wave and sawtooth shapes. These waveforms can be either repetitive or single-shot (which requires an internal or external trigger source). Integrated circuits used to generate waveforms may also be described as function generator ICs.\n\nIn addition to producing sine waves, function generators may typically produce other repetitive waveforms including sawtooth and triangular waveforms, square waves, and pulses. Another feature included on many function generators is the ability to add a DC offset.\n\nAlthough function generators cover both audio and RF frequencies, they are usually not suitable for applications that need low distortion or stable frequency signals. When those traits are required, other signal generators would be more appropriate.\n\nSome function generators can be phase-locked to an external signal source (which may be a frequency reference) or another function generator.\n\nFunction generators are used in the development, test and repair of electronic equipment. For example, they may be used as a signal source to test amplifiers or to introduce an error signal into a control loop. Function generators are primarily used for working with analog circuits, related pulse generators are primarily used for working with digital circuits.\n\nSimple function generators usually generate triangular waveform whose frequency can be controlled smoothly as well as in steps. This triangular wave is used as the basis for all of its other outputs. The triangular wave is generated by repeatedly charging and discharging a capacitor from a constant current source. This produces a linearly ascending and descending voltage ramp. As the output voltage reaches upper or lower limits, the charging or discharging is reversed using a comparator, producing the linear triangle wave. By varying the current and the size of the capacitor, different frequencies may be obtained. Sawtooth waves can be produced by charging the capacitor slowly, using a current, but using a diode over the current source to discharge quickly - the polarity of the diode changes the polarity of the resulting sawtooth, i.e. slow rise and fast fall, or fast rise and slow fall.\n\nA 50% duty cycle square wave is easily obtained by noting whether the capacitor is being charged or discharged, which is reflected in the current switching comparator output. Other duty cycles (theoretically from 0% to 100%) can be obtained by using a comparator and the sawtooth or triangle signal. Most function generators also contain a non-linear diode shaping circuit that can convert the triangle wave into a reasonably accurate sine wave by rounding off the corners of the triangle wave in a process similar to clipping in audio systems.\n\nA typical function generator can provide frequencies up to 20 MHz. RF generators for higher frequencies are not function generators in the strict sense since they typically produce pure or modulated sine signals only.\n\nFunction generators, like most signal generators, may also contain an attenuator, various means of modulating the output waveform, and often the ability to automatically and repetitively \"sweep\" the frequency of the output waveform (by means of a voltage-controlled oscillator) between two operator-determined limits. This capability makes it very easy to evaluate the frequency response of a given electronic circuit.\n\nSome function generators can also generate white or pink noise.\n\nMore advanced function generators are called arbitrary waveform generators (AWG). They use direct digital synthesis (DDS) techniques to generate any waveform that can be described by a table of amplitudes.\n\nTypical specifications for a general-purpose function generator are:\n\nA completely different approach to function generation is to use software instructions to generate a waveform, with provision for output. For example, a general-purpose digital computer can be used to generate the waveform; if frequency range and amplitude are acceptable, the sound card fitted to most computers can be used to output the generated wave.\n\nAn electronic circuit element used for generating waveforms within other apparatus that can be used in communications and instrumentation circuits, and also in a function generator instrument. Examples are the Exar XR2206 and the Intersil ICL8038 integrated circuits, which can generate sine, square, triangle, ramp, and pulse waveforms at a voltage-controllable frequency.\n\nAn electronic circuit element that provides an output proportional to some mathematical function (such as the square root) of its input; such devices are used in feedback control systems and in analog computers. Examples are the Raytheon QK329 square-law tube and the Intersil ICL8048 Log/Antilog Amplifier.\n\nMechanical function generators are linkages, cam-follower mechanisms or non-circular gears, designed to reproduce different types of functions, either periodic (like sine or cosine functions), or single-shot (logarithm, parabolic, tangent functions etc.).\nMeasurement instruments like pressure gauges, altimeters and barometers include linkage-type function generators as linearization means. \nBefore the advent of digital computers, mechanical function generators were used in the construction of gun fire control systems, and mechanical calculators.\n\n\n"}
{"id": "548308", "url": "https://en.wikipedia.org/wiki?curid=548308", "title": "Gas-filled tube", "text": "Gas-filled tube\n\nA gas-filled tube, also known as a discharge tube, is an arrangement of electrodes in a gas within an insulating, temperature-resistant envelope. Gas-filled tubes exploit phenomena related to electric discharge in gases, and operate by ionizing the gas with an applied voltage sufficient to cause electrical conduction by the underlying phenomena of the Townsend discharge. A gas-discharge lamp is an electric light using a gas-filled tube; these include fluorescent lamps, metal-halide lamps, sodium-vapor lamps, and neon lights. Specialized gas-filled tubes such as krytrons, thyratrons, and ignitrons are used as switching devices in electric devices.\n\nThe voltage required to initiate and sustain discharge is dependent on the pressure and composition of the fill gas and geometry of the tube. Although the envelope is typically glass, power tubes often use ceramics, and military tubes often use glass-lined metal. Both hot cathode and cold cathode type devices are encountered.\n\nHydrogen is used in tubes used for very fast switching, e.g. some thyratrons, dekatrons, and krytrons, where very steep edges are required. The build-up and recovery times of hydrogen are much shorter than in other gases. Hydrogen thyratrons are usually hot-cathode. Hydrogen (and deuterium) can be stored in the tube in the form of a metal hydride, heated with an auxiliary filament; hydrogen by heating such storage element can be used to replenish cleaned-up gas, and even to adjust the pressure as needed for a thyratron operation at a given voltage.\n\nDeuterium is used in ultraviolet lamps for ultraviolet spectroscopy, in neutron generator tubes, and in special tubes (e.g. crossatron). It has higher breakdown voltage than hydrogen. In fast switching tubes it is used instead of hydrogen where high voltage operation is required. For a comparison, the hydrogen-filled CX1140 thyratron has anode voltage rating of 25 kV, while the deuterium-filled and otherwise identical CX1159 has 33 kV. Also, at the same voltage the pressure of deuterium can be higher than of hydrogen, allowing higher rise rates of rise of current before it causes excessive anode dissipation. Significantly higher peak powers are achievable. Its recovery time is however about 40% slower than for hydrogen.\n\nNoble gases are frequently used in tubes for many purposes, from lighting to switching. Pure noble gases are employed in switching tubes. Noble-gas-filled thyratrons have better electrical parameters than mercury-based ones. The electrodes undergo damage by high-velocity ions. The neutral atoms of the gas slow the ions down by collisions, and reduce the energy transferred to the electrodes by the ion impact. Gases with high molecular weight, e.g. xenon, protect the electrodes better than lighter ones, e.g. neon.\n\n\n\nIn special cases (e.g., high-voltage switches), gases with good dielectric properties and very high breakdown voltages are needed. Highly electronegative elements, e.g., halogens, are favored as they rapidly recombine with the ions present in the discharge channel. One of the most popular choices is sulfur hexafluoride, used in special high-voltage applications. Other common options are dry pressurized nitrogen and halocarbons.\n\nThe fundamental mechanism is the Townsend discharge, which is the sustained multiplication of electron flow by ion impact when a critical value of electric field strength for the density of the gas is reached. As the electric field is increased various phases of discharge are encountered as shown in the accompanying plot. The gas used dramatically influences the parameters of the tube. The breakdown voltage depends on the gas composition and electrode distance; the dependencies are described by Paschen's law.\n\nThe gas pressure may range between ; most commonly, pressures between 1–10 torr are used. The gas pressure influences the following factors:\n\nAbove a certain value, the higher the gas pressure, the higher the ignition voltage. High-pressure lighting tubes can require a few kilovolts impulse for ignition when cold, when the gas pressure is low. After warming up, when the volatile compound used for light emission is vaporized and the pressure increases, reignition of the discharge requires either significantly higher voltage or reducing the internal pressure by cooling down the lamp. For example, many sodium vapor lamps cannot be re-lit immediately after being shut off; they must cool down before they can be lit up again.\n\nThe gas tends to be used up during the tube operation, by several phenomena collectively called clean-up. The gas atoms or molecules are adsorbed on the surfaces of the electrodes. In high voltage tubes, the accelerated ions can penetrate into the electrode materials. New surfaces, formed by sputtering of the electrodes and deposited on e.g. the inner surfaces of the tube, also readily adsorb gases. Non-inert gases can also chemically react with the tube components. Hydrogen may diffuse through some metals.\n\nFor removal of gas in vacuum tubes, getters are used. For resupplying gas for gas-filled tubes, replenishers are employed. Most commonly, replenishers are used with hydrogen; a filament made from a hydrogen-absorbing metal (e.g. zirconium or titanium) is present in the tube, and by controlling its temperature the ratio of absorbed and desorbed hydrogen is adjusted, resulting in controlling of the hydrogen pressure in the tube. The metal filament acts as a hydrogen storage. This approach is used in e.g. hydrogen thyratrons or neutron tubes. Usage of saturated mercury vapor allows using a pool of liquid mercury as a large storage of material; the atoms lost by clean-up are automatically replenished by evaporation of more mercury. The pressure in the tube is however strongly dependent on the mercury temperature, which has to be controlled carefully.\n\nLarge rectifiers use saturated mercury vapor with a small amount of an inert gas. The inert gas supports the discharge when the tube is cold.\n\nThe mercury arc valve current-voltage characteristics are highly dependent on the temperature of the liquid mercury. The voltage drop in forward bias decreases from about 60 volts at 0 °C to somewhat above 10 volts at 50 °C and then stays constant; the reverse bias breakdown (\"arc-back\") voltage drops dramatically with temperature, from 36 kV at 60 °C to 12 kV at 80 °C to even less at higher temperatures. The operating range is therefore usually between 18–65 °C.\n\nThe gas in the tube has to be kept pure to maintain the desired properties; even small amount of impurities can dramatically change the tube values; presence of non-inert gases generally increases the breakdown and burning voltages. The presence of impurities can be observed by changes in the glow color of the gas. Air leaking into the tube introduces oxygen, which is highly electronegative and inhibits the production of electron avalanches. This makes the discharge look pale, milky, or reddish. Traces of mercury vapors glow bluish, obscuring the original gas color. Magnesium vapor colors the discharge green. To prevent outgassing of the tube components during operation, a bake-out is required before filling with gas and sealing. Thorough degassing is required for high-quality tubes; even as little as 10 torr (≈1 μPa) of oxygen is sufficient for covering the electrodes with monomolecular oxide layer in few hours. Non-inert gases can be removed by suitable getters. for mercury-containing tubes, getters that do not form amalgams with mercury (e.g. zirconium, but not barium) have to be used. Cathode sputtering may be used intentionally for gettering non-inert gases; some reference tubes use molybdenum cathodes for this purpose.\n\nPure inert gases are used where the difference between the ignition voltage and the burning voltage has to be high, e.g. in switching tubes. Tubes for indication and stabilization, where the difference has to be lower, tend to be filled with Penning mixtures; the lower difference between ignition and burning voltages allows using lower power supply voltages and smaller series resistances.\n\nFluorescent lighting, CFL lamps, mercury and sodium discharge lamps and HID lamps are all gas-filled tubes used for lighting.\n\nNeon lamps and neon signage (most of which is not neon based these days) are also low-pressure gas-filled tubes.\n\nSpecialized historic low-pressure gas-filled tube devices include the Nixie tube (used to display numerals) and the Decatron (used to count or divide pulses, with display as a secondary function).\n\nXenon flash lamps are gas-filled tubes used in cameras and strobe lights to produce bright flashes of light.\n\nThe recently developed sulfur lamps are also gas-filled tubes when hot.\n\nSince the ignition voltage depends on the ion concentration which may drop to zero after a long period of inactivity, many tubes are primed for ion availability:\n\nSome important examples include the thyratron, krytron, and ignitron tubes, which are used to switch high-voltage currents. A specialized type of gas-filled tube called a Gas Discharge Tube (GDT) is fabricated for use as surge protectors, to limit voltage surges in electrical and electronic circuits.\n\nThe Schmitt trigger effect of the negative differential resistance-region can be exploited to realize timers, relaxation oscillators and digital circuits with neon lamps, \"trigger tubes\", \"relay tubes\", dekatrons and nixie tubes.\n\nThyratrons can also be used as triodes by operating them below their ignition voltage, allowing them to amplify analog signals as a self-quenching superregenerative detector in radio control receivers.\n\nThere were special neon lamps besides nixie tubes:\n\nHot-cathode, gas-discharge noise diodes were available in normal radio tube glass envelopes for frequencies up to UHF, and as long, thin glass tubes with a normal bayonet light bulb mount for the filament and an anode top cap, for SHF frequencies and diagonal insertion into a waveguide.\n\nThey were filled with a pure inert gas such as neon because mixtures made the output temperature-dependent. Their burning voltage was under 200 V, but they needed optical priming by an incandescent 2-watt lamp and a voltage surge in the 5-kV range for ignition.\n\nOne miniature thyratron found an additional use as a noise source, when operated as a diode in a transverse magnetic field.\n\nIn the mid-20th century, voltage-regulator tubes were commonly used.\n\nCathode sputtering is taken advantage of in the \"Time Totalizer\", a metal-vapor coulometer-based elapsed time meter where the sputtered metal is deposited on a collector element whose resistance therefore decreases slowly.\n\n\n\n"}
{"id": "6198995", "url": "https://en.wikipedia.org/wiki?curid=6198995", "title": "Geosteering", "text": "Geosteering\n\nGeosteering is the optimal placement of a wellbore based on the results of realtime downhole geological and geophysical logging measurements rather than three-dimensional targets in space. The objective is usually to keep a directional wellbore within a hydrocarbon pay zone defined in terms of its resistivity, density or even biostratigraphy. In mature areas, geosteering may be used to keep a wellbore in a particular section of a reservoir to minimize gas or water breakthrough and maximize economic production from the well. In the process of drilling a borehole, geosteering is the act of adjusting the borehole position (inclination and azimuth angles) \"on the fly\" to reach one or more geological targets. These changes are based on geological information gathered while drilling.\nOriginally only a projected target would be aimed for with crude directional tools. Now the advent of rotary steerable tools and an ever increasing arsenal of geophysical tools enables well placement with ever increasing accuracy. Typically a basic tool configuration with have directional and inclination sensors, along with a gamma ray tool. Other options are neutron density, look ahead seismic, downhole pressure readings et al. Due to the vast volume of data generated, especially by imaging tools, the data transmitted to surface is a carefully selected fraction of what is available. Data is collected in memory for a data dump when back on surface with the tool. \n\nGeosteering only practically became possible with the advent of deep reading 2 MHz resistivity LWD tools from the major LWD vendors (BakerHughes Reservoir Navigation Tool, SperrySun and Schlumberger) and other tools in the early 90's, and the forward modeling software from a number of vendors capable of predicting resistivity tool responses for different relative angles and formation resistivities. Prior to this, Gamma ray gave some bed information, but was rarely used to dynamically adjust the well path in relation to the best oil saturation and porosity. The advent of nuclear tools for porosity and azimuthally sensitive gamma and resistivity tools, improved the ability to infer whether the wellbore should be steered up or down. The development of the Troll Oilfield by Norsk Hydro (Later Statoil and Equinor) would not have been possible without the ability to precisely geosteer within a 4 meter thick horizon to avoid gas above and water below.\n\nFrom 2D and 3D models of underground substructures, deviated wells (2D and 3D) are planned in advance to achieve specific goals: exploration, fluids production, fluids injection or technical.\n\nA \"well plan\" is a continuous succession of straight and curved lines representing the geometrical figure of the expected well path. A well plan is always projected on vertical and horizontal maps.\n\nWhile the borehole is being drilled according to the well plan, new geological information is gathered from mud logging, measurement while drilling (MWD) and logging while drilling (LWD). These usually show some differences from what is expected from the model. As the model is continuously updated with the new geological information (formation evaluation) and the borehole position (\"well deviation survey\"), changes start to appear in the geological substructures and can lead to the well plan being updated to reach the corrected geological targets.\n\nThe following data can be used for the geosteering: MWD, LWD, Image logs, 2D and 3D seismic data, geological models.\n"}
{"id": "40100871", "url": "https://en.wikipedia.org/wiki?curid=40100871", "title": "GreenRight Certified", "text": "GreenRight Certified\n\nGreenRight Certified (GreenRighting) is a certification program rewarding commercial and industrial green buildings that meet a defined set of energy efficiency standards relating to lighting equipment, lighting systems, lighting power density (LPD), and associated building code compliance.\n\nDeveloped by CandleRay, the GreenRight Certification is intended to provide business and facility owners with a simple framework for implementing energy conservation through highly efficient, innovative, and more practical lighting systems. This platform is intended to ultimately streamline the adoption of more energy efficient technology, while also helping businesses improve cash flow over time.\n\nA before and after audit process determines the lighting power density (LPD) and the decrease in total facility electric load as it applies to the lighting system. The audit provides various improvements designed to qualify the facility for GreenRight Certification.\n\n\nPrerequisites\n\n---AND---\n---OR---\n\nSystem Core Requirements\n\n[A] the whole building method or [B] space-by-space method.\n\na. Bi-level or multi-level switching\nb. Individual space controls (as recommended by ASHRAE/IESNA)\nc. Automatic shut-off requirements (as recommended by ASHRAE/IESNA)\n\nOutside Fulfillment\n\n\n\nNotes\n"}
{"id": "2896399", "url": "https://en.wikipedia.org/wiki?curid=2896399", "title": "Harmonic balance", "text": "Harmonic balance\n\nHarmonic balance is a method used to calculate the steady-state response of nonlinear differential equations\n, and is mostly applied to nonlinear electrical circuits\nIt is a \"frequency domain\" method for calculating the steady state, as opposed to the various \"time-domain\" steady state methods. The name \"harmonic balance\" is descriptive of the method, which starts with Kirchhoff's Current Law written in the frequency domain and a chosen number of harmonics. A sinusoidal signal applied to a nonlinear component in a system will generate harmonics of the fundamental frequency. Effectively the method assumes the solution can be represented by a linear combination of sinusoids, then balances current and voltage sinusoids to satisfy Kirchhoff's law. The method is commonly used to simulate circuits which include nonlinear elements, and is most applicable to systems with feedback in which limit cycles occur.\n\nMicrowave circuits were the original application for harmonic balance methods in electrical engineering. Microwave circuits were well-suited because, historically, microwave circuits consist of many linear components which can be directly represented in the frequency domain, plus a few nonlinear components. System sizes were typically small. For more general circuits, the method was considered impractical for all but these very small circuits until the mid-1990s, when Krylov subspace methods were applied to the problem. \nThe application of preconditioned Krylov subspace methods allowed much larger systems to be solved, both in size of circuit and in numbers of harmonics. This made practical the present-day use of harmonic balance methods to analyze radio-frequency integrated circuits (RFICs).\n\nThe harmonic balance algorithm is a special version of Galerkin's method. It is used for the calculation of periodic solutions of autonomous and non-autonomous differential-algebraic systems of equations. The treatment of non-autonomous systems is slightly simpler than the treatment of autonomous ones. A non-autonomous DAE system has the representation\nwith a sufficiently smooth function formula_2\nwhere formula_3 is the number of equations and formula_4 are placeholders for time, the vector of unknowns and the vector of time-derivatives.\n\nThe system is non-autonomous if the function formula_5 is not constant for (some) fixed formula_6 and formula_7. Nevertheless, we require that there is a known \"excitation period\" formula_8 such that formula_5 is formula_10-periodic.\n\nA natural candidate set for the formula_10-periodic solutions of the system equations is the Sobolev space formula_12 of weakly differentiable functions on the interval formula_13 with periodic boundary conditions formula_14.\nWe assume that the smoothness and the structure of formula_15 ensures that formula_16 is square-integrable for all formula_17.\n\nThe system formula_18 of harmonic functions formula_19 is a Schauder basis of formula_12 and forms a :Hilbert basis of the Hilbert space formula_21 of square-integrable functions. Therefore, each solution candidate formula_17 can be represented by a Fourier-series formula_23 with Fourier-coefficients formula_24 and the system equation is satisfied in the weak sense if for every base function formula_25 the variational equation\nis fulfilled. This variational equation represents an infinite sequence of scalar equations since it has to be tested for the infinite number of base functions formula_27 in formula_28.\n\nThe Galerkin approach to the harmonic balance is to project the candidat set as well as the test space for the variational equation to the finitely dimensional sub-space spanned by the finite base formula_29.\n\nThis gives the finite-dimensional solution ansatz formula_30 and the finite set of equations\nwhich can be solved numerically.\n\nIn the special context of electronics the algorithm starts with Kirchhoff's current law written in the frequency-domain. To increase the efficiency of the procedure, the circuit may be partitioned into its linear and nonlinear parts, since the linear part is readily described and calculated using nodal analysis directly in the frequency domain.\n\nFirst, an initial guess is made for the solution, then an iterative process continues:\n\n\nConvergence is reached when formula_39 is acceptably small, at which point all voltages and currents of the steady-state solution are known, most often represented as Fourier coefficients.\n\nA harmonic-balance tool, named \nAgile,\nfor microwave circuits is available for download.\nA parallelized version\n\nwas also developed, but this version is not available.\nSandia national labs developed Xyce, a high performance parallel electronic simulator, that can perform harmonic balance analysis.\n"}
{"id": "24999087", "url": "https://en.wikipedia.org/wiki?curid=24999087", "title": "Heat stroke", "text": "Heat stroke\n\nHeat stroke, also known as sun stroke, is a type of severe heat illness that results in a body temperature greater than and confusion. Other symptoms include red, dry or damp skin, headache, and dizziness. Onset can be sudden or gradual. Complications may include seizures, rhabdomyolysis, or kidney failure.\nHeat stroke occurs because of high external temperatures or physical exertion. Risk factors include heat waves, high humidity, certain drugs such as diuretics, beta blockers, or alcohol, heart disease, and skin disorders. Cases not associated with physical exertion typically occur in those at the extremes of age or with long term health problems. Diagnosis is based on symptoms. It is a type of hyperthermia. It is distinct from a fever, where there is a physiological increase in the temperature set point.\nPreventive measures include drinking sufficient fluids and avoiding excessive heat. Treatment is by rapid physical cooling of the body and supportive care. Recommended methods include spraying the person with water and using a fan, putting the person in ice water, or giving cold intravenous fluids. While it is reasonable to add ice packs around a person, this by itself is not routinely recommended.\nIt results in more than 600 deaths a year in the United States. Rates have increased between 1995 and 2015. The risk of death is less than 5% in those with exercise-induced heat stroke and as high as 65% in those with non-exercise induced cases.\nHeat stroke generally presents with a hyperthermia of greater than in combination with disorientation and a lack of sweating. Before a heat stroke occurs, people show signs of heat exhaustion such as dizziness, mental confusion, headaches, and weakness; if a heat stroke occurs when the person is asleep, symptoms may be harder to notice. However, in exertional heat stroke, the affected person may sweat excessively. Young children, in particular, may have seizures. Eventually, unconsciousness, organ failure, and death will result.\n\nHeat stroke occurs when thermoregulation is overwhelmed by a combination of excessive metabolic production of heat (exertion), excessive environmental heat, and insufficient or impaired heat loss, resulting in an abnormally high body temperature. Substances that inhibit cooling and cause dehydration such as alcohol, stimulants, medications, and age-related physiological changes predispose to so-called \"classic\" or non-exertional heat stroke (NEHS), most often in elderly and infirm individuals in summer situations with insufficient ventilation. Exertional heat stroke (EHS) can happen in young people without health problems or medications most often in athletes, outdoor laborers, or military personnel engaged in strenuous hot-weather activity or in certified first responders wearing heavy personal protective equipment. In environments that are not only hot but also humid, it is important to recognize that humidity reduces the degree to which the body can cool itself by perspiration and evaporation. For humans and other warm-blooded animals, excessive body temperature can disrupt enzymes regulating biochemical reactions that are essential for cellular respiration and the functioning of major organs.\n\nWhen the outside temperature is , the temperature inside a car parked in direct sunlight can quickly exceed . Young children or elderly adults left alone in a vehicle are at particular risk of succumbing to heat stroke. \"Heat stroke in children and in the elderly can occur within minutes, even if a car window is opened slightly.\" As these groups of individuals may not be able to open car doors or to express discomfort verbally (or audibly, inside a closed car), their plight may not be immediately noticed by others in the vicinity.\n\nDogs are even more susceptible than humans to heat stroke in cars, as dogs cannot produce whole-body sweat to cool themselves. Leaving the dog at home with plenty of water on hot days is recommended instead, or, if a dog must be brought along, it can be tied up outside the destination and provided with a full water bowl.\n\nThe risk of heat stroke can be reduced by observing precautions to avoid overheating and dehydration. Light, loose-fitting clothes will allow perspiration to evaporate and cool the body. Wide-brimmed hats in light colors help prevent the sun from warming the head and neck. Vents on a hat will help cool the head, as will sweatbands wetted with cool water. Strenuous exercise should be avoided during hot weather, especially in the sun peak hours. Also do not remaining in confined spaces (such as automobiles) without air-conditioning or adequate ventilation.\n\nIn hot weather, people need to drink plenty of cool liquids and mineral salts to replace fluids lost from sweating. Thirst is not a reliable sign that a person needs fluids. A better indicator is the color of urine. A dark yellow color may indicate dehydration.\n\nThe Occupational Safety and Health Administration in the United States publishes a QuickCard with a checklist designed to help protect from heat stress:\n\n\nTreatment of heat stroke involves rapid mechanical cooling along with standard resuscitation measures.\n\nThe body temperature must be lowered quickly. The person should be moved to a cool area (indoors, or at least in the shade) and clothing removed to promote heat loss (passive cooling). Active cooling methods should also be used, if possible: The person is bathed in cold water, or a hyperthermia vest can be applied. (However, wrapping the person in wet towels or clothes can actually act as insulation and increase the body temperature.) Cold compresses to the torso, head, neck, and groin will help cool the victim. A fan or dehumidifying air-conditioning unit may be used to aid in evaporation of the water (evaporative method).\n\nImmersing a person into a tub of cold water (immersion method) is a widely recognized method of cooling. This method may require the effort of several people and the person should be monitored carefully during the treatment process. Immersion should be avoided for an unconscious person, but if there is no alternative, the person's head must be held above water.\n\nImmersion in very cold water was once thought to be counterproductive by reducing blood flow to the skin and thereby preventing heat from escaping the body core. However, this hypothesis has been challenged in experimental studies, as well as by systematic reviews of the clinical data, indicating that cutaneous vasoconstriction and shivering thermogenesis do not play a dominant role in the decrease in core body temperature brought on by cold water immersion. This can be seen in the effect of submersion hypothermia, where the body temperature decrease is directly related to environmental temperature, and though bodily defenses slow the decrease in temperature for a time, they ultimately fail to maintain endothermic homeostasis. Dantrolene, a direct-acting paralytic which abolishes shuddering and is effective in many other forms of hyperthermia, including centrally-, peripherally- and cellularly-mediated thermogenesis, has no individual or additive effects to cooling in the context of heat stroke, showing a lack of endogenous thermogenic response to cold water immersion. Thus, aggressive ice-water immersion remains the gold standard for life-threatening heat stroke.\n\nHydration is important in cooling the person. In mild cases of concomitant dehydration, this can be achieved by drinking water, or commercial isotonic sports drinks may be used as a substitute. In exercise- or heat-induced dehydration, electrolyte imbalance can result, and can be worsened by excess consumption of water. Hyponatremia can be corrected by intake of hypertonic fluids. Absorption is rapid and complete in most people but if the person is confused, unconscious, or unable to tolerate oral fluid, then an intravenous drip may be necessary for rehydration and electrolyte replacement.\n\nThe person's condition should be reassessed and stabilized by trained medical personnel. The person's heart rate and breathing should be monitored, and CPR may be necessary if the person goes into cardiac arrest.\n\nIt was long believed that heat strokes lead only rarely to permanent deficits and that convalescence is almost complete. However, following the 1995 Chicago heat wave, researchers from the University of Chicago Medical Center studied all 58 patients with heat stroke severe enough to require intensive care at 12 area hospitals between July 12 and 20, 1995, ranging in age from 25 to 95 years. Nearly half of these patients died within a year 21 percent before and 28 percent after release from the hospital. Many of the survivors had permanent loss of independent function; one-third had severe functional impairment at discharge, and none of them had improved after one year. The study also recognized that because of overcrowded conditions in all the participating hospitals during the crisis, the immediate care which is critical was not as comprehensive as it should have been.\n\nIn India, hundreds die every year from summer heat waves, including more than 2,500 in the year 2015. Later that same summer, the 2015 Pakistani heat wave caused about 2,000 deaths.\n\nHeatstroke can affect livestock, especially in hot, humid weather; or if the horse, cow, sheep or other is unfit, overweight, has a dense coat, is overworked, or is left in a horsebox in full sun. Symptoms include drooling, panting, high temperature, sweating, and rapid pulse.\n\nThe animal should be moved to shade, drenched in cold water and offered water or electrolyte to drink.\n\n"}
{"id": "3607623", "url": "https://en.wikipedia.org/wiki?curid=3607623", "title": "I-Opener", "text": "I-Opener\n\nThe i-Opener was a low-cost internet appliance produced by Netpliance (now known as TippingPoint) between the years 1999 and 2002. The hardware, cheaply available, became popular among collectors who modified the appliance to run as a normal PC. This made the device capable of running PC operating systems, such as Linux and Microsoft Windows.\n\nThe original retail price was $99. The actual cost of the device was roughly estimated between $300 and $400. The devices were sold as a loss leader for monthly Internet service. However, as soon as a hacking method became available on the Internet (in 2000), many customers canceled the monthly service, which eventually made the business model unsustainable. Similar business models and failures were also seen with the 3Com Audrey and Virgin Webplayer.\n\nJames Kmetz, a hacker from Indiana, discovered that the i-Opener was simply an x86 compatible PC inside a custom enclosure. When he removed the back cover of the device, he found a Socket 7 CPU socket with a 180 MHz IDT WinChip C6 CPU, a SO-DIMM socket, an IDE plug (which allowed adding a hard drive and CD-ROM, making the device nothing less than a $99 PC with an LCD screen), and a 16 MB SanDisk memory chip. However, the pins on the IDE connector were reversed, requiring the making or ordering of special cables and adapters to connect a hard drive to the unit. Attempts by Netpliance to thwart hacking included gluing the BIOS chip into its socket with epoxy and modifying its settings (rendering it unable to detect hard drives), limiting the type of CPU one could use to that included with the unit, and even cutting the pins on the IDE connector.\n"}
{"id": "52019044", "url": "https://en.wikipedia.org/wiki?curid=52019044", "title": "Intelligence Node", "text": "Intelligence Node\n\nIntelligence Node is a global technology company that specializes in the development of analytical products and services using a SaaS-based delivery model focused on price optimization. The company generates analytics from Big Data pertaining to the retail industry. Intelligence Node was constituted in 2012 as a consulting firm and since then has evolved into the retail space as the provider of an analytics platform.\n\nIntelligence Node was incepted in 2012 as a consulting company that focused on providing expert consulting to the retailers in the e-commerce apparel domain. The company was co-founded by Sanjeev Sularia, CEO of Intelligence Node and Yasen Dimitrov, COO of Intelligence Node. Sularia previously worked as the CFO for Exclusively.in (an e-commerce portal for upscale fashion), now acquired by Snapdeal, and CFO for Shersingh.com (a private label e-commerce fast fashion portal), now under Myntra. While Yasen was the Practice Leader at the Boston Consulting Group (BCG) in their London office. Prior to this, he was the Head of Research and Analytics in a boutique financial research lab in London. Intelligence Node began its operations with seven members at Mumbai, India. The company currently has offices in London, New York City, and Dubai along with Mumbai.\n\nThe enterprise expanded its consulting business into retail analytics that provides real-time information to the retailers by enabling them to gain access to pools of data generated globally, and also resources to synthesize them. Retailers can use the products as trading platforms where they can implement a dynamic pricing model based on accurate and reliable insights. \nThe technology engaged by the company encompasses a SaaS-based platform that scans the internet for the pricing strategies and cataloging models of over 1 billion products of more than 130,000 brands sold in around 1,100 categories.\n\nIn 2015, Intelligence Node raised $4 million in Series A funding from New Enterprise Associates and Orios Venture Partners and now plans to expand its operations in the US and Europe.\n\nCurrently, the company offers two products- Incompetitor which is a SaaS based offering that helps in competitor price assortment and benchmarking, and Inoptimizer, a rules-based optimization engine, which enables price optimization. The products make it possible for the retailers to offer everyday low pricing instead of specific period discounts.The analytics take into consideration the pricing variances based on the geographical locations of the customers allowing merchants to streamline the pricing.\n\nIntelligence Node seeks to fill the gap in the retail industry through its Big Data Analytics by enabling retailers to get details of what their competitors are offering. Intelligence Node’s solutions also analyze the product turnover rate of the global fashion industry. Both the products are offered a subscription-based licensing service to the users.\n\nAs a part of its global expansion strategy, Intelligence Node has integrated multilingual support into its applications. Currently, the platforms support 29 major languages, which represent around 95% of the total global GDP. It will enable the company to serve a global clientele and make its processes internationally scalable.\nIn 2016, Indonesian lifestyle retail giant Mitra Adiperska (MAP) entered into a contract with Intelligence Node for its analytical services. MAP operates across a range of retail products including apparel, food and sports equipment, and is the Indonesian master franchise partner for prominent brands that include Zara, Starbucks, New Balance and M&S. Another major organization that has partnered with Intelligence Node is Bfashion, a Bulgarian fashion retailer.\n\nIn Feb 2017, Intelligence Node announced the recent acquisition of three new global customers. The new wins include the UK's MADE.com, Brazil's Mobly, and India's Tata CLiQ.\n\nThe further business expansion strategy of Intelligence Nodes entails offering analytical services to offline businesses apart from its existing portfolio of online retailers.\n\nIntelligence Node® currently serves a suite of retail intelligence products Insuite™ – Incompetitor® , Inoptimizer®, Hook Fashion Discovery, and Infeed™. Incompetitor® and Inoptimizer® work on a Software-as-a-Service(SaaS) model and offer a subscription-based licensing service to the clients, while Infeed™ is a host of APIs providing systematic feed of market database. They have recently launched[15] their fashion discovery app called Hook, the first AI-generated fashion feed for consumers. Hook Fashion Discovery is free and available at the App Store and on Google Play.\nIncompetitor® provides a dashboard with multiple modules platform that uses data enriched with AI-based machine-learning to give customers real-time competitive sights, price optimization, and automatic catalog benchmarking for any number of pre-determined competitor websites. The comparative benchmarking includes in-house brands as well as private labels.\n\nInoptimizer® is a rules-based pricing engine that eliminates the need for the retailers to manually moderate pricing for their products to stay competitive, especially on multi-seller websites like Amazon, and instead offers dynamic pricing solution based on the industry and market trends. The prices can increase or decrease in real-time depending on the competition's pricing and catalog movement, providing a complete price optimization for tens of thousands of unique SKUs. It also enables smart inventory management using sales modeling and a recommendation engine to upsell and cross-sell.\n\nThe products of Intelligence Node are designed to tap into the potential of Big Data analytics. Big Data analytics has emerged in the recent years as the key driver of growth of businesses by offering invaluable insights into the dynamics of the markets and industries. It enables organizations to synthesize the vast amount of data which is generated around the globe by organizing it into comprehensible patterns, trends, and other useful knowledge. It allows enterprises to make decisions based on the reliable analytical information. The process of using Big Data Analytics has enabled companies to witness a paradigm shift in the way they operate and formulate, and implement their strategies. Managers are aptly supported by the knowledge they derive using analytics and market intelligence. One of the core functions of Big Data\n\nAnalytics is incorporating a dynamic pricing strategy leading to a more transparent and efficient system. Pricing intelligence helps enterprises to determine the right pricing structures based on the analysis of what their competitors offer. The pricing intelligence enables companies to leverage dynamic pricing to increase their profitability by avoiding over-charging as well as undercharging.\n"}
{"id": "41278", "url": "https://en.wikipedia.org/wiki?curid=41278", "title": "Interference filter", "text": "Interference filter\n\nAn interference filter or dichroic filter is an optical filter that reflects one or more spectral bands or lines and transmits others, while maintaining a nearly zero coefficient of absorption for all wavelengths of interest. An interference filter may be high-pass, low-pass, bandpass, or band-rejection.\n\nAn interference filter consists of multiple thin layers of dielectric material having different refractive indices. There also may be metallic layers. In its broadest meaning, interference filters comprise also etalons that could be implemented as tunable interference filters. Interference filters are wavelength-selective by virtue of the interference effects that take place between the incident and reflected waves at the thin-film boundaries. The important characteristic of the filter is the form of the leaving signal. It is considered that the best form is a rectangle.\n\nBandpass filters are normally designed for normal incidence. However, when the angle of incidence of the incoming light is increased from zero, the central wavelength of the filter decreases, resulting in partial tunability. The transmission band widens and the maximum transmission decreases. If λ is the central wavelength, λ is the central wavelength at normal incidence, and \"n\" is the filter effective index of refraction, then:\n\nFor example, for λ=1550 nm, \"n\"=1.5, Δλ = λ−λ=32 nm, the rotation angle is\nθ = 17.7°. This corresponds to C-band or L-band in 1550 nm fiber-optic communications window. Equipped with a stepper motor and electronics, a tunable optical filter that tunes center transmission wavelength over C-band or L-band by remote control can be achieved. See diagram below for its working principle and tunable optical filter devices.\n\n"}
{"id": "1444182", "url": "https://en.wikipedia.org/wiki?curid=1444182", "title": "Internationalized Resource Identifier", "text": "Internationalized Resource Identifier\n\nThe Internationalized Resource Identifier (IRI) – is an internet protocol standard which extends the ASCII characters subset of the Uniform Resource Identifier (URI) protocol. It was defined by the Internet Engineering Task Force (IETF) in 2005 as a new internet standard to extend the existing URI scheme. The primary standard is defined by the RFC 3987. While URIs are limited to a subset of the ASCII character set, IRIs may contain characters from the Universal Character Set (Unicode/ISO 10646), including Chinese or Japanese kanji, Korean, Cyrillic characters, and so forth.\n\nIRIs extend URIs by using the Universal Character Set, where URIs were limited to ASCII, with far fewer characters. IRIs may be represented by a sequence of octets but by definition are defined as a sequence of characters, because IRIs may be spoken or written by hand.\n\nIRIs are mapped to URIs to retain backwards-compatibility with systems that do not support the new format.\n\nFor applications and protocols that do not allow direct consumption of IRIs, the IRI should first be converted to Unicode using canonical composition normalization (NFC), if not already in Unicode format.\n\nAll non-ASCII code points in the IRI should next be encoded as UTF-8, and the resulting bytes percent-encoded, to produce a valid URI.\n\nExample: The IRI https://en.wiktionary.org/wiki/Ῥόδος becomes the URI https://en.wiktionary.org/wiki/%E1%BF%AC%CF%8C%CE%B4%CE%BF%CF%82\n\nASCII code points that are invalid URI characters \"may\" be encoded the same way, depending on implementation.\n\nThis conversion is easily reversible; by definition, converting an IRI to an URI and back again will yield an IRI that is semantically equivalent to the original IRI, even though it may differ in exact representation.\n\nSome protocols may impose further transformations; e.g. Punycode for DNS labels.\n\nThere are reasons to see URIs displayed in different languages; mostly, it makes it easier for users who are unfamiliar with the Latin (A-Z) alphabet. Assuming that it isn't too difficult for anyone to replicate arbitrary Unicode on their keyboards, this can make the URI system more accessible.\n\nMixing IRIs and ASCII URIs can make it much easier to execute phishing attacks that trick someone into believing they are on a different site that they really are. For example, one can replace an ASCII \"a\" in codice_1 with the Unicode look-alike \"α\", and point that IRI to a malicious site. This is known as an IDN homograph attack.\n\nWhile a URI does not provide people with a way to specify Web resources using their own alphabets, an IRI does not make clear how Web resources can be accessed with keyboards that are not capable of generating the requisite internationalized characters. This does mean that IRIs are now handled in a way very similar to many other software which might require the use of a non-keyboard input method when dealing with texts in various languages.\n\n\n"}
{"id": "51987980", "url": "https://en.wikipedia.org/wiki?curid=51987980", "title": "Junction (hackathon)", "text": "Junction (hackathon)\n\nJunction is a 48-hour international hackathon organized annually in Helsinki, Finland. The event brings together developers, designers, and entrepreneurs from around the world and helps them build solutions to real world challenges from local and multinational companies.\n\nJunction is a part of Major League Hacking and is also the largest hacking event in Europe.\n\nJunction was first launched in 2015. The event was held on November 6-8th in Kattilahalli, Suvilahti, Helsinki and gathered more than 550 participants and resulted in 145 different projects. Notable partners included Uber, Finnair, Supercell, Reaktor, and others. The winner Junction 2015 was Slush Smackdown, from the Supercell Unlimited track. It also won the whole Slush Hacks -hackathon competition main prize, worth 20 000 EUR.\n\nJunction 2016 was held on November 25-27th at Wanha Satama, in Katajanokka, Helsinki, Finland. About 1300 participants from over 77 nationalities attended the hackathon. Partners included Supercell, Zalando, the European Space Agency, General Electric, Sitra, Tieto, UPM and others.\n\nTeams had 48 hours to develop their ideas and pitch their ideas to other attendants and judges. The main prize for the winning idea of the 2016 event was 20 000 EUR, and many companies offered their own bounties for solving challenges in a specific way or using pre-specified technology. Teams were provided a number of different API's and other emerging technologies to develop their concepts including Oculus Rifts, HTC Vives, Apple Watches, 3D-printers, Microsoft Hololens, and Estimote Beacons among others.\n\nThe winner team was suju.online, who created a tool for event organizers and public transportation decision makers that allows them to design dynamic routing for the self-driving bus. The team originated from the local Aalto University and the hack was part of the Future of Mobility-track.\n\nJunction is a volunteer-based, non-profit organization composed mainly of students from different Finnish universities. It is owned by the non-profit foundation Startup Säätiö, but gathers all of its funding from the partnership contracts between its partner companies.\n\n\n \n"}
{"id": "4258931", "url": "https://en.wikipedia.org/wiki?curid=4258931", "title": "Liquid Elastomer Molding", "text": "Liquid Elastomer Molding\n\nThe Liquid Elastomer Molding (LEM) gasket consists of a metallic core, coated in selected areas on both sides with a thin layer of silicone with molded-in sealing beads. These beads have differing heights and widths dependent on the clamping load distribution and application requirements. The base elastomer coating provides a good overall micro-seal with the silicone beads ensuring optimum sealing in the critical areas. LEM can also include molding on its edge either for sealing of high pressure fluids or for T joints between mating flanges.\n"}
{"id": "18612939", "url": "https://en.wikipedia.org/wiki?curid=18612939", "title": "List of Linux kernel names", "text": "List of Linux kernel names\n\nMost of the Linux 1.2 and above kernels include a name in the Makefile of their source trees, which can be found in the git repository.\n"}
{"id": "59045990", "url": "https://en.wikipedia.org/wiki?curid=59045990", "title": "MK-1TS", "text": "MK-1TS\n\nMK-1TS Micron () is a Ukrainian small-sized spacecraft, artificial satellite of Earth manufactured by Yuzhmash. MK-1TS was launched on December 24, 2004, at 13:20 from the Plesetsk cosmodrome (Russia) using the Cyclone-3 launch vehicle together with Sich-1M satellite. Both satellites placed into incorrect orbits due to premature third stage cutoff. \n\nThe satellite was active until September 30, 2005. \n\nMK-1TS has a small on-board camera (MBTC-VD), which provides digital optical-electronic images of Earth in the panchromatic range. In addition, one of the tasks of the microsatellite was to work out a new system of its orientation on the base of a magnetometer and electromagnets without using other auxiliary devices.\n\n"}
{"id": "18276148", "url": "https://en.wikipedia.org/wiki?curid=18276148", "title": "Mammals and Birds Excluder Device", "text": "Mammals and Birds Excluder Device\n\nA Mammals and Birds Excluder Device or MBED (also named Cachalotera) is a fishing gear device that avoids the depredation of the fish caught in the line for Marine Mammals, and avoids the entanglement of seabirds when is setting the line and hauling. This device was designed mainly for the interactions with toothed whales: Sperm Whales and Killer Whales. \n\nThe Mammals and Birds Excluder Device (MBED) consists in a modification to the traditional Spanish bottom longline used in the fishery of Patagonian toothfish (\"Dissostichus eleginoides\"). Several configurations are in use depending on the country, and fishermen. The first descriptions were issued in Chile and Uruguay, starting the tests in 2006. \n\nThe main bottom longline is set in a simple way with a main line rigging from which many secondary or branch lines are hanging, of about 12 to 15 m long. On each of these lines, a cone-shaped device or protection net is placed in each secondary line, made by two metallic rings on the edge covered by a mesh net: the upper ring of 20 cm of diameter consisting in encased wire ending in retention rigging; and a lower ring of 100 cm diameter, with a separation distance between both rings of 180 cm. The mesh net composing the device is 7.5 cm, and on the upper ring, it ends in a knot allowing movement through the branch lines. Such branch lines are separated from 55 m to 70 m between them, and may be set in variable styles according to the hauling speed. One set contains 6 hooks, and such sets are prepared on the basis of 4 per box. This device as a whole has less density than the end weights (5 to 10 kg) and consequently, it rises up to the retention when hauling, and the hooks are uncovered when it reaches the bottom. When the longline is hauled back, the cone-shaped device is moved to the lower part of the branch lines, covering the hooks and consequently protecting the catch. The hooks are rigged in a piece divided into two bunches of 6 hooks each, being the main piece of 170 cm long and a diameter of 6 mm, and the two bunches are separated at 50 cm one from the other, the secondary lines (12 per piece) are 30 cm long and made of 4 mm diameter multifilament lines.\n\nFirst tests were carried out in 2006 in Chile and Uruguay in the longline fisherie of Toothfish (\"D. eleginoides\") in the case of Uruguay the main assessment were carried out in the FV Banzare operating in two different fishing areas at 40° and 50° latitudes in the Southwestern Atlantic from March to May 2007. The development of this fishing gear was monitored by Fisheries observers on board in all the cases\n\nIn all the cases, the incidental capture of birds registered was absolute: no bird was captured when the MBED was used on the fishing gear, no marine bird mortalities were due to gear captures during this study. \nThe MBED works in two aspects: \n\n\n\n"}
{"id": "41363", "url": "https://en.wikipedia.org/wiki?curid=41363", "title": "Mean time between outages", "text": "Mean time between outages\n\nIn a system the mean time between outages (MTBO) is the mean time between equipment failures that result in loss of system continuity or unacceptable degradation. \n\nThe MTBO is calculated by the equation,\n\nformula_1\n\nwhere MTBF is the nonredundant mean time between failures and FFAS is the fraction of failures for which the failed equipment is automatically bypassed. \n"}
{"id": "27866367", "url": "https://en.wikipedia.org/wiki?curid=27866367", "title": "Medical bag", "text": "Medical bag\n\nA medical bag (doctor's bag, physician's bag) is a portable bag used by a physician or other medical professional to transport medical supplies and medicine.\n\nTraditionally, the medical bag was made of leather, opened on the top with a split-handle design. During the American Civil War, physician's medical saddle bags were used. Modern medical bags are made of various materials and come in various designs that can include many pockets, pouches, and zippered or hook-and-loop openings.\n\nIndigenous North American medicine men and shamans use a medicine bag. A battle bag is used in the military.\n\nThe original Wonder Woman comic book character carried a medical bag (as a Lt. Nurse) in which she carried her costume and accessories.\n\nIn 1955, the MV Joyita charter boat was found partially submerged after being missing for 5 weeks. Among the items found onboard was a doctor's bag containing a stethoscope, a scalpel, and four lengths of blood-stained bandages.\n\nIn the television sitcom \"The Beverly Hillbillies\" (1962–1971), Granny Clampett is a backwoods doctor who has a medical bag.\n\nDoctor Ross (Charles Isaiah Ross, 1925–1993) was an American blues musician nicknamed \"Doctor\" because of his habit of carrying his harmonicas in a black bag that resembled a doctor's bag.\n\n\"The Little Black Bag\" is a short story by American science fiction author Cyril M. Kornbluth, first published in July 1950, about a disgraced doctor who comes across a medical bag from over a century in the future. It is the basis for a segment by the same name of Rod Serling’s \"Night Gallery\" which aired December 23, 1970.\n\nIn 1956, Lynn Pressman Raymond (of the Pressman Toy Corporation) created the \"Doctor Bag\" toy to help children feel more comfortable with visits to the doctor. Seeing the anxiety of her children on visits to the doctor due to ill health or for vaccinations, she created the Doctor Bag—which included a stethoscope, syringe, and other pretend medical supplies—to help kids deal with their fears.\n\nIn the 1984 film \"Crimes of Passion\", the \"Reverend\" Peter Shayne (played by Anthony Perkins) carries a doctor's bag full of sex toys.\n\nThe main character of 1990s television series \"Northern Exposure\", Dr. Joel Fleishman, carries a medical bag when making housecalls.\n\nBooks about doctor's bags include \"What's in a Doctor's Bag?\" by Neil B. Shulman and Sibley Fleming, and \"My Doctor's Bag\" (2002, ) by Anne Millard.\n\nSome video games, such as the \"Battlefield\" series (2002–present) and \"\" (2010), use medical bags to increase the player's health.\n\nThe ITV British police drama \"Heartbeat\" 2006 episode \"Dead Men Do Tell Tales\" is about a nurse, Carol Cassidy (played by Lisa Kay), who rushes off to treat an emergency, but absent-mindedly leaves her medical bag in her car which contains dangerous drugs; Carol has to fight for her career when local boys steal the bag.\n\nThroughout the series House M.D., each time that Dr. House had his fellows break-into a patient's home to check for environmental toxins they each brought a medical bag with them containing (in addition to medical testing supplies), breaking and entering equipment. \n\nIn 2011, the New York Times reported that the Susan B. Anthony House museum had sold a large quantity of \"a $250 handbag made of fake alligator that was inspired by one of Anthony’s own club bags, similar to a doctor’s bag,\" noting that for Anthony, \"a bag was not a fashion statement but a symbol of independence at a time when women were not allowed to enter into a contract or even open a bank account.\"\n\n\n"}
{"id": "45471258", "url": "https://en.wikipedia.org/wiki?curid=45471258", "title": "Metco 308", "text": "Metco 308\n\nMetco 308 is a graphite cermet powder used to lubricate gas turbine and jet engines. It is applied using a combustion gas spray gun such as the Metco 6p gun or equivalent. It operates in service temperatures up to . It is composed of 85% nickel and 15% graphite, Metco 308 produces what is essentially an oxide-free machine element seal.\n\nBoth Metco 307 and 308 have the same chemical structure, but the particle sizes are different. Metco 307 is more abradable and less erosion-resistant than 308.\n"}
{"id": "711123", "url": "https://en.wikipedia.org/wiki?curid=711123", "title": "Military satellite", "text": "Military satellite\n\nA military satellite is an artificial satellite used for a military purpose. The most common missions are intelligence gathering, navigation and military communications. The first military satellites were photographic reconnaissance missions. Some attempts were made to develop satellite based weapons but this work was halted in 1967 following the ratification of international treaties banning the deployment of weapons of mass destruction in orbit. As of 2013, there are 950 satellites of all types in Earth orbit. It is not possible to identify the exact number of these that are military satellites partly due to secrecy and partly due to dual purpose missions such as GPS satellites that serve both civilian and military purposes.\n\nThe first military use of satellites was for reconnaissance.\n\nIn the United States the first formal military satellite programs, Weapon System 117L, was developed in the mid 1950s. Within this program a number of sub-programs were developed including Corona. Satellites within the Corona program carried different code names. The first launches were code named Discoverer. This mission was a series of reconnaissance satellites, designed to enter orbit, take high-resolution photographs and then return the payload to Earth via parachute. Discoverer 1, the first mission, was launched on 28 February 1959 although it didn't carry a payload being intended as a test flight to prove the technology. The Corona program continued until 25 May 1972. It was abandoned after a Soviet Navy submarine was detected waiting beneath a mid-air retrieval zone in the Pacific Ocean. Corona was followed by other programs including Canyon (seven launches between 1968 and 1977), Aquacade and Orion (stated by US Government sources to be extremely large). There have also been a number of subsequent programs including Magnum and Trumpet, but these remain classified and therefore many details remain speculative.\n\nThe Soviet Union began the Almaz () program in the early 1960s. This program involved placing space stations in Earth orbit as an alternative to satellites. Three stations were launched between 1973 and 1976: Salyut 2, Salyut 3 and Salyut 5. Following Salyut 5, the Soviet Ministry of Defence judged in 1978 that the time consumed by station maintenance outweighed the benefits relative to automatic reconnaissance satellites.\n\nIn 2015, United States military space units, and commercial satellite operator Intelsat, became concerned about apparent reconnaissance test maneuvers by Russian Luch (or Olymp) satellite which was launched in September 2014, when it maneuvered between the Intelsat 7 and Intelsat 901 satellites which are located only half a degree from one another in geosynchronous orbit.\n\nThe first satellite navigation system, Transit, used by the United States Navy, was tested in 1960. It used a constellation of five satellites and could provide a navigational fix approximately once per hour.\n\nDuring the Cold War arms race, the nuclear threat was used to justify the cost of providing a more capable system. These developments led eventually to the deployment of the Global Positioning System (GPS). The US Navy required precise navigation to enable submarines to get an accurate fix of their positions before they launched their SLBMs. The USAF had requirements for a more accurate and reliable navigation system, as did the United States Army for geodetic surveying for which purpose they had developed the SECOR system. SECOR used ground-based transmitters from known locations that sent signals to satellite transponder in orbit. A fourth ground-based station, at an undetermined position, could then use those signals to fix its location precisely. The last SECOR satellite was launched in 1969.\n\nIn 1978, the first experimental Block-I GPS satellite was launched and by December 1993, GPS achieved initial operational capability (IOC), indicating a full constellation (24 satellites) was available and providing the Standard Positioning Service (SPS). Full Operational Capability (FOC) was declared by Air Force Space Command (AFSPC) in April 1995, signifying full availability of the military's secure Precise Positioning Service (PPS).\n\nA number of nations have developed satellite based early warning systems designed to detect ICBMs during different flight phases. In the United States these satellites are operated by the Defense Support Program (DSP). The first launch of a DSP satellite was on 6 November 1970 with the 23rd and last launched 10 November 2007. This program has been superseded by the Space-Based Infrared System (SBIRS).\n\nIn the United States, research into satellite based weapons was initiated by President Dwight D. Eisenhower in the 1950s. In 1958, the United States initiated Project Defender to develop an anti-ICBM solution launched from satellites. The satellites would have deployed a huge wire mesh to disable ICBMs during their early launch phase. The project floundered due to the lack of any mechanism to protect the satellites from attack resulting in the cancellation of Defender in 1968.\n\nSince October 1967 satellite based weapons systems have been limited by international treaty to conventional weapons only. of the Outer Space Treaty specifically prohibits signatories from installing weapons of mass destruction in Earth orbit. The treaty became effective on 10 October 1967 and, as of May 2013, 102 countries are parties to the treaty with a further 27 pending full ratification.\n\nCommunications satellites are used for [military communications] applications. Typically military satellites operate in the UHF, SHF (also known as X-band) or EHF (also known as K band) frequency bands.\n\nThe US Armed Forces maintains international networks of satellites with ground stations located in various continents. \nSignal latency is a major concern in satellite communications, so geographic and meteorological factors play an important role in choosing teleports. Since some of the major military activities of the U.S. army is in foreign territories, the U.S. government needs to subcontract satellite services to foreign carriers headquartered in areas with favorable climate.\n\nMilitary Strategic and Tactical Relay, or Milstar, is a constellation of military satellites managed by the United States Air Force. Six spacecraft were launched between 1994 and 2003, of which five are operational, with the sixth lost in a launch failure. They are deployed in geostationary orbit and provide wideband, narrowband and protected military communication systems. Wideband systems support high-bandwidth transfers. Protected systems offer more sophisticated security protection like antijam features and nuclear survivability, while narrowband systems are intended for basic communications services that do not require high bandwidth.\n\nThe United Kingdom also operates military communication satellites through its Skynet system. This is currently operated with support from Astrium Services and provides near worldwide coverage with both X band and Ultra high frequency services.\n\nSkynet 5 is the United Kingdom's most recent military communications satellite system. There are four Skynet satellites in orbit, with the latest launch completed in December 2012. The system is provided by a private contractor, Astrium, with the UK government paying service charges based on bandwidth consumption.\n\n\n\n"}
{"id": "3690642", "url": "https://en.wikipedia.org/wiki?curid=3690642", "title": "Nail file", "text": "Nail file\n\nA nail file is a tool used to gently grind down and shape the edges of nails. They are often used in manicures and pedicures after the nail has been trimmed using appropriate nail clippers. Nail files may either be emery boards, ceramic, glass, crystal, plain metal files or metal files coated with corundum.\nA nail drill is a powered rotary tool, which is used by a nail technician to file nails.\n\nEmery boards are small flat objects which have emery or emery paper glued to them, making them both abrasive and flexible, used for fingernail and toenail care. They are used by manicurists to shape and smooth the nail during manicure and pedicure sessions. Emery boards are inexpensive and disposable, making them a sanitary alternative to metal nail files. The emery board was first patented by J. Parker Pray of New York in 1883.\n\nEmery boards are generally less abrasive than the metal nail files, and hence, emery boards may take longer to file down nails than metal nail files. However, nail files may play a role in disease transmission if they are used on more than one person without adequate sterilization. Emery boards are usually less expensive than metal nail files, therefore emery boards can be economically disposed of after use on a single person.\nThe nail can be smoothed and shaped accurately by taking light, even strokes in one direction across the top of the nail. Twenty to thirty easy strokes can typically shorten excessively long fingernails, while five to ten strokes are sufficient for shaping the nails.\n\nGuitar players have also been known to use emery boards to smooth out calluses which may snag the strings of their guitars.\n\nBaseball pitchers and cricket bowlers have been known to use emery boards to scuff the outside of the ball. The roughness can offer more grip and hand control. Surface scratches also alter the ball's aerodynamics making it more susceptible to spin and movement when in flight. However, the deliberate manipulation of the ball using an emery board is classified as cheating in baseball and cricket.\n\nIn an infamous 1987 Major League Baseball incident, Joe Niekro of the Minnesota Twins was caught with an emery board in his pocket and suspended for ten games. He claimed it was for filing his nails.\n\nGlass nail files are more recently available. Since glass nail files have a smoother and more even surface they do not splinter the nail like emery boards or metal nail files. This makes them a preferred instrument by manicurists, although they are sometimes difficult to find in stores. Glass nail files come in very different qualities, some of them solid glass, others merely glass covered with an abrasive surface.\n\nAlthough the modern nail file only appeared at the end of the 19th century, evidence of nail file-like tools exist even further back in history. Marie Antoinette was known for her obsession with the \"lime à ongles\", which was a nail file-like tool made of pumice stone. When her perfectly shaped nails were seen, it became the latest female trend in the French Court of Versailles. The pumice stone was carved into a pencil like shape, which was used to trim and shape the edges of the nail. This tool would not be disposed after use, but would be hand washed by the maids and placed by the bathtub to be used again.\n\n"}
{"id": "3601262", "url": "https://en.wikipedia.org/wiki?curid=3601262", "title": "Nav/attack system", "text": "Nav/attack system\n\nA nav/attack system (short for navigation/attack system) is an integrated suite of sensors and navigation equipment that allows a military aircraft to locate and attack specific ground targets or conduct aerial reconnaissance with a high degree of precision.\n\nSince the late 1950s, nav/attack systems helped pilots increase the accuracy of releasing ordnance. A computer program would record the aircraft's velocity and use it to pinpoint their location in relationship with the target's location. Early integrated nav/attack systems suffered from poor reliability. Improvements in digital computing technology, advent of the microchip, have resulted in substantially more sophisticated and effective equipment.\n\nA typical modern nav/attack system is based around an inertial navigation system (INS) that allows the aircrew to locate the target area without relying on active sensors such as radar that might alert enemy combatants. INS can help calculate \"drift\", changes in course that deviate from the target, the nav/attack system can guide the aircraft to the target or be used as a tool to help guide the pilot to the target.\n\nModern systems typically provide an automatic weapons release; the aircraft can be programmed to release the ordnance before it misses the target. \nThe aircraft's computer system will release the ordnance unless the pilot chooses to override that command and release it instead. \nThe navigation program accounts for factors such as wind and velocity.\nEarly nav/attack systems were primitive but paved the way for the systems we have today. Today's systems give pilots deadlier accuracy because of technological advances that have developed since the first model. \n"}
{"id": "5259521", "url": "https://en.wikipedia.org/wiki?curid=5259521", "title": "Negative-pressure wound therapy", "text": "Negative-pressure wound therapy\n\nNegative-pressure wound therapy (NPWT) is a therapeutic technique using a vacuum dressing to promote healing in acute or chronic wounds and enhance healing of second- and third-degree burns. The therapy involves the controlled application of sub-atmospheric pressure to the local wound environment, using a sealed wound dressing connected to a vacuum pump. The use of this technique in wound management increased dramatically over the 1990s and 2000s and a large number of studies have been published examining NPWT. NPWT appears to be useful for diabetic ulcers and management of the open abdomen (laparotomy) but further research is required for other wound types.\n\nNPWT promotes wound healing by applying a vacuum through a special sealed dressing. The continued vacuum draws out fluid from the wound and increases blood flow to the area. The vacuum may be applied continuously or intermittently, depending on the type of wound being treated and the clinical objectives. Typically, the dressing is changed two to three times per week. The dressings used for the technique include open-cell foam dressings and gauze, sealed with an occlusive dressing intended to contain the vacuum at the wound site. Where NPWT devices allow delivery of fluids, such as saline or antibiotics to irrigate the wound, intermittent removal of used fluid supports the cleaning and drainage of the wound bed.\n\nIn 1995, Kinetic Concepts was the first company to have a NPWT product cleared by the US Food and Drug Administration. Following increased use of the technique by hospitals in the US, the procedure was approved for reimbursement by the Centers for Medicare and Medicaid Services in 2001.\n\nGeneral technique for NPWT is as follows: \"protect the periwound by applying a skin barrier then it should be followed by a transparent film.\" A dressing or filler material is fitted to the contours of a wound (which is covered with a non-adherent dressing film) and the overlying foam is then sealed with a transparent film. A drainage tube is connected to the dressing through an opening of the transparent film. A vacuum tube is connected through an opening in the film drape to a canister on the side of a vacuum pump. or vacuum source, turning an open wound into a controlled, closed wound while removing excess fluid from the wound bed to enhance circulation and remove wound fluids. This creates a moist healing environment and reduces edema. \"There must be an air tight seal in order for this therapy to be successful.\" The technique is usually used with chronic wounds or wounds that are expected to present difficulties while healing (such as those associated with diabetes).\n\nThree types of filler material are used over the wound surface: open-cell foam, gauze and transparent film, or honeycombed textiles with a dimpled wound contact surface. \n\nWith all three techniques, once the dressing is sealed the vacuum pump can be set to deliver continuous or intermittent pressures, with levels of pressure depending on the device used, varying between −125 and −75 mmHg depending on the material used and patient tolerance. Pressure can be applied constantly or intermittently.\n\nThe dressing type used depends on the type of wound, clinical objectives and patient. For pain sensitive patients with shallow or irregular wounds, wounds with undermining or explored tracts or tunnels, gauze may be used, while foam may be cut easily to fit a patient’s wound that has a regular contour and perform better when aggressive granulation formation and wound contraction is the desired goal.\n\nContraindications for NPWT use include:\n\nA 2007 Cochrane Review stated that the evidence comparing NPWT to alternative care was flawed and required more study, but the evidence did support improved healing and called for more, better quality research to be conducted. A 2010 systematic review found \"consistent evidence of the benefit of NPWT\" in the treatment of diabetic ulcers of the feet. Results for bedsores were \"conflicting\" and research on \"mixed wounds\" was of poor quality, but promising. The review did not find evidence of increased significant complications. The review concluded \"There is now sufficient evidence to show that NPWT is safe, and will accelerate healing, to justify its use in the treatment of diabetes-associated chronic leg wounds. There is also evidence, though of poor quality, to suggest that healing of other wounds may also be accelerated.\"\n"}
{"id": "27922585", "url": "https://en.wikipedia.org/wiki?curid=27922585", "title": "Oregon Iron Works Sea Scout", "text": "Oregon Iron Works Sea Scout\n\nThe Oregon Iron Works Sea Scout is an unmanned seaplane developed by Oregon Iron Works in Clackamas, Oregon and Geneva Aerospace of Carrollton, Texas for the United States Navy. The Sea Scout was developed from the Geneva Aerospace Dakota UAV as part of a $497,000 Vought Aircraft Industries study in 2005 funded by DARPA to convert the Dakota UAV for water-borne operations.\n\nThe Sea Scout's first flight was on May 30, 2006 and is the first auto-landing of a seaplane in the United States.\n"}
{"id": "2822439", "url": "https://en.wikipedia.org/wiki?curid=2822439", "title": "Pellet mill", "text": "Pellet mill\n\nA pellet mill, also known as a pellet press, is a type of mill or machine press used to create pellets from powdered material. Pellet mills are unlike grinding mills, in that they combine small materials into a larger, homogeneous mass, rather than break large materials into smaller pieces.\n\nThere are many types of pellet mills that can be generally grouped into \"large-scale\" and \"small-scale\" types. According to the production capacity, pellet mills also can be divided into flat die pellet mill and ring die pellet mill. \n\nThere are two common types of large-scale pellet mills: \"flat die\" mills and \"ring die\" mills. Flat die mills use a flat die with slots. The powder is introduced to the top of the die and as the die rotates a roller presses the powder through the holes in the die. A cutter on the other side of the die cuts the exposed pellet free from the die. In the ring die there are radial slot throughout the die. Powder is fed into the inside of the die and spreaders evenly distribute the powder. Two rollers then compress the powder through the die holes. Two cutters are used to cut the pellets free from the outside of the die.\n\nLarge scale pellet mills are usually used to produce animal feed, wood pellets, and fuel pellets for use in a pellet stove.\n\nSmall-scale mills are usually variations of screw presses or hydraulic presses. The same basic process is used for both types. A die, also known as a mold, holds the uncompressed powder in a shaped pocket. The pocket shape defined the final pellet shape. A platen is attached to the end of the screw (in a screw press) or the ram (in a hydraulic press) which compresses the powder.\n\nSome platens are heated to speed up the time it takes and improve the overall structure of the pellet. They may also have water ports for quick cooling between uses.\n\nOne of the more common applications is to produce KBr pellets which are used in infrared spectroscopy applications.\n\nAnimal feed pellets are usually a mixture of dry powdered feedstock, such as flour, sawdust, or grass, and a wet ingredient, such as molasses or steam. Feedstocks for pellet mills can sometimes break down and then re-form, or polymerize, under the extreme heat and pressure of the pellet mill.\n"}
{"id": "1696028", "url": "https://en.wikipedia.org/wiki?curid=1696028", "title": "Pin", "text": "Pin\n\nA pin is a device used for fastening objects or material together, and can have three sorts of body: a shaft of a rigid inflexible material meant to be inserted in a slot, groove, or hole (as with pivots, hinges, and jigs); a shaft connected to a head and ending in a sharp tip meant to pierce one or more pieces of soft materials like cloth or paper (the straight or push pin); a single strip of a rigid but flexible material (e.g. a wire) whose length has been folded into parallel prongs in such fashion that the middle length of each curves towards the other so that, when anything is inserted between them, they act as a clamp (e.g. the bobby pin), or two strips of a rigid material bound together by a spring at one end so that, when the spring held open, one can insert some material between the prongs at the other end that, the spring allowed to close, then clamp the inserted material. According to their function, pins can be made of metals (e.g. steel, copper, or brass), wood, or plastic. \n\nThe development of the pin closely paralleled that of its perforated counterpart, the needle. Archaeological evidence suggests that curved sewing pins have been used for over four thousand years. Originally, these were fashioned out of iron and bone by the Sumerians and were used to hold clothes together. Later, pins were also used to hold pages of books together by threading the needle through their top corner.\n\nMany later pins were made of brass, a relatively hard and ductile metal that became available during the Bronze Age. This development was followed by the use of steel which was much stronger but tended to rust when exposed to humid air. The development of inexpensive electroplating techniques allowed the steel to be plated with nickel. Nickel did not rust, but tended to flake off the steel in humid weather, again allowing it to rust. However, this took many months or even years to happen, and as nickel plated steel pins were usually used only temporarily to hold fabric in place prior to sewing, no further refinement has been considered necessary. Note, however, that some modern specialty pins are made out of rust-proof and very strong titanium.\n\nAdam Smith described the manufacture of pins using extensive division of labor in his Wealth of Nations. John Ireland Howe invented a pin-making machine in 1832, and an improved machine in 1841; his Howe Manufacturing Company of Derby, Connecticut, used three machines to produce 72,000 pins per day in 1839.\n\nWalter Hunt invented the safety pin by forming an eight-inch brass pin into a bent pin with a spring and guard. He sold the rights to his invention to pay a debt to a friend, not knowing that he could have made millions of dollars.\n\nThe push pin was invented in 1900 by Edwin Moore and quickly became a success. These pins are also called \"thumbtacks\". There is also a new push pin called a \"paper cricket\".\n\nThin, hardened pins can be driven into wood with a hammer with the goal of not being seen.\n\nIn engineering and machine design, a pin is a machine element that secures the position of two or more parts of a machine relative to each other. A large variety of types has been known for a long time; the most commonly used are solid cylindrical pins, solid tapered pins, groove pins, slotted spring pins and spirally coiled spring pins.\n\n"}
{"id": "26030713", "url": "https://en.wikipedia.org/wiki?curid=26030713", "title": "Reshma Saujani", "text": "Reshma Saujani\n\nReshma Saujani is an American lawyer and politician. She is the founder of the tech organization Girls Who Code. She was previously the Deputy Public Advocate at the Office of the New York City Public Advocate. Saujani lost the 2010 Democratic primary (19%-81%) for the U.S. House of Representatives in New York's 14th congressional district against incumbent Congresswoman Carolyn Maloney. Saujani was the first Indian-American woman (and the first South Asian American woman) to run for Congress. She ran as a Democratic candidate for New York City Public Advocate in 2013, coming third in the primary.\n\nSaujani was born in Illinois. She is of Gujarati Indian descent. Saujani's parents lived in Uganda, prior to being expelled along with other persons of Indian descent in the early 1970s by Idi Amin. They settled in Chicago.\n\nSaujani attended the University of Illinois at Urbana-Champaign, where she graduated in 1997 with majors in Political Science and Speech Communication. She attended the John F. Kennedy School of Government at Harvard University, where she received a Master of Public Policy in 1999, and Yale Law School, where she received her Juris Doctor in 2002.\n\nSaujani worked at the law firm Davis Polk & Wardwell LLP, where she defended securities fraud cases, and on a pro bono basis handled asylum cases. In 2005, she joined the investment firm Carret Asset Management. After Saujani left Carret, its principal owner, financier Hassan Nemazee, was convicted on felony charges relating to bank fraud carried out over the course of several years at Carret, including during Saujani's time at Carret; she later told the news media that she had had no knowledge of any illicit conduct at Carret. Subsequently, she joined Blue Wave Partners Management, a subsidiary of the Carlyle Group, the global alternative asset management firm specializing in private equity. She was an associate general counsel at Blue Wave, an equity multi-strategy hedge fund; it was closed in the aftermath of the 2008 market collapse. Immediately prior to running for Congress, Saujani was a deputy general counsel at Fortress Investment Group. In 2012, Saujani founded Girls Who Code, a nonprofit organization which works to close the gender gap in technology. In 2015, she collected a salary of $224,913 from the organization according to Internal Revenue Service filings.\n\nIn September 2015, Reshma Saujani was named to Fortune Magazine's 40 Under 40 list.\n\nSaujani founded \"South Asians for Kerry\" during the 2004 presidential election.\n\nSaujani served on the National Finance Board for Hillary Clinton during Clinton's campaign for president in 2008. Following the primaries, she was named Vice-Chair of the New York delegation at the 2008 Democratic National Convention in Denver.\n\nSaujani has also contributed to the Huffington Post and WNYC.\n\nShe has been featured on NY1, MSNBC, FOX, and CNBC.\n\nIn September 2011, she was named one of \"City & State\"'s \"40 under 40\" for being a young influential member of New York City politics.\n\nSaujani challenged incumbent Democratic Representative Carolyn Maloney in the 2010 House elections. Saujani's previous work for and link to Wall Street firms was seen as a liability to her credibility and acceptance by Democratic primary voters. Saujani won the support of Jack Dorsey, co-founder and chairman of Twitter; Randi Zuckerberg, director of market development for Facebook and sister of Facebook co-founder Mark Zuckerberg; Alexis Maybank, co-founder of Gilt Groupe; and Chris Hughes, co-founder of Facebook. Saujani outraised Maloney by almost a 2-to-1 margin in the last quarter of 2009, when Maloney had ceased fundraising following the death of her husband, Clifton Maloney, who in September had died unexpectedly on a mountain-climbing expedition in the Himalayas. Saujani's candidacy received the backing of prominent Upper East Side political fundraisers, including Cathy Lasry, Maureen White, and White's husband, financier Steven Rattner.\n\nA poll commissioned in the spring of 2010 by the Maloney campaign showed Saujani trailing Maloney by more than 68 points. The same poll found Maloney to hold a favorable rating of 86%. Saujani's campaign mailed a flyer to voters implicating Maloney as one of eight House members investigated for taking donations from special interests. Maloney won the primary by receiving 81% of the vote to Saujani's 19%, winning the Manhattan, Queens, and Roosevelt Island portions of the district across the board by decisive margins. Saujani received 6,231 votes, despite her campaign's expenditure of $1.3 million, spending more than $213 for every vote she received.\n\nSaujani's campaign was the first political campaign to use technology tools such as Square, Inc.\n\nSaujani ran for the role of New York Public Advocate in 2013, coming third in the Democratic primary. Her campaign manager in 2013 was Michael Blake, who later served as a New York State Assemblyman, and then ran for the Public Advocate seat himself in 2018.\n\nIn January 2013, Saujani's Wikipedia page was heavily edited to remove traces of Saujani working for Wall Street firms such as hedge funds. Her campaign admitted to this, arguing they did it because they disagreed with the stated facts.\n\nSaujani was featured at the opening session of the 2017 American Library Association Conference, speaking in support of programs targeting girls entering the computer science profession. She is the founder of Girls Who Code.\n\nSaujani is the author of \"Women Who Don't Wait in Line: Break the Mold, Lead the Way,\" published by Houghton Mifflin Harcourt in 2013, and \"Girls Who Code: Learn to Code and Change the World,\" published by Viking in August 2017.\n\nSaujani is married to entrepreneur Nihal Mehta, who was a co-founder of ad tech startup LocalResponse and now is a co-founding partner of Eniac Ventures, a seed stage venture capital firm. Saujani is a practicing Hindu. The two have a son born in February 2015.\n\n\n"}
{"id": "17889101", "url": "https://en.wikipedia.org/wiki?curid=17889101", "title": "Rietveld joint", "text": "Rietveld joint\n\nA Rietveld joint, also called a Cartesian node in furniture-making, is an overlapping joint of three battens in the three orthogonal directions. It was a prominent feature in the Red and Blue Chair that was designed by Gerrit Rietveld.\n\nRietveld joints are inextricably linked with the early 20th century Dutch artistic movement called De Stijl (of which Gerrit Rietveld was a member), a movement whose aims included ultimate simplicity and abstraction. This led to the movement's three-dimensional works having vertical and horizontal lines that are positioned in layers or planes that do not intersect, thereby allowing each element to exist independently and unobstructed by other elements and giving a piece a visually raw and simplified look.\n\nIn Gerrit Rietveld's furniture, many of these joints were doweled, meaning that the adjoining faces were connected with glued wooden pins. The first two connections were made by boring a hole about 1 mm deeper than the dowel length, but the third connection was made with\na longer dowel, boring through a batten, leaving a circular mark that had to be painted over.\n"}
{"id": "13167343", "url": "https://en.wikipedia.org/wiki?curid=13167343", "title": "Sodablasting", "text": "Sodablasting\n\nSodablasting is a mild form of abrasive blasting in which sodium bicarbonate particles are blasted against a surface using compressed air. It has a much milder abrasive effect than sandblasting. An early use was in the conservation-restoration of the Statue of Liberty in the 1980s.\n\nSodablasting is a non-destructive method for many applications in cleaning, paint and varnish stripping, automotive restoration, industrial equipment maintenance, rust removal, graffiti removal, molecular steel passivation against rust, oil removal by saponification and translocation, masonry cleaning and restoration, soot remediation, boat hull cleaning and for food processing facilities and equipment and tooth cleaning at the dental laboratory.\n\nSodablasting can be used for cleaning timber, wood, oak beams, oak floors, doors, stairs & bannisters, cars, boat hulls, masonry, and food processing equipment. Sodablasting can also be used to remove graffiti and to clean structural steel. Sodablasting is very effective for mold and fire/smoke damage cleanup as it cleans and deodorizes.\n\nA sodablaster is a self-contained system that includes a blast generator, high pressure compressed air, moisture decontamination system, blast hose, and a blast nozzle. The blasting material consists of formulated sodium bicarbonate (also known as baking soda). Blasting soda is an extremely friable material that undergoes micro fragmentation on impact, literally exploding away surface materials without damage to the substrate. Since sodium bicarbonate is much softer than the silicon carbide or aluminium oxide used in sandblasting, the blast nozzle used for sodablasting applications can be made of soft metals such as brass or steel. The pressures used are very low compared to those used in sandblasting, e.g. 20psi as opposed to 120psi.\n"}
{"id": "27612", "url": "https://en.wikipedia.org/wiki?curid=27612", "title": "Sonic screwdriver", "text": "Sonic screwdriver\n\nThe sonic screwdriver is a multifunctional fictional tool in the British science fiction television programme \"Doctor Who\" and its spin-offs, used by the Doctor. Like the TARDIS, it has become one of the icons of the programme, and spin-off media such as \"The Sarah Jane Adventures\" and \"Torchwood\" have replicated its functions in devices such as the sonic lipstick, sonic blaster, sonic probe, and sonic modulator.\n\nThe sonic screwdriver was first introduced in 1968 in the story \"Fury from the Deep\", and used twice more (\"The Dominators\" and \"The War Games\") during the Second Doctor's tenure. It became a popular tool for the Third Doctor and Fourth Doctor. It was finally written out of the series in 1982 due to the limitations it caused when writing for the show. It then featured briefly in the 1996 \"Doctor Who\" television movie, before making a full return in the 2005 continuation of the series.\n\nThroughout the programme, there have been many different versions of the sonic screwdriver, as with subsequent Doctors the design of it was changed. It has also been destroyed on a number of occasions, thus leading to the introduction of the next model. Not all iterations of the Doctor have used the sonic screwdriver on screen; the Fifth Doctor in fact opted not to replace his after it was destroyed.\n\nThe Twelfth Doctor loses his sonic screwdriver to the creator of the Daleks, Davros, after lending it to him when he was a child. In the last episode of Series 9, the Doctor received a new sonic screwdriver from the TARDIS in place of the temporary sonic glasses.\n\nDespite the Doctor's claim not to give his screwdriver to anyone, he gives one to his own doppelgänger in \"The Rebel Flesh\", and gives his to Rory Williams in \"The Girl Who Waited\" after having either given or loaned one to him for use in \"A Good Man Goes to War\" and loaning him one in \"The Big Bang\". He also gives one to River Song in \"The Husbands of River Song\" which is then used by the Tenth Doctor to save her life in \"Forest of the Dead\".\n\nThe functions of a sonic screwdriver are based on its power over sound waves, radiation, wavelengths, frequencies, signals, and electro-magnetism. It is shown to hack, disable, activate, and otherwise control technology from almost everything, allowing it to remotely control almost any machinery, mechanisms and computers it is applied to, allowing it to open locks, detonate explosives, remotely activate electronics, override most systems, activate computers, and cause some energy weapons to burst into flames or sparks. There is technology the sonic is unable to interface with, such as the isomorphic controls seen in \"A Christmas Carol\". It also is capable of causing chemical reactions that allowed the Doctor to turn eye glass lenses black like sunglasses and causing cut barbed wire to regenerate (setting 2428B). It is also capable of detecting, amplifying and controlling certain energies, sound, signals, frequencies, and waves, allowing the Doctor to intercept a teleporting individual and send them where he chooses, scan and identify matter, send out communications, enhance sounds, signals and frequencies, and acting as a catalyst or conduit for energies. Sonics are also capable of calculations, such as \"The Day of the Doctor\" (2013), when the War Doctor used calculations to allow the sonic to work on wood, the calculations of which appeared partly done on the Tenth Doctor's sonic and completed in the Eleventh's. The War Doctor also used his sonic in tandem with the Tenth and Eleventh's to create a force field wave to repel a Dalek.\n\nThese are more specific functions of the sonic screwdriver:\n\nAside from being a tool, the sonic screwdriver can be used and considered as a defensive weapon, which is effective for a few types of assault weapons, but not designed to kill or injure living things as the only way it can really hurt or incapacitate a creature is by emitting painful bursts of sound, or, as of \"Day of the Moon\" (2011) by blasting a green wave of energy to incapacitate a target, though only the Eleventh and Twelfth's sonic has been shown to do the latter.\n\nThe sonic screwdriver made its first appearance in the serial \"Fury from the Deep\" (1968), written by Victor Pemberton. It was used thereafter by the Second Doctor as a multi-purpose tool, with occasional variations in appearance over the course of the series.\n\nIts abilities and overall appearance varied greatly during the classic series. The name implies that it operates through the use of sound waves to exert physical forces on objects remotely. During the Second Doctor's tenure, it functioned much as its name implied—using sonic waves to dismantle equipment or to bypass locks. In addition, it was used as a welding torch in Episode Five of \"The Dominators\" (1968). In the audio commentary for \"The Sea Devils\" (1972), Michael Briant claims to have suggested it as a one-off gadget in 1968.\n\nDuring the Third Doctor's tenure, producer Barry Letts was adamant that the device not become a cure-all for the series, and limited its use to avoid writers becoming over-reliant on it. During this time, the device underwent significant design changes. In \"The Sea Devils\", the Doctor used it to detonate landmines; Michael E. Briant explains that this was feasible, stating that the sonic waves shook the mines. In \"The Three Doctors\" (1972–73), the sonic screwdriver is almost unrecognisable, being a unique, one-use prop with a plastic red spherical head. In the DVD commentary, Letts himself remarks on the thickness of the prop and the fact that it belies the idea that it was the regular one, prompting Katy Manning to question whether it was indeed a sonic screwdriver. This was due to the serial being produced out of transmission order: the original sonic screwdriver prop went missing during the recording of \"Carnival of Monsters\" (1973), requiring a new prop to be built for the rest of the season; \"The Three Doctors\" was recorded after \"Carnival\", but set before it, so the screwdriver could be seen to revert to its previous appearance for one story after \"The Three Doctors\" before receiving a more permanent redesign thereafter.\n\nDuring the first three years of the Fourth Doctor's tenure, producer Philip Hinchcliffe further reduced the use of the sonic screwdriver. Exceptions include \"Robot\" (which was the last story to be produced by Barry Letts), where it was again used to detonate mines, and as a \"miniature sonic lance\" to cut out a lock. Aside from unlocking doors, the device was greatly downplayed during the Fourth Doctor's second and third seasons. It saw a resurgence once Graham Williams took over as producer in 1977. In the final story of season 15, \"The Invasion of Time\", the Fourth Doctor conceded, \"Not even the sonic screwdriver can get me out of this one.\"\n\nIt featured regularly in season 16 during the Key to Time saga. The Doctor's Time Lady companion Romana constructed a sonic screwdriver of her own similar to the Doctor's. It is depicted as being smaller and sleeker than the Doctor's, and he was sufficiently impressed with her design that he attempted to swap screwdrivers with her in \"The Horns of Nimon\" (1979–80). By season 18, both script editor Christopher H Bidmead and producer John Nathan-Turner were eager to downplay the device as much as possible.\n\nThe sonic screwdriver was written out of the series late in season 19, in the Fifth Doctor serial \"The Visitation\" (1982). It is destroyed by a Terileptil to prevent the Doctor from escaping a holding cell; in response, the Doctor sorrowfully remarked, \"I feel as if you've just killed an old friend.\" Eric Saward later explained in a 2005 DVD interview that this was done on the instructions of producer John Nathan-Turner. Saward had written out the sonic screwdriver, believing that the Doctor had \"a cupboard full of them\" in the TARDIS. On the basis that a device that could help in any situation was very limiting for the script, Nathan-Turner decided that it would not return. The Tenth Doctor joked about the Fifth Doctor's lack of sonic screwdriver in the mini-episode \"Time Crash\" (2007), commenting that he \"went hands-free\" and could \"save the universe using a kettle and some string.\" The device did not appear again for the remainder of the original series.\n\nIn the \"Doctor Who\" TV Movie (1996) and \"The Night of the Doctor\" (2013), the Seventh (TVM), Eighth (both), & the War Doctor (\"The Night of the Doctor\") were seen to have a new sonic screwdriver with a telescopic mechanism: similar to its predecessors but with subtle differences such as a gold/brass band on the handle, a flat base and a red emitter tip.\n\nA redesigned sonic screwdriver appears in the new series, with a blue light in addition to the sound effect. In its first incarnation, the prop used in the new series was fragile and prone to breakage. Over the course of the next two years, the props were continually repaired and modified, with some additions being a new thumb slider design and different colours of wires used in the clear channel when extended.\n\nFor series 4 (2008), a new design of Screwdriver was commissioned by the BBC. Nick Robatto was hired to make two new props. These featured the final slider design, and redesigned body ridges, among other smaller changes. This design debuted in 2008's \"Partners in Crime\" and continued to be used until the Screwdriver's ultimate destruction in 2010's \"The Eleventh Hour\". This later design has gained the nickname \"Series 3–4 Sonic\" (relating to the fact that at the start of Series 3, in \"Smith and Jones\", the first Sonic Screwdriver was supposedly destroyed), even though strictly speaking it first appeared in Series 4.\n\nIn contrast with Nathan-Turner's attitude that the sonic screwdriver should not be used as a cure-all, the new production team gave it even more functionality than previous versions which has given the series some criticism as it seems to be a deus ex machina, a literary device that is generally avoided. Some of the uses in the new series include: repairing electronic equipment; re-attaching materials such as barbed wire; detecting, intercepting and sending signals; remotely operating the TARDIS; burning, cutting, or igniting substances; fusing metal; scanning and identifying substances; amplifying or augmenting sound; modifying mobile phones to enable \"universal roaming\"; disabling alien disguises; resonating concrete; reversing teleportation of another entity. It is sometimes used to disassemble robotic enemies or turn other objects into weapons; healing cuts and wounds. In \"The Parting of the Ways\" (2005) and \"Utopia\" (2007), it is used to operate the TARDIS controls remotely; when the Doctor attempts to counteract the Master's theft of the TARDIS, it is used to limit the TARDIS' destination. In \"Doomsday\" (2006), the Doctor states that the sonic screwdriver does not kill, wound or maim; however, it is sometimes brandished in a threatening manner, such as in \"The Christmas Invasion\" (2005), \"The Impossible Planet\" (2006), \"The Runaway Bride\" (2006), \"The Lazarus Experiment\" (2007), \"The Day of the Doctor\" (2013) and \"The Infinite Quest\" (2007). In \"World War Three\" (2005), when confronted by a group of Slitheen, the Doctor threatens to \"triplicate the flammability\" of a bottle of port wine with the sonic screwdriver, though one of the Slitheen realises he is bluffing. In \"Closing Time\" (2011), ringed energy beams are seen emitted from the device, giving it a more weapon-like appearance, particularly when used to disable a weakened Cyberman at a distance.\n\nIn \"Smith and Jones\", the sonic screwdriver burns out after the Doctor uses it to amplify the radiation output of a hospital X-ray machine. In the \"Series Three concept Artwork Gallery\", when referring to the burnt out sonic screwdriver, Peter McKinstry says \"the green crystal structure visible under the shattered dome refers back to the TARDIS console crystal. It's the same technology – the TARDIS's little brother.\" Though initially saddened at the loss of the screwdriver, the Doctor obtains a new one at the conclusion of the episode.\n\nThe sonic screwdriver is unable to open a \"deadlock seal\", used as a plot device to prevent an easy solution. Russell T Davies once mentioned that he would never make the sonic screwdriver the solution to an episode. In \"Silence in the Library\" (2008), while trying to open a wooden door, the Doctor tells Donna that the sonic screwdriver won't work because the door is made of wood, a fact later restated in \"The Hungry Earth\" (2010); when Rory complains about this, the Doctor counters to not \"diss the sonic.\" The sonic screwdriver's inability to work on wood is clarified in \"In the Forest of the Night\" (2014), when the Doctor states that the sonic screwdriver works by manipulating the moving parts in various machinery: since plant tissue lacks said moving parts, it is unaffected by the sonic screwdriver (though this claim is slightly inconsistent with its visible ability to repair human tissue). In \"The Parting of the Ways\" (2005), the Doctor mentions that when Emergency Program One was activated, the sonic screwdriver would receive a signal from the TARDIS. In \"Forest of the Dead\" (2008), he claims that a few hair-dryers can interfere with the device, though he states that he is \"working on that\".\n\nIn \"The Eleventh Hour\" (2010), the malfunctioning sonic screwdriver is destroyed when the Doctor tries to signal the Atraxi ships. The Doctor later receives a new one, which emerges from the newly regenerated TARDIS console. The Eleventh Doctor's sonic screwdriver is larger than its predecessor; it has a green light and metal claws that extend with a flick of the wrist. It is shown to have been created by the TARDIS as part of its automatic regeneration.\n\nIn \"A Christmas Carol\" (2010), the Doctor advises a young Kazran Sardick to pursue romance while implying that in a similar situation in his own past he had instead gone to his room to \"design a new kind of screwdriver.\"\nAlso in that episode, the sonic screwdriver gets split into two pieces, one of which ends up inside a flying shark. The remaining piece is said to be signalling its other half in an effort to repair itself. The Doctor uses this to send a signal through the half inside the sky shark to open up the clouds. Afterwards, the half not in the shark is left with Kazran Sardick. The Doctor tells Kazran that he can call him for help using the Sonic; though Kazran declines to do so. The Doctor had duplicates of this screwdriver, which he continued to use throughout his travels.\n\nIn \"Let's Kill Hitler\" (2011), it is explained that instead of having settings, this version operates through a psychic interface, basically doing whatever the user thinks of while pointing and holding down the button. This version of the screwdriver also appears, although never officially announced, to have a flashlight setting, as the Doctor is seen to have it emitting a continuous glow while not uttering the classic sonic noise. Also in the episode, the Doctor uses another modified version of his sonic, which he calls a \"Sonic Cane\". It is similar to a Tuxedo cane, except the top replaced with the upper portion of his screwdriver, with a metal ball cut in fourths attached to the claws.\n\nAhead of the 50th anniversary special, a mini-episode entitled \"The Night of the Doctor\" (2013) was produced in which the Eighth Doctor uses the sonic screwdriver twice. The Doctor uses his telescopic screwdriver previously seen in the TV Movie, rather than his updated steampunk version which had been used in numerous Big Finish audio dramas.\n\nFor the 50th anniversary special, \"The Day of the Doctor\" (2013), another version was seen in the hands of John Hurt's War Doctor. The design was similar to the one used by Tom Baker's Fourth Doctor. This time the halo and bullet tip had been removed, replaced by a red light as well as a large red dial added to the base. Character Options released a version of this sonic screwdriver on 23 November 2013 at London's ExCel labelling it \"The Other Doctor's Sonic\". It was established as a plot point in that episode that the sonic screwdrivers employed by various Doctor incarnations all use the same software, something the War Doctor exploited by running a calculation over a course of several centuries with the Tenth and Eleventh Doctors seeing the calculation completed through their models. It is also directly implied after the fact that the sonic screwdriver has actually been a part of every doctor's retinue, despite its disappearance for doctors six & seven; the Tenth Doctor says to the Gallifreyan high command, as all thirteen doctors are about to change history by saving the planet, that the calculations for doing what's about to be done have been \"running all my lives.\" In addition, when combined, the screwdrivers of the War, Tenth, and Eleventh Doctor could create a sonic force field blast to repel and destroy a Dalek.\n\n\"The Magician's Apprentice\" (2015) shows that the sonic screwdriver can create \"an acoustic corridor\" so that the Twelfth Doctor can communicate with a boy trapped in an extraterrestrial mine field. However, when the Doctor discovers that the boy is actually a young Davros, he abandons the boy, leaving the screwdriver behind, though it is revealed that he did save young Davros after all. Davros is shown to have kept the screwdriver in his possession ever since, and the Doctor tells Clara that he no longer has a screwdriver. By that time, the screwdriver had been withered and damaged by time and was seemingly useless.\n\nIn his first appearance at the beginning of series nine of \"Doctor Who\", the Doctor is seen wearing black Ray-Ban sunglasses (\"The Magician's Apprentice\"), and he says that he no longer has his sonic screwdriver. Later, in \"The Witch's Familiar\", he unveils that the sunglasses are actually a wearable version of the screwdriver, claiming that he is \"over\" screwdrivers: \"They spoil the line of your jacket.\" The glasses are used by the Doctor, and Clara on occasion, throughout the ninth series.\n\nThe sonic sunglasses appears to have the same basic functions as the traditional sonic screwdriver, such as scanning objects, while having features not seen before:\n\n\nThe glasses appear to be more susceptible to damage than the screwdriver; in \"The Girl Who Died\", a Viking warrior takes the glasses off the Doctor's face and easily breaks them in half. Nevertheless, the glasses continue to appear via replacement or repair until the end of the season. They return the following season during the Doctor's temporary period of blindness, showing the ability to scan his surroundings and transmit the information to his brain, as well as transmit any data recorded to them. However, while he is able to tell things about a person such as height, weight, gender, age, and even heart rate, he doesn't get enough detail to know faces, clothing, etc. (\"Extremis\") He was once able to tell that a person was holding a computer tablet, but not what was written on it, as well as 'see' a combination lock but not the numbers. (\"The Pyramid at the End of the World\")\n\nIn \"Hell Bent\", the TARDIS gives the Doctor a brand new sonic screwdriver. The new screwdriver has a TARDIS-blue shaft with gold and silver highlights. The upper half is a rectangular light grid that, when switched on, has four different functions: green light with low-pitched sound, blue light with high-pitched sound, green lights that pulse with a pulsing sound, and a blue light chasing pattern with a pulsing sound. The new sonic screwdriver is meant to represent the TARDIS. The Doctor first uses it in \"The Husbands of River Song\" (although he also employs the sonic sunglasses earlier in the episode). The new screwdriver has seen use in the spin-off show \"Class\", where the Doctor increases the voltage of flood lights to expel the Shadow Kin and partially close a rift in space-time. He is shown to have working copies of every version of the Sonic Screwdriver ever seen before in a cup on his desk in \"The Pilot.\" Nardole uses the Fifth Doctor's version when sealing bulkhead doors to keep out Daleks later in the episode.\n\nIn \"The Woman Who Fell to Earth\", the Thirteenth Doctor is depicted constructing a new sonic screwdriver. She proudly proclaims that the new screwdriver is forged out of \"Sheffield Steel\".\n\n\n\n\n\n\n\n\n\nIn the \"Doctor Who\" spin-off series, \"The Sarah Jane Adventures\", Sarah Jane Smith uses a \"sonic lipstick\", which is a gift the Tenth Doctor gave her alongside a new model of K9 and her scanner watch. It functions much like the sonic screwdriver, used primarily for opening and closing locked doors, and for disabling and re-enabling machines; like the sonic screwdriver, it remains ineffective against deadlock seals and wooden objects. A toy version is available.\n\n\n\nOwnership of the sonic screwdriver was retained by the BBC. Victor Pemberton told an interviewer for \"Doctor Who Magazine\", \"I'm very cross that the sonic screwdriver—which I invented—has been marketed with no credit to myself. … It's one thing not to receive any payment, but another not to receive any credit.\"\n\nThe toy version of the new series design (made by Character Options Ltd.) was slightly larger than the on screen version to accommodate a working sound chip. It also includes an ultraviolet light and changeable invisible ink nib for viewing messages written in the ultraviolet ink.\n\nA metal version of the sonic screwdriver produced by Wow Stuff mounts a functional set of changeable flat and Phillips heads under a removable cover as well as providing light and sound effects.\n\nQMx were given the licence to produce accurate replicas of this prop. In 2012, QMx released an \"Artisan Master Series\" replica of this sonic screwdriver, in a strictly limited run of 25, priced at nearly $5,000. These replicas were handmade by original prop-maker Nick Robatto, and have now sold out permanently. QMx later released an Artisan Master Series replica of River Song's sonic screwdriver, limited to a run of 15, also made by original prop maker Nick Robatto, which has also sold out.\n\nThe Wand Company released a universal remote control styled on the Eleventh Doctor's sonic screwdriver on 3 August 2012. Due to consumer demand, a Tenth Doctor version was released on 31 October 2013. An updated, extending version of the Eleventh Doctor's Sonic Screwdriver, named the Twelfth Doctor's Sonic Screwdriver Universal Remote Control, was released on 8 July 2015, to replace the older version, which is no longer produced.\n\nUnderground Toys have released the War Doctor's sonic screwdriver; titled \"The Other Doctor's Sonic Screwdriver\", it was released in the UK in November/December 2013 and in the US January 2014.\n\nCharacter Options have also released toy versions of the Third, Fourth, Fifth and Eighth Doctors' Sonic Screwdrivers.\n\n"}
{"id": "18952779", "url": "https://en.wikipedia.org/wiki?curid=18952779", "title": "Spaser", "text": "Spaser\n\nA spaser or plasmonic laser is a type of laser which aims to confine light at a subwavelength scale far below Rayleigh's diffraction limit of light, by storing some of the light energy in electron oscillations called surface plasmon polaritons. The phenomenon was first described by Bergman and Stockman in 2003. The word \"spaser\" is an acronym for \"surface plasmon amplification by stimulated emission of radiation\". The first such devices were announced in 2009 by three groups: a 44-nanometer-diameter nanoparticle with a gold core surrounded by a dyed silica gain medium created by researchers from Purdue, Norfolk State and Cornell universities, a nanowire on a silver screen by a Berkeley group, and a semiconductor layer of 90 nm surrounded by silver pumped electrically by groups at Technical University of Eindhoven and at Arizona State University. While the Purdue-Norfolk State-Cornell team demonstrated the confined plasmonic mode, the Berkeley team and the Eindhoven-Arizona State team demonstrated lasing in the so-called plasmonic gap mode.\n\nThe spaser is a proposed nanoscale source of optical fields that is being investigated in a number of leading laboratories around the world. Spasers could find a wide range of applications, including nanoscale lithography, fabrication of ultra-fast photonic nano circuits, single-molecule biochemical sensing, and microscopy.\n\nFrom \"Nature Photonics\":\n\nStudy of the quantum mechanical model of the spaser suggests that it should be possible to manufacture a spasing device analogous in function to the MOSFET transistor, but this has not yet been experimentally verified.\n\n"}
{"id": "28668869", "url": "https://en.wikipedia.org/wiki?curid=28668869", "title": "Sweat scraper", "text": "Sweat scraper\n\nA sweat scraper is a tool used in horse grooming and with other animals, such as dogs. It consists of a handle and a rubber blade. Sweat scrapers are available in both metal and plastic form, and also traditionally in wood (as seen in Mongolia). It is used to remove sweat and/or excess hair from larger pets. It is used in much the same manner as a window cleaner would scrape water or foam from a window with a rubber blade. The typical use of a sweat scraper is now actually to remove excess water after washing a horse to help it cool down rather than for just sweat. Without the use of a sweat scraper, it would take more effort and additional rags to remove the same amount of excess water therefore the proper use of a sweat scraper helps to ensure an effective cool down process.\n"}
{"id": "15288165", "url": "https://en.wikipedia.org/wiki?curid=15288165", "title": "Uinta Basin Replacement Project", "text": "Uinta Basin Replacement Project\n\nIn Section 203(a) of the Central Utah Project Completion Act, the United States Congress authorized a federally authorized and funded replacement project to replace the Uinta and Upalco Units of the Central Utah Project (CUP) which were not constructed. The replacement project is the Uinta Basin Replacement Project (UBRP). The UBRP will provide: of irrigation water; of municipal and industrial water; reduced wilderness impacts; increased instream flows; and improved recreation. Design work began in 2002. Construction began in 2004 and is anticipated to be completed in 2011. The Central Utah Water Conservancy District is responsible for construction. The United States Department of the Interior oversees funding and compliance with law and environmental regulation.\n\nThe Uinta Mountains are the only major mountain range running east to west in North America. The Uinta Basin lies to the south of the Uinta Mountains and is fed by creeks and rivers flowing south from those mountains. Many of the principal rivers (Strawberry River, Currant Creek, Rock Creek, Lake Fork River, and Uinta River) flow into the Duchesne River which feeds the Green River—a tributary of the Colorado River.\n\nThe basin is the location of the Ute Tribe of the Uinta and Ouray Reservation (Tribe) which is commonly referred to as the Northern Ute Tribe, as well as the cities of Duchesne, Roosevelt, and Vernal. When oil prices are sufficiently high to overcome the cost of transportation to areas outside the basin, the area’s oil industry roars to life (as it has in the past two years). Ordinarily, agriculture (chiefly cattle operations) is the lifeblood of the basin economy; and, in the basin, irrigation is the lifeblood of agriculture. It is important to note also that wilderness designation protects much of the Uinta Mountains. The mountains and associated streams are an important ecological resource.\nAt the sabres game the fan in the section 203 seat 4 said the above\n\nInterests competing for Uinta Basin water include: non-Indian irrigators, the Tribe, the cities, the oil industry, and the natural environment. All water development in the basin has been intended to serve one or more of these interests.\n\nThe UBRP is founded on and entwined with other water development in the basin. Key stages in that development are the establishment of the Northern Ute Reservation, homesteading and early water development, the Uinta Indian Irrigation Project, the Moon Lake Project, the CUP as originally planned (with the Uinta and Upalco Units), and the current UBRP.\n\n\nIn 1956, congress created the Colorado River Storage Project, authorizing the CUP (as well as other Reclamation projects). The CUP provided for the trans-basin diversion of Uinta Basin water to the Wasatch Front. The Wasatch Front is the most populous area of Utah and includes Provo and Salt Lake City. The project mitigated for the trans-basin diversion by creating the Uinta and Upalco Units. These units would have provided new storage in the Uinta Basin—on the Uinta and Lake Fork Rivers respectively.\n\nFor a variety of reasons, the Uinta and Upalco Units were never constructed. Section 203 (a) of the Central Utah Project Completion Act authorized funding for UBRP—a project intended to provide similar benefits, in some measure, to those that were promised by the units that were not constructed. Originally, the UBRP project planned under the authority of Section 203 (a) was to serve both Indian and non-Indian needs using Indian and non-Indian water. Although planning continued for several years, the Tribe withdrew its support at the eleventh hour—as contracts were being executed. The departure of the Tribe made a reformulation of the plan necessary. Eventually, a scaled-down version was developed. The scaled-down project intentionally avoided interference with tribal water rights, lands, and interests.\n\nThe Central Utah Water Conservancy District (District) is the sponsor and entity responsible for repayment of the federal obligation associated with the Bonneville Unit of the CUP and UBRP.\n\nEach stage in the Uinta Basin water development brought with it new water facilities. Each stage served a different bundle of water right interests and a different set of constituents. The result is a complex layering of economic interests, water rights, land ownership, management objectives, and politics.\n\nPerhaps nowhere in the Basin is this layering and the accompanying actual and potential conflict more focused than the Lake Fork River. The river begins in the High Uintas Wilderness area and feeds thirteen small, high-elevation lakes-turned-reservoirs (High Mountain Lakes). It then provides early-priority Tribe flow rights though a portion of the UIIP, feeds Reclamation’s Moon Lake Project (serving non-Indian irrigators), and provides additional irrigation water by exchange with Starvation Reservoir (a CUP feature). Because it diverts Lake Fork River water, integrating UBRP into this already complex and contentious water environment was difficult and problematic.\n\nThe Feasibility Study and Environmental Assessment for UBRP were published in 2001. As a partial replacement for the Uinta and Upalco Units, UBRP is intended to serve the following purposes: stabilizing the aging and unsafe High Mountain Lakes on the Lake Fork River drainage and restoring ecological values compatible with the High Uintas Wilderness; providing replacement water for the late season irrigation water stored in the High Mountain Lakes; providing of water per year to Roosevelt City for municipal and industrial (M&I) purposes; providing of water per year to Lake Fork River irrigators; facilitating improved water resources management and water conservation in the Uinta Basin by increasing water efficiency, enhancing beneficial use, and developing water storage; and enhancing environmental, fish, wildlife, and recreation resources.\n\nThe project purposes are to be accomplished by construction (or upgrade) of the following facilities.\n\n"}
{"id": "540849", "url": "https://en.wikipedia.org/wiki?curid=540849", "title": "Vitaphone", "text": "Vitaphone\n\nVitaphone was a sound film system used for feature films and nearly 1,000 short subjects made by Warner Bros. and its sister studio First National from 1926 to 1931. Vitaphone was the last major analog sound-on-disc system and the only one which was widely used and commercially successful. The soundtrack was not printed on the film itself, but issued separately on phonograph records. The discs, recorded at  rpm (a speed first used for this system) and typically in diameter, would be played on a turntable physically coupled to the projector motor while the film was being projected, achieving a frequency response of 4300 Hz. Many early talkies, such as \"The Jazz Singer\" (1927), used the Vitaphone system. The name \"Vitaphone\" derived from the Latin and Greek words, respectively, for \"living\" and \"sound\".\n\nThe \"Vitaphone\" trademark was later associated with cartoons and other short subjects that had optical soundtracks and did not use discs.\n\nIn the early 1920s, Western Electric was developing both sound-on-film and sound-on-disc systems, aided by the purchase of Lee De Forest's Audion amplifier tube in 1913, consequent advances in public address systems, and the first practical condenser microphone, which Western Electric engineer E.C. Wente had created in 1916 and greatly improved in 1922. De Forest debuted his own Phonofilm sound-on-film system in New York City on April 15, 1923, but due to the relatively poor sound quality of Phonofilm and the impressive state-of-the-art sound heard in Western Electric's private demonstrations, the Warner Brothers decided to go forward with the industrial giant and the more familiar disc technology.\n\nThe business was established at Western Electric's Bell Laboratories in New York City and acquired by Warner Bros. in April 1925. Warner Bros. introduced Vitaphone on August 5, 1926 with the premiere of their silent feature \"Don Juan\", which had been retrofitted with a symphonic musical score and sound effects. There was no spoken dialog. The feature was preceded by a program of short subjects with live-recorded sound, nearly all featuring classical instrumentalists and opera stars. The only \"pop music\" artist was guitarist Roy Smeck and the only actual \"talkie\" was the short film that opened the program: four minutes of introductory remarks by motion picture industry spokesman Will Hays.\n\n\"Don Juan\" was able to draw huge sums of money at the box office, but was not able to match the expensive budget Warner Bros. put into the film's production. After its financial failure, Paramount head Adolph Zukor offered Sam Warner a deal as an executive producer for Paramount if he brought Vitaphone with him. Sam, not wanting to take any more of Harry Warner's refusal to move forward with using sound in future Warner films, agreed to accept Zukor's offer, but the deal died after Paramount lost money in the wake of Rudolph Valentino's death. Harry eventually agreed to accept Sam's demands. Sam then pushed ahead with a new Vitaphone feature starring Al Jolson, the Broadway dynamo who had already scored a big hit with early Vitaphone audiences in \"A Plantation Act\", a musical short released on October 7, 1926. On October 6, 1927, \"The Jazz Singer\" premiered at the Warner Theater in New York City, broke box-office records, established Warner Bros. as a major player in Hollywood, and is traditionally credited with single-handedly launching the talkie revolution.\n\nAt first, the production of Vitaphone shorts and the recording of orchestral scores was strictly a New York phenomenon, taking advantage of the bountiful supply of stage and concert hall talent there, but the Warners soon migrated some of this activity to their more spacious facilities on the West Coast. Dance band leader Henry Halstead is given credit for starring in the first Vitaphone short subject filmed in Hollywood instead of New York. \"Carnival Night in Paris\" (1927) featured the Henry Halstead Orchestra and a cast of hundreds of costumed dancers in a Carnival atmosphere.\n\nFrom the perspective of the cast and crew on the sound stage, there was little difference between filming with Vitaphone and a sound-on-film system. In the early years of sound, the noisy cameras and their operators were enclosed in soundproofed booths with small windows made of thick glass. Cables suspended the microphones in fixed positions just above camera range, and sometimes they were hidden behind objects in the scene. The recording machines were usually located in a separate building to completely isolate them from sound stage floor vibrations and other undesirable influences. The audio signal was sent from an on-stage monitoring and control booth to the recording room over a heavy shielded cable. Synchronization was maintained by driving all the cameras and recorders with synchronous electric motors powered from a common source. When music and sound effects were being recorded to accompany existing film footage, the film was projected so that the conductor could synchronize the music with the visual cues and it was the projector, rather than a camera, that was electrically interlocked with the recording machine.\n\nExcept for the unusual disc size and speed, the physical record-making process was the same one employed by contemporary record companies to make smaller discs for home use. The recording lathe cut an audio-signal-modulated spiral groove into the polished surface of a thick round slab of wax-like material rotating on a turntable. The wax was much too soft to be played in the usual way, but a specially supported and guided pickup could be used to play it back immediately in order to detect any sound problems that might have gone unnoticed during the filming. If problems were found, the scene could then be re-shot while everything was still in place, minimizing additional expense. Even the lightest playback caused some damage to the wax master, so it was customary to employ two recorders and simultaneously record two waxes, one to play and the other to be sent for processing if that \"take\" of the scene was approved. At the processing plant, the surface of the wax was rendered electrically conductive and electroplated to produce a metal mold or \"stamper\" with a ridge instead of a groove, and this was used to press hard shellac discs from molten \"biscuits\" of the raw material.\n\nBecause of the universal desirability of an immediate playback capability, even studios using sound-on-film systems employed a wax disc \"playback machine\" in tandem with their film recorders, as it was impossible to play an optical recording until it had made the round trip to the film processing laboratory.\n\nA Vitaphone-equipped theater had normal projectors which had been furnished with special phonograph turntables and pickups; a fader; an amplifier; and a loudspeaker system. The projectors operated just as motorized silent projectors did, but at a fixed speed of 24 frames per second and mechanically interlocked with the attached turntables. When each projector was threaded, the projectionist would align a start mark on the film with the film gate, then cue up the corresponding soundtrack disc on the turntable, being careful to place the phonograph needle at a point indicated by an arrow scribed on the record's surface. When the projector was started, it rotated the linked turntable and (in theory) automatically kept the record \"in sync\" (correctly synchronized) with the projected image.\n\nThe Vitaphone process made several improvements over previous systems:\n\nThese innovations notwithstanding, the Vitaphone process lost the early format war with sound-on-film processes for many reasons:\n\nAfter the improvement of the competing sound-on-film systems, Vitaphone's disadvantages led to its retirement early in the sound era. Warner Bros. and First National stopped recording directly to disc and switched to Photophone sound-on-film recording. Warner Bros. had to publicly concede that Vitaphone was being retired, but put a positive spin on it by announcing that Warner films would now be available in \"both\" sound-on-film and sound-on-disc versions. Thus, instead of making a grudging admission that its technology had become obsolete, Warner Bros. purported to be doing the entire movie industry a favor.\n\nA significant number of theater owners, who had invested heavily in Vitaphone equipment only a short time before, were financially unable or unwilling to replace their sound-on-disc-only equipment. Their continuing need for discs compelled most Hollywood studios to prepare sets of soundtrack discs for their new films, made by dubbing from the optical soundtracks, and supply them as required. This practice continued, although on an ever-dwindling scale, into the mid-1930s.\n\nIn 1924–1925, when Western Electric established the format of the system which would eventually be named Vitaphone, they settled on a diameter disc rotating at  rpm as a good practical compromise of disc size and speed. The slow speed permitted the 11-minute playing time needed to match the maximum running time of a then-standard 1000 foot (300 meter) reel of film projected at 24 fps, yet the increased diameter preserved the average effective groove velocity, and therefore the sound quality, of a smaller, shorter-playing record rotating at the then-standard speed of about 78 rpm.\n\nLike ordinary pre-vinyl records, Vitaphone discs were made of a shellac compound rendered lightly abrasive by its major constituent, finely pulverized rock. Such records were played with a very inexpensive, imprecisely mass-produced steel needle with a point that quickly wore to fit the contour of the groove, but then went on to wear out in the course of playing one disc side, after which it was meant to be discarded and replaced. Unlike ordinary records, Vitaphone discs were recorded inside out, so that the groove started near the synchronization arrow scribed in the blank area around the label and proceeded outward. During playback, the needle would therefore be fresh where the groove's undulations were most closely packed and needed the most accurate tracing, and suffering from wear only as the much more widely spaced and easily traced undulations toward the edge of the disc were encountered.\n\nInitially, Vitaphone discs had a recording on one side only, each reel of film having its own disc. As the sound-on-disc method was slowly relegated to second-class status, cost-cutting changes were instituted, first by making use of both sides of each disc for non-consecutive reels of film, then by reducing the discs to in diameter. The use of RCA Victor's new \"Vitrolac\", a lightweight, flexible and less abrasive vinyl-based compound, made it possible to downsize the discs while actually improving their sound quality.\n\nThere were exceptions to the standard size of 1920s Vitaphone discs. In the case of very short films, such as trailers and some of the earliest musical shorts, the recording, still cut at  rpm and working outward from a minimum diameter of about , was pressed on a disc when the smaller size sufficed.\n\nIn 1991, The Vitaphone Project was started by a group of five vintage record collectors and movie enthusiasts. Since the soundtrack discs and film prints of Vitaphone productions often became separated, The Vitaphone Project searches for original 16-inch soundtrack discs and mute film elements that go with surviving soundtrack discs. The Vitaphone Project borrows or purchases soundtrack discs from private collectors and often works with the restoration labs at the University of California at Los Angeles to create new 35mm preservation prints that combine the original picture and sound elements. The Vitaphone Project also often partners with the Library of Congress and the British Film Institute.\n\nAs of December 2016, The Vitaphone Project had located about 6,500 soundtrack discs in private collections and helped preserve 125 films, 12 of which were feature-length films. They have also raised $400,000 in donations, with Hugh Hefner being a notable donor.\n\nThe Vitaphone Project has been able to help restore films featuring stars such as Rose Marie and Al Jolson. They also worked with Warner Brothers to restore 1929's \"Why Be Good?\", the final silent film made by Colleen Moore. Funding raised by The Vitaphone Project was used to restore 1928's \"The Beau Brummels\", starring vaudeville duo Al Shaw and Sam Lee, which was added to the National Film Registry in 2016.\n\nWarner Bros. kept the \"Vitaphone\" trademark alive in the name of its short subjects division, The Vitaphone Corporation (officially dissolved at the end of 1959), most famous for releasing the \"Looney Tunes\" and \"Merrie Melodies\" cartoons. In the 1950s, the Warner Bros. record label boasted \"Vitaphonic\" high-fidelity recording. In the 1960s, the end titles of \"Merrie Melodies\" cartoons (beginning with \"From Hare to Heir\" (1960)) carried the legend \"A Vitaphone Release\". \"Looney Tunes\" of the same period (beginning with that same year's \"Hopalong Casualty\") were credited as \"A Vitagraph Release\", making further use of the name of the venerable Vitagraph Studios in Brooklyn, which the Warners had bought in 1925, used as a facility for working out practical sound film production techniques and filming some early musical shorts, and from which a name for the previously nameless Western Electric sound-on-disc system had been derived.\n\nVitaphone was among the first 25 inductees into the TECnology Hall of Fame at its establishment in 2004, an honor given to \"products and innovations that have had an enduring impact on the development of audio technology.\" The award notes that Vitaphone, though short-lived, helped in popularizing theater sound and was critical in stimulating the development of the modern sound reinforcement system.\n\nThough operating on principles so different as to make it unrecognizable to a Vitaphone engineer, DTS is a sound-on-disc system, the first to gain wide adoption since the abandonment of Vitaphone.\n\n\nNotes\n\nFurther reading\n\n"}
{"id": "3854225", "url": "https://en.wikipedia.org/wiki?curid=3854225", "title": "Waveguide (electromagnetism)", "text": "Waveguide (electromagnetism)\n\nIn electromagnetics and communications engineering, the term waveguide may refer to any linear structure that conveys electromagnetic waves between its endpoints. However, the original and most common meaning is a hollow metal pipe used to carry radio waves. This type of waveguide is used as a transmission line mostly at microwave frequencies, for such purposes as connecting microwave transmitters and receivers to their antennas, in equipment such as microwave ovens, radar sets, satellite communications, and microwave radio links.\n\nA dielectric waveguide employs a solid dielectric rod rather than a hollow pipe. An optical fibre is a dielectric guide designed to work at optical frequencies. Transmission lines such as microstrip, coplanar waveguide, stripline or coaxial cable may also be considered to be waveguides.\n\nThe electromagnetic waves in a (metal-pipe) waveguide may be imagined as travelling down the guide in a zig-zag path, being repeatedly reflected between opposite walls of the guide. For the particular case of rectangular waveguide, it is possible to base an exact analysis on this view. Propagation in a dielectric waveguide may be viewed in the same way, with the waves confined to the dielectric by total internal reflection at its surface. Some structures, such as non-radiative dielectric waveguides and the Goubau line, use both metal walls and dielectric surfaces to confine the wave.\n\nDuring the 1890s theorists did the first analyses of electromagnetic waves in ducts. Around 1893 J. J. Thomson derived the electromagnetic modes inside a cylindrical metal cavity. In 1897 Lord Rayleigh did a definitive analysis of waveguides; he solved the boundary-value problem of electromagnetic waves propagating through both conducting tubes and dielectric rods of arbitrary shape. He showed that the waves could travel without attenuation only in specific normal modes with either the electric field (TE modes) or magnetic field (TM modes), or both, perpendicular to the direction of propagation. He also showed each mode had a cutoff frequency below which waves would not propagate. Since the cutoff wavelength for a given tube was of the same order as its width, it was clear that a hollow conducting tube could not carry radio wavelengths much larger than its diameter. In 1902 R. H. Weber observed that electromagnetic waves travel at a slower speed in tubes than in free space, and deduced the reason; that the waves travel in a \"zigzag\" path as they reflect from the walls.\n\nPrior to the 1920s, practical work on radio waves concentrated on the low frequency end of the radio spectrum, as these frequencies were better for long-range communication. These were far below the frequencies that could propagate in even large waveguides, so there was little experimental work on waveguides during this period, although a few experiments were done. In a June 1, 1894 lecture, \"The work of Hertz\", before the Royal Society, Oliver Lodge demonstrated the transmission of 3 inch radio waves from a spark gap through a short cylindrical copper duct. In his pioneering 1894-1900 research on microwaves, Jagadish Chandra Bose used short lengths of pipe to conduct the waves, so some sources credit him with inventing the waveguide. However, after this, the concept of radio waves being carried by a tube or duct passed out of engineering knowledge.\n\nDuring the 1920s the first continuous sources of high frequency radio waves were developed: the Barkhausen-Kurz tube, the first oscillator which could produce power at UHF frequencies; and the split-anode magnetron which by the 1930s had generated radio waves at up to 10 GHz. These made possible the first systematic research on microwaves in the 1930s. It was discovered that transmission lines used to carry lower frequency radio waves, parallel line and coaxial cable, had excessive power losses at microwave frequencies, creating a need for a new transmission method.\n\nThe waveguide was developed independently between 1932 and 1936 by George C. Southworth at Bell Telephone Laboratories and Wilmer L. Barrow at the Massachusetts Institute of Technology, who worked without knowledge of one another. Southworth's interest was sparked during his 1920s doctoral work in which he measured the dielectric constant of water with a radio frequency Lecher line in a long tank of water. He found that if he removed the Lecher line, the tank of water still showed resonance peaks, indicating it was acting as a dielectric waveguide. At Bell Labs in 1931 he resumed work in dielectric waveguides. By March 1932 he observed waves in water-filled copper pipes. Rayleigh's previous work had been forgotten, and Sergei A. Schelkunoff, a Bell Labs mathematician, did theoretical analyses of waveguides and rediscovered waveguide modes. In December 1933 it was realized that with a metal sheath the dielectric is superfluous and attention shifted to metal waveguides.\n\nBarrow had become interested in high frequencies in 1930 studying under Arnold Sommerfeld in Germany. At MIT beginning in 1932 he worked on high frequency antennas to generate narrow beams of radio waves to locate aircraft in fog. He invented a horn antenna and hit on the idea of using a hollow pipe as a feedline to feed radio waves to the antenna. By March 1936 he had derived the propagation modes and cutoff frequency in a rectangular waveguide. The source he was using had a large wavelength of 40 cm, so for his first successful waveguide experiments he used a 16-foot section of air duct, 18 inches in diameter.\n\nBarrow and Southworth became aware of each other's work a few weeks before both were scheduled to present papers on waveguides to a combined meeting of the American Physical Society and the Institute of Radio Engineers in May 1936. They amicably worked out credit sharing and patent division arrangements.\n\nThe development of centimeter radar during World War 2 and the first high power microwave tubes, the klystron (1938) and cavity magnetron (1940), resulted in the first widespread use of waveguide. Standard waveguide \"plumbing\" components were manufactured, with flanges on the end which could be bolted together. After the war in the 1950s and 60s waveguides became common in commercial microwave systems, such as airport radar and microwave relay networks which were built to transmit telephone calls and television programs between cities.\n\nDepending on the frequency, waveguides can be constructed from either conductive or dielectric materials. Generally, the lower the frequency to be passed the larger the waveguide is. For example, the natural waveguide the earth forms given by the dimensions between the conductive ionosphere and the ground as well as the circumference at the median altitude of the Earth is resonant at 7.83 Hz. This is known as Schumann resonance. On the other hand, waveguides used in extremely high frequency (EHF) communications can be less than a millimeter in width.\n\nElectromagnetic waveguides are analyzed by solving Maxwell's equations, or their reduced form, the electromagnetic wave equation, with boundary conditions determined by the properties of the materials and their interfaces. These equations have multiple solutions, or modes, which are eigenfunctions of the equation system. Each mode is characterized by a cutoff frequency below which the mode cannot exist in the guide. Waveguide propagation modes depend on the operating wavelength and polarization and the shape and size of the guide. The longitudinal mode of a waveguide is a particular standing wave pattern formed by waves confined in the cavity. The transverse modes are classified into different types:\nIn hollow waveguides (single conductor), TEM waves are not possible, since Maxwell's Equations will give that the electric field must then have zero divergence and zero curl and be equal to zero at boundaries, resulting in a zero field (or, equivalently, formula_1 with boundary conditions guaranteeing only the trivial solution). This contrasts with two-conductor transmission lines used at lower frequencies; coaxial cable, parallel wire line and stripline, in which TEM mode is possible. Additionally, the propagating modes (i.e. TE and TM) inside the waveguide can be mathematically expressed as the superposition of TEM waves.\n\nThe mode with the lowest cutoff frequency is termed the dominant mode of the guide. It is common to choose the size of the guide such that only this one mode can exist in the frequency band of operation. In rectangular and circular (hollow pipe) waveguides, the dominant modes are designated the TE mode and TE modes respectively.\n\nIn the microwave region of the electromagnetic spectrum, a waveguide normally consists of a hollow metallic conductor. These waveguides can take the form of single conductors with or without a dielectric coating, e.g. the Goubau line and helical waveguides. Hollow waveguides must be one-half wavelength or more in diameter in order to support one or more transverse wave modes.\n\nWaveguides may be filled with pressurized gas to inhibit arcing and prevent multipaction, allowing higher power transmission. Conversely, waveguides may be required to be evacuated as part of evacuated systems (e.g. electron beam systems).\n\nA slotted waveguide is generally used for radar and other similar applications. The waveguide serves as a feed path, and each slot is a separate radiator, thus forming an antenna. This structure has the capability of generating a radiation pattern to launch an electromagnetic wave in a specific relatively narrow and controllable direction.\n\nA closed waveguide is an electromagnetic waveguide (a) that is tubular, usually with a circular or rectangular cross section, (b) that has electrically conducting walls, (c) that may be hollow or filled with a dielectric material, (d) that can support a large number of discrete propagating modes, though only a few may be practical, (e) in which each discrete mode defines the propagation constant for that mode, (f) in which the field at any point is describable in terms of the supported modes, (g) in which there is no radiation field, and (h) in which discontinuities and bends may cause mode conversion but not radiation.\n\nThe dimensions of a hollow metallic waveguide determine which wavelengths it can support, and in which modes. Typically the waveguide is operated so that only a single mode is present. The lowest order mode possible is generally selected. Frequencies below the guide's cutoff frequency will not propagate. It is possible to operate waveguides at higher order modes, or with multiple modes present, but this is usually impractical.\n\nWaveguides are almost exclusively made of metal and mostly rigid structures. There are certain types of \"corrugated\" waveguides that have the ability to flex and bend but only used where essential since they degrade propagation properties. Due to propagation of energy in mostly air or space within the waveguide, it is one of the lowest loss transmission line types and highly preferred for high frequency applications where most other types of transmission structures introduce large losses. Due to the skin effect at high frequencies, electric current along the walls penetrates typically only a few micrometers into the metal of the inner surface. Since this is where most of the resistive loss occurs, it is important that the conductivity of interior surface be kept as high as possible. For this reason, most waveguide interior surfaces are plated with copper, silver, or gold.\nVoltage standing wave ratio (VSWR) measurements may be taken to ensure that a waveguide is contiguous and has no leaks or sharp bends. If such bends or holes in the waveguide surface are present, this may diminish the performance of both transmitter and receiver equipment connected at either end. Poor transmission through the waveguide may also occur as a result of moisture build up which corrodes and degrades conductivity of the inner surfaces, which is crucial for low loss propagation. For this reason, waveguides are nominally fitted with microwave windows at the outer end that will not interfere with propagation but keep the elements out. Moisture can also cause fungus build up or arcing in high power systems such as radio or radar transmitters. Moisture in waveguides can typically be prevented with silica gel, a desiccant, or slight pressurization of the waveguide cavities with dry nitrogen or argon. Desiccant silica gel canisters may be attached with screw-on nibs and higher power systems will have pressurized tanks for maintaining pressure including leakage monitors. Arcing may also occur if there is a hole, tear or bump in the conducting walls, if transmitting at high power (usually 200 watts or more). Waveguide plumbing is crucial for proper waveguide performance. Voltage standing waves occur when impedance mismatches in the waveguide cause energy to reflect back in the opposite direction of propagation. In addition to limiting the effective transfer of energy, these reflections can cause higher voltages in the waveguide and damage equipment.\n\nIn practice, waveguides act as the equivalent of cables for super high frequency (SHF) systems. For such applications, it is desired to operate waveguides with only one mode propagating through the waveguide. With rectangular waveguides, it is possible to design the waveguide such that the frequency band over which only one mode propagates is as high as 2:1 (i.e. the ratio of the upper band edge to lower band edge is two). The relation between the waveguide dimensions and the lowest frequency is simple: if formula_2 is the greater of its two dimensions, then the longest wavelength that will propagate is formula_3 and the lowest frequency is thus formula_4\n\nWith circular waveguides, the highest possible bandwidth allowing only a single mode to propagate is only 1.3601:1.\n\nBecause rectangular waveguides have a much larger bandwidth over which only a single mode can propagate, standards exist for rectangular waveguides, but not for circular waveguides. In general (but not always), standard waveguides are designed such that\n\nThe first condition is to allow for applications near band edges. The second condition limits dispersion, a phenomenon in which the velocity of propagation is a function of frequency. It also limits the loss per unit length. The third condition is to avoid evanescent-wave coupling via higher order modes. The fourth condition is that which allows a 2:1 operation bandwidth. Although it is possible to have a 2:1 operating bandwidth when the height is less than half the width, having the height exactly half the width maximizes the power that can propagate inside the waveguide before dielectric breakdown occurs.\n\nBelow is a table of standard waveguides. The waveguide name \"WR\" stands for \"waveguide rectangular\", and the number is the inner dimension width of the waveguide in hundredths of an inch (0.01 inch = 0.254 mm) rounded to the nearest hundredth of an inch.\n\nFor the frequencies in the table above, the main advantage of waveguides over coaxial cables is that waveguides support propagation with lower loss. For lower frequencies, the waveguide dimensions become impractically large, and for higher frequencies the dimensions become impractically small (the manufacturing tolerance becomes a significant portion of the waveguide size).\n\nDielectric rod and slab waveguides are used to conduct radio waves, mostly at millimeter wave frequencies and above. These confine the radio waves by total internal reflection from the step in refractive index due to the change in dielectric constant at the material surface. At millimeter wave frequencies and above, metal is not a good conductor, so metal waveguides can have increasing attenuation. At these wavelengths dielectric waveguides can have lower losses than metal waveguides. Optical fiber is a form of dielectric waveguide used at optical wavelengths.\n\nOne difference between dielectric and metal waveguides is that at a metal surface the electromagnetic waves are tightly confined; at high frequencies the electric and magnetic fields penetrate a very short distance into the metal. In contrast, the surface of the dielectric waveguide is an interface between two dielectrics, so the fields of the wave penetrate outside the dielectric in the form of an evanescent (non-propagating) wave.\n\n\"This article is based in part on material from Federal Standard 1037C and from MIL-STD-188, and ATIS\"\n\n\n\n"}
