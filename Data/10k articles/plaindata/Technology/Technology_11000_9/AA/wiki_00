{"id": "45476250", "url": "https://en.wikipedia.org/wiki?curid=45476250", "title": "1PN51-2", "text": "1PN51-2\n\n1PN51-2 () is the GRAU index for a Soviet designed passive night scope for the RPG-29 grenade launcher. \"1PN\" is the GRAU index of night vision devices, where PN stands for \"Nochnoy Pritsel\" () meaning night sight.\n\nThe scope weighs 2.1 kg and measures 280 mm × 192 mm × 106 mm (length × height × width). It is thus more compact than the similar multi-model 1PN51 night vision scope.\n\nIt is attached onto a matching side rail on the RPG after which a lever on the scope is pressed to hold it in place.\n\nIt comes in a metal container with room for extra batteries, battery charger and the other accessories, weighing 6.45 kg in total.\n\nThe scope gathers light via an 80 mm aperture into a reflector with the secondary mirror obscuring the central 42 mm of the aperture.\n\nThe top of the scope has two perpendicular knobs for zeroing the sight.\n\nThe aperture cover itself has two 12 mm apertures that can be opened partially allowing the scope to be used in light conditions that would otherwise saturate the light intensifier.\n\nThe rear end of the scope is a focus dial.\n\nThe eyepiece has a detachable soft rubber eyecup.\n\nThe scope has a magnification of 2.94.\n\nBelow the aperture the device has a brightness knob. Apart from powering on and off the device, this knob controls the brightness of the reticle allowing for the reticle to be visible without outshining the target.\n\nThe reticle has markings that match the height of a typical armoured vehicle at ranges 200 m, 300 m, 400 m and 500 m.\n\nThe light intensifier is powered by a pack of 5 D-0,55S () rechargeable cells, providing up to 7 V. The scope requires 6 V ± 1 V. The maximum current drawn is 40 mA.\n\nThe D-0,55S battery pack is used by a range of devices including 1PN51 and 1PN58 and has a separate charging device. The charging device has a switch to select one of 12 V or 27 V input and two red control lamps, one to indicate that power is available and one to indicate that charging is complete.\n"}
{"id": "44418367", "url": "https://en.wikipedia.org/wiki?curid=44418367", "title": "A3 problem solving", "text": "A3 problem solving\n\nA3 problem solving is a structured problem-solving and continuous-improvement approach, first employed at Toyota and typically used by lean manufacturing practitioners. It provides a simple and strict procedure that guides problem solving by workers. The approach typically uses a single sheet of ISO A3-size paper, which is the source of its name.\n\n"}
{"id": "813176", "url": "https://en.wikipedia.org/wiki?curid=813176", "title": "AI takeover", "text": "AI takeover\n\nAn AI takeover is a hypothetical scenario in which artificial intelligence (AI) becomes the dominant form of intelligence on Earth, with computers or robots effectively taking control of the planet away from the human species. Possible scenarios include replacement of the entire human workforce, takeover by a superintelligent AI, and the popular notion of a robot uprising. Some public figures, such as Stephen Hawking and Elon Musk, have advocated research into precautionary measures to ensure future superintelligent machines remain under human control. Robot rebellions have been a major theme throughout science fiction for many decades though the scenarios dealt with by science fiction are generally very different from those of concern to scientists.\n\nConcerns include AI taking over economies through workforce automation and taking over the world for its resources, eradicating the human race in the process. AI takeover is a major theme in sci-fi.\n\nThe traditional consensus among economists has been that technological progress does not cause long-term unemployment. However, recent innovation in the fields of robotics and artificial intelligence has raised worries that human labor will become obsolete, leaving people in various sectors without jobs to earn a living, leading to an economic crisis. Many small and medium size businesses may also be driven out of business if they won't be able to afford or licence the latest robotic and AI technology, and may need to focus on areas or services that cannot easily be replaced for continued viability in the face of such technology.\n\nComputer-integrated manufacturing is the manufacturing approach of using computers to control the entire production process. This integration allows individual processes to exchange information with each other and initiate actions. Although manufacturing can be faster and less error-prone by the integration of computers, the main advantage is the ability to create automated manufacturing processes. Computer-integrated manufacturing is used in automotive, aviation, space, and ship building industries.\n\nThe 21st century has seen a variety of skilled tasks partially taken over by machines, including translation, legal research and even low level journalism. Care work, entertainment, and other tasks requiring empathy, previously thought safe from automation, have also begun to be performed by robots.\n\nAn autonomous car is a vehicle that is capable of sensing its environment and navigating without human input. Many such vehicles are being developed, but as of May 2017 automated cars permitted on public roads are not yet fully autonomous. They all require a human driver at the wheel who is ready at a moment's notice to take control of the vehicle. Among the main obstacles to widespread adoption of autonomous vehicles, are concerns about the resulting loss of driving-related jobs in the road transport industry. On March 18, 2018, the first human was killed by an autonomous vehicle in Tempe, Arizona by an Uber self-driving car.\n\nIf a dominant superintelligent machine were to conclude that human survival is an unnecessary risk or a waste of resources, the result would be human extinction.\n\nWhile superhuman artificial intelligence is physically possible, scholars like Nick Bostrom debate how far off superhuman intelligence is, and whether it would actually pose a risk to mankind. A superintelligent machine would not necessarily be motivated by the same \"emotional\" desire to collect power that often drives human beings. However, a machine could be motivated to take over the world as a rational means toward attaining its ultimate goals; taking over the world would both increase its access to resources, and would help to prevent other agents from thwarting the machine's plans. As an oversimplified example, a paperclip maximizer designed solely to create as many paperclips as possible would want to take over the world so that it can use all of the world's resources to create as many paperclips as possible, and additionally so that it can prevent humans from shutting it down or using those resources on things other than paperclips.\n\nAI takeover is a common theme in science fiction. Fictional scenarios typically differ vastly from those hypothesized by researchers in that they involve an active conflict between humans and an AI or robots with anthropomorphic motives who see them as a threat or otherwise have active desire to fight humans, as opposed to the researchers' concern of an AI that rapidly exterminates humans as a byproduct of pursuing arbitrary goals. This theme is at least as old as Karel Čapek's \"R. U. R.\", which introduced the word \"robot\" to the global lexicon in 1921, and can even be glimpsed in Mary Shelley's \"Frankenstein\" (published in 1818), as Victor ponders whether, if he grants his monster's request and makes him a wife, they would reproduce and their kind would destroy humanity.\n\nThe word \"robot\" from R.U.R. comes from the Czech word, robota, meaning laborer or serf. The 1920 play was a protest against the rapid growth of technology, featuring manufactured \"robots\" with increasing capabilities who eventually revolt.\n\nSome examples of AI takeover in science fiction include:\n\n\nAn AI with the abilities of a competent artificial intelligence researcher, would be able to modify its own source code and increase its own intelligence. If its self-reprogramming leads to its getting even better at being able to reprogram itself, the result could be a recursive intelligence explosion where it would rapidly leave human intelligence far behind.\n\nA computer program that faithfully emulates a human brain, or that otherwise runs algorithms that are equally powerful as the human brain's algorithms, could still become a \"speed superintelligence\" if it can think many orders of magnitude faster than a human, due to being made of silicon rather than flesh, or due to optimization focusing on increasing the speed of the AGI. Biological neurons operate at about 200 Hz, whereas a modern microprocessor operates at a speed of about 2,000,000,000 Hz. Human axons carry action potentials at around 120 m/s, whereas computer signals travel near the speed of light.\n\nA network of human-level intelligences designed to network together and share complex thoughts and memories seamlessly, able to collectively work as a giant unified team without friction, or consisting of trillions of human-level intelligences, would become a \"collective superintelligence\".\n\nMore broadly, any number of qualitative improvements to a human-level AGI could result in a \"quality superintelligence\", perhaps resulting in an AGI as far above us in intelligence as humans are above non-human apes. The number of neurons in a human brain is limited by cranial volume and metabolic constraints; in contrast, you can add components to a supercomputer until it fills up its entire warehouse. An AGI need not be limited by human constraints on working memory, and might therefore be able to intuitively grasp more complex relationships than humans can. An AGI with specialized cognitive support for engineering or computer programming would have an advantage in these fields, compared with humans who evolved no specialized mental modules to specifically deal with those domains. Unlike humans, an AGI can spawn copies of itself and tinker with its copies' source code to attempt to further improve its algorithms.\n\nA significant problem is that unfriendly artificial intelligence is likely to be much easier to create than friendly AI. While both require large advances in recursive optimisation process design, friendly AI also requires the ability to make goal structures invariant under self-improvement (or the AI could transform itself into something unfriendly) and a goal structure that aligns with human values and does not automatically destroy the entire human race. An unfriendly AI, on the other hand, can optimize for an arbitrary goal structure, which does not need to be invariant under self-modification.\n\nThe sheer complexity of human value systems makes it very difficult to make AI's motivations human-friendly. Unless moral philosophy provides us with a flawless ethical theory, an AI's utility function could allow for many potentially harmful scenarios that conform with a given ethical framework but not \"common sense\". According to Eliezer Yudkowsky, there is little reason to suppose that an artificially designed mind would have such an adaptation.\n\nFor an AI takeover to be inevitable, it has to be postulated that two intelligent species cannot pursue mutually the goals of coexisting peacefully in an overlapping environment—especially if one is of much more advanced intelligence and much more powerful. While an AI takeover is thus a possible result of the invention of artificial intelligence, a peaceful outcome is not necessarily impossible.\n\nThe fear of cybernetic revolt is often based on interpretations of humanity's history, which is rife with incidents of enslavement and genocide. Such fears stem from a belief that competitiveness and aggression are necessary in any intelligent being's goal system. However, such human competitiveness stems from the evolutionary background to our intelligence, where the survival and reproduction of genes in the face of human and non-human competitors was the central goal. In fact, an arbitrary intelligence could have arbitrary goals: there is no particular reason that an artificially intelligent machine (not sharing humanity's evolutionary context) would be hostile—or friendly—unless its creator programs it to be such and it is not inclined or capable of modifying its programming. But the question remains: what would happen if AI systems could interact and evolve (evolution in this context means self-modification or selection and reproduction) and need to compete over resources, would that create goals of self-preservation? AI's goal of self-preservation could be in conflict with some goals of humans.\n\nSome scientists dispute the likelihood of cybernetic revolts as depicted in science fiction such as \"The Matrix\", claiming that it is more likely that any artificial intelligence powerful enough to threaten humanity would probably be programmed not to attack it. This would not, however, protect against the possibility of a revolt initiated by terrorists, or by accident. Artificial General Intelligence researcher Eliezer Yudkowsky has stated on this note that, probabilistically, humanity is less likely to be threatened by deliberately aggressive AIs than by AIs which were programmed such that their goals are unintentionally incompatible with human survival or well-being (as in the film \"I, Robot\" and in the short story \"The Evitable Conflict\"). Steve Omohundro suggests that present-day automation systems are not designed for safety and that AIs may blindly optimize narrow utility functions (say, playing chess at all costs), leading them to seek self-preservation and elimination of obstacles, including humans who might turn them off.\n\nAnother factor which may negate the likelihood of an AI takeover is the vast difference between humans and AIs in terms of the resources necessary for survival. Humans require a \"wet,\" organic, temperate, oxygen-laden environment while an AI might thrive essentially anywhere because their construction and energy needs would most likely be largely non-organic. With little or no competition for resources, conflict would perhaps be less likely no matter what sort of motivational architecture an artificial intelligence was given, especially provided with the superabundance of non-organic material resources in, for instance, the asteroid belt. This, however, does not negate the possibility of a disinterested or unsympathetic AI artificially decomposing all life on earth into mineral components for consumption or other purposes.\n\nOther scientists point to the possibility of humans upgrading their capabilities with bionics and/or genetic engineering and, as cyborgs, becoming the dominant species in themselves.\n\nIf a superhuman intelligence is a deliberate creation of human beings, theoretically its creators could have the foresight to take precautions in advance. In the case of a sudden \"intelligence explosion\", effective precautions will be extremely difficult; not only would its creators have little ability to test their precautions on an intermediate intelligence, but the creators might not even have made any precautions at all, if the advent of the intelligence explosion catches them completely by surprise.\n\nAn AGI's creators would have an important advantage in preventing a hostile AI takeover: they could choose to attempt to \"keep the AI in a box\", and deliberately limit its abilities. The tradeoff in boxing is that the creators presumably built the AGI for some concrete purpose; the more restrictions they place on the AGI, the less useful the AGI will be to its creators. (At an extreme, \"pulling the plug\" on the AGI makes it useless, and is therefore not a viable long-term solution.) A sufficiently strong superintelligence might find unexpected ways to escape the box, for example by social manipulation, or by providing the schematic for a device that ostensibly aids its creators but in reality brings about the AGI's freedom, once built.\n\nAnother important advantage is that an AGI's creators can theoretically attempt to instill human values in the AGI, or otherwise align the AGI's goals with their own, thus preventing the AGI from wanting to launch a hostile takeover. However, it is not currently known, even in theory, how to guarantee this. If such a Friendly AI were superintelligent, it may be possible to use its assistance to prevent future \"Unfriendly AIs\" from taking over.\n\nPhysicist Stephen Hawking, Microsoft founder Bill Gates and SpaceX founder Elon Musk have expressed concerns about the possibility that AI could develop to the point that humans could not control it, with Hawking theorizing that this could \"spell the end of the human race\". Stephen Hawking said in 2014 that \"Success in creating AI would be the biggest event in human history. Unfortunately, it might also be the last, unless we learn how to avoid the risks.\" Hawking believed that in the coming decades, AI could offer \"incalculable benefits and risks\" such as \"technology outsmarting financial markets, out-inventing human researchers, out-manipulating human leaders, and developing weapons we cannot even understand.\" In January 2015, Nick Bostrom joined Stephen Hawking, Max Tegmark, Elon Musk, Lord Martin Rees, Jaan Tallinn, and numerous AI researchers, in signing the Future of Life Institute's open letter speaking to the potential risks and benefits associated with artificial intelligence. The signatories \n\n\n"}
{"id": "23672379", "url": "https://en.wikipedia.org/wiki?curid=23672379", "title": "Agricultural machinery", "text": "Agricultural machinery\n\nAgricultural machinery is machinery used in farming or other agriculture. There are many types of such equipment, from hand tools and power tools to tractors and the countless kinds of farm implements that they tow or operate. Diverse arrays of equipment are used in both organic and nonorganic farming. Especially since the advent of mechanised agriculture, agricultural machinery is an indispensable part of how the world is fed.\n\nWith the coming of the Industrial Revolution and the development of more complicated machines, farming methods took a great leap forward. Instead of harvesting grain by hand with a sharp blade, wheeled machines cut a continuous swath. Instead of threshing the grain by beating it with sticks, threshing machines separated the seeds from the heads and stalks. The first tractors appeared in the late 19th century.\n\nPower for agricultural machinery was originally supplied by ox or other domesticated animals. With the invention of steam power came the portable engine, and later the traction engine, a multipurpose, mobile energy source that was the ground-crawling cousin to the steam locomotive. Agricultural steam engines took over the heavy pulling work of oxen, and were also equipped with a pulley that could power stationary machines via the use of a long belt. The steam-powered machines were low-powered by today's standards but, because of their size and their low gear ratios, they could provide a large drawbar pull. Their slow speed led farmers to comment that tractors had two speeds: \"slow, and damn slow.\"\n\nThe internal combustion engine; first the petrol engine, and later diesel engines; became the main source of power for the next generation of tractors. These engines also contributed to the development of the self-propelled, combined harvester and thresher, or combine harvester (also shortened to 'combine'). Instead of cutting the grain stalks and transporting them to a stationary threshing machine, these combines cut, threshed, and separated the grain while moving continuously through the field.\n\nCombines might have taken the harvesting job away from tractors, but tractors still do the majority of work on a modern farm. They are used to push/pull implements—machines that till the ground, plant seed, and perform other tasks.\n\nTillage implements prepare the soil for planting by loosening the soil and killing weeds or competing plants. The best-known is the plow, the ancient implement that was upgraded in 1838 by John Deere. Plows are now used less frequently in the U.S. than formerly, with offset disks used instead to turn over the soil, and chisels used to gain the depth needed to retain moisture.\n\nThe most common type of seeder is called a planter, and spaces seeds out equally in long rows, which are usually two to three feet apart. Some crops are planted by drills, which put out much more seed in rows less than a foot apart, blanketing the field with crops. Transplanters automate the task of transplanting seedlings to the field. With the widespread use of plastic mulch, plastic mulch layers, transplanters, and seeders lay down long rows of plastic, and plant through them automatically.\n\nAfter planting, other implements can be used to cultivate weeds from between rows, or to spread fertilizer and pesticides. Hay balers can be used to tightly package grass or alfalfa into a storable form for the winter months.\n\nModern irrigation relies on machinery. Engines, pumps and other specialized gear provide water quickly and in high volumes to large areas of land. Similar types of equipment can be used to deliver fertilizers and pesticides.\n\nBesides the tractor, other vehicles have been adapted for use in farming, including trucks, s, and helicopters, such as for transporting crops and making equipment mobile, to aerial spraying and livestock herd management.\n\nThe basic technology of agricultural machines has changed little in the last century. Though modern harvesters and planters may do a better job or be slightly tweaked from their predecessors, the US$250,000 combine of today still cuts, threshes, and separates grain in the same way it has always been done. However, technology is changing the way that humans operate the machines, as computer monitoring systems, GPS locators, and self-steer programs allow the most advanced tractors and implements to be more precise and less wasteful in the use of fuel, seed, or fertilizer. In the foreseeable future, there may be mass production of driverless tractors, which use GPS maps and electronic sensors. \n\nMany farmers are upset by their inability to fix the new types of high-tech farm equipment. This is due mostly to companies using intellectual property law to prevent farmers from having the legal right to fix their equipment (or gain access to the information to allow them to do it). In October 2015 an exemption was added to the DMCA to allow inspection and modification of the software in cars and other vehicles including agricultural machinery.\n\n\n\n"}
{"id": "55178112", "url": "https://en.wikipedia.org/wiki?curid=55178112", "title": "Angle bracket (fastener)", "text": "Angle bracket (fastener)\n\nAn angle bracket or angle brace or Angle Cleat is an L-shaped fastener used to join two parts generally at a 90 degree angle. It is typically made of metal but it can also be made of wood or plastic. The metallic angle brackets feature holes in them for screws. Its typical use is to join a wooden shelf to a wall or to join two furniture parts together.\n\nRetailers also use names like corner brace, corner bracket brace, shelf bracket, or L bracket.\n\nWhen the holes are enlarged for allowing adjustments, the name is angle stretcher plates or angle shrinkage.\n\nThere are different sizes are available , varying in Length , Width & angle.\n\n"}
{"id": "31321967", "url": "https://en.wikipedia.org/wiki?curid=31321967", "title": "Anodic bonding", "text": "Anodic bonding\n\nAnodic bonding is a wafer bonding process to seal glass to either silicon or metal without introducing an intermediate layer; it is commonly used to seal glass to silicon wafers in electronics and microfluidics. This bonding technique, also known as field assisted bonding or electrostatic sealing, is mostly used for connecting silicon/glass and metal/glass through electric fields. The requirements for anodic bonding are clean and even wafer surfaces and atomic contact between the bonding substrates through a sufficiently powerful electrostatic field. Also necessary is the use of borosilicate glass containing a high concentration of alkali ions. The coefficient of thermal expansion (CTE) of the processed glass needs to be similar to those of the bonding partner.\n\nAnodic bonding can be applied with glass wafers at temperatures of 250 to 400 °C or with sputtered glass at 400 °C. Structured borosilicate glass layers may also be deposited by plasma-assisted e-beam evaporation.\n\nThis procedure is mostly used for hermetic encapsulation of micro-mechanical silicon elements. The glass substrate encapsulation protects from environmental influences, e.g. humidity or contamination. Further, other materials are used for anodic bonding with silicon, i.e. low-temperature cofired ceramics (LTCC).\n\nAnodic bonding on silicon substrates is divided into bonding using a thin sheet of glass (a wafer) or a glass layer that is deposited onto the silicon using a technique such as sputtering. The glass wafer is often sodium-containing Borofloat or Pyrex glasses. With an intermediate glass layer, it is also possible to connect two silicon wafers. The glass layers are deposited by sputtering, spin-on of a glass solution or vapor deposition upon the processed silicon wafer. The thickness of these layers range from one to a few micrometers with spin-on glass layers needing 1 µm or less. Hermetic seals of silicon to glass using an aluminum layer with thickness of 50 to 100 nm can reach strengths of 18.0 MPa. This method enables burying electrically isolated conductors in the interface. Bonding of thermally oxidized wafers without a glass layer is also possible.\n\nThe procedural steps of anodic bonding are divided into the following:\n\n\nwith a process characterized by the following variables:\n\n\nThe typical bond strength is between 10 and 20 MPa according to pull tests, higher than the fracture strength of glass.\n\nDiffering coefficients of thermal expansion pose challenges for anodic bonding. Excessive mismatch can harm the bond through intrinsic material tensions and cause disruptions in the bonding materials. The use of sodium-containing glasses, e.g. Borofloat or Pyrex, serve to reduce the mismatch. These glasses have a similar CTE to silicon in the range of applied temperature, commonly up to 400 °C.\n\nAnodic bonding is first mentioned by Wallis and Pomerantz in 1969. It is applied as bonding of silicon wafers to sodium containing glass wafers under the influence of an applied electric field. This method is used up to date as encapsulation of sensors with electrically conducted glasses.\n\nThe anodic bonding procedure is able to bond hydrophilic and hydrophobic silicon surfaces equally effectively. The roughness of the surface should be less than 10 nm and free of contamination on the surface for the procedure to work properly. Even though anodic bonding is relatively tolerant to contaminations, a widely established cleaning procedure RCA takes place to remove any surface impurities.\n\nThe glass wafer can also be chemically etched or powder blasted for creating small cavities, where MEMS devices can be accommodated.\n\nFurther mechanisms supporting the bonding process of not completely inert anodic materials can be the planarization or polishing of surfaces and the ablation of the surface layer by electrochemical etching.\n\nThe wafers that meet the requirements are put into atomic contact. As soon as contact is first established, the bonding process starts close to the cathode and spreads in fronts to the edges, the process taking several minutes.\nThe anodic bonding procedure is based on a glass wafer that is usually placed above a silicon wafer. An electrode is in contact with the glass wafer either through a needle or a full area cathode electrode.\n\nIf using a needle electrode, the bond spreads radially to the outside which makes it impossible to trap air between the surfaces. The radius of the bonded area is approximately proportional to the square root of time elapsed during the procedure. Below temperatures of 350 to 400 °C and a bond voltage of 500 to 1000 V, this method is not very effective nor reliable.\n\nThe use of a full area cathode electrode shows bond reactions over the whole interface after powering up the potential. This is the result of a homogeneous electric field distribution at temperatures of around 300 °C and bond voltage of 250 V. Using thin deposited glass layers the voltages needed can be significantly reduced.\n\nThe wafers are placed between the chuck and the top tool used as bond electrode at temperatures between 200 and 500 °C (compare to image \"scheme of anodic bonding procedure\") but below the softening point of glass (glass transition temperature). The higher the temperature the better is the mobility of positive ions in glass.\n\nThe applied electrical potential between is set to a voltage of several 100 V. This causes a diffusion of sodium ions (Na) out of the bond interface to the backside of the glass to the cathode. That results, combined with humidity in formation of NaOH. High voltage helps to support the drifting of the positive ions in glass to the cathode. The diffusion is according to the Boltzmann distribution exponentially related to the temperature. The glass (NaO) with its remaining oxygen ions (O) is negatively volume charged at the bonding surface compared to the silicon (compare to figure \"ion drifting in bond glass\" (1)). This is based on the depletion of Na ions.\n\nSilicon is unlike, e.g. aluminium, an inert anode. In result no ions drift out of the silicon into the glass during the bond process. This affects a positive volume charge in the silicon wafer on the opposite side. As a result a few micrometer thick high-impedance depletion region is developed at the bond barrier in the glass wafer. In the gap between silicon and glass the bond voltage drops. The bond process as a combination of electrostatic and electrochemical process starts.\n\nThe electrical field intensity in the depletion region is so high that the oxygen ions drift to the bond interface and pass out to react with the silicon to form SiO (compare to figure \"ion drifting in bond glass\" (2)). Based on the high field intensity in the depletion region or in the gap at the interface, both wafer surfaces are pressed together at a specific bond voltage and bond temperature. The process is realized at temperatures from 200 - 500 °C for about 5 to 20 min. Typically, the bonding or sealing time becomes longer when temperature and voltage are reduced. The pressure is applied to create intimate contact between the surfaces to ensure good electrical conduction across the wafer pair. This ensures intimate contact for the surfaces of the bonding partners. The thin formed oxide layer between the bond surfaces, siloxane (Si-O-Si), ensures the irreversible connection between the bonding partners.\n\nIf using thermally oxidized wafers without a glass layer, the diffusion of OH and H ions instead of Na ions leads to the bonding.\n\nAfter the bonding process, slow cooling over several minutes has to take place. This can be supported by purging with an inert gas. The cooling time depends on the difference of CTE for the bonded materials: the higher the CTE difference, the longer the cooling period.\n"}
{"id": "856", "url": "https://en.wikipedia.org/wiki?curid=856", "title": "Apple Inc.", "text": "Apple Inc.\n\nApple Inc. is an American multinational technology company headquartered in Cupertino, California, that designs, develops, and sells consumer electronics, computer software, and online services. The company's hardware products include the iPhone smartphone, the iPad tablet computer, the Mac personal computer, the iPod portable media player, the Apple Watch smartwatch, the Apple TV digital media player, and the HomePod smart speaker. Apple's software includes the macOS and iOS operating systems, the iTunes media player, the Safari web browser, and the iLife and iWork creativity and productivity suites, as well as professional applications like Final Cut Pro, Logic Pro, and Xcode. Its online services include the iTunes Store, the iOS App Store and Mac App Store, Apple Music, and iCloud.\n\nApple was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne in April 1976 to develop and sell Wozniak's Apple I personal computer. It was incorporated as Apple Computer, Inc., in January 1977, and sales of its computers, including the Apple II, grew quickly. Within a few years, Jobs and Wozniak had hired a staff of computer designers and had a production line. Apple went public in 1980 to instant financial success. Over the next few years, Apple shipped new computers featuring innovative graphical user interfaces, such as the original Macintosh in 1984, and Apple's marketing commercials for its products received widespread critical acclaim. However, the high price tag of its products and limited software titles caused problems, as did power struggles between executives at the company. In 1985, Wozniak stepped away from Apple, while Jobs resigned and founded a new company—NeXT—with former Apple employees.\n\nAs the market for personal computers increased, Apple's computers lost share to lower-priced products, particularly ones that ran the Microsoft Windows operating system. After more executive job shuffles, CEO Gil Amelio in 1997 bought NeXT to bring Jobs back. Jobs regained leadership within the company and became the new CEO shortly after. He began to rebuild Apple's status, opening Apple's own retail stores in 2001, acquiring numerous companies to create a portfolio of software titles, and changing some of the hardware used in its computers. The company returned to profitability. In January 2007, Jobs renamed the company Apple Inc., reflecting its shifted focus toward consumer electronics, and announced the iPhone, which saw critical acclaim and significant financial success. In August 2011, Jobs resigned as CEO due to health complications, and Tim Cook became the new CEO. Two months later, Jobs died, marking the end of an era for the company. \n\nApple is well known for its size and revenues. Its worldwide annual revenue totaled $265billion for the 2018 fiscal year. Apple is the world's largest information technology company by revenue and the world's third-largest mobile phone manufacturer after Samsung and Huawei. In August 2018, Apple became the first public U.S. company to be valued at over US$1 trillion. The company employs 123,000 full-time employees and maintains 504 retail stores in 24 countries . It operates the iTunes Store, which is the world's largest music retailer. , more than 1.3 billion Apple products are actively in use worldwide. \n\nThe company also has a high level of brand loyalty and is ranked as the world's most valuable brand. However, Apple receives significant criticism regarding the labor practices of its contractors, its environmental practices and unethical business practices, including anti-competitive behavior, as well as the origins of source materials.\n\nApple Computer Company was founded on April 1, 1976, by Steve Jobs, Steve Wozniak and Ronald Wayne. The company's first product was the Apple I, a computer single-handedly designed and hand-built by Wozniak, and first shown to the public at the Homebrew Computer Club. Apple I was sold as a motherboard (with CPU, RAM, and basic textual-video chips), which was less than what is now considered a complete personal computer. The Apple I went on sale in July 1976 and was market-priced at $666.66 ($ in dollars, adjusted for inflation).\n\nApple Computer, Inc. was incorporated on January 3, 1977, without Wayne, who left and sold his share of the company back to Jobs and Wozniak for $800 only a couple weeks after co-founding Apple. Multimillionaire Mike Markkula provided essential business expertise and funding of $250,000 during the incorporation of Apple. During the first five years of operations revenues grew exponentially, doubling about every four months. Between September 1977 and September 1980, yearly sales grew from $775,000 to $118million, an average annual growth rate of 533%.\n\nThe Apple II, also invented by Wozniak, was introduced on April 16, 1977, at the first West Coast Computer Faire. It differed from its major rivals, the TRS-80 and Commodore PET, because of its character cell-based color graphics and open architecture. While early Apple II models used ordinary cassette tapes as storage devices, they were superseded by the introduction of a -inch floppy disk drive and interface called the Disk II. The Apple II was chosen to be the desktop platform for the first \"killer app\" of the business world: VisiCalc, a spreadsheet program. VisiCalc created a business market for the Apple II and gave home users an additional reason to buy an Apple II: compatibility with the office. Before VisiCalc, Apple had been a distant third place competitor to Commodore and Tandy.\n\nBy the end of the 1970s, Apple had a staff of computer designers and a production line. The company introduced the Apple III in May 1980 in an attempt to compete with IBM and Microsoft in the business and corporate computing market. Jobs and several Apple employees, including human–computer interface expert Jef Raskin, visited Xerox PARC in December 1979 to see the Xerox Alto. Xerox granted Apple engineers three days of access to the PARC facilities in return for the option to buy 100,000 shares (800,000 split-adjusted shares) of Apple at the pre-IPO price of $10 a share.\n\nJobs was immediately convinced that all future computers would use a graphical user interface (GUI), and development of a GUI began for the Apple Lisa. In 1982, however, he was pushed from the Lisa team due to infighting. Jobs then took over Wozniak and Raskin's low-cost-computer project, the Macintosh. A race broke out between the Lisa team and the Macintosh team over which product would ship first. Lisa won the race in 1983 and became the first personal computer sold to the public with a GUI, but was a commercial failure due to its high price tag and limited software titles.\n\nOn December 12, 1980, Apple went public at $22 per share, generating more capital than any IPO since Ford Motor Company in 1956, and immediately creating 300millionaires.\n\nIn 1984, Apple launched the Macintosh, the first personal computer to be sold without a programming language. Its debut was signified by \"1984\", a $1.5million television commercial directed by Ridley Scott that aired during the third quarter of Super Bowl XVIII on January 22, 1984. The commercial is now hailed as a watershed event for Apple's success and was called a \"masterpiece\" by CNN and one of the greatest commercials of all time by \"TV Guide\".\n\nThe Macintosh initially sold well, but follow-up sales were not strong due to its high price and limited range of software titles. The machine's fortunes changed with the introduction of the LaserWriter, the first PostScript laser printer to be sold at a reasonable price, and PageMaker, an early desktop publishing package. It has been suggested that the combination of these three products were responsible for the creation of the desktop publishing market. The Macintosh was particularly powerful in the desktop publishing market due to its advanced graphics capabilities, which had necessarily been built in to create the intuitive Macintosh GUI.\n\nIn 1985, a power struggle developed between Jobs and CEO John Sculley, who had been hired two years earlier. The Apple board of directors instructed Sculley to \"contain\" Jobs and limit his ability to launch expensive forays into untested products. Rather than submit to Sculley's direction, Jobs attempted to oust him from his leadership role at Apple. Sculley found out that Jobs had been attempting to organize a coup and called a board meeting at which Apple's board of directors sided with Sculley and removed Jobs from his managerial duties. Jobs resigned from Apple and founded NeXT Inc. the same year. Wozniak also left Apple in 1985 to pursue other ventures, stating that the company had \"been going in the wrong direction for the last five years\".\nAfter Jobs' and Wozniak's departure, the Macintosh product line underwent a steady change of focus to higher price points, the so-called \"high-right policy\" named for the position on a chart of price vs. profits. Jobs had argued the company should produce products aimed at the consumer market and aimed for a $1000 price for the Macintosh, which they were unable to meet. Newer models selling at higher price points offered higher profit margin, and appeared to have no effect on total sales as power users snapped up every increase in power. Although some worried about pricing themselves out of the market, the high-right policy was in full force by the mid-1980s, notably due to Jean-Louis Gassée's mantra of \"fifty-five or die\", referring to the 55% profit margins of the Macintosh II.\n\nThis policy began to backfire in the last years of the decade as new desktop publishing programs appeared on PC clones that offered some or much of the same functionality of the Macintosh but at far lower price points. The company lost its monopoly in this market and had already estranged many of its original consumer customer base who could no longer afford their high-priced products. The Christmas season of 1989 was the first in the company's history that saw declining sales, and led to a 20% drop in Apple's stock price. Gassée's objections were overruled, and he was forced from the company in 1990. Later that year, Apple introduced three lower cost models, the Macintosh Classic, Macintosh LC and Macintosh IIsi, all of which saw significant sales due to pent-up demand.\n\nIn 1991, Apple introduced the PowerBook, replacing the \"luggable\" Macintosh Portable with a design that set the current shape for almost all modern laptops. The same year, Apple introduced System 7, a major upgrade to the operating system which added color to the interface and introduced new networking capabilities. It remained the architectural basis for the Classic Mac OS. The success of the PowerBook and other products brought increasing revenue. For some time, Apple was doing incredibly well, introducing fresh new products and generating increasing profits in the process. The magazine \"MacAddict\" named the period between 1989 and 1991 as the \"first golden age\" of the Macintosh.\n\nApple believed the Apple II series was too expensive to produce and took away sales from the low-end Macintosh. In the 1990s, Apple released the Macintosh LC, and began efforts to promote that computer by advising developer technical support staff to recommend developing applications for Macintosh rather than Apple II, and authorizing salespersons to direct consumers towards Macintosh and away from Apple II. The Apple IIe was discontinued in 1993.\n\nThe success of Apple's lower-cost consumer models, especially the LC, also led to cannibalization of their higher priced machines. To address this, management introduced several new brands, selling largely identical machines at different price points aimed at different markets. These were the high-end Quadra, the mid-range Centris line, and the ill-fated Performa series. This led to significant market confusion, as customers did not understand the difference between models.\n\nApple also experimented with a number of other unsuccessful consumer targeted products during the 1990s, including digital cameras, portable CD audio players, speakers, video consoles, the eWorld online service, and TV appliances. Enormous resources were also invested in the problem-plagued Newton division based on John Sculley's unrealistic market forecasts. Ultimately, none of these products helped and Apple's market share and stock prices continued to slide.\n\nThroughout this period, Microsoft continued to gain market share with Windows by focusing on delivering software to cheap commodity personal computers, while Apple was delivering a richly engineered but expensive experience. Apple relied on high profit margins and never developed a clear response; instead, they sued Microsoft for using a GUI similar to the Apple Lisa in \"Apple Computer, Inc. v. Microsoft Corp.\" The lawsuit dragged on for years before it was finally dismissed. At this time, a series of major product flops and missed deadlines sullied Apple's reputation, and Sculley was replaced as CEO by Michael Spindler.\n\nBy the early 1990s, Apple was developing alternative platforms to the Macintosh, such as A/UX. The Macintosh platform itself was becoming outdated because it was not built for multitasking and because several important software routines were programmed directly into the hardware. In addition, Apple was facing competition from OS/2 and UNIX vendors such as Sun Microsystems. The Macintosh would need to be replaced by a new platform or reworked to run on more powerful hardware.\n\nIn 1994, Apple allied with IBM and Motorola in the AIM alliance with the goal of creating a new computing platform (the PowerPC Reference Platform), which would use IBM and Motorola hardware coupled with Apple software. The AIM alliance hoped that PReP's performance and Apple's software would leave the PC far behind and thus counter Microsoft. The same year, Apple introduced the Power Macintosh, the first of many Apple computers to use Motorola's PowerPC processor.\n\nIn 1996, Spindler was replaced by Gil Amelio as CEO. Amelio made numerous changes at Apple, including extensive layoffs and cut costs. After numerous failed attempts to improve Mac OS, first with the Taligent project and later with Copland and Gershwin, Amelio chose to purchase NeXT and its NeXTSTEP operating system and bring Steve Jobs back to Apple.\n\nAt the 1997 Macworld Expo, Jobs announced that Apple would join Microsoft to release new versions of Microsoft Office for the Macintosh, and that Microsoft had made a $150million investment in non-voting Apple stock. On November 10, 1997, Apple introduced the Apple Online Store, which was tied to a new build-to-order manufacturing strategy.\n\nThe NeXT deal was finalized on February 9, 1997, bringing Jobs back to Apple as an advisor. On July 9, 1997, Amelio was ousted by the board of directors after overseeing a three-year record-low stock price and crippling financial losses. Jobs acted as the interim CEO and began restructuring the company's product line; it was during this period that he identified the design talent of Jonathan Ive, and the pair worked collaboratively to rebuild Apple's status.\n\nOn August 15, 1998, Apple introduced a new all-in-one computer reminiscent of the Macintosh 128K: the iMac. The iMac design team was led by Ive, who would later design the iPod and the iPhone. The iMac featured modern technology and a unique design, and sold almost 800,000 units in its first five months.\n\nDuring this period, Apple completed numerous acquisitions to create a portfolio of digital production software for both professionals and consumers. In 1998, Apple purchased Macromedia's Key Grip software project, signaling an expansion into the digital video editing market. The sale was an outcome of Macromedia's decision to solely focus upon web development software. The product, still unfinished at the time of the sale, was renamed \"Final Cut Pro\" when it was launched on the retail market in April 1999. The development of Key Grip also led to Apple's release of the consumer video-editing product iMovie in October 1999. Next, Apple successfully acquired the German company Astarte, which had developed DVD authoring technology, as well as Astarte's corresponding products and engineering team in April 2000. Astarte's digital tool DVDirector was subsequently transformed into the professional-oriented DVD Studio Pro software product. Apple then employed the same technology to create iDVD for the consumer market. In July 2001, Apple acquired Spruce Technologies, a PC DVD authoring platform, to incorporate their technology into Apple's expanding portfolio of digital video projects.\n\nIn 2002, Apple purchased Nothing Real for their advanced digital compositing application Shake, as well as Emagic for the music productivity application Logic. The purchase of Emagic made Apple the first computer manufacturer to own a music software company. The acquisition was followed by the development of Apple's consumer-level GarageBand application. The release of iPhoto in the same year completed the iLife suite.\n\nMac OS X, based on NeXT's OPENSTEP and BSD Unix, was released on March 24, 2001, after several years of development. Aimed at consumers and professionals alike, Mac OS X aimed to combine the stability, reliability, and security of Unix with the ease of use afforded by an overhauled user interface. To aid users in migrating from Mac OS 9, the new operating system allowed the use of OS 9 applications within Mac OS X via the Classic Environment.\n\nOn May 19, 2001, Apple opened its first official eponymous retail stores in Virginia and California. On October 23 of the same year, Apple debuted the iPod portable digital audio player. The product, which was first sold on November 10, 2001, was phenomenally successful with over 100million units sold within six years. In 2003, Apple's iTunes Store was introduced. The service offered online music downloads for $0.99 a song and integration with the iPod. The iTunes Store quickly became the market leader in online music services, with over five billion downloads by June 19, 2008. Two years later, the iTunes Store was the world's largest music retailer.\n\nAt the Worldwide Developers Conference keynote address on June 6, 2005, Jobs announced that Apple would begin producing Intel-based Mac computers in 2006. On January 10, 2006, the new MacBook Pro and iMac became the first Apple computers to use Intel's Core Duo CPU. By August 7, 2006, Apple made the transition to Intel chips for the entire Mac product line—over one year sooner than announced. The Power Mac, iBook and PowerBook brands were retired during the transition; the Mac Pro, MacBook, and MacBook Pro became their respective successors. On April 29, 2009, \"The Wall Street Journal\" reported that Apple was building its own team of engineers to design microchips. Apple also introduced Boot Camp in 2006 to help users install Windows XP or Windows Vista on their Intel Macs alongside Mac OS X.\n\nApple's success during this period was evident in its stock price. Between early 2003 and 2006, the price of Apple's stock increased more than tenfold, from around $6 per share (split-adjusted) to over $80. In January 2006, Apple's market cap surpassed that of Dell. Nine years prior, Dell's CEO Michael Dell had said that if he ran Apple he would \"shut it down and give the money back to the shareholders.\" Although Apple's market share in computers had grown, it remained far behind its competitor Microsoft Windows, accounting for about 8% of desktops and laptops in the US.\n\nSince 2001, Apple's design team has progressively abandoned the use of translucent colored plastics first used in the iMac G3. This design change began with the titanium-made PowerBook and was followed by the iBook's white polycarbonate structure and the flat-panel iMac.\n\nDuring his keynote speech at the Macworld Expo on January 9, 2007, Jobs announced that Apple Computer, Inc. would thereafter be known as \"Apple Inc.\", because the company had shifted its emphasis from computers to consumer electronics. This event also saw the announcement of the iPhone and the Apple TV. The company sold 270,000 iPhone units during the first 30 hours of sales, and the device was called \"a game changer for the industry\". Apple would achieve widespread success with its iPhone, iPod Touch and iPad products, which introduced innovations in mobile phones, portable music players and personal computers respectively. Furthermore, by early 2007, 800,000 Final Cut Pro users were registered.\n\nIn an article posted on Apple's website on February 6, 2007, Jobs wrote that Apple would be willing to sell music on the iTunes Store without digital rights management (DRM), thereby allowing tracks to be played on third-party players, if record labels would agree to drop the technology. On April 2, 2007, Apple and EMI jointly announced the removal of DRM technology from EMI's catalog in the iTunes Store, effective in May 2007. Other record labels eventually followed suit and Apple published a press release in January 2009 to announce the corresponding changes to the iTunes Store.\n\nIn July 2008, Apple launched the App Store to sell third-party applications for the iPhone and iPod Touch. Within a month, the store sold 60million applications and registered an average daily revenue of $1million, with Jobs speculating in August 2008 that the App Store could become a billion-dollar business for Apple. By October 2008, Apple was the third-largest mobile handset supplier in the world due to the popularity of the iPhone.\n\nOn December 16, 2008, Apple announced that 2009 would be the last year the corporation would attend the Macworld Expo, after more than 20 years of attendance, and that senior vice president of Worldwide Product Marketing Phil Schiller would deliver the 2009 keynote address in lieu of the expected Jobs. The official press release explained that Apple was \"scaling back\" on trade shows in general, including Macworld Tokyo and the Apple Expo in Paris, France, primarily because the enormous successes of the Apple Retail Stores and website had rendered trade shows a minor promotional channel.\n\nOn January 14, 2009, Jobs announced in an internal memo that he would be taking a six-month medical leave of absence from Apple until the end of June 2009 and would spend the time focusing on his health. In the email, Jobs stated that \"the curiosity over my personal health continues to be a distraction not only for me and my family, but everyone else at Apple as well\", and explained that the break would allow the company \"to focus on delivering extraordinary products\". Despite Jobs's absence, Apple recorded its best non-holiday quarter (Q1 FY 2009) during the recession with revenue of $8.16billion and profit of $1.21billion.\nAfter years of speculation and multiple rumored \"leaks\", Apple unveiled a large screen, tablet-like media device known as the iPad on January 27, 2010. The iPad ran the same touch-based operating system as the iPhone, and many iPhone apps were compatible with the iPad. This gave the iPad a large app catalog on launch, despite very little development time before the release. Later that year on April 3, 2010, the iPad was launched in the US. It sold more than 300,000 units on its first day, and 500,000 by the end of the first week. In May of the same year, Apple's market cap exceeded that of competitor Microsoft for the first time since 1989.\n\nIn June 2010, Apple released the iPhone 4, which introduced video calling, multitasking, and a new uninsulated stainless steel design that acted as the phone's antenna. Later that year, Apple again refreshed its iPod line of MP3 players by introducing a multi-touch iPod Nano, an iPod Touch with FaceTime, and an iPod Shuffle that brought back the buttons of earlier generations. Additionally, on October 20, Apple updated the MacBook Air laptop, iLife suite of applications, and unveiled Mac OS X Lion, the last version with the name Mac OS X.\n\nIn October 2010, Apple shares hit an all-time high, eclipsing $300.\n\nOn January 6, 2011, the company opened its Mac App Store, a digital software distribution platform similar to the iOS App Store.\n\nAlongside peer entities such as Atari and Cisco Systems, Apple was featured in the documentary \"Something Ventured\", which premiered in 2011 and explored the three-decade era that led to the establishment and dominance of Silicon Valley.\n\nOn January 17, 2011, Jobs announced in an internal Apple memo that he would take another medical leave of absence for an indefinite period to allow him to focus on his health. Chief Operating Officer Tim Cook assumed Jobs's day-to-day operations at Apple, although Jobs would still remain \"involved in major strategic decisions\". Apple became the most valuable consumer-facing brand in the world. In June 2011, Jobs surprisingly took the stage and unveiled iCloud, an online storage and syncing service for music, photos, files and software which replaced MobileMe, Apple's previous attempt at content syncing.\n\nThis would be the last product launch Jobs would attend before his death. It has been argued that Apple has achieved such efficiency in its supply chain that the company operates as a monopsony (one buyer, many sellers) and can dictate terms to its suppliers. In July 2011, due to the American debt-ceiling crisis, Apple's financial reserves were briefly larger than those of the U.S. Government.\n\nOn August 24, 2011, Jobs resigned his position as CEO of Apple. He was replaced by Cook and Jobs became Apple's chairman. Prior to this, Apple did not have a chairman and instead had two co-lead directors, Andrea Jung and Arthur D. Levinson, who continued with those titles until Levinson became chairman of the board in November.\n\nOn October 5, 2011, Steve Jobs died, marking the end of an era for Apple. The first major product announcement by Apple following Jobs's passing occurred on January 19, 2012, when Apple's Phil Schiller introduced iBooks Textbooks for iOS and iBook Author for Mac OS X in New York City. Jobs had stated in his biography that he wanted to reinvent the textbook industry and education.\n\nFrom 2011 to 2012, Apple released the iPhone 4S and iPhone 5, which featured improved cameras, an intelligent software assistant named Siri, and cloud-sourced data with iCloud; the third and fourth generation iPads, which featured Retina displays; and the iPad Mini, which featured a 7.9-inch screen in contrast to the iPad's 9.7-inch screen. These launches were successful, with the iPhone 5 (released September 21, 2012) becoming Apple's biggest iPhone launch with over two million pre-orders and sales of three million iPads in three days following the launch of the iPad Mini and fourth generation iPad (released November 3, 2012). Apple also released a third-generation 13-inch MacBook Pro with a Retina display and new iMac and Mac Mini computers.\n\nOn August 20, 2012, Apple's rising stock price increased the company's market capitalization to a world-record $624billion. This beat the non-inflation-adjusted record for market capitalization set by Microsoft in 1999. On August 24, 2012, a US jury ruled that Samsung should pay Apple $1.05billion (£665m) in damages in an intellectual property lawsuit. Samsung appealed the damages award, which the Court reduced by $450million. The Court further granted Samsung's request for a new trial. On November 10, 2012, Apple confirmed a global settlement that would dismiss all lawsuits between Apple and HTC up to that date, in favor of a ten-year license agreement for current and future patents between the two companies. It is predicted that Apple will make $280million a year from this deal with HTC.\n\nA previously confidential email written by Jobs a year before his death was presented during the proceedings of the \"Apple Inc. v. Samsung Electronics Co.\" lawsuits and became publicly available in early April 2014. With a subject line that reads \"Top 100 – A,\" the email was sent only to the company's 100 most senior employees and outlines Jobs's vision of Apple Inc.'s future under 10 subheadings. Notably, Jobs declares a \"Holy War with Google\" for 2011 and schedules a \"new campus\" for 2015.\n\nIn March 2013, Apple filed a patent for an augmented reality (AR) system that can identify objects in a live video stream and present information corresponding to these objects through a computer-generated information layer overlaid on top of the real-world image. The company also made several high-profile hiring decisions in 2013. On July 2, 2013, Apple recruited Paul Deneve, Belgian President and CEO of Yves Saint Laurent as a vice president reporting directly to Tim Cook. A mid-October 2013 announcement revealed that Burberry executive Angela Ahrendts will commence as a senior vice president at Apple in mid-2014. Ahrendts oversaw Burberry's digital strategy for almost eight years and, during her tenure, sales increased to about US$3.2 billion and shares gained more than threefold.\n\nAlongside Google vice-president Vint Cerf and AT&T CEO Randall Stephenson, Cook attended a closed-door summit held by President Obama on August 8, 2013, in regard to government surveillance and the Internet in the wake of the Edward Snowden NSA incident. On February 4, 2014, Cook met with Abdullah Gül, the President of Turkey, in Ankara to discuss the company's involvement in the Fatih project.\n\nIn the first quarter of 2014, Apple reported sales of 51million iPhones and 26million iPads, becoming all-time quarterly sales records. It also experienced a significant year-over-year increase in Mac sales. This was contrasted with a significant drop in iPod sales. In May 2014, the company confirmed its intent to acquire Dr. Dre and Jimmy Iovine's audio company Beats Electronics—producer of the \"Beats by Dr. Dre\" line of headphones and speaker products, and operator of the music streaming service Beats Music—for $3billion, and to sell their products through Apple's retail outlets and resellers. Iovine felt that Beats had always \"belonged\" with Apple, as the company modeled itself after Apple's \"unmatched ability to marry culture and technology.\" The acquisition was the largest purchase in Apple's history.\n\nApple has been at the top of Interbrand's annual Best Global Brands report for 4 years in a row; 2013, 2014, 2015, and 2016, with a valuation of $178.1billion.\n\nIn January 2016, it was announced that one billion Apple devices were in active use worldwide.\n\nOn May 12, 2016, Apple Inc., invested US$1billion in Didi Chuxing, a Chinese competitor to Uber. \"The Information\" reported in October 2016 that Apple had taken a board seat in Didi Chuxing, a move that James Vincent of \"The Verge\" speculated could be a strategic company decision by Apple to get closer to the automobile industry, particularly Didi Chuxing's reported interest in self-driving cars.\n\nOn June 6, 2016, Forbes released their list of companies ranked on revenue generation. In the trailing fiscal year, Apple appeared on the list as the top tech company. It ranked third, overall, with $233billion in revenue. This represents a movement upward of two spots from the previous year's list.\n\nOn April 6, 2017, Apple launched Clips, an app that allows iPad and iPhone users to make and edit videos. The app provides a way to produce short videos to share with other users on the Messages app, Instagram, Facebook and other social networks. Apple also introduced Live Titles for Clips that allows users to add live animated captions and titles using their voice.\n\nIn May 2017, Apple refreshed two of its website designs. Their public relations \"Apple Press Info\" website was changed to an \"Apple Newsroom\" site, featuring a greater emphasis on imagery and therefore lower information density, and combines press releases, news items, and photos. Its \"Apple Leadership\" overview of company executives was also refreshed, adding a simpler layout with a prominent header image and two-column text fields. \"9to5Mac\" noted the design similarities to several of Apple's redesigned apps in iOS 10, particularly its Apple Music and News software.\n\nIn June 2017, Apple announced the HomePod, its smart speaker aimed to compete against Sonos and Amazon Echo. Towards the end of the year, \"TechCrunch\" reported that Apple was acquiring Shazam, a company specializing in music, TV, film and advertising recognition. The acquisition was confirmed a few days later, reportedly costing Apple $400million, with media reports noting that the purchase looked like a move by Apple to get data and tools to bolster its Apple Music streaming service. The purchase was approved by EU later in September 2018.\n\nOn June 5, 2018, Apple deprecated OpenGL across all Operating Systems and urges developers to use Metal instead.\n\nApple purchased Akonia Holographics in August 2018 who makes lenses for augmented reality goggles.\n\nMacs currently in production:\nApple sells a variety of computer accessories for Macs, including Thunderbolt Display, Magic Mouse, Magic Trackpad, Magic Keyboard, the AirPort wireless networking products, and Time Capsule.\n\nOn October 23, 2001, Apple introduced the iPod digital music player. Several updated models have since been introduced, and the iPod brand is now the market leader in portable music players by a significant margin. More than 350million units have shipped . Apple has partnered with Nike to offer the Nike+iPod Sports Kit, enabling runners to synchronize and monitor their runs with iTunes and the Nike+ website.\n\nIn late July 2017, Apple discontinued its iPod Nano and iPod Shuffle models, leaving only the iPod Touch available for purchase.\n\nAt the Macworld Conference & Expo in January 2007, Steve Jobs introduced the long-anticipated iPhone, a convergence of an Internet-enabled smartphone and iPod. The first-generation iPhone was released on June 29, 2007, for $499 (4 GB) and $599 (8 GB) with an AT&T contract. On February 5, 2008, it was updated to have 16 GB of memory, in addition to the 8 GB and 4 GB models. It combined a 2.5G quad band GSM and EDGE cellular phone with features found in handheld devices, running scaled-down versions of Apple's Mac OS X (dubbed iPhone OS, later renamed iOS), with various Mac OS X applications such as Safari and Mail. It also includes web-based and Dashboard apps such as Google Maps and Weather. The iPhone features a touchscreen display, Bluetooth, and Wi-Fi (both \"b\" and \"g\").\n\nA second version, the iPhone 3G, was released on July 11, 2008, with a reduced price of $199 for the 8 GB version and $299 for the 16 GB version. This version added support for 3G networking and assisted GPS navigation. The flat silver back and large antenna square of the original model were eliminated in favor of a glossy, curved black or white back. Software capabilities were improved with the release of the App Store, which provided iPhone-compatible applications to download. On April 24, 2009, the App Store surpassed one billion downloads. On June 8, 2009, Apple announced the iPhone 3GS. It provided an incremental update to the device, including faster internal components, support for faster 3G speeds, video recording capability, and voice control.\n\nAt the Worldwide Developers Conference (WWDC) on June 7, 2010, Apple announced the redesigned iPhone 4. It featured a 960 × 640 display, the Apple A4 processor, a gyroscope for enhanced gaming, a 5MP camera with LED flash, front-facing VGA camera and FaceTime video calling. Shortly after its release, reception issues were discovered by consumers, due to the stainless steel band around the edge of the device, which also serves as the phone's cellular signal and Wi-Fi antenna. The issue was corrected by a \"Bumper Case\" distributed by Apple for free to all owners for a few months. In June 2011, Apple overtook Nokia to become the world's biggest smartphone maker by volume. On October 4, 2011, Apple unveiled the iPhone 4S, which was first released on October 14, 2011. It features the Apple A5 processor and Siri voice assistant technology, the latter of which Apple had acquired in 2010. It also features an updated 8MP camera with new optics. Apple began a new accessibility feature, Made for iPhone Hearing Aids with the iPhone 4S. Made for iPhone Hearing Aids feature Live Listen, it can help the user hear a conversation in a noisy room or hear someone speaking across the room. Apple sold 4million iPhone 4S phones in the first three days of availability.\n\nOn September 12, 2012, Apple introduced the iPhone 5. It has a 4-inch display, 4G LTE connectivity, and the upgraded Apple A6 chip, among several other improvements. Two million iPhones were sold in the first twenty-four hours of pre-ordering and over five million handsets were sold in the first three days of its launch. Upon the launch of the iPhone 5S and iPhone 5C, Apple set a new record for first-weekend smartphone sales by selling over nine million devices in the first three days of its launch. The release of the iPhone 5S and 5C was the first time that Apple simultaneously launched two models.\n\nA patent filed in July 2013 revealed the development of a new iPhone battery system that uses location data in combination with data on the user's habits to moderate the handsets power settings accordingly. Apple is working towards a power management system that will provide features such as the ability of the iPhone to estimate the length of time a user will be away from a power source to modify energy usage and a detection function that adjusts the charging rate to best suit the type of power source that is being used.\n\nIn a March 2014 interview, Apple designer Jonathan Ive used the iPhone as an example of Apple's ethos of creating high-quality, life-changing products. He explained that the phones are comparatively expensive due to the intensive effort that is used to make them:\n\nOn September 9, 2014, Apple introduced the iPhone 6, alongside the iPhone 6 Plus that both have screen sizes over 4-inches. One year later, Apple introduced the iPhone 6S, and iPhone 6S Plus, which introduced a new technology called 3D Touch, including an increase of the rear camera to 12 MP, and the FaceTime camera to 5 MP. On March 21, 2016, Apple introduced the iPhone SE that has a 4-inch screen size last used with the 5S and has nearly the same internal hardware as the 6S.\n\nIn July 2016, Apple announced that one billion iPhones had been sold.\n\nOn September 7, 2016, Apple introduced the iPhone 7 and the iPhone 7 Plus, which feature improved system and graphics performance, add water resistance, a new rear dual-camera system on the 7 Plus model, and, controversially, remove the 3.5 mm headphone jack.\nOn September 12, 2017, Apple introduced the iPhone 8 and iPhone 8 Plus, standing as evolutionary updates to its previous phones with a faster processor, improved display technology, upgraded camera systems and wireless charging. The company also announced iPhone X, which radically changes the hardware of the iPhone lineup, removing the home button in favor of facial recognition technology and featuring a near bezel-less design along with wireless charging.\n\nOn September 12, 2018, Apple introduced the iPhone XS, iPhone XS Max and iPhone XR. The iPhone XS and iPhone XS Max features Super Retina displays, a faster and improved dual camera system that offers breakthrough photo and video features, the first 7-nanometer chip in a smartphone — the A12 Bionic chip with next-generation Neural Engine — faster Face ID, wider stereo sound and introduces Dual SIM to iPhone. The iPhone XR comes in an all-screen glass and aluminium design with the most advanced LCD in a smartphone featuring a 6.1-inch Liquid Retina display, A12 Bionic chip with next-generation Neural Engine, the TrueDepth camera system, Face ID and an advanced camera system that creates dramatic portraits using a single camera lens.\n\nOn January 27, 2010, Apple introduced their much-anticipated media tablet, the iPad. It offers multi-touch interaction with multimedia formats including newspapers, e-books, photos, videos, music, word processing documents, video games, and most existing iPhone apps using a 9.7-inch screen. It also includes a mobile version of Safari for web browsing, as well as access to the App Store, iTunes Library, iBookstore, Contacts, and Notes. Content is downloadable via Wi-Fi and optional 3G service or synced through the user's computer. AT&T was initially the sole U.S. provider of 3G wireless access for the iPad.\n\nOn March 2, 2011, Apple introduced the iPad 2, which had a faster processor and a camera on the front and back. It also added support for optional 3G service provided by Verizon in addition to AT&T. The availability of the iPad 2 was initially limited as a result of a devastating earthquake and tsunami in Japan in March 2011.\n\nThe third-generation iPad was released on March 7, 2012, and marketed as \"the new iPad\". It added LTE service from AT&T or Verizon, an upgraded A5X processor, and Retina display. The dimensions and form factor remained relatively unchanged, with the new iPad being a fraction thicker and heavier than the previous version and featuring minor positioning changes.\n\nOn October 23, 2012, Apple's fourth-generation iPad came out, marketed as the \"iPad with Retina display\". It added the upgraded A6X processor and replaced the traditional 30-pin dock connector with the all-digital Lightning connector. The iPad Mini was also introduced. It featured a reduced 7.9-inch display and much of the same internal specifications as the iPad 2.\n\nOn October 22, 2013, Apple introduced the iPad Air and the iPad Mini with Retina Display, both featuring a new 64-bit Apple A7 processor.\n\nThe iPad Air 2 was unveiled on October 16, 2014. It added better graphics and central processing and a camera burst mode as well as minor updates. The iPad Mini 3 was unveiled at the same time.\n\nSince its launch, iPad users have downloaded over three billion apps. The total number of App Store downloads, , is over 100billion.\n\nOn September 9, 2015, Apple announced the iPad Pro, an iPad with a 12.9-inch display that supports two new accessories, the Smart Keyboard and Apple Pencil. An updated IPad Mini 4 was announced at the same time. A 9.7-inch iPad Pro was announced on March 21, 2016. On June 5, 2017, Apple announced a new iPad Pro with a 10.5-inch display to replace the 9.7 inch model and an updated 12.9-inch model.\n\nThe original Apple Watch smartwatch was announced by Tim Cook on September 9, 2014, being introduced as a product with health and fitness-tracking. It was released on April 24, 2015.\n\nThe second generation of Apple Watch, Apple Watch Series 2, was released in September 2016, featuring greater water resistance, a faster processor, and brighter display.\n\nOn September 12, 2017, Apple introduced the Apple Watch Series 3 featuring LTE cellular connectivity, giving the wearable independence from an iPhone except for the setup process.\n\nOn September 12, 2018, Apple introduced the Apple Watch Series 4, featuring new display, electrocardiogram and fall detection.\n\nAt the 2007 Macworld conference, Jobs demonstrated the Apple TV (previously known as the iTV), a set-top video device intended to bridge the sale of content from iTunes with high-definition televisions. The device links up to a user's TV and syncs, either via Wi-Fi or a wired network, with one computer's iTunes library and streams content from an additional four. The Apple TV originally incorporated a 40 GB hard drive for storage, included outputs for HDMI and component video, and played video at a maximum resolution of 720p. On May 30, 2007, a 160 GB hard disk drive was released alongside the existing 40 GB model. A software update released on January 15, 2008, allowed media to be purchased directly from the Apple TV.\n\nIn September 2009, Apple discontinued the original 40 GB Apple TV and now continues to produce and sell the 160 GB Apple TV. On September 1, 2010, Apple released a completely redesigned Apple TV. The new device is 1/4 the size, runs quieter, and replaces the need for a hard drive with media streaming from any iTunes library on the network along with 8 GB of flash memory to cache media downloaded. Like the iPad and the iPhone, Apple TV runs on an A4 processor. The memory included in the device is half of that in the iPhone 4 at 256 MB; the same as the iPad, iPhone 3GS, third and fourth-generation iPod Touch.\n\nIt has HDMI out as the only video output source. Features include access to the iTunes Store to rent movies and TV shows (purchasing has been discontinued), streaming from internet video sources, including YouTube and Netflix, and media streaming from an iTunes library. Apple also reduced the price of the device to $99. A third generation of the device was introduced at an Apple event on March 7, 2012, with new features such as higher resolution (1080p) and a new user interface.\n\nAt the September 9, 2015, event, Apple unveiled an overhauled Apple TV, which now runs a variant of macOS, called tvOS, and contains 32GB or 64 GB of NAND Flash to store games, programs, and to cache the current media playing. The release also coincided with the opening of a separate Apple TV App Store and a new Siri Remote with a glass touchpad, gyroscope, and microphone.\n\nAt the September 12, 2017 event, Apple released a new 4K Apple TV with the same form factor as the 4th Generation model. The 4K model is powered by the A10X SoC designed in-house that also powers their second-generation iPad Pro. The 4K model also has support for high dynamic range.\n\nApple's first smart speaker, the HomePod was released on February 9, 2018 after being delayed from its initial December 2017 release. It also features 7 tweeters in the base, a four-inch woofer in the top, and six microphones for voice control and acoustic optimization On September 12, 2018, Apple announced that HomePod is adding new features—search by lyrics, set multiple timers, make and receive phone calls, Find My iPhone, Siri Shortcuts—and Siri languages.\n\nApple develops its own operating systems to run on its devices, including macOS for Mac personal computers, iOS for its iPhone, iPad and iPod Touch smartphones and tablets, watchOS for its Apple Watch smartwatches, and tvOS for its Apple TV digital media player.\n\nFor iOS and macOS, Apple also develops its own software titles, including Pages for writing, Numbers for spreadsheets, and Keynote for presentations, as part of its iWork productivity suite. For macOS, it also offers iMovie and Final Cut Pro X for video editing, and GarageBand and Logic Pro X for music creation.\n\nApple's range of server software includes the operating system macOS Server; Apple Remote Desktop, a remote systems management application; and Xsan, a storage area network file system.\n\nApple also offers online services with iCloud, which provides cloud storage and synchronization for a wide range of user data, including documents, photos, music, device backups, and application data, and Apple Music, its music and video streaming service.\n\nAccording to the \"Sydney Morning Herald\", Apple wants to start producing an electric car with autonomous driving as soon as 2020. Apple has made efforts to recruit battery development engineers and other electric automobile engineers from A123 Systems, LG Chem, Samsung Electronics, Panasonic, Toshiba, Johnson Controls and Tesla Motors.\n\nApple Energy, LLC is a wholly owned subsidiary of Apple Inc. that sells solar energy. , Apple's solar farms in California and Nevada have been declared to provide 217.9 megawatts of solar generation capacity. In addition to the company's solar energy production, Apple has received regulatory approval to construct a landfill gas energy plant in North Carolina. Apple will use the methane emissions to generate electricity. Apple's North Carolina data center is already powered entirely with energy from renewable sources.\n\nAccording to Steve Jobs, the company's name was inspired by his visit to an apple farm while on a fruitarian diet. Jobs thought the name \"Apple\" was \"fun, spirited and not intimidating\".\n\nApple's first logo, designed by Ron Wayne, depicts Sir Isaac Newton sitting under an apple tree. It was almost immediately replaced by Rob Janoff's \"rainbow Apple\", the now-familiar rainbow-colored silhouette of an apple with a bite taken out of it. Janoff presented Jobs with several different monochromatic themes for the \"bitten\" logo, and Jobs immediately took a liking to it. However, Jobs insisted that the logo be colorized to humanize the company. The logo was designed with a bite so that it would not be confused with a cherry. The colored stripes were conceived to make the logo more accessible, and to represent the fact the Apple II could generate graphics in color. This logo is often erroneously referred to as a tribute to Alan Turing, with the bite mark a reference to his method of suicide. Both Janoff and Apple deny any homage to Turing in the design of the logo.\n\nOn August 27, 1999 (the year following the introduction of the iMac G3), Apple officially dropped the rainbow scheme and began to use monochromatic logos nearly identical in shape to the previous rainbow incarnation. An Aqua-themed version of the monochrome logo was used from 1998 to 2003, and a glass-themed version was used from 2007 to 2013.\n\nSteve Jobs and Steve Wozniak were Beatles fans, but Apple Inc. had name and logo trademark issues with Apple Corps Ltd., a multimedia company started by the Beatles in 1967. This resulted in a series of lawsuits and tension between the two companies. These issues ended with the settling of their lawsuit in 2007.\n\nApple's first slogan, \"Byte into an Apple\", was coined in the late 1970s. From 1997 to 2002, the slogan \"Think Different\" was used in advertising campaigns, and is still closely associated with Apple. Apple also has slogans for specific product lines — for example, \"iThink, therefore iMac\" was used in 1998 to promote the iMac, and \"Say hello to iPhone\" has been used in iPhone advertisements. \"Hello\" was also used to introduce the original Macintosh, Newton, iMac (\"hello (again)\"), and iPod.\n\nFrom the introduction of the Macintosh in 1984, with the 1984 Super Bowl commercial to the more modern 'Get a Mac' adverts, Apple has been recognized for its efforts towards effective advertising and marketing for its products. However, claims made by later campaigns were criticized, particularly the 2005 Power Mac ads. Apple's product commercials gained a lot of attention as a result of their eye-popping graphics and catchy tunes. Musicians who benefited from an improved profile as a result of their songs being included on Apple commercials include Canadian singer Feist with the song \"1234\" and Yael Naïm with the song \"New Soul\".\n\nApple owns a YouTube channel where they release advertisements, tips, and introductions for their devices.\n\nApple customers gained a reputation for devotion and loyalty early in the company's history. \"BYTE\" in 1984 stated that\n\nApple evangelists were actively engaged by the company at one time, but this was after the phenomenon had already been firmly established. Apple evangelist Guy Kawasaki has called the brand fanaticism \"something that was stumbled upon,\" while Ive explained in 2014 that \"People have an incredibly personal relationship\" with Apple's products. Apple Store openings and new product releases can draw crowds of hundreds, with some waiting in line as much as a day before the opening. The opening of New York City's Fifth Avenue \"Cube\" store in 2006 became the setting of a marriage proposal, and had visitors from Europe who flew in for the event. In June 2017, a newlywed couple took their wedding photos inside the then-recently opened Orchard Road Apple Store in Singapore. The high level of brand loyalty has been criticized and ridiculed, applying the epithet \"Apple fanboy\" and mocking the lengthy lines before a product launch. An internal memo leaked in 2015 suggested the company planned to discourage long lines and direct customers to purchase its products on its website.\n\n\"Fortune\" magazine named Apple the most admired company in the United States in 2008, and in the world from 2008 to 2012. On September 30, 2013, Apple surpassed Coca-Cola to become the world's most valuable brand in the Omnicom Group's \"Best Global Brands\" report. Boston Consulting Group has ranked Apple as the world's most innovative brand every year since 2005.\n\n\"The New York Times\" in 1985 stated that \"Apple above all else is a marketing company\". John Sculley agreed, telling \"The Guardian\" newspaper in 1997 that \"People talk about technology, but Apple was a marketing company. It was the marketing company of the decade.\" Research in 2002 by NetRatings indicate that the average Apple consumer was usually more affluent and better educated than other PC company consumers. The research indicated that this correlation could stem from the fact that on average Apple Inc. products were more expensive than other PC products.\n\nIn response to a query about the devotion of loyal Apple consumers, Jonathan Ive responded:\nWhat people are responding to is much bigger than the object. They are responding to something rare—a group of people who do more than simply make something work, they make the very best products they possibly can. It's a demonstration against thoughtlessness and carelessness.\n\nThe Apple website home page has been used to commemorate, or pay tribute to, milestones and events outside of Apple's product offerings:\n\nApple Inc.'s world corporate headquarters are located in the middle of Silicon Valley, at 1–6 Infinite Loop, Cupertino, California. This Apple campus has six buildings that total and was built in 1993 by Sobrato Development Cos.\n\nApple has a satellite campus in neighboring Sunnyvale, California, where it houses a testing and research laboratory. AppleInsider published article in March 2014 claiming that Apple has a tucked away a top-secret facility where is developing the SG5 electric vehicle project codenamed \"Titan\" under the shell company name SixtyEight Research.\nIn 2006, Apple announced its intention to build a second campus in Cupertino about east of the current campus and next to Interstate 280. The new campus building has been designed by Norman Foster. The Cupertino City Council approved the proposed \"spaceship\" design campus on October 15, 2013, after a 2011 presentation by Jobs detailing the architectural design of the new building and its environs. The new campus is planned to house up to 13,000 employees in one central, four-storied, circular building surrounded by extensive landscape. It will feature a café with room for 3,000 sitting people and parking underground as well as in a parking structure. The 2.8million square foot facility will also include Jobs's original designs for a fitness center and a corporate auditorium.\nApple has expanded its campuses in Austin, Texas concurrently with building Apple Park in Cupertino. The expansion consists of two locations, with one having 1.1million square feet of workspace, and the other 216,000 square feet. At the biggest location, 6,000 employees work on technical support, manage Apple's network of suppliers to fulfill product shipments, aid in maintaining iTunes Store and App Store, handle economy, and continuously update Apple Maps with new data. At its smaller campus, 500 engineers work on next-generation processor chips to run in future Apple products.\n\nApple's headquarters for Europe, the Middle East and Africa (EMEA) are located in Cork in the south of Ireland. The facility, which opened in 1980, was Apple's first location outside of the United States. Apple Sales International, which deals with all of Apple's international sales outside of the US, is located at Apple's campus in Cork along with Apple Distribution International, which similarly deals with Apple's international distribution network. On April 20, 2012, Apple added 500 new jobs at its European headquarters, increasing the total workforce from around 2,800 to 3,300 employees. The company will build a new office block on its Hollyhill Campus to accommodate the additional staff. Its United Kingdom headquarters is at Stockley Park on the outskirts of London.\n\nIn February 2015, Apple opened their new 180,000-square-foot headquarters in Herzliya, Israel, which will accommodate approximately 800 employees. This opening was Apple's third office located within Israel; the first, also in Herzliya, was obtained as part of the Anobit acquisition, and the other is a research center in Haifa.\n\nIn December 2015, Apple bought the 70,000-square-foot manufacturing facility in North San Jose previously used by Maxim Integrated, in an $18.2million deal.\n\nThe first Apple Stores were originally opened as two locations in May 2001 by then-CEO Steve Jobs, after years of attempting but failing store-within-a-store concepts. Seeing a need for improved retail presentation of the company's products, he began an effort in 1997 to revamp the retail program to get an improved relationship to consumers, and hired Ron Johnson in 2000. Jobs relaunched Apple's online store in 1997, and opened the first two physical stores in 2001. Despite initial media speculation that Apple would fail, its stores were highly successful, bypassing the sales numbers of competing nearby stores and within three years reached US$1 billion in annual sales, becoming the fastest retailer in history to do so. Over the years, Apple has expanded the number of retail locations and its geographical coverage, with 499 stores across 22 countries worldwide . Strong product sales have placed Apple among the top-tier retail stores, with sales over $16 billion globally in 2011.\n\nIn May 2016, Angela Ahrendts, Apple's current Senior Vice President of Retail, unveiled a significantly redesigned Apple Store in Union Square, San Francisco, featuring large glass doors for the entry, open spaces, and rebranded rooms. In addition to purchasing products, consumers can get advice and help from \"Creative Pros\" – individuals with specialized knowledge of creative arts; get product support in a tree-lined Genius Grove; and attend sessions, conferences and community events, with Ahrendts commenting that the goal is to make Apple Stores into \"town squares\", a place where people naturally meet up and spend time. The new design will be applied to all Apple Stores worldwide, a process that has seen stores temporarily relocate or close.\n\nMany Apple Stores are located inside shopping malls, but Apple has built several stand-alone \"flagship\" stores in high-profile locations. It has been granted design patents and received architectural awards for its stores' designs and construction, specifically for its use of glass staircases and cubes. The success of Apple Stores have had significant influence over other consumer electronics retailers, who have lost traffic, control and profits due to a perceived higher quality of service and products at Apple Stores. Apple's notable brand loyalty among consumers causes long lines of hundreds of people at new Apple Store openings or product releases. Due to the popularity of the brand, Apple receives a large number of job applications, many of which come from young workers. Although Apple Store employees receive above-average pay, are offered money toward education and health care, and receive product discounts, there are limited or no paths of career advancement. A May 2016 report with an anonymous retail employee highlighted a hostile work environment with harassment from customers, intense internal criticism, and a lack of significant bonuses for securing major business contracts.\n\nApple was one of several highly successful companies founded in the 1970s that bucked the traditional notions of corporate culture. Jobs often walked around the office barefoot even after Apple became a Fortune 500 company. By the time of the \"1984\" television commercial, Apple's informal culture had become a key trait that differentiated it from its competitors. According to a 2011 report in \"Fortune,\" this has resulted in a corporate culture more akin to a startup rather than a multinational corporation.\n\nAs the company has grown and been led by a series of differently opinionated chief executives, it has arguably lost some of its original character. Nonetheless, it has maintained a reputation for fostering individuality and excellence that reliably attracts talented workers, particularly after Jobs returned to the company. Numerous Apple employees have stated that projects without Jobs's involvement often took longer than projects with it.\n\nTo recognize the best of its employees, Apple created the Apple Fellows program which awards individuals who make extraordinary technical or leadership contributions to personal computing while at the company. The Apple Fellowship has so far been awarded to individuals including Bill Atkinson, Steve Capps, Rod Holt, Alan Kay, Guy Kawasaki, Al Alcorn, Don Norman, Rich Page, and Steve Wozniak.\nAt Apple, employees are specialists who are not exposed to functions outside their area of expertise. Jobs saw this as a means of having \"best-in-class\" employees in every role. For instance, Ron Johnson—Senior Vice President of Retail Operations until November 1, 2011—was responsible for site selection, in-store service, and store layout, yet had no control of the inventory in his stores (this was done by Cook, who had a background in supply-chain management). Apple is also known for strictly enforcing accountability. Each project has a \"directly responsible individual,\" or \"DRI\" in Apple jargon. As an example, when iOS senior vice president Scott Forstall refused to sign Apple's official apology for numerous errors in the redesigned Maps app, he was forced to resign. Unlike other major U.S. companies Apple provides a relatively simple compensation policy for executives that does not include perks enjoyed by other CEOs like country club fees or private use of company aircraft. The company typically grants stock options to executives every other year.\n\nIn 2015, Apple had 110,000 full-time employees. This increased to 116,000 full-time employees the next year, a notable hiring decrease, largely due to its first revenue decline. Apple does not specify how many of its employees work in retail, though its 2014 SEC filing put the number at approximately half of its employee base. In September 2017, Apple announced that it had over 123,000 full-time employees.\n\nApple has a strong culture of corporate secrecy, and has an anti-leak Global Security team that recruits from the National Security Agency, the Federal Bureau of Investigation and the United States Secret Service.\n\nIn December 2017, Glassdoor named Facebook the best place to work, according to reviews from anonymous employees, with Apple dropping to 48th place, having originally entered at rank 19 in 2009, peaking at rank 10 in 2012, and falling down the ranks in subsequent years.\n\nAn editorial article in \"The Verge\" in September 2016 by technology journalist Thomas Ricker explored some of the public's perceived lack of innovation at Apple in recent years, specifically stating that Samsung has \"matched and even surpassed Apple in terms of smartphone industrial design\" and citing the belief that Apple is incapable of producing another breakthrough moment in technology with its products. He goes on to write that the criticism focuses on individual pieces of hardware rather than the ecosystem as a whole, stating \"Yes, iteration is boring. But it's also how Apple does business. [...] It enters a new market and then refines and refines and continues refining until it yields a success\". He acknowledges that people are wishing for the \"excitement of revolution\", but argues that people want \"the comfort that comes with harmony\". Furthermore, he writes that \"a device is only the starting point of an experience that will ultimately be ruled by the ecosystem in which it was spawned\", referring to how decent hardware products can still fail without a proper ecosystem (specifically mentioning that Walkman didn't have an ecosystem to keep users from leaving once something better came along), but how Apple devices in different hardware segments are able to communicate and cooperate through the iCloud cloud service with features including Universal Clipboard (in which text copied on one device can be pasted on a different device) as well as inter-connected device functionality including Auto Unlock (in which an Apple Watch can unlock a Mac in close proximity). He argues that Apple's ecosystem is its greatest innovation.\n\n\"The Wall Street Journal\" reported in June 2017 that Apple's increased reliance on Siri, its virtual personal assistant, has raised questions about how much Apple can actually accomplish in terms of functionality. Whereas Google and Amazon make use of big data and analyze customer information to personalize results, Apple has a strong pro-privacy stance, intentionally not retaining user data. \"Siri is a textbook of leading on something in tech and then losing an edge despite having all the money and the talent and sitting in Silicon Valley\", Holger Mueller, a technology analyst, told the \"Journal\". The report further claims that development on Siri has suffered due to team members and executives leaving the company for competitors, a lack of ambitious goals, and shifting strategies. Despite switching Siri's functions to machine learning and algorithms, which dramatically cut its error rate, the company reportedly still failed to anticipate the popularity of Amazon's Echo, which features the Alexa personal assistant. Improvements to Siri stalled, executives clashed, and there were disagreements over the restrictions imposed on third-party app interactions. While Apple acquired an England-based startup specializing in conversational assistants, Google's Assistant had already become capable of helping users select Wi-Fi networks by voice, and Siri was lagging in functionality.\n\nIn December 2017, two articles from \"The Verge\" and \"ZDNet\" debated what had been a particularly devastating week for Apple's macOS and iOS software platforms. The former had experienced a severe security vulnerability, in which Macs running the then-latest macOS High Sierra software were vulnerable to a bug that let anyone gain administrator privileges by entering \"root\" as the username in system prompts, leaving the password field empty and twice clicking \"unlock\", gaining full access. The bug was publicly disclosed on Twitter, rather than through proper bug bounty programs. Apple released a security fix within a day and issued an apology, stating that \"regrettably we stumbled\" in regards to the security of the latest updates. After installing the security patch, however, file sharing was broken for users, with Apple releasing a support document with instructions to separately fix that issue. Despite its promise of \"auditing our development processes to help prevent this from happening again\", users who installed the security update while running the older 10.13.0 version of the High Sierra operating system rather than the then-newest 10.13.1 release experienced that the \"root\" security vulnerability was re-introduced, and persisted even after fully updating their systems. On iOS, a date bug caused iOS devices that received local app notifications at 12:15am on December 2, 2017 to repeatedly restart. Users were recommended to turn off notifications for their apps. Apple quickly released an update, done during the nighttime in Cupertino, California time and outside of their usual software release window, with one of the headlining features of the update needing to be delayed for a few days. The combined problems of the week on both macOS and iOS caused \"The Verge\"s Tom Warren to call it a \"nightmare\" for Apple's software engineers and described it as a significant lapse in Apple's ability to protect its more than 1 billion devices. \"ZDNet\"s Adrian Kingsley-Hughes wrote that \"it's hard to not come away from the last week with the feeling that Apple is slipping\". Kingsley-Hughes also concluded his piece by referencing an earlier article, in which he wrote that \"As much as I don't want to bring up the tired old \"Apple wouldn't have done this under Steve Jobs' watch\" trope, a lot of what's happening at Apple lately is different from what came to expect under Jobs. Not to say that things didn't go wrong under his watch, but product announcements and launches felt a lot tighter for sure, as did the overall quality of what Apple was releasing.\" He did, however, also acknowledge that such failures \"may indeed have happened\" with Jobs in charge, though returning to the previous praise for Jobs' quality, stating \"it's almost guaranteed that given his personality that heads would have rolled, which limits future failures\".\n\nThe company's manufacturing, procurement, and logistics enable it to execute massive product launches without having to maintain large, profit-sapping inventories. In 2011, Apple's profit margins were 40 percent, compared with between 10 and 20 percent for most other hardware companies. Cook's catchphrase to describe his focus on the company's operational arm is: \"Nobody wants to buy sour milk\".\n\nDuring the Mac's early history Apple generally refused to adopt prevailing industry standards for hardware, instead creating their own. This trend was largely reversed in the late 1990s, beginning with Apple's adoption of the PCI bus in the 7500/8500/9500 Power Macs. Apple has since joined the industry standards groups to influence the future direction of technology standards such as USB, AGP, HyperTransport, Wi-Fi, NVMe, PCIe and others in its products. FireWire is an Apple-originated standard that was widely adopted across the industry after it was standardized as IEEE 1394 and is a legally mandated port in all Cable TV boxes in the United States.\n\nApple has gradually expanded its efforts in getting its products into the Indian market. In July 2012, during a conference call with investors, CEO Tim Cook said that he \"[loves] India\", but that Apple saw larger opportunities outside the region. India's requirement that 30% of products sold be manufactured in the country was described as \"really adds cost to getting product to market\". In October 2013, Indian Apple executives unveiled a plan for selling devices through instalment plans and store-within-a-store concepts, in an effort to expand further into the market. The news followed Cook's acknowledgment of the country in July when sales results showed that iPhone sales in India grew 400% during the second quarter of 2013. In March 2016, \"The Times of India\" reported that Apple had sought permission from the Indian government to sell refurbished iPhones in the country. However, two months later, the application was rejected, citing official country policy. In May 2016, Apple opened an iOS app development center in Bangalore and a maps development office for 4,000 staff in Hyderabad. In February 2017, Apple once again requested permission to sell used iPhones in the country. The same month, \"Bloomberg\" reported that Apple was close to receiving permission to open its first retail store in the country. In March, \"The Wall Street Journal\" reported that Apple would begin manufacturing iPhone models in India \"over the next two months\", and in May, the \"Journal\" wrote that an Apple manufacturer had begun production of iPhone SE in the country, while Apple told \"CNBC\" that the manufacturing was for a \"small number\" of units. Reuters reported in December 2017, that Apple and the Indian government were clashing over planned increases to import taxes for components used in mobile phone production, with Apple having engaged in talks with government officials to try to delay the plans, but the Indian government sticking to its policies of no exemptions to its \"Made in India\" initiative. The import tax increases went into effect a few days later, with Apple being hurt the most out of all phone manufacturers, having nine of out ten phones imported into the country, whereas main smartphone competitor Samsung produces almost all of its devices locally.\n\nIn May 2017, the company announced a $1 billion funding project for \"advanced manufacturing\" in the United States, and subsequently invested $200million in Corning Inc., a manufacturer of toughened Gorilla Glass technology used in its iPhone devices. The following December, Apple's chief operating officer, Jeff Williams, told \"CNBC\" that the \"$1 billion\" amount was \"absolutely not\" the final limit on its spending, elaborating that \"We're not thinking in terms of a fund limit. ... We're thinking about, where are the opportunities across the U.S. to help nurture companies that are making the advanced technology — and the advanced manufacturing that goes with that — that quite frankly is essential to our innovation\".\n\nThe company advertised its products as being made in America until the late 1990s; however, as a result of outsourcing initiatives in the 2000s, almost all of its manufacturing is now handled abroad. According to a report by \"The New York Times\", Apple insiders \"believe the vast scale of overseas factories, as well as the flexibility, diligence and industrial skills of foreign workers, have so outpaced their American counterparts that \"Made in the U.S.A.\" is no longer a viable option for most Apple products\".\n\nIn 2006, the \"Mail on Sunday\" reported on the working conditions of the Chinese factories where contract manufacturers Foxconn and Inventec produced the iPod. The article stated that one complex of factories that assembled the iPod and other items had over 200,000 workers living and working within it. Employees regularly worked more than 60 hours per week and made around $100 per month. A little over half of the workers' earnings was required to pay for rent and food from the company.\n\nApple immediately launched an investigation after the 2006 media report, and worked with their manufacturers to ensure acceptable working conditions. In 2007, Apple started yearly audits of all its suppliers regarding worker's rights, slowly raising standards and pruning suppliers that did not comply. Yearly progress reports have been published since 2008. In 2011, Apple admitted that its suppliers' child labor practices in China had worsened.\n\nThe Foxconn suicides occurred between January and November 2010, when 18 Foxconn (Chinese: 富士康) employees attempted suicide, resulting in 14 deaths—the company was the world's largest contract electronics manufacturer, for clients including Apple, at the time. The suicides drew media attention, and employment practices at Foxconn were investigated by Apple. Apple issued a public statement about the suicides, and company spokesperson Steven Dowling said:\n[Apple is] saddened and upset by the recent suicides at Foxconn ... A team from Apple is independently evaluating the steps they are taking to address these tragic events and we will continue our ongoing inspections of the facilities where our products are made.\n\nThe statement was released after the results from the company's probe into its suppliers' labor practices were published in early 2010. Foxconn was not specifically named in the report, but Apple identified a series of serious labor violations of labor laws, including Apple's own rules, and some child labor existed in a number of factories. Apple committed to the implementation of changes following the suicides.\n\nAlso in 2010, workers in China planned to sue iPhone contractors over poisoning by a cleaner used to clean LCD screens. One worker claimed that he and his coworkers had not been informed of possible occupational illnesses. After a high suicide rate in a Foxconn facility in China making iPads and iPhones, albeit a lower rate than that of China as a whole, workers were forced to sign a legally binding document guaranteeing that they would not kill themselves. Workers in factories producing Apple products have also been exposed to n-hexane, a neurotoxin that is a cheaper alternative than alcohol for cleaning the products.\n\nA 2014 BBC investigation found excessive hours and other problems persisted, despite Apple's promise to reform factory practice after the 2010 Foxconn suicides. The Pegatron factory was once again the subject of review, as reporters gained access to the working conditions inside through recruitment as employees. While the BBC maintained that the experiences of its reporters showed that labor violations were continuing since 2010, Apple publicly disagreed with the BBC and stated: \"We are aware of no other company doing as much as Apple to ensure fair and safe working conditions\".\n\nIn December 2014, the Institute for Global Labour and Human Rights published a report which documented inhumane conditions for the 15,000 workers at a Zhen Ding Technology factory in Shenzhen, China, which serves as a major supplier of circuit boards for Apple's iPhone and iPad. According to the report, workers are pressured into 65-hour work weeks which leaves them so exhausted that they often sleep during lunch breaks. They are also made to reside in \"primitive, dark and filthy dorms\" where they sleep \"on plywood, with six to ten workers in each crowded room.\" Omnipresent security personnel also routinely harass and beat the workers.\n\nFollowing a Greenpeace protest, Apple released a statement on April 17, 2012, committing to ending its use of coal and shifting to 100% renewable clean energy. By 2013, Apple was using 100% renewable energy to power their data centers. Overall, 75% of the company's power came from clean renewable sources.\n\nIn 2010, Climate Counts, a nonprofit organization dedicated to directing consumers toward the greenest companies, gave Apple a score of 52 points out of a possible 100, which puts Apple in their top category \"Striding\". This was an increase from May 2008, when Climate Counts only gave Apple 11 points out of 100, which placed the company last among electronics companies, at which time Climate Counts also labeled Apple with a \"stuck icon\", adding that Apple at the time was \"a choice to avoid for the climate conscious consumer\".\n\nIn May 2015, Greenpeace evaluated the state of the Green Internet and commended Apple on their environmental practices saying, \"Apple's commitment to renewable energy has helped set a new bar for the industry, illustrating in very concrete terms that a 100% renewable Internet is within its reach, and providing several models of intervention for other companies that want to build a sustainable Internet.\"\n\n, Apple states that 100% of its U.S. operations run on renewable energy, 100% of Apple's data centers run on renewable energy and 93% of Apple's global operations run on renewable energy. However, the facilities are connected to the local grid which usually contains a mix of fossil and renewable sources, so Apple carbon offsets its electricity use. The Electronic Product Environmental Assessment Tool (EPEAT) allows consumers to see the effect a product has on the environment. Each product receives a Gold, Silver, or Bronze rank depending on its efficiency and sustainability. Every Apple tablet, notebook, desktop computer, and display that EPEAT ranks achieves a Gold rating, the highest possible. Although Apple's data centers recycle water 35 times, the increased activity in retail, corporate and data centers also increase the amount of water use to 573million gallons in 2015.\n\nDuring an event on March 21, 2016, Apple provided a status update on its environmental initiative to be 100% renewable in all of its worldwide operations. Lisa P. Jackson, Apple's vice president of Environment, Policy and Social Initiatives who reports directly to CEO, Tim Cook, announced that , 93% of Apple's worldwide operations are powered with renewable energy. Also featured was the company's efforts to use sustainable paper in their product packaging; 99% of all paper used by Apple in the product packaging comes from post-consumer recycled paper or sustainably managed forests, as the company continues its move to all paper packaging for all of its products. Apple working in partnership with Conservation Fund, have preserved 36,000 acres of working forests in Maine and North Carolina. Another partnership announced is with the World Wildlife Fund to preserve up to 1,000,000 acres of forests in China. Featured was the company's installation of a 40 MW solar power plant in the Sichuan province of China that was tailor-made to coexist with the indigenous yaks that eat hay produced on the land, by raising the panels to be several feet off of the ground so the yaks and their feed would be unharmed grazing beneath the array. This installation alone compensates for more than all of the energy used in Apple's Stores and Offices in the whole of China, negating the company's energy carbon footprint in the country. In Singapore, Apple has worked with the Singaporean government to cover the rooftops of 800 buildings in the city-state with solar panels allowing Apple's Singapore operations to be run on 100% renewable energy. Liam was introduced to the world, an advanced robotic disassembler and sorter designed by Apple Engineers in California specifically for recycling outdated or broken iPhones. Reuses and recycles parts from traded in products.\n\nApple announced on August 16, 2016, that Lens Technology, one of its major suppliers in China, has committed to power all its glass production for Apple with 100 percent renewable energy by 2018. The commitment is a large step in Apple's efforts to help manufacturers lower their carbon footprint in China. Apple also announced that all 14 of its final assembly sites in China are now compliant with UL's Zero Waste to Landfill validation. The standard, which started in January 2015, certifies that all manufacturing waste is reused, recycled, composted, or converted into energy (when necessary). Since the program began, nearly, 140,000 metric tons of waste have been diverted from landfills.\n\nFollowing further campaigns by Greenpeace, in 2008, Apple became the first electronics manufacturer to fully eliminate all polyvinyl chloride (PVC) and brominated flame retardants (BFRs) in its complete product line. In June 2007, Apple began replacing the cold cathode fluorescent lamp (CCFL) backlit LCD displays in its computers with mercury-free LED-backlit LCD displays and arsenic-free glass, starting with the upgraded MacBook Pro. Apple offers comprehensive and transparent information about the COe, emissions, materials, and electrical usage concerning every product they currently produce or have sold in the past (and which they have enough data needed to produce the report), in their portfolio on their homepage. Allowing consumers to make informed purchasing decisions on the products they offer for sale. In June 2009, Apple's iPhone 3GS was free of PVC, arsenic, and BFRs. All Apple products now have mercury-free LED-backlit LCD displays, arsenic-free glass, and non-PVC cables. All Apple products have EPEAT Gold status and beat the latest Energy Star guidelines in each product's respective regulatory category.\n\nIn November 2011, Apple was featured in Greenpeace's Guide to Greener Electronics, which ranks electronics manufacturers on sustainability, climate and energy policy, and how \"green\" their products are. The company ranked fourth of fifteen electronics companies (moving up five places from the previous year) with a score of 4.6/10. Greenpeace praises Apple's sustainability, noting that the company exceeded its 70% global recycling goal in 2010. It continues to score well on the products rating with all Apple products now being free of PVC plastic and BFRs. However, the guide criticizes Apple on the Energy criteria for not seeking external verification of its greenhouse gas emissions data and for not setting out any targets to reduce emissions. In January 2012, Apple requested that its cable maker, Volex, begin producing halogen-free USB and power cables.\n\nIn February 2016, Apple issued a US$1.5billion green bond (climate bond), the first ever of its kind by a U.S. tech company. The green bond proceeds are dedicated to the financing of environmental projects.\n\nApple is the world's largest information technology company by revenue, the world's largest technology company by total assets, and the world's second-largest mobile phone manufacturer after Samsung.\n\nIn its fiscal year ending in September 2011, Apple Inc. reported a total of $108billion in annual revenues—a significant increase from its 2010 revenues of $65billion—and nearly $82billion in cash reserves. On March 19, 2012, Apple announced plans for a $2.65-per-share dividend beginning in fourth quarter of 2012, per approval by their board of directors.\n\nThe company's worldwide annual revenue in 2013 totaled $170billion. In May 2013, Apple entered the top ten of the Fortune 500 list of companies for the first time, rising 11 places above its 2012 ranking to take the sixth position. , Apple has around US$234billion of cash and marketable securities, of which 90% is located outside the United States for tax purposes.\n\nApple amassed 65% of all profits made by the eight largest worldwide smartphone manufacturers in quarter one of 2014, according to a report by Canaccord Genuity. In the first quarter of 2015, the company garnered 92% of all earnings.\n\nOn April 30, 2017, \"The Wall Street Journal\" reported that Apple had cash reserves of $250 billion, officially confirmed by Apple as specifically $256.8 billion a few days later.\n\n, Apple is the largest publicly traded corporation in the world by market capitalization. On August 2, 2018, Apple became the first publicly traded U.S. company to reach a $1 trillion market value. Apple is currently ranked #4 on the Fortune 500 rankings of the largest United States corporations by total revenue.\n\nApple has created subsidiaries in low-tax places such as Ireland, the Netherlands, Luxembourg and the British Virgin Islands to cut the taxes it pays around the world. According to \"The New York Times,\" in the 1980s Apple was among the first tech companies to designate overseas salespeople in high-tax countries in a manner that allowed the company to sell on behalf of low-tax subsidiaries on other continents, sidestepping income taxes. In the late 1980s, Apple was a pioneer of an accounting technique known as the \"Double Irish with a Dutch sandwich,\" which reduces taxes by routing profits through Irish subsidiaries and the Netherlands and then to the Caribbean.\n\nBritish Conservative Party Member of Parliament Charlie Elphicke published research on October 30, 2012, which showed that some multinational companies, including Apple Inc., were making billions of pounds of profit in the UK, but were paying an effective tax rate to the UK Treasury of only 3 percent, well below standard corporation tax. He followed this research by calling on the Chancellor of the Exchequer George Osborne to force these multinationals, which also included Google and The Coca-Cola Company, to state the effective rate of tax they pay on their UK revenues. Elphicke also said that government contracts should be withheld from multinationals who do not pay their fair share of UK tax.\n\nApple Inc. claims to be the single largest taxpayer to the Department of the Treasury of the United States of America with an effective tax rate of approximately of 26% as of the Second Quarter of the Apple Fiscal Year 2016. In an interview with the German newspaper FAZ in October 2017, Tim Cook stated, that Apple is the biggest taxpayer worldwide.\n\nIn 2015, Reuters reported that Apple had earnings abroad of $54.4billion which were untaxed by the IRS of the United States. Under U.S. tax law governed by the IRC, corporations don't pay income tax on overseas profits unless the profits are repatriated into the United States and as such Apple argues that to benefit its shareholders it will leave it overseas until a repatriation holiday or comprehensive tax reform takes place in the United States.\n\nOn 12 July 2016 the Central Statistics Office (Ireland) announced that 2015 Irish GDP had grown by 26.3%, and 2015 Irish GNP had grown by 18.7%. The figures attracted international scorn, and were labelled by Nobel-prize winning economist, Paul Krugman, as leprechaun economics. It was not until 2018 that Irish economists could definitively prove that the 2015 growth was due to Apple restructuring its controversial double Irish subsidiaries (Apple Sales International), which Apple converted into a new Irish capital allowances for intangible assets tax scheme (expires in January 2020). The affair required the Central Bank of Ireland to create a new measure of Irish economic growth, Modified GNI* to replace Irish GDP, given the distortion of Apple's tax schemes. Irish GDP is 143% of Irish Modified GNI*.\n\nOn August 30, 2016, after a two-year investigation, the EU Competition Commissioner concluded Apple received \"illegal State aid\" from Ireland. The EU ordered Apple to pay 13billion euros ($14.5billion), plus interest, in unpaid Irish taxes for 2004-2014. It is the largest tax fine in history. The Commission found that Apple had benefitted from a private Irish Revenue Commissioners tax ruling regarding its double Irish tax structure, Apple Sales International (ASI). Instead of using two companies for its double Irish structure, Apple was given a ruling to split ASI into two internal \"branches\". The Chancellor of Austria, Christian Kern, put this decision into perspective by stating that \"every Viennese cafe, every sausage stand pays more tax in Austria than a multinational corporation\".\n\n, Apple agreed to start paying €13 billion in back taxes to the Irish government, the repayments will be held in an escrow account while Apple and the Irish government continue their appeals in EU courts.\n\nApple Inc. is a joint-stock company registered with the SEC. , it has 4,829,926,000 outstanding shares. These are mainly held by institutional investors and funds.\n\nApple has been a participant in various legal proceedings and claims since it began operation. In particular, Apple is known for and promotes itself as actively and aggressively enforcing its intellectual property interests. Some litigation examples include \"Apple v. Samsung\", \"Apple v. Microsoft\", \"Motorola Mobility v. Apple Inc.\", and \"Apple Corps v. Apple Computer\". Apple has also had to defend itself against charges on numerous occasions of violating intellectual property rights. Most have been dismissed in the courts as shell companies known as patent trolls, with no evidence of actual use of patents in question. On December 21, 2016, Nokia announced that in the U.S. and Germany, it has filed a suit against Apple, claiming that the latter's products infringe on Nokia's patents. Most recently, in November 2017, the United States International Trade Commission announced an investigation into allegations of patent infringement in regards to Apple's remote desktop technology; Aqua Connect, a company that builds remote desktop software, has claimed that Apple infringed on two of its patents.\n\nApple has a notable pro-privacy stance, actively making privacy-conscious features and settings part of its conferences, promotional campaigns, and public image. With its iOS 8 mobile operating system in 2014, the company started encryption all contents of iOS devices through users' passcodes, making it impossible for the company to provide customer data to law enforcement requests seeking such information. With the popularity rise of cloud storage solutions, Apple began a technique in 2016 to do deep learning scans for facial data in photos on the user's local device and encrypting the content before uploading it to Apple's iCloud storage system. It also introduced \"differential privacy\", a way to collect crowdsourced data from many users, while keeping individual users anonymous, in a system that \"Wired\" described as \"trying to learn as much as possible about a group while learning as little as possible about any individual in it\". Users are explicitly asked if they want to participate, and can actively opt-in or opt-out.\n\nHowever, Apple aids law enforcement in criminal investigations by providing iCloud backups of users' devices, and the company's commitment to privacy has been questioned by its efforts to promote biometric authentication technology in its newer iPhone models, which don't have the same level of constitutional privacy as a passcode in the United States.\n\nApple is a partner of (PRODUCT)RED, a fundraising campaign for AIDS charity. In November 2014, Apple arranged for all App Store revenue in a two-week period to go to the fundraiser, generating more than US$20 million, and in March 2017, it released an iPhone 7 with a red color finish.\n\nApple contributes financially to fundraisers in times of natural disasters. In November 2012, it donated $2.5million to the American Red Cross to aid relief efforts after Hurricane Sandy, and in 2017 it donated $5million to relief efforts for both Hurricane Irma and Hurricane Harvey, as well as for the 2017 Central Mexico earthquake. The company has also used its iTunes platform to encourage donations, including, but not limited to, help the American Red Cross in the aftermath of the 2010 Haiti earthquake, followed by similar procedure in the aftermath of the 2011 Japan earthquake, Typhoon Haiyan in the Philippines in November 2013, and European migrant crisis in September 2015. Apple emphasizes that it does not incur any processing or other fees for iTunes donations, sending 100% of the payments directly to relief efforts, though it also acknowledges that the Red Cross does not receive any personal information on the users donating and that the payments may not be tax deductible.\n\nOn April 14, 2016, Apple and the World Wide Fund for Nature (WWF) announced that they have engaged in a partnership to, \"help protect life on our planet.\" Apple released a special page in the iTunes App Store, Apps for Earth. In the arrangement, Apple has committed that through April 24, WWF will receive 100% of the proceeds from the applications participating in the App Store via both the purchases of any paid apps and the In-App Purchases. Apple and WWF's Apps for Earth campaign raised more than $8million in total proceeds to support WWF's conservation work. WWF announced the results at WWDC 2016 in San Francisco.\n\nApple has been criticised for alleged unethical business practices such as anti-competitive behavior, rash litigation, and dubious tax tactics, production methods involving the use of sweatshop labor, customer service issues involving allegedly misleading warranties and insufficient data security, as well as its products' environmental footprint. Critics have claimed that Apple products combine stolen and/or purchased designs that Apple claims are its original creations. Additionally, it has been criticized for its alleged collaboration with the U.S. surveillance program PRISM.\n\n\n\n"}
{"id": "19767941", "url": "https://en.wikipedia.org/wiki?curid=19767941", "title": "Bean harvester", "text": "Bean harvester\n\nA bean harvester, also known as a bean thresher or bean combine, is a threshing machine which is used to harvest beans. It mainly consists of a pickup, several beaters, shakers, one or several fans, elevators, conveyor belts, a storage bin, and usually a spreader at the rear. Until recently, the only practical manufacturer of bean harvesters was The Bidwell Bean Thresher Company. \n\nThe pickup lifts the beans, which are arranged into windrows by rakes and pullers, off the ground and onto the main conveyor belt which feeds them into the first beater, which has many metal teeth, turns high RPMs, and does a significant portion of the threshing. From there the process varies from machine to machine. Basically the beans go through a series of more beaters and shakers.\n\n"}
{"id": "2397174", "url": "https://en.wikipedia.org/wiki?curid=2397174", "title": "BioImage", "text": "BioImage\n\nBioImage was established in 1993 as a drug discovery research unit within Novo Nordisk. The research unit was led by Ole Thastrup and spun out of Novo Nordisk in 1999.\n\nBioImage specializes in developing and selling proprietary bioassays to biopharmaceutical companies and research institutions. It also develops bioassays on a contract service basis.\n\nBioImage has made broad patents covering Enhanced GFP (EGFP), GFP-based biosensors and any genetically encoded protein fusion to a luminophore, with subsequent monitoring of the protein's translocation within a cell as the primary readout for drug discovery assays. This intellectual property, trademarked Redistribution, allows many collaborations and out-licensing activities with biopharmaceutical companies.\n\nIn April 2006, BioImage was acquired by Thermo Fisher Scientific. The merger was complete in November 2006, and technology transfer to a US site was completed during 2007 and 2008.\n"}
{"id": "1142136", "url": "https://en.wikipedia.org/wiki?curid=1142136", "title": "Biosolids", "text": "Biosolids\n\nBiosolids is a term used for several types of treated sewage sludges that can be used as soil conditioner.\n\nTreated sewage sludge has long been used in agriculture, but there are concerns about offensive odors and disease risks from pathogens and toxic chemicals. This may reduce public acceptance of such reuse activities.\n\nBiosolids may be defined as organic wastewater solids that can be reused after suitable sewage sludge treatment processes leading to sludge stabilization such as anaerobic digestion and composting.\n\nAlternatively, the biosolids definition may be restricted by local regulations to wastewater solids only after those solids have completed a specified treatment sequence and/or have concentrations of pathogens and toxic chemicals below specified levels.\n\nThe United States Environmental Protection Agency (EPA) defines the two terms – sewage sludge and biosolids – in the Code of Federal Regulations (CFR), Title 40, Part 503 as follows: \"Sewage sludge\" refers to the solids separated during the treatment of municipal wastewater (including domestic septage), while \"biosolids\" refers to treated sewage sludge that meets the EPA pollutant and pathogen requirements for land application and surface disposal. A similar definition has been used internationally, for example in Australia.\n\nUse of the term \"biosolids\" may officially be subject to government regulations. However, informal use describes a broad range of semi-solid organic products produced from sewage or sewage sludge. This could include any solids, slime solids or liquid slurry residue generated during the treatment of domestic sewage including scum and solids removed during primary, secondary or advanced treatment processes. Materials that do not conform to the regulatory definition of \"biosolids\" can be given alternative terms like \"wastewater solids\".\n\nApproximately 7.1 million dry tons of biosolids were generated in 2004 at approximately 16,500 municipal wastewater treatment facilities in the United States.\n\nIn the United States, as of 2013 about 55% of sewage solids are turned into fertilizer. Challenges faced when increasing the use of biosolids include, the capital needed to build anaerobic digesters and the complexity of complying with health regulations. There are also new concerns about micro-pollutions in sewage (e.g. environmental persistent pharmaceutical pollutants) which make the process of producing high quality biosolids complex. Some municipalities, states or countries have banned the use of biosolids on farmland.\n\nEncouraging agricultural use of biosolids is intended to prevent filling landfills with nutrient-rich organic materials from the treatment of domestic sewage that might be recycled and applied as fertilizer to improve and maintain productive soils and stimulate plant growth. Biosolids can be an ideal agricultural conditioner and fertilizer which can help promote crop growth to feed the increasing population. Biosolids may contain macronutrients nitrogen, phosphorus, potassium and sulphur with micronutrients copper, zinc, calcium, magnesium, iron, boron, molybdenum and manganese.\n\nThe United States Environmental Protection Agency (EPA) and others have shown that biosolids can contain measurable levels of synthetic organic compounds, radionuclides and heavy metals. EPA has set numeric limits for arsenic, cadmium, copper, lead, mercury, molybdenum, nickel, selenium, and zinc but has not regulated dioxin levels.\n\nContaminants from pharmaceuticals and personal care products and some steroids and hormones may also be present in biosolids. Substantial levels of persistent, bioaccumulative and toxic (PBT) polybrominated diphenyl ethers were detected in biosolids in 2001.\n\nThe United States Geological Survey analyzed in 2014 nine different consumer products containing biosolids as a main ingredient for 87 organic chemicals found in cleaners, personal care products, pharmaceuticals, and other products. These analysis detected 55 of the 87 organic chemicals measured in at least one of the nine biosolid samples, with as many as 45 chemicals found in a single sample.\n\nIn 2014, the City of Charlotte discovered extreme levels of PCB's in their biosolids after being alerted by SCDHEC that illegal PCB dumping was taking place at regional waste water treatment plants across the state. Biosolids land application was halted after an emergency regulation was enacted by SCDHEC that outlawed any PCB contaminated biosolids from being land applied regardless if Class A or Class B. Very soon thereafter, SCDHEC expanded PCB fish consumption adviseries for nearly every waterway bordering biosolids land application fields.\n\nIn the United States the EPA mandates certain treatment processes designed to significantly decrease levels of certain so-called indicator organisms, in biosolids. These include, \"...operational standards for fecal coliforms, \"Salmonella\" sp. bacteria, enteric viruses, and viable helminth ova.\"\n\nHowever, the US-based Water Environment Research Foundation has shown that some pathogens do survive sewage sludge treatment.\n\nEPA regulations allow only biosolids with no detectable pathogens to be widely applied; those with remaining pathogens are restricted in use.\n\n\n\n\n\n\n\nIn the United States Code of Federal Regulations (CFR), Title 40, Part 503 governs the management of biosolids. Within that federal regulation biosolids are generally classified differently depending upon the quantity of pollutants they contain and the level of treatment they have been subjected to (the latter of which determines both the level of vector attraction reduction and the level of pathogen reduction). These factors also affect how they may be disseminated (bulk or bagged) and the level of monitoring oversight which, in turn determines where and in what quantity they may be applied.\n\nThe European Union (EU) was the first to issue regulations for biosolids land application; this aimed to put a limit to the pathogen and pollution risk. These risks come from the fact that some metabolites remain intact after waste water treatment processes. Debates over biosolid use vary in severity acros the EU and gathering acceptance is the major hurdle facing biosolids in Europe.\n\nAs public concern arose about the disposal of increased volumes of solids in the United States being removed from sewage during sewage treatment mandated by the Clean Water Act. The Water Environment Federation (WEF) sought a new name to distinguish the clean, agriculturally viable product generated by modern wastewater treatment from earlier forms of sewage sludge widely remembered for causing offensive or dangerous conditions. Of three-hundred suggestions, \"biosolids\" was attributed to Dr. Bruce Logan of the University of Arizona, and recognized by WEF in 1991.\n\n\n"}
{"id": "13319264", "url": "https://en.wikipedia.org/wiki?curid=13319264", "title": "Boston Computer Exchange", "text": "Boston Computer Exchange\n\nBoston Computer Exchange was the world's first e-commerce company, and dominated electronic trading in used computers in the US in the 1980s. The Boston Computer Exchange, also called the BCE and BoCoEx, were in operation before the Internet became widely available to the general public. Their Bulletin Board System-based marketplace utilized Delphi online service as a platform for an on-line database of products where buyers and sellers bought, sold and traded computers. The company pioneered efforts to create a fully automated, on-line auction and trade systems for general commerce and eventually turned into an Internet-based business.\n\nBoston Computer Exchange was founded in 1982 as a marketplace for people who wanted to sell their used computers. Initially it was a paper database but quickly moved into a computerized database using Alpha 2 database manager on a dual floppy IBM PC. Nascent bulletin board systems were just being developed and the founders struck a mutual agreement with the owners of the Delphi online service bulletin board system to post the database on their public access system. The first database upload was on March 4, 1983. Fresh data was posted every day from that day until the business closed in the 1990s. The database was also posted as a searchable database on YellowData, and then Boston CitiNet. Later, when CompuServe opened their Electronic Mall in 1989, Boston Computer Exchange had the first store on that Mall, too.\n\nThe founders of the Boston Computer Exchange were Alexander Randall 5th and Cameron Hall. Randall held a PhD in General Systems research or Systems Theory and Hall had degrees in Economics. They fused their interest in creating a computerized marketplace for trade. The husband and wife started the business on the dining room table and worked together on it steadily for the next 10 years. Hall and Randall had previously owned several small entrepreneurial ventures. Randall was the Godson of J. Presper Eckert and had been involved with computers from childhood. Hall's father had been involved with modems from the earliest days of datacomm - so each brought special skills to the project.\n\nLike later Internet based e-commerce systems such as eBay, sellers uploaded inventory to a database, buyers browsed inventory online but in this pre-Internet era, they consummated transactions by telephone. Buyers then paid Sellers, Sellers shipped goods to Buyers and the Exchange billed the seller a commission. After several years of operations and some bad transactions, the Exchange invented an escrow services to protect buyers, sellers and the Exchange itself. The absence of a verifiable way to close credit card transactions on-line prevented an \"all on-line\" trade system.\n\nIn 1986, the Exchange created an electronic trading system that was showcased at the COMDEX Trade Show in Las Vegas which attracting wide attention to their vision of an all-electronic, all \"on-line\" system for buying and selling all types of equipment. The BCENE auction trading system pre-dated all other efforts to create on-line trade and was widely viewed as a major innovation in how commerce would be conducted in all business areas. Standard Oil Company brought BoCoEx under contract and secured all rights to the system seeking advice on how to create a world-scale on-line trading system. Standard Oil pursued this for several years until that oil company was sold to British Petroleum and the idea was shelved but not scrapped. Standard Oil tried to sell the idea and the BoCoEx contracts to other companies and eventually abandoned the effort and released Randall and Hall from their exclusive consulting contracts.\n\nOn advice from futurist Wes Thomas, the Boston Computer Exchange created a weekly price report - called the BoCoEx Index, a report on the High, Low and Closing Price on the Exchange for the most popular computer models. Starting in 1983, this price list became a standard tool for assessing the value of computers in court cases, after market sales and in valuations of assets in corporate mergers and acquisitions. The report was published every week in ComputerWorld and PC Week magazines. The report dominated the used computer after market and was a standard news item in other computer magazines, much like stock prices in a daily newspaper. The BoCoEx Index was also a regular feature on the Business Radio Network and was used to create a ten-year report on the price declines of popular computer models.\n\nThe founders sought to create trading partners to trade on the exchange and they wrote a book of instructions called a \"Seat on the Exchange.\" It was first offered in 1986 and expanded in several subsequent editions. The book was a set of tools for creating a free standing computer trading enterprise in any city. At the peak there were 150 \"Computer Exchanges\" that had licensed technology from Boston Computer Exchange. Among them were the Southern Computer Exchange, The NaComEx, and \"seats\" in such places as San Francisco, Virginia, Maryland, Los Angeles, New Jersey, New York, and as far afield as Santiago Chile, Stockholm and Leningrad in Russia. The \"Seat\" book detailed the operations of the business and provided access to a national database operating on a private server.\n\nRandall also authored the \"Used Computer Handbook\" for Microsoft Press in 1990 which detailed how to safely buy and sell computers in the after market. NY Times article on BCE and Seat Book\n\nOn Jan 1, 1990, Randall and Hall sold the Exchange to ValCom - a computer retailer - and that business did not choose to vigorously pursue the on-line aspects of the Boston Computer Exchange - rather they focused on using the Exchange to sell excess inventory from the ValCom Stores. Nevertheless, the Exchange did create an \"All Auctions\" system in the early 1990s. The whole enterprise was later sold to Compaq Corporation and subsequently to Hewlett-Packard. The Boston Computer Exchange eventually ceased to operate and was closed.\n\nHall died of cancer in 1998. Randall is presently professor of communication at the University of the Virgin Islands.\n\n"}
{"id": "39536272", "url": "https://en.wikipedia.org/wiki?curid=39536272", "title": "Chappie (film)", "text": "Chappie (film)\n\nChappie (stylized as CHAPPiE) is a 2015 American dystopian science fiction action crime thriller film directed by Neill Blomkamp and written by Blomkamp and Terri Tatchell. It stars Sharlto Copley, Dev Patel, Jose Pablo Cantillo, Sigourney Weaver, Hugh Jackman, and Ninja and Yolandi Visser of the South African zef rap-rave group Die Antwoord as metafictional versions of themselves. The film, set and shot in Johannesburg, is about an artificially intelligent law enforcement robot captured and taught by gangsters, who nickname it Chappie.\n\n\"Chappie\" premiered in New York City on March 4, 2015, and was released in U.S. cinemas on March 6, 2015. The film grossed $102 million worldwide against a $49 million budget.\n\nA skyrocketing crime rate leads the city of Johannesburg, South Africa to buy a squadron of scouts—state-of-the-art armour-plated attack robots—from weapons manufacturer Tetravaal. These autonomous androids are developed by British scientist Deon Wilson and largely supplant the overwhelmed human police force. A competing project within the company is the remotely controlled MOOSE, developed by Australian soldier-turned-engineer Vincent Moore. Deon is praised for Tetravaal's success but Vincent grows envious when the police are unwilling to give his heavy weapons platform equal attention.\n\nAt home, Deon creates a prototype artificial intelligence that mimics a human mind to the point of feeling emotions and having opinions, but Tetravaal CEO Michelle Bradley refuses to let him test the A.I. on a police robot. Undeterred, Deon steals a recently damaged robot before it is destroyed and puts it in his van, along with the \"guard key\" needed to update the robot's software.\n\nOn his way home, he is kidnapped by a group of gangsters, Ninja, Yolandi, and Amerika, who threaten to kill him unless he reprograms a police robot to help them steal. Deon installs the new software into the damaged robot, which responds with child-like trepidation upon powering up. Deon and Yolandi calm the robot, teaching it words and naming it \"Chappie\". Despite Deon wanting to stay with the robot, Ninja forces him out of their hideout.\n\nNinja's gang only has a few days to pay a debt of 20 million rand to Hippo, a powerful gangster. Yolandi sees Chappie as a child and wants to mother him, but Ninja grows impatient with his development due to both the impending deadline for the debt and Chappie's irreplaceable battery running out, giving him days to live. Ninja tries to train Chappie to be a gangster by leaving him in a dangerous neighborhood to fend for himself. After being wounded by thugs, he is followed by Vincent, who plans to deactivate all Tetravaal scouts except for MOOSE. Vincent successfully extracts the guard key for his own use, but the traumatized Chappie escapes and returns to the hideout. Yolandi scolds Ninja for this mistreatment, but he manages to earn Chappie's forgiveness by training him in martial arts and weapon handling. Ninja and Amerika trick Chappie into stealing cars for them, and lie about needing the money to replace his dying body.\n\nAt Tetravaal, Vincent uses the guard key to upload a virus, thus sabotaging and disabling all scouts including Chappie. Johannesburg's criminals immediately run rampant in the streets, and Deon brings Chappie to the Tetravaal factory to fix him. After being restarted, Chappie notices a helmet used to control MOOSE. At the hideout, he re-engineers it to allow him to transfer his consciousness into a computer, so he can change bodies when his current one dies. Ninja's gang uses Chappie to rob an armored car, an act which is caught on the news, prompting Tetravaal to pursue him. When Chappie learns that Ninja's plan to acquire the body was a lie, he prepares to kill Ninja for betrayal. However, Deon arrives to warn them that Michelle Bradley has ordered that Chappie be destroyed. At that moment, the MOOSE robot (controlled remotely by Vincent) is launched to assassinate Deon and Chappie at the hideout, at the same time that Hippo arrives to collect his debt. Amerika and Hippo are killed in the ensuing battle, while Deon is mortally wounded. When Ninja is about to be killed, Yolandi sacrifices herself to save him and Chappie destroys MOOSE by detonating a bomb.\n\nEnraged by Yolandi's death, Chappie drives Deon to the factory, storms into an office, and fiercely beats Vincent close to death. He then transfers the dying Deon's consciousness into a spare robot through the modified MOOSE helmet. In return, the now-robotic Deon wirelessly transfers Chappie's consciousness into one of the nearby disabled scouts. Deon and Chappie go into hiding as the police discontinue their contract with Tetravaal. While burning memorabilia of Yolandi, the grieving Ninja finds a box containing a doll copy of her and a flash drive marked \"Mommy's Consciousness Test Backup\" which contains a copy of Yolandi's consciousness that Chappie took while testing the device on her. Chappie hacks into Tetravaal's manufacturing facility, builds a robot resembling Yolandi, and uploads the drive's contents.\n\n\n\"Chappie\" is Blomkamp's third feature-length film as director. He wrote the screenplay along with his wife Terri Tatchell, who also co-wrote \"District 9\". It was unofficially based on Blomkamp's 2004 short film \"Tetra Vaal\". They wrote \"Chappie\" in two weeks, while Blomkamp was doing \"Elysium\". Filming began at the end of October 2013 in Johannesburg, South Africa. One scene was shot at the Ponte building. Filming was completed in February 2014. Re-shooting for the film took place in British Columbia, Canada in April 2014. The film was shot with Red Epic cameras, using Panavision anamorphic primes. Richard Muller said: \n\nLighting was handled by Kino Flo Celebs. The visual effects company was Image Engine, located in Vancouver. The name of the weapons company in \"Chappie\" – \"Tetravaal\" – is a reference to Blomkamp's 2003 short film of the same name, which centers on a police robot in Johannesburg with a similar design to Chappie. Blomkamp has said that \"Chappie\" is \"basically based\" on \"Tetra Vaal\". Blomkamp also employed a robot with a similar design in his 2005 short \"Tempbot\", and both \"Tempbot\" and his 2006 short/advertisement \"Yellow\" deal with a thinking and learning robot which tries to assimilate into society.\n\nBlomkamp has cited the \"Appleseed\" character Briareos as an influence on the design of Chappie.\n\nOn February 6, 2015, IMAX Corporation and Sony announced that the film would be digitally re-mastered into the IMAX format and released into IMAX theatres domestically on March 6, 2015. The film made its New York premiere on March 4, 2015. The film was released in the United States on March 6, 2015.\n\n\"Chappie\" grossed $31.6 million in North America and $70 million in other territories for a total gross of $102.1 million, against a budget of $49 million.\n\nThe film earned $4.6 million in its opening day, $5.3 million on its second day, and $3.5 million on its third day, totaling $13.4 million in its opening weekend, while playing in 3,201 theaters. It had a $4,155 per-theater average and finished first at the box office.\n\nReview aggregator website Rotten Tomatoes reported a 32% approval rating, based on 207 reviews, and a rating average of 4.9/10. The website's critical consensus reads, \"\"Chappie\" boasts more of the big ideas and visual panache that director Neill Blomkamp has become known for — and, sadly, more of the narrative shortcomings.\" On Metacritic, which assigns a normalized rating, the film has a score of 41 out of 100, based on 39 critics, indicating \"mixed or average reviews\". According to CinemaScore, audiences gave the film a grade of \"B\" on an A+ to F scale.\n\nJustin Chang of \"Variety\" wrote, \"Intelligence, artificial or otherwise, is one of the major casualties of \"Chappie\", a robot-themed action movie that winds up feeling as clunky and confused as the childlike droid with which it shares its name.\" Todd McCarthy of \"The Hollywood Reporter\" wrote, \"With unappealing one-note characters, retread concepts and implausible motivations, \"Chappie\" is a further downward step for director Neill Blomkamp.\" Tim Grierson of \"Screen International\" wrote, \"...despite his ambitions, \"Chappie\" is a bucket of bolts, Blomkamp's desire to say meaningful things outdistancing his ability to say them compellingly.\" Manohla Dargis of \"The New York Times\" wrote that Blomkamp \"struggles with the material\" but \"even at his shakiest, Mr. Blomkamp holds your attention\". Kenneth Turan of the \"Los Angeles Times\" called it \"cartoonish and preposterous, and not in a good way\".\n\nMick LaSalle of the \"San Francisco Chronicle\" rated it three out of four stars and wrote of Blomkamp, \"It's hard to say how much he's doing consciously and how much he's doing through intuition, but he's doing really interesting things in \"Chappie\", and right from the beginning.\" Tom Huddleston of \"Time Out London\" rated it four out of five stars and wrote that \"this hugely entertaining oddity could never be mistaken for the work of any other filmmaker\". Ryan Lambie, from denofgeek.com, gave the film a positive review stating, \"Despite the ragged edges of its story, \"Chappie\" nevertheless has real heart beating under its shabby exterior. If you liked the director's previous films, you owe it to yourself to see this one too.\" IGN reviewer Josh Lasser also gave Chappie a positive review, with a 'Good' score of 7.6 out of 10. He praised Sharlto Copley's performance and the \"big questions\" it asks, but criticized its failure to answer those questions. Several reviewers compared the Chappie character unfavorably to Jar Jar Binks of \"Star Wars\". Sameen Amer of \"The Express Tribune\" opined that the film disregards logic as certain \"existential quandaries\" are randomly thrown in without straightening out any of the themes before moving on to the next.\n\nBlomkamp said he \"wrote \"Chappie\" as a trilogy\" and expressed interest in making sequels if they were \"economically feasible\". As of November 2016, no sequels are planned. Blomkamp said the film did not perform well enough.\n\n"}
{"id": "1689615", "url": "https://en.wikipedia.org/wiki?curid=1689615", "title": "DFMA", "text": "DFMA\n\nDFMA stands for Design for Manufacture and Assembly. DFMA is the combination of two methodologies; Design for Manufacture, which means the design for ease of manufacture of the parts that will form a product, and Design for Assembly, which means the design of the product for ease of assembly.\n\nDFMA is used as the basis for concurrent engineering studies to provide guidance to the design team in simplifying the product structure, to reduce manufacturing and assembly costs, and to quantify improvements. The practice of applying DFMA is to identify, quantify and eliminate waste or inefficiency in a product design. DFMA is therefore a component of Lean Manufacturing\nDFMA is also used as a benchmarking tool to study competitors’ products, and as a should cost tool to assist in supplier negotiations.\n\nDFMA is the name of the integrated set of software products from Boothroyd Dewhurst, Inc. that are used by companies to implement the DFMA methodology. DFMA is a registered trademark of Boothroyd Dewhurst, Inc.\n\n"}
{"id": "56228", "url": "https://en.wikipedia.org/wiki?curid=56228", "title": "Dairy", "text": "Dairy\n\nA dairy is a business enterprise established for the harvesting or processing (or both) of animal milk – mostly from cows or goats, but also from buffaloes, sheep, horses, or camels – for human consumption. A dairy is typically located on a dedicated dairy farm or in a section of a multi-purpose farm (mixed farm) that is concerned with the harvesting of milk.\n\nTerminology differs between countries. For example, in the United States, an entire dairy farm is commonly called a \"dairy\". The building or farm area where milk is harvested from the cow is often called a \"milking parlor\" or \"parlor\". The farm area where milk is stored in bulk tanks is known as the farm's \"milk house\". Milk is then hauled (usually by truck) to a \"dairy plant\" = also referred to as a \"dairy\" - where raw milk is further processed and prepared for commercial sale of dairy products. In New Zealand, farm areas for milk harvesting are also called \"milking parlours\", and are historically known as \"milking sheds\". As in the United States, sometimes milking sheds are referred to by their type, such as \"herring bone shed\" or \"pit parlour\". Parlour design has evolved from simple barns or sheds to large rotary structures in which the workflow (throughput of cows) is very efficiently handled. In some countries, especially those with small numbers of animals being milked, the farm may perform the functions of a dairy plant, processing their own milk into salable dairy products, such as butter, cheese, or yogurt. This on-site processing is a traditional method of producing specialist milk products, common in Europe.\n\nIn the United States a \"dairy\" can also be a place that processes, distributes and sells dairy products, or a room, building or establishment where milk is stored and processed into milk products, such as butter or cheese. In New Zealand English the singular use of the word \"dairy\" almost exclusively refers to a corner shop, or superette. This usage is historical as such shops were a common place for the public to buy milk products.\n\nAs an attributive, the word \"dairy\" refers to milk-based products, derivatives and processes, and the animals and workers involved in their production: for example dairy cattle, dairy goat. A dairy farm produces milk and a dairy factory processes it into a variety of dairy products. These establishments constitute the global dairy industry, a component of the food industry.\n\nMilk producing animals have been domesticated for thousands of years. Initially, they were part of the subsistence farming that nomads engaged in. As the community moved about the country, their animals accompanied them. Protecting and feeding the animals were a big part of the symbiotic relationship between the animals and the herders.\n\nIn the more recent past, people in agricultural societies owned dairy animals that they milked for domestic and local (village) consumption, a typical example of a cottage industry. The animals might serve multiple purposes (for example, as a draught animal for pulling a plough as a youngster, and at the end of its useful life as meat). In this case the animals were normally milked by hand and the herd size was quite small, so that all of the animals could be milked in less than an hour—about 10 per milker. These tasks were performed by a \"dairymaid\" (\"dairywoman\") or \"dairyman\". The word \"dairy\" harkens back to Middle English \"dayerie\", \"deyerie\", from \"deye\" (female servant or dairymaid) and further back to Old English \"dæge\" (kneader of bread).\n\nWith industrialisation and urbanisation, the supply of milk became a commercial industry, with specialised breeds of cattle being developed for dairy, as distinct from beef or draught animals. Initially, more people were employed as milkers, but it soon turned to mechanisation with machines designed to do the milking.\nHistorically, the milking and the processing took place close together in space and time: on a dairy farm. People milked the animals by hand; on farms where only small numbers are kept, hand-milking may still be practiced. Hand-milking is accomplished by grasping the teats (often pronounced \"tit\" or \"tits\") in the hand and expressing milk either by squeezing the fingers progressively, from the udder end to the tip, or by squeezing the teat between thumb and index finger, then moving the hand downward from udder towards the end of the teat. The action of the hand or fingers is designed to close off the milk duct at the udder (upper) end and, by the movement of the fingers, close the duct progressively to the tip to express the trapped milk. Each half or quarter of the udder is emptied one milk-duct capacity at a time.\n\nThe \"stripping\" action is repeated, using both hands for speed. Both methods result in the milk that was trapped in the milk duct being squirted out the end into a bucket that is supported between the knees (or rests on the ground) of the milker, who usually sits on a low stool.\n\nTraditionally the cow, or cows, would stand in the field or paddock while being milked. Young stock, heifers, would have to be trained to remain still to be milked. In many countries, the cows were tethered to a post and milked.\n\nWhile most countries produce their own milk products, the structure of the dairy industry varies in different parts of the world. In major milk-producing countries most milk is distributed through whole sale markets. In Ireland and Australia, for example, farmers' co-operatives own many of the large-scale processors, while in the United States many farmers and processors do business through individual contracts. In the United States, the country's 196 farmers' cooperatives sold 86% of milk in the U.S. in 2002, with five cooperatives accounting for half that. This was down from 2,300 cooperatives in the 1940s. In developing countries, the past practice of farmers marketing milk in their own neighborhoods is changing rapidly. Notable developments include considerable foreign investment in the dairy industry and a growing role for dairy cooperatives. Output of milk is growing rapidly in such countries and presents a major source of income growth for many farmers.\n\nAs in many other branches of the food industry, dairy processing in the major dairy producing countries has become increasingly concentrated, with fewer but larger and more efficient plants operated by fewer workers. This is notably the case in the United States, Europe, Australia and New Zealand. In 2009, charges of anti-trust violations have been made against major dairy industry players in the United States, which critics call Big Milk. Another round of price fixing charges was settled in 2016.\n\nGovernment intervention in milk markets was common in the 20th century. A limited anti-trust exemption was created for U.S. dairy cooperatives by the Capper-Volstead Act of 1922. In the 1930s, some U.S. states adopted price controls, and Federal Milk Marketing Orders started under the Agricultural Marketing Agreement Act of 1937 and continue in the 2000s. The Federal Milk Price Support Program began in 1949. The Northeast Dairy Compact regulated wholesale milk prices in New England from 1997 to 2001.\n\nPlants producing liquid milk and products with short shelf life, such as yogurts, creams and soft cheeses, tend to be located on the outskirts of urban centres close to consumer markets. Plants manufacturing items with longer shelf life, such as butter, milk powders, cheese and whey powders, tend to be situated in rural areas closer to the milk supply. Most large processing plants tend to specialise in a limited range of products. Exceptionally, however, large plants producing a wide range of products are still common in Eastern Europe, a holdover from the former centralized, supply-driven concept of the market under Communist governments.\n\nAs processing plants grow fewer and larger, they tend to acquire bigger, more automated and more efficient equipment. While this technological tendency keeps manufacturing costs lower, the need for long-distance transportation often increases the environmental impact.\n\nMilk production is irregular, depending on cow biology. Producers must adjust the mix of milk which is sold in liquid form vs. processed foods (such as butter and cheese) depending on changing supply and demand.\n\nWhen it became necessary to milk larger cows, the cows would be brought to a shed or barn that was set up with stalls (milking stalls) where the cows could be confined their whole live while they were milked. One person could milk more cows this way, as many as 20 for a skilled worker. But having cows standing about in the yard and shed waiting to be milked is not good for the cow, as she needs as much time in the paddock grazing as is possible. It is usual to restrict the twice-daily milking to a maximum of an hour and a half each time. It makes no difference whether one milks 10 or 1000 cows, the milking time should not exceed a total of about three hours each day for any cow as they should be in stalls and laying down as long as possible to increase comfort which will in turn aid in milk production. A cow is only physically milked for about 10 minutes a day depending on her milk letdown time and the amount of milkings per day.\n\nAs herd sizes increased there was more need to have efficient milking machines, sheds, milk-storage facilities (vats), bulk-milk transport and shed cleaning capabilities and the means of getting cows from paddock to shed and back.\n\nAs herd numbers increased so did the problems of animal health. In New Zealand two approaches to this problem have been used. The first was improved veterinary medicines (and the government regulation of the medicines) that the farmer could use. The other was the creation of \"veterinary clubs\" where groups of farmers would employ a veterinarian (vet) full-time and share those services throughout the year. It was in the vet's interest to keep the animals healthy and reduce the number of calls from farmers, rather than to ensure that the farmer needed to call for service and pay regularly.\n\nThis daily milking routine goes on for about 300 to 320 days per year that the cow stays in milk. Some small herds are milked once a day for about the last 20 days of the production cycle but this is not usual for large herds. If a cow is left unmilked just once she is likely to reduce milk-production almost immediately and the rest of the season may see her \"dried off\" (giving no milk) and still consuming feed. However, once-a-day milking is now being practised more widely in New Zealand for profit and lifestyle reasons. This is effective because the fall in milk yield is at least partially offset by labour and cost savings from milking once per day. This compares to some intensive farm systems in the United States that milk three or more times per day due to higher milk yields per cow and lower marginal labor costs.\n\nFarmers who are contracted to supply liquid milk for human consumption (as opposed to milk for processing into butter, cheese, and so on—see milk) often have to manage their herd so that the contracted number of cows are in milk the year round, or the required minimum milk output is maintained. This is done by mating cows outside their natural mating time so that the period when each cow in the herd is giving maximum production is in rotation throughout the year.\n\nNorthern hemisphere farmers who keep cows in barns almost all the year usually manage their herds to give continuous production of milk so that they get paid all year round. In the southern hemisphere the cooperative dairying systems allow for two months on no productivity because their systems are designed to take advantage of maximum grass and milk production in the spring and because the milk processing plants pay bonuses in the dry (winter) season to carry the farmers through the mid-winter break from milking. It also means that cows have a rest from milk production when they are most heavily pregnant. Some year-round milk farms are penalised financially for overproduction at any time in the year by being unable to sell their overproduction at current prices.\n\nArtificial insemination (AI) is common in all high-production herds in order to improve the genetics of the female offspring which will be raised for replacements. AI also reduces the need for keeping potentially dangerous bulls on the farm. Male calves are sold to be raised for beef or veal. A cow will calve or freshen about once a year, until she is culled because of declining production, infertility or other health problems. Then the cow will be sold, most often going to slaughter.\n\nDairy plants process the raw milk they receive from farmers so as to extend its marketable life. Two main types of processes are employed: heat treatment to ensure the safety of milk for human consumption and to lengthen its shelf-life, and dehydrating dairy products such as butter, hard cheese and milk powders so that they can be stored.\n\nToday, milk is separated by huge machines in bulk into cream and skim milk. The cream is processed to produce various consumer products, depending on its thickness, its suitability for culinary uses and consumer demand, which differs from place to place and country to country.\n\nSome milk is dried and powdered, some is condensed (by evaporation) mixed with varying amounts of sugar and canned. Most cream from New Zealand and Australian factories is made into butter. This is done by churning the cream until the fat globules coagulate and form a monolithic mass. This butter mass is washed and, sometimes, salted to improve keeping qualities. The residual buttermilk goes on to further processing. The butter is packaged (25 to 50 kg boxes) and chilled for storage and sale. At a later stage these packages are broken down into home-consumption sized packs.\n\nThe product left after the cream is removed is called skim, or skimmed, milk. To make a consumable liquid a portion of cream is returned to the skim milk to make \"low fat milk\" (semi-skimmed) for human consumption. By varying the amount of cream returned, producers can make a variety of low-fat milks to suit their local market. Whole milk is also made by adding cream back to the skim to form a standardized product. Other products, such as calcium, vitamin D, and flavouring, are also added to appeal to consumers.\n\nCasein is the predominant phosphoprotein found in fresh milk. It has a very wide range of uses from being a filler for human foods, such as in ice cream, to the manufacture of products such as fabric, adhesives, and plastics.\n\nCheese is another product made from milk. Whole milk is reacted to form curds that can be compressed, processed and stored to form cheese. In countries where milk is legally allowed to be processed without pasteurization, a wide range of cheeses can be made using the bacteria found naturally in the milk. In most other countries, the range of cheeses is smaller and the use of artificial cheese curing is greater. Whey is also the byproduct of this process. Some people with lactose intolerance are surprisingly able to eat certain types of cheese. This is because some traditionally made hard cheeses, and soft ripened cheeses may create less reaction than the equivalent amount of milk because of the processes involved. Fermentation and higher fat content contribute to lesser amounts of lactose. Traditionally made Emmental or Cheddar might contain 10% of the lactose found in whole milk. In addition, the aging methods of traditional cheeses (sometimes over two years) reduce their lactose content to practically nothing. Commercial cheeses, however, are often manufactured by processes that do not have the same lactose-reducing properties. Ageing of some cheeses is governed by regulations; in other cases there is no quantitative indication of degree of ageing and concomitant lactose reduction, and lactose content is not usually indicated on labels.\n\nIn earlier times, whey or milk serum was considered to be a waste product and it was, mostly, fed to pigs as a convenient means of disposal. Beginning about 1950, and mostly since about 1980, lactose and many other products, mainly food additives, are made from both casein and cheese whey.\n\nYogurt (or yoghurt) making is a process similar to cheese making, only the process is arrested before the curd becomes very hard.\n\nMilk is also processed by various drying processes into powders. Whole milk, skim milk, buttermilk, and whey products are dried into a powder form and used for human and animal consumption. The main difference between production of powders for human or for animal consumption is in the protection of the process and the product from contamination. Some people drink milk reconstituted from powdered milk, because milk is about 88% water and it is much cheaper to transport the dried product.\n\nKumis is produced commercially in Central Asia. Although it is traditionally made from mare's milk, modern industrial variants may use cow's milk instead.\n\nOriginally, milking and processing took place on the dairy farm itself. Later, cream was separated from the milk by machine on the farm, and transported to a factory to be made into butter. The skim milk was fed to pigs. This allowed for the high cost of transport (taking the smallest volume high-value product), primitive trucks and the poor quality of roads. Only farms close to factories could afford to take whole milk, which was essential for cheesemaking in industrial quantities, to them.\n\nOriginally milk was distributed in 'pails', a lidded bucket with a handle. These proved impractical for transport by road or rail, and so the milk churn was introduced, based on the tall conical shape of the butter churn. Later large railway containers, such as the British Railway Milk Tank Wagon were introduced, enabling the transport of larger quantities of milk, and over longer distances.\n\nThe development of refrigeration and better road transport, in the late 1950s, has meant that most farmers milk their cows and only temporarily store the milk in large refrigerated bulk tanks, from where it is later transported by truck to central processing facilities.\n\nIn many European countries, particularly the United Kingdom, milk is then delivered direct to customers' homes by a milk float.\n\nMilking machines are used to harvest milk from cows when manual milking becomes inefficient or labour-intensive. One early model was patented in 1907. The milking unit is the portion of a milking machine for removing milk from an udder. It is made up of a claw, four teatcups, (Shells and rubber liners) long milk tube, long pulsation tube, and a pulsator. The claw is an assembly that connects the short pulse tubes and short milk tubes from the teatcups to the long pulse tube and long milk tube. (Cluster assembly) Claws are commonly made of stainless steel or plastic or both. Teatcups are composed of a rigid outer shell (stainless steel or plastic) that holds a soft inner liner or \"inflation\". Transparent sections in the shell may allow viewing of liner collapse and milk flow. The annular space between the shell and liner is called the pulse chamber.\n\nMilking machines work in a way that is different from hand milking or calf suckling. Continuous vacuum is applied inside the soft liner to massage milk from the teat by creating a pressure difference across the teat canal (or opening at the end of the teat). Vacuum also helps keep the machine attached to the cow. The vacuum applied to the teat causes congestion of teat tissues (accumulation of blood and other fluids). Atmospheric air is admitted into the pulsation chamber about once per second (the pulsation rate) to allow the liner to collapse around the end of teat and relieve congestion in the teat tissue. The ratio of the time that the liner is open (milking phase) and closed (rest phase) is called the pulsation ratio.\n\nThe four streams of milk from the teatcups are usually combined in the claw and transported to the milkline, or the collection bucket (usually sized to the output of one cow) in a single milk hose. Milk is then transported (manually in buckets) or with a combination of airflow and mechanical pump to a central storage vat or bulk tank. Milk is refrigerated on the farm in most countries either by passing through a heat-exchanger or in the bulk tank, or both.\n\nThe photo to the right shows a bucket milking system with the stainless steel bucket visible on the far side of the cow. The two rigid stainless steel teatcup shells applied to the front two quarters of the udder are visible. The top of the flexible liner is visible at the top of the shells as are the short milk tubes and short pulsation tubes extending from the bottom of the shells to the claw. The bottom of the claw is transparent to allow observation of milk flow. When milking is completed the vacuum to the milking unit is shut off and the teatcups are removed.\n\nMilking machines keep the milk enclosed and safe from external contamination. The interior 'milk contact' surfaces of the machine are kept clean by a manual or automated washing procedures implemented after milking is completed. Milk contact surfaces must comply with regulations requiring food-grade materials (typically stainless steel and special plastics and rubber compounds) and are easily cleaned.\n\nMost milking machines are powered by electricity but, in case of electrical failure, there can be an alternative means of motive power, often an internal combustion engine, for the vacuum and milk pumps.\n\nThis type of milking facility was the first development, after open-paddock milking, for many farmers. The building was a long, narrow, \"lean-to\" shed that was open along one long side. The cows were held in a yard at the open side and when they were about to be milked they were positioned in one of the bails (stalls). Usually the cows were restrained in the bail with a breech chain and a rope to restrain the outer back leg. The cow could not move about excessively and the milker could expect not to be kicked or trampled while sitting on a (three-legged) stool and milking into a bucket. When each cow was finished she backed out into the yard again. The UK bail, initially developed by Wiltshire dairy farmer Arthur Hosier, was a six standing mobile shed with steps that the cow mounted, so the herdsman didn't have to bend so low. The milking equipment was much as today, a vacuum from a pump, pulsators, a claw-piece with pipes leading to the four shells and liners that stimulate and suck the milk from the teat. The milk went into churns, via a cooler.\n\nAs herd sizes increased a door was set into the front of each bail so that when the milking was done for any cow the milker could, after undoing the leg-rope and with a remote link, open the door and allow her to exit to the pasture. The door was closed, the next cow walked into the bail and was secured. When milking machines were introduced bails were set in pairs so that a cow was being milked in one paired bail while the other could be prepared for milking. When one was finished the machine's cups are swapped to the other cow. This is the same as for \"Swingover Milking Parlours\" as described below except that the cups are loaded on the udder from the side. As herd numbers increased it was easier to double-up the cup-sets and milk both cows simultaneously than to increase the number of bails. About 50 cows an hour can be milked in a shed with 8 bails by one person. Using the same teat cups for successive cows has the danger of transmitting infection, mastitis, from one cow to another. Some farmers have devised their own ways to disinfect the clusters between cows.\n\nIn herringbone milking sheds, or parlours, cows enter, in single file, and line up almost perpendicular to the central aisle of the milking parlour on both sides of a central pit in which the milker works (you can visualise a fishbone with the ribs representing the cows and the spine being the milker's working area; the cows face outward). After washing the udder and teats the cups of the milking machine are applied to the cows, from the rear of their hind legs, on both sides of the working area. Large herringbone sheds can milk up to 600 cows efficiently with two people.\n\nSwingover parlours are the same as herringbone parlours except they have only one set of milking cups to be shared between the two rows of cows, as one side is being milked the cows on the other side are moved out and replaced with unmilked ones. The advantage of this system is that it is less costly to equip, however it operates at slightly better than half-speed and one would not normally try to milk more than about 100 cows with one person.\nRotary milking sheds (also known as Rotary milking parlor) consist of a turntable with about 12 to 100 individual stalls for cows around the outer edge. A \"good\" rotary will be operated with 24–32 (~48–50+) stalls by one (two) milkers. The turntable is turned by an electric-motor drive at a rate that one turn is the time for a cow to be milked completely. As an empty stall passes the entrance a cow steps on, facing the center, and rotates with the turntable. The next cow moves into the next vacant stall and so on. The operator, or milker, cleans the teats, attaches the cups and does any other feeding or whatever husbanding operations that are necessary. Cows are milked as the platform rotates. The milker, or an automatic device, removes the milking machine cups and the cow backs out and leaves at an exit just before the entrance. The rotary system is capable of milking very large herds—over a thousand cows.\n\nAutomatic milking or 'robotic milking' sheds can be seen in Australia, New Zealand, the U.S., Canada, and many European countries. Current automatic milking sheds use the voluntary milking (VM) method. These allow the cows to voluntarily present themselves for milking at any time of the day or night, although repeat visits may be limited by the farmer through computer software. A robot arm is used to clean teats and apply milking equipment, while automated gates direct cow traffic, eliminating the need for the farmer to be present during the process. The entire process is computer controlled.\n\nFarmers soon realised that a milking shed was a good place to feed cows supplementary foods that overcame local dietary deficiencies or added to the cows' wellbeing and production. Each bail might have a box into which such feed is delivered as the cow arrives so that she is eating while being milked. A computer can read the eartag of each animal to ration the correct individual supplement. A close alternative is to use 'out-of-parlour-feeders', stalls that respond to a transponder around the cow's neck that is programmed to provide each cow with a supplementary feed, the quantity dependent on her production, stage in lactation, and the benefits of the main ration\n\nThe holding yard at the entrance of the shed is important as a means of keeping cows moving into the shed. Most yards have a powered gate that ensures that the cows are kept close to the shed.\n\nWater is a vital commodity on a dairy farm: cows drink about 20 gallons (80 litres) a day, sheds need water to cool and clean them. Pumps and reservoirs are common at milking facilities. Water can be warmed by heat transfer with milk.\n\nMilk coming from the cow is transported to a nearby storage vessel by the airflow leaking around the cups on the cow or by a special \"air inlet\" (5-10 l/min free air) in the claw. From there it is pumped by a mechanical pump and cooled by a heat exchanger. The milk is then stored in a large vat, or bulk tank, which is usually refrigerated until collection for processing.\n\nIn countries where cows are grazed outside year-round, there is little waste disposal to deal with. The most concentrated waste is at the milking shed, where the animal waste may be liquefied (during the water-washing process) or left in a more solid form, either to be returned to be used on farm ground as organic fertilizer.\n\nIn the associated milk processing factories, most of the waste is washing water that is treated, usually by composting, and spread on farm fields in either liquid or solid form. This is much different from half a century ago, when the main products were butter, cheese and casein, and the rest of the milk had to be disposed of as waste (sometimes as animal feed).\n\nIn dairy-intensive areas, various methods have been proposed for disposing of large quantities of milk. Large application rates of milk onto land, or disposing in a hole, is problematic as the residue from the decomposing milk will block the soil pores and thereby reduce the water infiltration rate through the soil profile. As recovery of this effect can take time, any land-based application needs to be well managed and considered. Other waste milk disposal methods commonly employed include solidification and disposal at a solid waste landfill, disposal at a wastewater treatment plant, or discharge into a sanitary sewer.\n\nDairy products manufactured under unsanitary or unsuitable conditions have an increased chance of containing bacteria. Proper sanitation practices help to reduce the rate of bacterial contamination, and pasteurization greatly decreases the amount of contaminated milk that reaches the consumer. Many countries have required government oversight and regulations regarding dairy production, including requirements for pasteurization.\n\nA portion of the population, including many vegans and Jains, object to dairy production as unethical, cruel to animals, and environmentally deleterious. They do not consume dairy products. They state that cattle suffer under conditions employed by the dairy industry.\n\nIn 1937, it was found that bovine somatotropin (BST or bovine growth hormone) would increase the yield of milk. Several pharmaceutical companies developed commercial rBST products and they have been approved for use in the US, Mexico, Brazil, India, Russia, and at least ten others. The World Health Organization, and others have stated that dairy products and meat from BST-treated cows are safe for human consumption. However, based on negative animal welfare effects, rBST has not been allowed in Canada, Australia, New Zealand, Japan, Israel, or the European Union since 2000 - and in the U.S. has lost popularity due to consumer demands for rBST-free cows, with only about 17% of all cows in America now receiving rBST.\n\n\n\n"}
{"id": "33996417", "url": "https://en.wikipedia.org/wiki?curid=33996417", "title": "Data center services", "text": "Data center services\n\nData center services encompass all of the services and facility-related components or activities that support the implementation, maintenance, operation, and enhancement of a data center, which is an environment that provides processing, storage, networking, management and the distribution of data within an enterprise.\n\nGenerally, data center services fall into two categories: services provided to a data center or services provided from a data center.\nSupport services for the data center can be generally defined as technical support, which provides assistance to help solve problems related to technology products. Technical support services for data centers help to address challenges with the servers, storage, software and networking equipment that constitute a data center, or the related processes involved in managing data center equipment. Data center support services can also include installing and configuring technical equipment. Careers in this industry include (1) Technical Support Analyst, (2) Help Desk Engineer or (3) Information Support Specialists.\n\nConsulting and integration services provide expertise and input to help organizations make strategic decisions and systems integrations. Technical consulting services are one specific type of service that falls under the overall consulting services umbrella. Technical consulting services provide guidance and expertise on the application of technology. This can include selecting or designing new technology, redesigning existing technology, migrating existing technology to a new environment, or integrating new technology into existing technology. Examples of technical consulting services specific to data center services might include selecting a new data center location, consolidation, virtualization, automation, redesigning data centers for cloud computing, implementing storage arrays, or incorporating offsite storage services into an existing network.\n\nIT outsourcing occurs when one company (the outsourcing customer) contracts with an outsourcing vendor to provide IT services that the customer would otherwise deliver in-house. Such IT services could be disaster recovery, data storage or other IT functions. Outsourcing services for the data center can range from hosting, managing and maintaining an entire data center to more discrete data center tasks such as upgrading servers or backing up data.\n\nThe definition of application services varies depending on the type of company offering the services. An application service provider is a large segment within application services that provides software-based services to other companies that access those services over a network. Examples of ASP services include Web hosting and e-mail hosting. Application services can also include any service that helps companies develop, integrate or manage applications for their own networks. Services in this category can include applications for mobile environments and devices. Careers include, (1) Application Support Analysts, (2) Applications Engineer or (3) Business Analyst.\n\nThe specific definition of technical training varies depending on the industry and the job. The word \"technical\" simply indicates that something (a task, duty or job skill) is peculiar to a specific art, science, profession, trade or the like. Technical training services, therefore, provide knowledge, skills and competencies that apply to a specific job, trade or profession. Within the umbrella of data center services, technical training services can provide skills relevant to any of the hardware, software or processes related to managing a data center, or fixing, updating, integrating or managing any of the equipment within a data center.\n\nFinancing and leasing services provide a means for individuals or companies to acquire goods without any initial capital outlay. Financing is the act of acquiring capital for a purchase or some other activity. Financing services are offered by lenders (a bank or other institution) that provide capital to other individuals or companies in the form of a loan, which is then paid back within a predetermined time period for a set fee or interest rate. Leasing is the act of entering into a contractual arrangement (i.e. a lease) to obtain temporary possession of an asset (land, equipment, etc.) in exchange for a fixed compensation (for example, a monthly payment). Leasing services are provided by organizations that either manage the lease and payment transactions, furnish the assets or land that is being leased, or both. Financing and leasing services within the context of data center services might include leasing a data center facility; leasing data center equipment, such as servers; or financing a data center project, such as building or upgrading a data center facility.\n"}
{"id": "36674570", "url": "https://en.wikipedia.org/wiki?curid=36674570", "title": "Debubblizer", "text": "Debubblizer\n\nA debubblizer is a surface tension reducing agent that is used to reduce the prevalence of bubbles in industrial processes such as wax casting.\n"}
{"id": "32733136", "url": "https://en.wikipedia.org/wiki?curid=32733136", "title": "European Society for the History of Photography", "text": "European Society for the History of Photography\n\nThe European Society for the History of Photography (ESHPh), founded in 1978, is a society concerned with the historical events within photography from a European perspective.\n\nThe ESHPh publicly hosts symposia, publishes journals, and distributes the \"International Letter\" to its members. The ESHPh is actively chronicling the historiography of the history of photography in Europe.\n\nThe founding of the Europäischen Gesellschaft für die Geschichte der Photographie (ESHPh) [European Society for the History of Photography] took place at the first general meeting on 19 November 1978 in Leverkusen, Germany. The decision to form a society of this nature had been taken one year earlier in Antwerp, Belgium. A group of museum curators and photographic historians from six European countries - notably Laurent Roosens (of the Sterckshof Museum, Antwerp), Margaret Harker (the UK's Royal Photographic Society) and Rolf Krauss (Deutsche Gesellschafte für Photographie) - came together to establish a new society dealing with the history of photography in a European context.\n\nSince 2001, the presidential headquarters are to be found in Vienna. From 1978 until 1989, those headquarters were in Antwerp; thereafter, until 2001, in Croydon, UK. It is currently based in Vienna, although the website is hosted by the Donau University Krems, Austria.\n\nThe ESHPh was founded with the primary aim of researching the historical development of photography from its origins up to the present and integrating it within a European context within the social political matrix of photography's inherent interdisciplinary nature. Photographers, general historians and historians of photography, philosophers, sociologists, ethnologists, academics, curators and private collectors as well as many important European institutions and some from further afield all belong to the ESHPh. Alongside its research activities, the ESHPh takes part in a worldwide exchange of information. It supports both the recognition of the history of photography as an academic discipline and the establishment of chairs in the discipline at European universities.\n\nFrom 1981 until 2004, the society has held symposia in various locations in Europe, as evidenced by diverse publications. For its 30th anniversary in 2008, the ESHPh celebrated an internationally attended photography congress at the Austrian Academy of Sciences, in Vienna, from 6–8 November 2008. This anniversary event was accompanied by an English language commemorative publication and took place as the theoretical focus of the European Month of Photography 2008 in Vienna.\n\nThe ESHPh as a society was entered in the Austrian Register of Societies on 3 March 2004. However, the seat of society is connected to the presidency.\n\nThe first general meeting, at which the board was elected, took place on 8 June in the WestLicht Gallery in Vienna. The new Executive Committee of the ESHPh was elected at the Society’s annual general assembly that was held in Vienna on 4 November 2010, at the invitation of the Department for Pictures at the Austrian National Library.\n\n\n\nThe International Letter is sent to members twice a year; the letter is a summary of recent events and information of new events and symposia concerning photography across the world, and also includes exhibition notices and auctions.\n\nSince 1981, the society has brought together practitioners and specialists with the aim of discussing photography and to create contacts from a variety of disciplines relating to photography.\n\nThe society's printed journal, \"PhotoResearcher\", has been published since 1990. 2010 saw the journal published three times a year by contributing authors who are internationally recognised experts in the field of photography.\n\nNo. 12 onwards:\n\nNo's. 7–11 (2004–2008)\n\nNo. 6 (1994–1996)\n\nNo. 5 (1993)\n\nNo's. 1–4 (1990–1992)\n\nThis jubilee publication coincided with the 2008 conference in Vienna. It served to formulise the direction of the ESHPh and give an overview of the \"picture\" from trans-disciplinarian perspectives.\n\n\"Photohistorica: Serial Literature Index of the European Society for the History of Photography\" consisted of a bibliographical listing, with abstracts, of articles that had appeared in serial publications of the relevant years of publication. The first issue in May 1978 was a bibliographic listing only, but thereafter most bibliographic entries were accompanied by a short abstract. Apart from that pioneering issue of May 1978, each issue was double-numbered (such as 02/03) and except for 1979 and 1981 two double-numbered issues appeared annually (i.e. covering 1992 the two issues were numbers 50/51 and 52/53 containing abstract No.s 6656-6963 and 8964-7229). Karel van Deuren (the editor throughout the 1980s), Dr. Laurent Roosens (inaugural President of ESHPh), and Luc Salu (librarian of the Museum voor Fotographie, Antwerp) were the first compilers of the bibliography and abstracts. The production of those twenty–seven double-numbered issues of \"Photohistorica\" of 1978-1992 made possible in Belgium by annual grants provided until 1993 by Agfa–Gevaert. From the remaining funds provided by Agfa-Gevaert, a detailed Cumulative Index was sent out to members of ESHPh in mid–1994.\n\nFor some years, the office of the ESHPh (under the society's President Prof. Margaret Harker Farrand) was based in England, and 1993-94 witnessed two years of financial insecurity for the Society, with an income apparently limited solely to the subscriptions of its members. Yet the production of a bibliography of articles on the history of photography from current serials had been of undoubted value and a justified function of the ESHPh. After a lapse of two years, a new volunteer - R. Derek Wood (historian of early photography) - from its members in England was found to compile and edit a renewed bibliography. Thus with Agfa-Gevaert (Belgium) making a grant to ESHPh in February 1995 to cover printing costs, another two double-numbered issues (No. 54/55 and 56/57) of a renewed Photohistorica covering the years 1993 and 1994 could be published.\n\nHowever, with a low membership inevitable for a specialist subject area unable to provide a strong financial base, both publications (\"Photohistorica\" and \"PhotoResearcher\") of ESHPh could not continue in the late 1990s - except that is for ESHPh member Audrey Linkman of Manchester compiling and editing a final \"Photohistorica\" (issue 58). It provided 296 abstracts of articles on the history of photography, published in serials, mainly, but not exclusively, during the half-year January to June 1997. Unlike all the earlier issues (of a square 20x20cm format), issue 58 was printed in A4 format and a new categorisation of subjects was introduced.\n\nThis account of \"Photohistorica\" is derived mainly from R. Derek Wood's preface and postscript to the issues for 1993-1994.\n\n\n\nMembership is open to students, private individual and to contributing international museums and institutions in photography. It incorporates interested disciplinarians from the professional scientific and academic fields where photography is significant in whole or in part.\n\n"}
{"id": "8669429", "url": "https://en.wikipedia.org/wiki?curid=8669429", "title": "Ferdinand Hurter", "text": "Ferdinand Hurter\n\nFerdinand Hurter (15 March 1844 – 12 March 1898) was a Swiss industrial chemist who settled in England. He also carried out research into photography.\n\nFerdinand Hurter was born in Schaffhausen, Switzerland, the only son of Tobias Hurter, a bookbinder, and his wife Anna Oechslein. His father died when Ferdinand was aged only two and his mother worked as a nurse to support him and his sister Elizabeth. She later married her late husband's half-brother, David, and Ferdinand developed a strong relationship with his stepfather. After education at the local Gymnasium he became an apprentice to a dyer in Winterthur before moving to Zürich to work in a silk firm. He then attended Zürich Polytechnic before going to Heidelberg University. Here he studied chemistry under Robert Bunsen and physics under Gustav Kirchhoff. He graduated Ph.D. with the highest honours in 1866.\n\nHurter was offered a professorship in Aarau but declined this and, with a few letters of introduction, arrived in Manchester in 1867. He joined Henry Deacon and Holbrook Gaskell at their alkali manufacturing business, Gaskell, Deacon & Co., in Widnes, Lancashire. Here he became chief chemist and worked with Deacon to develop a process to convert hydrochloric acid, a waste by-product of the Leblanc process of making alkali, to chlorine which was then used to manufacture bleaching powder. He was a pioneer in applying the principles of physical chemistry and thermodynamics to industrial processes and by 1880 was considered to be a world authority on the manufacture of alkali. He was a strong defender of the Leblanc process against the other methods of manufacturing alkali being developed at the time although he did research the ammonia-soda process but without any success. He argued against the production of alkali by the electrolysis of brine because of the enormous amount of electrical power this would require although he was later to have second thoughts.\n\nWhen the Leblanc factories merged in 1890 to form the United Alkali Company, Hurter was placed in charge of developing a research laboratory in Widnes. This was later named after him. He played a part in the foundation of the Society of Chemical Industry in 1881, becoming its chairman in 1888–1890. He published 24 papers in English journals alone. He gave many lectures to try to popularise scientific subjects. As chief chemist to the United Alkali Company, despite his failing health, he travelled to a number of countries in Europe and also made one visit to the USA. The Society of Chemical Industry endowed the Hurter Memorial Lecture in his name.\n\nIn 1871 Hurter married Hannah Garnett of Farnworth, Widnes, with whom he had six children, one of whom died in infancy. They lived first at Prospect House in Crow Wood and later in Wilmere House, Widnes. Hurter remained a Swiss citizen throughout his life and sent his children to receive part of their education in Switzerland. He enjoyed music and played the clarinet and piano. He also took an interest in photography, collaborating in research with Vero Charles Driffield, an engineer at the Gaskell-Deacon works. Together they published many papers (in addition to Hurter's papers in chemistry). They were jointly awarded the Progress Medal of the Royal Photographic Society in 1898. The results of their research revolutionised photography. Hurter campaigned for free education and for the introduction of the metric system into Britain. He died at his home in Cressington Park, Liverpool and was buried in the churchyard of Farnworth church. His estate was valued at slightly less than £6,300.\n\n\nCitations\n\nSources\n"}
{"id": "29957827", "url": "https://en.wikipedia.org/wiki?curid=29957827", "title": "Flow, Turbulence and Combustion", "text": "Flow, Turbulence and Combustion\n\nFlow, Turbulence and Combustion is a peer-reviewed scientific journal on fluid mechanics. It covers original research on fluid mechanics and combustion, with the areas of interest including industrial, geophysical, and environmental applications. The journal was established in 1949 under the name Applied Scientific Research. It obtained its present name in 1998, which also reflects its association with the European Research Community on Flow, Turbulence and Combustion (ERCOFTAC).\n\nSince the start in 1948, the journal was published by Martinus Nijhoff Publishers. In the late 1980 it was taken over by Kluwer Academic Publishers, which subsequently became part of the current publisher, Springer Science+Business Media.\n\n"}
{"id": "30970278", "url": "https://en.wikipedia.org/wiki?curid=30970278", "title": "Hans Diedrich Henatsch", "text": "Hans Diedrich Henatsch\n\nHans Diedrich Henatsch served as the Head of the Department of Neurophysiology of the Medical School of the Georg-August-Universität Göttingen from the early sixties to the mid nineties.\n\nHe was a long-standing friend and colleague of Ragnar Granit and John Eccles. He became known in the sixties for recordings from spinal cord cells in anesthetized cats and his research in spinal cord physiology and spasticity.\n\nOn June 5 (Henatsch's birthday) 1997, after his death, Prof. Diethelm Richter (Henatsch's successor) organized a little memorial in the institute, on which occasion Eike Schomburg gave the laudatio.\n\n\n"}
{"id": "54102241", "url": "https://en.wikipedia.org/wiki?curid=54102241", "title": "Heat release parameter", "text": "Heat release parameter\n\nIn Combustion, heat release parameter (or gas expansion parameter) is a dimensionless parameter which measures the amount of heat released by the combustion process. It is defined as\n\nwhere\n\nIn typical combustion process, formula_4. For isobaric combustion, using ideal gas law, the parameter can be expressed in terms of density, i.e.,\n\nThe ratio of burnt gas to unburnt gas temperature is\n\n"}
{"id": "190460", "url": "https://en.wikipedia.org/wiki?curid=190460", "title": "Henri Coandă", "text": "Henri Coandă\n\nHenri Marie Coandă (; 7 June 1886 – 25 November 1972) was a Romanian inventor, aerodynamics pioneer, and builder of an experimental aircraft, the Coandă-1910 described by Coandă in the mid-1950s as the world's first jet, a controversial claim disputed by some and supported by others. He invented a great number of devices, designed a \"flying saucer\" and discovered the Coandă effect of fluid dynamics.\n\nBorn in Bucharest, Coandă was the second child of a large family. His father was General Constantin Coandă, a mathematics professor at the National School of Bridges and Roads. His mother, Aida Danet, was the daughter of French physician Gustave Danet, and was born in Brittany. Coandă recalled later in life that beginning from childhood he was fascinated by the miracle of wind.\n\nCoandă attended Elementary school at the \"Petrache Poenaru\" Communal School in Bucharest, then (1896) Began his secondary school career at the Liceu \"Sf. Sava\" (Saint Sava National College). After three years (1899), his father, who desired a military career for him, had him transferred to the Military High School in Iaşi where he required four additional years to complete high-school. He graduated in 1903 with the rank of sergeant major, and he continued his studies at the School of Artillery, Military, and Naval Engineering in Bucharest. Sent with an artillery regiment to Germany (1904), he enrolled in the Technische Hochschule in Charlottenburg, Berlin.\n\nCoandă graduated as an artillery officer, but he was more interested in the technical problems of flight. In 1905, he built a missile-aeroplane for the Romanian Army. He continued his studies (1907–08) at the Montefiore Institute in Liège, Belgium, where he met Gianni Caproni. In 1908 Coandă returned to Romania to serve as an active officer in the Second Artillery Regiment. His inventor's spirit did not comport well with military discipline and he obtained permission to leave the army, after which he took advantage of his renewed freedom to take a long automobile trip to Isfahan, Teheran, and Tibet.\n\nUpon his return in 1909, he travelled to Paris, where he enrolled in the newly founded \"École Nationale Supérieure d'Ingénieurs en Construction Aéronautique\" (now the École Nationale Supérieure de l'Aéronautique et de l'Espace, also known as SUPAERO). One year later (1910) he graduated at the head of the first class of aeronautical engineers.\n\nIn 1910, in the workshop of Gianni Caproni, he designed and built an aircraft known as the Coandă-1910, which he displayed publicly at the second International Aeronautic Salon in Paris that year. The aircraft used a 4-cylinder piston engine to power a rotary compressor which was intended to propel the craft by a combination of suction at the front and airflow out the rear instead of using a propeller.\n\nContemporary sources describe the Coandă-1910 as incapable of flight. Years later, after others had developed jet technology, Coandă started making claims that it was a motorjet, and that it actually flew. According to Charles Gibbs-Smith: \"There was never any idea of injecting fuel; the machine never flew; it was never destroyed on test; and \"Flight\" noted that it was sold to a Monsieur Weyman.\" Gibbs-Smith continued, \"The claim said that after a disastrous crash (which never happened) Coandă wished to begin a 'second aircraft', but 'his funds were exhausted.' Within a year he was ... exhibiting (in October 1911) a brand new propeller-driven machine at the Reims Concours Militaire...\" Other aviation writers accepted Coandă's story of his flight tests with the Coandă-1910.\n\nCoandă's colleague at Huyck Corporation, G. Harry Stine—a rocket scientist, author and \"the father of American model rocketry\"—stated in his book \"The Hopeful Future\" that \"there were several jet-propelled aircraft in existence at an early time-the Coandă-1910 jet and the 1938 Caproni Campini N.1, the pure jet aircraft flight was made in Germany in 1938\". Rolf Sonnemann and Klaus Krug from the University of Technology of Dresden, mentioned in passing in their 1987 book \"Technik und Technikwissenschaften in der Geschichte\" (\"Technology and Technical Sciences in History\") that the Coandă-1910 was the world's first jet.\nBetween 1911 and 1914, he worked as technical manager of the Bristol Aeroplane Company in the United Kingdom, where he designed several aeroplanes known as the Bristol-Coanda Monoplanes. In 1912 one of these aircraft won a prize at the British Military Aeroplane Competition.\n\nIn 1915, he returned to France where, working during World War I for Delaunay-Belleville in Saint-Denis, he designed and built three different models of propeller aeroplane, including the Coandă-1916, with two propellers mounted close to the tail. This design was to be reprised in the 1950s Sud Aviation Caravelle transport aeroplane, for which Coandă was a technical consultant.\n\nIn the years between the wars, he continued travelling and inventing. In 1934 he was granted a French patent related to the \"Coandă Effect\". During early 1930 he used the same principle as the basis for the design of a disc-shaped aircraft called \"Aerodina Lenticulară\" (lens-shaped aerodyne), a \"flying saucer\" shaped aircraft that used an unspecified source of high-pressure gases to flow through a ring-shaped vent system. In 1936 Coandă applied for a patent for his design. No practical full-scale version was built.\n\nCoanda spent World War II in occupied France where he worked for the Nazis to help their war effort by developing the turbopropulseur (turbopropeller) drive system from his 1910 biplane into a propulsion system for snow sleds. The German contract concluded after one year, yielding no plans for production.\n\nCoandă's research on the Coandă Effect was of interest post-war and became the basis for several investigations of entrained or augmented flow. A small stream of a high-velocity fluid could be used to generate a greater mass flow, at lower velocity. Although eventually unsuccessful for aircraft propulsion, this effect has been widely used on a smaller scale, from packaging machinery for small pills through to the Dyson \"Air Multiplier\" bladeless fan.\n\nIn 1969, during the early years of the Ceauşescu era, he returned to spend his last days in his native Romania, where he served as director of the Institute for Scientific and Technical Creation (INCREST) and in 1971 reorganized, along with professor Elie Carafoli, the Department of Aeronautical Engineering of the Polytechnic University of Bucharest, spinning it off from the Department of Mechanical Engineering.\n\nCoandă died in Bucharest on 25 November 1972 at the age of 86. He is buried at Bellu cemetery.\n\n\n\n\n"}
{"id": "10003073", "url": "https://en.wikipedia.org/wiki?curid=10003073", "title": "How Do They Do That?", "text": "How Do They Do That?\n\nHow Do They Do That? is a British television show, produced by Telepictures and Reg Grundy Productions in and broadcast on BBC1 from 25 January 1994 to 23 April 1997. Originally presented by Jenny Hull and Des Lynam, the show explored feats of engineering, organization, and special effects. Each season opened with a stunt apparently performed by one of the presenters, such as a skydiver crash-landing into the studio, a car chase, or the entire studio being washed away.\n\nAfter two series, Eamonn Holmes took over as male presenter, and from Series 5, was joined by Esther McVey. At its height, How Do They Do That? had 12 million viewers watching on Wednesday nights.\n\n"}
{"id": "39689650", "url": "https://en.wikipedia.org/wiki?curid=39689650", "title": "I-Trans cluster", "text": "I-Trans cluster\n\nI-Trans cluster is a French cluster for railway industry, sustainable multimodal and urban transportation systems. It is located in Northern France at Villeneuve-d'Ascq and Valenciennes and is supported by Université Lille Nord de France, Réseau Ferré de France, SNCF, Alstom.\n\nI-Trans cluster is the founding member of Ralenium institute.\n\n"}
{"id": "36510964", "url": "https://en.wikipedia.org/wiki?curid=36510964", "title": "IBM (atoms)", "text": "IBM (atoms)\n\nIBM in atoms was a demonstration by IBM scientists in 1989 of a technology capable of manipulating individual atoms. A scanning tunneling microscope was used to arrange 35 individual xenon atoms on a substrate of chilled crystal of nickel to spell out the three letter company initialism. It was the first time atoms had been precisely positioned on a flat surface.\n\nOn Apr 30, 2013 IBM published an article on its website and a video on YouTube called \"A Boy And His Atom: The World's Smallest Movie\".\nDonald Eigler and Erhard Schweizer of the IBM Almaden Research Center in San Jose, California, used a scanning tunneling microscope to position 35 individual xenon atoms on a substrate of chilled crystal of nickel to form the acronym \"IBM\". They also created chains of xenon atoms similar in form to molecules.\n\n\n"}
{"id": "3014996", "url": "https://en.wikipedia.org/wiki?curid=3014996", "title": "Intercom telephone", "text": "Intercom telephone\n\nAn intercom telephone is a special kind of telephone that controls a school or an office buildings intercom system. For example, with that telephone, the employers make the school announcements and can call each classroom's intercom by dialing the room number of that classroom. It can be interfaced with the building's access control system.\n\n"}
{"id": "17519063", "url": "https://en.wikipedia.org/wiki?curid=17519063", "title": "John von Neumann Computer Society", "text": "John von Neumann Computer Society\n\nThe John von Neumann Computer Society () is the central association for Hungarian researchers of Information communication technology and official partner of the International Federation for Information Processing founded in 1968.\n\n"}
{"id": "50700246", "url": "https://en.wikipedia.org/wiki?curid=50700246", "title": "Josephine Wapakabulo", "text": "Josephine Wapakabulo\n\nJosephine Kasalamwa Wapakabulo, also Josephine Wapakabulo Thomas, is a Ugandan electrical engineer and business executive. She is the Chief Executive Officer of Uganda National Oil Company. She was appointed in June 2016, being the first person to serve in that position.\n\nShe was born in 1976, in Arusha, Tanzania. She is the daughter of Angelina Wapakhabulo and the late James Wapakhabulo. She studied at Loughborough University in the United Kingdom, as an electrical and electronics engineer, obtaining a BEng, an MSc and a PhD in the field. She also holds an Executive MBA from the INSEAD Business School in France.\n\nFrom 2000 until 2002 Wapakabulo worked as a Leadership Trainee & Community Organizer in Coventry, United Kingdom. From 2002 until 2006, she worked as a Research Associate at LSC Group Consulting in Lichfield, United Kingdom. In 2006, she joined Rolls-Royce in Derby, United Kingdom as a Business Process & Information Engineering Specialist, serving in that capacity until 2011. From 2011 until 2014, she served as a Quality Executive and Chief of Quality and Continuous Improvement at Rolls-Royce in the Berlin Area, in Germany.\n\nBetween 2014 and 2015, she served as the Chief Operating Officer at The Walk Free Foundation in Perth, Australia. In 2015, she returned to her native Uganda and worked as a Business Consultant in Kampala, until 2016. She was named to her present appointment by the Board of UNOC, in June 2016.\n\nShe took up her appointment at Uganda National Oil Company on 1 August 2016, with over 15 years' experience in effective leadership, team building, project management and innovation in multinational companies, across multiple continents.\n\n\n"}
{"id": "53410378", "url": "https://en.wikipedia.org/wiki?curid=53410378", "title": "Koombea", "text": "Koombea\n\nKoombea INC is an American digital product development company, established in 2007.\n\nThe company has developed web solutions that equip clients with tools for sales, team and marketing management. \nAmong them is \"Saasler\", a tool that focuses on native integration to enhance product sales and promote brand loyalty. The application also includes several integration intelligence features, such as refreshing expired tokens, API throttling, security and data encryption, and a range of analytic.\n\"Convergely\" is a virtual assistant developed by Koombea, which works through integration with chat apps, like Slack and HipChat. \nThe company has also developed \"Dashable\", an app which builds up on the concept of time tracking.\n"}
{"id": "21620963", "url": "https://en.wikipedia.org/wiki?curid=21620963", "title": "M-Pesa", "text": "M-Pesa\n\nM-Pesa (M for mobile, pesa is Swahili for money) is a mobile phone-based money transfer, financing and microfinancing service, launched in 2007 by Vodafone for Safaricom and Vodacom, the largest mobile network operators in Kenya and Tanzania. It has since expanded to Afghanistan, South Africa, India and in 2014 to Romania and in 2015 to Albania. M-Pesa allows users to deposit, withdraw, transfer money and pay for goods and services (Lipa na M-Pesa) easily with a mobile device.\n\nThe service allows users to deposit money into an account stored on their cell phones, to send balances using PIN-secured SMS text messages to other users, including sellers of goods and services, and to redeem deposits for regular money. Users are charged a small fee for sending and withdrawing money using the service.\n\nM-Pesa is a branchless banking service; M-Pesa customers can deposit and withdraw money from a network of agents that includes airtime resellers and retail outlets acting as banking agents.\n\nM-Pesa has spread quickly, and by 2010 had become the most successful mobile-phone-based financial service in the developing world. By 2012, a stock of about 17 million M-Pesa accounts had been registered in Kenya. By June 2016, a total of 7 million M-Pesa accounts have been opened in Tanzania by Vodacom. The service has been lauded for giving millions of people access to the formal financial system and for reducing crime in otherwise largely cash-based societies.\n\nIn 2002, researchers at Gamos and the Commonwealth Telecommunications Organisation, funded by Department for International Development UK (DFID), documented that in Uganda, Botswana and Ghana, people were spontaneously using airtime as a proxy for money transfer. Kenyans were transferring airtime to their relatives or friends who were then using it or reselling it. Gamos researchers approached MCel in Mozambique, and in 2004 MCel introduced the first authorised airtime credit swapping – a precursor step towards M-Pesa. The idea was discussed by the Commission for Africa and DFID introduced the researchers to Vodafone who had been discussing supporting microfinance and back office banking with Mobile phones. S Batchelor (Gamos) and N Hughes (Vodafone CSR) discussed how a system of money transfer could be created in Kenya. DFID amended the terms of reference for its grant to Vodafone, and piloting began in 2005. A student from Moi University in Kenya came up with a mobile software that could allow people to send, receive, and withdraw money from their mobile devices. Safaricom however convinced the student and bought the rights of ownership of this project hence becoming the sole owners of the patent rights. In April 2007, following a student software development project from Kenya, Safaricom launched a new mobile phone-based payment and money transfer service, known as M-Pesa.\n\nThe initial work of developing the product was given to a product and technology development company known as Sagentia. Development and second line support responsibilities were transferred to IBM in September 2009, where most of the original Sagentia team transferred to.\n\nFollowing a 3-year migration project to a new technology stack, as of 26 February 2017, IBM's responsibilities have been transferred to Huawei in all markets.\n\nThe initial concept of M-Pesa was to create a service which would allow microfinance borrowers to conveniently receive and repay loans using the network of Safaricom airtime resellers. This would enable microfinance institutions (MFIs) to offer more competitive loan rates to their users, as costs are lower than when dealing in cash. The users of the service would gain through being able to track their finances more easily. When the service was piloted, customers adopted the service for a variety of alternative uses and complications arose with Faulu, the partnering MFI. In discussion with other parties, M-Pesa was re-focused and launched with a different value proposition: sending remittances home across the country and making payments.\n\nM-Pesa is operated by Safaricom and Vodacom, mobile network operators (MNO) not classed as deposit-taking institutions, such as a bank. M-Pesa customers can deposit and withdraw money from a network of agents that includes airtime resellers and retail outlets acting as banking agents. The service enables its users to:\n\nPartnerships with Kenyan banks offer expanded banking services like interest-bearing accounts, loans, and insurance.\n\nThe user interface technology of M-Pesa differs between Safaricom of Kenya and Vodacom of Tanzania, although the underlying platform is the same. While Safaricom uses SIM toolkit (STK) to provide handset menus for accessing the service, Vodacom relies mostly on USSD to provide users with menus, but also supports STK.\n\nTransaction charges depend on the amount of money being transferred and whether the payee is a registered user of the service. The actual cost is a fixed amount for a given range of transaction sizes; for example Safaricom charges up to 66 Kshs. for a transaction to an unregistered user for transactions between 101-500 Kshs. (US$1–5) and 27 Kshs. for a transfer to a registered user for the same amount. At the highest transfer bracket of 50,001-70,000 Kshs. the fee for a transfer to a registered user is 110 Kshs. The maximum amount that can be transferred to a non-registered user of the system is 35,000 Kshs, with a fee of 275 Kshs. Cash withdrawal fees are also charged. With a charge of 10 Kshs, for a withdrawal of 50-100 Kshs, up to 330 Kshs for a withdrawal of 50,001-70,000 Kshs.\nIn a 2015 published article Anja Bengelstorff cites the central bank of Kenya when she states that 1 billion CHF is moved in fiscal year 2014, with a profit of 268 million CHF, that is close to 27% of the moved money. In 2016 M-Pesa moved 15bn KES per day equivalent to 52 billion CHF in Kenya, with a revenue of 41bn KES. In 2017 6869bn KES were moved according to a figure in Safaricoms own annual report, with a revenue of 55bn. This would put Safaricom's profit ratio at around <1% of total money transferred - nothing like 27% but still a high figure.\n\nM-Pesa was first launched by the Kenyan mobile network operator Safaricom, where Vodafone is technically a minority shareholder (40%), in March 2007. M-Pesa quickly captured a significant market share for cash transfers, and grew to 17 million subscribers by December 2011 in Kenya alone.\n\nThe growth of the service forced formal banking institutions to take note of the new venture. In December 2008, a group of banks reportedly lobbied the Kenyan finance minister to audit M-Pesa, in an effort to at least slow the growth of the service. This ploy failed, as the audit found that the service was robust. At this time The Banking Act did not provide basis to regulate products offered by non-banks, of which M-Pesa was one such very successful product. As at November 2014, M-Pesa transactions for the 11 months of 2014 were valued at KES. 2.1 trillion, a 28% increase from 2013, and almost half the value of the country's GDP.\n\nOn 19 November 2014, Safaricom launched a companion android app Safaricom M-Ledger for its M-Pesa users. The application, currently available only on Android, gives M-Pesa users a historical view of all their transactions. Many other companies business models rely on the M-Pesa system in Kenya, such as M-kopa and Sportpesa.\n\nOn 23 February 2018, it was reported that the Google Play store started taking payments for apps via Kenya´s M-Pesa service.\n\nM-Pesa was launched in Tanzania by Vodacom in 2008 but its initial ability to attract customers fell short of expectations. In 2010, the International Finance Corporation released a report which explored many of these issues in greater depth and analyzed the strategic changes that Vodacom has implemented to improve their market position. As of May 2013, M-Pesa in Tanzania has five million subscribers.\n\nIn 2008 Vodafone partnered with Roshan, Afghanistan's primary mobile operator, to provide M-Pesa, the local brand of the service. When the service was launched it was initially used to pay policemen's salaries set to be competitive with what the Taliban were earning. Soon after the product was launched, the Afghan National Police found that under the previous cash model, 10% of their workforce were ghost police officers who did not exist; their salaries had been pocketed by others. When corrected in the new system, many police officers believed that they had received a raise or that there had been a mistake, as their salaries rose significantly. The National Police discovered that there was so much corruption when payments had been made using the previous model that the policemen did not know their true salary. The service has been so successful that it has been expanded to include limited merchant payments, peer-to-peer transfers, loan disbursements and payments.\n\nIn September 2010 Vodacom and Nedbank announced the launch of the service in South Africa, where there were estimated to be more than 13 million \"economically active\" people without a bank account. M-Pesa has been slow to gain a toehold in the South African market compared to Vodacom's projections that it would sign up 10 million users in the following three years. By May 2011, it had registered approximately 100,000 customers. The gap between expectations for M-Pesa's performance and its actual performance can be partly attributed to differences between the Kenyan and South African markets, including the banking regulations at the time of M-Pesa's launch in each country. According to MoneyWeb, a South African investment website, \"A tough regulatory environment with regards to customer registration and the acquisition of outlets also compounded the company's troubles, as the local regulations are more stringent in comparison to our African counterparts. Lack of education and product understanding also hindered efforts in the initial roll out of the product.\" In June 2011, Vodacom and Nedbank launched a campaign to re-position M-Pesa, targeting the product to potential customers who have a higher Living Standard Measures (LSM) than were first targeted.\n\nDespite efforts, as at March 2015, M-Pesa still struggled to grow its customer base. South Africa lags behind Tanzania and Kenya with only c.1 million subscribers. This comes as no surprise as South Africa is well known for being ahead of financial institutions globally in terms of maturity and technological innovation. According to Genesis Analytics, 70% of South Africans are \"banked\", meaning that they have at least one bank account with an established financial institution which have their own banking products which directly compete with the M-Pesa offering.\n\nM-Pesa, was launched in India as a close partnership with ICICI bank in November 2011. Development for the bank began as early as 2008. The service continues to operate in a limited geographical area in India. Vodafone India had partnered with both ICICI and ICICI bank, ICICI launched M-Pesa on 18 April 2013. Vodafone plans to rollout this service throughout India.\nThe user needs to register for this service, registration is free and there are charges levied per M-Pesa transaction for money transfer services and DTH and Prepaid recharges can be done through m-pesa for free.\n\nIn March 2014, M-Pesa expanded into Romania, while mentioning that it may continue to expand elsewhere into Eastern Europe, as a number of individuals there possess mobile phones but do not possess traditional bank accounts. It is unlikely, as of May 2014, however, that the service will expand into Western Europe anytime soon.\n\nIn May 2015, M-PESA was also launched in Albania. It was shut down on July 14, 2017.\n\nM-Pesa expanded into Mozambique, Lesotho, and Egypt in May, June, and July 2013, respectively. A full listing of countries in which M-Pesa currently operates can be found on M-Pesa's website.\n\nM-Pesa sought to engage Kenyan regulators and keep them updated on the development process. M-Pesa also reached out to international regulators, such as the UK's Financial Conduct Authority (FCA) and the Payment Card Industry (PCI) to understand how best to protect client information and adhere to internationally recognized best practices.\n\nKnow Your Customer (KYC) requirements impose obligations on prospective clients and on banks to collect identification documents of clients and then to have those documents verified by banks. The Kenyan government issues national identity cards that M-Pesa leveraged in their business processes to satisfy their KYC requirements.\n\nM-Pesa obtained a \"special\" license from regulators, despite concerns by regulators about non-branch banking adding to the current state of financial instability.\n\nSafaricom released the new MPESA platform dubbed MPESA G2 to offer versatile integration capabilities for development partners. Client to Business and Business to Client disbursements are some of features available through the API.\n\n\n\n"}
{"id": "822307", "url": "https://en.wikipedia.org/wiki?curid=822307", "title": "Maglev", "text": "Maglev\n\nMaglev (derived from magnetic levitation) is a system of train transportation that uses two sets of magnets, one set to repel and push the train up off the track as in levitation (hence Maglev, Magnetic-levitation), then another set to move the 'floating train' ahead at great speed taking advantage of the lack of friction. Along certain \"medium range\" routes (usually 200–400 miles) Maglev can compete favorably with high speed rail and airplanes.\n\nWith Maglev technology, there are no moving parts. The train travels along a guideway of magnets which control the train's stability and speed. Maglev trains are therefore quieter and smoother than conventional trains, and have the potential for much higher speeds. \n\nMaglev vehicles have set several speed records and Maglev trains can accelerate and decelerate much faster than conventional trains; the only practical limitation is the safety and comfort of the passengers. \n\nThe power needed for levitation is typically not a large percentage of the overall energy consumption of a high speed maglev system. Overcoming drag, which makes all land transport more energy intensive at higher speeds, takes up the most energy. Vactrain technology has been proposed as a means to overcome this limitation.\n\nMaglev systems have been much more expensive to construct than conventional train systems, although the simpler construction of maglev vehicles makes them cheaper to manufacture and maintain. Despite over a century of research and development, maglev transport systems are in operation in just three countries (Japan, South Korea and China). The incremental benefits of maglev technology have often been hard to justify against cost and risk, especially where there is an existing or proposed conventional high speed train line with spare passenger carrying capacity, as in continental Europe, the UK and Japan.\n\nIn the late 1940s, the British electrical engineer Eric Laithwaite, a professor at Imperial College London, developed the first full-size working model of the linear induction motor. He became professor of heavy electrical engineering at Imperial College in 1964, where he continued his successful development of the linear motor. Since linear motors do not require physical contact between the vehicle and guideway, they became a common fixture on advanced transportation systems in the 1960s and 70s. Laithwaite joined one such project, the Tracked Hovercraft, although the project was cancelled in 1973.\n\nThe linear motor was naturally suited to use with maglev systems as well. In the early 1970s, Laithwaite discovered a new arrangement of magnets, the magnetic river, that allowed a single linear motor to produce both lift and forward thrust, allowing a maglev system to be built with a single set of magnets. Working at the British Rail Research Division in Derby, along with teams at several civil engineering firms, the \"transverse-flux\" system was developed into a working system.\n\nThe first commercial maglev people mover was simply called \"MAGLEV\" and officially opened in 1984 near Birmingham, England. It operated on an elevated section of monorail track between Birmingham Airport and Birmingham International railway station, running at speeds up to . The system was closed in 1995 due to reliability problems.\n\nHigh-speed transportation patents were granted to various inventors throughout the world. Early United States patents for a linear motor propelled train were awarded to German inventor . The inventor was awarded (14 February 1905) and (21 August 1907). In 1907, another early electromagnetic transportation system was developed by F. S. Smith. A series of German patents for magnetic levitation trains propelled by linear motors were awarded to Hermann Kemper between 1937 and 1941. An early maglev train was described in , \"Magnetic system of transportation\", by G. R. Polgreen (25 August 1959). The first use of \"maglev\" in a United States patent was in \"Magnetic levitation guidance system\" by Canadian Patents and Development Limited.\n\nIn 1968, while delayed in traffic on the Throgs Neck Bridge, James Powell, a researcher at Brookhaven National Laboratory (BNL), thought of using magnetically levitated transportation. Powell and BNL colleague Gordon Danby worked out a MagLev concept using static magnets mounted on a moving vehicle to induce electrodynamic lifting and stabilizing forces in specially shaped loops, such as figure of 8 coils on a guideway.\n\nTransrapid 05 was the first maglev train with longstator propulsion licensed for passenger transportation. In 1979, a track was opened in Hamburg for the first (IVA 79). Interest was sufficient that operations were extended three months after the exhibition finished, having carried more than 50,000 passengers. It was reassembled in Kassel in 1980.\n\nIn 1979, in the USSR, in the town of Ramenskoye (Moscow oblast) was built an experimental test site\nfor running experiments with cars on magnetic suspension. The test site consisted of a 600-meter ramp\nwhich was later extended to 980 meters. From the late 1970s to the 1980s five prototypes of cars were built\nthat received designations from TP-01 (ТП-01) to TP-05 (ТП-05). The early cars were supposed to reach the speed up to 100 km/h.\n\nThe construction of a maglev track using the technology from Ramenskoye started in Armenian SSR in 1987\nand was planned to be completed in 1991. The track was supposed to connect the cities of Yerevan and Sevan via the city of Abovyan. The original design speed was 250 km/h which was later lowered to 180 km/h.\nHowever, the Spitak earthquake in 1988 and the Nagorno-Karabakh war caused the project to freeze. In the end the overpass was only partially constructed.\n\nIn the early 1990s, the maglev theme was continued by the Engineering Research Center \"TEMP\" (ИНЦ \"ТЭМП\") this time by the order from the Moscow government. The project was named V250 (В250). The idea was to build a high-speed maglev train to connect Moscow to the Sheremetyevo airport. The train would consist of 64-seater cars and can run at the speeds up to 250 km/h. In 1993, due to the financial crisis, the project was abandoned. However, from 1999 the \"TEMP\" research center had been participating as a co-developer in the creation of the linear motors for the Moscow monorail system.\n\nThe world's first commercial maglev system was a low-speed maglev shuttle that ran between the airport terminal of Birmingham International Airport and the nearby Birmingham International railway station between 1984 and 1995. Its track length was , and trains levitated at an altitude of , levitated by electromagnets, and propelled with linear induction motors. It operated for 11 years and was initially very popular with passengers, but obsolescence problems with the electronic systems made it progressively unreliable as years passed, leading to its closure in 1995. One of the original cars is now on display at Railworld in Peterborough, together with the RTV31 hover train vehicle. Another is on display at the National Railway Museum in York.\n\nSeveral favourable conditions existed when the link was built:\n\nAfter the system closed in 1995, the original guideway lay dormant until 2003, when a replacement cable-hauled system, the AirRail Link Cable Liner people mover, was opened.\n\nTransrapid, a German maglev company, had a test track in Emsland with a total length of . The single-track line ran between Dörpen and Lathen with turning loops at each end. The trains regularly ran at up to . Paying passengers were carried as part of the testing process. The construction of the test facility began in 1980 and finished in 1984. In 2006, the Lathen maglev train accident occurred killing 23 people, found to have been caused by human error in implementing safety checks. From 2006 no passengers were carried. At the end of 2011 the operation licence expired and was not renewed, and in early 2012 demolition permission was given for its facilities, including the track and factory.\n\nJapan operates two independently developed maglev trains. One is HSST (and its descendant, the Linimo line) by Japan Airlines and the other, which is more well-known, is SCMaglev by the Central Japan Railway Company.\n\nThe development of the latter started in 1969. Miyazaki test track regularly hit by 1979. After an accident that destroyed the train, a new design was selected. In Okazaki, Japan (1987), the SCMaglev took a test ride at the Okazaki exhibition. Tests through the 1980s continued in Miyazaki before transferring to a far larger test track, long, in Yamanashi in 1997.\n\nDevelopment of HSST started in 1974. In Tsukuba, Japan (1985), the HSST-03 (Linimo) became popular in spite of its at the Tsukuba World Exposition. In Saitama, Japan (1988), the HSST-04-1 was revealed at the Saitama exhibition performed in Kumagaya. Its fastest recorded speed was .\n\nA new high speed maglev line, the Chuo Shinkansen, is planned to become operational in 2027, with construction starting 2017.\n\nIn Vancouver, Canada, the HSST-03 by HSST Development Corporation (Japan Airlines and Sumitomo Corporation) was exhibited at Expo 86 and ran on a test track that provided guests with a ride in a single car along a short section of track at the fairgrounds. It was removed after the fair and debut at the Aoi Expo in 1987 and now on static display at Okazaki Minami Park.\n\nIn Hamburg, Germany, the TR-07 was exhibited at the international traffic exhibition (IVA88) in 1988.\n\nIn West Berlin, the M-Bahn was built in the late 1980s. It was a driverless maglev system with a track connecting three stations. Testing with passenger traffic started in August 1989, and regular operation started in July 1991. Although the line largely followed a new elevated alignment, it terminated at Gleisdreieck U-Bahn station, where it took over an unused platform for a line that formerly ran to East Berlin. After the fall of the Berlin Wall, plans were set in motion to reconnect this line (today's U2). Deconstruction of the M-Bahn line began only two months after regular service began. It was called the Pundai project and was teminated in February 1992 due to safety concerns.\n\nIn 1993, South Korea completed the development of its own maglev train, shown off at the Taejŏn Expo '93, which was developed further into a full-fledged maglev capable of travelling up to in 2006. This final model was incorporated in the Incheon Airport Maglev which opened on February 3, 2016, making South Korea the world's fourth country to operate its own self-developed maglev after the United Kingdom's Birmingham International Airport, Germany's Berlin M-Bahn, and Japan's Linimo. It links Incheon International Airport to the Yongyu Station and Leisure Complex on Yeongjong island. It offers a transfer to the Seoul Metropolitan Subway at AREX's Incheon International Airport Station and is offered free of charge to anyone to ride, operating between 9am and 6pm with 15 minute intervals. Operating hours are to be raised in the future.\n\nThe maglev system was co-developed by the South Korea Institute of Machinery and Materials (KIMM) and Hyundai Rotem. It is long, with six stations and a operating speed.\n\nTwo more stages are planned of and . Once completed it will become a circular line.\n\nIn the public imagination, \"maglev\" often evokes the concept of an elevated monorail track with a linear motor. Maglev systems may be monorail or dual rail and not all monorail trains are maglevs. Some railway transport systems incorporate linear motors but use electromagnetism only for \"propulsion\", without levitating the vehicle. Such trains have wheels and are not maglevs. Maglev tracks, monorail or not, can also be constructed at grade (i.e. not elevated). Conversely, non-maglev tracks, monorail or not, can be elevated too. Some maglev trains do incorporate wheels and function like linear motor-propelled wheeled vehicles at slower speeds but \"take off\" and levitate at higher speeds.\nThe two notable types of maglev technology are:\n\nAnother technology, which was designed, proven mathematically, peer-reviewed, and patented, but is, as of May 2015, unbuilt, is magnetodynamic suspension (MDS). It uses the attractive magnetic force of a permanent magnet array near a steel track to lift the train and hold it in place. Other technologies such as repulsive permanent magnets and superconducting magnets have seen some research.\n\nIn electromagnetic suspension (EMS) systems, the train levitates above a steel rail while electromagnets, attached to the train, are oriented toward the rail from below. The system is typically arranged on a series of C-shaped arms, with the upper portion of the arm attached to the vehicle, and the lower inside edge containing the magnets. The rail is situated inside the C, between the upper and lower edges.\n\nMagnetic attraction varies inversely with the cube of distance, so minor changes in distance between the magnets and the rail produce greatly varying forces. These changes in force are dynamically unstable – a slight divergence from the optimum position tends to grow, requiring sophisticated feedback systems to maintain a constant distance from the track, (approximately ).\n\nThe major advantage to suspended maglev systems is that they work at all speeds, unlike electrodynamic systems, which only work at a minimum speed of about . This eliminates the need for a separate low-speed suspension system, and can simplify track layout. On the downside, the dynamic instability demands fine track tolerances, which can offset this advantage. Eric Laithwaite was concerned that to meet required tolerances, the gap between magnets and rail would have to be increased to the point where the magnets would be unreasonably large. In practice, this problem was addressed through improved feedback systems, which support the required tolerances.\n\nIn electrodynamic suspension (EDS), both the guideway and the train exert a magnetic field, and the train is levitated by the repulsive and attractive force between these magnetic fields. In some configurations, the train can be levitated only by repulsive force. In the early stages of maglev development at the Miyazaki test track, a purely repulsive system was used instead of the later repulsive and attractive EDS system. The magnetic field is produced either by superconducting magnets (as in JR–Maglev) or by an array of permanent magnets (as in Inductrack). The repulsive and attractive force in the track is created by an induced magnetic field in wires or other conducting strips in the track. A major advantage of EDS maglev systems is that they are dynamically stable – changes in distance between the track and the magnets creates strong forces to return the system to its original position. In addition, the attractive force varies in the opposite manner, providing the same adjustment effects. No active feedback control is needed.\n\nHowever, at slow speeds, the current induced in these coils and the resultant magnetic flux is not large enough to levitate the train. For this reason, the train must have wheels or some other form of landing gear to support the train until it reaches take-off speed. Since a train may stop at any location, due to equipment problems for instance, the entire track must be able to support both low- and high-speed operation.\n\nAnother downside is that the EDS system naturally creates a field in the track in front and to the rear of the lift magnets, which acts against the magnets and creates magnetic drag. This is generally only a concern at low speeds, and is one of the reasons why JR abandoned a purely repulsive system and adopted the sidewall levitation system. At higher speeds other modes of drag dominate.\n\nThe drag force can be used to the electrodynamic system's advantage, however, as it creates a varying force in the rails that can be used as a reactionary system to drive the train, without the need for a separate reaction plate, as in most linear motor systems. Laithwaite led development of such \"traverse-flux\" systems at his Imperial College laboratory. Alternatively, propulsion coils on the guideway are used to exert a force on the magnets in the train and make the train move forward. The propulsion coils that exert a force on the train are effectively a linear motor: an alternating current through the coils generates a continuously varying magnetic field that moves forward along the track. The frequency of the alternating current is synchronized to match the speed of the train. The offset between the field exerted by magnets on the train and the applied field creates a force moving the train forward.\n\nThe term \"maglev\" refers not only to the vehicles, but to the railway system as well, specifically designed for magnetic levitation and propulsion. All operational implementations of maglev technology make minimal use of wheeled train technology and are not compatible with conventional rail tracks. Because they cannot share existing infrastructure, maglev systems must be designed as standalone systems. The SPM maglev system is inter-operable with steel rail tracks and would permit maglev vehicles and conventional trains to operate on the same tracks. MAN in Germany also designed a maglev system that worked with conventional rails, but it was never fully developed.\n\nEach implementation of the magnetic levitation principle for train-type travel involves advantages and disadvantages.\n\nNeither Inductrack nor the Superconducting EDS are able to levitate vehicles at a standstill, although Inductrack provides levitation at much lower speed; wheels are required for these systems. EMS systems are wheel-free.\n\nThe German Transrapid, Japanese HSST (Linimo), and Korean Rotem EMS maglevs levitate at a standstill, with electricity extracted from guideway using power rails for the latter two, and wirelessly for Transrapid. If guideway power is lost on the move, the Transrapid is still able to generate levitation down to speed, using the power from onboard batteries. This is not the case with the HSST and Rotem systems.\n\nEMS systems such as HSST/Linimo can provide both levitation and propulsion using an onboard linear motor. But EDS systems and some EMS systems such as Transrapid levitate but do not propel. Such systems need some other technology for propulsion. A linear motor (propulsion coils) mounted in the track is one solution. Over long distances coil costs could be prohibitive.\n\nEarnshaw's theorem shows that no combination of static magnets can be in a stable equilibrium. Therefore a dynamic (time varying) magnetic field is required to achieve stabilization. EMS systems rely on active electronic stabilization that constantly measures the bearing distance and adjusts the electromagnet current accordingly. EDS systems rely on changing magnetic fields to create currents, which can give passive stability.\n\nBecause maglev vehicles essentially fly, stabilisation of pitch, roll and yaw is required. In addition to rotation, surge (forward and backward motions), sway (sideways motion) or heave (up and down motions) can be problematic.\n\nSuperconducting magnets on a train above a track made out of a permanent magnet lock the train into its lateral position. It can move linearly along the track, but not off the track. This is due to the Meissner effect and flux pinning.\n\nSome systems use Null Current systems (also sometimes called Null Flux systems). These use a coil that is wound so that it enters two opposing, alternating fields, so that the average flux in the loop is zero. When the vehicle is in the straight ahead position, no current flows, but any moves off-line create flux that generates a field that naturally pushes/pulls it back into line.\n\nSome systems (notably the Swissmetro system) propose the use of vactrains—maglev train technology used in evacuated (airless) tubes, which removes air drag. This has the potential to increase speed and efficiency greatly, as most of the energy for conventional maglev trains is lost to aerodynamic drag.\n\nOne potential risk for passengers of trains operating in evacuated tubes is that they could be exposed to the risk of cabin depressurization unless tunnel safety monitoring systems can repressurize the tube in the event of a train malfunction or accident though since trains are likely to operate at or near the Earth's surface, emergency restoration of ambient pressure should be straightforward. The RAND Corporation has depicted a vacuum tube train that could, in theory, cross the Atlantic or the USA in ~21 minutes.\n\nEnergy for maglev trains is used to accelerate the train. Energy may be regained when the train slows down via regenerative braking. It also levitates and stabilises the train's movement. Most of the energy is needed to overcome \"air drag\". Some energy is used for air conditioning, heating, lighting and other miscellany.\n\nAt low speeds the percentage of power used for levitation can be significant, consuming up to 15% more power than a subway or light rail service. For short distances the energy used for acceleration might be considerable.\n\nThe power used to overcome air drag increases with the cube of the velocity and hence dominates at high speed. The energy needed per unit distance increases by the square of the velocity and the time decreases linearly. For example, 2.5 times as much power is needed to travel at than .\n\nAircraft take advantage of lower air pressure and lower temperatures by cruising at altitude to reduce energy consumption but unlike trains need to carry fuel on board. This has led to the suggestion of conveying maglev vehicles through partially evacuated tubes or tunnels with the possibility of supplying energy from renewable sources.\n\nMaglev transport is non-contact and electric powered. It relies less or not at all on the wheels, bearings and axles common to wheeled rail systems.\n\n\nDifferences between airplane and maglev travel:\n\n\nThe Shanghai maglev demonstration line cost US$1.2 billion to build in 2004. This total includes capital costs such as right-of-way clearing, extensive pile driving, on-site guideway manufacturing, in-situ pier construction at intervals, a maintenance facility and vehicle yard, several switches, two stations, operations and control systems, power feed system, cables and inverters, and operational training. Ridership is not a primary focus of this demonstration line, since the Longyang Road station is on the eastern outskirts of Shanghai. Once the line is extended to South Shanghai Train station and Hongqiao Airport station, which may not happen because of economic reasons, ridership was expected to cover operation and maintenance costs and generate significant net revenue.\n\nThe South Shanghai extension was expected to cost approximately US$18 million per kilometre. In 2006 the German government invested $125 million in guideway cost reduction development that produced an all-concrete modular design that is faster to build and is 30% less costly. Other new construction techniques were also developed that put maglev at or below price parity with new high-speed rail construction.\n\nThe United States Federal Railroad Administration, in a 2005 report to Congress, estimated cost per mile of between US$50 million and US$100 million. The Maryland Transit Administration (MTA) Environmental Impact Statement estimated a pricetag at US$4.9 billion for construction, and $53 million a year for operations of its project.\n\nThe proposed Chuo Shinkansen maglev in Japan was estimated to cost approximately US$82 billion to build, with a route requiring long tunnels. A Tokaido maglev route replacing the current Shinkansen would cost 1/10 the cost, as no new tunnel would be needed, but noise pollution issues made this infeasible.\n\nThe Japanese Linimo HSST, cost approximately US$100 million/km to build. Besides offering improved operation and maintenance costs over other transit systems, these low-speed maglevs provide ultra-high levels of operational reliability and introduce little noise and generate zero air pollution into dense urban settings.\n\nAs more maglev systems are deployed, experts expected construction costs to drop by employing new construction methods and from economies of scale.\n\nThe highest recorded maglev speed is , achieved in Japan by JR Central's L0 superconducting Maglev on 21 April 2015, faster than the conventional TGV wheel-rail speed record. However, the operational and performance differences between these two very different technologies is far greater. The TGV record was achieved accelerating down a slight decline, requiring 13 minutes. It then took another for the TGV to stop, requiring a total distance of for the test. The MLX01 record, however, was achieved on the Yamanashi test track – 1/8 the distance. No maglev or wheel-rail commercial operation has actually been attempted at speeds over .\n\nGeneral Atomics has a test facility in San Diego, that is used to test Union Pacific's freight shuttle in Los Angeles. The technology is \"passive\" (or \"permanent\"), using permanent magnets in a Halbach array for lift and requiring no electromagnets for either levitation or propulsion. General Atomics received US$90 million in research funding from the federal government. They are also considering their technology for high-speed passenger services.\n\nJapan has a demonstration line in Yamanashi prefecture where test train SCMaglev L0 Series Shinkansen reached , faster than any wheeled trains.\n\nThese trains use superconducting magnets, which allow for a larger gap, and repulsive/attractive-type electrodynamic suspension (EDS). In comparison Transrapid uses conventional electromagnets and attractive-type electromagnetic suspension (EMS).\n\nOn 15 November 2014, The Central Japan Railway Company ran eight days of testing for the experimental maglev Shinkansen train on its test track in Yamanashi Prefecture. One hundred passengers covered a route between the cities of Uenohara and Fuefuki, reaching speeds of up to .\n\nIn the US, the Federal Transit Administration (FTA) Urban Maglev Technology Demonstration program funded the design of several low-speed urban maglev demonstration projects. It assessed HSST for the Maryland Department of Transportation and maglev technology for the Colorado Department of Transportation. The FTA also funded work by General Atomics at California University of Pennsylvania to evaluate the MagneMotion M3 and of the Maglev2000 of Florida superconducting EDS system. Other US urban maglev demonstration projects of note are the LEVX in Washington State and the Massachusetts-based Magplane.\n\nOn 31 December 2000, the first crewed high-temperature superconducting maglev was tested successfully at Southwest Jiaotong University, Chengdu, China. This system is based on the principle that bulk high-temperature superconductors can be levitated stably above or below a permanent magnet. The load was over and the levitation gap over . The system uses liquid nitrogen to cool the superconductor.\n\nMax Bögl, a german construction company has built a testtrack in Sengenthal, Bavaria, Germany. In appearance it´s more like the German M-Bahn than the Transrapid system.\nThe vehicle tested on the track is patented in the US by Max Bögl.\n\nThe Shanghai Maglev Train, also known as the Transrapid, is the fastest commercial train currently in operation and has a top speed of . The line was designed to connect Shanghai Pudong International Airport and the outskirts of central Pudong, Shanghai. It covers a distance of in 8 minutes. The Shanghai system was labeled a white elephant by rivals.\n\nIn January 2001, the Chinese signed an agreement with Transrapid to build an EMS high-speed maglev line to link Pudong International Airport with Longyang Road Metro station on the eastern edge of Shanghai. This Shanghai Maglev Train demonstration line, or Initial Operating Segment (IOS), has been in commercial operations since April 2004 and now operates 115 daily trips (up from 110 in 2010) that traverse the between the two stations in 7 minutes, achieving a top speed of and averaging . On a 12 November 2003 system commissioning test run, it achieved , its designed top cruising speed. The Shanghai maglev is faster than Birmingham technology and comes with on-time – to the second – reliability greater than 99.97%.\n\nPlans to extend the line to Shanghai South Railway Station and Hongqiao Airport on the western edge of Shanghai are on hold. After the Shanghai–Hangzhou Passenger Railway became operational in late 2010, the maglev extension became somewhat redundant and may be canceled.\n\nThe commercial automated \"Urban Maglev\" system commenced operation in March 2005 in Aichi, Japan. The Tobu Kyuryo Line, otherwise known as the Linimo line, covers . It has a minimum operating radius of and a maximum gradient of 6%. The linear-motor magnetically levitated train has a top speed of . More than 10 million passengers used this \"urban maglev\" line in its first three months of operation. At , it is sufficiently fast for frequent stops, has little or no noise impact on surrounding communities, can navigate short radius rights of way, and operates during inclement weather. The trains were designed by the Chubu HSST Development Corporation, which also operates a test track in Nagoya.\n\nThe Incheon Airport Maglev began commercial operation on February 3, 2016. It was developed and built domestically. Compared to Linimo, it has a more futuristic design thanks to it being lighter with construction costs cut to half. It connects Incheon International Airport with Yongyu Station, cutting journey time.\n\nThe first maglev test trials using electromagnetic suspension opened to public was HML-03, made by Hyundai Heavy Industries for the Daejeon Expo in 1993, after five years of research and manufacturing two prototypes, HML-01 and HML-02. Government research on urban maglev using electromagnetic suspension began in 1994. The first operating urban maglev was UTM-02 in Daejeon beginning on 21 April 2008 after 14 years of development and one prototype; UTM-01. The train runs on a track between Expo Park and National Science Museum which has been shortened with the redevelopment of Expo Park. The track currently ends at the street parallel to the science museum. Meanwhile UTM-02 conducted the world's first ever maglev simulation. However UTM-02 is still the second prototype of a final model. The final UTM model of Rotem's urban maglev, UTM-03, was scheduled to debut at the end of 2014 in Incheon's Yeongjong island where Incheon International Airport is located.\n\nThe Hunan provincial government launched the construction of a maglev line between Changsha Huanghua International Airport and Changsha South Railway Station. Construction started in May 2014 and was completed by the end of 2015. Trial runs began on 26 December 2015 and trial operations started on 6 May 2016. As of 13th June 2018 the Changsha maglev covered distance of 1.7 million km and carried nearly 6 million passengers. The next generation of this vehicle is rolled off the production line and is capable of running at a top speed of 160 km/h.\n\nThe Beijing municipal government has built China's second low-speed maglev line, S1 Line, Beijing Subway, using technology developed by National University of Defense Technology. The line was opened on December 30, 2017. Its operating speed is .\n\nA second prototype system in Powder Springs, Georgia, USA, was built by American Maglev Technology, Inc. The test track is long with a curve. Vehicles are operated up to , below the proposed operational maximum of . A June 2013 review of the technology called for an extensive testing program to be carried out to ensure the system complies with various regulatory requirements including the American Society of Civil Engineers (ASCE) People Mover Standard. The review noted that the test track is too short to assess the vehicles' dynamics at the maximum proposed speeds.\n\n Construction of Chuo Shinkansen began in 2014. It was expected to begin operations by 2027. The plan for the Chuo Shinkansen bullet train system was finalized based on the Law for Construction of Countrywide Shinkansen. The Linear Chuo Shinkansen Project aimed to operate the Superconductive Magnetically Levitated Train to connect Tokyo and Osaka by way of Nagoya, the capital city of Aichi, in approximately one hour at a speed of . The full track between Tokyo and Osaka was to be completed in 2045.\n\nL0 Series train type undergoing testing by the Central Japan Railway Company (JR Central) for eventual use on the Chūō Shinkansen line set a world speed record of on 21 April 2015. The trains are planned to run at a maximum speed of , offering journey times of 40 minutes between Tokyo (Shinagawa Station) and , and 1 hour 7 minutes between Tokyo and Osaka.\n\nSkytran announced it would build an elevated network of sky cars in Tel Aviv, Israel. The technology was developed by NASA with the support of Israel Aerospace Industries. The system was meant to be suspended from an elevated track. The vehicles would travel at although the commercial rollout was expected to offer much faster vehicles. A trial of the system was to be built with a test track on the campus of Israel Aerospace Industries. Once successful, a full commercial version of SkyTran was expected to be rolled out first in Tel Aviv. The trial was scheduled to be up and running by the end of 2015. The company stated that speeds of up to are achievable.\n\nMany maglev systems have been proposed in North America, Asia and Europe. Many are in the early planning stages or were explicitly rejected.\n\nA maglev route was proposed between Sydney and Wollongong. The proposal came to prominence in the mid-1990s. The Sydney–Wollongong commuter corridor is the largest in Australia, with upwards of 20,000 people commuting each day. Current trains use the Illawarra line, between the cliff face of the Illawarra escarpment and the Pacific Ocean, with travel times about 2 hours. The proposal would cut travel times to 20 minutes.\n\n\nIn late 2008, a proposal was put forward to the Government of Victoria to build a privately funded and operated maglev line to service the Greater Melbourne metropolitan area in response to the Eddington Transport Report that did not investigate above-ground transport options. The maglev would service a population of over 4 million and the proposal was costed at A$8 billion.\n\nHowever despite road congestion and Australia's highest roadspace per capita, the government dismissed the proposal in favour of road expansion including an A$8.5 billion road tunnel, $6 billion extension of the Eastlink to the Western Ring Road and a $700 million Frankston Bypass.\n\nA first proposal was formalized in April 2008, in Brescia, by journalist Andrew Spannaus who recommended a high speed connection between Malpensa airport to the cities of Milan, Bergamo and Brescia.\n\nIn March 2011 Nicola Oliva proposed a maglev connection between Pisa airport and the cities of Prato and Florence (Santa Maria Novella train station and Florence Airport). The travelling time would be reduced from the typical 1 hour 15 minutes to around 20 minutes. The second part of the line would be a connection to Livorno, to integrate maritime, aerial and terrestrial transport systems.\n\nLondon – Glasgow: A line was proposed in the United Kingdom from London to Glasgow with several route options through the Midlands, Northwest and Northeast of England. It was reported to be under favourable consideration by the government. The approach was rejected in the Government White Paper \"Delivering a Sustainable Railway\" published on 24 July 2007. Another high-speed link was planned between Glasgow and Edinburgh but the technology remained unsettled.\n\nUnion Pacific freight conveyor: Plans are under way by American rail road operator Union Pacific to build a container shuttle between the Ports of Los Angeles and Long Beach, with UP's intermodal container transfer facility. The system would be based on \"passive\" technology, especially well suited to freight transfer as no power is needed on board. The vehicle is a chassis that glides to its destination. The system is being designed by General Atomics.\n\nCalifornia-Nevada Interstate Maglev: High-speed maglev lines between major cities of southern California and Las Vegas are under study via the California-Nevada Interstate Maglev Project. This plan was originally proposed as part of an I-5 or I-15 expansion plan, but the federal government ruled that it must be separated from interstate public work projects.\n\nAfter the decision, private groups from Nevada proposed a line running from Las Vegas to Los Angeles with stops in Primm, Nevada; Baker, California; and other points throughout San Bernardino County into Los Angeles. Politicians expressed concern that a high-speed rail line out of state would carry spending out of state along with travelers.\n\nBaltimore – Washington D.C. Maglev: A project has been proposed linking Camden Yards in Baltimore and Baltimore-Washington International (BWI) Airport to Union Station in Washington, D.C.\n\nThe Pennsylvania Project: The Pennsylvania High-Speed Maglev Project corridor extends from the Pittsburgh International Airport to Greensburg, with intermediate stops in Downtown Pittsburgh and Monroeville. This initial project was claimed to serve approximately 2.4 million people in the Pittsburgh metropolitan area. The Baltimore proposal competed with the Pittsburgh proposal for a US$90 million federal grant.\n\nSan Diego-Imperial County airport: In 2006 San Diego commissioned a study for a maglev line to a proposed airport located in Imperial County. SANDAG claimed that the concept would be an \"airports [sic] without terminals\", allowing passengers to check in at a terminal in San Diego (\"satellite terminals\"), take the train to the airport and directly board the airplane. In addition, the train would have the potential to carry freight. Further studies were requested although no funding was agreed.\n\nOrlando International Airport to Orange County Convention Center: In December 2012 the Florida Department of Transportation gave conditional approval to a proposal by American Maglev to build a privately run , 5-station line from Orlando International Airport to Orange County Convention Center. The Department requested a technical assessment and said there would be a request for proposals issued to reveal any competing plans. The route requires the use of a public right of way. If the first phase succeeded American Maglev would propose two further phases (of ) to carry the line to Walt Disney World.\n\nSan Juan – Caguas: A maglev project was proposed linking Tren Urbano's Cupey Station in San Juan with two proposed stations in the city of Caguas, south of San Juan. The maglev line would run along Highway PR-52, connecting both cities. According to American Maglev project cost would be approximately US$380 million.\n\nToronto Zoo: Edmonton-based Magnovate has proposed a new ride and transportation system at the Toronto Zoo reviving the Toronto Zoo Domain Ride system, which was closed following two severe accidents in 1994. The Zoo's board unanimously approved the proposal on November 29, 2018. \n\nThe company will construct and operate the $25 million system on the former route of the Domain Ride (known locally as the Monorail, despite not being considered one) at zero cost to the Zoo and operate it for 15 years, splitting the profits with the Zoo. The ride will serve a single-directional loop around Zoo grounds, serving five stations and likely replacing the current Zoomobile tour tram service. Planned to be operational by 2022 at the earliest, this will become the first commercially operating maglev system in North America should it be approved. \n\nOn 25 September 2007, Bavaria announced a high-speed maglev-rail service from Munich to its airport. The Bavarian government signed contracts with Deutsche Bahn and Transrapid with Siemens and ThyssenKrupp for the €1.85 billion project.\n\nOn 27 March 2008, the German Transport minister announced the project had been cancelled due to rising costs associated with constructing the track. A new estimate put the project between €3.2–3.4 billion.\n\nSwissRapide: The SwissRapide AG together with the SwissRapide Consortium was planning and developing the first maglev monorail system for intercity traffic between the country's major cities. SwissRapide was to be financed by private investors. In the long-term, the SwissRapide Express was to connect the major cities north of the Alps between Geneva and St. Gallen, including Lucerne and Basel. The first projects were Bern – Zurich, Lausanne – Geneva as well as Zurich – Winterthur. The first line (Lausanne – Geneva or Zurich – Winterthur) could go into service as early as 2020.\n\nSwissmetro: An earlier project, Swissmetro AG envisioned a partially evacuated underground maglev (a vactrain). As with SwissRapide, Swissmetro envisioned connecting the major cities in Switzerland with one another. In 2011, Swissmetro AG was dissolved and the IPRs from the organisation were passed onto the EPFL in Lausanne.\n\nShanghai – HangzhouChina planned to extend the existing Shanghai Maglev Train, initially by around to Shanghai Hongqiao Airport and then to the city of Hangzhou (Shanghai-Hangzhou Maglev Train). If built, this would be the first inter-city maglev rail line in commercial service.\n\nThe project was controversial and repeatedly delayed. In May 2007 the project was suspended by officials, reportedly due to public concerns about radiation from the system. In January and February 2008 hundreds of residents demonstrated in downtown Shanghai that the line route came too close to their homes, citing concerns about sickness due to exposure to the strong magnetic field, noise, pollution and devaluation of property near to the lines. Final approval to build the line was granted on 18 August 2008. Originally scheduled to be ready by Expo 2010, plans called for completion by 2014. The Shanghai municipal government considered multiple options, including undergrounding the line to allay public fears. This same report stated that the final decision had to be approved by the National Development and Reform Commission.\n\nIn 2007 the Shanghai municipal government was considering build a factory in Nanhui district to produce low-speed maglev trains for urban use.\n\nShanghai – BeijingA proposed line would have connected Shanghai to Beijing, over a distance of , at an estimated cost of £15.5bn. No projects had been revealed as of 2014.\n\nBeijing MetroIn October 2017 a low-speed maglev line opened in Beijing. The S1 Line operates at speeds up to 110 km/h and serves as a suburban commuter line.\n\nLow speed maglev (urban maglev) is proposed for YangMingShan MRT Line for Taipei, a circular line connecting Taipei City to New Taipei City, and almost all other Taipei transport routes, but especially the access starved northern suburbs of Tien Mou and YangMingShan. From these suburbs to the city, transit times would be reduced by 70% or more compared to peak hours, and between Tien Mou and YangMingShan, from approx 20 minutes, to 3 minutes. Key to the line is YangMingShan Station, at ‘Taipei level’ in the mountain, 200M below YangMingShan (YangMing Mountain) Village, with 40 second high speed elevators to the Village.\n\nLinimo or a similar system would be preferred, as being the core of Taipei's public transport system, it should run 24 hours a day. Also, in certain areas it would run within metres of apartments, so the near silent operation, and minimal maintenance requirements of maglev would be major advantages.\n\nAn extension of the line could run to Chiang Kai Shek Airport, and possibly on down the island, passing through major population centres, which the High Speed Rail must avoid. The minimal vibration of maglev would also be suitable to provide access Hsinchu Science Park, where sensitive silicon foundries are located. In the other direction, connection to the Tansui Line and to High Speed ferries at Tansui would provide overnight travel to Shanghai and Nagasaki, and to Busan or Mokpo in South Korea, thus interconnecting the public transport systems of four countries, with great savings in fossil fuel consumption compared to flight.\n\nYangMingShan MRT Line won the 'Engineering Excellence' Award, at the 2013 World Metro Summit in Shanghai.\n\nThe Express Rail Link, previously known as the Regional Express, which will connect Kowloon with the territory's border with China, explored different technologies and designs in its planning stage, between Maglev and conventional highspeed railway, and if the latter was chosen, between a dedicated new route and sharing the tracks with the existing West Rail. Finally conventional highspeed with dedicated new route was chosen. It is expected to be operational in 2018.\n\nMumbai – DelhiA project was presented to Indian railway minister (Mamata Banerjee) by an American company to connect Mumbai and Delhi. Then Prime Minister Manmohan Singh said that if the line project was successful the Indian government would build lines between other cities and also between Mumbai Central and Chhatrapati Shivaji International Airport.Mumbai – NagpurThe State of Maharashtra approved a feasibility study for a maglev train between Mumbai and Nagpur, some apart.Chennai – Bangalore – MysoreA detailed report was to be prepared and submitted by December 2012 for a line to connect Chennai to Mysore via Bangalore at a cost $26 million per kilometre, reaching speeds of 350 km/h.\n\nA Consortium led by UEM Group Bhd and ARA Group, proposed Maglev technology to link Malaysian cities to Singapore. The idea was first mooted by YTL Group. Its technology partner then was said to be Siemens. High costs sank the proposal. The concept of a high-speed rail link from Kuala Lumpur to Singapore resurfaced. It was cited as a proposed \"high impact\" project in the Economic Transformation Programme (ETP) that was unveiled in 2010. Approval has been given for the Kuala Lumpur-Singapore High Speed Rail project, but not using maglev technology.\n\nIn May 2009, Iran and a German company signed an agreement to use maglev to link Tehran and Mashhad. The agreement was signed at the Mashhad International Fair site between Iranian Ministry of Roads and Transportation and the German company. The line possibly could reduce travel time between Tehran and Mashhad to about 2.5 hours. Munich-based Schlegel Consulting Engineers said they had signed the contract with the Iranian ministry of transport and the governor of Mashad. \"We have been mandated to lead a German consortium in this project,\" a spokesman said. \"We are in a preparatory phase.\" The project could be worth between 10 billion and 12 billion euros, the Schlegel spokesman said.\n\nTwo incidents involved fires. A Japanese test train in Miyazaki, MLU002, was completely consumed in a fire in 1991.\n\nOn 11 August 2006, a fire broke out on the commercial Shanghai Transrapid shortly after arriving at the Longyang terminal. People were evacuated without incident before the vehicle was moved about 1 kilometre to keep smoke from filling the station. NAMTI officials toured the SMT maintenance facility in November 2010 and learned that the cause of the fire was \"thermal runaway\" in a battery tray. As a result, SMT secured a new battery vendor, installed new temperature sensors and insulators and redesigned the trays.\n\nOn 22 September 2006, a Transrapid train collided with a maintenance vehicle on a test/publicity run in Lathen (Lower Saxony / north-western Germany). Twenty-three people were killed and ten were injured; these were the first maglev crash fatalities. The accident was caused by human error. Charges were brought against three Transrapid employees after a year-long investigation.\n\nSafety becomes an ever greater concern with high speed public transport due to the potentially large impact force and number of casualties. In the case of maglev trains, an incident could result from human error, including loss of power, or factors outside human control, such as ground movement, for example, caused by an earthquake.\n\n\n\n"}
{"id": "10084099", "url": "https://en.wikipedia.org/wiki?curid=10084099", "title": "Ocean Rig", "text": "Ocean Rig\n\nOcean Rig UDW Inc. is an operator of semi-submersible oil rigs and UDW drillships based in Athens, Greece. The company also maintains offices in Luanda, Angola, Jersey, Rio de Janeiro, Brazil and Stavanger, Norway..\n\nThe company has two semi-submersibles, the \"Leiv Eiriksson\" and \"Eirik Raude\", and four ultra deepwater drill ships \"Ocean Rig Olympia\", \"Ocean Rig Mykonos\", \"Ocean Rig Poseidon\" and \"Ocean Rig Corcovado\". Four further ultra deep water drill ships are currently under construction with three due for completion in 2013, and one in 2015.\n\nAreas of operation as of 2012 are Brazil, West Africa, East Africa and the Norwegian sector.\n\nThe company was established in 1996 as Ocean Rig ASA. Ocean Rig was listed on the Oslo Stock Exchange in 1997–2008. Since 2011 it is listed in NASDAQ. In 2007–2008, 74% of the company is owned by DryShips Inc, controlled by Greek-American shipping tycoon George Economou.\n\nIn 2011 the \"Leiv Eirikson\" finished operations the Black Sea on contract to Petrobras and TPAO and went to the Arctic on contract to Cairn Energy. In 2012\n\"Leiv Eirikson\" is drilling in the East Falklands Basin. The \"Eirik Raude\" is in Ghana on contract to Tullow Oil. Both semi-submersible drilling rigs are based on the proprietary Bingo 9000 design. The rigs have a water depth capacity of and variable deck load of 7,000 tonnes.\n"}
{"id": "17444192", "url": "https://en.wikipedia.org/wiki?curid=17444192", "title": "Photonics mast", "text": "Photonics mast\n\nA photonics mast (or \"optronics mast\") is a sensor on a submarine which functions similarly to a periscope without requiring a periscope tube, thus freeing design space during construction and limiting risks of water leakage in the event of damage. A photonics mast replaces the mechanical, line-of-sight viewing system with digital equipment, similar to a digital camera array, and it has fewer locational and dimensional constraints than a traditional periscope.\n\nUnlike a periscope, it need not be located directly above its user, and it requires only a small pressure hull penetration for cabling. This allows the photonics mast to fit entirely within the sail of the submarine and means the control room need not be placed directly below the sail.\n\nA photonics mast operates by rising above the water in a manner similar to a telescoping car antenna and provides information through an array of sensors, such as high-definition low-light and thermographic cameras. Images and information can appear on display panels for analysis. The photonics mast can also support the navigation, electronic warfare, and communications functions of a conventional optical-periscope mast.\n\nThe Royal Navy tested an optronic mast on the in 1998. Boats of the currently under construction each have two optronic masts manufactured by Thales Optronics.\n\nIn 2004, the United States Navy began fitting photonics masts to s.\n\nAccording to the US Navy:\n\nIn \"Virginia\"-class boats, traditional periscopes have been supplanted by two Photonics Masts that house color, high-resolution black and white, and infrared digital cameras atop telescoping arms. With the removal of the barrel periscopes, the ships’ control room has been moved down one deck and away from the hull’s curvature, affording it more room and an improved layout that provides the commanding officer with enhanced situational awareness.\n\n"}
{"id": "45430318", "url": "https://en.wikipedia.org/wiki?curid=45430318", "title": "Plan Bay Area", "text": "Plan Bay Area\n\nPlan Bay Area 2040 is a state-mandated law that aims to integrate sustainable strategies to reduce transportation-related pollution and external greenhouse gas emission within the nine-counties of the San Francisco Bay Area. It is also known as the implementation of the Sustainable Communities and Climate Protection Act of 2008 or SB 375. The plan addresses methods of transportation, land-use, and housing. Over the next 25 years, the Bay Area is expected to grow by an estimated 2 million people and because of the projected growth and the growing economy, the Bay Area must provide more housing and transportation choices that will reduce their carbon footprint.\n\nThis adopted plan will invest in increasing methods of transportation with the goal of reducing CO2 emissions. To do so, the plan will invest in extending ferry services, freeway express lanes, and developing newer BART Stations to expand travel reach.\n\nThe goal of this plan is to improve on their earlier efforts of network and growth within the context of finance and environmental responsibility. Like all plans, it is a work in progress that is updated every four years to reflect on new priorities and changes with the goal of reducing greenhouse gas emissions.\n\nThe plan was approved on July 18, 2013 by the Association of Bay Area Governments and by the Metropolitan Transportation Commission.\n\nThe adoption of the plan by regional planners was covered by the San Francisco Chronicle.\n\nThe Bay Area is home to a high concentration of knowledge-based industries, research centers and universities. It is located at one of the most famous tech clusters widely known throughout the globe as Silicon Valley. With the various industries available within the region, it does not come as a surprise that the Bay Area is also home to a highly educated and international labor market.\n\nThe Bay Area attracts highly skilled and educated individuals around the world as it is the global epicenter for advancements in technology and related knowledge-based industries. Despite this growing population and the increase access of job opportunities, there is limited housing options available.\n\nDue to the continual growth of companies coming moving into the Bay Area, there is a high demand of employment. However, there is a low supply of housing available to accommodate these workers.\n\nThe Job-Housing Strategy consists of addressing housing, economic development, transportation, and land conservation policies in order to support long-term growth. This strategy focuses on locally designated Priority Development Areas to attract economic potential by providing housing and increasing transportation options for the growing demand of workers. This strategy consists of four goals: \nThe hope of these goals is to strengthen regional infrastructure and preserve agriculture land and natural resources.\n\nThe final blueprint for directing all growth in the Bay Area is to reduce urban sprawl onto natural and agricultural land. Some of the highlights include the following: \n"}
{"id": "42369099", "url": "https://en.wikipedia.org/wiki?curid=42369099", "title": "Ramleh (band)", "text": "Ramleh (band)\n\nRamleh are a British experimental music group formed by musician Gary Mundy in 1982. The current line-up of the band includes Gary Mundy, Anthony di Franco and Stuart Dennison. Originally a part of the English power electronics and industrial music scene in early 1980s, Ramleh experimented with a more traditional rock format in their later releases.\n\nThe group was formed by Mundy in 1982 as a part of the power electronics scene in early 1980s, which included artists such as Whitehouse and Sutcliffe Jügend. After releasing \"Onslaught\" cassette, he was joined by Philip Best, a 14-year-old musician who was known for his involvement in Iphar and Whitehouse. The band's \"21/5/62/82\" cassette was released in 1982 and was titled as a reference to the execution of Nazi war criminal Adolf Eichmann. Ramleh recorded four more cassette releases in 1982: \"Onslaught\", \"Live to Theresienstadt\", \"Live New Force\", and \"Live Phenol\". \"Live McCarthy\", \"Live at Moden Tower 12/10/1983\", and \"Live at Prossneck 1/10/83\", A Return to Slavery and The Hand of Glory EPs were added to the band's catalogue in 1983. This was followed by a string of cassette releases in 1983. Although Ramleh disbanded in 1984, Mundy's own record label Broken Flag continued releasing Ramleh material.\n\nAfter releasing \"Hole in the Heart\" cassette and a few records under the Ramleh alias in 1987, Mundy reformed the band in 1989 with Best. The reunion was followed by \"Grudge for Life\" LP in 1989. Inspired by Mundy's experimental rock band Skullflower, the band began to incorporate rock influences in their records, starting with \"Blowhole\" in 1991. After releasing \"Caught From Behind\", a split with Italian artist M.T.T, and \"Crystal Revenge\", the band added Skullflower members Anthony di Franco on bass and Stuart Dennison on drums to its line-up. The new line-up released \"Homeless\" in 1994. The band continued releasing rock records in late 1990s, which included \"Adieu, All You Judges\" and \"Be Careful What You Wish For\" in 1995, and \"Works III\" in 1996. After releasing \"Boeing\", Mundy disbanded Ramleh for the second time.\n\nIn 2009, Mundy and di Franco reformed Ramleh with drummer Martyn Watts. In that year, the band also returned to its original power electronics aesthetics with \"Valediction\" LP, although Mundy states that the band will be performing in both rock and electronic genres. In 2015, Stuart Dennison returned to drum with Ramleh and played on the US west coast tour in January 2016.\n\nEarly recordings of Ramleh were labeled as power electronics and noise music. Nevertheless, in 1990s the band started experiment with more traditional rock music structures. The band's more traditional works were commonly labeled as \"noise rock.\" Frances Morgan of The Quietus described the band music during this era as \"a brutal, abject strand of dark psychedelic rock,\" while albums such as \"Works III\" and \"Boeing\" were labeled as \"heavy psych-noise rock.\" Skullflower and Butthole Surfers were influences on these works. Ramleh's first album after 2009 reunion expressed a revival of the band's original power electronics genre and was compared to the works of Japanese noise musician Merzbow, while the band retained its rock music instrumentation during this era, performing on both genres.\n\nIn its early days, Ramleh flirted with Nazi and fascist imagery for its shock value, like other bands in the industrial music scene. Nevertheless, Mundy and Best since discontinued this practice and disavowed it, denying any affiliations with hate groups.\n\n\n\n\n\n\n"}
{"id": "5777268", "url": "https://en.wikipedia.org/wiki?curid=5777268", "title": "Real photo postcard", "text": "Real photo postcard\n\nA real photo postcard (RPPC) is a continuous-tone photographic image printed on postcard stock. The term recognizes a distinction between the real photo process and the lithographic or offset printing processes employed in the manufacture of most postcard images.\n\nIn 1903 Kodak introduced the No. 3A Folding Pocket Kodak. The camera, designed for postcard-size film, allowed the general public to take photographs and have them printed on postcard backs, usually in the same dimensions (3-1/2\" x 5-1/2\") as standard vintage postcards. Many other cameras were used, some of which used glass photographic plates that produced images that had to be cropped in order to fit the postcard format.\n\nIn 1907, Kodak introduced a service called \"real photo postcards,\" which enabled customers to make a postcard from any picture they took.\n\nWhile Kodak was the major promoter of photo postcard production, the company used the term \"real photo\" less frequently than photographers and others in the marketplace from 1903 to ca. 1930.\n\n\"Old House Journal\" states that \"beginning in 1902 Kodak offered a preprinted card back that allowed postcards to be made directly from negatives.\" This technology allowed photographers to travel from town to town and document life in the places they visited. \"Old House Journal\" continues: \"Local entrepreneurs hired them to record area events and the homes of prominent citizens. These postcards documented important buildings and sites, as well as parades, fires, and floods. Realtors used them to sell new housing by writing descriptions and prices on the back. Real photo postcards became expressions of pride in home and community, and were also sold as souvenirs in local drug stores and stationery shops.\" \n\nOn March 1, 1907, Federal legislation permitted senders, for the first time, to include a message on a portion of the back of a postcard. (Prior to that time, the address only was allowed on one side while the other side could present a photo or artwork.) The front side could then accommodate a full-size real photograph. The popularity of real photo postcards soared nationwide, and many people began collecting the cards in albums. No other single format has provided such a massive photo history of America, particularly of small-town and rural America where photography was often a luxury. Many real photo postcards were unique prints captured by amateur photographers, but others were mass-produced by companies such as the Eastern Illustrating and Publishing Company in Belfast, Maine. Real photo postcards were sometimes created and sold as mementoes at the scene of lynchings; they were also used to document such important events as the Mexican Revolution.\n\nReal photo postcards may or may not have a white border, or a divided back, or other features of postcards, depending on the paper the photographer used.\n\n\n"}
{"id": "18892315", "url": "https://en.wikipedia.org/wiki?curid=18892315", "title": "Real versus nominal value", "text": "Real versus nominal value\n\nThe distinction between real value and nominal value occurs in many fields. From a philosophical viewpoint, nominal value represents an accepted condition, which is a goal or an approximation, as opposed to the real value, which is always present. \n\nIn measurement, a nominal value is often a value existing in name only; it is assigned as a convenient designation rather than calculated by data analysis or following usual rounding methods. The use of nominal values can be based on de facto standards or some technical standards.\n\nAll real measurements have some variation depending on the accuracy and precision of the test method and the measurement uncertainty. The use of reported values often involves engineering tolerances.\n\nOne way to consider this is that the real value often has the characteristics of an irrational number. In real-world measuring situations, improving the measurement technique will eventually begin yielding unpredictable least significant digits. For example, a 1-inch long gauge block will measure to be exactly 1 inch long until the measuring techniques reach a certain degree of precision. As techniques improve beyond this threshold, it will become clear that 1 inch is not the real value of the gauge block length, but some other number approximates it.\n\nIn various subfields of engineering, a nominal value is one for which the \"name\" for the value is close to, but not the same as, the actual value. Some examples:\n\n\nOther cases involve diameter, speed, and volume.\n\nSometimes the word \"nominal\" is misused in engineering contexts as a synonym for \"normal\" or \"expected\"; for example, \"The rotor resistances on all the other operating wheels are nominal.\"\n\n"}
{"id": "157332", "url": "https://en.wikipedia.org/wiki?curid=157332", "title": "Reprography", "text": "Reprography\n\nReprography is the reproduction of graphics through mechanical or electrical means, such as photography or xerography. Reprography is commonly used in catalogs and archives, as well as in the architectural, engineering, and construction industries.\n\nIn the United States, the industry is a relatively small industry, with approximately 3000 firms. It comprises entrepreneurial businesses serving predominantly the large- and wide-format reproduction needs of the legal, architectural, engineering, manufacturing, retail, and advertising industries. Average sales volume is about $1.5 million and average employee counts are 20–25 people.\n\nLarge-format reproductions are produced with a variety of technologies dependent, in part, on the application of the final product and quantity needed. Examples of typical reproduction methods include: diazo (blueline), electrostatic (xerographic), photographic, laser, and ink jet.\n\nReproductions can be made from the same size or smaller/larger hard copy originals. Prints can also be computer generated from CADD (computer aided design and drafting) files or from a growing variety of desktop publishing and design software packages.\n\nIn addition to addressing the large-format reproduction needs of their customers, reprographers frequently sell reprographic equipment and consumable supplies. Other business services such as mounting and lamination, quick copying, microfilming, scanning and facility management may also be provided.\n\nTypical items produced by reprographers include architectural/engineering blueprints and renderings, indoor and outdoor signage, maps, billboards, backlit displays, trade show graphics, legal and medical exhibits, etc. \nMost of the reprographics firms in the United States belong to the International Reprographics Association (IRgA).\n\nReprographics is also referred to as \"reproprinting\".\n\n\n"}
{"id": "56951528", "url": "https://en.wikipedia.org/wiki?curid=56951528", "title": "SAE J3068", "text": "SAE J3068\n\nSAE J3068 is a North American recommended practice published and maintained by SAE International. J3068 defines electrical connectors and a control protocol for electric vehicles. It has the formal title \"SAE Surface Vehicle Recommended Practice J3068\". J3068 defines a system of conductive power transfer to an electric vehicle using a coupler capable of transferring single-phase and three-phase AC power as well as DC power, and defines a digital communication system for control. J3068 also specifies requirements for the vehicle inlet, supply equipment connector, mating housings and contacts. \n\nInitial discussions in the Electric Power Research Institute's Infrastructure Working Council meetings regarding issues related to three-phase charging in North America led to the development of J3068. There was a lack of non-proprietary, UL listed equipment that could be legally used in the United States. Some large electric vehicles were being charged without using ground fault protection, and without connectors that automatically de-enegerize when disconnected from the vehicle. \n\nTherefore, SAE authorized a new Task Force to develop a standard that focused on heavy and medium duty applications, and more generally any vehicle charging at commercial and industrial locations or other places where three-phase power is available and preferred. Early within the development of the standard, it was decided that the J3068 connector and inlet would based on the IEC 62196 Type 2 connector.\n\nThe control protocol is a variation of LIN which retains the analog voltage level signaling from SAE J1772. The positive level of the LIN signal waveform can change from 12 volts to 9 or 6 volts (known as State A, State B, and State C in J1772). An earlier version of this LIN-based control protocol was published in Annex D of IEC 61851 edition 3. Major contributors to the development of this protocol include ABB in Sweden, the University of Delaware, Vattenfall Sweden, Mack Trucks/Volvo Trucks North America and others.\n\nJ3068 states that it aims to cover three-phase equipment which meets applicable North American listing standards. \n\nThe core standards for Electric Vehicle Supply Equipment in North America are tri-national standards for Mexico, Canada, and the United States. See CANENA. They are essentially equivalent documents with different names in each country. \n\nThe J3068 connector is mechanically identical to the Type 2 connector, because it makes Normative references to IEC 62196-2 and -3. Additionally, J3068 supports voltage ratings which align with North American grid voltages and EVSE standards. Unlike Europe where the most common type of three-phase Wye power is nominally 400/230 VAC (meaning \"line-to-line/line-to-neutral Volts Alternating Current\"), in North America the three most common three-phase wye voltages are 208/120, 480/277, and 600/347 VAC. \n\nIEC standards limit single-phase AC charging to 250 VAC (see IEC 62196-2). Three-phase EVSE and single-phase vehicles are designed to be interoperable. A 480 phase-to-phase VAC rating is theoretically allowed in the IEC document but this is mathematically incongruent with the 250 VAC single phase limit. It effectively limits the maximum three-phase rating to 433VAC (250 * ), and means you cannot make a 480/277 VAC EVSE without exceeding the 250 VAC single phase limit. The SAE J3068 standard defines a system for nominal voltage ratings up to 600 VAC, which is also the maximum voltage rating covered by UL 2594.\n\nWhere AC voltages and current ratings exceed 250 VAC phase-to-neutral and/or 63 amps, digital communication (LIN-CP) is required. Even in the case of a North American EV designed to charge from 208/120 VAC three-phase, LIN-CP controls are required unless the EV can at least tolerate 400/230 VAC long enough to signal the EVSE to turn off the power, if it cannot actually charge from 400/230 VAC. This is because the typical European EV designed for three phase charging will be exposed to 400/230 with PWM controls, and there is no guarantee that a North American three-phase EV will not be exposed to European supply voltages if it is exported. \n\nUL 2594 requires any EVSE that supplies more than 250 VAC be permanently wired to the mains (IEC 61851-1 calls this Mode 3). J3068 requires EV cord sets to be permanently connected (IEC 61851-1 calls this Case C). \n\nExample 1: A J3068 EVSE supplying 480/277 VAC at up to 100A is sold in the United States. The EVSE will be tested to UL2594 and the grid power will be wired directly into the EVSE. NFPA 70, Article 625, requires the breaker/fuse and wiring be sized for 125A because the load is up to 100A continuous. The vehicle cord set used will be tested to UL 2251 and be permanently attached to the station. Digital communications (LIN-CP) will check the vehicle is compatible with this voltage (480/277 VAC) and indicate maximum charge rate of 100A. \n\nExample 2: An imported passenger EV which only supports 61851-1 Annex A is connected to a 600/347 VAC Canadian EVSE designed to comply with J3068. The vehicle would be protected from potential damage, because the charging station would not close its internal relay. Only a vehicle which supports LIN-CP and indicates it accepts 600VAC could use the EVSE. \n\nBasic AC charging as defined in SAE J1772 and IEC 61851-1 Annex A via analog control pilot and is used with a variety of single-phase AC grid voltages lower than 250VAC. LIN-CP or Local Interconnect Network on the Control Pilot was originally specified in IEC 61851-1 Annex D in Edition 3. Unlike PLC over Control Pilot (IEC 15118-2), it's designed to be a low-cost replacement for the PWM controls. \n\nThis is similar the approach used by Tesla based on J2411 (Single-wire CAN), but maintains the CP voltage levels to be compatible with existing EVSE safety models. \n\nLIN transceivers used for J3068 must have an extended supply range. For example, the TI SN65HVDA100-Q1 operators from 5V to 27V. This is because the LIN transceiver must operate when the Control Pilot is at 6V level. \n\nThe J3068 coupler is defined by reference to the IEC 62196 specifications, there are no mechanical differences. Voltage ratings are higher, but the original coupler was designed to support North American voltages, even if the PWM controls were not. Underwriters Laboratories standards may allow certification of advanced design implementations at higher currents than the European standard, which is more conservative than other EV charging coupler current densities. For example, the European 63 amp rating for the Type 2 connector 6 mm pins equates to about 2.23 amps per square mm of cross section, while the 200 amp rating for the 8 mm DC pins (without cooling) equates to 3.98 amps/mm. \n\nWhile J3068 focuses on AC charging (using the four smaller 6 mm pins), it also defines J3068 DC charging which is completely compatible with European Type 2 DC charging using the 8 mm pins (often referred to as \"CCS\", although the term \"CCS\" is not used in the IEC standards documents). Both systems are identical, J3068 neither adds nor takes away from the existing DC charging standards, but merely references them. J3068 AC is fully interoperable with J3068 DC, both systems can be implemented in the same vehicle without complication. Further, the only significant electrical difference between J3068 DC and J1772 DC charging is the value of the Prox resistor. (The coupler has mechanical differences, of course.)\n\nJ3068 AC charging using the 6 mm pins may be implemented using older PWM controls (instead of the newer digital LIN controls) if the voltages do not exceed 433 VAC from line to line, and do not exceed 250 VAC from line to neutral. However, this may not be optimal since a system designed for 400/230 VAC will probably not deliver sufficient charging power at 208/120 VAC, which is the only common voltage that is compatible with PWM controls in North America. For this reason, J3068 is best implemented with support for LIN controls in North America. For example, a charging system on a truck which is optimized for a highest nominal voltage of 208/120 VAC three phase (see Appendix E, figure 19 on page 91 of J3068) might simply refuse to charge if it does not detect LIN controls, thereby protecting itself from possible exposure to 400/230 VAC which is common with PWM controls. Vehicles that can safely charge from 400/230 VAC and higher might support both LIN and PWM, to maximize the ability to charge at more locations.\n\nDepending on the topology of the vehicle on-board charger, it may be possible to charge from a J1772 EVSE using an adapter. While adapters are generally discouraged, manufacturer specific adapters might be useful and are allowed in some countries according to IEC. Such an adapter shall be rated for 80 amps, as there is no practical way to signal the adapter's current rating. For example, an on-board charger configured for 480/277 which consists of three single-phase chargers wired from line to neutral, might support an adapter configured that connects L1, L2, and L3 of the J3068 together and to L1 of the J1772 input, and wires N from the J1772 inlet to N on the J3068 inlet. The vehicle must be able to detect the differences between Prox pin resistances and must scale the current limit to 1/3 for each charger in this example. Other configurations are possible depending on the design of the vehicle charger.\n\n"}
{"id": "4725497", "url": "https://en.wikipedia.org/wiki?curid=4725497", "title": "Slipform stonemasonry", "text": "Slipform stonemasonry\n\nSlipform stone masonry is a method for making a reinforced concrete wall with stone facing in which stones and mortar are built up in courses within reusable slipforms. It is a cross between traditional mortared stone wall and a veneered stone wall. Short forms, up to 60 cm high, are placed on both sides of the wall to serve as a guide for the stone work. The stones are placed inside the forms with the good faces against the form work. Concrete is poured in behind the rocks. Rebar is added for strength, to make a wall that is approximately half reinforced concrete and half stonework. The wall can be faced with stone on one side or both sides. After the concrete sets enough to hold the wall together, the forms are “slipped’ up to pour the next level. With slipforms it is easy for a novice to build free-standing stone walls. \n\nSlipform stone masonry was developed by New York architect Ernest Flagg in 1920. Flagg built a vertical framework as tall as the wall, then inserted 2x6 or 2x8 planks as forms to guide the stonework. When the masonry work reached the top of a plank, Flagg inserted another one, adding more planks until he reached the top of the wall. Helen and Scott Nearing modified the technique in Vermont in the 1930s, using slipforms that were slipped up the wall. \n\nThe diagram of the slipform wall section is completely misleading without showing the 2nd form. \n\n"}
{"id": "683436", "url": "https://en.wikipedia.org/wiki?curid=683436", "title": "Space elevator economics", "text": "Space elevator economics\n\nSpace elevator economics compares the cost of sending a payload into Earth orbit via a space elevator with the cost of doing so with alternatives, like rockets.\n\nThe costs of using a well-tested system to launch payloads are high. Prices range from about $2,350/kg for a Falcon Heavy launch to about US$40,000/kg for a Pegasus launch (2004). Various systems that have been proposed have offered lower rates, but have failed to get sufficient funding (Roton; Sea Dragon), are still under development like New Glenn or the BFR (which promises prices as low as $47/kg and first flight in the 2020s), or more commonly, have financially underperformed (as in the case of the Space Shuttle). The Shtil-3a rocket offers costs approximately $400/kg, but launches are infrequent and have a comparatively small payload, and its costs are partially subsidized by the Russian navy as part of launch exercises.\n\nRocket costs have changed relatively little since the 1960s, but the market has been very flat.\n\nFor a space elevator, the cost varies according to the design. Bradley C. Edwards received funding from NIAC from 2001 to 2003 to write a paper, describing a space elevator design. In it he stated that: \"The first space elevator would reduce lift costs immediately to $100 per pound\" ($220/kg).\n\nThe gravitational potential energy of any object in geosynchronous orbit (GEO), relative to Earth's surface, is about 50 MJ (15 kWh) of energy per kilogram (see geosynchronous orbit for details). Using wholesale electricity prices for 2008 to 2009, and the current 0.5% efficiency of power beaming, a space elevator would require US$220/kg just in electrical costs. Dr. Edwards expects technical advances to increase the efficiency to 2%.\n\nHowever, due to the fact that space elevators would have a limited throughput as only a few payloads could climb the tether at any one time, the launch price may be subject to market forces.\n\nAccording to a paper presented at the 55th International Astronautical Congress in Vancouver in October 2004, the space elevator can be considered a prestige megaproject whose current estimated cost (US$6.2 billion) is favourable compared to other megaprojects e.g. bridges, pipelines, tunnels, tall towers, high-speed rail links and maglevs. Costs are also favourable compared to that of other aerospace systems and launch vehicles.\n\nA space elevator built according to the Edwards proposal is estimated to cost $6 billion.\n\nFor comparison, in potentially the same time frame as the elevator, the Skylon, a 12,000 kg cargo capacity single-stage-to-orbit spaceplane (not a conventional rocket) is estimated to have an R&D and production cost of about $15 billion. The vehicle has about $3,000/kg price tag. Skylon would be suitable to launch cargo \"and particularly\" people to low/medium Earth orbit (targeting maximum 30 people per flight). Early space elevator designs move only cargo but could move people as well to a much wider range of destinations. Another alternative project to get large numbers of people and cargo to orbit inexpensively during this time frame is the BFR rocket which, like Skylon, is not a conventional rocket design as it will be fully reusable. Its cargo capacity will be 150,000 kg (250,000 kg if expendable), is estimated to have an R&D cost of $10 billion, and production cost of about $200-million for a ship, $130-million for a tanker and $230-million for a booster. The system has a less than $140/kg price tag which is possibly as low as $47/kg. It will be capable of transporting 100 people comfortably to Mars (therefore significantly more to low/medium earth orbit)\n"}
{"id": "1381368", "url": "https://en.wikipedia.org/wiki?curid=1381368", "title": "Superlattice", "text": "Superlattice\n\nA superlattice is a periodic structure of layers of two (or more) materials. Typically, the thickness of one layer is several nanometers. It can also refer to a lower-dimensional structure such as an array of quantum dots or quantum wires.\n\nSuperlattices were discovered early in 1925 by Johansson and Linde after the studies on gold-copper and palladium-copper systems through their special X-ray diffraction patterns. Further experimental observations and theoretical modifications on the field were done by Bradley and Jay, Gorsky, Borelius, Dehlinger and Graf, Bragg and Williams and Bethe. Theories were based on the transition of arrangement of atoms in crystal lattices from disordered state to an ordered state.\n\nJ.S. Koehler theoretically predicted that by using alternate (nano-)layers of materials with high and low elastic constants, shearing resistance is improved by up to 100 times as the Frank–Read source of dislocations cannot operate in the nanolayers.\n\nThe increased mechanical hardness of such superlattice materials was confirmed firstly by Lehoczky in 1978 on Al-Cu and Al-Ag, and later on by several others, e.g. Barnett and Sproul on hard PVD coatings.\n\nIf the superlattice is made of two semiconductor materials with different band gaps, each quantum well sets up new selection rules that affect the conditions for charges to flow through the structure. The two different semiconductor materials are deposited alternately on each other to form a periodic structure in the growth direction. Since the 1970 proposal of synthetic superlattices by Esaki and Tsu, advances in the physics of such ultra-fine semiconductors, presently called quantum structures, have been made. The concept of quantum confinement has led to the observation of quantum size effects in isolated quantum well heterostructures and is closely related to superlattices through the tunneling phenomena. Therefore, these two ideas are often discussed on the same physical basis, but each has different physics useful for applications in electric and optical devices.\n\nSuperlattice miniband structures depend on the heterostructure type, either \"type I\", \"type II\" or \"type III\". For type I the bottom of the conduction band and the top of the valence subband are formed in the same semiconductor layer. In type II the conduction and valence subbands are staggered in both real and reciprocal space, so that electrons and holes are confined in different layers. Type III superlattices involve semimetal material, such as HgTe/CdTe. Although the bottom of the conduction subband and the top of the valence subband are formed in the same semiconductor layer in Type III superlattice, which is similar with Type I superlattice, the band gap of Type III superlattices can be continuously adjusted from semiconductor to zero band gap material and to semimetal with negative band gap.\n\nAnother class of quasiperiodic superlattices is named after Fibonacci. A Fibonacci superlattice can be viewed as a one-dimensional quasicrystal, where either electron hopping transfer or on-site energy takes two values arranged in a Fibonacci sequence.\n\nSemiconductor materials, which are used to fabricate the superlattice structures, may be divided by the element groups, IV, III-V and II-VI. While group III-V semiconductors (especially GaAs/AlGaAs) have been extensively studied, group IV heterostructures such as the SiGe system are much more difficult to realize because of the large lattice mismatch. Nevertheless, the strain modification of the subband structures is interesting in these quantum structures and has attracted much attention.\n\nIn the GaAs/AlAs system both the difference in lattice constant between GaAs and AlAs and the difference of their thermal expansion coefficient are small. Thus, the remaining strain at room temperature can be minimized after cooling from epitaxial growth temperatures. The first compositional superlattice was realized using the GaAs/AlGaAs material system.\n\nA graphene/boron nitride system forms a semiconductor superlattice once the two crystals are aligned. Its charge carriers move perpendicular to the electric field, with little energy dissipation. h-BN has a hexagonal structure similar to graphene's. The superlattice has broken inversion symmetry. Locally, topological currents are comparable in strength to the applied current, indicating large valley-Hall angles.\n\nSuperlattices can be produced using various techniques, but the most common are molecular-beam epitaxy (MBE) and sputtering. With these methods, layers can be produced with thicknesses of only a few atomic spacings. An example of specifying a superlattice is []. It describes a bi-layer of 20Å of Iron (Fe) and 30Å of Vanadium (V) repeated 20 times, thus yielding a total thickness of 1000Å or 100 nm. The MBE technology as a means of fabricating semiconductor superlattices is of primary importance. In addition to the MBE technology, metal-organic chemical vapor deposition (MO-CVD) has contributed to the development of superconductor superlattices, which are composed of quaternary III-V compound semiconductors like InGaAsP alloys. Newer techniques include a combination of gas source handling with ultrahigh vacuum (UHV) technologies such as metal-organic molecules as source materials and gas-source MBE using hybrid gases such as arsine () and phosphine () have been developed.\n\nGenerally speaking MBE is a method of using three temperatures in binary systems, e.g., the substrate temperature, the source material temperature of the group III and the group V elements in the case of III-V compounds.\n\nThe structural quality of the produced superlattices can be verified by means of X-ray diffraction or neutron diffraction spectra which contain characteristic satellite peaks. Other effects associated with the alternating layering are: giant magnetoresistance, tunable reflectivity for X-ray and neutron mirrors, neutron spin polarization, and changes in elastic and acoustic properties. Depending on the nature of its components, a superlattice may be called \"magnetic\", \"optical\" or \"semiconducting\".\n\nThe schematic structure of a periodic superlattice is shown below, where A and B are two semiconductor materials of respective layer thickness \"a\" and \"b\" (period: formula_1). When \"a\" and \"b\" are not too small compared with the interatomic spacing, an adequate approximation is obtained by replacing these fast varying potentials by an effective potential derived from the band structure of the original bulk semiconductors. It is straightforward to solve 1D Schrödinger equations in each of the individual layers, whose solutions formula_2 are linear combinations of real or imaginary exponentials.\n\nFor a large barrier thickness, tunneling is a weak perturbation with regard to the uncoupled dispersionless states, which are fully confined as well. In this case the dispersion relation formula_3, periodic over formula_4 with over formula_5 by virtue of the Bloch theorem, is fully sinusoidal:\n\nand the effective mass changes sign for formula_7:\n\nIn the case of minibands, this sinusoidal character is no longer preserved. Only high up in the miniband (for wavevectors well beyond formula_9) is the top actually 'sensed' and does the effective mass change sign. The shape of the miniband dispersion influences miniband transport profoundly and accurate dispersion relation calculations are required given wide minibands. The condition for observing single miniband transport is the absence of interminiband transfer by any process. The thermal quantum \"kT\" should be much smaller than the energy difference formula_10 between the first and second miniband, even in the presence of the applied electric field.\n\nFor an ideal superlattice a complete set of eigenstates states can be constructed by products of plane waves formula_11 and a \"z\"-dependent function formula_12 which satisfies the eigenvalue equation\n\nAs formula_14 and formula_15 are periodic functions with the superlattice period \"d\", the eigenstates are Bloch state formula_16 with energy formula_17. Within first-order perturbation theory in k, one obtains the energy\n\nNow, formula_19 will exhibit a larger probability in the well, so that it seems reasonable to replace the second term by\n\nwhere formula_21 is the effective mass of the quantum well.\n\nBy definition the Bloch functions are delocalized over the whole superlattice. This may provide difficulties if electric fields are applied or effects due to the superlattice's finite length are considered. Therefore, it is often helpful to use different sets of basis states that are better localized. A tempting choice would be the use of eigenstates of single quantum wells. Nevertheless, such a choice has a severe shortcoming: the corresponding states are solutions of two different Hamiltonians, each neglecting the presence of the other well. Thus these states are not orthogonal, creating complications. Typically, the coupling is estimated by the transfer Hamiltonian within this approach. For these reasons, it is more convenient to use the set of Wannier functions.\n\nApplying an electric field \"F\" to the superlattice structure causes the Hamiltonian to exhibit an additional scalar potential \"eφ\"(\"z\") = −\"eFz\" that destroys the translational invariance. In this case, given an eigenstate with wavefunction formula_22 and energy formula_23, then the set of states corresponding to wavefunctions formula_24 are eigenstates of the Hamiltonian with energies \"E\" = \"E\" − \"jeFd\". These states are equally spaced both in energy and real space and form the so-called \"Wannier–Stark ladder\". The potential formula_25 is not bounded for the infinite crystal, which implies a continuous energy spectrum. Nevertheless, the characteristic energy spectrum of these Wannier–Stark ladders could be resolved experimentally.\n\nThe motion of charge carriers in a superlattice is different from that in the individual layers: mobility of charge carriers can be enhanced, which is beneficial for high-frequency devices, and specific optical properties are used in semiconductor lasers.\n\nIf an external bias is applied to a conductor, such as a metal or a semiconductor, typically an electric current is generated. The magnitude of this current is determined by the band structure of the material, scattering processes, the applied field strength and the equilibrium carrier distribution of the conductor.\n\nA particular case of superlattices called superstripes are made of superconducting units separated by spacers. In each miniband the superconducting order parameter, called the superconducting gap, takes different values, producing a multi-gap, or two-gap or multiband superconductivity.\n\nSoon after two-dimensional electron gases (2DEG) had become commonly available for experiments, research groups attempted to create structures that could be called 2D artificial crystals. The idea is to subject the electrons confined to an interface between two semiconductors (i.e. along \"z\"-direction) to an additional modulation potential \"V\"(\"x\",\"y\"). Contrary to the classical superlattices (1D/3D, that is 1D modulation of electrons in 3D bulk) described above, this is typically achieved by treating the heterostructure surface: depositing a suitably patterned metallic gate or etching. If the amplitude of \"V\"(\"x\",\"y\") is large (take formula_26 as an example) compared to the Fermi level, formula_27, the electrons in the superlattice should behave similarly to electrons in an atomic crystal with square lattice (in the example, these \"atoms\" would be located at positions (\"na\",\"ma\") where \"n\",\"m\" are integers).\n\nThe difference is in the length and energy scales. Lattice constants of atomic crystals are of the order of 1Å while those of superlattices (\"a\") are several hundreds or thousands larger as dictated by technological limits (e.g. electron-beam lithography used for the patterning of the heterostructure surface). Energies are correspondingly smaller in superlattices. Using the simple quantum-mechanically confined-particle model suggests formula_28. This relation is only a rough guide and actual calculations with currently topical graphene (a natural atomic crystal) and artificial graphene (superlattice) show that characteristic band widths are of the order of 1 eV and 10 meV, respectively. In the regime of weak modulation (formula_29), phenomena like commensurability oscillations or fractal energy spectra (Hofstadter butterfly) occur.\n\nArtificial two-dimensional crystals can be viewed as a 2D/2D case (2D modulation of a 2D system) and other combinations are experimentally available: an array of quantum wires (1D/2D) or 3D/3D photonic crystals.\n\n\n"}
{"id": "35823635", "url": "https://en.wikipedia.org/wiki?curid=35823635", "title": "Surgically implanted explosive device", "text": "Surgically implanted explosive device\n\nA surgically implanted improvised explosive device (SIIED) is an explosive device hidden inside the body of a person in order to commit a suicide attack. This type of terrorist weapon, more commonly known as Body Cavity Bomb (BCB), is only known to have been used once, in a failed assassination attempt.\n\nIn August 2009 Abdullah al-Asiri, the younger brother of Ibrahim al-Asiri (Al Qaeda in the Arabian Peninsula's chief bomb-maker), tried to assassinate a Saudi prince Muhammad bin Nayef with a bomb, later identified as a 'Body Cavity Bomb' (BCB). Al-Asiri absorbed most of the blast, which killed him instantly. Bin Nayef escaped with only minor injuries.\n\nIn May 2012, various reporters leaked their acquisition of documents describing the preparation and use of such devices.\nAccording to \"The Daily Mirror\" in the UK, security officials at MI-6 asserted that female bombers could travel undetected carrying the explosive chemicals in otherwise standard breast implants. The bomber would blow up the implanted explosives by injecting a chemical trigger.\n\nThe concept of a surgically implanted improvised explosive device (SIIED) is derived from the Body Cavity Bomb (BCB) concept enunciated by Robert J. Bunker, a research associate at the Terrorism Research Center. Bunker's work for the last few years, has been on assessing the potential use of body cavity bombs (BCB) or body cavity suicide bombs (BCSB) as a variation of suicide bombing tactics, techniques, and procedures (TTPs).\n\nThe term SIIED was used in a \"Newsweek\" article in May 2012 which described it as an \"explosive device hidden inside the body of a person in order to commit a suicide attack.\" However, it should be noted that, currently the United States Department of Defense Dictionary of Military Terms, only recognizes the acronym 'IED (improvised explosive device)'.\n\nBunker's 2011 report largely originated with the 2005 International Association of Chiefs of Police (IACP) training keys on Suicide (Homicide) Bombers: “No recorded use of cavity bombs (i.e., in the stomach, rectum, or vagina) exists, but this tactic represents a potential threat.” The author recognized early on the iterated offensive and defensive dynamic of suicide bomber and security force countermeasures and saw the offensive potentials inherent in an explosive device carried by a suicide bomber secreted inside of the human body. This resulted in a non-public disclosure series of presentations on projected BCB employment that took place between September 2006 and August 2008 in the United States and later in the United Kingdom. These presentations were resumed between October 2009 and February 2010 as a by-product of the first recorded use of a BCB device by Al-Qaeda on the Arabian Peninsula in August 2009. This was the attack, on 28 August, where a suicide bomber blew himself up in Jeddah during a Ramadan gathering that included Prince Mohammed bin Nayef, head of the security services. It was the first attempt on the life of a royal since the murder of King Faisal in 1975. The prince was treated at a hospital and released. This incident was the subject of two specific studies:\n\nThe 27 August 2009 suicide bomber attack on the Assistant Interior Minister of Saudi Arabia, Prince Muhammad bin Nayef, used a BCB type-weapon. This was an IED inserted into the bomber’s rectum. Activated, once the bomber was close to the Prince Muhammad, the prince was nevertheless only ‘lightly-injured’ in this attack. The aftermath of the Nayef attack seems to confirm that the blast event is largely contained by the attacker’s own body (who was later identified as al-Asiri).\nEuropol have assessed the possible use of the BCB, and made the following findings:\nEuropol found as well—\"should there be conclusive proof that the attack took place with an IED concealed inside the perpetrator’s body\", it would definitely have an impact in aviation safety and the current standard operational procedures in place should be reviewed.\n\nThe BCB is an explosive device inserted within a human being or an animal, with the view to hiding it from detection. It involves \"new tactics, techniques or procedures (TTPs).\" Concerning the BCB tactical evolution:\n\"Suicide bombings (human- and vehicle-borne) have been a staple of terrorist strategy and tactics. They provide a means of low-cost precision targeting that amplifies casualties and ensures the attacks are noticed. As countermeasures (weapons screening, searches, etc.) become more effective, a shift in targeting and/or TTPs is a likely terrorist adaptation.\"\n\nTactically speaking, the use and employment of the BCB falls into a category of tactics known as ‘in-situ’ attacks. The factors which could thwart the effective use of the BCB, are:\nThe other constraint is that this weapon likely decreases in effect if used outdoors, as indoors closed environments offer the best physical possible properties, where blast-reflection is a factor in confinement. Thus, as can be seen, the very factors that make the BCB effective are also highly limiting.\n\nThe 2012–2013 post-analysis research has enunciated tactical propositions that limit the effect of the BCB, and its \"tactical use of the BCB is limited to a specific set of circumstances\".\nThe likely employment of the BCB will be in circumstances where the attacker will attempt a one-on-one attack, specifically on an individual or object (such as an airplane’s critical control system), in a ‘close-in’ attack, requiring physical contact with the victim/target. However, \"the BCB may also ultimately develop into a purely terror, or a ‘protest horror’ weapon; the impact of which has less to do with its overall effectiveness, and more to do with its grotesqueness—a weapon designed to invite horror and revulsion.\"\n\nA summary of body scanning techniques for airport security reveals that the BCB can evade most of the commonly used sensor strategies. For instance, the current operational methods are:\n\nIn the case of sensor strategies under development, such as the Radiometric Scanner, these are unable to penetrate skin and cannot detect a BCB. These could eventually detect a device used to ignite one, if interpreted correctly. Several other methods can also be considered and for example include:\n\nDogs may be able to detect explosives in rectal, vaginal, or oral cavities, but not implanted explosives. Dogs can also detect traces of explosives if the terrorist has been in contact with them before implantation. However, they are subject to exhaustion. Additionally, issues exist concerning canine training procedures, as most bomb dogs are trained to ‘alert’ on items and not on individuals for detecting explosive material residues.\n\nPhysical examinations can detect a BCB with a medium-high probability. In practical terms, this is time consuming for a primary scan. This method is more than likely to be challenged by privacy groups, in particular, the issue of violation of a potentially pregnant woman.\n\nIt has also been speculated that there appears to be a partial overlap between mm wave radar and terahertz radar. Some of the public source information suggests that there are some possibilities for terahertz radar, which lies between mm wave radar and long infra-red in the electromagnetic spectrum. Namely, there is at least some penetration with terahertz radar as it is used for thickness and density measurement and biomedical scanning, and is suggested for detecting weapons under clothing. It can detect specific chemicals, including explosives, in vapour phase by the adsorption spectra. This should be able to detect explosives vapours inside a sealed package, provided there is some air void in the package when sealed. Some prototypes for area security scanning have been tested in the field, but the results as not publicly known. The capabilities appear to be better than given for mm wave radar. Ideally, a fully developed terahertz radar system might have the sensitivity of ultrasonic scanning, positive identification of explosives chemicals, and non-contact scanning as well as reducing the inconvenience to travellers. However, such a development may be far in the future.\n\nThe BCB primarily involves a device inserted into a body opening. As well, the idea of creating a surgically implanted IED (improvised explosive device), placed within a body, with the explosives detonated by injecting a chemical trigger, has been frequently discussed in news reporting, including media claims, that such a medical procedure to place a BCB inside a person or an animal, has been perfected. However, this possibility has been extensively reviewed in research literature on terrorism TTPs, which has concluded, that while this may give a much higher blast yield capability; such a procedure nevertheless:\n\nThe BCB has a long history in science fiction writing and film history. Notwithstanding, in conventional security thinking, it has been noted, that: \"placing bombs inside live human beings was still definitely not on the radar\", prior to 2009.\nThe concept of the BCB has been regularly used as a theatrical–plot device in many popular TV shows and movies since at least the late 1960s (and perhaps earlier), and a number of popular U.S. films and television series episodes have featured the BCB, \"ironically illustrating many of the key tactical concepts herein—that is, it is hidden in the human body, camouflaged from intelligence sensors, and used for attacks on specific targets\". For example:\n\n"}
{"id": "29838", "url": "https://en.wikipedia.org/wiki?curid=29838", "title": "The Simpsons", "text": "The Simpsons\n\nThe Simpsons is an American animated sitcom created by Matt Groening for the Fox Broadcasting Company. The series is a satirical depiction of working-class life, epitomized by the Simpson family, which consists of Homer, Marge, Bart, Lisa, and Maggie. The show is set in the fictional town of Springfield and parodies American culture and society, television, and the human condition.\n\nThe family was conceived by Groening shortly before a solicitation for a series of animated shorts with producer James L. Brooks. Groening created a dysfunctional family and named the characters after his own family members, substituting Bart for his own name. The shorts became a part of \"The Tracey Ullman Show\" on April 19, 1987. After three seasons, the sketch was developed into a half-hour prime time show and became Fox's first series to land in the Top 30 ratings in a season (1989–90).\n\nSince its debut on December 17, 1989, episodes of \"The Simpsons\" have been broadcast. It is the longest-running American sitcom, and the longest-running American scripted primetime television series in terms of seasons and number of episodes. \"The Simpsons Movie\", a feature-length film, was released in theaters worldwide on July 27, 2007, and grossed over $527 million. Then on October 30, 2007, a video game was released. Currently, \"The Simpsons\" is on its thirtieth season, which aired September 30, 2018. \"The Simpsons\" will be renewed for a thirty-first season, with Al Jean completing a Treehouse of Horror XXIX script, though the date has yet to be announced.\n\n\"The Simpsons\" received acclaim throughout its first nine or ten seasons, which are generally considered its \"Golden Age\". \"Time\" named it the 20th century's best television series, and Erik Adams of \"The A.V. Club\" named it \"television's crowning achievement regardless of format\". On January 14, 2000, the Simpson family was awarded a star on the Hollywood Walk of Fame. It has won dozens of awards since it debuted as a series, including 31 Primetime Emmy Awards, 30 Annie Awards, and a Peabody Award. Homer's exclamatory catchphrase \"D'oh!\" has been adopted into the English language, while \"The Simpsons\" has influenced many other later adult-oriented animated sitcoms. However, it has also been criticized for a perceived decline in quality over the years.\n\n\"The Simpsons\" is known for its wide ensemble of main and supporting characters. \n\nThe main characters are the Simpson family, who live in a fictional \"Middle America\" town of Springfield. Homer, the father, works as a safety inspector at the Springfield Nuclear Power Plant, a position at odds with his careless, buffoonish personality. He is married to Marge Bouvier, a stereotypical American housewife and mother. They have three children: Bart, a ten-year-old troublemaker and prankster; Lisa, a precocious eight-year-old activist; and Maggie, the baby of the family who rarely speaks, but communicates by sucking on a pacifier. Although the family is dysfunctional, many episodes examine their relationships and bonds with each other and they are often shown to care about one another. Homer's dad Grampa Simpson lives in the Springfield Retirement Home after Homer forced his dad to sell his house so that his family could buy theirs. Grampa Simpson has had starring roles in several episodes.\n\nThe family also owns a dog, Santa's Little Helper, and a cat, Snowball V, renamed Snowball II in \"I, (Annoyed Grunt)-Bot\". Both pets have had starring roles in several episodes.\nThe show includes an array of quirky supporting characters, which include Homer's co-workers (also friends) Lenny Leonard and Carl Carlson, the school principal Seymour Skinner and teachers Edna Krabappel and Elizabeth Hoover, friends Barney Gumble, Apu Nahasapeemapetilon, Moe Szyslak, Milhouse Van Houten, and Nelson Muntz, extended relatives Patty and Selma Bouvier, townspeople such as Mayor Quimby, Chief Clancy Wiggum, tycoon Charles Montgomery Burns and his executive assistant Waylon Smithers, and local celebrities Krusty the Clown and news reporter Kent Brockman.\n\nThe creators originally intended many of these characters as one-time jokes or for fulfilling needed functions in the town. A number of them have gained expanded roles and subsequently starred in their own episodes. According to Matt Groening, the show adopted the concept of a large supporting cast from the comedy show \"SCTV\".\n\nDespite the depiction of yearly milestones such as holidays or birthdays passing, the characters do not age between episodes (either physically or in stated age), and generally appear just as they did when the series began. The series uses a floating timeline in which episodes generally take place in the year the episode is produced even though the characters do not age. Flashbacks and flashforwards do occasionally depict the characters at other points in their lives, with the timeline of these depictions also generally floating relative to the year the episode is produced. For example, in the 1991 episode \"I Married Marge\", Bart (who is always 10 years old) appears to be born in 1980 or 1981. But in the 1995 episode \"And Maggie Makes Three\", Maggie (who always appears to be around 1 year old) appears to be born in 1993 or 1994.\n\nA canon of the show does exist, as \"Treehouse of Horror\" episodes and any fictional story told within the series are typically non-canon. However, continuity is inconsistent and limited in \"The Simpsons\", as with most other comedy-focused television shows. For example, Krusty the Clown may be able to read in one episode, but may not be able to read in another. Lessons learned by the family in one episode may be forgotten in the next. Some examples of limited continuity include Sideshow Bob's appearances where Bart and Lisa flashback at all the crimes he committed in Springfield or when the characters try to remember things that happened in previous episodes.\n\n\"The Simpsons\" takes place in the fictional American town of Springfield in an unknown and impossible-to-determine U.S. state. The show is intentionally evasive in regard to Springfield's location. Springfield's geography, and that of its surroundings, contains coastlines, deserts, vast farmland, tall mountains, or whatever the story or joke requires. Groening has said that Springfield has much in common with Portland, Oregon, the city where he grew up. The name \"Springfield\" is a common one in America and appears in 22 states. Groening has said that he named it after Springfield, Oregon, and the fictitious Springfield which was the setting of the series \"Father Knows Best\". He \"figured out that Springfield was one of the most common names for a city in the U.S. In anticipation of the success of the show, I thought, 'This will be cool; everyone will think it's their Springfield.' And they do.\" \n\nWhen producer James L. Brooks was working on the television variety show \"The Tracey Ullman Show\", he decided to include small animated sketches before and after the commercial breaks. Having seen one of cartoonist Matt Groening's \"Life in Hell\" comic strips, Brooks asked Groening to pitch an idea for a series of animated shorts. Groening initially intended to present an animated version of his \"Life in Hell\" series. However, Groening later realized that animating \"Life in Hell\" would require the rescinding of publication rights for his life's work. He therefore chose another approach while waiting in the lobby of Brooks's office for the pitch meeting, hurriedly formulating his version of a dysfunctional family that became the Simpsons. He named the characters after his own family members, substituting \"Bart\" for his own name, adopting an anagram of the word \"brat\".\n\nThe Simpson family first appeared as shorts in \"The Tracey Ullman Show\" on April 19, 1987. Groening submitted only basic sketches to the animators and assumed that the figures would be cleaned up in production. However, the animators merely re-traced his drawings, which led to the crude appearance of the characters in the initial shorts. The animation was produced domestically at Klasky Csupo, with Wes Archer, David Silverman, and Bill Kopp being animators for the first season. Colorist Gyorgyi Peluce was the person who decided to make the characters yellow.\n\nIn 1989, a team of production companies adapted \"The Simpsons\" into a half-hour series for the Fox Broadcasting Company. The team included the Klasky Csupo animation house. Brooks negotiated a provision in the contract with the Fox network that prevented Fox from interfering with the show's content. Groening said his goal in creating the show was to offer the audience an alternative to what he called \"the mainstream trash\" that they were watching. The half-hour series premiered on December 17, 1989, with \"Simpsons Roasting on an Open Fire\". \"Some Enchanted Evening\" was the first full-length episode produced, but it did not broadcast until May 1990, as the last episode of the first season, because of animation problems. In 1992, Tracey Ullman filed a lawsuit against Fox, claiming that her show was the source of the series' success. The suit said she should receive a share of the profits of \"The Simpsons\"—a claim rejected by the courts.\n\nMatt Groening and James L. Brooks have served as executive producers during the show's entire history, and also function as creative consultants. Sam Simon, described by former \"Simpsons\" director Brad Bird as \"the unsung hero\" of the show, served as creative supervisor for the first four seasons. He was constantly at odds with Groening, Brooks and the show's production company Gracie Films and left in 1993. Before leaving, he negotiated a deal that sees him receive a share of the profits every year, and an executive producer credit despite not having worked on the show since 1993, at least until his passing in 2015. A more involved position on the show is the showrunner, who acts as head writer and manages the show's production for an entire season.\n\nThe first team of writers, assembled by Sam Simon, consisted of John Swartzwelder, Jon Vitti, George Meyer, Jeff Martin, Al Jean, Mike Reiss, Jay Kogen and Wallace Wolodarsky. Newer \"Simpsons\" writing teams typically consist of sixteen writers who propose episode ideas at the beginning of each December. The main writer of each episode writes the first draft. Group rewriting sessions develop final scripts by adding or removing jokes, inserting scenes, and calling for re-readings of lines by the show's vocal performers. Until 2004, George Meyer, who had developed the show since the first season, was active in these sessions. According to long-time writer Jon Vitti, Meyer usually invented the best lines in a given episode, even though other writers may receive script credits. Each episode takes six months to produce so the show rarely comments on current events.\n\nCredited with sixty episodes, John Swartzwelder is the most prolific writer on \"The Simpsons\". One of the best-known former writers is Conan O'Brien, who contributed to several episodes in the early 1990s before replacing David Letterman as host of the talk show \"Late Night\". English comedian Ricky Gervais wrote the episode \"Homer Simpson, This Is Your Wife\", becoming the first celebrity to both write and guest star in an episode. Seth Rogen and Evan Goldberg, writers of the film \"Superbad\", wrote the episode \"Homer the Whopper\", with Rogen voicing a character in it.\n\nAt the end of 2007, the writers of \"The Simpsons\" went on strike together with the other members of the Writers Guild of America, East. The show's writers had joined the guild in 1998.\n\n\"The Simpsons\" has six main cast members: Dan Castellaneta, Julie Kavner, Nancy Cartwright, Yeardley Smith, Hank Azaria and Harry Shearer. Castellaneta voices Homer Simpson, Grampa Simpson, Krusty the Clown, Groundskeeper Willie, Mayor Quimby, Barney Gumble and other adult, male characters. Julie Kavner voices Marge Simpson and Patty and Selma, as well as several minor characters. Castellaneta and Kavner had been a part of \"The Tracey Ullman Show\" cast and were given the parts so that new actors would not be needed. Cartwright voices Bart Simpson, Nelson Muntz, Ralph Wiggum and other children. Smith, the voice of Lisa Simpson, is the only cast member who regularly voices only one character, although she occasionally plays other episodic characters. The producers decided to hold casting for the roles of Bart and Lisa. Smith had initially been asked to audition for the role of Bart, but casting director Bonita Pietila believed her voice was too high, so she was given the role of Lisa instead. Cartwright was originally brought in to voice Lisa, but upon arriving at the audition, she found that Lisa was simply described as the \"middle child\" and at the time did not have much personality. Cartwright became more interested in the role of Bart, who was described as \"devious, underachieving, school-hating, irreverent, [and] clever\". Groening let her try out for the part instead, and upon hearing her read, gave her the job on the spot. Cartwright is the only one of the six main \"Simpsons\" cast members who had been professionally trained in voice acting prior to working on the show. Azaria and Shearer do not voice members of the title family, but play a majority of the male townspeople. Azaria, who has been a part of the \"Simpsons\" regular voice cast since the second season, voices recurring characters such as Moe Szyslak, Chief Wiggum, Apu Nahasapeemapetilon and Professor Frink. Shearer provides voices for Mr. Burns, Mr. Smithers, Principal Skinner, Ned Flanders, Reverend Lovejoy and Dr. Hibbert. Every main cast member has won a Primetime Emmy Award for Outstanding Voice-Over Performance.\n\nWith one exception, episode credits list only the voice actors, and not the characters they voice. Both Fox and the production crew wanted to keep their identities secret during the early seasons and, therefore, closed most of the recording sessions while refusing to publish photos of the recording artists. However, the network eventually revealed which roles each actor performed in the episode \"Old Money\", because the producers said the voice actors should receive credit for their work. In 2003, the cast appeared in an episode of \"Inside the Actors Studio\", doing live performances of their characters' voices.\n\nThe six main actors were paid $30,000 per episode until 1998, when they were involved in a pay dispute with Fox. The company threatened to replace them with new actors, even going as far as preparing for casting of new voices, but series creator Groening supported the actors in their action. The issue was soon resolved and, from 1998 to 2004, they were paid $125,000 per episode. The show's revenue continued to rise through syndication and DVD sales, and in April 2004 the main cast stopped appearing for script readings, demanding they be paid $360,000 per episode. The strike was resolved a month later and their salaries were increased to something between $250,000 and $360,000 per episode. In 2008, production for the twentieth season was put on hold due to new contract negotiations with the voice actors, who wanted a \"healthy bump\" in salary to an amount close to $500,000 per episode. The negotiations were soon completed, and the actors' salary was raised to $400,000 per episode. Three years later, with Fox threatening to cancel the series unless production costs were cut, the cast members accepted a 30 percent pay cut, down to just over $300,000 per episode.\n\nIn addition to the main cast, Pamela Hayden, Tress MacNeille, Marcia Wallace, Maggie Roswell, and Russi Taylor voice supporting characters. From 1999 to 2002, Roswell's characters were voiced by Marcia Mitzman Gaven. Karl Wiedergott has also appeared in minor roles, but does not voice any recurring characters. Wiedergott left the show in 2010, and since then Chris Edgerly has appeared regularly to voice minor characters. Repeat \"special guest\" cast members include Albert Brooks, Phil Hartman, Jon Lovitz, Joe Mantegna, Maurice LaMarche, and Kelsey Grammer. Following Hartman's death in 1998, the characters he voiced (Troy McClure and Lionel Hutz) were retired; Wallace's character of Edna Krabappel was retired as well after her death in 2013.\n\nEpisodes will quite often feature guest voices from a wide range of professions, including actors, athletes, authors, bands, musicians and scientists. In the earlier seasons, most of the guest stars voiced characters, but eventually more started appearing as themselves. Tony Bennett was the first guest star to appear as himself, appearing briefly in the season two episode \"Dancin' Homer\". \"The Simpsons\" holds the world record for \"Most Guest Stars Featured in a Television Series\".\n\n\"The Simpsons\" has been dubbed into several other languages, including Japanese, German, Spanish, and Portuguese. It is also one of the few programs dubbed in both standard French and Quebec French. The show has been broadcast in Arabic, but due to Islamic customs, numerous aspects of the show have been changed. For example, Homer drinks soda instead of beer and eats Egyptian beef sausages instead of hot dogs. Because of such changes, the Arabized version of the series met with a negative reaction from the lifelong \"Simpsons\" fans in the area.\n\nSeveral different U.S. and international studios animate \"The Simpsons\". Throughout the run of the animated shorts on \"The Tracey Ullman Show,\" the animation was produced domestically at Klasky Csupo. With the debut of the series, because of an increased workload, Fox subcontracted production to several local and foreign studios. These are AKOM, Anivision, Rough Draft Studios, USAnimation, and Toonzone Entertainment.\n\nFor the first three seasons, Klasky Csupo animated \"The Simpsons\" in the United States. In 1992, the show's production company, Gracie Films, switched domestic production to Film Roman, who continued to animate the show until 2016. In Season 14, production switched from traditional cel animation to digital ink and paint. The first episode to experiment with digital coloring was \"Radioactive Man\" in 1995. Animators used digital ink and paint during production of the season 12 episode \"Tennis the Menace\", but Gracie Films delayed the regular use of digital ink and paint until two seasons later. The already completed \"Tennis the Menace\" was broadcast as made.\n\nThe production staff at the U.S. animation studio, Film Roman, draws storyboards, designs new characters, backgrounds, props and draws character and background layouts, which in turn become animatics to be screened for the writers at Gracie Films for any changes to be made before the work is shipped overseas. The overseas studios then draw the inbetweens, ink and paint, and render the animation to tape before it is shipped back to the United States to be delivered to Fox three to four months later.\n\nThe series began high-definition production in Season 20; the first episode, \"Take My Life, Please\", aired February 15, 2009. The move to HDTV included a new opening sequence. Matt Groening called it a complicated change because it affected the timing and composition of animation.\n\n\"The Simpsons\" uses the standard setup of a situational comedy, or sitcom, as its premise. The series centers on a family and their life in a typical American town, serving as a satirical parody of a middle class American lifestyle. However, because of its animated nature, \"The Simpsons\" scope is larger than that of a regular sitcom. The town of Springfield acts as a complete universe in which characters can explore the issues faced by modern society. By having Homer work in a nuclear power plant, the show can comment on the state of the environment. Through Bart and Lisa's days at Springfield Elementary School, the show's writers illustrate pressing or controversial issues in the field of education. The town features a vast array of media channels—from kids' television programming to local news, which enables the producers to make jokes about themselves and the entertainment industry.\n\nSome commentators say the show is political in nature and susceptible to a left-wing bias. Al Jean acknowledged in an interview that \"We [the show] are of liberal bent.\" The writers often evince an appreciation for liberal ideals, but the show makes jokes across the political spectrum. The show portrays government and large corporations as callous entities that take advantage of the common worker. Thus, the writers often portray authority figures in an unflattering or negative light. In \"The Simpsons\", politicians are corrupt, ministers such as Reverend Lovejoy are indifferent to churchgoers, and the local police force is incompetent. Religion also figures as a recurring theme. In times of crisis, the family often turns to God, and the show has dealt with most of the major religions.\n\n\"The Simpsons\" opening sequence is one of the show's most memorable hallmarks. The standard opening has gone through three iterations (a replacement of some shots at the start of the second season, and a brand new sequence when the show switched to high-definition in 2009). \n\nEach has the same basic sequence of events: the camera zooms through cumulus clouds, through the show's title towards the town of Springfield. The camera then follows the members of the family on their way home. Upon entering their house, the Simpsons settle down on their couch to watch television. The original opening was created by David Silverman, and was the first task he did when production began on the show. The series' distinctive theme song was composed by musician Danny Elfman in 1989, after Groening approached him requesting a retro style piece. This piece has been noted by Elfman as the most popular of his career.\n\nOne of the most distinctive aspects of the opening is that three of its elements change from episode to episode: Bart writes different things on the school chalkboard, Lisa plays different solos on her saxophone and different gags accompany the family as they enter their living room to sit on the couch.\n\nThe special Halloween episode has become an annual tradition. \"Treehouse of Horror\" first broadcast in 1990 as part of season two and established the pattern of three separate, self-contained stories in each Halloween episode. These pieces usually involve the family in some horror, science fiction, or supernatural setting and often parody or pay homage to a famous piece of work in those genres. They always take place outside the normal continuity of the show. Although the \"Treehouse\" series is meant to be seen on Halloween, this changed by the 2000s, when new installments have premiered after Halloween due to Fox's current contract with Major League Baseball's World Series, however, since 2011, every \"Treehouse of Horror\" episode has aired in October.\n\nThe show's humor turns on cultural references that cover a wide spectrum of society so that viewers from all generations can enjoy the show. Such references, for example, come from movies, television, music, literature, science, and history. The animators also regularly add jokes or sight gags into the show's background via humorous or incongruous bits of text in signs, newspapers, billboards, and elsewhere. The audience may often not notice the visual jokes in a single viewing. Some are so fleeting that they become apparent only by pausing a video recording of the show. Kristin Thompson argues that \"The Simpsons\" uses a \"flurry of cultural references, intentionally inconsistent characterization, and considerable self-reflexivity about television conventions and the status of the programme as a television show.\"\n\nOne of Bart's early hallmarks was his prank calls to Moe's Tavern owner Moe Szyslak in which Bart calls Moe and asks for a gag name. Moe tries to find that person in the bar, but soon realizes it is a prank call and angrily threatens Bart. These calls were apparently based on a series of prank calls known as the Tube Bar recordings, though Groening has denied any causal connection.\nMoe was based partly on Tube Bar owner Louis \"Red\" Deutsch, whose often profane responses inspired Moe's violent side. As the series progressed, it became more difficult for the writers to come up with a fake name and to write Moe's angry response, and the pranks were dropped as a regular joke during the fourth season. \"The Simpsons\" also often includes self-referential humor. The most common form is jokes about Fox Broadcasting. For example, the episode \"She Used to Be My Girl\" included a scene in which a Fox News Channel van drove down the street while displaying a large \"Bush Cheney 2004\" banner and playing Queen's \"We Are the Champions\", in reference to the 2004 U.S. presidential election and claims of conservative bias in Fox News.\n\nThe show uses catchphrases, and most of the primary and secondary characters have at least one each. Notable expressions include Homer's annoyed grunt \"D'oh!\", Mr. Burns' \"Excellent\" and Nelson Muntz's \"\"Ha\"-ha!\" Some of Bart's catchphrases, such as \"¡Ay, caramba!\", \"Don't have a cow, man!\" and \"Eat my shorts!\" appeared on T-shirts in the show's early days. However, Bart rarely used the latter two phrases until after they became popular through the merchandising. The use of many of these catchphrases has declined in recent seasons. The episode \"Bart Gets Famous\" mocks catchphrase-based humor, as Bart achieves fame on the \"Krusty the Clown Show\" solely for saying \"I didn't do it.\"\n\n\"The Simpsons\" has gained notoriety for including jokes that would eventually become reality. Perhaps the most famous example comes from the episode \"Bart to the Future\", which mentions billionaire Donald Trump having been President of the United States at one time and leaving the nation broke. The episode first aired in 2000, sixteen years before Trump would successfully run for the position. Another episode, \"When You Dish Upon a Star\", lampooned 20th Century Fox as a division of The Walt Disney Company. Nineteen years later, Disney indeed made a deal to purchase the studio from Rupert Murdoch. Other examples of \"The Simpsons\" predicting the future with accuracy include the introduction of the Smartwatch and autocorrection technology, and even Lady Gaga's acrobatic performance at the Super Bowl LI halftime show.\n\nA number of neologisms that originated on \"The Simpsons\" have entered popular vernacular. Mark Liberman, director of the Linguistic Data Consortium, remarked, \"\"The Simpsons\" has apparently taken over from Shakespeare and the Bible as our culture's greatest source of idioms, catchphrases and sundry other textual allusions.\" The most famous catchphrase is Homer's annoyed grunt: \"D'oh!\" So ubiquitous is the expression that it is now listed in the \"Oxford English Dictionary\", but without the apostrophe. Dan Castellaneta says he borrowed the phrase from James Finlayson, an actor in many Laurel and Hardy comedies, who pronounced it in a more elongated and whining tone. The staff of \"The Simpsons\" told Castellaneta to shorten the noise, and it went on to become the well-known exclamation in the television series.\n\nGroundskeeper Willie's description of the French as \"cheese-eating surrender monkeys\" was used by \"National Review\" columnist Jonah Goldberg in 2003, after France's opposition to the proposed invasion of Iraq. The phrase quickly spread to other journalists. \"\" and \"embiggen\", words used in \"Lisa the Iconoclast\", have since appeared in the Dictionary.com's 21st Century Lexicon, and scientific journals respectively. \"Kwyjibo\", a fake Scrabble word invented by Bart in \"Bart the Genius\", was used as one of the aliases of the creator of the Melissa worm. \"I, for one, welcome our new insect overlords\", was used by Kent Brockman in \"Deep Space Homer\" and has become a common phrase. Variants of Brockman's utterance are used to express obsequious submission. It has been used in media, such as \"New Scientist\" magazine. The dismissive term \"Meh\", believed to have been popularized by the show, entered the Collins English Dictionary in 2008. Other words credited as stemming from the show include \"yoink\" and \"craptacular\".\n\n\"The Oxford Dictionary of Modern Quotations\" includes several quotations from the show. As well as \"cheese-eating surrender monkeys\", Homer's lines, \"Kids, you tried your best and you failed miserably. The lesson is never try\", from \"Burns' Heir\" (season five, 1994) as well as \"Kids are the best, Apu. You can teach them to hate the things you hate. And they practically raise themselves, what with the Internet and all\", from \"Eight Misbehavin'\" (season 11, 1999), entered the dictionary in August 2007.\n\"The Simpsons\" was the first successful animated program in American prime time since \"Wait Till Your Father Gets Home\" in the 1970s. During most of the 1980s, US pundits considered animated shows as appropriate only for children, and animating a show was too expensive to achieve a quality suitable for prime-time television. \"The Simpsons\" changed this perception, initially leading to a short period where networks attempted to recreate prime-time cartoon success with shows like \"Capitol Critters\", \"Fish Police\", and \"Family Dog\", which were expensive and unsuccessful. \"The Simpsons\" use of Korean animation studios for tweening, coloring, and filming made the episodes cheaper. The success of \"The Simpsons\" and the lower production cost prompted US television networks to take chances on other adult animated series. This development led US producers to a 1990s boom in new, animated prime-time shows for adults, such as \"South Park\", \"Family Guy\", \"King of the Hill\", \"Futurama\" and \"The Critic\". For \"Family Guy\" creator Seth MacFarlane, \"\"The Simpsons\" created an audience for prime-time animation that had not been there for many, many years ... As far as I'm concerned, they basically re-invented the wheel. They created what is in many ways—you could classify it as—a wholly new medium.\"\n\n\"The Simpsons\" has had crossovers with four other shows. In the episode \"A Star Is Burns\", Marge invites Jay Sherman, the main character of \"The Critic\", to be a judge for a film festival in Springfield. Matt Groening had his name removed from the episode since he had no involvement with \"The Critic\". \"South Park\" later paid homage to \"The Simpsons\" with the episode \"Simpsons Already Did It\". In \"Simpsorama\", the Planet Express crew from \"Futurama\" come to Springfield in the present to prevent the Simpsons from destroying the future. In the \"Family Guy\" episode \"The Simpsons Guy\", the Griffins visit Springfield and meet the Simpsons.\n\n\"The Simpsons\" has also influenced live-action shows like \"Malcolm in the Middle\", which featured the use of sight gags and did not use a laugh track unlike most sitcoms. \"Malcolm in the Middle\" debuted January 9, 2000, in the time slot after \"The Simpsons\". Ricky Gervais called \"The Simpsons\" an influence on \"The Office\", and fellow British sitcom \"Spaced\" was, according to its director Edgar Wright, \"an attempt to do a live-action \"The Simpsons\".\" In Georgia, the animated television sitcom \"The Samsonadzes\", launched in November 2009, has been noted for its very strong resemblance with \"The Simpsons\", which its creator Shalva Ramishvili has acknowledged.\n\n\"The Simpsons\" was the Fox network's first television series to rank among a season's top 30 highest-rated shows. In 1990, Bart quickly became one of the most popular characters on television in what was termed \"Bartmania\". He became the most prevalent \"Simpsons\" character on memorabilia, such as T-shirts. In the early 1990s, millions of T-shirts featuring Bart were sold; as many as one million were sold on some days. Believing Bart to be a bad role model, several American public schools banned T-shirts featuring Bart next to captions such as \"I'm Bart Simpson. Who the hell are you?\" and \"Underachiever ('And proud of it, man!')\". \"The Simpsons\" merchandise sold well and generated $2 billion in revenue during the first 14 months of sales. Because of his popularity, Bart was often the most promoted member of the Simpson family in advertisements for the show, even for episodes in which he was not involved in the main plot.\n\nDue to the show's success, over the summer of 1990 the Fox Network decided to switch \"The Simpsons\" time slot so that it would move from 8:00 p.m. ET on Sunday night to the same time on Thursday, where it would compete with \"The Cosby Show\" on NBC, the number one show at the time. Through the summer, several news outlets published stories about the supposed \"Bill vs. Bart\" rivalry. \"Bart Gets an F\" (season two, 1990) was the first episode to air against \"The Cosby Show\", and it received a lower Nielsen ratings, tying for eighth behind \"The Cosby Show\", which had an 18.5 rating. The rating is based on the number of household televisions that were tuned into the show, but Nielsen Media Research estimated that 33.6 million viewers watched the episode, making it the number one show in terms of actual viewers that week. At the time, it was the most watched episode in the history of the Fox Network, and it is still the highest rated episode in the history of \"The Simpsons\". The show moved back to its Sunday slot in 1994 and has remained there ever since.\n\n\"The Simpsons\" has received overwhelmingly positive reviews from critics, and it has been noted for being described as \"the most irreverent and unapologetic show on the air.\" In a 1990 review of the show, Ken Tucker of \"Entertainment Weekly\" described it as \"the American family at its most complicated, drawn as simple cartoons. It's this neat paradox that makes millions of people turn away from the three big networks on Sunday nights to concentrate on The Simpsons.\" Tucker would also describe the show as a \"pop-cultural phenomenon, a prime-time cartoon show that appeals to the entire family.\"\n\nOn February 9, 1997, \"The Simpsons\" surpassed \"The Flintstones\" with the episode \"The Itchy & Scratchy & Poochie Show\" as the longest-running prime-time animated series in the United States. In 2004, \"The Simpsons\" replaced \"The Adventures of Ozzie and Harriet\" (1952 to 1966) as the longest-running sitcom (animated or live action) in the United States. In 2009, \"The Simpsons\" surpassed \"The Adventures of Ozzie and Harriet\"s record of 435 episodes and is now recognized by \"Guinness World Records\" as the world's longest running sitcom (in terms of episode count). In October 2004, \"Scooby-Doo\" briefly overtook \"The Simpsons\" as the American animated show with the highest number of episodes (albeit under several different iterations). However, network executives in April 2005 again cancelled \"Scooby-Doo\", which finished with 371 episodes, and \"The Simpsons\" reclaimed the title with 378 episodes at the end of their seventeenth season. In May 2007, \"The Simpsons\" reached their 400th episode at the end of the eighteenth season. While \"The Simpsons\" has the record for the number of episodes by an American animated show, other animated series have surpassed \"The Simpsons\". For example, the Japanese anime series \"Sazae-san\" has over 7,000 episodes to its credit.\n\nIn 2009, Fox began a year-long celebration of the show titled \"Best. 20 Years. Ever.\" to celebrate the 20th anniversary of the premiere of \"The Simpsons\". One of the first parts of the celebration is the \"Unleash Your Yellow\" contest in which entrants must design a poster for the show. The celebration ended on January 10, 2010 (almost 20 years after \"Bart the Genius\" aired on January 14, 1990), with \"The Simpsons 20th Anniversary Special – In 3-D! On Ice!\", a documentary special by documentary filmmaker Morgan Spurlock that examines the \"cultural phenomenon of \"The Simpsons\"\".\n\nAs of the twenty-first season (2009–2010), \"The Simpsons\" became the longest-running American scripted primetime television series, having surpassed \"Gunsmoke\". On April 29, 2018, \"The Simpsons\" also surpassed \"Gunsmoke\"s 635-episode count with the episode \"Forgive and Regret.\"\n\n\"The Simpsons\" has won dozens of awards since it debuted as a series, including 31 Primetime Emmy Awards, 30 Annie Awards and a Peabody Award. In a 1999 issue celebrating the 20th century's greatest achievements in arts and entertainment, \"Time\" magazine named \"The Simpsons\" the century's best television series. In that same issue, \"Time\" included Bart Simpson in the \"\", the publication's list of the century's 100 most influential people. Bart was the only fictional character on the list. On January 14, 2000, the Simpsons were awarded a star on the Hollywood Walk of Fame. Also in 2000, \"Entertainment Weekly\" magazine TV critic Ken Tucker named \"The Simpsons\" the greatest television show of the 1990s. Furthermore, viewers of the UK television channel Channel 4 have voted \"The Simpsons\" at the top of two polls: 2001's 100 Greatest Kids' TV shows, and 2005's The 100 Greatest Cartoons, with Homer Simpson voted into first place in 2001's 100 Greatest TV Characters. Homer would also place ninth on \"Entertainment Weekly\" list of the \"50 Greatest TV icons\". In 2002, \"The Simpsons\" ranked #8 on \"TV Guide\"s 50 Greatest TV Shows of All Time, and in 2007 it was included in \"Time\" list of the \"100 Best TV Shows of All Time\". In 2008 the show was placed in first on \"Entertainment Weekly\" \"Top 100 Shows of the Past 25 Years\". \"Empire\" named it the greatest TV show of all time. In 2010, \"Entertainment Weekly\" named Homer \"the greatest character of the last 20 years\", while in 2013 the Writers Guild of America listed \"The Simpsons\" as the 11th \"best written\" series in television history. In 2013, TV Guide ranked \"The Simpsons\" as the greatest TV cartoon of all time and the tenth greatest show of all time. Television critics Alan Sepinwall and Matt Zoller Seitz ranked \"The Simpsons\" as the greatest American TV series of all time in their 2016 book \"\".\n\nBart's rebellious, bad boy nature, which underlies his misbehavior and rarely leads to any punishment, led some people to characterize him as a poor role model for children. In schools, educators claimed that Bart was a \"threat to learning\" because of his \"underachiever and proud of it\" attitude and negative attitude regarding his education. Others described him as \"egotistical, aggressive and mean-spirited\". In a 1991 interview, Bill Cosby described Bart as a bad role model for children, calling him \"angry, confused, frustrated\". In response, Matt Groening said, \"That sums up Bart, all right. Most people are in a struggle to be normal [and] he thinks normal is very boring, and does things that others just wished they dare do.\" On January 27, 1992, then-President George H. W. Bush said, \"We are going to keep on trying to strengthen the American family, to make American families a lot more like the Waltons and a lot less like the Simpsons.\" The writers rushed out a tongue-in-cheek reply in the form of a short segment which aired three days later before a rerun of \"Stark Raving Dad\" in which Bart replied, \"Hey, we're just like the Waltons. We're praying for an end to the Depression, too.\"\n\nVarious episodes of the show have generated controversy. The Simpsons visit Australia in \"Bart vs. Australia\" (season six, 1995) and Brazil in \"Blame It on Lisa\" (season 13, 2002) and both episodes generated controversy and negative reaction in the visited countries. In the latter case, Rio de Janeiro's tourist board—which claimed that the city was portrayed as having rampant street crime, kidnappings, slums, and monkey and rat infestations—went so far as to threaten Fox with legal action. Groening was a fierce and vocal critic of the episode \"A Star Is Burns\" (season six, 1995) which featured a crossover with \"The Critic\". He felt that it was just an advertisement for \"The Critic\", and that people would incorrectly associate the show with him. When he was unsuccessful in getting the episode pulled, he had his name removed from the credits and went public with his concerns, openly criticizing James L. Brooks and saying the episode \"violates the Simpsons' universe.\" In response, Brooks said, \"I am furious with Matt, ... he's allowed his opinion, but airing this publicly in the press is going too far. ... his behavior right now is rotten.\" \n\n\"The Principal and the Pauper\" (season nine, 1997) is one of the most controversial episodes of \"The Simpsons\". Many fans and critics reacted negatively to the revelation that Seymour Skinner, a recurring character since the first season, was an impostor. The episode has been criticized by Groening and by Harry Shearer, who provides the voice of Skinner. In a 2001 interview, Shearer recalled that after reading the script, he told the writers, \"That's so wrong. You're taking something that an audience has built eight years or nine years of investment in and just tossed it in the trash can for no good reason, for a story we've done before with other characters. It's so arbitrary and gratuitous, and it's disrespectful to the audience.\"\n\nThe show has reportedly been taken off the air in several countries. China banned it from prime-time television in August 2006, \"in an effort to protect China's struggling animation studios.\" In 2008, Venezuela barred the show from airing on morning television as it was deemed \"unsuitable for children\". The same year, several Russian Pentecostal churches demanded that \"The Simpsons\", \"South Park\" and some other Western cartoons be removed from broadcast schedules \"for propaganda of various vices\" and the broadcaster's license to be revoked. However, the court decision later dismissed this request.\n\nCritics' reviews of early \"Simpsons\" episodes praised the show for its sassy humor, wit, realism, and intelligence. However, in the late 1990s, around the airing of season 10, the tone and emphasis of the show began to change. Some critics started calling the show \"tired\". By 2000, some long-term fans had become disillusioned with the show, and pointed to its shift from character-driven plots to what they perceived as an overemphasis on zany antics. Jim Schembri of \"The Sydney Morning Herald\" attributed the decline in quality to an abandonment of character-driven storylines in favor of and overuse of celebrity cameo appearances and references to popular culture. Schembri wrote: \"The central tragedy of \"The Simpsons\" is that it has gone from commanding attention to merely being attention-seeking. It began by proving that cartoon characters don't have to be caricatures; they can be invested with real emotions. Now the show has in essence fermented into a limp parody of itself. Memorable story arcs have been sacrificed for the sake of celebrity walk-ons and punchline-hungry dialogue.\"\n\nIn 2010, the BBC noted \"the common consensus is that \"The Simpsons\" golden era ended after season nine\", and Todd Leopold of CNN, in an article looking at its perceived decline, stated \"for many fans ... the glory days are long past.\" Similarly, Tyler Wilson of \"Coeur d'Alene Press\" has referred to seasons one to nine as the show's \"golden age\", and Ian Nathan of \"Empire\" described the show's classic era as being \"say, the first ten seasons.\" Jon Heacock of LucidWorks stated that \"for the first ten years [seasons], the show was consistently at the top of its game\", with \"so many moments, quotations, and references – both epic and obscure – that helped turn the Simpson family into the cultural icons that they remain to this day.\"\n\nMike Scully, who was showrunner during seasons nine through twelve, has been the subject of criticism. Chris Suellentrop of \"Slate\" wrote that \"under Scully's tenure, \"The Simpsons\" became, well, a cartoon ... Episodes that once would have ended with Homer and Marge bicycling into the sunset now end with Homer blowing a tranquilizer dart into Marge's neck. The show's still funny, but it hasn't been touching in years.\" When asked in 2007 how the series' longevity is sustained, Scully joked: \"Lower your quality standards. Once you've done that you can go on forever.\"\n\nAl Jean, showrunner since season thirteen, has also been the subject of criticism, with some arguing that the show has continued to decline in quality under his tenure. Former writers have complained that under Jean, the show is \"on auto-pilot\", \"too sentimental\", and the episodes are \"just being cranked out.\" Some critics believe that the show has \"entered a steady decline under Jean and is no longer really funny.\" John Ortved, author of \"\", characterized the Jean era as \"toothless\", and criticized what he perceived as the show's increase in social and political commentary. Jean responded: \"Well, it's possible that we've declined. But honestly, I've been here the whole time and I do remember in season two people saying, 'It's gone downhill.' If we'd listened to that then we would have stopped after episode 13. I'm glad we didn't.\"\n\nIn 2004, Harry Shearer criticized what he perceived as the show's declining quality: \"I rate the last three seasons as among the worst, so season four looks very good to me now.\" Dan Castellaneta responded: \"I don't agree, ... I think Harry's issue is that the show isn't as grounded as it was in the first three or four seasons, that it's gotten crazy or a little more madcap. I think it organically changes to stay fresh.\" Also in 2004 author Douglas Coupland described claims of declining quality in the series as \"hogwash\", saying \"\"The Simpsons\" hasn't fumbled the ball in fourteen years, it's hardly likely to fumble it now.\" In an April 2006 interview, Groening said: \"I honestly don't see any end in sight. I think it's possible that the show will become too financially cumbersome ... but right now, the show is creatively, I think, as good or better than it's ever been. The animation is incredibly detailed and imaginative, and the stories do things that we haven't done before. So creatively there's no reason to quit.\"\n\nIn 2016, popular culture writer Anna Leszkiewicz suggested that even though \"The Simpsons\" still holds cultural relevance, contemporary appeal is only for the first ten seasons, with recent episodes only garnering mainstream attention when a favorite character from the golden era is killed off, or when new information and shock twists are given for old characters. The series' ratings have also declined; while the first season enjoyed an average of 13.4 million viewing households per episode in the U.S., the twenty-first season had an average of 7.2 million viewers.\n\nAlan Sepinwall and Matt Zoller Seitz argued in their 2016 book titled \"TV (The Book)\" that the peak of \"The Simpsons\" are \"roughly seasons [three through twelve]\", and that despite the decline, episodes from the later seasons such as \"Eternal Moonshine of the Simpson Mind\" and \"Holidays of Future Passed\" could be considered on par with the earlier classic episodes, further stating that \"even if you want to call the show today a thin shadow of its former self, think about how mind-boggingly great its former self had to be for so-diminished a version to be watchable at all.\"\n\nThe stereotypical nature of the character Apu Nahasapeemapetilon has long been the subject of controversy. This was particularly highlighted by Indian-American comedian Hari Kondabolu's 2017 documentary \"The Problem with Apu\". In the film, Kondabolu states that as a child he was a fan of The Simpsons and liked Apu, but he now finds the character's stereotypical nature troublesome. Defenders of the character responded that the show is built on comical stereotypes, with creator Matt Groening saying, \"that's the nature of cartooning.\" He added that he was \"proud of what we do on the show\", and \"it's a time in our culture where people love to pretend they're offended\". In response to the controversy, Apu's voice actor, Hank Azaria, said he was willing to step aside from his role as Apu: \"The most important thing is to listen to South Asian people, Indian people in this country when they talk about what they feel and how they think about this character.\"\n\nThe criticisms were referenced in the Season 29 episode \"No Good Read Goes Unpunished\", when Lisa breaks the fourth wall and addresses the audience by saying, \"Something that started decades ago and was applauded and inoffensive is now politically incorrect. What can you do?\" to which Marge replies, \"Some things will be addressed at a later date.\" Lisa adds, \"If at all.\" This reference was clarified by the fact that there was a framed photo of Apu with the caption on the photo saying \"Don't have a cow, Apu\", a play on Bart's catchphrase \"Don't have a cow, man,\" as well as the fact that Hindus do not eat cows as they are considered sacred. In October 2018, it was reported that Apu would be written out of the show.\n\nNumerous Simpson-related comic books have been released over the years. So far, nine comic book series have been published by Bongo Comics since 1993. The first comic strips based on \"The Simpsons\" appeared in 1991 in the magazine \"Simpsons Illustrated\", which was a companion magazine to the show. The comic strips were popular and a one-shot comic book titled \"Simpsons Comics and Stories\", containing four different stories, was released in 1993 for the fans. The book was a success and due to this, the creator of \"The Simpsons\", Matt Groening, and his companions Bill Morrison, Mike Rote, Steve Vance and Cindy Vance created the publishing company Bongo Comics. Issues of \"Simpsons Comics\", \"Bart Simpson's Treehouse of Horror\" and \"Bart Simpson\" have been collected and reprinted in trade paperbacks in the United States by HarperCollins.\n\n20th Century Fox, Gracie Films, and Film Roman produced \"The Simpsons Movie\", an animated film that was released on July 27, 2007. The film was directed by long-time \"Simpsons\" producer David Silverman and written by a team of \"Simpsons\" writers comprising Matt Groening, James L. Brooks, Al Jean, George Meyer, Mike Reiss, John Swartzwelder, Jon Vitti, David Mirkin, Mike Scully, Matt Selman, and Ian Maxtone-Graham. Production of the film occurred alongside continued writing of the series despite long-time claims by those involved in the show that a film would enter production only after the series had concluded. There had been talk of a possible feature-length \"Simpsons\" film ever since the early seasons of the series. James L. Brooks originally thought that the story of the episode \"Kamp Krusty\" was suitable for a film, but he encountered difficulties in trying to expand the script to feature-length. For a long time, difficulties such as lack of a suitable story and an already fully engaged crew of writers delayed the project.\n\nOn August 10, 2018, 20th Century Fox announced that a sequel is in development.\n\nCollections of original music featured in the series have been released on the albums \"Songs in the Key of Springfield\", \"Go Simpsonic with The Simpsons\" and \"\". Several songs have been recorded with the purpose of a single or album release and have not been featured on the show. The album \"The Simpsons Sing the Blues\" was released in September 1990 and was a success, peaking at #3 on the \"Billboard\" 200 and becoming certified 2× platinum by the Recording Industry Association of America. The first single from the album was the pop rap song \"Do the Bartman\", performed by Nancy Cartwright and released on November 20, 1990. The song was written by Michael Jackson, although he did not receive any credit. \"The Yellow Album\" was released in 1998, but received poor reception and did not chart in any country.\n\nIn 2007, it was officially announced that \"The Simpsons\" Ride, a simulator ride, would be implemented into the Universal Studios Orlando and Universal Studios Hollywood. It officially opened May 15, 2008 in Florida and May 19, 2008, in Hollywood. In the ride, patrons are introduced to a cartoon theme park called Krustyland built by Krusty the Clown. However, Sideshow Bob is loose from prison to get revenge on Krusty and the Simpson family. It features more than 24 regular characters from \"The Simpsons\" and features the voices of the regular cast members, as well as Pamela Hayden, Russi Taylor and Kelsey Grammer. Harry Shearer did not participate in the ride, so none of his characters have vocal parts.\n\nNumerous video games based on the show have been produced. Some of the early games include Konami's arcade game \"The Simpsons\" (1991) and Acclaim Entertainment's \"\" (1991). More modern games include \"\" (2001), \"\" (2003) and \"The Simpsons Game\" (2007). Electronic Arts, which produced \"The Simpsons Game\", has owned the exclusive rights to create video games based on the show since 2005. In 2010, they released a game called \"The Simpsons Arcade\" for iOS. Another EA-produced mobile game, \"\", was released in 2012 for iOS users, then in 2013 for Android and Kindle users. Two \"Simpsons\" pinball machines have been produced: one that was available briefly after the first season, and another in 2007, both out of production.\n\nThe cable television network FXX has exclusive cable and digital syndication rights for \"The Simpsons.\" Original contracts had previously stated that syndication rights for \"The Simpsons\" would not be sold to cable until the series conclusion, at a time when cable syndication deals were highly rare. The series has been syndicated to local broadcast stations in nearly all markets throughout the United States since September 1993.\n\nFXX premiered \"The Simpsons\" on their network on August 21, 2014 by starting a twelve-day marathon which featured the first 552 episodes (every single episode that had already been released at the time) aired chronologically, including \"The Simpsons Movie\", which FX Networks had already owned the rights to air. It was the longest continuous marathon in the history of television (until VH1 Classic aired a 433-hour, nineteen-day, marathon of \"Saturday Night Live\" in 2015; celebrating that program's 40th anniversary). The first day of the marathon was the highest rated broadcast day in the history of the network so far, the ratings more than tripled that those of regular prime time programming for FXX. Ratings during the first six nights of the marathon grew night after night, with the network ranking within the top 5 networks in basic cable each night.\n\nOn October 21, 2014, a digital service courtesy of the FXNOW app, called \"Simpsons World\", launched. \"Simpsons World\" has every episode of the series accessible to authenticated FX subscribers, and is available on game consoles such as Xbox One, streaming devices such as Roku and Apple TV, and online via web browser. There was early criticism of both wrong aspect ratios for earlier episodes and the length of commercial breaks on the streaming service, but there are now fewer commercial breaks during individual episodes. Later it was announced that \"Simpsons World\" would now let users watch all of the SD episodes in their original format.\n\nIn July 2017, all episodes were made available for purchase on the iTunes Store, in the United States.\n\nThe popularity of \"The Simpsons\" has made it a billion-dollar merchandising industry. The title family and supporting characters appear on everything from T-shirts to posters. \"The Simpsons\" has been used as a theme for special editions of well-known board games, including Clue, Scrabble, Monopoly, Operation, and The Game of Life, as well as the trivia games What Would Homer Do? and Simpsons \"Jeopardy!\". Several card games such as trump cards and The Simpsons Trading Card Game have also been released. Many official or unofficial \"Simpsons\" books such as episode guides have been published. Many episodes of the show have been released on DVD and VHS over the years. When the first season DVD was released in 2001, it quickly became the best-selling television DVD in history, although it was later overtaken by the first season of \"Chappelle's Show\". In particular, seasons one through seventeen have been released on DVD in the U.S. (Region 1), Europe (Region 2) and Australia/New Zealand/Latin America (Region 4). However, on April 19, 2015, Al Jean announced that the Season 17 DVD would be the last one ever produced, leaving the collection from Season 1 to 17, Season 20 (released out of schedule in 2009), with Seasons 18, 19, and 21 onwards unreleased. Jean also stated that the deleted scenes and commentary would try to be released to the Simpsons World app, and that they were pushing for Simpsons World to be expanded outside of the U.S. Two years later, however, on July 22, 2017, it was announced that Season 18 would be released on December 5, 2017 on DVD.\n\nIn 2003, about 500 companies around the world were licensed to use \"Simpsons\" characters in their advertising. As a promotion for \"The Simpsons Movie\", twelve 7-Eleven stores were transformed into Kwik-E-Marts and sold \"The Simpsons\" related products. These included \"Buzz Cola\", \"Krusty-O\" cereal, pink doughnuts with sprinkles, and \"Squishees\".\n\nIn 2008 consumers around the world spent $750 million on merchandise related to \"The Simpsons\", with half of the amount originating from the United States. By 2009, 20th Century Fox had greatly increased merchandising efforts. On April 9, 2009, the United States Postal Service unveiled a series of five 44-cent stamps featuring Homer, Marge, Bart, Lisa and Maggie, to commemorate the show's twentieth anniversary. \"The Simpsons\" is the first television series still in production to receive this recognition. The stamps, designed by Matt Groening, were made available for purchase on May 7, 2009. Approximately one billion were printed, but only 318 million were sold, costing the Postal Service $1.2 million.\n\n\n\n"}
{"id": "20945543", "url": "https://en.wikipedia.org/wiki?curid=20945543", "title": "Trimethylolethane trinitrate", "text": "Trimethylolethane trinitrate\n\nTrimethylolethane trinitrate (TMETN), also known as metriol trinitrate (METN, MTN, METRTN) or nitropentaglycerin, is a nitrate ester. It is a high explosive similar to nitroglycerin. It is a transparent oily liquid, colorless to light brown. It is odorless. It is used in some solid propellants and smokeless powders as a plasticizer. Its chemical formula is CH-C(CH-O-NO).\n\nTMETN was first prepared and patented in Italy under name Metriolo. Germans began producing it before World War II when it was demonstrated to be an erosion and flash reducing agent in smokeless powders. It is a liquid explosive with properties similar to nitroglycerin but more stable to heat. It is prepared by nitration of trimethylolethane (metriol). It does not induce headaches.\n\nTMETN can be initiated by friction, impact, and electrostatic discharge. It can be used as a high viscosity plasticizer-binder together with nitrocellulose, but its poor coloiding properties made such use rare; long-term milling can however assist here; success can also be achieved by adding an inert plasticizer and a volatile solvent/colloiding agent.\n\nTMETN is miscible with ether and acetone. It is insoluble in 95% sulfuric acid. It can be used as a plasticizer together, or as an alternative to, triethyleneglycol dinitrate (TEGDN).It can also be used as a monopropellant, in fact Triethylene glycol dinitrate, diethylene glycol dinitrate, and trimethyloleate trinitrate are being considered as replacements for nitroglycerin in propellants.\n\n"}
{"id": "48458046", "url": "https://en.wikipedia.org/wiki?curid=48458046", "title": "Universal receiver", "text": "Universal receiver\n\nUniversal receiver is generally a radio receiver that is able to work with different standard transmitters.\n\nIn case of home automations, this identify a radio receiver that works with almost any remote control in the market normally, used to open gates, garage doors, traffic barriers, entrance doors, etcetera. \nIn other words, the universal receiver is able to recognize the code transmitted by other standard and not-standard remote controls, and is suitable to replace existing receiver permitting to add new and different remote controls on the automation system.\n\n"}
{"id": "27837569", "url": "https://en.wikipedia.org/wiki?curid=27837569", "title": "Viaspace", "text": "Viaspace\n\nViaspace is a clean energy company focused on commercializing technologies from NASA, Caltech, University of Southern California and the United States Department of Defense. The company operates in the alternative energy, renewable energy, and chemical sensing sectors. The company is associated with the Jet Propulsion Lab (JPL) and the California Institute of Technology through its CEO, Dr. Carl Kukkonen (the former Director of the Center for Space Microelectronics Technology (CSMT) and Manager of Supercomputing at the NASA Jet Propulsion Laboratory).\n\nViaspace was founded in 1998 as a Caltech/NASA spin-off. The company began with the objective of transforming space and defense technologies that were originally developed at JPL into commercial products.\n\nIn 1998, Viaspace signed a memorandum of understanding with RGC to commercialize a Quantum well infrared photodetector. This led to a joint venture partnership between the two companies called QWIP Technologies (QWIPTECH), which was incorporated in December 1998. Dr. Carl Kukkonen, CEO of Viaspace, served as initial CEO of QWIP Technologies until RGC acquired 100% of QWIPTECH in 2000. Since RGC's QWIPTECH acquisition, Viaspace has had no stake in QWIPTECH nor holds any Quantum Well Infrared Photodetector patents.\n\nIn the summer of 1998, Viaspace also signed a memorandum of understanding with Omicron Technologies to form a joint venture for the commercialization of applications of a technology known as Active Pixel Sensors (APS). It was anticipated at the time of the joint venture that APS technology would be a strong competitor in its field and ultimately have a chance of replacing the widely used Charged Coupled Devices (CCDs) used in imaging technology. However, in 2000, Omicron announced that it had dropped out of the project due to financial issues. Viaspace decided to discontinue commercialization efforts for APS technology because it would be too costly. Commercialization of the APS technology by Omicron and Viaspace never materialized; however, Viaspace reacquired three patents from the failed Omicron partnership. These three patents are not associated with the imaging technology, but rather, in the field of radio satellite technology. The three radio satellite technology patents reacquired through the failed Omicron/ViaSpace Joint Venture are being applied toward Viaspace's inactive eCARmerce Inc. subsidiary, although there are no plans to further develop the eCARmerce subsidiary toward commercialization at this time.\n\nIn 1999, a company called Spectrasensors Inc acquired exclusive patent rights from NASA and Caltech to commercialize gas sensor technology. SpectraSensors became a Viaspace subsidiary in which Dr. Carl Kukkonen was CEO. In 2001 a company called Tunable Photonics was spun off from SpectraSensors. Dr. Carl Kukkonen served as CEO of ViaSpace, SpectraSensors, and Tunable Photonics during 2001. In 2002, a company called FiberSpace acquired Tunable Photonics. In 2003, SpectraSensors reacquired the remaining intellectual property from Tunable Photonics. Presently, SpectraSensors is a profitable company separate from Viaspace.\n\nOn August 14, 2000, Viaspace and Hewlett Packard announced a strategic alliance in which HP would provide US$10 million to Viaspace for commercialization of new technologies. Five million of HP's went to the development of Viachange.com, which Viaspace no longer operates.\n\nIn 2002, a new company, Direct Methanol Fuel Cell Corporation (DMFCC) was formed. DMFCC, Caltech and USC signed a letter of intent for DMFCC to acquire rights to and over U.S. and foreign patents. These include the original and fundamental patent for using methanol dissolved in water as the fuel for Direct Methanol Fuel Cells. In exchange, Caltech and USC became equity shareholders in DMFCC and receive a royalty on sales. Dr. Carl Kukkonen was and continues to operate as CEO of DMFCC.\n\nIn 2005, Viaspace became a public company through a merger between ViaSpace and Global Wide Production. The name ViaSpace was changed to Viaspace (all caps). Dr. Carl Kukkonen remained CEO, Mr. Amjad Abdallat took the position of vice president and chief operating officer, and Mr. Stephen Muzi became the chief financial officer, Secretary, and Treasurer of Viaspace. At the beginning of 2006, DMFCC exercised an option for a worldwide license to and fuel cell patents from Caltech and USC. DMFCC currently owns and patents related to fuel cells.\n\nIn 2006, Viaspace's wholly owned security and homeland defense subsidiary, Arroyo Sciences Inc., was renamed Viaspace Security Inc. In 2007, Viaspace Security's expert system software, \"SHINE Expert System\", licensed from Caltech, was awarded the NASA Space Act Award.\n\nIn May 2007, Viaspace established a new subsidiary Viaspace Energy. In October 2008, Viaspace entered the biofuels market with the announcement of the acquisition of Inter-Pacific Arts Corp (IPA), a company with a license to grow a fast-growing grass. IPA also sells framed art. The framed art business of IPA is Viaspace's only non-high-technology business unit and is being used to fund the growth of the grass segment of the business. Viaspace sold its humidity sensor line in April 2008 in order to focus on near term projects.\n\nViaspace created Viaspace Green Energy in 2009 as its alternative energy subsidiary. Viaspace is currently seeking or already has undisclosed contracts for DMFCC products and Giant King Grass products. In 2010 Viaspace announced the launch of its first product, Green Logs. About a month later, Viaspace Green Energy announced its first power plant MOU.\n\nPresently, two of the three Viaspace business units (the alternative energy and chemical sensing units) are based on exclusive technologies developed by JPL and funded by NASA and the DOD. The renewable energy business unit is based on a worldwide license granted by China Gate to grow Giant King Grass, a non-genetically modified hybrid grass.\n\nFor the alternative energy market, Viaspace subsidiary Direct Methanol Fuel Cell Corporation develops and manufactures disposable fuel cartridges for fuel cell powered electronic devices such as notebook computers, mobile phones and military systems. Caltech and USC are equity shareholders in DMFCC and will receive royalties on any sales. DMFCC currently owns 65 issued and 33 pending patents related to fuel cells.\n\nLaws forbidding methanol and other fuels onboard aircraft has deterred large OEMs from proceeding with commercialization of fuel cell powered devices. The regulation and safety standards of fuel cells is one cause of the long delay for the roll out of Direct Methanol Fuel Cell powered devices. The decisions to allow Direct Methanol Fuel Cells onboard aircraft will enhance the future prospect of Viaspace.\n\nFor the renewable energy markets, its subsidiary, Viaspace Green Energy, is cultivating Giant King Grass, a proprietary, fast-growing perennial grass for the production of liquid biofuels for transportation, and as a renewable substitute or replacement for coal as the heat source in stationary electricity generating power plants. By June 2010, the company had of land under cultivation.\n\nThrough its subsidiary Ionfinity, Viaspace is involved in collaborations with Caltech and NASA's Jet Propulsion Laboratory to develop and commercialize new sensor technology that can detect very small amounts of hazardous materials such as explosives, chemical/biological weapons, toxic gases and drugs. Ionfinity's sensors are based on mass spectrometry technology. Ionfinity is partnered with General Dynamics Corp., Sionex Corp., and Imaginative Technologies LLC.\n"}
{"id": "12296681", "url": "https://en.wikipedia.org/wiki?curid=12296681", "title": "W42", "text": "W42\n\nThe W42 was an American nuclear fission weapon developed in 1957.\n\nIn December 1957 the Army requested the Atomic Energy Commission to develop a nuclear warhead for the HAWK low- to medium-altitude surface-to-air missile. In July 1958 the military characteristics were approved for the new warhead and the design released. Two months later the requirement for a HAWK with a nuclear warhead was cancelled.\n\nIt equipped the AIM-47 Falcon long-range air-to-air missile; the design of the AAM-N-10 Eagle missile also allowed for carriage of the W42.\n\nThe dimensions of the warhead were 13-14in wide by 18.5in long. It weighed 75-92 pounds and used a proximity fuze.\n\nThe project was cancelled in June 1961.\n\n"}
{"id": "7306686", "url": "https://en.wikipedia.org/wiki?curid=7306686", "title": "WOUGNET", "text": "WOUGNET\n\nWomen of Uganda Network (WOUGNET) is Ugandan non-governmental organization dedicated to aiding women and women's organizations in the use of information and communication technologies (ICTs). WOUGNET is a member of the Association for Progressive Communications (APC).\n\nWOUGNET was set up in May 2000 by women's organisations from Uganda. Its mailing lists are hosted by Kabissa. WOUGNET's mission is \"to promote and support the use of information and communication technologies by women organisations as well as individuals, so as to improve the conditions of life for Ugandan women, by enhancing their capacities and opportunities for exchange, collaboration and information sharing.\" The director is Dorothy Okello.\n\nPrimarily, WOUGNET focuses on using mobile phones, e-mail and the web, and is interested in the integration of \"traditional means\" such as radio, video, and print in a way that it enables wider outreach. Subscriptions to the WOUGNET's mailing lists, drawn from a global audience, have grown from 50 in the year 2000 to 1,292 (spread out across two lists, the WOUGNET mailing list and the WOUGNET update newsletter) by December 2006.\n\n"}
{"id": "254664", "url": "https://en.wikipedia.org/wiki?curid=254664", "title": "Windshield", "text": "Windshield\n\nThe windshield (North America) or windscreen (Commonwealth English) of an aircraft, car, bus, motorbike or tram is the front window. Modern windshields are generally made of laminated safety glass, a type of treated glass, which consists of two (typically) curved sheets of glass with a plastic layer laminated between them for safety, and are bonded into the window frame. Motorbike windshields are often made of high-impact polycarbonate or acrylic plastic.\n\nWindshields protect the vehicle's occupants from wind and flying debris such as dust, insects, and rocks, and provide an aerodynamically formed window towards the front. UV coating may be applied to screen out harmful ultraviolet radiation. However, this is usually unnecessary since most auto windshields are made from laminated safety glass. The majority of UV-B is absorbed by the glass itself, and any remaining UV-B together with most of the UV-A is absorbed by the PVB bonding layer.\n\nOn motorbikes their main function is to shield the rider from wind, though not as completely as in a car, whereas on sports and racing motorcycles the main function is reducing drag when the rider assumes the optimal aerodynamic configuration with his or her body in unison with the machine and does not shield the rider from wind when sitting upright.\n\nEarly windshields were made of ordinary window glass, but that could lead to serious injuries in the event of a crash. A series of crashes led up to the development of stronger windshields. The most notable example of this is the \"Pane vs. Ford\" case of 1917 that decided against Pane in that he was only injured through reckless driving. They were replaced with windshields made of toughened glass and were fitted in the frame using a rubber or neoprene seal. The hardened glass shattered into many mostly harmless fragments when the windshield broke. These windshields, however, could shatter from a simple stone chip. In 1919, Henry Ford solved the problem of flying debris by using the new French technology of glass laminating. Windshields made using this process were two layers of glass with a cellulose inner layer. This inner layer held the glass together when it fractured. Between 1919 and 1929, Ford ordered the use of laminated glass on all of his vehicles.\n\nModern, glued-in windshields contribute to the vehicle's rigidity, but the main force for innovation has historically been the need to prevent injury from sharp glass fragments. Almost all nations now require windshields to stay in one piece even if broken, except if pierced by a strong force. Properly installed automobile windshields are also essential to safety; along with the roof of the car, they provide protection to the vehicle's occupants in the case of a roll-over accident .\n\nToday’s windshields are a safety device just like seatbelts and airbags. The installation of the auto glass is done with an automotive grade urethane designed specifically for automobiles. The adhesive creates a molecular bond between the glass and the vehicle. If the adhesive bond fails at any point on the glass it can reduce the effectiveness of the airbag and substantially compromise the structural integrity of the roof. The urethane sealant is protected from UV in sunlight by a band of dark dots around the edge of the windshield. The darkened edge transitions to the clear windshield with smaller dots to minimize thermal stress in manufacturing. The same band of darkened dots is often expanded around the rearview mirror to act as a sunshade.\n\nIn many places, laws restrict the use of heavily tinted glass in vehicle windshields; generally, laws specify the maximum level of tint permitted. Some vehicles have noticeably more tint in the uppermost part of the windshield to block sunglare.\n\nIn aircraft windshields, an electric current is applied through a conducting layer of tin(IV) oxide to generate heat to prevent icing. A similar system for automobile windshields, introduced on Ford vehicles as \"Quickclear\" in Europe (\"InstaClear\" in North America) in the 1980s and through the early 1990s, used this conductive metallic coating applied to the inboard side of the outer layer of glass. Other glass manufacturers utilize a grid of micro-thin wires to conduct the heat especially on the later European Ford Transit vans. These systems are more typically utilized by European auto manufacturers such as Jaguar and Porsche.\n\nThe use of thermal glass prevents some navigation systems from functioning correctly, as the embedded metal blocks the satellite signal.The RF signal tends to flow along the metal wires or layer so very little radiation can pass. This can be resolved by using an external antenna. Mobile telephones can also have problems; thermal glass typically allows only 0.0001 (1‰, or one per mille or 1 ppt) of the signal to pass, whereas a concrete wall with rebars allows up to 0.0100 (10%, or 100‰) of the signal to pass.\n\nThe term \"windshield\" is used generally throughout North America. The term \"windscreen\" is the usual term in the British Isles and Australasia for all vehicles. In the US \"windscreen\" refers to the mesh or foam placed over a microphone to minimize wind noise, while a \"windshield\" refers to the front window of a car. \nIn the UK, the terms are reversed, although generally, the foam screen is referred to as a microphone shield, and not a windshield.\n\nSports or racing cars would sometimes have aero screens, which were small semi-circular or rectangular windshields. These were often mounted in pairs behind a foldable flat windshield. Aero screens are usually less than in height. They are known as aero screens because they only deflect the wind. The twin aeroscreen setup (often called Brooklands) was popular among older sports and modern cars in vintage style.\n\nA \"wiperless windshield\" is a windshield that uses a mechanism other than wipers to remove snow and rain from the windshield. The concept car Acura TL features a wiperless windshield using a series of jet nozzles in the cowl to blow pressurized air onto the windshield. Also several glass manufacturers have experimented with nano type coatings designed to repel external contaminants with varying degrees of success but to date none of these have made it to commercial applications.\n\nAccording to the US National Windshield Repair Association, many types of stone damage can be successfully repaired. Whether the windshield can be repaired always depends upon four factors: the size, type, depth and location of the damage.\n\nRepair of cracks up to is within permissible limits; automobile glass with more severe damage needs to be replaced. However, this is dependent on local laws. If a crack extends to the edge of the panel then this would compromise the structural integrity of the windshield. Aircraft windshields are designed in such a way that even if a crack were to extend all the way across the panel, the structural integrity is maintained via multiple failsafe methods in both frame and the glass plies. A sacrificial outer layer that cracks rather than devitrifies is the first failsafe.\n\nCircular bullseyes, linear cracks, crack chips, dings, pits and star-shaped breaks can be repaired without removing the glass, eliminating the risk of leaking or bonding problems sometimes associated with replacement.\n\nSome damages are very difficult to repair, or cannot be repaired: \n\nIn cracked windshield repair, air is removed from the damaged area on the windshield with a specified vacuum injection pump. Then using the injection pump, the clear adhesive resin is injected to replace the air in the windshield crack. The resin is then cured with an ultraviolet light. When done properly, the damaged area’s strength is restored, as is 90–95% of the clarity.\n\nWindshields that cannot be repaired have to be replaced. Replacement of a windshield typically takes less than an hour. To ensure the vehicle is safe to drive, time values called the Safe Drive Away Time have been established. Windshields which have been replaced must cure or bond sufficiently until they are able to withstand the forces of a crash. Knowing the minimum time needed to cure the glass bonding adhesives is therefore important. This safe drive away time (SDAT) or minimum drive away time (MDAT) refers to the time required until a windshield installation or glass replacement is considered safe to drive again. Criteria are specified in U.S. Federal Motor Vehicle Safety Standards 212/208 (see FMVSS) to ensure the reliability of adhesive systems. Typically the SDAT is verified with crash tests as well as with high-speed laboratory test methods.\n\nConsumers may be unaware that the MDAT or SDAT time is focused on safety and not necessarily on the quality, durability, or warranty of the installation. Care must be taken not to drive the vehicle prior to the SDAT/MDAT. If a vehicle is released to be driven before the SDAT and the adhesive used to set the new windshield has not had appropriate cure time, the occupants will not be properly protected in the event of a collision.\n\nAirbags deploy at speeds up to and in some cases exert tremendous force on the windshield. Occupants can impact the airbag just 50  ms after initial deployment. Depending on vehicle design, airbag deployment and/or occupant impact into the airbag may increase forces on the windshield, dramatically in some cases.\nForces of occupants on the airbags - and hence the potential forces on the windshield - are lower for belted occupants. As consequence, adhesive suppliers usually inform their customers about the level of security achieved:\n\n1) Example: Security exceeding FMVSS 212/208 belted\n\n2) Example: Security exceeding FMVSS 212/208 unbelted\n\nWith the advent of quick-cure adhesives, mobile windshield replacements have become more prevalent. Often the temperature and humidity cannot be controlled for mobile installations. For most common glass adhesives the ideal environment is and 50% humidity. Variations from the ideal curing environment can increase the time needed for a sufficiently safe bond to form. Because of the variables and difficulties involved in mobile windshield replacement, many vehicle manufacturers do not recommend this method of installation.\n\nWaste disposal of laminated glass is no longer permitted in a landfill in most European countries as the End of Life Vehicles Directive (ELV) is implemented. A study by Surrey University and Pilkington Glass proposes that waste laminated glass be placed into a separating device such as a rolling mill where the glass is fragmented and the larger cullet is mechanically detached from the inner film. The application of heat then melts the laminating plastic, usually, Polyvinyl Butyral \"PVB\" enabling both the glass and the interior film to be recycled. The PVB recycling process is a simple procedure of melting and reshaping it.\nOne possible method of recycling of simple automotive laminated windshields could involve heating the windshield to above the melting point of the PVB interlayer and then separating the glass plies. This depends chiefly on the differential melting points of PVB and glass and is not suitable for other interlayer materials such as silicone based materials.\n\n\nManufacturing Processes Reference Guide: Robert H. Todd, Dell K. Allen, and Leo Alting\nHow It's Made: Windshields\n\n"}
