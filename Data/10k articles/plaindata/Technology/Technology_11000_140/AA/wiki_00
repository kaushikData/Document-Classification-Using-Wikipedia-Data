{"id": "98931", "url": "https://en.wikipedia.org/wiki?curid=98931", "title": "AIM alliance", "text": "AIM alliance\n\nThe AIM alliance was formed on October 2, 1991, between Apple Inc. (then Apple Computer), IBM, and Motorola to create a new computing standard based on the PowerPC architecture.\n\nPhil Hester, a designer of the IBM RS/6000, convinced IBM's president Jack Kuehler of the necessity of a business alliance.\nIn 1991, a historic alliance was formed between Apple and IBM with the stated goal of creating a single unifying open-standard computing platform for the whole industry, made of a new hardware design and a next-generation operating system. This would also directly challenge the dominant Wintel duopoly.\n\nIn 1992, Apple and IBM created two new companies called Taligent and Kaleida Labs as part of the alliance. Taligent was formed from a core team of Apple software engineers to create a next-generation operating system, code-named \"Pink\", to run on the platform. Kaleida was to create an object-oriented, cross-platform multimedia scripting language which would enable developers to create entirely new kinds of applications that would harness the power of the platform. IBM provided affinity between Workplace OS and Taligent—replacing Taligent's microkernel with the IBM Microkernel and adopting Taligent's CommonPoint application framework for Workplace OS, OS/2, and AIX.\n\nIt was thought that the CISC processors from Intel were an evolutionary dead-end in microprocessor design, and that since RISC was the future, the next few years were a period of great opportunity.\n\nThe CPUs are the PowerPC processors, the first of which, the PowerPC 601, is a single-chip version of IBM's POWER1 CPU. Both IBM and Motorola would manufacture PowerPC integrated circuits for this new platform. The computer architecture base was called \"PReP\" (PowerPC Reference Platform), and later complemented with OpenFirmware and renamed \"CHRP\" (Common Hardware Reference Platform). IBM used PReP and CHRP for PCI version of IBM's RS/6000 platform, from existing Micro Channel architecture models, and changed only to support the new 60x bus style of the PowerPC.\n\nEfforts on the part of Motorola and IBM to popularize PReP/CHRP failed when Apple, IBM, and Taligent all failed to provide an operating system that could run on it and when Apple and IBM couldn't reach agreement on whether the reference design must or must not have a parallel port. Although the platform was eventually supported by several Unix variants as well as Windows NT and Workplace OS (in the form of OS/2), these operating systems generally ran just as well on Intel-based hardware so there was little reason to use the PReP systems. The BeBox, designed to run BeOS, used some PReP hardware but as a whole was not compatible with the standard. Kaleida folded in 1995. Taligent was absorbed into IBM in 1998. Some CHRP machines shipped in 1997 and 1998 without widespread reception.\n\nThe PowerPC program is the one success that came out of the AIM alliance; Apple started using PowerPC chips in the Macintosh line starting in 1994. Almost every Mac featured a PowerPC processor from then until 2006, when the company transitioned entirely to Intel CPUs, due to eventual disappointment with the direction and performance of PowerPC development as of the G5 model. PowerPC also has had success in the embedded market, and all three major seventh-generation video game consoles, Gamecube, Wii, and the Wii U feature chipsets derived from the PowerPC architecture at their core. \n\nPower.org was founded in 2004 by IBM and fifteen partners with intent to develop, enable, promote, and drive adoption of Power Architecture technology, such as PowerPC and POWER and applications based on them. Freescale joined in 2006 and today the consortium consists of over forty companies and institutions.\n\n"}
{"id": "9563525", "url": "https://en.wikipedia.org/wiki?curid=9563525", "title": "Access For Learning Community", "text": "Access For Learning Community\n\nThe Access For Learning Community, or A4L, is a global, not-for-profit corporation committed to providing solutions in the education data space and supporting the use of standards by schools, districts, states, countries, and education vendors. It has regional chapters in the US, UK, AU, and New Zealand.\n\nIt was formerly known as the Schools Interoperability Framework Association, or SIFA. The name was changed in May 2015.\n\nA4L members collaborate on a variety of technical standards sometimes collectively known as the Schools Interoperability Framework. A4L publishes these standards, and advocates their adoption and provides training and support services. It also offers an SIF Certification trademark licensing program. The name change to Access For Learning (A4L) represents a shift to a more solution oriented vision rather than merely advocating for the SIF specification- including using multiple standards to solve school and district problems.\n\nThe organization includes more than 1000 members as of 2015, including government agencies, school districts, public advocacy organization and vendors of Schools Interoperability Framework products.\n\nFounded as a working group for \"Schools Interoperability Framework\" in 1997 by vendors under the auspices of the Software and Information Industry Association. In April 2003, SIFA was incorporated and activities within SIF project of the SIIA were transferred to the current corporation. On May 20, 2015 the name of the organization was changed to the Access For Learning Community, as an indicator of a new emphasis on being over all solutions-oriented for the community rather than strictly advocating the SIF specification.\n\nA4L Members elect officials every year for terms on the Association's Board of Directors. Each regional Technical Board is composed of the Lead of each A4L Project Team and Task Force and four members elected At-Large by the membership. The A4L Technical Board Members serve a one-year term.\n\nA4L members collaborate on a variety of technical standards sometimes collectively known as the Schools Interoperability Framework (or \"SIF\").\n\n\n"}
{"id": "4001002", "url": "https://en.wikipedia.org/wiki?curid=4001002", "title": "Ard (plough)", "text": "Ard (plough)\n\nThe ard, ard plough, or scratch plough is a simple light plough without a mouldboard. It is symmetrical on either side of its line of draft and is fitted with a symmetrical share that traces a shallow furrow but does not invert the soil. It began to be replaced in most of Europe by the carruca turnplough from the 7th century.\n\nIn its simplest form it resembles a hoe, consisting of a \"draft-pole\" (either composite or a single piece) pierced with a nearly vertical, wooden, spiked \"head\" (or \"stock\") which is dragged through the soil by draft animals and very rarely by people. The ard-head is at one end a \"stilt\" (handle) for steering and at the other a \"share\" (cutting blade) which gouges the surface ground. More sophisticated models have a composite pole, where the section attached to the head is called the \"draft-beam\", and the share may be made of stone or iron. Some have a cross-bar for handles or two separate stilts for handles (two-handled ard). The share comes in two basic forms: a socket share slipped over the nose of the ard-head; and the tang share fitted into a groove where it is held with a clamp on the wooden head. Additionally, a slender protruding chisel (foreshare) can be fitted over the top of the mainshare.\n\nRather than cutting and turning the soil to produce ridged furrows, the ard breaks up a narrow strip of soil and cuts a shallow furrow (or drill), leaving intervening strips undisturbed. The ard is not suited for clearing new land, so grass and undergrowth are usually removed with hoes or mattocks. Cross-ploughing is often necessary to break the soil up better, where the soil is tilled twice at right angles to the original direction (lengthwise and across). This usually results in square or diamond-shaped fields and is effective at clearing annual weeds. The ard's shallow furrows are ideal for most cereals, and if the seed is sown broadcast, the ard can be used to cover the seed in rows. In fact, the ard may have been invented in the Near East to cover seed rather than till. That would explain why in Mesopotamia seed drills were used together with ards. The ard is most useful on light soils such as loams or sands, or in mountain fields where the soil is thin, and can be safely used in areas where deep ploughing would turn up hardpan or would cause salination or erosion.\n\nArds may be drawn by oxen, water buffalo, donkeys, camels, or other animals.\n\nArds come in a number of varieties. Based on use, there are two kinds: the \"tilth ard\", for cutting furrows in cleared land, and the \"rip ard\", or sod buster, which has a hooked share that gouges deeper into the soil and more effectively clears virgin or fallow land. The two were in early times used in conjunction with each other. Third is the \"seed drill ard\", used specifically in Mesopotamia, which added a funnel for dropping seed in the furrows as the ard cut them.\nThe earliest and most basic tilth ards are the two-piece models:\nThe bow ard is the weaker, narrower, and probably earlier of the two. It is used for shallow tillage, normally with a tang share, in dry, stony soils. It is restricted mainly to the Mediterranean (Spain, Tunisia, Greece, Turkey, Syria, Lebanon), Ethiopia, Iran, and eastern India and Sumatra. The more widespread body ard, sturdier and heavier for deeper tillage (in soils with enough moisture), usually has a socket share which is sometimes laterally extended or has serrated wings (Balkans, Morocco, Portugal, Spain) for better mixing of soil and cutting of weeds. It had a short portion of the body which was first made to slide on the furrow bottom and gradually developed into a horizontal body. The body ard dominates in Portugal, western Spain, the Balkans, India, Sri Lanka, Malaysia, Thailand, Japan, and most of Latin America.\n\nThe bow ard favored the development of a long horizontal sole body (slade) sliding on the ground. This led to the sole ard, first attested in Bronze Age Cyprus, being single-handled and consisting of a flat sole (or slade) into which were set the draft-pole and stilt, meaning there were three separate pieces. Their use in Ancient Greek agriculture was described by Hesiod. In northern Europe the single-handled crook ard was favored, consisting of a stilt inserted into a pole with a crook-shaft, i.e., the pole had a curved shape and had a natural crook tip that served as a share.\nLater variations of the sole ard come in two types: the triangular and quadrangular ards. The triangular ard has a horizontal sole body holding the beam and stilt which cross each other, forming a triangle at the base. The quandrangular ard has a horizontal sole body connected to a straight, nearly parallel beam by a stilt and a brace.\n\nEvidence of its use in prehistory is sometimes found at archaeological sites where the long, shallow scratches (\"ard marks\") it makes can be seen cutting into the subsoil. The ard first appears in the mid-Neolithic and is closely related to the domestication of cattle. It probably spread with animal traction in general across the cereal-growing cultures of the Neolithic Old World. Its exact point of origin is unknown, but it spread quickly throughout West Asia, South Asia and Europe in the late Neolithic and early Chalcolithic.\n\nEvidence appears in the Near East in the 6th millennium . Iron versions appeared   both in Assyria and 3rd-dynasty Egypt. In Europe, the earliest known wooden ard (at Lavagone in Italy) dates from around 2300-2000 , but the earliest scratch marks date from 3500-3000 . All of these were bow ards, also depicted in the rock drawings of Bohuslän, Sweden, and Fontanalba, France.\n\nThe first bow ards were likely adapted from hoes and like instruments and therefore suffered from poor balance due to their narrow bodies with only one point in the soil. This restricted their use to obstacle-free soils such as irrigated canals. The stress between body and pole was neutralized by adding a brace consisting of a fiber or leather strap between the low end of the pole and the body. The brace was later made out of wood and became important, not only on bow ards but also body ards. Today, a wooden brace between the draft-pole and upper stilt is a particular feature of body ards in Syria, central Iraq, Turkestan, and Kansu (China). The bow ard arrived in China as early as 3000 , most likely arriving with wheat, barley, and hemp in the Lungshanoid period. Today, the bow ard is confined to minority tribes and mountainous regions, but in earlier times was widely disseminated until ousted by the carruca turnplough beginning around  600.\n\nThe body ard made its way east as far as northwest China via Sinkiang Province, but then underwent radical changes. A long-pole body ard with a knee-like brace is still found in western Lanchow Province. In some parts of Europe with moist soils, the body ard's path was cleared by a \"ristle\", a coulter-like implement used to reach greater depth. In Spain and Portugal this remains a separate tool, but elsewhere it was the precursor to the coulter.\n\n\nA valuable reference book is Ard og Plov I Nordens Oldtid (with an extensive English summary)published by the Jutland Archeological Society of Aarhus University in 1951. The book is illustrated including maps showing the archaeological sites in Northern Europe that have provided evidence of the use of the ard in prehistoric times.\n\n"}
{"id": "3112664", "url": "https://en.wikipedia.org/wiki?curid=3112664", "title": "Avionics Full-Duplex Switched Ethernet", "text": "Avionics Full-Duplex Switched Ethernet\n\nAvionics Full-Duplex Switched Ethernet (AFDX) is a data network, patented by international aircraft manufacturer Airbus, for safety-critical applications that utilizes dedicated bandwidth while providing deterministic quality of service (QoS). AFDX is a worldwide registered trademark by Airbus. The AFDX data network is based on Ethernet technology using commercial off-the-shelf (COTS) components. The AFDX data network is a specific implementation of ARINC Specification 664 Part 7, a profiled version of an IEEE 802.3 network per parts 1 & 2, which defines how commercial off-the-shelf networking components will be used for future generation Aircraft Data Networks (ADN). The six primary aspects of an AFDX data network include full duplex, redundancy, determinism, high speed performance, switched and profiled network.\n\nMany commercial aircraft use the ARINC 429 standard developed in 1977 for safety-critical applications. ARINC 429 utilizes a unidirectional bus with a single transmitter and up to twenty receivers. A data word consists of 32 bits communicated over a twisted pair cable using the bipolar return-to-zero modulation. There are two speeds of transmission: high speed operates at 100 kbit/s and low speed operates at 12.5 kbit/s. ARINC 429 operates in such a way that its single transmitter communicates in a point-to-point connection, thus requiring a significant amount of wiring which amounts to added weight.\n\nAnother standard, ARINC 629, introduced by Boeing for the 777 provided increased data speeds of up to 2 Mbit/s and allowing a maximum of 120 data terminals. This ADN operates without the use of a bus controller thereby increasing the reliability of the network architecture. The drawback is that it requires custom hardware which can add significant cost to the aircraft. Because of this, other manufacturers did not openly accept the ARINC 629 standard.\n\nAFDX was designed as the next-generation aircraft data network. Basing on standards from the IEEE 802.3 committee (commonly known as Ethernet) allows commercial off-the-shelf hardware to reduce costs and development time. AFDX is one implementation of deterministic Ethernet defined by ARINC Specification 664 Part 7. AFDX was developed by Airbus Industries for the A380, initially to address real-time issues for flight-by-wire system development. Building on the experience from the A380, the Airbus A350 also uses an AFDX network, with avionics and systems supplied by Rockwell Collins. Airbus and its EADS parent company have made AFDX licenses available through the EADS Technology Licensing initiative, including agreements with Selex ES and Vector Informatik GmbH. A of deterministic Ethernet is used on the Boeing 787 Dreamliner. Multiple switches can be bridged together in a cascaded star topology. This type of network can significantly reduce wire runs and, thus, the overall weight of the aircraft. In addition, AFDX can provide quality of service and dual link redundancy.\n\nAFDX adopted concepts such as the token bucket from the telecom standards, asynchronous transfer mode (ATM), to fix the shortcomings of IEEE 802.3 Ethernet. By adding key elements from ATM to those already found in Ethernet, and constraining the specification of various options, a highly reliable full-duplex deterministic network is created providing guaranteed bandwidth and quality of service (QoS). Through the use of full-duplex Ethernet, the possibility of transmission collisions is eliminated. The network is designed in such a way that all critical traffic is prioritized using QoS policies so delivery, latency, and jitter are all guaranteed to be within set parameters. A highly intelligent switch, common to the AFDX network, is able to buffer transmission and reception packets. Through the use of twisted pair or fiber optic cables, full-duplex Ethernet uses two separate pairs or strands for transmitting and receiving the data. AFDX extends standard Ethernet to provide high data integrity and deterministic timing. Further a redundant pair of networks is used to improve the system integrity (although a virtual link may be configured to use one or the other network only). It specifies interoperable functional elements at the following OSI reference model layers:\n\n\nThe main elements of an AFDX network are:\n\nThe central feature of an AFDX network are its \"virtual links\" (VL). In one abstraction, it is possible to visualise the VLs as an ARINC 429 style network each with one source and one or more destinations. Virtual links are unidirectional logic paths from the source end-system to all of the destination end-systems. Unlike that of a traditional Ethernet switch which switches frames based on the Ethernet destination or MAC address, AFDX routes packets using a virtual link ID, which is carried in the same position in an AFDX frame as the MAC destination address in an Ethernet frame. However, in the case of AFDX, this virtual link ID identifies the data carried rather than the physical destination. The virtual link ID is a 16-bit unsigned integer value that follows a constant 32-bit field. The switches are designed to route an incoming frame from one, and only one, end system to a predetermined set of end systems. There can be one or more receiving end systems connected within each virtual link. Each virtual link is allocated dedicated bandwidth [sum of all VL bandwidth allocation gap (BAG) rates x MTU] with the total amount of bandwidth defined by the system integrator. However, total bandwidth cannot exceed the maximum available bandwidth on the network. Bi-directional communications must therefore require the specification of a complementary VL.\n\nEach VL is frozen in specification to ensure that the network has a designed maximum traffic, hence determinism. Also the switch, having a VL configuration table loaded, can reject any erroneous data transmission that may otherwise swamp other branches of the network. Additionally, there can be sub-virtual links (sub-VLs) that are designed to carry less critical data. Sub-virtual links are assigned to a particular virtual link. Data are read in a round-robin sequence among the virtual links with data to transmit. Also sub-virtual links do not provide guaranteed bandwidth or latency due to the buffering, but AFDX specifies that latency is measured from the traffic regulator function anyway.\n\nBAG stands for bandwidth allocation gap, this is one of the main features of the AFDX protocol. This is the maximum rate data can be sent, and it is guaranteed to be sent at that interval. When setting the BAG rate for each VL, care must be taken so there will be enough bandwidth for other VL's and the total speed cannot exceed 100 Mbit/s.\n\nEach switch has filtering, policing, and forwarding functions that should be able to process at least 4096 VLs. Therefore, in a network with multiple switches (cascaded star topology), the total number of virtual links is nearly limitless. There is no specified limit to the number of virtual links that can be handled by each end system, although this will be determined by the BAG rates and maximum frame size specified for each VL versus the Ethernet data rate. However, the number sub-VLs that may be created in a single virtual link is limited to four. The switch must also be non-blocking at the data rates that are specified by the system integrator, and in practice this may mean that the switch shall have a switching capacity that is the sum of all of its physical ports.\n\nSince AFDX utilizes the Ethernet protocol at the MAC layer, it is possible to use high performance COTS switches with Layer 2 routing as AFDX switches for testing purposes as a cost-cutting measure. However, some features of a real AFDX switch may be missing, such as traffic policing and redundancy functions.\n\nThe AFDX bus is used in Airbus A380, Boeing 787, Airbus A400M, Airbus A350, Sukhoi Superjet 100, ATR 42, ATR 72 (-600), AgustaWestland AW101, AgustaWestland AW189, AgustaWestland AW169, Irkut MC-21, Bombardier Global Express, Bombardier CSeries, Learjet 85, Comac ARJ21, and AgustaWestland AW149.\n\n\n"}
{"id": "20443048", "url": "https://en.wikipedia.org/wiki?curid=20443048", "title": "BSRIA", "text": "BSRIA\n\nBSRIA (it takes its name from the initial letters of the Building Services Research and Information Association) is a UK-based testing, instrumentation, research and consultancy organisation, providing specialist services in construction and building services engineering. It is a not-for-profit, member-based association, with over 650 member companies; related services are delivered by a trading company, BSRIA Limited. Any profits made are invested in its research programme, producing best practice guidance.\n\nBSRIA is a full member of the Construction Industry Council.\n\nBSRIA had a turnover of £11.8 million in 2010/11. It employs over 180 people at its UK head office in Bracknell as well as regionally based engineers in the UK and offices in France, Spain, Germany, China, Japan, Brazil and North America.\n\nBSRIA's mission is \n\"to enable the building services and construction industries and their clients to enhance the value of the built environment, by improving the quality of their products and services, the efficiency of their provision and the effectiveness of their operation.\"\n\nBSRIA was formed in 1955 as the Heating and Ventilating Research Council, later to become the Heating and Ventilating Research Association. As the industry became increasingly linked with other services so its research association and professional body saw the need to widen their remit. In 1975 the 'building services' scope was adopted, marked by the formation of the Building Services Research and Information Association, commonly shortened to BSRIA, and, in 1976, the formation of the Chartered Institution of Building Services, renamed the Chartered Institution of Building Services Engineers (CIBSE) in 1985.\n\nAs the Association's activities developed to meet the needs of an integrated construction industry and to provide more than just research and information, the full name became less relevant. When new government rules required it to split research and other activities into two companies, BSRIA started formal use of the abbreviation.\n\nTrading activities, including research, are now managed through a trading company, BSRIA Limited, which is a wholly owned subsidiary of the Building Services Research and Information Association, which is a company limited by guarantee. Thus, members - largely companies active in designing and delivering building services - join the Building Services Research and Information Association, and services are provided by BSRIA Limited.\n\n\nThe following companies were the founding members of BSRIA who remain as members now (original company names updated to current):\n\n\nBSRIA now has over 600 corporate members.\n\n\n"}
{"id": "4098193", "url": "https://en.wikipedia.org/wiki?curid=4098193", "title": "Blotting paper", "text": "Blotting paper\n\nBlotting paper, sometimes called bibulous paper, is a highly absorbent type of paper or other material. It is used to absorb an excess of liquid substances (such as ink or oil) from the surface of writing paper or objects. Blotting paper referred to as bibulous paper is mainly used in microscopy to remove excess liquids from the slide before viewing. Blotting paper has also been sold as a cosmetic to aid in the removal of skin oils and makeup.\n\nBlotting paper is made from different materials of varying thickness, softness, etc. depending on the application. It is often made of cotton and manufactured on special paper machines. Blotting paper is reputed to be first referred to in the English language in the 15th century but there is a tradition in Norfolk, England that it was invented by accident at Lyng Mill on the River Wensum.\n\nIt is reported that a Berkshire (England) paper mill worker failed to add sizing to a batch of paper that was being produced. The batch was discarded. Subsequently, someone tried to write on a piece of this discarded \"scrap\" paper and found that it rapidly absorbed any ink applied, making it unusable for writing. Its marked absorbency having been noted, however, led to its subsequently being produced and used as blotting paper, replacing sand, which was the material that had been used for absorbing superficial wet ink. In a time when most paper was produced from \"rags\", red/pink rags, from which it was difficult to remove all color and had generally been discarded, were now directed to the production of blotters, hence the historically characteristic pink color of blotters.\n\nA form of blotter paper commonly known as watercolor paper is produced for its absorbent qualities, allowing much better absorption of water and pigments than standard art or drawing papers. Although usually categorized as separate from blotting paper, differences in the constituents and thickness of blotting paper and watercolor paper are subtle, and making a distinction between the two is unnecessary as the production process is nearly identical.\n\nBlotting paper is used in chemical analyses as stationary phase in thin-layer chromatography. Blotting paper is also used in pool/spa maintenance to measure pH balance. Small squares of blotting paper attached to disposable plastic strips are impregnated with pH sensitive compounds usually extracted from lichens, especially Roccella tinctoria. These strips are used similarly to litmus strips, however filter paper is usually used for litmus strips, generally to allow for the property of diffusion.\n\nDrugs active in microgram range, most notably LSD, are commonly distributed on blotting paper. A liquid solution of the drug is applied to the blotting paper, which commonly is perforated into individual doses and artfully decorated with what is known as blotter art. Vanity blotter is blotter art that hasn't been exposed to LSD and is usually sold as a collectible, although inevitably much of this art ends up in illegal distribution. The artwork is printed onto blotter paper and then sometimes perforated into tiny squares or \"tabs\" which can be torn or cut apart. Most blotter art designs have grid lines as part of the design to either aid in perforation or to be left as a cutting grid. Blotter as a delivery method allows for easy dosing of potent substances and easy sublingual administration of drugs which has made it increasingly popular as a preparation for other potent drugs including 25I-NBOMe and alprazolam.\n\nPlain white LSD blotter without artwork is commonly referred to as WoW (White on White) and is usually not perforated but rather gridded with a pen and sometimes laid on commonly obtained watercolor paper.\n\nBlotting is frequently necessary when using dip pens and occasionally when using fountain pens. This was first done by sprinkling pounce over the wet ink.\n\nWhen used to remove ink from writings, the writing may appear in reverse on the surface of the blotting paper, a phenomenon which has been used as a plot device in a number of detective stories, such as in the Sherlock Holmes story The Adventure of the Missing Three-Quarter.\n\nBlotting papers are also commonly used in cosmetics to absorb excess sebum oil from the face. They are popularly marketed and have been sold by numerous cosmetic brands worldwide such as Mac and Bobbi Brown, as well as UK high street store: Boots UK. Prices for blotting papers can range from as low as $3.00 per packet to as high as $30 or more. More affordable brands can be found by makers such as Clean and Clear and pharmacies such as Walgreens or CVS often carry their own brands for a reduced price. \n\nThe papers are often dyed, for wider market appeal, and dusted with salicylic acid and minerals to actively prevent the formation of comedones and acne. However, there is a popular debate of whether blotting papers can help reduce acne by absorbing excess oil, or cause it. The quality of the blotting papers and the use of other ingredients such as mineral oils may be a determining factor.\n"}
{"id": "11423396", "url": "https://en.wikipedia.org/wiki?curid=11423396", "title": "Burnup", "text": "Burnup\n\nIn nuclear power technology, burnup (also known as fuel utilization) is a measure of how much energy is extracted from a primary nuclear fuel source. It is measured both as the fraction of fuel atoms that underwent fission in %FIMA (fissions per initial metal atom) and as the actual energy released per mass of initial fuel in gigawatt-days/metric ton of heavy metal (GWd/tHM), or similar units.\n\nExpressed as a percentage: if 5% of the initial heavy metal atoms have undergone fission, the burnup is 5%. In reactor operations, this percentage is difficult to measure, so the alternative definition is preferred. This can be computed by multiplying the thermal power of the plant by the time of operation and dividing by the mass of the initial fuel loading. For example, if a 3000 MW thermal (equivalent to 1000 MW electric) plant uses 24 tonnes of enriched uranium (tU) and operates at full power for 1 year, the average burnup of the fuel is (3000 MW·365 d)/24 metric tonnes = 45.63 GWd/t, or 45,625 MWd/tHM (where HM stands for heavy metal, meaning actinides like thorium, uranium, plutonium, etc.).\n\nConverting between percent and energy/mass requires knowledge of κ, the thermal energy released per fission event. A typical value is 193.7 MeV () of thermal energy per fission (see Nuclear fission). With this value, the maximum burnup of 100%, which includes fissioning not just fissile content but also the other fissionable nuclides, is equivalent to about 909 GWd/t. Nuclear engineers often use this to roughly approximate 10% burnup as just less than 100 GWd/t.\n\nThe actual fuel may be any actinide that can support a chain reaction, including uranium, plutonium, and more exotic transuranic fuels. This fuel content is often referred to as the \"heavy metal\" to distinguish it from other metals present in the fuel, such as those used for cladding. The heavy metal is typically present as either metal or oxide, but other compounds such as carbides or other salts are possible.\n\nGeneration II reactors were typically designed to achieve about 40 GWd/tU. With newer fuel technology, and particularly the use of nuclear poisons, these same reactors are now capable of achieving up to 60 GWd/tU. After so many fissions have occurred, the build-up of fission products poisons the chain reaction and the reactor must be shut down and refueled.\n\nSome more-advanced light-water reactor designs are expected to achieve over 90 GWd/t of higher-enriched fuel.\n\nFast reactors are more immune to fission-product poisoning and can inherently reach higher burnups in one cycle. In 1985, the EBR-II reactor at Argonne National Laboratory took metallic fuel up to 19.9% burnup, or just under 200 GWd/t.\n\nThe Deep Burn Modular Helium Reactor (DB-MHR) might reach 500 GWd/t of transuranic elements.\n\nIn a power station, high fuel burnup is desirable for:\n\n\nIt is also desirable that burnup should be as uniform as possible both within individual fuel elements and from one element to another within a fuel charge. In reactors with online refuelling, fuel elements can be repositioned during operation to help achieve this. In reactors without this facility, fine positioning of control rods to balance reactivity within the core, and repositioning of remaining fuel during shutdowns in which only part of the fuel charge is replaced may be used.\n\nOn the other hand, there are signs that increasing burnup above 50 or 60 GWd/tU leads to significant engineering challenges and that it does not necessarily lead to economic benefits. Higher-burnup fuels require higher initial enrichment to sustain reactivity. Since the amount of separative work units (SWUs) is not a linear function of enrichment, it is more expensive to achieve higher enrichments. There are also operational aspects of high burnup fuels that are associated especially with reliability of such fuel. The main concerns associated with high burnup fuels are:\n\nIn once-through nuclear fuel cycles such as are currently in use in much of the world, used fuel elements are disposed of whole as high level nuclear waste, and the remaining uranium and plutonium content is lost. Higher burnup allows more of the fissile U and of the plutonium bred from the U to be utilised, reducing the uranium requirements of the fuel cycle.\n\nIn once-through nuclear fuel cycles, higher burnup reduces the number of elements that need to be buried. However, short-term heat emission, one deep geological repository limiting factor, is predominantly from medium-lived fission products, particularly Cs (30.08 year half life) and Sr (28.9 year half life). As there are proportionately more of these in high-burnup fuel, the heat generated by the spent fuel is roughly constant for a given amount of energy generated.\n\nSimilarly, in fuel cycles with nuclear reprocessing, the amount of high-level waste for a given amount of energy generated is not closely related to burnup. High-burnup fuel generates a smaller volume of fuel for reprocessing, but with a higher specific activity.\n\nUnprocessed used fuel from current light-water reactors consists of 5% fission products and 95% actinides, and is dangerously radiotoxic, requiring special custody, for 300,000 years. Most of the long-term radiotoxic elements are transuranic, and therefore could be recycled as fuel. 70% of fission products are either stable or have half lives less than one year. Another six percent (I and Tc) can be transmuted to elements with extremely short half lives (I—12.36 hours—and Tc—15.46 seconds). Zr, having a very long half life, constitutes 5% of fission products, but can be alloyed with uranium and transuranics during fuel recycling, or used in cladding, where its radioactivity is irrelevant. The remaining 20% of fission products, or 1% of unprocessed fuel, for which the longest-lived isotopes are Cs and Sr, require special custody for only 300 years. Therefore, the mass of material needing special custody is 1% of the mass of unprocessed used fuel.\n\nBurnup is one of the key factors determining the isotopic composition of spent nuclear fuel, the others being its initial composition and the neutron spectrum of the reactor. Very low fuel burnup is essential for the production of weapons-grade plutonium for nuclear weapons, in order to produce plutonium that is predominantly Pu with the smallest possible proportion of Pu and Pu.\n\nPlutonium and other transuranic isotopes are produced from uranium by neutron absorption during reactor operation. While it is possible in principle to remove plutonium from used fuel and divert it to weapons usage, in practice there are formidable obstacles to doing so. First, fission products must be removed. Second, plutonium must be separated from other actinides. Third, fissionable isotopes of plutonium must be separated from non-fissionable isotopes, which is more difficult than separating fissionable from non-fissionable isotopes of uranium, not least because the mass difference is one atomic unit instead of three. All processes require operation on strongly radioactive materials. Since there are many simpler ways to make nuclear weapons, nobody has constructed weapons from used civilian electric power reactor fuel, and it is likely that nobody ever will do so. Furthermore, most plutonium produced during operation is fissioned. To the extent that fuel is reprocessed on-site, as proposed for the Integral Fast Reactor, opportunities for diversion are further limited. Therefore, production of plutonium during civilian electric power reactor operation is not a significant problem.\n\nOne 2003 MIT graduate student thesis concludes that \"the fuel cycle cost associated with a burnup level of 100 GWd/tHM is higher than for a burnup of 50 GWd/tHM. In addition, expenses will be required for the development of fuels capable of sustaining such high levels of irradiation. Under current conditions, the benefits of high burnup (lower spent fuel and plutonium discharge rates, degraded plutonium isotopics) are not rewarded. Hence there is no incentive for nuclear power plant operators to invest in high burnup fuels.\"\n\nA study sponsored by the Nuclear Energy University Programs investigated the economic and technical feasibility, in the longer term, of higher burnup.\n\n"}
{"id": "18983683", "url": "https://en.wikipedia.org/wiki?curid=18983683", "title": "CBEFF", "text": "CBEFF\n\nCBEFF (Common Biometric Exchange Formats Framework) was developed from 1999 to 2000 by the CBEFF Development Team (NIST) and the BioAPI Consortium. This standard provides the ability for different biometric devices and applications to exchange biometric information between system components efficiently. In order to support biometric technologies in a common way the CBEFF structure describes a set of necessary data elements.\n\nThe CBEFF Basic Structure consists of a single SBH (Standard Biometric Header) followed by a BSMB (Biometric Specific Memory Block) and an optional SB (Signature Block).\n\nThe CBEFF Nested Structure consists of a Root Header, optional Sub-Headers, CBEFF Basic Structure(s), and an optional SB (Signature Block).\n\n"}
{"id": "1484823", "url": "https://en.wikipedia.org/wiki?curid=1484823", "title": "Came", "text": "Came\n\nA came is a divider bar used between small pieces of glass to make a larger glazing panel.\n\nThere are two kinds of came: the H-shaped sections that hold two pieces together and the U-shaped sections that are used for the borders. Cames are mostly made of lead, zinc, copper, brass or brass-capped lead. Of the metal strips, lead is softer and more flexible, making it easier to cut and bend. The harder metals are used to work with slightly curved lines and pieces that require greater structural support. They can also be used as border came, once again for stability and support.\n\nCame serves three purposes:\n\nCame comes in varying face sizes and shapes. They can be round, flat or colonial shaped strips. They can also be narrow or have wide faces.\n\nCame strips are 4 to 6 feet in length.The came strips can be a leaf, channel or heart came: \n\n\"The leaf is the surface on either side of the came that overlaps the edges of the glass and is left exposed once the panel has been assembled. It has either a flat or rounded profile and its width is the measurement given when a came size is listed. \n\nThe channel runs the length of the came. H-shaped came has 2 back-to-back channels that hold adjoining glass pieces in position on the interior of a stained glass panel. It can also be used as a border came in certain situations. U-shaped came has only one channel and is used as a border around the perimeter of panels. \n\nThe heart is the part of the came that the glass pieces rest against inside the channel. The width of lead came pattern lines is usually 1/16 inch and allows for the thickness of the came's heart to fit between the adjoining pieces of glass.\"\n\nThe width and depth of the came used to assemble the piece affect the pattern for cutting glass and for creating the finished piece.\n\nBorder cames are U-channel cames that are used on the outside edges of works. The selection of the metal of the came may vary depending upon the work. For instance, zinc may be a solid selection for free-hanging panels, because it is rigid, but lightweight. Architectural panels, on the other hand, are often enclosed in framing and therefore do not require a hard metal.\n\nBumpers, or lead spacers, are pieces of cut came strips that are left over. They can be used temporarily in the glasswork process to hold together two pieces of glass to estimate the spacing of the finished project.\n\n"}
{"id": "44111579", "url": "https://en.wikipedia.org/wiki?curid=44111579", "title": "Carbon nanothread", "text": "Carbon nanothread\n\nA carbon nanothread (informally “diamond” nanothread) is a sp-bonded, one-dimensional carbon crystalline nanomaterial. The tetrahedral sp-bonding of its carbon is similar to that of diamond. Nanothreads are only a few atoms across, more than 20,000 times thinner than a human hair. They consist of a stiff, strong carbon core surrounded by hydrogen atoms. Carbon nanotubes, although also one-dimensional nanomaterials, in contrast have sp-carbon bonding as is found in graphite.\n\nNanothreads are synthesized by compressing liquid benzene to extreme pressure of 20 GPa (around 200,000 times the pressure at the surface of the Earth), and then slowly relieving that pressure. The mechanochemical synthesis reaction can be considered a form of organic solid state chemistry. The benzene chains form extremely thin, tight rings of carbon that are structurally similar to diamonds. Researchers at Cornell University have traced pathways from benzene to nanothreads, which may involve a series of organic [4+2] cycloaddition reactions along stacks of benzene molecules, followed by further reaction of unsaturated bonds. Recently synthesis of macroscopic single crystal arrays of nanothreads hundreds of microns in size has been reported. The order and lack of grain boundaries in single crystals is often very desirable because it facilitates both applications and characterization. In contrast, carbon nanotubes form only thin crystalline ropes. Control of the rate of compression and/or decompression appears to be important to the synthesis of polycrystalline and single crystal nanothreads. Slow compression/decompression may favor low energy reaction pathway(s). If the synthesis pressure for nanothreads can be reduced to 5 to 6 GPa, which is the pressure used for synthesis of industrial diamond, production on the large scale of >10 kg/yr would be possible.\n\nThe formation of nanothread crystals appears to be guided by uniaxial stress (mechanical stress in a particular single direction), to which the nanothreads consistently align. Reaction to form the crystals is not topochemical, as it involves a major rearrangement from a lower symmetry monoclinic benzene crystal to a higher symmetryhexagonal nanothread crystal. Topochemical reactions generally require commensuration between the periodicities and interatomic distances between reactant and product. The distances between benzene molecules with van der Waals separations between them must shrink by 40% or more as the short, strong covalent carbon-carbon bonds between them form during the nanothread synthesis reaction. Such large changes in geometry usual break up crystal order, but the nanothread reaction instead creates it. Even polycrystalline benzene reacts to form macroscopic single crystal packings of nanothreads hundreds of microns across. Topochemical solid state reactions such as the formation of single crystal polydiacetylenes from diacetylenes usually require a single crystal reactant to form a single crystal product.\n\nThe impetus for the formation of a hexagonal crystal appears to be the packing of circular cross section threads. The details of how it is possible to transform from a monoclinic benzene crystal to a hexagonal nanothread crystal are not yet fully understood. Further development of the theory of the effect of pressure on reactions may help.\n\nOrganic synthesis efforts towards polytwistane nanothreads have been reported. \n\nDiamond threads were described by Arthur C. Clarke in his novel The Fountains of Paradise in 1979. Nanothreads were first investigated theoretically in 2001 by researchers at Penn State University and later by researchers at Cornell University. In 2014, researchers at Penn State University created the first sp-carbon nanothreads in collaboration with Oak Ridge National Laboratory and the Carnegie Institution for Science. Prior to 2014, and despite a century of investigation, benzene was thought to produce only hydrogenated amorphous carbon when compressed. As of 2015, threads at least 90 nanometers in length had been created (compared to .5 meters for CNTs). \n\nSince “diamond nanothreads” are sp-bonded and one-dimensional they are unique in the matrix of hybridization (sp/sp) and dimensionality (0D/1D/2D/3D) for carbon nanomaterials.\n\nAssuming a topological unit cell of one or two benzene rings with at least two bonds interconnecting each adjacent pair of rings, 50 topologically distinct nanothreads have been enumerated. 15 of these are within 80 meV/carbon atom of the most stable member. Some of the more commonly discussed nanothread structures are known informally as polytwistane, tube (3,0), and Polymer I. Polytwistane is chiral. Tube (3,0) can be thought of as the thinnest possible thread that can be carved out of the diamond structure, consisting of stacked cyclohexane rings. Polymer I was predicted to form from benzene at high pressure.\n\nAlthough there is compelling evidence from two dimensional X-ray diffraction patterns, transmission electron diffraction, and solid-state nuclear magnetic resonance (NMR) for a structure consisting of hexagonally packed crystals of 6.5 Angstrom diameter nanothreads with largely (75 to 80%) sp-bonding, the atomic structure of nanothreads is still under investigation. Nanothreads have also been observed by transmission electron microscopy.\n\nNanothreads have also been classified by their degree of saturation. Fully saturated degree 6 nanothreads have no double bonds remaining. Three bonds form between each pair of benzene molecules. Degree 4 nanothreads have a double bond remaining from benzene and thus only two bonds formed between each pair of benzene molecules. Degree 2 have two double bonds remaining. Unless otherwise specified the term nanothread is assumed to refer to a degree six structure.\n\nNMR has revealed that nanothread crystals consist of both degree 6 and degree 4 threads. Moreover, spin diffusion experiments show that the sections of the threads that are fully saturated degree 6 must be at least 2.5 nm long, if not longer. NMR also shows that no second hydrocarbon or carbon phase is present in nanothread crystals. Thus all of the sp carbon is either in degree 4 nanothreads or small amounts of aromatic linker molecules, or even smaller amounts of C=O groups. NMR provides the chemical structural information necessary to refine syntheses towards pure degree 6 nanothreads.\n\nPyridine compressed slowly under pressure forms carbon nitride CHN nanothread crystals. They exhibit the six-fold diffraction \"signature\" of nanothread formation. NMR, chemical analysis and infrared spectroscopy provide further evidence for the synthesis of nanothreads from pyridine. Pyridine nanothreads incorporate significant amounts of nitrogen directly into their backbone. In contrast sp2 carbon nanotubes can only be doped with a small amount of nitrogen. A wide range of other functionalized nanothreads may be possible.\n\nEvery type of nanothread has a very high Young's modulus (stiffness). The value for the strongest type of nanothread is around 900 GPa compared to steel at 200 GPa and diamond at over 1,200 GPa. The strength carbon nanothreads may rival or exceed that of carbon nanotubes (CNTs). Molecular dynamics simulations have indicated a stiffness on the order of carbon nanotubes (approx. 850 GPa) and a specific strength of approx. 4 × 10 N·m/kg.\n\nMuch as graphite exfoliates into sheets and ultimately graphene, nanothread crystals exfoliate into fibers, consistent with their structure consisting of stiff, straight threads with a persistence length of ~100 nm that are held together with van der Waals forces. These fibers exhibit birefringence, as would be expected from their low dimensional character. In contrast, most polymers are much more flexible and often fold into crystalline lamella (see Crystallization of polymers) rather than forming into crystals that readily exfoliate.\n\nModeling suggests certain nanothreads may be auxetic, with a negative Poisson ratio. The thermal conductivity of nanothreads has been modeled. Modeling indicates their Bandgaps are tunable with strain over a wide range.\n\nNanothreads can be thought of essentially as \"flexible diamond\". The extremely high specific strength predicted for them by modeling has attracted attention for applications such as space elevators and would be useful in other applications related to transportation, aerospace, and sports equipment. They may uniquely combine extreme strength, flexibility, and resilience. Chemically substituted nanothreads may facilitate load transfer between neighbors through covalent bonding to transfer their mechanical strength to a surrounding matrix. Modeling also suggests that the kinks associated with Stone-Wales transformations in nanothreads may facilitate interfacial load transfer to a surrounding matrix, making them useful for high strength composites. In contrast to carbon nanotubes, bonds to the exterior of nanothreads need not disrupt their carbon core because only three of the four tetrahedral bonds are needed form it. The “extra” bond usually formed to hydrogen could be instead be linked to another nanothread or another molecule or atom. Nanothreads may thus be thought of as \"hybrids\" that are both hydrocarbon molecules and carbon nanomaterials. Bonds to carbon nanotubes require their carbon to change from near planar sp-bonding to tetrahedral sp-bonding, thus disrupting their tubular geometry and possibly weakening them. Nanothreads may be less susceptible to loss of strength through defects than carbon nanotubes. Thus far the extreme strength predicted for carbon nanotubes has largely not been realized in practical applications because of issues with load transfer to the surroundings and defects at various length scales from that of atoms on up.\n\nExfoliation into individual nanothreads may be possible, facilitating further functionalization and assembly into functional materials.\n\nThe carbon core of nanothreads is very stiff relative to the backbone of conventional polymers. They should thus be able to precisely orient molecular functions attached along their length (by substitution of hydrogen) relative to each other and to heteoatoms or unsaturated bonds in their backbone. These features may enable biological applications, for example. Defects, functional groups, and/or heteroatoms incorporated either into or exterior to the backbone of nanothreads with controlled orientation and distance between them may allow for robust, well controlled fluorescence. Doping and incorporation of heteroatoms such as nitrogen or boron into the nanothread backbone may allow for enhanced conducting or semiconducting properties of nanothreads that allow for application as photocatalysts, electron emitters, or possibly superconductors.\n\nModeling suggests carbon nanothread resonators exhibit low dissipation and may be useful as chemical sensors that can detect very small mass changes.\n\n"}
{"id": "55428952", "url": "https://en.wikipedia.org/wiki?curid=55428952", "title": "Civil engineering database", "text": "Civil engineering database\n\nThe Civil Engineering Database (CEDB) was created in 1994, and is maintained by American Society of Civil Engineers (ASCE). It is a free bibliographic database for all ASCE publications including journals, conference proceedings, books, standards, manuals, magazines, and newspapers on all the disciplines of civil engineering. The coverage dates back to 1872. \n\nUsers will be directed to ASCE Library when full text (pdf) of the records are available. \n"}
{"id": "15663068", "url": "https://en.wikipedia.org/wiki?curid=15663068", "title": "Color chart", "text": "Color chart\n\nA color chart or color reference card is a flat, physical object that has many different color samples present. They can be available as a one-page chart, or in the form of swatchbooks or color-matching fans.\n\nTypically there are two different types of color charts:\n\nColor reference charts are used for color comparisons and measurements such as checking the color reproduction of an imaging system, and calibration and/or profiling of digital input devices such as digital cameras, and scanners and output display systems like printers, monitors and projectors. They are also used by traditional photographers and cinematographers to calibrate cameras that use film and to check the color temperature of the lighting.\n\nColor reference cards can also be used to assess light quality, as in the color rendering index, where reflectance from a set of Munsell samples are evaluated.\n\nShirley cards are color reference cards that are used to perform skin-color balance in still photography printing. The industry standard for these cards in North American photography labs in the 1940s and 1950s depicted a solitary \"Caucasian\" female dressed in brightly colored clothes. Very few of these color reference cards showed an adult male as the reference image. Light skin tones therefore served as the recognized skin ideal standard. Stock color film chemistry for still cameras was designed originally with a positive bias toward \"Caucasian\" skin tones because of its high level of reflectivity.\n\nBy the mid-1990s, Japanese companies redesigned their Shirley cards using data from their own color preference tests. The new reference card featured Japanese women with light yellow skin.\n\nIn 1995, Kodak designed a multiracial norm reference card. This card showed three women (Caucasian, Asian, African) with different skin colors and brightly contrasted clothing.\n\nA similar cinematic calibration technique is known as the China Girl.\n\nThe ColorChecker—first produced as the “Macbeth ColorChecker” in 1976—a cardboard-framed arrangement of twenty-four squares of painted samples based on Munsell colors. Its previous maker Gretag–Macbeth was acquired in 2006 by X-Rite.\nA ColorChecker chart can be used to manually adjust color parameters (e.g. color temperature) to achieve a desired color rendition. ColorChecker charts are available in different sizes and forms.\n\nStandardized IT8 charts (also called IT8 targets) are made by several companies including Coloraid.de, FujiFilm, Kodak, LaserSoft Imaging. Unlike ColorChecker charts, IT8 charts are supplied with measurement values and can be used to create ICC color profiles by software (e.g. for digital cameras) to create reproducible color management.\nColor charts can take custom forms, as for example the calibration target used by the Curiosity rover for its Mars Hand Lens Imager (MAHLI).\nBecause paints and inks depend for their color on pigments and dyes, a reference is needed to match specific combinations of coloring substances in a given matrix against the resulting color. One of the earliest attempts to achieve this goal was the 1692 manuscript Klaer Lightende Spiegel der Verfkonst. It presented a range of watercolor mixtures, but remained relatively unknown, because only one manuscript was produced. Due to the development of the paint and ink industry, the requirement for this kind of chart intensified, and a number of systems are now available, including:\n"}
{"id": "652102", "url": "https://en.wikipedia.org/wiki?curid=652102", "title": "Corner case", "text": "Corner case\n\nIn engineering, a corner case (or pathological case) involves a problem or situation that occurs only outside of normal operating parameters—specifically one that manifests itself when multiple environmental variables or conditions are simultaneously at extreme levels, even though each parameter is within the specified range for that parameter.\n\nFor example, a loudspeaker might distort audio, but only when played at maximum volume, maximum bass, and in a high-humidity environment. Or a computer server may be unreliable, but only with the maximum complement of 64 processors, 512 GB of memory, and 10,000 signed-on users.\n\nContrast a corner case with an edge case, the latter an issue that occurs only at a (single) maximum or minimum parameter. For example, a speaker may distort audio at maximum volume, even in the absence of other extreme settings or conditions.\n\nCorner cases form part of an engineer's lexicon—especially an engineer involved in testing or debugging a complex system. Corner cases are often harder and more expensive to reproduce, test, and optimize because they require maximal configurations in multiple dimensions. They are frequently less-tested, given the belief that few product users will, in practice, exercise the product at multiple simultaneous maximum settings. Expert users of systems therefore routinely find corner case anomalies, and in many of these, errors.\n\nThe term \"corner case\" comes about by physical analogy with \"edge case\" as an extension of the \"flight envelope\" metaphor to a set of testing conditions whose boundaries are determined by the 2 combinations of extreme (minimum and maximum) values for the number \"n\" of variables being tested, \"i.e.\", the total parameter space for those variables. Where an edge case involves pushing one variable to a minimum or maximum, putting users at the \"edge\" of the configuration space, a corner case involves doing so with multiple variables, which would put users at a \"corner\" of a multidimensional configuration space.\n\n"}
{"id": "56907580", "url": "https://en.wikipedia.org/wiki?curid=56907580", "title": "Department of Standards Malaysia", "text": "Department of Standards Malaysia\n\nThe Department of Standards Malaysia (Standards Malaysia) is the National Standards Body and the National Accreditation Body, providing confidence to various stakeholders, through credible standardisation and accreditation services for global competitiveness. Governed by the Standard of Malaysia Act 1996 (Act 549), the Department of Standard Malaysia (Standards Malaysia) is an agency established on 28 August 1996 under the purview of Ministry of Energy, Science, Technology, Environment and Climate Change (MESTECC). \n\n\nDevelop and promote Malaysia Standard (MS)\n\nAccredit conformity assessment bodies consist of testing and calibration labs, inspection bodies and certification bodies.\n\nList of accredited organisations under all accreditation schemes by Standards Malaysia\n\nMalaysia, through Standards Malaysia has been accepted as a signatory to various regional and international arrangements.At the regional level Standards Malaysia is a signatory to the Asia Pacific Laboratory Accreditation Cooperation Mutual Recognition Arrangement (APLAC MRA) and Pacific Accreditation Cooperation Multilateral Recognition Arrangement (PAC MLA). As for at the international level, Standards Malaysia is a signatory to the International Laboratory Accreditation Cooperation Mutual Recognition Arrangement (ILAC MRA) and International Accreditation Forum Multilateral Recognition Arrangement (IAF MLA).\n\n\nThe main functions of the MSAC are:\n\n\n"}
{"id": "27977967", "url": "https://en.wikipedia.org/wiki?curid=27977967", "title": "Don Dodge", "text": "Don Dodge\n\nDon Dodge (born 1957) is a Developer Advocate for Google, which requires that he helps developers build applications on the company's platforms. Prior to working at Google, Dodge was a start-up evangelist at Microsoft, where he was one of their most visible employees following Robert Scoble's departure in 2006.\n\nDodge received a bachelor of science from the University of Southern Maine, majoring in accounting. Afterward, he received an MBA from New Hampshire College (now Southern New Hampshire University). Following graduation, Dodge worked at a number of technology companies, including Digital Equipment, Forte Software, AltaVista, Napster, and Bowstreet. Afterward, he worked at Groove Networks. When the company was acquired by Microsoft, Dodge became Director of Business Development for Microsoft's Emerging Business Team. He was also known as a \"start-up evangelist\" for Microsoft. Focusing on the New England area and based in New Hampshire, Dodge often worked specifically with companies in the greater Boston area, to help them use Microsoft products for their companies. Dodge felt positively towards Ray Ozzie, CEO of Groove Networks, whom replaced Bill Gates as Chief Software Architect at Microsoft following Gates' retirement announcement. \n\nDodge was laid off from Microsoft on November 5, 2009, and then he became a Developer Advocate for Google, where he helps developers build applications on Google's platforms, as well as help venture capitalists and start-up companies work with Google. After moving to Google, Dodge switched from using a Windows-based computer to a Mac-based one, a move which he enjoys greatly. In 2010, Dodge compared Google to Microsoft when it was a ten-year-old company, indicating that it still had a lot of growth ahead of it. Dodge writes a personal blog called \"The Next Big Thing\".\n\n"}
{"id": "5256483", "url": "https://en.wikipedia.org/wiki?curid=5256483", "title": "Electromagnetic field solver", "text": "Electromagnetic field solver\n\nElectromagnetic field solvers (or sometimes just field solvers) are specialized programs that solve (a subset of) Maxwell's equations directly. They form a part of the field of electronic design automation, or EDA, and are commonly used in the design of integrated circuits and printed circuit boards. They are used when a solution from first principles is needed, or the highest accuracy is required.\n\nThe extraction of parasitic circuit models is important for various aspects of physical\nverification such as timing, signal integrity, substrate coupling, and power grid analysis. As circuit\nspeeds and densities have increased, the need has grown to account accurately for\nparasitic effects for larger and more complicated interconnect structures. In addition, the\nelectromagnetic complexity has grown as well, from resistance and capacitance, to inductance,\nand now even full electromagnetic wave propagation. This increase in complexity\nhas also grown for the analysis of passive devices such as integrated inductors.\nElectromagnetic behavior is governed by Maxwell's equations, and all parasitic extraction\nrequires solving some form of Maxwell's equations. That form may be a simple\nanalytic parallel plate capacitance equation, or may involve a full numerical solution for a\ncomplicated 3D geometry with wave propagation. In layout extraction,\nanalytic formulas for simple or simplified geometry can be used where\naccuracy is less important than speed, but when the geometric configuration is not simple\nand accuracy demands do not allow simplification, numerical solution of the appropriate\nform of Maxwell's equations must be employed.\n\nThe appropriate form of Maxwell's equations is typically solved by one of two classes\nof methods. The first uses a differential form of the governing equations and requires the\ndiscretization (meshing) of the entire domain in which the electromagnetic fields reside.\nTwo of the most common approaches in this first class are the finite difference (FD) and\nfinite element (FEM) method. The resultant linear algebraic system (matrix) that must\nbe solved is large but sparse (contains very few non-zero entries). Sparse linear solution\nmethods, such as sparse factorization, conjugate-gradient, or multigrid methods can be\nused to solve these systems, the best of which require CPU time and memory of O(N)\ntime, where N is the number of elements in the discretization. However most problems\nin electronic design automation (EDA) are open problems, also called exterior problems,\nand since the fields decrease slowly towards infinity, these methods can require extremely\nlarge N.\n\nThe second class of methods are integral equation methods which instead require a\ndiscretization of only the sources of electromagnetic field. Those sources can be physical\nquantities, such as the surface charge density for the capacitance problem, or mathematical\nabstractions resulting from the application of Green's theorem. When the sources exist\nonly on two-dimensional surfaces for three-dimensional problems, the method is often\ncalled a boundary element method (BEM). For open problems, the sources of the field\nexist in a much smaller domain than the fields themselves, and thus the size of linear\nsystems generated by integral equations methods are much smaller than FD or FEM.\nIntegral equation methods, however, generate dense (all entries are nonzero) linear systems\nwhich makes such methods preferable to FD or FEM only for small problems. Such\nsystems require \"O(n)\" memory to store and \"O(n)\" to solve via direct Gaussian elimination\nor at best \"O(n)\" if solved iteratively. Increasing circuit speeds and densities require\nthe solution of increasingly complicated interconnect, making dense integral equation approaches\nunsuitable due to these high growth rates of computational cost with increasing\nproblem size.\n\nIn the past two decades, much work has gone into improving both the differential and integral\nequation approaches, as well as new approaches based on random walk methods.\nMethods of truncating the discretization required by the FD and FEM approaches has\ngreatly reduced the number of elements required. Integral equation approaches\nhave become particularly popular for interconnect extraction due to sparsification techniques,\nalso sometimes called matrix compression, acceleration, or matrix-free techniques,\nwhich have brought nearly \"O(n)\" growth in storage and solution time to integral equation\nmethods\n\nIn the IC industry, sparsified integral equation techniques are typically used to\nsolve capacitance and inductance extraction problems. The random-walk methods have\nbecome quite mature for capacitance extraction. For problems requiring the solution of\nthe full Maxwell's equations (full-wave), both differential and integral equation approaches\nare common.\n\n\n"}
{"id": "8726682", "url": "https://en.wikipedia.org/wiki?curid=8726682", "title": "Etching (microfabrication)", "text": "Etching (microfabrication)\n\nEtching is used in microfabrication to chemically remove layers from the surface of a wafer during manufacturing. Etching is a critically important process module, and every wafer undergoes many etching steps before it is complete. \n\nFor many etch steps, part of the wafer is protected from the etchant by a \"masking\" material which resists etching. In some cases, the masking material is a photoresist which has been patterned using photolithography. Other situations require a more durable mask, such as silicon nitride.\n\nIf the etch is intended to make a cavity in a material, the depth of the cavity may be controlled approximately using the etching time and the known etch rate. More often, though, etching must entirely remove the top layer of a multilayer structure, without damaging the underlying or masking layers. The etching system's ability to do this depends on the ratio of etch rates in the two materials (\"selectivity\").\n\nSome etches undercut the masking layer and form cavities with sloping sidewalls. The distance of undercutting is called \"bias\". Etchants with large bias are called \"isotropic\", because they erode the substrate equally in all directions. Modern processes greatly prefer anisotropic etches, because they produce sharp, well-controlled features.\n\nThe two fundamental types of etchants are liquid-phase (\"wet\") and plasma-phase (\"dry\"). Each of these exists in several varieties.\n\nThe first etching processes used liquid-phase (\"wet\") etchants. The wafer can be immersed in a bath of etchant, which must be agitated to achieve good process control. For instance, buffered hydrofluoric acid (BHF) is used commonly to etch silicon dioxide over a silicon substrate. \n\nDifferent specialised etchants can be used to characterise the surface etched.\n\nWet etchants are usually isotropic, which leads to large bias when etching thick films. They also require the disposal of large amounts of toxic waste. For these reasons, they are seldom used in state-of-the-art processes. However, the photographic developer used for photoresist resembles wet etching.\n\nAs an alternative to immersion, single wafer machines use the Bernoulli principle to employ a gas (usually, pure nitrogen) to cushion and protect one side of the wafer while etchant is applied to the other side. It can be done to either the front side or back side. The etch chemistry is dispensed on the top side when in the machine and the bottom side is not affected. This etch method is particularly effective just before \"backend\" processing (BEOL), where wafers are normally very much thinner after wafer backgrinding, and very sensitive to thermal or mechanical stress. Etching a thin layer of even a few micrometres will remove microcracks produced during backgrinding resulting in the wafer having dramatically increased strength and flexibility without breaking.\n\nSome wet etchants etch crystalline materials at very different rates depending upon which crystal face is exposed. In single-crystal materials (e.g. silicon wafers), this effect can allow very high anisotropy, as shown in the figure. The term \"crystallographic etching\" is synonymous with \"anisotropic etching along crystal planes\". \n\nHowever, for some non-crystal materials like glass, there are unconventional ways to etch in an anisotropic manner. The authors employs multistream laminar flow that contains etching non-etching solutions to fabricate a glass groove. The etching solution at the center is flanked by non-etching solutions and the area contacting etching solutions is limited by the surrounding non-etching solutions. Thereby, the direction of etching is mainly vertical to the surface of glass. The SEM images demonstrate the breaking of conventional theoretical limit of aspect ratio (width/height=0.5) and contribute a two-fold improvement (width/height=1).\n\nSeveral anisotropic wet etchants are available for silicon, all of them hot aqueous caustics. For instance, potassium hydroxide (KOH) displays an etch rate selectivity 400 times higher in <100> crystal directions than in <111> directions. EDP (an aqueous solution of ethylene diamine and pyrocatechol), displays a <100>/<111> selectivity of 17X, does not etch silicon dioxide as KOH does, and also displays high selectivity between lightly doped and heavily boron-doped (p-type) silicon. Use of these etchants on wafers that already contain CMOS integrated circuits requires protecting the circuitry. KOH may introduce mobile potassium ions into silicon dioxide, and EDP is highly corrosive and carcinogenic, so care is required in their use. Tetramethylammonium hydroxide (TMAH) presents a safer alternative than EDP, with a 37X selectivity between {100} and {111} planes in silicon.\n\nEtching a (100) silicon surface through a rectangular hole in a masking material, for example a hole in a layer of silicon nitride, creates a pit with flat sloping {111}-oriented sidewalls and a flat (100)-oriented bottom. The {111}-oriented sidewalls have an angle to the surface of the wafer of:\n\nIf the etching is continued \"to completion\", i.e. until the flat bottom disappears, the pit becomes a trench with a V-shaped cross section. If the original rectangle was a perfect square, the pit when etched to completion displays a pyramidal shape.\n\nThe undercut, \"δ\", under an edge of the masking material is given by:\n\nwhere \"R\" is the etch rate in the <xxx> direction, \"T\" is the etch time, \"D\" is the etch depth and \"S\" is the anisotropy of the material and etchant.\n\nDifferent etchants have different anisotropies. Below is a table of common anisotropic etchants for silicon:\n\nModern VLSI processes avoid wet etching, and use \"plasma etching\" instead. Plasma etchers can operate in several modes by adjusting the parameters of the plasma. Ordinary plasma etching operates between 0.1 and 5 Torr. (This unit of pressure, commonly used in vacuum engineering, equals approximately 133.3 pascals.) The plasma produces energetic free radicals, neutrally charged, that react at the surface of the wafer. Since neutral particles attack the wafer from all angles, this process is isotropic.\n\nPlasma etching can be isotropic, i.e., exhibiting a lateral undercut rate on a patterned surface approximately the same as its downward etch rate, or can be anisotropic, i.e., exhibiting a smaller lateral undercut rate than its downward etch rate. Such anisotropy is maximized in deep reactive ion etching. The use of the term anisotropy for plasma etching should not be conflated with the use of the same term when referring to orientation-dependent etching.\n\nThe source gas for the plasma usually contains small molecules rich in chlorine or fluorine. For instance, carbon tetrachloride (CCl) etches silicon and aluminium, and trifluoromethane etches silicon dioxide and silicon nitride. A plasma containing oxygen is used to oxidize (\"ash\") photoresist and facilitate its removal.\n\n\"Ion milling\", or \"sputter etching\", uses lower pressures, often as low as 10 Torr (10 mPa). It bombards the wafer with energetic ions of noble gases, often Ar, which knock atoms from the substrate by transferring momentum. Because the etching is performed by ions, which approach the wafer approximately from one direction, this process is highly anisotropic. On the other hand, it tends to display poor selectivity. \"Reactive-ion etching\" (RIE) operates under conditions intermediate between sputter and plasma etching (between 10 and 10 Torr). \"Deep reactive-ion etching\" (DRIE) modifies the RIE technique to produce deep, narrow features.\n\n\n"}
{"id": "20723955", "url": "https://en.wikipedia.org/wiki?curid=20723955", "title": "Flight envelope protection", "text": "Flight envelope protection\n\nFlight envelope protection is a human machine interface extension of an aircraft’s control system that prevents the pilot of an aircraft from making control commands that would force the aircraft to exceed its structural and aerodynamic operating limits. It is used in some form in all modern commercial fly-by-wire aircraft. The professed advantage of flight envelope protection systems is that they restrict a pilot's excessive control inputs, whether in surprise reaction to emergencies or otherwise, from translating into excessive flight control surface movements. Notionally, this allows pilots to react quickly to an emergency while blunting the effect of an excessive control input resulting from \"startle,\" by electronically limiting excessive control surface movements that could over-stress the airframe and endanger the safety of the aircraft. In practice, these limitations have sometimes resulted in unintended human factors errors and accidents of their own.\n\nAircraft have a flight envelope that describes its safe performance limits in regard to such things as minimum and maximum operating speeds, and its operating structural strength. Flight envelope protection calculates that flight envelope (and adds a margin of safety) and uses this information to stop pilots from making control inputs that would put the aircraft outside that flight envelope. For example, if the pilot uses the rearward side-stick to pitch the aircraft nose up, the control computers creating the flight envelope protection will prevent the pilot pitching the aircraft beyond the stalling angle of attack. As a result, even if the pilot tried to apply more and more if rearward control, the flight envelope protection would cause the aircraft to ignore this command. Flight envelope protection can in this way increase aircraft safety by allowing the pilot to apply in an emergency maximum control forces while not at the same time inadvertently putting the aircraft outside the margins of its operational safety.\n\nExamples of where this might stop air accidents are when it allows a pilot to make a quick evasive maneuver in response to a ground proximity warning system warning, or in quick response to an approaching aircraft and a potential mid air collision. In this case without a flight envelope protection system, \"you would probably hold back from maneuvering as hard as you could for fear of tumbling out of control, or worse. You would have to sneak up on it [2.5 G, the design limit], and when you got there you wouldn't be able to tell, because very few commercial pilots have ever flown 2.5 G. But in the A320, you wouldn't have to hesitate: you could just slam the controller all the way to the side and instantly get out of there as fast as the plane will take you.\" Thus the makers of the Airbus argue: \"envelope protection doesn't constrain the pilot. It liberates the pilot from uncertainty-and thus enhances safety.\"\n\nThe Airbus A320 was the first commercial aircraft to incorporate full flight-envelope protection into its flight-control software. This was instigated by former Airbus senior vice president for engineering Bernard Ziegler. In the Airbus, the flight envelope protection cannot be overridden completely, although the crew can fly beyond flight envelope limits by selecting an alternate \"control law\". Boeing in the Boeing 777 has taken a different approach by allowing the crew to override flight envelope limits using excessive force on the flight controls.\n\nOne objection raised against flight envelope protection is the incident that happened to China Airlines Flight 006, a Boeing 747SP-09, northwest of San Francisco in 1985. In this flight incident, the crew was forced to overstress (and structurally damage) the horizontal tail surfaces in order to recover from a roll and near-vertical dive. (This had been caused by an automatic disconnect of the autopilot and incorrect handling of a yaw brought about by an engine flame-out). The pilot recovered control with about 10,000 ft of altitude remaining (from its original high-altitude cruise). But to do that the pilot had to pull the aircraft with an estimated 5.5 G, or more than twice its design limits. If the aircraft had a flight envelope protection system, this recovery could not have been performed. Against this objection, Airbus has responded that an A320 in the situation of Flight 006 \"never would have fallen out of the air\nin the first place: the envelope protection would have automatically kept it in level flight in spite of the drag of a stalled engine\".\n\nFedEx Flight 705, a McDonnell Douglas DC-10-30, was a case of a FedEx Flight Engineer who, facing a dismissal, attempted to hijack the plane and crash it into FedEx Headquarters in order for his family to collect his life insurance policy. After being attacked and severely injured, the flight crew was able to fight back and land the plane safely. In order to keep the attacker off balance and out of the cockpit the crew had to perform extreme maneuvers, including a barrel roll and a dive so fast the airplane couldn't measure its speed. Had the crew not been able to exceed the plane's flight envelope, the crew might not have been successful .\n\nAmerican Airlines Flight 587, an Airbus A300, crashed when the vertical stabiliser broke off due to large rudder inputs by the pilot. A flight-envelope protection system could have prevented this crash, though it can still be argued that an override button should be provided for contingencies when the pilots are aware of the need to exceed normal limits.\n\nUS Airways Flight 1549, an Airbus A320, experienced a dual engine failure after a bird strike and subsequently landed safely in the Hudson River. The NTSB accident report mentions the effect of flight envelope protection: \"The airplane’s airspeed in the last 150 feet of the descent was low enough to activate the alpha-protection mode of the airplane’s fly-by-wire envelope protection features... Because of these features, the airplane could not reach the maximum AOA attainable in pitch normal law for the airplane weight and configuration; however, the airplane did provide maximum performance for the weight and configuration at that time... The flight envelope protections allowed the captain to pull full aft on the sidestick without the risk of stalling the airplane.\"\n\nAir France Flight 447, an Airbus A330, entered an aerodynamic stall from which it did not recover and crashed into the Atlantic Ocean killing all aboard.\nTemporary inconsistency between measured speeds, likely a result of the obstruction of the pitot tubes by ice crystals, caused autopilot disconnection and reconfiguration to alternate law; \nA second consequence of the reconfiguration into alternate law was that stall protection no longer operated. The crew made inappropriate control inputs that caused the aircraft to stall and did not recognize that the aircraft had stalled.\n\n"}
{"id": "51172323", "url": "https://en.wikipedia.org/wiki?curid=51172323", "title": "Gate checking", "text": "Gate checking\n\nGate checking refers to the practice that allows passengers check in their bags directly at the gate. Gate checking is mostly used on small planes when there isn’t enough space to take on board the cabin bags of all passengers.\n\nSome companies offer different incentives for passengers who volunteer to check their bags at the gate instead of taking them on board. Virgin America offered free early boarding to its passengers who offer to gate check their carry-ons.\n\nAirline Policies do not allow strollers on board. Passengers travelling with young children can check in their strollers at the gate, free of charge. For each child, airlines allow passengers to check in a stroller and a car seat. Most companies recommend small umbrella-type strollers that fold and many of them have size and weight limits. Almost all airlines return the strollers to the jet bridge upon arriving at destination.\n\nSome companies, such as United Airlines, Jet Blue, Southwest Airlines, assume no liability for any damage produced to gate-checked strollers. For this reason, it is recommended that passengers use Gate Check Bags for strollers and car seats.\n"}
{"id": "7699925", "url": "https://en.wikipedia.org/wiki?curid=7699925", "title": "Global Harmonization Task Force", "text": "Global Harmonization Task Force\n\nThe Global Harmonization Task Force (GHTF) was “a voluntary group of representatives from national medical device regulatory authorities (such as the U.S. Food and Drug Administration (FDA)) and the members of the medical device industry” whose goal was the standardization of medical device regulation across the world. The representatives from its five founding members (the European Union, the United States, Canada, Japan and Australia) were divided into three geographical areas: Europe, Asia-Pacific and North America, each of which actively regulates medical devices using their own unique regulatory framework. Founded in 1992, the GHTF was created in “an effort to respond to the growing need for international harmonization in the regulation of medical devices.\"\n\nThe GHTF disbanded late in 2012. Its mission has been taken over by the International Medical Device Regulators Forum (IMDRF), a successor organization composed of officials from regulatory agencies— not industry — around the world. The GHTF website is no longer operational.\n\nAs quoted from the GHTF site now (IMDRF), “The purpose of the GHTF is to encourage the convergence in regulatory practices related to ensuring the safety, effectiveness/performance and quality of medical devices, promoting technological innovation and facilitating international trade, and the primary way in which this is accomplished is via the publication and dissemination of harmonized guidance documents on basic regulatory practices. These documents, which are developed by four different GHTF Study Groups, can then be adopted/implemented by member national regulatory authorities.\n\nThe GHTF also serves as an information exchange forum through which countries with medical device regulatory systems under development can benefit from the experience of those with existing systems and/or pattern their practices upon those of GHTF Founding Members.”\n\nStated succinctly, the organization aims to standardize medical device regulations around the world by exchange of information.\n\nThe founding members consist of regulatory authorities or industry members from the EU, the United States, Japan, Australia and Canada because of their well established and high standards in medical device regulations. Members also participate in the steering committee, which can recommend the inclusion of other participants in Study Groups to be a part of all GHTF activities.\n\nParticipating members consist of representatives from regulatory agencies or medical device trade associations not a part of the founding members. Participating members are to facilitate the adoption of as much of the GHTF’s policies in their region/agency as possible within legal parameters. Participating members can also take part in Study Groups as well as other expert working groups.\n\nLiaison bodies are public health organizations, international standard-setting bodies or other groups who can contribute to or benefit from participation in GHTF. Liaison Bodies are encouraged to promote GHTF guidelines to their members and incorporate them into their work. Liaison bodies are permitted to nominate observers for GHTF Study Groups and other expert working groups.\n\nObservers must be nominated by members and approved by the Study Group Chair. The level of participation that an Observer is granted is also decided by the Study Group Chair.\n\nThe purpose of the Steering Committee is to provide policy and direction for the GHTF. It is responsible for the assignment and oversight of new work items, adopt and monitor GHTF guidance documents and the authorization and promotion of GHTF training events.\n\nThe Steering Committee members consist of up to 8 members from each of the Founding Members’ regions. Of the 8 members, up to 4 may be from the regulatory sectors and up to 4 from the industry sectors. The Chain and Vice Chair members of the controlling region are not to be included in this number.\n\nThere are five study groups in the GHTF, each with a different focus. The size of each Study Group is to be determined by the Study Group Chair. Recommended members include one participant from each region with founding member status as well as appropriate numbers from regulatory agencies and industry technical experts.\n\nStudy Group 1 is concerned with the current medical device regulatory systems. From examining the current field, the group isolates the principles suitable for harmonization as well as those that pose a threat to harmonization. The Group also deals with the standardization of pre-market submissions and product labeling.\n\nExamples of documents put out by Study Group 1 include Principles of Medical Devices Classification, and Labeling for Medical Devices.\n\nStudy Group 2 is concerned with medical device vigilance such as medical device reporting and post market surveillance. The Group is designed to harmonize the data collection and reporting systems of the industry.\nExamples of documents put out by Study Group 2 include Medical Devices Post Market Surveillance: Content of Field Safety Notices, Manufacturer's Trend Reporting of Adverse Events and National Competent Authority Report Exchange Criteria including reference to the use of the GMDN.\n\nStudy Group 3 is concerned with examining and harmonizing current quality systems requirements.\nExamples of documents put out by Study Group 3 include Implementation of Risk Management Principles and Activities Within a Quality Management System and Quality Management Systems - Process Validation Guidance.\n\nStudy Group 4 is concerned with examining current quality systems auditing practices and the harmonization of the auditing process.\nExamples of documents put out by Study Group 4 include Training Requirements for Auditors and Guidelines for Regulatory Auditing of Quality Management.\n\nStudy Group 5 is concerned with the convergence of clinical practices. This includes the harmonization of clinical terms, reports and evaluations.\nStudy Group 5 has yet to produce any final documents, but areas of proposed topics include Clinical Evaluation and Clinical Evidence.\n\nThe Study Group Chair member is appointed for a three-year term by the Steering Committee. Upon completion of the term, the Chair is re-evaluated by the Steering Committee based on the needs of the Study Group. The support of a Vice Chair member usually consists of a member from the industry in a different region from the Chair.\n\n\n"}
{"id": "44952824", "url": "https://en.wikipedia.org/wiki?curid=44952824", "title": "Gogoro", "text": "Gogoro\n\nGogoro is a Taiwan-based venture-backed company that develops and sells electric scooters and battery swapping infrastructure.\n\nGogoro was founded in 2011 by Horace Luke and Matt Taylor. In its year of inception, Gogoro secured $50 million in seed funding from Dr. Samuel Yin of Ruentex Group and Cher Wang. In October 2014, Gogoro raised an additional $100 million in Series B funding from a collection of investors. In November 2015, Gogoro announced a $30 million round of investment from Panasonic and Taiwan's National Development Fund. In September 2017, Gogoro announced a $300 million Series C round of investment from Singapore's Temasek, Generation Investment Management, co-founded by Al Gore, Japan's Sumitomo Corporation, and French utility Engie, increasing the Smartscooter innovator's capital up to US $480 million.\n\nGogoro Smartscooter, the first consumer product from Gogoro, was revealed at the Consumer Electronics Show (CES) in Las Vegas in January 2015. Along with the scooter, Gogoro announced a battery-swapping network under the name Gogoro Energy Network.\n\nThe Gogoro Smartscooter is an electric scooter designed for urban transportation. It's powered by an electric motor developed by Gogoro, which is marketed as the G1 Aluminum Liquid Cooled Permanent Magnet Synchronous Motor. Instead of plugging into an outlet to recharge, the Smartscooter runs on swappable Panasonic lithium ion 18650 batteries.\n\nThe company states the following figures for the Smartscooter based on internal testing:\n\n\nThe Smartscooter's sensors collect information such as speed, battery level, consumption rate, system failures, and scooter falls. This information is presented to riders via Gogoro mobile apps.\n\nThe Gogoro Energy Network is a modular battery swapping infrastructure designed to be deployed across an urban region. Riders would be able to swap out depleted batteries at a network of kiosks called GoStations for a monthly subscription fee. The Smartscooter is the first vehicle to be integrated into the Gogoro Energy Network.\n\nIn July 2015, Gogoro Smartscooter was launched in Taiwan, a country with the highest scooter density in the world. By the end of the same year, more than 4,000 Smartscooters were sold and its market share in Taiwan's electric scooter market hit 33.94%. According to Gogoro, the company now has a GoStation less than every 1.3 kilometers in Taipei.\n\nGogoro has announced the following strategic partnerships: \n\n\n"}
{"id": "30860855", "url": "https://en.wikipedia.org/wiki?curid=30860855", "title": "Hurricane-proof building", "text": "Hurricane-proof building\n\nTornadoes, cyclones, and other storms with strong winds damage or destroy many buildings. However, with proper design and construction, the damage to buildings by these forces can be greatly reduced. A variety of methods can help a building survive strong winds and storm surge.\n\nWaves along coastal areas can destroy many buildings. Buildings should preferably be built on high ground in order to avoid waves. If waves can reach the building site, the building ought to be elevated on steel, concrete, or wooden pilings or anchored to solid rock.\n\nWind acting on the roof surfaces of a building can cause negative pressures that create a lifting force sufficient to lift the roof off the building. Once this occurs, the building is weakened considerably and the rest of the building will likely fail as well. To minimize this vulnerability, the upper structure ought to be anchored through the walls to the foundation.\n\nSeveral methods can be used to anchor the roof. Typically, roof trusses are \"toenailed\" into the top of the walls, which provide insufficient force to resist high winds. Hurricane ties nail into the wall and wrap over the trusses provide higher force resistance.\n\nInterlocking metal pan roof systems installed on mobile homes can fail under the pressure differential (lift) created by the high velocity winds passing over the surface plane of the roof. This is compounded by the wind entering the building allowing the building interior to pressurize lifting the underside of the roof panels, resulting in destruction of the building. One example of pan roof systems can be found in this document from Structall Building Systems.\n\nTo mitigate this pressure differential, pre-installed aluminum tabular channels can permanently be fastened perpendicularly across the top of the interlocking ribs of the metal roof system without disturbing the flow of rainwater at the eaves, mid-span, and ridge locations of the building.\n\nEarth-sheltered construction is generally more resistant to strong winds and tornadoes than standard construction. Cellars and other earth sheltered components of other buildings, can provide safe refuge during tornadoes.\n\nThe physical geometry of a building affects its aerodynamic properties and how well it can withstand a storm. Geodesic dome roofs or buildings have low drag coefficients and can withstand higher wind forces than a square building of the same area. Even stronger buildings result from monolithic dome construction.\n\nA CAT 5 hurricane-proof log house is resistant to the winds up to 245 mph. Wall logs in such construction have to be made of glued laminated timber and all other components of the house have to be hurricane-resistant.\n\nBuilding openings such as garage doors and windows are often weak points susceptible to failure by wind pressure and blowing debris. Once failure occurs, wind pressure builds up inside the building resulting in the roof lifting off the building. Hurricane shutters can provide protection.\n\nDoors can be blown into the house by wind, causing potential structural failure (see http://www.floridadisaster.org/hrg/content/openings/openings_index.asp#Hinged_Exterior_Doors).\n\nWindows can be constructed with plastic panes, shatterproof glass, or glass with protective membranes. The panes are often more firmly attached than normal window panes, including using screws or bolts through the edges of larger panes. Tapcons are used to fasten windows with the concrete structure surrounding.\n\nWood has a relatively high degree of flexibility, which can be beneficial under certain building stresses.\n\nReinforced concrete is a strong, dense material that, if used in a building that is designed properly, can withstand the destructive power of very high winds, and high-speed debris.\n\nAfter Hurricane Andrew in 1992 caused $16 billion in insured damage, the state of Florida established new building standards and enforcement. The state increased performance criteria for wind-load provisions and adopted new wind provisions from the American Society of Civil Engineers. One important addition included with the new code was the requirement of missile-impact resisting glass, which can withstand high velocity impact from wind-borne debris during a hurricane. Many houses built in South Florida since Hurricane Andrew are cinder block masonry construction reinforced with concrete pillars, hurricane-strapped roof trusses, and codes requirements for adhesives and types of roofing. Florida also designated high velocity hurricane zones (i.e. High Velocity Hurricane Zone) with special requirements defined for Miami-Dade and Broward Counties.\n\nHong Kong requires many structures to withstand winds from typhoons.\n\nResidential construction in Darwin Northern Australia\n\n\nNotes\n"}
{"id": "368327", "url": "https://en.wikipedia.org/wiki?curid=368327", "title": "Identification friend or foe", "text": "Identification friend or foe\n\nIdentification, friend or foe (IFF) is an identification system designed for command and control. It enables military and civilian air traffic control interrogation systems to identify aircraft, vehicles or forces as friendly and to determine their bearing and range from the interrogator. IFF may be used by both military and civilian aircraft. IFF was first developed during the Second World War, with the arrival of radar, and several infamous friendly fire incidents.\n\nDespite the name, IFF can only positively identify friendly targets, not hostile ones. If an IFF interrogation receives no reply or an invalid reply, the object cannot be identified as friendly, but is not positively identified as foe (it may, for instance, be a friendly aircraft with an inoperative or malfunctioning transponder). There are in addition many reasons that friendly aircraft may not properly reply to IFF.\n\nIFF is a tool within the broader military action of Combat Identification (CID), \"the process of attaining an accurate characterization of detected objects in the operational environment sufficient to support an engagement decision.\" The broadest characterization is that of friend, enemy, neutral, or unknown. CID not only can reduce friendly fire incidents, but also contributes to overall tactical decision-making.\n\nWith the successful deployment of radar systems for air defence during World War II, combatants were immediately confronted with the difficulty of distinguishing friendly aircraft from hostile ones; by that time, aircraft were flown at high speed and altitude, making visual identification impossible, and the targets showed up as featureless blips on the radar screen.\nThis led to incidents such as the \"Battle of Barking Creek\", over Britain,\nand the \"air attack on the fortress of Koepenick\", over Germany.\n\nAlready before the deployment of their Chain Home radar system (CH), the RAF had considered the problem of IFF. Robert Watson-Watt had filed patents on such systems in 1935 and 1936. By 1938, researchers at Bawdsey Manor began experiments with \"reflectors\" consisting of dipole antennas tuned to resonate to the primary frequency of the CH radars. When a pulse from the CH transmitter hit the aircraft, the antennas would resonate for a short time, increasing the amount of energy returned to the CH receiver. The antenna was connected to a motorized switch that periodically shorted it out, preventing it from producing a signal. This caused the return on the CH set to periodically lengthen and shorten as the antenna was turned on and off. In practice, the system was found to be too unreliable to use; the return was highly dependent on the direction the aircraft was moving relative to the CH station, and often returned little or no additional signal.\n\nIt had been suspected this system would be of little use in practice. When that turned out to be the case, the RAF turned to an entirely different system that was also being planned. This consisted of a set of tracking stations using HF/DF radio direction finders. Their aircraft radios were modified to send out a 1 kHz tone for 14 seconds every minute, allowing the stations ample time to measure the aircraft's bearing. Several such stations were assigned to each \"sector\" of the air defence system, and sent their measurements to a plotting station at sector headquarters, who used triangulation to determine the aircraft's location. Known as \"pip-squeak\", the system worked, but was labour-intensive and did not display its information directly to the radar operators. A system that worked directly with the radar was clearly desirable.\n\nThe first active IFF transponder (transmitter/responder) was the IFF Mark I which was used experimentally in 1939. This used a regenerative receiver, which fed a small amount of the amplified output back into the input, strongly amplifying even small signals as long as they were of a single frequency (like Morse code, but unlike voice transmissions). They were turned to the signal from the CH radar (20–30 MHz), amplifying it so strongly that it was broadcast back out the aircraft's antenna. Since the signal was received at the same time as the original reflection of the CH signal, the result was a lengthened \"blip\" on the CH display which was easily identifiable. In testing, it was found that the unit would often overpower the radar or produce too little signal to be seen, and at the same time, new radars were being introduced using new frequencies.\n\nInstead of putting Mark I into production, a new IFF Mark II was introduced in early 1940. Mark II had a series of separate tuners inside tuned to different radar bands that it stepped through using a motorized switch, while an automatic gain control solved the problem of it sending out too much signal. Mark II was technically complete as the war began, but a lack of sets meant it was not available in quantity and only a small number of RAF aircraft carried it by the time of the Battle of Britain. Pip-squeak was kept in operation during this period, but as the Battle ended, IFF Mark II was quickly put into full operation. Pip-squeak was still used for areas over land where CH did not cover, as well as an emergency guidance system.\n\nEven by 1940 the complex system of Mark II was reaching its limits while new radars were being constantly introduced. By 1941, a number of sub-models were introduced that covered different combinations of radars, common naval ones for instance, or those used by the RAF. But the introduction of radars based on the microwave-frequency cavity magnetron rendered this obsolete; there was simply no way to make a responder operating in this band using contemporary electronics.\n\nIn 1940, English engineer Freddie Williams had suggested using a single separate frequency for all IFF signals, but at the time there seemed no pressing need to change the existing system. With the introduction of the magnetron, work on this concept began at the Telecommunications Research Establishment as the IFF Mark III. This was to become the standard for the Western Allies for most of the war.\n\nMark III transponders were designed to respond to specific 'interrogators', rather than replying directly to received radar signals. These interrogators worked on a limited selection of frequencies, no matter what radar they were paired with. The system also allowed limited communication to be made, including the ability to transmit a coded 'Mayday' response. The IFF sets were designed and built by Ferranti in Manchester to Williams' specifications. Equivalent sets were manufactured in the US, initially as copies of British sets, so that allied aircraft would be identified upon interrogation by each other's radar.\n\nIFF sets were obviously highly classified. Thus, many of them were wired with explosives in the event the aircrew bailed out or crash landed. Jerry Proc reports: \n\n\"Alongside the switch to turn on the unit was the IFF destruct switch to prevent its capture by the enemy. Many a pilot chose the wrong switch and blew up his IFF unit. The thud of a contained explosion and the acrid smell of burning insulation in the cockpit did not deter many pilots from destroying IFF units time and time again. Eventually, the self destruct switch was secured by a thin wire to prevent its accidental use.\"\n\nFuG 25a \"Erstling\" (English: Firstborn, Debut) was developed in Germany in 1940. It had two bands tuned to the low-VHF band at 125 MHz used by the Freya radar and the low-UHF-banded 550–580 MHz used by Würzburg). Before flight, the transceiver was set up with a selected day code of ten bits which was dialled into the unit. To start the identification procedure, the ground operator switched the pulse frequency of his radar from 3,750 Hz to 5,000 Hz. The airborne receiver decoded that and started to transmit the day code. The radar operator would then see the blip lengthen and shorten in the given code, ensuring it was not being spoofed. The IFF transmitter worked on 168 MHz with a power of 400 watts (PEP).\n\nThe system included a way for ground controllers to determine whether an aircraft had the right code or not but it did not include a way for the transponder to reject signals from other sources. British military scientists found a way of exploiting this by building their own IFF transmitter called \"Perfectos\", which were designed to trigger a response from any FuG 25a system in the vicinity. When an FuG 25a responded on its 168 MHz frequency, the signal was received by the antenna system from an AI Mk. IV radar, which originally operated at 212 MHz. By comparing the strength of the signal on different antennas the direction to the target could be determined. Mounted on Mosquitos, the \"Perfectos\" severely limited German use of the FuG 25a.\n\nThe United States Naval Research Laboratory had been working on their own IFF system since before the war. It used a single interrogation frequency, like the Mark III and a separate responder frequency. Responding on a different frequency has several practical advantages but requires a transmitter for the responder side of the circuitry, in contrast to the greatly simplified system used in the British designs. This technique is now known as a cross-band transponder. When the Mark II was revealed in 1941 during the Tizard Mission, it was decided to use it and take the time to further improve their experimental system. The result was what became the Mark IV. The main difference between this and earlier models is that it worked on higher frequencies, around 600 MHz, which allowed much smaller antennas. Unfortunately, this also turned out to be close to the frequencies used by the German Würzburg radar and there were concerns that it would be triggered by that radar and the transponder responses would be picked on its radar display and thereby give away the operational frequencies. This led to a US–British effort to make a further improved model, the Mark V, also known as the United Nations Beacon or UNB. This moved to still higher frequencies around 1 GHz but operational testing was not complete when the war ended. By the time testing was finished in 1948, the much improved Mark X was beginning its testing and Mark V was abandoned.\n\nMark X started as a purely experimental device operating at frequencies above 1 GHz, but as development continued it was decided to introduce an encoding system known as the \"Selective Identification Feature\", or SIF. SIF allowed the return signal to contain up to 12 pulses, representing four octal digits of 3 bits each. Depending on the timing of the interrogation signal, SIF would respond in several ways. Mode 1 indicated the type of aircraft or its mission (cargo, for instance) while Mode 2 returned a tail code.\n\nMark X began to be introduced in the early 1950s. This was during a period of great expansion of the civilian air transport system, and it was decided to use slightly modified Mark X sets for these aircraft as well. These sets included a new Mode 3 which was paired with a civilian Mode A, which operated similar to the original Mode 2 and returned a four-digit identifier. Because Mode 3 and A are identical, they are normally referred to as Mode 3/A. Mode C returned the altitude encoded in a single 12-bit number in Gillham code, which represented the altitude as (that number) x 100 feet - 1200. Mode B and D were specified but never used.\n\nThe current IFF system is the Mark XII. This works on the same frequencies as Mark X, and supports all of its military and civilian modes.\n\nThe main reason for the creation of Mark XII was the addition of the military Mode 4. Before Mark XII, the transponders would respond to any properly formed interrogation signal, broadcasting a reply that could be picked up by any receiver. Using triangulation, an enemy could determine the location of the transponder. The British had already used this during WWII, and it was used by the USAF against VPAF aircraft during the Vietnam War.\n\nMode 4 started with an interrogation similar to Mode 3, but then followed that with an encoded pulse chain similar to the one used in Mode 3/A. The receiver side of the transponder checks this code against a known day code, and only responds if the two match. The pulses in the reply are delayed based on the received code. This largely eliminates the ability for the enemy to trigger the transponder.\n\nDuring the 1980s, a new civilian mode, Mode S, was added that allowed greatly increased amounts of data to be encoded in the returned signal. This was used to encode the location of the aircraft from the navigation system. This is a basic part of the traffic collision avoidance system (TCAS) system that allows commercial aircraft to know the location of other aircraft in the area and avoid them without the need for ground operators.\n\nThe basic concepts from Mode S were then militarized as Mode 5, which is simply a cryptographically encoded version of the Mode S data.\n\nThe IFF of World War II and Soviet military systems (1946 to 1991) used coded radar signals (called Cross-Band Interrogation, or CBI) to automatically trigger the aircraft's transponder in an aircraft illuminated by the radar. Radar-based aircraft identification is also called secondary radar in both military and civil usage, with primary radar bouncing an RF pulse off of the aircraft to determine position. George Charrier, working for RCA, filed for a patent for such an IFF device in 1941. It required the operator to perform several adjustments to the radar receiver to suppress the image of the natural echo on the radar receiver, so that visual examination of the IFF signal would be possible.\n\nBy 1943, Donald Barchok filed a patent for a radar system using the acronym IFF in his text with only parenthetic explanation, indicating that this acronym had become an accepted term. In 1945, Emile Labin and Edwin Turner filed patents for radar IFF systems where the outgoing radar signal and the transponder's reply signal could each be independently programmed with a binary codes by setting arrays of toggle switches; this allowed the IFF code to be varied from day to day or even hour to hour.\n\nThe United States and other NATO countries started using a system called Mark XII in the late twentieth century; Britain had not until then implemented an IFF system compatible with that standard, but then developed a program for a compatible system known as successor IFF (SIFF).\n\n\nModes 4 and 5 are designated for use by NATO forces.\n\n\n"}
{"id": "317625", "url": "https://en.wikipedia.org/wiki?curid=317625", "title": "Image scanner", "text": "Image scanner\n\nAn image scanner—often abbreviated to just scanner, although the term is ambiguous out of context (barcode scanner, CT scanner etc.)—is a device that optically scans images, printed text, handwriting or an object and converts it to a digital image. Commonly used in offices are variations of the desktop \"flatbed scanner\" where the document is placed on a glass window for scanning. \"Hand-held scanners\", where the device is moved by hand, have evolved from text scanning \"wands\" to 3D scanners used for industrial design, reverse engineering, test and measurement, orthotics, gaming and other applications. Mechanically driven scanners that move the document are typically used for large-format documents, where a flatbed design would be impractical.\n\nModern scanners typically use a charge-coupled device (CCD) or a contact image sensor (CIS) as the image sensor, whereas \"drum scanners\", developed earlier and still used for the highest possible image quality, use a photomultiplier tube (PMT) as the image sensor. A \"rotary scanner,\" used for high-speed document scanning, is a type of drum scanner that uses a CCD array instead of a photomultiplier. Non-contact planetary scanners essentially photograph delicate books and documents. All these scanners produce two-dimensional images of subjects that are usually flat, but sometimes solid; 3D scanners produce information on the three-dimensional structure of solid objects.\n\nDigital cameras can be used for the same purposes as dedicated scanners. When compared to a true scanner, a camera image is subject to a degree of distortion, reflections, shadows, low contrast, and blur due to camera shake (reduced in cameras with image stabilization). Resolution is sufficient for less demanding applications. Digital cameras offer advantages of speed, portability and non-contact digitizing of thick documents without damaging the book spine. scanning technologies were combining 3D scanners with digital cameras to create full-color, photo-realistic 3D models of objects.\n\nIn the biomedical research area, detection devices for DNA microarrays are called scanners as well. These scanners are high-resolution systems (up to 1 µm/ pixel), similar to microscopes. The detection is done via CCD or a photomultiplier tube.\n\nModern scanners are considered the successors of early telephotography and fax input devices.\n\nThe pantelegraph (Italian: \"pantelegrafo\"; French: pantélégraphe) was an early form of facsimile machine transmitting over normal telegraph lines developed by Giovanni Caselli, used commercially in the 1860s, that was the first such device to enter practical service. It used electromagnets to drive and synchronize movement of pendulums at the source and the distant location, to scan and reproduce images. It could transmit handwriting, signatures, or drawings within an area of up to 150 × 100 mm.\n\nÉdouard Belin's Belinograph of 1913, scanned using a photocell and transmitted over ordinary phone lines, formed the basis for the AT&T Wirephoto service. In Europe, services similar to a wirephoto were called a Belino. It was used by news agencies from the 1920s to the mid-1990s, and consisted of a rotating drum with a single photodetector at a standard speed of 60 or 120 rpm (later models up to 240 rpm). They send a linear analog AM signal through standard telephone voice lines to receptors, which synchronously print the proportional intensity on special paper. Color photos were sent as three separated RGB filtered images consecutively, but only for special events due to transmission costs.\n\nDrum scanners capture image information with photomultiplier tubes (PMT), rather than the charge-coupled device (CCD) arrays found in flatbed scanners and inexpensive film scanners. \"Reflective and transmissive originals are mounted on an acrylic cylinder, the scanner drum, which rotates at high speed while it passes the object being scanned in front of precision optics that deliver image information to the PMTs. Modern color drum scanners use three matched PMTs, which read red, blue, and green light, respectively. Light from the original artwork is split into separate red, blue, and green beams in the optical bench of the scanner with dichroic filters.\" Photomultipliers offer superior dynamic range and for this reason drum scanners can extract more detail from very dark shadow areas of a transparency than flatbed scanners using CCD sensors. The smaller dynamic range of the CCD sensors, versus photomultiplier tubes, can lead to loss of shadow detail, especially when scanning very dense transparency film. While mechanics vary by manufacturer, most drum scanners pass light from halogen lamps though a focusing system to illuminate both reflective and transmissive originals.\n\nThe drum scanner gets its name from the clear acrylic cylinder, the drum, on which the original artwork is mounted for scanning. Depending on size, it is possible to mount originals up to , but maximum size varies by manufacturer. \"One of the unique features of drum scanners is the ability to control sample area and aperture size independently. The sample size is the area that the scanner encoder reads to create an individual pixel. The aperture is the actual opening that allows light into the optical bench of the scanner. The ability to control aperture and sample size separately is particularly useful for smoothing film grain when scanning black-and-white and color negative originals.\"\n\nWhile drum scanners are capable of scanning both reflective and transmissive artwork, a good-quality flatbed scanner can produce good scans from reflective artwork. As a result, drum scanners are rarely used to scan prints now that high-quality, inexpensive flatbed scanners are readily available. Film, however, is where drum scanners continue to be the tool of choice for high-end applications. Because film can be wet-mounted to the scanner drum, which enhances sharpness and masks dust and scratches, and because of the exceptional sensitivity of the PMTs, drum scanners are capable of capturing very subtle details in film originals.\n\nThe situation was that only a few companies continued to manufacture and service drum scanners. While prices of both new and used units dropped from the start of the 21st century, they were still much more costly than CCD flatbed and film scanners. Image quality produced by flatbed scanners had improved to the degree that the best ones were suitable for many graphic-arts operations, and they replaced drum scanners in many cases as they were less expensive and faster. However, drum scanners with their superior resolution (up to 24,000 PPI), color gradation, and value structure continued to be used for scanning images to be enlarged, and for museum-quality archiving of photographs and print production of high-quality books and magazine advertisements. As second-hand drum scanners became more plentiful and less costly, many fine-art photographers acquired them.\n\nThis type of scanner is sometimes called a reflective scanner because it works by shining white light onto the object to be scanned and reading the intensity and color of light that is reflected from it, usually a line at a time. They are designed for scanning prints or other flat, opaque materials but some have available transparency adapters, which for a number of reasons, in most cases, are not very well suited to scanning film.\n\n\"A flatbed scanner is usually composed of a glass pane (or platen), under which there is a bright light (often xenon, LED or cold cathode fluorescent) which illuminates the pane, and a moving optical array in CCD scanning. CCD-type scanners typically contain three rows (arrays) of sensors with red, green, and blue filters.\"\n\nContact image sensor (CIS) scanning consists of a moving set of red, green and blue LEDs strobed for illumination and a connected monochromatic photodiode array under a rod lens array for light collection. \"Images to be scanned are placed face down on the glass, an opaque cover is lowered over it to exclude ambient light, and the sensor array and light source move across the pane, reading the entire area. An image is therefore visible to the detector only because of the light it reflects. Transparent images do not work in this way, and require special accessories that illuminate them from the upper side. Many scanners offer this as an option.\"\n\nThis type of scanner is sometimes called a slide or transparency scanner and it works by passing a narrowly focused beam of light through the film and reading the intensity and color of the light that emerges. \"Usually, uncut film strips of up to six frames, or four mounted slides, are inserted in a carrier, which is moved by a stepper motor across a lens and CCD sensor inside the scanner. Some models are mainly used for same-size scans. Film scanners vary a great deal in price and quality.\" The lowest-cost dedicated film scanners can be had for less than $50 and they might be sufficient for modest needs. From there they inch up in staggered levels of quality and advanced features upward of five figures. \"The specifics vary by brand and model and the end results are greatly determined by the level of sophistication of the scanner's optical system and, equally important, the sophistication of the scanning software.\"\n\nScanners are available that pull a flat sheet over the scanning element between rotating rollers. They can only handle single sheets up to a specified width (typically about 210 mm, the width of many printed letters and documents), but can be very compact, just requiring a pair of narrow rollers between which the document is passed. Some are portable, powered by batteries and with their own storage, eventually transferring stored scans to a computer over a USB or other interface.\n\n3D scanners collect data on the three-dimensional shape and appearance of an object.\n\nPlanetary scanners scan a delicate object without physical contact.\n\nHand scanners are moved over the subject to be imaged by hand. There are two different types: document and 3D scanners.\n\nHand-held document scanners are manual devices that are dragged across the surface of the image to be scanned by hand. Scanning documents in this manner requires a steady hand, as an uneven scanning rate produces distorted images; an indicator light on the scanner indicates if motion is too fast. They typically have a \"start\" button, which is held by the user for the duration of the scan; some switches to set the optical resolution; and a roller, which generates a clock pulse for synchronization with the computer. Older hand scanners were monochrome, and produced light from an array of green LEDs to illuminate the image\"; later ones scan in monochrome or color, as desired. A hand scanner may have a small window through which the document being scanned could be viewed. In the early 1990s many hand scanners had a proprietary interface module specific to a particular type of computer, such as an Atari ST or Commodore Amiga. Since the introduction of the USB standard, it is the interface most commonly used. As hand scanners are much narrower than most normal document or book sizes, software (or the end user) needed to combine several narrow \"strips\" of scanned document to produce the finished article.\n\nInexpensive portable battery-powered \"glide-over\" hand scanners, typically capable of scanning an area as wide as a normal letter and much longer remain available .\n\nHandheld 3D scanners are used in industrial design, reverse engineering, inspection and analysis, digital manufacturing and medical applications. \"To compensate for the uneven motion of the human hand, most 3D scanning systems rely on the placement of reference markers, typically adhesive reflective tabs that the scanner uses to align elements and mark positions in space.\"\n\nImage scanners are usually used in conjunction with a computer which controls the scanner and stores scans. Small portable scanners, either roller-fed or \"glide-over\" hand-operated, operated by batteries and with storage capability, are available for use away from a computer; stored scans can be transferred later. Many can scan both small documents such as business cards and till receipts, and letter-sized documents.\n\nThe higher-resolution cameras fitted to some smartphones can produce reasonable quality document scans by taking a photograph with the phone's camera and post-processing it with a scanning app, a range of which are available for most phone operating systems, to whiten the background of a page, correct perspective distortion so that the shape of a rectangular document is corrected, convert to black-and-white, etc. Many such apps can scan multiple-page documents with successive camera exposures and output them either as a single file or multiple page files. Some smartphone scanning apps can save documents directly to online storage locations, such as Dropbox and Evernote, send via email or fax documents via email-to-fax gateways.\n\nSmartphone scanner apps can be broadly divided into three categories:\n\nColor scanners typically read RGB (red-green-blue color) data from the array. This data is then processed with some proprietary algorithm to correct for different exposure conditions, and sent to the computer via the device's input/output interface (usually USB, previous to which was SCSI or bidirectional parallel port in older units).\n\nColor depth varies depending on the scanning array characteristics, but is usually at least 24 bits. High quality models have 36-48 bits of color depth.\n\nAnother qualifying parameter for a scanner is its \"resolution\", measured in pixels per inch (ppi), sometimes more accurately referred to as Samples per inch (spi). Instead of using the scanner's true optical resolution, the only meaningful parameter, manufacturers like to refer to the \"interpolated resolution\", which is much higher thanks to software interpolation. , a high-end flatbed scanner can scan up to 5400 ppi and drum scanners have an optical resolution of between 3,000 and 24,000 ppi.\n\n\"Effective resolution\" is the true resolution of a scanner, and is determined by using a resolution test chart. The effective resolution of most all consumer flatbed scanners is considerably lower than the manufactures' given optical resolution. Example is the Epson V750 Pro with an optical resolution given by manufacturer as being 4800dpi and 6400dpi (dual lens), but tested \"According to this we get a resolution of only about 2300 dpi - that's just 40% of the claimed resolution!\" Dynamic range is claimed to be 4.0 Dmax, but \"Regarding the density range of the Epson Perfection V750 Pro, which is indicated as 4.0, one must say that here it doesn't reach the high-quality [of] film scanners either.\"\n\nManufacturers often claim interpolated resolutions as high as 19,200 ppi; but such numbers carry little meaningful value, because the number of possible interpolated pixels is unlimited and doing so does not increase the level of captured detail.\n\nThe size of the file created increases with the square of the resolution; doubling the resolution quadruples the file size. A resolution must be chosen that is within the capabilities of the equipment, preserves sufficient detail, and does not produce a file of excessive size. The file size can be reduced for a given resolution by using \"lossy\" compression methods such as JPEG, at some cost in quality. If the best possible quality is required lossless compression should be used; reduced-quality files of smaller size can be produced from such an image when required (e.g., image designed to be printed on a full page, and a much smaller file to be displayed as part of a fast-loading web page).\n\nPurity can be diminished by scanner noise, optical flare, poor analog to digital conversion, scratches, dust, Newton's rings, out of focus sensors, improper scanner operation, and poor software. Drum scanners are said to produce the purest digital representations of the film, followed by high end film scanners that use the larger Kodak Tri-Linear sensors.\n\nThe third important parameter for a scanner is its density range (Dynamic Range) or Drange (see Densitometry). A high density range means that the scanner is able to record shadow details and brightness details in one scan. Density of film is measured on a base 10 log scale and varies between 0.0 (transparent) and 5.0, about 16 stops. Density range is the space taken up in the 0 to 5 scale, and Dmin and Dmax denote where the least dense and most dense measurements on a negative or positive film. The density range of negative film is up to 3.6d, while slide film dynamic range is 2.4d. Color negative density range after processing is 2.0d thanks to compression of the 12 stops into a small density range. Dmax will be the densest on slide film for shadows, and densest on negative film for highlights. Some slide films can have a Dmax close to 4.0d with proper exposure, and so can black-and-white negative film.\n\nConsumer-level flatbed photo scanners have a dynamic range in the 2.0–3.0 range, which can be inadequate for scanning all types of photographic film, as Dmax can be and often is between 3.0d and 4.0d with traditional black-and-white film. Color film compresses its 12 stops of a possible 16 stops (film latitude) into just 2.0d of space via the process of dye coupling and removal of all silver from the emulsion. Kodak Vision 3 has 18 stops. So, color negative film scans the easiest of all film types on the widest range of scanners. Because traditional black-and-white film retains the image creating silver after processing, density range can be almost twice that of color film. This makes scanning traditional black-and-white film more difficult and requires a scanner with at least a 3.6d dynamic range, but also a Dmax between 4.0d to 5.0d. High-end (photo lab) flatbed scanners can reach a dynamic range of 3.7, and Dmax around 4.0d. Dedicated film scanners have a dynamic range between 3.0d–4.0d. Office document scanners can have a dynamic range of less than 2.0d. Drum scanners have a dynamic range of 3.6–4.5.\n\nBy combining full-color imagery with 3D models, modern hand-held scanners are able to completely reproduce objects electronically. The addition of 3D color printers enables accurate miniaturization of these objects, with applications across many industries and professions.\n\nFor scanner apps, the scan quality is highly dependent on the quality of the phone camera and on the framing chosen by the user of the app.\n\nScans must virtually always be transferred from the scanner to a computer or information storage system for further processing or storage. There are two basic issues: (1) how the scanner is physically connected to the computer and (2) how the application retrieves the information from the scanner.\n\nThe file size of a scan can be up to about 100 megabytes for a (9\"x11\") (slightly larger than A4 paper) uncompressed 24-bit image. Scanned files must be transferred and stored. Scanners can generate this volume of data in a matter of seconds, making a fast connection desirable.\n\nScanners communicate to their host computer using one of the following physical interfaces, listing roughly from slow to fast:\n\nDuring the early 1990s professional flatbed scanners were available over a local computer network. This proved useful to publishers, print shops, etc. This functionality largely fell out of use as the cost of flatbed scanners reduced enough to make sharing unnecessary.\n\nFrom 2000 all-in-one multi-purpose devices became available which were suitable for both small offices and consumers, with printing, scanning, copying, and fax capability in a single apparatus which can be made available to all members of a workgroup.\n\nBattery-powered portable scanners store scans on internal memory; they can later be transferred to a computer either by direct connection, typically USB, or in some cases a memory card may be removed from the scanner and plugged into the computer.\n\nA paint application such as GIMP or Adobe Photoshop must communicate with the scanner. There are many different scanners, and many of those scanners use different protocols. In order to simplify applications programming, some Applications programming interfaces (\"API\") were developed. The API presents a uniform interface to the scanner. This means that the application does not need to know the specific details of the scanner in order to access it directly. For example, Adobe Photoshop supports the TWAIN standard; therefore in theory Photoshop can acquire an image from any scanner that has a TWAIN driver.\n\nIn practice, there are often problems with an application communicating with a scanner. Either the application or the scanner manufacturer (or both) may have faults in their implementation of the API.\n\nTypically, the API is implemented as a dynamically linked library. Each scanner manufacturer provides software that translates the API procedure calls into primitive commands that are issued to a hardware controller (such as the SCSI, USB, or FireWire controller). The manufacturer's part of the API is commonly called a device driver, but that designation is not strictly accurate: the API does not run in kernel mode and does not directly access the device. Rather the scanner API library translates application requests into hardware requests.\n\nCommon scanner software API interfaces:\n\nSANE (Scanner Access Now Easy) is a free/open-source API for accessing scanners. Originally developed for Unix and Linux operating systems, it has been ported to OS/2, Mac OS X, and Microsoft Windows. Unlike TWAIN, SANE does not handle the user interface. This allows batch scans and transparent network access without any special support from the device driver.\n\nTWAIN is used by most scanners. Originally used for low-end and home-use equipment, it is now widely used for large-volume scanning.\n\nISIS (Image and Scanner Interface Specification) created by Pixel Translations, which still uses SCSI-II for performance reasons, is used by large, departmental-scale, machines.\n\nWIA (Windows Image Acquisition) is an API provided by Microsoft for use on Microsoft Windows.\n\nAlthough no software beyond a scanning utility is a feature of any scanner, many scanners come bundled with software. Typically, in addition to the scanning utility, some type of image-editing application (such as Adobe Photoshop), and optical character recognition (OCR) software are supplied. OCR software converts graphical images of text into standard text that can be edited using common word-processing and text-editing software; accuracy is rarely perfect.\n\nSome scanners, especially those designed for scanning printed documents, only work in black-and-white but most modern scanners work in color. For the latter, the scanned result is a non-compressed RGB image, which can be transferred to a computer's memory. The color output of different scanners is not the same due to the spectral response of their sensing elements, the nature of their light source and the correction applied by the scanning software. While most image sensors have a linear response, the output values are usually gamma compressed. Some scanners compress and clean up the image using embedded firmware. Once on the computer, the image can be processed with a raster graphics program (such as Adobe Photoshop or the GIMP) and saved on a storage device (such as a hard disk).\n\nImages are usually stored on a hard disk. Pictures are normally stored in image formats such as uncompressed Bitmap, \"non-lossy\" (lossless) compressed TIFF and PNG, and \"lossy\" compressed JPEG. Documents are best stored in TIFF or PDF format; JPEG is particularly unsuitable for text. Optical character recognition (OCR) software allows a scanned image of text to be converted into editable text with reasonable accuracy, so long as the text is cleanly printed and in a typeface and size that can be read by the software. OCR capability may be integrated into the scanning software, or the scanned image file can be processed with a separate OCR program.\n\nDocument imaging requirements differ from those of image scanning. These requirements include scanning speed, automated paper feed, and the ability to automatically scan both the front and the back of a document. On the other hand, image scanning typically requires the ability to handle fragile and or three dimensional objects as well as scan at a much higher resolution.\n\nDocument scanners have document feeders, usually larger than those sometimes found on copiers or all-purpose scanners. Scans are made at high speed, from 20 up to 280 or 420 pages per minute, often in grayscale, although many scanners support color. Many scanners can scan both sides of double-sided originals (duplex operation). Sophisticated document scanners have firmware or software that cleans up scans of text as they are produced, eliminating accidental marks and sharpening type; this would be unacceptable for photographic work, where marks cannot reliably be distinguished from desired fine detail. Files created are compressed as they are made.\n\nThe resolution used is usually from 150 to 300 dpi, although the hardware may be capable of 600 or higher resolution; this produces images of text good enough to read and for optical character recognition (OCR), without the higher demands on storage space required by higher-resolution images.\n\nDocument scans are often processed using OCR technology to create editable and searchable files. Most scanners use ISIS or TWAIN device drivers to scan documents into TIFF format so that the scanned pages can be fed into a document management system that will handle the archiving and retrieval of the scanned pages. Lossy JPEG compression, which is very efficient for pictures, is undesirable for text documents, as slanted straight edges take on a jagged appearance, and solid black (or other color) text on a light background compresses well with lossless compression formats.\n\nWhile paper feeding and scanning can be done automatically and quickly, preparation and indexing are necessary and require much work by humans. Preparation involves manually inspecting the papers to be scanned and making sure that they are in order, unfolded, without staples or anything else that might jam the scanner. Additionally, some industries such as legal and medical may require documents to have Bates Numbering or some other mark giving a document identification number and date/time of the document scan.\n\nIndexing involves associating relevant keywords to files so that they can be retrieved by content. This process can sometimes be automated to some extent, but it often requires manual labour performed by data-entry clerks. One common practice is the use of barcode-recognition technology: during preparation, barcode sheets with folder names or index information are inserted into the document files, folders, and document groups. Using automatic batch scanning, the documents are saved into appropriate folders, and an index is created for integration into document-management systems.\n\nA specialized form of document scanning is book scanning. Technical difficulties arise from the books usually being bound and sometimes fragile and irreplaceable, but some manufacturers have developed specialized machinery to deal with this. Often special robotic mechanisms are used to automate the page turning and scanning process.\n\nAnother category of document scanner is the document camera. Capturing images on document cameras differs from that of flatbed and Automatic document feeder (ADF) scanners in that there are no moving parts required to scan the object. Conventionally either the illumination/reflector rod inside the scanner must be moved over the document (such as for a flatbed scanner), or the document must be passed over the rod (such as for feeder scanners) in order to produce a scan of a whole image. Document cameras capture the whole document or object in one step, usually instantly. Typically, documents are placed on a flat surface, usually the office desk, underneath the capture area of the document camera. The process of whole-surface-at-once capturing has the benefit of increasing reaction time for the work flow of scanning. After being captured, the images are usually processed through software which may enhance the image and perform such tasks like automatically rotating, cropping and straightening them.\n\nIt is not required that the documents or objects being scanned make contact with the document camera, therefore increasing flexibility of the types of documents which are able to be scanned. Objects which have previously been difficult to scan on conventional scanners are now able to be done so with one device. This includes in particular documents which are of varying sizes and shapes, stapled, in folders or bent/crumpled which may get jammed in a feed scanner. Other objects include books, magazines, receipts, letters, tickets etc. No moving parts can also remove the need for maintenance, a consideration in the Total cost of ownership, which includes the continuing operational costs of scanners.\n\nIncreased reaction time whilst scanning also has benefits in the realm of context-scanning. ADF scanners, whilst very fast and very good at batch scanning, also require pre- and post- processing of the documents. Document cameras are able to be integrated directly into a Workflow or process, for example a teller at a bank. The document is scanned directly in the context of the customer, in which it is to be placed or used. Reaction time is an advantage in these situations. Document cameras usually also require a small amount of space and are often portable.\n\nWhilst scanning with document cameras may have a quick reaction time, large amounts of batch scanning of even, unstapled documents is more efficient with an ADF scanner. There are challenges which face this kind of technology regarding external factors (such as lighting) which may have influence on the scan results. The way in which these issues are resolved strongly depends on the sophistication of the product and how it deals with these issues.\n\nInfrared cleaning is a technique used to remove the effects of dust and scratches on images scanned from film; many modern scanners incorporate this feature. It works by scanning the film with infrared light; the dyes in typical color film emulsions are transparent to infrared light, but dust and scratches are not, and block infrared; scanner software can use the visible and infrared information to detect scratches and process the image to greatly reduce their visibility, considering their position, size, shape, and surroundings.\n\nScanner manufacturers usually have their own name attached to this technique. For example, Epson, Minolta, Nikon, Konica Minolta, Microtek, and others use Digital ICE, while Canon uses its own system FARE (Film Automatic Retouching and Enhancement system). Plustek uses LaserSoft Imaging iSRD. Some independent software developers design infrared cleaning tools.\n\nFlatbed scanners have been used as digital backs for large-format cameras to create high-resolution digital images of static subjects. A modified flatbed scanner has been used for documentation and quantification of thin layer chromatograms detected by fluorescence quenching on silica gel layers containing an ultraviolet (UV) indicator. 'ChromImage' is allegedly the first commercial flatbed scanner densitometer. It enables acquisition of TLC plate images and quantification of chromatograms by use of Galaxie-TLC software. Other than being turned into densitometers, flatbed scanners were also turned into colorimeters using different methods. Trichromatic Color Analyser is allegedly the first distributable system using a flatbed scanner as a tristimulus colorimetric device.\n\n\n"}
{"id": "244071", "url": "https://en.wikipedia.org/wiki?curid=244071", "title": "Interstellar ark", "text": "Interstellar ark\n\nAn interstellar ark or generation ship is a conceptual space vehicle designed for interstellar travel. Interstellar arks may be the most economically feasible method of traveling such distances. The ark has also been proposed as a potential habitat to preserve civilization and knowledge in the event of a global catastrophe.\n\nSuch a ship would have to be large, requiring a large power plant. The Project Orion concept of propulsion by nuclear pulses has been proposed. The largest spacecraft design analyzed in Project Orion had a 400 m diameter and weighed approximately 8 million tons. It could be large enough to host a city of 100,000 or more people.\n\nAnother concern is selection of power sources and mechanisms which would remain viable for the long time spans involved in interstellar travel through the desert of space. The longest lived space probes are the Voyager program probes, which use radioisotope thermoelectric generators having a useful lifespan of a mere 50 years.\n\nOne propulsion method for a crewed spacecraft could be a fusion microexplosion nuclear pulse propulsion system, like that proposed in Project Daedalus that may allow it to obtain an interstellar cruising velocity of up to 10% of the speed of light. However, if the ship is capable of transits requiring hundreds of thousands of years, chemical and gravitational slingshot propulsion may be sufficient.\n\n\n\n\n\n"}
{"id": "47893917", "url": "https://en.wikipedia.org/wiki?curid=47893917", "title": "Jakob Heusser-Staub", "text": "Jakob Heusser-Staub\n\nJakob Heusser-Staub (3 March 1862 – 23 August 1941 as Jakob Heusser) was a Swiss industrialist and philanthropist. Born and raised in the village of Irgenhausen, Heusser-Staub made Uster his home. With the support of his wife, Berta, he founded the \"Heusser-Staub\" foundation.\nBorn in the hamlet of Irgenhausen in the municipality of Wetzikon, he was the son of Luise née Schellenberg and Caspar. He attended \"Sekundarschule\" (pre-college level) in Wetzikon and was a citizen of Pfäffikon. From 1877 to 1879, he attended the Industrial School in Zürich. Afterwards he received practical and commercial training at his father's business. His father, Caspar Heusser (1836–1910), was a cotton manufacturer who sold his products in Kempten and the surrounding area. \n\nHis professional success enabled him to purchase the \"Spinnerei Stauber\" in Kempten (with 1,200 spindles) in 1869 and to introduce mechanical weaving with 36 machines. In 1883 he bought a cotton mill in Bubikon (6,000 spindles, 80 workers), where he also added a weaving factory. Heusser expanded to Winterthur and St. Gallen, leaving a considerable fortune. \n\nHe lived from 1880 to 1882 in Lyon and from 1882 to 1883 in England to gain professional experience. From 1883 to 1897 he served as trade merchant in his father's business in Bubikon, from 1897 independently as his own factory.\n\nIn 1900, Jakob Heusser became a textile industrialist in the city of Uster, the industrial centre of the region. He purchased the Boller mill in Uster, and developed it to produce quality yarns. \n\nIn 1910 he inherited the paternal factories and in 1917 bought the spinning factory Huber in Uster, which he modernized in 1928. Beginning in 1919 Heusser held the majority share of the textile factory Schiesser AG, with factories in Radolfzell and Kreuzlingen, and in 1929 he gained control of the cotton spinning and weaving factory, Wettingen, which he also modernized. Moreover, Heusser was involved in the short-lived Swiss car factory Turicum. He acquired the majority of shares of the \"Fabrik für Electrische Geräte\" from Alfred Zellweger, the later Zellweger Uster AG. \n\nHeusser was also involved in the \"Aluminium Industrie AG\" (now Alusuisse). He was a member of the board from 1924 to 1939, and from 1918 to 1939 he also sat on the board of \"Maschinenfabrik Rieter\". His involvement in the Terpena AG in the manufacturing of artificial camphor in the early 1930s was a financial fiasco, but in 1938 the activities of the spinning and weaving companies (except of \"Spinnerei Wettingen\") were summarized in the holding company \"Heusser-Staub AG\" and all other companies in the \"Hesta\" (He[usser]-sta[ub]) holding.\n\nDuring the interwar period Heusser became the most important industrialist of the Zürich Oberland region. In 1900 he employed about 60 workers and produced about ten tons of yarn per year. In 1950 there were 230 workers who produced about 50 to 60 tons of yarn per year.\n\nBerta and Jakob Heusser-Staub supported projects of labour welfare. In 1917 the Uster Castle was acquired and renovated to house an agricultural and domestic managenment school. It was given to the citizenry of Uster to establish the \"Heusser-Staub-Stiftung\". In the same year, Heusser and his wife Berta were appointed honorary citizens of Uster.\n\n\n"}
{"id": "24224101", "url": "https://en.wikipedia.org/wiki?curid=24224101", "title": "James May's Toy Stories", "text": "James May's Toy Stories\n\nJames May's Toy Stories is a television series presented by James May. The series was commissioned for BBC Two from Plum Pictures. The first episode, \"Airfix\", was broadcast on BBC Two at 8:00 pm on Tuesday 27 October 2009. In later years, three specials were made for the Christmas seasons, along with a follow-up to the sixth episode.\n\nThe premise of the 6-part show was to bring favourite toys of the past into the modern era, by using the toys in real life large scale enterprises. In each episode, he also explores the history of each toy. A few stars of the show include Airfix model planes, plasticine modelling material, Meccano construction toys, Scalextric cars and Lego.\n\nMay's interest in technology is known from his presentation of such programmes as \"James May's 20th Century\" and \"James May's Big Ideas\". He credits much of the inventiveness of humans to the love of playing with toys and he has credited many technological developments to men playing in sheds. He has shown his passion for toys in programmes he has presented including \"James May's Top Toys\" and \"\" and he has discussed his desire for children to get away from games consoles and play with real toys preferably with their parents. May was quoted as saying:\n\nMany of the plans involved significant engineering problems, so the programme makers searched for architects, designers and engineers to help them. However, many more volunteers would be required as a labour force, so appeals for volunteers were distributed in local newspapers.\n\nThe ambitious - world record-breaking in many cases - projects included:\n\nThe series was nominated in the Features category of the 2010 British Academy Television Awards, but lost out to the eventual winner, \"\".\n\nJames released a well-received book in conjunction with the series, through Conway Publishing (2009).\n\n"}
{"id": "1816110", "url": "https://en.wikipedia.org/wiki?curid=1816110", "title": "Joseph Engelberger", "text": "Joseph Engelberger\n\nJoseph Frederick Engelberger was born on July 26, 1925, in Brooklyn, New York. He grew up in Connecticut during the Great Depression, but later returned to New York City for his college education.\n\nEngelberger received his B.S. in physics in 1946, and M.S. in Electric Engineering in 1949 from Columbia University. He worked as an engineer with Manning, Maxwell and Moore, where he met inventor George Devol at a Westport cocktail party in 1956, two years after Devol had designed and patented a rudimentary industrial robotic arm. However, Manning, Maxwell and Moore was sold and Engelberger's division was closed that year.\n\nFinding himself jobless but with a business partner and an idea, Engelberger co-founded Unimation with Devol, creating the world's first robotics company. In 1957, he also founded Consolidated Controls Corporation. As president of Unimation, Engelberger collaborated with Devol to engineer and produce an industrial robot under the brand name Unimate. The first Unimate robotic arm was installed at a General Motors Plant in Ewing Township, New Jersey, in 1961.\n\nThe introduction of robotics to the manufacturing process effectively transformed the automotive industry, with Chrysler and the Ford Motor Company soon following General Motors' lead and installing Unimates in their manufacturing facilities. The rapid adoption of the technology also provided Unimation with a working business model: after selling the first Unimate at a $35,000 loss, as demand increased, the company was able to begin building the robotic arms for significantly less and thus began to turn a substantial profit. Over the next two decades, the Japanese took the lead by investing heavily in robots to replace people performing certain tasks. In Japan, Engelberger was widely hailed as a key player in the postwar ascendancy of Japanese manufacturing quality and efficiency.\n\nIn 1966, Engelberger and a Unimate robot appeared on \"The Tonight Show Starring Johnny Carson\". In the segment, the robot poured a beer, sank a golf putt, and directed the band.\n\nAn early proponent of increased investment in robotic systems, Engelberger published articles and gave congressional testimony on the value of using automation in space long before the successes of NASA's Mars landers, \"Galileo\", and other unmanned space science missions. He also consulted for NASA on the use of robotics in space exploration.\n\nUnimation purchased Victor Scheinman's Vicarm Inc. in 1977, and with Scheinman's help, the company created and began producing the Programmable Universal Machine for Assembly, a new model of robotic arm, and using Scheinman's cutting-edge VAL programming language. However, the automotive companies that had been Unimation's earliest and most reliable clients began moving away from the use of hydraulically powered robotic arms in the early 1980s in favor of electric motors, a change that Engelberger vehemently opposed. Sales fell, and the company was acquired by Westinghouse in 1982 for $107 million. Engelberger, who had served as Unimation's chief executive since its inception, left the company not long thereafter.\n\nAfter observing the help for his aging parents, Engelberger saw the robotics automations could be used in the medical field. In 1984, Engelberger founded Transitions Research Corporation. He introduced the HelpMate, a mobile robot hospital courier, as the flagship product of his new company. He hoped to kick-start a new industry for in-home robots, but he started in 1988 by selling his first HelpMate to Danbury Hospital, located in the same Connecticut city where his company was based. The medical robot was successful enough that the hospital ended up purchasing another, and within a decade, well over 100 hospitals worldwide operated HelpMates, whether purchased outright or rented from Engelberger's company, which he renamed HelpMate Robotics Inc.\n\nAfter Engelberger was awarded the Japan Prize in 1997, Senator Joseph Lieberman of Connecticut delivered a floor speech in the U.S. Senate in praise and recognition of the inventor, calling HelpMate Robotics \"an example of the way that a patient federal investment in science and technology can lead to new products that employ Americans and make for a better quality of life.\"\n\nHelpMate was acquired by Cardinal Health in the late 1990s, a move Engelberger came to regret, complaining that the new owners moved away from his preferred model of renting out robots toward selling off used, depreciated models.\n\nThe 2000 World Automation Congress was dedicated to Engelberger, who delivered the keynote address. Even after his departure from HelpMate and well into his 80s, he remained active in the promotion and development of robots for use in elder care. He notably discouraged the notion of legged robots, arguing that robots should use wheels for locomotion, although he supported the use of robotic arms to allow the machines to interact with their surroundings. He worked on developing a two-armed robot to act as a \"servant-companion\" to seniors with limited mobility.\n\nEngelberger died on December 1, 2015, in Newtown, Connecticut, a little more than four months after celebrating his 90th birthday.\n\nEngelberger published \"Robotics in Practice\" in 1980. The book became a classic in the field and has been translated into six languages. \"Robotics in Practice\" was followed by \"Robotics in Service\" in 1989.\n\nEngelberger was elected to the National Academy of Engineering in 1984. He was also honored among \"The 1000 Makers of the 20st Century\" by \"The Sunday Times\" in 1992. Additional honors include the Progress Award of the Society of Manufacturing Engineers, the 1982 Nyselius Award from the American Die Casting Institution, the 1982 Leonardo da Vinci Award of the American Society of Mechanical Engineers, the 1982 American Machinist Award, the 1983 Golden Omega Award at the Electrical Electronics Insulation Conference, the 1983 McKechnie Award from the University of Liverpool, the 1984 Egleston Medal from Columbia University, the 1997 Beckman Award for pioneering and original research in the field of automation, and the 1997 Japan Prize, the highest Japanese technology honor, for the establishment of the robot industry. He also received the IEEE Robotics and Automation Award in 2004.\n\nThe Robotics Industries Association annually presents the Joseph F. Engelberger Awards to \"persons who have contributed outstandingly to the furtherance of the science and practice of robotics.\" The award was first given in 1977.\n\nEngelberger's most famous co-invention, the Unimate industrial robotic arm, was among the first inductees into the Robot Hall of Fame in 2003.\n\n"}
{"id": "5679206", "url": "https://en.wikipedia.org/wiki?curid=5679206", "title": "KrioRus", "text": "KrioRus\n\nKrioRus () — the first Russian cryonics company, founded in 2005 as a project by a non-governmental organization \"Russian Transhumanist Movement\". KrioRus is the only cryonics company in Europe, that possesses its own cryostorage. The company stores bodies (or brains) of its cryopatients — dead people and animals, in liquid nitrogen, in the hope that someday it will be possible to revive them by means of the emerging technologies of the future. The company offers a service of freezing either the entire patient's body, or just their head. KrioRus cooperates with other cryonics companies of the world, and facilitates placement of patients' bodies in similar storage facilities, situated outside Russia.\n\nLegally, the company has the status of a scientific research organization, engaged in a non-mainstream activity, and its services are not subject to certification. One of the problems with KrioRus activity is considered to be the lack of cryonics-related legislation. The company does not guarantee the revivification of its cryopatient.\n\nCriticism of company's activity consists of the criticism of cryonics per se: yet there is little scientific proof that supports the theory of reanimation and most mainstream scientists and doctors express great scepticism about the field. In comparison with foreign cryonics companies, and of the fact that KrioRus, as indeed the other cryonics companies, is not always capable of fulfilling contractual obligations.\n\nFirst attempts at creating a Russian cryocompany were undertaken in the 1990s by physicist Mikhail Solovyev.\n\nInitial motivation of the founding was the desire of its nine founding members to freeze their own bodies as well as the bodies of their loved ones in order to be \"resurrected\" in future by means of some future medical technologies. Prior to the companys' founding, its prospective staff members have already had some experience in cryopreservation, when in 2003, Igor Artyukhov acted as the chief advisor to a project of preservation of the brain of one deceased biotech scientist.\n\nThe company has been eventually established in 2005 as a project of an NGO, called \"Russian Transhumanist Movement\". Lydia Fedorenko became the first patient of the company in 2005. However, at that time KrioRus did not yet possess a dedicated cryostorage, and prior to being preserved by the company, her family had for several months kept her brain on dry ice. During the existence of KrioRus, citizens from nine countries have become its patients, including citizens of the United States, Netherlands, Japan, Israel, Italy, Switzerland and Australia. By the same token, cryopreserved relatives of company employees are being kept in cryostorage.\n\nOn 3 May 2006 the company was formally added to the legal entities register, as required by Russian law.\nInitially, cryostorage facility was opened in year 2006, in the village of in Solnechnogorskiy district of the Moscow region, which was followed by the opening of the facility in Sergiev-Posad district of the Moscow region in 2012. In 2016 another move is planned, and is being prepared, to yet another place (near Tver), where the location shall be more conducive to the research activities of the company.\n\nAccording to KrioRus as well as according to the press reports, at the beginning of November 2016 the company has frozen 51 people (26 bodies and 25 patients' heads), 7 dogs, 8 cats, both male and female, as well as 3 birds and a chinchilla. In addition, there are human and animal DNA samples in storage. Almost as many as 200 Russian citizens have entered into cryopreservation agreements with the company.\n\nIt is thought that KrioRus has become, during the 2010-s, the third largest cryonics company in the world and now provides competition to companies such as Alcor (which has about 140 people in cryostorage). In addition, KrioRus is the first cryocompany in Europe, that possesses its own cryostorage facility.\n\nThe company has taken part in a number of Russian and international exhibitions, both dedicated to medicine as well as to the funeral homes business:\n\nCEO of the company is , who has held this position since June 2009. Since the day of the founding and until June 2009, position of CEO has been occupied by Danila Medvedev, who currently serves as the Chairman of the board of directors as well as the deputy to CEO for strategic development. Director for Science is the biophysicist, Igor Artyukhov. Valeria Udalova, Danila Medvedev and Igor Artyukhov are among the nine founders of the company listed at its inception. In 2010, the number of KrioRus founders' has increased to 10, and in 2016 it is at 11.\n\nThe KrioRus research team is headed by cryobiologist Yuri Pichugin, PhD, who has spent time from 2001 to 2007 working in Cryonics Institute (USA, Detroit). One notable staff member is a former president of Alcor, Mike Darwin.\n\nIn accordance with the state statistical rubricator, the company is engaged in research and development, insurance as well as provision of \"other kinds of services\". However, the company is presenting its activities as the provision of services, facilitating preservation of the bodies of their \"cryopatients\" in liquid nitrogen — of dead people and animals (or their respective brains) — in the hope that someday they it would become possible to revive them through the means of some highly advanced future technologies. Generally the bulk of company's clients are educated people of moderate means, both men and women in equal proportions.\n\nCompany representatives attitude to the possibility of \"resurrection\" is described by them as follows (in reply to the question: \"Doesn't cryonics give false hope?\"): \"There is no concrete evidence as to whether the development of cryonics would end in is success or will it fail. But the fact that the concept of cryonics is currently dependent upon a yet unknown science of the future, and that its success cannot be guaranteed, it is not the same as its guaranteed failure \".\n\nOne of the key advantages KrioRus possesses is the cost of its services, primarily for Russian and non-US citizens. Unlike American companies, KrioRus was founded in such a way, that it is not subject to the rules governing medical and funeral activities. As a result, the company does not face regulatory challenges in such fields of activity as acquisition of bodies from hospitals and morgues. Furthermore, it matters that KrioRus has a cleaner reputation than Alcor, which has suffered a few scandals. Danila Medvedev describes this situation as follows: \"We didn’t have the crisis that they had in the 1970s. People in Russia have no negative impression of cryonics\". Despite skepticism of its US competitors, KrioRus plans to implement the world's first center, where patients would die and be frozen, all in the same building. Company's cryostorage facility is designed to be able to relocate quickly in case of war, natural disasters etc., in which case it can be moved in the space of a few days, while its storage tanks are capable to work autonomously and to sustain necessary temperature for two days.\n\nIn the United States, as in Russia, cryonics companies employ largely the same cryopreservation procedures — after biological and legal death of the patient has been established, blood is evacuated from the body (and is replaced with a special solution, so prepared that its crystallization during the freezing process would not destroy the cells), the body is cooled down to the temperature of dry ice (-79 °C), transported and then cooled down to ultra low temperature (-196 °C) and placed in a long-term storage tank. Choices to preserve only the head occur not only due to financial considerations, but also because of the belief that in the future, technology would allow to restore the lost body, and the identity will be safeguarded in the brain. One of the problems of cryonics is to provide for a quick patient admission, since the quicker this occurs, the better it is possible to preserve the body. To address this problem, the company has several mobile teams of specialists across the country, who can quickly go and provide patients with necessary primary procedures on the spot. Similarly, KrioRus is cooperating with regional doctors, and provides them with lessons in primary preparative procedures for cryopreservation. As an additional service to complement its chief one, KrioRus offers help in safekeeping the lives' archives of their clients (blogs, video recordings), that should help to restore the identity of the person in the future.\nOne of the directions of company's development is the creation of cryostorage facilities in a neutral country such as Switzerland. This country is one of the primary target countries because it has allowed euthanasia, with the help of which one can create better conditions for cryopreservation. Also, representatives of the company named one of the objectives the improvement of the cryopatient preparation and transportation procedures, which will enable the provision of cryonics services to customers from all over the world, including such countries as Ecuador and China. Among other potential business activities of the company, was mentioned sperm freezing, as were freezing of embryos and organs, Cryobank creation, tours of cryostorage facilities, visiting relatives provided patients are stored in transparent sarcophagi, introduction of cryonics to the voluntary health insurance, etc. Danila Medvedev calls it the Company's Dream — the opportunity to bring members of Robert Scott's doomed expedition, who froze to death in the Antarctic in 1912, to the KrioRus lab. According to Danila Medvedev, the temperature on that continent is low enough, and little enough time has passed since then, in order for it to be possible to safeguard the explorers and bring them back to life.\n\nKrioRus conducts its research in two laboratories — in Moscow and in Voronezh. This work is focused on improving the process of cryopreservation itself, e.g., to improve vitrification technology, or to develop an apparatus, permitting storage in a gaseous environment with the controlled supply of liquid nitrogen. A separate scientific field of study is the reversible defrosting of organs. Currently, organ storage timeframe for transplantation is just a few hours, while this technology has the potential to allow to store such organs indefinitely.\n\nThe company collaborates with the in the field of reversible organ deep-freeze technologies. In addition, KrioRus cooperates with other cryonics companies of the world, facilitates exchanges of valuable experience and assists individuals, wishing to put their bodies in a similar storage facility, located outside of Russia.\n\nWhen clients deal with KrioRus, they sign a contract to carry out scientific experiment on the preservation and revitalization of a human, and at the same time KrioRus demands that the customer acknowledges the fact that the contractor does not provide guarantees to revive the cryopatient. The agreement covers safekeeping of the bodies for up to 100 years, with the possibility of extension.\n\nMaria Bast, chairman of the Russian Lawyers Association for Human Rights, have said that the status of KrioRus as a scientific organisation is justified, and the problem stems from the lack of legislation in the field of cryonics. However, there is a precedent, when in 2005 in Novosibirsk, the relatives of the deceased were keeping his body in a deep freeze and the state prosecutor did not find that it constituted a crime.\n\nAccording to the lawyer Svetlana Yudina, judging from a legal point of view, the company is involved in non-standard activities, but that does not necessarily mean that its employees are crooks. This is being justified as follows: \"Activities, directed towards cryopreservation of people can be considered fraud if an employee makes assurances or promises that the frozen corpse would inevitably come to life under any circumstances, and even specifies the date or the period when such a miracle is to be expected. Similarly, it can be considered fraud if an employee is presenting falsified evidence of successful experiments, photos, videos of re-animated people, and so on. However if the workers simply argue that a revival is possible, but by means of methods that have not yet been invented, no deception is to be found there\".\n\nAccording to the Health Ministry press service, cryonics companies' services are not subject to certification, since research is their chief activity.\n\nIn order for a person's body to be transferred postmortem to KrioRus, it is required that the individual in question would have stated in their will that their body should be handed over to the cryonics company, and in such a case, these works can not be prohibited by law. Otherwise, from a legal point of view one, is required to settle the problem with the client's next of kin. However, even with contract and with the will both being available one could run into problems (e.g., due to the \"hostile wife\" phenomenon).\n\nThe company's activity is seen in the context of criticism of cryonics as such. At present, the question of the possibility of \"resurrection\" of cryopatient is an open one in scientific community. On one hand, there are no known cases of \"resurrection\" of cryopatients, and cryonics companies (KrioRus included) do not guarantee such an outcome. On the other hand, there are experimental arguments in favour of the hypothesis of a successful \"resurrection\". From theoretical and research perspectives there is a number of arguments both in favour of cryonics supporters and in favour of its opponents.\n\nWhen comparing KrioRus and Alcor, journalists call the first company Lada of the world of cryonics, and the second one — Mercedes-Benz. Alcor cryonics is the largest cryonics company in the world, twice a week it conducts tours of its premises, demonstrating the operating room (where vitrification and freezing are conducted), as well as long-term cryopatients' storage facilities, where they could just be seen through bulletproof glass. On the other side, KrioRus does not offer any such services.\n\nThere is a known case of the \"hostile wife\" phenomenon in the practice of the company. In 2012, cancer patient, engineer Mikhail Voronin has signed a contract with the company KrioRus on neuropreservation and paid 300 thousand rubles. However, after the death, engineer's body complete with the brain has been cremated, by the widow, who \"stole\" Mikhails' body from the hospital and did not allow it to come into possession of the company. Thus, the employees' KrioRus were not able to cryopreserve patient, despite the fact that he has stated his will in writing and even recorded a video missive. Later, the court rejected the company's plea.\n\n\n"}
{"id": "863993", "url": "https://en.wikipedia.org/wiki?curid=863993", "title": "Line card", "text": "Line card\n\nA line card or digital line card is a modular electronic circuit designed to fit on a separate printed circuit board (PCB) and interface with a telecommunications access network.\n\nA line card typically interfaces the twisted pair cable of a plain old telephone service (POTS) local loop to the public switched telephone network (PSTN). Telephone line cards perform multiple tasks, such as analog-to-digital and digital-to-analog conversion of voice, off-hook detection, ring supervision, line integrity tests, and other BORSCHT functions. In some telephone exchange designs, the line cards generate ringing current and decode DTMF signals. The line card in a subscriber loop carrier is called a subscriber line interface card (SLIC).\n\nA line card can terminate a line supporting voice POTS service, ISDN service, DSL service, or proprietary ones. Some line cards are capable of terminating more than one type of service.\n\nSince an access network element is usually intended to interface many users (typically a few thousand), some exchanges have multiple line terminations per card. Likewise, one network element can have many line cards.\n\n"}
{"id": "56750520", "url": "https://en.wikipedia.org/wiki?curid=56750520", "title": "Ministry of Information and Broadcasting Services", "text": "Ministry of Information and Broadcasting Services\n\nThe Ministry of Information and Broadcasting Services is a ministry in Zambia. It is headed by the Minister of Information and Broadcasting Services.\n\nThe ministry controls two publicly-owned newspapers, the Times of Zambia and the Zambia Daily Mail, and has a seat on the board of the Zambia National Broadcasting Corporation.\n\nThe Information and Broadcasting Services portfolio was combined with Tourism during the 1960s, before the two were split.\n\n"}
{"id": "5285458", "url": "https://en.wikipedia.org/wiki?curid=5285458", "title": "Norwegian Union of Food, Beverage and Allied Workers", "text": "Norwegian Union of Food, Beverage and Allied Workers\n\nThe Norwegian Union of Food, Beverage and Allied Workers (NNN) is a trade union in Norway. It has a membership of 33,000 and is affiliated with the Norwegian Confederation of Trade Unions (LO).\n\n"}
{"id": "27858681", "url": "https://en.wikipedia.org/wiki?curid=27858681", "title": "Oscar (bionic cat)", "text": "Oscar (bionic cat)\n\nOscar is an all black cat owned by Kate Allan and Mike Nolan who lives on the Channel Island of Jersey. In 2009 Oscar had both hind paws severed by a combine harvester. Since then he has undergone a pioneering operation to add prosthetic feet. The treatment has since been considered for use with humans. A book about Oscar's story, \"Oscar the Bionic Cat\" was published in 2013. \n\nIn October 2009, at the age of two and a half years, Oscar had both the paws of his hind legs severed by a combine harvester while in a maize field near his home in Jersey. The legs were cut between the ankle and the foot. Oscar was later found by a passing cyclist who then brought Oscar to his owners' home. Mike Nolan, an IT manager in a bank, was at home when the woman brought Oscar; he said that at this point Oscar was covered in blood, and he was convinced the cat would have to be put down. He and Oscar's other owner, Kate Allan, took him to their local veterinarian Peter Haworth.\n\nPeter Haworth, a vet at the New Era Veterinary Hospital in Jersey, dressed Oscar's wounds and administered cat painkillers making him comfortable within minutes. Haworth then referred Allan and Nolan to the Surrey-based neuro-orthopaedic surgeon Noel Fitzpatrick. There was a lot of communication between the Irish surgeon and the Jersey owners. After looking at x-rays and pictures Fitzpatrick decided Oscar would be an ideal patient partly due to his young age. Oscar was then flown to the United Kingdom mainland by air cargo although he had to stay in his box for eight hours during the journey.\n\nOscar's owners did a lot of \"soul-searching\" before deciding to go ahead with the operation. Kate Allan later said that the cause for her uncertainty was that the kind of operation planned had never been done before. Although the operation carried out by Noel Fitzpatrick was a world first, it mimics a natural process, being similar to the way deer grow antler bones, in the manner that the implants grow through the skin. The implants were both custom-made to fit into holes drilled into Oscar's ankle bones. They are known as intraosseous transcutaneous amputation prosthetics (ITAPs) and were developed by Professor Gordon Blunn and Dr. Catherine Pendegrass of University College London's Centre for Biomedical Engineering. They have a honeycomb structure which enables skin to bond with the implant to prevent infection. The implants are placed into the drilled holes which then allow for a \"sock\" to be fitted over them.\n\nThe ITAP technology is currently being tested on humans and a prosthetic has been made for a woman injured in the July 2005 London bombings. Fitzpatrick has said he would welcome a collaborative approach with other surgeons working on human amputations.\n\nIn August 2012, as a result of a reoccurring infection in Oscar's right ankle, the ITAP snapped at the point where the titanium rod exits his stump. Peter Haworth of New Era Veterinary Hospital, Jersey, once again made Oscar comfortable while possible treatment options were explored. Oscar returned to Fitzpatrick Referrals in 2013 where veterinary surgeon Noel Fitzpatrick performed a 2-hour operation to implant a Perfits (Percutaneous Fixation to Skeleton) amputation endoprosthesis directly into Oscar's shinbone. A new exoprosthesis – or foot – needed to be developed for Oscar, as the removal of his ankle meant he could no longer wear a blade.\n\n\"The Bionic Vet\" is a BBC documentary following the work of Fitzpatrick which aired on BBC1 on 30 June 2010. The programme showed Oscar walking with prototype feet made for him by engineers at Salford University. Footage not shown on the programme of Oscar with a later set of better-designed feet was uploaded on to YouTube on 18 June 2010.\nAn update video with the vet involved showed Oscar's new feet and explained how they are designed to snap at a break point on the 'blade' rather than within the foot if he gets into difficulty.\n\nAn update on Oscar's progress was given in the Channel 4 television series \"The Supervet\". The television series follows the work of veterinary surgeon Noel Fitzpatrick and his practice Fitzpatrick Referrals. In Episode 1, broadcast on 7 May 2014, Vet Noel Fitzpatrick was shown fitting Oscar with his new foot following his recent surgery to replace the snapped ITAP.\n\nOscar holds two Guinness World Records, one for being the first animal with two bionic leg implants, and the other for being the first animal to receive implants into its moving joints.\n\n"}
{"id": "48423511", "url": "https://en.wikipedia.org/wiki?curid=48423511", "title": "Phiwa Nkambule", "text": "Phiwa Nkambule\n\nPhiwa Nkambule (born January 24, 1992) is an internet entrepreneur best known for co-founding and leading Riovic as its chief executive officer.\n\nPhiwa Nkambule was born in Manzini where he also spent his childhood. In 2006, as a 14-year-old, he began fixing and building computers with his uncle in a small township in Swaziland. Nkambule moved to South Africa in 2007 for academic purposes. Phiwa was a law student at the University of Pretoria before quitting to start his first technology company Cybatar from his garage in 2014. It was at the university where he taught himself web and app development.\n\nBefore leaving the University of Pretoria Phiwa attempted to work with the Swaziland National Library and the Manzini Regional Education Office in 2013 but was rejected. After dropping out of university in 2014 Nkambule founded Cybatar, a technology company focused on fuel delivery from his garage in Pretoria, South Africa.\n\nIn 2015 Nkambule co-founded Riovic, an insurance technology company. The company owns and operates online platforms that connect consumers with insurance, credit and investments. He was invited to deliver a keynote address on Digital Technologies in Insurance at the 13th International Microinsurance Conference in Peru, South America in November 2017.\n\nOn 24 October 2015 he released the first tuition crowdfunding platform in South Africa in the wake of the FeesMustFall protests that saw the country's tertiary institutions shutdown to help save students from tuition debt. He also launched a free online learning platform for digital skills aimed at reducing youth unemployment rate in South Africa.\n\nIn June 2018, Phiwa Nkambule was named in the Forbes Africa 30 Under 30 list of most promising entrepreneurs in the technology category. In October he was named in Destiny Man’s Power of 40 list, a list of 40 trailblazers under the age of 40.\n\n"}
{"id": "18466294", "url": "https://en.wikipedia.org/wiki?curid=18466294", "title": "Photo–Dember effect", "text": "Photo–Dember effect\n\nIn semiconductor physics, the photo–Dember effect (named after its discoverer ) is the formation of a charge dipole in the vicinity of a semiconductor surface after ultra-fast photo-generation of charge carriers.\n\nOne of the main applications of the photo–Dember effect is the generation of terahertz (THz) radiation pulses for terahertz time-domain spectroscopy. This effect is present in most semiconductors but it is particularly strong in narrow-gap semiconductors (mainly arsenides and antimonides) such as InAs and InSb owing to their high electron mobility. The photo–Dember terahertz emission should not be confused with the surface field emission, which occurs if the surface energy bands of a semiconductor fall between its valence and conduction bands, which produces a phenomenon known as Fermi level pinning, causing, at its time, band bending and consequently the formation of a depletion or accumulation layer close to the surface which contributes to the acceleration of charge carriers. These two effects can contribute constructively or destructively for the dipole formation depending on the direction of the band-bending.\n\n"}
{"id": "1990919", "url": "https://en.wikipedia.org/wiki?curid=1990919", "title": "Regulator (automatic control)", "text": "Regulator (automatic control)\n\nIn automatic control, a regulator is a device which has the function of maintaining a designated characteristic. It performs the activity of managing or maintaining a range of values in a machine. The measurable property of a device is managed closely by specified conditions or an advance set value; or it can be a variable according to a predetermined arrangement scheme. It can be used generally to connote any set of various controls or devices for regulating or controlling items or objects.\n\nExamples are a voltage regulator (which can be a transformer whose voltage ratio of transformation can be adjusted, or an electronic circuit that produces a defined voltage), a pressure regulator, such as a diving regulator, which maintains its output at a fixed pressure lower than its input, and a fuel regulator (which controls the supply of fuel).\n\nRegulators can be designed to control anything from gases or fluids, to light or electricity. Speed can be regulated by electronic, mechanical, or electro-mechanical means. Such instances include; \n\n"}
{"id": "22940420", "url": "https://en.wikipedia.org/wiki?curid=22940420", "title": "Roentgen stereophotogrammetry", "text": "Roentgen stereophotogrammetry\n\nRoentgen stereophotogrammetry (RSA) is a highly accurate technique for the assessment of three-dimensional migration and micromotion of a joint replacement prosthesis relative to the bone it is attached to. It was introduced in 1974 by Goran Selvic.\n\nSeveral studies have found implant migration to be predictive of long-term implant survival and, for most devices, measurement over 2 years might therefore provide a surrogate outcome measure with relatively low numbers of subjects, e.g. from 15 to 25 patients in each group in randomized studies. A smaller number of subjects can be used in these studies as a consequence of the high accuracy of the measurement technique. Because of this, RSA is an important technique in early clinical trials for screening new joint replacement prostheses.\n\nTo achieve the high accuracy, the following steps are carried out: Small radio opaque markers are introduced in the bone and attached to the prosthesis to serve as well-defined artificial landmarks. Two synchronised x-ray foci are used to obtain a stereo image of the bone and the prosthesis. The positions of the foci are assessed using a calibration object that holds tantalum markers at accurately known positions. The coordinates of the bone and prosthesis markers are accurately measured and the three-dimensional position of the markers is reconstructed using software. The change in the position (translation and rotation) of the prosthesis markers relative to the bone markers is then determined. The reported accuracy of RSA ranges between 0.05 and 0.5 mm for translations and between 0.15˚ and 1.15˚ for rotations (95% confidence interval). New RSA techniques that avoid the need for attaching markers to the prosthesis have been introduced.\n\n\n"}
{"id": "48492125", "url": "https://en.wikipedia.org/wiki?curid=48492125", "title": "SECU-3", "text": "SECU-3\n\nSECU-3 is an internal combustion engine control unit. Open source project (drawings, schematic diagrams, source code etc. are open). Anyone can take part in the project and can access all information without registration.\n\nDevice controls the ignition, fuel injection and various other actuators of the internal combustion engine (ICE) and vehicle. In particular, it is capable of controlling the carburetor's choke using a stepper motor (auto choke), thus controlling RPM when engine is warming up. Manages AFR on the carburetor (like AXTEC AFR systems), idle cut off and power valve on carburetor, electric fuel pump, stepper gas valve with oxygen sensor loopback etc. Unique opportunities for reassigning the I/O functions. Smooth speed control of the cooling fan motor. The ability to edit the main settings and maps in real time (when engine is running) and switching between 2 or 4 sets of maps. And other features and functions (see below).\n\nCurrently, there are five modifications of the unit:\n\nDevice performed on the 8-bit AVR microcontroller ATMega644, with 64kB memory (ROM), 4kB random access memory (RAM), and operates at a clock frequency of 20 MHz. It includes analog and digital inputs, chip for preprocessing signal from the knock sensor (KS) (except SECU-3 Lite and Micro units), a signal conditioner for reference VR sensor (except SECU-3 Micro unit), a signal conditioner for the crankshaft position (CKP) sensor, interface with a computer and outputs for actuators control.\n\nStructural diagram of the system with SECU-3T unit:\n\nStructural diagram of the system with SECU-3L unit is shown on the following picture:\n\nStructural diagram of the system with SECU-3 Micro unit:\nExample of wiring diagram of the SECU-3T unit for controlling of simultaneous or semi-sequential fuel injection on the 4-cylinder engine is shown on the picture below.\nHi-z injectors and stepper IAC valve are used. On the right side of picture we can see external connector functions which should be remapped to specified values. It is done in the SECU-3 Manager software.\nThe first version of SECU-3 was launched in October 2007 and successfully works on the author's (A.Shabelnikov) vehicle for now.\nSince then, the project has received a lot of new features and synchronization methods. First discussing of the project was started in 2007 in one topic on the iXBT conference. Since Dec. 2010 discussion moved to the forum on diyefi.org. In 2013 own project's forum had been opened.\nThe system has evolved from the ignition control to the engine management system (ECU). The project is supported by author all the time.\n\nContinue to develop and extend fuel injection features and algorithms (inter alia, full-sequential injection support). Also, author works on software for the SECU-3i unit.\n\nFeatures of the current firmware related to fuel injection:\n\nGPL, TAPR OHL with one addition: developments can not be used in commercial purposes without written approval of author (according to information from the official site).\n\n\nAdditional features:\n\n"}
{"id": "3608414", "url": "https://en.wikipedia.org/wiki?curid=3608414", "title": "Snow White design language", "text": "Snow White design language\n\nThe Snow White design language is an industrial design language which was developed by Hartmut Esslinger's Frog Design. Used by Apple Computer from 1984 to 1990, the scheme has vertical and horizontal stripes for decoration, ventilation, and the illusion that the computer enclosure is smaller than it actually is.\n\nThe design language boosted Apple’s global reputation, set design trends for the computer industry, and molded the perception of computers in the manufacturing and business world.\n\nAmong other design features, Esslinger's presentation of the Apple logo—a three-dimensional logo inlaid into the product case with the product name printed onto its surface—was included on nearly every product for several years.\n\nIn 1982, Apple officials looked outside the company and indeed the country for a designer who could help them establish the firm as a world-class company.\n\nSnow White refers to the seven projects code-named after the Seven Dwarves on which the new design language was to be applied. Several designers were courted by Apple under the Snow White project to see what they would come up with for the seven products (of which there were actually eight). The winner ultimately was Esslinger and the resulting style assumed the project’s code name.\n\nThe Apple IIc computer, and its peripherals, were the first Snow White design.\n\nInitially, Snow White debuted in a creamy off-white color known at Apple as \"Fog\" but later other products moved to the warm gray \"Platinum\" color, lighter than the previous Apple \"Putty\" color, used throughout the Apple product line from 1987 on. Esslinger favored a bright-white color originally for the IIc, but Jerry Manock successfully argued that it would attract fingerprints. Nevertheless, Esslinger detested the original Apple beige color and insisted all Snow White-styled products use the same off-white color as the IIc. Until the change to Platinum, no Snow White designs appeared in any other color, except for the Hard Disk 20SC in order to better match the beige color of the Macintosh Plus beneath which it was designed to sit.\n\nBeginning in 1990, the Apple Industrial Design Group gradually altered and phased out the use of the Snow White language.\n\nThe distinguishing characteristics originated by the Snow White design language, in contrast to the original Apple industrial design style, include the following:\n\n\nAny or all of these features indicate a Snow White Frog Design influence over an otherwise Apple-designed product. In particular the first official implementation, the Apple IIc, does not represent the complete set of design elements, while the Macintosh II includes all of them. Later, the Macintosh LC began to phase out some of the design elements.\n\nApple products designed in the Snow White theme (all used the “Platinum” gray color scheme except as noted):\n\n\nMost Apple Displays introduced between 1984 and 1994 also used Snow White, except those specifically designed to match the Apple II series.\n\nAll Apple ADB keyboards and mice introduced between 1986 and 1993 were Snow White designs.\n\n\nBoth the 100- and 200-series PowerBooks and accessories were intended to tie into the rest of the Apple desktop products using the corporate Snow White design language. However, the light colors and decorative recessed lines did not seem appropriate for the scaled-down designs. In addition to adopting the darker grey color scheme which co-ordinated with the official corporate look, they also adopted a raised series of ridges mimicking the indented lines on the desktops. These early PowerBooks would be the last to use the aging Snow White look and the only ones to make such a radical adaptation of it.\n\n\n"}
{"id": "576681", "url": "https://en.wikipedia.org/wiki?curid=576681", "title": "Speedometer", "text": "Speedometer\n\nA speedometer or a speed meter is a gauge that measures and displays the instantaneous speed of a vehicle. Now universally fitted to motor vehicles, they started to be available as options in the 1900s, and as standard equipment from about 1910 onwards. Speedometers for other vehicles have specific names and use other means of sensing speed. For a boat, this is a pit log. For an aircraft, this is an airspeed indicator.\n\nCharles Babbage is credited with creating an early type of a speedometer, which was usually fitted to locomotives.\n\nThe electric speedometer was invented by the Croatian Josip Belušić in 1888 and was originally called a velocimeter.\n\nOriginally patented by Otto Schultze on October 7, 1902, it uses a rotating flexible cable usually driven by gearing linked to the output of the vehicle's transmission. The early Volkswagen Beetle and many motorcycles, however, use a cable driven from a front wheel.\n\nWhen the vehicle is in motion, a speedometer gear assembly turns a speedometer cable, which then turns the speedometer mechanism itself. A small permanent magnet affixed to the speedometer cable interacts with a small aluminum cup (called a \"speedcup\") attached to the shaft of the pointer on the analogue speedometer instrument. As the magnet rotates near the cup, the changing magnetic field produces eddy currents in the cup, which themselves produce another magnetic field. The effect is that the magnet exerts a torque on the cup, \"dragging\" it, and thus the speedometer pointer, in the direction of its rotation with no mechanical connection between them.\n\nThe pointer shaft is held toward zero by a fine torsion spring. The torque on the cup increases with the speed of rotation of the magnet. Thus an increase in the speed of the car will twist the cup and speedometer pointer against the spring. The cup and pointer will turn until the torque of the eddy currents on the cup are balanced by the opposing torque of the spring, and then stop. Given the torque on the cup is proportional to the car's speed, and the spring's deflection is proportional to the torque, the angle of the pointer is also proportional to the speed, so that equally spaced markers on the dial can be used for gaps in speed. At a given speed, the pointer will remain motionless and pointing to the appropriate number on the speedometer's dial.\n\nThe return spring is calibrated such that a given revolution speed of the cable corresponds to a specific speed indication on the speedometer. This calibration must take into account several factors, including ratios of the tailshaft gears that drive the flexible cable, the final drive ratio in the differential, and the diameter of the driven tires.\n\nOne of the key disadvantages of the eddy current speedometer is that it cannot show the vehicle speed when running in reverse gear since the cup would turn in the opposite direction - in this scenario the needle would be driven against its mechanical stop pin on the zero position.\n\nMany modern speedometers are electronic. In designs derived from earlier eddy-current models, a rotation sensor mounted in the transmission delivers a series of electronic pulses whose frequency corresponds to the (average) rotational speed of the driveshaft, and therefore the vehicle's speed, assuming the wheels have full traction. The sensor is typically a set of one or more magnets mounted on the output shaft or (in transaxles) differential crownwheel, or a toothed metal disk positioned between a magnet and a magnetic field sensor. As the part in question turns, the magnets or teeth pass beneath the sensor, each time producing a pulse in the sensor as they affect the strength of the magnetic field it is measuring. Alternatively,particularly in vehicles with multiplex wiring, some manufacturers use the pulses coming from the ABS wheel sensors which communicate to the instrument panel via the CAN Bus. Most modern electronic speedometers have the additional ability over the eddy current type to show the vehicle speed when moving in reverse gear.\n\nA computer converts the pulses to a speed and displays this speed on an electronically controlled, analog-style needle or a digital display. Pulse information is also used for a variety of other purposes by the ECU or full-vehicle control system, e.g. triggering ABS or traction control, calculating average trip speed, or to increment the odometer in place of it being turned directly by the speedometer cable.\n\nAnother early form of electronic speedometer relies upon the interaction between a precision watch mechanism and a mechanical pulsator driven by the car's wheel or transmission. The watch mechanism endeavors to push the speedometer pointer toward zero, while the vehicle-driven pulsator tries to push it toward infinity. The position of the speedometer pointer reflects the relative magnitudes of the outputs of the two mechanisms.\n\nTypical bicycle speedometers measure the time between each wheel revolution, and give a readout on a small, handlebar-mounted digital display. The sensor is mounted on the bike at a fixed location, pulsing when the spoke-mounted magnet passes by. In this way, it is analogous to an electronic car speedometer using pulses from an ABS sensor, but with a much cruder time/distance resolution - typically one pulse/display update per revolution, or as seldom as once every 2–3 seconds at low speed with a 26-inch (2.07m circumference, without tire) wheel. However, this is rarely a critical problem, and the system provides frequent updates at higher road speeds where the information is of more importance. The low pulse frequency also has little impact on measurement accuracy, as these digital devices can be programmed by wheel size, or additionally by wheel or tire circumference in order to make distance measurements more accurate and precise than a typical motor vehicle gauge. However these devices carry some minor disadvantage in requiring power from batteries that must be replaced every so often in the receiver (AND sensor, for wireless models), and, in wired models, the signal being carried by a thin cable that is much less robust than that used for brakes, gears, or cabled speedometers.\n\nOther, usually older bicycle speedometers are cable driven from one or other wheel, as in the motorcycle speedometers described above. These do not require battery power, but can be relatively bulky and heavy, and may be less accurate. The turning force at the wheel may be provided either from a gearing system at the hub (making use of the presence of e.g. a hub brake, cylinder gear or dynamo) as per a typical motorcycle, or with a friction wheel device that pushes against the outer edge of the rim (same position as rim brakes, but on the opposite edge of the fork) or the sidewall of the tyre itself. The former type are quite reliable and low maintenance but need a gauge and hub gearing properly matched to the rim and tyre size, whereas the latter require little or no calibration for a moderately accurate readout (with standard tyres, the \"distance\" covered in each wheel rotation by a friction wheel set against the rim should scale fairly linearly with wheel size, almost as if it were rolling along the ground itself) but are unsuitable for off-road use, and must be kept properly tensioned and clean of road dirt to avoid slipping or jamming.\n\nMost speedometers have tolerances of some ±10%, mainly due to variations in tire diameter. Sources of error due to tire diameter variations are wear, temperature, pressure, vehicle load, and nominal tire size. Vehicle manufacturers usually calibrate speedometers to read high by an amount equal to the average error, to ensure that their speedometers never indicate a lower speed than the actual speed of the vehicle, to ensure they are not liable for drivers violating speed limits.\n\nExcessive speedometer error after manufacture can come from several causes but most commonly is due to nonstandard tire diameter, in which case the error is\n\nformula_1\n\nNearly all tires now have their size shown as \"T/A_W\" on the side of the tire (See: Tire code), and the tire's\n\nformula_2\n\nformula_3\n\nFor example, a standard tire is \"185/70R14\" with diameter = 2*185*(70/100)+(14*25.4) = 614.6 mm (185x70/1270 + 14 = 24.20 in). Another is \"195/50R15\" with 2*195*(50/100)+(15*25.4) = 576.0 mm (195x50/1270 + 15 = 22.68 in). Replacing the first tire (and wheels) with the second (on 15\" = 381 mm wheels), a speedometer reads 100 * (1-(576/614.6)) = 100 * (1 - 22.68/24.20) = 6.28% higher than the actual speed. At an actual speed of 100 km/h (60 mph), the speedometer will indicate 100 x 1.0628 = 106.28 km/h (60 * 1.0628 = 63.77 mph), approximately.\n\nIn the case of wear, a new \"185/70R14\" tyre of 620 mm (24.4 inch) diameter will have ≈8 mm tread depth, at legal limit this reduces to 1.6 mm, the difference being 12.8 mm in diameter or 0.5 inches which is 2% in 620 mm (24.4 inches).\n\nIn many countries the legislated error in speedometer readings is ultimately governed by the United Nations Economic Commission for Europe (UNECE) Regulation 39, which covers those aspects of vehicle type approval that relate to speedometers. The main purpose of the UNECE regulations is to facilitate trade in motor vehicles by agreeing uniform type approval standards rather than requiring a vehicle model to undergo different approval processes in each country where it is sold.\n\nEuropean Union member states must also grant type approval to vehicles meeting similar EU standards. The ones covering speedometers are similar to the UNECE regulation in that they specify that:\n\n\nThe standards specify both the limits on accuracy and many of the details of how it should be measured during the approvals process, for example that the test measurements should be made (for most vehicles) at 40, 80 and 120 km/h, and at a particular ambient temperature and road surface. There are slight differences between the different standards, for example in the minimum accuracy of the equipment measuring the true speed of the vehicle.\n\nThe UNECE regulation relaxes the requirements for vehicles mass-produced following type approval. At Conformity of Production Audits the upper limit on indicated speed is increased to 110 percent plus 6 km/h for cars, buses, trucks and similar vehicles, and 110 percent plus 8 km/h for two- or three-wheeled vehicles that have a maximum speed above 50 km/h (or a cylinder capacity, if powered by a heat engine, of more than 50 cm³). European Union Directive 2000/7/EC, which relates to two- and three-wheeled vehicles, provides similar slightly relaxed limits in production.\n\nThere were no Australian Design Rules in place for speedometers in Australia prior to July 1988. They had to be introduced when speed cameras were first used. This means there are no legally accurate speedometers for these older vehicles. All vehicles manufactured on or after 1 July 2007, and all models of vehicle introduced on or after 1 July 2006, must conform to UNECE Regulation 39.\n\nThe speedometers in vehicles manufactured before these dates but after 1 July 1995 (or 1 January 1995 for forward control passenger vehicles and off-road passenger vehicles) must conform to the previous Australian design rule. This specifies that they need only display the speed to an accuracy of +/- 10% at speeds above 40 km/h, and there is no specified accuracy at all for speeds below 40 km/h.\nAll vehicles manufactured in Australia or imported for supply to the Australian market must comply with the Australian Design Rules.\n\nThe amended Road Vehicles (Construction and Use) Regulations 1986 permits the use of speedometers that meet either the requirements of EC Council Directive 75/443 (as amended by Directive 97/39) or UNECE Regulation 39.\n\nThe Motor Vehicles (Approval) Regulations 2001 permits single vehicles to be approved. As with the UNECE regulation and the EC Directives, the speedometer must never show an indicated speed less than the actual speed. However it differs slightly from them in specifying that for all actual speeds between 25 mph and 70 mph (or the vehicles' maximum speed if it is lower than this), the indicated speed must not exceed 110% of the actual speed, plus 6.25 mph.\n\nFor example, if the vehicle is actually travelling at 50 mph, the speedometer must not show more than 61.25 mph or less than 50 mph.\n\nFederal standards in the United States allow a maximum 5 mph error at a speed of 50 mph on speedometer readings for commercial vehicles. Aftermarket modifications, such as different tire and wheel sizes or different differential gearing, can cause speedometer inaccuracy.\n\nOn September 1, 1979 the NHTSA required speedometers to have special emphasis on 55 mph and display no more than a maximum speed of 85 mph. On March 25, 1982 the NHTSA revoked the rule because no \"significant safety benefits\" could come from maintaining the standard.\n\nGPS devices are positional speedometers, based on how far the receiver has moved since the last measurement. Its speed calculations are not subject to the same sources of error as the vehicle's speedometer (wheel size, transmission/drive ratios). Instead, the GPS's positional accuracy, and therefore the accuracy of its calculated speed, is dependent on the satellite signal quality at the time. Speed calculations will be more accurate at higher speeds, when the ratio of positional error to positional change is lower. The GPS software may also use a moving average calculation to reduce error. Some GPS devices do not take into account the vertical position of the car so will under report the speed by the road's gradient.\n\nAs mentioned in the satnav article, GPS data has been used to overturn a speeding ticket; the GPS logs showed the defendant traveling below the speed limit when they were ticketed. That the data came from a GPS device was likely less important than the fact that it was logged; logs from the vehicle's speedometer could likely have been used instead, had they existed.\n\n\n"}
{"id": "11372954", "url": "https://en.wikipedia.org/wiki?curid=11372954", "title": "Stock obsolescence", "text": "Stock obsolescence\n\nObsolete stock or stock obsolescence calculations are done by companies to determine how much of their inventory (stock) on hand is unlikely to be used in the future.\n\nThe financial value of stock obsolescence that is calculated can be entered into a general ledger system to create a \"stock obsolescence provision\" which can reduce the tax liability of a company. For this reason, a systematic and auditable approach to designing a stock obsolescence report should be used. Estimation of stock obsolescence without any traceable calculations will probably not be acceptable to an auditor.\n\nTypically, a stock obsolescence report uses the value of \"stock on hand\" as a starting point, and then reduces this value based on the potential that stock will be used up in the future. The higher the probability that stock will be used in the future, the more the on-hand stock value can be reduced. Sometimes a historical usage of the item can also reduce the value, in this case, the more recently the item was used, the more the on-hand value can be reduced.\n\nThe formulae that calculate how much the on-hand value can be reduced by may vary from company to company and are normally described in a general way in the Generally Accepted Accounting Practices (GAAP) for that company or country. For example one formula may be: \"If there is any future usage of the item in the next 3 months then reduce the value by 100%, if there is usage in the next 6 months then reduce by 50%, and if it is only going to be used in a year's time then reduce by 10%, if it has been used in the past 6 months then reduce by 70%, if there has been usage in the past year then reduce by 30%.\"\n\nSome formulae may also take into account the volume used e.g.: reduce the on-hand value by the percentage of product used in the past 6 months.\n\nThis information was used, with permission, from the following website: 'timelineforum: How to design a Stock Obsolescence Report'.\n"}
{"id": "41837", "url": "https://en.wikipedia.org/wiki?curid=41837", "title": "Telecommunications link", "text": "Telecommunications link\n\nIn telecommunications a link is a communication channel that connects two or more devices. This link may be an actual physical link or it may be a logical link that uses one or more physical links or shares a physical link with other telecommunications links.\n\nA telecommunications link is generally one of several types of information transmission paths such as those provided by communication satellites, terrestrial radio communications infrastructure and computer networks to connect two or more points.\n\nThe term \"link\" is widely used in computer networking to refer to the communications facilities that connect nodes of a network. When the link is a logical link the type of physical link should always be specified (e.g., data link, uplink, downlink, fiber optic link, point-to-point link, etc.)\n\nA point-to-point link is a dedicated link that connects exactly two communication facilities (e.g., two nodes of a network, an intercom station at an entryway with a single internal intercom station, a radio path between two points, etc.).\n\nBroadcast links connect two or more nodes and support \"broadcast transmission\", where one node can transmit so that all other nodes can receive the same transmission. Ethernet is an example.\n\nAlso known as a \"multidrop\" link, a multipoint link is a link that connects \"two or more\" nodes. Also known as general topology networks, these include ATM and Frame Relay links, as well as X.25 networks when used as links for a network layer protocol like IP.\n\nUnlike broadcast links, there is no mechanism to efficiently send a single message to all other nodes without copying and retransmitting the message.\n\nA point-to-multipoint link (or simply a \"multipoint\") is a specific type of multipoint link which consists of a central connection endpoint (CE) that is connected to multiple peripheral CEs. Any transmission of data that originates from the central CE is received by all of the peripheral CEs while any transmission of data that originates from any of the peripheral CEs is only received by the central CE.\n\nLinks are often referred to by terms which refer to the ownership and / or accessibility of the link.\n\n\n\nA forward link is the link from a fixed location (e.g., a base station) to a mobile user. If the link includes a communications relay satellite, the forward link will consist of both an uplink (base station to satellite) and a downlink (satellite to mobile user).\n\nThe reverse link (sometimes called a \"return channel\") is the link from a mobile user to a fixed base station.\n\nIf the link includes a communications relay satellite, the reverse link will consist of both an uplink (mobile station to satellite) and a downlink (satellite to base station) which together constitute a half hop.\n\n\n"}
{"id": "1693174", "url": "https://en.wikipedia.org/wiki?curid=1693174", "title": "Telenursing", "text": "Telenursing\n\nTelenursing refers to the use of telecommunications and information technology in the provision of nursing services whenever a large physical distance exists between patient and nurse, or between any number of nurses. As a field, it is part of telehealth and telemedicine, and has many points of contacts with other medical and non-medical applications, such as telediagnosis, teleconsultation, and telemonitoring. The field, however, is still being developed as the information on telenursing isn't comprehensive enough.\n\nTelenursing is achieving a large rate of growth in many countries, due to several factors: the preoccupation in driving down the costs of health care, an increase in the number of aging and chronically ill population, and the increase in coverage of health care to distant, rural, small or sparsely populated regions. Among its many benefits, telenursing may help solve increasing shortages of nurses; to reduce distances and save travel time, and to keep patients out of hospital. A greater degree of job satisfaction has been registered among telenurses.\n\nNursing informatics, a branch of health informatics, has been defined by Judith Rae Graves and Sheila Corcoran as \"a combination of computer science, information science, and nursing science designed to assist in the management and processing of nursing data, information, and knowledge to support the practice of nursing and the delivery of nursing care\". Telenursing is a potential application of nursing informatics and as such, nursing informatics has served as a critical background concept its development.\n\nOne of the most distinctive telenursing applications is home care. For example, patients who are immobilized, or live in remote or difficult to reach places, citizens who have chronic ailments, such as chronic obstructive pulmonary disease, diabetes, congestive heart disease, or debilitating diseases, such as neural degenerative diseases (Parkinson's disease, Alzheimer's disease or ALS), may stay at home and be \"visited\" and assisted regularly by a nurse via videoconferencing, internet or videophone. Other applications of home care are the care of patients in immediate post-surgical situations, the care of wounds, ostomies or disabled individuals. In normal home health care, one nurse is able to visit up to 5-7 patients per day. Using telenursing, one nurse can “visit” 12-16 patients in the same amount of time.\n\nA common application of telenursing is also used by call centers operated by managed care organizations, which are staffed by registered nurses who act as case managers or perform patient triage, information and counseling as a means of regulating patient access and flow and decrease the use of emergency rooms. McKesson is a leading telephone health service provider in the United States of America, as well as in Australia.\n\nTelephone triage refers to symptom or clinically-based calls. Clinicians perform symptom assessment by asking detailed questions about the patient's illness or injury. The clinician's task is to estimate and/or rule out urgent symptoms. They may use pattern recognition and other problem-solving process as well. Clinicians may utilize guidelines, in paper or electronic format, to determine how urgent the symptoms are. Telephone triage requires clinicians to determine if the symptoms are life-threatening, emergency, urgent, acute or non-acute. It may involve educating and advising clients, and making safe, effective, and appropriate dispositions—all by telephone. Telephone triage takes place in settings as diverse as emergency rooms, ambulance services, large call centers, physician offices, clinics, student health centers and hospices.\n\nAn international telenursing survey was completed in 2005, reporting that the 719 responding full-time and part-time registered nurses and advanced practice nurses worked as a telenurse in 36 countries around the world. 68% were reported to be working in the United States, compared to only 0.6% in Finland. Some of these 36 countries include Australia, Canada, Norway, United Kingdom, New Zealand, Iran, Sweden, and the Netherlands.\n\nIn Australia, telephone triages are conducted in Western Australia, Australian Capital Territory, Northern Territory, Victoria and Queensland. The first telenursing triage was conducted in Western Australia in 1999, where Triage nurses would estimate patient complexity and refer them to Fremantle Hospital. Due to the remoteness of the Australian landscape it is vital that residents living in rural areas have access to clinical support and care. Telenursing allows nurses to overcome the barriers of distance and gives them the opportunity assist those who are unable to access health care clinics or services due to either the late hour or the distance.\n\nTelenursing is fraught with legal, ethical and regulatory issues, as it happens with telehealth as a whole. In many countries, interstate and intercountry practice of telenursing is forbidden (the attending nurse must have a license both in their state/country of residence and in the state/country where the patient receiving telecare is located). The Nurse Licensure Compact helps resolve some of these jurisdiction issues. Legal issues such as accountability and malpractice, etc. are also still largely unsolved and difficult to address. Ethical issues include maintaining autonomy, maintaining a patients integrity as well as preventing harm to a patient.\n\nIn addition, there are many considerations related to patient confidentiality and safety of clinical data.\n\n\n"}
{"id": "8973605", "url": "https://en.wikipedia.org/wiki?curid=8973605", "title": "ThalesRaytheonSystems", "text": "ThalesRaytheonSystems\n\nThales-Raytheon Systems Company LLC (ThalesRaytheonSystems or TRS) is an aerospace and defence company co-headquartered in Massy, Paris, France and Fullerton, California, United States, and a 50:50 joint venture between Raytheon and Thales Group. ThalesRaytheon was formed in June, 2001, for the purpose of combining the radar and Command, Control, Communications, Computers and Intelligence or C4I systems efforts of the two firms.\n\nThales S.A. and Raytheon Company announced the creation of Thales Raytheon Systems on 16 December 2000.\n\nAt the time of its creation Thales Raytheon Systems had a world market share of around 40 percent in the provision of air defense command and control centers, air defense radars and battlefield surveillance systems.\n\n"}
{"id": "11977151", "url": "https://en.wikipedia.org/wiki?curid=11977151", "title": "Triconex", "text": "Triconex\n\nTriconex is both the name of a Schneider Electric brand that supplies products, systems and services for safety, critical control and turbomachinery applications and the name of its hardware devices that utilize its TriStation application software. Triconex products are based on patented Triple modular redundancy (TMR) industrial safety-shutdown technology. Today, Triconex TMR products operate globally in more than 11,500 installations, making Triconex the largest TMR supplier in the world.\n\nCompany History: The history of Triconex was published in a book called 'The History of a Safer World' by Gary L. Wilkinson. The company was founded in September, 1983 by Jon Wimer in Santa Ana, California and began operations in March, 1984. The business plan was written by Wimer and Peter Pitsker, an automation industry veteran and Stanford graduate. They presented the plan for a TMR (Triple Modular Redundant) based system that would improve the safety and reliability in industrial applications. Among the customers they targeted were the petro-chemical giants, such as Exxon, Shell, Chevron, and BP.\n\nPitsker and Wimer presented the business plan to Los Angeles based investor Chuck Cole, who was also a professor at USC. Cole was interested, so he contacted his personal attorney, future two-time Los Angeles Mayor Richard Riordan. Riordan agreed to invest $50,000 and Cole's venture capital team matched it, providing the seed money for Triconex. After two years, however, the company nearly failed due to the expense and complications of testing a new safety system. In February, 1986, founder Wimer left the company and the board asked a seasoned executive, William K. Barkovitz to become CEO. Barkovitz ended up leading the company for 9 years. At the end of his term, Triconex became the leading safety system in a market it largely created, made acquisitions, and completed an IPO. In January, 1994, Triconex was acquired by British based SIEBE for 90 million dollars.\n\nThe hardware architect of the Tricon was Gary Hufton, the Software development manager was Glen Alleman. These managers, with Wing Toy (the lead engineering of the fault tolerant ESS telephone switch), led a small successful engineering team that built the first Tricon, sold in June, 1986. Soon after, Exxon became a customer and automation giant Honeywell agreed to distribute the Tricon. Among the software engineers who worked for Triconex were Phil Huber and Dennis Morin, who later left the company to found Wonderware, also based in Irvine California which became the world's leading supplier of Human Machine Interface (HMI). \n\nTriconex system is based on the TMR patented technology that supports up to SIL 3 and is usually used as a safety rather than control system.\n\nFault tolerance in the Tricon is achieved by means of a Triple-Modular Redundant(TMR) architecture. The Tricon provides error-free, uninterrupted control in the presence of either hard failures of components, or transient faults from internal or external sources.\nThe Tricon is designed with a fully triplicated architecture throughout, from the input modules through the Main Processors to the output modules. Every I/O module houses the circuitry for three independent legs.\nEach leg on the input modules reads the process data and passes that\ninformation to its respective Main Processor. The three Main Processors communicate with each other using a proprietary high-speed bus system called the TriBus. Once per scan, the three Main\nProcessors synchronize and communicate with their two neighbors over\nthe TriBus. The Tricon votes digital input data, compares output data, and sends copies of analog input data to each Main Processor.\nThe Main Processors execute the userwritten application and send outputs generated by the application to the output modules. In addition to voting the input data, the TriBus votes the output data. This is done on the output modules as close to the field as possible, in order to detect and compensate for any errors that could occur between the Tricon voting and the final output driven to the field.\n\nThe Triconex system usually consists of the following typical modules:\n\nThe Triconex main processors can communicate with the so-called TriStation 1131 application software to download, update and/or monitor programs. These programs are either written in:\nBesides, a Sequence of Events (SOE) recorder software and Diagnostic monitor software are implemented.\n\nIn December 2017 it was reported that the safety systems of an unidentified power station, believed to be in Saudi Arabia were compromised when the Triconex industrial safety technology made by Schneider Electric SE was targeted in what is believed to have been a state sponsored attack. The computer security company Symantec claimed that the malware, known as \"Triton\" exploited a vulnerability in computers running the Microsoft Windows operating system.\n\n"}
{"id": "3440272", "url": "https://en.wikipedia.org/wiki?curid=3440272", "title": "UnionPay", "text": "UnionPay\n\nUnionPay (), also known as China UnionPay () or by its abbreviation, CUP, is a Chinese financial services corporation headquartered in Shanghai, China. It provides bank card services and a major card scheme in mainland China. Founded on March 26, 2002, China UnionPay is an association for China's banking card industry, operating under the approval of the People's Bank of China (PBOC, central bank of China). It is also the only interbank network in China that links all the automatic teller machine (ATMs) of all banks throughout the country. It is also an electronic funds transfer at point of sale (EFTPOS) network. \n\nIt is the largest card payment organisation (debit and credit cards combined) in the world offering mobile and online payments based on total value of payment transactions, ahead of Visa and Mastercard. \n\nWith the approval of the People's Bank of China, China UnionPay was launched on March 26, 2002, in Shanghai by PBOC governor Dai Xianglong, The Industrial and Commercial Bank of China, the Agricultural Bank of China, the Bank of China and the China Construction Bank served as its first members. However, the concept of a unified Chinese bank card network dates back to 1993, with the formation of the \"Golden Card Project\" advocated by then-Chinese president Jiang Zemin. UnionPay is considered its descendant, although attempts at unifying China's various credit card and interbank networks have been in place since the 1990s.\n\nIn 2014, UnionPay was reported to have been contributing to capital flight from China through poorly regulated store front operations in Macau.\n\nIn 2005, UnionPay entered into agreements with other payment networks to increase acceptance around the world. Some major examples include:\n\n\nThe CUP logo originated in China before the establishment of the CUP network system. The red, blue, and green color block design represented the integration of cooperation, steady flow, and safety assurance. It is accompanied by the Chinese characters for \"UnionPay\" in white. The logo was first registered in 1997 and launched in the Shenzhen trial.\n\nChina UnionPay started a limited trial card distribution in March 2001. By January 2002, many banks and financial institutions began a larger trial in Beijing, Shanghai, Guangzhou, Hangzhou, Shenzhen and five other five cities , which gradually extended to the entire country.\n\nOn October 18, 2005, China UnionPay announced a new logo. The new card kept the three-colors of the old logo while other elements were adjusted. The new logo also featured increased use of English. At present, both card styles are in circulation, with the old UnionPay cards being gradually replaced.\n\nCUP was initially concerned that overseas merchants might fail to recognise the new logo and refuse to accept new-style UnionPay cards. Therefore, for a period, unified domestic debit and renminbi (RMB) single currency credit cards used the new logo, while international debit cards and dual currency credit cards used the old logo. From the beginning of 2009, dual-currency credit card banks began to gradually introduce the use of the new UnionPay logo.\n\nOn the introduction of EMV chips into China UnionPay cards, banks also introduced QuickPass (), a contactless smart card feature similar to MasterCard's PayPass or Visa's payWave. QuickPass is accepted in many supermarkets and fast food stores.\nQuickpass is also supported by several digital wallet providers such as Samsung Pay and Apple Pay.\n\nUnionPay is China's first financial-level pre-authorization service for secured transactions. The system allows payment for online shopping at any merchant that accepts UnionPay. In 2014, the total amount of cross-bank transactions of CUP card exceeded 41.1 trillion yuan.\n\nUnionPay cards can be used in 162 countries and regions around the world, making it the third-largest payment network by value of transactions processed, behind Visa and MasterCard. Some UnionPay credit cards are also affiliated with American Express, MasterCard or Visa, and they can be used abroad as an American Express, MasterCard or Visa. UnionPay debit cards, however, can only be used in the UnionPay network and other networks that have signed contracts with UnionPay. Since 2006, China UnionPay cards can be used in over 100 countries outside China.\n\nIn May 2005, Discover Network announced an alliance with China UnionPay Network. The two companies have signed a long-term agreement that allows acceptance of Discover Network brand cards at UnionPay ATMs and point-of-sale terminals in China and acceptance of China UnionPay cards on the PULSE network in the U.S. As of 1 November 2007, China UnionPay cards may be accepted where Discover Network Cards are accepted in the United States, Canada, Mexico, Central America and the Caribbean. As of early 2013, the cross acceptance agreement was expanded to support e-commerce or card-not-present transactions. In , PayPal announced a partnership with China UnionPay enabling the use of PayPal with UnionPay member cards. In 2015, China’s State Administration of Foreign Exchange (SAFE) placed a 100,000 yuan annual cap on overseas UnionPay (Issued by China's bank) cash withdrawals. In November 2017, Azoya teamed up with UnionPay to enable consumers in China to profit from the Black Friday online shopping festival via a cross-border marketing platform.\n\nUnionPay is the primary network of these Chinese banks:\n\n\nOther UnionPay-affiliated organizations include municipal commercial banks as well as rural credit cooperatives. \nOverall, there are 165 financial institutions that issue UnionPay cards.\n\nUnionPay had partnered with JETCO in Hong Kong and Macau until 1 January 2006. As of January 2013, Bank of East Asia and Citibank were the only banks allowed to independently issue UnionPay credit cards in Hong Kong and the mainland. HSBC and its subsidiary Hang Seng Bank independently issue UnionPay credit cards in Hong Kong, while they issue cards in the mainland in cooperation with local banks as noted above. Deutsche Bank only has co-issued cards, with no independently issued UnionPay credit cards.\n\nThe following eleven foreign banks have the right to issue UnionPay debit cards in China:\n\n\nUnionPay in other countries:\n\n\n\n"}
{"id": "202072", "url": "https://en.wikipedia.org/wiki?curid=202072", "title": "Very-small-aperture terminal", "text": "Very-small-aperture terminal\n\nA very small aperture terminal (VSAT) is a two-way satellite ground station with a dish antenna that is smaller than 3.8 meters. The majority of VSAT antennas range from 75 cm to 1.2 m. Data rates, in most cases, range from 4 kbit/s up to 16 Mbit/s. VSATs access satellites in geosynchronous orbit or geostationary orbit to relay data from small remote Earth stations (terminals) to other terminals (in mesh topology) or master Earth station \"hubs\" (in star topology).\n\nVSATs are used to transmit narrowband data (e.g., point-of-sale transactions using credit cards, polling or RFID data, or SCADA), or broadband data (for the provision of satellite Internet access to remote locations, VoIP or video). VSATs are also used for transportable, on-the-move (utilising phased array antennas) or mobile maritime communications.\n\nThe concept of the geostationary orbit was originated by Russian theorist Konstantin Tsiolkovsky, who wrote articles on space travel around the beginning of the 20th century. In the 1920s, Hermann Oberth and Herman Potocnik, also known as Herman Noordung, described an orbit at an altitude of whose period exactly matched the Earth's rotational period, making it appear to hover over a fixed point on the Earth's equator.\n\nArthur C. Clarke's October 1945 \"Wireless World\" article (called \"Extra-Terrestrial Relays: Can Rocket Stations Give World-wide Radio Coverage?\") discussed the necessary orbital characteristics for a geostationary orbit and the frequencies and power needed for communication.\n\nLive satellite communication was developed in the 1960s by NASA, which called it Syncom 1-3. It transmitted live coverage of the 1964 Olympics in Japan to viewers in the United States and Europe. On April 6, 1965, the first commercial satellite was launched into space, Intelsat I, nicknamed Early Bird.\n\nThe first commercial VSATs were C band (6 GHz) receive-only systems by Equatorial Communications using spread spectrum technology. More than 30,000 60 cm antenna systems were sold in the early 1980s. Equatorial later developed a C band (4/6 GHz) two-way system using 1 m x 0.5 m antennas and sold about 10,000 units in 1984–85.\n\nIn the early 80s, LINKABIT (the predecessor to Qualcomm and ViaSat) developed the world's first Ku-band (12–14 GHz) VSAT for Schlumberger to provide network connectivity for oil field drilling and exploration units. LINKABIT which had become part of M/A-COM went on to develop VSATs for enterprise customers such as Walmart, Holiday Inn, Chrysler, and General Motors. These enterprise terminals made up the vast majority of sites for the next 20 years for two-way data or telephony applications. A large VSAT network, with more than 12,000 sites, was deployed by Spacenet and MCI for the U.S. Postal Service in the 1980s. Today, the largest VSAT Ku-band network containing over 100,000 VSATs was deployed by and is operated by Hughes Communications for lottery applications.\n\nIn 2005, WildBlue (now ViaSat) started deploying VSAT networks deploying Ka-band. ViaSat launched the highest capacity satellite ever, ViaSat-1, in 2011 to expand the WildBlue base under its Exede brand. In 2007, Hughes Communications started deploying VSAT sites for consumers under its HughesNet brand on the Spaceway 3 satellite and later in 2012 on its EchoStar XXVII/Jupiter 1 satellite. By September 2014, Hughes became the first Satellite Internet Provider to surpass one million active terminals.\n\nMost VSAT networks are configured in one of these topologies:\n\nAdvances in technology have dramatically improved the price–performance ratio of fixed satellite service (FSS) over the past five years. New VSAT systems are coming online using technology that promise higher data rates for lower costs.\n\nFSS systems currently in orbit have a huge capacity with a relatively low price structure. FSS systems provide various applications for subscribers, including: telephony, fax, television, high-speed data communication services, Internet access, satellite news gathering (SNG), Digital Audio Broadcasting (DAB) and others. These systems provide high-quality service because they create efficient communication systems for both residential and business users.\n\n\nAll the outdoor parts on the dish are collectively called the ODU (Outdoor Unit), i.e., OMT to split signal between BUC and LNB. The IDU is effectively a modem, usually with ethernet port and 2 x F-connectors for the coax to BUC (Transmit) and from LNB (Receive). The Astra2Connect has an all-in-one OMT/BUC/LNA that looks like a Quad LNB in shape and size which mounts on a regular TV satellite mount. As a consequence it is only 500 mW compared with the normal 2W, thus is poorer in rain. Skylogic's Tooway system also uses an integrated OMT/BUC/LNB assembly called a transmit and receive integrated assembly (TRIA), which is 3W.\n\nA maritime VSAT has features that allow it to be operated on a ship at sea. A ship that is underway is in continuous motion in all axes. The antenna part of a marine VSAT system must be stabilized with respect to the horizon and true north as the ship moves beneath it. Motors and sensors are used to keep the antenna pointed accurately at the satellite. This enables it to transmit to and receive from the satellite whilst minimising losses and interference with adjacent satellites. New technology is emerging which allows a solid state device (flat panel) to electronically steer the antenna without moving parts, this new technology is in its infancy but will be a major game changer for the industry.\n\nInitially, stabilized satellite antennas were used on ships for reception of television signals. One of the first companies to manufacture stabilized VSAT antennas was SeaTel of Concord, California, which launched its first stabilized antenna in 1978. SeaTel dominates the supply of two-way VSAT stabilised antenna systems to the marine industry with almost 72% of the market in 2007 compared to Orbit's 17.6%. Initially, maritime VSAT was using single channel per carrier technology, which suited large-volume users like oil drilling rigs and oil platforms and large fleets of ships from one shipowner sailing within one or few satellite footprints. This changed when the company iDirect launched its IP-based time-division multiple access technology that dynamically allocated bandwidth to each ship for shared bandwidth, lowering the entry-level cost for getting maritime VSAT installed, which turned out to be of key importance to small to mid-sized fleets, and thus to the market acceptance of VSAT.\n\nAccording to the Maritime VSAT report issued by the Comsys Group, the market for stabilised maritime VSAT services (not including oil and gas rigs) reached more than $400 million in 2007. In 2010, COMSYS released its \"2nd Maritime VSAT Report\", where the market estimate had increased to $590 million in 2009 with predictions for 2010 at $850 million. The estimated size of the market in terms of vessels eligible to get VSAT was in this report set to in excess of 42.000 with just over 34.000 to go. The major companies market share in terms of number of vessels in service were in 2009 (2007 in parenthesis) according to these reports: Vizada: 17.6% (26.0%), Ship Equip: 11.0% (10.7%), Cap Rock 2.8% (2.9%), MTN 7.5% (6.4%), Stratos - % (3.6%), KVH 5.4% (- %) Elektrikom 4.9% (3.2%), Intelsat 3.4% (- %), Eutelsat 3.1%, NSSL 3.1%, Radio Holland 3.0%, Telemar 3.0%, DTS 2.6% and others accounted for 32.6% (27.7%). Many of the major providers have branded their maritime VSAT offerings such that Vizada offers its service through the Marlink division and the SeaLink and WaveCall products, OmniAccess, through their BroadBEAM products and Ship Equip calls its offering Sevsat.\n\nModern VSAT systems are a prime example of convergence, and hence require skills from both the RF and IP domains. VSAT-specific training includes:\n\n"}
{"id": "30701271", "url": "https://en.wikipedia.org/wiki?curid=30701271", "title": "Voder", "text": "Voder\n\nThe Bell Telephone Laboratory's Voder (from \"Voice Operating Demonstrator\") was the first attempt to electronically synthesize human speech by breaking it down into its acoustic components. It was invented by Homer Dudley in 1937–1938 and developed on his earlier work on the vocoder. The quality of the speech was limited; however, it demonstrated the synthesis of the human voice, which became one component of the vocoder used in voice communications for security and to save bandwidth.\nThe Voder synthesized human speech by imitating the effects of the human vocal tract. The operator could select one of two basic sounds by using a wrist bar. A buzz tone generated by a relaxation oscillator produced the voiced vowels and nasal sounds, with the pitch controlled by a foot pedal. A hissing noise produced by a white noise tube created the sibilants (voiceless fricative sounds). These initial sounds were passed through a bank of 10 band pass filters that were selected by keys; their outputs were combined, amplified and fed to a loudspeaker. The filters were controlled by a set of keys and a foot pedal to convert the hisses and tones into vowels, consonants, and inflections. Additional special keys were provided to make the plosive sounds such as \"p\" or \"d\", and the affrictive sounds of the \"j\" in \"jaw\" and the \"ch\" in \"cheese\". This was a complex machine to operate. After months of practice, a trained operator could produce recognizable speech.\n\nPerformances on the Voder were featured at the 1939 New York World's Fair and in San Francisco. Twenty operators were trained by Mrs. Helen Harper, particularly noted for her skill with the machine. The machine said the words \"Good afternoon, radio audience.\"\n\nThe Voder was developed from research into compression schemes for transmission of voice on copper wires and for voice encryption. In 1948, Werner Meyer-Eppler recognized the capability of the Voder machine to generate electronic music, as described in Dudley's patent.\n\nWhereas the vocoder analyzes speech, transforms it into electronically transmitted information, and recreates it, the voder generates synthesized speech by means of a console with fifteen touch-sensitive keys and a pedal. It basically consists of the \"second half\" of the vocoder, but with manual filter controls, and requires a highly trained operator.\n\n\n\n"}
{"id": "1053284", "url": "https://en.wikipedia.org/wiki?curid=1053284", "title": "Whistle mix", "text": "Whistle mix\n\nWhistle mix is a general term to refer to any pyrotechnic composition that emits a whistling sound when pressed into a tube and ignited. It is used as a rocket propellant, particularly in small bottle rockets. Whistle mix tends to be fast burning and brisant; therefore it is also used as burst charge in shells.\n\nA typical whistle mix is made from 70% potassium perchlorate and 30% sodium benzoate, measured by weight. The fuel in most whistle compositions is a salt of an organic acid. Compositions with chlorates and gallates were used historically, but have now been abandoned as prone to accidental ignition. These mixtures however, are less sensitive than the formerly used ones, which often contained mixtures with picric acid and potassium picrate. \n\nWhistle compositions tend to be particularly sensitive. To achieve the whistling behavior, the composition must be in a tube and be formed into a solid grain; it otherwise burns too rapidly and just explodes. The composition is typically compressed using an arbor or hydraulic press. Ramming with a mallet (which is acceptable for many other compositions) may result in an explosion.\n"}
{"id": "6263667", "url": "https://en.wikipedia.org/wiki?curid=6263667", "title": "Yaw-rate sensor", "text": "Yaw-rate sensor\n\nA yaw-rate sensor is a gyroscopic device that measures a vehicle’s angular velocity around its vertical axis. The angle between the vehicle's heading and vehicle actual movement direction is called slip angle, which is related to the yaw rate.\n\nThere are basically two types of Yaw rate sensors: piezoelectric type and micromechanical type.\n\nIn the piezoelectric type, the sensor is a \"tuning fork\"-shaped structure with four piezo elements (two on top and two below). During straight ahead driving, the upper ones produce no voltage as no Coriolis force acts. But in cornering, the rotational movement causes the upper part of the tuning fork to leave the oscillatory plane creating an alternating current voltage which is proportional to the yaw rate and oscillatory speed. The output signal's sign depends on the direction (left or right).\n\nIn the micromechanical type, the Coriolis acceleration is measured by a micro-mechanical capacitive acceleration sensor placed on an oscillating element. This acceleration is proportional to the product of yaw rate and the oscillatory velocity, which is maintained electronically at a constant value.\n\nA yaw-sensor is needed for Electronic stability control.\n\nYaw rate sensors are used in aircraft and in the electronic stability control systems of cars.\n\n"}
