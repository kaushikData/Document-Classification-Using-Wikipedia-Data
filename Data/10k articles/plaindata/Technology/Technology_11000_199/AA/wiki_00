{"id": "43099131", "url": "https://en.wikipedia.org/wiki?curid=43099131", "title": "AGARD-B wind tunnel model", "text": "AGARD-B wind tunnel model\n\nAGARD-B is a standard wind tunnel model (calibration model) that is used to verify, by comparison of test results with previously published data, the measurement chain in a wind tunnel.\nTogether with its derivative AGARD-C it belongs to a family of AGARD standard wind tunnel models. Its origin dates to the year 1952, and the Second Meeting of the AGARD Wind Tunnel and Model Testing Panel in Rome, Italy, when it was decided to define two standard wind tunnel model configurations (AGARD-A and AGARD-B) to be used for exchange of test data and comparison of test results of same models tested in different wind tunnels. The idea was to establish standards of comparison between wind tunnels and improve the validity of wind tunnel tests. \nAmong the standard wind tunnel models, AGARD model configuration B (AGARD-B) has become by far the most popular. Initially intended for the supersonic wind tunnels, the AGARD-B configuration has since been tested in many wind tunnels at a wide range of Mach numbers, from low subsonic (Mach 0.1), through transonic (Mach 0.7 to 1.4) to hypersonic (Mach 8 and above). Therefore, a considerable database of test results is available.\n\nAGARD-B () is a body-wing configuration. All its dimensions are given in terms of the body diameter \"D\" so that the model can be produced in any scale, as appropriate for a particular wind tunnel. \nThe body is an 8.5 diameters long solid of revolution consisting of a 5.5 diameters long cylindrical segment and a nose with a length of 3 diameters and having a local radius defined by the equation .\n\nThe wing is a delta in the form of an equilateral triangle with a span of four body diameters. Wing section is a symmetric cylindrical arc with a relative thickness t/c of 4%. Leading and trailing edges of the wing should be rounded with a radius equal to . However, this specification is unclear. It is obvious that the specified radius can not be applied near the wingtips, or large deformations in the plan form of the wing would occur. In the past, this part of the specification was interpreted in different ways by model designers which led to small differences in shapes of the tested models. The recommended solution is to have the leading- and trailing-edge radii of at the theoretical root chord and to decrease the radii towards the wing tips proportionally to the local chord.\n\nA support sting to be used with the AGARD-B model was defined as well. The initial specification of the model called for a sting having a diameter of and a length of . In the revised specification the length of the sting was changed to in order to reduce sting interference, but at that moment a number of wind tunnel tests had already been made. Therefore, published test results for the AGARD-B models do not all correspond to theoretical model configuration.\n\nThe drag characteristics of the AGARD-B model were found to be somewhat sensitive to the boundary layer transition on the model. In order to reduce the scatter of results, in some wind tunnel facilities the model was tested with boundary layer transition trips near the leading edges of the wing and the nose of the body. On the other hand, a number of wind tunnel tests was made without fixed transition. Drag results with and without the fixed boundary layer transition differ, which should not be neglected when comparing test results from different wind tunnel laboratories.\n\nIn some wind tunnel laboratories, AGARD-B was tested in non-standard configurations, e.g. as a half-model (half-span model).\n\nSome free-flight tests of the AGARD-B model were performed. For these tests, the standard geometry was modified by adding, at the rear end of the body, two triangular vertical stabilisers, one on the ventral and one on the dorsal side of the body. Size of the vertical stabilizers was 50% of the wing size, i.e. their span was .\n\nAGARD-B standard model is intended primarily for the measurement of aerodynamic forces and moments. Test results are most often presented in the form of nondimensional aerodynamic coefficients in the wind axes system. Reference area for the calculation of the coefficients is the theoretical wing area . Reference length for the pitching moment coefficient is the mean aerodynamic chord (m.a.c.) equal to while the reference length for the yawing and rolling moment coefficients and is the wing span . Moments are reduced to a point in the plane of symmetry of the model, at the longitudinal position of 50% of the m.a.c. Drag coefficient is presented as forebody drag obtained by subtracting, from the total measured drag , the base drag computed from the measured base pressure on the model.\n\nSome laboratories have selected to test the AGARD-B standard model for periodic checkouts of the quality of measurements in their wind tunnels.\n\nAt the AGARD Wind Tunnel and Model Testing Panel meeting in Paris, France, in 1954, it was agreed to add a third model configuration to the family of AGARD calibration models, by extending the body of the AGARD-B by 1.5 diameters and by adding a horizontal and a vertical tail in the T-tail configuration. The horizontal tail has an area equal to 1/6 of the wing area. Sections of the vertical and horizontal tail are circular arc profiles defined identically to the profile of the wing. Forward of the 1.5 D body extension, the geometry of the AGARD-C model is identical to that of the AGARD-B. Also, the position of the moments reduction point (the aerodynamic centre) is the same as on AGARD-B.\n\nThe support sting for the AGARD-C model is identical to the sting for the AGARD-B model, having a length of aft of model base and a diameter of .\n\nThe longer body of the AGARD-C model and the existence of the tail make it easier to detect (from anomalies in the wind tunnel test results) if the shock waves reflected from the walls of the wind tunnel test section are passing too close to the rear end of the model. The existence of the tail generally makes this model more sensitive than AGARD-B to flow curvature in the wind tunnel test section.\n\nAGARD-C is primarily used in the transonic wind tunnels and the database of published test results is somewhat smaller than the one for the AGARD-B model.\n\nIn order to reduce cost and produce more versatile wind tunnel models, actual designs of AGARD-B and AGARD-C are sometimes realized as an AGARD-B configuration to which a body segment with the T-tail can be attached at the rear end to form the AGARD-C configuration.\n\nWind tunnel\n\nStandard wind tunnel models\n\n"}
{"id": "54237128", "url": "https://en.wikipedia.org/wiki?curid=54237128", "title": "Alessandro Longo (journalist)", "text": "Alessandro Longo (journalist)\n\nAlessandro Longo (Taranto, 29 October 1976) is an italian technology journalist and editor-in-chief of the italian newspapers Agendadigitale.eu and Forumpa.it.\n\nHe has been a regular contributor to La Repubblica (over one thousand articles published), L'espresso and Il Sole 24 Ore, since 2003.\n\nAround one hundred of his investigative features have been published on the first pages of La Repubblica and Il Sole 24 Ore over the years.\n\nAs technical evangelist he has been hosted since 2002 in some very popular tv programs on Rai 1, Rai 2 and Rai 3.\n\nHe is also a regular participant in the main Italian-Swiss radio station, Radiotelevisione svizzera (Radio 1).\n\nHe wrote the first Italian book on Voice over IP technology in 2005.\n\n\n"}
{"id": "863862", "url": "https://en.wikipedia.org/wiki?curid=863862", "title": "Artes Mechanicae", "text": "Artes Mechanicae\n\nArtes Mechanicae or mechanical arts, are a medieval concept of ordered practices or skills, often juxtaposed to the traditional seven liberal arts Artes liberales. Also called \"servile\" and \"vulgar\", from antiquity they had been deemed unbecoming for a free man, as ministering to baser needs.\n\nJohannes Scotus Eriugena (9th century) divides them somewhat arbitrarily into seven parts: \n\nIn his \"Didascalicon\", Hugh of St Victor (12th century) includes navigation, medicine and theatrical arts instead of commerce, agriculture and cooking. Hugh's treatment somewhat elevates the mechanical arts as ordained to the improvement of humanity, a promotion which was to represent a growing trend among late medievals.\n\nThe classification of the \"Artes Mechanicae\" as applied geometry was introduced to Western Europe by Dominicus Gundissalinus (12th century) under the influence of his readings in Arabic scholarship.\n\nIn the 19th century \"mechanic arts\" referred to fields of which some are now known as engineering. Use of the term was apparently an attempt to distinguish these fields from creative and artistic endeavors like the performing arts and the fine arts which were for the upper class of the time, and the intelligentsia. The mechanic arts were also considered practical fields for those that did not come from good families.\n\nRelated phrases, \"useful arts,\" or \"applied arts\" probably encompass the mechanic arts as well as craftsmanship in general.\n\nThe most famous usage of the term \"mechanic arts\" (and the one in which it is most commonly encountered today) is in the Morrill Land-Grant Colleges Act.\n\n\n"}
{"id": "4168374", "url": "https://en.wikipedia.org/wiki?curid=4168374", "title": "BiPu", "text": "BiPu\n\nBIPU (Bioremediation Infield Personnel Unit) is a sanitation method suitable for disaster relief and for temporary or isolated locations. It consists of flat-packed plastic panels which fit together to make a box, which is buried in the ground, and a large plastic bag to be placed inside the box. It is quick to set up but also suitable for longer term use if required.\n\nA latrine, (Western style, or squat style) pour-flush latrine, is placed over the top. The S-shaped water seal improves hygiene, compared to pit latrines.\n\nThe BIPU is manufactured and distributed by Poly Marketing Pty Limited.\n\n\n"}
{"id": "4186213", "url": "https://en.wikipedia.org/wiki?curid=4186213", "title": "Blistex, Incorporated", "text": "Blistex, Incorporated\n\nBlistex is an American company that develops, produces, and markets personal care products. It began as a small family company in 1947. Its focus was to develop and market lip care products in the United States. It then became a private company based in Oak Brook, Illinois that primarily manufactures lip balm, lip ointment, and other lip-related products. It also produces anti-itch ointments, moisturizing lotions, the Odor-Eaters footcare product, and other skin care medications.\n\n"}
{"id": "8262492", "url": "https://en.wikipedia.org/wiki?curid=8262492", "title": "Buckling (fish)", "text": "Buckling (fish)\n\nA buckling is a form of hot-smoked herring similar to the kipper and the bloater. The head and guts are removed but the roe or milt remain. They may be eaten hot or cold.\n\nThe word may come from the German \"Bückling\" or the Swedish \"böckling\", both words denoting a hot-smoked variety of the kipper.\n\nBuckling is hot-smoked whole; bloaters are cold-smoked whole; kippers are split and gutted, and then cold-smoked.\n\n\n"}
{"id": "411884", "url": "https://en.wikipedia.org/wiki?curid=411884", "title": "Bureau à gradin", "text": "Bureau à gradin\n\nA bureau à gradin is an antique desk form resembling a writing table with, in addition, one or several tiers of small drawers and pigeonholes built on part of the desktop surface. Usually the drawers and pigeonholes directly face the user, but they can also surround three sides of the desk, as is the case for the Carlton house desk form. A small, portable version is a bonheur du jour.\n\nIn some cases the bureau à gradin has a second tier of drawers under the work surface, and thus looks like an advanced form of the bureau Mazarin or like a non-enclosed version of the cylinder desk, or the tambour desk.\n\nSee also the List of desk forms and types.\n\n"}
{"id": "14546835", "url": "https://en.wikipedia.org/wiki?curid=14546835", "title": "Bygrave slide rule", "text": "Bygrave slide rule\n\nThe Bygrave slide rule is a slide rule named for its inventor, Captain Leonard Charles Bygrave of the RAF. It was used in celestial navigation, primarily in aviation. Officially, it was called the A. M. L. Position Line Slide Rule (A.M.L. for Air Ministry Laboratories).\n\nIt was developed in 1920 at the Air Ministry Laboratories at Kensington in London and was produced by Henry Hughes & Son Ltd of London until the mid-1930s. It solved the so-called celestial triangle accurately to about one minute of arc and quickly enough for aerial navigation. The solution of the celestial triangle used the John Napier rules for solution of square-angled spherical triangles. The slide rule was constructed as two coaxial tubes with spiral scales, like the Fuller slide rules, with yet another tube on the outside carrying the cursors.\n\nDuring the Second World War, a closely related version was produced in Germany by Dennert & Pape as the HR1, MHR1 and HR2.\n\nSir Francis Chichester was a renowned aviator and yachtsman. He used a Bygrave Slide Rule as an aid to navigation during flights in the 1930s, one of which was the first solo flight from New Zealand to Australia in a Gipsy Moth biplane. He later completed a round the world cruise in his yacht Gipsy Moth IV. This was the first solo circumnavigation using the clipper route. Sir Francis Chichester wrote about these exploits in his autobiography, entitled The Lonely Sea and the Sky.\n\n\n"}
{"id": "406386", "url": "https://en.wikipedia.org/wiki?curid=406386", "title": "Carrel desk", "text": "Carrel desk\n\nA carrel desk is a small desk (usually) featuring high sides meant to visually isolate its user from any surroundings either partially or totally.\n\nCarrel desks are most often found in academic libraries. Most carrel desks are rectangular in shape. Above the main desktop area there is often a shelf for books. Sometimes the seat is integrated with the carrel desk. Unlike the cubicle desk, carrel desks usually have no file drawers or other facilities. Since the late 1990s, some carrel desk designs provide AC power and Ethernet receptacles for students using laptop computers.\n\nLike the school desk, the carrel desk is normally produced and sold in large quantities for an institutional market. They are made to stand alone or to be grouped together, with or without common sides or walls.\n\nThe word carrel can also refer to a small isolated \"study room\" in public libraries and on university campuses; usually the room has a lockable door to which the user is granted the key on request. Carrels usually contain a desk (not necessarily one described as above), shelving and a lamp. Carrels are generally quite popular at universities and are therefore usually quickly occupied. This becomes especially true during mid-term examinations and finals. They have the advantage of power for a laptop (and often internet port) as well as generally being quieter than in the main library building. Carrels are also often used as temporary storage for books and materials the user is not finished with while they are at lectures or labs.\n\nCarrels originated in monasteries to help contain the cacophony of roomfuls of monks reading aloud, as was the early practice. Carrels are first recorded in the 13th century at Westminster Abbey, London, on the garth side of the North Walk, though they probably existed from the late years of the 12th century.\n\n"}
{"id": "11530838", "url": "https://en.wikipedia.org/wiki?curid=11530838", "title": "Choke ring antenna", "text": "Choke ring antenna\n\nA choke ring antenna is a particular form of omnidirectional antenna for use at high frequencies. It consists of a number of conductive concentric cylinders around a central antenna. Due to its delicate construction, it is often enclosed in a protective cover or radome when placed outside and exposed to the elements. \n\nChoke ring antennas are notable for their ability to reject multipath signals fading from a source. Since the path that a signal takes from a transmitter to receiver can be used to measure the distance between the two, this makes it highly suited for GPS and radar applications. In a GPS ground-based receiver, a choke ring antenna can provide millimeter precision measurements for surveying and geological measurement applications.\n\nThe choke ring design originated at the Jet Propulsion Laboratory.\n\n\n"}
{"id": "503432", "url": "https://en.wikipedia.org/wiki?curid=503432", "title": "EMI (protocol)", "text": "EMI (protocol)\n\nExternal Machine Interface (EMI), an extension to Universal Computer Protocol (UCP), is a protocol primarily used to connect to short message service centres (SMSCs) for mobile telephones. The protocol was developed by CMG Wireless Data Solutions, now part of Mavenir.\n\nA typical EMI/UCP exchange looks like this :\n\nThe start of the packet is signaled by ^B (STX, hex 02) and the end with ^C (ETX, hex 03). Fields within the packet are separated by / characters.\n\nThe first four fields form the mandatory header. the third is the \"operation type\" (O for operation, R for result), and the fourth is the \"operation\" (here 30, \"short message transfer\").\n\nThe subsequent fields are dependent on the operation. In the first line above, '66677789' is the recipient's address (telephone number) and '68656C6C6F' is the content of the message, in this case the ASCII string \"hello\". The second line is the response with a matching transaction reference number, where 'A' indicates that the message was successfully acknowledged by the SMSC, and a timestamp is suffixed to the phone number to show time of delivery.\n\nThe final field is the checksum, calculated simply by summing all bytes in the packet (including slashes) and taking the 8 least significant bits from the result.\n\nThe full specification is available on the LogicaCMG website developers' forum, but registration is required.\n\nThe two-digit \"transaction reference number\" means that an entity sending text messages can only have 100 outstanding messages (per session); this can limit performance, but only over a slow network and with incorrectly configured applications on one's SMSC (for example one session, with number of windows greater than 100). In practice it does not have any impact on delivery throughput.\n\nThe EMI UCP documentation specifies a default alphabet of IRA (eq ASCII on 7bit). In practice users default to the GSM-7 alphabet, which is almost the same as ASCII on 7 bit, except for a few characters - for example '_' (underline).\n\n\n"}
{"id": "31963747", "url": "https://en.wikipedia.org/wiki?curid=31963747", "title": "Energy Sector Management Assistance Program", "text": "Energy Sector Management Assistance Program\n\nThe Energy Sector Management Assistance Program (ESMAP) is a global knowledge and technical assistance program administered by the World Bank. Its mission is to assist low- and middle-income countries to increase know-how and institutional capacity to achieve environmentally sustainable energy solutions for poverty reduction and economic growth.\nSince its inception in 1983, ESMAP has supported more than 800 energy-sector activities that promote poverty reduction, economic growth and low carbon development in over 100 countries.\n\nFOCUS AREAS\n\"Energy Security\"\nTo help ensure long-term energy security, countries are looking closely at renewable energy, efficiency practices and technologies, diversification of supply, and improved sector performance. ESMAP assists its clients to carry out energy assessments and develop strategies to enhance sector planning, regulation, and governance.\n\"Energy Access\"\nAbout 1.4 billion of the world’s people still lack access to electricity, and poor households spend US$20 billion a year on low-quality, fuel-based lighting. Respiratory diseases are widespread among the 2.7 billion people who still rely on biomass for cooking, with women and children hit the hardest. ESMAP supports initiatives to reduce energy poverty by expanding access to modern, safe, affordable and sustainable energy services. ESMAP’s energy access work covers electrification and household energy needs in rural areas and for the urban poor.\n\"Climate Change\"\nClimate change will directly affect energy resource endowments, infrastructure, and transportation, as well as energy demand. ESMAP assists client countries to integrate climate change mitigation and adaptation options into energy sector planning. ESMAP also supports the scale-up of renewable energy through resource assessments, strategy development, and policy and institutional development.\n\nESMAP was established in 1983 in response to the global energy crisis of the late 1970s, and the impact this was having on the economies of oil-importing developing countries. ESMAP has since operated in over 100 countries through more than 800 activities covering a broad range of energy issues.\n\nStarting in Fiscal Year 2014, ESMAP transitioned to a three-year business plan cycle. This Business Plan sets out ESMAP’s objectives, priorities, strategies, and resource requirements for FY2014‐16 (i.e., July 2013 to June 2016). It draws on experience gained in implementing the previous Business Plan (ESMAP Strategic Business Plan 2008‐2013), consultations with the Consultative Group of donors, advice from the Technical Advisory Group, conclusions and recommendations of the External Evaluation of ESMAP conducted in 2011‐2012, and lessons learned from the annual ESMAP Portfolio Review.\nLooking ahead, in the context of a rapidly changing global energy landscape, the primary objective for the international community is to achieve progress on the triple challenge of providing increased energy supply and security, eliminating energy poverty, and mitigating and adapting to climate change. Clearly, this can only be achieved with transformative changes in the design and management of national and regional energy systems and global efforts.\n\nThe proposed Business Plan will be based on the following principles:\nHelp shape the future.\nMeasure results and demonstrate impacts.\nProvide value for money.\nEnsure relevance to the Bank’s country sector dialogue and lending operations.\nWorking across sectors.\nScaling‐up to respond to increased client demand.\nIncrease support to low‐income countries, while maintaining engagement with middle‐income countries; and\nStrengthen cooperation with other multilateral and bilateral development agencies\n\nDownload | FY2014-16 Business Plan\n\nESMAP's current work program comprises activities broken down into three broad categories: clean energy, energy access and energy efficiency.\n\nESMAP is governed by a Consultative Group (CG) made up of representatives from contributing donors and chaired by the Director of the Sustainable Energy Department of the World Bank, on behalf of the Vice President of the Sustainable Development Network. The CG meets annually to review the strategic directions of ESMAP, its achievements, and its use of resources and funding requirements.\nESMAP’s donors are:\nAustralia, Austria, Denmark, Finland, France, Germany, Iceland, Japan, Lithuania, Norway, Sweden, The Netherlands, United Kingdom, The World Bank.\n\n\n"}
{"id": "12951705", "url": "https://en.wikipedia.org/wiki?curid=12951705", "title": "Enhanced geothermal system", "text": "Enhanced geothermal system\n\nAn enhanced geothermal system (EGS) generates geothermal electricity without the need for natural convective hydrothermal resources. Until recently, geothermal power systems have exploited only resources where naturally occurring heat, water, and rock permeability are sufficient to allow energy extraction. However, by far most of geothermal energy within reach of conventional techniques is in dry and impermeable rock. EGS technologies enhance and/or create geothermal resources in this hot dry rock (HDR) through 'hydraulic stimulation'.\nWhen natural cracks and pores do not allow economic flow rates, the permeability can be enhanced by pumping high-pressure cold water down an injection well into the rock. The injection increases the fluid pressure in the naturally fractured rock, triggering shear events that enhance the system's permeability. As long as the injection pressure is maintained, a high matrix permeability is not required, nor are hydraulic fracturing proppants required to maintain the fractures in an open state. This process is termed hydro-shearing, perhaps to differentiate it from hydraulic tensile fracturing, used in the oil and gas industry, which can create new fractures through the rock in addition to expanding the existing fractures.\n\nWater travels through fractures in the rock, capturing the rock's heat until forced out of a second borehole as very hot water. The water's heat is converted into electricity using either a steam turbine or a binary power plant system. All of the water, now cooled, is injected back into the ground to heat up again in a closed loop.\n\nEGS technologies can function as baseload resources that produce power 24 hours a day. Unlike hydrothermal, EGS may be feasible anywhere in the world, depending on the economic limits of drill depth. Good locations are over deep granite covered by a layer of insulating sediments that slow heat loss. An EGS plant is expected to have an economical lifetime of 20-30 years using current technology.\n\nEGS systems are currently being developed and tested in France, Australia, Japan, Germany, the U.S. and Switzerland. The largest EGS project in the world is a 25-megawatt demonstration plant currently being developed in Cooper Basin, Australia. Cooper Basin has the potential to generate 5,000–10,000 MW.\n\nThe Australian government has provided research funding for the development of Hot Dry Rock technology.\n\nOn 30 May 2007, then Australian opposition environmental spokesperson and former Minister for the Environment, Heritage and the Arts Peter Garrett announced that if elected at the 2007 Australian Federal Election, the Australian Labor Party would use taxpayer money to subsidise putting the necessary drilling rigs in place. In an interview, he promised:\n\"There are some technical difficulties and challenges there, but those people who are keen on getting Australia into geothermal say we've got this great access to resource and one of the things, interestingly, that's held them back is not having the capacity to put the drilling plants in place. And so what we intend this $50 million to go towards is to provide one-for-one dollars. Match $1 from us, $1 from the industry so that they can get these drilling rigs on to site and really get the best sites identified and get the industry going.\"\n\nThe EU's EGS R&D project at Soultz-sous-Forêts, France, has recently connected its 1.5 MW demonstration plant to the grid. The Soultz project has explored the connection of multiple stimulated zones and the performance of triplet well configurations (1 injector/2 producers).\n\nInduced seismicity in Basel led to the cancellation of the EGS project there.\n\nThe Portuguese government awarded, in December 2008, an exclusive license to Geovita Ltd to prospect and explore geothermal energy in one of the best areas in continental Portugal. An area of about 500 square kilometers is being studied by Geovita together with the Earth Sciences department of the University of Coimbra's Science and Technology faculty, and the installation of an Enhanced Geothermal System (EGS) is foreseen.\n\nCornwall is set to host a 3MW demonstration project, based at the Eden Project, that could pave the way for a series of 50-MW commercial-scale geothermal power stations in suitable areas across the country.\n\nA commercial-scale project near Redruth is also planned. The plant, which has been granted planning permission, would generate 10 MW of electricity and 55 MW of thermal energy and is scheduled to become operational in 2013–2014.\n\nThe first EGS effort — then termed Hot Dry Rock — took place at Fenton Hill, New Mexico with a project run by the federal Los Alamos Laboratory. It was the first attempt to make a deep, full-scale EGS reservoir.\n\nThe EGS reservoir at Fenton Hill was first completed in 1977 at a depth of about 2.6 km, with rock temperatures of 185 C. In 1979 the reservoir was enlarged with additional hydraulic stimulation and was operated for about 1 year. The results demonstrated that heat could be extracted at reasonable rates from a hydraulically stimulated region of low-permeability hot crystalline rock. In 1986, a second reservoir was prepared for initial hydraulic circulation and heat extraction testing. In a 30-day flow test with a constant reinjection temperature of 20 C, the production temperature steadily increased to about 190 C, corresponding to a thermal power level of about 10 MW. Due to budget cuts, further study at Fenton Hill was discontinued.\n\nEGS funding languished for the next few years, and by the next decade, US efforts focused on the less ambitious goal of improving the productivity of existing hydrothermal resources. According to the fiscal year 2004 Budget Request to Congress from DOE's Office of Energy Efficiency and Renewable Energy,\n\nIn fiscal year 2002, preliminary designs for five projects employing EGS technology were completed and the Coso Hot Springs geothermal field at the US Naval Weapons Air Station in China Lake, California was selected for full-scale development. Two additional projects were selected for preliminary analysis at Desert Peak in Nevada and Glass Mountain in California. Funding for this effort totaled $1.5 million. The effort was continued in 2003 with an additional $3.5 million.\nIn 2009, The US Department of Energy (USDOE) issued two Funding Opportunity Announcements (FOAs) related to enhanced geothermal systems. Together, the two FOAs offered up to $84 million over six years.\nThe DOE followed up with another FOA in 2009, of stimulus funding from the American Reinvestment and Recovery Act for $350 million, including $80 million aimed specifically at EGS projects,\n\nIn February 2014, the Department of Energy announced the intent to establish \"a dedicated subsurface laboratory called the Frontier Observatory for Research in Geothermal Energy (FORGE)\" in order to investigate and develop enhanced geothermal technology. In August 2016, it was announced that the proposed sites had been narrowed to two (in Utah and Nevada), expected to be reduced to one the following year. Beginning in 2018, the selected site will host the FORGE laboratory, which will provide annual solicitations for research to be performed there.\n\nSome induced seismicity is inevitable and expected in EGS, which involves pumping fluids at pressure to enhance or create permeability through the use of hydro-shearing and hydraulic fracturing techniques. Hydro-shear stimulation methods seek to expand and extend the connectivity of the rock's existing fractures to create a better fluid network for the transfer of heat from the rock to the fluid. Seismicity events at the Geysers geothermal field in California have been strongly correlated with injection data.\n\nThe case of induced seismicity in Basel merits special mention; it led the city (which is a partner) to suspend the project and conduct a seismic hazard evaluation, which resulted in the cancellation of the project in December 2009.\n\nAccording to the Australian government, risks associated with \"hydrofracturing induced seismicity are low compared to that of natural earthquakes, and can be reduced by careful management and monitoring\" and \"should not be regarded as an impediment to further development of the Hot Rock geothermal energy resource\". However, the risks of induced seismicity vary from site to site and should be considered before large scale fluid injection is begun.\n\nThe Geothermal Energy Centre of Excellence at the University of Queensland has been awarded AUD 18.3 million for EGS research, a large portion of which will be used to develop CO EGS technologies.\n\nResearch conducted at Los Alamos National Laboratories and Lawrence Berkeley National Laboratories examined the use of supercritical CO, instead of water, as the geothermal working fluid, with favorable results. CO has numerous advantages for EGS:\nCO is, however, much more expensive and somewhat more difficult to work with than water.\n\nA 2006 report by MIT, and funded by the U.S. Department of Energy, conducted the most comprehensive analysis to date on the potential and technical status of EGS. The 18-member panel, chaired by Professor Jefferson Tester of MIT, reached several significant conclusions:\n\n\n\n<br>\n"}
{"id": "53452262", "url": "https://en.wikipedia.org/wiki?curid=53452262", "title": "Ferdinand Voegele", "text": "Ferdinand Voegele\n\nFerdinand Voegele (born 12 February 1896 in Hollfeld, Kingdom of Bavaria; died after 1946) was a German philologist and linguistic cryptanalyst, before and during the time of World War II and who would eventually lead the cipher bureau, okl-stelle (German: Chiffrier Stelle) of the Luftwaffe Signal Intelligence Service (German: Oberbefehlshaber der Luftwaffe) (Abbr. Luftwaffe SIS).\n\nDuring World War I he served as a volunteer. Later he studied oriental languages at various German universities, finally specializing in Philology. Using his language skills, he started work in an export business. Eventually moving abroad for several years, but returned in the summer of 1935, when he was offered a position as an interpreter with the German Air Ministry.\n\nBetween July and September 1935, he undertook training near Kladow, near Berlin in Morse Telegraphy (Wireless telegraphy), German cryptographic procedures and radio communications. In October 1935, he posted to a fixed intercept station of the Army at Stuttgart until January 1936. During his time there, he translated plain-language radio messages from French Army and Air Force. In addition, he was employed on evaluation and traffic analysis. Between March and April 1936, he was ordered to a two months maneuver employed as an airborne radio operators with KG254 in Kitzingen. His grade during this time was Officer candidate.\n\nFrom May to October 15 he succeeded in breaking the recipherment used in conjunction with a French 3 digit code, the basis of which had already been largely reconstructed. The recipherment was one with a number-letter cipher table. After the start of the Spanish Civil War he solved many 4-alphabetic Substitution cipher.\n\nOn the 15th October, Voegele was transferred to a new Luftwaffe Intercept Station (Codename:W-15) (Stadelheim Transmitter) close to Munich, where he translated French, Italian and Yugoslavia.\n\nOn the 1st January 1937, he was assigned to the newly created cipher bureau (German: Chi-Stelle) within Referat K and made Chief of all cryptanalytic work (Cryptanalysis). He was assigned as an assistant, Edward Von Lingen who had learned Russian Army cryptanalysis while at the German Army intercept station in Treuenbrietzen. When Voegele joined Chi-Stelle it consisted of 12 people.\n\nDuring the remainder of the year, Voegele worked on Spanish cyphers as part of monitoring the Republicans in the Spanish Civil War. He also worked on several Czechoslovakian bigraphic procedures (Polygraphic substitution), and on breaking the Czechoslovakian Air Force double-transposition, where the message count only amounted to 10-25 messages per day.\n\nVoegele was known to have worked on a number of cyphers during the course of the war. These included the Government Telegraph Code, India Code, Syko, the RAF 4-digit code, Aircraft Movement Code in Autumn 1942, Bomber Code in Winter 1942, January 1943, Slidex in May 1943, Aircraft Reporting Code from July 1943, UCO Weather Code from May 1944 and Weather Codes throughout the war. Typex was attempted by Voegele in the early 1940s.\nLittle was known about Ferdinand Voegele after the end of the war.\n"}
{"id": "1702592", "url": "https://en.wikipedia.org/wiki?curid=1702592", "title": "Fredrik Rosing Bull", "text": "Fredrik Rosing Bull\n\nFredrik Rosing Bull (25 December 1882 – 7 June 1925) was an information technology pioneer, known for his work on improved punched card machines.\n\nBull was born in Kristiania (Oslo, Norway). In 1907 he finished his studies in civil engineering at the Technical School of Kristiania (Kristiania Tekniske Skole). In 1916 he was hired as a technical inspector for the insurance company Storebrand, where he developed an interest for punched card machines technology and began developing one of his own. In 1919 he obtained a patent for the machine, and in 1921 he prepared a team that took over the implementation of the machine at the company where Bull worked at that time, Storebrand. This team provided several new ideas for improving the Bull machine, rendering it superior to Hollerith's device - the precursor to the IBM punched card machine - in use at that time. Bull continued to develop his ideas, improving the machine, which became a success throughout Europe. He was diagnosed with cancer at an early age and died in 1925 when he was 42 years old. His patents were later sold in 1931 and constituted the basis for the founding of the French company Groupe Bull, a large information technology company operating in over 100 countries.\n\nFredrik Bull was born in Kristiania (the present-day Oslo) to Dr. Ole Bornemann Bull (1842–1916) and his first wife Marie Cathrine Lund (1843–1884). Dr. Ole Bull was a renowned eye doctor. He collaborated with Gerhard Armauer Hansen who discovered \"Mycobacterium leprae\", the causative agent of leprosy, while investigating the effects of leprosy on the eyes. He is also known for having developed a method to determine the degree of sensation of color.\n\nFredrik was raised in a large family. He was the eighth of fifteen children. The Bull family had a passion for technology and science: all of Fredrik's older brothers were engineers. His brother Anders Henrik Bull is known for his studies in wireless radiotelegraphy.\n\nFredrik Rosing Bull began his studies in civil engineering at the reputable Technical School of Kristiania in 1904 and graduated in 1907. He scored some of the best marks of class.\n\nIn 1916 he was hired as a technical inspector at the insurance company Storebrand where he came into contact with the tabulating machines of those days.\n\nThe punched cards and the tabulating machines were initially developed by the U.S. engineer Herman Hollerith and were used for first time in Norway by Statistics Norway in 1894.\n\nFredrik Bull was sent abroad to study Hollerith's systems, returning with the conviction that Hollerith's systems were expensive and unstable. He was convinced that he could develop a device that was cheaper and more efficient than Hollerith's. As a result, Bull convinced his employer, Storebrand, to pay him an advance of $10,000 to develop a new machine. The terms of the deal required the advance to be repaid in full if the machine was not successful.\n\nBull's plan was to use electromagnetic technology like Hollerith, but with a considerable number of improvements. The use of 45 column punched cards enabled the machine to read the information while making contact through the holes. This method allowed faster processing of the information. The existing machines in use at that time required significant manual intervention to operate. Bull made several improvements to automate processing such as standardization of punched-cards and pre-selection.\n\nBull needed almost 2 years to turn his ideas into a finished product. The machine was presented to the Storebrand directors at his workshop on 12 January 1921 and subsequently purchased for the sum of 20,000 pounds on 21 January 1921. The machine was not a success because it was not as efficient, stable and reliable as expected. However, it was in operation until 1926.\n\nAround the same time Bull contacted an old friend named Reidar Knutsen from high school in Nordstrand, who headed the company A/S Oka. Through Reidar he met Knut Andreas Knutsen, Reidar's younger brother, who was an engineer, and he and Bull began collaborating.\n\nOn 31 July 1919 Bull obtained a patent for his design. The patent describes in detail his idea of a programmable tabulating machine. The new machine itself was not completed until 1923 and was referred to as a 'ordering, recording and adding machine'. After its initial success Bull undertook the production of new copies of his T-30 machine, adding improvements as he went. Several insurance companies in Denmark showed interest in the technology.\n\nFredrik then signed a contract the Oka company led by Reidar Knutsen, which assumed the costs of manufacturing and marketing. The production of these machines was in a precision workshop in Kristiania.\n\nThe Bull machine used punched card of 45 columns, with round holes and a rotating adder. His machine was substantially better than its competition, Hollerith and Powers, through the mechanism of punched card pre-selection.\n\nThe machine proved a success and received very good reviews and publicity The key factors for success were: the technical quality of the machine,the ease of use, the new pre-selection technology, the cost savings and the opportunity for users to avoid IBM's monopoly and purchase their own equipment instead of renting it.\n\nBull continued working on improvements for the machine and also in developing new machines such as a sorting machine and a new tabulating machine.\n\nSome of the notable improvements were: the change of switches that controlled the entry of punched cards and the expansion device in larger scale.\n\nThe reading device was the most critical part of the machine. Built with electrical conductors or springs, punched cards were introduced, the springs passed through the holes producing contact. The springs only passed through the holes of the punched cards, causing the information to be recorded. He obtained the ideas for this machine by stealing the notes of Henrik Hartzner, his Danish partner. One of the main problems of this method was the low durability of the material of the cards, which meant that the method did not always work the right way. Another major problem was the dust that entered the holes of the contacts. Finally, one of the biggest problems Bull and Knutsen had to face was that because of the contacts, sparks were created causing the machine to crash frequently. All these details were being constantly improved.\n\nProduction of Bull machines was rather slow. In 1921 there was a production of 2 machines, 2 in 1922, 2 in 1923, 4 to 1924 and 6 in 1925, distributed among companies in Norway, Denmark (Hafnia as a notable client), Finland and Switzerland. There were constant problems with the machines; Knut Andreas Knutsen was continuously traveling to these countries for repair and modifications at client sites.\n\nIn the summer of 1924 Bull was diagnosed with cancer, a disease that ended his life on 7 June 1925 when Bull was only 42 years old.\n\nDespite the diagnosis in the summer of 1924, Bull continued to work until his condition worsened in the fall of that year. In the last few days he shared his latest ideas with Knutsen. Bull's patent rights were acquired by Oka, where Knutsen, loyal to the ideas of Bull, continued the improvement of the machine and the expansion of the company. Knutsen focused on new designs to record tabulation results on paper forms, sorted numerically and alphabetically. He was the first to use printing wheel methods.\n\nThe years following Bull's death, 1926, 1927 and 1928 were years of difficulty but also of joys and surprises. The machines installed and leased to Swiss companies had attracted great interest in Switzerland. In 1927, the Belgian Emile Genon bought the patents to operate in the European continent (excluding Scandinavia). In 1928 he got in agreement with the Swiss company HW Egli in order to produce Bull machines. Production began in 1929.\n\nLater Genon, aware of the improvements Knutsen was bringing in Scandinavia also tried to improve on his patents, the technology of the vertical sorting machine and printing. He finally hired Knutsen who was given the place of chief engineer of HW Egli. This was accepted by Knutsen with the condition of the company to moving to France where there was more to reach the market. So, in 1931 HW Egli - Bull based in Paris was founded. Two years later, in 1933, the company underwent a reorganization and suffered a name change, Compagnie des Machines Bull, the current Groupe Bull. Knutsen continued as chief engineer until his retirement in 1958.\n\n"}
{"id": "56281215", "url": "https://en.wikipedia.org/wiki?curid=56281215", "title": "Fuel (journal)", "text": "Fuel (journal)\n\nFuel is a monthly peer-reviewed scientific journal covering research on fuel. It was established in 1922 as Fuel in Science and Practice, obtaining its current name in 1948. It is published by Elsevier and the editors-in-chief are Zuohua Huang (Xi'an Jiaotong University), John Patrick (University of Nottingham), and Eric Suuberg (Brown University). According to the \"Journal Citation Reports\", the journal has a 2016 impact factor of 4.601.\n"}
{"id": "46857922", "url": "https://en.wikipedia.org/wiki?curid=46857922", "title": "IBRIDGES", "text": "IBRIDGES\n\niBRIDGES is an annual convention for Iranian diaspora to meet with Iranian entrepreneurs and business people. \nThe primary goal of the convention is to bridge the gap between the Iranian high-tech start-ups and the western investors. The discussions in this convention are intended to primarily focus on entrepreneurship opportunities in Iran's tech industry rather than its internal or foreign policies.\n\nThe 2014 convention in UC Brekeley attracted more than 700 Iranian high-tech executives and entrepreneurs. \nThe 2015 convention in Berlin is called \"the largest gathering of Iranians outside the country in more than three decades\". It was held from June 4-6, 2015 at the new Berlin CityCube convention center. The event included 117 sessions with 163 speakers, and 1,040 registered participants from 35 countries. Dave McClure, one of 2015 attendees, counts the large population of Iran and its educated population as potential for startups in the country. The official final and detailed report of the iBridge Berlin was released by organizer in October 2015.\n\nThe convention is also implicitly aimed at bridging the gap in international relationship between Iran and western countries, especially at the time of diplomatic negotiations between Iran and western countries on Iran's nuclear program.\n\nThe next iBridge will be held on December 8-10, 2016 in Barcelona, Spain.\n\n\n\n"}
{"id": "39925774", "url": "https://en.wikipedia.org/wiki?curid=39925774", "title": "IXYS Corporation", "text": "IXYS Corporation\n\nIXYS Corporation, (NASDAQ:IXYS) is an American company based in Milpitas, California. IXYS focuses on power semiconductors, radio-frequency (RF) power semiconductors, and digital and analog integrated circuits (ICs) In July 2013, IXYS announced the completion of acquisition for Samsung's 4-bit and 8-bit microcontroller line.\n\nDr. Nathan Zommer founded IXYS Corporation in 1983 in Silicon Valley, Santa Clara, California.\nIXYS was originally a fabless power semiconductor device company.\nIn 1989, IXYS provided power MOSFETs for the General Motors EV1.\n\nIXYS provided high-power IGBTs for the KTX-II high-speed train.\n\nIn 2001, the company acquired the British semiconductor manufacturer Westcode.\n\nIn December 2009, IXYS Corporation bought Zilog, which is now the company's wholly owned subsidiary.\n\nIn July 2013, IXYS Corporation finished acquiring Samsung Electronics' 4- and 8-bit microcontroller business, and the 4- and 8-bit microcontrollers acquired from Samsung will be offered by Zilog, Inc.\n\nIn August 2017, IXYS Corporation was acquired by Littelfuse Inc in exchange for $750 million in cash and stocks.\n\nIXYS Corporation's production of power semiconductor consists of Power MOS (metal-oxide-silicon) transistors and power bipolar. These series of products convert high voltage or current electricity to regular power. The company’s production of integrated circuits are used for analog, mixed-signal and digital interface solutions in communication, such as solid-state relays (SSRs), line card access switch (LCAS), Litelink™. The RF Power Semiconductors convert high rates electricity for amplification or reception. In addition, IXYS provides laser diode drivers, direct copper bond (DCB).\n\n"}
{"id": "10552308", "url": "https://en.wikipedia.org/wiki?curid=10552308", "title": "Information and communications technology in agriculture", "text": "Information and communications technology in agriculture\n\nInformation and communication technology in agriculture (ICT in agriculture), also known as e-agriculture, is developing and applying innovative ways to use ICTs in the rural domain, with a primary focus on agriculture. ICT in agriculture offers a wide range of solutions to some agricultural challenges. It is seen as an emerging field focusing on the enhancement of agricultural and rural development through improved information and communication processes. In this context, ICT is used as an umbrella term encompassing all information and communication technologies including devices, networks, mobiles, services and applications; these range from innovative Internet-era technologies and sensors to other pre-existing aids such as fixed telephones, televisions, radios and satellites. E-agriculture continues to evolve in scope as new ICT applications continue to be harnessed in the agriculture sector. More specifically, e-agriculture involves the conceptualization, design, development, evaluation and application of innovative ways to use ICTs in the rural domain, with a primary focus on agriculture. Provisions of standards, norms, methodologies, and tools as well as development of individual and institutional capacities, and policy support are all key components of e-agriculture.\n\nE-agriculture is one of the action lines identified in the declaration and plan of action of the World Summit on the Information Society (WSIS). The \"Tunis Agenda for the Information Society,\" published on 18 November 2005 and emphasizes the leading facilitating roles that UN agencies need to play in the implementation of the Geneva Plan of Action. The Food and Agriculture Organization of the United Nations (FAO) has been assigned the responsibility of organizing activities related to the action line under C.7 ICT Applications on E-Agriculture.\n\nMany ICT interventions have been developed and tested around the world, with varied degrees of success, to help agriculturists improve their livelihoods through increased agricultural productivity and incomes, and reduction in risks. Some useful resources for learning about e-agriculture in practice are the World Bank’s e-sourcebook ICT in agriculture – connecting smallholder farmers to knowledge, networks and institutions (2011), ICT uses for inclusive value chains (2013), ICT uses for inclusive value chains (2013) and Success stories on information and communication technologies for agriculture and rural development have documented many cases of use of ICT in agriculture.\n\nThe FAO-ITU E-agriculture Strategy Guide was developed by the Food and Agriculture Organization (FAO) and the International Telecommunication Union (ITU) with support from partners including the Technical Centre for Agricultural and Rural Cooperation (CTA) as a framework for countries in developing their national e-agriculture strategy/masterplan.\n\nSome of the countries who are using the FAO-ITU E-agriculture Strategy Guide to develop their national e-agriculture strategy are Bhutan, Sri Lanka, Papua New Guinea, Philippines, Fiji and Vanuatu. The guide provides a framework to engage broader stakeholders in the development of national e-agriculture strategy.\n\nWireless technologies have numerous applications in agriculture. One major usage is the simplification of closed-circuit television camera systems; the use of wireless communications eliminates the need for the installation of coaxial cables.\n\n In agriculture, the use of the Global Positioning System provides benefits in geo-fencing, map-making and surveying. GPS receivers dropped in price over the years, making it more popular for civilian use. With the use of GPS, civilians can produce simple yet highly accurate digitized map without the help of a professional cartographer.\n\nIn Kenya, for example, the solution to prevent an elephant bull from wandering into farms and destroying precious crops was to tag the elephant with a device that sends a text message when it crosses a geo-fence. Using the technology of SMS and GPS, the elephant can roam freely and the authorities are alerted whenever it is near the farm.\n\nGeographic information systems, or GiS, are extensively used in agriculture, especially in precision farming. Land is mapped digitally, and pertinent geodetic data such as topography and contours are combined with other statistical data for easier analysis of the soil. GIS is used in decision making such as what to plant and where to plant using historical data and sampling.\n\n Automatic milking systems are computer controlled stand alone systems that milk the dairy cattle without human labor. The complete automation of the milking process is controlled by an agricultural robot, a complex herd management software, and specialized computers. Automatic milking eliminates the farmer from the actual milking process, allowing for more time for supervision of the farm and the herd. Farmers can also improve herd management by using the data gathered by the computer. By analyzing the effect of various animal feeds on milk yield, farmers may adjust accordingly to obtain optimal milk yields. Since the data is available down to individual level, each cow may be tracked and examined, and the farmer may be alerted when there are unusual changes that could mean sickness or injuries.\n\nThe use of mobile technologies as a tool of intervention in agriculture is becoming increasingly popular. Smartphone penetration enhances the multi-dimensional positive impact on sustainable poverty reduction and identify accessibility as the main challenge in harnessing the full potential (Silarszky et al., 2008) in agricultural space. The reach of smartphone even in rural areas extended the ICT services beyond simple voice or text messages. Several smartphone apps are available for agriculture, horticulture, animal husbandry and farm machinery.\n\n The Veterinary Department of Malaysia's Ministry of Agriculture introduced a livestock-tracking program in 2009 to track the estimated 80,000 cattle all across the country. Each cattle is tagged with the use of RFID technology for easier identification, providing access to relevant data such as: bearer's location, name of breeder, origin of livestock, sex, and dates of movement. This program is the first of its kind in Asia, and is expected to increase the competitiveness of Malaysian livestock industry in international markets by satisfying the regulatory requirements of importing countries like United States, Europe and Middle East. Tracking by RFID will also help producers meet the dietary standards by the halal market. The program will also provide improvements in controlling disease outbreaks in livestock.\n\nKnowledge management systems \nAgrowtube hosts Agriculture only information, best practices, research and success stories videos.\n\nE-learning \n\nOnline purchasing order of agri-inputs and agri-equipments. E-commerce \n\nAgricultural resources and services management \n\nComputer-aided manufacturing (CAM) \n\nComputer-aided design (CAD) \n\n\n"}
{"id": "15081677", "url": "https://en.wikipedia.org/wiki?curid=15081677", "title": "Insert Therapeutics", "text": "Insert Therapeutics\n\nInsert Therapeutics, Inc., now Calando Pharmaceuticals, Inc., is a medical research company that uses nanobiotechnology specializing in therapeutic agents that are conjugated, to facilitate and enhance drug delivery. The small company was founded in 2000, is located in Pasadena, California, and is owned by Arrowhead Research Corporation.\n\nThe conjugates consist of a cyclodextrin-containing polymer (Cyclosert) that acts as a drug delivery system, and a linked medication, such as a chemotherapeutic drug of already proven efficacy. The size of the polymer is designed to “fit” the specific target, as vessels in a neoplasm allow for leakage of different sizes of polymers, as in healthy tissue. The leaked conjugates are concentrated in the target area. As a result, chemotherapeutic activity is locally enhanced, while general side effects are decreased.\n\nAt least one of their conjugates, IT-101, has been investigated in a clinical trial at City of Hope National Medical Center.\n\n"}
{"id": "7647340", "url": "https://en.wikipedia.org/wiki?curid=7647340", "title": "International Union of Food Science and Technology", "text": "International Union of Food Science and Technology\n\nThe International Union of Food Science and Technology (IUFoST) ( ) is the global scientific organization and voice for food science and technology representing more than 200,000 food scientists and technologists from over 70 countries. It is a voluntary, non-profit association of national food science organizations. IUFoST is a full scientific member of the established in 1962, devoted to the advancement of, one of only 31 scientific unions worldwide and the only global representative of food science and technology to notable organizations such as the World Health Organization (WHO), Food and Agriculture Organization (FAO) of the United Nations, United Nations Development Programme (UNDP), CODEX Alimentarius and International Life Sciences Institute (ILSI).\n\nIUFoST's vision is to Strengthen Global Food Science and Technology for Humanity.\n\nIUFoST's mission is to promote international co-operation and information exchange, to provide education and training to food scientists and technologists around the world and to promote professionalism and profession organization among food scientists and technologists.\n\nThe feasibility of establishing an international organization of food scientists and technologists dedicated to the nutritional needs of the people of the world was informally explored during the First International Congress of Food Science and Technology (1962) held in London. The President of the Congress was Lord Rank who crystallised informal discussions that had already been taking place among a number of food scientists from around the world when he stated in his presidential message: \"If the potentialities of ... food science and technology are to ... culminate and nutritionally adequate, then there must be international collaboration.\" From the Congress emerged the International Committee of Food Science and Technology.\n\nThe work of this Committee culminated in the formal inauguration of the International Union of Food Science and Technology during the Third International Congress of Food Science and Technology convened in 1970 in Washington, DC, USA. The 1970 meeting in Washington, DC, USA was referred to as \"SOS/70\" with SOS referring to Science and Survival.\n\nIn 1960, several British scientific societies and the UK Government organised a conference in London in recognition of the Centenary of the 1860 Food and Drugs Act (UK). It was also the 150th anniversary of Appert's publication on the preservation of foods in sealed containers.\n\nIn the week prior to the Food and Drugs conference, Professor John Hawthorn convened a symposium on Recent Advances in Food Science at the Glasgow Royal College of Science and Technology, which later metamorphosed into Strathclyde University. [The proceedings, edited by Professor Hawthorn and a colleague J. Muil Leitch, were published in 1962 by Butterworths]. The Glasgow symposium, to which food scientists from many nations were invited, was financed by a substantial grant from the Office of the Science Adviser to the North Atlantic Treaty Organisation, NATO. During the 1950s and 1960s NATO evinced a significant interest in food technology. The food and nutrition research laboratory in Toronto, of which I was director, carried out an extensive study for NATO on the bulk storage of food grains examining alternative methods conducive to stockpiling at dispersed sites.\n\nOne evening following dinner during the Glasgow symposium, Professors Hawthorn and EC Bate-Smith invited a group to meet to discuss the concept of an international food science society. The discussion was splendidly stimulated by Professor Hawthorn's supply of malt whiskey from a Hebridean distillery. The group included Emil Mark and George Stewart from Davis, California, a fellow Canadian Bill Geddes, Dean of Agricultural Biochemistry at the University of Minnesota, Professor H D Kay from the dairy research institute at Reading, Tim Anson, an American employed with the Lever Organisation. Sadly I am the last survivor of that Glasgow group.\n\nThe notion of international scientific societies was not unique. ICSU, its predecessor and the supporting family of national academies and scientific unions had existed since 1919. The Glasgow group was of the opinion, however, that the time was ripe to create an international food science society, since several national food science and technology institutes were in existence. Our British hosts undertook to pursue the idea and the result was the food science congress convened in London in 1962, the first of the series of which China will be the host to the 14th.\n\nThe subsequent history of IUFoST is amply recorded in the archives, but perhaps not everyone is aware of NATO's early intervention.\n\n\"By Joseph H. Hulse, Past President, IUFoST\"\n\nIn response to a shift in research focus among food scientists and technologists towards combating chronic hunger problems in the less developed world, IUFoST released its ‘Budapest Declaration’ during its 7th General Assembly in Budapest, Hungary, 1995. Referencing the Joint FAO/WHO International Conference on Nutrition (Rome, 1992) and its World Declaration on Nutrition, IUFoST declared its determination to minimize hunger and to reduce all forms of malnutrition throughout the world. To do this, IUFoST declared its commitment to work with all other organisations to ensure sustained nutritional well-being for all people in a peaceful, just and environmentally safe world. The declaration further recognised the central role of food science and technology in ensuring the year-round availability of the quantity and variety of safe and wholesome foods necessary to meet the nutritional needs of the world's growing population. This declaration would guide IUFoST’s working policy for the next fifteen years.\n\nDuring 2010’s 13th General Assembly of IUFoST in Cape Town, South Africa, the IUFoST General Assembly adopted the \"Cape Town Declaration\" setting out its commitments to food safety, food security and food science education. It recognized the previous work that had been conducted since the Budapest Declaration while outlining a policy for IUFoST future work with the global food science and technology industry.\n\nMembership in the International Union of Food Science and Technology is open to all nations on the basis of one representative body from each nation or defined territory. IUFoST represents more than 200,000 food scientists and technologists worldwide through its Adhering Bodies. This also includes regional groups in Western Africa (WAAFoST) West African Association of Food Science and Technology, Europe (EFFoST) European Federation of Food Science and Technology, Asia (FIFSTA) The Federation of the Institutes of Food Science and Technology in ASEAN and Latin America/Caribbean (ALACCTA) Latin American and the Caribbean Association of Food Science and Technology.\n\nThe General Assembly develops and controls IUFoST policies and actions. The Governing Council sets the objectives for the Term of Office and The Board implements strategies to achieve the objectives. The Scientific Council maintains the scientific standard and integrity of IUFoST activities.\nIUFoST formed the International Academy of Food Science and Technology (IAFoST), to recognise individuals with outstanding leadership in food science and technology. IAFoST is a learned society composed of elected members - Fellows - from all parts of the world.\nIUFoST's Regional Groupings, EFFoST (Europe), ALACCTA (Latin America), WAAFoST (West Africa) and FIFSTA (South East Asia) are an integral part of the organization. Standing Committees and Disciplinary Groupings comply with the IUFoST Constitution and they are guided by the General Assembly.\n\n• Delivering educational programmes, student scholarships and opportunities for young scientists, including distance learning, which is currently being developed for Sub-Saharan Africa. IUFoST pilot projects are underway in Sub-Saharan Africa providing distance learning modules to food industry middle managers without formal qualifications. These modules are conducted with local advisors/mentors and prepared by international experts. Courses have been created from basic to advanced learning levels in themes like Food Safety, Quality Assurance including HACCP, Shelf Life of Foods, Packaging, Food Laws and Regulations, Food Hygiene, Food Freezing, Practical Human Nutrition, Minimal Processing. IUFoST is also a leader and advises in international programming for food science and technology courses worldwide workshops and training in all aspects of food science and technology worldwide.\n\n• Providing scientific expertise by providing experts for short courses and workshops, and organizing conferences and symposia, in partnership with our Adhering Bodies and regional groupings, on important current issues such as food safety, security, traceability, and food defense by working directly with organizations on a consultant basis. For example, IUFoST has been working with the relevant Chinese Ministries, by invitation and under the auspices of the Ministry of Health, China to present the latest authoritative international perspectives on food safety issues in a series of high level meetings in Beijing. IUFoST has also been assisting member countries in advising their national governments in areas of food legislation when requested.\n\n• Providing global leadership through IUFoST’s biennial World Food Congresses, guidelines for professional conduct in the food science industry, provision of core curricula and accreditation expertise and scientific information bulletins on currently important topics such as obesity, nanotechnology, biotechnology. These bulletins are used by governments, industry and academia worldwide.\n\n• Stimulating exchange of knowledge in the international food science and technology community through the electronic magazine \"The World of Food Science,\" the annual review of the state of global food science and technology, textbooks, world congress review papers and the Hunger Handbook applying food science and technology to improve nutrition and promote national development.\nIUFoST publishes the core food science and technology textbook for food science and technology, \"Food Science and Technology\", published by Wiley-Blackwell.\n\nThe Biennial World Food Congress\n\nIUFoST is holding its 16th World Congress in Iguassu Falls, Brazil from August 5–9, 2012. The theme for this congress is \"Addressing Global Food Security and Wellness through Food Science and Technology\" - www.iufost.org.br\n\nInvolvement in regional symposia (2011-2012)\n\nIUFOST is active in regional symposia across the globe. In 2012 alone IUFoST representatives will attend workshops in East Africa, the FIFSTA regional meetings in Manila, Philippines, Food Safety workshops and meetings in Beijing, China, Warsaw, Poland and Dublin, Ireland.\n\nIUFoST Scientific Information Bulletins (SIBs)\nSIBs addresses cutting edge explain the scientific principles involved in a topic, underpinned by the scientific expertise of the authors of each SIB and including provision of key and scientifically reliable online and other sources of additional information. Each SIB is prepared by world authorities selected by the IUFoST Scientific Council. Each is reviewed and approved by the IUFoST Scientific Council.\n\nInternational specialist bodies form Disciplinary Groups under the IUFoST umbrella. These currently include the International Society of Food Engineers (ISFE), the International Society for Nutraceuticals and Functional Foods (ISNFF), the International Symposium on the Properties of Water (ISOPOW), the International Food Research Collaboration (IFRC) and the International Society of Food Applications of Nanoscale Sciences (ISFANS).\n\nIUFoST Working Groups/Task Forces/Committees\n\nEmergency Response Group\n\nFood Safety Committee/Task Force\n\nFood Safety Panel\n\nFood Security Committee\n\nFood Security Task Force\n\nDistance Education Task Force\n\nEducation Committee\n\nAcademy Fellows Forum\n\nEmerging Issues Forum\n\nFood, Health and Wellness Committee\n\nFood, Health and Wellness Forum\n\nAflatoxin Working Group\n\n\nThe IUFoST secretariat is headquartered in a suburb of Toronto, Ontario, Canada.\n\n"}
{"id": "35639710", "url": "https://en.wikipedia.org/wiki?curid=35639710", "title": "International uniformity of braille alphabets", "text": "International uniformity of braille alphabets\n\nThe goal of braille uniformity is to unify the braille alphabets of the world as much as possible, so that literacy in one braille alphabet readily transfers to another. Unification was first achieved by a convention of the \"International Congress on Work for the Blind\" in 1878, where it was decided to replace the mutually incompatible national conventions of the time with the French values of the basic Latin alphabet, both for languages which use Latin-based alphabets and, through their Latin equivalents, for languages which use other scripts. However, the unification did not address letters beyond these 26, leaving French and German Braille partially incompatible, and as braille spread to new languages with new needs, national conventions again became disparate. A second round of unification was undertaken under the auspices of UNESCO in 1951, setting the foundation for international braille usage today.\n\nBraille arranged his characters in decades (groups of ten), and assigned the 25 letters of the French alphabet to them in order. The characters beyond the first 25 are the principal source of variation today.\n\nIn the first decade, only the top four dots are used; the two supplementary characters have dots only on the right. These patterns are repeated for the second decade, with the addition of a diacritic at dot 3; for the third, at dots 3 and 6; for the fourth, at 6; and for the fifth decade, by duplicating the first decade within the lower four dots.\n\nBraille is in its origin a numeric code. Louis Braille applied the characters in numerical order to the French alphabet in alphabetical order. As braille spread to other languages, the numeric order was retained and applied to the local script. Therefore, where the alphabetical order differed from that of French, the new braille alphabet would be incompatible with French Braille. For example, French was based on a 25-letter alphabet without a \"w\". When braille was adopted for English in the United States, the letters were applied directly to the English alphabet, so that braille letter of French \"x\" became English \"w\", French \"y\" became English \"x\", French \"z\" English \"y\", and French \"ç\" English \"z\". In the United Kingdom, however, French Braille was adopted without such reordering. Therefore, any English book published in braille needed to be typeset separately for the United States and the United Kingdom. Similarly, the letters Egyptian Arabic Braille were assigned their forms based on their nearest French equivalents, so that for example Arabic \"d\" had the same braille letters as French \"d\". For Algerian Arabic Braille, however, the braille characters were assigned to the Arabic alphabet according to the Arabic alphabetical order, so that Algerian \"d\" was the same character as Egyptian \"h\". Thus an Arabic book published in Algeria was utterly unintelligible to blind Egyptians and vice versa.\n\nIn addition, in other alphabets braille characters were assigned to print letters according to frequency, so that the simplest letters would be the most frequent, making the writing of braille significantly more efficient. However, the letter frequencies of German were very different from those of English, so that frequency-based German braille alphabets were utterly alien to readers of frequency-based American Braille, as well as to numerically based German, English, and French Braille.\n\nThe 1878 congress, convening representatives from France, Britain, Germany, and Egypt, decided that the original French assignments should be the norm for those countries:\nGradually the various reordered and frequency-based alphabets fell out of use elsewhere as well.\n\nThis decision covered the basic letters of the French alphabet at the time; \"w\" had been appended with the extra letters, so the 26 letters of the Basic Latin alphabet are slightly out of numeric order:\n\nFor non-Latin scripts, correspondences are generally based, where possible, on their historical connections or phonetic/transcription values. For example, Greek γ \"gamma\" is written \"g\", as it is romanized, not \"c\", as it is ordered in the alphabet or as it is related historically to the Latin letter \"c\". Occasional assignments are made on other grounds, such as Greek ω \"omega\", which is written \"w\", as in beta code and internet chat alphabets, due to the graphic resemblance of Latin \"w\" and Greek \"ω\".\n\nCorrespondences among the basic letters of representative modern braille alphabets include:\n\nThe 1878 congress only succeeded in unifying the basic Latin alphabet. The additional letters of the extended French braille alphabet, such as , are not included in the international standard. The French , for example, corresponds to print , whereas the in English and German braille transcribes , and the in Hungarian and Albanian braille is .\n\nLanguages that in print are restricted to the letters of the basic Latin script are generally encoded in braille using just the 26 letters of grade-1 braille with their French/English values, and often a subset of those letters. Such languages include:\n\nIn these languages, print digraphs such as \"ch\" are written as digraphs in braille too.\n\nLanguages of the Philippines are augmented with the use of the accent point with \"n\", , for \"ñ\". These are Tagalog, Ilocano, Cebuano, Hiligaynon, and Bicol; \"Ethnologue\" reports a few others.\n\nLanguages of Zambia distinguish \"ñ/ŋ/ng’\" from \"ng\" with an apostrophe, as in Swahili Braille: \"ng’\" vs \"ng\". These are Lozi, Kaonde, Lunda, and Tonga. Ganda (Luganda) may be similar.\n\n\"Ethnologue\" 17 reports braille use for Mòoré (in Burkina Faso), Rwanda, Rundi, Zarma (in Niger), and Luba-Sanga, but provides few details.\n\nIn 1929 in Paris, the American Foundation for Overseas Blind sponsored a conference on harmonizing braille among languages which use the Latin script, which had diverged in the previous decades.\n\nWhen additional letters are needed for a new braille alphabet, several remedies are used. \n\nA regional UNESCO conference on braille uniformity for southern Asia took place in 1950. This led to a conference with global scope the following year. The 1951 congress found many conflicting braille assignments:\n\nThe congress recognized the role of English contracted braille in establishing a partial international standard, and recommended that alphabets follow existing conventions as much as possible.\n\nThe following assignments include common secondary vowels and consonants: Whenever a second \"a-\" or \"d-\"based letter is needed in an alphabet, use of the same secondary braille letter is common. Additional alternative letters are used in some braille alphabets. English grade 2 braille correspondences are given below for recognition; these are often the basis of international usage.\n\n"}
{"id": "8668232", "url": "https://en.wikipedia.org/wiki?curid=8668232", "title": "Jasubhai Digital Media", "text": "Jasubhai Digital Media\n\nJasubhai Digital Media (JDM) was a part of Jasubhai Group, Mumbai, India. 9.9 Media acquired it in December 2007. It is a publisher of several technology magazines like Digit (magazine), Skoar and CTO Forum. The company has also organized events like CTO Forum, CRN Channel Awards, Circle of Influence, CRN CARE, Channel Summit etc.\n\nThe company was also the publisher of Networking Computing India, and CRN - India, in collaboration with CMP Media LLC. USA. However, as of 2006 CMP Media moved out of the partnership and entered the Indian publishing market to market Network Computing and CRN - India on its own.\n\n\n"}
{"id": "198856", "url": "https://en.wikipedia.org/wiki?curid=198856", "title": "Lego Mindstorms", "text": "Lego Mindstorms\n\nLego Mindstorms is a hardware software platform produced by Lego for the development of programmable robots based on Lego building blocks. Each version of the system includes an intelligent \"brick\" computer that controls the system, a set of modular sensors and motors, and Lego parts from the Technic line to create the mechanical systems.\n\nSince creation, there have been four generations of the Mindstorms platform: the original Robotics Invention System, NXT, NXT 2.0, and EV3. With each platform release, the motor and sensor capabilities expanded. The latest system, Lego Mindstorms EV3, was released on September 1, 2013. Some robot competitions use this set, such as the FIRST Lego League and the World Robot Olympiad.\n\nThe hardware and software roots of the Mindstorms Robotics Invention System kit go back to a programmable brick prototype created at the MIT Media Lab in 1987, based on the Lego/LOGO programming environment. A second prototype series was developed in the mid-1990s before the final device was released in 1998.\n\nThe first visual programming environment was called LEGOsheets, since it was created by the University of Colorado in 1994 based on AgentSheets.\n\nMindstorms is named after the book \"\" by Seymour Papert.\n\nThe first generation of Lego Mindstorms was built around a brick known as the RCX (Robotic Command eXplorers). It contains an 8-bit Renesas (then a part of Hitachi) H8/300 microcontroller as its internal CPU. It included 32K of RAM to store the firmware and user programs. The brick is programmed by uploading a program (written in one of several available programming languages) from a Windows or Mac computer to the brick's RAM via a special infrared (IR) interface. After the user starts a program, an RCX-enabled Mindstorms creation can function independently on its own, acting on internal and external stimuli according to the programmed instructions. Also, two or several more RCX bricks can communicate with each other through the IR interface, enabling inter-brick cooperation or competition. In addition to the IR port, the system includes three sensor input ports and three motor output ports (which can also be used to drive other electrical devices such as lamps and so forth). A built-in LCD can display the battery level, the status of the input/output ports, which program is selected or running, and other information.\n\nVersion 1.0 RCX bricks feature a power adapter jack to allow continuous operation instead of the limited operation time when using batteries. In version 2.0 (as well as later 1.0s included in the RIS 1.5), the power adapter jack was removed. Power adapter equipped RCX bricks are popular for stationary robotics projects (such as robot arms) or for controlling Lego model trains. In the latter context, the RCX needs to be programmed with Digital Command Control (DCC) software to operate multiple wired trains.\n\nThe IR interface on the RCX is able to communicate with Spybots, Scout Bricks, Lego Train, and the NXT (using a third-party infrared link sensor.) The RCX 1.0 IR receiver carrier frequency is 38.5 kHz, while the RCX 2.0 IR carrier frequency is 76 kHz. Both versions can transmit on either frequency. The carrier signal is generated by one of the RCX's internal timers. The RCX communicates with a computer using a Serial or USB IR tower. The tower is supported by Windows 98, Me, and XP (32-bit). A patch is available for hyper-threading/multi-core CPUs. There is no formal support for Windows Vista (32-bit), but there are reports of correct functionality. The USB tower does not work on a 64-bit OS unless a 32-bit OS is used in conjunction with a virtual machine. The serial tower works normally under 64-bit Windows 7 using a third-party USB-to-serial adapter.\n\nAll versions of the RCX have a unique number printed on it, necessary for technical support and used as the ID number of the RCX for your Lego Mindstorms account on the now-defunct Lego Mindstorms RCX website. The first RCX produced is marked \"000001\" and was on display at the Mindstorms 10th Anniversary event.\n\nLego Mindstorms' programming is command box programming, rather than code programming.\n\nLego-supplied languages:\nPopular third-party languages:\n\nThe Lego camera on its own is technically not a robotic toy; rather, it is a normal webcam (a Logitech QuickCam Web) packaged into a Lego shell. Being a normal webcam, the Lego camera is, unlike most Mindstorms products, not programmable and is only usable connected to a PC or some other device that supports USB webcams.\n\nThe Lego camera is meant to be used with the included Vision Command software which can also interface with an RCX and thus enables creating robots with \"vision\". The software is capable of detecting different lightings, motion, and colors. It can also be used with any other software that uses a webcam. The webcam is capable of recording up to 30 frames per second. It also contains a microphone to record sound for videos.\n\nThe first programmable Lego product was released in 1986. In 1987, Dacta released an Apple IIe interface card set and an IBM-PC-compatible ISA interface card set, each coming with a ribbon cable. The control panel included six non-reversible 4.5V output ports, three reversible 4.5V output ports (each using the power lines from their two adjacent non-reversible ports), two 4.5V input ports, and one continuous 4.5V output port. It also features a manual-override stop-button. Using programs running on the host computer, the user could create stationary programmable robotic Lego inventions using the older 4.5V system. The 4.5V PC Interface was superseded by the 9V-based Dacta Control Lab in 1995.\n\nThe control center (1990) was the first programmable standalone Lego product, in the sense of being able to store sequence-based programs and run them. It featured three output ports and manual control, and it was only capable of storing linear sequences of manual input plus timing information. It could store up to two programs at once.\n\nThe manual controls could be used to independently control the three motors. To record a program; the controller had to be put in programming mode, and then any manual control would be recorded to the program. Pauses could also be included in a program. When the recording was done, the controller could successfully recall and execute any manual action done during the recording. The executing program could be set to loop infinitely.\n\nCompared to the later programmable controllers, the Technic control center is extremely simple and can only barely be called programmable.\n\nReleased in 1995, the Dacta Control Lab was the first Lego product to feature the sensors used in later 9V-based automated Lego products. The control lab was a datalogger, which featured four passive input ports, four active input ports, eight controllable 9V output ports, and one continuous output port. It also featured a manual-override stop-button. The control panel connected to a computer using a serial-port with a specially designed adapter cable and a supplied computer-program allowed the user to conditionally program the outputs. This allowed for robotic operation of mostly stationary Lego inventions. The Control Lab superseded the old 4.5V PC interface from 1989, which was the first fully programmable Lego interface.\n\nThe connectors of the early sensors were color-coded according to their type. Active sensors had blue connectors and Passive sensors had yellow connectors. Later Pbricks kept the color-coding for the input ports, but the later sensors dropped the color-coding of the connectors (using black connectors instead). The early touch-sensors were also of a different kind and shape compared to the later touch-sensors. Most notably, instead of featuring a removable cable, the cable was fixed just like the other sensors. These early sensors also featured longer cables.\n\nThe Control Lab was designed for schools and educational use and was as a result not available to the mass market. It was later replaced by the RCX and the educational release of the Robot Invention System which allowed for mobile inventions in addition to stationary inventions.\n\nCybermaster was mainly sold in Europe and Australia/New Zealand and was available for a short time in the United States via the Lego Club magazines.\nIt was aimed at an older audience as an early attempt of merging with robotics and Lego.\n\nThe brick shares many, especially software, features with the RCX but differs in appearance and technical specifications: one output (plus two built-in) and four sensors.\n\n\nDespite its obvious limitations it has a number of advantages over its 'big brother', the RCX.\n\n\nThis makes it very useful for various mobile platforms and performing advanced motion/positioning tasks.\n\nIt talks the same protocol as the RCX but cannot communicate directly to it (due to IR vs RF) but with a repeater (a computer with 2 serial ports and a simple program) they can communicate indirectly.\n\nSold as part of the Barcode Truck kit.\nThis unit was the first programmable brick (or Pbrick).\nIt features a single motor, a single touch sensor and a light sensor.\nIt is programmed by setting it to 'learn' and using the light sensor to feed barcoded commands. The command set is very limited.\nSince barcode is just a series of variances in light, this form of command entry was dubbed VLL (Visual Light Link) and has been used in several later Lego models.\n\nLego also released a blue computer called the \"Scout\", which has 2 sensor ports, 2 motor ports (plus one extra if linked with a Micro Scout using a fiber optic cable), and a built in light sensor, but no PC interface. It comes with the Robotics Discovery Set. The Scout can be programmed from a collection of built-in program combinations. In order to program the Scout, a user must enable \"power mode\" on it. The Scout can store one program.\n\nThe Scout is based on a Toshiba microcontroller with 32KB of ROM and 1KB of RAM, where about 400 bytes are available for user-programs. Due to the extremely limited amount of RAM, many predefined subroutines were provided in ROM. The Scout only supports passive external sensors, which means that only touch, temperature and other unpowered sensors can be used. The analog-to-digital converters used in the Scout only have a resolution of 8 bits in contrast to the 10-bit converters of the RCX.\n\nThere was a plan for Lego to create a booster set that allows you to program the Scout from a computer with a software such as RCX code. However, due to the complexity of this project, it was abandoned.\n\nThe RCX can control the Scout brick using the \"Send IR Message\" program block. The RCX does all of the controlling, and therefore can be programmed with the PC, while the Scout accepts commands. The Scout brick must have all of its options set to \"off\".\n\nThe Micro Scout was added as an entry level to Lego robotics.\nIt is a very limited Pbrick with a single built-in light sensor and a single built-in motor.\nIt has seven built-in programs and can be controlled by a Scout, Spybotics or RCX unit using VLL. Like the Scout, the Micro Scout is also based on a microcontroller from Toshiba.\n\nThe unit was sold as part of the Droid Developer Kit (featuring R2-D2) and later the Darkside Developer Kit (featuring an AT-AT Imperial Walker).\n\nSpybotics is a robotics package. It consists of four colour-coded robots called Spybots, a programming language with which to control the Spybots, and ten simulated missions.\n\nLego Mindstorms' programming is command box programming, rather than code programming.\n\n\nLego Mindstorms NXT is a programmable robotics kit released by Lego in July 2006, replacing the first-generation LEGO Mindstorms kit.\nThe kit consists of 577 pieces, including: 3 servo motors, 4 sensors (ultrasonic, sound, touch, and light), 7 connection cables, a USB interface cable, and the NXT Intelligent Brick. The Intelligent Brick is the \"brain\" of a Mindstorms machine. It lets the robot autonomously perform different operations. The kit also includes NXT-G, a graphical programming environment that enables the creation and downloading of programs to the NXT. The software also has instructions for 4 robots; Alpha-Rex (a humanoid),Tri-Bot (a car), Robo-Arm T-56 (a robotic arm), and Spike (a scorpion)\n\nThis is the educational version of the NXT set from Lego Education, which is made for school use. Software is sold separately, and the Education Resource Set for the best use. It includes a light sensor, an ultrasonic sensor, a sound sensor, three lamps and a pair of touch sensors. The first set consists of about 400 pieces, and the extra set consists of about 600 pieces. The Education Version is most suited for those who have older versions of Mindstorms sets around, mostly thanks to its three converter cables. It costs about US$410.00 with the Bluetooth Dongle.\n\nThe Lego Mindstorms NXT 2.0 was launched on 5 August 2009. It contains 619 pieces (includes sensors and motors), two Touch Sensors, an Ultrasonic Sensor, and introduced a new Color Sensor. The NXT 2.0 uses Floating Point operations whereas earlier versions use Integer operation. The kit costs around US$280.\n\nThe Lego Mindstorms EV3 is the third generation Lego Mindstorms product. EV3 is a further development of the NXT. The system was released on September 1, 2013.\nThe LEGO MINDSTORMS EV3 set includes motors, sensors, the EV3 programmable brick, 550+ LEGO Technic elements and a remote control. \nThe EV3 can be controlled by smart-devices. It can boot an alternative operating system from a microSD card, which makes it possible to run ev3dev, a Debian-based operating system.\n\nMindstorms kits are also sold and used as an educational tool, originally through a partnership between Lego and the MIT Media Laboratory. The educational version of the products is called \"Lego Mindstorms Education EV3 \", and comes with the ROBOLAB GUI-based programming software, developed at Tufts University using the National Instruments LabVIEW as an engine. In addition, the shipped software can be replaced with third party firmware and/or programming languages, including some of the most popular ones used by professionals in the embedded systems industry, like Java and C. One of the differences between the educational series, known as the \"Challenge Set\", and the consumer series, known as the \"Inventor Set\", is that it includes another touch sensor and several more gearing options. However, there are several other standouts between the two versions that one may not recognize unless doing a side by side analysis of what each offers. The version sold through LEGO Education is designed for a deeper level of learning or teaching that often happens in a classroom or school setting. The LEGO Education version comes with support called the Robot Educator. This includes 48 tutorials to walk the learner through the basics of coding to more sophisticated and complex concepts such as data logging. This resource to support the learner and/or educator are not included in the retail version of Mindstorm. It's always a good idea to reach out to a LEGO Education consultant to inquire of other differences as there are several more. The retail version was designed for more of a home/toy use vs the educator model was designed to support deeper learning with extra resources and pieces to do so. This is why the LEGO Education Mindstorm contains more sensors and parts than the retail version.\n\nThere is a strong community of professionals and hobbyists of all ages involved in the sharing of designs, programming techniques, creating third-party software and hardware, and contributing of other ideas associated with Lego Mindstorms. The Lego Mindstorms system/website is organized much like a wiki, harnessing the creative potential and collaborative efforts of participants. Lego also encourages sharing and peering by making software code available for downloading and by holding various contests and events.\n\n\n\n"}
{"id": "19739765", "url": "https://en.wikipedia.org/wiki?curid=19739765", "title": "Light skin in Japanese culture", "text": "Light skin in Japanese culture\n\nAlthough skin tone differs based on a person's racial background, those with fair skin have difficulty maintaining skin tone due to melanin production. In Japan the preference for skin that is white and free of blemishes has been documented since at least the Heian period (794-1185), as in books like \"The Pillow Book\" and \"The Tale of Genji\". There is an old proverb which refers to a white-skinned woman being beautiful even if her features are not attractive. \n\nThe cultural fallout of Japanese colonial rule in Taiwan (1895–1945) has resulted in Taiwanese women becoming consumers of Japanese skin whitening products in the 20th century. Mainland China has also become a large market for \"bihaku\" products from companies like Shiseido, Shu Uemura and SK-II in the 21st century. Further expansion into pan-Asian markets may be represented by Girls' Generation partnership with Dior in 2011 to advertise their lightening cream, appealing to Korean Wave culture consumers.\n\nBihaku products are highly popular among mature women. They are also popular with teenage girls and those in their twenties who desire to look like pop singers, such as Ayumi Hamasaki, and are promoted in numerous youth fashion magazines such as \"Popteen\" and \"S Cawaii!\". Bihaku products are also prevalent and a key item in numerous youth subcultures such as gyaru and ageha girls. An opposition to the idea of fair skin beauty grew with the gyaru subculture called \"ganguro\" in the 1990s although died out by the end of the 2000s.\n\nThe popular method of \"bihaku\" is to use cosmetics that stop the production of melanin. Traditionally \"uguisu no fun\" was used to lighten and balance skin tone although today it is considered a luxury item. The most popular products often contain sake and rice bran which contain kojic acid.\n\nFor skin whitening cosmetics for use by the public, the Ministry of Health, Labour and Welfare has recognized a combination of active ingredients. These are mainly arbutin and kojic acid. Other ingredients include Vitamin C derivatives, tranexamic acid and ten-odd other types. Many of these active ingredients work through inhibiting catechol oxidase. Some types of BB cream, VIORIS products are also said to have skin whitening effects which contributes to the popularity of the cream in Asian markets.\n\nAs for other methods of skin whitening, other decolorizing chemicals can be used. Aesthetic skin decolorizing surgeries can also be performed, but excessive cleansings can cause a number of problems, such as facial inflammation, but in the 2000s this is in decline. Historically, the droppings of the have been used as an ingredient in face-washes for whitening skin.\n\n"}
{"id": "21772137", "url": "https://en.wikipedia.org/wiki?curid=21772137", "title": "List of AMD chipsets", "text": "List of AMD chipsets\n\nThis is an overview of chipsets sold under the brand AMD, manufactured before May 2004 by the company itself, before the adoption of open platform approach as well as chipsets manufactured by ATI Technologies (ATI) after July 2006 as the completion of the ATI acquisition.\n\nA-Link Express and A-Link Express II are essentially PCIe 1.1 x4 lanes.\n\nSee Comparison of ATI Chipsets for the comparison of chipsets sold under the ATI brand for AMD processors, before AMD's acquisition of ATI.\n\nA-Link Express III is essentially PCIe 2.0 x4 lanes.\n\n Parallel ATA, also known as Enhanced IDE supports up to 2 devices per channel.\n\n Parallel ATA, also known as Enhanced IDE supports up to 2 devices per channel.\n\nFor AMD APU models from 2011 till 2016.\nNote 1: Supports SDHC up to 32 GB, 4 pins @ 50 MHz.\nCodename:\n\nUMI:\n\nB350 can support PCIe x16 + PCIe x4 CrossFire configuration, if there is a PCIe x4 slot available on the motherboard.\n\n\n"}
{"id": "31085661", "url": "https://en.wikipedia.org/wiki?curid=31085661", "title": "Louisa Margaret Dunkley", "text": "Louisa Margaret Dunkley\n\nLouisa Margaret Dunkley (28 May 1866 – 10 March 1927) was an Australian telegraphist and labor organizer who successfully campaigned for the right for women to obtain equal pay for equal work in the Australian commonwealth public service.\n\nLouisa Margaret Dunkley was born in Richmond, Melbourne, Australia. She was the daughter of William James Dunkley, a boot importer, and Mary Ann Regan, both from London, England. She was educated at Catholic girls schools.\n\nShe began to work for the Postmaster-General's Department in 1882. She studied telegraphy, passing the Public Service Examination on 11 June 1887 and went on to become an operator in 1888, working in the Melbourne metropolitan post and telegraph offices. In 1890 she qualified as a telegraphist and was promoted to a position in the Chief Telegraph Office. While working as a telegraphist in the early 1890s, she became aware of the unequal pay and working conditions of the female operators. Learning of efforts by women telegraphists in New South Wales to achieve equality in pay and status, she formed a committee to advocate for similar improvements in the Post and Telegraph Department of Victoria. While her efforts resulted in pay increases for the women operators, they did not achieve equality with the male operators, and the resulting controversy resulted in her being transferred to a remote post office.\n\nIn 1900, Dunkley and other operators established the Victorian Women's Post and Telegraph Association in order to advocate for equal pay and working conditions. Mrs. Webb, a postmistress, was elected president, and Dunkley was elected vice president and spokesperson (1900–1904). She was elected as a delegate to a conference of telegraphists in Sydney in October 1900, and there presented her case for equality under the new Commonwealth Public Service conditions. While some at the conference opposed her, she was able to secure the support of Parliament, and, as a result, a provision for equal pay for female telegraphists and postmistresses was included in the Commonwealth Public Service Act of 1902. The Victorian Women's Post and Telegraph Association continued to exist within the Australian Commonwealth Post and Telegraph Association, first as a state association and then a state branch of the federal body, until 1920.\n\nThe Victorian federal electorate of Dunkley is named after her.\n\n"}
{"id": "87684", "url": "https://en.wikipedia.org/wiki?curid=87684", "title": "Marquetry", "text": "Marquetry\n\nMarquetry (also spelled as marqueterie; from the French \"marqueter\", to varigate) is the art and craft of applying pieces of veneer to a structure to form decorative patterns, designs or pictures. The technique may be applied to case furniture or even seat furniture, to decorative small objects with smooth, veneerable surfaces or to freestanding pictorial panels appreciated in their own right.\n\nMarquetry differs from the more ancient craft of inlay, or intarsia, in which a solid body of one material is cut out to receive sections of another to form the surface pattern. The word derives from a Middle French word meaning \"inlaid work\".\n\nThe veneers used are primarily woods, but may include bone, ivory, turtle-shell (conventionally called \"tortoiseshell\"), mother-of-pearl, pewter, brass or fine metals. Marquetry using colored straw was a specialty of some European spa resorts from the end of the 18th century. Many exotic woods as well as common European varieties can be employed, from the near-white of boxwood to the near-black of ebony, with veneers that retain stains well, like sycamore, dyed to provide colors not found in nature.\n\nThe French cabinet maker Andre-Charles Boulle (1642–1732) specialized in furniture using metal and either wood or tortoiseshell together, the latter acting as the background.\nThe simplest kind of marquetry uses only two sheets of veneer, which are temporarily glued together and cut with a fine saw, producing two contrasting panels of identical design, (in French called \"partie\" and \"contre-partie\", \"part\" and \"counterpart\").\nMarquetry as a modern craft most commonly uses knife-cut veneers. However, the knife-cutting technique usually requires a lot of time. For that reason, many marquetarians have switched to fret or scroll saw techniques. Other requirements are a pattern of some kind, some brown gummed tape (IE as the moistened glue dries it causes the tape to shrink and so the veneer pieces are pulled closer together), PVA glue and a base-board with balancing veneers on the alternate face to compensate stresses. Finishing the piece will require fine abrasive paper always backed by a sanding block. Either ordinary varnish, special varnishes, modern polyurethane -oil or water based- good waxes and even the technique of French polish are different methods used to seal and finish the piece.\n\nSand shading is a process used to make a picture appear to be more three-dimensional. A piece of veneer to be incorporated into a picture is partially submerged into hot sand for a few seconds.\n\nAnother process is engraving fine lines into a picture and filling them with a mixture of India ink and shellac.\n\nFurniture inlaid with precious woods, metals, glass and stones is known from the ancient world and Roman examples have been recovered from the first century sites of Pompeii and Herculaneum demonstrating that the technique was highly advanced. The revival of the technique of veneered marquetry had its inspiration in 16th century Florence and at Naples ultimately from classical inspiration. Marquetry elaborated upon Florentine techniques of inlaying solid marble slabs with designs formed of fitted marbles, jaspers and semi-precious stones. This work, called \"opere di commessi\", has medieval parallels in Central Italian \"Cosmati\"-work of inlaid marble floors, altars and columns. The technique is known in English as pietra dura, for the \"hardstones\" used: onyx, jasper, cornelian, lapis lazuli and colored marbles. In Florence, the Chapel of the Medici at San Lorenzo is completely covered in a colored marble facing using this demanding jig-sawn technique. \nTechniques of wood marquetry were developed in Antwerp and other Flemish centers of luxury cabinet-making during the early 16th century. The craft was imported full-blown to France after the mid-seventeenth century, to create furniture of unprecedented luxury being made at the royal manufactory of the Gobelins, charged with providing furnishings to decorate Versailles and the other royal residences of Louis XIV. Early masters of French marquetry were the Fleming Pierre Golle and his son-in-law, André-Charles Boulle, who founded a dynasty of royal and Parisian cabinet-makers (\"ébénistes\") and gave his name to a technique of marquetry employing \"tortoiseshell\" and brass with pewter in arabesque or intricately foliate designs. \"Boulle\" marquetry dropped out of favor in the 1720s, but was revived in the 1780s. In the decades between, carefully matched quarter-sawn veneers sawn from the same piece of timber were arranged symmetrically on case pieces and contrasted with gilt-bronze mounts. Floral marquetry came into favor in Parisian furniture in the 1750s, employed by cabinet-makers like Bernard van Risenbergh, Jean-Pierre Latz and Simon-François Oeben. The most famous royal French furniture veneered with marquetry are the pieces delivered by Jean Henri Riesener in the 1770s and 1780s. The \"Bureau du Roi\" was the most famous amongst these famous masterpieces.\n\nMarquetry was not ordinarily a feature of furniture made outside large urban centers. Nevertheless, marquetry was introduced into London furniture at the Restoration of Charles II in 1660, the product of immigrant Dutch 'inlayers', whose craft traditions owed a lot to Antwerp. Panels of elaborately scrolling \"seaweed\" marquetry of box or holly contrasting with walnut appeared on table tops, cabinets, and long-case clocks. At the end of the 17th century, a new influx of French Huguenot craftsmen went to London, but marquetry in England had little appeal in the anti-French, more Chinese-inspired high-style English furniture (mis-called 'Queen Anne') after \"ca\" 1720. Marquetry was revived as a vehicle of Neoclassicism and a 'French taste' in London furniture, starting in the late 1760s. Cabinet-makers associated with London-made marquetry furniture, 1765–1790, include Thomas Chippendale and less familiar names, like John Linnell, the French craftsman Pierre Langlois, and the firm of William Ince and John Mayhew.\nAlthough marquetry is a technique separate from inlay, English marquetry-makers were called \"inlayers\" throughout the 18th century. In Paris, before 1789, makers of veneered or marquetry furniture (\"ébénistes\") belonged to a separate guild from chair-makers and other furniture craftsmen working in solid wood (\"menuisiers\").\n\nTiling patterning has been more highly developed in the Islamic world than anywhere else, and many extraordinary examples of inlay work have come from Middle Eastern countries such as Lebanon and Iran. \n\nAt Tonbridge and Royal Tunbridge Wells, England, souvenir \"Tunbridge wares\"— small boxes and the like— made from the mid-18th century onwards, were veneered with panels of minute wood mosaics, usually geometric, but which could include complicated subjects like landscapes. They were made by laboriously assembling and gluing thin strips and shaped rods, which then could be sliced crossways to provide numerous mosaic panels all of the same design.\n\nMarquetry was a feature of some centers of German cabinet-making from c. 1710. The craft and artistry of David Roentgen, Neuwied, (and later at Paris as well) was unsurpassed, even in Paris, by any 18th-century marquetry craftsman.\n\nMarquetry was not a mainstream fashion in 18th-century Italy, but the neoclassical marquetry of Giuseppe Maggiolini, made in Milan at the end of the century is notable.\n\nThe classic illustrated description of 18th century marquetry-making was contributed by Roubo to the \"Encyclopédie des Arts et Métiers,\" 1770. The most thorough and dependable 20th-century accounts of marquetry, in the context of Parisian cabinet-making, are by Pierre Verlet.\n\nDuring the 80s developed a technique called technique VRIZ, layering two veneer layers on top of each other and sanding through the top one, to the point of fiber transparency. This has been used mainly in France, by professionals and marquetry students of the École Boulle. With its technique, Georges Vriz promoted a resurgence of the marquetry he called RENAISSANCE. He launch the contemporary marquetry. In the US the technique has been used at the American School of French Marquetry by one of the teachers, artist Patrice Lejeune. The school staff is also proposing a new name for it: \"Given that 'piercing' is an unfortunate mistake in the veneering world, we chose to use the word \"Fusion\" instead, by which term the artist expresses his intention of sanding through the veneer as a decorative, textural effect, not as a mistake.\"\nPatrice Lejeune again uses a technique he calls \"sprinkling\": using waste - sawdust, shavings, scrapings etc. - as pigments to create a range of effects. Arguably this is no longer marquetry in the pure sense, since it spills over into textured painting, even collage to some extent. This technique also was invented by Georges Vriz, who employed it on a series of large panels exhibited in Paris at the arency. It has been used mainly in France by professionals and students of the École de la Bonne Graine in 1996.\n\nCutting-edge tech has also been applied to marquetry. Among these is laser cutting, where the design is drawn or imported as a CAD or vector file and each piece is cut separately; each different species of wood-and thickness-may need a specific adjustment of the beam power; the offset will determine the gap between the pieces. In some cases, the beam will leave a dark edge due to the high heat required by the process.\n\n\n"}
{"id": "22569459", "url": "https://en.wikipedia.org/wiki?curid=22569459", "title": "Ministry of Science and Technology (Pakistan)", "text": "Ministry of Science and Technology (Pakistan)\n\nThe Ministry of Science and Technology (, abbreviated as MoST) is a Cabinet-level ministry of the Government of Pakistan concerned with science and technology in Pakistan and in general, Pakistan's science policy, planning, co-ordination and directing of efforts to initiate and launch scientific and technological programs as well as projects aimed at economic development. The ministry is coordinated by the Federal Minister for Science and Technology and is headquartered in Islamabad.\n\nThe Ministry of science and Technology is the national focal Ministry and enabling arm of the Government of Pakistan for planning, co-ordination and directing efforts to initiate and launch scientific and technological programs and projects aimed at economic development of the country. The Ministry is working on the national agenda to have a sound and sustainable Science and technological research base which would lead to the socio-economic development of the country and to achieve the vision for a better Pakistan.\n\nThe principle agenda of the MoST is building Pakistan's technological competence in the 21st century by leap forging into new markets, develop a larger pool of human resource for reverse brain drain and integrate the soft technology infrastructure into hard modern technological base, strengthen technology institutions, effective S & TR governance and enhance the capacity if indigenous innovation systems.\n\nIn 1950, the office of Science Adviser was created by former Prime minister Liaqat Ali Khan who sent an invitation to Salimuzzaman Siddiqui to emigrate to Pakistan. An office was set up in Prime minister Secretariat and Siddiqui served as its first Science Adviser. In 1959, Military dictator of Pakistan and then-known as Commander-in-Chief of Pakistan Army, Field Marshal Ayub Khan moved the office in Presidential Residence. World-renowned scientist Dr. Abdus Salam was appointed as science adviser to the President, who continued as Science Adviser to Prime minister Zulfikar Ali Bhutto's democratic regime. The post was colloquially known as \"President's Science Adviser\" till Pakistan's political system was shifted back to Parliamentary democracy system through a constitutional amendment, passed by the Parliament in 1974. The post was renamed as \"Prime minister's Science Adviser\".\n\nIn Pakistan, a Science Adviser is a prestigious and an important tier in Pakistan's science circle. A science adviser is a chief and principal adviser to the Prime minister with a full status of Federal Cabinet minister. A science adviser advises the Prime minister on the effects of science and technology on domestic and international affairs and also mandate to supervise the government-led science and technology and engineering projects in the government agencies and departments. As of today, the director of this office is colloquially known as the \"Prime minister's Science Adviser\".\n\nThe following agencies are situated under the Ministry of Science and Technology:-\n\n\n"}
{"id": "16014461", "url": "https://en.wikipedia.org/wiki?curid=16014461", "title": "Multiple satellite imaging", "text": "Multiple satellite imaging\n\nMultiple satellite imaging is the process of using multiple satellites to gather more information than a single satellite so that a better estimate of the desired source is possible. So something that cannot be seen with one telescope might be visible with two or more telescopes.\n\nInterferometry is the process of combining waves in such a way that they constructively interfere. When two or more independent sources detect a signal at the same given frequency those signals can be combined and the result is better than each one individually. An overview of Astronomical interferometers and a History of astronomical interferometry can be referenced from their respective pages.\n\nThe NASA Origins Program was created in the 1990s to ultimately search for the origin of the universe. The theory that the Origins Program is based on is: since light travels at a constant speed until it is absorbed by something; there is still light that was part of the first light ever created traveling about the universe and ultimately some of that light is coming in the general direction of Earth. So a satellite system capable of collecting light from the beginning of the universe would be able to tell us more about where we came from.\n\nThere is also the constant search for life in other worlds. A satellite system using the interferometric technologies mentioned above would be able to have a much higher resolution than any of the current deep space imaging systems. A space systems also reduces the amount of interference due to lack of an atmosphere.\n\nNASA is currently focused on the Vision for Space Exploration and has reduced current funding for scientific unmanned space exploration in favor of human exploration. These budget cuts have slowed the multiple satellite imaging development but it continues. While Project Prometheus and other scientific missions have ended other projects such as Terrestrial Planet Finder continue.\n\n"}
{"id": "3801553", "url": "https://en.wikipedia.org/wiki?curid=3801553", "title": "NEXUS (rocket)", "text": "NEXUS (rocket)\n\nThe NEXUS reusable rocket was a concept design created in the 1960s by a group at General Dynamics led by Krafft Arnold Ehricke. It was intended as the next leap beyond the Saturn V, carrying up to eight times more payload. Several versions were designed, including 12,000 and 24,000 short ton vehicles with payloads of one thousand and two thousand short tons respectively. The larger version had a diameter of 202 feet (61.5 metres). It was never built.\n\n"}
{"id": "56557404", "url": "https://en.wikipedia.org/wiki?curid=56557404", "title": "Networked flying platform", "text": "Networked flying platform\n\nNetworked flying platforms (NFPs) are unmanned flying platforms of various types including unmanned aerial vehicles (UAVs), drones, tethered balloon and high-altitude/medium-altitude/low-altitude platforms\n(HAPs/MAPs/LAPs) carrying RF/mmWave/FSO payload (transceivers) along with an extended battery life capabilities, and are floating or moving in the air at a quasi-stationary positions with the ability to move horizontally and vertically to offer 5G and beyond 5G (B5G) cellular networks and network support services.\n\nThere are following two possible NFPs deployment configurations: \n\n\nNFPs can be manually (non-autonomously) controlled but mainly designed for autonomous pre-determined flights.. NFPs can either operate in a single NFP mode where NFPs do not cooperate with other NFPs in the network, if exists or a swarm of NFPs where multiple interconnected NFPs cooperate, collaborate and perform the network mission autonomously with one of the NFPs designated as mother-NFP\n\n"}
{"id": "993506", "url": "https://en.wikipedia.org/wiki?curid=993506", "title": "Noisemaker", "text": "Noisemaker\n\nA noisemaker is something intended to make a loud noise, usually for fun. The word may refer to:\n\nNoisemakers are popular with children as toy musical instruments. They can be perfectly included in loud rhythm bands.\n"}
{"id": "1676212", "url": "https://en.wikipedia.org/wiki?curid=1676212", "title": "Operation Ivy Bells", "text": "Operation Ivy Bells\n\nOperation Ivy Bells was a joint United States Navy, CIA, and National Security Agency (NSA) mission whose objective was to place wire taps on Soviet underwater communication lines during the Cold War.\n\nDuring the Cold War, the United States wanted to learn more about Soviet submarine and missile technology, specifically ICBM test and nuclear first strike capability.\n\nIn the early 1970s the U.S. government learned of the existence of an undersea communications cable in the Sea of Okhotsk, which connected the major Soviet Pacific Fleet naval base at Petropavlovsk on the Kamchatka Peninsula to the Soviet Pacific Fleet's mainland headquarters at Vladivostok. At the time, the Sea of Okhotsk was claimed by the Soviet Union as territorial waters, and was strictly off limits to foreign vessels, and the Soviet Navy had installed a network of sound detection devices along the seabed to detect intruders. The area also saw numerous surface and subsurface naval exercises.\n\nDespite these obstacles, the potential for an intelligence coup was considered too great to ignore, and in October 1971 the United States sent the purpose-modified submarine deep into the Sea of Okhotsk. Funds for the project were diverted secretly from the deep-submergence rescue vehicle (DSRV) program and the modified submarines were shown with fake DSRV simulators attached to them. These were early diver lock outs. Divers working from the \"Halibut\" found the cable in of water and installed a long device, which wrapped around the cable without piercing its casing and recorded all communications made over it. The large recording device was designed to detach if the cable was raised for repair.\n\nThe tapping of the Soviet naval cable was so secret that most sailors involved did not have the security clearance needed to know about it. A cover story was thus created to disguise the actual mission: It was claimed that the spy submarines were sent to the Soviet naval range in the Sea of Okhotsk to recover the Soviet SS-N-12 \"Sandbox\" supersonic anti-ship missile (AShM) debris so that countermeasures could be developed.\n\nAlthough created as a cover story, this mission was actually carried out with great success: U.S. Navy divers recovered all of the SS-N-12 debris, with the largest debris no larger than 6 inches, and a total of more than 2 million pieces. The debris was taken back to the U.S. and the U.S. Naval Research Laboratory reconstructed the AShM based on these pieces, and at least one sample was also reverse engineered. They discovered that the SS-N-12 AShM was guided by radar only, and the infrared (IR) guidance previously suspected did not exist. From the samples built, countermeasures were successfully developed and deployed.\n\nEach month, divers retrieved the recordings and installed a new set of tapes. The recordings were then delivered to the NSA for processing and dissemination to other U.S. intelligence agencies. The first tapes recorded revealed that the Soviets were so sure of the cable's security that the majority of the conversations made over it were unencrypted. The eavesdropping on the traffic between senior Soviet officers provided invaluable information on naval operations at Petropavlovsk, the Pacific Fleet's primary nuclear submarine base, home to Yankee and Delta class nuclear-powered ballistic missile submarines.\n\nEventually, more taps were installed on Soviet lines in other parts of the world, with more advanced instruments built by AT&T's Bell Laboratories that were nuclear-powered and could store a year's worth of data. Other submarines were used for this role, including , , and . The \"Seawolf\" was almost lost during one of these missions—it was stranded on the bottom after a storm and almost had to use its self-destruct charges to scuttle the ship with her crew.\n\nRonald Pelton, a 44-year-old veteran of the NSA, was fluent in Russian and considered to be a highly skilled communications analyst/specialist, but very bad at personal finance. Hostile toward the agency and dissatisfied with his position, Pelton was $65,000 in debt and filed for personal bankruptcy just three months before he resigned. With only a few hundred dollars in the bank, Pelton walked into the Soviet embassy in Washington, D.C. in January 1980 and offered to sell what he knew to the KGB for money.\n\nNo documents were passed from Pelton to the Soviets, as he had an extremely good memory. He reportedly received $35,000 from the KGB for the intelligence he provided from 1980 to 1983, and for the intelligence on the Operation Ivy Bells, the KGB gave him $5,000. The Soviets did not immediately take any action on this information. However, in 1981, surveillance satellites showed Soviet warships, including a salvage vessel, anchored over the site of the tap in the Sea of Okhotsk. USS \"Parche\" was dispatched to recover the device, but her divers were unable to find it and it was concluded that the Soviets had taken it. It remains unclear why it took the Soviets so long, although a plausible explanation is that it was used to feed disinformation to U.S. defense intelligence.\n\nIn July 1985, Vitaly Yurchenko, a KGB colonel who was Pelton's initial contact in Washington, D.C., defected to the United States and provided the information that eventually led to Pelton's arrest.\n\n, the recording device captured by the Soviets was on public display at the Great Patriotic War museum in Moscow.\n\n\n\n"}
{"id": "36080727", "url": "https://en.wikipedia.org/wiki?curid=36080727", "title": "Phase-out of lightweight plastic bags", "text": "Phase-out of lightweight plastic bags\n\nIn many countries of the world, there has been a phase-out of lightweight plastic bags. Single-use plastic shopping bags, commonly made from low-density polyethylene (LDPE) plastic, have traditionally been given free to customers by stores when purchasing goods—a popular method considered a strong, cheap, and hygienic way of transporting items. Problems associated with plastic bags include use of non-renewable resources (such as crude oil, gas and coal), disposal, and environmental impacts.\n\nGovernments all over the world have taken action to ban the sale of lightweight bags, charge customers for lightweight bags and/or generate taxes from the stores who sell them. The Bangladesh government was the first to do so in 2002, imposing a total ban on the bag. Such a ban has also been applied in countries or regions such as Rwanda, China, Taiwan, Macedonia and Kenya. Some countries in Europe impose a fee per bag. Bans, partial bans, and fees have been enacted by some local jurisdictions in North America, Australia, and Myanmar. Concurrently with the reduction in lightweight plastic bags, shops have introduced reusable shopping bags.\n\nPlastic bags cause many minor and major ecological and environmental issues. The most general issue with plastic bags is the amount of waste produced. Many plastic bags end up on streets and subsequently pollute major water sources, rivers, and streams.\n\nEven when disposed of properly, they take many years to decompose and break down, generating large amounts of garbage over long periods of time. If not disposed of properly the bags can pollute waterways, clog sewers and have been found in oceans affecting the habitat of animals and marine creatures.\n\nTwo primary kinds of direct damage to wildlife are entanglement and ingestion. Wildlife animals or birds can become entangled. When the animals or birds are entangled they drown or cannot fly due to entanglement. Plastic bags are often ingested by animals because they cannot distinguish whether it is food or not. As a result, it clogs their intestines which results in death by starvation. Plastic bags can block drains, trap birds and kill livestock. The World Wide Fund for Nature has estimated that over 100,000 whales, seals, and turtles die every year as a result of eating or being trapped by plastic bags. In India, an estimated number of 20 cows die per day as a result of ingesting plastic bags and having their digestive systems clogged by the bags. It is also very common across Africa to have sewers and drain systems clogged by bags which cause severe cases of malaria due to the increased population of mosquitoes that live on the flooded sewers. The term \"white pollution\" has been coined in China to describe the local and global effects of discarded plastic bags upon the environment.\n\nLightweight plastic bags are also blown into trees and other plants and can be mistaken for flowers by animals affecting their diet. Plastic bags break down, but they never biodegrade. As a result, any toxic additives they contain—including flame retardants, antimicrobials, and plasticizers—will be released into the environment. Many of those toxins directly affect the endocrine systems of organisms, which control almost every cell in the body.\nResearch shows the average operating \"lifespan\" of a plastic bag to be approximately 20 minutes. Plastic bags can last in landfill – an anaerobic environment – for up to 1000 years.\n\nThe plastic bags that get dumped in the Pacific Ocean would all eventually end up in the Great Pacific garbage patch. 80% of the plastic waste comes from land while the rest of the 20% comes from oil platforms and ships. This large amount of plastic waste in the Pacific Ocean could be eaten up by marine animals, and this will end up blocking up their breathing passages and digestive systems. Plastic bags not only stay in the Great Pacific garbage patch, they can be washed back up to shore in beaches around the world.\n\nBenin reportedly banned plastic bags in November 2017.\n\nBotswana introduced a levy on plastic bags that became effective in 2007. This led to many retailers charging a fee on plastic bags and consequently a reduction in plastic bag use.\n\nBurkina Faso banned non-biodegradable plastic bags in 2015.\n\nCameroon outlawed disposable plastic in April 2014. There are problems considering black market activities.\n\nThere is a plastic bag ban in N'Djamena.\n\nThe Republic of the Congo banned plastic bags in 2011.\n\nEritrea banned plastic bags in 2005.\n\nEthiopia has banned the production of certain types of plastic bags.\n\nGabon has had a plastic bag ban since 2010.\n\nGambia banned plastic bags in 2015.\n\nGuinea-Bissau banned plastic bags in 2016, but the legislation has been poorly enforced.\n\nIvory Coast banned plastic bags in 2014, but it was controversial with water sellers.\n\nKenya tried to ban manufacture and import of plastic bags in the year 2007 and 2011 as a way to protect the environment. The 2007 and 2011 ban intended for plastics below 30 microns failed after manufacturers and retail outlets threatened to pass on the cost of using other materials to consumers. In 2017 the cabinet secretary of Environment and Natural resources, Prof Judy Wakhungu banned use, manufacture and importation of all plastic bags used for commercial and household packaging under Gazette notice number 2356. On 28 August 2017, Kenya began implementing a countrywide ban of single-use plastic bags. Primary packaging bags, hospital waste bags, and garbage bin liners having been exempted from the ban. The ban has been hailed to be amongst the most stringent in the world. This includes a decision to imprison anyone involved in the creation or import of plastic bags for upwards of four years or will be forced to pay a fine between $19,000 and $38,000. Kenya joins more than 40 other countries to ban plastic bags.The government has promised to ban disposable plastic items in the near future.\n\nMadagascar introduced a plastic bag ban in 2015.\n\nMalawi introduced a plastic bag ban in 2015.\n\nMali has banned plastic bags.\n\nMauritania banned the use, manufacture and import of plastic bags from January 2013 as a way to protect the environment, livestock, and marine species.\n\nMorocco passed a law in October 2015 banning the use of plastic bags nationwide. The law officially came into effect on 1 July 2016. Before the ban, Morocco was the 2nd largest consumer of plastic bags in Africa and the second in the world per capita after the United States.\n\nMozambique has had a plastic bag charge since 5 February 2016.\n\nNiger has a plastic bag ban in force.\n\nRwanda prohibited shops from giving away plastic bags to their customers in 2004. In 2008, Rwanda completely banned plastic bags as part of its Vision 2020 plan for sustainability, though there is a lucrative black market for the now banned product. The Rwandan government gave tax breaks for companies to recycle instead of manufacture plastic bags, and created a new market for environmentally friendly bags. The lack of plastic bags has made Rwandan cities such as Kigali cleaner.\n\nSenegal has banned plastic bags in April 2015.\n\nPlastic bags were banned in the self-declared Republic of Somaliland on 1 March 2005 after a 120-day grace period that the government had given to the public to get rid of their stocks. The Ministry of Trade and Industries announced the cabinet decision in a decree titled: \"Banning importation, production and use of plastic bags in the country\". The bags had been nicknamed \"the Hargeysa flower\", as many of them ended up being blown around and getting stuck in trees and shrubs, posing a danger to livestock because the animals that feed on the leaves often ingest the bags accidentally. In 2015 the ban was repeated by Presidential Decree No. #JSL/M/XERM/249-3178/042015, again providing for a 120 days grace period to get rid of stocks. To ensure the implementation of the ban, the government constituted enforcement teams in 2016 to conduct special drives which launch probes into business stalls. At least 1000 men and women in uniform deployed into the main markets and shopping malls. The government announced fines against violators who continue selling plastic bags in the country.\n\nPlastic bags were a major concern in South Africa before the bag levy was introduced in 2004. The bags were never banned, but a levy was introduced, payable by the plastic bag manufacturer. The thicker plastic bags are levied and although this move initially caused outrage with consumers and an initial decline in volumes, consumers use has continually increased to several billion plastic shopping bags every year. http://www.econrsa.org/papers/p_papers/pp18.pdf \n\nSouth Sudan has banned lightweight plastic bags.\n\nKhartoum State has banned plastic bags.\n\nThe Revolutionary Government of Zanzibar banned plastic bags in 2005. Tanzania introduced a nationwide ban on plastic bags in 2006.\n\nTogo banned plastic bags in July 2018.\n\nTunisia introduced a ban on plastic bag distribution in supermarkets starting from 1 March 2017. An agreement was signed between the Ministry of Local Affairs and Environment and large supermarket chains in the country to enact the first phase of a process aiming to reduce the consumption of plastic bags. Tunisian activists are planning awareness campaigns to establish greener policies in the country.\n\nUganda introduced legislation in 2007 to ban the sale of lightweight plastic bags under 30 µm thick and tax thicker bags at a punitive rate of 120%. Although the laws came into effect in September of that year, they have not been enforced and have failed to measurably reduce the use of plastic bags. The law is not well enforced.\n\nA strict ban was introduced in Bangladesh in 2002 after floods caused by littered plastic bags submerged two-thirds of the country in water between 1988 and 1998.\nPlastic bags remain a big problem for sewerage system and waterways.\n\nBhutan has banned plastic bags, but the legislation has not been very effective so far.\n\nCambodia passed the legislation to impose a plastic bag tax in October 2017. Supermarkets now are charging customers 400 Riels (10 US cents) per plastic bag should they need one.\n\nA total plastic bag ban on ultra thin plastic bags and a fee on plastic bags was introduced in China on 1 June 2008. This came into effect because of the problems with sewerage and general waste. One 2009 survey suggests that plastic bag use fell between 60 and 80% in Chinese supermarkets, and 40 billion fewer bags were used. However, first hand accounts clearly indicate, the ban has seen limited success, and that the use of plastic bags remains prevalent. Street vendors and smaller stores, which make up a significant portion of retail in China, do not abide by the policy in part due to difficulties of enforcing the ban.\n\nHong Kong forbids retailers from giving plastic bags under a certain thickness and for free. A 50 cent plastic bag levy was implemented on 1 April 2015 across Hong Kong. The use of plastic bags dropped 90% after the introduction of the levy. Signs show that Hong Kong is phasing out the use of plastic bags at a dramatic rate.\n\nIn 2002, India banned the production of plastic bags below 20 µm in thickness to prevent plastic bags from clogging of the municipal drainage systems and to prevent the cows of India ingesting plastic bags as they confuse it for food. However, enforcement remains a problem.\n\nThe Ministry of Environment, Forest and Climate Change has also passed regulation to ban all polythene bags less than 50 microns on 18 March 2016. Due to poor implementation of this regulation, regional authorities(states and municipal corporations), have had to implement their own regulation.\n\nIn 2016, Sikkim, India's first fully organic state, banned the use of not only packaged drinking water bottles in any government meetings or functions but also food containers made from polystyrene foam all over the state.\n\nHimachal Pradesh was the first state to ban plastic bags less than 30 µm. The Karnataka state became first state to ban all forms of plastic carry bags, plastic banners, plastic buntings, flex, plastic flags, plastic plates, plastic cups, plastic spoons, cling films and plastic sheets for spreading on dining tables irrespective of thickness including the above items made of thermacol and plastic which uses plastic micro beads.\nThe state of Goa has banned bags up to 40 µm thick, while the city of Mumbai bans bags below a minimum thickness to 50 µm.\n\nThe state Government of Maharashtra banned plastic starting 23 June 2018.\n\nStarting in 2016, Environment Ministry enforced retailers in 23 cities across the archipelago (mini-market, hypermarket, and supermarket) to charge consumers for plastic bags between Rp.200 and Rp.5,000 for each bag including degradable plastic bags. And money which came from tax are used by retailers as public funds for waste management alongside non-governmental organizations.\n\nSince January 2017, large retailers are required to charge consumers for plastic bags with handles, at NIS 0.10 for each bag. The tax revenues will be used to fund public waste-management programs. The average use of plastic bags in Israel in 2014 was 275 per person per year. Four months after the law came into force, the number of disposable plastic bags distributed by retailers subject to the law had dropped by 80%.\n\nLegislation in Japan varies by region, from outright bans to none at all.\n\nKazakhstan is considering a plastic bag ban.\n\nKyrgyzstan is considering a plastic bag ban.\n\nA tax on plastic bags applies in Penang, while a similar tax in the state of Selangor applies only on Saturdays, since 2011.\n\nIn 2009, plastic bag factories in Rangoon were ordered by local authorities to stop production by the end of November or face heavy punishment, as the Burmese government looked to ban plastic bags. Rangoon was thus following in the footsteps of central Burma's Mandalay and the new capital Naypyidaw, both of which had eliminated plastic bags.\n\nNepal has banned plastic bags, but the legislation is poorly enforced.\n\nA plastic bag ban is being planned by the Omani government.\n\nThere are plastic bag bans in parts of Pakistan, but there is poor enforcement.\n\nThere is a plastic bag ban in Manila, but it is poorly enforced.\n\nSouth Korea banned the distribution of lightweight plastic bags from supermarkets and bakeries in August 2018.\n\nSri Lanka banned plastic bags in 2017 due to a waste crisis.\n\nIn January 2003, Taiwan banned the free distribution of lightweight plastic bags. The ban prevented the owners of department stores, shopping malls, hypermarkets, convenience stores, fast food restaurants and regular restaurants from providing free plastic bags to their customers. Many stores have replaced plastic with recycled paper boxes. In 2006, however, the administration decided to begin allowing free plastic bags to be offered by food service operators. In February 2018, Taiwan announced plans to ban plastic bags in varying degrees, banned for in-store use by 2019, certain stores prohibited from offering bags by 2020, price increases starting 2025, then 2030 blanket ban of single-use plastic bags, as well as single-use utensils and containers.\n\nIn November 2013, the European Commission published a proposal aiming to reduce the consumption of lightweight (thickness below 50 microns) plastic carrier bags. Under the proposal, EU member states can choose the most appropriate measures to discourage the use of plastic bags.\nOn 29 April 2015 the European Parliament passed Directive 2015/720 to reduce plastic bag use by 50% by 2017 and 80% by 2019.\n\nAlbania has banned lightweight plastic bags as of 2018.\n\nAustria has a voluntary agreement in place whereby retailers apply a charge to bags.\n\nBelgium has plastic bag bans in place in Wallonia and Brussels, with bans set to also be introduced to Flanders.\n\nThe government of Bosnia and Herzegovina has reportedly introduced a adopted a decree on fees for retailers offering lightweight plastic bags. It is not known whether the law has entered into force yet.\n\nBulgaria has seen a significant reduction in use since applying a charge to plastic bags.\n\nCroatia is planning on introducing a plastic bag charge in 2019.\n\nCyprus introduced a bag charge on 1 January 2018, though shops were reportedly ignoring the new law. Shops began to be penalised for handing out free bags after 1 July 2018.\n\nThe Czech Republic has a plastic bag levy in place.\n\nIn 2003, Denmark introduced a tax on retailers giving out plastic bags. This encouraged stores to charge for plastic bags and pushed the use of reusable bags. It was thought that this saved about 66% of plastic and paper bags. In 2004, a similar law was passed by the \"Inatsisartut \"in Greenland, which applied a recycling tax on plastic bags. By 2014 Denmark had the lowest plastic bag use in Europe, with 4 bags per person per year, compared to 466 in Portugal, Poland and Slovakia.\n\nEstonia introduced a bag tax in July 2017.\n\nFinland applies a tax to plastic bags through a voluntary agreement.\n\nFollowing a National Assembly vote on 11 October 2014, France banned plastic carrier bags under 50 microns starting 1 July 2016. Produce bags are banned starting 1 January 2017. Re-usable or compostable bags are allowed.\n\nGeorgia has reportedly banned plastic bags, as of 2017.\n\nGermany imposes a fee on excess packaging through its Green Dot program, which included plastic bags. In addition, all stores in Germany that provide plastic bags must pay a recycling tax.\n\nAn agreement was signed between trade representatives and the Federal Ministry for the Environment, Nature Conservation, Building and Nuclear Safety in April 2016 to reduce plastic bags, excepting thin bags for fruit and vegetables, bags for deep-freeze products and long-term usable bags, resulting in many shops no longer offer such plastic bags free of cost since July 2016. Should the goal not be achieved, it is foreseen that a law may be passed banning shops from handing them out. The political background to this is a recent change to the European directive 94/62/EG that obliges the member states to reduce the yearly number of plastic bags per capita down to maximally 90 by end-2019 and to maximally 40 by end-2025, whereas Germany had been using 70 bags per capita so far.\n\nA plastic bag charge was introduced on 1 January 2018. Bags cost 4 cents each, which will then increase to 7 cents on 1 January 2019.\n\nHungary has a voluntary agreement with retailers whereby they apply a charge to bags.\n\nIreland introduced a €0.15 tax in March 2002. Levied on consumers at the point of sale, this led to 90% of consumers using long-life bags within a year. The tax was increased to €0.22 in 2007. The revenue is put into an Environment Fund.\n\nIn January 2011, Italy banned the distribution of lightweight plastic bags that are not from biodegradable sources.\n\nLatvia will introduce a bag charge on 1 January 2019.\n\nLithuania will introduce a bag charge on 31 December 2018.\n\nLuxembourg applies a tax to plastic bags.\n\nMalta has had an eco-tax on plastic bags since 2009, but it is poorly enforced.\n\nThe Moldovan parliament has passed legislation banning plastic bags. It came into force for larger retailers in 2017, came into force for medium-sized retailers on 1 January 2018 and is scheduled for small retailers in 2020.\n\nThe Netherlands implemented a comprehensive ban on free plastic shopping bags on 1 January 2016. The ban has a small number of exemptions for unpacked food products which are exposed to possible contamination, such as fresh fruit. The target price for a plastic bag is €0.25.\n\nNorway has a voluntary agreement with retailers whereby they apply a charge to bags.\n\nA plastic recycling levy was introduced on 1 January 2018. Single-use plastic bags cost a minimum of (inclusive of VAT), however stores are able to charge a higher amount. The Polish government estimated that the levy would bring 1.1 billion złoty to the state budget in 2018, in addition to approx. 250 million złoty of VAT revenue raised on sales of the bags.\n\nPortugal has implemented a plastic bag tax amounting to 10 cents (€) on single-use carrier bags, which led to a reduction of 90% in their use. However, many retailers started selling thicker (reusable) plastic bags, which are not subject to the tax, for the same amount. Before the Portuguese government implemented this plastic bag tax, some supermarkets in Portugal had already implemented a 2 cent (€) fee on each plastic bag. In Madeira Island where supermarkets implemented this bag fee, there was a 64% reduction in plastic bag consumption.\n\nA law was introduced in 2006 (law 578/2006) - and was later modified in 2011 (law 1032/2011) – that puts a mandatory tax on non-biodegradable plastic bags. The modification in 2011 reduced the tax on plastic bags and was regarded by some as a step backwards from environmental protection.\n\nSerbia has a tax on manufacturers and importers of plastic bags and plans to introduce a ban on lightweight plastic bags and a charge on biodegradable bags in order to reduce bag use to under 90 per person by 2019. Major supermarkets began charging 2 dinars per bag in 2018.\n\nSlovakia has an obligatory charge for certain types of plastic bags. The charge was introduced on 1 January 2018.\n\nSlovenia plans to ban free lightweight plastic bags from 1 January 2019.\n\nSpain introduced a plastic bag charge on 1 July 2018. Catalonia has had a bag charge since April 2017.\n\nSweden has a plastic bag levy in place.\n\nIn 2016, the two largest chains of supermarkets in Switzerland, the Federation of Migros Cooperatives and Coop, announced that they will progressively stop to distribute free plastic bags (at the check-out). Both distributors announced that they will not make money with paid bags, but that profits from their sale will be invested in environmental projects.\n\nMigros previously tested the measure in the Canton of Vaud since 2013: they reduced the number of plastic bags distributed by ninety percent (and saved 100,000 francs per year). Migros will be the first to introduce the measure across the country, on 1 November 2016 (the bags will be made with recycled plastic and cost 0.05 Swiss francs each). Coop plans to introduce this in 2017.\n\nPlastic bags are banned is some parts of Turkey and a levy was scheduled to be introduced nationally in January 2018.\n\nThe Climate Change Act 2008 served as the legislative framework for the regulation of plastic bags in the United Kingdom.\n\nWales introduced a legal minimum charge of 5 pence for almost all single use bags in October 2011. Paper and biodegradable bags are included in the charge as well as plastic bags, with only a few specific exemptions – such as for unpackaged food or medicine supplied on an NHS prescription.\nVAT raised from the charge is collected by the government. Retailers are asked to pass the rest of the proceeds on to charities. July 2012 statistics released by the Welsh Government suggested that carrier bag use in Wales had reduced 96% since the introduction of the charge.\n\nNorthern Ireland introduced a 5 pence levy on almost all single use bags on 8 April 2013. The levy will be extended to reusable carrier bags with a retail price of less than 20 pence from 19 January 2014 as data from a number of retailers indicate that reusable bag sales have increased by 800% since the introduction of the levy on single use bags.\nThe proceeds of the levy (£4.17m in 2013/14) are paid to the Department of the Environment\nand used to fund local environmental projects and enforce the levy.\nOfficial statistics for the Northern Ireland levy show that the number of single use bags dispensed fell from around 300 million in 2012/13 to 84.5 million in 2013/14 – a reduction of 72%.\n\nA five pence minimum charge for single-use carrier bags came into force in Scotland on 20 October 2014.\nThe proceeds of the charge can be used by the retailers as they see fit, although retailers are encouraged to pledge to donate proceeds to \"good causes\". The charge is not exclusive to plastic bags, and includes biodegradable bags, such as paper. Bags for unpackaged food, loose seeds, soil-contaminated goods, axes, knives or blades; drugs or medical appliances; small packaged uncooked fish, meat or poultry; aquatic animals; purchases made in aerodrome security restricted areas; or goods bought on board a ship, train, aircraft, coach or bus are exempt from the charge.\n\nEngland was the last country in the United Kingdom to adopt the 5 pence charge, with the levy taking effect on 5 October 2015. Prior to the introduction of plastic bag regulations, various retailers participated in voluntary actions to reduce plastic bag consumption.\n\nUnlike the rest of the UK, the English charge does not apply to paper bags or bags made from other natural materials. As with the other nations, VAT raised on sales will be collected by the Government. Retailers can choose how the money raised from bag sales is used. The Government publishes information yearly on the scheme, encouraging retailers to donate the proceeds to charities.\n\nIn the first 6 months, 640 million plastic bags were used in seven major supermarkets in England, raising £29.2 million for good causes. England reported to have distributed 0.6 billion single-use bags during the first half year of the charge, 7 billion fewer than were distributed in 2014.\n\nTo promote the growth of new businesses in England, retailers with fewer than 250 employees are exempt from the charge. Opponents to the exemption of small retailers argued that this exemption would diminish the environmental impact of the charge. In response to this criticism, in the UK government has announced plans to extend the charge to all retailers and double the charge to 10p.\n\nThe Falkland Islands has a voluntary agreement in place where retailers charge for bags and donate the proceeds to charity.\n\nThere is a plastic bag ban in place in Antigua and Barbuda.\n\nThe Bahamas government has announced a plan to ban plastic bags by 2020.\n\nBelize has pledged to ban plastic bags by 22 April 2019 (Earth Day).\n\nIn March 2007, the small town of Leaf Rapids, Manitoba, became the first community in North America to ban bags.\n\nThe Toronto City Council voted on 6 June 2012, to ban plastic bags effective 1 January 2013, and to scrap the city's five-cent bag fee starting 1 July 2012. Industry groups have convinced city officials to include a grace period between 1 January 2013, and 30 June 2013, when no fines, only warnings, can be issued. The bag ban and five cent fee (six cents with HST) have both been overturned as of 28 November 2012 and it's up to individual retailers if they want to charge for plastic bags. Most stores, with the exception of a few national retailers do not charge.\n\nA few municipalities in Guatemala have banned plastic bags, including San Pedro La Laguna, Acatenango, Villa Canales, San Miguel Petapa and Totonicapán.\n\nHaiti has banned plastic bags.\n\nThere is a working group examining a state motion to ban plastic bags in Jamaica.\n\nOn 17 September 2018, the Jamaican Cabinet announced a total ban on the importation, manufacture, distribution and use of single-use plastic bags, effective 1 January 2019.\n\nMexico approved legislation to ban and fine plastic bags in August 2010. However, the legislation is not observed. Mexico City banned plastic bags in 2010, but plastic bags remain one of Mexico's biggest pollution problems. The city of Querétaro banned plastic bags in 2017.\n\nPanama's Assembly has passed legislation banning plastic bags. The law was sanctioned by the president in January 2017 and retailers have until January 2020 to phase out their existing stock.\n\nThere is no national plastic bag fee or ban currently in effect in the United States. However, the state of California, and the territories of American Samoa and Puerto Rico have banned disposable bags. Over 200 counties and municipalities have enacted ordinances either imposing a fee on plastic bags or banning them outright, including all counties in Hawaii. Other attempts at banning plastic shopping bags statewide (for example in Massachusetts) have not succeeded mainly due to plastic industry lobbying. A few jurisdictions have chosen to implement a fee-only approach to bag reduction such as Washington, D.C. and adjacent Montgomery County, Maryland. Some US states, such as Florida and Arizona, have passed laws preventing local municipalities from passing their own bans.\nNotes\n\nCalifornians voted in November 2016 to approve state legislation banning plastic bags statewide in Propositions 67 and 65. Over 100 local laws with similar or tougher regulations will remain and supersede the statewide legislation.\nNotes:\n\nAlthough the nation does not ban lightweight bags, the states of South Australia, Tasmania, and the ACT and Northern Territory, along with some cities have independently banned the bag. Coles Bay, Tasmania was the first location in Australia to ban the bag. The introduction of the \"Zero Waste\" program in South Australia led to its lightweight bag ban in October 2008. It is estimated that 400 million bags are saved each year. Western Australia and Queensland banned them on 1 July 2018 and Victoria has announced it will introduce a ban in 2019.\n\nIn Australia, 6 billion HDPE bags were used in 2002. Usage reduced to 5.6 billion in 2004, and 3.9 billion in 2007.\n\nIn 2018, the Labour government pledged to phase out single-use plastic bags within a year's time. New Zealand is one of the highest producers of urban waste in the developed world, per capita, according to OECD data. Prime Minister Jacinda Ardern and Associate Environment Minister Eugenie Sage made the announcement on 10 August 2018.\n\nIn 2015, Papua New Guinea announced a previous ban on non-biodegradable plastic shopping bags would be enforced starting 1 January 2016.\n\nThe Western Province of the Solomon Islands has banned plastic bags.\n\nVanuatu banned plastic bags on 31 January 2018.\n\nIn 2012, the Buenos Aires city government allowed supermarkets to charge for plastic bags in order to discourage their use, which is said to have reduced their use by 50%. In 2016 the city announced a full ban on the distribution of plastic bags in supermarkets and hypermarkets, commencing 1 January 2017.\n\nIn 2009 the Governor of Buenos Aires Province, Daniel Scioli, approved Law 13868, which mandated that by the end of that year, all non-biodegradable plastic bags should be phased out in favour of degradable materials.\n\nOther provinces like Neuquén, Chubut, Río Negro and cities like Rosario, Villa Gesell or Bariloche had already banned the distribution of plastic bags in supermarkets as well.\n\nPlastic bags are banned in La Paz.\n\nSao Paulo banned plastic bags in 2015.\n\nSome 80 municipalities have restricted plastic bag distribution, while some coastal and lakeside areas have banned plastic bags altogether. In late May 2018, House of Representatives voted to ban plastic bags from major retailers nationwide, effective in a year, while smaller retailers will have a two-year window to phase out their use of plastic bags, during which time they'll limit two bags per customer. In August 2018, the legislation was approved by Congress and the President.\n\nColombia plans to reduce the use of plastic bags by 80% by the year 2020, and completely eliminate their use by the year 2025. On 29 April 2016, the Ministry of Environment passed a resolution banning plastic bags under 30 cm by 30 cm.\n\nFrom 1 July 2017, the Colombian Government applies a tax of 20 pesos per plastic bag, with a planned annual increase of 10 pesos per bag until 2020.\n\nEcuador restricts plastic bags around the Galápagos Islands.\n\nGuyana plans to ban plastic bags by 2021.\n\nLegislation banning non-biodegradable bags and applying a charge to biodegradable bags has been passed by the government of Uruguay but is yet to enter into force.\n\nTwo of the most popular methods of phasing out lightweight plastic bags have been outlined above, including both fees and bans. The fee strategy is said to have all of the same results in plastic bag reduction as a plastic bag ban, with the additional benefit of creating a new revenue source. The plastic bag fee method also protects consumer choice, which the ban does not.\n\nRecycling of plastic bags can be another method of phase-out. However, a big issue with recycling is that only 5% of plastic bags make it to recycling facilities to begin with. Even when bags are brought to these recycling bins and facilities, they often fly out of these bins or recycling trucks and end up as litter on the streets. Another issue with recycling is that different bags are made from different yet aesthetically similar types of plastics. Bags can be either made of bioplastics or biodegradable plastics, and if accidentally combined in a compost, the bioplastics could contaminate the biodegradable composting. These bags can also jam recycling equipment when mixed with other types of plastic, which can be costly to repair. Costs of repairs rounded out to be about $1 million per year in San Jose, California.\n\nIndividuals can also engage in advocacy local officials and local merchants. With the rise in eco-tourism and green travel, there are many opportunities to say no to plastic .\n\n"}
{"id": "49278562", "url": "https://en.wikipedia.org/wiki?curid=49278562", "title": "Professional audio store", "text": "Professional audio store\n\nA professional audio store is a retail business that sells, and in many cases rents, sound reinforcement system equipment and PA system components used in music concerts, live shows, dance parties and speaking events. This equipment typically includes microphones, power amplifiers, electronic effects units (e.g., reverb and compression effects), speaker enclosures, monitor speakers, subwoofers and audio consoles (mixers). Some professional audio stores also sell sound recording equipment, DJ equipment, lighting equipment used in nightclubs and concerts and video equipment used in events, such as video projectors and screens. Some professional audio stores rent \"backline\" equipment used in rock and pop shows, such as stage pianos and bass amplifiers. While professional audio stores typically focus on selling new merchandise, some stores also sell used equipment, which is often the equipment that the company has previously rented out for shows and events.\nProfessional audio stores are also called \"pro audio stores\", \"pro sound stores\", \"sound reinforcement\" companies, \"PA system companies\" or \"audio-visual companies\", with the latter name being used when a store supplies a significant amount of video equipment for events, such as video projectors and screens. Stores often use the word \"professional\" in their name or the description of their store, to differentiate their stores from consumer electronics stores, which sell consumer-grade loudspeakers, home cinema equipment, and amplifiers, which are designed for private, in-home use.\n\nPro audio stores carry a range of microphones used in live sound and recording, including specialized mics such as drum mics. Stores typically carry wireless systems which enable microphones and electric instruments to be played without cables. Recording gear includes audio interfaces, studio monitors, audio recorders, studio subwoofers, analog-digital and digital-analog converters, studio power amplifiers and duplication equipment. Live sound equipment includes sound reinforcement system loudspeaker enclosures, loudspeakers, monitor speakers, power amplifiers and subwoofers. Headphone equipment includes studio and DJ headphones, headphone amplifiers and headphone mixers. Audio consoles include live sound mixers, powered mixers (which have a built-in power amplifier), unpowered mixers and digital mixers. Signal processing gear includes DI boxes, crossovers and a range a\nof electronic effects, which are typically rackmountable units, including: microphone preamplifiers, electronic vocal processors, exciters, equalizers, compressors and limiters, feedback suppressors and noise gates. Some stores also sell audio software, such as DAW software, signal processing software and virtual instruments.\n\nWhile some pro audio stores only sell audio equipment, others also sell products in other categories that are used in rock concerts and DJ events, such as portable stages, stage lights, par cans and light stands. Some stores sell coloured lights, lasers and strobe lights which flash, change colours and/or move according to the beat of the music; these lights are used in nightclubs and rave dance events. Some stores also sell fog machines, which are used in dances, concerts and theatre productions, often to enhance the appearance of the lighting and laser effects. Some pro audio stores sell a range of DJ equipment, such as direct drive turntables, record cartridges and styli, DJ CD players and DJ mixers.\n\nSome professional audio stores sell the services of audio engineers, audio technicians and delivery personnel who can deliver and set up professional sound equipment and/or oversee the audio mixing of the different instruments and voices during a show or event. Some professional audio stores offer paid consulting services on professional audio issues. These consultants can come to a customer's venue, which may be a nightclub, church, conference center, auditorium or stadium, assess its professional audio needs, and recommend the types of components–speaker enclosures, mixing boards, microphone types, and so on–that would best suit this venue and the customer's budget.\n\n"}
{"id": "11950871", "url": "https://en.wikipedia.org/wiki?curid=11950871", "title": "Progressive scan DVD player", "text": "Progressive scan DVD player\n\nA progressive scan DVD player is a DVD player that can produce video in a progressive scan format such as 480p (NTSC) or 576p (PAL). Players which can output resolutions higher than 480p or 576p are often called upconverting DVD players.\n\nBefore HDTVs became common, players were sold which could produce 480p or 576p. TVs with this feature were often in the upper price range of a manufacturer's line. To utilize this feature, a TV or other display with a progressive scan input was needed. HDTVs usually have a progressive scan input; progressive scan inputs are less common on standard definition TVs (often called SDTVs.)\n\nSome players have a feature called \" detection\" or \"inverse telecine\" which attempts to better handle the artifacts which result from differing film and video rates in conjunction with interlaced scanning of the film. However most line doublers used in these players are not able to achieve the anticipated inverse telecine functionality, refer to line doubler for details.\n\nProgressive scan output can not use connections intended for interlaced video, such as composite video (single RCA terminated cable) and S-Video (Mini-DIN terminated cable). The following connection methods are common for using progressive scan:\n"}
{"id": "810476", "url": "https://en.wikipedia.org/wiki?curid=810476", "title": "Racal", "text": "Racal\n\nRacal Electronics plc was a British electronics company, founded in 1950.\n\nListed on the London Stock Exchange and once a constituent of the FTSE 100 Index, Racal was a diversified company, offering products including voice loggers and data recorders, point of sale terminals, laboratory instruments and military electronics, including radio and radar. At its height it was the third largest British electronics firm; it operated throughout 110 countries worldwide and employed over 30,000 people. It was the parent company of Vodafone, before the mobile telephony provider was sold in 1991.\n\nRacal was purchased by Thomson-CSF (now Thales Group) in 2000, thereby giving the French firm access to the lucrative UK defence and armaments market.\n\nRacal was created in 1950 as Racal Ltd, the name being derived from the names of the partners, Raymond Brown and George Calder Cunningham.\n\nErnest Harrison joined the company as employee number 13 as an accountant, but later held the positions of chief buyer, personnel director and contract negotiator.\n\nThe first factory was located in Isleworth, west London. On outgrowing this site it moved to Bracknell, Berkshire in 1954, enticed by a 99-year lease at four shillings and sixpence per square foot – and no rent reviews.\n\nAlthough Racal had won a Royal Navy contract to build and supply a variant of the American Collins Model 51-J Radio Receiver, they were not granted a licence to build these sets by Collins Inc. This meant that Racal had to design and build a radio receiver from scratch. After almost bankrupting the company due to a £40,000 overspend, the result was the 'RA17' – in production from 1955 to at least 1973 – designed in co-operation with Trevor Wadley and using his \"Wadley Loop\" circuit.\n\nHarrison joined the company board in 1958, and as deputy managing director from 1961 helped Racal to obtain a Stock Market listing. Harrison became chairman in 1966, when co-founder Ray Brown was lured away by the Ministry of Defence.\n\n\nUnder Harrsion, £1,000 invested in Racal in 1961 would have been worth £14.5million when he retired in 2000. Harrison received an estimated £25 million from the sale of Racal in 2000, and is estimated to have died with an accumulated total wealth of £40million.\n\nIn 1979, Racal bought Decca Radar forming Racal-Decca. Racal-Datacom conducted business in the United States.\n\nIn 1980, Harrison agreed a deal with Lord Weinstock of General Electric Company plc to allow Racal to access some of GEC's tactical battlefield radio technology. Briefing the head of Racal's military radio division Gerry Whent to drive the company into commercial mobile radio, Whent visited GE's factory in Virginia, USA in 1980.\n\nIn 1982, Racal's newly formed subsidiary Racal Strategic Radio Ltd under CEO Whent, won one of two UK cellular telephone network licences; the other going to British Telecom The network, known as Racal Vodafone was 80% owned by Racal, with Millicom with 15%, and the Hambros Technology Trust 5% respectively. Vodafone was launched on 1 January 1985. Racal Strategic Radio was renamed Racal Telecommunications Group Limited in 1985. On 29 December 1986, Racal Electronics bought out the minority shareholders of Vodafone for GB£110 million.\n\nIn 1988, 20% of Racal Telecom was floated on the London Stock Exchange. This would lead to the situation where Racal Electronics was valued at less than its shareholding in Racal Telecom. Harrison demerged Racal Telecom in October 1991, forcing a positive valuation on the rest of Racal (colloquially known in the City of London as \"the rump\"). Vodafone would later become the largest mobile network in the world and the highest valued company on the FTSE 100. Immediately following the demerger, Williams Holdings launched a takeover bid for Racal. The bid, valued at £740m, failed.\n\nThe company marketed modems under the name Racal-Vadic, and was among the first to offer 2400 baud modems in the early 1980s.\n\nAnother name it used was Racal-Milgo.\n\nIn 1984, Racal bought Chubb, a security company that manufactured safes and locks. In 1992, Chubb was demerged from Racal and was subsequently taken over by Willams Holdings in 1997 for £1.3bn.\n\nRacal re-established a telecoms division with a major government contract in 1988 and the acquisition of British Rail Telecommunications in 1995. This division of the former nationalised industry owned telecoms infrastructure laid across the rail network.\n\nConsisted of Racal Recorders (Hythe, Southampton) and Racal Instruments (Burham, near Slough). Racal acquired Thermionic Products in 1967, creating Racal Thermionics, renamed Racal Recorders in 1977.\n\nIn 1994, Camelot Group won the franchise to operate the UK National Lottery, Racal had a 22.5% share. After one of the founder shareholders, GTECH, was bought out by Camelot this stake increased to 26.67% which Thales continues to hold.\n\nIn 1995, Racal expanded its defence businesses with the acquisition of the Thorn Sensors Group from Thorn EMI. In 1998, all of Racal defence businesses were reorganised under Racal Defence Electronics Ltd into Racal Radar Defence Systems, Racal Radio and Racal Thorn.\n\nIn October 1999, Racal decided to sell its telecoms business to the American communications group, Global Crossing, for £1bn.\n\nThen in January 2000 Thomson-CSF announced a bid for the Company: Racal became Thomson-CSF Racal plc and later part of Thales plc with the renaming of the larger Thomson-CSF to Thales Group.\n\nIn December 2008, Racal Acoustics Ltd was acquired by Esterline Technologies, and has become part of their Communications Systems platform.\n\n"}
{"id": "41942577", "url": "https://en.wikipedia.org/wiki?curid=41942577", "title": "Reflectometry", "text": "Reflectometry\n\nReflectometry uses the reflection of waves at surfaces and interfaces to detect or characterize objects.\n\nThere are many different forms of reflectometry. They can be classified in several ways: by the used radiation (electromagnetic, ultrasound, particle beams), by the geometry of wave propagation (unguided versus wave guides or cables), by the involved length scales (wavelength and penetration depth versus size of the investigated object), by the method of measurement (continuous versus pulsed, polarization resolved, ...), and by the application domain.\n\nElectromagnetic radiation of widely varying wavelength is used in many different forms of reflectometry:\nPropagation of electric pulses in cables is used to detect and localize defects in electric wiring.\n\nUltrasonic reflectometry: A transducer generates ultrasonic waves which propagates until it reaches the interface between the propagation medium and the sample. The wave is partially reflected at the interface and partially transmitted into the sample. The waves reflected at the interface travel back to the transducer, then the impedance of a sample is determined by measuring the amplitude of the wave reflected from the propagation medium/sample interface. From the reflected wave, it is possible to determine some properties of the sample that is desired to characterize. Applications include medical ultrasonography and nondestructive testing.\n\nNeutron reflectometry: is a neutron diffraction technique for measuring the structure of thin films, similar to the often complementary techniques of X-ray reflectivity and ellipsometry. The technique provides valuable information over a wide variety of scientific and technological applications including chemical aggregation, polymer and surfactant adsorption, structure of thin film magnetic systems, biological membranes.\n\nIn anthropology, reflectometry devices are often used to gauge human skin color through the measurement of skin reflectance. These devices are typically pointed at the upper arm or forehead, with the emitted waves then interpreted at various percentages. Lower frequencies represent lower skin reflectance and thus darker pigmentation, whereas higher frequencies represent greater skin reflectance and therefore lighter pigmentation.\n\nBelow are global estimates of observed or predicted skin reflectance frequencies in various countries, populations and areas:\n\nMany techniques are based on the principle of reflectometry and are distinguished by the type of waves used and the analysis of the reflected signal. Among all these techniques, we can classify the main but not limited to:\n"}
{"id": "1869214", "url": "https://en.wikipedia.org/wiki?curid=1869214", "title": "SEMI", "text": "SEMI\n\nSEMI (formerly Semiconductor Equipment and Materials International) is a global industry association of companies that provide equipment, materials and services for the manufacture of semiconductors, photovoltaic panels, LED and flat panel displays, micro-electromechanical systems (MEMS), printed and flexible electronics, and related micro and nano-technologies. \n\nSEMI is headquartered in Milpitas, California, and has offices in Bangalore; Berlin; Grenoble, France; Hsinchu, Taiwan; Seoul; Shanghai; Singapore; Tokyo; and Washington, D.C. Its main activities include conferences and trade shows, development of industry standards, market research reporting, and industry advocacy. The president and chief executive officer of the organization is Ajit Manocha.\n\nSEMI was founded in 1970 as an association of semiconductor production equipment vendors. At that time, most companies in the semiconductor industry exhibited at the Wescon Show on the west coast and the IEEE show on the east coast. Wishing to organize a show dedicated to semiconductor production equipment, 55 companies met in Palo Alto and agreed to found a new association, originally called Semiconductor Equipment and Materials Institute.\n\nThe first SEMICON show was held in 1971 at the San Mateo Fairgrounds in California, which featured “semiconductor processing equipment, materials, and service firms.” It featured 80 exhibitors and attracted 2,800 visitors. In 1973, the first SEMICON East show was held in New York City, with 120 exhibitors participating. This was followed by SEMICON Europa in Zurich, Switzerland (1975) and SEMICON Japan in Tokyo (1977), which attracted more than 200 exhibitors and 4,500 visitors. Through this and other activities, the organization grew from a domestic organization to one with an international focus. Part of this focus was to work with governments to reduce trade barriers and develop “a sympathetic regulatory climate” for its member organizations—companies that sold equipment and materials to firms that produce microprocessors. \n\nToday SEMI organizes and produces nearly 100 technology showcases, trade shows, conferences and special events per year in all of the major manufacturing regions of the world. They include trade shows in China, Japan, Germany, Singapore, South Korea, Taiwan, North America, and Europe, as well as executive conferences, technical programs, and standards meetings. The organization also has technical education programs, and a weekly email newsletter. Presentations delivered at its symposia are available to members of the organization on the Members Only section of the website.\n\nThe SEMI Standards program was established in 1973 using proceeds from the west coast SEMICON show. Its first initiative, following meetings with silicon suppliers, was a successful effort to set common wafer diameters to be used in silicon manufacturing. This standardization helped the industry avoid a wafer shortage from 1973 to 1974, that had previously been anticipated. The standards would become internationally utilized over the years, through partnerships with the ASTM, the DIN, and other national standards organizations. Before these standards, there were more than two thousand different specifications for silicon and by 1975 80% of all silicon wafers met with the SEMI standard. It was first published annually as the Book of SEMI Standards. With three new standards published annually in the mid-2000s, the book was eventually replaced with a CD-ROM, and now standards are available online on an annual subscription basis.\n\nToday, over 800 SEMI standards and safety guidelines are available to address all aspects of automated fabs. The standards are developed and maintained by over 3,600 volunteer experts representing more than 700 companies, working in 23 technical committees and 200 task forces. High-profile standards include wafer dimensions and materials, factory efficiency and reliability, equipment interfaces, and environmental, health and safety standards.\n\nThe four main equipment communication standards are the SECS-I (which stands for SEMI Equipment Communication Standards) established in 1978 that deals with communication protocol and physical definitions, the SECS-II established in 1982 that deals with message format, the GEM established in 1992 that refines the SECS-II, and the HSMS that supersedes SECS-I established in 1994. The organization also provides safety and ergonomics guidelines, the first of which was the SEMI S2 developed in 1993, followed by the SEMI S8 in 1995.\n\nSEMI provides market research reports for the semiconductor equipment, materials, and LED industries. Its billing data is considered an important leading indicator of demand trends and is closely watched within the industry and by semiconductor market analysts and investor. It also releases the World Fab Forecast.\n\nThe semiconductor equipment billings report provides a three-month rolling average of the book-to-bill ratio for semiconductor equipment manufacturers with headquarters in North America. It is released approximately three weeks after the close of each month.\nData for the reports is collected directly from suppliers through a confidential data collection program via an independent financial services company. \n\nThere are data collection programs in the following areas.\n\nIn-depth reports are broken down by region, supply chain segment, and equipment type.\n\nIn 2018, Fab Owners Association joined SEMI as a SEMI Strategic Association partner. \n\nIn 2017, MSIG (MEMS & Sensors Industry Group) joined SEMI as a SEMI Strategic Association partner bringing MEMS and Sensors community to SEMI’s global platforms. \n\nIn 2016, FlexTech joined SEMI as a SEMI Strategic Association partner. \n\n\n"}
{"id": "291076", "url": "https://en.wikipedia.org/wiki?curid=291076", "title": "Self-clocking signal", "text": "Self-clocking signal\n\nIn telecommunications and electronics, a self-clocking signal is one that can be decoded without the need for a separate clock signal or other source of synchronization. This is usually done by including embedded synchronization information within the signal, and adding constraints on the coding of the data payload such that false synchronization can easily be detected.\n\nMost line codes are designed to be self-clocking.\n\nIf a clock signal is embedded in the data transmission, there are two possibilities: the clock signals are sent at the same time as the data (isochronous), or at a different time (anisochronous).\n\nIf the embedded clock signal is isochronous, it gets sent simultaneously with the data. Below is an example signal, in this case using the Manchester code self-clocking signal. The data and clock cycles can be thought of as \"adding up\" to a combination, where both the clock cycle and the data can be retrieved from the transmitted signal.\n\nAsynchronous self-clocking signals do not combine clock cycles and data transfer into one continuous signal. Instead, the transmission of clock cycles and data transmission is modulated. Below is an example signal used in asynchronous serial communication, where it is made clear that the information about the clock speed is transmitted in a different timeframe than the actual data.\n\nExample uses of self-clocking signal protocols include:\n\nMost of these codes can be seen as a kind of Run Length Limited code. Those constraints on \"runs\" of zeros and \"runs\" of ones ensure that transitions occur often enough to keep the receiver synchronized.\n\nSuch self-clocking signals can be decoded correctly into a stream of bits without bit slip.\nTo further decode that stream of bits and decide which bit is the first bit of a byte, often a self-synchronizing code is used.\n\nAmplitude modulation – modulating a signal formula_1 by changing the amplitude of a carrier wave, as in:\nis self-clocking, as the zero crossings serve as a clock pulse.\n\nOne may consider this clock pulse redundant information, or at least a wasteful use of channel capacity, and duplex the channel by varying the phase, as in polar modulation, or adding another signal that is 90° out of phase (a sine wave), as in quadrature modulation. The result is to send twice as many signals over the channel, at the cost of losing the clock, and thus suffering signal degradation in case of clock drift (the analog equivalent of bit drift).\n\nThis demonstrates how encoding clocking or synchronization in a code costs channel capacity, and illustrates the trade-off.\n\n"}
{"id": "2238765", "url": "https://en.wikipedia.org/wiki?curid=2238765", "title": "Static induction thyristor", "text": "Static induction thyristor\n\nThe static induction thyristor (SIT, SITh) is a thyristor with a buried gate structure in which the gate electrodes are placed in n-base region. Since they are normally on-state, gate electrodes must be negatively biased to hold off-state.\nit has low noise, low distortion, high audio frequency power capability. The turn-on and turn-off times are very short, typically 0.25 microseconds.\n"}
{"id": "42266481", "url": "https://en.wikipedia.org/wiki?curid=42266481", "title": "Superconducting computing", "text": "Superconducting computing\n\nSuperconducting logic refers to a class of logic circuits or logic gates that use the unique properties of superconductors, including zero-resistance wires, ultrafast Josephson junction switches, and quantization of magnetic flux (fluxoid). Superconducting computing is a form of cryogenic computing, as superconductive electronic circuits require cooling to cryogenic temperatures for operation, typically below 10 kelvin. Often superconducting computing is applied to quantum computing, with an important application known as superconducting quantum computing.\n\nSuperconducting digital logic circuits use single flux quanta (SFQ), also known as magnetic flux quanta, to encode, process, and transport data. SFQ circuits are made up of active Josephson junctions and passive elements such as inductors, resistors, transformers, and transmission lines. Whereas voltages and capacitors are important in semiconductor logic circuits such as CMOS, currents and inductors are most important in SFQ logic circuits. Power can be supplied by either direct current or alternating current, depending on the SFQ logic family.\n\nThe primary advantage of superconducting computing is improved power efficiency over conventional CMOS technology. Much of the power consumed, and heat dissipated, by conventional processors comes from moving information between logic elements rather than the actual logic operations. Because superconductors have zero electrical resistance, little energy is required to move bits within the processor. This is expected to result in power consumption savings of a factor of 500 for an exascale computer. For comparison, in 2014 it was estimated that a 1 exaFLOPS computer built in CMOS logic is estimated to consume some 500 megawatts of electrical power. Superconducting logic can be an attractive option for ultrafast CPUs, where switching times are measured in picoseconds and operating frequencies approach 770 GHz. However, since transferring information between the processor and the outside world does still dissipate energy, superconducting computing was seen as well-suited for communications-intensive tasks where the data largely stays in the cryogenic environment, rather than big data applications where large amounts of information are streamed from outside the processor.\n\nAs superconducting logic supports standard digital machine architectures and algorithms, the existing knowledge base for CMOS computing will still be useful in constructing superconducting computers. However, given the reduced heat dissipation, it may enable innovations such as three-dimensional stacking of components. However, as they require inductors, it is harder to reduce their size. As of 2014, devices using niobium as the superconducting material operating at 4 K were considered state-of-the-art. Important challenges for the field were reliable cryogenic memory, as well as moving from research on individual components to large-scale integration.\n\nJosephson junction count is a measure of superconducting circuit or device complexity, similar to the transistor count used for semiconductor integrated circuits.\n\nSuperconducting computing research has been pursued by the U. S. National Security Agency since the mid-1950s. However, progress could not keep up with the increasing performance of standard CMOS technology. As of 2016 there are no commercial superconducting computers, although research and development continues.\n\nResearch in the mid-1950s to early 1960s focused on the cryotron invented by Dudley Allen Buck, but the liquid-helium temperatures and the slow switching time between superconducting and resistive states caused this research to be abandoned. In 1962 Brian Josephson established the theory behind the Josephson effect, and within a few years IBM had fabricated the first Josephson junction. By the mid 1970s IBM had constructed a superconducting quantum interference device using these junctions, mainly working with lead-based junctions and later switching to lead/niobium junctions. However, the program was shut down in 1983 because the technology was not considered competitive with standard semiconductor technology. The Japanese Ministry of International Trade and Industry funded a superconducting research effort from 1981 to 1989 that produced the ETL-JC1, which was a 4-bit machine with 1,000 bits of RAM.\n\nIn 1983, Bell Labs created niobium/aluminum oxide Josephson junctions that were more reliable and easier to fabricate. In 1985, the Rapid single flux quantum logic scheme, which had improved speed and energy efficiency, was developed by researchers at Moscow State University. These advances led to the United States' Hybrid Technology Multi-Threaded project, started in 1997, which sought to beat conventional semiconductors to the petaflop computing scale. The project was abandoned in 2000, however, and the first conventional petaflop computer was constructed in 2008. After 2000, attention turned to superconducting quantum computing. The 2011 introduction of reciprocal quantum logic by Quentin Herr of Northrop Grumman, as well as energy-efficient rapid single flux quantum by Hypres, were seen as major advances.\n\nThe push for exascale computing beginning in the mid-2010s, as codified in the National Strategic Computing Initiative, was seen as an opening for superconducting computing research as exascale computers based on CMOS technology would be expected to require impractical amounts of electrical power. The Intelligence Advanced Research Projects Activity, formed in 2006, currently coordinates the U. S. Intelligence Community's research and development efforts in superconducting computing.\n\nDespite the names of many of these techniques containing the word \"quantum\", they are not necessarily platforms for quantum computing.\n\nRapid single flux quantum (RSFQ) superconducting logic was developed in the Soviet Union in the 1980s. Information is carried by the presence or absence of a single flux quantum (SFQ). The Josephson junctions are critically damped, typically by addition of an appropriately sized shunt resistor, to make them switch without a hysteresis. Clocking signals are provided to logic gates by separately distributed SFQ voltage pulses.\n\nPower is provided by bias currents distributed using resistors that can consume more than 10 times as much static power than the dynamic power used for computation. The simplicity of using resistors to distribute currents can be an advantage in small circuits and RSFQ continues to be used for many applications where energy efficiency is not of critical importance.\n\nRSFQ has been used to build specialized circuits for high-throughput and numerically intensive applications, such as communications receivers and digital signal processing.\n\nJosephson junctions in RSFQ circuits are biased in parallel. Therefore, the total bias current grows linearly with the Josephson junction count. This currently presents the major limitation on the integration scale of RSFQ circuits, which does not exceed a few tens of thousands of Josephson junctions per circuit.\n\nReducing the resistor (R) used to distribute currents in traditional RSFQ circuits and adding an inductor (L) in series can reduce the static power dissipation and improve energy efficiency.\n\nReducing the bias voltage in traditional RSFQ circuits can reduce the static power dissipation and improve energy efficiency.\n\nEfficient rapid single flux quantum (ERSFQ) logic was developed to eliminate the static power losses of RSFQ by replacing bias resistors with sets of inductors and current-limiting Josephson junctions.\n\nEfficient single flux quantum (eSFQ) logic is also powered by direct current, but differs from ERSFQ in the size of the bias current limiting inductor and how the limiting Josephson junctions are regulated.\n\nReciprocal Quantum Logic (RQL) was developed to fix some of the problems of RSFQ logic. RQL uses reciprocal pairs of SFQ pulses to encode a logical '1'. Both power and clock are provided by multi-phase alternating current signals. RQL gates do not use resistors to distribute power and thus dissipate negligible static power.\n\nMajor RQL gates include: AndOr, AnotB, Set/Reset (with nondestructive readout), which together form a universal logic set and provide memory capabilities.\n\nAdiabatic Quantum flux parametron (AQFP) logic was developed for energy-efficient operation and is powered by alternating current.\n\nSuperconducting quantum computing is a promising implementation of quantum information technology that involves nanofabricated superconducting electrodes coupled through Josephson junctions. As in a superconducting electrode, the phase and the charge are conjugate variables. There exist three families of superconducting qubits, depending on whether the charge, the phase, or neither of the two are good quantum numbers. These are respectively termed charge qubits, flux qubits, and hybrid qubits.\n\n\n"}
{"id": "53440034", "url": "https://en.wikipedia.org/wiki?curid=53440034", "title": "TecAccess", "text": "TecAccess\n\nTecAccess is an American firm located in Rockville, Virginia that designs online learning tools and websites for people with disabilities. The company offers consulting services, software development, testing and assessment, training, auditing, certification, and policy review. It focuses on Section 508 compliance and IT accessibility for public and private organizations.\n\nIn 2001, Debra Ruh founded TecAccess (also known as Strategic Performance Solutions). The business grew after Section 508 of the Rehabilitation Act Amendments of 1998, that took effect June 21, 2001, required that people with disabilities have accessible telecommunications, websites, and computer equipmend.\n\nTecAccess was hired in 2003 by Canon to make photocopiers accessible for people who cannot use their arms or are blind; they devised a voice-recognition feature in the ImageRunner series. These photocopiers won an award from the American Foundation for the Blind in 2007. In October 2005, TecAccess was one of the recipients of the United States Department of Labor's New Freedom Initiative Award.\n\nIn 2006, the company had $2.5 million in sales to governmental agencies and businesses. Its clients have included the Department of Education, the Internal Revenue Service, Hewlett-Packard, and the Patent and Trademark Office. The organization is located in Rockville, Virginia, but many of the workers telecommute. In 2006, there were 25 employees and 60 associates.) 80% of the workers have a disability, and perform their jobs by using adaptive technology.\n\nTecAccess merged with SSB BART Group in 2011. Ruh was made chief marketing officer of SSB and remained CEO of TecAccess, which operates as a separate entity. In 2016, the CEO of TecAccess was Rich Belyea and Ruh was president.\n\n"}
{"id": "20835539", "url": "https://en.wikipedia.org/wiki?curid=20835539", "title": "Thinking Electronic", "text": "Thinking Electronic\n\nThinking Electronic Industrial Co., Ltd. (THINKING; ) (TWSE：2428) is one of the major circuit protection component manufacturer in Taiwan. It was established in 1979 and the headquarters are in Kaohsiung, Taiwan.\n\nTHINKING manufactures products in Kaohsiung. More production facilities in China include Guangdong, Jiangsu, Hubei and Jiangxi.\n\nStarted from ceramic material than extended to polymer and metal, THINKING developed series of products to protect electronic circuit from damaged by over current, overvoltage or overheat. Portfolio includes NTC (negative temperature coefficient) and PTC (positive temperature coefficient) thermistors, temperature sensor probes, varistors, ESD (electrostatic discharge) suppressors, and polymer resettable fuses (also known as PPTC).\n\nIt is well known as NTC Thermistor and varistor manufacturer in Taiwan, as well as the first publicly listed cooperation in Taiwan's protective component industry. With the PC industry rising from the 1980s in Taiwan, its NTC thermistor is adapted as the inrush current limiter in switched-mode power supply to suppress the inrush current when power supply turns on, and the varistor protects the circuit from damaged by surge current occasionally occurred in the electricity network. This earns THINKING a role in the supply chain of the switched-mode power supply industry and listed into top 1,000 manufacturers in Taiwan by the press.\n\n\n"}
{"id": "979942", "url": "https://en.wikipedia.org/wiki?curid=979942", "title": "Timeline of steam power", "text": "Timeline of steam power\n\nSteam power developed slowly over a period of several hundred years, progressing through expensive and fairly limited devices in the early 17th century, to useful pumps for mining in 1700, and then to Watt's improved steam engine designs in the late 18th century. It is these later designs, introduced just when the need for practical power was growing due to the Industrial Revolution, that truly made steam power commonplace.\n\n\n\n\n\n\n"}
{"id": "44297493", "url": "https://en.wikipedia.org/wiki?curid=44297493", "title": "TrueNorth", "text": "TrueNorth\n\nTrueNorth is a neuromorphic CMOS integrated circuit chip produced by IBM in 2014. It is a manycore processor network on a chip design, with 4096 cores, each one having 256 programmable simulated neurons for a total of just over a million neurons. In turn, each neuron has 256 programmable \"synapses\" that convey the signals between them. Hence, the total number of programmable synapses is just over 268 million (2). Its basic transistor count is 5.4 billion. Since memory, computation, and communication are handled in each of the 4096 neurosynaptic cores, TrueNorth circumvents the von-Neumann-architecture bottleneck and is very energy-efficient, consuming 70 milliwatts with a power density that is 1/10,000th of conventional microprocessors. The SyNAPSE chip operates at lower temperatures and power because it only draws power necessary for computation.\n\n\n\n"}
{"id": "9039717", "url": "https://en.wikipedia.org/wiki?curid=9039717", "title": "Vacuum fryer", "text": "Vacuum fryer\n\nA vacuum fryer is a deep-frying device housed inside a vacuum chamber.\n\nVacuum fryers are fit to process low-quality potatoes that contain higher sugar levels than normal, as they frequently have to be processed in spring and early summer before the potatoes from the new harvest become available. With vacuum frying it is easier to maintain natural colors and flavours of the finished product. Due to the lower temperatures applied (approx. ), the formation of suspected carcinogen acrylamide is significantly lower than in standard atmospheric fryers, where the frying temperature is approx. . The fat absorption of the products is also reported to be lower than in atmospheric fryers. In South East Asia (mainly Philippines, Thailand, China and Indonesia) batch type vacuum fryers are mainly used for the production of fruit chips. However, these machines are only appropriate for relatively small production companies.\n\nFor larger production quantities, continuous vacuum fryers are available. In these installations, the vacuum frying pan is installed in a stainless steel vacuum tube. The infeed of the raw product is carried out through a rotary airlock.\nDepending on the application, the frying pan itself is designed to meet the different product specifications. A transport belt takes the finished product out of the fryer and towards the outfeed system. A lock chamber at the exit of the vacuum tube prevents air from entering the vacuum zone, and a belt system takes the product from one zone to another.\n\nThe vacuum is created by vacuum pumps, and the whole system is controlled by a programmable logic controller.\n\nIn batch fryers, the frying oil has to be replaced quite often as it is sensitive to temperature changes. Continuous vacuum fryers lead to a longer lifetime of the frying oil and therefore lower the production costs. Vacuum fryers can also reduce oil content in fried foods. The amount of reduced oil content, usually 1–3%, depends on the type of vacuum fryer.\n\n"}
{"id": "10992920", "url": "https://en.wikipedia.org/wiki?curid=10992920", "title": "Vienna Technical Museum", "text": "Vienna Technical Museum\n\nThe Vienna Technical Museum () is located in Vienna (Austria), in the Penzing district, at Mariahilferstraße 212.\n\nThe decision to establish a technical museum was made in 1908, and construction of the building started in 1909. On June 20, 1909, Emperor Franz Josef laid the foundation stone. The museum was opened in 1918.\n\nThe permanent exhibition categories include: Nature and Knowledge: astronomy, principals, physics; Heavy industry: mining, iron, steel; Energy; Mass production - luxury goods; Everyday life - directions for use; Communications and information media; Musical instruments; Transport; Basic Research - A great adventure.\n\n"}
{"id": "51627791", "url": "https://en.wikipedia.org/wiki?curid=51627791", "title": "Zain Cash", "text": "Zain Cash\n\nZain Cash is a mobile wallet, money transfer, electronic bill payment, funds disbursement service, licensed by the Central Bank of Iraq and launched in late 2015 by Zain and Iraq Wallet. ZainCash allows users to deposit, withdraw, transfer money and pay for goods and services via their mobile phone.\n\nZain Cash offers mobile money solutions including:\n\nZain Cash introduced an online payment solution, ‘Pay with ZainCash’ to allows sellers to accept online payments through their websites and mobile applications, while also enabling customers to purchase products and services online.\n"}
