{"id": "10089924", "url": "https://en.wikipedia.org/wiki?curid=10089924", "title": "Andrex", "text": "Andrex\n\nAndrex is a British brand of toilet roll. It is owned by the American company Kimberly-Clark. The \"Andrex Puppy\", a Labrador Retriever puppy that appears on the company's television adverts, is synonymous with the brand.\n\nIts sister brand in the U.S. and Australia is \"Kleenex Cottonelle\", and in Germany as just \"Cottonelle.\" In The Netherlands, Andrex is known as \"Page\". In Belgium, Italy, Spain and Portugal it is branded as \"Scottex\".\n\nIn Australia, the puppy is known as the \"Kleenex Puppy\" and Kleenex is a partner and supporter of Guide Dogs Australia.\n\nAndrex was originally developed in 1942 by paper manufacturer St Andrew Mills Ltd., as a disposable handkerchief. Harrods department store in London sold the handkerchiefs exclusively. Before Andrex, brands such as Bronco and Izal produced products that were harsher. They were mainly sold through chemists and known as “shinies”.\n\nThe name Andrex comes from St Andrew Mill, on St Andrews Road in Walthamstow, where the toilet tissue was first made. The concept of two ply luxury paper had been inspired by the facial tissues used by American women, as witnessed by the man who created the name Andrex, Ronald Keith Kent. It was the first two-ply tissue.\n\nSt Andrew Mills was taken-over by Bower in 1955, and in 1956, Bowater formed a joint venture with the Scott Paper Company, Bowater-Scott, that specialized in tissue products including Andrex.\n\nOne of the most popular TV ads in the UK almost did not happen. The original idea in 1972 was for a girl to run through a house trailing a roll of Andrex. The television regulators did not approve this as they felt it encouraged children to be wasteful. Bowater-Scott's Marketing Director, Raymond Dinkin decided to use a Labrador puppy instead. Since then there have been 130 different adverts featuring the puppy.\n\nIn 1986, Bowater sold Bowater-Scott to Scott Paper, and in 1995, Kimberly-Clark purchased Scott Paper.\n\nAndrex says that it marketed the first moist toilet paper in 1992.\n\nIn 2004, Andrex replaced its advertising slogan “Soft, Strong and very very Long”, with “Tuggable, Huggable softness”, and changed to “Be Kind To Your Behind” in 2008. By 2015, it was using the slogans “Andrex clean” and “How Andrex do you feel?”\n\nAll Andrex mainstream is made in Northfleet. Factories in Flint and Barrow in Furness \nsupplement production on the mainline product, along with the Puppies on a Roll, Aloe Vera and Quilts variations.\n\n"}
{"id": "435456", "url": "https://en.wikipedia.org/wiki?curid=435456", "title": "Asahi Pentax", "text": "Asahi Pentax\n\nThe Asahi Pentax series, by the , was a pivotal development in modern photography. They were the earliest Pentax cameras.\n\nIn 1957, the Asahi Optical Company (later \"Pentax\") introduced the Pentax, a 35 mm Single-lens reflex camera (SLR) camera which was so well received that it influenced the design of 35 mm SLRs worldwide for years to come.\n\nThe Pentax and its later development and likewise classic 1964 Pentax Spotmatic allowed Asahi Optical Company to develop into a photographic multinational company, eventually leading the company to rename itself \"Pentax\" after its seminal product.\n\nThe Asahi Pentax of 1957 featured:\n\n\nMoreover, the Pentax placed controls in locations that would become standard on 35 mm SLRs from all manufacturers, such as the right-handed rapid wind lever, the bottom right mounted rewind release. It also had a film speed reminder around the film rewind crank, a location that remained standard until the dial went from being merely a reminder to the photographer to actually controlling the light meter built into later SLRs.\n\nThe two photographic giants, Canon and Nikon did not introduce their own SLR cameras until 1959 with the Canonflex and the F-series respectively. By contrast, the Pentax offered these features at a relatively low price, introducing many photographers to 35 mm SLR photography.\n\nThe Pentax became so dominant that the 42 mm screw lens mount used on the Pentax and Pentax Spotmatic become known as the \"Pentax universal screw mount\" although it had actually been introduced by Contax in 1949. Previously most makes of camera used proprietary mounts; the use of this mount by other manufacturers allowed owners of M42-equipped cameras to mount lenses from Zeiss, Yashica, Soligor, Vivitar, Topcon, Sigma, Chinon, and many more as well as Asahi's own highly regarded Takumar lenses. These lenses had no other communication with the camera than a diaphragm interface which allowed focusing at full aperture, the lens being stopped down to working aperture on pressing the shutter release. Later cameras required more lens-body communication to implement shutter priority exposure, program auto exposure, and finally, autofocussing, and different manufacturers used different interfaces, ending the era of interoperability. In 1975 Pentax introduced the K mount to replace the 42 mm screw lens mount used so successfully until then.\n\n"}
{"id": "10095442", "url": "https://en.wikipedia.org/wiki?curid=10095442", "title": "Augustus Moore Herring", "text": "Augustus Moore Herring\n\nAugustus Moore Herring (August 3, 1867 – July 17, 1926) was an American aviation pioneer, who sometimes is claimed by Michigan promoters to be the first true aviator of a motorized heavier-than-air aircraft.\n\nHerring was born in Covington, Georgia, to William F. Herring, a wealthy cotton broker, and his wife Cloe Perry Conyers. He studied in both Switzerland and Germany, before his family settled in New York in 1884. In 1885-6, as a student at the Stevens Institute of Technology, Herring was already building models of flying machines. By 1893, he had built a full sized glider – which he crashed when trying to leave the ground. He began studying glider expert Otto Lilienthal's work. In 1894, Herring built a Type 11-monoplane glider based on Otto Lilienthal‘s 1893 German patent.\n\nHerring was then hired by Octave Chanute to build and test aircraft models from plans drawn up by either Herring and Chanute. Later in 1895, Samuel Pierpont Langley hired Herring to assist in his experiments. Herring was rehired by Chanute in January 1896, but continued experimenting on his own. In December 1896, he applied for a patent of a man-supporting, heavier-than-air \"flying machine\" that was motor powered and controllable, but the patent application was rejected.\n\nOn October 10, 1898, Herring telegraphed Chanute to come and watch him fly a powered aeroplane of his own design, based on the Chanute-type biplane structure, using a compressed air engine at Silver Beach Amusement Park in St. Joseph, Michigan. He could not get airborne. Herring was reported to have made a longer flight on October 22, witnessed by two locals.\nIn 1909 Herring joined Glenn Curtiss to create the Herring-Curtiss Company. The next year, he left Curtiss and joined Starling Burgess in Marblehead, Massachusetts to design and build aeroplanes. He left Burgess after a year, following disagreements with another Burgess partner, Greely S. Curtis. Herring brought suit against Glenn Curtiss, claiming he had been cheated out of his property and ideas, but we have to remember that the patent Herring claimed to have did not exist.\n\nHerring did some aviation design work for the United States Army during World War I, he later was partially paralyzed by a series of strokes.\n\nHe died in 1926 at the age of 59, survived by his wife, the former Lillian Mellen. Ironically, four years later Herring won his suit against Curtiss with a sizeable financial award.\n\nAviation historian Phil Scott in \"The Shoulders of Giants: A History of Human Flight to 1919\" (1995, ) wrote that he does not consider Herring a candidate for the first flight claim. Scott says Herring's glider was difficult to steer and his two-cylinder, three-horsepower compressed air engine could operate for only 30 seconds at a time. Scott considers Herring as having simply expanded the traditional hang-gliding by adding an engine.\n\nHerring's defenders point out that hang-glider fliers today steer their aircraft by shifting their body, as Herring did. This method was superseded by the Wright Brothers system of dynamic three axis control used by most aircraft flying today.\n\n\n"}
{"id": "973701", "url": "https://en.wikipedia.org/wiki?curid=973701", "title": "Baggage reclaim", "text": "Baggage reclaim\n\nIn airport terminals, a baggage reclaim area is an area where arriving passengers claim checked-in baggage after disembarking from an airline flight. The alternative term baggage claim is used at airports in the USA and some other airports internationally. Similar systems are also used at train stations served by companies that offer checked bags, such as Amtrak in the United States.\n\nA typical baggage claim area contains baggage carousels or conveyor systems that deliver checked baggage to the passenger. The baggage claim area generally contains the airline's customer service counter for claiming oversized baggage or to report missing or damaged baggage.\n\nSome airports required that passengers display their baggage receipt obtained at check-in so that it can be positively matched against the bag they are trying to remove from baggage reclaim, and many airports still recommend he baggage receipt is checked against the bag tag of the bag reclaimed. This serves two purposes: first it reduces baggage theft, and secondly it helps to prevent passengers from accidentally leaving the airport with another passenger's bag that bears resemblance to their own.\n\nFor international arrivals, the baggage reclaim area is a restricted area, after passport and visa control and before clearing customs, so that all baggage can be inspected by customs agents, but the passenger does not have to handle heavy baggage while moving through the passport booth. In the United States and Canada, and also in some airports in Asia, all arriving international passengers' baggage is reclaimed here and can be re-surrendered to the airline for connecting flights on the other side of customs (for connection from international to domestic flights in most countries, all passengers must reclaim their baggage). In most other countries passengers transferring to an onward flight do not need to collect their bags unless their airline does not offer to through-check their bags to their final destination. This is required in American and some Canadian airports because international terminals are not enclosed (the only exit being through customs) and often serve domestic flights. The same rule applies in the case of airports that have U.S. border preclearance facilities. This means that passengers continuing onto the U.S. from other cities must retrieve their checked baggage first, then re-check them in after clearing U.S. Customs.\n\nDepending on the airport, the domestic baggage reclaim area may be located next to or shared with the international reclaim area, or sometimes located in the public part of the airport alongside car rental desks and airport exits, and only passengers at their final destination claim their bags here. In most large airports in the United States and in some small ones as well, the domestic baggage reclaim is located on a different floor than the ticket counter, usually lower.\n\nThe efficiency of baggage reclaim units can be measured in a number of ways including the amount of time a unit is in use for a given flight or the amount of baggage a unit can hold. A number of factors can independently affect the efficiency of a particular unit:\n"}
{"id": "55677685", "url": "https://en.wikipedia.org/wiki?curid=55677685", "title": "Bare machine computing", "text": "Bare machine computing\n\nBare Machine Computing (BMC) is a programming paradigm based on bare machines. In the BMC paradigm, applications run without the support of any operating system (OS) or centralized kernel i.e., no intermediary software is loaded on the bare machine prior to running applications. The applications, which are called bare machine applications or simply BMC applications, do not use any persistent storage or a hard disk, and instead are stored on detachable mass storage such as a USB flash drive. A BMC program consists of a single application or a small set of applications (application suite) that runs as a single executable within one address space. BMC applications have direct access to the necessary hardware resources. They are self-contained, self-managed and self-controlled entities that boot, load and run without using any other software components or external software. BMC applications have inherent security due to their design. There are no OS-related vulnerabilities, and each application only contains the necessary (minimal) functionality. There is no privileged mode in a BMC system since applications only run in user mode. Also, application code is statically compiled-there is no means to dynamically alter BMC program flow during execution.\n\nIn the early days of computing, computer applications directly communicated to the hardware. As applications grew larger encompassing various domains, OSes were invented. They served as middleware providing hardware abstractions to applications. OSes have grown immensely in their size and complexity resulting in attempts to reduce OS overhead and improve performance including Microkernel, Exokernel , Tiny-OS, OS-Kit, Palacio and Kitten ,IO_Lite, bare-metal Linux, IBM-Libra and other lean kernels. In addition to the above approaches, in embedded systems such as smart phones, a small and dedicated portion of an OS and a given set of applications are closely integrated with the hardware. There are also a myriad of industrial control and gaming applications that run directly on the hardware. In most of these systems, the hardware is not open to run general purpose applications. \n\nBare machine computing originated with application object (AO) concept invented by Karne at Towson University. It evolved over the years into dispersed operating systems (DOSC), and eventually into the BMC paradigm.\n\nIn many ways, the BMC paradigm differs from conventional computing. There is no centralized kernel or OS running during the execution of BMC applications. Also, a bare machine in the BMC paradigm does not have any ownership or store valuable resources; and it can be used to run general purpose computing applications. Such characteristics are not found in conventional computing systems including embedded systems and system on a chip (SOC). In addition, the BMC concept is a minimalistic approach to achieve simplicity, smaller code sizes and security.\n\nThe BMC paradigm has been used to implement webservers, split servers, VoIP, SIP server, email, webmail, security protocols, file systems, RAID,transformed bare SQLite., middleware for network cards interfaces(NICS),and ethernet BONDING on BMC webserver with dual NICs, Success in transforming conventional Windows or Linux applications to run as BMC applications will pave the way for new uses of the BMC paradigm.\n"}
{"id": "44542595", "url": "https://en.wikipedia.org/wiki?curid=44542595", "title": "Bharat Bill Payment System", "text": "Bharat Bill Payment System\n\nBharat Bill Payment System (BBPS) is an integrated bill payment system in India offering interoperable and accessible bill payment service to customers through a network of agents of registered member as Agent Institutions (AI), enabling multiple payment modes, and providing instant confirmation of payment.\n\nNational Payments Corporation of India (NPCI) functions as the authorised Bharat Bill Payment Central Unit (BBPCU), which will be responsible for setting business standards, rules and procedures for technical and business requirements for all the participants. NPCI, as the BBPCU, will also undertake clearing and settlement activities related to transactions routed through BBPS. Existing bill aggregators and banks are envisaged to work as Operating Units to provide an interoperable bill payment system irrespective of which unit has on-boarded a particular biller. Payments may be made through the BBPS using cash, transfer cheques, and electronic modes.\n\nThe Committee headed by RBI Executive Director G. Padmanabhan was set up in 2013 to study the feasibility of implementation of Giro based Payment Systems. It had estimated that over 30,800 million bills amounting to Rs.6223 billion are generated each year in the top 20 cities in the country.\n\nIt was felt that integrated bill payment system is required in the country that could offer interoperable and accessible bill payment services to customers through a network of agents, allow multiple payment modes, and provide instant confirmation of payment. This should also serve as an efficient, cost-effective alternative to the existing systems and enhance consumer confidence and experience.\n"}
{"id": "6138641", "url": "https://en.wikipedia.org/wiki?curid=6138641", "title": "Blast wave", "text": "Blast wave\n\nIn fluid dynamics, a blast wave is the increased pressure and flow resulting from the deposition of a large amount of energy in a small, very localised volume. The flow field can be approximated as a lead shock wave, followed by a self-similar subsonic flow field. In simpler terms, a blast wave is an area of pressure expanding supersonically outward from an explosive core. It has a leading shock front of compressed gases. The blast wave is followed by a blast wind of negative pressure, which sucks items back in towards the center. The blast wave is harmful especially when one is very close to the center or at a location of constructive interference. High explosives that detonate generate blast waves.\n\nHigh-order explosives (HE) are more powerful than low-order explosives (LE). HE detonate to produce a defining supersonic over-pressurization shock wave. Several sources of HE include trinitrotoluene, C-4, Semtex, nitroglycerin, and ammonium nitrate fuel oil (ANFO). LE deflagrate to create a subsonic explosion and lack HE’s over-pressurization wave. Sources of LE include pipe bombs, gunpowder, and most pure petroleum-based incendiary bombs such as Molotov cocktails or aircraft improvised as guided missiles. HE and LE induce different injury patterns. Only HE produce true blast waves.\n\nThe classic flow solution—the so-called \"similarity solution\"—was independently devised by John von Neumann and British mathematician Geoffrey Ingram Taylor during World War II. After the war, the similarity solution was published by three other authors—L. I. Sedov, R. Latter, and J. Lockwood-Taylor—who had discovered it independently.\n\nSince the early theoretical work more than 50 years ago, both theoretical and experimental studies of blast waves have been ongoing.\n\nThe simplest form of a blast wave has been described and termed the Friedlander waveform. It occurs when a high explosive detonates in a free field, that is, with no surfaces nearby with which it can interact.\nBlast waves have properties predicted by the physics of waves. For example, they can diffract through a narrow opening, and refract as they pass through materials. Like light or sound waves, when a blast wave reaches a boundary between two materials, part of it is transmitted, part of it is absorbed, and part of it is reflected. The impedances of the two materials determine how much of each occurs.\n\nThe equation for a Friedlander waveform describes the pressure of the blast wave as a function of time:\n\nwhere P is the peak pressure and t* is the time at which the pressure first crosses the horizontal axis (before the negative phase).\n\nBlast waves will wrap around objects and buildings. Therefore, persons or objects behind a large building are not necessarily protected from a blast that starts on the opposite side of the building. Scientists use sophisticated mathematical models to predict how objects will respond to a blast in order to design effective barriers and safer buildings.\n\n Mach stem formation occurs when a blast wave reflects off the ground and the reflection catches up with the original shock front, therefore creating a high pressure zone that extends from the ground up to a certain point called the triple point at the edge of the blast wave. Anything in this area experiences peak pressures that can be several times higher than the peak pressure of the original shock front.\n\n In physics, interference is the meeting of two correlated waves and either increasing or lowering the net amplitude, depending on whether it is constructive or destructive interference. If a crest of a wave meets a crest of another wave at the same point then the crests interfere constructively and the resultant crest wave amplitude is increased; forming a much more powerful wave than either of the beginning waves. Similarly two troughs make a trough of increased amplitude. If a crest of a wave meets a trough of another wave then they interfere destructively, and the overall amplitude is decreased; thus making a wave that is much smaller than either of the parent waves.\n\nThe formation of a mach stem is one example of constructive interference. Whenever a blast wave reflects off of a surface, such as a building wall or the inside of a vehicle, different reflected waves can interact with each other to cause an increase in pressure at a certain point (constructive interference) or a decrease (destructive interference). In this way the interaction of blast waves is similar to that of sound waves or water waves.\n\nBlast waves cause damage by a combination of the significant compression of the air in front of the wave (forming a shock front) and the subsequent wind that follows. A blast wave travels faster than the speed of sound and the passage of the shock wave usually lasts only a few milliseconds. Like other types of explosions, a blast wave can also cause damage to things and people by the blast wind, debris, and fires. The original explosion will send out fragments that travel very fast. Debris and sometimes even people can get swept up into a blast wave, causing more injuries such as penetrating wounds, impalement, broken bones, or even death. The blast wind is the area of low pressure that causes debris and fragments to actually rush back towards the original explosions. The blast wave can also cause fires or even secondary explosions by a combination of the high temperatures that result from detonation and the physical destruction of fuel-containing objects.\n\nIn response to an inquiry from the British MAUD Committee, G. I. Taylor estimated the amount of energy that would be released by the explosion of an atomic bomb in air. He postulated that for an idealized point source of energy, the spatial distributions of the flow variables would have the same form during a given time interval, the variables differing only in scale. (Thus the name of the \"similarity solution.\") This hypothesis allowed the partial differential equations in terms of r (the radius of the blast wave) and t (time) to be transformed into an ordinary differential equation in terms of the similarity variable formula_2 ,\n\nwhere formula_3 is the density of the air and formula_4 is the energy that's released by the explosion. This result allowed G. I. Taylor to estimate the yield of the first atomic explosion in New Mexico in 1945 using only photographs of the blast, which had been published in newspapers and magazines. The yield of the explosion was determined by using the equation: formula_5,\n\nwhere formula_6 is a dimensionless constant that is a function of the ratio of the specific heat of air at constant pressure to the specific heat of air at constant volume. The value of C is also affected by radiative losses, but for air, values of C of 1.00-1.10 generally give reasonable results. In 1950, G. I. Taylor published two articles in which he revealed the yield E of the first atomic explosion, which had previously been classified and whose publication therefore caused a great to-do.\n\nWhile nuclear explosions are among the clearest examples of the destructive power of blast waves, blast waves generated by exploding conventional bombs and other weapons made from high explosives have been used as weapons of war due to their effectiveness at creating polytraumatic injury. During World War II and the U.S.’s involvement in the Vietnam War, blast lung was a common and often deadly injury. Improvements in vehicular and personal protective equipment have helped to reduce the incidence of blast lung. However, as soldiers are better protected from penetrating injury and surviving previously lethal exposures, limb injuries, eye and ear injuries, and traumatic brain injuries have become more prevalent.\n\nStructural behaviour during an explosion depends entirely on the materials used in the construction of the building. Upon hitting the face of a building, the shock front from an explosion is instantly reflected. This impact with the structure imparts momentum to exterior components of the building. The associated kinetic energy of the moving components must be absorbed or dissipated in order for them to survive. Generally, this is achieved by converting the kinetic energy of the moving component to strain energy in resisting elements.\n\nTypically the resisting elements, such as windows, building facades and support columns fail, causing partial damage through to progressive collapse of the building.\n\nThe so-called Sedov-Taylor solution has become useful in astrophysics. For example, it can be applied to quantify an estimate for the outcome from supernova-explosions. The Sedov-Taylor expansion is also known as the 'Blast Wave' phase, which is an adiabatic expansion phase in the life cycle of supernova. The temperature of the material in a supernova shell decreases with time, but the internal energy of the material is always 72% of E, the initial energy released. This is helpful for astrophysicists interested in predicting the behavior of supernova remnants.\n\nBlast waves are generated in research environments using explosive or compressed-gas driven shock tubes in an effort to replicate the environment of a military conflict to better understand the physics of blasts and injuries that may result, and to develop better protection against blast exposure. Blast waves are directed against structures (such as vehicles), materials, and biological specimens or surrogates. High-speed pressure sensors and/or high speed cameras are often used to quantify the response to blast exposure. Anthropomorphic test devices (ATDs or test dummies) initially developed for the automotive industry are being used, sometimes with added instrumentation, to estimate the human response to blast events. For examples, personnel in vehicles and personnel on demining teams have been simulated using these ATDs.\n\nCombined with experiments, complex mathematical models have been made of the interaction of blast waves with inanimate and biological structures. Validated models are useful for \"what if\" experiments – predictions of outcomes for different scenarios. Depending on the system being modeled, it can be difficult to have accurate input parameters (for example, the material properties of a rate-sensitive material at blast rates of loading). Lack of experimental validation severely limits the usefulness of any numerical model.\n\n"}
{"id": "21255948", "url": "https://en.wikipedia.org/wiki?curid=21255948", "title": "Data Discovery and Query Builder", "text": "Data Discovery and Query Builder\n\nData Discovery and Query Builder (DDQB) is a data abstraction technology, developed by IBM, that allows users to retrieve information from a data warehouse, in terms of the user's specific area of expertise instead of SQL.\n\nDDQB serves the user through a web based graphical user interface and configurable data abstraction model (DAM), which contains both an understanding of the user knowledge domain and the database below it.\n\nDDQB uses a set of Eclipse-based customization tooling and can be deployed as a set of Web Services.\n\n\n\n"}
{"id": "59135145", "url": "https://en.wikipedia.org/wiki?curid=59135145", "title": "Deltaco", "text": "Deltaco\n\nDeltaco is a Swedish computer hardware company founded in Ludvika in 1991, incorporated under the name \"Swedeltaco AB\" as well as \"Dist IT.\" Originally it mainly imported Taiwanese cables for resale, but came to both produce and sell its own products across a variety of product lines. In 2011 its own products stood for 40% of its revenue. In 2007 it launched across the Nordic countries as DELTACO, and in 2017 it released its own line of gaming peripherals, Deltaco Gaming.\n\nDeltaco has previously advocated against expensive cables, stating that: \"when it comes to analogue signals, either the signal arrives, or it doesn't\", and that there is no need to pay more for cables for audiophiles or video-enthusiasts.\n"}
{"id": "6155162", "url": "https://en.wikipedia.org/wiki?curid=6155162", "title": "Digestate", "text": "Digestate\n\nDigestate is the material remaining after the anaerobic digestion of a biodegradable feedstock. Anaerobic digestion produces two main products: digestate and biogas. Digestate is produced both by acidogenesis and methanogenesis and each has different characteristics.\n\nAcidogenic digestate is fibrous and consists of structural plant matter including lignin and cellulose. Acidogenic digestate has high moisture retention properties. The digestate may also contain minerals and remnants of bacteria.\n\nMethanogenic digestate is a sludge (sometimes called a liquor). This is often high in nutrients such as ammoniums and phosphates.\n\nThe primary use of digestate is as a soil conditioner. Acidogenic digestate provides moisture retention and organic content for soils. This organic material can break down further, aerobically in soil. Methanogenic digestate provides nutrients for plant growth. It can also be used to protect soils against erosion.\n\nAcidogenic digestate can also be used as an environmentally friendly filler to give structure to composite plastics.\n\nGrowth trials on digestate originating from mixed waste have showed healthy growth results for crops. Digestate can also be used in intensive greenhouse cultivation of plants, e.g. in Digeponics.\n\nApplication of digestate has been shown to inhibit plant diseases and induction of resistance. Digestate application has a direct effect on soil-born diseases, and an indirect effect by stimulation of biological activity.\n\nDigestate is technically not compost although it is similar to it in physical and chemical characteristics. Compost is produced by aerobic digestion- decomposition by aerobes. This includes fungi and bacteria which are able to break down the lignin and cellulose to a greater extent.\n\nThe standard of digestate produced by anaerobic digestion can be assessed on three criteria, chemical, biological and physical aspects. Chemical quality needs to be considered in terms of heavy metals and other inorganic contaminant, persistent organic compounds and the content of macro-elements such as nitrogen, phosphorus and potassium. Depending on their source, biowastes can contain pathogens, which can lead to the spreading of human, animal or plant diseases if not appropriately managed. \n\nThe physical standards of composts includes mainly appearance and odour factors. Whilst physical contamination does not present a problem with regards to human, plant or animal health, contamination (in the form of plastics, metals and ceramics) can cause a negative public perception. Even if the compost is of high quality and all standards are met, a negative public perception of waste-based composts still exists. The presence of visible contaminants reminds users of this.\n\nQuality control of the feedstock is the most important way of ensuring a quality end product. The content and quality of waste arriving on-site should be characterised as thoroughly as possible prior to being supplied.\n\nIn the UK the Publicly Available Specification (called PAS110) governs the definition of digestate derived from the anaerobic digestion of source-segregated biodegradable materials. The specification ensures all digested materials are of consistent quality and fit for purpose. If a biogas plant meets the standard, its digestate will be regarded as having been fully recovered and to have ceased to be waste, and it can be sold with the name “Bio- fertiliser”.\n\n"}
{"id": "28944525", "url": "https://en.wikipedia.org/wiki?curid=28944525", "title": "Distortion meter", "text": "Distortion meter\n\nA distortion meter is a type of electronic test equipment used to determine specific frequencies that cause distortion in electronic devices. The device is primarily used in audio related equipment.\n\nA typical unit injects a signal in to the input of a circuit and monitors the output of the circuit for distortion.\n\n"}
{"id": "7260875", "url": "https://en.wikipedia.org/wiki?curid=7260875", "title": "Edison screw", "text": "Edison screw\n\nEdison screw (ES) is a standard lightbulb socket for electric light bulbs in North America. It was developed by Thomas Edison and was licensed in 1909 under General Electric's Mazda trademark. The bulbs have right-hand threaded metal bases (caps) which screw into matching threaded sockets (lamp holders). For bulbs powered by AC current, the thread is generally connected to neutral and the contact on the bottom tip of the base is connected to the \"live\" phase.\n\nIn North America and continental Europe, Edison screws displaced other socket types for general lighting. In the early days of electrification, Edison screws were the only standard connector, and appliances other than light bulbs were connected to AC power via lamp sockets. Today Edison screw sockets comply with international standards.\n\nEarly US incandescent lamp manufacturers used several different and incompatible bases. The Thomson-Houston Electric Company used a threaded stud at the bottom of the socket, and a flat contact ring. The Sawyer-Mann or Westinghouse base used a spring clip acting on grooves in the bulb base, and a contact stud at the bottom of the lamp. By about 1908, the Edison base was most common in the US, with the others falling out of use.\n\nIn response to Edison's patent, Reginald Fessenden invented the bi-pin connector for the 1893 World's Fair. Other lamp bases include the bayonet mount and wedge base.\n\nSpecifications for all lamp mount types are defined in the following American National Standards Institute (ANSI) and International Electrotechnical Commission (IEC) publications:\n\n\nGenerally, the two standards are harmonized, although several types of screw mount are still defined in only one standard.\n\nIn the designation \"Exx\", \"E\" stands for \"Edison\" and \"xx\" indicates the diameter in millimeters as measured across the peaks of the thread on the base (male), e.g., E12 has a diameter of 12 mm. This is distinct from the glass envelope (bulb) diameter, which in the U.S. is given in eighths of an inch, e.g., A19, MR16, T12.\n\nThere are four commonly used thread size groups for mains supply lamps:\n\n\nThe E26 and E27 are usually interchangeable, as are the E39 and E40, because there is only a 1 mm difference in thread outside diameter. E11 and E12 are not interchangeable. Other semi-standard screw thread sizes are available for certain specific applications.\n\nThe large E39 \"Mogul\" and E40 \"Goliath\" base are used on street lights, and high-wattage lamps (such as a 100-/200-/300-watt three-way) and many high-intensity discharge lamps. In areas following the U.S. National Electrical Code, general-use lamps over 300 W cannot use an E26 base and must instead use the E39 base; 300 W lamps may use either base. Medium Edison screw (MES) bulbs for 12 V are also produced for recreational vehicles. Large outdoor Christmas lights use Intermediate base, as do some desk lamps and many microwave ovens. Previously, emergency exit signs also tended to use the intermediate base, but U.S. and Canadian rules now require long-life and energy-efficient LED lamps, which can be purchased inside a conventional Edison base bulb as a retrofit. A medium screw base should not carry more than 25 amperes current; this may limit the practical rating of low voltage lamps.\n\nE29 \"Admedium\" bases are used for special applications, for example UV spotlight lamps in magnetic crack detection machines.\n\nIn countries that use 220–240 volt AC domestic power, standard-size E27 and small E14 are the most common screw-mount sizes and are prevalent throughout continental Europe and China.\n\nIn 120-volt North America, 100-volt Japan and Taiwan, the standard size for general-purpose lamps is E26.\n\nE12 is typically used for candelabra fixtures. E17 is also sometimes used, especially in small table lamps and novelty lighting, and occasionally the lights on newer ceiling fans. Christmas lights use various base sizes E17 for C9 bulbs, E12 for C7 bulbs, E10 for decades-old series-wired C6 bulb sets in the U.S., and an entirely different wedge base for T1¾ mini lights. For a short time early on, these mini lights were manufactured using E5 screw bases.\n\nA tiny E5 or E5.5 size is used only for extra-low voltages, such as in interior illumination for model buildings, and model vehicles such as model trains. These are often called \"pea bulbs\" if they are globe-shaped, but they commonly look like mini Christmas bulbs, or large \"grain-of-wheat\" bulbs. E10 bulbs are common on battery-powered flashlights, as are bayonet mounts (although those are usually held in with a circular flange located where the base meets the glass envelope of the bulb). The E11 base is sometimes used for 50/75/100-watt halogen lights in North America, where it is called the \"mini-can\", and tighter threads are used to keep them out of E12-base nightlights and other places where they could start a fire.\n\nThere are also adapters between screw sizes, and for adapting to or from bayonet caps. A socket extender makes the bulb stick out further, such as to accommodate a compact fluorescent lamp that doesn't fit in a recessed lighting fixture.\n\nMost Edison screws have right-hand threads (lamp is turned clockwise to tighten), but left-hand threaded screws are sometimes used, usually for a non-standard voltage or wattage bulb. This prevents the use of an incorrect bulb, which could cause damage. Public locations such as railway trains and the New York City Subway have used light bulbs with left-hand threads to discourage theft of the bulbs for use in regular light fixtures.\n\nThe Edison screw socket was used as an outlet (such as for toasters) when mains electricity was still mainly used for lighting, and before wall outlets became common.\n\nIn North America, fuses were used in buildings wired before 1960. These Edison base fuses would screw into a fuse socket similar to Edison-base incandescent lamps.\n\nSome adapters for wall outlets use an Edison screw, allowing a light socket to become an ungrounded electrical outlet (such as to install Christmas lights temporarily via a porch light), or to make a pull-chain switch with two outlets, or to split it for two lamps. Another adapter can make a wall outlet into a lamp holder (lamp socket).\n\nVarious other accessories have been made, including a smoke detector that recharges over a few hours and lasts for a few days or weeks thereafter, and still allows the attached lamp to operate normally. There have also been electronics that stick onto the end of the screw base and allow the attached lamp to flash, for example, to attract the attention of arriving guests or emergency vehicles; others function as a dimmer or timer, or dim gradually in a child's bedroom in the evening.\n\nSome thermionic valves vacuum tubes, such as certain rectifiers, use an Edison screw base.\n\nThree-way lamps have a \"d\" suffix to indicate double contacts, usually E26d or E27d, or rarely E39d. The second contact is used for the lower-wattage filament of the two inside the lamp. This extra contact is a ring located around the main contact. Unlike bayonet sockets, three-way and regular lamps are interchangeable, although the low filament or low setting doesn’t work if mismatched.\n\nThe small Edison screw has nine threads per inch, or about 2.8 mm per thread.\n\nThe medium Edison screw has seven threads per inch, or about 3.6 mm per thread. In the U.S., the Energy Independence and Security Act of 2007 requirement for greater energy efficiency only applies to the medium Edison screw, all other being considered \"specialty\" lamps.\n\nDiazed fuses DII uses the same E27 thread as standard 230 V lamps, but have a longer body and cannot be screwed into a lamp holder (socket). A lamp base is too short to contact the bottom terminal of a fuse holder. However it's possible (but not useful) to screw a DII fuse holder without a fuse in an E27 lamp holder.\n\nScrew bases have a number of disadvantages compared to the bayonet fit type:\nScrew bases have a number of advantages compared to the bayonet fit type:\n\n\n"}
{"id": "1947499", "url": "https://en.wikipedia.org/wiki?curid=1947499", "title": "Electrical equipment", "text": "Electrical equipment\n\nElectrical equipment includes any machine powered by electricity. It usually consists of an enclosure, a variety of electrical components, and often a power switch. Examples of these include:\n\nMore specifically, often electrical equipment refers only to components part of the electrical distribution system such as:\n\n"}
{"id": "415624", "url": "https://en.wikipedia.org/wiki?curid=415624", "title": "Fire screen desk", "text": "Fire screen desk\n\nThe fire screen desk (also known as a screen writing table) is a very small antique desk form meant to be placed in front of a fireplace to keep a user's feet warm while he or she is stationary while writing. This kind of desk was very popular in prosperous homes in Europe during the 18th century and slowly disappeared during the 19th, with the gradual introduction of stoves and central heating. \n\nIn order to keep the feet and the calves exposed to the heat from the fire, the fire screen desk usually had the form of a miniature writing table or a tiny bureau à gradin, with just a few drawers beneath the desktop. As its name indicates, it had a retractable fire screen in the back to protect the user's relatively exposed face from too much heat from the fireplace. The screen was usually made of a pleated or straight piece of heavy fabric, supported by crossed and sliding metallic supports. Many fire screen desks still exist, but the original screens have rarely survived. The metal supports or rods which extended the screens generally have been maintained with the desk. When the bare rods are in their extended position, they form an 'X shape' above the back of the desk.\n\nA few fire screen desks had no screen per se but were simply lighter, narrower, and extremely thinner versions of the high secretary desk put on some form of permanent trestle mount. Their high form shielded the user's face from the heat of the flames while the open trestle mount at the bottom exposed the feet. They were basically a smaller version of a French form called Secretaire en portefeuille.\n\nThe fire screen desk was often designed for use by a person of a specific gender: those designed for use by a female frequently had complex ornamentation and were generally smaller (light enough to be transported easily by a lady's maid) than those designed for use by a male. Because of these differences, individual desks were frequently called a \"gentleman's screen writing table\" or a \"lady's screen writing table\".\n\n"}
{"id": "28353266", "url": "https://en.wikipedia.org/wiki?curid=28353266", "title": "Flexicoil suspension", "text": "Flexicoil suspension\n\nFlexicoil suspension is a wear-resistant and maintenance-free suspension system, used in railway vehicles. It is a secondary suspension, installed between the body and the bogie of the locomotive, passenger car or wagon so fitted.\n\nThis type of suspension is most commonly used in modern rail passenger cars when air suspension is not required, since it is cheaper to buy and to maintain than air suspension.\n\nThe word \"Flexicoil\" was coined by General Motors' Electro Motive Division, to describe a suspension system fitted to some of the diesel locomotives in its range. As early as the 1930s, flexicoil suspensions were being used in locomotives in Spain, the Soviet Union and Africa.\n\nFlexicoil suspension technology in high speed electric locomotives was pioneered in Germany in the 1950s and 1960s, in various DB standard electric locomotives, and especially the DB Class 103. Between 1969 and 1971, British Rail conducted trials of a flexicoil suspension system in a British Rail Class 86 locomotive, no E 3173, which was affectionately nicknamed \"Zebedee\", after the jack-in-the-box character in the BBC television series \"The Magic Roundabout\". These experiments were successful, and led initially to the rebuilding of 56 members of the class with flexicoil suspension, as class 86/2. Ultimately, all members of class 86 were fitted with flexicoil suspensions.\n\nThe springs in a flexicoil suspension are made of steel. Protruding from above and below, and into, each spring is a spherical rubber dome that can absorb some of the horizontal forces. These domes are connected firmly to either the vehicle body (above) or the bogie frame (below). Under this arrangement, each flexicoil spring is twisted and moved from its vertical axis when the vehicle is cornering. This helps the two bogies to align themselves equally underneath the vehicle body. The vertical forces are absorbed entirely by the steel springs.\n\nAs the springs have relatively soft characteristics, hydraulic vertical dampers must also be installed for vibration damping at higher speeds than , along with longitudinal dampers. Lateral damping is not normally required.\n\nIn railway passenger cars fitted with flexicoil suspension, the springs are the only mechanical connection between the bogie and the car body. In heavier types of flexicoil suspension rolling stock, a bogie pivot fitted with rubber-metal bearings is used to hold a cross anchor yoke, which transfers the forces to the bogie frame via two cross anchor link pins.\n\nLocomotive bogies are usually also provided with a , or with a different tension transmission.\n\n\n\n\"This article is based upon a translation of the as at August 2010. The original authors can be seen here.\"\n"}
{"id": "34325661", "url": "https://en.wikipedia.org/wiki?curid=34325661", "title": "Foodie.fm", "text": "Foodie.fm\n\nFoodie.fm is an online shopping service that incorporates grocery shopping and recipe discovery into a social context. The service is available on the web and for a mobile device and can be downloaded for IPhone, Nokia, Android (operating system) or as a Facebook application. Foodie.fm has been referred to as the Facebook for groceries, and described as enabling smart grocery shopping since users personalize their information. to receive product and recipe recommendations. Referred to as 'social eatworking' and forecasted as a trend for 2012, users post and share shopping ideas, recipes and recommendations with other users on the service.\n\nThe application functions by recommending recipes and suggesting groceries for the user to buy based on specified preferences. Users can also connect to other users and family members to plan cooking and grocery shopping together by sharing shopping lists. The service is connected to all of the stores in a given grocery chain and connects users to their local store and product inventory. In the United Kingdom, the Foodie.fm product assortment is linked to Tesco through public Tesco API where users can check-out with Tesco.com. In Finland, the company has a cooperation with S Group which is one of the largest retail chains of the Nordic countries with reportedly 44% market share in Finland.\n\nFounded by Kalle Koutajoki, Samuli Mattila, Lauri Arte and Arto Lukkarila in 2009, the service is available in Finland and the United Kingdom as Beta. The company is based in Finland but formally launched internationally at Le Web conference in December 2011. As a business model, the company provides a one-to-one channel (personalized marketing) between the retailer and the consumer.\n\nIn an interview with CEO Kalle Koutajoki, he emphasizes that Foodie.fm has been created with internationalization in mind, and that the UK service will have more features such as crowdsourcing and revised commenting to make the service even more personal.\n\nFoodie.fm’s recommendation system relies on a patent-pending technology which learns from a user’s eating and buying habits and suggests groceries and recipes accordingly. The system also takes into account user profile settings which specifies food allergies, personal budget and dietary restrictions.\n\n\n"}
{"id": "19344555", "url": "https://en.wikipedia.org/wiki?curid=19344555", "title": "Herodian architecture", "text": "Herodian architecture\n\nHerodian architecture is a style of classical architecture characteristic of the numerous building projects undertaken during the reign (37–4 BC) of Herod the Great, the Roman client king of Judea. Herod undertook many colossal building projects, most famously his reconstruction of the Temple in Jerusalem (c. 19 BC). Many of his structures were built upon comparable, previous Hasmonean buildings and most of his have, in their turn, vanished as well.\n\nHerod introduced numerous architectural innovations and construction techniques in his buildings, such as the domes inside the Double Gate to the Temple Mount. He adapted the \"mikveh\" — a Jewish ritual bath — for use as the frigidarium in the Roman-style bathhouses in his many palaces. Herod also developed an innovative combination of palace and fortress; examples include the Antonia Fortress in Jerusalem, the Herodium in the Judean Desert about 2 miles south of Bethlehem, and Masada. Characteristically, they have (or had) one tower higher and stronger than the others. Herod’s fortification innovations strongly influenced the military architecture of subsequent generations.\n\nIn line with contemporary Jewish customs, Herod generally avoided the representation of human and animal figures, even in the closed and private parts of his palaces.\n\nIn the eighteenth year of his reign (20–19 BC), Herod rebuilt the Second Temple in Jerusalem on \"a more magnificent scale\". The new Temple was finished in a year and a half, although work on out-buildings and courts continued another eighty years. To comply with religious law, Herod employed a thousand priests as masons and carpenters for the rebuilding. The finished temple, which was destroyed by the Romans in 70 AD, is often referred to as Herod's Temple. The Wailing Wall (Western Wall) in Jerusalem was for many years the only section visible of the four retaining walls whose construction was begun by Herod to create a flat platform (the Temple Mount) upon which his Temple was constructed. Recent findings suggest that the Temple Mount walls and Robinson's Arch may not have been completed until at least 20 years after his death during the reign of Herod Agrippa II.\n\nHerod constructed several lavish palace-fortresses within his kingdom, most notably at Jerusalem, Herodium, Masada, and Caesarea Maritima.\nHerod’s massive building projects featured a distinctive style of stone-dressing. This stone-dressing method — usually featuring the pale local \"meleke\" limestone — was so prominently practiced in Herod's day that it has led to such terms as “Herodian blocks”, “Herodian masonry”, “Herodian dressing”, and the like. It makes Herodian stones easily discernible from the earlier stone courses below, and later ones above, in the surviving walls at many sites. Best known is the example of the impressive retaining walls of the Temple Mount, readily visible at the Western Wall.\n\nEnormous quantities of stone were needed for these structures and the remains of the numerous quarries used can still be found, especially in the vicinity of Jerusalem’s Old City, notably those to the north known as Solomon's Quarries. Freeing the stones from the bedrock was an elaborate process: Wide grooves were chiseled with metal tools around the intended stone block. The block was then freed up by driving metal wedges into the grooves. The initial dressing of the stone was probably accomplished on site before transport. Many of these stones were very large, weighing between two and five tons. (The largest found, in the Western Wall Tunnel, measures some 12.8 meters in length, 3.4 meters high and 4.3 meters deep; it weighs about 660 tons.) Once moved to the building site, further fine chiseling was done and the blocks were hauled into place using ramps, cranes and crow bars. The stones were laid in dry courses, typically about 1 meter high without the use of any mortar. Each course was set 3 to 5 cm back from the course underneath it. Final dressing and refinements were carried out once the stones had been set in place.\n\nThe huge rectangular building blocks, laid in horizontal courses, feature flat, projecting central portions (bosses) surrounded by narrow, shallow dressed margins (“marginal drafts”) creating a finely chiseled, frame-like effect. The depressed “frame” is sunk some 2 centimeters below the smooth face of the stone and its average width is about 8 centimeters. A wide, toothed chisel was used to smooth the stone margins.\n\nThe origins of this margin-cutting style predate Herod, as witnessed by the Hellenistic architecture of Alexandria, Asia Minor, and Greece itself, as well as by examples in the Levant (e.g., the palace of the Sons of Tuvia at Iraq, el-Amir in Jordan (near Amman), dating from at least the 3rd century BC). Examples of pre-Herodian margin stone-cutting are also attested in Jerusalem itself: at the “Tower of David” (the Paza’el Tower), in the \"First city wall\" and in the Hasmonean Tower unearthed in the Jewish Quarter. Authentic “Herodian masonry” includes examples at the sites at Hebron (Elonei Mamre, the Cave of Machpelah), in the Augusteum in Sebastia and possibly also in the Herodian platform at Caesarea Maritima. In Jerusalem, in addition to the Temple Mount, Herodian stones are preserved beneath the Damascus Gate. It has been observed that this distinctive stone-dressing style serves as a decorative theme on Second Temple period ossuaries found in the Jerusalem area.\n\n\n\n\n"}
{"id": "7676521", "url": "https://en.wikipedia.org/wiki?curid=7676521", "title": "Hiking equipment", "text": "Hiking equipment\n\nHiking equipment is the equipment taken on outdoor walking trips. Hiking is usually divided into day-hikes and multiple-day hikes, called backpacking, trekking, and walking tours.\n\nThe equipment selected varies according to the duration, distance, planned activities, and the environment. Additional factors include weight and preparedness for unplanned events. The level of preparedness can relate to remoteness and potential hazards; for example, a short day hike across farmland or trekking in the Himalayas. The length and duration of a walk can influence the amount of weight carried.\n\nThe nature of a hike is both by the natural environment and the applicable government regulations and hikers plan accordingly when considering equipment. To minimize the impact on the natural environment, many hikers follow the principles of \"Leave No Trace\".\n\nAccording to Tom Brown, the basic plan for survival is in the order of shelter (including clothing), water, fire, and food. Cody Lundin writes about the \"Rule of 3s\"; this relates to human survival without basics: three minutes without air, three hours without shelter, three days without water, or three weeks without food.\n\nHikers may take with them equipment ranging from a stout knife to ultralight backpacking (10–25 pounds), to the heaviest, most durable gear a hiker can carry. Checklists help to minimize the chance of forgetting something important.\nConsiderations for choice of hiking equipment may include:\n\n\nA pack's capacity to carry items is determined by:\n\nCommonly-used carrying methods include:\n\nSome hikers divide their backpack into sections associated with specific needs, i.e. kitchen, bedroom, bathroom, etc., or by clothes, shelter, water, fire, and food. Military and law-enforcement personnel use a variety of modular and attachment systems, like duty belts, tactical vests, All-purpose Lightweight Individual Carrying Equipment, MOLLE, Improved Load Bearing Equipment, FILBE, and PLCE. Military surplus outlets are optional sources for backpacking equipment.\n\nConstruction quality may be determined by design, manufacturer reputation, advertised purpose, and field testing. Customer reviews are often posted online. Heavy pack fabrics are made from 800–1000 denier nylon material.\n\nA large, heavy pack of weighs , and of water weighs . The best-made packs may carry up to twice their weight in water; less well-made packs may only carry half their weight in water. The British army bergen backpack, which has a capacity of carrying up to is made from 1000 denier nylon. Backpacks carrying more than usually have waist-belts to help with posture by transferring the weight to the hips. Some experts recommend keeping the equipment's total weight to less than 25% of the hiker's weight.\n\nApparel, including clothing, shoes, hats, etc., provides insulation from heat, cold, water or fire. It shades the body and protects it from injury from thorns and insect bites.\n\nBasic outdoor clothing materials are goose down, wool, polyester, and polyolefin, which provide similar degrees of insulation when dry. Wool and polyesters perform reasonably well for most weather conditions and provide some insulation while wet. Cotton/linen wicks moisture, good for hot/humid weather. Cotton, linen and down lose insulation when wet unless they are treated to be water-resistant.\n\nNatural fabrics, such as cotton, linen and wool have higher burn temperatures, and they char instead of melting when exposed to flame. When a fabric melts onto skin it is difficult to remove, unlike a material that chars. Nomex is used for fire-resistant clothing. Wool is a good all-around fabric. Cotton and linen are best for hot weather and worst for cold, wet weather. Synthetics can be about the same as wool in the winter; many of them are fire hazards. Fabrics can be treated to help reduce their disadvantages.\n\nDown is the lightest thermal-insulating material and compresses the most. Synthetics are next best. Wool is heavier than down and synthetics, and does not compress well. Stuff sacks and compression sacks are used for carrying insulated clothing and sleeping bags. Layered clothing allows for fine tuning of body temperature. The inner-base layer should wick away moisture. The mid-layer is used for the appropriate insulation, and the outer-shell layer provides wind and rain protection.\nFor long trips, having enough clothes to change into is helpful, while washing or drying others. An extra pair of socks can be used as mittens. Shorts for swimming and fording streams are also useful. Wet clothes do not insulate as well and can freeze while a hiker is wearing them. If a hiker falls into ice water, an immediate dry change of clothes from a dry bag can be lifesaving. Layered clothing helps regulate body temperature in varying weather conditions.\n\nGloves provide protection from blisters, abrasions, cold and hot objects, and insects. General purpose gloves are a thin glove-liners—wool may be preferred around campfires—combined with a pair of leather gloves. Glove liners often provide enough dexterity while not fully exposing the hands to freezing conditions. Shoes with traction reduce the chance of slipping, causing an injury or death. Shoes that support the ankle may also prevent injury. Well-constructed, breathable, waterproof hiking boots are general-purpose hiking shoes. Mountaineering boots provide more specialized protection. Trainers, sandles, or moccasins are useful for easy walks and may be taken on extended hikes as backup, and to wear when fording streams and in the evening around camp. Waterproof gaiters are used in cold or wet conditions to protect the lower pants and upper part of the shoes, and reduce the amount of water, snow, and debris from entering boots and soaking into other fabrics. Brush chaps or pants for thick brush or thorns, and snake chaps or gaiters help protect the legs from snake bites.\n\n\nHigh-altitude hikers encounter freezing conditions, even in summer, and there are also permanent glaciers and snowfields.\n\n\nAn overnight shelter may be as simple as a wool blanket and tarp, or a complete sleep-system inside a double-walled, four-season tent. Sleeping layers may be layered the same way as clothing layers: inner, mid, and outer shell. Bedding options range from a pillow made from clothes to a sleep system comprising sleeping pad, sleeping bag, bivouac shelter, bag liner, and compression sack. Shelter structures can be constructed from a tarpaulin, ground sheet, rope, poles, or trees, with a mosquito net. Rain poncho may be used as a ground sheet, or used as an overhead tarp, or rigged as a hammock. Tent hammocks comes with a bug net and overhead tarp. A cave, bivouac shelter, or debris shelter can also be used. Jungle shelters are used in jungles and tropical rainforest, where rainfall, mud, invertebrates, and snakes are common. A Venezuelan or jungle hammock is well ventilated, with a bug net and a covering tarpaulin. A platform can be built off the ground or tied into a tree. Trekking poles can be used to construct a shelter; they can be used as poles for a tarpaulin. Some tents are designed to use trekking poles in place of carrying additional poles, a technique common in ultralight backpacking.\n\nThe line can blur or shift between clothing, bedding, and structural shelter. A rain-poncho and its thermal liner (or a regular poncho) is an example of equipment that can be clothing, bedding, and structural shelter. Ultralight backpackers use typical cold-weather clothes to extend the temperature ranges of their sleepingbags. Then this reasoning can extend to packing a winter coat and snow pants with a bivy bag before adding a two-pound sleeping bag. Adding an insulated pair of socks or down booties would complete the insulation layer.\n\nGiven an unexpected turn toward cold weather, bedding can be converted to mobile insulation, but if the pack already contains those items, then time and energy are saved.\n\nThe most basic hiking equipment is a stout knife, a pot, cordage, a few ways to make a fire, and equipment to carry water and other gear.\n\nWater needs to be drinkable. Hikers usually carry some, but do not carry all that they need, because it weighs one kilogram (2.2 lbs) per liter, and hikers can consume 2-4+ liters per day (4–9 lbs). Additional water usually can be located, collected, filtered, and purified. All water in the wild is potentially unclean.\n\nThe details of locating water are beyond the scope of this article. The basics are using a map, knowing how water flows through and collects in certain geographical formations (natural cisterns), and identifying which plants indicate shallow-underground water and contain easily accessed water. Heading downhill to streams, and looking for rich, green vegetation that may indicate a spring, are ways to start. Following bees and tracking animals to cisterns, knowing where to dig in apparent dry stream beds, and possibly waiting for night when vegetation releases water, are slightly more advanced techniques. Water can be collected in a clean container. Clear plastic bags can be used to make vegetation and solar stills. Dehydrated, chemical-free sponges can be used to wipe dew from vegetation, or tied to ankles before one walks through damp vegetation in the morning, soaking up water from wet rocks or sand. A flexible drinking straw can access water in a rock crack, or drink from a water still without opening it. Tarpaulins can also be used to collect rain water or dew.\n\nTo remove larger impurities, water can be filtered through grass, sand, charcoal or cloth, such as a bandana or pantyhose. Pantyhose can also be used as an emergency fishing net. Filtering water of larger impurities is a useful way to extend the life of commercial filters, preventing them from getting clogged quickly.\n\nWater must be purified of harmful living organisms and chemicals. Some commercial filters can remove most organisms and some harmful chemicals, but they are not 100% effective. Distillation filters, purifies, and removes some harmful chemicals. Chemicals with a lower or about equal boiling point of water are not eliminated by distilling. Iodine or chlorine dioxide solutions or tablets can be used to purify water. It can be boil water in a fire-resistant pot or water bottle. Water can be boiled in some flammable materials like bark because the water absorbs the heat. Pasteurization takes place at temperatures lower than boiling point, but knowing the temperature of the water and calculating the duration of treatment can be difficult. This technique is useful when only non-durable containers are available. Sunlight can be used with a clear container. Filters made from heat-treated diatomaceous earth can also be used.\n\nA wide-mouth, metal water bottle or a metal pot or cup can also be used to boil and transport water, and can be used fairly easily for cooking. A lid for the pot will help water to boil sooner, helps with cooking by requiring less fuel, and reduces water loss. Other containers for transporting water include appropriate plastic water bottles in materials like Nalgene. There are hard plastic bottles, and soft-collapsible bottles. A hydration pack tube freezes easily. A non-lubricated condom can hold up to two liters, but is very vulnerable to puncture. Placing a stick in the knot will allow it to be re-used. Breast milk bags are plastic bags that double-Ziploc, so they are easier to reseal than a condom and they do not puncture as easily. They are transparent, allowing solar purification and can be used as a magnifying lens to start a fire. Containers that may freeze with water in them may allow for 10% expansion; they may be filled to 90%. Oral rehydration therapy packets can be added to water to help replace electrolytes.\n\nFire needs ignition, oxygen, and fuel, and the ability to be extinguish. Ignition can come from a spark, a chemical reaction, electricity, or concentrated solar energy. The more oxygen involved, the easier the fire starts and the hotter it burns. Organic material must either be dry or the fire must be hot enough to dry it and burn it. Fraying organic material is more combustible as a tinder. Grain dust and granulated sugar can ignite when oxygenated over a flame.\n\nSources of ignition include flint, carbon steel, firesteel and a sharp edge, matches, butane and Zippo, and peanut lighters, and magnifying glasses.\nFuels include natural substances like dry wood, peat and coal. pitch, petroleum jelly, charred cotton, shaved rubber, and frayed synthetic cloth can be used as kindling. Candles provide illumination and can help start a fire. Alcohol, DIY and commercial alcohol stoves are made and carried by hikers. Oil, petroleum, vegetable, and tallow can help start and feed a fire. Propane bottles are made for backpacking. Charcoal or briquettes could be packed in the fire.\n\nSure fire is a way to start a fire in bad conditions or when a hiker has no man-made equipment, like when the fuel is wet, or the lighter has run out of fuel. Some hikers will carry tinder in a few forms, such as a few cotton balls soaked in pure petroleum jelly, fat wood (pitch). Alcohol-wipes and alcohol-hand-sanitizers are other options. Vegetable oils, and some fruit oils, like olive oil, coconut oil, corn chips, or nuts are edible and can be used to help start a fire because of the oil in them. \"Bad\" conditions also includes high altitude because of less oxygen, high winds blowing out a fire, high humidity that soaks either the fuel source or the igniter.\n\nTo extinguish a campfire, see extinguishing a campfire. Knowing ways to survive a wildfire may also be helpful.\n\nCordage provides the abilities to bind, build, repair, and prevent damage. It comes in many sizes and materials, and can be used for building shelters and traps, flossing teeth, fishing, repairing and making clothes, replacing shoelaces, gluing or taping things together. Many cordages are made from natural materials. Some types of cordage are:\n\nThere are a variety of containers for organizing and keeping equipment dry:\n\nMilitary ready meals provide a wide range of food options for hikers; they tend to be higher in fat and salt than is appropriate for sedentary people. The meals are not dehydrated, and are not intended for more than a few days of hiking. Most of them are not designed to minimize the space they take in a pack.\n\nIn addition to a food's expiration date, the main considerations for hiking food are water content, caloric density (more energy per pound for a given space), and nutritional density (more nutrition per pound for a given space). Water weighs one gram per cubic centimeter, or 8.33 pounds per gallon, so a 4-liter (1 gallon) food container can weigh up to eight pounds less when it contains dehydrated food. Dehydrating foods can reduce weight and may reduce nutrition while increasing the need for water to reconstitute the food. More weight also expends more energy, so packing lighter foods reduces the need for more calories. Calories equate to energy. Nutrition becomes more important as the number of hiking days increases; for example MREs are not intended to be used beyond ten days. Multi-vitamins may help offset some nutrition deficiencies.\n\nThe three macronutrients are fats (lipids), carbohydrates (sugars and starches), and protein. Fats are calorie dense and nutritionally important, nuts are a good example. Carbohydrates (starches and sugars) that release energy slowly (as measure by glycemic index and glycemic load or the insulin index) give sustained energy, such as legumes and whole grains. Some sources of protein are meats, dairy products, fish, eggs, whole grains, pulses, legumes, and nuts. These are the reasons that \"trail\" mix usually has dried fruit and a variety of nuts. Nuts and dried fruit can last a long time based on their expiration date. The USDA's page on expiration dates is available online.\n\nNot all food needs to be dehydrated or dried. When a hiker plans to carry a couple liters of water, that is 4.4 pounds of water weight that can be carried in fresh fruits and vegetables for the first day. The same is true for other foods based on their water-weight. Depending on which ones are chosen, this can eliminate or reduce the need for cooking, and the reconstitution time. One of the first meals on a hike could be a Greek salad with a fruit cocktail, followed later with refried beans and tortillas. Nut-butter and honey sandwiches on flatbread can last longer depending on the preservatives in the bread and nut-butter. The same is true for canned goods, most of the weight is in the water. Selecting a canned food is the same: calorie and nutritional dense. Using this can put a hiker down the trail a day or two with little difference in the foods normally eaten.\n\nTaking foods that do not require cooking provides for higher mobility (not stopping to cook), and allows for the contingencies of not having a fire, the cook stove breaking, or running out of fuel. In general, the foods in a grocery store that are not in the refrigerated-freezer sections, are available for the trail.\n\nNo-bake home-made \"energy\" protein bars may contain oatmeal, ground flaxseed, arrowroot powder (medicinal uses), peanut butter, powdered nuts, chopped nuts, coconut oil (multi-use), coconut flakes, dried fruit, cinnamon (medicinal), cooked beans, and natural sweeteners, like honey; they may also be baked. Baked versions may contain natural sweeteners like bananas, applesauce, grated carrots and zucchini. Either way, they and the no-bake ingredients may be used for the trail.\n\nFlavor enhancers: salt, salt substitute, powdered peppers, spices, dried herbs, powdered bullion or cubes, hot sauce.\n\nIf food supplies run out, a field guide to edible, medicinal, and poisonous plants may be useful. Or a hiker could study them ahead of time. As the movie \"Into the Wild\" brought out, some poisonous plants look like edible plants. He had a field guide with him but did not notice the details well enough.\n\nVegan note: The equipment in this article comes from hoping for the best and preparing for the worst, balanced with how much a hiker wants to carry and is willing to risk. Within that context, if the worse scenario happens and starvation is imminent, then it may be too late to choose and learn and be able to fish and trap. As neutrally stated, the decision becomes an informed choice.\n\nIf hikers plan their food carefully, they may wind up eating more healthily on the trail.\n\nWater and food can be cooled in snow. Evaporation causes cooling and is used in the pot-in-pot refrigerator. Placing green grass or a sponge into a hat and soaking it with water is another technique. Bottled water can be cooled in a stream.\n\nUltralight backpackers rely only on food that does not need cooking, and reconstitute dehydrated, pre-cooked food without cooking it. A hot drink or meal may help someone with a lower body temperature or help boost morale. In an emergency, most locations would supply material for a fire, as long as there was a container that could withstand the heat. Some options and tradeoffs for choosing equipment.\n\nCooking options\nCooking options may range from a candle to a bonfire, and may include a solar oven, or a Fresnel lens, or more typical tools and other options:\n\nCommon utensils: knife, fork, spoon, and spork. A butter knife may not be an optimal weight item considering that other knives may be available, or at least it may be sharpened. Utensils may be carved from wood. A fork spears food, so can a sharp stick or a knife. Sporks trade off the volume of the spoon with the ability to spear food. A mid-sized, sturdy metal spoon may be used for cooking, eating, and digging. Even if not cooking, utensils can be useful as tools.\n\nEquipment not already in the kitchen.\n\nHandheld-waterproof electronics (or stored in waterproof bags) with spare batteries for critical gear. Some devices come with different power options: solar, hand-crank, and/or USB. And then there are portable solar-charging systems. Depending on electronics to work in life-and-death situations means that the hiker's life is at risk when the equipment fails.\n\n\nChecklists may be compiled from multiple sources, and then tailored to fit a hiker's preferences, and adjusted for specific hikes.\n\nThe possible hazards of hiking may affect equipment choices and decisions about which skills are important to learn. A hiker can consider the \"Rule of 3s\". Hazards enountered by hikers include:\n\n"}
{"id": "21945671", "url": "https://en.wikipedia.org/wiki?curid=21945671", "title": "Home audio", "text": "Home audio\n\nHome audio systems are audio electronics intended for home entertainment use, such as shelf stereos and surround sound receivers. Home audio generally does not include standard equipment such as built-in television speakers, but rather accessory equipment, which may be intended to enhance or replace standard equipment, such as standard TV speakers. Since surround sound receivers, which are primarily intended to enhance the reproduction of a movie, are the most popular home audio device, the primary field of home audio is home cinema.\n\nHome audio dates back before electricity, to Edison's phonograph, a monaural, low fidelity sound reproduction format. Early electrical phonographs as well as many other audio formats started out as monaural formats.\n\nStereophonic sound was invented as a means of creating a sound stage, a more realistic reproduction of the sound as recorded live. Stereo sound usually refers to two-channel audio, but technically it refers to anything better than monaural audio, as the term literally means \"solid sound.\"\n\nQuadraphonic sound was a four-channel reproduction system, which is considered to be the origin of surround sound. It was recorded on phonograph, tape, and a few CDs, and required a quadraphonic player for playback. The format was released in 1970 and never gained much popularity.\n\nSurround sound formats were used in movie theatres dating back to Disney's Fantasia, and became available to consumers in the late 80's. There are many formats of surround sound, differing based on the type of decoding processor they used. Dolby Pro Logic is one of the oldest processors, creating four channels, and Dolby Pro Logic IIx is one of the newest, creating seven or eight discrete channels. Competing technologies have complicated the purchasing decisions of consumers.\n\nHiFi equipment was available to consumers followed by boomboxes becoming popular in the 1980s due to availability of cheaper batteries.\n\n\n"}
{"id": "23134281", "url": "https://en.wikipedia.org/wiki?curid=23134281", "title": "Hurricane Electric", "text": "Hurricane Electric\n\nHurricane Electric is a global Internet service provider offering IPv4 and IPv6 services, as well as data centers in San Jose, California and in Fremont, California, where the company is based.\n\nHurricane Electric operates the largest Internet Protocol version 4 (IPv4) and Internet Protocol version 6 (IPv6) transit networks globally, as measured by the count of interconnections to other networks (\"peering\"). The majority of these adjacencies are native IPv6 BGP sessions. This may be determined with Hurricane Electric's BGP looking glass at http://lg.he.net.\n\nHurricane Electric offers an IPv6 tunnel broker service, providing free connectivity to the IPv6 Internet via 6-in-4 IPv6 transition mechanisms. The company also provides an IPv6 certification program to further education and compliance in IPv6 technology. According to Hurricane Electric's statistics, as of May 7, 2018, the company provided 97,067 tunnels spanning 197 countries via the IPv6 tunnel broker and 15,382 individuals in 155 countries have reached the highest level of the IPv6 certification.\n\nWithin its global network, Hurricane Electric is connected to more than 200 major exchange points and exchanges IP traffic directly with more than 8,000 different networks.\n\nAccording to European Internet Exchange Association (Euro-IX), Hurricane Electric ranks first in the world for the number of connections to Internet exchange points, with presence at more than 100 of Euro-IX member IXPs.\n\n"}
{"id": "21522001", "url": "https://en.wikipedia.org/wiki?curid=21522001", "title": "Hydromill trench cutter", "text": "Hydromill trench cutter\n\nThe hydromill trench cutter is a type of construction equipment designed to dig the narrow but deep trenches used in the casting of slurry walls. Typically, it is a cutter attachment mounted on a crawler crane base machine, with different types of hose handling systems. The machine excavates by cutting the soil using two cutting wheels, while a powerful pump extracts the loose material mixed with some of the slurry, typically bentonite.\n\nThe hydromill, also known as hydraulic cutter, basically consists of:\n\nUsually, there are two sets of hoses, one for hydraulic oil, and another for extraction of slurry from the diaphragm wall.\n\nHydraulic cutter assemblies have a standard length of , with various widths, varying from up to . Cutting wheel teeth depend mainly on the type of soil intended to be excavated.\n\n"}
{"id": "48328508", "url": "https://en.wikipedia.org/wiki?curid=48328508", "title": "Insteon (company)", "text": "Insteon (company)\n\nInsteon is an Irvine, CA-based developer of home automation (aka domotics) hardware and software. The technology, also called Insteon, allows light switches, lights, thermostats, motion sensors, and other electrical devices to interoperate through power lines, radio frequency (RF) communications, or both. The company produces over 200 products featuring the technology.\nInsteon is a subsidiary of Smartlabs, Inc., also based in Irvine, CA.\n\nInsteon was founded in 2005 in Irvine, CA by CEO Joe Dada. Dada had previously founded Smarthome in 1992, a home automation product catalog company, and operator of the Smarthome.com e-commerce site. In the late 1990s, Dada acquired two product engineering firms which undertook extensive product development efforts to create networking technology based on both power-line and RF communications. In 2004, the company filed for patent protection for the resultant technology, called Insteon, and it was released in 2005. In 2012, the company released the first network-controlled light bulb using Insteon-enabled technology, and at that point Dada spun Insteon off from Smarthome.\n\nInsteon technology uses a dual-mesh networking topology in which all devices are peers and each device independently transmits, receives, and repeats messages.\n\nInsteon produces over 200 products using its technology, including LED bulbs, wall switches, wall keypads, sensors, thermostats, plug in modules and embedded devices, along with central controllers for system management.\n\nInsteon markets two different central controllers: its own brand, called the Insteon Hub, and a newer HomeKit-enabled Insteon Hub Pro designed for Apple HomeKit compatibility. In 2012, the company introduced the first network-controlled LED light bulb.\n\n"}
{"id": "40333038", "url": "https://en.wikipedia.org/wiki?curid=40333038", "title": "Jigar Shah", "text": "Jigar Shah\n\nJigar Shah (born August 30, 1974) is a clean energy entrepreneur in creating market-driven solutions and eliminating market barriers to address climate change. Shah has recognized this as \"Creating Climate Wealth.\"\n\nShah maintains that Climate Wealth is created when mainstream investors team up with entrepreneurs, corporations, mainstream capital, and governments at scale to solve the big problems of our time while generating compelling financial returns – not concessionary returns.\n\nShah is the co-founder and President of Generate Capital. Shah was the founder and CEO of SunEdison (NASDAQ: SUNE), where he pioneered “no money down solar” and unlocked a multi-billion-dollar solar market, creating the largest solar services company worldwide. Shah is author of \"Creating Climate Wealth: Unlocking the Impact Economy, 2013 Icosa Publishing\". The book talks about the prominent role of business model innovation, more than new technology, in attracting mainstream capital and unlocking transformational change. In the book, the author pictures reaching our 2020 climate change goals as means to create the next economy with the equivalent of 100,000 companies worldwide, each generating $100 million in sales. Shah argues that, while new technical innovation is valuable, deployment of existing technologies are the key to reaching our near-term climate targets.\n\nShah serves as a board member of the \"Carbon War Room\", a global organization he previously served as CEO.\n\nShah has also become an outspoken advocate to end all energy subsidies, including those for renewable energy, to \"create a level playing field.\" \n\nIn 2013, Jigar served as a mentor for Unreasonable at Sea, a technology business accelerator for social entrepreneurs seeking to scale their ventures in international markets. Founded by Unreasonable Group, Semester at Sea, and Stanford's Hasso Plattner Institute of Design. Shah writes for Unreasonable Group's venture UNREASONABLE.is, a hub for social entrepreneurs.\n\nShah is currently co-host of The Energy Gang, a podcast dedicated to exploring the technological, political and market forces driving energy and environmental issues. On a recent episode, Shah introduced the Jigar Shah Rule - \"Countries should not have stupid policy\". As noted by co-host Stephen Lacy, the new ruling is pulled directly from the Jigar Shah Playbook, which suggests you must have competitive options such as volumetric reductions and feed-in tariffs, and the way these were designed seven to eight years ago do not work.\n\nFrom 2009 to March 2012, Shah served as the first CEO of the Carbon War Room, the global organization founded by Richard Branson and Virgin United that works to harness the power of entrepreneurship to deploy solution technologies at scale.\n\nPrior to his tenure as Carbon War Room CEO, Shah founded SunEdison in 2003. The company simplified solar as a service through the implementation of the power purchase agreement (PPA) business model. That model changed the status quo, allowing organizations to purchase solar energy services under long-term predictably priced contracts and avoid the significant capital costs of ownership and operation of solar energy systems. The SunEdison business model is a recognized catalyst that helped turn solar PV into a multi-billion dollar industry worldwide.\n\nShah previously worked in strategy for BP Solar and as a contractor for the Department of Energy on alternative vehicles and fuel cell programs.\n\nBorn in India, Shah moved to the United States with his family when he was one year old. Shah moved to Sterling, Illinois when he was eight years old.\n\nShah holds a B.S. in Mechanical Engineering from the University of Illinois, Champaign-Urbana, and an MBA from the University of Maryland.\n\n"}
{"id": "49994399", "url": "https://en.wikipedia.org/wiki?curid=49994399", "title": "Letitia Chitty", "text": "Letitia Chitty\n\nLetitia Chitty (15 July 1897 – 29 September 1982) was an English engineer who became a respected structural analytical engineer, achieving several firsts for women engineers, including becoming the first female fellow of the Royal Aeronautical Society and the first female recipient of the Telford Medal.\n\nChitty was spotted as a talented mathematician in her teens. During World War I, when still a maths student, Chitty was recruited as a teenager to do war work with Alfred Pippard at the Admiralty Air Department. She subsequently changed subjects, studied engineering, and graduated from Newnham College Cambridge with first class honours in the Mechanical Sciences Tripos, 1921, the first woman to do so.\n\nHer early career focused on analysing the stresses of airframes, airships and civil engineering structures, initially with the Admiralty Air Department and then, after graduating, at the Air Ministry with Richard Southwell and Alfred Pippard.\n\nW. G. Tarrant, previously a timber merchant, designed a massive bomber at the end of World War I, the Tarrant Tabor. The original biplane design had to be altered to triplane to accommodate more engines, and the Admiralty Air Department was asked to check its structural strength. Chitty was given this task.\n\nIn her own words:\n\n\"Mr. Tarrant was an inspired timber merchant who dreamed of a super-Camel. It hadn't a chance. It was too big, too heavy - that wasn't its fault, but Grade A spruce had by now run out and it had to be built of American white wood (tulip). In my language, 3,500 instead of 5,500 lb/sq in.\"\n\nTragically, her mathematical analysis was not heeded. The plane crashed nose down during its first take-off, from the Royal Aircraft Establishment at Farnborough on 26 May 1919, killing both pilots and seriously injuring the other six people on board.\n\nChitty moved to Imperial College in 1934 where she remained for the rest of her career, initially specialising in structural stresses in aircraft. During the 1930s, she was part of a group which analysed the crash of the airship R58, and published various Air Ministry papers on stresses and strains on airship structures. She was an early member of the Women's Engineering Society.\n\nHer World War II work included research into stresses in submarine hulls under shell attack, extensible cables and pulley blocks for barrage balloons, for the Director of Scientific Research of the Admiralty and the Ministry of Supply. Later research interests included arches and arch dams - in particular, the Dukan Dam in Iraq - and she contributed to an international symposium on arched dams in 1968.\n\nInitially an Imperial College research assistant, Chitty became a lecturer in 1937, and retired in 1962. She was the first female Fellow of the Royal Aeronautical Society (FRAeS), the third female Corporate Member of the Institution of Civil Engineers and the first woman to be appointed to an ICE technical committee, in 1958. She was awarded four Telford Premium medals for papers written with Pippard, and in 1969 became the first woman to receive the Telford Gold Medal.\n\nShe travelled widely and published a book, \"Abroad. An alphabet of Flowers\", in 1948, with her own drawings and notes about her holidays.\n\nIn her will, she left a bequest to Imperial College, which named its Library reading room after her. Imperial College also presents a Letitia Chitty Centenary Memorial Prize, while Newnham College has presented a 'Letitia Chitty Award for Engineering'.\n\n"}
{"id": "41958", "url": "https://en.wikipedia.org/wiki?curid=41958", "title": "Lidar", "text": "Lidar\n\nLidar (also called LIDAR, LiDAR, and LADAR) is a surveying method that measures distance to a target by illuminating the target with pulsed laser light and measuring the reflected pulses with a sensor. Differences in laser return times and wavelengths can then be used to make digital 3-D representations of the target. The name \"lidar\", now used as an acronym of \"light detection and ranging\" (sometimes \"light imaging, detection, and ranging\"), was originally a portmanteau of \"light\" and \"radar\". Lidar sometimes is called 3D laser scanning, a special combination of a 3D scanning and laser scanning. It has terrestrial, airborne, and mobile applications.\n\nLidar is commonly used to make high-resolution maps, with applications in geodesy, geomatics, archaeology, geography, geology, geomorphology, seismology, forestry, atmospheric physics, laser guidance, airborne laser swath mapping (ALSM), and laser altimetry. The technology is also used in control and navigation for some autonomous cars.\nLidar originated in the early 1960s, shortly after the invention of the laser, and combined laser-focused imaging with the ability to calculate distances by measuring the time for a signal to return using appropriate sensors and data acquisition electronics. Its first applications came in meteorology, where the National Center for Atmospheric Research used it to measure clouds. The general public became aware of the accuracy and usefulness of lidar systems in 1971 during the Apollo 15 mission, when astronauts used a laser altimeter to map the surface of the moon.\n\nAlthough now most sources treat the word \"lidar\" as an acronym, the term originated as a portmanteau of \"light\" and \"radar\". The first published mention of lidar, in 1963, makes this clear: \"Eventually the laser may provide an extremely sensitive detector of particular wavelengths from distant objects. Meanwhile, it is being used to study the moon by 'lidar' (light radar) ...\" The \"Oxford English Dictionary\" supports this etymology.\n\nThe interpretation of \"lidar\" as an acronym (\"LIDAR\" or \"LiDAR\") came later, beginning in 1970, based on the assumption that since the base term \"radar\" originally started as an acronym for \"Radio Detection And Ranging\", \"LIDAR\" must stand for \"Light Detection And Ranging\", or for \"Laser Imaging, Detection And Ranging\". Although the English language no longer treats \"radar\" as an acronym and printed texts universally present the word uncapitalized, the word \"lidar\" became capitalized as \"LIDAR\" or \"LiDAR\" in some publications beginning in the 1980s. Currently no consensus exists on capitalization, reflecting uncertainty about whether or not \"lidar\" is an acronym, and if it is an acronym, whether it should appear in lower case, like \"radar\". Various publications refer to lidar as \"LIDAR\", \"LiDAR\", \"LIDaR\", or \"Lidar\". The USGS uses both \"LIDAR\" and \"lidar\", sometimes in the same document; the \"New York Times\" predominantly uses \"lidar\" for staff written articles, although contributing news feeds such as Reuters may use Lidar;\n\nLidar uses ultraviolet, visible, or near infrared light to image objects. It can target a wide range of materials, including non-metallic objects, rocks, rain, chemical compounds, aerosols, clouds and even single molecules. A narrow laser beam can map physical features with very high resolutions; for example, an aircraft can map terrain at resolution or better.\n\nThe essential concept of Lidar was originated by EH Synge in 1930, who envisaged the use of powerful searchlights to probe the atmosphere. Indeed, Lidar has since been used extensively for atmospheric research and meteorology. Lidar instruments fitted to aircraft and satellites carry out surveying and mapping – a recent example being the U.S. Geological Survey Experimental Advanced Airborne Research Lidar. NASA has identified lidar as a key technology for enabling autonomous precision safe landing of future robotic and crewed lunar-landing vehicles.\n\nWavelengths vary to suit the target: from about 10 micrometers to the UV (approximately 250 nm). Typically light is reflected via backscattering, as opposed to pure reflection one might find with a mirror. Different types of scattering are used for different lidar applications: most commonly Rayleigh scattering, Mie scattering, Raman scattering, and fluorescence. Suitable combinations of wavelengths can allow for remote mapping of atmospheric contents by identifying wavelength-dependent changes in the intensity of the returned signal.\n\nThe two kinds of lidar detection schemes are \"incoherent\" or direct energy detection (which principally measures amplitude changes of the reflected light) and coherent detection (best for measuring Doppler shifts, or changes in phase of the reflected light). Coherent systems generally use optical heterodyne detection. This is more sensitive than direct detection and allows them to operate at a much lower power, but requires more complex transceivers.\n\nBoth types employ pulse models: either \"micropulse or\" \"high energy\". Micropulse systems utilize intermittent bursts of energy. They developed as a result of ever-increasing computer power, combined with advances in laser technology. They use considerably less energy in the laser, typically on the order of one microjoule, and are often \"eye-safe\", meaning they can be used without safety precautions. High-power systems are common in atmospheric research, where they are widely used for measuring atmospheric parameters: the height, layering and densities of clouds, cloud particle properties (extinction coefficient, backscatter coefficient, depolarization), temperature, pressure, wind, humidity, and trace gas concentration (ozone, methane, nitrous oxide, etc.).\n\nLidar systems consist of several major components.\n\n600–1000 nm lasers are most common for non-scientific applications. Maximum power is limited by the need to make them eye-safe (in applications that operate around people).\n\nOne common alternative, 1550 nm lasers, are eye-safe at relatively high power levels since this wavelength is not strongly absorbed by the eye, but the detector technology is less advanced and so these wavelengths are generally used at longer ranges with lower accuracies. They are also used for military applications because 1550 nm is not visible in night vision goggles, unlike the shorter 1000 nm infrared laser.\n\nAirborne topographic mapping lidars generally use 1064 nm diode pumped YAG lasers, while bathymetric (underwater depth research) systems generally use 532 nm frequency doubled diode pumped YAG lasers because 532 nm penetrates water with much less attenuation than does 1064 nm. Laser settings include the laser repetition rate (which controls the data collection speed). Pulse length is generally an attribute of the laser cavity length, the number of passes required through the gain material (YAG, YLF, etc.), and Q-switch (pulsing) speed. Better target resolution is achieved with shorter pulses, provided the lidar receiver detectors and electronics have sufficient bandwidth.\n\nSolid-state electronics by definition have no moving parts.\n\nFlash uses a single light source that illuminates the field of view in a single pulse.\n\nSeeing at a distance requires a powerful burst of light. The power is limited to levels that do not damage human retinas. Wavelengths must not affect human eyes. However, low cost silicon imagers do not read light in the eye-safe spectrum. Instead, gallium-arsenide imagers are required, which can boost costs to $200,000.\n\nA phased array can illuminate any direction by using a microscopic array of individual antennas. Controlling the timing (phase) of each antenna steers a cohesive signal in a specific direction.\n\nPhased arrays have been used in radar since the 1950s. The same technique can be used with light. On the order of a million optical antennas are used to see a radiation pattern of a certain size in a certain direction. The system is controlled by timing the precise flash. A single chip (or a few) replace a $75,000 electromechanical system, drastically reducing costs.\n\nThe control system can change the shape of the lens to enable zoom in/zoom out functions. Specific sub-zones can be targeted at sub-second intervals.\n\nElectromechanical lidar lasts for between 1,000 and 2,000 hours. By contrast, solid-state lidar can run for 100,000 hours.\n\nMicro electromechanical mirrors (MEMS) are not entirely solid-state. However, their tiny form factor provides many of the same cost benefits. A single laser is directed to a single mirror that can be reoriented to view any part of the target field. The mirror spins at a rapid rate. However, MEMS systems generally operate in a single plane (left to right). To add a second dimension generally requires a second mirror that moves up and down. Alternatively another laser can hit the same mirror from another angle. MEMS systems can be disrupted by shock/vibration and may require repeated calibration.\n\nImage development speed is affected by the speed at which they are scanned. Options to scan the azimuth and elevation include dual oscillating plane mirrors, a combination with a polygon mirror and a dual axis scanner. Optic choices affect the angular resolution and range that can be detected. A hole mirror or a beam splitter are options to collect a return signal.\n\nTwo main photodetector technologies are used in lidar: solid state photodetectors, such as silicon avalanche photodiodes, or photomultipliers. The sensitivity of the receiver is another parameter that has to be balanced in a lidar design.\n\nLidar sensors mounted on mobile platforms such as airplanes or satellites require instrumentation to determine the absolute position and orientation of the sensor. Such devices generally include a Global Positioning System receiver and an Inertial Measurement Unit (IMU).\n\nLidar uses active sensors that supply their own illumination source. The energy source hits objects and the reflected energy is detected and measured by sensors. Distance to the object is determined by recording the time between transmitted and backscattered pulses and by using the speed of light to calculate the distance traveled.\n\n3-D imaging can be achieved using both scanning and non-scanning systems. \"3-D gated viewing laser radar\" is a non-scanning laser ranging system that applies a pulsed laser and a fast gated camera. Research has begun for virtual beam steering using Digital Light Processing (DLP) technology.\n\nImaging lidar can also be performed using arrays of high speed detectors and modulation sensitive detector arrays typically built on single chips using complementary metal–oxide–semiconductor (CMOS) and hybrid CMOS/Charge-coupled device (CCD) fabrication techniques. In these devices each pixel performs some local processing such as demodulation or gating at high speed, downconverting the signals to video rate so that the array can be read like a camera. Using this technique many thousands of pixels / channels may be acquired simultaneously. High resolution 3-D lidar cameras use homodyne detection with an electronic CCD or CMOS shutter.<ref name=\"Medina A, Gayá F, and Pozo F 800–805 http://www.opticsinfobase.org/josaa/abstract.cfm?URI=josaa-23-4-800\"></ref>\n\nA coherent imaging lidar uses synthetic array heterodyne detection to enable a staring single element receiver to act as though it were an imaging array.\n\nIn 2014, Lincoln Laboratory announced a new imaging chip with more than 16,384 pixels, each able to image a single photon, enabling them to capture a wide area in a single image. An earlier generation of the technology with one fourth that number of pixels was dispatched by the U.S. military after the January 2010 Haiti earthquake; a single pass by a business jet at 3,000 meters (10,000 ft.) over Port-au-Prince was able to capture instantaneous snapshots of 600-meter squares of the city at a resolution of , displaying the precise height of rubble strewn in city streets. The Lincoln system is 10x faster. The chip uses indium gallium arsenide (InGaAs), which operates in the infrared spectrum at a relatively long wavelength that allows for higher power and longer ranges. In many applications, such as self-driving cars, the new system will lower costs by not requiring a mechanical component to aim the chip. InGaAs uses less hazardous wavelengths than conventional silicon detectors, which operate at visual wavelengths.\n\nLidar can be oriented to nadir, zenith, or laterally.\nFor example, lidar altimeters look down, an atmospheric lidar looks up, and lidar-based collision avoidance systems are side-looking.\n\nLidar applications can be divided into airborne and terrestrial types. The two types require scanners with varying specifications based on the data's purpose, the size of the area to be captured, the range of measurement desired, the cost of equipment, and more.\nSpaceborne platforms are also possible.\n\nAirborne lidar (also \"airborne laser scanning\") is when a laser scanner, while attached to an aircraft during flight, creates a 3-D point cloud model of the landscape. This is currently the most detailed and accurate method of creating digital elevation models, replacing photogrammetry. One major advantage in comparison with photogrammetry is the ability to filter out reflections from vegetation from the point cloud model to create a digital surface model which represents ground surfaces such as rivers, paths, cultural heritage sites, etc., which are concealed by trees. Within the category of airborne lidar, there is sometimes a distinction made between high-altitude and low-altitude applications, but the main difference is a reduction in both accuracy and point density of data acquired at higher altitudes. Airborne lidar can also be used to create bathymetric models in shallow water.\n\nThe main constituents of airborne lidar include digital elevation models (DEM) and digital surface models (DSM). The points and ground points are the vectors of discrete points while DEM and DSM are interpolated raster grids of discrete points. The process also involves capturing of digital aerial photographs. In order to interpret deep seated landslides for example, under the cover of vegetation, scarps, tension cracks or tipped trees air borne lidar is used. Air borne lidar digital elevation models can see through the canopy of forest cover, perform detailed measurements of scarps, erosion and tilting of electric poles.\n\nAirborne lidar data is processed using a toolbox called Toolbox for Lidar Data Filtering and Forest Studies (TIFFS) for lidar data filtering and terrain study software. The data is interpolated to digital terrain models using the software. The laser is directed at the region to be mapped and each point's height above the ground is calculated by subtracting the original z-coordinate from the corresponding digital terrain model elevation. Based on this height above the ground the non-vegetation data is obtained which may include objects such as buildings, electric power lines, flying birds, etc. The rest of the points are treated as vegetation and used for modeling and mapping. Within each of these plots, lidar metrics are calculated by calculating statistics such as mean, standard deviation, skewness, percentiles, quadratic mean, etc.\n\nThe airborne lidar bathymetric technological system involves the measurement of time of flight of a signal from a source to its return to the sensor. The data acquisition technique involves a sea floor mapping component and a ground truth component that includes video transects and sampling. It works using a green spectrum (532 nm) laser beam. Two beams are projected onto a fast rotating mirror, which creates an array of points. One of the beams penetrates the water and also detects the bottom surface of the water under favorable conditions.\n\nThe data obtained shows the full extent of the land surface exposed above the sea floor. This technique is extremely useful as it will play an important role in the major sea floor mapping program. The mapping yields onshore topography as well as under water elevations. Sea floor reflectance imaging is another solution product from this system which can benefit mapping of underwater habitats. This technique has been used for three dimensional image mapping of California's waters using a hydrographic lidar.\nDrones are now being used with laser scanners, as well as other remote sensors, as a more economical method to scan smaller areas. The possibility of drone remote sensing also eliminates any danger that crews of a manned aircraft may be subjected to in difficult terrain or remote areas.\n\nTerrestrial applications of lidar (also \"terrestrial laser scanning\") happen on the Earth's surface and can be either stationary or mobile. Stationary terrestrial scanning is most common as a survey method, for example in conventional topography, monitoring, cultural heritage documentation and forensics. The 3-D point clouds acquired from these types of scanners can be matched with digital images taken of the scanned area from the scanner's location to create realistic looking 3-D models in a relatively short time when compared to other technologies. Each point in the point cloud is given the colour of the pixel from the image taken located at the same angle as the laser beam that created the point.\n\nMobile lidar (also \"mobile laser scanning\") is when two or more scanners are attached to a moving vehicle to collect data along a path. These scanners are almost always paired with other kinds of equipment, including GNSS receivers and IMUs. One example application is surveying streets, where power lines, exact bridge heights, bordering trees, etc. all need to be taken into account. Instead of collecting each of these measurements individually in the field with a tachymeter, a 3-D model from a point cloud can be created where all of the measurements needed can be made, depending on the quality of the data collected. This eliminates the problem of forgetting to take a measurement, so long as the model is available, reliable and has an appropriate level of accuracy.\n\nTerrestrial lidar mapping involves a process of occupancy grid map generation. The process involves an array of cells divided into grids which employs a process to store the height values when lidar data falls into the respective grid cell. A binary map is then created by applying a particular threshold to the cell values for further processing. The next step is to process the radial distance and z-coordinates from each scan to identify which 3-D points correspond to each of the specified grid cell leading to the process of data formation.\n\nThere are a wide variety of applications for lidar, in addition to the applications listed below, as it is often mentioned in National lidar dataset programs.\n\nAgricultural robots have been used for a variety of purposes ranging from seed and fertilizer dispersions, sensing techniques as well as crop scouting for the task of weed control.\n\nLidar can help determine where to apply costly fertilizer. It can create a topographical map of the fields and reveal slopes and sun exposure of the farm land. Researchers at the Agricultural Research Service used this topographical data with the farmland yield results from previous years, to categorize land into zones of high, medium, or low yield. This indicates where to apply fertilizer to maximize yield.\n\nAnother application is crop mapping in orchards and vineyards, to detect foliage growth and the need for pruning or other maintenance, detect variations in fruit production, or count plants.\n\nLidar is useful in GPS-denied situations, such as nut and fruit orchards, where foliage blocks GPS signals to precision agriculture equipment or a driverless tractor. Lidar sensors can detect the edges of rows, so that farming equipment can continue moving until GPS signal is reestablished.\n\nControlling weeds requires identifying plant species. This can be done by using 3-D lidar and machine learning. Lidar produces plant contours as a \"point cloud\" with range and reflectance values. This data is transformed, and features are extracted from it. If the species is known, the features are added as new data. The species is labelled and its features are initially stored as an example to identify the species in the real environment. This method is efficient because it uses a low-resolution lidar and supervised learning. It includes an easy-to-compute feature set with common statistical features which are independent of the plant size.\n\nLidar has many uses in archaeology, including planning of field campaigns, mapping features under forest canopy, and overview of broad, continuous features indistinguishable from the ground. Lidar can produce high-resolution datasets quickly and cheaply. Lidar-derived products can be easily integrated into a Geographic Information System (GIS) for analysis and interpretation.\n\nLidar can also help to create high-resolution digital elevation models (DEMs) of archaeological sites that can reveal micro-topography that is otherwise hidden by vegetation. The intensity of the returned lidar signal can be used to detect features buried under flat vegetated surfaces such as fields, especially when mapping using the infrared spectrum. The presence of these features affects plant growth and thus the amount of infrared light reflected back. For example, at Fort Beauséjour – Fort Cumberland National Historic Site, Canada, lidar discovered archaeological features related to the siege of the Fort in 1755. Features that could not be distinguished on the ground or through aerial photography were identified by overlaying hill shades of the DEM created with artificial illumination from various angles. Another example is work at Caracol by Arlen Chase and his wife Diane Zaino Chase. In 2012, lidar was used to search for the legendary city of La Ciudad Blanca or \"City of the Monkey God\" in the La Mosquitia region of the Honduran jungle. During a seven-day mapping period, evidence was found of man-made structures. In June 2013, the rediscovery of the city of Mahendraparvata was announced. In southern New England, lidar was used to reveal stone walls, building foundations, abandoned roads, and other landscape features obscured in aerial photography by the region's dense forest canopy. In Cambodia, lidar data were used by Demian Evans and Roland Fletcher to reveal anthropogenic changes to Angkor landscape In 2016, Lidar was used to map ancient Maya causeways in northern Guatemala, discovering 17 elevated roads linking the ancient city of El Mirador to other sites. In 2018, archaeologists using lidar discovered more than 60,000 man-made structures in the Maya Biosphere Reserve, a \"major breakthrough\" that showed the Maya civilization was much larger than previously thought.\n\nAutonomous vehicles may use lidar for obstacle detection and avoidance to navigate safely through environments, using rotating laser beams. Cost map or point cloud outputs from the lidar sensor provide the necessary data for robot software to determine where potential obstacles exist in the environment and where the robot is in relation to those potential obstacles. Singapore's \"Singapore-MIT Alliance for Research and Technology (SMART)\" is actively developing technologies for autonomous lidar vehicles. Examples of companies that produce lidar sensors commonly used in robotics or vehicle automation are Sick and Hokuyo. Examples of obstacle detection and avoidance products that leverage lidar sensors are the Autonomous Solution, Inc. Forecast 3D Laser System and Velodyne HDL-64E. Lidar simulation models are also provided in autonomous car simulators.\n\nThe very first generations of automotive adaptive cruise control systems used only lidar sensors.\n\nIn transportation systems, to ensure vehicle and passenger safety and to develop electronic systems that deliver driver assistance, understanding vehicle and its surrounding environment is essential. Lidar systems play an important role in the safety of transportation systems. Lots of electronic systems which add to the driver assistance and vehicle safety such as Adaptive Cruise Control (ACC), Emergency Brake Assist, Anti-lock Braking System (ABS) depend on the detection of a vehicle's environment to act autonomously or semi-autonomously. Lidar mapping and estimation achieve this.\n\nBasics overview: Current lidar systems use rotating hexagonal mirrors which split the laser beam. The upper three beams are used for vehicle and obstacles ahead and the lower beams are used to detect lane markings and road features. The major advantage of using lidar is that the spatial structure is obtained and this data can be fused with other sensors such as radar, etc. to get a better picture of the vehicle environment in terms of static and dynamic properties of the objects present in the environment. Conversely, a significant issue with lidar is the difficulty in reconstructing point cloud data in poor weather conditions. In heavy rain, for example, the light pulses emitted from the lidar system are partially reflected off of rain droplets which adds noise to the data, called 'echoes'.\n\nBelow mentioned are various approaches of processing lidar data and using it along with data from other sensors through sensor fusion to detect the vehicle environment conditions.\n\nIn this method, proposed by Philipp Lindner and Gerd Wanielik, laser data is processed using a multidimensional occupancy grid. Data from a four-layer laser is pre-processed at the signal level and then processed at a higher level to extract the features of the obstacles. A combination two- and three-dimensional grid structure is used and the space in these structures is tessellated into several discrete cells. This method allows a huge amount of raw measurement data to be effectively handled by collecting it in spatial containers, the cells of the evidence grid. Each cell is associated with a probability measure that identifies the cell occupation. This probability is calculated by using the range measurement of the lidar sensor obtained over time and a new range measurement, which are related using Bayes' theorem. A two dimensional grid can observe an obstacle in front of it, but cannot observe the space behind the obstacle. To address this, the unknown state behind the obstacle is assigned a probability of 0.5. By introducing the third dimension or in other terms using a multi-layer laser, the spatial configuration of an object could be mapped into the grid structure to a degree of complexity. This is achieved by transferring the measurement points into a three-dimensional grid. The grid cells which are occupied will possess a probability greater than 0.5 and the mapping would be color coded based on the probability. The cells that are not occupied will possess a probability less than 0.5 and this area will usually be white space. This measurement is then transformed to a grid coordinate system by using the sensor position on the vehicle and the vehicle position in the world coordinate system. The coordinates of the sensor depends upon its location on the vehicle and the coordinates of the vehicle is computed using egomotion estimation, which is estimating the vehicle motion relative to a rigid scene. For this method, the grid profile must be defined. The grid cells touched by the transmitted laser beam are calculated by applying Bresenham's line algorithm. To obtain the spatial extended structure, a connected component analysis of these cells is performed. This information is then passed on to a rotating caliper algorithm to obtain the spatial characteristics of the object. In addition to the lidar detection, RADAR data obtained by using two short range radars is integrated to get additional dynamic properties of the object, such as its velocity. The measurements are assigned to the object using a potential distance function.\n\nThe geometric features of the objects are extracted efficiently, from the measurements obtained by the 3-D occupancy grid, using rotating caliper algorithm. Fusing the radar data to the lidar measurements give information about the dynamic properties of the obstacle such as velocity and location of the obstacle with respect to the sensor location which helps the vehicle or the driver decide the action to be performed in order to ensure safety. The only concern is the computational requirement to implement this data processing technique. It can be implemented in real time and has been proven efficient if the 3-D occupancy grid size is considerably restricted. But this can be improved to an even wider range by using dedicated spatial datastructures that manipulate the spatial data more effectively, for the 3-D grid representation.\n\nThe framework proposed in this method by Soonmin Hwang et al., is split into four steps. First, the data from the camera and 3-D lidar is input into the system. Both inputs from lidar and camera are parallelly obtained and the color image from the camera is calibrated with the lidar. To improve the efficiency, horizontal 3-D point sampling is applied as pre-processing. Second, the segmentation stage is where the entire 3-D points are divided into several groups per the distance from the sensor and local planes from close plane to far plane are sequentially estimated. The local planes are estimated using statistical analysis. The group of points closer to the sensor are used to compute the initial plane. By using the current local plane, the next local plane is estimated by iterative update. The object proposals in the 2-D image are used to separate foreground objects from background. For faster and accurate detection and tracking Binarized Normed Gradients for Objectness Estimation at 300fps is used. BING is a combination of normed gradient and its binarized version which speeds up the feature extraction and testing process, to estimate the objectness of an image window. This way the foreground and background objects are separated. To form objects after estimating the objectness of an image using BING, the 3-D points are grouped or clustered. Clustering is done using DBSCAN (Density-Based Spatial Clustering of Applications with Noise) algorithm which could be robust due to its less-parametric characteristic. Using the clustered 3-D points, i.e. 3-D segment, more accurate region-of-interests (RoIs) are generated by projecting 3-D points on the 2-D image. The third step is detection, which is broadly divided into two parts. First is object detection in 2-D image which is achieved using Fast R-CNN as this method doesn't need training and it also considers an image and several regions of interest. Second is object detection in 3-D space that is done by using the spin image method. This method extracts local and global histograms to represent a certain object. To merge the results of 2-D image and 3-D space object detection, same 3-D region is considered and two independent classifiers from 2-D image and 3-D space are applied to the considered region. Scores calibration is done to get a single confidence score from both detectors. This single score is obtained in the form of probability. The final step is tracking. This is done by associating moving objects in present and past frame. For object tracking, segment matching is adopted. Features such as mean, standard deviation, quantized color histograms, volume size and number of 3-D points of a segment are computed. Euclidean distance is used to measure differences between segments. To judge the appearance and disappearance of an object, similar segments (obtained based on the Euclidean distance) from two different frames are taken and the physical distance and dissimilarity scores are calculated. If the scores go beyond a range for every segment in previous frame, the object being tracked is considered to have disappeared.\n\nThe advantages of this method are using 2-D image and 3-D data together, F l-score (which gives a measure of test's accuracy), average precision (AP) are higher than that when only 3-D data from lidar is used. These scores are conventional measurements which judge the framework. The drawback of this method is the usage of BING for object proposal estimation as BING predicts a small set of object bounding boxes.\n\nThis method proposed by Kun Zhou et al. not only focuses on object detection and tracking but also recognizes lane marking and road features. As mentioned earlier the lidar systems use rotating hexagonal mirrors that split the laser beam into six beams. The upper three layers are used to detect the forward objects such as vehicles and roadside objects. The sensor is made of weather-resistant material. The data detected by lidar are clustered to several segments and tracked by Kalman filter. Data clustering here is done based on characteristics of each segment based on object model, which distinguish different objects such as vehicles, signboards, etc. These characteristics include the dimensions of the object, etc. The reflectors on the rear edges of vehicles are used to differentiate vehicles from other objects. Object tracking is done using a 2-stage Kalman filter considering the stability of tracking and the accelerated motion of objects Lidar reflective intensity data is also used for curb detection by making use of robust regression to deal with occlusions. The road marking is detected using a modified Otsu method by distinguishing rough and shiny surfaces.\n\nRoadside reflectors that indicate lane border are sometimes hidden due to various reasons. Therefore, other information is needed to recognize the road border. The lidar used in this method can measure the reflectivity from the object. Hence, with this data road border can also be recognized. Also the usage of sensor with weather-robust head helps detecting the objects even in bad weather conditions. Canopy Height Model before and after flood is a good example. Lidar can detect high detailed canopy height data as well as its road border.\n\nLidar measurements help identify the spatial structure of the obstacle. This helps distinguish objects based on size and estimate the impact of driving over it.\n\nLidar systems provides better range and a large field of view which helps detecting obstacles on the curves. This is one major advantage over RADAR systems which have a narrower field of view. The fusion of lidar measurement with different sensors makes the system robust and useful in real-time applications, since lidar dependent systems can't estimate the dynamic information about the detected object.\n\nIt has been shown that lidar can be manipulated, such that self-driving cars are tricked into taking evasive action.\n\nLidar has also found many applications in forestry. Canopy heights, biomass measurements, and leaf area can all be studied using airborne lidar systems. Similarly, lidar is also used by many industries, including Energy and Railroad, and the Department of Transportation as a faster way of surveying. Topographic maps can also be generated readily from lidar, including for recreational use such as in the production of orienteering maps.\n\nIn addition, the Save the Redwoods League has undertaking a project to map the tall redwoods on the Northern California coast. Lidar allows research scientists to not only measure the height of previously unmapped trees, but to determine the biodiversity of the redwood forest. Stephen Sillett, who is working with the League on the North Coast lidar project, claims this technology will be useful in directing future efforts to preserve and protect ancient redwood trees.\n\nHigh-resolution digital elevation maps generated by airborne and stationary lidar have led to significant advances in geomorphology (the branch of geoscience concerned with the origin and evolution of the Earth surface topography). The lidar abilities to detect subtle topographic features such as river terraces and river channel banks, to measure the land-surface elevation beneath the vegetation canopy, to better resolve spatial derivatives of elevation, and to detect elevation changes between repeat surveys have enabled many novel studies of the physical and chemical processes that shape landscapes.\nIn 2005 the Tour Ronde in the Mont Blanc massif became the first high alpine mountain on which lidar was employed to monitor the increasing occurrence of severe rock-fall over large rock faces allegedly caused by climate change and degradation of permafrost at high altitude.\n\nIn geophysics and tectonics, a combination of aircraft-based lidar and GPS has evolved into an important tool for detecting faults and for measuring uplift. The output of the two technologies can produce extremely accurate elevation models for terrain – models that can even measure ground elevation through trees. This combination was used most famously to find the location of the Seattle Fault in Washington, United States. This combination also measures uplift at Mt. St. Helens by using data from before and after the 2004 uplift. Airborne lidar systems monitor glaciers and have the ability to detect subtle amounts of growth or decline. A satellite-based system, the NASA ICESat, includes a lidar sub-system for this purpose. The NASA Airborne Topographic Mapper is also used extensively to monitor glaciers and perform coastal change analysis.\nThe combination is also used by soil scientists while creating a soil survey. The detailed terrain modeling allows soil scientists to see slope changes and landform breaks which indicate patterns in soil spatial relationships.\n\nInitially based on ruby lasers, lidar for meteorological applications was constructed shortly after the invention of the laser and represent one of the first applications of laser technology. Lidar technology has since expanded vastly in capability and lidar systems are used to perform a range of measurements that include profiling clouds, measuring winds, studying aerosols, and quantifying various atmospheric components. Atmospheric components can in turn provide useful information including surface pressure (by measuring the absorption of oxygen or nitrogen), greenhouse gas emissions (carbon dioxide and methane), photosynthesis (carbon dioxide), fires (carbon monoxide), and humidity (water vapor). Atmospheric lidars can be either ground-based, airborne or satellite depending on the type of measurement.\n\nAtmospheric lidar remote sensing works in two ways – \n\nBackscatter from the atmosphere directly gives a measure of clouds and aerosols. Other derived measurements from backscatter such as winds or cirrus ice crystals require careful selecting of the wavelength and/or polarization detected. \"Doppler lidar\" and \"Rayleigh Doppler lidar\" are used to measure temperature and/or wind speed along the beam by measuring the frequency of the backscattered light. The Doppler broadening of gases in motion allows the determination of properties via the resulting frequency shift. Scanning lidars, such as the conical-scanning NASA HARLIE LIDAR, have been used to measure atmospheric wind velocity. The ESA wind mission ADM-Aeolus will be equipped with a Doppler lidar system in order to provide global measurements of vertical wind profiles. A doppler lidar system was used in the 2008 Summer Olympics to measure wind fields during the yacht competition.\n\nDoppler lidar systems are also now beginning to be successfully applied in the renewable energy sector to acquire wind speed, turbulence, wind veer, and wind shear data. Both pulsed and continuous wave systems are being used. Pulsed systems use signal timing to obtain vertical distance resolution, whereas continuous wave systems rely on detector focusing.\n\nThe term, \"eolics\", has been proposed to describe the collaborative and interdisciplinary study of wind using computational fluid mechanics simulations and Doppler lidar measurements.\n\nThe ground reflection of an airborne lidar gives a measure of surface reflectivity (assuming the atmospheric transmittance is well known) at the lidar wavelength, however, the ground reflection is typically used for making absorption measurements of the atmosphere. \"Differential absorption lidar\" (DIAL) measurements utilize two or more closely spaced (<1 nm) wavelengths to factor out surface reflectivity as well as other transmission losses, since these factors are relatively insensitive to wavelength. When tuned to the appropriate absorption lines of a particular gas, DIAL measurements can be used to determine the concentration (mixing ratio) of that particular gas in the atmosphere. This is referred to as an \"Integrated Path Differential Absorption\" (IPDA) approach, since it is a measure of the integrated absorption along the entire lidar path. IPDA lidars can be either pulsed or CW and typically use two or more wavelengths. IPDA lidars have been used for remote sensing of carbon dioxide and methane.\n\n\"Synthetic array lidar\" allows imaging lidar without the need for an array detector. It can be used for imaging Doppler velocimetry, ultra-fast frame rate (MHz) imaging, as well as for speckle reduction in coherent lidar. An extensive lidar bibliography for atmospheric and hydrospheric applications is given by Grant.\n\nAnother lidar technique for atmospheric remote sensing has emerged. It is based on Scheimpflug principle, referred to as Scheimpflug lidar (slidar).\n\n\"The implication of the Scheimpflug principle is that when a laser beam is transmitted into the atmosphere, the backscattering echo of the entire illuminating probe volume is still in focus simultaneously without diminishing the aperture as long as the object plane, image plane and the lens plane intersect with each other\". A two dimensional CCD/CMOS camera is used to resolve the backscattering echo of the transmitted laser beam.\n\nThus as in the case of conventional lidar technologies continuous wave light sources such as diode lasers can be employed for remote sensing instead of using complicated nanosecond pulse light sources. The SLidar system is also a robust and inexpensive system based on compact laser diodes and array detectors.\n\nLidar speed guns are used by the police to measure the speed of vehicles for speed limit enforcement purposes. Additionally, it is used in forensics to aid in crime scene investigations. Scans of a scene are taken to record exact details of object placement, blood, and other important information for later review. These scans can also be used to determine bullet trajectory in cases of shootings.\n\nFew military applications are known to be in place and are classified (such as the lidar-based speed measurement of the AGM-129 ACM stealth nuclear cruise missile), but a considerable amount of research is underway in their use for imaging. Higher resolution systems collect enough detail to identify targets, such as tanks. Examples of military applications of lidar include the Airborne Laser Mine Detection System (ALMDS) for counter-mine warfare by Areté Associates.\n\nA NATO report (RTO-TR-SET-098) evaluated the potential technologies to do stand-off detection for the discrimination of biological warfare agents. The potential technologies evaluated were Long-Wave Infrared (LWIR), Differential Scattering (DISC), and Ultraviolet Laser Induced Fluorescence (UV-LIF). The report concluded that : \"Based upon the results of the lidar systems tested and discussed above, the Task Group recommends that the best option for the near-term (2008–2010) application of stand-off detection systems is UV-LIF \", however, in the long-term, other techniques such as stand-off Raman spectroscopy may prove to be useful for identification of biological warfare agents.\n\nShort-range compact spectrometric lidar based on Laser-Induced Fluorescence (LIF) would address the presence of bio-threats in aerosol form over critical indoor, semi-enclosed and outdoor venues such as stadiums, subways, and airports. This near real-time capability would enable rapid detection of a bioaerosol release and allow for timely implementation of measures to protect occupants and minimize the extent of contamination.\n\nThe Long-Range Biological Standoff Detection System (LR-BSDS) was developed for the U.S. Army to provide the earliest possible standoff warning of a biological attack. It is an airborne system carried by a helicopter to detect synthetic aerosol clouds containing biological and chemical agents at long range. The LR-BSDS, with a detection range of 30 km or more, was fielded in June 1997. \nFive lidar units produced by the German company Sick AG were used for short range detection on Stanley, the autonomous car that won the 2005 DARPA Grand Challenge.\n\nA robotic Boeing AH-6 performed a fully autonomous flight in June 2010, including avoiding obstacles using lidar.\n\nFor The calculation of ore volumes is accomplished by periodic (monthly) scanning in areas of ore removal, then comparing surface data to the previous scan.\n\nLidar sensors may also be used for obstacle detection and avoidance for robotic mining vehicles such as in the Komatsu Autonomous Haulage System (AHS) used in Rio Tinto's Mine of the Future.\n\nA worldwide network of observatories uses lidars to measure the distance to reflectors placed on the moon, allowing the position of the moon to be measured with millimeter precision and tests of general relativity to be done. MOLA, the Mars Orbiting Laser Altimeter, used a lidar instrument in a Mars-orbiting satellite (the NASA Mars Global Surveyor) to produce a spectacularly precise global topographic survey of the red planet.\n\nIn September, 2008, the NASA Phoenix Lander used lidar to detect snow in the atmosphere of Mars.\n\nIn atmospheric physics, lidar is used as a remote detection instrument to measure densities of certain constituents of the middle and upper atmosphere, such as potassium, sodium, or molecular nitrogen and oxygen. These measurements can be used to calculate temperatures. Lidar can also be used to measure wind speed and to provide information about vertical distribution of the aerosol particles.\n\nAt the JET nuclear fusion research facility, in the UK near Abingdon, Oxfordshire, lidar Thomson Scattering is used to determine Electron Density and Temperature profiles of the plasma.\n\nLidar has been widely used in rock mechanics for rock mass characterization and slope change detection. Some important geomechanical properties from the rock mass can be extracted from the 3-D point clouds obtained by means of the lidar. Some of these properties are: \nSome of these properties have been used to assess the geomechanical quality of the rock mass through the RMR index. Moreover, as the orientations of discontinuities can be extracted using the existing methodologies, it is possible to assess the geomechanical quality of a rock slope through the SMR index. In addition to this, the comparison of different 3-D point clouds from a slope acquired at different times allows researchers to study the changes produced on the scene during this time interval as a result of rockfalls or any other landsliding processes.\n\nTHOR\n\nTHOR is a laser designed toward measuring Earth's atmospheric conditions. The laser enters a cloud cover and measures the thickness of the return halo. The sensor has a fiber optic aperture with a width of 7.5 inches that is used to measure the return light.\n\nLidar technology is being used in robotics for the perception of the environment as well as object classification. The ability of lidar technology to provide three-dimensional elevation maps of the terrain, high precision distance to the ground, and approach velocity can enable safe landing of robotic and manned vehicles with a high degree of precision. Lidar are also widely used in robotics for simultaneous localization and mapping and well integrated into robot simulators. Refer to the Military section above for further examples.\n\nLidar is increasingly being utilized for rangefinding and orbital element calculation of relative velocity in proximity operations and stationkeeping of spacecraft. Lidar has also been used for atmospheric studies from space. Short pulses of laser light beamed from a spacecraft can reflect off of tiny particles in the atmosphere and back to a telescope aligned with the spacecraft laser. By precisely timing the lidar 'echo,' and by measuring how much laser light is received by the telescope, scientists can accurately determine the location, distribution and nature of the particles. The result is a revolutionary new tool for studying constituents in the atmosphere, from cloud droplets to industrial pollutants, which are difficult to detect by other means.\"\n\nAirborne lidar sensors are used by companies in the remote sensing field. They can be used to create a DTM (Digital Terrain Model) or DEM (Digital Elevation Model); this is quite a common practice for larger areas as a plane can acquire 3–4 km wide swaths in a single flyover. Greater vertical accuracy of below 50 mm can be achieved with a lower flyover, even in forests, where it is able to give the height of the canopy as well as the ground elevation. Typically, a GNSS receiver configured over a georeferenced control point is needed to link the data in with the WGS (World Geodetic System).\n\nLiDAR are also in use in hydrographic surveying. Depending upon the clarity of the water LiDAR can measure depths from 0.9m to 40m with a vertical accuracy of 15 cm and horizontal accuracy of 2.5m.\n\nForestry\n\nLidar systems have also been applied to improve forestry management. Measurements are used to take inventory in forest plots as well as calculate individual tree heights, crown width and crown diameter. Other statistical analysis use lidar data to estimate total plot information such as canopy volume, mean, minimum and maximum heights, and vegetation cover estimates.\n\nLidar has been used in the railroad industry to generate asset health reports for asset management and by departments of transportation to assess their road conditions. CivilMaps.com is a leading company in the field. Lidar has been used in adaptive cruise control (ACC) systems for automobiles. Systems such as those by Siemens, Hella, and Cepton use a lidar device mounted on the front of the vehicle, such as the bumper, to monitor the distance between the vehicle and any vehicle in front of it. In the event the vehicle in front slows down or is too close, the ACC applies the brakes to slow the vehicle. When the road ahead is clear, the ACC allows the vehicle to accelerate to a speed preset by the driver. Refer to the Military section above for further examples. A lidar-based device, the Ceilometer is used at airports worldwide to measure the height of clouds on runway approach paths.\n\nLidar can be used to increase the energy output from wind farms by accurately measuring wind speeds and wind turbulence. Experimental lidar systems can be mounted on the nacelle of a wind turbine or integrated into the rotating spinner to measure oncoming horizontal winds, winds in the wake of the wind turbine, and proactively adjust blades to protect components and increase power. Lidar is also used to characterise the incident wind resource for comparison with wind turbine power production to verify the performance of the wind turbine by measuring the wind turbine's power curve. Wind farm optimization can be considered a topic in \"applied eolics\". Another aspect of Lidar in wind related industry is to use computational fluid dynamics over Lidar-scanned surfaces in order to assess the wind potential, which can be used for optimal wind farms placement.\n\nLidar can also be used to assist planners and developers in optimizing solar photovoltaic systems at the city level by determining appropriate roof tops and for determining shading losses. Recent airborne laser scanning efforts have focused on ways to estimate the amount of solar light hitting vertical building facades, or by incorporating more detailed shading losses by considering the influence from vegetation and larger surrounding terrain.\n\nRecent simulation racing games such as iRacing, Assetto Corsa and Project CARS increasingly feature race tracks reproduced from 3-D point clouds acquired through Lidar surveys, resulting in surfaces replicated with millimeter precision in the in-game 3-D environment.\n\nThe 2017 exploration game \"Scanner Sombre\", by Introversion Software, uses Lidar as a fundamental game mechanic.\n\nThe video for the song \"House of Cards\" by Radiohead was believed to be the first use of real-time 3-D laser scanning to record a music video. The range data in the video is not completely from a lidar, as structured light scanning is also used.\n\nRecent development of Structure From Motion (SFM) technologies allows delivering 3-D images and maps based on data extracted from visual and IR photography. The elevation or 3-D data is extracted using multiple parallel passes over mapped area, yielding both visual light images and 3-D structure from the same sensor, which is often a specially chosen and calibrated digital camera. \n\n\n"}
{"id": "1027480", "url": "https://en.wikipedia.org/wiki?curid=1027480", "title": "List of 7400-series integrated circuits", "text": "List of 7400-series integrated circuits\n\nThe following is a list of 7400-series digital logic integrated circuits. The original 7400-series integrated circuits were made by Texas Instruments with the prefix \"SN\" to create the name SN74xx. Due to the popularity of these parts, other manufacturers have released pin-to-pin compatible devices which kept the 7400 sequence number as an aid to identification of compatible parts. However, different manufacturers will use different prefixes or no prefix at all.\n\nSome TTL logic parts were made with an extended military-specification temperature range. These parts are prefixed with 54 instead of 74 in the part number. A short-lived 64 prefix on Texas Instruments parts indicated an industrial temperature range; this prefix had been dropped from the TI literature by 1973. Most recent 7400 series parts are fabricated in CMOS or BiCMOS technology rather than TTL. Surface mount parts with a single gate (often in a 5-pin or 6-pin package) are prefixed with 741G instead of 74.\n\nSome manufacturers released some 4000-series equivalent CMOS circuits with a 74 prefix, for example the 74HC4066 was a replacement for the 4066 with slightly different electrical characteristics (different power supply voltage ratings, higher frequency capabilities, lower \"on\" resistances in analog switches, etc.). See List of 4000-series integrated circuits.\nConversely, the 4000-series has \"borrowed\" from the 7400 series - such as the CD40193 and CD40161 being pin-for-pin \"functional\" replacements for 74C193 and 74C161.\n\nOlder TTL parts made by manufacturers such as Signetics, Motorola, Mullard and Siemens may have different numeric prefix and numbering series entirely, such as in the European FJ family FJH101 is an 8-input NAND gate like a 7430.\n\nA few alphabetic characters to designate a specific logic subfamily may immediately follow the 74 or 54 in the\npart number, e.g., 74LS74 for Low-power Schottky. Some CMOS parts such as 74HCT74 for High-speed CMOS with TTL-compatible input thresholds are functionally similar to the TTL part. Not all functions are available in all families.\n\nIn a few instances, such as the 7478 and 74107, the same suffix in different families do not have completely equivalent logic functions.\n\nAnother extension to the series is the 7416xxx variant, representing mostly the 16-bit wide counterpart of otherwise 8-bit-wide \"base\" chips with the same three ending digits. Thus e.g. a \"7416373\" would be the 16-bit-wide equivalent of a \"74373\". Some 7416xxx parts, however, do not have a direct counterpart from the standard 74xxx range but deliver new functionality instead, which needs making use of the 7416xxx series' higher pin count. For more details, refer primarily to the Texas Instruments documentation mentioned in the References section.\n\nFor CMOS (AC, HC, etc.) subfamilies, read \"open drain\" for \"open collector\" in the table below.\n\nThere are a few numeric suffixes that have multiple conflicting assignments, such as the 74453.\n\nParts in this section have a pin count of 14 pins or more. The lower part numbers were established in the 1960s and 1970s, then higher part numbers were added incrementally over decades. IC manufacturers continue to make a core subset of this group, but many of these part numbers are considered obsolete and no longer manufactured. Older discontinued parts may be available from a limited number of sellers as new old stock (NOS), though some are much harder to find.\n\nFor the following table:\n\nAs board designs have migrated away from large amounts of logic chips, so has the need for many of the same gate in one package. Since about 1996, there has been an ongoing trend towards one / two / three logic gates per chip. Now logic can be placed where it is physically needed on a board, instead of running long signal traces to a full-size logic chip that has many of the same gate.\n\nAll chips in the following sections are available 4 to 12 pin surface mount packages. The right digits, after the 1G/2G/3G, typically has the same functional features as older legacy chips, except for the multifunctional chips and 4-digit chip numbers which are unique to these newer families. The \"x\" in the part number is a place holder for the logic family name. For example, 74x1G14 in \"LVC\" logic family would be \"74LVC1G14\". The previously stated prefixes of \"SN-\" and \"MC-\" are used to denote manufacturers, Texas Instruments and ON Semiconductor respectively.\n\nSome of the manufacturers that make these smaller IC chips are: Diodes Incorporated, Nexperia (NXP Semiconductors), ON Semiconductor (Fairchild Semiconductor), Texas Instruments (National Semiconductor), Toshiba.\n\nAll chips in this section have one gate, noted by the \"1G\" in the part numbers. The most popular logic families are LVC and AUP, however there have been other releases such as AUC and AXP families with shorter propagation delays or expansions of the existing families such as the AHC(T) and HC(T).\n\nAll chips in this section have two gates, noted by the \"2G\" in the part numbers. The \"2G\" chips mainly consist of AUG and LVC logic families, more recently AHC, AHCT, HC, HCT families have been expanding, plus some support for AXP family.\n\nAll chips in this section have three gates, noted by the \"3G\" in the part numbers. The \"3G\" chips mainly consist of AUG and LVC logic families, more recently AHC, AHCT, HC, HCT families have been expanding.\n\n\n"}
{"id": "3273309", "url": "https://en.wikipedia.org/wiki?curid=3273309", "title": "List of Minolta products", "text": "List of Minolta products\n\nList of products manufactured by electronics company Minolta.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMinolta PT-2\n\n\n"}
{"id": "8985569", "url": "https://en.wikipedia.org/wiki?curid=8985569", "title": "Load dump", "text": "Load dump\n\nLoad dump means the disconnection of a powered load. It can cause 2 problems: \n\nIn automotive electronics, it refers to the disconnection of the vehicle battery from the alternator while the battery is being charged. Due to such a disconnection of the battery, other loads connected to the alternator see a surge in power line. The peak voltage of this surge may be as high as 120 V and the surge may take up to 400 ms to decay. It is typically clamped to 40 V in 12 V vehicles and about 60 V in 24 V systems.\n\nThe windings of an alternator have a large inductance. When the vehicle battery is being charged, the alternator supplies it with a large current, the magnitude of which is controlled by the current in the field winding. If the battery becomes disconnected while it is being charged the alternator load suddenly decreases. However the alternator's regulator cannot quickly cause the field current to decrease sufficiently, so the alternator continues to generate a large current. This large current causes the voltage on the vehicle bus to increase significantly -- well above the normal and regulated level.\n\nAll the loads connected to the alternator see this high voltage spike. The strength of the spike depends on many factors including the speed at which the alternator is rotating and the current which was being supplied to the battery before it was disconnected. These spike may peak at as high as 120 V and may take up to 400 ms to decay. This kind of a spike would damage many semiconductor devices, e.g. ECUs, that may be connected to the alternator. Special protection devices, such as TVS diodes, varistors which can withstand and absorb the energy of these spikes may be added to protect such semiconductor devices.\n\nVarious automotive standards such as ISO 7637-2 and SAE J1113-11 specify a standard shape of the load dump pulse against which automotive electronic components may be designed.\n\nThere can also be a smaller inductive spike due to the inductance of the stator windings. That may have a larger voltage, but it will be for a much shorter duration, as relatively little energy is stored in the inductance of these windings. Load dump can be more damaging because the alternator continues to generate power until the field current can decrease, so much more energy can be released.\n"}
{"id": "32339962", "url": "https://en.wikipedia.org/wiki?curid=32339962", "title": "Mop bucket cart", "text": "Mop bucket cart\n\nA mop bucket cart (or mop trolley) is a wheeled bucket that allows its user to wring out a wet mop without getting the hands dirty. The cart has two buckets with the upper one usually clipped onto the lower.\n\nThe upper bucket is used to place the wet mop for storage and press handle to wring out the mop. Water trickles down to another bucket below, which collects the waste water. In some carts, there are separate lower front bucket to collect waste water. The smaller lower rear bucket is filled with a floor cleaning solution.\n\nWheels are usually present to allow the user to push the cart around using the wring handle bar to steer, allowing complete mobility.\n\nThese carts are usually made of heavy duty plastic and usually found in institutional, commercial or industrial settings, but can be used in the home as a more convenient and less dirty tool for cleaning floors.\n"}
{"id": "30676402", "url": "https://en.wikipedia.org/wiki?curid=30676402", "title": "Nanoneedle", "text": "Nanoneedle\n\nNanoneedles may be conical or tubular needles in the nanometre size range, made from silicon or boron-nitride with a central bore of sufficient size to allow the passage of large molecules, or solid needles useful in Raman spectroscopy, light emitting diodes (LED) and laser diodes.\n\nIn 2005 the Research Institute for Cell Engineering at Japan's National Institute of Advanced Industrial Science and Technology (AIST) and Tokyo University of Agriculture and Technology used nanoneedles controlled by an atomic force microscope (AFM) to penetrate the nucleus of living cells and insert molecules of nucleic acid, proteins or possibly to carry out cell surgery. The technique can accurately establish the position of the needle by monitoring the force exerted. Cells to be used for tracking, diagnosing, and treatment of illness may be removed from the body and replaced after being injected. The 100 nm diameter needles were cut from silicon AFM tips using focused ion beam etching.\n\nIn 2009, researchers at the University of Illinois produced a 50 nm diameter boron-nitride nanoneedle with a thin coating of gold, suitable for biophysical research. Its diameter allows easy penetration of cell walls in order to deliver organic matter or fluorescent quantum dots into the cytoplasm or the nucleus. It may also be used as electrochemical probe or optical biosensor in a cellular environment.\n\nThe University of California, Berkeley in 2008 produced gallium arsenide (GaAs) nanoneedles which emit extremely bright light, though not yet lasers, when optically pumped. With a length of 3-4 micrometres, they taper to tips of 2-5 nm across. In addition to optoelectronic devices, the needles will be useful in atomic force microscopy (AFM), and can be easily grown in arrays. Such AFM arrays, besides producing near-atomic resolution images of surfaces, could lead to new forms of data storage by direct manipulation of atoms. The needles may also find a use in tip-enhanced Raman spectroscopy, a process in which molecular energy levels are measured by comparing the frequency of incident light with that of outgoing light. A sharp needle tip allows for a more precise examination of the sample, down perhaps to that of single molecules.\n\nResearch at the department of NanoMedicine and Biomedical Engineering at the University of Texas in 2010 created a new type of nanoneedle using silicon. A solution of hydrogen peroxide produces porous needles - their porosity is controlled along their length by altering the concentration of peroxide over time. The coloured porous needles are constructed to biodegrade over a predictable period, and have a surface area 120 times that of equivalent solid wires, making them useful as drug-delivery vehicles. Since porous silicon does not harm cells, the needles may also be used to tag cells and monitor chemical reactions.\n\nA note of caution was sounded by Martin A. Philbert, professor of toxicology at the University of Michigan, Ann Arbor. \"The ability to manipulate nanometer-scale materials at the molecular level holds the promise of conferring specificity of cellular delivery and the reduction of collateral nuisance injury to neighboring cells. In the context of environmental health, the scientific community will have to pay close attention to those physicochemical properties of engineered nanomaterials that defeat or circumvent normal cellular processes and lend themselves to indiscriminate penetration of biological barriers, tissues, and cellular systems.\" \n"}
{"id": "333382", "url": "https://en.wikipedia.org/wiki?curid=333382", "title": "Pulper", "text": "Pulper\n\nIn agriculture, a pulper is a machine designed to remove pulp (I.e. the soft flesh from agricultural produce). For example, in coffee growing the ripe, red cherries are picked from the coffee bushes and prior to fermentation and later drying the soft pulp needs to be removed (otherwise a potentially uncontrollable fermentation/rot will occur). In the case of coffee the pulping is normally done in a pulper that is either hand-cranked or engine-driven; the beans are emptied into an elevated hopper and then dropped through a narrow slot within which they come into contact with a rotating spiked drum that removes the pulp or flesh. Again in the case of coffee, the sticky beans that result from this process then have to be washed, fermented, washed again and dried prior to further processing (milling to remove the parchment) and then roasting.\n\nIn paper making, a pulper is a machine that produces pulp from cellulose fibres; this pulp can directly be used by a paper machine.\n\nPost-consumer waste is re-pulped, in one of the processes involved in recycling it.\n"}
{"id": "3534703", "url": "https://en.wikipedia.org/wiki?curid=3534703", "title": "Robotic lawn mower", "text": "Robotic lawn mower\n\nA robotic lawn mower is an autonomous robot used to cut lawn grass. A typical robotic lawn mower (in particular earlier generation models) requires the user to set up a border wire around the lawn that defines the area to be mowed. The robot uses this wire to locate the boundary of the area to be trimmed and in some cases to locate a recharging dock. Robotic mowers are capable of maintaining up to of grass.\n\nRobotic lawn mowers are increasingly sophisticated, are self-docking and some contain rain sensors if necessary, nearly eliminating human interaction. Robotic lawn mowers represented the second largest category of domestic robots used by the end of 2005.\n\nPossibly the first commercial robotic lawn mower was the MowBot, introduced and patented in 1969 and already showing many features of today's most popular products.\n\nIn 2012, the growth of robotic lawn mower sales was 15 times that of the traditional styles. \nWith the emergence of smart phones some robotic mowers have integrated features within custom apps to adjust settings or scheduled mowing times and frequency, as well as manually control the mower with a digital joystick.\n\nModern robotic lawn mowers can contain specialized sensors, allowing them to automatically mow around obstacles or even go to sleep when it starts to rain.\nIn 1995, the first fully solar powered robotic mower became available.\n\nThe mower can find its charging station via radio frequency emissions, by following a boundary wire, or by following an optional guide wire. This can eliminate wear patterns in the lawn caused by the mower only being able to follow one wire back to the station.\n\nTo get to remote areas or areas only accessible through narrow passages the mower can follow a guide wire or a boundary wire out of the station.\n\nBatteries used include nickel–metal hydride (NiMH), lithium-ion and lead-acid.\n\nThe price of a robotic lawn mower varies from around $1000 to $4500.\n\n"}
{"id": "38307144", "url": "https://en.wikipedia.org/wiki?curid=38307144", "title": "Royale (brand)", "text": "Royale (brand)\n\nRoyale is a Canadian brand of consumer household paper products such as facial tissue, bathroom tissue, paper towel, and paper napkins.\n\nIn 1929, New York-based National Cellulose Company dissolved a relationship with its Canadian distributor and opened its first Canadian office in downtown Toronto In 1936, Toronto businessman William S. Gibson and a team of investors bought out National Cellulose and Dominion Cellulose was formed. Dominion Cellulose continued to sell its Facelle tissue in Canada until 1961 when the company was sold to Canadian International Paper Company and was renamed Facelle Company. Facelle Company launched its Royale brand in 1963 with two products; 3-ply facial tissue, and 2-ply bathroom tissue.\n\nIn August 1991 the Royale brand was sold to Procter & Gamble where it remained until 2001 when Irving Tissue purchased P&G’s Weston Road plant in Toronto, Ontario along with the rights to the Royale brand.\n\nThe Royale brand is represented by the Royale Kittens, two white Persian kittens who embody the Kitten-y softness of Royale products. They first appeared in a 1973 television commercial which ran until 1984. Since then, the Kittens have appeared in television, print, and Internet marketing material for Royale. In 2010, an official Facebook community page was created in the name of the Royale Kittens.\n\nRoyale’s longest running television ad campaign ran from 1973 to 1984, and featured the Royale Kittens playing on a white shag rug and unwinding rolls of bathroom tissue. Other memorable campaigns include Royale’s “The Nose” spot featuring pro hockey player Eddie Shack.\n"}
{"id": "2500987", "url": "https://en.wikipedia.org/wiki?curid=2500987", "title": "STS relay", "text": "STS relay\n\nSTS relay is the speech-to-speech relay service available to any telephone callers or callees with speech disability and to those who wish to talk with them.\n\n\"STS Relay\" is available via 711 in the US through the Telecommunications Relay Service; in a telephone call, first dial 711, then ask for STS. A trained communication assistant will ask you what number you want to call. The assistant will repeat what the caller with the speech disability is saying. The callee can then respond. The caller can then reply. The communication assistant will \"revoice\" the caller's message. The callee then responds in this three-way assisted phone conversation.\n\nThe service is available in Australia, Sweden, and in other nations on a trial basis. STS Relay on the PSTN (public switch telephone network) is available for those who need telephone call assistance because of a speech disability.\n\nSTS Relay first became available in the US in California, in 1997; the service became available nationally March 1, 2001.\n\nOn May 12, 2006, the University of Wisconsin - Madison awarded Robert Z. Segalman, PhD (UW 1972), an honorary Doctor of Science for his work in creating Speech To Speech.\n\n\nDrSTS@comcast.net—this email address is intended for the use of those who need information on how to use Speech to Speech on the telephone in their daily lives\n"}
{"id": "5641966", "url": "https://en.wikipedia.org/wiki?curid=5641966", "title": "Signal Transfer Point", "text": "Signal Transfer Point\n\nA Signal Transfer Point (STP) is a router that relays SS7 messages between \"signaling end-points\" (SEPs) and other signaling transfer points (STPs). Typical SEPs include \"service switching points\" (SSPs) and \"service control points\" (SCPs). The STP is connected to adjacent SEPs and STPs via signaling links. Based on the address fields of the SS7 messages, the STP routes the messages to the appropriate outgoing signaling link. Edge STPs can also route based upon message body content using deep packet inspection techniques, and can provide address translations and screen content to limit the transfer of messages with dubious content or sent from unreliable sources. To meet stringent reliability requirements, STPs are typically provisioned in mated pairs.\n\nThese 'routers' are connected just by signaling links; they don't have users attached (where a \"user\" could be a mobile station (MS), a PSTN user in case of a public terrestrial network, or a piece of terminal equipment at the end of an ISDN B channel). SEPs send signaling messages to other SEPs, but the messages are normally routed via the SEP's adjacent STPs. An STP's main function is to identify the best path for two SEPs to communicate. A typical application would be for two SEPs to agree on the use of a shared data path (e.g., using ISUP to initiate a voice call between a user on one SEP and a user on the second SEP). In this way, STPs route signaling messages (for starting, maintaining or finishing any kind of calls originated by the SEPs' attached users) while avoiding disabled intermediary STPs.\n\nA signaling message typically never goes directly from a given SEP to the destination SEP: the message would normally have to pass through the initiating SEP's adjacent STP so that it can be routed to the destination SEP. In some applications, however, SEPs might be directly connected with signaling links; this would typically be done to enhance robustness or performance between two critical SEPs. Such mesh network configurations are also common in Europe, where STPs have not found widespread deployment.\n\nIn some cases, signaling messages can be originated by the STP to learn about the state of the signaling network Some examples include:\n\nA given piece of equipment can implement both SEP and STP functionality. This is commonly done in some SSPs. This is also seen in Signaling Gateways that also have Application Server (AS) functionality as defined by the IETF.\n\nSome UMTS number portability solutions are implemented in STPs. In UMTS, the STP provides Global Title Translation (GTT), which may be used to route queries from a gateway MSC (GMSC) to the HLR. Note that for every call to an MS, the call is first routed to the MS's Gateway MSC.\n"}
{"id": "30671765", "url": "https://en.wikipedia.org/wiki?curid=30671765", "title": "Sound and music computing", "text": "Sound and music computing\n\nSound and music computing (SMC) is a research field that studies the whole sound and music communication chain from a multidisciplinary point of view. By combining scientific, technological and artistic methodologies it aims at understanding, modeling and generating sound and music through computational approaches.\n\nThe Sound and Music Computing research field can be traced back to the 1950s, when a few experimental composers, together with some engineers and scientists, independently and in different parts of the world, began exploring the use of the new digital technologies for music applications. Since then the SMC research field has had a fruitful history and different terms have been used to identify it. Computer Music and Music Technology might be the terms that have been used the most, being Sound and Music Computing a more recent term. The research community established in 1974 the International Computer Music Association and the International Computer Music Conference. In 1977 the Computer Music Journal was established. The Center for Computer Research in Music and Acoustics (CCRMA) at Stanford University was created in the early 1970s and the Institute for Research and Coordination Acoustic/Music (IRCAM) in Paris in the late 1970s.\n\nThe Sound and Music Computing term was first proposed in the mid 1990s and it was included in the ACM Computing Classification System. Using this name, in 2004 the Sound and Music Computing Conference was started and also in 2004 a roadmapping initiative was funded by the European Commission that resulted on the SMC Roadmap and on the Sound and Music Computing Summer School.\n\nGiven the increasing research specialization within the SMC field a number of focused conferences have been created. Particularly relevant are the International Conference on Digital Audio Effects, established in 1998, the International Conference on Music Information Retrieval (ISMIR), established in 2000, and the International Conference on New Interfaces for Musical Expression (NIME), established in 2001.\n\nThe current SMC research field can be grouped into a number of subfields that focus on specific aspects of the sound and music communication chain.\n\n\nSMC research is a field driven by applications. Examples of applications are:\n\n\n\n\n\n\n\n\n"}
{"id": "5307239", "url": "https://en.wikipedia.org/wiki?curid=5307239", "title": "Syntegrity", "text": "Syntegrity\n\n\"Syntegrity\" is a formal model presented by Anthony Stafford Beer, a British theorist, in his work on management cybernetics, the science of large, complex, probabilistic systems. \n\nThe word Syntegrity is derived from the words \"synergistic\" and \"tensegrity\". Its etymology signifies the ideal balance of tension and compression that makes structures stronger and more stable as they grow. \n\n\"Syntegration\" is a trademarked name of the proprietary methodology that delivers the Syntegrity protocol in the context of complex organizational challenges. The methodology enables a large group of people to be networked together to achieve major insights, alignment and breakthroughs in condensed time frames.\n\nTypical areas of application include: strategy formulation, overall transformation, planning, innovation, ERM, M&A, data and analytics, customer experience, product launch, and more. \nThe words \"Syntegrity\", \"Team Syntegrity\", and \"Syntegration\" are all registered trademarks.\n\n\n\n"}
{"id": "154985", "url": "https://en.wikipedia.org/wiki?curid=154985", "title": "System administrator", "text": "System administrator\n\nA system administrator, or sysadmin, is a person who is responsible for the upkeep, configuration, and reliable operation of computer systems; especially multi-user computers, such as servers. The system administrator seeks to ensure that the uptime, performance, resources, and security of the computers they manage meet the needs of the users, without exceeding a set budget when doing so.\n\nTo meet these needs, a system administrator may acquire, install, or upgrade computer components and software; provide routine automation; maintain security policies; troubleshoot; train or supervise staff; or offer technical support for projects.\n\nMany organizations staff other jobs related to system administration. In a larger company, these may all be separate positions within a computer support or Information Services (IS) department. In a smaller group they may be shared by a few sysadmins, or even a single person.\n\n\nMost employers require a bachelor's degree in a related field, such as computer science, information technology, electronics engineering, or computer engineering. Some schools also offer undergraduate degrees and graduate programs in system administration.\n\nIn addition, because of the practical nature of system administration and the easy availability of open-source server software, many system administrators enter the field self-taught.\n\nGenerally, a prospective will be required to have some experience with the computer system they are expected to manage. In some cases, candidates are expected to possess industry certifications such as the Microsoft MCSA, MCSE, MCITP, Red Hat RHCE, Novell CNA, CNE, Cisco CCNA or CompTIA's A+ or Network+, Sun Certified SCNA, Linux Professional Institute, Linux Foundation Certified Engineer or Linux Foundation Certified System Administrator, among others.\n\nSometimes, almost exclusively in smaller sites, the role of system administrator may be given to a skilled user in addition to or in replacement of his or her duties.\n\nThe \"subject matter\" of system administration includes computer systems and the ways people use them in an organization. This entails a knowledge of operating systems and applications, as well as hardware and software troubleshooting, but also knowledge of the purposes for which people in the organization use the computers.\n\nPerhaps the most important skill for a system administrator is problem solving—frequently under various sorts of constraints and stress. The sysadmin is on call when a computer system goes down or malfunctions, and must be able to quickly and correctly diagnose what is wrong and how best to fix it.\nThey may also need to have teamwork and communication skills; as well as being able to install and configure hardware and software.\n\nSysadmins must understand the behavior of software in order to deploy it and to troubleshoot problems, and generally know several programming languages used for scripting or automation of routine tasks. A typical sysadmin's role is not to design or write new application software but when they are responsible for automating system or application configuration with various configuration management tools, the lines somewhat blur. Depending on the sysadmin's role and skillset they may be expected to understand equivalent key/core concepts a software engineer understands. That said, system administrators are not software engineers or developers, in the job title sense.\n\nParticularly when dealing with Internet-facing or business-critical systems, a sysadmin must have a strong grasp of computer security. This includes not merely deploying software patches, but also preventing break-ins and other security problems with preventive measures. In some organizations, computer security administration is a separate role responsible for overall security and the upkeep of firewalls and intrusion detection systems, but all sysadmins are generally responsible for the security of computer systems.\n\nA system administrator's responsibilities might include:\n\nIn larger organizations, some of the tasks above may be divided among different system administrators or members of different organizational groups. For example, a dedicated individual(s) may apply all system upgrades, a Quality Assurance (QA) team may perform testing and validation, and one or more technical writers may be responsible for all technical documentation written for a company. System administrators, in larger organizations, tend not to be systems architects, systems engineers, or systems designers.\n\nIn smaller organizations, the system administrator might also act as technical support, Database Administrator, Network Administrator, Storage (SAN) Administrator or application analyst.\n\n\n\n"}
{"id": "1135168", "url": "https://en.wikipedia.org/wiki?curid=1135168", "title": "Taggant", "text": "Taggant\n\nA taggant can mean a radio frequency microchip used in automated identification and data capture (see RFID). In such cases, electronic devices use radio waves to track and identify items, such as pharmaceutical products, by assigning individual serial numbers to the containers holding each product. This technology may prevent the diversion or counterfeiting of drugs by allowing wholesalers and pharmacists to determine the identity and dosage of individual products.\n\nA taggant is also a chemical or physical marker added to materials to allow various forms of testing. Physical taggants can take many different forms but are typically microscopic in size, included at low levels, and simple to detect. They can be utilized to differentiate authentic product from counterfeits, provide identifying information for traceability purposes (e.g. lot number, company name), determine mixing homogeneity and cross-contamination, and to detect dilution of proprietary products. Taggants are known to be widely used in the animal feed industry, plastics, inks, sheet and flexible explosives, and pharmaceuticals.\n\nA software taggant is a cryptographic signature added to software that enables positive origin identification and integrity of programs. Software taggants use standard PKI techniques (see public key infrastructure) and were introduced by the Industry Connections Security Group of IEEE in an attempt to control proliferation of malware obfuscation via executable compression.\n\nThe word 'taggant' originates from the trademarked name \"Microtaggant Identification Particles\". Microtaggants were originally developed by 3M for the post detonation of explosives. In 1985, Microtrace, LLC acquired the technology and began to utilize Microtaggants for anti-counterfeiting and brand protection. Since 1985, the word 'taggant' has become widely utilized and refers to multiple variations.\n\nThere are two types of taggant which have been considered for use with explosives. One is to help detect the presence of a bomb in, for example, airport screening of luggage; and the other to assist the police in identifying the explosive after the detonation of such a bomb.\n\nThese are volatile chemicals which will slowly evaporate from the explosive and can be detected in the atmosphere by either detection dogs or specialised machines. They are intended to enhance the detectability of the explosive by instruments or animals thus revealing the presence of a bomb containing the explosive to be detected. Although various technologies exist to detect untagged explosives, detection taggants help to increase their reliability. The inclusion of detection taggants in explosives is mandatory in some countries. Following the bombing of PanAm 103 over Scotland, the International Civil Aviation Organization (ICAO) was instrumental in effecting a worldwide requirement for placing a detection taggant in plastic bonded explosives.\n\nThere is a choice between four possible detection taggant chemicals which must be added to plastic explosives under the 1991 International Civil Aviation Organization's Convention on the Marking of Plastic Explosives for the Purpose of Detection. In the United States the marker is always 2,3-dimethyl-2,3-dinitrobutane, usually called DMDNB or DMNB. Dogs are very sensitive to it and can detect as little as 0.5 parts per billion in the air, as can specialised ion mobility spectrometers. Other taggants in use are ethylene glycol dinitrate, known as EGDN and used to mark Semtex, ortho-mononitrotoluene (o-MNT), and para-mononitrotoluene (p-MNT).\n\nThese have been considered for introduction in industrial explosives so that the manufacturer and batch number can be determined if they are used illegally. The taggant must survive the detonation of the product and not be contaminated by the environment afterwards. Several different technologies have been considered, but the most common are microscopic polymer/metallic particles. Taggant evidence was crucial in the 1980 conviction of James L. McFillin in Maryland for the 1979 truck bombing murder of Nathan A. Allen, Sr.\n\nA contention claimed for opposing mandated taggants is that most terrorist attacks use homemade explosives (HME) which would allegedly not be tagged. Examples given included, for instance, the 1993 World Trade Center bombing, the Oklahoma City and the Omagh bombings. Contamination of the site is also cited as a problem, since different taggants might be present at a crime scene from, for example, explosives used to obtain the building materials.\n\nSwitzerland passed a law in 1980 requiring taggants in explosives manufactured there, and that the code must be changed every six months. So far it is the only country which requires identification taggants. Imported explosives must be tagged only if competing products are also manufactured in Switzerland.\n\nIn the United States, The NRA opposed the mandated use of taggants in firearm propellants after tests reveled a dangerous increase in burn rates. A chemical incompatibility with the propellent powders caused such an increase in pressures it was determined many firearms would burst using a taggent-laced powder that had been stored for as little as several months.\n\nWhen used as a chemical marker, taggants can be used for authentication of products and documents.\nTaggants are sometimes used by brand owners and governments to authenticate commonly counterfeited items. Taggants are integrated into the material of the item itself or into the packaging. Once integrated, the taggants can only be verified with specially engineered readers.\n\n\n\n"}
{"id": "13732858", "url": "https://en.wikipedia.org/wiki?curid=13732858", "title": "TekBots", "text": "TekBots\n\nTekBots are programmable robots used by several universities to help students learn some of the fundamental concepts that are found in the fields of computer and electrical engineering.\n\nTekBots are centered on the Atmel microcontroller platform. This is the \"brain\" of the robot as it controls the robot's two motorized wheels allowing it to move. The robot's controller boards, wheels and all other peripherals are housed in an aluminum base.\n\nThe original TekBots program was developed by the Oregon State University College of Engineering. Professors there wanted to provide a fun and interesting way for students to get excited about engineering. In 2000, the TekBots program was able to get off the ground with a $500,000 grant from the Oregon-based company, Tektronix inc.\n\nFreshman students entering Oregon State University's engineering program start out with $80 worth of electronics to build their initial TekBot. As the students take more and more classes while in the electrical and computer engineering program, more and more functionality is added to the robots; such as bump sensors to sense when the robot has struck a wall or LCD screens to display a message or even infrared (IR) transmitters and receivers to communicate with the robot.\n\nStudents program the robot using such software as AVR Studio 4 in order to write and compile a C program. The program is then transferred to the robot via a USB or parallel port dongle.\n\nThe TekBots program at Oregon State University is still seed-funded by Tektronix today.\n\nTekBots is currently offered by 5 universities worldwide:\n\n\nSeveral community colleges and other universities have also purchased TekBots over the years.\n\nAt most of the colleges the TekBot is used in an introduction to the electrical engineering course. At Oregon State they are used as a platform for learning in 10 classes. At Nebraska they are used in three classes in combination with the Mega 128 microcontroller. Also at Rochester they are used in digital logic courses as well as the microprocessor and introduction classes.\n\nBoth Nebraska and Oregon State combine the TekBot in integrating a freshman mentoring program.\n\nMany senior design projects at Oregon State are completed with the TekBot. An example was the Tekway, a Segway built using TekBots brains.\n\n\n\n"}
{"id": "21884508", "url": "https://en.wikipedia.org/wiki?curid=21884508", "title": "Thermal simulations for integrated circuits", "text": "Thermal simulations for integrated circuits\n\nMiniaturizing components has always been a primary goal in the semiconductor industry because it cuts production cost and lets companies build smaller computers and other devices. Miniaturization, however, has increased dissipated power per unit area and made it a key limiting factor in integrated circuit performance. Temperature increase becomes relevant for relatively small-cross-sections wires, where it may affect normal semiconductor behavior. Besides, since the generation of heat is proportional to the frequency of operation for switching circuits, fast computers have larger heat generation than slow ones, an undesired effect for chips manufacturers. This article summaries physical concepts that describe the generation and conduction of heat in an integrated circuit, and presents numerical methods that model heat transfer from a macroscopic point of view.\n\nAt macroscopic level, Fourier's law states a relation between the transmitted heat per unit time per unit area and the gradient of temperature:\n\nWhere formula_2 is the thermal conductivity, <nowiki>[</nowiki>W·m K<nowiki>]</nowiki>.\n\nElectronic systems work based on current and voltage signals. Current is the a flow of charged particles through the material and these particles (electrons or holes), interact with the lattice of the crystal losing its energy which is released in form of heat. Joule Heating is a predominant mechanism for heat generation in integrated circuits and is an undesired effect in most of the cases. For an ohmic material, it has the form:\n\nWhere formula_4 is the current density in <nowiki>[</nowiki>A·m<nowiki>]</nowiki>, formula_5 is the specific electric resistivity in <nowiki>[</nowiki>formula_6·m<nowiki>]</nowiki> and formula_7 is the generated heat per unit volume in <nowiki>[</nowiki>W·m<nowiki>]</nowiki>.\n\nThe governing equation of the physics of the heat transfer problem relates the flux of heat in space, its variation in time and the generation of power by the following expression:\n\nWhere formula_2 is the thermal conductivity, formula_10 is the density of the medium, formula_11 is the specific heat, formula_12, the thermal diffusivity and formula_13 is the rate of heat generation per unit volume. Heat diffuses from the source following the above equation and solution in an homogeneous medium follows a Gaussian distribution.\n\nTo get rid of the temperature dependence of formula_14, Kirchhoff transformation can be performed \n\nwhere formula_16 and formula_17 is the heat sink temperature. When applying this transformation, the heat equation becomes:\n\nwhere formula_19 is called the diffusivity, which also depends on the temperature. To completely linearize the equation, a second transformation is employed:\n\nformula_20\n\nyielding the expression:\n\nformula_21\n\nSimple, direct application of this equation requires approximation. Additional terms arising in the transformed Laplacian are dropped, leaving the Laplacian in its conventional form.\n\nAlthough analytical solutions can only be found for specific and simple cases, they give a good insight to deal with more complex situations. Analytical solutions for regular subsystems can also be combined to provide detailed descriptions of complex structures. In Prof. Batty's work, a Fourier series expansion to the temperature in the Laplace domain is introduced to find the solution to the linearized heat equation.\n\nThis procedure can be applied to a simple but nontrivial case: an homogeneous cube die made out of GaAs, L=300 um. The goal is to find the temperature distribution on the top surface. The top surface is discretized into smaller squares with index i=1...N. One of them is considered to be the source.\n\nTaking the Laplace transform to the heat equation:\nwhere formula_23\n\nFunction formula_24 is expanded in terms of cosine functions for the formula_25 and formula_26 variables and in terms of hyperbolic cosines and sines for formula_27 variable. Next, by applying adiabatic boundary conditions at the lateral walls and fix temperature at the bottom (heat sink temperature), thermal impedance matrix equation is derived:\n\nWhere the index formula_29 accounts for the power sources, while the index formula_30 refers to each small area.\n\nFor more details about the derivation, please see Prof. Batty's paper.\nThe below figure shows the steady state temperature distribution of this analytical method for a cubic die, with dimensions 300 um. A constant power source of 0.3W is applied over a central surface of dimension 0.1L x 0.1L. As expected, the distribution decays as it approaches to the boundaries, its maximum is located at the center and almost reaches 400K\n\nNumerical solutions use a mesh of the structure to perform the simulation. The most popular methods are: Finite difference time-domain (FDTD) method, Finite element method (FEM) and method of moments (MoM).\n\nThe finite-difference time-domain (FDTD) method is a robust and popular technique that consists in solving differential equations numerically as well as certain boundary conditions defined by the problem. This is done by discretizing the space and time, and using finite differencing formulas, thus the partial differential equations that describe the physics of the problem can be solved numerically by computer programs.\nThe FEM is also a numerical scheme employed to solve engineering and mathematical problems described by differential equations as well as boundary conditions. It discretizes the space into smaller elements for which basis functions are assigned to their nodes or edges. Basis functions are linear or higher order polynomials. Applying the differential equation and the boundary conditions of the problem to the basis functions, a system of equations is formulated using either the Ritz or Galerkin method. Finally, a direct or iterative method is employed to solve the system of linear equations. For the thermal case, FEM method is more suitable due to the nonlinearity nature of the thermal properties.\n\nThe previous example can be solved with a numerical method. For this case, the cube can by discretized into rectangular elements. Its basis functions can be chosen to be a first order approximation (linear):\n\nformula_31\n\nformula_32\n\nformula_33\n\nwhere formula_34. If formula_35, then formula_36.\n\nUsing this basis functions and after applying Galerkin's method to the heat transfer equation, a matrix equation is obtained:\n\nformula_37\n\nwhere,\n\nThis expressions can be evaluated by using a simple FEM code. For more details, please see. The figure below shows the temperature distribution for the numerical solution case. This solution shows very good agreement with the analytical case, its peak also reaches 390 K at the center. The apparent lack of smoothness of the distribution comes from the first order approximation of the basis functions and this can be solved by using higher order basis functions. Also, better results might be obtained by employing a denser mesh of the structure; however, for very dense meshes the computation time increases a lot, making the simulation non-practical.\n\nThe next figure shows a comparison of the peak temperature as a function of time for both methods. The system reaches steady state in approximately formula_41.\n\nThe numerical methods such as FEM or FDM derive a matrix equation as shown in the previous section. To solve this equation faster, a method called Model order reduction can be employed to find an approximation of lower order. This method is based on the fact that a high-dimensional state vector belongs to a low-dimensional subspace .\n\nFigure below shows the concept of the MOR approximation: finding matrix V, the dimension of the system can be reduced to solve a simplified system. \n\nTherefore, the original system of equation:\n\nbecomes:\n\nWhose order is much lower than the original making the computation much less expensive. Once the solution is obtained, the original vector is found by taking the product with V.\n\nThe generation of heat is mainly produced by joule heating, this undesired effect has limited the performance of integrated circuits. In the preset article heat conduction was described and analytical and numerical methods to solve a heat transfer problem were presented. Using these methods, steady state temperature distribution was computed as well as the peak temperature as a function of time for a cubic die. For an input power of formula_44 (or formula_45) applied over a single surface source on the top of a cubic die a peak increment of temperature in the order of 100 K was computed. Such increase in temperature can affect the behavior of surrounding semiconductor devices. Important parameters like mobility change drastically. That is why the heat dissipation is a relevant issue and must be considered for circuit designing.\n\n"}
{"id": "40686222", "url": "https://en.wikipedia.org/wiki?curid=40686222", "title": "Tubing spider", "text": "Tubing spider\n\nA Tubing spider is a tool used primarily in the oil industry for gripping the drill string while assembling or reassembling parts of the string.\n\nThe spider is normally operated hydraulically from a remote location. The spider consists of multiple gripper tools, sometimes constructed as wedge-shaped arms (Slips (oil drilling)) that holds the string by the downward force of the pipe. Teeth on the inside of the slips grip the pipe, and the resulting compressive force inward on the drill pipe holds the pipe securely.\n"}
{"id": "17318432", "url": "https://en.wikipedia.org/wiki?curid=17318432", "title": "WS-Atomic Transaction", "text": "WS-Atomic Transaction\n\nWeb Service Atomic Transaction is an OASIS standard. \nTo achieve all-or-nothing property for a group of services, it defines three protocols (completion, volatile two-phase commit, and durable two-phase commit), and a set of services. These protocols and services together ensure automatic activation, registration, propagation and atomic termination of web services. The protocols are implemented via the WS-Coordination context management framework and emulate ACID transaction properties.\n\nFollowing the standard, a distributed transaction has a coordinator, an initiator, and one or more participants.\n\n\n"}
{"id": "31331135", "url": "https://en.wikipedia.org/wiki?curid=31331135", "title": "Wafer bonding", "text": "Wafer bonding\n\nWafer bonding is a packaging technology on wafer-level for the fabrication of microelectromechanical systems (MEMS), nanoelectromechanical systems (NEMS), microelectronics and optoelectronics, ensuring a mechanically stable and hermetically sealed encapsulation. The wafers' diameter range from 100 mm to 200 mm (4 inch to 8 inch) for MEMS/NEMS and up to 300 mm (12 inch) for the production of microelectronic devices. Smaller wafers were used in the early days of the microelectronics industry, with wafers being just 1 inch in diameter in the 1950s.\n\nIn microelectromechanical systems (MEMS) and nanoelectromechanical systems (NEMS), the package protects the sensitive internal structures from environmental influences such as temperature, moisture, high pressure and oxidizing species. The long-term stability and reliability of the functional elements depend on the encapsulation process, as does the overall device cost. The package has to fulfill the following requirements:\n\nThe commonly used and developed bonding methods are as follows:\n\nThe bonding of wafers requires specific environmental conditions which can generally be defined as follows:\n\n\nThe actual bond is an interaction of all those conditions and requirements. Hence, the applied technology needs to be chosen in respect to the present substrate and defined specification like max. bearable temperature, mechanical pressure or desired gaseous atmosphere.\n\nThe bonded wafers are characterized in order to evaluate a technology's yield, bonding strength and level of hermeticity either for fabricated devices or for the purpose of process development. Therefore, several different approaches for the bond characterization have emerged. On the one hand non-destructive optical methods to find cracks or interfacial voids are used beside destructive techniques for the bond strength evaluation, like tensile or shear testing. On the other hand, the unique properties of carefully chosen gases or the pressure depending vibration behavior of micro resonators are exploited for hermeticity testing.\n\n"}
{"id": "31192428", "url": "https://en.wikipedia.org/wiki?curid=31192428", "title": "Way of the Roses", "text": "Way of the Roses\n\nThe Way of the Roses is the newest of Great Britain's coast-to-coast, long-distance cycle routes and is based on minor roads, disused railway lines and specially constructed cycle paths. It lies entirely within the counties of Lancashire and Yorkshire, crossing the Yorkshire Dales and the Yorkshire Wolds in the north of England, passing through the historic cities of Lancaster and York and scenic towns and villages including Settle, Pateley Bridge and Ripon.\n\nAt long, the route is designed for the whole range of cyclists, from families to cycling club riders. Although a challenge with some hard climbs—the highest point being over the route is steadily increasing in popularity. The route is fully open and signed.\n\nThe route is named after the Wars of the Roses, a fifteenth-century war between the English dynastic families Lancaster and York.\n\nThe route was developed by Sustrans and part of the National Cycle Network (NCN Route 69) in partnership with various Local Authorities, Lancaster City Council, Cyclists Touring Club, Bridlington Renaissance Partnership and Welcome to Yorkshire amongst others. The route was opened in 2010 running from Morecambe on the west coast of Lancashire to the east coast at Bridlington. A second diversion between Pateley Bridge and York that goes via Harrogate and Knaresborough was opened in 2011. Additionally, there is a section that links Kingston upon Hull to the cycle route that joins/leaves near Pocklington rather than going to/from Bridlington.\n\nA number of public artworks have been commissioned for the route. Matt Baker is currently developing a series of linked artworks at various points along the route. This work has not yet been completed.\n\nThe route is well signposted with signs carrying the name of the route or marked with the red and white heraldic roses from which the name of the route is derived.\n\nThe route starts in the resort town of Morecambe, Lancashire loosely following the River Lune and the River Wenning into the Pennines at Settle and entering into the stunning scenery of the Yorkshire Dales National Park. From there it makes its steepest climb (eastwards) across the edge of Rye Loaf Hill before descending to Airton. Thence it heads northeast to Grassington before following the River Wharfe for several miles and then turning towards the high point of the route at Greenhow and descending to Pateley Bridge on the River Nidd. Beyond Pateley Bridge the hills are significantly lower and after Ripon (with a short exception of the Yorkshire Wolds) the route is more or less flat, passing through York before finally reaching Bridlington and the North Sea. The route is made up primarily of:\n\n\nThe Way Of The Roses is best ridden from West to East to take advantage of the prevailing winds from the West and the more favourable gradients. Tradition dictates that you start the ride by dipping your back wheel in the Irish Sea and only ends when your front wheel gets a dip in the North Sea at the finish. It is typically completed in 3–5 days.\n\nThe Way of the Roses makes use of 8 National Cycle Network routes. Starting in Morecambe on Route 69. It transfers to Route 68 at Clapham on to Route 688 at Winterburn and Route 65 at Linton-on-Ouse Through central York it follows the short Route 658 before joining Route 66 At Pockington it takes Route 164 over the Yorkshire Wolds before picking up Route 1 near Hutton Cranswick which it then uses to the finish in Bridlington.\n\nThe route links to other parts of the NCN so can be used as part of a longer cycle tour. In addition to the above listed routes the way of the Roses has junctions with Route 700 at Morecambe Route 6 at Lancaster Route 67 near Fountains Abbey and Route 167 at Huggate in the Yorkshire Wolds\n\nRoute maps for The Way Of The Roses and detailed route guides from other publishers are available from Sustrans.\n\n"}
