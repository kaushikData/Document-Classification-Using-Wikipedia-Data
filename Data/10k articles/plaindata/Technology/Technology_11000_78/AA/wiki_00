{"id": "23365275", "url": "https://en.wikipedia.org/wiki?curid=23365275", "title": "Access IS", "text": "Access IS\n\nAccess-IS develops and manufactures electronic systems designed to accurately capture and transfer information into electronic systems based on 30 years’ experience in image processing, RFID/NFC technology and barcode reading. Access-IS also manufactures specialist keyboards for banking and PoS (Point of Sale) applications.\n\nOperating in over 72 countries Access-IS is focussed on three specialised verticals; Airline/Airport, ID Document Readers & Security and Transport Ticketing. In addition to its custom keyboards which are used by banks, trading floors, airlines and retailers, the product range also includes boarding gate readers, a range of document readers for ID document and age verification and paper and electronic ticket readers for ground transport and access control.\n\nAccess has its headquarters in Reading, UK, with approximately 60 salaried staff. In addition, it has a sales subsidiary in Atlanta, USA\n\nAccess IS is the trading name of Access Limited. For further information on the brand name, see below.\n\nAccess IS is an abbreviation of 'Access Interfacing Solutions'. Originally Access Keyboards Limited, the company was renamed Access Ltd and adopted the brand name Access IS in October 2007 to reflect the broader product offering the company offered. The new logo device was intended to allude to the company's history in keyboard design by using the shape of a keyboard return key. The two interlocking shapes that make up the logo device was intended to represent the process of interfacing to pass data between systems, or between media and host systems.\n\nOptical character recognition reading, MICR, Magnetic stripe card reading, biometric fingerprint readers, smart card and contactless smart card reading, e-passport decoding and reading, bar code scanners and airport boarding gate readers.\n\n1984 - The company was incorporated in December 1984 and was wholly owned by the Videcom Group of companies. Access IS (then named Access Keyboards) began trading January 1985.\n1989 - Became authorised distributor for Cherry keyboards.\n\n1992 - Gained ISO 9001 accreditation.\n1994 - Became autonomous in 1994 after a management buy-out with funding provided by 3i.\n1997 - First programmable point of sale keyboards launched.\n\n2004 - 3i’s shares were sold back to the company.\n2006 - Access manufacture BGR (boarding gate readers).\n2007 - Subsidiary established in Atlanta.\n2007 - Access Keyboards Limited renamed Access Limited, and began trading as Access-IS.\n2009 - Access-IS gained ISO 9001:2008. (Certificate No. 21703)\n2011 - Access-IS released a range of ID Document Readers for document authentification\n2014 - The Kingdom of Saudi Arabia accredited two Access-IS electronic passport readers for use by Hajj and Umrah tour operators and agents worldwide to process the passports of pilgrims.\n\n\n"}
{"id": "15040079", "url": "https://en.wikipedia.org/wiki?curid=15040079", "title": "Airsmith (HVAC)", "text": "Airsmith (HVAC)\n\nAn airsmith is an airflow technician who engineers, designs, builds, and repairs high pressure air pumps and compressors for practical use. \nEquipment used or dealt with can include: \nAn air conditioning & heating technician would be an example of an airsmith. \n"}
{"id": "12715119", "url": "https://en.wikipedia.org/wiki?curid=12715119", "title": "Amadeus CRS", "text": "Amadeus CRS\n\nAmadeus is a computer reservation system (or global distribution system, since it sells tickets for multiple airlines) owned by the Amadeus IT Group with headquarters in Madrid, Spain. The central database is located at Erding, Germany. The major development centers are located in Sophia Antipolis (France), Bangalore (India), London (UK), and Boston (United States). In addition to airlines, the CRS is also used to book train travel, cruises, car rental, ferry reservations, and hotel rooms. Amadeus also provides New Generation departure control systems to airlines. Amadeus IT Group is a transaction processor for the global travel and tourism industry. The company is structured around two key related areas—its global distribution system and its IT Solutions business area.\n\nAmadeus is a member of IATA, OTA and SITA. Its IATA airline designator code is 1A.\n\n\n\n"}
{"id": "2527996", "url": "https://en.wikipedia.org/wiki?curid=2527996", "title": "Automatic frequency control", "text": "Automatic frequency control\n\nIn radio equipment, Automatic Frequency Control (AFC), also called Automatic Fine Tuning (AFT), is a method or circuit to automatically keep a resonant circuit tuned to the frequency of an incoming radio signal. It is primarily used in radio receivers to keep the receiver tuned to the frequency of the desired station. \n\nIn radio communication, AFC is needed because, after the bandpass frequency of a receiver is tuned to the frequency of a transmitter, the two frequencies may drift apart, interrupting the reception. This can be caused by a poorly controlled transmitter frequency, but the most common cause is drift of the center bandpass frequency of the receiver, due to thermal or mechanical drift in the values of the electronic components.\nAssuming that a receiver is nearly tuned to the desired frequency, the AFC circuit in the receiver develops an error voltage proportional to the degree to which the receiver is mistuned. This error voltage is then fed back to the tuning circuit in such a way that the tuning error is reduced. In most frequency modulation (FM) detectors, an error voltage of this type is easily available. See Negative feedback.\n\nAFC was mainly used in radios and television sets around the mid-20th century. In the 1970s, receivers began to be designed using frequency synthesizer circuits, which synthesized the receiver's input frequency from a crystal oscillator using the vibrations of an ultra-stable quartz crystal. These maintained sufficiently stable frequencies that AFC's were no longer needed.\n\n\n"}
{"id": "194685", "url": "https://en.wikipedia.org/wiki?curid=194685", "title": "Baker's yeast", "text": "Baker's yeast\n\nBaker's yeast is the common name for the strains of yeast commonly used as a leavening agent in baking bread and bakery products, where it converts the fermentable sugars present in the dough into carbon dioxide and ethanol. Baker's yeast is of the species \"Saccharomyces cerevisiae\", which is the same species (but a different strain) commonly used in alcoholic fermentation, which is called brewer's yeast. Baker's yeast is also a single-cell microorganism found on and around the human body.\n\nThe use of steamed or boiled potatoes, water from potato boiling, or sugar in a bread dough provides food for the growth of yeasts; however, too much sugar will dehydrate them. Yeast growth is inhibited by both salt and sugar, but more so by salt than sugar. Some sources say fats, such as butter and eggs, slow down yeast growth; others say the effect of fat on dough remains unclear, presenting evidence that small amounts of fat are beneficial for baked bread volume.\n\n\"Saccharomyces exiguus\" (also known as \"S. minor\") is a wild yeast found on plants, fruits, and grains that is occasionally used for baking; however, in general it is not used in a pure form but comes from being propagated in a sourdough starter.\n\nIt is not known when yeast was first used to bake bread; the earliest definite records come from Ancient Egypt. Researchers speculate that a mixture of flour meal and water was left longer than usual on a warm day and the yeasts that occur in natural contaminants of the flour caused it to ferment before baking. The resulting bread would have been lighter and tastier than the previous hard flatbreads. It is generally assumed that the earliest forms of leavening were likely very similar to modern sourdough; the leavening action of yeast would have been discovered from its action on flatbread doughs, and would have been either cultivated separately or transferred from batch to batch by means of previously mixed (\"old\") dough. Also, the development of leavened bread seems to have developed in close proximity to the development of beer brewing, and barm from the beer fermentation process can also be used in bread making.\n\nWithout an understanding of microbiology, early bakers would have had little ability to directly control yeast cultures, but still kept locally interesting cultures by reusing doughs and starters to leaven later batches. However, it became possible to isolate and propagate favored yeast strains in the same manner as was done in the beer industry, and it eventually became practical to propagate yeast in a slurry with a composition similar to beer wort, usually including malted barley and wheat flour. Such cultures (sometimes referred to in old American cookery as \"emptins\", from their origins as the dregs of beer or cider fermentation) would become the ancestors of modern baker's yeast, as, in general, they were carefully maintained to avoid what would later be discovered to be bacterial contamination, including using preservatives such as hops as well as boiling the growth medium.\n\nIn the 19th century, bread bakers obtained their yeast from beer brewers, and this led to sweet-fermented breads such as the Imperial \"Kaiser-Semmel\" roll, which in general lacked the sourness created by the acidification typical of \"Lactobacillus\". However, beer brewers slowly switched from top-fermenting to bottom-fermenting yeast (both S. cerevisiae) and this created a shortage of yeast for making bread, so the Vienna Process was developed in 1846. While the innovation is often popularly credited for using steam in baking ovens, leading to a different crust characteristic, it is notable for including procedures for high milling of grains (see Vienna grits), cracking them incrementally instead of mashing them with one pass; as well as better processes for growing and harvesting top-fermenting yeasts, known as press-yeast.\n\nRefinements in microbiology following the work of Louis Pasteur led to more advanced methods of culturing pure strains. In 1879, Great Britain introduced specialized growing vats for the production of \"S. cerevisiae\", and in the United States around the turn of the century centrifuges were used for concentrating the yeast, making modern commercial yeast possible, and turning yeast production into a major industrial endeavor. The slurry yeast made by small bakers and grocery shops became cream yeast, a suspension of live yeast cells in growth medium, and then compressed yeast, the fresh cake yeast that became the standard leaven for bread bakers in much of the Westernized world during the early 20th century.\n\nDuring World War II, Fleischmann's developed a active dry yeast for the United States armed forces, which did not require refrigeration and had a longer shelf-life and better temperature tolerance than fresh yeast; it is still the standard yeast for US military recipes. The company created yeast that would rise twice as fast, cutting down on baking time. Lesaffre would later create instant yeast in 1973, which has gained considerable use and market share at the expense of both fresh and dry yeast in their various applications.\n\nBaker's yeast is available in a number of different forms, the main differences being the moisture contents. Though each version has certain advantages over the others, the choice of which form to use is largely a question of the requirements of the recipe at hand and the training of the cook preparing it. Dry yeast forms are good choices for longer-term storage, often lasting more than a year at room temperatures without significant loss of viability. In general, with occasional allowances for liquid content and temperature, the different forms of commercial yeast are considered interchangeable.\n\n\n\nFor most commercial uses, yeast of any form is packaged in bulk (blocks or freezer bags for fresh yeast; vacuum-packed brick bags for dry or instant); however, yeast for home use is often packaged in pre-measured doses, either small squares for compressed yeast or sealed packets for dry or instant. For active dry and instant yeast, in general a single dose (reckoned for the average bread recipe of between 500 g and 1000 g of dough) is about 2.5 tsp (~12 mL) or about , though comparatively lesser amounts are used when the yeast is used in a pre-ferment. In general, a yeast flavor in the baked bread is not noticeable when the bakers' percent of added yeast is less than 2.5%.\n\nBecause it is readily available and easy to culture, baker's yeast has long been used in chemical, biological, and genetic research as a model organism. In 1996, after 6 years of work, \"S. cerevisiae\" became the first eukaryote to have its entire genome sequenced. It has over 12 million base pairs and around 6000 genes. Since then, it has remained in the forefront of genetic research. For example, most of our knowledge of the cell division cycle was worked out from experiments with yeast.\n\nBaker's yeast contains enzymes that can reduce a carbonyl group into a hydroxyl group in fairly high yield, thus making it useful for biotransformations in organic syntheses. It is known to reduce organometallic carbonyl compounds in very high yield.\n\nBaker's yeast can also be used to produce ethanol via fermentation for use in chemical synthesis, although doing so in some places requires permits.\n\nThe baking industry relies on industrial production of its ingredients, including baking yeasts. Much effort has been put into developing and marketing yeasts that will perform reliably in mass production. Since the end of the nineteenth century, baker's yeast has been produced by companies that specialize in its production.\n\nThe main ingredients for industrial production are yeast cultures, cane and beet; but a number of minerals, nitrogen and vitamins are also needed.\n\nFermentation happens in several phases, which vary depending on the manufacturer:\nThe yeast grows from hundreds kg in the intermediate and stock fermentor to tens of thousands kg in the trade fermentor, where most yeast is produced. The earlier stages produce more ethanol and other alcohols, while in the final stages ethanol production is suppressed up to 95 % by controlling the amount of oxygen and sugar, in order to increase the yeast production instead.\n\nThe industry is highly concentrated, with 5 companies holding up to 80 % of the worldwide market for dry yeast as of 2006. While dry yeast is exported over long distances and mostly sold in the developing countries, industrial customers often prefer to supply fresh yeast from local facilities, with a single wholesaler having up to 90 % of liquid yeast market in UK in 2006. In USA companies like Lesaffre Group, AB Vista, DSM, GB Plange and AB Mauri, produced hundreds of thousands of metric tons of yeast in 2012.\n\n\n"}
{"id": "98918", "url": "https://en.wikipedia.org/wiki?curid=98918", "title": "Bolometer", "text": "Bolometer\n\nA bolometer is a device for measuring the power of incident electromagnetic radiation via the heating of a material with a temperature-dependent electrical resistance. It was invented in 1878 by the American astronomer Samuel Pierpont Langley.\n\nA bolometer consists of an absorptive element, such as a thin layer of metal, connected to a thermal reservoir (a body of constant temperature) through a thermal link. The result is that any radiation impinging on the absorptive element raises its temperature above that of the reservoir – the greater the absorbed power, the higher the temperature. The intrinsic thermal time constant, which sets the speed of the detector, is equal to the ratio of the heat capacity of the absorptive element to the thermal conductance between the absorptive element and the reservoir. The temperature change can be measured directly with an attached resistive thermometer, or the resistance of the absorptive element itself can be used as a thermometer. Metal bolometers usually work without cooling. They are produced from thin foils or metal films. Today, most bolometers use semiconductor or superconductor absorptive elements rather than metals. These devices can be operated at cryogenic temperatures, enabling significantly greater sensitivity.\n\nBolometers are directly sensitive to the energy left inside the absorber. For this reason they can be used not only for ionizing particles and photons, but also for non-ionizing particles, any sort of radiation, and even to search for unknown forms of mass or energy (like dark matter); this lack of discrimination can also be a shortcoming. The most sensitive bolometers are very slow to reset (i.e., return to thermal equilibrium with the environment). On the other hand, compared to more conventional particle detectors, they are extremely efficient in energy resolution and in sensitivity. They are also known as thermal detectors.\n\nThe first bolometer used by Langley consisted of two platinum strips covered with lampblack. One strip was shielded from radiation and one exposed to it. The strips formed two branches of a Wheatstone bridge which was fitted with a sensitive galvanometer and connected to a battery. Electromagnetic radiation falling on the exposed strip would heat it and change its resistance. By 1880, Langley's bolometer was refined enough to detect thermal radiation from a cow a quarter of a mile away. This radiant-heat detector is sensitive to differences in temperature of one hundred-thousandth of a degree Celsius (0.00001 C). This instrument enabled him to thermally detect across a broad spectrum, noting all the chief Fraunhofer lines. He also discovered new atomic and molecular absorption lines in the invisible infrared portion of the electromagnetic spectrum. Nikola Tesla personally asked Dr. Langley if he could use his bolometer for his power transmission experiments in 1892. Thanks to that first use, he succeeded in making the first demonstration between West Point and his laboratory on Houston Street.\n\nWhile bolometers can be used to measure radiation of any frequency, for most wavelength ranges there are other methods of detection that are more sensitive. For sub-millimeter wavelengths (from around 200 µm to 1 mm wavelength, also known as the far-infrared or terahertz), bolometers are among the most sensitive available detectors, and are therefore used for astronomy at these wavelengths. To achieve the best sensitivity, they must be cooled to a fraction of a degree above absolute zero (typically from 50 millikelvins to 300 mK). Notable examples of bolometers employed in submillimeter astronomy include the Herschel Space Observatory, the James Clerk Maxwell Telescope, and the Stratospheric Observatory for Infrared Astronomy (SOFIA).\n\nThe term bolometer is also used in particle physics to designate an unconventional particle detector. They use the same principle described above. The bolometers are sensitive not only to light but to every form of energy.\nThe operating principle is similar to that of a calorimeter in thermodynamics. However, the approximations, ultra low temperature, and the different purpose of the device make the operational use rather different. In the jargon of high energy physics, these devices are not called calorimeters since this term is already used for a different type of detector (see Calorimeter). Their use as particle detectors was proposed from the beginning of the 20th century, but the first regular, though pioneering, use was only in the 1980s because of the difficulty associated with cooling and operating a system at cryogenic temperature. They can still be considered to be at the developmental stage.\n\nA microbolometer is a specific type of bolometer used as a detector in a thermal camera. It is a grid of vanadium oxide or amorphous silicon heat sensors atop a corresponding grid of silicon. Infrared radiation from a specific range of wavelengths strikes the vanadium oxide or amorphous silicon, and changes its electrical resistance. This resistance change is measured and processed into temperatures which can be represented graphically. The microbolometer grid is commonly found in three sizes, a 640×480 array, a 320×240 array (384×288 amorphous silicon) or less expensive 160×120 array. Different arrays provide the same resolution with larger array providing a wider field of view. Larger, 1024×768 arrays were announced in 2008.\n\nThe hot electron bolometer (HEB) operates at cryogenic temperatures, typically within a few degrees of absolute zero. At these very low temperatures, the electron system in a metal is weakly coupled to the phonon system. Power coupled to the electron system drives it out of thermal equilibrium with the phonon system, creating hot electrons. Phonons in the metal are typically well-coupled to substrate phonons and act as a thermal reservoir. In describing the performance of the HEB, the relevant heat capacity is the electronic heat capacity and the relevant thermal conductance is the electron-phonon thermal conductance.\n\nIf the resistance of the absorbing element depends on the electron temperature, then the resistance can be used as a thermometer of the electron system. This is the case for both semiconducting and superconducting materials at low temperature. If the absorbing element does not have a temperature-dependent resistance, as is typical of normal (non-superconducting) metals at very low temperature, then an attached resistive thermometer can be used to measure the electron temperature.\n\nA bolometer can be used to measure power at microwave frequencies. In this application, a resistive element is exposed to microwave power. A dc bias current is applied to the resistor to raise its temperature via Joule heating, such that the resistance is matched to the waveguide characteristic impedance. After applying microwave power, the bias current is reduced to return the bolometer to its resistance in the absence of microwave power. The change in the dc power is then equal to the absorbed microwave power. To reject the effect of ambient temperature changes, the active (measuring) element is in a bridge circuit with an identical element not exposed to microwaves; variations in temperature common to both elements do not affect the accuracy of the reading. The average response time of the bolometer allows convenient measurement of the power of a pulsed source.\n\n\n"}
{"id": "52312791", "url": "https://en.wikipedia.org/wiki?curid=52312791", "title": "Brushcutter (garden tool)", "text": "Brushcutter (garden tool)\n\nA brushcutter (also called a brushsaw or clearing saw) is a powered garden or agricultural tool used to trim weeds, small trees, and other foliage not accessible by a lawn mower or rotary mower. Various blades or trimmer heads can be attached to the machine for specific applications.\n\nIt consists of:\n\nThere are three main types of power unit:\n\nThere are three types of shaft:\n\nHandles vary on brush cutters depending on weight and size of the unit. Larger, more powerful saws employ bike handles (two handlebars on either side of the shaft), and smaller units use a D-shaped handle mounted on the shaft. Heavier saws usually require harnesses for safety and reduced fatigue. The shaft on units requiring a harness has multiple slots for the harness to attach for balance of the entire unit.\n\nCutting heads include circular saw blades (chisel tooth or scratcher tooth), brush knives, grass blades, etc. Most brushcutters also allow other heads to be fitted, including bump feed and fixed line heads such as those used on line trimmers or modified saw blades such as a beaver blade which resembles a chainsaw. Deflectors are attached on the cutting side of the machine to prevent injury to the operator from debris thrown by the cutting head.\n\nPlastic or metal flails can be used for cutting stems too large for a line head but not requiring a blade. Following an incident in the UK in which when a metal chain link thrown from an aftermarket flail killed a bystander, all flail heads are now banned in the EU.\n"}
{"id": "58412722", "url": "https://en.wikipedia.org/wiki?curid=58412722", "title": "Butterfield dial", "text": "Butterfield dial\n\nA Butterfield dial is a portable horizontal sundial designed to be folded flat and used in latitudes between 35° and 60°. A Butterfield dial was named after the English gnomonist, Michael Butterfield who was active in Paris around 1690.\n\nThey were constructed with a hinged gnomon, whose angle could be adjusted for the latitude; the latitude was indicated by the beak of a bird. The gnomon was held in place by a rivet which was displayed by the birds eye, and thumbscrew. \nThe dial plate would have three chapter rings for 44°, 48° and 52° which would be sufficiently accurate to be used between 35° and 60° (roughly between Gibraltar to the Shetland Isles). There would also be a compass and a plumb bob.\nMichael Butterfield (1635-1724) was a British clockmaker who moved to Paris about 1663. He worked at the royal court was appointed engineer to the King Louis XIV. He opened a shop selling precision instruments in 1677 in rue Neuve-des-Fossés, in Saint-Germain. He sold all types of sundial, but dominated the market for the small travelling dial with the adjustable gnomonwith bird motif and three chapter rings. This type of dial became fashionable and called the Butterfield dial. This type of dial was known before Butterfield manufactured them, for instance Roch Blondeau and Timothee Collet, and other instrument makers in Paris and beyond, continued to make them particularly after his death. Among his international clients was the Russian Czar Peter the Great who visited his shop in 1717 and ordered a great quantity of gilt copper dials.\n\nNicolas Bion (1652-1735), in his 1709 book, *The Construction and Principal Uses of Mathematical Instruments on page 322 and plate 26, gives a clear description of the construction and usage of such dials.\n"}
{"id": "54853196", "url": "https://en.wikipedia.org/wiki?curid=54853196", "title": "Claudia Olsson", "text": "Claudia Olsson\n\nClaudia Olsson (born 27 December 1983) is a Swedish technology expert, business leader, and speaker with a background in engineering and economics. She is CEO and founder of Exponential AB, founder of Stellar Capacity AB, an Associate Faculty member at Singularity University, a David Rockefeller Fellow at the Trilateral Commission, as well as a Young Global Leader with the World Economic Forum.\n\nOlsson started her career as Project Manager of the Stockholm International Youth Science Seminar for the Nobel Prize Committee and the Federation of Young Scientists. She then worked for the Swedish Trade Council in Warsaw and the United Nations Economic and Social Council (ECOSOC) in New York City. She set up and managed the policy think-tank ACCESS Health International in Singapore following her work for ACCESS in India. She then served as a Senior Advisor to the Office of Strategic Analysis at the Ministry for Foreign Affairs in Sweden. From 2010 to 2015, Olsson served as a board member of Project Playground, a Swedish non-profit organization aiming to improve the life opportunities of children and youth in South Africa. In 2014, Olsson founded Exponential AB, a global education company. Exponential has among other notable missions been tasked to author the \"Sweden 2030 Future Scenario\" for the Digitalization Commission of the Government of Sweden, a report released in 2016 focusing on the digital, integrated, smart and competitive society. Olsson also co-authored the report “Blockchain-Decentralized Trust”  for the Entrepreneurship Forum. Also in 2014, Olsson founded Stellar Capacity AB, known as \"Swedish for Professionals\", a leading education company working to help professionals integrate in the Swedish society and to learn Swedish. The company has developed its own methodology leveraging new technologies and blended learning technique and aims to prepare citizens for a more globalized world. The same year, she became an Associate Faculty member at Singularity University following her engagement with the university as an advisor on Global Grand Challenges in 2013. In 2016, she was appointed a European David Rockefeller Fellow to the Trilateral Commission. In 2017, Olsson co-founded the executive program Decoding X at the Stockholm School of Economics. The same year, she began her engagement with the World Economic Forum in their Europe Policy Group. She also shares insights into technology and globalization through the editorial column of SvD.\n\nOlsson has studied International Economics and Business at Stockholm School of Economics as well as Industrial Engineering at KTH Royal Institute of Technology. She has also studied at INSA Lyon, France and in Karlsruhe University, Germany. In 2001, she was among the 21 students selected to attend the inaugural program of the Raoul Wallenberg Academy. In 2009, Olsson was appointed the Energy Student of the Year in Sweden. In 2010, Olsson was the first Swedish participant to attend Singularity University's Graduate Studies Program. In 2017, she was selected for the Bucerius Summer School on Global Governance\n\nIn 2018, Olsson was appointed a member of the High Level Industrial Roundtable \"Industry 2030\" at the European Commission as well as a European Young Leader (EYL40) by the Friends of Europe. In 2017, Olsson was appointed a Young Global Leader by the World Economic Forum. In 2016, she was appointed a European David Rockefeller Fellow at the Trilateral Commission, ranked as one of the top 99 most impactful individuals of the future by TCO, and ranked as one of Sweden’s most inspiring female engineers by Ny Teknik. In 2015, she was ranked as one of Sweden’s Top-10 Speakers 2014 by Talarforum. In 2014, she was ranked top 10 of Sweden’s Business Talents by 4Potentials and Svenska Dagbladet. In 2012, she was selected for the Symposium for Leaders of the Next Generation by the Star Foundation in Penglai, China and as a Gifted Citizen and Finalist in the Global Impact Project Competition for La Ciudad de las ideas in Mexico. In 2011, she was appointed as The Young Leader of the Year in Sweden by 4Potentials, Ledarstudion, and SvD. In 2010, she was the Nova of the Year (Top Talent) in Sweden, appointed a Future Leader of Tomorrow at the St. Gallen Symposium in Switzerland, and ranked as one of Sweden's 101 Supertalents in the Business Magazine Veckans Affärer.\n\n"}
{"id": "51713681", "url": "https://en.wikipedia.org/wiki?curid=51713681", "title": "Constellation shaping", "text": "Constellation shaping\n\nConstellation shaping is an energy efficiency enhancement scheme for digital signal modulation that improves upon the amplitude and phase-shift keying (APSK) and the conventional quadrature amplitude modulation (QAM)) modulation schemes by transmitting low-energy signals more frequently than high-energy ones.\n\n\"Constellation\" is a pattern of the possible signal combinations; in a static constellation, all of the combinations are used equally. In the real world, however, the transmission media (channel) distorts the signal unevenly; some combinations require lower energy and resist channel noise more than others.\n\nA \"shaped constellation\" transmission sends some signal combinations more often and others less frequently to optimize the signal quality at the destination or to maintain the same quality using less transmission energy.\n\nProbabilistic (and adaptive) constellation shaping changes the shaping parameters based on predefined terms. This allows a significant capacity increase (e.g. 15–43% on 16-QAM channel). This technique gathered more interest in September 2016 when Nokia Bell Labs demonstrated working 1 Tbit/s data transmission channels between German cities. In October 2016, Alcatel-Lucent and Nokia Bell Labs claimed to have achieved 65 Tbit/s transmission over a 6,600 km (4,100 mile) single mode fiber in laboratory trials.\n\n"}
{"id": "36316650", "url": "https://en.wikipedia.org/wiki?curid=36316650", "title": "Current conveyor", "text": "Current conveyor\n\nA current conveyor is an abstraction for a three terminal analogue electronic device. It is a form of electronic amplifier with unity gain. There are three versions of generations of the idealised device, CCI, CCII and CCIII. When configured with other circuit elements, real current conveyors can perform many analogue signal processing functions, in a similar manner to the way op-amps and the ideal concept of the op-amp are used.\n\nWhen Sedra and Smith first introduced the current conveyor in 1968, it was not clear what the benefits of the concept would be. The idea of the op-amp had been well known since the 1940s and integrated circuit manufacturers were better able to capitalise on this widespread knowledge within the electronics industry. Monolithic current conveyor implementations were not introduced and the op-amp became widely implemented. Since the early 2000s, implementations of the current conveyor concept, especially within larger VLSI projects such as mobile phones, have proved worthwhile.\n\nCurrent conveyors can provide better gain-bandwidth products than comparable op-amps, under both small and large signal conditions. In instrumentation amplifiers, their gain does not depend on the matching of pairs of external components, only on the absolute value of a single circuit element.\n\nThe CCI is a three-terminal device with the terminals designated \"X\", \"Y\", and \"Z\". The potential at \"X\" equals whatever voltage is applied to \"Y\". Whatever current flows into \"Y\" also flows into \"X\", and is mirrored at \"Z\" with a high output impedance, as a variable constant current source. In sub-type CCI+, current into \"Y\" produces current into \"Z\"; in a CCI-, current into \"Y\" results in an equivalent current flowing \"out\" of \"Z\".\n\nIn a more versatile later design, no current flows through terminal \"Y\". The ideal CCII can be seen as an ideal transistor, with perfected characteristics. No current flows into the gate or base which is represented by \"Y\". There is no base-emitter or gate-source voltage drop, so the emitter or source voltage (at \"X\") follows the voltage at \"Y\". The gate or base has an infinite input impedance (\"Y\"), while the emitter or source has a zero input impedance (\"X\"). Any current out of the emitter or source (\"X\") is reflected at the collector or drain (\"Z\") as a current in, but with an infinite output impedance. Because of this reversal of sense between \"X\" and \"Z\" currents, this ideal bipolar or field-effect transistor represents a CCII−. If current flowing out of \"X\" resulted in the same high-impedance current flowing \"out\" of \"Z\", it would be a CCII+.\n\nThe third configuration of the current conveyor is similar to the CCI except that the current in \"X\" is reversed, so in a CCIII whatever current flows into \"Y\" also flows out of \"X\".\n\n"}
{"id": "50786173", "url": "https://en.wikipedia.org/wiki?curid=50786173", "title": "Data-oriented design", "text": "Data-oriented design\n\nIn computing, data-oriented design is a program optimization approach motivated by cache coherency, used in video game development (usually in the programming languages C or C++). The approach is to focus on the data layout, separating and sorting fields according to when they are needed, and to think about transformations of data. Proponents include Mike Acton and Scott Meyers. \n\nThese methods became especially popular during the seventh generation of video game consoles that included PlayStation 3 (PS3) and Xbox 360, when the hazards of cache misses became especially pronounced, due to their use of in-order processors with high clock speeds and deep pipelines (some of the software issues were similar to those encountered on the Itanium, requiring loop unrolling for upfront scheduling). In modern systems (even with out of order execution), main memory is as many as hundreds of clock cycles away from the processing elements; consequently locality of reference issues dominate performance, requiring improvement of memory access patterns to fix. Game consoles often have relatively weak central processing units (CPUs) to devote more power and transistor budget to the graphics processing units (GPUs). Thus, it is critical that CPU side code is efficient to avoid Von Neumann bottlenecking.\n\nThe claim is that traditional object-oriented programming (OOP) design principles result in poor data locality, more so if runtime polymorphism (dynamic dispatch) is used (which is especially problematic on some processors). Although OOP does superficially seem to \"organise code around data\", the practice is quite different. OOP is actually about organising source code around data types, rather than physically grouping individual fields and arrays in a format efficient for access by specific functions. It also often hides layout details under abstraction layers, while a data-oriented programmer wants to consider this first and foremost.\n\nThe experimental programming language JAI being developed by Jonathan Blow has explicit support for data-oriented design, while eschewing the traditional OOP paradigm. This is facilitated by being able to transparently move fields between records without extensive source code changes to functions using them (or without extensive boilerplate code to enable this), and by adding direct support for \"structure of arrays\" (SoA) data layout.\n\n"}
{"id": "3689264", "url": "https://en.wikipedia.org/wiki?curid=3689264", "title": "Design closure", "text": "Design closure\n\nIn VLSI semiconductor manufacturing, the process of Design Closure is a part of the development workflow by which an integrated circuit design is modified from its initial description to meet a growing list of design constraints and objectives.\n\nEvery step in the IC design (such as static timing analysis, placement, routing, and so on) is already complex and often forms its own field of study. This article, however, looks at the overall design closure process, which takes a chip from its initial design state to the final form in which all of its design constraints are met.\n\nEvery chip starts off as someone’s idea of a good thing: \"If we can make a part that performs function X, we will all be rich!\" Once the concept is established, someone from marketing says \"To make this chip profitably, it must cost $C and run at frequency F.\" Someone from manufacturing says \"To meet this chip’s targets, it must have a yield of Y%.\" Someone from packaging says “It must fit in the P package and dissipate no more than W watts.” Eventually, the team generates an extensive list of all the constraints and objectives they must meet to manufacture a product that can be sold profitably. The management then forms a design team, which consists of chip architects, logic designers, functional verification engineers, physical designers, and timing engineers, and assigns them to create a chip to the specifications.\n\nThe distinction between constraints and objectives is straightforward: a constraint is a design target that must be met for the design to be successful. For example, a chip may be required to run at a specific frequency so it can interface with other components in a system. In contrast, an objective is a design target where more\n(or less) is better. For example, yield is generally an objective, which is maximized to lower manufacturing cost. For the purposes of design closure, the distinction between constraints and objectives is not important; this article uses the words interchangeably.\n\nDesigning a chip used to be a much simpler task. In the early days of VLSI, a chip consisted of a few thousand logic circuits that performed a simple function at speeds of a few MHz. Design closure was simple: if all of the necessary circuits and wires \"fit\", the chip would perform the desired function.\n\nModern design closure has grown orders of magnitude more complex. Modern logic chips can have tens to hundreds of millions of logic elements switching at speeds of several\nGHz. This improvement has been driven by Moore’s law of scaling of technology, and has introduced many new design considerations. As a result, a modern VLSI designer must consider the performance of a chip against a list of dozens of design constraints and objectives including performance, power, signal integrity, reliability, and yield. In response to this growing list of constraints, the design closure flow has evolved from a simple linear list of tasks to a very complex, highly iterative flow such as the following simplified ASIC design flow:\n\n\nThe purpose of the flow is to take a design from concept phase to working chip. The complexity of the flow is a direct result of the addition and evolution of the list of design closure constraints. To understand this evolution it is important to understand the life cycle of a design constraint. In general, design constraints influence the design flow via the following five-stage evolution:\n\nA good example of this evolution can be found in the signal integrity constraint. In the mid-1990s (180 nm\nnode), industry visionaries were describing the impending dangers of coupling noise long before chips were\nfailing. By the mid-late 1990s, noise problems were cropping up in advanced microprocessor designs.\nBy 2000, automated noise analysis tools were available and were used to guide manual fix-up. The total\nnumber of noise problems identified by the analysis tools identified by the flow quickly became too many\nto correct manually. In response, CAD companies developed the noise avoidance flows that are currently in\nuse in the industry.\n\nAt any point in time, the constraints in the design flow are at different stages of their life cycle. At the\ntime of this writing, for example, performance optimization is the most mature and is well into the fifth\nphase with the widespread use of timing-driven design flows. Power- and defect-oriented yield optimization\nis well into the fourth phase; power supply integrity, a type of noise constraint, is in the third phase;\ncircuit-limited yield optimization is in the second phase, etc. A list of the first-phase impending constraint\ncrises can always be found in the International Technology Roadmap for Semiconductors (ITRS) 15-year-outlook technology roadmaps.\n\nAs a constraint matures in the design flow, it tends to work its way from the end of the flow to the beginning.\nAs it does this, it also tends to increase in complexity and in the degree that it contends with other constraints.\nConstraints tend to move up in the flow due to one of the basic paradoxes of design: accuracy vs.\ninfluence. Specifically, the earlier in a design flow a constraint is addressed, the more flexibility there is to\naddress the constraint. Ironically, the earlier one is in a design flow, the more difficult it is to predict compliance.\nFor example, an architectural decision to pipeline a logic function can have a far greater impact on\ntotal chip performance than any amount of postrouting fix-up. At the same time, accurately predicting the\nperformance impact of such a change before the chip logic is synthesized, let alone placed or routed, is very\ndifficult. This paradox has shaped the evolution of the design closure flow in several ways. First, it requires\nthat the design flow is no longer composed of a linear set of discrete steps. In the early stages of VLSI it was\nsufficient to break the design into discrete stages, i.e., first do logic synthesis, then do placement, then do\nrouting. As the number and complexity of design closure constraints has increased, the linear design flow\nhas broken down. In the past if there were too many timing constraint violations left after routing, it was\nnecessary to loop back, modify the tool settings slightly, and reexecute the previous placement steps. If the\nconstraints were still not met, it was necessary to reach further back in the flow and modify the chip logic\nand repeat the synthesis and placement steps. This type of looping is both time consuming and unable to\nguarantee convergence i.e., it is possible to loop back in the flow to correct one constraint violation only to\nfind that the correction induced another unrelated violation.\n\n\n"}
{"id": "1503112", "url": "https://en.wikipedia.org/wiki?curid=1503112", "title": "Domed city", "text": "Domed city\n\nA domed city is a hypothetical structure that encloses a large urban area under a single roof. In most descriptions, the dome is airtight and pressurized, creating a habitat that can be controlled for air temperature, composition and quality, typically due to an external atmosphere (or lack thereof) that is inimical to habitation for one or more reasons. Domed cities have been a fixture of science fiction and futurology since the early 20th century, and may be situated on Earth, a moon or other planet.\n\nIt is not clear exactly when the concept of a domed city first appeared. The phrase \"domed city\" had come into use by the 19th century in a different sense, meaning a skyline with dome-topped buildings. One catalog of early science fiction mentions the 1881 socialist and white supremacist fantasy \"Three Hundred Years Hence\" by British author William Delisle Hay. Hay's book describes a future civilization where most of humanity lives in glass-domed cities beneath the sea, allowing the surface of the earth to be used primarily for agriculture. Several examples from the early 20th century are also listed.\n\nAuthors used domed cities in response to many problems, sometimes to the benefit of the people living in them and sometimes not. The problems of air pollution and other environmental destruction are a common motive, particularly in stories of the middle to late 20th century. As in the \"Pure\" trilogy of books by Julianna Baggott. In some works, the domed city represents the last stand of a human race that is either dead or dying. The 1976 film \"Logan's Run\" shows both of these themes. The characters have a comfortable life within a domed city, but the city also serves to control the populace and to ensure that humanity never again outgrows its means.\n\nThe domed city in fiction has been interpreted as a symbolic womb that both nourishes and protects humanity. Where other science fiction stories emphasize the vast expanse of the universe, the domed city places limits on its inhabitants, with the subtext that chaos will ensue if they interact with the world outside.\n\nIn some works cities are getting \"domed\" to quarantine its inhabitants.\n\n\nDuring the 1960s and 1970s, the domed city concept was widely discussed outside the confines of science fiction. In 1960, visionary engineer Buckminster Fuller described a 3 km geodesic dome spanning Midtown Manhattan that would regulate weather and reduce air pollution. A domed city was proposed in 1979 for Winooski, Vermont and in 2010 for Houston.\n\nIn order to test whether an artificial closed ecological system was feasible, Biosphere 2 (a complex of interconnected domes and glass pyramids) was constructed in the late 1980s. Its original experiment housed eight people and remains the largest such system attempted to date.\n\nIn 2010, a domed city known as Eco-city 2020 of 100,000 was proposed for the Mir mine in Siberia. In 2014, the ruler of Dubai announced plans for a climate-controlled domed city covering an area of 48 million square feet (4.5 square kilometers).\n\n"}
{"id": "12296287", "url": "https://en.wikipedia.org/wiki?curid=12296287", "title": "EFaktura", "text": "EFaktura\n\neFaktura is a Norwegian electronic billing system issued by Nets Branch Norway AS (Nets). The system involves both business-to-customer (B2C) systems, branded as eFaktura, and business-to-business (B2B) branded as eFaktura B2B. The system is built upon the bankgiro system used for online banking.\n\nUse of eFaktura require the customer to use an online banking system from a Norwegian bank. Because all banks are connected to BBS, there is no discrimination between customers of different banks. Any company or organisation can sign an eFaktura agreement with their bank (though usually for a typically five-digit NOK startup fee) and send electronic bills to any client as long as they have a Norwegian online banking account. There is no requirement for the two to use the same bank. The ordinary eFaktura includes a specification of the bill, and the entire bill or invoice can be seen in the online banking system, and printed if so desired. eFaktura was launched in 2000.\n\nFor companies the eFaktura B2B has been developed. Companies using electronic billing need to be able to import the invoice directly into the accounting software of the company. Nets offers services to send out paper bills to any company not able to receive electronic billing. eFaktura B2B was launched in 2006.\n\n"}
{"id": "6358896", "url": "https://en.wikipedia.org/wiki?curid=6358896", "title": "Electric aircraft", "text": "Electric aircraft\n\nAn electric aircraft is an aircraft powered by electric motors. Electricity may be supplied by a variety of methods including batteries, ground power cables, solar cells, ultracapacitors, fuel cells and power beaming.\n\nElectrically powered model aircraft have been flown since the 1970s, with one unconfirmed report as early as 1957. They have since developed into small battery-powered unmanned aerial vehicles or drones, which in the twenty-first century have become widely used for many purposes.\n\nAlthough manned flights in a tethered helicopter go back to 1917 and in airships to the previous century, the first manned free flight by an electrically powered aeroplane was not made until 1973 and most manned electric aircraft today are still only experimental demonstrators. Between 2015 and 2016, Solar Impulse 2 completed a circumnavigation of the Earth.\n\nAll electric aircraft to date have been powered by electric motors driving thrust-generating propellers or lift-generating rotors. Some of the propeller-driven types have been airships.\n\nMechanisms for storing and supplying the necessary electricity vary considerably, and each has distinct advantages and disadvantages. Mechanisms used include:\n\nBatteries are the most common energy carrier component of electric aircraft, due to their relatively high capacity. Batteries were the earliest source of electricity, first powering airships in the nineteenth century. These early batteries were very heavy and it was not until the arrival of technologies such as nickel-cadmium (NiCad) rechargeable types in the second half of the twentieth century, that batteries became a practicable power source. Modern battery types include lithium-based and a number of other less widely used technologies. Such batteries remain a popular power source today, although they still have limited life between charges and hence limited range.\n\nBatteries are also often used for temporary storage of electricity generated by another source.\n\nAn electrical power cable may be connected to a ground-based supply, such as an electric generator. At low altitudes this can avoid carrying heavy batteries and was used by the experimental Petróczy-Kármán-Žurovec PKZ-1 observation helicopter of 1917. However such a craft must remain tethered to a ground facility, and the higher it flies, the heavier the weight of cable it must lift with it.\n\nA solar cell converts sunlight directly into electricity, either for direct power or temporary storage. The power output of solar cells is small, even when many are connected together, which limits their use and is also expensive. However their use of freely available sunlight makes them attractive for high-altitude, long-endurance applications.\n\nFor endurance flights, keeping the craft in the air all night typically requires a backup storage system, which supplies power during the hours of darkness and recharges during the day.\n\nAn ultracapacitor can store a limited amount of energy for short bursts of high-power use, such as when taking off, but due to its relatively small storage ability it is not suitable as a primary power source. Its advantage over a small battery is the ability to charge and discharge much faster with higher peak currents.\n\nA fuel cell uses the reaction between two fluids such as hydrogen and oxygen to create electricity. Unlike a battery, the fluids are not stored in the battery but are drawn in from outside. This offers the prospect of much greater range than batteries and experimental examples have flown, but the technology has yet to reach production.\n\nPower beaming of electromagnetic energy such as microwaves, like a power cable, requires a ground-based power source. However, compared to a power cable, power beaming carries much less weight penalty as altitude increases. The technology has been demonstrated on small models but awaits practical development.\n\nThe use of electricity for aircraft propulsion was first experimented with during the development of the airship which took place in the latter part of the nineteenth century. On 8 October 1883, Gaston Tissandier flew the first electrically-powered airship. The following year, Charles Renard and Arthur Krebs flew La France with a more powerful motor. Even with the lifting capacity of an airship, the heavy accumulators needed to store the electricity severely limited the speed and range of such early airships.\n\nFor a tethered device such as an air observation platform, it is possible to run the power up the tether. In an attempt to create a more practical solution than the clumsy balloons then in use, the Austro-Hungarian Petróczy-Kármán-Žurovec PKZ-1 electric-powered helicopter was flown in 1917. It had a specially-designed continuous-rated electric motor made by Austro-Daimler and received its power up a cable from a ground-based DC generator. However electric motors were not yet powerful enough for such applications and the motor burned out after only a few flights.\n\nIn 1909, an electric free flight model was claimed to have been flown eight minutes, but this claim was disputed by the builder of the first recorded electric Radio-Controlled model aircraft flight in 1957.\nPower density for electric flight is problematic even for small models.\n\nIn 1964, William C. Brown at Raytheon flew a model helicopter that received all of the power needed for flight by microwave power transmission.\n\nSuccess in a full-sized aeroplane would not be achieved until Nickel-cadmium (NiCad) batteries were developed, having a much higher storage-to-weight ratio than older technologies. In 1973, Fred Militky and Heino Brditschka converted a Brditschka HB-3 motor glider to an electric aircraft, the Militky MB-E1. It flew for just 14 minutes to become the first manned electric aircraft to fly under its own power.\n\nDeveloped almost in parallel with NiCad technology, solar cells were also slowly becoming a practicable power source. Following a successful model test in 1974, the world’s first official flight in a solar-powered, man-carrying aircraft took place on April 29, 1979. The Mauro Solar Riser used photovoltaic cells to deliver 350 watts at 30 volts. These charged a small battery, which in turn powered the motor. The battery alone was capable of powering the motor for 3 to 5 minutes, following a 1.5-hour charge, enabling it to reach a gliding altitude.\n\nUnder the direction of Freddie To, an architect and member of the Kremer prize committee, the Solar One was designed by David Williams and produced by Solar-Powered Aircraft Developments. A motor-glider type aircraft originally built as a pedal-powered airplane to attempt the Channel crossing, the airplane proved too heavy to be successfully powered by human power and was then converted to solar power, using an electric motor driven by batteries that were charged before flight by a solar cell array on the wing. The maiden flight of Solar One took place at Lasham Airfield, Hampshire, on June 13, 1979.\n\nFollowing successful human-powered flight, a relaunched Kremer prize allowed the crew to store energy before takeoff. In the 1980s several such designs stored electricity generated by pedalling, including the Massachusetts Institute of Technology Monarch and the Aerovironment Bionic Bat.\n\nThe human piloted Solair 1, developed by Günther Rochelt, flew in 1983 with notably improved performance. It employed 2499 wing-mounted solar cells.\n\nThe German solar-powered aircraft \"Icaré II\" was designed and built by the institute of aircraft design (Institut für Flugzeugbau) of the University of Stuttgart in 1996. The leader of the project and often pilot of the aircraft is Rudolf Voit-Nitschmann the head of the institute. The design won the Berblinger prize in 1996, the EAA Special Achievement Award in Oshkosh, the Golden Daidalos Medal of the German Aeroclub and the OSTIV-Prize in France in 1997.\n\nNASA's Pathfinder, Pathfinder Plus, Centurion, and Helios were a series of solar and fuel cell system–powered unmanned aerial vehicles (UAVs) developed by AeroVironment, Inc. from 1983 until 2003 under NASA's Environmental Research Aircraft and Sensor Technology program. On September 11, 1995, Pathfinder set an unofficial altitude record for solar-powered aircraft of during a 12-hour flight from NASA Dryden. After further modifications, the aircraft was moved to the U.S. Navy's Pacific Missile Range Facility (PMRF) on the Hawaiian island of Kauai. On July 7, 1997, Pathfinder raised the altitude record for solar–powered aircraft to , which was also the record for propeller–driven aircraft.\n\nOn August 6, 1998, Pathfinder Plus raised the national altitude record to for solar-powered and propeller-driven aircraft.\n\nOn August 14, 2001 Helios set an altitude record of – the record for FAI class U (experimental/new technologies), and FAI class U-1.d (remotely controlled UAV: mass 500 kg to less than 2,500 kg) as well as the altitude record for propeller–driven aircraft. On June 26, 2003, the Helios prototype broke up and fell into the Pacific Ocean off Hawaii after the aircraft encountered turbulence, ending the program.\n\nThe QinetiQ Zephyr is a lightweight solar-powered unmanned aerial vehicle (UAV). As of 23 July 2010 it holds the endurance record for an unmanned aerial vehicle of over 2 weeks (336 hours). It is of carbon fiber-reinforced polymer construction, the 2010 version weighing (the 2008 version weighed ) with a span of 22.5 metres (the 2008 version had ). During the day it uses sunlight to charge lithium-sulphur batteries, which power the aircraft at night. In July 2010 a Zephyr made a world record UAV endurance flight of 336 hours, 22 minutes and 8 seconds (more than two weeks) and also set an altitude record of for FAI class U-1.c (remotely controlled UAV: weight 50 kg to less than 500 kg).\n\nThe first commercially available, non-certified production electric aircraft, the Alisport Silent Club self-launching glider plane, flew in 1997. It is optionally driven by a DC electric motor running on of batteries that store 1.4 kWh of energy.\n\nThe first certificate of airworthiness for an electric powered aircraft was granted to the Lange Antares 20E in 2003. Also an electric, self-launching 20-meter glider/sailplane, with a 42-kilowatt DC/DC brushless motor and lithium-ion batteries, it can climb up to 3,000 meters with fully charged cells. The first flight was in 2003. In 2011 the aircraft won the 2011 Berblinger competition.\n\nIn 2005, Alan Cocconi of AC Propulsion flew, with the assistance of several other pilots, an unmanned airplane named \"SoLong\" for 48 hours non-stop, propelled entirely by solar energy. This was the first such around-the-clock flight, on energy stored in the batteries mounted on the plane.\n\nIn 2007, the non-profit CAFE Foundation held the first Electric Aircraft Symposium in San Francisco.\n\nThe Boeing-led FCD (fuel cell demonstrator) project uses a Diamond HK-36 Super Dimona motor glider as a research test bed for a hydrogen fuel cell powered light airplane. Successful flights took place in February and March 2008.\n\nThe first the NASA Green Flight Challenge took place in 2011 and was won by a Pipistrel Taurus G4 on 3 October 2011.\n\nIn 2013 Chip Yates demonstrated that the world's fastest electric plane, a Long ESA, a modified Rutan Long-EZ, could outperform a gasoline-powered Cessna and other aircraft in a series of trials verified by the Fédération Aéronautique Internationale. The Long ESA was found to be less expensive, have a higher maximum speed, and higher rate of climb, partly due to the ability of the aircraft to maintain performance at altitude as no combustion takes place.\n\nIn 2017, Siemens used a modified Extra EA-300 acrobatic airplane, the 330LE, to set two new records: on March 23 at the Dinslaken Schwarze Heide airfield in Germany, the aircraft reached a top speed of around over three kilometers; the next day, it became the first glider towing electric aircraft.\n\nSolar Impulse 2 is powered by four electric motors. Energy from solar cells on the wings and horizontal stabilizer is stored in lithium polymer batteries and used to drive propellers. In 2012 the first Solar Impulse made the first intercontinental flight by a solar plane, flying from Madrid, Spain to Rabat, Morocco.\n\nCompleted in 2014, Solar Impulse 2 carried more solar cells and more powerful engines, among other improvements. In March 2015, the plane took off on the first stage of a planned round-the-world trip, flying Eastwards from Abu Dhabi, United Arab Emirates. Due to battery damage, the craft halted at Hawaii until April 2016. On 23 June 2016 the plane reached Seville, Spain. It has since returned to Abu Dhabi, completing its circumnavigation of the world.\n\nThe NASA Puffin was a concept, proposed in 2010, for an electric-powered, vertical takeoff and landing (VTOL), personal air vehicle.\n\nThe European Commission has financed many low TRL projects for innovative electric or hybrid propulsion aircraft. The ENFICA-FC is a project of the European Commission, to study and demonstrate an all-electric aircraft with fuel-cells as the main or auxiliary power system. During the three-year project, a fuel-cell based power system was designed and flown in a Rapid 200FC ultralight aircraft.\n\nThe NASA Electric Aircraft Testbed (NEAT) is a NASA reconfigurable testbed in Plum Brook Station, Ohio, used to design, develop, assemble and test electric aircraft power systems, from a small, one or two person aircraft up to airliners. NASA research agreements (NRA) are granted to develop electric-propulsion components. They will be completed in 2019 and the internal NASA work by 2020, then they will be assembled in a megawatt-scale drive system to be tested in the narrowbody-sized NEAT.\n\nNASA developed the X-57 Maxwell to demonstrate technology to reduce fuel use, emissions, and noise. Modified from a Tecnam P2006T, the X-57 will have 14 electric motors driving propellers mounted on the wing leading edges. In July 2017, Scaled Composites is modifying a first P2006T by replacing the piston engines with electric motors, to fly early in 2018, then will move the motors to the wingtips to increase propulsive efficiency and finally will instal of the high aspect ratio wing with 12 smaller props.\n\nIn September 2017, UK budget carrier EasyJet announced it was developing an electric 180-seater for 2027 with Wright Electric. Founded in 2016, US Wright Electric did built a two-seat proof-of-concept with 272 kg (600 lb) of batteries, and believes they can be scaled up with substantially lighter new battery chemistries: a 291 nm (540 km) range would suffice for 20% of Easyjet passengers. Wright Electric will then develop a 10-seater, eventually an at least 120 passengers single aisle, short haul airliner and targets 50% lower noise and 10% lower costs.\n\nOn March 19, 2018, Israel Aerospace Industries announced it plans to develop a short-haul electric airliner, building on its small UAS electric power systems experience.\nIt could develop it in-house, or with a startup like Israeli Eviation, U.S. Zunum Aero or Wright Electric.\n\nAustralia-based MagniX intends to fly an electric Cessna 208 Caravan with a motor for up to an hour, by August 2019.\nThe company's Magni5 electric motor already produces continuously peak at 2,500 rpm at 95% efficiency with a 53 kg (117 lb.) dry mass, a 5 kW/kg power density, competing with the , Siemens SP260D for the Extra 330LE.\nBy September 2018, a electric motor with a propeller had been tested on a Cessna iron bird. The Caravan was expected to fly by the fall of 2019 and by 2022 MagniX estimates electric aircraft will fly up to by 2024.\nThe motor ran on a test dynamometer for 1,000 hours. The iron bird is a Caravan forward fuselage used as a test bed, with the usual PT6 turboprop engine replaced by an electric motor, inverter and a liquid-cooling system, including radiators, driving a Cessna 206 propeller.\nThe production motor will produce at 1,900 rpm, down from the test motor's 2,500 rpm, allowing the installation of the propeller without a reduction gearbox.\n\nZunum Aero, backed by Boeing and JetBlue, is working since 2013 on a family of 10- to 50-seat hybrid electric regional aircraft. On 5 October 2017, Zunum launched the development of a six-to-12-seat aircraft with its powertrain installed on a testbed and flown in 2019. Aiming to fly in 2020 and be delivered in 2022, it should lower operating costs by 40–80% to reach available seat miles (ASM) costs of a 78-seat Dash 8-Q400.\n\nOn 28 November 2017, Airbus announced a partnership with Rolls-Royce plc and Siemens to develop the E-Fan X hybrid-electric airliner demonstrator, to fly in 2020.\n\nThe 1,300-shp GE Catalyst could be used in hybrid-electric propulsion: in late 2016, General Electric modified a GE F110 fighter turbofan to extract 250 kW from its turbine and 750 kW from its turbine, supported by the USAF Research Laboratory and NASA, developed and tested a 1-megawatt electric motor/generator with GE Global Research, and tested a liquid-cooled inverter converting 2,400-volt DC to three-phase AC with silicon carbide-based switches and 1.7-kW MOSFET power modules.\n\nBy May 2018, consulting firm Roland Berger counted almost 100 electric aircraft in development.\nThis was up from 70 the previous year and included 60% from startups, 32% from aerospace incumbents, half of them major OEMs and 8% from academic, government organizations and non-aerospace companies, mainly from Europe (45%) and the U.S. (40%).\nMostly urban air taxis (50%) and general aviation aircraft (47%), a majority are battery-powered (73%), while some are hybrid-electric (31%), mostly larger airliners.\nIndustry experts expects a 50+ seat hybrid-electric airliner to debut in commercial operation by 2032 for routes like London-Paris.\n\nThe potential of electric and hybrid-electric propulsion remains limited for general aviation, according to Textron Aviation, as the specific energy of electricity storage is still 2% of aviation fuel.\nAn hybrid configuration is needed for airliners: lithium-ion batteries including packaging and accessories gives 160 Wh/kg while aviation fuel gives 12,500 Wh/kg.\nAs electric machines and converters are more efficient, their shaft power available is closer to 145 Wh/kg of battery while a gas turbine gives 6,545 Wh/kg of fuel: a 6545/145round0:1 ratio.\nThe EU funded the Hypstair program with €6.55 million over three years till 2016 for a TRL of 4: a Pipistrel Panthera mockup received a serial hybrid-electric powertrain, ground testing a 200-kW motor driven by batteries only, by a 100-kW generator-only and by both combined.\nIt is followed by Mahepa project from 2017, EU-funded over four years with €9 million under the Horizon 2020 research program to reduce aviation carbon emissions by 70% in 2050, till TRL 6 before entering product development.\nThe Panthera drivetrain will be divided in modules: electric motor thrust generator and internal combustion power generator in the nose, human-machine interface and computing, fuel and batteries in the wing.\nGround testing is planned for 2019 before flight tests in 2020.\nThe dual-fuselage, four-seat, battery-powered Pipistrel Taurus G4 received a DLR hydrogen fuel cell powertrain to fly as the HY4 in September 2016, with hydrogen tanks and batteries in the fuselages, fuel cells and motor in the central nacelle.\nPartners are German motor and inverter developer Compact Dynamics, Ulm University, TU Delft, Politecnico di Milano and University of Maribor.\nGround and flight tests should follow those of the Panthera a couple of months later.\n\nAlong their ground handling, scaling to 19- and 70-seat airliners will be studied in two configurations: more of the same size modules for electric distributed propulsion, or larger sized modules extrapolating the flight-test results, powering twin propellers.\nFlights will test system behavior, measure performance and reliability, and evaluate failure modes.\nA failure rate of one per 10 million hours is targeted, as low as in airliners, with very reliable components or with redundancy.\n\nAustrian company ScaleWings, developer of a P-51 Mustang scale replica, has developed a hybrid and redundant piston/electric engine, based on independent modules: a four-stroke V-twin producing when turbocharged, and electric motors, producing combined.\n\nVoltAero is a startup company formed in September 2017 by the CTO and test pilot of the 2014 Airbus E-Fan 1.0, located in Royan and established with the support of the French Nouvelle-Aquitaine region. The company is developing the VoltAero Cassio 1, a hybrid testbed based on the Cessna 337 Skymaster, which it intends to fly in late February 2019.\nThe clean-sheet, all-composite VoltAero Cassio 2 prototype should follow in 2020, before deliveries in late 2021 or early 2022. It will be powered by two electric motors driving tractor propellers on the wing and a piston engine and motor driving a pusher propeller in the aft fuselage. The combination of fuel and batteries will give it a range with nine people aboard.\n\nOn 31 October 2018, Diamond Aircraft flew the , funded by Germany’s economics ministry and the Austrian Research Promotion Agency, reaching and within 20 minutes. It is a modified DA40 with its single piston engine replaced by two Siemens electric motors in the nose powered by a Austro Engine AE 300 diesel or two batteries, for a 5 h. endurance or 30 min. on batteries only.\n\nIn November 2018, MIT engineers flew the first plane with no moving parts, propelled by ion wind thrust.\n\nCurrently, battery-powered electric aircraft have much more limited payload, range and endurance than those powered by internal combustion engines. However, pilot training is an area that emphasises short flights. Several companies make, or have demonstrated, light aircraft suitable for initial flight training. The Airbus E-Fan was aimed at flight training but the project was cancelled. Pipistrel makes light sport electric aircraft such as the Pipistrel WATTsUP. A prototype of the Aero Electric Sun Flyer. The advantage of electric aircraft for flight training is the lower cost of electrical energy compared to aviation fuel. Noise and exhaust emissions are also reduced compared with combustion engines.\n\nAlthough the Austro-Hungarian Petróczy-Kármán-Žurovec team flew an experimental tethered military observation helicopter in 1917, the use of electric power for rotor-borne flight was not exploited until modern times.\n\nLightweight components have enabled the development, for recreational purposes among others, of small, cheap radio-controlled unmanned aerial vehicles, often called drones, notably the widespread quadcopter.\n\nThe Solution F/Chretien Helicopter the world's first man-carrying, free-flying electric helicopter was developed by Pascal Chretien. The concept was taken from the conceptual computer-aided design model on September 10, 2010 to the first testing at 30% power on March 1, 2011—less than six months. The aircraft first flew August 4 to 12, 2011. All development was conducted in Venelles, France.\n\nIn February 2016, Philippe Antoine, AQUINEA and ENAC, Ecole Nationale Supérieure de l'Aviation Civile, successfully flew the first full electric conventional helicopter called Volta in Castelnaudary Airfield, France. Volta demonstrated a 15-minute hovering flight in December 2016. The helicopter is powered by two PMSM motors delivering together 80 kW and a 22kWh Lithium battery. Volta is officially registered by DGAC, the French Airworthiness Authority, and is authorized for flying in the French civilian airspace.\n\nIn September 2016, Martine Rothblatt and Tier1 Engineering successfully tested an electric-powered helicopter. The five minute flight reached an altitude of 400 feet with a peak speed of 80 knots. The Robinson R44 helicopter was modified with two three-phase permanent magnet synchronous YASA Motors, weighing 100 lb, plus 11 Brammo Lithium polymer batteries weighing 1100 lb and a digital cockpit display. It later flew for 20 minutes in 2016.\n\nThe Sikorsky Firefly S-300 was a project to flight test an electric rotorcraft, but the project was put on hold due to battery limitations. The world's first large-scale all-electric tilt-rotor was the AgustaWestland Project Zero unmanned aerial vehicle technology demonstrator, which performed unmanned tethered fights on ground power in June 2011, less than six months after the company gave the official go-ahead.\n\nThe Airbus CityAirbus is an electrically-powered VTOL aircraft demonstrator. The multirotor aircraft is intended to carry four passengers, with a pilot initially and to become self-piloted when regulations allow. Its first unmanned flight is scheduled for the end of 2018 with manned flights following in 2019. Type certification and commercial introduction are planned for 2023.\n\n\n"}
{"id": "18740868", "url": "https://en.wikipedia.org/wiki?curid=18740868", "title": "Electromagnetic oscillograph", "text": "Electromagnetic oscillograph\n\nAn electromagnetic oscillograph is an oscillograph which measures variations of electric current by having it go through a magnetic coil. Variations in current induce momentum in the coil, which can be directly measured.\n\nThe electromagnetic oscillograph was invented by William Duddell. \n\nSome models utilise a mirror which reflects a beam of light, allowing measurement of minute movements of the coil. Other were fitted with a hand, possibly fitted with a pen to record values.\n\n"}
{"id": "42080517", "url": "https://en.wikipedia.org/wiki?curid=42080517", "title": "Elmer E. Kirkpatrick", "text": "Elmer E. Kirkpatrick\n\nColonel Elmer Ellsworth Kirkpatrick, Jr., was a United States Army Quartermaster Corps and Army Corps of Engineers officer who worked on the Alaska Highway, the Canol project, and the Manhattan Project during World War II.\n\nA 1929 graduate of the United States Military Academy at West Point, Kirkpatrick was involved in numerous construction projects in the United States and Panama. He went to Washington, D.C., in October 1940 to work in the office of the Quartermaster General, where he worked to prepare the necessary accommodation and training facilities for the vast army that would be created to fight World War II. After duty in Alaska, he joined the Manhattan Project, and was responsible for the development of the base facilities used for the atomic bombing of Hiroshima and Nagasaki.\n\nAfter the war he was Chief of Staff of the Armed Forces Special Weapons Project, and the head of the Construction Division of the Far East Command in Japan.\n\nElmer Ellsworth Kirkpatrick, Jr., was born in Yukon, Oklahoma on 17 August 1905, the second of four sons of Elmer Ellsworth Kirkpatrick, Sr., a dentist, and his wife Helene Claudia née Spencer. Kirkpatrick and his brothers had a younger sister, Mary Elizabeth.\n\nKirkpatrick was educated at McKinley Elementary and Central High School in Oklahoma City. He joined the Reserve Officer Training Corps in his freshman year, and rose to the rank of corporal in the 189th Field Artillery Battery of the Oklahoma National Guard. After graduation he spent a year at the Marion Military Institute.\n\nOn 1 July 1925, Kirkpatrick entered the United States Military Academy at West Point, following in the footsteps of his older brother Lewis Spencer Kirkpatrick, who had graduated with the class of 1924. Lewis later died as a prisoner of the Japanese on 27 April 1943. He graduated 169th in his class of 299 on 13 June 1929, and was commissioned as a second lieutenant in the Quartermaster Corps.\n\nTwo days later he married Edith Luise Koelsch. His first posting was to Fort Sam Houston, Texas, as an assistant to the Constructing Quartermaster, where his first child, a daughter called Patricia, was born in 1930. On 9 June 1931, he entered Carnegie Institute of Technology, from which he graduated with a Bachelor of Science degree in civil engineering the following year.\n\nKirkpatrick was posted to Hot Springs, Arkansas in July 1932 as assistant to the Constructing Quartermaster building the Army and Navy Hospital there. He was then sent to Harrodsburg, Kentucky, as assistant to the Constructing Quartermaster in June 1933, where he was engaged in building the Pioneer Memorial Monument there. In November 1933 he returned to West Point as assistant to the Constructing Quartermaster . After five years as a second lieutenant, he was promoted to first lieutenant on 1 November 1934.\n\nAfter attending the Quartermaster School in Philadelphia, Pennsylvania, from September 1936 to June 1937, Kirkpatrick was assigned to Fort Monmouth, New Jersey, as Post Quartermaster, and then to Fort DuPont, Delaware, as Constructing Quartermaster in June 1938. His son William Terry was born in Washington, D.C. later that year. He was promoted to captain on 13 June 1939.\n\nKirkpatrick 's first overseas posting came in August 1939, when he was sent to the Panama Canal Department as Assistant Constructing Quartermaster. There, he supervised works at Fort Davis, Fort Randolph, France Field, and the new anti-aircraft artillery positions on Gatun Lake.\n\nKirkpatrick went to Washington, D.C., in October 1940 to work in the office of the Quartermaster General. At this point, the US Army was about to embark on a national mobilization, and it was the task of the Construction Division of the Quartermaster Corps to prepare the necessary accommodation and training facilities for the vast army that would be created to fight World War II, which was already raging in Europe.\n\nThe enormous construction program had been dogged by bottlenecks, shortages, delays, spiralling costs, and poor living conditions at the construction sites. Newspapers began publishing accounts charging the Construction Division with incompetence, ineptitude, and inefficiency. Between 1 July 1940 and 10 December 1941, the Construction Division let contracts worth $1,676,293,000. He was promoted to major on 10 October 1942 and lieutenant colonel on 1 February 1942. On 19 February, he was transferred to the Army Corps of Engineers.\n\nIn October 1942, Kirkpatrick became District Engineer of the Milwaukee District. As such he was responsible for the management of $150 million of construction of airfields, cantonments, and other facilities in Michigan, including a new Allis-Chalmers Manufacturing Company factory. In March 1943 he became Chief of Staff of the Northwest Service Command, with its headquarters at Whitehorse, Yukon. This was responsible for the maintenance of the Alaska Highway, and for the Canol project. He was promoted to the rank of colonel on 21 April 1943. For his service, he was awarded the Legion of Merit.\n\nKirkpatrick returned to Washington, D.C., in September 1944, where he became a special assistant to the Director of the Manhattan Project, Major General Leslie R. Groves, Jr. He was sent to the Pacific island of Tinian as liaison to the Twentieth Air Force. On Tinian he was responsible for base development in support of Project Alberta and the 509th Composite Group, and was alternate to Brigadier General Thomas F. Farrell, Groves's deputy for Operations. The facilities would be used for operations including the atomic bombing of Hiroshima and Nagasaki. For his services to the Manhattan Project he was awarded a second Legion of Merit, and the Commendation Ribbon.\n\nAfter the war, Kirkpatrick was posted to Oak Ridge, Tennessee, as Deputy District Engineer of the Manhattan District. He was reduced to his permanent rank of major on 13 June 1946. After the Manhattan District was dissolved he was posted back to West Point in March 1947 as Assistant Chief of Staff, Logistics (G-4). There he was promoted to lieutenant colonel again on 1 July 1948. He returned to Washington, D.C., in July 1949 as Chief of Staff of the Armed Forces Special Weapons Project.\n\nKirkpatrick subsequently served in Japan as head of the Construction Division of the Far East Command and United States Army Forces in the Far East, and as Chief of the Japan Construction Agency. He then became District Engineer in Jacksonville, Florida, where he was responsible for the construction of the initial facilities at Cape Canaveral for the space program. This was followed by duty as District Engineer of the Southern District of the Mediterranean Division, with its headquarters in Livorno, Italy. He retired from the Army on 1 November 1958 with the rank of colonel. He was awarded a third Legion of Merit.\n\nKirkpatrick moved to Jacksonville, Florida, where he became an Assistant Professor in the College of Architecture and the University of Florida in Gainesville, Florida. He retired from this in 1965. His son Terry graduated from West Point with the class of 1961 and served with the engineers in the Vietnam War. His wife died in 1982 and he married Virginia Wright in 1986. After he died in Jacksonville on 26 March 1990, he was cremated and half of his ashes were scattered into the waters of Melrose Bay, Florida, while the other half were interred with his first wife's in West Point Cemetery.\n\n"}
{"id": "12870097", "url": "https://en.wikipedia.org/wiki?curid=12870097", "title": "Energy neutral design", "text": "Energy neutral design\n\nAn Energy Neutral Design is a Design of any type (Website, Multi-media, Architecture, Art, Music, Entertainment, etc.) that has the environment and low energy consumption practices in mind during all stages of planning and production.\n\nEnergy neutral design can also refer to environmentally powered electronics, where devices absorb or harvest energy from the immediate surroundings and transform it to the electricity they require for their operation. One example of this is the Batteryless_radio. More recently wireless sensor networks and internet of things devices have featured energy neutral designs where light, heat, motion or other forms of energy are converted to electricity.\n\n"}
{"id": "42543708", "url": "https://en.wikipedia.org/wiki?curid=42543708", "title": "Fill factor (image sensor)", "text": "Fill factor (image sensor)\n\nThe fill factor of an image sensor array is the ratio of a pixel's light sensitive area to its total area. \nFor pixels without microlenses, the fill factor is the ratio of photodiode area to total pixel area,\nbut the use of microlenses increases the \"effective fill factor\", often to nearly 100%, by converging light from the whole pixel area into the photodiode.\n\nAnother case that reduces the fill factor of an image is, to add additional memory beside each pixel, to achieve global shutter effect on CMOS sensor.\n"}
{"id": "10964957", "url": "https://en.wikipedia.org/wiki?curid=10964957", "title": "Fishing rod tapers", "text": "Fishing rod tapers\n\nFishing rod tapers describe how much a fishing rod bends or flexes under pressure. Different tapers are used for different fishing scenarios as well as for personal preference. \n\nThe action of a taper is described by the flex of the tip of a rod when pressure is applied perpendicular to the rod. Only a section of the rod starting at the tip of the rod should bend while the remainder of the rod should stay rigid.\n\nVariations can be described in three main categories, fast, medium, or slow with variations in between each. A rod with a fast taper will only flex the top 20 percent. Medium fast and medium tapers will flex approximately 30 to 60 percent of the rod respectively. If the rod has a slow taper, almost the entire rod or blank will bend or flex under pressure.\n\nRod taper is important for several reasons. The feel for the lure being used and the fish being caught dictate the appropriate taper use.\n\nA fast action tip will be used when fishing jig type lures. The angler can feel and therefore control what the lure is doing quite easily. Since only the very tip of the rod bends, when a fish strikes the angler has ample rod shaft and backbone to set the hook correctly.\n\nIn contrast to fast tapers, the slow flex rods offer the angler advantages when fighting large fish with light fishing line. This additional flex allows the rod to absorb the force of the fish as opposed to the line. This is often the angler who likes to fish split shot rigs or Lindy rigs for walleye.\n"}
{"id": "20088199", "url": "https://en.wikipedia.org/wiki?curid=20088199", "title": "Flow mark", "text": "Flow mark\n\nFlow marks, also known as flow lines, are molding defects that can occur in the manufacturing process of injection molding. They are best described as directionally \"off tone\" wavy lines or patterns. The reason for this is that the Injection speed is set too slow (the plastic has cooled down too much during injection, injection speeds must be set as fast as you can get away with at all times).\n"}
{"id": "3206199", "url": "https://en.wikipedia.org/wiki?curid=3206199", "title": "Garden Organic", "text": "Garden Organic\n\nGarden Organic, formerly known as the Henry Doubleday Research Association (HDRA), is a UK organic growing charity dedicated to researching and promoting organic gardening, farming and food. The charity maintains the Heritage Seed Library to preserve vegetable seeds from heritage cultivars and make them available to growers.\n\nThe Henry Doubleday Research Association was founded in 1954 to research and promote organic gardening, farming, and food. The charity adopted the working name \"Garden Organic\" in 2005 and is now the UK’s leading organic growing charity. \"Henry Doubleday Research Association\" remains the legal name under which it is registered as a charity.\n\nIt was founded by horticulturist and freelance journalist Lawrence D Hills and named after Henry Doubleday, an Essex-based Quaker smallholder who had a particular interest in the properties of comfrey. The organisation was first based at Bocking near Braintree in Essex, hence the name of Bocking 14, a variety of comfrey bred by Hills for its useful properties. A sister organisation was also formed in Australia, the Henry Doubleday Research Association of Australia Inc.\n\nJackie and Alan Gear took over management of the charity in 1976, and in 1985 the organisation relocated to its present headquarters site at Ryton-on-Dunsmore near Coventry in the West Midlands. The Gears retired in 2004, when Dr. Susan Kay-Williams became the chief executive and the charity changed its working name to Garden Organic. Dr. Kay-Williams left in the summer of 2007 and the charity appointed Myles Bremner, former Director of Fundraising at children’s charity, NCH. Myles Bremner left in the summer of 2013 and was replaced by James Campbell, former acting chief development officer of the Earthwatch Institute.\n\nIn the autumn of 2017 Garden Organic announced that it was considering options for the future of its Ryton site, with full or partial sale among the possibilities. Some members expressed concern over the way the charity was handling the issue.\n\nThe organisation has over 20,000 members. It has trained over 600 Master Composter volunteers from around the UK to spread the home composting message and runs research and international development programmes that help commercial growers across the UK and overseas adopt organic methods.\n\nIn 2010 with funding from the Big Lottery Fund’s Local Food Scheme, Sheepdrove Trust and local authorities in four areas — Warwickshire, North London, South London and Norfolk — the Charity set up a Master Gardener Programme. The Charity's Master Gardeners Programme trains and supports mentors and community growing initiatives around the Country working with Local Authorities, Housing Associations and NHS Health providers to support networks of Master Gardeners and volunteers. The Programme has expanded to other areas in the UK and is currently working with G4S in supporting a Master Gardener Programme for offenders in prisons HMP Rye Hill and Onsley.\n\nIt used to actively campaign on issues vital to both people and the environment including health, sustainability, and climate change, and helps children in over 15% of the UK's schools learn about food and organic growing through its free education programme, Garden Organic for Schools and through its work on the Food for Life Partnership.\n\nThe charity's headquarters are at its Ryton site in Warwickshire. Here the organisation not only leads its charitable delivery activities, but also runs over 30 individual gardens in of landscaped grounds open to the public. The site is also home to The Organic Way, extensive conference and educational facilities, a vegetarian/vegan restaurant, a small shop with organic seeds and the charity’s Heritage Seed Library, which conserves over 800 endangered varieties of rare vegetable seeds under threat from extinction.\n\nAs well as Ryton Gardens, the charity has run the walled kitchen gardens at Audley End, Essex in association with English Heritage. Audley End is a Jacobean stately home owned by English Heritage and in 1999 Garden Organic restored its walled kitchen garden using organic methods. The Gardens continue to be managed by English Heritage under the guidance of Garden Organic.\n\nA demonstration garden in Yalding, Kent, showing organic growing techniques in fourteen individual gardens was closed in 2007 after 12 years' development because of financial unviability. The site then came under a sequence of several owners and since 2016 has become a venue for weddings and other events.\n\nThe charity relies on funds from its supporters and members to carry out its work and, in return, offers a six-monthly magazine, members-only web pages and information sheets, as well as access to the charity’s dedicated team of advisors who answer more than 5,000 organic gardening queries every year. In addition, members gain unlimited free admission to the two demonstration gardens together with the Royal Horticultural Society gardens at Wisley, Harlow Carr, Rosemoor and Hyde Hall, plus over 20 other gardens across the UK.\n\nGarden Organic’s patron is HRH The Prince of Wales. The organisation's President is Professor Tim Lang and Vice Presidents are Raymond Blanc, Thelma Barlow and Susan Hampshire. The charity reaches more than three million beneficiaries across the world.\n\n"}
{"id": "6968798", "url": "https://en.wikipedia.org/wiki?curid=6968798", "title": "Headway", "text": "Headway\n\nHeadway is a measurement of the distance or time between vehicles in a transit system. The \"minimum headway\" is the shortest such distance or time achievable by a system without a reduction in the speed of vehicles. The precise definition varies depending on the application, but it is most commonly measured as the distance from the tip of one vehicle to the tip of the next one behind it. It can be expressed as the distance between vehicles, or as time it will take for the trailing vehicle to cover that distance. A \"shorter\" headway signifies closer spacing between the vehicles. Freight trains might have headways measured in parts of an hour, metro systems operate with headways on the order of 1 to 5 minutes, and vehicles on a freeway can have as little as 2 seconds headway between them.\n\nHeadway is a key input in calculating the overall route capacity of any transit system. A system that requires large headways has more empty space than passenger capacity, which lowers the total number of passengers or cargo quantity being transported for a given length of line (railroad or highway, for instance). In this case, the capacity has to be improved through the use of larger vehicles. On the other end of the scale, a system with short headways, like cars on a freeway, can offer relatively large capacities even though the vehicles carry few passengers.\n\nThe term is most often applied to rail transport and bus transport, where low headways are often needed to move large numbers of people in mass transit railways and bus rapid transit systems. A lower headway requires more infrastructure, making lower headways expensive to achieve. Modern large cities require passenger rail systems with tremendous capacity, and low headways allow passenger demand to be met in all but the busiest cities. Newer signalling systems and moving block controls have significantly reduced headways in modern systems compared to the same lines only a few years ago. In principle, automated personal rapid transit systems and automobile platoons could reduce headways to as little as fractions of a second.\n\nThere are a number of different ways to measure and express the same concept, the distance between vehicles. The differences are largely due to historical development in different countries or fields.\n\nThe term developed from railway use, where the distance between the trains was very great compared to the length of the train itself. Measuring headway from the front of one train to the front of the next was simple and consistent with timetable scheduling of trains, but constraining tip-to-tip headway does not always ensure safety. In the case of a metro system, train lengths are uniformly short and the headway allowed for stopping is much longer, so tip-to-tip headway may be used with a minor safety factor. Where vehicle size varies and may be longer than their stopping distances or spacing, as with freight trains and highway applications, tip-to-tail measurements are more common.\n\nThe units of measure also vary. The most common terminology is to use the time of passing from one vehicle to the next, which closely mirrors the way the headways were measured in the past. A timer is started when one train passes a point, and then measures time until the next one passes, giving the tip-to-tip time. This same measure can also be expressed in terms of vehicles-per-hour, which is used on the Moscow Metro for instance. Distance measurements are somewhat common in non-train applications, like vehicles on a road, but time measurements are common here as well.\n\nTrain movements in most rail systems are tightly controlled by railway signalling systems, or signalling block system. In many railways drivers are given instructions on speeds, and routes through the rail network. Trains (rollingstock) can only accelerate and decelerate relatively slowly, so stopping from anything but low speeds requires several hundred metres or even more. The track distance required to stop is often much longer than the range of the driver's vision. If the track ahead is obstructed, for example a train is at stop there, then the train behind it will probably see it far too late to avoid a collision. \n\nSignalling systems serve to provide drivers with information on the state of the track ahead, so that a collision may be avoided. A side effect of this important safety function is that the headway of any rail system is effectively determined by the structure of the signalling system, and particularly the spacing between signals and the amount of information that can be provided in the signal. Rail system headways can be calculated from the signalling system. In practice there are a variety of different methods of keeping trains apart, some which are manual such as train order working or systems involving telegraphs, and others which rely entirely on signalling infrastructure to regulate train movements. Manual systems of working trains are common in area with low numbers of train movements (such as 1 per day), and headways are more often discussed in the context of non-manual systems. Automatic block signalling is probably the most relevant to the calculation of headways.\n\nFor automatic block signalling (ABS), the headway is measured in minutes, and calculated from the time from the passage of a train to when the signalling system returns to full clear (proceed). It is not normally measured tip to tip. An ABS system divides the track into blocks, into which only one train can enter at a time. Commonly trains are kept two to three block sections apart, depending on how the signalling system is designed, and so the size of the block will often determine the headway.\n\nTo have visual contact as a method to avoid collision (such as during shunting) is done only at low speeds, like 40 km/h. A key safety factor of train operations is to space the trains out by at least this distance, the \"brick-wall stop\" criterion. In order to signal the trains in time to allow them to stop, the railways placed workmen on the lines who timed the passing of a train, and then signalled any following trains if a certain elapsed time had not passed. This is why train headways are normally measured as tip-to-tip times, because the clock was reset as the engine passed the workman.\n\nAs remote signalling systems were invented, the workmen were replaced with signal towers at set locations along the track. This broke the track into a series of \"blocks\" between the towers. Trains were not allowed to enter a block until the signal said it was clear, thereby guaranteeing a minimum of one block's headway between the trains. This had the side-effect of limiting the maximum speed of the trains to the speed where they could stop in the distance of one block. This was an important consideration for the Advanced Passenger Train in the United Kingdom, where the block sizes limited speeds and demanded a new braking system be developed.\n\nThere is no perfect block size for the block-control approach; some considerations favour a shorter block size, some a longer. Longer blocks have the advantages that they use as few signals as possible, signals being expensive and points of failure, and that they give the trains more time to stop and thus allow for higher speeds. On the other hand, spreading the signals out over greater distances increases the headway, and thus reduces the overall capacity of the line. These needs have to be balanced on a case-by-case basis.\n\nIn the case of automobile traffic, the key consideration in braking performance is the user's reaction time. Unlike the train case, the stopping distance is generally much shorter than the spotting distance. That means that the driver will be matching their speed to the vehicle in front before they reach it, eliminating the \"brick-wall\" effect.\n\nWidely used numbers are that a car traveling at 60 mph will require about 225 feet to stop, a distance it will cover just under 6 seconds. Nevertheless, highway travel often occurs with considerable safety with tip-to-tail headways on the order of 2 seconds. That's because the user's reaction time is about 1.5 seconds so 2 seconds allows for a slight overlap that makes up for any difference in braking performance between the two cars.\n\nVarious personal rapid transit systems in the 1970s considerably reduced the headways compared to earlier rail systems. Under computer control, reaction times can be reduced to fractions of a second. Whether traditional headway regulations should apply to PRT and car train technology is debatable. In the case of the Cabinentaxi system developed in Germany, headways were set to 1.9 seconds because the developers were forced to adhere to the brick-wall criterion. In experiments, they demonstrated headways on the order of half of a second.\n\nHeadway spacing is selected by various safety criteria, but the basic concept remains the same - leave enough time for the vehicle to safely stop behind the vehicle in front of it. The \"safely stop\" criterion has a non-obvious solution, however; if a vehicle follows immediately behind the one in front, the vehicle in front simply cannot stop quickly enough to damage the vehicle behind it. An example would be a conventional train, where the vehicles are held together and have only a few millimetres of \"play\" in the couplings. Even when the locomotive applies emergency braking, the cars following do not suffer any damage because they quickly close the gap in the couplings before the speed difference can build up.\n\nThere have been many experiments with automated driving systems that follow this logic and greatly decrease headways to tenths or hundredths of a second in order to improve safety. Today, modern CBTC railway signalling systems are able to significantly reduce headway between trains in the operation. Using automated \"car follower\" cruise control systems, vehicles can be formed into flocks that approximate the capacity of conventional trains. These systems were first employed as part of personal rapid transit research, but later using conventional cars with autopilot-like systems.\n\nRoute capacity is defined by three figures; the number of passengers (or weight of cargo) per vehicle, the maximum safe speed of the vehicles, and the number of vehicles per unit time. Since the headway factors into two of the three inputs, it is a primary consideration in capacity calculations. The headway, in turn, is defined by the braking performance, or some external factor based on it, like block sizes. Following the methods in Anderson:\n\nThe minimum safe headway measured tip-to-tail is defined by the braking performance:\n\nformula_1\n\nwhere:\n\nThe tip-to-tip headway is simply the tip-to-tail headway plus the length of the vehicle, expressed in time:\n\nformula_9\n\nwhere:\n\nThe vehicular capacity of a single lane of vehicles is simply the inverse of the tip-to-tip headway. This is most often expressed in vehicles-per-hour:\n\nformula_12\n\nwhere:\n\nThe passenger capacity of the lane is simply the product of vehicle capacity and the passenger capacity of the vehicles:\n\nformula_15\n\nwhere:\n\nConsider these examples:\n\n1) freeway traffic, per lane: 100 km/h (~28 m/s) speeds, 4 passengers per vehicle, 4 meter vehicle length, 2.5 m/s braking (1/4 \"gee\"), 2 second reaction time, brick-wall stop, formula_8 of 1.5;\n\nThe headway used in reality is much less than 10.5 seconds, since the brick-wall principle is not used on freeways. In reality, 1.5 persons per car and 2 seconds headway can be assumed, giving 1800 cars or 2700 passengers per lane and hour.\n\nFor comparison, the Marin County, California (near San Francisco) states that peak flow on the three-lane Highway 101 is about 7,200 \"vehicles\" per hour. This is about the same number of passengers per lane.\n\nNotwithstanding these formulas it is widely known that reducing headway increases risk of collision in standard private automobile settings and is often referred to as tailgating.\n\n2) metro system, per line: 40 km/h (~11 m/s) speeds, 1000 passengers, 100 meter vehicle length, 0.5 m/s braking, 2 second reaction time, brick-wall stop, formula_8 of 1.5;\n\nNote that most signalling systems used on metros place an artificial limit on headway that is not dependent on braking performance. Also the time needed for station stops limits the headway. Using a typical figure of 2 minutes (120 seconds):\n\nSince the headway of a metro is constrained by signalling considerations, not vehicle performance, reductions in headway through improved signalling have a direct impact on passenger capacity. For this reason, the London Underground system has spent a considerable amount of money on upgrading the SSR Network, Jubilee and Central lines with new CBTC signalling to reduce the headway from about 3 minutes to 1, while preparing for the 2012 Olympics.\n\n3) automated personal rapid transit system, 30 km/h (~8 m/s) speeds, 3 passengers, 3 meter vehicle length, 2.5 m/s braking (1/4 \"gee\"), 0.01 second reaction time, brake-failure on lead vehicle for 1 m/s slowing, bot 2.5, m/s if lead vehicle breaks. formula_8 of 1.1;\n\nThis number is similar to the ones proposed by the Cabinentaxi system, although they predicted that actual use would be much lower. Although PRTs have less passenger seating and speeds, their shorter headways dramatically improve passenger capacity. However, these systems are often constrained by brick-wall considerations for legal reasons, which limits their performance to a car-like 2 seconds. In this case:\n\nHeadways have an enormous impact on ridership levels above a certain critical waiting time. Following Boyle, the effect of changes in headway are directly proportional to changes in ridership by a simple conversion factor of 1.5. That is, if a headway is reduced from 12 to 10 minutes, the average rider wait time will decrease by 1 minute, the overall trip time by the same one minute, so the ridership increase will be on the order of 1 x 1.5 + 1 or about 2.5%. Also see Ceder for an extensive discussion.\n\n"}
{"id": "56377493", "url": "https://en.wikipedia.org/wiki?curid=56377493", "title": "Helix (genomics company)", "text": "Helix (genomics company)\n\nHelix is an American consumer genomics company.\n\nHelix focuses on personal genomics and citizen science. Helix has a marketplace that offers applications created by approved partners. Helix handles sample collection, DNA sequencing, and secure data storage and partners develop on-demand products. Helix is headquartered in the San Francisco Bay Area and operates a sequencing laboratory in San Diego.\n\nIn 2016, Helix partnered with the National Geographic Society to sequence DNA for the Genographic Project.\n\nIn 2018, Helix partnered with the Desert Research Institute and Renown Institute of Health Innovation in support of the Healthy Nevada project, which offers free access to genomic sequencing to 40,000 residents of northern Nevada for health research.\n\nHelix uses NGS to sequence a proprietary assay called Exome+, a version of Exome sequencing the company claims to provide 100 times more data than was previously available. Exome+ includes all 22,000 protein-coding genes as well as additional regions known to be of interest. All samples are processed in Helix’s CLIA- and CAP-accredited sequencing lab powered by Illumina NGS technology, using the Exome+ assay.\n\n"}
{"id": "41239", "url": "https://en.wikipedia.org/wiki?curid=41239", "title": "High-performance equipment", "text": "High-performance equipment\n\nHigh-performance equipment describes telecommunications equipment that\n\n\"Note:\" Requirements for global and tactical high-performance equipment may differ.\n"}
{"id": "37215299", "url": "https://en.wikipedia.org/wiki?curid=37215299", "title": "High efficiency glandless circulating pump", "text": "High efficiency glandless circulating pump\n\nA high efficiency glandless circulating pump is a component of a heating and air conditioning system that allows the system to perform with increased efficiency while significantly reducing the system's electrical usage. \n\nIt is primarily composed of an electronically commutated synchronous motor (ECM) with a permanent magnet rotor. The ECM is a motor that converts a direct current (DC) from an electrical source into an alternating current (AC) which is sent to the motor itself, allowing for increased efficiency over standard AC motors. The permanent magnet rotor consists of an iron core, surrounded by multiple magnetic rare earth metals, and finally a metal sleeve that evenly spaces the magnets around the core, which helps to drive the motor. By utilizing multiple small improvements in pump-design technology such as a double pump in parallel system and variable controls, these pumps are able to run at about a 50% to 70% increased efficiency with up to an 80% decrease in electricity consumption over the previous standard design. This pump has recently become the new standard in both commercial and residential buildings across the European Union due to a recent ordinance by the European ErP (Eco-Design) Directive. The ErP directive began enforcing this new standard of regulation of these pumps January 1st, 2013 and will become even stricter on efficiency standards on August 1st, 2015 in order to meet the EU's goal of a 50% total reduction in the pump's energy usage by 2020.\n\nThe primary design factors of a high efficiency glandless circulating pump include an electronically commutated synchronous motor, a permanent magnet rotor, and canned rotor technology. An electronically commutated synchronous motor is used to convert the energy current from a DC energy source into an AC current which is supplied to the drive motor. It utilizes the magnetomotive force which is generated by surface currents placed on the surfaces of the stator and rotor and the permanent magnets to generate the electric current which is in output to the drive motor. The canned rotor technology eliminates the need for a shaft seal that many conventional pumps must use through its unique design. Whereas standard pumps with shaft seals have multiple chambers with different rotating parts in each, canned rotor technology allows all of the rotating parts within the pump to exist in a single chamber. This increases the overall efficiency since the liquid used to lubricate the shaft bearings is also used to cool the motor. The electronic components of the motor are attached outside this system by means of an encapsulated motor cartridge, which is an independent metal compartment used solely for housing the electronic components.\n\nMany minor factors of the pump's design including its double pump system and control options give it additional efficiency without sacrificing any of its performance. By using a double pump system together with variable and automatic control, the pump is able to decrease its energy consumption while increasing efficiency and reliability. Using the pump's variable controls allows the pump to base its amount of energy consumption on how much it is actually performing, cutting down on usage during non-peak hours and extending the pump's life span. The automatic controls allow the pump to follow a set schedule of how much energy to consume during specific hours, which allows building owners to cut down even further on electricity costs. By dividing the output into a double pump in parallel design, the system is able to greatly adapt to partial load conditions. This accounts for a significant increase in reliability and the 50% to 70% efficiency increase that these high efficiency pumps achieve.\n\nThese types of pumps are used primarily in heating and air conditioning systems within both residential and commercial buildings such as offices and apartment complexes. The pump is the central component of these systems and accounts for most of the electricity usage within the system, making its design key to an increase in efficiency and decrease in energy consumption. Although the pump can be installed both inside and outside of buildings, many precautions must be taken in order to protect the pump from unfavorable weather conditions. These pumps are fairly simple to integrate into systems that follow the old standard since each pump is able to increase its efficiency by changing its design internally, meaning it will still fit into older systems without any problems requiring special adapters.\n\nHigh efficiency glandless circulating pumps have become the industry standard when developing and maintaining buildings within the European Union due to recent changes to the carbon emissions goals. Commercial and residential buildings now have to be outfitted with these pumps in order to decrease electricity usage and, in the long run, decrease the amount of pollutants produced. This new standard, referred to as the energy efficiency index (EEI), will set the bare minimum efficiency level at 0.27, and set the efficiency grading scale from this base value. The EU has also scheduled the efficiency scale to be revised again by August 1st, 2015 to set the minimum efficiency to 0.23. Various companies such as Wilo have successfully developed pumps that have been projected to save up to 80% in electricity usage, meeting both of the new grading scale minimums set this year and in 2015. Pump designs are still being revised to continually try to achieve higher efficiency standards and lower the impact on the environment in order to meet the goal of up to a 50% reduction in both CO emissions and electricity usage across the EU by 2020.\n"}
{"id": "20218892", "url": "https://en.wikipedia.org/wiki?curid=20218892", "title": "History of printing in Poland", "text": "History of printing in Poland\n\nThe history of printing in Poland began in the late 15th century, when following the creation of the Gutenberg Bible in 1455, printers from Western Europe spread the new craft abroad.\n\nThe Polish capital at the time was in Kraków, where scholars, artists and merchants from Western Europe had already been present. Other cities which were part of the Polish kingdom followed later. Cities of northern Polish province of Royal Prussia, like the Hanseatic League city of Danzig (Gdańsk), had established printing houses early on.\n\nThe first printing shop was possibly opened in Kraków by Augsburg-based Günther Zainer in 1465. In 1491, Schweipolt Fiol printed the first book in Cyrillic script.\n\nThe next recorded printing shop was a Dutch one known by the name \"Typographus Sermonum Papae Leonis I.\" that might have been established in 1473 on Polish territory, but its exact location has yet to be determined.\n\nThe oldest known print from Poland is considered to be the Almanach cracoviense ad annum 1474 (Cracovian Almanac for the Year 1474) which is a single-sheet astronomical wall calendar for the year 1474 printed and published in 1473 by Kasper Straube. The only surviving copy of \"Almanach cracoviense\" measures 37 cm by 26.2 cm, and is in the collections of the Jagiellonian University.\n\nThe first text in Polish language was printed in Breslau (Wrocław) in 1475. The first book printed in Polish was \"Historyja umęczenia Pana naszego Jezusa Chrystusa\", published in 1508 by Johann Haller's publishing house. For a long time, the first print written in Polish language was believed to be \"Hortulus Animae polonice\", a Polish version of Hortulus Animae written by Biernat of Lublin, printed and published in 1513 by Florian Ungler in Kraków. The last known copy was lost during World War II. \n\nOne of the first commercial printers in Poland is considered to be Johann Haller who worked in Kraków in the early 16th century (since 1505) who in 1509 printed Nicolaus Copernicus \"Theophilacti Scolastici Simocatti Epistole morales, rurales at amatoriae, interpretatione latina\".\n\nOther well known early printers in Poland are:\n\nIn the late 16th century there were 7 printing shops in Kraków, and in 1610 10 printing shops. A decline started in around 1615. Due to this fact in 1650 there remained only 3 secular printing shops, accompanied by a few ecclesial ones.\n\nOnly one printing shop is recorded in Warszawa in 1707, owned by the Piarists. This situation improved during the realm of the last Polish king, Stanisław August Poniatowski, that marked political and cultural revival in Poland. Unfortunately his attempts to reform the state led to the Partitions of Poland carried out by Prussia, Austria and Russia.\n\n"}
{"id": "4257911", "url": "https://en.wikipedia.org/wiki?curid=4257911", "title": "Information Architecture Institute", "text": "Information Architecture Institute\n\nThe Information Architecture Institute (IA Institute or IAI) is a non-profit volunteer organization dedicated to advancing and promoting information architecture. The organization, originally known as the Asilomar Institute for Information Architecture, was incorporated in November 2002, and is a 501(c)(6) organization. Since then, the IA Institute has grown to become one of the world's largest professional groups for web specialists, with over 1200 members in 60 countries.\n\nThe institute broadly defines \"information architecture\" as:\n\n"}
{"id": "4023588", "url": "https://en.wikipedia.org/wiki?curid=4023588", "title": "Lazy Susan", "text": "Lazy Susan\n\nA Lazy Susan is a turntable (rotating tray) placed on a table or countertop to aid in distributing food. Lazy Susans may be made from a variety of materials but are usually glass, wood, or plastic. They are usually circular and placed in the center of a circular table to share dishes easily among diners. Owing to the nature of Chinese cuisine, especially dim sum, they are common at formal Chinese restaurants both on the mainland and abroad. In Chinese, they are simply known as (p \"cānzhuō zhuànpán\") or \"dinner-table turntables\".\n\nIt is likely that the explanation of the term \"Lazy Susan\" has been lost to history. Folk etymologies claim it as an American invention and trace its name to a product Ovington's $8.50 mahogany \"Revolving Server or Lazy Susan\" advertised in a 1917 \"Vanity Fair\", but the term's use predates both the advertisement and, probably, the country.\n\nPart of the mystery arises from the variety of devices that were grouped under the term \"dumb waiter\" (today written \"dumbwaiter\"). An early 18th-century British article in \"The Gentleman's Magazine\" describes how silent machines had replaced garrulous servants at some tables and, by the 1750s, Christopher Smart was praising the \"foreign\" but discreet devices in verse. It is, however, almost certain that the devices under discussion were wheeled serving trays similar to those introduced by Thomas Jefferson to the United States from France, where they were known as \"étagères\". At some point during or before the 3rd quarter of the 18th century, the name dumb waiter also began to be applied to rotating trays. (Jefferson never had a Lazy Susan at Monticello but he did construct a box-shaped rotating book stand and, as part of serving \"in the French style\", employed a revolving dining-room door whose reverse side supported a number of shelves.) Finally, by the 1840s, Americans were applying the term to small elevators carrying food between floors as well. The success of George W. Cannon's 1887 mechanical dumbwaiter then popularized this usage, replacing the previous meanings of \"dumbwaiter.\"\n\nThe Lazy Susan was initially uncommon enough in the United States for the utopianist Oneida Community to be credited with its invention. They employed the devices as part of their practice of communalism, making food easily and equally available to residents and visitors at meals. An American patent was issued in 1891 to Elizabeth Howell for \"certain new and useful Improvements in Self-Waiting Tables\". Howell's device ran more smoothly and did not permit bread crumbs to fall into the space between the Lazy Susan and the table.\n\nDespite various folk etymologies linking the name to Jefferson and Edison's daughters, the earliest use of these \"serviettes\" or \"butler's assistants\" being called a \"lazy Susan\" dates to the 1903 \"Boston Journal\":John B. Laurie, as the resuscitator of \"Lazy Susan\", seems destined to leap into fortune as an individual worker. \"Lazy Susan\" is a step toward solving the ever-vexing servant problem. She can be seen, but not heard, nor can she hear, she simply minds her business and carries out your orders in a jiffy.Laurie was a Scottish carpenter who made his \"Lazy Susan\" to the design of a Hingham-area lady; finishing the device too late for her to present it as a gift, Laurie received an abusive tirade and then, asked for the price, \"told her it wasn’t for sale, though of course it is\". The name was repeated in a 1911 \"Idaho Statesman\" article which describes it as \"a cousin to the <nowiki>'</nowiki>curate's assistant<nowiki>'</nowiki>, as the English muffin stand is called\" and again in the 1912 \"Christian Science Monitor\", which calls the \"silver\" Lazy Susan \"the characteristic feature of the self-serving dinner table\". By the next year, the \"Lima Daily News\" described an Ohioan \"inaugurat[ing] ... the 'Lazy Susan' method of serving\". Henry Ford used an enormous one on his camping trips in the 1920s to avoid bringing a full contingent of servants along with his guests. In 1933, the term was added to the Webster's Dictionary.\n\nUnusually, the 1916 \"American Cookery\" describes the device as a German invention:\nThere is a table arrangement used much in Germany, which has now found its way to America, though it is still by no means common. The German \"frau\" calls it \"Lazy Susan\", but it is entirely different from our product used for salt and pepper shakers. Its only point of similarity is the swivel upon which it turns. The one which joys my heart is of mahogany, and it turns automatically at the slightest touch. It contains seven china dishes, six of which are trapezoids, the center one being octagonal. The trapezoids fit about the center octagon, forming a perfect whole.\n\nBy 1918, \"Century Magazine\" was already describing the Lazy Susan as out of fashion, but beginning in the 1950s its popularity soared once again after the redesign and reintroduction of the Lazy Susan by George Hall, an engineer, soy-sauce manufacturer, and partner in popular San Francisco-area Chinese restaurants (Johnny Kan's and Ming's of Palo Alto), and the rotating tray became ubiquitous in Chinese restaurants, and was used in homes around the globe. The decline in America's domestic service sector after World War I and its collapse following World War II, combined with the post-war Baby Boom, led to a great demand for them in US households across the country in the 1950s and '60s. This popularity has had the effect, however, of making them seem kitsch in subsequent decades.\n\nA Lazy Susan may be employed as a cake turntable for cake decorating.\n\nSmaller Lazy Susans are used for spice racks and rotating TV or monitor platforms.\n\nBy analogy, the term \"Lazy Susan\" is sometimes applied to cabinets (especially corner cabinets) whose circular shelves rotate around a vertical axle to allow easy access to a greater area of space. Such corner cabinets cut out a quarter of the circle to permit two \"doors\" to be mounted at right angles to one another. These are especially common in kitchen cabinets.\n\nThe term is also infrequently used for the much-older turntables employed in pottery wheels and related tasks like sculpture, modeling, repair work, etc.\n\nA Lazy Susan can be placed under a game-board, such as Scrabble, improving usability of editions that lack a built-in turntable.\n\n"}
{"id": "16793276", "url": "https://en.wikipedia.org/wiki?curid=16793276", "title": "Lift-off (microtechnology)", "text": "Lift-off (microtechnology)\n\nLift-off process in microstructuring technology is a method of creating structures (patterning) of a target material on the surface of a substrate (e.g. wafer) using a sacrificial material (e.g., Photoresist).\nIt is an additive technique as opposed to more traditional subtracting technique like etching.\nThe scale of the structures can vary from the nanoscale up to the centimeter scale or further, but are typically of micrometric dimensions.\n\nAn inverse pattern is first created in the sacrificial stencil layer (ex. photoresist), deposited on the surface of the substrate. This is done by etching openings through the layer so that the target material can reach the surface of the substrate in those regions, where the final pattern is to be created. The target material is deposited over the whole area of the wafer, reaching the surface of the substrate in the etched regions and staying on the top of the sacrificial layer in the regions, where it was not previously etched. When the sacrificial layer is washed away (photoresist in a solvent), the material on the top is lifted-off and washed together with the sacrificial layer below. After the lift-off, the target material remains only in the regions where it had a direct contact with the substrate.\n\n\nLift-off is applied in cases where a direct etching of structural material would have undesirable effects on the layer below. Lift-off is a cheap alternative to etching in a research context, which permits a slower turn-around time. Finally, lifting off a material is an option if there is no access to an etching tool with the appropriate gases.\n\nThere are 3 major problems with lift-off:\nIf the ears remain on the surface, the risk remains that these ears will go through different layers put on top of the wafer and they might cause unwanted connections.\n\nLift-off process is used mostly to create metallic interconnections. <br>\nThere are several types of lift-off processes, and what can be achieved depends highly on the actual process being used. Very fine structures have been used using EBL, for instance. The lift-off process can also involve multiple layers of different types of resist. This can for instance be used to create shapes that will prevent side walls of the resist being covered in the metal deposition stage.\n\n"}
{"id": "5709360", "url": "https://en.wikipedia.org/wiki?curid=5709360", "title": "Live food", "text": "Live food\n\nLive food is living food for carnivorous or omnivorous animals kept in captivity; in other words, small animals such as insects or mice fed to larger carnivorous or omnivorous species kept in either in a zoo or as pet. \n\nLive food is commonly used as feed for a variety of species of exotic pets and zoo animals, ranging from alligators to various snakes, frogs and lizards, but also including other, non-reptile, non-amphibian carnivores and omnivores (for instance, skunks, which are omnivorous mammals, can be technically be fed a limited amount of live food, though this is not known to be a common practice). Common live food ranges from crickets (used as an inexpensive form of feed for carnivorous and omnivorous reptiles such as bearded dragons and commonly available in pet stores for this reason), waxworms, mealworms and to a lesser extent cockroaches and locusts, to small birds and mammals such as mice or chickens. \n\nLive foods commonly available are crickets (both \"Gryllus bimaculatus\" and \"Acheta domesticus\" commonly), waxworms (\"Galleria mellonella\"), mealworms (\"Tenebrio molitor\"), Superworms (\"Zophobas morio\") and locusts (a number of species are seen commonly). There are however many more species used such as butter worms, phoenix worms, a variety of cockroach species, silkworms and more. Insect species are most commonly used to feed small reptiles and amphibians.\n\nAnother common form of live food, most commonly used to feed snakes, is small rodents. The most commonly known small rodent used for live food is likely the mouse; many pet stores which carry snakes or cater to snake owners also carry \"feeder mice\" for this reason (see \"Fancy mouse\"). It is also common to feed reptiles freshly killed or frozen/thawed rodents as most reptiles will readily accept them.\n\nCreatures that are the most common choices for live foods, ranging from feeder mice to crickets and mealworms, generally are bred and raised in captivity themselves, and can often be found both through local pet stores and from wholesalers or \"farms\" that breed them specifically for live food sales.\n\nAnimals that are commonly fed live food include bearded dragon and other lizards, various types of snake, turtles, and carnivorous fish, though other animals, such as skunks (which are sometimes kept as pets), being omnivorous, can also eat some live food, though it is unknown how common this is in practice.\n"}
{"id": "41375", "url": "https://en.wikipedia.org/wiki?curid=41375", "title": "Mode scrambler", "text": "Mode scrambler\n\nIn telecommunications, a mode scrambler mode mixer is a device for inducing mode coupling in an optical fiber, or a device that, itself, exhibits a uniform output intensity profile independent of the input mode volume or modal excitation condition. Mode scramblers are used to provide a modal distribution that is independent of the optical source for purposes of laboratory, manufacturing, or field measurements or tests. Mode scramblers are primarily used to improve reproducibility of multimode fiber bandwidth measurements.\n\nIf multimode fiber bandwidth is measured using a laser diode directly coupled to its input, the resulting measurement can vary by as much as an order of magnitude. This measurement variability is due to the combination of differences in laser output characteristics (emitted mode power distribution) and the differential mode delay of the fiber. Differential mode delay is the difference in the time delays amongst the fiber's propagating modes caused by imperfections or nonideality of the fiber refractive index profile.\n\nThe primary purpose of a mode scrambler is to create a uniform, overfilled launch condition that can be easily reproduced on multiple measurement systems, so that measurement systems have essentially the same launch conditions and can measure approximately the same bandwidth despite having different laser sources. These were used for this purpose in the first U.S. NIST round-robins on multimode fiber. The overfilled launch (OFL) was created to reduce measurement variability, and improve concatenation estimates for multimode fibers, used at that time for telecom 'long haul' (e.g., 7–10 km 850 nm or 20–30 km 1300 nm) systems.\n\nWhen the telecom industry converted to near-exclusive use of single-mode fiber ca. 1984, multimode fiber was re-purposed for use in LANs, such as Fiber Distributed Date Interface (FDDI), then under development. The output modal power distribution of a mode scrambler is similar to the surface-emitters used in those first LAN transmitters, but this was fortuitous coincidence. On average, but not in every case, the OFL bandwidth measured using a mode scrambler is lower than that produced by excitation of a partial mode volume (restricted mode launch or RML), such as occurs with directly coupled laser diodes.\n\nThere are two common types of mode scramblers: the \"Step-Graded-Step\" (S-G-S) and the \"step index with bends\". The S-G-S mode scrambler is actually an assembly, a fusion-spliced concatenation of a step-index profile, a graded-index profile and another step-index profile fiber. Typically, each segment is approximately 1 meter long, and may use segments of unconventional size to produce the distribution required according to core size of fiber to be tested. Unconventional fiber size was not an issue, as they were developed by fiber manufacturers, but some test equipment has difficulty complying with revised qualification standards, and now use \"Step Index with Bends\" mode scramblers, which can be adjusted to purpose. Step Index with Bend mode scramblers are created simply by routing a specially designed step-index multimode fiber through a series of small radius bends, or by compressing fiber against surfaces with specific roughness. The implementations are simple, but generally less reproducible, and require care to avoid over-stressing the fiber.\n\nA mode scrambler can be characterized and qualified by measuring its near-field and far-field distributions, as well as by measuring one of these distributions while restricting the other. Guidelines for constructing a mode scrambler and qualifying its output can be found in the ANSI/TIA/EIA-455-54 fiber optic test procedure (FOTP).\n\n"}
{"id": "34555677", "url": "https://en.wikipedia.org/wiki?curid=34555677", "title": "Motorized tricycle", "text": "Motorized tricycle\n\nA motorized tricycle, motor trike, or three-wheeled motorcycle is a three-wheeled vehicle based on the same technology as a bicycle or motorcycle, and powered by an electric motor, motorcycle, scooter or car engine.\nDepending on the design of the vehicle, a motorized trike may be categorized as a motorcycle, motor scooter, or simply the three-wheeled counterpart to a motorized or electric bicycle. The main difference between a motorcycle trike and a scooter trike is that motorcycles are sat on in a \"saddle\"-style seating (as with a horse), with the legs apart, and motorcycles have manual transmissions. Scooters have a \"step-through\" seating style, in which the driver sits on a more chair-like seat, with the legs together; as well, scooters have automatic transmissions. Laypersons often associate the engine size as a dividing line between motorcycles and scooters, since a typical scooter has a small 50 cc engine, but scooter engines can also be as large as 650cc as used in the Suzuki Burgman.\n\nMotorcycles with sidecars are not usually considered tricycles. It can be harder to categorize three-wheeled automobiles. While some early prototype automobiles were steam tricycles, three-wheeled cars such as the Morgan 3-Wheeler are often classified as cars rather than motorcycles. Generally, the motorcycle classification will require passengers to sit behind the driver, whereas in the car classification, at least one passenger is able to sit abreast to the driver.\n\nA motorized tricycle's wheels may be arranged in either configuration: delta or tadpole. A delta trike has one wheel in front and two in back, and the tadpole trike has two wheels in front and one in back. Occasionally, rear wheel steering is used, although this increases the turning circle and can affect handling (the geometry is similar to a regular trike operating in reverse, but with a steering damper added). \n\nTadpoles are more stable under braking and more likely to slide instead of roll; front braking hard on a delta requires the vehicle to steer almost straight to avoid tipping. The balance of friction patches and rolling resistance also means that tadpoles tend to oversteer and deltas understeer.\n\nMotor trikes are attractive for those with mobility or balance problems.\n\nUnder some local regulations, while riding a three-wheeled vehicle, it may be possible to carry multiple passengers with a motorcycle driving license, to ride a motorcycle-style vehicle with a car license, or to avoid motorcycle helmet use regulations.\n\nThese machines are generally custom-built. A common arrangement is to fit chopper-style (\"ape hanger\") front forks to a VW Beetle engine and transaxle, popular because it is largely self-contained on a single subframe. Similarly, the engine, transmission and rear wheel may be taken from a large motorcycle as a single unit, and used in the construction of a tadpole trike.\n\nMass-manufactured motor tricycles include the Piaggio MP3; the Piaggio Ape (Italian for \"Bee\") delivery trike (delta); the Harley-Davidson Tri Glide Ultra Classic; the Bombardier Recreational Products Can-Am Spyder (tadpole); the Polaris Slingshot (tadpole); the T-Rex reverse trike; trikes used by municipal authorities in the USA; and, historically, vehicles such as the Scammell Scarab railway dray, a common sight around post-war British railway stations.\n\nIn Asian and Southeast Asian countries, motorized trikes are used as small freight trucks and commercial vehicles. Nicknamed \"three-wheelers\" or \"tuk-tuks\" in popular parlance, they are a motorized version of the traditional pulled rickshaw or cycle rickshaw. While they are mostly used as taxis for hire, they are also used for commercial and freight deliveries. They are particularly popular in cities where traffic congestion is a problem.\n\nThey usually have a sheet-metal body or open frame that rests on three wheels, a canvas roof with drop-down sides, a small cabin in the front of the vehicle for the driver, an air-cooled scooter version of a two-stroke engine, with handlebar controls instead of a steering wheel.\nThe smaller motorized trikes are used as delivery vehicles for lighter loads. The larger trikes, with more powerful engines, have larger cargo bays, and they can carry freight within a city.\n\nMotorized three-wheel freight vehicles are a common sight throughout China. They come in various sizes, from open saddle-style trikes to 'three-wheel trucks' with a fully closed cabin.\n\nIn the Philippines, a \"motorbike and sidecar\" is called a tricycle. They are commonly used as a public utility vehicle and for personal transportation.\n\nSince 2012, electric tricycles known as e-rickshaws have become popular, replacing other commercial transports. For vehicles other than electric rickshaws, various locally made configurations are used in India. They fall under the category of Jugaad and serve as both passenger and commercial vehicles. The motorized versions are popular for their low cost, because they are put together from salvaged motorcycles and often do not require the operator to have a drivers license.\n\n"}
{"id": "32304493", "url": "https://en.wikipedia.org/wiki?curid=32304493", "title": "NextGenPower", "text": "NextGenPower\n\nNextGenPower is an integrated project which aims to demonstrate new alloys and coatings in boiler, turbine and interconnecting pipework. The concept of NextGenPower is to perform innovative demonstrations that will significantly contribute to the EU target to increase the efficiency in existing and new build pulverized coal power plants.\n\nCarbon Capture and Storage (CCS) is envisaged to be the main transition technology to comply with the CO2 reduction targets set by the European Commission. However, CCS has the drawback that the electrical efficiency of the coal-fired power plant will drop significantly. The efficiency loss caused by CCS in coal-fired power plants will range from 4 to 12% points, depending on the CCS technology chosen.\nTo overcome this drawback, one has to increase the plant efficiency or the share of biomass co-firing. Both options are limited due to the quality of the current available coatings and materials. Live steam temperatures well in excess of 700°C are necessary to compensate the efficiency loss caused by CCS and to achieve a net efficiency of 45%.\nNextGenPower aims to develop and demonstrate coatings and materials that can be applied in ultra-supercritical (in excess of 700˚C) conditions.\n\nThe NextGenPower project was due to start on 1 May 2010 and have a duration of 48 months. The budget is €10.3million, with an EU contribution making up €6million of the budget.\n\nThe following scientific and technological objectives have been defined for NextGenPower, leading to the following project activities:\n\nThere are also four sub-projects which will be focused on throughout the course of the NextGenPower project.\n\nNextGenPower aims at overcoming fireside corrosion and steamside oxidation in high temperature parts through the application of suitable coatings. The main goal for Sub Project 1 is to demonstrate the benefits and limitations of materials and coatings for the fireside under biomass co-firing conditions as well as for the boiler and main steam pipework under USC and current steam conditions.\n\nThe main goals for Sub Project 2 are to select the best candidate alloys for the HP and ID steam turbines operating at high steam temperatures (≥720˚C). A number of nickel-base alloys have been developed whose properties have been proven at the laboratory scale and for small-scale components. The main uncertainty in the application of these alloys for steam turbine applications is the ability to manufacture, weld and inspect large components. The performance in service presents a much smaller risk since there is confidence that the mechanical behaviour can be modelled on the basis of the material properties. This philosophy follows the approach applied in the development, demonstration and exploitation of materials technology for 700-720˚C steam turbines in other projects (AD700, COMTES, EON 50plus) where the first commercial steam turbine will enter service without prior operation in a test loop. Following alloy selection, full-scale steam turbine casings and rotor forgings will be manufactured and materials properties demonstrated through implementation of a mechanical testing programme. Full-scale demonstration of the welding technology and the NDE capability required for welded rotor and casing manufacture will also be carried out.\n\nSub Project 3 provides a framework for the testing and demonstration work in the overall project. It will review the expected operating parameters required for NGP plants, with and without CO2 capture technologies, and with and without biomass co-firing. The aim is to evaluate a series of NextGenPower plants with CCS systems in terms of their power generation efficiencies and CO2 emissions per unit of electricity generated.\n\nThe main goal for Sub Project 4 is to ensure that the generic results and results from topical activities are actively disseminated. It promotes results and approaches and encourages the duplication in other, thereby contributing to EU objectives of the CO2 reduction, efficiency improvement and security of energy supply. Another objective is to facilitate the sharing of policies, approaches and knowledge between the participants.\n\n\n"}
{"id": "5960778", "url": "https://en.wikipedia.org/wiki?curid=5960778", "title": "Nigel Pendse", "text": "Nigel Pendse\n\nNigel Pendse is a business intelligence and OLAP analyst and the editor of The BI Verdict (formerly The OLAP Report) and author of The BI Survey (previously known as The OLAP Survey). He also advises and speaks on a variety of OLAP related subjects. Previously, he had worked both as a user and then in a variety of roles as a salesperson of business intelligence products since 1977. He has a master's degree in nuclear reactor engineering from Imperial College, London.\n\n"}
{"id": "34038431", "url": "https://en.wikipedia.org/wiki?curid=34038431", "title": "Now the Chips are Down", "text": "Now the Chips are Down\n\nNow the Chips are Down is a 1978 television documentary about the importance and influence of microprocessors within the British economy. It was aired by the BBC as part of its \"Horizon\" series.\n\nThe programme was instrumental in raising general awareness within the UK about microprocessors.\n\nThe documentary is a report on the \"applications and implications\" of microprocessors to employment within the British economy.\n\nThe documentary was produced by BBC Television as part of its 1978 \"Horizon\" series. It was narrated by British radio and television presenter Paul Vaughan.\n\nScience historian Robert M. Young wrote in 1981 that the programme played an \"important part\" in raising awareness about microprocessors within government and the general public.\n\nBritain's lagging place in the worldwide technology race was widely acknowledged after the documentary was screened. The UK government launched the Microelectronics Education Programme in 1981, with a budget of more than . This included nationwide discounts on computers to schools and colleges, and was followed by government backing of the BBC's Computer Literacy Project. Funding for related education schemes continued until 1988.\n\n"}
{"id": "19187172", "url": "https://en.wikipedia.org/wiki?curid=19187172", "title": "OSAMI", "text": "OSAMI\n\nThe European ITEA \"2\" research project OSAMI (Open Source AMbient Intelligence) targets open source common foundations for a dynamic service-oriented platform which is able to personalize itself in large diversity of cooperating Software Intensive Systems (SIS).\n\nAccording to the vision of this project the relationship between humans, computers and electronic devices has evolved rapidly, defining technology eras with shifts in the related information technology (IT) business leadership. From the one-to-many relationship – computer versus human users – in the enterprise during the mainframe era in the 1960s, computers moved to the family environment with the personal computer (PC) in the 1980s. With the mobile phone, they established a personal one-to-one relationship ten years later.\n\nThe emergence of Ambient Intelligence is consequence of moving to a one-to-many relationship with phone complements, WiFi routers, gaming consoles, MP3 players, set-top boxes (STBs), TVs and infrastructures with impressive computing and storage capabilities. This environment is an enabler for a new concept of global and transversal platform that will exploit the real potential of the network affecting all business areas.\n\nIn this convergence process, the Ambient Intelligence can be defined as an automated service provider embedding the devices. The Ambient Intelligence platform will be able to personalise itself dynamically in devices according to the context (i.e. physical containers, user needs and environment). The consortium shares the vision of this platform emerging from a community process. The software infrastructure is progressively embedding users in a virtual world. In the long term, everyone will contribute as individual and community playing service-provider and consumer roles. This interaction will lead the evolution of the platform.\n\nThe global ITEA OSAMI project consists of a number of networked national sub-projects focussing on different areas from common technology foundations.\n\n"}
{"id": "3450450", "url": "https://en.wikipedia.org/wiki?curid=3450450", "title": "Philippine Science High School System", "text": "Philippine Science High School System\n\nThe Philippine Science High School System is a specialized public high school system in the Philippines that operates as an attached agency of the Philippine Department of Science and Technology. PSHS is considered as the top science high school in the Philippines and is viewed to be among the best in the ASEAN region by 2016.\n\nThe PSHS System offers scholarships to Filipino students who are gifted in the sciences and mathematics. Admission to the PSHS is by competitive examination, and only Filipino citizens are eligible to attend. Graduates of the PSHS are bound by law to major in the pure and applied sciences, mathematics, or engineering on entering college. The system is known to have a very challenging curriculum which produces the best professionals in the country.\n\nPSHS is known for its active participation in national and international science, technology, and mathematics competitions such as Sipnayan, Kapnayan, MATHirang MATHibay, Metrobank-MTAP-DepEd Math Challenge, Philippine Mathematics, Physics, and Chemistry Olympiads, Australian Mathematics Competition and Australian Chemistry Quiz. Through private funding, students successfully reap awards in international competitions such as the Taiwan International Science and Engineering Fair, Intel International Science and Engineering Fair, International Math Olympiad, International Junior Science Olympiad, International Earth Science Olympiad, International Olympiad on Astronomy and Astrophysics, and International Physics Olympiad.\n\nA movie was released in 2007 in honor of Philippine Science High School. \"Pisay\" got national and international recognition as it was sent to the Toronto International Film Festival. \"Pisay\" was directed by an alumnus of the school, Auraeus Solito, and was nominated for Best Documentary Feature Film at the 2008 Asia Pacific Screen Awards.\n\nFor 24 years, the PSHS was a single campus on Agham Road, Diliman, Quezon City where the top 240 examinees in the National Competitive Examination held yearly were accepted as government scholars. All campuses have at most 30 students in each class. However, regional campuses only have three classes in contrast to the main campus which has eight classes per batch. Currently, PSHS has 15 regional campuses in addition to the main campus.\n\nThe Board of Trustees (BOT) is the highest policy making body of the PSHS System. The Executive Committee (ExeCom), composed of the directors of different PSHS campuses, is a collegial body that recommends policies and guidelines for the consideration of the BOT. The Executive Committee is chaired by the Executive Director, who coordinates the implementation of these policies and guidelines. PSHS campuses are headed by directors who are members of the ExeCom.\n\nThe Philippine Science High School was established through Republic Act 3661, authored by Congressman Virgilio Afable, and signed into law in 1963 by President Diosdado Macapagal. This charter mandates the PSHS “to offer on a free scholarship basis a secondary course with emphasis on subjects pertaining to service with the end in view of preparing its students for a science career”. The school started operations in 1964.\n\nNational scientist Dr. Gregorio Velasquez led the PSHS through its first three years. The campus started in a small rented GSIS-owned property along the Quezon Memorial Circle. In 1970 PSHS started building on a 75,000 square metre lot along Agham Road in Diliman, Quezon City.\n\nBy the end of the 1980s, PSHS started to spread across the nation. The first regional campuses were built, starting with the Mindanao Campus (now Southern Mindanao Campus), in Davao City, in 1988.\n\nThe PSHS System Law (R.A. 8496) was signed by President Fidel V. Ramos in 1997 that established the PSHS System and unified all the existing campuses into a single system of governance and management. Thus, the PSHS continues fulfilling its mandate “to offer, on a free scholarship basis, a secondary course with special emphasis on subjects pertaining to the sciences, with the end view of preparing its students for a science career”.\n\n\n"}
{"id": "8607762", "url": "https://en.wikipedia.org/wiki?curid=8607762", "title": "Position sensitive device", "text": "Position sensitive device\n\nA Position Sensitive Device and/or Position Sensitive Detector (PSD) is an optical position sensor (OPS), that can measure a position of a light spot in one or two-dimensions on a sensor surface.\n\nPSDs can be divided into two classes which work according to different principles: In the first class, the sensors have an isotropic sensor surface that supplies continuous position data. The second class has discrete sensors in an raster-like structure on the sensor surface that supply local discrete data.\n\nThe technical term PSD was first used in a 1957 publication by J.T. Wallmark for \"lateral photoelectric effect \" used for local measurements. On a laminar semiconductor, a so-called PIN diode is exposed to a tiny spot of light. This exposure causes a change in local resistance and thus electron flow in four electrodes. From the currents formula_1, formula_2, formula_3 and formula_4 in the electrodes, the location of the light spot is computed using the following equations.\nand\n\nThe formula_7 and formula_8 are simple scaling factors, which permit transformation into coordinates.\nAn advantage of this process is the continuous measurement of the light spot position with measuring rates up to over 100 kHz. The dependence of local measurement on form and size of the light spot as well as the nonlinear connection are a disadvantage that can be partly compensated by special electrode shapes. \n\nA 2-D tetra-lateral PSD is capable of providing continuous\nposition measurement of the incident light spot in 2-D. It consists of a single square PIN diode with a resistive layer. When there is an incident light on the active area of the sensor, photocurrents are generated and collected from four electrodes placed along each side of the square near the boundary. The incident light position can be estimated based on currents collected from the electrodes: \n\nand\nThe 2-D tetra-lateral PSD has the advantages of fast response, much lower dark current, easy bias application and lower fabrication cost. Its measurement accuracy and resolution is independent of the spot shape and size unlike the quadrant detector which could be easily changed by air turbulence. However, it suffers from the nonlinearity problem. While the position estimate is approximately linear with respect to the real position when the spot is in the center area of the PSD, the relationship becomes nonlinear when the light spot is away from the center. This seriously limits its applications and there are urgent demands for linearity improvement in many applications. \n\nTo reduce the nonlinearity of 2-D PSD, a new set of formulae have been proposed to estimate the incident light position (Song Cui, Yeng Chai Soh：\"Linearity indices and linearity improvement of 2-D tetra-lateral position sensitive detector.\" IEEE Transactions on Electron Devices， Vol. 57, No. 9, pp. 2310-2316, 2010):\n\nand\nwhere :formula_13, and :formula_14 are new scale factors.\n\nThe position estimation results obtained by this set of formulae are simulated below. We assume the light spot is moving in steps in both directions and we plot position estimates on a 2-D plane. Thus a regular grid pattern should be obtained if the estimated position is perfectly linear with the true position. The performance is much better than the previous formulae. Detailed simulations and experiment results can be found in S. Cui's paper.\n\nThe most common sensor applications with a sampling rate of less than 1000 Hz are CCD or CMOS cameras. The sensor is partitioned into individual pixels whose exposure value can be read out sequentially. The position of the light spot can be computed with the methods of photogrammetry directly from the brightness distribution.\n\nFor faster applications, matrix sensors with parallel processing were developed. Both line by line and in columns, the density of light of each pixel is compared with a global threshold value. The results of comparison become lines and columns with logical OR links. From all columns and all lines the one element that is brighter than a given threshold value is the average value of the coordinates computed of the light spot.\n\n\n"}
{"id": "24064182", "url": "https://en.wikipedia.org/wiki?curid=24064182", "title": "Sandy Carter", "text": "Sandy Carter\n\nSandra “Sandy” Carter is an American business person, speaker and author. She was a general manager at IBM from 2013 to 2016, and in April 2017 she became a vice president at Amazon Web Services.\n\nCarter holds a Bachelor of Science in math and computer science from Duke University and an MBA from Harvard. She is fluent in eight programming languages. She is the author of five books, including “The New Language of Business: SOA & Web 2.0”, which won the Platinum MarCom Award in 2008, and “The New Language of Marketing 2.0: Social Media”, which won the Silver MarketingSherpa award in 2009.\n\nShe is chairman of the board for the non-profit organisation Girls in Tech and an adjunct professor at Carnegie Mellon Silicon Valley.\n\n\nCarter has authored four books “The New Language of Business: SOA & Web 2.0”, which won the Platinum MarCom Award in 2008, and “The New Language of Marketing 2.0: Social Media”, which won the Silver Marketing Sherpa award in 2009, \"Get Bold” in 2011, and \"Extreme Innovation: 3 Superpowers for Purpose and Profit\" released in 2017.\n\n\n"}
{"id": "22890808", "url": "https://en.wikipedia.org/wiki?curid=22890808", "title": "Simulation-based acquisition", "text": "Simulation-based acquisition\n\nIn the USA the Director for Test Systems Engineering and Evaluation (DTSE&E) commissioned in 1995 a one-year study to assess the effectiveness of the use of M&S in weapon systems acquisition and support processes.\n\nThe DTSE&E study developed an approach to acquisition which was named simulation-based acquisition (SBA).\n\nDTSE&E was disestablished by the US Secretary of Defense on 7 June 1999; some functions were transferred to the Director, Operational Test and Evaluation (DOT&E).\n\n"}
{"id": "5191421", "url": "https://en.wikipedia.org/wiki?curid=5191421", "title": "StICQ", "text": "StICQ\n\nstICQ is an ICQ client for mobile phones with symbian OS.\n\nStICQ has been written by Russian programmer Sergey Taldykin. StICQ is a native Symbian application (.SIS) for instant messaging over Internet for the ICQ network (using the OSCAR protocol).\n\nIt supports all main statuses including \"Not Available\", \"Invisible\" etc., contact search using ICQ UID, black lists, multi-user support, sound announcements and even SMS sending using default ICQ server.\n\nIt is featured by small size, low memory usage and relatively stable work.\n\nOne of the key features of the client is its ability to suspend outcoming data until GPRS coverage is available. It also suspend the status of the user, while all other mobile clients (Jimm, for instance) usually report connection problem and drop user out.\n\nCurrently, stICQ does not support smiley pictures but have a unique feature of quick emoticon input using the call button (special plugin required).\n\nNotable, stICQ supports the yellow \"Ready to chat\" extended status while \"Depressive\", as well as \"At home\", \"At work\" etc. are displayed as \"Offline\". This caused to call stICQ an \"anti-depressive ICQ\".\n\nThe source code has been sold to the development team of Quiet Internet Pager messenger. 1.01 version QiP for Symbian has been released recently.\n\nStICQ is free for download, as are wide variety of mods changing status icons and menu text.\n\n\n\n"}
{"id": "18041723", "url": "https://en.wikipedia.org/wiki?curid=18041723", "title": "TADIXS", "text": "TADIXS\n\nThe Tactical Data Information Exchange Subsystem (TADIXS) is a military communications system designed to allow the exchange of tactical information between commanders using the Global Command and Control System-Maritime (GCCS-M). Specifically, TADIXS allows for communication between land-based (shore) computer systems and those on U.S. Navy fleet ships deployed around the world.\n\nTADIXS has entered its fourth phase of development and is likely to replace the Officer in Tactical Command Information Exchange System (OTCIXS). This information exchange improves the overall situational awareness of tactical commanders in the field and strategic commanders at command and control centers.\n"}
{"id": "58534400", "url": "https://en.wikipedia.org/wiki?curid=58534400", "title": "Tech Bureau", "text": "Tech Bureau\n\nTech Bureau, Corp. is an internet and software development company based in Nishi-ku, Osaka, Japan.\n\nZaif is a cryptocurrency exchange that handles currencies including Bitcoin, Bitcoin Cash and Monacoin. As of September 2018, it was ranked as the 35th largest cryptocurrency exchange by turnover, and was one of sixteen cryptocurrency exchanges licensed and regulated by the Japanese Financial Services Agency (FSA). The FSA issued business improvement orders to the exchange in March and June 2018.\n\nOn September 14, 2018, the exchange was hacked and the equivalent of $60 million in cryptocurrency was stolen. The hackers reportedly gained access to \"hot wallets\" through which the exchange held funds for immediate transactions. Tech Bureau said that it did not notice the breach until Monday, September 17, and that the breach was then promptly reported to police and the FSA. The hack resulted in a suspension of withdrawals and deposits, and a bailout agreement with Fisco, a Japanese company that injected 5 billion yen in financial support to Tech Bureau. The FSA issued a third business improvement order to the exchange following the incident, and were reportedly considering suspending or cancelling its license.\n\nCOMSA is an integrated blockchain solutions provider offering initial coin offering fundraising and blockchain technology integration services.\n\n"}
{"id": "7570874", "url": "https://en.wikipedia.org/wiki?curid=7570874", "title": "Temporal isolation", "text": "Temporal isolation\n\nIn computer science, temporal isolation is the capability of a set of processes running on the same system to run without interferences concerning their temporal constraints among each other.\n\nSpecifically, there is temporal isolation among processes whenever the ability for each process to respect its own timing constraints (e.g. terminating a computation within a specified time) does not depend on the temporal behavior of other unrelated processes running on the same system, thus sharing with it a set of resources such as the CPU, disk, network, etc.\n\nOperating systems able to provide such guarantees to running processes are suitable for hosting real-time applications.\n"}
{"id": "26849676", "url": "https://en.wikipedia.org/wiki?curid=26849676", "title": "Tessellated roof", "text": "Tessellated roof\n\nTessellated roof is a frame and a self-supporting structural system in architecture. A simple ridged roof may inside be a tessellated system. The interlinking shapes are replicated across the moulded surface using curvilinear coordinates, a specific technique with rigid interlinking beams, having characteristics similar to woven fabric. A tessellated roof is one of the most flexible framed systems to design. The measurements and precision are complex and commonly part of a computer-aided design process of production. It is used in a honeycomb geometry form, in the biomes of the Eden Project.\n\nIt can be fabricated to fit a wide range of situations. The size of the repeated geometric shape used can be customised, with a multitude of the same shape throughout the structure. An even and equal load is shared by the interlocking structural integrity of the frame as a whole. The use of a tessellated roof for public areas is an increasingly implemented architectural feature of modern public buildings, covering walkways and over retail centers. A transparent roof being for shelter from the weather, has an advantage during daylight with electricity for artificial lighting in solid roof buildings being a financial cost.\n\nA modern tessellated roof for roofing public areas is a variation of a greenhouse or glass roof in different shapes and sized. The roof can be held aloft with columns, that may have branches to support and connect to the roof latticework, which stabilise the roof to create a strong structure. The material of the roof in-between or covering the tessellated frame may be a light composite, toughened glass or insulated glazing. There are roofed boulevards with columns that can form a colonnade. Some tessellated roof shapes connect to the ground in place of conventional rain gutters, for example the FieraMilano, or it can be supported entirely by the surrounding buildings. A tessellated roof can convert previous outdoor space into a dry public area; some examples of this method are Galleria Vittorio Emanuele II and many other shopping complexes or the Queen Elizabeth II Great Court at the British Museum in London by Norman Foster.\n\n"}
{"id": "58263364", "url": "https://en.wikipedia.org/wiki?curid=58263364", "title": "Tim Rowe", "text": "Tim Rowe\n\nTimothy Rowe is the founder and CEO of Cambridge Innovation Center (CIC), founder of Venture Café, partner of New Atlantic Ventures, Chair of LabCentral, and Chair of MassRobotics. Previously, Tim has served as a lecturer at the MIT Sloan School of Management, a manager with the Boston Consulting Group, and an analyst with the Mitsubishi Research Institute. Tim speaks Spanish and Japanese fluently and holds an MBA from MIT’s Sloan School of Management and a BA from Amherst College. \n\nHe was one of the major supporters of the Kendall Square Association, a group designed to nurture innovation in the area around the Massachusetts Institute of Technology. In 212, he helped create their \"Walk of Fame\" to help make the contributions of innovators more obvious to the walking public. The group installed plaques on the sidewalks modeled after the stars along Hollywood Boulevard. \n\nTim contacted MIT for their smallest space to lease, eventually signing a lease for a 3,000-square-foot office. The space was too large for just him and his wife, so they invited friends to stay with them. Tim, his wife Amy, and his friends begin starting companies and began using the offices for their new companies. It was during this time that Tim came up with the idea to create a shared work environment, which became the Cambridge Innovation Center (CIC).\n\nRowe is a connector who is driven to bring people together to apply their talents to solving problems.. When Joi Ito came to Boston to run the MIT Media Lab, Tim brought Joi to CIC with Rich Miner.In 2014, he was named Entrepreneur of the Year. \n\nCIC is the \"largest space for startups.\" CIC currently has shared innovation spaces with the Cambridge Space, and spaces in Boston, Massachusetts; Miami, Florida; St. Louis, Missouri; Rotterdam, Netherlands; and soon Philadelphia, Philadelphia.\n\n\n"}
{"id": "58486621", "url": "https://en.wikipedia.org/wiki?curid=58486621", "title": "WISPR", "text": "WISPR\n\nThe Wide-Field Imager for Solar Probe (WISPR) is an imaging instrument of the \"Parker Solar Probe\" mission to the Sun, launched in August 2018. Imaging targets include visible light images of the corona, solar wind, shocks, solar ejecta, etc. Development of WISPR was led by the U.S. Naval Research Laboratory. The \"Parker Solar Probe\" with WISPR on board was launched by a Delta IV Heavy on 12 August 2018 from Cape Canaveral, Florida. WISPR is intended take advantage of the spacecraft's proximity to the Sun by taking coronagraph-style images of the solar corona and features like coronal streamers, plumes, and mass ejections. One of the goals is to better understand the structure of the solar corona near the Sun.\n\nWISPR is designed to study the electron density and velocity structure of the corona. The instrument field of view is planned to extend from 13 to 108 degrees away from the Sun, and does not directly image the Sun; the area of interest is a very wide field extending away from the Sun.\n\nWISPR includes two separate telescopes, each with a radiation-hardened CMOS imager with resolution of 2,000×2,000 pixels. The CMOS sensors are an active pixel sensor type of detector.\n\nThe WISPR first light image was published in September 2018.\n\n"}
