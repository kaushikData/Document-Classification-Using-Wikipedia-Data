{"id": "19634920", "url": "https://en.wikipedia.org/wiki?curid=19634920", "title": "Acision", "text": "Acision\n\nHaving been acquired by Comverse, Inc. on 6 August 2015, Acision was known as Xura, a new company launched on 9 September 2015 combining both companies. In 2017, Xura became Mavenir after Xura acquired a start up called Ranzure and Mavenir Systems. Prior to this, it was a privately held mobile communications software company specialising in messaging systems that enable popular services such as text messaging or Short Message Service (SMS), Multimedia Messaging Service (MMS), voicemail, IP Messaging, Mobile Value Added Services and Enterprise Mobility Solutions.\n\nBefore Xura, Inc. Acision's roots came from two companies:\n\nIn 1997, Aldiscon was acquired by UK-based Logica, which merged with CMG in 2002 to form LogicaCMG. Both company's wireless divisions merged into LogicaCMG Wireless Networks. Acision was born on February 20, 2007, when LogicaCMG Wireless Networks was sold for £265m (US $525m) to private investors Atlantic Bridge Ventures and Access Industries and became known as Acision. The lead investor at Atlantic Bridge (and now executive chairman at Acision), Laurence Quinn, was one of the founders of Aldiscon.\n\nIn 2015 Acision was acquired by Comverse.\n\nIn September 2015, Xura, Inc. was launched. The new joint entity changed its name to Xura, Inc. The name 'Xura' was supposedly adapted from the word 'Aura'.\n\n\n"}
{"id": "399476", "url": "https://en.wikipedia.org/wiki?curid=399476", "title": "Aluminium foil", "text": "Aluminium foil\n\nAluminium foil (or aluminum foil), often referred to with the misnomer tin foil, is aluminium prepared in thin metal leaves with a thickness less than ; thinner gauges down to are also commonly used. In the United States, foils are commonly gauged in thousandths of an inch or mils. Standard household foil is typically thick, and heavy duty household foil is typically . The foil is pliable, and can be readily bent or wrapped around objects. Thin foils are fragile and are sometimes laminated to other materials such as plastics or paper to make them more useful. Aluminium foil supplanted tin foil in the mid 20th century.\n\nAnnual production of aluminium foil was approximately in Europe and in the U.S. in 2003. Approximately 75% of aluminium foil is used for packaging of foods, cosmetics, and chemical products, and 25% used for industrial applications (e.g. thermal insulation, cables and electronics). It can be recycled.\nIn North America, aluminium foil is known as aluminum foil. It was popularised by Reynolds Metals, the leading manufacturer in North America. In the United Kingdom and United States it is, informally, widely called tin foil, for historical reasons (similar to how aluminium cans are often still called (\"tin cans\"). Metallised films are sometimes mistaken for aluminium foil, but are actually polymer films coated with a thin layer of aluminium. In Australia, aluminium foil is widely called alfoil.\n\nFoil made from a thin leaf of tin was commercially available before its aluminium counterpart. Tin foil was marketed commercially from the late nineteenth into the early twentieth century. The term \"tin foil\" survives in the English language as a term for the newer aluminium foil. Tin foil is less malleable than aluminium foil and tends to give a slight tin taste to food wrapped in it. Tin foil has been supplanted by aluminium and other materials for wrapping food.\n\nThe first audio recordings on phonograph cylinders were made on tin foil.\n\nTin was first replaced by aluminium in 1910, when the first aluminium foil rolling plant, \"Dr. Lauber, Neher & Cie.\" was opened in Emmishofen, Switzerland. The plant, owned by J.G. Neher & Sons, the aluminium manufacturers, started in 1886 in Schaffhausen, Switzerland, at the foot of the Rhine Falls, capturing the falls' energy to process aluminium. Neher's sons, together with Dr. Lauber, discovered the endless rolling process and the use of aluminium foil as a protective barrier in December 1907.\n\nIn 1911, Bern-based Tobler began wrapping its chocolate bars in aluminium foil, including the unique triangular chocolate bar, Toblerone. By 1912, aluminium foil was being used by Maggi (today a Nestlé brand) to pack soups and stock cubes. \n\nThe first use of foil in the United States was in 1913 for wrapping Life Savers, candy bars, and gum. Processes evolved over time to include the use of print, colour, lacquer, laminate and the embossing of the aluminium.\n\nAluminium foil is produced by rolling sheet ingots cast from molten billet aluminium, then re-rolling on sheet and foil rolling mills to the desired thickness, or by continuously casting and cold rolling. To maintain a constant thickness in aluminium foil production, beta radiation is passed through the foil to a sensor on the other side. If the intensity becomes too high, then the rollers adjust, increasing the thickness. If the intensities become too low and the foil has become too thick, the rollers apply more pressure, causing the foil to be made thinner.\n\nThe continuous casting method is much less energy intensive and has become the preferred process. For thicknesses below , two layers are usually put together for the final pass and afterwards separated which produces foil with one bright side and one matte side. The two sides in contact with each other are matte and the exterior sides become bright; this is done to reduce tearing, increase production rates, control thickness, and get around the need for a smaller diameter roller.\n\nSome lubrication is needed during the rolling stages; otherwise, the foil surface can become marked with a herringbone pattern. These lubricants are sprayed on the foil surface before passing through the mill rolls. Kerosene based lubricants are commonly used, although oils approved for food contact must be used for foil intended for food packaging.\n\nAluminium becomes work hardened during the cold rolling process and is annealed for most purposes. The rolls of foil are heated until the degree of softness is reached, which may be up to for 12 hours. During this heating, the lubricating oils are burned off, leaving a dry surface. Lubricant oils may not be completely burnt off for hard temper rolls, which can make subsequent coating or printing more difficult.\n\nThe rolls of aluminium foil are then slit on slitter rewinding machines into smaller rolls. Roll slitting and rewinding is an essential part of the finishing process.\n\nAluminium foils thicker than are impermeable to oxygen and water. Foils thinner than this become slightly permeable due to minute pinholes caused by the production process.\n\nAluminium foil has a shiny side and a matte side. The shiny side is produced when the aluminium is rolled during the final pass. It is difficult to produce rollers with a gap fine enough to cope with the foil gauge, therefore, for the final pass, two sheets are rolled at the same time, doubling the thickness of the gauge at entry to the rollers. When the sheets are later separated, the inside surface is dull, and the outside surface is shiny. This difference in the finish has led to the perception that favouring a side has an effect when cooking. While many believe (wrongly) that the different properties keep heat out when wrapped with the shiny finish facing out, and keep heat in with the shiny finish facing inwards, the actual difference is imperceptible without instrumentation. Increased reflectivity decreases both absorption and emission of radiation. Foil may have a non-stick coating on only one side. The reflectivity of bright aluminium foil is 88% while dull embossed foil is about 80%.\n\nAluminium is used for packaging as it is highly malleable: it can be easily converted to thin sheets and folded, rolled or packed. Aluminium foil acts as a total barrier to light and oxygen (which cause fats to oxidise or become rancid), odours and flavours, moistness, and germs, and so it is used broadly in food and pharmaceutical packaging, including long-life packs (aseptic packaging) for drinks and dairy goods, which allows storing without refrigeration. Aluminium foil containers and trays are used to bake pies and to pack takeaway meals, ready snacks and long life pet foods.\n\nAluminium foil is widely sold into the consumer market, often in rolls of width and several metres in length. It is used for wrapping food in order to preserve it, for example, when storing leftover food in a refrigerator (where it serves the additional purpose of preventing odour exchange), when taking sandwiches on a journey, when baking, or when selling some kinds of take-away or fast food. Tex-Mex restaurants in the United States, for example, typically provide take-away burritos wrapped in aluminium foil.\n\nAluminium foil is widely used for radiation shield (barrier and reflectivity), heat exchangers (heat conduction) and cable liners (barrier and electrical conductivity). Aluminium foil's heat conductive qualities make it a common accessory in hookah smoking: a sheet of perforated aluminium foil is frequently placed between the coal and the tobacco, allowing the tobacco to be heated without coming into direct contact with the burning coal.\n\nThe shielding effectiveness of aluminium foil depends upon the type of incident field (electric, magnetic, or plane wave), the thickness of the foil, and the frequency (which determines the skin depth). Shielding effectiveness is usually broken down into a reflection loss (the energy bounces off the shield rather than penetrates it) and an absorption loss (the energy is dissipated within the shield).\n\nAlthough aluminium is non-magnetic, it is a good conductor, so even a thin sheet reflects almost all of an incident electric wave. At frequencies more than 100 MHz, the \"transmitted\" electric field is attenuated by more than 80 decibels (dB) (less than 10 = 0.00000001 of the power gets through) -- however actual energy absorption is minimal: the remaining high-frequency rf energy is almost perfectly reflected from uniform flat aluminium surface, and thus, reflected signal may continue to propagate internally, and if holes or passages of suitable geometry exist in the shield, signal propagation may continue out through those, the aluminium being good material for implementation of a microwave-frequency waveguide.\n\nThin sheets of aluminium are not very effective at attenuating low-frequency magnetic fields. The shielding effectiveness is dependent upon the skin depth. A field travelling through one skin depth will lose about 63 per cent of its energy (it is attenuated to 1/e = 1/2.718... of its original energy). Thin shields also have internal reflections that reduce the shielding effectiveness. For effective shielding from a magnetic field, the shield should be several skin depths thick. Aluminium foil is about ; a thickness of (ten times thicker) offers less than 1 dB of shielding at 1 kHz, about 8 dB at 10 kHz, and about 25 dB at 100 kHz. At these frequencies a ferromagnetic material such as mild steel is much more effective, due to different and complementary electromagnetic permeability properties, and common practical shielding implementations utilise both an inner high-frequency reflective material such as aluminium, preferably bonded (via annealing or electroplating, done to avoid capacitance between separated layers), to a more substantial structural ferromagnetic shell, usually mild steel (in specialized applications, more expensive, less structurally useful and less workable materials may be preferred.) Despite the relative low mass density of aluminium, this design is usually both lighter and more effective than an equivalently absorptive design utilizing aluminium alone (although with poorer heat dissipative properties, typically accommodated by improved ventilation, which itself needs careful consideration in order to preserve the desired shielding effectiveness).\n\nAluminium foil is also used for barbecuing delicate foods, such as mushrooms and vegetables. Using this method, sometimes called a hobo pack, food is wrapped in foil, then placed on the grill, preventing loss of moisture that may result in a less appealing texture.\n\nAs is the case with all metallic items, aluminium foil reacts to being placed in a microwave oven. This is because of the electromagnetic fields of the microwaves inducing electric currents in the foil and high potentials at the sharp points of the foil sheet; if the potential is sufficiently high, it will cause electric arcing to areas with lower potential, even to the air surrounding the sheet. Modern microwave ovens have been designed to prevent damage to the cavity magnetron tube from microwave energy reflection, and aluminium packages designed for microwave heating are available.\n\nHeavier foils made of aluminium are used for art, decoration, and crafts, especially in bright metallic colours. Metallic aluminium, normally silvery in colour, can be made to take on other colours through anodisation. Anodising creates an oxide layer on the aluminium surface that can accept coloured dyes or metallic salts, depending on the process used. In this way, aluminium is used to create an inexpensive gold foil that actually contains no gold, and many other bright metallic colours. These foils are sometimes used in distinctive packaging.\n\nFoil is used by organic/petroleum geochemists for protecting rock samples taken from the fields and in the labs where the sample is subject to biomarker analysis. While plastic or cloth bags are normally used for a geological sampling exercise, cloth bags are permeable and may allow organic solvents or oils (such as oils imparted from the skin) to taint the sample, and traces of the plastics from plastic bags may also taint the sample. Foil provides a seal to the ingress of organic solvents and does not taint the sample. Foil is also used extensively in geochemical laboratories to provide a barrier for the geochemist, and for sample storage.\n\nThe material used in many ribbon microphones is aluminium leaf, or \"imitation silver leaf\", as it is sometimes called. This is pure aluminium and is around 0.6 to 2.0 micrometres thick. It is virtually the same material that the BBC used on Coles ribbons, with the exception that they also hand beat the leaf even thinner. They did this by sandwiching the ribbon between toilet paper and beating with a ball-peen hammer. This \"cold forges\" the leaf. The aluminium leaf was then annealed for an hour in an oven to restore flexibility. Corrugations must also be imparted into the ribbon: Coles used 25 per inch (1 mm cycle). RCA 44BX has 19 corrugations per inch (0.7 mm cycle) and is around long; RCA 77 has 13 corrugations per inch (0.5 mm cycle). RCA ribbon material is around 1 to 1.5 micrometres (0.00005 inch) thick. The new Nady ribbon plus AEA both state that they use 2 micrometre aluminium ribbon in their microphones.\n\nSome aluminium foil products can be recycled at around 5% of the original energy cost, although many aluminium laminates are not recycled due to difficulties in separating the components and low yield of aluminium metal.\n\n\n"}
{"id": "1237523", "url": "https://en.wikipedia.org/wiki?curid=1237523", "title": "Automatic picture transmission", "text": "Automatic picture transmission\n\nThe Automatic Picture Transmission (APT) system is an analog image transmission system developed for use on weather satellites. It was introduced in the 1960s and over four decades has provided image data to relatively low-cost user stations at locations in most countries of the world. A user station anywhere in the world can receive local data at least twice a day from each satellite as it passes nearly overhead.\n\nThe broadcast transmission is composed of two image channels, telemetry information, and synchronization data, with the image channels typically referred to as Video A and Video B. All this data is transmitted as a horizontal scan line. A complete line is 2080 pixels long, with each image using 909 pixels and the remainder going to the telemetry and synchronization. Lines are transmitted at 2 per second, which equates to a 4160 words per second, or 4160 baud.\n\nOn NOAA POES system satellites, the two images are 4 km / pixel smoothed 8-bit images derived from two channels of the advanced very-high-resolution radiometer (AVHRR) sensor. The images are corrected for nearly constant geometric resolution prior to being broadcast; as such, the images are free of distortion caused by the curvature of the Earth.\n\nOf the two images, one is typically long-wave infrared (10.8 micrometers) with the second switching between near-visible (0.86 micrometers) and mid-wave infrared (3.75 micrometers) depending on whether the ground is illuminated by sunlight. However, NOAA can configure the satellite to transmit any two of the AVHRR's image channels.\n\nIncluded in the transmission are a series of synchronization pulses, minute markers, and telemetry information.\n\nThe synchronization information, transmitted at the start of each video channel, allows the receiving software to align its sampling with the baud rate of the signal, which can vary slightly over time. The minute markers are four lines of alternating black then white lines which repeat every 60 seconds (120 lines).\n\nThe telemetry section is composed of sixteen blocks, each 8 lines long, which are used as reference values to decode the image channels. The first eight blocks, called \"wedges,\" begin at 1/8 max intensity and successively increase by 1/8 to full intensity in the eighth wedge, with the ninth being zero intensity. Blocks ten through fifteen each encode a calibration value for the sensor. The sixteenth block identifies which sensor channel was used for the preceding image channel by matching the intensity of one of the wedges one through six. Video channel A typically matches either wedge two or three, channel B matches wedge four.\n\nThe first fourteen blocks should be identical for both channels. The sixteen telemetry blocks repeat every 128 lines, and these 128 lines are referred to as a frame.\n\nThe signal itself is a 256-level amplitude modulated 2400Hz subcarrier, which is then frequency modulated onto the 137 MHz-band RF carrier. Maximum subcarrier modulation is 87% (±5%), and overall RF bandwidth is 34 kHz. On NOAA POES vehicles, the signal is broadcast at approximately 37dBm (5 watts) effective radiated power.\n\nAn APT signal is continuously broadcast, with reception beginning at the start of the next line when the receiver is within radio range. Images can be received in real-time by relatively unsophisticated, inexpensive receivers during the time the satellite is within radio range, which typically lasts 8 to 15 minutes.\n\nThe bandwidth required to receive APT transmissions is approximately 34 kHz. Most older scanners (police and fire type receivers) are the standard 15 kHz bandwidth which were designed to support voice transmissions. Newer VHF general coverage receivers are equipped with multiple IF bandpasses; some are, but not limited to: 6 kHz, 15 kHz 50 kHz & 230 kHz(broadcast FM). Use of a receiver with too narrow a bandwidth will produce pictures that are saturated in the blacks and whites, as well as possible inversion. Too wide, and the noise floor of the receiver will be too high to acquire a good picture. For the amateur enthusiast, a computer controller receiver is the best option to allow the software to automatically tune and set the required modes for proper reception. There are also dedicated APT receivers made specifically for computer control and APT reception. Specifically, ICOM PCR1000, PCR1500 & PCR2500 will produce excellent results. Searching on the web for \"NOAA APT (RECEPTION or RECEIVER)\" will produce a wealth of information on receivers, software, and antennas.\n\nAPT images from weather satellites can be received with a right-hand circular polarized, 137 MHz antenna. Normally, there is no need to have the antenna follow the satellite and a fixed position antenna will provide good results.\n\nThe two most frequently recommended antennas are the crossed dipole and the quadrifilar helix antenna (QHA).\n\nYears ago, to receive APT images, a specialized decoder was required in addition to the receiver to display or print images, much like HF WEFAX (serving the maritime community). Often both receiver and decoder were combined into one unit.\n\nToday, with the advent of personal computers, all that is required is dedicated software (many of which offer \"free\" versions ) and a sound card. The sound card acquires and digitizes the slow scan video (in the audible range) coming from the speaker, phones, or line-out of the receiver, and then the software will process the various visible and infrared channels of the AVHRR sensor. Most software will automatically save every image and publish processed image onto the website of choice, putting up a new image on every pass of an APT satellite.\n\nSince each channel of the AVHRR sensor is sensitive to only one wavelength of light, each of the two images is luminance only, also known as grayscale. However, different materials tend to emit or reflect with a consistent relative intensity. This has enabled the development of software that can apply a color palette to the images which simulates visible light coloring. If the decoding software knows exactly where the satellite was, it can also overlay outlines and boundaries to help in utilizing the resulting images.\n\n\n\nNone.\n\nWith improvements in electronics, analog transmission systems have given way to digital transmissions systems. NOAA-19, called NOAA-N' prior to its launch on 6 February 2009, is the last satellite to carry an APT system. The MetOp program, a collaboration between NOAA and EUMETSAT, has switched to Low Rate Picture Transmission (LRPT) for its new polar-orbit satellites.\n\n\n"}
{"id": "36550537", "url": "https://en.wikipedia.org/wiki?curid=36550537", "title": "Barcelona International Centre of Photography", "text": "Barcelona International Centre of Photography\n\nThe Barcelona International Centre of Photography (El \"Centre Internacional de Fotografia Barcelona\", in Catalan language, CIFB) was a singular initiative in the photographic culture of Spain in the second half of the 1970s, becoming a pioneering institution in the formation, study, exhibition, distribution and production of the photographic image. \n\nThe professional career of its initiator, Albert Guspi (1943-1985), an important innovator and central figure within the new photographic scene of the seventies, culminated in the creation of the CIFB. Despite its brief five-year existence, the CIFB became a reference in the reformation of photographic culture during the Spanish transition to democracy. \n\nIn the heart of the Raval, at Carrer Aurora 11 bis, we can still find the building that once housed the Centre Internacional de Fotografia Barcelona, CIFB. On its façade, an icon of the renovation of the neighbourhood, we can still see the paintings by Arranz Bravo and Bartolozzi, restored in 1997. \n\nThe CIFB was a short-lived experiment in the process of institutionalisation of photographic culture during Spain's democratic Transition. The current study of this experiment, little known and almost forgotten despite its nearness in time and space, should be understood from a double perspective: local and global. On the one hand, this is a local study of a process that was taking place at an international level during the seventies: the re-composition of the cultural field within the new cultural industries following a post-industrial economic model. This was a moment of great expansion for the art market, with photography becoming part of it to an unprecedented degree. The seventies marked the beginning of a great international resurgence of institutions, festivals, academic programmes, galleries and publications that laid down the conditions for the interpenetration of culture and economy as it is known today. On the other hand, this is a study of how such generalised historical conditions took on a specific, local and very concrete form in the field of photography in Barcelona during the Transition. In this sense, the study sheds a different light on the period, allowing us to understand how disparate photographic practices and traditions, which have since become separate, were able to coexist at the time. The multiplicity of the seventies eventually lost ground when faced with a visualist conception of creative photography, whose hegemony began to establish itself after the Jornades Catalanes de Fotografia, which took place at the Fundació Joan Miró in 1980, and which, in retrospect, are still regarded as photography's official entry into the new cultural policies. The CIFB declined to take part in the Jornades.\n\n"}
{"id": "795072", "url": "https://en.wikipedia.org/wiki?curid=795072", "title": "Binder clip", "text": "Binder clip\n\nA binder clip, less commonly known as a banker's clip or foldover clip, is a simple device for binding sheets of paper together. It leaves the paper intact and can be removed quickly and easily, unlike the staple. The term \"foldback clip\" is used in the United Kingdom to describe this invention (not to be confused with a Bulldog clip, an older device with the same function, which is stronger and has rigid rather than folding handles). It is also sometimes referred to as a \"handbag clip\" because, when not in use, its clip can be folded up to look like a handbag.\n\nA binder clip is a strip of spring steel bent into the shape of an isosceles triangle with loops at the . Tension along the base of the triangle forces the two sides closed, and the loops prevent the sharp steel edges from cutting into the paper. The loops also serve to hold two pieces of stiff wire, which are used as handles and allow the clip to be opened. The two slots cut in each loop are shaped so that the wire handles can be folded down once the clip has been attached, and the spring force of the wire holds them down on the surface of the paper. This holds the clip relatively flat, for easier stacking of paper. One handle can also be folded down while the other remains up to allow the stack of papers to be hung up. The handles can also be removed altogether by squeezing them sideways and pulling them out, allowing for more permanent binding. As compared to a paper clip, the binder clip is able to bind sheets of paper more securely, and is also resistant to rust.\n\nThere are several sizes of binder clips, ranging from a base size of 5 millimetres (0.2 in) to 50 mm (1.97 in). The sheet steel portion is customarily black oxide coated, but a variety of decorative painted color schemes are also available. The sheet steel portion is occasionally made of stainless steel, the more typical spring steel can also be finished in nickel, silver or gold. The handles are normally nickel-plated.\n\nThe binder clip is in common use in the modern office. It can hold a few to many sheets of paper, and is usually used in place of the paper clip for large volumes of paper. Various practical (and sometimes whimsical) alternative uses have been proposed. These include holding pieces of quilt together, creating a \"beer pyramid\" in a refrigerator with wire shelves, serving as a bookmark, a cheap alternative to a money clip or preventing computer cables from slipping behind desks. Smaller sized clips have been commonly used as \"quick fix\" fitting and sizing solutions in the fashion industry.\n\nIn 1966, test pilot Joseph F. Cotton used the shiny metal portion of such a clip to short-circuit an electrical circuit panel to force the landing gear of the XB-70 bomber on a flight.\n\nThe binder clip was invented in 1910 by Washington resident Louis E. Baltzley, who ultimately was granted for his invention. At that time, the method of binding sheets of paper together was to punch holes in them and sew them together, making it tedious to remove a single sheet of paper.\n\nLouis Baltzley invented the binder clip to help his father, Edwin Baltzey, a writer and inventor, hold his manuscripts together easily. While the original design has since been changed five times, the basic mechanism has remained the same.\n\nBaltzey initially produced his invention through the L.E.B. Manufacturing Company. These earliest binder clips are stamped \"L.E.B.\" on one side of the sheet steel. Manufacturing rights were later licensed to other companies.\n"}
{"id": "33891099", "url": "https://en.wikipedia.org/wiki?curid=33891099", "title": "BioLineRx", "text": "BioLineRx\n\nBioLineRx (), or BioLine, is a publicly traded drug development company that seeks to discover compounds for disease treatment and develop them into commercializable drugs. Headquartered in Israel, its shares are traded on the NASDAQ Capital Market and on the Tel Aviv Stock Exchange.\n\nBioLineRx is a drug development company that seeks to discover compounds with potential to treat a variety of diseases, including cancer, schizophrenia and cardiac deterioration. When promising compounds are discovered, BioLine leads them through preclinical trials and engages other companies to advance the compounds' development into commercializable drugs. The company entered into its first major commercialization agreement in 2009 when it partnered with Ikaria Holdings Inc. to develop its BL-1040 compound. In 2010 BioLine entered into a commercialization agreement with Cypress Bioscience Inc. for development of its BL-1020 compound. The agreement with Cypress was canceled in 2011 when the company was taken over by Ramius LLC.\n\nBelow is a partial list of drug compounds in various stages of development by BioLineRx. Unless indicated otherwise, they have not obtained regulatory approval in relation to the diseases cited.\n\nBioLine's business model consists of three stages. In the first stage, called the \"bench\" stage, the potential drug candidate is evaluated \"from both scientific and marketing perspectives.\" In the second stage, called the \"bedside\" stage, BioLine accompanies the drug through early clinical trials. In the third stage, the \"partner\" stage, BioLine enters into strategic partnership with a pharmaceutical company to see the drug through its advanced clinical trials and bring it to the market.\n\nBioLineRx was established in 2003 as a joint venture of Teva, Hadasit Bio-Holdings, the Jerusalem Development Authority, Yehuda Zisapel, and other investors. It executed an initial public offering on the Tel Aviv Stock Exchange in February 2007, raising 211 million NIS ($50 million) – the TASE's largest biotech IPO until that time. In August 2011 BioLine's ADRs began trading on the NASDAQ Capital Market. In January 2012, BioLineRx announced a deal with Genoscience, a French pharmaceutical company to jointly develop and market the BL-8020 compound, as a treatment for Hepatitis C. At the end of 2014, Novartis acquired a 12.8% stake in the company as a strategic move to gain access to Israeli-sourced drug candidates.\n\nMorris Laster, Downstate Medical Center (M.D.) and SUNY Albany (B.Sc.) alumnus, was CEO of BioLineRx until 2009. He was replaced by Kinneret Savitsky, alumnus of Tel Aviv University (Master's and Ph.D.) and the Hebrew University of Jerusalem (B.Sc.), early in 2010. Savitsky was replaced as CEO by BioLine COO Philip Serlin on October 10, 2016.\n\n\n"}
{"id": "43330686", "url": "https://en.wikipedia.org/wiki?curid=43330686", "title": "Busbud", "text": "Busbud\n\nBusbud is a worldwide bus and coach travel company that allows travellers to search, compare, and book intercity bus tickets. Busbud operates throughout Europe, South America, North America, Africa and South East Asia. It partners with over 1,300 bus and coach operators to provide a search engine and a booking platform via its website and mobile app. Busbud serves 19,000 cities in 79 countries, in 11 languages, and 30 currencies.\n\nBusbud was founded after CEO and co-founder, LP Maurice, spent 2011 backpacking throughout South America. He faced many difficulties finding and booking reliable inter-city buses throughout the continent and began drafting a business plan on a 10-hour bus ride in Argentina. He then came back to Montreal and founded Busbud with longtime friends, Michael Gradek (CTO and Microsoft Bing veteran) and Frederic Thouin (CAO). The company acts as a reseller, but also provides support on the bus tickets that are sold.\n\nBusbud caters to local and international travellers by offering intercity bus routes in 79 countries. Bus ticket prices are available on Busbud in 30 currencies, while the website is available in 11 languages. They have rolled out features such as Apple Pay, interconnected bus routes and travel reviews on their platform.\n\nBusbud has recently integrated one of the largest bus companies in the world, Autobuses de Oriente (ADO), operating in Mexico. Tourists and travellers are able, for the first time, to buy their ADO tickets in their local currency and language, using their preferred method of payment as Busbud is the first international bus booking platform to offer this on the market.\n\nBacked by venture and angel investors, Busbud has an advisory board made up of Expedia Board Member and Managing Partner of InterMedia Partners, Peter Kern; TripAdvisor VP of SEO, Luc Levesque; CEO of the travel startup Luxury Retreats, Joe Poulin, and Orleans Express founder Sylvain Langis.\n\nIn May 2013, Busbud completed a seed round financing of $1.2 million, which was co-led by Canadian funds iNovia Capital and Real Ventures.\n\nIn July, 2014, Busbud acquired another round of funding of $9 million, co-led by OMERS Ventures and Revolution Ventures. Busbud's plans include growing its in-house team, expanding its route territory, and developing an improved version of their iOS and Android mobile app.\n\nIn January 2018, Busbud announced a US$11 Million Series B round of funding, led by iNovia Capital and included new investors Teralys, Claridge and Plaza Ventures, as well as Real Ventures. The capital will be used to fuel technology development, further grow the team and accelerate geographic expansion.\n"}
{"id": "16018870", "url": "https://en.wikipedia.org/wiki?curid=16018870", "title": "Centre stick", "text": "Centre stick\n\nA centre stick (or center stick in the United States), or simply control stick is an aircraft cockpit arrangement where the control column (or joystick) is located in the center of the cockpit between the pilot's legs. Since the throttle controls are typically located to the left of the pilot, the right hand is used for the stick, although left-hand or both-hands operation is possible if required.\n\nThe centre stick is a part of an aircraft's flight control system, and is typically linked to its ailerons and elevators, or alternatively to its elevons, by control rods or control cables on basic aircraft. On heavier, faster, more advanced aircraft the centre stick may also control power-assist modules. Modern aircraft centre sticks are also usually equipped with a number of electrical control switches within easy finger reach, in order to reduce the pilot's workload.\n\nThe centre stick is used in many military fighter jets such as Eurofighter Typhoon and the Mirage III, but also in light aircraft such as Piper Cubs and the Diamond Aircraft line of products such as the DA20, DA40 and DA42.\n\nThis arrangement contrasts with the more recently developed \"side-stick\" which is used in such military fighter jets as the F-16, the F-35 Lightning II and Rafale and also on civil aircraft such as the Airbus A320.\n\nThe centre stick originated at the turn of the twentieth century. In 1900 Wilhelm Kress of Austria developed a control stick for aircraft, but did not apply for a patent. Instead, a patent was awarded to the French aviator, Robert Esnault-Pelterie who applied for it in 1907.\n\n"}
{"id": "12310344", "url": "https://en.wikipedia.org/wiki?curid=12310344", "title": "Coal-tax post", "text": "Coal-tax post\n\nCoal-tax posts are boundary marker posts found in southern England. They were erected in the 1860s and form an irregular loop between 12 and 18 miles from London to mark the points where taxes on coal were due to the Corporation of London. There were originally around 280 posts of which around 210 remain. \n\nCoal imported into the City of London had been taxed since medieval times and, as it was originally all brought by sea to riverside wharfs, the collection of the duties was relatively easy. The city is a small (one square mile) but influential and rich part of London. The Port of London, within which the duties were payable, stretched far beyond the boundaries of the City, all the way along the Thames from Yantlet Creek (downstream from Gravesend) to Staines.\n\nBy the 19th century, however, there was increasing trade by canal and rail, and various Acts of Parliament extended the catchment area to include these new modes of transport. In 1845 the boundary was set at a radius of 20 miles from the General Post Office, London, from Langley in the west to Gravesend in the east and from Ware in the north to Redhill in the south. In 1851 an Act permitted the erection of boundary markers to indicate where this boundary lay; and about fifty markers, inscribed with a reference to the Act, were erected.\n\nIn 1861 a further Act – the London Coal and Wine Duties Continuance Act 1861 – was passed, reducing the area to that of the Metropolitan Police District plus the City of London. This stretched from Colnbrook in the west to Crayford Ness, at the mouth of the River Darent, in the east, and from Wormley, Hertfordshire in the north to Banstead Heath, Surrey in the south. New marker posts (about 280) were erected to show the boundary within which the duty was payable. These again cite the Act by regnal year and chapter number, i.e. 24 & 25 VICT CAP 42. In some cases, notably on railways and canals, markers made for earlier acts were reused on the new boundary. Most (over 200) of these posts survive. Although the title of the Act refers to wine duties, these were collected only in the Port of London: the boundary marks have no connection with the wine duties and it is incorrect to call them \"coal and wine duty posts\".\n\nThe purpose of the posts was to give notice of where the boundary ran so that no-one could claim ignorance of liability to pay the duties. However, in general, duties were not actually collected on the boundary. The one known exception was the Grand Junction Canal: originally customs officers collected the duties at Grove Park, Hertfordshire. After the boundary was changed in 1861 a permanent house for the collector was built at Stockers Lock near Rickmansworth. In other cases the railway and canal companies or local coal merchants calculated the sums due and paid the money to the Corporation. The railway companies were initially allowed some coal free of duty for their engines.\n\nThere are five different forms of coal duty boundary markers in all.\nAlmost all bear the City's shield or in some cases the full coat of arms. Most of the cast-iron posts are painted white, with the cross and sword of the shield picked out in red, but the stone ones are often of a sombre black, still bearing the stains accumulated on the smoky trackside. Most of the posts are Grade II listed buildings.\n\nThe City of London had the right to collect dues for weighing and measuring coal entering the Port of London since medieval times. After the Great Fire of London in 1666, Acts of Parliament imposed further duties to help pay for the rebuilding. Although some of the proceeds were for general rebuilding purposes, most was to cover the costs of rebuilding St Paul's Cathedral and the City churches. After the completion of St Paul's, the duties were paid to the Commission for Building Fifty New Churches. In 1718 the duty was converted into a Government duty, though some was still used for ecclesiastical purposes, such as the rebuilding of Gravesend Church in 1730. During the Napoleonic wars, the duty was increased several times to help pay for the wars. Government duties on coal were abolished in 1831.\n\nAt the end of the 17th century, the City of London owed large sums, notably to the funds which they held on trust for the orphans of City Freemen. In 1694 the City persuaded Parliament to pass an Act for the Relief of the Orphans and other Creditors of the City of London which allowed it to raise money in various ways, including the imposition of duties on coal. This Act was the ancestor of the ones which set up the posts. In the middle of the 18th century the income from the duties started to be used to finance public works in London, not only in the City itself but also in surrounding areas such as the West End, Southwark and Whitechapel. These included bridges such as Blackfriars Bridge, roads improvements such as at Temple Bar and the Ratcliffe Highway, and court buildings such as the Old Bailey and the Middlesex Sessions House in Clerkenwell. In 1803 a further duty was introduced to pay for the expenses of the coal market in London.\n\nThe use of the coal duties to pay for public works continued in the nineteenth century: for example they paid for the rebuilding of the Royal Exchange and the construction of New Oxford Street. After creation of the Metropolitan Board of Works (MBW) in 1855 the major part of duties went to the Board and were used to pay for the creation of a unified sewerage system in London and the construction of the Thames embankments. The City's portion of the duties paid for the building of Cannon Street, and later of Holborn Viaduct.\n\nIn the 1870s the duties were used to free from toll a number of bridges on the Thames: Kew, Kingston upon Thames, Hampton Court, Walton upon Thames, and Staines, together with Chingford, and Tottenham Mills on the Lea.\n\nThe coal duties had always been unpopular and were the subject of attacks by pamphleteers (for example Joseph Bottomley Firth in 1887) etc. throughout their life. Objection was taken to a tax on a basic necessity and the anomaly of a tax in London which did not apply to the rest of the country. The greater anomaly was that the area of collection – the Metropolitan Police District – was so much larger than the area in which they were spent: the Metropolitan Board of Works covered much the same area as its successor the London County Council. With the growth of the outer suburbs, their residents resented paying a tax which had very little direct benefit for them. This is why in 1868 Parliament decided that the duties were to be used to free from toll the bridges in outer London mentioned above.\n\nIn the 1880s the City and the MBW wanted the duties to continue, in the face of growing opposition from the public and national politicians, but when the MBW was replaced by the London County Council in 1889, the new council declined to support renewal. An act was passed in that year abolishing the duties, the last of which was collected in 1890. The abolition was opposed with some underhand tactics: a parliamentary select committee sitting in 1887 found that signatures on a petition in support of keeping the tax had been forged.\n\nThe posts thus represent the final phase of the duties in the face of growing opposition. They had been collected for over 300 years but within 30 years of the posts going up were abolished.\n\n\n"}
{"id": "41174313", "url": "https://en.wikipedia.org/wiki?curid=41174313", "title": "Comparison of Firefox OS devices", "text": "Comparison of Firefox OS devices\n\nFirefox OS is an operating system for mobile devices. This page seeks to list and compare hardware devices that are shipped with Firefox OS operating system.\n\n\n"}
{"id": "2963141", "url": "https://en.wikipedia.org/wiki?curid=2963141", "title": "Creepmeter", "text": "Creepmeter\n\nA creepmeter is an instrument that monitors the slow surface displacement of an active geologic fault in the earth. Its function is to record the slow, aseismic creep between earthquakes. The measurement range of a creepmeter is usually limited to 10–30 mm. Approximately 40 creepmeters are in operation in California—most are operated by the United States Geological Survey (USGS), but nine are maintained by the University of Colorado.\n"}
{"id": "7300596", "url": "https://en.wikipedia.org/wiki?curid=7300596", "title": "CrystEngCommunity", "text": "CrystEngCommunity\n\nCrystEngCommunity is a virtual web community for people working in the field of crystal engineering. The website is owned by the Royal Society of Chemistry (RSC). \n\nCrystEngCommunity has links to the main international research groups working in crystal engineering; publishes occasional profiles (interviews) of crystal engineers; a conference diary that lists and links to international events in the field of crystal engineering; and a terminology wiki, CrystEngWiki, for crystal engineering.\n\nAlso on the community are links to research articles on crystal engineering including \"CrystEngSelects\" (a selection of recent articles of interest to crystal engineers from across the RSC journals \"Chemical Communications\", \"CrystEngComm\", \"Dalton Transactions\", \"Journal of Materials Chemistry\", \"New Journal of Chemistry\" and \"Organic & Biomolecular Chemistry\"); links to special \"CrystEngComm\" Discussion conference special issues; and links to past crystal engineering articles from the RSC Journals Archive.\n\nOther useful links include downloadable wallpapers for PC desktops, book reviews and a compilation of useful weblinks for crystal engineers\n\nThe community has a particularly close association with the RSC’s crystal engineering journal, \"CrystEngComm\".\n\n\n"}
{"id": "43727085", "url": "https://en.wikipedia.org/wiki?curid=43727085", "title": "Dematerialization (products)", "text": "Dematerialization (products)\n\nThe dematerialization of a product literally means less, or better yet, no material is used to deliver the same level of functionality to the user. Sharing, borrowing and the organization of group services that facilitate and cater for communities needs could alleviate the requirement of ownership of many products.\n\nIn his book ‘'In the Bubble: designing in a complex world'’, John Thakara states that \"the average consumer power tool is used for ten minutes in its entire life - but it takes hundreds of times its own weight to manufacture such an object”. A product service system with shared tools could simply offer access to them when needed. This shift from a reliance on products to services is the process of dematerialization. Digital music distribution systems, car clubs, bike hire schemes and laundry services are all examples of dematerialization.\n\n"}
{"id": "55797400", "url": "https://en.wikipedia.org/wiki?curid=55797400", "title": "Design studies", "text": "Design studies\n\nDesign Studies is an academic discipline that pursues a critical understanding of design and its effects through analytical and practical modes of inquiry. Its origins can be traced to design history where the field first got its start before slowly expanding to include larger themes and more varied subject matters. In that light, Victor Margolin, one of the founders of the discipline in the US, proposes Design Studies as a term that comprises various design researches and relates them to one another.\n\nAs a highly interdisciplinary field, Design Studies references many scholarship paradigms and focuses on how design knowledge is developed, articulated and communicated. It therefore incorporates an expansive set of evolving methodologies and theories that are drawn from key thinkers and theorists from the field itself (such as Victor Margolin, Clive Dilnot, and Richard Buchanan), but also from several related fields such as, the humanities (literature, art, visual studies, cultural studies), the social sciences (anthropology, political sciences, and sociology), the sciences (engineering, material studies, neurology, technology studies). Design Studies also generates scholarly work in the fields of architecture, urban planning and policy, and spatial studies. Design Studies not only considers objects, places and systems, it investigates their meanings, contexts, possibilities and consequences.\n\nDesign Studies recognizes that design, as a practice, is merely one facet of a much larger paradigm. It examines, probes, and questions the role of design in shaping past and present personal and cultural values, especially in light of how they shape the future. The subjects of Design Studies are inherently fluid while being anchored to a core body of work and scholarship that revolves around broader themes such as ethics, environmental sustainment, and social sustainability.\n\nThe American author, editor and educator Susan Yelavich, encapsulates the terrain of Design Studies as embracing \"two broad perspectives—one that focuses inward on the nature of design and one that looks outward to the circumstances that shape it, and conversely, the circumstances design changes, intentionally or not.\"\n\nMasters programs in Design Studies are offered in the United States at Carnegie Mellon School of Design, Harvard Graduate School of Design, Parsons School of Design, and IIT Institute of Design.\n\nThe history of the field of Design Studies can be traced to the early 1960s in England. In 1962, a “Conference on Design Methods” held in London led to the emergence of the Design Research Society, bringing together academics and practitioners who shared interests in new approaches to the process of designing. Throughout the 1960s and 1970s, a series of conferences were held that helped continue the development of the Design Methods Movement (DMM)— a product of the post-war optimism of the 1950s, cancelled in 1962. This movement focused on the comparison between science and design and tried to determine methods that distinguished design as an important academic field apart from the realm of art and art history. However, in 1980 at the Design Research Society’s Design:Science:Method conference concluded that there was not much for design to learn from science, instead, science had something to learn from design. From this point, design became a discipline of study “based on the view that design has its own things to know and its own ways of knowing them.” This stance was promulgated in the first issue of \"Design Studies\" with the launch of a series of articles in its pages called “Design as a Discipline\".\"” (\"Design Studies, The Interdisciplinary Journal of Design Research\" as it is now known, was first published as Design Studies 1, no.1 in July 1979. Produced by the publisher Reed Elsevier known since 2015 as Elsevier). The series began with Bruce Archer, and his 1979 essay, “Whatever became of Design Methodology?”. In his accompanying article from the same issue titled \"The Three Rs,\" Archer places Design with a capital D as a third extreme in an education triangle with the Sciences and Humanities situating design, though not exclusively, within acts of configuration, composition, meaning, value, and purpose in man-made phenomena.\n\nDebates about the discipline of design and design research continued through the 1980s and were significantly reignited in 1995 when Victor Margolin, an American scholar who contributed to the development of design history, argued for a new approach to “Design Studies.” Margolin referred to the \"dynamic crossings of intellectual boundaries\" when describing the interdisciplinary nature of intellectual practice at the time. He felt that early design historians should question \"whether design history as it [had] been constituted...[was] a viable enterprise.\"\n\nMargolin defines design studies as a field of inquiry that addresses how we make and use products and how we have done so in the past. These products compromise the domain in the artificial. Design studies addresses ideas of product conception and planning, production, form, distribution, and use. It considers these topics in the present as well as in the past.\n\nMargolin's position triggered counter arguments about how to characterize the study of design. A battle in print began with his article titled, “Design history or design studies: subject matter and methods” published in the international journal \"Design Studies (Design Studies was the journal of the Design Research Society, founded in the UK in 1966; the journal itself has been in publication since 1979).\" This controversial topic had resonance in Britain where Adrian Forty’s response appeared in the pages of the \"Journal of Design History\", in which he argued in favor of research that led to the understanding of quality judgements defining good design \"as an entirely legitimate field for design historical research.\" The importance of this debate was made clear by the fact that it was reprinted in a special issue of \"Design Issues\" in 1995 where it refocused attention on \"some of the controversies and problems that surround the seemingly simple task of telling the history of design.\" The shift from Design History to Design Studies started to occur as the research and approaches to the field began to focus on broader questions of meaning, authority and power, in other words, with the dynamics surrounding and enabling the practice of design. The realization came that Design History is only “but one component of what goes on in studying design, and to claim that all that is going on now could use the umbrella term 'design history’ is not tenable.” This new field of Design Studies would now include not only design history, but also allow for a dialogue about “issues of product conception and planning, production, form, distribution, and use” in a historical and contemporary context.\n\nL. Bruce Archer. (1922-2005) was a British mechanical engineer and later Professor of Design Research at the Royal College of Art who championed research in design, and helped to establish design as an academic discipline. Archer trained a generation of design researchers, showing them how the procedures of scholarly research based on well-founded evidence and systematic analysis were as applicable in design as in the more traditional academic subjects. In 1967 he helped to found the cross-disciplinary Design Research Society.\n\nReyner Banham. (1922-1988) Banham’s \"Theory and Design in the First Machine Age\" and his journalistic articles written for \"New Society\" have been described by the British writer and design historian Penny Sparke as representing a major “shift in how material culture was seen. His writing focused on popular commodities as well as formal architecture.\n\nGui Bonsiepe. (born 1934) German designer and professor for various universities including FH Koln; Carnegie Mellon; EUA, Chile; LBDI/FIESC, Brazil; Jan van Eyck Academy, Netherlands. His most influential work is \"Design and Democracy.\"\n\nRichard Buchanan. American professor of design, management, and information systems and editor of the journal Design Issues. He is well known for “extending the application of design into new areas of theory and practice, writing, and teaching as well as practicing the concepts and methods of interaction design.” As a co-editor of \"Discovering Design: Explorations in Design Studies\" with Victor Margolin, he brought together the fields of psychology, sociology, political theory, technology studies, rhetoric, and philosophy.\n\nRichard Buckminster Fuller. (1895-1983) American architect, engineer, inventor, philosopher, author, cartographer, geometrician, futurist, teacher, and poet—established a reputation as one of the most original thinkers of the second half of the 20th century. His research was aimed at finding “a radical solution of world problems by finding the means to do more with less.”\n\nRichard Coyne. Professor at the University of Edinburgh and author of several books on the implications of information technology and design particularly as developed by Coyne's colleague Adrian Snodgrass in the 1990s, and with whom he co-authored the book \"Interpretation in Architecture: Design as a Way of Thinking\".\n\nNigel Cross. (born 1942) Cross is a British academic, design researcher and educator who focuses on design’s intellectual space in the academic sphere. He is a Professor of Design Studies in the Department of Design and Innovation, Faculty of Technology, at the UK's Open University, and Editor-in-Chief of Design Studies, the international journal of Design Research. With his 1982 journal article “Designerly Ways of Knowing” in \"Design Studies\", Cross argues that Design has its own intellectual and practical culture as a basis for education, contrasting it with cultures of Science and Arts and Humanities.\n\nClive Dilnot. Originally educated as a fine artist, Dilnot later began studying social philosophy and the sociology of culture with Polish sociologist Zygmunt Bauman. Dilnot has worked on the history, theory, and criticism of the visual arts in their broadest terms. His teaching and writing have focused on design history, photography, criticism, and theory. Dilnot’s most significant contribution to design scholarship is a study of ethics in relation to design, and the role of design's capabilities in creating a humane world in his book, \"Ethics? Design?\" published in 2005. He has also written and taught in fields ranging from aesthetics and art theory to photography, the decorative arts, museums and their framing of objects, architecture and architectural theory, and the economics of the current crisis and the question of how we can contend culturally with the world we have made.\n\nCameron Tonkinwise. An Australian academic, Cameron Tonkinwise has a background in philosophy, with a particular emphasis on Heidegger's genealogy of thought and its informing design practice. Having worked closely with Tony Fry at the Ecodesign Foundation in the 1990s, Tonkinwise later headed initiatives in sustainability at Parsons, The New School, and later became chair of design studies at Carnegie Mellon University, where he set up the PhD programs in Transition Design and Design Studies. Cameron's primary area of research is sustainable design and designing for socio-technical transitions - in particular, he focuses on the design of systems that lower societal materials intensity, primarily by decoupling use and ownership, i.e systems of shared use.\n\nAdrian Forty: (born 1948) was Professor of Architectural History at The Bartlett, The Faculty of the Built Environment at University College London. Forty believed that the drive to define a new field, the field of Design Studies, was unnecessary due to the fact that the field of Design History had not exhausted all of its possibilities. His book \"Objects of Desire\" explores how consumer goods relate to larger issues of social processes.\n\nTony Fry is a British design theorist and philosopher who writes on the relationship between design, unsustainability, and politics. Fry has taught design and cultural theory in Britain, the United States, Hong Kong and Australia. He is perhaps best known for his writing as a defuturing phenomenon by virtue of the resources it depletes.\n\nJohn Heskett (1937-2014) In the late 1970s, Heskett became a prominent member of a group of academics based in several of Britain's art schools (then part of the polytechnics) who helped develop the discipline of design history and theory, later to become subsumed under the broader banner of Design Studies. In subsequent years, as design became a global practice increasingly valued by corporations and governments alike, design history became, along with design pedagogy, one of the nation's most successful academic exports. Heskett brought his deep knowledge of economics, politics and history to the project and worked alongside scholars from other disciplines to communicate the meaning and function of that increasingly important concept, \"design\", both past and present.\n\nVictor Margolin (DS-History) Considered one of the founders of Design Studies, Victor Margolin is Professor Emeritus of Design History at the University of Illinois, Chicago. He is a co-editor of the academic design journal, \"Design Issues\", and is the author, editor, or co-editor of a number of books including \"Design Discourse\", \"Discovering Design\", \"The Idea of Design\", \"The Designed World\", and \"The Politics of the Artificial\".\n\nVictor Papanek. The architect-designer Victor Papanek suggested that industrial design had lethal effects by virtue of creating new species of permanent garbage and by choosing materials and processes that pollute the air. His \"Design for the Real World\" (1972), has been identified by the British design historian and librarian Anthony Coulson as an example of a “growth in the literature stressing the visual/perceptual aspects of design” and a “plea for design to adopt a much broader role.\n\nPenny Sparke: A professor of Design History and Director of the Modern Interiors Research Centre (MIRC) at Kingston University, London. Along with Fiona Fisher, Sparke co-edited the recently published \"The Routledge Companion to Design Studies\", a comprehensive collection of essays embracing the wide range of scholarship relating to design - theoretical, practice-related, and historical which makes an original and significant contribution to the field of Design Studies.\n\nAccording to Ahmed Ansari, Danah Abdulla, Ece Canli, Mahmoud Keshavarz, Matthew Kiem, Pedro Oliveira, Luiza Prado, and Tristan Schultz who make up the \"Decolonising Design Group\", “Coloniality is not an abstract concept nor is it a subject to be examined from a comfortable distance. It is something that affects our communities, our countries and our peoples every single day. It is a continuous process of domination and violence to which we are submitted. It demeans our knowledge, subjugates our bodies, and renders our lives arduous.”\n\nEstablished via their online blog “Decolonising Design,” this collective of design researchers, academics, and practitioners working in and with the fields of Design Studies and Design Research firmly believe that “decolonisation is imperative for survival.” The Decolonising Design Group's effort was born from their frustrations with academia during the events that led up to their withdrawal from the 2016 Design Research Society Conference and driven by their desire to engage in a profound debate of the colonial ethos of design and research. The collective believes it is, “not sufficient for design studies and design research to simply include a greater ‘diversity of perspectives’ as a means to delay and offset demands for radical systemic change.” With the purpose of transforming the agenda of design studies and design research, the group organized a symposium on decolonization titled “Intersectional Perspectives on Design, Politics & Power” which was held at the School of Arts and Communication, Malmö University, Sweden on 14–15 November 2016. For these [relatively] young academics, the field of design studies is not “geared towards delivering the kinds of knowledge and understanding that are adequate to addressing the systemic problems that arise from the coloniality of power.”\n\nThey argue that design history and design research tends to have the most influence from the triad of Western Europe, North America, and Japan. The effect tends to be in line with the notion that history is written by the victors and thus design history is written by the economically powerful. They point to concurrent histories outside of the western context. For instance, Hong Kong has a unique system of design that was established prior to the economic growth of the Pearl River delta which can be found in the continuities of design in product types and styles, manufacturing and printing companies, and families of artist-designers. Or in Cuba for instance, where the origins of design was influenced by the crisis of “modern movement ideology and the ideologies oh how to escape underdevelopment.” These countries lie on the periphery of the westernized view of design history and design studies and in some instances may have suffered in their adaptation of European modernity. As such, Gui Bonsiepe, a German designer, teacher, and writer, suggested that “Decolonization in all its manifestations, economic, technological and cultural, should be the goal of project activity in the periphery.”\n\nThe need for understanding design as a global and multicultural phenomenon is also argued by Jonathan M. Woodham, Victor Margolin, and Anna Calvera in Denise Whitehouse’s collection of essays.” Together their aim is to “create a theoretical narrative that brings intellectual logic to the multiple stories of how different countries… have negotiated the process of Westernization and the idea of design according to their specific economic, geographical, political, and cultural circumstances.”\n\nAs Whitehouse points out, “While many countries produce local histories of design, the output is uneven and often driven by nationalist and trade agendas.” Academic groups like the Japanese Design History Forum and The International Committee for Design History and Studies (ICDHS) draw together both western and non-western, post-communist, postcolonial, Asian, and Southern Hemisphere, “to remap the scope and narrative concerns of design history.”\n\nThe United Nations and Decolonization- http://www.un.org/en/decolonization/index.shtml (Accessed November 12, 2017)\n\nManipulations Platform – http://www.manipulations.info/ (Accessed November 12, 2017)\n\nDecolonize ALL The Things – https://www.decolonizeallthethings.com/ (Accessed November 12, 2017)\n\nDesign Studies thinks ambitiously about design, beyond its professional enclaves, and studies the significance and consequences of design activity in the modern world. It looks at design as a complex and multifarious activity and examines the forces that design exerts in, and on, the world—forces design sets in motion but does not control. The field of Design Studies views design as both the embodiment of the imminent future (by virtue of behaviors it triggers and resources it depletes) and as a means of envisioning alternative futures. Because Design Studies is interdisciplinary (moving between disciplines), multi-disciplinary (utilizing multiple disciplines in its process and methods) and transdisciplinary (combining disciplines in creating new disciplinary structures), its approaches and scopes are not constrained by any boundaries of academic disciplines. It is promiscuous and draws on the knowledge of philosophy, sociology, anthropology, literature, cultural theory, politics and the sciences to ask questions of what is design, and how can we comprehend its acting in the world by analyzing its possibilities and limits.\n\nAs an organized field of study, Design Studies is substantiated by its own academic and professional discourse and theoretical perspectives concerning the ways we think about design—its nature, purpose, agency, configuration, engagement, deployment, place, responsibilities, ethics, politics, problems, environment, sustainment, potentialities and alternative futures. It focuses on describing the why, the how and the what of design. It does not limit its inquiry to prescriptive definitions of what design is supposed to be, but instead it aims to understand (and study) the possibilities of what design can achieve and uses varied methodologies to explore the delineations and synergies between academic inquiry, critical theory and design practice. Its scholars explore the coherent structures and intellectual parameters of how design is encountered in the world, as well as analyze which different modes of contemporary practice are rethinking design to propose and realize alternative futures.\n\nAs an organized field of study, Design Studies is a discipline concerned with design as a practice and as an intervention in the world. It is substantiated by its own academic and professional discourses and theoretical perspectives concerning ways to think about design—its nature, purpose, agency, configuration, engagement, deployment, place, responsibilities, ethics, politics, problems, environment, sustainment, potentialities and alternative futures. It does not limit its inquiry to prescriptive definitions of what design is supposed to be, but instead it aims to understand (and study) the possibilities of what design can achieve by using various methodologies to analyze the delineations and synergies between academic inquiry, design practice and critical theory.\n\nDesign Studies analyzes how different modes of contemporary practice are rethinking design to propose and realize alternative futures using approaches such as those conventions listed under design as well as:\n\nDesign Studies asks us to think about the meaning of design. It studies the influence of designers and the effects design has on citizens and the environment. Victor Margolin distinguishes a degree in Design from a degree in Design Studies by saying that “the former is about producing design, while the latter is about reflecting on design as it has been practiced, is currently practiced, and how it might be practiced.”\n\nDesign Studies urges to rethink design as a process, as a practice, and as a generator or products and systems that gives lives meaning and sustains our economic and political systems. Design thinking invites to explore the complexities inherent to the task of thinking about design. Design Studies is concerned with the relationship between design and gender, design and race, and design and culture. It studies issues such as ethics, sustainment (social and environmental) and works with concepts such as agency and the artificial.\n\nDesign has the capacity of structuring life in certain ways and thus design should result in the greater good for individuals and society but it doesn’t always do so. Ethics deals with how our actions affect others. Design Studies sees ethics as central to design. Tony Fry, a leading figure in Design Studies claims, “Design is quintessentially an ethical process but despite this recognition that ethics is integral to design in many ways, design ethics remains ‘massively underdeveloped and even in its crudest forms remains marginal within design education.” It is important to involve ethics in the design process, especially as the world we inhabit is increasingly becoming artificial.\n\nClive Dilnot’s essay, \"Ethics in Design –\" \"Ten Questions\"\",\" explores why we need ethics in design, what is the relationship between design and ethics. Dilnot writes that ethics should as a responsibility, as the ability of the designer to address the public as citizens and not as consumers or as the infusing of “humane intelligence” into the made environment, assume the possibility of truly human – humane, sustainable ways or making and remaking the world.\n\nClive Dilnot goes further and clarifies that the artificial is by no means confined to technology. Today, it is combination of technical systems, the symbolic realm, including mind and the realm of our transformations and transmutations of nature. He gives the example of a genetically modified tomato that is neither purely natural nor purely artificial. It belongs rather to the extended realms of living things that are, as human beings ourselves are, a hybrid between these conditions – Neither nature nor the artificial nor the human are today pure.\n\nDesign Studies scholars also reference sociologist Bruno Latour when investigating the dynamics of the artificial. Latour's concept of Actor-Network Theory (ANT) portrays the social as an interdependent network of human individual actors and actants, which are non-human, non-individual entities. ANT aims at accounting for the very essence of societies and natures.\n\nDesign plays a constitutive role in everyday life. We engage design with all of our senses – The things we see and read, the objects we use, and the places we inhabit are all designed. These products (all artificial because they are catalyzed by people) constitute an increasingly large part of the world. The built environment is the physical infrastructure that enables behavior, activity, routines, habits, and rituals, which affect our agency. Jamer Hunt defines the built environment as the combination of all design work.\n\nThis form of research requires the scholar to partake in the use of, or observe others use, a designed object or system. Design-based Ethnography has become a common tool where design is observed as a social practice. It describes a process in which a researcher will partake in traditional observant style ethnography, and observe potential users complete activities that can inform design opportunities and solutions. Other ethnographic techniques used by Design Studies scholars would fall more in line with anthropologists usage of the method. These techniques are observant and participant ethnography. The observant style requires the scholar to observe in an unobtrusive manner. Observations are recorded and further analyzed. The participant style requires the scholar to partake in the activities with their subject. This tactic enables the scholar to record what they see, but also what they themselves experience.\n\nWhile it remains a broader theory or concept Actor-Network theory can be used by Design Studies scholars as a research framework. When using this method, scholars will assess a designed object and consider the physical and nonphysical interactions which revolve around the object. The scholar will analyze what the object’s impact is on psychological, societal, economical, and political worlds. This widened viewpoint allows the researcher to explore and map out the objects many interactions, identify its role within the network, and in what ways it is connected to stakeholders.\n\nDesign Studies scholars may also analyze or research a designed object or system by studying it in terms of images and their various meanings. Based in representation and meaning-making, semiotics as pertinent design as an act of communication between the designer, the thing, and the user or users. This concept branches out into a rhetorical analysis of the designed thing. Scholars such as Richard Buchanan, argue that design can be studied in such a way due to the existence of a design argument. The design argument is made up by the designer, the user, and the applicability to “practical life.” The scholar would pull these segments apart and thoroughly analyze each component and their interactions. Finally, discourse analysis or a Foucauldian discourse analysis can be adopted by the Design Studies scholar to further explore the above components. A Foucauldian approach specifically will analyze the power structures put in place, manipulated by, or used within a designed thing or object. This process can be particularly useful when the scholar intends to understand if the designed thing has agency or enables others to have agency.\n\n\"Design and Culture, The Journal of the Design Studies Forum\"\n\n\"Design Issues\": Established in 1984. The first American academic journal to examine design history, theory, and criticism, \"Design Issues\" is a quarterly publication that provokes inquiry into the cultural and intellectual issues surrounding design.\n\n\"The Design Journal\": Established in 1998, the journal of the European Academy of Design, \"The Design Journal\" is an international refereed journal covering all aspects of design. Published six times a year, the journal provides a forum for design scholars, professionals, educators and managers worldwide. It aims to publish thought-provoking work which will have a direct impact on design knowledge and which challenges assumptions and methods, while being open-minded about the evolving role of design.\n\n\"Design Philosophy Papers\"\n\n\"Design Studies\": Design Studies publishes work that is concerned with the process of designing, and is relevant to a broad audience of researchers, teachers and practitioners. \"Design Studies\" is a leading international academic journal focused on developing understanding of design processes. It studies design activity across all domains of application, including engineering and product design, architectural and urban design, computer artefacts and systems design.\n\n\"Early Popular Visual Culture\"\n\n\"Home Cultures\"\n\n\"International Journal of Cultural Studies\"\n\n\"International Journal of Sociology\"\n\n\"Journal of Consumer Culture\"\n\n\"Journal of Consumer Research\"\n\n\"Journal of Design History\": published by Oxford University Press on behalf of the Design History Society. It is the leading journal in its field, and plays an active role in the development of design history, including the history of crafts and applied arts, as well as contributing to the broader fields of visual and material culture studies.\n\n\"Journal of Design Strategies\"\n\n\"Journal of Intercultural Studies\"\n\n\"Journal of Material Culture\"\n\n\"Journal of Popular Culture\"\n\n\"Journal of Visual Culture\"\n\n\"Material Culture\"\n\n\"Social Research\"\n\n\"The Journal of Cloth and Culture\"\n\nThe Design Research Society (DRS) is a learned society committed to promoting and developing design research. It is the longest established, multi-disciplinary worldwide society for the design research community. The Design Research Society was founded in the UK in 1966. The origins of the Society lie in the Conference on Design Methods, held in London in 1962, which enabled a core of people to be identified who shared interests in new approaches to the process of designing. The purpose of the DRS, as embodied in its first statement of rules, was to promote ‘the study of and research into the process of designing in all its many fields'. The DRS Constitution states the Rules by which the society is governed. The Annual General Meeting reports detail the governance, finance, activities, and plans of the society.\n\nDesign History Society: Leading organization that promotes the study of global design histories, and brings together and supports all those engaged in the subject—students, researchers, educators, designers, designer-makers, critics, and curators. The Society aims to play an important role in shaping an inclusive design history.\n"}
{"id": "43770267", "url": "https://en.wikipedia.org/wiki?curid=43770267", "title": "DigitalCurriculum", "text": "DigitalCurriculum\n\nDigitalCurriculum was the first educational video-on-demand system and remains the standard for interactive streaming multimedia libraries. An early SaaS model, DigitalCurriculum was conceived and designed in 1997 and produced and released in 1999, by AIMS Multimedia's David S. Sherman, Ph. D., co-president of AIMS MULTIMEDIA, and software architect Richard Williams. The service drew from and incorporated the AIMS Multimedia educational video library, executive producer Mike Wright and associate producer Pat Davies. Also heavily involved in the design team were Hillary Broadwater, Elizabeth von Schoff, and Aram Iskenderian.\n\nThe video component in DigitalCurriculum included over $300 million in educational productions — programs that received more than 1,000 awards worldwide — including the prestigious Emmy, Oscar, Peabody and Parents’ Choice awards. These premier titles came from hundreds of world-renowned producers and distributors including: Scholastic/Weston Woods, ABC, Paramount, TV Ontario, TEAMS Distance Learning, Channel One and the National Film Board of Canada.\n\nDigitalCurriculum was a curriculum-on-demand teaching and learning system that fully integrated full-length educational videos, key concept video clips, still images, Encyclopædia Britannica content, teacher guides, lesson plans, and interactive online assessments and assignments into a comprehensive learning tool for teachers, students, and administrators with complete record-keeping and an internal messaging service. At the time of its acquisition in 2004 by Discovery Communications, DigitalCurriculum had over 100,000 educational multimedia components for every K-12 subject, state and national framework correlations, multiple bit-rate encoding for school and home use, simple incorporation of local content, and a paid subscriber base of more than 20 million teachers, librarians, administrators, and students.\n\nDigitalCurriculum is of particular historical interest as it was a SaaS pioneer and one of the first video on demand services. It used a revolutionary multiple bitrate encoding that allowed video and audio streaming by users with shared DSL fractional T-1 internet connectivity; it even allowed streaming at 56kbit/s dial up modems.\n\nDigitalCurriculum was described as innovative and visionary; its design, features and functionality having been copied and incorporated by virtually all educational media companies since its initial release back in 1998-1999 and it's various iterations, culminating in v.5.0 in 2004.\n"}
{"id": "914462", "url": "https://en.wikipedia.org/wiki?curid=914462", "title": "Engine-indicating and crew-alerting system", "text": "Engine-indicating and crew-alerting system\n\nAn engine-indicating and crew-alerting system (EICAS) is an integrated system used in modern aircraft to provide aircraft crew with aircraft engines and other systems instrumentation and crew annunciations. On EICAS equipped aircraft the \"recommended remedial action\" is called a checklist.\n\nEICAS typically includes instrumentation of various engine parameters, including for example revolutions per minute, temperature values, fuel flow and quantity, oil pressure etc. Typical other aircraft systems monitored by EICAS are for example hydraulic, pneumatic, electrical, deicing, environmental and control surface systems. EICAS has high connectivity & provides data acquisition and routing.\n\nEICAS is a key function of a glass cockpit system, which replaces all analog gauges with software-driven electronic displays. Most of the display area is used for navigation and orientation displays, but one display or a section of a display is set aside specifically for EICAS.\n\nThe crew-alerting system (CAS) is used in place of the annunciator panel on older systems. Rather than signaling a system failure by turning on a light behind a translucent button, failures are shown as a list of messages in a small window near the other EICAS indications.\n\n\n"}
{"id": "154208", "url": "https://en.wikipedia.org/wiki?curid=154208", "title": "Fansub", "text": "Fansub\n\nA fansub (short for fan-subtitled) is a version of a foreign film or foreign television program which has been translated by fans (as opposed to an officially licensed translation done by professionals) and subtitled into a language usually other than that of the original.\n\nThe practice of making fansubs is called fansubbing and is done by a fansubber. Fansubbers typically form groups and divide the work up. The first distribution media of fansubbed material was VHS and Betamax tapes.\n\nEarly fansubs were produced using analog video editing equipment. First, a copy of the original source material or raw was obtained, most commonly from a commercial laserdisc. VHS tapes or even a homemade recording could be used as well, though this would produce a lower quality finished product. The dialogue was then translated into a script, that was then timed to match the dialogue, and typeset for appearance. The two most popular programs used in this process were JACOsub for the Commodore Amiga and Substation Alpha for MS Windows. The next step was to produce one or more masters, a high quality copy of the finished fansub from which many distribution copies could be made. The fansubber would play back the raw video through a computer equipped with a genlock in order to generate the subtitles and then overlay them on the raw signal. The hardware most often used was an Amiga PC, as most professional genlocks were prohibitively expensive. The final output of this arrangement was then recorded. The master was most often recorded onto S-VHS tape in an attempt to maximize quality, though some fansubbers used the less expensive VHS or Beta. Once completed, the master copy was then sent to a distributor. \n\nThe internet allows for highly collaborative fansubbing, and each member of a fansub team may only complete one task. Online fansubbing communities are able to release a fully subtitled episode (including elaborate karaoke with translation, kana, and kanji for songs, as well as additional remarks and translations of signs) within 24 hours of an episode's debut in Japan.\n\nThe production of a fansub typically begins with obtaining the unsubtitled source video called a \"raw\" that typically comes from DVDs, VHS tapes, television broadcasts, peer-to-peer networks, and directly from Japanese-based contacts. Then a translator watches the video and produces a time-stamped text file of the screenplay with any relevant notes. The same series or episode may be subtitled by multiple groups with independent translations of varying quality. Fansub groups sometimes translate other already translated fansubs that are more susceptible to more errors. Translated text is assigned with start and end times in a process known as timing to ensure subtitles appear when dialogue is spoken and disappear with the silence. An editor and a translation checker reads over the script to ensure that English is natural and coherent while still retaining the original meaning. A typesetter then appearance for the dialogue, signs, translator notes, etc. Then groups perform quality control to catch any final errors.\n\nEncoders then take the script file and create a single subtitled video file, often aiming for a target file size or video quality. \"Hard\" subtitles, or \"hard subs\", are encoded into the footage, and thus become hard to remove from the video without losing video quality. \"Soft\" subtitles, or \"soft subs\", are subtitles applied at playback time from a subtitle datafile, either mixed directly into the video file (.mkv, .ogm, etc.), or in a separate file (.ssa, .srt, etc.). Soft subs can also be rendered at higher resolutions, which can make for easier reading if the viewer is upscaling the file, but also are more difficult to blend into the video (for instance rotated text/moving text). Hard subs have traditionally been more popular than softsubs, due to a lack of player support and worries over plagiarism, but most fansub groups now release a softsub version of their releases.\n\nThe resulting fansub is a computer video file and can be distributed via CD, DVD, DDL, P2P software, and by file-sharing bots on IRC. This distribution is usually handled by a distribution team, or \"distro\" team, composed of one or more individuals with a server or very high upload speed.\n\nThe first documented Japanese animation to be distributed in the United States was \"The Tale of the White Serpent\" airing on March 15, 1961. Until the late 1970s, Japanese community TV stations' broadcasts were aimed exclusive at very young children. Soon after the release video cassette recorders in November 1975, post-\"Astro Boy\" anime began to spread throughout the United States. By March 1976, TV stations in the United States began broadcasting super robot shows such as \"Getter Robo\", and due to the availability of VCRs, fans could record these shows to show to their friends. Fred Patten describes his first exposure to anime at the Los Angeles Science Fiction Society (LASFS) in 1976 when he met up with another fan who was an early adopter of Sony's betamax technology. By May 1977 he and a group of fans founded the first anime club in the United States, the Cartoon/Fantasy Organization (C/FO).\n\nIn November 1977, the C/FO began corresponding with other Japanese animation fans across the country and because distribution of shows across the United States was different based on location, fans began trading tapes of shows they were missing between each other. At the time many LASFS members maintained contact with members around the world, and thus C/FO members began exchanging videos with fans located in Japan, typically US military personnel, who wanted \"Star Trek\" and \"Battlestar Galactica\". Fortunately, shows from either the United States or Japan could be played in either region as both used the NTSC format for broadcast. These shows were not translated, however Japanese animations remained simple enough that the average viewer could discern the plot exclusively from the visuals. By 1979, fans and clubs of Japanese animation had begun to separate from the science fiction movement and began to refer to the media they watched as anime.\n\nThroughout this period it was considered socially acceptable to screen anime for an audience without consent as few companies had American offices, and of the few that did, the answer was invariably \"no\". Japanese companies made it apparent that they knew fans in the United States engaged in unauthorized distribution and screening, however knew that fans were not profiting. Japanese companies asked fans to help them publicize, for instance, Toei Animation asked the C/FO to aid it with some marketing research at San Diego Comic-Con. Starting in 1978, Japanese companies tried to set up their own American divisions; however, with the exception of the film \"The Sea Prince and the Fire Child\" which was licensed to RCA/Columbia Pictures Home Video, they realized they were not going to succeed in the American market and the last American anime company branch closed in 1982.\n\nAfter anime companies pulled out of the United States in 1982, there were no longer any legal or moral forces to discourage fans from copying and distributing tapes among themselves. From the late 1970s until the late 1980s, clubs began expanding to have chapters in other cities and grew to become of national and international scales. As the fandom grew, fans begun to experience ideological conflicts such as whether to keep the fandom niche or not. The visual quality of tapes began to degrade as fans made copies of copies; by the early 1980s some C/FO members reported tapes in their 15th to 20th generation that were extremely poor quality. In the mid to late 1980s, fans began to make booklets containing the translated dialogue for entire films (typically $2–3 to cover costs) and anime-focused magazines.\n\nDespite numerous attempts, any efforts to convince US companies to license Japanese animation fail with the exception of a handful of companies that were intent on \"carving up\" any series rewriting them into kiddy cartoons. Sean Leonard states that entertainment executives at the time mistakenly assumed that since anime are cartoons, they must be marketed at young children; furthermore Japanese cartoons were much too violent and complex in plot for children. Leonard states that the most notorious example was the translation of Nausicaä of the Valley of the Wind airing in the US in April 1986 that left its creators Hayao Miyazaki and Isao Takahata appalled; Takahata exclaimed licensing Nausicaä was a huge error and no further Studio Ghibli produced films would be licensed internationally. These edits however were no worse than most other non-Disney animation films that were available in the US. Fans who obtained the Japanese originals of \"Nausicaä\" were inspired so as to organize an anime tour to Tokyo in 1986 to see Miyazaki's \"\" and landmarks in anime.\n\nCarl Macek played a key role in creating a pivotal wave of anime fans. Macek ran a comic book and movie memorabilia speciality shop. After assisting in marketing and promotion of \"Heavy Metal\" and the recent establishment of a nearby C/FO chapter, he began researching Japanese animation and imported Japanese cels becoming known as a Japanese animation specialist. Harmony Gold then contacted him as they had acquired international licenses for several series, were planning on distributing in Latin America, Europe, and the US, and enlisted his help for the US market. After Macek noticed their selection of \"Macross\" and similar science fiction series, Macek obtained Harmony Gold's approval to release an anime if he could edit three series together into what they named, \"Robotech\". Macek went to science fiction conventions to promote the series and discovered the growing cult interest among adolescent and young adults, in contrast to the assumption of an exclusively viable child-targeted market. Macek edits \"Macross\", \"Southern Cross\", and \"Genesis Climber MOSPEADA\" together into \"Robotech\" and lands a resounding commercial success earning him a lot of notoriety in fan community. Leonard describes as it being more faithful to the original series than any other commercial success at the time as it included key elements such as the first love triangle on both Japanese and American animated television.\n\nThe C/FO was at its height between 1985 and 1989 with over three dozen chapters throughout the US. John Renault helped lead the C/FO chapter in Japan and played a key role throughout fansub history due to his ability with Japanese, anime industry contacts, and military background. Renault helped exchange raws from Japan, wrote informative articles about production, translated booklets, introduced military techniques to anime distribution, provided plot synopses that proved invaluable for watching Japanese only anime. Fan distribution through C/FO’s efforts, particularly C/FO Rising Sun, sought to keep anime free but keep anime controlled within the C/FO organization in order to promote Japanese animation. Bootlegging at the time was economically infeasible. However a growing divide in fandom between the \"haves\" and \"have-nots\" limited access to anime as a function of who you knew. In 1989 members began to accuse Patten of disloyalty for writing articles for general magazines rather than the perpetually behind schedule C/FO fanzine. However Patten felt that in writing for popular magazines he was furthering their cause to proselytize and promote anime. With no clear succession route left behind after Patten stepped down, the C/FO began to break apart, and eventually ceased to exist as a conglomerate in July 1989.\n\nThe first known fansub documented at the Rising Sun chapter of the C/FO was in 1986 of a \"Lupin III\" episode produced on the Commodore Amiga, marking the introduction of the formula for the process of fansubbing. However fansubbing was extremely expensive at this time (on the order of $4000 in 1986 and over one hundred hours). There were a few ventures into subtitling in the late 1980s; Leonard labels the fansub of the first two episodes of Ranma 1/2 in May 1989 as the earliest, widely distributed fansub.\n\nIn the late 1990s and early 2000s, fansubs in electronic form were primarily distributed like VHS and Beta tapes: via mailed CD-Rs. Many fans did not have high speed Internet and were unable to download large files. Many of the early digital fansubs were made from regular tape subs.\n\nIn the mid-2000s, most fansubs were distributed through IRC channels, file hosting services and BitTorrent. In recent years most groups have shifted from using IRC to being primarily BitTorrent. BitTorrent trackers dedicated to anime fansub releases allow fans to easily find the latest releases, and individual fansub groups often use their own websites to inform fans of new releases. Because of an almost complete de-emphasis on CD-R and DVD-R distribution, file size standards are less frequently followed.\n\nHye-Kyung Lee, a lecturer at King's College London, states that anime fansubber embody the general characteristics of fans described by John Fiske; fansubbers are motivated by strong affection for anime, devotion to sharing it with other fans, the sense of community interaction with their viewers, working together as a member of a group, and a strong desire to support the local animation industry by promoting anime culture and widening anime's accessibility. Lee describes fansubbers as involved in productive activities that enhance their knowledge of anime and improve their skills culminating in a final product. The goal of the first anime club, Cartoon Fantasy Organization, and its subsequent chapters was to proselytize and promote anime. Sean Leonard and Lee agree that without fan distribution that began in 1976 till fansubbing 1993, the anime industry would not take off as it did in the 1990s. Some companies such as Protoculture Addicts with its titular magazine and Viz Media with \"Animerica\" drew their origins from anime club fanzines in the early history of fansubs.\n\nIntellectual property lawyer Jordan Hatcher situates fansubs on the boundary between the desirable dojinshi fan culture and the \"massive online file trading so vilified by the recording and motion picture industries\". Legal scholar Lawrence Lessig states that the re-working of culture—remix—is necessary to cultural growth and points to doujinshi in Japan as an example of how permitting more remix can contribute to a vibrant cultural industry. However Hatcher states that fansubs do not match this type of remix because their aim is to remain faithful to the original. Furthermore, Hatcher states that fansubs compete with the original cultural product since they have the potential to replace the market need for official translations and thus resemble the debate over peer-to-peer file trading.\n\nHatcher states that copyright law does not condone fansubs. The Berne Convention, international copyright treaty, states that its signatories—including Japan—grant authors exclusive right to translation. Hatcher states that fansubs could \"potentially\" be legal within Japan given the nature of Japan's domestic copyright laws, although the target audience of fansubs is the non-Japanese market. However Hatcher states that copyright law in the United States—the frame of reference for most online discussions of fansub legality—construes translations as derivative, and fansubs infringe on the author's right to prepare derivative works and to reproduction by copying original source material.\n\nLee describes an unspoken rule in the fan community: \"once the anime was licensed the fansubbed version should no longer be circulated\". As a result, many fansubbers do not view themselves as pirates. Up until the late 1980s, fans were for the most part unable to obtain anime through official means, and the few anime that were licensed were rewritten to a much lower quality that even outraged the Japanese creators. Fans such as Fred Patten attempted to obtain official consent; however, no series really proved commercially successful. Until sometime after 1989 when subtitling became affordable signalling the rise of both fansubbing and the domestic industry, bootlegging was not financially feasible. Sean Leonard distinguishes fansubs from bootlegs as fansubs following the unspoken rule in the fan community with the intent to promote anime whereas bootlegs aim to make a profit. Many fansubs began to include a \"This is a free fansub: not for sale, rent, or auction\" notice as a response to bootleggers, and would encourage viewers to buy official copies. Anime Expo in 1993 was the first time the US industry representatives began talking more publicly about pre-existing copies eating into profits. For early fansubs due to the deteriorating nature of copying VHS tapes, official releases would be far superior in terms of visual quality, and thus there would be no competition between fansubs and official releases.\n\nHowever, with the digital age at the start of 2000, each step of the fansubbing process was made easier and cheaper with a dramatic improvement to the visual standards of fansubs. Lee described English fansubbing as having been rapidly globalized over the years in terms of viewership. Lee states that it was the rise of peer-to-peer file sharing software \"BitTorrent\" that \"put fansubbing on the map internationally\". Lee states that while other language communities exist, the English language fansubbing community has the greatest pull. US publishers traditionally found fansubbing useful for testing demand and broadening their fanbase, whereas Japanese publishers treat fansubbing as something remote and insignificant. Lee states that some Japanese producers even praise fansubber's efforts at promoting their work overseas. However at the turn of the new millennium in the face of fans' demands for greater immediacy, temporal and spatial disparity in overseas licensing, English as the internationally preferred medium for fansubs, and the increasingly globalized membership of the English fansubbing community, fansubbing groups are becoming less and less willing to follow the unspoken rule. Some fansubbers state that they don't want to abandon the rest of the world because someone bought the region 1 license.\n\nFans' attitudes also seem to have changed. With a lower barrier to entry, even the least dedicated can view anime with a few clicks. Newer fans also seem less willing to purchase or collect DVDs. Consequently, the anime industry's view of fansubbing has changed. US companies have begun blaming fansubbers for the decline in DVD sales.\n\nHenry Jenkins states that fansubbing has a positive impact on the anime industry through its function as publicity. However, as the internet grew in availability and speed, fansub groups were able to host and distribute fansubs online easily. The advent of BitTorrent as opposed to IRC has been pointed to as a key ingredient in the current fansubbing scene. It has been argued that this prompted fans to ignore official releases altogether, and some websites started charging for easier downloading rates. Many anime shows make their debut outside of Japan's shores in electronic format, and it is rare that a popular anime will go without fansubs.\n\nDue to 4Kids' heavy editing of their properties and refusal to release untouched versions on DVD, some fansubbing groups continue to subtitle and release popular shows owned by the company such as \"Tokyo Mew Mew\", \"One Piece\", and \"Yu-Gi-Oh!\". 4Kids attempted an uncut bilingual release of \"Shaman King\" and \"Yu-Gi-Oh\" in the mid-2000s, releasing a handful of volumes of each title in the format, but in an interview with ANN Alfred Kahn stated that \"The market for them just isn't as large as the one for the cut version,\" pointing out that their sales might not have met 4Kids' needs or expectations to continue them.\n\nPast market reactions have shown that time might be better spent petitioning 4Kids for a bilingual release, and supporting the uncut release of former 4Kids licenses like \"One Piece\", to show them there is a market for such titles. An older example is \"Sailor Moon\", which was initially licensed by DiC. After fan demand showed there was a market for the title, uncut, unedited versions of the show, and Pioneer successfully release the \"Sailor Moon\" Movies in a subtitled VHS format in 1999, followed by dubbed versions and bilingual DVDs. This was quickly followed by the release of \"Sailor Moon S\" and \"Sailor Moon Supers\", which both received complete unedited releases on VHS and DVD from Geneon. In 2003, the commercial subtitles of the first two seasons appeared, released by ADV Films under license by DIC, nearly completing the uncut release that many fans never believed would be possible (Prior to Viz Media obtaining the license, the final season of the original Sailor Moon Series \"Sailor Stars\" was not commercially released in the United States.).\n\nThere is a belief among some fans that an \"unspoken agreement\" exists between the fansubbers and Japanese copyright holders that fansubs help promote a product. Steve Kleckner of Tokyopop noted:\nFrankly, I find it kind of flattering, not threatening[...] To be honest, I believe that if the music industry had used downloading and file sharing properly, it would have increased their business, not eaten into it. And, hey, if you get 2,000 fans saying they want a book you've never heard of, well, you gotta go out and get it.\"\nThis belief was challenged when in December 2004 Media Factory, itself a Japanese copyright holder, directly requested that its works be removed from download sites and since then numerous other companies such as Nippon TV have followed suit in the wake of the appearance of fansubs on YouTube.\n\nRecently, a few titles such as \"\" were prelicensed, meaning that they were released simultaneously in Japan and North America, in an effort to negate the need for fansubs. However, some fansubbing of such titles still occurs, as some people prefer fansubs over commercial releases.\n\nFansub opposers claim that Japanese licensors have reportedly grown discontent with fansubbers because the ease of access with which their works are obtained has begun to affect foreign licensees' willingness to license a series, as evidenced by the Western market's sharp drop in new acquisitions in 2005. They also suggest that anime fans in Japan have reportedly begun to turn to English fansubs which often appear days after a show's release, affecting sales in their home market. Indeed, Japanese companies have banded together to form JASRAC, a copyright holders' rights company, which has frequently taken YouTube to task for providing content which domestic Japanese viewers often use, which includes fansubs, as seen on their official site. A growing anti-fansub stance has been taken by US distributors, as seen in Geneon and ADV's comments at the State of the Industry Panel at Anime Boston, as well as recent comments by Matt Greenfield of ADV Films at Anime Central:\n\nIn 1999, Ryuta Shiiki, a former representative of SPE Visual Works Inc. sent a letter to a fansub distribution group to take down the illegal copies of the anime Rurouni Kenshin, because a company that was interested in the rights of said series notified the Japanese company about the illegal distribution of it. The group complied and the series was pulled from distribution. This is the first legal action via a cease-and-desist letter against a fansub in the United States.\n\nIn 2002, Hideaki Hatta, president of Kyoto Animation, sent a letter to a fansub group requesting the stop of illegal distribution of the anime OAV Munto. The fansub group complied and the distribution stopped. This is the first legal action via a cease-and-desist letter against the fansubbing of an anime title not available outside Japan. However, time later, it was confirmed that Central Park Media licensed the title in the United States.\n\nIn 2003, a fansubbing group known as Anime Junkies was involved in a conflict with the licensor and co-producer of the , Urban Vision's even provided the pitch to Madhouse to create the series. Urban Vision sent a letter asking for Anime Junkies to stop hosting the licensed material, but Anime Junkies did not comply with the request and responded negatively to Urban Vision. Christopher Macdonald, an editor at Anime News Network, highlighted the ethics code of the fansubbing community and asked that fans not support Anime Junkies as a result of their actions.\n\nOn December 7, 2004, a Tokyo law firm representing Media Factory sent letters and e-mails to the anime BitTorrent directory AnimeSuki and fansub groups Lunar Anime and Wannabe Fansubs requesting that they halt the fansubbing and hosting of all current and future fansubbing productions. AnimeSuki and Lunar Anime complied, and shortly after, other fansub groups such as Solar and Shining Fansubs followed suit. Despite the request, Wannabe Fansubs and a handful of other fansubbing groups continued to produce fansubs of MFI anime series.\n\nOn July 27th, 2006, the legal department representing the Spanish anime company Selecta Visión sent a cease-and-desist letter to the anime BitTorrent and fansubbing site Frozen-Layer requesting the halt of the fansubbing and publishing all of current and prior anime licensed by the company. The owner complied and, until 2013, established that all licensed anime in Spain was banned from the site, regardless of the status of the license.\n\nIn Singapore, anime distributor Odex has been actively tracking down and sending legal threats against internet users in Singapore since 2007. These users have allegedly downloaded fansubbed anime via the BitTorrent protocol. Court orders on ISPs to reveal subscribers' personal information have been ruled in Odex's favour, leading to several downloaders receiving letters of legal threat from Odex and subsequently pursuing out-of-court settlements for at least S$3,000 (US$2,000) per person, the youngest person being only 9 years old. These actions were considered controversial by the local anime community and have attracted criticisms towards the company, as they are seen by fans as heavy-handed.\n\nOn May 18th, 2007, Anime News Network reported that the police in Poland and Germany seized the fansubbing site Napisy.org arrested at least 9 people related to it. These raids were orchestrated by the Polish Society of the Phonographic Industry (ZPAV), a collective rights organisation, and German authorities shut the site which was hosted on servers in that jurisdiction. In May of 2013, that case was closed, as prosecutors decided to drop the charges due to the charged individuals' ignorance of the unlawfulness of their actions. The site Napisy.org is currently closed and it shows sites to watch legal content.\n\nOn May 19th, 2007, the Spanish organization Federación Anti Piratería (FAP) sent a cease-and-desist against the website Wikisubtitles.net and their website provider Bluehost, requesting the closure of the site since the owners were profiting with the content of others, violating copyright laws. The webmaster complied and the site was closed.. However, the webmaster published the source-code of the website. Since then, websites like Addic7ed, Subtitulos.es and Wikisubs appeared using the Wikisubtitles source code.\n\nOn July 9th, 2013, the Swedish copyright enforcement agency Intrångsundersökning seized the servers for Swedish and English website Undertexter.se, a website that contained fansub scripts of several movies and series. On 2016, the owner of the website, Eugen Archy was prosecuted of violating the Swedish Copyright Act and was found guilty of copyright violation and the Attunda District Court sentenced him to probation. In addition, he has to pay 217,000 Swedish kronor ($27,000), which will be taken from the advertising and donation revenues he collected through the site.\n\nOn September 21, 2016, the Kyoto Prefectural Police in Japan arrested two Chinese company workers, Liang Wang and Wangyi Yang, on Wednesday on suspicion of violating the Japanese Copyright Act by uploading the anime series The Heroic Legend of Arslan: Dust Storm Dance and Fate/kaleid liner Prisma Illya Drei!! with Chinese subtitles. Both suspects admitted to the charge, and Yang claimed to be a member of a Chinese fansubbing group. This became the first known legal action against fansubbing in Japan. \n\nOn October 27th, 2016, the Kyoto Prefectural Police arrested two Chinese individuals on charges of violating the Japanese Copyright Act. The two suspects were both located in Tokyo. The first suspect is a 29-year-old male living in Edogawa ward. The second suspect is a 23-year-old male college student. According to police, the first suspect is accused of fansubbing episodes of the anime Saki: The Nationals in Chinese and uploading the subtitled episodes on a file sharing service. The second suspect allegedly subtitled a different anime in Chinese, and similarly used a file sharing service, but the report didn't mention the anime. \n\nOn February 16th, 2017, the Kyoto Prefectural Police arrested a 26-year-old Chinese man on the charge of illegally subtitle the anime Ange Vierge in Chinese and distribute it through a file sharing software. Police allege that the man is a member of the group \"Jimaku Gumi\".\n\nOn April 22, 2017 a judge in Amsterdam, Netherlands, declared fansubtitling illegal. The Dutch court declared that these translations correspond to the producers and no one else. In case they do not exist, they can not be created by fans. After this ruling, the creation of subtitles without the consent of the author of an audiovisual production is now considered a crime in the Netherlands. This is the first ruling in the world that values subtitles as intellectual property and that punishes with fines and imprisonment those who violate copyright laws.\n\nOn January 31th, 2018, Sankei West and Asahi Shimbun reported that police departments from Kyoto, Yamaguchi, Shizuoka, Mie, and Shimane Prefectures in Japan, along with the Association of Copyright for Computer Software arrested four Chinese nationals for illegal fansubbing anime, manga and videogames. The suspects, who range in age from 23 to 28, are allegedly part of a translating group that distributed Chinese-translated manga, anime, and other materials online. The titles includes Yuki Ochimura ni Ojō-sama!, Yu-Gi-Oh! ARC-V and Kimi ni Todoke. The Association of Copyright for Computer Software reported that one of the suspects, a 23-year-old female company worker from Niiza City in Saitama Prefecture, translated the 123rd and final chapter of the manga Kimi ni Todoke. Police from Kanagawa, Ishikawa, Gifu, and Shiga Prefectures also worked on the case. This is the first known arrest regarding illegal manga translation in Japan.\n\n\n"}
{"id": "45297664", "url": "https://en.wikipedia.org/wiki?curid=45297664", "title": "Flow diverter", "text": "Flow diverter\n\nA flow diverter is an endovascular prosthesis used to treat intracranial aneurysms. It is placed in the aneurysm's parent artery, covering the neck, in order to divert blood flow and determine a progressive thrombosis of the sac. Flow diverting stents consist of structural Cobalt-chrome or Nitinol alloy wires and often a set of radiopaque wires woven together in a flexible braid. \n\nFlow diverters are treatment for intracranial aneurysms alternative to endosaccular coil embolization (although the techniques can be combined, especially in large/giant aneurysms). It is mainly effective in wide neck unrupted saccular aneurysms, that are difficult to coil because of the tendency of the coils to fill the parent artery (referred to as prolapse). Another situation is fusiform shape or circumferential aneurysms. \nPrior to flow diverters many intracranial aneurysms went untreated.\n\nThe efficacy of flow diverters can be evaluated using a grading system developed by researchers at Oxford Neurovascular and Neuroradiology Research Unit (Kamran et al. 2011), commonly referred to as \"flow diverter grading system\" or \"Kamran grading system\". After receiving a cerebral flow diverter, patients are placed on dual antiplatelet therapy for an extended period of time to reduce the likelihood of peri-procedural and post-procedural thromboembolic complications. \n\nThe degree of aneurysm occlusion is graded on a five-point scale from 0 (no change in the endoaneurysmal flow) to 4 (complete obliteration of the aneurysm). The patency status of the parent artery is evaluated on a three-point scale, from no change in the parent artery diameter to parent artery occlusion. This grading system is used in clinical practice. It has also been used and adapted by researchers to evaluate and report the effectiveness of flow diverters in general.\n\n\n"}
{"id": "25771779", "url": "https://en.wikipedia.org/wiki?curid=25771779", "title": "Garmin G3000", "text": "Garmin G3000\n\nThe Garmin G3000 (and G2000/G5000) is the first touchscreen glass integrated avionics system designed for light turbine aircraft. It uses a variety of 14.1 inch integrated cockpit displays for ease of viewing and operation and 5.7 inch touchscreen controllers for intuitive control. The G3000 is capable of running Garmin's Synthetic Vision Technology, a graphical 3D rendering of terrain. The G3000 was unveiled at the NBAA Convention in 2009.\n\n\n\n"}
{"id": "1499906", "url": "https://en.wikipedia.org/wiki?curid=1499906", "title": "Glass electrode", "text": "Glass electrode\n\nA glass electrode is a type of ion-selective electrode made of a doped glass membrane that is sensitive to a specific ion. The most common application of ion-selective glass electrodes is for the measurement of pH. The pH electrode is an example of a glass electrode that is sensitive to hydrogen ions. Glass electrodes play an important part in the instrumentation for chemical analysis and physico-chemical studies. The voltage of the glass electrode, relative to some reference value, is sensitive to changes in the activity of certain type of ions.\n\nThe first studies of glass electrodes (GE) found different sensitivities of different glasses to change of the medium's acidity (pH), due to effects of the alkali metal ions.\n\nIn 1906, M. Cremer, the father of Erika Cremer, determined that the electric potential that arises between parts of the fluid, located on opposite sides of the glass membrane is proportional to the concentration of acid (hydrogen ion concentration).\n\nIn 1909, S. P. L. Sørensen introduced the concept of pH, and in the same year F. Haber and Z. Klemensiewicz reported results of their research on the glass electrode in The Society of Chemistry in Karlsruhe. \nIn 1922, W. S. Hughes showed that the alkali-silicate GE are similar to hydrogen electrode, reversible with respect to H.\n\nIn 1925, P.M. Tookey Kerridge developed the first glass electrode for analysis of blood samples and highlighted some of the practical problems with the equipment such as the high resistance of glass (50–150 megohms). During her PhD, Kerridge developed the miniature glass electrode, maximizing the surface area of the tool by heat treating the platinum with platinum chloride at red heat, thus enabling a much larger signal; her design was the predecessor of many of the glass electrodes used today.\n\nGlass electrodes are commonly used for pH measurements. There are also specialized ion sensitive glass electrodes used for determination of the concentration of lithium, sodium, ammonium, and other ions. Glass electrodes have been utilized in a wide range of applications including pure research, control of industrial processes, analysis of foods and cosmetics, measurement of environmental indicators, and microelectrode measurements such as cell membrane electrical potential and soil acidity.\n\nAlmost all commercial electrodes respond to single charged ions, like H, Na, Ag. The most common glass electrode is the pH-electrode. Only a few chalcogenide glass electrodes are sensitive to double-charged ions, like Pb, Cd and some others.\n\nThere are two main glass-forming systems: silicate matrix based on molecular network of silicon dioxide (SiO) with additions of other metal oxides, such as Na, K, Li, Al, B, Ca, etc. and chalcogenide matrix based on molecular network of AsS, AsSe, AsTe.\n\nBecause of the ion-exchange nature of the glass membrane, it is possible for some other ions to concurrently interact with ion-exchange centers of the glass and to distort the linear dependence of the measured electrode potential on pH or other electrode function. In some cases it is possible to change the electrode function from one ion to another. For example, some silicate pNa electrodes can be changed to pAg function by soaking in a silver salt solution.\n\nInterference effects are commonly described by the semiempirical Nicolsky-Eisenman equation (also known as Nikolsky-Eisenman equation), an extension to the Nernst equation. It is given by\nwhere \"E\" is the emf, \"E\" the standard electrode potential, \"z\" the ionic valency including the sign, \"a\" the activity, \"i\" the ion of interest, \"j\" the interfering ions and \"k\" is the selectivity coefficient. The smaller the selectivity coefficient, the less is the interference by \"j\".\n\nTo see the interfering effect of Na to a pH-electrode:\n\nThe pH range at constant concentration can be divided into 3 parts:\n\nwhere F is Faraday's constant (see Nernst equation).\nThe effect is usually noticeable at pH > 12, and concentrations of lithium or sodium ions of 0.1 moles per litre or more. Potassium ions usually cause less error than sodium ions.\n\nSpecialized electrodes exist for working in extreme pH ranges.\n\nA typical modern pH probe is a combination electrode, which combines both the glass and reference electrodes into one body. The combination electrode consists of the following parts (see the drawing):\n\n\nThe bottom of a pH electrode balloons out into a round thin glass bulb. The pH electrode is best thought of as a tube within a tube. The inner tube contains an unchanging 1×10 mol/L HCl solution. Also inside the inner tube is the cathode terminus of the reference probe. The anodic terminus wraps itself around the outside of the inner tube and ends with the same sort of reference probe as was on the inside of the inner tube. It is filled with a reference solution of KCl and has contact with the solution on the outside of the pH probe by way of a porous plug that serves as a salt bridge.\n\nThis section describes the functioning of two distinct types of electrodes as one unit which combines both the glass electrode and the reference electrode into one body. It deserves some explanation.\n\nThis device is essentially a galvanic cell that can be schematically represented as:\n\nIn this schematic representation of the galvanic cell, one will note the symmetry between the left and the right members as seen from the center of the row occupied by the \"Test Solution\" (the solution whose pH must be measured). In other words, the glass membrane and the ceramic junction occupies both the same relative place in each respective electrode (indicative (sensing) electrode or reference electrode). The double \"pipe symbol\" (||) indicates a diffusive barrier that prevents (glass membrane), or slowing down (ceramic junction), the mixing of the different solutions. By using the same electrodes on the left and right, any potentials generated at the interfaces cancel each other (in principle), resulting in the system voltage being dependent only on the interaction of the glass membrane and the test solution.\n\nThe measuring part of the electrode, the glass bulb on the bottom, is coated both inside and out with a ~10 nm layer of a hydrated gel. These two layers are separated by a layer of dry glass. The silica glass structure (that is, the conformation of its atomic structure) is shaped in such a way that it allows Na ions some mobility. The metal cations (Na) in the hydrated gel diffuse out of the glass and into solution while H from solution can diffuse into the hydrated gel. It is the hydrated gel, which makes the pH electrode an ion-selective electrode.\n\nH does not cross through the glass membrane of the pH electrode, it is the Na which crosses and allows for a change in free energy. When an ion diffuses from a region of activity to another region of activity, there is a free energy change and this is what the pH meter actually measures. The hydrated gel membrane is connected by Na transport and thus the concentration of H on the outside of the membrane is 'relayed' to the inside of the membrane by Na.\n\nAll glass pH electrodes have extremely high electric resistance from 50 to 500 MΩ. Therefore, the glass electrode can be used only with a high input-impedance measuring device like a pH meter, or, more generically, a high input-impedance voltmeter which is called an electrometer.\n\nBetween measurements any glass and membrane electrodes should be kept in a solution of its own ion. It is necessary to prevent the glass membrane from drying out because the performance is dependent on the existence of a hydrated layer, which forms slowly.\n\n\n"}
{"id": "5768303", "url": "https://en.wikipedia.org/wiki?curid=5768303", "title": "Handheld television", "text": "Handheld television\n\nA handheld television is a portable device for watching television that usually uses a TFT LCD or OLED color display. Many of these devices resemble handheld transistor radios.\n\nIn the 1970s and early 1980s, Panasonic and Sinclair Research released the first TVs which were small enough to fit in a large pocket; called the Panasonic IC TV MODEL TR-001 and MTV-1. Since LCD technology was not yet mature at the time, the TV used a minuscule CRT which set the record for being the smallest CRT on a commercially marketed product.\n\nLater in 1982, Sony released the first model of the Watchman, a pun on Walkman. It had grayscale video at first. Several years later, a color model with an active-matrix LCD was released. Some smartphones integrate a television receiver, although Internet broadband video is far more common.\n\nSince the switch-over to digital broadcasting, handheld TVs have reduced in size and improved in quality. The major current manufacturers of DVB-T standard (common throughout Europe) handheld TVs are August International, ODYS and Xoro.\n\nThese devices often have stereo 1⁄8 inch (3.5 mm) phono plugs for composite video-analog mono audio relay to serve them as composite monitors; also, some models have mono 3.5 mm jacks for the broadcast signal that is usually relayed via F connector or Belling-Lee connector on standard television models. \n\nSome include HDMI, USB and SD ports.\n\nScreen sizes vary from . Some handheld televisions also double as portable DVD players and USB personal video recorders.\n\nPortable televisions cannot fit in a pocket, but often run on batteries and include a cigarette lighter receptacle plug.\n\nPocket televisions fit in a pocket.\n\nWearable televisions sometimes are made in the form of a wristwatch.\n\n\n\n"}
{"id": "882056", "url": "https://en.wikipedia.org/wiki?curid=882056", "title": "Industrial Age", "text": "Industrial Age\n\nThe Industrial Age is a period of history that encompasses the changes in economic and social organization that began around 1760 in Great Britain and later in other countries, characterized chiefly by the replacement of hand tools with power-driven machines such as the power loom and the steam engine, and by the concentration of industry in large establishments.\n\nWhile it is commonly believed that the Industrial Age was supplanted by the Information Age in the late 20th century, a view that has become common since the Revolutions of 1989, as of 2013 electric power generation is still based mostly on fossil fuels and much of the Third World economy is still based on manufacturing. Thus it is debatable whether we have left the Industrial Age already or are still in it and in the process of reaching the Information Age.\n\nHuge changes in agricultural methods made the Industrial Revolution possible. This agricultural revolution started with changes in farming in the Netherlands, later developed by the British.\n\nThe Industrial mining from places such as Wales and County Durham.\n\nThe Industrial Revolution began in Great Britain because it had the factors of production, land (all natural resources), capital, and labor. Britain had plenty of harbors that enabled trade, Britain had access to capital, such as goods and money, for example, tools, machinery, equipment, and inventory. Britain, lastly, had an abundance of labor, or industrial workers in this case. There are many other conditions that help show why the Industrial Revolution began in Great Britain. The British Isles and colonies overseas represented huge markets that created a large demand for British goods. Britain also had one of the largest spheres of influence due to its massive navy and merchant marine. The British government's concern for commercial interests was also important. \nThe steam engine allowed for steamboats and the locomotives, which made transportation much faster. By the mid-19th century the Industrial Revolution had spread to Continental Europe and North America, and since then it has spread to most of the world.\n\nThe cotton industry was the first industry to go through mechanization, the use of automatic machinery to increase production. The domestic system sprouted as a result of when businesses began importing raw cotton, employing spinners and weavers to make it into cloth from their home. Jarry Hargreaves invented the spinning jenny, which could produce eight times as much thread as a single spinning wheel, and Richard Arkwright made it driven by water. Later Arkwright opened a spinning mill which marked the beginning of the factory system. In 1785 Edmund Cartwright invented a loom which was powered by water.\n\nIn 1712 Thomas Newcomen produced the first successful steam engine, and in 1769 James Watt patented the modern steam engine. As a result, steam replaced water as industry's major power source.\n\nThe steam engine allowed for steamboats and the locomotives, which made transportation much faster. By the mid-19th century the Industrial Revolution had spread to Continental Europe and North America, and since then it has spread to most of the world.\n\nThe Industrial Age is defined by mass production, broadcasting, the rise of the nation state, power, modern medicine and running water. The quality of human life has increased dramatically during the Industrial Age. Life expectancy today worldwide is more than twice as high as it was when the Industrial Revolution began.\n\n"}
{"id": "44797478", "url": "https://en.wikipedia.org/wiki?curid=44797478", "title": "International Journal of Energy Research", "text": "International Journal of Energy Research\n\nInternational Journal of Energy Research is a monthly peer-reviewed scientific journal published by John Wiley & Sons. Its scope includes fossil, nuclear, and renewable energy sources, and research into energy storage. It was established in 1997 and the editor-in-chief is Ibrahim Dincer (University of Ontario Institute of Technology).\n\nThe journal is abstracted and indexed in:\n\nAccording to the \"Journal Citation Reports\", the journal has a 2013 impact factor of 2.737.\n"}
{"id": "14682402", "url": "https://en.wikipedia.org/wiki?curid=14682402", "title": "Jack Henry &amp; Associates", "text": "Jack Henry &amp; Associates\n\nJack Henry & Associates, Inc.® (NASDAQ: JKHY) is a provider of technology solutions and payment processing services primarily for the financial services industry. Its solutions serve more than 9,000 customers nationwide, and are marketed and supported through three primary brands. Headquartered in Monett, Missouri, JHA made $1.54 billion in annual revenue during fiscal 2018.\n\nJack Henry & Associates (commonly referred to as JHA) was formed in 1976 by Jack Henry and Jerry Hall in Monett, Missouri. In 1977, Jack Henry & Associates was incorporated and generated $115,222 in revenue.\n\nOn November 20, 1985, an Initial Public Offering made JHA a public company trading 3,125,000 common shares on the NASDAQ exchange under the symbol JKHY. In 1992, JHA began to aggressively acquire companies that expanded its product offering and its client base. It acquired Symitar® in 2000, establishing its second brand which serves the credit union industry. In 2004, JHA’s focused diversification acquisition strategy resulted in the acquisition of a number of companies and products that can be sold outside JHA’s core client base to all financial services organizations regardless of charter, asset size, core processing platform. In 2006, JHA launched its third primary brand – ProfitStars® – to encompass the specialized products and services assembled through its focused diversification acquisition strategy. In 2012, JHA announced $1 billion in annual revenue. The company celebrated its 40 year anniversary in 2016. JHA placed on Forbes as one of America's Best Employers for 2017 and 2018. They ranked number 2 in the IT, Internet, Software, and Services category and number 12 overall on the large companies list in 2018. \n\nJack Henry & Associates, Inc.® (NASDAQ: JKHY) is a leading provider of technology solutions and payment processing services primarily for the financial services industry. Its solutions serve more than 9,000 customers nationwide, and are marketed and supported through three primary brands listed below.\n\nJack Henry Banking®, a division of Jack Henry & Associates, Inc.®, is a leading provider of integrated computer systems for banks ranging from de novo to multi-billion-dollar institutions. Jack Henry Banking currently serves approximately 1,100 banks as a single source for integrated, enterprise-wide automation and as a single point of contact and support.\n\nSymitar®, a division of Jack Henry & Associates, Inc.®, was founded in 1984 and acquired by JHA in 2000. Symitar is the leading provider of integrated computer systems for credit unions of all sizes. Symitar has been selected as the primary technology partner by more than 800 credit unions, serving as a single source for integrated, enterprise-wide automation and as a single point of contact and support. Symitar's product is Episys, a software application used to manage member base and process transactions. It has its own PowerOn scripting language, RepGen, and its own SymConnect and SymXchange interfaces allowing for access by Symitar, Jack Henry add-on modules, and third-party applications.\n\nProfitStars®, a division of Jack Henry & Associates, Inc.®, helps financial institutions of every asset size and charter, and diverse corporate entities, proactively identify and prepare for risks and market changes that could negatively impact their business. ProfitStars’ industry-leading solutions and services include JHA Payment Solutions,Information Security & Risk Management, Online & Mobile, Lending, Financial Performance, and Imaging/Data Management. These solutions help approximately 9,000 clients mitigate and control risks, optimize revenue and growth opportunities, contain costs, and drive future success. It provides a sales force automation system, check imaging, and disaster recovery services using any core processing system.\n\n\n\n\n\n\n\n\n\n"}
{"id": "30888502", "url": "https://en.wikipedia.org/wiki?curid=30888502", "title": "Keneth Alden Simons", "text": "Keneth Alden Simons\n\nKeneth Alden Simons (March 10, 1913 – June 11, 2004) was an American electrical engineer best known for his pioneering contributions to the technical development of cable television in the United States, for the most part as chief engineer for the Jerrold Electronics Corporation. Jerrold was one of the first manufacturers of cable television equipment and also constructed entire cable systems. Simons designed one of the first converters and the two most important pieces of the early test equipment, the Model 704 Field Strength Meter and Model 900 Sweep Frequency Generator. He also authored a seminal technical handbook on cable television systems, and served on national and international engineering standards committees. Fellow cable engineer Archer Taylor stated that Simons was seen as the leading technical expert at Jerrold for over two decades.\n\nBorn in Philadelphia, Pennsylvania, Simons' interest in radio began at an early age, and he obtained his amateur radio license (callsign W3UB) in 1930. Simons started his career as a radio troubleshooter for RCA in 1932 in Camden, and worked for RCA while he attended college. In 1938 he graduated from the Moore School of Electrical Engineering of the University of Pennsylvania,with distinction and recipient of the A. Atwater Kent Prize in Electrical Engineering] (see Atwater Kent Museum of Philadelphia) He then became a television field engineer for RCA. On one occasion in 1939 he and another field engineer installed a television set in the honeymoon cottage of movie stars Robert Taylor and Barbara Stanwyck, and Simons showed her how to operate it. Later Simons helped run the at the 1939 World’s Fair. In the summer of 1940 he was sent by RCA to run the public address system and make recordings of speeches on the campaign train of Wendell Willkie, the Republican candidate for president that year.\n\nIn 1941 he was a radio engineer for WCAU in Philadelphia, broadcasting live concerts over the radio. From 1942 until 1946 he was the chief instructor for the RCA Signal Corps School. Along with teaching operation and repair of various devices, he wrote instruction manuals on oscilloscope use and synchronous motors.\n\nHe moved to Kansas City, Missouri, in 1946 and was the chief television instructor at Central Radio School until 1948. Simons then worked for Sylvania for about a year developing television tuners and an indoor antenna. In 1952 he formed a partnership to design and manufacture direct-coupled oscilloscopes. Due to lack of funding, they ultimately were not produced.\n\nSimons began at Jerrold Electronics Corporation as a part-time consulting engineer in 1951. His first project was to design a high-to-low frequency converter. He and other Jerrold engineers worked out of Simons' personal laboratory located on the second floor of a stained glass factory in Bryn Athyn, Pa., until a new Jerrold lab was built in Hatboro, Pa., in 1955. Simons characterized his role at Jerrold in his resume: \"Three of us were primarily responsible for equipment design in the early years. Donald Kirk was talented in coming up with new ideas, my contribution was often in getting a system to work, and Henry Arbeiter took all the bright ideas and made them producible.\" Other engineering colleagues included Eric Winston, Mike Jeffers, Frank Ragone, Caywood Cooley, Vic Nicholson, Len Ecker, and Bill Felsher. Simons successively became chief engineer, chief test equipment engineer, vice president and director of advanced development. Some of his noteworthy designs include the Model 704B Field Strength Meter. In a technology area based on rapid and constant change, the 704B was of note in being in production and use for more than 20 years The 704 name is honored even today in a fraternal organization of its users \"The Loyal Order of the 704\", commemorating the meter’s defining role in cable development. Simons also designed its successor, the Model 727 Field Strength Meter; the Model 900 and Model 1015 Sweep Frequency Generators, and the Model SCA 213 Distributed Amplifier.\n\nSimons held 13 US and foreign patents, published four books, one of which was translated into Spanish. and 37 articles in engineering publications (e.g.\n). His well-regarded \"Technical Handbook for CATV Systems\" went through 4 editions from 1965 to 1985.\n\nSimons served on two technical committees of the International Electrotechnical Commission, part of the \"International Organization for Standardization\", beginning in 1969. He was a life member of the Institute of \"Electrical\" and Electronics Engineers (IEEE), a member of the Society of Cable Television Engineers, and a Fellow of the British Society of Cable Engineers.\n\nAs part of the International Geophysical Year, the Smithsonian Astrophysical Observatory set up a national network of amateur-run observation stations to track the early Russian artificial satellites, Sputniks I and II, Operation Moonwatch. As a member of his local Moonwatch group Moonwatch group, he made use of a unique radio-based Doppler tracking system he designed to enhance the accuracy of his team’s sightings.\n\nSimons retired from Jerrold in 1976. He then served as a consultant for a number of cable industry manufacturers until 1989, and then for the University of Pennsylvania beginning in 1990.\n\nIn February 1992, Simons was interviewed by Archer Taylor covering a broad range of topics from his life in cable television. The Audio and Transcript of the interview are now archived in the oral histories maintained by The Cable Center.\n\nSimons had originally patented a directional coupler, U.S. Patent 3,048,798, filed December 24, 1959, that had defined this key component for cable-based distribution of television. Now, 35 years later, he designed another coupler unit, U.S Patent 5,461,349, filed Oct. 17, 1994, a wide-band bidirectional coupler. He expanded on its concept with a proposal for a contemporary bidirectional hybrid copper and optical cable television headend, with a 1 GHz bandwidth and privacy capabilities.\n\nThe final innovation he worked on involved getting back together with a friend he had first worked with when both were in college, the distinguished biophysicist Britton Chance. “In BC’s group meeting on every Saturday, he invited his friend Ken Simons (retired from RCA lab) to teach us circuits and electronics.”\nChance’s group wanted to construct an optical tomography-based replacement for the standard MRI. Simons collaborated in this effort, attempting to use phase modulation of the illuminating laser to more efficiently measure hemoglobin deoxygenation in body tissue.\n\nChance later wrote:\n\n\"A Boon to Medicine\"\n\nI appreciated the June 15 obituary of Keneth Simons. However, not only was he a contributor to cable television but he volunteered his unique knowledge to the faculty of the University of Pennsylvania Medical School in developing optical imaging systems for the detection of breast cancer and brain function. This deep knowledge and facile handiwork made possible the perfection of devices that are now the focus of new types of medical devices that make possible non-invasive and highly sensitive detection of brain function, muscle function and cancer detection.\nSimons will be long remembered for his generous and far-reaching knowledge of electronic circuits.\n\nBritton Chance\n\nDepartment of Biochemistry and Biophysics\nUniversity of Pennsylvania\nPhiladelphia\n\nPhilly.com: Letters\nPosted: June 30, 2004 \n\nIn addition to the list of memberships and committee assignments\nSimons was an invited participant at a variety of standards-setting meetings.\n\nThe National Cable Television Association (NCTA) named Simons \"CATV Engineer of the Year\" in 1965, and he served on NCTA's Ad Hoc Committee on Technical Standards and their Engineering Subcommittee. In 1973 NCTA presented Simons with the \"Technical Achievement Award\" (now the \"Vanguard Award for Science & Technology\").\n\nSimons was awarded the first IEEE Delmer Ports Award, in 1978 at IEEE’s annual meeting. He was characterized in the award as a legend in the CATV industry and credited for his role in developing NCTA technology. He was credited as responsible for NCTA noise interference standards and for the measurement of distortion components. His \"Technical Handbook for CATV Systems\" was characterized as an indispensable sourcebook on the technical aspects of CATV and for many years the best tutorial available on performance and measurement in CATV.\n\nSimons died June 11, 2004.\n\nUniversity of Pennsylvania, \"Alumni Gazette\" November/December 2004 issue, Class of 1938\n\nDowney, S. Keneth A. Simons, 91, leader in the cable-television industry \n\n"}
{"id": "7486928", "url": "https://en.wikipedia.org/wiki?curid=7486928", "title": "Library card", "text": "Library card\n\nA library card can refer to several cards traditionally used for the management of books and patrons in a library. In its most common use, a library card serves similar functions as a membership card. A person who holds a library card has borrowing or other privileges associated with the issuing library. The library card also serves as a method of identification. When a person chooses an item to borrow and presents their library card to the library, they take responsibility for the borrowed item and promise to abide by certain rules, usually including a promise to return the item by the due date or face a library fine. If the cardholder violates these responsibilities, their borrowing privileges may be suspended. As of 2011, 62% of all Americans are library cardholders.\n\n\"Library card\" may also refer to the \"borrowing cards\" used to record book borrowing before the advent of computer systems. When a library book was prepared for lending, a borrowing card would be inserted into a small pocket in the front or back cover of the book. When a patron borrowed a book, their name and the book's due date would be recorded on the borrowing card, which would be filed under the patron's name or card number. The borrowing card would be replaced with a stamped due date card to inform the patron of the item's due date. The book was then released to the patron. When the book was returned, the patron's name would be crossed off the borrowing card. The borrowing card would be placed back in the book and the book would be shelved. In some libraries, this system of borrowing may still be in use.\n\n"}
{"id": "24759565", "url": "https://en.wikipedia.org/wiki?curid=24759565", "title": "László Kozma", "text": "László Kozma\n\nLászló Kozma (Miskolc, Hungary, 28 November 1902 − Budapest, Hungary, 9 November 1983) was a Hungarian electrical engineer, designer of the first Hungarian digital computer (1957), a full member of the Hungarian Academy of Sciences.\n\nDue to the regulations of numerus clausus his application to the Budapest University of Technology was rejected in 1921, and he started to work as an electrician. Between 1925 and 1930 he studied at the Brno University of Technology, where he graduated as an electrical engineer in 1930, then was hired by the Antwerpen office of the International Telephone & Telegraph company to design automated telephone switchboards and electromechanical computers. He moved back to Hungary in 1942, but in 1944 he was deported to the Mauthausen concentration camp. He returned in August 1945 in a very poor physical state, then worked for a Hungarian electrical company, Standard Electrical Co. as designing engineer. He was arrested by the communist government in 1949, and sentenced to 15 years in the show trial called Standard Gate. He was rehabilitated and released from prison in 1954 and taught as a professor at the Budapest University of Technology and Economics between 1955 and 1972.\n\nHis main researches were in the field of automatization of telephone technology, but he is more notable for the first Hungarian digital computer (called MESZ–1) what he designed and created between 1955 and 1957. He was a corresponding (1961), then a full member (1976) of the Hungarian Academy of Sciences.\n\n\n"}
{"id": "12286667", "url": "https://en.wikipedia.org/wiki?curid=12286667", "title": "Mark 26 nuclear bomb", "text": "Mark 26 nuclear bomb\n\nThe Mark 26 nuclear bomb was related to the Mark 21. Development of the Mk-26 started on 1 September 1954. At the end of July 1955 the design of the Mk-21 was released for production, while the design for the Mk-26 was not. The \"Clean\" Mk-21C which was tested in the Redwing Navajo shot did not interest the US Air Force, or AEC. As the decision not to pursue the \"clean\" Mk-21 closely coincided with the decision to terminate development of the Mk-26 in April 1957, it is possible that Mk-26 was the designation for the clean version of the Mk-21.\n\n"}
{"id": "14719170", "url": "https://en.wikipedia.org/wiki?curid=14719170", "title": "MicroMSI", "text": "MicroMSI\n\nMicroMSI for Windows is a remote sensing imagery analysis program designed for use in introductory courses in remote sensing, developed by the National Geospatial-Intelligence Agency. MicroMSI for Windows is a \"public domain program and can be freely redistributed for non-commercial purposes\", after modern terminology freeware.\n\nThese pages have been made available to enhance the support services for the MicroMSI user community. A number of resources are provided here to help you resolve problems, report bugs, and suggest improvements to MicroMSI products and services.\n\nMicroMSI for Windows updates the original DOS-based version with a full 32-bit Windows implementation.\n\nDocumentation is supplied in the extensive help file which serves as a reference to MicroMSI features and commands, but also provides a multi-spectral image processing tutorial as student exercises.\n\n\n"}
{"id": "1166229", "url": "https://en.wikipedia.org/wiki?curid=1166229", "title": "Mop", "text": "Mop\n\nA mop (such as a floor mop) is a mass or bundle of coarse strings or yarn, etc., or a piece of cloth, sponge, or other absorbent material, attached to a pole or stick. It is used to soak up liquid, for cleaning floors and other surfaces, to mop up dust, or for other cleaning purposes. The word (then spelled \"mappe\") is attested in English as early as 1496, but new refinements and variations of mop designs have been introduced, from time to time. For example, American inventor Jacob Howe received U.S. patent #241 for a mop holder in 1837 and Thomas W. Stewart (U.S. patent #499,402) in 1893. At the 1968 Miss America protest, protestors symbolically threw a number of feminine products into a \"Freedom Trash Can\", which included mops.\n\nA dry mop or dust mop is designed to pick up dry, loose contamination such as dust, earth, and sand from the surface of the floor. It consists of yarn and/or microfiber and is used as a first step in cleaning a floor.\n\nProfessional dry mops consist of a flat sheet of microfiber textile or sheets with a surface of looped yarn, usually about wide, and comes in variable lengths (usually ).\n\nThe dry mop can in many instances replace a broom and has the ability to hold a limited amount of dust or sand within itself. The heads of dry mops are often removable and can be washed and replaced when saturated with dust. Another option is using a vacuum cleaner to suck surface dust away from the mop; however, this is much more limited in its effectiveness.\n\nSingle-use dry mops are also available and widely sold.\n\nA wet mop or moist mop is, in professional cleaning, used as in the second step in the cleaning of a surface. The wet mop is swept over the surface to dissolve and absorb fat, mud and dried-in liquid contaminations. Professional wet mops consist of a flat sheet of microfiber textile or a sheet with a surface of looped yarn (which might contain microfiber as well), usually about wide, and come in various lengths (usually ).\n\nProfessional flat mops are made for pre-moisting. Mops are pre-impregnated with an ideal amount of water mixed with an appropriate amount of detergent. This means that the cleaner does not need to bring any additional water on the cleaning trolley. This ideal amount is often recommended by the manufacturer in terms of weight percent of water per weight of the dry mop, for example \"175% water per weight of the dry mop\".\n\nMops for pre-moisting are flat sheets of (often microfiber) textile, usually about wide, and comes in variable lengths (usually ). Mops for pre-moisting are fastened on a handle with a flat pad mount with the aid of velcro or a pouch on the mop, in which the pad on the handle fits.\n\nPre-moisting can be done with a special washing machine or by hand by simply folding and packing the mops tight in a container and pouring the measured amount of water over them. The mops will then need about 5–10 minutes for the liquid to distribute evenly in their tissue before use. This offers some advantages:\n\nThe \"hot mop\" (or steam mop) follows a similar concept to a steam iron. After adding water, the water is heated to make it exude on top of a floor, which can then be cleaned without using a cleaning solvent. These can work best on surfaces where a regular mop would also be used, such as bare floors, hearths, and laminate.\n\nA \"syntho-mop\" such as the Scooba is not considered a mop, because even though it performs the same function as a traditional mop, the lack of hand operation makes it ineligible for status as a mop.\n\nMicrofiber mops are constructed of a blend of polyester and polyamide fibers which are “split” and formed into a single fiber. This blend consists of 70-90% polyester that serves as the scrubbing and cleaning fiber and 10–30% polyamide which performs as the holding and quick drying fiber. This blend is usually expressed as a ratio on the label of the mop, e.g. an 80% polyester and 20% polyamide blend would be labeled as \"80/20\".\n\nA mop handle consists of a long piece of wood or aluminium tubing fitted with a specific mount for the mop. The handle can be attached for mounting a mop on it by means of:\n\n\nIn her book \"Maggie's Memories\" Margaret Wadkin (late of Hickling, near Melton Mowbray in England) describes the use of a mop nail for constructing homemade mops from old pieces of cloth during her village childhood in the early 20th century. \"The mop nail was made by the blacksmith (if there are any still around, they will be antiques). This nail was several inches long with a point at the end and a flat head a couple or so inches wide. We would stand the nail on its flat head, cut pieces of old material into squares and push over the sharp end of the nail and when enough fix a piece of leather, then push the sharp point into the mop stale or handle. There was a knack of twisting these mops over the wrist to swish away surplus water, every woman could use one of these useful mops.\"\n\n"}
{"id": "56984039", "url": "https://en.wikipedia.org/wiki?curid=56984039", "title": "Mr. Steven", "text": "Mr. Steven\n\nMr. Steven is the ship intended as a landing platform for the SpaceX reusable rocket payload fairings. The ship is fitted with four large arms which support an elevated horizontal net, similar to a giant trampoline or trapeze net. It is named after Steven Miguez, the father of SeaTran CEO Blake J. Miguez.\n\nAs a part of the SES-10 mission in March 2017, SpaceX successfully performed a controlled landing of the payload fairing for the first time. SpaceX was able to recover a fairing half after it landed, aided by attitude-control thrusters and a steerable parachute, gently on water. The company announced its intent to land the fairings on a dry flexible structure, jokingly described by Elon Musk as a \"floating bouncy castle\", with the goal of reusing the fairings.\n\nThe bouncy castle idea led to a fast platform supply vessel named \"Mr. Steven\" which has a net strung between large arms. \"Mr. Steven\" is equipped with a dynamic positioning system and was first tested after the launch of the Paz satellite from Vandenberg Air Force Base in February 2017. The test was not fully successful because the fairing missed the boat by a few hundred meters but landed safely in the water before being recovered and taken back to port. , all four attempts by SpaceX to land a fairing on the recovery ship have failed, despite fitting \"Mr. Steven\" with larger nets before the July 2018 attempt.\n\nIn October 2018, to practice recovery outside mission situations, SpaceX started to perform drop tests of a fairing half from a helicopter into \"Mr. Steven's\" net.\n\nThe cost of a fairing is about $6 million which accounts for 10 percent of overall launch costs.\n\nIn July 2018, \"Mr. Steven\" was upgraded to fit a broader net with an area of , four times the original net size. The upgrade included fitting four new arms, which are each supported and positioned by two extendable shock-absorbing booms. Each arm can be removed and disassembled into six subsections. These four shock-absorbing arms replaced the previous rigid arms.\n\n"}
{"id": "25240121", "url": "https://en.wikipedia.org/wiki?curid=25240121", "title": "Multiplex polymerase chain reaction", "text": "Multiplex polymerase chain reaction\n\nMultiplex polymerase chain reaction (Multiplex PCR) refers to the use of polymerase chain reaction to amplify several different DNA sequences simultaneously (as if performing many separate PCR reactions all together in one reaction). This process amplifies DNA in samples using multiple primers and a temperature-mediated DNA polymerase in a thermal cycler. The primer design for all primers pairs has to be optimized so that all primer pairs can work at the same annealing temperature during PCR.\n\nMultiplex-PCR was first described in 1988 as a method to detect deletions in the dystrophin gene. It has also been used with the steroid sulfatase gene. In 2008, multiplex-PCR was used for analysis of microsatellites and SNPs.\n\nMultiplex-PCR consists of multiple primer sets within a single PCR mixture to produce amplicons of varying sizes that are specific to different DNA sequences. By targeting multiple sequences at once, additional information may be gained from a single test run that otherwise would require several times the reagents and more time to perform. Annealing temperatures for each of the primer sets must be optimized to work correctly within a single reaction, and amplicon sizes, i.e., their base pair length, should be different enough to form distinct bands when visualized by gel electrophoresis. Alternatively, if amplicon sizes overlap, the different amplicons may be differentiated and visualised using primers that have been dyed with different colour fluorescent dyes. Commercial multiplexing kits for PCR are available and used by many forensic laboratories to amplify degraded DNA samples.\n\nSome of the applications of multiplex PCR include:\n\nVisual OMP - Software for Multiplex PCR Primer design\n\nPrimerPlex - Software for Multiplex PCR Primer design\n\nuMelt Batch 1.5 - Software for Predicting Melting Curves for Multiplex PCR Products (sum of curves)\n\nPrimer Pooler\n"}
{"id": "32714200", "url": "https://en.wikipedia.org/wiki?curid=32714200", "title": "Neil Gallagher (Donegal footballer)", "text": "Neil Gallagher (Donegal footballer)\n\nNeil Gallagher (born 1982/1983) is a Gaelic football player. He plies his trade with Glenswilly and played inter-county for Donegal, usually at midfield from 2004 until his retirement in 2017.\n\nAmong other accolades, he has two All Stars to his name (2012 and 2014), one All-Ireland Senior Football Championship (2012), three Ulster Senior Football Championships (2011, 2012 and 2014) and one National Football League (2007). He captained Donegal to the National Football League title in 2007.\n\nEducated at Saint Eunan's College in Letterkenny, he warmed the bench during the College's 2000 McLarnon Cup victory.\n\nGallagher was part of the Glenswilly team that won the 2011 Donegal Senior Football Championship (his team's first County Championship at senior level). Glenswilly defeated Naomh Mícheál by 1-8 to 0-9 in the final. He won his second Donegal Senior Football Championship with Glenswilly in 2013, scoring a goal in the final against Killybegs. The team had a successful Ulster campaign, advancing to the final of the 2013 Ulster Senior Club Football Championship, where they lost to Ballinderry.\n\nGallagher was first called up to the senior team by Brian McEniff for winter training in 2003. He made his senior debut for Donegal in 2004. That year his team made it to the Ulster final but were defeated by Armagh. 2005 was unsuccessful. Donegal reached the 2006 Ulster Senior Football Championship Final and he played in that match at Croke Park.\n\nIn 2007, he was part of the Donegal team that won the county's first National Football League title. They defeated Mayo in the final. He was the caption that day.\n\nAlongside Glenswilly teammate Ciaran Bonner, he was dropped by manager John Joe Doherty over a breach of discipline ahead of the 2009 All-Ireland Senior Football Championship qualifier game against Carlow.\n\nHe became a linchpin of the Donegal midfield during the Jim McGuinness managerial era, winning his first Ulster title in 2011. He won his second in 2012. He was then part of the Donegal team that reached the 2012 All-Ireland Senior Football Championship Final. He scored a point against Mayo at Croke Park as Donegal claimed the Sam Maguire Cup.\n\nHe also started for Donegal in the 2014 All-Ireland Senior Football Championship Final.\n\nInjuries prompted him to announce his retirement from inter-county football at the age of 33 on 20 February 2017.\n\nIn conjunction with teammate Michael Murphy, Gallagher opened the sports store \"Michael Murphy Sports and Leisure\" in Letterkenny in August 2014.\n\nLess than a week after the 2014 All-Ireland Senior Football Championship Final, Gallagher attended the 2014 Ryder Cup in Perthshire, Scotland.\n\n\n\n"}
{"id": "37843", "url": "https://en.wikipedia.org/wiki?curid=37843", "title": "Nuclear electric rocket", "text": "Nuclear electric rocket\n\nIn a Nuclear Electric Rocket (also known as nuclear electric propulsion and space nuclear fission electric power systems), nuclear thermal energy is changed into electrical energy that is used to power one of the electrical propulsion technologies. Technically the powerplant is nuclear, not the propulsion system, but the terminology is standard. A number of heat-to-electricity schemes have been proposed: Rankine cycle, Brayton cycle, Stirling cycle, thermoelectric (including graphene-based thermal power conversion), pyroelectric, thermophotovoltaic, thermionic and magnetohydrodynamic type thermoelectric materials.\n\nOne of the more practical schemes is a variant of a pebble bed reactor. It would use a high mass-flow nitrogen coolant near normal atmospheric pressures. This would take advantage of highly developed conventional gas turbine technologies. The fuel for this reactor would be highly enriched, and encapsulated in low-boron graphite balls probably 5–10 cm in diameter. The graphite serves to slow, or moderate, the neutrons.\n\nThis style of reactor can be designed to be inherently safe. As it heats, the graphite expands, separating the fuel and reducing the reactor's criticality. This property can simplify the operating controls to a single valve throttling the turbine. When closed, the reactor heats, but produces less power. When open, the reactor cools, but becomes more critical and produces more power.\n\nThe graphite encapsulation simplifies refueling and waste handling. Graphite is mechanically strong, and resists high temperatures. This reduces the risk of an unplanned release of radioactives.\n\nSince this style of reactor produces high power without heavy castings to contain high pressures, it is well suited to power spacecraft.\n\nResearch in nuclear propulsion began with studies for nuclear thermal propulsion, where the reactor heated a propellant (usually hydrogen) that was allowed to expand through a nozzle. This was essentially an ordinary chemical rocket with the nuclear reaction replacing chemical combustion as the rocket's heat source. Because the reactor could supply more heat to the propellant than chemical combustion, higher exhaust velocities, i.e., higher specific impulses, were possible. See KIWI, NERVA. The reports at the time (and since) indicated that keeping the system light would require high-temperature, densely packed designs, such as fast metal-cooled reactors or hexagonal pin fueled, high temperature gas-cooled reactors. In the past several decades the attention has turned to using the nuclear reactor to drive a turbine to produce electricity, which is used to create a plasma which is accelerated. See Project Prometheus. The present best of tech is the SAFE-400, which uses a 400 kW thermal reactor and a gas turbine (called a closed Brayton cycle) to produce electric power. Heat rejection is kept low-mass using advanced heat pipe systems (such as are now used in some laptop computers for cooling as well). Safety comes from ruggedness, proper shielding, control pins and spoiler pins inside the reactor which arrest the reaction.\n\nThe key elements to NEP, as they are being pursued today are:\n\nThe SAFE-400 is the current best of tech for items 1–3. Item 4 is common to all spacecraft. Some examples of thrusters that might be suitable for this are VASIMR, DS4G and pulsed inductive thruster (PIT). PIT and VASIMR are unique in their ability to trade between power usage, specific impulse (a measure of efficiency, see specific impulse) and thrust in-flight. PIT has the additional advantage of not needing the power conditioning system between itself and the electric generators.\n\nNuclear electric propulsion is a field that is distinct from other space nuclear power areas, such as radioisotope systems (including radioisotope thermoelectric generators, radioisotope heater units, radioisotope piezoelectric generators & the radioisotope rocket - all of which use the heat from a static radioactive source (usually Plutonium-238) for a low level of electric or direct propulsion power), a nuclear thermal rocket (energy is used to heat the liquid hydrogen propellant), direct nuclear (fission products from a nuclear reaction directly propel the rocket), nuclear pulse propulsion (nuclear explosions propel the rocket), or space based nuclear fusion systems, either a fusion rocket, or some as-yet theoretical or unproven experimental fusion technology.\n\n"}
{"id": "362151", "url": "https://en.wikipedia.org/wiki?curid=362151", "title": "OMAR Mine Museum", "text": "OMAR Mine Museum\n\nLocated in Kabul, Afghanistan, the OMAR Mine Museum contains a collection of 51 types of land mines out of the 53 used in Afghanistan over the years. OMAR is an acronym for the Organization for Mine Clearance and Afghan Rehabilitation. The collection includes unexploded ordnance, cluster bombs and airdrop bombs used by the War in Afghanistan.\n\nThe museum also displays a variety of other military hardware from wars fought in Afghanistan over the recent decades, including artillery, surface-to-air missiles, and a collection of Soviet military aircraft.\n\nFor security reasons, the museum is not open for casual visitors. All appointments must be made through the main OMAR office.\n\n\n\n\nBlog entries describing visits to the museum:\n"}
{"id": "13816853", "url": "https://en.wikipedia.org/wiki?curid=13816853", "title": "Overengineering", "text": "Overengineering\n\nOverengineering (or over-engineering) is the act of designing a product to be more robust or have more features than necessary for its intended use, or for a process to be unnecessarily complex or inefficient.\n\nOverengineering is often done to increase a factor of safety, add function, or overcome perceived design flaws that most users would accept. Overengineering can be desirable when safety or performance is critical (e.g. in aerospace vehicles), or when extremely broad functionality is required (e.g. diagnostic tools), but it is generally criticized in terms of value engineering as wasteful of resources such as materials, time and money. As a design philosophy, it is the opposite of the minimalist ethos of \"less is more\" and a violation of the KISS principle.\n\nOverengineering generally occurs in high-end products or specialized markets. In one form, products are \"overbuilt\" and have performance far in excess of expected normal operation (a city car that can travel at 300 km/h, or a home video recorder with a projected lifespan of 100 years), and hence are more expensive, bulkier, and heavier than necessary. Alternatively, they may become \"overcomplicated\" – the extra functions may be unnecessary, and potentially reduce the usability of the product by overwhelming end users.\n\nOverengineering can decrease the productivity of the design team because of the need to build and maintain unwanted features.\n\nA related issue is market segmentation – making different products for different market segments. In this context, a particular product may be more or less suited (and thus considered over- or under-engineered) for a particular market segment.\n\nA story about very precise engineering is given in the 1858 story \"\" by Oliver Wendell Holmes, Sr., which tells of a carriage (one-horse shay)\n<poem>That was built in such a logical way\nIt ran a hundred years to a day,\nAnd then,\nwent to pieces all at once, --\nAll at once, and nothing first, --\nJust as bubbles do when they burst.\n</poem>\nBecause it had been engineered so that no single piece failed first – no piece was over-engineered relative to the others, and they thus all collapsed at the same time.\n\nA similar quote by Ferdinand Porsche claimed \"the perfect race car crosses the finish line in first place and immediately falls into pieces.\"\n\nA modern example is Juicero, a wi-fi \"smart\" juicing press. But after its release, Bloomberg News published a story that showed that the juice packs could be squeezed by hand faster than the press, and that hand-squeezing produced juice that was indistinguishable in quantity and quality from the output of the machine.\n\n\n"}
{"id": "79488", "url": "https://en.wikipedia.org/wiki?curid=79488", "title": "Paper shredder", "text": "Paper shredder\n\nA paper shredder is a mechanical device used to cut paper into either strips or fine particles. Government organizations, businesses, and private individuals use shredders to destroy private, confidential, or otherwise sensitive documents. \n\nThe first paper shredder is credited to prolific inventor Abbot Augustus Low, whose patent was filed on February 2, 1909. His invention was however never manufactured.\n\nAdolf Ehinger's paper shredder, based on a hand-crank pasta maker, was manufactured in 1935 in Germany. Supposedly he needed to shred his anti-Nazi propaganda to avoid the inquiries of the authorities. Ehinger later marketed his shredders to government agencies and financial institutions converting from hand-crank to electric motor. Ehinger's company, EBA Maschinenfabrik, manufactured the first cross-cut paper shredders in 1959 and continues to do so to this day as EBA Krug & Priester GmbH & Co. in Balingen.\n\nUntil the mid-1980s, it was rare for paper shredders to be used by non-government entities. \n\nA high-profile example of their use was when the U.S. embassy in Iran used shredders to reduce paper pages to strips before the embassy was taken over in 1979, but some documents were reconstructed from the strips, as detailed below.\n\nAfter Colonel Oliver North told Congress that he used a Schleicher cross-cut model to shred Iran-Contra documents, sales for that company increased nearly 20 percent in 1987. \n\nPaper shredders became more popular among U.S. citizens with privacy concerns after the 1988 Supreme Court decision in \"California v. Greenwood\"; in which the Supreme Court of the United States held that the Fourth Amendment does not prohibit the warrantless search and seizure of garbage left for collection outside of a home. Anti-burning laws also resulted in increased demand for paper shredding.\n\nMore recently, concerns about identity theft have driven increased personal use, with the US Federal Trade Commission recommending that individuals shred financial documents before disposal.\n\nInformation privacy laws like FACTA, HIPAA and the Gramm–Leach–Bliley Act are driving shredder usage, as businesses and individuals take steps to securely dispose of confidential information.\n\nShredders range in size and price from small and inexpensive units designed for a certain amount of pages, to large units used by commercial shredding services that cost hundreds of thousands of dollars and can shred millions of documents per hour. While the very smallest shredders may be hand-cranked, most shredders are electrically powered.\n\nShredders over time have added features to improve the shredder user's experience. Many now reject paper that is fed over capacity to avoid jams; others have safety features to reduce risks. Some shredders designed for use in shared workspaces or department copy rooms have noise reduction.\n\nLarger organisation or shredding services sometimes use \"mobile shredding trucks\", typically constructed as a box truck with an industrial-size paper shredder mounted inside and space for storage of the shredded materials. Such a unit may also offer the shredding of CDs, DVDs, hard drives, credit cards, and uniforms, among other things.\n\nA \"shredding kiosk\" is an automated retail machine (or kiosk) that allows public access to a commercial or industrial-capacity paper shredder. This is an alternative solution to the use of a personal or business paper shredder, where the public can use a faster and more powerful shredder, paying for each shredding event rather than purchasing shredding equipment.\n\nSome companies outsource their shredding to \"shredding services\". These companies either shred on-site, with mobile shredder trucks or have off-site shredding facilities. Documents that need to be destroyed are often placed in locked bins that are emptied periodically.\nAs well as size and capacity, shredders are classified according to the method they use; and the size and shape of the shreds they produce. \n\n\nThere are a number of standards covering the security levels of paper shredders, including:\n\nThe previous DIN 32757 standard has now been replaced with DIN 66399. This is complex, but can be summarized as below:\n\n\nThere have been many instances where it is alleged that documents have been improperly or illegally destroyed by shredding, including:\n\n\n\nIn theory shredded documents should not be able to be reassembled and read. In practice the feasibility of this depends on, (a) how well the shredding has been done, and (b) the resources put into reconstruction. The cost benefit analysis will depend on whether it is a simple personal matter, corporate espionage, a criminal matter - or if national security is at stake.\n\nFactors making reconstruction more likely include not only the cutting method, but also the orientation of the material when fed, and whether the shredded material is further randomized afterwards. Even without a full reconstruction, in some cases useful information can be obtained by forensic analysis of the paper, ink, and cutting method.\n\n\n\n\n\nThe individual shredder that was used to destroy a given document may be sometimes be of forensic interest. Shredders display certain device-specific characteristics, \"fingerprints\", like the exact spacing of the blades, the degree and pattern of their wear. By closely examining the shredded material, the minute variations of size of the paper strips and the microscopic marks on their edges may be able to be linked to a specific machine. (c.f. the forensic identification of typewriters.)\n\nThe resulting shredded paper can be recycled in a number of ways, including:\n\n"}
{"id": "18578250", "url": "https://en.wikipedia.org/wiki?curid=18578250", "title": "Parachute mine", "text": "Parachute mine\n\nA parachute mine is a naval mine dropped from an aircraft by parachute. They were mostly used in the Second World War by the Luftwaffe and initially by the Royal Air Force (RAF) Bomber Command.\nFrequently, they were dropped on land targets.\n\nThese mines were attached to parachutes to act as blast bombs; when detonated at roof level rather than on impact the aerodynamic effects of their blast were maximised. Instead of the shock waves from the explosion being cushioned by surrounding buildings, they could reach a wider area, with the potential to destroy a whole street of houses in a radius and windows being blown in up to a mile away.\n\nDuring the Second World War, the Luftwaffe used a number of different kinds of parachute mine. The Luftmine A (LMA) and Luftmine B (LMB) weighed and respectively. The LMA was in length and the LMB .\n\nAfter the parachute opened, the mine would descend at around . If it came down on land, a clockwork mechanism would detonate the mine 25 seconds after impact. If the mine landed in water it would sink to the bottom. If the depth was greater than , water pressure and the dissolving of a water–soluble plug would deactivate the clockwork time-detonator, and activate an anti-shipping detonator. These were initially magnetic detonators but later, acoustic or magnetic/acoustic detonators could be fitted.\n\nThe Luftwaffe began dropping mines in British waters in November 1939, using Heinkel He 115 seaplanes and Heinkel He 111 land–based bombers. They were first used against land targets on 16 September 1940 in the early stages of the Blitz. Clearance of these was carried out by the Royal Navy, which quickly despatched a team to London from HMS Vernon, while Army Bomb disposal staff were warned that it was extremely inadvisable to attempt to render them safe without Naval guidance.\n\nThe Luftwaffe also used the Bombenmine (BM 1000, Monika, or G Mine). This was fitted with a tail made from Bakelite which broke up on impact. It had a photoelectric cell beneath a cover which detonated the bomb if exposed to light to counteract the work of bomb disposal units.\n\nThe RAF initially used naval mines, but replaced them with purpose-made blockbuster bombs, which were produced in various sizes up to .\n\n\n"}
{"id": "22372421", "url": "https://en.wikipedia.org/wiki?curid=22372421", "title": "Paul E. Ceruzzi", "text": "Paul E. Ceruzzi\n\nPaul E. Ceruzzi (born 1949) is curator of Aerospace Electronics and Computing at the Smithsonian's National Air and Space Museum in Washington, D.C.\n\nCeruzzi received a BA from Yale University in 1970, and a PhD from the University of Kansas in 1981, both in American studies. Before joining the National Air and Space Museum, he was a Fulbright scholar in Hamburg, Germany, and taught History of Technology at Clemson University in Clemson, South Carolina. Ceruzzi is the author and co-author of several books on the history of computing and aerospace technology. He has curated or assisted in the mounting of several exhibitions at NASM, including: Beyond the Limits - Flight Enters the Computer Age, The Global Positioning System - A New Constellation, Space Race, How Things Fly and the James McDonnell Space Hangar of the Museum's Steven F. Udvar-Hazy Center, at Dulles Airport.\n\n\n"}
{"id": "16616387", "url": "https://en.wikipedia.org/wiki?curid=16616387", "title": "Personal navigation assistant", "text": "Personal navigation assistant\n\nA Personal Navigation Assistant (PNA) also known as Personal Navigation Device or Portable Navigation Device (PND) is a portable electronic product which combines a positioning capability (such as GPS) and navigation functions.\n\nSome PNA devices are PDAs with limited features and can be unlocked.\n\nThe earliest PNAs were hand-held GPS units (circa mid-1980s) which were capable of displaying the user's location on an electronic map. These units included simple navigation functions such as course-to-steer and course-made-good. This first generation of PNAs were used by the US military.\n\nAccording to the analyst firm Berg Insight, there were more than 150 million turn-by-turn navigation systems worldwide in mid-2009, including about 35 million factory installed and aftermarket in-dash navigation systems, over 90 million Personal Navigation Devices (PNDs) and an estimated 28 million navigation-enabled mobile handsets with GPS. \n\nThe term PNA has come into widespread use with the growing popularity of automobile navigation systems. Original PNAs provided users with a map layer, real-time-traffic, and a routing engine with audio/visual cues for turn-by-turn guidance. The latest generation of PNA have sophisticated navigation functions such as parking assistance and personalization engines that enhance the user experience. To reduce total cost of ownership and time to market, most modern PNA devices such as those made by Garmin Ltd., Mio Technology Ltd. or TomTom International BV. are running an off-the-shelf embedded operating system such as Windows CE or Embedded Linux on commodity hardware with OEM versions of popular PDA Navigation software packages such as TomTom Navigator, I-GO 2006, Netropa IntelliNav iGuidance, or Destinator. \n\nOther manufacturers such as Garmin and Magellan prefer to bundle their own software developed in-house. Because many of these devices use an embedded OS, many technically inclined users find it easy to modify PNAs to run third party software and use them for things other than navigation, such as a low-cost audio-video player or PDA replacement.\n\nGPS equipped mobile phones have now eclipsed the sale of dedicated GPS units. Nokia, Samsung Electronics, Motorola and other handset makers were predicted to sell 162 million GPS equipped phones in 2007, dwarfing the 20 million units Garmin and TomTom have forecast they will sell combined, according to iSuppli, a leading market researcher in California. The inclusion of Google Maps Navigation in Android devices such as Motorola Droid and Nokia's announcement of free Ovi Maps has led to many people using their smartphones instead of having a separate PNA for trip navigation.\n\n"}
{"id": "31483101", "url": "https://en.wikipedia.org/wiki?curid=31483101", "title": "Plumett AL-52", "text": "Plumett AL-52\n\nThe AL-52 is a compressed air launcher of British origin manufactured by Plumett Ltd. The AL-52 is capable of launching grappling hooks for the likes of special forces and line throwing.\n\n"}
{"id": "949492", "url": "https://en.wikipedia.org/wiki?curid=949492", "title": "Purfleet", "text": "Purfleet\n\nPurfleet is a town in the Thurrock unitary authority in Essex, England. It is contained between the A13 road to the north and the River Thames to the south and is within the easterly bounds of the M25 motorway but just outside the Greater London boundary. It was within the traditional Church of England parish of West Thurrock. There is some industry to the south and the area forms part of the Thames Gateway redevelopment area. Purfleet is one of seven conservation areas in Thurrock.\n\nIn the 18th century, Purfleet Royal Gunpowder Magazine was established as a location for the storage of gunpowder together with a garrison to protect it. There was a constant danger of explosion as a result of lightning strikes. Benjamin Franklin was asked for advice on the design of a lightning conductor and a committee of the Royal Society supported his design for pointed conductors. After the American Revolution the powder store was protected from lightning which hit the building, though metal drainpipes actually did the work. When King George III heard of this, he insisted they be replaced with blunt conductors and the president of the Royal Society was forced to resign.\n\nMagazine number 5, the only one remaining of the original five, is now the Purfleet Garrison Heritage and Military Centre and a Scheduled Ancient Monument. It is run by volunteers and contains a wide range of local and military memorabilia (including from RAF Hornchurch) and is open to the public on Thursdays, Sundays and bank holidays.\n\nJ.M.W. Turner (1775-1851) made sketches of Purfleet in 1805-08 mainly featuring the Powder Magazines. The sketches are collected in the River and Margate Sketchbook which are part of the Tate Britain collection and accepted as part of the Turner Bequest in 1856. \n\nOther surviving 18th century buildings include the proofing house (now used for community activities) and the gatehouse clock tower (described by English Heritage as forming \"an integral part of the finest ensemble in any of the Ordnance Yards, consistent with the high standards practised by the Ordnance Board in its designs for fortifications and barracks from the C17\").\n\nIn his history of Essex (1848) W. White describes Purfleet as having 704 inhabitants including 199 from the barracks. \"Purfleet is a village and military station...at the mouth of a rivulet, and at the west end of West Thurrock ...sometimes called a township...and has a pleasure fair on the 13th of June. Near it are the extensive limeade chalk pits of W.H.Whitbread, the lord of the manor. The harbour is often full of shipping business and animation: and joining it is a large government powder magazine, consisting of five detached bomb-proof and well-protected store-houses, barracks for a company of artillery, a store keeper's mansion, and a good quay. The magazine was built in 1781,and has room for the safe keeping of 60,000 barrels of gunpowder.\" \n\nIn March 1916, anti-aircraft gunners based at Purfleet shot down the German Zeppelin LZ15 – a first. As a result, the gunners received a prize from the Lord Mayor of London.\n\nFrom 1921 to 1936, Purfleet formed an urban district of Essex including the parishes of Aveley, West Thurrock and South Ockendon. It covered an area of and in 1931 had a population of 8,511. The parishes and urban district were abolished in 1936 and their former area was used to form part of Thurrock Urban District.\n\nReflecting a strong port and storage history, Purfleet was listed by the Ministry of Food as one of 14 sensitive A-bomb targets in 1955, including for the supply of tea.\n\nIn Bram Stoker's novel, Count Dracula had an estate here.\n\nIn 2006 Thurrock Thames Gateway Development Corporation initiated a project to regenerate High House Purfleet by renovating historic farm buildings dating back to the 16th century and encouraging the development of some creative industries buildings on the 14-acre site.\nThe Royal Opera House's Bob and Tamar Manoukian scene-making facility for its operas and ballets opened on the High House site in December 2010 followed by a Costume Centre in 2015. Creative & Cultural Skills opened The Backstage Centre at the park in March 2013. The Backstage Centre now houses the national headquarters of Creative & Cultural Skills. In July 2013 ACME Studios, opened 43 artist studios in the park.\n\nPurfleet has been the site of a Unilever (formerly Van den Berghs & Jurgens) works producing Stork, Flora, Bertolli, and ICBINB! margarine since 1917, reputed to be the largest in the world. It is also the location of an Esso lubricants plant, a ro-ro ferry terminal, and the head office of Carpetright, the UK's largest flooring company. It is also home to Scania GB Ltd's largest European workshop/office.\n\n\nThere are transport links to towns such as Basildon and Grays, as well as Lakeside Shopping Centre with buses operated by Imperial Buses, Ensignbus and Arriva Southern Counties. Railway services operated by c2c from Purfleet station offer frequent services to London Fenchurch Street, Barking, Grays, Tilbury and Southend.\n\nIt is also one of the ends of the London LOOP long distance footpath.\n\nThurrock F.C. (formerly Purfleet F.C.) play in the town and the local council assist in seven leisure centres and one country club in the Borough, the nearest centre being in Springhouse Road, Corringham.\n\n"}
{"id": "49599909", "url": "https://en.wikipedia.org/wiki?curid=49599909", "title": "RiverSync", "text": "RiverSync\n\nRiverSync is a Thai corporation headquartered in Bangkok, Thailand. RiverSync sells converged micro data center, modular data center, and physical infrastructure equipment that enable businesses to rapidly deploy their computing infrastructure with prefabricated environment. RiverSync target markets including large companies and small and medium-sized businesses across various markets.\n\nRiverSync has around 200 employees, competing against Schneider, Rittal, Emerson, and Panduit.\n\nRiverSync, founded in 2012 by Sarin Na Wangkanai, Vitool Songwattana, and Veerayuth Punnium, introduced its micro data center product in 2015 and continued with the development of rack enclosure.\n\nRiverSync sells products and services designed to allow IT departments to rapidly deploy their computing.\nThe terms has use to describe the concept of converged infrastructure in box where compute cooling, power supply, power backup, monitoring, and management are all converged into a single enclosure that is prefabricated from the manufacture for rapid deployment to the client location.\n\n"}
{"id": "1183515", "url": "https://en.wikipedia.org/wiki?curid=1183515", "title": "Scratch drive actuator", "text": "Scratch drive actuator\n\nA scratch drive actuator (SDA) is a microelectromechanical system device that converts electrical energy into one-dimensional motion.\n\nThe actuator component can come in many shapes and sizes, depending on the fabrication method used. It can be visualised as an 'L'. The smaller end is called the 'bushing'.\n\nThe actuator sits on top of a substrate that has a thin insulating dielectric layer on top. A voltage is applied between the actuator and the substrate, and the resulting potential pulls the body of the actuator downwards. When this occurs, the brush is pushed forwards by a small amount, and energy is stored in the strained actuator. When the voltage is removed, the actuator springs back into shape while the bushing remains in its new position. By applying a pulsed voltage, the SDA can be made to move forward.\n\nThe voltage is usually applied to the actuator by means of a 'tether'. This can consist of a rigid connector or a rail which the SDA follows.\n\nThe size of an SDA is typically measured on the μm scale.\n"}
{"id": "35807955", "url": "https://en.wikipedia.org/wiki?curid=35807955", "title": "Spårvägsmuseet", "text": "Spårvägsmuseet\n\nThe Spårvägsmuseet, or Tramway Museum, was located at Tegelviksgatan 22 in Södermalm, Stockholm. In the museum there was also a café, a library, an archive and another museum called \"Leksaksmuseet\" (\"Toy Museum\"). It was owned by Storstockholms Lokaltrafik. It showed vehicles and the development of the public transport at Stockholm from the 19th century until present.\n\nThe museum closed to the public in September 2017 and will open again in early 2020 in a new premises (Norra Djurgårdsstaden).\n\nThe tramway chief started collecting things in about 1900, when there were horse trams. There was an internal museum at the headquarters of the company at Tegnérgatan. (You can read about this in a newspaper article from 1922.)\n\nIn 1944 the museum was publicly opened on Tulegatan close to the old tram depot. In 1964 the museum was moved to Odenplan, but the museum was small and it was impossible to show many vehicles. In 1990 it moved to its location Tegelviksgatan 22.\n\n"}
{"id": "1291728", "url": "https://en.wikipedia.org/wiki?curid=1291728", "title": "TCL Corporation", "text": "TCL Corporation\n\nTCL Corporation () (originally an abbreviation for Telephone Communication Limited) is a Chinese multinational electronics company headquartered in Huizhou, Guangdong Province. It designs, develops, manufactures and sells products including television sets, mobile phones, air conditioners, washing machines, refrigerators and small electrical appliances. In 2010 it was the world's 25th-largest consumer electronics producer. Since 2015, it remains the third-largest television manufacturer by market share.\n\nTCL comprises four listed companies: TCL Corporation which is listed on the Shenzhen Stock Exchange, and TCL Multimedia Technology Holdings, Ltd. (), TCL Communication Technology Holdings, Ltd.(former code ; delisted in 2016), TCL Display Technology () and Tonly Electronics () which are listed on the Hong Kong Stock Exchange.\n\nTCL's corporate slogan is \"The Creative Life\".\n\nThe company was founded in 1981 under the brand name TTK as a cassette manufacturer, making knock-off TDK cassettes. In 1985, after being sued by TDK for intellectual property violation, the company changed its brand name to TCL by taking the initials from \"T\"elephone \"C\"ommunication \"L\"imited. It began manufacturing consumer electronics for the Chinese market during the 1980s, and began to sell overseas in the 2000s. Though a state-owned enterprise, TCL was established as a joint venture with several Hong Kong-based investors. \nIn July 2003, TCL chairman Li Dongsheng formally announced a \"Dragon and Tiger Plan\" to establish two competitive TCL businesses in global markets (\"Dragons\") and three leading businesses inside China (\"Tigers\").\n\nIn November 2003, TCL and Thomson SA of France announced the creation of a joint venture to produce televisions and DVD players worldwide. TCL took a 67 percent stake in the joint venture, with Thomson SA holding the rest of the shares, and it was agreed that televisions made by TCL-Thomson would be marketed under the TCL brand in Asia and the Thomson and RCA brands in Europe and North America.\n\nIn April 2004, TCL and Alcatel announced the creation of a mobile phone manufacturing joint venture: Alcatel Mobile Phones. TCL injected 55 million euros in the venture in return for a 55 per cent shareholding.\n\nIn May 2005, TCL announced that its Hong Kong-listed unit would acquire Alcatel's 45 per cent stake in their mobile-phone joint venture for consideration of HK$63.34 million ($8.1 million) worth of TCL Communication shares.\n\nIn June 2007, TCL announced that its mobile phone division planned to cease using the Alcatel brand and switch entirely to the TCL brand within five years.\n\nIn April 2008, Samsung Electronics announced that it would be outsourcing the production of some LCD TV modules to TCL.\n\nIn July 2008, TCL announced that it planned to raise 1.7 billion yuan ($249 million) via a share placement on the Shenzhen Stock Exchange to fund the construction of two production lines for LCD televisions; one for screens of up to 42 inches, and the other for screens of up to 56 inches. TCL sold a total of 4.18 million LCD TV sets in 2008, more than triple the number during 2007.\n\nIn January 2009, TCL announced plans to double its LCD TV production capacity to 10 million units by the end of 2009.\n\nIn November 2009, TCL announced that it had formed a joint-venture with the Shenzhen government to construct an 8.5-generation thin film transistor-liquid crystal display production facility in the city at a cost of $3.9 billion.\n\nIn March 2010, TCL Multimedia raised HK$525 million through the sale of shares on the Hong Kong Stock Exchange, in order to fund the development of its LCD and LED businesses and to generate working capital.\n\nIn May 2011, TCL launched the China Smart Multimedia Terminal Technology Association in partnership with Hisense Electric Co. and Sichuan Changhong Electric Co., with the aim of helping to establish industry standards for smart televisions.\n\nIn January 2013, TCL bought the naming rights for Grauman's Chinese Theatre for $5 million.\nIn 2014, TCL changed the meaning of its identifying initials from \"Telephone Communication Limited\" to a branding slogan, \"The Creative Life\", for commercial purposes.\n\nIn February 2014, TCL spent 280 million RMB to purchase 11% shareholdings of Tianjin 712 Communication & Broadcasting Co., Ltd, a Chinese military-owned company which produces communication devices and navigation systems for the Chinese army.\n\nIn August 2014, TCL Corporation was implicated in bribing a government official in Guangdong province in exchange for government subsidies. \nIn October 2014, TCL acquired the Palm brand from HP for use on smartphones.\n\nIn 2016, TCL reached an agreement with BlackBerry Limited to produce smartphones under the BlackBerry brand, under BlackBerry Mobile.\n\nTCL is organized into five business divisions:\n\n\nIn addition it has four affiliated business areas:\n\n\nTCL has operations in more than 80 cities across Africa, Asia, Australasia, Europe, North America and South America. It has 18 R&D centers, 20 major manufacturing facilities and over 40 sales offices worldwide.\n\nTCL Corporation also has its own research facility called TCL Corporate Research, which is located at Shenzhen, China with the objective to research cutting-edge technology innovations for other subsidiaries.\n\nTCL's primary products are TVs, DVD players, air conditioners, mobile phones, home appliances, electric lighting, and digital media.\n\nIt primarily sells its products under the following brand names:\n\nThe company, as of April 2012, is in venture with Swedish furniture giant IKEA to provide the consumer electronics behind the Uppleva integrated HDTV and entertainment system product.\n\nIn 2016, it contract manufactured the DTEK50 and DTEK60, for BlackBerry Limited, under their flagship BlackBerry brand. In December 2016, it became a licensee of the BlackBerry brand, to manufacture, distribute, and design devices for the global market. As of 2017, it distributes BlackBerry devices under the name of BlackBerry Mobile.\n\nTCL is also the owner of the Palm brand.\n\nSince 2015, TCL offers its own video streaming service: GoLive TV or simply \"GoLive\".\n\n"}
{"id": "2720716", "url": "https://en.wikipedia.org/wiki?curid=2720716", "title": "Team OS/2", "text": "Team OS/2\n\nTeam OS/2 was an advocacy group formed to promote IBM's OS/2 operating system. Originally internal to IBM with no formal IBM support, Team OS/2 successfully converted to a grassroots movement formally supported (but not directed) by IBM - consisting of well over ten thousand OS/2 enthusiasts both within and without IBM. It is one of the earliest examples of both an online viral phenomenon and a cause attracting supporters primarily through online communications.\n\nThe decline of Team OS/2 largely coincided with IBM's abandonment of OS/2 and the coinciding attacks orchestrated by Microsoft on OS/2, Team OS/2, and IBM's early attempts at online evangelism.\n\nTeam OS/2 was a significant factor in the spread and acceptance of OS/2. Formed in February 1992, Team OS/2 began when IBM employee Dave Whittle, recently appointed by IBM to evangelize OS/2 online, formed an internal IBM discussion group titled TEAMOS2 FORUM on IBM's worldwide network, which at the time, served more individuals than did the more academic Internet. \n\nThe forum header stated that its purpose was \nThe forum went viral as increasing numbers of IBMers worldwide began to contribute a wide variety of ideas as to how IBM could effectively compete with Microsoft to establish OS/2 as the industry standard desktop operating system. Within a short time, thousands of IBM employees had added the words TEAMOS2 to their internet phone directory listing, which enabled anyone within IBM to find like-minded OS/2 enthusiasts within the company and work together to overcome the challenges posed by IBM's size, insularity, and top-down marketing style. TEAMOS2 FORUM quickly caught the attention of some IBM executives, including Lee Reiswig and Lucy Baney, who after initial scepticism, offered moral and financial support for Whittle's grass roots and online marketing efforts. IBM's official program for generating word-of-mouth enthusiasm was called the \"OS/2 Ambassador Program\", where OS/2 enthusiasts company-wide could win Gold, Silver, and Bronze Ambassador pins and corporate recognition with various levels of structured achievement. Both the OS/2 Ambassador Program and Team OS/2 were effective in evangelizing OS/2 within IBM, but only Team OS/2 was effective in generating support for the promotion of OS/2 outside of IBM.\n\nWhittle began to extend the Team OS/2 effort outside of IBM with various posts on CompuServe, Prodigy, bulletin boards, newsgroups, and other venues. He also made a proposal to IBM executives, which they eventually implemented when IBM Personal Software Products moved to Austin, Texas, that they form a \"Grass Roots Marketing Department\".\n\nTeam OS/2 went external that spring, when the first Team OS/2 Party was held in Chicago. The IBM Marketing Office in Chicago created a huge banner visible from the streets. Microsoft reacted when Steve Ballmer roamed the floor with an application on diskette that had been specially programmed to crash OS/2; and OS/2 enthusiasts gathered for an evening of excitement at the first Team OS/2 party. Tickets were limited to those who had requested them on one of the online discussion groups. Attendees were asked to nominate their favorite \"Teamer\" for the \"Team OS/2 Hall of Fame\", and those whose names were drawn came forward to tell the story of their nominee - what sacrifice they had made to promote OS/2 and why they were deserving of recognition. Prizes included limousine rides that evening. At the end, all attendees received the first TEAM OS/2 T-shirt, which includes the first Team OS/2 logo on the front and the distinctive IBM blue-stripe logo on the back - except with lower-case letters: \"ibm/2\" to represent the new IBM. Even the lead singer in the band Chicago that had provided music for the event asked if they could have a T-shirt for each member of the band. One IBM executive in attendance said it was the first IBM event that had given him goosebumps.\n\nAfter that, word about the Team OS/2 phenomenon spread even more quickly, both within IBM and without. OS/2 enthusiasts spread the word to computer user groups across the United States, then eventually worldwide, independently of IBM marketing efforts. Whittle established multiple localized forums within IBM, such as TEAMNY, TEAMDC, TEAMFL, TEAMTX, and TEAMCA, which attracted new supporters and enabled enthusiastic followers to share ideas and success stories, plan events, and creatively apply what they were learning from one another.\n\nThe \"Teamer Invasion\" of COMDEX in the Fall of 1993 was perhaps the high water mark for Team OS/2. COMDEX was, at that time, the most important computer and electronics trade show, held in Las Vegas. Wearing the salmon-colored shirts which were to become associated with Team OS/2, the group's members, led by Doug Azzarito, Keith Wood, Mike Kogan, IBM User Group Manager Gene Barlow, and others wandered the convention floors, promoting OS/2 and providing demo discs to vendors and offering to install the distributed version of OS/2 on display computers. Many Team OS/2 volunteers had traveled to the convention on their own, including some from overseas; so their independence and grass-roots enthusiasm attracted significant attention in the media and amongst exhibitors.\n\nWhat little funding IBM provided went to provide the shirts, \"trinkets and trash\", and an onsite headquarters for Teamers to coordinate their efforts and collect items to give to vendors. IBM had established the Grass Roots Marketing department proposed earlier, and had even tapped Vicci Conway and Janet Gobeille to provide support and guidance for Team OS/2 with Whittle voluntarily stepping aside from his previous day-to-day focus on supporting and monitoring Team OS/2 activities. Janet was nicknamed \"Team Godmother\", but everyone in IBM, especially Whittle, was wary of trying to direct volunteers or make Team OS/2 too structured or formal, in order to avoid \"breaking something that works\".\n\nAccording to the Team OS/2 Frequently Asked Questions document, Team OS/2 at one point had a presence (sponsoring members willing to publish their e-mail addresses as points of contact) in Argentina, Australia, Austria, Belgium, Canada, Denmark, Germany, Ireland, Japan, Latvia, the Netherlands, Portugal, Singapore, South Africa, Spain, Sweden, Switzerland, and the United Kingdom; as well as online on America Online, CompuServe, Delphi, FidoNet, Genie, the Internet/Usenet/mail servers, Prodigy, and WWIVNet.\n\nIn an article analyzing Team OS/2 and its meaning and context, Robert L. Scheier listed several of the factors the led to the success of the group. These included the creation of a strong group identity with a powerful name, corporate support without corporate direction, the ability of volunteer members to do things that companies couldn't do, keeping it \"loose\" and relatively unstructured, providing lots of smaller material rewards without compensation, and listening to team members as if they were the \"eyes and ears of the public.\"\n\nHowever, Team OS/2's very lack of structure left it vulnerable. Various journalists have documented a \"dirty tricks\" campaign by Microsoft. Online, numerous individuals (nicknamed \"Microsoft Munchkins\" by John C. Dvorak) used pseudonyms to attack OS/2 and manipulate online discussions. Whittle was the target of a widespread online character assassination campaign.\n\nSome journalists who were less than enthusiastic about OS/2 received death threats and other nasty emails from numerous sources, identified in taglines as \"Team OS/2\" without a name. Whether this attack pattern was part of Microsoft's efforts or from Team OS/2, the identity was never proven. Ultimately, at least some of Microsoft's efforts were exposed on Will Zachmann's Canopus forum on CompuServe, where the owner of one particular account, ostensibly belonging to \"Steve Barkto\", (who had been attacking OS/2, David Barnes, Whittle, and other OS/2 fans) was discovered to be funded by the credit card of Rick Segal, a high-level Microsoft employee and evangelist, who had also been active in the forums. James Fallows, a nationally renowned journalist, weighed in to state that the stylistic fingerprint found in the Barkto posts were almost certainly a match with the stylistic fingerprints in the Microsoft evangelist's postings.\nWill Zachmann sent an open letter to Steve Ballmer, futilely demanding a public investigation into the business practices of the publicly traded Microsoft.\n\nAt the height of the marketing effort, Team OS/2 consisted of more than ten thousand known members, and countless undocumented members. IBM acknowledged publicly that without Team OS/2, there might not have been a fourth generation (\"Warp 4\") of the operating system. However, the IBM Marketing Director over the Grass Roots Marketing Department made the decision to meet his headcount cut targets by eliminating the entire department - one week before the 1995 Fall Comdex. Microsoft executives were said to be positively gleeful and Team OS/2 members worldwide were said to be incredulous.\n\nWithin months, Whittle and Barlow had left IBM, Conway and Gobeille were reassigned within IBM, and Teamers were crushed by IBM's announcement that the marketing of individual desktop versions would come to a close. Most Team members eventually migrated away from OS/2 to Linux, which offered the power and stability which they had come to expect from OS/2, and where much of what was learned with Team OS/2 inspired at least some in the Linux and Open Source movements.\n\nMicrosoft attempted to fabricate \"Team NT\" for COMDEX Fall 1995, but this was widely ridiculed as a blatant attempt at impersonation. \"Team NT\" members were Microsoft employees, and called \"Team Nice Try\" by industry pundits such as \"Spencer F. Katt\" (a pen name with various contributors, such as Paul Connolly), in PCWeek Magazine.\n\nWhen Microsoft was readying the first version of Windows NT (designated \"Version 3.1\") in 1993, a Texas computer user group (HAL-PC) invited IBM and Microsoft to a public \"shootout\" between the two operating systems. Videotape of the two demonstrations was later distributed by IBM and Team OS/2 members. Compared to the dynamic presentation given by David Barnes as he put OS/2 through its paces, the Microsoft presenter and NT showed so poorly that Microsoft demanded that all portions of the NT presentation be cut out of the videotapes which IBM was distributing of the event. This resulted in issuance of an edited version of the tape, but hundreds of original (complete) copies had already been released. The uncut version of the \"OS/2 - NT Shootout\" tape have been dubbed the \"OS/2 - NT Shootdown\" or \"The Shootdown of Flight 31\". The tape has been used to train professional software and hardware presenters who might face user groups.\n"}
{"id": "19964363", "url": "https://en.wikipedia.org/wiki?curid=19964363", "title": "Total system power", "text": "Total system power\n\nTotal system power is a term often used in audio electronics to rate the power of an audio system. Total system power refers to the total power consumption of the unit, rather than the power handling of the speakers or the power output of the amplifier. This can be viewed as a somewhat deceptive marketing ploy, as the total power consumption of the unit will of course be greater than any of its other power ratings, except for, perhaps, the peak power of the amplifier, which is essentially an exaggerated value anyway. Shelf stereos and surround sound receivers are often rated using total system power.\n\nOne way to use total system power to get a more accurate estimate of power is to consider the amplifier class which would give an educated guess of the power output by considering the efficiency of the class. For example, class AB amplifiers are around 25 or 50% efficiency while Class D amps are much higher; around 80% or more efficiency. A very exceptional efficiency for a specific Class D amp, the ROHM BD5421efs, operates at 90% efficiency. \n\nIn some cases, an audio device may be measured by the \"total system power\" of all its loudspeakers by adding all their peak power ratings. Many home theater in a box systems are rated this way. Often low-end home theater systems' power ratings are taken at a high level of harmonic distortion as well; as high as 10%, which would be painfully noticeable. \n"}
{"id": "1844689", "url": "https://en.wikipedia.org/wiki?curid=1844689", "title": "Victoria Drummond", "text": "Victoria Drummond\n\nVictoria Alexandrina Drummond MBE (1894–1978), was the first woman marine engineer in Britain and first woman member of Institute of Marine Engineers. In World War II she served at sea as an engineering officer in the British Merchant Navy and received awards for bravery under enemy fire.\n\nVictoria Drummond was born on 14 October 1894 at Errol, Perthshire, Scotland. Her father was Captain Malcolm Drummond of Megginch, Groom in Waiting to Queen Victoria and Deputy Lieutenant of Perthshire. Her mother, Geraldine Margaret Tyssen-Amherst was the daughter of William Tyssen-Amherst, 1st Baron Amherst of Hackney.\n\nShe had two sisters, Jean and Frances, and a younger brother, John Drummond, 15th Baron Strange. She was baptised Victoria after Queen Victoria, who was one of her godmothers. Drummond and her siblings were brought up in both the Church of Scotland and the Scottish Episcopal Church. All four worked as children: growing vegetables and flowers to sell and keeping poultry. Drummond's speciality was hand-churning butter. Their privileged upbringing was straitened after one pair of grandparents lost a fortune in investments in 1906.\n\nOne of Drummond's grandmothers turned wood and ivory and belonged to the Worshipful Company of Turners. Drummond herself became a prizewinning model maker, making her own toys that were shown in exhibitions and won prizes in competitions.\n\nDrummond used to visit the engineering works of Robert Morton and Sons in Errol, which built steam-powered and petrol-engined lorries and buses. As a young girl she asked Mr Morton how she could learn to be a marine engineer and go to sea. Morton may or may not have taken the young girl seriously, but he told her to serve an apprenticeship, find a shop with a vacancy and start at the beginning, serve her time and then find a ship that would give her a berth as an engineer.\n\nIn February 1913 Drummond's parents took her to London where she was presented at court to King George V and Queen Mary as a Debutante.\n\nIn 1915 Drummond turned 21 and her father encouraged her to choose her own career. She repeated her ambition to be a marine engineer. From 18 October 1916 she was apprenticed at the Northern Garage, South Street, Perth. Her wage as a first year apprentice was three shillings a week, from which sixpence was deducted for National Insurance so her net wage was half a crown. In her second year her wage before National Insurance was six shillings. Her foreman, a Mr Malcolm, who had worked in Clyde shipyards, gone to sea and risen to be a Chief Engineer at sea, supported her training. On three evenings a week a teacher from Dundee Technical College (now Abertay University) taught her maths and engineering.\n\nMr Malcolm supported Drummond's training but in 1918 the garage dismissed him for drunkenness. Drummond took this as the right time to move on and resigned from the garage. Her father got her an introduction to the Caledon Shipbuilding & Engineering Company in Dundee, which took her on in its engine and boiler works at Lilybank in Dundee. She started as a pattern maker for metal casting, and in 1919 was promoted to the finishing shop. She completed her apprenticeship in 1920 and stayed on at Caledon as a journeyman, later transferring to the drawing office. In 1922 Caledon suffered a decline in orders and laid off many workers, including Drummond who left on 7 July.\n\nEarly in Drummond's time at Caledon, the founder W.B. Thompson introduced her and her parents to Henry Wortley, a director of Blue Funnel Line. Wortley offered Drummond the promise of a position as an engineer at sea when she completed her apprenticeship. When Caledon gave her notice in 1922, Drummond wrote to Wortley to take up his offer. Unknown to Drummond, Wortley had died in 1919. However, Lawrence Holt honoured Wortley's promise and invited her to Liverpool for an interview.\n\nBlue Funnel employed Drummond initially in its engineering record office in Liverpool on a salary of £12 a month. About a month later, on 25 August, she was instructed to sign on the passenger liner for a trial trip from Liverpool to Glasgow as an Assistant Engineer. On 2 September she signed on \"Anchises\" again as Tenth Engineer. The salary of £10 a month was £2 less than the company had paid her ashore! She served on the ship until 1924, making four voyages to Australia and one to China.\n\nOn \"Anchises\" all the crew, all but one of the officers and most of the passengers accepted having a woman engineer. A few of the women passengers passed demeaning remarks at her. When \"Anchises\" usual Second Engineer was taken ill his position was covered by an extra Second, Mr Howard, who Drummond says \"persecuted\" her. Drummond was friends with the usual Second Engineer, Malcolm Quayle, who supported her career, was her escort for social events ashore and whom she called her \"protector\". The pair had prickly tempers, for which Drummond nicknamed Quayle \"hedgehog\" and he nicknamed her \"Kate\", after Katherina in William Shakespeare's \"The Taming of the Shrew\". Quayle was married and had two children, and Drummond was emphatic that there was never any impropriety between them. However, when in 1924 she wanted to take her exams to become a Second Engineer, she unwisely wrote to her manager at Blue Funnel, Mr Freeman, suggesting that Quayle be promoted to Chief Engineer and she could be his Second. This gave Freeman the damaging impression that Quayle and Drummond were having an affair. Drummond left \"Anchises\" and Blue Funnel in April 1924.\n\nDrummond began study for her Second Engineer's qualification. However, after qualifying, she was able to find work only as a Fifth Engineer, signing on the British-India Steam Navigation Company steam turbine liner on 14 April 1927. She served on the ship until 4 December 1928, completing one voyage to East Africa and four to India and Ceylon.\n\nAboard \"Mulbera\" Drummond was again accepted by nearly all the ship's company. The exception was the Second Engineer, Mr Lamb, who on Drummond's first day aboard told her that he didn't want her there. Drummond said Lamb often shouted at her, occasionally swore at her and thus wore her down. Drummond privately nicknamed Lamb the Tiger Cat or just \"The Tiger\". On occasion she also encountered passengers who initially did not believe a woman could be a marine engineer. Drummond won them round by competently doing her job.\n\nIn port in Aden on 11 May 1928 Drummond received an air mail letter telling her that aboard her former ship \"Anchises\" on 13 April her friend Malcolm Quayle had died. The letter gave no details of what had happened and she found out none until some time thereafter.\n\nFrom about 1919 Drummond's sister Jean ran the Queen Victoria Girl's Club at 122 Kennington Road, Lambeth, south London: a job that included a flat at the top of the building. From 1929 Victoria and Frances leased a house almost opposite at 143 Kennington Road, which they named The Studio. Frances worked as a commercial artist and she and Victoria also developed a business, the Golden Fisheries, trading goldfish that they kept in their garden pond and in tanks in the house.\n\nFrom October 1929 Drummond repeatedly sat the Board of Trade examination for Chief Engineer, but every time the examiners failed her. Mr Martin at Dundee continued to support her and eventually in 1936 tackled the examiners, who privately admitted to him that they always failed her because she was a woman. Indeed, to prevent any accusations of unfairness, the Board of Trade Examiners habitually failed all candidates who sat the examinations with her.\n\nFrom 1935 Frances and Victoria's business took them abroad to trade fairs in Leipzig, Prague and Vienna. In March 1938 when German forces occupied Austria in the Anschluss, the two sisters were at a trade fair in Vienna. Drummond photographed Hitler in his motorcade and later described that time in Vienna as very tense, chaotic and dangerous.\n\nIn 1939 war seemed to grow inevitable so Drummond applied to return to sea as a Second Engineer. Despite her good service on liners of two of the most prestigious companies in the Merchant Navy, and glowing references from numerous superior officers, all her many applications were declined. Therefore, on the eve of World War II she joined Jean and Frances enlisting as Air raid wardens in Lambeth, London.\n\nDrummond then tried visiting the Royal Docks in the hope of finding a ship that would take her on. Eventually on such a visit a donkeyman, who had served with her on \"Mulbera\" 12 years earlier, recognised Drummond in a café. He and his shipmates advised her that if no British company would take her she should try for a berth on a foreign ship. They introduced her to a representative of Palestine Maritime Lloyd, owned by a group of Jewish businessmen based in Haifa, Palestine. He was sceptical of signing a woman engineer until he saw her papers. Palestine Maritime Lloyd operated mostly coasters of to , but had also one small deep-sea cargo and passenger ship, the (Mount Zion), that which could carry both cargo and 110 passengers. \"Har Zion\" needed a new Second Engineer so he immediately offered Drummond a berth at a salary of £41 10s.\n\n\"Har Zion\" was registered at Famagusta in the British Protectorate of Cyprus. Her officers and crew were a mixture of Arab, Czech, Egyptian, German, Hungarian, Russian, Spanish, and the ship's dog was Polish. She was built in 1907 and by 1940 was in poor condition. Drummond mastered disciplinary problems among the engine room crew and then in drydock in Antwerp completed enough furnace and boiler repairs for \"Har Zion\" to pass its Lloyd's Certificate inspection.\n\nIn Antwerp \"Har Zion\" took on a Greek Third Engineer who clashed with Drummond. The ship worked to Beirut, Haifa and back, and on its return trip evacuated the British Consul and part of the British Expeditionary Force from Marseille to Gibraltar. When the ship returned to London in July 1940 Drummond left to get away from the Third Engineer. About a month later, in August 1940, \"Har Zion\" was sunk in the Western Approaches by the , with the loss of 36 of the 37 people aboard.\n\nIn August 1940 a Panamanian company, \"Compañía Arena Limitada\", gave Drummond a berth on its cargo ship at a salary of £46 10s — £5 a month more than on \"Har Zion\". Drummond joined her at Fowey in Cornwall where the ship loaded china clay for the USA. Being a neutral ship she was not offered the protection of a place in a convoy.\n\nOn the morning of Sunday 25 August 1940 \"Bonita\" was in the North Atlantic about from land when \"Luftwaffe\" Focke-Wulf Fw 200 Condor aircraft attacked. Drummond was on watch and immediately ordered the fireman and greaser to join her on the starting platform ready in case they needed to escape. Near misses from bombs blew all the lagging off the pipes in the engine room and split the main water service pipe feeding the boilers. Fuel oil started leaking from somewhere, hitting Drummond in the face and closing one of her eyes. She ordered her fireman and greaser to open the fuel injectors and main steam throttle to increase speed and then get out of the engine room in case they needed to abandon ship.\n\nDrummond remained alone at her post. \"Bonita\" had never before exceeded but in 10 minutes Drummond somehow increased speed to . The Master, a Captain Herz from Hungary, used the extra speed to change course sharply and avoid being hit whenever a Condor bombed the ship. The bombs were heavy enough to lift \"Bonita\" in the water and cause damage even by near misses. The ship was hit by both and machine-gun fire. Drummond says 25 bombs were dropped; this suggests that six or seven aircraft took part in the attack, which continued for 30–35 minutes. \"Bonita\" continued her crossing without further incident and reached Norfolk, Virginia on 8 September. There Drummond received news that The Studio at 143 Kennington Road had been bombed but Frances and Jean were safe.\nAboard \"Bonita\" Drummond formed a close friendship with another married man, the First Mate Mr Warner. In a published account of her conduct in the air raid, Warner described Drummond as \"about the most courageous woman I ever saw\". Newspapers in Norfolk, VA quoted Captain Herz commending Drummond as \"\"one of the most competent engineers ever employed on this vessel\".\n\nIn Norfolk, Drummond made friends with a Virginian woman, Mrs Julia Davies, who was engaged in charitable work collecting goods to send to Britain that were in short supply because of the War. Davies engaged Drummond as a speaker at charitable events, and in return directed to Lambeth much of the goods that her charitable network was collecting.\nAt Norfolk \"Bonita\" discharged her china clay and loaded scrap iron. The ship made her return crossing \"via\" Halifax, Nova Scotia, where she joined an eastbound convoy. The oil-burning ship was unable to stop making black smoke, which made her dangerously conspicuous. When the third or fourth engineer were on watch the ship lost speed and fell behind the convoy. Whenever Drummond was on watch the ship managed to increase speed and regain her station.\n\nBy Christmas 1941 Drummond's sisters Jean and Frances were preparing to move into a flat in Restormel House, Chester Way, Kennington.\n\nBy 1941 Drummond had qualified as a Panamanian chief engineer. These examinations were a purely written paper, with the gender or status of the candidate not being known to the examiners. By then the Board of Trade had failed her for Chief Engineer 31 times. Due to the needs of war the Board of Trade was now granting Chief Engineer certificates to experienced Second Engineers on the sole basis of an oral examination. However, when Drummond requested this dispensation the Board refused. Because of the dangers of war, the Board patronisingly suggested that Drummond take a shore job as an instructor. Drummond replied firmly that numerous Chief and other engineers with whom she had served had lacked the nerve to cope while under enemy attack, and therefore the best service she could give was as a Chief Engineer at sea.\n\nIn about April 1941, Drummond learnt that Mrs Davies in Virginia had raised £400 toward the provision of a \"Victoria A. Drummond Ambulance\" for the people of Lambeth. In raising funds Davies and a Mrs Leitch had even enlisted the poet Robert Frost to give a public reading of his works. However, what Lambeth needed more was a British Restaurant for people who had been bombed out of their homes. Accordingly, the \"Victoria A. Drummond Canteen\" was opened in Westminster Bridge Road near Lambeth North tube station. The canteen served hot meals for sixpence a head and remained open for the remainder of the war.\n\nFor her courage aboard \"Bonita\" Drummond was awarded the MBE and the Lloyd's War Medal for Bravery at Sea in July 1941. Her MBE was presented by George VI.\n\nIn February 1941 Warner and Drummond signed on as Captain and Second Engineer of an old Panamanian steamship, . The ship was in Lisbon so a skeleton crew including Warner and Drummond sailed out to join her on Yeoward Brothers' passenger liner . They sailed \"Czikos\" to Gibraltar, where they joined a convoy bound for the Firth of Clyde. About northwest of Ireland a \"Luftwaffe\" Fw 200 Condor attacked \"Czikos\". As with \"Bonita\", none of the bombs hit but the near misses damaged the ship. The Condor also machine-gunned the ship, killing a quartermaster at the helm and wounding two other crewmen.\n\nIn April 1942 Drummond joined Manchester Liners' in Liverpool as Fifth Engineer. The ship was unkempt and filthy, including the galley, the food was ill-served and the Master, Captain Davis, seemed permanently drunk. Nevertheless, \"Manchester Port\" was made Commodore Ship for convoy ON 89 to North America. The ship survived the crossing and on 17 May loaded dynamite at Trois-Rivières, Quebec. On 20 May the ship reached Halifax to join an eastbound convoy. Drummond reported Davis for drunkenness and on 21 May he was removed under police escort, replaced by a Captain Middleton. \"Manchester Port\" joined convoy HX 191, which left Halifax on 24 May and reached Liverpool on 6 June. The ship discharged her explosive cargo in Manchester and Drummond returned to her sisters in Lambeth.\n\nAt the end of August 1942 Drummond and Warner joined the cargo steamer at Boston, Lincolnshire as First Mate and Second Engineer. The ship was owned by the Ministry of War Transport and managed by Ambrose, Davies and Matthews, who had chosen someone else for Second Engineer. The Third and Fourth Engineers were unqualified. The Master, Captain Cheek, the Chief Engineer and either the third or fourth engineer were all heavy drinkers. Drummond called \"Danae II\" \"The worst ship I ever sailed in\".\n\nThe ship steamed north \"via\" North Shields in Northumberland to Methil Docks in Fife. There Cheek tried to give Drummond her notice on medical grounds, but doctor ashore stopped him. When the ship reached Aultbea in Ross Cheek sacked Drummond with 24 hours' notice, although she had signed on for two years. The firemen, greasers and donkeyman all refused to sail without Drummond, and so did the deck crew. Her friend Warner, however, refused to leave the ship, leaving Drummond feeling betrayed.\n\nDrummond reported the mismanagement of \"Danae II\" to the MoWT and Ambrose, Davies and Matthews. Cheek's solicitors threatened to sue Drummond for defamation, but no action followed.\n\nAt the end of January 1943 Drummond returned to Blue Funnel, signing on as refrigeration engineer on the refrigerated cargo ship . Again Drummond was beset by a hostile Second Engineer always being rude to her, giving her extra work and trying to prevent her from getting shore leave.\n\n\"Perseus\" circumnavigated the World westbound from Liverpool \"via\" New York, Cuba, the Panama Canal, Australia, South Africa, Sierra Leone and Gibraltar, returning to Liverpool in September 1943. In July 1943 the ship visited Cape Town, where Drummond was able to go ashore and visit her friend Malcolm Quayle's grave outside the city.\n\nAfter an eight-month voyage Drummond did not want to return to sea immediately. After leaving \"Perseus\" in September 1943 she returned to her sisters in Lambeth, where Restormel House had been damaged by a bomb but their flat remained intact. Drummond did not seek another position at sea until January 1944.\n\nIn April 1944 Drummond signed on as Assistant Engineer of a diesel ship, the Baltic Trading Company's oil tanker , with which she sailed on an Arctic convoy to Onega in the USSR. On return to England in May 1944 Drummond signed onto \"Karabagh\" again as Fourth Engineer. After D-Day on 6 June 1944 the tanker spent three months shuttling supplies such as aviation spirit across the English Channel for the Invasion of Normandy, initially from the Solent and later from Newport, Wales.\n\nDrummond formed a friendship with \"Karabagh\"s Master, a man from Northern Ireland called Captain Charlton. In Newport the two took occasional trips ashore, and once on a visit to Tintern Abbey he proposed to her. She did not accept, and later explained that this was because both he and she had short tempers.\n\nAfter the War the bomb-damaged Restormel House was demolished. In December 1945 and January 1946 Drummond's sisters Jean and Frances moved into 160 Kennington Road, which they named Tresco.\nIn April 1946 Blue Funnel appointed Drummond to return to Caledon in Dundee to supervise the completion of the sister ships and , which she did until July.\n\n\"Karabagh\" had given Drummond enough experience to take her Second Engineer's motor examination. She passed in May 1946 on her second attempt. In September Drummond returned to sea as Second Engineer, now with Cunard-White Star Line. She worked as a relief Second Engineer, serving for short periods on Cunard cargo ships until January 1947. After leaving Cunard she served on the MoWT's Type C1 ship for five months, signing on in May 1947 at Fowey in Cornwall, leaving in September in Philadelphia and returning to Britain as a passenger on Cunard's .\n\nFor the next four years Drummond worked as Chief or Second Engineer for short periods for various shipping companies. They included \"Elsie Beth\", which she joined at Barry, South Wales in August 1949 and left in Dublin in December. The voyage took Drummond back to Onega in the USSR, where she had previously been in 1944 on \"Karabagh\".\n\nIn February 1952 Drummond returned to supervising shilbuilding in Scotland. The Phocian Ship Agency sent her to the Burntisland Shipbuilding Company in Fife to oversee building of the until the ship was launched in September. Drummond would have liked further jobs supervising shipbuilding, but instead Phocian offered her a berth on the . She spent a month on \"Markab\" as Second Engineer in October and November 1952, then returned to the ship as Chief Engineer in January 1953. This turned out to be a year-long voyage that included the Suez Canal, Japan, Hong Kong, Singapore, the Mediterranean, the Black Sea, the USA, the Caribbean, Argentina, Brazil, Cape Verde and ended in Antwerp in January 1954.\n\nDrummond next spent another three years serving for short periods for various shipping companies. Then in April 1957 in London she signed on Monarch Steamship Company's . This turned out to be a six-month voyage: across the Atlantic to the USA, through the Panama Canal, across the Pacific to Japan, south to Fiji, north to British Columbia and back through the Panama Canal, back across the Atlantic and ending in Liverpool in November 1957.\n\nDrummond returned home to Kennington Road until May 1958, when she began a two-month voyage as the engineer of an old motor yacht, \"My Adventuress\", from Southampton to Istanbul. The engine was unreliable and Drummond's relationship with the owner and his family was strained. Thereafter she stayed ashore in Kennington for another year.\n\nDrummond spent her final three years at sea as a Chief Engineer with the Jebshun Shipping Company of Hong Kong. Her first Jebshun ship was the former Empire ship \"Grelrosa\", which Drummond joined in Garston, Merseyside, Liverpool in July 1959. The ship had been laid up for 18 months and needed extensive work to pass its Lloyd's inspection. \"Grelrosa\" steamed \"via\" the Suez Canal and Singapore to Japan, China and Hong Kong, where Jebshun renamed her \"Shantae\".\n\nAs \"Shantae\" in 1960 the ship sailed to Malaysia and Thailand. In February 1960 in Bangkok Port the ship loaded a flammable mixed cargo of rice, firewood, paper, cotton, palm husks, charcoal, flour and palm oil, all carelessly and chaotically packed into the holds. On top of this, 580 head of live buffalo were crammed on as deck cargo. \"En route\" to Hong Kong on 1 March the cargo in number 2 hold caught fire. Drummond provided steam to smother and contain the fire, but this depleted the ship's water supply which was needed to make steam to power the main engine. \"Shantae\" reached Hong Kong on 3 March, where the port's fire service used carbon dioxide gas to extinguish the fire. The ship returned to sea 11 days later, trading to Chinese ports including Tsingtao. Drummond signed off at Hong Kong in mid-April.\n\nDrummond's next Jebshun vessel was the Park ship \"Shun Fung\", which she joined in Kristiansand, Norway in September 1960. This was another steamship that had been laid up and needed work to make her reliable. Drummond served on her for 14 months, sailing \"via\" the Suez Canal to Japan and China, then \"via\" Durban to West Africa, back to Hong Kong, then to India, and back \"via\" Singapore and Chinese ports to Hong Kong, where she signed off in November 1961.\n\nDrummond's final Jebshun ship, and the final vessel of her career, was the Liberty ship \"Santa Granda\". Only 10 days after signing off \"Shun Fung\" in Hong Kong she signed on \"Santa Granda\" for six months. She found \"Santa Granda\" to be in very poor condition: rusty, dirty and in poor repair. The governor, a vital piece of safety equipment, was missing from the engine.\n\n\"Santa Granda\" worked to Shanghai and then Basuo on Hainan Island, where it loaded iron ore in December 1961. The ship left port on 8 December, and by midnight was struggling against a strong headwind. The next day water was found in the Number one hold bilge, which took an hour and a half to pump out. On 11 December the Number one hold bilge again needed pumping out, which took an hour and three quarters. From 12 December the Number one hold bilge needed pumping continuously.\n\nFinally on 13 December the Master and Drummond inspected the Number One hold. They found about 10 frames adrift, a plate near the bulkhead split either side of the frame, and frames corroded through at the bottom and broken across. With the motion of the ship, plates and frames were moving past each other and friction was heating the metal. If a plate failed and flooded Number One hold, the Number One bulkhead would be likely to fail. In that case, and laden with dense iron ore, \"Santa Granda\" would be likely to sink within a very few minutes.\n\n\"Santa Granda\" initially made for Shanghai, until the Number One Hold's bulkhead began to buckle. Then the Master put the ship about for Whampoa on the Pearl River Delta, arriving on 17 December. After the iron ore was unloaded, ship surveyors allowed the damaged \"Santa Granda\" to leave to make for Hong Kong for repairs. Christmas was spent in Hong Kong, with Drummond arguing against Jebshun representatives who wanted to postpone many of the repairs essential to make the ship safe. Drummond began engine and boiler repairs, and on 29 December the ship moved to drydock in Kowloon.\n\nA fortgnight later \"Santa Granda\" returned to sea, continuing to take cargoes of iron ore from Basuo to other Chinese ports. On 25 March 1962 Drummond advised that the ship was still in too poor a condition to pass its forthcoming Lloyd's inspection. Two days later \"Santa Granda\" reached Hong Kong, where Jebshun told the Master they would transfer the insurance from Lloyd's to a French company. Drummond believed this was to avoid inspection, and on 30 March she gave the Master her notice that she would quit the ship the next day. Then Drummond spent 10 days in Hong Kong and visited friends in Japan before returning to London and retirement.\n\nDrummond and her two sisters spent the next 12 years living at 160 Kennington Road. She attended annual meetings of the Institute of Marine Engineers (now IMarEST) and wrote her life story. In the early 1970s Drummond grew less mobile and more dependent on Jean and Frances. In 1974 she fell out of bed, broke her leg and was admitted to St Thomas' Hospital. Soon Jean and Frances were admitted to the same hospital, where they died within two days of each other. Drummond recovered physically but her state of mind deteriorated and she was discharged to St George's Retreat, a church-run nursing home at Ditchling Common in East Sussex. She died there on Christmas Day 1978, and is buried at Megginch Castle beside her parents and sisters.\n\nIn a career spanning 40 years Drummond made 49 ocean-going voyages. She persevered with her career through hardship and some discrimination, doing the hard physical work of the engine room, managing the engine room crew and at times enduring prejudice and discrimination from some of her immediate superiors. However, she won acceptance and support from most of her fellow-officers and near-universal support and loyalty from crewmen.\n\nShe is commemorated by a Victoria Drummond Room at the IMarEST headquarters in London. Her biography, \"The Remarkable Life of Victoria Drummond – Marine Engineer\", was written by her niece, Cherry Drummond, 16th Baroness Strange.\n"}
{"id": "13344348", "url": "https://en.wikipedia.org/wiki?curid=13344348", "title": "Wall of Discovery", "text": "Wall of Discovery\n\nThe Wall of Discovery is an environmental artwork that includes a 253-foot-long printed \"blackboard\" located in the center of the Scholars Walk on the University of Minnesota campus. This installation was designed to celebrate the discoveries, inventions and creations of alumni and faculty of the University that have brought significant changes to the world in which we live.\n\nThe method used to capture the work was first to create an extensive list of notable U of M graduates in as many fields as possible. Extensive research was done by Minneapolis design firm LA ink that led to the finding of many original hand written notes and diagrams chronicling the discoveries by these scholars. The documents were then scanned and retouched, pixel by pixel, until they looked as if they were rendered in chalk on a chalkboard. 20 Glass edge lit panels were also designed to both illuminate the walkway and possibly inspire current students toward future discoveries.\n\nAn installation of this nature has never before been attempted by a major institution like the University of Minnesota.\n\nThe Artwork was submitted to the SEGD design competition in 2007 and won their \"Honor Award\" the highest achievement category. That same year it also received the AIA Minnesota Honor Award.\n\nOver 100 alumni and faculty from the University of Minnesota are represented on the wall a few of whom are:\n\n"}
