{"id": "18450700", "url": "https://en.wikipedia.org/wiki?curid=18450700", "title": "Airbrush makeup", "text": "Airbrush makeup\n\nAirbrush makeup is makeup sprayed onto the skin using an airbrush instead of being applied with sponges, brushes, fingers, or other methods. An airbrush is characterized by 3 major parts. A powered compressor is used to create an even and controllable airflow through a medical grade hose. The hose connects to a metal, trigger-actioned gun. An airbrush system can be altered to suit every type of makeup application by changing the air pressure (typically measured in pounds per square inch) for lighter, heavier, detailed or broader makeups. It is popular in film, theater, bridal makeup and sunless tanning. Systems designed for personal cosmetic use in the home are also available. Airbrush systems designed for home use are usually smaller and work at a lower pressures than systems used in industrial applications. The technique was first used in 1959 on actors in Ben Hur and has since grown in popularity in the entertainment business.\n\nAirbrushed makeup was first used in the film 1959 \"Ben Hur\", where the makeup artists used the technique to apply makeup to a large cast.\n\nAirbrush makeup has become more popular with the advent of high-definition video and television (HD). Traditional powder or liquid based make-up can settle and appear in pores and wrinkles and be visible on HD film. As the makeup is sprayed on, it connects with the skin as millions of droplets of formula. The formula can create an even, sheer, natural appearance to the skin that, if applied properly for a natural look, can appear natural and non-heavy like traditional makeup. Airbrush makeup wears longer than traditional powder or liquid foundation, and is able to stay put upwards of 12–24 hours. It can be used to cover five o'clock shadows for men. Airbrush makeup is also available for eye shadow, blush, eyebrows and lips and can be layered, shaded, highlighted and contoured. Application wise, the technique is more sanitary than traditional makeup application due the artist never having to touch the skin. It's also faster, if done by a trained artist. Fantasy and special effects are able to be stenciled or created by freehand.\n\nAirbrush makeup is characterized by its unique 'globular' application technique. The makeup is dispersed as an extremely fine mist through the airbrush gun. Millions of tiny little dots are created on the skin and when connected and layered together, create somewhat of a net over the entire face. This makes airbrush makeup to be a thin, light layer on the skin that is barely noticeable to the wearer. Certain formulas wear better than others and it is important to choose carefully when deciding what mixture is right for the job. Some airbrush makeups are entirely waterproof unless taken off with a specific remover that breaks down the active ingredient. For instance, silicone-based airbrush fluid is largely waterproof depending on how much, and how you set the makeup. It can be dunked in water (handy for fashion photography or film) or sweat through without removing or dislodging the airbrush base. It does however, take a specific silicone makeup remover to thoroughly take off (but will naturally come off over the course of many hours). In the contemporary makeup scene, airbrush makeup has become a preferred option for bridal and events makeup due to its long wearing and flawless appearance. \n\nAirbrush makeup comes in six different formulas:\nAirbrush makeup can be removed by using a 50/50 mix of isopropyl alcohol and isopropyl myristate.\n\nAirbrushing for makeup utilizes a freehand technique to apply makeup while manipulating aspects such as distance and air pressure to produce certain effects and coverage. Airbrush makeup artists will either use a circular motion or forward-back motion with the airgun when applying foundation. Both dual-action and single-action airbrushes can be used for airbrushing makeup and require slightly different techniques. \n\nA dual-action airbrush allows the user to control airflow by depressing the trigger with the index finger and drawing it backwards. This draws air from the compressor. The further the trigger is depressed, the more makeup is released. The advantage to using a dual-action airbrush is that one can use the air as a guide before allowing makeup to pass through the nozzle. Air is also used to dry the makeup after application. Makeup is also mixed in the cup by allowing a small amount of air to flow into it, thereby mixing two pigments. This technique is known as 'back-bubbling'. \n\nA single-action airbrush is generally considered easier to use because depressing the trigger releases a fixed ratio of makeup to air. However, in order to achieve different levels of coverage and detail the nozzle has to be changed between applications. \n\nGenerally an airbrush makeup artist will work with a PSI range between 0-35 PSI. Many compressors designed for personal use in the home will not achieve airflow greater than 15 PSI. A low PSI is preferable when airbrushing makeup around the face and eyes while full body application (such as covering blemishes or tanning) is easier and faster with a higher PSI. \n\nAirbrush makeup is applied by layering several passes of makeup. This allows the artists to build upon previous layers to produce subtle changes. When applying foundation between 6-12 drops of makeup are used. The makeup is sprayed onto the face at a distance of 6-12 inches.\n\nStencils are commonly used to assist the application of difficult areas such as eye-liner. Stencils are also available for body-art and temporary tattoos.\n\n"}
{"id": "3005578", "url": "https://en.wikipedia.org/wiki?curid=3005578", "title": "Arming plug", "text": "Arming plug\n\nAn arming plug is a small plug that is fitted into flight hardware to enable functions that, for instrument or personnel safety, should not be activated before flight. In the case of a missile or bomb, the (lack of the) arming plug prevents explosion before flight; in the case of a spacecraft or scientific sounding rocket, it might prevent premature firing of a hydrazine thruster system (hydrazine is extremely toxic) or block cryogenic or photographic film systems from operating before launch.\n"}
{"id": "38709822", "url": "https://en.wikipedia.org/wiki?curid=38709822", "title": "AutoTrack", "text": "AutoTrack\n\nAutoTrack is a vehicle swept path analysis software program used for analysing the movements of steered and wheeled vehicles including cars, trucks, trams, aircraft and other more specialist vehicles such as fork lift trucks, wheelchairs and access platforms. AutoTrack was the world's first swept path analysis software program, originally being jointly developed by TRL (the UK's Transport Research Laboratory) and British engineering consultants, Travers Morgan (acquired by Symonds in 1995 who are now part of Capita Symonds, in the form of TRACK. The term track refers to the tracking of a vehicle's simulated movements in relation to geometry, based upon vehicle dimensions, chassis and steering specification. AutoTrack has many similarities and performs the same function as the alternative swept path analysis program AutoTURN, which is developed by Transoft Solutions, Inc..\n\nAutoTrack is generally used by transportation engineers, architects and planners for the analysis and design of highways, intersections, buildings and other facilities to check that provision has been made for the space and geometry required to manoeuvre specified design vehicles. A design vehicle may be a real vehicle modelled within the software's computer environment but will often be a virtual vehicle that does not exist in real life, rather being indicative of the type and configuration of vehicle that the final design is expected to accommodate. Design vehicles are commonly specified by the relevant governing body that also controls the specification for which the design must conform.\n\nThe AutoTrack range is divided into modules that service the Road, Rail and Airports industries and operates within several different CAD systems such as AutoCAD by Autodesk, Microstation by Bentley Systems, Bricscad by Bricsys (a former member of the IntelliCAD Technology Consortium) and standalone in Microsoft Windows. When the software was first developed it initially ran as a DOS-based application and when it was ported to operate within AutoCAD, it was given the name AutoTrack. The software, initially developed for consulting purposes, was sold commercially and following the demise of the original company, a management buy out pre-empted the incorporation of Savoy Computing Services Ltd. in 1996. Two of the surviving directors of Savoy Computing were involved with the original development of TRACK.\n\nIn August, 2013 Autodesk acquired the technology assets of Savoy Computing Services Ltd, including the AutoTrack technology. Autodesk subsequently released Autodesk Vehicle Tracking, which directly superseded AutoTrack in November, 2013. At this point Savoy Computing Services ceased trading and the AutoTrack software product is since no longer supported.\n\n\n\n"}
{"id": "37115360", "url": "https://en.wikipedia.org/wiki?curid=37115360", "title": "Buddle pit", "text": "Buddle pit\n\nA buddle pit or buddle pond is a pit, often circular when specifically constructed, the purpose of which was to separate by sedimentation minerals from lighter rock dust in crushed ore, and used in the mineral mining industry (such as in extracting tin, lead and zinc). Many of the relics seen today date from Victorian times.\n\nEarly examples of buddle pits were often natural hollows in the ground, adapted by lining them with stone or clay to make them waterproof.\n\nA purpose-built pit, constructed from stone or brick, cement and mortar, contained water, and a set of brushes, often powered by a water wheel, which rotated in the water in order to agitate the mixture, the result of which was that the heavier and denser material - i.e. the ore - tended to collect at the centre of the pit, from where it could be retrieved. The worthless gangue was then disposed of, often by draining.\n\nUsually a set of buddle pits was utilised, with the richer central deposits in the pit being carried to another buddle, where they were treated in the same manner, and so on.\n\nWhilst the round buddle pit was the most common, there was a variation called the concave buddle, which had a concave bottom.\nThe following detailed extract comes from \"Machinery for Metalliferous Mines: A practical treatise for mining engineers, metallurgists and managers of mines\", by E. Henry Davies, C. Lockwood and son, 1902 :\n\n"}
{"id": "18583225", "url": "https://en.wikipedia.org/wiki?curid=18583225", "title": "Buffer (GIS)", "text": "Buffer (GIS)\n\nA buffer in GIS is a zone around a map feature measured in units of distance or time. A buffer is useful for proximity analysis.\n\nA buffer is an area defined by the bounding region determined by a set of points at a specified maximum distance from all nodes along segments of an object.\n\n\n"}
{"id": "47735068", "url": "https://en.wikipedia.org/wiki?curid=47735068", "title": "Case IH Axial Flow Combines", "text": "Case IH Axial Flow Combines\n\nAxial flow combines (also known as rotary harvesters) are a type of combine harvester that has been manufactured by International Harvester, and later Case International, Case Corporation and CNH Global, used by farmers to harvest a wide range of grains around the world.\n\nIntroduced in 1977, these harvesters marked a departure from traditional combine harvester design, in that threshing and separation was performed mainly by a rotor, as opposed to the drum and straw walker type models used previously. This is shown in the image at right, where the bulk of the processing area is devoted to a cylinder, that spins and threshes grain from the grain heads and allows for far greater capacity than the previous drum and walker design of harvester. This increase in capacity has led to a significant productivity increase of harvesters and therefore farmers who use them.\n\nThe rotary design by International Harvester was the first of its kind to be mass-produced and its patent over the design gave IH a competitive advantage over its rivals, including John Deere, Massey Ferguson, New Holland and others.\n\nThe following is a summary of the model development of the Case IH harvester to the present day.\n\nInternational Harvester had launched the 15 series of conventional combine harvesters in 1968. In 1977, after extensive engineering efforts and a bottom up design, IH released the 1440 and 1460 models of harvester. In 1978, the larger model 1480 was released, as well as the specialty models 1470 (for hillside operation), and the 1482, designed to be pulled behind a tractor with PTO capability. Further models were introduced as the series was developed including the 1420 in 1980,\n\nIn 1985, International Harvester and Case Corporation merged.\n\nThe 16 series was the first harvester series released by the new Case International and was an upgrade to the 14 series rather than a replacement. All models of the 14 series had 16 series equivalents, in the 1620, 1640, 1660, 1670, 1680 and 1682.\n\nReleased in 1993, the 16 series was again upgraded to the 16-4/6/8 series. Models included the 1644, 1666 and 1688, and incorporated many changes to improve processing capacity.\n\nTenneco demerged CaseIH in 1995 and the new Case Corporation released the 21 series combine harvesters, comprising the 2144, 2166, 2188. These models represented a significant step forward in the model design featuring improved operator comfort, higher power engines and a range of other productivity and user ease improvements.\n\nMaking incremental improvements on the 21 series, the 23 series were quite similar to the 21 series featuring more upgrades to engine power and other improvements to harvester operation. The series featured the 2344, 2366, 2377 and 2388 models. The 2377 was intended to replace the 2366, though the 2366 remained popular.\n\nIn 1999, CaseIH and New Holland AG merged to form CNH Global. As part of the post merger product simplification process, both harvester lines of CaseIH and New Holland were based on a common basic platform, with each model then customised to the features usually found on each harvester (e.g. cabin, external panelling, colouring, decals etc.). These combine harvesters are manufactured in Grand Island, Nebraska\n\nThis series consisted of the 7120, 8120 and 9120 models and were based on a 5.4m (7120) and 6.5m (8120/9120) cleaning area. Significant improvements were made to the design including replacing many chains and belts with hydraulic control, including the main rotor drive belt. This hydraulic drive also allowed the fitting of an in cabin rotor reversing mechanism, allowing operators to reverse the entire rotor and feeder house in the event of a blockage.\n\nThe 88 series continued the 23 series line in parallel to the 120 series, and consisted of the 5088, 6088 and 7088 models. This series had 5.48m2 of separation area. The series has been phased out of production in most markets. Until they we stopped being made in 2009.\n\nIn 2009, the 130/230 series was released. It has a Tier 4a/Tier 4 interim engine emissions control. This series has two sub-series with the difference based on total cleaning area. The smaller sub-series uses a 5.9m cleaning area and consists of the 5130 (Class V), 6130 (Class VI) and 7130 (Class VII) models. The larger sub-series uses a 6.1m cleaning area and consists of the 7230 (Class VII), 8230 (Class VIII) and 9230 (Class IX) models.\n\nBased on the 66 series Axial-Flow harvesters, the 4000 series, 4077 and 4088 were produced from 2014 in CNH Industrial's Harbin plant in China\n\n"}
{"id": "153914", "url": "https://en.wikipedia.org/wiki?curid=153914", "title": "Cassette deck", "text": "Cassette deck\n\nA cassette deck is a type of tape machine for playing and recording audio compact cassettes. Consumer electronics formerly used the term \"deck\" to distinguish them from a \"tape recorder\", the \"deck\" being part of a stereo component system, while a \"tape recorder\" was more portable and usually had a self-contained power amplifier (and often speakers).\n\nAlthough the two terms became interchangeable, a recorder is typically thought of as a low-fidelity portable device, while a deck is considered a high fidelity component.\n\nThe first consumer tape recorder to employ a tape reel permanently housed in a small removable cartridge was the RCA tape cartridge, which appeared in 1958 as a predecessor to the cassette format. At that time, reel to reel recorders and players were commonly used by enthusiasts, but required large individual reels and tapes which had to be threaded by hand, making them less-accessible to the casual consumer. Both RCA and Bell Sound attempted to commercialize the cartridge format, but a few factors stalled adoption, including lower-than-advertised availability of selections in the prerecorded media catalog, delays in production setup, and a stand-alone design that was not considered by audiophiles to be truly hi-fi.\n\nThe \"compact cassette\" (a Philips trademark) was introduced by the Philips Corporation at the Internationale Funkausstellung Berlin in 1963 and marketed as a device purely intended for portable speech-only dictation machines. The tape width was ⁄ inch (actually 0.15 inch, 3.81 mm) and tape speed was 1.875 inches (4.8 cm) per second, giving a decidedly non Hi-Fi frequency response and quite high noise levels.\n\nEarly recorders were intended for dictation and journalists, and were typically hand-held battery-powered devices with built-in microphones and automatic gain control on recording. Tape recorder audio-quality had improved by the mid-1970s, and a cassette deck with manual level controls and VU meters became a standard component of home high-fidelity systems. Eventually the reel-to-reel recorder was completely displaced, in part because of the usage constraints presented by their large size, expense, and the inconvenience of threading and rewinding the tape reels - cassettes are more portable and can be stopped and immediately removed in the middle of playback without rewinding. Cassettes became extremely popular for automotive and other portable music applications. Although pre-recorded cassettes were widely available, many users would combine (dub) songs from their vinyl records or cassettes to make a new custom mixtape cassette.\n\nIn 1970, the Advent Corporation combined Dolby B noise reduction system with chromium dioxide (CrO) tape to create the Advent Model 200, the first high-fidelity cassette deck. Dolby B uses volume companding of high frequencies to boost low-level treble information by up to 9 dB, reducing them (and the hiss) on playback. CrO used different bias and equalization settings to reduce the overall noise level and extend the high frequency response. Together these allowed a usefully flat frequency response beyond 15 kHz for the first time. This deck was based on a top-loading mechanism by Nakamichi, then soon replaced by the Model 201 based on a more reliable transport made by Wollensak, a division of 3M, which was commonly used in audio/visual applications. Both featured an unusual single VU meter which could be switched between or for both channels. The Model 200 featured piano key style transport controls, with the Model 201 using the distinctive combination of a separate lever for rewind/fast forward and the large play and stop button as found on their commercial reel to reel machines of the era.\n\nMost manufacturers adopted a standard top-loading format with piano key controls, dual VU meters, and slider level controls. There was a variety of configurations leading to the next standard format in the late 1970s, which settled on front-loading (see main picture) with cassette well on one side, dual VU meters on the other, and later dual-cassette decks with meters in the middle. Mechanical controls were replaced with electronic push buttons controlling solenoid mechanical actuators, though low cost models would retain mechanical controls. Some models could search and count gaps between songs.\n\nCassette decks soon came into widespread use and were designed variously for professional applications, home audio systems, and for mobile use in cars, as well as portable recorders. From the mid-1970s to the late 1990s the cassette deck was the preferred music source for the automobile. Like an 8-track cartridge, it was relatively insensitive to vehicle motion, but it had reduced tape flutter, as well as the obvious advantages of smaller physical size and fast forward/rewind capability.\nA major boost to the cassette's popularity came with the release of the Sony Walkman \"personal\" cassette player in 1979, designed specifically as a headphone-only ultra-compact \"wearable\" music source. Although the vast majority of such players eventually sold were not Sony products, the name \"Walkman\" has become synonymous with this type of device.\n\nCassette decks were eventually manufactured by almost every well known brand in home audio, and many in professional audio, \nwith each company offering models of very high quality.\n\nCassette decks reached their pinnacle of performance and complexity by the mid-1980s. Cassette decks from companies such as Nakamichi, Revox, and Tandberg incorporated advanced features such as multiple tape heads and dual capstan drive with separate reel motors. Auto-reversing decks became popular and were standard on most factory installed automobile decks. \n\nAs a part of the Digital Revolution, the ongoing development of electronics technology decreased the cost of digital circuitry to the point that the technology could be applied to consumer electronics. The application of such digital electronics to cassette decks provides an early example of mechatronic design, which aims to enhance mechanical systems with electronic components in order to improve performance, increase system flexibility, or reduce cost. The inclusion of logic circuitry and solenoids into the transport and control mechanisms of cassette decks, often referred to \"logic control,\" contrasts with earlier \"piano-key\" transport controls and mechanical linkages. One goal of using logic circuitry in cassette decks or recorders was to minimize equipment damage upon incorrect user input by including fail-safes into the transport and control mechanism. Such fail-safe behavior was described in a review by Julian Hirsch of a particular cassette deck featuring logic control. Some examples of fail-safe mechanisms incorporated into logic control decks include: a mechanism designed to protect internal components from damage when the tape or motor is locked, a mechanism designed to prevent the tape from being wound improperly, among others. Some logic control decks were designed to incorporate light-touch buttons or remote control, among other features marketed as being convenient. In the car stereo industry, full logic control was developed with the aim of miniaturization, so that the cassette deck would take up less dashboard space.\n\nThree-head technology uses separate heads for recording and playback (the third of the three heads being the erase head). \nThis allows different record and playback head gaps to be used. \nA narrower head gap is optimal for playback than for recording, so the head gap width of any combined record/playback head must necessarily be a compromise. \nSeparate record and playback heads also allow off-the-tape monitoring during recording, permitting immediate verification of the recording quality. \n(Such machines can be identified by the presence of a \"monitor\" switch with positions for \"tape\" and \"source\", or similar.) \nThree-head systems were common on reel-to-reel decks, but were more difficult to implement for cassettes, \nwhich do not provide separate openings for record and play heads. \nSome models squeezed a monitor head into the capstan area, and others combined separate record and playback gaps into a single headshell.\n\nThe Dolby B noise reduction system was key to realizing low noise performance on slow, narrow, cassette tapes. It works by boosting the high frequencies on recording, especially low-level high-frequency sounds, with corresponding high frequency reduction on playback. This lowers the high frequency noise (hiss) by approximately 9 dB. Enhanced versions included Dolby C (in 1980) and Dolby S types. Of the three, however, only Dolby B became common on automobile decks.\n\nBang & Olufsen developed the HX Pro headroom extension system in conjunction with Dolby Laboratories in 1982. This was used in many higher-end decks. HX Pro reduces the high-frequency bias during recording when the signal being recorded has a high level of high frequency content. Such a signal is self-biasing. Reducing the level of the bias signal permits the desired signal to be recorded at a higher level without saturating the tape, thus increasing \"headroom\" or maximum recording level.\n\nSome decks incorporated microprocessor programs to adjust tape bias and record level calibration automatically.\n\nIn later years, an \"auto reverse\" feature appeared that allowed the deck to play (and, in some decks, record) on both sides of the cassette without the operator having to manually remove, flip, and re-insert the cassette. \nMost auto-reverse machines use a four channel head (similar to those on multitrack recorders), with only two channels connected to the electronics at one time, one pair for each direction. \nAuto-reverse decks employ a capstan and pinch roller for each side. \nSince these use the same opening in the cassette shell normally used for the erase head, \nsuch decks must fit the erase head (or two, one for each direction) into the center opening in the shell along with the record/play head.\n\nIn later auto reverse machines, the \"auto reverse\" mechanism uses an ordinary two-track, quarter-width head, \nbut operates by mechanically rotating the head 180 degrees so that the two head gaps access the other tracks of the tape. \nThere is usually an azimuth adjustment screw for each position. \nNevertheless, due to the repeated movement, the alignment (in particular, the azimuth) deviates with usage. \nEven in a machine with a four channel head, slight asymmetries in the cassette shell make it difficult to align the \nhead perfectly for both directions. \n\nIn one machine, the \"Dragon\", Nakamichi addressed the issue with a motor-driven automatic head alignment mechanism. \nThis proved effective but very expensive. \nA later Nakamichi auto-reverse model was essentially a single-directional deck, \nbut with an added mechanism that physically removed the cassette from the transport, flipped it over, and re-inserted it. \nAkai made a similar machine but doing it \"flat\" instead of \"upright\". \nThis permitted the convenience of auto-reverse with little compromise in record or playback quality.\n\nNew tape formulations were introduced. \nChromium dioxide (referred to as CrO or Type II) was the first tape designed for extended high frequency response, but it required higher bias. Later, as the IEC Type II standard was defined, a different equalization settings was also mandated to reduce hiss, thus giving up some extension at the high end of the audio spectrum. \nBetter-quality cassette recorders soon appeared with a switch for the tape type. \nLater decks incorporated coded holes in the shell to autodetect the tape type. \nChromium dioxide tape was thought to cause increased wear on the heads, so TDK and Maxell adapted cobalt-doped ferric formulations to mimic CrO. \nSony briefly tried FerriChrome (Type III) which claimed to combine the best of both; some people, however, stated that the reverse was true because the Cr top layer seemed to wear off quickly, reducing this type to Fe in practice. Most recent decks produce the best response and dynamic headroom with metal tapes (IEC Type IV) which require still higher bias for recording, though they will play back correctly at the II setting since the equalization is the same.\n\nWith all of these improvements, the best units could record and play the full audible spectrum from 20 Hz to over 20 kHz (although this was commonly quoted at -10, -20 or even -30 dB, not at full output level), with wow and flutter less than 0.05% and very low noise. A high-quality recording on cassette could rival the sound of an average commercial CD, though the quality of pre-recorded cassettes has been regarded by the general public as lower than could be achieved in a quality home recording. There was a call for better sound quality in 1981, surprisingly by the head of Tower Records, Russ Solomon. At a meeting of the National Association of Recording Merchandisers (NARM) Retail Advisory Committee in Carlsbad, California, Solomon played two recordings of a Santana track; one he had recorded himself and the pre-recorded cassette release from Columbia Records. He used this technique to demonstrate what he called \"the tunnel effect\" in the audio range of pre-recorded cassettes and commented to the reporter Sam Sutherland, who wrote a news article printed in Billboard magazine:\n\"The buyer who is aware of sound quality is making his own.\" [...] \"They won't be satisfied with the 'tunnel effect' of prerecorded tape. And home tape deck users don't use prerecorded tapes at all.\" Yet, contended Solomon, while Tower's own stores show strong blank tape sales gains, it's prerecorded sales have increased by only 2% to 3%. With an estimated 15% of the chain's total tape business now generated by the sales of blanks, \"it would appear our added tape sales are going to TDK, Maxell and Sony, not you.\" he concluded. - Billboard Magazine, Vol. 93, No. 38, 26 Sep 1981.\nA variety of noise reduction and other schemes are used to increase fidelity, with Dolby B being almost universal for both prerecorded tapes and home recording. Dolby B was designed to address the high-frequency noise inherent in cassette tapes, and along with improvements in tape formulation it helped the cassette win acceptances as a high-fidelity medium. At the same time, Dolby B provided acceptable performance when played back on decks that lacked Dolby circuitry, meaning there was little reason not to use it if it was available.\n\nThe main alternative to Dolby was the dbx noise reduction system, which achieved a high signal-to-noise ratio, but was essentially unlistenable when played back on decks that lacked the dbx decoding circuitry.\n\nPhilips developed an alternative noise reduction system known as Dynamic Noise Limiter (DNL) which did not require the tapes to be processed during recording; this was also the basis of the later DNR noise reduction.\n\nDolby later introduced Dolby C and Dolby S noise reduction, which achieved higher levels of noise reduction; Dolby C became common on high-fidelity decks, but Dolby S, released when cassette sales had begun to decline, never achieved widespread use. It was only licensed for use on higher end tape decks that included dual motors, triple heads, and other refinements.\n\nDolby HX Pro headroom extension provided better high-frequency response by adjusting the inaudible tape bias during the recording of strong high-frequency sounds, which had a bias effect of their own. Developed by Bang & Olufsen, it did not require a decoder to play back. Since B&O held patent rights and required paying license fees, many other manufacturers refrained from using it too.\n\nOther refinements to improve cassette performance included Tandberg's DYNEQ, Toshiba's and Telefunken's High Com, and on some high-end decks, automatic recording bias, fine pitch adjustment and (sometimes) head azimuth adjustment such as the Tandberg TCD-330 and TCD-340A.\n\nBy the late 1980s, thanks to such improvements in the electronics, the tape material and manufacturing techniques, as well as dramatic improvements to the precision of the cassette shell, tape heads and transport mechanics, sound fidelity on equipment from the top manufacturers far surpassed the levels originally expected of the medium. On suitable audio equipment, cassettes could produce a very pleasant listening experience. High-end cassette decks could achieve 15 Hz-22 kHz±3 dB frequency response with wow and flutter below 0.022%, and a signal-to-noise ratio of up to 61 dB (for Type IV tape, without noise-reduction) . With noise reduction typical signal-to-noise figures of 70-76 dB with Dolby C, 80-86 dB with Dolby S, and 85 - 90 dB with dbx could be achieved. Many casual listeners could not tell the difference between compact cassette and compact disc.\n\nFrom the early 1980s, the fidelity of prerecorded cassettes began to improve dramatically. Whereas Dolby B was already in widespread use in the 1970s, prerecorded cassettes were duplicated onto rather poor quality tape stock at (often) high speed and did not compare in fidelity to high-grade LPs. However, systems such as XDR, along with the adoption of higher-grade tape (such as chromium dioxide, but typically recorded in such a way as to play back at the normal 120 μs position), and the frequent use of Dolby HX Pro, meant that cassettes became a viable high-fidelity option, one that was more portable and required less maintenance than records. In addition, cover art, which had generally previously been restricted to a single image of the LP cover along with a minimum of text, began to be tailored to cassettes as well, with fold-out lyric sheets or librettos and fold-out sleeves becoming commonplace.\n\nSome companies, such as Mobile Fidelity, produced audiophile cassettes in the 1980s, which were recorded on high-grade tape and duplicated on premium equipment in real time from a digital master. Unlike audiophile LPs, which continue to attract a following, these became moot after the Compact Disc became widespread.\n\nAlmost all cassette decks have an MPX filter to improve the sound quality and the tracking of the noise reduction system when recording from a FM stereo broadcast. However, in many especially cheaper decks, this filter cannot be disabled, and because of that record/playback frequency response in those decks typically is limited to 16 kHz. In other decks, the MPX filter can be switched off or on independently from the Dolby switch. On yet other decks, the filter is off by default, and an option to switch it on or off is only provided when Dolby is activated; this prevents the MPX filter from being used when it's not required.\n\nA key element of the cassette's success was its use in in-car entertainment systems, where the small size of the tape was significantly more convenient than the competing 8-track cartridge system. Cassette players in cars and for home use were often integrated with a radio receiver, and the term \"casseiver\" was occasionally used for combination units for home use. In-car cassette players were the first to adopt automatic reverse (\"auto-reverse\") of the tape direction at each end, allowing a cassette to be played endlessly without manual intervention. Home cassette decks soon added the feature. In-car cassette players are preferred by some particularly for their cheaper cost and serviceability.\n\nCassette tape adaptors have been developed which allow newer media players to be played through existing cassette decks, in particular those in cars which generally do not have input jacks. These units do not suffer from reception problems from FM transmitter based system to play back media players through the FM radio, though supported frequencies for FM transmitters that aren't used on commercial broadcasters in a given region (e.g. any frequency below 88.1 in the US) somewhat eliminates that problem.\n\nCassette equipment needs regular maintenance, as cassette tape is a magnetic medium which is in physical contact with the tape head and other metallic parts of the recorder/player mechanism. Without such maintenance, the high frequency response of the cassette equipment will suffer.\n\nOne problem occurs when iron oxide (or similar) particles from the tape itself become lodged in the playback head. As a result, the tape heads will require occasional cleaning to remove such particles. The metal capstan and the rubber pinch roller can become coated with these particles, leading them to pull the tape less precisely over the head; this in turn leads to misalignment of the tape over the head azimuth, producing noticeably unclear high tones, just as if the head itself were out of alignment.\n\nThe heads and other metallic components in the tape path (such as spindles and capstans) may become magnetized with use, and require demagnetizing (see Cassette demagnetizer).\n\nIsopropyl alcohol and Denatured alcohol are both suitable head-cleaning fluids. (Rubbing alcohol may contain oil which is not suitable.) Head cleaning fluid is a relatively expensive way to buy isopropyl alcohol.\n\nAnalog cassette deck sales were expected to decline rapidly with the advent of the compact disc and other digital recording technologies such as digital audio tape (DAT), MiniDisc, and the CD-R recorder drives. Philips responded with the digital compact cassette, a system which was backward-compatible with existing analog cassette recordings for playback, but it failed to garner a significant market share and was withdrawn. One reason proposed for the lack of acceptance of digital recording formats such as DAT was a fear by content providers that the ability to make very high quality copies would hurt sales of copyrighted recordings.\n\nThe rapid transition was not realized and CDs and cassettes successfully co-existed for nearly 20 years. A contributing factor may have been the inability of early CD players to reliably read discs with surface damage and offer anti-skipping features for applications where external vibration would be present, such as automotive and recreation environments. Early CD playback equipment also tended to be expensive compared to cassette equipment of similar quality and did not offer recording capability. Many home and portable entertainment systems supported both formats and commonly allowed the CD playback to be recorded on cassette tape. The rise of inexpensive all-solid-state portable digital music systems based on MP3, AAC and similar formats finally saw the eventual decline of the domestic cassette deck. Tascam, Marantz, Yamaha, Teac, Denon, Sony, and JVC are among the companies still manufacturing cassette decks in relatively small quantities for professional and niche market use. By the late 1990s, automobiles were offered with entertainment systems that played both cassettes and CDs. By the end of the late 2000s, very few cars were offered with cassette decks. As radios became tightly integrated into dashboards, many cars lacked even standard openings that would accept aftermarket cassette player installations.\n\nDespite the decline in the production of cassette decks, these products are still valued by some. Many blind and elderly people find the newest digital technologies very difficult to use compared to the cassette format. Cassette tapes are not vulnerable to scratching from handling (though the exposed magnetic tape is vulnerable to stretching from poking), and play from where they were last stopped (though some modern MP3 players offer savestating electronically). Cassette tapes can also be recorded multiple times (though some solid-state digital recorders are now offering that function).\n\nToday, cassette decks are not considered by most people to be either the most versatile or highest fidelity sound recording devices available, as even very inexpensive CD or digital audio players can reproduce a wide frequency range with no speed variations. Many current budget-oriented cassette decks lack a tape selector to set proper bias and equalization settings to take best advantage of the extended high end of Type II [High Bias] and Type IV [Metal Bias] tapes.\n\nCassettes remain popular for audio-visual applications. Some CD recorders, particularly those intended for business use, incorporate a cassette deck to allow both formats for recording meetings, church sermons and books on tape.\n\n"}
{"id": "269975", "url": "https://en.wikipedia.org/wiki?curid=269975", "title": "Clapperboard", "text": "Clapperboard\n\nA clapperboard is a device used in filmmaking and video production to assist in synchronizing of picture and sound, and to designate and mark the various scenes and takes as they are filmed and audio-recorded. Other names include clapper, clapboard, clacker, slate, slate board, slapperboard, sync slate, time slate, sticks, board, smart slate, dumb slate and sound marker.\n\nWhen a movie's sound and picture are out of synchronization, this is known as lip flap.\n\nClapperboards have been essential to filmmaking since the earliest sound films because (until the advent of digital cinematography) visual and audio tracks were recorded on separate media by separate equipment. The clapperboard combines a 'chalkboard slate' with a 'clapstick'. The slate displays the name of the production, the scene and \"take\" about to be performed, and similar information; an assistant holds the clapperboard so the slate is in view of the cameras, speaks out information for the benefit of the audio recording, then opens the clapstick and claps it shut. The shutting of the clapstick is easily identified on the visual track, and the sharp \"clap\" noise is easily identified on the separate audio track; the two tracks can later be precisely synchronised by matching the sound and movement. And since each take is identified on both the visual and audio tracks, segments of film are easily matched with segments of audio.\n\nTraditional clapperboards consisted of a wooden slate with a hinged clapstick attached to its top. Modern clapperboards generally use a pair of wooden sticks atop either a whiteboard or a translucent acrylic glass slate (the latter being easily legible via the light coming through it from the scene about to be shot). Smart slates or digislates are electronic SMPTE time code versions with digitally displayed information. The clapsticks traditionally have diagonally interleaved lines of black and white to ensure a clear visual of the clap in most lighting conditions. In recent years sticks with calibrated color stripes have become available. In some productions, particularly those created in the digital domain, electronically superimposed versions of a clapperboard have supplanted the real thing.\n\nThe slate typically includes the date, the production title, the name of the director, the name of the director of photography (DP) and the scene information — which follows two popular systems:\nOften the European system will also include the scene number; however, a separate \"continuity sheet\" that maps the \"slate\" number to the scene number, camera angle and take number may be used if the scene number is not included on the slate. This is generally not as great a concern with short films, however. The clapper loader (or 2nd AC) is generally responsible for the maintenance and operation of the clapperboard, while the script supervisor is responsible for determining which system will be used and what numbers a given take should have. While these are usually fairly obvious once a system has been agreed upon, the script supervisor is usually considered the final arbiter in the event of an unclear situation.\n\nA verbal identification of the numbers, known either as \"voice slate\" or \"announcement\", occurs after sound has reached speed. At the same time or shortly thereafter, the camera will start running, and the clapperboard is then filmed briefly at the start of the 'take' and the clapsticks are clapped sharply as soon as the camera has reached sync speed. Specific procedures vary depending on the nature of the production (documentary, television, feature, commercial, etc.) and the dominant camera assisting conventions of the region; therefore it is not possible to describe a definitive practice aside from the general principles. Occasionally, instead of preparing an actual slate, a voice slate will be announced (often by an actor in the scene) and then the actor will clap their hands together, to provide the synchronisation mark.\n\nSometimes a tail slate or end slate is filmed at the end of a take, during which the clapperboard is held upside-down. This is done when the clapperboard was not captured at the start of the take due to the camera being set up for the shot in such a way that the board cannot be captured, for example when a specific focus or frame is set up and cannot be altered until the take is complete. A clapper board is generally used to identify all takes on a production, even takes that do not require synchronization, such as MOS takes. When a slate is used to mark an MOS take, the slate is held half open, with a hand blocking the sticks, or closed, with a hand over the sticks.\n\nThe clapper (two sticks hinged together) was invented by F. W. Thring (father of actor Frank Thring), who was head of Efftee Studios in Melbourne, Australia. Some mention that Efftee was not founded until 1931, not in the 1920s as sometimes stated. However, the date of Efftee's founding does not assume the start of F.W. Thring's involvement in the industry. Consider the start of the Australian film industry with 1906's The Story of the Kelly Gang, which was the first feature length narrative film in the world. The director of this film, Charles Tait, was associated with J. C. Williamson. The former's production company, J. & N. Tait, merged with the J. C. Williamson Film Company. F.W. Thring was managing director of J.C. Williamson Films in 1918. The clapboard with both the sticks and slate together was refined by Leon M. Leon (1903–1998) a pioneer sound engineer.\n\n"}
{"id": "883627", "url": "https://en.wikipedia.org/wiki?curid=883627", "title": "Coalbrookdale", "text": "Coalbrookdale\n\nCoalbrookdale is a village in the Ironbridge Gorge in Shropshire, England, containing a settlement of great significance in the history of iron ore smelting. It lies within the civil parish called the Gorge.\n\nThis is where iron ore was first smelted by Abraham Darby using easily mined \"coking coal\". The coal was drawn from drift mines in the sides of the valley. As it contained far fewer impurities than normal coal, the iron it produced was of a superior quality. Along with many other industrial developments that were going on in other parts of the country, this discovery was a major factor in the growing industrialisation of Britain, which was to become known as the Industrial Revolution. Today, Coalbrookdale is home to the Ironbridge Institute, a partnership between the University of Birmingham and the Ironbridge Gorge Museum Trust offering postgraduate and professional development courses in heritage.\n\nBefore the Dissolution of the Monasteries, Madeley and the adjacent Little Wenlock belonged to Much Wenlock Priory. At the Dissolution there was a bloomsmithy called \"Caldebroke Smithy\". The manor passed about 1572 to John Brooke, who developed coal mining in his manor on a substantial scale. His son Sir Basil Brooke was a significant industrialist, and invested in ironworks elsewhere. It is probable that he also had ironworks at Coalbrookdale, but evidence is lacking. He also acquired an interest in the patent for the cementation process of making steel in about 1615. Though forced to surrender the patent in 1619, he continued making iron and steel until his estate was sequestrated during the Civil War, but the works continued in use.\n\nIn 1651, the manor was leased to Francis Wolfe, the clerk of the ironworks, and he and his son operated them as tenant of (or possibly manager for) Brooke's heirs. The surviving old blast furnace contains a cast-iron lintel bearing a date, which is currently painted as 1638, but an archive photograph has been found showing it as 1658. What ironworks existed at Coalbrookdale and from precisely what dates thus remains obscure. By 1688, the ironworks were operated by Lawrence Wellington, but a few years after the furnace was occupied by Shadrach Fox. He renewed the lease in 1696, letting the Great Forge and Plate Forge to Wellington. Some evidence may suggest that Shadrach Fox smelted iron with mineral coal, though this remains controversial. Fox was evidently an iron founder, as he supplied round shot and grenado shells to the Board of Ordnance during the Nine Years War, but not later than April 1703, the furnace blew up. It remained derelict until the arrival of Abraham Darby the Elder in 1709. However the forges remained in use. A brass works was built sometime before 1712 (possibly as early as 1706), but closed in 1714.\n\nIn 1709, the first Abraham Darby rebuilt Coalbrookdale Furnace, and used coke as his fuel. His business was that of an ironfounder, making cast-iron pots and other goods, an activity in which he was particularly successful because of his patented foundry method, which enabled him to produce cheaper pots than his rivals. Coalbrookdale has been claimed as the home of the world's first coke-fired blast furnace; this is not strictly correct, but it was the first in Europe to operate successfully for more than a few years.\n\nDarby renewed his lease of the works in 1714, forming a new partnership with John Chamberlain and Thomas Baylies. They built a second furnace in about 1715, which was intended to be followed up with a furnace at Dolgûn near Dolgellau and taking over Vale Royal Furnace in 1718. However, Darby died prematurely in 1717, followed quickly by his widow Mary. The partnership was dissolved before Mary's death, Baylies taking over Vale Royal. After Mary's death, Baylies had difficulty extracting his capital. The works then passed to a company led by his fellow Quaker Thomas Goldney II of Bristol and managed by Richard Ford (also a Quaker). Darby's son Abraham Darby the Younger was brought into the business as an assistant manager when old enough.\n\nThe company's main business was producing cast-iron goods. Molten iron for this foundry work was not only produced from the blast furnaces, but also by remelting pig iron in air furnaces, a variant of the reverberatory furnace. The Company also became early suppliers of steam engine cylinders in this period.\n\nFrom 1720, the Company operated a forge at Coalbrookdale but this was not profitable. In about 1754, renewed experiments took place with the application of coke pig iron to the production of bar iron in charcoal finery forges. This proved to be a success, and led to the partners building new furnaces at Horsehay and Ketley. This was the beginning of a great expansion in coke ironmaking.\n\nIn 1767, the Company began to produce the first cast-iron rails for railways. In 1778, Abraham Darby III undertook the building of the world's first cast-iron bridge, the iconic Iron Bridge, opened 1 January 1781. The fame of this bridge leads many people today to associate the iron-making part of the Industrial Revolution with the neighbouring village of Ironbridge, but in fact most of the work was done at Coalbrookdale, as there was no settlement at Ironbridge in the eighteenth century. Expansion of Coalbrookdale's industrial facilities continued, with the development of sophisticated ponds and culverts to provide water power, and even \"Resolution\", a water-returning beam engine to recirculate this water.\n\nIn 1795, the first porcelain factory near Coalbrookdale was founded at Coalport, east of the Iron Bridge, by William Reynolds and John Rose, producing Coalport porcelain.\n\nIn the 19th century, Coalbrookdale was noted for its decorative ironwork. It is here (for example) that the gates of London's Hyde Park were built. Other examples include the Coalbrookdale verandah at St John's in Monmouth, Wales, and as far away as the Peacock Fountain in Christchurch, New Zealand. The blast furnaces were closed down, perhaps as early as the 1820s, but the foundries remained in use. The Coalbrookdale Company became part of an alliance of ironfounding companies called Light Castings Limited. This was absorbed by Allied Ironfounders Limited in 1929. This was in turn taken over by Glynwed which has since become Aga Foodservice. The Coalbrookdale foundry closed in November 2017.\n\nSeveral of Coalbrookdale's industrial heritage sites are to be found on the local trail: including: Coalbrookdale railway station, the Quaker Burial Ground, the Darby Houses, Tea Kettle Row and the Great Western Railway Viaduct.\n\nIn the century after the Old Blast Furnace closed, it became buried. There was a proposal for the site to be cleared and the furnace dismantled, but instead, it was decided to excavate and preserve it. It and a small museum were opened to celebrate 250 years of the Company in 1959. This became part of a larger project, the Ironbridge Gorge Museums. Its Museum of Iron is based in the Great Warehouse constructed in 1838 and Ironbridge Institute is based in the Long Warehouse, these two form the sides of an open space. On another side of which is the Old Blast Furnace, now under a building (erected in 1981) to protect it from the weather. The fourth side is a viaduct carrying the railway that delivers coal to the Ironbridge Power Station. One of the two tracks is due to be taken over by Telford Steam Railway as part of its southern extension from Horsehay. The Museum's archaeology unit continues to investigate the earlier history of Coalbrookdale, and has recently excavated the remains of the 17th century cementation furnaces, near the site of the Upper (formerly Middle) Forge.\n\nThe Old Furnace began life as a typical blast furnace, but went over to coke in 1709. Abraham Darby I used it to cast pots, kettles and other goods. His grandson Abraham Darby III smelted the iron here for the first Ironbridge, the world's first iron bridge.\nThe lintels of the furnace bear dated inscriptions. The uppermost reads \"Abraham Darby 1777\", probably recording its enlargement for casting the Iron Bridge. It is unclear whether the date on one of the lower ones should be 1638 (as it is now painted) or 1658 (as shown on an old photo). The interior profile of the furnace is typical of its period, bulging around the middle, below which the boshes taper in again so that the charge descends into a narrower and hotter hearth, where the iron was molten. When Abraham Darby III enlarged the furnace, he only made the boshes wider on the front and left sides, but not on the right where doing so would have entailed moving the water wheel. The mouth of the furnace is thus off-centre.\n\nIron was now being made in large quantities for many customers. In the 1720s and 1730s, its main products were cast-iron cooking pots, kettles and other domestic articles. It also cast the cylinders for steam engines, and pig iron for use by other foundries. In the late 18th century, it sometimes produced structural ironwork, including for Buildwas Bridge. This was built in 1795, 2 miles up the river from the original Ironbridge. Due to advances in technology, it used only half as much cast iron despite being 30 feet (9 m) wider than the Ironbridge. The year after that, in 1796, Thomas Telford began a new project, Longdon-on-Tern Aqueduct. It carried the Shrewsbury Canal over the River Tern and was supported by cast-iron columns. Charles Bage designed and built the world's first multi-storey cast-iron-framed mill. It used only brick and iron, with no wood, to improve its fire-resistance. In the 19th century ornamental ironwork became a speciality.\n\n\n\n\n"}
{"id": "6832027", "url": "https://en.wikipedia.org/wiki?curid=6832027", "title": "Control Arms Campaign", "text": "Control Arms Campaign\n\nThe Control Arms Coalition is a campaign jointly run by a coalition of over 100 organisations including Amnesty International, IANSA, Oxfam International and Saferworld. \n\nThe campaign has been active since 2003 in calling for an international Arms Trade Treaty (ATT). The campaign began due to the lack of regulation in the international trade in arms. Control Arms has argued that the lack of controls on the arms trade is fuelling armed conflict, poverty and human rights abuses worldwide. Even though existing treaties and pieces of international law exist that focus on the international arms trade, none of them, before the Arms Trade Treaty, were legally binding and fully international.\n\nSince 2003 it has used a range of tactics to get its message across, including publicity stunts, mass public actions, petitions including the Million Faces campaign, worldwide public consultations, policy publications and the lobbying of politicians and diplomats across the world.\n\nThe process towards creating an international Arms Trade Treaty began in the United Nations in 2006. On April 2, 2013 the UN General Assembly voted overwhelmingly to adopt an international Arms Trade Treaty.\n\nThe Arms Trade Treaty began as an idea in an NGO meeting in the 1990s. At the end of the decade, after successfully lobbying to bring about the EU Code of Conduct on Arms Exporters, civil society groups worked with a group of Nobel Peace Prize Laureates to draft proposals for the regulation of the international arms trade. In 2001, they began to circulate a \"Draft Framework Convention on International Arms Transfers\" and sought the support of governments around the world.\n\nIn 2003, the Control Arms campaign began, campaigning for an international ATT in more than one hundred countries. One of the main elements of the early campaign was the 'Million Faces' petition. The petition brought together people from around the world who had suffered from armed conflict and armed violence as well as other supporters. The petition reached its goal in 2006, and the petition was presented to UN Secretary-General Kofi Annan by 'Millionth Face' Julius Arile, from Kenya.\n\nIn 2006, UN Members voted to consider states' views on a potential Treaty and convene an expert group, with only the United States against. Alongside this consultation Control Arms conducted a parallel 'People's Consultation', holding events in over one hundred countries. The intention was to use ordinary people's voices to influence government's responses to the UN consultation. Whereas similar consultations usually result in ten to fifteen responses, when the UN Secretary-General presented the findings in 2007, the ATT consultation had received over one hundred.\n\nBy 2009 the UN voted overwhelmingly in favour of convening negotiations on an ATT, with Zimbabwe the only vote against. States finally met In 2012 and 2013 to negotiate an ATT, all the while receiving significant input from civil society groups including Control Arms. On April 2, 2013, despite the objections of North Korea, Iran and Syria, the UN General Assembly voted overwhelmingly to support the ATT, in a 156-3-22 vote. The ATT has been open for signature since June 3, 2013.\n\nThroughout the Arms Trade Treaty process, Control Arms worked closely with supportive governments in their campaign for a strong ATT. The campaign has maintained close relations with the co-authors of the original Resolution in 2006 - Argentina, Australia, Costa Rica, Finland, Japan, Kenya and the United Kingdom - as well as working closely with other supportive governments.\n\nThe campaign, with teams focusing on legal and policy issues, has also provided expertise and support to states with limited resources at the United Nations.\n\nIn turn, members of Control Arms have also been members of delegations during the process, including with Finland, Mexico, New Zealand, Norway, Palau and the Solomon Islands.\n\nControl Arms have had a presence at all major meetings on the Arms Trade Treaty. In particular, representatives of the campaign participated in both UN negotiating conferences in July 2012 and March 2013, including making presentations on the views of civil society during plenary sessions.\n\nAs part of the ongoing process, the campaign organised petitions and other activities to engage the public with the campaign, culminating in a global call to \"Speak Out\" to get states to support a strong Arms Trade Treaty.\n\nControl Arms, alongside Reaching Critical Will, also operated a website tracking states' positions on the Arms Trade Treaty. Since April 2013, it also holds a record of states' votes for the final Resolution adopting the ATT, as well as a record of state signatures and ratifications.\n\nThe main aim of the Control Arms campaign, achieving an international Arms Trade Treaty, was effectively met on April 2, 2013 when the United Nations voted to adopt the text agreed at the negotiating conference the previous month.\n\nThe Treaty had been the work of a concerted campaign over the course of more than a decade, and is particularly noteworthy given the speed in which it was agreed, and that it was agreed through the UN system. The UN Conference on Disarmament has been at a stalemate for over 16 years. Comparative treaties, such as the Mine Ban Treaty and the Convention on Cluster Munitions, have had to find agreement outside the UN process.\n\nAs an indication of the centrality of civil society groups including Control Arms to the success of the process, a number of states, the UN Secretary-General Ban Ki-moon, and the President of the final negotiating conference all praised civil society for their contributions. Ban Ki-moon said that he commended \"the members of civil society for their tireless campaigns, expert contributions and unwavering support\". In a statement given whilst signing the Arms Trade Treaty as Australian Ambassador to the UN, the President of the final conference, Peter Woolcott, said that \"[s]tates did not do this alone. It is important we recognize the enormous contribution of civil society who have been advocating for this Treaty for many years, who informed our negotiations and who have an important role in the years ahead\".\n\nAlthough the main goal of the Control Arms campaign has been achieved - an international Arms Trade Treaty has been agreed - the campaign will continue to be involved in the Arms Trade Treaty process. Currently, Control Arms is pushing members to ask their state to sign the Arms Trade Treaty as soon as possible.\n\nIn the future, the campaign will seek to monitor states' compliance with the Arms Trade Treaty, and push for states to ensure strong and consistent application of the Treaty.\n\n\n"}
{"id": "912923", "url": "https://en.wikipedia.org/wiki?curid=912923", "title": "DiSEqC", "text": "DiSEqC\n\nDiSEqC (Digital Satellite Equipment Control), pronounced \"Die-Sec\", is a special communication protocol for use between a satellite receiver and a device such as a multi-dish switch or a small dish antenna rotor. DiSEqC was developed by European satellite provider Eutelsat, which now acts as the standards agency for the protocol.\n\nEutelsat apparently developed the system to allow satellite users in Continental Europe to switch between the more popular SES Astra satellites at 19.2° east and Eutelsat's own Hot Bird system at 13° east. As a result, the vast majority of European satellite receivers support DiSEqC 1.0 or higher, with the exception of all set top boxes manufactured under the Sky Digibox name. All supporting receivers have received certification to carry a logo specifying which variation of DiSEqC they support.\n\nDiSEqC relies only upon a coaxial cable to transmit both bidirectional data/signals and power. DiSEqC is commonly used to control switches and motors, and is more flexible than 13/18 volt and 22 kHz tone or ToneBurst/MiniDiSEqC techniques. DiSEqC is also compatible with the actuators used to rotate large C band dishes if used with a DiSEqC positioner. DiSEqC uses a pulsed (tone-burst) 22 kHz sine-wave at 0.65 V (± 0.25 V) peak to peak.\n\nThe \"Di\" (digital) part of the name refers to the digital nature of the signals used by the protocol and does not imply anything about the transmission that the dish is used to receive; DiSEqC may be used with both digital or analogue satellite systems.\n\nA number of versions of DiSEqC exist:\n\nFirst four variations were standardized by February 1998, prior to general use of digital satellite television. The later versions are backwards compatible with the lower revisions, but the lower revisions are, as might be expected, not forwards compatible with the higher revision numbers. 1.x and 2.x versions are both backwards and forwards compatible.\n\nThe terms DiSEqC 1.3 and 2.3 are also often used by manufacturers and retailers to refer to the use of DiSEqC with other protocols. For example, 1.3 usually refers to a receiver which uses USALS in conjunction with the DiSEqC 1.2 protocol. Such terminology has not been authorised by Eutelsat.\n\nThe following table shows compatibility between the various DiSEqC versions:\n\nNOTE: a 1.x receiver will not be able to receive communication from a switch or motor. Usually this is not important, as the switch or motor can be controlled by the receiver without problems.\n\n\n"}
{"id": "41033", "url": "https://en.wikipedia.org/wiki?curid=41033", "title": "Digital filter", "text": "Digital filter\n\nIn signal processing, a digital filter is a system that performs mathematical operations on a sampled, discrete-time signal to reduce or enhance certain aspects of that signal. This is in contrast to the other major type of electronic filter, the analog filter, which is an electronic circuit operating on continuous-time analog signals.\n\nA digital filter system usually consists of an analog-to-digital converter (ADC) to sample the input signal, followed by a microprocessor and some peripheral components such as memory to store data and filter coefficients etc. Finally a digital-to-analog converter to complete the output stage. Program Instructions (software) running on the microprocessor implement the digital filter by performing the necessary mathematical operations on the numbers received from the ADC. In some high performance applications, an FPGA or ASIC is used instead of a general purpose microprocessor, or a specialized digital signal processor (DSP) with specific paralleled architecture for expediting operations such as filtering.\n\nDigital filters may be more expensive than an equivalent analog filter due to their increased complexity, but they make practical many designs that are impractical or impossible as analog filters. Digital filters can often be made very high order, and are often finite impulse response filters which allows for linear phase response. When used in the context of real-time analog systems, digital filters sometimes have problematic latency (the difference in time between the input and the response) due to the associated analog-to-digital and digital-to-analog conversions and anti-aliasing filters, or due to other delays in their implementation.\n\nDigital filters are commonplace and an essential element of everyday electronics such as radios, cellphones, and AV receivers.\n\nA digital filter is characterized by its transfer function, or equivalently, its difference equation. Mathematical analysis of the transfer function can describe how it will respond to any input. As such, designing a filter consists of developing specifications appropriate to the problem (for example, a second-order low pass filter with a specific cut-off frequency), and then producing a transfer function which meets the specifications.\n\nThe transfer function for a linear, time-invariant, digital filter can be expressed as a transfer function in the \"Z\"-domain; if it is causal, then it has the form:\n\nwhere the order of the filter is the greater of \"N\" or \"M\".\nSee \"Z\"-transform's LCCD equation for further discussion of this transfer function.\n\nThis is the form for a recursive filter, which typically leads to an IIR infinite impulse response behaviour, but if the denominator is made equal to unity i.e. no feedback, then this becomes an FIR or finite impulse response filter.\n\nA variety of mathematical techniques may be employed to analyze the behaviour of a given digital filter. Many of these analysis techniques may also be employed in designs, and often form the basis of a filter specification.\n\nTypically, one characterizes filters by calculating how they will respond to a simple input such as an impulse. One can then extend this information to compute the filter's response to more complex signals.\n\nThe impulse response, often denoted formula_2 or formula_3, is a measurement of how a filter will respond to the Kronecker delta function. For example, given a difference equation, one would set formula_4 and formula_5 for formula_6 and evaluate. The impulse response is a characterization of the filter's behaviour. Digital filters are typically considered in two categories: infinite impulse response (IIR) and finite impulse response (FIR).\nIn the case of linear time-invariant FIR filters, the impulse response is exactly equal to the sequence of filter coefficients:\n\nIIR filters on the other hand are recursive, with the output depending on both current and previous inputs as well as previous outputs. The general form of an IIR filter is thus:\n\nPlotting the impulse response will reveal how a filter will respond to a sudden, momentary disturbance.\n\nIn discrete-time systems, the digital filter is often implemented by converting the transfer function to a linear constant-coefficient difference equation (LCCD) via the Z-transform. The discrete frequency-domain transfer function is written as the ratio of two polynomials. For example:\n\nThis is expanded:\n\nand to make the corresponding filter causal, the numerator and denominator are divided by the highest order of formula_11:\n\nThe coefficients of the denominator, formula_13, are the 'feed-backward' coefficients and the coefficients of the numerator are the 'feed-forward' coefficients, formula_14. The resultant linear difference equation is:\n\nor, for the example above:\n\nrearranging terms:\n\nthen by taking the inverse \"z\"-transform:\n\nand finally, by solving for formula_19:\n\nThis equation shows how to compute the next output sample, formula_19, in terms of the past outputs, formula_22, the present input, formula_23, and the past inputs, formula_24. Applying the filter to an input in this form is equivalent to a Direct Form I or II (see below) realization, depending on the exact order of evaluation.\n\nIn plain terms, for example, as used by a computer programmer implementing the above equation in code, it can be described as follows:\n\nformula_25 = the output, or filtered value<br>\nformula_26 = the input, or incoming raw value<br>\nformula_27 = the sample number, iteration number, or time period number\n\nand therefore:\n\nformula_19 = the current filtered (output) value<br>\nformula_29 = the last filtered (output) value<br>\nformula_30 = the 2nd-to-last filtered (output) value<br>\nformula_23 = the current raw input value<br>\nformula_32 = the last raw input value<br>\nformula_33 = the 2nd-to-last raw input value\n\nThe design of digital filters is a deceptively complex topic. Although filters are easily understood and calculated, the practical challenges of their design and implementation are significant and are the subject of much advanced research.\n\nThere are two categories of digital filter: the recursive filter and the nonrecursive filter. These are often referred to as infinite impulse response (IIR) filters and finite impulse response (FIR) filters, respectively.\n\nAfter a filter is designed, it must be \"realized\" by developing a signal flow diagram that describes the filter in terms of operations on sample sequences.\n\nA given transfer function may be realized in many ways. Consider how a simple expression such as formula_34 could be evaluated – one could also compute the equivalent formula_35. In the same way, all realizations may be seen as \"factorizations\" of the same transfer function, but different realizations will have different numerical properties. Specifically, some realizations are more efficient in terms of the number of operations or storage elements required for their implementation, and others provide advantages such as improved numerical stability and reduced round-off error. Some structures are better for fixed-point arithmetic and others may be better for floating-point arithmetic.\n\nA straightforward approach for IIR filter realization is direct form I, where the difference equation is evaluated directly. This form is practical for small filters, but may be inefficient and impractical (numerically unstable) for complex designs. In general, this form requires 2N delay elements (for both input and output signals) for a filter of order N.\n\nThe alternate direct form II only needs \"N\" delay units, where \"N\" is the order of the filter – potentially half as much as direct form I. This structure is obtained by reversing the order of the numerator and denominator sections of Direct Form I, since they are in fact two linear systems, and the commutativity property applies. Then, one will notice that there are two columns of delays (formula_36) that tap off the center net, and these can be combined since they are redundant, yielding the implementation as shown below.\n\nThe disadvantage is that direct form II increases the possibility of arithmetic overflow for filters of high \"Q\" or resonance. It has been shown that as \"Q\" increases, the round-off noise of both direct form topologies increases without bounds. This is because, conceptually, the signal is first passed through an all-pole filter (which normally boosts gain at the resonant frequencies) before the result of that is saturated, then passed through an all-zero filter (which often attenuates much of what the all-pole half amplifies).\n\nA common strategy is to realize a higher-order (greater than 2) digital filter as a cascaded series of second-order \"biquadratric\" (or \"biquad\") sections (see digital biquad filter). The advantage of this strategy is that the coefficient range is limited. Cascading direct form II sections results in \"N\" delay elements for filters of order \"N\". Cascading direct form I sections results in \"N\" + 2 delay elements, since the delay elements of the input of any section (except the first section) are redundant with the delay elements of the output of the preceding section.\n\nOther forms include:\n\nDigital filters are not subject to the component non-linearities that greatly complicate the design of analog filters. Analog filters consist of imperfect electronic components, whose values are specified to a limit tolerance (e.g. resistor values often have a tolerance of ±5%) and which may also change with temperature and drift with time. As the order of an analog filter increases, and thus its component count, the effect of variable component errors is greatly magnified. In digital filters, the coefficient values are stored in computer memory, making them far more stable and predictable.\n\nBecause the coefficients of digital filters are definite, they can be used to achieve much more complex and selective designs – specifically with digital filters, one can achieve a lower passband ripple, faster transition, and higher stopband attenuation than is practical with analog filters. Even if the design could be achieved using analog filters, the engineering cost of designing an equivalent digital filter would likely be much lower. Furthermore, one can readily modify the coefficients of a digital filter to make an adaptive filter or a user-controllable parametric filter. While these techniques are possible in an analog filter, they are again considerably more difficult.\n\nDigital filters can be used in the design of finite impulse response filters. Equivalent analog filters are often more complicated, as these require delay elements.\n\nDigital filters rely less on analog circuitry, potentially allowing for a better signal-to-noise ratio. A digital filter will introduce noise to a signal during analog low pass filtering, analog to digital conversion, digital to analog conversion and may introduce digital noise due to quantization. With analog filters, every component is a source of thermal noise (such as Johnson noise), so as the filter complexity grows, so does the noise.\n\nHowever, digital filters do introduce a higher fundamental latency to the system. In an analog filter, latency is often negligible; strictly speaking it is the time for an electrical signal to propagate through the filter circuit. In digital systems, latency is introduced by delay elements in the digital signal path, and by analog-to-digital and digital-to-analog converters that enable the system to process analog signals.\n\nIn very simple cases, it is more cost effective to use an analog filter. Introducing a digital filter requires considerable overhead circuitry, as previously discussed, including two low pass analog filters.\n\nAnother argument for analog filters is low power consumption. Analog filters require substantially less power and are therefore the only solution when power requirements are tight.\n\nWhen making an electrical circuit on a PCB it is generally easier to use a digital solution, because the processing units are highly optimized over the years. Making the same circuit with analog components would take up a lot more space when using discrete components. Two alternatives are FPAA's and ASIC's, but they are expensive for low quantities.\n\nMany digital filters are based on the fast Fourier transform, a mathematical algorithm that quickly extracts the frequency spectrum of a signal, allowing the spectrum to be manipulated (such as to create very high order band-pass filters) before converting the modified spectrum back into a time-series signal with an inverse FFT operation. These filters give O(n log n) computational costs whereas conventional digital filters tend to be O(n).\n\nAnother form of a digital filter is that of a state-space model.\nA well used state-space filter is the Kalman filter published by Rudolf Kalman in 1960.\n\nTraditional linear filters are usually based on attenuation. Alternatively nonlinear filters can be designed, including energy transfer filters which allow the user to move energy in a designed way. So that unwanted noise or effects can be moved to new frequency bands either lower or higher in frequency, spread over a range of frequencies, split, or focused. Energy transfer filters complement traditional filter designs and introduce many more degrees of freedom in filter design. Digital energy transfer filters are relatively easy to design and to implement and exploit nonlinear dynamics.\n\n\n"}
{"id": "32727975", "url": "https://en.wikipedia.org/wiki?curid=32727975", "title": "Digital marketing system", "text": "Digital marketing system\n\nA digital marketing system (DMS) is a method of centralized channel distribution used primarily by SaaS products. It combines a content management system (CMS) with syndication across the web, mobile, scannable surface, and social channels.\n\nA DMS publishes to web channels, usually in the form of a stand-alone website. It can manage any part of the web process, including web design, web hosting, domain registering, marketing, content creation and other standard methods of web promotion. The goal of web publication is to give the user a digital 'home' on the web, where clients, guests, fans and other web browsers arrive as a destination. Other methods of digital marketing often work to drive traffic to the web channel.\n\nAn example of a SaaS DMS services is HubSpot.\n\nA DMS publishes to popular social channels, including Facebook and Twitter as a means to communicate with fans, friends, followers, and customers and drive traffic to the user's website. The social publication can take the form of a status update, a text message, a 'tweet', a photo, a video and many other means of social communication. The idea is to find browsers in social spaces who might not otherwise be targeted. And that of which helps to communicate including social media networks for example Click here\n\nA DMS publishes to mobile devices, offering unique content formatted for those devices, such as the iPhone, iPad and Android phones. Mobile publication often takes the form of a mobile-optimized website theme, with larger navigation and a cleaner user interface. A mobile publication can also include 'apps' for devices that support them, 'push' notifications and SMS texting marketing.\n\nGaming is also a new form of Digital marketing, where creators custom makes games fit for a certain brand. It is used with larger navigation and an interface. It is the key factor to where mobile publication is included within the services.\n\nA set of a scannable surface includes tablet PC, publishing material, TV etc media. QR code enables traditional marketing channels to be utilized for a new digital transform. A quick scan on the QR code can guide viewers directly to the information they need without spending time on browsing and be searching, and the most valuable method of using QR code scan is to link to purchase basket.\n\nNFC or Near field communication is a growing technology used in information sharing, that is, cash transactions, access information and other personal information.\n\nDigital marketing is considered as a challenge for privacy because consumers' information is searched, collected, and used in the process of digital marketing without consumers' awareness. The privacy of customers is important because that it is related to customers' perceived value, satisfaction, loyalty, their trust on a company and performance of a company.\n\nBasic information：\n\nIn the traditional sense, private information mainly includes gender, age, education background, marital status and other basic information.\n\nIn the network society, private information also includes personalized digital information such as account passwords.\n\nActivity information：\n\nPrivate information refers to browsing history, purchasing records, location, social activities and so on \n\nAt present, the discussion on the consequences of privacy issues caused by digital marketing technology is increasingly focused on the possibility of illegal use of information. The information of consumers may become commodities, which will be exchanged or traded without the consumer's awareness and authorization.\n\nThe consumers' information is mainly exchanged or transacted in two forms. \nOne is that the related merchants share those data between each other. The other is that those data are sold by certain recommenders to a third party. For example, the data that can identify the financial status of consumers is very attractive to credit agencies. All these above increases the risk of consumer privacy.\n\nSome customers tend to choose the latter between a right of privacy and other favorable conditions. Pieces of evidence show that some customers are willing to allow merchants to use their personal information if they can have something to gain in return, even just small rewards, even though they do worry about their privacy may be invaded. In addition, digital marketing provide convenience to people. In the minds of some customers, this convenience is more important than their privacy, especially for teens. Nevertheless, most people are very concerned about whether their privacy is protected. It allows your brand to deliver relevant and targeted content to your customers, which leads to better conversation and customer retention.\n\nPermission marketing seems to be a good way to solve legal issues and privacy issues. It provides a suitable way to let merchants could connect with customers. Consumers can grant licenses only to a few merchants which are chosen from a large number of merchants. Permission marketing aims to make digital marketing matches the request of the law and provide consumers with information autonomy and.Krafft, M., Arden, C. and Verhoef, P. (2017). Permission Marketing and Privacy Concerns — Why Do Customers (Not) Grant Permissions?. \"Journal of Interactive Marketing\"</ref> The other solution is that merchants post privacy logs to promote transparency and accountability.\n\nThe General Data Protection Regulation (GDPR) is an example which meets the above requirements. It stipulates that merchants can collect customers' information only for specific, clear and legitimate purposes and deal with them only in a fair, transparent, and legal manner and merchants must protect these data. Customers should be informed that how will their data be used, what will be the effects and other relevant information in a concise, easy-to-understand and freeway so that they can clearly determine whether it is necessary to grant authorization or not. Except the right to be informed, the GDPR also provide customers with seven other rights such us the right of access, the right to erasure, the right to restrict processing, the right to object and establishes corresponding accountability system.\n"}
{"id": "15515769", "url": "https://en.wikipedia.org/wiki?curid=15515769", "title": "Double envelope house", "text": "Double envelope house\n\nA double envelope house is a passive solar house design which collects solar energy in a solarium and passively allows the warm air to circulate around the house between two sets of walls, a double building envelope. This design is from 1975 by Lee Porter Butler in the United States.\n\nLee Porter Butler's 1975 Double Envelope (Shell) design received wide publicity after the U.S. solar energy tax credits were created in 1978. Versions were on the cover of \"Better Homes and Gardens\" and \"Popular Science\" magazines.\n\nButler was an artistic/ecological building designer, a self-proclaimed \"Ekotect.\" He did not hold formal qualifications as an energy engineer.\nLee had built hundreds of homes, shopping centers and business buildings including banks and schools by the time he entered North Carolina State University to study architecture. He had studied engineering at Georgia Institute of Technology. Lee did not even have a high school diploma, but ended up teaching his invention of \"the gravity geo-thermal envelope\" at The University of California Berkeley in the Graduate School of design and Planning. Lee went to school for the education, not for the diploma. He was asked to speak at The Royal College of Science in London, where Sir Isaac Newton delivered Principia.\n\nLee's facile and curious mind led him his entire life to question methods by which humanity could live on the earth in harmony with the earth, and with each other. His most recent contribution to humanity \"Ekotecture\" is a totally self-sufficient way to live in harmony on the planet and to safeguard human life no matter what the external conditions. Lee felt that if we talk about sustainability we must talk about not just sustaining the earth, but the sustaining of human life. His contributions include a method whereby humanity can live peaceably and safely on the planet in cooperation.\n\nButler's experimental design was a form of isolated passive solar design that incorporated a passive heat distribution system. It attempted to address the problem of unequal distribution of heat that was associated with some direct gain systems. . This phenomenon is observed particularly in designs with inadequate thermal mass, poor cross ventilation and excessive polar facing windows.\n\nButler's design essentially composed of a house within a house. Thermal energy was captured from a south-facing solarium and heat was circulated by a natural convection flow loop in the cavity between the two building envelopes and through a sub-floor or via earth cooling tubes.\n\nA recirculating air flow path resulted from the warm (less-dense) air rising in a south-side solarium, and cooler (denser) air falling on the north side to create pressure differentials that automatically moved excess solar thermal gain from the south to the north side of the building without forced convection systems. Air flow was proportional to the differences in temperature between the two convection paths.\n\nIn the summer, shading devices eliminate all direct solar gain. Vents are opened at the top to exhaust hot air. Fresh air intake uses ambient temperature Earth to cool and dehumidify replacement air at the base.\n\nIn winter, the air in the cavity is buffered by warm ambient-temperature Earth under the floor (which is partially recharged by the natural convection flow loop during each winter day). In the summer, the convective flow is replaced with cooler near-ambient-temperature Earth replacement air, and the warm air exhausts by natural convection.\n\nThe original explanation provided for its efficiency was the thermal buffer that existed in the double envelope cavity. However, observers have also commented that the overall insulation of the design is higher with two walls instead of just one.\n\nWhile the design can perform better than a conventional home, formal performance monitoring suggested there were some problems with the original design. .\n\nCommentators have criticised the design on various grounds:\n\nSubsequent modifications have attempted to address these issues.\n\nA modification based on Butler's original design has been described but not yet formally evaluated. It attempted to eliminate some of the initial issues.\n\nAn important difference is the polar limb of the convection loop (thermal buffer zone/TBZ) is employed as a utility area e.g. laundry room, closets, pantry, and storage space. The laundry room also doubled as an area for clothes drying.\n\nAn external window is located on the polar side which can be opened to admit mild air into the TBZ during summer. An additional internal window separates the equatorial side living quarters. This can be opened to admit warm winter air from the solarium to enter directly into polar rooms.\n\nThe designer states that on cold winter days, the TBZ tempered with solar-heated air could be often above 85 degrees F, while the outside air was below freezing.\n\nCurrent technology makes it difficult to model the effects of these convective flow designs because computer performance simulation software does not presently incorporate these processes in their calculations.\n\n\nPassive solar design concepts\n\nSolar-designers\n"}
{"id": "22250817", "url": "https://en.wikipedia.org/wiki?curid=22250817", "title": "ESD simulator", "text": "ESD simulator\n\nAn ESD simulator, also known as an ESD gun, is a handheld unit used to test the immunity of devices to electrostatic discharge (ESD). These simulators are used in special electromagnetic compatibility (EMC) laboratories. ESD pulses are fast, high-voltage pulses created when two objects with different electrical charges come into close proximity or contact. Recreating them in a test environment helps to verify that the device under test is immune to static electricity discharges.\n\nESD testing is necessary to receive a CE mark, and for most suppliers of components for motor vehicles as part of required electromagnetic compatibility testing. It is often useful to automate these tests to eliminate the human factor.\n\nThere are three distinct test models for electrostatic discharge: human-body, machine, and charged-devices models. The human-body model emulates the action of a human body discharging static electricity, the machine model simulates static discharge from a machine, and the charged-device model simulates the charging and discharging events that occur in production processes and equipment.\n\nMany ESD guns have interchangeable modules containing different discharge Networks or RC Modules (Specific resistance and capacitance values) to simulate different discharges. These modules typically slide into the handle of the pistol portion of the ESD simulator, much like loading some handguns. They change the characteristics of the waveshape discharged from the pistol and are called out in general standards like IEC 61000-4-2, SAE J113 and industry specific standards like ISO 10605. Resistance is referred to in ohms (Ω), capacitance is referred to in picofarad (pF or \"puff\"). The most commonly used discharge network is for IEC 61000-4-2 and ISO 10605, expressed as 150pF/330Ω. There are over 50 combinations of resistance and capacitance depending on the standards and the applicable electronics.\n\nStandards that require ESD testing include:\n"}
{"id": "52786646", "url": "https://en.wikipedia.org/wiki?curid=52786646", "title": "Ecoplanet Bamboo Group", "text": "Ecoplanet Bamboo Group\n\nWinner of the U.S. Department of State's 2014 Award for Corporate Excellence\n, founded in 2010 by Troy Wiseman and Camille Rebelo, EcoPlanet Bamboo has pioneered the industrialization of bamboo as an alternative fiber for timber manufacturing industries. To date the Company has 37,250 acres of bamboo farms under ownership, in Central American, Western and Southern Africa, with larger scale plantations underway.\n\nEcoPlanet Bamboo is a privately owned United States Company, registered in Delaware and with corporate headquarters located outside of Chicago, Illinois. It is a US Series LLC allowing each geographic region and individual bamboo plantation to be funded and operated separately but under the same umbrella.\n\nThe Company has been recognized for its social impact created more than 750 jobs and operates in some of the poorest parts of the world in Nicaragua, South Africa and Ghana.\n\nEcoPlanet Bamboo plants species of tropical clumping (sympodial) bamboos, using only highly degraded and marginal land to produce a tree free, deforestation free fiber. The Company has developed a framework for what sustainability means in respect to bamboo. Farms reach maturity in 5–7 years and the fiber is targeted towards Fortune 500 companies dependent on wood and fiber as their raw resource.\n\nThe company is highly decentralized with individual bamboo plantations operating under EcoPlanet Bamboo Groups standardized operational framework to achieve Forest Landscape Restoration. A full set of qualified managerial staff exists on each farm and is overseen by a core managerial team.\n\nAlthough bamboo is a plant that has been grown and harvested in China for generations, it occurs only within a smallholder model. There are few commercial or large scale managed plantations. The majority of area under bamboo comprises plots of a few Mu in size, owned by individual farmers or families, and managed as part of a diverse mix of livelihood crops. Throughout China bamboo has been planted only in areas not suitable for agriculture, which generally mean mountainous land that is often inaccessible. Most of China's bamboo industry is focused on a single iconic species – Moso (\"Phyllostachys edulis\")\n\nThe processing of bamboo in China is dominated by low and medium level processing, with a large focus on two very different markets (1) the global handicraft industry and (2) the production of edible bamboo shoots for the food industry. In recent years there has been an increase in the production of bamboo flooring.\n\nEcoPlanet Bamboo is working in a different manner growing certified bamboo fiber for the pulp and paper industry, textiles and engineered timber.\n\nEcoPlanet Bamboo claims to have overcome many barriers to industrialize bamboo as a commercial crop:\n\nEcoPlanet Bamboo is a triple bottom line company promoting the concept of conscious capitalism. The company has pioneered the concept of sustainability certification for commercially produced bamboo. Nicaraguan farms are certified under the Forest Stewardship Council (FSC), the Verified Carbon Standard (VCS) and have gold level Climate Community Biodiversity Alliance (CCBA) stamp of approval. EcoPlanet Bamboo is the first entity to have received these certifications for application to bamboo.\n\nThe Company has been insured by the World Bank's Multilateral Insurance Guarantee Agency (MIGA), holding a $48 million policy. MIGA has featured EcoPlanet Bamboo for strong social and environmental impact.\n\nEcoPlanet Bamboo's farms are examples of private sector forest landscape restoration, with planted bamboo conserving and reconnecting remnant forest patches and scattered native vegetation, restoring soil functioning, water tables and carbon sinks.\n\nThis annual award was presented to EcoPlanet Bamboo by Secretary Kerry at the US State Department in 2014. EcoPlanet Bamboo was honored alongside the Coca Cola company for trendsetting good business practices in its countries of operation.\n"}
{"id": "8892017", "url": "https://en.wikipedia.org/wiki?curid=8892017", "title": "Electric guitar design", "text": "Electric guitar design\n\nElectric guitar design is a type of industrial design where the looks and efficiency of the shape as well as the acoustical aspects of the guitar are important factors. In the past many guitars have been designed with all kinds of odd shapes as well as very practical and convenient solutions to improve the usability of the object.\n\nThe first electrified fretted guitars were hollow-bodied archtop acoustic guitars to which some form of electromagnetic transducer had been attached. George Beauchamp invented the electric guitar by designing a lap steel guitar with a pickup. \n\nAt least one company, Audiovox, built and may have offered an electric solid-body as early as 1932. Audiovox electric guitars were built by Paul Tutmarc who is also credited as the co-inventor of the magnetic pickup along with Art Stimpson, and the fretted electric bass guitar. Bob Wisner worked for Paul converting tube radio amplifiers into guitar amplifiers and eventually developing his own amplifier circuits so Paul's instruments could be sold along with their own amplifiers. Paul was unsuccessful at obtaining a patent for his magnetic pickup as it was too similar to the telephone microphone coil sensor device. Audiovox production was handed over to Paul's son, Bud Tutmarc, who continued building these instruments under the brand, \"Bud-Electro\" until the early 1950s. Bud Tutmarc had been delegated by the senior Tutmarc the task of winding the pickup coils used on his father's and he continued producing them for his own guitars. He used horseshoe magnets in a single-coil and later a hum cancelling dual coil configuration. Bob Wisner was hired by Rickenbacher, later spelled \"Rickenbacker\" and may have passed on Tutmarc's magnetic pickup technology and helped them develop the more familiar bar magnet and pole-piece pickup construction still widely used today for their cast aluminum electric guitar, nicknamed The Frying Pan or The Pancake Guitar, beginning in 1933.\n\nAnother early solid body electric guitar was designed and built by musician and inventor Les Paul in the early 1940s, working after hours in the Epiphone Guitar factory. His log guitar (so called because it consisted of a simple 4x4 wood post with a neck attached to it and homemade pickups and hardware, with two detachable Swedish hollow body halves attached to the sides for appearance only) was patented and is often considered to be the first of its kind, although it shares nothing in design or hardware with the solid body \"Les Paul\" model sold by Gibson.\n\nIn 1950 and 1951, electronics and instrument amplifier maker Leo Fender through his company, designed the first commercially successful solid-body electric guitar with a single magnetic pickup, which was initially named the \"Esquire\". The two-pickup version of the Esquire was called the \"Broadcaster\". The bolt-on neck was consistent with Leo Fender's belief that the instrument design should be modular to allow cost-effective and consistent manufacture and assembly, as well as simple repair or replacement. The Broadcaster name was changed to Telecaster because of a legal dispute over the name. \n\nIn 1954, Fender introduced the Fender Stratocaster, or \"Strat\". It was positioned as a deluxe model and offered various product improvements and innovations over the Telecaster. These innovations included an ash or alder double-cutaway body design for badge assembly with an integrated vibrato mechanism (called a \"synchronized tremolo\" by Fender, thus beginning a confusion of the terms that still continues), three single-coil pickups, and body comfort contours. Leo Fender is also credited with developing the first commercially successful electric bass called the Fender Precision Bass, introduced in 1951.\n\nGibson, like many guitar manufacturers, had long offered semi-acoustic guitars with pickups, and previously rejected Les Paul and his \"log\" electric in the 1940s. In apparent response to the Telecaster, Gibson introduced the first Gibson Les Paul solid body guitar in 1952 (although Les Paul was actually brought in only towards the end of the design process for expert fine tuning of the nearly complete design and for marketing endorsement ). Features of the Les Paul include a solid mahogany body with a carved maple top (much like a violin and earlier Gibson archtop hollow body electric guitars) and contrasting edge binding, two single-coil \"soapbar\" pickups, a 24¾\" scale mahogany neck with a more traditional glued-in \"set\" neck joint, binding on the edges of the fretboard, and a tilt-back headstock with three machine heads (tuners) to a side. The earliest models had a combination bridge and trapeze-tailpiece design that was in fact designed by Les Paul himself, but was largely disliked and discontinued after the first year. Gibson then developed the Tune-o-matic bridge and separate stop tailpiece, an adjustable non-vibrato design that has endured. By 1957, Gibson had made the final major change to the Les Paul as we know it today - the humbucking pickup, or humbucker. The humbucker, invented by Seth Lover, was a dual-coil pickup which featured two windings connected out of phase and reverse-wound, in order to cancel the 60-cycle hum associated with single-coil pickups; as a byproduct, however, it also produces a distinctive, more \"mellow\" tone which appeals to many guitarists. The more traditionally designed and styled Gibson solid-body instruments were a contrast to Leo Fender's modular designs, with the most notable differentiator being the method of neck attachment and the scale of the neck (Gibson-24.75\", Fender-25.5\"). Each design has its own merits.\n\nIn 1962 Vox introduced the pentagonal Phantom guitar, originally made in England but soon after made by EKO of Italy. It was followed a year later by the teardrop-shaped Mark VI, the prototype of which was used by Brian Jones of The Rolling Stones. Vox guitars also experimented with onboard effects and electronics. The Teardrop won a prize for its design. In the mid 1960s, as the sound of electric 12 string guitar became popular, Vox introduced the Phantom XII and Mark XII electric 12 string guitars. Vox produced many more traditional 6 and 12 string electric guitars in both England and Italy. It may be noted that the Phantom guitar shape was quite similar to that of first fretted electric bass guitar, the Audiovox \"Electric Bass Fiddle\" of 1934.\n\nGuitarOrgan\n\nIn 1966 Vox introduced the revolutionary but problematic GuitarOrgan, a Phantom VI guitar with internal organ electronics. The instrument's trigger mechanism required a specially-wired plectrum that completed circuit connections to each fret, resulting in a very wide and unwieldy neck. John Lennon was given one in a bid to secure an endorsement, though this never panned out. According to \"Up-Tight: the Velvet Underground Story\", Brian Jones of the Rolling Stones also tried one; when asked by the Velvets if it \"worked\", his answer was negative. The instrument never became popular, but it was a precursor to the modern guitar synthesizer.\n\nIn recent years, guitars and basses with multi-scale or fanned-fret fingerboards started to appear. These instruments are supposed to offer an advantage over the classical fixed-scale guitars and basses by providing more freedom in setting the tension of each string at the design and manufacturing phases. This may result in a more uniform tension of the strings, as well as possibly offer timbre and tonal characteristics somewhat different from the usual fixed-scale instruments.\n\nAlso other materials than wood were used. Travis Bean as well as Kramer built guitars with aluminium necks. Danelectro used masonite bodies. Also plastic and carbon bodied guitars have been made in the past. The Gittler guitar was a design guitar made in the 80s. \n\n1991 saw the introduction of guitar designer Jol Dantzig's first truly workable acoustic-electric hybrid guitar design. The instrument, called the DuoTone, was conceived while Dantzig was at Hamer Guitars. (Dantzig was also the designer of the first 12 string bass.) Adapted by players like Ty Tabor, Stone Gossard, Elvis Costello and Jeff Tweedy, the DuoTone was a full \"duplex\" instrument that could switch between acoustic and electric tones. Recently there have been many entries in the hybrid category (capable of both acoustic and electric tones) including the T5 by Taylor, Michael Kelly's \"Hybrid,\" the Parker Fly and the Anderson Crowdster. \n\nIn the 90s the band Neptune began building weird looking metal guitar with 3rd bridge options incorporated. A predecessor of this type of guitars is the Pencilina. Linda Manzer designed the Pikasso guitar with multiple necks.\n"}
{"id": "7156988", "url": "https://en.wikipedia.org/wiki?curid=7156988", "title": "Electric water boiler", "text": "Electric water boiler\n\nAn electric water boiler, also called a thermo pot, is a consumer electronics small appliance used for boiling water and maintaining it at a constant temperature. It is typically used to provide an immediate source of hot water for making tea, hot chocolate, coffee, instant noodles, or baby formula, or for any other household use where clean hot water is required. They are a common component of Japanese kitchens and the kitchens of many East Asian countries but are found in varying use globally. Some thermo pots are designed with a feature that can purify water.\n\nBlack tea is typically steeped at \nwhile green tea is steeped at under . A number of thermo pot models offer an adjustable target temperature.\n\nAn electric water boiler consists of a water reservoir with a heating element at the bottom. Some models offer multiple temperature settings. Other models are part of larger water systems that boil water and provide hot, cold, and lukewarm water. Water may be dispensed in various ways, e.g. by pouring, an electric pump or by pressing a large button that functions as a diaphragm pump. Electric water boilers have a built in thermostat that detects when water has reached its boiling point of to automatically shut off.\n\nSedimentation is the accumulation within the water reservoir of natural minerals that exist in trace amounts in municipal water mains, mainly calcium carbonate. Heating the water causes the minerals to separate and fall to the bottom of the reservoir. This buildup can eventually create a variety of noises in gas boilers, reduce the efficiency of the unit and give rise to a sulfur (or rotten-egg) smell. Vinegar has been used to descale electric kettles.\n\n\n"}
{"id": "51207047", "url": "https://en.wikipedia.org/wiki?curid=51207047", "title": "Elissa Shevinsky", "text": "Elissa Shevinsky\n\nElissa Shevinsky is an American technology executive, entrepreneur, cybersecurity expert, public speaker and author.\n\nShevinsky attended Benjamin Cardozo High School before studying for a Political Theory major at Williams College, where she also took classes in Computer Science, graduating in 2001.\n\nIn 2010 Shevinsky defended her company against \"New York Times\", as co-owner of Neighborhoodies, over the use of the \"New York Herald Tribune\" logo on T-shirts. Shevinsky argued that the trademark had been abandoned. In 2012, she founded MakeOut Labs, a startup known for casual Jewish online dating in NYC.\n\nShevinsky co-founded Glimpse, an encrypted photo and video sharing app, with Pax Dickinson in 2013. At Glimpse, Shevinksy served as chief executive of the company. During her time at Glimpse, she experienced conflict with Dickinson over his defense of a pair of app developers accused of misogyny. He wrote on Twitter, \"It is not misogyny to tell a sexist joke, or to fail to take a woman seriously, or to enjoy boobies\". A few days afterwards, Shevinsky quit her job at Glimpse, citing the Twitter controversy as her reasoning. Shevinsky returned to Glimpse in December 2013, after Dickinson published an apology letter. In an agreement formed with Dickinson, Shevinsky would be the chief executive and public face of the company, would have to sign off on what he said in press conferences, and Glimpse would support women in technology.\n\nAfter Glimpse, Shevinsky was funded by MACH37 for Jekudo Privacy Company. In 2016, Shevinsky joined Brave as Head of Product.\n\nShevinsky has spoken and written on enterprise security policy. She spoke on the potential for social media to influence election outcomes at HOPE XI. Shevinsky is the founder and organizer of SecretCon.\n\nAs of 2018, Shevinsky is speaking on information security at universities and infosec conferences. She is chief operating officer of SoHo Token Labs, building developer tools for smart contracts.\n\nIn 2018, Shevinsky was named \"Woman of the Decade\" by Williams College in a speech where she announced she wanted to lead the way for the development and protection of privacy for the following decade.\n\nShevinsky considered herself \"a GamerGate neutral\". In a 2015 post Shevinsky wrote, \"I’d like to see less harassment. That’s my position. Less harassment, for everyone. I do hope this isn’t a controversial statement.\" When James Damore was fired by Google, Shevinsky was widely quoted saying that speech \"questioning the technical qualifications of people based on race or gender\" was potentially within the purview of Title VII of the Civil Rights Act, which prohibits employment discrimination based on race, color, religion, sex and national origin. As a Press Lead for the 2018 HOPE conference in NYC, Shevinsky called for stronger enforcement of the Code of Conduct.\n\n\nShevinsky appears in the documentary \"\". She is also a cast member in the documentary \"Silenced\".\n"}
{"id": "50401423", "url": "https://en.wikipedia.org/wiki?curid=50401423", "title": "Environmental Sample Processor", "text": "Environmental Sample Processor\n\nThe Monterey Bay Aquarium Research Institute's (MBARI's)] Environmental Sample Processor (ESP) is a \"lab in a can\" designed for autonomous deployment. The ESP—provides on-site (in situ) collection and analysis of water samples from the subsurface ocean. The instrument is an electromechanical/fluidic system designed to collect discrete water samples, concentrate microorganisms or particles, and automate application of molecular probes which identify microorganisms and their gene products. The ESP also archives samples so that further analyses may be done after the instrument is recovered.\n\nThe MBARI-designed Environmental Sample Processor was the first underwater robotic instrument to provide autonomous detection of both a HAB species and its toxin. This ability allows scientists, in near real-time, to determine whether or not an algal bloom is toxic, thus allowing better prediction and treatment of public or ecosystem health threats.\n\nThe NOAA Great Lakes Environmental Research Laboratory (GLERL) will deploy the first ever freshwater ESP in Lake Erie. This ESP will measure concentrations of particulate microcystins in the western basin of the lake, every other day. It can also genetically detect Microcystis and archive samples for future processing. With the addition of information from the ESPs, NOAA's suite of Lake Erie HAB products, (i.e. weekly Lake Erie HAB bulletin), and the Experimental HAB Tracker]), will have the ability to provide water managers with bloom location, projected direction, intensity, AND toxicity before the water reaches the intake.\n\nInitial deployments of the ESP took place in 2016: the first field tests of the communications and the microcystin detection happened in July. The ESP was re-deployed in August near the Toledo water intake crib for its first full mission. The Lake Erie ESP is deployed on a custom-built, underwater stationary mooring assembly. It samples the surface and in the water column, allowing the detection of microcystins as they relate to recreational risk (surface concentrations) or drinking water intake risk (at depth concentrations). After QC/QA, data is uploaded to NOAA’s Great Lakes Environmental Research Laboratory (GLERL) \"HABs and Hypoxia\" page to inform decision making by water managers and other stakeholders in near real-time.\n\nManagers without access to ESP data rely on 'in house' toxin testing, weekly sampling, surrogates (i.e. using algal pigment concentrations to infer risk of microcystins), or a combination of those. Toxins detected 'in house' are already either just outside the intake or present in the system. The ESP can provide managers earlier warning of blooms and toxicity. Correlations between data collected on toxicity and chlorophyll concentrations will be monitored in an effort to develop an experimental forecast of bloom toxicity.\n\nThe Lake Erie ESP was purchased by GLERL with funding from the EPA's Great Lakes Restoration Initiative. NOAA's National Centers for Coastal Ocean Science (NCCOS)] leads development of algal toxin sensors for ESPs. The technology to detect microcystins by ELISA assay) was developed by NCCOS, GLERL, and the Cooperative Institute for Limnology and Ecosystems Research. The viability of ESP technology to assist in monitoring and forecasting of marine HABs and their related toxins in California and the Gulf of Maine has been supported by NCCOS funding.\n\n"}
{"id": "38565046", "url": "https://en.wikipedia.org/wiki?curid=38565046", "title": "Federal Energy Agency (Russia)", "text": "Federal Energy Agency (Russia)\n\nRussian Energy Agency is a federal state budgetary organization under the Ministry of Energy of the Russian Federation, that provides implementation of the Federal Law \"Improvement of energy conservation and energy efficiency\", and the Government's activities in the field of energy efficiency and sustainable energy development of the Russian economy, innovative energy, renewable energy sources (RES). Furthermore, the Russian Energy Agency is a center for the exchange, monitoring of information, trainings, coordination and promotion of projects in the field of energy efficiency, renewable energy and innovation in the fuel and energy sector. The Russian Energy Agency has an extensive network of branches in 70 regions of the Russian Federation and employs over 2000 people.\n\nThe agency was established in December 2009 by converting the FSI \"Association\" Rosinformresurs \"Russian Energy Ministry (Order of the Ministry of Energy of the Russian Federation № 560 of December 16, 2009) in order to implement the major strategic targets for reducing energy intensity of the national economy by 40% by 2020, set by President of Russia Dmitry Medvedev ( Decree № 889 of June 4, 2008 \"On some measures to improve energy and environmental performance of the Russian economy\").\n"}
{"id": "26788410", "url": "https://en.wikipedia.org/wiki?curid=26788410", "title": "Historically Black Colleges and Universities Photographic Preservation Project", "text": "Historically Black Colleges and Universities Photographic Preservation Project\n\nThe Historically Black Colleges and Universities Photographic Preservation Project began in 2007 as a four-phase initiative to improve the preservation of significant photographic collections held within historically black colleges and universities in the United States (\"HBCUs\"). These collections document the visual and institutional history and legacy of HBCUs and form a core of primary research materials for the study of African American history. Ten HBCU institutions are participants.\n\nThe HBCU project is funded by a grant from the Andrew W. Mellon Foundation. Partners in the administration of the project include LYRASIS, the Art Conservation Department at the University of Delaware, the HBCU Library Alliance, the Conservation Center for Art and Historic Artifacts, and the Image Permanence Institute.\n\nThe project empowers the stewards of important collections by providing practical training in photograph preservation, assisting with prioritization of needed projects, stabilization of at-risk collections, and encouraging investment in preservation capacity-building within their institutions.\n\n\n"}
{"id": "177680", "url": "https://en.wikipedia.org/wiki?curid=177680", "title": "History of aviation", "text": "History of aviation\n\nThe history of aviation extends for more than two thousand years, from the earliest forms of aviation such as kites and attempts at tower jumping to supersonic and hypersonic flight by powered, heavier-than-air jets.\n\nKite flying in China dates back to several hundred years BC and slowly spread around the world. It is thought to be the earliest example of man-made flight.\n\nLeonardo da Vinci's 15th-century dream of flight found expression in several rational but unscientific designs, though he did not attempt to construct any of them.\n\nThe discovery of hydrogen gas in the 18th century led to the invention of the hydrogen balloon, at almost exactly the same time that the Montgolfier brothers rediscovered the hot-air balloon and began manned flights. Various theories in mechanics by physicists during the same period of time, notably fluid dynamics and Newton's laws of motion, led to the foundation of modern aerodynamics, most notably by Sir George Cayley.\n\nBalloons, both free-flying and tethered, began to be used for military purposes from the end of the 18th century, with the French government establishing Balloon Companies during the Revolution.\n\nThe term aviation, noun of action from stem of Latin avis \"bird\" with suffix -ation meaning action or progress, was coined in 1863 by French pioneer Guillaume Joseph Gabriel de La Landelle (1812–1886) in \"Aviation ou Navigation aérienne sans ballons\".\n\nExperiments with gliders provided the groundwork for heavier-than-air craft, and by the early-20th century, advances in engine technology and aerodynamics made controlled, powered flight possible for the first time. The modern aeroplane with its characteristic tail was established by 1909 and from then on the history of the aeroplane became tied to the development of more and more powerful engines.\n\nThe first great ships of the air were the rigid dirigible balloons pioneered by Ferdinand von Zeppelin, which soon became synonymous with airships and dominated long-distance flight until the 1930s, when large flying boats became popular. After World War II, the flying boats were in their turn replaced by land planes, and the new and immensely powerful jet engine revolutionised both air travel and military aviation.\n\nIn the latter part of the 20th century the advent of digital electronics produced great advances in flight instrumentation and \"fly-by-wire\" systems. The 21st century saw the large-scale use of pilotless drones for military, civilian and leisure use. With digital controls, inherently unstable aircraft such as flying wings became possible.\n\nFrom the earliest legends there have been stories of men strapping birdlike wings, stiffened cloaks or other devices to themselves and attempting to fly, typically by jumping off a tower. The Greek legend of Daedalus and Icarus is one of the earliest known; others originated from India, China and the European Middle Age. During this early period the issues of lift, stability and control were not understood, and most attempts ended in serious injury or death.\n\nIn the seventeenth century, the Algerian historian Ahmed Mohammed al-Maqqari stated that the Andalusian scientist Abbas ibn Firnas (810–887 A.D.) made a jump in Cordoba, Spain, covering his body with vulture feathers and attaching two wings to his arms. No other sources record the event. Writing in the twelfth century, William of Malmesbury stated that the eleventh century Benedictine monk Eilmer of Malmesbury attached wings to his hands and feet and flew a short distance. Beyond those based on William's account, there are no other known sources documenting Eilmer's life.\n\nMany others made well-documented jumps in the following centuries. As late as 1811, Albrecht Berblinger constructed an ornithopter and jumped into the Danube at Ulm.\n\nThe kite may have been the first form of man-made aircraft. It was invented in China possibly as far back as the 5th century BC by Mozi (Mo Di) and Lu Ban (Gongshu Ban). Later designs often emulated flying insects, birds, and other beasts, both real and mythical. Some were fitted with strings and whistles to make musical sounds while flying. Ancient and medieval Chinese sources describe kites being used to measure distances, test the wind, lift men, signal, and communicate and send messages.\n\nKites spread from China around the world. After its introduction into India, the kite further evolved into the fighter kite, where an abrasive line is used to cut down other kites.\n\nMan-carrying kites are believed to have been used extensively in ancient China, for both civil and military purposes and sometimes enforced as a punishment. An early recorded flight was that of the prisoner Yuan Huangtou, a Chinese prince, in the 6th Century AD. Stories of man-carrying kites also occur in Japan, following the introduction of the kite from China around the seventh century AD. It is said that at one time there was a Japanese law against man-carrying kites.\n\nThe use of a rotor for vertical flight has existed since 400 BC in the form of the bamboo-copter, an ancient Chinese toy. The similar \"moulinet à noix\" (rotor on a nut) appeared in Europe in the 14th century AD.\n\nFrom ancient times the Chinese have understood that hot air rises and have applied the principle to a type of small hot air balloon called a sky lantern. A sky lantern consists of a paper balloon under or just inside which a small lamp is placed. Sky lanterns are traditionally launched for pleasure and during festivals. According to Joseph Needham, such lanterns were known in China from the 3rd century BC. Their military use is attributed to the general Zhuge Liang (180–234 AD, honorific title \"Kongming\"), who is said to have used them to scare the enemy troops.\n\nThere is evidence that the Chinese also \"solved the problem of aerial navigation\" using balloons, hundreds of years before the 18th century.\n\nEventually some investigators began to discover and define some of the basics of rational aircraft design. Most notable of these was Leonardo da Vinci, although his work remained unknown until 1797, and so had no influence on developments over the next three hundred years. While his designs were at least rational, they were not based on particularly good science.\n\nLeonardo studied bird flight, analyzing it and anticipating many principles of aerodynamics. He did at least understand that \"An object offers as much resistance to the air as the air does to the object.\" Newton would not publish the Third law of motion until 1687.\n\nFrom the last years of the 15th century on he wrote about and sketched many designs for flying machines and mechanisms, including ornithopters, fixed-wing gliders, rotorcraft and parachutes. His early designs were man-powered types including ornithopters and rotorcraft, however he came to realise the impracticality of this and later turned to controlled gliding flight, also sketching some designs powered by a spring.\n\nIn 1670 Francesco Lana de Terzi published a work that suggested lighter than air flight would be possible by using copper foil spheres that, containing a vacuum, would be lighter than the displaced air to lift an airship. While theoretically sound, his design was not feasible: the pressure of the surrounding air would crush the spheres. The idea of using vacuum to produce lift is now known as vacuum airship but remains unfeasible with any current materials.\nIn 1709 Bartolomeu de Gusmão presented a petition to King John V of Portugal, begging for support for his invention of an airship, in which he expressed the greatest confidence. The public test of the machine, which was set for June 24, 1709, did not take place. According to contemporary reports, however, Gusmão appears to have made several less ambitious experiments with this machine, descending from eminences. It is certain that Gusmão was working on this principle at the public exhibition he gave before the Court on August 8, 1709, in the hall of the Casa da Índia in Lisbon, when he propelled a ball to the roof by combustion.\n\n1783 was a watershed year for ballooning and aviation. Between June 4 and December 1, five aviation firsts were achieved in France:\n\nBallooning became a major \"rage\" in Europe in the late 18th century, providing the first detailed understanding of the relationship between altitude and the atmosphere.\n\nNon-steerable balloons were employed during the American Civil War by the Union Army Balloon Corps. The young Ferdinand von Zeppelin first flew as a balloon passenger with the Union Army of the Potomac in 1863.\n\nIn the early 1900s ballooning was a popular sport in Britain. These privately owned balloons usually used coal gas as the lifting gas. This has half the lifting power of hydrogen so the balloons had to be larger, however coal gas was far more readily available and the local gas works sometimes provided a special lightweight formula for ballooning events.\n\nAirships were originally called \"dirigible balloons\" and are still sometimes called dirigibles today.\n\nWork on developing a steerable (or dirigible) balloon continued sporadically throughout the 19th century. The first powered, controlled, sustained lighter-than-air flight is believed to have taken place in 1852 when Henri Giffard flew in France, with a steam engine driven craft.\n\nAnother advance was made in 1884, when the first fully controllable free-flight was made in a French Army electric-powered airship, \"La France\", by Charles Renard and Arthur Krebs. The long, airship covered in 23 minutes with the aid of an 8½ horsepower electric motor.\n\nHowever, these aircraft were generally short-lived and extremely frail. Routine, controlled flights would not occur until the advent of the internal combustion engine (see below.)\n\nThe first aircraft to make routine controlled flights were non-rigid airships (sometimes called \"blimps\".) The most successful early pioneering pilot of this type of aircraft was the Brazilian Alberto Santos-Dumont who effectively combined a balloon with an internal combustion engine. On October 19, 1901 he flew his airship \"Number 6\" over Paris from the Parc de Saint Cloud around the Eiffel Tower and back in under 30 minutes to win the Deutsch de la Meurthe prize. Santos-Dumont went on to design and build several aircraft. Subsequent controversy surrounding his and others' competing claims with regard to aircraft overshadowed his great contribution to the development of airships.\n\nAt the same time that non-rigid airships were starting to have some success, the first successful rigid airships were also being developed. These would be far more capable than fixed-wing aircraft in terms of pure cargo carrying capacity for decades. Rigid airship design and advancement was pioneered by the German count Ferdinand von Zeppelin.\n\nConstruction of the first Zeppelin airship began in 1899 in a floating assembly hall on Lake Constance in the Bay of Manzell, Friedrichshafen. This was intended to ease the starting procedure, as the hall could easily be aligned with the wind. The prototype airship \"LZ 1\" (LZ for \"Luftschiff Zeppelin\") had a length of was driven by two Daimler engines and balanced by moving a weight between its two nacelles.\n\nIts first flight, on July 2, 1900, lasted for only 18 minutes, as LZ 1 was forced to land on the lake after the winding mechanism for the balancing weight had broken. Upon repair, the technology proved its potential in subsequent flights, bettering the 6 m/s speed attained by the French airship \"La France\" by 3 m/s, but could not yet convince possible investors. It would be several years before the Count was able to raise enough funds for another try.\n\nAlthough airships were used in both World War I and II, and continue on a limited basis to this day, their development has been largely overshadowed by heavier-than-air craft.\n\nItalian inventor Tito Livio Burattini, invited by the Polish King Władysław IV to his court in Warsaw, built a model aircraft with four fixed glider wings in 1647. Described as \"four pairs of wings attached to an elaborate 'dragon'\", it was said to have successfully lifted a cat in 1648 but not Burattini himself. He promised that \"only the most minor injuries\" would result from landing the craft. His \"Dragon Volant\" is considered \"the most elaborate and sophisticated aeroplane to be built before the 19th Century\".\n\nThe first published paper on aviation was \"Sketch of a Machine for Flying in the Air\" by Emanuel Swedenborg published in 1716. This flying machine consisted of a light frame covered with strong canvas and provided with two large oars or wings moving on a horizontal axis, arranged so that the upstroke met with no resistance while the downstroke provided lifting power. Swedenborg knew that the machine would not fly, but suggested it as a start and was confident that the problem would be solved. He wrote: \"It seems easier to talk of such a machine than to put it into actuality, for it requires greater force and less weight than exists in a human body. The science of mechanics might perhaps suggest a means, namely, a strong spiral spring. If these advantages and requisites are observed, perhaps in time to come some one might know how better to utilize our sketch and cause some addition to be made so as to accomplish that which we can only suggest. Yet there are sufficient proofs and examples from nature that such flights can take place without danger, although when the first trials are made you may have to pay for the experience, and not mind an arm or leg.\" Swedenborg would prove prescient in his observation that a method of powering of an aircraft was one of the critical problems to be overcome.\n\nBalloon jumping replaced tower jumping, also demonstrating with typically fatal results that man-power and flapping wings were useless in achieving flight. At the same time scientific study of heavier-than-air flight began in earnest. In 1837 French mathematician and brigadier general stated, \"Aviation will be successful only if one finds an engine whose ratio with the weight of the device to be supported will be larger than current steam machines or the strength developed by humans or most of the animals.\"\n\nSir George Cayley was first called the \"father of the aeroplane\" in 1846. During the last years of the previous century he had begun the first rigorous study of the physics of flight and would later design the first modern heavier-than-air craft. Among his many achievements, his most important contributions to aeronautics include:\n\nCayley's first innovation was to study the basic science of lift by adopting the whirling arm test rig for use in aircraft research and using simple aerodynamic models on the arm, rather than attempting to fly a model of a complete design.\n\nIn 1799 he set down the concept of the modern aeroplane as a fixed-wing flying machine with separate systems for lift, propulsion, and control.\n\nIn 1804 Cayley constructed a model glider which was the first modern heavier-than-air flying machine, having the layout of a conventional modern aircraft with an inclined wing towards the front and adjustable tail at the back with both tailplane and fin. A movable weight allowed adjustment of the model's centre of gravity.\nIn 1809, goaded by the farcical antics of his contemporaries (see above), he began the publication of a landmark three-part treatise titled \"On Aerial Navigation\" (1809–1810). In it he wrote the first scientific statement of the problem, \"The whole problem is confined within these limits, viz. to make a surface support a given weight by the application of power to the resistance of air.\" He identified the four vector forces that influence an aircraft: \"thrust\", \"lift\", \"drag\" and \"weight\" and distinguished stability and control in his designs. He also identified and described the importance of the cambered aerofoil, dihedral, diagonal bracing and drag reduction, and contributed to the understanding and design of ornithopters and parachutes.\n\nIn 1848 he had progressed far enough to construct a glider in the form of a triplane large and safe enough to carry a child. A local boy was chosen but his name is not known.\n\nHe went on to publish in 1852 the design for a full-size manned glider or \"governable parachute\" to be launched from a balloon and then to construct a version capable of launching from the top of a hill, which carried the first adult aviator across Brompton Dale in 1853.\n\nMinor inventions included the rubber-powered motor, which provided a reliable power source for research models. By 1808 he had even re-invented the wheel, devising the tension-spoked wheel in which all compression loads are carried by the rim, allowing a lightweight undercarriage.\n\nDrawing directly from Cayley's work, Henson's 1842 design for an aerial steam carriage broke new ground. Although only a design, it was the first in history for a propeller-driven fixed-wing aircraft.\n\n1866 saw the founding of the Aeronautical Society of Great Britain and two years later the world's first aeronautical exhibition was held at the Crystal Palace, London, where John Stringfellow was awarded a £100 prize for the steam engine with the best power-to-weight ratio. In 1848 Stringfellow achieved the first powered flight using an unmanned 10 ft wingspan steam-powered monoplane built in a disused lace factory in Chard, Somerset. Employing two contra-rotating propellers on the first attempt, made indoors, the machine flew ten feet before becoming destabilised, damaging the craft. The second attempt was more successful, the machine leaving a guide wire to fly freely, achieving some thirty yards of straight and level powered flight. Francis Herbert Wenham presented the first paper to the newly formed Aeronautical Society (later the Royal Aeronautical Society), \"On Aerial Locomotion\". He advanced Cayley's work on cambered wings, making important findings. To test his ideas, from 1858 he had constructed several gliders, both manned and unmanned, and with up to five stacked wings. He realised that long, thin wings are better than bat-like ones because they have more leading edge for their area. Today this relationship is known as the aspect ratio of a wing.\n\nThe latter part of the 19th century became a period of intense study, characterized by the \"gentleman scientists\" who represented most research efforts until the 20th century. Among them was the British scientist-philosopher and inventor Matthew Piers Watt Boulton, who studied lateral flight control and was the first to patent an aileron control system in 1868.\n\nIn 1871 Wenham and Browning made the first wind tunnel.\nMeanwhile, the British advances had galvanised French researchers. In 1857 Félix du Temple proposed a monoplane with a tail plane and retractable undercarriage. Developing his ideas with a model powered first by clockwork and later by steam, he eventually achieved a short hop with a full-size manned craft in 1874. It achieved lift-off under its own power after launching from a ramp, glided for a short time and returned safely to the ground, making it the first successful powered glide in history.\n\nIn 1865 Louis Pierre Mouillard published an influential book The Empire Of The Air (\"l'Empire de l'Air\").\nIn 1856, Frenchman Jean-Marie Le Bris made the first flight higher than his point of departure, by having his glider \"\"L'Albatros artificiel\" pulled by a horse on a beach. He reportedly achieved a height of 100 meters, over a distance of 200 meters.\nAlphonse Pénaud, a Frenchman, advanced the theory of wing contours and aerodynamics and constructed successful models of aeroplanes, helicopters and ornithopters. In 1871 he flew the first aerodynamically stable fixed-wing aeroplane, a model monoplane he called the \"Planophore\", a distance of . Pénaud's model incorporated several of Cayley's discoveries, including the use of a tail, wing dihedral for inherent stability, and rubber power. The planophore also had longitudinal stability, being trimmed such that the tailplane was set at a smaller angle of incidence than the wings, an original and important contribution to the theory of aeronautics. Pénaud's later project for an amphibian aeroplane, although never built, incorporated other modern features. A tailless monoplane with a single vertical fin and twin tractor propellers, it also featured hinged rear elevator and rudder surfaces, retractable undercarriage and a fully enclosed, instrumented cockpit.\nEqually authoritative as a theorist was Pénaud's fellow countryman Victor Tatin. In 1879 he flew a model which, like Pénaud's project, was a monoplane with twin tractor propellers but also had a separate horizontal tail. It was powered by compressed air. Flown tethered to a pole, this was the first model to take off under its own power.\n\nIn 1884 Alexandre Goupil published his work \"La Locomotion Aérienne\" (\"Aerial Locomotion\"), although the flying machine he later constructed failed to fly.\nIn 1890 the French engineer Clément Ader completed the first of three steam-driven flying machines, the Éole. On October 9, 1890 Ader made an uncontrolled hop of around 50 m (165 ft); this was the first manned airplane to take off under its own power. His Avion III of 1897, notable only for having twin steam engines, failed to fly: Ader would later claim success and was not debunked until 1910 when the French Army published its report on his attempt.\n\nSir Hiram Maxim was an American engineer who had moved to England. He built his own whirling arm rig and wind tunnel, and constructed a large machine with a wingspan of , a length of , fore and aft horizontal surfaces and a crew of three. Twin propellers were powered by two lightweight compound steam engines each delivering . Overall weight was . It was intended as a test rig to investigate aerodynamic lift: lacking flight controls it ran on rails, with a second set of rails above the wheels to restrain it. Completed in 1894, on its third run it broke from the rail, became airborne for about 200 yards at two to three feet of altitude and was badly damaged upon falling back to the ground. It was subsequently repaired, but Maxim abandoned his experiments shortly afterwards.\n\nIn the last decade or so of the 19th century, a number of key figures were refining and defining the modern aeroplane. Lacking a suitable engine, aircraft work focused on stability and control in gliding flight. In 1879 Biot constructed a bird-like glider with the help of Massia and flew in it briefly. It is preserved in the Musee de l'Air, France, and is claimed to be the earliest man-carrying flying machine still in existence.\n\nThe Englishman Horatio Phillips made key contributions to aerodynamics. He conducted extensive wind tunnel research on aerofoil sections, proving the principles of aerodynamic lift foreseen by Cayley and Wenham. His findings underpin all modern aerofoil design.\nOtto Lilienthal became known as the \"Glider King\" or \"Flying Man\" of Germany. He duplicated Wenham's work and greatly expanded on it in 1884, publishing his research in 1889 as \"Birdflight as the Basis of Aviation\" (\"Der Vogelflug als Grundlage der Fliegekunst\"). He also produced a series of hang gliders, including bat-wing, monoplane and biplane forms, such as the Derwitzer Glider and Normal soaring apparatus. Starting in 1891 he became the first person to make controlled untethered glides routinely, and the first to be photographed flying a heavier-than-air machine, stimulating interest around the world. He rigorously documented his work, including photographs, and for this reason is one of the best known of the early pioneers. Lilienthal made over 2,000 glides until his death in 1896 from injuries sustained in a glider crash.\n\nPicking up where Lilienthal left off, Octave Chanute took up aircraft design after an early retirement, and funded the development of several gliders. In the summer of 1896 his team flew several of their designs eventually deciding that the best was a biplane design. Like Lilienthal, he documented and photographed his work.\n\nIn Britain Percy Pilcher, who had worked for Maxim, built and successfully flew several gliders during the mid to late 1890s.\n\nThe invention of the box kite during this period by the Australian Lawrence Hargrave would lead to the development of the practical biplane. In 1894 Hargrave linked four of his kites together, added a sling seat, and flew . Later pioneers of manned kite flying included Samuel Franklin Cody in England and Captain Génie Saconney in France.\n\nAfter a distinguished career in astronomy and shortly before becoming Secretary of the Smithsonian Institution, Samuel Pierpont Langley started a serious investigation into aerodynamics at what is today the University of Pittsburgh. In 1891 he published \"Experiments in Aerodynamics\" detailing his research, and then turned to building his designs. He hoped to achieve automatic aerodynamic stability, so he gave little consideration to in-flight control. On May 6, 1896, Langley's \"Aerodrome No. 5\" made the first successful sustained flight of an unpiloted, engine-driven heavier-than-air craft of substantial size. It was launched from a spring-actuated catapult mounted on top of a houseboat on the Potomac River near Quantico, Virginia. Two flights were made that afternoon, one of and a second of , at a speed of approximately . On both occasions the \"Aerodrome No. 5\" landed in the water as planned, because in order to save weight, it was not equipped with landing gear. On November 28, 1896, another successful flight was made with the \"Aerodrome No. 6\". This flight, of , was witnessed and photographed by Alexander Graham Bell. The \"Aerodrome No. 6\" was actually \"Aerodrome No. 4\" greatly modified. So little remained of the original aircraft that it was given a new designation.\n\nWith the successes of the \"Aerodrome No. 5\" and \"No. 6\", Langley started looking for funding to build a full-scale man-carrying version of his designs. Spurred by the Spanish–American War, the U.S. government granted him $50,000 to develop a man-carrying flying machine for aerial reconnaissance. Langley planned on building a scaled-up version known as the Aerodrome A, and started with the smaller Quarter-scale Aerodrome, which flew twice on June 18, 1901, and then again with a newer and more powerful engine in 1903.\n\nWith the basic design apparently successfully tested, he then turned to the problem of a suitable engine. He contracted Stephen Balzer to build one, but was disappointed when it delivered only instead of he expected. Langley's assistant, Charles M. Manly, then reworked the design into a five-cylinder water-cooled radial that delivered at 950 rpm, a feat that took years to duplicate. Now with both power and a design, Langley put the two together with great hopes.\n\nTo his dismay, the resulting aircraft proved to be too fragile. Simply scaling up the original small models resulted in a design that was too weak to hold itself together. Two launches in late 1903 both ended with the \"Aerodrome\" immediately crashing into the water. The pilot, Manly, was rescued each time. Also, the aircraft's control system was inadequate to allow quick pilot responses, and it had no method of lateral control, and the \"Aerodrome\"s aerial stability was marginal.\n\nLangley's attempts to gain further funding failed, and his efforts ended. Nine days after his second abortive launch on December 8, the Wright brothers successfully flew their \"Flyer\". Glenn Curtiss made 93 modifications to the \"Aerodrome\" and flew this very different aircraft in 1914. Without acknowledging the modifications, the Smithsonian Institution asserted that Langley's \"Aerodrome\" was the first machine \"capable of flight\".\n\nGustave Weißkopf was a German who emigrated to the U.S., where he soon changed his name to Whitehead. From 1897 to 1915 he designed and built early flying machines and engines. On August 14, 1901, two and a half years before the Wright Brothers' flight, he claimed to have carried out a controlled, powered flight in his Number 21 monoplane at Fairfield, Connecticut. The flight was reported in the \"Bridgeport Sunday Herald\" local newspaper. About 30 years later, several people questioned by a researcher claimed to have seen that or other Whitehead flights.\n\nIn March 2013 \"Jane's All the World's Aircraft\", an authoritative source for contemporary aviation, published an editorial which accepted Whitehead's flight as the first manned, powered, controlled flight of a heavier-than-air craft. The Smithsonian Institution (custodians of the original Wright Flyer) and many aviation historians continue to maintain that Whitehead did not fly as suggested.\n\nUsing a methodological approach and concentrating on the controllability of the aircraft, the brothers built and tested a series of kite and glider designs from 1900 to 1902 before attempting to build a powered design. The gliders worked, but not as well as the Wrights had expected based on the experiments and writings of their 19th-century predecessors. Their first glider, launched in 1900, had only about half the lift they anticipated. Their second glider, built the following year, performed even more poorly. Rather than giving up, the Wrights constructed their own wind tunnel and created a number of sophisticated devices to measure lift and drag on the 200 wing designs they tested. As a result, the Wrights corrected earlier mistakes in calculations regarding drag and lift. Their testing and calculating produced a third glider with a higher aspect ratio and true three-axis control. They flew it successfully hundreds of times in 1902, and it performed far better than the previous models. By using a rigorous system of experimentation, involving wind-tunnel testing of airfoils and flight testing of full-size prototypes, the Wrights not only built a working aircraft, the Wright Flyer, but also helped advance the science of aeronautical engineering.\nThe Wrights appear to be the first to make serious studied attempts to simultaneously solve the power and control problems. Both problems proved difficult, but they never lost interest. They solved the control problem by inventing wing warping for roll control, combined with simultaneous yaw control with a steerable rear rudder. Almost as an afterthought, they designed and built a low-powered internal combustion engine. They also designed and carved wooden propellers that were more efficient than any before, enabling them to gain adequate performance from their low engine power. Although wing-warping as a means of lateral control was used only briefly during the early history of aviation, the principle of combining lateral control in combination with a rudder was a key advance in aircraft control. While many aviation pioneers appeared to leave safety largely to chance, the Wrights' design was greatly influenced by the need to teach themselves to fly without unreasonable risk to life and limb, by surviving crashes. This emphasis, as well as low engine power, was the reason for low flying speed and for taking off in a head wind. Performance, rather than safety, was the reason for the rear-heavy design, because the canard could not be highly loaded; anhedral wings were less affected by crosswinds and were consistent with the low yaw stability.\n\nAccording to the Smithsonian Institution and Fédération Aéronautique Internationale (FAI), the Wrights made the first sustained, controlled, powered heavier-than-air manned flight at Kill Devil Hills, North Carolina, four miles (8 km) south of Kitty Hawk, North Carolina on December 17, 1903.\n\nThe first flight by Orville Wright, of in 12 seconds, was recorded in a famous photograph. In the fourth flight of the same day, Wilbur Wright flew in 59 seconds. The flights were witnessed by three coastal lifesaving crewmen, a local businessman, and a boy from the village, making these the first public flights and the first well-documented ones.\n\nOrville described the final flight of the day: \"The first few hundred feet were up and down, as before, but by the time three hundred feet had been covered, the machine was under much better control. The course for the next four or five hundred feet had but little undulation. However, when out about eight hundred feet the machine began pitching again, and, in one of its darts downward, struck the ground. The distance over the ground was measured to be ; the time of the flight was 59 seconds. The frame supporting the front rudder was badly broken, but the main part of the machine was not injured at all. We estimated that the machine could be put in condition for flight again in about a day or two.\" They flew only about ten feet above the ground as a safety precaution, so they had little room to maneuver, and all four flights in the gusty winds ended in a bumpy and unintended \"landing\". Modern analysis by Professor Fred E. C. Culick and Henry R. Rex (1985) has demonstrated that the 1903 Wright Flyer was so unstable as to be almost unmanageable by anyone but the Wrights, who had trained themselves in the 1902 glider.\n\nThe Wrights continued flying at Huffman Prairie near Dayton, Ohio in 1904–05. In May 1904 they introduced the Flyer II, a heavier and improved version of the original Flyer. On June 23, 1905 they first flew a third machine, the Flyer III. After a severe crash on 14 July 1905, they rebuilt the Flyer III and made important design changes. They almost doubled the size of the elevator and rudder and moved them about twice the distance from the wings. They added two fixed vertical vanes (called \"blinkers\") between the elevators, and gave the wings a very slight dihedral. They disconnected the rudder from the wing-warping control, and as in all future aircraft, placed it on a separate control handle. When flights resumed the results were immediate. The serious pitch instability that hampered Flyers I and II was significantly reduced, so repeated minor crashes were eliminated. Flights with the redesigned Flyer III started lasting over 10 minutes, then 20, then 30. Flyer III became the first practical aircraft (though without wheels and needing a launching device), flying consistently under full control and bringing its pilot back to the starting point safely and landing without damage. On 5 October 1905, Wilbur flew in 39 minutes 23 seconds.\"\n\nAccording to the April 1907 issue of the \"Scientific American\" magazine, the Wright brothers seemed to have the most advanced knowledge of heavier-than-air navigation at the time. However, the same magazine issue also claimed that no public flight had been made in the United States before its April 1907 issue. Hence, they devised the Scientific American Aeronautic Trophy in order to encourage the development of a heavier-than-air flying machine.\n\nThis period saw the development of practical aeroplanes and airships and their early application, alongside balloons and kites, for private, sport and military use.\n\nAlthough full details of the Wright Brothers' system of flight control had been published in l'Aerophile in January 1906, the importance of this advance was not recognised, and European experimenters generally concentrated on attempting to produce inherently stable machines.\n\nShort powered flights were performed in France by Romanian engineer Traian Vuia on March 18 and August 19, 1906 when he flew 12 and 24 meters, respectively, in a self-designed, fully self-propelled, fixed-wing aircraft, that possessed a fully wheeled undercarriage. He was followed by Jacob Ellehammer who built a monoplane which he tested with a tether in Denmark on September 12, 1906, flying 42 meters.\n\nOn September 13, 1906, a day after Ellehammer's tethered flight and three years after the Wright Brothers' flight, Alberto Santos-Dumont made a public flight in Paris with the 14-bis, also known as \"Oiseau de proie\" (French for \"bird of prey\"). This was of canard configuration with pronounced wing dihedral, and covered a distance of on the grounds of the Chateau de Bagatelle in Paris' Bois de Boulogne before a large crowd of witnesses. This well-documented event was the first flight verified by the Aéro-Club de France of a powered heavier-than-air machine in Europe and won the Deutsch-Archdeacon Prize for the first officially observed flight greater than . On November 12, 1906, Santos-Dumont set the first world record recognized by the Federation Aeronautique Internationale by flying in 21.5 seconds. Only one more brief flight was made by the 14bis in March 1907, after which it was abandoned.\nIn March 1907 Gabriel Voisin flew the first example of his Voisin biplane. On 13 January 1908 a second example of the type was flown by Henri Farman to win the Deutsch-Archdeacon \"Grand Prix d'Aviation\" prize for a flight in which the aircraft flew a distance of more than a kilometer and landed at the point where it had taken off. The flight lasted 1 minute and 28 seconds.\n\nIn 1914, just before the start of World War I, Romania completed the world's first metal-built aircraft, Vlaicu III. It was captured by the Germans in 1916 and last seen at a 1942 aviation exhibition in Berlin.\n\nSantos-Dumont later added ailerons, between the wings in an effort to gain more lateral stability. His final design, first flown in 1907, was the series of Demoiselle monoplanes (Nos. 19 to 22). The \"Demoiselle No 19\" could be constructed in only 15 days and became the world's first series production aircraft. The Demoiselle achieved 120 km/h. The fuselage consisted of three specially reinforced bamboo booms: the pilot sat a seat between the main wheels of a conventional landing gear whose pair of wire-spoked mainwheels were located at the lower front of the airframe, with a tailskid half-way back beneath the rear fuselage structure. The Demoiselle was controlled in flight by a cruciform tail unit hinged on a form of universal joint at the aft end of the fuselage structure to function as elevator and rudder, with roll control provided through wing warping (No. 20), with the wings only warping \"down\".\n\nIn 1908 Wilbur Wright travelled to Europe, and starting in August gave a series of flight demonstrations at Le Mans in France. The first demonstration, made on 8 August, attracted an audience including most of the major French aviation experimenters, who were astonished by the clear superiority of the Wright Brothers' aircraft, particularly its ability to make tight controlled turns. The importance of using roll control in making turns was recognised by almost all the European experimenters: Henri Farman fitted ailerons to his Voisin biplane and shortly afterwards set up his own aircraft construction business, whose first product was the influential Farman III biplane.\n\nThe following year saw the widespread recognition of powered flight as something other than the preserve of dreamers and eccentrics. On 25 July Louis Blériot won worldwide fame by winning a £1,000 prize offered by the British \"Daily Mail\" newspaper for a flight across the English Channel, and in August around half a million people, including the President of France Armand Fallières and David Lloyd George, attended one of the first aviation meetings, the Grande Semaine d'Aviation at Reims.\n\nIn 1877, Enrico Forlanini developed an unmanned helicopter powered by a steam engine. It rose to a height of 13 meters, where it remained for some 20 seconds, after a vertical take-off from a park in Milan.\n\nThe first time a manned helicopter is known to have risen off the ground was on a tethered flight in 1907 by the Breguet-Richet Gyroplane. Later the same year the Cornu helicopter, also French, made the first rotary-winged free flight at Lisenux, France. However, these were not practical designs.\n\nAlmost as soon as they were invented, airplanes were used for military purposes. The first country to use them for military purposes was Italy, whose aircraft made reconnaissance, bombing and artillery correction flights in Libya during the Italian-Turkish war (September 1911 – October 1912). The first mission (a reconnaissance) occurred on 23 October 1911. The first bombing mission was flown on 1 November 1911. Then Bulgaria followed this example. Its airplanes attacked and reconnoitered the Ottoman positions during the First Balkan War 1912–13. The first war to see major use of airplanes in offensive, defensive and reconnaissance capabilities was World War I. The Allies and Central Powers both used airplanes and airships extensively.\n\nWhile the concept of using the airplane as an offensive weapon was generally discounted before World War I, the idea of using it for photography was one that was not lost on any of the major forces. All of the major forces in Europe had light aircraft, typically derived from pre-war sporting designs, attached to their reconnaissance departments. Radiotelephones were also being explored on airplanes, notably the SCR-68, as communication between pilots and ground commander grew more and more important.\n\nIt was not long before aircraft were shooting at each other, but the lack of any sort of steady point for the gun was a problem. The French solved this problem when, in late 1914, Roland Garros attached a fixed machine gun to the front of his plane, but while Adolphe Pegoud would become known as the first \"ace\", getting credit for five victories, before also becoming the first ace to die in action, it was German Luftstreitkräfte Leutnant Kurt Wintgens, who, on July 1, 1915, scored the very first aerial victory by a purpose-built fighter plane, with a synchronized machine gun.\n\nAviators were styled as modern-day knights, doing individual combat with their enemies. Several pilots became famous for their air-to-air combat; the most well known is Manfred von Richthofen, better known as the Red Baron, who shot down 80 planes in air-to-air combat with several different planes, the most celebrated of which was the Fokker Dr.I. On the Allied side, René Paul Fonck is credited with the most all-time victories at 75, even when later wars are considered.\n\nFrance, Britain, Germany and Italy were the leading manufacturers of fighter planes that saw action during the war, with German aviation technologist Hugo Junkers showing the way to the future through his pioneering use of all-metal aircraft from late 1915.\n\nThe years between World War I and World War II saw great advancements in aircraft technology. Airplanes evolved from low-powered biplanes made from wood and fabric to sleek, high-powered monoplanes made of aluminum, based primarily on the founding work of Hugo Junkers during the World War I period and its adoption by American designer William Bushnell Stout and Soviet designer Andrei Tupolev. The age of the great rigid airships came and went. The first successful rotorcraft appeared in the form of the autogyro, invented by Spanish engineer Juan de la Cierva and first flown in 1919. In this design, the rotor is not powered but is spun like a windmill by its passage through the air. A separate powerplant is used to propel the aircraft forwards.\nAfter World War I, experienced fighter pilots were eager to show off their skills. Many American pilots became barnstormers, flying into small towns across the country and showing off their flying abilities, as well as taking paying passengers for rides. Eventually the barnstormers grouped into more organized displays. Air shows sprang up around the country, with air races, acrobatic stunts, and feats of air superiority. The air races drove engine and airframe development—the Schneider Trophy, for example, led to a series of ever faster and sleeker monoplane designs culminating in the Supermarine S.6B. With pilots competing for cash prizes, there was an incentive to go faster. Amelia Earhart was perhaps the most famous of those on the barnstorming/air show circuit. She was also the first female pilot to achieve records such as crossing of the Atlantic and Pacific Oceans.\nOther prizes, for distance and speed records, also drove development forwards. For example, on June 14, 1919, Captain John Alcock and Lieutenant Arthur Brown co-piloted a Vickers Vimy non-stop from St. John's, Newfoundland to Clifden, Ireland, winning the £13,000 ($65,000) Northcliffe prize. The first flight across the South Atlantic and the first aerial crossing using astronomical navigation, was made by the naval aviators Gago Coutinho and Sacadura Cabral in 1922, from Lisbon, Portugal, to Rio de Janeiro, Brazil, with only internal means of navigation, in an aircraft specifically fitted for himself with an artificial horizon for aeronautical use, an invention that revolutionized air navigation at the time (Gago Coutinho invented a type of sextant incorporating two spirit levels to provide an artificial horizon). Five years later Charles Lindbergh took the Orteig Prize of $25,000 for the first \"solo\" non-stop crossing of the Atlantic. Months after Lindbergh, Paul Redfern was the first to solo the Caribbean Sea and was last seen flying over Venezuela.\n\nAustralian Sir Charles Kingsford Smith was the first to fly across the larger Pacific Ocean in the Southern Cross. His crew left Oakland, California to make the first trans-Pacific flight to Australia in three stages. The first (from Oakland to Hawaii) was 2,400 miles, took 27 hours 25 minutes and was uneventful. They then flew to Suva, Fiji 3,100 miles away, taking 34 hours 30 minutes. This was the toughest part of the journey as they flew through a massive lightning storm near the equator. They then flew on to Brisbane in 20 hours, where they landed on 9 June 1928 after approximately 7,400 miles total flight. On arrival, Kingsford Smith was met by a huge crowd of 25,000 at Eagle Farm Airport in his hometown of Brisbane. Accompanying him were Australian aviator Charles Ulm as the relief pilot, and the Americans James Warner and Captain Harry Lyon (who were the radio operator, navigator and engineer). A week after they landed, Kingsford Smith and Ulm recorded a disc for Columbia talking about their trip. With Ulm, Kingsford Smith later continued his journey being the first in 1929 to circumnavigate the world, crossing the equator twice.\n\nThe first lighter-than-air crossings of the Atlantic were made by airship in July 1919 by His Majesty's Airship R34 and crew when they flew from East Lothian, Scotland to Long Island, New York and then back to Pulham, England. By 1929, airship technology had advanced to the point that the first round-the-world flight was completed by the \"Graf Zeppelin\" in September and in October, the same aircraft inaugurated the first commercial transatlantic service. However, the age of the rigid airship ended following the destruction by fire of the zeppelin LZ 129 \"Hindenburg\" just before landing at Lakehurst, New Jersey on May 6, 1937, killing 35 of the 97 people aboard. Previous spectacular airship accidents, from the \"Wingfoot Express\" disaster (1919) to the loss of the R101 (1930), the \"Akron\" (1933) and the \"Macon\" (1935) had already cast doubt on airship safety, but with the disasters of the U.S. Navy's rigids showing the importance of solely using helium as the lifting medium; following the destruction of the Hindenburg, the remaining airship making international flights, the \"Graf Zeppelin\" was retired (June 1937). Its replacement, the rigid airship \"Graf Zeppelin II\", made a number of flights, primarily over Germany, from 1938 to 1939, but was grounded when Germany began World War II. Both remaining German zeppelins were scrapped in 1940 to supply metal for the German Luftwaffe; the last American rigid airship, the \"Los Angeles\", which had not flown since 1932, was dismantled in late 1939.\n\nMeanwhile, Germany, which was restricted by the Treaty of Versailles in its development of powered aircraft, developed gliding as a sport, especially at the Wasserkuppe, during the 1920s. In its various forms, in the 21st century sailplane aviation now has over 400,000 participants.\n\nIn 1929 Jimmy Doolittle developed instrument flight.\n\n1929 also saw the first flight of by far the largest plane ever built until then: the Dornier Do X with a wing span of 48 m. On its 70th test flight on October 21 there were 169 people on board, a record that was not broken for 20 years.\n\nLess than a decade after the development of the first practical rotorcraft of any type with the autogyro, in the Soviet Union, Boris N. Yuriev and Alexei M. Cheremukhin, two aeronautical engineers working at the \"Tsentralniy Aerogidrodinamicheskiy Institut\", constructed and flew the TsAGI 1-EA single rotor helicopter, which used an open tubing framework, a four blade main rotor, and twin sets of diameter anti-torque rotors; one set of two at the nose and one set of two at the tail. Powered by two M-2 powerplants, up-rated copies of the Gnome Monosoupape rotary radial engine of World War I, the TsAGI 1-EA made several successful low altitude flights. By 14 August 1932, Cheremukhin managed to get the 1-EA up to an unofficial altitude of with what is likely to be the first successful single-lift rotor helicopter design ever tested and flown.\n\nOnly five years after the German Dornier Do-X had flown, Tupolev designed the largest aircraft of the 1930s era, the \"Maksim Gorky\" in the Soviet Union by 1934, as the largest aircraft ever built using the Junkers methods of metal aircraft construction.\n\nIn the 1930s development of the jet engine began in Germany and in Britain – both countries would go on to develop jet aircraft by the end of World War II.\n\nWorld War II saw a great increase in the pace of development and production, not only of aircraft but also the associated flight-based weapon delivery systems. Air combat tactics and doctrines took advantage. Large-scale strategic bombing campaigns were launched, fighter escorts introduced and the more flexible aircraft and weapons allowed precise attacks on small targets with dive bombers, fighter-bombers, and ground-attack aircraft. New technologies like radar also allowed more coordinated and controlled deployment of air defense.\n\nThe first jet aircraft to fly was the Heinkel He 178 (Germany), flown by Erich Warsitz in 1939, followed by the world's first operational jet aircraft, the Me 262, in July 1942 and world's first jet-powered bomber, the Arado Ar 234, in June 1943. British developments, like the Gloster Meteor, followed afterwards, but saw only brief use in World War II. The first cruise missile (V-1), the first ballistic missile (V-2), the first (and to date only) operational rocket-powered combat aircraft Me 163—with attained velocities of up to in test flights—and the first vertical take-off manned point-defense interceptor, the Bachem Ba 349 \"Natter\", were also developed by Germany. However, jet and rocket aircraft had only limited impact due to their late introduction, fuel shortages, the lack of experienced pilots and the declining war industry of Germany.\n\nNot only airplanes, but also helicopters saw rapid development in the Second World War, with the introduction of the Focke Achgelis Fa 223, the Flettner Fl 282 synchropter in 1941 in Germany and the Sikorsky R-4 in 1942 in the USA.\n\nAfter World War II, commercial aviation grew rapidly, using mostly ex-military aircraft to transport people and cargo. This growth was accelerated by the glut of heavy and super-heavy bomber airframes like the B-29 and Lancaster that could be converted into commercial aircraft. The DC-3 also made for easier and longer commercial flights. The first commercial jet airliner to fly was the British de Havilland Comet. By 1952, the British state airline BOAC had introduced the Comet into scheduled service. While a technical achievement, the plane suffered a series of highly public failures, as the shape of the windows led to cracks due to metal fatigue. The fatigue was caused by cycles of pressurization and depressurization of the cabin, and eventually led to catastrophic failure of the plane's fuselage. By the time the problems were overcome, other jet airliner designs had already taken to the skies.\n\nUSSR's Aeroflot became the first airline in the world to operate sustained regular jet services on September 15, 1956 with the Tupolev Tu-104. The Boeing 707 and DC-8 which established new levels of comfort, safety and passenger expectations, ushered in the age of mass commercial air travel, dubbed the Jet Age.\n\nIn October 1947 Chuck Yeager took the rocket-powered Bell X-1 through the sound barrier. Although anecdotal evidence exists that some fighter pilots may have done so while dive bombing ground targets during the war, this was the first controlled, level flight to exceed the speed of sound. Further barriers of distance fell in 1948 and 1952 with the first jet crossing of the Atlantic and the first nonstop flight to Australia.\n\nThe 1945 invention of nuclear bombs briefly increased the strategic importance of military aircraft in the Cold War between East and West. Even a moderate fleet of long-range bombers could deliver a deadly blow to the enemy, so great efforts were made to develop countermeasures. At first, the supersonic interceptor aircraft were produced in considerable numbers. By 1955 most development efforts shifted to guided surface-to-air missiles. However, the approach diametrically changed when a new type of nuclear-carrying platform appeared that could not be stopped in any feasible way: intercontinental ballistic missiles. The possibility of these was demonstrated in 1957 with the launch of Sputnik 1 by the Soviet Union. This action started the Space Race between the nations.\n\nIn 1961, the sky was no longer the limit for manned flight, as Yuri Gagarin orbited once around the planet within 108 minutes, and then used the descent module of Vostok I to safely reenter the atmosphere and reduce speed from Mach 25 using friction and converting the kinetic energy of the velocity into heat. The United States responded by launching Alan Shepard into space on a suborbital flight in a Mercury space capsule. With the launch of the Alouette I in 1963, Canada became the third country to send a satellite into space. The space race between the United States and the Soviet Union would ultimately lead to the landing of men on the moon in 1969.\n\nIn 1967, the X-15 set the air speed record for an aircraft at or Mach 6.1. Aside from vehicles designed to fly in outer space, this record was renewed by X-43 in the 21st century.\n\nThe Harrier Jump Jet, often referred to as just \"Harrier\" or \"the Jump Jet\", is a British designed military jet aircraft capable of Vertical/Short Takeoff and Landing (V/STOL) via thrust vectoring. It first flew in 1969, the same year that Neil Armstrong and Buzz Aldrin set foot on the moon, and Boeing unveiled the Boeing 747 and the Aérospatiale-BAC Concorde supersonic passenger airliner had its maiden flight. The Boeing 747 was the largest commercial passenger aircraft ever to fly, and still carries millions of passengers each year, though it has been superseded by the Airbus A380, which is capable of carrying up to 853 passengers. In 1975 Aeroflot started regular service on the Tu-144—the first supersonic passenger plane. In 1976 British Airways and Air France began supersonic service across the Atlantic, with Concorde. A few years earlier the SR-71 Blackbird had set the record for crossing the Atlantic in under 2 hours, and Concorde followed in its footsteps.\n\nIn 1979 the Gossamer Albatross became the first human powered aircraft to cross the English channel. This achievement finally saw the realization of centuries of dreams of human flight.\n\nThe last quarter of the 20th century saw a change of emphasis. No longer was revolutionary progress made in flight speeds, distances and materials technology. This part of the century instead saw the spreading of the digital revolution both in flight avionics and in aircraft design and manufacturing techniques.\n\nIn 1986 Dick Rutan and Jeana Yeager flew an aircraft, the Rutan Voyager, around the world unrefuelled, and without landing. In 1999 Bertrand Piccard became the first person to circle the earth in a balloon.\n\nDigital fly-by-wire systems allow an aircraft to be designed with relaxed static stability. Initially used to increase the manoeuvrability of military aircraft such as the General Dynamics F-16 Fighting Falcon, this is now being used to reduce drag on commercial airliners.\n\nThe \"U.S. Centennial of Flight Commission\" was established in 1999 to encourage the broadest national and international participation in the celebration of 100 years of powered flight. It publicized and encouraged a number of programs, projects and events intended to educate people about the history of aviation.\n\n21st century aviation has seen increasing interest in fuel savings and fuel diversification, as well as low cost airlines and facilities. Additionally, much of the developing world that did not have good access to air transport has been steadily adding aircraft and facilities, though severe congestion remains a problem in many up and coming nations. Some 20,000 city pairs are served by commercial aviation, up from less than 10,000 as recently as 1996.\n\nThere appears to be newfound interest in returning to the supersonic era whereby waning demand and bureaucratic hurdles in the turn of the 20th century made flights unprofitable, as well as the final commercial stoppage of the Concorde due to a fatal accident.\n\nIn the beginning of the 21st century, digital technology allowed subsonic military aviation to begin eliminating the pilot in favor of remotely operated or completely autonomous unmanned aerial vehicles (UAVs). In April 2001 the unmanned aircraft Global Hawk flew from Edwards AFB in the US to Australia non-stop and unrefuelled. This is the longest point-to-point flight ever undertaken by an unmanned aircraft, and took 23 hours and 23 minutes. In October 2003 the first totally autonomous flight across the Atlantic by a computer-controlled model aircraft occurred. UAVs are now an established feature of modern warfare, carrying out pinpoint attacks under the control of a remote operator.\n\nMajor disruptions to air travel in the 21st century included the closing of U.S. airspace due to the September 11 attacks, and the closing of most of European airspace after the 2010 eruption of Eyjafjallajökull.\n\nIn 2015, André Borschberg flew a record distance of 4481 miles (7212 km) from Nagoya, Japan to Honolulu, Hawaii in a solar-powered plane, Solar Impulse 2. The flight took nearly five days; during the nights the aircraft used its batteries and the potential energy gained during the day.\n\n\n\n\n\n"}
{"id": "20242651", "url": "https://en.wikipedia.org/wiki?curid=20242651", "title": "IGeoSIT", "text": "IGeoSIT\n\niGeoSIT, the Interim Geo-Spatial Intelligence Tool, is a situational awareness tool developed by the NATO Communications and Information Agency (NCIA) used widely within NATO.\n\niGeoSIT consists of a web-enabled Java server client and a central server, running Apache and Tomcat. When a NATO person enters the URL for an iGeoSIT server, it checks first to see if the user has a locally cached copy of the client, a mapping utility. If the local cache exists, the Java application is loaded. If it does not, the Apache server send the java client application. The Java on the server side runs on Tomcat with proposed plans to one day run on a newer Java engine.\n\niGeoSIT servers respond similarly as ArcGIS, and other GIS servers, to WMS requests. WMS requests are tcp/IP messages where the server instructions are contained within the URL request to the webserver. It will contain requests for data layers, opacity, and different base maps. The request is replied with a JPG image and a redirect if there is a live overlay, such as current positions of a patrol or aircraft.\n\niGeoSIT clients are used by analysts and operators to geospatially reference events or perform terrain analysis. For example, a units current location can be visually compared to a SQL response which contains the geospatial data point for a nearby military outpost. The Java tool has things like rulers to physically measure distance(s), or draw shapes for export to PowerPoint for a mission brief, or event log.\n\n"}
{"id": "58644759", "url": "https://en.wikipedia.org/wiki?curid=58644759", "title": "Information engineering (field)", "text": "Information engineering (field)\n\nInformation engineering is the engineering discipline that deals with the generation, distribution, analysis, and use of information, data, and knowledge in systems. The field first became identifiable in the early 21st century.\n\nThe components of information engineering include more theoretical fields such as machine learning, artificial intelligence, control theory, signal processing, and information theory, and more applied fields such as computer vision, natural language processing, bioinformatics, medical image computing, cheminformatics, autonomous robotics, mobile robotics, and telecommunications. Many of these originate from computer science, as well as other branches of engineering such as computer engineering, electrical engineering, and bioengineering.\n\nThe field of information engineering is based heavily on mathematics, particularly probability, statistics, calculus, linear algebra, optimization, differential equations, variational calculus, and complex analysis.\n\nInformation engineers often hold a degree in information engineering or a related area, and are often part of a professional body such as the Institution of Engineering and Technology or Institute of Measurement and Control. They are employed in almost all industries due to the widespread use of information engineering.\n\nThe term information engineering used to refer to a software engineering methodology that is now more commonly known as \ninformation technology engineering or information engineering methodology. It began to gain its current meaning early on in the 21st century.\n\nMachine learning is the field that involves the use of statistical and probabilistic methods to let computers \"learn\" from data without being explicitly programmed. Data science involves the application of machine learning to extract knowledge from data.\n\nSubfields of machine learning include deep learning, supervised learning, unsupervised learning, reinforcement learning, semi-supervised learning, and active learning.\n\nCausal inference is another related component of information engineering.\n\nControl theory refers to the control of (continuous) dynamical systems, with the aim being to avoid delays, overshoots, or instability. Information engineers tend to focus more on control theory rather than the physical design of control systems and circuits (which tends to fall under electrical engineering).\n\nSubfields of control theory include classical control, optimal control, and nonlinear control.\n\nSignal processing refers to the generation, analysis and use of signals, which could take many forms such as image, sound, electrical, or biological.\n\nInformation theory studies the analysis, transmission, and storage of information. Major subfields of information theory include coding and data compression.\n\nComputer vision is the field that deals with getting computers to understand image and video data at a high level.\n\nNatural language processing deals with getting computers to understand human (natural) languages at a high level. This usually means text, but also often includes speech processing and recognition.\n\nBioinformatics is the field that deals with the analysis, processing, and use of biological data. This usually means topics such as genomics and proteomics, and sometimes also includes medical image computing.\n\nCheminformatics is the field that deals with the analysis, processing, and use of chemical data.\n\nRobotics in information engineering focuses mainly on the algorithms and computer programs used to control robots. As such, information engineering tends to focus more on autonomous, mobile, or probabilistic robots. Major subfields studied by information engineers include control, perception, SLAM, and motion planning.\n\nIn the past some areas in information engineering such as signal processing used analog electronics, but nowadays most information engineering is done with digital computers. Many tasks in information engineering can be parallelized, and so nowadays information engineering is carried out using CPUs, GPUs, and AI accelerators. There has also been interest in using quantum computers for some subfields of information engineering such as machine learning and robotics.\n\n"}
{"id": "198463", "url": "https://en.wikipedia.org/wiki?curid=198463", "title": "Kleenex", "text": "Kleenex\n\nKleenex is a brand name for a variety of paper-based products such as facial tissue, bathroom tissue, paper towels, tampons, and diapers. Often used informally as a genericized trademark for facial tissue in the United States, the name \"Kleenex\" is a registered trademark of Kimberly-Clark Worldwide, Inc. Kleenex products are manufactured in 30 countries and sold in more than 170 countries. Kleenex brands include Cottonelle, Huggies, and VIVA.\n\nThe first Japanese facial tissue, introduced in 1918 and originally marketed as a way to remove cold cream (it had been in use for centuries before in Japan; see History of facial tissue for details). It was a disposable substitute for face towels or cotton wool. In 1925, the first Kleenex tissue ad was used in magazines showing \"the new secret of keeping a pretty skin as used by famous movie stars...\". A few years after the introduction of Kleenex, the company's head researcher tried to persuade the head of advertising to try to market the tissue for colds and hay fever. The administrator declined the idea but then committed a small amount of ad space to mention of using Kleenex tissue as a handkerchief. By the 1930s, Kleenex was being marketed with the slogan “Don’t Carry a Cold in Your Pocket” and its use as a disposable handkerchief replacement became predominant. In 1943, Kleenex began licensing the Little Lulu cartoon character to popularize the brand.\n\nThe original Kleenex trademark application at the United States Patent and Trademark Office (USPTO) was filed in the class of Medical, Beauty, & Agricultural Services by Cellucotton Products Company of Neenah, Wisconsin, on Saturday, July 12, 1924. The description provided to the USPTO was \"absorbent pads or sheets for removing cold cream\".\n\nThe first use for the drawing and stylized word mark was on June 12, 1924, and its first use in commerce on June 12, 1924, as well. USPTO granted trademark registration on November 25, 1924. International Cellucotton Products Company officially assigned trademark interest and good will of the business to Kimberly-Clark Corporation on September 30, 1955. Kimberly-Clark Corporation of Neenah, Wisconsin is the current registered owner of the Kleenex trademark.\n\nIn the USA, the Kleenex name has become—in common usage but \"not\" in law—genericized: the popularity of the product has led to the use of its name to refer to any facial tissue, regardless of the brand. Many dictionaries, including Merriam-Webster and Oxford, now include definitions in their publications defining it as such.\n\n\n"}
{"id": "24384363", "url": "https://en.wikipedia.org/wiki?curid=24384363", "title": "List of Blu-ray player manufacturers", "text": "List of Blu-ray player manufacturers\n\nThis aims to be a complete list of Blu-ray manufacturers.\nThis list is not necessarily complete or up to date - if you see a manufacturer that should be here but isn't (or one that shouldn't be here but is), please update the page accordingly.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "13985780", "url": "https://en.wikipedia.org/wiki?curid=13985780", "title": "Livestock crush", "text": "Livestock crush\n\nA cattle crush (in UK, New Zealand, Ireland and Australia), squeeze chute (North America), standing stock, or simply stock (North America, Ireland) is a strongly built stall or cage for holding cattle, horses, or other livestock safely while they are examined, marked, or given veterinary treatment. Cows may be made to suckle calves in a crush. For the safety of the animal and the people attending it, a close-fitting crush may be used to ensure the animal stands \"stock still\". The overall purpose of a crush is to hold an animal still to minimise the risk of injury to both the animal and the operator while work on the animal is performed.\n\nCrushes were traditionally manufactured from wood; this, however, was prone to deterioration from the elements over time, as well as having the potential to splinter and cause injury to the animal. In recent years, most budget-quality crushes have been built using standard heavy steel pipe that is welded together, while superior quality crushes are now manufactured using doubly symmetric oval tubing for increasing bending strength, bruise minimisation and stiffness in stockyard applications. In Australia, the steel itself should ideally be manufactured to High Tensile Grade 350LO - 450LO and conform to Australian Standards AS 1163 for structural steel.\n\nCattle crushes may be fully fixed or mobile; however, most crushes are best classified as semipermanent, being potentially movable but designed to primarily stay in one place. A cattle crush is typically linked to a \"cattle race\" (also known as an \"alley\"). The front end has a \"head bail\" (or \"neck yoke\" or \"head gate\") to catch the animal and may have a baulk gate that swings aside to assist in catching the beast. The bail is often adjustable to accommodate animals of different sizes. This bail may incorporate a chin or neck bar to hold the animal's head still. A side lever operates the head bail to capture the animals, with the better types having a rear drop-away safety lever for easier movement of the cattle into the bail. Usually, smaller animals can walk through the head bails incorporated in crushes.\n\nLower side panels and/or gates of sheet metal, timber or conveyor belting are used in some cases to ensure animals’ legs do not get caught and reduce the likelihood of operator injury. At least one side gate is usually split to allow access to various parts of the animal being held, as well as providing access to feed a calf, amongst other things. A \"squeeze crush\" has a manual or hydraulic mechanism to squeeze the animal from the sides, immobilizing the animal while keeping bruising to a minimum. A sliding entrance gate, operated from the side of the crush, is set a few feet behind the captured animal to allow for clearance and prevent other animals entering. Crushes will, in many cases, have a single or split veterinary gate that swings behind the animal to improve operator safety, while preventing the animal from moving backwards by a horizontal \"rump bar\" inserted just behind its haunches into one of a series of slots. If this arrangement is absent, a palpation cage can be added to the crush for veterinary use when artificial insemination or pregnancy testing is being performed, or for other uses. Older crushes can also be found to have a guillotine gate that is also operated from the side via rope or chain where the gate is raised up for the animal to go under upon entering the crush, and then let down behind the animal.\n\nA crush is a permanent fixture in slaughterhouses, because the animal is carried on a conveyor restrainer under its belly, with its legs dangling in a slot on either side. Carried in this manner, the animal is unable to move either forward or backward by its own volition.\n\nSome mobile crushes are equipped with a set of wheels so they can be towed from yard to yard. A few of these portable crushes are built so the crush may also be used as a portable loading ramp. A mobile crush must incorporate a strong floor, to prevent the animal moving it by walking along the ground.\n\nCrushes vary in sophistication, according to requirements and cost. The simplest are just a part of a cattle race (alley) with a suitable head bail. More complex ones incorporate features such as automatic catching systems, hatches (to gain access to various parts of the animal), winches (to raise the feet or the whole animal), constricting sides to hold the animal firmly (normal in North American slaughterhouses), a rocking floor to prevent kicking or a weighing mechanism.\n\nSpecialist crushes are made for various purposes. For example, those designed for cattle with very long horns (such as Highland cattle or Texas Longhorn cattle) are low-sided or very wide, to avoid damage to the horns. Other specialist crushes include those for tasks such as automatic scanning, foot-trimming or clipping the hair under the belly, and smaller crushes (calf cradles) for calves.\n\nStanding stocks for cattle and horses are more commonly stand-alone units, not connected to races (alleys) except for handling animals not accustomed to being handled. These stand-alone units may be permanent or portable. Some portable units disassemble for transport to shows and sales. These units are used during grooming and also with veterinary procedures performed with the animal standing, especially if it requires heavy sedation, or to permit surgery under sedation rather than general anesthesia. For some surgical procedures, this is reported to be efficient. These units also are used during some procedures that require a horse to stand still, but without sedation.\n\nThere are two different types of specialised crushes used in rodeo arenas. Those for the \"rough stock\" events, such as bronc riding and bull riding, are known as bucking chutes or rough-riding chutes. For events such as steer roping, the crush is called a roping chute. The rough-riding chutes are notably higher in order to hold horses and adult bulls, and have platforms and rail spacing that allows riders and assistants to access the animal from above. These chutes release the animal and the rider through a side gate. A roping chute is large enough to contain a steer of the size used in steer wrestling and may have a seat above the chute for an operator. The steer or calf is released through the front of the chute.\n\nA hoof trimming crush, also called a hoof trimming chute or hoof trimming stalls, is a crush specifically designed for the task of caring for cattle hooves, specifically trimming excess hoof material and cleaning. Such crushes range from simple standing frameworks to highly complex fixed or portable devices where much or all of the process is mechanised. Many standard crushes now come with optional fitting kits to add to a non foot trimming crush.\n\nIn recent years, crushes are often integrated with weighing systems. The crush provides the ideal opportunity to weigh and measure the animal while it is safely contained within the unit.\n\nMany cattle producers managed herds with nothing more than a race (alley) and a headgate (or a rope) until tagging requirements and disease control necessitated the installation of crushes. \n\nIn the past the principal use of the crush, in England also known as a trevis, was for the shoeing of oxen. Crushes were, and in places still are, used for this purpose in North America and in many European countries. They were usually stand-alone constructions of heavy timbers or stone columns and beams. Some were simple, without a head bail or yoke, while others had more sophisticated restraints and mechanisms; a common feature is a belly sling which allows the animal to be partly or wholly raised from the ground. In Spain, the crush was a village community resource and is called , or \"shoeing frame\". In France it is called (plural \"travails\", not \"travaux\") or \"shoeing trevis\", and was associated with blacksmith shops. Although the word \"travail\" derives from Latin \"tripalium\", \"three beams\", all surviving examples but that at Roissard have four columns. In central Italy it is called a \"travaglio\", but in Sardinia is referred to as , or \"the machine for shoeing the oxen\". In the United States it was called an ox sling, an ox press or shoeing stalls. In some countries, including the Netherlands and France, horses were commonly shod in the same structures. In the United States similar but smaller structures, usually called horse shoeing stocks, are still in use, primarily to assist farriers in supporting the weight of the horse's hoof and leg when shoeing draft horses.\n\n"}
{"id": "24445354", "url": "https://en.wikipedia.org/wiki?curid=24445354", "title": "Low-voltage detect", "text": "Low-voltage detect\n\nA low-voltage detect (LVD) is a microcontroller or microprocessor peripheral that generates a reset signal when the Vcc supply voltage falls below Vref. Sometimes is combined with power-on reset (POR) and then it is called POR-LVD.\n\n"}
{"id": "50425805", "url": "https://en.wikipedia.org/wiki?curid=50425805", "title": "Magnetic self-protection", "text": "Magnetic self-protection\n\nMagnetic self-protection (MSP), also \"mine protection\" is an active measure to reduce the magnetic signature of a ship. This is needed so that the magnetic ignition mechanism of naval mines or torpedoes are not triggered.\n\nThe mere demagnetization is to be distinguished from that with which the permanent magnetic orientation of a metal hulk can be lifted with a strong magnetic field for some time.\n\nThe first magnetic self-protection equipment was developed at the beginning of World War II because of the advent of magnetically detonated mines. This was initially a cable which was placed along the entire length to the hull of the vessel and the application of direct current produced a magnetic field that counteracted the magnetic field of the steel mass of the vessel.\n\nDuring the second world war these methods of mine protection were standard for all large battle ships. A simple magnetic coil, however, was no longer capable of adequately compensating for the increasingly sophisticated magneto ignition, for the non-uniform magnetic field of a ship and for the variable effects of the Earth's magnetic field in different regions of the world.\n\nModern MSP systems consist of a plurality of electromagnetic coils which suppress the magnetic signature in several directions. For that, the signature of the vessel is accurately measured under various conditions first, so that the signature of counteracting magnetic fields can be suitably generated. For the majority of the vessels of the German Navy, this is done in the two magnetic measurement and treatment centers in Wilhelmshaven and Kiel.\n\nNot only must the uneven distribution of magnetic disturbances in the hull and the variable magnetic field in various areas of the world be taken into account, but also the movements of vessels (speed, rolling movements) or magnetic effects caused by units not constantly in use.\n\nAccordingly, an MSP system today does not generate a static magnetic field any more, but a magnetic field which is tailored depending on the location and movement, as well as various internal processes of the ship.\n\nIn so-called highly protected vessels, such as anti-mine vessels or submarines that by construction already have a low magnetic signature, it can be almost completely eliminated with the aid of MSP systems. The German Navy maintains an Earth's magnetic field simulator for this purpose in the Borgsted narrows at Schirnau-Lehmbek, in which the MSP system is adjusted accordingly for the entire vessel in various operating states and for different measured latitudes.\n"}
{"id": "4561186", "url": "https://en.wikipedia.org/wiki?curid=4561186", "title": "Mousehole (drilling)", "text": "Mousehole (drilling)\n\nThe mousehole is the storage area on a drilling rig where the next joint of drilling pipe is held until needed. This hole is in the floor of the rig, bored into the earth for a short way, and usually lined with a metal casing known as a scabbard.\n\nThe purpose is to have the top of the piece of drill pipe on a level with the kelly when the time comes to add the new piece of drill pipe.\n\n"}
{"id": "28333036", "url": "https://en.wikipedia.org/wiki?curid=28333036", "title": "Multi-channel analytics", "text": "Multi-channel analytics\n\nMulti-channel analytics refers to the business process whereby multiple sets of data from different sources (i.e. channels) are linked and/or housed together and then analysed to provide business and in particular customer and marketing intelligence - thereby guiding effective and successful decision-making.\n\nBusinesses interact with their users and potential clients across multiple channels including television, telephones, the Internet, mobile phones, and retail stores. Multi-channel analytics allows businesses to take data from all these sources and where possible make sense of it. This allows them to better understand, segment and therefore target their customers and potential users.\n\nMulti-channel analytics services are provided by a number of businesses including:\n\n\nMore on Multi-channel Analytics\">\n"}
{"id": "49145233", "url": "https://en.wikipedia.org/wiki?curid=49145233", "title": "National Air Duct Cleaners Association", "text": "National Air Duct Cleaners Association\n\nThe National Air Duct Cleaners Association (NADCA) is a non-profit organization committed to publishing standards for safety, evaluation, and cleaning of heating, ventilation, and air conditioning (HVAC) ducts. They also offer several certifications for HVAC companies and professionals, as well as maintain an anti-fraud task force.\n\nThe Division of Occupational Safety and Health of the United States Department of Labor recommends hiring only duct cleaning professionals who are NADCA members.\n\nThe NADCA was founded in 1989 when Pringle Power Vac owner John Sumerlin gathered 25 HVAC professionals to discuss the professional duct cleaning industry.\n\nFounded to promote the source removal method of duct cleaning and the establishment of industry standards, the NADCA currently offers training courses, publishes standards, provides professional resources, maintains an HVAC professional locator tool, and more.\n\nThe NADCA first published a standard, “Standard 1992-01, Mechanical Cleaning of Non-Porous Air Conveyance System Components,” in 1992. They currently publish “Standard for the Assessment, Cleaning, and Restoration of HVAC Systems,” called ACR: the NADCA Standard. The ACR provides guidelines for assessing HVAC systems, evaluating cleanliness, preventing hazards, cleaning methods, and cleaning equipment.\n\nPresently, the members of the NADCA are over 1,000 HVAC cleaning companies with one or more certified ASCS technicians.\n\nIn 1995, the NADCA began their first certification program, administering examinations for Air Systems Cleaning Specialist (ASCS) in Baltimore, Atlanta, Chicago, Dallas, and Los Angeles.\n\nIn 2003, they launched a Ventilation System Mold Remediator (VSMR) training and certification program, as well as a Certified Ventilation Inspector (CVI) training and certification program.\n\nIn 2013 NADCA decided to combine the ASCS and VSMR certifications into one certification, the ASCS. The present ASCS course has been revised to include the necessary VSMR training.\n\nThe ASCS and CVI programs are currently being offered.\n\n\n\n"}
{"id": "36284350", "url": "https://en.wikipedia.org/wiki?curid=36284350", "title": "Noricum scandal", "text": "Noricum scandal\n\nThe Noricum scandal, or Noricum affair was an Austrian arms export scandal centering on the illegal export of weapons to Iran, by VOEST subsidiary \"Noricum\" during the 1980s. It was named after the Roman geographical area Noricum.\n\n"}
{"id": "832032", "url": "https://en.wikipedia.org/wiki?curid=832032", "title": "Open Programming Language", "text": "Open Programming Language\n\nOpen Programming Language (OPL) is an embedded programming language for portable devices that run the Symbian Operating System.\n\nIt can be found on the Nokia 9200, 9300 and 9500 Communicator series mobile telephone/personal digital assistant (PDA) and the Sony Ericsson P800, P900, P910 series. On classic Psion PDAs such as the Series 3, 5/5mx, Series 7, and netBook/netPad, as well as the MC218, OPL is part of the standard application suite. OPL is also included in Psion Teklogix industrial handhelds such as the Workabout mx. OPL is an interpreted language similar to BASIC. A fully Visual Basic-compatible language OVAL has been also developed.\n\nThe language was originally called Organiser Programming Language, developed by Psion Ltd for the Psion Organiser. Designed by Colly Myers with the first iteration implemented by Richard Harrison and Martin Stamp. The first implementation (without graphics) was for the original Psion Organiser (now referred to as the Psion Organiser I, 1984), and it came bundled with the Science, Finance and Math data packs. It became truly accessible as built-in software in the Psion Organiser II (1986), and the language went on to be used in the Psion Series 3 and later. After Psion retired from the portable digital assistant market, the project was delayed until 2003, when the fledgling Symbian Developer Program released it as open source. The language is now developed on SourceForge in the opl-dev project.\n\nThe language is not available from Symbian OS v8 and later, mainly due to lack of interest and support from major Symbian licencees Nokia and Sony Ericsson. Hence, OPL will most likely never be made available for the newer generation of Symbian OS phones such as Sony Ericsson P990, M600, W950, P1i and Nokia E61i and E90. As of 2010, Nokia device developers are encouraged to use Python for S60 instead (See Python for S60).\n\nHere is the console version of a Hello world program:\n\nAnd here is a GUI version for Nokia's Series 80 user interface:\n\nOPL is a structured programming language. OPL programs contain PROCedures, which are much like functions in other programming languages.\n\nAn example:\n\nIn this cruel interrogative program, the Yes button is assigned the shortcut of Ctrl+y, while No has Ctrl+n, represented by %y and %n respectively. The user's input from the DIALOG is tested in the IF statement, PRINTing appropriate responses to the screen. Note that the 'GET' keyword, which gets user input without using a dialog box, is here used simply to wait for a keypress before terminating the program (otherwise it would end immediately without giving time for the user to read the text). The output from DIALOG can also be stored in a variable.\n\nVariables specific to a procedure must be declared with the LOCAL keyword; global variables are defined with the GLOBAL keyword.\n\nThe table below uses an example variable called 'var'.\n\nOPL interfaced with advanced Psion Series 3 features by means of operating system CALLs, but in the later Psion Series 5mx this was changed to a so-called 'OPX' library, stored in the system ROM (the Z drive). 'OPX' libraries were also made available for the Nokia 9210, Nokia 9300 and Nokia 9500 Communicators, adding OPXs routines for handling SMS and managing Bluetooth communication.\n\nOther OPL features include those with a letter 'g' at the beginning, for graphical functions; those with a letter 'm', for menus; and those with a letter 'd', for dialogs.\n\n\n"}
{"id": "40520995", "url": "https://en.wikipedia.org/wiki?curid=40520995", "title": "Oshiroi", "text": "Oshiroi\n\n\"白粉\" literally means \"white powder\", while the pronunciation \"oshiroi\" means \"white\" (\"shiroi\") with the honorific prefix \"o-\".\n\n"}
{"id": "8159055", "url": "https://en.wikipedia.org/wiki?curid=8159055", "title": "Out of wallet", "text": "Out of wallet\n\nOut of Wallet refers to private data used for authentication in activities such as telephone banking or internet banking to prevent identity theft. The practice may part of a knowledge-based authentication process.\n\nIdeally, out of wallet information is easily recallable by a user but obscure to most other persons and difficult for them to uncover. Prompts for out of wallet questions are now often generated automatically through convergence of databases containing users' financial transactions, vehicle registrations, and other records.\n\nTypical out of wallet questions a user may be asked include:\n\n\nSuch information is available to a database compiler but may not be readily available to criminals attempting to commit identity theft.\n"}
{"id": "26602975", "url": "https://en.wikipedia.org/wiki?curid=26602975", "title": "Package testing", "text": "Package testing\n\nPackage testing or packaging testing involves the measurement of a characteristic or property involved with packaging. This includes packaging materials, packaging components, primary packages, shipping containers, and unit loads, as well as the associated processes.\n\nTesting measures the effects and interactions of the levels of packaging, the package contents, external forces, and end-use.\n\nIt can involve controlled laboratory experiments, subjective evaluations by people, or field testing. Documentation is important: formal test method, test report, photographs, video, etc.\n\nTesting can be a qualitative or quantitative procedure. Package testing is often a physical test. With some types of packaging such as food and pharmaceuticals, chemical tests are conducted to determine suitability of food contact materials. Testing programs range from simple tests with little replication to more thorough experimental designs.\n\nPackage testing can extend for the full life cycle. Packages can be tested for their ability to be recycled and their ability to degrade as surface litter, in a sealed landfill or under composting conditions.\n\nPackaging testing might have a variety of purposes, such as:\n\nPackaging tests can be used for:\n\nFor some types of products, package testing is mandated by regulations: food. pharmaceuticals, medical devices, dangerous goods, etc. This may cover both the design qualification, periodic retesting, and control of the packaging processes. Processes may be controlled by a variety of quality management systems such as HACCP, statistical process control, validation protocols, ISO 9000, etc.\n\nFor unregulated products, testing can be required by a contract or governing specification. The degree of package testing can often be a business decision. Risk management may involve factors such as\n\nWith distribution packaging, one vital packaging development consideration is to determine if a packaged-product is likely to be damaged in the process of getting to the final customer. A primary purpose of a package is to ensure the safety of a product during transportation and storage. If a product is damaged during this process, then the package has failed to accomplish a primary objective and the customer will either return the product or be unlikely to purchase the product altogether.\n\nPackage testing is often a formal part of Project management programs. Packages are usually tested when there is a new packaging design, a revision to a current design, a change in packaging material, and various other reasons. Testing a new packaging design before full scale manufacturing can save time and money.\n\nMany suppliers or vendors offer limited material and package testing as a free service to customers. It is common for packagers to partner with reputable suppliers: Many suppliers have certified quality management systems such as ISO 9000 or allow customers to conduct technical and quality audits. Data from testing is commonly shared. There is sometimes a risk that supplier testing may tend to be self-serving and not completely impartial.\n\nLarge companies often have their own packaging staff and a package testing and development laboratory. Corporate engineers know their products, manufacturing capabilities, logistics system, and their customers best. Cost reduction of existing products and cost avoidance for new products have been documented.\n\nAnother option is to use a paid consultant, Independent contractor, and third-party independent testing laboratory. They are commonly chosen for specialized expertise, for access to certain test equipment, for surge projects, or where independent testing is otherwise required. Many have certifications and accreditations: ISO 9000, ISO/IEC 17025, and various governing agencies.\n\nSeveral standards organizations publish test methods for package testing. Included are:\nGovernments and regulators publish some packaging test methods. There are also many corporate test standards in use. A review of technical literature and patents provides good options to consider for test procedures.\n\nResearchers are not restricted to the use of published standards but can modify existing test methods or develop procedures specific to their particular needs. If a test is conducted with a deviation from a published test method or if a new method is employed, the test report must fully disclose the procedure.\n\nThe basis of packaging design and performance is the component materials. The physical properties, and sometimes chemical properties, of the materials need to be communicated to packaging engineers to aid in the design process. Suppliers publish data sheets and other technical communications that include the typical or average relevant physical properties and the test method these are based upon. Sometimes these are adequate. Other times, additional material and component testing is required by the packager or supplier to better define certain characteristics.\n\nWhen a final package design is complete, the specifications for the component materials needs to be communicated to suppliers. Packaging materials testing is often needed to identify the critical material characteristics and engineering tolerances. These are used to prepare and enforce specifications.\n\nFor example, shrink film data might include: tensile strength (MD and CD), elongation, Elastic modulus, surface energy, thickness, Moisture vapor transmission rate, Oxygen transmission rate, heat seal strength, heat sealing conditions, heat shrinking conditions, etc. Average and process capability are often provided. The chemical properties related for use as Food contact materials may be necessary.\n\nSome types of package testing do not use scientific instruments but use people for the evaluation.\n\nThe regulations for child-resistant packaging require a test protocol that involves children. Samples of the test packages are given to a prescribed population of children. With specified 50-child panels, a high percentage must be unable to open a test package within 5 minutes.\nAdults are also tested for their ability to open a child-resistant package.\n\nConsumer packages are often evaluated by focus groups. People evaluate the package features in a room monitored by video cameras. The consumer responses are treated qualitatively for feedback into the new packaging process.\n\nSome food packagers use organoleptic evaluations. People use their senses (taste, smell, etc.) to determine if a package component has tainted the food in the package.\n\nA new package may be evaluated in a test market that uses people to try the packages at home. Consumers have the opportunity to buy a product, perhaps with a coupon or discount. Return postcards or Internet sites provide feedback to package developers. Perhaps the most critical feedback is repeated sales items in the new package. Packaging evaluations are an important part of marketing research.\n\nLegibility of text on packaging and labels is always subjective due to the inherent variations of people. Efforts have been made to help better quantify this by people in a laboratory: still using people for the evaluation but also employing a test apparatus to help reduce variability.\n\nSome laboratory tests are conducted but still result in an observation by people. Some test procedures call for a judgment by test engineers whether or not pre-established acceptance criteria have been met.\n\nThe environmental conditions of testing are critical. The measured performance of many packages is affected by the conditioning and testing atmospheres. For example, paper based products are strongly affected by their moisture content: Relative humidity needs to be controlled. Plastic products are often strongly affected by temperature.\n\nConditions of 23 °C (73.4 °F) and 50% relative humidity are common but other standard testing conditions are also published in material and package test standards. Engineering tolerances for the conditions are also specified. Often the package is conditioned to the specified environment and tested under those conditions. This can be in a conditioned room or in a chamber enclosing the test. With some testing, the package is conditioned to a specified environment, then is removed to ambient conditions and quickly tested. The test report needs to state the actual conditions used.\n\nEngineers have found it important to know the effects of the full range of expected conditions on package performance. This can be through investigating published technical literature, obtaining supplier documentation, or by conducting controlled tests at diverse conditions.\n\nLaboratory tests can help determine the shelf life of a package and its contents under a variety of conditions. This is particularly important for foods, pharmaceuticals, some chemicals, and a variety of products. The testing is usually product specific: the mechanisms of degradation are often different. Exposures to expected and elevated temperatures and humidities are commonly used for shelf life testing. The ability of packaging to control product degradation is frequently a subject of laboratory and field evaluations.\n\nMany products degrade with exposure to the atmosphere: foods, pharmaceuticals, chemicals, etc. The ability of a package to control the permeation and penetration of gasses is vital for many types of products. Tests are often conducted on the packaging materials but also on the completed packages, sometimes after being subjected to flexing, handling, vibration, or temperature.\n\nPackages can degrade with exposure to temperature, humidity, time, sterlization (steam, radiation, gas, etc.), sunlight, and other environmental factors. For some types of packaging, it is common to test for possible corrosion of metals, polymer degradation, and weather testing of polymers. Several types of accelerated aging of packaging and materials can be accomplished in a laboratory.\n\nExposure to elevated temperatures accelerates some degradation mechanisms. An Arrhenius equation is often used to correlate certain chemical reactions at different temperatures, based on the proper choice of Q coefficients.\n\nAs with any laboratory testing, validating field trials are important.\n\nVacuum chambers are used to test the ability of a package to withstand low pressures. This can be to:\n\nBoth primary (consumer) packages and shipping containers have a risk of being dropped or being impacted by other items. Package integrity and product protection are important packaging functions. Tests are conducted to measure the resistance of packages and products to controlled laboratory shock and impact.\n\nTesting also determines the effectiveness of package cushioning to isolate fragile products from shock. Instrumentation is used to measure the shock transmitted to a cushioned product.\n\nMany packages are used for products that are sensitive to temperature. The ability of insulated shipping containers to protect their contents from exposure to temperature fluctuations can be measured in a laboratory. The testing can be of empty containers or of full containers with appropriate jell or ice packs, contents, etc. Ovens, freezers, and environmental chambers are commonly used for this and other types of packaging.\n\nDigital temperature data loggers are used to measure temperatures experienced in different distribution systems. This data is sometimes used to develop unique laboratory test methods for that distribution system.\n\nSome packages, particularly glass, can be sensitive to sudden changes in temperature: Thermal shock. One method of testing involves rapid movement from cold to hot water baths, and back.\n\nPackage handles (and hand holes in packages) assist carrying and handling packages. Objective laboratory procedures are frequently used to help determine performance. Fixtured ‘’hands’’ of various designs are used to hold a handle (sometimes two handles for a box). Most common are “jerk testing’’ by modified drop test procedures or use of the constant pull rates of a universal testing machine. Other procedures use a static force by hanging a heavily loaded package for an extended time or even using a centrifuge.\n\nVibration is encountered during shipping (vehicle vibration, rough roads, etc.) and movement on conveyors. Potential vibration damage may include:\nThe ability of a package to withstand these vibrations and to protect the contents can be measured by several laboratory test procedures. Some allow searching for the particular frequencies of vibration that have potential for damage. Modal testing methodologies are sometimes employed. Others use specified bands of random vibration to better represent complex vibrations measured in field studies of distribution environments.\n\nCompression testing relates to stacking or crushing of packages, particularly shipping containers. It usually measures of the force required to crush a package, stack of packages, or a unit load. Packages can be empty or filled as for shipment. A force-deflection curve used to obtain the peak load or other desired points. Other tests use a constant load and measure the time to failure or to a critical deflection.\n\nDynamic compression is sometimes tested by shock or impact testing with an additional load to crush the test package. Dynamic compression also takes place in stacked vibration testing.\n\nLarge pallet loads, bulk boxes, wooden boxes, and crates can be evaluated by many of the other test procedures previously listed. In addition, some special test methods are available for these larger loads.\n\nShipping containers are often subjected to sequential tests involving a combination of individual test methods. A variety of standard test schedules or protocols are available for evaluating transport packaging. They are used to help determine the ability of complete and filled shipping containers to various types of logistics systems. Some test the general ruggedness of the shipping container while others have been shown to reproduce the types of damage encountered in distribution. Some base the type and severity of testing on formal studies of the distribution environment: instrumentation, data loggers, and observation. Test cycles with these documented elements better simulate parts of certain logistics shipping environments.\n\nIn addition, package testing often relates to the specific product inside the package. Some broad categories of products and special package testing considerations follow:\n\nFoods categories such as fresh produce, frozen foods, irradiated foods, fresh fish, canned foods, etc. have regulatory requirements and special packaging needs. Package testing often relates to:\n\nPackaging for drugs and pharmaceuticals is highly regulated. Special testing needs include:\nPackaging for medical materials, medical devices, health care supplies, etc., have special user requirements and is highly regulated. Barrier properties, durability, visibility, sterility and strength need to be controlled; usually with documented test results for initial designs and for production.\n\nAssurance of sterility and suitability for use are critical. For example, medical devices and products are often sterilized in the package. The sterility must be maintained throughout distribution to allow immediate use by physicians. A series of special packaging tests is used to measure the ability of the package to maintain sterility. Verification and validation protocols are rigidly maintained.\n\nPackaging of hazardous materials, or dangerous goods, are highly regulated. There are some material and construction requirements but also performance testing is required. The testing is based on the packing group (hazard level) of the contents, the quantity of material, and the type of container.\n\n\n\n"}
{"id": "2671429", "url": "https://en.wikipedia.org/wiki?curid=2671429", "title": "Power pro", "text": "Power pro\n\nPower Pro a type of braided fishing line made out of a material called Spectra fibers. It has an equivalent diameter of nearly 1/5 of monofilament. Thus the diameter of a piece of Power Pro testing at 50 pounds is equivalent to monofilaments' diameter testing at around 12 pounds. It lacks stretch that monofilament has, giving the fisherman a better \"feel\" and also helps set the hook faster. Environmentalists have criticized the use of spectra fiber, as it takes a long time to degrade thus harming the environment. Spectra is a form of gel-spun polyethylene.\n\nOne note in using Power Pro, the drag has to be set at a much lighter strength than compared to monofilament due to the propensity for Power Pro to dig into itself while fighting large fish.\n"}
{"id": "4750937", "url": "https://en.wikipedia.org/wiki?curid=4750937", "title": "Rat trap", "text": "Rat trap\n\nA rat trap is a trap designed to catch rats.\n\nSpring traps for large rodents such as rats or squirrels are powerful enough to break the animal's neck or spine. They may break human fingers as well, whereas an ordinary spring-based mousetrap is very unlikely to break a human finger. Rat spring traps may not be sensitive enough to spring when a mouse takes the bait.\n\nA \"rat cage trap\" is a metal cage box-shaped device that is designed primarily to catch rats without killing them. Food bait (not poisoned) is put in the cage trap. When an animal enters the cage and moves toward the bait, the mechanism triggers and closes a door over the entry point. The animal is caught alive and without injury. The animal can be transported and released elsewhere or subsequently killed.\n\nGlue traps are non-poisonous sticky glue spread over card boards and the like and kept in places rats frequent, which gets them stuck to it when they pass over it. The rat will subsequently die from dehydration and asphyxiation. A bait may also be placed on the cardboard to attract the rats.\n\nAnother form of non-lethal trap is one where the wires it is constructed of are cut and formed into a funnel shape directed into the body of the cage. This design is usually dome shaped with the funnel at the crown. Rats are extremely flexible and can push through the narrower opening into the cage, but cannot escape due to the ends of the wires poking them in the face. The advantage of this design is that it can catch more than one rat at a setting.\n\nOther types of traps (as shown below) are designed to kill the animal.\n\nElectronic rat traps detect the presence of a rodent via metal plates on the floor of the trap, then deliver a lethal dose of high-voltage electricity stepped up from batteries to several thousand volts. Some brands offer remote indication to tell you when the trap has operated. The Eliminator (South Africa) and Victor (US) are two brands of electronic rat traps.\n\nGlue traps, however, are not considered a humane method of rodent control, especially if the rodent is left to die. They can also harm non-targeted animals.\n\nAnother trap design, often considered more humane, is a self-resetting rat trap like the Goodnature A24. These traps kill rodents with an impact from a CO-powered piston and are self-resetting.\n\nMousetrap\n\n"}
{"id": "16835723", "url": "https://en.wikipedia.org/wiki?curid=16835723", "title": "Rigs-to-Reefs", "text": "Rigs-to-Reefs\n\nRigs-to-Reefs (RTR) is the practice of converting decommissioned offshore oil and petroleum rigs into artificial reefs. Such biotic reefs have been created from oil rigs in the United States, Brunei and Malaysia. In the United States, where the practice started and is most common, Rigs-to-Reefs is a nationwide program developed by the former Minerals Management Service (MMS), now Bureau of Safety and Environmental Enforcement (BSEE), of the U.S. Department of the Interior.\n\nThe program has been generally popular with fishermen, the oil industry, and government regulators in the Gulf of Mexico, where offshore platforms develop into coral reefs, and as of September 2012, 420 former oil platforms, about 10 percent of decommissioned platforms, have been converted to permanent reefs.\n\nOpposition in California has prevented a rigs-to-reefs program on the West Coast of the US. Similarly, environmental opposition has prevented implementation of Rigs-to-Reefs in the North Sea.\n\nInevitably, marine organisms attach themselves to the underwater portions of oil production platforms, transforming them into artificial reefs.\n\nThese platforms continue to function as long as the reservoirs underneath them provide oil at a profitable rate. At the end of their productive lives they must be decommissioned and removed (in the US within one year). An alternative to removal is to turn the rig into a reef through the Rigs-to-Reef (RTR) program. All coastal states in the US have such artificial reef programs in the interest of increasing ocean fisheries but not all participate in RTR. The rig's steel structures are stable and durable. They create shelter for marine life in open waters where there was none.\n\nNote that production platforms are often called \"rigs\"; that terminology is used occasionally in this article—and indeed in the term Rigs-to-Reefs. However, within the industry \"rigs\" refers to apparatus with a derrick that can drill and service wells. (Most production platforms do not have such equipment installed.)\n\nOnce a rig stops producing at economic rates, the site is usually abandoned. In the United States, the Minerals Management Service (MMS) requires the operator to remove the rig within a year of abandonment (stopped production) and lease end. MMS supports and encourages RTR as an alternative to total removal. RTR recognizes that during a rig's productive years, significant marine life comes to live on and around its structure. RTR preserves much of that marine life and encourages further growth. The operator benefits by avoiding the substantial cost of removal. Cumulative costs of removal had reached an estimated $1 billion by the year 2000. The shape and complexity of the structure may lead to significant species diversity.\n\nOfficially, decommissioning an oil rig is the act of removal according to regulatory requirements and includes flushing, plugging and cementing wells to make them safe. Decommissioning is complicated by factors such as cost, safety, operational duration, environmental issues, risk, experience, and historical relationship between operator and state.\n\nAs part of decommissioning, the operator must deal with the shell mound that collects on the bottom surrounding the rig. The mound forms on the pile of cuttings discharged from the original drilling operations, shells that have fallen from the platform's underwater structure, and material that has fallen and/or leaked from the platform, occasionally mixed with well seepage. Mounds can contain significant levels of toxic metals including, arsenic, cadmium, chromium, copper, nickel, PCBs, lead, zinc, and poly-nuclear hydrocarbons. Removing the rig structure does not eliminate the need to address the mound.\n\nThe method of decommissioning depends on water depth and structure type and is a three-step process that includes planning, permitting, and implementation. A party other than the operator usually administers the process.\n\nIn Louisiana, costs as well as the risk involved are the primary factors in determining how to decommission rigs. If the savings are large enough, the operator typically chooses reefing and donates 1/2 the savings to maintain the reef. Decommissioning a shallow water rig typically costs $10–15 million so the amounts can be substantial. The Louisiana Artificial Reef program from its inception through 1998 received roughly $9.7 million in donations and has not taken taxpayer money.\n\nSevering the rig from the bottom using explosives is the easiest approach, but has the potential to harm marine life. This potential is greatly reduced if the explosives are all placed deep below the seafloor. Current requirements place the explosives a minimum of below the seafloor which eliminates the threat to all but the closest sea turtles. National Oceanographic and Atmospheric Administration (NOAA) National Marine Fisheries Service (NMFS) marine observers and helicopter surveys hours preceding the event keep most sea turtles away from the area. Alternatively, commercial divers can use mechanical and abrasive cutters, which preserves marine life, but places the divers at considerable risk.\n\nReefing involves one of three methods.:\n\n\nOffshore drilling began in California in the late 1800s from piers built out over the ocean. The first offshore oil platform in the Gulf of Mexico was built in 1947 off the Louisiana coast.\n\nThe United States began extracting oil offshore in the early 20th Century; \"Today over 4,500 offshore oil and gas platforms have been installed supplying 25% of the United States' production of natural gas and 10% of its oil.\" However, the concern over abandoned oil rigs surfaced only in the 1980s.\n\nThe US Congress passed the Outer Continental Shelf Lands Act (OCSLA) in 1953, to control leasing of exploration rights in the Outer Continental Shelf (OCS). The OCSLA did not contain any real environmental provisions associated with drilling and the 1969 Santa Barbara oil spill triggered the National Environmental Policy Act (NEPA), which required that every major federal action (i.e.: oil exploration on the OCS) required an Environmental Impact Statement (EIS). In 1982, The U.S. Department of the Interior created the Minerals Management Service (MMS) to monitor development on the Outer Continental Shelf. The MMS leases submerged federal lands and assesses the environmental effects of exploration and drilling (by issuing an EIS). In 1984 Congress passed the National Fishing Enhancement Act (NFEA) which provided the basis for artificial reef programs. The NFEA spawned the National Artificial Reef Plan of 1985. This plan cleared the way for government-endorsed artificial reef projects and subsequently the Minerals Management Services' Rigs-to-Reef program.\n\nFollowing a number of hurricanes from 2004 to 2008, including Katrina, Ike, Ivan, and Rita, that damaged oil production platforms, offshore oil operators filed numerous applications to abandon unused platforms in place. The federal government responded by placing a moratorium on Rigs-to-Reefs, and requiring unused platforms to be speedily decommissioned by removal. In June 2013, the BSEE lifted its moratorium on Rigs-to-Reefs, subject to Coast Guard determination that the structure would not pose a threat to navigation, and acceptance of ownership and liability by the state government.\n\nIf the Rigs-to-Reefs option is expected to be less expensive than removal, the platform owner pays half the estimated savings to the state agency receiving the former platform.\n\nThe more than 4,500 oil production platforms in the US portion of the Gulf of Mexico are the largest concentration of offshore platforms in the world, having more offshore platforms than the rest of the world combined. The oil production platforms in the Gulf have also been called the largest artificial reef complex in the world.\n\nIn 1979, Exxon relocated their experimental subsea production system from offshore Louisiana to a permitted artificial reef site off Apalachicola, Florida. The first platform jacket was donated by Tenneco and towed from Louisiana to Pensacola, Florida.\n\nBy 2000, 151 platforms had been converted to permanent reefs. Of these, 90 were towed to new locations and 61 were abandoned in place. Louisiana had 94 of the platforms-turned reefs, Texas 50, Alabama 4, and Florida 3. Florida, which has a long-standing ban on offshore oil production, has requested and received a number of decommissioned oil platforms for creation of artificial reefs in Florida state waters.\n\nIn contrast to the Gulf of Mexico states, old oil platforms have not been converted to artificial reefs in offshore California, the only other offshore oil-producing area in the contiguous 48 states. A number of reasons have been cited for this, primarily the strength of the environmental movement in California, its antagonistic relationship with the oil industry, and its reluctance to support any measure that would financially benefit the offshore oil industry. Other differences include the smaller number of offshore platforms (27 off California, versus approximately 4,500 in the Gulf of Mexico), and the smaller portion of the California economy made up by oil and fishing.\n\nThe California legislature passed a bill allowing conditional partial removal of oil platforms in 2010, and the measure was signed by Governor Arnold Schwarzenegger. A.B. 2503 “allows a platform owner or operator to design a ‘partial removal’ plan for a platform and to apply for permission to implement it”. The plan requires the approval of three agencies: The Department of Fish and Game (DFG), The Department of Ocean Protection Council (OPC), and the California State Lands Commission. As of 2013, no oil platforms have been converted to permanent reefs.\n\nBrunei has had a rigs-to-reefs policy since 1988. Offshore operator Shell Brunei Petroleum has towed numerous old platforms and jackets to two designated artificial reef areas located away from shipping lanes.\n\nThe Baram-8 platform was damaged in a storm and collapsed to the seabed in 1975. It was made into an artificial reef. As of 2013, Malaysia has no rigs-to-reefs program, but was studying the Baram-8 reef as an example.\n\nIn 2017, Dana and D30 Platform was laid out for rigs-to-reef in offshore Sarawak.\n\nStudies have concluded that oil platforms in the North Sea attract fish, and that a rigs-to-reefs policy there would benefit fishermen. However, the highly publicized occupation of the Brent Spar North Sea oil platform by Greenpeace in 1995 has been highly influential in Europe. Despite scientific findings of the potential value of rigs-to-reefs in the North Sea, the Oslo-Paris Commission (OSPAR), which has jurisdiction over North Sea oil development, has blocked rigs-to-reefs.\n\nOpposition to, and also support for, Rigs-to-Reefs comes from environmentalists, fisherman, oil companies, and others. California and the North Sea are each debating RTR. In California, legislation was proposed during the 2010 session to clear legal hurdles for RTR; the Coastal Commission held hearings, but then the legislation was tabled. Even with the RTR successes in the Gulf of Mexico and Philippines, differences in terrain, government entities, and concerned citizens generated conflict.\n\nSome point out that the title “Rigs to Reefs” is somewhat of a misnomer. As Milton Love, a biologist with the UC Santa Barbara Marine Science Institute noted, the oil production platforms are not just potential artificial reefs: \"They are in fact artificial reefs right now.\" The question to Rigs-to-Reef supporters is whether it is good public policy to remove established artificial reefs.\n\nA 2000 MMS report lists research that shows fish densities 20 to 50 times higher around oil and gas platforms than in nearby open water. Divers assess fish populations surrounding platforms. The report encourages recreational fisherman, divers and others who benefit from the increased density. Opponents claim that the greater density comes from an influx of nearby fish rather than increased total population. Research on rockfish populations on oil rigs offshore California supports both theories.\n\nThe high fish populations make both active and inactive oil platforms in the Gulf of Mexico and offshore California popular destinations for sport fishermen and the charter fishing industry. The diversity of aquatic life on and near the platforms attracts recreational divers. These groups tend to support Rigs-to-Reefs, and fear the loss of coral and fish habitat if the oil platforms are removed.\n\nCommercial fishing for red snapper in the Gulf of Mexico is seen as highly dependent on oil platform habitat, which provides a hard substrate for aquatic life that is otherwise scarce in much of the Gulf. Dr. Bob Shipp, chairman of the University of South Alabama Department of Marine Sciences, and director of the Alabama Center for Estuarine Studies, would like to see 100 percent participation in Rigs-to-Reefs, and said of removing unused oil rigs from the Gulf: “As a fisheries scientist, I think it’s a very big mistake,” He elaborated:\n\nThose commercial fisherman who trawl generally oppose Rigs-to-Reefs because their nets may snag a rig, creating a hazardous situation. This is particularly the case in offshore California with bottom trawling commercial fishermen, who can foul their nets on the shell mounds that build up on the sea floor near the rig. Several fisherman have reported tangling their nets on submerged rigs.\n\nNavigational mishaps and diving accidents may also occur around an artificial reef. Gulf of Mexico Rigs-to-Reefs participants have not yet reported any liability problems.\n\nRigs-to-Reefs was first explored in 1979 when the first oil rig was transported from Louisiana to a Florida site. This rig was the first of 5 Rigs-to-Reefs towed to Florida's coast. Louisiana was the first state to develop a program that allowed transfer of liability and ownership from the operator to the state. Texas later followed this example. Rigs-to-Reef is now the core of both Louisiana and Texas' artificial reef programs.\n\nUnder the original guidelines, the Minerals Management Service would not release an operator from liability unless another entity accepts ongoing liability for the rig. If the reef is in state waters, the state typically accepts liability. In federal waters, liability typically goes to a private entity or to another MMS-approved agency. Critics claim that the primary reason that operators support RTR is their desire to offload decommissioning costs and liability. In 2001, the California legislature passed, although the governor then vetoed, a bill that would allow operators to transfer liability to another entity, while retaining liability for any pollution from the underlying well.\n\nUnder the new policy issued June 2013, oil platforms in the Rigs-to-Reefs program must be deeded, and liability accepted by, the state government.\n\nAs with cap-and-trade and ecotourism, RTR attempts to enlist the private sector in helping the environment. To many environmentalists, any program which benefits the oil industry, by lower decommissioning costs, is suspect. Some charge that rigs-to-reefs is an excuse for ocean dumping. Environmental groups have long opposed oil companies and frame their critique around distrust of the industry, particularly with regard to Rigs-to-Reefs in offshore California. \"No other industry is allowed to leave a toxic mess for the state to manage and maintain at taxpayer expense\" said Linda Krop, Chief council for the Santa Barbara-based Environmental Defense Center.\n\nThe Environmental Defense Fund supports Rigs-to-Reefs in the Gulf of Mexico, as a way to preserve the existing reef habitat of the oil platforms.\n\n\n\n"}
{"id": "23718456", "url": "https://en.wikipedia.org/wiki?curid=23718456", "title": "Sarah Guppy", "text": "Sarah Guppy\n\nSarah Guppy, née Beach (1770 – 24 August 1852) was an English inventor who developed a number of domestic products.\n\nFollowing the publication of an erroneous entry in the ONDB in 2016, Guppy has in recent times been incorrectly credited with the design of Isambard Kingdom Brunel's Clifton Suspension Bridge. She designed and patented her own chain bridge in 1811 (before the announcement of the first competition for a bridge across the Avon Gorge) but this design was never realised. Brunel’s winning design for a bridge across the Avon Gorge differed from Guppy's patent in several significant ways: it had a deck suspended from flat wrought iron bar links rather than resting on top of chains like Guppy's; and it did not feature riverbed foundations (a key component of Guppy's design) as it was constructed 75 metres above high tide where the piers were not at risk of damage from water erosion. \n\nSarah Maria Beach was born in Birmingham, England, and baptised in November 1770. She married Samuel Guppy in 1795. In 1811 she patented the first of her inventions, a method of making safe piling for bridges. Thomas Telford asked her for permission to use her patented design for suspension bridge foundations, and she granted it to him free of charge. As a friend of Isambard Kingdom Brunel and his family she became involved in the Great Western Railway, writing to the directors with ideas and giving her support. In 1841 she wrote a letter recommending planting willows and poplars to stabilise embankments. She continued to offer technical advice despite the fact that, as she wrote, \"it is unpleasant to speak of oneself—it may seem boastful particularly in a woman.\"\n\nThe family took out 10 patents in the first half of the nineteenth century, including a method of keeping ships free of barnacles that led to a government contract worth £40,000. Other inventions included a bed with built-in exercise equipment, a device for a tea or coffee urn which would cook eggs in the steam as well as having a small dish to keep toast warm and a device for \"improvements in caulking ships, boats and other vessels.\" In later life she wrote \"The Cottagers and Labourers Friend\" and \"Dialogues for Children\", invented the fire hood or Cook's Comforter, and patented a new type of candlestick that enabled candles to burn longer.\n\nAfter marrying Bristol merchant Samuel Guppy they lived in Queen Square and Prince Street, a leading light of the Bristol and Clifton social scene. The couple had six children, including Thomas Richard, who with older brother Samuel operated the Friars Sugar Refinery in Bristol (1826–42) before becoming an engineer and associate of Brunel, contributing significantly to the design of SS \"Great Western\" and SS \"Great Britain\". Brunel painted a portrait of the younger Sarah Guppy c. 1836.\n\nIn 1837 the widowed Sarah, now 67, married Richard Eyre Coote, 28 years her junior. For a while they lived at Arnos Court, Brislington, but Richard ran through his rich wife's money at a rapid rate, spending on horses and neglecting her. Sarah moved into 7 Richmond Hill, Clifton, in 1842. She bought the land opposite the house for the benefit of Clifton residents and it still remains green space.\n"}
{"id": "16892551", "url": "https://en.wikipedia.org/wiki?curid=16892551", "title": "Showco", "text": "Showco\n\nShowco was a sound equipment provider of touring sound reinforcement equipment and services to the concert touring industry. It was based in Dallas, Texas, United States. In 2000, Showco was acquired by Clair Global.\n\nShowco was established in 1970 by Jack Maxson and Rusty Brutsche, and Jack Calmes, and is known for helping to pioneer post Woodstock-era stadium rock shows by providing state-of-the-art sound equipment for famous acts beginning with Led Zeppelin, Three Dog Night and James Taylor. According to Brutsche:\n\nWith Showco equipment and services, the star performers could count on reliable and consistent sound reproduction at different venues. Showco introduced such features as mixing gear and stage monitors to aid the musicians. The equipment was also built to handle rugged touring schedules, outdoor weather conditions and quick assembly and disassembly.\n\nLater forays into stage lighting led to the 1981 formation of sister company Vari-Lite, Inc.\n\nThe list of artists that Showco has provided equipment for is extensive, including Jesus Christ Superstar; Mountain; Blood, Sweat & Tears; Lee Michaels, Grand Funk Railroad; the Osmonds; Rare Earth; Cat Stevens; David Cassidy; Little Feat; The Band; Wishbone Ash; Genesis; Eric Clapton; Leon Russell; Linda Ronstadt; Carole King; Jackson Browne; The Kinks; Commodores; Guess Who; Nazareth; The Average White Band; Black Oak Arkansas; Thin Lizzy; Golden Earring; Robert Palmer; The Moody Blues; Yoko Ono; REO Speedwagon; Ted Nugent; Uriah Heep; Willie Nelson; the Beach Boys; Lynyrd Skynyrd; Bad Company; Freddie King; Alice Cooper; Van Halen; Peter Gabriel; ZZ Top; Bee Gees; Wings; Paul McCartney; The Rolling Stones; David Bowie; The Who; Prince; Julian Lennon; Bob Seger; Diana Ross; Janet Jackson; Reba McEntire; Vince Gill; Alan Jackson; Clint Black; George Michael; INXS; Phil Collins; Mick Jagger; Boston; Santana; Bon Jovi; Guns N' Roses; Britney Spears; 'N Sync; Ozzy Osbourne & Ozzfest; Korn; Limp Bizkit.\n\nShowco was acquired by Clair Brothers in late 2000. Showco was merged into the touring arm of Clair Brothers. The combined division was then renamed ClairShowco. In 2008 the name was changed once again to Clair and given the corporate tagline \"Global Service and Live Shows Since 1966.\"\n\n"}
{"id": "23916699", "url": "https://en.wikipedia.org/wiki?curid=23916699", "title": "Strategic Computing Initiative", "text": "Strategic Computing Initiative\n\nThe United States government's Strategic Computing Initiative funded research into advanced computer hardware and artificial intelligence from 1983 to 1993. The initiative was designed to support various projects that were required to develop machine intelligence in a prescribed ten-year time frame, from chip design and manufacture, computer architecture to artificial intelligence software. The Department of Defense spent a total of $1 billion on the project.\n\nThe inspiration for the program was Japan's fifth generation computer project, an enormous initiative that set aside billions for research into computing and artificial intelligence. As with Sputnik in 1959, the American government saw the Japanese project as a challenge to its technological dominance. The British government also funded a program of their own around the same time, known as Alvey, and a consortium of U.S. companies funded another similar project, the Microelectronics and Computer Technology Corporation.\n\nThe goal of SCI, and other contemporary projects, was nothing less than full machine intelligence. \"The machine envisioned by SC\", according to Alex Roland and Philip Shiman, \"would run ten billion instructions per second to see, hear, speak, and think like a human. The degree of integration required would rival that achieved by the human brain, the most complex instrument known to man.\"\n\nThe initiative was conceived as an integrated program, similar to the Apollo moon program, where different subsystems would be created by various companies and academic projects and eventually brought together into a single integrated system. Roland and Shiman wrote that \"While most research programs entail tactics or strategy, SC boasted grand strategy, a master plan for an entire campaign.\"\n\nThe project was funded by the Defense Advanced Research Projects Agency and directed by the Information Processing Technology Office (IPTO). By 1985 it had spent $100 million, and 92 projects were underway at 60 institutions: half in industry, half in universities and government labs. Robert Kahn, who directed IPTO in those years, provided the project with its early leadership and inspiration. Clint Kelly managed the SC Initiative for three years and developed many of the specific application programs for DARPA, such as the Autonomous Land Vehicle.\n\nBy the late 1980s, it became apparent that the project would not succeed in creating machine intelligence at the levels that had been hoped for. Insiders in the program cited problems in communication, organization, and integration. When Jack Schwarz ascended to the leadership of IPTO in 1987, he cut funding to artificial intelligence research (the software component) \"deeply and brutally\", \"eviscerating\" the program (wrote Pamela McCorduck). Schwarz felt that DARPA should focus its funding only on those technologies which showed the most promise. In his words, DARPA should \"surf\", rather than \"dog paddle\", and he felt strongly AI was not \"the next wave\".\n\nAlthough the program failed to meet its goal of high-level machine intelligence, it did meet some of its specific technical objectives, for example those of autonomous land navigation. The Autonomous Land Vehicle program and its sister Navlab project at Carnegie Mellon University, in particular, laid the scientific and technical foundation for many of the driverless vehicle programs that came after it, such as the Demo II and III programs (ALV being Demo I), Perceptor, and the DARPA Grand Challenge. The use of video cameras plus laser scanners and inertial navigation units pioneered by the SCI ALV program form the basis of almost all commercial driverless car developments today. It also helped to advance the state of the art of computer hardware to a considerable degree. On the software side, the initiative funded development of the Dynamic Analysis and Replanning Tool, a program that handled logistics using artificial intelligence techniques. This was a huge success, saving the Department of Defense billions during Desert Storm.\n\nThe project was superseded in the 1990s by the Accelerated Strategic Computing Initiative and then by the Advanced Simulation and Computing Program. These later programs did not include artificial general intelligence as a goal, but instead focused on supercomputing for large scale simulation, such as atomic bomb simulations. The Strategic Computing Initiative of the 1980s is distinct from the 2015 National Strategic Computing Initiative -- the two are unrelated. \n\n\n"}
{"id": "4522453", "url": "https://en.wikipedia.org/wiki?curid=4522453", "title": "Tine (structural)", "text": "Tine (structural)\n\nTines or prongs or teeth are parallel or branching spikes forming parts of a tool or natural object. They are used to spear, hook, move or otherwise act on other objects. They may be made of metal, wood, bone or other hard, strong materials.\n\nThe number of tines (also written tynes) on tools varies widely – a pitchfork may have just two, a garden fork may have four, and a rake or harrow many. Tines may be blunt, such as those on a fork used as an eating utensil; or sharp, as on a pitchfork; or even barbed, as on a trident. The terms \"tine\" and \"prong\" are mostly interchangeable. A tooth of a comb is a tine.\n\nTines and prongs occur in nature—for example, forming the branched bony antlers of deer or the forked horns of pronghorn antelopes. The term \"tine\" is also used for mountains, such as the fictional Silvertine in \"The Lord of the Rings\".\n\nIn chaos theory (physics, non-linear dynamics), the branches of a bifurcation diagram are called \"tines\" and \"subtines\".\n"}
{"id": "30677", "url": "https://en.wikipedia.org/wiki?curid=30677", "title": "Tool", "text": "Tool\n\nA tool is an object of whatever relatively simple construction is necessary for its user to hold and operate easily to perform a simple task (like moving, lifting, breaking, holding, turning, bending) not as effectively performed or not possible, safe, or desirable to perform using a bodily member alone. Although many animals use simple tools, only human beings, whose use of stone tools dates back hundreds of millennia, use tools to make other tools. The set of tools needed to perform different tasks that are part of the same activity is called gear or equipment.\n\nWhile one may apply the term \"tool\" loosely to many things that are means to an end (e.g., a fork), strictly speaking an object is a tool only if, besides being constructed to be held, it is also made of a material that allows its user to apply to it various degrees of force. If repeated use wears part of the tool \"down\" (like a knife blade), it may be possible to restore it; if it wears the tool \"out\" or breaks it, the tool must be replaced. Thus \"tool\" falls under the taxonomic category \"implement\", and is on the same taxonomic rank as \"instrument\", \"utensil\", \"device\", or ware.\n\nAnthropologists believe that the use of tools was an important step in the evolution of mankind. Because tools are used extensively by both humans and wild chimpanzees, it is widely assumed that the first routine use of tools took place prior to the divergence between the two species. These early tools, however, were likely made of perishable materials such as sticks, or consisted of unmodified stones that cannot be distinguished from other stones as tools.\n\nStone artifacts only date back to about 2.5 million years ago. However, a 2010 study suggests the hominin species \"Australopithecus afarensis\" ate meat by carving animal carcasses with stone implements. This finding pushes back the earliest known use of stone tools among hominins to about 3.4 million years ago.\n\nFinds of actual tools date back at least 2.6 million years in Ethiopia. One of the earliest distinguishable stone tool forms is the hand axe.\n\nUp until recently, weapons found in digs were the only tools of “early man” that were studied and given importance. Now, more tools are recognized as culturally and historically relevant. As well as hunting, other activities required tools such as preparing food, “…nutting, leatherworking, grain harvesting and woodworking…” Included in this group are “flake stone tools\".\n\nTools are the most important items that the ancient humans used to climb to the top of the food chain; by inventing tools, they were able to accomplish tasks that human bodies could not, such as using a spear or bow and arrow to kill prey, since their teeth were not sharp enough to pierce many animals' skins. “Man the hunter” as the catalyst for Hominin change has been questioned. Based on marks on the bones at archaeological sites, it is now more evident that pre-humans were scavenging off of other predators' carcasses rather than killing their own food.\n\nMechanical devices experienced a major expansion in their use in Ancient Greece and Ancient Rome with the systematic employment of new energy sources, especially waterwheels. Their use expanded through the Dark Ages with the addition of windmills.\n\nMachine tools occasioned a surge in producing new tools in the industrial revolution. Advocates of nanotechnology expect a similar surge as tools become microscopic in size.\n\nOne can classify tools according to their basic functions:\n\nSome tools may be combinations of other tools. An alarm-clock is for example a combination of a measuring tool (the clock) and a perception tool (the alarm). This enables the alarm-clock to be a tool that falls outside of all the categories mentioned above.\n\nThere is some debate on whether to consider protective gear items as tools, because they do not directly help perform work, just protect the worker like ordinary clothing. They do meet the general definition of tools and in many cases are necessary for the completion of the work. Personal protective equipment includes such items as gloves, safety glasses, ear defenders and biohazard suits.\n\nA simple machine is a mechanical device that changes the direction or magnitude of a force. In general, they are the simplest mechanisms that use mechanical advantage (also called leverage) to multiply force. The six classical simple machines which were defined by Renaissance scientists are:\n\nOften, by design or coincidence, a tool may share key functional attributes with one or more other tools. In this case, some tools can substitute for other tools, either as a makeshift solution or as a matter of practical efficiency. \"One tool does it all\" is a motto of some importance for workers who cannot practically carry every specialized tool to the location of every work task; such as a carpenter who does not necessarily work in a shop all day and needs to do jobs in a customer's house. Tool substitution may be divided broadly into two classes: substitution \"by-design\", or \"multi-purpose\", and substitution as makeshift. Substitution \"by-design\" would be tools that are designed specifically to accomplish multiple tasks using only that one tool.\n\nSubstitution as makeshift is when human ingenuity comes into play and a tool is used for its unintended purpose such as a mechanic using a long screw driver to separate a cars control arm from a ball joint instead of using a tuning fork. In many cases, the designed secondary functions of tools are not widely known. As an example of the former, many wood-cutting hand saws integrate a carpenter's square by incorporating a specially shaped handle that allows 90° and 45° angles to be marked by aligning the appropriate part of the handle with an edge and scribing along the back edge of the saw. The latter is illustrated by the saying \"All tools can be used as hammers.\" Nearly all tools can be used to function as a hammer, even though very few tools are intentionally designed for it and even fewer work as well as the original.\n\nTools are also often used to substitute for many mechanical apparatuses, especially in older mechanical devices. In many cases a cheap tool could be used to occupy the place of a missing mechanical part. A window roller in a car could easily be replaced with a pair of vise-grips or regular pliers. A transmission shifter or ignition switch would be able to be replaced with a screw-driver. Again, these would be considered tools that are being used for their unintended purposes, substitution as makeshift. Tools such as a rotary tool would be considered the substitution \"by-design\", or \"multi-purpose\". This class of tools allows the use of one tool that has at least two different capabilities. \"Multi-purpose\" tools are basically multiple tools in one device/tool. Tools such as this are often power tools that come with many different attachments like a rotary tool does, so you could say that a power drill is a \"multi-purpose\" tool because you can do more than just one thing with a power drill.\n\nA multi-tool is a hand tool that incorporates several tools into a single, portable device; the Swiss army knife represents one of the earliest examples. Other tools have a primary purpose but also incorporate other functionality – for example, lineman's pliers incorporate a gripper and cutter, and are often used as a hammer; and some hand saws incorporate a carpenter's square in the right-angle between the blade's dull edge and the saw's handle. This would also be the category of \"multi-purpose\" tools, since they are also multiple tools in one (multi-use and multi-purpose can be used interchangeably – compare hand axe). These types of tools were specifically made to catch the eye of many different craftsman who traveled to do their work. To these workers these types of tools were revolutionary because they were one tool or one device that could do several different things. With this new revolution of tools the traveling craftsman would not have to carry so many tools with them to job sites, in that their space would be limited to the vehicle or to the beast of burden they were driving. Multi-use tools solve the problem of having to deal with many different tools.\n\nObservation has confirmed that a number of species can use tools including monkeys, apes, elephants, several birds, and sea otters. Philosophers originally thought that only humans had the ability to \"make\" tools, until zoologists observed birds and apes making tools. Now the unique relationship of humans with tools is considered to be that we are the only species that uses tools to make \"other\" tools.\n\nA telephone is a communication tool that interfaces between two people engaged in conversation at one level. It also interfaces between each user and the communication network at another level. It is in the domain of media and communications technology that a counter-intuitive aspect of our relationships with our tools first began to gain popular recognition. Marshall McLuhan famously said \"We shape our tools. And then our tools shape us.\" McLuhan was referring to the fact that our social practices co-evolve with our use of new tools and the refinements we make to existing tools.\n\n\n"}
{"id": "34478836", "url": "https://en.wikipedia.org/wiki?curid=34478836", "title": "Tree planting bar", "text": "Tree planting bar\n\nA tree planting bar or dibble bar is a tool used by foresters to plant trees, especially in large-scale afforestation or reforestation. It is very ergonomic, as it greatly speeds up the planting and prevents back pain.\n\nPointed planting bars are better for rockier soils.\n\n\n"}
{"id": "44649882", "url": "https://en.wikipedia.org/wiki?curid=44649882", "title": "VHPready", "text": "VHPready\n\nVHPready (abbreviation for Virtual Heat and Power Ready) is an open industry standard for the control of decentralised power generation plants, consumers and energy storage systems via a central control centre. The uniform use of this standard enables the flexible connection of decentralized power plants to virtual power plants and Smart Grid applications.\n\nVHPready was originally developed by Vattenfall on the basis of international communication standards and was initially used to network its own plants. At the beginning of 2014, Vattenfall handed over the standard with all rights to the Industrieforum VHPready e. V., which had been significantly prepared by the Fraunhofer Institute for Open Communication Systems (FOKUS) and took over the further development and dissemination as an international industry standard.\n\nIn the wake of the energy revolution, decentralised power generation plants such as wind power plants, photovoltaic plants, biogas plants, small hydropower plants and mini or micro combined heat and power plants, as well as controllable consumers and energy storage systems, are becoming increasingly important. One approach to integrating them into the energy supply and exploiting synergies is to interconnect these decentralised plants to form virtual power plants. These can help to intelligently orchestrate and reconcile consumption and generation, which should lead to better integration of renewable energies and decentralised plants, a reduction in the maximum load on the grids and cost advantages for market participants. An intelligent power grid (see Smart Grid) plays a key role in this. Various price mechanisms, some of which are already in use today (see standard power), can serve as an incentive for providing this so-called flexibility.\n\nUp to now, the connection of the plants has been carried out by manufacturer-specific information and communication standards using different data models. With the aid of an open industry standard and certification of the decentralised plants, the process for connection and pre-qualification is to be facilitated and shortened.\n\n2011\n\n\n2012\n\n\n2013\n\n\n2014\n\n\n2015\n\n\n2017\n\n\nVHPready comprises different requirements regarding system configuration as well as necessary control and measuring elements. Supported plant types range from power generation plants to energy storage units and consumers. \n\nCertification is carried out by VHPready Services GmbH and accredited testing laboratories. After receipt of an application for the VHPready certificate, testing laboratories are commissioned to test the respective systems on the basis of the technical requirements. \n\nThe process is divided into two stages: first, the systems are tested against specifications by means of conformity tests. They begin with the static testing of the properties specified by the manufacturer. This is followed by the verification of the dynamic properties, i.e. tests under controlled conditions. In the second stage, end-to-end tests are carried out using reference systems. After successful testing and acceptance of the test report by VHPready Services GmbH, the systems receive a product-related VHPready certificate. Changed products require recertification. \n\nIn order to obtain the VHPready certificate, the plants must meet certain minimum requirements. These ensure that a technical connection to a virtual power plant runs smoothly. They concern, among other things, the connection protocols used, technical performance requirements, security of data transmission and types of commands to the plants. The focus is on data communication, remote monitoring and remote control of the equipment.\n\nThe current version of the specification is VHPready 4.0. The functional core of VHPready 4.0 is an extensive data point list. It supports the integration of different energy systems into virtual power plants. The telecontrol protocol IEC 60870-5-104 or a modelling according to IEC 61850-7-420 is used for this purpose. In addition to a plant park with a network of different energy systems, this data point list enables the integration of block-type thermal power stations (CHPs), wind power and solar plants, heat pumps, batteries, electric heaters, boiler and buffer storage. In addition, there are data points for meters and external signalling contacts.[8] The security of data transmission is guaranteed by the establishment of a virtual private network (VPN) based on OpenVPN with SSL/TLS connections (Secure Sockets Layer, Transport Layer Security).[9]\n\nAn essential goal of VHPready is the definition of subsets or profiles of the standards used, so that only the profile has to be named during certification and project realization. Project-specific agreements on the details of the standards are thus largely eliminated. All tests for certification to the VHPready standard follow internationally standardized methods and techniques as defined by ISO/IEC and ETSI.\n\nCurrently 47 member companies are participating in the initiative for the integration and standardization of decentralized energy systems. Among the members are manufacturers of system components, providers of software and IT services, network operators, test service providers as well as companies from research and development.\n\nThe members of the Industry Alliance VHPready e.V. actively design all new application areas for new use cases of the VHPready specifications. In working groups the technical advancements of the industry standard are compiled together, application scenarios are developed, testing and certification processes are modeled as well as positions and strategies of the industry forum for the public work are conceived. The new development statuses are available to the member companies ahead of time. This allows them to test the VHPready communication in their products and in interaction with the systems of other member companies even before the publication of new applications, for example during a Plugfest.\n\n"}
{"id": "30062754", "url": "https://en.wikipedia.org/wiki?curid=30062754", "title": "Zymo Research", "text": "Zymo Research\n\nZymo Research is a privately held American manufacturer of molecular biology research tools used for DNA and RNA research and analysis. The company also supports epigenetics research, the field of medicine studying stable heritable traits that cannot be explained by changes in DNA sequence.\n\nZymo Research Corporation was founded by Larry Jia in 1994. The company started its home base in Orange, CA in a garage, manufacturing products for DNA and RNA extraction and purification and other specialty products for E. coli and yeast based research. It expanded its product offerings to include tools for epigenetics research. In December 2010, the company relocated to Irvine, CA.\n\nIn 2009, Zymo Research Europe was established in Freiburg, Germany. It works as a distribution support hub for Europe and the Middle East and will also be initiating research and development programs at a new facility, intended for state-of-the-art researching.\n\nThe company is a supplier of DNA extraction and RNA extraction kit products used to isolate and purify DNA and RNA from various sample sources ranging from tough to lyse environmental samples to tissue, blood, and serum samples. The company expanded and by 2017 was also an epigenetics company, offering products in DNA methylation and DNA hydroxymethylation.\n\nZymo Research develops epigenetics products for CpG methylation detection and quantitation. Many of these products exploit the bisulfite conversion approach, wherein unmethylated cytosine is converted to uracil, allowing for downstream sequencing analysis. The company also offers polymerases optimized for polymerase chain reaction (PCR) analysis of bisulfite-converted DNA, as well as antibodies for IP-based epigenetics research.\n\nIncluded in the company’s epigenetics portfolio are kits for nucleosomal DNA purification, chromatin immunoprecipitation, and small RNA isolation.\n\nThe company's products are distributed in North America and internationally through distributors located in Europe, Asia, South America, Africa, Australia, and others.\n\n"}
