{"id": "2396851", "url": "https://en.wikipedia.org/wiki?curid=2396851", "title": "Airline meal", "text": "Airline meal\n\nAn airline meal, airline food, or in-flight meal is a meal served to passengers on board a commercial airliner. These meals are prepared by specialist airline catering services and normally served to passengers using an airline service trolley.\n\nThese meals vary widely in quality and quantity across different airline companies and classes of travel. They range from a simple snack or beverage in short-haul economy class to a seven-course gourmet meal in a first class long-haul flight. When ticket prices were regulated in the American domestic market, food was the primary means airlines differentiated themselves.\n\nThe first airline meals were served by Handley Page Transport, an airline company founded in 1919, to serve the London–Paris route in October of that year. Passengers could choose from a selection of sandwiches and fruit.\n\nThe type of food varies depending upon the airline company and class of travel. Meals may be served on one tray or in multiple courses with no tray and with a tablecloth, metal cutlery, and glassware (generally in first and business classes). Often the food is reflective of the culture of the country the airline is based in.\n\nThe airline dinner typically includes meat (most commonly chicken or beef), fish, or pasta; a salad or vegetable; a small bread roll; and a dessert. Condiments (typically salt, pepper, and sugar) are supplied in small sachets or shakers.\n\nCaterers usually produce alternative meals for passengers with restrictive diets. These must usually be ordered at least 24 hours in advance, sometimes when buying the ticket. Some of the more common examples include:\n\nFor several Islamic airlines (e.g. EgyptAir, Emirates, Etihad Airways, Garuda Indonesia, Batik Air, Malindo Air, Flydubai, Gulf Air, Iran Air, Mahan Air, Iran Aseman Airlines, Oman Air, Yemenia, Royal Jordanian, Kuwait Airways, Iraqi Airways, Qatar Airways, Saudia, Biman Bangladesh Airlines, Pakistan International Airlines, Malaysia Airlines, Royal Brunei Airlines, Royal Air Maroc, Libyan Airlines, Afriqiyah Airways, Tunisair, Jazeera Airways, Air Algérie, Air Arabia, and Turkish Airlines), in accordance with Islamic customs, all classes and dishes on the plane are served a Muslim meal with Halal certification – without pork and alcohol. While Emirates, Etihad, and Qatar still provide bottles of wine to non-Muslim passengers, the cabin crew does not deliver alcoholic beverages lest to violate Islamic customs, unless those non-Muslim passengers request it. Turkish Airlines does not serve any meals with pork or lard, but especially during international flights, a variety of alcoholic beverages are served upon request. Because Iran and Saudi Arabia apply strict Sharia regulations, those countries' airlines do not deliver pork or alcoholic beverages, and all airlines flying to or from Iran or Saudi Arabia are prohibited from serving either. However, Garuda Indonesia still serves alcoholic beverages (whiskey, beer, champagne, and wine) to non-Muslim passengers.\n\nIn the case of Israeli airlines El Al, Arkia, and Israir, all meals served are kosher-certified by Rabbis. Even at destinations outside Israel, sky chefs must be supervised by rabbis to make kosher meals and load their planes.\n\nBefore the September 11 attacks in 2001, first class passengers were often provided with full sets of metal cutlery. Afterward, common household items were evaluated more closely for their potential use as weapons on aircraft, and both first class and coach class passengers were restricted to plastic utensils. Some airlines switched from metal to all-plastic or plastic-handled cutlery during the SARS outbreak in 2003, since the SARS virus transfers from person to person easily, and plastic cutlery can be thrown away after use. Many airlines later switched back to metal cutlery. However, Singapore Airlines and Swiss International Air Lines continue to use metal utensils even in economy class as of 2018.\n\nIn May 2010, concerns were raised in Australia and New Zealand over their respective flag carriers, Qantas and Air New Zealand, reusing their plastic cutlery for international flights between 10 and 30 times before replacement. Both airlines cited cost saving, international quarantine, and environmental as the reasons for the choice. Both have also said that the plastic cutlery is commercially washed and sterilized before reuse. Reusing plastic tablewares though is a regular practice among many airliners and food caterers.\nFor cleanliness, most meals come with a napkin and a moist towelette. First and business class passengers are often provided with hot towels.\n\nDuring morning flights a cooked breakfast or smaller continental-style may be served. On long haul flights (and short/medium haul flights within Asia) breakfast normally includes an entrée of pancakes or eggs, traditional fried breakfast foods such as sausages and grilled tomatoes, and often muffins or pastries, fruits, and breakfast cereal on the side. On shorter flights a continental-style breakfast, generally including a miniature box of breakfast cereal, fruits and either a muffin, pastry, or bagel. Coffee and tea are offered as well, and sometimes hot chocolate.\n\nFood on board a flight is usually free on full-service Asian airlines and on almost all long-distance flights, while they might cost extra on low-cost airlines or European full-service airline flights. Quality may also fluctuate due to shifts in the economics of the airline industry.\n\nOn long-haul international flights in first class and business class, most Asian and European airlines serve gourmet meals, while legacy carriers based in the US tend to serve multicourse meals including a cocktail snack, appetizer, soup, salad, entrée (chicken, beef, fish, or pasta), cheeses with fruit, and ice cream. Some long-haul flights in first and business class offer such delicacies as caviar, champagne, and sorbet (intermezzo).\n\nThe cost and availability of meals on US airlines has changed considerably in recent years, as financial pressures have forced some airlines to either begin charging for meals, or abandon them altogether in favor of small snacks, as in the case of Southwest Airlines. Eliminating free pretzels saved Northwest $2 million annually. Nowadays, the main US legacy carriers (American, Delta, and United) have discontinued full meal service in economy class on short-haul US domestic and North American flights, while retaining it on most intercontinental routes; and at least one European carrier, Icelandair, follows this policy on intercontinental runs as well.\n\nAs of 2018, all 4 major U.S. legacy airlines now offer free snacks on board in economy class. United Airlines re-introduced free snacks in February 2016. From April 2016, American Airlines fully restored free snacks on all domestic flights in economy class. Free meals will also be available on certain domestic routes. Delta and Southwest have already been offering free snacks for years.\n\nHawaiian Airlines is the only remaining major US airline that offers complimentary in–flight meals on its domestic flights.\n\nAir China has reported that each domestic flight's meal requires RMB50 (US$7.30) while international flights require RMB70 (US$10). However, this figure varies from airline to airline, as some have reported costs to be as low as US$3.50. Air China is also minimizing costs by loading only 95% of all meals to reduce leftovers and storing non-perishable foods for emergencies.\n\nIn 1958 Pan Am and several European airlines entered into a legal dispute over whether certain airline food sandwiches counted as a \"meal\".\n\nMeals must generally be prepared on the ground before takeoff. Guillaume de Syon, a history professor at Albright College who wrote about the history of airline meals, said that the higher altitudes alter the taste of the food and the function of the taste buds; according to de Syon the food may taste \"dry and flavorless\" as a result of the pressurization and passengers, feeling thirsty due to pressurization, many drink alcohol when they ought to drink water. Tests have shown that the perception of saltiness and sweetness drops 30% at high altitudes. The low humidity in airline cabins also dries out the nose which decreases olfactory sensors which are essential for tasting flavor in dishes.\n\nFood safety is paramount in the airline catering industry. A case of mass food poisoning amongst the passengers on an airliner could have disastrous consequences. For example, on February 20, 1992, shrimp tainted with cholera was served on Aerolíneas Argentinas Flight 386. An elderly passenger died and other passengers fell ill. For this reason catering firms and airlines have worked together to provide a set of industry guidelines specific to the needs of airline catering. The World Food Safety Guidelines for Airline Catering is offered free of charge by the International Flight Service Association.\n\n"}
{"id": "190450", "url": "https://en.wikipedia.org/wiki?curid=190450", "title": "Appropriate technology", "text": "Appropriate technology\n\nAppropriate technology is a movement (and its manifestations) encompassing technological choice and application that is small-scale, decentralized, labor-intensive, energy-efficient, environmentally sound, and locally autonomous. It was originally articulated as intermediate technology by the economist Dr. Ernst Friedrich \"Fritz\" Schumacher in his work \"Small is Beautiful.\" Both Schumacher and many modern-day proponents of appropriate technology also emphasize the technology as people-centered.\n\nAppropriate technology has been used to address issues in a wide range of fields. Well-known examples of appropriate technology applications include: bike- and hand-powered water pumps (and other self-powered equipment), the universal nut sheller, self-contained solar lamps and streetlights, and passive solar building designs. Today appropriate technology is often developed using open source principles, which have led to open-source appropriate technology (OSAT) and thus many of the plans of the technology can be freely found on the Internet. OSAT has been proposed as a new model of enabling innovation for sustainable development.\n\nAppropriate technology is most commonly discussed in its relationship to economic development and as an alternative to technology transfer of more capital-intensive technology from industrialized nations to developing countries. However, appropriate technology movements can be found in both developing and developed countries. In developed countries, the appropriate technology movement grew out of the energy crisis of the 1970s and focuses mainly on environmental and sustainability issues. Today the idea is multifaceted; in some contexts, appropriate technology can be described as the simplest level of technology that can achieve the intended purpose, whereas in others, it can refer to engineering that takes adequate consideration of social and environmental ramifications. The facets are connected through robustness and sustainable living.\n\nIndian ideological leader Mahatma Gandhi is often cited as the \"father\" of the appropriate technology movement. Though the concept had not been given a name, Gandhi advocated for small, local and predominantly village-based technology to help India's villages become self-reliant. He disagreed with the idea of technology that benefited a minority of people at the expense of the majority or that put people out of work to increase profit. In 1925 Gandhi founded the All-India Spinners Association and in 1935 he retired from politics to form the All-India Village Industries Association. Both organizations focused on village-based technology similar to the future appropriate technology movement.\n\nChina also implemented policies similar to appropriate technology during the reign of Mao Zedong and the following Cultural Revolution. During the Cultural Revolution, development policies based on the idea of \"walking on two legs\" advocated the development of both large-scale factories and small-scale village industries.\n\nDespite these early examples, Dr. Ernst Friedrich \"Fritz\" Schumacher is credited as the founder of the appropriate technology movement. A well-known economist, Schumacher worked for the British National Coal Board for more than 20 years, where he blamed the size of the industry's operations for its uncaring response to the harm black-lung disease inflicted on the miners. However it was his work with developing countries, such as India and Burma, which helped Schumacher form the underlying principles of appropriate technology.\n\nSchumacher first articulated the idea of \"intermediate technology,\" now known as appropriate technology, in a 1962 report to the Indian Planning Commission in which he described India as long in labor and short in capital, calling for an \"intermediate industrial technology\" that harnessed India's labor surplus. Schumacher had been developing the idea of intermediate technology for several years prior to the Planning Commission report. In 1955, following a stint as an economic advisor to the government of Burma, he published the short paper \"Economics in a Buddhist Country,\" his first known critique of the effects of Western economics on developing countries. In addition to Buddhism, Schumacher also credited his ideas to Gandhi.\n\nInitially, Schumacher's ideas were rejected by both the Indian government and leading development economists. Spurred to action over concern the idea of intermediate technology would languish, Schumacher, George McRobie, Mansur Hoda and Julia Porter brought together a group of approximately 20 people to form the Intermediate Technology Development Group (ITDG) in May 1965. Later that year, a Schumacher article published in the Observer garnered significant attention and support for the group. In 1967, the group published the \"Tools for Progress: A Guide to Small-scale Equipment for Rural Development\" and sold 7,000 copies. ITDG also formed panels of experts and practitioners around specific technological needs (such as building construction, energy and water) to develop intermediate technologies to address those needs. At a conference hosted by the ITDG in 1968 the term \"intermediate technology\" was discarded in favor of the term \"appropriate technology\" used today. Intermediate technology had been criticized as suggesting the technology was inferior to advanced (or high) technology and not including the social and political factors included in the concept put forth by the proponents. In 1973, Schumacher described the concept of appropriate technology to a mass audience in his influential work, \"Small is Beautiful: Economics as if People Mattered.\"...\n\nBetween 1966 and 1975 the number of new appropriate technology organizations founded each year was three times greater than the previous nine years. There was also an increase in organizations focusing on applying appropriate technology to the problems of industrialized nations, particularly issues related to energy and the environment. In 1977, the OECD identified in its \"Appropriate Technology Directory\" 680 organizations involved in the development and promotion of appropriate technology. By 1980, this number had grown to more than 1,000. International agencies and government departments were also emerging as major innovators in appropriate technology, indicating its progression from a small movement fighting against the established norms to a legitimate technological choice supported by the establishment. For example, the Inter-American Development Bank created a Committee for the Application of Intermediate Technology in 1976 and the World Health Organization established the Appropriate Technology for Health Program in 1977.\n\nAppropriate technology was also increasingly applied in developed countries. For example, the energy crisis of the mid-1970s led to the creation of the National Center for Appropriate Technology (NCAT) in 1977 with an initial appropriation of 3 million dollars from the U.S. Congress. The Center sponsored appropriate technology demonstrations to \"help low-income communities find better ways to do things that will improve the quality of life, and that will be doable with the skills and resources at hand.\" However, by 1981 the NCAT's funding agency, Community Services Administration, had been abolished. For several decades NCAT worked with the US departments of Energy and Agriculture on contract to develop appropriate technology programs. Since 2005, NCAT's informational web site is no longer funded by the US government.\n\nIn more recent years, the appropriate technology movement has continued to decline in prominence. Germany's German Appropriate Technology Exchange (GATE) and Holland's Technology Transfer for Development (TOOL) are examples of organizations no longer in operation. Recently, a study looked at the continued barriers to AT deployment despite the relatively low cost of transferring information in the internet age. The barriers have been identified as: AT seen as inferior or \"poor person's\" technology, technical transferability and robustness of AT, insufficient funding, weak institutional support, and the challenges of distance and time in tackling rural poverty.\n\nA more free market-centric view has also begun to dominate the field. For example, Paul Polak, founder of International Development Enterprises (an organization that designs and manufactures products that follow the ideals of appropriate technology), declared appropriate technology dead in a 2010 blog post.\n\nPolak argues the \"design for the other 90 percent\" movement has replaced appropriate technology. Growing out of the appropriate technology movement, designing for the other 90 percent advocates the creation of low-cost solutions for the 5.8 billion of the world's 6.8 billion population \"who have little or no access to most of the products and services many of us take for granted.\"\n\nMany of the ideas integral to appropriate technology can now be found in the increasingly popular \"sustainable development\" movement, which among many tenets advocates technological choice that meets human needs while preserving the environment for future generations. In 1983, the OECD published the results of an extensive survey of appropriate technology organizations titled, \"The World of Appropriate Technology,\" in which it defined appropriate technology as characterized by \"low investment cost per work-place, low capital investment per unit of output, organizational simplicity, high adaptability to a particular social or cultural environment, sparing use of natural resources, low cost of final product or high potential for employment.\" Today, the OECD web site redirects from the \"Glossary of Statistical Terms\" entry on \"appropriate technology\" to \"environmentally sound technologies.\" The United Nations' \"Index to Economic and Social Development\" also redirects from the \"appropriate technology\" entry to \"sustainable development.\"\n\nDespite the decline, several appropriate technology organizations are still in existence, including the ITDG which became Practical Action after a name change in 2005. Skat (Schwierzerische Kontaktstelle für Angepasste Technology) adapted by becoming a private consultancy in 1998, though some Intermediate Technology activities are continued by Skat Foundation through the Rural Water Supply Network (RWSN). Another actor still very active is the charity CEAS (Centre Ecologique Albert Schweitzer). Pioneer in food transformation and solar heaters, it offers vocational training in West Africa and Madagascar. There is also currently a notable resurgence as viewed by the number of groups adopting open source appropriate technology (OSAT) because of the enabling technology of the Internet. These OSAT groups include: Akvo Foundation, Appropedia, Appropriate Technology Collaborative, Catalytic Communities, Centre for Alternative Technology, Center For Development Alternatives, Engineers Without Borders, Open Source Ecology, Practical Action, and Village Earth. Most recently ASME, Engineers Without Borders(USA) and the IEEE have joined together to produce Engineering for Change, which facilitates the development of affordable, locally appropriate and sustainable solutions to the most pressing humanitarian challenges.\n\nAppropriate technology frequently serves as an umbrella term for a variety names for this type of technology. Frequently these terms are used interchangeably; however, the use of one term over another can indicate the specific focus, bias or agenda of the technological choice in question. Though the original name for the concept now known as appropriate technology, \"intermediate technology\" is now often considered a subset of appropriate technology that focuses on technology that is more productive than \"inefficient\" traditional technologies, but less costly than the technology of industrialized societies. Other types of technology under the appropriate technology umbrella include:\nA variety of competing definitions exist in academic literature and organization and government policy papers for each of these terms. However, the general consensus is appropriate technology encompasses the ideas represented by the above list. Furthermore, the use of one term over another in referring to an appropriate technology can indicate ideological bias or emphasis on particular economic or social variables. Some terms inherently emphasize the importance of increased employment and labor utilization (such as labor-intensive or capital-saving technology), while others may emphasize the importance of human development (such as self-help and people's technology).\n\nIt is also possible to distinguish between \"hard\" and \"soft\" technologies. According to Dr. Maurice Albertson and Audrey Faulkner, appropriate \"hard\" technology is \"engineering techniques, physical structures, and machinery that meet a need defined by a community, and utilize the material at hand or readily available. It can be built, operated and maintained by the local people with very limited outside assistance (e.g., technical, material, or financial). it is usually related to an economic goal.\"\n\nAlbertson and Faulkner consider appropriate \"soft\" technology as technology that deals with \"the social structures, human interactive processes, and motivation techniques. It is the structure and process for social participation and action by individuals and groups in analyzing situations, making choices and engaging in choice-implementing behaviors that bring about change.\"\n\nSome of the well known practitioners of the appropriate technology-sector include:\nB.V. Doshi, Buckminster Fuller, William Moyer (1933–2002), Amory Lovins, Sanoussi Diakité, Albert Bates, Victor Papanek, Giorgio Ceragioli (1930–2008), Frithjof Bergmann, Arne Næss, (1912–2009), and Mansur Hoda, Laurie Baker.\n\nSchumacher's initial concept of intermediate technology was created as a critique of the currently prevailing development strategies which focused on maximizing aggregate economic growth through increases to overall measurements of a country's economy, such as gross domestic product (GDP). Developed countries became aware of the situation of developing countries during and in the years following World War II. Based on the continuing rise in income levels in Western countries since the Industrial Revolution, developed countries embarked on a campaign of massive transfers of capital and technology to developing countries in order to force a rapid industrialization intended to result in an economic \"take-off\" in the developing countries.\n\nHowever, by the late 1960s it was becoming clear this development method had not worked as expected and a growing number of development experts and national policy makers were recognizing it as a potential cause of increasing poverty and income inequality in developing countries. In many countries, this influx of technology had increased the overall economic capacity of the country. However, it had created a dual or two-tiered economy with pronounced division between the classes. The foreign technology imports were only benefiting a small minority of urban elites. This was also increasing urbanization with the rural poor moving to urban cities in hope of more financial opportunities. The increased strain on urban infrastructures and public services led to \"increasing squalor, severe impacts on public health and distortions in the social structure.\"\n\nAppropriate technology was meant to address four problems: extreme poverty, starvation, unemployment and urban migration. Schumacher saw the main purpose for economic development programs was the eradication of extreme poverty and he saw a clear connection between mass unemployment and extreme poverty. Schumacher sought to shift development efforts from a bias towards urban areas and on increasing the output per laborer to focusing on rural areas (where a majority of the population still lived) and on increasing employment.\n\nThe term \"appropriate technology\" is also used in developed nations to describe the use of technology and engineering that result in less negative impacts on the environment and society, i.e., technology should be both environmentally sustainable and socially appropriate. E. F. Schumacher asserts that such technology, described in the book \"Small is Beautiful\" tends to promote values such as health, beauty and permanence, in that order.\n\nOften the type of appropriate technology that is used in developed countries is \"appropriate and sustainable technology\" (AST), appropriate technology that, besides being functional and relatively cheap (though often more expensive than true AT), is durable and employs renewable resources. AT does not include this (see Sustainable design).\n\nIn order to increase the efficiency of a great number of city services (efficient water provisioning, efficient electricity provisioning, easy traffic flow, water drainage, decreased spread of disease with epidemics, ...), the city itself must first be built correctly. In the developing world, many cities are expanding rapidly and new ones are being built. Looking into the cities design in advance is a must for every developing nation.\n\nThe local context must be considered as, for example, mudbrick may not be durable in a high rainfall area (although a large roof overhang and cement stabilisation can be used to correct for this), and, if the materials are not readily available, the method may be inappropriate. Other forms of natural building may be considered appropriate technology, though in many cases the emphasis is on sustainability and self-sufficiency rather than affordability or suitability. As such, many buildings are also built to function as autonomous buildings (e.g. earthships, ...). One example of an organisation that applies appropriate earthbuilding techniques would be Builders Without Borders.\n\nThe building structure must also be considered. Cost-effectiveness is an important issue in projects based around appropriate technology, and one of the most efficient designs herein is the public housing approach. This approach lets everyone have their own sleeping/recreation space, yet incorporate communal spaces e.g. mess halls, latrines, public showers, ...\n\nIn addition, to decrease costs of operation (heating, cooling, ...) techniques as Earth sheltering, Trombe walls, ... are often incorporated.\n\nOrganizations as Architecture for Humanity also follows principles consistent with appropriate technology, aiming to serve the needs of poor and disaster-affected people.\n\nAppropriate technology has been applied extensively to improve agricultural production in developing countries. In the United States, the National Center for Appropriate Technology operates ATTRA (attra.ncat.org), a national sustainable agriculture assistance program.\n\nAs of 2006, waterborne diseases are estimated to cause 1.8 million deaths each year while about 1.1 billion people lack proper drinking water.\n\nWater generally needs treatment before use, depending on the source and the intended use (with high standards required for drinking water). The quality of water from household connections and community water points in low-income countries is not reliably safe for direct human consumption. Water extracted directly from surface waters and open hand-dug shallow wells nearly always requires treatment.\n\nAppropriate technology options in water treatment include both community-scale and household-scale point-of-use (POU) designs.\n\nThe most reliable way to kill microbial pathogenic agents is to heat water to a rolling boil. Other techniques, such as varying forms of filtration, chemical disinfection, and exposure to ultraviolet radiation (including solar UV) have been demonstrated in an array of randomized control trials to significantly reduce levels of waterborne disease among users in low-income countries.\n\nOver the past decade, an increasing number of field-based studies have been undertaken to determine the success of POU measures in reducing waterborne disease. The ability of POU options to reduce disease is a function of both their ability to remove microbial pathogens if properly applied and such social factors as ease of use and cultural appropriateness. Technologies may generate more (or less) health benefit than their lab-based microbial removal performance would suggest.\n\nThe current priority of the proponents of POU treatment is to reach large numbers of low-income households on a sustainable basis. Few POU measures have reached significant scale thus far, but efforts to promote and commercially distribute these products to the world's poor have only been under way for a few years.\n\nOn the other hand, small-scale water treatment is reaching increasing fractions of the population in low-income countries, particularly in South and Southeast Asia, in the form of water treatment kiosks (also known as water refill stations or packaged water producers). While quality control and quality assurance in such locations may be variable, sophisticated technology (such as multi-stage particle filtration, UV irradiation, ozonation, and membrane filtration) is applied with increasing frequency. Such microenterprises are able to vend water at extremely low prices, with increasing government regulation. Initial assessments of vended water quality are encouraging.\n\nWhether applied at the household or community level, some examples of specific treatment processes include:\n\nSome appropriate technology water supply measures include:\n\nPoor sanitation is a major issue for a large proportion of the human population, with about 2.5 billion people lacking even the most basic forms of sanitation and more than a billion people worldwide practising open defecation in 2015 according to the Joint Monitoring Programme for Water Supply and Sanitation of the United Nations.\n\nThe ideas of appropriate technology influenced the provision of sanitation systems for many years. However, since about the early 2000s there has been a departure from a focus on simplistic 'one-size-fits-all' sanitation systems. As conditions vary, sanitation systems also need to vary to meet the needs of the users and other stakeholders.\n\nTechnologies for sanitation provision, such as toilets, are important but only one piece of the puzzle. Sanitation needs to be regarded as a system that includes technical and non-technical aspects, such as behavior change and management as well as political aspects – the enabling environment. The overall aim should be to achieve a sustainable sanitation system. One option of achieving that aim can be the ecological sanitation approach which focuses on safe reuse of excreta.\n\nIt is impossible to name all possible sanitation technologies that may fall under the category of \"appropriate technologies\" but some common systems which might be considered to be \"appropriate\" include:\n\nThe term soft energy technology was coined by Amory Lovins to describe \"appropriate\" renewable energy.\n\"Appropriate\" energy technologies are especially suitable for isolated and/or small scale energy needs. Electricity can be provided from:\n\nSome intermediate technologies include:\n\nFinally, urine can also be used as a basis to generate hydrogen (which is an energy carrier). Using urine, hydrogen production is 332% more energy efficient than using water.\n\nElectricity distribution could be improved so to make use of a more structured electricity line arrangement and universal AC power plugs and sockets (e.g. the CEE 7/7 plug). In addition, a universal system of electricity provisioning (e.g. universal voltage, frequency, ampère; e.g. 230 V with 50 Hz), as well as perhaps a better mains power system (e.g. through the use of special systems as perfected single-wire earth returns; e.g. Tunisia's MALT-system, which features low costs and easy placement)\n\nElectricity storage (which is required for autonomous energy systems) can be provided through appropriate technology solutions as deep-cycle and car-batteries (intermediate technology), long duration flywheels, electrochemical capacitors, compressed air energy storage (CAES), liquid nitrogen and pumped hydro. Many solutions for the developing world are sold as a single package, containing a (micro) electricity generation power plant and energy storage. Such packages are called remote-area power supply\n\nHuman powered-vehicles include the bicycle (and the future bamboo bicycle), which provides general-purpose transportation at lower costs compared to motorized vehicles, and many advantages over walking, and the whirlwind wheelchair, which provides mobility for disabled people who cannot afford the expensive wheelchairs used in developed countries. Animal powered vehicles/transport may also be another appropriate technology.\nCertain zero-emissions vehicles may be considered appropriate transportation technology, including compressed air cars, liquid nitrogen and hydrogen-powered vehicles. Also, vehicles with internal combustion engines may be converted to hydrogen or oxyhydrogen combustion.\n\nBicycles can also be applied to commercial transport of goods to and from remote areas. An example of this is Karaba, a free-trade coffee co-op in Rwanda, which uses 400 modified bicycles to carry hundreds of pounds of coffee beans for processing. Other projects for developing countries include the redesign of cycle rickshaws to convert them to electric power. However recent reports suggest that these rickshaws are not plying on the roads.\n\nAccording to the Global Health Council, rather than the use of professionally schooled doctors, the training of villagers to remedy most maladies in towns in the developing world is most appropriate. Trained villagers are able to eliminate 80% of the health problems. Small (low-cost) hospitals – based on the model of the Jamkhed hospital – can remedy another 15%, while only 5% will need to go to a larger (more expensive) hospital.\n\nNote that many Appropriate Technologies benefit public health, in particular by providing sanitation and safe drinking water. Refrigeration may also provide a health benefit. (These are discussed in the following paragraphs.) This was too found at the Comprehensive Rural Health Project and the Women Health Volunteers projects in countries as Iran, Iraq and Nepal.\n\nSome proven intensive, low-effort food-production systems include urban gardening (indoors and outdoors). Indoor cultivation may be set up using hydroponics with Grow lights, while outdoor cultivation may be done using permaculture, forest gardening, no-till farming, Do Nothing Farming, etc. In order to better control the irrigation outdoors, special irrigation systems may be created as well (although this increases costs, and may again open the door to cultivating non-indigenous plants; something which is best avoided).\nOne such system for the developing world is discussed here.\n\nCrop production tools are best kept simple (reduces operating difficulty, cost, replacement difficulties and pollution, when compared to motorized equipment). Tools can include scythes, animal-pulled plows (although no-till farming should be preferred), dibbers, wheeled augers (for planting large trees), kirpis, hoes, ...\n\nGreenhouses are also sometimes included (see Earthship Biotincture). Sometimes they are also fitted with irrigation systems, and/or heat sink-systems which can respectively irrigate the plants or help to store energy from the sun and redistribute it at night (when the greenhouse starts to cool down).\n\nAccording to proponents, Appropriate Technologies can greatly reduce the labor required to prepare food, compared to traditional methods, while being much simpler and cheaper than the processing used in Western countries. This reflects E.F. Schumacher's concept of \"intermediate technology,\" i.e. technology which is significantly more effective and expensive than traditional methods, but still an order of magnitude (10 times) cheaper than developed world technology. Key examples are:\n\n\nThrough financial systems envisioned especially for the poor/developed world, many companies have been able to get started with only limited capital. Often banks lend the money to people wishing to start a business (such as with microfinance). In other systems, people for a Rotating Savings and Credit Association or ROSCA to purchase costly material together (such as Tontines and Susu accounts). Organisations, communities, cities or individuals can provide loans to other communities/cities (such as with the approach followed by Kiva, World Vision Microloans MicroPlace and LETS). Finally, in certain communities (usually isolated communities such as small islands or oases) everything of value is shared. This is called gift economy.\n\nFeatures such as low cost, low usage of fossil fuels and use of locally available resources can give some advantages in terms of sustainability. For that reason, these technologies are sometimes used and promoted by advocates of sustainability and alternative technology.\n\nBesides using natural, locally available resources (e.g. wood or adobe), waste materials imported from cities using conventional (and inefficient) waste management may be gathered and re-used to build a sustainable living environment. Use of these cities' waste material allows the gathering of a huge amount of building material at a low cost. When obtained, the materials may be recycled over and over in the own city/community, using the cradle to cradle design method. Locations where waste can be found include landfills, junkyards, on water surfaces and anywhere around towns or near highways. Organic waste that can be reused to fertilise plants can be found in sewages. Also, town districts and other places (e.g. cemeteries) that are subject of undergoing renovation or removal can be used for gathering materials as stone, concrete, or potassium.\n\n\n"}
{"id": "57887390", "url": "https://en.wikipedia.org/wiki?curid=57887390", "title": "Aurora Pulsed Radiation Simulator", "text": "Aurora Pulsed Radiation Simulator\n\nThe Aurora Pulsed Radiation Simulator (also known as the Aurora flash x-ray simulator) is a 14 TW flash gamma-ray simulator that was designed to simulate the effects of a nuclear weapon’s bremsstrahlung, or gamma radiation, pulses on military electronic systems. It was built in 1971 by the U.S. Defense Atomic Support Agency (DASA), which eventually became the Defense Threat Reduction Agency, and the U.S. Department of Energy (DOE).\n\nMore than 161 feet long and weighing at 1,450 tons, the Aurora Simulator was the first gamma radiation simulator of its size in the world at the time. It was also one of only four large machines in the United States that were built specifically to test complete nuclear weapons packages, with the other three being the Hermes I to III simulators at Sandia Base, New Mexico. Situated at the Harry Diamond Laboratories (which later became a part of the Army Research Laboratory) in Adelphi, Maryland, it was used to test complete weapons electronics packages from the warheads of intercontinental ballistic missiles (ICBMs) to satellites. After more than 20 years of use during the Cold War, the Aurora Simulator was officially decommissioned and disassembled in 1996.\n\nIn 1986, the Aurora facility set the world record for the largest amount of high-power microwave power generated from a virtual cathode oscillator. As a result, HDL was recognized by the American Defense Preparedness Association (ADPA) in 1987. \n\nFollowing the use of the atomic bomb in World War II, studies on flash radiography found that field emission flash x-rays, which were previously used to analyze explosions, could simulate radiation from a nuclear bomb. Given this realization, the U.S. military began to prioritize the development of flash x-ray machines to test parts of missile packages during the 1960s. \n\nAfter the Soviet Union demonstrated the use of the world’s first anti-ballistic missiles (ABM) in 1964, DASA launched a series of projects in response that aimed to hasten the advancement of nuclear effects laboratories in the United States. The U.S. military was concerned that the introduction and subsequent nuclear explosion of Soviet AMBs into the airspace would increase the likelihood of the resulting radiation interfering with the electronics systems of inbound U.S. ICBMs. In order to thoroughly harden U.S. missiles, DASA initiated the construction of the Aurora Simulator as well as a full-threat level facility that engaged in gamma radiation testing and missile refinement in 1969.\n\nWhen selecting the site for the Aurora facility, DASA wanted the gamma radiation simulator to be situated at an existing military laboratory. After much deliberation between the Air Force Weapons Laboratory (AFWL) in New Mexico and the Army and Navy laboratories in the Washington, D.C. area, DASA chose the latter and granted the Harry Diamond Laboratory (HDL) the responsibility of operating the facility. In order to house the Aurora Simulator, HDL moved from its downtown Washington, D.C. site to an area of land in White Oak, Maryland, which would eventually become the now-present Adelphi.\n\nThe cooperation between DASA and HDL on the Aurora project led to many HDL researchers becoming involved in the simulator’s development, including assistant to DASA Deputy Director for Science and Technology Peter Haas and former participant in the Manhattan Project Paul Caldwell, who later was placed in charge of the Aurora Simulator. In turn, Caldwell hired physicist Alexander Stewart from Ion Physics (IP) and HDL’s Robert Lamb and Dennis Whittaker, the four of whom (including Caldwell) made up the bulk of the research and development team for the Aurora project. The construction of the Aurora Simulator was completed on January 1971, costing about $16 million, and the first test was conducted on the Spartan ABM flight control set in April 1972. Throughout its entire run at HDL, which ended in 1995, the Aurora Simulator conducted 287 numbered tests, resulting in more than 9,100 test shots.\n\nThe Aurora Pulsed Radiation Simulator consisted of four 14 MV Marx generators, each of which contained four parallel 1.25 MJ units connected together to drive four parallel oil-dielectric Blumlein pulse-forming lines (PFLs). Each PFL was coupled with an E-beam diode.\n\nThe Aurora Simulator emitted four short pulses of high energy bremsstrahlung radiation that overlapped to deliver a single 120 ns wide pulse of 20 to 50 krads (Si) into a 1m cube. It could also deliver 25 krads (Si) throughout a 1m diameter and 1m long cylindrical volume or 50 krads (Si) throughout a 25cm sphere. What made the Aurora Simulator unique was its ability to provide an extremely high volumetric dose output. Due to this large irradiation volume, dose measurements ranged up to 200 locations within a single electronics system. However, in order to obtain the desired radiation levels, all four 8-MeV, 230-kA bremsstrahlung pulses had to overlay within 10 ns. This synchronization was made possible by the symmetrization of the four Blumleins. During active testing, the Aurora Simulator was capable of accommodating as many as 13 test shots in a single day. In comparison, nuclear weapons testing at the Nevada Test Site was limited to one test shot per three months.\n\nThere were two main limitations to the operation of the Aurora Simulator. First, the long discharge time of the Blumeins often hindered the extraction of the bremsstrahlung pulses. Second, the high internal impedance of the Blumeins made them rather inefficient for energy transfer to low impedance loads.\n"}
{"id": "2768593", "url": "https://en.wikipedia.org/wiki?curid=2768593", "title": "Bank code", "text": "Bank code\n\nA bank code is a code assigned by a central bank, a bank supervisory body or a Bankers Association in a country to all its licensed member banks or financial institutions. The rules vary to a great extent between the countries. Also the name of bank codes varies. In some countries the bank codes can be viewed over the internet, but mostly in the local language.\n\nThe (national) bank codes differ from the international Bank Identifier Code (BIC/ISO 9362, a normalized code - also known as Business Identifier Code, Bank International Code and SWIFT code). Those countries which use International Bank Account Numbers (IBAN) have mostly integrated the bank code into the prefix of specifying IBAN account numbers. The bank codes also differ from the Bank card code (CSC).\n\nThe term \"bank code\" is sometimes (inappropriately) used by merchants to refer to the Card Security Code printed on a credit card.\n\nAs of February 2014 all countries in the Single Euro Payments Area have switched to an IBAN-based system for clearing (including TARGET2 for cross-border transfers). The national bank codes have been integrated into the IBAN definition, in most cases at the start of the new account number (starting at position 5 after the common prefix of two-letter country identifier and two check digits). This is valid for transfers in the euro currency. Countries which retain their own currency use their own system for transfers in their currency.\n\n\n\n\n\n"}
{"id": "26447606", "url": "https://en.wikipedia.org/wiki?curid=26447606", "title": "Beam and block", "text": "Beam and block\n\nBeam and block is a construction method to support flooring, especially for ground floors as well as multi storey buildings. It is made of cast concrete, one piece of which is a prestressed concrete Beam which can be inverted T-shape beam, or lintel, the other piece being a simple rectangular block. The blocks are placed at regular intervals and the beams placed between them to form a connection between each block section. They form a support for the next layer of flooring materials.\n\nBeam and Block is also referred to as Rib and block and lintel and block is some countries. Certain countries incorporate the use of temporary propping for 21 days while other rib and block systems use propless systems. Systems where props are used incorporate lighter beams while the prop line allows for structural cross support. Propless systems used heavier inverted T beams to compensate for the exclusion of props.\n\nThe lintels and blocks are packed above load bearing walls under supervision and design by a structural engineer. This system is extremely versatile in achieving complex designs and using unskilled labour. It is cost efficient as well as easily understood by all contractors.\n\nThe use of polystyrene blocks to replace concrete hollow blocks are used for lightweight insulated slabs. This keeps buildings warmer in winter and cooler in summer. From a structural viewpoint a lighter slab assists by allowing load bearing walls and foundations taking less strain.\n"}
{"id": "57924291", "url": "https://en.wikipedia.org/wiki?curid=57924291", "title": "Bluebonnet Ordnance Plant", "text": "Bluebonnet Ordnance Plant\n\nBluebonnet Ordnance Plant was a munitions plant near McGregor, Texas, which manufactured TNT, bombs, ammonium nitrate and similar products for the American troops during World War II. BlueBonnet Ordnance Plant was one of four ordnance plants in the United States during World War II. \n\nDuring the earliest days of McGregor, Texas, the future site of Bluebonnet Ordnance was the crossroads of two railroads in 1879 (Santa Fe Railroad and the Cotton Belt Railroad). The site that would become the plant had fertile, rich soil which contributed to its usages years later. Gradually the McGregor area grew by over 1200 citizens in the 1920s setting the foundation for the founding of the plant a decade later.\n\nAs the United States engaged in World War II, existing plants and equipment were considered for conversion to directly support the war effort. The National Gypsum Company of Buffalo successfully lobbied the United States War Department to purchase their 18,000 acre facility located near McGregor, Texas for the construction and operation of a munitions plant. On March 7, 1942; National Gypsum executives worked with Army engineers in Waco, Texas, to come up with the design and construction of the plant. The offices that were set up for this endeveour was located in the Armory and in the Waco library.\n\nThe plant was operated by the National Gypsum Company but overseen by the military and was one of the four Ordnance plants in the United States during World War II. The army engineers were in charge of all plant construction while the Gypsum personnel and others worked out other strategies. Bluebonnet Ordnance Plant got its name from Major Paul Van Tuyl, who named the plant after the state flower of Texas (Bluebonnet).\n\nThe munitions plant started production of bombs on October 16, 1942. Over 1100 automobiles and trucks went to and from the plant each day, taking workers to and from the plant. Many of the workers at the plant were from out of state, and even out of the region. The plant primarily manufactured TNT and ammonium nitrate used to fill bomb casings which were manufactured elsewhere. Production was focused on three bomb types: armor piercing, general purpose and fragmentation. Bluebonnet also produced other ordnance products, including 105-mm semi-fixed high explosive shells, bomb booster charges, and demolition blocks. At maximum production, the plant employed 5,732 workers. The plant ceased production on August 14, 1945.\n\nAfter the war, the facilities were converted to support the development and manufacture of ammonium nitrate based solid rocket propellants and operated by a number of successive companies: Phillips Petroleum Company (1952–1958), Astrodyne Incorporated (1958–1959), Rocketdyne (1959–1978), and Hercules Inc. (1978–1995). In 1995 Hercules transferred their operations to the Allegany Ballistics Laboratory in West Virginia, ending the manufacture of energetic materials at the site.\n\nThe overall size of the former Bluebonnet Ordnance Plant was reduced over time by the rededication of land to agricultural research and conversion into an industrial park. The now defunct Beal Aerospace established rocket engine testing facilities within the remaining portion before going out of business in October, 2000. The upgraded facilities are now used by SpaceX as their Rocket Development and Test Facility. Some of the wood from the Bluebonnet Ordnance Plant was used in the construction of a pizzeria in Waco in 2016.\n"}
{"id": "3946504", "url": "https://en.wikipedia.org/wiki?curid=3946504", "title": "Break junction", "text": "Break junction\n\nA break junction is an electronic device which consists of two metal wires separated by a very thin gap, on the order of the inter-atomic spacing (less than a nanometer). This can be done by physically pulling the wires apart or through chemical etching or electromigration. As the wire breaks, the separation between the electrodes can be indirectly controlled by monitoring the electrical resistance of the junction.\n\nAfter the gap is formed, its width can often be controlled by bending the substrate that the metal contacts lie on. The gap can be controlled to a precision of picometers.\n\nA typical conductance versus time trace during the breaking process (conductance is simply current divided by applied voltage bias) shows two regimes. First is a regime where the break junction comprises a quantum point contact. In this regime conductance decreases in steps equal to the conductance quantum formula_1 which is expressed through the electron charge (−\"e\") and Planck's constant formula_2. The conductance quantum has a value of 7.74×10 siemens, corresponding to a resistance increase of roughly 12.9 kΩ. These step decreases are interpreted as the result of a decrease, as the electrodes are pulled apart, in the number of single-atom-wide metal strands bridging between the two electrodes, each strand having a conductance equal to the quantum of conductance. As the wire is pulled, the neck becomes thinner with fewer atomic strands in it. Each time the neck reconfigures, which happens abruptly, a step-like decrease of the conductance can be observed. This picture inferred from the current measurement has been confirmed by \"in-situ\" TEM imaging of the breaking process combined with current measurement.\n\nIn a second regime, when the wire is pulled further apart, the conductance collapses to values less than the quantum of conductance. This is the tunneling regime where electrons tunnel through vacuum between the electrodes.\n\nBreak junctions are used to make electrical contacts to study single molecules.\n"}
{"id": "5289467", "url": "https://en.wikipedia.org/wiki?curid=5289467", "title": "Brown powder", "text": "Brown powder\n\nBrown powder or prismatic powder, sometimes referred as \"cocoa powder\" due to its color, was a propellant used in large artillery and ship's guns from about the 1870s. While similar to black powder, it was chemically formulated and formed hydraulically into a specific grain shape to provide a slower burn rates with neutral or progressive burning, as opposed to the faster and regressive burn typical of randomly shaped grains of black powder produced by crushing and screening powder formed into sheets in a press box, as was typical for cannon powder previously.\n\nFor pure explosive damage, high burn rates or detonation speeds (and accompanying brisance) are generally preferable, but in guns and especially cannons, slower-burning powder decreases firing stresses. This allows for lighter, longer (and more accurate) barrels with associated decreases in production and maintenance costs. Further modifications of its burning rate were achieved by shaping the powder grains into prismatic shapes, typically single-perforated hexagonal or octagonal prisms.\n\nThey became obsolete as a propellant due to the introduction of nitro-explosive propellants such as Poudre B, in France, and later by cordite, in Britain. These new propellants produced less smoke, particularly less black smoke.\n\nThe differences in burning rate were achieved by several means. Changes to formulation were altering ingredients relative percentage by weight and using differently processed charcoals for fuel than those of a standard 75:15:10 (potassium nitrate:charcoal:sulfur) black cannon powder. \n\nTypically, sulfur was either not used in brown powders, or Sulfur content reduced to around 1% by weight from the usual 10%. The reduction or outright removal of sulfur slowed the burn rate, while replacement of higher molecular weight sulfur dioxide by carbon dioxide or monoxide in the propellant gas mixture gave a higher specific impulse. \n\nDifferently processed charcoals were used. Fully carbonized charcoal (mostly composed of elemental carbon) in black powder provides its distinctive black color, while its replacement with an incompletely carbonized, brownish colored charcoal produces a dark brown appearance, hence the names \"brown powder\" or \"cocoa powder\". The less carbonized charcoal was \"more\" reactive than fully carbonized charcoal, somewhat making up for the easy ignition characteristics usually provided by sulfur. The Brown charcoal also helped to produce sturdier grains and replaced sulfur in the role of a binder.\n\nFurther modifications of burn rate were achieved by shaping the individual powder grains, often into prismatic shapes such as single-perforated hexagonal or octagonal prisms.\n\nLarge-grained powder, made in the traditional way as flat sheets but screened to larger sizes, was introduced in the 1850s by U.S. Army Major Thomas Rodman for his large-calibre cannon. In 1875 Lammot du Pont invented \"Hexagonal\" powder for large artillery, which was pressed using shaped plates with a small center core; about diameter, like a wagon wheel nut, the center hole widened as the grain burned. By 1880 naval guns were using Hexagonal grains, in height. Very large grain powders, being subject to defects in manufacturing, did not completely remove the danger of overpressure, as demonstrated in the 1880 accident on the Italian ironclad \"Caio Duilio\", which involved powder made at the chemical works at Fossano.\n\nIn 1884 the German Rottweil Company developed Prismatic Brown Powder (PBC), which was also adopted by the Royal Navy in 1884. It retarded burning even further by using only 2 percent sulfur and using charcoal made from rye straw that had not been completely charred. It was pressed into prisms with a central hole, similar to the DuPont Hexagonal.\n\nThe French Navy instead developed the Slow Burning Cocoa (SBC) powder, which had grains of about ; still only 40% of it burned, the rest was ejected as heavy black smoke.\n\nThe first smokeless propellant, the guncotton-based Poudre B was introduced by the French Navy in 1886, triggering rapid development of smokeless compounds which replaced brown powder.\n"}
{"id": "14854540", "url": "https://en.wikipedia.org/wiki?curid=14854540", "title": "Center for Women in Technology", "text": "Center for Women in Technology\n\nThe Center for Women In Technology (CWIT) was established at the University of Maryland, Baltimore County in July 1998. The center's original name was the \"Center for Women and Information Technology\", and it was founded to encourage women as both developers of information technology and to women's experiences as users of IT. The original CWIT site included a large number of resources and links and served as a clearinghouse about women and information technology. This work included focusing on K-12 education as well as supporting university students, and work force advancement and retention. The center has included engineering majors since 2006, and in 2011 its name was changed to the Center for Women In Technology.\n\nThe Center for Women in Technology Scholars Program is a merit scholarship opportunity for talented undergraduates majoring in computer science, computer engineering, information systems or a related program. It is open to high school seniors planning to major in one of these areas of study. Scholars in the program receive mentoring from university faculty and IT professionals as well as participate in specially designed activities and events.\n\nCWIT and the UMBC Center for Cybersecurity jointly run the UMBC Cyber Scholars Program with the goal of preparing the next generation of cybersecurity professionals. The program is funded by the Northrop Grumman Foundation.\n\n\n\n\n\n"}
{"id": "29319967", "url": "https://en.wikipedia.org/wiki?curid=29319967", "title": "Cheese ripening", "text": "Cheese ripening\n\nCheese ripening, alternatively cheese maturation or affinage, is a process in cheesemaking. It is responsible for the distinct flavour of cheese, and through the modification of \"ripening agents\", determines the features that define many different varieties of cheeses, such as taste, texture, and body. The process is \"characterized by a series of complex physical, chemical and microbiological changes\" that incorporates the agents of \"bacteria and enzymes of the milk, lactic culture, rennet, lipases, added moulds or yeasts, and environmental contaminants\". The majority of cheese is ripened, save for fresh cheese.\n\nCheese ripening was not always the highly industrialised process it is today; in the past, cellars and caves were used to ripen cheeses instead of the current highly regulated process involving machinery and biochemistry. Some cheeses still are made using more historical methods, such as the blue cheese Roquefort, which is required to be ripened in designated caves in south-eastern France. However, with the invention of refrigeration in the 20th century, the process evolved considerably, and is much more efficient at producing a consistent quality of cheese, at a faster pace, and a lower cost (depending on the type of cheese).\n\nAfter the initial manufacturing process of the cheese is done, the cheese ripening process occurs. This process is especially important, since it defines the flavour and texture of the cheese, which differentiates the many varieties. Duration is dependent on the type of cheese and the desired quality, and typically ranges from \"three weeks to two or more years\".\n\nRipening is influenced by a variety of factors, ranging from the microflora to the curd, and others. The enzymatic process is the most crucial process for all cheeses, although bacteria plays a role in many varieties. The most important agents in this process include the following elements: \n\n\nEach of these factors affects the cheese-ripening process differently, and has been the subject of much research. It is important for manufacturers to understand how each of these elements work, so that they are able to maintain the quality of the cheese while producing the cheese at an acceptable investment of time and cost. These agents contribute to the three primary reactions that define cheese ripening: glycolysis, proteolysis, and lipolysis.\n\nBy taking the cheese through a series of maturation stages where temperature and relative humidity are carefully controlled, the cheese maker allows the surface mould to grow and the mould ripening of the cheese by fungi to occur. Mould-ripened cheeses ripen faster than hard cheeses, in weeks as opposed to the typical months or even years. This is because the fungi used are more biochemically active than the starter bacteria. Where the ripening occurs is largely dependent on the type of cheese: some cheeses are surface-ripened by moulds, such as Camembert and Brie; and some are ripened internally, such as Stilton. Surface ripening of some cheeses, such as Saint-Nectaire cheese, may also be influenced by yeasts which contribute flavour and coat texture. Others are allowed by the cheesemaker to develop bacterial surface growths which give characteristic colours and appearances. The growth of \"Brevibacterium linens\", for example, creates an orange coat to cheeses.\n\nIn contrast to cheddaring, making cheeses like Camembert requires a more gentle treatment of the curd. It is carefully transferred to cheese hoops and the whey is allowed to drain from the curd by gravity, generally overnight. The cheese curds are then removed from the hoops to be brined by immersion in a saturated salt solution. This is because the amount of salt has a large effect on the rate of proteolysis in the cheese, stopping the bacteria from growing. If white-mould spores have not been added to the cheese milk, the cheese maker applies them to the cheese either by spraying the cheese with a suspension of mould spores in water, or by immersing the cheese in a bath containing spores of, e.g., \"Penicillium candida\".\n\nThe round holes that are a characteristic feature of Swiss-type cheese (e.g. Emmentaler cheese) and some Dutch-type cheeses are called \"eyes\". They are bubbles of carbon dioxide that is produced by bacteria in the cheese.\n\nIn Swiss-type cheeses, the eyes form as a result of the activity of propionic acid bacteria (\"propionibacteria\"), notably \"Propionibacterium freudenreichii\" subsp. \"shermanii\". In Dutch-type cheeses, the CO that forms the eyes results from the metabolisation of citrate by citrate-positive (\"Cit+\") strains of lactococci.\n\nThe process of cheese ripening affects the taste of the final product. If the product is not ripened, the resulting cheese is tasteless, and so, all cheese is ripened except for fresh cheeses. Different factors define taste in cheese, including casein, fat, brine, and many other elements. Brine, as an example, mixes with saliva, delivering the flavour of the cheese to the taste buds and determining the cheese's moistness. Many of these elements are specific to the type of cheese. For instance, proline is more abundant in Emmental than in any other type of cheese, and gives the cheese its much sweeter taste.\n\n\n"}
{"id": "42734157", "url": "https://en.wikipedia.org/wiki?curid=42734157", "title": "CoCalc", "text": "CoCalc\n\nCoCalc (formerly called SageMathCloud) is a web-based cloud computing (SaaS) and course management platform for computational mathematics. Part of the Sage project, it supports editing of Sage worksheets, LaTeX documents and Jupyter notebooks. CoCalc runs an Ubuntu Linux environment that can be interacted with through a terminal, additionally giving access to most of the capabilities of Linux.\n\nCoCalc offers both free and paid accounts. Subscriptions starting at $14/month provide internet access and more storage and computing resources. One subscription can be used to increase quotas for one project used by multiple accounts. There are subscription plans for courses. Over 200 courses have used CoCalc.\n\nCoCalc directly supports Sage worksheets, which interactively evaluate Sage code. The worksheets support Markdown and HTML for decoration, and R, Octave, Cython, Julia and others for programming in addition to Sage. CoCalc supports IPython notebooks, which are enhanced with real-time synchronization for collaboration and a history recording function. Additionally, there is also a full LaTeX editor, with collaboration support, a preview of the resulting document and also support for SageTeX. With the Linux terminal, CoCalc also indirectly supports editing and running many other languages, including Java, C/C++, Perl, Ruby, and other popular languages that can be run on Linux. Other packages can be installed on request.\n\nUsers can have multiple projects on CoCalc, and each project has separate disk space and may be on an entirely different server. Many users can collaborate on a single project, and documents are synced so multiple users can edit the same file at once, similar to Google Docs. All the data on projects is automatically backed up about every five minutes with bup, and snapshots of previous versions are accessible. Through the terminal, files can be tracked using revision control systems like Git.\n\nCoCalc is open source software hosted by SageMath Inc. The creator and lead developer of CoCalc is William Stein, a professor of mathematics at the University of Washington who also created the Sage software system. Initial development was funded by the University of Washington and grants from the National Science Foundation and Google. Now CoCalc is mostly funded by paying users. It is intended as a replacement for sagenb, which also let users edit and share Sage worksheets online.\n\n"}
{"id": "56538024", "url": "https://en.wikipedia.org/wiki?curid=56538024", "title": "Columbia Data Center", "text": "Columbia Data Center\n\nColumbia Data Center is Microsoft's data center in Quincy, Washington. Property at Quincy was purchased in 2006; the building opened in April, 2007; and the data center reached operational status in May, 2017. It was said to be the largest data center in the world as of 2015. The company located there due to low land costs, abundant data fiber, and extremely low cost electricity provided by Grant County PUD for as little as 1.9 or 2.5 cents per kilowatt-hour. Building began with a facility in 2006 and several expansions followed, occupying with of floorspace in two buildings on a complex by 2016.\nThe data center consumed 30 to 50 megawatts in 2012 and employs 50 people.\n"}
{"id": "58733032", "url": "https://en.wikipedia.org/wiki?curid=58733032", "title": "CreditPilot PLC", "text": "CreditPilot PLC\n\nCreditPilot PLC (or Credit Pilot PLC) is an international FinTech company, based in Cyprus and active in the BFSI arena. Its main areas of engagement are platforms for MNOs and MVNOs, retail fintech platforms, acquiring, ESPI (enterprise scale payments), and operating financial regulated companies. The group is mainly active in B2B and B2B2C sectors, with plans to introduce a B2C product in 2019.\n\nCreditPilot was established in 1998 as a FinTech spin-off from Megafon, one of the largest mobile network operators in Russia. Shortly after its establishment, CreditPilot began rendering services not just to its former parent company, but also to numerous other MNOs and service providers in Russia, including banks, utility companies, and retail. The initial array of services offered by CreditPilot was mainly focused on payment kiosks and acquiring; however, starting from the mid-2000s, CreditPilot began to explore other markets, opportunities and areas of expertise, such as SaaS services and establishment of regulated companies, banks and remittance.\n\nThis expansion helped CreditPilot grow, while keeping the company's key focus on providing its business partners with a reliable payments infrastructure. Following a change of ownership in 2010, CreditPilot started a pivot towards processing, FinTech products, and providing ready-to-go platforms to its partners, instead of simply providing services.\n\nWith the growth of its client base, CreditPilot began an organic expansion into the European market, becoming a key player in the sector of regulated companies: banks, remittance companies, payment institutions, etc. In 2018, the company began a restructuring process on the basis of CreditPilot PLC, the result of which should be the company’s listing on the Cyprus Stock Exchange by the end of Q4 2018, with the aim to become a solid presence in the Frankfurt and the London Stock Exchanges, too. CreditPilot took part in Mobile World Congress Shanghai 2018, where it presented its Any2Any platform.\n\nCreditPilot's major focus lies in the transactional and processing platforms that act within a financial market infrastructure and require regulated licenses to operate. As such, CreditPilot offers its clients several proprietary solutions:\n\nThe team behind CreditPilot consists of experts from the telecom, banking, and IT industries. The company's geography spans across the globe from the US, through the Caribbean, to Europe, and now Asia.\n\n\n"}
{"id": "2454067", "url": "https://en.wikipedia.org/wiki?curid=2454067", "title": "Data Recall Diamond", "text": "Data Recall Diamond\n\nThe Data Recall Diamond One was a word processing typewriter, designed and built by Data Recall Ltd at Dorking, Surrey, England in the late 1970s and early 1980s. The machine drove a Qume daisy wheel printer via a serial interface at 35–55 characters per second, and used an 8-inch floppy disc drive capable of holding 250,000 characters. It was user programmable. Later models included the Diamond III, the Diamond Five (a.k.a. Diamond V), and the Diamond 7.\n\nOne of the names suggested for the Amstrad PCW was the Zircon, on the grounds that zircon was \"a Diamond substitute\". This name was rejected.\n\n"}
{"id": "43346724", "url": "https://en.wikipedia.org/wiki?curid=43346724", "title": "Demolition", "text": "Demolition\n\nDemolition or razing is the tearing down of buildings and other man-made structures. Demolition contrasts with deconstruction, which involves taking a building apart while carefully preserving valuable elements for reuse purposes.\n\nFor small buildings, such as houses, that are only two or three stories high, demolition is a rather simple process. The building is pulled down either manually or mechanically using large hydraulic equipment: elevated work platforms, cranes, excavators or bulldozers. Larger buildings may require the use of a wrecking ball, a heavy weight on a cable that is swung by a crane into the side of the buildings. Wrecking balls are especially effective against masonry, but are less easily controlled and often less efficient than other methods. Newer methods may use rotational hydraulic shears and silenced rock-breakers attached to excavators to cut or break through wood, steel, and concrete. The use of shears is especially common when flame cutting would be dangerous.\n\nThe tallest planned demolition of a building was the 47-story Singer Building in New York City, which was built in 1908 and torn down in 1967–1968 to be replaced by One Liberty Plaza.\n\nBefore any demolition activities can take place, there are many steps that must be carried out beforehand, including performing asbestos abatement, removing hazardous or regulated materials, obtaining necessary permits, submitting necessary notifications, disconnecting utilities, rodent baiting and the development of site-specific safety and work plans.\n\nThe typical razing of a building is accomplished as follows:\n\nHydraulic excavators may be used to topple one- or two-story buildings by an undermining process. The strategy is to undermine the building while controlling the manner and direction in which it falls. The demolition project manager/supervisor will determine where undermining is necessary so that a building is pulled in the desired manner and direction. The walls are typically undermined at a building's base, but this is not always the case if the building design dictates otherwise. Safety and cleanup considerations are also taken into account in determining how the building is undermined and ultimately demolished.\n\nIn some cases a crane with a wrecking ball is used to demolish the structure down to a certain manageable height. At that point undermining takes place as described above. However crane mounted demolition balls are rarely used within demolition due to the uncontrollable nature of the swinging ball and the safety implications associated.\n\nHigh reach demolition excavators are more often used for tall buildings where explosive demolition is not appropriate or possible. Excavators with shear attachments are typically used to dismantle steel structural elements. Hydraulic hammers are often used for concrete structures and concrete processing attachments are used to crush concrete to a manageable size, and to remove reinforcing steel. For tall concrete buildings, where neither explosive or high reach demolition with an excavator is safe or practical, the \"inside-out\" method is used, whereby remotely operated mini-excavators demolish the building from the inside, whilst maintaining the outer walls of the building as a scaffolding, as each floor is demolished.\n\nTo control dust, fire hoses are used to maintain a wet demolition. Hoses may be held by workers, secured in fixed location, or attached to lifts to gain elevation.\n\nLoaders or bulldozers may also be used to demolish a building. They are typically equipped with \"rakes\" (thick pieces of steel that could be an I-beam or tube) that are used to ram building walls. Skid loaders and loaders will also be used to take materials out and sort steel.\n\nThe technique of Vérinage is used in France to weaken and buckle the supports of central floors promoting the collapse of the top part of a building onto the bottom resulting in a rapid, symmetrical, collapse.\n\nThe Japanese company Kajima Construction has developed a new method of demolishing buildings which involves using computer-controlled hydraulic jacks to support the bottom floor as the supporting columns are removed. The floor is lowered and this process is repeated for each floor. This technique is safer and more environmentally friendly, and is useful in areas of high population density.\n\nTo demolish bridges, hoe rams are typically used to remove the concrete road deck and piers, while hydraulic shears are used to remove the bridge's structural steel.\n\nLarge buildings, tall chimneys, smokestacks, bridges, and increasingly some smaller structures may be destroyed by building implosion using explosives. Imploding a structure is very fast—the collapse itself only takes seconds—and an expert can ensure that the structure falls into its own footprint, so as not to damage neighboring structures. This is essential for tall structures in dense urban areas.\n\nAny error can be disastrous, however, and some demolitions have failed, severely damaging neighboring structures. One significant danger is from flying debris, which, when improperly prepared for, can kill onlookers.\n\nAnother dangerous scenario is the partial failure of an attempted implosion. When a building fails to collapse completely the structure may be unstable, tilting at a dangerous angle, and filled with un-detonated but still primed explosives, making it difficult for workers to approach safely.\n\nA third danger comes from air overpressure that occurs during the implosion. If the sky is clear, the shock wave, a wave of energy and sound, travels upwards and disperses, but if cloud coverage is low, the shock wave can travel outwards, breaking windows or causing other damage to surrounding buildings.\n\nStephanie Kegley of CST Environmental described shock waves by saying, \"The shock wave is like a water hose. If you put your hand in front of the water as it comes out, it fans to all sides. When cloud coverage is below 1,200 feet, it reacts like the hand in front of the hose. The wave from the shock fans out instead of up toward the sky.\"\n\nControlled implosion, being spectacular, is the method that the general public often thinks of when discussing demolition; however, it can be dangerous and is only used as a last resort when other methods are impractical or too costly. The destruction of large buildings has become increasingly common as the massive housing projects of the 1960s and 1970s are being leveled around the world. At and , the J. L. Hudson Department Store and Addition is the tallest steel framed building and largest single structure ever imploded.\n\nIt takes several weeks or months to prepare a building for implosion. All items of value, such as copper wiring, are stripped from a building. Some materials must be removed, such as glass that can form deadly projectiles, and insulation that can scatter over a wide area. Non-load bearing partitions and drywall are removed. Selected columns on floors where explosives will be set are drilled and high explosives such as nitroglycerin, TNT, RDX, or C4 are placed in the holes. Smaller columns and walls are wrapped in detonating cord. The goal is to use as little explosive as possible so that the structure will fail in a progressive collapse therefore only a few floors are rigged with explosives, so that it is safer (fewer explosives) and costs less. The areas with explosives are covered in thick geotextile fabric and fencing to absorb flying debris. Far more time-consuming than the demolition itself is the clean-up of the site, as the debris is loaded into trucks and hauled away.\n\nA new approach to demolition is the deconstruction of a building with the goal of minimizing the amount of materials going to landfills. This \"green\" approach is applied by removing the materials by type material and segregating them for reuse or recycling. With proper planning this approach has resulted in landfill diversion rates that exceed 90% of an entire building and its contents in some cases. It also vastly reduces the CO emissions of the removing of a building in comparison to demolition.\n\nThe development of plant and equipment has allowed for the easier segregation of demolition waste types on site and the reuse within the construction of the replacement building. On site crushers allow the demolished concrete to be reused as type 1 crushed aggregate either as a piling mat for ground stabilization or as aggregate in the mixing of concrete.\n\nTimber waste can be shredded using specialist timber shredders and composted, or used to form manufactured timber boards, such as MDF or chipboard.\n\nSafety is paramount; a site safety officer is usually assigned to each project to enforce all safety rules and regulations.\n\nThere is a small niche of companies that offer diamond wire sawing and similar services for a more precise demolition option, these companies include CTI, Penhall, and Bluegrass companies\n\n\n"}
{"id": "47298234", "url": "https://en.wikipedia.org/wiki?curid=47298234", "title": "Dog rope", "text": "Dog rope\n\nA dog rope is a short length of rawhide rope that was used by the Dog Soldiers of the Cheyenne warrior societies and warriors considered especially brave of other tribes. Its purpose was to anchor the warrior in place when a last-ditch defence was called for, thus indicating an intention not to retreat even against overwhelming odds.\n\nThe dog rope consisted of eight to twelve feet of rawhide around four inches wide. One end of the rope was tied to a picket pin (a pin that could be hammered into the ground, normally used for fixing the picket rope of a horse) by a string. The rope was usually carried wound over the right shoulder and under the left arm. It was looped through a slit cut in the free end to secure it to the wearer. It could also be hung from the belt by a string.\n\nThe leather of the rope was decorated with feathers and porcupine quills dyed bright colours. The picket pin was made of wood and painted red. Beadwork, although a common Native American form of decoration, was never used on dog ropes.\n\nThe Cheyennes on the Great Plains of the American Old West had a number of warrior societies. Virtually all Cheyenne young men belonged to one or other of these societies. One society would be appointed by the tribal chiefs to act as camp police. This society also organised warfare and hunting expeditions as the need arose.\n\nThe societies took it in turns to fulfil this role. The use of the dog rope amongst the Cheyennes was peculiar to the Dog Warrior Society. The Dog society eventually took on the nature of a separate band of Cheyennes as opposed to a society within the bands. This band became known to the whites as the Dog Soldiers. They were much admired amongst the Cheyenne for their bravery and they played a leading role in the fighting against US forces.\n\nHowever, the use of dog ropes was not limited to the Cheyenne. They were also used by many other plains tribes, including the Arapahos, Mandans, Kiowas and Apaches. The term \"dog rope\" is thus unlikely to derive from the Dog warrior society. According to an informant of Marquis the term \"dog soldier\" is a general term for a camp guard, so called because they complement the barked warnings of the camp dogs. Thus, the use of a dog rope by a dog soldier is to be compared to the leash of a guard dog.\n\nOnly warriors considered the bravest carried a dog rope. If a warrior carried a dog rope then he was obliged to use it if needed. They were typically used as a last resort in defending a camp under attack as a last-ditch stand. A warrior might also declare in advance, in order to demonstrate his bravery, that in the next battle he would use his dog rope regardless of the necessity. When required, the dog rope warriors would insert their picket pins into the ground. Once inserted, the warrior was obliged to restrict his movements to the distance allowed by the length of the dog rope and fight and die on that spot.\n\nThe warrior was not permitted to remove the pin himself, but a comrade might do so if he considered it honourable or desirable. When a dog rope warrior was released in this way, he was ceremoniously driven off the field of battle by the releasing warrior with a quirt. The symbolism is that the dog rope warrior would not leave the fight of his own will. The use of a dog rope in battle was considered tantamount to suicide.\n\nDog ropes were brought to the Cheyennes by the mythical and mystical founder of the Dog Soldiers. When no one showed interest in joining this proposed new society, he caused all the dogs to disappear, then all the buffalo, then himself. Some warriors reported seeing a vision of Dog Soldiers at the man's camp but they were gone when they returned with their friends. The man then produced four miniature dog ropes from his throat and instructed some women to make all future dog ropes to this pattern.\n\nTwo of the four dog ropes were to be given to unmarried men. The remaining two he reswallowed saying that anyone who wanted one would have to pay for it. One of the newly enrolled Dog Soldiers, Crooked Neck, was criticised by his mother, Dying Woman, for being badly painted. He asked for one of the dog ropes to show his worth, and received it after Dying Woman paid five dogs (including a wolf). Crooked Neck was then painted properly (red all over) and the buffalo returned to the plains.\n\nThis myth was used to explain certain traditions regarding dog ropes. Amongst the Cheyennes, there were only four dog ropes at any one time. Two of these, which had longer pins, were a higher grade than the other two. An owner of a dog rope could pass it on to a younger warrior, chosen by the society chiefs, but payment was expected. He who wished to receive a dog rope piled up goods until the owner considered the payment to be sufficient. If the owner was not satisfied with the offer, he could pick up the dog rope and put it down again in another place. The purchaser and his family then increased the pile of goods. This could be repeated several times. Finally, the owner would place the dog rope over the purchaser. Dancing then commenced to celebrate, starting with the seller leading the purchaser by the dog rope.\n\nIn 1835 a Kiowa village travelled north intending to trade with the Crows. They were attacked by Cheyennes from the Hevhaitanio clan led by Yellow Wolf and a band of Suhtais led by Black Shin. This fight occurred at Kiowa Creek, just east of Denver. A Kiowa chief carrying a dog rope attempted to single-handedly hold up the Cheyennes while the Kiowas built defences in nearby woodland. This Kiowa made repeated charges on horseback through the Cheyenne lines. He was finally brought down by arrow fire. Although he never dismounted to use his dog rope, he made such an impression on the Cheyennes that they were still telling the story of his bravery at meetings into the 20th century.\n\nGrinnell records the use of a dog rope witnessed by Tall Bull, the leader of the Cheyenne Dog Soldiers. Little Man had been at the front of the charge, but then the Cheyennes started to retreat. Little Man dismounted and pinned his dog rope. This stopped the Cheyenne retreat but they began to be pushed back. Little Man was saved by a warbonnet Cheyenne who pulled up his pin and drove him back.\n\nAt the Battle of Summit Springs in 1869 the Cheyenne Dog Soldiers led by Tall Bull (who was killed in this engagement) were surprised by an attack from US soldiers. A number of Cheyennes became trapped in a ravine. A dog rope warrior, Wolf with Plenty of Hair, pinned his dog rope at the entrance of the ravine to defend them and was killed there. This was the last recorded use of a dog rope in battle.\n\n"}
{"id": "8052331", "url": "https://en.wikipedia.org/wiki?curid=8052331", "title": "Durable medical equipment", "text": "Durable medical equipment\n\nDurable Medical Equipment (DME) is any equipment that provides therapeutic benefits to a patient in need because of certain medical conditions and/or illnesses.\nDurable Medical Equipment (DME) consists of items which:\n\nDME includes, but is not limited to, wheelchairs (manual and electric), traction equipment, canes, crutches, walkers, kidney machines, ventilators, oxygen, monitors, pressure mattresses, lifts, nebulizers, bili blankets and bili lights.\n\nSimilar criteria are used by Medicare and Medicaid.\n\nInsurance companies will provide coverage for Durable Medical Equipment when it is determined to be medically necessary because the medical criteria and guidelines for its use are met.\n\nDurable medical equipment may be covered when All of the following criteria are met:\nDurable Medical Equipment and Services are not covered when..\n\n"}
{"id": "58253701", "url": "https://en.wikipedia.org/wiki?curid=58253701", "title": "Endless tape cartridge", "text": "Endless tape cartridge\n\nAn endless tape cartridge is a tape cartridge or cassette that contains magnetic audio tape that can be played in an endless loop, without the need to rewind to repeat.\n\nThe endless tape cartridge has a tape transport that allows forward movement only. The magnetic tape can have start and end markers, like a magnetic beacon, an electric conductive splice, a hole that can be optically scanned, or a transparent splice tape. The cartridge was invented by sound engineer Bernard A. Cousino and it dominated the North American market for many years.\n\nOne of the first products that used the endless tape technology was the Audio Vendor from 1952, an invention of Cousino's. It was registered as patent US2804401A. The tape is passed through an inner ring of loose tape reel, where the recording is stored, and looped back through the outer ring of the reel. Initially, this mechanism was to be implemented in a reel-to-reel audio tape recorder. \n\nLater, Cousino developed a plastic case that could be hung up on some existing tape recorders. This cartridge was marketed by John Herbert Orr as Orrtronic Tapette. In this generation, the magnetic coating of the tape was wound on the inside of the reel. Later cartridge types had the magnetic layer aligned to the outside of the cartridge, which required a specially designed recorder to play it. One traction of the tape by capstan was added, which allowed users the convenience of just pushing the cartridge into the recorder without having to thread the tape. These cassettes needed no internal space for the tape head slider because they accessed the tape from outside the cartridge. \n\nBased on these new cassettes, George Eash developed the Fidelipac cartridge in 1954. PlayTape and the 8-track tape and endless compact cassettes for the announcement text of answering machines were made with this technique. The take-up roll got a table and the perforation for traction was removed. There was no rear winding roll inside such a cassette so rewinding was impossible. Previously, a similar technique was used to store Tefifon's vinyl sonic tape in the Tefi cartridge.\n\nAnother invention patented by Cousino was the graphite coating applied to the bottom side of the tape in endless cartridges. The coating allowed endless tape to be pulled out without crinkling it. 8-track cassettes also used the coating which caused the bottom side of the tape to be grey in colour.\n\n\nThe different data and sound cartridges in chronological market launch order: \n\n"}
{"id": "9908318", "url": "https://en.wikipedia.org/wiki?curid=9908318", "title": "Engineering an Empire", "text": "Engineering an Empire\n\nEngineering an Empire is a program on The History Channel that explores the engineering and/or architectural feats that were characteristic of some of the greatest societies on this planet. It is hosted by Peter Weller, famous for his acting role as RoboCop but also a lecturer at Syracuse University, where he completed his Master's in Roman and Renaissance Art. The executive producer is Delores Gavin. The show started as a documentary about the engineering feats of Ancient Rome and later evolved into a series. It originally ran for one full season of weekly episodes.\n\nEngineering an Empire has received critical acclaim. The premiere \"Rome\" won two Emmys after being nominated in four categories.\n\n\n"}
{"id": "24338083", "url": "https://en.wikipedia.org/wiki?curid=24338083", "title": "Gansu Wind Farm", "text": "Gansu Wind Farm\n\nThe Gansu Wind Farm Project or Jiuquan Wind Power Base is a group of large wind farms under construction in western Gansu province in China. The Gansu Wind Farm Project is located in desert areas near the city of Jiuquan in two localities of Guazhou County and also near Yumen City, in the northwest province of Gansu, which has an abundance of wind resources.\nThe complex has a planned capacity of 8 GW.\n\nThe project is one of six national wind power megaprojects approved by the Chinese government. It is expected to grow to 20,000 megawatts by 2020, at an estimated cost of 120 billion Chinese yuan ($17.5 billion). The project is being built by more than 20 developers in two localities in Guazhou County and also near Yumen City.\nThe project is divided into multiple phases. The first 3,800 MW phase consisted of eighteen 200 MW wind farms and two 100 MW wind farms. The second 8,000 MW phase consists of forty 200 MW wind farms. The planned capacity is 5,160 MW by 2010, 12,710 MW by 2015 and 20,000 MW in 2020. \n\nIn 2008, construction began on a 750 kV AC power line to carry electricity from the wind farm, and construction of the wind farms themselves started in August 2009. Power in 2012 was being purchased for 0.54 yuan per kWh, compared with electricity from coal fired powerplants at 0.3 yuan per kWh. Since operations began, some 6.26 billion kWh has been generated as of October 31, 2011 with 5.96 billion kWh of that produced in 2011.\n\nIn November 2010 officials announced the completion of the project's first phase, involving the installation of over 3,500 wind turbines with an installed capacity of approximately 5,160 MW according to Wang Jianxin, director of the Jiuquan Development and Reform Commission. Total installed capacity rose to approximately 6,000 MW in March 2012—roughly equivalent to the United Kingdom's entire wind power capacity at that time—with new wind turbines being erected at the rate of 36 per day.\n\nOn March 1, 2012, a \"wind power coordinated control system\" was implemented to adjust the output of the 18 wind farms of the Gansu Wind Farm Project, which total 10 GW, to meet the needs of the transmission grid, which is limited to 1.5 GW. This permitted the production of 1 GWh more per day than previously, and greatly improves the system's stability.\n\nCurtailment of wind turbine operations is a first order method for dealing with the intermittency of wind, but normally loses available output when the power grid's transmission capacity has been reached. Other methods involve either added local industrial usage or added local storage capacity.\n\nWith local-government favoritism toward coal and inadequate long-distance transmission capacity, Gansu \"now has some of the highest rates of underutilization in the wind sector in China\". National Energy Administration statistics showed 39 percent of wind capacity in 2015 in Jiuquan was wasted.\n\nCurrently, Gansu is far from full capacity and the wind farm is producing less than half of its full potential. The two main reasons why this is happening is that Gansu is located far from the major Chinese cities and that there is a lack of demand for wind energy in China.\n\nThe Gansu wind farm sits along the Gobi desert where there are extremely high winds. However, this location is about a thousand miles from China’s high density port cities that would serve as the biggest consumer of this energy.\nThere is a lack of enough infrastructure and transmission lines that would allow the energy to flow into the cities.\nThere is still also little demand for wind power in China compared to coal. Although China’s central government is actively trying to reduce its emissions and build its clean energy sector, the local governments still push coal on their local industries because it creates more economic output and because the coal is mined locally, which helps local coal companies.\n\n"}
{"id": "14094", "url": "https://en.wikipedia.org/wiki?curid=14094", "title": "Human cloning", "text": "Human cloning\n\nHuman cloning is the creation of a genetically identical copy (or clone) of a human. The term is generally used to refer to artificial human cloning, which is the reproduction of human cells and tissue. It does not refer to the natural conception and delivery of identical twins. The possibility of human cloning has raised controversies. These ethical concerns have prompted several nations to pass laws regarding human cloning and its legality.\n\nTwo commonly discussed types of theoretical human cloning are: \"therapeutic cloning\" and \"reproductive cloning\". Therapeutic cloning would involve cloning cells from a human for use in medicine and transplants, and is an active area of research, but is not in medical practice anywhere in the world, . Two common methods of therapeutic cloning that are being researched are somatic-cell nuclear transfer and, more recently, pluripotent stem cell induction. Reproductive cloning would involve making an entire cloned human, instead of just specific cells or tissues.\n\nAlthough the possibility of cloning humans had been the subject of speculation for much of the 20th century, scientists and policy makers began to take the prospect seriously in the mid-1960s.\n\nNobel Prize-winning geneticist Joshua Lederberg advocated cloning and genetic engineering in an article in The American Naturalist in 1966 and again, the following year, in The Washington Post. He sparked a debate with conservative bioethicist Leon Kass, who wrote at the time that \"the programmed reproduction of man will, in fact, dehumanize him.\" Another Nobel Laureate, James D. Watson, publicized the potential and the perils of cloning in his Atlantic Monthly essay, \"Moving Toward the Clonal Man\", in 1971.\n\nWith the cloning of a sheep known as Dolly in 1996 by somatic cell nuclear transfer (SCNT), the idea of human cloning became a hot debate topic. Many nations outlawed it, while a few scientists promised to make a clone within the next few years. The first hybrid human clone was created in November 1998, by Advanced Cell Technology. It was created using SCNT - a nucleus was taken from a man's leg cell and inserted into a cow's egg from which the nucleus had been removed, and the hybrid cell was cultured, and developed into an embryo. The embryo was destroyed after 12 days.\n\nIn 2004 and 2005, Hwang Woo-suk, a professor at Seoul National University, published two separate articles in the journal \"Science\" claiming to have successfully harvested pluripotent, embryonic stem cells from a cloned human blastocyst using somatic-cell nuclear transfer techniques. Hwang claimed to have created eleven different patent-specific stem cell lines. This would have been the first major breakthrough in human cloning. However, in 2006 \"Science\" retracted both of his articles on clear evidence that much of his data from the experiments was fabricated.\n\nIn January 2008, Dr. Andrew French and Samuel Wood of the biotechnology company Stemagen announced that they successfully created the first five mature human embryos using SCNT. In this case, each embryo was created by taking a nucleus from a skin cell (donated by Wood and a colleague) and inserting it into a human egg from which the nucleus had been removed. The embryos were developed only to the blastocyst stage, at which point they were studied in processes that destroyed them. Members of the lab said that their next set of experiments would aim to generate embryonic stem cell lines; these are the \"holy grail\" that would be useful for therapeutic or reproductive cloning.\n\nIn 2011, scientists at the New York Stem Cell Foundation announced that they had succeeded in generating embryonic stem cell lines, but their process involved leaving the oocyte's nucleus in place, resulting in triploid cells, which would not be useful for cloning.\n\nIn 2013, a group of scientists led by Shoukhrat Mitalipov published the first report of embryonic stem cells created using SCNT. In this experiment, the researchers developed a protocol for using SCNT in human cells, which differs slightly from the one used in other organisms. Four embryonic stem cell lines from human fetal somatic cells were derived from those blastocysts. All four lines were derived using oocytes from the same donor, ensuring that all mitochondrial DNA inherited was identical. A year later, a team led by Robert Lanza at Advanced Cell Technology reported that they had replicated Mitalipov's results and further demonstrated the effectiveness by cloning adult cells using SCNT.\n\nIn 2018, the first successful cloning of primates using somatic cell nuclear transfer, the same method as \"Dolly\" the sheep, with the birth of two live female clones (crab-eating macaques named \"Zhong Zhong\" and \"Hua Hua\") was reported.\n\nIn somatic cell nuclear transfer (\"SCNT\"), the nucleus of a somatic cell is taken from a donor and transplanted into a host egg cell, which had its own genetic material removed previously, making it an enucleated egg. After the donor somatic cell genetic material is transferred into the host oocyte with a micropipette, the somatic cell genetic material is fused with the egg using an electric current. Once the two cells have fused, the new cell can be permitted to grow in a surrogate or artificially. This is the process that was used to successfully clone Dolly the sheep (see section on History in this article).\n\nCreating induced pluripotent stem cells (\"iPSCs\") is a long and inefficient process. Pluripotency refers to a stem cell that has the potential to differentiate into any of the three germ layers: endoderm (interior stomach lining, gastrointestinal tract, the lungs), mesoderm (muscle, bone, blood, urogenital), or ectoderm (epidermal tissues and nervous tissue). A specific set of genes, often called \"reprogramming factors\", are introduced into a specific adult cell type. These factors send signals in the mature cell that cause the cell to become a pluripotent stem cell. This process is highly studied and new techniques are being discovered frequently on how to better this induction process.\n\nDepending on the method used, reprogramming of adult cells into iPSCs for implantation could have severe limitations in humans. If a virus is used as a reprogramming factor for the cell, cancer-causing genes called oncogenes may be activated. These cells would appear as rapidly dividing cancer cells that do not respond to the body's natural cell signaling process. However, in 2008 scientists discovered a technique that could remove the presence of these oncogenes after pluripotency induction, thereby increasing the potential use of iPSC in humans.\n\nBoth the processes of SCNT and iPSCs have benefits and deficiencies. Historically, reprogramming methods were better studied than SCNT derived embryonic stem cells (ESCs). However, more recent studies have put more emphasis on developing new procedures for SCNT-ESCs. The major advantage of SCNT over iPSCs at this time is the speed with which cells can be produced. iPSCs derivation takes several months while SCNT would take a much shorter time, which could be important for medical applications. New studies are working to improve the process of iPSC in terms of both speed and efficiency with the discovery of new reprogramming factors in oocytes. Another advantage SCNT could have over iPSCs is its potential to treat mitochondrial disease, as it utilizes a donor oocyte. No other advantages are known at this time in using stem cells derived from one method over stem cells derived from the other.\n\nWork on cloning techniques has advanced our basic understanding of developmental biology in humans. Observing human pluripotent stem cells grown in culture provides great insight into human embryo development, which otherwise cannot be seen. Scientists are now able to better define steps of early human development. Studying signal transduction along with genetic manipulation within the early human embryo has the potential to provide answers to many developmental diseases and defects. Many human-specific signaling pathways have been discovered by studying human embryonic stem cells. Studying developmental pathways in humans has given developmental biologists more evidence toward the hypothesis that developmental pathways are conserved throughout species.\n\niPSCs and cells created by SCNT are useful for research into the causes of disease, and as model systems used in drug discovery.\n\nCells produced with SCNT, or iPSCs could eventually be used in stem cell therapy, or to create organs to be used in transplantation, known as regenerative medicine. Stem cell therapy is the use of stem cells to treat or prevent a disease or condition. Bone marrow transplantation is a widely used form of stem cell therapy. No other forms of stem cell therapy are in clinical use at this time. Research is underway to potentially use stem cell therapy to treat heart disease, diabetes, and spinal cord injuries. Regenerative medicine is not in clinical practice, but is heavily researched for its potential uses. This type of medicine would allow for autologous transplantation, thus removing the risk of organ transplant rejection by the recipient. For instance, a person with liver disease could potentially have a new liver grown using their same genetic material and transplanted to remove the damaged liver. In current research, human pluripotent stem cells have been promised as a reliable source for generating human neurons, showing the potential for regenerative medicine in brain and neural injuries.\n\nIn bioethics, the ethics of cloning refers to a variety of ethical positions regarding the practice and possibilities of cloning, especially human cloning. While many of these views are religious in origin, the questions raised by cloning are faced by secular perspectives as well. Human therapeutic and reproductive cloning are not commercially used; animals are currently cloned in laboratories and in livestock production.\n\nAdvocates support development of therapeutic cloning in order to generate tissues and whole organs to treat patients who otherwise cannot obtain transplants, to avoid the need for immunosuppressive drugs, and to stave off the effects of aging. Advocates for reproductive cloning believe that parents who cannot otherwise procreate should have access to the technology.\n\nOpposition to therapeutic cloning mainly centers around the status of embryonic stem cells, which has connections with the abortion debate.\n\nSome opponents of reproductive cloning have concerns that technology is not yet developed enough to be safe - for example, the position of the American Association for the Advancement of Science , while others emphasize that reproductive cloning could be prone to abuse (leading to the generation of humans whose organs and tissues would be harvested), and have concerns about how cloned individuals could integrate with families and with society at large.\n\nReligious groups are divided, with some opposing the technology as usurping god's (in monotheistic traditions) place and, to the extent embryos are used, destroying a human life; others support therapeutic cloning's potential life-saving benefits.\n\nIn 2015 it was reported that about 70 countries had banned human cloning.\n\nHuman cloning is banned by the Presidential Decree 200/97 of 7 March 1997.\n\nAustralia has prohibited human cloning, though , a bill legalizing therapeutic cloning and the creation of human embryos for stem cell research passed the House of Representatives. Within certain regulatory limits, and subject to the effect of state legislation, therapeutic cloning is now legal in some parts of Australia.\n\nCanadian law prohibits the following: cloning humans, cloning stem cells, growing human embryos for research purposes, and buying or selling of embryos, sperm, eggs or other human reproductive material. It also bans making changes to human DNA that would pass from one generation to the next, including use of animal DNA in humans. Surrogate mothers are legally allowed, as is donation of sperm or eggs for reproductive purposes. Human embryos and stem cells are also permitted to be donated for research.\n\nThere have been consistent calls in Canada to ban human reproductive cloning since the 1993 Report of the Royal Commission on New Reproductive Technologies. Polls have indicated that an overwhelming majority of Canadians oppose human reproductive cloning, though the regulation of human cloning continues to be a significant national and international policy issue. The notion of \"human dignity\" is commonly used to justify cloning laws. The basis for this justification is that reproductive human cloning necessarily infringes notions of human dignity.\n\nHuman cloning is prohibited in Article 133 of the Colombian Penal Code.\n\nThe European Convention on Human Rights and Biomedicine prohibits human cloning in one of its additional protocols, but this protocol has been ratified only by Greece, Spain and Portugal. The Charter of Fundamental Rights of the European Union explicitly prohibits reproductive human cloning. The charter is legally binding for the institutions of the European Union under the Treaty of Lisbon and for member states of the Union implementing EU law.\n\nIndia does not have specific law regarding cloning but has guidelines prohibiting whole human cloning or reproductive cloning. India allows therapeutic cloning and the use of embryonic stem cells for research proposes.\n\nThe Federal Assembly of Russia introduced the Federal Law N 54-FZ \"On the temporary ban on human cloning\" in April 19, 2002. On May 20, 2002 President Vladimir Putin signed this moratorium on the implementation of human cloning. On March 29, 2010 The Federal Assembly introduced second revision of this law without time limit.\n\nHuman cloning is explicitly prohibited in Article 24, \"Right to Life\" of the 2006 Constitution of Serbia.\n\nIn terms of section 39A of the Human Tissue Act 65 of 1983, genetic manipulation of gametes or zygotes outside the human body is absolutely prohibited. A zygote is the cell resulting from the fusion of two gametes; thus the fertilised ovum. Section 39A thus prohibits human cloning.\n\nOn January 14, 2001 the British government passed The Human Fertilisation and Embryology (Research Purposes) Regulations 2001 to amend the Human Fertilisation and Embryology Act 1990 by extending allowable reasons for embryo research to permit research around stem cells and cell nuclear replacement, thus allowing therapeutic cloning. However, on November 15, 2001, a pro-life group won a High Court legal challenge, which struck down the regulation and effectively left all forms of cloning unregulated in the UK. Their hope was that Parliament would fill this gap by passing prohibitive legislation. Parliament was quick to pass the Human Reproductive Cloning Act 2001 which explicitly prohibited reproductive cloning. The remaining gap with regard to therapeutic cloning was closed when the appeals courts reversed the previous decision of the High Court.\n\nThe first license was granted on August 11, 2004 to researchers at the University of Newcastle to allow them to investigate treatments for diabetes, Parkinson's disease and Alzheimer's disease. The Human Fertilisation and Embryology Act 2008, a major review of fertility legislation, repealed the 2001 Cloning Act by making amendments of similar effect to the 1990 Act. The 2008 Act also allows experiments on hybrid human-animal embryos.\n\nOn December 13, 2001, the United Nations General Assembly began elaborating an international convention against the reproductive cloning of humans. A broad coalition of States, including Spain, Italy, the Philippines, the United States, Costa Rica and the Holy See sought to extend the debate to ban all forms of human cloning, noting that, in their view, therapeutic human cloning violates human dignity. Costa Rica proposed the adoption of an international convention to ban all forms of human cloning. Unable to reach a consensus on a binding convention, in March 2005 a non-binding United Nations Declaration on Human Cloning, calling for the ban of all forms of human cloning contrary to human dignity, was adopted.\n\nThe Patients First Act of 2017 (HR 2918, 115th Congress) aims to promote stem cell research, using cells that are “ethically obtained”, that could contribute to a better understanding of diseases and therapies, and promote the “derivation of pluripotent stem cell lines without the creation of human embryos…”.\n\nIn 1998, 2001, 2004, 2005, 2007 and 2009, the US Congress voted whether to ban all human cloning, both reproductive and therapeutic (see Stem Cell Research Enhancement Act). Each time, divisions in the Senate, or an eventual veto from the sitting President (President George W. Bush in 2005 and 2007), over therapeutic cloning prevented either competing proposal (a ban on both forms or on reproductive cloning only) from being passed into law. On March 10, 2010 a bill (HR 4808) was introduced with a section banning federal funding for human cloning. Such a law, if passed, would not have prevented research from occurring in private institutions (such as universities) that have both private and federal funding. However, the 2010 law was not passed.\n\nThere are currently no federal laws in the United States which ban cloning completely. Fifteen American states (Arkansas, California, Connecticut, Iowa, Indiana, Massachusetts, Maryland, Michigan, North Dakota, New Jersey, Rhode Island, South Dakota, Florida, Georgia, and Virginia) ban reproductive cloning and three states (Arizona, Maryland, and Missouri) prohibit use of public funds for such activities.\n\nScience fiction has used cloning, most commonly and specifically human cloning, due to the fact that it brings up controversial questions of identity. Humorous fiction, such as \"Multiplicity\" (1996) and the Maxwell Smart feature \"The Nude Bomb\" (1980), have featured human cloning. A recurring sub-theme of cloning fiction is the use of clones as a supply of organs for transplantation. Robin Cook's 1997 novel \"Chromosome 6\" and Michael Bay's \"The Island\" are examples of this; \"Chromosome 6\" also features genetic manipulation and xenotransplantation. There is also a series named Orphan Black which follows human clones' stories and experiences as they deal with issues and react to being the property of a chain of scientific institutions.\n\n\n"}
{"id": "27008909", "url": "https://en.wikipedia.org/wiki?curid=27008909", "title": "IkeGPS", "text": "IkeGPS\n\nikeGPS Limited is a technology company that designs and manufactures measurement solutions - smart laser-based field tools, mobile software apps and industry specific cloud software solutions for measuring, modeling and managing assets. \n\nikeGPS was founded in the mid-2000s by a group of engineers seeking to design and commercialize a solution to enable the capture of verifiable geodata of offset assets and targets for use in Geographical Information Systems. ikeGPS is headquartered in Wellington, New Zealand, with offices in Broomfield, Colorado and Seattle, Washington.\n\nIkeGPS allows a user to quickly record the geodata of multiple targets together with their photographs. ikeGPS lets the user do this from a distance, which is helpful if the user is dealing with any hard to reach or dangerous target. In 2009, GPS World reviewed ikeGPS as the best GPS device in the world for its purpose because of its unique capability.\n\nThe Spike product uses a phone camera, a laser-based system and mobile app software to capture height, width, and distance of any object with advertised 3% accuracy. Thus, in a measurement of 100 feet, the error will be approximately 3 feet - substantially greater than using steel tape, but acceptable for rough measurements where time and accessibility are more important than accuracy. \n\nikeGPS is used around the world by utilities for pole audits and asset management, by intelligence and defense groups and by other organisations for emergency management and enterprise asset management. A major user of the ikeGPS is the United States Army Corps of Engineers who have deployed the ikeGPS across a range of applications, for example after the 2005 levee failures in Greater New Orleans – so that engineers could send back information about the scale of problems to be dealt with at different sites, and in Afghanistan and Iraq – for rapid mapping of infrastructure. Organisations are also using ikeGPS for humanitarian demining. Surveylab's partners include Science Applications International Corporation. \n\nESRI recently announced the use of the Spike device with ESRI's Collector for ArcGIS to improve annual signage inventory and mapping in Carbon County, Utah, USA, reducing inventory costs to one-tenth their original cost, and resulting in a 568% return on investment. \n\n\n"}
{"id": "50780483", "url": "https://en.wikipedia.org/wiki?curid=50780483", "title": "Interleaving (data)", "text": "Interleaving (data)\n\nIn computing, interleaving of data refers to the interspersing of fields or channels of different meaning sequentially in memory, in processor registers, or in file formats. For example, for coordinate data, codice_1 is interleaved whilst codice_2 is not.\n\nA processor may support permute instructions, or strided load and store instructions, for moving between interleaved and non-interleaved representations.\n\nInterleaving has performance implications for cache coherency, ease of leveraging SIMD hardware, and leveraging a computer's addressing modes. (e.g. - interleaved data may require one address to be calculated, from which individual fields may then be accessed via immediate offsets; conversely if only one field is required by index, de-interleaved data may leverage scaled index addressing).\n\n"}
{"id": "25606899", "url": "https://en.wikipedia.org/wiki?curid=25606899", "title": "International Journal of High Speed Electronics and Systems", "text": "International Journal of High Speed Electronics and Systems\n\nThe International Journal of High Speed Electronics and Systems was established in 1990 and is published quarterly by World Scientific. It aims to \"promote engineering education by advancing interdisciplinary science between electronics and systems and to explore high speed technology in photonics and electronics\".\n\nThe journal is abstracted and indexed in Inspec, Scopus and Compendex.\n"}
{"id": "31120153", "url": "https://en.wikipedia.org/wiki?curid=31120153", "title": "Jaime Teevan", "text": "Jaime Teevan\n\nJaime Teevan is an American computer scientist known for her research in human-computer interaction and information retrieval. She is particularly known for the work she has done on personalized search. According to the Technology Review, Teevan \"is a leader in using data about people's knowledge, preferences, and habits to help them manage information.\"\n\nTeevan received a B.S. in Computer Science from Yale University and a Ph.D. and S.M. from MIT.\n\nShe is currently a researcher at Microsoft Research and an affiliate associate professor at the University of Washington. There she co-authored the first book on collaborative information seeking. She also edited a book on Personal Information Management (PIM), \nedited a special issue of Communications of the ACM on the topic, and organized workshops on PIM and query log analysis. She has published numerous technical papers, including several best papers, and was chair of the Web Search and Data Mining (WSDM) 2012 conference.\n\nTeevan works on 'microproductivity,' breaking down complex tasks into a series of microtasks that can be completed more easily and efficiently. She also developed the concept of selfsourcing, where microtasks are completed by the task owner rather than crowd workers. A 2017 article in the New York Magazine quotes her as saying, \"I could probably pretty easily find an extra hour in my day at work, just in these little micro-moments of time when I’m not being productive.\" \n\nTeevan was named a Technology Review (TR35) 2009 Young Innovator for her research on personalized search and received the CRA-W Borg Early Career Award (BECA) in 2014. In 2016 she received the Karen Spärck Jones award from the British Computer Society for her \"technically strong and exceptionally creative contributions to the intersection of information retrieval, user experience and social media.\" \n\nTeevan is married to Alexander Hehmeyer.\nThe couple live in Bellevue, Washington\nand have four children.\nTeevan is an advocate for helping researchers successfully integrate parenthood and academic efforts.\n\n"}
{"id": "11980309", "url": "https://en.wikipedia.org/wiki?curid=11980309", "title": "JasperReports", "text": "JasperReports\n\nJasperReports is an open source Java reporting tool that can write to a variety of targets, such as: screen, a printer, into PDF, HTML, Microsoft Excel, RTF, ODT, Comma-separated values or XML files.\n\nIt can be used in Java-enabled applications, including Java EE or web applications, to generate dynamic content. It reads its instructions from an XML or .jasper file.\n\n\"JasperReports\" is part of the Lisog open source stack initiative.\n\nJasperReports is an open source reporting library that can be embedded into any Java application. Features include:\n\nFor users with more sophisticated report management requirements, reports designed for JasperReports can be easily imported into the \"JasperServer\" - the interactive report server.\n\nTeodor Danciu began work on JasperReports in June 2001, the sf.net project was registered in September 2001 and JasperReports 0.1.5 was released on November 3, 2001.\n\nJasperReports Version 1.0 was released on July 21, 2005.\n\nThe code was originally licensed under a copyleft \"JasperReports License\" and later moved to LGPL.\n\nJaspersoft was originally called Panscopic, and was founded by Al Campa, CEO, and Raj Bhargava, VP of Products in 2001. Panscopic raised $23M from Doll Capital, Discovery Ventures, Morgenthaler Ventures, and Partech. In 2004 Panscopic teamed up with Teodor Danciu, acquired the intellectual property of JasperReports, and changed the name of the company to Jaspersoft. Brian Gentile became CEO in 2007.\n\nJaspersoft provides commercial software around the JasperReports product, and negotiate contracts with software developers that wish to embed the JasperReports engine into a closed source product.\n\nJaspersoft's main related product is JasperReports Server, a Java EE web application that provides advanced report server capabilities such as report scheduling and permissions. It is available under an open source license for use in conjunction with open source infrastructure such as MySQL and JBoss, or a commercial license for enterprise deployments involving commercial databases and application servers.\n\nJaspersoft is a gold partner with MySQL, and JasperReports was included in the PostgreSQL distribution \"Bizgres\" version 0.7.\n\nOn April 28, 2014, TIBCO announced it had acquired Jaspersoft for approximately $185 million.\n\nJasperReports reports are defined in an XML file format, called JRXML, which can be hand-coded, generated, or designed using a tool. The file format is defined by a Document Type Definition (DTD) or XML schema for newer versions, providing limited interoperability. JRXML files have the filename extension \".jrxml\".\n\nA \".jasper\" file is a compiled version of a \".jrxml\" file. iReport does the compilation on the fly, but the compilation can also get achieved at runtime using the JasperCompileManager class.\n\nSeveral Java IDEs, such as NetBeans, Eclipse and IBM Websphere Studio Application Developer provide instructions for users wishing to integrate JasperReports into a project.\n\n\nJasperReports has been the focus of several academic papers on code refactoring\n"}
{"id": "32107771", "url": "https://en.wikipedia.org/wiki?curid=32107771", "title": "Jim Williams (analog designer)", "text": "Jim Williams (analog designer)\n\nJames M. Williams (April 14, 1948 – June 12, 2011) was an analog circuit designer and technical author who worked for the Massachusetts Institute of Technology (1968–1979), Philbrick, National Semiconductor (1979–1982) and Linear Technology Corporation (LTC) (1982–2011). He wrote over 350 publications relating to analog circuit design, including 5 books, 21 application notes for National Semiconductor, 62 application notes for Linear Technology, and over 125 articles for EDN Magazine.\n\nWilliams suffered a stroke on June 10 and died on June 12, 2011.\n\n\nFor a complete bibliography, see.\n\n\n"}
{"id": "56039031", "url": "https://en.wikipedia.org/wiki?curid=56039031", "title": "Jyoti Prakash Tamang", "text": "Jyoti Prakash Tamang\n\nJyoti Prakash Tamang (born 11 November 1961) is an Indian food technologist, microbiologist and the officiating vice chancellor of the Sikkim Central University. Known for his studies on fermented food, Tamang is an elected fellow of the National Academy of Agricultural Sciences, Indian Academy of Microbiological Sciences and the Biotech Research Society of India. The Department of Biotechnology of the Government of India awarded him the National Bioscience Award for Career Development, one of the highest Indian science awards, for his contributions to biosciences in 2004.\n\nJyoti Prakash Tamang was born on 16 November 1961 in the mountain district of Darjeeling in the Indian state of West Bengal from Nepali parents. He completed his schooling at Turnbull High School, Darjeeling in 1977 and his pre-university course at the St Joseph's College, Darjeeling in 1979. His undergraduate education was at the Darjeeling Government College of North Bengal University from where he passed BSc honors in 1982 and continued at the institution to earn an MSc in microbiology in 1984, passing the examination winning a gold medal for academic excellence. He started his career in 1986 as an associate professor at the department of botany of Sikkim Government College, Tadong where he worked until 2011. Simultaneously, he enrolled at North Bengal University for his doctoral studies and after securing a PhD in microbiology in 1992, he did his post-doctoral work at two institutions abroad during 1994–95; first at the National Food Research Institute, Tsukuba with a fellowship from the United Nations University-Kirin Brewery Company and, later, at the Institute of Hygiene and Toxicology, Karlsruhe, on a fellowship received from Volkswagen Foundation. In 2011, he joined Central Sikkim University (CUS) as a member of faculty and has been serving the institution since then. He has held various positions at the university which included those of an academic coordinator, the dean of the School of Life Sciences, the registrar (the first registrar of the university) and a professor (presently the senior-most professor at CUS). He also serves as the officiating vice chancellor of the university. In between, he had a short stint at the Research Institute of Humanity and Nature of the Ministry of Education, Science and Technology, Kyoto as a visiting professor during 2009–10.\n\nTamang focused his research on the culture, microbiology, nutrition, and functional property of food and is known to be an expert on fermented food in use across the world. He is reported to have identified the probiotic and functional properties of fermented food found in the Himalayan region and has studied its microbial diversity. His studies have been documented by way of a number of articles and ResearchGate, an online repository of scientific articles has listed 36 of them. Besides, he has published four books namely, \"Himalayan Fermented Foods: Microbiology, Nutrition, and Ethnic Values\", \"Ethnic fermented foods and alcoholic beverages of Asia\", \"Fermented foods and beverages of the world\" and \"Health benefits of fermented foods and beverages\".\n\nTamang received the Women's Association Award of the United Nations University in 1996. The Department of Biotechnology of the Government of India awarded him the National Bioscience Award for Career Development, one of the highest Indian science awards in 2004. He was elected as a fellow by the Biotech Research Society of India in 2006 and he received the Gourmand World Cookbook Award in 2010; the same year as he received the elected fellowship of the Indian Academy of Microbiological Sciences. The elected fellowship of the National Academy of Agricultural Sciences reached him in 2016.\n\n\n\n"}
{"id": "23001725", "url": "https://en.wikipedia.org/wiki?curid=23001725", "title": "Lurgi–Ruhrgas process", "text": "Lurgi–Ruhrgas process\n\nThe Lurgi–Ruhrgas process is an above-ground coal liquefaction and shale oil extraction technology. It is classified as a hot recycled solids technology.\n\nThe Lurgi–Ruhrgas process was originally invented in the 1940s and further developed in the 1950s for a low-temperature liquefaction of lignite (brown coal). The technology is named after its developers Lurgi Gesellschaft für Wärmetechnik G.m.b.H. and Ruhrgas AG. Over a time, the process was used for coal processing in Japan, Germany, the United Kingdom, Argentina, and former Yugoslavia. The plant in Japan processed also cracking petroleum oils to olefins.\n\nIn 1947–1949, the Lurgi–Ruhrgas process was used in Germany for shale oil production. In Lukavac, Bosnia and Herzegovina, two retorts for liquefaction of lignite were in operation from 1963 to 1968. The capacity of the plant was 850 tons of lignite per day. The plant in Lincolnshire, the United Kingdom, operated in 1978–1979 with capacity of 900 tons of coal per day. In late 1960s and early 1970s oil shales from different European countries and from the Green River Formation of Colorado, the United States, were tested at the Lurgi's pilot plant in Frankfurt. In the United States, the technology was promoted in cooperation with Dravo Corporation. In the 1970s, the technology was licensed to the Rio Blanco Shale Oil Project for construction of a modular retort in combination with the modified \"in situ\" process. However, this plan was terminated.\n\nIn 1980, the Natural Resources Authority of Jordan commissioned from the Klöckner-Lurgi consortium a pre-feasibility study of construction of an oil shale retorting complex in Jordan using the Lurgi–Ruhrgas process. However, although the study found the technology feasible, it was never implemented.\n\nThe Lurgi–Ruhrgas process is a hot recycled solids technology, which processes fine particles of coal or oil shale sized . As a heat carrier, it uses spent char or spent oil shale (oil shale ash), mixed with sand or other more durable materials. In this process, crushed coal or oil shale is fed into the top of the retort. In retort, coal or oil shale is mixed with the heated char or spent oil shale particles in the mechanical mixer (screw conveyor). The heat is transferred from the heated char or spent oil shale to the coal or raw oil shale causing pyrolysis. As a result, oil shale decomposes to shale oil vapors, oil shale gas and spent oil shale. The oil vapor and product gases pass through a hot cyclone for cleaning before sending to a condenser. In the condenser, shale oil is separated from product gases.\n\nThe spent oil shale, still including residual carbon (char), is burnt at a lift pipe combustor to heat the process. If necessary, additional fuel oil is used for combustion. During the combustion process, heated solid particles in the pipe are moved to the surge bin by pre-heated air that is introduced from the bottom of the pipe. At the surge bin, solids and gases are separated, and solid particles are transferred to the mixer unit to conduct the pyrolysis of the raw oil shale.\n\nOne of the disadvantages of this technology is the fact that produced shale oil vapors are mixed with shale ash causing impurities in shale oil. Ensuring the quality of produced shale oil is complicated as compared with other mineral dusts the shale ash is more difficult to collect.\n\n"}
{"id": "3088777", "url": "https://en.wikipedia.org/wiki?curid=3088777", "title": "Ministry of Climate, Energy and Building (Denmark)", "text": "Ministry of Climate, Energy and Building (Denmark)\n\nThe Danish Ministry of Climate, Energy and Building () is a governmental agency in Denmark. It is responsible for national climate policy and international cooperation on climate change, as well as energy issues, meteorology and national geological surveys in Denmark and Greenland.\n\nThe predecessor of the Ministry of Climate and Energy, the Ministry of Energy (), was created in 1979, from the energy department of the Ministry of Trade. In 1994, it was merged with Ministry of the Environment and in 2005 it was detached from that ministry, to be merged with Ministry of Transport and Energy.\n\nOn 23 November 2007, the energy issues were de-merged from the Ministry of Transport and climate issues were de-merged from the Ministry of Environment and the Ministry of Climate and Energy was created.\n\nThe minister of climate and energy was Connie Hedegaard until November 2009 when she was replaced with Lykke Friis. Martin Lidegaard followed on 3 October 2011 who was replaced by Rasmus Helveg Petersen on 3 February 2014.\n\nThe Danish Energy Agency belongs under this ministry.\n\nThe Danish Electricity Saving Trust (Elsparefonden) is an independent trust under the auspices of the Danish Ministry of Climate and Energy. The Trust works to promote energy savings and a more efficient use of electricity.\n\n\n"}
{"id": "10156160", "url": "https://en.wikipedia.org/wiki?curid=10156160", "title": "Music stand", "text": "Music stand\n\nA music stand is a pedestal or elevated rack designed to hold a paper score or sheets of music in position for reading. Most music stands for orchestral, chamber music or solo orchestra-family instruments (violin, oboe, trumpet, etc.) can be raised or lowered to accommodate seated or standing performers, or performers of different heights. Many types of keyboard instruments have a built-in or removable music rack or stand where sheet music can be placed. Music stands enable musicians to read sheet music or scores while playing an instrument or conducting, as the stand leaves the hands free. Music stands are sometimes used by singers, however for choirs, singers typically hold their sheet music in a folder, and singers performing solo recitals or opera performances typically memorize the lyrics and melodies. Some singers use stands, such as lounge singers and wedding vocalists who have a repertoire of hundreds of songs, which makes remembering all of the verses difficult.\n\nThere are various types of music stands for different purposes and intended users. Folding stands collapse, which makes them convenient to take to rehearsals and performances out of the home. Folding stands are typically used by amateur musicians at rehearsals and performances. Professional musicians are more likely to limit their use of folding stands to rehearsals held outside of normal performance venues (e.g., a chamber music rehearsal at a private home) or small gigs. Non-folding stands tend to be used by professional orchestras and big bands for rehearsals and concerts.\n\nFolding stands range from inexpensive, lightweight models made of metal, which are designed to hold a few pages of sheet music or a thin songbook, to stronger, more expensive heavy-duty models. Metal folding stands often have solid wire extensions or metal \"arms\" which can be folded out to support more than two pages of music or over-size sheets or pages. This is the kind most often used by music students in youth orchestras. Lightweight folding stands are designed to collapsible; if folding stands did not collapse, they would be awkward and unwieldy to carry. The collapsible nature of folding stands makes them small enough to slip into many instrument cases or backpacks. This feature makes folding stands more portable. As such, they are a popular stand type for rehearsals, auditions and even some types of performances. Amateur orchestras and some youth orchestras may ask members to bring folding stands to rehearsals, and sometimes also to performances, as this saves the ensemble the cost of buying or renting, and transporting one or more racks of non-folding stands.\n\nLightweight stands are not designed to support heavy books of music such as full-size fake books; while the fake book may stay open on the stand, the music stand may fall over. Folding stands consist of a rack for the music and a telescoping cylindrical column for supporting the rack, with screws or other fastening devices to secure the extended columns at the desired height. Folding stands typically have a foldable tripod that supports the column and the music shelf. The rack area for holding the music is either pre-set at a slight incline away from the performer (as compared with being straight up), so that a song book or étude book will lie open naturally, or the degree of incline can be adjusted by the performer (on more expensive stands).\n\nThe portability of lightweight music stands can lead to some problems. Heavy fake books or full scores may overload the stand, leading to it falling over when a performer turns a page. As well, when a lightweight stand is used with its column fully extended, as by a standing orchestral timpanist or double bass player, a heavy part may be \"tippy\" on the over-extended column. Oversized parts, which are used in some contemporary classical music, may be too wide to be supported by the stand; a solution that some musicians use is to use multiple stands for oversize parts. As well, during outdoor performances, such as playing at a wedding, picnic or a bandstand, lightweight stands may be blown over by wind, which can interrupt a performance or even, if the stand strikes an instrument, damage the finish of an instrument.\n\nHeavy duty folding models typically use a hollow cylindrical column as the main support and three cylindrical columns arrayed in a tripod to ensure the stand stays upright. Heavy duty stands can reliably support a thick, several hundred page fake book, song book or a binder full of songs. The height of the column can be raised or lowered to permit the stand to be used for a seated performer (common for most orchestral instruments, except for percussion and sometimes double bass) or a standing performer.\n\nProfessional orchestras, concert bands and big bands typically use non-portable, non-folding heavy-duty stands. The stands are typically coloured or painted black so that the stands blend in with the black clothing of the musicians and are not distracting. The music holding portion of the stand may be plastic or metal, and in both cases, the music holding portion is supported by a metal column. The part supporting the music often has a shelf below it for pencils, rosin (for string players), and other rehearsal accessories. The metal column can be raised or lowered to put the stand at the desired height. Professional stands can be lowered to be used for a seated performer or raised for standing performers. Some non-folding stands have perforations in the music rack to reduce the weight of the stand, an especially important consideration when a large number of stands are being moved.\n\nThese stands do not fold or collapse (apart from the ability to lower the height of the stand) and are thus rarely used by musicians travelling alone or one-by-one to rehearsals or gigs. The stands can be moved, but for a full orchestra to move its 50-100 stands, which are often loaded onto a heavy rack, a moving truck and movers need to be hired to relocate the stands. Professional stands either have some type of tripod-style or quadruped-style base, or they have a heavy, metal base, often circular.\n\nSome musicians use non-folding, professional stands for all of their rehearsals and gigs, even though this may require them to take more trips to load their gear into the hall. The reason some musicians choose to use non-folding stands is because they are more stable, even with heavy parts or scores, they are more resistant to falling over during outdoor shows, and they look more professional. As well, some performers like to have access to a shelf underneath their stand, to obtain music accessories that are needed throughout a rehearsal or show (e.g., pencils, rosin for string players, picks for guitar players, reeds for reed players, valve oil for brass players, a tuning key for percussionists, etc.)\n\nMusicians may also have expensive non-folding stands in their homes or music studios made of wood or metal. These stands are not designs that are meant to be relocated. Due to their weight and/or their delicate finishes, they are intended to be used in a single location, such as a private home. Some heavy stands are made of carved wood and feature bas relief carvings and inlay work. Other heavy stands are made of brass, and feature musical motifs such as treble clefs. Some of these heavy stands are objects of art in their own right.\n\nDigital music stands that use a computer screen to display the music began being used in the 1990s and 2000s. The digital \"pages\" can be turned by pressing an electronic footpedal, thus enabling performers to play chamber music or solo pieces with difficult page turns without hiring or finding a volunteer to act as a page turner. The music notation is typically displayed on a flatscreen display or a tablet computer screen.\n\nMarching band or some brass band members use a small sheet holder called a lyre or a clip which, can be attached to an instrument. The clip holds a smaller-sized part for the performer, so she/he can read the music while marching.\n\nLarge, heavy duty music stands are available for conductors of orchestras, concert bands, choirs and big bands to hold their heavy, over-size scores of music. These stands are typically not designed to be easily transportable, and they are usually intended for installation in a rehearsal hall or concert hall. Conductor's stands have to be able to be angled much flatter than an instrumentalist's stand, because the conductor reads from a large full-score, which contains the parts for all of the instruments. For some symphonies, the score can be both thick and heavy; to ensure that the stand is stable, a conducting stand needs to have a heavy, wide base and a sturdy platform for the score. As with professional instrumentalist stands, some conducting stands have a narrow shelf where a conductor can store her batons, handkerchiefs, reading glasses, and, for rehearsals, a small metronome.\n\nUpright pianos, grand pianos, stage pianos, harpsichords, pipe organs, Hammond organs and many post-1980s electronic keyboards have some type of rack or stand to hold sheet music and/or scores. On some grand pianos, the music stand can be removed, for example, if the performer is playing a piano solo work or a piano concerto from memory. On some electronic or electric keyboards, the stand can be removed, to facilitate transportation of the instrument to rehearsals and gigs. If the music stands on electronic and electric keyboards were permanently affixed, they would make the instrument harder to load into a van or car, and the stand would be vulnerable to damage. \n\nOn some digital pianos designed for use in a private home or studio, the music rack is permanently installed, but most users of digital pianos do not transport them to rehearsals and gigs, because these instruments often have a number of design features that are not conducive to regular transport (e.g., fixed keyboard legs and a modesty panel and fixed pedals for sustain and sostenuto). Most keyboardists who are regularly transporting electronic keyboards to rehearsals and gigs use stage pianos or MIDI controller keyboards along with a sound module; on these instruments, all of the accessories (music rack, keyboard stand, sustain pedal) can be disconnected. By enabling the keyboard to be broken down into separate components, it makes the instrument more transportable in a regular car, even including small vehicles. In contrast, a high-end digital piano with a fixed music rack, stand and pedals would need a van and several helpers to transport it.\n\nWhile the vast majority of music stands are designed to provide their own support for raising the music rack to the desired height, there are some music racks which are designed for placing on a table or counter. Since a table or counter must be used, this makes these racks unsuitable for instruments such as timpani.\n\nWith outdoor performances, users of music stands can face challenges due to wind blowing the pages of sheet music off the stand or blowing the pages to an incorrect page. To resolve this challenge, performers use metal clips or clothes pins on the sides of the music or lay a sheet of plexiglass over the stand. While these methods prevent the music or pages from being blown by the wind, they make page turns more difficult. As well, users of lightweight folding stand may face challenges on windy days, as the opened pages of a music part may act like a sail and catch the wind, which can lead to the entire stand blowing over. Heavy-duty folded stands, and professional stands are less likely to blow over in outdoor concerts, due to their greater weight. In outdoor concerts where windy conditions are a problem, the most wind-resistant stand is a professional, non-folding stand with a heavy, weighted base.\n\nIn opera, ballet and musical theatre, the orchestra (or band in the case of musicals) often plays in an orchestra pit in front of and at a lower level than the main performance stage. For dramatic reasons, the stage may be darkened at times during the performance, and the house lights turned off. This darkness could pose challenges for the musicians who are reading parts or chord charts in the pit. To resolve this challenge, small stand lights are clipped onto the tops of stands. To avoid having the stand lights distract audience members, some venues have cloth \"hoods\" over the lights. Originally, stand lights were incandescent, requiring extension cords running throughout the pit and regular bulb changes. In the 2000s, as LED lights became more affordable, battery powered LED lights have become widely used. LED lights do not need extension cords and the bulbs almost never need replacement. Stand lights do not clip as securely to thin folding stands. Stand lights clip more securely onto the solid rack of a professional, non-folding stand. A Canadian viola player invented a stand with a built-in LED light, for dark performing settings.\n\nThe term \"stand\", as it is used to describe furniture such as a plant stand or music stand, generally implies a relatively small surface area supported at the required height, most usually by a turned leg or support known as a \"standard\". Any inclined surface that can be used for supporting music may be thought of a music stand, although generally this function is divided between two types of furniture: a music stand proper and a music desk. The music stand, as the name suggests, consists of a support for the music raised upon a freestanding column or tripod, which, in addition to being movable may also be adjustable with regard to its height and the angle at which it may be tilted. A music desk generally implies a similar, tiltable support for the music, but rather than being raised on a stand, instead forms part of a table. In as much as the term \"desk\" originally implied a sloping-topped table for reading or writing, the slight adjustment necessary to turn a desk into a music desk was a relatively simple matter.\n"}
{"id": "309954", "url": "https://en.wikipedia.org/wiki?curid=309954", "title": "Network Computer", "text": "Network Computer\n\nThe Network Computer (or NC) was a diskless desktop computer device made by Oracle Corporation from about 1996 to 2000. The devices were designed and manufactured by an alliance, which included Sun Microsystems, IBM, and others. The devices were designed with minimum specifications, based on the Network Computer Reference Profile. The brand was also employed as a marketing term to try to popularize this design of computer within enterprise and among consumers.\n\nThe NC brand was mainly intended to inspire a range of desktop computers from various suppliers that, by virtue of their diskless design and use of inexpensive components and software, were cheaper and easier to manage than standard fat client desktops. However, due to the commoditization of standard desktop components, and due to the increasing availability and popularity of various software options for using full desktops as diskless nodes, thin clients, and hybrid clients, the Network Computer brand never achieved the popularity hoped for by Oracle and was eventually mothballed.\n\nThe term \"network computer\" is now used for any diskless desktop computer or a thin client.\n\nThe failure of the NC to impact on the scale predicted by Larry Ellison may have been caused by a number of factors. Firstly, prices of PCs quickly fell below $1000, making the competition very hard. Secondly, the software available for NCs was neither mature nor open.\n\nThirdly, the idea could simply have been ahead of its time, as at the NC's launch in 1996, the typical home Internet connection was only a 28.8 kbit/s modem dialup. This was simply insufficient for the delivery of executable content. The world wide web itself was not considered mainstream until its breakout year, 1998. Prior to this, very few Internet service providers advertised in mainstream press (at least outside of the USA), and knowledge of the Internet was limited. This could have held back uptake of what would be seen as a very niche device with no (then) obvious appeal.\n\nNCs ended up being used as the very 'dumb terminals' they were intended to replace, as the proprietary backend infrastructure is not readily available. 1990s era NCs are often network-booted into a minimal Unix with X, to serve as X terminal. While NC purists may consider this to be a suboptimal use of NC hardware, the NCs work well as terminals, and are considerably cheaper than purpose-built terminal hardware.\n\nThe initial Network Computing standard, the Network Computer Reference Profile (NCRef), required that all 'NC' appliances supported HTML, Java, HTTP, JPEG, and other key standards.\n\nBecause many NCs did not use Intel CPUs or Microsoft software, Microsoft and Intel developed a competing standard called NetPC. Other alternatives to the NCRef were WeBRef (Motorola and HDS Network Systems) and Odin (National Semiconductor). The HDS @workStation was stated to ship by the end of June 1996.\n\nThe Acorn Network Computer was Oracle's initial reference implementation of the NC. Its development was subcontracted to British company Acorn Computers, who adapted its own to create NCOS. Acorn made use of local partner companies ANT, Icon Technology and Design Edge to fulfil their contract.\n\nIn 1997 Apple announced the Mac NC, its attempt to develop the Pippin into a network computer platform. By the end of 1997, Steve Jobs discontinued all Macintosh clone efforts, effectively killing the Pippin, although key components of the Mac NC technology were inherited by the original iMac.\n\nThe first generation NetStation design and the NetStation trademark was licensed to NChannel, which provided the consumer equipment and Internet service (with associated infrastructure) for the UK market. After a few months, NChannel split into two entities: NetChannel (which provided the Internet service) and NetProducts which provided the consumer hardware.\n\nNetProducts started working with Acorn to develop a next-generation product, NetStation II and started developing an email-only set-top-box (the TVemail). NetProducts went into voluntary liquidation in 1998 before either project was completed.\n\nSun Microsystems developed the JavaStation, a JavaOS-based NC based on SPARC hardware, initially similar to Sun's range of Unix workstations.\n\nIBM launched its Network Station in September 1996. As with the later reference design, the Network Station used a NetBSD-based NCOS booted over a LAN from an AS/400 or IBM PC server. The Network Station supported local execution of basic applications, such as a web browser and console. In addition, X capability was also implemented to allow both locally and remotely run applications to be used on the same machine. In practice, the lack of real applications meant that this was little more than a hardware X terminal.\n\nThe IBM Network Station was originally based on the PowerPC architecture, but the final few models used Intel Pentium processors.\n\nSome see the idea behind the NC as existing in contemporary times in the system of cloud computing and in particular Google Chrome OS. In Wired magazine, Daniel Roth claims that the failure of the network computer eventually led to the development of cloud computing. A large contribution to this transition was attributed to Eric Schmidt, once the CTO of Sun Microsystems, a proponent of the network computer, who eventually became the CEO of Google. Google is a large purveyor of cloud technology, \"most notably Google Docs and Spreadsheets.\"\n\n\n"}
{"id": "19308581", "url": "https://en.wikipedia.org/wiki?curid=19308581", "title": "Notice Advisory to Navstar Users", "text": "Notice Advisory to Navstar Users\n\nA Notice Advisory to Navstar Users (NANU) is a message issued jointly by the United States Coast Guard and the GPS Operations Center at Schriever Air Force Base in Colorado. Such notices (NANUs) provide updates on the general health of individual satellites in the GPS constellation. NANUs are typically issued approximately three days prior to a change in the operation of a GPS satellite, such as a change in orbit or scheduled on-board equipment maintenance.\n\nForecast Outages\n\n\nUnscheduled Outages\n\n\nOther\n\n\n"}
{"id": "1575015", "url": "https://en.wikipedia.org/wiki?curid=1575015", "title": "O. Winston Link", "text": "O. Winston Link\n\nOgle Winston Link (December 16, 1914 – January 30, 2001), known commonly as O. Winston Link, was an American photographer. He is best known for his black-and-white photography and sound recordings of the last days of steam locomotive railroading on the Norfolk & Western in the United States in the late 1950s. A commercial photographer, Link helped establish rail photography as a hobby. He also pioneered night photography, producing several well known examples including \"Hotshot Eastbound\", a photograph of a steam train passing a drive-in movie theater, and \"Hawksbill Creek Swimming Hole\" showing a train crossing a bridge above children bathing.\n\nLink and his siblings, Eleanor and Albert Jr., spent their childhood in the borough of Brooklyn, New York City, where they lived with their parents, Albert Link, Sr. and Anne Winston Jones Link. Link's given names honor ancestors Alexander Ogle and John Winston Jones, who had served in the U.S. House of Representatives in the 19th century. Al Link taught woodworking in the New York City Public School system, and encouraged his children's interest in arts and crafts and first introduced Winston to photography.\n\nLink's early photography was created with a borrowed medium format Autographic Kodak camera. By the time he was in high school he had built his own photographic enlarger. After completing high school, Link attended the Polytechnic Institute of Brooklyn, receiving a degree in civil engineering. Before his graduation in 1937, he spoke at a banquet for the institute's newspaper, where he served as photo editor. An executive from Carl Byoir's public relations firm was present and was impressed by Link's speaking ability. He offered Link a job as a photographer.\n\nLink worked for Carl Byoir and Associates for five years, learning his trade on the job. He adapted to the technique of making posed photographs looking candid, as well as creatively emphasizing a point. On his first major assignment, to photograph part of the state of Louisiana in the summer of 1937, he found himself in New Iberia, the location where Cecil B. DeMille's 1938 movie \"The Buccaneer\", about Jean LaFitte was being filmed. Here he met his future first wife, a former Miss Ark-La-Tex, now actress/model/body double, Vanda Marteal Oglesby, who stood-in for lead actress Franciska Gaal. They 'took a shine' to one another and later that year she posed for some of his photographs in the French Quarter of New Orleans. They eventually married in 1942, but later divorced. Some of Link's photographs from this time included an image of a man aiming a gun at a pig wearing a bulletproof vest, and one eventually known as \"What Is This Girl Selling?\" or \"Girl on Ice,\" which was widely published in the United States and later featured in \"Life\" as a \"classic publicity picture.\" According to Thomas Garver, a later assistant to Link, during his employment at Byoir's firm, Link \"clearly defined a point of view and developed working methods that were to shape his entire career.\"\n\nWhen World War II reached the United States, Link found himself unable to join the military as a result of mumps-induced hearing loss. He left Byoir's employ in 1942 to work for the Airborne Instruments Laboratory, part of Columbia University. Drawing on both his university degree and professional photographic experience, Link worked at the laboratory as both project engineer and photographer. The laboratory was then researching a device to enable low-flying airplanes to detect submarines underwater. Link's main responsibility was photographing the project for the United States government.\n\nIn 1945, with the end of the war, Link's employment at the Airborne Instruments Laboratory also ended. Byoir invited Link back, but Link instead opened his own studio in New York City in 1946; his clients included Goodrich, Alcoa, Texaco, and Ethyl.\n\nWhile in Staunton, Virginia, for an industrial photography job in 1955, Link's longstanding love of railroads became focused on the nearby Norfolk and Western Railway line. N&W was the last major (Class I) railroad to make the transition from steam to diesel motive power and had refined its use of steam locomotives, earning a reputation for \"precision transportation.\" Link took his first night photograph of the road on January 21, 1955, in Waynesboro, Virginia. On May 29, 1955 the N&W announced its first conversion to diesel and Link's work became a documentation of the end of the steam era. He returned to Virginia for about twenty visits to continue photographing the N&W. His last night shot was taken in 1959 and the last of all in 1960, the year the road completed the transition to diesel, by which time he had accumulated 2400 negatives on the project.\n\nAlthough it was entirely self-financed, Link's work was encouraged and facilitated by N&W officials, from President Robert Hall Smith downwards. Besides the locomotives, he captured the people of the N&W performing their jobs on the railroad and in the trackside communities. Some of his images were of the massive Roanoke Shops, where the company had long built and maintained its own locomotives.\n\nLink's images were always meticulously set up and posed, and he chose to take most of his railroad photographs at night. He said \"I can't move the sun — and it's always in the wrong place — and I can't even move the tracks, so I had to create my own environment through lighting.\" Although others, including Philip Hastings and Jim Shaughnessy, had photographed locomotives at night before, Link's vision required him to develop new techniques for flash photography of such large subjects. For instance, the movie theater image \"Hotshot Eastbound (Iaeger, West Virginia)\", photographed on August 2, 1956 [negative NW1103], used 42 #2 flashbulbs and one #0 fired simultaneously. Link, with an assistant such as George Thom, had to lug all his equipment into position and wire it up: this was done in series so any failure would prevent a picture being taken at all; and in taking night shots of moving trains the right position for the subject could only be guessed at. Link used a 4 x 5 Graphic View view camera with black and white film, from which he produced silver gelatin prints.\n\n\"Hawksbill Creek Swimming Hole (Luray, Virginia)\" was photographed on August 9, 1956 [NW1126]. Other widely known images include \"Swimming Pool (Welch, West Virginia)\" (1958 [NW1963]), \"Ghost Town (Stanley, Virginia)\" [NW1345], \"Main Line on Main Street (Northfork, West Virginia)\" (1958 [NW1966]) and \"Mr and Mrs Ben Pope watch the last steam powered passenger train (Max Meadows, Virginia)\" (1957 [NW1648]).\n\nIn addition to his black and white night shots, Link also recorded the single daytime train on the Norfolk & Western's hilly Abingdon branch, serving the rural communities from Abingdon, Virginia, 55 miles (88 km) south to West Jefferson, North Carolina. It was also on this line that most of his railroad color photography was done; a selection is included in \"The Last Steam Railroad in America\". His familiar 1956 view of a horse and steam locomotive \"Maud bows to the Virginia Creeper (Green Cove, Virginia)\" exists in black and white and color versions.\n\nAs well as photographing them, Link was also making sound recordings of the trains, which he issued on a set of six gramophone records between 1957 and 1977 under the overall title \"Sounds of Steam Railroading\". In the railfan world he was probably best known by these, and by photographs published in \"Trains\" magazine and elsewhere in the 1950s, which inspired others to follow his example.\n\nA traveling exhibition in 1983 brought his work to a wider public as did Paul Yule's award-winning documentary \"Trains That Passed In The Night\" (1990), in which Link re-visited the scenes of his classic photographs of the Norfolk and Western.\n\nFrom 1960 until he retired in 1983 Link devoted himself to advertising. Among notable pictures taken during this period are those recording construction of the Verrazano-Narrows Bridge and other views of New York Harbor including the great ocean liners. In retirement, Link moved to South Salem, Westchester County, New York.\n\nIn 1996, Link's second wife, Conchita, was arrested for (and later convicted of) stealing a collection of Link's photographs and attempting to sell them, claiming that Link had Alzheimer's disease and that she had power of attorney. She served six years in prison. After being released, she again attempted to sell some of Link's works that she had stolen, this time using the Internet auction site eBay. She received a three-year sentence. Conchita was also accused of imprisoning her husband. However, this allegation is disputed by some, and it never led to any criminal charges against Conchita. The story of Winston and Conchita became the subject of the documentary \"The Photographer, His Wife, Her Lover\" (2005) made by Paul Yule.\n\nLink made a cameo appearance as a steam locomotive engineer in the 1999 film \"October Sky\". He was actively involved with the planning of a museum of his work when he suffered a heart attack near his home in South Salem, was transported to Northern Westchester Hospital in Mt. Kisco, Westchester County, NY where he died on January 30, 2001. Mr. Link was interred adjacent to his parents in Elmwood Cemetery, Shepherdstown, Jefferson County, West Virginia.\n\nThe rail photography of Winston Link is featured at the O. Winston Link Museum in Roanoke, Virginia, which opened in January 2004. The museum is housed in the former passenger station of the Norfolk and Western Railway. Link's N&W caboose forms part of the display.\n\n\n"}
{"id": "43923886", "url": "https://en.wikipedia.org/wiki?curid=43923886", "title": "PACT (interaction design)", "text": "PACT (interaction design)\n\nIn interaction design, PACT (an acronym for People, Activities, Contexts, Technologies) is a structure used to analyse with whom, what and where a user interact with a user interface \n"}
{"id": "17604369", "url": "https://en.wikipedia.org/wiki?curid=17604369", "title": "Phase shift module", "text": "Phase shift module\n\nA phase shift module is a microwave network module which provides a controllable phase shift of the RF signal. Phase shifters are used in phased arrays.\n\n\n\n"}
{"id": "42113520", "url": "https://en.wikipedia.org/wiki?curid=42113520", "title": "Procurify", "text": "Procurify\n\nProcurify is a cloud-based procurement software company located in Vancouver, British Columbia, Canada. Procurify's main product offering is a cloud-based procurement solution which can be used to manage company spending. Companies that offer procurement solutions will typically focus on automation and of company spending in real-time. The current Procurify platform is considered horizontal, rather than industry specific.\n\nProcurify is headquartered in Vancouver, British Columbia and was founded in 2013 by CEO Aman Mann, CTO Eugene Dong, and COO Kenneth Loi.\n\nProcurify's cloud based procurement software solution is used by companies to manage organizational purchasing and procurement. Like most e-procurement solutions available, Procurify focuses on providing users features including digital purchase order submission and accounts payable automation. Procurify is hosted on the Amazon Web Services and is built using Django. The solution is available as a SaaS. Procurify is offered as a browser-based and mobile procurement software.\n\nThe company founders are BCIT School of Business alumni who graduated together in Operations Management in 2011.\n\nThe idea for Procurify came from a BCIT class project where the founders Aman Mann - CEO, Eugene Dong - CTO, and Kenneth Loi - COO were randomly placed together to consult a Vancouver-based business on their internal processes.\n\nIn November 2012, they joined the Growlab Accelerator program.\nIn February 2013, Procurify graduated from Vancouver-based incubator program GrowLab.\nIn April 2014, Procurify raised a total of 1.2 Million seed round from venture capitalists Nexus Ventures, BDC and Mark Cuban.\nIn July 2015, Procurify raised another seed round totaling $4 Million from Point Nine Capital, Nexus Venture Partners and the Business Development Bank of Canada (BDC). Hootsuite’s CEO Ryan Holmes and its chief revenue officer Steve Johnson also participated in this round.\n"}
{"id": "54949441", "url": "https://en.wikipedia.org/wiki?curid=54949441", "title": "Proton-Electrotex", "text": "Proton-Electrotex\n\nJoint Stock Company \"Proton-Electrotex\" is a Russian company mainly involved in development, manufacturing and sales of bipolar power semiconductor devices — diodes and thyristors, power assemblies and IGBT modules. The company is located in Orel and is one of the largest companies in Orel oblast. Total area of the premises exceeds 15 000 m\n\nThe company was founded in 1996 at premises of a former \"Proton\" plant affiliated with the Ministry of Electronic Industry of the USSR. The purchased facilities and equipment were intended for clean technologies enabling to launch production of power semiconductors, however almost all assembly lines and manufacturing processes, as well as manufacturing processes and routes had to be researched and launched all over again. Designs and technologies were developed jointly with specialists of the in Moscow.\n\nOn January 11, 2011 the company founded a Research and Development Center involved in R&D, designing automatization systems and measurement equipment.\n\nIn 2016 the company launched serial production of IGBT modules, 95% of which had been previously imported to Russia from abroad. Later in 2018 they were extended by a family of low-inductance MIDA-type modules, Full-SiC MCDA-type IGBT and pressure contact PIMA-type IGBT.\n\nIn 2018 quality management system and ecology management systems of the company were certified according to and ISO 14001:2015 standards.\n\n"}
{"id": "4754155", "url": "https://en.wikipedia.org/wiki?curid=4754155", "title": "Rate integrating gyroscope", "text": "Rate integrating gyroscope\n\nA Rate integrating gyroscope is a rate gyro with a built in integrator. It is usually a component of an Inertial Measurement Unit or a stabilization system.\n\nIn a rate indicating gyroscope, the gyroscope is turned at a steady rate about its input axis and a torque is applied to the spin axis. This causes the gyroscope to precess about the output axis.\nThe rate indicating gyroscope consists of a damping fluid between the float assembly can and the outer casing. This viscous fluid resists the motion of the gimbal precession. This causes the gimbal to accelerate initially in the fluid, until the damping effect is equal to the precessing force.\nThe rate of precession, will hence be directly proportional to the rate of turn of the gyroscope about its input axis and the total angle of movement about the output axis will be proportional to the speed and length of time the input axis is turning.\n\nIn a typical application (e.g. an aircraft), the output axis could have revolved 180 degrees clockwise in 20 seconds, then 80° anti-clockwise (say if the aircraft was changing direction again).\nThis output would then be fed to a computer to calculate the total distance traveled (Inertial Navigation Platform).\n\n\n\nGimbal gain is the amount of precession that can be varied by varying the viscosity of the damping fluid. For (for example) increased sensitivity of a gyroscopic instrument.\n\n"}
{"id": "21063926", "url": "https://en.wikipedia.org/wiki?curid=21063926", "title": "SelectaVision", "text": "SelectaVision\n\nSelectaVision was a trademark name used on four classes of device by RCA:\n\nThe \"SelectaVision\" name was abandoned after General Electric's acquisition of RCA in 1986.\n\n\n"}
{"id": "539055", "url": "https://en.wikipedia.org/wiki?curid=539055", "title": "Share taxi", "text": "Share taxi\n\nA share taxi (also called shared taxi) is a mode of transport which falls between a taxicab and a bus. These vehicles for hire are typically smaller than buses and usually take passengers on a fixed or semi-fixed route without timetables, but instead departing when all seats are filled. They may stop anywhere to pick up or drop off their passengers. Often found in developing countries, the vehicles used as share taxis range from four-seat cars to minibuses. They are often owner-operated.\n\nThe UITP term \"informal transport\" includes share taxis.\n\nA given share taxi route may start and finish in fixed central locations, and landmarks may serve as route names or route termini. In some African cities routes are run between formal termini, where the majority of passengers board. In these places the share taxis wait for a full load of passengers prior to departing, and off-peak wait times may be in excess of an hour.\n\nIn other places there may be no formal termini, with taxis simply congregating at a central location, instead.\n\nEven more-formal terminals may be little more than parking lots.\n\nIn South Africa, its also referred to as a rank, which denotes an area specifically built, by a municipality or city, for taxi operators, where commuters may start and end their journey.\n\nWhere they exist, share taxis provide service on set routes within and sometimes between towns.\n\nAfter a share taxi has picked up passengers at its terminus, it proceeds along a semi-fixed route where the driver may determine the actual route within an area according to traffic condition. Drivers will stop anywhere to allow riders to disembark, and may sometimes do the same when prospective passengers want to ride.\n\nWhile all share taxis share certain characteristics—and many regional versions exhibit peculiarities—some basic operational distinctions can be delineated.\n\nMost share taxis are operated under one of two regimes. Some share taxis are operated by a company. For example, in Dakar there are company-owned fleets of hundred of \"car rapides\". In the Soviet Union, share taxis, known as \"marshrutka\", were operated by state-owned taxi parks. There are also individual operators in many countries. In Africa, while there are company share taxis, individual owners are more common. Rarely owning more than two vehicles at a time, they will rent out a minibus to operators, who pay fuel and other running costs, and keep revenue.\n\nIn some places, like some African cities and also Hong Kong, share taxi minibuses are overseen by syndicates, unions, or route associations. These groups often function in the absence of a regulatory environment and may collect dues or fees from drivers (such as per-use terminal payments, sometimes illegally), set routes, manage terminals, and fix fares. Terminal management may include ensuring each vehicle leaves with a full load of passengers.\n\nBecause the syndicates represent owners, their regulatory efforts tend to favor operators rather than passengers, and the very termini syndicates upkeep can cost delays and money for passengers as well as forcing them to disembark at inconvenient locations, in a phenomenon called \"terminal constraint\".\n\nIn Africa, regulation is mainly something that pertains to the vehicle itself not its operator or its mode of operation.\n\nIn Kenya, regulation does extend to operators and mode of operation (such as routes used) as well as the vehicle\n\nAs of 2008, African minibuses are difficult to tax, and may operate in a \"regulatory vacuum\" perhaps because their existence is not part of a government scheme, but is simply a market response to a growing demand for such services. Route syndicates and operator's associations often exercise unrestricted control, and existing rules may see little enforcement.\n\nShare taxi is a unique mode of transport independent of vehicle type. Minibuses, midibuses, covered pickup trucks, station wagons, and lorries see use as share taxis.\n\nCertain vehicle types may be better-suited to current condition than others. In many traffic-choked, sprawling, and low-density African cities minibuses profit.\n\nIn Israel they were mostly the largest model of Mercedes, owned generally by Arabs, and very efficient, having space for 7-8 people, and having loosely fixed routes, dropping a passenger either at a specific terminus or going a little out of way to facilitate the passenger.\n\nWhile carrying different names and distinguished by regional peculiarities, the share taxi is an everyday feature of life in many places throughout the world.\n\nIn Algeria, \"taxis collectifs\" ply fixed routes with their destination displayed. Rides are shared with others who are picked up along the way, and the taxi will leave only when it seats all the passengers it can. While stations, set locations to board and disembark, exist, prospective passengers flag down a \"taxis collectifs\" when they want a ride.\n\nOperating inter and intra-city, \"taxis collectifs\" that travel between towns may be called \"interwilaya taxis\".\n\nAlong with all forms of public transport in Algeria, the Foreign Affairs and International Trade Canada recommend against using these share taxis. The Irish Department of Foreign Affairs asks that you use taxis recommended by a hotel.\nThose in Kinshasa, DRC, (or perhaps just the Kongo people) may call share taxis \"fula fula\" meaning \"quick quick\".\n\nThere was no independent transport authority in the city of Kinshasa as of 2008.\n\nIn Côte d'Ivoire, \"gbaka\" are a name for minibus public transports.\n\nThe transport regulator in Abidjan, CI, is \"Agence de Gestion des Transports Urbains\" or AGETU.\n\nAs of 2008, Abidjan public transport was serviced by large buses as well as minibuses.\n\nSyndicates include UPETCA, SNTMVCI.\nMinibus taxis in Ethiopia are one of the most important modes of transport in big cities like Addis Ababa. They are preferred by the majority of the populace over public buses and more-traditional taxicabs because they are generally cheap, operate on diverse routes, and are available in abundance. All minibus taxis in Ethiopia have a standard blue-and-white coloring scheme, much like the yellow color of New York taxis except it isn't yellow. Minibus taxis are usually Toyota Hiaces, frequent the streets. They typically can carry 11 passengers, but will always have room for another until that is no longer the case. The minibus driver has a crew member called a \"weyala\", and his job is to collect the fare from passengers.\n\nIn 2008, publicly operated public transport was available in Addis Ababa in addition to that provided by the minibuses. A fleet of 350 large buses may operate for this purpose, as such a number does exist. Also as of 2008, the city lacks an independent transport authority, but some regulation, such as that controlling market entry, does exist.\n\nRoute syndicates may be a presence but are described as \"various\".\n\nIn Ghana and neighboring countries, \"tro tro\" are privately owned minibus vehicles for hire that travel fixed routes leaving when filled to capacity. While there are \"tro tro\" stations, these share taxis can also be boarded anywhere along the route.\n\nOperated by a driver and a conductor, who collects money, shouts out the destination, and is called a \"mate\", many are decorated with slogans and sayings, often religious, and few operate on Sundays.\n\nAs of 2008, there is no independent transport authority in Accra, Ghana, and the share taxi industry may be wholly unregulated.\n\n\"Tro tro\" are used by 70% of Ghanaian commuters. This popularity may be because in cities such as Accra have no public transportation system save for these small minibuses.\n\nLarge buses also provide public transport in Accra, as of 2008.\n\nAn informal means of transportation, in Ghana they are licensed by the government, but the industry is self-regulated. In Accra, syndicates include GPRTU and PROTOA.\n\nShare taxis do exist in Cameroon, but as of 2008 minibuses cannot be used for this purpose, by law. That same year, Douala, Cameroon, also was without an independent transport authority.\n\nIn Ouagadougou, capital of Burkina Faso, the share taxi role is not filled by the traditional African minibus.\n\nIn Mali, at least two words for share taxi may have common currency \"sotrama\" and \"dourouni\".\n\nAs of 2008, Bamako, Mali, has no independent transport authority, but share taxi activity could fall under regulator \"Direction de la régulation et du contrôle du transport urbain (municipal)\" or DRCTU control.\nIn Morocco, \"grands taxis\" are the name for large, unmetered, shared taxicabs used for transportation between towns. \"Grands taxis\" are generally old full-size Mercedes-Benz sedans, and seat six or more passengers.\n\nIn Nigeria, both minibuses (called \"danfo\") and midibuses (\"molue\") may be operated as share taxis. Such forms of public transport may also be referred to as \"bolekaja\", and many bear slogans or sayings.\n\nLagos, Nigeria, has a transport-dedicated regulator, Lagos Metropolitan\nArea Transport Agency (LAMATA), its remit most probably includes share taxi activity. Outside of Lagos, most major cities in Africa have similar systems of transport.\n\nSyndicates in Lagos may include National Union of Road and Transport Workers (NURTW).\n\nMinibus public transports in Rwanda may be called coaster buses, share taxis, or \"twegerane\". The latter could easily be a word meaning \"stuffed\" or \"full\".\n\nAs of 2011 in Kigali, Rwanda, syndicates include ATRACO and ONATRACOM, but an independent transport authority is absent.\n\nOver 60% of South African commuters use shared minibus taxis (16 seater commuter buses). \n\nMany of these vehicles are unsafe and not roadworthy, and often dangerously overloaded.\n\nPrior to 1987, the taxi industry in South Africa was highly regulated and controlled. Black taxi operators were declined permits in the Apartheid era and all minibus taxi operations were, by their very nature, illegal.\n\nPost 1987, the industry was rapidly deregulated, leading to an influx of new minibus taxi operators, keen to make money off the high demand for this service. Taxi operators banded together to form local and national associations. Because the industry was largely unregulated and the official regulating bodies corrupt, these associations soon engaged in anti-competitive price fixing and exhibited gangster tactics – including the hiring of hit-men and all-out gang warfare. During the height of the conflict, it was not uncommon for taxi drivers to carry shotguns and AK-47s to simply shoot rival taxi drivers and their passengers on sight.\n\nCurrently the South African Government is attempting to formalize and re-regulate the out-of-control minibus taxi industry. Along with new legislation, the government has instituted a 7-year recapitalization scheme to replace the old and unroadworthy vehicles with new 18- and 35-seater minibuses. These new minibus taxis carry the South African flag on the side and are notably more spacious and safe.\n\nMinivans (minibuses may be a more correct term here) are used as vehicles for hire and referred to as \"dala dala\" in Tanzania. While \"dala dala\" may run fixed routes picking up passengers at central locations, they will also stop along the route to drop someone off or allow a prospective passenger to board. Before minibuses became widely used, the typical \"dala dala\" was a pick-up truck with benches placed in the truck bed.\n\nIn Dar es Salaam, publicly operated minibus service may also exist as of 2008.\n\nUsually run by both a driver and a conductor, the latter is called a \"mpigadebe\", literally meaning \"a person who hits a debe\" (a 4-gallon tin container used for transporting gasoline or water). The name is in reference to the fact that conductors are often hitting the roof and side of the van to attract customers and notify the driver when to leave the station.\n\nThese often-crowded public transports have their routes allocated by a Tanzania transport regulator, Surface and Marine Transport Regulatory Authority (SUMATRA), but syndicates also exist and include DARCOBOA.\n\nIn Kenya, Uganda, and neighboring nations \"matatu\" are privately owned minibuses, although pick-up trucks were in the past pressed into service as these East African public transports whose decoration often features portraits of the famous. Slogans and sayings also appear, some religious. In addition to a driver, \"matatu\" may be staffed by a tout, conductor, or porter.\n\nThey may ply set routes, display this route, run from termini, run both inter and intra-city, and may stop along said route to purchase or collect money from passengers.\n\nAs of 1999, \"matatu\" could have been the only form of public transport in Nairobi, Kenya, but this may not have been the case in 2006 and 2008. As of 2008, Kampala, Uganda, may only be serviced by minibuses.\n\nThe name is a Swahili colloquialism, and were it convenient, passengers could even pay for their journeys via cell phone. The name is literally a conjugation of the word \"three\", and derives from their original price, three shillings \"mashilingi matatu\".\n\nIn Kenya, this industry is regulated, and such minibuses must, by law, be fitted with seatbelts and speed governors. Present regulation may not be sufficient deterrent to prevent small infractions as even decoration may be prohibited. Kenya has one of the \"most extensive regulatory controls to market entry\", and a \"matatu\" worker can be pulled from the streets simply for sporting too loud a shirt.\n\nAs of 2008, Kampala, Uganda, has no independent transport authority, but transport is authorised by Kampala Capital city Authority (KCCA). In Kampala the informal vehicles are called taxis. \n\nEgyptian share cabs are generally known as micro-bus (' or ' , \"project\"; plural ' or ' ). The second name is used by Alexandrians.\n\nMicro-buses are licensed by each governorate as taxicabs, and are generally operated privately by their drivers. Although each governorate attempts to maintain a consistent paint scheme for them, in practice the color of them varies wildly, as the \"consistent\" schemes have changed from time to time and many drivers have not bothered to repaint their cars.\n\nRates vary depending on distance traveled, although these rates are generally well known to those riding the micro-bus. The fares also depend on the city. Riders can typically hail micro-buses from any point along the route, often with well-established hand signals indicating the prospective rider's destination, although certain areas tend to be well-known micro-bus stops.\n\nLike the Eastern European \"marshrutka\", a typical micro-bus is a large van, most often a Toyota HiAce or its Jinbei equivalent, the Haise, and the latter is produced by the Bavarian Auto Manufacturing Group in 6th of October City in Egypt. Smaller vans and larger small buses are also used.\nShare taxis in Tunisia are called \"louage\" and follow fixed or semi-fixed routes, departing from stations when full. Usually minibuses or compact cars, although some \"louage\" are station wagons, passengers may board and disembark at any point during travel.\n\nThey run between towns and within cities.\nThe term \"kia kia\" may be used in Yorùbáland to refer to minibus public transports, and means \"quick quick\".\n\nIn Mainland China, it is normal in some areas like Yingkou City to share a regular taxicab with other passengers waiting song the same route. However, the primary passenger has the right to refuse pickup.\nPublic light buses (), also known as minibus or maxicab (), run the length and breadth of Hong Kong, through areas which the standard bus lines cannot or do not reach as frequently, quickly or directly.\n\nTypically offering a faster and more efficient transportation solution due to their small size, limited carrying capacity, frequency and diverse range of routes, although they are generally slightly more expensive than standard buses, minibuses carry a maximum of 16 seated passengers. Standing passengers are not allowed.\n\nThere are two types of public light minibus, green and red. Both types have a cream-coloured body, the distinguishing feature being the colour of the external roof, and the type of service that the colour denotes: green is like regular transit bus with fixed number, route, schedule and fare (but generally not fixed stops); red is a shared taxi, operating on semi-fixed route unregulated, with the driver waiting for enough passengers to justify leaving, as his income depends on the revenue.\n\nShared taxis have been operating in Mumbai, India, since the early 1970s. These are point-to-point services that operate during peak hours. During off-peak hours they ply like regular taxis; they can be hailed anywhere on the roads and passengers are charged by the meter. During peak hours they will take a full cab load of passengers to a more or less common destination. The pick-up points are usually fixed, and sometimes (but not always) marked by a sign saying \"shared taxis\". Cabs typically line up at this point during peak hours.\n\nThey sometimes display their general destination on their windscreens, and passengers get in and wait for the cab to fill up. Once full the cab moves off. Fares are fixed and much lower than the metered fare to the same destination, but higher than a bus or train fare.\n\nSuch informal arrangements also exist in other Indian cities. Share jeeps are a common form of transportation in the Himalayas, the North Eastern States and elsewhere.\n\nAngkutan Kota abbreviated Angkot or Mikrolet are share taxis in Indonesia widely operating throughout the country usually with Mini vans. In some places there are also three-wheelers which are called \"Bemo\" (such as autorickshaws based on the Daihatsu Midget). The older version of Angkot is called \"Oplet\". The name of this transportation differs from each different province or area in the country. In Jakarta, it is called \"Angkot\", in other parts such as in Sulawesi, the term \"Mikrolet\" shortened \"Mikro\" is more widely used especially in Manado. In Makassar it is called \"Pete-Pete\", in Malang it is called \"Angkota\", in Medan it is called \"Sudako\".\n\nIt runs accordingly with its exact routes and passengers can stop the van anywhere according to its destination, and is not required to stop at a bus stop or station.\n\nIn Iran a share taxi is usually called \"taxi\", while a non-share is called \"ajans\"/اژانس, pronounced [aʒans]. Four passengers share a taxi and sometimes there is no terminus and they wait in the street side and blare their destination to all taxies until one of them stops. These are regular taxies but if somebody wants to get a non-share taxi he can call for an ajans (taxi service) for himself or wait in the street side and say 'DARBAST' (which means non-share). It means he is not interested in sharing the taxi and is consequently willing to pay more for the privilege.\n\nMinibuses, in the past years, with a capacity of 18 passengers, and nowadays van taxies, with a capacity of 10 passengers are other kinds of share transport in Iran.\n\nIn \"Sherut\", pl. \"moniyot sherut\" is a word meaning \"service\". Also referring to vans that serve as share taxis in Israel, these can be picked up from \"sherut\" stations. They follow fixed routes (sometimes the same routes as public transport buses), leave when full, and will only disembark passengers along the route. \"Moniyot sherut\" operate both inter and intra-city. Payment is often done by passing money to the driver in a \"human chain\" formed by the passengers seated before. The change (and the receipt, when requested) are returned to the person who paid by the same means. In intra-city routes, where they compete with official buses, the drivers usually coordinate their travel by radio so that they can arrive at the bus station just before public transport buses and take the most passengers.\n\nCalled \"ser-vees\" (service taxi) by Palestinians, in the West Bank vans are replaced by minibuses, for a while \"Ford Transit\" model was predominant in the Palestinian territories, hence the names \"Ford\" and \"Fordat\"(pl) are used to describe minibuses of various makes, which replaced aging Mercedes sedans previously used widely, etc.\n\nThe most popular means of public transportation in the Philippines as of 2007, jeepneys were originally made out of US military jeeps left over from World War II and are known for their color and flamboyant decoration. Today the jeepneys are built by local body shops from a combination of prefabricated elements (from handful Filipino manufacturers) and improvisation and in most cases equipped with \"surplus\" or used Japanese SUV or light truck engines, drive train, suspension and steering components (from recycled vehicles in Japan).\n\nThey have not changed much since their post-war creation, even in the face of an increased access to pre-made vehicles, such as minibuses.\n\nJeepneys have the entrance on the back, and there is space for two people beside the driver (or more if they are small). The back of the Jeepney is equipped with two long bench seats along the sides and the people seated closest to the driver are responsible for passing the fare of new passengers forward to the driver and the change back to the passenger. The start and end point of the Jeepney route is often a Jeepney terminal, where there is a queue system so only one Jeepney plying a particular route is filled at a time, and where a person helps the driver to collect fares and fill the vehicles with people, usually to more than comfortable capacity.\n\nPreferring to leave only when full and only stop for a crowd of potential passengers, riders can nonetheless disembark at any time; and while jeepneys ply fixed routes, these may be subject to change over time. New ones may need approval from a Philippine transport regulator. Jeepney stations do exist.\n\nLiterally \"two rows\" a \"songthaew\" or \"song thaew\" (Thai สองแถว, Lao: ສອງແຖວ [sɔ̌ːŋtʰíw]) is a passenger vehicle in Thailand and Laos adapted from a pick-up or a larger truck and used as a share taxi. They are also known as baht buses.\n\nIn New Zealand the first widespread motor vehicle services were shared taxi services termed \"service cars\"; a significant early provider was Aard, operating elongated Hudson Super-Six Coaches. By 1930 there were 597 service cars. Aard was taken over by New Zealand Railways Road Services in 1928. Shared taxis in New Zealand nowadays are referred to as \"Shuttles\" or \"Shuttle vans\" (see below).\nShared buses or vans are available in many more developed countries connecting frequent destinations, charging a fixed fee per passenger. The most common case is a connection between an airport and central city locations. These services are often known as shuttles. Such services usually use smaller vehicles than normal buses, and often operate on demand. An air traveller can contact the shuttle company by telephone or Internet, not necessarily in advance; the company will ensure that a shuttle is provided without unreasonable delay. The shuttle will typically connect one airport with several large hotels, or addresses in a specified area of the city. The shuttle offers much of the convenience of a taxi, although taking longer, at a price which is significantly lower for one or two passengers. Scheduled services between an airport and a hotel, usually operated by the hotel, are also called shuttles.\n\nIn many cases the shuttle operator takes the risk of there not being enough passengers to make the trip profitable; in others there is a minimum charge when there are not enough passengers.\n\nUsually there are regulations covering vehicles and drivers; for example in New Zealand under NZTA regulations, shuttles are only allowed to have up to eleven passenger seats, and the driver must have a passenger endorsement (P) on their drivers' licence.\n\nIn Cyprus, there are privately owned share taxis that travel to set destinations and board additional passengers en route called service taxis.\n\nIn Turkey and Turkish controlled Northern Cyprus \"dolmuş\" (pronounced \"dolmush\") are share taxis that run on set routes within and between cities. Each of these cars or minibuses displays their particular route on signboards behind the windscreen.\n\nSome cities may only allow \"dolmuş\" to pick up and disembark passengers at designated stops, and terminals also exist. The word derives from Turkish for \"full\" or \"stuffed\", as these share taxis depart from the terminal only when a sufficient number of passengers have boarded. Visitors to Turkey have been surprised by the speed of \"dolmuş\" travel.\n\nThese share taxis are also found in Turkish-controlled, Northern Cyprus under the same name. Traveling intra and inter-city, the privately owned minibuses or aging Mercedes stretch limos are overseen by a governance institution; routes are leased and vehicles licensed. Passengers board anywhere along the route (you may have to get the driver to stop if he doesn't honk at you) as well as at termini and official stations. \"Dolmuş\" in Turkish-controlled, Northern Cyprus display their routes but don't follow timetables. Instead, they simply appear frequently.\n\nShare taxis in Estonia are mostly found in Tallinn, the capital. Called \"liinitakso\", \"marsruuttakso\", \"taksobuss\" or \"mikroautobuss\" depending on the language spoken, these minibuses run fixed routes and allow passengers to disembark at any time.\n\nIn Athens, Greece most taxis were share taxis, but since the country joined the EU this tradition started to disappear.\n\n\"Marshrutka\" or \"marshrutnoe taksi\" are share taxis found in Eastern Europe and the republics of the former Soviet Union. Usually vans, they drive along set routes, usually depart only when all seats are filled, and may have higher fares than buses. Passengers can board a \"marshrutka\" anywhere along its route if there are seats available.\n\nAs fares are usually paid before the \"marshrutka\" leaves, which seat you choose can have consequences. Riders nearer the driver are responsible for handing up the other passengers' fares and passing back change.\n\nIn Lithuania, share taxis are called \"maršrutinis taksi\".\n\nBesides the conventional \"deeltaxi\", there are \"treintaxis\" in some Dutch towns. Operated on behalf of the Netherlands Railways, they run to and from railway stations and the ride is shared with additional passengers picked up along the way. Tickets can be purchased at railway ticket offices or from the cabdriver, but \"treintaxis\" must be ordered by phone unless boarding at a railway station.\n\nIn 2018 Arriva launched shared taxi service Arriva Click in Liverpool and Sittingbourne and Kent Science Park in the United Kingdom.\n\nIn some towns in Northern Ireland, notably certain districts in Ballymena, Belfast, Derry and Newry, share taxi services operate using Hackney carriages and are called black taxis. These services developed during The Troubles as public bus services were often interrupted due to street rioting. Taxi collectives are closely linked with political groups – those operating in Catholic areas with Sinn Féin, those in Protestant areas with loyalist paramilitaries and their political wings.\n\nTypically, fares approximate to those of Translink operated bus services on the same route. Service frequencies are typically higher than on bus services, especially at peak times, although limited capacities mean that passengers living close to the termini may find it difficult to find a black taxi with seats available in the rush hour.\n\n\"Carros Públicos\" (literally \"Public Cars\") are share taxis in the Dominican Republic and Puerto Rico.\n\nIn the Dominican Republic, these privately owned vehicles run fixed routes with no designated stops, and the ride is shared with other passengers.\n\nForeign Affairs and International Trade Canada advises against traveling in Dominican Republic \"carros públicos\" because doing so makes passengers targets for robbery, and because the taxis are known to, \"disregard traffic laws, often resulting in serious accidents involving injuries and sometimes death.\" The US Department of State also warns that using them is hazardous, as passengers often have their pockets picked, and are sometimes robbed by the drivers themselves.\n\nIn Puerto Rico, \"carros públicos\" ply set routes with several passengers sharing the ride and others picked up throughout the journey.\n\nThe industry is regulated by the Puerto Rico Public Service Commission.\n\nWhile these cars do travel inter-city, they may not be available for longer, cross-island travel. Stations may exist in cities, and Puerto Rican \"carros públicos\" may congregate in specific places around town.\n\nIn Quebec, share taxis or jitneys are called \"taxis collectifs\" (in English \"collective taxis\") or \"transport collectif par taxi\" (which may be translated in English as \"taxibus\") and are operated by subcontractors to the local transit authorities on fixed routes.\n\nIn the case of the Montréal the fare is the same as local bus fare, but no cash and transfers are issued or accepted; in case of the STL only bus passes. The Réseau de transport de Longueuil accepts regular RTL tickets and all RTL and some Réseau de transport métropolitain TRAM passes.\n\nIn Saint Lucia, waychehs are a name for minibus public transports using Toyota HiAce.\n\n\"Jitney\" is an American English term that originally referred to a vehicle for hire intermediate between a taxi and a bus. They are generally small-capacity vehicles that follow a rough service route, but can go slightly out of their way to pick up and drop off passengers. In many US cities (e.g. Pittsburgh and Detroit), the term \"jitney\" refers to an unlicensed taxi cab.\n\nThe name comes from an archaic, colloquial term for a five-cent piece in the US (the nickel). The common fare for the service when it first came into use was five cents, so the \"five-cent cab\" or \"jitney cab\" came to be known for the price charged.\n\nIn Rhode Island a jitney license plate is used for all public passenger buses, even for larger ones.\nWhile jitneys became fairly common in many other countries, such as the Philippines, they first appeared in the US and Canada. The first US jitneys ran in 1914 in Los Angeles, California. By 1915, there were 62,000 nationwide. Local regulations, demanded by streetcar companies, killed the jitney in most places. By the end of 1916, only 6,000 jitneys remained. Similarly, in Vancouver, British Columbia, Canada, in the 1920s, jitneys competed directly with the streetcar monopoly operating along the same routes as the streetcars, but jitneys were charging lower fares. Operators were referred to as \"jitney men.\" They were so successful that the city government banned them at the request of the streetcar operators.\n\nSince the 1973 oil crisis (as well as the mid-20th-century decline in transit service), jitneys have reappeared in some areas of the US, particularly in inner city areas once served by streetcars and private buses. An increase in bus fares usually leads to a significant rise in jitney usage. Liberalization of jitneys is often encouraged by libertarian urban economists, such as University of Chicago's Richard Epstein, Rutgers' James Dunn, and USC's Peter Gordon, as a more \"market-friendly\" alternative to public transportation. Concerns over fares, insurance liabilities, and passenger safety have kept legislative support for jitneys decidedly tepid. Nevertheless, in New York City and northern New Jersey, jitneys (known as \"dollar vans\" because of their original price) are regulated.\n\nMiami has the country's most comprehensive jitney network, due to Caribbean influence. In Atlanta jitneys run along Buford Highway.\n\nIn Atlantic City the ACJA operates a jitney service that travels the main strip of casinos. One of the routes also services the new cluster of casinos west of Atlantic City proper.\n\nIn 2009, the Houston Waves, Houston's first jitney service in 17 years, started running. It has expanded into a network of buses operating within Loop 610 and to all special event venues in Houston.\n\n\"Colectivos\" operated as share taxis from the late 1920s until the 1950s in Buenos Aires, Argentina when they were integrated into the public transportation system. Vehicles still known as \"colectivos\" operate throughout the country, but have long been indistinguishable from buses.\n\nOften share taxi routes in Mexico are \"ad hoc\" arrangements to fill in gaps in regular public transportation, and many operate inter-city as well as local routes. In many rural areas, they are the only public transportation.\n\nIn some cases truck/taxi combination vehicles have evolved to transport light goods as well as passengers. Heavily used share taxi routes often evolve into regulated microbus public transit routes, as has occurred in Mexico City and in Lima.\n\n\"Taxis colectivos\" are also found in Perú, Chile, Guatemala, and Argentina, where they are most commonly referred to simply as \"colectivos\", although in some places they have become essentially standard buses.\n\n\"Tap taps\", gaily painted buses or pick-up trucks, and \"publiques\", usually older saloon cars, serve as share taxis in Haiti.\n\n\"Tap taps\" are privately owned and beautifully decorated. They follow fixed routes; won't leave until filled with passengers; and many feature wild colors, portraits of famous people, and intricate, hand-cut wooden window covers. Often they are painted with religious names or slogans. Riders can disembark at any point in the journey. Their name refers to \"fast motion\".\n\nThe \"publiques\" operate on fixed routes and pick up additional passengers all along the way.\n\nWhile saying not to use any form of public transport in Haiti, the Foreign Affairs and International Trade Canada advises against \"tap tap\" travel especially. The US State Department also warns travelers not to use \"tap taps\", \"because they are often overloaded, mechanically unsound, and driven unsafely.\"\nIn Guatemala, \"ruleteros\", minibus share taxis, pick up and discharge passengers along major streets.\n\nModern Paratransit services, also known as demand responsive transport systems in the UK, can provide shared transport services in situations where scheduled services are not viable. Traditionally these services had to be booked a day in advance, but are becoming increasingly responsive using modern communications systems with a central booking system accessed by phone or internet and instant communications with GPS tracked vehicles. Unlike scheduled services the vehicles need not operate on fixed routes of timetables, although they do often have constrained routes.\n\nSome newer taxi share systems now use internet and mobile phone communications for booking and scheduling purposes, with the actual service provided by normal hackney carriage or Private Hire vehicles. Prospective passengers make bookings and supply destination details using SMS to a central server which aggregates these travel requests and creates packages of trips which are then communicated to drivers.\n\nThere are many operators of airport shuttle services between Airports and Hotels around the world that operate on flexible routing and timing to offer a service that is both cheaper than a sole-occupancy taxi and also often more convenient that other forms of public transport. The requirement to carry luggage offers an added incentive to use such services over scheduled transport which will normally require a walk from the drop-off location to the final destination. Services from these operators are starting to spread from airports to railway stations and to other locations.\n\nSome operators and/or governments around the world are now offering demand-based shared transport to residents in community with low ridership numbers, which could help maintain the existence of public transport. Operations are predefined according to bookings.\n\n"}
{"id": "220901", "url": "https://en.wikipedia.org/wiki?curid=220901", "title": "Software release life cycle", "text": "Software release life cycle\n\nA software release life cycle is the sum of the stages of development and maturity for a piece of computer software: ranging from its initial development to its eventual release, and including updated versions of the released version to help improve software or fix software bugs still present in the software.\n\nUsage of the \"alpha/beta\" test terminology originated at IBM. Similar terminologies for IBM's software development were used by people involved with IBM from at least the 1950s (and probably earlier). \"A\" test was the verification of a new product before the public announcement. \"B\" test was the verification before releasing the product to be manufactured. \"C\" test was the final test before the general availability of the product. As software became a significant part of IBM's offerings, the alpha test terminology was used to denote the pre-announcement test and the beta test was used to show product readiness for general availability. Martin Belsky, a manager on some of IBM's earlier software projects claimed to have invented the terminology. IBM dropped the alpha/beta terminology during the 1960s, but by then it had received fairly wide notice. The usage of \"beta test\" to refer to testing done by customers was not done in IBM. Rather, IBM used the term \"field test\".\n\nPre-alpha refers to all activities performed during the software project before formal testing. These activities can include requirements analysis, software design, software development, and unit testing. In typical open source development, there are several types of pre-alpha versions. \"Milestone\" versions include specific sets of functions and are released as soon as the functionality is complete.\n\nThe alpha phase of the release life cycle is the first phase to begin software testing (alpha is the first letter of the Greek alphabet, used as the number 1). In this phase, developers generally test the software using white-box techniques. Additional validation is then performed using black-box or gray-box techniques, by another testing team. Moving to black-box testing inside the organization is known as \"alpha release\".\n\nAlpha software can be unstable and could cause crashes or data loss. Alpha software may not contain all of the features that are planned for the final version. In general, external availability of alpha software is uncommon in proprietary software, while open source software often has publicly available alpha versions. The alpha phase usually ends with a feature freeze, indicating that no more features will be added to the software. At this time, the software is said to be feature complete.\n\nBeta, named after the second letter of the Greek alphabet, is the software development phase following alpha. Software in the beta stage is also known as \"betaware\". Beta phase generally begins when the software is feature complete but likely to contain a number of known or unknown bugs. Software in the beta phase will generally have many more bugs in it than completed software, speed or performance issues, and may still cause crashes or data loss. The focus of beta testing is reducing impacts to users, often incorporating usability testing. The process of delivering a beta version to the users is called \"beta release\" and this is typically the first time that the software is available outside of the organization that developed it. Beta version software is often useful for demonstrations and previews within an organization and to prospective customers. Some developers refer to this stage as a \"preview\", \"preview release\", \"prototype\", \"technical preview\" / \"technology preview\" (\"TP\"), or \"early access\". Some software is kept in perpetual beta, where new features and functionality are continually added to the software without establishing a final \"stable\" release.\n\n\"Beta testers\" are people who actively report issues of beta software. They are usually customers or representatives of prospective customers of the organization that develops the software. Beta testers tend to volunteer their services free of charge but often receive versions of the product they test, discounts on the release version, or other incentives.\n\nAs the Internet has facilitated rapid and inexpensive distribution of software, companies have begun to take a looser approach to use of the word \"beta\". In February 2005, ZDNet published an article about the recent phenomenon of a beta version often staying for years and being used as if it were in production level, disparagingly called \"perpetual beta\". It noted that Gmail and Google News, for example, had been in beta for a long time although widely used; Google News did leave beta in January 2006, followed by Google Apps, including Gmail, in July 2009. This technique may allow a developer to delay offering full support and responsibility for remaining issues. In the context of Web 2.0, people even talk of perpetual betas to signify that some software is meant to stay in beta state. Also, \"beta\" is sometimes used to indicate something more like a release candidate, or as a form of time-limited demo, or marketing technique. Since the introduction of Windows 8, Microsoft has called pre-release software as a \"preview\", rather than beta. All pre-release builds released through the Windows Insider Program launched in 2014 are termed \"Insider Preview builds\".\n\nDevelopers may release either a \"closed beta\" also called \"private beta\", or an \"open beta\" also called \"public beta\"; closed beta versions are released to a restricted group of individuals for a user test by invitation, while open beta testers are from a larger group, or anyone interested. Private beta could be suitable for the software that is capable to deliver value, but is not ready to be used by everyone either due to scaling issues, lack of documentation or still missing vital features. The testers report any bugs that they find, and sometimes suggest additional features they think should be available in the final version. Examples of a major public beta test include the following:\n\nOpen betas serve the dual purpose of demonstrating a product to potential consumers, and testing among an extremely wide user base likely to bring to light obscure errors that a much smaller testing team might not find.\n\nA \"release candidate\" (\"RC\"), also known as \"going silver\", is a beta version with potential to be a final product, which is ready to release unless significant bugs emerge. In this stage of product stabilization, all product features have been designed, coded and tested through one or more beta cycles with no known showstopper-class bugs. A release is called \"code complete\" when the development team agrees that no entirely new source code will be added to this release. There could still be source code changes to fix defects, changes to documentation and data files, and peripheral code for test cases or utilities. Beta testers, if privately selected, will often be credited for using the release candidate as though it were a finished product. Beta testing is conducted in a client's or customer's location and to test the software from a user's perspective.\n\nOnce released, the software is generally known as a \"stable release\". The formal term often depends on the method of release: physical media, online release or a web application.\n\nThe term \"release to manufacturing\", also known as \"going gold\", is a term used when a software product is ready to be delivered. This build may be digitally signed, allowing the end user to verify the integrity and authenticity of the software purchase. A copy of the RTM build known as the \"gold master\" or GM is sent for mass duplication if applicable. RTM precedes general availability (GA) when the product is released to the public.\n\nIt is typically used in certain retail mass-production software contexts—as opposed to a specialized software production or project in a commercial or government production and distribution—where the software is sold as part of a bundle in a related computer hardware sale and typically where the software and related hardware is ultimately to be available and sold on mass/public basis at retail stores to indicate that the software has met a defined quality level and is ready for mass retail distribution. RTM could also mean in other contexts that the software has been delivered or released to a client or customer for installation or distribution to the related hardware end user computers or machines. The term does \"not\" define the delivery mechanism or volume; it only states that the quality is sufficient for mass distribution. The deliverable from the engineering organization is frequently in the form of a golden master media used for duplication or to produce the image for the web.\n\n\"General availability\" (\"GA\") is the marketing stage at which all necessary commercialization activities have been completed and a software product is available for purchase, depending, however, on language, region, electronic vs. media availability. Commercialization activities could include security and compliance tests, as well as localization and worldwide availability. The time between RTM and GA can be from a week to months in some cases before a generally available release can be declared because of the time needed to complete all commercialization activities required by GA. At this stage, the software has \"gone live\".\n\n\"Release to the web (RTW)\" or \"web release\" is a means of software delivery that utilizes the Internet for distribution. No physical media are produced in this type of release mechanism by the manufacturer. Web releases are becoming more common as Internet usage grows.\n\nDuring its supported lifetime, software is sometimes subjected to service releases, patches or service packs, sometimes also called \"interim releases\". For example, Microsoft released three major service packs for the 32-bit editions of Windows XP and two service packs for the 64-bit editions. Such service releases contain a collection of updates, fixes, and enhancements, delivered in the form of a single installable package. They may also implement new features. Some software is released with the expectation of regular support. Classes of software that generally involve protracted support as the norm include anti-virus suites and massively multiplayer online games. A good example of a game that utilizes this process is Minecraft, an indie game developed by Mojang, which features regular \"updates\" featuring new content and bug fixes.\n\nWhen software is no longer sold or supported, the product is said to have reached end-of-life, to be discontinued, retired, deprecated, abandoned, or obsolete, but user loyalty may continue its existence for some time, even long after its platform is obsolete—e.g., the Atari ST and Sinclair ZX Spectrum.\n\nAfter the end-of-life date, the developer will usually not implement any new features, fix existing defects, bugs or vulnerabilities (known before that date or not) or provide any support for the product.\n\n\n"}
{"id": "25985990", "url": "https://en.wikipedia.org/wiki?curid=25985990", "title": "Spurious tone", "text": "Spurious tone\n\nIn electronics (radio in particular), a spurious tone (also known as an interfering tone, a continuous tone or a spur) denotes a tone in an electronic circuit which interferes with a signal and is often masked underneath that signal. Spurious tones are any tones other than a fundamental tone or its harmonics. They also include tones generated within the back-to-back connected transmit and receive terminal or channel units, when the fundamental is applied to the transmit terminal or channel-unit input.\n\n"}
{"id": "56859287", "url": "https://en.wikipedia.org/wiki?curid=56859287", "title": "TeXet", "text": "TeXet\n\nTeXet is a Russian manufacturer of consumer electronics, based in Saint Petersburg. It is owned by Electronic Systems Alkotel.\n\nThe company's flagship phone was the TM-5200, which was installed with the Yandex Opera Mini and Yandex Opera Mobile web browsers.\n\n\nteXet also manufacturers feature phones, which have fewer features and are considered to meet operational security requirements approved by the General Staff of the Armed Forces of the Russian Federation.\n\n"}
{"id": "12626087", "url": "https://en.wikipedia.org/wiki?curid=12626087", "title": "The Clean Tech Revolution", "text": "The Clean Tech Revolution\n\nThe Clean Tech Revolution: The Next Big Growth and Investment Opportunity is a 2007 book by Ron Pernick and Clint Wilder, who say that commercializing clean technologies is a profitable enterprise that is moving steadily into mainstream business. As the world economy faces challenges from energy price spikes, resource shortages, global environmental problems, and security threats, clean technologies are seen to be the next engine of economic growth.\n\nPernick and Wilder highlight eight major clean technology sectors: solar power, wind power, biofuels, green buildings, personal transportation, the smart grid, mobile applications, and water filtration. Six major forces, which they call the six C’s, are pushing clean technology into the mainstream: costs, capital, competition, China, consumers, and climate. Very large corporations such as GE, Toyota and Sharp, and investment firms such as Goldman Sachs are making multibillion-dollar investments in clean technology.\n\nThe book has been reviewed in \"USA Today\", \"Business Week\", \"Energy Priorities\", \"Sustainability Investment News\" and several other magazines, and has been translated into seven languages. \"Clean Tech Nation\" is the sequel to \"The Clean Tech Revolution\".\n\nPernick and Wilder explain that, in the 1970s, clean technology was considered “alternative,” the province of back-to-the-land lifestyle advocates, altruistic environmentalists, and lab scientists on research grants. Such technology was in an early stage of development, was too expensive, it did not have widespread political support, and very few large, established companies were embracing the sector. Even at the start of the 21st century, the term \"clean tech\" was not yet in the financial or business community’s vocabulary. But now, throughout much of the world, in trends large and small, there is \"the beginning of a revolution that is changing the places where we live and work, the products we manufacture and purchase, and the development plans of cities, regional governments, and nations around the globe.\"\n\nPernick and Wilder define \"clean tech\" as \"any product, service, or process that delivers value using limited or zero non-renewable resources and/or creates significantly less waste than conventional offerings.\" They highlight eight major clean technology sectors: solar power, wind power, biofuels, green buildings, personal transportation, the smart grid, mobile applications (such as portable fuel cells), and water filtration. The authors explain how investors, entrepreneurs, and individuals can profit from technological innovation in these areas. Pernick and Wilder identify some specific clean technologies, companies, and regions that are leading the way.\n\nThe authors present a list of drivers for clean tech: \"high energy prices, depleted natural resources, volatile sources of foreign oil, record deficits, and unprecedented environmental and security challenges\". The central message, which is repeated in almost every chapter, is that a clean tech revolution with benefit humanity worldwide, and will require significant collaboration between the public and private sectors.\n\nPernick and Wilder present examples which show that the \"clean tech revolution\" is already under way. Very large corporations such as GE, Toyota and Sharp, and investment firms such as Goldman Sachs are making multibillion-dollar investments in clean technology. Emerging clean tech cities are seen to include Copenhagen, where wind power generates 20 percent of Denmark's electricity, and Chicago, a leader in \"green\" buildings saving energy, heating and cooling costs. Statistics from the U.S. and from abroad, especially from China, India, Brazil, and Europe are presented.\n\nThe authors' claim that nuclear power and clean coal are not clean technologies. Apart from the risks associated with nuclear power, \"multibillion-dollar nuclear plants are simply not cost-effective when compared with other energy sources.\" The authors also believe that \"clean coal\" is an oxymoron for a myriad of reasons, including the sheer number of coal mine-related deaths and the fact that coal-fired plants, even some cleaner ones, are major contributors to serious illnesses such as asthma, heart disease, and mercury poisoning.\n\nPernick and Wilder do not recommend specific stocks or securities. They prefer to lay out a blueprint of opportunities, technologies, companies, and trends that may build successful businesses and strengthen economies.\n\nPernick and Wilder identify six major forces, which they call the six C’s, that are pushing clean technology into the mainstream and driving rapid growth and expansion: costs, capital, competition, China, consumers, and climate.\n\n\nThe six C’s are a simple list of factors, not necessarily a useful framework for understanding, or profiting from, the clean technology industry.\n\n\"The Clean Tech Revolution\" was published by Collins as a 320-page hardcover book on June 12, 2007. An e-book version was published by HarperCollins on June 7, 2007. In 2008, a revised paperback edition was published, with a new sub-title: \"Discover the Top Trends, Technologies and Companies to Watch\". The book has been translated into seven languages.\n\nPaul Gruber from the Erb Institute states that \"The Clean Tech Revolution\" is logically organized and is \"an excellent resource for those who would like a solid understanding of clean tech and the potential of each sector\". He also says that it is very useful for those seeking out the names of companies, NGOs, agencies, and people working on each technology. Gruber identifies one omission: the concern that major investments in clean technology parallel those made during the Internet boom, with the attendant fear that there \"may be a bubble burst with clean tech\".\n\nThe physicist and environmentalist, Joseph Romm, has recommended \"The Clean Tech Revolution\" to people who are looking for one book to help them understand what is happening in clean technology. He says \"The Clean Tech Revolution\" is the only book that covers the whole gamut of the latest in clean energy.\n\nRuss Juskalian from \"USA Today\" says \"The Clean Tech Revolution\" shows the green movement not in \"heartstring terms\" but as economically profitable. The real power players are the mainstream consumers, investors, entrepreneurs, governments and multinational corporations whose \"eyes are trained on that most crucial of economic fundamentals: the bottom line\".\n\nAccording to Reena Jana from \"Business Week\", \"The Clean Tech Revolution\" is a \"readable, straightforward guide to earth-friendly business strategies\". The authors explain how businesses can follow the lead of companies such as Toyota by designing, selling, or funding inventive eco-friendly products and services. Jana says that the Toyota Prius is just one well-known example of successful clean technology in action.\n\nDenis Du Bois, editor of \"Energy Priorities\" magazine, commented on the realistic and comprehensive coverage of the book. However, he suggests that \"The Clean Tech Revolution\" is not an explanation of the technologies and how they work, nor is it an analysis of energy or environmental policy. Policy is complicated and the authors avoid discussing it in detail. Little discussion ties the various clean technologies together and a \"single-minded American focus\" dominates. There is very little on the influence of mass transit and urban planning in Europe and other progressive regions. The chapter on water focuses on filtration, which is already an area of considerable opportunity, affecting even \"green\" industries, such as photovoltaics manufacturing.\n\nFrancesca Rheannon in \"Sustainability Investment News\" says that the book does not ask the most challenging question of all: is \"clean growth\" an oxymoron? She says that at a time when some experts say carbon emissions will need to be cut by 80 to 90% by 2050, the world may have to accept steady or even decreasing energy production, no matter how clean it is. Rheannon also states that there is little coverage of social issues. For example, nowhere is there mention of how water supply privatization and delivery by multinational corporations could affect the poor people of the world.\n\nThe \"Clean Tech Revolution\" was followed by the 2012 book \"Clean Tech Nation: How the U.S. Can Lead in the New Global Economy\".\n\nAuthor Ron Pernick is co-founder and managing director of Clean Edge, a research and strategy firm in the United States which focuses on the commercialization of renewable energy and other clean technologies. Clint Wilder is senior editor at Clean Edge, and a veteran business and technology journalist. Both authors have been mapping clean technology trends for many years, and identifying business opportunities for prospective investors.\n\n"}
{"id": "435791", "url": "https://en.wikipedia.org/wiki?curid=435791", "title": "The Triumph of Technique", "text": "The Triumph of Technique\n\nThe Triumph of Technique: The Industrialization of Agriculture and the Destruction of Rural America is a 2004 book by Robert Wolf.\n\n\"The Triumph of Technique\" examines contemporary agriculture and its impact on rural economies. This book has been hailed by leaders of the sustainable agriculture movement as a significant contribution to understanding the depth of the current crisis in agriculture and its implications.\n\nThe “technique” of the title refers not only to technologies but to any methods developed for the purpose of achieving predetermined ends. Wolf argues that technique, as he defines it, has taken the art out of farming by transforming it into agribusiness, on a much larger scale. He claims that this transformation has led to the decline of rural communities.\n"}
{"id": "4133407", "url": "https://en.wikipedia.org/wiki?curid=4133407", "title": "Uranium Information Centre", "text": "Uranium Information Centre\n\nThe Uranium Information Centre (UIC) was an Australian organisation primarily concerned with increasing the public understanding of uranium mining and nuclear electricity generation. \n\nFounded in 1978, the Centre worked for many years to provide information about the development of the Australian uranium industry, the contribution it can make to world energy supplies and the benefits it can bring Australia. It was a broker of information on all aspects of the mining and processing of uranium, the nuclear fuel cycle, and the role of nuclear energy in helping to meet world electricity demand.\n\nThe Centre was funded by companies involved in uranium exploration, mining and export in Australia.\n\nIn 1995 Ian Hore-Lacy assumed the role of General Manager of the UIC, a position he held until 2001. The UIC's website was established in the year of his appointment. After leaving the UIC, Ian Hore-Lacy went on to work for the World Nuclear Association (WNA) as Director of Public Information for 12 years and as of 2015 he continues to work there as a Senior Research Analyst. In the late 2000s, the UIC's main information-providing function was assumed by the WNA and World Nuclear News (WNN), based in London, UK.\n\nIn 2008 the UIC's purely domestic function was taken over by the Australian Uranium Association, and was subsequently absorbed by the Minerals Council of Australia's uranium portfolio in 2013.\n\n\n"}
{"id": "35747818", "url": "https://en.wikipedia.org/wiki?curid=35747818", "title": "Vaxess Technologies", "text": "Vaxess Technologies\n\nVaxess Technologies, Inc. is a company started by a team of four graduate students from Harvard developing a suite of vaccines on the MIMIX sustained dermal delivery platform that combines high temperature stability, improved efficacy, and simplified delivery to improve global vaccine access.\n\nStudents Michael Schrader, Livio Valenti, Kathryn Kosuda, and Patrick Ho started Vaxess in December 2011, based on a technology created by David Kaplan and Fiorenzo Omenetto. Schrader graduated with an MBA from Harvard Business School in 2012. Valenti attended the John F. Kennedy School of Government. Kosuda had been a Harvard postdoctoral fellow in chemistry, and Patrick Ho had earned a J.D in 2012.\n\nIn 2012, Vaxess was awarded $25,000 from Harvard Business School for Harvard's Business Plan Contest in the Business Ventures Track. Vaxess Technologies was a semi-finalist for MIT's $100K Entrepreneurship Competition in the Life Sciences section. In 2012, it won the Harvard President's Challenge in the Global Health section and was awarded $70,000. The company was selected as a finalist for two 2013 MassTLC Awards, Start-Up to Watch and Innovative Technology of the Year: Healthcare/Life Sciences.\n\nIn May 2013, Vaxess received $3.75M in funding from Norwich Ventures and an undisclosed amount of money from angel investor Jeffrey Walker.\n\nIn August 2013, the company announced that it would be moving out of Harvard's Innovation Lab to a new location at LabCentral in Cambridge.\n\nIn December 2013, the Massachusetts Life Sciences Center awarded $1.5M to local startups. Vaxess received $1M of that amount which is the most that the MLSC's Accelerator Loan Program will lend to one organization. Vaxess's CEO Michael Schrader was quoted as saying, \"The $1 million Accelerator loan will enable Vaxess to grow the company’s internal R&D capabilities and deliver heat-stable vaccines to patients around the world even sooner.\"\n\nIn January 2014, co-founder Livio Valenti was named by Forbes's \"30 Under 30\" in Science & Healthcare for his work with Vaxess.\n\nIn February 2014, Vaxess added George Siber, M.D. to their organization as the chair of their Scientific Advisory Board. Previously, Siber served as the EVP and CSO of Wyeth Vaccines. He also played a role in bringing Prevnar to market.\n\nIn April 2014, Vaxess announced that Thomas Monath, MD, and Russell Middaugh, PhD. would join the company's scientific advisory board. Monath being an expert in the field of vaccinology and Middaugh being an expert in the fields of in the fields of biophysical chemistry and pharmaceutical formulation.\n\nIn February 2015, Verizon announced that Vaxess had won one of the $1M Verizon Powerful Answers Awards. Verizon issued approximately $6 million is prizes to 12 different organizations across 4 categories. Vaxess won first place in the Transportation category, above HopOn and Matternet.\n\nIn March 2017, Vaxess announced the receipt of $6M in grants from The Bill and Melinda Gates Foundation to advance both an inactivated polio vaccine as well as a measles-rubella vaccine on the company's MIMIX platform. The grants will fund development of both the MIMIX platform as well as these two specific indications over the next two years.\nVaxess's business plan is based around a technology developed by Tufts University Professors Fiorenzo Omenetto and David Kaplan. The technology uses a silk-derived protein called fibroin to stabilize vaccines so that they can be shipped and stored without refrigeration, eliminating the need for the cold chain. Vaxess is working with vaccine manufacturers to develop heat-stable vaccines and targeting a product launch by 2019.\n"}
{"id": "4220227", "url": "https://en.wikipedia.org/wiki?curid=4220227", "title": "Wahl Clipper", "text": "Wahl Clipper\n\nThe Wahl Clipper Corporation, based in Sterling, Illinois, manufactures grooming products for people and animals.\n\nThe company was founded on the strength of Leo J. Wahl's patent for an electromagnetic hair clipper in 1919. In 1965 Wahl introduced the first vacuum clipper, which allowed a person's hair to be cut without use of a cape.\n\nIn 1967 Wahl produced the first cordless hair clipper using its own rechargeable battery technology. Four years later it started an electronics division with the world's first cordless and rechargeable soldering iron. In 1975 the company released a line of back and foot massagers utilizing the vibrating motor technology used in their hair trimmers. In 1984 Wahl invented the first cordless consumer beard and mustache trimmer. \n\nIn 2001 it patented the first vacuuming consumer beard trimmer, the Trim N Vac. Wahl manufactures its clippers and trimmers in its own factories in Sterling, Illinois; Germany, England, China, and Hungary. \n\nWahl is also a brand of men's trimmers including trimmers for beards, mustaches, goatees, body, and ear / nose & brow. \n\nProducts are sold in over 150 countries worldwide under the brands Wahl, Moser, Lister and more recently Groom Ease. In 2006 Wahl licensed the \"For Dummies\" brand from John Wiley & Sons publishing company and launched the Home Haircutting for Dummies product line.\n\nThe Wahl 'Super Taper' is one the most popular electric razors used by barbers across the world today. Its adjustable blade length makes it very useful in the world of modern barbering with popularity of \"Skin-fades\" and other \"faded\" haircuts. \n\n"}
