{"id": "6151641", "url": "https://en.wikipedia.org/wiki?curid=6151641", "title": "AN/AAQ-26", "text": "AN/AAQ-26\n\nThe AN/AAQ-26 is a second generation infrared detection set manufactured by Raytheon. The infrared detecting set is a high-performance multipurpose thermal imaging sensor, providing long-range navigation, surveillance, and fire control capabilities.\n\nThe AAQ-26 features a second-generation focal plane array, electronic image stabilization, local area processing, and an adaptable interface. Additional features include a dual mode video tracker, a 1553 data bus or discrete controls, and multiple fields of view. Because the system passively detects energy in the far infrared (heat) wavelengths, it avoids the disadvantages of active sensors, such as night vision or radar, minimizing the amount of detectable energy emitted by the aircraft.\n\nThe system replaced the AN/AAQ-17 and is deployed on the AC-130H and the AC-130U gunships; it is designed to support a wide variety of platforms and missions.\n\n\n"}
{"id": "51955375", "url": "https://en.wikipedia.org/wiki?curid=51955375", "title": "Agricultural drone", "text": "Agricultural drone\n\nAn agricultural drone is an unmanned aerial vehicle applied to farming in order to help increase crop production and monitor crop growth. Sensors and digital imaging capabilities can give farmers a richer picture of their fields. This information may prove useful in improving crop yields and farm efficiency.\n\nAgricultural drones let farmers see their fields from the sky. This bird's-eye view can reveal many issues such as irrigation problems, soil variation, and pest and fungal infestations. Multispectral images show a near-infrared view as well as a visual spectrum view. The combination shows the farmer the differences between healthy and unhealthy plants, a difference not always clearly visible to the naked eye. Thus, these views can assist in assessing crop growth and production. \n\nAdditionally, the drone can survey the crops for the farmer periodically to their liking. Weekly, daily, or even hourly, pictures can show the changes in the crops over time, thus showing possible “trouble spots”. Having identified these trouble spots, the farmer can attempt to improve crop management and production.\n\nAs drones entered use in agriculture, the Federal Aviation Administration (FAA) encouraged farmers to use this new technology to monitor their fields. However, with the unexpected boom of agricultural drones, the FAA quickly retracted such encouragement, pending new rules and regulations. With incidents such as drones crashing into crop dusters, it was vital for the FAA and the AFBF (American Farm Bureau Federation) to agree on regulations that would allow the beneficial use of such drones in a safe and efficient manner. Although the American Farm Bureau Federation would like small adjustments to some of the restrictions that have been implemented, they are happy that the agricultural industry can actually use this new machinery without the worry of facing any legal issues. \n\nOther companies might start flying their drones in unregulated areas to survey their competition and get to know the condition of crops and agricultural yield. Such a scenario could lead to compromising vital company secrets. People want to know that they are safe and protected, so the burden doesn’t just fall on the farmer, but on many of those around the farmer, too.\n\nThe use of agricultural drones has ethical and social implications. One benefit is that they are able to monitor and control the use of pesticides properly. This allows minimizing the environmental impact of pesticides. However, drones don't need access authority to flying overs someone's property at under 400 feet (130 m) altitude. They may have microphones and cameras attached, and the resulting concern for potential privacy violation has caused some opposition towards drones.\n\nThere is a lot of room for growth with agricultural drones. With technology constantly improving, imaging of the crops will need to improve as well. With the data that drones record from the crops the farmers are able to analyze their crops and make educated decisions on how to proceed given the accurate crop information. Software programs for analyzing and correcting crop production have the potential to grow in this market. Farmers will fly a drone over their crops, accurately identify an issue in a specific area, and take the necessary actions to correct the problem. This gives the farmer time to focus on the big picture of production instead of spending time surveying their crops. \n\n\n"}
{"id": "309497", "url": "https://en.wikipedia.org/wiki?curid=309497", "title": "Ajeeb", "text": "Ajeeb\n\nAjeeb was a chess-playing \"automaton\", created by Charles Hooper (a cabinet maker), first presented at the Royal Polytechnical Institute in 1868. A particularly intriguing piece of faux mechanical technology (while presented as entirely automated, it in fact concealed a strong human chess player inside), it drew scores of thousands of spectators to its games, the opponents for which included Harry Houdini, Theodore Roosevelt, and O. Henry. The device's name was derived from the Arabic/Urdu/Persian word عجيب (\"ʿajīb\") meaning \"wonderful, marvelous.\"\n\nThe genius behind \"Ajeeb\" were players such as Harry Nelson Pillsbury (1898–1904), Albert Beauregard Hodges, Constant Ferdinand Burille, Charles Moehle, and Charles Francis Barker. The machine also played checkers, matching against figures such as 1920s American champ Sam Gonotsky, who would also direct the machine under the ownership of Hattie Elmore.\n\nIn the history of such devices, it succeeded \"The Turk\" and preceded \"Mephisto\".\n"}
{"id": "40350150", "url": "https://en.wikipedia.org/wiki?curid=40350150", "title": "Akoma Ntoso", "text": "Akoma Ntoso\n\nAkoma Ntoso (\"A\"rchitecture for \"K\"nowledge-\"O\"riented \"M\"anagement of \"A\"frican \"N\"ormative \"T\"exts using \"O\"pen \"S\"tandards and \"O\"ntologies) is an international technical standard for representing executive, legislative and judiciary documents in a structured manner. It is a legal XML vocabulary and it suggests also a naming convention for providing unique identifier to legal sources based on FRBR model.\n\nThe term \"akoma ntoso\" means \"linked hearts\" in the Akan language of West Africa and for this reason it was selected for nominating this legal XML standard. The usual acronym is AKN, to designate the \"XML AKN format\".\n\nAkoma Ntoso started as an UNDESA project within the “Strengthening Parliaments’ Information Systems in Africa” and the core vocabulary was created mostly by two professors from University of Bologna. Later it became the main work package of the activities of the LegalDocML Technical Committee within OASIS. The \"Akoma Ntoso XML schema standard\" \"“defines a ‘machine readable’ set of simple technology-neutral electronic representations (in XML format) of parliamentary, legislative and judiciary documents”\".\n\nAkoma Ntoso is constituted by an XML document schema providing sophisticated description possibilities for several parliamentary, legislative and judiciary document types (including bills, acts and parliamentary records, judgments, gazette, etc.). The work provided the basis for the OASIS Legal XML LegalDocumentML project.\n\nIn 2010 European Parliament developed an open source tool (AT4AM) based on Akoma Ntoso for facilitating the production and the management of amendments. Thanks to this project EU Parliament extended the application to Akoma Ntoso to other documents (e.g., proposal, transcript) and to other scenarios (e.g., translation process).\n\nThe \"United States Legislative Markup\" (USLM) schema for the United States Code (the US codified laws), developed in 2013, and the LexML Brasil XML schema for Brazilian legislative and judiciary documents, developed in 2008, were designed to be consistent with Akoma Ntoso. Akoma Ntoso also was explicitly designed to be compliant with CEN Metalex, one of the other de facto standards besides Akoma Ntoso, which is used in the UK Statute Law Database.\n\nThe United States Library of Congress created the Markup of US Legislation in Akoma Ntoso challenge in July 2013 to create representations of selected US bills using the most recent Akoma Ntoso standard within a couple months for a $5000 prize, and the Legislative XML Data Mapping challenge in September 2013 to produce a data map for US bill XML and UK bill XML to the most recent Akoma Ntoso schema within a couple months for a $10000 prize.\n\nThe National Archives of UK converted all the legislation in AKN in 2014 and the availability of bulk \"moved the UK's ranking from fourth to first, in the 2014 Global Open Data Index, for legislation\". \n\nThe Senate of Italian Republic provides, since July 2016, all the bills in Akoma Ntoso as bulk in open data repository .\n\nThe High-Level Committee on Management (HLCM),part of the United Nations System Chief Executives Board for Coordination, set up a Working Group on Document Standards that approved on April 2017 to adopt Akoma Ntoso as standard for modeling its documentation.\n\nAs official self-description, the standard\n\n\n"}
{"id": "14952843", "url": "https://en.wikipedia.org/wiki?curid=14952843", "title": "Angle of list", "text": "Angle of list\n\nThe angle of list is the degree to which a vessel heels (leans or tilts) to either port or starboard.\n\nA listing vessel is stable and at equilibrium, but the distribution of weight aboard (often caused by uneven loading or flooding) causes it to heel to one side.\n\nBy contrast, roll is the dynamic movement from side to side caused by waves.\n\nIf a listing ship goes beyond the point where a righting moment will keep it afloat, it will capsize and potentially sink.\n\n"}
{"id": "25145023", "url": "https://en.wikipedia.org/wiki?curid=25145023", "title": "Bang snaps", "text": "Bang snaps\n\nBang snaps (also known as \"Devil Bangers\", \"Lil' Splodeys\", Throwdowns, snap-its, poppers, poppies, pop-its, snappers, whip'n pops, Pop Pop Snappers, whipper snappers, fun snaps, party snaps, pop pops , whiz-bangers, cherry poppers, snap'n pops or \"'bangers\"') are a type of small novelty firework sold as a trick noisemaker. \n\nBang snaps consist of a small amount of gravel or coarse sand impregnated with a minute quantity (~0.2 milligrams) of silver fulminate high explosive and twisted in a cigarette paper to produce a shape resembling a cherry. The friction-sensitive silver fulminate detonates when stepped on, ignited, or thrown on a hard surface, producing a sharp salute similar to a cap gun's.\n\nDespite producing a legitimate (albeit tiny) high-explosive detonation, the extremely high mass ratio of gravel to explosive acts as a buffer to ensure that they produce only the audible \"crack\" of the supersonic shockwave; they are incapable of producing physical damage, even when discharged in the hand. The explosion is unable to propel the gravel any distance, which usually falls to the ground, making them safe for use as a children's toy, for which purpose they have been widely sold around the world since the 1950s. They are also a common part of Chinese New Year celebrations.\n\nBang snaps are primarily produced alongside other export fireworks in Brazil, Korea and China and are widely available over the counter at small toy stores and shops specializing in jokes, novelties and magic tricks. The snaps are typically packed in sawdust to prevent them from discharging due to rough handling while in transit.\n\nSome states impose the same age restrictions on purchasing bang snaps as that of permitted fireworks, usually 17 or 18.\n\nIn the UK advertised as fun snaps is sold to people 16 or above.\n\n\n"}
{"id": "22664670", "url": "https://en.wikipedia.org/wiki?curid=22664670", "title": "Barrett Communications", "text": "Barrett Communications\n\nBarrett Communications is a specialist manufacturer and supplier of commercial high frequency (HF), tactical HF and very high frequency (VHF) communications equipment. Its head office for design and manufacturing is located in Perth, Western Australia.\n\nBarrett Communications was founded in 1976. The company steadily grew and began exporting their first commercial HF radios in 1987. The range has been expanded to include transceivers (base, portable and mobile), modems, power supplies, amplifiers, antennas and accessories.\nIn May 2009, Barrett Communication acquired Q-MAC Electronics which increased the Barrett Communications product range to include VHF radio systems.\nIn August 2011, Barrett Communications received certification from the Joint Interoperability Test Command (JITC) for its Barrett 2050 HF mobile and base station transceiver.\nThis certification includes conformance to MIL-STD-188-141B as well as the Automatic Link Establishment (ALE) specifications of MIL-STD-188-141B Appendix A.\nIn 2012 Barrett Communications exports to over 150 countries with a global dealer network in 65 countries.\nThe company maintains a quality assurance system, covering both design and manufacturing approved to ISO 9001: 2008.\nBarrett Communications also operates a marketing office in the United Kingdom. Barrett Europe Limited, a wholly owned subsidiary of Barrett Communications, is located in Whiteley in Hampshire.\nNVIS Communications/Barrett Consulting Division is North American Systems Integrator for Barrett Communications in USA and Canada\n\nBarrett Communications designs and manufactures a range of HF communications equipment for commercial and tactical use. The range includes transceivers (base, portable and mobile), modems, power supplies, amplifiers, antennas and accessories. Barrett’s range of HF communications equipment ranges from basic voice communication to data, email, fax and GPS tracking.\n\nBarrett’s PRC-2090 tactical radio meets MIL-STD 180G, FED-STD 1045 / MIL-STD 188-141B ALE (JITC certifiable) and AS-NZS 4770:200.\n\nBarrett Communications designs and manufactures a range of VHF, communications equipment specifically for tactical use. The range known as the Barrett PRC-2080 Tactical VHF radio system includes VHF 30 to 88 MHz squad, brigade, base and mobile transceivers and rebroadcast units. This equipment provides digital voice, encryption, frequency hopping, data, positional awareness and rebroadcast capability.\n\n"}
{"id": "16105212", "url": "https://en.wikipedia.org/wiki?curid=16105212", "title": "Battery electric vehicle", "text": "Battery electric vehicle\n\nA battery electric vehicle (BEV), pure electric vehicle or all-electric vehicle is a type of electric vehicle (EV) that uses chemical energy stored in rechargeable battery packs. BEVs use electric motors and motor controllers instead of internal combustion engines (ICEs) for propulsion. They derive all power from battery packs and thus have no internal combustion engine, fuel cell, or fuel tank. BEVs include - but are not limited to - motorcycles, bicycles, scooters, skateboards, rail cars, watercraft, forklifts, buses, trucks, and cars.\n\nIn 2016 there were 210 million electric bikes worldwide used daily. Cumulative global sales of highway-capable light-duty pure electric car vehicles passed the one million unit milestone in September 2016. , the world's top selling highway legal all-electric car in history is the Nissan Leaf with global sales of over 300,000 units, followed by the Tesla Model S with more than 200,000 units delivered worldwide.\n\nVehicles using both electric motors and internal combustion engines are examples of hybrid electric vehicles, and are not considered pure or all-electric vehicles because they cannot be externally charged (operate in charge-sustaining mode) and instead they are continually recharged with power from the internal combustion engine and regenerative braking.\n\nHybrid vehicles with batteries that can be charged externally to displace some or all of their internal combustion engine power and gasoline fuel are called plug-in hybrid electric vehicles (PHEV), and run as BEVs during their charge-depleting mode. PHEVs with a series powertrain are also called range-extended electric vehicles (REEVs), such as the Chevrolet Volt and Fisker Karma.\n\nPlug-in electric vehicles (PEVs) are a subcategory of electric vehicles that includes battery electric vehicles (BEVs), plug-in hybrid vehicles, (PHEVs), and electric vehicle conversions of hybrid electric vehicles and conventional internal combustion engine vehicles.\n\nIn China, plug-in electric vehicles, together with hybrid electric vehicles are called new energy vehicles (NEVs). However, in the United States, neighborhood electric vehicles (NEVs) are battery electric vehicles that are legally limited to roads with posted speed limits no higher than 45 miles per hour (72 km/h), are usually built to have a top speed of 30 miles per hour (48 km/h), and have a maximum loaded weight of 3,000 lbs.\n\nThe concept of battery electric vehicles is to use charged batteries on board vehicles for propulsion. Battery electric cars are becoming more and more attractive with the advancement of new battery technology (Lithium Ion) that have higher power and energy density (i.e., greater possible acceleration and more range with fewer batteries) and higher oil prices.\n\nBEVs include automobiles, light trucks, and neighborhood electric vehicles.\n\n\nChattanooga, Tennessee operates nine zero-fare electric buses, which have been in operation since 1992 and have carried 11.3 million passengers and covered a distance of , they were made locally by Advanced Vehicle Systems. Two of these buses were used for the 1996 Summer Olympics in Atlanta.\n\nBeginning in the summer of 2000, Hong Kong Airport began operating a 16-passenger Mitsubishi Rosa electric shuttle bus, and in the fall of 2000, New York City began testing a 66-passenger battery-powered school bus, an all-electric version of the Blue Bird TC/2000. A similar bus was operated in Napa Valley, California for 14 months ending in April, 2004.\n\nThe 2008 Beijing Olympics used a fleet of 50 electric buses, which have a range of with the air conditioning on. They use Lithium-ion batteries, and consume about . The buses were designed by the Beijing Institute of Technology and built by the Jinghua Coach. The batteries are replaced with fully charged ones at the recharging station to allow 24-hour operation of the buses.\n\nIn France, the electric bus phenomenon is in development, but some buses are already operating in numerous cities. PVI, a medium-sized company located in the Paris region, is one of the leaders of the market with its brand Gepebus (offering Oreos 2X and Oreos 4X).\n\nIn the United States, the first battery-electric, fast-charge bus has been in operation in Pomona, California since September 2010 at Foothill Transit. The Proterra EcoRide BE35 uses lithium-titanate batteries and is able to fast-charge in less than 10 minutes.\n\nIn 2014, the first production model all-electric school bus was delivered to the Kings Canyon Unified School District in California’s San Joaquin Valley. The bus was one of four the district ordered. This battery electric school bus, which has 4 sodium nickel batteries, is the first modern electric school bus approved for student transportation by any state.\nThe same technology is used to power the Mountain View Community Shuttles. This technology was supported by the California Energy Commission, and the shuttle program is being supported by Google.\n\nThunder Sky (based in Hong Kong) builds lithium-ion batteries used in submarines and has three models of electric buses, the 10/21 passenger EV-6700 with a range of under 20 mins quick-charge, the EV-2009 city buses, and the 43 passenger EV-2008 highway bus, which has a range of under quick-charge (20 mins to 80 percent), and under full charge (25 mins). The buses will also be built in the United States and Finland.\n\nTindo is an all-electric bus from Adelaide, Australia. The Tindo (aboriginal word for sun) is made by Designline International in New Zealand and gets its electricity from a solar PV system on Adelaide's central bus station. Rides are zero-fare as part of Adelaide's public transport system.\n\nProterra's EcoRide BE35 transit bus, called the Ecoliner by Foothill Transit in West Covina, California, is a heavy duty, fast charge, battery-electric bus. Proterra's ProDrive drive-system uses a UQM motor and regenerative braking that captures 90 percent of the available energy and returns it to the TerraVolt energy storage system, which in turn increases the total distance the bus can drive by 31–35 percent. It can travel 30–40 miles on a single charge, is up to 600 percent more fuel-efficient than a typical diesel or CNG bus, and produces 44 percent less carbon than CNG.\n\nFor most of the 20th century, the majority of the world's battery electric road vehicles were British milk floats. The 21st century saw the massive development of BYD electric trucks.\n\nIn March 2012, Smith Electric Vehicles announced the release of the Newton Step-Van, an all-electric, zero-emission vehicle built on the versatile Newton platform that features a walk-in body produced by Indiana-based Utilimaster.\n\nBYD supplies DHL with electric distribution fleet of commercial BYD T3.\n\nA battery-powered electric car is an automobile which is propelled by electric motors.\n\nAlthough electric cars often give good acceleration and have generally acceptable top speed, the lower specific energy of production batteries available in 2015 compared with carbon-based fuels means that electric cars need batteries that are fairly large fraction of the vehicle mass but still often give relatively low range between charges. Recharging can also take significant lengths of time. For journeys within a single battery charge, rather than long journeys, electric cars are practical forms of transportation and can be recharged overnight.\n\nElectric cars have the potential of significantly reducing city pollution by having zero tail pipe emissions.\nVehicle greenhouse gas savings depend on how the electricity is generated. With the current US energy mix, using an electric car would result in a 30 percent reduction in carbon dioxide emissions.\nGiven the current energy mixes in other countries, it has been predicted that such emissions would decrease by 40 percent in the UK, 19 percent in China, and as little as 1 percent in Germany.\n\nElectric cars are expected to have a major impact in the auto industry given advantages in city pollution, less dependence on oil, and expected rise in gasoline prices. World governments are pledging billions to fund development of electric vehicles and their components. The US has pledged in federal grants for electric cars and batteries. China has announced it will provide to initiate an electric car industry.\n\nIn 2015, it was the first time BYD also ranked first in accumulated global sales throughout an entire year – with a total of over 43,073 NEVs sold (a >220% surge compared to last year), exceeding all American, Japanese and European leaders to date. \n\nCumulative global sales of highway-capable battery electric cars and vans passed the 1 million unit milestone in September 2016. The Renault-Nissan Alliance is the leading all-electric vehicle manufacturer. The Alliance achieved the sales milestone of 350,000 all-electric vehicles delivered globally in August 2016. Ranking second is Tesla Motors with over 139,000 electric cars sold between 2008 and June 2016.\n\n, the world's top selling highway capable all-electric car in history is the Nissan Leaf, released in December 2010, with global sales of more than 250,000 units, followed by the Tesla Model S with more than 158,000 units delivered worldwide. Ranking next are the BMW i with about 65,500 units, and the Renault Zoe with 61,205 units, both through December 2016. Until June 2016 the Mitsubishi i-MiEV family ranked fifth with about 37,600 units delivered globally. The Renault Kangoo Z.E. utility van is the leader of the light-duty all-electric segment with global sales of 25,205 units through December 2016.\n\nFormula E is a fully electric international single seater championship. The series was conceived in 2012, and the inaugural championship started in Beijing on 13 September 2014. The series is sanctioned by the FIA. Alejandro Agag is the current CEO of Formula E.\n\nThe Formula E championship is currently contested by ten teams with two drivers each (after the withdrawal of Team Trulli, there are temporarily only nine teams competing). Racing generally takes place on temporary city-center street circuits which are approximately 2 to 3.4 km (1.2 to 2.1 mi) long. Currently, only the Mexico City ePrix takes place on a road course, a modified version of the Autódromo Hermanos Rodríguez.\nElectric vehicles produce no GHG emissions, at the tailpipe.\nSo they are considered 'green' because they have no emissions in the place where they are used.\nHowever, battery electric vehicles can be considered Zero emission engines only locally, because they generally produce GHG in the power plants where electricity is generated. \nThe two factors driving these GHG emissions of Battery Electric Vehicles are:\nThe Carbon Intensity of electricity can largely vary, depending on the electricity mix of the geographic region where electricity is consumed (a Country with high shares of renewables in his electricity mix will have a low C.I.).\nIn the European Union, in 2013, the Carbon Intensity had a strong geographic variability, but in almost all the Member States Electric vehicles were \"greener\" than conventional ones. On average, Electric car saved 50%-60% of CO2 emissions compared to diesel and gasoline fuelled engines. \nMoreover, the de-carbonisation process is constantly reducing the GHG emissions due to the use of Electric Vehicles. In the European Union, on average, between 2009 and 2013 there was a reduction of the electricity Carbon Intensity of 17%. In a Life-cycle assessment perspective, considering the GHG necessary to build the battery and its end-of-life, the GHG savings are 10-13% lower.\n\nSpecial-purpose vehicles come in a wide range of types, ranging from relatively common ones such as golf carts, things like electric golf trolleys, milk floats, all-terrain vehicles, neighborhood electric vehicles, and a wide range of other devices. Certain manufacturers specialize in electric-powered \"in plant\" work machines.\n\nThree-wheeled vehicles include electric rickshaws, a powered variant of the cycle rickshaw.\nThe large-scale adoption of electric two-wheelers can reduce traffic noise and road congestion but may necessitate adaptations of the existing urban infrastructure and safety regulations.\n\nFrom India, AVERA new and renewable energy company is going to launch two models of electric scooters at the end of 2018, with Lithium Iron Phosphate Battery technology.\n\nChina has experienced an explosive growth of sales of non-assisted e-bikes including scooter type, with annual sales jumping from 56,000 units in 1998 to over 21 million in 2008, and reaching an estimated 120 million e-bikes on the road in early 2010. China is the world's leading manufacturer of e-bikes, with 22.2 million units produced in 2009. Some of the biggest manufacturers of E-bikes in the world are BYD, Geoby.\n\nAn increasing variety of personal transporters are being manufactured, including the one-wheeled self-balancing unicycles, self-balancing scooters, electric kick scooters, and electric skateboards.\n\nSeveral battery electric ships operate throughout the world, some for business. Electric ferries are being operated and constructed.\n\nThe motor controller receives a signal from potentiometers linked to the accelerator pedal, and it uses this signal to determine how much electric power is needed. This DC power is supplied by the battery pack, and the controller regulates the power to the motor, supplying either variable pulse width DC or variable frequency variable amplitude AC, depending on the motor type. The controller also handles regenerative braking, whereby electrical power is gathered as the vehicle slows down and this power recharges the battery. In addition to power and motor management, the controller performs various safety checks such as anomaly detection, functional safety tests and failure diagnostics.\nMost electric vehicles today use an electric battery, consisting of electrochemical cells with external connections in order to provide power to the vehicle. \n\nBattery technology for EVs has developed from early lead-acid batteries used in the late 19th Century to the 2010s, to lithium-ion batteries which are found in most EVs today. The overall battery is referred to as a battery pack, which is a group of multiple battery modules and cells. The battery pack powering modern EVs can have as little as 96 battery cells to as many as 2,976 cells.\n\nElectric cars have traditionally used series wound DC motors, a form of brushed DC electric motor. Separately excited and permanent magnet are just two of the types of DC motors available. More recent electric vehicles have made use of a variety of AC motor types, as these are simpler to build and have no brushes that can wear out. These are usually induction motors or brushless AC electric motors which use permanent magnets. There are several variations of the permanent magnet motor which offer simpler drive schemes and/or lower cost including the brushless DC electric motor.\n\nOnce electric power is supplied to the motor (from the controller), the magnetic field interaction inside the motor will turn the drive shaft and ultimately the vehicle's wheels.\n\n\n\n\n\n\n"}
{"id": "431310", "url": "https://en.wikipedia.org/wiki?curid=431310", "title": "Chemical engineer", "text": "Chemical engineer\n\nIn the field of engineering, a chemical engineer is a professional, who is equipped with the knowledge of chemical engineering, works principally in the chemical industry to convert basic raw materials into a variety of products, and deals with the design and operation of plants and equipment. In general, a chemical engineer is one who applies and uses principles of chemical engineering in any of its various practical applications; these often include 1) design, manufacture, and operation of plants and machinery in industrial chemical and related processes (\"chemical process engineers\"); 2) development of new or adapted substances for products ranging from foods and beverages to cosmetics to cleaners to pharmaceutical ingredients, among many other products (\"chemical product engineers\"); and 3) development of new technologies such as fuel cells, hydrogen power and nanotechnology, as well as working in fields wholly or partially derived from chemical engineering such as materials science, polymer engineering, and biomedical engineering.\n\nThe president of the Institution of Chemical Engineers said in his presidential address \"I believe most of us would be willing to regard Edward Charles Howard (1774–1816) as the first chemical engineer of any eminence\". Others have suggested Johann Rudolf Glauber (1604–1670) for his development of processes for the manufacture of the major industrial acids.\n\nThe term appeared in print in 1839, though from the context it suggests a person with mechanical engineering knowledge working in the chemical industry. \nIn 1880, George E. Davis wrote in a letter to \"Chemical News\" \"A Chemical Engineer is a person who possesses chemical and mechanical knowledge, and who applies that knowledge to the utilisation, on a manufacturing scale, of chemical action.\" He proposed the name Society of Chemical Engineers, for what was in fact constituted as the Society of Chemical Industry. At the first General Meeting of the Society in 1882, some 15 of the 300 members described themselves as chemical engineers, but the Society's formation of a Chemical Engineering Group in 1918 attracted about 400 members.\n\nIn 1905 a publication called \"The Chemical Engineer\" was founded in the US, and in 1908 the American Institute of Chemical Engineers was established.\n\nIn 1924 the Institution of Chemical Engineers adopted the following definition: \"A chemical engineer is a professional man experienced in the design, construction and operation of plant and works in which matter undergoes a change of state and composition.\"\n\nAs can be seen from the later definition, the occupation is not limited to the chemical industry, but more generally the process industries, or other situations in which complex physical and/or chemical processes are to be managed.\n\nThe UK journal \"The Chemical Engineer\" (began 1956) has a series of biographies available online entitled “Chemical Engineers who Changed the World”,\n\nHistorically, the chemical engineer has been primarily concerned with process engineering, which can generally be divided into two complementary areas: chemical reaction engineering and separation processes. The modern discipline of chemical engineering, however, encompasses much more than just process engineering. Chemical engineers are now engaged in the development and production of a diverse range of products, as well as in commodity and specialty chemicals. These products include high-performance materials needed for aerospace, automotive, biomedical, electronic, environmental and military applications. Examples include ultra-strong fibers, fabrics, adhesives and composites for vehicles, bio-compatible materials for implants and prosthetics, gels for medical applications, pharmaceuticals, and films with special dielectric, optical or spectroscopic properties for opto-electronic devices. Additionally, chemical engineering is often intertwined with biology and biomedical engineering. Many chemical engineers work on biological projects such as understanding biopolymers (proteins) and mapping the human genome.\n\nAccording to a 2015 salary survey by the AIChE, the median annual salary for a chemical engineer was approximately $127,000. In the UK, the IChemE 2016 Salary Survey reported a median salary of approximately £57,000, with a starting salary for a graduate averaging £28,350. Chemical engineering in the USA is one of the engineering disciplines with the highest participation of women, with 35% of students compared with 20% in engineering. In the UK in 2014, students starting degrees were 25% female, compared with 15% in engineering. US graduates who responded to a 2015 salary survey were 18.8% female.\n\n\n"}
{"id": "15378707", "url": "https://en.wikipedia.org/wiki?curid=15378707", "title": "Coat rack", "text": "Coat rack\n\nCoat rack, coat stand or a hatstand is an item of furniture on which clothes may be hung. A coat rack often refers to a set of hooks that are attached to a wall and is mainly used to hang coats and jackets. In a kitchen or bathroom environment the coat rack is often used to hang towels. In some cases, a coat rack refers to a self-standing piece of furniture. The self-standing variant is more often referred to as an hatstand and is mostly used to hang coats, jackets, umbrellas and hats.\n\n"}
{"id": "356415", "url": "https://en.wikipedia.org/wiki?curid=356415", "title": "Computer-aided maintenance", "text": "Computer-aided maintenance\n\nComputer-aided maintenance (not to be confused with CAM which usually stands for Computer Aided Manufacturing) refers to systems that utilize software to organize planning, scheduling and support of maintenance and repair. A common application of such systems is the maintenance of computers, either hardware or software, themselves. It can also apply to the maintenance of other complex systems that require periodic maintenance, such as reminding operators that preventive maintenance is due or even predicting when such maintenance should be performed based on recorded past experience.\n\nThe first computer-aided maintenance software came from DEC in the 1980s to configure VAX computers. The software was built using the techniques of artificial intelligence expert systems, because the problem of configuring a VAX required expert knowledge. During the research, the software was called \"R1\" and was renamed \"XCON\" when placed in service. Fundamentally, \"XCON\" was a rule-based \"configuration database\" written as an expert system using forward chaining rules. As one of the first expert systems to be pressed into commercial service it created high expectations, which did not materialize, as DEC lost commercial pre-eminence. \n\nHelp desks frequently use help desk software that captures symptoms of a bug and relates them to fixes, in a \"fix database\". One of the problems with this approach is that the understanding of the problem is embodied in a non-human way, so that solutions are not unified.\n\n"}
{"id": "8555091", "url": "https://en.wikipedia.org/wiki?curid=8555091", "title": "Copper(II) azide", "text": "Copper(II) azide\n\nCopper(II) azide is a medium density explosive with the molecular formula Cu(N).\n\nCopper azide is very explosive and is too sensitive for any practical use unless handled in solution.\n\nCopper azide can be prepared by a metathesis reaction between water-soluble sources of Cu and azide ions. (Spectator ions omitted in reaction below).\n\nIt can be destroyed by concentrated nitric acid to form non-explosive products, being nitrogen, nitrogen oxides and copper(II) nitrate.\n"}
{"id": "38854584", "url": "https://en.wikipedia.org/wiki?curid=38854584", "title": "Cosmetovigilance", "text": "Cosmetovigilance\n\nCosmetovigilance is the ongoing and systematic monitoring of the safety of cosmetics in terms of human health. The aim is to detect adverse effects of cosmetic products, and to prevent adverse effects by taking appropriate measures. Regulations for cosmetic products primarily address the safety of products that may be used by large populations of healthy consumers. The identification and analysis of adverse effects related to cosmetic products is a process that is currently still, to a large extent, industry driven. It is the responsibility of manufacturers to determine that products and ingredients are safe before they are marketed, and then to collect reports of adverse reactions.\n\nThe legal basis for monitoring cosmetics in the U.S.A. is The Federal Food, Drug, and Cosmetic Act (FD&C Act), which defines cosmetics by their intended use, as “articles intended to be rubbed, poured, sprinkled, or sprayed on, introduced into, or otherwise applied to the human body...for cleansing, beautifying, promoting attractiveness, or altering the appearance”. Among the products included in this definition are skin moisturizers, perfumes, lipsticks, fingernail polishes, eye and facial makeup preparations, shampoos, permanent waves, hair colors, toothpastes, and deodorants, as well as any material intended for use as a component of a cosmetic product.\n\nIn the US, state regulation applies in addition to federal regulation. For example, California's governor Arnold Schwarzenegger signed off fiercely contested toxics legislation that requires cosmetic producers to report use of ingredients classified as carcinogenic or toxic to reproduction, a measure primarily aimed at phthalates.\nThe legal basis for monitoring cosmetics in the European Union is derived from Cosmetics Directive 76/768/EEC. This 1976 directive requires that cosmetic products 'must not cause damage to human health when applied under normal or reasonably foreseeable conditions of use'. The safety officer of a company with marketed cosmetics files product information, including a safety report, in electronic or other format to the competent authority of the Member State. This takes place after placing cosmetic products on the market, with updates by state requirement.\n\nThe practical consequence of cosmetics legislation is a requirement for continuous observation of cosmetic products after marketing. This applies particularly to \"adverse effects\" and \"serious adverse effects\". The European legislation defines \"adverse effect\" as a negative impact on human health, which is attributable to the normal or reasonably foreseeable use of a cosmetic product. A \"serious adverse effect\" resulting in temporary or permanent functional incapacity, disability, hospitalization, congenital anomalies or an immediate danger to life or death.\n\n"}
{"id": "33945321", "url": "https://en.wikipedia.org/wiki?curid=33945321", "title": "Cultural probe", "text": "Cultural probe\n\nCultural probes (or design probes) is a technique used to inspire ideas in a design process. It serves as a means of gathering inspirational data about people's lives, values and thoughts. The probes are small packages that can include any sort of artifact (like a map, postcard, camera or diary) along with evocative tasks, which are given to participants to allow them to record specific events, feelings or interactions. The aim is to elicit inspirational responses from people, in order to understand their culture, thoughts and values better, and thus stimulate designer's imaginations.Probes is one of the prominent approaches in the practice of co-designing. It is design-led approaches as described by the landscape of design research and practice. probes are usually used in the early front end of the design process. The probes were not designed to be analyzed, nor did we summarize what they revealed about the sites as an explicit stage in the process. Rather, the design proposals we produced reflected what we learned from the materials.Furthermore, probes were born to gather “fragmentary clues” about people’s “lives and thoughts” which means they are tools to inspire - others argue that they can be used to, provide relevant information and gather empathetic data.\n\nCultural Probes was developed by Gaver, Dunne and Pacenti in 1999. They were inspired by the art movement Situationist International. \nThis technique does not follow the scientific approach. It follows the artistic approach, which is characterized by being irrational, uncontrolled, getting inspiration, and cannot be analysed systematically. As Gaver pointed out , the conceptual concerns and specific techniques of various arts movements also influenced their probes design.\n\nCultural probes can be used for idea generation, inspiration, values and dreams in a design process. \nThe technique is about opening up the design space, instead of narrowing it. Cultural probes aim to seek out subjective thoughts, values and dreams and surprise and uncertainty is a key value.\nThe probes provoke inspirational responses by using a creative approach in questions instead of analytical and descriptive question usually asked in User Experience Research.Cultural Probe kit is a vehicle for self-reporting by asking participants to observe, reflect upon and report their experiences which can lead to have better and deeper observation in a context where, due to privacy as well as time constraints, it is not possible to conduct full participant observations.\n\nSince the initial publication in 1999 of cultural probes in interactions, the use of probes has been interpreted broadly and used in a wide variety of projects within user experience. Some cases are grounded very much in the original cultural probes work, while, in other cases, ‘probes’ has become an umbrella term covering everything from Diary Studies to longitudinal user studies to field trips.\n\nIn the traditional design process, designers usually engage in making after the design opportunity has already been identified. Over the last 10 years, we have seen the focus shift to more varied forms and formats of making in the front end of the process. Today making has become an activity that both designers and co-designers can engage in during all phases of the process. Cultural probe is one of these making approaches, which is used in the very earliest phase of the design process, the focus is on using making activities for making sense of the future. \n\nSince Bill Gaver and his colleagues developed ‘Cultural Probes’, they have been adopted and adapted. Here are some probes which are derived from Cultural Probes; Informational Probes, Technology Probes, Mobile Probes, Empathy Probes, Domestic Probes, Urban Probes, Reflective Probes, Primitive Probes. Each kinds of Probes bring users to account to members differently: for example, probes that log everyday actions do this quite differently from those that require describing dreams. Each makes different forms of action and interaction visible and in different ways. Most forms of Probes involve investigative participation. Participants engage in reflective participation – both in the standard sociological sense of becoming aware of actions and interactions and describing them in some way, and in the methodological sense of making actions accountable. However, there is also evidence of different forms of participation. Cultural Probes emphasis imaginative and playful participation, engaging participants in activities that promote the use of aspects of their lives that are more “ludic’ and less goal-driven. Empathy Probes emphasis emotional participation, seeking out participants’ effective responses both to things in their everyday lives and new technologies. Both Technology Probes and Mobile Probes emphasis reactive participation and, to some extent, a change in participation or disruptive participation. Participants have to react to these new technologies placed in their lives and to the disruption to their existing routines that they enforce. \nProbing will add strong element of making to the research which is based on literature and practical work. It is difficult to create a precise pattern of the design process for probes. \"The problem and the solution go hand in hand, and there is no single answer or method for analyses the probe materials. An inspiring idea about things such as the overall appearance of the probe, a single probe article or a visual detail can tune up the probe design along with a consistent approach to the problem. Although the methodological instructions can in principle be taken to the extreme, the outcome finally depends on the agents, i.e., researchers, designers and even users in the case of probes. Practical instructions are helpful, but somebody conducting research must personally be tuned-in to receive signals, interpret them and be surprised at them, as well as tolerate the ambiguous nature of the probing process (and design)\".\n\n\n"}
{"id": "30483138", "url": "https://en.wikipedia.org/wiki?curid=30483138", "title": "Cutting ring fitting", "text": "Cutting ring fitting\n\nCutting ring fittings are flareless fittings used for connections in fluid applications. They are widely used worldwide in hydraulic systems.\n\nThe cutting ring fitting consists of the body, the cutting ring and the nut. On assembly, the two cutting edges of the cutting ring carves into the outer surface of the tube hence ensuring the necessary holding power and sealing for high operating pressures. The tubes have usually metric dimensions.\n\nThe cutting ring fitting was invented by Ermeto in Germany in the early 1930s. Later Parker Hannifin acquired Ermeto and introduced the fittings to the US. Today they are standardized in ISO 8434.\n\n"}
{"id": "18581645", "url": "https://en.wikipedia.org/wiki?curid=18581645", "title": "Digital television transition", "text": "Digital television transition\n\nThe digital television transition, also called the digital switchover, the analog switch-off (ASO), or the analog shutdown, is the process in which older analog television broadcasting is converted to and replaced by digital television. This primarily involves the conversion of analog terrestrial television to digital terrestrial. However, it also involves analog cable conversion to digital cable or internet protocol television, as well as analog to digital satellite television. Begun by some countries around 2000, this is an involved process because the existing analog television receivers owned by viewers cannot receive digital broadcasts; viewers must either purchase new digital TVs, or converter boxes which change the digital signal to an analog signal which can be viewed on the old TV.\n\nIn many countries, a simulcast service is operated where a broadcast is made available to viewers in both analog and digital at the same time. As digital becomes more popular, it is likely that the existing analog services will be removed. In some cases this has already happened, where a broadcaster has offered incentives to viewers to encourage them to switch to digital. In other cases government policies have been introduced to encourage or force the switchover process, especially with regard to terrestrial broadcasts. Government intervention usually involves providing some funding for broadcasters and, in some cases, monetary relief to viewers, to enable a switchover to happen by a given deadline.\n\nThe switchover process is being accomplished on different schedules in different countries; in some countries it is being implemented in stages as in Australia, Brazil, India, Mexico, and the United Kingdom, where each region has a separate date to switch off. In others, the whole country switches on one date, such as the Netherlands, which switched off its analog terrestrial services on 11 December 2006. On 3 August 2003, Berlin became the world's first city to switch off terrestrial analogue signals. Luxembourg was the first country to complete its terrestrial switchover, in September 2006. Technically the United Kingdom and Ireland were the first countries that turned off analogue signals - in the form of satellite television on 28 September 2001 - but terrestrial signals in the two countries were not switched until 2012.\n\n\nThe Geneva 2006 Agreement set 17 June 2015 as the date after which countries may use frequencies currently assigned for analog television transmission for digital services, without being required to protect the analog services of neighbouring countries against interference. This date was generally viewed as an internationally mandated analog switch-off date, at least along national borders. The European Commission has recommended that digital switchover should be completed by 1 January 2012 - Commission Recommendation 2009/848/EC, of 28 October 2009.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfter the switch from analog to digital broadcasts is complete, analog TVs will be incapable of receiving over-the-air broadcasts without the addition of a set-top converter box. Consequently, a digital converter box – an electronic device that connects to an analog television – must be used in order to allow the television to receive digital broadcasts. In the United States, the government subsidized the purchase of such boxes for consumers via their coupon-eligible converter box program in 2009, funded by a small part of the billions of dollars brought in by a spectrum auction. The program was managed by the Department of Commerce through its National Telecommunications and Information Administration.\n\n\n"}
{"id": "45542869", "url": "https://en.wikipedia.org/wiki?curid=45542869", "title": "Dry Creek explosives depot", "text": "Dry Creek explosives depot\n\nThe Dry Creek explosives depot was a secure storage facility near Port Adelaide from 1906 to 1995, serving the construction, mining and quarrying industries of South Australia, as well as the mines of Broken Hill in New South Wales.\n\nThe ten magazines of the Dry Creek explosives depot were built in 1906 at the expenditure of £6,000 or £7,000 at Broad Creek, a tidal distributary channel on the eastern side of the Barker Inlet of the Port River Estuary, which runs in the direction of the suburb of Dry Creek. The Broad Creek site, located on the landward side of intertidal mangroves and supratidal saltmarshes, was chosen as a more isolated location from Port Adelaide, replacing an earlier explosives depot called North Arm Powder Magazine at Magazine Creek at Gillman, south of the North Arm of the Port River.\n\nA narrow gauge tramway with a track gauge of was constructed in 1906. It ran along the magazines and connected the depot via a length of 2 km (1¼ miles) to the landing jetty and on the other side via 800 m (½ mile) to the Dry Creek railway station. Six bespoke wagons were used for the transport of explosives such as dynamite to the magazines - each held 1¼ tons. The wagons were drawn by horses. Previously, explosives had to be transported by road from the North Arm to the magazines, and this both dangerous and expensive. The wagons were donated in 1978 to the Illawarra Light Railway Museum, where they are now exhibited.\n\nThe president of the Marine Board, Arthur Searcy, and four wardens officially inspected the Dry Creek explosives depot on Tuesday, 19 June 1906. They were conveyed to the Broad Creek jetty in the motor launch \"Warden\". The party travelled on one of the horse-drawn wagons to the magazines, which were found in perfect order. Each magazine was capable of storing 40 tons of explosives, but 20 tons were at that time fixed as the maximum quantity to be stored in them. Every precaution was taken to guard against explosion, and printed regulations were exhibited on each of the magazine doors. Mounds had been built between each magazine, so that should one of the magazines explode no injury would result to the others. The party was quite satisfied that the system for the handling and storage of explosives was superior in every respect to the one formerly in use. The magazine reserve, which consisted of about 307 acres, was being improved, by the planting of tamarisk and other trees to provide shadow and explosion breaks.\n\nLimewash was normally applied to magazines' exterior walls. Care was taken to minimise and isolate the explosives from damp, heat and grit. The magazine structures incorporated insulated walls and were designed to create a naturally and reasonably cooled and ventilated environment. Their ventilation shafts were covered by metal ventilation louvers, coupled with spark arrestors and dust deflectors.\n\nThe king tides regularly flooded the estuarine plain. Consequently, the tramline along the mangroves from the magazines to the jetty at Broad Creek was frequently damaged. In July, 1917, the jetty was inundated by the highest tide on record up to that date, 3.6 m above low water, and was washed away. The following August an unusually high tide washed away the gear of the levee workmen, including planks, barrels, barricades and bags of silt, which disappeared without a trace.\n\nBy 1925 explosives were delivered from Deer Park, Victoria less frequently but in larger batches. Therefore, less explosives were delivered via the jetty, the number of daily paid stevedores declined and the turnover was reduced.\n\nBy 1934, shipworm and lack of preventive maintenance had materially weakened the wooden structures. From 1934 explosives were railed from Victoria directly to the Dry Creek explosives depot. By 1947 all explosives were delivered this way. In 1950 urgent safety relevant repairs were ordered, but were not conducted until September 1952. Decreasing revenue from the port trade led to lessened maintenance and dredging of the Broad Creek landing. The jetty was last used in February 1970 and demolished about 1976.\n\nAs waterborne trade decreased, land transport of explosives was coupled to technological progress in the explosive usage. From early 1978 ammonium nitrate came into fashion as an ingredient of explosives mixtures that could be prepared on-site. This resulted in further safety refinements, and diffusion of responsibility for explosive storage. This eliminated much of the previously needed inspection, sampling and storage.\n\nThe operation of the site ceased in October 1995. Eleven of the historic buildings at Dry Creek, which were built from 1903 to 1907, are still in place and were listed on the South Australian Heritage Register on 15 December 1994 as No. 14521. Their condition was generally sound as of the year 2000, but the reinforcement bars of hollow concrete piles, which were installed instead of jarrah piles in the 1960s, are so corroded by the saline soil that the long term stability is under threat. Remains of the wharf once used to unload explosives and the narrow gauge railway line are still visible on the seawards side of the salt pans, if Broad Creek is entered by a canoe.\n"}
{"id": "21052955", "url": "https://en.wikipedia.org/wiki?curid=21052955", "title": "Ejection charge", "text": "Ejection charge\n\nEjection charge, also called expelling charge, is a pyrotechnic composition, a type of a pyrotechnic gas generator designed to produce a small short-term amount of thrust to burst open a container and eject its content. \n\nIn model rocketry, ejection charges are used to deploy a recovery system (usually parachute or streamer). The ejection charge is ignited through a layer of delay composition, to fire shortly after the main engine burns out. Ejection charges can be also triggered by a timer or an altimeter. A small amount of black powder is usually used, but smokeless powder and other compositions are possible.\n\nEjection charges are also used in some flares to eject the light or smoke producing components out of the flare casing. In countermeasure flares, ejection charges are used to propel the flares out of their casing, or to eject pyrophoric fluids from their containers.\n\nIn cluster bombs, ejection charges are used to disperse the submunitions.\n\nBurst charges are also used to dispense leaflets from leaflet bombs.\n\nIn chemical weapons, ejection charges are used to disperse the chemical agent from the bomb, submunition, grenade, or warhead. \n\n"}
{"id": "3335817", "url": "https://en.wikipedia.org/wiki?curid=3335817", "title": "Electronic trading", "text": "Electronic trading\n\nElectronic or scripless trading, sometimes called e-trading or paperless trading is a method of trading securities (such as stocks, and bonds), foreign exchange or financial derivatives electronically. Information technology is used to bring together buyers and sellers through an electronic trading platform and network to create virtual market places. They can include various exchange-based systems, such as NASDAQ, NYSE Arca and Globex, as well as other types of trading platforms, such as electronic communication networks (ECNs), alternative trading systems, crossing networks and \"dark pools\". Electronic trading is rapidly replacing human trading in global securities markets.\nElectronic trading is in contrast to older floor trading and phone trading and has a number of advantages, but glitches and cancelled trades do still occur.\n\nFor many years stock exchanges were physical locations where buyers and sellers met and negotiated. Exchange trading would typically happen on the floor of an exchange, where traders in brightly colored jackets (to identify which firm they worked for) would shout and gesticulate at one another – a process known as open outcry or pit trading (the exchange floors were often pit-shaped – circular, sloping downwards to the centre, so that the traders could see one another). With the improvement in communications technology in the late 20th century, the need for a physical location became less important and traders started to transact from remote locations in what became known as electronic trading. Electronic trading made transactions easier to complete, monitor, clear, and settle and this helped spur on its development.\n\nOne of the earliest examples of widespread electronic trading was on Globex, the CME Group’s electronic trading platform conceived in 1987 and launched fully in 1992. This allowed access to a variety of financial markets such as treasuries, foreign exchange and commodities. The Chicago Board of Trade (CBOT) produced a rival system that was based on Oak Trading Systems’ Oak platform branded ‘E Open Outcry,’ an electronic trading platform that allowed for trading to take place alongside that took place in the CBOT pits.\n\nSet up in 1971, NASDAQ was the world's first electronic stock market, though it originally operated as an electronic bulletin board, rather than offering straight-through processing (STP).\n\nBy 2011 investment firms on both the buy side and sell side were increasing their spending on technology for electronic trading. With the result that many floor traders and brokers were removed from the trading process. Traders also increasingly started to rely on algorithms to analyze market conditions and then execute their orders automatically.\n\nThe move to electronic trading compared to floor trading continued to increase with many of the major exchanges around the world moving from floor trading to completely electronic trading.\n\nTrading in the financial markets can broadly be split into two groups:\n\nWhile the majority of retail trading in the United States happens over the Internet, retail trading volumes are dwarfed by institutional, inter-dealer and exchange trading. However, in developing economies, especially in Asia, retail trading constitutes a significant portion of overall trading volume.\n\nFor instruments which are not exchange-traded (e.g. US treasury bonds), the inter-dealer market substitutes for the exchange. This is where dealers trade directly with one another or through inter-dealer brokers (i.e. companies like GFI Group, ICAP and BGC Partners. They acted as middle-men between dealers such as investment banks). This type of trading traditionally took place over the phone but brokers moved to offering electronic trading services instead.\n\nSimilarly, B2C trading traditionally happened over the phone and, while some still does, more brokers are allowing their clients to place orders using electronic systems. Many retail (or \"discount\") brokers (e.g. Charles Schwab, E-Trade) went online during the late 1990s and most retail stock-broking probably takes place over the web now.\n\nLarger institutional clients, however, will generally place electronic orders via proprietary electronic trading platforms such as Bloomberg Terminal, Reuters 3000 Xtra, Thomson Reuters Eikon, BondsPro, Thomson TradeWeb or CanDeal (which connect institutional clients to several dealers), or using their brokers' proprietary software.\n\nFor stock trading, the process of connecting counterparties through electronic trading is supported by the Financial Information eXchange (FIX) Protocol. Used by the vast majority of exchanges and traders, the FIX Protocol is the industry standard for pre-trade messaging and trade execution. While the FIX Protocol was developed for trading stocks, it has been further developed to accommodate commodities, foreign exchange, derivatives, and fixed income trading.\n\nThe increase of electronic trading has had some important implications:\n\nFor retail investors, financial services on the web offer great benefits. The primary benefit is the reduced cost of transactions for all concerned as well as the ease and the convenience. Webdriven financial transactions bypass traditional hurdles such as logistics. Conversely there is concern about the impact of speculation through trading, considered negatively and of potential significant damage to the real economy.\n\nElectronic trading systems are typically proprietary software (\"etrading platforms\" or electronic trading platforms), running on COTS hardware and operating systems, often using common underlying protocols, such as TCP/IP.\n\nExchanges typically develop their own systems (sometimes referred to as matching engines), although sometimes an exchange will use another exchange's technology (e.g. e-cbot, the Chicago Board of Trade's electronic trading platform, uses LIFFE's Connect system), and some newer electronic exchanges use 3rd-party specialist software providers (e.g. the Budapest stock exchange and the Moscow Interbank Currency Exchange use automated trading system originally written and implemented by FMSC, an Australian technology company that was acquired by Computershare, and whose intellectual property rights are now owned by OMX).\n\nExchanges and ECNs generally offer two methods of accessing their systems –\n\nFrom an infrastructure point of view, most exchanges will provide \"gateways\" which sit on a company's network, acting in a manner similar to a proxy, connecting back to the exchange's central system.\n\nECNs will generally forego the gateway/proxy, and their GUI or the API will connect directly to a central system, across a leased line.\n\nMany brokers develop their own systems, although there are some third-party solutions providers specializing in this area. Like ECNs, brokers will often offer both a GUI and an API (although it's likely that a slightly smaller proportion of brokers offer an API, as compared with ECNs), and connectivity is typically direct to the broker's systems, rather than through a gateway.\n\nInvestment banks and other dealers have far more complex technology requirements, as they have to interface with multiple exchanges, brokers and multi-dealer platforms, as well as their own pricing, P&L, trade processing and position-keeping systems. Some banks will develop their own electronic trading systems in-house, but this can be costly, especially when they need to connect to many exchanges, ECNs and brokers. There are a number of companies offering solutions in this area.\n\nSome electronic trades are not planned or executed by human traders, but by complex algorithms.\n\nMany types of algorithmic or automated trading activities can be described as high-frequency trading (HFT), which is a specialized form of algorithmic trading characterized by high turnover and high order-to-trade ratios\n\n"}
{"id": "22456841", "url": "https://en.wikipedia.org/wiki?curid=22456841", "title": "Fujitsu Technology Solutions", "text": "Fujitsu Technology Solutions\n\nFujitsu Technology Solutions is a European information technology vendor with a presence in markets in Europe, the Middle East, Africa, as well as India. A subsidiary of Fujitsu Limited headquartered in Tokyo, Japan, FTS was founded in 2009 after Fujitsu bought out Siemens' 50% share of Fujitsu Siemens Computers.\n\nThe company is focused on serving large,medium, and small-sized companies. Fujitsu Technology Solutions offers IT products and services, for data centers, managed infrastructure and infrastructure as a service.\n\nFujitsu Technology Solutions provides a broad range of information and communications technology based products, services and solutions.\n\nFujitsu Technology Solutions' current products and services include:\n\n\nFujitsu Technology Solutions' discontinued products and services include:\n\nFujitsu Technology Solutions operates a product compliance labore which is used inhouse and by third parties. \n\n\n"}
{"id": "6913666", "url": "https://en.wikipedia.org/wiki?curid=6913666", "title": "GeoRSS", "text": "GeoRSS\n\nGeoRSS is a specification for encoding location as part of a Web feed. \"(Web feeds are used to describe feeds (\"channels\") of content, such as news articles, Audio blogs, video blogs and text blog entries. These web feeds are rendered by programs such as aggregators and web browsers.)\" The name \"GeoRSS\" is derived from RSS, the most known Web feed and syndication format.\n\nIn GeoRSS, location content consists of geographical points, lines, and polygons of interest and related feature descriptions. GeoRSS feeds are designed to be consumed by geographic software such as map generators. By building these encodings on a common information model, the GeoRSS collaboration is promoting interoperability and \"upwards-compatibility\" across encodings.\n\nAt this point, the GeoRSS collaboration has completed work on two primary encodings that are called GeoRSS Geography Markup Language (GML) and GeoRSS Simple. GeoRSS-Simple is a very lightweight format that supports basic geometries (point, line, box, polygon) and covers the typical use cases when encoding locations. GeoRSS GML is a formal Open Geospatial Consortium (OGC) GML Application Profile, and supports a greater range of features than GeoRSS Simple, notably coordinate reference systems other than WGS84 latitude/longitude. There is also a W3C GeoRSS serialization, which is older and partly deprecated but still the most widely used.\n\nGeoRSS can be used to extend both RSS 1.0 and 2.0, as well as Atom, the IETF's latest standard for feeds.\n\nHere's a GeoRSS Simple example using Atom.\n\nHere is a schema fragment for a GeoRSS GML encoding for RSS 2.0 \n\nHere is example of W3C geo GeoRSS\n\nExample feeds\n\nUsage and implementation\nOpen source projects\n\nProducts\n\n\n"}
{"id": "1584291", "url": "https://en.wikipedia.org/wiki?curid=1584291", "title": "Guastavino tile", "text": "Guastavino tile\n\nGuastavino tile is a version of Catalan vault introduced to the United States in 1885 by Valencian (Spanish) architect and builder Rafael Guastavino (1842–1908). \n\nGuastavino vaulting is a technique for constructing robust, self-supporting arches and architectural vaults using interlocking terracotta tiles and layers of mortar to form a thin skin, with the tiles following the curve of the roof as opposed to horizontally (corbelling), or perpendicular to the curve (as in Roman vaulting). This is known as timbrel vaulting, because of supposed likeness to the skin of a timbrel or tambourine. It is also called \"Catalan vaulting\" and \"compression-only thin-tile vaulting\".\n\nGuastavino tile is found in some of New York’s most prominent Beaux-Arts landmarks and in major buildings across the United States.\n\nThe Guastavino terracotta tiles are standardized, less than an inch (25 mm) thick, and approximately by across. They are usually set in three herringbone-pattern courses with a sandwich of thin layers of Portland cement. Unlike heavier stone construction, these tile domes could be built without centering. Each tile was cantilevered out over the open space, relying only on the quick drying cements developed by the company. Akoustolith, a special sound absorbing tile, was one of several trade names used by Guastavino.\n\nGuastavino tile has both structural and aesthetic significance. \n\nStructurally, the timbrel vault was based on traditional vernacular vaulting techniques already very familiar to Mediterranean architects, but not well known in America. Terracotta free-span timbrel vaults were far more economical and structurally resilient than the ancient Roman vaulting alternatives. \n\nGuastavino wrote extensively about his system of \"Cohesive Construction\". As the name suggests, he believed that these timbrel vaults represented an innovation in structural engineering. The tile system provided solutions that were impossible with traditional masonry arches and vaults. Subsequent research has shown the timbrel vault is simply a masonry vault, much less thick than traditional arches, that produces less horizontal thrust due to its lighter weight. This permits flatter arch profiles, which would produce unacceptable horizontal thrust if constructed in thicker, heavier masonry.\n\nIn 2012, a group of students under supervision of MIT professor John Ochsendorf built a full-scale reproduction of a small Guastavino vault. The resulting structure was exhibited, as well as a time lapse video documenting the construction process.\n\nOchsendorf also curated an exhibition \"Palaces for the People\", featuring the history and legacy of Guastavino, which premiered in September 2012 at the Boston Public Library, Rafael Guastavino's first major architectural work in America. The exhibition then traveled to the National Building Museum in Washington DC, and an expanded version appeared at the Museum of the City of New York. Ochsendorf, a winner of the Macarthur Foundation \"genius grant\", also wrote the book-length color-illustrated monograph \"Guastavino vaulting : the art of structural tile\", and an online exhibition coordinated with the traveling exhibits.\n\nIn addition, Ochsendorf directs the Guastavino Project at MIT, which researches and maintains the Guastavino.net online archive of related materials.\n\nThe Guastavino company was headquartered in Woburn, Massachusetts, in a building of their own design which still stands. The records and drawings of the Guastavino Fireproof Construction Company are now preserved by the Department of Drawings & Archives in the Avery Architectural and Fine Arts Library at Columbia University in New York City.\n\n\n"}
{"id": "7394916", "url": "https://en.wikipedia.org/wiki?curid=7394916", "title": "Gun data computer", "text": "Gun data computer\n\nThe gun data computer was a series of artillery computers used by the U.S. Army for coastal artillery, field artillery and antiaircraft artillery applications. In antiaircraft applications they were used in conjunction with a director.\n\n\nThe last TACFIRE fielding was completed in 1987. Replacement of TACFIRE equipment began in 1994.\n\nTACFIRE used the AN/GYK-12, a second-generation mainframe computer developed primarily by Litton Industries for Army Divisional Field Artillery (DIVARTY) units. It had two configurations, division and battalion level, housed in mobile command shelters. Field Artillery Brigades also use the division configuration.\n\nComponents of the system were identified using acronyms:\n\nThe successor to the TACFIRE system is the Advanced Field Artillery Tactical Data System (AFATDS).\n\n\nOne reason for a lack of surviving examples of early units was the use of radium on the dials, which officially made them hazardous waste, and as such were disposed of by the United States Department of Energy. Currently there is one surviving example of FADAC at the Fort Sill artillery museum.\n\n\n\n"}
{"id": "1168875", "url": "https://en.wikipedia.org/wiki?curid=1168875", "title": "Handbag", "text": "Handbag\n\nA handbag, also called purse in North American English, is a handled medium-to-large bag used to carry personal items.\n\nThe term \"purse\" originally referred to a small bag for holding coins. In many English-speaking countries it is still used to refer a small money bag. A \"handbag\" is a larger accessory that holds objects beyond currency, such as personal items. American English typically uses the terms purse and handbag interchangeably. The term handbag began appearing in the early 1900s. Initially, it was most often used to refer men's hand-luggage. Women's bags grew larger and more complex during this period, and the term was attached to the accessory.\n\nEarly modern Europeans wore purses for one sole purpose: to carry coins. Purses were made of soft fabric or leather and were worn by men as often as ladies; the Scottish sporran is a survival of this custom. In the 17th century, young girls were taught embroidery as a necessary skill for marriage; this also helped them make very beautiful handbags. By the late 18th century, fashions in Europe were moving towards a slender shape for these accessories, inspired by the silhouettes of Ancient Greece and Rome. Women wanted purses that would not be bulky or untidy in appearance, so \"reticules\" were designed. Reticules were made of fine fabrics like silk and velvet, carried with wrist straps. First becoming popular in France, they crossed over into Britain, where they became known as \"indispensables.\" Men, however, did not adopt the trend. They used purses and pockets, which became popular in men's trousers.\n\nThe modern purse, clutch, pouch or handbag came about in England during the Industrial Revolution, in part due to the increase in travel by railway. In 1841 the Doncaster industrialist and confectionery entrepreneur Samuel Parkinson (of butterscotch fame) ordered a set of travelling cases and trunks and insisted on a travelling case or bag for his wife's particulars after noticing that her purse was too small and made from material that would not withstand the journey. He stipulated that he wanted various handbags for his wife, varying in size for different occasions and asked that they be made from the same leather that was being used for his cases and trunks to distinguish them from the then-familiar carpetbag and other travellers' cloth bags used by members of the popular classes. H. J. Cave (London) obliged and produced the first modern set of luxury handbags, as we would recognize them today, including a clutch and a tote (named as 'ladies travelling case'). These are now on display in the Museum of Bags and Purses in Amsterdam. H. J. Cave did continue to sell and advertise the handbags, but many critics said that women did not need them and that bags of such size and heavy material would 'break the backs of ladies.' H. J. Cave ceased to promote the bags after 1865, concentrating on trunks instead, although they continued to make the odd handbag for royalty, celebrities or to celebrate special occasions, the Queen's 2012 Diamond Jubilee being the most recent. However, H.J. Cave resumed handbag production in 2010.\n\nDuring the 1940s, the rationing of textiles for World War II led to the manufacturing of handbags made in materials like raffia or crocheted from yarn. Some women crocheted their own small handbags from commercial patterns during this period.\n\nThe oldest known purse dates back more than 5000 years, and was a pouch worn by a man, Ötzi the Iceman. Men once carried coin purses. In early Modern Europe, when women's fashions moved in the direction of using small ornamental purses, which evolved into handbags, men's fashions were moving in another direction. Men's trousers replaced men's breeches during the course of the 18th and 19th centuries, and pockets were incorporated in the loose, heavy material. This enabled men to continue carrying coins, and then paper currency, in small leather wallets. Men's pockets were plentiful in 19th century and 20th century trousers and coats, to carry possessions, such as pipes, matches and knives, and they were an item frequently mended by their wives.\n\nMen's purses were revived by designers in the 1970s in Europe. Since the 1990s, designers have marketed a more diverse range of accessory bags for men. The names man bag, man-purse and murse have been used. The designs are typically variations on backpacks or messenger bags, and have either a masculine or a more unisex appearance, although they are often more streamlined than a backpack and less bulky than a briefcase. These bags are often called messenger bags or organizer bags. The leather satchel is also common. Men's designer bags are produced by well-known companies such as Prada, Louis Vuitton, Coach, and Bottega Veneta in a variety of shapes and sizes. The global men's bag and small leather goods trade is a $4-billion-a-year industry. Sales of men's accessories including \"holdall\" bags are increasing in North America.\n\nAs a fashion accessory, handbags can be categorized according to the silhouette of the bag, as well as the type of handle. The current popular handbag silhouettes are (as of 2011):\n\n\nAccording to type of handle, handbags are often categorized as:\n\n\nHandbags that are designed for specific utilitarian needs include:\n\n\nA distinction can also be made between soft-body handbags or frame handbags, where a metal frame supports the textile or leather of the bag. Frame bags often use a kissing lock closure, with two interlocking metal beads set on the top of the frame. Kissing locks were popular on handbags during the early- to mid-20th century, and remain popular with vintage collectors and in \"retro\" designs. These locks are still seen on smaller change purses.\n\nThe verb \"to handbag\" was inspired in the 1980s by UK prime minister Margaret Thatcher having “weaponized” the handbag in the opinion of British biographer and historian David Cannadine. As “her most visible symbol of her power to command” the bag became an emphatic prop that she produced at meetings to show she meant business. She would invariably bring out of the bag a crucial document from which she would quote, her speech notes often being cut to size to fit inside. Because Thatcher was Britain’s first female prime minister, former Daily Telegraph editor Charles Moore wrote in his authorised biography of 2013, “her handbag became the sceptre of her rule”. \n\nThe verb's more general meaning of \"treating ruthlessly\" came to symbolize Thatcher's whole style of government. Victims of her handbaggings, from political leaders to journalists, have testified to what the German chancellor Helmut Kohl perceived as her “ice-cold pursuit of her interests”. US secretary of state James Baker recalled her standby ploy: “When negotiations stall, get out the handbag! The solution is always there.”\n\nJulian Critchley, one of her biggest Tory backbench critics, once said, \"Margaret Thatcher and her handbag is the same as Winston Churchill and his cigar.\" Thatcher's bag was almost as newsworthy an item as she was herself and on the day she died, one of her handbag-makers saw a sharp rise in sales of her favorite structured design. The original bag Thatcher asserts on a signed card was the one “used every day in my time at Downing Street” is archived at Churchill College, Cambridge. Made of dark blue leather “in mock-croc style”, it was a gift from friends on her birthday in 1984.\n\n"}
{"id": "19009230", "url": "https://en.wikipedia.org/wiki?curid=19009230", "title": "Hybrid positioning system", "text": "Hybrid positioning system\n\nHybrid positioning systems are systems for finding the location of a mobile device using several different positioning technologies. Usually GPS (Global Positioning System) is one major component of such systems, combined with cell tower signals, wireless internet signals, Bluetooth sensors, IP addresses and network environment data.\n\nThese systems are specifically designed to overcome the limitations of GPS, which is very exact in open areas, but works poorly indoors or between tall buildings (the urban canyon effect). By comparison, cell tower signals are not hindered by buildings or bad weather, but usually provide less precise positioning. Wi-Fi positioning systems may give very exact positioning, in urban areas with high Wi-Fi density - and depend on a comprehensive database of Wi-Fi access points.\n\nHybrid positioning systems are increasingly being explored for certain civilian and commercial location-based services and location-based media, which need to work well in urban areas in order to be commercially and practically viable.\n\nEarly works in this area include the Place Lab project, which started on 2003 and went inactive in 2006. Later methods let smartphones combine the accuracy of GPS with the low power consumption of cell-ID transition point finding.\n\n"}
{"id": "38063531", "url": "https://en.wikipedia.org/wiki?curid=38063531", "title": "Inclined elevator", "text": "Inclined elevator\n\nAn inclined elevator or \ninclined lift\nis a form of a cable railway system for steep gradient.\n\nAn inclined elevator consists of one or two inclined tracks on a slope with a single car on each carrying payload. In the case of a two-track configuration each car operates in a \"shuttle principle\": it moves up and down on its own track independently of the other car. A car is either winched up to the station on the top of the incline where the cable is collected on a winch drum. Alternatively a car is balanced by a counterweight moving along the track in the opposite direction, quite similar to an ordinary lift.\n\nUnlike a standard elevator, it can go up tilted grades, and can be used for both residential and commercial purposes. The purpose of inclined elevators is to provide accessibility to steep hillsides and inclines at minimal effort to the user. Inclined elevator is a form of cable railway.\n\nUsers with mobility and disability challenges often use an incline platform lift to climb staircases in their home with their mobility scooter or motorized wheelchair. Outdoor inclined elevators are used to access steep hillside property where stairs are not a preferred option. Inclined elevators can also be used to move equipment and materials to hard to reach elevated locations for industrial or construction purposes.\n\nIn European Union \"inclined lifts\" are subject to EU lift regulations part 22 EN 81-22:2014 which defines some standard limits for their implementations: track inclination is between 15° and 75°, maximum cabin capacity is 100 people (7.500 kg), maximum speed — 4 m/s, the track is straight in the horizontal plane. These limits are not compulsory though and if not followed by an installation, for example, the path is curved, some unspecified additional risk analysis is required to be conducted.\n\nInclined elevator's design is based on the same basic technology as conventional, vertical elevator. In general standard elevator's equipment can be adapted for systems with an inclines up 10° from vertical, while an incline with more than 20° from vertical will require some additional considerations.\n\nFor example, inclined elevators used in the Stockholm metro were using standard \"vertical\" elevator cabins mounted on wheeled platforms adapted to 30° incline. The cabin was balanced by a counterweight and it was moved by a conventional elevator's hoist and cables along the guide rails.\n\nWhile some inclined elevators are outdoor systems designed to move people and goods along steep gradients, the others are used in buildings.\n\nMost common inclined elevators are constructed from steel or aluminum materials, are powered by electric motors, and operate with push button electronic controls. Common drive systems include cable winding drums and continuous loop traction drives.\n\nMany inclined lifts were constructed along the pressure lines of storage power plants for transporting building materials. Examples are the \"Gelmerbahn\" leading to the Gelmersee and the \"Funicolare Piora–Ritom\" leading to Lago Ritom, both in Switzerland.\n\nModern versions resembling an elevator are used in some installations, such as at the Cityplace Station in Dallas, Texas, the Huntington Metro Station in Huntington, Virginia, the San Diego Convention Center in San Diego, the Luxor Hotel in Las Vegas, Nevada, and the Eiffel Tower in Paris. The London Millennium Funicular provides an alternative to staircase access to London's Millennium Bridge.\n\nA mixture between an inclined lift and a funicular with two cars was the second Angels Flight in Los Angeles, which ran from 1996 to 2001. The original funicular closed in 1969 and was reinstalled in 1996 using separate cables for each car, which were winched on separate winch drums in the station at the top. The winch drums were connected to the drive motor and the service brake by a gear train. The system failed because of gear train breakage, causing a fatal accident in 2001. The railway reopened as a true funicular, with a single main haulage cable with one car attached to each end, in 2010. It has closed and reopened several times since, last re-opening on 31 August 2017.\n\nAn inclined elevator differs from a funicular in that the latter has a cable attached to a pair of vehicles, the ascending and descending vehicles counterbalancing each other. In the inclined elevator one car is either winched up to the station at the top of the incline where the cable is collected on a winch drum, or the single car is balanced by a counterweight. Some scholars though consider an inclined elevator as a descendant of a funicular.\n\nEuropean Union legislation separates inclined elevators and funiculars by putting them in different regulations: inclined lift installations are regulated by EN 81-22:2014 while funicular installations are regulated by EU directive 2000/9/EC\n\nFor example, despite its name the Montmartre Funicular in Paris after a reconstruction in 1991 is technically a \"double inclined elevator\" since each of its two cabins have its own cable traction with own counterweight and they operate independently from each other.\n\n\n"}
{"id": "23743131", "url": "https://en.wikipedia.org/wiki?curid=23743131", "title": "Journal of Microwave Power and Electromagnetic Energy", "text": "Journal of Microwave Power and Electromagnetic Energy\n\nThe Journal of Microwave Power and Electromagnetic Energy is a quarterly peer-reviewed scientific journal covering industrial, medical, and scientific applications of electromagnetic and microwaves from 0.1 to 100 GHz, including topics such as food processing, instrumentation, polymer technologies, and systems design.\n\nThe journal is published by the International Microwave Power Institute. The editor-in-chief is Eli Jerby (Tel Aviv University).\n"}
{"id": "20041664", "url": "https://en.wikipedia.org/wiki?curid=20041664", "title": "Low hydrogen annealing", "text": "Low hydrogen annealing\n\nLow hydrogen annealing is a heat treatment in metallurgy for the reduction or elimination of hydrogen in a material to prevent hydrogen embrittlement.\n\nThe material is kept in an hydrogen annealing oven over several hours at temperatures between 200 °C and 300 °C. The enclosed hydrogen atoms, known for hydrogen embrittlement are removed by effusion. The method is predominantly used immediately after welding, coating process or galvanizing of the parts.\n\n"}
{"id": "1468595", "url": "https://en.wikipedia.org/wiki?curid=1468595", "title": "MVCML", "text": "MVCML\n\nMultiple-valued current mode logic (MVCML) or current mode multiple-valued logic (CM-MVL) is a method of representing electronic logic levels in analog CMOS circuits. In MVCML, logic levels are represented by multiples of a base current, I, set to a certain value, x. Thus, level 0 is associated with the value of null, level 1 is associated with I = x, level 2 is represented by I = 2x, and so on.\n\n"}
{"id": "41726381", "url": "https://en.wikipedia.org/wiki?curid=41726381", "title": "Nanoprobing", "text": "Nanoprobing\n\nNanoprobing is method of extracting device electrical parameters through the use of nanoscale tungsten wires, used primarily in the semiconductor industry. The characterization of individual devices is instrumental to engineers and integrated circuit designers during initial product development and debug. It is commonly utilized in device failure analysis laboratories to aid with yield enhancement, quality and reliability issues and customer returns. Commercially available nanoprobing systems are integrated into either a vacuum-based scanning electron microscope (SEM) or atomic force microscope (AFM). Nanoprobing systems that are based on AFM technology are referred to as Atomic Force nanoProbers (AFP).\n\nAFM based nanoprobers, enable up to eight probe tips to be scanned to generate high resolution AFM topography images, as well as Conductive AFM, Scanning Capacitance, and Electrostatic Force Microscopy images. Conductive AFM provides pico-amp resolution to identify and localize electrical failures such as shorts, opens, resistive contacts and leakage paths, enabling accurate probe positioning for current-voltage measurements. AFM based nanoprobers enable nanometer scale device defect localization and accurate transistor device characterization without the physical damage and electrical bias induced by high energy electron beam exposure.\nFor SEM based nanoprobers, the ultra-high resolution of the microscopes that house the nanoprobing system allow the operator to navigate the probe tips with precise movement, allowing the user to see exactly where the tips will be landed, in real time. Existing nanoprobe needles or “probe tips” have a typical end-point radius ranging from 5 to 35 nm. The fine tips enable access to individual contacts nodes of modern IC transistors. Navigation of the probe tips in SEM based nanoprobers are typically controlled by precision piezoelectric manipulators. Typical systems have anywhere from 2 to 8 probe manipulators with high end tools having better than 5 nm of placement resolution in the X, Y & Z axes and a high accuracy sample stage for navigation of the sample under test.\n\nCommon nanoprobing techniques include, but are not limited to:\n\nCommon issues that arise:\n\nNanoprobe Capacitance-Voltage Spectroscopy (NCVS) Localization of 32nm SOI SRAM Array Failure\n\n"}
{"id": "944825", "url": "https://en.wikipedia.org/wiki?curid=944825", "title": "Negative imprinting", "text": "Negative imprinting\n\nNegative imprinting is a feature of some film cameras, in which the date, shutter speed and aperture setting are recorded on the negative directly as the film is exposed.\n\nThe oldest patent on this is US patent #3,882,512, which uses half-silvered mirrors to direct the readout of a digital clock and mix it with the light rays coming through the main camera lens.\n\nThe type of imprinter used in modern SLR cameras is of the type described in patent #4,001,846. This imprinter is fixed to the back of the camera on the film backing plate. It uses a small LED display for illumination and optics to focus the light onto a specific part of the film. The LED display is exposed on the negative at the same time the picture is taken. \n\nThe imprinter superimposes the date and other information on the image and this can be distracting. Digital cameras can often encode all the information in the image file itself. The Exif format is the most commonly used format.\n"}
{"id": "18698650", "url": "https://en.wikipedia.org/wiki?curid=18698650", "title": "Observer effect (information technology)", "text": "Observer effect (information technology)\n\nIn information technology, the observer effect is the impact on the behaviour of a computer process caused by the act of observing the process while it is running.\n\nFor example: if a process uses a log file to record its progress, the process could slow down. Furthermore, the act of viewing the file while the process is running could cause an I/O error in the process, which could, in turn, cause it to stop. Another example would be observing the performance of a CPU by running both the observed and observing programs on the same CPU, which will lead to inaccurate results because the observer program itself affects the CPU performance (modern, heavily cached and pipelined CPUs are particularly affected by this kind of observation).\n\nThe observer effect could either have a positive or negative impact on the computer process behaviour. A positive impact can be software bugs, also known as Heisenbugs, which diminish or change their negative behavior when observation mechanisms, such as debugging, are enabled. Such bugs usually create extra difficulties in being isolated.\n"}
{"id": "4400526", "url": "https://en.wikipedia.org/wiki?curid=4400526", "title": "PAREXEL", "text": "PAREXEL\n\nPAREXEL International is a global provider of biopharmaceutical services. It conducts clinical trials on behalf of its pharmaceutical clients to expedite the drug approval process. It is the second largest clinical research organization in the world and has helped develop approximately 95% of the 200 top-selling biopharmaceuticals on the market today. The company publishes the annual PAREXEL R&D Statistical Sourcebook, operates the PAREXEL-Academy, and councils all of the top 50 biopharmaceutical and top 30 biotechnology companies.\n\nPAREXEL was founded in 1982 by Josef von Rickenbach and organic chemist Anne B. Sayigh initially to advise Japanese and German firms on how to navigate the FDA approval process. The firm has grown organically over the years and through 40 acquisitions. Josef von Rickenbach is credited with establishing PAREXEL’s culture and practices based on the principles he experienced as a researcher at Schering-Plough in Lucerne, Switzerland.\n\nIn 1990, the firm expanded internationally and established new practice areas. By 1999 it had a staff of 4,500 and 45 offices. In the 2000s, it grew to over 18,000 employees. PAREXEL’s consulting and clinical trial work has helped establish many household drug brands and contributed to numerous successes in modern pharmacology.\n\nThe company was acquired by private equity firm Pamplona Capital Management for approximately $5.0 billion. The deal closed in September of 2017.\n\n\nIn March 2006, a PAREXEL-run trial on behalf of TeGenero, the now bankrupt German biotechnology firm, on its anti-inflammatory drug TGN1412 to treat rheumatoid arthritis, multiple sclerosis or leukaemia, caused severe inflammation and multiple organ failure in six healthy volunteers at a facility based at Northwick Park Hospital in London. The drug had been tested on animals but this was the first test on humans.\n\nPAREXEL became the target of legal proceedings from lawyers representing the injured volunteers after the insurance policy of TeGenero was unable to provide sufficient compensation. When the liable company subsequently declared bankruptcy, lawyers for the volunteers initiated legal proceeding against PAREXEL and the two parties later entered into talks; the results of this meeting have not been made public.\n\nA documentary shown in the UK on 28 September 2006 featuring journalist Brian Deer as part of Channel 4's Dispatches series exposed uncertainty about the existence of data that should mandatorily have been submitted by TeGenero to the Medicines and Healthcare products Regulatory Agency (MHRA) prior to the trial indicating whether TGN1412 had been adequately tested on human blood in vitro. Concerns were also raised about whether a safe human dosage was properly obtained by TeGenero. The MHRA however concluded that none of the companies involved could be held responsible for the outcome of the test and that the adverse events that occurred were most likely caused by an unpredicted biological action of the drug in humans.\n\n"}
{"id": "2057983", "url": "https://en.wikipedia.org/wiki?curid=2057983", "title": "PICMG", "text": "PICMG\n\nThe PCI Industrial Computer Manufacturers Group (PICMG) is a consortium of over 150 companies. Founded in 1994, the group was originally formed to adapt PCI technology for use in high-performance telecommunications, military, and industrial computing applications, but its work has now grown to include newer technologies. PICMG is distinct from the similarly named and adjacently-focused PCI Special Interest Group (PCI-SIG).\n\nPICMG currently focuses on developing and implementing specifications and guidelines for open standards-based computer architectures from a wide variety of interconnects.\n\nPICMG is a leading standards development organization in the embedded computing industry. Members work collaboratively to develop new specifications and enhancements to existing ones. The members benefit from participating in standards development, gain early access to leading-edge technology, and forging relationships with thought leaders and suppliers in the industry. \n\nThe original PICMG mission was to provide extensions to the PCI standard developed by PCI-SIG for a range of applications. The organization's collaborations eventually expanded to include a variety of interconnect technologies for industrial computing and telecommunications. PICMG's specifications are used in a wide variety of industries including industrial automation, military, aerospace, telecommunications, medical, gaming, transportation, physics/research, test & measurement, energy, drone/robotics, and general embedded computing. \n\nIn 2011, PICMG completed its transfer of assets from the Communications Platforms Trade Association (CP-TA). Since 2006, CP-TA had been a collaboration of communications vendors, developing interoperability testing requirements, methodologies, and procedures based on open specifications from PICMG, The Linux Foundation, and the Service Availability Forum. PICMG has continued the educational and marketing outreach formerly conducted by members of the CP-TA marketing work group.\n\nOpen specifications and standards provide several benefits including multiple sources, scalability and upgrades, a large ecosystem of interoperable products, proven and tested designs, and much more. But they should not be confused with open source. The open source groups tend to focus on specific product designs where even the Gerber files, schematics, and mechanical drawings are included. This lends itself to monochrome, commodity products with little differentiation. Open specification/open standard groups on the other hand define focus on common interfaces for interoperable products rather than finished products. Multiple vendors contribute to the base definitions and interfaces, but the implementation can vary greatly. The result is a rich and diverse set of interoperable products geared for a wide range of applications.\n\nFor many years, PICMG used a numerical naming convention with specification being referred to as “PICMG X.YY”. Where X was used denoted differing form factors (“1” for slot card based single board computers, “2” for CompactPCI and “3” for AdvancedTCA) while YY was used to indicate incremental changes, option definitions or slight variation of a specification form its core specification. In 2003, PICMG added an acronym-based naming convention for its specifications to yield better results from internet search engines. Specifications are now often named ABCD.X where ABCD is an acronym of the specification. In this naming convention, base or main specification are denote with X=0 (i.e. ABCD.0) and PICMG subsidiary specifications are denoted X>0. PICMG subsidiary specifications represent how various options or variations of a based specification should be handled.\n\nThese groups represent standing committees which may result in new subsidiary specification, revisions to existing specification, reference materials for future PICMG committees or new PICMG specifications.\n\nThe following specifications were developed by the ASI SIG which has now disbanded and has transferred these documents to PICMG. \n\nThe PICMG has active liaisons with several industry bodies including the Service Availability Forum.\n\n\n"}
{"id": "19763505", "url": "https://en.wikipedia.org/wiki?curid=19763505", "title": "Rat-tail splice", "text": "Rat-tail splice\n\nA rat-tail splice, also known as a twist splice or a pig-tail splice, is a very basic electrical splice that can be done with both solid and stranded wire. It is made by taking two or more bare wires and wrapping them together symmetrically around the common axis of both wires. The bare splice can be insulated with electrical tape or other means.\n\nThis common and simple splice is not very strong mechanically. It can be made stronger by coating it with solder, or it can be twisted and then held in place by the internal metal spring or threads of a twist-on wire connector, also called a wire nut. Because it is not very strong, the splice is not meant to connect wires that will be pulled or stressed. Rather, it is intended for wires that are protected inside an enclosure or junction box.\n\n\n"}
{"id": "6210017", "url": "https://en.wikipedia.org/wiki?curid=6210017", "title": "Scaffold (programming)", "text": "Scaffold (programming)\n\nScaffolding, as used in computing, refers to one of two techniques: The first is a code generation technique related to database access in some model–view–controller frameworks; the second is a project generation technique supported by various tools.\n\nScaffolding is a technique supported by some model–view–controller frameworks, in which the programmer can specify how the application database may be used. The compiler or framework uses this specification, together with pre-defined code templates, to generate the final code that the application can use to create, read, update and delete database entries, effectively treating the templates as a \"scaffold\" on which to build a more powerful application.\n\nScaffolding is an evolution of database code generators from earlier development environments, such as Oracle's CASE Generator, and many other 4GL client-server software development products.\n\nScaffolding was made popular by the Ruby on Rails framework. It has been adapted to other software frameworks, including OutSystems Platform, Express Framework, Play framework, Django, web2py, MonoRail, Brail, Symfony, Laravel, CodeIgniter, Yii, CakePHP, Phalcon PHP, Model-Glue, PRADO, Grails, Catalyst, Mojolicious, Seam Framework, Spring Roo, JHipster, ASP.NET Dynamic Data, KumbiaPHP and ASP.NET MVC framework's Metadata Template Helpers.\n\nScaffolding can occur at two different phases of the program lifecycle: design time and run time. Design time scaffolding produces files of code that can later be modified by the programmer to customize the way the application database is used. However, for large-scale applications this approach may be difficult to maintain due to the sheer number of files produced, and the fact that the design of the files was largely fixed when they were generated or copied from the original templates. Alternatively, run time scaffolding produces code on the fly. It allows changes to the design of the templates to be immediately reflected throughout the application. But modifying the design of the templates may be more difficult or impractical in the case of run time scaffolding.\n\nWhen the line codice_1 is added to a controller, Rails will automatically generate all of the appropriate data interfaces at run time. Since the API is generated on the fly, the programmer cannot easily modify the interfaces generated this way. Such a simple scaffold is often used for prototyping applications and entering test data into a database.\n\nThe programmer may also run an external command to generate Ruby code for the scaffold in advance: codice_2. The codice_3 script will produce files of Ruby code that the application can use to interact with the database. It is somewhat less convenient than dynamic scaffolding, but gives the programmer the flexibility of modifying and customizing the generated APIs.\n\nNote: As of Rails 2.0, dynamic scaffolding is no longer stored.\n\nScaffolding techniques based on the application database typically involve Server side frameworks. Server side web frameworks commonly perform operations directly against database entries, and code generation for these operations may be considered Server side Scaffolding. Alternatively, Client side development often uses frameworks that perform data transport operations instead of directly accessing the database. The focus of Client side Scaffolding is thus more on generating a starter template for the application as a whole, rather than generating code to access a database.\n\nSome Client side web frameworks, such as Meteor, allow the client to perform database operations in a manner similar to Server side frameworks. In this case, Scaffolding techniques can go beyond merely generating a starter template. They can perform run time scaffolding of web forms on the Client side to create, read, update and delete database entries. One example of this is provided by an add-on to Meteor called aldeed:autoform .\n\nComplicated software projects often share certain conventions on project structure and requirements. For example, they often have separate folders for source code, binaries and code tests, as well as files containing license agreements, release notes and contact information. To simplify the creation of projects following those conventions, \"scaffolding\" tools can automatically generate them at the beginning of each project. Such tools include Yeoman and Cargo.\n\n\n"}
{"id": "13434399", "url": "https://en.wikipedia.org/wiki?curid=13434399", "title": "Sevan Marine", "text": "Sevan Marine\n\nSevan Marine ASA is specializing in design, engineering and project execution of floating units for offshore applications. The main product is cylinder platforms used for floating production and drilling.\n\nThe company is based in Arendal but also has office in Oslo and Singapore. Sevan Marine ASA is listed on Oslo Børs with ticker SEVAN.\n"}
{"id": "24958693", "url": "https://en.wikipedia.org/wiki?curid=24958693", "title": "Simon Phipps (programmer)", "text": "Simon Phipps (programmer)\n\nSimon Phipps is a computer scientist and web and open source advocate.\n\nPhipps was instrumental in IBM's involvement in the Java programming language, founding IBM's Java Technology Center. He left IBM for Sun Microsystems in 2000, taking leadership of Sun's open source programme from Danese Cooper. Under Phipps, most of Sun's core software was released under open source licenses, including Solaris and Java.\n\nPhipps was not hired into Oracle as part of the acquisition of Sun Microsystems and his final day was March 8, 2010 when the two entities combined. Following Sun, he spent a year as Chief Strategy Officer of identity startup ForgeRock before becoming an independent consultant. In 2015 he joined Wipro Technologies as director of their open source advisory practice.\n\nPhipps was President of the Open Source Initiative until 2015 when he stepped down in preparation for the end of his Board term in 2016, and was re-elected in 2017 and re-appointed President by the Board in September 2017. He is also currently a board member of the Open Rights Group and The Document Foundation and on the advisory board of Open Source for America. He has served on a number of advisory boards for other projects, including as CEO of the MariaDB Foundation, and at the GNOME Foundation, OpenSolaris, OpenJDK, and OpenSPARC.\n\nHe appeared as a guest on episodes 39 , 113 and 337 of FLOSS Weekly and as a regular co-host, such as on episodes 124 and 201.\n\n"}
{"id": "312076", "url": "https://en.wikipedia.org/wiki?curid=312076", "title": "Spike strip", "text": "Spike strip\n\nA spike strip (also known as traffic spikes, tire shredders, one-way traffic treadles, stingers, stop sticks, a stinger in police slang, and formally known as a tire deflation device) is a device or weapon used to impede or stop the movement of wheeled vehicles by puncturing their tires. Generally, the strip is composed of a collection of 35 to 75 mm (1.5 to 3 inches) long metal barbs, teeth or spikes pointing upward. The spikes are designed to puncture and flatten tires when a vehicle is driven over them; they may be detachable, with new spikes fitted to the strip after use. The spikes may be hollow or solid; hollow ones are designed to detach and become embedded in the tires, allowing air to escape at a steady rate to reduce the risk of the driver losing control and crashing. One type was co-invented by Donald Kilgrow, a retired Utah Highway Patrol trooper, along with a design engineer. They are historically a development of the caltrop, anti-cavalry and anti-personnel versions being used as early as 331 BC by Darius III against Alexander the Great at the Battle of Gaugamela in Persia.\n\nIn the United States, five officers were killed deploying spike strips in 2011 alone. Dallas, Texas police are among those banned from using them, in response to the hazards.\n\nRemotely deployable spike strips have been invented to reduce the danger to police officers deploying them. Spike strips are also built into some parking barriers to control traffic flow.\n\nPrivate possession of spike strips was banned in New South Wales, Australia in 2003 after a strip cheaply constructed from a steel pipe studded with nails was used against a police vehicle. John Watkins, a member of New South Wales Legislative Assembly, stated they would be added to the New South Wales prohibited weapons list.\n\nFollowing the rise in terrorist vehicle attacks whereby a vehicle is driven at speed into pedestrians, a net with steel spikes that can be deployed by two people in less than a minute, reported able to stop a vehicle of up to 17 tonnes, was developed for preventive use at public events in the UK, with the name \"Talon\" (also referred to as X-Net(R), manufactured by british defence company QinetiQ). It has steel spikes to puncture tyres, and becomes entangled around the front wheels, halting the vehicle. It is designed to reduce risk to crowds by making the vehicle skid in a straight line without veering unpredictably. It was first deployed to protect a parade on 11 September 2017.\n\n"}
{"id": "30987670", "url": "https://en.wikipedia.org/wiki?curid=30987670", "title": "Suits (U.S. TV series)", "text": "Suits (U.S. TV series)\n\nSuits is an American legal drama television series created and written by Aaron Korsh. The series premiered on June 23, 2011, on the cable network USA, and is produced by Universal Cable. \"Suits\" is set at a fictional law firm in New York City. The focal point of the show follows talented college dropout Mike Ross (Patrick J. Adams), who initially works as a law associate for Harvey Specter (Gabriel Macht), despite never actually having attended law school. The show focuses on Harvey and Mike managing to close cases while maintaining Mike's secret.\n\n\"Suits\" has been nominated for several awards since 2012, with Gina Torres and Patrick J. Adams receiving individual praise for their roles as Jessica Pearson and Mike Ross, respectively. On top of two nominations recognizing her role as a supporting actress, Torres was awarded Outstanding Performance in a Television Series at the 2013 NHMC Impact Awards. Adams was nominated for Outstanding Performance by a Male Actor in a Drama Series at the 2012 Screen Actors Guild Awards, and the show itself has been nominated for two People's Choice Awards.\n\nOn January 30, 2018, it was announced the series was renewed for an eighth season without series regulars Patrick J. Adams and Meghan Markle. It was later announced that Katherine Heigl would join the cast in season 8 as attorney Samantha Wheeler, with recurring stars Dulé Hill and Amanda Schull being promoted to series regulars. On March 8, 2018, it was announced previous series star, Gina Torres, will have a spin-off centered around her character, Jessica Pearson. Season 8 premiered on July 18, 2018, with the back half of the season premering January 23, 2019.\n\nFormer student Mike Ross makes a living illegally taking the Law School Admission Test for others. To pay for his grandmother's care, he agrees to deliver a case of marijuana for his best friend Trevor, a drug dealer. Mike astutely avoids being arrested in a sting, only to stumble into a job interview with Harvey Specter, called the best closer in the city. Mike's knowledge of the law impresses Harvey enough to win him the associate position, even though Mike didn't attend Harvard. Together they try cases for the firm while maintaining the secret that Mike is a fraud.\n\nJessica Pearson, managing partner, learns Mike's secret, but other issues take precedence when co-founding partner Daniel Hardman returns to the firm, pressuring Jessica and Harvey. Mike begins to foster a relationship with paralegal Rachel Zane, but finds himself pursuing other romantic entanglements after his grandmother's sudden death. Harvey and his secretary Donna face accusations of burying evidence and must discover the truth while keeping incriminating evidence from Hardman, who would use it to leverage a managing partner position. The intensifying threat from Hardman forces Jessica into a merger with a British firm headed by Edward Darby. And Mike reveals he's a fraud to Rachel.\n\nDarby's presence in the firm gives Harvey leverage to seek a position as a named partner. Meanwhile, the merger causes Louis Litt to clash with his British counterpart. Darby International client Ava Hessington draws Harvey into a lengthy trial against his former mentor and, when the lawsuit turns into a murder charge, the arrest of Darby's \"fixer\" Stephen Huntley becomes grounds for a messy dissolution of the merger. Rachel gets accepted into law school at Columbia, and she and Mike move in together. Realizing that his fraud can't continue forever, Mike leaves newly renamed Pearson Specter to take a position as an investment banker.\n\nMike's new job puts him and Harvey on opposite sides of a takeover battle, causing the SEC to accuse them of collusion. When Mike is fired, Louis goes to extreme lengths to persuade Mike to come back to Pearson Specter, which put him in debt to shady billionaire investor Charles Forstman. Louis demands a name partner position, competing with Harvey, but his wrongdoings get him fired instead. When he realizes Mike never went to Harvard, he blackmails Jessica into rehiring him with the promotion he desired. Mike proposes to Rachel; Donna leaves Harvey to work for Louis.\n\nHarvey struggles with losing Donna and begins to open up to a therapist about his broken relationship with his mother. Louis' insecurity, however, and desire to undermine Harvey create an opening for Jack Soloff, an ambitious partner who is being manipulated by Hardman. Rachel's wedding plans and her relationship with her parents are both overshadowed by Mike's secret. Mike and Harvey both resign to protect their future, but Mike is abruptly arrested for fraud. More and more people involved realize the allegations are true, and facing a tenacious Anita Gibbs, Mike accepts a plea bargain, pleads guilty, and turns himself in so that no one else will go to jail. At the wedding, Mike tells Rachel that he will not marry her now but if she still wants him in two years then he will marry her after getting out of prison. Harvey escorts him to prison making their last few goodbyes.\n\nA two-year prison sentence puts Mike at the mercy of Frank Gallo, an inmate with a grudge against Harvey. At Pearson Specter Litt, few employees remain to help. Rachel works an Innocence Project case for her law professor; Jessica assists pro bono but is distracted from matters at the firm, and chooses to leave her position to pursue her own life. Mike's cellmate proves pivotal in a deal for Mike's freedom. He struggles with his fraud being public knowledge but obtains a job at a legal clinic. Harvey helps both Rachel and Mike pass the bar, and persuades Mike to come back to the firm, but not after Harvey has to cross some ethical lines to make sure Mike does pass the bar.\n\nEveryone at the firm struggles to adjust to a new normal without Jessica. Donna takes a position as COO and Harvey's friend Alex joins the team. Harvey begins dating his former therapist, Paula; Louis sees a therapist of his own, with mixed results. Rachel begins her career as an attorney, having passed the bar. Mike continues to work pro bono cases at the clinic, with Harvey's blessing, but one of the cases puts Alex, Harvey and others at risk. Louis and Sheila reconnect; as does Jessica with her family in Chicago (back-door pilot to Second City). Mike and Rachel accept a job offer in Seattle, Washington to run their own firm that takes on class-action suits, and get married before leaving.\n\n\n\"Suits\" first appeared on USA network's development slate under the title \"A Legal Mind\" in April 2010. On April 5, 2010, USA announced that it was developing seven new pilots for its 2010–2011 television season, including \"A Legal Mind\", which would later become \"Suits\". The premiere was written by Aaron Korsh, and David Bartis and Gene Klein served as executive producers. It was later announced on May 17, 2010, that USA ordered a ninety-minute cast-contingent pilot for the series. The network later picked up \"A Legal Mind\" on January 19, 2011, and ordered eleven one-hour episodes in addition to the 90-minute pilot.\n\nCreator Aaron Korsh, whose \"Notes from the Underbelly\" sitcom was canceled during the 2007–2008 Writers' strike, wrote a spec script intended to be a \"half-hour \"Entourage\"-type based on my experiences working on Wall Street.\" He later realized that the project should have hour-long episodes. Korsh and his agent took the script to several production companies and wanted to give the script to Universal Media Studios. However, Korsh found it odd that the studio did not want to sell the script to NBC, the network the studio typically worked with. Korsh's agent convinced USA Network executive Alex Sepiol that although the series was neither a procedural nor what the network typically did, he would like the characters. Sepiol approved of the script, and by then, Hypnotic Films & Television signed on to the project. The team pitched the script to USA network, which bought the script after the pitch. Korsh did not pitch it to anyone else. When rewriting the script, Korsh made only small changes to the first half-hour, up to when Mike is hired. Originally, Mike did not take LSATs for others and only pretends to have attended Harvard, as opposed to pretending he attended Harvard and has a law degree. Korsh noted that there is no degree or test needed, to work on Wall Street and be a mathematical genius, unlike the bar examination in law. He decided to \"embrace\" this difference and change the premise.\n\nThe pilot episode was filmed in New York City, where the series is set. The rest of the series is filmed in Toronto (at Downsview Park Studios), where the sets are built to be identical to the New York law offices seen in the pilot. To promote the series debut, USA had an advance screening of the pilot on June 2, 2011, at the Hudson River Park and distributed free Häagen-Dazs Sundaes cones at the viewing. The network also had a branded ice cream carts, bikes, and scooters give away at the Sundaes and USA/\"Entertainment Weekly\" 2011 promotion summer guides on June 22 and 23. They also held the promotion in New York City, Los Angeles, Chicago, San Francisco, and Boston to endorse the pilot.\n\nThe season was created by Aaron Korsh and was aired on the USA Network in the United States. The season was produced by Hypnotic Films & Television and Universal Cable Productions. The executive producers were Korsh, Doug Liman, and David Bartis. The staff writers were: Korsh with three writing credits; Sean Jablonski, Jon Cowan, Ethan Drogin, and Rick Muirragui with two each; and Erica Lipez with one. The directors throughout the season were Kevin Bray, John Scott, Dennie Gordon, Kate Woods, Terry McDonough, Tim Matheson, Norberto Barba, Felix Alcala, Jennifer Getzinger, and Mike Smith. The first role in which a casting spot was filled was for Patrick J. Adams, who was cast in the lead role of Mike Ross in July 2010. In late July, Gabriel Macht joined the main cast as Harvey Specter. Rick Hoffman came on board in mid-August to portray Harvey's competition, Louis, at the law firm. Meghan Markle and Gina Torres soon joined the cast in late August, who were set to play Rachel Zane and Jessica Pearson respectively. Sarah Rafferty completed the main cast as Donna, and the pilot was filmed in New York City in the fall of 2010.\n\nThe series was soon commissioned with a 12-episode order on January 19, 2011. The series began filming in Toronto on April 25, 2011, and completed on August 12, 2011, in New York City. Post production for the series was done at Cherry Beach Sound. \"Greenback Boogie\" by Ima Robot serves as the theme song of the show and was released as a single on September 18, 2010, and is included on the band's third album, \"Another Man's Treasure\".\n\nA deleted scene leaked onto YouTube shows Victor Garber as Phillip Hardman, originally part of the pilot, but was ultimately cut during script rewrites. It shows that Hardman had retired from the firm on his own accord. Despite being cut for American audiences, the scene was left in for British viewers when it was first aired, and the scene continues to be included in re-runs.\n\nThe first season premiered on June 23, 2011, and concluded on September 8, 2011. It ran for 12 episodes, including a 90-minute pilot. The complete first season was available on Region 1 DVD on May 1, 2012, and Region A/B Blu-ray on April 10, 2014.\n\n\"Suits\" was renewed for a second season consisting of 16 episodes on August 11, 2011, which premiered on June 14, 2012. The mid-season finale aired on August 23, 2012, with the remaining six episodes returning on January 17, 2013. The complete second season was available on Region 1 DVD on December 2, 2013, and Region A/B Blu-ray on June 26, 2014. On October 12, 2012, the show was renewed for a third season of 16 episodes. Season 3 premiered on July 16, 2013, with the final six episodes airing after March 6, 2014. The complete third season was available on December 22, 2014, on Region 1 DVD and was released on Region A/B Blu-ray on September 1, 2014.\n\nA fourth season of 16 episodes was announced on October 24, 2013. Season 4 premiered on June 11, 2014, with the mid-season finale on August 6, 2014. The complete fourth season was available on June 8, 2015, on Region 1 DVD and was released on Region A/B Blu-ray on June 8, 2015. On August 11, 2014, USA Network announced a fifth season of 16 episodes, which premiered on June 24, 2015. The complete fifth season was available on May 31, 2016 Region 1 DVD and was released on Region A/B Blu-ray on June 6, 2016. The complete sixth season was available on Region 1 DVD on May 30, 2017 and was released on Region A/B Blu-ray on May 29, 2017.\n\nOn July 1, 2015, \"Suits\" was renewed for a sixth season consisting of 16 episodes and premiered on July 13, 2016. The series is available through streaming services on Amazon Video, iTunes, Vudu, and Xfinity.\n\nIn the United Kingdom and Ireland, the first six seasons of \"Suits\" were broadcast on Dave, but the channel chose to drop the series before Season 7, causing Netflix to pick up the UK rights, streaming the programme less than 24 hours after its U.S. broadcast. Netflix did not pick up the rights for Ireland.\n\nThe series has not been released on Blu-ray in the United States or in Canada, but Region A/B releases are readily available in the United Kingdom, Germany, Italy and Spain.\n\n\"Suits\" has received critical acclaim on Metacritic. On Rotten Tomatoes, the series holds an 91% approval rating with the Season 3 consensus reading, \"Though it's occasionally overly wordy, \"Suits\" stimulates with drama derived from the strength of its well-developed characters' relationships.\" Carrie Raisler of \"The A.V. Club\" said, \"\"Suits\" has more internal forward momentum than [al]most anything else on television right now, and when it's on, like it mostly is here, it just cooks.\" Julie Hinds of \"The Detroit Free Press\" said, \"The combination of Gabriel Macht as slick attorney Harvey Specter and Patrick J. Adams as unlicensed legal genius Mike Ross has been a winning one.\"\n\nIn February 2017, USA began early talks for a potential Jessica Pearson spin-off. Gina Torres would star in and produce the spin-off. In August 2017, it was revealed that the season 7 finale of \"Suits\" would serve as a backdoor pilot to the potential Jessica Pearson spin-off series. On March 8, 2018, it was announced the Jessica Pearson spin-off was picked up to series.\n\nJang Dong-gun and Park Hyung-sik will star in a Korean remake of the series, which will be produced by Monster Union and EnterMedia Pictures and be broadcast on KBS2 in 2018.\n\nYūji Oda and Yūto Nakajima will played leading roles in a Japanese remake broadcast by Fuji Television in 2018.\n\n"}
{"id": "23642093", "url": "https://en.wikipedia.org/wiki?curid=23642093", "title": "Superior multimineral process", "text": "Superior multimineral process\n\nThe Superior multimineral process (also known as the McDowell–Wellman process or circular grate process) is an above ground shale oil extraction technology designed for production of shale oil, a type of synthetic crude oil. The process heats oil shale in a sealed horizontal segmented vessel (retort) causing its decomposition into shale oil, oil shale gas and spent residue. The particularities of this process is a recovery of saline minerals from the oil shale, and a doughnut-shape of the retort. The process is suitable for processing of mineral-rich oil shales, such as in the Piceance Basin. It has a relatively high reliability and high oil yield. The technology was developed by the American oil company Superior Oil.\n\nThe multimineral process was developed by Superior Oil Company, now part of ExxonMobil, for processing of the Piceance Basin's oil shale. The technology tests were carried out in pilot plants in Cleveland, Ohio. In the 1970s, Superior Oil planned a commercial-size demonstration plant in the northern Piceance Basin area with a capacity of of shale oil per day; however, because of low crude oil price these plans were never implemented.\n\nThe process was developed to combine the shale oil production with production of sodium bicarbonate, sodium carbonate, and aluminum from nahcolite and dawsonite, occurring in oil shales of the Piceance Basin. In this process, the nahcolite is recovered from the raw oil shale by crushing it to lumps smaller than . As a result, most of the nahcolite in the oil shale becomes a fine powder what could screened out. Screened oil shale lumps are further crushed to particles smaller than . Oil shale particles are further processed in a horizontal segmented doughnut-shaped traveling-grate retort in the direct or indirect heating mode. The retort was originally designed by Davy McKee Corporation for iron ore pelletizing and it also known as the Dravo retort. In the direct retort, oil shale moves past ducts through which are provided hot inert gas for heating the raw oil shale, air for combustion of carbon residue (char or semi-coke) in the spent oil shale, and cold inert gas for cooling the spent oil shale. The oil pyrolysis takes place in the heating section. To minimize solubility of aluminium compounds in the oil shale, the heat control is a crucial factor. Necessary heat for pyrolysis is generated in the carbon recovery section by combustion of carbon residue (char or semi-coke) remained in the spent oil shale. While blowing inert gases through the spent oil shale, the spent oil shale is cooled and gases are heated to cause pyrolysis. The indirect mode is similar; the difference is that combustion of carbonaceous residue takes place in separate vessel. The last section is for discharging of oil shale ash. Aluminium oxide and sodium carbonate are recovered from calcined dawsonite and calcined nahcolite in the oil shale ash.\n\nThe traveling-grate retort allows close temperature control, and therefore better control of dawsonite's solubility during the burning stage. During retorting, there is no relative movement of oil shale, which avoids dust creation, and therefore increase the quality of generated products. The oil recovery yields greater than 98% Fischer Assay. The technology has also a relatively high reliability. The sealed system of this process has environmental advantage as it prevents gas and mist leakage.\n\n"}
{"id": "14555507", "url": "https://en.wikipedia.org/wiki?curid=14555507", "title": "Tables of European biogas utilisation", "text": "Tables of European biogas utilisation\n\nThe following tables outline the utilization of biogas in the European Union as of 2006. This table is likely to change due to the increasing interest in biogas use as a renewable fuel and the tax penalties being imposed on energy or utility companies that waste biogas by burning it off.\n"}
{"id": "23371634", "url": "https://en.wikipedia.org/wiki?curid=23371634", "title": "Technological innovation system", "text": "Technological innovation system\n\nThe technological innovation system is a concept developed within the scientific field of innovation studies which serves to explain the nature and rate of technological change. A Technological Innovation System can be defined as ‘a dynamic network of agents interacting in a specific economic/industrial area under a particular institutional infrastructure and involved in the generation, diffusion, and utilization of technology’.\n\nThe approach may be applied to at least three levels of analysis: to a technology in the sense of a knowledge field, to a product or an artifact, or to a set of related products and artifacts aimed at satisfying a particular (societal) function’. With respect to the latter, the approach has especially proven itself in explaining why and how sustainable (energy) technologies have developed and diffused into a society, or have failed to do so.\n\nThe concept of a technological innovation system was introduced as part of a wider theoretical school, called the innovation system approach.The central idea behind this approach is that determinants of technological change are not (only) to be found in individual firms or in research institutes, but (also) in a broad societal structure in which firms, as well as knowledge institutes, are embedded. Since the 1980s, innovation system studies have pointed out the influence of societal structures on technological change, and indirectly on long-term economic growth, within nations, sectors or technological fields.\n\nThe purpose of analyzing a Technolo is to analyze and evaluate the development of a particular technological field in terms of the structures and processes that support or hamper it. Besides its particular focus, there are two, more analytical, features that set the Technological Innovation System approach apart from other innovation system approaches.\n\nFirstly, the technological innovaion to be built up over time. This was already put forward by Carlsson and Stankiewicz:\n‘[T]echnological Innovation Systems are defined in terms of knowledge/competence flows rather than flows of ordinary goods and services. They consist of dynamic knowledge and competence networks. In the presence of an entrepreneur and sufficient critical mass, such networks can be transformed into development blocks, i.e. synergistic clusters of firms and technologies within an industry or a group of industries.’\n\nThis means that a Technological Innovation System may be analyzed in terms of its system components and/or in terms of its dynamics. Both perspectives will be explained below.\n\nThe system components of a Technological Innovation System are called structures. These represent the static aspect of the system, as they are relatively stable over time. Three basic categories are distinguished:\n\n\nThe structural factors are merely the elements that make up the system. In an actual system, these factors are all linked to each other. If they form dense configurations they are called networks. An example would be a coalition of firms jointly working on the application of a fuel cell, guided by a set of problem-solving routines and supported by a subsidy program. Likewise, industry associations, research communities, policy networks, user-supplier relations etc. are all examples of networks.\n\nAn analysis of structures typically yields insight into systemic features - complementarities and conflicts - that constitute drivers and barriers for technology diffusion at a certain moment or within a given period in time.\n\nStructures involve elements that are relatively stable over time. Nevertheless, for many technologies, especially newly emerging ones, these structures are not yet (fully) in place. For this reason, mostly, the scholars have recently enriched the literature on Technological Innovation Systems with studies that focus on the build-up of structures over time. The central idea of this approach is to consider all activities that contribute to the development, diffusion, and use of innovations as system functions. These system functions are to be understood as types of activities that influence the build-up of a Technological Innovation System. Each system function may be ‘fulfilled’ in a variety of ways. The premise is that, in order to properly develop, the system should positively fulfil all system functions. Various ‘lists’ of system functions have been constructed. Authors like Bergek et al., Hekkert et al., Negro and Suurs give useful overviews. These lists show much overlap and differences reside mostly in the particular way of clustering activities. An example of such a list is provided below.\n\nNote that it is also possible that activities negatively contribute to a system function. These negative contributions imply a (partial) breakdown of the system. In particular, domestic instability has been shown to exert downward pressure on innovation systems, while international threats and national security alliances have a significantly positive effect on national innovative performance.\n\nAs an example, the seven system functions defined by Hekkert are explained here:\n\n\nSince Carlsson and Stankiewicz introduced the concept of a Technological Innovation System, an increasing number of scholars have started focusing on dynamics. A recurring theme within their studies has been the notion of cumulative causation, closely related to the idea of a virtuous circle or vicious circle, by Gunnar Myrdal.\n\nIn this context, cumulative causation is the phenomenon that the build-up of a Technological Innovation System accelerates due to system functions interacting and reinforcing each other over time. For example, the successful realization of a research project, contributing to Knowledge Development, may result in high expectations, contributing to Guidance of the Search, among policy makers, which may, subsequently, trigger the start-up of a subsidy program, contributing to Resource Mobilization, which induces even more research activities: Knowledge Development, Guidance of the Search, etc. System functions may also reinforce each other ‘downwards’. In that case interactions result in conflicting developments or a vicious circle! Recently scholars have increasingly paid attention to the question of how cumulative causation may be established, often with a particular focus on the development of sustainable energy technologies.\n\nTo improve competitiveness and retain sustainability, firms require new technologies and capabilities. In this age of rapid innovation and complexity, it is challenging for the firms to develop internally and remain competitive at the same time. Merger, acquisition and alliance are some of the ways to achieve this, but the primary driver is the desire to obtain valuable resources. Many acquisitions failed to achieve their objectives and resulted in poor performance because of improper implementation.\n\n1. Improper documentation and changing implicit knowledge makes it difficult to share information during acquisition.\n\n2. For acquired firm symbolic and cultural independence which is the base of technology and capabilities are more important than administrative independence.\n\n3. Detailed knowledge exchange and integrations are difficult when the acquired firm is large and high performing.\n\n4. Management of executives from acquired firm is critical in terms of promotions and pay incentives to utilize their talent and value their expertise.\n\n5. Transfer of technologies and capabilities are most difficult task to manage because of complications of acquisition implementation. The risk of losing implicit knowledge is always associated with the fast pace acquisition.\n\nPreservation of tacit knowledge, employees and literature are always delicate during and after acquisition. Strategic management of all these resources is a very important factor for a successful acquisition.\n\nIncrease in acquisitions in our global business environment has pushed us to evaluate the key stake holders of acquisition very carefully before implementation. It is imperative for the acquirer to understand this relationship and apply it to its advantage. Retention is only possible when resources are exchanged and managed without affecting their independence.\n\n\n"}
{"id": "54288469", "url": "https://en.wikipedia.org/wiki?curid=54288469", "title": "Template-Guided Self-Assembly", "text": "Template-Guided Self-Assembly\n\nTemplate-guided self-assembly is a versatile fabrication process that can arrange various micrometer to nanometer sized particles into lithographically created template with defined patterns. The process contain the following four steps.\n\nThe \"template\" can be created by either photolithography or e-beam lithography to define binding sites for various building blocks. The binding sites should reflect the foot print of the building blocks or clusters to be bound.\n\nAfter film development, the created pattern is treated with charged polymers in order to “stick” the particles. Take poly-lysine as an example, the poly-lysine will cover the negatively charged glass surface and turn the charge to be positive; it thus can non-specifically bind negatively charged metallic nanoparticles.\n\nTo do particle assembly, treated pattern is submerged in a small amount of aqueous solution of particles. A few approaches can be used to facilitate the binding efficiency. One of them is to use capillary force at the edge of the aqueous droplet to “push” the particles into the binding sites. If assembling multiple types of particles, the particles should be assembled in the order of decreasing sizes. For example, if assembling both 60 nm gold nanoparticles as well as 40 nm silver nanoparticles, 60 nm gold nanoparticles should be applied first because it is too big to enter binding sites tailored for 40 nm particles. Rationally design the binding sequence as well as the binding site sizes can minimize the binding errors from occurring.\n\nAfter binding of all building blocks, the template can be removed by either dissolving in an organic solvent, or stripped off by a scotch tape. \n"}
{"id": "47489726", "url": "https://en.wikipedia.org/wiki?curid=47489726", "title": "Transient photocurrent", "text": "Transient photocurrent\n\nTransient photocurrent (TPC) is a measurement technique, typically employed in the physics of thin film semiconductors. TPC allows to study the time-dependent (on a microsecond time scale) extraction of charges generated by photovoltaic effect in semiconductor devices, such as solar cells. \n\nA semiconductor is sandwiched between two extracting electrodes. When it is excited with a short pulse of light (as short as 100 femtoseconds), the photogenerated charges are extracted on the electrodes, resulting in a current, which is detected by an oscilloscope in form of voltage across a resistor. Since the excitation pulse is square, there are two ways to measure TPC: in a “light on” and a “light off” positions. In a “Light on”, the signal is recorded as soon as the excitation pulse is switched on, allowing to observe the build-up of charges on the electrode after the start of excitation. “Light off” measurements show how the charges decay after the pulse is switched off.\n\nIn contrast to transient photovoltage, TPC measurements are conducted under short circuit condition and yield information about extractable charges, charge recombination and density of states. Quite often, TPC measurements help to build “drift-diffusion” model which reflects trapping and detrapping of the photogenerated charges and the quality of contact between different layers.\n\nTPC allows varying different measurement parameters, such as intensity or length of the light pulse, applied voltage, etc.\n\n\n"}
{"id": "2482201", "url": "https://en.wikipedia.org/wiki?curid=2482201", "title": "Twink (home perm)", "text": "Twink (home perm)\n\nSilky Curler Twink by Elida was a popular brand of home perm kit that was available in Britain in the late 1960s and 1970s, retailing for about 37 pence. It was promoted using full-page advertisements in women's magazines, such as the leading title \"Woman\", and became a household name. Like some other such kits, its use could produce a strong odour of chemicals in the hair that some found unpleasant. The fashion for home perming subsequently ended and the brand has long since ceased being produced. However, the brand still evokes a sense of nostalgia in some who remember it from their youth and examples of its packaging can be collectors items.\n\nThe British musician and actor Twink, born John Charles Alder, is said to have taken his stage name from the product.\n\nElida Gibbs Limited, based in Kingston upon Thames, Surrey, England was established in 1910 and was renamed Elida Faberge Limited in 1995. It is now a member of the Unilever NV group of companies.\n"}
{"id": "4702515", "url": "https://en.wikipedia.org/wiki?curid=4702515", "title": "Vapor-compression refrigeration", "text": "Vapor-compression refrigeration\n\nVapor-compression refrigeration or vapor-compression refrigeration system (VCRS), in which the refrigerant undergoes phase changes, is one of the many refrigeration cycles and is the most widely used method for air-conditioning of buildings and automobiles. It is also used in domestic and commercial refrigerators, large-scale warehouses for chilled or frozen storage of foods and meats, refrigerated trucks and railroad cars, and a host of other commercial and industrial services. Oil refineries, petrochemical and chemical processing plants, and natural gas processing plants are among the many types of industrial plants that often utilize large vapor-compression refrigeration systems.\n\nRefrigeration may be defined as lowering the temperature of an enclosed space by removing heat from that space and transferring it elsewhere. A device that performs this function may also be called an air conditioner, refrigerator, air source heat pump, geothermal heat pump or chiller (heat pump).\n\nThe vapor-compression uses a circulating liquid refrigerant as the medium which absorbs and removes heat from the space to be cooled and subsequently rejects that heat elsewhere. Figure 1 depicts a typical, single-stage vapor-compression system. All such systems have four components: a compressor, a condenser, a thermal expansion valve (also called a throttle valve or metering device), and an evaporator. Circulating refrigerant enters the compressor in the thermodynamic state known as a saturated vapor and is compressed to a higher pressure, resulting in a higher temperature as well. The hot, compressed vapor is then in the thermodynamic state known as a superheated vapor and it is at a temperature and pressure at which it can be condensed with either cooling water or cooling air flowing across the coil or tubes. This is where the circulating refrigerant rejects heat from the system and the rejected heat is carried away by either the water or the air (whichever may be the case).\n\nThe condensed liquid refrigerant, in the thermodynamic state known as a saturated liquid, is next routed through an expansion valve where it undergoes an abrupt reduction in pressure. That pressure reduction results in the adiabatic flash evaporation of a part of the liquid refrigerant. The auto-refrigeration effect of the adiabatic flash evaporation lowers the temperature of the liquid and vapor refrigerant mixture to where it is colder than the temperature of the enclosed space to be refrigerated.\n\nThe cold mixture is then routed through the coil or tubes in the evaporator. A fan circulates the warm air in the enclosed space across the coil or tubes carrying the cold refrigerant liquid and vapor mixture. That warm air evaporates the liquid part of the cold refrigerant mixture. At the same time, the circulating air is cooled and thus lowers the temperature of the enclosed space to the desired temperature. The evaporator is where the circulating refrigerant absorbs and removes heat which is subsequently rejected in the condenser and transferred elsewhere by the water or air used in the condenser.\n\nTo complete the refrigeration cycle, the refrigerant vapor from the evaporator is again a saturated vapor and is routed back into the compressor.\n\nThe selection of working fluids has a significant impact on the performance of the refrigeration cycles and as such it plays a key role when it comes to designing or simply choosing an ideal machine for a certain task. One of the most widespread refrigerant is \"Freon\". Freon is a trade name for a family of haloalkane refrigerants manufactured by DuPont and other companies. These refrigerants were commonly used due to their superior stability and safety properties: they were not flammable at room temperature and atmospheric pressure, nor obviously toxic as were the fluids they replaced, such as sulfur dioxide. Haloalkanes are also an order(s) of magnitude more expensive than petroleum derived flammable alkanes of similar or better cooling performance. \n\nUnfortunately, chlorine- and fluorine-bearing refrigerants reach the upper atmosphere when they escape. In the stratosphere, CFCs break up due to UV radiation, releasing their chlorine free radicals. These chlorine free radicals act as catalysts in the breakdown of ozone through chain reactions. One CFC molecule can cause thousands of ozone molecules to break down. This causes severe damage to the ozone layer that shields the Earth's surface from the Sun's strong UV radiation, and has been shown to lead to increased rates of skin cancer. The chlorine will remain active as a catalyst until and unless it binds with another particle, forming a stable molecule. CFC refrigerants in common but receding usage include R-11 and R-12. \n\nNewer refrigerants with reduced ozone depletion effect such as HCFCs (R-22, used in most homes today) and HFCs (R-134a, used in most cars) have replaced most CFC use. HCFCs in turn are being phased out under the Montreal Protocol and replaced by hydrofluorocarbons (HFCs), such as R-410A, which lack chlorine. However, CFCs, HCFCs, and HFCs all have large global warming potential.\n\nMore benign refrigerants are currently the subject of research, such as supercritical carbon dioxide, known as R-744. These have similar efficiencies compared to existing CFC and HFC based compounds, and have many orders of magnitude lower global warming potential.\n\nThe thermodynamics of the vapor compression cycle can be analyzed on a temperature versus entropy diagram as depicted in Figure 2. At point 1 in the diagram, the circulating refrigerant enters the compressor as a saturated vapor. From point 1 to point 2, the vapor is isentropically compressed (compressed at constant entropy) and exits the compressor as a superheated vapor.\n\nFrom point 2 to point 3, the vapor travels through part of the condenser which removes the superheat by cooling the vapor. Between point 3 and point 4, the vapor travels through the remainder of the condenser and is condensed into a saturated liquid. The condensation process occurs at essentially constant pressure.\n\nBetween points 4 and 5, the saturated liquid refrigerant passes through the expansion valve and undergoes an abrupt decrease of pressure. That process results in the adiabatic flash evaporation and auto-refrigeration of a portion of the liquid (typically, less than half of the liquid flashes). The adiabatic flash evaporation process is isenthalpic (occurs at constant enthalpy).\n\nBetween points 5 and 1, the cold and partially vaporized refrigerant travels through the coil or tubes in the evaporator where it is totally vaporized by the warm air (from the space being refrigerated) that a fan circulates across the coil or tubes in the\nevaporator. The evaporator operates at essentially constant pressure and boils off all available liquid there after adding 4–8 kelvins of superheat to the refrigerant as a safeguard for the compressor as it cannot pump liquid.\nThe resulting refrigerant vapor returns to the compressor inlet at point 1 to complete the thermodynamic cycle.\n\nIt should be noted that the above discussion is based on the ideal vapor-compression refrigeration cycle which does not take into account real world items like frictional pressure drop in the system, slight internal irreversibility during the compression of the refrigerant vapor, or non-ideal gas behavior (if any).\n\nThe most common compressors used in chillers are reciprocating, rotary screw, centrifugal, and scroll compressors. Each application prefers one or another due to size, noise, efficiency and pressure issues. Compressors are often described as being either open, hermetic, or semi-hermetic, to describe how the compressor and/or motor is situated in relation to the refrigerant being compressed. Variations of motor/compressor types can lead to the following configurations:\n\nTypically in hermetic, and most semi-hermetic compressors (sometimes known as accessible hermetic compressors), the compressor and motor driving the compressor are integrated, and operate within the refrigerant system. The motor is hermetic and is designed to operate, and be cooled by, the refrigerant being compressed. The obvious disadvantage of hermetic motor compressors is that the motor drive cannot be maintained in situ, and the entire compressor must be removed if a motor fails. A further disadvantage is that burnt out windings can contaminate whole refrigeration systems requiring the system to be entirely pumped down and the refrigerant replaced.\n\nAn open compressor has a motor drive which is outside of the refrigeration system, and provides drive to the compressor by means of an input shaft with suitable gland seals. Open compressor motors are typically air-cooled and can be fairly easily exchanged or repaired without degassing of the refrigeration system. The disadvantage of this type of compressor is a failure of the shaft seals, leading to loss of refrigerant.\n\nOpen motor compressors are generally easier to cool (using ambient air) and therefore tend to be simpler in design and more reliable, especially in high pressure applications where compressed gas temperatures can be very high. However the use of liquid injection for additional cooling can generally overcome this issue in most hermetic motor compressors.\n\nReciprocating compressors are piston-style, positive displacement compressors.\n\nRotary screw compressors are also positive displacement compressors. Two meshing screw-rotors rotate in opposite directions, trapping refrigerant vapor, and reducing the volume of the refrigerant along the rotors to the discharge point.\n\nCentrifugal compressors are dynamic compressors. These compressors raise the pressure of the refrigerant by imparting velocity or dynamic energy, using a rotating impeller, and converting it to pressure energy.\n\nScroll compressors are also positive displacement compressors. The refrigerant is compressed when one spiral orbits around a second stationary spiral, creating smaller and smaller pockets and higher pressures. By the time the refrigerant is discharged, it is fully pressurized.\n\nIn order to lubricate the moving parts of the compressor, oil is added to the refrigerant during installation or commissioning. The type of oil may be mineral or synthetic to suit the compressor type, and also chosen so as not to react with the refrigerant type and other components in the system. In small refrigeration systems the oil is allowed to circulate throughout the whole circuit, but care must be taken to design the pipework and components such that oil can drain back under gravity to the compressor. In larger more distributed systems, especially in retail refrigeration, the oil is normally captured at an oil separator immediately after the compressor, and is in turn re-delivered, by an oil level management system, back to the compressor(s). Oil separators are not 100% efficient so system pipework must still be designed so that oil can drain back by gravity to the oil separator or compressor.\n\nSome newer compressor technologies use magnetic bearings and require no lubrication, for example the Danfoss Turbocor range of centrifugal compressors. Avoiding the need for oil lubrication and the design requirements and ancillaries associated with it, simplifies the design of the refrigerant system and reduces maintenance requirements.\n\nIn simple commercial refrigeration systems the compressor is normally controlled by a simple pressure switch, with the expansion performed by a capillary tube or simple thermostatic expansion valve. In more complex systems, including multiple compressor installations, the use of electronic controls is typical, with adjustable set points to control the pressure at which compressors cut in and cut out, and temperature control by the use of electronic expansion valves.\n\nIn addition to the operational controls, separate high pressure and low pressure switches are normally utilised to provide secondary protection to the compressors and other components of the system from operating outside of safe parameters.\n\nIn more advanced electronic control systems the use of floating head pressure, and proactive suction pressure, control routines allow the compressor operation to be adjusted to accurately meet differing cooling demands whilst reducing energy consumption.\n\nThe schematic diagram of a single-stage refrigeration system shown in Figure 1 does not include other equipment items that would be provided in a large commercial or industrial vapor compression refrigeration system, such as:\n\n\nThe cooling capacity of refrigeration systems is often defined in units called \"tons of refrigeration\". The most common definition of that unit is: 1 ton of refrigeration is the rate of heat removal required to freeze a short ton (i.e., , ) of water at () in . Based on the heat of fusion for water being 144 Btu per pound, 1 ton of refrigeration = 12,000 Btu/h = 12,660 kJ/h = . Most residential air conditioning units range in capacity from about 1 to 5 tons () of refrigeration.\n\nA much less common definition is: 1 tonne of refrigeration is the rate of heat removal required to freeze a metric ton (i.e., ) of water at in . Based on the heat of fusion being , 1 tonne of refrigeration = 13,954 kJ/h = . As can be seen, the definition of 1 tonne of refrigeration in metric units is 10 percent larger than 1 ton of refrigeration using imperial units.\n\n\nMany systems still use HCFC refrigerants, which contribute to depletion of the Earth's ozone layer. In countries adhering to the Montreal Protocol, HCFCs are due to be phased out and are largely being replaced by ozone-friendly HFCs. However, systems using HFC refrigerants tend to be slightly less efficient than systems using HCFCs. HFCs also have an extremely large global warming potential, because they remain in the atmosphere for many years and trap heat more effectively than carbon dioxide.\n\nWith the ultimate phasing out of HCFCs already a certainty, alternative non-haloalkane refrigerants are gaining popularity. In particular, once-abandoned refrigerants such as hydrocarbons (butane for example) and CO are coming back into more extensive use. For example, Coca-Cola's vending machines at the 2006 FIFA World Cup in Germany used refrigeration utilizing CO. Ammonia (NH) is one of the oldest refrigerants, with excellent performance and essentially no pollution problems. However, ammonia has two disadvantages: it is toxic and it is incompatible with copper tubing.\n\nIn 1805, the American inventor Oliver Evans described a closed vapor-compression refrigeration cycle for the production of ice by ether under vacuum. Heat would be removed from the environment by recycling vaporized refrigerant, where it would move through a compressor and condenser and would eventually revert to a liquid form in order to repeat the refrigeration process over again. However, no such refrigeration unit was built by Evans.\n\nIn 1834, an American expatriate to Great Britain, Jacob Perkins, built the first working vapor-compression refrigeration system in the world. It was a closed-cycle that could operate continuously, as he described in his patent:\n\nHis prototype system worked although it did not succeed commercially.\n\nA similar attempt was made in 1842, by American physician, John Gorrie, who built a working prototype, but it was a commercial failure. American engineer Alexander Twining took out a British patent in 1850 for a vapor compression system that used ether.\nThe first practical vapor compression refrigeration system was built by James Harrison, a British journalist who had emigrated to Australia. His 1856 patent was for a vapor compression system using ether, alcohol or ammonia. He built a mechanical ice-making machine in 1851 on the banks of the Barwon River at Rocky Point in Geelong, Victoria, and his first commercial ice-making machine followed in 1854. Harrison also introduced commercial vapor-compression refrigeration to breweries and meat packing houses, and by 1861, a dozen of his systems were in operation in Australia and England.\n\nThe first gas absorption refrigeration system using gaseous ammonia dissolved in water (referred to as \"aqua ammonia\") was developed by Ferdinand Carré of France in 1859 and patented in 1860. Carl von Linde, an engineering professor at the Technological University Munich in Germany, patented an improved method of liquefying gases in 1876. His new process made possible using gases such as ammonia, sulfur dioxide and methyl chloride (CHCl) as refrigerants and they were widely used for that purpose until the late 1920s.\n\n\n"}
{"id": "6884040", "url": "https://en.wikipedia.org/wiki?curid=6884040", "title": "Veľké Kostoľany transmitter", "text": "Veľké Kostoľany transmitter\n\nVelke Kostolany transmitter is the main transmission facility of Slovakian broadcasting company, situated north of Velke Kostolany near Nitra and also known as \"Nitra transmitter\". It was inaugurated in 1949 and is used for mediumwave and shortwave broadcasting. For mediumwave broadcasting a 140 metres tall guyed mast is used. Until 2003 it transmitted in the mediumwave band on 1098 kHz with omnidirectional radiation, today the radiated power may be only fifty kilowatts.\n"}
{"id": "11078950", "url": "https://en.wikipedia.org/wiki?curid=11078950", "title": "Wheel chock", "text": "Wheel chock\n\nWheel chocks (or chocks) are wedges of sturdy material placed closely against a vehicle's wheels to prevent accidental movement. Chocks are placed for safety in addition to setting the brakes. The bottom surface is sometimes coated in rubber to enhance grip with the ground. For ease of removal, a rope may be tied to the chock or a set of two chocks. One edge of the wedge has a concave profile to contour to the wheel and increase the force necessary to overrun the chock. Most commonly, chocks are seen on aircraft and train cars.\n\nAutomobiles usually have parking brakes on the rear wheels. If the rear axle is jacked off the ground with only the parking brake set, the vehicle may roll on the front wheels and fall. Chocking the front wheels prevents this mishap. Regular trailers, except for motorhomes, normally do not have parking brakes, and there is no other factory mechanism that can control rear or front rocking movement, so it’s recommended by NHSA that wheel chocks be used. For tent trailers, it is enough to install one single-tire chock. Alternatively, a tire-locking chock can be installed for trailer stability. It is recommended to use dual or triple-axle locking chocks for travel or 5th-wheel trailers.\n\nMotorcycle and bicycle chocks are bifurcated and fit around the wheel, supporting the bike and preventing its movement.\n\nThe mining industry uses wheel chocks to protect lubrication trucks and heavy maintenance vehicles from slipping on off-road terrain when placed in Park. The huge haul trucks, which can weigh up to 450 tonnes, require a much larger wheel chock that itself will weigh almost 40 kilograms. These circumstances will benefit from urethane wheel chocks that are lightweight enough to be maneuvered, yet can withstand the responsibility of holding a truck if a brake should fail. The Mine Safety and Health Administration (MSHA) has established standards that wheel chocks are used when a vehicle is parked on a grade, and OSHA has guidelines that require wheel chocks during loading or unloading of a heavy truck.\n\nTo use, wheel chocks must be selected to match the size of the tires on the vehicle and used in pairs, as the size of the tire is designed to be proportional to the vehicle's weight and size. For a maximum slope of approximately 15.6 degrees, use a chock 1/4 height of the wheel as per SAE J348. The maximum slope angle for any given chock is formula_1. For example, for a chock 1/6 the height of the wheel, the maximum slope angle would be 10 degrees. Some manufacturers recommend wheel chocks that are slightly bigger than 1/4 the height of the wheel.\n\nThree main factors affect the performance of wheel chocks:\n\nWheel chocks must be used on a level surface; some rubber wheel chocks have steel grates and ice cleat accessories. The vehicle is placed in park (on vehicles with automatic gearboxes) and the parking or emergency brake is applied. The wheel chocks are then snugly positioned against the center of the tires in the direction of the grade, on both the left and right side of the vehicle. On even surfaces, chocks are applied to the rear-facing as well as the front-facing side of each tire.\n\nA parking space commonly contains a parking chock, a barrier which is used to prevent cars from pulling too far into the space and obstructing an adjacent parking space, curb, or sidewalk.\n\nThis barrier, also called a parking stop or a turtarrier, is usually made of concrete or recycled plastic and will normally be a horizontal bar to prevent the tires from moving forward or a vertical bar that may cause damage to the vehicle if contact is made. In a parking garage, the barrier will often be a concrete wall. The recycled plastic parking stops are more lightweight than concrete and will not crack or chip. This lighter version can be installed by one person and will resist auto oils and fuels and will never need maintenance such as repainting.\n"}
{"id": "9012599", "url": "https://en.wikipedia.org/wiki?curid=9012599", "title": "White oil", "text": "White oil\n\nWhite oil is a homemade insecticide spray used for controlling a wide range of insect pests in the garden. The spray works by blocking the breathing pores of insects, causing suffocation and death. It is effective in the control of aphids, scale, mealybug, mites, citrus leaf miner and smooth skinned caterpillars.\n\n\"White oil\" is also an alternative name for mineral oil.\n\nThe quantities vary depending on the source, but a typical mixture is 4 parts of vegetable oil (a non-mineral oil) to one part of dish-washing detergent (for washing by hand). It may be blended in a mixer until homogeneous to be stored. Diluting 1:50 with water may be used for spraying leaves from above and below.\n\n"}
