{"id": "37014888", "url": "https://en.wikipedia.org/wiki?curid=37014888", "title": "Advanced fire information system", "text": "Advanced fire information system\n\nThe advanced fire information system (AFIS) provides information on current and historical fires detected by sensors on Earth observation satellites, e.g. NASA MODIS, EUMETSAT MSG, GOES, NPP, etc. covering multiple regions across the globe. The system provides monitoring of active fire on a web-based map and delivers near real-time alerts to registered users when a fire is detected within their specified areas of interest via email, SMS, XMPP, etc.\n\nThe system started as a research project at the CSIR Meraka Institute in collaboration with Eskom in 2007. It was then extended to support many fire protection associations in South Africa.\n\n"}
{"id": "10061589", "url": "https://en.wikipedia.org/wiki?curid=10061589", "title": "Ampeg Portaflex", "text": "Ampeg Portaflex\n\nThe Portaflex is a line of amplifiers for electric guitars and bass guitars created by Ampeg. Originally designed by Jess Oliver, the main characteristic of the Portaflex is that the head of the amplifier is stored inside the cabinet and flips over when being used. The Portaflex line has many different configurations.\n\nAmpeg manufactured the Portaflex SB-12 model amplifier from 1965-1971. This lightweight (67 pound) cabinet incorporated the flip-top design of other larger Portaflex amplifiers of the time. Although the SB-12 isn't as well known as the more powerful B-15, it is still highly sought after by musicians who use it mainly for studio recording.\n\nThe 'SB' in SB-12 stood for string bass; the '12' indicates the diameter of the speaker in inches. It contained a single-channel, 25-watt tube amplifier and a single Jensen speaker. Unlike bulk of the Portaflex line of bass amplifiers, the SB-12 was designed as a universal amplifier. It incorporated two separate inputs, one labeled \"Bass\" and the other \"Instruments\".\n\n\n\n"}
{"id": "164536", "url": "https://en.wikipedia.org/wiki?curid=164536", "title": "Aviation accidents and incidents", "text": "Aviation accidents and incidents\n\nIn aviation, an accident is defined by the Convention on International Civil Aviation Annex 13 as an occurrence associated with the operation of an aircraft, which takes place from the time any person boards the aircraft with the intention of flight until all such persons have disembarked, and in which a) a person is fatally or seriously injured, b) the aircraft sustains significant damage or structural failure, or c) the aircraft goes missing or becomes completely inaccessible. Annex 13 defines an incident as an occurrence, other than an accident, associated with the operation of an aircraft that affects or could affect the safety of operation.\n\nA hull loss occurs if an aircraft is destroyed, damaged beyond repair, lost, or becomes completely inaccessible.\n\nThe first fatal aviation accident was the crash of a Rozière balloon near Wimereux, France, on June 15, 1785, killing the balloon's inventor, Jean-François Pilâtre de Rozier, and the other occupant, Pierre Romain. The first involving a powered aircraft was the crash of a Wright Model A aircraft at Fort Myer, Virginia, in the United States on September 17, 1908, injuring its co-inventor and pilot, Orville Wright, and killing the passenger, Signal Corps Lieutenant Thomas Selfridge.\n\n2,996: The deadliest aviation-related disaster of any kind, considering fatalities on both the aircraft and the ground, was the destruction of the World Trade Center in New York City on September 11, 2001. On that morning four aircraft traveling on transcontinental flights from East Coast airports to California were hijacked after takeoff, and used in four separate suicide attacks against major American landmarks by 19 Islamic terrorists affiliated with Al Qaeda. American Airlines Flight 11 and United Airlines Flight 175 were intentionally crashed into the North and South Towers respectively of the World Trade Center, destroying both buildings in less than two hours. The World Trade Center crashes killed 2,753, the vast majority of fatalities being occupants of the World Trade Center towers or emergency personnel responding to the disaster. In addition, 184 were killed by American Airlines Flight 77, which crashed into The Pentagon (causing severe damage and partial destruction to the building's west side). 40 passengers were also killed when United Airlines Flight 93 crashed into a Somerset County Pennsylvania field after passengers fought back and prevented the hijackers from reaching their designated target. This brought the total number of casualties of the September 11 attacks to 2,996 (including the 19 terrorist hijackers). As deliberate terrorist acts, the 9/11 crashes were not classified as accidents, but as mass murder-suicide; these events were subsequently treated by the United States and the member nations of NATO as an act of war and terrorism.\n\n583: The Tenerife airport disaster, which occurred on March 27, 1977, remains the accident with the highest number of airliner passenger fatalities. 583 people died when a KLM Boeing 747 attempted to take off without flight clearance, and collided with a taxiing Pan Am 747 at Los Rodeos Airport on the Canary Island of Tenerife, Spain. There were no survivors from the KLM aircraft; 61 of the 396 passengers and crew on the Pan Am aircraft survived. Pilot error was the primary cause, as the KLM captain began his takeoff run without obtaining air traffic control clearance. A contributing factor was the dense fog. The KLM flight crew could not see the Pan Am aircraft on the runway until immediately before the collision. The accident had a lasting influence on the industry, particularly in the area of communication. An increased emphasis was placed on using standardized phraseology in air traffic control (ATC) communication by both controllers and pilots alike. \"Cockpit Resource Management\" has also been incorporated into flight crew training. The captain is no longer considered infallible, and combined crew input is encouraged during aircraft operations.\n\n520: The crash of Japan Airlines Flight 123 on August 12, 1985, is the single-aircraft disaster with the highest number of fatalities: 520 people died on board a Boeing 747. The aircraft suffered an explosive decompression from an incorrectly repaired aft pressure bulkhead, which failed in mid flight, destroying most of its vertical stabilizer and severing all of the hydraulic lines, making the 747 virtually uncontrollable. Pilots were able to keep the plane flying for 32 minutes after the mechanical failure before crashing into a mountain. All 15 crew members and 505 of the 509 passengers on board died. The death toll was exacerbated by delays in the rescue operation. Although a number of people survived the impact, by the time the Japanese rescue teams arrived at the crash site all but four had succumbed to their injuries.\n\n349: On November 12, 1996, the world's deadliest mid-air collision was the Charkhi Dadri mid-air collision involving Saudia Flight 763 and Kazakhstan Airlines Flight 1907 over Charkhi Dadri, India. The collision was mainly the result of the Kazakh pilot flying lower than the assigned clearance altitude. All 349 passengers and crew on board of both the aircraft died. The Ramesh Chandra Lahoti Commission, empowered to study the causes, recommended the creation of the \"semi-circular rule\", to prevent aircraft from flying in opposite directions at the same altitude. The Civil Aviation Authorities in India made it mandatory for all aircraft flying in and out of India to be equipped with a Traffic Collision Avoidance System (TCAS), setting a worldwide precedent for mandatory use of TCAS.\n\n346: On March 3, 1974, Turkish Airlines Flight 981, a McDonnell Douglas DC-10, crashed in a forest northeast of Paris, France. The London-bound plane crashed shortly after taking off from Orly airport; all 346 people on board died. It was later determined that the cargo door detached, which caused an explosive decompression; this caused the floor just above to collapse. The collapsed floor severed the control cables, which left the pilots without control of the elevators, the rudder and No. 2 engine. The plane entered a steep dive and crashed. It was the deadliest plane crash of all time until the Tenerife disaster in 1977.\n\n329: On June 23, 1985, Air India Flight 182, a Boeing 747-237B, crashed off the southwest coast of Ireland when a bomb exploded in the cargo hold. All 307 passengers and 22 crew members died. One passenger had checked in as \"M. Singh\". Singh did not board the flight. His suitcase containing the bomb was loaded onto the plane, however. \"Mr Singh\" was never identified or captured. It was later determined Sikh extremists were behind the bombing as a retaliation for the Indian government's attack on the Golden Temple in the city of Amritsar, which is very important for the Sikhs. This was, at the time, the deadliest terrorist attack involving an airplane.\n\n301: On August 19, 1980, Saudi Arabian Airlines Flight 163, a Lockheed L-1011, became the world's deadliest aviation accident that did not involve a crash. The crew performed an emergency landing at Riyadh after a fire broke out in an aft baggage compartment. The fire burned through the ceiling of the compartment and into the passenger cabin. While the crew managed to land the plane safely, the captain did not stop immediately and order an evacuation. He taxied off the runway instead, by which time everyone in the cabin had become unconscious due to fumes and unable to open any doors or evacuate. All 301 passengers and crew died of suffocation before rescue ground crews could open any door, after which the aircraft burst into flames and was consumed by fire.\n\n298: On July 17, 2014, Malaysia Airlines Flight 17, a Boeing 777-200ER, flying from Amsterdam to Kuala Lumpur with 298 people on board, was shot down in an area of Eastern Ukraine near the Ukraine/Russian border during Russian invasion of Ukraine. There were 283 passengers, including 3 infants, and 15 crew members on board MH17, all of whom perished. The crew were all Malaysians, while the passengers were of various nationalities, most from the Netherlands. According to a Dutch report, high-energy objects hit the plane in midair, causing it to break apart. According to the preliminary report of the international investigation commission, the plane was shot down by Russian occupation troops using a surface-to-air missile fired from the Ukrainian territory that they occupied. This was the deadliest incident involving a Boeing 777.\n\n290: On July 3, 1988, Iran Air Flight 655, an Iranian Airbus A300-200 airliner, was shot down by two surface-to-air missiles from the U.S. Navy guided missile cruiser USS \"Vincennes\" over the Strait of Hormuz. All 290 passengers and crew aboard the aircraft died.\n\n275: On February 19, 2003, an Iranian military Ilyushin Il-76 crashed in mountainous terrain near Kerman in Iran. The official report says bad weather brought the aircraft down; high winds and fog were present at the time of the crash.\n\n273: On May 25, 1979, American Airlines Flight 191, A McDonnell Douglas DC-10-10, crashed shortly after lifting off the runway at Chicago O'Hare Airport after the number one (left) engine and pylon separated from the wing. This broke hydraulic lines, causing leading edge lift devices to retract on that side of the aircraft and resulted in asymmetrical lift and loss of control. The accident was attributed to improper maintenance procedures. The crash resulted in the deaths of all 271 passengers and crew on board, as well as two people on the ground. It remains the deadliest commercial aircraft accident in United States history, and was also the country's deadliest aviation disaster until the September 11 attacks in 2001.\n\n270: On December 21, 1988, Pan Am Flight 103, a Boeing 747–121 bound for New York–JFK from London–Heathrow with continued service to Detroit, was destroyed by a terrorist bomb over the town of Lockerbie, Scotland. All 243 passengers and 16 crew, and 11 people on the ground (all residents of Sherwood Crescent, Lockerbie), died,\nmaking it the worst terrorist attack involving an aircraft in the UK and the deadliest terrorist attack on British soil. Following the crash, the Federal Aviation Administration imposed new security measures on American airlines flying out of 103 airports in Western Europe and the Middle East.\n\n269: On September 1, 1983, a Soviet interceptor Sukhoi Su-15 shot down Korean Air Lines Flight 007, a Boeing 747-230B, bound for Gimpo International Airport in Seoul, South Korea, after it flew into Soviet airspace; all 269 passengers and crew on board died.\n\n265: On November 12, 2001, American Airlines Flight 587, an Airbus A300, crashed in the Belle Harbor neighborhood of Queens, New York, just after departing John F. Kennedy International Airport bound for Las Américas International Airport, Santo Domingo. The first officer's overuse of the rudder in response to wake turbulence from a Japan Airlines 747 was cited as cause. All 260 people on board, as well as five people on the ground, died from the crash. It is the second-deadliest aviation accident on U.S. soil, after American Airlines Flight 191.\n\n264: On April 26, 1994, China Airlines Flight 140 was completing a routine flight and approach at Nagoya Airport, Japan, when the Airbus A300B4-622R's First Officer inadvertently pressed the Takeoff/Go-around button, which raises the throttle position to the same as take offs and go-arounds. The action and the two pilots' reaction resulted in a crash that killed 264 (15 crew and 249 passengers) of the 271 people aboard.\n\n261: On July 11, 1991, Nigeria Airways Flight 2120, a Douglas DC-8-61 aircraft operated by Nationair Canada, crashed in Jeddah, Saudi Arabia, after two tires ignited upon takeoff, leading to an in-flight fire. All 247 passengers and 14 crew members were killed. It is the deadliest aviation accident involving a DC-8, the largest aviation disaster involving a Canadian-registered aircraft and the second-worst accident in Saudi Arabia.\n\n257: On April 11, 2018, an Algerian Air Force Il-76 transport plane crashed shortly after take-off from Boufarik Airport, killing all 247 passengers and 10 crew on board.\n\n257: On November 28, 1979, Air New Zealand Flight 901, an Antarctic sightseeing flight, collided with Mount Erebus on Ross Island, Antarctica, killing all 237 passengers and 20 crew on board. The flight crew had not been informed that the computer coordinates for the flight path of the McDonnell Douglas DC-10-30 had been changed the night before, directing the flight directly into Mount Erebus rather than the usual path down McMurdo Sound.\n\n256: On December 12, 1985, a Douglas DC-8, Arrow Air Flight 1285, carrying American military personnel on a charter flight home for Christmas, crashed in Newfoundland; all 248 passengers and 8 crew members died. The Canadian Aviation Safety Board investigating the cause of the crash issued two different reports: the majority report cited ice on the wings as cause of the crash; the minority report suggests an explosion was the likely cause.\n\n239: On March 8, 2014, a Boeing 777-200ER, Malaysia Airlines Flight 370, flying from Kuala Lumpur, Malaysia, to Beijing, China, lost contact with air traffic controllers over the South China Sea, deviated from its planned route, and was presumed lost in the southern Indian Ocean. It carried 12 Malaysian crew members and 227 passengers from 15 nations. A multinational search effort, the most extensive and expensive in aviation history, has thus far failed to locate them, though debris from the aircraft were recovered on July 29, 2015, on Réunion Island. Numerous theories have been offered to explain the disappearance of the flight, but none has been confirmed.\n\n234: On September 26, 1997, an Airbus A300B4-220, Garuda Indonesia Flight 152, which departed from Jakarta, Indonesia, and was preparing to land at Medan, North Sumatra, crashed into mountainous terrain, killing 222 passengers and 12 crew members. The causes included turning left instead of right as instructed by the ATC and descending below the assigned altitude of 2,000 feet due to pilot error.\n\n230: On July 17, 1996, a Boeing 747-131, TWA Flight 800, carrying 212 passengers and 18 crew, exploded and crashed into the Atlantic Ocean near East Moriches, New York, shortly after departing from John F. Kennedy International Airport on a flight to Paris and Rome. A lengthy investigation concluded that the probable cause of the accident was a short circuit in a fuel tank that contained an explosive mixture of fuel vapor and air. As a result, new requirements were developed to prevent future fuel tank explosions in aircraft.\n\n229: On September 2, 1998, a McDonnell Douglas MD-11, Swissair Flight 111, carrying 215 passengers and 14 crew from New York City to Geneva, Switzerland crashed into the Atlantic Ocean near Halifax, Nova Scotia, Canada, killing all aboard. After a lengthy investigation, an official report stated that flammable material used in the aircraft's structure, specifically the Personal TV Systems recently installed in the Business Class Cabin, allowed a fire to spread, resulting in a loss of control.\n\n228: On June 1, 2009, an Airbus A330-203, Air France Flight 447, carrying 216 passengers and 12 crew, was en route from Rio de Janeiro, Brazil to Paris, France, when it crashed into the Atlantic Ocean. The aircraft's flight recorders were not recovered from the ocean floor until May 2011, and the final investigative report was released in July 2012. It determined that the disaster was likely due to the aircraft's pitot tubes being obstructed by ice crystals, causing the autopilot to disconnect. The crew reacted incorrectly, leading to an aerodynamic stall from which the jet did not recover.\n\n228: On August 6, 1997, a Boeing 747-3B5, Korean Air Flight 801, crashed on approach to the international airport in the United States territory of Guam, killing 228 of the 254 people aboard. Contributing factors in the crash were fatigue and errors by the flight crew, inadequate flight crew training, and a modification of the airport's altitude warning system that prevented it from detecting aircraft below a minimum safe altitude.\n\n227: On January 8, 1996, an Antonov An-32B aircraft with 6 crew members on board overshot the runway at Kahemba Airport and plowed into a market place. Four on board survived but 225 people on the ground were killed and an estimated 500 were injured (estimated 253 seriously injured). It is the crash with the most non-passenger ground fatalities (not including 9/11). It is usually known as the 1996 Air Africa crash.\n\n225: On May 25, 2002, a Boeing 747-209B, China Airlines Flight 611, bound for Hong Kong International Airport in Hong Kong, disintegrated in mid-air and crashed into the Taiwan Strait 20 minutes after takeoff from Chiang Kai-shek International Airport (now Taiwan Taoyuan International Airport) in Taiwan. It was determined that the crash, which killed all 206 passengers and 19 crewmembers aboard the plane, was caused by improper repairs to the aircraft 22 years earlier when the aircraft encountered a tailstrike.\n\n224: On October 31, 2015, an Airbus A321-231, Metrojet Flight 9268, crashed in the Sinai Peninsula after departing Sharm el-Sheikh International Airport, Egypt, en route to Pulkovo Airport, Saint Petersburg, Russia. All 217 passengers and 7 crewmembers were killed. A branch of the Islamic State of Iraq and the Levant claimed responsibility for bringing down the jet, and a Russian investigation concluded that a bomb was detonated inside the plane at a high altitude.\n\n223: On May 26, 1991, a Boeing 767-3Z9ER, Lauda Air Flight 004, broke up in midair over a remote area of Thailand due to an uncommanded deployment of a thrust reverser on one of the plane's engines, killing all 213 passengers and 10 crewmembers aboard. The flight, which originated at Kai Tak Airport, Hong Kong, and made a stopover at Don Mueang International Airport in Bangkok, Thailand, was en route to Vienna International Airport, Vienna, Austria, when the accident occurred.\n\n217: On October 31, 1999, a Boeing 767-366ER, EgyptAir Flight 990, flying from Los Angeles International Airport, United States, to Cairo International Airport, Egypt, with a stop at John F. Kennedy International Airport, New York City, crashed into the Atlantic Ocean south of Nantucket Island, Massachusetts, killing all 203 passengers and 14 crewmembers. The National Transportation Safety Board determined that the probable cause of the crash was deliberate action by the relief first officer in response to his removal from international service within Egyptair, a finding disputed by Egyptian authorities who maintain another cause of the accident.\n\n213: On January 1, 1978, a Boeing 747-237B, Air India Flight 855, crashed into the Arabian Sea just off the coast of Bombay, India, killing all 190 passengers and 23 crew on board. An investigation concluded that the captain became disoriented after the failure of one of the flight instruments in the cockpit, leading to \"irrational control inputs\" that caused the plane to crash.\n\n203: On February 16, 1998, an Airbus A300B4-622R, China Airlines Flight 676, en route from Ngurah Rai Airport in Bali, Indonesia, to Chiang Kai-shek International Airport (now Taoyuan International Airport), Taiwan, crashed into a road and residential neighborhood in Taoyuan, Taiwan, killing 182 passengers, 14 crew, and 7 people on the ground. An investigation determined that when the control tower ordered the pilot to abort his landing and \"go around\" for a second attempt, the pilot, who had unintentionally released the plane's autopilot, did nothing to take control of the plane for 11 seconds as he apparently thought the autopilot would initiate the go around. As the aircraft approached the airport, the pilot executed a sudden steep ascent that produced a stall and crash. China Airlines was also criticized for \"insufficient training.\"\n\n200: On July 10, 1985, a Tupolev Tu-154B-2, Aeroflot Flight 7425, on a domestic Karshi–Ufa–Leningrad route, crashed near Uchkuduk, Uzbek SSR, Soviet Union, on the second leg of its route. All 191 passengers and 9 crew were killed. An investigation concluded that the plane went down due to pilot error. The air crew used an inappropriately low airspeed, causing vibrations that they incorrectly interpreted as engine surges. As a result, they further reduced engine power, causing the aircraft to stall and crash.\n\nIn over one hundred years of implementation, aviation safety has improved considerably. In modern times, two major manufacturers still produce heavy passenger aircraft for the civilian market: Boeing in the United States of America, and the European company Airbus. Both place huge emphasis on the use of aviation safety equipment, now a billion-dollar industry in its own right; for each, safety is a major selling point—realizing that a poor safety record in the aviation industry is a threat to corporate survival. Some major safety devices now required in commercial aircraft involve:\n\nMeasured on a passenger-distance calculation, air travel is the safest form of transportation available: Figures mentioned are the ones shared by the air industry when quoting air safety statistics. A typical statement, e.g., by the BBC: \"UK airline operations are among the safest anywhere. When compared to all other modes of transport, on a 'fatality per mile basis', air transport is the safest — six times safer than traveling by car; twice as safe as rail.\"\n\nWhen measured by fatalities per person transported, however, buses are the safest form of transportation. The number of air travel fatalities per person is surpassed only by bicycles and motorcycles. This statistic is used by the insurance industry when calculating insurance rates for air travel.\n\nPer every billion kilometers traveled, trains have a fatality rate 12 times over air travel; by comparison, fatality rates for automobiles are 62 times greater than air travel. By contrast, for every billion journeys, buses are the safest form of transportation. By the last measure, air transportation is three times more dangerous than car transportation, and almost 30 times more dangerous than bus.\nA 2007 study by \"Popular Mechanics\" found passengers sitting at the back of a plane are 40% more likely to survive a crash than those sitting in the front. Although this article quotes Boeing, the FAA and a website on aircraft safety, all claim there is no \"safest\" seat. The article studied 20 crashes, not taking into account the developments in safety after those accidents. A flight data recorder is usually mounted in the aircraft's empennage (tail section), however, where it is more likely to survive a severe crash.\n\nOver 95% of people in U.S. plane crashes, between 1983 and 2000, survived.\n\nIn efforts to prevent incidents such as the disappearance of Malaysia Airlines Flight MH370, a new standard has been issued for all commercial aircraft to report their position every 15 minutes to air traffic controllers regardless of the country of origin. The regulation was taken into effect in 2016 by the ICAO, and requires no new aircraft equipment so long as airlines adhere to it. This requirement is part of a long-term plan, in which by 2020 ICAO will require new aircraft be fitted with data broadcast systems that air traffic controllers are in constant contact with. The plan is called the Global Aeronautical Distress and Safety System.\n\nThe Aviation Safety Reporting System (ASRS) collects voluntarily submitted aviation safety incident/situation reports from pilots, controllers and others. The ASRS uses reports to identify system deficiencies, issue alert messages, and produce two publications, \"CALLBACK\", and \"ASRS Directline\". The collected information is made available to the public, and is used by the FAA, NASA and other organizations working in research and flight safety.\n\nThe Bureau of Aircraft Accidents Archives (B3A), a non-government organization based in Geneva, compiles statistics on aviation accidents of aircraft capable of carrying more than six passengers, excluding helicopters, balloons, and combat aircraft. Note that ACRO only considers crashes in which the aircraft has suffered such damage that it is removed from service, which will further reduce the statistics for incidents and fatalities compared to some other data.\n\nAccording to ACRO, recent years have been considerably safer for aviation, with fewer than 170 incidents every year between 2009 and 2017, compared to as many as 226 as recently as 1998.\n\nAnnual fatalities have been less than 1,000 in nine of the fourteen years since 2004, with 2017 experiencing the lowest number of fatalities, at 399, since the end of World War II.\n\n2014 included the disappearance of flight MH370 over the Indian Ocean (possible homicide, plane not found apart from minor debris washed ashore) and the shootdown of flight MH17 by pro-Russian separatists in Ukraine as part of the War in Donbass. The total number of fatalities in 2014 was 869 more than in 2013.\n\nDeaths and incidents per year according to ACRO and Bureau of Aircraft Accident Archives data, :\n\nThe European Aviation Safety Agency (EASA) is tasked by Article 15(4) of Regulation (EC) No 216/2008 of the European Parliament and of the Council of February 20, 2008 to provide an annual review of aviation safety.\n\nThe Annual Safety Review presents statistics on European and worldwide civil aviation safety. Statistics are grouped according to type of operation, for instance, commercial air transport, and aircraft category, such as aeroplanes, helicopters, gliders, etc.\nThe Agency has access to accident and statistical information collected by the International Civil Aviation Organization (ICAO). States are required, according to ICAO Annex 13, on Aircraft Accident and Incident Investigation, to report to ICAO information, on accidents and serious incidents to aircraft with a maximum certificated take-off mass (MTOM) over 2250 kg. Therefore, most statistics in this review concern aircraft above this mass. In addition to the ICAO data, a request was made to the EASA Member States to obtain light aircraft accident data. Furthermore, data on the operation of aircraft for commercial air transport were obtained from both ICAO and the NLR Air Transport Safety Institute.\n\nAnnex 13 of the Chicago Convention provides the international Standards And Recommended Practices that form the basis for air accident and incident investigations by signatory countries, as well as reporting and preventative measures. The International Civil Aviation Organization (ICAO) is specifically focused on preventing accidents, rather than determining liability.\n\nIn Australia, the Australian Transport Safety Bureau is the federal government body responsible for investigating transport-related accidents and incidents, covering air, sea, and rail travel. Formerly an agency of the Department of Infrastructure, Transport, Regional Development and Local Government, in 2010, in the interests of keeping its independence it became a stand-alone agency.\n\nIn Brazil, the Aeronautical Accidents Investigation and Prevention Center (CENIPA) was established under the auspices of the Aeronautical Accident Investigation and Prevention Center, a Military Organization of the Brazilian Air Force (FAB). The organization is responsible for the activities of aircraft accident prevention, and investigation of civil and military aviation occurrences. Formed in 1971, and in accordance with international standards, CENIPA represented a new philosophy: investigations are conducted with the sole purpose of promoting the \"prevention of aeronautical accidents\".\n\nIn Canada, the Transportation Safety Board of Canada (TSB), is an independent agency responsible for the advancement of transportation safety through the investigation and reporting of accident and incident occurrences in all prevalent Canadian modes of transportation — marine, air, rail and pipeline.,\n\nIn France, the agency responsible for investigation of civilian air crashes is the Bureau d'Enquêtes et d'Analyses pour la Sécurité de l'Aviation Civile (BEA). Its purpose is to establish the circumstances and causes of the accident and to make recommendations for their future avoidance.\n\nIn Germany, the agency for investigating air crashes is the Federal Bureau of Aircraft Accidents Investigation (BFU). It is an agency of the Federal Ministry of Transport and Digital Infrastructure. The focus of the BFU is to improve safety by determining the causes of accidents and serious incidents and making safety recommendations to prevent recurrence.\n\nIn Hong Kong, the Civil Aviation Department's Flight Standards & Airworthiness Division and Accident Investigation Division are charged with accident investigation involving aircraft within Hong Kong.\n\nUntil May 30, 2012, the Directorate General of Civil Aviation investigated incidents involving aircraft. Since then, the Aircraft Accident Investigation Bureau has taken over investigation responsibilities.\n\nIn Indonesia, the National Transportation Safety Committee (NTSC; , KNKT) is responsible for the investigation of incidents and accidents, including air accidents. Its aim is the improvement of transportation safety, not just aviation, in Indonesia.\n\nCreated in 1999 in Italy, the Agenzia Nazionale per la Sicurezza del Volo (ANSV), has two main tasks: conducting technical investigations for civil aviation aircraft accidents and incidents, while issuing safety recommendations as appropriate; and conducting studies and surveys aimed at increasing flight safety. The organization is also responsible for establishing and maintaining the \"voluntary reporting system.\" Although not under the supervision of the Ministry of Infrastructure and Transport, the ANSV is a public authority under the oversight of the Presidency of the Council of Ministers of Italy.\n\nThe Japan Transport Safety Board investigates aviation accidents and incidents. The Aircraft Accident Investigation Commission investigated aviation accidents and incidents in Japan until October 1, 2001, when the Aircraft and Railway Accidents Investigation Commission (ARAIC) replaced it, and the ARAIC did this function until October 1, 2008, when it merged into the JTSB.\n\nIn Mexico the Directorate General of Civil Aviation (DGAC) investigates aviation accidents.\n\nIn the Netherlands, the Dutch Safety Board (\"Onderzoeksraad voor Veiligheid\") is responsible for the investigation of incidents and accidents, including air accidents. Its aim is the improvement of safety in the Netherlands. Its main focus is on those situations in which civilians are dependent on the government, companies or organizations for their safety. The Board solely investigates when incidents or accidents occur and aims to draw lessons from the results of these investigations. The Safety Board is objective, impartial and independent in its judgment. The Board will always be critical towards all parties concerned.\n\nIn New Zealand, the Transport Accident Investigation Commission (TAIC), is responsible for the investigation of air accidents. \"The Commission's purpose, as set out in its Act, is to determine the circumstances and causes of aviation, rail and maritime accidents, and incidents, with a view to avoiding similar occurrences in the future, rather than to ascribe blame to any person.\" The TAIC will investigate in accordance with annex 13 of the ICAO\n\nIn Russia, the Interstate Aviation Committee (IAC, MAK according to the original Russian name) is an executive body overseeing the use and management of civil aviation in the Commonwealth of Independent States. This Organization investigates air accidents in the former USSR area under the umbrella of the Air Accident Investigation Commission of the Interstate Aviation Committee.\n\nIn Taiwan, the Aviation Safety Council (ASC) is the independent government agency that is responsible for aviation accident investigations. Established in 1998, ASC is under the administration of the Executive Yuan and independent from Civil Aeronautics Administration of Taiwan. The ASC consisted of five to seven board members, including a chairman and a vice chairman, appointed by the Premier. The managing director of ASC manages the day-to-day function of the organization, including accident investigations.\n\nIn the United Kingdom, the agency responsible for investigation of civilian air crashes is the Air Accidents Investigation Branch (AAIB) of the Department for Transport. Its purpose is to establish the circumstances and causes of the accident and to make recommendations for their future avoidance.\n\nUnited States civil aviation incidents are investigated by the National Transportation Safety Board (NTSB). NTSB officials piece together evidence from the crash site to determine likely cause, or causes. The NTSB also investigates overseas incidents involving US-registered aircraft, in collaboration with local investigative authorities, especially when there is significant loss of American lives, or when the involved aircraft is American built.\n\nIt is common for an airline to cease using the flight number of a fatal crash, although that is not always the case.\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "1903649", "url": "https://en.wikipedia.org/wiki?curid=1903649", "title": "Betavoltaic device", "text": "Betavoltaic device\n\nBetavoltaic devices, also known as betavoltaic cells, are generators of electric current, in effect a form of battery, which use energy from a radioactive source emitting beta particles (electrons). A common source used is the hydrogen isotope tritium. \nUnlike most nuclear power sources, which use nuclear radiation to generate heat, which then is used to generate electricity (thermoelectric and thermionic sources), betavoltaics use a non-thermal conversion process; converting the electron-hole pairs produced by the ionization trail of beta particles traversing a semiconductor.\n\nBetavoltaic power sources (and the related technology of alphavoltaic power sources) are particularly well-suited to low-power electrical applications where long life of the energy source is needed, such as implantable medical devices or military and space applications.\n\nBetavoltaics were invented in the 1970s. Some pacemakers in the 1970s used betavoltaics based on promethium, but were phased out as cheaper lithium batteries were developed.\n\nEarly semiconducting materials weren't efficient at converting electrons from beta decay into usable current, so higher energy, more expensive—and potentially hazardous—isotopes were used. The more efficient semiconducting materials used today can be paired with relatively benign isotopes such as tritium, which produce less radiation.\n\nThe Betacel was considered the first successfully commercialized betavoltaic battery. The use of diamond-encapsulated carbon-14 to be extracted from nuclear waste was proposed in 2016 as a very long lived betavoltaic source.\n\nIn 2018 a Russian design based on 2-micron thick nickel-63 slabs sandwiched between 10 micron diamond layers was introduced. It produced power output of about 1 microWatt (μW) at a power density of 10 μW/cm. Its energy density was 3.3 kilowatt-hours/kg. The half-life of nickel-63 is 100 years.\n\nThe primary use for betavoltaics is for remote and long-term use, such as spacecraft requiring electrical power for a decade or two. Recent progress has prompted some to suggest using betavoltaics to trickle-charge conventional batteries in consumer devices, such as cell phones and laptop computers. As early as 1973, betavoltaics were suggested for use in long-term medical devices such as pacemakers.\n\nAlthough betavoltaics use a radioactive material as a power source, the beta particles used are low energy and easily stopped by a few millimetres of shielding. With proper device construction (that is, proper shielding and containment), a betavoltaic device would not emit dangerous radiation. Leakage of the enclosed material would engender health risks, just as leakage of the materials in other types of batteries (such as lithium, cadmium and lead) leads to significant health and environmental concerns.\n\nAs radioactive material emits, it slowly decreases in activity (refer to half-life). Thus, over time a betavoltaic device will provide less power. For practical devices, this decrease occurs over a period of many years. For tritium devices, the half-life is 12.32 years. In device design, one must account for what battery characteristics are required at end-of-life, and ensure that the beginning-of-life properties take into account the desired usable lifetime.\n\nLiability connected with environmental laws and human exposure to tritium and its beta decay must also be taken into consideration in risk assessment and product development. Naturally, this increases both time-to-market and the already high cost associated with tritium.\nA 2007 report by the UK government's Health Protection Agency Advisory Group on Ionizing Radiation declared the health risks of tritium exposure to be double those previously set by the International Commission on Radiological Protection located in Sweden.\n\n\n"}
{"id": "3028930", "url": "https://en.wikipedia.org/wiki?curid=3028930", "title": "Brenda Laurel", "text": "Brenda Laurel\n\nBrenda Laurel, Ph.D. works as an independent scholar and consultant. She is an advocate for diversity and inclusiveness in video games, a \"pioneer in developing virtual reality\", a public speaker and an academic. She is also a board member of several companies and organizations. She was founder and chair of the Graduate Design Program at California College of the Arts (2006–2012). and of the Media Design graduate program at Art Center College of Design (2000–2006). She has worked for Atari, co-founded the game development firm Purple Moon, and served as an interaction design consultant for multiple companies including Sony Pictures, Apple, and Citibank.\n\nLaurel received a Bachelor of Arts from DePauw University. She received her Masters of Fine Arts as well as her Ph.D. from Ohio State University.\n\nLaurel's first games were for the CyberVision platform in 1977/78. Later the worked as a producer at Atari between 1980 and 1983 after which she worked for Activision between 1985 and 1987. In the late 80's and early 90's she worked as a creative consultant on a number of Lucasfilm Games and Chris Crawford's Balance of the Planet.\n\nAs one of the earliest female game designers, Laurel is also one of the foremost theorists regarding developing videogames for girls. She posited that while the early videogame industry focused almost exclusively upon developing products aimed at young men, girls were not inherently disinterested in the medium. Rather, girls were simply interested in \"different kinds\" of gaming experiences. Her research uncovered that young women tended to prefer experiences based around complex social interaction, verbal skills, and transmedia.\n\nIn 1996, Laurel founded Purple Moon, the first American software company to cater games to young girls between the ages of 8 and 14. Laurel's vision was to create games for girls that focused more on real life decision-making rather than creating games that focused on appearances and materiality. The company was an experiment in turning research on girl's gaming preferences into marketable video games. The firm produced games designed around storytelling, open-ended exploration, and rehearsing realistic scenarios from one's day-to-day life, as opposed to competitive games featuring scores and timed segments. The company produced ten games primarily divided into two series: \"Rockett\", which focused around a young girl's quotidian interactions, and the more meditative \"Secret Path\" series. It was eventually bought by Mattel in 1999.\n\nPurple Moon received criticism for focusing on designing games based on gender. The research was accused of reifying the differences between genders that girls were already socialized to accept, thus the focus on the stereotypically feminine values of cooperation, narrative, and socialization as opposed to the stereotypically masculine values embodied in most games as violence and competition.\n\nIn Laurel's work regarding interface design, she is well known for her support of the theory of \"interactivity,\" the \"degree to which users of a medium can influence the form or content of the mediated environment.\" Virtual reality, according to Laurel, is less characterized by its \"imaginary\" or \"unreal\" elements than by its \"multisensory\" representation of objects, be they real or imaginary. While discussions around virtual reality tended to center on visual representations, audio and kinesthesia are two potent sources of sensory input that virtual reality devices attempt to tap into. Laurel's 1994 \"Placeholder\" installation at Banff Center for the Arts—a collaboration with Rachel Strickland—explored these multisensory possibilities. The installation allowed multiple people to construct a narrative by attaching movement trackers to its subjects' bodies while letting them navigate a virtual environment by doing common physical acts with special results, such as flapping one's arms to fly.\n\nBooks\n\n\nGames\n\n\n"}
{"id": "275712", "url": "https://en.wikipedia.org/wiki?curid=275712", "title": "Cleanroom", "text": "Cleanroom\n\nA cleanroom or clean room is a facility ordinarily utilized as a part of specialized industrial production or scientific research, including the manufacture of pharmaceutical items and microprocessors. Cleanrooms are designed to maintain extremely low levels of particulates, such as dust, airborne organisms, or vaporized particles. Cleanrooms typically have an cleanliness level quanitified by the number of particles per cubic meter at a predetermined molecule measure. The ambient outdoor air in a typical urban area contains 35,000,000 particles for each cubic meter in the size range 0.5 μm and bigger in measurement, equivalent to an ISO 9 cleanroom, while by comparison an ISO 1 cleanroom permits no particles in that size range and just 12 particles for each cubic meter of 0.3 μm and smaller.\n\nThe modern cleanroom was invented by American physicist Willis Whitfield. As employee of the Sandia National Laboratories, Whitfield created the initial plans for the cleanroom in 1960. Prior to Whitfield's invention, earlier cleanrooms often had problems with particles and unpredictable airflows. Whitfield designed his cleanroom with a constant, highly filtered air flow to flush out impurities. Within a few years of its invention in the 1960s, Whitfield's modern cleanroom had generated more than 50 billion USD in sales worldwide.\n\nThe majority of the integrated circuit manufacturing facilities in Silicon Valley were made by three companies: MicroAire, PureAire, and Key Plastics. These competitors made laminar flow units, glove boxes, clean rooms and air showers, along with the chemical tanks and benches used in the 'Wet Process' building of integrated circuits. These three companies were the pioneers of the use of Teflon for airguns, chemical pumps, scrubbers, water guns, and other devices needed for the production of [[integrated circuit]s. William (Bill) C. McElroy Jr. worked as engineering manager, drafting room supervisor, QA/QC, and designer for all three companies and his designs added 45 original patents to the technology of the time. McElroy also wrote a four page article for MicroContamination Journal, wet processing training manuals, and equipment manuals for wet processing and clean rooms.\n\nCleanrooms can be very large. Entire manufacturing facilities can be contained within a cleanroom with factory floors covering thousands of square meters. They are used extensively in [[Fabrication (semiconductor)|semiconductor manufacturing]], [[biotechnology]], the [[life sciences]], and other fields that are very sensitive to environmental contamination. There are also modular cleanrooms.\n\nThe air entering a cleanroom from outside is [[filter (air)|filter]]ed to exclude dust, and the air inside is constantly recirculated through high-efficiency particulate air ([[HEPA]]) and/or ultra-low particulate air ([[ULPA]]) filters to remove internally generated contaminants.\n\nStaff enter and leave through [[airlock]]s (sometimes including an [[air shower (room)|air shower]] stage), and wear protective clothing such as hoods, face masks, gloves, boots, and coveralls.\n\nEquipment inside the cleanroom is designed to generate minimal air contamination. Only special [[mop]]s and [[bucket]]s are used. Cleanroom furniture is designed to produce a minimum of particles and is easy to clean.\n\nCommon materials such as [[paper]], [[pencil]]s, and [[Textile|fabric]]s made from natural fibers are often excluded, and alternatives used. Cleanrooms are not [[sterilization (microbiology)|sterile]] (i.e., free of uncontrolled microbes); only airborne particles are controlled. Particle levels are usually tested using a [[particle counter]] and microorganisms detected and counted through environmental monitoring methods. [[Polymer]] tools used in cleanrooms must be carefully determined to be [[Chemical compatibility|chemically compatible]] with cleanroom processing fluids as well as ensured to generate a low level of particle generation.\n\nSome cleanrooms are kept at a [[positive pressure]] so if any leaks occur, air leaks out of the chamber instead of unfiltered air coming in.\n\nSome cleanroom [[HVAC]] systems control the [[humidity]] to such low levels that extra equipment like [[Air_ioniser|air ionizers]] are required to prevent [[electrostatic discharge]] problems.\n\nLow-level cleanrooms may only require special shoes, with completely smooth soles that do not track in dust or dirt. However, for safety reasons, shoe soles must not create slipping hazards. Access to a cleanroom is usually restricted to those wearing a [[cleanroom suit]].\n\nIn cleanrooms in which the standards of air contamination are less rigorous, the entrance to the cleanroom may not have an air shower. An anteroom (known as a \"gray room\") is used to put on clean-room clothing.\n\nSome manufacturing facilities do not use fully classified cleanrooms, but use some practices or technologies typical of cleanrooms to meet their contamination requirements.\n\nIn [[Hospital]]s, [[Operating theater|Theatre]]s are similar to cleanroom for surgical patients' operation with [[Surgical incision|incisions]] to prevent any infections for the patient.\n\nCleanrooms maintain particulate-free air through the use of either [[HEPA]] or [[ULPA]] filters employing laminar or turbulent air flow principles. Laminar, or unidirectional, air flow systems direct filtered air downward or in horizontal direction in a constant stream towards filters located on walls near the cleanroom floor or through raised perforated floor panels to be recirculated. Laminar air flow systems are typically employed across 80% of a cleanroom ceiling to maintain constant air processing. Stainless steel or other non shedding materials are used to construct laminar air flow filters and hoods to prevent excess particles entering the air. Turbulent, or non unidirectional, air flow uses both laminar air flow hoods and nonspecific velocity filters to keep air in a cleanroom in constant motion, although not all in the same direction. The rough air seeks to trap particles that may be in the air and drive them towards the floor, where they enter filters and leave the cleanroom environment. US FDA and EU have laid down guidelines and limit for microbial contamination which is very stringent to ensure freedom from microbial contamination in pharmaceutical products.\n\nThe greatest threat to cleanroom contamination comes from the users themselves. In the healthcare and pharmaceutical sectors, control of microorganisms is important, especially microorganisms likely to be deposited into the air stream from skin shedding. Studying cleanroom microflora is of importance for microbiologists and quality control personnel to assess changes in trends. Shifts in the types of microflora may indicate deviations from the “norm” such as resistant strains or problems with cleaning practices.\n\nIn assessing cleanroom microorganisms, the typical flora are primarily those associated with human skin (Gram-positive cocci), although microorganisms from other sources such as the environment (Gram-positive rods) and water (Gram-negative rods) are also detected, although in lower number. Common bacterial genera include \"Micrococcus\", \"Staphylococcus\", \"Corynebacterium\", and \"Bacillus\", and fungal genera include \"Aspergillus\" and \"Pencillin\".\n\nCleanrooms are classified according to the number and size of particles permitted per volume of air. Large numbers like \"class 100\" or \"class 1000\" refer to [[FED-STD-209E]], and denote the number of particles of size 0.5 µm or larger permitted per cubic foot of air. The standard also allows interpolation; for example [[SNOLAB]] is maintained as a class 2000 cleanroom.\n\nA discrete, light-scattering airborne particle counter is used to determine the concentration of airborne particles, equal to and larger than the specified sizes, at designated sampling locations.\n\nSmall numbers refer to [[ISO 14644|ISO 14644-1]] standards, which specify the decimal [[logarithm]] of the number of particles 0.1 µm or larger permitted per m of air. So, for example, an ISO class 5 cleanroom has at most 10 particles/m.\n\nBoth FS 209E and ISO 14644-1 assume log-log relationships between particle size and particle concentration. For that reason, zero particle concentration does not exist. Some classes do not require testing some particle sizes, because the concentration is too low or too high to be practical to test for, but such blanks should not be read as zero.\n\nBecause 1 m is about 35 ft, the two standards are mostly equivalent when measuring 0.5 µm particles, although the testing standards differ. Ordinary room air is around class 1,000,000 or ISO 9.\n\n[[ISO 14644|ISO 14644-1]] and [[ISO 14698]] are [[non-governmental organization|non-governmental]] standards developed by the [[International Organization for Standardization]] (ISO). The former applies to clean rooms in general (see table below); the latter to cleanrooms where [[contamination|biocontamination]] may be an issue.\n\n[[ISO 14644|ISO 14644-1]] defines the maximum concentration of particles per class and per particle size with the following formula\n\nformula_1\n\nWhere formula_2 is the maximum concentration of particles in a volume of 1mformula_3 of airborne particles that are equal to, or larger, than the considered particle size which is rounded to the nearest whole number, using no more than three significant figures, formula_4 is the ISO class number, formula_5 is the size of the particle in formula_6m and 0.1 is a constant expressed in formula_6m. The result for standard particle sizes is expressed in the following table.\n\nUS [[FED-STD-209E]] was a [[United States]] [[Federal government of the United States|federal]] standard. It was officially cancelled by the [[General Services Administration]] on November 29, 2001, but is still widely used.\n\nEU GMP guidelines are more stringent than others, requiring cleanrooms to meet particle counts at operation (during manufacturing process) and at rest (when manufacturing process is not carried out, but room [[Air handler|AHU]] is on).\n\nBS 5295 is a [[British Standard]].\nBS 5295 Class 1 also requires that the greatest particle present in any sample can not exceed 5 μm. BS 5295 has been superseded, withdrawn since the year 2007 and replaced with \"BS EN ISO 14644-6:2007\".\n\n\n\n[[Category:Rooms]]\n[[Category:Semiconductor device fabrication]]\n[[Category:Filters]]\n[[Category:Telecommunications engineering]]\n[[Category:Cleanroom technology]]"}
{"id": "56741259", "url": "https://en.wikipedia.org/wiki?curid=56741259", "title": "Combustion Science and Technology", "text": "Combustion Science and Technology\n\nCombustion Science and Technology is a monthly peer-reviewed scientific journal covering the field of combustion. The editor-in-chief is Richard A. Yetter (Pennsylvania State University). It is published by Taylor & Francis and was established in 1969. The journal was preceded by \"Pyrotechnics\", which was published from 1964-1969.\n\nThe journal is abstracted and indexed in,\n\nAccording to the \"Journal Citation Reports\", the journal has a 2016 impact factor of 1.241.\n"}
{"id": "58171134", "url": "https://en.wikipedia.org/wiki?curid=58171134", "title": "Contact cleaner", "text": "Contact cleaner\n\nContact cleaner, also known as switch cleaner, is a term for a chemical, or a mixture of chemicals, intended to remove or prevent the build-up of oxides or other unwanted substances on the conductive surfaces of connectors, switches and other electronic components with moving surface contacts. The use of contact cleaner can help to minimise the wetting current across a pair of contacts.\n\nAn example of a simple contact cleaner is isopropyl alcohol.\n\nSome contact cleaners are designed to evaporate completely and rapidly, leaving no residue. Others may contain lubricants. Lubricants themselves should not necessarily be used as contact cleaners, especially if they are designed to leave an unsuitable residue. However, appropriate lubricants may work well as contact cleaners.\n\nContact cleaner brands include Scotch (3M), Servisol, CRC, and Deoxit.\n"}
{"id": "5204368", "url": "https://en.wikipedia.org/wiki?curid=5204368", "title": "Data and object carousel", "text": "Data and object carousel\n\nIn digital video broadcasting (DVB), a data and object carousel is used for repeatedly delivering data in a continuous cycle. Carousels allow data to be pushed from a broadcaster to multiple receivers by transmitting a data set repeatedly in a standard format. A set-top box receiver may tune to the data stream at any time and is able to reconstitute the data into a virtual file system. The carousel may therefore be considered as a transport file system or file broadcasting system that allows data files to be transmitted from the broadcaster to multiple receivers or clients simultaneously.\n\nIn a unidirectional broadcast environment, the receiver is unable to request the retransmission of any data that was missed or received incorrectly. Repeated retransmission of data allows the receiver to cope with random tuning to a channel at an unpredictable time, for instance as the user changes a channel.\n\nThe carousel cycle period generally determines the maximum time required for a receiver to acquire an application or specific datum. It is possible to reduce the access time for commonly used files by broadcasting some data more often than others.\n\nAn individual object carousel is also called a service domain in some documents. To be precise, a service domain is a group of related DSM-CC objects. In broadcast systems, there is no difference between an object carousel and a service domain except for the terminology: an object carousel is a service domain, and vice versa.\n\nData and object carousels are most commonly used in DVB, which has standards for broadcasting digital television content using carousels. The standard format for a carousel is defined in the Digital Storage Media Command and Control (DSM-CC) toolkit in ISO/IEC 13818-6 and is part of the Digital Audio Video Council (DAVIC) DVB standard for digital video broadcasting. The specification provides support for a variety of communication models, including provision for interactive transport control of audio and video streams in a bi-directional environment such as a cable television video on demand system.\n\nThe DSM-CC standard specifies two types of carousel, a data carousel and an object carousel. The object carousel extends the more limited data carousel and specifies a standard format for representing a file system directory structure comprising a root directory or service gateway and one or more files and directories.\n\nFiles and directories are encapsulated in a DSM-CC object carousel in several layers. Objects are encapsulated in modules, which are carried within download data blocks, within DSM-CC sections encoded in MPEG private sections which are assembled from packets.\n\nCarousel complexity can increase dramatically based on various factors such as the content type or the content filling algorithm. Generally the content of a transmission carousel is dynamic, based on a multitude of variables, such as duration of the carousel transmission, and is either determined by some type of algorithm or management utility.\n\nConcepts such as embedded carousels are well-known and in use. This is when the main transmission carousel has a particular piece of content dynamically changing itself based on a sub-carousel content provider.\n\n"}
{"id": "343934", "url": "https://en.wikipedia.org/wiki?curid=343934", "title": "Design life", "text": "Design life\n\nThe design life of a component or product is the period of time during which the item is expected by its designers to work within its specified parameters; in other words, the life expectancy of the item. It is the length of time between placement into service of a single item and that item's onset of wearout.\n\nThe design life of components and products differs from the items' mean time between failures, (MTBF), in that MTBF is a measure of the rate of occurrence of random failures in time where these failures are not due to a wear-out mechanism. For example, the mean time between failure of a device may be 100,000 hours and the design-life is 20,000 hours. In this example, across the population of products, one failure will occur, on average, every 100,000 population operating hours. (100,000 units operating for 1 hour each = 100,000 population operating hours.) None of these units will ever approach reaching 100,000 operating hours as each one will fail due to wear-out and be replaced by a new unit. Aluminum electrolytic capacitors, fans, and batteries are classic examples of components that will fail due to wear-out well before they could individually achieve the operating time indicated by their individual MTBF.\n\nAnother use of the term design life deals with consumer products. Many products employ design life as one factor of their differentiation from competing products and components. A disposable camera is designed to withstand a short life, whilst an expensive single-lens reflex camera can be expected to have a design life measured in years or decades. (Clearly in this example there are other differentiators.)\n\nSome products designed for heavy or demanding use are so well-made that they are retained and used well beyond their design life. Some public transport vehicles come into this category, as do a number of artificial satellites and spacecraft. In general, entry-level products—those at the lowest end of the price range fulfilling a certain specification—will tend to have shorter design lives than more expensive products fulfilling the same function, since there are savings to be made in using designs that are cheaper to implement, or, conversely, costs to be passed onto the customer in engineering to provide a safe margin leading to an increased working life. This economic truism leads to the phenomenon of products designed (or appearing to be designed) to last only so long as their warranty period.\n\nDesign life is related to but distinct from the concept of built-in obsolescence. The latter is the somewhat more nebulous notion that products are designed so as to become obsolete—at least in the eyes of the user—before the end of their design life. Two classic examples here are digital cameras, which become genuinely obsolete as a result of the very rapid rate of technological advances, although still in perfect working order; and non-digital cameras, which are perceived as obsolete after a year or so as they are no longer \"the latest design\" although actually capable of years of useful service.\n\n\n"}
{"id": "31172573", "url": "https://en.wikipedia.org/wiki?curid=31172573", "title": "Diag Human", "text": "Diag Human\n\nDiag Human is a Liechtenstein-incorporated blood plasma trading company, established by Swiss-Czech entrepreneur Josef Šťáva (born 17 March 1950 in Prague) in the 1980s. The stated aim of the company was to help \"currency-deficient Eastern Bloc states acquire modern blood plasma technology\".\n\nThe company received media attention in the 1996, when it filed a lawsuit against the Czech government in Prague Commercial Court, for defamation and unfair competition. The company claimed that the Health Minister had contacted Novo Nordisk, a major business partner of Diag Human, to dissuade the company from doing business with them, which led to the failure of Diag Human's business in the country. The two parties agreed to enter arbitration, and the case became one of the largest cases of commercial litigation in the history of Czech Republic. In 2008, the court found in favour of Diag Human, awarding around $650 million to the company.\n"}
{"id": "4738002", "url": "https://en.wikipedia.org/wiki?curid=4738002", "title": "Direct borohydride fuel cell", "text": "Direct borohydride fuel cell\n\nDirect borohydride fuel cells (DBFCs) are a subcategory of alkaline fuel cells which are directly fed by sodium borohydride or potassium borohydride as a fuel and either air/oxygen or hydrogen peroxide as the oxidant. DBFCs are relatively new types of fuel cells which are currently in the developmental stage and are attractive due to their high operating potential in relation to other type of fuel cells.\n\nSodium borohydride could potentially be used in more conventional hydrogen fuel cell systems as a means of storing hydrogen. The hydrogen can be regenerated for a fuel cell by catalytic decomposition of the borohydride:\n\nDirect borohydride fuel cells decompose and oxidize the borohydride directly, side-stepping hydrogen production and even producing slightly higher energy yields:\n\nThe simplified reaction is:\n\nThe working temperature of a direct sodium borohydride fuel cell is 70 °C (158 °F).\n\nDBFCs could be produced more cheaply than a traditional fuel cell because they do not need expensive platinum catalysts. In addition, they have a higher power density.\n\nUnfortunately, DBFCs do produce some hydrogen from a side reaction of NaBH with water heated by the fuel cell. This hydrogen can either be piped out to the exhaust or piped to a conventional hydrogen fuel cell. Either fuel cell will produce water, and the water can be recycled to allow for higher concentrations of NaBH.\n\nMore importantly, the process of creating electricity via a DBFC is not easily reversible. For example, after sodium borohydride (NaBH) has released its hydrogen and has been oxidized, the product is NaBO (sodium metaborate). Sodium metaborate might be hydrogenated back into sodium borohydride fuel by several different techniques, some of which might theoretically require nothing more than water and electricity or heat. However, these techniques are still in active development. As of June 30, 2010, many patents claiming to effectively achieve the conversion of sodium metaborate to sodium borohydride have been investigated but none have been confirmed—the current efficiency of \"boron hydride recycling\" seems to be well below 1% which is unsuitable for recharging a vehicle.\n\nSodium borohydride costs US$500 per kg, but with borax recycling and mass production projected prices for the fuel are as low as US$10/kg.\nSodium borohydride can already be purchased for as low as US$ 200 per kg from european eBay's sellers\n"}
{"id": "53375615", "url": "https://en.wikipedia.org/wiki?curid=53375615", "title": "Dynamic Roentgen stereophotogrammetry", "text": "Dynamic Roentgen stereophotogrammetry\n\nDynamic Roentgen stereophotogrammetry (also referred to as dynamic RSA) is a modern and sophisticated x-ray recording method, used to measure real-time 3D motions of prostheses and bones during motion with high accuracy. It is mostly used in orthopedic research settings and is an advancement of conventional RSA.\n\nConventional static RSA is used to evaluate migration of prosthesis with respect to the bone in three dimensions as a function of time. Migration of the prosthesis are normal 12‐24 months after the surgery. Ongoing migration increase the risk of aseptic loosening with revision surgery as a consequence. The method has proven valuable in the evaluation of fixation for hip and knee arthroplasty, as early RSA evaluations have shown high predictive value for later aseptic component loosening.\n\nIn contrast, Dynamic RSA makes it possible to accurately assess both micro movements in the fixation interface and kinematics of the prosthetic components in three dimensions, during active motions.\n"}
{"id": "3213396", "url": "https://en.wikipedia.org/wiki?curid=3213396", "title": "Electronic hardware", "text": "Electronic hardware\n\nElectronic hardware consists of interconnected electronic components which perform analog or logic operations on received and locally stored information to produce as output or store resulting new information or to provide control for output actuator mechanisms.\n\nElectronic hardware can range from individual chips/circuits to distributed information processing systems. Well designed electronic hardware is composed of hierarchies of functional modules which inter-communicate via precisely defined interfaces.\n\nHardware logic is primarily a differentiation of the data processing circuitry from other more generalized circuitry. For example nearly all computers include a power supply which consists of circuitry not involved in data processing but rather powering the data processing circuits. Similarly, a computer may output information to a computer monitor or audio amplifier which is also not involved in the computational processes.\n\n"}
{"id": "9883", "url": "https://en.wikipedia.org/wiki?curid=9883", "title": "Eurocard (printed circuit board)", "text": "Eurocard (printed circuit board)\n\nEurocard is a European standard format for printed circuit board (PCB) cards that can be plugged together into a standard chassis which, in turn, can be mounted in a 19-inch rack. The chassis consists of a series of slotted card guides on the top and bottom, into which the cards are slid so they stand on end, like books on a shelf. At the spine of each card is one or more connectors which plug into mating connectors on a backplane that closes the rear of the chassis.\n\nAs the cards are assumed to be installed in a vertical orientation, the usual meanings of height and width are transposed: A card might be 233.35 mm \"high\", but only 20 mm \"wide\". Height is measured in rack units, \"U\", with 1 U being . This dimension refers to the subrack in which the card is to be mounted, rather than the card itself. \n\nEnclosure heights are multiples of 3U, with the cards always shorter than the enclosure. Two common heights are 3U (a 100 mm card in a subrack) and 6U (a 233.35 mm card in a high subrack). As two 3U cards are shorter than a 6U card (by 33.35 mm), it is possible to install two 3U cards in one slot of a 6U subrack, with a mid-height structure for proper support. \n\nCard widths are specified in horizontal pitch units \"HP\", with 1 HP being .\n\nCard depths start at and increase in increments. The most common today is , but standard hardware is available for depths of , , , , , and .\n\nThe Eurocard mechanical architecture was defined originally under IEC-60297-3. Today, the most widely recognized standards for this mechanical structure are IEEE 1101.1, IEEE 1101.10 (also known commonly as \"dot ten\") and IEEE 1101.11. IEEE 1101.10 covers the additional mechanical and electromagnetic interference features required for VITA 1.1-1997(R2002), which is the VME64 Extensions standard, as well as PICMG 2.0 (R3.0), which is the CompactPCI specification.\n\nThe IEEE 1101.11 standard covers rear plug-in units that are also called rear transition modules or RTMs.\n\nThe Eurocard is a mechanical system and does not define the specific connector to be used or the signals that are assigned to connector contacts.\n\nThe connector systems that are commonly used with Eurocard architectures include the original DIN 41612 connector that is also standardized as IEC 60603.2. This is the connector that is used for the VMEbus standard, which was IEEE 1014. The connector known as the 5-row DIN, which is used for the VME64 Extensions standard is IEC 61076-4-113. The VME64 Extension architecture defined by VITA 1.1-1997 (R2002).\n\nAnother popular computer architecture that utilizes the 6U-160 Eurocard is CompactPCI and CompactPCI Express. These are defined by PICMG 2.0R3 and PICMG Exp0 R1 respectively. Other computer architectures that utilize the Eurocard system are VME eXtensions for Instrumentation (VXI), PCI eXtensions for Instrumentation (PXI), and PXI Express.\n\nA computer architecture that used the 6U-220 Eurocard format was Multibus-II, which was IEEE 1296.\n\nBecause the Eurocard system provided for so many modular card sizes and because connector manufacturers have continued to create new connectors that are compatible with this system, it is a popular mechanical standard that is also used for innumerable \"one-off\" applications.\n\nConduction-cooled Eurocards are used in military and aerospace applications. They are defined by the IEEE 1101.2-1992 (2001) standard.\n\nThe Eurocard standard is also the basis of the \"Eurorack\" format for modular electronic music synthesizers, popularized by Doepfer and other manufacturers.\n\n"}
{"id": "20306810", "url": "https://en.wikipedia.org/wiki?curid=20306810", "title": "Eyelid glue", "text": "Eyelid glue\n\nEyelid glue, commonly called , is a type of eye make-up used in East Asia designed to change the monolid (eyelid without a crease). Eyelid glue is a water-soluble adhesive that can be easily removed.\n\nEyelid glue became available in Japan in the late 1970s.\n\nDouble eyelids are considered a sign of feminine beauty in East Asia. Some women opt for a temporary solution by wearing eyelid glue. The glue is painted on the upper eyelid, which is then pushed upward with a plastic prong and held in place by the adhesive. The glue needs to dry for a minute before holding the fold. This method creates or enhances a fold in the eyelid (\"double eyelid\") that opens up the eye exposing the eyelashes. The use of eyelid glue also exists amongst men.\n\nThe glue does not last and must be reapplied after a few hours. Eyelid glue may also cause irritation.\n\nA variant called eyelid tape or crease tape comes in a fibrous elastic strip that is trimmed to shape and placed on the eyelid. The tape creates a crease that stays on the eyelid. The tape does not last and must be reapplied after a few hours.\n\n\n"}
{"id": "41902674", "url": "https://en.wikipedia.org/wiki?curid=41902674", "title": "Heritage Operations Processing System", "text": "Heritage Operations Processing System\n\nHeritage Operations Processing System, Heritage Ops, or HOPS, is a web-based tool for the day-to-day running and management of preserved and heritage railways. The system was developed, from a concept drawn up by Danny Scroggins and Luke Cartey.\n\nThe HOPS Project began early in August 2009 in the rostering office of the signalling department at the Gloucestershire Warwickshire Railway – who embraced the use of the technology. Beta testing began in January 2010 with a small group of volunteers, the group being enlarged later that year. After this bedding-in period, the system was made more widely available to other UK heritage railways in January 2011.\n\nThe purpose of the system is to provide administration tools associated with operating functions on heritage railways, such as staff rostering, timetabling and competence management, document control, etc. The system assists railways in meeting the requirements of government legislation such as the Railways and Other Guided Transport Systems (Safety) Regulations 2006 (ROGS) which were introduced in Great Britain to put the 2004 European Railway Safety Directive into practice. The system assists with competency management (as a requirement of the Safety Management System).\n\nThe ethos of the development of the system has been that in the majority of cases, producing large-scale data-handling and storage facilities, with the appropriate level of security, access, backups, etc., would not be economical for an individual railway. A single program, in use by many railway companies, however, would make the investment economical.\n\nThe system has grown significantly in the five years it has been in development, mainly in response to feedback from users and demands of the industry, and promises to continue to develop on the same lines in the future.\n"}
{"id": "31900850", "url": "https://en.wikipedia.org/wiki?curid=31900850", "title": "History of fountains in the United States", "text": "History of fountains in the United States\n\nThe first decorative fountain in the United States was dedicated in City Hall Park, in New York City, in 1842. Early American fountains were used to distribute clean drinking water, had little ornamentation, and copied European styles.\n\nIn the 20th century, American fountains often ceased to distribute drinking water; they became purely decorative, and were designed to honor events or individuals, as works of urban sculpture or to imitate nature. In the late 20th century, the musical fountain, where the dance of water is controlled by a computer and is accompanied by lights and music, became a form of public entertainment in Las Vegas and other American cities.\n\nPhiladelphia built the first citywide water system in the United States, which began operation in January 1801. Underground aqueducts carried drinking water from the Schuylkill River, and twin steam pumps propelled it into a water tower at Centre Square, now the site of Philadelphia City Hall. Scottish-born architect Benjamin Henry Latrobe designed the system along with the Greek Revival pumping house/water tower. Centre Square was converted from a meadow into a public park, and an ornamental fountain was added, 1808–1809. Sculptor William Rush carved a wooden statue, \"Allegory of the Schuylkill River\" (better known as \"Water Nymph with Bittern\"), to adorn the Centre Square fountain.\n\nThe first monumental fountains in the United States were built to mark the termini of aqueducts bringing fresh drinking water into New York City. A cholera epidemic in 1832 and the disastrous Great Fire of New York, in 1835, persuaded the government of New York City to build the Croton aqueduct to bring abundant fresh water into the city. The Croton Dam, aqueduct, and reservoir were finished in 1841, bringing water 40 miles from the Croton River to New York City. In commemoration, the first fountain in the U.S., the \"Croton Fountain\" in City Hall Park, was turned on on October 14, 1842 and jetted water 50 feet into the air. A second fountain in Union Square was also connected to the system.\n\nThe first fountains were very simple, without sculpture, and simply spouted water up into the air. They no longer exist, though vestiges of the original water system remain.\n\nIn 1848, Boston completed its own new water system, an aqueduct from Lake Cochituate 20 miles (32 km) to the Boston Common, where the first fountain was located. A parade and festival were held to mark the fountain's opening on October 25, 1848. The ceremony included schoolchildren singing an ode written by American poet James Russell Lowell for the event. The ode began:\n\n\"My name is Water: I have sped\nthrough strange dark ways untried before,\nBy pure desire of friendship led,\nCochituate's Ambassador:\nHe sends four gifts by me,\nLong life, health, peace, and purity.\"\n\nIn contrast to the first American fountains, which were simple and functional, in the 1850s, more decorative fountains were constructed as part of a nationwide effort to beautify American cities by building parks, squares, and fountains inspired by European models. \n\nFor example, the \"Bethesda Fountain\" was created to adorn New York City's new Central Park, which project had been begun in 1858 by Frederick Law Olmsted and Calvert Vaux, to create a vast natural landscape in the heart of the city. In the middle of the park was one formal element: a mall adorned with elm trees and a terrace with views over a lake. In 1863, the park commissioners decided to build a monumental fountain for the central basin in the middle of the mall. The sculptor was a little-known American artist, Emma Stebbins, whose brother was the head of the New York Stock Exchange and President of the Board of Commissioners, who lobbied on her behalf. Her fountain was based on the biblical verse from the Gospel of Saint John, in which an angel touched, or \"troubled\", the waters of the Pool of Bethesda in Jerusalem, giving it healing powers. She wrote about the fountain: \"We have no less healing, comfort and purification freely sent to us through the blessed gift of pure, wholesome water, which to all the countless homes of this great city comes like an angel visitant.\" It was criticized by some writers when it was opened in 1873: the \"New York Times\" called it \"a feebly-pretty idealess thing\", but gradually the fountain became a popular favorite, featured in many films and in recent times in Tony Kushner's play \"Angels in America\".\n\nFountains built in the United States between 1900 and 1950 mostly followed European models and classical styles. For example:\n\nAfter World War II, fountains in the United States became more varied in form. Some, like the Vaillancourt Fountain in San Francisco (1971), were pure works of sculpture. The modernist French-Canadian Armand Vaillancourt built his monumental fountain at Embarcadero Plaza in San Francisco in a cubist style, though it was intended as a political statement - the official title is \"Quebec Libre!\", and the artist was arrested at the time of the opening for painting political slogans on his own fountain.\n\nOther fountains, like the \"Frankin Roosevelt Memorial Waterfall\" (1997), by architect Lawrence Halprin, were designed as landscapes to illustrate themes. This fountain is part of the Franklin Delano Roosevelt Memorial in Washington D.C., which has four outdoor \"rooms\" illustrating FDR's Presidency. Each \"room\" contains a cascade or waterfall; the cascade in the third room illustrates the turbulence of the years of the World War II. Halprin wrote at an early stage of the design; \"the whole environment of the memorial becomes sculpture: to touch, feel, hear and contact - with all the senses.\"\n\nOne of the most unusual modern American fountains is the Civil Rights Memorial (1989) at the Southern Poverty Law Center in Montgomery, Alabama, designed by Maya Lin, the designer of the Vietnam Veterans Memorial in Washington D.C. The \"Civil Rights Memorial\" fountain features a low elliptical black granite table, with a thin surface of water flowing over the surface, over the inscribed names of civil rights leaders who lost their lives, illustrating the quotation from Martin Luther King Jr.: \"...Until justice rolls down like waters and righteousness like a mighty stream.\" Visitors are invited to touch the names through the water. \"The water is as slow as I could get it,\" Lin wrote. \"It remains very still until you touch it. Your hand carves ripples, which transform and alter the piece, just as reading the words completes the piece.\"\n\n\n"}
{"id": "4951756", "url": "https://en.wikipedia.org/wiki?curid=4951756", "title": "Interactive Pager", "text": "Interactive Pager\n\nThe Inter@ctive Pager, introduced in 1996 by Research In Motion (RIM), allowed users to receive and send messages over the internet via a wireless data network known as Mobitex. The US Operator of Mobitex, RAM Mobile Data operated the network and introduced the Inter@ctive Pager service as RAMfirst Interactive Paging. The product was named the 1997 Top Product by Wireless for the Corporate User Magazine. The Inter@ctive Pager was also known as the RIM-900.\n\nIn August 1998, BellSouth Wireless Data replaced the RIM-900 with the RIM 950 and marketed the service as BellSouth Interactive Paging(sm).\n\nThe Interactive Paging service introduced wireless users to such features as peer-to-peer Delivery and Read Receipts and sending faxes and text to speech messages to a telephone. It also incorporated all the features of a traditional one way paging system (Interactive voice response, Telocator Alphanumeric input Protocol, etc..) and added two way extensions to those services. The devices communicated to the internet, peer users, and the PSTN via a Gateway which also served as the store and forward mailbox for the wireless user. Interactive Paging became known as Interactive Messaging Plus(sm) when BellSouth and SBC formed Cingular Wireless.\n\nRIM also produced a proprietary file format called IPD, or Inter@ctive Pager Database.\n\n"}
{"id": "43460961", "url": "https://en.wikipedia.org/wiki?curid=43460961", "title": "Johnson's Baby", "text": "Johnson's Baby\n\nJohnson's Baby is an American brand of baby cosmetics and skin care products owned by Johnson & Johnson. The brand dates back to 1893 when Johnson's Baby Powder was introduced. Product line consists of baby powder, shampoos, body lotions, massage oil, shower gels and baby wipes. The brand has reputation for making baby products that are \"exceptionally pure and safe\" since at least the 1980s.\n\nJohnson's Baby Powder was an invention of Dr. Frederick B. Kilmer, company's first director of scientific affairs. In 1892 he got a letter from a physician noting that patient suffered skin irritations after using medicated plasters. Kilmer suggested to use scented Italian talcum powder to mitigate the irritation and sent a can to the doctor.\n\nBaby Powder debuted in 1893 and went to the market in 1894. The earliest Baby Powder was in a yellow and red tin with a label \"For Toilet and Nursery”.\n\nAccording to Robert Shook, sanitary napkins were included in the young mother's kit but never considered a separate product until customers asked the company for it.\nThe first baby to appear on Johnson's Baby powder label was Mary Lea Johnson Richards, granddaughter of Robert Wood Johnson I (co-founder of Johnson & Johnson).\n\nJohnson's Baby Powder has a particular scent that for many Americans is associated with the smell of the baby itself. According to Johnson & Johnson's representative Fred Tewell (cited by Toronto Star), baby powder-scented cleaning products became almost a standard not only to cosmetics, but to diapers as well. And all Johnson's Baby products have a \"powdery\" note in them.\n\nJohnson's Baby cream was introduced in 1921.\n\nAccording to Margaret Gurowitz, Johnson & Johnson's corporate historian, in 1921 the company released its first \"Baby Gift Box\" that contained small packages of Baby Powder, Baby Cream and Baby Soap and \"was designed as a small gift that people could take when visiting a family with a new baby\".\n\nIntroduced in 1938 Johnson's Baby massage oil was heavily advertised nationwide (\"Life\" magazine) since 1943 as a complementary product to Baby Powder.\n\nOften referred as the \"Pink Brand\" (after the color of the bottle), Johnson's Baby Lotion appeared in 1942.\n\n\"No More Tears\" shampoo was introduced in 1953.\n\nAs noted by Nunes and Johnson:\n\nIn 1955 Johnson & Johnson placed advertising at the \"Adventures of Robin Hood TV series for Band-Aid and Johnson's baby shampoo. The later was advertised with the tagline \"Johnson's can't burn eyes\".\n\n\"No More Tears\" has been registered as a trademark only since 1959.\n\n\"No More Tangles\" shampoo (named after popular \"No More Tears\" shampoo) debuted in 1971.\n\nIn 1976 the brand entered publishing business with the book \"Infant development program: birth-12 months\" by Richard A. Chase, followed by \"The First wondrous year: you and your baby\" (1979) by Chase and Richard R. Rubin.\n\nJohnson's baby wipes appeared in 1980 as Johnson's Baby Wash Cloths.\n\nThe product was renamed \"wipes\" sometime during 90s (the product has already been present as early as 1990). In 1994 it was advertised as a better option for cleansing baby skin than water due to mild, pH-neutral cleansing lotion that wipes contain.\n\nSun screen was introduced in Spring 1991.\n\nHead-To-Toe ultra mild cleanser was introduced in 1997.\n\nBedtime Bath introduced in 2000 was the first of products later known as Johnson’s Baby Bedtime range with four products (Bedtime Bath, Bedtime Lotion, Bedtime Wash and Bedtime Oil) that contain lavender and camomile.\n\nIn 2001 Bedtime lotion was advertised in magazines like \"Working Mom Magazine\" as \"The world's first lullaby in a lotion\".\n\nIn 2015 the brand launched the \"So much more\" campaign focused on multi-sensory experiences (such as a massage during bathing) highlighting the benefits of such experiences for baby's development.\n\nThe company has been using \"Best for the Baby – Best for You\" tagline since the early days. Some examples of such advertising can be spotted as early as 1913, when only Johnson's Baby Powder existed.\n\nSometime in the beginning of 70s Johnson & Johnson started marketing baby products to families, promoting so-called \"family usage\".\n\nThe strategy has been a success. By the 80s Johnson's Baby grew market share in the adult market due to the perception that \"baby products are milder than others\". In 1985, for instance, 70 percent of Johnson's Baby powder in the United States was used by adults.\n\nJohnson's Baby products are widely used for non-baby occasions. For example, Johnson's Baby Oil is used as a facial cleanser (it has been reported by the \"New York\" magazine that popular TV talk show host Martha Stewart uses it this way), by male strippers as well as a lubricant in some sexual practices.\n\nIn December 1985 two physicians urged parents not to use baby powder, stating that it was unsafe to inhale and Johnson & Johnson responded with an official statement that \"product is safe when used as it is intended\".\n\nIn February 2016, J&J was ordered to pay $72 million in damages to the family of Jackie Fox, a 62-year-old woman who died of ovarian cancer in 2015. She had used Johnson's Baby Powder for many years. J&J claimed that the safety of cosmetic talc is supported by decades of scientific evidence and it plans to appeal the verdict. The British charity, Ovacome was quoted as saying that while there were 16 studies which showed that using talc increased the risk of ovarian cancer by around a third, and a 2013 review of US studies had similar results for genital, but not general, talcum powder use they were not convinced that the results were reliable. Furthermore, they said, \"Ovarian cancer is a rare disease, and increasing a small risk by a third still gives a small risk.\"\n\nIn 2007 Johnson & Johnson sponsored \"1st European Round Table meeting on 'Best Practice for Infant Cleansing\" (a panel of expert dermatologists and paediatricians from across Europe) focused on the use of liquid cleansers in bathing as opposed to washing with water. It has been concluded that \"bathing is generally superior to washing, provided basic safety procedures are followed, and has psychological benefits for the infant and parents\".\n\nA randomized clinical trial, sponsored by Johnson's baby brand in 2010 studied the effectiveness of using moisturizer as part of a standardized skin care regimen, for improving moisture levels in baby skin. Research showed that using baby lotion is effective for maintaining favorable moisture levels in baby skin (in comparison to not using baby lotion).\n\nIn February 2013 Journal of Obstetric, Gynecologic, & Neonatal Nursing published a research by academics at The University of Manchester that showed that washing newborn babies with Johnson’s Baby Top-to-Toe wash is just as safe as using water alone. Research has been sponsored by Johnson & Johnson \"but carried out under strict, independent scientific protocols, including blind testing and peer review\".\n"}
{"id": "42321402", "url": "https://en.wikipedia.org/wiki?curid=42321402", "title": "Kalashnikov grenade launcher", "text": "Kalashnikov grenade launcher\n\nAll AK-47 type rifles can mount a cup-type grenade-launcher that fires standard RGD-5 Soviet hand-grenades. The soup-can shaped launcher is screwed onto the AK-47’s muzzle. To fire, first insert a standard RGD-5 hand-grenade into the launcher and then remove the safety pin. Second, insert a special blank cartridge into the rifle's chamber. Third, place the butt-stock of the rifle on the ground and fire from this position. The maximum effective range is approximately 150 meters. This cup-type launcher can also be used to launch tear-gas and riot control grenades.\n"}
{"id": "8975421", "url": "https://en.wikipedia.org/wiki?curid=8975421", "title": "LaborNet", "text": "LaborNet\n\nLaborNet is a San Francisco-based \"democratic communications\" network for the labour movement. It was founded in 1991.\n\nAccording to LaborNet's website, its \"founders believe that the new communication technology must be put to use to revitalize and rebuild the labor movement. To that end we established the first regular Labor News web page in the United States.\" \n\nCurrently, the initiative has been expanded, with \"LaborNets\" being also set up in other places like Canada, United Kingdom, Austria, Germany, Japan and Korea. LaborNet says it also works to defend the internet from censorship and the privatization of information \"that would limit and destroy our rights to communicate and build world unionism.\"\n\n"}
{"id": "1679381", "url": "https://en.wikipedia.org/wiki?curid=1679381", "title": "List of industrial designers", "text": "List of industrial designers\n\nThe following industrial designers and product designers are among those who are noted for their accomplishments in industrial or product design, and/or who have made extraordinary contributions to industrial-design education or philosophy.\n\nThis list is categorized by the main design movements of the twentieth century. Although many industrial designers of this list followed many such trends, they are listed under the movement they are most associated with.\n\n\nNote - This category also includes preliminary work of the Wiener Werkstätte\n\n\n\n\n\n\n\n\nSensory design\n"}
{"id": "11337341", "url": "https://en.wikipedia.org/wiki?curid=11337341", "title": "List of on-air resignations", "text": "List of on-air resignations\n\nThis is a list of on-air resignations. These are resignations in the public eye.\n\n\n"}
{"id": "58966244", "url": "https://en.wikipedia.org/wiki?curid=58966244", "title": "MetaSolv Solution", "text": "MetaSolv Solution\n\nMetaSolv Solution (\"also known as MetaSolv or MSS\") is an Operations Support System database application originally created by MetaSolv Software, Inc. for use by the telcommunications industry. The company was acquired by Oracle Corporation, and Oracle still supports the application today under the umbrella of Oracle Communications. The software is used by many telecom companies (not just telephone, but ISPs, cable companies, and more).\n\nWhen MetaSolv was originally developed in the early 1990s, the new application was first referred to as ASAP (\"Access Services and Provisioning\"). ASAP provided a method for tracking equipment inventory, port consumption and circuit designs for engineering departments within telecom companies. But, by 1997, the need for tracking customer service orders was identified, and the system enhanced to provide for it. Along with order tracking, the need for workflow management was also addressed.\n\nBy the late 1990s, the application was rebranded by the company as TBS (\"Telecom Business Solution\") from version 3.10 through version 4.11, until the introduction of the 5.0 version. At that time (\"about 2003\"), MetaSolv Inc again rebranded the application, this time to MetaSolv Solution, also known as M/5. The latest release is often simply referred to simply as M6.\n\nMetaSolv Inc had several other products besides M6, and made efforts to provide seamless integration and connectivity between MetaSolv and those products in various ways. After Oracle acquired MetaSolv Inc (see below), Oracle absorbed all of MetaSolv Inc's products and continued the trend of integrating them. Even without those integrations, MetaSolv is a stand-alone OSS application that supports service provisioning through the entire life-cycle of customer and network development.\n\nMetaSolv Software Inc. (\"Nasdaq: MSLV\") was privately founded in 1992 soon becoming a leading provider of service fulfillment solutions designed to meet the needs of telecommunications providers. MetaSolv Inc became a publicly traded company offering an IPO in 1999. MetaSolv (\"the company\") was acquired by Oracle in 2006 for $219 million. On December 15, 2006, a majority of MetaSolv stockholders approved Oracle's acquisition of MetaSolv Software Inc.. Oracle continues to offer and maintain the application today.\n\nMetaSolv Solution (\"the software\") is an Oracle Database application sometimes described as \"Telco in a Box\". The system provides for many business processes common among all types of telecommunications businesses including:\n\n\nTypical implementation of MetaSolv within any telecom company often include users from Customer Care, Service Ordering, Engineering, Switching, Central Office and Field Technician departments.\n\nEarly in the development of the application, MetaSolv Inc realized the need to implement common industry standard practices such as those provided today by iConectiv (\"previously known as Telcordia Technologies, but rebranded after Ericsson acquired them\"). These standards included such things as standard equipment identifiers, circuit identification, location identification (\"commonly called CLLI code\"), connection codes (\"also known as Network Channel codes\"), rate codes, and much more. Across the industry, such standards are typically provided by iConectiv in the form of Common Language Information Services. By adding these standards to MetaSolv, the application more properly fit into the telecom OSS industry.\n\nLater however, companies expressed an interest in varying from industry standards. Releases after version 6.0 (6.1, 6.2, etc) included the ability to do so in some areas.\n\nToday, MetaSolv is often interfaced with other telecom company OSS/BSS systems through APIs and other means. Since the software is a front-end database application with an Oracle database behind it, multiple off-the-shelf SQL-based reporting tools are used to support business intelligence needs in several departments.\n\n\n"}
{"id": "2023546", "url": "https://en.wikipedia.org/wiki?curid=2023546", "title": "Military communications", "text": "Military communications\n\nMilitary communications or military signals involve all aspects of communications, or conveyance of information, by armed forces. Military communications span from pre-history to the present. The earliest military communications were delivered by runners. Later, communications progressed to visual and audible signals, and then advanced into the electronic age. Examples from \"Jane's Military Communications\" include text, audio, facsimile, tactical ground-based communications, terrestrial microwave, tropospheric scatter, naval, satellite communications systems and equipment, surveillance and signal analysis, encryption and security and direction-finding and jamming.\n\nIn past centuries communicating a message usually required someone to go to the destination, bringing the message. Thus, the term \"communication\" often implied the ability to transport people and supplies. A place under siege was one that lost communication in both senses. The association between transport and messaging declined in recent centuries.\n\nThe first military communications involved the use of runners or the sending and receiving of simple signals (sometimes encoded to be unrecognizable). The first distinctive uses of military communications were called \"signals\". Modern units specializing in these tactics are usually designated as \"signal corps\". The Roman system of military communication (\"cursus publicus\" or \"cursus vehicularis\") is an early example of this. Later, the terms \"signals\" and \"signaler\" became words referring to a highly-distinct military occupation dealing with general communications methods (similar to those in civil use) rather than with weapons.\n\nPresent-day military forces of an informational society conduct intense and complicated communicating activities on a daily basis, using modern telecommunications and computing methods. Only a small portion of these activities are directly related to combat actions.\n\nModern concepts of network-centric warfare (NCW) rely on network-oriented methods of communications and control to make existing forces more effective.\n\nDrums, horns, flags, and riders on horseback were some of the early methods the military used to send messages over distances. In the middle 20th century radio equipment came to dominate the field.\n\nMany modern pieces of military communications equipment are built to both encrypt and decode transmissions and survive rough treatment in hostile climates. They use different frequencies to send signals to other radios and to satellites.\n\nMilitary communications - or \"comms\" - are activities, equipment, techniques, and tactics used by the military in some of the most hostile areas of the earth and in challenging environments such as battlefields, on land, underwater and also in air. Military comms include command, control and communications and intelligence and were known as the C3I model before computers were fully integrated. The U.S. Army expanded the model to C4I when it recognized the vital role played by automated computer equipment to send and receive large, bulky amounts of data. \n\nThe advent of distinctive signals led to the formation of the signal corps, a group specialized in the tactics of military communications. The signal corps evolved into a distinctive occupation where the signaler became a highly technical job dealing with all available communications methods including civil ones. \n\nIn the modern world, most nations attempt to minimize the risk of war caused by miscommunication or inadequate communication. As a result, military communication is intense and complicated, and often motivates the development of advanced technology for remote systems such as satellites and aircraft, both manned and unmanned, as well as computers. Computers and their varied applications have revolutionized military comms. Although military communication is designed for warfare, it also supports intelligence-gathering and communication between adversaries, and thus sometimes prevents war.\n\nThere are six categories of military comms: the alert measurement systems, cryptography, military radio systems, nuclear command control, the signal corps, and network-centric warfare.\n\nThe alert measurement systems are various states of alertness or readiness for the armed forces used around the world during a state of war, act of terrorism or a military attack against a state. They are known by different acronyms, such as DEFCON, or defense readiness condition, used by the U.S. Armed Forces.\n\nCryptography is the study of methods of converting messages to a form unreadable except to one who knows how to decrypt them. This ancient military comms art gained new importance with the rise of radio systems whose signals traveled far and were easily intercepted. Cryptographic software is also widely used in civilian commerce.\n\nIn United States military communications systems, commercial refile refers to sending a military message via a commercial communications network. \nThe message may come from a military network, such as a tape relay network, a point-to-point telegraph network, a radio-telegraph network, or the Defense Switched Network.\n\nCommercial refiling of a message will usually require a reformatting of the message, particularly the heading.\n\n\n\n"}
{"id": "19644137", "url": "https://en.wikipedia.org/wiki?curid=19644137", "title": "Mobile phone", "text": "Mobile phone\n\nA mobile phone, cell phone or hand phone (short for mobile telephone, cellular telephone and handheld telephone respectively), sometimes shortened to simply mobile, cell or just phone, is a portable telephone that can make and receive calls over a radio frequency link while the user is moving within a telephone service area. The radio frequency link establishes a connection to the switching systems of a mobile phone operator, which provides access to the public switched telephone network (PSTN). Modern mobile telephone services use a cellular network architecture, and, therefore, mobile telephones are called \"cellular telephones\" or \"cell phones\", in North America. In addition to telephony, 2000s-era mobile phones support a variety of other services, such as text messaging, MMS, email, Internet access, short-range wireless communications (infrared, Bluetooth), business applications, video games, and digital photography. Mobile phones offering only those capabilities are known as feature phones; mobile phones which offer greatly advanced computing capabilities are referred to as smartphones.\n\nThe first handheld mobile phone was demonstrated by John F. Mitchell and Martin Cooper of Motorola in 1973, using a handset weighing c. 2 kilograms (4.4 lbs). In 1979, Nippon Telegraph and Telephone (NTT) launched the world's first cellular network in Japan. In 1983, the DynaTAC 8000x was the first commercially available handheld mobile phone. From 1983 to 2014, worldwide mobile phone subscriptions grew to over seven billion--enough to provide one for every person on Earth. In first quarter of 2016, the top smartphone developers worldwide were Samsung, Apple, and Huawei, with smartphone sales represented 78 percent of total mobile phone sales. For feature phones (or \"dumbphones\") as of 2016, the largest were Samsung, Nokia, and Alcatel.\n\nA handheld mobile radio telephone service was envisioned in the early stages of radio engineering. In 1917, Finnish inventor Eric Tigerstedt filed a patent for a \"pocket-size folding telephone with a very thin carbon microphone\". Early predecessors of cellular phones included analog radio communications from ships and trains. The race to create truly portable telephone devices began after World War II, with developments taking place in many countries. The advances in mobile telephony have been traced in successive \"generations\", starting with the early zeroth-generation (0G) services, such as Bell System's Mobile Telephone Service and its successor, the Improved Mobile Telephone Service. These 0G systems were not cellular, supported few simultaneous calls, and were very expensive.\nThe first handheld cellular mobile phone was demonstrated by John F. Mitchell and Martin Cooper of Motorola in 1973, using a handset weighing . The first commercial automated cellular network (1G) analog was launched in Japan by Nippon Telegraph and Telephone in 1979. This was followed in 1981 by the simultaneous launch of the Nordic Mobile Telephone (NMT) system in Denmark, Finland, Norway, and Sweden. Several other countries then followed in the early to mid-1980s. These first-generation (1G) systems could support far more simultaneous calls but still used analog cellular technology. In 1983, the DynaTAC 8000x was the first commercially available handheld mobile phone.\n\nIn 1991, the second-generation (2G) digital cellular technology was launched in Finland by Radiolinja on the GSM standard. This sparked competition in the sector as the new operators challenged the incumbent 1G network operators.\n\nTen years later, in 2001, the third generation (3G) was launched in Japan by NTT DoCoMo on the WCDMA standard. This was followed by 3.5G, 3G+ or turbo 3G enhancements based on the high-speed packet access (HSPA) family, allowing UMTS networks to have higher data transfer speeds and capacity.\n\nBy 2009, it had become clear that, at some point, 3G networks would be overwhelmed by the growth of bandwidth-intensive applications, such as streaming media. Consequently, the industry began looking to data-optimized fourth-generation technologies, with the promise of speed improvements up to ten-fold over existing 3G technologies. The first two commercially available technologies billed as 4G were the WiMAX standard, offered in North America by Sprint, and the LTE standard, first offered in Scandinavia by TeliaSonera.\n\n5G is a technology and term used in research papers and projects to denote the next major phase in mobile telecommunication standards beyond the 4G/IMT-Advanced standards. The term 5G is not officially used in any specification or official document yet made public by telecommunication companies or standardization bodies such as 3GPP, WiMAX Forum or ITU-R. New standards beyond 4G are currently being developed by standardization bodies, but they are at this time seen as under the 4G umbrella, not for a new mobile generation.\n\nSmartphones have a number of distinguishing features. The International Telecommunication Union measures those with Internet connection, which it calls \"Active Mobile-Broadband subscriptions\" (which includes tablets, etc.). In the developed world, smartphones have now overtaken the usage of earlier mobile systems. However, in the developing world, they account for around 50% of mobile telephony.\n\nFeature phone is a term typically used as a retronym to describe mobile phones which are limited in capabilities in contrast to a modern smartphone. Feature phones typically provide voice calling and text messaging functionality, in addition to basic multimedia and Internet capabilities, and other services offered by the user's wireless service provider. A feature phone has additional functions over and above a basic mobile phone which is only capable of voice calling and text messaging. Feature phones and basic mobile phones tend to use a proprietary, custom-designed software and user interface. By contrast, smartphones generally use a mobile operating system that often shares common traits across devices.\n\nThere are Orthodox Jewish religious restrictions which, by some interpretations, standard mobile telephones overstep. To deal with this problem, some rabbinical organizations have recommended that phones with text-messaging capability not be used by children. Phones with restricted features are known as kosher phones and have rabbinical approval for use in Israel and elsewhere by observant Orthodox Jews. Although these phones are intended to prevent immodesty, some vendors report good sales to adults who prefer the simplicity of the devices. Some phones are approved for use by essential workers (such as health, security, and public service workers) on the sabbath, even though the use of any electrical device is generally prohibited during this time.\n\nMobile phones communicate with cell towers that are placed to give coverage across a telephone service area which is divided up into 'cells'. Each cell uses a different set of frequencies from neighbouring cells, and will typically be covered by 3 towers placed at different locations. The cell towers are usually interconnected to each other and the phone network and the internet by wired connections. Due to bandwidth limitations each cell will have a maximum number of cell phones it can handle at once. The cells are therefore sized depending on the expected usage density, and may be much smaller in cities. In that case much lower transmitter powers are used to avoid broadcasting beyond the cell.\n\nAs a phone moves around, a phone will \"hand off\"- automatically disconnect and reconnect to the tower that gives the best reception.\n\nAdditionally, short-range Wi-Fi infrastructure is often used by smartphones as much as possible as it offloads traffic from cell networks on to local area networks.\n\nThe common components found on all phones are:\n\n\nLow-end mobile phones are often referred to as feature phones and offer basic telephony. Handsets with more advanced computing ability through the use of native software applications are known as smartphones.\n\nMobile phones have central processing units (CPUs), similar to those in computers, but optimised to operate in low power environments.\n\nMobile CPU performance depends not only on the clock rate (generally given in multiples of hertz) but also the memory hierarchy also greatly affects overall performance. Because of these problems, the performance of mobile phone CPUs is often more appropriately given by scores derived from various standardized tests to measure the real effective performance in commonly used applications.\n\nOne of the main characteristics of phones is the screen. Depending on the device's type and design, the screen fills most or nearly all of the space on a device's front surface. Many smartphone displays have an aspect ratio of , but taller aspect ratios became more common in 2017.\n\nScreen sizes are measured in diagonal inches; feature phones generally have screen sizes below 3.5 inches. Phones with screens larger than 5.2 inches are often called \"phablets.\" Smartphones with screens over 4.5 inches in size are commonly difficult to use with only a single hand, since most thumbs cannot reach the entire screen surface; they may need to be shifted around in the hand, held in one hand and manipulated by the other, or used in place with both hands. Due to design advances, some modern smartphones with large screen sizes and \"edge-to-edge\" designs have compact builds that improve their ergonomics, while the shift to taller aspect ratios have resulted in phones that have larger screen sizes whilst maintaining the ergonomics associated with smaller 16:9 displays.\n\nLiquid-crystal displays are the most common; others are IPS, LED, OLED, and AMOLED displays. Some displays are integrated with pressure-sensitive digitizers, such as those developed by Wacom and Samsung, and Apple's \"3D Touch\" system.\n\nIn sound, smartphones and feature phones vary little. Some audio-quality enhancing features, such as Voice over LTE and HD Voice, have appeared and are often available on newer smartphones. Sound quality can remain a problem due to the design of the phone, the quality of the cellular network and compression algorithms used in long distance calls. Audio quality can be improved using a VoIP application over WiFi. Cellphones have small speakers so that the user can use a speakerphone feature and talk to a person on the phone without holding it to their ear. The small speakers can also be used to listen to digital audio files of music or speech or watch videos with an audio component, without holding the phone close to the ear.\n\nThe average phone battery lasts 2-3 years at best. Many of the wireless devices use a Lithium-Ion (Li-Ion) battery, which charges 500-2500 times, depending on how users take care of the battery and the charging techniques used. It is only natural for these rechargeable batteries to chemically age, which is why the performance of the battery when used for a year or two will begin to deteriorate. Battery life can be extended by draining it regularly, not overcharging it, and keeping it away from heat.\n\nMobile phones require a small microchip called a Subscriber Identity Module or SIM card, in order to function. The SIM card is approximately the size of a small postage stamp and is usually placed underneath the battery in the rear of the unit. The SIM securely stores the service-subscriber key (IMSI) and the K used to identify and authenticate the user of the mobile phone. The SIM card allows users to change phones by simply removing the SIM card from one mobile phone and inserting it into another mobile phone or broadband telephony device, provided that this is not prevented by a SIM lock. The first SIM card was made in 1991 by Munich smart card maker Giesecke & Devrient for the Finnish wireless network operator Radiolinja. \n\nA hybrid mobile phone can hold up to four SIM cards, with a phone having an IMEI per SIM Card. SIM and R-UIM cards may be mixed together to allow both GSM and CDMA networks to be accessed. From 2010 onwards, such phones became popular in emerging markets, and this was attributed to the desire to obtain the lowest on-net calling rate.\n\nFeature phones have basic software platforms.\n\nSmartphones have advanced software platforms.\n\nA mobile app is a computer program designed to run on a mobile device, such as a smartphone. The term \"app\" is a shortening of the term \"software application\".\n\n\nA common data application on mobile phones is Short Message Service (SMS) text messaging. The first SMS message was sent from a computer to a mobile phone in 1992 in the UK while the first person-to-person SMS from phone to phone was sent in Finland in 1993. The first mobile news service, delivered via SMS, was launched in Finland in 2000, and subsequently many organizations provided \"on-demand\" and \"instant\" news services by SMS. Multimedia Messaging Service (MMS) was introduced in 2001.\n\nThe introduction of Apple's App Store for the iPhone and iPod Touch in July 2008 popularized manufacturer-hosted online distribution for third-party applications (software and computer programs) focused on a single platform. There are a huge variety of apps, including video games, music products and business tools. Up until that point, smartphone application distribution depended on third-party sources providing applications for multiple platforms, such as GetJar, Handango, Handmark, and PocketGear. Following the success of the App Store, other smartphone manufacturers launched application stores, such as Google's Android Market (later renamed to the Google Play Store) and RIM's BlackBerry App World and Android-related app stores like F-Droid. In February 2014, 93% of mobile developers were targeting smartphones first for mobile app development.\n\nFrom 1983 to 1998, Motorola was market leader in mobile phones. Nokia was the market leader in mobile phones from 1998 to 2012. In Q1 2012, Samsung surpassed Nokia, selling 93.5 million units as against Nokia's 82.7 million units. Samsung has retained its top position since then. In 2017, the top five manufacturers worldwide were Samsung (20.9%), Apple (14.0%), Huawei (9.8%), Oppo (5.7%), and Vivo (6.5%). During Q2 2018, Huawei overtook Apple as the world's second-largest phone manufacturer.\n\nThe world's largest individual mobile operator by number of subscribers is China Mobile, which has over 902 million mobile phone subscribers . Over 50 mobile operators have over ten million subscribers each, and over 150 mobile operators had at least one million subscribers by the end of 2009. In 2014, there were more than seven billion mobile phone subscribers worldwide, a number that is expected to keep growing.\n\nMobile phones are used for a variety of purposes, such as keeping in touch with family members, for conducting business, and in order to have access to a telephone in the event of an emergency. Some people carry more than one mobile phone for different purposes, such as for business and personal use. Multiple SIM cards may be used to take advantage of the benefits of different calling plans. For example, a particular plan might provide for cheaper local calls, long-distance calls, international calls, or roaming.\n\nThe mobile phone has been used in a variety of diverse contexts in society. For example:\n\nIn 1998, one of the first examples of distributing and selling media content through the mobile phone was the sale of ringtones by Radiolinja in Finland. Soon afterwards, other media content appeared, such as news, video games, jokes, horoscopes, TV content and advertising. Most early content for mobile phones tended to be copies of legacy media, such as banner advertisements or TV news highlight video clips. Recently, unique content for mobile phones has been emerging, from ringtones and ringback tones to mobisodes, video content that has been produced exclusively for mobile phones.\n\nIn many countries, mobile phones are used to provide mobile banking services, which may include the ability to transfer cash payments by secure SMS text message. Kenya's M-PESA mobile banking service, for example, allows customers of the mobile phone operator Safaricom to hold cash balances which are recorded on their SIM cards. Cash can be deposited or withdrawn from M-PESA accounts at Safaricom retail outlets located throughout the country and can be transferred electronically from person to person and used to pay bills to companies.\n\nBranchless banking has also been successful in South Africa and the Philippines. A pilot project in Bali was launched in 2011 by the International Finance Corporation and an Indonesian bank, Bank Mandiri.\n\nAnother application of mobile banking technology is Zidisha, a US-based nonprofit micro-lending platform that allows residents of developing countries to raise small business loans from Web users worldwide. Zidisha uses mobile banking for loan disbursements and repayments, transferring funds from lenders in the United States to borrowers in rural Africa who have mobile phones and can use the Internet.\n\nMobile payments were first trialled in Finland in 1998 when two Coca-Cola vending machines in Espoo were enabled to work with SMS payments. Eventually, the idea spread and in 1999, the Philippines launched the country's first commercial mobile payments systems with mobile operators Globe and Smart.\n\nSome mobile phones can make mobile payments via direct mobile billing schemes, or through contactless payments if the phone and the point of sale support near field communication (NFC). Enabling contactless payments through NFC-equipped mobile phones requires the co-operation of manufacturers, network operators, and retail merchants.\n\nMobile phones are commonly used to collect location data. While the phone is turned on, the geographical location of a mobile phone can be determined easily (whether it is being used or not) using a technique known as multilateration to calculate the differences in time for a signal to travel from the mobile phone to each of several cell towers near the owner of the phone.\n\nThe movements of a mobile phone user can be tracked by their service provider and if desired, by law enforcement agencies and their governments. Both the SIM card and the handset can be tracked.\n\nChina has proposed using this technology to track the commuting patterns of Beijing city residents. In the UK and US, law enforcement and intelligence services use mobile phones to perform surveillance operations. They possess technology that enables them to activate the microphones in mobile phones remotely in order to listen to conversations which take place near the phone.\n\nHackers are able to track a phone's location, read messages, and record calls, just by knowing the phone number.\n\nMobile phone use while driving, including talking on the phone, texting, or operating other phone features, is common but controversial. It is widely considered dangerous due to distracted driving. Being distracted while operating a motor vehicle has been shown to increase the risk of accidents. In September 2010, the US National Highway Traffic Safety Administration (NHTSA) reported that 995 people were killed by drivers distracted by cell phones. In March 2011, a U.S. insurance company, State Farm Insurance, announced the results of a study which showed 19% of drivers surveyed accessed the Internet on a smartphone while driving. Many jurisdictions prohibit the use of mobile phones while driving. In Egypt, Israel, Japan, Portugal, and Singapore, both handheld and hands-free use of a mobile phone (which uses a speakerphone) is banned. In other countries, including the UK and France and in many U.S. states, only handheld phone use is banned while hands-free use is permitted.\n\nA 2011 study reported that over 90% of college students surveyed text (initiate, reply or read) while driving.\nThe scientific literature on the dangers of driving while sending a text message from a mobile phone, or \"texting while driving\", is limited. A simulation study at the University of Utah found a sixfold increase in distraction-related accidents when texting.\n\nDue to the increasing complexity of mobile phones, they are often more like mobile computers in their available uses. This has introduced additional difficulties for law enforcement officials when attempting to distinguish one usage from another in drivers using their devices. This is more apparent in countries which ban both handheld and hands-free usage, rather than those which ban handheld use only, as officials cannot easily tell which function of the mobile phone is being used simply by looking at the driver. This can lead to drivers being stopped for using their device illegally for a phone call when, in fact, they were using the device legally, for example, when using the phone's incorporated controls for car stereo, GPS or satnav.\n\nA 2010 study reviewed the incidence of mobile phone use while cycling and its effects on behaviour and safety. In 2013, a national survey in the US reported the number of drivers who reported using their cellphones to access the Internet while driving had risen to nearly one of four. A study conducted by the University of Vienna examined approaches for reducing inappropriate and problematic use of mobile phones, such as using mobile phones while driving.\n\nAccidents involving a driver being distracted by talking on a mobile phone have begun to be prosecuted as negligence similar to speeding. In the United Kingdom, from 27 February 2007, motorists who are caught using a hand-held mobile phone while driving will have three penalty points added to their license in addition to the fine of £60. This increase was introduced to try to stem the increase in drivers ignoring the law. Japan prohibits all mobile phone use while driving, including use of hands-free devices. New Zealand has banned hand-held cell phone use since 1 November 2009. Many states in the United States have banned texting on cell phones while driving. Illinois became the 17th American state to enforce this law. As of July 2010, 30 states had banned texting while driving, with Kentucky becoming the most recent addition on 15 July.\n\nPublic Health Law Research maintains a list of distracted driving laws in the United States. This database of laws provides a comprehensive view of the provisions of laws that restrict the use of mobile communication devices while driving for all 50 states and the District of Columbia between 1992 when first law was passed, through 1 December 2010. The dataset contains information on 22 dichotomous, continuous or categorical variables including, for example, activities regulated (e.g., texting versus talking, hands-free versus handheld), targeted populations, and exemptions.\n\nIn 2010, an estimated 1500 pedestrians were injured in the US while using a cellphone and some jurisdictions have attempted to ban pedestrians from using their cellphones.\n\nThe effect of mobile phone radiation on human health is the subject of recent interest and study, as a result of the enormous increase in mobile phone usage throughout the world. Mobile phones use electromagnetic radiation in the microwave range, which some believe may be harmful to human health. A large body of research exists, both epidemiological and experimental, in non-human animals and in humans. The majority of this research shows no definite causative relationship between exposure to mobile phones and harmful biological effects in humans. This is often paraphrased simply as the balance of evidence showing no harm to humans from mobile phones, although a significant number of individual studies do suggest such a relationship, or are inconclusive. Other digital wireless systems, such as data communication networks, produce similar radiation.\n\nOn 31 May 2011, the World Health Organization stated that mobile phone use may possibly represent a long-term health risk, classifying mobile phone radiation as \"possibly carcinogenic to humans\" after a team of scientists reviewed studies on mobile phone safety. The mobile phone is in category 2B, which ranks it alongside coffee and other possibly carcinogenic substances.\n\nSome recent studies have found an association between mobile phone use and certain kinds of brain and salivary gland tumors. Lennart Hardell and other authors of a 2009 meta-analysis of 11 studies from peer-reviewed journals concluded that cell phone usage for at least ten years \"approximately doubles the risk of being diagnosed with a brain tumor on the same ('ipsilateral') side of the head as that preferred for cell phone use\".\n\nOne study of past mobile phone use cited in the report showed a \"40% increased risk for gliomas (brain cancer) in the highest category of heavy users (reported average: 30 minutes per day over a 10‐year period)\". This is a reversal of the study's prior position that cancer was unlikely to be caused by cellular phones or their base stations and that reviews had found no convincing evidence for other health effects. However, a study published 24 March 2012, in the \"British Medical Journal\" questioned these estimates because the increase in brain cancers has not paralleled the increase in mobile phone use. Certain countries, including France, have warned against the use of mobile phones by minors in particular, due to health risk uncertainties. Mobile pollution by transmitting electromagnetic waves can be decreased up to 90% by adopting the circuit as designed in mobile phone and mobile exchange.\n\nIn May 2016, preliminary findings of a long-term study by the U.S. government suggested that radio-frequency (RF) radiation, the type emitted by cell phones, can cause cancer.\n\nA study by the London School of Economics found that banning mobile phones in schools could increase pupils' academic performance, providing benefits equal to one extra week of schooling per year.\n\nStudies have shown that around 40–50% of the environmental impact of mobile phones occurs during the manufacture of their printed wiring boards and integrated circuits.\n\nThe average user replaces their mobile phone every 11 to 18 months, and the discarded phones then contribute to electronic waste. Mobile phone manufacturers within Europe are subject to the WEEE directive, and Australia has introduced a mobile phone recycling scheme.\n\nApple Inc. had an advanced robotic disassembler and sorter called Liam specifically for recycling outdated or broken iPhones.\n\nAccording to the Federal Communications Commission, one out of three robberies involve the theft of a cellular phone. Police data in San Francisco show that half of all robberies in 2012 were thefts of cellular phones. An online petition on Change.org, called \"Secure our Smartphones\", urged smartphone manufacturers to install kill switches in their devices to make them unusable if stolen. The petition is part of a joint effort by New York Attorney General Eric Schneiderman and San Francisco District Attorney George Gascón and was directed to the CEOs of the major smartphone manufacturers and telecommunication carriers. On Monday, 10 June 2013, Apple announced that it would install a \"kill switch\" on its next iPhone operating system, due to debut in October 2013.\n\nAll mobile phones have a unique identifier called IMEI. Anyone can report their phone as lost or stolen with their Telecom Carrier, and the IMEI would be blacklisted with a central registry. Telecom carriers, depending upon local regulation can or must implement blocking of blacklisted phones in their network. There are, however, a number of ways to circumvent a blacklist. One method is to send the phone to a country where the telecom carriers are not required to implement the blacklisting and sell it there, another involves altering the phone's IMEI number. Even so, mobile phones typically have less value on the second-hand market if the phones original IMEI is blacklisted.\n\nAn unusual example of a phone bill caused by theft (reported on 28 June 2018) was when a biological group in Poland put a GPS tracker on a white stork and released it; during autumn migration over the Blue Nile valley in eastern Sudan someone got hold of the stork's GPS tracker, and found in it a mobile-phone-type sim card, which he put in his mobile phone, and made 20 hours of calls on it, running up a bill of over 10,000 Polish zlotys (= $2700) for the biological group.\n\nDemand for metals used in mobile phones and other electronics fuelled the Second Congo War, which claimed almost 5.5 million lives. In a 2012 news story, \"The Guardian\" reported: \"In unsafe mines deep underground in eastern Congo, children are working to extract minerals essential for the electronics industry. The profits from the minerals finance the bloodiest conflict since the second world war; the war has lasted nearly 20 years and has recently flared up again. ... For the last 15 years, the Democratic Republic of the Congo has been a major source of natural resources for the mobile phone industry.\" The company Fairphone has worked to develop a mobile phone that does not contain conflict minerals.\n\n\n"}
{"id": "23800840", "url": "https://en.wikipedia.org/wiki?curid=23800840", "title": "Modular construction", "text": "Modular construction\n\nModular construction is the use of volumetric building modules where the units form the structure of the building as well as enclose usable space. Modular construction is particularly popular for hotels and student residences due to the economies of scale available from many similar sized modules and the particular benefit of reduced site construction time.\n\nModular construction can help eliminate or reduce many hazards associated with traditional construction can be avoided including: \nUse of modular construction methods is encouraged by proponents of Prevention through Design techniques in construction. It is included as a recommended hazard control for construction projects in the \"PtD - Architectural Design and Construction Education Module\" published by the National Institute for Occupational Safety and Health.\n\n"}
{"id": "30737379", "url": "https://en.wikipedia.org/wiki?curid=30737379", "title": "Nanobiomechanics", "text": "Nanobiomechanics\n\nNanobiomechanics (also bionanomechanics) is an emerging field in nanoscience and biomechanics that combines the powerful tools of nanomechanics to explore fundamental science of biomaterials and biomechanics.\n\nSince the introduction by its founder Yuan-Cheng Fung, the field of biomechanics has become one of the branches of mechanics and bioscience. For many years, biomechanics has examined tissue. Through advancements in nanoscience, the scale of the forces that could be measured and also the scale of observation of biomaterials was reduced to \"nano\" and \"pico\" level. Consequently, it became possible to measure the mechanical properties of biological materials at nanoscale.\n\nMost of the biological materials have different hierarchical levels, and the smallest ones refer to the nanoscale. For example, bone has up to seven levels of biological organization, and the smallest level, i.e., single collagen fibril and hydroxylapatite minerals have dimensions well below 100 nm. Therefore, being able to probe properties at this small scales provides a great opportunity for better understanding the fundamental properties of these materials. For example, measurements have shown that nanomechanical heterogeneity exists even within single collagen fibrils as small as 100 nm.\n\nOne of the other most relevant topics in this field is measurement of tiny forces on living cells to recognize changes caused by different diseases. For example, it has been shown that red blood cells infected by malaria are 10 times stiffer than normal cells. Likewise, it has been shown that cancer cells are 70 percent softer than normal cells. Early signs of aging cartilage and osteoarthritis has been shown by looking at the changes in the tissue at the nanoscale.\n\nThe common methods in nanobiomechanics are atomic force microscope, optical tweezers, and magnetic twisting cytometry.\n\nExamples of relevant materials are bone and its hierarchical constituents such as single collagen fibrils, single living cells, actin filaments and microtubules,\nand synthetic peptide nanotubes.\n\nIn addition to experimental aspect, research has been expanding through computational methods. Molecular dynamics (MD) simulations have provided a wealth of knowledge in this area. Although, the MD simulation are still limited to a small number of atoms and molecules, due to limitation in the computational performance, they have proved to be an instrumental branch of this emerging field.\n"}
{"id": "3430593", "url": "https://en.wikipedia.org/wiki?curid=3430593", "title": "Nitro engine", "text": "Nitro engine\n\nA nitro engine generally refers to an engine powered with a fuel that contains some portion (usually between 10% and 40%) of nitromethane mixed with methanol. Nitromethane is a highly combustible substance that is generally only used in very specifically designed engines found in Top Fuel drag racing and miniature internal combustion engines in radio control, control line and free flight model aircraft.\n\nThe term \"nitro\" has only come into use in the last few years to describe these engines and has its origins in marketing hype in the model car market. For the fifty or so years prior to this term since the engines were first developed, they were simply referred to as \"glow engines\", but the term \"nitro\" has more impact in ad copy. These engines are actually fueled by methanol, but the fuel is often doped with nitromethane as a performance additive. The ignition system consists of a glow plug - hence the older term \"glow\" engine - which has a coil of platinum-containing wire alloy, usually platinum-Iridium. The glow plug is heated with electric current for starting, after which power is disconnected and the combination of residual heat and catalytic action of the platinum alloy with methanol ignites the fuel mixture.\n\nNitro engines for models can turn in excess of 50,000 RPM. Typical operating rpm for sport model aircraft engines is 10,000-14,000 rpm. For radio control (RC) boats and ducted fan aircraft engines, 20,000-25,000 is the usual range, and for cars rpm in the range of 25,000-37,000 is common. With this much movement, a lot of frictional heat is generated and the fuel used for these engines usually contains between 12-20% oil content depending on the nitromethane and methanol percentage, the engine type and application. Most engines in RC cars today are 2 stroke engines, which means that it takes 2 strokes of the piston (one revolution) to complete the engine cycle. On the first stroke as the piston travels upward, a mixture of fuel and air is sucked into the crankcase, from the carburettor. When the piston travels downward the new fuel air mixture travels into the induction port and finally into the combustion chamber. As the piston travels upward the mixture is compressed which causes the fuel/air mixture to ignite, producing hot gas under pressure to force the piston down. As the piston travels downward the spent exhaust gases escape out of the combustion chamber through the exhaust port, and the cycle starts over by the fuel mixture being again pushed into the induction port.\n\nWhen starting, the glow plug is electrically preheated by electric current. The glow plug is not to be confused with a spark plug - there is no spark in the glow plug. Catalysis from methanol vapor on the heated platinum element keeps it red-hot even after voltage has been removed, which ignites the fuel and keeps the engine running. Whereas spark plugs are constantly used to ignite the fuel/air mix every time the piston comes up, as seen in the petrol engine where the spark plug is used, the fuel cannot be ignited with compression alone. It is the plug's temperature, still red-hot from previous ignition and from catalysis with the new compressed mixture, that ignites the fuel.\n\nNitros engines typically use a carburetor to mix the fuel and air together, although for some applications where throttling is not required they have a simple venturi with a spraybar and needle valve. The carburetor can either be sliding or rotary. On a rotary carburetor, the slide is opened as the arm is turned by the servo. On a slide carburetor the slide is opened by sliding the arm out by the servo. Both are held open slightly by an idle screw which allows the engine to receive a very small amount of fuel to keep the engine running when the vehicle is at a stop. The carburetors usually feature 2 needles used to tune the mixture. A high speed needle tunes how much fuel is allowed into the carburetor at mid to high RPM, and a low speed needle determines how much fuel is allowed into the carburetor at low to mid range RPM. Turning either needle in a clockwise motion will thin the fuel mixture. Lean describes the amount of fuel in the fuel / air mixture. To a point this will make the engine run faster with better performance, but once too lean the engine will overheat, and wear out prematurely due to not receiving enough lubrication. Turning either needle counterclockwise will enrich the fuel mixture (unless the low speed needle is an air bleed in which case the opposite is true). Rich is the opposite of lean, it means more oil (fuel mixture) is entering the engine. If the engine is too rich, it will run poorly, and fuel that has not yet been burnt may start to spit out of the exhaust. The engine will run very slowly and seem to have no power and possibly cut out from being flooded with fuel. Although, being too rich is better than being too lean, because being too rich just means the engine is getting too much oil which is perfectly fine, although performance may not be as good as if the engine were lean. An excessively lean mixture can damage an engine in a short time, as it will run above its design temperature. A properly tuned engine will last a long time with good performance throughout its life.\n\nThere are several different types of R/C engines. There are on-road, off-road, aircraft, marine, and monster truck engines. \n\nOn-road engines are designed to come into their power band from mid to high RPM. These engines can be used in off-road vehicles but are normally used in on-road sedans where very high RPM and high speed is required. Off-road engines have a less abrupt power curve compared to on-road engines. Off-road engines have a power band that extends through most of the RPM range. Off-road engines do not rev as high as on-road engines, but they do have more torque that can easily propel the vehicle it is in to impressive speeds. Off-road engines are usually used in 1/8 scale buggies where high speeds and good acceleration are required.\n\nMonster truck engines are generally very large compared to on-road and off-road engines. Where an off-road engine may be 0.21 cubic inch (ci) size, a monster truck engine may be as much as 0.46 ci. Monster truck engines generate much of their torque and horsepower at low to mid range RPM. They are usually used in large and heavy trucks where all that power is needed to get good performance out of the vehicle.\n\nAircraft engines are manufactured to be able to sustain high RPM. The biggest difference between all other nitro engines and aircraft engines is the ability to sustain RPM. Other nitro engines tend to break if run at full throttle for a full tank of fuel.\n\nMarine engines are cooled with water rather than air like other nitro engines.\n\nMembers of the full scale drag racing industry use much higher concentrations of nitromethane: they are limited by the rules to 90% (at least in the NHRA, the main sanctioning body). Historically, racers used higher percentages which frequently caused massive explosions. Modern engines are estimated to generate around 8000 horsepower. The cars can accelerate from 0 to 100mph in 0.8 seconds and 0 to 335mph in 4.5 seconds.\n\n"}
{"id": "3802554", "url": "https://en.wikipedia.org/wiki?curid=3802554", "title": "OKFOL", "text": "OKFOL\n\nOKFOL is an explosive, used in a variety of applications. It is particularly suitable for use in shaped charges. It normally consists of 95% HMX phlegmatized with 5% wax. It has a density of 1.777 grams per cubic centimetre and an explosive velocity of 8,670 metres per second.\n\n"}
{"id": "17209699", "url": "https://en.wikipedia.org/wiki?curid=17209699", "title": "PUSH (university guide)", "text": "PUSH (university guide)\n\nPush is a British media organisation that offers information to university applicants and students in the United Kingdom.\n\nIts flagship is now the website Push.co.uk, which features profiles of every UK university, advice about choosing a university and student finance, and a tool called the 'Uni Chooser' which allows users to create a shortlist of suitable universities sorted according to a large variety of criteria. Push describes itself as \"the ruthlessly independent guide to UK universities\" and uses the tagline \"Push… like it is\".\n\nPreviously, Push published a range of books including \"The Push Guide to Which University\", \"The Push Guide to Money\" and \"The Push Guide to Choosing a University\", but these are now out of print and their content has been updated, extended and incorporated into the Push website. In association with various sponsors, Push also conducts an annual tour of schools and sixth-form colleges, delivering guidance talks and reaching around 200 institutions each year.\n\nPush was founded in 1992 by two brothers, Johnny Rich and Ben Rich, to publish the Polytechnic and University Student Handbook. It differed from other similar books because they did not give copy approval to the universities included and covered a wider range of concerns, particularly those relating to non-academic features of student life. The first edition of the book coincided with legislation that led to the transformation of all British polytechnics into universities, but the acronym was retained as the book had provoked considerable media interest. In particular, attention focused on what Push called 'flunk rates' (i.e. the proportion of students who dropped out or failed their courses), which were revealed in a comparative form for the first time.\n\nThe website was launched in 1996 and, shortly afterwards, Ben Rich left Push as his career in public relations demanded too much of his time.\n\nJohnny Rich still manages the organisation as editor and is an acknowledged authority on university applications and student life and finance. He makes regular media appearances.\n\nIn 2005, Push became a division of Independent News & Media, publishers of The Independent newspaper. Push left The Independent in 2010 and merged with Real World, a print and online magazine providing careers information and advice for graduates.\n\nPush's research methodology is significantly different from similar resources such as league tables of British universities published by several UK newspapers. Although it uses publicly available data from Higher Education Statistics Agency, National Student Survey and other sources, Push also originates most of its own research from a series of lengthy questionnaires sent to the universities and students unions and from annual site visits by Push's own research team to every UK university. These visits involve face-to-face interviews with students from the university.\n\nThis research is published in the form of detailed profiles of each university and in a number of statistical tables and top ten lists for individual criteria.\n\nThe following are among the statistics exclusive to Push:\n\n\nMedia attention is also often given to data published about sex ratios at each university, clearing rates (i.e. the proportion of student arriving through the UCAS clearing system), the availability and cost of housing, famous alumni and the provision of welfare.\n\nPush has a stated opposition to the league tables of British universities and Johnny Rich has been outspoken on the subject on a number of occasions. Push's position is that \"Any university ranking is based on what its inventors think is important, but their priorities may be a snail's hike from yours.\" In an effort to prove the point and provoke controversy, on April Fools' Day 2008 Push published its own alternative league table which used what it argued were more student-centred criteria and which featured very different universities at the top of the list. These included \nLampeter University in first place and two institutions – Harper Adams University College and Bishop Grosseteste University College – which had only gained full university status in the past year. Neither Oxford University nor Cambridge University made it into the top ten.\n\nPush makes extensive use of interesting snippets of information about universities and student life. For example:\n\n\n\n"}
{"id": "3461195", "url": "https://en.wikipedia.org/wiki?curid=3461195", "title": "Park Royal", "text": "Park Royal\n\nPark Royal is an area in northwest London, England. It is the site of the largest business park in London, occupying about . Park Royal Business Park is promoted commercially by the Park Royal Business Group (PRBG) which is part of West London Business. Park Royal is partly in the London Borough of Brent and partly the London Borough of Ealing.\n\nPark Royal business park has over 1,200 businesses, employing an estimated 35,000 workers. Approximately 500 food companies operate at Park Royal, employing more than 14,000 people. One third of all the food consumed in London is supplied by businesses in Park Royal. Park Royal also has areas of residential housing and amenities serving them.\n\nTo the north of Park Royal is Harlesden in the northeast, West Twyford, an outlying area of Ealing, in the northwest, and a Network Rail depot at Stonebridge Park in the far north, which also has London Underground Bakerloo line tracks running through it (and Harlesden station nearby). On the eastern side, Park Royal is bounded by Acton Lane and Park Royal Road (B4492). The Central Middlesex Hospital is located here.\n\nOn the southern side beyond the arterial Western Avenue (A40), which leads to the Hanger Lane Gyratory System, is the Royale Leisure Park, which contains a cinema, restaurants, arcade and a bowling alley. There is also a B&Q superstore, Renault and Nissan Car Dealerships, a Staples Superstore and other industrial buildings comprising the southern half of Park Royal. Park Royal Underground station, on the Piccadilly line, is located just off Western Avenue. To the west of Park Royal is Hanger Hill and the North Circular Road (A406).\n\nAs well as many small industrial firms, Park Royal is the location of some large company buildings, including McVities and Heinz. The old Guinness brewery and sports ground site at the south-western extremity of the district has now been totally demolished, however the rail sidings are still in use for aggregate freight traffic supplying the Lafarge Tarmac depot. The first building erected adjacent to the new roundabout and bridge link to Western Avenue is occupied by international drinks company Diageo, owner of the Guinness brand and the redevelopment site. The Female Health Company, which manufactures Femidoms, has one of its two manufacturing plants here, too.\n\nThe Grand Union Canal runs through the middle of the Park Royal industrial estate, with pedestrian access via the towpath.\n\nThe name Park Royal derives from the short-lived showgrounds opened in 1903 by the Royal Agricultural Society as a permanent exhibition site for the society's annual show. After only three years the society sold the site, and returned to a touring format for its shows. With its road, rail and canal links, Park Royal was subsequently developed for industrial use, mainly during the 1930s.\nFor many years it was a centre of engineering, with firms including Park Royal Vehicles, GKN and Landis and Gyr.\n\nQueens Park Rangers F.C. played on two grounds in Park Royal. The first was the Horse Ring, later the site of the Guinness brewery, which had a capacity of 40,000. When the Royal Agricultural Society sold the grounds in 1907, QPR moved to the Park Royal Ground, south, an almost exact replica of Ayresome Park, with a capacity of 60,000. The club was forced to move out in February 1915 as the ground was taken over by the Army.\n\nOn 12 December 1908, the first ever rugby league test match between Great Britain and Australia took place at the Park Royal Ground in front of 2,000 fans. The match ended in a 22-all draw and was played as part of the first ever Kangaroo Tour.\n\nThe Guinness Sports Club hosted some of the field hockey events for the 1948 Summer Olympics.\n\nIt is public policy to maintain Park Royal as predominantly a business area. It is designated as an Opportunity Area, and in 2008 the Mayor of London's office published a draft Planning Framework which aspires to maintain, \"growing economic clusters of food/drink, transport/logistics and television/film.\" The framework does not preclude use of parts of the site for housing.\n\nIn summer 2011, the London Borough of Hammersmith and Fulham launched a Park Royal City plan for Old Oak Common, based around the immediate eastern border of North Acton, including light-rail lines to nearby areas.\n\nPark Royal is served by the A40 and A406 roads, and is situated close to a major interchange called the Hanger Lane gyratory.\n\nThere is a proposal to build a Barclays Cycle Superhighway CS10 from Hyde Park to Park Royal, which is under review by Transport for London.\n\nLondon Cycle Network routes 40, 42, 84 and 85 all serve Park Royal.\n\nStations in the area are:\n\nThree possible new transport services have been proposed for the area: the West London Orbital, Fastbus and the North and West London Light railway.\n\nIn 2004, the multinational Diageo company agreed to build extra Central line platforms at Park Royal tube station, as part of its First Central business park, built on the site of the (now demolished) Guinness brewery. As of the beginning of 2018, this had not yet happened.\n\n"}
{"id": "567489", "url": "https://en.wikipedia.org/wiki?curid=567489", "title": "Pliers", "text": "Pliers\n\nPliers are a hand tool used to hold objects firmly, possibly developed from tongs used to handle hot metal in Bronze Age Europe. They are also useful for bending and compressing a wide range of materials. Generally, pliers consist of a pair of metal first-class levers joined at a fulcrum positioned closer to one end of the levers, creating short \"jaws\" on one side of the fulcrum, and longer \"handles\" on the other side. This arrangement creates a mechanical advantage, allowing the force of the hand's grip to be amplified and focused on an object with precision. The jaws can also be used to manipulate objects too small or unwieldy to be manipulated with the fingers.\n\nPincers are a similar tool with a different type of head used for cutting and pulling, rather than squeezing. Tools designed for safely handling hot objects are usually called tongs. Special tools for making crimp connections in electrical and electronic applications are often called \"crimping pliers\"; each type of connection uses its own dedicated tool.\n\nThere are many kinds of pliers made for various general and specific purposes.\n\nAs pliers in the general sense are an ancient and simple invention, no single point in history, or inventor, can be credited. Early metal working processes from several millennia BCE would have required plier-like devices to handle hot materials in the process of smithing or casting. Development from wooden to bronze pliers would have probably happened sometime prior to 3000 BCE. Among the oldest illustrations of pliers are those showing the Greek god Hephaestus in his forge. The number of different designs of pliers grew with the invention of the different objects which they were used to handle: horseshoes, fasteners, wire, pipes, electrical, and electronic components.\n\nThe basic design of pliers has changed little since their origins, with the pair of \"handles\", the \"pivot\" (often formed by a rivet), and the \"head\" section with the gripping jaws or cutting edges forming the three elements.\n\nThe materials used to make pliers consist mainly of steel alloys with additives such as vanadium or chromium, to improve strength and prevent corrosion. The metal handles of pliers are often fitted with grips of other materials to ensure better handling; grips are usually insulated and additionally protect against electric shock. The jaws vary widely in size, from delicate needle-nose pliers to heavy jaws capable of exerting much pressure, and shape, from basic flat jaws to various specialized and often asymmetrical jaw configurations for specific manipulations. The surfaces are typically textured rather than smooth, to minimize slipping.\n\nA plier-like tool designed for cutting wires is often called diagonal pliers. Some pliers for electrical work are fitted with wire-cutter blades either built into the jaws or on the handles just below the pivot.\n\nWhere it is necessary to avoid scratching or damaging the workpiece, as for example in jewellery and musical instrument repair, pliers with a layer of softer material such as aluminium, brass, or plastic over the jaws are used.\n\nMuch research has been undertaken to improve the design of pliers, to make them easier to use in often difficult circumstances (such as restricted spaces). The handles can be bent, for example, so that the load applied by the hand is aligned with the arm, rather than at an angle, so reducing muscle fatigue. It is especially important for factory workers who use pliers continuously and prevents carpal tunnel syndrome.\n\n\n"}
{"id": "23747094", "url": "https://en.wikipedia.org/wiki?curid=23747094", "title": "Pride International", "text": "Pride International\n\nPride International, Inc. was an offshore oil drilling company headquartered in Houston, Texas, the United States. With over 7000 employees, Pride provided contract drilling and related services to oil and gas companies worldwide. It had positioned its fleet to operate offshore with more than 50 units in five continents. Its largest operations included those in Angola, Brazil, India, Mexico and Saudi Arabia. Pride spun off its mat jackups as a public company called Seahawk Drilling in August 2009, so the company's focus is primarily deep-water drilling along with some high-spec jackups.\n\nEffective from 31 May 2011, Pride International was acquired by Ensco plc.\n"}
{"id": "56525875", "url": "https://en.wikipedia.org/wiki?curid=56525875", "title": "Professor John Perkins' Review of Engineering Skills", "text": "Professor John Perkins' Review of Engineering Skills\n\nProfessor John Perkins' Review of Engineering Skills, also known as the Perkins Review, was a 2013 report commissioned by the Department for Business, Innovation and Skills (BIS) on engineering training and the skills shortage in the United Kingdom. Principally authored by the Chief Scientific Adviser to the BIS (Professor John Perkins), it made key recommendations for improving the training of British engineers and encouraging more entrants into the profession. Key aspects it highlighted included the gender gap, with ten times more men employed in the profession than women, and the current reliance on foreign engineers.\n\nThe report was commissioned by the Department for Business, Innovation and Skills (BIS) under the Cameron–Clegg coalition government and took two years to prepare. The principal author of the report was Professor John Perkins, the chief scientific adviser to BIS, and it was published in November 2013. Perkins' contract expired the next year and he left the BIS. A 1980 paper, the Finniston Report made a similar review of the state of the engineering profession in the United Kingdom.\n\nPerkins stated that an engineering skills shortage was hampering the country's recovery from the Great Recession. There was a \"substantial demand for engineers\" and an undersupply which meant that 73% of manufacturing companies had reported a difficulty in filling engineering roles since 2010. More than half of the occupations listed in the British government's tier 2 shortage occupations list are in engineering with a further 20% for allied scientific or technical roles.\n\nThe report showed that there was a failure to attract girls into the profession. It stated that only 35% of 11–14 year-old girls would consider a career in engineering and only 24% of their parents would consider it a suitable career for their daughters. This fed through into the older age groups – at further education level only around 15% of applicants for undergraduate engineering courses are women and only one in ten of British engineering professionals are female, the lowest proportion in any country of the European Union. Perkins stated that there was a lack of female role models from within the profession. In press interviews accompanying the release of the report business secretary Vince Cable stated that \"half of all state schools don't have a single girl doing physics\".\n\nPerkins showed that the profession was relying on immigrants to make up the skills deficit. The report stated that in some sectors such as oil and gas or aerospace immigrants accounted for 20% of professional engineering roles and that 32% of students studying engineering and technology in the UK were from overseas.\n\nThe Perkins report made 22 key recommendations for the government to address the skills shortage. This included working to promote the industry to girls, increasing the uptake of A-level physics, recruiting more physics teachers and introducing new vocational qualifications for 16-19 year olds. He also urged the professional engineering institutions to work to promote the sector to young people.\n\nUpon his retirement Perkins expressed confidence that the government had implemented measures to address the skills shortage. This included providing additional university funding for STEM courses, to fund engineering research and to construct teaching facilities. He also highlighted work done by practising engineers in schools and colleges to promote the subject. As part of the response to the Perkins Review business secretary Vince Cable announced £49 million of funding for improvements to engineering education. This included funding for the new Manufacturing Technology Centre in Coventry, schemes to encourage children to consider engineering as a career and for initiatives to encourage former engineers to return to the industry. The funding was monitored as part of the government's Employer Ownership Fund.\n\nA further £2.8 million of funding, as part of the Improving Engineering Careers scheme, was announced in March 2015 to help six companies implement the objectives of the Perkins Review. The companies, which included the Nissan plant in Sunderland, would match the government funding and implement schemes to train more British engineers and offer more job positions. The government will introduce the first T Levels, a new technical qualification for 17-18 year olds from 2020.\n\nThe review was welcomed by many of the engineering institutions including the Institution of Engineering and Technology, the Institution of Mechanical Engineers and the Nuclear Institute – many of whom highlighted their existing schemes to encourage women and young people into the industry. One key outcome from the report was support for the Tomorrow's Engineers programme, a national initiative to give every 11- to 14-year-old hand-on experience with a local engineering firm. A year on from the report the programme had reached 50,000 school pupils in more than 1,200 schools. Girls who participated in the programme were 50% more likely to see engineering as an attractive career choice.\n\nShortly after its publication the report was debated by the British House of Commons in a Westminster Hall debate on 10 December 2013. Conservative MP Peter Luff advocated targeting campaigns at age groups even younger than the 11-year-olds proposed in Perkins' report, citing research from the National Foundation for Educational Research that intervention at primary school age was most effective – an opinion echoed by Meg Munn. Andrew Miller advocated a more joined up system of apprenticeships as a means of meeting the Perkins objectives. David Mowat called for greater visibility of engineers in the media and noted that, unlike in Britain, in Europe engineers were held in higher regard – on a par with doctors. He also noted that salaries were an issue with many engineering graduates entering other high-paid professions such as accountancy instead.\n\nPerkins carried out his own review on actions taken in the year following the publication of the report. He noted the improvement in the standing of the profession brought about by the government funding of the Tomorrow's Engineers programme and the successful introduction of a \"Tomorrow's Engineers Week\". He also welcomed the actions taken by 200 engineering companies to open up new entry-level engineering positions and to implement their own schemes to attract young people and women into the profession. There was also an improvement recognised in the education sector with steps taken to fund scholarships to attract high-quality STEM candidates into the teaching profession but noted that there had been no progress in improving the uptake of A-level physics amongst female students. At further education level it was noted that applications for engineering courses had increased by 6.1% over the previous year and recognised an increase of £385 million in government funding of science and engineering courses.\n"}
{"id": "47857900", "url": "https://en.wikipedia.org/wiki?curid=47857900", "title": "Route capacity", "text": "Route capacity\n\nRoute capacity is the maximum number of vehicles, people, or amount of freight than can travel a given route in a given amount of time, usually an hour. It may be limited by the worst bottleneck in the system, such as a stretch of road with fewer lanes. Air traffic route capacity is affected by weather. For a metro system, route capacity is generally the capacity of each vehicle, times the number of vehicles per train, times the number of trains per hour (tph). In this way, route capacity is highly dependent on headway. Beyond this mathematical theory, capacity may be influenced by other factors such as slow zones, single-tracked areas, and infrastructure limitations, e.g. to useful train lengths.\n\nAny assessment of the effectiveness of a transport network includes a calculation of what capacity is used, how it is used, and whether it is used effectively. For instance, overloaded routes may need to be upgraded, or capacity provided by other routes. Unused capacity can represent an opportunity to move more people or goods: as the capacity exists no additional investment is needed. Many transport networks have unused capacity.\n\nExternal factors affect route capacity in different ways. Severely overcrowded highways will reduce the capacity of bus services. Severe snowfalls will reduce the capacity of highways and freeways, and high winds will make landing and departing airports difficult. In many cases route capacity will vary day to day depending on external factors. Rail systems are more rarely affected by external factors.\n\nRoutes can become congested where only a fraction of routes can accept certain traffic types. For example, a road may have a low bridge that restricts the height of any trucks (lorries), or a rail line may be unable to accept wagons loaded beyond a certain axle load. This will result in any route that can accept a wider range of vehicles being congested, and other more restrictive routes be underutilised. Rail traffic between the US and Mexico is limited by the types of vehicles, especially grain wagons, and as 2009 the only routes that could accept newer rail wagons passed through Texas.\n\nBottlenecks play a large role in determining route capacity. Along any route the capacity is limited to the point with the lowest capacity, and long routes may have their capacity compromised by one bottleneck. Where more vehicles enter a route than a single bottleneck can accept, then the route will be free of congestion at all points except at the bottleneck. For this reason bottlenecks are often the focus of transport improvement projects.\n\nRoute capacity is often calculated and applied in the management and design of rail systems. For railways with very high passenger loads, the maximum possible route capacity is an important factor. A common unit for route capacity is people per hour (pph), which can for metro style systems can be as high as 80,000. Route capacity can also be expressed as number of vehicles per hour, such as 20 trains per hour (tph). Route capacities in rail lines with two tracks are almost always the same in either direction.\n\nThe maximum speed or average speed of rail traffic will have no impact on the route capacity where all train services are of the same type, and the stopping patterns are the same. Whilst slower trains will mean passengers take longer to reach their destination, the number of trains moving past a specific point will remain the same. Route capacity at a particular period of time can be observed by an observer standing on a station platform. A slower rail system will require more rolling stock to maintain a high throughput of trains. The speed of traffic will affect the required headway between trains (it is not simply proportional to the speed) and will thus affect the route capacity.\n\nIn calculating route capacity it is important to consider practical considerations. Many railways will wish to operate at the maximum capacity for hours on any given day, and the theoretical capacity is not sustainable for more than a few trains. A reduced level of capacity, which can be maintained for hours, is often calculated. A railway that operates at close to the level of theoretical capacity for extended periods will have lower punctuality (fewer trains arriving when timetabled).\n\nRoute capacity depends on the number of passengers using a system, if only because this will affect the length of station stops. Much of the route capacity in an existing rail system will be used for existing timetabled rail movements. This is described as used capacity. What capacity remains to be allocated to additional trains is called available capacity.\n\nIncreasing route capacity for a rail system requires substantial investment in infrastructure. Increasing route capacity for a railway from, for example, 12 trains per hour, to 20 per hour, can be a very substantial project requiring substantial budgets.\n\nRail capacity is often less affected by the weather than route capacity for aircraft. However it can be affected by e.g. snow blocking the line, or by buckled rails at high temperatures.\n\nThe are two main methods of calculating route capacity; using the method outlined in UIC 406, and by using headways. The International Union of Railways produces documents on a variety of rail related topics, and published a leaflet on rail capacity. This leaflet provides a method of calculating route capacity based on the creation of paths through a rail route. The number of paths for a \"standard\" train is created, and then the train paths added. The total number of trains that can potentially enter the route, and leave it, as well as the actual number, can then be determined.\n\nThe classic formula for the calculation of a route capacity from a headway is:\n\nFor example, a headway of 4 minutes translates into a route capacity of 15 trains per hour.\n\nRoute capacity is maximised for any rail system when all the rail traffic is the same type. Mixing different types of trains, or even different stopping patterns, will result in a substantial reduction of capacity. Where different types of trains are mixed together this is sometimes called heterogeneity. In this context different types of trains means those that are slower than other trains, for example, freight and passenger trains. Freight trains often accelerate and brake more slowly than passenger, and have lower top speeds. Also passenger trains that have different stopping patterns, such as a local all stops service, when mixed with a limited or express service, will result in a reduction of route capacity. Route capacity is not lost where all the trains on one route stop at all stations, but only where trains with different stopping patterns are mixed together.\n\nRail systems vary greatly in performance and route capacity, with metro systems having the highest capacity. Tram and light rail systems have in theory very high route capacities, but in practice route capacities of 12 trains per hour is a practical upper limit. For High Speed Rail a route capacity of up to 18 trains per hour may be possible. The Punggol metro line in Singapore uses a moving block system to achieve a headway of 90 seconds, so the route capacity is 40 trains per hour. Route capacity for a commuter rail system is typically around 12 to 16 trains per hour, which is lower than a metro, as the trains are longer, and the traffic is often mixed with other rail services such as freight and intercity trains. By contrast the Alameda Freight Corridor in Los Angeles has a route capacity of 150 freight trains per day, which is high in comparison to other rail freight systems, but low compared to metros.\n\nThe route capacity of freight rail systems is often limited by the terminal to which the freight is heading. Large terminals will be able to accept more freight trains, but a route capacity of 15 freight trains per hour would be very unusual.\n\nStations in a railway system, and where train are required to stop to pick up or drop off passengers, serves to reduce the route capacity. This is particularly the case where trains of different stopping patterns are moving one after another through a rail system. Dwell time, known as layover in the US, is the time taken from the opening of train doors at a station, to their closing again. Dwell times strongly influence route capacity in a rail system.\n\nMany rail systems use a fixed block system for signalling. Moving block represents a new type of signalling that allows the reduction of headways, and an improvement of route capacity. Moving block is a signalling principle that exists within a signalling system called automatic train protection. Many technical problems exist with the construction of any rail line that supports moving block, as this type of signalling system requires constant communication between signalling systems and trains, which is often achieved with a train radio system (but can be achieved other ways). Another problem is the signalling system needs to know the length of any train at all times, and so an engineering system is needed on all trains that can detect all carriages and wagons within the train.\n\n\n"}
{"id": "56887061", "url": "https://en.wikipedia.org/wiki?curid=56887061", "title": "SAE J306", "text": "SAE J306\n\nSAE J306 is a standard that defines the viscometric properties of automotive gear oils, maintained by SAE International. Key parameters for this standard are the kinematic viscosity of the gear oil, the maximum temperature at which the oil has a viscosity of 150,000 cP, and a measure of its shear stability through the KRL test.\n"}
{"id": "904426", "url": "https://en.wikipedia.org/wiki?curid=904426", "title": "Samuel T. Cohen", "text": "Samuel T. Cohen\n\nSamuel Theodore Cohen (January 25, 1921 – November 28, 2010) was an American physicist who is generally credited as the father of the neutron bomb.\n\nCohen's parents were Austrian Jews who emigrated from London, England. He was born on January 25, 1921, in Brooklyn and raised in New York City. He studied mathematics and physics at University of California, Los Angeles before joining the United States Army after the Japanese attack on Pearl Harbor. In 1944 he worked on the Manhattan Project in the efficiency group at Los Alamos and calculated how neutrons behaved in Fat Man, the atomic bomb that was later detonated over Nagasaki, Japan. After the war he studied for his Ph.D. at Berkeley before dropping out to join the RAND Corporation. At RAND Corporation in 1950, his work on the intensity of fallout radiation first became public when his calculations were included as a special appendix in Samuel Glasstone's book \"The Effects of Atomic Weapons\". Cohen was personally responsible for recruiting the famous strategist Herman Kahn into the RAND Corporation.\nDuring the Vietnam War, Cohen argued that using small neutron bombs would end the war quickly and save many American lives, but politicians were not amenable to his ideas and other scientists ignored the neutron bomb in reviewing the role of nuclear weapons. He was a member of the \"Los Alamos Tactical Nuclear Weapons Panel\" in the early 1970s. President Carter delayed development of the neutron bomb in 1978, but during Ronald Reagan's presidency, Cohen claims to have convinced Reagan to make 700 neutron bombs, 350 shells to go into the 8 inch (200-millimeter) howitzer and 350 W70 Mod. 3 warheads for the Lance missile.\n\nIn 1956, President Dwight D. Eisenhower announced the testing of a 95% \"clean\" (2-stage) fusion weapon, later identified to have been the 11 July \"Navajo\" test at Bikini Atoll during \"Operation Redwing\". This weapon had a yield of 4.5 megatons. Previous \"dirty\" weapons had fission proportions of 50–77%, due to the use of uranium-238 as a \"pusher\" around the lithium deuteride (secondary) stage. This is deliberate; the fusion reactions give off large quantities of 14.1 M neutrons, which have more energy than then 1.1 MeV \"fission threshold\" for U238. This means the neutrons, which would otherwise escape, create fission reactions in the tamper, increasing the overall yield of the weapon essentially \"for free\".\n\nThe 1956 \"clean\" tests used a lead pusher, while in 1958 a tungsten carbide pusher was employed. Hans A. Bethe supported clean nuclear weapons in 1958 as Chairman of a Presidential science advisory group on nuclear testing:\n... certain hard targets require ground bursts, such as airfield runways if it is desired to make a crater, railroad yards if severe destruction of tracks is to be accomplished ... The use of clean weapons in strategic situations may be indicated in order to protect the local population.– Dr. Hans Bethe, Working Group Chairman, 27 March 1958 \"Top Secret — Restricted Data\" Report to the NSC Ad Hoc Working Group on the Technical Feasibility of a Cessation of Nuclear Testing, p 9.\n\nIn consequence of Bethe's recommendations, on 12 July 1958, the \"Hardtack-Poplar\" shot of the Mk-41C warhead was carried out on a barge in the lagoon yielded 9.3 megatons, of which only 4.8% was fission, and thus 95.2% \"clean\".\n\nIn 1958, Cohen investigated a low-yield \"clean\" nuclear weapon and discovered that the \"clean\" bomb case thickness scales as the cube-root of yield. So a larger percentage of neutrons escapes from a small detonation, due to the thinner case required to reflect back X-rays during the secondary stage (fusion) ignition. For example, a 1-kiloton bomb only needs a case one-tenth the thickness of that required for 1-megaton.\n\nSo, although most neutrons are absorbed by the casing in a 1-megaton bomb, in a 1-kiloton bomb they would mostly escape. A neutron bomb is only feasible if the yield is sufficiently high that efficient fusion stage ignition is possible, and if the yield is low enough that the case thickness will not absorb too many neutrons. This means that neutron bombs have a yield range of 1–10 kilotons, with fission proportion varying from 50% at 1-kiloton to 25% at 10-kilotons (all of which comes from the primary stage). The neutron output per kiloton is then 10–15 times greater than for a pure fission implosion weapon or for a strategic warhead like a W87 or W88.\n\nCohen's neutron bomb is not mentioned in the unclassified manual by Glasstone and Dolan, \"The Effects of Nuclear Weapons\" 1957–1977, but is included as an \"enhanced neutron weapon\" in chapter 5 of the declassified (formerly secret) manual edited by Philip J. Dolan, \"Capabilities of Nuclear Weapons\", U.S. Department of Defense, effects manual DNA-EM-1, updated 1981 (U.S. Freedom of Information Act).\n\nUnder most atmospheric conditions no fallout effects would occur from the use of a neutron bomb, according to that manual, as the combination of 500-meter burst altitude and low yield prevents fallout in addition to significant thermal and blast effects. The reduction in damage outside the target area is a major advantage of such a weapon to deter massed tank invasions. An aggressor would thus be forced to disperse tanks, which would make them easier to destroy by simple hand-held anti-tank missile launchers.\n\nCohen's backing of investigations into these controversial ideas won him some media attention after many years of being ignored. In 1992 he was featured in the award-winning BBC TV series \"Pandora's Box\", episode \"To the Brink of Eternity\", discussing his battles with officialdom and colleagues at the RAND Corporation. Cohen controversially argued: \"When we started this systems analysis business, we stepped through the looking glass where people did the weirdest things and (used) the most perverse kind of logic imaginable and yet claimed to have the most precise understanding of everything.\"\n\nCohen reportedly worked in France on low-yield, highly discriminate tactical nuclear weapons in 1979–80. He claimed that he was awarded a medal by Pope John Paul II in 1979 for his bid to reform modern warfare. Author Charles Platt reported in a 2005 profile of Sam Cohen that \"... he showed me the Medal of Peace that he had received from the Pope in 1979.\"\n\nAt the time, Warsaw Pact forces had a massive tank superiority in Europe (though NATO maintained an overall strategic superiority); the \"Christian Science Monitor\" reported in 1981 that there were \"19,500 tanks in the Soviet-controlled forces of the Warsaw Pact aimed at Western Europe. Of these, 12,500 are Soviet tanks in Soviet units. NATO has 7,000 tanks on its side facing the 19,500.\" A deterrent which was designed to minimise civilian casualties was a step away from the risk of indiscriminate warfare. The neutron bomb's killing by neutron radiation is different from the fallout of a normal high yield thermonuclear weapon because it can be controlled more precisely, restricted to military targets and kept away from civilians.\n\nThe speed of modern warfare meant that the civilian population would be unlikely to be able to withdraw from combat zones and would suffer a large number of deaths in a nuclear war where the blast yields and fallout were significant. Because neutron bombs do not produce the indiscriminate blast (only 40 kilopascals at ground zero from a 1 kt blast yield detonation at 500 m altitude, and only 7 kPa at 2 km distance), heat, and fallout damage of other nuclear weapons, they were more credible as a deterrent to Soviet tanks. However, many people believed that the very deployment of the neutron bomb threatened an escalation to full-scale nuclear retaliation, thus canceling out the supposed benefits. Advances in precision anti-tank weapons ultimately made the neutron bomb redundant tactically in its original objective. The debate over \"clean\" low yield nuclear weapons continues with earth penetrator technology (\"nuclear bunker busters\").\n\nMore recently, Cohen was the main proponent of what most consider to be a mythical substance, red mercury. If the \"conventional story\" is to be believed, red mercury was a disinformation campaign led by US government agencies in order to lure potential terrorists into being captured. The story that was released was that red mercury was developed by the Soviet Union as a \"shortcut\" to a fusion bomb, and that with the fall of the Soviet Union it was being offered on the market by the Soviet mafia. When prospective buyers showed up to take delivery of the material, they were arrested.\n\nDuring the height of the story, in the 1990s, Cohen became a proponent of red mercury, claiming not only that it existed, but going further to claim that it was a powerful ballotechnic material that directly compressed the fusion fuel without the need for a fission primary. Bombs using red mercury had no real critical mass and could be developed at any size. He further claimed that the Soviets had produced a number of \"micro-nukes\" based on red mercury, which are described as being about as large as a baseball and weighing 10 pounds. According to Cohen, their existence meant that any effort to control nuclear proliferation based on fissile material was thus hopeless. A reiteration of the claim can be seen in \"The Nuclear Threat That Doesn't Exist – or Does It?\", by Cohen and Joe Douglass in an 11 March 2003 guest editorial in \"Financial Sense Online\".\n\nIn a column for WorldNetDaily, Cohen claimed that 100 of these mini-nukes were in the hands of terrorists, and later that Saddam Hussein had taken delivery of about fifty of these devices, which he supposedly planned on using against the US forces as they approached Baghdad.\n\nCohen spoke at an April 2000 fundraiser in La Canada, California, for then-Reform Party presidential candidate Patrick Buchanan. Irv Rubin was prominently present at this event, with his organization, the Jewish Defense League (JDL), and with members of the Libertarian Party, to protest. The JDL posted Cohen's home phone number and address on its website, urging its members to contact him, to persuade him to stop supporting Buchanan.\n\nIn her address to the 2000 Reform Party National Convention, Buchanan's running mate, Ezola Foster, cited Cohen's endorsement of Buchanan to refute the claim that the candidate was anti-Semitic.\n\nAs part of a self-described unusual friendship, Cohen wrote the afterword to Dr. William P. Grady's 2005 bestseller titled \"How Satan Turned America Against God\". Cohen explained that although he was an unbelieving Jew, and thus could not relate to the spiritual content of the book, he concurred with Grady's grasp of America's disastrous foreign policy.\n\nHe died on November 28, 2010 in Brentwood, Los Angeles, from complications of his stomach cancer.\n\nOn the DVD of film \"Repo Man\" (which contains a fictional character loosely based on Cohen and the neutron bomb as a plot device), Cohen is interviewed in the commentary on the deleted scenes. During the interview, Cohen asserts that the neutron bomb conforms to just war theories.\n\n"}
{"id": "43364546", "url": "https://en.wikipedia.org/wiki?curid=43364546", "title": "Satellite delay", "text": "Satellite delay\n\nSatellite delay is the noticeable latency which occurs due to the speed of light, when sending data to and from satellites, especially the much further out geosynchronous satellites. Bouncing a signal off one geosynchronous satellite takes about a quarter of a second, which is enough to be noticeable, but relaying data between 2 or 3 such satellites increases the delay further.\n\n"}
{"id": "1640978", "url": "https://en.wikipedia.org/wiki?curid=1640978", "title": "Science and invention in Birmingham", "text": "Science and invention in Birmingham\n\nBirmingham is one of England's principal industrial centres and has a history of industrial and scientific innovation. It was once known as 'city of a thousand trades' and in 1791, Arthur Young (the writer and commentator on British economic life) described Birmingham as \"the first manufacturing town in the world\". Right up until the mid-19th century Birmingham was regarded as the prime industrial urban town in Britain and perhaps the world, the town's rivals were more specific in their trade bases. Mills and foundries across the world were helped along by the advances in steam power and engineering that were taking place in the city. The town offered a vast array of industries and was the world's leading manufacturer of metal ware, although this was by no means the only trade flourishing in the town.\n\nBy the year 2000, of the 4,000 inventions copyrighted in the UK, 2,800 came from within a 35-mile radius of Birmingham. Peter Colegate of the Patent Office stated that \"Every year, Birmingham amazes us by coming up with thousands of inventions. It is impossible to explain but people in the area seem to have a remarkable ability to come up with, and have the dedication to produce, ideas.\"\n\nWhile the time line of industry and innovation listed below is extensive, it is by no means a comprehensive list of Birmingham's industrial and scientific achievements, more a guide to highlight the great diversity in the city's industrial might, which can still be seen today.\n\nBirmingham's reputation for trade and innovation really begins to take off in the 12th century with the expansion of a market held there by the De Birmingham family. Around this time the Birmingham Bull Ring begins to take shape, and with the town's markets there arises a necessity to produce items good enough to be sold elsewhere.\n\nMedieval crafts in the town include textiles, leather working and iron working, with archaeological evidence also suggesting the presence of pottery, tile manufacture and probably the working of bone and horn. The following period sees the new town expand rapidly in highly favourable economic circumstances and there is archaeological evidence of small-scale industries taking place such as kilns producing the distinctive local Deritend ware pottery.\n\nThe following decades, Birmingham becomes very productive in several trades metal working, including making small, high value items, possibly jewellery or metal ornaments, for Master of the Knights Templar. They are sufficiently well known to be referred to without explanation as far away as London.\n\nBirmingham's first notable literary figure is John Rogers, the compiler and editor of the 1537 \"Matthew Bible\", parts of which he also translates. This is the first complete authorised version of the Bible to be printed in the English language and the most influential of the early English printed Bibles, providing the basis for the later \"Great Bible\" and the \"Authorized King James Version\". Rogers' 1548 translation of Philip Melanchthon's \"Weighing of the Interim\", possibly translated in Deritend, is the first book by a Birmingham man known to have been printed in England.\n\nBy the early 16th century Birmingham has already evolved into a well established arms manufacturing town, in 1538 churchman John Leialand passes through the Midlands and writes:\n\n\"I came through a praty street or ever I entered Bermingham. This street, as I remember, is called Dirty (Deritend). In it dwells smiths and cutlers and there is a brooke that divides this street from Bermingham ... There be many smiths in the towne, that use to make knives and all manner of cutting tools, and many lorimers that make bittes, and a great many naylours, so that a great part of the towne is maintained by smiths, who have their iron and sea-coal out of Staffordshire.\"\"\n\nBirmingham loses its Lord of the Manor in the 16th century, and the district as a whole remains an area of weak lordship throughout the following centuries. With local government remaining essentially manorial, the townspeoples' resulting high degree of economic and social freedom is to be a highly significant factor in Birmingham's subsequent development.\nIn 1642 the early Birmingham mathematician and astronomer Nathaniel Nye publishes \"A New Almanacke and Prognostication calculated exactly for the faire and populous Towne of Birmicham in Warwickshire, where the Pole is elevated above the Horizon 52 degrees and 38 minutes, and may serve for any part of this Kingdome\".\n\nBirmingham's principal tradesmen during the English Civil War were the smiths, who were called upon to manufacture over 15,000 sword blades, these are supplied to Parliamentarian forces only. One of the town's leading minds, 'Nathaniel Nye' is recorded as testing a Birmingham cannon in 1643. Nye also experimented with a saker in Deritend in 1645. From 1645 he became the master gunner to the Parliamentarian garrison at Evesham and in 1646 he successfully directs the artillery at the Siege of Worcester, detailing his experiences and in his 1647 book \"The Art of Gunnery\", believing that war is as much a science as an art.\nThe earliest known clock makers in the town arrived from London in 1667. Between 1770 and 1870 there are over 700 clock and watch makers in the town.\n\nIn 1689 Sir Richard Newdigate, one of the new, local Newdigate baronets, approaches manufacturers in the town with the notion of supplying the British Government with small arms. It is stressed that they would need to be of high enough calibre to equal the small arms that were being imported from abroad. After a successful trial order in 1692, the Government places its first contract. On 5 January 1693, the \"Officers of Ordnance\" chooses five local firearms manufacturers to initially produce 200 \"snaphance musquets\" per month over the period of one year, paying 17 shillings per musket, plus 3 shillings per hundredweight for delivery to London.\n\n1722: Richard Baddeley, ironmonger, patents a method for \"casting wheel streaks and box irons\".\n\n1727: Birmingham is becoming a hot-bed of creative activity and local businessman and bookseller Thomas Warren opens a bookshop in the Birmingham's High Street. Warren is an influential figure in Birmingham at this time.\n\n1732: The \"Birmingham Journal\" is founded and published from Thomas Warren's book store. This is possibly Birmingham's first weekly newspaper; one of its contributors is the very notable Samuel Johnson of nearby Lichfield.\n\n1733: Thomas Warren edits and publishes Samuel Johnson's first original writing—a translation of Jerónimo Lobo's Voyage to Abyssinia. Johnson works for the Journal while he lodges with Warren. Johnson later moves on to greater things and James Boswell writes of Johnson's life: \"After nine years of work, Johnson's \"A Dictionary of the English Language\" was published in 1755; it had a far-reaching effect on Modern English and has been described as \"one of the greatest single achievements of scholarship\". The dictionary brings Johnson popularity and success. Until the completion of the \"Oxford English Dictionary\" 150 years later, Johnson's dictionary is among the most influential dictionaries in the history of the English language.\n1738: Lewis Paul and John Wyatt, of Birmingham, patent the roller spinning machine and the flyer-and-bobbin system, for drawing cotton to a more even thickness, using two sets of rollers that travel at different speeds. This principle later becomes the basis of Richard Arkwright's water frame.\n\n1741: John Wyatt, mechanic and inventor, designs and constructs a cart-weighing machine, later referred to as a compound lever weighing machine; the design works by way of levers that hold in place a platform, no matter where the weight is placed the load is transferred to a central lever. Weights attached to that lever then help in obtaining a reading of accurate weight. The simplicity, efficiency and accuracy of the weighing machine prove extremely popular across England, subsequently weighing errors are reduced to approximately one pound per ton, this remains a high standard of measurement into the mid-19th century.\n\n1741: The Upper Priory Cotton Mill opens as the world's first mechanised cotton-spinning factory. It is financed by local businessman Thomas Warren, and opened by John Wyatt and Lewis Paul.\n\n1742: John Baskerville takes out a patent for making metal mouldings, rolling, grinding and japanning metal plates by use of weights, rollers and pickling, which Baskerville uses over the more traditional method of employing screws. This is the first patent for making metal mouldings by passing them through rolls of a certain profile.\n1743: A factory opens in Northampton, fifty spindles turned on five of Paul and Wyatt's machines proving more successful than their first mill. This operates until 1764.\n\n1746: The Colmore family release land on what is later to be known as the Jewellery Quarter to help satisfy the demands of an increasing population.\n\n1746: A sulphuric acid factory is set up at Steelhouse Lane to use the lead chamber process invented by its co-founder John Roebuck. Roebuck and local businessman Samuel Garbett later relocate to Prestonpans in Scotland, taking with them several skilled men from the Birmingham factory. It is here in 1762 where Roebuck takes out a patent for making malleable iron.\n\n1748: Lewis Paul invents the hand driven carding machine. A coat of wire slips are placed around a card, which is then wrapped around a cylinder. Lewis's invention is later developed and improved by Richard Arkwright and Samuel Crompton, although this comes about under great suspicion after a fire at Daniel Bourn's factory in Leominster that specifically uses Paul and Wyatt's spindles. Bourn produces a similar patent in the same year.\n\n1757: Rev John Dyer of Northampton recognises the importance of the Paul and Wyatt cotton spinning machine in poem:\n\n1757: Baskerville serif typeface is designed by John Baskerville (1706–1775) in Birmingham, England. Baskerville is classified as a transitional typeface, positioned between the old style typefaces of William Caslon, and the modern styles of Giambattista Bodoni and Firmin Didot.\n\n1758: Paul and Wyatt improve their Roller Spinning machine and take out a second patent. Richard Arkwright later uses this as the model for his water frame.\n\n1758: Benjamin Franklin first travels to Birmingham \"to improve and increase Acquaintance among Persons of Influence\", and later returns in 1760 to conduct experiments with Boulton on electricity and sound. Franklin remains a common link among many of the early Lunar Society members.\n\n1759: A patent is granted to Thomas Blockley (locksmith), for rolling iron into different forms and making (metal) wheel tyres.\n\n1762: Matthew Boulton opens the Soho Foundry engineering works, Handsworth; his partnership with Scottish engineer James Watt makes the steam engine into the power plant for the Industrial Revolution. The term \"horsepower\" is coined by Watt.\n1765: The Lunar Society begins life as a dinner club and informal learned society of prominent figures in the Midlands Enlightenment, including industrialists, natural philosophers and intellectuals, who meet regularly until 1813 in Birmingham. A paper read at the Science Museum in London in 1963 claims that \"of all the provincial philosophical societies it was the most important, perhaps because it was not merely provincial. All the world came to Soho to meet Boulton, Watt or Small, who were acquainted with the leading men of Science throughout Europe and America.\" The Midlands Enlightenment dominates the\nexperience of the Enlightenment within England and its leading thinkers have international influence. In particular, it forms a pivotal link between the earlier Scientific Revolution and the later Industrial Revolution, facilitating the exchange of ideas between experimental science, polite culture and practical technology that enables the technological preconditions for rapid economic growth to be attained.\n1767: A number of prominent Birmingham businessmen, including Matthew Boulton and others from the Lunar Society, hold a public meeting in the White Swan, High Street, to consider the possibility of building a canal from Birmingham to the Staffordshire and Worcestershire Canal near Wolverhampton, taking in the coalfields of the Black Country. They commission the canal engineer James Brindley to propose a route. Brindley comes back with a largely level route via Smethwick, Oldbury, Tipton, Bilston and Wolverhampton to Aldersley. This kick-starts what is to become the Birmingham Canal Navigations.\n\n1770: James Watt applies the first screw propeller to an early steam engine at his Birmingham works, thus beginning the use of a hydrodynamic screw for propulsion.\n\n1775: Ketley's Building Society is founded and becomes the world's first building society. Midland Bank (now owned by HSBC) and Lloyds Bank are also founded in Birmingham.\n\n1777: Boulton and Watt build 'Old Bess', as described by the London science museums 'an engine that stands at a crossroads in history'.\n\n1779: James Keir takes out a patent for a compound metal that is capable of being forged when hot or cold more fit for the making of bolts, nails, and sheathing for ships prior to anything before. This metal uses the same compounds and similar quantities of metals as the patent of Muntz metal, which appears at the same time.\n1779: Matthew Wasbrough designs and builds the Pickard Engine (first crank engine) for James Pickard of Snow Hill, this is defined as 'the first atmospheric engine in the world to directly achieve rotary motion by the use of a crank and flywheel.'\n\n1779: James Watt patents a copying press or 'letter copying machine' to deal with the mass of paper work at his business; he also invents an ink to work with it. This is the first widely used copy machine for offices and is a commercial success, being used for over a century. This letter copying press is considered to be the original photocopier.\n1781: James Watt markets his rotary-motion steam engine. The earlier steam engine's vertical movement was ideal for operating water pumps but the new engine can be adapted to drive all sorts of machinery. Richard Arkwright pioneers its use in his cotton mills and within 15 years there are 500+ Boulton & Watt steam engines in British factories and mines. Boulton also arranges, in 1775, an Act of Parliament extending the term of Watt's 1769 patent to 1799.\n\n1784: James Watt refers to a two-speed transmission in patent No. 1432, which relates to steam carriages: The concept of changing speed (or a variable velocity) in gearing, which could arguably be the seed of thought for all subsequent gearing systems.\n\n\"Motion [from a steam engine] is communicated to the axle-tree of one or more wheels of the carriage by means of the \"circulating rotative to machinery\" formerly patented by the inventor. Two or more loose wheels of different diameters are placed to be locked on the axle and impart extra power for bad roads or steep ascents.\"\n\n1785: William Withering publishes \"An Account of the Foxglove and some of its Medical Uses\", pioneering its use as a cardiac drug, Digitalis.\n\n1785: James Watt and William Murdoch invent the oscillating cylinder and double action engine. Around this time James Watt creates a governor and throttle valve for automatically regulating the supply of steam to an engine although no patents for this are taken out by Watt.\n1788: Boulton and Watt build the rotative steam engine also known as a piston engine, an improved steam engine whose smooth reciprocating action enable it to drive a variety of rotary machinery.\n\n1790: W. Richardson publishes \"The Chemical Principles of the Metallic Arts: designed chiefly for the use of Manufacturers\", which is used to help with diseases associated with the metal working industry.\n1794: Ralph Heaton patents a steam powered machine for mass-producing button shanks. This is one of the earliest forms of mechanical mass production and steam powered machine tool operation.\n\nAround this time William Futrell (a well known Birmingham pugilist) becomes publisher of possibly the first British boxing paper.\n\n1797: Matthew Boulton erects at Soho a complete coining plant with which he strikes coins for the Sierra Leone and East India companies and for Russia, and produces a new copper coinage for Britain. Also in 1797, he takes out a British patent in connection with raising water on the principle of the hydraulic ram although one of a similar nature appears in France at around the same time.\n\n1799: The first bellcrank engine is patented by William Murdoch while working for Boulton and Watt. It is the first compact, self-contained engine.\n\nAmong the products Matthew Boulton seeks to make in his new facility are sterling silver plate for those able to afford it, and Sheffield plate, silver-plated copper, for those less well off. Boulton and his father make small silver items throughout the 18th century, and there is no record of large items in either silver or Sheffield plate being made in Birmingham before Boulton does so. To make items such as candlesticks more cheaply than the London competition, the firm makes many items out of thin, die-stamped sections, which are shaped and joined together.\n\nOne impediment to Boulton's work is the lack of an assay office in Birmingham. The silver toys long made by the family firm are generally too light to require assaying, but silver plate has to be sent over 70 miles (110 km) to the nearest assay office, at Chester, to be assayed and hallmarked, with the attendant risks of damage and loss. Alternatively they can be sent to London, but this exposes them to the risk of being copied by competitors.\n\nBoulton writes in 1771, \"I am very desirous of becoming a great silversmith, yet I am determined not to take up that branch in the large way I intended, unless powers can be obtained to have a marking hall [assay office] at Birmingham.\"\n\nBoulton petitions Parliament for the establishment of an assay office in Birmingham. Though the petition is bitterly opposed by London goldsmiths, he is successful in getting Parliament to pass an act establishing assay offices in Birmingham and Sheffield, whose silversmiths face similar difficulties in transporting their wares. The act is passed in March 1773, to grant Birmingham and Sheffield the right to assay silver.\n\n1773: The Birmingham Assay Office opens on 31 August and the town becomes a leading manufacturer of all types of silver ware spanning three centuries. The Assay office can still be visited today by appointment and is situated near to the city's well renowned Jewellery Quarter.\n\n1793: \"A gentleman of the name of Hand\" in Birmingham obtains a patent for preparing flexible leather having a glaze and polish that renders it impervious to water and needing only be wiped with a sponge to restore it to its original lustre. This is later recognised as patent leather and is further improved by other inventors.\n\nAt some time around the late 18th or early 19th century a stand-alone cooking range or stove is invented by John Heard (joiner), capable of roasting, boiling, baking and of course heating a room. The products of combustion are carried off by means of a flue leading to the chimney, the inventor mentions it is particularly suitable for use on board ships. This is possibly the first of its kind, as earlier stoves such as the Franklin stove do not appear to have flues attached and require a hearth and chimney to function, also it is not until the turn of the 19th century that other stoves begin appearing for cooking as well as heating a room.\n\n1802: The exterior of the Soho Foundry is lit with gas lighting by William Murdoch. Murdoch, its developer, worked for Matthew Boulton and James Watt at Soho. This becomes the basis for Birmingham's immense gas industry, which incorporates many products and trades that rely on gas to work.\n\n1811: Henry James takes out a patent for propelling vessels by steam, via a paddle wheel fixed in the middle of the stern and steered by two fins to relieve leggers from the arduous duty of pushing boats through canal tunnels.\n\n1814: Thomas Dobbs (actor) invents a reaping machine, which consists of a circular saw or sickle; the grain is drawn or fed up to the saw by means of a pair of rollers. This predates William Bell's straw cutting machine.\n1821: Emanuel Heaton, gun finisher, takes out a patent for a watertight pan for gun locks.\n\n1823: Francis Deakin improves a method of stringing the piano by employing the screw and nut as opposed to the previously used wooden peg, thus allowing a greater tension and strength of wire.\n\n1824: American inventor William Church patents a printing machine in his Birmingham works, which positions the paper sheets more accurately. He is a prolific inventor, taking out numerous patents for methods of button making, nail making, metal working, smelting iron, spinning and other branches of engineering.\n\n1824: John Cadbury begins selling tea, coffee, and drinking chocolate, which he produces himself, at Bull Street. He later moves into the production of a variety of cocoa and drinking chocolates, made in a factory in Bridge Street and sold mainly to the wealthy because of the high cost of production. John Cadbury becomes a partner with his brother Benjamin and the company they form is called 'Cadbury Brothers of Birmingham'.\n\nThe brothers open an office in London and in 1854 they receive the Royal Warrant as manufacturers of chocolate and cocoa to Queen Victoria. In the 1850s the industry receives a much needed boost, with the reduction in the high import taxes on cocoa, allowing chocolate to be more affordable to everybody. Cadbury's later becomes one of the largest chocolate manufacturers in the world and is still in production across the world today with a major production plant in Bournville.\n\n1828: Josiah Mason improves a cheap, efficient slip-in nib that can be added to a fountain pen.\n\n1830: With the invention of a new machine, William Joseph Gillott, John Mitchell and James Stephen Perry devise a way to mass-produce robust, cheap steel pen nibs. This boosts the Birmingham pen trade and by the 1850s, Birmingham exists as a world centre for steel pen and steel nib manufacture; more than half the steel-nib pens manufactured in the world are made in Birmingham. Thousands of skilled craftsmen and -women are employed in the industry. Many new manufacturing techniques are perfected, enabling the city's factories to mass-produce their pens cheaply and efficiently. These are sold worldwide to many who previously cannot afford to write, thus encouraging the development of education and literacy.\n\n1830s: Thomas Ridgway begins trading in the Bull Ring, selling tea. Ridgway later goes bankrupt. Setting up business in London, he pays back all of his creditors and continues his tea trade, becoming one of the first English tea companies to hygienically prepack tea so as to avoid adulteration. In 1876, Queen Victoria commands House of Ridgways to create a blend for her own personal use.\n\n1832: Muntz metal is patented, an alpha-beta brass with about 40% zinc and 60% copper. Its original use is as a replacement for the copper lining placed on the bottom of boats as it maintains the anti-fouling abilities of the pure form.\n\nIt costs around two-thirds that of pure copper and has identical properties for this application, it becomes the material of choice and Muntz makes his fortune. A notable use of Muntz Metal is in the hull of the Cutty Sark.\n1832: William Chance, owner of a Birmingham iron merchants, invests in his brothers failing glass works in nearby Smethwick. After saving the company, this partnership later becomes the Chance Brothers. The company relies on local workers, and at one stage is known as \"... the greatest glass manufacturer in Britain\", taking advantage of the Birmingham Canal Navigations and the Industrial Revolution in the region. Great advances in glass manufacture take place such as perfection of the earliest optical lenses to block the harmful ultra violet rays of the sun and improvements in lighthouse illumination. The company is responsible for glazing the original Crystal Palace to house the Great Exhibition of 1851, and the Houses of Parliament (built 1840–1860). At that time it is the only firm that is able to make the opal glass for the four faces of the Westminster Clock Tower that houses the famous bell, Big Ben. The ornamental windows for the White House in America are also made at Chances.\n1832: A form of German silver is invented by Charles Askins, this is used to make spoons and cutlery specifically in the Birmingham area.\n\n1837: Bird's Custard is first formulated and cooked by Alfred Bird, because his wife is allergic to eggs, the key ingredient used to thicken traditional custard. Bird's custard powder later becomes famous around the world.\n\n1838: Charles Green patents an original and unique method of producing solid, seamless brass and copper tubes, around this time much development takes place in Birmingham and Manchester with regard to copper tubing and printing plates.\n\n1839: After many years of research, innovation and campaigning, Rowland Hill (of Kidderminster and later Birmingham) is given a two-year contract to run his new postal system. Hill is an English teacher, inventor and social reformer. He campaigns for a comprehensive reform of the postal system, based on the concept of penny postage and his solution of prepayment facilitates the safe, speedy and cheap transfer of letters. Hill later serves as a government postal official, and he is usually credited with originating the basic concepts of the modern postal service, including the invention of the postage stamp (his brother Edwin Hill helps the service with further innovations).\n1839: Sir Edward Thomason improves the gun lock by making the cock detachable by the thumb and finger as well as making improvements to prevent misfires.\n\nGeorge Elkington and Henry Elkington found the English electroplating industry in the early 19th century. In 1840, they aid John Wright, who discovers that potassium cyanide is a suitable electrolyte for gold and silver electroplating.\n\nCarl Wilhelm Siemens has several meetings with George Elkington, and makes speeches on 'Science and Industry,' to the Birmingham and Midland Institute, he later sets up a works in Birmingham and carries out experiments on metals and telegraphy.\n\n1845: During the late 1830s, canal steam boats begin operating with limited success but in 1845, Birmingham engineer John Inshaw builds the first twin-screw canal steamers. Inshaw finds great success through his engineering and in 1859 the owners of the Ashby Canal ban his steamer \"Pioneer\", claiming it erodes the canal banks. It is later allowed to run no faster than 4 mph, thus begin speed limits on British waterways. Inshaw's \"Pioneer\" is successful and later inspires other steam boats such as those built for the Grand Junction Canal. Inshaw is also consulted by George Stephenson on the design of wheels for steam locomotives.\n\n1847: William Stroudley joins Birmingham engineer John Inshaw as one of his most successful pupils. Stroudley later becomes one of Britain's most famous steam locomotive engineers of the 19th century, working principally for the London, Brighton and South Coast Railway (LB&SCR). He designs some of the most famous and longest-lived steam locomotives of his era.\n\nBirmingham glassworks are among the early mass-producers of uranium glass. Manufacturers include Bacchus, Green & Green (later George Bacchus & Sons), Union Glassworks, in the 1840s, and Lloyd & Summerfield in the 1850s, who are the first to use uranium in glass commercially.\n\n1849: William Tranter takes out the first of many patents for his improvements in manufacture of the firearm.\n\nThe use of weather charts in a modern sense begins in the middle portion of the 19th century. Weather map pioneers include William Charles Redfield, William Reid, Elias Loomis, and Birmingham's Sir Francis Galton, who creates the first weather maps in order to devise a theory on storm systems.\nGalton formulates (and later coins the term for) eugenics as well as questionnaires and many important tools in statistics. Galton avidly supports the theories of his cousin Charles Darwin, and also furthers the most important advances in fingerprinting.\n\n1851: John Nettlefold, screw manufacturer, attends the Paris exhibition. He later buys exclusive rights to use Thomas Sloan's machine for making screws, which is in the show. With adaptation of the machine for their Birmingham premises and inspiration of Birmingham mass production methods, Nettlefold & Chamberlain become Britain's leading screw-making firm.\n\n1854: Birmingham chemist Thomas Allcock invents the porous plaster for the relief of pain in New York after fighting as a General for the New York Heavy Artillery during the American Civil War after emigrating in 1845 aged 20.\n\n1857: Joseph Sturge buys the Elberton Sugar Estate and converts it into a lime production plant. The Montserrat Co. Ltd. is formed in Edgbaston by J.& E. Sturge. Lime juice is produced in the city and then exported for use in the manufacture of citric acid. The failure of Sicily's lemon crop at this time results in an opening in the market, which Sturge takes great advantage of utilizing their extensive chemical works based in Edgbaston. He also tries to prove that Free labour can be made profitable (the Sturge family are instrumental in the anti-slavery movement). A company is set up by the Sturge and Albright families who fund the development of Montserrat estates in 1867.\n\n1858: After several failed attempts of launching the steam ship, Isambard Kingdom Brunel turns to Richard Tangye's more powerful hydraulic rams, which are successfully employed in the launch.\n\nRichard Tangye's company then acquires the patent of the differential pulley-block in 1859, and in 1862 he invents the Tangye Patent hydraulic jack. This results in the 1862 purchase and demolition of Soho-located Smethwick Hall, on the site of which is built the Cornwall Works.\n\n1867: The patent for a new type of direct-acting steam pump is acquired, in 1869 Tangye Ltd is commissioned to design the hydraulic systems for the UK's first funicular cliff railway in Scarborough, North Yorkshire and in 1870 the company commences the manufacture of steam engines. Richard Tangye and his brother George found the Birmingham Art Gallery in 1885, which today has a collection of international importance covering fine art, ceramics, metalwork, jewellery, archaeology, ethnography, local history and industrial history. They also found the Birmingham School of Art.\n\n1859: The first ever game of lawn tennis is played in Edgbaston, international tennis is still played at Edgbaston's Priory Club.\nThe first celluloid as a bulk material for forming objects is invented in 1856 by Alexander Parkes. Many years later, and with the recognition of celluloid as a format for making photographic film, an American court declares Parkes as the true inventor of celluloid.\n\n1862: the thermoplastic Parkesine is showcased at the Great International Exhibition in London. Invented by Alexander Parkes, this celluloid is credited by the London Science Museum to be \"generally accepted as the first plastic\". (This presumably refers to synthetic plastic formed into objects: it is predated by the 1848 collodion, a nitrocellulose-based solution that dries to a celluloid-like film but is useless for industrial purposes, (as well as several natural plastics).\n\n1862: James Moore Clements of Livery Street, who has already invented an improved machine for making buttonholes, is granted a patent for a new arrangement of 'stitching the hole'.\n\n1863: William Sumner (founder of Typhoo) publishes \"A Popular Treatise on Tea\". In 1870, Sumner starts a pharmacy/grocery business on the High Street, Birmingham. This grows and forces Sumner to move to new premises on Castle Street and then on to Bordesley Street at the canalside. Typhoo tea later becomes one of the largest teabag makers in Britain. The brand is now based in Wirral.\n\n1865: The steel wire, some 16,000 miles long, for sheathing the first successful Transatlantic telegraph cable is made by Webster and Horsfall, Birmingham.\n\n1865: Joseph Hinks sets up James Hinks & Son, of 91-96 Great Hampton Street and 66 Hockley Street. He patents improvements to oil lamps, marketing the resultant Duplex Lamp, which is later used across the world and becomes a popular choice for railway workers.\n\n1868: John Barnes Linnett patents the world's first flip book.\n\n1873: William Westley Richards, gunmakers, takes out the first of many patents relating to the firearm, for which gold medals and royal warrants were awarded.\n\n1875: Joseph Lucas begins making lamps for ships, concentrating on the new types of lamp burning paraffin and petroleum for which there is considerable demand. The business becomes Lucas Industries.\n\n1878: Joseph Hudson makes the first whistle ever to be used by a football referee. It is used for the first time at a game held at Nottingham Forest, this replaces the referee's use of the handkerchief to attract footballers attention. Later, in 1883 Hudson invents and manufactures the first police whistle for the Metropolitan police force, prior to this police use hand rattles, whistles are usually used as musical instruments or toys. His whistle is still used by the force and many others today. In 1884 Hudson invents the world's most successful whistle to date, the 'Acme Thunderer' (the first ever pea whistle). The whistle is used as an alarm or attention instrument by all manner of industries, sports and revelers. It continues to sell in great quantities throughout the world.\n1880: Gamgee Tissue, a surgical dressing with a thick layer of absorbent cotton wool between two layers of absorbent gauze, is invented by Joseph Sampson Gamgee. It represents the first use of cotton wool in a medical context, and is a major advancement in the prevention of infection of surgical wounds. It is still the basis for many modern surgical dressings. Gamgee also invents the aseptic technique, a procedure that is performed under sterile conditions. This includes medical and laboratory techniques, such as with microbiological cultures. It includes techniques like flame sterilization. The largest example of aseptic techniques is in hospital operating theatres. J. R. R. Tolkien later bases Lord of the Rings character 'Sam Gamgee' on this character as they live near to Mr Gamgee.\n\nDuring the late 19th century, Birmingham companies such as Joseph Lucas & Sons and Powell & Hammer pioneered the production of bicycle lamps and lanterns for ships, capitalising on the advances in using acetylene gas. The Birmingham lamps were exported around the world, with the Lucas company later becoming famous for manufacturing components related to the motor industry and aerospace industry. Richard Bissell Prosser(1838–1918) writes 58 lives for the \"Dictionary of National Biography\", and supplies much material for the \"New English Dictionary\". Prosser also writes Birmingham Inventors and Inventions, 1881 and is a pioneer of the study of technical history, his published biographies and manuscript records are an incomparable source for present-day researchers. His father Richard Prosser (1804–1854), engineer and inventor, was heavily involved with the introduction of the Patent Law Amendment Act of 1852, and his 700-volume library, combined with that of Bennet Woodcroft forms the basis of the Patent Office Library.\n\n1879: Harry Lucas designs a hub lamp for use in a high bicycle and names the oil lamp \"King of the Road\".\n\n1881: Birmingham businessman John Skirrow Wright invents the postal order and its use subsequently spreads across the world. Skirrow becomes one of the prominent pioneers and social improvers of the 19th century.\n\n1883: Surgeon and gynaecologist Lawson Tait, pioneer of several surgical procedures, carries out the world's first successful operation on a ruptured ectopic pregnancy.\n\n1884: John Berry Haycraft has been actively engaged in research and published papers on the coagulation of blood and in 1884, he discovers that the leech secretes a powerful anticoagulant, which he names hirudin.\n1885: Birmingham School of Art becomes the first Municipal School of Art. It later becomes the leading centre for the Arts and Crafts movement.\n\n1885: The world's first professional football league is founded at a meeting in Aston under the auspices of William McGregor, a director of Aston Villa.\n\n1889: Charles Pinkney of Tangyes perfects a gas engine, this comes about through his experimentation with a hydrocarbon gas producer and a bituminous coal gas generator. The engine proves to be more economical that an earlier Four-stroke Otto cycle engine.\n\n1891: The Dunlop Rubber Company co-founded by John Boyd Dunlop established its Birmingham factory Fort Dunlop, later to become the focus of Dunlop as one of the largest multinational manufacturers of automotive and aeronautical tyres.\n\n1894: Richard Norris, a doctor of medicine and professor of physiology at Queen's College, Birmingham, brings out a new patent of dry plate used in photography and is generally credited with the first development of the collodion dry plate in the 1860s.\n\n1895: Frederick William Lanchester and his brother build the first petrol driven four-wheeled car in Britain. Lanchester also experiments with the wick carburetor, fuel injection, turbochargers and invents the accelerator pedal and first uses the pendulum governor for controlling the speed of a car engine. In 1893 he designs and builds his first engine (a vertical single cylinder) that is fitted to the first British motorboat.\n\n1895: Herbert Austin, an employee at Wolseley Sheep Shearing Company, becomes interested in engines and automobiles. During the winter of 1895–96 he makes his own version of a design by Léon Bollée that he has seen in Paris. Later he finds that another British group have bought the rights, therefore Austin has to come up with a design of his own.\n\nTwo years later, the second Wolseley car is revealed. It is a three-wheeled design featuring independent rear suspension, mid-engine and back-to-back seating for two adults. Four years later the Wolseley Gasoline Carriage is built featuring a steering wheel instead of a tiller. Austin manages the new Wolseley company for a short time before resigning to form his own concern, the Austin Motor Company, in 1905. Wolseley later becomes a successful car and engine maker selling upmarket cars, and even opens a lavish showroom, Wolseley House, in Piccadilly London (next to the Ritz Hotel, now housing a restaurant called The Wolseley). The company is later merged in other motor car companies.\n\n1896: The first radiograph used to assist in surgery is taken in Birmingham by the British pioneer of medical X-rays, Major John Hall-Edwards thus kick-starting a whole new field of medical science.\n\n1896: A new building is built in Corporation Street to house James Henry Cook's vegetarian restaurant, one of the first in England. In 1898, 'The Pitman Vegetarian Hotel', named after the famous vegetarian Sir Isaac Pitman, opens on the same site, and the proprietors subsequently open a long-running health food store.\n\n1896: The first 'public' trial in Birmingham of a \"horseless carriage\" or motor car takes place at Cannon Hill Park.\n\n1897: John Benjamin Stone founds the National Photographic Record Association, of which he becomes president. The National Portrait Gallery holds 62 of his portraits and many photographs of people and places in and around Westminster. His career culminates in 1911 with his appointment as official photographer to the coronation of King George V. Stone travels widely in pursuit of his hobby, taking 26,000 photographs, and writing books as he travels. He publishes works and invaluable records of the folk customs and traditions of the British Isles, which later influence photographers of note, such as Tony Ray-Jones.\n\n1897: The Reynolds Tube Company patents the process for making butted bicycle tubes, which are thicker at the ends than in the middle, this allows frame builders to create frames that are both strong and lightweight. Reynolds continues to develop lightweight bicycle frames into the 20th century picking up many awards for wins in races such as the Tour de France, the company still makes lightweight frames in the city today.\n\nBicycles have been manufactured in the Midlands (mainly Birmingham and Coventry) since the mid 19th century. By 1900 Birmingham has the largest number of bicycle makers and component manufacturers in Britain. Several advances in the development of the bicycle take place, one of the longer established high quality manufacturers being the 'Quadrant Cycle Company' of Sheepcote Street, which later manufactures motorbikes (as do many cycle makers).\n\nOther notable firms are Reynolds (still manufacturing in the city), New Hudson, Rudge-Whitworth (also of Coventry), B.S.A., C.W.S., Dawes, Grundle, James Cycle Co, Ariel, Armstrong Cycles, Phillips Cycles, Excelsior (originally of Coventry), Sun Cycle & Fittings Co, Pashley Cycles (now manufactured in Stratford-upon-Avon) and Hercules Cycle and Motor Company.\n\nThrough the 20th century, many of Birmingham's bicycle manufacturers evolve into automobile and motorcycle brands, creating one of the busiest and most productive engineering hubs in the world.\n\nMotor engineering brands such as Wolseley, Lanchester, Metro Cammell, Austin, Morris, Vickers-Armstrongs, New Hudson, Revere, Beardmore, Sun, Ariel, Norton, Rex-Acme, Alldays & Onions, Velocette, Midland Red and BSA either originate or have substantial factories in Birmingham, manufacturing motorbikes, buses, tractors, cars, tanks and aeroplanes.\n\nOther diverse engineering companies develop to feed the supply chain of the motoring industry such as Webster and Horsfall (pioneering wire for aircraft and cars), Dunlop Rubber (supplying rubber and tyres), Lucas Industries (pioneering electric and lighting), Accles & Pollock (producing tubular sections for aircraft) and Pockley Electric (manufacturing car lights).\n\n1900: Bournville Village Trust is founded by George Cadbury, this is to make many improvements and set high standards of living and leisure pastimes for factory workers across Britain. Cadbury's still makes chocolate in the city today and Bournville remains a sought after area to live in.\n\n1900: John Wright invents a much-improved gas fire, which uses fretted columns of fireclay, rather than tufted asbestos, to radiate the heat. The Wright design of gas fire heating endures throughout the century, however, electric fires improve at a similar pace.\n1902: The first caliper-type automobile disc brake is patented by Frederick William Lanchester in his Birmingham factory and used successfully on Lanchester cars. However, the limited choice of metals in this period means that he has to use copper as the braking medium acting on the disc. The poor state of the roads at this time — no more than dusty, rough tracks — means that the copper wears quickly, making the disc brake system non-viable. It is not until 1929, in the same city that manufacturers Girling and New Hudson further develop disc brakes, which are very successful on racing cars from the early 1950s to the 1970s. Girling brakes have the quirk of using natural rubber (later nitrile) seals. Girling still manufacture disc brakes in Birmingham today.\n\n1902: George Andrew Darby patents the first electrical heat detector and smoke detector.\n\n1903: Birmingham-born patent lawyer Bertram Hopkinson is elected to the Cambridge chair in mechanism and applied mechanics, where he carries out early research on tank armour plating.\n\nHopkinson builds a team of researchers, one of whom is Harry Ricardo, the engineer who makes his name for his pioneering work on internal combustion engines. Hopkinson encourages Ricardo to work on engines.\n\n1903: Brummie Francis William Aston wins a scholarship to the University of Birmingham and in his studies of electronic discharge tubes he discovers the phenomenon now known as the Aston Dark Space. He later moves to the Cavendish Laboratory in Cambridge, where he uses a method of electromagnetic focusing to invent the mass spectrograph, which rapidly allows him to identify no fewer than 212 of the 287 naturally occurring isotopes. His work on isotopes also leads to his formulation of the Whole Number Rule, which is later used extensively in the development of nuclear energy. In 1922 he wins the Nobel Prize in Chemistry for the invention of the mass spectrometer.\n1905: A manually powered domestic vacuum cleaner is invented by manufacturer Walter Griffiths of 72, Conybere Street, Highgate. It is originally patented as 'Griffiths' Improved Vacuum Apparatus for Removing Dust from Carpets'. Although an electric cleaner is patented in 1901 by H. Cecil Booth, Griffiths' design is more similar to modern portable cleaners than Booth's cart-mounted device.\n\n1905: Herbert Austin begins making cars at Longbridge, many improvements in mass car manufacture and production later arise from these car works. Seventeen years later the Austin 7 goes into production, it becomes one of the most popular cars ever produced for the British market, its effect on the British market is similar to that of the Model T Ford in the USA. Austin's designs and production help set up other car brands around the world that later become famous in their own right, such as BMW, Nissan and Lotus.\n\n1905: Accles & Pollock Produces the first tubular box spanners.\n1906: The earliest work on the parkerizing processes is developed by British inventors William Alexander Ross, in 1869, and by Thomas Watts Coslett, in 1906. Coslett, of Birmingham, subsequently files a patent based on this same process in America in 1907. It essentially provides an iron phosphating process, using phosphoric acid. Parkerizing (also called phosphating and phosphatizing) is a method of protecting a steel surface from corrosion and increasing its resistance to wear. Parkerizing is commonly used on firearms.\n\n1907: Accles & Pollock produce the first tubular sections for aircraft and the first tubular furniture.\n\n1908: Pockley Automobile Electric Lighting Syndicate markets the world's first electric car lights to be sold as a set, which consist of headlights, sidelights and tail lights and are powered by an 8 volt battery.\n\n1910: J. R. R. Tolkien begins to construct his first Elfin tongue whilst a pupil at King Edward's School, Birmingham. He later calls it Qenya (c. 1915). Tolkien is already familiar with Latin, Greek, Spanish, and several ancient Germanic languages, Gothic, Old Norse and Old English. Tolkien's parents are from Birmingham and he himself grows up, and studies in and around Birmingham (Tolkien also meets his wife in the town and considers himself a 'West Midlander'). The enduring popularity of \"The Lord of the Rings\" later leads to numerous references in popular culture, the founding of many societies by fans of Tolkien's works, and the publication of many books about Tolkien and his works. \"The Lord of the Rings\" continues to inspire artwork, music, films and television, video games and subsequent literature, including reference in the Oxford English Dictionary. Award-winning adaptations of \"The Lord of the Rings\" are later made for radio, theatre and film.\n1910: Oliver Lucas's company design and make an electric car vehicle horn, which becomes industry standard; an electric motorcycle horn is manufactured the following year.\n\n1913: Accles & Pollock is granted a patent for seamless tapered steel golf shafts.\n\n1914: Oliver Lucas and Charles Breeden carry out pioneering work on the design of the dynamo and electric equipment for motorcycles and by 1914 they are already manufacturing these items.\n\n1914 Birmingham, by now, is supplying the world with 28 million mass-produced pen nibs per week.\n\n1915: William Mills develops the first \"safe grenade\" meaning it is safe for the soldier throwing it rather than his opponent. It is named the Mills bomb, and is adopted by the British Army as its standard hand grenade in 1915. 75,000,000 grenades are supplied during The Great War.\n1918: Much work is carried out by Oliver Lucas's company on the design and improvement of the military search light, he also designs a signalling lamp after experiences at the Somme and the design is later used by the British Army.\n\n1920: Charles Henry Foyle invents the folding carton and is founder of Boxfoldia. However, an American process is developed by accident prior to this.\n\n1921: A British patent for windscreen wipers is registered by Mills Munitions. Several other patents take place for windscreen wipers around the world.\n\n1922: Birmingham rubber manufacturer Dunlop invents a tyre with steel rods and a canvas casing that lasts three times longer than any other tyre, this is a milestone in tyre manufacture. The following year their tyres help Henry Segrave win a Grand Prix title in a Sunbeam racing car, and are then used on a Bentley to help win the 24 Hours of Le Mans race.\n\nBy 1927 Dunlop tyres have already helped Malcolm Campbell reach a British land speed record and in this year, they help Henry Segrave achieve the world land speed record in a Sunbeam 1000 hp at Daytona Beach Road Course, USA. In 1931 Dunlop tyres help Malcolm Campbell achieve a new land speed record in a Blue Bird at Daytona Beach Road Course, USA. In 1935 Dunlop helps Malcolm Campbell achieve yet another new land speed record in the USA. Foam rubber is also invented at the Dunlop Latex Development Laboratories, Fort Dunlop in 1929. Dunlop continues to pioneer advances in tyre manufacture and becomes industry standard for many prestigious car makers and its tyres have been used, and continue to be used, on cars achieving victory in motor rallies and racing championships such as Formula 1 and touring.\n\n1923: Arthur L. Large invents the immersed heating resistor, a major advancement in the electric kettle. A safety valve is introduced by kettle maker Walter H. Bullpitt, also from Birmingham, in 1931.\nThese two advances in electrical water heating are to have profound effects on water heating and become the basis of the modern day electric kettle.\n\n1926: Cameras have been made in Birmingham since 1880, by companies such as J. Lancaster & Son and in 1926 Coronet begin manufacturing cameras in the city. Coronet eventually mass-produce cheap, but affordable cameras. Coronet have close links with other Birmingham camera makers such as Standard Cameras Ltd (featured in the National Media Museum) and E Elliott Ltd, who manufacture the unique and now collectible V. P. Twin (featured in the Museum of early consumer electronics and 1st achievements).\n\n1928: Brummie, Oscar Deutsch opens his first Odeon Cinema in nearby Brierley Hill. By 1930, \"Odeon\" is a household name and the cinemas are known for their maritime-inspired Art Deco architecture. This style is first used in 1930 on the cinema at Perry Barr in Birmingham, which is bought by Deutsch to expand the chain. He likes the style so much that he commissions the architect, Harry Weedon, to design his future buildings. The Odeon cinema chain later becomes one of the largest cinema chains in Europe.\n\n1929: Brylcreem (made famous by the Teddy Boy) is invented in the city and later gives rise to other hair styling products.\n\nFirst production run of Birmingham and Midland Motor Omnibus Company (Midland Red) buses takes place during the 1920s—one of the first British buses to have pneumatic tyres. BMMO later develop petrol and diesel engines during the 1930s, with experimental rear-engined buses being built. By the 1940s experiments with, and production of under-floor engined single-deck buses take place. Experiments and developments of independent front suspension, air suspension, rubber suspension, glass fibre construction and disc brakes take place during the 1950s. 1959 sees the introduction of a turbocharged coach capable of almost 100 mph, for non-stop motorway services. High speed (motorway) buses are developed with passenger toilets. During the 1960s BMMO becomes the first British bus company to make wide-scale use of computers in compiling bus schedules and staff rosters.\n\n1932: The Birmingham Sound Reproducers company is set up in the West Midlands. In the early 1950s, Samuel Margolin begins buying auto-changing turntables from BSR, using them as the basis of his Dansette record player. Over the next twenty years, \"Dansette\" becomes a household word in Britain. By 1957, BSR has grown to employ 2,600 workers. In addition to manufacturing their own brand of player—the Monarch Automatic Record Changer that could select and play 7\", 10\" and 12\" records at 33, 45 or 78 rpm, changing between the various settings automatically—BSR McDonald supplied turntables and autochangers to most of the world's record player manufacturers, eventually gaining 87% of the market. By 1977, BSR's various factories produced over 250,000 units a week.\n\n1932: Leonard Parsons is the first to use synthetic vitamin C as treatment for scurvy in children.\n\n1933: Credenda Conduit Co. Ltd of Birmingham patent a Credastat automatic oven thermostat, which is fitted to Creda electric cookers. This is an early advancement in electric cookers and a feature that eventually becomes standard on all electric cookers. An example of this cooker is on display at the London Science Museum.\n\n1934: The Reynolds Tube Company introduces the double-butted tube-set 531 for high strength but lightweight bicycle frames. Reynolds 531 remains for many years at the forefront of alloy steel tubing technology and is used to form the front subframes on the Jaguar E-Type during the 1960s. Before the introduction of more exotic materials such as aluminium, titanium or composites, Reynolds is considered the dominant maker of high end materials for bicycle frames. According to the company, 27 winners of the Tour de France have won riding on Reynolds tubing.\n\n1935: Birmingham has a long history of toy and trinket manufacture and in 1935 the biggest toy makers in England, Chad Valley, are appointed Toy Makers to the Queen of the United Kingdom. During their existence Chad Valley carry out several improvements and practices in the manufacture of toys during their production between the late 19th and mid-20th centuries, constantly striving to develop new board games, jigsaws and toys.\n\n1937: Professor Norman Haworth is awarded the Nobel Prize for Chemistry for his pioneering work on carbohydrates and synthetic vitamin C.\n\n1939: Dr Mary Evans and Dr Wilfred Gaisford begin trials of the world's first antibiotic M&B (sulfapyridine) as treatment for lobar pneumonia.\n\nBirmingham becomes the major British manufacturer of the phenolic plastic Bakelite.\nThe magnetron, the core component in the development of radar, and the first microwave power oscillators are developed at the University of Birmingham during World War II (the microwave oven owes its existence to these developments).\n\n1940: After initial teething problems with management, Castle Bromwich Aircraft Factory started production of the Spitfire fighter plane. By the time production ended at Castle Bromwich in June 1945, a total of 12,129 Spitfires (921 Mk IIs, 4489 Mk Vs, 5665 Mk IXs and 1054 Mk XVIs) had been built. CBAF became the largest and most successful plant of its type during the 1939–45 conflict. As the largest Spitfire factory in the UK, by producing up to 320 aircraft per month, it built over half of the approximately 20,000 aircraft of this type.\n\n1944: Anthony Ernest Pratt takes out his first patent for a board game named 'Murder', this is later to become the world-renowned murder mystery game 'Cluedo'.\n\n1946: Chance Brothers produce the first all-glass syringe with interchangeable barrel and plunger, thereby allowing mass sterilisation of components without the need for matching them.\n\n1947: Dunlop tyres help John Cobb raise the world land speed record to 630 km/h in the Railton Special, which is now displayed in Birmingham's Thinktank museum.\n\nBetween 1947 and 1951 Professor Peter Medawar pioneers research on skin graft rejection at Birmingham University, this leads to the discovery of a substance that aids nerves to reunite and the discovery of acquired immunological tolerance, Medawar is awarded the Nobel Prize for Medicine in 1960 for his work during this time.\n\n1950: In February, the first operation in England for 'hole-in-the-heart' (congenital atrial septal defect) is performed at Birmingham Children's Hospital.\n\nConway Berners-Lee, a mathematician and computer scientist from Birmingham, works in the team that develops the Ferranti Mark 1, the world's first commercial stored program electronic computer. Berners-Lee is demobilized from the British Army in 1947 with the rank of Major. By the late 1960s Berners-Lee leads the Medical Development Team of ICT and then ICL and is involved in some of the earliest developments in the applications of computers in medicine, and his text compression ideas are taken up by an early electronic patient record system. Berners-Lee later marries Mary Lee Woods (also from Birmingham). Woods studies at Birmingham University and later works in the team that develop programs for the Manchester Mark 1, Ferranti Mark 1 and Mark 1 Star computers. In 1955 the Berners-Lees become parents to Tim Berners-Lee, who invents the World Wide Web, making the first proposal for it in March 1989.\n1952: Professor Charlotte Anderson (Leonard Parsons Professor of Paediatrics and Child Health) is one of the team who prove that the glutens in wheat cause coeliac disease, from this gluten-free diets are introduced.\n\n1954: The Stewart platform (a parallel robot) first comes into use. Stewart platforms have applications in machine tool technology, crane technology, underwater research, air-to-sea rescue, satellite dish positioning, telescopes and orthopedic surgery but are better known for flight simulation.\n\n1950–1959: Essential research and development on heart pacemakers and plastic heart valves is carried out by Leon Abrams at Birmingham University.\n\n1959: The Mini car begins production at Birmingham's Longbridge plant. The original is considered a British icon of the 1960s, and its space-saving front-wheel-drive layout (which allowed 80% of the area of the car's floorpan to be used for passengers and luggage) influenced a generation of car makers. In 1999 the Mini was voted the second most influential car of the 20th century, behind the Ford Model T.\n1962: Maurice Wilkins, New Zealand born and Birmingham raised, receives the Nobel Prize for his work on DNA structure, he is one of three who become known as the Code Breakers. Wilkins is educated at King Edward's School (and St John's College, Cambridge), he receives a PhD for the study of phosphors at the University of Birmingham, where he works on radar display screens and uranium isotope separation before moving to the Manhattan Project.\n1962: Bill Fransen of American company Chamberlins brings two of their musical instruments to England to search for someone who could manufacture 70 matching tape heads for future Chamberlin keyboards. Fransen approaches a UK company that is skilled enough to develop the idea further and a deal is struck with Bradmatic Ltd. The first Mellotron sample keyboards are manufactured in Aston and are to enjoy great longevity in the music industry. Alongside the Hammond organ, the Mellotron later becomes a seminal musical instrument for music genres such as rock and psychedelia, it is also crucial to shaping the sound of the progressive rock and hard rock groups of the 1970s as well as inspiring further development of the sample keyboard, most notably the Fairlight, which, in turn, inspired sample modules such as the Akai Sampler range; synonymous with hip hop and dance music.\n\nSome of the more notable songs that make use of the signature Mellotron sound include Nights In White Satin by The Moody Blues, Tomorrow Never Knows and Strawberry Fields Forever by The Beatles, 2000 Light Years from Home and We Love You by The Rolling Stones, Hole In My Shoe by Traffic, Mercy Mercy Me by Marvin Gaye, Days by The Kinks, Space Oddity by David Bowie, Stairway to Heaven, The Rain Song and Kashmir by Led Zeppelin.\n\n1965: \"The Birmingham Press and Mail\" installs the GEC PABX 4 ACD, the earliest example of a call centre in the UK. Already the hallmarks of the call centre can be seen in the rows of agents with individual phone terminals, taking and making calls.\n\n1969–1970: Heavy metal music begins to take shape in Britain and America. Of the earliest influential bands that are later to be described as Heavy Metal, several of the most notable artists arise from the mid to late 1960s Brum Beat music scene, such as: Robert Plant and John Bonham of Led Zeppelin, Ozzy Osbourne, Tony Iommi, Geezer Butler and Bill Ward of Black Sabbath and Rob Halford and Glenn Tipton of Judas Priest.\nDuring the later half of the 20th century the first trials of the combined oral contraceptive pill outside the USA take place at Birmingham University and extensive research into advanced allergy vaccines and the synthesis of artificial blood take place.\n\n1975: Birmingham inventor Michael Gerzon co-invents the Soundfield microphone. Gerzon studies at the University of Oxford, and is inspired by Alan Blumlein's landmark 1933 development of stereophonic recording and reproduction. The Soundfield range of microphones are now considered the ultimate microphones for recording both stereophonic and multichannel surround formats. Gerzon later plays a large role in the invention of Ambisonics, which is a series of recording and replay techniques using multichannel mixing technology that can be used live or in the studio. \n\nBalti cuisine becomes nationally renowned, after initial growth in the city during the late 1980s. Today Balti restaurants are extremely popular throughout Britain and abroad.\n\nSir John Robert Vane, winner of a Nobel Prize in Physiology or Medicine in 1982 for his work on aspirin, is educated at King Edward's School and studies Chemistry at the University of Birmingham.\n\n1991: Derek McMinn begins the first successful modern metal-on-metal hip resurfacing operations and the instrumentation and surgical technique to implant it.\n\nMost of Birmingham's present day research and innovation is being undertaken in the fields of medical science, such as cancer research and eye disease research.\n\nSince the establishment of its Nanoscale Physics Research Laboratory, the University of Birmingham has become one of the significant UK research centres for nanotechnology.\n\nAston University is also carrying out groundbreaking research in the field of micro-technologies, including a micro-robotic drill for use in surgery, which is able to drill a hole so small into the shell of an egg, that the membrane remains intact. This is being developed for use in operations on the inner ear. A project to use fibre optics instead of electric sensors in aircraft fuel tanks is also being undertaken, cutting substantially the risk of sparks setting off an explosion.\n\n\n\n"}
{"id": "5463517", "url": "https://en.wikipedia.org/wiki?curid=5463517", "title": "Shadow (OS/2)", "text": "Shadow (OS/2)\n\nIn the graphical Workplace Shell (WPS) of the OS/2 operating system, a shadow is an object that represents another object.\n\nA shadow is a stand-in for any other object on the desktop, such as a document, an application, a folder, a hard disk, a network share or removable medium, or a printer. A target object can have an arbitrary number of shadows. When double-clicked, the desktop acts the same way as if the original object had been double-clicked. The shadow's context menu is the same as the target object's context menu, with the addition of an \"Original\" sub-menu, that allows the location of, and explicit operation upon, the original object.\n\nA shadow is a dynamic reference to an object. The original may be moved to another place in the file system, without breaking the link. The WPS updates shadows of objects whenever the original target objects are renamed or moved. To do this, it requests notification from the operating system of all file rename operations. (Thus if a target filesystem object is renamed when the WPS is not running, the link between the shadow and the target object is broken.)\n\nShadows are similar in operation to aliases in Mac OS, although there are some differences:\n\nShadows are different from symbolic links and shortcuts because they are not filesystem objects, and because shadows are dynamically updated as target objects are moved.\n\nShadows are different from hard links because unlike hard links they can cross volume boundaries and because their names are always the same as those of their target objects.\n\nOn (and within nested folders on) the WPS desktop, shadows' \"icon titles\" can be set to one's preferred font color, independently of the preferred font-color assigned to other non-shadow WPS objects, although they share the font actually selected for that text.\n\nLike the icons for all other 'open' objects on the WPS Desktop, whether for folders or applications, Shadows' icons become diagonally hatched on 'opening' and remain in that state until closed/exited respectively.\n\nThere are several ways to create a shadow. One way is to select the target object and choose \"Create Shadow\" from its context menu. The desktop then prompts with a dialogue box allowing the user to specify where the shadow should be created**. Another way is to employ drag-and-drop to create shadows, holding down the shift and control modifier keys whilst dragging.\n\nThe dialog box opens initially with a view of currently opened folders on the \"Opened\" Tab (page) of the dialog, first of which is the current Desktop folder, allowing direct selection of the destination. There are a further 4 Tabs for \"Related\", \"Desktop\", \"Drives\" and \"Path\", this latter allowing textual path specification including drive(volume), whereas the other three options display an expandable hierarchical tree of folders to select from.\n"}
{"id": "59045870", "url": "https://en.wikipedia.org/wiki?curid=59045870", "title": "Sich-1M", "text": "Sich-1M\n\nSich-1M () is a Ukrainian spacecraft, an artificial satellite of Earth, constructed for remote sensing of Earth.\n\nDeveloped byYuzhnoye Design Office and manufactured by Yuzhmash. \n\nSich-1M was launched on December 24, 2004 at 13:20 from the Plesetsk cosmodrome (Russia) using the Cyclone-3 launch vehicle together with MK-1TS microsatellite. Both satellites placed into incorrect orbits due to premature third stage cutoff.\n\nThe satellite was active until April 15, 2006.\n\nSich-1M was designed to receive information simultaneously in the optical, infrared and microwave ranges. The complex of research equipment installed on the spacecraft allowed to study the atmosphere of Earth and the World Ocean, monitoring the hydrological and ice conditions, vegetation and soil cover of the land, etc.\n\n\n"}
{"id": "1185832", "url": "https://en.wikipedia.org/wiki?curid=1185832", "title": "Sonicare", "text": "Sonicare\n\nSonicare is the brand name of an electric toothbrush produced by Philips.\n\nThe brush head vibrates at hundreds of times per second, with the latest models at 31,000 strokes per minute or 62,000 movements per minute (258 Hz). Rather than connecting to its charger with conductors, it uses inductive charging—the charger includes the primary winding of the voltage-reducing transformer and the fat handle of the brush includes the secondary winding. The replaceable head is also driven magnetically.\n\nIndividual clinical research has shown Sonicare toothbrushes to be more effective than comparable Oral-B electric toothbrushes in reduction of gingival inflammation and therefore improvement in periodontal health. However a 2004 review of 29 studies concluded that only electric toothbrushes with rotational/oscillation movement removed more plaque than other brushes when correctly used. A second review found no clinical evidence for the dynamic fluid activity of the Sonicare toothbrush being more effective in plaque removal than an Oral-B oscillating/rotating electric toothbrush. A 2007 study comparing the two found the rotation/oscillation brush to be more effective in single-use plaque reduction.\n\nAn additional study showed that while both Sonicare and Oral B electric toothbrushes do better than manual toothbrushes in removing plaque, reducing gingival inflammation, and reducing probing depths, the Sonicare showed significantly more improvement than Oral B. The percentage reduction in inflammation from baseline at 6 months was 31.9% for Sonicare and 18.1% for Oral B. In regards to probing depth, Sonicare showed a mean reduction of 0.84 mm from baseline at 6 months, while Oral B showed an average reduction of 0.39 mm.\n\nIndividual studies have shown that Sonicare toothbrushes are more effective in plaque removal and reduction in gingivitis compared to manual toothbrushes.\n\nIn 1987, David Giuliani, an entrepreneur with a background in electrical engineering, met with University of Washington professors Drs. David Engel and Roy Martin. They formed a new company named GEMTech to promote a dental hygiene device using a piezoelectric multimorph transducer. After several years of research and creating prototypes, the Sonicare toothbrush was introduced in November 1992 at a periodontal convention.\n\nIn 1995, GEMTech changed its name to Optiva Corporation. In October 2000, Philips Domestic Appliances and Personal Care, a division of Philips, acquired the company. A few months later Optiva Corporation changed its name to Philips Oral Healthcare, Inc. By the end of 2001, Sonicare had become the number-one selling rechargeable power toothbrush in the United States. In 2003, to improve Philips brand recognition in the US, Philips began rebranding the Sonicare toothbrush as \"Philips Sonicare\".\n\n"}
{"id": "51213873", "url": "https://en.wikipedia.org/wiki?curid=51213873", "title": "SuperMeat", "text": "SuperMeat\n\nSuperMeat is an Israeli startup company working to develop a \"meal-ready\" chicken cultured meat product created through the use of cell culture. The company, which is crowdfunded through Indiegogo, claims that their product is more environmentally sound than conventional meat production as well as more economic, and involves no animal slaughter.\n\nIn January 2018 SuperMeat announced a $3M seed funding round by New Crop Capital and Stray Dog Capital, as well as a strategic partnership with PHW, one of Europe’s largest poultry producers.\n"}
{"id": "215226", "url": "https://en.wikipedia.org/wiki?curid=215226", "title": "Thermionic emission", "text": "Thermionic emission\n\nThermionic emission is the thermally induced flow of charge carriers from a surface or over a potential-energy barrier. This occurs because the thermal energy given to the carrier overcomes the work function of the material. The charge carriers can be electrons or ions, and in older literature are sometimes referred to as thermions. After emission, a charge that is equal in magnitude and opposite in sign to the total charge emitted is initially left behind in the emitting region. But if the emitter is connected to a battery, the charge left behind is neutralized by charge supplied by the battery as the emitted charge carriers move away from the emitter, and finally the emitter will be in the same state as it was before emission.\n\nThe classical example of thermionic emission is that of electrons from a hot cathode into a vacuum (also known as thermal electron emission or the Edison effect) in a vacuum tube. The hot cathode can be a metal filament, a coated metal filament, or a separate structure of metal or carbides or borides of transition metals. Vacuum emission from metals tends to become significant only for temperatures over .\n\nThe term \"thermionic emission\" is now also used to refer to any thermally-excited charge emission process, even when the charge is emitted from one solid-state region into another. This process is crucially important in the operation of a variety of electronic devices and can be used for electricity generation (such as thermionic converters and electrodynamic tethers) or cooling. The magnitude of the charge flow increases dramatically with increasing temperature.\n\nBecause the electron was not identified as a separate physical particle until the 1897 work of J. J. Thomson, the word \"electron\" was not used when discussing experiments that took place before this date.\n\nThe phenomenon was initially reported in 1853 by Edmond Becquerel. It was rediscovered in 1873 by Frederick Guthrie in Britain. While doing work on charged objects, Guthrie discovered that a red-hot iron sphere with a negative charge would lose its charge (by somehow discharging it into air). He also found that this did not happen if the sphere had a positive charge. Other early contributors included Johann Wilhelm Hittorf (1869–1883), Eugen Goldstein (1885), and Julius Elster and Hans Friedrich Geitel (1882–1889).\n\nThe effect was rediscovered again by Thomas Edison on February 13, 1880, while he was trying to discover the reason for breakage of lamp filaments and uneven blackening (darkest near the positive terminal of the filament) of the bulbs in his incandescent lamps.\n\nEdison built several experimental lamp bulbs with an extra wire, metal plate, or foil inside the bulb that was separate from the filament and thus could serve as an electrode. He connected a galvanometer, a device used to measure current (the flow of charge), to the output of the extra metal electrode. If the foil was put at a negative potential relative to the filament, there was no measurable current between the filament and the foil. When the foil was raised to a positive potential relative to the filament, there could be a significant current between the filament through the vacuum to the foil if the filament was heated sufficiently (by its own external power source).\n\nWe now know that the filament was emitting electrons, which were attracted to a positively charged foil, but not a negatively charged one. This one-way current was called the \"Edison effect\" (although the term is occasionally used to refer to thermionic emission itself). He found that the current emitted by the hot filament increased rapidly with increasing voltage, and filed a patent application for a voltage-regulating device using the effect on November 15, 1883 (U.S. patent 307,031, the first US patent for an electronic device). He found that sufficient current would pass through the device to operate a telegraph sounder. This was exhibited at the International Electrical Exposition in Philadelphia in September 1884. William Preece, a British scientist, took back with him several of the Edison effect bulbs. He presented a paper on them in 1885, where he referred to thermionic emission as the \"Edison Effect.\" The British physicist John Ambrose Fleming, working for the British \"Wireless Telegraphy\" Company, discovered that the Edison Effect could be used to detect radio waves. Fleming went on to develop the two-element vacuum tube known as the diode, which he patented on November 16, 1904.\n\nThe thermionic diode can also be configured as a device that converts a heat difference to electric power directly without moving parts (a thermionic converter, a type of heat engine).\n\nFollowing J. J. Thomson's identification of the electron in 1897, the British physicist Owen Willans Richardson began work on the topic that he later called \"thermionic emission\". He received a Nobel Prize in Physics in 1928 \"for his work on the thermionic phenomenon and especially for the discovery of the law named after him\".\n\nFrom band theory, there are one or two electrons per atom in a solid that are free to move from atom to atom. This is sometimes collectively referred to as a \"sea of electrons\". Their velocities follow a statistical distribution, rather than being uniform, and occasionally an electron will have enough velocity to exit the metal without being pulled back in. The minimum amount of energy needed for an electron to leave a surface is called the work function. The work function is characteristic of the material and for most metals is on the order of several electronvolts. Thermionic currents can be increased by decreasing the work function. This often-desired goal can be achieved by applying various oxide coatings to the wire.\n\nIn 1901 Richardson published the results of his experiments: the current from a heated wire seemed to depend exponentially on the temperature of the wire with a mathematical form similar to the Arrhenius equation. Later, he proposed that the emission law should have the mathematical form\n\nwhere \"J\" is the emission current density, \"T\" is the temperature of the metal, \"W\" is the work function of the metal, \"k\" is the Boltzmann constant, and \"A\" is a parameter discussed next.\n\nIn the period 1911 to 1930, as physical understanding of the behaviour of electrons in metals increased, various theoretical expressions (based on different physical assumptions) were put forwards for \"A\", by Richardson, Saul Dushman, Ralph H. Fowler, Arnold Sommerfeld and Lothar Wolfgang Nordheim. Over 60 years later, there is still no consensus amongst interested theoreticians as to what is the exact expression of \"A\", but there is agreement that \"A\" must be written in the form\nwhere \"λ\" is a material-specific correction factor that is typically of order 0.5, and \"A\" is a universal constant given by\nwhere \"m\" and −\"e\" are the mass and charge of an electron, and \"h\" is Planck's constant.\n\nIn fact, by about 1930 there was agreement that, due to the wave-like nature of electrons, some proportion \"r\" of the outgoing electrons would be reflected as they reached the emitter surface, so the emission current density would be reduced, and \"λ\" would have the value (1-\"r\"). Thus, one sometimes sees the thermionic emission equation written in the form\n\nHowever, a modern theoretical treatment by Modinos assumes that the band-structure of the emitting material must also be taken into account. This would introduce a second correction factor \"λ\" into \"λ\", giving formula_5. Experimental values for the \"generalized\" coefficient \"A\" are generally of the order of magnitude of \"A\", but do differ significantly as between different emitting materials, and can differ as between different crystallographic faces of the same material. At least qualitatively, these experimental differences can be explained as due to differences in the value of \"λ\".\n\nConsiderable confusion exists in the literature of this area because: (1) many sources do not distinguish between \"A\" and \"A\", but just use the symbol \"A\" (and sometimes the name \"Richardson constant\") indiscriminately; (2) equations with and without the correction factor here denoted by \"λ\" are both given the same name; and (3) a variety of names exist for these equations, including \"Richardson equation\", \"Dushman's equation\", \"Richardson–Dushman equation\" and \"Richardson–Laue–Dushman equation\". In the literature, the elementary equation is sometimes given in circumstances where the generalized equation would be more appropriate, and this in itself can cause confusion. To avoid misunderstandings, the meaning of any \"A-like\" symbol should always be explicitly defined in terms of the more fundamental quantities involved.\n\nBecause of the exponential function, the current increases rapidly with temperature when \"kT\" is less than \"W\". (For essentially every material, melting occurs well before \"kT\" = \"W\".)\n\nIn electron emission devices, especially electron guns, the thermionic electron emitter will be biased negative relative to its surroundings. This creates an electric field of magnitude \"F\" at the emitter surface. Without the field, the surface barrier seen by an escaping Fermi-level electron has height \"W\" equal to the local work-function. The electric field lowers the surface barrier by an amount Δ\"W\", and increases the emission current. This is known as the Schottky effect (named for Walter H. Schottky) or field enhanced thermionic emission. It can be modeled by a simple modification of the Richardson equation, by replacing \"W\" by (\"W\" − Δ\"W\"). This gives the equation\nwhere \"ε\" is the electric constant (also, formerly, called the vacuum permittivity).\n\nElectron emission that takes place in the field-and-temperature-regime where this modified equation applies is often called Schottky emission. This equation is relatively accurate for electric field strengths lower than about 10 V  m. For electric field strengths higher than 10 V m, so-called Fowler-Nordheim (FN) tunneling begins to contribute significant emission current. In this regime, the combined effects of field-enhanced thermionic and field emission can be modeled by the Murphy-Good equation for thermo-field (T-F) emission. At even higher fields, FN tunneling becomes the dominant electron emission mechanism, and the emitter operates in the so-called \"cold field electron emission (CFE)\" regime.\n\nThermionic emission can also be enhanced by interaction with other forms of excitation such as light. For example, excited Cs-vapours in thermionic converters form clusters of Cs-Rydberg matter which yield a decrease of collector emitting work function from 1.5 eV to 1.0–0.7 eV. Due to long-lived nature of Rydberg matter this low work function remains low which essentially increases the low-temperature converter's efficiency.\n\nPhoton-enhanced thermionic emission (PETE) is a process developed by scientists at Stanford University that harnesses both the light and heat of the sun to generate electricity and increases the efficiency of solar power production by more than twice the current levels. The device developed for the process reaches peak efficiency above 200 °C, while most silicon solar cells become inert after reaching 100 °C. Such devices work best in parabolic dish collectors, which reach temperatures up to 800 °C. Although the team used a gallium nitride semiconductor in its proof-of-concept device, it claims that the use of gallium arsenide can increase the device's efficiency to 55–60 percent, nearly triple that of existing systems, and 12–17 percent more than existing 43 percent multi-junction solar cells.\n\n"}
{"id": "740742", "url": "https://en.wikipedia.org/wiki?curid=740742", "title": "Underground power station", "text": "Underground power station\n\nAn underground power station is a type of hydroelectric power station constructed by excavating the major components (e.g. machine hall, penstocks, and tailrace) from rock, rather than the more common surface-based construction methods.\n\nOne or more conditions impact whether a power station is constructed underground. The terrain or geology around a dam is taken into consideration, as gorges or steep valleys may not accommodate a surface power station. A power station within bedrock may be less expensive to construct than a surface power station on loose soil. Avalanche-prone valleys often make a surface station unfeasible as well. After World War II, large hydroelectric power stations were placed underground more often in order to protect them from airstrikes.\n\nOften underground power stations form part of pumped storage hydroelectricity schemes, whose basic function is to level load: they use cheap or surplus off-peak power to pump water from a lower lake to an upper lake. During peak periods (when electricity prices are often high), the power station generates power from the water held in the upper lake.\n\nSome notable underground power stations are:\n\n"}
{"id": "49669673", "url": "https://en.wikipedia.org/wiki?curid=49669673", "title": "Urea perchlorate", "text": "Urea perchlorate\n\nUrea perchlorate is a sheet-shaped crystallite with good chemical stability and strong hygroscopicity. It has usage as an oxidizer in liquid explosives including underwater blasting.\n\nThe compound is synthesized by gradual addition of urea into a perchloric acid solution:\n\nAn alternative route is addition of urea to hydrochloric acid solution, followed by addition of sodium perchlorate, and filtration of the salt.\n"}
{"id": "19718830", "url": "https://en.wikipedia.org/wiki?curid=19718830", "title": "VHF Data Link", "text": "VHF Data Link\n\nThe VHF Data Link or VHF Digital Link (VDL) is a means of sending information between aircraft and ground stations (and in the case of VDL Mode 4, other aircraft). Aeronautical VHF data links use the band 117.975–137 MHz assigned by the International Telecommunication Union to Aeronautical mobile (R) service. There are ARINC standards for ACARS on VHF and other data links installed on approximately 14,000 aircraft and a range of ICAO standards defined by the Aeronautical Mobile Communications Panel (AMCP) in the 1990s. Mode 2 is the only VDL mode being implemented operationally to support Controller Pilot Data Link Communications (CPDLC).\n\nThe ICAO AMCP defined this Mode for validation purposes. It was the same as VDL Mode 2 except that it used the same VHF link as VHF ACARS so it could be implemented using analog radios before VHF Digital Radio implementation was completed. The ICAO AMCP completed validation of VDL Modes 1&2 in 1994, after which the Mode 1 was no longer needed and was deleted from the ICAO standards.\n\nThe ICAO VDL Mode 2 is the main version of VDL. It has been implemented in a Eurocontrol Link 2000+ program and is specified as the primary link in the EU Single European Sky rule adopted in January 2009 requiring all new aircraft flying in Europe after January 1, 2014 to be equipped with CPDLC.\n\nIn advance of CPDLC implementation, VDL Mode 2 has already been implemented in approximately 2,000 aircraft to transport ACARS messages simplifying the addition of CPDLC. Networks of ground stations providing VDL Mode 2 service have been deployed by ARINC and SITA with varying levels of coverage.\n\nThe ICAO standard for the VDL Mode 2 specifies three layers: the \"Subnetwork\", \"Link\", and \"Physical Layer\". The Subnetwork Layer complies with the requirements of the ICAO Aeronautical Telecommunication Network (ATN) standard which specifies an end-to-end data protocol to be used over multiple air-ground and ground subnetworks including VDL.\n\nThe VDL Mode 2 Link Layer is made up of two sublayers: a \"Data Link\" service and a \"media access control\" (MAC) sublayer. The Data Link protocol is based on the ISO standards used for dial-up HDLC access to X.25 networks. It provides aircraft with a positive link establishment to a ground station, and defines an addressing scheme for ground stations. The MAC protocol is a version of Carrier Sense Multiple Access (CSMA).\n\nThe VDL Mode 2 Physical Layer specifies the use in a 25 kHz wide VHF channel of a modulation scheme called Differential 8-Phase-shift keying with a symbol rate of 10,500 symbols per second. The raw (uncoded) physical layer bit rate is thus 31.5 kilobit/second. This required the implementation of VHF digital radios.\n\nThe ICAO standard for VDL Mode 3 defines a protocol providing aircraft with both data and digitized voice communications that was defined by the US FAA with support from Mitre. The digitized voice support made the Mode 3 protocol much more complex than VDL Mode 2. The data and digitized voice packets go in Time Division Multiple Access (TDMA) slots assigned by ground stations. The FAA implemented a prototype system around 2003 but did not manage to convince airlines to install VDL Mode 3 avionics and in 2004 abandoned its implementation.\n\nThe ICAO standard for VDL Mode 4 specifies a protocol enabling aircraft to exchange data with ground stations and other aircraft.\n\nVDL Mode 4 uses a protocol (Self-organized Time Division Multiple Access, STDMA, invented by Swede Håkan Lans in 1988) that allows it to be self-organizing, meaning no master ground station is required. This made it much simpler to implement than VDL Mode 3.\n\nIn November 2001 this protocol was adopted by ICAO as a global standard. Its primary function was to provide a VHF frequency physical layer for ADS-B transmissions. However it was overtaken as the link for ADS-B by the Mode S radar link operating in the 1,090 MHz band which was selected as the primary link by the ICAO Air Navigation Conference in 2003.\n\nThe VDL Mode 4 medium can also be used for air-ground exchanges. It is best used for short message transmissions between a large number of users, e.g. providing situational awareness, Digital Aeronautical Information Management (D-AIM), etc..\n\nEuropean Air Traffic Management modernization trials have implemented ADS-B and air-ground exchanges using VDL Mode 4 systems. However, on air transport aircraft the operational implementations of ADS-B will use the Mode S link and of CPDLC will use VDL Mode 2.\n\nMode 2:\n\nMode 4:\n"}
