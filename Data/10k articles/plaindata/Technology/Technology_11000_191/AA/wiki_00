{"id": "46373107", "url": "https://en.wikipedia.org/wiki?curid=46373107", "title": "Adsorption/Bio-oxidation process", "text": "Adsorption/Bio-oxidation process\n\nThe adsorption/bio-oxidation process is a two-stage modification of the activated sludge process used for wastewater treatment. It consists of a high-loaded A-stage and low-loaded B-stage. The process is operated without a primary clarifier, with the A-stage being an open dynamic biological system. Both stages have separate settling tanks and sludge recycling lines, thus maintaining unique microbial communities in both reactors.\n\nAdsorption/bio-oxidation process was invented in the mid-1970s by the professor of the RWTH Aachen University Botho Böhnke. It was based on the finding, made by the German engineer Karl Imhoff in the 50th. Imhoff stated that the treatment efficiency of 60-80 percent could be achieved in highly loaded activated sludge basins.\n\nIn 1977 Böhnke published his first article on adsorption/bio-oxidation process. The same year the patent was issued. Extensive research of the following years, conducted by prof. Böhnke together with Bernd and Andreas Diering, ended up in 1985 with the establishment of the company Dr.-Ing. Bernd Diering GmbH. The same year AB-process was for the first time applied in a full-scale at the Krefeld, Germany sewage treatment plant (800 000 P.E.). In 1990, 19 full scale installations existed in Western Germany alone. Further application of the process in Europe was hindered by the tightening of the effluent discharge requirements with respect to nitrogen and phosphorus. The process came into notice in 2000th again due to the increased interest in energy recovery from wastewater.\n\nThe A-stage, or adsorption stage is the most innovative component of the process. It is not preceded by primary treatment. Influent organic matter is removed in the A-stage mainly by flocculation and sorption to sludge due to the high loading rates (2-10 g BOD • g VSS • d) and low sludge age (typically 4-10 h). Hydrolysis of complex organic molecules occurs improving biodegradability of the influent of the B-stage. High loading rates and low sludge age favours development of dynamic biocoenosis with a large fraction of microorganisms present in the exponential growth phase. Diverse sludge biocoenosis increase variety of organic compounds that can be degraded in the A-stage and makes the process more stable towards the shock loads. Altogether, up to 80% of the influent organic matter can be removed in the A-stage. The required reactor volume and oxygen supply are lower if compared to the removal in the conventional activated sludge process.\n\nThe B-stage, or bio-oxidation stage, is a typical low-loaded activated sludge process, where biodegradation of the remaining organic material occurs. The B-stage can be designed for nitrogen and/or phosphorus removal by alternating aerobic, anoxic and anaerobic zones in the reactor.\n\n\n\nNitrogen removal in the A-stage can reach 30-40%, as nitrogen of organic compounds is incorporated in upflow anaerobic sludge blanket (UASB) reactor sludge.\n\nThe sludge age of the B-stage is typically between 8 and 20 days promoting the growth of nitrifiers. Therefore, complete nitrification is usually achieved in the B-stage. Complete denitrification is difficult to achieve, because of the low C:N ratio in the influent of the B-stage. Insufficient carbon supply of carbon source to the B-stage occurs due to the high efficiency of organic matter removal in the A-stage. The problem can be solved by decreasing organic matter removal in the A-stage, external carbon source supply, intermittent aeration or decreased HRT of the A-stage and/or on-line control of certain operational parameters. To achieve biological nitrogen and phosphorus removal anaerobic and anoxic compartments are introduced before the aerated zone of the B-stage.\n\nPhosphorus removal from the secondary effluent of the B-stage can be achieved by coagulation with ferric and aluminium salts, e.g. FeCl or Al(SO).\n\nThe adsorption/bio-oxidation process was applied at the Krefeld plant (800 000 P.E.) in 1985 for the first time. The plant was expanded and modified and currently treats municipal and industrial wastewater of 1 200 000 P.E.\n\nCurrently adsorption/bio-oxidation process is applied at the municipal treatment plants in Germany, the Netherlands (WWTP Dokhaven (Rotterdam), WWTP Utrecht, WWTP Garmerwolde (Groningen) etc.), Austria (WWTP Salzburg, WWTP Strass etc.), Spain, USA, China etc.\n\nAdsorption/bio-oxidation process is a part of innovative wastewater treatment concept WaterSchoon, realized in the Netherlands. 250 apartments in the new district Noorderhoek (Sneek, the Netherlands) are equipped with separate collection systems for toilet wastewater and the rest of the household wastewater (or so-called greywater). Both streams are treated separately in order to maximize recovery of resources from wastewater. Adsorption/bio-oxidation process is used for grey water treatment to increase sludge production. Sludge, produced in both stages of the process, is digested together with toilet wastewater in the UASB reactor to maximize energy recovery.\n\nThe adsorption/bio-oxidation process is used for treatment of industrial wastewater with high COD, including wastewater from:\n\nThe C/N and C/P ratios of industrial wastewater is often too high for complete aerobic biodegradation of the influent organic matter, even after the adsorption stage. Addition of nutrients prior to bio-oxidation stage is required in these cases.\n\n"}
{"id": "21239195", "url": "https://en.wikipedia.org/wiki?curid=21239195", "title": "Ancient Roman pottery", "text": "Ancient Roman pottery\n\nPottery was produced in enormous quantities in ancient Rome, mostly for utilitarian purposes. It is found all over the former Roman Empire and beyond. Monte Testaccio is a huge waste mound in Rome made almost entirely of broken amphorae used for transporting and storing liquids and other products – in this case probably mostly Spanish olive oil, which was landed nearby, and was the main fuel for lighting, as well as its use in the kitchen and washing in the baths.\n\nIt is usual to divide Roman domestic pottery broadly into coarse wares and fine wares, the former being the everyday pottery jars, dishes and bowls that were used for cooking or the storage and transport of foods and other goods, and in some cases also as tableware, and which were often made and bought locally. Fine wares were serving vessels or tableware used for more formal dining, and are usually of more decorative and elegant appearance. Some of the most important of these were made at specialised pottery workshops, and were often traded over substantial distances, not only within, but also between, different provinces of the Roman Empire. For example, dozens of different types of British coarse and fine wares were produced locally, yet many other classes of pottery were also imported from elsewhere in the Empire. The manufacture of fine wares such as \" took place in large workshop complexes that were organised along industrial lines and produced highly standardised products that lend themselves well to precise and systematic classification.\n\nThere is no direct Roman equivalent to the artistically central vase-painting of ancient Greece, and few objects of outstanding artistic interest have survived, but there is a great deal of fine tableware, and very many small figures, often incorporated into oil lamps or similar objects, and often with religious or erotic themes. Roman burial customs varied over time and space, so vessels deposited as grave goods, the usual source of complete ancient pottery vessels, are not always abundant, though all Roman sites produce plenty of broken potsherds. \"Fine\" rather than luxury pottery is the main strength of Roman pottery, unlike Roman glass, which the elite often used alongside gold or silver tableware, and which could be extremely extravagant and expensive. It is clear from the quantities found that fine pottery was used very widely in both social and geographic terms. The more expensive pottery tended to use relief decoration, usually moulded, rather than colour, and often copied shapes and decoration from the more prestigious metalwork. Especially in the Eastern Empire, local traditions continued, hybridizing with Roman styles to varying extents. From the 3rd century the quality of fine pottery steadily declined, partly because of economic and political disturbances, and because glassware was replacing pottery for drinking cups (the rich had always preferred silver in any case).\n\nFired clay or terracotta was also widely employed in the Roman period for architectural purposes, as structural bricks and tiles, and occasionally as architectural decoration, and for the manufacture of small statuettes and lamps. These are not normally classified under the heading 'pottery' by archaeologists, but the terracottas and lamps will be included in this article. Pottery is a key material in the dating and interpretation of archaeological sites from the Neolithic period onwards, and has been minutely studied by archaeologists for generations. In the Roman period, ceramics were produced and used in enormous quantities, and the literature on the subject, in numerous languages, is very extensive.\n\nThe designation 'fine wares' is used by archaeologists for Roman pottery intended for serving food and drink at table, as opposed to pots designed for cooking and food preparation, storage, transport and other purposes. Although there were many types of fine pottery, for example, drinking vessels in very delicate and thin-walled wares, and pottery finished with vitreous lead glazes, the major class that comes first to mind is the Roman red-gloss ware of Italy and Gaul make, and widely traded, from the 1st century BC to the late 2nd century AD, and traditionally known as '. These vessels have fine, fairly hard and well-fired buff to pink fabrics, with a naturally glossy surface slip ranging in colour from light orange to quite a bright red. The variations in the colour and texture of both body fabric and slip, as well as the vessel-shapes and the designs on the decorated forms can enable a trained student to identify source, date and often individual workshop quite accurately. Arretine ware, made at Arezzo in Tuscany, was the pre-eminent type of fine pottery in the 1st century BC and early 1st century AD, and was succeeded by samian ware, manufactured in a number of centres in Gaul, modern France and Germany. However the definition of all these terms has varied and evolved over the many generations during which the material has been studied. Technically, red-gloss wares have much in common with earlier Greek painted pottery, but the decorated forms employ raised, relief decoration rather than painting.\n\nAfrican Red Slip (ARS) ware belonged to the same tradition, and continued to be made much later than Italian and Gaulish sigillata, right through to the Islamic conquest. ARS in turn influenced the production of Phocaean red slip, which is common in the Eastern Mediterranean and also appeared occasionally as far west as Southern France and Britain.\nThe production of related types of wares existed in Asia Minor and in other eastern regions of the Empire (Eastern Sigillata wares), while the Iberian provinces also had local industries producing terra sigillata hispanica, which had some similarities with the Gaulish products.\n\nMost of these wares were widely distributed and produced on an industrial scale (the largest kilns could fire up to 40,000 pieces at a time ), and undoubtedly using a high degree of specialisation within the workshops. The names of many potters and factory-owners are known from the potters' marks frequently applied to fine wares, and can be highly informative. Cnaius Ateius was an especially prominent producer at Arezzo, but wares with his stamps can be shown by modern analysis of their clay to have been produced in Pisa in Tuscany, and at branch factories at both Lyon and La Graufesenque in modern France. However, the interpretation of name-stamps can be more complex than it appears at first sight. Bold name-stamps visible in decorated areas advertise the name of the factory, but the names of individual artisans working within the pottery, the bowl-makers, appear on plain vessels, while the moulds for decorated bowls were also sometimes signed freehand by the mould-makers, and their signatures also sometimes appear on finished vessels. Theoretically, a decorated vessel might bear the mould-maker's name, that of the bowl-maker or finisher (for example, on the rim), and the 'brand-name' of the factory in the decoration. The use of slave labour in the Italian workshops is unproven, though some names are certainly of \" (freedmen, that is, freed former slaves). The site of La Graufesenque in South Gaul, near Millau, has been extensively studied and excavated. Its products had an immensely wide distribution in the later 1st century AD, and sherds have been found from India to the Sudan and Scotland. \nIn 1895, the German scholar Hans Dragendorff produced a classification of vessel shapes in Roman red gloss pottery that is still used (as e.g. \"Drag. 27\" or \"Dr.27\" to refer to the small biconvex-profiled cup). Other scholars added to his numbered forms, and some archaeologists working on the products of specific manufacturing sites, or the finds from important excavations, initiated their own typologies, so that there are now many other classification systems for Arretine and samian, as there are, indeed, for other classes of Roman pottery, such as the Hayes numbers for African Red Slip forms. Other numbering systems used with Italian and Gaulish sigillata include those of Déchelette, Knorr, Curle, Walters, Loeschcke, Ritterling and Ludowici, to name but a few.\n\nThe most common method of making relief decoration on the surface of an open ' vessel was to throw a pottery bowl whose interior profile corresponded with the desired form of the final vessel's exterior. The internal surface was then decorated using individual positive stamps ('), usually themselves made of fired clay, or small wheels bearing repeated motifs, such as the ovolo (egg-and-tongue) design that often formed the upper border of the decoration. Details could also be added by hand with a stylus. When the decoration was complete in intaglio on the interior, the mould was dried and fired in the usual way, and was subsequently used for shaping bowls. As the bowl dried, it shrank sufficiently to remove it from the mould, after which the finishing processes were carried out, such as the shaping or addition of a foot-ring and the finishing of the rim. The details varied according to the form. The completed bowl could then be slipped, dried again, and fired. Closed forms, such as jugs and jars, were seldom decorated in relief using moulds, though some vessels of this type were made at La Graufesenque by making the upper and lower parts of the vessel separately in moulds and joining them at the point of widest diameter. Relief-decoration of tall vases or jars was usually achieved by using moulded appliqué motifs (sprigs) and/or barbotine decoration (slip-trailing). The latter technique was particularly popular at the East Gaulish workshops of Rheinzabern, and was also widely used on other pottery types.\nPlain sigillata table vessels, which included large platters, shallow dishes in several sizes, slightly deeper bowls, and small cups, were made on the wheel using a range of templates to create very precise profiles. The sizes were also standardised, which would have facilitated the firing, storage and transport of the huge numbers that were made. The evolution in forms matches in many respects that seen in silver and glass table vessels of the same periods, and the precise forms can sometimes be closely dated. The forms archaeologically classified as 'plain' do sometimes bear decoration of a simple kind, often in the form of a ring of rouletting within the flat interior base of a dish. Plain wares also often bear name-stamps.\n\nARS (African Red Slip) ware was the most widely distributed representative of the sigillata tradition in the late-Roman period. (Occasional imports of ARS have been found as far afield as Britain in the 5th–6th centuries. It was manufactured in the province of (approximately modern Tunisia), and similar forms and fabrics were made for more local distribution in Egypt, which had its own very active and diverse ceramic traditions in the Roman period. A wide range of bowls, dishes and flagons were made in ARS, but the technique of making entire relief-decorated vessels in moulds was discontinued. Instead, appliqué motifs were frequently used where decoration in relief was required, separately made and applied to the vessel before drying and firing. Stamped motifs were also a favoured form of decoration, and in the later centuries, Christian subjects and symbols often appear.\n\nSome of the shapes of Arretine plain wares were quite closely copied in the later 1st century BC and early 1st century AD in a class of pottery made in north-east Gaul and known as Gallo-Belgic ware. Many of these plates and dishes in red-slipped (') and black-slipped (') fabrics bear potters' stamps. Other fine, thin-walled flagons, drinking beakers, bowls and dishes were made locally in most regions of the Roman Empire, including frontier provinces such as Britain: for example, Romano-British 'colour-coated' (slipped) wares made at Colchester and in the Nene Valley belong to that classification. Several of the pots to the right of the group photograph in the lead section of this article are Nene Valley wares, including the large black beaker decorated with a lively hunting scene of hounds and hares in the barbotine technique. Many decorative techniques were used to beautify pottery tableware, including the use of coloured slips, painting, and various textured surfaces. Painted decoration did not, however, continue the Greek and Etruscan traditions as a specialised technique used for elaborate luxury tablewares, though simpler painted designs do appear on many pottery types, both coarse and fine, throughout the Empire. The dividing lines between 'fine' and 'coarse' wares, or tablewares and cooking wares, become a little blurred in the case of some of the local, provincial products, because pottery is often multi-purpose. \nLead-glazed pottery was made in many regions of the Roman Empire, including Gaul, Italy and the eastern provinces. This type of vitreous glaze was most often used for small, decorative items of tableware, including mould-made cups with relief decoration, lamps and zoomorphic containers. The glazes vary in colour from amber to brown and many shades of green.\n\nTableware made of Egyptian faience, glazed in vivid blue, turquoise or green, continued to be manufactured in Egypt throughout the Roman period, and the shapes of some of these faience vessels in the 1st century BC and 1st century AD were directly influenced by Arretine ware. Very elaborate, decorated polychrome faience vessels were also produced. Egyptian faience, frit or 'glazed composition', as it is often termed by Egyptologists, has rather more in common technically with glass manufacture than with earthenware, since it is a non-clay ceramic material.\n\nThe dividing line between pottery vessels and terracotta figurines is another that is not always sharp, since certain types of small container, such as oil-pourers, were sometimes moulded in representational forms.\n\nPottery was essential for cooking food in antiquity. Although metal utensils made of bronze or iron were widely available in the Roman period, simple, functional earthenware bowls, pans, casseroles and jars were an inexpensive and standard part of the equipment of every kitchen. From Britain to Egypt, from Spain to Syria, over the length and breadth of a vast Empire, local pre-Roman pottery traditions in simple cooking wares often continued without major changes for centuries. Roman cooking pots therefore have to be studied on a regional basis. As well as the ordinary bowls and pans used for cooking, ceramic utensils were made for many specialised uses, such as the small cheese-press illustrated to the left of the group photograph of Roman pottery from Britain above. The two black jars to the left behind the cheese-press in the same photograph are examples of Romano-British black-burnished ware, first made in south-west England in the late Iron Age, before the Roman conquest: this ware continued to be popular throughout the Roman period, and was made in greater quantities, and marketed more widely, under Roman influence. Other wares made in Roman Britain were Crambeck Ware, Huntcliff ware, and Nene Valley Colour Coated Ware, which was often decorated.\n\nHowever, one vessel type used in food preparation was closely linked with the spread of Roman culture and Roman cuisine: the \". This was a robust shallow bowl with a thick, out-curved rim that made it easy to handle, often a pouring lip, and an internal surface deliberately roughened with a coating of grit or coarse sand during manufacture. It was used with a pestle to purée or pulverise ingredients in order to prepare elaborate and carefully seasoned Roman dishes; the Roman culinary tradition made extensive use of herbs and spices. The mortarium was the Roman equivalent of the food-processor, and is a real indicator of 'romanisation'; In Britain, the first mortaria were being imported from Gaulish sources more than a generation before Britain became a Roman province in AD 43, indicating the growing influence of Roman culture in late Iron Age southern Britain, and perhaps the actual presence of immigrants from Gaul. Later, locally-made mortaria produced at specialised potteries in different areas of the province were available throughout Britain, in addition to imported products: Paul Tyers discusses mortaria from no fewer than 16 different manufacturing sources, Romano-British and Continental, that have been found in Britain. Like so many other specialised Roman ceramic products, many mortaria also bore workshop or makers' stamps on their rims, and noting their chronology and distribution can help archaeologists understand trading patterns and the Roman economy.\n\nAmphorae, or amphoras, were used during Roman times to transport food on long and short distances. The content was generally liquid, olive oil or wine in most cases, but also \", the popular fish sauce, and fruit sauce. As a container, an amphora was supposed to be strong, not too heavy, shaped in a way suitable for easy storage in the ship, and, at the same time, convenient for handling once arrived to its final destination. Usually, amphorae are two-handled terracotta containers with a globular/cylindrical body, a rim of various shapes, and a spiked or, less commonly, flat base. The spike was suited for a stable storage arrangement in the ship and it worked as a third handle in the process of emptying the container.\n\nThe first systematic classification of amphorae types was undertaken by the German scholar Heinrich Dressel. Following the exceptional amphorae deposit uncovered in Rome in Castro Pretorio at the end of the 1800s, he collected almost 200 inscriptions from amphorae and included them in the \". In his studies of the amphorae deposit he was the first one to elaborate a classification of types, the so-called Dressel table, which is still used today for many types. Subsequent studies on Roman amphorae have produced more detailed classifications which are usually named after the scholar who studied them. For the neo-Phoenician types see the work by Maña published in 1951, and the revised classification by van der Werff in 1977–1978. The Gallic amphorae have been studied by Laubenheimer in a study published in 1989, whereas the Cretan amphorae have been analyzed by Marangou-Lerat. Beltràn studied the Spanish types in 1970. Adriatic types have been studied by Lamboglia in 1955. For a general analysis of the Western Mediterranean types see Panella, and Peacock and Williams.\n\nAmphorae were wheel-thrown terracotta containers. During the production process the body was made first and then let it partially dry. Then, coils of clay would be added to form the neck, the rim, and the handles. Once the amphora was completed, the interior was treated with resin in order to ensure a better performance in liquid storage. The reconstruction of these stages of production is based primarily on ethnographic data coming from the study of modern amphorae production in some areas of the eastern Mediterranean. Amphorae are often marked with a variety of stamps and graffiti. The function of these stamps are related to the entire life of the vessel. Stamps, graffiti and inscriptions provided information from the production cycle to the content and the commercialisation. A stamp was usually applied to the amphora at a partially dry stage and it often indicated the name of the ' (workshop) and/or the name of the owner of the workshop. Painted stamps, ', were executed when the amphora was completed and provided indications regarding the weight of the container and the content.\n\nThe first type of Roman amphora, Dressel 1, appears in central Italy in the late 2nd century BC. This type had thick walls and a characteristic red fabric. It was very heavy, though also strong. Around the middle of the 1st century BC the so-called Dressel 2–4 starts to become widely used. This type of amphora presented some advantages in being lighter and with thinner walls. It has been calculated that while a ship could accommodate approximately 4,500 Dressel 1, it was possible to fit 6,000 Dressel 2–4 in the same space. Dressel 2–4 were often produced in the same workshops used for the production of Dressel 1 which almost suddenly ceased to be used. At the same time in Cuma (southern Italy) the production of the \"\" type starts (Dressel 21–22). These containers were mainly used for the transportation of fruit and were used until the middle imperial times. At the same time, in central Italy, the so-called Spello amphorae, small containers, were produced for the transportation of wine. On the Adriatic coast the older types were replaced by the Lamboglia 2 type, a wine amphora commonly produced between the end of the 2nd and the 1st century BC. This type develops later into the Dressel 6A which becomes dominant during Augustan times.\n\nIn the Gallic provinces the first examples of Roman amphorae were local imitations of pre-existent types such as Dressel 1, Dressel 2–4, Pascual 1, and Haltern 70. The more typical Gallic production begins within the ceramic ateliers in Marseille during the late Augustan times. The type Oberaden 74 was produced to such an extent that it influenced the production of some Italic types. Spanish amphorae became particularly popular thanks to a flourishing production phase in the late Republican times. The ' and ' regions (south-western and eastern Spain) were the main production areas between the 2nd and the 1st century BC thanks to the land distribution to the veterans and the founding of new colonies. The Spanish amphorae were widely spread in the Mediterranean during the early imperial times. The most common types were all produced in the Baetica and among these there was the Dressel 20, typical olive oil container, the Dressel 7–13, for garum, and the Haltern 70, for the defrutum, fruit sauce. In the Tarraconensis region the Pascual 1 was the most common type, a wine amphora shaped onto the Dressel 1, and imitations of Dressel 2–4.\n\nNorth-African production was based on ancient tradition which could be traced back to the Phoenician colony of Carthage. Phoenician amphorae had characteristic small handles attached directly onto the upper body. This feature becomes the distinctive mark of late-Republican/early imperial productions which are then called neo-Phoenician. The types produced in Tripolitania and Northern Tunisia are the Maña C1 and C2, later renamed van Der Werff 1, 2, and 3. In the Aegean area the types from the island of Rhodes were quite popular starting from the 3rd century BC thanks to the local wine production which flourished for long time. This types developed into the \"Camulodunum\" 184, an amphora used for the transportation of the Rhodian wine all over the empire. Imitations of the Dressel 2–4 were produced in the island of Cos for the transportation of wine from the 4th BC until the middle imperial times. Cretan containers were also popular for the transportation of wine and can be found in the Mediterranean from the Augustan times until the 3rd century AD. During the late empire north-African types dominated the amphorae production. The so-called African I and II were widely used from the 2nd until the late 4th century AD. Other types from the eastern Mediterranean (Gaza), such as the so-called Late Roman 4, became very popular between the 4th and the 7th century AD, while Italic productions ceased to exist.\n\nArtificial lighting was commonplace in the Roman world. Candles, made from beeswax or tallow, were undoubtedly the cheapest means of lighting, but candles seldom survive archaeologically. Lamps fueled with olive oil and other vegetable oils survive in great numbers, however, and have been studied in minute detail. Some Roman lamps were made of metal, and could be of highly elaborate forms incorporating statuettes and multiple nozzles, but fired clay was the most usual material, and the majority of small, probably inexpensive, clay lamps had a single nozzle for one wick, and therefore one flame.\n\nMost of these clay lamps were shaped using moulds in workshops that turned out large numbers of standardised products. Some of the most popular forms incorporated a central ', a circular area usually around 4–6 cm. in diameter, that incorporated the filling-hole and could be ornamented with pictorial motifs in low relief. The range of decoration included pagan deities, myths and legends, genre scenes from everyday life, animals, hunting, public entertainments such as gladiatorial combat and chariot-racing, erotic encounters, and in late-Roman times, some Christian symbolism: in short, the full range of subjects that occur in the Roman decorative arts (Jewish lamps with symbols such as the menorah are also found). Types and decoration initiated at the centre of Empire, in Italy, were often imitated in products made in workshops located in other provinces. Lamps could be directly copied by the process known as ', using an existing lamp as the archetype for producing the mould, rather than creating a hand-modelled clay archetype.\n\nThe highly organised manufacturing methods, usually using plaster (gypsum) moulds, the volume of production, and the trading and wide distribution all echo in some respects the production of red-gloss wares such as Arretine and samian, as does the existence of name-stamps on some of the lamps. Makers' or workshop names were normally placed on the underside of the lamp, and are common on the usually undecorated lamps known as ' ('factory lamps'), a type which was popular in the military zones of the north-west Roman provinces during the 2nd century AD. One well-known name is that of \"Fortis\", and his products were evidently copied outside his own workshop in Italy – or perhaps Fortis had his own branch factories in the provinces. The Gaulish ' in the adjacent picture, found in London, is stamped on the base with the name of the maker Atimetus.\n\nIn addition to the many basic lamp-shapes, which consisted of a rounded or ovoid body, with one or more projecting nozzles, and sometimes a handle, terracotta lamps were also made in a variety of much more fanciful forms, moulded to represent animals, grotesque heads, feet and many other shapes. These are known traditionally as \"plastic lamps\" ('plastic' meaning 'modelled or moulded').\n\nThe close dating and distribution information that can be obtained from the detailed study of forms, makers' marks and decoration makes Roman lamps important and useful finds on archaeological sites. They are not found in quite as great profusion on Roman sites in Britain as on sites elsewhere in the Empire, including Gaul, quite possibly because imported olive oil would probably have been more expensive in Britannia.\n\nItalian styles exerted much less influence across the Empire in terracotta figurines or statuettes than in pottery vessels; here the longstanding traditions of Greek terracotta figurines, and those of Egypt and other Eastern provinces of the Empire, were the dominant influences. In some northern provinces, such as Gaul and Germany, there was no native Iron Age tradition of making terracotta figurines, but new industries developed under Roman influence manufacturing mould-made figures in fine white pipeclay. Like bronze statuettes, which would have been more expensive items, small terracotta figures were generally made for ritual or religious purposes, such as dedication at temples, display in household shrines, or as grave-goods to be deposited with the dead. However, some terracottas were also used as toys by children, even if they were not manufactured for that specific purpose. Most of the small terracotta figurines were mould-made objects manufactured in quite large numbers, and most would have been painted in bright colours when new. These pigments, applied after firing, rarely survive burial except in small and faded patches.\nEach region of the Empire produced terracottas in distinctive local styles, but all had rather similar ranges of subjects, above all the standard religious themes of gods, goddesses and their attributes; representations of birds and animals may often be linked with specific deities, though some animal figures may well have been made without any religious or ritual purpose. The religious subjects often include local traditions and cults: for example, the Romano-Egyptian repertoire of terracottas includes Egyptian deities, such as Harpocrates, the Graeco-Roman form of Horus, while Celtic gods appear amongst those made in the Central Gaulish industries, centred in the Allier Valley and the Rhineland industry at Cologne.\n\nA Celtic mother-goddess nursing one, or sometimes two, infants, is one of the most popular Central Gaulish types, though Venus was also very frequently represented in Gaul. The mother-goddess figurines are shown seated in high-backed basketwork chairs that seem to have been typical of Gaul and Britain. Figurines from the Allier Valley and Cologne sources sometimes bear the signatures of modellers and/or mouldmakers. As in the case of the Gaulish samian industries, the makers' names and the styles and themes all illustrate the fusion of local and Mediterranean traditions.\n\nTwo manufactured materials were of great importance in Roman architecture: concrete and fired clay in the form of structural bricks and tiles, and to a lesser extent, in architectural decoration. These materials were used in buildings all over the Roman Empire, and in many areas, they fell out of use again after the Roman period, only to be rediscovered centuries later. Like other mass-produced Roman ceramic objects, bricks and tiles were often marked with inscriptions that indicate their manufacturer, or the organisation or authority, military or civilian, for which they had been made.\n\nThe Roman bricks used for building walls are often referred to as 'tiles', because they are rather thin, flat squares, made in standard sizes, often related to the Roman foot ( ), from around 20 cm to about 58 cm square, and about 5–7 cm thick. Even stone-built walls frequently incorporated horizontal tile-courses. Brick-built walls were finished with various types of facing, rendering or plastering on both exterior and interior surfaces, so that the bricks themselves were not visible.\n\nTiles used for roofing were intended to be seen, however. Roof-tiles were of distinctive shapes, the ' (pl. '), which was a large, thin tile, almost square, with upturned flanges on its longer sides, and the ' (pl. '), of slightly tapered half-cylindrical form. The imbrices, interlocking because of their tapered form, were laid over the raised flanges of the tegulae, and together formed the characteristic ridged tiled roof still to be seen in Italy and southern France today. The pitch of such a roof has to be fairly low, not more than about 30 degrees. The roof was finished with a series of plain ridge-tiles, and often with decorative finials, which could also be of terracotta, at the gable.\n\nSome buildings also featured \"antefixes\", vertical ornaments of triangular or rounded shape that were placed along the edge of the roof. They, too, were often made of terracotta, and could be decorated with pictorial motifs intended to avert ill-luck, or with inscriptions: those made in military tileries attached to legionary forts bore the number and symbol of the relevant legion. \nRoman hypocaust heating systems made extensive use of fired clay elements: The space beneath the floor of a room to be heated was supported on robust pillars (\"pilae\"), usually made of small, square bricks mortared together, so that the heat from the adjacent furnace could circulate freely. In public and private bath-houses (essential to the Roman way of life), heat was also carried up through the walls in flues made of interlocking box-tiles. Though these were covered up by wall facings both inside and out, they were sometimes manufactured with quite elaborate geometric and even figural decoration. Pipes for water and drainage were also often made of fired clay.\n\nCeramic tiles were not normally used for flooring in Roman buildings, though ', a favoured flooring material, was composed of concrete and crushed tile, and carefully cut small squares from tiles were often used in mosaic floors, ' about 2–3 cm. square being used for plain borders, and smaller squares, about 1 cm., where a red colour was required in a pictorial mosaic with multi-coloured geometric or figural designs.\n\nThe edge of a roof might be embellished with plaques called antefixes, as mentioned above, and some pottery relief \"revetment\" panels with figurative scenes for setting into walls emulate the marble friezes of grand temples. These are still often called \"Campana reliefs\", after Giampietro Campana, the 19th-century Italian scholar and collector who first studied them. They were developed from about 50 BC and were used almost entirely in Italy between Tuscany and Campania – areas once in the ambit of the Etruscan culture of which they seem a continuation. Initially used on small temples, they are later found on a wide range of public and private buildings. Usually between 22 and 50 cm high and 27 to 48 cm wide, plaques were perhaps typically arranged in bands or friezes. Subjects are usually drawn from mythology. They cease to be found after the middle of the 2nd century; they had to compete with moulded stucco as well as wall-paintings.\n\nIn archaeology, bricks and tiles, especially when encountered only in fragmentary form, are often classified under the generic term ceramic building material or CBM.\n\n\n\n"}
{"id": "56506756", "url": "https://en.wikipedia.org/wiki?curid=56506756", "title": "Angle deception jamming", "text": "Angle deception jamming\n\nAngle deception jamming is an electronic warfare technique used against conical scanning radar systems. It generates a false signal that fools the radar into believing the target is to one side of the boresight, causing the radar to \"walk away\" from the target and break its radar lock-on. It is also known as angle walk-off, angle stealing, or inverse con-scan.\n\nAngle stealing was one of the earliest jamming techniques to be used operationally, with systems employed against the German Würzburg radars near the end of World War II. The technique is not useful against monopulse radars, and is one of the main reasons those radars became popular in the post-war era.\n\nAngle stealing belongs to the wider class of \"deceptive jamming\" techniques, which attempt to deceive radars based on knowledge of their operating procedures, rather than simply trying to blind them with noise. Another popular deception technique that was used against early radars is range gate pull-off.\n\nA typical radar produces a beam that is several degrees wide. The pattern is non-linear; the antenna is most sensitive at the center of the beam, also known as the \"boresight\" or \"centroid\", and its sensitivity drops off at greater angles. This pattern is typically represented by measuring the angle where it has one-half the sensitivity as it does on the boresight. This is known as the half power point.\n\nThis means that a target in a radar beam will return a signal when the antenna is anywhere within a few degrees of the boresight. The pattern is too wide to allow the radar to directly guide weapons, especially anti-aircraft artillery which need accuracy on the order of 0.1 degrees. However, it is possible to use the non-linear pattern to improve the angle measurement using a system known as conical scanning.\n\nThe basic idea of conical scanning is to offset the antenna slightly to one side of the boresight and in front of a parabolic reflector. This causes the beam to be deflected slightly to the opposite side of the boresight. The antenna is then spun so that it rotates (or \"nutates\") around the boresight axis (pointing in the direction of the target). As it rotates, the beam traces out a cone, with its tip at the antenna and its long axis aligned with the boresight. A target that is centred in the boresight will always return some signal to the radar, creating a strong, constant signal. If it is located to one side, the signal will rise and fall as the most sensitive region of the pattern rotates across it.\n\nTo use this for automatic tracking, or radar lock-on, a simple circuit is added. First, the signal is sent into a smoother that extracts the amplitude modulated signal of the series of radar pulses that were returned as it swept across the target. This will produce a flat line if the target is centred, or some form of sine wave otherwise. This is then mixed with a second control signal that has a fixed relationship to the spinning of the antenna. For instance, in the case of the Würzburg the antenna spun at 25 Hz, so this fixed signal was also 25 Hz. Sending these two signals into a phase detector produces a varying output that can be used to drive the antenna pointing motors. This output is known as the \"error signal\", and drops to zero when the antenna is pointing directly at the target.\n\nAn angle stealer is a transponder turned to the radar's operational frequency that also has some knowledge about the timing of the target radar's scanning rate. The rate can be determined by examining the signal as it is received, or by being pre-set based on some basic knowledge of the radar system.\n\nThe idea is to add additional signal from the transponder to the signal naturally reflected off the target, such that the addition of those two signals no longer produces the proper output from the smoother. The radar's electronics interpret this as the antenna being misaligned, and it begins to move away from the target. Over time, this can cause the radar to \"walk-off\" the target entirely.\n\nThere are two primary methods for causing this to occur:\n\nTransponders are relatively simple radios that receive a signal, amplify it, and send it back out. Examples were in use for identification friend or foe from the start of World War II. However, these early models had the problem that they often over-amplified the signal, causing interference with other radars. This was addressed in the IFF Mark II with the addition of an automatic gain control system, which amplified the received signal to a pre-set level.\n\nInverse gain modulation, also known as inverse amplitude modulation, is a simple modification to this sort of transponder. It adds a smoother circuit like the one in the radar receiver, which creates an amplitude modulated signal output. This output is then inverted and sent into the gain control. The result is an output signal that is strong when the radar signal is weak, and weak when it is strong.\n\nDepending on the exact strength of the signals, when this mixes with the radar's own signal at the radar receiver, the result is either a nearly flat smoothed curve, or one that is the inverse of the radar's curve. The resulting error signal quickly drives the radar away from the target. A carefully matched signal that is an exact invert of the original will cause the radar to believe it is aimed at the target no matter where it is pointed.\n\nThe inverse gain technique was so effective against early tracking radars that these radars began using a system known as CORSO, conical-on-receive-signal-only. CORSO typically used two antennas, a transmitter with a fixed antenna, and a conically scanning receiver. The lock-on technique works the same as in a normal conical scan radar, but the transmitted signal is constant and denies the transponder information about the scanning rate of the radar. For this reason, this concept is also known as \"silent lobing\".\n\nThis led to the introduction of the swept square wave (SSW) technique, also known as scan rate modulation. This is generally similar to the inverse gain method, but does not know the scanning rate. Instead, the system sends out pulses on the radar's frequency at a pulse repetition frequency that is similar to the estimated scanning rate of the radar. These pulses will only be received by the radar if the receiver is pointed roughly in the aircraft's direction. To ensure this will occur at some point, the repetition frequency is slowly increased and decreased so that at some point in this pattern it briefly synchronizes with the scan rate of the antenna.\n\nWhen that occurs, the radar now receives its own signal as well as a second one that is slightly offset in time. When fed into the phase detector, the output signal will no longer be a single pulse, but two, creating an error signal. Because the signal is being swept in repetition frequency, this second part of the signal moves in relation to the radar's own signal. When the two are closely synchronized it generates large error signals that can quickly drive the antenna away from the target. However, because the rate is constantly changing, after a period the error will drop to zero again, potentially before the radar has moved completely off the target.\n\nThe system is not as effective as inverse gain, which interrupts the tracking process once every scan compared to the once-every-so-often for SSW, but it provides some protection against any conical scanning or CORSO radar.\n"}
{"id": "2691925", "url": "https://en.wikipedia.org/wiki?curid=2691925", "title": "Arthur Munby", "text": "Arthur Munby\n\nArthur Joseph Munby (19 August 1828 – 29 January 1910) was a British diarist, poet, portrait photographer, barrister and solicitor. He is also known by his initials, A. J. Munby.\n\nArthur Munby was born in York. He was educated at Trinity College, Cambridge, graduating with a BA in 1851, and was called to the Bar from Lincoln's Inn in 1855. He worked as a civil servant in the Ecclesiastical Commissioners' office from 1858 until his retirement in 1888. His published poetry included \"Benoni\" (1852) and \"Verses New and Old\" (1865). He taught Latin at the Working Men's College for more than a decade and helped promote the Working Men's College Volunteer Corps, a response to the national call for Volunteer Rifle Corps (1859) to combat a perceived threat from Napoleon the Third. Munby penned verses of support, the \"Invicta: a Song of 1860\", for the 19th Middlesex Regiment, a regiment to which the W.M.C.V.C. was attached. In 1864, a sister Working Women's College was established; Munby was a leading spirit of, and teacher at, the new college.\n\nMunby had a lifelong fascination with working-class women, particularly those who did hard physical labour. His favourite pastime was wandering the streets of London and other industrial cities where he approached working women to ask about their lives and the details of their work, while noting their clothes and dialects. The observations were recorded in his journals.\n\nHe was an amateur artist, and his diaries contain sketches of working women. He collected hundreds of photographs of women who worked at collieries, kitchen maids, milkmaids, charwomen, acrobats and so on. His diaries and images provide historical information on the lives of working-class Victorian women. Much of his obsession is hinted at in his last book, \"Faithful Servants: being epitaphs and obituaries recording their names and services\" (1891).\n\nHis papers are housed at Trinity College, Cambridge, there is a list of his papers on the Cambridge Janus website\n\nIn 1854, while on one of his urban wanderings, Munby met Hannah Cullwick, a Shropshire-born maid-of-all-work. They formed a relationship in which Munby was the master and Cullwick the slave, with him training her in the virtues of hard work and loyalty. His scenarios included elements of ageplay and infantilism, with Cullwick holding him in her lap or carrying him.\n\nThey married secretly in 1873 but Cullwick resisted his efforts to make her into a lady and she lived with him as a domestic servant, not a wife. She played the role of a lady wife on trips to Europe. They separated in 1877, but continued to see each other until Cullwick's death in 1909. The marriage was secret from all but a few close friends; he revealed it to his brother only a few months before his own death from pneumonia.\n\n"}
{"id": "51404222", "url": "https://en.wikipedia.org/wiki?curid=51404222", "title": "Artisto", "text": "Artisto\n\nArtisto is a video processing application with art and movie effects filters based on neural network algorithms created in 2016 by Mail.ru Group machine learning specialists.\n\nAt the moment the application can process videos up to 10 seconds long and offers users 21 filters, including those based on the works of famous artists (e.g. Blue Dream — Pablo Picasso), theme-based (Rio-2016 — related to the 2016 Summer Olympics in Rio de Janeiro) and others. The app works with both pre-recorded videos and videos recorded with the application.\n\nInformation on the application first appeared on Mail.ru Group Vice President Anna Artamonova's FB page on July 29, 2016. At the moment of posting there was only an Android version available. According to Anna, the application's first version only took eight days to develop. On July 31 the application was added to the AppStore for free download.\n\nFrom this moment and continuing on into the present, Artisto has been the world’s first app that uses neural networks for editing short videos, processing them in the style of famous artworks or any other source image. Prisma (app) application developers promise to deliver similar functionality at any moment.\n\nThe application soon won recognition and started to attract the attention of both international brands (e.g. Korean auto manufacturer Kia Motors) and popular singers and musicians.\n\nAccording to the independent App Annie analysis system, within the first two weeks on the market the application made it onto TOP download lists in nine countries.\n\nThe idea of transferring styles from the works by famous artists to images was first mentioned in September 2015 after the publication of Leon Gatys's article \"A Neural Algorithm of Artistic Style\", where he described the algorithm in detail. The major shortcoming of this algorithm is its slow performance, which is up to dozens of seconds depending on the algorithm's settings.\n\nIn March 2016, Russian researcher Dmitry Ulyanov's article was published, where he invented a way to improve the generation of stylized pictures using additional neuron generator network training. With this approach, stylized images can be generated within just dozens of milliseconds. Seventeen days after Ulyanov's article, Justin Johnson published an article containing an identical idea, the only difference being the structure of the generator network.\n\nThe Artisto application was developed using these open-source technologies, which Mail.ru Group's machine learning specialists improved for faster video processing and better quality.\n"}
{"id": "21189305", "url": "https://en.wikipedia.org/wiki?curid=21189305", "title": "Audio engineer", "text": "Audio engineer\n\nAn audio engineer (also sometimes recording engineer) helps to produce a recording or a live performance, balancing and adjusting sound sources using equalization and audio effects, mixing, reproduction, and reinforcement of sound. Audio engineers work on the \"...technical aspect of recording—the placing of microphones, pre-amp knobs, the setting of levels. The physical recording of any project is done by an engineer ... the nuts and bolts.\" It's a creative hobby and profession where musical instruments and technology are used to produce sound for film, radio, television, music, and video games. Audio engineers also set up, sound check and do live sound mixing using a mixing console and a sound reinforcement system for music concerts, theatre, sports games and corporate events.\n\nAlternatively, audio engineer can refer to a scientist or professional engineer who holds an engineering degree and who designs, develops and builds audio or musical technology working under terms such as acoustical engineering, electronic/electrical engineering or (musical) signal processing.\n\nResearch and development audio engineers invent new technologies, equipment and techniques, to enhance the process and art of audio engineering. They might design acoustical simulations of rooms, shape algorithms for audio signal processing, specify the requirements for public address systems, carry out research on audible sound for video game console manufacturers, and other advanced fields of audio engineering. They might also be referred to as acoustic engineers.\n\nAudio engineers working in research and development may come from backgrounds such as acoustics, computer science, broadcast engineering, physics, acoustical engineering, electrical engineering and electronics. Audio engineering courses at university or college fall into two rough categories: (i) training in the creative use of audio as a sound engineer, and (ii) training in science or engineering topics, which then allows students to apply these concepts while pursuing a career developing audio technologies. Audio training courses give you a good knowledge of technologies and their application to recording studio and sound reinforcement systems, but do not have sufficient mathematical and scientific content to allow you to get a job in research and development in the audio and acoustic industry.\n\nAudio engineers in research and development usually possess a bachelor's degree, master's degree or higher qualification in acoustics, physics, computer science or another engineering discipline. They might work in acoustic consultancy, specializing in architectural acoustics. Alternatively they might work in audio companies (e.g. headphone manufacturer), or other industries that need audio expertise (e.g., automobile manufacturer), or carry out research in a university. Some positions, such as faculty (academic staff) require a Doctor of Philosophy. In Germany a \"Toningenieur\" is an audio engineer who designs, builds and repairs audio systems.\n\nThe listed subdisciplines are based on PACS (Physics and Astronomy Classification Scheme) coding used by the Acoustical Society of America with some revision.\n\nAudio engineers develop audio signal processing algorithms to allow the electronic manipulation of audio signals. These can be processed at the heart of much audio production such as reverberation, Auto-Tune or perceptual coding (e.g. mp3 or Opus). Alternatively, the algorithms might carry out echo cancellation on Skype, or identify and categorize audio tracks through Music Information Retrieval (e.g., Shazam).\n\nArchitectural acoustics is the science and engineering of achieving a good sound within a room. For audio engineers, architectural acoustics can be about achieving good speech intelligibility in a stadium or enhancing the quality of music in a theatre. Architectural Acoustic design is usually done by acoustic consultants.\n\nElectroacoustics is concerned with the design of headphones, microphones, loudspeakers, sound reproduction systems and recording technologies. Examples of electroacoustic design include portable electronic devices (e.g. mobile phones, portable media players, and tablet computers), sound systems in architectural acoustics, surround sound and wave field synthesis in movie theater and vehicle audio.\n\nMusical acoustics is concerned with researching and describing the science of music. In audio engineering, this includes the design of electronic instruments such as synthesizers; the human voice (the physics and neurophysiology of singing); physical modeling of musical instruments; room acoustics of concert venues; music information retrieval; music therapy, and the perception and cognition of music.\n\nPsychoacoustics is the scientific study of how humans respond to what they hear. At the heart of audio engineering are listeners who are the final arbitrator as to whether an audio design is successful, such as whether a binaural recording sounds immersive.\n\nThe production, computer processing and perception of speech is an important part of audio engineering. Ensuring speech is transmitted intelligibly, efficiently and with high quality; in rooms, through public address systems and through mobile telephone systems are important areas of study.\n\nA variety of terms are used to describe audio engineers who install or operate sound recording, sound reinforcement, or sound broadcasting equipment, including large and small format consoles. Terms such as \"audio technician,\" \"sound technician,\" \"audio engineer,\" \"audio technologist,\" \"recording engineer,\" \"sound mixer\" and \"sound engineer\" can be ambiguous; depending on the context they may be synonymous, or they may refer to different roles in audio production. Such terms can refer to a person working in sound and music production; for instance, a \"sound engineer\" or \"recording engineer\" is commonly listed in the credits of commercial music recordings (as well as in other productions that include sound, such as movies). These titles can also refer to technicians who maintain professional audio equipment. Certain jurisdictions specifically prohibit the use of the title engineer to any individual not a registered member of a professional engineering licensing body.\n\nIn German, the \"Tontechniker\" (audio technician) is the one who operates the audio equipment and the \"Tonmeister\" (sound master) is a person who creates recordings or broadcasts of music, who is both deeply musically trained (in classical and non-classical genres), and who also has a detailed theoretical and practical knowledge of virtually all aspects of sound.\n\nAudio engineers come from backgrounds or postsecondary training in fields such as audio, fine arts, broadcasting, music, or electrical engineering. Training in audio engineering and sound recording is offered by colleges and universities. Some audio engineers are autodidacts with no formal training, but who have attained professional skills in audio through extensive on-the-job experience.\n\nAudio engineers must have extensive knowledge of audio engineering principles and techniques. For instance, they must understand how audio signals travel, which equipment to use and when, how to mic different instruments and amplifiers, which microphones to use and how to position them to get the best quality recordings. In addition to technical knowledge, an audio engineer must have the ability to problem solve quickly. The best audio engineers also have a high degree of creativity that allow them to stand out amongst their peers. In the music realm, an audio engineer must also understand the types of sounds and tones that are expected in musical ensembles across different genres - rock and pop music for example. This knowledge of musical style is typically learned from years of experience listening to and mixing music in recording or live sound contexts. For education and training, there are audio engineering schools all over the world. In North America, the most notable being Full Sail University in Winter Park, Florida, United States, and OIART (The Ontario Institute of Audio Recording Technology) in London, Canada.\n\nIn the recording studio environment, a sound engineer records, edits, manipulates, mixes, or masters sound by technical means to realize the creative vision of the artist and record producer. While usually associated with music production, an audio engineer deals with sound for a wide range of applications, including post-production for video and film, live sound reinforcement, advertising, multimedia, and broadcasting. In larger productions, an audio engineer is responsible for the technical aspects of a sound recording or other audio production, and works together with a record producer or director, although the engineer's role may also be integrated with that of the producer. In smaller productions and studios the sound engineer and producer are often the same person.\n\nIn typical sound reinforcement applications, audio engineers often assume the role of producer, making artistic and technical decisions, and sometimes even scheduling and budget decisions.\n\nAccording to Women's Audio Mission (WAM), a nonprofit organization based in San Francisco dedicated to the advancement of women in music production and the recording arts, less than 5% of the people creating sound and media are women. \"Only three women have ever been nominated for best producer at the Brits or the Grammys\" and none won either award. \"Women who want to enter the [producing] field face a boys' club, or a guild mentality\". The UK \"Music Producers' Guild says less than 4% of its members are women\" and at the Liverpool Institute of Performing Arts, \"...only 6% of the students enrolled on its sound technology course are female.\"\n\nWomen's Audio Mission was started in 2003 to address the lack of women in professional audio by training over 6,000 women and girls in the recording arts and is the only professional recording studio built and run by women. Notable recording projects include the Grammy Award-winning Kronos Quartet, Angelique Kidjo (2014 Grammy winner), author Salman Rushdie, the Academy Award-nominated soundtrack to “Dirty Wars”, Van-Ahn Vo (NPR’s top 50 albums of 2013), Grammy-nominated St. Lawrence Quartet, and world music artists Tanya Tagaq and Wu Man.\n\nOne of the first women to produce, engineer, arrange and promote music on her own rock and roll music label was Cordell Jackson (1923-2004). Trina Shoemaker is a mixer, record producer and sound engineer who became the first woman to win the Grammy Award for Best Engineered Album in 1998 for her work on \"The Globe Sessions\".\n\nGail Davies was the '...first female producer in country music, delivering a string of Top 10 hits in the '70s and '80s including \"Someone Is Looking for Someone Like You,\" \"Blue Heartache\" and \"I'll Be There (If You Ever Want Me).\" When she moved to Nashville in 1976, men \"...didn't want to work for a woman\" and she was told women in the city were \"...still barefoot, pregnant and [singing] in the vocal booth.\" \n\nWendy Waldman, who became a producer after Davies, saw that Davies had a difficult time. When Jonell Polansky arrived in Nashville in 1994, with a degree in electrical engineering and recording experience in the Bay Area, she was told \"...[y]ou're a woman, and we already had one\"–a reference to Waldman. \nKK Proffitt, who is a studio \"owner and chief engineer\" states that men in Nashville do not want to have women in the recording booth. At a meeting of the Audio Engineering Society, Proffitt was told to \"shut up\" by a male producer when she raised the issue of updating studio recording technologies. Proffitt said she finds \"...finds sexism rampant in the industry\".\n\nOther notable women include:\n\nThere are four distinct steps to commercial production of a recording: recording, editing, mixing, and mastering. Typically, each is performed by a sound engineer who specializes only in that part of production.\n\nAn audio engineer is proficient with different types of recording media, such as analog tape, digital multi-track recorders and workstations, and computer knowledge. With the advent of the digital age, it is increasingly important for the audio engineer to understand software and hardware integration, from synchronization to analog to digital transfers. In their daily work, audio engineers use many tools, including:\n\n\n\n\n\n\n"}
{"id": "1624450", "url": "https://en.wikipedia.org/wiki?curid=1624450", "title": "Betterton–Kroll process", "text": "Betterton–Kroll process\n\nThe Betterton–Kroll process is an industrial process for removing bismuth from lead. The process was developed by William Justin Kroll and patented in 1922. Further improvements were developed by Jesse Oatman Betterton in the 1930s.\n\nCalcium and magnesium are added to a molten lead-bismuth bath. The resulting bismuth compounds have higher melting points and lower densities than the lead, and can be removed as dross. The compounds are treated with chlorine to free up the bismuth. Temperature used in the process is about 380–500 °C(572–932 °F) . The other major processes for separating the two metals are by fractional crystallization and by the Betts electrolytic process.\n\n"}
{"id": "1498921", "url": "https://en.wikipedia.org/wiki?curid=1498921", "title": "Blitzen (computer)", "text": "Blitzen (computer)\n\nThe Blitzen was a miniaturized SIMD (single instruction, multiple data) computer system designed for NASA in the late 1980s by a team of researchers at Duke University, North Carolina State University and the Microelectronics Center of North Carolina. The Blitzen was composed of a control unit and a set of simple processors connected in a grid topology. The machine influenced, to some extent, the design of the MasPar MP-1 computer.\n\nApplications of the Blitzen machine include high-speed image processing, where each processor operates on a pixel of the input image and communicates with its grid neighbours to apply image processing filters on the image.\n"}
{"id": "7669294", "url": "https://en.wikipedia.org/wiki?curid=7669294", "title": "Casio fx-3900Pv", "text": "Casio fx-3900Pv\n\nThe Casio fx-3900Pv is a programmable scientific calculator with 300 steps. Introduced in 1992, its production has since stopped with the introduction of fx-3650P and fx-3950P.\n\n"}
{"id": "17922530", "url": "https://en.wikipedia.org/wiki?curid=17922530", "title": "Centrepiece", "text": "Centrepiece\n\nA centrepiece is an important item of a display, usually of a table setting. Centrepieces help set the theme of the decorations and bring extra decorations to the room. A centrepiece also refers to any central or important object in a collection of items.\n\nOn the table, a centrepiece is a central object which serves a decorative purpose. However, centrepieces are often not too large, to avoid difficulty with visibility around the table and to allow for the easier serving of dishes. \n\nOther centrepieces are often made from flowers, candles, fruit, or candy.\n\nCentrepieces are a major part of the decoration for a wedding reception, being used widely at wedding receptions with flowers being the most popular form of centrepieces. Weddings, baby showers, engagement parties, anniversary parties and birthdays often have some form of centrepiece.\n\nFormal functions in Europe can sometimes have very elaborate centrepieces, which can span the entire length of the table.\n\nAt holiday times, including Valentine's Day, Easter, Halloween, Thanksgiving, and Christmas, homes are often decorated with holiday centrepieces.\n\nIn September 2017, Lipscomb University President Randy Lowry had to apologize after he invited African-American student to a dinner with \"stalks of cotton\" (a symbol of slavery in the United States) as centerpieces.\n"}
{"id": "14718510", "url": "https://en.wikipedia.org/wiki?curid=14718510", "title": "Communication Linking Protocol", "text": "Communication Linking Protocol\n\nCommunication Linking Protocol (CLP) is a communications protocol used to communicate with many devices using the Motorola ReFLEX network. CLP allows a user to direct a ReFlex capable device to send or receive messages. CLP is used by Advantra's ReFLEX devices. Advantra's ReFLEX product line was purchased by Inilex who now manufactures the devices.\n\n"}
{"id": "288212", "url": "https://en.wikipedia.org/wiki?curid=288212", "title": "Component video", "text": "Component video\n\nComponent video is a video signal that has been split into two or more component channels. In popular use, it refers to a type of component analog video (CAV) information that is transmitted or stored as three separate signals. Component video can be contrasted with \"composite video\" (NTSC, PAL or SECAM) in which all the video information is combined into a single line level signal that is used in analog television. Like composite, component-video cables do not carry audio and are often paired with audio cables.\n\nWhen used without any other qualifications the term \"component video\" usually refers to analog component video with sync on luma.\n\nReproducing a video signal on a display device (for example, a cathode ray tube (CRT)) is a straightforward process complicated by the multitude of signal sources. DVD, VHS, computers and video game consoles all store, process and transmit video signals using different methods, and often each will provide more than one signal option. One way of maintaining signal clarity is by separating the components of a video signal so that they do not interfere with each other. A signal separated in this way is called \"component video\". S-Video, RGB and signals comprise two or more separate signals, and thus are all component-video signals. For most consumer-level video applications, the common three-cable system using BNC or RCA connectors analog component video was used. Typical resolutions (in lines) are 480i (DVD) and 576i (US and Japan broadcast analog TV). For personal computer displays the 15 pin DIN connector (IBM VGA) provided screen resolutions including 640x480, 800x600, 1024x768, 1152x864, 1280x1024 and much larger.\nThe various RGB (red, green, blue) analog component video standards (e.g., RGBS, RGBHV, RGsB) use no compression and impose no real limit on color depth or resolution, but require large bandwidth to carry the signal and contain a lot of redundant data since each channel typically includes much of the same black-and-white image. At one time computers offered this signal via a VGA port. Many televisions, especially in Europe, utilize RGB via the SCART connector. All arcade games, other than early vector and black-and-white games, use RGB monitors.\n\nIn addition to the red, green and blue color signals, RGB requires two additional signals to synchronize the video display. Several methods are used: \n\nComposite sync is common in the European SCART connection scheme (using pins 17 [ground] and 19 [composite-out] or 20 [composite-in]). RGBS requires four wires – red, green, blue and sync. If separate cables are used, the sync cable is usually colored yellow (as is the standard for composite video) or white.\n\nSeparate sync is most common with VGA, used worldwide for analog computer monitors. This is sometimes known as RGBHV, as the horizontal and vertical synchronization pulses are sent in separate channels. This mode requires five conductors. If separate cables are used, the sync lines are usually yellow (H) and white (V), yellow (H) and black (V), or gray (H) and black (V).\n\nSync on Green (SoG) is less common, and while some VGA monitors support it, most do not. Sony is a big proponent of SoG, and most of their monitors (and their PlayStation line of video game consoles) use it. Like devices that use composite video or S-video, SoG devices require additional circuitry to remove the sync signal from the green line. A monitor that is not equipped to handle SoG will display an image with an extreme green tint, if any image at all, when given a SoG input.\n\nSync on red and sync on blue are even rarer than sync on green, and are typically used only in certain specialized equipment.\n\nSync on composite, not to be confused with composite sync, is commonly used on devices that output both composite video and RGB over SCART. The RGB signal is used for color information, while the composite video signal is only used to extract the sync information. This is generally an inferior sync method, as this often causes checkerboards to appear on an image, but the image quality is still much sharper than standalone composite video.\n\nSync on luma is much similar to sync on composite, but uses the Y signal from S-Video instead of a composite video signal. This is sometimes used on SCART, since both composite video and S-Video luma ride along the same pins. This generally does not suffer from the same checkerboard issue as sync on composite, and is generally acceptable on devices that do not feature composite sync, such as the Sony PlayStation and some modded Nintendo 64 models.\n\nFurther types of component analog video signals do not use separate red, green and blue components but rather a colorless component, termed luma, which provides brightness information (as in black-and-white video). This combines with one or more color-carrying components, termed chroma, that give only color information. Both the S-Video component video output (two separate signals) and the component video output (three separate signals) seen on DVD players are examples of this method.\n\nConverting video into luma and chroma allows for chroma subsampling, a method used by JPEG and MPEG compression schemes to reduce the storage requirements for images and video (respectively).\n\nMany consumer TVs, DVD players, monitors, video projectors and other video devices at one time used output or input.\n\nWhen used for connecting a video source to a video display where both support 4:3 and 16:9 display formats, the PAL television standard provides for signaling pulses that will automatically switch the display from one format to the other.\n\n\nDigital component video makes use of single cables with signal lines/connector pins dedicated to digital signals, transmitting digital color space values allowing higher resolutions such as 480p, 576i, 576p, 720p, 1080i, and 1080p.\n\nRGB component video has largely been replaced by modern digital formats, such as DisplayPort or Digital Visual Interface (DVI) digital connections, while home theater systems increasingly favor High-Definition Multimedia Interface (HDMI), which support higher resolutions, higher dynamic range, and can be made to support digital rights management. The demise of analog is largely due to screens moving to large flat digital panels as well as the desire for having a single cable for both audio and video but also due to a slight loss of clarity when converting from a digital media source to analogue and back again for a flat digital display, particularly when used at higher resolutions where analog signals are highly susceptible to noise.\n\nExamples of international component video standards are:\n\nIn a composite signal, the luminance, Brightness (Y) signal and the chrominance, Color (C) signals are encoded together into one signal. When the color components are kept as separate signals, the video is called component analog video (CAV), which requires three separate signals: the luminance signal (Y) and the color difference signals (R-Y and B-Y).\n\nSince component video does not undergo the encoding process, the color quality is noticeably better than composite video.\n\nComponent video connectors are not unique in that the same connectors are used for several different standards; hence, making a component video connection often does not lead to a satisfactory video signal being transferred. Many DVD players and TVs may need to be set to indicate the type of input/output being used, and if set incorrectly the image may not be properly displayed. Progressive scan, for example, is often not enabled by default, even when component video output is selected.\n\n"}
{"id": "1408610", "url": "https://en.wikipedia.org/wiki?curid=1408610", "title": "Confederation of European Business", "text": "Confederation of European Business\n\nThe Confederation of European Business, shortened BusinessEurope, is a lobby group representing enterprises of all sizes in the European Union (EU) and six non-EU European countries. Members of the confederation are 39 national industry and employers' organizations. The current president of the confederation is Pierre Gattaz, while the Director General is Markus J. Beyrer.\n\nBased in Brussels, the confederation is officially recognised as a social partner at European level, is involved in a range of economic and social decisions and cooperates with a number of stakeholders and business partners. It promotes the interests of corporate citizens to ensure that public policy supports the European economy.\n\nIn 2014, Unilever terminated its membership in BusinessEurope's Advisory and Support Group, because it opposed the organisation's stance on carbon dioxide emissions.\n\nThe association is led by a president. In the past, the following persons used to hold this office:\n\n\nBusinessEurope is administrated by a director general. Markus J. Beyrer has been holding this position since 2013.\n\nThe Confederation of European Business organises the annual BusinessEurope Day and European Business Summit in Brussels.\n\n\n\n"}
{"id": "5155293", "url": "https://en.wikipedia.org/wiki?curid=5155293", "title": "Construction field computing", "text": "Construction field computing\n\nConstruction field computing is the use of handheld devices that augment the construction superintendent's ability to manage the operations on a construction site. These information appliances (IA) must be portable devices which can be carried or worn by the user, and have computational and connectivity capacity to perform the tasks of communication management. Data entry and retrieval must be simple so that the user can manipulate the device while simultaneously moving, observing events, studying materials, checking quality, or performing other tasks required. Examples of these devices are the PDA, tablet PC modern tablet devices including iPad and Android Tablets and smartphone.\n\nSuperintendents are often moving about the construction site or between various sites. Their responsibilities cover a wide variety of tasks such as:\n\nThese tasks require that information is readily accessible and easily communicated to others and the company database. Since construction sites are unique, the device and system must be adaptable and flexible. Durability, predictability, and perceived value by the field management will determine the system's acceptance and thus proper use. Construction personnel are not well known for adapting to new technologies, but they do embrace methods that are proven to lighten work load and increase income.\n\nConstruction industry field personnel were quick to adopt new technologies such as the FAX machine and mobile phone, they have been slower to embrace the PC, tablet PC, PDA, and other devices. Disruptive technology is usually difficult in construction field use for several reasons:\nOvercoming these issues is imperative for most construction firms. The augmentation and automation of managerial practices is required to make the construction process more efficient. The information appliance makes it possible field supervisors to access needed information, communicate requirements to others, and document the process effectively.\n\nAn effective device will be able to process data into actionable information and transmit data and information to other devices or persons. The device may not actually perform computation of final communication, but it must appear as though it does. Extra steps to upload and download information will be perceived as a nuisance or waste of time to the user and cause the device to be underutilized. Some IAs are self-contained in that they have computing capacity and software to perform required tasks independent of a server or other devices. Others rely on connectivity with other devices and/or a server to perform required functions.\n\nA fat client refers to a device that has sufficient speed and size to run programs and is loaded locally with software needed for operation. It can stand alone. Some advantages of this type of system are:\n\nA thin client refers to a device that acts as a terminal or interface with a server or other device. Sometimes called dumb terminal, these devices do not have sufficient computing capacity or data storage capacity of process information, but only allow the user to access the software and data needed by them. Some advantages of this type of system are:\n\nComputer transparency is important in construction because of the requirements listed in the 'usages' section in this article. Especially important here are the lack of training in computer sciences and need to remain focused on the job-site activities. Any suitable device and system should support the user without their understanding of the technical aspects of the computer or system. Any data functions operations must require no knowledge of the database schema. Response to commands or input should be immediate and reversible so that the user can quickly experiment and learn by doing without causing damage to the system or data. The user will most often feel that access to information and control over the system is not unduly limited. These traits will reduce user anxiety and encourage usage and acceptance of new technologies and systems.\n\nUser friendliness is needed due to the varied level of knowledge of the user. The functional options should be easily labeled and structured such that the user can understand by viewing the screen and by intuition. Usability will in large part determine whether or not the device and/or system is utilized. An ineffective tool is not only useless, but can be deleterious in that it takes time from the user, but does not return value. Even if the user only perceives the operation of the device to be worthless, he/she will be 'demotivated' to use the device and do so improperly or insufficiently. This will render the activity useless, fulfilling the expectation of failure.\n\nLaptop or notebook computers are small enough to be carried around the construction site, but too big to do so comfortably. Other disadvantages include:\n\nThe tablet PC is basically a scaled down laptop with a touch screen that accepts handwriting rather than keyboard entry. Some do have keyboards, but they must be set down to operate and thus suffer the same problem of not being usable and portable at the same time. They can be carried with one hand and used with the other, thus allowing for ambulatory use. They are generally the size of a clipboard or notepad carried by many superintendents and are a good replacement for those devices due to the automation advantages of the computer, but they are still too big to be worn so that the user can move throughout the jobsite easily (up and down ladders) and have hands available for other uses (measuring manipulating objects to demonstrate technique or effect).\n\nThe PDA has been accepted by many construction firms to aid the management of punch lists, safety inspections, and maintenance work. They can be thin or thick devices, but are often a combination of the two, having connectivity, but containing programs to operate even when out of range of WiFi or coverage. PDAs are durable, inexpensive, and very portable (being worn on a clip or carried in a pocket). The small screen size and limited ability to quickly enter data are the drawbacks of this device.\n\nA smart phone is basically a mobile phone and PDA combined into one IA. Other functionalities such as digital camera and voice recorder are common. Data entry, like with the PDA, is by stylus or keypad and cumbersome. Many have web browsing capabilities but the small screen size diminishes the utility of this function to viewing email, weather reports, or some web content. Both PDA and smart phones have calendars, task lists, and phone lists, but they are useful to superintendents when coupled with the phone functions as is the case with the latter. Popular devices include the Blackberry and Treo, the pocket pc, iPhone and Droid all are popular because of their web/email abilities and ease of use.\n\nWith the advent of modern tablets including the iPad and Android tablets the area of mobile IT in construction is moving into a new era. These devices overcome many of the limitations of the rugged PDAs in terms of data entry, data access in field and its timely communication to others who need to act on it. In addition they cost a fraction of the cost of the rugged devices or rugged slate PCs.\n\nDigital cameras are often included in smart phones and PDAs, but their resolution is lower than the dedicated camera device. Most are not truly IA because they do not readily communicate with other devices or process information. Most brands share information by USB or flash memory card which is removed from the camera and inserted in complementary devices (most PDAs accept these cards). Other methods, such as Infrared Communications or Bluetooth are also available.\n\nA wide variety of software applications for each of the devices listed above are available. The user must determine system requirements and then ensure that software is available to perform the needed functions on a specific device.\n\nSome IAs (such as the total station) are made specifically for construction use, but they are for very specific applications and will not be considered here as the purpose of this article concerns general construction site management. Traditional input and output methods of keyboard, mouse, and screen are not suitable for the portable IA due to size constraints. These features are very important and must be considered.\n\nData, queries, commands, or responses must be entered into the computer through some sort of interface. Following are some of the methods useful in portable IAs.\n\nThe touch screen and stylus is effective for construction applications as it allows handwriting recognition for those who do not feel comfortable with keyboards or the small size of keyboards on portable IAs. They are also free hand entry so that the user can sketch and draw notes and measurements directly onto the screen. The digital image of the sketch can be transmitted to others or converted to another format after uploading to a printer or other computer.\n\nThese devices are the standard entry method for phones and easy to understand but are a slow means for alphanumeric data entry. They may be suitable for numeric entry into data fields. The user enters numbers on the keypad in response to prompts on the IA screen so this method is only suitable for entry of quantifiable standard information.\n\nVoice Recognition is the ability to respond to verbal commands. Speech recognition refers to the capacity of the IA to convert voice entry into data. Both have been difficult to use in many construction applications due to ambient noise, construction jargon which varies by region, trade, and company, and because of speech patterns of the individual user. This method is slower than keyboard entry for the experienced user.\n\nThe touch screen is the standard display method for tablet PC and smaller IAs. Color may or may not be important to the user but can be an aid in directing the user. The screen size is perhaps the most important consideration. Organization of the screen is challenging on the small screen and the user should be considered when designing the interface. See section 2.2 and 2.3 in Ben Shneiderman's \"Designing the user interface\" () concerning design of the interface.\n\nVoice or tonal output from the IA can be effective as a reminder, warning, or indication of action performed, but tends to be irritating to the user if it is the principal method of interaction. Verbal output is slower than viewing the information and it is difficult for a person to pay attention to and understand information. Systems such as JAWS screen reader for the visually impaired do exist, but are not practical for construction site users and application. See Shneiderman section 9.4 ().\n\nEyetap is a technology being developed that may have construction applications in the future. It allows the user to receive input from the computer superimposed over the scene in view. A diptych screen may be utilized to increase overall screen size and input area. Other 'Star Trek' devices and methods are being developed but the usable products have yet to be 'beamed down' to planet Earth.\n\nThe section on transparency in this article discusses some requirements for usability. Before implementing a system, a study on how it will add value to the user must be done. Having more data from the field is not directly beneficial to the site superintended. Reducing the time it takes to do 'paperwork' is valued. Sending an image taken from the IA camera directly to an architect for clarification does save time and effort and will be valued by the user.\n\nThe system and device should be designed such that it encourages experimentation and usage. Immediate response to input and adaptability based on level of experience are better than sitting through a training seminar to get a few dry donuts. Training is best accomplished by showing and encouraging use. A 'guru' or user expert within the company may be best way to resolve questions and provide answers to questions and concerns. See 'The social life of information' (need reference).\n\nTechnologies will evolve and the user will be facing new challenges with each change. It is usually wiser to adopt a small system that works and then later add features. This gradual adoption reduces anxiety and increases acceptance and use. This work by Linda V. Orr discusses methods to reduce anxiety for new computer users.\n\nConsideration should be given to ensure that IA devices and different software packages communicate with each other so that information is not lost or re-entry is not required by the user. Users do not always know or care what software is being used or which database is being accessed and do not understand why they must enter the same information again. For example, once the date has been entered, the user will be frustrated to be prompted to enter it again during the same session. Taking this further, the user may be frustrated to have to enter a date since there is a calendar function on the IA being used.\n\nWeb Based Mobile IT \n\nThese systems from leading vendors are not simply all about mobility in field and cutting the work required by in field managers in the area of report writing. Cloud based tablet and PC systems provide not just mobile capture and access to data in field but also for the first time they both computerise and move to the cloud the quality function. The use of powerful relational databases at the back end permits the data captured in field to be analysed. This can be used for instance to rate sub-contractors and to feed into continuous quality improvement. \n\nBenefits of Mobile IT in Construction \n\nStudies from the UK organisation COMIT and others have shown there is a valuable ROI from using this technology. Firms have reported faster delivery of projects, project hand over with zero defects, reduced costs from the process of managing sub-contractors and report writing and the value of having a secure audit trail. \n\n\n"}
{"id": "39388486", "url": "https://en.wikipedia.org/wiki?curid=39388486", "title": "Digital current loop interface", "text": "Digital current loop interface\n\nFor serial communications, a current loop is a communication interface that uses current instead of voltage for signaling. Current loops can be used over moderately long distances (tens of kilometres), and can be interfaced with optically isolated links.\n\nLong before the RS-232 standard, current loops were used to send digital data in serial form for teleprinters. More than two teleprinters could be connected on a single circuit allowing a simple form of networking. Older teleprinters used a 60 mA current loop. Later machines, such as the Teletype Model 33, operated on a lower 20 mA current level and most early minicomputers featured a 20 mA current loop interface, with an RS-232 port generally available as a more expensive option. The original IBM PC serial port card had provisions for a 20 mA current loop. \n\nA digital current loop uses the absence of current for high (space or break), and the presence of current in the loop for low (mark). This is done to ensure that on normal conditions there is always current flowing and in the event of a line being cut the flow stops indefinitely, immediately raising the alarm of the event usually as the heavy noise of the teleprinter not being synchronized, something that would not have been possible if the idle state had been no current flowing.\n\nThe maximum resistance for a current loop is limited by the available voltage. Current loop interfaces usually use voltages much higher than those found on an RS-232 interface, and cannot be interconnected with voltage-type inputs without some form of level translator circuit.\n\nFor full-duplex communication between two devices, two pairs of wires would be used. There is no common standard for current loop interfaces, so details such as timing, connectors, wire color codes, and so on, are all application specific. \n\n"}
{"id": "995994", "url": "https://en.wikipedia.org/wiki?curid=995994", "title": "Electro-galvanic oxygen sensor", "text": "Electro-galvanic oxygen sensor\n\nAn electro-galvanic fuel cell is an electrochemical device which consumes a fuel to produce an electrical output by a chemical reaction. One form of electro-galvanic fuel cell based on the oxidation of lead is commonly used to measure the concentration of oxygen gas in underwater diving and medical breathing gases.\n\nElectronically monitored or controlled diving rebreather systems, saturation diving systems, and many medical life-support systems use galvanic oxygen sensors in their control circuits to directly monitor oxygen partial pressure during operation. They are also used in oxygen analysers in recreational, technical diving and surface supplied mixed gas diving to analyse the proportion of oxygen in a nitrox, heliox or trimix breathing gas before a dive. \n\nThese cells are lead/oxygen galvanic cells where oxygen molecules are dissociated and reduced to hydroxyl ions at the cathode. The ions diffuse through the electrolyte and oxidize the lead anode. A current proportional to the rate of oxygen consumption is generated when the cathode and anode are electrically connected through a resistor\n\nThe cell reaction for a lead/oxygen cell is: 2Pb+O=2PbO, made up of the cathode reaction: O2+2HO+4e-4OH, and anode reaction: 2Pb+4OH-2PbO+2HO + 4e.\n\nThe cell current is proportional to the rate of oxygen reduction at the cathode, but this is not linearly dependent on the partial pressure of oxygen in the gas to which the cell is exposed: Linearity is achieved by placing a diffusion barrier between the gas and the cathode, which limits the amount of gas reaching the cathode to an amount that can be fully reduced without significant delay, making the partial pressure in the immediate vicinity of the electrode close to zero. As a result of this the amount of oxygen reaching the electrode follows Fick's laws of diffusion and is proportional to the partial pressure in the gas beyond the membrane. This makes the current proportional to P. \nThe load resistor over the cell allows the electronics to measure a voltage rather than a current. This voltage depends on the construction and age of the sensor, and typically varies between 7 and 28 mV for a P of 0.21 bar\n\nDiffusion is linearly dependent on the partial pressure gradient, but is also temperature dependent, and the current rises about two to three percent per kelvin rise in temperature. A negative temperature coefficient resistor is used to compensate, and for this to be effective it must be at the same temperature as the cell. Oxygen cells which may be exposed to relatively large or rapid temperature changes, like rebreathers, generally use thermally conductive paste between the temperature compensating circuit and the cell to speed up the balancing of temperature.\n\nTemperature also affects the signal response time, which is generally between 6 and 15 seconds at room temperature for a 90% response to a step change in partial pressure. Cold cells react much slower and hot cells much faster. As the anode material is oxidised the output current drops and eventually will cease altogether. The oxidation rate depends on the oxygen reaching the anode from the sensor membrane. Lifetime is measured in oxygen-hours, and also depends on temperature and humidity\n\nThe oxygen content of a stored gas mixture can be analysed by passing a small flow of the gas over a recently calibrated cell for long enough that the output stabilises. The stable output represents the fraction of oxygen in the mixture. Care must be taken to ensure that the gas flow is not diluted by ambient air, as this would affect the reading.\n\nThe partial pressure of oxygen in anaesthetic gases is monitored by siting the cell in the gas flow, which is at local atmospheric pressure, and can be calibrated to directly indicate the fraction of oxygen in the mix.\n\nThe partial pressure of oxygen in diving chambers and surface supplied breathing gas mixtures can also be monitored using these cells. This can either be done by placing the cell directly in the hyperbaric environment, wired through the hull to the monitor, or indirectly, by bleeding off gas from the hyperbaric environment or diver gas supply and analysing at atmospheric pressure, then calculating the partial pressure in the hyperbaric environment. This is frequently required in saturation diving and surface oriented surface supplied mixed gas commercial diving.\n\nThe breathing gas mixture in a diving rebreather loop is usually measured using oxygen cells, and the output of the cells is used by either the diver or an electronic control system to control addition of oxygen to increase partial pressure when it is below the chosen lower set-point, or to flush with diluent gas when it is above the upper set-point. When the partial pressure is between the upper and lower set-points, it is suitable for breathing at that depth and is left until it changes as a result of consumption by the diver, or a change in ambient pressure as a result of a depth change.\n\nAccuracy and reliability of measurement is important in this application for two basic reasons. Firstly, if the oxygen content is too low, the diver will lose consciousness due to hypoxia and probably die, or if the oxygen content is too high, the risk of central nervous system oxygen toxicity causing convulsions and loss of consciousness, with a high risk of drowning becomes unacceptable. Secondly, decompression obligations cannot be accurately or reliably calculated if the breathing gas composition is not known. Pre-dive calibration of the cells can only check response to partial pressures up to 100% at atmospheric pressure, or 1 bar. As the set points are commonly in the range of 1.2 to 1.6 bar, special hyperbaric calibration equipment would be required to reliably test the response at the set-points. This equipment is available, but is expensive and not in common use, and requires the cells to be removed from the rebreather and installed in the test unit. To compensate for the possibility of a cell failure during a dive, three cells are generally fitted, on the principle that failure of one cell at a time is most likely, and that if two cells indicate the same P, they are more likely to be correct than the single cell with a different reading. Voting logic allows the control system to control the circuit for the rest of the dive according to the two cells assumed to be correct. This is not entirely reliable, as it is possible for two cells to fail on the same dive. \n\nThe sensors should be placed in the rebreather where a temperature gradient between the gas and the electronics in the back of the cells will not occur.\n\nOxygen cells behave in a similar way to electrical batteries in that they have a finite lifespan which is dependent upon use. The chemical reaction described above causes the cell to create an electrical output that has a predicted voltage which is dependent on the materials used. In theory they should give that voltage from the day they are made until they are exhausted, except that one component of the planned chemical reaction has been left out of the assembly: oxygen.\n\nOxygen is one of the fuels of the cell so the more oxygen there is at the reaction surface, the more electrical current is generated. The chemistry sets the voltage and the oxygen concentration controls the electric current output. If an electrical load is connected across the cell it can draw up to this current but if the cell is overloaded the voltage will drop. When the lead electrode has been substantially oxidised, the maximum current that the cell can produce will drop, and eventually linearity of output voltage to partial pressure of oxygen at the reactive surface will fail within the required range of measurement, and the cell will no longer be accurate.\n\nThere are two commonly used ways to specify expected sensor life span: The time in months at room temperature in air, or volume percentage oxygen hours (Vol%Oh). Storage at low oxygen partial pressure when not in use would seem an effective way to extend cell life, but when stored in anoxic conditions the sensor current will cease and the surface of the electrode may be passivated, which can lead to sensor failure. High ambient temperatures will increase sensor current, and reduce cell life. In diving service a cell typically lasts for 12 to 18 months, with perhaps 150 hours service in the diving loop at an oxygen partial pressure of about 1.2 bar and the rest of the time in storage in air at room temperature.\n\nFailures in cells can be life-threatening for technical divers and in particular, rebreather divers. The failure modes common to these cells are: failing with a higher than expected output due to electrolyte leaks, which is usually attributable to physical damage, contamination, or other defects in manufacture, or current limitation due to exhausted cell life and non linear output across its range. \n\nShelf life can be maximised by keeping the cell in the sealed bag as supplied by the manufacturer until being put into service, storing the cell before and between use at or below room temperature, - a range of from 10 to 22°C is recommended by a manufacturer - and avoid storing the cell in warm or dry environments for prolonged periods, particularly areas exposed to direct sunlight.\n\nWhen new, a sensor can produce a linear output for over 4 bar partial pressure of oxygen, and as the anode is consumed the linear output range drops, eventually to below the range of partial pressures which may be expected in service, at which stage it is no longer fit to control the system. The maximum output current eventually drops below the amount needed to indicate the full range of partial pressures expected in operation. This state is called \"current-limited\". When a current limited sensor can no longer reliably activate the control system at the upper set-point in a life support system, there is a severe risk of an excessive oxygen partial pressure occurring which will not be noticed, which can be life-threatening.\n\nOther failure modes include mechanical damage, such as broken conductors, corroded contacts and loss of electrolyte due to damaged membranes.\n\nFailing high is invariably a result of a manufacturing fault or mechanical damage. In rebreathers, failing high will result in the rebreather assuming that there is more oxygen in the loop than there actually is which can result in hypoxia.\n\nCurrent limited cells do not give a high enough output in high concentrations of oxygen. The rebreather control circuit responds as if there is insufficient oxygen in the loop and injects more oxygen to reach a setpoint the cell can never indicate resulting in hyperoxia.\n\nNon-linear cells do not perform in the expected manner across the required range of oxygen partial pressures. Two-point calibration against diluent and oxygen at atmospheric pressure will not pick up this fault which results in inaccurate loop contents of a rebreather. This gives the potential for decompression illness if the loop is maintained at a lower partial pressure than indicated by the cell output, or hyperoxia if the loop os maintained at a lower partial pressure than indicated by cell output.\n\nPreventing accidents in rebreathers from cell failures is possible in most cases by accurately testing the cells before use. Some divers carry out in-water checks by pushing the oxygen content in the loop to a pressure that is above that of pure oxygen at sea level to indicate if the cell is capable of high outputs. This test is only a spot check and does not accurately assess the quality of that cell or predict its failure. The only way to accurately test a cell is with a test chamber which can hold a calibrated static pressure above the upper set-point without deviation and the ability to record the output voltage over the full range of working partial pressures and graph them.\n\nIf more than one statistically independent cell is used, it is unlikely that more than one will fail at a time. If one assumes that only one cell will fail, then comparing three or more outputs which have been calibrated at two points is likely to pick up the cell which has failed by assuming that any two cells that produce the same output are correct and the one which produces a different output is defective. This assumption is usually correct in practice, particularly if there is some difference in the history of the cells involved. The concept of comparing the output from three cells at the same place in the loop and controlling the gas mixture based on the average output of the two with the most similar output at any given time is known as voting logic, and is more reliable than control based on a single cell. If the third cell output deviates sufficiently from the other two, an alarm indicates probable cell failure. If this occurs before the dive, the rebreather is deemed unsafe and should not be used. If it occurs during a dive, it indicates an unreliable control system, and the dive should be aborted. Continuing a dive using a rebreather with a failed cell alarm significantly increases the risk of a fatal loop control failure. This system is not totally reliable. There has been at least one case reported where two cells failed similarly and the control system voted out the remaining good cell.\n\nIf the probability of failure of each cell was statistically independent of the others, and each cell alone was sufficient to allow safe function of the rebreather, the use of three fully redundant cells in parallel would reduce risk of failure by five or six orders of magnitude.\n\nThe voting logic changes this considerably. A majority of cells must not fail for safe function of the unit. In order to decide whether a cell is functioning correctly, it must be compared with an expected output. This is done by comparing it against the outputs of other cells. In the case of two cells, if the outputs differ, then one at least must be wrong, but it is not known which one. In such a case the diver should assume the unit is unsafe and bail out to open circuit. With three cells, if they all differ within an accepted tolerance, they may all be deemed functional. If two differ within tolerance, and the third does not, the two within tolerance may be deemed functional, and the third faulty. If none are within tolerance of each other, they may all be faulty, and if one is not, there is no way of identifying it.\n\nUsing this logic, the improvement in reliability gained by use of voting logic where at least two sensors must function for the system to function is greatly reduced compared to the fully redundant version. Improvements are only in the order of one to two orders of magnitude. This would be great improvement over the single sensor, but the analysis above has assumed statistical independence of the failure of the sensors, which is generally not realistic.\n\nFactors which make the cell outputs in a rebreather statistically dependent include:\n\nThis statistical dependency can be minimised and mitigated by:\n\nAn alternative method of providing redundancy in the control system is to recalibrate the sensors periodically during the dive by exposing them to a flow of either diluent or oxygen or both at different times, and using the output to check whether the cell is reacting appropriately to the known gas as the known depth. This method has the added advantage of allowing calibration at higher oxygen partial pressure than 1 bar. This procedure may be done automatically, where the system has been designed to do it, or the diver can manually perform a \"diluent flush\" at any depth at which the diluent is breathable to compare the cell P readings against a known F and absolute pressure to verify the displayed values. This test does not only validate the cell. If the sensor does not display the expected value, it is possible that the oxygen sensor, the pressure sensor(depth), or the gas mixture F, or any combination of these may be faulty. As all three of these possible faults could be life-threatening, the test is quite powerful.\n\nThe first certified cell checking device that was commercially available was launched in 2005 by Narked at 90, but did not achieve commercial success. A much revised model was released in 2007 and won the \"Gordon Smith Award\" for Innovation at the Diving Equipment Manufacturers Exhibition in Florida. Narked at 90 Ltd won the Award for Innovation for the Development of Advanced Diving products at Eurotek 2010 for the Cell Checker and its continuing Development. Now used throughout the world by organisations such as Teledyne, Vandagraph, National Oceanic and Atmospheric Administration, NURC (NATO Undersea Research Centre), and Diving Diseases Research Centre.\n\n"}
{"id": "10209776", "url": "https://en.wikipedia.org/wiki?curid=10209776", "title": "Energy applications of nanotechnology", "text": "Energy applications of nanotechnology\n\nOver the past few decades, the fields of science and engineering have been seeking to develop new and improved types of energy technologies that have the capability of improving life all over the world. In order to make the next leap forward from the current generation of technology, scientists and engineers have been developing energy applications of nanotechnology. Nanotechnology, a new field in science, is any technology that contains components smaller than 100 nanometers. For scale, a single virus particle is about 100 nanometers in width.\n\nAn important subfield of nanotechnology related to energy is nanofabrication. Nanofabrication is the process of designing and creating devices on the nanoscale. Creating devices smaller than 100 nanometers opens many doors for the development of new ways to capture, store, and transfer energy. The inherent level of control that nanofabrication could give scientists and engineers would be critical in providing the capability of solving many of the problems that the world is facing today related to the current generation of energy technologies.\n\nPeople in the fields of science and engineering have already begun developing ways of utilizing nanotechnology for the development of consumer products. Benefits already observed from the design of these products are an increased efficiency of lighting and heating, increased electrical storage capacity, and a decrease in the amount of pollution from the use of energy. Benefits such as these make the investment of capital in the research and development of nanotechnology a top priority.\n\nRecently, previously established and entirely new companies such as BetaBatt, Inc. and Oxane Materials are focusing on nanomaterials as a way to develop and improve upon older methods for the capture, transfer, and storage of energy for the development of consumer products.\n\nConsERV, a product developed by the Dais Analytic Corporation, uses nanoscale polymer membranes to increase the efficiency of heating and cooling systems and has already proven to be a lucrative design. The polymer membrane was specifically configured for this application by selectively engineering the size of the pores in the membrane to prevent air from passing, while allowing moisture to pass through the membrane. ConsERV's value is demonstrated in the form of an energy recovery a device which pretreats the incoming fresh air to a building using the energy found in the exhaust air steam using no moving parts to lower the energy and carbon footprint of existing forms of heating and cooling equipment Polymer membranes can be designed to selectively allow particles of one size and shape to pass through while preventing other. This makes for a powerful tool that can be used in all markets - consumer, commercial, industrial, and government products from biological weapons protection to industrial chemical separations. Dais's near term uses of this 'family' of selectively engineered nanotechnology materials, aside from ConsERV, include (a.) a completely new cooling cycle capable of replacing the refrigerant based cooling cycle the world has known for the past 100 plus years. This product, under development, is named NanoAir. NanoAir uses only water and this selectively engineered membrane material to cool (or heat) and dehumidify (or humidify) air. There are no fluorocarbon producing gasses used, and the energy required to cool a space drops as thermodynamics does the actual cooling. The company was awarded an Advanced Research Program Administration - Energy award in 2010, and a United States Department of Defense (DoD) grant in 2011 both designed to accelerate this newer, energy efficient technology closer to commercialization, and (b.) a novel way to clean most all contaminated forms of water called NanoClear. By using the selectivity of this hermetic, engineered composite material it can transfer only a water molecule from one face of the membrane to the other leaving behind the contaminants. It should also be noted Dais received a US Patent (Patent Number 7,990,679) in October 2011 titled \"Nanoparticle Ultracapacitor\". This patented item again uses the selectively engineered material to create an energy storage mechanism projected to have performance and cost advantages over existing storage technologies. The company has used this patent's concepts to create a functional energy storage prototype device named NanoCap. NanoCap is a form of ultra-capacitor potentially useful to power a broad range of applications including most forms of transportation, energy storage (especially useful as a storage media for renewable energy technologies), telecommunication infrastructure, transistor gate dielectrics, and consumer battery applications (cell phones, computers, etc.).\n\nA New York-based company called Applied NanoWorks, Inc. has been developing a consumer product that utilizes LED technology to generate light. Light-emitting diodes or LEDs, use only about 10% of the energy that a typical incandescent or fluorescent light bulb uses and typically last much longer, which makes them a viable alternative to traditional light bulbs. While LEDs have been around for decades, this company and others like it have been developing a special variant of LED called the white LED. White LEDs consist of semi-conducting organic layers that are only about 100 nanometers in distance from each other and are placed between two electrodes, which create an anode, and a cathode. When voltage is applied to the system, light is generated when electricity passes through the two organic layers. This is called electroluminescence. The semiconductor properties of the organic layers are what allow for the minimal amount of energy necessary to generate light. In traditional light bulbs, a metal filament is used to generate light when electricity is run through the filament. Using metal generates a great deal of heat and therefore lowers efficiency.\nResearch for longer lasting batteries has been an ongoing process for years. Researchers have now begun to utilize nanotechnology for battery technology. mPhase Technologies in conglomeration with Rutgers University and Bell Laboratories have utilized nanomaterials to alter the wetting behavior of the surface where the liquid in the battery lies to spread the liquid droplets over a greater area on the surface and therefore have greater control over the movement of the droplets. This gives more control to the designer of the battery. This control prevents reactions in the battery by separating the electrolytic liquid from the anode and the cathode when the battery is not in use and joining them when the battery is in need of use.\n\nThermal applications also are a future applications of nanothechonlogy creating low cost system of heating, ventilation, and air conditioning, changing molecular structure for better management of temperature\n\nA reduction of energy consumption can be reached by better insulation systems, by the use of more efficient lighting or combustion systems, and by use of lighter and stronger materials in the transportation sector. Currently used light bulbs only convert approximately 5% of the electrical energy into light. Nanotechnological approaches like or quantum caged atoms (QCAs) could lead to a strong reduction of energy consumption for illumination.\n\nToday's best solar cells have layers of several different semiconductors stacked together to absorb light at different energies but they still only manage to use 40 percent of the Sun's energy. Commercially available solar cells have much lower efficiencies (15-20%). Nanostructuring has been used to improve the efficiencies of established photovoltaic technologies, for example by improving current collection in amorphous silicon devices, plasmonic enhancement in dye-sensitized solar cells, and improved light trapping in crystalline silicon.\nFurthermore, nanotechnology could help increase the efficiency of light conversion by using nanostructures with a continuum of bandgaps, or by controlling the directivity and photon escape probability of photovoltaic devices.\n\nThe degree of efficiency of the internal combustion engine is about 30-40% at present. Nanotechnology could improve combustion by designing specific catalysts with maximized surface area. In 2005, scientists at the University of Toronto developed a spray-on nanoparticle substance that, when applied to a surface, instantly transforms it into a solar collector.\n\nNanomaterials deployed by swarm robotics may be helpful for decontaminating a site of a nuclear accident which poses hazards to humans because of high levels of radiation and radioactive particles. Hot nuclear compounds such as corium or melting fuel rods may be contained in \"bubbles\" made from nanomaterials that are designed to isolate the harmful effects of nuclear activity occurring inside of them from the outside environment that organisms inhabit.\n\nThe relatively recent shift toward using nanotechnology with respect to the capture, transfer, and storage of energy has and will continue to have many positive economic impacts on society. The control of materials that nanotechnology offers to scientists and engineers of consumer products is one of the most important aspects of nanotechnology. This allows for an improved efficiency of products across the board.\n\nA major issue with current energy generation is the loss of efficiency from the generation of heat as a by-product of the process. A common example of this is the heat generated by the internal combustion engine. The internal combustion engine loses about 64% of the energy from gasoline as heat and an improvement of this alone could have a significant economic impact. However, improving the internal combustion engine in this respect has proven to be extremely difficult without sacrificing performance. Improving the efficiency of fuel cells through the use of nanotechnology appears to be more plausible by using molecularly tailored catalysts, polymer membranes, and improved fuel storage.\n\nIn order for a fuel cell to operate, particularly of the hydrogen variant, a noble-metal catalyst (usually platinum, which is very expensive) is needed to separate the electrons from the protons of the hydrogen atoms. However, catalysts of this type are extremely sensitive to carbon monoxide reactions. In order to combat this, alcohols or hydrocarbons compounds are used to lower the carbon monoxide concentration in the system. This adds an additional cost to the device. Using nanotechnology, catalysts can be designed through nanofabrication that are much more resistant to carbon monoxide reactions, which improves the efficiency of the process and may be designed with cheaper materials to additionally lower costs.\n\nFuel cells that are currently designed for transportation need rapid start-up periods for the practicality of consumer use. This process puts a lot of strain on the traditional polymer electrolyte membranes, which decreases the life of the membrane requiring frequent replacement. Using nanotechnology, engineers have the ability to create a much more durable polymer membrane, which addresses this problem. Nanoscale polymer membranes are also much more efficient in ionic conductivity. This improves the efficiency of the system and decreases the time between replacements, which lowers costs.\n\nAnother problem with contemporary fuel cells is the storage of the fuel. In the case of hydrogen fuel cells, storing the hydrogen in gaseous rather than liquid form improves the efficiency by 5%. However, the materials that we currently have available to us significantly limit fuel storage due to low stress tolerance and costs. Scientists have come up with an answer to this by using a nanoporous styrene material (which is a relatively inexpensive material) that when super-cooled to around -196C, naturally holds on to hydrogen atoms and when heated again releases the hydrogen for use.\n\nFor decades, scientists and engineers have been attempting to make computers smaller and more efficient. A crucial component of computers are capacitors. A capacitor is a device that is made of a pair of electrodes separated by an insulator that each stores an opposite charge. A capacitor stores a charge when it is removed from the circuit that it is connected to; the charge is released when it is replaced back into the circuit. Capacitors have an advantage over batteries in that they release their charge much more quickly than a battery. \nTraditional or foil capacitors are composed of thin metal conducting plates separated by an electrical insulator, which are then stacked or rolled and placed in a casing. The problem with a traditional capacitor such as this is that they limit how small an engineer can design a computer. Scientists and engineers have since turned to nanotechnology for a solution to the problem. \nUsing nanotechnology, researchers developed what they call “ultracapacitors.” An ultracapacitor is a capacitor that contains nanocomponents. Ultracapacitors are being researched heavily because of their high density interior, compact size, reliability, and high capacitance. This decrease in size makes it increasingly possible to develop much smaller circuits and computers. Ultracapacitors also have the capability to supplement batteries in hybrid vehicles by providing a large amount of energy during peak acceleration and allowing the battery to supply energy over longer periods of time, such as during a constant driving speed. This could decrease the size and weight of the large batteries needed in hybrid vehicles as well as take additional stress off the battery. However, the combination of ultracapacitors and a battery is not cost effective due to the need of additional DC/DC electronics to coordinate the two.\n\nNanoporous carbon aerogel is one type of material that is being utilized for the design of ultracapacitors. These aerogels have a very large interior surface area and can have its properties altered by changing the pore diameter and distribution along with adding nanosized alkali metals to alter its conductivity.\n\nCarbon nanotubes are another possible material for use in an ultracapacitor. Carbon nanotubes are created by vaporizing carbon and allowing it to condense on a surface. When the carbon condenses, it forms a nanosized tube composed of carbon atoms. This tube has a high surface area, which increases the amount of charge that can be stored. The low reliability and high cost of using carbon nanotubes for ultracapacitors is currently an issue of research.\n\nIn a study concerning ultracapacitors or supercapacitors, researchers at the Sungkyunkwan University in the Republic of Korea explored the possibility of increasing the capacitance of electrodes through the addition of fluorine atoms to the walls of carbon nanotubes. As briefly mentioned before, carbon nanotubes are an increasing form of capacitors due to their superb chemical stability, high conductivity, light mass, and their large surface area. These researchers fluorinated single-walled carbon nanotubes (SWCNTs) at high temperatures to bind fluorine atoms to the walls. The attached fluorine atoms changed the non-polar nanotubes to become polar molecules. This can be attributed to the charge transfer from the fluorine. This created dipole-dipole layers along the carbon nanotube walls. Testing of these fluorinated SWCNTs against normal state SWCNTs showed a difference in capacitance. It was determined that the fluorinated SWCNTs are advantageous in fabricating electrodes for capacitors and improve the wettability with aqueous electrolytes, which promotes the overall performance of supercapacitors. While this study brought to knowledge a more efficient example of capacitors, little is known about this new supercapacitor, large scale synthesis is lacking and is necessary for any massive production, and preparation conditions are quite tedious in achieving the final product.\n\nUnderstanding the concept of capacitance can be helpful in understanding why nanotechnology is such a powerful tool for the design of higher energy storing capacitors. A capacitor’s capacitance (C) or amount of energy stored is equal to the amount of charge (Q) stored on each plate divided by the voltage (V) between the plates. Another representation of capacitance is that capacitance (C) is approximately equal to the permittivity (ε) of the dielectric times the area (A) of the plates divided by the distance (d) between them. Therefore, capacitance is proportional to the surface area of the conducting plate and inversely proportional to the distance between the plates.\n\nUsing carbon nanotubes as an example, a property of carbon nanotubes is that they have a very high surface area to store a charge. Using the above proportionality that capacitance (C) is proportional to the surface area (A) of the conducting plate; it becomes obvious that using nanoscaled materials with high surface area would be great for increasing capacitance. The other proportionality described above is that capacitance (C) is inversely proportional to the distance (d) between the plates. Using nanoscaled plates such as carbon nanotubes with nanofabrication techniques, gives the capability of decreasing the space between plates which again increases capacitance.\n\n\n"}
{"id": "1443002", "url": "https://en.wikipedia.org/wiki?curid=1443002", "title": "Environmental technology", "text": "Environmental technology\n\nEnvironmental technology (\"envirotech\"), green technology (\"greentech\") or clean technology (\"cleantech\") is the application of one or more of environmental science, green chemistry, environmental monitoring and electronic devices to monitor, model and conserve the natural environment and resources, and to curb the negative impacts of human involvement. The term is also used to describe sustainable energy generation technologies such as photovoltaics, wind turbines, bioreactors, etc. Sustainable development is the core of \"environmental technologies\". The term \"environmental technologies\" is also used to describe a class of electronic devices that can promote sustainable management of resources.\n\n\nRenewable energy is the energy that can be replenished easily. For years we have been using sources such as wood, sun, water, etc. for means for producing energy. Energy that can be produced by natural objects like wood, sun, wind, etc. is considered to be renewable.\n\nWater purification: The whole idea/concept of having dirt/germ/pollution free water flowing throughout the environment. Many other phenomena lead from this concept of purification of water. Water pollution is the main enemy of this concept, and various campaigns and activists have been organized around the world to help purify water.\n\nAir purification: Basic and common green plants can be grown indoors to keep air fresh because all plants remove CO and convert it into oxygen. The best examples are: \"Dypsis lutescens\", \"Sansevieria trifasciata\", and \"Epipremnum aureum\". It should also be noted that besides using the plants themselves, some species of bacteria can also be added to the leaves of these plants to help remove toxic gases, such as toluene\n\nSewage treatment is conceptually similar to water purification. Sewage treatments are very important as they purify water per levels of its pollution. The most polluted water is not used for anything, and the least polluted water is supplied to places where water is used affluently. It may lead to various other concepts of environmental protection, sustainability etc.\n\nEnvironmental remediation is the removal of pollutants or contaminants for the general protection of the environment. This is accomplished by various chemical, biological, and bulk methods.\n\nSolid waste management is the purification, consumption, reuse, disposal and treatment of solid waste that is undertaken by the government or the ruling bodies of a city/town.\n\nEgain forecasting is a method using forecasting technology to predict the future weather's impact on a building. By adjusting the heat based on the weather forecast, the system eliminates redundant use of heat, thus reducing the energy consumption and the emission of greenhouse gases.\n\nEnergy conservation is the utilization of devices that require smaller amounts of energy in order to reduce the consumption of electricity. Reducing the use of electricity causes less fossil fuels to be burned to provide that electricity.\n\nPrinciples:\n\nConcerns over pollution and greenhouse gases have spurred the search for sustainable alternatives to our current fuel use. For example, biogas from anaerobic digestion of plant waste can be stored to produce heat or electricity. The global reduction of greenhouse gases requires the adoption of energy conservation as well as sustainable generation. That environmental harm reduction involves global changes such as:\n\n\nSince fuel used by industry and transportation account for the majority of world demand, by investing in conservation and efficiency (using less fuel), pollution and greenhouse gases from these two sectors can be reduced around the globe. Advanced energy efficient electric motor (and electric generator) technology that are cost effective to encourage their application, such as variable speed generators and efficient energy use, can reduce the amount of carbon dioxide (CO) and sulfur dioxide (SO) that would otherwise be introduced to the atmosphere, if electricity were generated using fossil fuels. Greasestock is an event held yearly in Yorktown Heights, New York which is one of the largest showcases of environmental technology in the United States.\n\nCourses aimed at developing graduates with specific skills in environmental systems or environmental technology are becoming more common and fall into three broads classes:\n\n\n"}
{"id": "692113", "url": "https://en.wikipedia.org/wiki?curid=692113", "title": "Fusing (manufacturing)", "text": "Fusing (manufacturing)\n\n\"For the art, see stained glass fusing.\"\n\nFusing is a type of manufacturing process for joining or terminating electrical magnet wire, that is coated with a varnish (film) type insulation, to itself or some type of electrical terminal, without prior removal of the insulation. During the fusing process, the varnish film insulation is vaporized automatically. The entire process takes between a quarter of a second to 50 seconds, depending upon the geometry of the wires being joined.\n"}
{"id": "54084302", "url": "https://en.wikipedia.org/wiki?curid=54084302", "title": "Garlic peeler", "text": "Garlic peeler\n\nA garlic peeler is a kitchen utensil used to take off the skin off the garlic cloves.\n\nA closed, hard-walled container, such as a jar or lidded tub or bowl, can be used to peel garlic. The bulb of garlic is smashed with the bottom of the container, and the cloves placed in the container and shaken to separate them from their skins.\n\nOne garlic-peeling device is a silicone or rubber tube. Using hands to apply a moderate pressure and to rotate the tube on a cutting board or a table makes the skin come off the clove. The tube peeler was invented by Ben Omessi, a retired American architect who was designing home items for people with disabilities and it was patented in 1998.\n\nA food chopper can also be used to peel garlic, by replacing the blades with a central device having a surface featuring large bumps. The rotation will push the cloves to bounce between the wall and the bumpy surface, taking the skin off.\n\n\n"}
{"id": "50021376", "url": "https://en.wikipedia.org/wiki?curid=50021376", "title": "GoMedia", "text": "GoMedia\n\nGoMedia is a British company which supplies a management system which delivers entertainment packages including featuring films to travelers on trains and coaches including on Eurostar trains. The system also gives real-time travel information. Rather than using a monitor on the seat in front of the passenger, it uses the passenger's own device (\"Bring Your Own Device\" or BYOD) such as mobiles and tablets. It uses the vehicle's own wi-fi rather than the passenger's independent mobile network for on-board infotainment.\n\nTheir BEAM management system is the first app of its kind in the UK, and is used across Virgin West Coast and East Coast. The films available include \"Independence Day\", which formed the foundation of Virgin Trains’ BEAM launch at Euston Station, London in late 2016. TV box sets from BBC Worldwide, cartoons, games, digital newspapers and magazines are also offered. The free on-demand entertainment provided includes films, catch-up TV, box sets, cartoons, games, newspapers and magazines. A tracker app also shows the train's exact location. GoMedia have awarded the 'cloaking contract' to Irdeto, as well as the wi-fi's security, using their Secure Key Exchange.\n\nManagement includes chief executive Matt Seaman, managing director Roger Matthews, and Simon Dore.\n\n"}
{"id": "12825955", "url": "https://en.wikipedia.org/wiki?curid=12825955", "title": "History of the oil shale industry", "text": "History of the oil shale industry\n\nThe history of the oil shale industry started in ancient times. The modern industrial use of oil shale for oil extraction dates to the mid-19th century and started growing just before World War I because of the mass production of automobiles and trucks and the supposed shortage of gasoline for transportation needs. Between the World Wars oil shale projects were begun in several countries.\n\nAfter World War II, the oil shale industry declined due to increased accessibility to conventional crude oil. As of 2010, oil shale was commercially used in Estonia, China and Brazil, while several countries are considering to start or restart commercial use of oil shale.\n\nHumans have used oil shale as a fuel since prehistoric times, since it generally burns without any processing. It was also used for decorative purposes and construction. Britons of the Iron Age used to polish and form oil shale into ornaments. Around 3000 BC, \"rock oil\" was used in Mesopotamia for road construction and making architectural adhesives.\n\nAs a decorative material, oil shale was also used over the Greek, Roman, Byzantinian, Umayyad and Abbasid periods to decorate mosaics and floors of the palaces, churches and mosques.\n\nShale oil was used for medical and military purposes. Mesopotamians used it for medical purposes and for caulking ships, Mongols used to cap their arrows with flaming oil shale. In the 10th century, the Arabian physician Masawaih al-Mardini (Mesue the Younger) described a method of extraction of oil from \"some kind of bituminous shale\". In the early 14th century, the first use of shale oil was recorded in Switzerland and Austria. In 1350, a knight Berthold von Ebenhausen was awarded a right to exploit the Seefeld oil shale in Tyrol. Oil shale was used for production of shale oil using an early retorting method of heating the crushed oil shale put in crucibles. The healing properties of a mineral oil distilled from oil shale were noted in 1596 by the personal physician of the Duke of Württemberg Frederick I.\n\nIn Skåne, the Swedish alum shale dating from the Cambrian and Ordovician periods was used for extracting potassium aluminium sulfate by roasting it over fire as early as 1637. In Italy, shale oil was used to light the streets of Modena at the turn of the 17th century. The British Crown granted a patent in 1694 to three persons named Martin Eele, Thomas Hancock and William Portlock who had \"found a way to extract and make great quantities of pitch, tarr, and oyle out of a sort of stone.\" Shale oil was produced by extracting Shropshire oil shale. Later sold as Betton's British Oil, the distilled product was said to have been \"tried by divers persons in Aches and Pains with much benefit.\" In 1781, Archibald Cochrane, 9th Earl of Dundonald, registered a patent for an extraction process to produce tar, pitch and oil from coal and bituminous shales, using masonry retorts and wooden condensers.\n\nIn Russia Peter the Great initiated an investigative program of Ukhta oil shale in 1697. Data on physical and chemical properties of Ukhta oil shale was published by a correspondent member of the Russian Academy Tertii Bornovolokov in 1809. In 1769, Peter Simon Pallas described oil shale of the Volga Region. In the 1830s Germain Henri Hess investigated Baltic oil shales with resulting determination of the semicoking process product yields.\n\nOil shale in Australia was referred to for the first time by François Péron, \"et al.\", in \"Voyage de Découverte aux Terres Australes\" which was published in Paris in 1807, describing what was probably torbanite from the Newnes deposit.\n\nThe modern industrial use of oil shale for oil extraction started in France, where oil shale commercial mining began in Autun in 1837. The shale oil production started in 1838 by using Selligue process, invented by Alexander Selligue. In 1846 the Canadian physician and geologist Abraham Gesner invented a process for retorting an illuminating liquid from coal, bitumen and oil shale. In 1847 the Scottish chemist James Young prepared \"lighting oil,\" lubricating oil and wax from cannel coal and since 1862 from torbanite. In 1850 he patented the process of retorting and refining shale oil and purifying paraffin wax from it. Commercial scale shale oil extraction from lamosite started in 1859 by Robert Bell in Broxburn, West Lothian. In After expiring of Young's patent in 1862 many small shale oil works were opened. By 1865, there were about 120 shale oil works in Scotland. In 1866 Young established Young's Paraffin Light and Mineral Oil Company at Addiewell. Other notable shale oil companies were the Broxburn Oil Company established in 1878 and the Pumpherston Oil Company established in 1892.\n\nIn the United States early oil-shale industry concentrated on the eastern oil shale deposits. An oil distillery was built in 1855 at Breckinridge County, Kentucky to produce oil from locally mined cannel coal. By the following year it was producing . In 1860, there were 55 companies in the United States extracting oil from locally mined cannel coal. Commercial-scale shale oil extraction, other than cannel coal processing, began at shale oil retorts using the Devonian oil shale along the Ohio River Valley in 1857. However, the discovery of cheap and abundant petroleum in the same region, starting with the Drake Oil Well at Titusville, Pennsylvania in 1859, put the American oil shale industry out of business by 1860. The largest deposit, Green River Formation, was accidentally discovered in 1874 but not utilized until beginning of the 20th century.\n\nIn 1857, oil shale industry started in Germany. In Canada, the Craigleith Shale Oil Works started to retort oil shale of the Ordovician Whitby Formation near Collingwood, Ontario, on Lake Huron in 1859. In 1861 it became economically infeasible due to the discovery of petroleum nearby.\n\nIn Australia, the first oil shale mine was commenced in 1865 at American Creek, Mount Kembla in New South Wales. At the same year, the first shale oil was produced by the Pioneer Kerosene Works at American Creek. A number of other mines and shale oil plants were opened in New South Wales; however, in the beginning of the 20th century they were closed due to the import of cheaper crude oil.\n\nIn Austria, oil shale was used in 1840–1882 for production of asphalt mastic, naphtha and asphalt tar. In Sweden, the first attempt to extract oil from alum shale was made in 1864. Shale oil production started in the 1890s and lasted few years. In Brazil, oil shale was first exploited in 1884 in Bahia. In 1900 shale oil extraction industry was initiated also in New Zealand.\n\nIn 1894, the Pumpherston retort (also known as the Bryson retort) was invented, which is considered as a separation of the oil shale industry from the coal industry. It stayed in use until 1938.\n\nOperations during the 19th century focused on the production of kerosene, lamp oil, and paraffin wax; these products helped supply the growing demand for lighting that arose during the Industrial Revolution. Fuel oil, lubricating oil and grease, and ammonium sulfate were also produced.\n\nThe oil shale industry expanded immediately before World War I because of limited access to conventional petroleum resources and the mass production of automobiles and trucks, which accompanied an increase in gasoline consumption. Oil shale production in Scotland peaked in 1910–1912 with more than three million tonnes. That time Scottish shale oil industry contributed 2% of global oil production. After that, production declined with exception of the period of World War II. In 1919, five survived shale oil companies (\"Young's Paraffin Light & Mineral Oil Company\", \"Broxburn Oil Company\", \"Pumpherston Shale Oil Company\", \"Oakbank Oil Company\", and \"James Ross & Company Philpstoun Oil Works\"), were merged into Scottish Oils, a subsidiary of Anglo-Persian Oil Company.\nIn the United States the government started to create the Naval Petroleum and Oil Shale Reserves in 1909. The reserves were seen as a possible emergency source of fuel for the military, particularly the Navy. The government reserved the Roan Plateau near Rifle, Colorado which later became a federal demonstration and test site. First attempt to produce oil from the western deposits was made in Nevada by local businessman Robert Catlin by acquiring oil-shale properties in the 1890s and erecting the first retorts in 1915 and 1916. Although the attempt was commercially unsuccessful, in 1917 he incorporated Catlin Shale Products Company which made several unsuccessful attempts to sold shale oil products until it was dissolved in 1930. The first attempts to exploit the Green River Formation deposit was made by establishment of The Oil Shale Mining Company in 1916. In 1917, they erected the first commercial retort at the head of Dry Creek, near De Beque, Colorado. However, also these attempts were unsuccessful and by 1926 the company had lost its property. In addition, companies like Cities Service, Standard Oil of California, Texaco and Union started their oil shale operations in 1918–1920. In 1915–1920 about 200 companies were established to exploit oil shale and at least 25 shale oil retorting processes reached to the pilot-plant stage. Discoveries of the large quantities of petroleum in eastern Texas ended the oil-shale boom. One of technological achievements before World War II was invention of the N-T-U retort. In 1925, the NTU Company built a test plant at Sherman Cut near Casmalia, California. In 1925–1929, the retort was also tested by the United States Bureau of Mines in their Oil Shale Experiment Station at Anvil Point in Rifle, Colorado.\n\nDuring World War I, the German Army produced shale oil from the Jordan oil shale at the Yarmouk area to operate the Hejaz Railway. In 1915 an oil shale industry was established in Switzerland. About 1920, a small mall shale oil extraction plant was opened at Kinnekulle, Sweden. In 1922, a small shale oil extraction plant was opened in Puertollano, Spain.\n\nThe year 1916 is considered the beginning of the Estonian oil shale industry. when a group of geologists, led by Nikolay Pogrebov, was sent to Estonia to organise the mining of oil shale and its transportation to Saint Petersburg (then known as Petrograd). In June 1916, the first tonnes of oil shale were mined at Pavandu and delivered to Saint Petersburg Polytechnical University for large-scale experiments. In 1917, Russian paleontologist Mikhail Zalessky named kukersite oil shale after the Kukruse settlement. Continuous mining activities started shortly after. Initially, oil shale was used primarily in the cement industry, for firing in locomotive furnaces, and as a household fuel, followed by shale oil and power production. As of 1925, all locomotives in Estonia were powered by oil shale. The first experimental oil shale processing retorts were built in 1921, using the method developed by Julius Pintsch AG. In 1924, the Tallinn Power Plant was the first power plant in the world to employ oil shale as its primary fuel. In 1939 Estonia mined 1.453 million tonnes of oil shale and produced 181,000 tonnes of shale oil, including 22,500 tonnes of oil that were suitable gasoline equivalents. Almost half of Estonian produced shale oil was exported accounting for 8% of country's total export.\n\nIn China, the extraction of oil shale began in 1926 under the Japanese rule. The commercial-scale production of shale oil began in 1930 in Fushun, Manchuria, with the construction of the \"Refinery No. 1\" operating Fushun-type retorts. In Russia, Kashpirskoye oil shale near Syzran in the Volga region was mined and processed in 1919–1924 and again starting from 1929. Leningradslanets opened the Kirov oil shale mine in 1934 in Slantsy, Leningrad Oblast and shale oil production started in 1939. Saratov and Syzran power stations in Russia started to use oil shale as fuel. In South Africa different attempts of using oil shale were made since beginning of century. In 1903 the Transvaal Oil Shale Syndicate investigated oil shale at Kikvorschfontein. In 1919–1931 the African Oil Corporation investigated oil shale at Kromhoek and Goedgevonden. In 1935, The South African Torbanite Mining and Refining Company, a joint venture of Anglo-Transvaal Consolidated Investment Company and Burmah Oil opened shale oil plant at Ermelo in 1935.\n\nBetween the World Wars oil shale projects were also in restarted in Brazil and, for a short time, in Canada.\n\nIn 1939–1945, a shale oil pilot plant operated in Morocco. In Australia shale oil production restarted shortly before World War II. In 1937, the \"National Oil Proprietary\" was created. The Glen Davis Shale Oil Works became operational at Glen Davis, New South Wales in 1940 as the main facility in the country. In addition, in 1940–1952, three N-T-U retorts were operated at Marangaroo, New South Wales.\n\nIn Sweden, \"Svenska skifferolje AB\" (Swedish Shale Oil Company) was formed in 1940. It exploited one of the earliest \"in-situ\" processes–underground gasification by electrical energy (Ljungström method)–between 1940 and 1966 at Kvarntorp.\n\nDuring the German occupation of Estonia, Estonia's oil shale industry was merged into a company named \"Baltische Öl GmbH\". This entity was subordinated to \"Kontinentale Öl\", a company that had exclusive rights to oil production in German-occupied territories. The primary purpose of the industry was production of oil for the German Army.\n\nIn Germany shale oil extraction started at the Dotternhausen cement factory in 1940. Later the Operation Desert (\"Unternehmen Wüste\") was launched for the oil extraction from Swabian Alb oil shale deposits (Posidonia Shale). However, out of ten planned shale-oil extraction plants only four became operational. The used modified \"in-situ\" process was primitive with extremely low oil recovery and it was hard to control.\n\nIn 1944 the United States adopted the Synthetic Liquid Fuels Program with goal to establish a liquid fuel supply from domestic oil shale. The Bureau of Mines started mining studies and development of the gas combustion retort process at Anvil Point. In 1943 Mobil Oil built a pilot shale oil extraction plant and in 1944 Union built an experimental oil shale retort. In 1945 Texaco started shale oil refining study.\n\nAlthough the Estonian, Russian and Chinese oil shale industries continued to grow after World War II, most other countries abandoned their projects due to high processing costs and the availability of cheaper petroleum. The shale oil extraction in Australia was discontinued in 1952 due to ceasing of government funding, in France in 1957, in Britain and South Africa in 1962, and in Sweden and Spain in 1966. In Germany only Rohrbach Zement (now part of Holcim) in Dotternhausen continued using oil shale for cement, power and thermal energy production.\n\nAfter World War II, the Soviet occupation regime restored the oil shale industry in Estonia. In 1945, the first tunnel kiln was restored and by the end of the 1940s four tunnel kilns had been restored. German prisoners of war contributed most of the labour. In addition to tunnel kilns a number of Kiviter-type retorts and the first Galoter-type retort were built in the 1950s. Since 1948, Estonian-produced oil shale gas was used in Leningrad (Saint Petersburg) and in northern Estonia cities as a substitute for natural gas. During the 1950s, unsuccessful tests of oil shale underground gasification were conducted at Kiviõli. In 1946–1952, uranium compounds were extracted from Graptolitic argillite oil shale in Sillamäe. In 1949, the Kohtla-Järve Power Plant – the first power plant in the world using pulverized oil shale at an industrial scale – was commissioned in Estonia. The world's two largest oil shale-fired power stations – Balti Power Plant and Eesti Power Plant (known as the Narva Power Plants) – were opened in 1965 and in 1973. In 1965, of oil shale gas were produced and 16.5 million tonnes of oil shale were mined in Estonia.\n\nIn Russia, the Slantsy oil shale gas extraction plant was built for supplying oil shale gas to Leningrad and the first unit of the Slantsy oil-shale-fired power plant were commissioned in 1952. Since 1955 until 2003, the plant also produced shale oil using Kiviter technology.\n\nIn China, the \"Refinery No. 2\" of Fushun began its production in 1954 and in 1959, the maximum annual shale oil production increased to 780,000 tonnes. The produced shale oil was used for producing light liquid fuels. In 1961, China was producing one third of its total oil production from oil shale. Afterwards the shale oil production decreased due to the discovery of Daqing oil field and increased production of the cheaper conventional petroleum.\n\nIn 1951, the United States Department of Defense became interested in oil shale as an alternative resource for producing a jet fuel. The United States Bureau of Mines continued its research program at Anvil Point until 1956. It opened a demonstration mine which operated at a small scale. From 1949 to 1955 it also tested the gas combustion retort. In 1964 the Avril Point demonstration facility was leased by Colorado School of Mines and was used by Mobil-led consortium (Mobil, Humble, Continental, Amoco, Phillips and Sinclair) for further development of that type of retort. In 1953, Sinclair Oil Corporation developed an \"in-situ\" processing method using existing and induced fractures between vertical wells. In the 1960s, a proposal known as Project Bronco, was suggested for a modified \"in situ\" process which involved creation of a rubble chimney (a zone in the rock formation created by breaking the rock into fragments) using a nuclear explosive. This plan was abandoned by the Atomic Energy Commission in 1968. Companies developing experimental \"in-situ\" retorting processes also included Equity Oil, ARCO, Shell Oil and the Laramie Energy Technology Center.\n\nUnocal Corporation started the development of the Union process in the late 1940s, when the Union A retort was designed. This technology was tested between 1954 and 1958 at the company-owned tract in the Parachute Creek. This production was finally shut down in 1961 due to cost. In 1957 Texaco built a shale oil extraction pilot plant to develop its own hydroretorting process. In the early 1960s TOSCO (The Oil Shale Corporation) opened an underground mine and built an experimental plant near Parachute, Colorado. It was closed in 1972 because the price of production exceeded the cost of imported crude oil.\n\nDue to the 1973 oil crisis, the oil shale industry restarted in several countries. The United States Navy and the Office of Naval Petroleum and Oil Shale Reserves started evaluations of oil shale's suitability for military fuels, such as jet fuels, marine fuels and a heavy fuel oil. Shale-oil based JP-4 jet fuel was produced until the early 1990s, when it was replaced with kerosene-based JP-8. Seventeen companies led by Standard Oil of Ohio formed the Paraho Development Corporation to develop the Paraho process. Production started in 1974 but was closed in 1978. In 1974 the United States Department of the Interior announced an oil shale leasing program in the oil shale regions of Colorado and Utah. In 1980 the Synthetic Fuels Corporation was established which operated until 1985.\n\nIn 1972, the first modified \"in situ\" oil shale experiment in the United States was conducted by Occidental Petroleum at Logan Wash, Colorado. Rio Blanco Oil Shale Company, a partnership between Gulf Oil and Standard Oil of Indiana, originally considered using Lurgi–Ruhrgas above-ground retort but in 1977 switch also to the modified \"in-situ\" process. In 1985 the company ceased its operations. The White River Shale Corporation, a partnership of Sun Oil, Phillips and Sohio, existed between 1974 and 1986 for developing the tract in the Uintah Basin on the White River area.\n\nIn 1977, Superior Oil Company cancelled its Meeker shale oil plant project. Year later Ashland, Cleveland Cliffs and Sohio exited the Colony Shale Oil Project near Parachute, Colorado. Also, Shell exited the Colony project but continued with \"in-situ\" test. The United States oil shale industry collapsed when oil prices fell in the early 1980s. On 2 May 1982, known as \"Black Sunday\", Exxon cancelled the Colony project due to low oil-prices and increased expenses, laying off more than 2,000 workers. In 1986, President Ronald Reagan signed into law the Consolidated Omnibus Budget Reconciliation Act of 1985 which among other things abolished the United States' Synthetic Liquid Fuels Program. The last oil shale retort in the United States, operated by Unocal Corporation, was closed in 1991.\n\nBecause of the success of oil shale-based power generation, Estonian oil shale mining peaked in 1980 at 31.35 million tonnes and oil-shale-based power generation peaked at the same year at 18.9 TWh. The largest oil shale mine in the world – the Estonia Mine – was opened in 1972. In 1980 the Narva Oil Plant was commissioned. The industry declined during the two decades that followed this peak. Demand for locally produced electrical power was reduced by construction of nuclear power stations in the Soviet Union, particularly Leningrad Nuclear Power Station.\n\nIn Israel, a 0.1 MW pilot oil shale-fired power plant was tested in 1982–1986. A 12.5 MW fluidised-bed demonstration plant in Mishor Rotem became operational in 1989. In Romania, a 990 MW oil shale-fired power plant at Crivina operated in 1983–1988; however, it was decommissioned due to inefficiency and technical problems. In Brazil a 2,400 tons per day semi-works retort (the Irati Profile Plant) was brought on line in 1972, and began limited commercial operation in 1980. A pilot plant that used Petrosix technology started in 1982. It was followed by a demonstration plant in 1984. A commercial retort was brought into service in December 1991.\n\nThe global oil shale industry started to grow slightly in the mid-1990s although most of the industries were ceased in Russia. Oil-shale-fired power stations in Slantsy and Syzran were converted to use natural gas and fuel oil. Also, shale-oil producer \"Zavod Slantsy\" ceased oil-shale processing. Only Syzran processing plant continued using oil shale for production of ammonium bituminosulfonate.\n\nExisting shale oil extraction plants in Fushun and Moaming, China, were closed in the beginning of 1990s. However, the new shale oil plants in Fushun consist of 220 retorts and the annual capacity has increased up to 350,000 tonnes of shale oil. Several other projects have been developed in various locations. In 2005, China became the largest shale oil producer in the world with an increased number of companies involved in the shale oil extraction.\n\nAfter decrease in the beginning of 1990s Estonian oil shale production has continuously increased since 1995. Several new processing plants using modified Galoter technology have been built. In 2006, 90 years after major mining had begun, one billion tonnes were mined. Construction of the new 300 MW oil shale-fired power plant began in 2012.\n\nIn Australia, the Alberta Taciuk technology was used for a demonstration-scale processing plant at the Stuart Deposit near Gladstone, Queensland, which produced between 2000 and 2004 over of shale oil. In 2008–2009, the facility was dismantled and a new demonstration plant based on the Paraho II process was opened in September 2011.\n\nIn the United States, an oil shale development program was initiated in 2003. The Energy Policy Act of 2005 introduced a commercial leasing program for oil shale and tar sands resources on public lands within the states of Colorado, Utah, and Wyoming. In 2007, leases were awarded to Chevron Shale Oil, EGL Resources (now American Shale Oil), Oil Shale Exploration Company (now Enefit American Oil) and Shell Frontier Oil & Gas, and in 2010 to ExxonMobil, Natural Soda and AuraSource. Several other companies like Red Leaf Resources and TomCo Energy operates on the private leases. However, Chevron closed its Chevron CRUSH project in 2012 and Shell closed its Mahogany Research Project in 2013.\n\nSince 2006 the government of Jordan has signed a number of memorandum of understanding with foreign companies for shale oil production, including with Petrobras, and has signed concession agreements with Shell, Eesti Energia, Karak International Oil and Saudi Arabian International Corporation for Oil Shale Investment. In 2008, the Ministry of Energy and Mineral Resources of Jordan, the National Electricity Power Company of Jordan, and Eesti Energia signed an agreement to build the 460 MW oil shale-fired Attarat Power Plant.\n\nIn 2005 Morocco adopted a new strategy and legal framework for oil shale activities. Since then different agreements have been signed with a number of companies, including Petrobras, Total S.A. and San Leon Energy. In April 2010, the 4th Workshop on Regional Cooperation for Clean Utilization of Oil Shale was held in Egypt and later the same month an Oil Shale Cooperation Center was established in Amman by Egypt, Jordan, Morocco, Syria and Turkey. In 2011, Israel closed the Mishor Rotem Power Station.\n\nIn 2013, Uzbekistani national oil company Uzbekneftegaz started construction of the shale oil extraction plant on the Sangruntau oil shale deposit.\n\n\n"}
{"id": "21911792", "url": "https://en.wikipedia.org/wiki?curid=21911792", "title": "IP load tester", "text": "IP load tester\n\nIP load testers are a class of protocol analyzers focused on the practical evaluation of router performance. Router performance is usually broken down into two categories: forwarding performance (or data plane), and routing performance (or control plane). In practice, the two functions are often evaluated simultaneously.\n\nTo test forwarding performance, IP load testers typically surround a router with simulated Internet traffic. This function is called \"packet blasting\", and there are a couple of popular methods. The first method approximates real Internet traffic by using a representative mix of packet lengths, usually referred to as IMIX. Another popular technique is to blast the router with the shortest packet lengths possible, in order to stress the computational performance of the router. In both cases, the IP load tester measures the performance of the router in terms of loss, latency and throughput.\n\nTo test the control plane IP load testers typically emulate various protocols via the test ports in order to connect to the real implementations of those protocols on the router itself. For example, within the core of the Internet, various routing protocols are used for the control plane, or routing function of routers. Core routing protocols include BGP, IS-IS, OSPF, and RIP. Control plane performance is usually characterized by measurements of scalability and performance. Scalability typically means how many protocol sessions can be handled by the router at one time, and ultimately is a stress of memory. Performance usually refers to a time-varying parameter, such as sessions per second, and ultimately is a stress of CPU power.\n"}
{"id": "29529012", "url": "https://en.wikipedia.org/wiki?curid=29529012", "title": "JoAnn H. Morgan", "text": "JoAnn H. Morgan\n\nJoAnn Hardin Morgan (December 4, 1940) is an American aerospace engineer who was a trailblazer in the United States space flight program as the first female engineer at the National Aeronautics and Space Administration (NASA) John F. Kennedy Space Center and the first woman to serve as a senior executive at Kennedy Space Center. For her work at NASA, Morgan was honored by U.S. President Bill Clinton as a Meritorious Executive in 1995 and 1998. Prior to her retirement in 2003, she held various leadership positions over 40 years in the manned space flight programs at NASA. Morgan served as the director of the External Relations and Business Development during her final years at the space center.\n\nJoAnn Hardin, the oldest child of four children of Don and Laverne Hardin, was born in Huntsville, Alabama on December 4, 1940 near where her father was stationed as a U.S. Army pilot at Redstone Arsenal during World War Two. While she was in high school, her family relocated to Titusville, Florida where her father worked at Cape Canaveral as an ordnance administrator in the U.S. Army's rocket program. There she met her future husband, Larry Morgan. Immediately after graduating from high school in June 1958, she joined the Army Ballistic Missile Agency at Cape Canaveral as a civilian engineering aide. In the Fall of 1958, Hardin enrolled at the University of Florida in Gainesville where she studied mathematics. During her summer breaks, she continued to work at Cape Canaveral under mentors such as German-American engineer Wernher von Braun. In her work as an engineering aide, Hardin had hands on experience designing rocket launch computer systems for the initial NASA flight programs. After Hardin earned a Bachelor of Arts in mathematics at the Jacksonville State University in Alabama in 1963, she went to work for NASA at the Kennedy Space Center as an aerospace engineer.\n\nIn 1963, Morgan began full-time employment at Kennedy Space Center. She was the only female engineer, and she recalls that she \"would remain the only woman there for a long time.\" Morgan humorously notes that \"for the first 15 years, I worked in a building where there wasn't a ladies' rest room,\" and \"it was a big day in my book when there was one.\"\n\nMorgan was selected to receive a Sloan Fellowship to prepare her for a management position at the space center. She enrolled at Stanford University and earned a Masters of Science in 1977. Two years later she was promoted to the Chief of the Computer Services Division. Morgan served as the director of the External Relations and Business Development during her final years at the space center except for a brief stint in 2002 when she was appointed as acting deputy director of KSC for several months. Morgan retired in August 2003 with forty-five years of service to NASA.\n\nMorgan was honored by U.S. President Bill Clinton as a Meritorious Executive in 1995 and 1998. In 1995, she was inducted into the Florida Women's Hall of Fame. According to \"Orlando Business Journal\", \"during her career in the U.S. human space flight programs, Morgan has received many honors and awards, including an achievement award for her work during the activation of Apollo Launch Complex 39, four exceptional service medals, and two outstanding leadership medals.\" She received an Outstanding Leadership Medal in 1991 and 2001, the Society of Women Engineer's National \"Upward Mobility Award,\" and the American Society of Mechanical Engineers' \"J. Tal Webb Award\" in 1994, the \"Distinguished Service Award\" by the Space Coast Chapter of Federally Employed Women in 1996, the \"Achievement Award for Management Leadership\" by the 34th Annual Space Congress in 1998, the \"Debus Award\" from the National Space Club in 1998, and the \"1998 Presidential Distinguished Rank Award\". Morgan is a member of AIAA, the National Space Club, and Tau Beta Pi. Morgan was appointed to be a Trustee of the Florida state universities for two terms, in 2001 and 2003.\n\n"}
{"id": "54965230", "url": "https://en.wikipedia.org/wiki?curid=54965230", "title": "Joseph Palmer Frizell", "text": "Joseph Palmer Frizell\n\nJoseph Frizell (13 March 1832 - 4 May 1910) was an American engineer. He is notable for having independently derived the fundamental equations to describe the velocity of a shock wave (Water hammer equations) in 1898 and for his book Water-Power in 1901, which was the first practical book on hydraulics in the USA. I was a major milestone in the engienering knowledge, as Schutze wrote ″As an hydraulic engineer, Frizell was prominent, and his book, Waterpower, filled a definitive need in the technology of that day.″\n"}
{"id": "50591463", "url": "https://en.wikipedia.org/wiki?curid=50591463", "title": "JotForm", "text": "JotForm\n\nJotForm is a San Francisco-based online form building company. JotForm's software creates forms with a drag and drop creation tool and an option to encrypt user data. As of 2015, JotForm had 2 million registered users and 7,000 form templates. The forms can be integrated on external sites including MailChimp, PayPal, Stripe, and Salesforce.\n\nJotForm was founded in 2006 by Aytekin Tank. In 2011, JotForm released Wishbox, a feedback tool that annotates screenshots. By 2012, JotForm had over 700,000 users and published over 2 million user forms. JotForm released an Adobe Document Cloud eSign Widget in June 2015 for embedded esigning into forms.\n\nIn April 2016, JotForm announced that its software was available on Weebly. In December 2016, the company partnered with IFTTT to integrate an \"Applet\" to create forms in other applications. \"Tech Times\" recognized JotForm online form integration on Slack as one of the \"Best Productivity Apps\" of 2016.\n\nIn February 2012, the United States Secret Service shut down the JotForm site as part of an undisclosed investigation of user-created forms. After two days, the site was back up.\n"}
{"id": "28795220", "url": "https://en.wikipedia.org/wiki?curid=28795220", "title": "L'Aérophile", "text": "L'Aérophile\n\nL’Aérophile was a French aviation magazine published from 1893 to 1947. It has been described as \"the leading aeronautical journal of the world\" around 1910.\n\n\"L’Aérophile\" was founded and run for many years by Georges Besançon. In 1898 it became the official journal of the Aéro Club of France.\n\nImportant developments in early aviation were documented in its pages:\n\n\nHistorian Charles Gibbs-Smith criticised \"L’Aérophile\" for not publishing the official report on the tests of Clément Ader’s 1897 \"Avion III\" when this report was finally made public in 1910, and thus failing to oppose the claim that Ader's machine had made a controlled flight in 1897.\n\n\"L'Aérophile\" was a monthly publication in its first years, then started to come out twice a month in 1910.\n\nFrom 1893-4, \"L'Aérophile\" was associated with the Union aérophile de France.\nStarting at the end of 1898 it was the official journal of the Aero Club of France.\nIn later years it was also an official publication of the alumni association (Association des anciens élèves) of the French national aeronautical college (École nationale supérieure de l'aéronautique).\n\nSome early issues have been scanned and are available at archive.org thanks to the Smithsonian Institution Libraries.\nOther issues are online at google books.\n\nSome portion of the \"L'Aérophile\" archives are kept by the US Library of Congress.\n"}
{"id": "27731754", "url": "https://en.wikipedia.org/wiki?curid=27731754", "title": "LanSlide Gaming PCs", "text": "LanSlide Gaming PCs\n\nLanSlide Gaming PCs, LLC was founded in 2005 by a group of gamers tired of moving large gaming desktops to LAN parties. The company focuses on computers designed to be portable and sells a wide range of desktop gaming computers, all of which are built into cases with carrying handles for ease of transport. Each computer comes with a special backpack to hold everything needed to run a desktop computer with the exception of the computer case. In addition to portable computers, LanSlide Gaming PCs also sells a line of computers designed for 3D gaming.\n\nSmall Form Factor Computers: \nMid-Tower Computers: \n3D Gaming Computers:\n\nIn August, 2010 LaSlide Gaming PCs launched the \"Absolutely Free Computer Help Page\", which provides free computer support to the general public, regardless of their status as a customer of the company. The service allows users to submit gaming computer related questions and get answers from live people within approximately 48 hours. While the service is focused on questions about building, buying, and fixing gaming computers, it is completely open ended, allowing users to ask any computer related question and get an answer.\n\nLaSlide Gaming PCs holds patent pending status on a special backpack intended to make it easier to move a gaming set-up in one trip and avoid dropping or damaging desktop components during transit. The backpack is designed to hold and protect up to a 22″ widescreen monitor, extra-long gaming keyboard, mouse, headphones, surge protector, cables, and other miscellaneous paraphernalia need to run a desktop computer.\n\n\n\n"}
{"id": "53278977", "url": "https://en.wikipedia.org/wiki?curid=53278977", "title": "Language Server Protocol", "text": "Language Server Protocol\n\nThe Language Server Protocol (LSP) is an open, JSON-RPC-based protocol for use between source code editors or integrated development environments (IDEs) and servers that provide programming language-specific features. The goal of the protocol is to allow programming language support to be implemented and distributed independently of any given editor or IDE.\n\nThe Language Server Protocol was originally developed for Microsoft's Visual Studio Code and is now an open standard. On 2016 June 27, Microsoft announced a collaboration with Red Hat and Codenvy to standardize the protocol's specification. The protocol is supported and has been adopted by the three companies. Its specification is hosted and developed on GitHub.\n\nModern integrated development environments (IDEs) provide developers with sophisticated features like code completion, refactoring, navigating to a symbol's definition, syntax highlighting, and error and warning markers.\n\nFor example, in a text-based programming language, a programmer might want to rename a method codice_1. The programmer could either manually edit the respective source code files and change the appropriate occurrences of the old method name into the new name, or instead use an IDE's refactoring capabilities to make all the necessary changes automatically. To be able to support this style of refactoring, an IDE needs a sophisticated understanding of the programming language that the program's source is written in. A programming tool without a such an understanding—for example, one that performs a naive search-and-replace instead—could introduce errors. When renaming a codice_1 method, for example, the tool should not replace the partial match in a variable that might be called codice_3, nor should it replace the portion of a code comment containing the word \"already\". Neither should renaming a local variable codice_4, for example, end up altering similarly named variables in other scopes.\n\nConventional compilers or interpreters for a specific programming language are typically unable to provide these \"language services\", because they are written with the goal of either transforming the source code into object code or immediately executing the code. Additionally, language services must be able to handle source code that is not well-formed, e.g. because the programmer is in the middle of editing and has not yet finished typing a statement, procedure, or other construct. Additionally, small changes to a source code file which are done during typing usually change the semantics of the program. In order to provide instant feedback to the user, the editing tool must be able to very quickly evaluate the syntactical and semantical consequences of a specific modification. Compilers and interpreters therefore provide a poor candidate for producing the information needed for an editing tool to consume.\n\nPrior to the design and implementation of the Language Server Protocol for the development of Visual Studio Code, most language services were generally tied to a given IDE or other editor. In the absence of the Language Server Protocol, language services are typically implemented by utilizing a tool-specific extension API. Providing the same language service to another editing tool requires effort to adapt the existing code so that the service may target the second editor's extension interfaces.\n\nThe Language Server Protocol allows for decoupling language services from the editor so that the services may be contained within a general purpose \"language server\". Any editor can inherit sophisticated support for many different languages by making use of existing language servers. Similarly, a programmer involved with the development of a new programming language can make services for that language available to existing editing tools. Making use of language servers via the Language Server Protocol thus also reduces the burden on vendors of editing tools, because vendors do not need to develop language services of their own for the languages the vendor intends to support, as long as the language servers have already been implemented. The Language Server Protocol also enables the distribution and development of servers contributed by an interested third-party, such as end users, without additional involvement by either the vendor of the compiler for the programming language in use or the vendor of the editor to which the language support is being added.\n\nLSP is not restricted to programming languages, it can rather be used for any kind of text-based languages, like specifications or domain-specific languages (DSL).\n\nWhen a user edits one or more source code files using a language server protocol-enabled tool, the tool acts as a \"client\" that consumes the \"language services\" provided by a \"language server\". The tool may be a text editor or IDE and the language services could be e.g. refactoring, code completion, etc.\n\nThe client informs the server about what the user is doing, e.g. opening a file, inserting a character at a specific text position, etc. The client can also request the server to perform a language service, e.g. to format a specified range in the text document. The server answers a client's request with an appropriate response. For example, the formatting request is answered either by a response that transfers the formatted text to the client or by an error response containing details about the error.\n\nThe Language Server Protocol (LSP) defines the messages that are exchanged between client and language server:\n\nThe protocol does not make any provisions about how requests, responses and notifications are transferred between client and server. For example, client and server could be components within the same process exchanging JSON strings via method calls. They could also be different processes on the same or on different machines communicating via network sockets.\n\nA global language service registry, hosted by the Eclipse Foundation, should make language servers publicly available. Additionally, there are lists of LSP-compatible implementations, maintained by the community-driven Langserver.org or Microsoft.\n\n"}
{"id": "1052219", "url": "https://en.wikipedia.org/wiki?curid=1052219", "title": "List of DIN standards", "text": "List of DIN standards\n\nThis is an incomplete list of DIN standards.\n\nIccbhq din 0007\n\nDIN ISO 53438\n\n\n"}
{"id": "22228526", "url": "https://en.wikipedia.org/wiki?curid=22228526", "title": "List of French inventions and discoveries", "text": "List of French inventions and discoveries\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "12066349", "url": "https://en.wikipedia.org/wiki?curid=12066349", "title": "MAASP", "text": "MAASP\n\nMaximum Allowable Annulus Surface Pressure is an absolute upper limit for the pressure in the annulus of an oil and gas well as measured at the wellhead.\n\nPreserving well integrity is a vital task for the operators. This includes ensuring that the annuli remain intact. One major threat to annulus integrity is overpressure within the annulus, which could lead to burst or collapse of a casing or damage to the formation below. This will happen first at the shoe of the annulus because the pressure will naturally be higher with the weight of the column of brine. However, annuli usually only have pressure gauges at the wellhead. Therefore, a MAASP is calculated to provide a surface pressure, which will produce the limiting pressure at the shoe.\n\nThere are four different ways an annulus may be overpressured: burst of the outside casing, collapse of the inside casing, fracturing of the formation at the shoe, overpressure of the surface equipment. Each of these produces its own limiting pressure at the shoe. The MAASP is taken as the most limiting of these.\n\nThe following example is for the 'B' annulus of a gas lifted well, filled with 1.2 sg brine from the shoe at 4070ftTVD (true vertical depth) to surface.\n\nIn this well, the outside casing of the 'B' annulus is 13⅜\" N80 grade with a weight of . The burst pressure of this casing is 5020 psi. 1.2 sg brine produces a pressure gradient of 0.52 psi.ft (see Well kill for the mathematical basics of hydrostatic heads). Therefore, the column of brine produces a pressure difference between top and bottom of 2116 psi. Therefore, the pressure at the wellhead can reach 2904 psi before 5020 psi is reached at the bottom. Therefore, the MAASP for casing burst is 2904 psi.\n\nThe inside casing is 9⅝\" L80 . The collapse pressure of this casing is 4750 psi. Therefore, pressure at the shoe of the 'B' annulus cannot exceed this. Given a hydrostatic head of 2116 psi, the pressure at the wellhead must not exceed 2634 psi.\n\nGeologists will have logged fracture pressures of the formation as the well was drilled. This can be used to provide a limiting pressure much as before. If the cement used to cement the casing in place is still intact, fracturing the formation is not a hazard.\n\nWellheads usually have a pressure rating of 5000 psi, 10,000 psi or 15,000 psi. These are far in excess of the other limits. As such, surface equipment is not usually the limiting factor.\n\nCollapse of the 9⅝\" casing is clearly the limiting factor so the MAASP will be published as 2634 psi.\n\n"}
{"id": "6437480", "url": "https://en.wikipedia.org/wiki?curid=6437480", "title": "Meteosat visible and infrared imager", "text": "Meteosat visible and infrared imager\n\nThe Meteosat visible and infrared imager (or MVIRI) is the scientific instrument package on board the seven Meteosat first-generation geostationary meteorological satellites. This instrument is capable of capturing images in the visible, infrared, and water vapor regions of the electromagnetic spectrum.\n\n"}
{"id": "5807398", "url": "https://en.wikipedia.org/wiki?curid=5807398", "title": "Miniature inertial measurement unit", "text": "Miniature inertial measurement unit\n\nMiniature inertial measurement unit (MIMU) is an inertial measurement unit (IMU) developed and built by Honeywell International to control and stabilize spacecraft during mission operations. MIMUs can also be configured to perform as an inertial reference unit (IRU). MIMUs have been flown on GEO, Low Earth orbit (LEO), planetary missions and deep-space-probe applications.\n\n\n\n\n\n"}
{"id": "29192816", "url": "https://en.wikipedia.org/wiki?curid=29192816", "title": "Ministry of Information and Communication Technologies (Tunisia)", "text": "Ministry of Information and Communication Technologies (Tunisia)\n\nThe Ministry of Communication Technologies and Digital Economy of Tunisia () is a cabinet-level governmental agency in Tunisia in charge of organizing the sector, planning, control and supervision of activities directed at acquiring new technology and improving the communications sector in Tunisia.\n\nThe ministry is headed by the Minister aided by the Secretary of State for Information, Internet and Free Software.\nThe Cabinet of the ministry consists of several departments:\n\nMinistry is responsible for setting up strategic studies in the field of telecommunications; supervising research programs and industrial activities, and fitting them to the sector’s requirements; setting up the standards and specifications pertaining to the communications sector; introducing the technological progress in the context of the economic and social development plans; supervising investors and, where necessary, intervening in the concerned enterprises to help them obtain services that come under this sector in the best possible conditions; supervising agents’ activities in the field of telecommunications and postal services; establishing organizational and regulatory framework to ensure the sector operates correctly, and introducing the structural and functional changes required by the demands of efficiency and quality in this domain; developing international cooperation and partnership in the field of telecommunications.\n\n\n"}
{"id": "49150279", "url": "https://en.wikipedia.org/wiki?curid=49150279", "title": "Mubarak Muyika", "text": "Mubarak Muyika\n\nMubarak Muyika (born May 31, 1994, Western Province, Kenya), is a Kenyan American business executive, computer programmer and internet entrepreneur based in Silicon Valley. Orphaned at the age of 10, at age 16 Muyika founded Hype Century, a web hosting company which he sold two years later for six figures. He is the founder and CEO of Zagace, a company which runs an app store for businesses to access software for accounting, human resource management, marketing, among other uses.\n\n\"Forbes\" listed him as one of \"Forbes Africa\"s 30 under 30 both in 2015 and 2017, and he was youngest in Business Insider's list of top young entrepreneurs around the world.\n\nMubarak Muyika was born in Western Province, Kenya, and has one brother. His father was the district commissioner of Siaya, a senior civil servant, who died when Mubarak was 2, and mother a high school teacher who died when he was 11. Muyika was raised by his mother's sister and her husband in the suburbs of Nairobi.\n\nWhile a student at Friends School Kamusinga, Muyika won two awards in Kenya's national science fair, the annual Kenya Students Congress on Science and Technology:\n\nIn the fair's 48th edition in 2010, he won for a technical whitepaper titled \"'Kahunic infra-photo surveyor\"', which was presented as a computer talk, and was ranked first in that category. Muyika's whitepaper was based on Java, MySQL and C++ dependencies, infra-red and laser rays, and customized ray emitters to identify objects concealed behind concrete and wood, among other uses, by use of reflection and refraction.\n\nIn the fair's 49th edition the following year, Muyika won for a database he developed to manage the flow of petrol and movement of oil tankers. The project's original name in the fair was \"'Techno Fibre System\"', but it was also referred to as \"'Enhanced petrol tracker\"'. It was presented as a computer exhibit in the ICT category, and although Muyika was recognized as the best student in the category, the project was ranked third nationally in the category.\n\nHe graduated from Friend's School Kamusinga in 2011.\n\nHis adoptive parents operated a small book publishing and distribution company, Acrodile Publishers. Using online resources and technical experience gained in earlier years, Muyika built a better Website for the company.\n\nIn 2011, Muyika founded Hype Century Technologies & Investments Limited, a company focused on website creation and webhosting. The following year, for his work in HypeCentury, he received the Anzisha Prize for young entrepreneurs, from the African Leadership Academy.\n\nMuyika sold HypeCentury to Wemps Telecoms in a six figure deal in May 2013. By the time of the sale Hypecentury had 14 employees and was handling over 700 companies with 1400 domains. HypeCentury has since rebranded and is a fully owned subsidiary of Wemps Telecoms.\n\nLater in 2013, Muyika founded Zagace in Nairobi with proceeds from the sale of HypeCentury, with additional funding from investors. Zagace has since raised a number of angel investments from various investors.\n\nIn June 2015, Zagace's parent company was restructured as a Delaware-based parent corporation of the same name, with the company now based in San Jose, California.\n\n\n"}
{"id": "64020", "url": "https://en.wikipedia.org/wiki?curid=64020", "title": "Multiprocessing", "text": "Multiprocessing\n\nMultiprocessing is the use of two or more central processing units (CPUs) within a single computer system. The term also refers to the ability of a system to support more than one processor or the ability to allocate tasks between them. There are many variations on this basic theme, and the definition of multiprocessing can vary with context, mostly as a function of how CPUs are defined (multiple cores on one die, multiple dies in one package, multiple packages in one system unit, etc.).\n\nAccording to some on-line dictionaries, a multiprocessor is a computer system having two or more processing units (multiple processors) each sharing main memory and peripherals, in order to simultaneously process programs. A 2009 textbook defined multiprocessor system similarly, but noting that the processors may share \"some or all of the system’s memory and I/O facilities\"; it also gave tightly coupled system as a synonymous term.\n\nAt the operating system level, \"multiprocessing\" is sometimes used to refer to the execution of multiple concurrent processes in a system, with each process running on a separate CPU or core, as opposed to a single process at any one instant. When used with this definition, multiprocessing is sometimes contrasted with multitasking, which may use just a single processor but switch it in time slices between tasks (i.e. a time-sharing system). Multiprocessing however means true parallel execution of multiple processes using more than one processor. Multiprocessing doesn't necessarily mean that a single process or task uses more than one processor simultaneously; the term parallel processing is generally used to denote that scenario. Other authors prefer to refer to the operating system techniques as multiprogramming and reserve the term \"multiprocessing\" for the hardware aspect of having more than one processor. The remainder of this article discusses multiprocessing only in this hardware sense.\n\nIn Flynn's taxonomy, multiprocessors as defined above are MIMD machines. As they are normally construed to be tightly coupled (share memory), multiprocessors are not the entire class of MIMD machines, which also contains message passing multicomputer systems.\n\nPossibly the first expression of the idea of multiprocessing was written by Luigi Federico Menabrea in 1842, about Charles Babbage's analytical engine (as translated by Ada Lovelace): \"the machine can be brought into play so as to give several results at the same time, which will greatly abridge the whole amount of the processes.\"\n\nIn a multiprocessing system, all CPUs may be equal, or some may be reserved for special purposes. A combination of hardware and operating system software design considerations determine the symmetry (or lack thereof) in a given system. For example, hardware or software considerations may require that only one particular CPU respond to all hardware interrupts, whereas all other work in the system may be distributed equally among CPUs; or execution of kernel-mode code may be restricted to only one particular CPU, whereas user-mode code may be executed in any combination of processors. Multiprocessing systems are often easier to design if such restrictions are imposed, but they tend to be less efficient than systems in which all CPUs are utilized.\n\nSystems that treat all CPUs equally are called symmetric multiprocessing (SMP) systems. In systems where all CPUs are not equal, system resources may be divided in a number of ways, including asymmetric multiprocessing (ASMP), non-uniform memory access (NUMA) multiprocessing, and clustered multiprocessing.\n\nIn a master/slave multiprocessor system, the master CPU is in control of the computer and the slave CPU(s) performs assigned tasks. The CPUs can be completely different in terms of speed and architecture. Some (or all) of the CPUs can have share common bus, each can also have a private bus (for private resources), or they may be isolated except for a common communications pathway. Likewise, the CPUs can share common RAM and/or have private RAM that the other processor(s) cannot access. The roles of master and slave can change from one CPU to another.\n\nAn early example of a master/slave multiprocessor system is the Tandy/Radio Shack TRS-80 Model 16 desktop computer which came out in February 1982 and ran the multi-user/multi-tasking Xenix operating system, Microsoft's version of UNIX (called TRS-XENIX). The Model 16 has 3 microprocessors, an 8-bit Zilog Z80 CPU running at 4MHz, a 16-bit Motorola 68000 CPU running at 6MHz and an Intel 8021 in the keyboard. When the system was booted, the Z-80 was the master and the Xenix boot process initialized the slave 68000, and then transferred control to the 68000, whereupon the CPUs changed roles and the Z-80 became a slave processor that was responsible for all I/O operations including disk, communications, printer and network, as well as the keyboard and integrated monitor, while the operating system and applications ran on the 68000 CPU. The Z-80 could be used to do other tasks.\n\nThe earlier TRS-80 Model II, which was released in 1979, could also be considered a multiprocessor system as it had both a Z-80 CPU and an Intel 8021 microprocessor in the keyboard. The 8021 made the Model II the first desktop computer system with a separate detachable lightweight keyboard connected with by a single thin flexible wire, and likely the first keyboard to use a dedicated microprocessor, both attributes that would later be copied years later by Apple and IBM.\n\nIn multiprocessing, the processors can be used to execute a single sequence of instructions in multiple contexts (single-instruction, multiple-data or SIMD, often used in vector processing), multiple sequences of instructions in a single context (multiple-instruction, single-data or MISD, used for redundancy in fail-safe systems and sometimes applied to describe pipelined processors or hyper-threading), or multiple sequences of instructions in multiple contexts (multiple-instruction, multiple-data or MIMD).\n\nTightly coupled multiprocessor systems contain multiple CPUs that are connected at the bus level. These CPUs may have access to a central shared memory (SMP or UMA), or may participate in a memory hierarchy with both local and shared memory (SM)(NUMA). The IBM p690 Regatta is an example of a high end SMP system. Intel Xeon processors dominated the multiprocessor market for business PCs and were the only major x86 option until the release of AMD's Opteron range of processors in 2004. Both ranges of processors had their own onboard cache but provided access to shared memory; the Xeon processors via a common pipe and the Opteron processors via independent pathways to the system RAM.\n\nChip multiprocessors, also known as multi-core computing, involves more than one processor placed on a single chip and can be thought of the most extreme form of tightly coupled multiprocessing. Mainframe systems with multiple processors are often tightly coupled.\n\nLoosely coupled multiprocessor systems (often referred to as clusters) are based on multiple standalone single or dual processor commodity computers interconnected via a high speed communication system (Gigabit Ethernet is common). A Linux Beowulf cluster is an example of a loosely coupled system.\n\nTightly coupled systems perform better and are physically smaller than loosely coupled systems, but have historically required greater initial investments and may depreciate rapidly; nodes in a loosely coupled system are usually inexpensive commodity computers and can be recycled as independent machines upon retirement from the cluster.\n\nPower consumption is also a consideration. Tightly coupled systems tend to be much more energy efficient than clusters. This is because considerable economy can be realized by designing components to work together from the beginning in tightly coupled systems, whereas loosely coupled systems use components that were not necessarily intended specifically for use in such systems.\n\nLoosely coupled systems have the ability to run different operating systems or OS versions on different systems.\n\n"}
{"id": "3568175", "url": "https://en.wikipedia.org/wiki?curid=3568175", "title": "Nested polymerase chain reaction", "text": "Nested polymerase chain reaction\n\nNested polymerase chain reaction (Nested PCR) is a modification of polymerase chain reaction intended to reduce non-specific binding in products due to the amplification of unexpected primer binding sites.\n\nPolymerase chain reaction itself is the process used to amplify DNA samples, via a temperature-mediated DNA polymerase. The products can be used for sequencing or analysis, and this process is a key part of many genetics research laboratories, along with uses in DNA fingerprinting for forensics and other human genetic cases. Conventional PCR requires primers complementary to the termini of the target DNA. The amount of product from the PCR increases with the number of temperature cycles that the reaction is subjected to. A commonly occurring problem is primers binding to incorrect regions of the DNA, giving unexpected products. This problem becomes more likely with an increased number of cycles of PCR.\n\nNested polymerase chain reaction involves two sets of primers, used in two successive runs of polymerase chain reaction, the second set intended to amplify a secondary target within the first run product. This allows amplification for a low number of runs in the first round, limiting non-specific products. The second nested primer set should only amplify the intended product from the first round of amplification and not non-specific product. This allows running more total cycles while minimizing non-specific products. This is useful for rare templates or PCR with high background.\n\nThe target DNA undergoes the first run of polymerase chain reaction with the first set of primers, shown in green. The selection of alternative and similar primer binding sites gives a selection of products, only one containing the intended sequence.\n\nThe product from the first reaction undergoes a second run with the second set of primers, shown in red. It is very unlikely that any of the unwanted PCR products contain binding sites for both the new primers, ensuring the product from the second PCR has little contamination from unwanted products of primer dimers, hairpins, and alternative primer target sequences.\n"}
{"id": "5889117", "url": "https://en.wikipedia.org/wiki?curid=5889117", "title": "Perfboard", "text": "Perfboard\n\nPerfboard is a material for prototyping electronic circuits (also called DOT PCB). It is a thin, rigid sheet with holes pre-drilled at standard intervals across a grid, usually a square grid of spacing. These holes are ringed by round or square copper pads, though bare boards are also available. Inexpensive perfboard may have pads on only one side of the board, while better quality perfboard can have pads on both sides (plate-through holes). Since each pad is electrically isolated, the builder makes all connections with either wire wrap or miniature point to point wiring techniques. Discrete components are soldered to the prototype board such as resistors, capacitors, and integrated circuits. The substrate is typically made of paper laminated with phenolic resin (such as FR-2) or a fiberglass-reinforced epoxy laminate (FR-4).\n\nThe grid system accommodates integrated circuits in DIP packages and many other types of through-hole components. Perfboard is not designed for prototyping surface mount devices.\n\nBefore building a circuit on perfboard, the locations of the components and connections are typically planned in detail on paper or with software tools. Small scale prototypes, however, are often built ad hoc, using an oversized perfboard.\n\nSoftware for PCB layout can often be used to generate perfboard layouts as well. In this case, the designer positions the components so all leads fall on intersections of a grid. When routing the connections more than 2 copper layers can be used, as multiple overlaps are not a problem for insulated wires.\n\nOnce the layout is finalized, the components are soldered in their designated locations, paying attention to orientation of polarized parts such as electrolytic capacitors, diodes, and integrated circuits. Next, electrical connections are made as called for in the layout.\n\nOne school of thought is to make as many connections as possible without adding extra wire. This is done by bending the existing leads on resistors, capacitors, etc. into position, trimming off extra length, and soldering the lead to make the required electrical connection. Another school of thought refuses to bend the excessive leads of components and use them for wiring, on the ground that this makes removing a component later hard or impossible, e.g. when a repair is needed.\n\nIf extra wires need to be used, or are used for principal reasons, they are typically routed entirely on the copper side of perfboards, because, as opposed to stripboards, nearby holes aren't connected, and the only hole in a pad is already occupied by a component's lead. Wires used range from isolated wires, including verowire (enameled copper wire with a polyurethane insulation supposed to melt when soldered), to bare copper wire, depending on individual preference, and often also on what is currently at hand in the workshop.\n\nFor insulated wires thin solid core wire with temperature-resistant insulation such as Kynar or Tefzel is preferred. The wire gauge is typically 24 - 30 AWG. A special stripping tool can be used, incorporating a thin steel blade with a slit that the wire is simply inserted into and then pulled loose, leaving a clean stripped end. This wire was developed initially for circuit assembly by the wire wrap technique but also serves well for miniature point-to-point wiring on perfboard. Bare copper wire is useful when merging a number of connections to form an electrical bus such as the circuit's ground, and when there is enough space to properly route connections, instead of wiring them rats-nest style.\n\nIntentional solder bridges can be used to connect adjacent pads when necessary. Careful hand–eye coordination is needed to avoid causing inadvertent short circuits.\n\nCircuits assembled on perfboard are not necessarily fragile but may be less impact-resistant than printed circuit boards.\n\nPerfboard differs from stripboard in that each pad on perfboard is isolated. Stripboard is made with rows of copper conductors that form default connections, which are broken into isolated segments as required by scraping through the copper. This is similar to the pattern of default connections on a solderless breadboard. However, the absence of default connectivity on perfboard gives the designer more freedom in positioning components and lends itself more readily to software-aided design than stripboard or breadboard.\n\n"}
{"id": "29678719", "url": "https://en.wikipedia.org/wiki?curid=29678719", "title": "Radiant cooling", "text": "Radiant cooling\n\nRadiant cooling is the use of cooled surfaces to remove sensible heat by radiation and convection. It is related to radiant heating. Radiant systems that use water to cool the radiant surfaces are called hydronic systems. Unlike “all-air” air conditioning systems that circulate cooled air only, hydronic radiant systems circulate cooled water in pipes through specially-mounted panels or a building’s floor or ceiling to provide comfortable temperatures. There is a separate system to provide air for ventilation, dehumidification, and potentially additionally cooling. Radiant systems are less common than all-air systems for cooling, but can have advantages compared to all-air systems in some applications.\n\nSome well-known buildings using radiant cooling include Bangkok’s Suvarnabhumi Airport, the Infosys Software Development Building 1 in Hyderabad, IIT Hyderabad, and the San Francisco Exploratorium. Radiant cooling is also used as a design strategy in some net zero energy buildings.\n\nBy definition, radiant cooling systems primarily remove sensible heat through thermal radiation. ASHRAE defines radiant systems as temperature-controlled surfaces where 50% or more of the design heat transfer takes place by thermal radiation.\n\nThermal (longwave) radiation travels at the speed of light, in straight lines. It can be reflected. People, equipment, and surfaces in buildings will warm up if they absorb thermal radiation, but the radiation does not noticeably heat up the air it is traveling through. This means heat will flow from objects, occupants, equipment, and lights in a space to a cooled surface as long as their temperatures are warmer than that of the cooled surface and they are within the direct or indirect line of sight of the cooled surface. Some heat is also removed by convection because the air temperature will be lowered when air comes in contact with the cooled surface.\n\nRadiant heating systems have been used for thousands of years, notably in ancient Korea, China, and Rome. Hydronic radiant cooling systems are relatively more recent. Early radiant cooling systems were installed in the late 1930s and 40's in Europe and by the 1950s in the US. They became more common in Europe in the 1990s and continue to be used today.\n\nRadiant cooling systems are usually hydronic, cooling using circulating water running in pipes in thermal contact with the surface. Typically the circulating water only needs to be 2–4 °C below the desired indoor air temperature. Once having been absorbed by the actively cooled surface, heat is removed by water flowing through a hydronic circuit, replacing the warmed water with cooler water.\n\nSince the majority of the cooling process results from removing sensible heat through radiant exchange with people and objects and not air, occupant thermal comfort can be achieved with warmer interior air temperatures than with air based cooling systems. As a result of the high cooling capacity of water, and the delivery of a cooled surface close to the desired indoor air temperature, radiant cooling systems potentially offer reductions in cooling energy consumption. The latent loads (humidity) from occupants, infiltration and processes generally need to be managed by an independent system. Radiant cooling may also be integrated with other energy-efficient strategies such as night time flushing, indirect evaporative cooling, or ground source heat pumps as it requires a small difference in temperature between desired indoor air temperature and the cooled surface.\n\nWhile there are a broad range of system technologies, there are two primary types of radiant cooling systems. The first type is systems that deliver cooling through the building structure, usually slabs. These systems are also named thermally activated building systems (TABS). The second type is systems that deliver cooling through specialized panels. Systems using concrete slabs are generally cheaper than panel systems and offer the advantage of thermal mass, while panel systems offer faster temperature control and flexibility.\n\nRadiant cooling from a slab can be delivered to a space from the floor or ceiling. Since radiant heating systems tend to be in the floor, the obvious choice would be to use the same circulation system for cooled water. While this makes sense in some cases, delivering cooling from the ceiling has several advantages.\n\nFirst, it is easier to leave ceilings exposed to a room than floors, increasing the effectiveness of thermal mass. Floors offer the downside of coverings and furnishings that decrease the effectiveness of the system.\n\nSecond, greater convective heat exchange occurs through a chilled ceiling as warm air rises, leading to more air coming in contact with the cooled surface.\n\nCooling delivered through the floor makes the most sense when there is a high amount of solar gain from sun penetration, because the cool floor can more easily remove those loads than the ceiling.\n\nChilled slabs, compared to panels, offer more significant thermal mass and therefore can take better advantage of outside diurnal temperatures swings. Chilled slabs cost less per unit of surface area, and are more integrated with structure.\n\nRadiant cooling panels are generally attached to ceilings, but can be attached to walls also. They are usually suspended from the ceiling, but can also be directly integrated with continuous dropped ceilings. Modular construction offers increased flexibility in terms of placement and integration with lighting or other electrical systems. Lower thermal mass compared to chilled slabs means they can’t easily take advantage of passive cooling from thermal storage, but controls in panels can more quickly adjust to changes in outdoor temperature. Chilled panels are also better suited to buildings with spaces that have a greater variance in cooling loads. Perforated panels also offer better acoustical dampening than chilled slabs. Ceiling panels are also very suitable for retrofits because they can be attached to any ceiling. Chilled ceiling panels can be more easily integrated with ventilation supplied from the ceiling. Panels tend to cost more per unit of surface area than chilled slabs.\n\nRadiant cooling systems offer lower energy consumption than conventional cooling systems based on research conducted by the Lawrence Berkeley National Laboratory. Radiant cooling energy savings depend on the climate, but on average across the US savings are in the range of 30% compared to conventional systems. Cool, humid regions might have savings of 17% while hot, arid regions have savings of 42%. Hot, dry climates offer the greatest advantage for radiant cooling as they have the largest proportion of cooling by way of removing sensible heat. While this research is informative, more research needs to be done to account for the limitations of simulation tools and integrated system approaches. Much of the energy savings is also attributed to the lower amount of energy required to pump water as opposed to distribute air with fans. By coupling the system with building mass, radiant cooling can shift some cooling to off-peak night time hours. Radiant cooling appears to have lower first costs and lifecycle costs compared to conventional systems. Lower first costs are largely attributed to integration with structure and design elements, while lower life cycle costs result from decreased maintenance. However, a recent study on comparison of VAV reheat versus active chilled beams & DOAS challenged the claims of lower first cost due to added cost of piping \n\nBecause of the potential for condensate formation on the cold radiant surface (resulting in water damage, mold and the like), radiant cooling systems have not been widely applied. Condensation caused by humidity is a limiting factor for the cooling capacity of a radiant cooling system. The surface temperature should not be equal or below the dew point temperature in the space. Some standards suggest a limit for the relative humidity in a space to 60% or 70%. An air temperature of 26 °C (79 °F) would mean a dew point between 17 °C and 20 °C (63 °F and 68 °F). There is, however, evidence that suggests decreasing the surface temperature to below the dew point temperature for a short period of time may not cause condensation. Also, the use of an additional system, such as a dehumidifier or DOAS, can limit humidity and allow for increased cooling capacity.\n\nASHRAE Handbook. HVAC Systems and Equipment 2012. Chapter 13. Hydronic Heating and Cooling.\n\nASHRAE Handbook. HVAC Systems and Equipment 2008. Chapter 12. Hydronic Heating and Cooling System Design.\n\nKessling, W., Holst, S., Schuler, M. Innovative Design Concept for the New Bangkok International Airport, NBIA.\n\nOlesen, B.W. Radiant Heating and Cooling by Water-based systems. Technical University of Denmark, International Centre for Indoor Environment and Energy.\n"}
{"id": "35985905", "url": "https://en.wikipedia.org/wiki?curid=35985905", "title": "Satmap", "text": "Satmap\n\nSatmap Systems Limited is a United Kingdom company founded on 19 October 2005 and based in Leatherhead, Surrey. Since 2007 it has produced a standalone handheld GPS satellite navigation mapping device for use by walkers, cyclists, mountain rescue, emergency services and the military.\n\nThe Active 10 available since 2007 is sold in four different bundles:\n\n\nThe Active 12 introduced in 2014 is more technically advanced than the Active 10 with a High-Resolution 320x488 pixel HVGA screen, doubled RAM, Bluetooth and a barometric altimeter and it is supplied with a high resolution UK GB 1:50,000 map. It is virtually identical in appearance to the Active 10 but is distinguishable by its orange buttons.\n\nAccessories include a vehicle mount, silicone protective cases and screen covers. It is necessary to swap the caddy holding the batteries to change the power source. Detailed maps can be loaded on to the device by inserting an SD card into the side, 350 map titles from 13 countries are available including; 1:25,000 and 1:50,000 scale Ordnance Survey maps, Harvey Maps, a 1:16,000 A-Z street maps of London and other UK cities, marine maps, United States, Canada, Australia, Europe and Morocco maps.\n\n"}
{"id": "313566", "url": "https://en.wikipedia.org/wiki?curid=313566", "title": "Scandinavian Multi Access Reservations for Travel Agents", "text": "Scandinavian Multi Access Reservations for Travel Agents\n\nSMART, Scandinavian Multi Access Reservations for Travel Agents, is a computerized system for ticket reservation. \n\nIt was created in 1979 by SAS, Braathens and Swedish State Railways. Many travel companies had computerized their systems at the time, and provided terminal interfaces for travel agencies. Each had their own system, often involving widely different codes and procedures. It was cumbersome and expensive for a travel agency to have multiple terminals, each one connected to a different provider. SMART solved this, by providing a single interface over the public data network Datex. \n\nIt worked by having a Host Interface Processor (HIP) at each travel company. These would emulate a number of terminals, translate the messages, codes and addresses, wrap them in SMARTs own communications protocol, and provide the interface over Datex to the various travel agencies. There was, of course, functionality to limit access. \n\nOn the travel agency side, there would be SMART Terminal Equipment (STE) with the reverse function, emulating a server and providing interfaces for terminals. Now however, a travel agent could easily switch between screens for the different companies. The interfaces were similar to those for direct connections, but provided some standardization for codes to ease the transition between the systems.\n\nThe STE would also allow printing of documents, tickets, bills and similar, as well as interfacing with the accounting system.\n\nSMART could utilize some of Datex extra features like queuing and group numbers, and a logical connection (session) was not dependent on the physical connection (which could go up and down for instance during idle times to save money). Parallel sessions could be held with different or the same provider.\n\nSMART spawned off into a company centered in Stockholm in 1984, SMART AB, with the subsidiaries SMART Sverige AB, SMART Danmark A/S, and SMART Norge AS (in Sweden, Denmark and Norway respectively).\n\nSMART is still in use, though not over Datex. It has been widely replaced by Amadeus, by the same company. In 2003, SMART AB changed its name to Amadeus Scandinavia.\n\n"}
{"id": "44290857", "url": "https://en.wikipedia.org/wiki?curid=44290857", "title": "Scott and Roberts Dry Cleaning Plant, Office, and Store", "text": "Scott and Roberts Dry Cleaning Plant, Office, and Store\n\nScott and Roberts Dry Cleaning Plant, Office, and Store is a historic dry cleaning plant, office, and store located at Durham, Durham County, North Carolina. It was built in 1947, and is a one-story, three bay Moderne brick building on a partial concrete basement. It features a projecting center bay, plate-glass storefront windows, and a centered front entrance with original glass-block entrance surround.\n\nIt was listed on the National Register of Historic Places in 2012.\n"}
{"id": "19032220", "url": "https://en.wikipedia.org/wiki?curid=19032220", "title": "Space archaeology", "text": "Space archaeology\n\nIn archaeology, space archaeology is the research-based study of various human-made items found in space, their interpretation as clues to the adventures mankind has experienced in space, and their preservation as cultural heritage.\n\nIt includes launch complexes on Earth, orbital debris, satellites, and objects and structures on other celestial bodies such as Mars. It also includes the applied field of cultural resource which evaluates the significance of space sites and objects in terms of national and international preservation laws. Cultural resource looks at what, how and why these artifacts of our recent history should be preserved for future generations.\n\nSpace tourism could affect archaeological artifacts, for example, on the Moon. The notion that cultural heritage is at stake and requires action to prevent deterioration or destruction is gaining ground. Perhaps artifacts (say, antiquated space stations) could be preserved in \"museum orbit\". Many such artifacts have been lost because they were not recognized and assessed. Experts assert that continuity and connection to the past are vital elements of survival in the modern world. A model has been suggested for international cooperation based upon Antarctica. Implications for cooperation interest anthropologists as well.\n\nAn unexpected ramification of this work is the development of techniques for detecting signs of life or technology on other planets, or extraterrestrial visitation on Earth. One facet of this work is the use of satellites for identifying structures of archeological significance.\n\nSatellites are key artifacts in examining human encounters with space over time and the effect we leave through artificial objects. This list includes:\n\nSatellites are just one example of several human traces we leave behind in, and out of this world.\n\nThe complexities and ambiguities of international legal structures to deal with these sites as cultural resources leave them vulnerable to impacts in the near future by many varieties of space travel. An outline of the legal situation was made by Harrison Schmitt and Neil Armstrong, both of them astronauts who walked on the moon as part of the Apollo program. The governing law on the Moon and other celestial bodies is the \"Outer Space Treaty\" of 1967 based upon guidelines from experience in the Antarctic. Another source of ideas is the \"Law of the Sea\". The \"Outer Space Treaty\" contains language stating that space objects remain under the jurisdiction of the originating state, and the civil and criminal laws of that state govern private parties both on the Moon and \"events leading up to such activity\". State parties are to inform the public about the nature and result of their activities.\n\nThe later \"Moon Agreement\" of 1979 was signed but not ratified by many spacefaring nations. Schmitt and Armstrong believe this lack of ratification relates to disagreement over wording such as \"the Moon and its natural resources are the common heritage of mankind\", which is taken as possibly excluding private activity, and objections to wording concerning the disruption of the existing environment.\nA non-profit organization called For All Moonkind, Inc. is working to establish legal protections for archaeological sites in outer space. The entirely volunteer group includes space lawyers and policymakers from around the world. As a result of their efforts, the United Nations Committee on the Peaceful Uses of Outer Space agreed, in January 2018, to consider the creation of a \"universal space heritage sites program.\". Having created a discussion around preservation in outer space, For All Moonkind is now focused on preparing drafts of implementing regulations and protocols.\n\nDuring a graduate seminar at New Mexico State University in 1999, Ralph Gibson asked: \"Does federal preservation law apply on the moon?\" That question led to Gibson's thesis \"Lunar Archaeology: The Application of Federal Historic Preservation Law to the Site where Humans first set foot upon the Moon\", to a grant from the New Mexico Space Grant Consortium, and to creation of the Lunar Legacy Project.\n\nA manuscript by scientists at NASA and ESA in 2004 raised the possibility of preserving Apollo landing sites for future \"astroarcheologists.\"\n\nIn 2006, Dr. O’Leary with New Mexico State Historic Preservation Officer Katherine Slick and the New Mexico Museum of Space History (NMMSH), documented the Apollo 11 Tranquility Base archaeological site on the Moon. Some legal aspects of this work already have surfaced.\n\nThough its mission isn't primarily archaeological, the Lunar Reconnaissance Orbiter has imaged all of the Apollo landing sites as well as rediscovering the location of the first Lunokhod 1 rover, lost since 1971 (note: all of the U. S. flags left on the moon during the Apollo missions were found to still be standing, with the exception of the one left during the Apollo 11 mission, which was blown over during that mission's lift-off from the lunar surface and return to the mission command module in lunar orbit; the degree to which these flags are preserved and intact remains unknown).\n\nBased on an idea by British amateur astronomer Nick Howes, a team of experts has been assembled to try to locate the Lunar Module of the Apollo 10 mission nicknamed \"Snoopy\", which was released during the mission and is currently thought to be in a heliocentric orbit. The Snoopy mission is encouraged by the 2002 re-sighting of the Apollo 12 third-stage rocket.\n\nSpace\n\nHeritage\nLegal documents\n\n"}
{"id": "27577809", "url": "https://en.wikipedia.org/wiki?curid=27577809", "title": "Spaceborne Imaging Radar", "text": "Spaceborne Imaging Radar\n\nThe Spaceborne Imaging Radar (SIR) – full name 'Spaceborne Imaging Radar-C/X-band Synthetic Aperture Radar (SIR-C/X-SAR)', is a synthetic aperture radar which flew on two separate shuttle missions. Once from the Space Shuttle Endeavour in April 1994 on (STS-59) and again in October 1994 on (STS-68). The radar was run by NASA's Space Radar Laboratory. SIR utilizes 3 radar frequencies: L band (24 cm wavelength), C band (6 cm) and X band (3 cm), allowing for study of geology, hydrology, ecology and oceanography. Comparing radar images to data collected by teams of people on the ground as well as aircraft and ships using simultaneous measurements of vegetation, soil moisture, sea state, snow and weather conditions during each flight. The imaging radar was able to take images anytime regardless of clouds cover. The Radar-C system was built and operated by NASA's Jet Propulsion Laboratory (JPL). The mission was a joint work of NASA with the German and Italian space agencies. Each of the week long mission scanned about 50 million square kilometers of the Earth's surface, (19.3 million square miles).\n\nThe SIR mission revealed hidden river channels in the Sahara Desert indicating significant climate change in the past. SIR was also used for volcano research by keeping researchers a safe distance from hazardous and often inaccessible areas. The radar was also used to generate detailed three dimensional mappings of the Earth's surface.\n\nRadar also found temples in Angkor, and ancient segments of China's Great Wall.\n\n\n"}
{"id": "41285425", "url": "https://en.wikipedia.org/wiki?curid=41285425", "title": "Threshers, pedal powered", "text": "Threshers, pedal powered\n\nThreshing is a key part of agriculture that involves removing the seeds or grain from plants (for example rice or wheat) from the plant stalk. In the case of small farms, threshing is done by beating or crushing the grain by hand or foot, and requires a large amount of hard physical labour. A simple thresher with a crank can be used to make this work much easier for the farmer. In most cases it takes two people to work these: one person to turn the crank and the other to feed the grain through the machine. These threshers can be built using simple materials and can improve the efficiency of grain threshing. They can also be built with pedals, or be attached to a bicycle, so that the person operating it can simply pedal to reduce the work even more and make threshing faster.\n\nThreshers can be made in a number of ways using simple tools, and can be used in the harvesting of maize/corn, rice, wheat, sorghum, pearl millet, and any other grain or seed that must be separated from a stalk. The attachment of a thresher to a pedal-system can be built with basic materials. Two versions are the pedal-powered thresher which is built as one piece and the attachment to a bicycle for a regular thresher with a crank. Pedal-powered threshers have been suggested or made available to farming communities by governmental or non-governmental organizations. It should be remembered that there are some disadvantages to these threshers and their impact in the specific region should be researched before being suggested.\n\nThresher are many different designs for threshers and they can be made from wood or metal. The shape of the thresher can vary, but it must include some main parts:\n\nAn addition that can be built to make a thresher more efficient is to make it pedal-powered. This adds two more parts:\nThe pedal-powered thresher developed by the Maya Pedal Project provides a good example of a built-in pedal system to a thresher/mill.\n\nAn attachment to a regular bicycle can be built to allow the bike to be used as the seat, pedals, chain and sprocket of the thresher. The bicycle must be on a stand so that the back wheel is raised off the ground. Plans have been developed to build the attachment and the wheel-stand out of pieces of metal, including a large wheel that can be screwed to the crank section of the thresher (see External links). A drill will be required to make this as well.\n\nAdvantages of the thresher include less physical labour and more efficiency (amount of grain thresher per amount of time). Less seed breakage is also a benefit of using a thresher as opposed to stomping or beating grains. However, more breakage can occur it is not used properly.\n\nCultural differences must be considered. Introduction of machinery to the threshing process, and the way that the pedal-powered thresher is used have conflicted with cultural beliefs or practices in some cases. The preferences of the region must be taken into consideration.\n\nThere are physical dangers involved in introducing machinery into a farming process; one of these is injury to hands and arms when feeding the stalks into the thresher. When building the thresher, creating a higher hood/chute cover helps stop the operator’s hands from contacting the machine, but does not entirely eliminate the danger.\n\nSeeds can be broken and ruined as they go through the thresher, and seed breakage can happen more often with threshers that are the wrong size or design for the type of seed. The wire loops or spikes may have to be adjusted if seeds appear to be broken (\"please see suggestion for spacing\"). Seed breakage also happens with stomping and beating, however if the thresher is not built in an appropriate way for the specific grain, more breakage may occur. If the thresher is well-suited for the size of the grain and stalks, it should have fewer broken seeds than beating or stomping. The most common seed breakage with threshers is with corn/maize, when there is too much moisture in the kernels. This can be reduced by drying kernels more thoroughly before threshing.\n\nThe size and weight of the thresher can be problematic. The thresher may need to be carried, and therefore must be light enough for one person. The suggested weight is 35 kg. On hillside farms it may be difficult to transport the thresher or to set it up properly.\n\n\n"}
{"id": "152692", "url": "https://en.wikipedia.org/wiki?curid=152692", "title": "Tractor", "text": "Tractor\n\nA tractor is an engineering vehicle specifically designed to deliver at a high tractive effort (or torque) at slow speeds, for the purposes of hauling a trailer or machinery used in agriculture or construction. Most commonly, the term is used to describe a farm vehicle that provides the power and traction to mechanize agricultural tasks, especially (and originally) tillage, but nowadays a great variety of tasks. Agricultural implements may be towed behind or mounted on the tractor, and the tractor may also provide a source of power if the implement is mechanised.\n\nThe word \"tractor\" was taken from Latin, being the agent noun of \"trahere\" \"to pull\". The first recorded use of the word meaning \"an engine or vehicle for pulling wagons or ploughs\" occurred in 1896, from the earlier term \"traction engine\" (1859).\n\nIn the UK, the Republic of Ireland, Australia, India, Spain, Argentina, Slovenia, Serbia, Croatia, the Netherlands, and Germany, the word \"tractor\" usually means \"farm tractor\", and the use of the word \"tractor\" to mean other types of vehicles is familiar to the vehicle trade, but unfamiliar to much of the general public. In Canada and the US, the word may also refer to the road tractor portion of a tractor trailer truck, but also usually refers to the piece of farm equipment.\n\nAlthough there are many tractors that look similar to each other, there are hundreds of different manufacturers of these tractors. These manufacturers produce many different models of tractor for different requirements on different farms in different countries. In other words, they can be tailor made to suit their purpose. Some of the many tractor manufacturers worldwide include:\n\n\nThese are some of the many tractor manufacturers. However, there have been hundreds more over the past few decades that no longer exist/manufacture tractors anymore.\n\nThe first powered farm implements in the early 19th century were portable engines – steam engines on wheels that could be used to drive mechanical farm machinery by way of a flexible belt. Richard Trevithick designed the first 'semi-portable' stationary steam engine for agricultural use, known as a \"barn engine\" in 1812, and it was used to drive a corn threshing machine. The truly portable engine was invented in 1839 by William Tuxford of Boston, Lincolnshire who started manufacture of an engine built around a locomotive-style boiler with horizontal smoke tubes. A large flywheel was mounted on the crankshaft, and a stout leather belt was used to transfer the drive to the equipment being driven. In the 1850s, John Fowler used a Clayton & Shuttleworth portable engine to drive apparatus in the first public demonstrations of the application of cable haulage to cultivation.\n\nIn parallel with the early portable engine development, many engineers attempted to make them self-propelled – the fore-runners of the traction engine. In most cases this was achieved by fitting a sprocket on the end of the crankshaft, and running a chain from this to a larger sprocket on the rear axle. These experiments met with mixed success. The first proper traction engine, in the form recognisable today, was developed in 1859 when British engineer Thomas Aveling modified a Clayton & Shuttleworth portable engine, which had to be hauled from job to job by horses, into a self-propelled one. The alteration was made by fitting a long driving chain between the crankshaft and the rear axle.\n\nThe first half of the 1860s was a period of great experimentation but by the end of the decade the standard form of the traction engine had evolved and would change little over the next sixty years. It was widely adopted for agricultural use. The first tractors were steam-powered plowing engines. They were used in pairs, placed on either side of a field to haul a plow back and forth between them using a wire cable. In Britain Mann's and Garrett developed steam tractors for direct ploughing, but the heavy, wet soil of England meant that these designs were less economical than a team of horses. In the United States, where soil conditions permitted, steam tractors were used to direct-haul plows. Steam-powered agricultural engines remained in use well into the 20th century until reliable internal combustion engines had been developed.\n\nIn 1892, John Froelich invented and built the first gasoline/petrol-powered tractor in Clayton County, Iowa, US. A Van Duzen single-cylinder gasoline engine was mounted on a Robinson engine chassis, which could be controlled and propelled by Froelich's gear box. After receiving a patent, Froelich started up the Waterloo Gasoline Engine Company and invested all of his assets. However, the venture was very unsuccessful, and by 1895 all was lost and he went out of business.\n\nRichard Hornsby & Sons are credited with producing and selling the first oil-engined tractor in Britain invented by Herbert Akroyd Stuart. The Hornsby-Akroyd Patent Safety Oil Traction Engine was made in 1896 with a 20 hp engine. In 1897, it was bought by Mr. Locke-King, and this is the first recorded sale of a tractor in Britain. Also in that year, the tractor won a Silver Medal of the Royal Agricultural Society of England. That tractor would later be returned to the factory and fitted with a caterpillar track.\n\nThe first commercially successful light-weight petrol-powered general purpose tractor was built by Dan Albone, a British inventor in 1901. He filed for a patent on 15 February 1902 for his tractor design and then formed Ivel Agricultural Motors Limited. The other directors were Selwyn Edge, Charles Jarrott, John Hewitt and Lord Willoughby. He called his machine the Ivel Agricultural Motor; the word \"tractor\" did not come into common use until later. The Ivel Agricultural Motor was light, powerful and compact. It had one front wheel, with solid rubber tyre, and two large rear wheels like a modern tractor. The engine used water cooling, by evaporation. It had one forward and one reverse gear. A pulley wheel on the left hand side allowed it to be used as a stationary engine, driving a wide range of agricultural machinery. The 1903 sale price was £300. His tractor won a medal at the Royal Agricultural Show, in 1903 and 1904. About 500 were built, and many were exported all over the world. The original engine was made by Payne & Co. of Coventry. After 1906, French Aster engines were used.\n\nThe first successful American tractor was built by Charles W. Hart and Charles H. Parr. They developed a two-cylinder gasoline engine and set up their business in Charles City, Iowa. In 1903, the firm built 15 tractors. Their 14,000-pound #3 is the oldest surviving internal combustion engine tractor in the United States, and is on display at the Smithsonian National Museum of American History in Washington, D.C. The two-cylinder engine has a unique hit-and-miss firing cycle that produced 30 horsepower at the belt and 18 at the drawbar.\n\nIn 1908, the Saunderson Tractor and Implement Co. of Bedford introduced a four-wheel design, and went on to become the largest tractor manufacturer in Britain at the time. While the earlier, heavier tractors were initially very successful, it became increasingly apparent at this time that the weight of a large supporting frame was less-efficient than lighter designs. Henry Ford introduced a light-weight, mass-produced design which largely displaced the heavier designs. Some companies halfheartedly followed suit with mediocre designs, as if to disprove the concept, but they were largely unsuccessful in that endeavor.\n\nWhile unpopular at first, these gasoline-powered machines began to catch on in the 1910s, when they became smaller and more affordable. Henry Ford introduced the Fordson, a wildly popular mass-produced tractor, in 1917. They were built in the U.S., Ireland, England and Russia, and by 1923, Fordson had 77% of the U.S. market. The Fordson dispensed with a frame, using the strength of the engine block to hold the machine together. By the 1920s, tractors with gasoline-powered internal combustion engines had become the norm.\n\nHarry Ferguson applied for a British patent for his three-point hitch in 1926, a three-point attachment of the implement to the tractor and the simplest and the only statically determinate way of joining two bodies in engineering. The Ferguson-Brown Company produced the Model A Ferguson-Brown tractor with a Ferguson-designed hydraulic hitch. In 1938 Ferguson entered into a collaboration with Henry Ford to produce the Ford-Ferguson 9N tractor. The three-point hitch soon became the favorite hitch attachment system among farmers around the world. This tractor model also included a rear Power Take Off (PTO) shaft that could be used to power three point hitch mounted implements such as sickle-bar mowers. This PTO location set the standard for future tractor developments.\n\nTractors can be generally classified by number of axles or wheels, with main categories of two-wheel tractors (single-axle tractors) and four-wheel tractors (two-axle tractors); more axles are possible but uncommon. Among four-wheel tractors (two-axle tractors), most are two-wheel drive (usually at the rear); but many are two-wheel drive with front wheel assist, four-wheel drive (often with articulated steering), or track tractors (with steel or rubber tracks).\n\nThe classic farm tractor is a simple open vehicle, with two very large driving wheels on an axle below and slightly behind a single seat (the seat and steering wheel consequently are in the center), and the engine in front of the driver, with two steerable wheels below the engine compartment. This basic design has remained unchanged for a number of years, but enclosed cabs are fitted on almost all modern models, for reasons of operator safety and comfort. \nIn some localities with heavy or wet soils, notably in the Central Valley of California, the \"Caterpillar\" or \"crawler\" type of tracked tractor became popular in the 1930s, due to superior traction and flotation. These were usually maneuvered through the use of turning brake pedals and separate track clutches operated by levers rather than a steering wheel.\n\nFour-wheel drive tractors began to appear in the 1960s. Some four-wheel drive tractors have the standard \"two large, two small\" configuration typical of smaller tractors, while some have four large, powered wheels. The larger tractors are typically an articulated, center-hinged design steered by hydraulic cylinders that move the forward power unit while the trailing unit is not steered separately.\nIn the early 21st century, articulated or non-articulated, steerable multitrack tractors have largely supplanted the Caterpillar type for farm use. Larger types of modern farm tractors include articulated four-wheel or eight-wheel drive units with one or two power units which are hinged in the middle and steered by hydraulic clutches or pumps. A relatively recent development is the replacement of wheels or steel crawler-type tracks with flexible, steel-reinforced rubber tracks, usually powered by hydrostatic or completely hydraulic driving mechanisms. The configuration of these tractors bears little resemblance to the classic farm tractor design. \n\nThe predecessors of modern tractors, traction engines, used steam engines for power.\n\nSince the turn of the 20th century, internal combustion engines have been the power source of choice. Between 1900 and 1960, gasoline was the predominant fuel, with kerosene (the Rumely Oil Pull was the most notable of this kind) and ethanol being common alternatives. Generally, one engine could burn any of those, although cold starting was easiest on gasoline. Often, a small auxiliary fuel tank was available to hold gasoline for cold starting and warm-up, while the main fuel tank held whatever fuel was most convenient or least expensive for the particular farmer. In the United Kingdom, a gasoline-kerosene engine is known as a petrol-paraffin engine.\n\nDieselisation gained momentum starting in the 1960s, and modern farm tractors usually employ diesel engines, which range in power output from 18 to 575 horsepower (15 to 480 kW). Size and output are dependent on application, with smaller tractors used for lawn mowing, landscaping, orchard work, and truck farming, and larger tractors for vast fields of wheat, maize, soy, and other bulk crops.\n\nLiquified petroleum gas (LPG) or propane also have been used as tractor fuels, but require special pressurized fuel tanks and filling equipment, so are less prevalent in most markets.\n\nIn some countries such as Germany, biodiesel is often used. Some other biofuels such as straight vegetable oil are also being used by some farmers.\n\nMost older farm tractors use a manual transmission with several gear ratios, typically three to six, sometimes multiplied into two or three ranges. This arrangement provides a set of discrete ratios that, combined with the varying of the throttle, allow final-drive speeds from less than one up to about 25 miles per hour (40 km/h), with the lower speeds used for working the land and the highest speed used on the road.\n\nSlow, controllable speeds are necessary for most of the operations performed with a tractor. They help give the farmer a larger degree of control in certain situations, such as field work. However, when travelling on public roads, the slow operating speeds can cause problems, such as long queues or tailbacks, which can delay or annoy motorists in cars and trucks. These motorists are responsible for being duly careful around farm tractors and sharing the road with them, but many shirk this responsibility, so various ways to minimize the interaction or minimize the speed differential are employed where feasible. Some countries (for example the Netherlands) employ a road sign on some roads that means \"no farm tractors\". Some modern tractors, such as the JCB Fastrac, are now capable of much higher road speeds of around 50 mph (80 km/h).\nOlder tractors usually have unsynchronized transmission designs, which often require the operator stop the tractor to shift between gears. This mode of use is inherently unsuited to some of the work tractors do, and has been circumvented in various ways over the years. For existing unsynchronized tractors, the methods of circumvention are double clutching or power-shifting, both of which require the operator to rely on skill to speed-match the gears while shifting, and are undesirable from a risk-mitigation standpoint because of what can go wrong if the operator makes a mistake – transmission damage is possible, and loss of vehicle control can occur if the tractor is towing a heavy load either uphill or downhill – something that tractors often do. Therefore, operator's manuals for most of these tractors state one must always stop the tractor before shifting, and they do not even mention the alternatives. As already said, that mode of use is inherently unsuited to some of the work tractors do, so better options were pursued for newer tractor designs. \n\nIn these, unsynchronized transmission designs were replaced with synchronization or with continuously variable transmissions (CVTs). Either a synchronized manual transmission with enough available gear ratios (often achieved with dual ranges, high and low) or a CVT allow the engine speed to be matched to the desired final-drive speed, while keeping engine speed within the appropriate speed (as measured in rotations per minute or rpm) range for power generation (the working range) (whereas throttling back to achieve the desired final-drive speed is a trade-off that leaves the working range). The problems, solutions, and developments described here also describe the history of transmission evolution in semi-trailer trucks. The biggest difference is fleet turnover; whereas most of the old road tractors have long since been scrapped, many of the old farm tractors are still in use. Therefore, old transmission design and operation is primarily just of historical interest in trucking, whereas in farming it still often affects daily life.\n\nThe power produced by the engine must be transmitted to the implement or equipment to do the actual work intended for the equipment. This may be accomplished via a drawbar or hitch system if the implement is to be towed or otherwise pulled through the tractive power of the engine, or via a pulley or power takeoff system if the implement is stationary, or a combination of the two.\n\nUntil the 1940s, plows and other tillage equipment usually were connected to the tractor via a drawbar. The classic drawbar is simply a steel bar attached to the tractor (or in some cases, as in the early Fordsons, cast as part of the rear transmission housing) to which the hitch of the implement was attached with a pin or by a loop and clevis. The implement could be readily attached and removed, allowing the tractor to be used for other purposes on a daily basis. If the tractor was equipped with a swinging drawbar, then it could be set at the center or offset from center to allow the tractor to run outside the path of the implement.\n\nThe drawbar system necessitated the implement having its own running gear (usually wheels) and in the case of a plow, chisel cultivator or harrow, some sort of lift mechanism to raise it out of the ground at turns or for transport. Drawbars necessarily posed a rollover risk depending on how the tractive torque was applied. The Fordson tractors (of which more units were produced and placed in service than any other farm tractor) was extremely prone to roll over backwards due to an excessively short wheelbase. The linkage between the implement and the tractor usually had some slack which could lead to jerky starts and greater wear and tear on the tractor and the equipment.\n\nDrawbars were appropriate to the dawn of mechanization, because they were very simple in concept and because as the tractor replaced the horse, existing horse-drawn implements usually already had running gear. As the history of mechanization progressed, however, the advantages of other hitching systems became apparent, leading to new developments (see below). Depending on the function for which a tractor is used, though, the drawbar is still one of the usual means of attaching an implement to a tractor (see photo at left).\n\nSome tractor manufacturers produced matching equipment that could be directly mounted on the tractor. Examples included front-end loaders, belly mowers, row crop cultivators, corn pickers and corn planters. In most cases, these fixed mounts were proprietary and unique to each make of tractor, so an implement produced by John Deere, for example, could not be attached to a Minneapolis Moline tractor. Another disadvantage was mounting usually required some time and labor, resulting in the implement being semi-permanently attached with bolts or other mounting hardware. Usually, it was impractical to remove the implement and reinstall it on a day-to-day basis. As a result, the tractor was unavailable for other uses and dedicated to a single use for an appreciable period of time. An implement generally would be mounted at the beginning of its season of use (such as tillage, planting or harvesting) and removed only when the likely use season had ended.\n\nThe drawbar system was virtually the exclusive method of attaching implements (other than direct attachment to the tractor) before Harry Ferguson developed the three-point hitch. Equipment attached to the three-point hitch can be raised or lowered hydraulically with a control lever. The equipment attached to the three-point hitch is usually completely supported by the tractor. Another way to attach an implement is via a quick hitch, which is attached to the three-point hitch. This enables a single person to attach an implement quicker and put the person in less danger when attaching the implement.\n\nThe three-point hitch revolutionized farm tractors and their implements. While the Ferguson system was still under patent, other manufacturers developed new hitching systems to try to fend off some of Ferguson's competitive advantage. For example, International Harvestor's Farmall tractors gained a two-point \"Fast Hitch\", and John Deere had a power lift that was similar to, but not as flexible as, the Ferguson invention. Once the patent protection expired on the three-point hitch, it became an industry standard.\n\nAlmost every tractor today features Ferguson's three-point linkage or a derivative of it. This hitch allows for easy attachment and detachment of implements while allowing the implement to function as a part of the tractor, almost as if it were attached by a fixed mount. Previously, when the implement hit an obstacle, the towing link would break or the tractor could flip over. Ferguson's genius was to combine a connection via two lower and one upper lift arms that were connected to a hydraulic lifting ram. The ram was, in turn, connected to the upper of the three links so the increased drag (as when a plough hits a rock) caused the hydraulics to lift the implement until the obstacle was passed.\n\nRecently, Bobcat's patent on its front loader connection (inspired by these earlier systems) has expired, and compact tractors are now being outfitted with quick-connect attachments for their front-end loaders.\n\nIn addition to towing an implement or supplying tractive power through the wheels, most tractors have a means to transfer power to another machine such as a baler, swather, or mower. Unless it functions solely by pulling it through or over the ground, a towed implement needs its own power source (such as a baler or combine with a separate engine) or else a means of transmitting power from the tractor to the mechanical operations of the equipment.\n\nEarly tractors used belts or cables wrapped around the flywheel or a separate belt pulley to power stationary equipment, such as a threshing machine, buzz saw, silage blower, or stationary baler. In most cases, it was not practical for the tractor and equipment to move with a flexible belt or cable between them, so this system required the tractor to remain in one location, with the work brought to the equipment, or the tractor to be relocated at each turn and the power set-up reapplied (as in cable-drawn plowing systems used in early steam tractor operations).\n\nModern tractors use a power take-off (PTO) shaft to provide rotary power to machinery that may be stationary or pulled. The PTO shaft generally is at the rear of the tractor, and can be connected to an implement that is either towed by a drawbar or a three-point hitch. This eliminates the need for a separate, implement-mounted power source, which is almost never seen in modern farm equipment.\n\nVirtually all modern tractors can also provide external hydraulic fluid and electrical power to the equipment they are towing, either by hoses or wires.\n\nModern tractors have many electrical switches and levers in the cab for controlling the multitude of different functions available on the tractor.\n\nModern farm tractors usually have four or five foot-pedals for the operator on the floor of the tractor.\n\nThe pedal on the left is the clutch. The operator presses on this pedal to disengage the transmission for either shifting gears or stopping the tractor. Some modern tractors have (or as optional equipment) a button on the gear stick for controlling the clutch, in addition to the standard pedal.\n\nTwo of the pedals on the right are the brakes. The left brake pedal stops the left rear wheel and the right brake pedal does the same with the right side. This independent left and right wheel-braking augments the steering of the tractor when only the two rear wheels are driven. This is usually done when it is necessary to make a sharp turn. The split brake pedal is also used in mud or soft soil to control a tire spinning due to loss of traction. The operator presses both pedals together to stop the tractor. Usually a swinging or sliding bolt is provided to lock the two together when desired.\n\nThe pedal furthest to the right is the foot throttle. Unlike in automobiles, it can also be controlled from a hand-operated lever (\"hand throttle\"). This helps provide a constant speed in field work. It also helps provide continuous power for stationary tractors that are operating an implement by shaft or belt. The foot throttle gives the operator more automobile-like control over the speed of the tractor for road work. This is a feature of more recent tractors; older tractors often did not have it. In the UK, foot pedal use to control engine speed while travelling on the road is mandatory. Some tractors, especially those designed for row-crop work, have a 'de-accelerator' pedal, which operates in the reverse fashion to an automobile throttle, in that the pedal is pushed down to slow the engine. This allows fine control over the speed of the tractor when maneuvering at the end of crop rows in fields- the operating speed of the engine is set using the hand throttle, and to slow the tractor to turn, the operator simply has to press the pedal, and turn and release it once the turn is completed, rather than having to alter the setting of the hand throttle twice during the maneuver.\n\nA fifth pedal is traditionally included just in front of the driver's seat (often pressed with the operator's heel) to operate the rear differential lock (diff-lock), which prevents wheel slip. The differential normally allows the outside wheel to travel faster than the inside wheel during a turn. However, in low-traction conditions on a soft surface, the same mechanism could allow one wheel to slip, further reducing traction. The diff-lock overrides this, forcing both wheels to turn at the same speed, reducing wheel slip and improving traction. Care must be taken to unlock the differential before turning, usually by hitting the pedal a second time, since the tractor with good traction cannot perform a turn with the diff-lock engaged. In modern tractors, this pedal is replaced with an electrical switch.\n\nMany functions once controlled with levers have been replaced with some model of electrical switch with the rise of indirect computer controlling of functions in modern tractors.\n\nUntil the beginning of the 1960s, tractors had a single register of gears, hence one gear stick, often with three to five forward gears and 1 reverse. Then, group gears were introduced, and another gear stick was added. Later, control of the forward-reverse direction was moved to a special stick attached at the side of the steering wheel, which allowed forward or reverse travel in any gear. Nowadays, with CVTs or other clutch-free gear types, fewer sticks control the transmission, and some are replaced with electrical switches or are totally computer-controlled.\n\nThe three-point hitch was controlled with a lever for adjusting the position, or as with the earliest ones, just the function for raising or lowering the hitch. With modern electrical systems, it is often replaced with a potentiometer for the lower bound position and another one for the upper bound, and a switch allowing automatic adjustment of the hitch between these settings.\n\nThe external hydraulics also originally had levers, but now are often replaced with some form of electrical switch; the same is true for the power take-off shaft.\n\nAgriculture in the United States is one of the most hazardous industries, only surpassed\nby mining and construction. No other farm machine is so identified with the hazards of production agriculture as the tractor. Tractor-related injuries account for approximately 32% of the fatalities and 6% of the nonfatal injuries in agriculture. Over 50% is attributed to tractor overturns.\n\nThe roll-over protection structure (ROPS) and seat belt, when worn, are the most important safety devices to protect operators from death during tractor overturns.\n\nModern tractors have a ROPS to prevent an operator from being crushed if the tractor turns over. The ROPS does not prevent tractor overturns; rather, it prevents the operator from being crushed during an overturn. This is especially important in open-air tractors, where the ROPS is a steel beam that extends above the operator's seat. For tractors with operator cabs, the ROPS is part\nof the frame of the cab. A ROPS with enclosed cab further reduces the likelihood of serious injury because the operator is protected by the sides and windows of the cab.\n\nThese structures were first required by legislation in Sweden in 1959. Before they were required, some farmers died when their tractors rolled on top of them. Row-crop tractors, before ROPS, were particularly dangerous because of their 'tricycle' design with the two front wheels spaced close together and angled inward toward the ground. Some farmers were killed by rollovers while operating tractors along steep slopes. Others have been killed while attempting to tow or pull an excessive load from above axle height, or when cold weather caused the tires to freeze to the ground, in both cases causing the tractor to pivot around the rear axle. ROPS were first required in the United States in 1986, but this requirement did not retroactively apply to tractors produced before this year; therefore, adoption of ROPS has been incomplete in the farming community. To combat this problem, CROPS (cost-effective roll-over protection structures) have been developed to encourage farmers to retrofit older tractors.\n\nFor the ROPS to work as designed, the operator must stay within its protective frame. This means the operator must wear the seat belt; not wearing it may defeat the primary purpose of the ROPS.\n\nThe most common use of the term \"tractor\" is for the vehicles used on farms. The farm tractor is used for pulling or pushing agricultural machinery or trailers, for plowing, tilling, disking, harrowing, planting, and similar tasks.\n\nA variety of specialty farm tractors have been developed for particular uses. These include \"row crop\" tractors with adjustable tread width to allow the tractor to pass down rows of corn, tomatoes or other crops without crushing the plants, \"wheatland\" or \"standard\" tractors with fixed wheels and a lower center of gravity for plowing and other heavy field work for broadcast crops, and \"high crop\" tractors with adjustable tread and increased ground clearance, often used in the cultivation of cotton and other high-growing row crop plant operations, and \"utility tractors\", typically smaller tractors with a low center of gravity and short turning radius, used for general purposes around the farmstead. Many utility tractors are used for nonfarm grading, landscape maintenance and excavation purposes, particularly with loaders, backhoes, pallet forks and similar devices. Small garden or lawn tractors designed for suburban and semirural gardening and landscape maintenance also exist in a variety of configurations. \n\nSome farm-type tractors are found elsewhere than on farms: with large universities' gardening departments, in public parks, or for highway workman use with blowtorch cylinders strapped to the sides and a pneumatic drill air compressor permanently fastened over the power take-off. These are often fitted with grass (turf) tyres which are less damaging to soft surfaces than agricultural tires.\n\nSpace technology has been incorporated into agriculture in the form of GPS devices, and robust on-board computers installed as optional features on farm tractors. These technologies are used in modern, precision farming techniques. The spin-offs from the space race have actually facilitated automation in plowing and the use of autosteer systems (drone on tractors that are manned but only steered at the end of a row), the idea being to neither overlap and use more fuel nor leave streaks when performing jobs such as cultivating. Several tractor companies have also been working on producing a driverless tractor.\n\nThe durability and engine power of tractors made them very suitable for engineering tasks. Tractors can be fitted with engineering tools such as dozer blades, buckets, hoes, rippers, etc. The most common attachments for the front of a tractor are dozer blades or buckets. When attached to engineering tools, the tractor is called an engineering vehicle.\n\nA bulldozer is a track-type tractor with a blade attached in the front and a rope-winch behind. Bulldozers are very powerful tractors and have excellent ground-hold, as their main tasks are to push or drag.\n\nBulldozers have been further modified over time to evolve into new machines which are capable of working in ways that the original bulldozer can not. One example is that loader tractors were created by removing the blade and substituting a large volume bucket and hydraulic arms which can raise and lower the bucket, thus making it useful for scooping up earth, rock and similar loose material to load it into trucks.\n\nA front-loader or loader is a tractor with an engineering tool which consists of two hydraulic powered arms on either side of the front engine compartment and a tilting implement. This is usually a wide-open box called a bucket, but other common attachments are a pallet fork and a bale grappler.\n\nOther modifications to the original bulldozer include making the machine smaller to let it operate in small work areas where movement is limited. Also, tiny wheeled loaders, officially called skid-steer loaders, but nicknamed \"Bobcat\" after the original manufacturer, are particularly suited for small excavation projects in confined areas.\n\nThe most common variation of the classic farm tractor is the hoe, also called a hoe-loader. As the name implies, it has a loader assembly on the front and a backhoe on the back. Backhoes attach to a three-point hitch on farm or industrial tractors. Industrial tractors are often heavier in construction, particularly with regards to the use of steel grill for protection from rocks and the use of construction tires. When the backhoe is permanently attached, the machine usually has a seat that can swivel to the rear to face the hoe controls. Removable backhoe attachments almost always have a separate seat on the attachment.\n\nBackhoe-loaders are very common and can be used for a wide variety of tasks: construction, small demolitions, light transportation of building materials, powering building equipment, digging holes, loading trucks, breaking asphalt and paving roads. Some buckets have retractable bottoms, enabling them to empty their loads more quickly and efficiently. Buckets with retractable bottoms are also often used for grading and scratching off sand. The front assembly may be a removable attachment or permanently mounted. Often the bucket can be replaced with other devices or tools.\n\nTheir relatively small frames and precise controls make backhoe-loaders very useful and common in urban engineering projects, such as construction and repairs in areas too small for larger equipment. Their versatility and compact size makes them one of the most popular urban construction vehicles.\n\nIn the UK and Ireland, the word \"JCB\" is used colloquially as a genericized trademark for any such type of engineering vehicle. The term JCB now appears in the Oxford English Dictionary, although it is still legally a trademark of J. C. Bamford Ltd. The term \"digger\" is also commonly used.\n\nA compact utility tractor (CUT) is a smaller version of an agricultural tractor, but designed primarily for landscaping and estate management tasks rather than for planting and harvesting on a commercial scale. Typical CUTs range from 20 to 50 horsepower (15–37 kW) with available power take-off (PTO) horsepower ranging from 15 to 45 hp (11–34 kW). CUTs are often equipped with both a mid-mounted and a standard rear PTO, especially those below 40 horsepower (30 kW). The mid-mount PTO shaft typically rotates at/near 2000 rpm and is typically used to power mid-mount finish mowers, front-mounted snow blowers or front-mounted rotary brooms. The rear PTO is standardized at 540 rpms for the North American markets, but in some parts of the world, a dual 540/1000 rpm PTO is standard, and implements are available for either standard in those markets.\n\nOne of the most common attachment for a CUT is the front-end loader or FEL. Like the larger agricultural tractors, a CUT will have an adjustable, hydraulically controlled three-point hitch. Typically, a CUT will have four-wheel drive, or more correctly four-wheel assist. Modern CUTs often feature hydrostatic transmissions, but many variants of gear-drive transmissions are also offered from low priced, simple gear transmissions to synchronized transmissions to advanced glide-shift transmissions. All modern CUTs feature government-mandated roll over protection structures just like agricultural tractors. The most well-known brands in North America include Kubota, John Deere Tractor, New Holland Ag, Case-Farmall and Massey-Ferguson. Although less common, compact backhoes are often attached to compact utility tractors.\n\nCompact utility tractors require special, smaller implements than full-sized agricultural tractors. Very common implements include the box blade, the grader blade, the landscape rake, the post hole digger (or post hole auger), the rotary cutter (slasher or a brush hog), a mid- or rear-mount finish mower, a broadcast seeder, a subsoiler and the rototiller (rotary tiller). In northern climates, a rear-mounted snow blower is very common; some smaller CUT models are available with front-mounted snow blowers powered by mid-PTO shafts. Implement brands outnumbere tractor brands, so CUT owners have a wide selection of implements.\n\nFor small-scale farming or large-scale gardening, some planting and harvesting implements are sized for CUTs. One- and two-row planting units are commonly available, as are cultivators, sprayers and different types of seeders (slit, rotary and drop). One of the first CUTs offered for small farms of three to 30 acres and for small jobs on larger farms was a three-wheeled unit, with the rear wheel being the drive wheel, offered by Sears & Roebuck in 1954 and priced at $598 for the basic model.\n\nThe earliest tractors were called \"standard\" tractors, and were intended almost solely for plowing and harrowing before planting, which were difficult tasks for humans and draft animals. They were characterized by a low, rearward seating position, fixed-width tread, and low ground clearance. These early tractors were cumbersome, and were not well-suited to getting into a field of already-planted row crops to do weed control. The \"standard\" tractor definition is no longer in current use.\n\nA general-purpose or row-crop tractor is tailored specifically to the growing of crops grown in rows, and most especially to cultivating these crops. These tractors are universal machines, capable of both primary tillage and cultivation of a crop. The \"row-crop\" or \"general-purpose\" designation is no longer in current use. \nThe row-crop tractor category evolved rather than appearing overnight, but the International Harvester (IH) Farmall is often considered the \"first\" tractor of the category. Some earlier tractors of the 1910s and 1920s approached the form factor from the heavier side, as did motorized cultivators from the lighter side, but the Farmall brought all of the salient features together into one package, with a capable distribution network to ensure its commercial success. In the new form factor that the Farmall popularized, the cultivator was mounted in the front so it was easily visible. Additionally, the tractor had a narrow front end; the front tires were spaced very closely and angled in towards the bottom. The back wheels straddled two rows, and the unit could cultivate four rows at once.\n\nFrom 1924 until 1963, Farmalls were the largest selling row-crop tractors.\n\nTo compete, John Deere designed the Model C, which had a wide front and could cultivate three rows at once. Only 112 prototypes were made, as Deere realized sales would be lost to Farmall if their model did less. In 1928, Deere released the Model C anyway, only as the Model GP (General Purpose) to avoid confusion with the Model D when ordered over the then unclear telephone.\n\nOliver refined its \"Row Crop\" model early in 1930. Until 1935, the 18–27 was Oliver–Hart-Parr's only row-crop tractor.\nMany Oliver row-crop models are referred to as \"Oliver Row Crop 77\", \"Oliver Row Crop 88\", etc.\n\nMany early row-crop tractors had a tricycle design with two closely spaced front tires, and some even had a single front tire. This made it dangerous to operate on the side of a steep hill; as a result, many farmers died from tractor rollovers. Also, early row-crop tractors had no rollover protection system (ROPS), meaning if the tractor flipped back, the operator could be crushed. Sweden was the first country which passed legislation requiring ROPS, in 1959.\n\nOver 50% of tractor related injuries and deaths are attributed to tractor rollover.\n\nCanadian agricultural equipment manufacturer Versatile makes row-crop tractors that are ; powered by an 8.9 liter Cummins Diesel engine.\n\nCase IH and New Holland of CNH Industrial both produce high horsepower front-wheel-assist row crop tractors with available rear tracks. Case IH also has a 500 hp (373 kW) four-wheel drive track system called Rowtrac.\n\nJohn Deere has an extensive line of available row crop tractors ranging from 140 to 400 horsepower (104 to 298 kW).\n\nModern row crop tractors have rollover protection systems in the form of a reinforced cab or a roll bar.\n\nGarden tractors (mini tractors) are small, light tractors designed for use in domestic gardens and small estates. Garden tractors are designed for cutting grass, snow removal, and small property cultivation. In the U.S., the term riding lawn mower today often is used to refer to mid- or rear-engined machines. Front-engined tractor layout machines designed primarily for cutting grass and light towing are called lawn tractors; heavier-duty tractors of similar size are garden tractors. Garden tractors are capable of mounting a wider array of attachments than lawn tractors. Unlike lawn tractors and rear-engined riding mowers, garden tractors are powered by horizontal-crankshaft engines with a belt-drive to transaxle-type transmissions (usually of four- or five-speeds, although some may also have two-speed reduction gearboxes, drive-shafts, or hydrostatic or hydraulic drives). Garden tractors from Wheel Horse, Cub Cadet, Economy (Power King), John Deere, Massey Ferguson and Case Ingersoll are built in this manner. The engines are generally a one- or two-cylinder petrol (gasoline) engines, although diesel engine models are also available, especially in Europe. Typically, diesel-powered garden tractors are larger and heavier-duty than gasoline-powered units and compare more similarly to compact utility tractors.\n\nVisually, the distinction between a garden tractor and a lawn tractor is often hard to make – generally, garden tractors are more sturdily built, with stronger frames, 12-inch or larger wheels mounted with multiple lugs (most lawn tractors have a single bolt or clip on the hub), heavier transaxles, and ability to accommodate a wide range of front, belly, and rear mounted attachments.\n\nAlthough most people think first of four-wheel vehicles when they think of tractors, a tractor may have one or more axles. The key benefit is the power itself, which only takes one axle to provide. Single-axle tractors, more often called two-wheel tractors or walk-behind tractors, have had many users since the beginning of internal combustion engine tractors. They tend to be small and affordable. This was especially true before the 1960s, when a walk-behind tractor could often be more affordable than a two-axle tractor of comparable power. Today's compact utility tractors and advanced garden tractors may negate most of that market advantage, but two-wheel tractors still enjoy a loyal following, especially where an already-paid-for two-wheel tractor is financially superior to a compact or garden tractor that would have to be purchased. Countries where two-wheel tractors are especially prevalent today include, Thailand, China, Bangladesh, India, and other Southeast Asia countries.\n\nTractors tailored to use in fruit orchards typically have features suited to passing under tree branches with impunity. These include a lower overall profile; reduced tree-branch-snagging risk (via underslung exhaust pipes rather than smoke-stack-style exhaust, and large sheetmetal cowlings and fairings that allow branches to deflect and slide off rather than catch); spark arrestors on the exhaust tips; and often wire cages to protect the operator from snags.\n\nThe ingenuity of farm mechanics, coupled in some cases with OEM or aftermarket assistance, has often resulted in the conversion of automobiles for use as farm tractors. In the United States, this trend was especially strong from the 1910s through 1950s. It began early in the development of vehicles powered by internal combustion engines, with blacksmiths and amateur mechanics tinkering in their shops. Especially during the interwar period, dozens of manufacturers (Montgomery Ward among them) marketed aftermarket kits for converting Ford Model Ts for use as tractors. (These were sometimes called 'Hoover wagons' during the Great Depression, although this term was usually reserved for automobiles converted to horse-drawn buggy use when gasoline was unavailable or unaffordable. During the same period, another common name was \"Doodlebug\"). Ford even considered producing an \"official\" optional kit. Many Model A Fords also were converted for this purpose. In later years, some farm mechanics have been known to convert more modern trucks or cars for use as tractors, more often as curiosities or for recreational purposes (rather than out of the earlier motives of pure necessity or frugality).\nDuring World War II, a shortage of tractors in Sweden led to the development of the so-called \"EPA\" tractor (EPA was a chain of discount stores and it was often used to signify something lacking in quality). An EPA tractor was simply an automobile, truck or lorry, with the passenger space cut off behind the front seats, equipped with two gearboxes in a row. When done to an older car with a ladder frame, the result was not dissimilar to a tractor and could be used as one. After the war it remained popular, now not as a farm vehicle, but as a way for young people without a driver's license to own something similar to a car. Since it was legally seen as a tractor, it could be driven from 16 years of age and only required a tractor license. Eventually, the legal loophole was closed and no new EPA tractors were allowed to be made, but the remaining ones were still legal, which led to inflated prices and many protests from people who preferred EPA tractors to ordinary cars.\n\nThe German occupation of Italy during World War II resulted in a severe shortage of mechanized farm equipment. The destruction of tractors was a sort of scorched-earth strategy used to reduce the independence of the conquered. The shortage of tractors in that area of Europe was the origin of Lamborghini. The war was also the inspiration for dual-purpose vehicles such as the Land Rover. Based on the Jeep, the company made a vehicle that combined PTO, tillage, and transportation.\n\nIn March 1975, a similar type of vehicle was introduced in Sweden, the \"A tractor\" [from \"arbetstraktor\" (work tractor)]; the main difference is an A tractor has a top speed of 30 km/h. This is usually done by fitting two gearboxes in a row and not using one of them. The Volvo Duett was, for a long time, the primary choice for conversion to an EPA or A tractor, but since supplies have dried up, other cars have been used, in most cases another Volvo. The SFRO is a Swedish organization advocating homebuilt and modified vehicles.\n\nAnother type of homemade tractors are ones that are fabricated from scratch. The \"from scratch\" description is relative, as often individual components will be repurposed from earlier vehicles or machinery (e.g., engines, gearboxes, axle housings), but the tractor's overall chassis is essentially designed and built by the owner (e.g., a frame is welded from bar stock—channel stock, angle stock, flat stock, etc.). As with automobile conversions, the heyday of this type of tractor, at least in developed economies, lies in the past, when there were large populations of blue-collar workers for whom metalworking and farming were prevalent parts of their lives. (For example, many 19th- and 20th-century New England and Midwestern machinists and factory workers had grown up on farms.) Backyard fabrication was a natural activity to them (whereas it might seem daunting to most people today).\n\nThe term \"tractor\" (US and Canada) or \"tractor unit\" (UK) is also applied to:\n\nIn addition to commercial manufacturers, the Open Source Ecology group has developed several working prototypes of an open source hardware tractor called the LifeTrac as part of its Global Village Construction Set.\n\n\n\n"}
{"id": "1229169", "url": "https://en.wikipedia.org/wiki?curid=1229169", "title": "Triathlon equipment", "text": "Triathlon equipment\n\nThe special needs of triathlon competitions have led to the development of a whole range of specialized clothing and equipment.\n\nTypical equipment for a swim includes a cap, goggles and a swimsuit and/or wetsuit. Usually, participants must wear a swim cap provided by the event. For safety reasons, the swim caps are generally brightly colored for high visibility. The colors may categorize swimmers by event (e.g. Olympic, Sprint) or by heat.\n\nAny artificial propulsion device, e.g. fin, sock, glove, paddle or flotation device except a wet suit, is prohibited. Snorkels, however, are a gray area. Triathlon Canada, Australia Triathlon, USAT and ITU do not specifically disallow snorkels. British Triathlon does not list snorkels as part of the accepted equipment, thus they are disallowed. For safety reasons in open-water events, some federations permit special inflatable flotation devices; though activating the device will usually disqualify the swimmer, it can be used to float if the swimmer experiences difficulty.\n\nBecause most triathlon swim stages are conducted in open waters (lakes, rivers, or oceans) which are often cold, many early races allowed wetsuits. However, typical wetsuits manufactured for snorkeling or water skiing are not optimal for triathlon, because the sleeves generally restrict the range of motion too much for comfortable stroking during the swim. Modern triathlon wetsuits were invented by Dan Empfield in 1987 and are customized to the needs of triathletes, and generally incorporate the following features:\n\nIn addition, tri wetsuits have a very smooth, but often fragile, surface. This slick surface helps to reduce water friction and allow a faster swim, but it would be easily destroyed by contact with a sandy surfboard. Another advantage of a wetsuit is the added buoyancy. It provides triathletes with a considerable advantage.\n\nRules vary by event, but typically wetsuits are allowed only if the water temperature is below a specified threshold on the day of the event (e.g. 26 °C, 78 °F). Any athlete has the option of wearing another style of swimsuit allowed by the rules at any temperature. As of 2013, triathlons sanctioned by USAT also have a wetsuit thickness rule. No wetsuit with a thickness of greater than 5mm may be used. Most triathlon wetsuits have thicknesses of 3mm to 5mm, but the new rule likely affects some models and older wetsuits.\n\nUnfortunately, most triathletes do not have the luxury of an open water swim environment near where they train, and year-round outside training can be difficult in cold climates. Several swim training products have been created to address this issue including ergometers like the Vasa Swim Trainer or compact swimming treadmills like Endless Pools.\n\nTrisuits may also be used for the swim, bike, and run. They are made out of a swimsuit material and usually have some form of chamois.\n\nTriathlon bicycles are a variant of road-racing bicycles, designed primarily to optimize aerodynamics. Since in most triathlons, cyclists do not draft as in many other forms of road racing, triathletes can gain a significant advantage by riding a bicycle which reduces wind resistance. The most obvious features of a triathlon bicycle are the handlebars, commonly known as \"aero-bars\" (see below).\n\nIn addition, many components of a triathlon bicycle are designed with an aerodynamic profile: frame tubes have an oval or teardrop (instead of circular) cross-section; handlebars may be flat instead of round; wheels may have fewer spokes, or even be carbon fiber tri-spokes or discs rather than conventional spoked wheels. Lastly, a number of \"radical\" bicycle frames that are illegal in road cycling are still legal in triathlon, so \"nontraditional\" frame designs are also common, including Zipp 2001, Softride, and Kestrel.\n\nTri bikes generally have a very \"aggressive\" geometry, meaning steep (close to vertical) tube angles and a low stem and handlebars relative to the saddle. This position helps to improve aerodynamics by lowering the cyclist's torso and creating a smaller overall \"drag profile\". In addition, many triathletes feel cycling in this position helps preserve the muscles used in running by emphasizing pedaling with non-running muscle groups.\n\nThe concept of a tri specific bicycle was pioneered by Ralph Ray and Dan Empfield in the late 1980s. Tri bikes are generally very similar to time trial bicycles used in time trial races. In 1989, Empfield designed the Quintana Roo Superform, a triathlon specific bicycle \"built from the aerobars back\" which provided an aerodynamic advantage as well as more power when in the \"aero\" position. Empfield's bike had 650c wheels and an 80 degree seat angle which was unique to the period. Many professional triathletes were skeptical of the \"steep\" design at first but when Ray Browning rode it at Ironman New Zealand breaking the bike and overall course records and left the bike leg with a 30-minute lead over rival Scott Tinley, the concepts were here to stay.\n\nThe aerodynamic shape causes somewhat higher weight, even if carbon fiber is used. In very hilly races where a lot of time is spent in slow uphills, a low-weight traditional road bicycle might be preferred.\n\nAerobars, also commonly referred to as \"tri-bars,\" are handlebars designed to reduce the cyclist's wind profile. Triathlon played a key role in the development of cycling with an aero geometry during the 1980s. Aerobars are used in other forms of cycling, such as time trials and some events in track cycling.\n\nInstead of the familiar curved \"drop bars\" of road bicycles, aerobars are mounted to a set of \"pace bars\" or \"bull-horns\". A pair of bars stretches straight forward from the center of these handlebars at the stem of the fork. Padded cups or pads in the middle of the bars support the athlete's elbows and/or forearms while the hands are stretched forward to hold the center bars. This position keeps the rider's elbows in close to the body and lowers his or her torso compared to the usual upright position.\n\nThe brake levers are mounted on the side horns; the rider will hold these instead of the center bars when braking or maneuvering is required. Often the shifters for the derailleur gears are mounted at the tips of the aero bars allowing the athlete to change gear ratios without compromising their aerodynamic position.\n\nRiding with aerobars is facilitated by adopting a steep seat-tube angle, often referred to as an \"aggressive\" geometry. The forward nature of this positioning is not as easy to control as traditional seat tube angle and upright position. Maneuverability is compromised for an aerodynamic body position when a bike is fitted with low aerobars.\n\nThe International Triathlon Union regulates the size of aerobars used in competition for draft-legal races. Triathlons allowing drafting promote cycling as a group on the cycle leg of the triathlon, allowing athletes to compete with a very aggressive geometry compromises safety as maneuverability is reduced. Professional triathletes competing in these races use \"shorty\" aerobars mounted on traditional drop handlebars.\n\nTriathlon shoes are similar to other forms of cycling shoe used in racing, with automatic binding cleats (clipless) that snap the cyclist's feet to the pedals. Tri shoes are often optimized for this approach: they may be padded to allow comfortable use without socks, have holes to allow water from the swim to drain easily, and have only one or two velcro straps for ease of fastening rather than the three straps, laces, or ratcheting buckles found on modern road racing shoes. It is not uncommon for the Velcro straps used to close from the outside of the foot inwards, this non-traditional configuration keeps the opened straps away from the chain and bicycles, preventing the possibility of entangling them if pedaling with unstrapped shoes early or late in the race.\n\nMany competitive triathletes choose to leave their shoes clipped onto the pedals for the entire duration of the race in order to save time during transitions. This means the athlete is jumping onto the bicycle with wet, bare feet after the swim, and will pedal up to a reasonable speed, with his or her feet sitting on top of the shoes, before pausing to slip the feet inside the shoes and fasten them. Likewise, the athlete will pull his or her feet out of the shoes while coasting up to the bike-run transition area and run barefoot into the transition corral rather than attempt to run on the awkward cycling cleats.\n\nAs with everything else, triathletes often strive to make their water bottles as aerodynamic as possible, and often to reduce the need to reach for a water bottle - which may interrupt pedaling and slow the racer down. Triathletes have tried placing water bottles in unusual locations, such as in a bracket behind the saddle, on the theory that the bottles are shielded from the wind by the body. However, a recent wind-tunnel study by \"Triathlete Magazine\" discovered that this approach is actually counterproductive because it interrupts the laminar flow of air down the athlete's curved back. A 2003, wind tunnel study by Dan Empfield found that the best configuration was a single water bottle on the bike's downtube (it smoothed airflow to the seat tube and rear wheel). This caused less drag than having no waterbottle at all. The most drag was 2 water bottles; one on the down tube and one on the seat tube.\n\nA number of products have been created to satisfy triathlete's demands for aerodynamic hydration systems. Examples include the Aerodrink system by Profile Design, an aero bottle that hangs from the handlebars with a straw so the athlete can drink without using his hands; and the Neverreach system, a teardrop-shaped reservoir mounted behind the seat with a tube running up to the handlebars. In addition, certain high-end triathlon bicycles have a hydration system integrated into the frame's tubing itself.\n\nOn long-distance triathlons, the participants will get filled bottles by the organiser during the race as replacement for the used ones. If using special bottles, the received bottle should be emptied into own bottle, and immediately thrown. Bottles hanging from the handlebars are generally prepared for this. To throw bottles outside aid stations is not allowed. In Ironman own aid suppliers are not allowed.\n\nA vast array of low-weight and/or aerodynamic wheels exist for racing bicycles. Some (such as wheels with an aerodynamic ring, flat spokes, and fewer spokes than the traditional 32) are legal for use in most cycling events, while others such as carbon-fiber tri-spokes (wheels with only three large, rigid spokes) generally are only legal in triathlons and time-trials. Typically wheels that are lighter are preferred and, although this is an obvious consideration, it is not the only one. Higher profile wheels (larger rim) are conducive to laminar flow of air past them more so than traditional thin rimmed wheels.\n\nSolid disc wheels are used as well, though in outdoor settings these are generally not used on the front wheel because they are difficult to handle in crosswinds. Disc wheels provide a significant aerodynamic advantage when mounted on the rear wheel improving laminar flow over the rear half of the bike. Recent developments in technology have given rise to disc wheels with a dimpled surface like a golf ball, also in the name of aerodynamics. Disc wheels are not permitted at the Ironman World Championships in Kona Hawaii, as large crosswinds are not uncommon and present an unsafe situation to athletes.\n\nSome triathlon bikes use 650c wheels (a nominal diameter of 65 centimeters) rather than the conventional 700c wheels used on nearly all road bikes. The smaller wheels weigh less, have a smaller cross-sectional area (reducing wind resistance), and reduce the overall wind resistance of the bicycle by bringing the frame and cyclist closer to the ground. A potential drawback is that the smaller diameter means a higher curvature at the tire's contact patch, which increases rolling resistance. Which effect is more prominent depends on the cyclist and the windiness and steepness of the course.\n\nMany triathletes can be quite fixated with improving the aerodynamics and lowering the weight of their bicycles. As a result, the triathlon industry has developed a whole host of components which improve myriad characteristics of the bicycle. Examples include chainrings which have no holes or gaps (increasing aerodynamics a minuscule amount at the cost of a few grams of weight), brake and shifter cables which run inside the bicycle frame, and components of all sorts made from carbon fiber composite rather than steel or aluminum, in order to save weight.\n\nTriathletes often lace their running shoes with elastic shoelaces. This allows them to pre-set the tension of the laces but then to pull on the shoes without stopping to tie the laces. This saves a few seconds of time during the bike-to-run transition. The most popular brands of such laces that are designed specifically for triathlon are Lock Laces, Speedlaces, and Yankz.\n\nShoes with holes in the bottom allow water to drain out so that they do not become saturated and heavy, which can happen in long races like Iron-Man and Half-Iron-Man and can become very painful and annoying. Triathlon running stages are generally held later on the day compared to running races, creating a hotter temperature. Certain triathlon specific brand shoes already have holes in them for drainage.\n\nSocks are avoided, especially on shorter races, to give faster transitions, as they are not legal in swimming. If they are used they should be fast to put on. Not using socks can cause abrasion which might be painful. Triathletes should practice running the intended distance in the racing shoes without socks. There are triathlon specialty shoes with seamless insides, prepared for long distances without socks. On the Ironman distance some athletes use long compression socks in the expectation that an enhanced endurance will compensate for the extra time spent to put them on.\n\n\n"}
{"id": "7850829", "url": "https://en.wikipedia.org/wiki?curid=7850829", "title": "William Warrington", "text": "William Warrington\n\nWilliam Warrington, (1796–1869), was an English maker of stained glass windows. His firm, operating from 1832 to 1875, was one of the earliest of the English Medieval revival and served clients such as Norwich and Peterborough Cathedrals. Warrington was an historian of medieval glass and published an illustrated book \"The History of Stained Glass\".\n\nIn his youth, Warrington first trained with his father as a painter of armorial shields. He then moved for a time into the stained glass workshop of Thomas Willement, one of the earliest such workshops to be of high renown. In 1832 Warrington established his own stained glass company, where he produced windows that well satisfied the rising fashion of Gothic Revival and in which his own skills as an armorial painter were utilised in the production of domestic as well as ecclesiastical windows. \n\nFrom studying existent ancient windows and emulation of the leading techniques of the master Thomas Willement, Warrington developed a style which allowed him to create windows strongly resembling those of the 13th and 14th centuries in appearance. His windows became the preferred choice of the architect Augustus Welby Pugin who used them in most of his earliest churches, between 1838 and 1842. \n\nBut Pugin was soon to fall out with Warrington, claiming \"“The Glass-Painters will shorten my days, they are the greatest plague I have. The reason I did not give Warrington the window at the hospital is this. He has lately become so conceited and got nearly as expensive as Willement.”\" Warrington produced drawings of windows to be used by Pugin in the Houses of Parliament, but the firms that Pugin employed were Ballantine and Allen and Hardman & Co.\n\nIn 1848 Warrington published \"“The History of Stained Glass, from the Earliest Period of the Art to the Present Time”\" . The book came out in a folio edition with coloured lithographs illustrating British stained glass windows from the 11th to the 15th centuries. However Warrington expressed his dislike of the glass of the centuries that followed as being \"a misconception and misapplication of this art.\" \n\nAmong Warrington's significant commissions was the tiered arrangement of windows for the Eastern Apse of Norwich Cathedral. He also designed for Ely Cathedral, where his work may still be seen, both installed and on display in the Stained Glass Museum.\n\nAfter Warrington’s death in 1869, the firm continued until 1875.\n\nWarrington was able to reproduce closely the geometric and foliate backgrounds of the 13th century and create pictorial rondels composed of small pieces of glass that gave a similar impression to the Medieval originals, though tending to let through more light and have less luminosity, because the nature of the glass was less flawed and therefore less refractive. Warrington's windows often contain a background comprising a distinctive pattern of little red and blue diagonal checks which was copied from medieval originals.\nMany of Warrington’s Gothic Revival windows have a pleasant simplicity about them, the stylised foliage which takes up much of the window space being less heavy in appearance than some of his rivals, such as Clutterbuck, and based more closely upon recognisable plants. \n\nThe balance and arrangements of pictorial scenes within their formal background shows Warrington as a much more skilful designer than his teacher Willement, in whose windows the overall arrangement has a fairly arbitrary quality. Warrington’s figurative painting strives towards the Medieval in its forms, which are somewhat elongated and elegant, with simply-painted drapery falling in deep folds in such a way that line and movement is emphasised in the pictorial composition. His painting of the details, particularly of faces, is both masterly and exquisite. Towards the end of his career he also designed windows in a more painterly and less Gothic manner to suit changing tastes.\n\nSt. John's Horninglow, Burton on Trent - five-light east window illustrative of the life of St. John the Evangelist. Given by Mr. H. E. Smith, Shelbrook House, Ashby de la Zouch\n\n\n\n"}
