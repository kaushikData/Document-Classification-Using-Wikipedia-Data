{"id": "5315016", "url": "https://en.wikipedia.org/wiki?curid=5315016", "title": "Aeration", "text": "Aeration\n\nAeration (also called aerification or aeriation) is the process by which air is circulated through, mixed with or dissolved in a liquid or substance.\n\nAeration of liquids (usually water) is achieved by:\n\nPorous ceramic diffusers are made by fusing aluminum oxide grains using porcelain bonds to form a strong, uniformly porous and homogeneous structure. The naturally hydrophilic material is easily wetted resulting in the production of fine, uniform bubbles.\n\nOn a given volume of air or liquid, the surface area changes proportionally with drop or bubble size, the very surface area where exchange can occur. Utilizing extremely small bubbles or drops increases the rate of gas transfer (aeration) due to the higher contact surface area. The pores which these bubbles pass through are generally micrometre-size.\n\n\nIn soil, aeration refers to the extent of air gaps.\n\nSoil aeration is the process of using mechanized or manual equipment to either puncture the soil with spikes (spike aeration) or remove approximately 1\" x 2\" cores of soil from the ground (core aeration). Aeration may be overlooked when trying to restore a lawn but is vital to bring it back to health. It improves drainage and reduces puddles formation. \n\nSpike aeration involves the use of an aeration machine with spikes up to a foot or more in length. It is sometimes used to address drainage issues in areas with turf. Core aeration is done on turf areas as a means of reducing turf compaction, reducing thatch buildup, improving the infiltration of water/nutrients, encouraging deeper roots, and creating an environment where grass seed can have direct contact with the soil. \n\nThere are many types of lawn aerators including walk behind models, ride on versions and tractor pulled versions, as well as spiked shoes.\n\nRefers to the process in which air is absorbed into the food item. It refers to the lightness of cakes and bread, as measured by the type of pores they contain, and the color and texture of some sauces which have incorporated air bubbles.\n\nIn wine tasting, a variety of methods are used to aerate wine and bring out the aromas including swirl wine in the glass, use of a decanter to increase exposure to air, or a specialized wine aerator.\n\nCider from Asturias is poured into the glass from a height of about 1 metre (\"el escanciado\") to increase aeration.\n"}
{"id": "17099782", "url": "https://en.wikipedia.org/wiki?curid=17099782", "title": "AirNav Systems RadarBox", "text": "AirNav Systems RadarBox\n\nAirNav RadarBox is a Windows PC software and hardware package which allows appropriately equipped aircraft to be seen on a simulated radar screen. A small receiver connects to the PC via USB and aircraft are detected using the small supplied antenna. By decoding ADS-B (Automatic Dependent Surveillance Broadcast) transmissions from aircraft, those aircraft are displayed on a computer in a similar display to that used by Air Traffic Control. Flight number, aircraft type, altitude, heading, speed are visible and updated every second. The RadarBox system can be used at any location, either as a stand-alone system, or connected to the Internet which allows additional functions. An internal map database provides 3D multi-window maps with worldwide coverage and geographic points which include airports, runways, VOR, NDB, Fixes, cities, roads, airways and elevation data.\n\nWhen the PC running the RadarBox software is connected to the Internet, the RadarBox Network function is available. This allows viewing of data received by other RadarBox users all over the world. Network data is delayed by 5 minutes by default, but real-time Network data is also available.\n\nRadarBox24.com is a website showing AirNav RadarBox and other receivers data in real-time from all over the world.\nAirNav Systems has released iOS and Android mobile apps.\n\nThe screen consists of two major sections, the \"radar\" map and the tabbed information area. The map can be scrolled and zoomed using the mouse to view any area on the Earth's surface. Aircraft symbols and associated data blocks show flight information which includes aircraft type, registration and altitude. The information area allows viewing of aircraft lists for both live and network aircraft and gives access to other functions which include Alerting and Fleetwatch displays.\n\nRadarBox is also optionally available with a 3D and 2D map display based on Google Earth mapping.\n\n"}
{"id": "233956", "url": "https://en.wikipedia.org/wiki?curid=233956", "title": "Anti-pattern", "text": "Anti-pattern\n\nAn anti-pattern is a common response to a recurring problem that is usually ineffective and risks being highly counterproductive. The term, coined in 1995 by Andrew Koenig, was inspired by a book, \"Design Patterns\", which highlights a number of design patterns in software development that its authors considered to be highly reliable and effective.\n\nThe term was popularized three years later by the book \"AntiPatterns\", which extended its use beyond the field of software design to refer informally to any commonly reinvented but bad solution to a problem. Examples include analysis paralysis, cargo cult programming, death march, groupthink and vendor lock-in.\n\nAccording to the authors of \"Design Patterns\", there must be at least two key elements present to formally distinguish an actual anti-pattern from a simple bad habit, bad practice, or bad idea:\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "9288194", "url": "https://en.wikipedia.org/wiki?curid=9288194", "title": "Atmospheric chemistry observational databases", "text": "Atmospheric chemistry observational databases\n\nOver the last two centuries many environmental chemical observations have been made from a variety of ground-based, airborne, and orbital platforms and deposited in databases. Many of these databases are publicly available. All of the instruments mentioned in this article give online public access to their data. These observations are critical in developing our understanding of the Earth's atmosphere and issues such as climate change, ozone depletion and air quality. Some of the external links provide repositories of many of these datasets in one place. For example, the Cambridge Atmospheric Chemical Database, is a large database in a uniform ASCII format. Each observation is augmented with the meteorological conditions such as the temperature, potential temperature, geopotential height, and equivalent PV latitude.\n\n\n\n\n\n\n\n"}
{"id": "29126119", "url": "https://en.wikipedia.org/wiki?curid=29126119", "title": "Balloon", "text": "Balloon\n\nA balloon is a flexible bag that can be inflated with a gas, such as helium, hydrogen, nitrous oxide, oxygen, air or water. Modern day balloons are made from materials such as rubber, latex, polychloroprene, or a nylon fabric, and can come in many different colors. Some early balloons were made of dried animal bladders, such as the pig bladder. Some balloons are used for decorative purposes or entertaining purposes, while others are used for practical purposes such as meteorology, medical treatment, military defense, or transportation. A balloon's properties, including its low density and low cost, have led to a wide range of applications.\n\nThe rubber balloon was invented by Datboi in 1824, during experiments with various gases.\n\nBalloon decorating\n\nBalloons are used for decorating birthday parties, weddings, corporate functions, school events, and for other festive gatherings. The artists who use the round balloons to build are called \"stackers\" and the artists who use pencil balloons to build are called \"twisters.\" Most commonly associated with helium balloon decor, more recently balloon decorators have been moving towards the creation of air-filled balloon decorations due to the non-renewable natural resource of helium limited in supply. The most common types of balloon decor include arches, columns, centerpieces, balloon drops, sculptures, and balloon bouquets. With the increased aptitude for balloon twisting as well as balloon stacking, the rise of the deco-twister manifests itself as the combination of stacking techniques as well as twisting techniques to create unique and interesting balloon decor option. \nParty balloons are mostly made of a natural latex tapped from rubber trees, and can be filled with air, helium, water, or any other suitable liquid or gas. The rubber's elasticity makes the volume adjustable.\n\nFilling the balloon with air can be done with the mouth, a manual or electric inflater (such as a hand pump), or with a source of compressed gas.\n\nWhen rubber or plastic balloons are filled with helium so that they float, they typically retain their buoyancy for only a day or so, sometimes longer. The enclosed helium atoms escape through small pores in the latex which are larger than the helium atoms. Balloons filled with air usually hold their size and shape much longer, sometimes for up to a week.\n\nEven a perfect rubber balloon eventually loses gas to the outside. The process by which a substance or solute migrates from a region of high concentration, through a barrier or membrane, to a region of lower concentration is called diffusion. The inside of balloons can be treated with a special gel (for instance, the polymer solution sold under the \"Hi Float\" brand) which coats the inside of the balloon to reduce the helium leakage, thus increasing float time to a week or longer.\nBeginning in the late 1970s, some more expensive (and longer-lasting) foil balloons made of thin, unstretchable, less permeable metallised films such as Mylar (BoPET) started being produced. These balloons have attractive shiny reflective surfaces and are often printed with color pictures and patterns for gifts and parties. The most important attribute of metallised nylon for balloons is its lightweight, increasing buoyancy and its ability to keep the helium gas from escaping for several weeks. Foil balloons have been criticized for interfering with power lines.\n\nBalloon artists are entertainers who twist and tie inflated tubular balloons into sculptures (see balloon modelling). The balloons used for sculpture are made of extra-stretchy rubber so that they can be twisted and tied without bursting. Since the pressure required to inflate a balloon is inversely proportional to the diameter of the balloon, these tiny tubular balloons are extremely hard to inflate initially. A pump is usually used to inflate these balloons.\n\nDecorators may use helium balloons to create balloon sculptures. Usually the round shape of the balloon restricts these to simple arches or walls, but on occasion more ambitious \"sculptures\" have been attempted. It is also common to use balloons as table decorations for celebratory events. Balloons can sometimes be modeled to form shapes of animals. Table decorations normally appear with three or five balloons on each bouquet. Ribbon is curled and added with a weight to keep the balloons from floating away.\n\nA decorative use for balloons is in balloon drops. In a balloon drop, a plastic bag or net filled with air-inflated balloons is suspended from a fixed height. Once released, the balloons fall onto their target area below. Balloon drops are commonly performed at New Year's Eve celebrations and at political rallies and conventions, but may also be performed at celebrations, including graduations and weddings.\n\nFor decades, people have also celebrated with balloon releases. This practice has been discouraged by the balloon industry, as it has posed problematic for the environment and cities. In recent years, legislation, such as the California Balloon Law, has been enacted to enforce consumers and retailers to tether helium-filled foil (BoPET) balloons with a balloon weight. This ensures that the helium-filled balloons do not float into the atmosphere, which is both potentially injurious to animals, the environment, and power lines. Many states now have banned balloon releases.\n\nIt is becoming more common for balloons to be filled with air instead of helium, as air-filled balloons will not release into the atmosphere or deplete the earthly helium supply. There are numerous party games and school-related activities that can use air-filled balloons as opposed to helium balloons. When age-appropriate, these activities often include the added fun of blowing the balloons up. In many events, the balloons will contain prizes, and party-goers can pop the balloons to retrieve the items inside.\n\nBalloons are used for publicity at major events. Screen printing processes can be used to print designs and company logos onto the balloons. Custom built printers inflate the balloon and apply ink with elastic qualities through a silk screen template. In January 2008, the Jewish Community Relations Council of New York organized a display of 4,200 red balloons outside the United Nations Headquarters.\n\nAlso in the 1950s at the start of the Cold War, activists in Western Europe uses balloons for propaganda purposes that would float east over Eastern Europe, which would release newspapers and pamphlets. Today, South Korean activists are using the same balloon method to get information to those in North Korea.\n\nPaolo Scannavino set the record of 11 for the most giant balloons entered in 2 minutes.\n\nWater balloons are thin, small rubber balloons filled with a liquid, usually water, instead of a gas, and intended to be easily broken. They are usually used by children, who throw them at each other, trying to get each other wet, as a game, competition, or practical joke. By forcing water out the open end of a water balloon, it is possible to use it as a makeshift water gun.\n\nSolar balloons are thin, large balloons filled with air that is heated by the sun in order to decrease its density to obtain lift.\n\nBalloons are often deliberately released, creating a so-called balloon rocket. Balloon rockets work because the elastic balloons contract on the air within them, and so when the mouth of the balloon is opened, the gas within the balloon is expelled out, and due to Newton's third law of motion, the balloon is propelled forward. This is the same way that a rocket works.\n\nBalloons filled with hot air or a buoyant gas have been used as flying machines since the 18th century. The earliest flights were made with hot air balloons using air heated with a flame, or hydrogen as the lifting gas. Later, coal gas and later still helium were used. An unpowered balloon travels with the wind. A balloon which has an engine to propel it is called a dirigible balloon or airship.\n\nAngioplasty is a surgical procedure in which very small balloons are inserted into blocked or partially blocked blood vessels near the heart. Once in place, the balloon is inflated to clear or compress arterial plaque, and to stretch the walls of the vessel, thus preventing myocardial infarction. A small stent can be inserted at the angioplasty site to keep the vessel open after the balloon's removal.\n\nBalloon catheters are catheters that have balloons at their tip to keep them from slipping out. For example, the balloon of a Foley catheter is inflated when the catheter is inserted into the urinary bladder and secures its position.\n\nInsertion of balloons subsequently filled with air or liquid can be used to stop bleeding in hollow internal organs such as stomach or uterus.\n\nThere has been some environmental concern over metallised nylon balloons, as they do not biodegrade or shred as rubber balloons do. Release of these types of balloons into the atmosphere is considered harmful to the environment. This type of balloon can also conduct electricity on its surface and released foil balloons can become entangled in power lines and cause power outages.\n\nReleased balloons can land anywhere, including on nature reserves or other areas where they can pose a hazard to animals through ingestion or entanglement. Because of the potential harm to wildlife and the effect of litter on the environment, some jurisdictions even legislate to control mass balloon releases. Legislation proposed in Maryland, US, was named after Inky, a pygmy sperm whale who needed six operations after swallowing debris, the largest piece of which was a Mylar balloon. To date, there is no documentary evidence to suggest that the death of any sea mammal has been attributed to foil balloons as a sole cause. In the United Kingdom, foil balloons sold at major theme parks and zoos have balloon weights attached to help prevent accidental release into the environment.\n\nAnthony Andrady says that releases of latex balloons that descend into the sea pose a serious ingestion and/or entanglement hazard to marine animals because balloons exposed floating in seawater deteriorate much more slowly than those exposed in air. Balloon manufacturers will often state that a latex balloon is perfectly safe to release into the environment as it is made from a natural substance and will biodegrade over time. However, a latex balloon can take up to a year to degrade if it lands in the sea and during this time it is possible for a marine animal to ingest the balloon and die from slow starvation if its digestive system is blocked.\n\nNABAS (National Association of Balloon Artists and Suppliers), an organisation that styles itself \"The Balloon and Party Professionals Association\" and represents the UK balloon industry, publishes guidelines for people holding balloon releases.\n\nWhen balloons eventually return to the ground, they begin the degradation process. Latex balloons are the most used because of their ability to biodegrade. The problem with this is that it can take at least 4 weeks to show substantial degradation of the polymer in the environment, and around 6 months in aquatic environments. This issue can have an effect on the wildlife on both land and in aquatic systems because animals will confuse deflated balloons as food, nesting material, or simply something to play with. When that happens, it can lead to negative effects for the animals. For example, a bird will use a deflated balloon as a component for its nest. When the eggs hatch, they will get tangled in the balloon and that can lead to death. Another environmental problem with latex balloons is not the effects the balloons have on the environment once they are decomposed, but when they are being made. When latex is being produced, it produces greenhouse gases, such as CO, CH, NO. This is becoming an increasing problem, especially in Thailand which is responsible for 35% of the worlds natural rubber production.\n\nOnce inflated with regular, atmospheric air, the air inside the balloon will have a greater air pressure than the original atmospheric air pressure.\n\nAir pressure, technically, is a measurement of the amount of collisions against a surface at any time. In the case of balloon, it's supposed to measure how many particles at any in any given time space collide with the wall of the balloon and bounce off. However, since this is near impossible to measure, air pressure seems to be easier described as density. The similarity comes from the idea that when there are more molecules in the same space, more of them will be heading towards a collision course with the wall.\n\nThe first concept of air pressure within a balloon that is necessary to know is that air pressures \"try\" to even out. With all the bouncing against the balloon wall (both interior and exterior) there will be a certain amount of expansion/contraction. As air pressure itself is a description of the total forces against an object, each of these forces, on the outside of the balloon, causes the balloon to contract a tiny bit, while the inside forces cause the balloon to expand. With this knowledge, one would immediately assume that a balloon with high air pressure inside would expand based on the high amount of internal forces, and vice versa. This would make the inside and outside air pressures equal.\n\nHowever, balloons have a certain elasticity to them that needs to be taken into account. The act of stretching a balloon fills it with potential energy. When it is released, the potential energy is converted to kinetic energy and the balloon snaps back into its original position, though perhaps a little stretched out. When a balloon is filled with air, the balloon is being stretched. While the elasticity of the balloon causes tension that would have the balloon collapse, it is also being pushed back out by the constant bouncing of the internal air molecules. The internal air has to exert force not only to counteract the external air to keep the air pressures \"even\", but it also has to counteract the natural contraction of the balloon. Therefore, it requires more air pressure (or force) than the air outside the balloon wall. Because of this, when helium balloons are left and they float higher, as atmospheric pressure decreases, the air inside it exerts more pressure than outside it so the balloon pops from tension. In some cases, the helium leaks out from pores and the balloon deflates, falling down.\n\n\"Stories Behind Everyday Things\"; New York: Reader's Digest, 1980.\n\n"}
{"id": "51309912", "url": "https://en.wikipedia.org/wiki?curid=51309912", "title": "BetterHelp", "text": "BetterHelp\n\nBetterHelp is an online portal that provides direct-to-consumer access to behavioral health services. The online counseling and therapy services are provided through web-based interaction as well as phone and text communication. BetterHelp was founded in 2013 by Alon Matas and Danny Bragonier, and acquired by Teladoc, Inc. in 2015. BetterHelp maintained its brand name post acquisition and continues to provide online counseling services to consumers.\n\nBetterHelp was founded by Alon Matas in 2013, after he faced personal challenges finding professional counseling services that accommodated his schedule. With the mission of helping all those facing similar challenges in gaining access to professional counseling, Matas partnered with co-founder Danny Bragonier to develop BetterHelp’s web-based counseling portal and therapist directory. Revenue had reached a projected $60 million by 2018.\n\nBetterHelp is a web-based platform that allows patients to interact with counselors and therapists online in a private web-based setting. Client and patient are provided a dedicated \"room\" on its website, which acts as a private and secure online portal for communication. The “room” is open 24/7 and can be accessed from any Internet-connected device from any physical location.\n\nIn 2015, BetterHelp was acquired by Teladoc, Inc., a telehealth company that uses telephone and videoconferencing technology to provide on-demand remote therapy. Teledoc acquired BetterHelp for $3.5 million in cash and a $1.0 million promissory note, with an agreement to make annual payments to the sellers equal to 15% of the total net revenue generated by the BetterHelp business for each of the next three years. \n\nIn October of 2018, BetterHelp gained attention from media personalities after concerns were raised about alleged use of unfair pricing, paid reviews from actors and questionable terms of service. CEO Alon Matas issued a statement responding to the allegations. YouTube content creators such as PewDiePie and Boogie2988 have spoken out on this issue.\n"}
{"id": "7397481", "url": "https://en.wikipedia.org/wiki?curid=7397481", "title": "Carbon dioxide flooding", "text": "Carbon dioxide flooding\n\nCarbon dioxide (CO) flooding is a process whereby carbon dioxide is injected into an oil reservoir in order to increase output when extracting oil.\n\nWhen a reservoir’s pressure is depleted through primary and secondary production, carbon dioxide flooding can be an ideal tertiary recovery method. It is particularly effective in reservoirs deeper than 2,500 ft., where will be in a supercritical state, with API oil gravity greater than 22–25° and remaining oil saturation greater than 20%. Carbon dioxide flooding is not affected by the lithology of the reservoir area, but simply by the reservoir porosity and permeability, so that it is viable in both sandstone and carbonate reservoirs.\nBy injecting CO into the reservoir, the viscosity of any hydrocarbon will be reduced and hence will be easier to sweep to the production well.\n\nAs an oil field matures and production rates decline, there is growing incentive to intervene and attempt to increase oil output utilizing tertiary recovery techniques (also termed improved or enhanced oil recovery). Petroleum engineers assess available options for increasing well productivity, options that include chemical injection, thermal/steam injection, and CO injection. Based on data-gathering and computer simulations, the most optimal enhanced oil-recovery technique to maximize well-productivity is determined. To increase the rate of oil production, the pressure within the reservoir must be increased.\n\nIn CO flooding, the first step is injection of water into the reservoir, which will cause the reservoir pressure to increase. Once the reservoir has sufficient pressure, the next step is to pump the CO down through the same injection wells. The CO gas is forced into the reservoir to come into contact with the oil. This creates a miscible zone that can be moved more easily to the production well. Normally the CO injection is alternated with water injection and the water acts to sweep the oil towards the production zone.\n\nCO flooding is the second most common tertiary recovery technique and is used in facilities around the world. In connection with greenhouse gas emissions and global warming, CO flooding sequesters underground and therefore offsets CO emissions elsewhere.\n\n"}
{"id": "46378961", "url": "https://en.wikipedia.org/wiki?curid=46378961", "title": "Carousell (company)", "text": "Carousell (company)\n\nCarousell is a smartphone and web-based consumer to consumer marketplace for buying and selling new and secondhand goods. It is headquartered in Singapore. Carousell operates within Singapore, Malaysia, Indonesia, Taiwan, Hong Kong, and Australia. Carousell is currently available as a mobile app for both Apple and Android devices.\n\nCarousell was founded in Singapore on May 14, 2012, by co-founders Quek Siu Rui, Lucas Ngoo, and Marcus Tan, all graduates of Ngee Ann Polytechnic The first item sold on Carousell was an Amazon Kindle e-reader for S$75. Carousell was subsequently registered as Carousell Pte. Ltd. on Jan 2, 2013.\n\nCarousell received its first investment from Quest Ventures. In November 2013, Rakuten, with follow-on investments by Golden Gate Ventures, 500 Startups, and a few other investors invested $1 million in Carousell. Subsequently, in November 2014, Carousell announced that it received US$6 million in investment from Sequoia India. In August 2016, Carousell raised $35 million in their Series B funding round by Rakuten Ventures, Sequoia India, Golden Gate Ventures, and 500 Startups.\n\nAs of 2016, over 23 million items had been sold on Carousell and users had created over 57 million listings of new and used items for sale.\n\nCarousell has expanded regionally to seven countries, including Australia, Hong Kong, Malaysia, Indonesia, and Taiwan. However, Carousell's expansion into Taiwan faces competition against headstart companies like Yahoo! and Ruten, which are already settled in the e-commerce market.\n\nThe company raised $85 million Series C funding in May 2018. The round was co-led by existing investor Rakuten Ventures and EDBI. Other participants included 500 Startups, Golden Gate Ventures and Sequoia India as well as new investor DBS.\n\nIn January 2013, Singapore Press Holdings' ST Classifieds announced its collaboration with Carousell.\n\nAccording to a Yahoo Finance article in August 2013, Carousell announced its partnership with Singapore Press Holdings (SPH) Magazines, a subsidiary of SPH, to create a mobile app called SheShops Marketplace, selling fashion and beauty items.\n\nCarousell is an online mobile platform for consumers to buy or sell items. It lists and sells a variety of products. Items are prohibited for sale on Carousell if they are illegal or they violate the marketplace's community guidelines.\n\nIn a Yahoo Tumblr page, images of users posting photos or screenshots of their bad experiences they encounter on Carousell relating to scam, fraud and harassment have circulated on social media platforms like Facebook and Tumblr. Users of Carousell have also complained about cases of scams by fake sellers.\n"}
{"id": "2179652", "url": "https://en.wikipedia.org/wiki?curid=2179652", "title": "Cluster impact fusion", "text": "Cluster impact fusion\n\nCluster Impact Fusion is a suggested method of producing practical fusion power using small clusters of heavy water molecules directly accelerated into a titanium-deuteride target. Calculations suggested that such a system enhanced the cross section by many orders of magnitude.\n\nThe idea was first reported by researchers at Brookhaven in 1989. Intrigued by recent reports of cold fusion, they attempted to study potential causes for the effect by accelerating tiny droplets of heavy water, about 25 to 1300 D2O molecules each, into a target at about 220 eV. To their surprise they immediately saw fusion effects, at a rate that was many times what any of them could explain via conventional theory.\n\nThe experiment was fairly simple in concept but required an appropriate accelerator, so it was some time before other labs were able to repeat the experiments. One of the first was the University of Washington, who reported a null result in 1991. Further experiments and a review from MIT in 1992 solved the mystery: the fusion products were the results of contamination, which could be eliminated by filtering with a magnet. The Brookhaven experimenters tried this and the effect disappeared. Cluster fusion references end abruptly at that point.\n\n\n Estimates of cluster-impact fusion yields\n\n"}
{"id": "47887859", "url": "https://en.wikipedia.org/wiki?curid=47887859", "title": "Cycle of quantification/qualification", "text": "Cycle of quantification/qualification\n\nCycle of quantification/qualification (C) is a parameter used in real-time polymerase chain reaction techniques, indicating the cycle number where a PCR amplification curve meets a predefined mathematical criterion. A C may be used for quantification of the target sequence or to determine whether the target sequence is present or not.\n\nTwo criteria to determine the C are used by different thermocyclers:\nCycle of Threshold (CT) is the number of cycles required for the fluorescent signal to cross a given value threshold. Usually, the threshold is set above the baseline, about 10 times the standard deviation of the noise of the baseline, to avoid random effects on the CT. However, the threshold shouln't be set much higher than that to avoid reduced reproducibility due to uncontrolled factors. \nCrossing point (Cp) and Take off point (TOP) are the cycle value of the maximum second derivative of the amplification curve.\n"}
{"id": "39456703", "url": "https://en.wikipedia.org/wiki?curid=39456703", "title": "Density cup", "text": "Density cup\n\nA density cup is an instrument that is used to ensure quality control in a paint or lacquer. It does this by measuring the density of the paint or lacquer, and comparing this density with the density of a standard for that paint or lacquer. If the density reading is different from the standard, then there is an error in paint composition because if there were no error in paint composition, then the measurement would match up to the standard density for that paint or lacquer.\n\nKnowing the density of a paint is essential because a consistent density assures overall consistency between products of the same color.\n\nDensity cups are precisely measured cylinders that are made of stainless steel, and usually have a hole in the top through which excess liquid and air bubbles can escape. \n"}
{"id": "25571951", "url": "https://en.wikipedia.org/wiki?curid=25571951", "title": "Dry blender", "text": "Dry blender\n\nA dry blender is a type of industrial mixer which is typically used to blend multiple dry components until they are homogenous. Often minor liquid additions are made to the dry blend to modify the product formulation. Blending times using dry ingredients are often short (15–30 minutes) but are somewhat dependent upon the varying percentages of each component, and the difference in the bulk densities of each.\n\nRibbon, Paddle, Tumble and Vertical Blenders are available. Many products including pharmaceuticals, foods, chemicals, fertilizers, plastics, pigments, and cosmetics are manufactured in these designs.\n\nDry blenders range in capacity from half-cubic-foot laboratory models to 500-cubic-foot production units. A wide variety of horsepower-and-speed combinations and optional features such as sanitary finishes, vacuum construction, special valves and cover openings are offered by most manufacturers.\n\n\n"}
{"id": "16105186", "url": "https://en.wikipedia.org/wiki?curid=16105186", "title": "Electric car", "text": "Electric car\n\nAn electric car (also battery electric car or all-electric car) is a plug-in electric automobile that is propelled by one or more electric motors, using energy typically stored in rechargeable batteries.\n\nSince 2008, a renaissance in electric vehicle manufacturing occurred due to advances in batteries, concerns about increasing oil prices, and the desire to reduce greenhouse gas emissions. Several national and local governments have established tax credits, subsidies, and other incentives to promote the introduction and adoption in the mass market of new electric vehicles, often depending on battery size, their electric range and purchase price. The current maximum tax credit allowed by the US Government is . Compared with internal combustion engine vehicles, electric cars are quieter and have no tailpipe emissions, and, often lower emissions in general. \nCharging an electric car can be done at a variety of charging stations, these charging stations can be installed in both houses and public areas. The two best selling electric vehicles, the Nissan Leaf and the Tesla Model S, have EPA ranges reaching 151 miles (243 km) and 335 miles (539 km) respectively.\n\n, there are over 4 million all-electric and plug-in hybrid cars in use around the world, of which, 2.6 million were pure electric cars (65%). The Nissan Leaf is the best-selling highway-capable electric car ever, with over 350,000 units sold globally by September 2018. Ranking second is the Tesla Model S with 250,000 units sold worldwide through September 2018.\n\nElectric cars are a variety of electric vehicle (EV). The term \"electric vehicle\" refers to any vehicle that uses electric motors for propulsion, while \"electric car\" generally refers to highway-capable automobiles powered by electricity. Low-speed electric vehicles, classified as neighborhood electric vehicles (NEVs) in the United States, and as electric motorised quadricycles in Europe, are plug-in electric-powered microcars or city cars with limitations in terms of weight, power and maximum speed that are allowed to travel on public roads and city streets up to a certain posted speed limit, which varies by country.\n\nWhile an electric car's power source is not explicitly an on-board battery, electric cars with motors powered by other energy sources are typically referred to by a different name. An electric car carrying solar panels to power it is a solar car, and an electric car powered by a gasoline generator is a form of hybrid car. Thus, an electric car that derives its power from an on-board battery pack is a form of battery electric vehicle (BEV). Most often, the term \"electric car\" is used to refer to battery electric vehicles, but may also refer to plug-in hybrid electric vehicles (PHEV).\n\nIn 1884, over 20 years before the Ford Model T, Thomas Parker built the first practical production electric car in London using his own specially designed high-capacity rechargeable batteries. The \"Flocken Elektrowagen\" of 1888 was designed by German inventor Andreas Flocken. Electric cars were among the preferred methods for automobile propulsion in the late 19th century and early 20th century, providing a level of comfort and ease of operation that could not be achieved by the gasoline cars of the time. The electric vehicle stock peaked at approximately 30,000 vehicles at the turn of the 20th century.\n\nIn 1897, electric cars found their first commercial use in the US. Based on the design of the Electrobat II, a fleet of twelve hansom cabs and one brougham were used in New York City as part of a project funded in part by the Electric Storage Battery Company of Philadelphia. During the 20th century, the main manufacturers of electric vehicles in the US were Anthony Electric, Baker, Columbia, Anderson, Edison, Riker, Milburn, Bailey Electric and others. Unlike gasoline-powered vehicles, the electric ones were less noisy, and did not require gear changes.\n\nAdvances in internal combustion engines (ICE) in the first decade of the 20th century lessened the relative advantages of the electric car. Their much quicker refueling times, and cheaper production costs, made them more popular. However, a decisive moment was the introduction in 1912 of the electric starter motor which replaced other, often laborious, methods of starting the ICE, such as hand-cranking.\n\nSix electric cars held the land speed record. The last of them was the rocket-shaped La Jamais Contente, driven by Camille Jenatzy, which broke the speed barrier by reaching a top speed of on 29 April 1899.\n\nIn the early 1990s, the California Air Resources Board (CARB) began a push for more fuel-efficient, lower-emissions vehicles, with the ultimate goal being a move to zero-emissions vehicles such as electric vehicles. In response, automakers developed electric models, including the Chrysler TEVan, Ford Ranger EV pickup truck, GM EV1, and S10 EV pickup, Honda EV Plus hatchback, Nissan Altra EV miniwagon, and Toyota RAV4 EV. Both US Electricar and Solectria produced 3-phase AC Geo-bodied electric cars with the support of GM, Hughes, and Delco. These early cars were eventually withdrawn from the U.S. market.\n\nCalifornia electric automaker Tesla Motors began development in 2004 on what would become the Tesla Roadster (2008), which was first delivered to customers in 2008. The Roadster was the first highway legal serial production all-electric car to use lithium-ion battery cells, and the first production all-electric car to travel more than per charge.\n\nTesla global sales passed 250,000 units in September 2017. The Renault–Nissan–Mitsubishi Alliance achieved the milestone of 500,000 units electric vehicles sold in October 2017. Tesla sold its 200,000th Model S in the fourth quarter of 2017. Global Leaf sales passed 300,000 units in January 2018, keeping its record as the world's top selling plug-in electric car ever. Tesla delivered its 100,000th Model 3 in October 2018.\n\nMany countries have set goals to ban the sales of gasoline and diesel powered vehicles in the future, notably; Norway by 2025, China by 2030, India by 2030, Germany by 2030, France by 2040, and Britain by 2040 or 2050. Similarly, more cities around the world have begun transitioning public transportation towards electric vehicles, than previously was the case.\n\n, electric cars are less expensive to run than comparable internal combustion engine vehicles due to the lower cost of repairs and energy. However, as of 2018, electric cars on average cost significantly more to initially buy, and depreciate more quickly than conventional cars.\n\nThe Chinese auto manufacturer BYD calculated on its website in 2015 that a BYD e6 taxi over five years would give a saving of about $74,000 over the equivalent petrol consumption.\n\nIn 2018 the Australian Federal Government’s advisory firm on vehicle emissions estimated the TCO for electric cars was 5 to 10 thousand dollars more per year than a roughly equivalent petrol powered car.\n\nSeveral national and local governments have established incentives to reduce the purchasing price of electric cars and other plug-ins.\n\nWhen designing an electric vehicle, manufacturers may find that for low production, converting existing platforms may be cheaper as development cost is lower, however, for higher production, a dedicated platform may be preferred to optimize design, and cost.\n\nAlmost 80% of electric vehicles in the U.S. are leased, while the lease rate for the country's entire fleet is about 30%. In early 2018, electric compact cars of 2014 are worth 23 percent of their original sticker price, as comparable cars with combustion engines worth 41 percent.\n\nBatteries play a significant cost when designing an electric vehicle, for example; Tesla Motors uses batteries that cost around $200 per kilowatt hour.\n\nAccording to a study done in 2018, the average operating cost of an electric vehicle in the United States is $485 per year, as opposed to an Internal combustion engines $1,117 per year.\n\nElectric cars have several benefits over conventional internal combustion engine automobiles, including a significant reduction of local air pollution, as they do not directly emit pollutants such as particulates (soot), volatile organic compounds, hydrocarbons, carbon monoxide, ozone, lead, and various oxides of nitrogen.\n\nDepending on the production process and the source of the electricity to charge the vehicle, emissions may be partly shifted from cities to the material transportation, production plants and generation plants. The amount of carbon dioxide emitted depends on the emissions of the electricity source, and the efficiency of the vehicle. For electricity from the grid, the emissions vary significantly depending on your region, the availability of renewable sources and the efficiency of the fossil fuel-based generation used.\n\nThe same is true of ICE vehicles. The sourcing of fossil fuels (oil well to tank) causes further damage and use of resources during the extraction and refinement processes,including high amounts of electricity. \nIn December 2014, Nissan announced that Leaf owners have accumulated together 1 billion kilometers (620 million miles) driven. This translates into saving 180 million kilograms of emissions by driving an electric car in comparison to travelling with a gasoline-powered car. In December 2016, Nissan reported that Leaf owners worldwide achieved the milestone of 3 billion kilometers (1.9 billion miles) driven collectively through November 2016.\n\nElectric motors can provide high power-to-weight ratios, batteries can be designed to supply the currents needed to support these motors. Electric motors have flat torque curve down to zero speed. For simplicity and reliability, many electric cars use fixed-ratio gearboxes and have no clutch.\n\nMany electric cars have motors that have high acceleration, relative to comparable cars, however, Neighborhood Electric Vehicles may have a low acceleration due to their relatively weak motors. This is largely due to the relatively constant torque of an electric motor, which often increase the acceleration relative to a similar motor power internal combustion engine.\n\nElectric vehicles can also use a direct motor-to-wheel configuration which increases the available power. Having motors connected directly to each wheel allows the wheels to be used both for propulsion and as braking systems, thereby increasing traction. When not fitted with an axle, differential, or transmission, electric vehicles have less drive-train inertia.\n\nFor example, the Venturi Fetish delivers supercar acceleration despite a relatively modest , and top speed of around . Some DC-motor-equipped drag racer EVs have simple two-speed manual transmissions to improve top speed. The Tesla Roadster (2008) 2.5 Sport can accelerate from in 3.7 seconds with a motor rated at . Tesla Model S P100D (Performance / 100kWh / 4-wheel drive) is capable of 2.28 seconds for 0–60 mph at a price of $140,000 . , the P100D is the second fastest production car ever built, taking only 0.08 seconds longer for , compared to a $847,975 Porsche 918 Spyder. The electric supercar Rimac Concept One can go from in 2.5 seconds.\n\nInternal combustion engines have thermodynamic limits on efficiency, expressed as fraction of energy used to propel the vehicle compared to energy produced by burning fuel. Gasoline engines effectively use only 15% of the fuel energy content to move the vehicle or to power accessories, and diesel engines can reach on-board efficiency of 20%, while electric vehicles have on-board efficiency of over 90%, when counted against stored chemical energy, or around 80%, when counted against required energy to recharge.\n\nElectric motors are more efficient than internal combustion engines in converting stored energy into driving a vehicle. Electric cars can not idle. Regenerative braking, which is most common in electric vehicles, can recover as much as one fifth of the energy normally lost during braking.\n\nProduction and conversion electric cars typically use 10 to 23 kW·h/100 km (0.17 to 0.37 kW·h/mi). Approximately 20% of this power consumption is due to inefficiencies in charging the batteries. Tesla Motors indicates that the vehicle efficiency (including charging inefficiencies) of their lithium-ion battery powered vehicle is 12.7 kW·h/100 km (0.21 kW·h/mi) and the well-to-wheels efficiency (if the electricity is generated from natural gas) is 24.4 kW·h/100 km (0.39 kW·h/mi).\n\nWhile heating can be provided with an electric resistance heater, higher efficiency and integral cooling can be obtained with a reversible heat pump. PTC junction cooling is also attractive for its simplicity — this kind of system is used, for example, in the Tesla Roadster (2008).\n\nTo avoid using part of the battery's energy for heating and thus reducing the range, some models allow the cabin to be heated while the car is plugged in. For example, the Nissan Leaf, the Mitsubishi i-MiEV and the Tesla Model S can be pre-heated while the vehicle is plugged in.\n\nSome electric cars, for example the Citroën Berlingo Electrique, use an auxiliary heating system (for example gasoline-fueled units manufactured by Webasto or Eberspächer) but sacrifice \"green\" and \"Zero emissions\" credentials. Cabin cooling can be augmented with solar power, or by automatically allowing outside air to flow through the car when parked. Two models of the 2010 Toyota Prius include this feature as an option.\n\nThe safety issues of BEVs are largely dealt with by the international standard ISO 6469. This document is divided in three parts dealing with specific issues:\n\n\nLike their internal combustion engine counterparts, electric vehicle batteries can catch fire after a crash or mechanical failure. Plug-in electric vehicle fire incidents have occurred, albeit less per mile than I.C.E vehicles. \nThe first modern crash-related fire was reported in China in May 2012, after a high-speed car crashed into a BYD e6 taxi in Shenzhen. The second reported incident occurred in the United States on October 1, 2013, when a Tesla Model S caught fire over ten minutes after the electric car hit metal debris on a highway in Kent, Washington state, and the debris punctured one of 16 modules within the battery pack. A third reported fire occurred on October 18, 2013 in Merida, Mexico. In this case the vehicle was being driven at high speed through a roundabout and crashed through a wall and into a tree. The fire broke out several minutes after the driver exited the vehicle.\n\nIn the United States, General Motors ran in several cities a training program for firefighters and first responders to demonstrate how to safely disable the Chevrolet Volt’s powertrain and its 12 volt electrical system. The Volt's high-voltage system is designed to shut down automatically in the event of an airbag deployment, and to detect a loss of communication from an airbag control module. GM also made available an Emergency Response Guide for the 2011 Volt for use by emergency responders. The guide also describes methods of disabling the high voltage system and identifies cut zone information. Nissan also published a guide for first responders that details procedures for handling a damaged 2011 Leaf at the scene of an accident, including a manual high-voltage system shutdown, rather than the automatic process built-in the car's safety systems.\n\nThe weight of the batteries themselves usually makes an EV heavier than a comparable gasoline vehicle, in a collision, the occupants of a heavy vehicle will on average, suffer fewer and less serious injuries than the occupants of a lighter vehicle; therefore, the additional weight brings safety benefits despite having a negative effect on the car's performance. Depending on where the battery is located, it may lower the center of gravity, increasing driving stability, lowering the risk of an accident through loss of control.\nAn accident in a vehicle will on average cause about 50% more injuries to its occupants than a vehicle.\n\nSome electric cars use low rolling resistance tires, which typically offer less grip than normal tires. The Insurance Institute for Highway Safety in America had condemned the use of low speed vehicles and \"mini trucks,\" referred to as neighborhood electric vehicles (NEVs) when powered by electric motors, on public roads. Mindful of this, several companies (Tesla Motors, BMW, Uniti) have succeeded in keeping the body light, while making it very strong.\n\nAt low speeds, electric cars produced less roadway noise than vehicles propelled by internal combustion engines. Blind or visually impaired people consider the noise of combustion engines a helpful aid while crossing streets, hence electric cars and hybrids could pose an unexpected hazard. Tests have shown that this is a valid concern, as vehicles operating in electric mode can be particularly hard to hear below , which affects all road users, not just the visually impaired. At higher speeds, the sound created by tire friction and the air displaced by the vehicle start to make sufficient audible noise.\n\nThe Government of Japan, the U.S. Congress, and the European Parliament passed legislation to regulate the minimum level of sound for hybrids and plug-in electric vehicles when operating in electric mode, so that blind people and other pedestrians and cyclists can hear them coming and detect from which direction they are approaching. The Nissan Leaf was the first electric car to use Nissan's Vehicle Sound for Pedestrians system, which includes one sound for forward motion and another for reverse. , most of the hybrids and plug-in electric and hybrids available in the United States, Japan and Europe make warning noises using a speaker system. The Tesla Model S is one of the few electric cars without warning sounds; Tesla Motors will wait until regulations are enacted. Volkswagen and BMW also decided to only add artificial sounds to their electric drive cars only when required by regulation.\n\nSeveral anti-noise and electric car advocates have opposed the introduction of artificial sounds as warning for pedestrians, as such an introduction is based on vehicle type and not actual noise level, a concern regarding ICE vehicles which themselves are becoming quieter.\n\n, most Electric cars have similar driving controls to that of a car with a conventional automatic transmission. Even though the motor may be permanently connected to the wheels through a fixed-ratio gear and no parking pawl may be present the modes \"P\" and \"N\" are often still provided on the selector. In this case the motor is disabled in \"N\" and an electrically actuated hand brake provides the \"P\" mode.\n\nIn some cars the motor will spin slowly to provide a small amount of creep in \"D\", similar to a traditional automatic.\n\nWhen the foot is lifted from the accelerator of an ICE, engine braking causes the car to slow. An EV would coast under these conditions, if it wasn't for regenerative braking which instead provides a more familiar response and recharges the battery to an extent. These features also reduce the use of the conventional brakes, significantly reducing wear and tear and maintenance costs as well as improving vehicle range.\n\nLithium-based batteries are often chosen for their high power and energy density, although may wear out over a long period of time. However, there are many emergring technologies trying to combat this issue.\n\nThere are also other battery types, such as Nickel metal hydride (NiMH) batteries which have a poorer power to weight ratio than lithium ion, but are cheaper. Several other battery chemistries are in development such as zinc-air battery which could be much lighter.\n\nThe range of an electric car depends on the number and type of batteries used, and as with all vehicles, the weight and type of vehicle, performance requirements, and the weather.\n\nThe range of production electric vehicles in 2017 ranged from (Renault Twizy) to (Tesla Model S 100D)\n\nThe majority of electric cars are fitted with a display of expected range. This may take into account many factors of how the vehicle is being used, and what the battery is powering. However, since factors can vary over the route, the estimate can vary from the actual achieved range. The display allows the driver to make informed choices about driving speed and whether to stop at a charging point en route. Some roadside assistance organizations offer charge trucks to recharge electric cars in case of emergency.\n\nA study in 2016 stated that 87% of US vehicle-days can be met by current affordable electric cars.\n\nElectric cars are typically charged overnight from a charging station installed in the owner's house, or from faster charging stations found in businesses and public areas.\n\nAn overnight charge of 8 hours will only give about a 40 mile charge with a standard 120 volt outlet whereas a 240 volt outlet would give around 180 miles in the same amount of time. \n\nWithin each major region of the world, electric car charging stations are essentially universal across car and charger brands, and simply plugging in a charger into an electric car will charge the car at the fastest rate that car and charger can support. A notable exception are the Tesla line of cars and charging stations, which use their own proprietary chargers. However, this can be solved by using a converter.\n\nSome companies have been experimenting with battery swapping to eliminate delay while charging.\n\nSome electric vehicles have built in generators, these are considered a type of hybrid vehicle.\n\nAs with all lithium-ion batteries, electric vehicle batteries may degrade over long periods of time, especially if they are frequently overcharged, however, this may take at least several years before being noticeable.\n\nHowever, Nissan stated in 2015 that thus far only 0.01 percent of batteries had to be replaced because of failures or problems, and then only because of externally inflicted damage. The vehicles that had already covered more than , have no problems with the battery.\n\nOver half of the world's cobalt, a key element in lithium-ion batteries, is mined in the Democratic Republic of Congo where the children are forced to mine the cobalt while having little to no protection. \n\n\nVolkswagen, in collaboration with six partners, is developing an EU research project that is focused on automating the parking and charging of electric vehicles. The objective of this project is to develop a smart car system that allows for autonomous driving in designated areas (e.g. valet parking, park and ride) and can offer advanced driver support in urban environments. Tesla has shown interest in making an arm that automatically charges their vehicles.\n\n\nIt is estimated that there are sufficient lithium reserves to power 4 billion electric cars. Most electric cars use a lithium-ion battery and an electric motor which uses rare-earth elements. The demand for lithium, heavy metals, and other elements (such as neodymium, boron and cobalt) required for the batteries and powertrain is expected to grow significantly due to the future sales increase of plug-in electric vehicles in the mid and long term. Some of the largest world reserves of lithium and other rare metals are located in countries with strong resource nationalism, unstable governments or hostility to U.S. interests, raising concerns about the risk of replacing dependence on foreign oil with a new dependence on hostile countries to supply strategic materials.\n\nExperimental supercapacitors and flywheel energy storage devices offer comparable storage capacity, faster charging, and lower volatility. They have the potential to overtake batteries as the preferred rechargeable storage for EVs. The FIA included their use in its sporting regulations of energy systems for Formula One race vehicles in 2007 (for supercapacitors) and 2009 (for flywheel energy storage devices).\n\nSolar cars are electric vehicles powered completely or significantly by direct solar energy, usually, through photovoltaic (PV) cells contained in solar panels that convert the sun's energy directly into electric energy, usually used to charge a battery.\n\nQualcomm, Hyundai, Ford, and Mitsubishi are the top patent holders of the close to 800 electric vehicle charging patents filed between 2014 and 2017. A majority of patents on electric vehicle charging were filed in Japan between 2014 and 2017. It is followed by the US and then by China.\n\nBattery Electric Vehicles are most commonly charged from the power grid overnight at the owner's house, provided they have their own charging station. The electricity on the grid is in turn generated from a variety of sources; such as coal, hydroelectricity, nuclear and others. Power sources such as photovoltaic solar cell panels, micro hydro or wind may also be used and are promoted because of concerns regarding global warming.\n\nCharging stations can have a variety of different speeds of charging, with slower charging being more common for houses, and more powerful charging stations on public roads and areas for trips. The BMW i3 can charge 0–80% of the battery in under 30 minutes in rapid charging mode. The superchargers developed by Tesla Motors provided up to 130 kW of charging, allowing a 300-mile charge in about an hour.\n\nMost electric cars have used conductive coupling to supply electricity for recharging after the California Air Resources Board settled on the SAE J1772-2001 standard as the charging interface for electric vehicles in California in June 2001. In Europe, the ACEA has decided to use the Type 2 connector from the range of IEC_62196 plug types for conductive charging of electric vehicles in the European Union, as the Type 1 connector (SAE J1772-2009) does not provide for three-phase charging.\n\nAnother approach is inductive charging using a non-conducting \"paddle\" inserted into a slot in the car. Delco Electronics developed the Magne Charge inductive charging system around 1998 for the General Motors EV1 which was also used for the Chevrolet S-10 EV and Toyota RAV4 EV vehicles.\n\nDuring peak load periods, when the cost of generation can be very high, electric vehicles could contribute energy to the grid. These vehicles can then be recharged during off-peak hours at cheaper rates while helping to absorb excess night time generation. Here the batteries in the vehicles serve as a distributed storage system to buffer power.\n\nElectric vehicles provide for less dependence on foreign oil, which for the United States and other developed or emerging countries is cause for concern about vulnerability to oil price volatility and supply disruption. Also for many developing countries, and particularly for the poorest in Africa, high oil prices have an adverse impact on their balance of payments, hindering their economic growth. In the United States, presidential candidate Obama proposed in 2008 \"1 million plug-in and electric\" cars by 2015. At the end of 2015 about 550 thousand plugin-in vehicles had been sold in the US.\n\n, there were over 30 models of highway-capable all-electric passenger cars and utility vans available in the market for retail sales. The Renault–Nissan–Mitsubishi Alliance is the world's leading all-electric vehicle manufacturer. By mid-2018, the Alliance's global all-electric vehicle sales totaled about 600,000 units, including those manufactured by Mitsubishi Motors, now part of the Alliance.\n\nTesla is the second best-selling all-electric vehicle manufacturer with almost 500,000 electric cars delivered worldwide by November 2018. Its Model S was the world's best selling plug-in electric car for two years in a row, 2015 and 2016. \nThe world's all-time top selling highway legal electric car is the Nissan Leaf, released in December 2010, with global sales of more than 350,000 units by September 2018. The Tesla Model S ranks second with global sales of 250,000 cars delivered . The Renault Kangoo Z.E. utility van is the leader of the light-duty all-electric segment with global sales of 35,310 units through September 2018.\n\nThe following table lists the all-time best-selling highway-capable all-electric passenger cars with cumulative global sales of around or more than 75,000 units since their inception through September 2018:\n\nGlobal sales of highway legal plug-in electric passenger cars and light utility vehicles achieved the one million milestone in September 2015, almost twice as fast as hybrid electric vehicles (HEV). While it took four years and 10 months for the plug-in segment to reach one-million sales, it took more than around nine years and a few months for HEVs to reach its first million sales. Cumulative global sales of light-duty all-electric vehicles reached one million units in September 2016.\n\nCumulative global sales of plug-in cars passed 2 million in December 2016, the 3 million mark in November 2017, and 4 million in September 2018.\nDespite the rapid growth experienced, the stock of plug-in electric cars represented just about 1 out of every 300 vehicles on the world's roads by September 2018. When global sales are broken down by type of powertrain, all-electric cars have oversold plug-in hybrids, the global ratio between the stock of all-electrics (BEVs) and plug-in hybrids (PHEVs) was 61:39 at the end of 2016. According to Navigant Research, there were about 2.6 million all-electric cars on the world's roads by November 2018.\n\nSeveral countries have established grants and tax credits for the purchase of new electric cars, often depending on battery size. The U.S. offers a federal income tax credit up to , and several states have additional incentives. The UK offers a Plug-in Car Grant up to a maximum of (). The U.S. government also pledged in federal grants for the development of advanced technologies for electric cars and batteries, despite the fact that overall sales aren't increasing at the expected speed.\n\nAs of April 2011, 15 European Union member states provide economic incentives for the purchase of new electrically chargeable vehicles, which consist of tax reductions and exemptions, as well as of bonus payments for buyers of all-electric and plug-in hybrid vehicles, hybrid electric vehicles, and some alternative fuel vehicles.\n\n\n"}
{"id": "14247793", "url": "https://en.wikipedia.org/wiki?curid=14247793", "title": "Extreme Machines", "text": "Extreme Machines\n\nExtreme Machines is a television series aired on Discovery Channel.\n\nThe program feature some of the largest created man-made machines on earth. Like a container ship, Excavators, and Cranes.\n\nAs taken from the official Canadian webpage for Discovery Channel:\n\n\n\n"}
{"id": "7606575", "url": "https://en.wikipedia.org/wiki?curid=7606575", "title": "Feed mixer", "text": "Feed mixer\n\nFeed mixers are used in feed mills for the mixing of feed ingredients and premixes. The mixer plays a vital role in the feed production process, with efficient mixing being the key to good feed production. If feed is not mixed properly, ingredients and nutrients will not be properly distributed when it comes time to extrude and pelletize the feed, or if the feed is to be used as mash. This means that not only would the feed not have nutritional benefit, it would be bad for the animals that are eating it.\n\nThere are a number of different type of mixers used in the feed industry with the most widely used being:\n\n\nThese machines come in a variety of configurations:\n\n"}
{"id": "47810647", "url": "https://en.wikipedia.org/wiki?curid=47810647", "title": "Flame front", "text": "Flame front\n\nOne approach of modern combustion theory describes a premixed flame as a thin interface separating reactants and products. The surface of the interface that faces reactants is often termed as the flame front. Similarly, the surface that faces the products can be termed as the flame back.\n\nAnalysis of flow field and thermo-chemical structure at the flame front can provide information about the burning efficiency of a premixed flame...\n"}
{"id": "32814049", "url": "https://en.wikipedia.org/wiki?curid=32814049", "title": "Flux switching alternator", "text": "Flux switching alternator\n\nA flux switching alternator is a form of high-speed alternator, an AC electrical generator, intended for direct drive by a turbine. They are simple in design, making them rugged and capable of high rotation speeds. This makes them suitable for their only widespread use, in guided missiles.\n\nGuided missiles require a source of electrical power during flight. This is needed to power the guidance and fuzing systems, possibly also the high-power loads of an active radar seeker (i.e. a transmitter) and rarely the missile's control surfaces. Control surface actuators for a high-speed missile require a high force and so these are usually powered by some non-electric means, such as tapping propellant exhaust gas from the missile's motor. Rare exceptions where electrically powered control surfaces are used are mostly medium-range subsonic naval missiles, e.g. Exocet, Harpoon and Martel. The total load varies for different missiles between around 100W to several kW.\n\nThe electrical supply for a missile must be reliable, particularly after long storage. Depending on the missile type, it may also be required to start delivering power almost immediately after start-up, or even before launch to allow gyroscopes to be accelerated to speed, and to provide power for varying lengths of time. Small anti-tank or air-to-air missiles may only require power for a few seconds of flight. Others, such as tactical missiles or ICBMs, may require power for several minutes. Turbojet-powered cruise missiles have the longest flight times (being long-ranged, yet also slowest in flight) however these also have engines that are capable of driving a more conventional generator.\n\nTwo technologies are used in practice to power missiles: batteries and generators. The batteries used are usually esoteric types rarely found outside missiles, such as silver-zinc or thermal batteries. The generators used are simple high-speed generators, driven directly by a turbine rotor that is powered by either the rocket motor's exhaust, or else a dedicated gas generator.\n\nThe generator is required to be rugged and capable of very high speeds, as it is driven at the turbine's speed, without reduction gearing. The rotor must thus be simple in design and there can also be no sliding contacts to sliprings or other brushgear. Although the power requirement for the missile may be a largely DC supply, the AC alternator and its need for a rectifier is still favoured for its mechanical robustness.\n\nUnusually, both the field coils and the armature winding are carried on the fixed stator. The rotor is a simple toothed wheel, with no windings or electrical components.\n\nIn the simplest case, the stator has four poles and the field coils and armature windings are arranged alternately around the stator between the poles. The field magnets are arranged with their poles opposing each other, i.e. one armature is between the two North poles, one between the two South. The rotor is a simple toothed disc of magnetic, but unmagnetized, iron. As it rotates between poles, it links the flux between a single pair of opposing poles. The magnetic circuit of the stator is thus a pair of triangles, each containing a field, an armature and a shared path through the rotor. Flux passes in each circuit from one field and through one armature. As the rotor turns, the other triangular path is formed, switching the flux from one pair of field and armature to the other and also reversing the direction of the flux in the armature coil. It is this reversal of flux that produces the alternating emf.\n\nThe rotor must bridge the path between opposing pole pieces, but must never bridge all four simultaneously. It must thus have an even number of poles, but this must not be divisible by four. Practical rotors use six poles. As the rotation of one tooth pitch is sufficient to generate one AC cycle, the output frequency is thus the product of the rotation speed (in revs. per second) and the number of rotor teeth. Early AC systems used the standard frequency of 400 Hz, which limited alternators to two pole rotors and a maximum rotation speed of 24,000 rpm. The use of higher frequencies, from multi-pole rotors, was already recognised as a future means to achieve greater power for the same weight. The Seaslug missile alternator used a speed of 24,000 rpm to produce 1.5 kVA of electricity at 2,400 Hz.\n\nThe field may be supplied by either permanent magnets or by field coils. Regulation of the output voltage is achieved by controlling the current through a winding, either the field coil, or a control winding around a permanent magnet.\n\nThe simplest solution taps off some hot exhaust gas from the propulsion motor and routes it instead through the generator turbine. This gas may also be used to power the control surface actuators, as was used for Vigilant. This is one of the simplest and lightest electrical power supplies available for a missile.\n\nBleeding exhaust gas from the motor increases the amount of fuel required, but this effect is trivial, around 1%. The exhaust is hot, possibly as hot as 2,400 °C, and at pressures varying from 2,600 psi at the boost phase to 465 psi during sustain. A more serious drawback is the amount of sooty particulates in the exhaust, which requires a filter to keep them from the turbine. As such filters may themselves clog, this method is best suited for short flight durations.\n\nA gas generator is a chemical device that burns to provide a supply of gas under pressure. Although still hot, comparable to rocket motor exhaust, this gas can be cooler and cleaner of particulates than rocket efflux. Both solid and liquid-fuelled gas generators may be used.\n\nAdvantages of a gas generator drive, rather than motor exhaust are:\n\nThe first alternators of this type began with the first missiles requiring considerable electric power, those using radar seekers (initially semi-active radar homing). Development of these began in the late 1940s, with air-to-air missiles such as Sparrow. Sparrow was a relatively large missile with an airframe 8 inches in diameter. By the late 1950s, turbine-driven alternators were also being used in lightweight anti-tank missiles such as Vigilant. Vigilant has a body diameter of 4 inches, including a  inch central jetpipe. The alternator and turbine was fitted into a remaining annular space of only 1 inches.\n\nAn alternative high-speed generator is the permanent magnet magneto. Achieving the output needed depends on the use of modern rare earth magnets, such as samarium cobalt or neodymium. The output coil is formed as a stator, with axial magnetic flux from a rotating multi-pole ring magnet.\n\n"}
{"id": "298214", "url": "https://en.wikipedia.org/wiki?curid=298214", "title": "Garlic press", "text": "Garlic press\n\nA garlic press (also known as a garlic crusher in Australia, New Zealand and the United Kingdom), is a kitchen utensil to crush garlic cloves efficiently by forcing them through a grid of small holes, usually with some type of piston. Many garlic presses also have a device with a matching grid of blunt pins to clean out the holes.\n\nGarlic presses present a convenient alternative to mincing garlic with a knife, especially because a clove of garlic can be passed through a sturdy press without even removing its peel. The peel remains in the press while the garlic is extruded out. Some sources also claim that pressing with the peel on makes cleaning the press easier. \n\nGarlic crushed by a press is generally believed to have a different flavor from minced garlic, more of garlic's strong flavor compounds are liberated. A few sources prefer the flavor of pressed garlic. Raw-foods chef Renée Underkoffler says \"a good garlic press makes dealing with garlic a clean pleasure. Pressed garlic has a lighter, more delicate flavor than minced garlic because it excludes the bitter center stem.\" The magazine \"Cook's Illustrated\" says \"a good garlic press can break down cloves more finely and evenly than an average cook using a knife, which means better distribution of garlic flavor throughout any given dish.\"\n\nOn the other hand, some chefs say garlic crushed in a press has an inferior flavor compared to other forms of garlic. For instance, chef Anthony Bourdain called garlic presses \"abominations\" and advised \"\"don't\" put it through a press. I don't know what that junk is that squeezes out of the end of those things, but it ain't garlic.\" The cookery writer Elizabeth David wrote an essay titled \"Garlic Presses are Utterly Useless\". Alton Brown (known for his dislike of single-purpose kitchen tools) has referred to garlic presses as \"useless\" and without a reason to exist.\n\n\"Cook's Illustrated\" lists some additional uses for a garlic press, such as mashing other small items (including olives, capers, anchovies, and canned chipotles) or pressing out small quantities of onion or shallot juice.\n\nGarlic mincers can be used to obtain fine grains of garlic too.\n\n"}
{"id": "39314790", "url": "https://en.wikipedia.org/wiki?curid=39314790", "title": "Great Online Shopping Festival", "text": "Great Online Shopping Festival\n\nThe Great Online Shopping Festival (GOSF) was an online shopping event created by Google India on 12 December 2012 in collaboration with a number of Indian online shopping portals. The concept of the GOSF was that the online shopping sites would give heavy discounts for one day, in order to promote their sales. In November 2015, Google announced that the event would not be repeated. \n\nThe concept of a one-day online sale originated in the United States, where many online shopping sites offer discounts on \"Cyber Monday\", the first Monday after the so-called Black Friday, the day that follows the U.S. Thanksgiving. Cyber Monday started in 2005 and the concept has spread to several countries including Canada, Japan, Australia, Colombia, and the U.K.. In China a similar day of online shopping is observed on November 11, which is known as \"Singles Day\".\n\nThe first Great Online Shopping Festival in 2012 was advertised on YouTube and via posts on Google Plus. For the event, Google partnered with a number of ecommerce sites such as Flipkart, HomeShop18, Snapdeal, Indiatimes shopping, Infibeam and Makemytrip, which would participate in the GOSF. The ecommerce sites created dedicated landing pages for GOSF. GOSF site engaged users through games and showing offers and eventually it redirected users to the dedicated landing pages of ecommerce sites to do the transactions.\n\nAccording to critics, the first GOSF left some consumers a little disappointed as the discounts were marginal or nonexistent.\n\nIn 2013, the Great Online Shopping Festival was held on 11–14 December. Participating companies included Myntra, Jabong.com, and Indiatimes Shopping. Google claimed that the shopping festival was a success for the companies, and extended the event, which was planned to end on 13 December, by one day.\n\nIn December 2014, the GOSF took place on 10-12 December, and involved over 450 online retailers. 2014 GOSF included several categories such as lifestyle, electronics, books and media, home and kitchen, groceries, mobile apps, automobiles, and real estate. Discounts were also given on career services, health care and insurance policies, travel packages and matrimonial plans. Several brands also launched new products at the GOSF.\n\n\n"}
{"id": "18384281", "url": "https://en.wikipedia.org/wiki?curid=18384281", "title": "Hoe-farming", "text": "Hoe-farming\n\nHoe-farming is a term introuduced (as ) by Eduard Hahn in 1910\nto collectively refer to primitive forms of agriculture, defined by the absence of the plough. Tillage in hoe-farming cultures is done by simple manual tools such as \ndigging sticks or hoes.\nHoe-farming is the earliest form of agriculture practiced in the Neolithic Revolution.\nEarly forms of the plough (\"ard\") were introduced throughout the Near East (Naqada II) and Europe (Linear Pottery culture) by the 5th to 4th millennium BC. \nThe invention spread throughout Greater Persia and parts of Central Asia, reaching East Asia in the 2nd millennium BC (Chinese Bronze Age).\n\nThe parts of the world where agriculture was introduced but not the plough (in the case of the New World up to the introduction of plough-farming with European colonisation) were named the hoe-cultivation belt () by Hahn (1914), followed by Werth (1954). \nThe Hoe-cultivation belt is mostly located in tropical latitudes, including Sub-Saharan Africa (but not the Horn of Africa, where the plough appears to have been introduced \nvia Egypt), the Indian subcontinent, Maritime Southeast Asia, and the pre-Columbian Americas.\n\nHoe-farming often coincides with long fallow systems and shifting cultivation, The split hoe, (also known as prong hoes, tined hoes or bent forks) are hoes that have two or more tines at right angles to the shaft. Their use is typically to loosen the soil, prior to planting or sowing. It points out that the ability to cultivate effectively at small row distances. Split hoeing, contrasted to permanent plough-based cultivation systems and the intensification of agriculture. Hoe-farming may contain slash and burn clearance techniques, but they are not strictly necessary. It is usually embedded in the logic of subsistence agriculture. \n\n\n"}
{"id": "641565", "url": "https://en.wikipedia.org/wiki?curid=641565", "title": "Hydraulic accumulator", "text": "Hydraulic accumulator\n\nA hydraulic accumulator is a pressure storage reservoir in which a non-compressible hydraulic fluid is held under pressure that is applied by an external source. The external source can be a spring, a raised weight, or a compressed gas. An accumulator enables a hydraulic system to cope with extremes of demand using a less powerful pump, to respond more quickly to a temporary demand, and to smooth out pulsations. It is a type of energy storage device.\n\nCompressed gas accumulators, also called hydro-pneumatic accumulators, are by far the most common type.\n\nThe first accumulators for Armstrong's hydraulic dock machinery were simple raised water towers. Water was pumped to a tank at the top of these towers by steam pumps. When dock machinery required hydraulic power, the hydrostatic head of the water's height above ground provided the necessary pressure.\n\nThese simple towers were extremely tall. One of the best known, Grimsby Dock Tower opened in 1852, is tall. The size of these towers made them expensive to construct. These simple tower accumulators were constructed for less than a decade. Around the same time, John Fowler was working on the construction of the ferry quay at nearby New Holland but could not use similar hydraulic power as the poor ground conditions did not permit a tall accumulator tower to be built. By the time Grimsby was opened, it was already obsolete as Armstrong had developed the more complex, but much smaller, weighted accumulator for use at New Holland. In 1892 the original Grimsby tower's function was replaced, on Fowler's advice, by a smaller weighted accumulator on an adjacent dock, although the tower remains to this day as a well-known landmark.\n\nAnother surviving tower is adjacent to East Float in Birkenhead, England.\n\nA raised weight accumulator consists of a vertical cylinder containing fluid connected to the hydraulic line. The cylinder is closed by a piston on which a series of weights are placed that exert a downward force on the piston and thereby pressurizes the fluid in the cylinder. In contrast to compressed gas and spring accumulators, this type delivers a nearly constant pressure, regardless of the volume of fluid in the cylinder, until it is empty. (The pressure will decline somewhat as the cylinder is emptied due to the decline in weight of the remaining fluid.)\n\nA working example of this type of accumulator may be found at the hydraulic engine house, Bristol Harbour. The original 1887 accumulator is in place in its tower, an external accumulator was added in 1954 and this system was used until 2010 to power the Cumberland Basin (Bristol) lock gates. The water is pumped from the harbour into a header tank and then fed by gravity to the pumps. The working pressure is 750 psi (5.2 MPa, or 52 bar) which was used to power the cranes, bridges and locks of Bristol Harbour.\n\nThe original operating mechanism of Tower Bridge, London, also used this type of accumulator. Although no longer in use, two of the six accumulators may still be seen \"in situ\" in the bridge's museum.\n\nRegent's Canal Dock, now named Limehouse Basin has the remains of a hydraulic accumulator, dating from 1869, a fragment of the oldest remaining such facility in the world, the second at the dock, which was installed later than that at Poplar Dock, originally listed incorrectly as a signalling cabin for the London and Blackwall Railway, when correctly identified, it was restored as a tourist attraction by the now defunct London Docklands Development Corporation. Now owned by the British Waterways Board, it is open for large groups on application to the Dockmaster's Office at the basin and on both the afternoons of London Open House Weekend, held on the third weekend of September each year.\n\nLondon had an extensive public hydraulic power system from the mid-nineteenth century finally closing in the 1970s with 5 hydraulic power stations, operated by the London Hydraulic Power Company. Railway goods yards and docks often had their own separate system.\n\nA simple form of accumulator is an enclosed volume, filled with air. A vertical section of pipe, often enlarged diameter, may be enough and fills itself with air, trapped as the pipework fills.\n\nSuch accumulators do not have enough capacity to store power for long periods, but they can act as a buffer to absorb fluctuations in pressure. They are used to smooth out the delivery from piston pumps. Another use is as a shock absorber to damp out water hammer.\n\nA compressed gas accumulator consists of a cylinder with two chambers that are separated by an elastic diaphragm, a totally enclosed bladder, or a floating piston. One chamber contains hydraulic fluid and is connected to the hydraulic line. The other chamber contains an inert gas under pressure (typically nitrogen) that provides the compressive force on the hydraulic fluid. Inert gas is used because oxygen and oil can form an explosive mixture when combined under high pressure. As the volume of the compressed gas changes, the pressure of the gas (and the pressure on the fluid) changes inversely.\n\nIt is possible to increase the gas volume of the accumulator by coupling a gas bottle to the gas side of the accumulator. This is mainly done since a gas bottle normally is cheaper to produce than an accumulator.\n\nA compressed gas accumulator was invented by Jean Mercier for use in variable-pitch propellers.\n\nA spring type accumulator is similar in operation to the gas-charged accumulator above, except that a heavy spring (or springs) is used to provide the compressive force. According to Hooke's law the magnitude of the force exerted by a spring is linearly proportional to its change of length. Therefore, as the spring compresses, the force it exerts on the fluid is increased linearly.\n\nThe metal bellows accumulators function similarly to the compressed gas type, except the elastic diaphragm or floating piston is replaced by a hermetically sealed welded metal bellows. Fluid may be internal or external to the bellows. The advantages to the metal bellows type include exceptionally low spring rate, allowing the gas charge to do all the work with little change in pressure from full to empty, and a long stroke relative to solid (empty) height, which gives maximum storage volume for a given container size. The welded metal bellows accumulator provides an exceptionally high level of accumulator performance, and can be produced with a broad spectrum of alloys resulting in a broad range of fluid compatibility. Another advantage to this type is that it does not face issues with high pressure operation, thus allowing more energy storage capacity.\n\nIn modern, often mobile, hydraulic systems the preferred item is a gas charged accumulator, but simple systems may be spring-loaded. There may be more than one accumulator in a system. The exact type and placement of each may be a compromise due to its effects and the costs of manufacture. \n\nAn accumulator is placed close to the pump with a non-return valve preventing flow back to the pump. In the case of piston-type pumps this accumulator is placed in the ideal location to absorb pulsations of energy from the multi-piston pump. It also helps protect the system from fluid hammer. This protects system components, particularly pipework, from both potentially destructive forces. \n\nAn additional benefit is the additional energy that can be stored while the pump is subject to low demand. The designer can use a smaller-capacity pump. The large excursions of system components, such as landing gear on a large aircraft, that require a considerable volume of fluid can also benefit from one or more accumulators. These are often placed close to the demand to help overcome restrictions and drag from long pipework runs. The outflow of energy from a discharging accumulator is much greater, for a short time, than even large pumps could generate. \n\nAn accumulator can maintain the pressure in a system for periods when there are slight leaks without the pump being cycled on and off constantly. When temperature changes cause pressure excursions the accumulator helps absorb them. Its size helps absorb fluid that might otherwise be locked in a small fixed system with no room for expansion due to valve arrangement. \n\nThe gas precharge in an accumulator is set so that the separating bladder, diaphragm or piston does not reach or strike either end of the operating cylinder. The design precharge normally ensures that the moving parts do not foul the ends or block fluid passages. Poor maintenance of precharge can destroy an operating accumulator. A properly designed and maintained accumulator should operate trouble-free for years.\n\n\n"}
{"id": "33485814", "url": "https://en.wikipedia.org/wiki?curid=33485814", "title": "Institut für Dokumentologie und Editorik", "text": "Institut für Dokumentologie und Editorik\n\nThe Institut für Dokumentologie und Editorik (IDE - Institute for Documentology and Scholarly Editing) is a German association (with the legal status of \"Eingetragener Verein\") of researchers working on the application of digital methods to historical documents. Fields of interest include digitization, transcription, text encoding, textual criticism, critical scholarly editing, digital palaeography, and digital codicology. It was established in 2006 and has contributed in several ways to the field of digital humanities and has organized Summer Schools on a regular basis at various universities in Germany and Austria (Berlin, Chemnitz, Cologne, Rostock, Vienna). Most notably, the IDE publishes the series \"Schriften des Instituts für Dokumentologie und Editorik\" distributed in print and freely online. The IDE supports open access. The series is discussed and reviewed in German and international journals.\n\nSince July 2014 the IDE also publishes the open access journal \"RIDE: A Review Journal for Digital Editions and Resources\".\n\n"}
{"id": "6979831", "url": "https://en.wikipedia.org/wiki?curid=6979831", "title": "Instruction creep", "text": "Instruction creep\n\nInstruction creep occurs when instructions increase in number and size over time until they are unmanageable. It can be insidious and damaging to the success of large groups such as corporations, originating from ignorance of the KISS principle and resulting in over-complex (as opposed to \"simplified\") procedures that are often misunderstood, followed with great irritation, or ignored.\n\nInstruction creep is common in complex organizations, where rules and guidelines are created by changing groups of people over extended periods of time. The constant state of flux in such groups often leads them to add or modify instructions, rather than simplifying or consolidating existing ones. This can result in considerable overlap in the message of directives, at the expense of clarity, efficiency, and communication, or even of consistency.\n\nThe fundamental fallacy of instruction creep is believing that people read instructions with the same level of attention and comprehension, regardless of the volume or complexity of those instructions. A byproduct is the advent of many new rules having the deliberate intent to control others via fiat, without considering consensus or collaboration. This tends to antagonize others, even when it appears to the instigators that they are acting with proper intent.\n\n\n"}
{"id": "598949", "url": "https://en.wikipedia.org/wiki?curid=598949", "title": "Integrated circuit layout", "text": "Integrated circuit layout\n\nIntegrated circuit layout, also known IC layout, IC mask layout, or mask design, is the representation of an integrated circuit in terms of planar geometric shapes which correspond to the patterns of metal, oxide, or semiconductor layers that make up the components of the integrated circuit. \n\nWhen using a standard process—where the interaction of the many chemical, thermal, and photographic variables is known and carefully controlled—the behaviour of the final integrated circuit depends largely on the positions and interconnections of the geometric shapes. Using a computer-aided layout tool, the layout engineer—or layout technician—places and connects all of the components that make up the chip such that they meet certain criteria—typically: performance, size, density, and manufacturability. This practice is often subdivided between two primary layout disciplines: Analog and digital.\n\nThe generated layout must pass a series of checks in a process known as physical verification. The most common checks in this verification process are\n\nWhen all verification is complete, the data is translated into an industry-standard format, typically GDSII, and sent to a semiconductor foundry. The process of sending this data to the foundry is called tapeout because the data used to be shipped out on a magnetic tape. The foundry converts the data into another format and uses it to generate the photomasks used in a photolithographic process of semiconductor device fabrication.\n\nIn the earlier, simpler, days of IC design, layout was done by hand using opaque tapes and films, much like the early days of printed circuit board (PCB) design. Modern IC layout is done with the aid of IC layout editor software, mostly automatically using EDA tools, including place and route tools or schematic-driven layout tools. The manual operation of choosing and positioning the geometric shapes is informally known as \"polygon pushing\".\n\n\n"}
{"id": "1629311", "url": "https://en.wikipedia.org/wiki?curid=1629311", "title": "Iterative design", "text": "Iterative design\n\nIterative design is a design methodology based on a cyclic process of prototyping, testing, analyzing, and refining a product or process. Based on the results of testing the most recent iteration of a design, changes and refinements are made. This process is intended to ultimately improve the quality and functionality of a design. In iterative design, interaction with the designed system is used as a form of research for informing and evolving a project, as successive versions, or iterations of a design are implemented.\n\nThe iterative design process may be applied throughout the new product development process. However, changes are easiest and less expensive to implement in the earliest stages of development. The first step in the iterative design process is to develop a prototype. The prototype should be evaluated by a focus group or a group not associated with the product in order to deliver non-biased opinions. Information from the focus group should be synthesized and incorporated into the next iteration of the design. The process should be repeated until user issues have been reduced to an acceptable level.\n\nIterative design is commonly used in the development of human computer interfaces. This allows designers to identify any usability issues that may arise in the user interface before it is put into wide use. Even the best usability experts cannot design perfect user interfaces in a single attempt, so a usability engineering lifecycle should be built around the concept of iteration.\n\nThe typical steps of iterative design in user interfaces are as follows:\n\n\nIterative design in user interfaces can be implemented in many ways. One common method of using iterative design in computer software is software testing. While this includes testing the product for functionality outside of the user interface, important feedback on the interface can be gained from subject testing early versions of a program. This allows software companies to release a better quality product to the public, and prevents the need of product modification following its release.\n\nIterative design in online (website) interfaces is a more continual process, as website modification, after it has been released to the user, is far more viable than in software design. Often websites use their users as test subjects for interface design, making modifications based on recommendations from visitors to their sites.\n\nIterative design is a way of confronting the reality of unpredictable user needs and behaviors that can lead to sweeping and fundamental changes in a design. User testing will often show that even carefully evaluated ideas will be inadequate when confronted with a user test. Thus, it is important that the flexibility of the iterative design’s implementation approach extends as far into the system as possible. Designers must further recognize that user testing results may suggest radical change that requires the designers to be prepared to completely abandon old ideas in favor of new ideas that are more equipped to suit user needs. Iterative design applies in many fields, from making knives to rockets. As an example consider the design of an electronic circuit that must perform a certain task, and must ultimately fit in a small space on a circuit board. It is useful to split these independent tasks into two smaller and simpler tasks, the functionality task, and the space and weight task. A breadboard is a useful way of implementing the electronic circuit on an interim basis, without having to worry about space and weight.\n\nOnce the circuit works, improvements or incremental changes may be applied to the breadboard to increase or improve functionality over the original design. When the design is finalized, one can set about designing a proper circuit board meeting the space and weight criteria. Compacting the circuit on the circuit board requires that the wires and components be juggled around without changing their electrical characteristics. This juggling follows simpler rules than the design of the circuit itself, and is often automated. As far as possible off the shelf components are used, but where necessary for space or performance reasons, custom made components may be developed.\n\nSeveral instances of iterative design are as follows:\n\n\nOne approach to iterative design is to use the highest level of abstraction for developing an early generation product. The principle here is that rapid development may not produce efficient code, but obtaining feedback is more important that technology optimization. Examples of this approach include use of non-functional code, object databases, or low code platforms - these allow quick testing of designs before issues of optimization are addressed.\n\nWhen properly applied, iterative design will ensure a product or process is the best solution possible. When applied early in the development stage, significant cost savings are possible.\n\nOther benefits to iterative design include:\n\nThe Marshmallow Challenge is an instructive design challenge. It involves the task of constructing the highest possible free-standing structure with a marshmallow on top. The structure must be completed within 18 minutes using only 20 sticks of spaghetti, one yard of tape, and one yard of string.\n\nObservation and studies of participants show that kindergartners are regularly able to build higher structures, in comparison to groups of business school graduates. This is explained by the tendency for children to at once stick the marshmallow on top of a simple structure, test the prototype, and continue to improve upon it. Whereas, business school students tend to spend time vying for power, planning, and finally producing a structure to which the marshmallow is added. The challenge was invented by Peter Skillman of Palm, Inc. and popularized by Tom Wujec of Autodesk.\n\n\n\n"}
{"id": "18330364", "url": "https://en.wikipedia.org/wiki?curid=18330364", "title": "KWorld", "text": "KWorld\n\nKWorld Computer Co. Ltd () is a Taiwan-based technology company that specializes in TV tuner cards and boxes. They are a consumer audio/video developer and provider whose market focus is PC based peripherals. The company offers analogue, digital, hybrid, satellite TV tuners, and video/audio capture/editing cards and boxes.\n\nKWorld develops TV tuners for PAL, NTSC, and SECAM analogue television systems and for DVB-T, DVB-S, ISDB-T, DMB-T/H, ATSC, and IPTV digital television systems. KWorld also develops video capture/editing and audio capture/editing devices for both Macintosh and Microsoft Windows operating systems.\n\n"}
{"id": "49473349", "url": "https://en.wikipedia.org/wiki?curid=49473349", "title": "Kadenze", "text": "Kadenze\n\nkadenze.com, operated by Kadenze, Inc. (\"Kadenze\"), is a for-profit massive open online course (MOOC) provider that offers courses geared toward art, music, and creative technology, fields which are falling behind other fields such as computer science in terms of number of courses offered in the MOOC space. It was launched on June 16, 2015 with 18 academic partners including: Stanford University, Princeton University, UCLA, California Institute of the Arts, School of Art Institute of Chicago, Maryland Institute College of Art, Goldsmiths College, MassArt, Seoul Institute of the Arts, Paris College of Art, National University of Singapore, Cornish College of Art, University of Texas at Austin, Rhode Island School of Design, Pacific Northwest College of Art, Arizona State University, Columbus College of Art and Design, and School of Visual Arts.\n\nThe primary method of learning on kadenze.com is through video-based lectures. Courses typically range from five to eight sessions long, with each session broken up into a group of short lessons.\n\nA course can run in either Scheduled or Adaptive mode. A Scheduled course follows a set calendar, with a course start/end date, prescribed due dates for assignments, and new lecture content that is released on specific dates (e.g. once a week). Adaptive courses are more flexible in terms of scheduling, allowing learners to initiate sessions and progress through course material at their own pace. While all video are immediately accessible when running in Adaptive mode, assignments are “unlocked” upon completing the previous assignment. A suggested due date of 1-week is set to help learners stay on track, however, learners can go at their own pace.\n\nCore to the used Kannu platform is the ability to embed media (image, video, audio) nearly anywhere on the platform, such as a course’s forums and gallery. This enables learners and customers/purchasers of the Premium membership to engage with one another’s works without the need to leave the learning environment. This also expands the possibilities of peer assessment based learning methods (which is a common form of assessment on MOOC platforms).\n\nkadenze.com offers a tier-based membership model. The free tier enables learners to watch all lecture material, and to participate in the course forums. A fee-based Premium membership allows students to have full participation in courses, submit assignments, receive grades and feedback, collaborate with peers, build their online portfolio, and gain eligibility to receive a verified Certificate of Accomplishment if a course is completed satisfactorily. Additionally, many courses offer Premium Members access to exclusive student discounts from the kadenze.com industrial partners. Some courses on kadenze.com are also offered as credit-eligible, meaning that learners can take the course for actual college credit from the partnering institution. Many of the individual courses in area of sub specialization are available as part of a Program. \n\nAfter being awarded a National Science Foundation grant in 2012 to study methods of teaching computer science to non-programmers, specifically art students, Kapur and Cook taught a music programming language course on another MOOC platform. The course saw around 45,000 students enroll. However, it was clear that there were limited options for these art-tech courses online, and challenges emerged in trying to effectively measure students’ work.\n\nKadenze was founded as a Delaware corporation in September 2013 by the 6 cofounders with Ashok Ahuja as the lead investor and Executive Chairman and Jordan Hochenbaum as the individual providing strategic and product direction. kadenze.com was launched in June 2015, with 18 international educational partners offering courses ranging from art history to computer programming for musicians and artists. At launch, kadenze.com also offered credit-eligible courses from some of its partners including California Institute of the Arts and Otis College of Art and Design.\n\nAs of February 2017 kadenze.com has expanded its partner list to 31 educational partners including two non-profit organizations. Today, kadenze.com offers approximately 100 courses in a number of creativity related fields including business, music, music technology, visual arts, creative computing, computational graphics, design, history and culture, fashion, entertainment technology, math, game design, film, curation, and web development. Many of these courses are similar to courses already taught at partner non-profit public and private institutions, and feature the staff and faculty from these partner institutions. The kadenze.com website does not disclose the terms of agreement or the level of financial remuneration it offers the staff and faculty already holding positions at non-profit partner institutions. Additionally, Kadenze has established partnerships with industrial for-profit partners including Ableton, Adobe, Cognella, Focusrite, Manning Publications, Native Instruments, Novation, and RME. These courses are offered under the Kadenze Academy banner. Some of the industrial partners offer kadenze.com premium members additional benefits. Similarly, the kadenze.com website does not disclose the terms of agreement it has with industrial partners and whether the industrial partners also have pre-existing agreements with partner institution, which is likely due to commercial sensitivities.\n\nOn November 19, 2015, Kadenze launched Kannu, a learning management system geared toward creative education, music, arts, and design. Early adopters of the customized platform on campus were California Institute of the Arts, Otis College of Art and Design Rhode Island School of Design, Goldsmiths College, Stanford University and non academic institutions such as Unity and Maker Media Inc.\n\nIn November 2016, EdSurge did a review of the progress on Kadenze, one year after launching \n\nKadenze is lead by co-founder Ashok Ahuja - CEO, President & Executive Chairman; co-founder Jordan Hochenbaum - Special Advisor to CEO, Technology & Strategy; Brad Haseman - EVP kadenze.com Business Unit\n"}
{"id": "298235", "url": "https://en.wikipedia.org/wiki?curid=298235", "title": "Lateral thinking", "text": "Lateral thinking\n\nLateral thinking is a manner of solving problems using an indirect and creative approach via reasoning that is not immediately obvious. It involves ideas that may not be obtainable using only traditional step-by-step logic. \n\nThe term was promulgated in 1967 by Edward de Bono. He cites as an example the Judgment of Solomon, where King Solomon resolves a dispute over the parentage of a child by calling for the child to be cut in half, and making his judgment according to the reactions that this order receives. Edward de Bono also links lateral thinking with humour, arguing there's a switch-over from a familiar pattern to a new, unexpected one. It is in this moment of surprise generating laughter and new insight which facilitates the ability of seeing a different thought pattern which initially was not obvious.\n\nAccording to de Bono, lateral thinking deliberately distances itself from the standard perception of creativity as \"vertical\" logic (the classic method for problem solving).\n\nTo understand lateral thinking, it is necessary to compare lateral thinking and critical thinking. Critical thinking is primarily concerned with judging the true value of statements and seeking errors. Lateral thinking is more concerned with the \"movement value\" of statements and ideas. A person uses lateral thinking to move from one known idea to creating new ideas. Edward de Bono defines four types of thinking tools:\n\n\n\n\n\n\n\n"}
{"id": "2261362", "url": "https://en.wikipedia.org/wiki?curid=2261362", "title": "Legacy port", "text": "Legacy port\n\nA legacy port is a computer port or connector that is considered by some to be fully or partially superseded. The replacement ports usually provide most of the functionality of the legacy ports with higher speeds, more compact design, or plug and play and hot swap capabilities for greater ease of use. Modern PC motherboards use separate Super I/O controllers to provide legacy ports since current chipsets do not offer direct support for them. A category of computers called legacy-free PCs omits these ports, typically retaining only USB for external expansion.\n\nUSB adapters are often used to provide legacy ports if they are required on systems not equipped with them. \n\n\n"}
{"id": "3233676", "url": "https://en.wikipedia.org/wiki?curid=3233676", "title": "Low-pressure discharge", "text": "Low-pressure discharge\n\nLow-pressure discharges are discharges made under gas pressures from a few millitorr to a little less than atmospheric. They have the benefit of less power requirement of sustenance of the discharge as volume-recombination rates are lower.\n\nIt is easier to achieve uniform discharges at low pressure. Normally, the system is pumped down and only necessary plasma gases are then flown into the plasma chamber. Argon is a typical background gas because it has low ionization potential and therefore is easier to break down and sustain.\n\nMost discharges used in the semiconductor industry employ low-pressure plasmas.\n"}
{"id": "19001", "url": "https://en.wikipedia.org/wiki?curid=19001", "title": "Microsoft", "text": "Microsoft\n\nMicrosoft Corporation (MS) is an American multinational technology company with headquarters in Redmond, Washington. It develops, manufactures, licenses, supports and sells computer software, consumer electronics, personal computers, and related services. Its best known software products are the Microsoft Windows line of operating systems, the Microsoft Office suite, and the Internet Explorer and Edge web browsers. Its flagship hardware products are the Xbox video game consoles and the Microsoft Surface lineup of touchscreen personal computers. As of 2016, it is the world's largest software maker by revenue, and one of the world's most valuable companies. The word \"Microsoft\" is a portmanteau of \"microcomputer\" and \"software\". Microsoft is ranked No. 30 in the 2018 Fortune 500 rankings of the largest United States corporations by total revenue.\n\nMicrosoft was founded by Bill Gates and Paul Allen on April 4, 1975, to develop and sell BASIC interpreters for the Altair 8800. It rose to dominate the personal computer operating system market with MS-DOS in the mid-1980s, followed by Microsoft Windows. The company's 1986 initial public offering (IPO), and subsequent rise in its share price, created three billionaires and an estimated 12,000 millionaires among Microsoft employees. Since the 1990s, it has increasingly diversified from the operating system market and has made a number of corporate acquisitions, their largest being the acquisition of LinkedIn for $26.2 billion in December 2016, followed by their acquisition of Skype Technologies for $8.5 billion in May 2011.\n\n, Microsoft is market-dominant in the IBM PC-compatible operating system market and the office software suite market, although it has lost the majority of the overall operating system market to Android. The company also produces a wide range of other consumer and enterprise software for desktops and servers, including Internet search (with Bing), the digital services market (through MSN), mixed reality (HoloLens), cloud computing (Azure) and software development (Visual Studio).\n\nSteve Ballmer replaced Gates as CEO in 2000, and later envisioned a \"devices and services\" strategy. This began with the acquisition of Danger Inc. in 2008, entering the personal computer production market for the first time in June 2012 with the launch of the Microsoft Surface line of tablet computers; and later forming Microsoft Mobile through the acquisition of Nokia's devices and services division. Since Satya Nadella took over as CEO in 2014, the company has scaled back on hardware and has instead focused on cloud computing, a move that helped the company's shares reach its highest value since December 1999.\n\nIn 2018, Microsoft surpassed Apple as the most valuable publicly traded company in the world after being dethroned by the tech giant in 2010.\n\nChildhood friends Bill Gates and Paul Allen sought to make a business utilizing their shared skills in computer programming. In 1972 they founded their first company, named Traf-O-Data, which sold a rudimentary computer to track and analyze automobile traffic data. While Gates enrolled at Harvard, Allen pursued a degree in computer science at Washington State University, though he later dropped out of school to work at Honeywell. The January 1975 issue of \"Popular Electronics\" featured Micro Instrumentation and Telemetry Systems's (MITS) Altair 8800 microcomputer, which inspired Allen to suggest that they could program a BASIC interpreter for the device. After a call from Gates claiming to have a working interpreter, MITS requested a demonstration. Since they didn't yet have one, Allen worked on a simulator for the Altair while Gates developed the interpreter. Although they developed the interpreter on a simulator and not the actual device, it worked flawlessly when they (in March 1975) demonstrated the interpreter to MITS in Albuquerque, New Mexico. MITS agreed to distribute it, marketing it as Altair BASIC. Gates and Allen officially established Microsoft on April 4, 1975, with Gates as the CEO. The original name of \"Micro-Soft\" was suggested by Allen. In August 1977 the company formed an agreement with ASCII Magazine in Japan, resulting in its first international office, \"ASCII Microsoft\". Microsoft moved to a new home in Bellevue, Washington in January 1979.\n\nMicrosoft entered the operating system (OS) business in 1980 with its own version of Unix, called Xenix. However, it was MS-DOS that solidified the company's dominance. After negotiations with Digital Research failed, IBM awarded a contract to Microsoft in November 1980 to provide a version of the CP/M OS, which was set to be used in the upcoming IBM Personal Computer (IBM PC). For this deal, Microsoft purchased a CP/M clone called 86-DOS from Seattle Computer Products, which it branded as MS-DOS, though IBM rebranded it to PC DOS. Following the release of the IBM PC in August 1981, Microsoft retained ownership of MS-DOS. Since IBM had copyrighted the IBM PC BIOS, other companies had to reverse engineer it in order for non-IBM hardware to run as IBM PC compatibles, but no such restriction applied to the operating systems. Due to various factors, such as MS-DOS's available software selection, Microsoft eventually became the leading PC operating systems vendor. The company expanded into new markets with the release of the \"Microsoft Mouse\" in 1983, as well as with a publishing division named Microsoft Press.\nPaul Allen resigned from Microsoft in 1983 after developing Hodgkin's disease. Allen claimed that Gates wanted to dilute his share in the company when he was diagnosed with Hodgkin's disease because he didn't think he was working hard enough. After leaving Microsoft, Allen lost billions of dollars on ill-conceived or mistimed technology investments. He later invested in low-tech sectors, sports teams, and commercial real estate.\n\nDespite having begun jointly developing a new operating system, OS/2, with IBM in August 1985, Microsoft released Microsoft Windows, a graphical extension for MS-DOS, on November 20. Microsoft moved its headquarters to Redmond on February 26, 1986, and on March 13 went public, with the resulting rise in stock making an estimated four billionaires and 12,000 millionaires from Microsoft employees. Microsoft released its version of OS/2 to original equipment manufacturers (OEMs) on April 2, 1987. In 1990, due to the partnership with IBM, the Federal Trade Commission set its eye on Microsoft for possible collusion, marking the beginning of over a decade of legal clashes with the U.S. government. Meanwhile, the company was at work on a 32-bit OS, Microsoft Windows NT, which was heavily based on their copy of the OS/2 code. It shipped on July 21, 1993, with a new modular kernel and the Win32 application programming interface (API), making porting from 16-bit (MS-DOS-based) Windows easier. Once Microsoft informed IBM of NT, the OS/2 partnership deteriorated.\n\nIn 1990, Microsoft introduced its office suite, Microsoft Office. The suite bundled separate productivity applications, such as Microsoft Word and Microsoft Excel. On May 22, Microsoft launched Windows 3.0, featuring streamlined user interface graphics and improved protected mode capability for the Intel 386 processor. Both Office and Windows became dominant in their respective areas.\n\nOn July 27, 1994, the U.S. Department of Justice, Antitrust Division filed a Competitive Impact Statement that said, in part: \"Beginning in 1988, and continuing until July 15, 1994, Microsoft induced many OEMs to execute anti-competitive \"per processor\" licenses. Under a per processor license, an OEM pays Microsoft a royalty for each computer it sells containing a particular microprocessor, whether the OEM sells the computer with a Microsoft operating system or a non-Microsoft operating system. In effect, the royalty payment to Microsoft when no Microsoft product is being used acts as a penalty, or tax, on the OEM's use of a competing PC operating system. Since 1988, Microsoft's use of per processor licenses has increased.\"\n\nFollowing Bill Gates's internal \"Internet Tidal Wave memo\" on May 26, 1995, Microsoft began to redefine its offerings and expand its product line into computer networking and the World Wide Web. The company released Windows 95 on August 24, 1995, featuring pre-emptive multitasking, a completely new user interface with a novel start button, and 32-bit compatibility; similar to NT, it provided the Win32 API. Windows 95 came bundled with the online service MSN (which was at first intended to be a competitor to the Internet), and (for OEMs) Internet Explorer, a web browser. Internet Explorer was not bundled with the retail Windows 95 boxes because the boxes were printed before the team finished the web browser, and instead was included in the Windows 95 Plus! pack. Branching out into new markets in 1996, Microsoft and General Electric's NBC unit created a new 24/7 cable news channel, MSNBC. Microsoft created Windows CE 1.0, a new OS designed for devices with low memory and other constraints, such as personal digital assistants. In October 1997, the Justice Department filed a motion in the Federal District Court, stating that Microsoft violated an agreement signed in 1994 and asked the court to stop the bundling of Internet Explorer with Windows.\nOn January 13, 2000, Bill Gates handed over the CEO position to Steve Ballmer, an old college friend of Gates and employee of the company since 1980, while creating a new position for himself as Chief Software Architect. Various companies including Microsoft formed the Trusted Computing Platform Alliance in October 1999 to (among other things) increase security and protect intellectual property through identifying changes in hardware and software. Critics decried the alliance as a way to enforce indiscriminate restrictions over how consumers use software, and over how computers behave, and as a form of digital rights management: for example the scenario where a computer is not only secured for its owner, but also secured against its owner as well. On April 3, 2000, a judgment was handed down in the case of \"United States v. Microsoft\", calling the company an \"abusive monopoly.\" Microsoft later settled with the U.S. Department of Justice in 2004. On October 25, 2001, Microsoft released Windows XP, unifying the mainstream and NT lines of OS under the NT codebase. The company released the Xbox later that year, entering the game console market dominated by Sony and Nintendo. In March 2004 the European Union brought antitrust legal action against the company, citing it abused its dominance with the Windows OS, resulting in a judgment of €497million ($613million) and requiring Microsoft to produce new versions of Windows XP without Windows Media Player: Windows XP Home Edition N and Windows XP Professional N. In November 2005, the Xbox 360 was released. There were two versions, a no-frills version for $299.99 and a bells-and-whistles version for $399.99.\n\nReleased in January 2007, the next version of Windows, Vista, focused on features, security and a redesigned user interface dubbed Aero. Microsoft Office 2007, released at the same time, featured a \"Ribbon\" user interface which was a significant departure from its predecessors. Relatively strong sales of both products helped to produce a record profit in 2007. The European Union imposed another fine of €899million ($1.4billion) for Microsoft's lack of compliance with the March 2004 judgment on February 27, 2008, saying that the company charged rivals unreasonable prices for key information about its workgroup and backoffice servers. Microsoft stated that it was in compliance and that \"these fines are about the past issues that have been resolved\". 2007 also saw the creation of a multi-core unit at Microsoft, following the steps of server companies such as Sun and IBM.\n\nGates retired from his role as Chief Software Architect on June 27, 2008, a decision announced in June 2006, while retaining other positions related to the company in addition to being an advisor for the company on key projects. Azure Services Platform, the company's entry into the cloud computing market for Windows, launched on October 27, 2008. On February 12, 2009, Microsoft announced its intent to open a chain of Microsoft-branded retail stores, and on October 22, 2009 the first retail Microsoft Store opened in Scottsdale, Arizona; the same day Windows 7 was officially released to the public. Windows 7's focus was on refining Vista with ease of use features and performance enhancements, rather than a large reworking of Windows.\n\nAs the smartphone industry boomed in 2007, Microsoft had struggled to keep up with its rivals Apple and Google in providing a modern smartphone operating system. As a result, in 2010 Microsoft revamped their aging flagship mobile operating system, Windows Mobile, replacing it with the new Windows Phone OS. Microsoft implemented a new strategy for the software industry that had them working more closely with smartphone manufacturers, such as Nokia, and providing a consistent user experience across all smartphones using the Windows Phone OS. It used a new user interface design language, codenamed \"Metro\", which prominently used simple shapes, typography and iconography, utilizing the concept of minimalism. Microsoft is a founding member of the Open Networking Foundation started on March 23, 2011. Fellow founders were Google, HP Networking, Yahoo, Verizon, Deutsche Telekom and 17 other companies. This nonprofit organization is focused on providing support for a new cloud computing initiative called Software-Defined Networking. The initiative is meant to speed innovation through simple software changes in telecommunications networks, wireless networks, data centers and other networking areas.\n\nFollowing the release of Windows Phone, Microsoft undertook a gradual rebranding of its product range throughout 2011 and 2012, with the corporation's logos, products, services and websites adopting the principles and concepts of the Metro design language. Microsoft unveiled Windows 8, an operating system designed to power both personal computers and tablet computers, in Taipei in June 2011. A developer preview was released on September 13, which was subsequently replaced by a consumer preview on February 29, 2012 and released to the public in May. The Surface was unveiled on June 18, becoming the first computer in the company's history to have its hardware made by Microsoft. On June 25, Microsoft paid US$1.2 billion to buy the social network Yammer. On July 31, they launched the Outlook.com webmail service to compete with Gmail. On September 4, 2012, Microsoft released Windows Server 2012.\n\nIn July 2012, Microsoft sold its 50% stake in MSNBC.com, which it had run as a joint venture with NBC since 1996. On October 1, Microsoft announced its intention to launch a news operation, part of a new-look MSN, with Windows 8 later in the month. On October 26, 2012, Microsoft launched Windows 8 and the Microsoft Surface. Three days later, Windows Phone 8 was launched. To cope with the potential for an increase in demand for products and services, Microsoft opened a number of \"holiday stores\" across the U.S. to complement the increasing number of \"bricks-and-mortar\" Microsoft Stores that opened in 2012. On March 29, 2013, Microsoft launched a Patent Tracker.\n\nThe Kinect, a motion-sensing input device made by Microsoft and designed as a video game controller, first introduced in November 2010, was upgraded for the 2013 release of the Xbox One video game console. Kinect's capabilities were revealed in May 2013: an ultra-wide 1080p camera, function in the dark due to an infrared sensor, higher-end processing power and new software, the ability to distinguish between fine movements (such as a thumb movements), and determining a user's heart rate by looking at their face. Microsoft filed a patent application in 2011 that suggests that the corporation may use the Kinect camera system to monitor the behavior of television viewers as part of a plan to make the viewing experience more interactive. On July 19, 2013, Microsoft stocks suffered its biggest one-day percentage sell-off since the year 2000, after its fourth-quarter report raised concerns among the investors on the poor showings of both Windows 8 and the Surface tablet. Microsoft suffered a loss of more than US$32 billion. \n\nIn line with the maturing PC business, in July 2013, Microsoft announced that it would reorganize the business into four new business divisions: Operating System, Apps, Cloud, and Devices. All previous divisions will be diluted into new divisions without any workforce cut. On September 3, 2013, Microsoft agreed to buy Nokia's mobile unit for $7 billion, following Amy Hood taking the role of CFO.\n\nIn November 2018, Microsoft agreed to supply 100,000 HoloLens headsets to the United States military in order to \"increase lethality by enhancing the ability to detect, decide and engage before the enemy.\"\nOn February 4, 2014, Steve Ballmer stepped down as CEO of Microsoft and was succeeded by Satya Nadella, who previously led Microsoft's Cloud and Enterprise division. On the same day, John W. Thompson took on the role of chairman, in place of Bill Gates, who continued to participate as a technology advisor. Thompson became the second chairman in Microsoft's history.\n\nOn April 25, 2014, Microsoft acquired Nokia Devices and Services for $7.2 billion. This new subsidiary was renamed Microsoft Mobile Oy.\nIn May 2016, the company announced it was laying off 1,850 workers, and taking an impairment and restructuring charge of $950 million. During the previous summer of 2015 the company lost $7.6 billion related to its mobile-phone business, firing 7,800 employees.\n\nOn September 15, 2014, Microsoft acquired the video game development company Mojang, best known for \"Minecraft\", for $2.5 billion. On June 8, 2017, Microsoft acquired Hexadite, an Israeli security firm, for $100 million. As of 2017, the company is organised into three operating business units, and four operating development or engineering units.\n\nOn June 4, 2018 Microsoft officially announced the acquisition of GitHub for $7.5 billion, a deal that is expected to close by the end of the year.\n\nOn January 21, 2015, Microsoft announced the release of their first Interactive whiteboard, Microsoft Surface Hub. On July 29, 2015, Windows 10 was released, with its server sibling, Windows Server 2016, released in September 2016.\n\nIn Q1 2015, Microsoft was the third largest maker of mobile phones, selling 33 million units (7.2% of all). While a large majority (at least 75%) of them do not run any version of Windows Phone – those other phones are not categorized as smartphones by Gartner – in the same time frame 8 million Windows smartphones (2.5% of all smartphones) were made by all manufacturers (but mostly by Microsoft). Microsoft's share of the U.S. smartphone market in January 2016 was 2.7%.\n\nOn March 1, 2016, Microsoft announced the merger of its PC and Xbox divisions, with Phil Spencer announcing that Universal Windows Platform (UWP) apps would be the focus for Microsoft's gaming in the future. On January 24, 2017, Microsoft showcased Intune for Education at the BETT 2017 education technology conference in London. Intune for Education is a new cloud-based application and device management service for the education sector. Microsoft planned to launch a preview of Intune for Education \"in the coming weeks\", with general availability scheduled for spring 2017, priced at $30 per device, or through volume licensing agreements.\n\nIn June 2016, Microsoft announced a project named Microsoft Azure Information Protection. It aims to help enterprises protect their data as it moves between servers and devices. In November 2016, Microsoft joined the Linux Foundation as a Platinum member during Microsoft's Connect(); developer event in New York. The cost of each Platinum membership is US$500,000 per year. Some analysts deemed this unthinkable ten years prior, however, as in 2001 then-CEO Steve Ballmer called Linux \"cancer\".\n\nIn August 2018, Microsoft released two initiatives to protect cybersecurity and fight fake news, the first called Microsoft AccountGuard and the second called Defending Democracy.\n\nIn August 2018, Toyota Tsusho began a partnership with Microsoft to create fish farming tools using the Microsoft Azure application suite for IoT technologies related to water management. Developed in part by researchers from Kindai University, the water pump mechanisms use artificial intelligence to count the number of fish on a conveyor belt, analyze the number of fish, and deduce the effectiveness of water flow from the data the fish provide. The specific computer programs used in the process fall under the Azure Machine Learning and the Azure IoT Hub platforms.\n\nOn 10 October, 2018, Microsoft joined the Open Invention Network community despite holding more than 60,000 patents.\n\nThe company is run by a board of directors made up of mostly company outsiders, as is customary for publicly traded companies. Members of the board of directors as of January 2018 are Bill Gates, Satya Nadella, Reid Hoffman, Lee Johnson, Teri L. List-Stoll, Charles Noski, Helmut Panke, Sandi Peterson, Penny Pritzker, Charles W. Scharf, Arne Sorenson, John W. Stanton, John W. Thompson and Padmasree Warrior. Board members are elected every year at the annual shareholders' meeting using a majority vote system. There are five committees within the board which oversee more specific matters. These committees include the Audit Committee, which handles accounting issues with the company including auditing and reporting; the Compensation Committee, which approves compensation for the CEO and other employees of the company; the Finance Committee, which handles financial matters such as proposing mergers and acquisitions; the Governance and Nominating Committee, which handles various corporate matters including nomination of the board; and the Antitrust Compliance Committee, which attempts to prevent company practices from violating antitrust laws.\n\nWhen Microsoft went public and launched its initial public offering (IPO) in 1986, the opening stock price was $21; after the trading day, the price closed at $27.75. As of July 2010, with the company's nine stock splits, any IPO shares would be multiplied by 288; if one were to buy the IPO today given the splits and other factors, it would cost about 9cents. The stock price peaked in 1999 at around $119 ($60.928 adjusting for splits). The company began to offer a dividend on January 16, 2003, starting at eight cents per share for the fiscal year followed by a dividend of sixteen cents per share the subsequent year, switching from yearly to quarterly dividends in 2005 with eight cents a share per quarter and a special one-time payout of three dollars per share for the second quarter of the fiscal year. Though the company had subsequent increases in dividend payouts, the price of Microsoft's stock remained steady for years.\n\nStandard and Poor's and Moody's have both given a AAA rating to Microsoft, whose assets were valued at $41 billion as compared to only $8.5 billion in unsecured debt. Consequently, in February 2011 Microsoft released a corporate bond amounting to $2.25 billion with relatively low borrowing rates compared to government bonds. For the first time in 20 years Apple Inc. surpassed Microsoft in Q1 2011 quarterly profits and revenues due to a slowdown in PC sales and continuing huge losses in Microsoft's Online Services Division (which contains its search engine Bing). Microsoft profits were $5.2 billion, while Apple Inc. profits were $6 billion, on revenues of $14.5 billion and $24.7 billion respectively. Microsoft's Online Services Division has been continuously loss-making since 2006 and in Q1 2011 it lost $726 million. This follows a loss of $2.5 billion for the year 2010.\n\nOn July 20, 2012, Microsoft posted its first quarterly loss ever, despite earning record revenues for the quarter and fiscal year, with a net loss of $492 million due to a writedown related to the advertising company aQuantive, which had been acquired for $6.2 billion back in 2007. As of January 2014, Microsoft's market capitalization stood at $314B, making it the 8th largest company in the world by market capitalization. On November 14, 2014, Microsoft overtook Exxon Mobil to become the 2nd most valuable company by market capitalization, behind only Apple Inc. Its total market value was over $410B — with the stock price hitting $50.04 a share, the highest since early 2000. In 2015, Reuters reported that Microsoft Corp had earnings abroad of $76.4 billion which were untaxed by the IRS. Under U.S. law corporations don't pay income tax on overseas profits until the profits are brought into the United States.\nIn November, 2018, the company won a $480 million military contract with the U.S. government to bring AR headset tech into the weapon repertoires of American soldiers. The two-year contract may result in follow-on orders of more than 100,000 headsets according to documentation describing the bidding process. One of the contract’s tag lines for the AR tech seems to be its ability to enable “25 bloodless battles before the 1st battle,” suggesting that actual combat training is going to be an essential aspect of the AR headset capabilities.\n\nIn 2004, Microsoft commissioned research firms to do independent studies comparing the total cost of ownership (TCO) of Windows Server 2003 to Linux; the firms concluded that companies found Windows easier to administrate than Linux, thus those using Windows would administrate faster resulting in lower costs for their company (i.e. lower TCO). This spurred a wave of related studies; a study by the Yankee Group concluded that upgrading from one version of Windows Server to another costs a fraction of the switching costs from Windows Server to Linux, although companies surveyed noted the increased security and reliability of Linux servers and concern about being locked into using Microsoft products. Another study, released by the Open Source Development Labs, claimed that the Microsoft studies were \"simply outdated and one-sided\" and their survey concluded that the TCO of Linux was lower due to Linux administrators managing more servers on average and other reasons.\n\nAs part of the \"Get the Facts\" campaign, Microsoft highlighted the .NET trading platform that it had developed in partnership with Accenture for the London Stock Exchange, claiming that it provided \"five nines\" reliability. After suffering extended downtime and unreliability the LSE announced in 2009 that it was planning to drop its Microsoft solution and switch to a Linux-based one in 2010.\n\nIn 2012, Microsoft hired a political pollster named Mark Penn, whom the \"New York Times\" called \"famous for bulldozing\" his political opponents as Executive Vice-President, Advertising and Strategy. Penn created a series of negative ads targeting one of Microsoft's chief competitors, Google. The ads, called \"Scroogled\", attempt to make the case that Google is \"screwing\" consumers with search results rigged to favor Google's paid advertisers, that Gmail violates the privacy of its users to place ad results related to the content of their emails and shopping results which favor Google products. Tech publications like TechCrunch have been highly critical of the ad campaign, while Google employees have embraced it.\n\nIn July 2014, Microsoft announced plans to lay off 18,000 employees. Microsoft employed 127,104 people as of June 5, 2014, making this about a 14 percent reduction of its workforce as the biggest Microsoft lay off ever. This included 12,500 professional and factory personnel. Previously, Microsoft has laid off 5,800 jobs in 2009 in line with US financial crisis. In September 2014, Microsoft laid off 2,100 people, including 747 people in the Seattle-Redmond area, where the company is headquartered. The firings came as a second wave of the layoffs that were previously announced. This brings the total number to over 15,000 out of the 18,000 expected cuts. In October 2014, Microsoft revealed that it was almost done with the elimination of 18,000 employees which was its largest ever layoff sweep. In July 2015, Microsoft announced another 7,800 job cuts in the next several months. In May 2016, Microsoft announced another 1,850 job cuts mostly in (Nokia) mobile phone division. As a result, the company will record an impairment and restructuring charge of approximately $950 million, of which approximately $200 million will relate to severance payments.\n\nMicrosoft provides information about reported bugs in their software to intelligence agencies of the United States government, prior to the public release of the fix. A Microsoft spokesperson has stated that the corporation runs several programs that facilitate the sharing of such information with the U.S. government. Following media reports about PRISM, NSA's massive electronic surveillance program, in May 2013, several technology companies were identified as participants, including Microsoft. According to leaks of said program, Microsoft joined the PRISM program in 2007. However, in June 2013, an official statement from Microsoft flatly denied their participation in the program:\n\nWe provide customer data only when we receive a legally binding order or subpoena to do so, and never on a voluntary basis. In addition we only ever comply with orders for requests about specific accounts or identifiers. If the government has a broader voluntary national security program to gather customer data, we don't participate in it.\n\nDuring the first six months in 2013, Microsoft had received requests that affected between 15,000 and 15,999 accounts. In December 2013, the company made statement to further emphasize the fact that they take their customers' privacy and data protection very seriously, even saying that \"government snooping potentially now constitutes an \"advanced persistent threat,\" alongside sophisticated malware and cyber attacks\". The statement also marked the beginning of three-part program to enhance Microsoft's encryption and transparency efforts. On July 1, 2014, as part of this program they opened the first (of many) Microsoft Transparency Center, that provides \"participating governments with the ability to review source code for our key products, assure themselves of their software integrity, and confirm there are no \"back doors.\" Microsoft has also argued that the United States Congress should enact strong privacy regulations to protect consumer data.\n\nIn April 2016, the company sued the U.S. government, arguing that secrecy orders were preventing the company from disclosing warrants to customers in violation of the company's and customers' rights. Microsoft argued that it was unconstitutional for the government to indefinitely ban Microsoft from informing its users that the government was requesting their emails and other documents, and that the Fourth Amendment made it so people or businesses had the right to know if the government searches or seizes their property. On October 23, 2017, Microsoft said it would drop the lawsuit as a result of a policy change by the Department of Justice (DoJ). The DoJ had \"changed data request rules on alerting internet users about agencies accessing their information.\" The new policy mandated defined periods of time for secrecy orders from the government.\n\nTechnical reference for developers and articles for various Microsoft magazines such as \"Microsoft Systems Journal\" (MSJ) are available through the Microsoft Developer Network (MSDN). MSDN also offers subscriptions for companies and individuals, and the more expensive subscriptions usually offer access to pre-release beta versions of Microsoft software. In April 2004 Microsoft launched a community site for developers and users, titled Channel 9, that provides a wiki and an Internet forum. Another community site that provides daily videocasts and other services, On10.net, launched on March 3, 2006. Free technical support is traditionally provided through online Usenet newsgroups, and CompuServe in the past, monitored by Microsoft employees; there can be several newsgroups for a single product. Helpful people can be elected by peers or Microsoft employees for Microsoft Most Valuable Professional (MVP) status, which entitles them to a sort of special social status and possibilities for awards and other benefits.\n\nNoted for its internal lexicon, the expression \"eating our own dog food\" is used to describe the policy of using pre-release and beta versions of products inside Microsoft in an effort to test them in \"real-world\" situations. This is usually shortened to just \"dog food\" and is used as noun, verb, and adjective. Another bit of jargon, FYIFV or FYIV (\"Fuck You, I'm [Fully] Vested\"), is used by an employee to indicate they are financially independent and can avoid work anytime they wish. The company is also known for its hiring process, mimicked in other organizations and dubbed the \"Microsoft interview\", which is notorious for off-the-wall questions such as \"Why is a manhole cover round?\".\n\nMicrosoft is an outspoken opponent of the cap on H1B visas, which allow companies in the U.S. to employ certain foreign workers. Bill Gates claims the cap on H1B visas makes it difficult to hire employees for the company, stating \"I'd certainly get rid of the H1B cap\" in 2005. Critics of H1B visas argue that relaxing the limits would result in increased unemployment for U.S. citizens due to H1B workers working for lower salaries. The Human Rights Campaign Corporate Equality Index, a report of how progressive the organization deems company policies towards LGBT employees, rated Microsoft as 87% from 2002 to 2004 and as 100% from 2005 to 2010 after they allowed gender expression.\n\nIn August 2018, Microsoft implemented a policy for all companies providing subcontractors to require 12 weeks of paid parental leave to each employee. This expands on the former requirement from 2015 requiring 15 days of paid vacation and sick leave each year. In 2015, Microsoft established its own parental leave policy to allow 12 weeks off for parental leave with an additional 8 weeks for the parent who gave birth.\n\nIn 2011, Greenpeace released a report rating the top ten big brands in cloud computing on their sources of electricity for their data centers. At the time, data centers consumed up to 2% of all global electricity and this amount was projected to increase. Phil Radford of Greenpeace said \"we are concerned that this new explosion in electricity use could lock us into old, polluting energy sources instead of the clean energy available today,\" and called on \"Amazon, Microsoft and other leaders of the information-technology industry must embrace clean energy to power their cloud-based data centers.\" In 2013, Microsoft agreed to buy power generated by a Texas wind project to power one of its data centers. Microsoft is ranked on the 17th place in Greenpeace's \"Guide to Greener Electronics\" (16th Edition) that ranks 18 electronics manufacturers according to their policies on toxic chemicals, recycling and climate change. Microsoft's timeline for phasing out brominated flame retardant (BFRs) and phthalates in all products is 2012 but its commitment to phasing out PVC is not clear. As of January 2011, it has no products that are completely free from PVC and BFRs.\n\nMicrosoft's main U.S. campus received a silver certification from the Leadership in Energy and Environmental Design (LEED) program in 2008, and it installed over 2,000 solar panels on top of its buildings in its Silicon Valley campus, generating approximately 15 percent of the total energy needed by the facilities in April 2005. Microsoft makes use of alternative forms of transit. It created one of the world's largest private bus systems, the \"Connector\", to transport people from outside the company; for on-campus transportation, the \"Shuttle Connect\" uses a large fleet of hybrid cars to save fuel. The company also subsidises regional public transport, provided by Sound Transit and King County Metro, as an incentive. In February 2010 however, Microsoft took a stance against adding additional public transport and high-occupancy vehicle (HOV) lanes to the State Route 520 and its floating bridge connecting Redmond to Seattle; the company did not want to delay the construction any further. Microsoft was ranked number 1 in the list of the World's Best Multinational Workplaces by the Great Place to Work Institute in 2011.\n\nThe corporate headquarters, informally known as the Microsoft Redmond campus, is located at One Microsoft Way in Redmond, Washington. Microsoft initially moved onto the grounds of the campus on February 26, 1986, weeks before the company went public on March 13. The headquarters has since experienced multiple expansions since its establishment. It is estimated to encompass over 8 million ft (750,000 m) of office space and 30,000–40,000 employees. Additional offices are located in Bellevue and Issaquah (90,000 employees worldwide). The company is planning to upgrade its Mountain View, California campus on a grand scale. The company has occupied this campus since 1981. The company is planning to buy the 32-acre campus. The plans submitted involve expanding the campus by 25%. It is expected that it will take three years to complete the expansion. If approved, construction will start in early 2017. Microsoft operates an East Coast headquarters in Charlotte, North Carolina.\n\nOn October 26, 2015, the company opened its flagship retail location on Fifth Avenue in New York City. The location features a five-story glass storefront and is 22,270 square feet. As per company executives, Microsoft had been on the lookout for a flagship location since 2009. The company's retail locations are part of a greater\nstrategy to help build a connection with its consumers. The\nopening of the store coincided with the launch of the Surface Book and Surface\nPro 4. On November 12, 2015, Microsoft opened a second flagship store, located in Sydney's Pitt Street Mall.\n\nMicrosoft adopted the so-called \"\"Pac-Man\" Logo\", designed by Scott Baker, in 1987. Baker stated \"The new logo, in Helvetica italic typeface, has a slash between the \"o\" and \"s\" to emphasize the \"soft\" part of the name and convey motion and speed.\" Dave Norris ran an internal joke campaign to save the old logo, which was green, in all uppercase, and featured a fanciful letter \"O\", nicknamed the \"blibbet\", but it was discarded. Microsoft's logo with the tagline \"Your potential. Our passion.\" below the main corporate name is based on a slogan Microsoft used in 2008. In 2002, the company started using the logo in the United States and eventually started a television campaign with the slogan, changed from the previous tagline of \"Where do you want to go today?\" During the private MGX (Microsoft Global Exchange) conference in 2010, Microsoft unveiled the company's next tagline, \"Be What's Next.\" They also had a slogan/tagline \"Making it all make sense.\"\n\nOn August 23, 2012, Microsoft unveiled a new corporate logo at the opening of its 23rd Microsoft store in Boston, indicating the company's shift of focus from the classic style to the tile-centric modern interface, which it uses/will use on the Windows Phone platform, Xbox 360, Windows 8 and the upcoming Office Suites. The new logo also includes four squares with the colors of the then-current Windows logo which have been used to represent Microsoft's four major products: Windows (blue), Office (red), Xbox (green) and Bing (yellow). The logo resembles the opening of one of the commercials for Windows 95.\n\nThe company was the official jersey sponsor of Finland's national basketball team at the 2015 EuroBasket.\n\n"}
{"id": "55886058", "url": "https://en.wikipedia.org/wiki?curid=55886058", "title": "Mobile Telecommunications Company of Esfahan", "text": "Mobile Telecommunications Company of Esfahan\n\nMobile Telecommunication Company of Esfahan (شرکت مخابرات سیار اصفهان, MTCE) also known as Espadan was a mobile network operator in Iran.\n\nFollowing the agreements reached during the Iranian President Hashemi Rafsanjani's visit to Malaysia in 1994, and according to the laws of attracting and supporting foreign investment, in 29 May 2001 the license for launching the first prepaid mobile telephone network in Iran with an initial capacity of 20 thousand subscribers was granted to Celcom for 15 years, and the Malaysian Technology Resources Industry Company received permission to use GSM 24.18 Mbit/s bandwidth within the Isfahan province.\n\nIn 2005 Celcom sold its stakes to TM International(Telekom Malaysia).\n\nIn 2008 MTCE bought the WiMAX license from Iranian Communications Regulatory Authority (CRA).\n\nIn 2011 MTCE went broke and deactivated all sim cards following merger with Mobile Telecommunications Company of Iran.\n\nAxiata Group Berhad (49%) | Telecommunications Company of Esfahan (49%) | Iran Telecom Industries (2%)\n"}
{"id": "37571325", "url": "https://en.wikipedia.org/wiki?curid=37571325", "title": "National University of Food Technologies", "text": "National University of Food Technologies\n\nThe National University of Food Technologies is a Ukrainian university located in Kiev, the capital of Ukraine.\n\nThe campus includes eight buildings. Building \"A\" hosts the University administration section, Assembly Hall, Academic Council Hall, Dean of Faculty, Departmental offices, Teaching offices, Classrooms and Laboratories. Building \"B\" hosts the University Entrance exam rooms, Department of Pre-University Education, Training rooms, Museum and classrooms. Buildings \"C\", \"D\", and \"F\" - each host departmental offices, teachers' offices, classrooms, and laboratories. Buildings \"E\" and \"I\" host University service centers: Human Resources, Accounting, Supplies Division, Chief Power Sources, the Department of Fire Safety and more.\n\nThe National University of Food Technology consists of 21 faculties (including eight via correspondence or satellite campuses) which are located in the following regions of Ukraine: Kyiv, Vinnytsia, Lutsk, Kerch, Lviv, Poltava, Svaliava, Ivano-Frankivsk, Kamianets-Podilskyi, Simferopol, Smila, Sumy, and Odesa.\n\nIn Kyiv, there are the following programs of study:\n\n\nAll-Ukrainian rating Vyssh uchebnыh wound \"Compass 2012\" - 7th place.\n\nRating the State Intellectual Property Service of Ukraine - 1st place among universities with the highest inventive activities.\n\n"}
{"id": "58482903", "url": "https://en.wikipedia.org/wiki?curid=58482903", "title": "Pedago", "text": "Pedago\n\nPedago is an educational technology company founded by Alexie Harper, Tom Adams, and Ori Ratner focused on the development of online education solutions and interactive courses. It currently offers an online MBA and Executive MBA program as well as several business foundation courses through its \"mobile-first\" Smartly platform, first launched in September 2015.It offers over 600 lessons in nine business subjects, including accounting, economics, and statistics. An application process that runs several times a year is required for the admission of candidates. Candidates are required to pass its business foundation courses in order to be considered for application. However, its MBA program is free upon acceptance by the admissions team. It also offers an EMBA program with full scholarships available.\n\nPedago was founded by Tom Adams, Alexie Harper, and Ori Ratner in May 2013 in Arlington, Virginia upon the realization that traditional MBA programs were not achieving the same return on investment as they used to apart from several top-tiered MBA programs. The three came up with the idea after leaving Rosetta Stone, and they bootstrapped Pedago into what has become a 40-person education technology company.\n\nIt accepted its first cohort of MBA candidates in July 2016 and several of its alumni have since been honorees of the Forbes 30 Under 30.\n\nThe Smartly MBA and EMBA programs currently offer a free online platform for studying and to connect students with worldwide employers. The business model is based on receiving financing from employers searching for MBA graduates sourced from its selective program, allowing it to cut down on overhead in the case of traditional recruitment. Affiliated hiring organizations already include Square, Capital One, and smaller startups like Door Dash.\n\nPedago is largely funded by Tom Adams and a few unnamed external investors.\n\nIt has also partnered with Uber to train its drivers in Africa and to help incoming MBA students in Georgetown University prepare them in introductory courses.\n\nPedago's first product is the Smartly platform, which offers both an MBA and EMBA program through its web and mobile application, combining interactive problem solving with instant feedback while using the active learning method. Instead of using video as its primary medium of delivering its content often seen in many MOOCs, it focuses on delivering its lessons through piecemeal concepts. All Smartly MBA applicants are required to possess a bachelor's degree or possess previous business experience in lieu of a bachelor's degree, as well as an essay component and completion of its business foundation courses in order to be accepted as a candidate. Applicants are required to submit academic transcripts upon acceptance, similar to traditional university matriculation procedures.\n\nThe MBA core curriculum consists of sections divided according to various functional departments in an organization, including accounting, finance, marketing, supply chain management, and strategy. Communication is also done through Slack with weekly discussion for candidates. Optional elective courses are also offered in topics including game theory, IP laws, M&As, and vertical integration as well as up and coming topics in entrepreneurship, e-commerce, and data science.\n"}
{"id": "28333458", "url": "https://en.wikipedia.org/wiki?curid=28333458", "title": "Peptide amphiphile", "text": "Peptide amphiphile\n\nPeptide amphiphiles are peptide-based molecules that self-assemble into structures including high aspect ratio nanofibers. A peptide amphiphile typically comprises a hydrophilic peptide sequence with an attached lipid chains, in this case being a lipopeptide. They were first described by the group of Matthew Tirrell in 1995. These molecules are often composed of multiple domains which allow self-assembly into various supramolecular structures. The individual domains associate with each other and result in growth of larger assemblies. Work by Hartgerink et al. in the early 2000s demonstrated a peptide amphiphile which has three regions: a hydrophobic tail, a region of beta-sheet forming amino acids, and a peptide epitope designed to allow solubility of the molecule in water, perform a biological function by interacting with living systems, or both. Self-assembly occurs by the combination of hydrogen-bonding between beta-sheet forming amino acids and hydrophobic collapse of the tails to yield the formation of cylindrical micelles that present the peptide epitope at extremely high density at the nanofiber surface. In a newer system developed by Hartgerink in the mid 2000s, multidomain peptides consisting nominally of alternating hydrophobic and hydrophilic amino acids, with terminal lysines self-assemble into parallel or anti-parallel beta sheets. This self-assembly of molecules into fibers occurs spontaneously in all solutions of peptide amphiphiles, which have a vanishingly small critical micelle concentration. By changing pH or adding counterions to screen the charged surfaces of fibers, gels can be formed. It has been shown that injection of peptide amphiphile solutions in vivo leads to in situ gel formation due to the presence of counterions in physiological solutions. This, along with the complete biodegradability of the materials, suggests numerous applications in in vitro and in vivo therapies.\n\nThe modular nature of the chemistry allows the tuning of both the mechanical properties and bioactivities of the resulting self-assembled fibers and gels. Bioactive sequences can be used to bind growth factors to localize and present them at high densities to cells, or to directly mimic the function of endogenous biomolecules. Epitopes mimicking the adhesive RGD loop in fibronectin, the IKVAV sequence in laminin and a consensus sequence to bind heparin sulfate are just a few of the large library of sequences that have been synthesized. These molecules and the materials made from them have been shown to be effective in promoting cell adhesion, wound healing, mineralization of bone, differentiation of cells and even recovery of function after spinal cord injury in mice.\n\nIn addition to this, peptide amphiphiles can be used to form more sophisticated architectures which can be tuned on demand. In recent years, two discoveries have yielded bioactive materials with more advanced structures and potential applications. In one study, a thermal treatment of peptide amphiphile solutions led to the formation of large birefringent domains in the material that could be aligned by a weak shear force into one continuous monodomain gel of aligned nanofibers. The low shear forces used in aligning the material permit the encapsulation of living cells inside these aligned gels and suggest several applications in regenerating tissues that rely on cell polarity and alignment for function. In another study, the combination of positively charged peptide amphiphiles and negatively charged long biopolymers led to the formation of hierarchically ordered membranes. When the two solutions are brought into contact, electrostatic complexation between the components of each solution creates a diffusion barrier that prevents the mixing of the solutions. Over time, an osmotic pressure difference drives the reptation of polymer chains through the diffusion barrier into the peptide amphiphile compartment, leading to the formation of fibers perpendicular to the interface that grow over time. These materials can be made in the form of flat membranes or as spherical sacs by dropping one solution into the other. These materials are robust enough to handle mechanically and a range of mechanical properties can be accessed by altering growth conditions and time. They can incorporate bioactive peptide amphiphiles, encapsulate cells and biomolecules, and are biocompatible and biodegradable.\n\n\n"}
{"id": "9992916", "url": "https://en.wikipedia.org/wiki?curid=9992916", "title": "RingGo", "text": "RingGo\n\nRingGo is a pay by phone parking service, based in the UK. It processes over 2 million phone parking transactions a month and over 6 million individual UK motorists have used the service. Offered in public car parks and on-street locations across the United Kingdom it is now deployed in support of over 100 local authorities. The first major implementation (from June 2006) was for the First Great Western Railway in 60 stations. The project by the FirstGroup, was an early step in the trend away from the established system of paying for parking using electro-mechanical machines which dispense paper tickets – the pay and display model.\n\nRailways were a major area of early stage growth. Franchises that adopted the service included Network Rail, Chiltern Railways, South West Trains, First Capital Connect, National Express East Anglia, c2c, First TransPennine Express, Arriva Trains Wales and East Coast Railway. The service has also been offered in NCP operated and managed car parks since March 2010.\n\nParking was an early area in which electronic money as opposed to cash-money made considerable advances although it has been overtaken since in sectors such as mass transportation.\n\nOn 1 October 2009, Richmond Council introduced variable parking charges which were linked to the carbon dioxide emissions of vehicles parking there (carbon metered parking). Payment of the service was either via RingGo or by a Richmond smart card, which could be used in the machine.\n\nMilton Keynes Council, Richmond Council, Lewisham Council and, from November 2014, Westminster council provide online parking permits that are an extension of the RingGo phone parking service\n\nThe RingGo brand is owned by Cobalt Telephone Technologies Ltd, a UK private company headquartered in Basingstoke, Hampshire. Cobalt was acquired by the Parkmobile Group in August 2012. The Parkmobile group is a global specialist in phone parking and has similar operations in support of cities, railways and municipalities in North America, The Netherlands, Belgium and Germany.\n\n"}
{"id": "2891983", "url": "https://en.wikipedia.org/wiki?curid=2891983", "title": "Sony eVilla", "text": "Sony eVilla\n\nThe Sony eVilla is a discontinued Internet appliance from Sony. After 18 months of development, it was released to the public on June 14, 2001 for $499 USD. With the additional $21.95 USD monthly fee, users could access the Internet, send and receive e-mail, play audio and video, and save files to Sony's Memory Stick.\n\nAfter less than three months in the market, Sony discontinued the product on September 13, 2001. Customers received full refunds for the product and the monthly subscription fee. Spokesman John Dolak remarked that \"[the] product did not meet our expectations, it did not operate as planned.\"\n\nSony entered the Internet appliance market as other manufacturers were getting out, canceling their plans, and discontinuing their offerings. By the time the Sony eVilla shipped, only 150,000 internet appliance devices had shipped within the past year. In addition, many customers could not justify the purchase of an inherently limited internet appliance when other manufacturers were offering more capable personal computers for the same price.\n\nThe Sony eVilla was powered by a 266 MHz Geode GX 1 CPU, with 64 MiB DRAM, and 24 MiB flash memory. It weighed 31.5 pounds (14.3 kg) and measured 11.81 × 16.18 × 15.82 inches (30 × 41.1 x 40.2 cm).\n\nThere was no hard disk, but the system could read and write to Sony's Memory Stick cards. The included keyboard and mouse were connected by two PS/2 ports, and additional devices could be connected with two USB ports. A 56K V.90 modem was built into the case, which also housed an unused Ethernet port.\n\nThe display was a portrait-style 15 inch (38 cm) Sony Trinitron, with 800×1024 pixel resolution.\n\nThe system used the BeIA 1.0 operating system from Be Inc., and supported Java applications, Macromedia Flash animations, and some Microsoft Office file formats. Also included was RealNetworks's RealPlayer.\n\nOne of the major drawbacks of the eVilla was the inability to save pictures and media from internet sites.\n\n"}
{"id": "38623378", "url": "https://en.wikipedia.org/wiki?curid=38623378", "title": "Sue Ion", "text": "Sue Ion\n\nDame Susan Elizabeth Ion (née Burrows; ) (née Burrows; 3 February 1955) is a British engineer and an expert advisor on the nuclear power industry.\n\nBorn Susan Elizabeth Burrows on 3 February 1955 in Cumbria, she is the daughter of Lawrence James Burrows, a planning officer for British Rail, and Doris Burrows (née Cherry), a secretary.\n\nIon was educated at Penwortham Girls Grammar School near Preston, Lancashire in the same year as Nancy Rothwell. As a young student, she enjoyed science, which her parents encouraged by letting her do chemistry experiments in the family's kitchen.\n\nAt school, she took a leadership role as Head Girl from 1972 to 1973 and deputy leader of the orchestra. At 16, Ion won a book on atomic energy as a prize for her O-levels in science, which helped inspire her enthusiasm for the topic. She recalled, \"When I was in school ... it was quite different. You were given every encouragement possible to do science subjects if you were interested in them\".\n\nIon went on to study Materials Science at Imperial College London, gaining a first class Bachelor of Science degree and a PhD in Metallurgy in 1979 supervised by F.J. Humphreys and S.H. White.\n\nShe taught in an inner-city school in London while completing her doctorate, and used supplies from the college laboratories in her lessons to help students become enthusiastic about the industry. \"Where there is no vision ... the people perish\", she says.\n\nIn 1979, Ion was first hired as a technical officer at British Nuclear Fuels (BNFL). At the time, she and one other woman were the only females working in the chemical engineering department.\n\nIn 1992, she was promoted to Executive Director of Technology, a position Ion held within the organisation until 2006.\n\nDuring this time, nuclear or atomic energy was viewed as a valuable source of energy, along with the existing coal industry, and a necessary part of rebuilding post-war Britain. It was, according to Ion, an exciting industry with a vibrant research and development program and great prospects. As she told Jim Al-Khalili in a 2013 interview for BBC Radio Four, \"Nothing over time has changed my view of that\".\n\nAs technical director of BNFL, Ion held a seat on Tony Blair's Council for Science and Technology and has been credited with persuading Blair to change Labour's official government's policy on nuclear power.\n\nIon's work, along with David King, took about 10 years of educating government officials to consider the scientific evidence surrounding the issues of nuclear power and renewable energy to inform policy. She helped advise Gordon Brown on long-term energy policies.\n\nIn 2004, Ion was among 180 women invited to a \"Women's Theme Day\" luncheon at Buckingham Palace in recognition of her contributions to the field of science and technology.\n\nIon was elected a Fellow of the Royal Academy of Engineering (FREng) in 1996 and was a vice-president from 2002 to 2008.\n\nIn 2006, Ion was appointed visiting professor of Imperial College and admitted to the Fellowship of the college in 2005.\n\nIon has studied energy supplies for more than 30 years. She spent a lot of time early in her career advising government officials about nuclear reactors and countering the negativity caused by the incidents at Three Mile Island and Chernobyl.\nIon supports the development of smaller, modular versions of nuclear reactors for their economy of size, portability and cost. These smaller reactors would, most likely, be housed on existing nuclear sites licensed for that purpose.\n\nIon views her biggest challenge is \"persuading decades-worth of politicians that nuclear energy is really needed.\" Her position is that renewable energy sources (particularly wind power), coal and nuclear power will be necessary components of Britain's energy policy moving forward.\n\nIn Ion's outreach as a spokesperson for the nuclear power industry, she has expressed a belief that more needs to be done to attract women into the field of engineering. She has expressed concerns that some areas of the educational system still view engineering as a subject only for males.\n\nWhile major institutions may support the idea of females entering the field of science and engineering, Ion notes that grade schools under the current system may not provide the prerequisite coursework early enough in students' academic careers for them to be successful at university.\n\nIon supports educational programs that support all students, regardless of gender, to explore science and develop the skills necessary to replace what the Royal Academy of Engineering views as a retiring workforce. In response to a report commissioned by the Nuclear Industry Association (NIA) discussing the UK's plans for future energy production, she cautions: \"There will be an unprecedented demand for new infrastructure to support the changes in the energy industry. There are not enough people going into university to study engineering and provide all the turbine specialists, heavy electrical engineers and construction engineers that will be required\".\n\nShe married John Albert Ion in 1980 and lives in Leyland, Lancashire.\n"}
{"id": "9754990", "url": "https://en.wikipedia.org/wiki?curid=9754990", "title": "Supernode (circuit)", "text": "Supernode (circuit)\n\nIn circuit theory, a supernode is a theoretical construct that can be used to solve a circuit. This is done by viewing a voltage source on a wire as a point source voltage in relation to other point voltages located at various nodes in the circuit, relative to a ground node assigned a zero or negative charge.\n\nEach supernode contains two nodes, one non-reference node and another node that may be a second non-reference node or the reference node. Supernodes containing the reference node have one node voltage variable. For nodal analysis, the supernode construct is only required between two non-reference nodes.\n\nIt is related to Kirchhoff's Current Law which states that the total or algebraic sum of currents meeting at a junction or node is zero. Every junction where two or more branches meet is a node. One of the nodes in the network is taken as reference node. If there are n nodes in any network, the number of simultaneous equation to be solved will be (n-1).\n"}
{"id": "25696595", "url": "https://en.wikipedia.org/wiki?curid=25696595", "title": "Sustainability declaration", "text": "Sustainability declaration\n\nSustainability declarations are checklists of sustainability features that were a requirement to be completed by home-owners and vendors in Queensland, Australia before a home can be sold.\nThe checklist identifies the property's environmental and social sustainability features in the four areas of energy, water, safety, and access.\n\nHome owners must complete these sustainability checklists or risk being fined up to $4000. Advertising for homes must also include details about where the Sustainability Declaration for the property can be viewed. Properties that have a larger number of sustainability features generate fewer greenhouse gas emissions, use less energy for heating and cooling, use less water and are more comfortable to live in. They also can have fewer operating costs and be more energy and water efficient.\n\nSustainability Declaration now no longer needed for Queensland home owners August 2012\n\n"}
{"id": "1002744", "url": "https://en.wikipedia.org/wiki?curid=1002744", "title": "Sustainable transport", "text": "Sustainable transport\n\nSustainable transport refers to the broad subject of transport that is sustainable in the senses of social, environmental and climate impacts and the ability to, in the global scope, supply the source energy indefinitely. Components for evaluating sustainability include the particular vehicles used for road, water or air transport; the source of energy; and the infrastructure used to accommodate the transport (roads, railways, airways, waterways, canals and terminals). Transport operations and logistics as well as transit-oriented development are also involved in evaluation. Transportation sustainability is largely being measured by transportation system effectiveness and efficiency as well as the environmental and climate impacts of the system.\n\nShort-term activity often promotes incremental improvement in fuel efficiency and vehicle emissions controls while long-term goals include migrating transportation from fossil-based energy to other alternatives such as renewable energy and use of other renewable resources. The entire life cycle of transport systems is subject to sustainability measurement and optimization.\n\nSustainable transport systems make a positive contribution to the environmental, social and economic sustainability of the communities they serve. Transport systems exist to provide social and economic connections, and people quickly take up the opportunities offered by increased mobility, with poor households benefiting greatly from low carbon transport options. The advantages of increased mobility need to be weighed against the environmental, social and economic costs that transport systems pose.\n\nTransport systems have significant impacts on the environment, accounting for between 20% and 25% of world energy consumption and carbon dioxide emissions. The majority of the emissions, almost 97%, came from direct burning of fossil fuels. Greenhouse gas emissions from transport are increasing at a faster rate than any other energy using sector. Road transport is also a major contributor to local air pollution and smog.\n\nThe United Nations Environment Programme (UNEP) estimates that each year 2.4 million premature deaths from outdoor air pollution could be avoided. Particularly hazardous for health are emissions of black carbon, a component of particulate matter, which is a known cause of respiratory and carcinogenic diseases and a significant contributor to global climate change. The links between greenhouse gas emissions and particulate matter make low carbon transport an increasingly sustainable investment at local level—both by reducing emission levels and thus mitigating climate change; and by improving public health through better air quality.\n\nThe social costs of transport include road crashes, air pollution, physical inactivity, time taken away from the family while commuting and vulnerability to fuel price increases. Many of these negative impacts fall disproportionately on those social groups who are also least likely to own and drive cars. Traffic congestion imposes economic costs by wasting people's time and by slowing the delivery of goods and services.\n\nTraditional transport planning aims to improve mobility, especially for vehicles, and may fail to adequately consider wider impacts. But the real purpose of transport is access – to work, education, goods and services, friends and family – and there are proven techniques to improve access while simultaneously reducing environmental and social impacts, and managing traffic congestion. Communities which are successfully improving the sustainability of their transport networks are doing so as part of a wider programme of creating more vibrant, livable, sustainable cities.\n\nThe term sustainable transport came into use as a logical follow-on from sustainable development, and is used to describe modes of transport, and systems of transport planning, which are consistent with wider concerns of sustainability. There are many definitions of the sustainable transport, and of the related terms sustainable transportation and sustainable mobility. One such definition, from the European Union Council of Ministers of Transport, defines a sustainable transportation system as one that:\n\nSustainability extends beyond just the operating efficiency and emissions. A life-cycle assessment involves production, use and post-use considerations. A cradle-to-cradle design is more important than a focus on a single factor such as energy efficiency.\n\nMost of the tools and concepts of sustainable transport were developed before the phrase was coined. Walking, the first mode of transport, is also the most sustainable. Public transport dates back at least as far as the invention of the public bus by Blaise Pascal in 1662. The first passenger tram began operation in 1807 and the first passenger rail service in 1825. Pedal bicycles date from the 1860s. These were the only personal transport choices available to most people in Western countries prior to World War II, and remain the only options for most people in the developing world. Freight was moved by human power, animal power or rail.\n\nThe post-war years brought increased wealth and a demand for much greater mobility for people and goods. The number of road vehicles in Britain increased fivefold between 1950 and 1979, with similar trends in other Western nations. Most affluent countries and cities invested heavily in bigger and better-designed roads and motorways, which were considered essential to underpin growth and prosperity. Transport planning became a branch of Urban Planning and identified induced demand as a pivotal change from \"predict and provide\" toward a sustainable approach incorporating land use planning and public transit. Public investment in transit, walking and cycling declined dramatically in the United States, Great Britain and Australia, although this did not occur to the same extent in Canada or mainland Europe.\n\nConcerns about the sustainability of this approach became widespread during the 1973 oil crisis and the 1979 energy crisis. The high cost and limited availability of fuel led to a resurgence of interest in alternatives to single occupancy vehicle travel.\n\nTransport innovations dating from this period include high-occupancy vehicle lanes, citywide carpool systems and transportation demand management. Singapore implemented congestion pricing in the late 1970s, and Curitiba began implementing its Bus Rapid Transit system in the early 1980s.\n\nRelatively low and stable oil prices during the 1980s and 1990s led to significant increases in vehicle travel from 1980–2000, both directly because people chose to travel by car more often and for greater distances, and indirectly because cities developed tracts of suburban housing, distant from shops and from workplaces, now referred to as urban sprawl. Trends in freight logistics, including a movement from rail and coastal shipping to road freight and a requirement for just in time deliveries, meant that freight traffic grew faster than general vehicle traffic.\n\nAt the same time, the academic foundations of the \"predict and provide\" approach to transport were being questioned, notably by Peter Newman in a set of comparative studies of cities and their transport systems dating from the mid-1980s.\n\nThe British Government's White Paper on Transport marked a change in direction for transport planning in the UK. In the introduction to the White Paper, Prime Minister Tony Blair stated that\nWe recognise that we cannot simply build our way out of the problems we face. It would be environmentally irresponsible – and would not work.\n\nA companion document to the White Paper called \"Smarter Choices\" researched the potential to scale up the small and scattered sustainable transport initiatives then occurring across Britain, and concluded that the comprehensive application of these techniques could reduce peak period car travel in urban areas by over 20%.\n\nA similar study by the United States Federal Highway Administration, was also released in 2004 and also concluded that a more proactive approach to transportation demand was an important component of overall national transport strategy.\n\nTransport systems are major emitters of greenhouse gases, responsible for 23% of world energy-related GHG emissions in 2004, with about three quarters coming from road vehicles. Currently 95% of transport energy comes from petroleum. Energy is consumed in the manufacture as well as the use of vehicles, and is embodied in transport infrastructure including roads, bridges and railways.\n\nThe first historical attempts of evaluating the Life Cycle environmental impact of vehicle is due to Theodore Von Karman. After decades in which all the analysis has been focused on emending the Von Karman model, Dewulf and Van Langenhove have introduced an model based on the second law of thermodynamics and exergy analysis. Chester and Orwath, have developed a similar model based on the first law that accounts the necessary costs for the infrastructure. \n\nThe environmental impacts of transport can be reduced by reducing the weight of vehicles, sustainable styles of driving, reducing the friction of tires, encouraging electric and hybrid vehicles, improving the walking and cycling environment in cities, and by enhancing the role of public transport, especially electric rail.\n\nGreen vehicles are intended to have less environmental impact than equivalent standard vehicles, although when the environmental impact of a vehicle is assessed over the whole of its life cycle this may not be the case. Electric vehicle technology has the potential to reduce transport CO emissions, depending on the embodied energy of the vehicle and the source of the electricity. The primary sources of electricity currently used in most countries (coal, gas, oil) mean that until world electricity production changes substantially, private electric cars will result in the same or higher production of CO2 than petrol equivalent vehicles. The Online Electric Vehicle (OLEV), developed by the Korea Advanced Institute of Science and Technology (KAIST), is an electric vehicle that can be charged while stationary or driving, thus removing the need to stop at a charging station. The City of Gumi in South Korea runs a 24 km roundtrip along which the bus will receive 100 kW (136 horsepower) electricity at an 85% maximum power transmission efficiency rate while maintaining a 17 cm air gap between the underbody of the vehicle and the road surface.\nAt that power, only a few sections of the road need embedded cables. Hybrid vehicles, which use an internal combustion engine combined with an electric engine to achieve better fuel efficiency than a regular combustion engine, are already common. Natural gas is also used as a transport fuel. Biofuels are a less common, and less promising, technology; Brazil met 17% of its transport fuel needs from bioethanol in 2007, but the OECD has warned that the success of biofuels in Brazil is due to specific local circumstances; internationally, biofuels are forecast to have little or no impact on greenhouse emissions, at significantly higher cost than energy efficiency measures.\n\nIn practice there is a sliding scale of green transport depending on the sustainability of the option. Green vehicles are more fuel-efficient, but only in comparison with standard vehicles, and they still contribute to traffic congestion and road crashes. Well-patronised public transport networks based on traditional diesel buses use less fuel per passenger than private vehicles, and are generally safer and use less road space than private vehicles. Green public transport vehicles including electric trains, trams and electric buses combine the advantages of green vehicles with those of sustainable transport choices. Other transport choices with very low environmental impact are cycling and other human-powered vehicles, and animal powered transport. The most common green transport choice, with the least environmental impact is walking.\n\nTransport on rails boasts an excellent efficiency (see fuel efficiency in transportation).\n\nCities with overbuilt roadways have experienced unintended consequences, linked to radical drops in public transport, walking, and cycling. In many cases, streets became void of “life.” Stores, schools, government centers and libraries moved away from central cities, and residents who did not flee to the suburbs experienced a much reduced quality of public space and of public services. As schools were closed their mega-school replacements in outlying areas generated additional traffic; the number of cars on US roads between 7:15 and 8:15 a.m. increases 30% during the school year.\n\nYet another impact was an increase in sedentary lifestyles, causing and complicating a national epidemic of obesity, and accompanying dramatically increased health care costs.\n\nCities are shaped by their transport systems. In The City in History, Lewis Mumford documented how the location and layout of cities was shaped around a walkable center, often located near a port or waterway, and with suburbs accessible by animal transport or, later, by rail or tram lines.\n\nIn 1939, the New York World's Fair included a model of an imagined city, built around a car-based transport system. In this \"greater and better world of tomorrow\", residential, commercial and industrial areas were separated, and skyscrapers loomed over a network of urban motorways. These ideas captured the popular imagination, and are credited with influencing city planning from the 1940s to the 1970s.\nThe popularity of the car in the post-war era led to major changes in the structure and function of cities. There was some opposition to these changes at the time. The writings of Jane Jacobs, in particular The Death and Life of Great American Cities provide a poignant reminder of what was lost in this transformation, and a record of community efforts to resist these changes. Lewis Mumford asked \"is the city for cars or for people?\" Donald Appleyard documented the consequences for communities of increasing car traffic in \"The View from the Road\" (1964) and in the UK, Mayer Hillman first published research into the impacts of traffic on child independent mobility in 1971. Despite these notes of caution, trends in car ownership, car use and fuel consumption continued steeply upward throughout the post-war period.\n\nMainstream transport planning in Europe has, by contrast, never been based on assumptions that the private car was the best or only solution for urban mobility. For example, the Dutch Transport Structure Scheme has since the 1970s required that demand for additional vehicle capacity only be met \"if the contribution to societal welfare is positive\", and since 1990 has included an explicit target to halve the rate of growth in vehicle traffic. Some cities outside Europe have also consistently linked transport to sustainability and to land-use planning, notably Curitiba, Brazil, Portland, Oregon and Vancouver, Canada.\nThere are major differences in transport energy consumption between cities; an average U.S. urban dweller uses 24 times more energy annually for private transport than a Chinese urban resident, and almost four times as much as a European urban dweller. These differences cannot be explained by wealth alone but are closely linked to the rates of walking, cycling, and public transport use and to enduring features of the city including urban density and urban design.\nThe cities and nations that have invested most heavily in car-based transport systems are now the least environmentally sustainable, as measured by per capita fossil fuel use. The social and economic sustainability of car-based transportation engineering has also been questioned. Within the United States, residents of sprawling cities make more frequent and longer car trips, while residents of traditional urban neighbourhoods make a similar number of trips, but travel shorter distances and walk, cycle and use transit more often. It has been calculated that New York residents save $19 billion each year simply by owning fewer cars and driving less than the average American. A less car intensive means of urban transport is carsharing, which is becoming popular in North America and Europe, and according to The Economist, carsharing can reduce car ownership at an estimated rate of one rental car replacing 15 owned vehicles. Car sharing has also begun in the developing world, where traffic and urban density is often worse than in developed countries. Companies like Zoom in India, eHi in China, and Carrot in Mexico, are bringing car-sharing to developing countries in an effort to reduce car-related pollution, ameliorate traffic, and expand the number of people who have access to cars.\n\nThe European Commission adopted the Action Plan on urban mobility on 2009-09-30 for sustainable urban mobility. The European Commission will conduct a review of the implementation of the Action Plan in the year 2012, and will assess the need for further action. In 2007, 72% of the European population lived in urban areas, which are key to growth and employment. Cities need efficient transport systems to support their economy and the welfare of their inhabitants. Around 85% of the EU’s GDP is generated in cities. Urban areas face today the challenge of making transport sustainable in environmental (CO, air pollution, noise) and competitiveness (congestion) terms while at the same time addressing social concerns. These range from the need to respond to health problems and demographic trends, fostering economic and social cohesion to taking into account the needs of persons with reduced mobility, families and children.\n\nSustainable transport policies have their greatest impact at the city level. Outside Western Europe, cities which have consistently included sustainability as a key consideration in transport and land use planning include Curitiba, Brazil; Bogota, Colombia; Portland, Oregon; and Vancouver, Canada. The state of Victoria, Australia passed legislation in 2010 – the Transport Integration Act – to compel its transport agencies to actively consider sustainability issues including climate change impacts in transport policy, planning and operations.\n\nMany other cities throughout the world have recognised the need to link sustainability and transport policies, for example by joining Cities for Climate Protection.\nSustainable transport is fundamentally a grassroots movement, albeit one which is now recognised as of citywide, national and international significance.\n\nWhereas it started as a movement driven by environmental concerns, over these last years there has been increased emphasis on social equity and fairness issues, and in particular the need to ensure proper access and services for lower income groups and people with mobility limitations, including the fast-growing population of older citizens. Many of the people exposed to the most vehicle noise, pollution and safety risk have been those who do not own, or cannot drive cars, and those for whom the cost of car ownership causes a severe financial burden.\n\nAn organization called Greenxc started in 2011 created a national awareness campaign in the United States encouraging people to carpool by ride-sharing cross country stopping over at various destinations along the way and documenting their travel through video footage, posts and photography. Ride-sharing reduces individual's carbon footprint by allowing several people to use one car instead of everyone using individual cars.\n\nCar travel increased steadily throughout the twentieth century, but trends since 2000 have been more complex. Oil price rises from 2003 have been linked to a decline in per capita fuel use for private vehicle travel in the USA, Britain and Australia. In 2008, global oil consumption fell by 0.8% overall, with significant declines in consumption in North America, Western Europe, and parts of Asia.\nOther factors affecting a decline in driving, at least in America, include the retirement of Baby Boomers who now drive less, preference for other travel modes (such as transit) by younger age cohorts, the Great Recession, and the rising use of technology (internet, mobile devices) which have made travel less necessary and possibly less attractive.\n\nThe term \"green transport\" is often used as a greenwash marketing technique for products which are not proven to make a positive contribution to environmental sustainability. Such claims can be legally challenged. For instance Norway's consumer ombudsman has targeted automakers who claim that their cars are \"green\", \"clean\" or \"environmentally friendly\". Manufacturers risk fines if they fail to drop the words. The Australian Competition and Consumer Commission (ACCC) describes \"green\" claims on products as \"very vague\", \"inviting consumers to give a wide range of meanings to the claim, which risks misleading them\". In 2008 the ACCC forced a car retailer to stop its \"green\" marketing of Saab cars, which was found by the Australian Federal Court as \"misleading\".\n\nThe EU Directorate-General for Transport and Energy (DG-TREN) has launched a programme which focusses mostly on Urban Transport. Its main measures are:\n\n\n"}
{"id": "8999642", "url": "https://en.wikipedia.org/wiki?curid=8999642", "title": "TN 81", "text": "TN 81\n\nThe French airborne nuclear warheads (TN81) is a thermonuclear warhead carried by the Air-Sol Moyenne Portée (ASMP) medium-range air-to-surface missile, a component of the Force de frappe French nuclear deterrent. The warhead was introduced in 1988. By 1991, 80 warheads had been produced.\n\nDeployment: 60 warheads carried by the ASMP equipping the 60 Mirage 2000 N with the French Air Force and 20 Super Etendard of Naval Aviation. Each TN81 has a declared destructive power of 300 kilotonnes. This amounts to over 20 times the power of the bomb that destroyed Hiroshima on 6 August 1945 and caused some 250 000 deaths then or in the aftermath.\n\nIt has been replaced by 54 TNA (Airborne nuclear warhead) thermonuclear warhead carried by the ASMPA equipping the Mirage 2000 N and Dassault Rafale.\n\nSpecifications: \n"}
{"id": "21592527", "url": "https://en.wikipedia.org/wiki?curid=21592527", "title": "Temperature cycling", "text": "Temperature cycling\n\nTemperature cycling (or temperature cycle) is the process of cycling through two temperature extremes, typically at relatively high rates of change. It is an environmental stress test used in evaluating product reliability as well as in manufacturing to catch early-term, latent defects by inducing failure through thermal fatigue.\n\n"}
{"id": "54065414", "url": "https://en.wikipedia.org/wiki?curid=54065414", "title": "TigerSwan", "text": "TigerSwan\n\nTigerSwan is an international security and global stability firm founded in 2008 by retired U.S. Army lieutenant colonel and Delta Force operator James Reese.\n\nTigerSwan is a Service-Disabled Veteran-Owned Small Business based in Apex, North Carolina. The company operates globally. Founder James Reese served in the elite Delta Force unit. He started his career as an ROTC cadet and served in the United States Army for 25 years. Reese was an adviser, commander and operations officer during the invasions of Afghanistan and Iraq.\n\nThe company has over 300 employees and conducts operations in over 50 countries.\n\nThe TigerSwan firearms training center was located near Cedar Creek in Cumberland County, North Carolina. Since it opened in 2010, the range has offered firearms and tactical training to military, law enforcement and the public. In 2014, Reese sold the training company, and the shooting range changed its name to the Range Complex.\n\nIn the book \"Kill Bin Laden\" Dalton Fury wrote: \"Delta Force legends like Paul Howe of Combat Shooting and Tactics Inc., Larry Vickers of Vickers Tactical Inc., and Brian Searcy of Tiger Swan Inc., and Kyle Lamb of Viking Tactics Inc., can't only teach you how to shoot a gnat off a bull's ass at fifty yards while on the move but they will actually show you how it's done first.\"\n\nThe firm provided security for the Iraqi Mine-Unexploded Ordnance Clearing Organization, a U.S. State Department funded NGO tasked with clearing munitions and mines in Iraq.\n\nDuring the 2014 Sochi Olympics, TigerSwan provided security for members of Olympic committees, corporate sponsors and sports fans traveling to Sochi. They said they could pinpoint a client's location within a 3 foot radius using a GPS device provided to their clients.\n\nTigerSwan was hired by Dakota Access, LLC to provide security consulting during the Dakota Access Pipeline protests. Internal company documents, which were leaked to \"The Intercept\", reportedly compared the movement opposed to the pipeline with jihadis, calling them \"an ideologically driven insurgency with a strong religious component.\" \"The Intercept\" called the DAPL operation a \"multi-faceted private security operation characterized by sweeping and invasive surveillance of protesters,\" and reported that the leaked situation and disinformation reports prepared by the company during the protest provide evidence of aerial surveillance, as well as radio eavesdropping.\n\nThe owner of the Dakota Access Pipeline hired over a half dozen security companies to work with law enforcement officials to protect the pipeline against vandalism, arson, and other acts of eco-terrorism. \"As TigerSwan security employees began to arrive in at the Standing Rock protest site, protesters began showing up in the camps calling for violence and engaging in increasingly menacing rhetoric. The FBI, the Joint Terrorism Task Force, and Bureau of Land Management all participated in the security operation.\"\n\nThe pipeline needed extra security due to arson and other acts of destruction. For example, on July 24, 2017, activists Jessica Reznicek and Ruby Montoya admitted that they were responsible for setting fires to the pipeline and destroying valves. The two referred to their actions as \"peaceful.\" The two women cut through the pipeline with a torch, but at one point torched a hole through a part of the pipeline that had oil in it, which caused oil to spill.\n\nIn 2013 TigerSwan filed a lawsuit against the United States in Federal Court alleging breach of contract due to improper termination. The dispute was over two contracts that were awarded by the Department of Defense for Iraq-based security services. The DoD initially awarded the contracts to TigerSwan, but then terminated the contracts and awarded them instead to the British private military company Aegis Defence Services. The Court denied the government's request to dismiss the case, finding that a contractor does not always need to show specific intent in order to prevail on a claim that alleges bad-faith.\n"}
{"id": "4794899", "url": "https://en.wikipedia.org/wiki?curid=4794899", "title": "Timeline of Olympus creative digital cameras", "text": "Timeline of Olympus creative digital cameras\n\nThis timeline concentrates on the \"creative\" digital camera models from Olympus, i.e. those where there is the possibility to control aperture, shutter speed and focus.\n"}
{"id": "49063779", "url": "https://en.wikipedia.org/wiki?curid=49063779", "title": "Transaction payments as a service", "text": "Transaction payments as a service\n\nTransaction payments as a service (TPaaS) is a phrase used to describe a SaaS-based methodology which allows platforms to become their own merchant platforms and provide merchant services directly. This is distinct from payments as a service which aggregates multiple payment technologies into one platform.\n\nThe TPaaS layer allows organisations to become their own merchant provider, this facilitates functionality that is normally only available to merchant aggregators such as commission splits, merchant of record and instant onboarding.\n\n"}
{"id": "1972705", "url": "https://en.wikipedia.org/wiki?curid=1972705", "title": "Tutte l'opere d'architettura et prospetiva", "text": "Tutte l'opere d'architettura et prospetiva\n\nTutte l'opere d'architettura et prospetiva (\"All the Works of Architecture and Perspective\") is an architectural treatise by Italian Renaissance architect Sebastiano Serlio (1475-1554). Serlio is sometimes regarded as one of the most important. The treatise is composed of eight books, the sixth of which was lost for some centuries and the eighth of which was not published until relatively recently. The eighth book is not always considered to be part of the treatise. The first five books cover Serlio's works on geometry, perspective, Roman antiquity, the Orders and church design. The sixth illustrates domestic designs ranging from peasant huts to royal palaces, providing a unique record of Renaissance house types, including up-to-date fortresses for tyrants and mercenaries as well as Serlio's unbuilt design for the Louvre. The seventh book illustrates a range of common design problems ignored by past theorists, including how to remodel, or 'restore', Gothic façades following antique principles of symmetry and proportion. The eighth book, called \"Castrametation of the Romans\", reconstructs a Roman encampment after the description by Polybius, followed by a military city and monumental bridge supposedly built by the Emperor Trajan. With its forum, consul's palace and baths, the book is part-fantasy and part-archaeology, quite unlike Serlio's other more practical works.\n"}
{"id": "47282412", "url": "https://en.wikipedia.org/wiki?curid=47282412", "title": "Walter Hochschild", "text": "Walter Hochschild\n\nWalter Hochschild (1901 – February 2, 1983) was an American industrialist, having spent 63 years as an executive with the American Metal Company (later AMAX), founded by his father, Berthold Hochschild. He became president of the company in 1950 and chairman and chief executive officer in 1957. He served as a trustee of the Museum of the City of New York for thirty years, and as a lifelong senior trustee of the United States Council of the International Chamber of Commerce. He was a member of the Council on Foreign Relations since 1947.\n\nHe built Eagle Nest camp in Blue Mountain Lake, New York, an Adirondack Great Camp.\n\nHe was married to Kathrin Samstag; they had three daughters: Patricia Hochschild Labalme, Lynn Hochschild Boillot, and Ann Hochschild Poole.\n\n"}
{"id": "58630362", "url": "https://en.wikipedia.org/wiki?curid=58630362", "title": "West Melbourne Gasworks", "text": "West Melbourne Gasworks\n\nThe West Melbourne Gasworks was a coal gasification plant in West Melbourne, Victoria, Australia.\n\nMelbourne was settled in 1835, and by the early 1850s the gold-rushes had led to rapid population growth. The City of Melbourne Gas and Coke Company leased five acres (2 hectares) of Crown Land in 1854, to construct a plant for the gasification of black coal. The works operated until 1962, importing coal via a dedicated wharf and a system of narrow gauge tracks drawn by steam locomotives. Several of these locomotives have been preserved and are now used on the Puffing Billy Railway. \n\nIn 1962, the works was upgraded to incorporate a catalytic oil gas facility, but this was shiort-lived, and in 1970 the works was closed down, and the remaining structures demolished by 1974.\n\nThe works was gradually expanded between 1900 and 1910, eventually covering 8 hectares in an area now extending from Waterview Walk to the Yarra River, with the new Collins Street extension and Harbour Esplanade running through the site. \n"}
{"id": "57596233", "url": "https://en.wikipedia.org/wiki?curid=57596233", "title": "Xiaomi Mi Band 3", "text": "Xiaomi Mi Band 3\n\nThe Xiaomi Mi Band 3 is a wearable activity tracker produced by Xiaomi Inc. It was released on 31 May 2018. It has a capacitive OLED display and claims 5ATM waterproofing. The tracker features heart rate monitoring, although it does not offer continuous heart rate display.\n\n\n"}
