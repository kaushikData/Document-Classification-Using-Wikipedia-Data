{"id": "11172310", "url": "https://en.wikipedia.org/wiki?curid=11172310", "title": "1967 Oil Embargo", "text": "1967 Oil Embargo\n\nThe 1967 Oil Embargo began on June 6, 1967, the second day of the Six-Day War, with a joint Arab decision to deter any countries from supporting Israel militarily. Several Middle Eastern countries eventually limited their oil shipments, some embargoing only the United States and the United Kingdom, while others placed a total ban on oil exports. The Oil Embargo did not significantly decrease the amount of oil available in the United States or any affected European countries, due mainly to a lack of solidarity and uniformity in embargoing specific countries. The embargo was effectively ended on September 1 with the issuance of the Khartoum Resolution.\n\nDuring the June 9–18 Oil Ministers' Conference in Baghdad, Iraq, several Arab countries issued a communiqué that two resolutions were unanimously passed:\n\n\nInvitees included Egypt, Syria, Kuwait, Libya, Saudi Arabia, Algeria, Bahrain, Abu Dhabi, and Qatar. Iraq sent copies of the Council resolution to the Embassies of Iran and Indonesia, and sought the support of Venezuela.\n\nThe Baghdad Resolutions were important because Egypt broadcast claims of US aircraft support on June 6. Iraq was the first country to limit its oil shipments, embargoing the United States and the United Kingdom on June 6. Iraq, Kuwait, Algeria, and Bahrain eventually embargoed the United States and the United Kingdom. Syria stopped all oil exports, rather than just embargoing specific countries, in order to avoid declaring specific nations as aggressors.\n\nThe United States advocated emergency measures in OECD meetings and supported the establishment of an International Industry Advisory Board. The Advisory Board was critical in efficiently apportioning limited tanker resources and managing the distribution of the limited oil resources. This was an effective measure to negate the oil embargo as there was no consensus on what countries to embargo, and more importantly, oil shipped to a European country could then be shipped to any of the embargoed countries. Some Arab countries encouraged the oil companies to circumvent the embargo, as the Amir of Kuwait even proposed to the US ambassador that companies simply alter shipping manifests to ship oil to prohibited countries.\nEgypt sought to bend not only international political policy but also the policies of more moderate governments, and sought to export the socialist revolution to neighboring moderate (i.e. conservative) countries. The embargo resulted in public pressure on Middle Eastern leaders to support Arab solidarity. Nasser effectively limited moderate countries' political options lest they risk a revolution.\n\nThe Khartoum Resolution issued on September 1 allowed the moderate oil-producing nations (Kuwait, Saudi Arabia, and Libya) to resume oil exports and regain this critical source of revenue without risking disquiet or even overthrow from their more radical citizens. In exchange, these countries agreed to give annual aid to \"victims of Zionist aggression\", namely Egypt and Jordan ($266 million and $112 million, respectively).\n\nThe 1967 oil embargo was the main reason for the formation of OAPEC, which would provide a forum for the discussion of using oil politically. The organization's next embargo had a much stronger impact, triggering the oil crisis of 1973–74.\n\n"}
{"id": "852442", "url": "https://en.wikipedia.org/wiki?curid=852442", "title": "ASTM International", "text": "ASTM International\n\nASTM International, formerly known as American Society for Testing and Materials, is an international standards organization that develops and publishes voluntary consensus technical standards for a wide range of materials, products, systems, and services. Some 12,575 ASTM voluntary consensus standards operate globally. The organization's headquarters is in West Conshohocken, Pennsylvania, about northwest of Philadelphia.\n\nFounded in 1898 as the American Section of the International Association for Testing Materials, ASTM International predates other standards organizations such as the BSI (1901), IEC (1906), DIN (1917), ANSI (1918), AFNOR (1926), and ISO (1947).\n\nA group of scientists and engineers, led by Charles Benjamin Dudley formed ASTM in 1898 to address the frequent rail breaks affecting the fast-growing railroad industry. The group developed a standard for the steel used to fabricate rails. Originally called the \"American Society for Testing Materials\" in 1902, it became the \"American Society for Testing and Materials\" in 1961 before it changed its name to “ASTM International” in 2001 and added the tagline \"Standards Worldwide\". In 2014, it has changed the tagline to \"Helping our World Work better\". Now, ASTM International has offices in Belgium, Canada, China, Peru, and Washington, D.C.\n\nMembership in the organization is open to anyone with an interest in its activities. Standards are developed within committees, and new committees are formed as needed, upon request of interested members. Membership in most committees is voluntary and is initiated by the member's own request, not by appointment nor by invitation. Members are classified as users, producers, consumers, and \"general interest\". The latter includes academics and consultants. Users include industry users, who may be producers in the context of other technical committees, and end-users such as consumers. In order to meet the requirements of antitrust laws, producers must constitute less than 50% of every committee or subcommittee, and votes are limited to one per producer company. Because of these restrictions, there can be a substantial waiting-list of producers seeking organizational memberships on the more popular committees. Members can, however, participate without a formal vote and their input will be fully considered.\n\nAs of 2015, ASTM has more than 30,000 members, including over 1,150 organizational members, from more than 140 countries. The members serve on one or more of 140+ ASTM Technical Committees. ASTM International has several awards for contributions to standards authorship, including the ASTM International Award of Merit (the organization's highest award) ASTM International is classified by the United States Internal Revenue Service as a 501(c)(3) nonprofit organization.\n\nASTM International has no role in requiring or enforcing compliance with its standards. The standards, however, may become mandatory when referenced by an external contract, corporation, or government.\n\n\n\n"}
{"id": "9125919", "url": "https://en.wikipedia.org/wiki?curid=9125919", "title": "Abductor wedge", "text": "Abductor wedge\n\nAn abductor wedge is designed to separate the legs of a patient. It is often used after hip surgery to prevent the new hip from \"popping out\".\n\nIt can also be used to support the legs of an individual with spinal cord injury or severe physical or neurological disabilities in abduction (legs apart position) while seated in a wheelchair.\n\n"}
{"id": "4117074", "url": "https://en.wikipedia.org/wiki?curid=4117074", "title": "Acoustic cleaning", "text": "Acoustic cleaning\n\nAcoustic cleaning is a maintenance method used in material-handling and storage systems that handle bulk granular or particulate materials, such as grain elevators, to remove the buildup of material on surfaces. Acoustic cleaning apparatus, usually built into the material-handling equipment, works by generating powerful sound waves which shake particulates loose from surfaces, reducing the need for manual cleaning.\n\nAn acoustic cleaner consists of a sound source similar to an air horn found on trucks and trains, attached to the material-handling equipment, which directs a loud sound into the interior. It is powered by compressed air rather than electricity so there is no danger of sparking, which could set off an explosion. It consists of two parts:\nThe overall length of acoustic cleaner horns range from 430 mm to over 3 metres long. The device can operate from a pressure range of 4.8 to 6.2 bars or 70 to 90 psi. The resultant sound pressure level will be around 200 dB.\n\nThere are generally 4 ways to control the operation of an acoustic cleaner. \n\nAn acoustic cleaner will typically sound for 10 seconds and then wait for a further 500 seconds before sounding again. This ratio for on/off is approximately proportional to the working life of the diaphragm. Provided the operating environment is between −40 C and 100 °C, a diaphragm should last between 3 and 5 years. The wave generator and the bell have a much longer life span and will often outlast the environment in which they operate.\n\nThe older bells which were made from cast iron were susceptible to rusting in certain environments. The new bells made from 316 spun steel have no problem with rust and are ideal for sterile environments such as found in the food industry or in pharmaceutical plants.\n\nAcoustic cleaning began in the early 1970s with experiments using ship horns or air raid sirens. The first acoustic cleaners were made from cast iron. From 1990 onwards the technology became commercially viable and began to be used in dry processing, storage, transport, power generation and manufacturing industries. The latest technology uses 316 spun stainless steel to ensure optimum performance.\n\nThe majority of acoustic cleaners operate in the audio frequency range from 60 hertz up to 420 Hz. However a few operate in the infrasonic range, below 40 Hz, which is mostly below the human hearing range, to satisfy strict noise control requirements.\nThere are three scientific fields which converge in the understanding of acoustic cleaning technology.\nAn acoustic cleaner will create a series of very rapid and powerful sound induced pressure fluctuations which are then transmitted into the solid particles of ash, dust, granules or powder. This causes them to move at differing speeds and debond from adjoining particles and the surface that they are adhering to. Once they have been separated then the material will fall off due to gravity or it will be carried away by the process gas or air stream. \n\nThe key features which determine whether or not an acoustic cleaner will be effective for any given problem are the particle size range, the moisture content and the density of the particles as well as how these characteristics will change with temperature and time.\nTypically particles between 20 micrometres and 5 mm with moisture content below 8.5% are ideal. Upper temperature limits are dependent upon the melting point of the particles and acoustic cleaners have been employed at temperatures above 1000 C to remove ash build-up in boiler plants.\n\nIt is important to match the operating frequencies to the requirements. Higher frequencies can be directed more accurately whilst lower frequencies will carry further, and are generally used for more demanding requirements. A typical selection of frequencies available would be as follows:\n\n\nThe introduction of acoustic cleaners has been a significant improvement in many areas of health and safety. For instance in silo cleaning - the previous solutions tended to be intrusive or destructive. Air cannons, soot blowers, external vibrators, hammering or costly man entry are all superseded by noninvasive sonic horns.\nAn acoustic cleaner requires no down time and will operate during normal usage of the site.\nTaking the example of silo cleaning a little further, there are two typical problems.\n\nThis is when the silo blocks at the outlet. Previously the problem was addressed by manual cleaning from underneath the silo which in its turn introduced significant risk from falling material when the blockage was cleared. An acoustic cleaner is able to operate from the top of a silo through in situ material to clear the blockage at the base.\n\nCompaction on the side of a silo. This not only reduces the operating volume in a silo but it also compromises quality control by disrupting the first in first out cycle. Older material compacted on the side of a silo can also start to degrade and produce dangerous gases. An acoustic cleaner will produce sound waves which will make the compacted material resonate at a different rate to the surrounding environment resulting in debonding and clearance.\n\n\nThese advantages mean that the financial payback is often very quick.\n\nIt is also possible to compare acoustic cleaners directly to alternative solutions.\n\n\n\n\n"}
{"id": "53113460", "url": "https://en.wikipedia.org/wiki?curid=53113460", "title": "Association Française de Mécanique", "text": "Association Française de Mécanique\n\nThe Association française de mécanique (AFM), French Association of Mechanics, was created in 1997 by the union of 17 scientific and engineers societies covering the disciplines of mechanics. It was promoted by the High Mechanical Committee (HCM), with the decisive support of the Federation of Mechanical Industries (FIM), the Technical Center of Mechanical Industries (CETIM) and the University Association in Mechanics (AUM) for the academic part. It is a forum for information, exchange and reflection for the mechanical community: business leaders, engineers, technicians, researchers, professors, mechanical experts. Its main objective is to promote activities and achievements in the main fields of mechanics.\n\nThe AFM's operating mode, through its 19 scientific and technical groups (GST) and Commissions, its transversal thematic groups (GTT), the organization of conferences, congress, publication of newsletters and an indexed international journal Mechanics & Industry, aims at the transfer of knowledge and more particularly promotes the \"transfer of technologies\" from research to industry. It is also meant to represent French mechanics in front of its foreign counterparts. AFM is the referring partner of the French Ministry of Higher Education and Research for all research activities in Mechanics and in close collaboration with the French National Committee of Mechanics (CNFM) which is the link for France with IUTAM (International Union of theoretical and Applied Mechanics).\n\nThe AFM organizes every two years a national conference entitled French Congress of Mechanics gathering more than 1000 participants. It is at the initiative of a \" Livre blanc de la Mécanique \", which identifies the scientific and technological locks remaining to be lifted in the field.\n\nSince 1997, eight presidents have successively headed the association. The current president is Eric Arquis, elected in March 2016.\n"}
{"id": "9478340", "url": "https://en.wikipedia.org/wiki?curid=9478340", "title": "Blast chilling", "text": "Blast chilling\n\nBlast chilling is a method of cooling food quickly to a low temperature that is relatively safe from bacterial growth. Bacteria multiply fastest between +8 °C (46 °F) and +68 °C (154 °F). By reducing the temperature of cooked food from +70 °C (158 °F) to +3 °C (37 °F) or below within 90 minutes, the food is rendered safe for storage and later consumption. This method of preserving food is commonly used in food catering and, recently, in the preparation of 'instant' foods, as it ensures the safety and the quality of the food product.\n\nThe blast chiller is a cousin of the refrigerator, another appliance designed to store food between +3 °C and +5 °C, but the blast chiller is a higher grade and more expensive appliance and is usually only found in commercial kitchens. As of 2013, in the UK, blast chillers are typically priced from GBP 2,000 to GBP 8,000 excluding VAT.\n\nUse of blast chillers is prescribed for the restaurants of the European Union, e.g. in the regulations 852/2004 or 853/2004.\n\n"}
{"id": "54064251", "url": "https://en.wikipedia.org/wiki?curid=54064251", "title": "Burke–Schumann flame", "text": "Burke–Schumann flame\n\nIn combustion, a Burke–Schumann flame is a type of diffusion flame, established at the mouth of the two concentric ducts, by issuing fuel and oxidizer from the two region respectively. It is named after S.P. Burke and T.E.W. Schumann, who were able to predict the flame height and flame shape using their simple analysis of infinitely fast chemistry (which is now called as Burke–Schumann limit) in 1928.\n\nConsider a cylindrical duct with axis along formula_1 direction with radius formula_2 through which fuel is fed from the bottom and the tube mouth is located at formula_3. Oxidizer is fed along the same axis, but in the concentric tube of radius formula_4 outside the fuel tube. Let the mass fraction in the fuel tube be formula_5 and the mass fraction of the oxygen in the outside duct be formula_6. Fuel and oxygen mixing occurs in the region formula_7. The following assumptions were made in the analysis:\n\nConsider a one-step irreversible Arrhenius law, formula_11, where formula_12 is the mass of oxygen required to burn unit mass of fuel and formula_13 is the amount of heat released per unit mass of fuel burned. If formula_14 is the number of moles of fuel burned per unit volume per unit time and introducing the non-dimensional fuel and mass fraction and the Stoichiometry parameter,\n\nthe governing equations for fuel and oxidizer mass fraction reduce to\nwhere Lewis number of both species is assumed to be unity and formula_17 is assumed to be constant, where formula_18 is the thermal diffusivity. The boundary conditions for the problem are\n\nwhere formula_21 is known as the mixture fraction. The mixture fraction takes the value of unity in the fuel stream and zero in the oxidizer stream and it is a scalar field which is not affected by the reaction. The equation satisfied by formula_21 is\n\nIntroducing the following coordinate transformation\n\nreduces the equation to\n\nThe corresponding boundary conditions become\n\nThe equation can be solved by separation of variables\n\nwhere formula_28 and formula_29 are the Bessel function of the first kind and formula_30 is the nth root of formula_31 Solution can also be obtained for the planar ducts instead of the axisymmetric ducts discussed here.\n\nIn the Burke-Schumann limit, the flame is considered as a thin reaction sheet outside which both fuel and oxygen cannot exist together, i.e., formula_32. The reaction sheet itself is located by the stoichiometric surface where formula_33, in other words, where\n\nwhere formula_35 is the stoichiometric mixture fraction. Therefore, for given values of formula_36 and formula_37, the flame shape formula_38 is determined by the following equation\n\nThe reaction sheet separates fuel and oxidizer region. On the fuel side of the reaction sheet formula_40 and on the oxidizer side formula_41 When formula_42, the flame extends from the mouth of the inner tube to some height at the outer tube (under-ventilated case) and when formula_43, the flame starts from the mouth of the inner tube and joins at the axis at some height away from the mouth (over-ventilated case). Similar results are obtained when formula_44. The flame height can be estimated approximately by keeping only the first term of the series (it give accurate results because it appears in the exponential) by setting formula_45 for the over-ventilated case and formula_46 for the under-ventilated case. This approximation predicts the flame height to be\n\nwhere formula_48 The inner structure of the reaction sheet is described by Liñán's equation.\n"}
{"id": "23463243", "url": "https://en.wikipedia.org/wiki?curid=23463243", "title": "CBERS-2", "text": "CBERS-2\n\nChina–Brazil Earth Resources Satellite 2 (CBERS-2), also known as Ziyuan I-02 or Ziyuan 1B, was a remote sensing satellite operated as part of the China–Brazil Earth Resources Satellite programme between the China Centre for Resources Satellite Data and Application and Brazil's National Institute for Space Research. The second CBERS satellite to fly, it was launched by China in 2003 to replace CBERS-1.\n\nCBERS-2 was a spacecraft built by the China Academy of Space Technology and based on the Phoenix-Eye 1 satellite bus. The spacecraft was powered by a single solar array, which provided 1,100 watts of electricity for the satellite's systems. The instrument suite aboard the CBERS-2 spacecraft consisted of three systems: the Wide Field Imager (WFI) produced visible-light to near-infrared images with a resolution of and a swath width of ; a high-resolution CCD camera was used for multispectral imaging at a resolution of with a swath width of ; the third instrument, the Infrared Multispectral Scanner (IMS), had a resolution of and a swath width of .\n\nA Chang Zheng 4B carrier rocket, operated by the China Academy of Launch Vehicle Technology, was used to launch CBERS-2. The launch took place at 03:16 UTC on 21 October 2003, using Launch Complex 7 at the Taiyuan Satellite Launch Centre. The satellite was successfully placed into a sun-synchronous orbit.\n\nFollowing the launch of CBERS-2B in 2007, CBERS-2 was retired from service. As of 1 December 2013, the dericict satellite remains in orbit, with a perigee of , an apogee of , 98.17 degrees inclination and a period of 100.33 minutes. Its orbit has a semimajor axis of , and eccentricity of 0.0001886.\n"}
{"id": "50421011", "url": "https://en.wikipedia.org/wiki?curid=50421011", "title": "Clock Software", "text": "Clock Software\n\nClock Software is a private limited company developing software and hardware solutions for the hospitality industry - property management system, restaurant point of sale, online booking engine, channel manager, self-service kiosk, mobile hotel app. Its headquarters is in London, UK.\n\nClock Software was incorporated in 1994 in Varna, Bulgaria, under the name Clock Ltd (Клок ООД). Initially, the company specialized in selling hardware and peripherals but soon switched its focus to the development of hotel software. In 1996 Clock launched their first property management system - ClockFront for Windows. At the time, a huge privatisation was going on as part of the transition of the country to democracy and market economy. All hotels, previously owned by the state, were changing ownership and needed new software to replace previous, often centralised, management systems. Clock Software took the chance to offer their software to the newly privatised hotels.\n\nIn 2006 Clock Software started to expand to countries outside Bulgaria and opened offices in Romania (2007) and Croatia (2008). The first markets where their products were adopted were Romania, Macedonia and Croatia.\n\nIn 2010 Clock took the decision to create a completely new hospitality software suite based on cloud technology. The new product was built around the idea of consolidation of separate applications into one cloud-based platform and switching from data-focused to guest-centered software model. A new branch was registered in London, UK under the name of Clock Software Ltd. to take over the international development and the distribution of the cloud-based software products, while the Bulgarian branch remained in charge of software development and support.\nClock Software launched their first cloud product, the free Internet reservation system InnHand, in 2012. In 2013 they launched the hotel management platform Clock PMS. A year later InnHand was discontinued and the company focused entirely on the new system. In 2016, the company released their first hardware device, a self-service kiosk.\n\nIts Windows-based installable software solutions Clock Software offers in Eastern Europe, while the latest cloud-based hotel management platform, Clock PMS, is available globally. Clock PMS has customers in 50+ countries (as of end of 2016) with Lark Hotels and McMillan Hotels among them. In 2015 Clock PMS was featured in the annual report by Software Advice \"Hotel Software User View report - 2015\" and in 2016 Clock Software was included in the Grant Thornton's report \"Emerging clouds in hotel technology | Spotlight on cloud-based PMS\" \n\nClock PMS is a property management system delivered as SaaS. It is hosted on Amazon Web Services (AWS) and is a certified partner of various third party providers: payment gateways - PayPal, Authorize.Net, Worldpay, Adyen; channel managers - RoomCloud and Yield Planet; door lock systems - ASSA ABLOY, hotel meta search websites - TripConnect by Tripadvisor\n\nClock PMS is a cloud based suite of software solutions for hotels, chains, vacation rentals and other accommodation providers. It includes the following modules:\nClock EVO - Property management system for Windows\nClock POSitive - Point of Sale system for Windows\nClock Effect - Inventory management system for Windows\n\n"}
{"id": "25717385", "url": "https://en.wikipedia.org/wiki?curid=25717385", "title": "Constrained-layer damping", "text": "Constrained-layer damping\n\nConstrained-layer damping is a mechanical engineering technique for suppression of vibration. Typically a viscoelastic or other damping material, is sandwiched between two sheets of stiff materials that lack sufficient damping by themselves. The ending result is, any vibration made on either side of the constraining materials (the two stiffer materials on the sides) are trapped and evidently dissipated in the viscoelastic or middle layer.\n\nPassive Viscoelastic Constrained Layer Damping Application for a Small Aircraft Landing Gear System An engineering Master's thesis\n"}
{"id": "37848311", "url": "https://en.wikipedia.org/wiki?curid=37848311", "title": "Craster kipper", "text": "Craster kipper\n\nCraster kippers are kippers from the Northumberland village of Craster. They have been acclaimed as the best British kipper.\n\nLike the Newmarket sausage or the Stornoway black pudding, the Craster kipper (sometimes called by aficionados simply \"the Craster\"\n) is a British food named after, and strongly associated with, its place of origin. Although the herrings used for Craster kippers may not be strictly local, the defining characteristic of the Craster kipper is that the smoking process takes place in a smokehouse located in or around the village of Craster.\n\nClarissa Dickson Wright has named Craster as the birthplace of the kipper. There is. however. some dispute over this – other places, including the nearby town of Seahouses, also claim this distinction.\n\nAlthough a long-standing tradition in Craster, commercial kipper production is currently only continued there by L. Robson & Sons, using their 100-year-old smokehouses.\n\nThe preparation process begins with selected raw North Sea herrings, known locally as \"silver darlings\". These are split, gutted and washed, soaked in brine, and then taken to the smokehouse where they are cured over smouldering oak and white wood shavings for sixteen hours. The famous smokehouse is unmistakable — a stone building often with white plumes pouring out of the wooden vents in the roof.\n\nIn appearance a Craster kipper is still recognizably a fish; the head is preserved and the natural colours of the skin are tanned golden by the oak smoke. The flesh has a distinctive reddish-brown colour.\n\nIt has been said that comparing the Craster kipper with a common commercial processed kipper is like \"comparing a fillet steak with a cheap burger\", and that \"on the tongue, the [Craster] kipper is as delicate, as sophisticated, as the finest smoked salmon in the world and costs but a fraction of the price.\"\n\nCraster kippers have been described as \"the best\", although that claim has also been made of other British kippers such as Loch Fyne kippers.\n\n\n"}
{"id": "23542335", "url": "https://en.wikipedia.org/wiki?curid=23542335", "title": "Cryogenic oxygen plant", "text": "Cryogenic oxygen plant\n\nA cryogenic oxygen plant is an industrial facility that creates molecular oxygen at relatively high purity. Oxygen is the most common element in the earth's crust and the second largest industrial gas. This process was pioneered by Dr. Carl von Linde in 1902.\nThe cryogenic air separation achieves high purity oxygen of more than 99.5%. The resulting high purity product can be stored as a liquid and/or filled into cylinders. These cylinders can even be distributed to customer in the medical sector, welding or mixed with other gases and used as breathing gas for diving.\nTypical production ranges from 50 normal m/hour up to 860,000 Nm/hour (Ras Laffan refinery).\n\nA cryogenic oxygen plant comprises:\n\n\n\n\nAtmospheric air is roughly filtered and pressurised by a compressor, which provides the product pressure to deliver to the customer. The amount of air sucked in depends on the customer’s oxygen demand.\n\nThe air receiver collects condensate and minimises pressure drop. The dry and compressed air leaves the air to refrigerant heat exchanger with about 10°C.\n\nTo clean the process air further, there are different stages of filtration. First of all, more condensate is removed, then a coalescing filter acts as a gravity filter and finally an adsorber filled with activated carbon removes some hydrocarbons.\n\nThe last unit process in the warm end container is the thermal swing adsorber (TSA). The Air purification unit cleans the compressed process air by removing any residual water vapour, carbon dioxide and hydrocarbons. It comprises two vessels, valves and exhaust to allow the changeover of vessels. While one of the TSA beds is on stream the second one is regenerated by the waste gas flow, which is vented through a silencer into the ambient environment.\n\nThe process air enters the main heat exchanger in the coldbox where it is cooled in counter flow with the waste gas stream. After leaving the main heat exchanger the process air has a temperature of about –112°C and is partly liquefied. The complete liquefaction is achieved through evaporation of cooled liquid oxygen in the boiler. After passing a purity control valve process air enters on tip of the distillation column and flows down through the packing material.\n\nThe steam of evaporated oxygen vapour in the shell of the boiler vents back into the distillation column. It rises through the column packing material and encounters the descending stream of liquid process air.\n\nThe liquid air descending down the column loses nitrogen. It becomes richer in oxygen and collects at the base of the column as pure liquid oxygen. It flows out into the boiler to the cold box liquid product valve. An on-line oxygen analyser controls the opening of the liquid product valve to transfer pure low-pressure liquid oxygen into the storage tank.\n\nThe rising oxygen vapour becomes rich in nitrogen and argon. It leaves the column and exits the cold box at ambient temperature through the main heat exchanger as a waste gas. This waste gas provides purge gas to regenerate the TSA unit and to the cool the refrigeration turbine.\n\nTurbines located at the base of the cold box provide refrigeration for the process. A stream of high-pressure gas from the main heat exchangers is cooled and expanded to low pressure in the turbine. This cold air returns to the waste stream of the heat exchanger to inject refrigeration.\nEnergy removed by the turbine re-appears as heat in the turbine’s closed-cycle air-brake circuit. This heat is removed in an air-to-air cooler by waste gas from the cold box.\n\nLiquid from the tank is compressed to high pressure in a cryogenic liquid pump. It is then vaporised in an ambient air evaporator to produce gaseous oxygen. The high-pressure gas then can pass into cylinders via the gas manifold or fed into a customers product pipeline.\n\n\n"}
{"id": "5895924", "url": "https://en.wikipedia.org/wiki?curid=5895924", "title": "Decorative box", "text": "Decorative box\n\nA decorative box is a form of packaging that is generally more than just functional, but also intended to be decorative and artistic. Many such boxes are used for promotional packaging, both commercially and privately. Historical objects are usually called caskets if larger than a few inches in more than one dimension, with only smaller ones called boxes.\n\nTraditionally gift boxes used for promotional and seasonal gifts are made from sturdy paperboard or corrugated fiberboard. These boxes normally consist of a base and detachable lid and are made by using a die cutting process to cut the board. The box is then covered with decorative paper. Gift boxes can be dressed with other gift packaging material, such as decorative ribbons and gift tissue paper.\n\nThe most common type of decorative box is the feminine work box. It is usually fitted with a tray divided into many small compartments for needles, reels of silk and cotton, and other necessaries for stitchery. The date of its origin is unclear, but 17th-century examples exist, covered with silk and adorned with beads and embroidery.\n\nNo lady would have been without her work box in the 18th century. In the second half of that century, elaborate pains were taken to make these boxes dainty and elegant.\n\nWork boxes are ordinarily portable, but at times they form the top of a stationary table.\n\nA jewelry box, also known as a casket, is a receptacle for trinkets, not only jewels. It may take a very modest form, covered in leather and lined with satin, or it may reach the monumental proportions of the jewel cabinets which were made for Marie Antoinette, one of which is at Windsor Castle, and another at the Palace of Versailles; the work of Schwerdfeger as cabinetmaker, Degault as miniature-painter, and Thomire as chaser.\n\nSnuff boxes are made in two sizes, ones for the pocket and communal boxes made for table use. Pocket boxes are usually made to hold a small amount of snuff for immediate consumption. High-quality boxes have tightly-sealed lids to ensure that air does not penetrate the box, although wholly air-tight boxes are a rarity. Pocket boxes are intended keep a day or two's supply. Table boxes are still to be found in the mess of certain old regiments – often in the traditional 'ram's head' style – and a communal snuff box is kept in the House of Lords in the UK parliament.\n\nPeople of all social classes used these boxes when snuff was at its peak of popularity and the wealthy carried a variety of fancy snuff-boxes created by craftsmen in metal-work, jewellers and enamellers. Some of these were elaborately made and decorated, rich in detail and made from precious or expensive materials such as gold, silver and ivory and were often adorned with artwork, gems and precious stones. Boxes made for the poorer snuff taker were more ordinary; popular and cheap boxes were made in papier-mâché and even potato-pulp, which made durable boxes that kept the snuff in good condition. Alloys that resembled gold or silver were developed in the 18th and 19th centuries such as the \"ersatz\" gold Pinchbeck and the silver look-alike, Sheffield Plate.\n\nOther popular materials used in making these boxes include:\nThe lids were often adorned with a portrait, a classical vignette, portrait miniature, hardstone inlays, or micromosaic panel. Some of the most expensive just used subtly different colours of gold. Perhaps the most widely used semi-precious metal was silver and snuffs of all shapes and sizes were made in that metal during snuff's great popularity.\n\nEven after snuff-taking ceased to be a general habit, the practice lingered among diplomats, doctors, lawyers and other professionals as well as members of professions where smoking was not possible, such as miners and print workers and snuff still has a considerable following, particularly amongst ex-smokers. Monarchs retained the habit of bestowing snuff-boxes upon ambassadors and other intermediaries as a form of honor. As Talleyrand explained, the diplomatic corps found a ceremonious pinch to be a useful aid to reflection in a business interview. At the coronation of George IV of England, Messrs. Rundell and Bridge, the court jewellers, were paid £8,205 for snuff-boxes for gifts to foreign representatives.\n\nToday snuffboxes are collected at many levels – the high-end of the market being reserved for gold boxes that have been jewelled or have original art work on them, or boxes with provenance linking them to world figures, such as Napoleon or Lord Nelson. Some of the most expensive are French and German 18th century examples, and the record auction price for a German box is £789,250 (about US$1.3 million), bid in 2003 at Christie's in London.\n\nModern snuff boxes are made from a variety of woods, pewter and even plastic and are manufactured in surprising numbers due, largely, to snuff's resurgence amongst tobacco connoisseurs and ex-smokers.\n\nA strong-box is a receptacle for money, deeds and securities. Its place has been taken in modern life by the safe. Some have extremely elaborate locks, such as Sir Thomas Bodley's strong-box in the Bodleian library, which has a locking mechanism in the under-side of the lid.\n\nIn the Middle Ages people usually brought their own cutlery with them when eating away from home, and the more expensive types came with their own custom-made leather cases, stamped and embossed in various designs. Later, as cutlery became provided by the host, decorative cases, especially for the knives, were often left on display in the dining-room. Some of the most elegant and often ornate were in the styles of Robert Adam, George Hepplewhite and Thomas Sheraton. Occasionally flat-topped containers, they were most frequently either rod-shaped, or tall and narrow with a sloping top necessitated by a series of raised veins for exhibiting the handles of knives and the bowls of spoons. Mahogany and satinwoods were most common, occasionally inlaid with marquetry, or edged with boxwood which was resistant to chipping. These receptacles, often made in pairs, still exist in large numbers; they are often converted into stationery cabinets. Another version is an open tray or rack, usually with a handle, also for the storage of table cutlery.\n\nA Bible box is a box made to hold a Bible. These boxes started being manufactured in the 17th century.\n\nAn (from the French, for keeper or holder) is a woman's ornamental case, usually carried in a pocket or purse. It holds small tools for daily use such as folding scissors, bodkins, sewing needles (a needlecase), hairpins, tweezers, makeup pencils, etc. Some étuis were also used to carry doctors' lancets. These boxes were made of different materials such as wood, leather, ivory, silver,  gold, tortoise shell, mother of pearl, and shagreen. Fabergé created the Necessaire Egg as an étui.\n\nWooden wine boxes, also known as wooden wine crates, are used to ship and store expensive wines in transit and cellarage. Most wineries that use wooden boxes burn their logo and designs on the front panel. Originally intended as purely practical items, these panels or the whole box are often used by bars or wine collectors as decorative pieces for their bars or wine cellars. A typical wooden wine box holds either six or twelve 750 ml bottles.\n\n"}
{"id": "10390862", "url": "https://en.wikipedia.org/wiki?curid=10390862", "title": "Delete character", "text": "Delete character\n\nIn computing, the delete character (sometimes also called rubout) is the last character in the ASCII repertoire, with the code 127 (decimal). Not a graphic character but a control character, it is denoted as codice_1 in caret notation and has a graphic representation of ␡ in Unicode (as all ASCII control characters have graphic representations).\n\nOn modern systems terminal emulators typically turn keys marked \"Delete\" or \"Del\" into an escape sequence such as codice_2. Terminal emulators may produce DEL when key or + or + are typed, and some programs such as [[Microsoft Notepad|Notepad]] may insert this character with the same key presses.\n\nThis code was originally used to mark deleted characters on [[punched tape]], since any character could be changed to all ones by punching holes everywhere. If a character was punched erroneously, punching out all seven bits caused this position to be ignored or deleted, a computer version of [[correction fluid]]. In [[hexadecimal]], this is 7F to rubout 7 bits, and [[Eight Ones|FF to rubout 8 bits]]. For teleprinters like the [[Teletype Model 33]], lines were commonly ended by the three characters [[carriage return|CR]], [[line feed|LF]], and rubout, with the rubout allowing time for the print mechanism to physically move to the left margin. On [[VT100]] compatible terminals, this is the character generated by the key labeled Delete, which transmits a delete character (octal 177, hexadecimal 7F) to the host system. On [[VT510]] compatible terminals, this is the character generated by the key labeled ?, usually called backspace on modern machines, and does not correspond to the PC \"Delete\" key.\n\n[[Unix-like]] operating systems are known to use it as [[stty|]] control character, i.e. to delete the previous character in the [[line mode]]. This, though, differs from its original function where this code replaced (physically) characters on a punched tape to be deleted.\n\n[[DOS]]/[[Microsoft Windows|Windows]] never used this character in any way, using the [[backspace]] (0x08, or control-H) to delete the previous character. [[VGA-compatible text mode|EGA/VGA fonts]], as fonts used by [[Win32 console]], usually have the [[Miscellaneous Technical (Unicode block)|\"house\" symbol]] ⌂ at 127 (0x7F) code point, see [[Code page 437]] for details. However, its legacy can be seen in some applications distributed as part of the Windows operating system: as an example, typing the and key combination in [[Microsoft Notepad]] will output the delete character.\n\n\n[[Category:Control characters]]\n[[Category:Text user interface]]\n[[Category:History of computing]]"}
{"id": "10710154", "url": "https://en.wikipedia.org/wiki?curid=10710154", "title": "Design rationale", "text": "Design rationale\n\nA design rationale is an explicit documentation of the reasons behind decisions made when designing a system or artifact. As initially developed by W.R. Kunz and Horst Rittel, design rationale seeks to provide argumentation-based structure to the political, collaborative process of addressing wicked problems.\n\nA design rationale is the explicit listing of decisions made during a design process, and the reasons why those decisions were made. Its primary goal is to support designers by providing a means to record and communicate the argumentation and reasoning behind the design process. \nIt should therefore include:\n\nSeveral science areas are involved in the study of design rationales, such as computer science cognitive science, artificial intelligence, and knowledge management. For supporting design rationale, various frameworks have been proposed, such as QOC, DRCS, IBIS, and DRL.\n\nWhile argumentation formats can be traced back to Stephen Toulmin's work in the 1950s datums, claims, warrants, backings and rebuttals, the origin of design rationale can be traced back to W.R. Kunz and Horst Rittel's development of the Issue-Based Information System (IBIS) notation in 1970. Several variants on IBIS have since been proposed.\n\n\nThe first Rationale Management System (RMS) was PROTOCOL, which supported PHI, which was followed by other PHI-based systems MIKROPOLIS and PHIDIAS. The first system providing IBIS support was 's STIEC. Rittel developed a small system in 1983 (also not published) and the better known gIBIS (graphical IBIS) was developed in 1987.\n\nNot all successful DR approaches involve structured argumentation. For example, Carroll and Rosson's Scenario-Claims Analysis approach captures rationale in scenarios that describe how the system is used and how well the system features support the user goals. Carroll and Rosson's approach to design rationale is intended to help designers of computer software and hardware identify underlying design tradeoffs and make inferences about the impact of potential design interventions.\n\nThere are a number of ways to characterize DR approaches. Some key distinguishing features are how it is captured, how it is represented, and how it can be used.\n\n\"Rationale capture\" is the process of acquiring rationale information to a rationale management\n\n\nThe choice of design rationale representation is very important to make sure that the rationales we capture is what we desire and we can use efficiently. According to the degree of formality, the approaches that are used to represent design rationale can be divided into three main categories: informal, semiformal, or formal. In the informal representation, rationales can be recorded and captured by just using our traditionally accepted methods and media, such as word processors, audio and video records or even hand writings. However, these descriptions make it hard for automatic interpretation or other computer-based supports. In the formal representation, the rationale must be collected under a strict format so that the rationale can be interpreted and understood by computers. However, due to the strict format of rationale defined by formal representations, the contents can hardly be understood by human being and the process of capturing design rationale will require more efforts to finish, and therefore becomes more intrusive.\n\nSemiformal representations try to combine the advantages of informal and formal representations. On one hand, the information captured should be able to be processed by computers so that more computer based support can be provided. On the other hand, the procedure and method used to capture information of design rationale should not be very intrusive. In the system with a semiformal representation, the information expected is suggested and the users can capture rationale by following the instructions to either fill out the attributes according to some templates or just type into natural language descriptions.\n\n\n\n\n\n\n\n\n\nDesign rationale has the potential to be used in many different ways. One set of uses, defined by Burge and Brown (1998), are:\n\nDR is used by research communities in software engineering, mechanical design, artificial intelligence, civil engineering, and human-computer interaction research. In software engineering, it could be used to support the designers ideas during requirement analysis, capturing and documenting design meetings and predicting possible issues due to new design approach. In software architecture and outcourcing solution design, it can justify the outcome of architectural decisions and serve as a design guide.\nIn civil engineering, it helps to coordinate the variety of work that the designers do at the same time in different areas of a construction project. It also help the designers to understand and respect each other's ideas and resolve any possible issues.\n\nThe DR can also be used by the project managers to maintain their project plan and the project status up to date. Also, the project team members who missed a design meeting can refer back the DR to learn what was discussed on a particular topic. The unresolved issues captured in DR could be used to organize further meetings on those topics.\nDesign rationale helps the designers to avoid the same mistakes made in the previous design. This can also be helpful to avoid duplication of work. In some cases DR could save time and money when a software system is upgraded from its previous versions.\n\nThere are several books and articles that provide excellent surveys of rationale approaches applied to HCI, Engineering Design and Software Engineering.\n\n\n\n\n\n"}
{"id": "33465220", "url": "https://en.wikipedia.org/wiki?curid=33465220", "title": "Destoner", "text": "Destoner\n\nA destoner is a machine that removes stones and clods from soil ridges and moves them to the furrow so that the ridges are free from stones. This also helps when harvesting in wet conditions as the harvester can drive on a row of stones which helps improve traction.\n\nThey remove stone using a series of webs (between two and five webs). The stones stay on the web and the clay falls through it. The stones travel through the machine and the bigger stones fall into a boulder box and the smaller stones fall onto a cross conveyor and in turn fall into a trench. On the next pass the tractor tramps these stones down.\n\nDestoners are usually fitted with steerable wheels which makes them more maneuverable on headlands. Some are fitted with hydraulic leveling.\n"}
{"id": "8324", "url": "https://en.wikipedia.org/wiki?curid=8324", "title": "Difference engine", "text": "Difference engine\n\nA difference engine created by Charles Babbage is an automatic mechanical calculator designed to tabulate polynomial functions. Its name is derived from the method of divided differences, a way to interpolate or tabulate functions by using a small set of polynomial coefficients. Most mathematical functions commonly used by engineers, scientists and navigators, including logarithmic and trigonometric functions, can be approximated by polynomials, so a difference engine can compute many useful tables of numbers.\n\nThe historical difficulty in producing error-free tables by teams of mathematicians and human \"computers\" spurred Charles Babbage's desire to build a mechanism to automate the process.\n\nThe notion of a mechanical calculator for mathematical functions can be traced back to the Antikythera mechanism of the 2nd century BC, while early modern examples are attributed to Pascal and Leibniz in the 17th century. \nIn 1784 J. H. Müller, an engineer in the Hessian army, devised and built an adding machine and described the basic principles of a difference machine in a book published in 1786 (the first written reference to a difference machine is dated to 1784), but he was unable to obtain funding to progress with the idea.\n\nCharles Babbage began to construct a small difference engine in c. 1819 and had completed it by 1822 (Difference Engine 0). He announced his invention on June 14, 1822, in a paper to the Royal Astronomical Society, entitled \"Note on the application of machinery to the computation of astronomical and mathematical tables\". This machine used the decimal number system and was powered by cranking a handle. The British government was interested, since producing tables was time-consuming and expensive and they hoped the difference engine would make the task more economical.\n\nIn 1823, the British government gave Babbage £1700 to start work on the project. Although Babbage's design was feasible, the metalworking techniques of the era could not economically make parts in the precision and quantity required. Thus the implementation proved to be much more expensive and doubtful of success than the government's initial estimate. In 1832, Babbage and Joseph Clement produced a small working model (1/7 of the calculating section of Difference Engine No. 1, which was intended to operate on 20-digit numbers and sixth-order differences) which operated on 6-digit numbers and second-order differences. Lady Byron described seeing the working prototype in 1833: \"We both went to see the thinking machine (for so it seems) last Monday. It raised several Nos. to the 2nd and 3rd powers, and extracted the root of a Quadratic equation.\" Work on the larger engine was suspended in 1833.\n\nBy the time the government abandoned the project in 1842, Babbage had received and spent over £17,000 on development, which still fell short of achieving a working engine. The government valued only the machine's output (economically produced tables), not the development (at unknown and unpredictable cost to complete) of the machine itself. Babbage did not, or was unwilling to, recognize that predicament. Meanwhile, Babbage's attention had moved on to developing an analytical engine, further undermining the government’s confidence in the eventual success of the difference engine. By improving the concept as an analytical engine, Babbage had made the difference engine concept obsolete, and the project to implement it an utter failure in the view of the government.\n\nThe incomplete Difference Engine No. 1 was put on display to the public at the 1862 International Exhibition in South Kensington, London.\n\nBabbage went on to design his much more general analytical engine, but later produced an improved \"Difference Engine No. 2\" design (31-digit numbers and seventh-order differences), between 1846 and 1849. Babbage was able to take advantage of ideas developed for the analytical engine to make the new difference engine calculate more quickly while using fewer parts.\n\nInspired by Babbage's difference engine in 1834, Per Georg Scheutz built several experimental models. In 1837 his son Edward proposed to construct a working model in metal, and in 1840 finished the calculating part, capable of calculating series with 5-digit numbers and first-order differences, which was later extended to third-order (1842). In 1843, after adding the printing part, the model was completed.\n\nIn 1851, funded by the government, construction of the larger and improved (15-digit numbers and fourth-order differences) machine began, and finished in 1853. The machine was demonstrated at the World's Fair in Paris, 1855 and then sold in 1856 to the Dudley Observatory in Albany, New York (delivered in 1857). In 1857 British government ordered next Scheutz's difference machine, which was built in 1859. It had the same basic construction as the previous one. Weighed about .\n\nMartin Wiberg improved Scheutz's construction (c. 1859, his machine has the same capacity as Scheutz's - 15-digit and fourth-order) but used his device only for producing and publishing printed tables (interest tables in 1860, and logarithmic tables in 1875).\n\nAlfred Deacon of London in c. 1862 produced a small difference engine (20-digit numbers and third-order differences).\n\nAmerican George B. Grant started working on his calculating machine in 1869, unaware of the works of Babbage and Scheutz (Schentz). One year later (1870) he learned about difference engines and proceed to design one himself, describing his construction in 1871. In 1874 the Boston Thursday Club raised a subscription for the construction of a large-scale model, which was built in 1876. It could be expanded to enhance precision, weighed about .\n\nChristel Hamann built one machine (16-digit numbers and second-order differences) in 1909 for the \"Tables of Bauschinger and Peters\" (\"Logarithmic-Trigonometrical Tables with eight decimal places\"), which was first published in Leipzig in 1910. Weighed about .\n\nBurroughs Corporation in about 1912 built a machine for Nautical Almanac Office which was used as a difference engine of second-order. It was later replaced in 1929 by a Burroughs Class 11 (13-digit numbers and second-order differences, or 11-digit numbers and <nowiki>[at least up to]</nowiki> fifth-order differences).\n\nAlexander John Thompson about 1927 built \"integrating and differencing machine\" (13-digit numbers and fifth-order differences) for his table of logarithms \"Logarithmetica britannica\". This machine was composed of four modified Triumphator calculators.\n\nLeslie Comrie in 1928 described how to use the Brunsviga-Dupla calculating machine as a difference engine of second-order (15-digit numbers). He also noted in 1931 that National Accounting Machine Class 3000 could be used as a difference engine of sixth-order.\n\nDuring the 1980s, Allan G. Bromley, an associate professor at the University of Sydney, Australia, studied Babbage's original drawings for the Difference and Analytical Engines at the Science Museum library in London. This work led the Science Museum to construct a working calculating section of difference engine No. 2 from 1985 to 1991, under Doron Swade, the then Curator of Computing. This was to celebrate the 200th anniversary of Babbage's birth in 1999. In 2002, the printer which Babbage originally designed for the difference engine was also completed. The conversion of the original design drawings into drawings suitable for engineering manufacturers' use revealed some minor errors in Babbage's design (possibly introduced as a protection in case the plans were stolen), which had to be corrected. Once completed, both the engine and its printer worked flawlessly, and still do. The difference engine and printer were constructed to tolerances achievable with 19th-century technology, resolving a long-standing debate as to whether Babbage's design would actually have worked. (One of the reasons formerly advanced for the non-completion of Babbage's engines had been that engineering methods were insufficiently developed in the Victorian era.)\n\nThe printer's primary purpose is to produce stereotype plates for use in printing presses, which it does by pressing type into soft plaster to create a flong. Babbage intended that the Engine's results be conveyed directly to mass printing, having recognized that many errors in previous tables were not the result of human calculating mistakes but from error in the manual typesetting process. The printer's paper output is mainly a means of checking the Engine's performance.\n\nIn addition to funding the construction of the output mechanism for the Science Museum's Difference Engine No. 2, Nathan Myhrvold commissioned the construction of a second complete Difference Engine No. 2, which was on exhibit at the Computer History Museum in Mountain View, California from 10 May 2008 until 31 January 2016.\nIt has since been transferred to Intellectual Ventures in Seattle where it is on display just outside the main lobby.\n\nThe difference engine consists of a number of columns, numbered from 1 to N. The machine is able to store one decimal number in each column. The machine can only add the value of a column \"n\" + 1 to column \"n\" to produce the new value of \"n\". Column \"N\" can only store a constant, column 1 displays (and possibly prints) the value of the calculation on the current iteration.\n\nThe engine is programmed by setting initial values to the columns. Column 1 is set to the value of the polynomial at the start of computation. Column 2 is set to a value derived from the first and higher derivatives of the polynomial at the same value of X. Each of the columns from 3 to \"N\" is set to a value derived from the formula_1 first and higher derivatives of the polynomial.\n\nIn the Babbage design, one iteration (i.e., one full set of addition and carry operations) happens for each rotation of the main shaft. Odd and even columns alternately perform an addition in one cycle. The sequence of operations for column formula_2 is thus:\n\n\nSteps 1,2,3,4 occur for every odd column, while steps 3,4,1,2 occur for every even column.\n\nWhile Babbage's original design placed the crank directly on the main shaft, it was later realized that the force required to crank the machine would have been too great for a human to handle comfortably. Therefore, the two models that were built incorporate a 4:1 reduction gear at the crank, and four revolutions of the crank are required to perform one full cycle.\n\nEach iteration creates a new result, and is accomplished in four steps corresponding to four complete turns of the handle shown at the far right in the picture below. The four steps are:\n\n\nThe engine represents negative numbers as ten's complements. Subtraction amounts to addition of a negative number. This works in the same manner that modern computers perform subtraction, known as two's complement.\n\nThe principle of a difference engine is Newton's method of divided differences. If the initial value of a polynomial (and of its finite differences) is calculated by some means for some value of X, the difference engine can calculate any number of nearby values, using the method generally known as the method of finite differences. For example, consider the quadratic polynomial\n\nwith the goal of tabulating the values \"p\"(0), \"p\"(1), \"p\"(2), \"p\"(3), \"p\"(4), and so forth. The table below is constructed as follows: the second column contains the values of the polynomial, the third column contains the differences of the two left neighbors in the second column, and the fourth column contains the differences of the two neighbors in the third column:\n\nThe numbers in the third values-column are constant. In fact, by starting with any polynomial of degree \"n\", the column number \"n\" + 1 will always be constant. This is the crucial fact behind the success of the method.\n\nThis table was built from left to right, but it is possible to continue building it from right to left down a diagonal in order to compute more values. To calculate \"p\"(5) use the values from the lowest diagonal. Start with the fourth column constant value of 4 and copy it down the column. Then continue the third column by adding 4 to 11 to get 15. Next continue the second column by taking its previous value, 22 and adding the 15 from the third column. Thus \"p\"(5) is 22 + 15 = 37. In order to compute \"p\"(6), we iterate the same algorithm on the \"p\"(5) values: take 4 from the fourth column, add that to the third column's value 15 to get 19, then add that to the second column's value 37 to get 56, which is \"p\"(6). This process may be continued ad infinitum. The values of the polynomial are produced without ever having to multiply. A difference engine only needs to be able to add. From one loop to the next, it needs to store 2 numbers—in this example (the last elements in the first and second columns). To tabulate polynomials of degree \"n\", one needs sufficient storage to hold \"n\" numbers.\n\nBabbage's difference engine No. 2, finally built in 1991, could hold 8 numbers of 31 decimal digits each and could thus tabulate 7th degree polynomials to that precision. The best machines from Scheutz could store 4 numbers with 15 digits each.\n\nThe initial values of columns can be calculated by first manually calculating N consecutive values of the function and by backtracking, i.e. calculating the required differences.\n\nCol formula_6 gets the value of the function at the start of computation formula_7. Col formula_8 is the difference between formula_9 and formula_7…\n\nIf the function to be calculated is a polynomial function, expressed as\nthe initial values can be calculated directly from the constant coefficients \"a\", \"a\",\"a\", …, \"a\" without calculating any data points. The initial values are thus:\n\n\nMany commonly used functions are analytic functions, which can be expressed as power series, for example as a Taylor series. The initial values can be calculated to any degree of accuracy; if done correctly the engine will give exact results for first N steps. After that, the engine will only give an approximation of the function.\n\nThe Taylor series expresses the function as a sum obtained from its derivatives at one point. For many functions the higher derivatives are trivial to obtain; for instance, the sine function at 0 has values of 0 or formula_19 for all derivatives. Setting 0 as the start of computation we get the simplified Maclaurin series\n\nThe same method of calculating the initial values from the coefficients can be used as for polynomial functions. The polynomial constant coefficients will now have the value\n\nThe problem with the methods described above is that errors will accumulate and the series will tend to diverge from the true function. A solution which guarantees a constant maximum error is to use curve fitting. A minimum of \"N\" values are calculated evenly spaced along the range of the desired calculations. Using a curve fitting technique like Gaussian reduction an \"N\"−1th degree polynomial interpolation of the function is found. With the optimized polynomial, the initial values can be calculated as above.\n\nWilliam Gibson and Bruce Sterling's \"The Difference Engine\" is an alternate history novel that looks how society would have progressed had the difference engine worked the way Babbage envisioned it.\n\nThe story takes places in Victorian England where technological advancement is on the rise. This is due to the effect of the success of Babbage's analytical machine. The convention of steampunk where Victorian fashion is combined with the technological elements of the Industrial Revolution is seen throughout the story due to technology being so advanced in that era.\n\n\n"}
{"id": "12674948", "url": "https://en.wikipedia.org/wiki?curid=12674948", "title": "Dual mode mobile", "text": "Dual mode mobile\n\nDual mode mobiles refer to mobile phones that are compatible with more than one form of data transmission or network.\n\nA dual-mode phone is a telephone which uses more than one technique for sending and receiving voice and data. This could be for wireless mobile phones or for wired phones.\n\nThere are three types of dual mode phones.\n\nMobile phones containing two types of cellular radios for voice and data. These phones include combination of GSM and CDMA technology. They can be used as a GSM or CDMA phone according to the user's preference. These handsets are also called global phones. An example of this is the Samsung SCH-A790.\n\nThese dual mode handsets are compatible with both GSM and CDMA networks and are essentially 2 phones in one device.\n\nSuch phones make sense in those countries that have both GSM & CDMA networks or international CDMA roamers who want to keep a single handset with 2 numbers on it.\n\nMost dual mode handsets require two identifying cards (one SIM and one RUIM), though some dual-mode phones (for example, the iPhone 4S) only require one SIM and one ESN. Not all dual SIM handsets are dual mode (for example dual SIM GSM phones).\n\nMobile phones contain both cellular and non-cellular radios used for voice and data communication. There are also 2 types of dual mode phones which use cellular radio which will contain GSM/CDMA/W-CDMA as well as other technology like IEEE 802.11 (Wi-Fi) radio or DECT (Digital Enhanced Cordless Telecommunications) radio. These phones can be used as cellular phones when connected to a wide area cellular network. When within range of a suitable WiFi or DECT network, the phone can be used as a WiFi/DECT phone for all communications purposes. This method of operation can reduce cost (for both the network operator and the subscriber), improve indoor coverage and increase data access speeds.\n\nWired phones with VoIP and POTS technology. These phones can be used for making VoIP calls and also used for phones on the circuit switchnetwork. These phones require compatible routers and modem to make VoIP calls.\n\nLG Nexus 5X\n\nLG Nexus 6P\n\nGoogle Pixel & Pixel XL\n\nGoogle Pixel 2 & Pixel 2 XL\n\nMotorola Moto X4 and Android One Moto X4\n\niPhone 6s\n\nDual mode mobiles could also refer to:\n\n"}
{"id": "1353103", "url": "https://en.wikipedia.org/wiki?curid=1353103", "title": "Durabrand", "text": "Durabrand\n\nDurabrand was first started in early 1999 as a brand only made for Wal-Mart stores as a generic brand for electronics, but has grown to be available near-internationally (due to Wal-Mart's global reach).\n\nWal-Mart Germany was the first country to introduce the private label with a lineup in Consumer Electronics. Responsible for the first launch in 1999 were Uwe Bremeyer (Senior Buyer Dept. 5) and Michael Werry (Buyer Dept. 5), since 2002 Martin Schulz (Senior Buyer Dept. 5) & Frank Mades (Divisional Merchandise Manager Electronics) for Wal-Mart Germany.\nThe very first product launched was a 120 min Videocassette produced at RAKS in Manisa (Turkey).\n\nThe products are marked for only Wal-Mart stores and available in very few other stores than Wal-Mart. Like most generic brands, Durabrand is a chain of different manufacturers. Durabrand is chained with Lenoxx Sound, Alco, Funai (which would also include Emerson, Sylvania, and Symphonic), Orion, Maxell, Resonance, Initial Technology, and many other different companies. The prices of a majority of their products are often considered loss leaders.\n\nDurabrand does have some \"company rivals,\" despite the low prices, their products are matched up between other in-house brands like Wal-Mart's iLo brand (considered as an upmarket brand, offers MP3 digital audio players and plasma video displays), Target's TruTech brand; and to an extent, K-Mart's former Curtis Mathes/White-Westinghouse (in the mid-to-late 1990s) now Home Essentials brand. Due to the fact that all of these are store brands, the stores are often competitive to get buyers to their store brand. Aside from store brands, Durabrand is matched up to Coby Electronics, Jwin, GPX, and other low-cost electronics brands. Durabrand offers audio equipment (CD players, alarm clocks, boomboxes, theater systems) and video equipment (VCRs, DVD players, televisions). However, it has also been lately focused on home appliances such as kitchen equipment, telephones, vacuums, and other general home appliances.\n\n\nA large D is often found on the front of their products.\nSilver and black are the predominant colors used on their products.\n\n\n"}
{"id": "53305844", "url": "https://en.wikipedia.org/wiki?curid=53305844", "title": "DyNet", "text": "DyNet\n\nDyNet is the communications network and communications protocol for Dynalite lighting automation and building automation. It is now part of Philips Lighting.\n\nThe network runs on a 4-twisted-pair cable of 100Ω 100 MHz CAT5E [http://www.lighting.philips.com/main/prof/lighting-controls/indoor-lighting-management-systems/dynalite-network-devices/913703041409_EU/product <nowiki>[1]</nowiki>] or a flat cable with RS485 serial port, usually with a RJ-12 connector. A daisy-chain serial network topology is strongly recommended with no stubs. The recommended cable colour-coding is:\n\nGreen/White pair = paralleled for GND\n\nOrange/White pair = paralleled for +12V\n\nBlue/White pair = blue for DATA+ and white for DATA-\n\nBrown/White pair = spare or shield if unshielded cable is used.\n"}
{"id": "33653552", "url": "https://en.wikipedia.org/wiki?curid=33653552", "title": "European Association for Architectural Education / Association Européenne pour l'Enseignement de l'Architecture", "text": "European Association for Architectural Education / Association Européenne pour l'Enseignement de l'Architecture\n\nThe European Association for Architectural Education / Association Européenne pour l'Enseignement de l'Architecture (EAAE/AEEA) is a non-profit bilingual (English/French) association that, since 1975, is trying to increase the knowledge and the quality of architectural and urban design education, for the benefit of teachers, students, citizens, and society. Today, the association counts among its members over 140 European and international schools of architecture, representing some 5000 teaching staff and over 120,000 students.\n\nThe \"Charter for Architectural Research\" is intended as a reference document for the use of universities, architecture schools, research institutions, funding agencies, and professional practices that are undertaking architectural research. It specifies the character and objectives of architectural research, confirms the variety of valid methodologies and supports the development of a vibrant, internationally recognized and well funded research community.\n\nThe \"Charter\", produced by the EAAE/AEEA Research Committee between 2009 and 2011, consists of two distinct parts : A short \"Declaration\" approved at the General Assembly in September 2011, and a more detailed \"Framework\" document, on which work is ongoing, and concerning which comments are of course invited from the community of educators and researchers in architecture.\n\nArchitecture is about the creation, transformation and interpretation of the built environment and the articulation of space at various scales. It is a discipline involving art, design, conservation, planning, management, construction and representation, addressing issues of ethics, aesthetics, culture and society. The discipline of architecture engages with the cultural, socio-economic and environmental conditions affecting our quality of life.\n\nArchitecture is facing challenges of climate change, globalisation, urbanisation and social transformation that necessitate vital research. In parallel, the horizons of architectural experimentation are expanding rapidly with the development of new technologies and media. If we are to understand, explain, anticipate and influence the consequences of these changes, research is essential. Moreover, research is essential for the continued expansion of the discipline’s knowledge base and improvement in teaching, learning and practice of architecture.\n\nThe EAAE/AEEA confirms that architectural research has a particular knowledge base, tools and methods; it confirms the trans-disciplinary nature of architectural research and the legitimacy of a wide range of approaches. Architecture tackles various dimensions of the built environment in a specifically integrative way; the EAAE/AEEA calls for recognition of all appropriate areas and modes of architectural research, for better definition of context and scope and acknowledges research by design as part of the diversity of valid methods with which to research, practice and study architecture.\n\nThe generic expectations of originality, rigour and significance apply to all genres of architectural research. Valid architectural research outputs are as varied as the constantly growing range of research approaches and the EAAE/AEEA recognises installations, experimental projects, proposals, models and actual buildings as such, in addition to written and graphic research outputs. Peer review, communication and international dissemination are crucial and should relate to the nature of the research.\n\nThe EAAE/AEEA advocates stronger links between theoretical and practice-based research and therefore between academia and the profession in the establishment of an expanded arena of architectural research.\n\nSee the latest PDF version of the \"Declaration\" on the EAAE/AEEA Research webspace\n\nSee the latest PDF version of the \"Framework\" on the EAAE/AEEA Research webspace\n"}
{"id": "4685393", "url": "https://en.wikipedia.org/wiki?curid=4685393", "title": "Fault (technology)", "text": "Fault (technology)\n\nIn document ISO 10303-226, a fault is defined as an abnormal condition or defect at the component, equipment, or sub-system level which may lead to a failure.\n\nIn telecommunications, according to the Federal Standard 1037C of the United States, the term \"fault\" has the following meanings: \n\nA random fault is a fault that occurs as a result of wear or other deterioration. Whereas the time of a particular occurrence of such a fault cannot be determined, the rate at which such faults occur within the equipment population on average can be predicted with accuracy. Manufacturers will often accept random faults as a risk if the chances are virtually negligible.\nA fault can happen in virtually any object or appliance, most common with electronics and machinery.\nFor example, an Xbox 360 console will deteriorate over time due to dust buildup in the fans. This will cause the Xbox to overheat, cause an error, and shut the console down.\n\nSystematic faults are often a result of an error in the specification of the equipment and therefore affect all examples of that type. Such faults can remain undetected for years, until conditions conduce to create the failure. Given the same circumstances, each and every example of the equipment would fail identically at that time.\n\nFailures in hardware can be caused by random faults or systematic faults, but failures in software are always systematic.\n\n"}
{"id": "38175442", "url": "https://en.wikipedia.org/wiki?curid=38175442", "title": "Fracking hose", "text": "Fracking hose\n\nFracking hoses are used in hydraulic fracturing (fracking). Hydraulic fracturing uses between 1.2 and 3.5 million US gallons (4.5 and 13 Ml) of water per well, with large projects using up to 5 million US gallons (19 Ml). Additional water is used when wells are refractured; this may be done several times.\n\nThe traditional solution is to use metal pipes to transfer water but these are costly to deliver and assemble. Thermoplastic polyurethane (TPU) covered hoses and Nitrile rubber (NBR) covered hoses have a lot of advantages compared to metal pipes. It is easy to deliver, assemble and disassemble hoses and long sections of NBR- and TPU-covered hoses reduce the possibility of leakage in connecting parts. These large-diameter NBR- and TPU-covered hoses are called fracking hoses.\n\nFracking hoses are high-pressure, high-strength lay-flat hoses designed for pumping aggressive water around mine sites. Safety and efficiency are important factors when choosing products for these applications.\n\nFracking hoses are solutions derived from the fire hose industries. The fire hose manufacturers manufacture NBR or TPU covered hoses for fire fighting, water discharge, irrigation etc. The fracking industries borrowed the idea from the fire hose industries and use these hoses in fracking.\n"}
{"id": "20053170", "url": "https://en.wikipedia.org/wiki?curid=20053170", "title": "Global Open University", "text": "Global Open University\n\nThe Global Open University is an Indian university in the state of Nagaland, with campuses in Dimapur and Kohima.\n\nThe University was founded by the fully sponsoring body President Dr. P. R. Trividi, President, World Institution Building Programme (WIBP), Reverend Dr. M. Motsuo Ngullie, Founding Father and the first Vice-Chancellor of the Global Open University Nagaland (2007-2008) is the witness signatory between the Government of Nagaland represented by Dr. Edward Lotha, Director of Higher Education and M. Yanrenthung Ngullie, the first Assistant Registrer of TGOUN, Nagaland Peoples Front (NPF) Vice-President, Pinyimthung Patton were the pioneers to established the said University which received the assent of the Hon'le Governor and passed the Global Open University Act 3 of 2006 in Wokha as permanent (Main Campus/Headquarter) in the state of Nagaland and campuses in Kohima and Dimapur. As stated above, It has been established under the provisions of The Global Open University Act 2006 (Act 3 of 2006) of the Government of Nagaland with a view to introducing vocational, job oriented and employment centric education in the North-East in general and in the State of Nagaland in particular. The Global Open University, Nagaland has been legislated by the Nagaland State Legislative Assembly under The Global Open University Act 2006 (Act 3 of 2006) which received the assent of the Governor of Nagaland on 30 August 2006 and was notified vide Notification number Law/Act-10/2006 on 18 September 2006. The provisions of The Global Open University Act 2006 were published in the Nagaland Official Gazette on 18 September 2006 for general information.\n\nAfter much hardship, the third reading in the Nagaland Legislative Assembly and the assent of the Hon'ble Governor was passed and became an act (Act 3 of 2006), the inaugural programme was launched with the courses offered by the TGOUN in the field of higher vocational and professional field.\n\nHon'ble Minister for Higher Education (2007), Dr. Shurhozelie inaugurated the Global Open University Nagaland, Headquarter: Wokha on 31 May 2007 as the Chief Guest.\n\nIn his inaugural speech, Dr. Shurhozelie said education is vital for social development and so is higher education for higher level of development and achievement. He spoke on the successful implementation of communitisation of public institution in the state.\n\nHe extended his gratitude to Dr. P. R. Trivedi, Pro-Chancellir Global Open University Nagaland, Headquarter and main campus, Wokha and reverend Dr. Motsuo Ngullie, Vice-Chancellor (2007-2008) who is the brain-child to establish the Global Open University in Nagaland and invested all his potential ability to pursue for establishing TGOUN since 2004 to make it a reality for the larger interest of India and North-East in general and Nagaland in particular in the field of higher education and encourage one and all to become a 'Job giver but not job seeker' and ventured to provide facilities for higher level of vocational and professional learning to the people of Nagaland.\n\nParliamentary Secretary, Nkhao Lotha also spoke on the occasion and appealed to the citizens of Wokha to extent full support and cooperation to the university.\n\nDr. P. R. Trivedi announced the views and action plans of TGOU (The Global Open University) Nagaland, Wokha. Reverend Dr. M. Motsuo Ngullie, Vice-Chancellor (2007-2008) gave the welcome speech and brief how he work tirelessly to establish the TGOU in Nagaland after he was officially appointed as the Director, Indian Institute of Ecology and Environment, Nagaland extension, Wokha which is based in Paryavaran Complex, South of Saket in New Delhi as its main campus. He also opied that Naga youths will be suitabilly rewarded through gainful opportunities, thereby giving relief to the problem of educated unemoloyed youths and extended his gratitude to the sponsoring body President, World Institution Building Programme, Dr. P. R. Trivedi, Rev. Dr. N. Ezung said the invocation prayer. The function was chaired by N. Mhao Lotha, Administrative Officer, TGOUN. A host of dignitaries including Dr. Deorani, Principal Secretary, Higher Education, Thepfulhovi Solo, Rtd. Principal CCF, Deputy Commissioner, Wokha Mikha Lomi, heads of offices, Lotha Hohi, Lotha Students' Union, public leaders and students attended the function followed by a grand feast. The whole arrangement of the said programme was initiated by the first Assistant Registrer of the Global Open University Nagaland, Oking, Wokha, Shri. M. Y. Lotha and his team.\n\nThe university has operated from its Headquarter, Wokha District. However, with the instication of some vested interested individuals convinced the President of the sponsoring body of TGOUN and theteby, neglected its Main Campus/Headquarter: Wokha at 'Tzukum Valley' since April 2012 till date (2017) and abandoned the demarkated land of the university which was submitted to the Hon'ble Governor to give his assent after proper and justified verification.\n\nThe university's Dimapur campus was inaugurated by the Chief Minister of Nagaland, Neiphiu Rio, on (World Environment Day) 5 June 2007. Two other campuses have subsequently been launched at Kohima and Dimapur with permanent headquarter at Wokha as stated above. The Governor of Nagaland is the Chancellor/Visitor of the University. The Global Open University (TGOU), Nagaland is administered by a Governing Council and Executive Council.\n\nThe Global Open University is a joint public-private partnership venture between the Government of Nagaland and the World Institution Building Programme (WIBP). The state government gives grants-in-aid to sponsor the students from Nagaland by paying their fee, and the WIBP as the sponsoring agency for the university provides Rs. 7 Crore as the Corpus Fund in the name of The Global Open University.\n\nTGOU is provisionally recognized (2008-2009) as a Private University by the University Grants Commission of India (UGC) The Association of Indian Universities (AIU) recognizes IGNOU conferred degrees as on par with the degrees conferred by its members.\n\nIn 2008, the Global Open University was recognised provisionally by the Distance Education Council for offering distance programmes the same year.\n\nThe Global Open University offers academic degree programmes at both undergraduate and postgraduate levels in the following areas:\n\n\nThe university also offers short-term online certificate courses apart from its distance education degree courses. These certificate courses are totally online which includes online registration, online study material and also have online examination system. This University also has the courses of laparoscopic surgery conducted at World Laparoscopy Hospital, New Delhi headed by Dr. Mishra. It also awards distance education degrees in various programmes.\n\n"}
{"id": "922920", "url": "https://en.wikipedia.org/wiki?curid=922920", "title": "Hostile Waters: Antaeus Rising", "text": "Hostile Waters: Antaeus Rising\n\nHostile Waters, released as Hostile Waters: Antaeus Rising in America, is a hybrid vehicle and strategy game released on the PC in 2001 by the British company Rage Games Limited. It was inspired by an earlier game known as \"Carrier Command\" (Realtime Games, 1988). It has won several awards and one unofficial award from Rock Paper Shotgun as a \"lost classic\" or \"The best game you’ve never played\".\n\n\"Hostile Waters\" takes place in a Utopian future where war has been abolished. In the year 2012, a revolution takes place between the corrupt and power-hungry politicians, leaders and businessmen (described as the \"Old Guard\") and the people. The Old Guard were defeated, with only a few of their leaders escaping. By 2032, the world has been rebuilt as a utopia, with the help of nano-technological assemblers, which are used in \"creation engines\" used to create matter from energy and waste, for free. The newly united world is governed from a capital city known as Central.\n\nMissile attacks are suddenly launched against major cities all over the world from unknown locations. The location is eventually discovered to be an island chain in the South Pacific Ocean. A response to the missile attacks was a special forces team sent in to investigate the area for preliminary investigations. The Ministry of Intelligence (MinIntel) loses contact with it shortly thereafter. The world government authorises a reactivation of the \"Antaeus\" program, a series of warships able to create any weapon of their choosing using their on-board nano-technological creation engine. Two of these were left on the seabed in the case of an emergency, capable of being re-activated and refloating itself. On board are a series of \"soulcatcher\" chips, a classified 1990s military program researched into for the storage of human brain functions on a silicon chip. The soulcatcher technology was used to store the minds of every crew member ever assigned to an Antaeus vessel.\n\nIt is soon discovered that one of the cruisers does not respond to the awakening signal. The other cruiser, however, is refloated and re-activated, with heavy damage to vital ship components. A course is plotted for a nearby, disused wet-dock.\n\nAs the \"Antaeus\" progresses from the wet-dock, unusual biological life-forms are discovered amongst the enemy bases on the islands. The identity of the aggressor firing the missiles is confirmed as the leftovers of the old, pre-Central forces, known as the Cabal. Outnumbering Central's army a thousand to one, they are fighting with thousands of troops and weapons that they hid away when it was apparent that the war was lost. The \"Antaeus\" is deployed into the chicane to stop the Cabal's operations there. It's later discovered that along with their superior numbers, they have also biologically engineered a species of organic machines, designed in the popular likeness of extraterrestrials, which they intend to use to create the fear of an alien invasion, to facilitate their taking over the world and the removal of the public use of creation engines.\n\nThe Cabal later lose control of the species, which eventually turn on their masters, destroying them, and start spreading, modifying the planetary climate and geographical features in an attempt to exterminate humanity and make the planet more hospitable to themselves. Having exterminated its creators, the species resolves to cleanse humanity as a whole from the planet using a massive 'disassembler cannon', only to be stopped by the \"Antaeus\". The species subsequently attempts to flee into the cosmos and colonise the surrounding planets and stars, by launching a massive number of 'culture stones' (information devices that also double as creation engines) into space from an enormous, artificially-grown organic \"island\", their final staging point. Central's only option is to bind the \"Antaeus\" creation engine and the disassembler cannon stolen from the aliens together to create a makeshift bomb, and detonate it at the central \"column\" containing the culture stones. The plan succeeds, and the \"Antaeus\" is sacrificed to save the world.\n\nThe final cinematic show the organic disassembler cannon and the \"Antaeus\" creation engine moving closer together and fusing, creating something new. A post-credits scene also shows that two of the species' culture stones have managed to get into space.\n\nEach Mission takes place on and or near a fortified enemy island containing various forms of anti-air and ground defence, with scattered unit-production complexes powered by oil-derricks and fuel containers (which are dependent on the oil-derricks) that the player can destroy to keep the enemy from replacing destroyed forces.\n\nVehicles are built on the Antaeus and, if desired, land vehicles can be delivered to a location by the air-lifting \"magpie\". Units are created by providing Antaeus with a number of resources which are obtained at the beginning of the level and debris which are taken from destroyed enemy units and structures. Transport helicopters such as the \"Pegasus\" can fly to an object and airlift it to the ship-board recycling system with little resources required. The carrier can analyse objects it disassembles at the rear of the Antaeus cruiser, and several of the game's vehicles and items are unlocked by \"sampling\" them in this fashion.\n\nThe game has a number of vehicles that are progressively unlocked as the missions progress. Vehicles contain a number of slots for equipment and a selection of different types of weapons to use the vehicle with. A variety of vehicle equipment combinations can be designed and used.\n\nVehicles have an individual damage multiplier such that different vehicles with the same weapon will do different damage. In addition to this, each soul-chip personality specializes in one unit along with specific equipment, which, if equipped will gain them a bonus in efficiency.\n\n"}
{"id": "2027682", "url": "https://en.wikipedia.org/wiki?curid=2027682", "title": "Hyosung", "text": "Hyosung\n\nHyosung Corporation is a South Korean industrial conglomerate, founded in 1966. It operates in various fields, including the chemical industry, industrial machinery, IT, trade, and construction. It is known in Korea mostly for high-end apartments and automatic teller machines. Its CEO is S. R. Cho (조석래).\n\n2013. World's first polyketone developed and commercialized; Product strategy award won for ESS project (Energy Storage System) at the 2013 Frost & Sullivan Korea Excellence Awards; Award for '2012 Global Preferred Supplier' won by Neochem PU; Industry Innovation Movement 3.0 joined with MOU signed for shared growth fund donation; Carbon fiber plant completed in Jeonju; Carbon fiber brand 'TANSOME' launched; Hyosung Harington Place sold by Construction PU and Chin Hung International after opening a model house in Chilgok and Okdong in North Gyeongsang Province\n\n2012. Selected as the 'charging system business' of Korea Electric Power Corporation's (KEPCO) EV sharing pilot project; Neochem PU won '2011 Global Most Improved Supplier' award from LINDE in Germany; Power & Industrial Systems PU R&D Center commercialized 1 kW dual cell stack for home fuel cells; Industrial Machinery PU signed an agreement with Korea Gas Safety Corporation to obtain IECEx and ATEX for 25 electric motor types; Packaging PU launched new beverages (including Del Monte Cold); Power & Industrial Systems PG signed a contract for electrical power grid construction in Qatar; Power & Industrial Systems PG delivered the first product of its solar inverter; Vietnam Smile Expedition won KPRA Korea PR Awards for its Global PR; Company newsletter <HYOSUNG> won 'Chairman's Prize of Korea Clean Contents National Movement Association' in Company Newsletter of '2012 Korea Communication Awards'; Tire & Industrial Reinforcement Materials PU completed construction of Thailand JV steel cord plant with SEI; Packaging PU produced Seoul Dairy Cooperative's new Dotoru products; Nautilus Hyosung won the '2012 Red Dot Design Award'\n\n2011. Gwanghyewon factory introduces PS Call-based quality control system; Power & Industrial Systems PG has signed an MOU with Electric Insulation Research Center, Seoan Traffic University for joint research and development; Tire & Industrial Reinforcements PU extends its MOU with Michelin for another 5-year’s supply; Gwanghyewon factory selected as Best Partner for Clients 2010; Three types of intelligent electronic devices for automation of digital transformation acquired IEC 61850 from KEMA, the Dutch-based international certificate authority; Nautilus Hyosung signs an MOU with SKT for ‘Smart Branch’; Donated 500 million won to “Bridge of Hope Korea Disaster Relief Association” for the flood damage recovery; Developing the country’s first Carbon Fiber; Built spandex plant in Brazil.\n\n2010. Received Tower of Exports Order for $4 Billion in exports(The 47th Annual Trade Day); Built steel cord plant in Vietnam \nSigned agreement to build spandex plant in Brazil; Signed contract to build electrical power grid in Qatar; Launched transformer substation construction project in Algeria; Supplied 50MVA STACOM to KEPCO for the first time in Korea; Hyosung EBARA Engineering launches sewage treatment business in Algeria; Participated in 2010 Shanghai Expo; Hyosung R&D Business Labs received Awards for Creativity in Science and Technology and Honors from Vice-Minister of Education, Science and Technology for developing the country’s first TAC film\n\n2009. Declared the Hyosung Way; Built aramid fiber plant; Built TAC film plant; Hyosung Capital merged with Star Lease Co., Ltd.; Established Hyosung Toyota; Signed MOU to build power generation and wind turbine plant with Korea Southern Power Co.; Received international certification for 750 kW gear-type wind turbine(DEWI-OCC, Germany); Xanadu polyester fibers selected as Next-Generation World-Class Product by Ministry of Commerce; High barrier gas multi-layer for PET beer bottles selected as Next-Generation World-Class Product by Ministry of Commerce; Hyosung R&DB Labs received Presidential Award for Merit of promotion of Science and Technology (Korea Industrial Technology Association)\n\n2008. Built spandex plant in Turkey and Vietnam; Acquired Chinhung International Inc.; Expanded ultra high voltage power facility \nBuilt tire cord plant in Vietnam; Built plant for Nantong Hyosung Transformer Co., Ltd. In China; Built Photovoltaic Power plant in Taean, Chuncheongnam-do\n\n2007.\nAcquired StarLease Co., Ltd; work for the NF factory completed; built facility for anti-bacterial filled PET bottles; construction of a #1 solar power system was completed; exceeded KRW 5 trillion in sales for Hyosung Co., Ltd.\n\n2006.\nContracted with Goodyear for the long-term supply of Tire Cords and Contracted to take over four Factories around the World; acquired an Agfa photo production facility in Germany; acquired the Nantong Hyosung Transformer Co., Ltd. in China; acquired Dongguk Trade's spandex factory in China\n\n2005.\nWork for the nylon film plant in Jiaxing, China completed\n\n2004.\nCompleted work for the spandex plant in Zhuhai, China; completed work for the transformer plant in Baoding, China; completed work for the tire cord plant in Jiaxing, China; signed a supply contract for 750 kV switchgear with Northwest Street Power Grid Corp, China; expanded the nylon film facilities at the Gumi 1 factory\n\n2003.\nThe Class Hyosung was established, Hyosung Spandex (Guangdong) Co., Ltd was established in Guangdong Province, China;\nHyosung Film (Jiaxing) Co., Ltd was established in Zhejiang Province, China\n\n2002.\nTook over the Tire Cord Plant of Michelin in Scottsville, U.S.A.; Aerocool was selected as one of the world's best products.\n\n2001.\nAdopted ERP; established the Spandex Plant in China; concluded a contract with Beijing Coca-Cola for the long-term supply of PET bottles\n\n2000.\nEstablished the spandex plant in Gumi\n\n1999.\nAcquired Korean Trade (KT) marks for the Hyosung Computer, Ultra High Voltage GIS (Gas Insulated Switchgear), and Polyester Fiber (Aerocool)\n\n1998.\nT&C, Trading Company, Life Industry, and Heavy Industry all merged into Hyosung Co., Ltd.; developed 800 kV GIS, a first in Korea, and only the 3rd time Globally\n\n1996.\nEstablished the nylon film plant in Daejeon\n\n1995.\nEstablished PET bottle company in China; established the tile carpet plant in Daejeon\n\n1990.\nEntered the spandex Business\n\n1989.\nEntered the PP and propylene business; established Hyosung EBARA Co., Ltd.\n\n1983.\nDeveloped a microfiber that combines Nylon and Polyester\n\n1979.\nStarted producing PET bottles at the Eonyang Plant\n\n1977.\nEstablished the heavy industry plant in Changwon\n\n1975.\nAcquired Hanyoung Industries Co., Ltd. (formerly Hyosung Heavy Industry)\n\n1973.\nEstablished Tongyang Polyester Co., Ltd.; established Tongyang Dyeing Co., Ltd.\n\n1972.\nExported tire cords to Southeast Asian countries for the first time\n\n1971.\nEstablished R&DB Labs, a first in Korea\n\n1970.\nAcquired Hanil Nylon Co., Ltd.\n\n1969.\nDeveloped Korea’s first 154kV high-voltage transformer\n\n1968.\nCompleted the Ulsan Plant\n\n1967.\nCompleted the tire cord plant in Ulsan\n\n1966.\nEstablished Tongyang Nylon Co., Ltd.\n\n\n"}
{"id": "5175523", "url": "https://en.wikipedia.org/wiki?curid=5175523", "title": "Intelligent environment", "text": "Intelligent environment\n\nIntelligent Environments (IE) are spaces with embedded systems and information and communication technologies creating interactive spaces that bring computation into the physical world and enhance occupants experiences. \"Intelligent environments are spaces in which computation is seamlessly used to enhance ordinary activity. One of the driving forces behind the emerging interest in highly interactive environments is to make computers not only genuine user-friendly but also essentially invisible to the user\".\n\nIEs describe physical environments in which information and communication technologies and sensor systems disappear as they become embedded into physical objects, infrastructures, and the surroundings in which we live, travel and work. The goal here is to allow computers to take part in activities never previously involved and allow people to interact with computers via gesture, voice, movement, and context.\n\nThe idea of having an artificial intelligence capable of managing an environment, recollect data, and respond in consequence is older than we would expect. In the novel \"\" from 1968, long before the microcomputers revolution, you have the fictional character HAL 9000, a computer capable of controlling the different sensors and systems of the environment and using them as extensions of itself. The character Proteus from the 1973 novel Demon Seed also portrays the same characteristics of an artificial intelligence controlling an embedded environment. By the time these two novels were released, the idea of a computer controlling the environment that surrounds us was not broadly accepted by the community since both characters played the role of evil machines whose only objectives included the control over humans.\n\nIt is not until 1991 with the introduction of ubiquitous computing by Mark Weiser when we start seeing an inclination from the scientific community to study the area of computing outside of the typical machine with a keyboard and a screen. It became something that could be potentially implemented into anything that surrounds us, proposing casual access to computing to any user. In 1996 Hashimoto Laboratory at the University of Tokyo developed the first research on intelligent spaces. J.-H. Lee and H. Hashimoto designed a room with a homemade three-dimensional tracking sensor and mobile robots, all this connected to a network. The idea was for the robots to support the person in the room with different tasks with the help of vision cameras and computer sets, becoming one of the first intelligent environment.\n\nAt first, intelligent spaces were designed with the only objective to help people with physical tasks. Robots included in the room would help people to grab objects as well as support people with disabilities to do certain jobs. This idea started shifting into the concept we have today of intelligent environments, not only an environment to support people but also robots. The intelligent space became a platform that extends the censorial capacity of anything connected to it. If we start designing products, either software or hardware around this intelligent environments, the effort needed to complete all kinds of tasks would be drastically reduced.\n\nPractical implementation of intelligent environments implies the solution of many challenges. Pervasive computing systems embedded in IE need to be proactive and to accomplish this, it is crucial that systems can track and determine the users' intent. The challenge here is finding that action that supposedly will help the user rather than hinder him. As of right now, algorithms behind the intelligent environments are constantly being reworked by the simple method of trial and error in artificial environments. It is not until a programmer can see an accurate enough level of prediction for the product to become commercialized. The degree of accuracy of intelligent environments depends on the task they want to accomplish. Some simple actions that do not substantially affect the user can admit more failures in the predictions than other functions that hold more responsibility. Still, there are always actions that cannot be fully predicted by the IE and needs some input from the user to be completed. One of the most significant challenges as of right now is determining which are those actions that are required for user input and how to create algorithms capable of eliminating that input so that the usability of the systems improves. \n\nBy the other hand, pro-activity of such environments has to be handled very carefully. Pervasive computing systems are supposed to be minimally intrusive and at the same time be capable of taking decisions that will help users. One way to achieve that is making those systems capable of modifying their behavior based on the user's state and surroundings. Here again, some challenges arise: What are the required data and information that a system needs to be context-aware? How frequently should that information be measured and consulted without hurting system performance? The goal is to create an IE capable of reacting fast and accurate to the needs and inputs of the user so it would be unnecessary for the sensors to record information that will not help the algorithms make the correct action to what is happening. Recognizing important data and filtering the environment to search for the appropriate place to obtain it results in a great challenge.\n\nIt is crucial for pervasive computing systems to find the right level of pro-activity and transparency without annoying the user. Systems can infer the user's needs for pro-activity based on his level of expertise on a particular task. Self-tuning can be crucial for accomplishing this goal.\n\nAs the Intelligent Environments Conference (2007) points out: \"Types of Intelligent Environments range from private to public and from fixed to mobile; some are ephemeral while others are permanent; some change type during their lifespan. The realization of Intelligent Environments requires the convergence of different disciplines: Information and Computer Science, Architecture, Material Engineering, Artificial Intelligence, Sociology, and Design. Besides, technical breakthroughs are required in key enabling technology fields, such as microelectronics (e.g., miniaturization, power consumption), communication and networking technologies (e.g., broadband and wireless networks), smart materials (e.g., bio-implants) and intelligent agents (e.g., context awareness)\". The correct integration of all of these components is crucial to developing a useful IE.\n\nOne of the main areas that will experience a significant impact on the emergence of IE is business relations. The way companies interact with each other and with people will suffer the most significant impact. Their relationships will become more dynamic and should emphasize a more flexible approach to businesses, trying to adapt to the continually changing commercial environment. Such flexibility should also be reflected also on their employees and their work environment. Even today, companies that have shown significant levels of flexibility on their working environments and with their employees (as at Microsoft or Google) have increasing levels of productivity and employees retention.\n\nAnother critical issue that companies must take into account in the IE era is the way they approach the privacy of their clients. The success of these future companies will depend significantly on how people feel more confident in the use they give to their personal information. Another essential key to the success of these prospective businesses will be to allow the end user to have control over the way in which the IE systems make the decisions. Friendly user configurations should enable them to be in control of these systems but at the time is one of the biggest challenges for systems engineers.\n\nNew ways of entertainment have emerged since the creation of IE. There have been several experiments in museums where this technology is used to create a more interactive experience that makes the visitors not only experience history with their eyes but also feel in all of their senses. From the use of sounds and lights that adapt according to the expositions presented to the incorporation of smells that define unique environments, there are endless opportunities to the application of IE into this sort of entertainment.\n\nThe same concept can be used to not only improve existent leisure experiences but also to create new ones. Artistic expression has had a significant influence on this since we have seen new forms of art using Artificial Intelligence and IE. Take for example the work of the artist Chris Milk where you can see the implementation of immersive installations that make the user not only appreciate a work of art but also be part of it. One of his most important work of arts, \"The Treachery of Sanctuary\" uses projections of the users' bodies in different screens to explore the creative process by using generated digital birds. These type of art requires the user's interaction to exist.\n\nOne of the most critical applications of Intelligent Environments is in the Healthcare Industry. You can use IE in the hospital's rooms to monitor the state of the patients without the patient even noticing, which results in less disturbance to those patients who need extraordinary amounts of rest and fewer efforts for nurses that are no longer required to check on patients regularly. This technology could substantially change the way in which hospitals and clinics are designed since nurses can be more efficient with their time attending patients in critical needs without leaving other patients under the care of intelligent rooms. This unique installations will no longer monitor the patient's health and notify the nurses, but it could also be programmed to interact with them with preventative purposes by administering specific drugs or directly delivering food when needed.\n\nCaring of frail, elderly patients could dramatically change in the future with the use of IE. By introducing this technology into their own homes, we will be able to monitor a patient from anywhere we are without having the need to transporting them to hospitals or clinics to have proper care. This could transform nearly any house into an intelligent nursing home care, allowing families to save lots of money by dramatically reducing the cost of care.\n\nPreventing is the best way to fighting a possible problem and there is no better way to do so that gathering information prior to a problematic event that helps us know when it would happen. IE would provide the perfect way to gather the data necessary to predict hazards and possible problems in the future. If we implement IE in our houses, it could notify, for example, the fire department if a fire is about to happen without us even noticing, or the police department if suspicious activity is detected in the proximity of our homes. In the best scenario, the event would not happen since the IE will help us create a diagnosis of the environment where it is implemented so that we could attack possible issues long before it happens. This will substantially improve live conditions in the cities, and a substantial economic impact since less hazardous events would happen, preventing material loss.\n\nIntelligent Environments will help us monitor different natural environments at a much higher precision and granularity than the currently used techniques. By having access to a richer and more significant data, it will not only help us to control the environment for possible hazards, but it will also change the way in which we understand it, making us improve the current theories and models of environmental processes. As of today, this technology is being used to study phenomena such as coastal erosion, flooding and the movement of glacial. We know very little about the why of many natural processes that are currently affecting us and having more accurate and precise data will significantly improve the way in which we attack those issues so that we not only make humans more environmentally friendly but also improve the health of our planet.\n\n\n"}
{"id": "17420716", "url": "https://en.wikipedia.org/wiki?curid=17420716", "title": "List of electric-vehicle-battery manufacturers", "text": "List of electric-vehicle-battery manufacturers\n\nAccording to Shenzhen-Guangdong Industry Research CATL is the largest producer of Lithum-ion batteries for electric mobility with a capacity of 12 GWh. Followed by Panasonic and BYD. According to Shenzhen Gaogong Industry Research, CATL last year churned out 11.8 GWh in battery capacity, a surge of over 74% from 2016. Japan’s Panasonic was second-largest with 10 GWh, and BYD came in third with 7.2 GWh. Another China-based maker, OptimumNano Energy Co. Ltd., and South Korea’s LG Chem were No. 4 and No. 5, producing 5.5 GWh and 4.5 GWh respectively.\n\n"}
{"id": "984752", "url": "https://en.wikipedia.org/wiki?curid=984752", "title": "Lyapunov equation", "text": "Lyapunov equation\n\nIn control theory, the discrete Lyapunov equation is of the form\nwhere formula_2 is a Hermitian matrix and formula_3 is the conjugate transpose of formula_4. \nThe continuous Lyapunov equation is of form: formula_5.\n\nThe Lyapunov equation occurs in many branches of control theory, such as stability analysis and optimal control. This and related equations are named after the Russian mathematician Aleksandr Lyapunov.\n\nIn the following theorems formula_6, and formula_7 and formula_2 are symmetric. The notation formula_9 means that the matrix formula_7 is positive definite.\n\nTheorem (continuous time version). Given any formula_11, there exists a unique formula_9 satisfying formula_13 if and only if the linear system formula_14 is globally asymptotically stable. The quadratic function formula_15 is a Lyapunov function that can be used to verify stability.\n\nTheorem (discrete time version). Given any formula_11, there exists a unique formula_9 satisfying formula_18 if and only if the linear system formula_19 is globally asymptotically stable. As before, formula_20 is a Lyapunov function.\n\nSpecialized software is available for solving Lyapunov equations. For the discrete case, the Schur method of Kitagawa is often used. For the continuous Lyapunov equation the method of Bartels and Stewart can be used.\n\nDefining the formula_21 operator as stacking the columns of a matrix formula_4 and formula_23 as the Kronecker product of formula_4 and formula_25, the continuous time and discrete time Lyapunov equations can be expressed as solutions of a matrix equation. Furthermore, if the matrix formula_4 is stable, the solution can also be expressed as an integral (continuous time case) or as an infinite sum (discrete time case).\n\nUsing the result that formula_27, one has\nwhere formula_29 is a conformable identity matrix. One may then solve for formula_30 by inverting or solving the linear equations. To get formula_31, one must just reshape formula_32 appropriately.\n\nMoreover, if formula_4 is stable, the solution formula_31 can also be written as\n\nFor comparison, consider the one-dimensional case, where this just says that the solution of formula_36 is formula_37.\n\nUsing again the Kronecker product notation and the vectorization operator, one has the matrix equation\nwhere formula_39 denotes the matrix obtained by complex conjugating the entries of formula_4.\n\nSimilar to the discrete-time case, if formula_4 is stable, the solution formula_31 can also be written as\n\nFor comparison, consider the one-dimensional case, where this just says that the solution of formula_44 is formula_45.\n\n"}
{"id": "13475684", "url": "https://en.wikipedia.org/wiki?curid=13475684", "title": "Microbial biodegradation", "text": "Microbial biodegradation\n\nMicrobial biodegradation is the use of bioremediation and biotransformation methods to harness the naturally occurring ability of microbial xenobiotic metabolism to degrade, transform or accumulate environmental pollutants, including hydrocarbons (e.g. oil), polychlorinated biphenyls (PCBs), polyaromatic hydrocarbons (PAHs), heterocyclic compounds (such as pyridine or quinoline), pharmaceutical substances, radionuclides and metals.\n\nInterest in the microbial biodegradation of pollutants has intensified in recent years, and recent major methodological breakthroughs have enabled detailed genomic, metagenomic, proteomic, bioinformatic and other high-throughput analyses of environmentally relevant microorganisms, providing new insights into biodegradative pathways and the ability of organisms to adapt to changing environmental conditions.\n\nBiological processes play a major role in the removal of contaminants and take advantage of the catabolic versatility of microorganisms to degrade or convert such compounds. In environmental microbiology, genome-based global studies are increasing the understanding of metabolic and regulatory networks, as well as providing new information on the evolution of degradation pathways and molecular adaptation strategies to changing environmental conditions.\n\nThe increasing amount of bacterial genomic data provides new opportunities for understanding the genetic and molecular bases of the degradation of organic pollutants. Aromatic compounds are among the most persistent of these pollutants and lessons can be learned from the recent genomic studies of \"Burkholderia xenovorans\" LB400 and \"Rhodococcus\" sp. strain RHA1, two of the largest bacterial genomes completely sequenced to date. These studies have helped expand our understanding of bacterial catabolism, non-catabolic physiological adaptation to organic compounds, and the evolution of large bacterial genomes. First, the metabolic pathways from phylogenetically diverse isolates are very similar with respect to overall organization. Thus, as originally noted in pseudomonads, a large number of \"peripheral aromatic\" pathways funnel a range of natural and xenobiotic compounds into a restricted number of \"central aromatic\" pathways. Nevertheless, these pathways are genetically organized in genus-specific fashions, as exemplified by the b-ketoadipate and Paa pathways. Comparative genomic studies further reveal that some pathways are more widespread than initially thought. Thus, the Box and Paa pathways illustrate the prevalence of non-oxygenolytic ring-cleavage strategies in aerobic aromatic degradation processes. Functional genomic studies have been useful in establishing that even organisms harboring high numbers of homologous enzymes seem to contain few examples of true redundancy. For example, the multiplicity of ring-cleaving dioxygenases in certain rhodococcal isolates may be attributed to the cryptic aromatic catabolism of different terpenoids and steroids. Finally, analyses have indicated that recent genetic flux appears to have played a more significant role in the evolution of some large genomes, such as LB400's, than others. However, the emerging trend is that the large gene repertoires of potent pollutant degraders such as LB400 and RHA1 have evolved principally through more ancient processes. That this is true in such phylogenetically diverse species is remarkable and further suggests the ancient origin of this catabolic capacity.\n\nAnaerobic microbial mineralization of recalcitrant organic pollutants is of great environmental significance and involves intriguing novel biochemical reactions. In particular, hydrocarbons and halogenated compounds have long been doubted to be degradable in the absence of oxygen, but the isolation of hitherto unknown anaerobic hydrocarbon-degrading and reductively dehalogenating bacteria during the last decades provided ultimate proof for these processes in nature. While such research involved mostly chlorinated compounds initially, recent studies have revealed reductive dehalogenation of bromine and iodine moieties in aromatic pesticides. Other reactions, such as biologically induced abiotic reduction by soil minerals, has been shown to deactivate relatively persistent aniline-based herbicides far more rapidly than observed in aerobic environments. Many novel biochemical reactions were discovered enabling the respective metabolic pathways, but progress in the molecular understanding of these bacteria was rather slow, since genetic systems are not readily applicable for most of them. However, with the increasing application of genomics in the field of environmental microbiology, a new and promising perspective is now at hand to obtain molecular insights into these new metabolic properties. Several complete genome sequences were determined during the last few years from bacteria capable of anaerobic organic pollutant degradation. The ~4.7 Mb genome of the facultative denitrifying \"Aromatoleum aromaticum\" strain EbN1 was the first to be determined for an anaerobic hydrocarbon degrader (using toluene or ethylbenzene as substrates). The genome sequence revealed about two dozen gene clusters (including several paralogs) coding for a complex catabolic network for anaerobic and aerobic degradation of aromatic compounds. The genome sequence forms the basis for current detailed studies on regulation of pathways and enzyme structures. Further genomes of anaerobic hydrocarbon degrading bacteria were recently completed for the iron-reducing species \"Geobacter metallireducens\" (accession nr. NC_007517) and the perchlorate-reducing \"Dechloromonas aromatica\" (accession nr. NC_007298), but these are not yet evaluated in formal publications. Complete genomes were also determined for bacteria capable of anaerobic degradation of halogenated hydrocarbons by halorespiration: the ~1.4 Mb genomes of \"Dehalococcoides ethenogenes\" strain 195 and \"Dehalococcoides\" sp. strain CBDB1 and the ~5.7 Mb genome of \"Desulfitobacterium hafniense\" strain Y51. Characteristic for all these bacteria is the presence of multiple paralogous genes for reductive dehalogenases, implicating a wider dehalogenating spectrum of the organisms than previously known. Moreover, genome sequences provided unprecedented insights into the evolution of reductive dehalogenation and differing strategies for niche adaptation.\n\nRecently, it has become apparent that some organisms, including \"Desulfitobacterium chlororespirans\", originally evaluated for halorespiration on chlorophenols, can also use certain brominated compounds, such as the herbicide bromoxynil and its major metabolite as electron acceptors for growth. Iodinated compounds may be dehalogenated as well, though the process may not satisfy the need for an electron acceptor.\n\nBioavailability, or the amount of a substance that is physiochemically accessible to microorganisms is a key factor in the efficient biodegradation of pollutants. O'Loughlin \"et al.\" (2000) showed that, with the exception of kaolinite clay, most soil clays and cation exchange resins attenuated biodegradation of 2-picoline by \"Arthrobacter\" sp. strain R1, as a result of adsorption of the substrate to the clays. Chemotaxis, or the directed movement of motile organisms towards or away from chemicals in the environment is an important physiological response that may contribute to effective catabolism of molecules in the environment. In addition, mechanisms for the intracellular accumulation of aromatic molecules via various transport mechanisms are also important.\n\nPetroleum oil contains aromatic compounds that are toxic to most life forms. Episodic and chronic pollution of the environment by oil causes major disruption to the local ecological environment. Marine environments in particular are especially vulnerable, as oil spills near coastal regions and in the open sea are difficult to contain and make mitigation efforts more complicated. In addition to pollution through human activities, approximately 250 million litres of petroleum enter the marine environment every year from natural seepages. Despite its toxicity, a considerable fraction of petroleum oil entering marine systems is eliminated by the hydrocarbon-degrading activities of microbial communities, in particular by a recently discovered group of specialists, the hydrocarbonoclastic bacteria (HCB). \"Alcanivorax borkumensis\" was the first HCB to have its genome sequenced. In addition to hydrocarbons, crude oil often contains various heterocyclic compounds, such as pyridine, which appear to be degraded by similar mechanisms to hydrocarbons.\n\nMany synthetic steroidic compounds like some sexual hormones frequently appear in municipal and industrial wastewaters, acting as environmental pollutants with strong metabolic activities negatively affecting the ecosystems. Since these compounds are common carbon sources for many different microorganisms their aerobic and anaerobic mineralization has been extensively studied. The interest of these studies lies on the biotechnological applications of sterol transforming enzymes for the industrial synthesis of sexual hormones and corticoids. Very recently, the catabolism of cholesterol has acquired a high relevance because it is involved in the infectivity of the pathogen \"Mycobacterium tuberculosis\" (\"Mtb\"). \"Mtb\" causes tuberculosis disease, and it has been demonstrated that novel enzyme architectures have evolved to bind and modify steroid compounds like cholesterol in this organism and other steroid-utilizing bacteria as well. These new enzymes might be of interest for their potential in the chemical modification of steroid substrates.\n\nSustainable development requires the promotion of environmental management and a constant search for new technologies to treat vast quantities of wastes generated by increasing anthropogenic activities. Biotreatment, the processing of wastes using living organisms, is an environmentally friendly, relatively simple and cost-effective alternative to physico-chemical clean-up options. Confined environments, such as bioreactors, have been engineered to overcome the physical, chemical and biological limiting factors of biotreatment processes in highly controlled systems. The great versatility in the design of confined environments allows the treatment of a wide range of wastes under optimized conditions. To perform a correct assessment, it is necessary to consider various microorganisms having a variety of genomes and expressed transcripts and proteins. A great number of analyses are often required. Using traditional genomic techniques, such assessments are limited and time-consuming. However, several high-throughput techniques originally developed for medical studies can be applied to assess biotreatment in confined environments.\n\nThe study of the fate of persistent organic chemicals in the environment has revealed a large reservoir of enzymatic reactions with a large potential in preparative organic synthesis, which has already been exploited for a number of oxygenases on pilot and even on industrial scale. Novel catalysts can be obtained from metagenomic libraries and DNA sequence based approaches. Our increasing capabilities in adapting the catalysts to specific reactions and process requirements by rational and random mutagenesis broadens the scope for application in the fine chemical industry, but also in the field of biodegradation. In many cases, these catalysts need to be exploited in whole cell bioconversions or in fermentations, calling for system-wide approaches to understanding strain physiology and metabolism and rational approaches to the engineering of whole cells as they are increasingly put forward in the area of systems biotechnology and synthetic biology.\n\nIn the ecosystem, different substrates are attacked at different rates by consortia of organisms from different kingdoms. \"Aspergillus\" and other moulds play an important role in these consortia because they are adept at recycling starches, hemicelluloses, celluloses, pectins and other sugar polymers. Some aspergilli are capable of degrading more refractory compounds such as fats, oils, chitin, and keratin. Maximum decomposition occurs when there is sufficient nitrogen, phosphorus and other essential inorganic nutrients. Fungi also provide food for many soil organisms.\n\nFor \"Aspergillus\" the process of degradation is the means of obtaining nutrients. When these moulds degrade human-made substrates, the process usually is called biodeterioration. Both paper and textiles (cotton, jute, and linen) are particularly vulnerable to \"Aspergillus\" degradation. Our artistic heritage is also subject to \"Aspergillus\" assault. To give but one example, after Florence in Italy flooded in 1969, 74% of the isolates from a damaged Ghirlandaio fresco in the Ognissanti church were \"Aspergillus versicolor\".\n\n"}
{"id": "9562761", "url": "https://en.wikipedia.org/wiki?curid=9562761", "title": "Microsoft Office PerformancePoint Server", "text": "Microsoft Office PerformancePoint Server\n\nMicrosoft Office PerformancePoint Server is a business intelligence software product released in 2007 by Microsoft. The product was generally an integration of the acquisitions from ProClarity - the Planning Server and Monitoring Server - into Microsoft's SharePoint server product line. Although discontinued in 2009, the dashboard, scorecard, and analytics capabilities of PerformancePoint Server were incorporated into SharePoint 2010 and later versions.\n\nPerformancePoint Server also provided a planning and budgeting component directly integrated with Excel.\n\nMicrosoft offered preview releases of PerformancePoint Server starting in mid-2006. Previews of the product were formed from Business Scorecard Manager 2005 and the Planning Server component. Acquisitions ProClarity and Great Plains brought additional analytics and planning/reporting capabilities, as well as companion products ProClarity 6.3 and FRx.\n\nPerformancePoint Server was officially released in November 2007.\n\nMicrosoft discontinued PerformancePoint Server as an independent product in 2009 and folded its dashboard, scorecard and analytics capabilities into PerformancePoint Services in SharePoint Server 2010.\n\nBusiness monitoring capabilities, including dashboards, scorecards & key performance indicators, navigable reports for deeper analysis, strategy maps, and linked filtering, are provided by PerformancePoint's Monitoring Server component. A Dashboard Designer application that is distributed from Monitoring Server enables business analysts or IT Administrators to:\n\n\nDashboard Designer saved content and security information back to the Monitoring Server. Data source connections, such as OLAP cubes or relational tables, were also made through Monitoring Server.\nAfter a dashboard has been published to the Monitoring Server database, it would be deployed as a SharePoint page and shared with other users as such. When the pages were opened in a web browser, Monitoring Server updated the data in the views by connecting back to the original data sources.\n\nPerformancePoint's Planning Server component supported maintenance of logical business models, budget & approval workflows, enterprise data sources, and it followed Generally Accepted Accounting Principles.\n\nPlanning Server made use of Excel for input and line-of-business reporting, as well as SQL Server for storing and processing business models.\n\nThe Management Reporter component was designed to perform financial reporting and can read PerformancePoint Planning models directly. A development kit was also available to allow this component to read other models .\n\n"}
{"id": "36207361", "url": "https://en.wikipedia.org/wiki?curid=36207361", "title": "Mumasy", "text": "Mumasy\n\nMumasy (Multimedia machine information system) is a vendor-neutral markup language for document authoring based on XML, similar to DocBook and DITA.\n"}
{"id": "26738463", "url": "https://en.wikipedia.org/wiki?curid=26738463", "title": "Musée de l'Imprimerie", "text": "Musée de l'Imprimerie\n\nThe Musée de l'Imprimerie is a museum in Lyon, France, with the mission of enhancing, conserving, documenting and valuing the heritage of printed books and graphic arts.\n\nThe museum was inaugurated in 1964. In 2006 the \"Grand Guide Michelin France\" awarded it two stars out of three and in 2007, the museum had 16,819 visitors.\n\nThe Musee de l'Imprimerie was established in Lyon because Lyon had been a centre of printing and the book trade in Europe in the 15th and 16th centuries and the city held large historical collections of books and the graphic arts. The museum was designed by the master printer and historian Maurice Audin, with the historian of the book, Henri-Jean Martin, then chief curator of the Library of Lyon. There are two banners before the entrance of the Hôtel de la Couronne, which hosted the meetings of the City of Lyon aldermen from 1604 to 1655 and which is currently the headquarters of the Musée de l'Imprimerie, located at 13 rue de la Poulaillerie. In 1957 the building was given to the City of Lyon by the banking corporation, LCL S.A., and on 8 June 1963 the mayor of Lyon, Louis Pradel, inaugurated the Musée de la Banque on the occasion of the centenary of LCL. Finally the current museum was opened in 1964.\n\nAlan Marshall, a former printer, was its director until May 2015. He was replaced, in summer 2015, by Joseph Belletante, researcher in media history.\n\nThe museum has works by early printers of Lyon, including Martin Husz, Josse Bade, Sébastien Gryphe, Etienne Dolet, Jean de Tournes, Guillaume Rouillé and Bernard Salomon. It shows the beginnings of Western printing from the fifteenth century - including examples of the work of Sweynheim and Pannartz, Aldus Manutius, Johann Froben, the Estiennes and Christopher Plantin - to the twentieth century. It includes displays of the 20th-century inventions, Higonnet and Moyroud's Lumitype-Photon phototypesetter and the BBR system of computer typesetting.\n\n\n"}
{"id": "56068639", "url": "https://en.wikipedia.org/wiki?curid=56068639", "title": "Nomadic (company)", "text": "Nomadic (company)\n\nNomadic (sometimes referred to as Nomadic VR or NomadicVR), is a location-based virtual reality entertainment company based in San Rafael, California, in the United States.\n\nNomadic is a virtual reality (VR) entertainment company based in San Rafael, California. Nomadic partners with film and gaming companies to create virtual reality \"arcades\", or various commercial brick and mortar locations such as malls and theaters, where participants' tactile and virtual realities are merged. Users wear headsets and computer backpacks to explore virtual environments, and often use physical props as part of the VR narrative. Venues host modular sets that can be easily adapted to accommodate regularly-updated VR content.\n\nThe company's founders have backgrounds in the brand, film, gaming, and retail industries. Doug Griffin serves as chief executive officer, and Rick Schulze serves as creative director. John Duncan is the \"head of physical production\", and Kalon Gutierrez holds the role of \"head of growth\".\n\nNomadic's initial $1 million in funding was provided by \"family and friends\". The company had six full-time employees, as of 2017.\n\nThe company unveiled its prototype at the CinemaCon trade show, which is presented by the National Association of Theatre Owners, in Las Vegas in March 2017. In June 2017, Nomadic received $6 million in seed funding from Horizons Ventures, Maveron, Presence Capital, Verus International, and Vulcan Capital, which was used to hire staff, develop technology, and enter new markets and venues. The company's experience was made available to the general public in the Wonderful Worlds of Whampoa mall in Hong Kong in mid 2017. The Technicolor Experience Center, in Culver City, California, hosted a temporary installation in October. Nomadic plans to launch public location-based VR experiences by early 2018.\n\n"}
{"id": "2000303", "url": "https://en.wikipedia.org/wiki?curid=2000303", "title": "Peter Desaga", "text": "Peter Desaga\n\nPeter Desaga was a German instrument maker at the University of Heidelberg who worked with Robert Wilhelm Bunsen. In 1855, Desaga perfected an earlier design of the laboratory burner by Michael Faraday into the Bunsen burner. The Desaga family held the right to market the burner for generations, as part of an agreement made with Bunsen. The Bunsen burner was essential to the invention of the spectroscope by Robert Wilhelm Bunsen and Gustav Robert Georg Kirchhoff.\n\nPeter Desaga's son, Carl Desaga, founded C. Desaga.\n\nRetrieved November 9, 2011.\n"}
{"id": "26707357", "url": "https://en.wikipedia.org/wiki?curid=26707357", "title": "Prüfening dedicatory inscription", "text": "Prüfening dedicatory inscription\n\nThe Prüfening dedicatory inscription () is a high medieval inscription impressed on clay which was created in 1119, over three hundred years before Johannes Gutenberg, by the typographic principle. The inscription plate belongs to the Prüfening Abbey, a former Benedictine monastery, in Regensburg, Germany.\n\nThe Latin inscription is still at its original location in Prüfening Abbey, attached to one of the main pillars of its church. It reports the consecration act of the monastery in honour of St. George, carried out by the two bishops Otto of Bamberg and Hartwig of Regensburg. The inscription plate specifies the year of the act and, by implication, its own date as 1119 (•MCXVIIII•). It was made of baked clay, painted over in an alternating, red white pattern, and is approximately 26 cm wide, 41 cm high and 3 cm thick, with a crack running through its entire breadth. The sunk letterforms are the classical \"capitalis monumentalis\" or Roman square capitals. Copies are at display in several German museums, including the Gutenberg Museum at Mainz.\n\nThe unusual sharpness of the inscription letters has long led epigraphists to believe that they were not carved by hand into the clay. The typographic character of the inscription was recently demonstrated in a systematic examination of the text body by the typesetter and linguist Herbert Brekle. His findings confirm that the text was produced with a printing method similar to that of the Phaistos Disc: The 17-line text was created by pressing individual, pre-formed stamps (probably made of wood) into the soft clay in a way that, for each letter which occurred more than once, the same letter stamp was re-used, thereby producing identical imprints throughout the text. Thus, the essential criterion for typographic text production was met, namely the repeated use of identical types for a single character. In applying this technique, it is not relevant that the Prüfening inscription was made by stamping letters into the clay and not − as later practiced by Gutenberg − by printing on paper, since neither the technical execution nor the print medium define movable type printing, but rather the criterion of type identity:\n\nBy projecting the text letters one upon the other (e.g., all \"A\"s onto one another) at high magnification, the consistent type identity of the dedicatory inscription could be demonstrated beyond doubt. An additional indication that its creator had worked with reusable types is the marked tendency of some letters to tilt to the right or left; in those case the artisan apparently did not succeed in setting up the letter stamps completely parallel to the lateral borderline of the plate. The evidence of the skewed letters, but most importantly the observation that the type token criterion was met throughout the text prove the \"typographic character of the Prüfening dedicatory inscription with certainty.\"\n\nA fragment of another inscription plate found close to the monastery indicates that the Prüfening abbey inscription did not remain an isolated phenomenon, but that at least locally the typographic production method was applied more frequently.\n\nIn the cathedral of Cividale, the silver altarpiece of Pellegrino II, the patriarch of Aquileia between 1195 and 1204, was inscribed in Latin by the means of individual letter punches (instead of stamps). Apart from stamping and punching, another typographic method existed which followed the scrabble principle: for decorating the paved floors of monasteries and churches, individual letter tiles were burnt and then so assembled that they formed Christian inscriptions on the floor. This technique seemed to be fairly widespread, with known examples ranging from England over the Netherlands to Germany.\n\nThe Latin inscription runs written out in full:\n\nTranslated into English:\n\nFurther medieval techniques\n\n"}
{"id": "12837013", "url": "https://en.wikipedia.org/wiki?curid=12837013", "title": "Reactive material", "text": "Reactive material\n\nIn the U.S. military, reactive materials (RM) are a new class of materials currently being investigated by the Office of Naval Research and others as a means to increase the lethality of direct-hit or fragmentation warheads. Reactive materials are similar to insensitive high explosives, but are usually thermite-like pyrotechnic compositions of two or more nonexplosive solid materials, which stay inert and do not react with each other until subjected to a sufficiently strong mechanical, electrical or laser stimulus, after which they undergo fast burning or explosion with release of high amount of chemical energy in addition to their kinetic energy. Fragments or projectiles made of such materials have therefore greater damaging effect than inert ones, with expected lethality increase up to 500%.\n\nThe material classes under investigation are thermites, intermetallic compounds, metal-polymer mixtures (e.g., magnesium/teflon/viton-like), metastable intermolecular composites (MIC), matrix materials, and hydrides. These materials must be strong enough to act as structural components, be sufficiently stable to survive handling and launch, to penetrate a target, and sufficiently unstable to reliably ignite on impact.\n\nThe mixtures under investigation include one or more finely powdered (down to nanoparticle size) metalloids or metals like aluminium, magnesium, zirconium, titanium, tungsten, tantalum, uranium or hafnium, with one or more oxidizers like teflon or other fluoropolymer, pressed or sintered or bonded by other method to a compact, high-density mass. To achieve a suitable reaction rate and insensitivity to impact, friction, and electrostatic discharge, fuel particles have sizes usually between 1-250 µm. A standard composition is aluminium-teflon (Al-PTFE).\n\nMetals which can form intermetallic compounds by an exothermic reaction are another class of candidate materials. An example is a laminate of thin alternating layers of aluminum and nickel, commercially available as NanoFoil.\n\nThe RM weapons under development include an active protection system defensive grenade for intercepting incoming missiles or grenades and detonating them at a safe distance, and the BattleAxe warhead that covers a wide area with RM fragments with devastating results to soft targets, while the unexploded fragments left behind have very low lethality versus conventional cluster bomb remains.\n\nUnder research are materials with high mechanical strength, high density, high energy density, and which can rapidly convert from a consolidated structural material to fine powder with large surface area, be dispersed and then ignited to produce a large thermobaric blast.\n\nA palladium-clad aluminum wire, known under trademark \"Pyrofuze\", is used as a pyrotechnic initiator.\n\nReactive materials also have non-weapon uses. Thin layers of reactive materials, clad with a solder, are used for reactive bonding, e.g., in electronics, or for brazing, such as in composite armor plates.\n\n"}
{"id": "10169528", "url": "https://en.wikipedia.org/wiki?curid=10169528", "title": "Reading Works", "text": "Reading Works\n\nWestern Electric's Reading Works in Berks County, Pennsylvania was a manufacturer of integrated circuit and optoelectronic equipment for communication and computing. The work force grew to nearly 5,000 by 1985 making the Reading, Pennsylvania, facility one of Berks County's largest industrial employers. As a part of Western Electric and the Bell System, it changed it masthead many times during its life.\n\nThe origins can be traced back to 1876, when Elisha Gray lost his race to invent the telephone. Alexander Graham Bell put in a patent application just hours before Gray filed one. Gray nevertheless left his mark on the telephone industry in 1869 when he and Enos N. Barton formed Gray and Barton, a small manufacturing firm in Cleveland, Ohio. Three years later, the firm, now based in Chicago, was renamed the Western Electric Manufacturing Co. By 1880 it was the largest electrical manufacturing company in the US. A year later when growth of the telephone network was outstripping the capacity of smaller suppliers, American Bell purchased a controlling interest in Western Electric Company and made it the exclusive manufacturer of equipment for the Bell telephone companies. Western Electric Company was responsible for developing as well as manufacturing Bell equipment. In 1907, Theodore N. Vail combined the AT&T and Western Electric engineering departments into a single organization that became Bell Labs in 1925. Western Electric became the manufacturing arm of the Bell System.\n\nIn 1951, just four years after the invention of the transistor by Bell Laboratories, the Allentown Plant was opened to manufacture the first transistors. Jack Morton was assigned to develop transistors for manufacture. He had been responsible for inventing and providing the military with microwave components during WWII and knew how to get an idea from the lab, into production, and into the field. He established a system of branch labs at several Western Electric plants, consisting of teams of Bell Labs scientists and engineers focused on production engineering and acting as liaison with their colleagues back in Murray Hill. Morton fine-tuned this approach at the new Western Electric plant in Allentown, Pa., which produced electronic devices and components for the Bell System. He set up a Bell Labs semiconductor development group there and put Eugene Anderson in charge.\n\nIn 1952, operations in Reading began when Western Electric Company (WECO) converted the old Rosedale knitting mill in Laureldale into a factory that produced electronic components for the U.S. government for use by the military and the space program. On August 22, 1952, Western Electric Company opened the doors of its new electronics manufacturing facility in Laureldale. Growth was slow but steady. By the end of 1952, there were 130 employees, and by the end of 1953, 253 employees.\n\nOn January 12, 1956, a diffused base transistor was unveiled at Laureldale before top military brass at a solid-state diffusion symposium. That was the same year that Bell Labs' scientists Bardeen, Brattain, and Shockley received the 1956 Nobel Prize in physics for the invention of the transistor. \"Bell Laboratories scientists in Murray Hill, N.J., may have won the Nobel Prizes and gotten most of the press, but Allentown and Reading delivered the goods,\" notes Stuart W. Leslie, a historian of science at Johns Hopkins University in Baltimore.\n\nIn 1958, a group of Bell Laboratories scientists moved to Reading, Pennsylvania, from other locations and started the Laureldale Laboratory in the Laureldale Western Electric Plant. Bell Labs was a division of Western Electric. Initially the Laureldale Laboratory designed electron tubes (vacuum tubes). Eventually, after becoming the Reading Laboratory, it designed semiconductor devices which eventually included integrated circuits, light emitting diodes, and lasers.\n\nBy the late 1950s, the increased demand for its products necessitated Western Electric building a larger facility, so plans were developed for a building at the North 11th Street site. The Greater Berks Development Fund built the Reading plant at the end of 11th street for $2 million to lease to Bell Labs and Western Electric.\n\nGround breaking took place in November 1960, and on January 2, 1962, Western Electric took possession of the new building, Building 30 (the manufacturing building).\n\nIn 1964, Western Electric bought the building. By 1966 all facilities had moved from the Laureldale plant to the Muhlenberg Township, Pennsylvania, site. The new facility was called the Reading Works and the branch of Bell Labs was called the Reading Labs.\n\nIn 1967, when the Reading Works celebrated its 15th anniversary in Berks County, it employed about 2,600 employees. Various additions since the mid-1960s increased the manufacturing space to . Construction on the office building (Building 20) began in 1980, and the building was first occupied in 1982.\n\nIn 1984 the Bell System broke up into the various Baby Bell operating companies and AT&T. As a result of this divestiture in 1984, the Western Electric plant became an AT&T Technology Systems (AT&T Technology Systems) location as part of AT&T, supplying devices for use in the former Bell System's network. By 1984, employment had reached what would be an all-time high of 4,900. In 1988, microchip and fiber-optic component manufacturing was combined into an AT&T organization called AT&T Microelectronics. In 1989 the AT&T work force nationwide was 297,000 and while employment at the Reading Works was 3,200. In 1992 the Reading Works of AT&T Microelectronics had 3,300 workers and provided an annual payroll of $100 million. The product mix included lightwave components, linear bipolar integrated circuits, high voltage integrated circuits, high speed silicon integrated circuits, and gallium arsenide integrated circuits. A satellite manufacturing building, Building 10, was constructed on North 13th Street, just north of the General Mail Facility, in 1992. The same year the Falconer building across the street was also used. AT&T Reading Works was the No. 2 employer in Berks County in 1993, but that was soon to end. In February 1994, AT&T Reading Works announced that it would be cutting 850 jobs over a 3-year period. In 1994 the Reading Works' work force was reduced from 2,929 to 2,700 with most of the cuts in the Lightwave unit. The Lightwave unit makes fiber-optic laser transmitters and receivers. In 1995 the Reading Works' work force stood at 2,400 including AT&T Microelectronics and Bell Labs as it prepared for the spin off from AT&T into Lucent Technologies.\n\nUnder the 1996 restructuring of AT&T, AT&T Technologies became Lucent Technologies. The Lucent Technologies Reading, Pennsylvania, facility became both a Lucent Microelectronics and a Lucent Optoelectronics facility, designing and manufacturing optoelectronic and integrated circuit components for applications in the telecommunications and computing industries.\n\nThe Lucent Reading Plant was unique in the semiconductor industry because it manufactured both optoelectronic and integrated circuit components. The facility received a $6 million renovation to boost its optoelectronics manufacturing capacity.\n\nIn addition to serving the traditional communications markets, the Lucent Optoelectronics portion of the facility provided a family of transmitters and receivers for use in network computing applications. Lucent was also a leading player in the cable TV and hybrid fiber coaxial markets. In addition to Reading, Pennsylvania, other Lucent Optoelectronics facilities were located in Breinigsville, Pennsylvania; Murray Hill, New Jersey; Alhambra, California; and Matamoros, Mexico.\n\nThe Lucent Microelectronics portion of the facility produced linear bipolar, high voltage and gallium arsenide integrated circuits. These microchips were used in tone ringers, data processing, voltage regulators, video distribution, and in the industrial, computer, communication and instrumental markets. In addition to Reading, other Lucent Microelectronics integrated circuit sites included Allentown, Pennsylvania; Orlando, Florida; Bangkok, Thailand; Tres Cantos, Spain; and Singapore. \n\nIn 1996 the Reading Works' work force stood at 2,450 including AT&T Microelectronics and Bell Labs as it made the transition from AT&T into Lucent Technologies. The spin off of AT&T manufacturing units as Lucent Technologies became necessary as these units increasingly found that their prospective customers were AT&T competitors. The divestiture of the manufacturing units made them suppliers rather than competitors, opening up new markets to Lucent and to the Reading Works. At the same time it caused the anxiety that comes with change. On October 1, 1996, Lucent Technologies became independent of AT&T. The Reading Works became Lucent Technologies Reading Facility. It employed 2,177 people, down considerably from 4,900 in 1985. By the end of 1997, the Reading Facility workforce had declined and remained stable at 2,000. By the end of 1998, the Reading Facility workforce had rebounded to 2,177. In 1999 a pickup in Lightwave business caused expansion of both the Reading Facility and the Breinigsville plant.\n\nThe Reading Plant's heritage, combined with constant innovation and product quality, positioned the Reading site as one of the largest semiconductor facilities in the world. In 2000, Lucent Microelectronics and Optoelectronics were reorganized as Agere Systems with the intention of spinning it off as an independent company. Agere Systems Inc. produced high-tech components such as opto-electronics products, which use light-wave technologies to transmit information, and integrated circuits, which are miniaturized chips used in computers and communications. The opto-electronics parts were used in systems such as submarine communication cables, cable transmitters, cable receivers, laser components, and network computing devices. The integrated circuits were found in a wide array of electronic products from modems and computers to cell phones and telephone offices to video equipment and digital television. After becoming Agere Systems, by the end of 2000, the Reading Facility became the Muhlenberg plant and had grown its workforce by 800 to 3,000 as the anticipated lightwave business materialized. In 2001, Agere Systems's stock went public in late March. The spin-off was completed on June 1, 2002. By mid-2001, Agere cut 508 jobs at the Reading Works. These layoffs continued in waves as conditions in the semiconductor market deteriorated and by the end of the year only had a workforce of 1,546.\n\nOn January 24, 2002, Agere Systems announced that it would be closing the Reading Works in 12 to 18 months. The planned changes involved closing the Breinigsville, Pennsylvania plant in Lehigh County, Pennsylvania, which was opened in 1988; selling the Orlando plant in Florida; and consolidating several locations in New Jersey. All operations were consolidated at the Allentown, Pennsylvania, headquarters location and the New Jersey locations. About 1,500 workers were transferred from Reading to Allentown where 3,200 workers were employed prior to the relocation. As Agere was leaving, Legerity, Inc., assumed some of the operations formerly done by the Muhlenberg plant in the old Building 10 on North 13th Street. In this facility Legerity assembled 40 former Agere circuit-design, physical-design, application-design and process development engineers to support the analog line card integrated circuit business it purchased from Agere. Legerity is a design facility that uses other companies foundries to manufacture its products. In May 2003, Agere Systems Inc. ended all manufacturing and began decommissioning its Muhlenberg Township plant. The last 346 manufacturing employees were laid off. About 50 employees — mostly maintenance — remained at the plant until a buyer was found.\n\nAgere built a $165 million World Headquarters building in Hanover Township, Lehigh County, Pennsylvania. This building was started in 2001 and completed in 2003. It brought together research and development facilities from Breinigsville and Muhlenberg Township. It absorbed about 2,000 workers from these two facilities. Agere Systems tried unsuccessfully to sell its Union Boulevard plant in Allentown, where the first commercial production line for transistors was set up in 1951. Agere Systems demolished the manufacturing part of the Union Boulevard facility. The company continues to use the offices and wet labs in the remaining part of the building. Its headquarters building is nearby in Hanover Township, Pennsylvania. In 2003, Agere Systems sold the chip plant and research center in Breinigsville to TriQuint Semiconductor, which also bought the company's fiber-optic components division. The facility, now under different ownership, is a multi-tenant technology park.\n\nAt the end of 1999 shares of Lucent stock hit a high of nearly $80. After spinning off Agere Systems, Lucent shares dropped to around $4.50 and later dropped to $0.55 in October 2002. After being spun off, Agere shares were about $4 and dropped to a low of $0.50 in October 2002. Agere started 2000 with 18,000 employees. By the end of the year it had only 10,000 employees. By the end of 2001 the number of employees had dropped to about 7,000. The last wafer starts at the Reading Works were scheduled for April, 2003 and the last shipments were scheduled for May, 2003. The doors locked on May 16, 2003. Starting May 17, the Reading work force consisted of 100 employees who cleaned up the facility and disposed of equipment. In July the work force was down to 50 maintenance employees who manned the facility while an attempts were made to sell it or at least rent or lease it. On December 13, 2005, it was announced that Agere had signed a sales agreement with a Montgomery County, Pennsylvania, developer to sell the Agere Systems Inc. property in Muhlenberg Township, Pennsylvania, and projects the return of 1,000 jobs to the site within 18 months, with more jobs to follow.\n\nThe last USA based Agere Systems manufacturing plant in Orlando, Florida, which once employed 1,800, was closed on September 30, 2005, after 20 years of semiconductors manufacture and sold in 2007. The company has plants in Singapore and Thailand, and operated 22 sales offices and 16 research and development facilities throughout the world. Its key centers are in Ascot, U.K.; Bangalore, India; San Jose, CA, U.S.; Shanghai, China; and Singapore as well as the world headquarters in Lehigh Valley, PA.\n\nAgere Systems still maintained its position as a key chip supplier for cell phones and hard disk drives. However, the chips it supplied were purchased from outside chip foundries or made offshore rather than made locally. In 2003, 3,000 of the best jobs in town disappeared when Agere Systems closed the Reading Works. But the jobs won't come back when the economy does; like many other high-tech companies, Agere Systems moved production overseas.\n\nOutsourcing is a new name for a long-standing phenomenon: the movement of jobs from the USA to countries where wages, benefits and the cost of living are much lower. In the 1970s and 1980s, heavy manufacturing jobs went to other countries by the tens of thousands. The result was cheaper goods for U.S. consumers and less pollution in many of the nation's industrial cities. Economists who backed the trend envisioned a new \"knowledge economy\" in which well-trained Americans would become the world's designers, innovators and administrators. The dirty work would be sent overseas.\n\nNot to take advantage of those countries' pools of highly educated, relatively low-wage workers would be foolish, Agere Systems officials said. \"Our customers are very demanding,\" says John Harris, an engineer and marketing manager at Agere's Allentown, Pennsylvania, headquarters. \"They're under intense pressure to deliver extremely high quality at extremely low cost. That pressure comes right back on us.\"\n\nOn December 4, 2006, Agere's President and CEO, Rick Clemmer, announced that it would be bought by LSI Logic Corporation of Milpitas, California in an all-stock transaction. On March 29, 2007, this merger was approved by shareholders of both companies, making it official. The companies together own a patent portfolio consisting of more than 10,000 issued and pending U.S. patents. Spun off by Lucent Technologies in 2001, Agere Systems was the creation of a corporate behemoth, while LSI was born 25 years ago as a tiny startup. LSI Logic already has decided to dump the Agere name, which once symbolized the Lehigh Valley's aspirations to become a technology hub. Compared to Agere Systems, LSI Logic has run a tight ship. It generates roughly 20 percent more revenue — $2 billion — with fewer employees worldwide: 3,900, compared to Agere's 5,300. LSI Logic will use the Agere Systems facilities as the center of its research operations, but the combined company's headquarters will be in Milpitas, California.\n\nLSI Logic has come a long way since 1981, when Wilfred Corrigan founded the company with $6 million of venture capital. Corrigan, a native of Liverpool, England, moved to the United States to pursue a career in electronics. He climbed the ladder at Motorola in Phoenix, Arizona, before becoming CEO of Fairchild Semiconductor in Mountain View, California, in the mid-1970s. The launch of LSI Logic marked his transition to entrepreneur. The company went public in 1983. By the mid-1990s, LSI Logic was selling chips to Sony for its PlayStation video game machine. And in 2001, it made its first major acquisition, C-Cube Microsystems, in a stock deal valued at $851 million.\n\nIn recent times, LSI Logic has followed a strategy similar to Agere Systems. This year, the company sold an Oregon semiconductor manufacturing facility and acquired two smaller companies, in Israel and India. Now it's swallowing up Agere Systems, which is nearly its equal, in terms of revenue but not productivity. Hence ends the saga of the semiconductor plant that was built in Reading in 1952.\n\nAudubon Land Development of Oaks, Montgomery County, Pennsylvania, bought the old Reading Works in December 2005 for an undisclosed amount. Agere Systems spokesman Glen Haley confirmed the deal. Agere Systems had been asking for $8 million for the property, but Haley and Call declined to disclose the purchase price. The assessment of the property was lowered to $9.5 million from $26.3 million after Agere Systems appealed. On Tuesday, March 14, 2006, Urban Expositions, a Georgia-based trade show company, announced it would hold the 10th annual Philadelphia Gift Show at the Reading center July 23–26, 2006. The facility is being called the Greater Reading Expo Center. A company press release calls the event, with an expected 1,400 booths, the largest regional gift show in the country. Gene Call, an Audubon spokesman, said Audubon's subsidiary, Stonepoint Management Corp., which is leasing the Agere Systems building, would run the exposition center. Stonepoint would use , he said. Stonepoint is exploring other uses but has not made firm plans, he said.\n\nCrystal Seitz, president of the Greater Reading Convention & Visitors Bureau, said a typical convention center with a steady stream of shows generates about $150 million for a local economy, including money spent for lodging and meals. Jon C. Scott, president of the Berks Economic Partnership, said he has met several times with Audubon officials and is excited about the prospects for the center. “It opens up the type of exhibits that would never have been available before,” Scott said. “It leads to other intriguing possibilities.” Some of the shows scheduled for the facility included: Philadelphia Gift Show which includes Birdwatch America-Philadelphia, Great Train Expo, Bead Fest Philadelphia, Greater Philadelphia Pet Expo, Great American Guitar Show, Sports Card & Memorabilia Show, Home & Garden Show, and The Greater Reading Sport, Travel & Outdoors Show.\n\nSuccess of the Expo Center is in part due to the closing of the Fort Washington Exposition Center in Montgomery County and the Pennsylvania Expo Center in Lehigh County and in part due to the of inside space, several auditoriums, numerous meeting rooms, 13 loading docks, ample parking and a full-service cafeteria among its amenities, the expo center. Muhlenberg Township waived the 10% amusement tax on admission to the expo center from January through September 2007. This was an attempt to allow the Expo Center to become better established. The township estimates future revenues at $50,000 per year.\n\nThe Pennsylvania Department of Community and Economic Development included the StonePointe Center, the former Agere complex in Muhlenberg Township, which includes the Greater Reading Expo Center, as part of the Greater Reading Keystone Innovation Zone and invested $235,000 to fund its operations. Also included in this zone is TEK Park, the former home of Lucent/Agere Optoelectronics in Breinigsville, Lehigh County, which houses a number of industrial tenants and the Kutztown University Innovation Center.\nBuilding 30 is now called the \"Flex Building\" and building 20 is the \"Office Building\". They are keeping their options open. Here is what they say: \"Imagine a state of the art business center, with more than one million square feet of available space for office, manufacturing and distribution; a facility with high-tech infrastructure and easy access to transportation. Imagine a convenient location near Reading, Pennsylvania, with professional on-site management to support your business. Imagine your business at StonePointe Center.\" \nThe Expo Center is the latest in venues that mark a renaissance in Reading. It started with the opening of the Sovereign Center and its sister the Sovereign Performing Arts Center. Now it includes the Goggle-Works Center for the Arts, and the Greater Reading Expo Center.\n\n"}
{"id": "33789596", "url": "https://en.wikipedia.org/wiki?curid=33789596", "title": "Robert Galloway", "text": "Robert Galloway\n\nRobert Lindsay Galloway (22 February 1844 – 24 February 1908) was a Scottish mining engineer and author, the son of William Galloway (1799–1854), a Paisley shawl manufacturer and coal master and Margaret Lindsay (1818–1902) daughter of Thomas Lindsay, a Glasgow brewer. He was born in Paisley, Scotland\n\nGalloway was the younger brother of Sir William Galloway, mining engineer and professor of mining at the University College of Wales in Cardiff. He married Elizabeth Baird, daughter of James Baird, farmer from Sorn in Ayrshire on 14 November 1871. They had two sons, William Galloway born 1872 in Newcastle and James Baird Galloway born in 1874 at Gateshead. His wife and younger son died in 1875 and his son William was brought up by his maternal grandparents in Sorn, and became a farmer before moving to Essex.\n\nHis half-brother John Galloway who lived in Ayrshire, and younger brothers, T. Lindsay Galloway and James Jack Galloway of Glasgow, were also coal masters. John's son James William Galloway, coalmaster in Ayrshire, and Sir William's son Christian Francis John Galloway, a mining engineer and author in Cardiff were the only members of the next generation to continue in the industry.\n\nRobert Galloway died in Scotland on 24 February 1908 at Bridge of Allan, in Stirlingshire.\n\nWhen Galloway was 27 he was a mining engineer and coal master employing five men in 1871 at Sorn in Ayrshire. After he married he moved to County Durham and qualified as a certificated colliery manager and became a member of the North of England Institute of Mining and Mechanical Engineers at Ryton on Tyne on 6 December 1873. While he was a mining engineer and colliery manager in the Newcastle area and in Scotland, he became known as a historian specialising in writing about the mining industry and the steam engine.\n\nOn 30 April 1879 Galloway presented 'Earliest records connected with the working of coal on the banks of the River Tyne' to a meeting of the Society of Antiquaries of Newcastle upon Tyne. In 1880 his book 'The Steam Engine and its Inventors' was published. Two years later his 'A History of Coal Mining in Great Britain' was printed.\nGalloway helped organize a mining exhibition between 1–24 September 1885 at Burnbank Drill Halls, Glasgow and he wrote a 'Review of the Progressive Improvements of Mining in Scotland' as an introduction to the exhibition catalogue. In 1906 papers relating to the history of the coal trade and the invention of the steam engine were published.\n\n"}
{"id": "32613770", "url": "https://en.wikipedia.org/wiki?curid=32613770", "title": "Saros (software)", "text": "Saros (software)\n\nSaros is an Eclipse plug-in for distributed collaborative text editing that can support five participants at once (typically two or three). It can be used for a variety of purposes ranging from simple remote code review, over Remote pair programming, through to variants of Side-by-side programming with more than two participants.\n\nAll members of a session have an identical copy of Eclipse projects and Saros keeps these copies in sync as editing progresses. \nAt the beginning of a session, Saros will automatically synchronize the contents of the Eclipse project from the initiator of a session (\"host\") to the other participants.\n\nDuring the session, markers in every participant's viewport will indicate who is currently seeing what and who made recent changes where (\"awareness information\"). \nExplicit highlighting of text for others is done by means of simple text selection which will be shown in a color that indicates who performed the selection.\n\nSeparate audio conferencing (such as Skype) completes the collaboration scenario. Basic whiteboard sketching functionality is built in.\n\nWith multiple concurrent writers, write conflicts can occur. Saros will resolve them consistently by means of the Jupiter algorithm (an architecture for operational transformation).\n\nSaros uses an XMPP/Jabber server for session initiation. It will also use XMPP for subsequent communication if and insofar as some participants cannot be reached directly via IP (typically because their computer is behind a firewall or NAT). \nHowever, Saros uses Socks5 to provide low-latency, high-bandwidth connections whenever possible and is able to apply UPnP for traversing the NATs of typical home networks.\n\nCompared to cooperation via screensharing, working with Saros has a number of \nadvantages:\nThe latter (if used wisely) can be advantageous even in comparison to local pair programming.\n\nSaros is an open source project under GPL. It is hosted at SourceForge.\n\n"}
{"id": "3333009", "url": "https://en.wikipedia.org/wiki?curid=3333009", "title": "Self-checkout", "text": "Self-checkout\n\nSelf-checkout (also known as self-service checkout and as semi-attended customer-activated terminal, SACAT) machines provide a mechanism for customers to process their own purchases from a retailer. They are an alternative to the traditional cashier-staffed checkout. The customer performs the job of the cashier themselves, by scanning and applying payment for the items.\n\nAs of 2013, there were 191,000 self-checkout units worldwide, and the number was estimated to reach 325,000 units by 2019. The machines were invented by David R. Humble.\n\nIn self-checkout systems, the customer is required to:\n\nPayment by various methods may be accepted by the machines: card via EFTPOS, debit/credit cards, electronic food assistance cards, cash via coin slot and bank note scanner, and in-store gift cards where applicable. Most coupons also have barcodes and can be scanned the same way that items are scanned, although some require entry by a member of staff.\n\nThe benefit to the retailer in providing self-checkout machines is in reduced labour costs: one attendant can often run four to six checkout lanes with the work of the cashier now being assumed by the customer. The size of a self-checkout machine is also smaller than a traditional checkout manned by a cashier; thus, a store can save space, which could be used for more shelves, display cabinets or additional checkouts.\n\nCustomers who do not want to interact with the cashier can use the self-checkout.\n\nSelf-checkout can also sometimes be faster than using a cashier lane. This can reduce the length of checkout lines (British: queues) and wait times. In a survey by NCR, 42% of customers said they liked the convenience of self-checkout, while 39% said it was faster than the cashier-assisted line. 90% of those surveyed responded as being users of self-checkout, with 7% of respondents saying they will always use self-checkout regardless of store lines and number of items. Survey respondents in Italy and Australia said they \"always use self-checkout\" at a rate of 13% and 9% respectively.\n\nOne advantage is that self-checkouts can, if the necessary investment is made, provide a partly multilingual service. (It cannot be fully bilingual unless the goods are labelled in all the relevant languages, which is often not the case.) For example, Tesco's Welsh stores which can serve customers in Welsh, whereas finding enough fluent Welsh-speakers as staff can be difficult because in some areas only a small proportion of local people have Welsh as their first language. \n\nSelf-checkout is vulnerable to some shoplifting techniques. In some cases the machine will pick up the attempt to steal, or cause the shopper to alter their behavior (e.g. an item can be put not on the scales but somewhere else where it should not be put, and this may be noticed by the system supervisor). For example, in 2007, a man was charged with replacing the tag of a plasma TV with a $4.88 DVD, and trying to purchase it through self-checkout.\n\nStudies suggest that a large proportion of shoppers are tempted to shoplift due to the relative ease of fooling self-checkouts. For example, a person who (initially without intent to steal) does not scan an item, may remember that this was easy, and fail to scan other items deliberately. A 2012 survey with 4,952 respondents in the UK found that a third of shoppers had stolen this way, with around a quarter of the remainder stating they were deterred by the risk of detection. Non-barcode items such as produce, and store staff overriding (or ignoring) checkout alerts, were singled out as vulnerabilities, and poverty was not seen as a major factor. The founder of one store video surveillance system estimated that \"Theft — intentional or not — is up to five times higher with self checkout than when cashiers are working\", although behaviour of shoplifters is becoming well known, and stores are now better at shoplifting detection. A 2014 survey in of 2,634 respondents confirmed the same general findings, but commented that the cost of additional theft was evidently seen as \"tolerable\" compared to the cost of other processes, such as manned checkouts, and harm due to poorer customer service arising from the slowness of manned versus automated checkouts.\n\nIn 2002, a study was carried out where people with disabilities used self-checkout machines, and found that existing checkout machines were not designed for accessibility.\n\nSelf-checkouts are also criticized for reducing the possibilities for customers and store staff to interact, and adversely affecting customer service in general. Self-checkout lanes may lack some rather basic customer interactions, like informing the customer that a coupon was not accepted, and why.\n\nBeing more complex, self-checkouts are more prone to failure. For example, they use scales to weigh goods in the bagging area, and if the scale fails, the machine does not work. Also, in a manned checkout lane, any simple problems like lack of receipt paper would be immediately fixed by the operator, while self-checkouts may not be fixed for quite some time. This lack of reliability can be compensated for by having excess lanes available or enough staff on hand to perform immediate maintenance.\n\nAn alternative system (self-scanning) consists of a portable barcode scanner that is used by the customer to scan and bag items while shopping. When the customer has finished shopping, the scanner is brought to a checkout kiosk, where the information from the barcode scanner is downloaded to the kiosk, usually in conjunction with a customer loyalty card. The customer pays and receives a receipt at the checkout kiosk. The integrity of the system is maintained through the use of random audits or RFID. Walmart owned warehouse club, Sam's Club allows customers to download an app and scan items into their cart using a mobile application. In summer 2018, Walmart China launched its Wechat-based \"Scan and Go\" program, allowing customers to scan items into their carts without downloading another mobile app, while paying through Wechat Payment or Alipay. The \"Scan and Go\"program carried 30% of all payments made in Chinese stores, and even improved sales in certain markets by 10%.\n\nIn December 2016, Amazon announced a bricks and mortar store in Seattle under the name Amazon Go, which uses a variety of cameras and sensors in order to see what customers are putting into their shopping bags. The customers scan a QR code when they enter the store through a companion app, which is linked to their Amazon.com account. When the customer exits the store, the items in their bag are automatically charged to the account.\n\nSuppliers like ITAB, NCR, Wincor-Nixdorf and others have manufactured hybrid checkout systems that allows the checkout counter to be switched between either a cashier operated mode or a customer self-service mode.\n\nHybridCheckout from PeoplePos has taken the hybrid concept further by allowing the cashier and customer to do parallel and simultaneous scanning. This is achieved by adding a customer scanning area next to the cashier scanning area. The HybridCheckout solution allows for an increased throughput and a combination of cashier operated scanning and customer self-service.\n\nIn 2010, the \"open-source-self-check\" project was announced. By using hardware and open source software, this library self-checkout system costs less than one-tenth of the commercial version.\n\nA Java based open source self check client for libraries, which has been used at the University of Oxford, is also available under a GPL v3 license.\n\nBBC News reported in December 2009 on the rise of self-service tills and how error messages like 'unexpected item in the bagging area' are becoming part of the new shopping experience and even given rise to T-shirts bearing the slogan.\n\nSelf-serving checkout counters drastically reduce the demand for low skilled workers, using technology to eliminate a key human player in the marketplace. The widespread implementation of self checkout services will result in a decrease in available jobs for low skilled checkout workers, some of whom have depended on such jobs for a living.\n\nAn appeal court in California confirmed in September 2013 a bill banning sales of alcoholic beverages in self-service checkouts. The law requires alcohol only to be sold in face-to-face transactions with store clerks.\n\n"}
{"id": "44311066", "url": "https://en.wikipedia.org/wiki?curid=44311066", "title": "Shaala Darpan", "text": "Shaala Darpan\n\nShaala Darpan is an ICT programme of Ministry of Human Resource Development, Government of India that to provide mobile access to parents of students of Government and Government aided schools.\n\nUsing Shaala Darpan parents can view updates on their child’s progress. They can view records of attendance, assignments and achievements of their child. The ministry aims to launch the service by 2015 academic session.\n"}
{"id": "4963806", "url": "https://en.wikipedia.org/wiki?curid=4963806", "title": "Smart mine", "text": "Smart mine\n\nSmart mine refers to a number of next-generation land mine designs being developed by military forces around the world. These include mines designed to self-destruct or self-deactivate at the end of a conflict, and mines designed to re-deploy themselves if its neighbors detonate or are removed. The development of smart mines began as a response to the International Campaign to Ban Landmines as a way of reducing non-combatant and civilian injury. \n\nCritics claim that new technology is unreliable, and that the perception of a \"safe mine\" will lead to increased deployment of land mines in future conflicts. Current guidelines allow for a 10% failure rate, leaving a significant number of mines to pose a threat. Additionally, in the case of self-destructing mines, civilians still are at risk of injury when the mine self-destructs and are denied access to land which has been mined.\n\nAs mines are inherently non-discriminate weapons even smart mines may injure civilians during a time of war. Many critics believe this to be unacceptable under international law. The human security paradigm is outspoken on the issue of the reduction in the use of land mines due to the extremely individual nature of their impact - a facet that is ignored by traditional security concerns which focus on military and state level security issues.\n\n"}
{"id": "63199", "url": "https://en.wikipedia.org/wiki?curid=63199", "title": "Spontaneous human combustion", "text": "Spontaneous human combustion\n\nSpontaneous human combustion (SHC) is a term encompassing reported cases of the combustion of a living (or very recently deceased) human body without an apparent external source of ignition. In addition to reported cases, examples of the phenomenon appear in literature, and both types have been observed to share common characteristics, regarding circumstances and remains of the victim.\n\nForensic investigations have attempted to analyze reported instances of SHC and have resulted in hypotheses regarding potential causes and mechanisms, including victim behavior and habits, alcohol consumption and proximity to potential sources of ignition, as well as the behavior of fires that consume melted fats. Natural explanations, as well as unverified natural phenomena, have been proposed to explain reports of SHC. Current scientific consensus is that most, and perhaps all, cases of SHC involve overlooked external sources of ignition.\n\n\"Spontaneous human combustion\" refers to the death from a fire originating without an apparent external source of ignition; the fire is believed to start within the body of the victim. This idea and the term 'spontaneous human combustion' were both first proposed in 1746 by Paul Rolli in an article published in the \"Philosophical Transactions\". Writing in \"The British Medical Journal\" in 1938, coroner Gavin Thurston describes the phenomenon as having \"attracted the attention not only of the medical profession but of the laity\" as early as 1834 (more than one hundred years prior to Thurston's article). In his 1995 book \"Ablaze!\", Larry E. Arnold wrote that there had been about 200 cited reports of spontaneous human combustion worldwide over a period of around 300 years.\n\nThe topic received coverage in the \"British Medical Journal\" in 1938. An article by L. A. Parry cited an 1823-published book \"Medical Jurisprudence\", which stated that commonalities among recorded cases of spontaneous human combustion included the following characteristics:\n\"[...]the recorded cases have these things in common:\n\n\nAlcoholism is a common theme in early SHC literary references, in part because some Victorian era physicians and writers believed spontaneous human combustion was the result of alcoholism.\n\nAn extensive two-year research project, involving thirty historical cases of alleged SHC, was conducted in 1984 by science investigator Joe Nickell and forensic analyst John F. Fischer. Their lengthy, two-part report was published in the journal of the International Association of Arson Investigators, as well as part of a book. Nickell has written frequently on the subject, appeared on television documentaries, conducted additional research, and lectured at the New York State Academy of Fire Science at Montour Falls, New York, as a guest instructor.\n\nNickell and Fischer's investigation, which looked at cases in the 18th, 19th and 20th centuries, showed that the burned bodies were in close proximity to plausible sources for the ignition: candles, lamps, fireplaces, and so on. Such sources were often omitted from published accounts of these incidents, presumably to deepen the aura of mystery surrounding an apparently \"spontaneous\" death. The investigations also found that there was a correlation between alleged SHC deaths and the victim's intoxication (or other forms of incapacitation) which could conceivably have caused them to be careless and unable to respond properly to an accident. Where the destruction of the body was not particularly extensive, a primary source of combustible fuel could plausibly have been the victim's clothing or a covering such as a blanket or comforter.\n\nHowever, where the destruction was extensive, additional fuel sources were involved, such as chair stuffing, floor coverings, the flooring itself, and the like. The investigators described how such materials helped to retain melted fat, which caused more of the body to be burned and destroyed, yielding still more liquified fat, in a cyclic process known as the \"wick effect\" or the \"candle effect\".\n\nAccording to Nickell and Fischer's investigation, nearby objects often remained undamaged because fire tends to burn upward, but burns laterally with some difficulty. The fires in question are relatively small, achieving considerable destruction by the wick effect, and relatively nearby objects may not be close enough to catch fire themselves (much as one can closely approach a modest campfire without burning). As with other mysteries, Nickell and Fischer cautioned against \"single, simplistic explanation for all unusual burning deaths\" but rather urged investigating \"on an individual basis\".\n\nNeurologist Steven Novella has said that skepticism about spontaneous human combustion is now bleeding over into becoming popular skepticism about spontaneous combustion.\n\nA 2002 study by Angi M. Christensen of the University of Tennessee cremated both healthy and osteoporotic samples of human bone and compared the resulting color changes and fragmentation. The study found that osteoporotic bone samples \"consistently displayed more discoloration and a greater degree of fragmentation than healthy ones.\" The same study found that when human tissue is burned, the resulting flame produces a small amount of heat, indicating that fire is unlikely to spread from burning tissue.\n\nSome hypotheses attempt to explain how SHC might occur without an external flame source, while other hypotheses suggest that incidents that might appear as \"spontaneous\" combustion did in fact have an external source of ignition – and that the likelihood of spontaneous human combustion without an external ignition source is quite low. Benjamin Radford, science writer and deputy editor of the science magazine \"Skeptical Inquirer\", casts doubt on the plausibility of spontaneous human combustion, \"If SHC is a real phenomenon (and not the result of an elderly or infirm person being too close to a flame source), why doesn't it happen more often? There are 5 billion [The world's population reached 5 billion in 1987] people in the world, and yet we don't see reports of people bursting into flame while walking down the street, attending football games, or sipping a coffee at a local Starbucks.\" Paranormal researcher Brian Dunning states that SHC stories \"are simply the rare cases where a natural death in isolation has been followed by a slow combustion from some nearby source of ignition.\" He further suggested that reports of people suddenly aflame should be called \"Unsolved deaths by fire\", stating that an unknown cause did not necessarily imply that the fire lacked an external ignition source.\n\n\n\nOn 2 July 1951, Mary Reeser, a 67-year-old woman, was found burned to death in her house after her landlady realised that the house's doorknob was unusually warm. The landlady notified the police, and upon entering the home, they found Reeser's remains completely burned into ash, with only one leg remaining. The chair she was sitting in was also destroyed. During the investigation, detectives found that Reeser's temperature was around , which puzzled the investigators, as almost everything else in the room in which Reeser was found remained intact. Reeser took sleeping pills and was also a smoker. A common theory was that she was smoking a cigarette after taking sleeping pills, and then fell asleep while still holding the burning cigarette, which could have ignited her gown, ultimately leading to her death. Investigators also found that the fire had burned a socket, which stopped a clock at 2:26am, suggesting that Reeser had died at around that time.\n\nMargaret Hogan, an 89-year-old widow who lived alone in a house on Prussia Street, Dublin, was found burned almost to the point of complete destruction on 28 March 1970. Plastic flowers on a table in the centre of the room had been reduced to liquid and a television with a melted screen sat 12 feet from the armchair in which the ashen remains were found; otherwise, the surroundings were almost untouched. Her two feet, and both legs from below the knees, were undamaged. A small coal fire had been burning in the grate when a neighbour left the house the previous day; however, no connection between this fire and that in which Mrs. Hogan died could be found. An inquest, held on 3 April 1970, recorded death by burning, with the cause of the fire listed as \"unknown\".\n\nHenry Thomas, a 73-year-old man, was found burned to death in the living room of his council house on the Rassau estate in Ebbw Vale, South Wales, in 1980. His entire body was incinerated, leaving only his skull and a portion of each leg below the knee. The feet and legs were still clothed in socks and trousers. Half of the chair in which he had been sitting was also destroyed. Police forensic officers decided that the incineration of Thomas was due to the wick effect. \n\nIn December 2010, the death of Michael Faherty in County Galway, Ireland, was recorded as \"spontaneous combustion\" by the coroner. The doctor, Ciaran McLoughlin, made this statement at the inquiry into the death: \"This fire was thoroughly investigated and I'm left with the conclusion that this fits into the category of spontaneous human combustion, for which there is no adequate explanation.\"\n\nThe most recent reported case of apparent SHC occurred in the early afternoon of 17 September 2017 in Tottenham, north London, when a 70-year-old pensioner, John Nolan from County Mayo in Ireland, appeared to spontaneously burst into flames while walking in the street. Some passers-by tried to help him at the scene and he was airlifted to hospital where he died the next day, having suffered severe third-degree burns on 65% of his body. At the time, investigators were unable to establish a reason for this incident and his death was treated as unexplained. An inquest was opened at North London Coroner's Court in March 2018, to further examine the circumstances of his death. The coroner concluded that Mr. Nolan accidentally set fire to himself while lighting a cigarette and the cause of death was given as \"accidental ignition of clothing\".\n\n"}
{"id": "42051580", "url": "https://en.wikipedia.org/wiki?curid=42051580", "title": "Suikerbond", "text": "Suikerbond\n\nThe Suikerbond (\"Sugar Union\") was a trade union for European workers in the sugar industry in the Dutch East Indies. The organization was founded on 14 March 1907 in Surabaya, as the \"Bond van Geëmployeerden in de Suikerindustrie in Nederlandsch-Indië\" (\"Union of those employed in the sugar industry in the Netherlands Indies\").One of the two strongest unions for Europeans, in the early 1920s, during a wave of strikes by factory workers (many of whom were organized in Communist trade unions), the Suikerbond had been \"bought off\" by the sugar industry which had raised wages for European workers. In 1921 the organization founded its own newspaper, \"De Indische Courant\", which was run by the union's president, W. Burger, and appears in two editions on the island of Java; initially leaning social-democratic, under pressure from union members a more conservative editor in chief was installed. By 1922 the organization numbered over 3800 members and had a strike fund of a half a million guilders.\n"}
{"id": "27903154", "url": "https://en.wikipedia.org/wiki?curid=27903154", "title": "Temporal isolation among virtual machines", "text": "Temporal isolation among virtual machines\n\nTemporal isolation or performance isolation among virtual machine (VMs) refers to the capability of isolating the temporal behavior (or limiting the temporal interferences) of multiple VMs among each other, despite them running on the same physical host and sharing a set of physical resources such as processors, memory, and disks.\n\nOne of the key advantages of using virtualization in server consolidation, is the possibility to seamlessly \"pack\" multiple under-utilized systems into a single physical host, thus achieving a better overall utilization of the available hardware resources. In fact, an entire Operating System (OS), along with the applications running within, can be run in a virtual machine (VM).\nHowever, when multiple VMs concurrently run on the same physical host, they share the available physical resources, including CPU(s), network adapter(s), disk(s) and memory. This adds a level of unpredictability in the performance that may be exhibited by each individual VM, as compared to what is expected. For example, a VM with a temporary compute-intensive peak might disturb the other running VMs, causing a significant and undesirable temporary drop in their performance. In a world of computing that is shifting towards cloud computing paradigms where resources (computing, storage, networking) may be remotely rented in virtualized form under precise service-level agreements, it would be highly desirable that the performance of the virtualized resources be as stable and predictable as possible.\n\nMultiple techniques may be used to face with the aforementioned problem. They aim to achieve some degree of temporal isolation across the concurrently running VMs, at the various critical levels of scheduling: CPU scheduling, network scheduling and disk scheduling.\n\nFor the CPU, it is possible to use proper scheduling techniques at the hypervisor level to contain the amount of computing each VM may impose on a shared physical CPU or core. For example, on the Xen hypervisor, the BVT, Credit-based and S-EDF schedulers have been proposed for controlling how the computing power is distributed among competing VMs.\nTo get stable performance in virtualized applications, it is necessary to use scheduler configurations that are not work-conserving.\nAlso, on the KVM hypervisor, some have proposed using EDF-based scheduling strategies\nto maintain stable and predictable performance of virtualized applications. Finally, with a multi-core or multi-processor physical host, it is possible to deploy each VM on a separate processor or core to temporally isolate the performance of various VMs.\n\nFor the network, it is possible to use traffic shaping techniques to limit the amount of traffic that each VM can impose on the host. Also, it is possible to install multiple network adapters on the same physical host, and configure the virtualization layer so that each VM may grant exclusive access to each one of them. For example, this is possible with the driver domains of the Xen hypervisor. Multi-queue network adapters exist which support multiple VMs at the hardware level, having separate packet queues associated to the different hosted VMs (by means of the IP addresses of the VMs), such as the Virtual Machine Device Queue (VMDq) devices by Intel. Finally, real-time scheduling of the CPU may also be used for enhancing temporal isolation of network traffic from multiple VMs deployed on the same CPU.\n\nWhen using real-time scheduling for controlling the amount of CPU resources reserved for each VM, one challenging problem is properly accounting for the CPU time applicable to system-wide activities. For example, in the case of the Xen scheduler, the Dom0 and the driver domains services might be shared across multiple VMs accessing them. Similarly, in the case of the KVM hypervisor, the workload imposed on the host OS due to serving network traffic for each individual guest OS might not be easily distinguishable, because it mainly involves kernel-level device drivers and the networking infrastructure (on the host OS). Some techniques for mitigating such problems have been proposed for the Xen case.\n\nAlong the lines of adaptive reservations, it is possible to apply feedback-control strategies to dynamically adapt the amount of resources reserved to each virtual machine to maintain stable performance for the virtualized application(s).\nFollowing the trend of adaptiveness, in those cases in which a virtualized system is not fulfilling the expected performance levels (either due to unforeseen interferences of other concurrently running VMs, or due to a bad deployment strategy that simply picked up a machine with insufficient hardware resources), it is possible to live-migrate virtual machines while they are running, so as to host them on a more capable (or less loaded) physical host.\n"}
{"id": "28639467", "url": "https://en.wikipedia.org/wiki?curid=28639467", "title": "The Outies", "text": "The Outies\n\nThe Outies, formally known as the \"Out & Equal Workplace Awards\", is an annual awards gala hosted by Out & Equal Workplace Advocates. The Outies honor individuals and organizations that are leaders in advancing equality for lesbian, gay, bisexual, and transgender (LGBT) employees in America’s workplaces. Through these awards, Out & Equal provides the business and LGBT communities with examples of innovative approaches and proven successes to help create safe and equitable workplaces. The awards are presented annually at the Out & Equal Workplace Summit, a nationwide conference addressing LGBT issues in the workplace.\n\nOutie Awards are given in five different categories, with two recognizing individuals and three recognizing organizations. To win an Outie, recipients must have taken significant action to create more equitable workplaces for members of the LGBT community.\n\nThe Workplace Excellence Award recognizes any employer that has an historic and ongoing commitment to pursuing and executing workplace equality for LGBT employees in their own workplace. This employer has a history of continually raising the bar of workplace equality for others to follow.\n\nThe Trailblazer Award recognizes an LGBT person who has made a significant contribution to advancing workplace equality. This individual’s activities will have made a marked improvement in their own workplace and/or have contributed to equality nationally.\n\nThe Champion Award recognizes any LGBTQ person or ally who has made a significant contribution to advancing workplace equality. The Champion Award winner will have shown a unique commitment to LGBTQ workplace rights and will have used their talents to further that cause, even if at some risk..\n\nThe LGBT ERG of the Year Award recognizes a particular employee resource group (ERG), sometimes referred to as a business group or network, that has a proven track record of success in advocating for LGBT equal rights in its own workplace.\n\nThe Regional Affiliate of the Year Award recognizes an Out & Equal regional affiliate that has demonstrated commitment to the Out & Equal mission through exceptional programming and sound organizational practices.\n\nThe Significant Achievement Award recognizes any employer that has made significant strides in the past year in advancing a fair and equitable workplace for its LGBT employees, such as: announcing domestic partner health insurance, including gender identity diversity training, or initiating a unique general advertising campaign that includes LGBT people.\n\nAll Outie nominations are read by the Out & Equal awards committee and judging panel, which is made up of a diverse cross-section of leaders in the movement for LGBT workplace equality. Awards Committee members and judges change each year and are expected to opt out of voting if their own affiliations may bias their votes.\n\nNominees are evaluated on originality, duplicability of initiatives, leadership, results, and other criteria. Organizations are evaluated based on the aforementioned criteria, plus the degree to which they have incorporated the 20 Steps to an Out & Equal Workplace. The previous year’s awardees are not considered for the same award for the following two years. Additionally, companies or organizations may only submit one nomination in the organization award categories and one nomination in the individual award categories, for a maximum possible total of two nominations from any one company or organization.\n\nRecognizes any employer that has a longstanding commitment to pursuing and executing workplace equality for LGBT employees in their own workplace. This employer has a history of continually raising the bar of workplace equality for others to follow.\n\nRecognizes a LGBT person who has made a significant contribution to advancing workplace equality. This individual’s activities will have made a marked improvement in their own workplace and/or have contributed to equality nationally.\n\nThe Champion Award recognizes any LGBTQ+ person or ally who has made a significant contribution to advancing workplace equality. The Champion Award winner will have shown a unique commitment to LGBTQ+ workplace rights and will have used their talents to further that cause, even if at some risk...\n\n\nRecognizes a particular employee resource group (ERG), sometimes referred to as a business group or network that has a proven track record of success in advocating for LGBT equal rights in its own workplace.\n\nRecognizes an Out & Equal regional affiliate that has demonstrated commitment to the Out & Equal mission through exceptional programming and sound organizational practices.\n\n\nRecognizes an exceptional individual whose visionary leadership, tireless efforts, and remarkable accomplishments have been a critical contribution toward achieving LGBT workplace equality. In addition to leading change in the world of employment, this leader inspires countless individuals to champion workplace equality for all inclusive of sexual orientation, gender identity, expression, or characteristics.\n\n"}
{"id": "41999635", "url": "https://en.wikipedia.org/wiki?curid=41999635", "title": "UNIT9", "text": "UNIT9\n\nUNIT9 is one of the leading multidisciplinary production companies working in different interactive areas: films, games, virtual reality and digital technology. Founded in 1997, UNIT9 operates globally with offices in London, Los Angeles, New York, Florence, Berlin and Poland. Directors, writers and technologists work collaboratively to create content, advertising, utility and gaming. Ad Age Production Company A-List, UNIT9 partners with advertising agencies worldwide on the digital components of campaigns.\n\nUNIT9's work has been honoured with 1x Emmy, Cannes Lions, 17 One Show Pencils, 200+ FWA, 15 Webby Awards, including Winner of Best Use of Interactive Video in 2013, 13 Awards, including Site of the Year (Users Choice) for Slavery Footprint, Silver and Bronze Effie 2013, and a BAFTA nomination,\n\nLifesaver is a crisis simulating app created for the UK Resuscitation Council with the goal of teaching basic CPR to users through interactivity, gamification and live-action film. Lifesaver presents users with high-stress scenarios to test their speed and efficiency in administering CPR. The option to share these results on social platforms was added to the app to promote engagement among a younger audience.\n\nJust a Reflektor is an interactive video directed by Vincent Morisset, featuring the song \"Reflektor\" by Canadian rock group Arcade Fire. The music video takes advantage of dual screen interactivity, allowing users to cast virtual projections with their mobile devices as the video plays in a web browser. This innovative music video is the first of its kind, allowing the viewer to transform the film visually and instantly.\nSlavery Footprint is a website and mobile app that launched on the 149th anniversary of the announcement of the Emancipation Proclamation. The interactive questionnaire approximates the number of real-world slaves who work to create the goods that users enjoy on a daily basis. The HTML5 survey was built to increase awareness of modern-day slavery and to inform users of their slavery footprint. The project was publicly endorsed by the US President Barack Obama during his speech to the Clinton Global Initiative in 2012.\n\nFind Your Way To Oz is an interactive Google Chrome Experiment inspired by Disney's \"Oz the Great and Powerful\". The game is set in a Kansas circus where players work through a series of challenges that eventually lead them to the mythical land of Oz. This project was developed as an interactive trailer for the film, utilizing innovative technology to create a 3D environment built entirely on WebGL and CSS3 platforms. The game’s final sequence—including a massive tornado—was created with the use of a custom GLSL shader. An animation previously developed to map the inside of the brain cell of a mouse was used as the framework to simulate the tornado’s movement. Developers implemented a custom volumetric shader to adapt the animation while maintaining acceptable processing rates, allowing players to view the tornado from all directions.\n\nAttraction is an interactive anime directed by Koji Morimoto and Anrick Bregman, commissioned by the French Ministry of Health and targeted and educating youth on the dangers of smoking. Users interact with the story by manipulating events with their cursor and webcam, ultimately altering the flow of the story. Attraction is based in 2040 Tokyo and focuses on the journey of three Japanese children. A live installation was developed in 2013 as an adaptation of Attraction. The updated installation was featured at the Electronic Language International Festival, where hundreds of users were able to interact with the story by shifting and moving their own body in a single space. UNIT9 applied motion sensor technology and immersive sound to allow the user to interact from a distance and become an active part of the story as it played on a large projection in front of them.\n\nWorking with world-class directors, UNIT9 Films specializes in live action and storytelling film content for TV, social web, mobile, installations and VR.\n\nBarclaycard: #Bespokeballads was a user-generated viral video project that used the hashtag “#bespokeballads” to interact directly with Twitter followers. The project took place over the course of one week, in which songwriters wrote, performed, and recorded custom-made ballads inspired by the randomly selected Twitter feeds of users tweeting with the hashtag “#bespokeballads.” The artists also wrote songs about the latest celebrity gossips and Internet trends. In total, more than 80 songs were created.\n\nBitchcraft is a paranormal web series starring Fay Ripley. The series follows Gemma who—after losing her boyfriend and job—returns home to live with her parents. Upon arrival, she is horrified to learn that her mother has become a practicing witch. Gemma struggles to return her life to normal as she quickly realizes that the entire neighbourhood is infused with black magic. The series has been popular with young audiences, such as fans of Misfits and Merlin.\n\nTropicana: Energie Naturelle is a short documentary that tells the story of an installation created in Paris for Tropicana in 2011, directed by Johnny Hardstaff. The installation connected over 2,500 oranges with zinc and copper spikes to create a full-scale billboard, with the words “Energie Naturelle” powered by 1,800 volts of electricity. The film documents the building process as well as viewer’s reactions.\n\nPhilips: You Need to Hear This was an interactive music video project in which users were able to create custom music videos for the song Carolyn, by the Swiss Lips. The videos were created based on the user’s performance in a retro-styled 8-bit racing game—their decisions in the game automatically remixed the song and generated a unique accompanying video.\n\nDomino’s Pizza Hero Domino’s Pizza Hero is an interactive gaming app developed for Domino’s Pizza for use on tablet and mobile devices. Players are tasked with creating pizzas as quickly and efficiently as possible, with the top players receiving real-world job offers from Domino’s Pizza. The game is a unique and immersive approach to recruitment. Additionally, users were able to order pizzas directly from the app.\n\nMINI Maps is a multiplayer racing game that merges technologies from both Google Maps and Facebook. Players race against other Facebook users in a series of randomized real-world locations. The app also provides local weather data for each racing location and the option for users to custom design their own MINI.\n\nNano Panda is a puzzle game developed for iOS and Android platforms. The gameplay is based on conceptual physics, heavily utilizing magnetic simulation. The main character—a panda shrunk down to nano size—is tasked with destroying evil atoms. The game won the W3 Gold Award in Mobile Applications in the Games category and was downloaded over a million times globally.\n\nHoxton Window Project is a public art project hosted and curated by UNIT9. Artists are invited to cover the windows of UNIT9’s Hoxton Square office with different forms of art, from graphic design to illustration to interactive displays. The Hoxton Window Project has included art from Mcbess and Jon Burgerman, among others.\n\n"}
{"id": "33496", "url": "https://en.wikipedia.org/wiki?curid=33496", "title": "Weapon", "text": "Weapon\n\nA weapon, arm or armament is any device that can be used with intent to inflict damage or harm. Weapons are used to increase the efficacy and efficiency of activities such as hunting, crime, law enforcement, self-defense, and warfare. In broader context, weapons may be construed to include anything used to gain a tactical, strategic, material or mental advantage over an adversary or enemy target.\n\nWhile ordinary objects such as sticks, stones, cars, or pencils can be used as weapons, many are expressly designed for the purpose – ranging from simple implements such as clubs, swords and axes, to complicated modern intercontinental ballistic missiles, biological weapons and cyberweapons. Something that has been re-purposed, converted, or enhanced to become a weapon of war is termed weaponized, such as a weaponized virus or weaponized laser.\n\nThe use of objects as weapons has been observed among chimpanzees, leading to speculation that early hominids used weapons as early as five million years ago. However, this can not be confirmed using physical evidence because wooden clubs, spears, and unshaped stones would have left an ambiguous record. The earliest unambiguous weapons to be found are the Schöningen spears, eight wooden throwing spears dating back more than 300,000 years. At the site of Nataruk in Turkana, Kenya, numerous human skeletons dating to 10,000 years ago may present evidence of traumatic injuries to the head, neck, ribs, knees and hands, including obsidian projectiles embedded in the bones that might have been caused from arrows and clubs during conflict between two hunter-gatherer groups. But the evidence interpretation of warfare at Nataruk has been challenged.\n\nThe earliest ancient weapons were evolutionary improvements of late neolithic implements, but significant improvements in materials and crafting techniques led to a series of revolutions in military technology.\n\nThe development of metal tools began with copper during the Copper Age (about 3,300 BC) and was followed by the Bronze Age, leading to the creation of the Bronze Age sword and similar weapons.\n\nDuring the Bronze Age, the first defensive structures and fortifications appeared as well, indicating an increased need for security. Weapons designed to breach fortifications followed soon after, such as the battering ram was in use by 2500 BC.\n\nThe development of iron-working around 1300 BC in Greece had an important impact on the development of ancient weapons. It was not the introduction of early Iron Age swords, however, as they were not superior to their bronze predecessors, \nbut rather the domestication of the horse and widespread use of spoked wheels by ca. 2000 BC. This led to the creation of the light, horse-drawn chariot, whose improved mobility proved important during this era. Spoke-wheeled chariot usage peaked around 1300 BC and then declined, ceasing to be militarily relevant by the 4th century BC.\n\nCavalry developed once horses were bred to support the weight of a human. The horse extended the range and increased the speed of attacks.\n\nIn addition to land based weaponry, warships, such as the trireme, were in use by the 7th century BC.\n\nEuropean warfare during the Post-classical history was dominated by elite groups of knights supported by massed infantry (both in combat and ranged roles). They were involved in mobile combat and sieges which involved various siege weapons and tactics. Knights on horseback developed tactics for charging with lances providing an impact on the enemy formations and then drawing more practical weapons (such as swords) once they entered into the melee. By contrast, infantry, in the age before structured formations, relied on cheap, sturdy weapons such as spears and billhooks in close combat and bows from a distance. As armies became more professional, their equipment was standardized and infantry transitioned to pikes. Pikes are normally seven to eight feet in length, and used in conjunction with smaller side-arms (short sword).\n\nIn Eastern and Middle Eastern warfare, similar tactics were developed independent of European influences.\n\nThe introduction of gunpowder from the Asia at the end of this period revolutionized warfare. Formations of musketeers, protected by pikemen came to dominate open battles, and the cannon replaced the trebuchet as the dominant siege weapon.\n\nThe European Renaissance marked the beginning of the implementation of firearms in western warfare. Guns and rockets were introduced to the battlefield.\n\nFirearms are qualitatively different from earlier weapons because they release energy from combustible propellants such as gunpowder, rather than from a counter-weight or spring. This energy is released very rapidly and can be replicated without much effort by the user. Therefore even early firearms such as the arquebus were much more powerful than human-powered weapons. Firearms became increasingly important and effective during the 16th century to 19th century, with progressive improvements in ignition mechanisms followed by revolutionary changes in ammunition handling and propellant. During the U.S. Civil War new applications of firearms including the machine gun and ironclad warship emerged that would still be recognizable and useful military weapons today, particularly in limited conflicts. In the 19th century warship propulsion changed from sail power to fossil fuel-powered steam engines.\nSince the mid-18th century North American French-Indian war through the beginning of the 20th century, human-powered weapons were reduced from the primary weaponry of the battlefield yielding to gunpowder-based weaponry. Sometimes referred to as the \"Age of Rifles\", this period was characterized by the development of firearms for infantry and cannons for support, as well as the beginnings of mechanized weapons such as the machine gun. \nOf particular note, Howitzers were able to destroy masonry fortresses and other fortifications, and this single invention caused a Revolution in Military Affairs (RMA), establishing tactics and doctrine that are still in use today. \"See Technology during World War I for a detailed discussion.\"\n\nAn important feature of industrial age warfare was technological escalation – innovations were rapidly matched through replication or countered by another innovation. The technological escalation during World War I (WW I) was profound, including the wide introduction of aircraft into warfare, and naval warfare with the introduction of aircraft carriers.\n\nWorld War I marked the entry of fully industrialized warfare as well as weapons of mass destruction (\"e.g.\", chemical and biological weapons), and new weapons were developed quickly to meet wartime needs. Above all, it promised to the military commanders the independence from the horse and the resurgence in maneuver warfare through extensive use of motor vehicles. The changes that these military technologies underwent before and during the Second World War were evolutionary, but defined the development for the rest of the century.\n\nThis period of innovation in weapon design continued in the inter-war period (between WW I and WW II) with continuous evolution of weapon systems by all major industrial powers. Many modern military weapons, particularly ground-based ones, are relatively minor improvements of weapon systems developed during World War II. \"See military technology during World War II for a detailed discussion.\"\n\nWorld War II however, perhaps marked the most frantic period of weapons development in the history of humanity. Massive numbers of new designs and concepts were fielded, and all existing technologies were improved between 1939 and 1945. The most powerful weapon invented during this period was the atomic bomb, however many other weapons influenced the world in ways overshadowed by the importance of nuclear weapons.\n\nSince the realization of mutually assured destruction (MAD), the nuclear option of all-out war is no longer considered a survivable scenario. During the Cold War in the years following World War II, both the United States and the Soviet Union engaged in a nuclear arms race. Each country and their allies continually attempted to out-develop each other in the field of nuclear armaments. Once the joint technological capabilities reached the point of being able to ensure the destruction of the Earth x100 fold, then a new tactic had to be developed. With this realization, armaments development funding shifted back to primarily sponsoring the development of conventional arms technologies for support of limited wars rather than total war.\n\nDuring the late 2010s, tensions between the West and the East escalate as nuclear-based issues arise. Such event has been since dubbed as Cold War II.\n\n\n\n\nThe arms industry is a global industry that involves the sales and manufacture of weaponry. It consists of a commercial industry involved in the research and development, engineering, production, and servicing of military material, equipment, and facilities.\n\nThe production, possession, trade and use of many weapons are controlled. This may be at a local or central government level, or international treaty. Examples of such controls include:\n\nAll countries have laws and policies regulating aspects such as the manufacture, sale, transfer, possession, modification and use of small arms by civilians. \n\nCountries which regulate access to firearms will typically restrict access to certain categories of firearms and then restrict the categories of persons who may be granted a license for access to such firearms. There may be separate licenses for hunting, sport shooting (a.k.a. target shooting), self-defense, collecting, and concealed carry, with different sets of requirements, permissions, and responsibilities.\n\nInternational treaties and agreements place restrictions upon the development, production, stockpiling, proliferation and usage of weapons from small arms and heavy weapons to weapons of mass destruction. Arms control is typically exercised through the use of diplomacy which seeks to impose such limitations upon consenting participants, although it may also comprise efforts by a nation or group of nations to enforce limitations upon a non-consenting country.\n\nArms trafficking is the trafficking of contraband weapons and ammunition. What constitutes legal trade in firearms varies widely, depending on local and national laws.\n\nThere are a number of issue around the potential ongoing risks from deployed weapons, the safe storage of weapons, and their eventual disposal when no longer effective or safe.\n\n"}
