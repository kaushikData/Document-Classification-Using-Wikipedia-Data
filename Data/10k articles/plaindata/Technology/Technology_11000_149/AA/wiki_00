{"id": "30283143", "url": "https://en.wikipedia.org/wiki?curid=30283143", "title": "Air core gauge", "text": "Air core gauge\n\nAn air core gauge is a specific type of rotary actuator in an analog display gauge that allows an indicator to rotate a full 360 degrees. It is used in gauges and displays, most commonly automotive instrument clusters. \n\nA typical automotive application is shown at the right. The air core gauge is a type of \"air-core motor\". It may be considered a \"gauge movement\" or \"pointer indication device\".\n\nThere are four common types of rotary actuators:\n\nThe air core gauge consists of two independent, perpendicular coils surrounding a hollow chamber. A needle shaft protrudes into the chamber, where a permanent magnet is affixed to the shaft. When current flows through the perpendicular coils, their magnetic fields superimpose and the magnet is free to align with the combined fields. \nA typical air core gauge has four terminals, two for each coil, as shown. The two coils are identified as the sine coil and the cosine coil.\n\nThe direction formula_1 of the overall magnetic field is approximately:\n\nWhere formula_3 and formula_4 are the coils' sine and cosine currents respectively. The permanent magnet aligns itself with that field, eventually settling near formula_1. In this way, by proportioning the current through each coil, the needle can reach all 360° of rotation.\n\nIf the sin coil current is 29 mA and the cos current is 50 mA:\n\nThe coil current ratio is 0.58, and arctan 0.58 = 30 degrees.\n\nAir core gauges require special electronics to properly drive the coils. Some driver integrated circuits have a serial input data port and two pair of output lines. One pair of the output lines drives the sin coil and one pair drives the cos coil.\n\nThe input data defines:\n\nSome typical driver ICs include:\n\n"}
{"id": "16179920", "url": "https://en.wikipedia.org/wiki?curid=16179920", "title": "App Store (iOS)", "text": "App Store (iOS)\n\nThe App Store is a digital distribution platform, developed and maintained by Apple Inc., for mobile apps on its iOS operating system. The store allows users to browse and download apps developed with Apple's iOS software development kit. Apps can be downloaded on the iPhone smartphone, the iPod Touch handheld computer, or the iPad tablet computer, and some can be transferred to the Apple Watch smartwatch or 4th-generation or newer Apple TVs as extensions of iPhone apps.\n\nThe App Store was opened on July 10, 2008, with an initial 500 applications available. , the store features over 2.1 million apps.\n\nDevelopers have multiple options for monetizing their applications, ranging from free, free with in-app purchases, and paid. However, App Store has been criticized for a lackluster development environment, prompting the company in June 2016 to announce a \"renewed focus and energy\" on the store. Major changes introduced in the following months include ads in search results, a new app subscription model, and the ability for developers to respond to customer reviews. Additionally, Apple began a process to remove old apps that do not function as intended or that don't follow current app guidelines, with app research firms noticing significant numbers of app removals from the store. Furthermore, with the release of iOS 11 in September 2017, App Store received a complete design overhaul, bringing a greater focus on editorial content and daily highlights, as well as a design similar in style to several of Apple's built-in iOS apps.\n\nThe iPhone App Store opened on July 10, 2008. On July 11, the iPhone 3G was released and came pre-loaded with support for App Store.\n\nAfter the success of Apple's App Store and the launch of similar services by its competitors, the term \"app store\" has been adopted to refer to any similar service for mobile devices. However, Apple applied for a U.S. trademark on the term \"App Store\" in 2008, which was tentatively approved in early 2011. In June 2011, U.S. District Judge Phyllis Hamilton, who was presiding over Apple's case against Amazon, said she would \"probably\" deny Apple's motion to stop Amazon from using the \"App Store\" name. In July, Apple was denied preliminary injunction against Amazon's Appstore by a federal judge.\n\nThe term \"app\" has become a popular buzzword; in January 2011, \"app\" was awarded the honor of being 2010's \"Word of the Year\" by the American Dialect Society. \"App\" has been used as shorthand for \"application\" since at least the mid-1990s, and in product names since at least 2006, for example then-named Google Apps.\n\nApple announced Mac App Store, a similar app distribution platform for its macOS personal computer operating system, in October 2010, with the official launch taking place in January 2011 with the release of its 10.6.6 \"Snow Leopard\" update.\n\nIn February 2013, Apple informed developers that they could begin using appstore.com for links to their apps. In June at its developer conference, Apple announced an upcoming \"Kids\" section in App Store, a new section featuring apps categorized by age range, and the section was launched alongside the release of iOS 7 in September 2013.\n\nIn November 2014, due to pressure from the European Commission, Apple updated App Store so that all apps that have no charge to download are labeled \"Get\" instead of the previous \"Free\", due to many \"free\" apps' inclusions of paid in-app purchases.\n\nIn January 2017, reports surfaced that documentation for a new beta for the then-upcoming release of iOS 10.3 detailed that Apple would let developers respond to customer reviews in the App Store, marking a significant change from the previous limitation, which prevented developers from communicating with users. The functionality was officially enabled on March 27, 2017 when iOS 10.3 was released to users. Further details were also released about reviews for users, including that they will be able to rate and review apps in the apps themselves rather than being redirected to the App Store, and that they can mark other users' reviews as \"Helpful\" or \"Not Helpful\". Apple published a document describing proper ways to respond for developers, including being timely, clear and concise, prioritize certain forms of reviews (low-star ratings, certain countries or recent reviews) through filtering in iTunes Connect, and that developer responses go through an approval process before being published. Developers are also forbidden from manipulating or incenting feedback. Developer responses are listed in the App Store as a line underneath the respective user's review, and users receive a notification/email upon a response from the respective developer, with the option to update their review.\n\nIn March 2017, App Store submissions containing pricing details, such as \"free\", in the name started getting rejected. Developers had previously been advised in developer guides in iTunes Connect and App Store overview pages that they should refrain from the practice, though apps were still approved. Starting in March, some (though not all) apps with \"free\" in their titles were being rejected.\n\nIn October 2016, in an effort to improve app discoverability, Apple rolled out the ability for developers to purchase advertising spots in App Store to users in the United States. The ads, shown at the top of the search results, are based strictly on relevant keywords, and are not used to create profiles on users. Apple expanded search ads to the United Kingdom, Australia and New Zealand in April 2017, along with more configurable advertising settings for developers. Search ads were expanded to Canada, Mexico and Switzerland in October 2017. In December 2017, Apple revamped its search ads program to offer two distinctive versions; \"Search Ads Basic\" is a pay-per-install program aimed at smaller developers, in which they only pay when users actually install their app. Search Ads Basic also features an easier setup process and a restricted monthly budget. \"Search Ads Advanced\" is a new name given to the older method, in which developers have to pay whenever users tap on their apps in search results, along with unlimited monthly budgets. At launch, the Basic program is only available in the U.S., with international rollout expected \"sometime next year\".\n\nApple also offers an iTunes Affiliate Program, which lets people refer others to apps and other iTunes content, along with in-app purchases, for a percentage of sales. The commission rate for in-app purchases was reduced from 7% to 2.5% in May 2017, while affiliate rates for paid apps, music, movies, books, and TV shows remained at 7%.\n\nApp Store received a major design overhaul with the release of iOS 11. The new design features a greater focus on editorial content and daily highlights, and introduces a \"cleaner and more consistent and colorful look\" similar to several of Apple's built-in iOS apps.\n\nPrior to September 2017, Apple offered a way for users to manage their iOS app purchases through the iTunes computer software. In September, version 12.7 of iTunes was released, removing the App Store section in the process. However, the following month, iTunes 12.6.3 was also released, retaining the App Store, with \"9to5Mac\" noting that the secondary release was positioned by Apple as \"necessary for some businesses performing internal app deployments\".\n\nIn December 2017, Apple announced that developers could offer applications for pre-order, letting them make apps visible in the store between 2–90 days ahead of release.\n\nOn January 4, 2018, Apple announced that the App Store had a record-breaking holiday season according to a new press release. During the week starting on Christmas Eve, a record number of customers made App Store purchases, spending more than $890 million in that seven-day period. On New Year's Day 2018 alone, customers made $300 million in purchases.\n\nThe iOS SDK (Software Development Kit) allows for the development of mobile apps on iOS.\n\nWhile originally developing iPhone prior to its unveiling in 2007, Apple's then-CEO Steve Jobs did not intend to let third-party developers build native apps for iOS, instead directing them to make web applications for the Safari web browser. However, backlash from developers prompted the company to reconsider, with Jobs announcing in October 2007 that Apple would have a software development kit available for developers by February 2008. The SDK was released on March 6, 2008.\n\nThe SDK is a free download for users of Mac personal computers. It is not available for Microsoft Windows PCs. The SDK contains sets giving developers access to various functions and services of iOS devices, such as hardware and software attributes. It also contains an iPhone simulator to mimic the look and feel of the device on the computer while developing. New versions of the SDK accompany new versions of iOS. In order to test applications, get technical support, and distribute apps through App Store, developers are required to subscribe to the Apple Developer Program.\n\nCombined with Xcode, the iOS SDK helps developers write iOS apps using officially supported programming languages, including Swift and Objective-C. Other companies have also created tools that allow for the development of native iOS apps using their respective programming languages.\n\nTo publish apps on App Store, developers must pay a $99 yearly fee for access to Apple's Developer Program. Apple has announced that, in the United States in 2018, it will waive the fee for nonprofit organizations and governments.\n\nDevelopers have a few options for monetizing their applications. The \"Free Model\" enables free apps, increasing likelihood of engagement. The \"Freemium Model\" makes the app download free, but users are offered optional additional features in-app that require payments. The \"Subscription Model\" enables ongoing monetization through renewable transactions. The \"Paid Model\" makes the app itself a paid download and offers no additional features. The \"Paymium Model\" enables paid app downloads and paid in-app content.\n\nIn-app subscriptions were originally introduced for magazines, newspapers and music apps in February 2011, giving developers 70% of revenue earned and Apple 30%. Publishers could also sell digital subscriptions through their website, bypassing Apple's fees, but were not allowed to advertise their website alternative through the apps themselves.\n\nIn 2016, multiple media outlets reported that apps had decreased significantly in popularity. \"Recode\" wrote that \"The app boom is over\", an editorial in \"TechCrunch\" stated that \"The air of hopelessness that surrounds the mobile app ecosystem is obvious and demoralizing\", and \"The Verge\" wrote that \"the original App Store model of selling apps for a buck or two looks antiquated\". Issues included consumer \"boredom\", a lack of app discoverability, and, as stated by a report from 2014, a lack of new app downloads among smartphone users.\n\nIn an interview with \"The Verge\" in June 2016, Phil Schiller, Apple's senior vice president of Worldwide Marketing, said that Apple had a \"renewed focus and energy\" on the App Store, and announced multiple significant changes, including advertisements in search results and a new app subscription model. The subscription model saw the firmly established 70/30 revenue split between developers and Apple change into a new 85/15 revenue split if a user stays subscribed to the developer's app for a year, and opens the possibility of subscriptions to all apps, not just select categories.\n\nApp data and insights analyst company App Annie released a report in October 2016, announcing that China had overtaken the United States as Apple's biggest market in App Store revenue. In the third quarter of 2016, Chinese users spent $1.7 billion vs. approximately $1.5 billion by American users.\n\nIn June 2017, Apple announced that App Store had generated over $70 billion in revenue for developers since its 2008 launch.\n\nOn July 10, 2008, Apple's then-CEO Steve Jobs told \"USA Today\" that App Store contained 500 third-party applications for the iPhone and the iPod Touch, and of these 25 percent were free. Ten million applications were downloaded the first weekend. By September, the number of available apps had increased to 3,000, with over 100 million downloads.\n\nOver the years, the store has surpassed multiple major milestones, including 50,000, 100,000, 250,000, 500,000, 1 million, and 2 million apps. The billionth application was downloaded on April 24, 2009.\n\nThe iPad was released in April 2010, with approximately 3,000 apps available. By July 2011, 16 months after the release, there were over 100,000 apps available designed specifically for the device.\n\nApple publishes a list on a yearly basis, giving credit to the apps with the highest number of downloads in the past year.\n\nApple rates applications worldwide based on their content, and determines the age group for which each is appropriate. According to the iPhone OS 3.0 launch event, the iPhone will allow blocking of objectionable apps in the iPhone's settings. The following are the ratings that Apple has detailed:\n\nApplications are subject to approval by Apple, as outlined in the SDK agreement, for basic reliability testing and other analysis. Applications may still be distributed \"ad-hoc\" if they are rejected, by the author manually submitting a request to Apple to license the application to individual iPhones, although Apple may withdraw the ability for authors to do this at a later date.\n\n, Apple employed mostly static analysis for their app review process, which means that dynamic code reassembly techniques could defeat the review process.\n\nIn June 2017, Apple updated its App Store review guidelines to specify that app developers will no longer have the ability to use custom prompts for encouraging users to leave reviews for their apps. With the release of iOS 11 in late 2017, Apple will also let developers choose whether to keep current app reviews when updating their apps or to reset. Additionally, another update to App Store policies allows users to optionally \"tip\" content creators, by voluntarily sending them money.\n\nIn November 2012, Boyfriend Maker, a dating sim game, was removed due to \"reports of references to violent sexual acts and paedophilia\" deemed inappropriate to Boyfriend Maker's age rating of 4+. A revised version called Boyfriend Plus was approved by Apple in April 2013.\n\nIn March 2013, HiddenApps was approved and appeared in App Store. The app provided access to developer diagnostic menus, allowed for stock apps to be hidden, and enabled an opt-out feature for iAds, Apple's developer-driven advertisement system. The app was removed shortly afterwards for violating guidelines.\n\nIn April 2013, Apple removed AppGratis, a then-successful app store market that promoted paid apps by offering one for free each day. Apple told \"All Things Digital\" that the app violated two of its developer agreement clauses, including \"Apps that display Apps other than your own for purchase or promotion in a manner similar to or confusing with the App Store will be rejected\" and \"Apps cannot use Push Notifications to send advertising, promotions, or direct marketing of any kind\". Apple did, however, tell the developers they were \"welcome to resubmit\" after changing the app, though there was \"not much hope that it could survive in anything like its current incarnation\".\n\nIn November 2014, Apple removed the marijuana social networking app MassRoots, with the reason given that it \"encourage[d] excessive consumption of alcohol or illegal substances.” In February 2015, MassRoots was reintroduced into the store after Apple changed its enforcement guidelines to allow cannabis social apps in the 23 states where it is legal.\n\nIn September 2015, it was discovered that \"hundreds\" of apps submitted and approved on App Store were using XcodeGhost, a malicious version of the Xcode development software. The issues prompted Apple to remove infected apps from the store and issue a statement that it was \"working with the developers to make sure they’re using the proper version of Xcode\". A security firm later published lists of infected apps, including a China-only version of \"Angry Birds 2\", CamCard, Lifesmart, TinyDeal.com, and WeChat. In the aftermath, Apple stated that it would make Xcode faster to download in certain regions outside the United States, and contacted all developers to ensure they only download the code from the Mac App Store or Apple's website, and provided a code signature for developers to test if they are running a tampered version of Xcode.\n\nIn June 2017, a scamming trend was discovered on the store, in which developers make apps built on non-existent services, attach in-app purchase subscriptions to the opening dialogue, then buy App Store search advertising space to get the app into the higher rankings. In one instance, an app by the name of \"Mobile protection :Clean & Security VPN\" would require payments of $99.99 for a seven-day subscription after a short trial. Apple has not yet responded to the issues.\n\nIn addition, Apple has removed software licensed under the GNU General Public License (GPL) from App Store, due to text in Apple's Terms of Service agreement imposing digital rights management and proprietary legal terms incompatible with the terms of the GPL.\n\nOn September 1, 2016, Apple announced that starting September 7, it would be removing old apps that do not function as intended or that don't follow current review guidelines. Developers will be warned and given 30 days to update their apps, but apps that crash on startup will be removed immediately. Additionally, app names registered by developers cannot exceed 50 characters, in an attempt to stop developers from inserting long descriptions or irrelevant terms in app names to improve the app's ranking in App Store search results. App intelligence firm Sensor Tower revealed in November 2016 that Apple, as promised from its September announcement of removing old apps, had removed 47,300 apps from App Store in October 2016, a 238 percent increase of its prior number of average monthly app removals.\n\nIn June 2017, \"TechCrunch\" reported that Apple had turned its app removal focus on apps copying functionality from other, popular apps. An example cited included \"if a popular game like \"Flappy Bird\" or \"Red Ball\" hits the charts, there will be hundreds or thousands of clones within weeks that attempt to capitalize on the initial wave of popularity\". The report also noted removals of music apps serving pirated tracks. The publication wrote that, since the initial September app removals began, Apple had removed \"multiple hundreds of thousands\" of apps.\n\nIn December 2017, a new report from \"TechCrunch\" stated that Apple had begun enforcing new restrictions on the use of \"commercialized template or app generation services\". Originally introduced as part of Apple's 2017 developer conference, new App Store guidelines allow the company to ban apps making use of templates or commercial app services. This affected many small businesses, with \"TechCrunch\"s report citing that \"local retailers, restaurants, small fitness studios, nonprofits, churches and other organizations\" benefit from using templates or app services due to minimal costs. Developers had received notice from Apple with a January 1, 2018 deadline to change their respective apps. The news caught the attention of Congress, with Congressman Ted Lieu writing a letter to Apple at the beginning of December, asking it to reconsider, writing that \"It is my understanding that many small businesses, research organizations, and religious institutions rely on template apps when they do not possess the resources to develop apps in-house\", and that the new rules cast \"too wide a net\", specifically \"invalidating apps from longstanding and legitimate developers who pose no threat to the App Store’s integrity\". Additionally, the news of stricter enforcement caused significant criticism from app development firms; one company told \"TechCrunch\" that it chose to close down its business following the news, saying that \"The 4.2.6 [rule enforcement] was just a final drop that made us move on a bit faster with that decision [to close]\", and another company told the publication that \"There was no way in June [when the guidelines changed] that we would have said, ‘that’s going to target our apps' ... Apple had told us you aren’t being targeted by this from a quality standpoint. So being hit now under the umbrella of spam is shocking to every quality developer out there and all the good actors\". Furthermore, the latter company stated that \"there’s only so much you can do with apps that perform the same utility – ordering food\". A third company said that \"Rule 4.2.6 is a concrete illustration of the danger of Apple’s dominant position\", and a fourth said that \"They’ve wiped out pretty much an entire industry. Not just DIY tools like AppMakr, but also development suites like Titanium\". Towards the end of the year, Apple updated the guideline to clarify that companies and organizations are allowed to use template apps, but only as long as they directly publish their app on their own; it remained a violation of the rule for commercial app services to publish apps for the respective clients.\n\nIn January 2017, Apple complied with a request from the Chinese government to remove the Chinese version of \"The New York Times\" app. This followed the government's efforts in 2012 to block the \"Times\" website after stories of hidden wealth among family members of then-leader of China, Wen Jiabao, were published. In a statement, an Apple spokesperson told the media that \"we have been informed that the app is in violation of local regulations\", though would not specify which regulations, and added that \"As a result the app must be taken down off the China app store. When this situation changes the app store will once again offer the \"New York Times\" app for download in China\". The following July, it was reported that Apple had begun to remove listings in China for apps that circumvent government Internet censorship policies and new laws restricting virtual private network (VPN) services. Apple issued a statement, explaining that the app removals were a result of developers not complying with new laws in China requiring a government license for businesses offering VPNs, and that \"These apps remain available in all other markets where they do business\". In an earnings call the following month, Cook elaborated on the recent news, explainining that \"We would obviously rather not remove the apps, but like we do in other countries, we follow the law wherever we do business\". Besides VPN services, a number of Internet calling apps, including Microsoft's Skype, were also removed from the Chinese App Store in 2017, with Apple telling \"The New York Times\" that, similar to the VPN apps, these new apps also violated local law. Microsoft explained to \"BBC News\" that its Skype app had been \"temporarily removed\" and that it was \"working to reinstate the app as soon as possible\", though many news outlets reported on the Chinese government's increased efforts and pressure to crack down on Internet freedom.\n\nFollowing Apple CEO Tim Cook's appearance at China's World Internet Conference in December 2017, in which Cook stated that Apple and China share a vision of \"developing a digital economy for openness and shared benefits\", free speech and human rights activists criticized Cook and the company. Maya Wang at Human Rights Watch told \"The Washington Post\" that \"Cook’s appearance lends credibility to a state that aggressively censors the internet, throws people in jail for being critical about social ills, and is building artificial intelligence systems that monitors everyone and targets dissent. ... The version of cyberspace the Chinese government is building is a decidedly dystopian one, and I don’t think anyone would want to share in this ‘common future.’ Apple should have spoken out against it, not endorsed it.\" U.S. Senator Patrick Leahy told \"CNBC\" that \"American tech companies have become leading champions of free expression. But that commitment should not end at our borders. ... Global leaders in innovation, like Apple, have both an opportunity and a moral obligation to promote free expression and other basic human rights in countries that routinely deny these rights.\" Cook told \"Reuters\" that \"My hope over time is that some of the things, the couple of things that’s been pulled, come back. I have great hope on that and great optimism on that\". However, \"TechCrunch\"s Jon Russell criticized this line of thinking, writing that \"Firstly, Apple didn’t just remove a \"couple of things\" from the reach of China-based users\", but rather \"a couple of hundred\" apps, acknowledging that \"even that is under counting\". Furthermore, Russell listed censorship efforts by the Chinese government, including VPN bans and restrictions on live video and messaging apps, and wrote that \"Apple had little choice but to follow Beijing’s line in order to continue to do business in the lucrative Chinese market, but statements like Cook’s today are dangerous because they massively underplay the severity of the situation\". Florida Senator Marco Rubio also criticized Cook's appearance at the World Internet Conference, describing the situation as \"here’s an example of a company, in my view, so desperate to have access to the Chinese market place that they are willing to follow the laws of that country even if those laws run counter to what those companies’ own standards are supposed to be\". In August 2018, as a result of Chinese regulations, 25,000 illegal apps were pulled down by Apple from the App Store in China.\n\n\n"}
{"id": "48924130", "url": "https://en.wikipedia.org/wiki?curid=48924130", "title": "Applied Energy", "text": "Applied Energy\n\nApplied Energy is a peer-reviewed academic journal covering research on energy engineering that was established in 1975. It is published by Elsevier and the editor-in-chief is Jinyue Yan. According to the \"Journal Citation Reports\", the journal has a 2014 impact factor of 5.613, ranking it 9th out of 89 journals in the category \"Energy & Fuels\" and 6th out of 135 journals in \"engineering, chemical\".\n\n"}
{"id": "37859328", "url": "https://en.wikipedia.org/wiki?curid=37859328", "title": "Australian Computer Museum Society", "text": "Australian Computer Museum Society\n\nThe Australian Computer Museum Society Inc, (ACMS) is a society dedicated to the preservation of the history of computing in Australia, including software, hardware, operating systems and literature. ACMS was registered and is a charitable institution which relies on memberships and donations to operate. Established in 1994, their members have since amassed a large number of unique devices designed and built by Australians.\n"}
{"id": "8373894", "url": "https://en.wikipedia.org/wiki?curid=8373894", "title": "Automated truck loading systems", "text": "Automated truck loading systems\n\nAutomated Truck Loading Systems - ATLS has been commonly used in the material handling industry to refer to the automation of loading or unloading trucks and trailers with product either on or without pallets, slip sheets, racks, containers, using several different types of automated guided vehicle systems (AGV) or engineered conveyor belt systems that are integrated into vehicles, automating the shipping / receiving and logistics operations.\n\nThese conveyor systems are commonly referred to as\n\n\nSome of these systems are used to handle bulk products such as garbage, agriculture products, recycled tires, cotton, bark or sawdust. Manufacturing industries such as automotive, food & beverage, paper, consumer products, appliance manufacturers and uses ATLS systems for incoming materials and outgoing product to increase throughput and streamline production. The transportation industry relies heavily on ATLS material handling systems to rapidly move product via land, sea, and air.\n\nNext to solutions for palletised goods, Ancra Systems developed a custommade trailer unloading system for the automatic unloading of loose loaded parcels. The major advantages of this solution:\n\n\nATLS vehicle loading technologies significantly reduce the manpower required on the shipping and receiving docks, eliminate product damage, accidents, and ergonomic injuries related to lift-truck operation. Generally, products can be loaded quicker and product density is increased resulting in more payload per shipment which reduces shipping cost, using a loading automation system. Loading automation is often the key component to achieve complete plant automation.\n\n"}
{"id": "10697483", "url": "https://en.wikipedia.org/wiki?curid=10697483", "title": "Blast wall", "text": "Blast wall\n\nA blast wall is a barrier designed to protect vulnerable buildings or other structures and the people inside them from the effects of a nearby explosion, whether caused by industrial accident, military action or terrorism.\n\nResearch by Cranfield University Defence Academy, building on earlier work, has shown that blast walls have the following properties:\n\nPermanent blast walls can be made from pre-cast reinforced concrete, or steel sheeting. Various types of moveable blast wall have been manufactured. These include the Bremer wall concrete barriers used in Iraq and Afghanistan by US Armed Forces, and the HESCO bastions, wire mesh containers filled with sand or soil, which are used by British Armed Forces.\n\n"}
{"id": "28207659", "url": "https://en.wikipedia.org/wiki?curid=28207659", "title": "Brooklyn College Center for Computer Music", "text": "Brooklyn College Center for Computer Music\n\nThe Brooklyn College Center for Computer Music (BC-CCM) located at Brooklyn College of the City University of New York (CUNY) was one of the first computer music centers at a public university in the United States. The BC-CCM is a community of artists and researchers that began in the 1970s.\n\nThe mission of the BC-CCM is to explore the creative possibilities of technology in relation to the creation of music, sound art, sound design, and multimedia arts. Courses cover techniques of music composition with digital tools and instruments, theories and implementation of sound processing and sound synthesis, design and creation of new digital music and multimedia performance instruments, audio production, history and aesthetics of experimental music and sound art, and creative collaboration. The BC-CCM also sponsors residencies of visiting composers and media creators.\n\nThe Brooklyn College Center for Computer Music began when composer Robert Starer, then a member of the faculty of the Conservatory of Music at Brooklyn College, proposed the idea of creating an electronic music studio at Brooklyn College in the mid-1970s. The idea took root, and Jacob Druckman and Noah Creshevsky were the studio’s first Co-Directors. In those early days the equipment consisted largely of Moog analog synthesizers. Charles Dodge took over as Director in 1978, and he was responsible for having the studios designated as a center within Brooklyn College, the Center for Computer Music (CCM).\n\nCharles Dodge was a pivotal figure in the history of the center. Dodge, originally from Iowa, had done a bachelor's degree at the University of Iowa and then earned his MA and doctorate (DMA) in Music Composition at Columbia University. While at Columbia, Dodge was very active at the Columbia-Princeton Electronic Music Center. In particular, Dodge was one of the leading innovators in the emerging field of computer music composition (as opposed to analog electronic composition, the norm in the field through the 1970s). Dodge created some of the first meritorious works in the field of computer music, including Earth’s Magnetic Field (1970), which mapped magnetic field data to musical sounds, Speech Songs, a 1974 work that used analysis and resynthesis of human voices, and Any Resemblance is Purely Coincidental (1980), which combines live piano performance with a digitally-manipulated recording of Enrico Caruso singing the aria \"Vesti la giubba\".\n\nDuring Dodge’s years as Professor of Composition and Director of the Brooklyn College Center for Computer Music (BC-CCM), Dodge had the CCM designated as a center within Brooklyn College in 1978, and brought it to a world-class standing in the field of computer music. Dodge secured an initial donation of equipment from Bell Laboratories, and then proceeded to acquire large grants to fund BC-CCM work. The facilities received funding through grants from the United States Office of Education, the National Endowment for the Arts, the City University of New York Faculty Research and Award Program, and the Rockefeller Foundation, and through donations from private individuals.\n\nUnder Dodge’s leadership and with the efforts of numerous students, guests and artistic partners, the BC-CCM came to national prominence. At that time the USA was leading the world in the field of computer music, and so this made the BC-CCM one of the world’s most highly regarded centers. During these years, the BC-CCM presented summer workshops, which were attended by musicians from around the world, and hosted residencies for many composers of national and international stature, including John Cage, Lejaren Hiller, Laurie Spiegel, and Judy Klein, Larry Austin, the Fylkingen Group from Stockholm, EMS Sweden, Robert Dick, Bob Ostertag, Morton Subotnick, Pauline Oliveros, Jon Appleton, Noah Creshevsky, James C. Mobberley, Jean Claude Risset, Lars Gunnar Bodin, Sten Hanson, and directors of IMEB Françoise Barriere and Christian Clozier. This helped attract outstanding students, some of whom are now leaders in the field today, including Curtis Bahn (faculty, Rensselaer Polytechnic Institute), Matthew Suttor (faculty, Yale), Jason Stanyek (faculty, NYU), and Madelyne Byrne (faculty, Palomar College).\n\nIn the early 1990s after Charles Dodge stepped down as Director of the BC-CCM Noah Creshevsky assumed the directorship, with George Brunner as Technical Director. It was at this time that the CCM began to host an International Electro-Acoustic Music Festival and concert series, offering performances of music, video, film, and live electronic works by artists from around the world. When Noah Creshevsky retired in 2000, George Brunner took over as Acting Director until Amnon Wolman was named Director in 2003. Douglas Cohen generously served as Acting Director while Wolman was on an extended leave, and Douglas Geers joined the faculty as Director of the BC-CCM in fall of 2009.\n\nCurrent faculty include composer Douglas Geers, Director; composer-producer George Brunner, Director of Music Technology; composer Doug Cohen, Associate Director; guitarist/composer David Grubbs; media artist John J.A. Jannone; audio producer Miguel Macias; and computer scientist Elizabeth Sklar.\n\n\n\n"}
{"id": "32347351", "url": "https://en.wikipedia.org/wiki?curid=32347351", "title": "California pottery", "text": "California pottery\n\nCalifornia pottery includes industrial, commercial, and decorative pottery produced in the Northern California and Southern California regions of the U.S. state of California. Production includes brick, sewer pipe, architectural terra cotta, tile, garden ware, tableware, kitchenware, art ware, figurines, giftware, and ceramics for industrial use. Ceramics include terra cotta, earthenware, porcelain, and stoneware products.\nKey milestones in the history of California pottery include: the arrival of Spanish settlers, the advent of Statehood and subsequent population growth, the arts and crafts movement, Great Depression, World War II era and the post-WWII onslaught of low-priced imports leading to a steep decline in the number of California potteries. California potters large and small have left a legacy of tableware design, collectibles, art, and architecture.\n\nTile has been a favorite building material in California since the early Spanish settled the area and brought with them the tradition of using brightly-colored tiles in architecture. Helen Stiles, author of numerous books on the history of pottery, noted that Spanish, Mexican, and Chinese design of the 17th and 18th centuries all influenced the decoration of tile and other pottery in California.\n\nAs people moved into California after statehood in 1848, the demand for ceramic products grew exponentially. Buildings needed roofs, floors, and sewer pipes. The ceramic industry grew as the demand increased. The \"Golden Era in tile making\" and art pottery, influenced by the Arts and Crafts movement, was around 1910. Architect Julia Morgan used tiles to adorn her buildings including the Hearst Castle in the 1920s.\n\nThe most active period for the production of household ceramics including tableware, kitchenware, giftware, and art ware was from the 1930s through the 1960s. The major area of U.S. household ceramics production was in the Los Angeles basin. Around Los Angeles there were over 300 producers of figurines. Next in size was the Trenton area, followed by East Liverpool, and a few in the middle west such as Ceramic Arts Studio, Red Wing Pottery and Haeger Potteries.\n\nThe period around World War II saw the greatest growth for the U.S. ceramic industry. With imports cut off from European and Asian markets, small family-owned and larger potteries stepped in to fill the need for ceramic giftware and tableware throughout the United States. By 1948, \"the peak year for the industry, over eight hundred ceramic concerns were in operation throughout California.\" \nWith sunlight year round, an abundance of raw materials, and relatively inexpensive natural gas, California became competitive with centers of ceramic production such as the \"Pottery Capital of the World\" East Liverpool, Ohio and Stoke-on-Trent, Staffordshire, England.\n\nIn the 1950s, favorable trade agreements toward Asian countries contributed to a flood of competitively priced ceramic wares entering the United States market. Only a fraction of California potteries survived this competition through the early 1960s. Today, only a few are still in business.\n\nThe \"Big Five\" California potteries, from the 1930s to the 1960s in reference to the range of products and output, were Vernon Kilns, J.A. Bauer Pottery, Metlox Potteries, Pacific Clay Products, and Gladding, McBean & Co. All of the \"Big Five\" potteries operated production facilities in the Los Angeles Basin. Gladding, McBean & Co. grew from one factory manufacturing sewer pipe and architectural terra cotta in Lincoln, California to factories throughout California and the Pacific Northwest. Vernon Kilns closed in 1958, J.A. Bauer in 1962, and Metlox in 1988. The former Gladding, McBean & Co.'s Franciscan tableware and tile factory in Los Angeles was bought by Wedgwood from the Interpace corporation in 1979. Wedgwood closed the Franciscan Ceramics plant in 1984, moving production of the Franciscan tableware brands to England. The former Gladding, McBean & Co.'s Lincoln factory was purchased by Pacific Coast Building Products in 1976 and continues to produce sewer pipe, architectural terra cotta, and terra cotta garden ware. Pacific Clay Products discontinued manufacturing tableware, art ware, and figurines in 1942. Pacific Clay Products continues to manufacture sewer pipe.\n\nTo use the sortable tables: click on the icons at the top of each column to sort that column in alphabetical order; click again for reverse alphabetical order.\n\n\"Geographically, see Northern California.\"\n\nTo use the sortable tables: click on the icons at the top of each column to sort that column in alphabetical order; click again for reverse alphabetical order.\n\n\"Geographically, see Southern California.\"\n\nTo use the sortable tables: click on the icons at the top of each column to sort that column in alphabetical order; click again for reverse alphabetical order.\n\n"}
{"id": "1096481", "url": "https://en.wikipedia.org/wiki?curid=1096481", "title": "Content industry", "text": "Content industry\n\nThe content industry is an umbrella term that encompasses companies owning and providing mass media and media metadata. This can include music and movies, text publications of any kind, ownership of standards, geographic data, and metadata about all and any of the above.\n\nIn the Information Age, the content industry comprises an enormous market.\n\n"}
{"id": "6188446", "url": "https://en.wikipedia.org/wiki?curid=6188446", "title": "Cutting balloon", "text": "Cutting balloon\n\nA cutting balloon is an angioplasty device invented by Barath \"et al.\" used in percutaneous coronary interventions. It has a special balloon tip with small blades, that are activated when the balloon is inflated. This procedure is different from Rotoblation (Percutaneous Transluminal Rotational Atherectomy or PCRA) whereby a diamond tipped device spins at high revolutions to cut away calcific (chalky) atheroma usually prior to coronary stenting. Boston Scientific's Flextome is the most widely used cutting balloon.\n\n\n"}
{"id": "4692745", "url": "https://en.wikipedia.org/wiki?curid=4692745", "title": "Department of Energy (Philippines)", "text": "Department of Energy (Philippines)\n\nThe Philippines' Department of Energy (, abbreviated as DOE) is the executive department of the Philippine Government responsible for preparing, integrating, manipulating, organizing, coordinating, supervising and controlling all plans, programs, projects and activities of the Government relative to energy exploration, development, utilization, distribution and conservation.\n\nThe Department of Energy was created by then President Marcos as he issued Presidential Decree No. 1206 which created the Ministry of Energy and attached the National Power Corporation and Philippine National Oil Company to this new agency. The Ministry and its two bureaus (Bureau of Energy Development and Bureau of Energy Utilization) remained intact but was downgraded into a mere Office of Energy Affairs--headed by Wenceslao de la Paz and reporting to then Deputy Executive Secretary for Energy Catalino Macaraig, Jr. based in Malacanang--during the regime of President Corazon Aquino. During the regime of President Fidel V. Ramos, the Department was created due to Republic Act No. 7638 otherwise known as the \"Department of Energy Act of 1992\".\n\nThe Department was vested additional powers and functions under pertinent energy and power-related legislations, such as Republic Act (RA) No. 9136 or the \"Electric Power Industry Reform Act of 2001\", RA No. 9367 or \"Biofuels Act of 2006\", and RA No. 9513 or \"Renewable Energy Act of 2008.\n\nThe Department is headed by the Secretary of Energy who is assisted by three Undersecretaries and three Assistant Secretaries. Under the Department are the Administrative Service, Financial Service, Information Technology and Management Service, Legal Service and Energy Research Testing and Laboratory Service. \n\nThe Department is composed of the following bureaus: \n\nThe following units, agencies and corporations are attached to the Department:\n\nDue to the rapid growth of the country's population and the interrelated growing of the country's demand for energy, the Department of Energy (DOE) introduced its Philippine Energy Plan 2009–2030.\n\nThe plan for the period 2009–2030 mentions three broad policy thrusts based on the concept of enabling better energy choices for a better quality of life.\n\nOn April 28, 2010, Director Jesus Tamang of the Energy Policy and Planning Bureau explained that keeping the self-sufficiency level on nearly 60% will be challenging, but he also stated that a way to counter-streer this massive population growth was the country's future investments in new projects that are targeted in the plan.\n\nThe DOE's proposal consists of these following three principles that will have an important impact within the next 20 years on the country’s energy future:\n\n\n\n\n\n\n"}
{"id": "13333998", "url": "https://en.wikipedia.org/wiki?curid=13333998", "title": "Dielectric resonator antenna", "text": "Dielectric resonator antenna\n\nA dielectric resonator antenna (DRA) is a radio antenna mostly used at microwave frequencies and higher, that consists of a block of ceramic material of various shapes, the dielectric resonator, mounted on a metal surface, a ground plane. Radio waves are introduced into the inside of the resonator material from the transmitter circuit and bounce back and forth between the resonator walls, forming standing waves. The walls of the resonator are partially transparent to radio waves, allowing the radio power to radiate into space.\n\nAn advantage of dielectric resonator antennas is they lack metal parts, which become lossy at high frequencies, dissipating energy. So these antennas can have lower losses and be more efficient than metal antennas at high microwave and millimeter wave frequencies. Dielectric waveguide antennas are used in some compact portable wireless devices, and military millimeter-wave radar equipment. The antenna was first proposed by Robert Richtmyer in 1939. In 1982, Long et al. did the first design and test of dielectric resonator antennas considering a leaky waveguide model assuming magnetic conductor model of the dielectric surface . \n\nAn antenna like effect is achieved by periodic swing of electrons from its capacitive element to the ground plane which behaves like an inductor. The authors further argued that the operation of a dielectric antenna resembles the antenna conceived by Marconi, the only difference is that inductive element is replaced by the dielectric material.\n\nDielectric resonator antennas offer the following attractive features:\n\n\n\n\n"}
{"id": "38378108", "url": "https://en.wikipedia.org/wiki?curid=38378108", "title": "Digital Storm", "text": "Digital Storm\n\nDigital Storm is a privately owned boutique computer manufacturer in the United States that primarily specializes on high-performance gaming desktop and laptop computers. Headquartered in Fremont, California, the company also sells upgrade components and gaming peripherals, such as headsets, gaming mice, custom keyboards and high-resolution computer monitors.\n\nDigital Storm was founded in 2002. Originally an internet retailer of computer components, the company began building custom gaming PCs after repeated requests by customers for pre-assembled systems.\nThe first custom-built PC system the company ever marketed was the Digital Storm Twister. In 2012, the company began designing proprietary designs, starting with their Aventum and the Bolt models.\n\nFocusing heavily on the gaming market, Digital Storm’s designs for gaming desktops and laptops focus primarily on high-performance custom PC configurations, though they also produce workstation models. They specialize in customizing each machine with features such as overclocking, dual video card implementations (such as SLI), RAID arrays, liquid-cooling systems and noise-reduction modifications.\n\nDigital Storm also sells upgrade PC components such as computer memory, video cards, CPUs, motherboards, hard drives, cooling systems and computer monitors. They also offer accessories aimed at gamers, such as custom keyboards, audio headsets and gaming mice.\n\nIn 2013, they began offering a service called LaserMark, which allows custom images to be etched onto computer cases.\n\nThe company offers custom overclocking of CPUs and GPUs through its “Twister Boost” technology on many of its gaming computers.\n\nBefore shipping out an order, a technician for Digital Storm performs 72-hour stress testing and quality control to screen for assembly errors, faulty components and other quality issues.\n\nOn most desktop models, Digital Storm offers Cryo-TEC and Sub-Zero liquid cooling systems.\n\nDigital Storm’s systems are often reviewed by technology writers and gaming industry publications. For their more notable systems, they have received critical acclaim and awards.\nIn 2012, the company was recognized as a Design and Engineering Award Honoree for its Cryo-TEC cooling system.\nThe Bolt, Digital Storm’s most successful gaming PC model, received Maximum PC’s \"Kick-Ass Award\" in 2013, and also received special attention for the compact design and performance measurements.\nUbergizmo called it the \"thinnest gaming PC in the world.\"\nThe Aventum, another of the company’s more popular models, won the \"2012 Best of What’s New\" award from the editors of Popular Science Magazine, who called it a \"melt-down proof computer.\"\n\n\n"}
{"id": "49416930", "url": "https://en.wikipedia.org/wiki?curid=49416930", "title": "Einfochips", "text": "Einfochips\n\neInfochips is a Product Engineering and Software R&D Services firm based in Sunnyvale, California that offers solutions in software, hardware, VLSI and mechanical engineering services. In January 2018, the company was acquired by Arrow Electronics (a Fortune #113 brand), for its specialization in IoT, product transformation and digital transformation capabilities. The company has developed its niche as a technology partner for several Fortune 500 product companies and hi-tech firms such as Qualcomm, Texas Instruments, Toshiba, and Microsemi and is also a development partner for companies including Microsoft, Amazon, and Intel. The company provides a range of products and services spanning multiple industries including semiconductors, aerospace & defense, medical devices, industrial automation, retail & e-Commerce, automotive, video surveillance, and smart city.\n\nThe company further claims to have expertise in various technologies for Internet of Things, Business Intelligence, Cloud, Deep Learning and Video Analytics. It has collaborated with its partners on a number of projects including LinkNYC, an ambitious network to cover New York City with free Wi-Fi service by converting old payphones into hotspot points and the global IoT network called ZigBee Alliance. It has further collaborated with Kroger on retail site intelligence solutions. einfochips was chosen by Rockwell Collins as their Global Supplier of the Year 2014 for Engineering and Design Services. It was able to shrink design cycles by six months for Texas Instrument's 6AK2Ex processors.\n\neInfochips was founded in 1994 by Pratul Shroff. with global headquarters in both Ahmedabad, India and Sunnyvale, California and has 1500 employees worldwide. From its origins as a chip design company, it has over the years, diversified into complete product engineering and R&D services spanning multiple industries. It has further developed sales presence across Austin, Boston, Cedar Rapids, Cincinnati, Chicago, Dallas and Raleigh in the US, Toronto (Canada), Tokyo (Japan) and London (UK).\n\neInfochips is primarily known in the semiconductor industry for its Eragon product line, which is a development platform based on Qualcomm Snapdragon processors. It has found application across a variety of industry segments including industrial, security and surveillance, infotainment, avionics (in-flight entertainment), display systems (digital signage, smart vending), and Internet of Everything (IoE) systems, and also smart cities, smart grid, smart transit and smart factories. The Eragon600 System on Module (SoM) and the development kit was displayed at Embedded World 2015 conference in Nuremberg, Germany, where the company showcased an interactive digital signage solution based on Snapdragon 600 processor. With real-time video analytics captured from an IP camera, eInfochips measured the attention span and popularity of the signage content, and updated it in real-time. The setup also included an AllJoyn™ based mobile application to empower viewers to interact with the digital signage content.\nAccording to Aviation Today magazine, eInfochips was one of the partners chosen by Microsemi to provide DO-254 compliant design services for avionics systems.\n\n\n"}
{"id": "5665192", "url": "https://en.wikipedia.org/wiki?curid=5665192", "title": "Energy crop", "text": "Energy crop\n\nAn energy crop is a plant grown as a low-cost and low-maintenance harvest used to make biofuels, such as bioethanol, or combusted for its energy content to generate electricity or heat. Energy crops are generally categorized as woody or herbaceous plants; many of the latter are grasses of the family \"Graminaceae\".\n\nCommercial energy crops are typically densely planted, high-yielding crop species which are processed to bio-fuel and burnt to generate power. Woody crops such as willow or poplar are widely utilised, as well as temperate grasses such as \"Miscanthus\" and \"Pennisetum purpureum\" (both known as elephant grass). If carbohydrate content is desired for the production of biogas, whole-crops such as maize, Sudan grass, millet, white sweet clover, and many others can be made into silage and then converted into biogas.\n\nThrough genetic modification and application of biotechnology plants can be manipulated to create greater yields, high energy yields can also be realized with existing cultivars.. However, some additional advantages such as reduced associated costs (i.e. costs during the manufacturing process ) and less water use can only be accomplished by using Genetically_modified_crops#Biofuel genetically modified crops.\n\nEnergy generated by burning plants grown for the purpose, often after the dry matter is pelletized. Energy crops are used for firing power plants, either alone or co-fired with other fuels. Alternatively they may be used for heat or combined heat and power (CHP) production.\n\nTo cover the increasing requirements of woody biomass, short rotation coppice (SRC) were applied to agricultural sites. Within this cropping systems fast growing tree species like willows and poplars are planted in growing cycles of three to five years. The cultivation of this cultures is dependent on wet soil conditions and could be an alternative for moist field sieds. However, an influence on local water conditions could not be excluded. This indicates that an establishment should exclude the vicinity to vulnerable wetland ecosystems.\n\nAnaerobic digesters or biogas plants can be directly supplemented with energy crops once they have been ensiled into silage. The fastest growing sector of German biofarming has been in the area of \"Renewable Energy Crops\" on nearly of land (2006). Energy crops can also be grown to boost gas yields where feedstocks have a low energy content, such as manures and spoiled grain. It is estimated that the energy yield presently of bioenergy crops converted via silage to methane is about . Small mixed cropping enterprises with animals can use a portion of their acreage to grow and convert energy crops and sustain the entire farms energy requirements with about one fifth of the acreage. In Europe and especially Germany, however, this rapid growth has occurred only with substantial government support, as in the German bonus system for renewable energy. Similar developments of integrating crop farming and bioenergy production via silage-methane have been almost entirely overlooked in N. America, where political and structural issues and a huge continued push to centralize energy production has overshadowed positive developments.\n\nEuropean production of biodiesel from energy crops has grown steadily in the last decade, principally focused on rapeseed used for oil and energy. Production of oil/biodiesel from rape covers more than 12,000 km² in Germany alone, and has doubled in the past 15 years. Typical yield of oil as pure biodiesel may be is or more, making biodiesel crops economically attractive, provided sustainable crop rotations exist that are nutrient-balanced and preventative of the spread of disease such as clubroot. Biodiesel yield of soybeans is significantly lower than that of rape.\nEnergy crops for biobutanol are grasses. Two leading non-food crops for the production of cellulosic bioethanol are switchgrass and giant miscanthus.\nThere has been a preoccupation with cellulosic bioethanol in America as the agricultural structure supporting biomethane is absent in many regions, with no credits or bonus system in place. Consequently, a lot of private money and investor hopes are being pinned on marketable and patentable innovations in enzyme hydrolysis and the like.\n\nBioethanol also refers to the technology of using principally corn (maize seed) to make ethanol directly through fermentation, a process that under certain field and process conditions can consume as much energy as is the energy value of the ethanol it produces, therefore being non-sustainable. New developments in converting grain stillage (referred to as distillers grain stillage or DGS) into biogas energy looks promising as a means to improve the poor energy ratio of this type of bioethanol process.\n\nDedicated energy crops are non-food energy crops as giant miscanthus, switchgrass, jatropha, fungi, and algae. Dedicated energy crops are promising cellulose sources that can be sustainably produced in many regions of the United States.\n\nAdditionally, the green waste byproducts of food and non-food energy crops can be used to produce various biofuels.\n\n"}
{"id": "30283686", "url": "https://en.wikipedia.org/wiki?curid=30283686", "title": "Finlaycolor", "text": "Finlaycolor\n\nFinlaycolor was an early color photography process.\n\nIn \"Uncle Tungsten,\" Oliver Sacks reminisces:\n\n"}
{"id": "31878431", "url": "https://en.wikipedia.org/wiki?curid=31878431", "title": "Flatrod system", "text": "Flatrod system\n\nThe flatrod system ( or \"Stangenleitung\"; or \"Stånggång\") was an invention of the mining industry that enabled the mechanical movement generated by a water wheel (German: \"Kunstrad\") to be transferred over short distances. It was invented in the 16th century and by the 18th century was being used to transmit power up to four kilometres. Flatrod systems were widely used in the Harz and Ore Mountains of Germany as well as in Cornwall, England and Bergslagen in Sweden.\n\nA replica of a flatrod system may be seen in Bad Kösen in Germany on the River Saale and there is a replica water wheel, used to drive flatrods, in Clausthal-Zellerfeld in the Upper Harz, formerly the biggest mining region in Europe.\n\nThe flatrod system dates to the period before the invention of the steam engine and electricity. Using flatrods it was possible to operate man engines and pumping systems, even though the water wheel in question had a rotary, not a reciprocal, motion. So that the rods could be made to move in a reciprocal fashion, a change of direction had to be achieved by means of specially shaped components. The components of the system that were mounted in the mining shaft were called shaft rods (\"Schachtgestänge\") or pump rods (\"Hubgestänge\"). Systems mounted in drift mines were called drift rods (\"Streckengestänge\").\n\nThe flatrods (\"Feldgestänge\") themselves were used to transfer power over greater distances between the main engine and the pump rods. Iron collars (\"Kunstringe\") were fitted onto the wheel axles, connecting pipes (\"Ansetzröhren\") and metal sleeves (\"Ansteckkielen\") as well as certain parts of the wooden flatrods. The actual rods (\"Kunststangen\") were long squared timbers that transmitted the power horizontally or at an incline. They had articulated iron joints (\"Kunstschlösser\" or \"Stangenschlösser\") that were designed such that they could be interleaved into one another and secured with bolts or screws.\n\nThe lifting rod system ran vertically up the mineshaft, either to transfer power to the individual sets of shaft pumps (when they were known as pump rods) or, in the case of man engines, to operate the man engine rods. In some cases the lifting rod system performed both duties. It consisted of roughly 19 to 20 centimetre thick squared spruce timbers. The poles were dovetailed at the ends and sides and were fixed to one another with correspondingly mortised wooden joints (\"Holzlaschen\"). These joints were tightly bound to the ends of the lifting rods with iron collars. In addition the iron collars were prevented from slipping by bolts inserted through them. At set distances there were also hooks on the sides that were used to hang the piston rods (\"Kolbenstangen\"). So that the horizontal movement of the flat rods could be turned into a vertical movement, a rotating cross-shaped lever (\"Kunstkreuz\") was fitted to the lifting rods. Connexion to the cross lever was achieved using a crank (\"Kunstschloss\"). To balance the load it was usual to have two lifting rods.\n\nThe purpose of the flatrods was to transfer the power of the motive engine over greater distances to the pump rods in the shaft. This was necessary if the motive engine could not be mounted above or immediately next to the mine shaft. A flatrod system had the disadvantage that there were additional efficiency losses due to the greater masses that had to be moved. The reciprocal motion in the joints (\"Schlösser\") of the interconnected flatrods lead to lifting losses of from 25 to 50 percent. In addition the construction of flatrods required additional timber. This was very maintenance-intensive due to the effects of weathering and it needed additional staff to inspect and maintain the flatrods.\n\nThe flatrods consisted of several wooden rods, fitted with iron hinges. At the ends of the rods, on either side, were so-called \"Kunstschlösser\". These were cut to fit in such a way that one rod could be mortised into another. This was necessary so that the flatrods could not slide apart as a result of to-and-fro or up-and-down motion.\n\nThere were two types of flatrod: flatrods with rollers and flatrods with oscillating cranks (\"Schwingen\"). The former were laid on rollers. The rollers consisted of round timbers about eight to ten inches thick, that were firmly set into the ground on their underside and fixed in place with braces. In order to minimise friction, the rod was fitted with a drag rail (\"Schleppschiene\") in the area of the individual rollers that was made of beechwood and long enough to for the entire stroke length.\n"}
{"id": "48313506", "url": "https://en.wikipedia.org/wiki?curid=48313506", "title": "Flow cups", "text": "Flow cups\n\nFlow Cups are designed to accurately measure the viscosity of paints, inks, varnishes and similar products.\n\nThe process of flow through an orifice can often be used as a relative measurement and classification of viscosity.\n\nThis measured kinematic viscosity is generally expressed in seconds of flow time which can be converted into centistokes (cSt) using a viscosity calculator.\n\nFlow cups are manufactured using high grade aluminium alloy with stainless steel orifices (where indicated), Flow Cups are available with a range of UKAS / ISO 17025 certified standard oils to confirm the flow cup is measuring within specification.\n\n"}
{"id": "45657902", "url": "https://en.wikipedia.org/wiki?curid=45657902", "title": "Intelligent laser speckle classification", "text": "Intelligent laser speckle classification\n\nIntelligent laser speckle classification, or ILSC, is a scanning method used to discriminate between various micro-textural structures, such as the cellular components in human skin. or discriminates sub-surface characteristics of any material (e.g. industrial, pharmaceutical, etc.)\n\nAn ILSC scanner is composed mainly of two instruments: A laser and a modified CCD camera. Light from the laser interacts uniquely with various micro-textural structures, creating a specific laser speckle effect (or \"signature\"). This signature can then be read by the incorporated camera, which utilizes Bayesian inference and inbuilt libraries of micro-textures to create a \"laser speckle image\" of the target. Since the method is comparative, it may also be used to differentiate very small changes in micro-structural objects, for example, a change in cell size. This ability to generate \"comparative\" laser speckle images is again due to the interactions between the laser and the cellular objects.\n\nThe concept has been found to be very effective in analyzing human skin for issues caused by ageing, especially in the lower layers of the epidermis, such as the basal layer, and has also been found to be less invasive than other methods, such as confocal microscopy.\nThe potential application areas of ILSC are as follows :\n\n- Skin analysis: it is possible to make an automated parametric discrimination between the two different conditions of skin (e.g. normal or effected by a disease)that are invisible to human eye. This would be particularly very useful for early diagnosis of the systemic diseases where the skin does not yet exhibits their visual effects by the surface changes [3]\n\n- Pharmaceutical inspection :ILSC is also used for pharmaceitical product inspection as the laser light (with an ideal wavelength) can penetrate into the pharmaceutical (tablet) subsurface and scatters back by conveying the subsurface material characteristics to be identified and analysed by ILSC technique \n- Industrial material identification : Depending on laser-material surface interaction, ILSC can identify and discriminate the different materials that are used in industrial production areas (e.g. metal, wood, plastic, etc.) to make the production process in fully automated form by eliminating the most of environmental undesired lightening effects.\n"}
{"id": "4990087", "url": "https://en.wikipedia.org/wiki?curid=4990087", "title": "Lilug", "text": "Lilug\n\nLilug or Long Island Linux User Group, Inc., is a Linux user group based in New York State.\n\nLilug is an official not-for-profit organization, incorporated under Section 402 of the New York State Not-For-Profit corporation law. It is dedicated to spreading public awareness about Linux, and helping others to become more familiar with it.\n\nThe group was formed in December 1998, out of interested parties from two previously-existing organizations, the Farmingdale Linux and Associated Technologies Club and the Brookhaven National Laboratory Local Linux Users Group. It meets monthly on the second Tuesday of each month on the Cold Spring Harbor Lab Woodbury Campus, in the Woodbury Auditorium.\n\nLilug has two special interest groups, one for developers and one for security. The SIGs are usually smaller events with a more discussion-oriented approach.\n\n\n\n"}
{"id": "53703349", "url": "https://en.wikipedia.org/wiki?curid=53703349", "title": "Loitering munition", "text": "Loitering munition\n\nA loitering munition (also known as a suicide drone or kamikaze drone) is a weapon system category in which the munition loiters around the target area for some time, searches for targets, and attacks once a target is located. Loitering munitions enable faster reaction times against concealed or hidden targets that emerge for short periods without placing high-value platforms close to the target area, and also allow more selective targeting as the actual attack mission can be aborted. \n\nLoitering munitions fit in the niche between cruise missiles and unmanned combat aerial vehicles (UCAVs) sharing characteristics with both. They differ from cruise missiles in that they are designed to loiter for a relatively long time around the target area, and from UCAVs in that a loitering munition is intended to be expended in an attack and has a built-in warhead.\n\nLoitering weapons first emerged in the 1980s for use in the Suppression of Enemy Air Defenses (SEAD) role against surface-to-air missiles (SAMs), and were deployed for the SEAD role in a number of military forces in the 1990s. Starting in the 2000s, loitering weapons have been developed for additional roles ranging from relatively long-range strikes and fire support down to tactical, very short range battlefield systems that fit in a backpack.\n\nLoitering munitions have proliferated into use by at least 14 countries, with several different types in use as of 2017. The rising proliferation and the ability to use some systems as lethal autonomous weapons coupled with ethical concerns over such use have led to research and discussion by International humanitarian law scholars and activists.\n\nInitially, loitering munitions were not referred to as such but rather as suicide UAVs or loitering missiles. Different sources point at different projects as originating the weapon category. The early 1980s initial Israeli Delilah variants or the failed US AGM-136 Tacit Rainbow program are mentioned by some sources. Alternatively, the late 1980s IAI Harpy which was widely exported is considered by some as the first loitering munition system.\n\nEarly projects did not use the \"loitering munition\" nomenclature which emerged at a much later date, and used existing terminology at the time. For instance the AGM-136 Tacit Rainbow was described as follows in a 1988 \"Air Force Magazine\" article: \n\nThe response to the first generation of fixed installation surface-to-air missiles (SAMs) such as SA-2 and SA-3 was the development of the anti-radiation missile such as AGM-45 Shrike and other means to attack fixed SAM installations, as well as developing SEAD doctrines. The Soviet counter-response was the use of mobile SAMs such as SA-6 with intermittent use of radar. Thus, the SAM battery was only visible for a small period of time, during which it was also a significant threat to high-value Wild Weasel fighters. In 1982 Operation Mole Cricket 19 various means including UAVs and air-launched Samson decoys were used over suspected SAM areas to saturate enemy SAMs and to bait them to activate their radar systems, which were then attacked by anti-radiation missiles.\n\nIn the 1980s, a number of programs, such as the IAI Harpy or the AGM-136 Tacit Rainbow, integrated anti-radiation sensors into a drone or missile air frames coupled with command and control and loitering capabilities. This allowed the attacking force to place relatively cheap munitions in place over suspected SAM sites, and to attack promptly the moment the SAM battery is visible. This integrated the use of a drone as a baiting decoy with the attack role into one small and relatively cheap platform in comparison to the alternative wild weasel jet fighter.\n\nStarting in the 2000s, loitering weapons have been developed for additional roles beyond the initial SEAD role ranging from relatively long-range strikes and fire support down to tactical, very short-range battlefield use such as the AeroVironment Switchblade which is deployed at the platoon level and fits in a backpack. A documented use of loitering munitions was in 2016 Nagorno-Karabakh clashes in which an IAI Harop was used against a bus functioning as a troop transport.\n\nLoitering munitions may be as simple as an unmanned aerial vehicle (UAV) with attached explosives that is sent on a potential \"kamikaze\" mission, and may even be constructed with off the shelf commercial quadcopters with strapped on explosives.\n\nPurpose built munitions are more elaborate in flight and control capabilities, warhead size and design, and on-board sensors for locating targets. Some loitering munitions use a human operator to locate targets whereas others, such as IAI Harop, can function autonomously searching and launching attacks without human intervention.\n\nSome loitering munitions may return and be recovered by the operator if they are unused in an attack and have enough fuel; in particular this is characteristic of UAVs with a secondary suicide mission. Other systems, such as Delilah or IAI Harop, don't have a recovery option and are self-destructed in mission aborts.\n\nLoitering munitions fit in the niche between cruise missiles and unmanned combat aerial vehicles (UCAVs).\n\nThe following table compares similar size-class cruise missiles, loitering munitions, and UCAVS:\n\nWhereas some cruise missiles, such as the block IV Tomahawk, have the ability to loiter and have some sensory and remote control features, their primary mission is typically strike and not target acquisition. Cruise missiles, as their name implies, are optimized for long-range flight at constant speed both in terms of propulsion systems and wings or lifting body design. They are often unable to loiter at slow fuel-efficient speeds which significantly reduces potential loiter time even when the missile has some loiter capabilities.\n\nConversely almost any UAV could be piloted to crash onto a target in a suicide attack and most could be fitted with an improvised explosive warhead. However the primary use of a UAV or UCAV would be for recoverable flight operations carrying reconnaissance equipment and/or munitions. While many UAV designs are explicitly designed with loitering in mind, they are not optimized for a diving attack often lacking forward facing cameras, lacking in control response-speed which is unneeded in regular UAV flight, and are noisy when diving at the target potentially providing warning to the target. UAV's, being designed as multi-use platforms, often have a unit cost that is not appropriate for regular one-time expendable mission use.\n\nThe primary mission of a loitering munition is reaching the suspected target area, target acquisition during a loitering phase, followed by a suicide strike, and the munition is optimized in this regard in terms of characteristics (e.g. very short engine life time, silence in strike phase, speed of strike dive, optimization toward loitering time instead of range/speed) and unit cost (appropriate for a one-off strike mission).\n\nLoitering munitions that are capable of making autonomous attack decisions (man out of the loop) raise moral, ethical, and international humanitarian law concerns because a human being is not involved in making the actual decision to attack and potentially kill humans. Whereas some guided munitions may lock-on after launch or may be sensor fuzed, their flight time is typically limited and a human launches them at an area where enemy activity is strongly suspected. An autonomous loitering munition, on the other hand, may be launched at an area where enemy activity is only probable, and loiter searching autonomously for targets for potentially hours following the initial launch decision. The IAI Harpy and IAI Harop are frequently cited in the relevant literature as they set a precedent for an aerial system (though not necessarily a precedent when comparing to a modern naval mine) in terms of length and quality of autonomous function, in relation to a cruise missile for example.\n\nAs of 2017, loitering munitions are in use in several countries, including: \n\n"}
{"id": "23679585", "url": "https://en.wikipedia.org/wiki?curid=23679585", "title": "Mud Gas Separator", "text": "Mud Gas Separator\n\nMud Gas Separator is commonly called a gas-buster or poor boy degasser. It captures and separates the large volumes of free gas within the drilling fluid. If there is a \"kick\" situation, this vessel separates the mud and the gas by allowing it to flow over baffle plates. The gas then is forced to flow through a line, venting to a flare. A \"kick\" situation happens when the annular hydrostatic pressure in a drilling well temporarily (and usually relatively suddenly) falls below that of the formation, or pore, pressure in a permeable section downhole, and before control of the situation is lost.\n\nIt is always safe to design the mud/gas separator that will handle the maximum possible gas flow that can occur.\n\nThe principle of mud/gas separation for different types of vessels is the same.\nThe closed-bottom separator, as the name implies, is closed at the vessel bottom with the mud return line directed back to the mud tanks.\nCommonly called the poor boy, the open-bottom mud gas separator is typically mounted on a mud tank or trip tank with the bottom of the separator body submerged in the mud.\nFluid level (mud leg) is maintained in a float-type mud gas separator by a float/valve configuration. The float opens and closes a valve on the mud return line to maintain the mud-leg level.\nAccording to pedestal or base type there are:\n\nPoor boy degassers are usually named according to the vessel diameter. Types include:\n\nThe degasser type or configuration is typically customisable.\n\nThe principle behind the mud gas separator is relatively simple. On the figure, the mud and gas mixture is fed at the inlet allowing it to impinge on a series of baffles designed to separate gas and mud. The free gas then is moved into the flare line to reduce the threat of toxic and hazardous gases and the mud then discharges to the shale shaker and to the tank.\n\n"}
{"id": "3082158", "url": "https://en.wikipedia.org/wiki?curid=3082158", "title": "Multileaf collimator", "text": "Multileaf collimator\n\nA multileaf collimator (MLC) is a device made up of individual \"leaves\" of a high atomic numbered material, usually tungsten, that can move independently in and out of the path of a particle beam in order to block it.\n\nMLCs are used on linear accelerators to provide conformal shaping of radiotherapy treatment beams. Specifically, conformal radiotherapy and Intensity Modulated Radiation Therapy (IMRT) can be delivered using MLCs.\n\nThe MLC has improved rapidly since its inception and the first use of leaves to shape structures in 1965 to modern day operation and use. MLCs are now widely used and have become an integral part of any radiotherapy department. MLCs were primarily used for conformal radiotherapy, and have allowed the cost effective implementation of conformal treatment with significant time saving, and also have been adapted for use for IMRT treatments. For conformal radiotherapy the MLC allows conformal shaping of the linear accelerator (LINAC) beam to match the borders of the target tumour. For intensity modulated treatments the leaves of a MLC can be moved across the field to create IMRT distributions (MLCs really provide a fluence modulation rather than intensity modulation).\n\nThe MLC is an important tool for radiation therapy dose delivery. It was originally used as a surrogate for alloy block field shaping and is now widely used for IMRT. As with any tool used in radiotherapy the MLC must undergo commissioning and quality assurance. Additional commissioning measurements are completed to model a MLC for treatment planning. Various MLCs are provided by different vendors and they all have unique design features as determined by specifications of design, and these differences are quite significant.\n"}
{"id": "54030316", "url": "https://en.wikipedia.org/wiki?curid=54030316", "title": "NJFX", "text": "NJFX\n\nNJFX, also known as New Jersey Fiber Exchange, is a Wall Township, NJ-based data center operator. The company offers Tier 3 data center, meet-me room and colocation services from a 58 acre site adjacent to Tata Communications' subsea cable landing station.\n\nNJFX was founded by Gil Santaliz, a telecommunications executive who in 2008 sold metro dark fiber provider 4Connections to Optimal Lightpath, a subsidiary of NY cable operator Cablevision (now Altice USA). Tata Communications was a founding partner of NJFX.\n\nNJFX opened a meet-me room (MMR) within Tata Communication’s Wall, NJ subsea cable landing station (CLS). One of Tata's cables terminating in the cable landing station is the Seabras-1 undersea cable, which links North America and Brazil, with a landing point in Sao Paulo. Tata's TGN Atlantic subsea cable also lands in Wall Township, connecting to Highbridge, Somerset, United Kingdom. As the MMR operator, NJFX managed the network connections between its own customers and those of Tata Communication's CLS.\n\nIn September 2015, NJFX announced they would be constructing a 64,000 sq ft Tier III data center adjacent to Tata's CLS, providing direct access to their European and South America subsea cables. Design would be done by Boston-based Bala Consulting Engineers.\n\nIn January 2016, voice and data network provider Windstream announced it was extending its 100 Gigabit Ethernet (100G) network from NJFX's presence at the CLS to Ashburn, Virginia's Internet hub. In September, the new data center came online.\n\nIn March 2017, NJFX announced they were adding an additional data center on their campus.\n\nNJFX operates a data center campus in Wall Township, NJ, offering meet-me room, data center and colocation services to business customers. The center is adjacent to a substation operated by Jersey Central Power & Light (JCP&L), a subsidiary of energy giant FirstEnergy.\n\n"}
{"id": "56106791", "url": "https://en.wikipedia.org/wiki?curid=56106791", "title": "Noise blanker", "text": "Noise blanker\n\nIn the design of radio receivers, a noise blanker is a circuit intended to reduce the effect of certain kinds of radio noise on a received signal.\n\nA noise blanker is a common feature on broadcast shortwave receivers or communications receivers and some types of two-way radio transceivers. The noise blanker is only effective on impulse-type noise such as from lightning or from automotive ignition systems, and cannot improve performance on wideband continuous background noise, or interfering signals on the same frequency. In cases where there are strong signals on frequencies near to the desired frequency, a noise blanker circuit may be ineffective and may reduce the quality of the received signal. \n\nTypically this is a network in the intermediate frequency section of the receiver; when a pulse of noise passes through the IF amplifiers, it is usually of greater amplitude than the desired signal. The noise blanker circuit momentarily reduces the gain of the IF stage during the impulse. More complex noise blankers may use a secondary IF stage and have adjustable threshold and timing characteristics so as to reduce the noise passed through to the audio stages of the receiver.\n\nA noise blanker is best applied before any narrow-bandwidth filters in the signal path, so as not to introduce \"ringing\" and distortion in the filtered signal. Noise blankers are most useful with amplitude modulation or single sideband signals. Frequency modulation receivers generally include a signal limiter stage which tends to reject noise pulses. \n"}
{"id": "17124425", "url": "https://en.wikipedia.org/wiki?curid=17124425", "title": "Nokia Internet tablet", "text": "Nokia Internet tablet\n\nNokia Internet Tablets is the name given to a range of Nokia mobile Internet appliances products. These tablets fall in the range between a personal digital assistant (PDA) and an Ultra-Mobile PC (UMPC), and slightly below Intel's Mobile Internet device (MID).\n\nNokia had plans for an Internet tablet since before 2000. An early model was test manufactured in 2001, the Nokia M510, which was running on EPOC and featuring an Opera browser, speakers and a 10-inch 800x600 screen, but it was not released because of fears that the market was not ready for it. The M510 was first leaked to the public in 2014.\n\nPrior to the introduction of Nokia's Internet tablets, Nokia unveiled two \"media devices\" in 2003-04 which were mobile phones but had a form factor similar to the Internet tablets that followed them. The first of this type of device was the Nokia 7700 which was intended for mass production but ended up being canned in favor of the Nokia 7710 which had a slightly more traditional form-factor and better specs.\n\nNokia Internet Tablets run the Debian Linux-based Maemo, which draws much of its GUI, frameworks, and libraries from the GNOME project. It uses the embedded-targeted Matchbox as its window manager and uses Hildon, a lightweight GTK-based toolkit designed for handheld devices, as its GUI and application framework.\n\nMaemo can be replaced entirely by a number of other Linux distributions.\n\n\n\n"}
{"id": "44532676", "url": "https://en.wikipedia.org/wiki?curid=44532676", "title": "Oilseed press", "text": "Oilseed press\n\nAn oilseed press is a machine that lies at the center of vegetable oil extraction. This is due to the fact that this technology is designed to release oil from oilseeds. Multiple oilseed press layouts have been developed over time to complete this process, with each having its own distinct set of advantages and disadvantages. Moreover, the products that are created by oilseed presses, namely oil and oilseed meal, possess great nutritive benefits for humans and livestock respectively. The oilseed press, being at the center of the oil-extraction process, is joined with various other pieces of equipment and procedures that form a pre- and post-extraction system.\n\nBreaking it down to its simplest formulation, the process that oilseed presses carry out appears is quite simple. Oilseed presses essentially extrude or ‘press’ vegetable oil from oil-bearing seeds, which include soybean, sunflower, peanut, safflower, canola, sesame, niger, castor bean, linseed, mustard, coconut, olive, and oil palm. The simplicity of this procedure is shadowed by the diversity of oilseed press designs that perform it. As seen in Table 1, oilseed press designs can be placed into the three major classes of traditional, manual, and mechanical presses. \nTraditional presses include ghanis, water extraction systems, and other methods. Aside from the ghani, these designs are generally low yielding and particularly labour intensive. Moreover, all the traditional forms mentioned operate on a batch system. This entails that only a given amount of oilseed can be processed at a given time and, when the oil has been extracted, the pressed oilseed must be cleaned out of the machine. Despite these setbacks, traditional oilseed presses are basic in their design and are composed of easily obtainable or easy-to-manufacture equipment.\n\nAs for manual presses, cage style and ram presses are the general layouts. While cage presses operate on a tedious batch system, the operation of ram presses is continuous. The latter point about the ram press design is joined by multiple other advantages that are listed in Table 1. These advantages are especially attractive for developing nations.\n\nThe final major class of oilseed presses, the powered press, is dominated by the expeller. These presses also exhibit continuous operation. Furthermore, they are available in a great range of sizes that can process anywhere from a few kilograms per hour to multiple tons per hour. These and other positive attributes (Table 1) are countered by how powered expellers require electricity or fossil fuels and how the components of expellers can wear quickly.\n\nTable 1: Advantages and Drawbacks of Various Oilseed Press Designs\n\nNote: *Pressure is a good indicator of pressing efficiency for oilseed presses.\n\nNo matter the design, the same end products are obtained from the operation of an oilseed press. After the oil is removed from the oilseed, an oilseed meal or cake remains. This valuable by-product is especially rich in protein. Aside from safflower and sunflower meal, most oilseed meals contain around 40% crude protein. Although this allows most oilseed meals to be readily applied as protein supplements for ruminants such as cattle, the truth is that many of these meals have undesirable amino acid ratios or exhibit poor digestibility which limits their use in swine and poultry diets.\n\nAn exception to this trend is soybean meal. It possesses an excellent amino acid profile, a low fibre content, high digestibility, and high crude protein levels ranging from 44 to 50%. These advantages, including soybean meal’s high lysine content of 6.5%, make it a very appropriate protein supplement in poultry and swine as well as ruminant diets. In fact, soybean meal accounts for 63% of the protein feed sources that are utilized globally. This surpasses the next-leading canola meal, which is also nutritionally adept for feeding to poultry and swine, by a full 51%.\n\nIn addition to the meal, the oil that is procured from oilseed presses possesses nutritive benefits. Oils are naturally energy-dense materials that constitute about 25% of the total caloric intake of the typical individual. Particularly, vegetable oils are composed mainly of unsaturated fats (EUFIC, 2014; Indiana University 2014; Zambiazi et al., 2007), which include the essential omega-3 and -6 polyunsaturated fatty acids. Animal-based fats, in contrast, contain saturated fats, which are linked to cardiovascular disease.\n\nDifferent oilseed species possess unique fatty acid profiles. This same principle applies to the oil contents of various oilseeds as well. For example, while canola typically exhibits an oil content of around 40-45 %, soybeans consist of about 20% oil. Despite these specifics, it is important to note that the amount of oil extracted depends on the efficiency of the extraction process (Lardy, 2008). Decreased oil yield is detrimental in the perspective of oil production, yet is potentially beneficial for livestock producers since the leftover cake’s nutritive value is augmented.\n\nThe actual extruding of vegetable oil from oilseeds by oilseed presses is preceded and followed by several other activities. The first step in the procedure is to have clean, dry seed. Removing material such as rocks, soil, chaff, leaves, sand, dust, and other foreign particles augments pressing efficiency, reduces wear, and decreases the chances of damage being done to the press. Drying seed to around 10% prevents the press from being clogged and also prevents the spread of mould during storage.\n\nFor seeds with hard seed coats such as sunflowers or groundnuts, dehusking or decortication is required. This removal of the seed coats improves productivity and reduces bulk. In addition to decortication, preliminary milling for some oilseeds such as groundnuts is needed. Before the oilseed can be pressed, scorching or heating of the seed may also have to be conducted. An example of this is how soybeans must be roasted to deactivate trypsin inhibitors that are anti-nutritional for swine and poultry. In general, warming seed before processing increases oil yield. Although the best seed temperature for pressing is 38-71 °C, it is known that warming sunflower seed in the sun for just a half hour raises oil yields by 25%.\n\nAll of this leads up to that actual pressing of the oilseed, which is followed by more procedures that involve processing the oil. Clarification removes small contaminants and impurities in the oil by letting the oil sit for a period, which allows the particles to settle. Further clarification can be done by heating the oil or filtering it through a fine cloth. Clarification extends the shelf-life of the oil from days to months.\nDegumming, bleaching, neutralization, and deodorizing are all processes that follow clarification. These procedures are often not applicable to developing nations due to their complexity and the fact that the flavours of unrefined oils are well accepted in these areas. Whether these processes are applied or not, the oil must be stored in some way. Storage containers should be filled with oil to the top, completely clean, air and water tight, and opaque in colour. Moreover, oil should be stored in a cool area away from light.\n"}
{"id": "22306", "url": "https://en.wikipedia.org/wiki?curid=22306", "title": "Overgrazing", "text": "Overgrazing\n\nOvergrazing occurs when plants are exposed to intensive grazing for extended periods of time, or without sufficient recovery periods. It can be caused by either livestock in poorly managed agricultural applications, game reserves, or nature reserves. It can also be caused by immobile, travel restricted populations of native or non-native wild animals. Cows are the main things that causes overgrazing and \"overgrazing\". However, \"overgrazing\" is a controversial concept, based on equilibrium system theory. \n\nIt reduces the usefulness, productivity, and biodiversity of the land and is one cause of desertification and erosion. Overgrazing is also seen as a cause of the spread of invasive species of non-native plants and of weeds. It is caused by nomadic grazers in huge populations of travel herds, such as the American bison of the Great Plains, or migratory Wildebeests of the African savannas, or by holistic planned grazing.\n\nSustainable grassland production is based on grass and grassland management, land management, animal management and livestock marketing. Grazing management, with sustainable agriculture and agroecology practices, is the foundation of grassland-based livestock production since it affects both animal and plant health and productivity. There are several new grazing models and management systems that attempt to reduce or eliminate overgrazing like Holistic management and Permaculture\n\nOne indicator of overgrazing is that the animals run short of pasture. In some regions of the United States under continuous grazing, overgrazed pastures are predominated by short-grass species such as bluegrass and will be less than 2-3 inches tall in the grazed areas. In other parts of the world, overgrazed pasture is typically taller than sustainably grazed pasture, with grass heights typically over 1 meter and dominated by unpalatable species such as \"Aristida\" or \"Imperata\". In all cases, palatable tall grasses such as orchard grass are sparse or non-existent. In such cases of overgrazing, soil may be visible between plants in the stand, allowing erosion to occur, though in many circumstances overgrazed pastures have a greater sward cover than sustainably grazed pastures.\n\nUnder rotational grazing, overgrazed plants do not have enough time to recover to the proper height between grazing events. The animals resume grazing before the plants have restored carbohydrate reserves and grown back roots lost after the last defoliation. The result is the same as under continuous grazing: in some parts of the United States tall-growing species die and short-growing species that are more subject to drought injury predominate the pasture, while in most other parts of the world tall, drought tolerant, unpalatable species such as \"Imperata\" or \"Aristida\" come to dominate. As the sod thins, weeds encroach into the pasture in some parts of the United States, whereas in most other parts of the worlds overgrazing can promote thick swards of native unpalatable grasses that hamper the spread of weeds.\n\nAnother indicator of overgrazing in some parts of North America is that livestock run out of pasture, and hay needs to be fed early in the fall. In contrast, most areas of the world do not experience the same climatic regime as the continental United States and hay feeding is rarely conducted.\n\nOvergrazing is also indicated in livestock performance and condition. Cows having inadequate pasture immediately following their calf's weaning may have poor body condition the following season. This may reduce the health and vigor of cows and calves at calving. Also, cows in poor body condition do not cycle as soon after calving, which can result in delayed breeding. This can result in a long calving season. With good cow genetics, nutrition, ideal seasons and controlled breeding 55% to 75% of the calves should come in the first 21 days of the calving season. Poor weaning weights of calves can be caused by insufficient pasture, when cows give less milk and the calves need pasture to maintain weight gain.\n\nOvergrazing typically increases soil erosion. Reduction in soil depth, soil organic matter and soil fertility impair the land's future natural and agricultural productivity. Soil fertility can sometimes be mitigated by applying the appropriate lime and organic fertilizers. However, the loss of soil depth and organic matter takes centuries to correct. Their loss is critical in determining the soil's water-holding capacity and how well pasture plants do during dry weather.\n\nNative plant grass species, both individual bunch grasses and in grasslands, are especially vulnerable.\n\nIn the continental United States, to prevent overgrazing, match the forage supplement to the herd's requirement. This means that a buffer needs to be in the system to adjust for the fastest growth of forages.\n\nAnother potential buffer is to plant warm-season perennial grasses such as switchgrass, which do not grow early in the season. This reduces the area that the livestock can use early in the season, making it easier for them to keep up with the cool-season grasses. The animals then use the warm-season grasses during the heat of the summer, and the cool-season grasses recover for fall grazing.\n\nThe grazing guidelines in the table are for rotationally grazed, cool-season forages. When using continuous grazing, manage pasture height at one-half the recommended turn-in height for rotational grazing to optimize plant health. The growth habit of some forage species, such as alfalfa, does not permit their survival under continuous grazing. When managing for legumes in the stand, it is beneficial to use rotational grazing and graze the stand close and then give adequate rest to stimulate the legumes' growth.\n\nOvergrazing is used as an example in the economic concept now known as the Tragedy of the Commons devised in a 1968 paper by Garrett Hardin. This cited the work of a Victorian economist who used the over-grazing of common land as an example of behaviour. Hardin's example could only apply to unregulated use of land regarded as a common resource.\n\nNormally, rights of use of Common land in England and Wales were, and still are, closely regulated, and available only to \"commoners\". If excessive use was made of common land, for example in overgrazing, a common would be \"stinted\", that is, a limit would be put on the number of animals each commoner was allowed to graze. These regulations were responsive to demographic and economic pressure; thus rather than let a common become degraded, access was restricted even further. This important part of actual historic practice was absent from the economic model of Hardin.\nIn reality the use of common land in England and Wales was a triumph of conserving a scarce resource using agreed custom and practice.\n\n\nOvergrazing does not necessarily mean total denudation of the land. Overgrazing can also occur with native species. In the Australian Capital Territory, Australia the local government, in 2013, authorised the culling of 1455 kangaroos due to overgrazing.\n\n\n"}
{"id": "4522868", "url": "https://en.wikipedia.org/wiki?curid=4522868", "title": "Philosophy of information", "text": "Philosophy of information\n\nThe philosophy of information (PI) is a branch of philosophy that studies topics relevant to computer science, information science and information technology.\n\nIt includes:\n\nThe philosophy of information (PI) has evolved from the philosophy of artificial intelligence, logic of information, cybernetics, social theory, ethics and the study of language and information.\n\nThe logic of information, also known as the \"logical theory of information\", considers the information content of logical signs and expressions along the lines initially developed by Charles Sanders Peirce.\n\nOne source for the philosophy of information can be found in the technical work of Norbert Wiener, Alan Turing (though his work has a wholly different origin and theoretical framework), William Ross Ashby, Claude Shannon, Warren Weaver, and many other scientists working on computing and information theory back in the early 1950s. See the main article on Cybernetics.\n\nSome important work on information and communication was done by Gregory Bateson and his colleagues.\n\nLater contributions to the field were made by Fred Dretske, Jon Barwise, Brian Cantwell Smith, and others.\n\nThe Center for the Study of Language and Information (CSLI) was founded at Stanford University in 1983 by philosophers, computer scientists, linguists, and psychologists, under the direction of John Perry and Jon Barwise.\n\nMore recently this field has become known as the philosophy of information. The expression was coined in the 1990s by Luciano Floridi, who has published prolifically in this area with the intention of elaborating a unified and coherent, conceptual frame for the whole subject.\n\nThe concept \"information\" has been defined by several theorists.\n\nCharles S. Peirce's theory of information was embedded in his wider theory of symbolic communication he called the \"semeiotic\", now a major part of semiotics. For Peirce, information integrates the aspects of signs and expressions separately covered by the concepts of denotation and extension, on the one hand, and by connotation and comprehension on the other.\n\nClaude E. Shannon, for his part, was very cautious: \"The word 'information' has been given different meanings by various writers in the general field of information theory. It is likely that at least a number of these will prove sufficiently useful in certain applications to deserve further study and permanent recognition. It is hardly to be expected that a single concept of information would satisfactorily account for the numerous possible applications of this general field.\" (Shannon 1993, p. 180). Thus, following Shannon, Weaver supported a tripartite analysis of information in terms of (1) technical problems concerning the quantification of information and dealt with by Shannon's theory; (2) semantic problems relating to meaning and truth; and (3) what he called \"influential\" problems concerning the impact and effectiveness of information on human behaviour, which he thought had to play an equally important role. And these are only two early examples of the problems raised by any analysis of information.\n\nA map of the main senses in which one may speak of information is provided by the Stanford Encyclopedia of Philosophy article. The previous paragraphs are based on it.\n\nGregory Bateson defined information as \"a difference that makes a difference\". which is based on Donald M. MacKay: information is a distinction that makes a difference.\n\nAccording to Luciano Floridi, four kinds of mutually compatible phenomena are commonly referred to as \"information\": \n\nThe word \"information\" is commonly used so metaphorically or so abstractly that the meaning is unclear.\n\nRecent creative advances and efforts in computing, such as semantic web, ontology engineering, knowledge engineering, and modern artificial intelligence provide philosophy with fertile ideas, new and evolving subject matters, methodologies, and models for philosophical inquiry. While computer science brings new opportunities and challenges to traditional philosophical studies, and changes the ways philosophers understand foundational concepts in philosophy, further major progress in computer science would only be feasible when philosophy provides sound foundations for areas such as bioinformatics, software engineering, knowledge engineering, and ontologies.\n\nClassical topics in philosophy, namely, mind, consciousness, experience, reasoning, knowledge, truth, morality and creativity are rapidly becoming common concerns and foci of investigation in computer science, e.g., in areas such as agent computing, software agents, and intelligent mobile agent technologies.\n\nAccording to Luciano Floridi \" one can think of several ways for applying computational methods towards philosophical matters:\n\nNumerous philosophers and other thinkers have carried out philosophical studies of the social and cultural aspects of electronically mediated information.\n\n\n\n\n\n"}
{"id": "12250407", "url": "https://en.wikipedia.org/wiki?curid=12250407", "title": "Powder box", "text": "Powder box\n\nPowder box was a small device used to carry gunpowder. Used for many centuries, they ranged from simple and functional to quite ornate and decorative.\n"}
{"id": "580905", "url": "https://en.wikipedia.org/wiki?curid=580905", "title": "Presence information", "text": "Presence information\n\nIn computer and telecommunications networks, presence information is a status indicator that conveys ability and willingness of a potential communication partner—for example a user—to communicate. A user's client provides presence information (presence state) via a network connection to a presence service, which is stored in what constitutes his personal availability record (called a presentity) and can be made available for distribution to other users (called \"watchers\") to convey his availability for communication. Presence information has wide application in many communication services and is one of the innovations driving the popularity of instant messaging or recent implementations of voice over IP clients.\n\nA user client may publish a presence state to indicate its current communication status. This published state informs others that wish to contact the user of his availability and willingness to communicate. The most common use of presence today is to display an indicator icon on instant messaging clients, typically from a choice of graphic symbols with easy-to-convey meanings, and a list of corresponding text descriptions of each of the states. Even when technically not the same, the \"on-hook\" or \"off-hook\" state of called telephone is an analogy, as long as the caller receives a distinctive tone indicating unavailability or availability.\n\nCommon states on the user's availability are \"free for chat\", \"busy\", \"away\", \"do not disturb\", \"out to lunch\". Such states exist in many variations across different modern instant messaging clients. Current standards support a rich choice of additional presence attributes that can be used for presence information, such as user mood, location, or free text status.\n\nThe analogy with free/busy tone on PSTN is inexact, as the \"on-hook\" telephone status reflects the ability of the network to reach the recipient after the requester has initiated the conversation. The requester must commit to the connection method before discovering the recipient's availability state. Conversely, Presence shows the availability state before a conversation is initiated. A similar comparison might be the requester needing to know if the recipient is at work. The most straightforward way of checking if the recipient is available is to walk to the desk, which requires the commitment of the walk regardless of the outcome and usually requires some interaction if the recipient is at the desk. The requester can call first to save the walk, but now must commit to an interaction via phone. Presence gives the state of the recipient to the requester and the requester has the choice to interact with the recipient or use that information for non-interactive purposes (such as taking roll).\n\nPresence becomes interesting for communication systems when it spans a number of different communication channels. The idea that multiple communication devices can combine state, to provide an aggregated view of a user's presence has been termed Multiple Points of Presence (MPOP). MPOP becomes even more powerful when it is automatically inferred from passive observation of a user's actions. This idea is already familiar to instant messaging users who have their status set to \"Away\" (or equivalent) if their computer keyboard is inactive for some time. Extension to other devices could include whether the user's cell phone is on, whether they are logged into their computer, or perhaps checking their electronic calendar to see if they are in a meeting or on vacation. For example, if a user's calendar was marked as out of office and their cell phone was on, they might be considered in a \"Roaming\" state.\n\nMPOP status can then be used to automatically direct incoming messages across all contributing devices. For example, \"Out of office\" might translate to a system directing all messages and calls to the user's cell phone. The status \"Do not disturb\" might automatically save all messages for later and send all phone calls to voicemail.\n\nXMPP, discussed below, allows for MPOP by assigning each client a \"resource\" (a specific identifier) and a priority number for each resource. A message directed to the user's ID would go to the resource with highest priority, although messaging a specific resource is possible by using the form user@domain/resource.\n\nPresence is highly sensitive information and in non-trivial systems a presentity may define limits to which its presence information may be revealed to different watchers. For example, a worker may only want colleagues to see detailed presence information during office hours. Basic versions of this idea are already common in instant messaging clients as a \"Blocking\" facility, where users can appear as unavailable to selected watchers.\n\nPresence, particularly MPOP, requires collaboration between a number of electronic devices (for example IM client, home phone, cell phone, and electronic calendar) and the presence services each of them are connected with. To date, the most common and wide-scale implementations use closed systems, with a SPOP (Single Point of Presence, where a single device publishes state). Some vendors have upgraded their services to automatically log out connected clients when a new login request reaches the server from a newly connecting different device. For presence to universally work with MPOP support, multiple devices must be able to not only intercommunicate among each other, the status information must also be appropriately handled by all other interoperable, connected presence services and the MPOP scheme for their clients.\n\n2.5G and, even more so, 3G cell phone networks can support management and access of presence information services for mobile users cell phone handsets.\n\nIn the workplace, private messaging servers offer the possibility of MPOP within a company or work team.\n\nPresence information is a growing tool towards more effective and efficient communication within a business setting. Presence information allows you to instantly see who is available in your corporate network, giving more flexibility to set up short-term meetings and conference calls. The result is precise communication that all but eliminates the inefficiency of phone tag or email messaging. An example of the time-saving aspect of presence information is a driver with a GPS; he/she can be tracked and sent messages on upcoming traffic patterns that, in return, save time and money.\n\nAccording to IDC surveys, employees \"often feel that IM gives their workdays the kind of 'flow' that they feel when sitting directly among their colleagues, being able to ask questions of them, and getting the kind of quick responses that allow them to drive on to the next task\". This phenomenon has been called the \"Presence Effect\" in contrast to its predecessor the \"water cooler\" effect, whereby this level of flow was only thought to be achieved in person.\n\nWith presence information, privacy of the users can become an issue. For example, when an employee is on his/her day off they are still connected to the network and have greater ability to be tracked down. Therefore, a concern of presence information is to determine how far the companies want to go with staying connected.\n\nThere was, and still is, significant work done in several working groups on achieving a standardization for presence-related protocols.\n\nIn 1999, a group called the Instant Message and Presence Protocol (IMPP) working group (WG), was formed within the Internet Engineering Task Force organization (IETF) in order to develop protocols and data formats for simple presence and instant messaging services. Unfortunately, IMPP WG was not able to come to consensus on a single protocol for presence. Instead it issued a common profile for presence and instant messaging (CPP) which defined semantics for common services of presence to facilitate the creation of gateways between presence services. Thus any two CPP-compatible presence protocol suites are automatically interoperable.\n\nIn 2001, the SIMPLE working group was formed within IETF to develop a suite of CPP-compliant standards for presence and instant messaging applications over the Session Initiation Protocol (SIP). The SIMPLE activity specifies extensions to the SIP protocol which deal with a publish and subscribe mechanism for presence information and sending instant messages. These extensions include rich presence document formats, privacy control, \"partial publications\" and notifications, past and future presence, watcher information and more. Despite its name, SIMPLE is far from simple. It is described in about 30 documents on more than 1,000 pages. This is in addition to the complexity of the SIP protocol stack on which SIMPLE is based.\n\nAt the end of 2001, Nokia, Motorola, and Ericsson formed the Wireless Village (WV) initiative to define a set of universal specifications for mobile Instant Messaging and Presence Services (IMPS) and presence services for wireless networks. In October 2002, Wireless Village was consolidated into the Open Mobile Alliance (OMA) and a month later released the first version of\nthe XML-based OMA Instant Messaging and Presence Service (IMPS). IMPS defines a system architecture, syntax, and semantics for representation of presence information and a set of protocols for the four primary features: presence, IM, groups, and shared content. Presence is the key, enabling technology for the IMPS.\n\nThe XML-based XMPP or Extensible Messaging and Presence Protocol was designed and is currently maintained by the XMPP Standards Foundation. This IM protocol, which is a robust and widely extended protocol, is also the protocol used in the commercial implementation of Google Talk and Facebook Chat. In October 2004, the XMPP working group at IETF published the documents RFC 3920, RFC 3921, RFC 3922 and RFC 3923, to standardize the core XMPP protocol.\n\n\n"}
{"id": "1119719", "url": "https://en.wikipedia.org/wiki?curid=1119719", "title": "Priority ceiling protocol", "text": "Priority ceiling protocol\n\nIn real-time computing, the priority ceiling protocol is a synchronization protocol for shared resources to avoid unbounded priority inversion and mutual deadlock due to wrong nesting of critical sections. In this protocol each resource is assigned a priority ceiling, which is a priority equal to the highest priority of any task which may lock the resource. The protocol works by temporarily raising the priorities of tasks in certain situations, thus it requires a scheduler that supports dynamic priority scheduling.\n\nThere are two variants of the protocol: Original Ceiling Priority Protocol (OCPP) and Immediate Ceiling Priority Protocol (ICPP). The worst-case behaviour of the two ceiling schemes is identical from a scheduling view point. Both variants work by temporarily raising the priorities of tasks.\n\nIn OCPP, a task X's priority is raised when a higher-priority task Y tries to acquire a resource that X has locked. The task's priority is then raised to the priority ceiling of the resource, ensuring that task X quickly finishes its critical section, unlocking the resource. A task is only allowed to lock a resource if its dynamic priority is higher than the priority ceilings of all resources locked by other tasks. Otherwise the task becomes blocked, waiting for the resource.\n\nIn ICPP, a task's priority is immediately raised when it locks a resource. The task's priority is set to the priority ceiling of the resource, thus no task that may lock the resource is able to get scheduled. This ensures the OCPP property that \"A task can only lock a resource if its dynamic priority is higher than the priority ceilings of all resources locked by other tasks\".\n\n\nICPP is called \"Ceiling Locking\" in Ada, \"Priority Protect Protocol\" in POSIX and \"Priority Ceiling Emulation\" in RTSJ.\nIt is also known as \"Highest Locker's Priority Protocol\" (HLP).\n\n"}
{"id": "43474263", "url": "https://en.wikipedia.org/wiki?curid=43474263", "title": "Radiation Safety Information Computational Center", "text": "Radiation Safety Information Computational Center\n\nThe Radiation Safety Information Computational Center (RSICC) is a U.S. Department of Energy Specialized Information Analysis Center (SIAC) authorized to collect, analyze, maintain, and distribute computer software and data sets in the areas of radiation transport and safety. The RSICC is operated by Oak Ridge National Laboratory in Oak Ridge, Tennessee. The primary sponsors of the RSICC are the U.S. Department of Energy, the U.S. Department of Homeland Security, and the U.S. Nuclear Regulatory Commission.\n\nThe center began as the Radiation Shielding Information Center (RSIC) in 1962, but was renamed to RSICC in August 1996 to better reflect the scope of computer code technology at the center (i.e., radiation transport and safety).\n\nThe RSICC staff maintain an online software catalog at their website, which site visitors may browse (though no search functionality is provided). The software in the catalog cover a broad range of nuclear computational tools, providing in-depth coverage of radiation transport and safety topics for nuclear science and engineering, in support of modeling and simulation. Registered users may request software from the repository. With a few specific exceptions, a \"cost recovery fee\" is required to recoup the cost associated with RSICC operations before software requests are fulfilled.\n\nThe European counterpart to the RSICC is the Organisation for Economic Co-operation and Development’s (OECD) Nuclear Energy Agency (NEA) Data Bank.\n\n\n"}
{"id": "2401965", "url": "https://en.wikipedia.org/wiki?curid=2401965", "title": "Reconfigurable optical add-drop multiplexer", "text": "Reconfigurable optical add-drop multiplexer\n\nIn fiber optics, a reconfigurable optical add-drop multiplexer (ROADM) is a form of optical add-drop multiplexer that adds the ability to remotely switch traffic from a wavelength-division multiplexing (WDM) system at the wavelength layer. This is achieved through the use of a wavelength selective switching module. This allows individual or multiple wavelengths carrying data channels to be added and/or dropped from a transport fiber without the need to convert the signals on all of the WDM channels to electronic signals and back again to optical signals.\n\nThe main advantages of the ROADM are:\n\nROADM functionality originally appeared in long-haul dense wavelength division multiplexing (DWDM) equipment, but by 2005, it began to appear in metro optical systems because of the need to build out major metropolitan networks in order to deal with the traffic driven by the increasing demand for packet-based services.\n\nThe switching or reconfiguration functions of a ROADM can be achieved using a variety of switching technologies including microelectromechanical systems (MEMS), liquid crystal, thermo optic and beam-steering switches in planar waveguide circuits, and tunable optical filter technology.\n\n\n"}
{"id": "21024652", "url": "https://en.wikipedia.org/wiki?curid=21024652", "title": "Reservisor", "text": "Reservisor\n\nStarting in 1946, American Airlines developed a number of automated airline booking systems known as Reservisor. Although somewhat successful, American's unhappiness with the Reservisor systems led them to develop the computerized Sabre system used to this day.\n\nC. R. Smith became president of American Airlines in 1934 and set an aggressive expansion policy. When AA had 85 planes in its fleet he stated \"Any employee who can't see a day when we will have a thousand planes had better look for a job somewhere else.\" Known as a hands-on manager, Smith pushed his vice presidents to drive out inefficiencies that might block their potential expansion.\n\nFollowing Smith's lead, Marion Sadler, manager of customer support, and Bill Hogan, in charge of finance, concluded that the company was spending too much effort on keeping on top of accounting, and not enough on the problem of booking times. They hired Charles Amman to study the problem. He broke the process down into three steps; finding if a seat was available, updating the seating inventory when they purchased a seat or canceled a booking, and finally recording the passenger data (name, address, etc.) after the sale.\n\nAt the time, bookings were handled by a system known as \"request and reply\". Booking data for any particular flight, say Buffalo to Boston, would be handled by a single office. Here, each scheduled flight was represented by an index card known as a flight card. The offices were normally located at one of the airports involved, but were increasingly centralized at major airports or located at a telephone company switching office to ease the adding or removing of phone lines.\n\nIn order to book a ticket on a flight, a sales agent would call into the right booking office and request information on a particular flight. The booking agent would then walk over to a filing cabinet and retrieve the flight card. They would then return to the phone to tell the sales agent if there were any seats available. If there was an available seat, they simply checked off a box, informed the sales agent, and returned the card to the cabinet.\n\nProblems occurred when the flights were close to full. In that case the booking agent would have to inform the sales agent that there were no seats, and the sales agent would then ask the customer if there were any other flights they might choose as an alternative. The booking agent would have to return to the cabinets each time to retrieve the flight cards; since there were many booking agents who might want to retrieve the cards, the agents couldn't take more than one at a time. During busy schedule periods, this process could stretch out the booking process indefinitely.\n\nAmman attacked this problem first. In 1939 he implemented a new system called \"sell and report\" that reduced the reporting needs by allowing any office to book seats without calling the central office until 75% of the seats were sold. Each office had a board of future flights that consisted of a single hole representing a flight; when the flight reached 75% a large peg was inserted that the booking agents could see, sometimes using binoculars. Once the flight had been pegged, the agents reverted to the older centralized booking system. In an era where aircraft rarely flew with 75% of the seats filled, this system dramatically reduced the number of phone calls.\n\nAlthough the \"sell and report\" system worked, it didn't solve the other problems that occurred when the flight had reached the 75% point. The problem of finding an alternate flight when the flight was filled also remained a major problem.\n\nAmman suggested that an automated system for storing seat inventory be built, and in 1944 mocked up a system for a single flight and showed it to Smith. Smith was encouraged, and approved funding for building a real-world system.\n\nAmman approached a number of business machine vendors about building the system he referred to as the Reservisor, but most proved uninterested. It was not until he showed the mock-up to the Teleregister Company of Stamford, Connecticut that he found a partner willing to work on the system. Teleregister had started as part of Western Union, a division that sent stock market quotes across the country and presented them in \"big board\" form instead of a ticker. Their knowledge of remote signaling and electrical display made them a suitable partner for the Reservisor project.\n\nThe Reservisor was essentially an electromechanical version of the flight boards introduced for the \"sell and report\" system. The heart of the machine consisted of a large matrix with the rows representing the flights and the columns representing the next ten days. When a flight reached its limit, 75% at first but later increased, a relay was inserted into the board to short out the lines when they were energized.\n\nBooking operators were equipped with terminals that looked like a smaller version of the control system, replacing the holes with lamps. They could query the flight status by selecting a flight and then energizing their board. Electricity flowed from their terminal through the selected flight, displaying the status for that flight for all ten days at once. The booking agent could then tell the sales agent the flight status without walking to the cabinet, as well as immediately offer alternatives if it was sold out. The flight card was only updated when the customer actually bought a seat.\n\nThe major advantage of this system over the older pegboard was that the signals could be operated remotely. This eliminated the need to have one very large room for bookings, and allowed the terminals to be installed remotely. The flight status could also easily be copied from machine to machine by installing a remote display at another booking office and then having operators copy the settings from one machine to the other.\n\nThe Reservisor was installed in American's Boston reservation office in February 1946. After a one-year trial, they found that the office was handling 200 more passengers a day, with 20 fewer operators. One downside was that the electrical relay contacts would get dirty and required constant cleaning. And although it did help solve the availability issues, this made the rest of the booking task - collecting passenger information and recording the sale - that much more of a problem that needed to be solved.\n\nEncouraged by the Reservisor, but ultimately unhappy with the advantages it offered, Amman started examining a much more advanced system that handled not only the availability issues, but the actual seat inventory as well. At about this time, Howard Aiken had started work with the highly publicized Harvard Mark I computer, which used a drum memory for storage. American and Teleregister decided to make a drum-based system that allowed direct manipulation of the number of seats available.\n\nSince the machine was now returning discrete information, instead of a simple on-off status, the terminals could no longer automatically display the overall status of a group of flights. Each flight had to be queried separately from the drum, and then light the lamp if it was filled. Amman spent a considerable amount of time studying the user interaction with the machine, trying to find an easy way for the operator to query the data for a group of flights.\n\nThe trials included buttons, dials, rolls of paper tape, loops of 35 mm film and finally, the \"destination plate\". The plate consisted of a metal card with notches on the edge that engaged switches in the terminal, which energized lines back to the drum to retrieve information for all of the flights to that destination at once. A series of lights indicated which ones still had available seats. When a booking was made, a lever on the terminal subtracted one seat from the value stored on the drum, while another allowed it to be added back in the case of a cancellation.\n\nThe resulting Magnetronic Reservisor was installed in American's La Guardia Airport booking office in 1952. The system was built with the ability to store information for up to 1,000 flights 10 days into the future, and took about 1.2 seconds per query. In 1956 a new version was installed at American's New York West Side Terminal with storage for 2,000 flights 31 days into the future, and improved access times to about half a second. The new system also recorded additional information every time a booking was made, including statistical information on the number of inquiries, bookings and cancellations on a per-operator and overall basis. To take full advantage of the new system, the entire office was re-arranged to include 362 telephone operators to interact directly with the public, 40 to handle travel agents and large business accounts, and another 140 to connect to other American ticket offices around the country. Calls averaged 45,000 a day, requiring a staff of 40 machine operators and supervisors.\n\nAfter installing the Magnetronic Reservisor, Teleregister produced a number of different versions for a variety of customers. A number of customers bought Magnetronic Reservisor systems, including Braniff International Airways, National Airlines, Atchison, Topeka & Santa Fe Railroad and New Haven Railroad. Modified versions, larger or smaller, were also sold as the United Airlines' \"UNISEL\", New York Central Railroad's \"Centronic\", and a variety of warehousing and hotel room availability systems.\n\nThe Magnetronic Reservisor largely solved the booking and availability problems, but this left the issue of recording passenger information after the sale was made. Working with IBM, Amman built the Reserwriter, which allowed operators to type passenger information onto a punched card for storage. The card was then processed into a paper tape form, and read to the ticketing offices over American's existing teletype network to automatically print tickets with complete routing information. The tapes could then be forwarded for processing at remote sites, including the Magnetronic Reservisor in New York, allowing remote offices to directly book and cancel flights while recording passenger information at the same time. By 1958, Reserwriters had been installed at most of American's larger offices.\n\nIn spite of the successes with the Reservisor and Reserwriter, the system as a whole was highly dependent on manual input. It was prone to errors as a result, and about 8 percent of all bookings contained errors. To add to the confusion, the full process of booking a flight, even a single-leg, required the input of 12 different people and took as long as 3 hours in total.\n\nAs if this were not bad enough, in 1952 American had ordered 30 Boeing 707s, their first jets. These aircraft increased seating from about 80 on the existing Douglas DC-7 fleet to 112 on the new aircraft. Their speed was also much greater, allowing almost twice as many flights per aircraft per day. The result was that the aircraft could deliver passengers faster than their existing booking systems could sell tickets for them.\n\nIn 1953 C.R. Smith was on a flight from Los Angeles to New York when he struck up a conversation with another passenger and learned that he was also named Smith. The passenger was Blair Smith, an IBM sales executive. C.R. arranged for Smith to visit the Magnetronic Reservisor office and suggest ways that IBM might be able to improve the system. Blair alerted IBM's president, Thomas Watson, Jr. that American would be interested in a major collaboration. IBM was at that time starting work on the Semi-Automatic Ground Environment (SAGE) system for the US Air Force, which had a large number of features in common with a booking system; remote communications with \"offices\", real-time updating, interactive user terminals, and storage of large amounts of information.\n\nLow-level exploratory work continued for some time before IBM was able to offer a formal development contract on 18 September 1957. Development of the Sabre system started, which many computer historians have suggested was one of the major milestones in the commercialization of computers. SABRE was not, however, the first computerized booking system, that honor goes to the little-known Trans-Canada Air Lines (today's Air Canada) system, ReserVec.\n\n"}
{"id": "996863", "url": "https://en.wikipedia.org/wiki?curid=996863", "title": "Robert F. Christy", "text": "Robert F. Christy\n\nRobert Frederick Christy (May 14, 1916 – October 3, 2012) was a Canadian-American theoretical physicist and later astrophysicist who was one of the last surviving people to have worked on the Manhattan Project during World War II. He briefly served as acting president of California Institute of Technology (Caltech).\n\nA graduate of the University of British Columbia (UBC) in the 1930s where he studied physics, he followed George Volkoff, who was a year ahead of him, to the University of California, Berkeley, where he was accepted as a graduate student by Robert Oppenheimer, the leading theoretical physicist in the United States at that time. Christy received his doctorate in 1941 and joined the physics department of Illinois Institute of Technology.\n\nIn 1942 he joined the Manhattan Project at the University of Chicago, where he was recruited by Enrico Fermi to join the effort to build the first nuclear reactor, having been recommended as a theory resource by Oppenheimer. When Oppenheimer formed the Manhattan Project's Los Alamos Laboratory in 1943, Christy was one of the early recruits to join the Theory Group. Christy is generally credited with the insight that a solid sub-critical mass of plutonium could be explosively compressed into supercriticality, a great simplification of earlier concepts of implosion requiring hollow shells. For this insight the solid-core plutonium model is often referred to as the \"Christy pit\".\n\nAfter the war, Christy briefly joined the University of Chicago Physics department before being recruited to join the Caltech faculty in 1946 when Oppenheimer decided it was not practical for him to resume his academic activities. He stayed at Caltech for his academic career, serving as Department Chair, Provost and Acting President. In 1960 Christy turned his attention to astrophysics, creating some of the first practical computation models of stellar operation. For this work Christy was awarded the Eddington Medal of the Royal Astronomical Society in 1967. In the 1980s and 1990s Christy participated in the National Research Council's Committee on Dosimetry, an extended effort to better understand the actual radiation exposure due to the bombs dropped on Japan, and on the basis of that learning, better understand the medical risks of radiation exposure.\n\nRobert Frederick Cohen was born in May 14, 1916 in Vancouver, British Columbia, the son of Moise Jacques Cohen, an electrical engineer, and his wife Hattie Alberta née Mackay, a school teacher. He was named Robert after his maternal great uncle Robert Wood, and Frederick after Frederick Alexander Christy, the second husband of his maternal grandmother. He had an older brother, John, who was born in 1913. Moise changed the family surname to Christy by deed poll on August 31, 1918. On November 4, Moise was accidentally electrocuted at work. Hattie died after goitre surgery in 1926. Christy and his brother were then cared for by Robert Wood, their grandmother Alberta Mackay, and their great aunt Maud Mackay.\n\nChristy was educated at Magee High School, and graduated in 1932 with the highest examination score in the province of British Columbia. He was awarded the Governor General's Academic Medal, and, importantly in view of his family's limited ability to pay, free tuition to attend the University of British Columbia (UBC). At the award dinner he met the second-place winner, Dagmar Elizabeth von Lieven, whom he dated while at UBC. He received his Bachelor of Arts (BA) degree in mathematics and physics with first class honors in 1935, and his Master of Arts (MA) degree in 1937, writing a thesis on \"Electron attachment and negative ion formation in oxygen\".\n\nGeorge Volkoff, a friend of Christy who was a year ahead of him at UBC, was accepted as a graduate student at the University of California, Berkeley, by Robert Oppenheimer, who led the most active school of theoretical physics in the United States at that time. This inspired Christy to apply to the University of California as well. He was accepted, and was awarded a fellowship for his first year. At Berkeley he shared an apartment with Volkoff, Robert Cornog, Ken McKenzie and McKenzie's wife Lynn McKenzie. For his thesis, Oppenheimer had him look at mesotrons, subatomic particles called muons today that then recently been found in cosmic rays. They were so-called because they were larger than electrons but smaller than protons. With the help of Shuichi Kusaka he performed detailed calculations of the particle's spin. He published two papers on mesotrons with Kusaka in the Physical Review, which formed the basis of his 1941 Doctor of Philosophy (PhD) thesis \n\nChristy could have graduated in 1940, but could not then be a teaching assistant, and this would have left him jobless and without income. In 1941, Oppenheimer found him a post at the physics department at Illinois Institute of Technology (IIT). In May 1941, he married Dagmar von Lieven. They had two sons: Thomas Edward (Ted), born in 1944, and Peter Robert, born in 1946. IIT paid Christy $200 per month to teach 27 hours per week for 11 months per annum. To keep abreast of developments in physics, he attended seminars at the University of Chicago. This brought him to the attention of Eugene Wigner, who hired him for the same money that IIT was paying him as a full-time research assistant, commencing in January 1942.\nEnrico Fermi and his team from Columbia University arrived at the University of Chicago in January 1942 as part of an effort to concentrate the Manhattan Project's reactor work at the new Metallurgical Laboratory. Fermi arranged with Wigner for Christy to join his group, which was building a nuclear reactor, which Fermi called a \"pile\", in the squash court under Stagg Field at the University of Chicago. Construction began on November 6, 1942, and Christy was present when Chicago Pile-1 went critical on December 2.\n\nIn early 1943, Christy joined Oppenheimer's Los Alamos Laboratory in New Mexico, where he became an American citizen in 1943 or 1944. Hans Bethe, the head of T (Theoretical) Division, detailed his physicists to assist with the projects at the laboratory. With his knowledge of reactors, Christy's assignment was to help Donald W. Kerst's Water Boiler group. The Water Boiler was an aqueous homogeneous reactor intended as a laboratory instrument to test critical mass calculations and the effect of various tamper materials. It was the first reactor to use enriched uranium as a fuel, and the first to use liquid fuel in the form of soluble uranium sulfate dissolved in water. Christy estimated that it would require of pure uranium-235, a figure he subsequently revised to . When the reactor went critical on May 9, 1944 with , the accuracy of Christy's figures raised the laboratory's confidence in T Division's calculations.\n\nThe discovery by Emilio Segrè's group in April and May 1944 of high levels of plutonium-240 in reactor-produced plutonium meant that an implosion-type nuclear weapon was required, but studies indicated that this would be extremely difficult to achieve. By August 1944, the calculations had been made of how an ideal spherical implosion would work; the problem was how to make it work in the real world where jets and spalling were a problem. Christy worked in Rudolf Peierls's T-1 Group, which studied the theory of implosion. He suggested the possibility of using a solid plutonium core that would form a critical mass when compressed. This was an ultra-conservative design that solved the problem of jets by brute force. It became known as the \"Christy pit\" or \"Christy gadget\", \"gadget\" being the laboratory euphemism for a bomb. However the solid pit was intrinsically less efficient than a hollow pit, and it required a modulated neutron initiator to start the chain reaction. Christy worked with Klaus Fuchs, Paul Stein and Hans Bethe to develop a suitable initiator design, which became known as an \"urchin\". The Gadget used in the Trinity nuclear test and the Fat Man used in the atomic bombing of Nagasaki used Christy pits.\n\nLater in life, Christy agreed to give a number of both oral history and video interviews in which he discussed his role in the Manhattan Project and latter interests.\n\nAfter the war ended, Christy accepted an assistant professorship at the University of Chicago, at a salary of $5,000 per annum, twice what he had been making before the war. He moved back to Chicago in February 1946, but suitable housing was hard to find in the immediate post-war period, and Christy and his family shared a mansion with Edward Teller and his family.\n\nBefore the war, Oppenheimer had spent part of each year teaching at California Institute of Technology (Caltech). Christy was one of Oppenheimer's Berkeley students who made the trip down to Pasadena, California, each year to continue studying with Oppenheimer. After the war, Oppenheimer decided that with his additional responsibilities he could no longer continue this arrangement. The head of the W. K. Kellogg Radiation Laboratory at Caltech, Charles Lauritsen therefore asked Oppenheimer for the name of a theoretical physicist that he would recommend as a replacement. Oppenheimer recommended Christy. Willy Fowler then approached Christy with an offer of a full-time position at Caltech at $5,400 per annum, and Christy accepted. He remained at Caltech for the rest of his academic career. The drawback to working at Caltech was that neither Lauritsen nor Fowler was a theoretical physicist, so a heavy workload fell on Christy. This was recognised by a pay raise to $10,000 per annum in 1954.\n\nChristy joined Oppenheimer, Lauritsen and Robert Bacher, who joined the faculty at Caltech in 1949, in Project Vista, a detailed 1951 study on how Western Europe could be defended against the Soviet Union. Christy was distraught at the outcome of the 1954 Oppenheimer security hearing. When he encountered Teller, who had testified against Oppenheimer, at Los Alamos in 1954, Christy publicly refused to shake Teller's hand. \"I viewed Oppenheimer as a god\", he later recalled, \"and I was sure that he was not a treasonable person.\" Asked about his relationship with Teller in 2006, Christy said:\n\nIn 1956, Christy was one of a number of scientists from Caltech who publicly called for a ban on atmospheric nuclear testing. The 1963 Partial Nuclear Test Ban Treaty that Christy advocated put an end to one of his most unusual projects. He worked with Freeman Dyson on Project Orion, the design of a spacecraft propelled by atomic bombs.\nDuring a sabbatical year at Princeton University in 1960, Christy began an investigation of Cepheid variables and the smaller RR Lyrae variables, classes of luminous variable stars. At the time it was a mystery as to why they varied. He used the knowledge of the hydrodynamics of implosion gained at Los Alamos during the war to explain this phenomenon. This earned him the Royal Astronomical Society's Eddington Medal for contributions to theoretical astrophysics in 1967.\n\nChristy was appointed Vice President and Provost of Caltech in 1970. Under Christy and President Harold Brown Caltech expanded its humanities and added economics to allow students to broaden their education. He had David Morrisroe appointed as Vice President for Financial Affairs, and they steered Caltech through the financially stringent 1970s. The first women were admitted as undergraduates in the 1970s.\n\nWhen Jenijoy La Belle, who had been hired in 1969 but refused tenure in 1974, filed suit with the Equal Employment Opportunity Commission, Christy pressed for the case to be settled and La Belle to be given tenure. The EEOC ruled against Caltech in 1977, adding that she had been paid less than male colleagues. La Belle received tenure in 1979.\n\nIn 1970 he became romantically involved with Inge-Juliana Sackman, a fellow physicist 26 years his junior. He divorced Dagmar in early 1971, and married Juliana on August 4, 1973. They had two daughters, Illia Juliana Lilly Christy, born in 1974, and Alexandra Roberta (Alexa) Christy, born in 1976.\n\nChristy briefly became acting President of Caltech in 1977 when Brown left to become Secretary of Defense. Christy returned to teaching after Marvin L. Goldberger became President in 1978. He became Institute Professor of Theoretical Physics in 1983, and Institute Professor Emeritus in 1986.\n\nChristy died on October 3, 2012. He was survived by his wife Juliana, their two daughters, Illia and Alexa, and his two sons, Peter and Ted. He was buried at Mountain View Cemetery in Altadena, California.\n\n\n"}
{"id": "12783520", "url": "https://en.wikipedia.org/wiki?curid=12783520", "title": "School of Ballooning", "text": "School of Ballooning\n\nThe School of Ballooning was a training and test centre for British Army experiments with balloons and airships. It was established at Chatham in Kent in 1888. The School moved to Stanhope Lines, Aldershot in 1890 when a balloon section and depot were formed as permanent units of the Royal Engineers establishment. The School was sometimes known as the Balloon Factory.\n\nIn 1862 two Royal Engineers officers, who had seen balloons being used in the American Civil War, drew the attention of the War Office to the potential use of balloons for observation. These officers demonstrated balloons to the army, but it was only in 1878 that the War Office directed Captain James Templer, an army reservist and experienced balloonist, to set up a small unit of Royal Engineers which became known as the School of Ballooning.\n\nInitially the School was based at the Royal Arsenal, Woolwich. In 1878 the school constructed and flew a hydrogen-filled balloon of capacity. By 1879 the unit had 5 balloons. In 1880 military balloon training and demonstration took place at Aldershot. After a tragic incident in 1881 Templer concentrated on development of balloons rather than making ascents himself.\n\nIn 1882 the School moved to the School of Military Engineering at Chatham where they discovered that Goldbeater's skin was superior balloon fabric than the material they had used previously – in particular it was easier to stow for transport. Templer also took out a patent for the use of unmanned balloons for “balloon photography” of the ground below.\n\nIn 1890 the School moved to Aldershot where a section of the Royal Engineers had been formed to use balloons operationally. The School of Ballooning was renamed the Balloon Factory in 1897. In 1899 the Factory increased production to supply balloons for use in the Boer War. The Factory began experiments with \"dirigible balloons\" (airships) in 1902.\n\n\nThe Aldershot site was found to be too enclosed so in 1904-1906 the Factory moved to a site at the edge of Farnborough Common. A high airship shed was built at the site.\n\nIn 1906 Colonel John Capper took up command of the School of Ballooning. During his time in command, Capper contributed to the development of Britain's military airships and, with Cody, piloted the first successful British airship flight, that of the \"Nulli Secundus\" over London during 1907.\n\nSamuel Cody experimented with man-lifting kites at the site.In 1906 he was appointed as Chief Instructor in Kiting.\n\nIn 1909-1911, part of the Factory was separated to form the Air Battalion of the Royal Engineers. In 1912 the Balloon Factory was renamed the Royal Aircraft Factory.\n\nThe following officers served as superintendent of the Balloon Factory:\nIn 1909, the Balloon Factory was separated from the Balloon School. Colonel Capper continued as commander of the Balloon School, and the civilian consultant engineer Mervyn O'Gorman was appointed superintendent of the Balloon Factory. Several months later Major Sir Alexander Bannerman took over the Balloon School from Colonel Capper.\n"}
{"id": "85012", "url": "https://en.wikipedia.org/wiki?curid=85012", "title": "Sewing machine", "text": "Sewing machine\n\nA sewing machine is a machine used to stitch fabric and other materials together with thread. Sewing machines were invented during the first Industrial Revolution to decrease the amount of manual sewing work performed in clothing companies. Since the invention of the first working sewing machine, generally considered to have been the work of Englishman Thomas Saint in 1790, the sewing machine has greatly improved the efficiency and productivity of the clothing industry.\n\nHome sewing machines are designed for one person to sew individual items while using a single stitch type. In a modern sewing machine the fabric easily glides in and out of the machine without the inconvenience of needles and thimbles and other such tools used in hand sewing, automating the process of stitching and saving time.\n\nIndustrial sewing machines, by contrast to domestic machines, are larger, faster, and more varied in their size, cost, appearance, and task.\n\nCharles Fredrick Wiesenthal, a German-born engineer working in England was awarded the first British patent for a mechanical device to aid the art of sewing, in 1755. His invention consisted of a double pointed needle with an eye at one end.\nIn 1790, the English inventor Thomas Saint invented the first sewing machine design, but he did not successfully advertise or market his invention. His machine was meant to be used on leather and canvas material. It is likely that Saint had a working model but there is no evidence of one; he was a skilled cabinet maker and his device included many practically functional features: an overhanging arm, a feed mechanism (adequate for short lengths of leather), a vertical needle bar, and a looper.\n\nHis sewing machine used the chain stitch method, in which the machine uses a single thread to make simple stitches in the fabric. A stitching awl would pierce the material and a forked point rod would carry the thread through the hole where it would be hooked underneath and moved to the next stitching place, where the cycle would be repeated, locking the stitch. Saint's machine was designed to aid the manufacture of various leather goods, including saddles and bridles, but it was also capable of working with canvas, and was used for sewing ship sails. Although his machine was very advanced for the era, the concept would need steady improvement over the coming decades before it could become a practical proposition. In 1874, a sewing machine manufacturer, William Newton Wilson, found Saint's drawings in the London Patent Office, made adjustments to the looper, and built a working machine, currently owned by the London Science Museum.\n\nIn 1804, a sewing machine was built by the Englishmen Thomas Stone and James Henderson, and a machine for embroidering was constructed by John Duncan in Scotland. An Austrian tailor, Josef Madersperger, began developing his first sewing machine in 1807. He presented his first working machine in 1814. Having received financial support from his government, the Austrian tailor worked on the development of his machine until 1839 but he couldn’t create anything worthwhile. Perhaps the tailor didn’t have the technical wit, perhaps technical knowledge, and perhaps – simple luck. But the fact remains that state money was wasted. However, in 1839 he built a machine imitating the weaving process using the chain stitch. \n\nThe first practical and widely used sewing machine was invented by Barthélemy Thimonnier, a French tailor, in 1829. His machine sewed straight seams using chain stitch like Saint's model, and in 1830, he signed a contract with Auguste Ferrand, a mining engineer, who made the requisite drawings and submitted a patent application. The patent for his machine was issued on 17 July 1830, and in the same year, he opened (with partners) the first machine-based clothing manufacturing company in the world to create army uniforms for the French Army. However, the factory was burned down, reportedly by workers fearful of losing their livelihood following the issuing of the patent.\n\nA model of the machine is exhibited at the London Science Museum. The machine is made of wood and uses a barbed needle which passes downward through the cloth to grab the thread and pull it up to form a loop to be locked by the next loop. The first American lockstitch sewing machine was invented by Walter Hunt in 1832. His machine used an eye-pointed needle (with the eye and the point on the same end) carrying the upper thread and a falling shuttle carrying the lower thread. The curved needle moved through the fabric horizontally, leaving the loop as it withdrew. The shuttle passed through the loop, interlocking the thread. The feed let the machine down, requiring the machine to be stopped frequently and reset up. Hunt eventually lost interest in his machine and sold individual machines without bothering to patent his invention, and only patenting it at a late date of 1854. In 1842, John Greenough patented the first sewing machine in the United States. The British partners Newton and Archibold introduced the eye-pointed needle and the use of two pressing surfaces to keep the pieces of fabric in position, in 1841.\n\nThe first machine to combine all the disparate elements of the previous half-century of innovation into the modern sewing machine was the device built by English inventor John Fisher in 1844, thus a little earlier than the very similar machines built by Isaac Merritt Singer in 1851, and the lesser known Elias Howe, in 1845. However, due to the botched filing of Fisher's patent at the Patent Office, he did not receive due recognition for the modern sewing machine in the legal disputations of priority with Singer, and it was Singer who won the benefits of the patent.\n\nElias Howe, born in Spencer, Massachusetts, created his sewing machine in 1845, using a similar method to Fisher's except that the fabric was held vertically. An important improvement on his machine was to have the needle running away from the point, starting from the eye. After a lengthy stay in England trying to attract interest in his machine, he returned to America to find various people infringing his patent, among them Isaac Merritt Singer. He eventually won a case for patent infringement in 1854 and was awarded the right to claim royalties from the manufacturers using ideas covered by his patent, including Singer.\n\nSinger had seen a rotary sewing machine being repaired in a Boston shop. As an engineer, he thought it was clumsy and decided to design a better one. The machine he devised used a falling shuttle instead of a rotary one; the needle was mounted vertically and included a presser foot to hold the cloth in place. It had a fixed arm to hold the needle and included a basic tension system. This machine combined elements of Thimonnier, Hunt and Howe's machines. Singer was granted an American patent in 1851, and it was suggested he patent the foot pedal or treadle, used to power some of his machines; unfortunately, the foot pedal had been in use too long for a patent to be issued. When Howe learned of Singer's machine he took him to court, where Howe won and Singer was forced to pay a lump sum for all machines already produced. Singer then took out a license under Howe's patent and paid him $1.15 per machine before entering into a joint partnership with a lawyer named Edward Clark. They created the first hire-purchase arrangement to allow people to buy their machines through payments over time.\n\nMeanwhile, Allen B. Wilson developed a shuttle that reciprocated in a short arc, which was an improvement over Singer and Howe's. However, John Bradshaw had patented a similar device and threatened to sue, so Wilson decided to try a new method. He went into partnership with Nathaniel Wheeler to produce a machine with a rotary hook instead of a shuttle. This was far quieter and smoother than other methods, with the result that the Wheeler & Wilson Company produced more machines in the 1850s and 1860s than any other manufacturer. Wilson also invented the four-motion feed mechanism that is still seen on every sewing machine today. This had a forward, down, back and up motion, which drew the cloth through in an even and smooth motion. Charles Miller patented the first machine to stitch buttonholes. Throughout the 1850s more and more companies were being formed, each trying to sue the others for patent infringement. This triggered a patent thicket known as the Sewing Machine War.\n\nIn 1856, the Sewing Machine Combination was formed, consisting of Singer, Howe, Wheeler, Wilson, Grover and Baker. These four companies pooled their patents, with the result that all other manufacturers had to obtain a license and pay $15 per machine. This lasted until 1877 when the last patent expired. \n\nJames Edward Allen Gibbs (1829–1902), a farmer from Raphine in Rockbridge County, Virginia patented the first chain stitch single-thread sewing machine on June 2, 1857. In partnership with James Willcox, Gibbs became a principal partner in Willcox & Gibbs Sewing Machine Company. Willcox & Gibbs commercial sewing machines are still used in the 21st century.\n\nWilliam Jones started making sewing machines in 1859 and in 1860 formed a partnership with Thomas Chadwick. As Chadwick & Jones, they manufactured sewing machines at Ashton-under-Lyne, England until 1863. Their machines used designs from Howe and Wilson produced under licence. Thomas Chadwick later joined Bradbury & Co. William Jones opened a factory in Guide Bridge, Manchester in 1869. In 1893 a Jones advertising sheet claimed that this factory was the \"Largest Factory in England Exclusively Making First Class Sewing Machines\". The firm was renamed as the Jones Sewing Machine Co. Ltd and was later acquired by Brother Industries of Japan, in 1968.\n\nClothing manufacturers were the first sewing machine customers, and used them to produce the first ready-to-wear clothing and shoes. In the 1860s consumers began purchasing them, and the machines—ranging in price from £6 to £15 in Britain depending on features—became very common in middle-class homes. Owners were much more likely to spend free time with their machines to make and mend clothing for their families than to visit friends, and women's magazines and household guides such as \"Mrs Beeton's\" offered dress patterns and instructions. A sewing machine could produce a man's shirt in about one hour, compared to 14 1/2 hours by hand.\n\nIn 1877 the world's first crochet machine was invented and patented by Joseph M. Merrow, then-president of what had started in the 1840s as a machine shop to develop specialized machinery for the knitting operations. This crochet machine was the first production overlock sewing machine. The Merrow Machine Company went on to become one of the largest American Manufacturers of overlock sewing machines and continues to be a global presence in the 21st century as the last American over-lock sewing machine manufacturer.\n\nIn 1885 Singer patented the Singer Vibrating Shuttle sewing machine, which used Allen B. Wilson's idea for a vibrating shuttle and was a better lockstitcher than the oscillating shuttles of the time. Millions of the machines, perhaps the world's first really practical sewing machine for domestic use, were produced until finally superseded by rotary shuttle machines in the 20th century. Sewing machines continued being made to roughly the same design, with more lavish decoration appearing until well into the 1900s.\n\nThe first electric machines were developed by Singer Sewing Co. and introduced in 1889. By the end of the First World War, Singer was offering hand, treadle and electric machines for sale. At first, the electric machines were standard machines with a motor strapped on the side, but as more homes gained power, they became more popular and the motor was gradually introduced into the casing.\n\nSewing machines can make a great variety of plain or patterned stitches. Ignoring strictly decorative aspects, over three dozen distinct stitch formations are formally recognized by the ISO 4915:1991 standard, involving one to seven separate threads to form the stitch.\n\nPlain stitches fall into four general categories: chainstitch, lockstitch, overlock, and coverstitch.\n\nChainstitch was used by early sewing machines and has two major drawbacks:\n\n\nA better stitch was found in the lockstitch. The chainstitch is still used today in clothing manufacture, though due to its major drawback it is generally paired with an overlock stitch along the same seam.\n\nLockstitch is the familiar stitch performed by most household sewing machines and most industrial \"single needle\" sewing machines from two threads, one passed through a needle and one coming from a bobbin or shuttle. Each thread stays on the same side of the material being sewn, interlacing with the other thread at each needle hole by means of a bobbin driver. As a result, a lockstitch can be formed anywhere on the material being sewn; it does not need to be near an edge.\n\nOverlock, also known as \"serging\" or \"serger stitch\", can be formed with one to four threads, one or two needles, and one or two loopers. Overlock sewing machines are usually equipped with knives that trim or create the edge immediately in front of the stitch formation. Household and industrial overlock machines are commonly used for garment seams in knit or stretchy fabrics, for garment seams where the fabric is light enough that the seam does not need to be pressed open, and for protecting edges against raveling. Machines using two to four threads are most common, and frequently one machine can be configured for several varieties of overlock stitch. Overlock machines with five or more threads usually make both a chainstitch with one needle and one looper, and an overlock stitch with the remaining needles and loopers. This combination is known as a \"safety stitch\". A similar machine used for stretch fabrics is called a \"mock safety\".\n\nCoverstitch is formed by two or more needles and one or two loopers. Like lockstitch and chainstitch, coverstitch can be formed anywhere on the material being sewn. One looper manipulates a thread below the material being sewn, forming a bottom cover stitch against the needle threads. An additional looper above the material can form a top cover stitch simultaneously. The needle threads form parallel rows, while the looper threads cross back and forth all the needle rows. Coverstitch is so-called because the grid of crossing needle and looper threads covers raw seam edges, much as the overlock stitch does. It is widely used in garment construction, particularly for attaching trims and flat seaming where the raw edges can be finished in the same operation as forming the seam.\n\nA zigzag stitch is a variant geometry of the lockstitch. It is a back-and-forth stitch used where a straight stitch will not suffice, such as in preventing raveling of a fabric, in stitching stretchable fabrics, and in temporarily joining two work pieces edge-to-edge.\n\nWhen creating a zigzag stitch, the back-and-forth motion of the sewing machine's needle is controlled by a cam. As the cam rotates, a fingerlike follower, connected to the needle bar, rides along the cam and tracks its indentations. As the follower moves in and out, the needle bar is moved from side to side. Very old sewing machines lack this hardware and so cannot natively produce a zigzag stitch, but there are often shank-driven attachments available which enable them to do so.\n\nBesides the basic motion of needles, loopers and bobbins, the material being sewn must move so that each cycle of needle motion involves a different part of the material. This motion is known as feed, and sewing machines have almost as many ways of feeding material as they do of forming stitches. For general categories, there are: drop feed, needle feed, walking foot, puller, and manual. Often, multiple types of feed are used on the same machine. Besides these general categories, there are also uncommon feed mechanisms used in specific applications like edge joining fur, making seams on caps, and blindstitching.\n\nThe drop feed mechanism is used by almost all household machines and involves a mechanism below the sewing surface of the machine. When the needle is withdrawn from the material being sewn, a set of \"feed dogs\" is pushed up through slots in the machine surface, then dragged horizontally past the needle. The dogs are serrated to grip the material, and a \"presser foot\" is used to keep the material in contact with the dogs. At the end of their horizontal motion, the dogs are lowered again and returned to their original position while the needle makes its next pass through the material. While the needle is in the material, there is no feed action. Almost all household machines and the majority of industrial machines use drop feed. \n\nDifferential feed is a variation of drop feed with two independent sets of dogs, one before and one after the needle. By changing their relative motions, these sets of dogs can be used to stretch or compress the material in the vicinity of the needle. This is extremely useful when sewing stretchy material, and overlock machines (heavily used for such materials) frequently have differential feed.\n\nA needle feed, used only in industrial machines, moves the material while the needle is in the material. In fact, the needle may be the primary feeding force. Some implementations of needle feed rock the axis of needle motion back and forth, while other implementations keep the axis vertical while moving it forward and back. In both cases, there is no feed action while the needle is out of the material. Needle feed is often used in conjunction with a modified drop feed, and is very common on industrial two needle machines. Household machines do not use needle feed as a general rule.\n\nA walking foot replaces the stationary presser foot with one that moves along with whatever other feed mechanisms the machine already has. As the walking foot moves, it shifts the workpiece along with it. It is most useful for sewing heavy materials where needle feed is mechanically inadequate, for spongy or cushioned materials where lifting the foot out of contact with the material helps in the feeding action, and for sewing many layers together where a drop feed will cause the lower layers to shift out of position with the upper layers.\n\nSome factory machines and a few household machines are set up with an auxiliary \"puller feed\", which grips the material being sewn (usually from behind the needles) and pulls it with a force and reliability usually not possible with other types of feed. Puller feeds are seldom built directly into the basic sewing machine. Their action must be synchronized with the needle and feed action built into the machine to avoid damaging the machine. Pullers are also limited to straight seams, or very nearly so. Despite their additional cost and limitations, pulling feeds are very useful when making large heavy items like tents and vehicle covers.\n\nA manual feed is used primarily in freehand embroidery, quilting, and shoe repair. With manual feed, the stitch length and direction is controlled entirely by the motion of the material being sewn. Frequently some form of hoop or stabilizing material is used with fabric to keep the material under proper tension and aid in moving it around. Most household machines can be set for manual feed by disengaging the drop feed dogs. Most industrial machines can not be used for manual feed without actually removing the feed dogs.\n\nSewing machines use special needles tailored to their needs and to the character of the material being sewn.\n\nIndustrial sewing machines are larger, faster, and more varied in their size, cost, appearance, and task. Industrial machines, unlike domestic machines, perform a single dedicated task and are capable of long hours of usage and as such have larger moving parts and comparatively much larger motors. Industrial machines are also more generic; a motor for almost any type of machine can work on any brand. Sewing feet and bobbins between brands are interchangeable. However, with domestic machines the motor, and to a lesser extent bobbins and sewing feet, are brand specific.\n\nThe motors on industrial machines, as with most of their components, lights, etc., are separate, usually mounted to the underside of the table. Domestic machines have their OEM motors mounted inside the machine. There are two different types of motor available for industrial machines: a servo motor (which uses less electricity and is silent when not in use), and the more traditional clutch motor (which is always spinning; even when not in use).\n\nBefore sewing machines were invented women spent much of their time maintaining their family's clothing. Middle-class housewives, even with the aid of a hired seamstress, would devote several days of each month to this task. It took an experienced seamstress at least 14 hours to make a dress shirt for a man; a woman's dress took 10 hours; and a pair of summer pants took nearly three hours. Most individuals would have only two sets of clothing: a work outfit and a Sunday outfit.\n\nSewing machines reduced the time for making a dress shirt to an hour and 15 minutes; the time to make a dress to an hour; and the time for a pair of summer pants to 38 minutes. This reduced labor resulted in women having a diminished role in household management, and allowed more hours for their own leisure as well as the ability to seek more employment.\nIndustrial use of sewing machines further reduced the burden placed upon housewives, moving clothing production from housewives and seamstresses to large-scale factories. The movement to large-scale factories also resulted in a decrease in the amount of time clothing production took, which caused the prices for clothing to drop significantly. This is because manufacturers were able to decrease the number of workers needed to produce the same amount of clothing, resulting in reduced costs. Increased supply also lowered the cost.\n\nThe initial effects of sewing machines on workers were both positive and negative, however in the long run the negative effects decreased. Many of the women who had previously been busy at home could now seek employment in factories, increasing the income for their family. This allowed for families to be able to afford more sets of clothing and items than they previously could. For seamstresses, home sewing machines allowed them to produce clothing for the average person during periods when demand for fitted clothes was low, effectively increasing their earnings. When industrial sewing machines initially became popular many seamstresses working in factories, as well as those working at home, lost their jobs as it meant that fewer workers could produce the same output. In the long run these now unemployed workers along with thousands of men and children would eventually be able to gain employment in jobs created as the clothing industry grew.\n\nThe sewing machine's effects on the clothing industry resulted in major changes for other industries as well. Cotton production needed to increase in order to match the demand of the new clothing factories. As a result, cotton became planted in new areas where it hadn't previously been farmed. Other industries involved in the process benefited as well such as metal companies who provided for parts of the machines and shippers to move the increased amounts of goods. In addition to being important for clothing production, sewing machines also became important in the manufacturing of furniture with upholstery, curtains and towels, toys, books, and many other products.\n\nNew home 1917 sewing machine in cabinet\n\n"}
{"id": "54133496", "url": "https://en.wikipedia.org/wiki?curid=54133496", "title": "Stash (company)", "text": "Stash (company)\n\nStash Financial, Inc., or simply Stash, is an American financial technology and financial services company based in New York, NY. Founded in February 2015 by Brandon Krieg, Ed Robinson, and David Ronick, the company launched its online investing platform in October 2015. As of July 2018, Stash had approximately 2.4 million users.\n"}
{"id": "21511323", "url": "https://en.wikipedia.org/wiki?curid=21511323", "title": "Sugar nips", "text": "Sugar nips\n\nSugar nips are a large pair of pincers with sharp blades, designed to cut sugar from a block. Before the introduction of granulated and cube sugars in the second half of the 19th century, the domestic consumer purchased sugar in the form of a sugarloaf, or at least a part of one, and pieces were cut from it by hand using sugar nips. Greater leverage and improved safety was provided by heavier sugar nips set in a wooden base for counter- and table-top use.\n\nThere was also an all-in-one version; a box that could serve as container for the sugarloaf with built-in pliers and collector drawer for fine-grained residues from the sugar cutting.\n\n"}
{"id": "194808", "url": "https://en.wikipedia.org/wiki?curid=194808", "title": "Superminicomputer", "text": "Superminicomputer\n\nA superminicomputer, or supermini, was “a minicomputer with high performance compared to ordinary minicomputers.” The term was an invention used from the mid-1970s mainly to distinguish the emerging 32-bit minis from the classical 16-bit minicomputers. The term is now largely obsolete but still remains of interest for students/researchers of computer history.\n\n"}
{"id": "20188144", "url": "https://en.wikipedia.org/wiki?curid=20188144", "title": "Sustainable Agriculture Innovation Network", "text": "Sustainable Agriculture Innovation Network\n\nThe China-UK Sustainable Agriculture Innovation Network (SAIN) is a Sustainable agriculture Network launched in 2008 to provide a framework for collaboration on agriculture and climate change between the UK and China.\n\nThe agreement supports the already existing China-UK Sustainable Development Dialogue (SDD) signed by the Chinese Ministry of Agriculture and the UK Department of Environment, Food and Rural Affairs (DEFRA). Agreed upon by the Chinese Ministry of Agriculture (MOA) and the Department of Environment, Food and Rural Affairs (DEFRA), the development of SAIN was included in the SDD work program on Sustainable Agriculture and Fisheries. After being originally proposed at the UK-China Partners in Science Conference in North West China, a business plan was created after consultation with Chinese stake-holders, bilateral agencies, and international organizations. in December 2008, the Ministry of Agriculture (MOA) and Department of Environment, food and Rural Affairs accepted and adopted the new policy.\n\nThe UK-China Sustainable Agriculture Innovation Network has four primary goals:\n1. Support UK-China SDD by policy approaches, institutional mechanisms, and moving policy and science to the ground level.\n2. Encourage and grow research on environmentally sustainable agriculture and its relevance to local, national, and the global economy.\n3. Gather important actors, such as farmers and policy makers, and educate them on environmentally sustainable agriculture issues. \n4. Increase global sustainability with south-south learning.\n\nThe organization of SAIN consists of a Governing Board, two Secretariat Offices, and Working Groups. The North West Agriculture Forestry University in China and East Anglia University in England are the locations of the two Secretariat Offices.\n\n\n"}
{"id": "7147380", "url": "https://en.wikipedia.org/wiki?curid=7147380", "title": "Síragon", "text": "Síragon\n\nSíragon, C.A. is a Venezuelan manufacturer and assembler of computer hardware and other electronic products such as digital cameras, tablet computers and LCD televisions. Siragon also designs and manufactures its own RAM and flash memory and printed circuit boards. The company was created in an alliance between Venezuelan and Japanese investors. Its plant is located in the North Industrial Zone of Valencia, Carabobo.\n\nOn November 2009, Síragon started to distribute its product line in Argentina, Allied with the Argentinian computer wholesale vendor Greentech. Síragon manufactures its own designs and also builds under license, all-in-one computers from Brazilian Itautec.\n\nSiragon products are all manufactured in Venezuela. At the 2012 international consumer electronics show Siragon formally announced its intent to enter the US market by the end of 2012. Siragon is engaged in a design partnership with BMW for which it both manufactures electronics for and collaborates on electronic designs with.\n\nSiragon currently holds the third largest share of the electronics market in Venezuela. The company intends to surpass Lenovo and move up to the second position by 2012.\n\n\n"}
{"id": "16816599", "url": "https://en.wikipedia.org/wiki?curid=16816599", "title": "Top Industrial Managers for Europe", "text": "Top Industrial Managers for Europe\n\nTop Industrial Managers for Europe (T.I.M.E.) is a network of fifty-three engineering schools and faculties and technical universities. The oldest European network of engineering schools in its field, the T.I.M.E. Association promotes graduate student exchanges and double degrees throughout Europe and the world to enable students to achieve a broader, high-level scientific engineering education with in-depth intercultural experience.\n\nSeveral hundreds of graduate students per year participate in T.I.M.E. mobility activities and pursue double degrees (at Master and Doctorate levels). Double degrees require the participating student to spend more than three semesters in another member university and at least the same in her/his home university, in order to be awarded two full degrees.\n\nThe T.I.M.E. network includes primarily graduate engineering schools and technical universities from Europe, but increasing numbers of members are now from other continents.\n\nIn 1989, the T.I.M.E. network was created at the École Centrale Paris, a leading French engineering school. Its main purpose was to coordinate European double degree and exchange programmes in engineering at the Master’s level. The T.I.M.E. network had 16 founding members, each a leading engineering institution in its respective country.\n\nThe T.I.M.E. Association was formally incorporated as a not-for-profit body under French law in 1997, with 29 members. Current membership (2015-2016) is 53 institutions from 20 countries. To date, the T.I.M.E network has produced more than 5,000 graduates in total.\n\nTIME members include the following engineering schools and faculties and technical universities:\n\n"}
{"id": "23573013", "url": "https://en.wikipedia.org/wiki?curid=23573013", "title": "Urban stream", "text": "Urban stream\n\nAn urban stream is a formerly natural waterway that flows through a heavily populated area. Urban streams are often polluted by urban runoff and combined sewer outflows. Water scarcity makes flow management in the rehabilitation of urban streams problematic.\n\nGovernments may alter the flow or course of an urban stream to prevent localized flooding by river engineering: lining stream beds with concrete or other hardscape materials, diverting the stream into culverts and storm sewers, or other means. Some urban streams, such as the subterranean rivers of London, run completely underground. These modifications have often reduced habitat for fish and other species, caused downstream flooding due to alterations of flood plains, and worsened water quality.\nSome communities have begun stream restoration projects in an attempt to correct the problems caused by alteration, using techniques such as daylighting and fixing stream bank erosion caused by heavy stormwater runoff. Streamflow augmentation to restore habitat and aesthetics is also an option, and recycled water can be used for this purpose.\n\n\n"}
{"id": "53878496", "url": "https://en.wikipedia.org/wiki?curid=53878496", "title": "Valneva SE", "text": "Valneva SE\n\nValneva SE is a fully integrated, commercial stage biotech company focused on developing innovative life-saving vaccines. Valneva was founded in 2013 through the merger of Intercell and Vivalis SA.\n\nIt has been listed on the Vienna Stock Exchange and Euronext since May 28, 2013.\n\nMarketed vaccines generated by Valneva include Ixiaro, a vaccine against Japanese encephalitis (approved in Europe, America and Australia) and Dukoral, a vaccine against cholera (approved in Europe, America and Australia)\n\nSome of its candidates have failed in clinical trials: VLA43, a therapeutic vaccine against Pseudomonas Aeruginosa, V710, a therapeutic vaccine against Staphylococcus aureus (in collaboration with Merck), and IC41, therapeutic vaccine against hepatitis C\n\n"}
{"id": "26915887", "url": "https://en.wikipedia.org/wiki?curid=26915887", "title": "Voigt-Thomson law", "text": "Voigt-Thomson law\n\nVoigt-Thomson law describes anisotropic magnetoresistance effect in a thin film strip as a relationship between the electric resistivity and the direction of electric current:\n\nwhere:\n\nThe equation can also be expressed as:\n\nwhere:\n"}
{"id": "640672", "url": "https://en.wikipedia.org/wiki?curid=640672", "title": "XD-Picture Card", "text": "XD-Picture Card\n\nxD-Picture Card is a flash memory card format, used in digital cameras made by Olympus and Fujifilm. The xD in the xD-Picture Card stands for eXtreme Digital.\n\nxD cards have been manufactured with capacities of 16 MB up to 2 GB. They are not used in any cameras currently in production.\n\nThe cards were developed by Olympus and Fujifilm, and introduced into the market in July 2002. Toshiba Corporation and Samsung Electronics manufactured the cards for Olympus and Fujifilm. xD cards were sold under other brands, including Kodak, SanDisk, PNY, and Lexar, but were not branded with the respective companies' logos, except for Kodak. Previously, xD competed primarily with Secure Digital (SD) cards, CompactFlash (CF), and Sony's Memory Stick. Because of its higher cost and limited usage in products other than digital cameras, xD lost ground to SD, which is broadly used by cellular phones, personal computers, digital audio players and many other digital cameras.\n\nOlympus began to move away from the xD format with the release of the E-P1 camera, which supported only Secure Digital memory cards. As of Spring 2010, all new Olympus cameras announced at the 2010 Consumer Electronics Show and Photo Marketing Association International Trade Show can use SD cards. This changeover to the SD card format has never been officially announced by Olympus Corporation. The higher-end DSLR cameras such as the E-3 and E-5 among others continue to use Compact Flash cards as well.\n\nThe xD format has been discontinued. New cards are still manufactured, but cameras supporting xD memory cards exclusively are no longer manufactured.\n\n\n\nThe original xD cards were available in 16 MiB to 512 MiB capacities. The Type M card, released in February 2005, uses multi-level cell (MLC) architecture to achieve a theoretical storage capacity of up to 8 GiB. , Type M cards are available in sizes from 256 MiB to 2 GiB. However, the Type M suffers from slower read/write speeds than the original cards.\n\nThe Type H card, first released in November 2005, offers higher data rates than Type M cards (theoretically as much as 3 times faster). As of 2008, Type H cards were only available in 256 MiB, 512 MiB, 1 GiB, and 2 GiB capacities. Both Fuji and Olympus discontinued the production of Type H cards in 2008, citing high production costs.\n\nThe Type M+ card, first released in April 2008, offers data rates 1.5 times that of Type M cards. As of 2008, cards are available only in 1 and 2 GiB capacities.\n\nOlympus says that its xD cards support special \"picture effects\" when used in some Olympus cameras, though these software features are not intrinsically hardware-dependent. Type H and M+ cards however, are required in newer models to capture video at high rate (640×480 @ 30fps). Due to changes in the cards' storage architecture, newer Type M and H cards may have compatibility issues with some older cameras (especially video recording). Compatibility lists are available for Olympus: Olympus America's and Fujifilm's. Newer cards are incompatible with some card readers.\n\nPictures may be transferred from a digital camera's xD card to a personal computer by plugging the camera into the PC via a USB or IEEE 1394 cable, or by removing the card from the camera and inserting it into a card reader. In both cases, the computer sees the card as a mass storage device containing image files, although software or firmware can alter this representation. Card readers may be integrated into the PC or attached via cable. Adapters are available to allow an xD picture card to be plugged into other readers (and in some cases cameras), including PC card, parallel port, CompactFlash and SmartMedia.\n\nDetailed specifications are tightly controlled by Olympus and Fujifilm, which charge licensing fees and royalties and require non-disclosure agreements in exchange for the technical information required to produce xD-compatible devices.\n\nThe memory format used is not well documented. It is difficult to study it directly, since most camera devices and most USB card readers do not provide direct access to the flash memory. Since the cards are controller-less, cameras and card readers must perform wear leveling and error detection. They normally hide the portion of the memory which stores this information (among other things) from higher level access.\n\nHowever, a few models of xD card readers based on the Alauda chip \"do\" allow direct access (bypassing the above mechanisms) to an xD card's flash memory. These readers have been reverse-engineered and Linux drivers have been produced by the Alauda Project, which has documented the on-chip data structures of the xD card. According to this information, xD card headers are similar to those used by SmartMedia, and include chip manufacturer information.\n\nAt the raw hardware level, an xD card is simply an ordinary NAND flash integrated circuit in an unusual package. Comparing the pinout of an xD card to the pinout of a NAND flash chip in a standard TSOP package, one finds a nearly one-to-one correspondence between the active pins of the two devices. xD cards share this characteristic with the older SmartMedia cards, which are also basically raw NAND flash chips, albeit in a larger package.\n\nxD and SmartMedia cards can be used by hobbyists as a convenient source of NAND flash memory chips for custom projects. For example, the Mattel Juice Box PMP can be booted into Linux using a modified cartridge containing an xD card with a boot image written on it. Additionally, SmartMedia and xD card readers can be used to read the data from NAND flash chips in electronic devices, by soldering leads between the chip and the card reader.\n\nSome Olympus cameras offer camera-based panoramic processing. In those cameras that support both xD and CompactFlash cards, panoramic processing only works with images stored on the xD card, if installed. Newer Olympus cameras have neither xD cards nor this restriction.\n\nUnsubtantiated reports claim that some cameras such as the E-450 only support panoramic processing when using Olympus branded xD cards. The model numbers have not been documented. In this case, there appears to be a workaround: it appears that the card manufacturer information is simply stored in the flash memory, in the Card Information Structure (described in the Alauda Project's documentation, see above). Thus, it is possible to alter another brand of xD card to present itself as Olympus xD card by accessing the raw flash memory. This can be done by using a hacked device driver for a USB card reader.\n\n\n"}
