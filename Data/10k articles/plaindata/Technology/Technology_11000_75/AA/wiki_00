{"id": "38381509", "url": "https://en.wikipedia.org/wiki?curid=38381509", "title": "Adams Filmi", "text": "Adams Filmi\n\nAdams Filmi Oy (previously Adamsin Filmitoimisto) was a Finnish film production company. Founded in 1912 by Abel Adams (1879–1938), the company was later merged with Fenno-Filmi which eventually became Fennada-Filmi. The Finnish Broadcasting Company bought Fennada-Filmi in 1982. When Adams Filmi Oy, O.Y. Kinosto and Ky Kino Savoy merged in 1986, a new film company Finnkino was born.\n\nAfter Abel Adams suddenly died in 1938, his wife became the head of the company. Their daughter Felicia Adams took over the charge in 1958. Valuable film material was lost in a fire in 1959, including three early films by Teuvo Tulio.\n\n"}
{"id": "1964597", "url": "https://en.wikipedia.org/wiki?curid=1964597", "title": "American Association for Women Radiologists", "text": "American Association for Women Radiologists\n\nThe American Association for Women Radiologists (or AAWR) is a professional association founded in 1981 as a resource for \"professional socialization\" for women in a male-dominated field of radiology.\n\nAAWR’s role model is Marie Curie, extraordinary scientist, mother and teacher.\n\nThe main goals of the association were to provide a forum for issues unique to women in radiology, radiation oncology and related professions, to sponsor programs that promote opportunities for women, and to facilitate networking among women radiologists.\n\n"}
{"id": "1845245", "url": "https://en.wikipedia.org/wiki?curid=1845245", "title": "Bandwidth (company)", "text": "Bandwidth (company)\n\nBandwidth is a Communications Platform as a Service (CPaaS) company.  They sell software application programming interfaces (or APIs) for voice and messaging, using their own IP voice network.\n\nFormed in 1999, Bandwidth by co-founder David Morken and . Bandwidth moved to North Carolina in at the Centennial Campus of North Carolina State University in Raleigh, North Carolina. As of December 31, 2017, Bandwidth maintains a workforce of 378 employees. Bandwidth reported Q2 2018 revenue of $48.3 million. \n\nIn November 2017, the company had an initial public offering on the NASDAQ.\n\nBandwidth offers communications APIs that allow companies to embed voice calling and messaging capability into their applications; enhanced 911 (emergency) calling; and access to virtual phone numbers.\n\nIn July 2011, Bandwidth Inc. started working with Alabama's 911 (emergency) centers to allow people to send text messages, pictures and videos to 911.\n\nBandwidth Inc. manages the assignment of telephone numbers for Google Voice— a carrier search on a Google Voice number, for example, will indicate that the carrier's identity is Bandwidth Inc.\n\n"}
{"id": "1954269", "url": "https://en.wikipedia.org/wiki?curid=1954269", "title": "Candy Jones", "text": "Candy Jones\n\nCandy Jones, originally known as Jessica Arline Wilcox (December 31, 1925 – January 18, 1990), was an American fashion model, writer and radio talk show hostess.\n\nBorn in Wilkes-Barre, Pennsylvania, she was raised and educated in Atlantic City, New Jersey.\n\nIn the 1940s and 1950s, she was a leading model and pin-up girl, and afterward, established a modeling school and wrote several books on modeling and fashion. In 1972, Jones married the popular radio show host Long John Nebel (he was her second husband), and became the co-host of his all-night talk-show on WMCA in New York City. The show dealt with paranormal, UFO, and conspiracy theory claims.\n\nJones controversially claimed to be a victim of Project MKULTRA, the CIA mind-control program, in the 1960s.\n\nCandy Jones was born to a well-off family. Jones reported vivid, conscious memories of physical abuse by her parents and vague memories of sexual abuse in her youth. She was shuttled among relatives, and her mother, Jones insisted, often kept her cloistered or locked in dark rooms. As a child, Jones said she had an imaginary friend named Arlene to help through her lonely episodes.\n\nJones grew into an attractive, statuesque young woman, about . Changing her name, she pursued a career as a fashion model. She was a quick success, becoming a runner up for Miss New Jersey in the Miss America contest. Jones was able to parlay this into a hostess job at the main Miss America contest, and a successful career. She was one of the leading pin-up girls of the World War II era: In one month in 1943, she appeared on 11 magazine covers.\n\nDuring a lengthy United Service Organizations (USO) tour in the Philippines, Jones fell ill in 1945, and was treated by a doctor who was still alive when Candy publicised her mind-control claims; Donald Bain gave this doctor the alias \"Gilbert Jensen\". According to researcher Martin Cannon, who interviewed Jones before she died in 1990, the \"Marshall Burger\" alias in Bain's book who worked with Jensen on the Jones case was actually Dr. William S. Kroger, a psychologist at one time associated with UCLA.\n\nIn 1946, Jones married fashion czar Harry Conover, one of the first model agents. They had three sons, and Jones says she didn't realize Conover was bisexual until some years into their marriage. She recognized some people might consider this naive, but Jones insisted her abusive childhood had made her wary of intimate relationships, and though she had many suitors, she was sexually inexperienced when she married. She reported that Conover initiated sexual activities with her very few times, and only when he was intoxicated.\n\nWithout notice, Conover disappeared in late 1958. Jones notified police, and Conover's absence made the news. When he returned after a long binge, Jones sued for divorce in 1959. After the divorce, she was left with $36, and considerable debts.\n\nJones opened a modeling school, and she began appearing regularly on NBC's weekend radio news program \"Monitor\".\n\nOn December 31, 1972, Jones married radio host Long John Nebel after a one-month courtship; they briefly met decades earlier when Nebel was a photographer. Jones was soon the regular co-host of Nebel's popular overnight radio talk show, which usually discussed various paranormal topics.\n\nShortly after their marriage, Nebel said, he noted that Jones exhibited violent mood swings, and at times, seemed to display a different personality. Nebel called this \"The Voice ... a look, a few moments of bitchiness.\" 'The Voice' usually vanished rather quickly, but the change was so drastic from Jones's usually pleasant demeanor that Nebel was startled and distressed.\n\nColin Bennett writes, \nA few weeks after their marriage, [Jones] did tell Nebel that she had worked for the FBI for some time, adding mysteriously that she might have to go out of town on occasion without giving a reason. This left Nebel wondering whether there was a connection between the 'other' personality within Candy and the strange trips she said she made for the FBI.\n\nNebel began hypnotising Jones, and uncovered an alternate personality named \"Arlene\". Under hypnosis, Jones related a lengthy, elaborate account of her being trained in a CIA mind-control program, often at west coast colleges and universities. Jones and Nebel eventually recorded hundreds of hours of these hypnotic sessions.\n\nJones said she had some conscious memories of her involvement in the mind-control program: it began in 1960, she said, when an old USO acquaintance (an unnamed retired army general) asked to use Jones' modeling school as a mailing address to receive some letters and packages. Jones agreed, she said, out of a sense of patriotism.\n\nEventually, said Jones, she was asked to deliver a letter to Oakland, California on a business trip she had scheduled. Again, Jones reported she agreed, and was surprised to discover the letter was delivered to the same Dr. Jensen who had treated her in the Philippines nearly two decades earlier. Jones said that Jensen and his associate, Dr. \"Marshall Burger\" (another alias) offered hefty amounts of cash if she was willing to engage in further plans; in their earlier meetings, Jensen had noted that Jones was an ideal subject for hypnosis. Jones agreed, she said, because her modeling school was faltering, and she wanted to keep her sons in their costly private schools.\n\nDuring hypnosis sessions, an alternate personality called \"Arlene\" was reportedly groomed by Jensen, so that Jones would have no memory of Arlene's activities. Jones allegedly made trips to locations as far away as Taiwan. While hypnotized, Jones claimed that she was subjected to painful torture in order to test the effectiveness of the alternate personality. Donald Bain writes, \"[Jones] would be a messenger for the agency in conjunction with her normal business trips.\"\n\nAgain with the USO, Jones visited South Vietnam in 1970; she later suspected her visit had some connection to a disastrous attempt to free American prisoners of war from North Vietnam.\n\nJones's and Nebel's claims were first made public in 1976 (in Donald Bain's \"The Control of Candy Jones\", published by Playboy Press). Nebel apparently accepted his wife's claims, and openly discussed killing Dr. Jensen in revenge. However, Nebel was a prankster and a hoaxer of long standing and as he was not above hoaxing his radio audience, some of whom doubted the recovered memories of Candy Jones's past were genuine. Later skeptics would argue that an alleged false memory syndrome was a more plausible explanation.\n\nSeveral years later, Jones' story gained more notice after the public disclosure of MK-ULTRA in 1977.\n\nBain reported that associates in Jones' modeling schools asserted that Jones indeed had some puzzling absences – supposed business trips where little or no business seemed to be conducted. Bain also writes that another piece of evidence came forth when \"Candy inadvertently held onto a passport of 'Arlene Grant': Candy in a dark wig and dark makeup\". Jones says she had no memory of dressing in such an outfit or of posing for a passport in a different name.\n\nBain also claimed that a tape-recorded message on an answering machine was left on Jones and Nebel's home telephone number on July 3, 1973:\n\nThis is Japan Airlines calling on oh-three July at 4.10 p.m. ... Please have Miss Grant call 759-9100 ... she is holding a reservation on Japan Airlines Flight 5 for the sixth of July, Kennedy to Tokyo, with an option on to Taipei. This is per Cynthia that we are calling. \n\nWhen Jones telephoned the number and asked for Cynthia, she was told that no one of that name worked at the reservations desk.\n\nAdditionally, Brian Haughton notes that \n\nThere was also a letter [Jones] wrote to her attorney, William Williams, to cover herself in case she died or disappeared suddenly or under unusual circumstances; she told him she was not at liberty to reveal exactly what she was involved in. Bain wrote to Williams who corroborated this fact.\n\nBain also notes that in 1971, an article by hypnosis expert George Estabrooks was published in \"Science Digest\", wherein Estabrooks openly discussed the successful creation of amnesiac couriers of the type Jones claimed to have been.\n\nDr. Herbert Spiegel, a nationally recognized hypnosis expert, wrote the foreword to \"The Control of Candy Jones\".\n\nCandy Jones is the subject of the Exit Clov song \"MK ULTRA.\"\n\nThe story of her mind-control claims was featured in an episode of \"\" in a segment entitled \"Sexy Secret Agent\".\n\nJones died of cancer on January 18, 1990 at Lenox Hill Hospital. She was 64 years old and had been living in Manhattan.\n\n\n"}
{"id": "13150274", "url": "https://en.wikipedia.org/wiki?curid=13150274", "title": "Challenger LTD", "text": "Challenger LTD\n\nChallenger Ltd is a provider of contract oil and gas land drilling and workover services.\n\nChallenger is based in the Middle East and North Africa (MENA) region, and is currently led by Chairman Hassan Tatanaki.\nThe company was founded in 1991 and operated first in Africa later expanding into the Middle East.\n\nChallenger Limited is a provider of contract oil and gas land well drilling and work over services. The company owns and operates 25 drilling rigs in Libya providing drilling and work-over services for oil, gas, and water wells, with offices in Egypt, Saudi Arabia and the United Arab Emirates. Workover refers to any kind of oil well intervention involving invasive techniques, such as wireline, coiled tubing or snubbing. More specifically though, it will refer to the expensive process of pulling and replacing a Completion (oil well).\n\nIt has an extensive client base, including several national oil companies as well as international corporations such as Agip/Eni, Total, Marathon Oil, Veba and Verenex Energy. Challenger works as a regular subcontractor to the state-owned National Oil Corporation of Libya. Challenger is one of the oldest drilling companies in Africa, and particularly in Libya. Since inception, the company has grown every year producing impressive financial results. Challenger is a private company limited by shares registered in the General Registry of the Isle of Man, G.B. It operates as a commercial entity through a network of branches in Liechtenstein, the Middle East and Africa. Financial Consultants and audit firms include KPMG and PriceWaterhouseCoopers.\n\n\nIn 2006, Venture Capital Bank (VC Bank), a Bahrain-based investment bank, along with its partner, the U.S. private equity firm Global Emerging Markets (GEM), acquired a significant stake in Challenger. The acquisition cost roughly $50 million and was co-financed by VC Bank and GEM. This transaction demonstrated that the MENA region contains several attractive, yet obscured, investment opportunities represented in privately held companies such as Challenger.\n\nThe investment is beneficial to both parties, allowing Challenger to achieve its growth plan and helping VC Bank to achieve its objectives of supporting companies in the MENA region. Challenger Chairman Hassan Tatanaki said that \"amongst alternative financing routes available, Challenger's management decided to partner with VC Bank and GEM to fuel and expedite its capacity expansion plans and its geographical coverage.\" Tatanaki added that \"in the oil sector, with Libya in particular, oil production in the 1970s was more than 3 million bpd compared to today's levels of 1.6 million bpd. With proven oil reserves of of mainly sweet light crude oil in January 2007, an aggressive plan has been introduced by the Libyan government to enhance production capabilities to 3 million bpd by 2010. Since the lifting of sanctions, exploration concessions have been granted to international exploration companies, which hope to drill 50 exploration wells per year.\"\n\nVC Bank CEO Abdullatif Mohammed Janahi added, “our investment in Challenger will help the company snatch the exceptional growth potential in Libya and enter international markets. Soaring oil prices have brought about a supply/demand imbalance of oil rigs worldwide, leading oil and gas companies to spend more on exploration and production. This has, in turn, increased demand for oil drilling contractors such as Challenger.”\n\n\n"}
{"id": "18756813", "url": "https://en.wikipedia.org/wiki?curid=18756813", "title": "Cher Wang", "text": "Cher Wang\n\nCher Wang (; born 15 September 1958) is a Taiwanese entrepreneur and philanthropist born in Taipei, Taiwan. As co-founder and chairperson (since 2007) of HTC Corporation (which manufactured one out of every six smartphones sold in the United States) and integrated chipset maker VIA Technologies. She is considered one of the most powerful and successful women in technology. Wang's father was Wang Yung-ching, founder of the plastics and petrochemicals conglomerate Formosa Plastics Group and one of the wealthiest individuals in Taiwan before his death in 2008. As of 2014, she is listed as the 54th most powerful woman in the world by \"Forbes\".\n\nWang studied abroad at The College Preparatory School in Oakland, California, and went on to receive her bachelor's degree in economics from the University of California, Berkeley in 1981.\n\nShe joined First International Computer (FIC) in 1982. Wang and others founded VIA in 1987 and HTC in 1997. In May 2011, Forbes ranked her with husband Wen Chi Chen as the wealthiest person in Taiwan, with a net worth of US$8.8 billion. In August 2012, Wang was named #56 on Forbes' list of The World's 100 Most Powerful Women. As of 2014, she is listed as the 54th most powerful woman in the world by \"Forbes\".\n\nIn Oct. 2014, Cher Wang refused to accept the Final Award of the \"HKIAC / A11022 arbitration\" and appealed to the Hong Kong High Court (Case No.:HCCT40 / 2014) before Judge Mimmie Chan. Wang asserted that the Award was contrary to public policy. VIA product VT3421, an anti-hack chip (also named asTF376) was suspected in assisting the Chinese government of surveilling mobile devices of anti-communist and human rights activists. VIA executive Li Shaolun (Steven S. Lee) admitted in the proceedings that VIA chips did have \"back door\". The Hong Kong HKIAC sentenced VIA with compensation. In a hearing before the Justice Mimmie Chan, in the High Court of Hong Kong, she said she believed the Award was in violation of Hong Kong's public order and morals. In June 2015 in she remised the case back to Arbitrator Anthony Neoh. The tribunal upheld the conviction in October 2015, and VIA lost the case for millions of dollars.\nThe backdoor of hacking prevention chip VT3421/TF376 cause big issues in Taiwan. 11 Legislative Senators made suggestion to suspend the government procurement of hTC related communication products until the VIA Electronics' VT3421/TF376 hacking control chip backdoor issue should be thoroughly investigated by National Security Bureau and National Communication Committee.\n\nIn March 2015, Cher Wang took over the CEO role from Peter Chou and returned to the day-to-day operations of HTC.\n\nIn September 2017, HTC and Google announced a US$1.1 billion cooperation agreement, which involved certain HTC employees would join Google, and Google would receive HTC IP through a non-exclusive licensing agreement.\n\nWang’s Charity Foundations are holding eight investment companies’ stocks with market value of over US$200 millions. However, only US$ twenty-seven thousand has been donated to charity(0.000135%). Wang suited the reporter with anger and failed the case on Feb. 2018. \nIn 2011 Wang donated US$28.1 million to help found Guizhou Forerunner College, a charitable college in southwest China set up by VIA Technologies' non-profit Faith-Hope-Love Foundation. The not-for-profit college aims to provide three years of free or low-cost education to students from low-income families. Wang has stated that if the college proves successful she may well set up additional similar institutions in other parts of the country.\n\nWang has also made significant donations to the University of California, Berkeley, including funding to support and enhance the prestigious American Physical Society's Oliver E. Buckley Condensed Matter Prize, given to researchers who make considerable contributions to the field of condensed-matter physics.\n\nWang and Chen also provide funding to support a collaborative program between the psychology departments at UC Berkeley and Tsinghua University in Beijing. The Berkeley-Tsinghua Program for the Advanced Study in Psychology aims to create and support collaborative, psychological research between faculty and students from both universities.\n\nIn August 2012 Wang donated 6,000 HTC Flyer tablet PCs to 60 high schools in Taipei.\n\nWang is an avid philanthropist who says she prefers to stay out of the limelight despite her many accomplishments. She has begun to insert herself in Taiwan politics, however, by supporting Taiwan President Ma Ying-jeou in his bid for re-election and by voicing her support for the 1992 Consensus. Her husband is Wen Chi Chen, the CEO of VIA Technologies. Wang is Christian. She has two children.\n\n"}
{"id": "21980549", "url": "https://en.wikipedia.org/wiki?curid=21980549", "title": "Conquest of the Air", "text": "Conquest of the Air\n\nConquest of the Air is a 1936 documentary film or docudrama on the history of aviation, until the early stages of World War II. The film features historical footage, and dramatic re-creations, of the developments of commercial and military aviation; including the early stages of technology developments in design, propulsion, and air navigation aids. The film was a London Films production, commissioned by the Air Ministry of the British Government.\n\nThe film was initially commissioned by Alexander Korda prior to the advent of World War II, and the Air Ministry saw the value in promoting Britain's contribution and leadership in aviation during this period. Some notable footage is featured of the early phases of automated flight, navigational equipment, and the transitions between civil and military developments, including heavy bombers; fast fighter aircraft; and the advent of naval aviation (aircraft carrier), plus the initial experiments with vertical rotary flight (helicopters).\n\nAn updated version was released in 1940 and released in the United States on 20 May 1940.\n\n"}
{"id": "31517648", "url": "https://en.wikipedia.org/wiki?curid=31517648", "title": "Corinna E. Lathan", "text": "Corinna E. Lathan\n\nCorinna E. Lathan is an American entrepreneur, engineer, and social activist. She is the Chief Executive Officer, Co-Founder, and Board Chair of AnthroTronix, Inc., a biomedical research and development company headquartered in Silver Spring, Maryland, USA. Lathan is recognized for her work on digital health software and assistive technology.\n\nLathan received her B.A. in Biopsychology and Mathematics from Swarthmore College in Swarthmore, Pennsylvania and an S.M. in Aeronautics and Astronautics and Ph.D. in Neuroscience from MIT in Cambridge, Massachusetts.\n\nPrior to founding AnthroTronix, Lathan was an Associate Professor of Biomedical Engineering at The Catholic University of America and an Adjunct Associate Professor of Aerospace Engineering at the University of Maryland, College Park.\n\nIn 1999, Lathan co-founded AnthroTronix, Inc., a research and development company in Silver Spring, Maryland. In 2005, she founded AT KidSystems, Inc., a spinoff of AnthroTronix, which distributes alternative computer interfaces and educational software.\n\nAt AnthroTronix, Lathan spearheaded the development of biomedical assistive devices such as CosmoBot, an interactive robot serving children with autism and with disorders that affect the nervous system. Most recently, she led the development of Defense Automated Neurobehavioral Assessment (DANA), an FDA-cleared digital health platform which helps healthcare providers better assess cognitive function.\n\nLathan’s work with children with disabilities and robotics has been featured in magazines including Forbes, Time, and The New Yorker. She was named as Maryland's Top Innovator of the Year, MIT Technology Review’s “Top 100 World Innovators,” and one of Fast Company Magazine’s “Most Creative People in Business,” among other recognitions.\n\nLathan serves as co-chair of World Economic Forum’s Global Futures Council on Human Enhancement, a Board Member for the Smithsonian Institute's Lemelson Center for the Study of Invention and Innovation, and a Board Member at Engineering World Health, supporting the emergence of healthcare technology in the developing world. She also serves as an Independent Director at PTC, a global technology provider for internet of things and augmented reality platforms.\n\nDedicated to empowering women and minorities in science and technology, Lathan founded Keys to Empowering Youth (KEYs) in 1993 at MIT, which has since been adopted at other universities nationwide. She is an advisor to the FIRST and VEX robotics programs and a Board Member at KID Museum.\n\nPreviously, Lathan was an Advisory Board Member of Amman Imman - Water is Life, a judge for Qualcomm Tricorder XPRIZE, and a Board Member of the National Black Child Development Institute.\n\n\n"}
{"id": "34335793", "url": "https://en.wikipedia.org/wiki?curid=34335793", "title": "CuBox", "text": "CuBox\n\nCuBox and CuBox-i are series of small and fanless nettop-class computers manufactured by the Israeli company SolidRun Ltd. They are all cube-shaped and sized at approximately 2 × 2 × 2 inches and weigh 91 grams (0.2 lb, or 3.2 oz). CuBox was first announced in December 2011 and began shipping in January 2012, initially being marketed as a cheap open-source developer platform for embedded systems.\n\nThe first-generation CuBox was according to SolidRun the first commercially available desktop computer based on the Marvell Armada 500-series SoC (System-on-Chip) and at the time was said to be the world's smallest desktop computer. \n\nIn November 2013, SolidRun released the Cubox-i1, i2, i2eX, and i4Pro, containing i.MX6 processors.\n\nCuBox is a low-power computer based on ARM-architecture CPU, using the Marvell Armada 510 (88AP510) SoC with an ARM v6/v7-compliant superscalar processor core, Vivante GC600 OpenGL 3.0 and OpenGL ES 2.0 capable 2D/3D graphics processing unit, Marvell vMeta HD Video Decoder hardware engine, and TrustZone security extensions, Cryptographic Engines and Security Accelerator (CESA) co-processor.\nDespite being about 2-inch-square in size, the platform can stream and decode 1080p content, use desktop-class interfaces such as KDE or GNOME under Linux, while requiring less than 3 watts and less than 1 watt in standby.\n\nSolidRun currently officially only supports Linux kernel 2.6.x or later and Android 2.2.x and later. It comes with Ubuntu Desktop 10.04 and Android 2.2 dual-boot pre-installed.\n\nIn November 2013, SolidRun released a family of CuBox-i computers named CuBox-i1, i2, i2eX, and i4Pro, containing a range of different i.MX6 processors by Freescale Semiconductor.\n\nThey have also released a series of caseless i.MX6 models called the Hummingboard.\n\nAnnounced in December 2014, CuBoxTV is a mid-range and simplified version of the CuBox-i computer. It is designed to exclusively operate KODI (formerly known as XBMC) on an OpenELEC operating system.\n\nCuBoxTV weighs approximately 9.9oz (281 grams), and is around 2X2 Inches wide and 1.8 inches high, shaped like a cube with rounded sides. It features an i.MX6 Quad core processor at a 1GHz speed, 1GB of RAM memory, 8GB base storage memory and a GC2000 OpenGL quad shader GPU. It houses a couple of USB 2.0 ports, a HDMI port, microSD port and an Ethernet port.\n\n\n\n"}
{"id": "870234", "url": "https://en.wikipedia.org/wiki?curid=870234", "title": "Cwm Silicon", "text": "Cwm Silicon\n\nCwm Silicon (literally \"Silicon Valley\") is an epithet applied to a region of South Wales in the far west of Newport that attracted much interest and inward investment from the technology sector in the early 2000s.\n\nThe future of the area as an important technological centre is now uncertain following the closure of its key LG factory in August 2003. The area is next to the M4 and is a centre for high-technology companies, like much of the M4 corridor.\n\n"}
{"id": "12557219", "url": "https://en.wikipedia.org/wiki?curid=12557219", "title": "Cybozu", "text": "Cybozu\n\nThe U.S.-based subsidiary, kintone Corporation, is located in San Francisco, California.\n\nIn 1997, Toru Takasuka resigned as the Vice President/Director of Matsushita Electric Works V-Internet Operations, an in-house venture company he helped to create. Along with partners Yoshihisa Aono and Shinya Hata, he started the software company in Matsuyama, Ehime with a $200,000 loan from family and friends. The company aimed to produce Japan’s first web-based groupware products. Cybozu, Japanese for “cyber-kid”, rapidly gained market share in the Japanese market. Within three years the company went public – at that time the fastest company rise to IPO in the history of Japan’s 2nd section of the Tokyo Stock Exchange. Today Cybozu is the number one groupware producer in Japan. They are currently listed on the 1st section of the Tokyo Stock Exchange.\n\nCybozu prides itself on having a corporate culture that enables its employees to have a healthy work-life balance. In 2017, Cybozu was listed by Great Place to Work as the number one mid-sized Japanese company for women.\n\nReleased in 2011, Cybozu's low code/no code platform known as kintone was recognized by the Gartner Magic Quadrant for Enterprise Application Platform as a Service (aPaaS) in both 2016 and 2017. It was also listed by CIO Applications as one of the 25 Workflow Solutions Transforming Businesses in 2016. In November 2013, Cybozu along with Zendesk launched their joint marketing efforts at the cybozu.com conference on cloud computing in Tokyo.\n"}
{"id": "31480059", "url": "https://en.wikipedia.org/wiki?curid=31480059", "title": "DA-88", "text": "DA-88\n\nThe DA-88 was a digital\nmultitrack recording device introduced by the TASCAM division of the TEAC Corporation in 1993. This modular, digital multitrack device uses tape as the recording medium and could record up to eight tracks simultaneously. It also allowed multiple DA-88 devices to be combined to record 16 or more tracks. The first models in the series (the TASCAM DA-88, DA-38, DA-98 and Sony PCM-800) recorded at 16-bit resolution. TASCAM later introduced the DA-98HR and DA-78HR, which recorded at 24-bit resolution. Audio data was stored in the DTRS (Digital Tape Recording System) format on Hi-8mm video compact cassettes, allowing up to 108 minutes of continuous recording on a single tape.\n\nIn 1995, the TASCAM DA-88 won the Emmy award for technical excellence. The affordability and digital format of the DA-88 led to sales of more than 60,000 units by 1999. At that time, it was the biggest product in the history of TASCAM.Because of its reliability and durability, the DA-88 and its subsequent fellow units continue to be used by aficionados.\n\n\n"}
{"id": "32607572", "url": "https://en.wikipedia.org/wiki?curid=32607572", "title": "D mount", "text": "D mount\n\nA D-mount is a type of lens mount commonly found on 8mm movie cameras.\n\nThroat or thread diameter 15.88 mm (0.625 inch)\nMount thread pitch 32 TPI\nFlange focal distance 12.29 mm\n\nD-Mount lenses have found new uses in the Nikon 1 series and the Pentax Q series cameras.\n\n"}
{"id": "29474006", "url": "https://en.wikipedia.org/wiki?curid=29474006", "title": "DoceboLMS", "text": "DoceboLMS\n\nDocebo is a software as a service artificial intelligence platform for e-learning, also known as a learning management system. Established in 2005, Docebo (Latin for \"I will teach\") offers a learning portal for companies and their employees, partners and customers. Docebo is compatible with SCORM 1.2 and 2004 as well as Tin Can. Developed by Docebo Srl, the program was originally released under a GPL V. 2.0 license with no licensing costs. The program now operates as a cloud-hosted software as a service platform as well as being third-party compatible. It currently runs version 7.5. The company using the platform loads a course, creates a username and password for employees, and tracks the progress of its users. Docebo is available in more than 40 languages. While the primary users of Docebo are midsized companies, it is also assessable for large companies and SMEs. Docebo also has their platform being used for external enterprise training.\n\nIn 2016, 2017 and 2018, Docebo was named by PCMag as \"the best online learning platform for business on the market.\" \n\nIn October 2018, Docebo released their learning-specific artificial intelligence algorithms into the learning platform that are powered by a combination of machine learning, deep learning and natural language processing to produce an automated and holistic approach to learning (formal LMS, experiential and social) that drives growth, organizational performance, and revenue.\n\nWith Docebo Learn (LMS), enterprises have the ability to centralize and organize courses, distribute and manage online and instructor-led courses, track certifications and measure results with dashboards and custom analytics. Docebo Learn (LMS) is powered by AI, automatically tagging learning content and making it easier to find.\n\nDocebo also provides accompanying modules to Docebo Learn include Docebo Coach & Share (AI Powered Social Learning), enabling learning in the flow of work with informal and experiential learning opportunities and Docebo Perform (skills gap management), helping organizations empower their people through skills gap analysis and improving employee competencies with targeted learning programs based on the current and future skills need of your business.\n\nDocebo was founded in 2005 by Claudio Erba, who continues to lead the company as CEO. Erba had previously been working at the University of Florence as a computer consultant when a customer asked for a storage solution for teaching material. The storage solution evolved into what is now Docebo.\n\nIn 2012, Docebo received its first round of funding from Italian venture capital firm Principia SGR. Later that same year, Docebo opened an office in Athens, Georgia.\n\nDocebo's second venture-backed financing round came from Canadian firm Klass Capital in 2016, funding its continued North American expansion with the opening of an office in Toronto, Ontario.\n\n"}
{"id": "36706464", "url": "https://en.wikipedia.org/wiki?curid=36706464", "title": "Educarchile", "text": "Educarchile\n\neducarchile is a Chilean educational website owned by the Ministry of Education of Chile and Fundación Chile. educarchile was created in 2001 using as a basis two different projects from the Ministry of Education and Fundación Chile, and its purpose is \"to be the great Internet educative center for teachers, students, families and education researchers.\"\n\n"}
{"id": "37690280", "url": "https://en.wikipedia.org/wiki?curid=37690280", "title": "FastSpring", "text": "FastSpring\n\nFastSpring is a SaaS company that offers a subscription billing service & eCommerce platform for SaaS, software and other digital product & service companies to monetize their products and services online. The Company's technology provides an end-to-end payment processing, subscription management & fulfillment solution for companies that develop SaaS, software, digital media, video games, e-books and more.\n\nFounded in 2005, the company is based in Santa Barbara, CA. In March 2011, FastSpring launched its subscription management and recurring billing solution. The company received its first outside investment in April 2013 for an undisclosed amount from Pylon Capital. \nFastSpring was recognized for a Silver Stevie Award for Customer Service Department of the Year in 2013 and again in 2014 and 2015.\n\n\n"}
{"id": "25820465", "url": "https://en.wikipedia.org/wiki?curid=25820465", "title": "GO-ESSP", "text": "GO-ESSP\n\nThe Global Organization of Earth System Science Portals or (\"GO-ESSP\") is an international collaboration, formed in 2003, that is developing software infrastructure to support the distribution, and analysis of climate model data and related observations.\n\nGO-ESSP is playing a central role in coordinating United States and European efforts to document and distribute data for the 5th coupled model intercomparison project, which will be part of the IPCC Fifth Assessment Report.\n\n"}
{"id": "58901230", "url": "https://en.wikipedia.org/wiki?curid=58901230", "title": "Germain Service", "text": "Germain Service\n\nThe Germain Service is an 18th-century tableware set comprising more than a thousand pieces in cast, raised, and chiselled silver, made in the workshop of French silversmith François-Thomas Germain for the Portuguese royal family. This service is now on permanent exhibition as part of the collection of the National Museum of Ancient Art, in Lisbon, Portugal.\n\nThe service was commissioned by Joseph I of Portugal in 1756, just after the 1755 Lisbon earthquake, in an attempt to renew the splendor of the royal court (as the earthquake had, in the words of Royal Jewel Keeper António Pinto da Silva, \"[reduced] \"to ashes all treasure and tapestries of the Royal Household, sparing nothing\"\"); there were, however, troubles in the consignment of the service: in 1765, Germain declared bankruptcy and the order was left unfinished (which precipitated the Portuguese Crown to start a legal dispute to reclaim the loss of the goods, to no avail). One of the most expressive elements of a great \"à la française\" service was missing: the fourth-course \"surtout\". Still, the Germain Service was considered the \"First Service\" of the Crown, to which was added the service confiscated from the Duke of Aveiro in 1759 (the \"Second Service\") — they both made up \"all necessary tableware\" for court feasts.\n\nThe Germain Service was used publicly for the first time during the ceremonies of the Acclamation of Queen Maria I, the daughter of Joseph I, on 13 May 1777.\n\nIn 2006, the Germain Service was made part of the Ministry of Culture's list of Portuguese National Treasures.\n"}
{"id": "38130916", "url": "https://en.wikipedia.org/wiki?curid=38130916", "title": "German Continental Deep Drilling Programme", "text": "German Continental Deep Drilling Programme\n\nThe German Continental Deep Drilling Program (in German: ), abbreviated as the KTB borehole, was a scientific drilling project carried out from 1987 to 1995 near Windischeschenbach, Bavaria. The main super-deep borehole reached a depth of 9,101 meters in the Earth's continental crust.\n\nThe Federal Ministry of Research funded the project with 528 million DM (270 million Euros). The Lower Saxony LBEG mining office (State Office for Mining, Energy and Geology) took the project lead. After the drilling project ended, the German Research Centre for Geosciences used the borehole to install a seismic deep observatory () which was active from 1996 to 2001. The derrick used at the site, one of the largest in the world, remains in place and has become a tourist attraction. The two boreholes were kept open for further scientific research.\n\nIn October 1986 the German Minister for Research and Technology (Bundesminister für Forschung und Technologie), Dr. H. Riesenhuber, officially announced that the super-deep borehole of the Continental Deep Drilling Program of the Federal Republic of Germany (KTB) would be drilled in the Upper Palatinate area of Northern Bavaria. This site was selected against an alternative proposed site in the Black Forest area based on recommendations made by the Deutsche Forschungsgemeinschaft (DFG). These were based on evaluations of the technical and financial risks by the project management team. The site recommendation and selection was preceded by a conference held from September19 to 21, 1986 in Seeheim/Odenwald. Results of the site studies in the Upper Palatinate and the Black Forest were presented and discussed there. Immediately following the conference and evaluation of scientific and technical models and targets, members of the DFG Senate Commission for Geoscientific Interdisciplinary Research voted almost unanimously for the Oberpfalz site. In presenting their decision, the DFG Senate Commission emphasized that while the Upper Palatinate site was favoured in the vote, both locations offered a number of positive research objectives and that both locations were potentially suitable sites for research drilling.\n\nThe KTB project utilized several innovations to drill design. The Kola drilling experiment had had problems with high friction that was increased by the vertical instability when drilling to such depths. German scientists designed a new drill head which would maintain direction with a minimal lateral difference. The drill head was also designed to withstand temperatures between . The original expectations had been that this temperature would be reached at a depth of about 10 to 14 kilometers. This is also the reason why the Upper Palatinate site was chosen. The Black Forest site had been considered suitable from a scientific view, but it was expected to have a higher temperature gradient. At the Upper Palatinate location, however, it was hoped to reach the – a deep-lying mass that is believed to be on the boundary of a former continental plate and is identified by its characteristic reflection of seismic waves.\n\nEven though the was not reached, the KTB drilling was widely considered a success. For one thing, the temperature rose much more quickly than expected. This caused discussion and a reformulation of theories about the temperature gradient of very deep drill holes. Other theory changes were also required – it had been expected that the large tectonic pressures and high temperatures would create metamorphic rock. Unexpectedly the rock layers were not solid at the depths reached. Instead large amounts of fluid and gas poured into the drill hole. Due to the heat and fluids, the rock was of a dynamic nature which changed how the next super-deep drilling needed to be planned.\n\nThe experiments at the KTB produced interesting results. The initial seismic tests showed very different recordings compared to those near the surface so that the theories on the source of seismic reflections needed to change. Using the data, the reflections from depth could be interpreted better even when initiated from the surface.\n\nThe first experiment, the measured the electric conductibility around the drill hole. This showed lines of graphite spanning through the rocks that allowed the rocks to slide when under sufficient pressure. The second experiment was to exert high pressure in the drill hole such that the rock would start cracking, the . The resulting seismic activity was measured at multiple stations in the area. The conclusion was that the overall pressure came from the south, the African tectonic plate at work. The third experiment, the ,\" pumped large amounts of fluid into the rock which proved it to be generally porous.\n\nThese experiences were the foundation of the follow-up project, the International Continental Scientific Drilling Program (ICDP) founded in 1996. The German scientists of the KTB were also called to help with the San Andreas Fault Observatory at Depth drill hole.\n\n"}
{"id": "28244713", "url": "https://en.wikipedia.org/wiki?curid=28244713", "title": "Gorilla Glass", "text": "Gorilla Glass\n\nGorilla Glass is a brand of chemically strengthened glass developed and manufactured by Corning, now in its sixth generation, designed to be thin, light and damage-resistant. Gorilla Glass is unique to Corning, but close equivalents exist, including AGC Inc. Dragontrail and Schott AG Xensation.\n\nThe alkali-aluminosilicate sheet glass is used primarily as cover glass for portable electronic devices, including mobile phones, portable media players, portable computer displays, and television screens. It is manufactured in Harrodsburg, Kentucky, US; Asan, Korea; and Taiwan.\n\nThe glass gains its surface strength, ability to contain flaws, and crack-resistance by being immersed in a proprietary, hot potassium salt ion-exchange bath.\n\nCorning experimented with chemically strengthened glass in 1960, as part of a \"Project Muscle\" initiative. Within a few years they had developed a \"muscled glass\" marketed as \"Chemcor\". The product was used until the early 1990s in commercial and industrial applications, including automotive, aviation and pharmaceutical uses, notably in approximately one hundred 1968 Dodge Dart and Plymouth Barracuda racing cars, where minimizing the vehicle's weight was essential. Experimentation was revived in 2005, investigating whether the glass could be made thin enough for use in consumer electronics. It was brought into commercial use when Apple asked Corning for a thin, toughened glass to be used in its new iPhone.\n\nAs of October 2017, some five billion devices globally contain Gorilla Glass. While dominating its market, Gorilla Glass faces varying competition from rivals such as Dragontrail and sapphire glass.\n\nCorning further developed the material for a variety of smartphones and other consumer electronics devices for a range of companies.\n\nThe manufacturer markets the material's primary properties as its high scratch-resistance (protective coating) and its hardness (with a Vickers hardness test rating of 622 to 701), which allows the glass to be thin without fragility. It can be recycled.\n\nBy 2010, the glass had been used in approximately 20% of mobile handsets worldwide, about 200 million units. The second generation, called \"Gorilla Glass 2\", was introduced in 2012. On October 24, 2012, Corning announced that over one billion mobile devices used Gorilla Glass. Gorilla Glass 2 is 20% thinner than the original Gorilla Glass.\n\nGorilla Glass 3 was introduced at CES 2013. According to Corning, the material is up to three times more scratch-resistant than the previous version, with enhanced ability to resist deep scratches that typically weaken glass. The promotional material for Gorilla Glass 3 claims that it is 40% more scratch-resistant, in addition to being more flexible. The design of Gorilla Glass 3 was Corning's first use of atomic-scale modeling before the material was melted in laboratories, with the prediction of the optimal composition obtained through the application of rigidity theory.\n\nWhen Gorilla Glass 3 was announced Corning indicated that areas for future improvements included reducing reflectivity and susceptibility to fingerprint smudges, and changing the surface treatments and the way it is finished. Antimicrobial Gorilla Glass with ionic silver, which is antibacterial, incorporated into its surface was demonstrated in early 2014.\n\nGorilla Glass 4, with better damage resistance and capability to be made thinner with the same performance as its predecessor, was announced at the end of 2014.\n\nGorilla Glass 5 was first used on the Samsung Galaxy Note 7 in 2016.\n\nGorilla Glass SR+ was first used on the Samsung Gear S3 smartwatch in 2016.\n\nGorilla Glass has also addressed the automobile market. Ford Motor Company announced it will be using the material for the front and rear windshields on its Ford GT sports car beginning in 2016.\n\nDuring its manufacture, the glass is toughened by ion exchange. The material is immersed in a molten alkaline potassium salt at a temperature of approximately , wherein smaller sodium ions in the glass are replaced by larger potassium ions from the salt bath. The larger ions occupy more volume and thereby create a surface layer of high residual compressive stress, giving the glass surface increased strength, ability to contain flaws, and overall crack-resistance, making it resistant to damage from everyday use.\n\nOn October 26, 2011, Corning announced the commercial launch of Lotus Glass, designed for OLED and next-generation LCD displays. The intrinsic thermal consistency of Lotus Glass allows it to retain its shape and quality during high-temperature processing. Decreased compaction and variation during the crystallization and activation step further reduce stress and distortions to the substrate. This enables tighter design rules in advanced backplanes for higher resolution and faster response time. According to Corning, Gorilla Glass is specifically a cover glass for the exterior of display devices while Lotus Glass is designed as a glass substrate to be used within liquid crystal display panels. In other words, a single product could incorporate both Gorilla Glass and Lotus Glass. On February 2, 2012, Corning Incorporated and Samsung Mobile Display Co., Ltd. signed an agreement to establish a new equity venture for the manufacture of specialty glass substrates for the OLED device market in Korea. The joint venture is based on Lotus Glass. Lotus XT Glass became available in 2013.\n\nIn 2012, Corning introduced Willow Glass, a flexible glass based on borosilicate glass, launched for use as a display substrate.\n\n\n"}
{"id": "23095994", "url": "https://en.wikipedia.org/wiki?curid=23095994", "title": "Heli-logging", "text": "Heli-logging\n\nHeli-Logging, or Helicopter Logging, is a method of logging that uses helicopters to remove cut trees from forests by lifting them on cables attached to a helicopter. Helicopter logging is often used in inaccessible areas of forests. Because the use of helicopters reduces the level of infrastructure required to log in a specific location, the method also helps to reduce the environmental impact of logging. It also can increase the productivity in these remote areas.\n\nStanding Stem Harvesting, a selective harvesting method within Heli-Logging, was invented by Philip Jarman of Port Alberni, British Columbia between May and October 1997. The initial harvesting equipment used wire rope or chokers to rig the stem and a modified external hook to engage the choker and lift the stem clear of the stump. In this way, the process of harvesting, which includes climbing, measuring, cutting, rigging, and lifting was pioneered by a single pilot flying a light utility helicopter. \nIn 1998, the inventor supervised the building of an experimental grapple which was to be operated by a K-Max Lift Truck helicopter. However, because the K-Max had no hydraulics, it was necessary to design and install an externally mounted, jettisonable sled carrying a hydraulic power pack, to operate the grapple.\nInitial flight trials were carried out using the external hook and wire rope configuration on the 25th of April 1998. In late October 1998, a successful full-scale harvesting trial using a grapple designed by the inventor and funded by the timber licensee was carried out at Lunchtime Lake on Vancouver Island. Press releases and logging industry recognition followed. Patent applications in the United States and Canada were submitted and granted in 2001 and 2002 respectively.\n\nIn general, Heli-logging operations rarely use the light-weight, single-engine Kaman, and most operators will select one of three tested heavier twin-engine helicopter types: the 9000hp Sikorsky S-64 Skycrane, the 3900hp MIL 8, and the 4400hp KAMOV Ka-32. These three types are most suited to Heli-logging because of structural and systems designs, for example, their twin-engine layout, and dual hydraulic systems. Although the S-64 is an excellent and powerful machine, relatively few have been made, certainly less than 50 total. On the other hand, hundreds of Ka-32s have been built, and the MIL-8s number in the thousands. The Kamov Ka-32A11BC is used for Heli-logging in mountainous areas of western Canada because of its availability and the fact that it is certified in Canada and Europe for commercial operations.\n\nHeli-Logging is also known as standing stem harvesting which is based on individual tree selection (ITS). The selection process is done by engineers and surveyors. The trees are selected based on demand for specific types and grades. Before the selection process is complete the selected trees are bored to check their reliability. The selected trees are then marked and their diameters are recorded. The diameter of the tree is measured at 1.3 meters above the ground. The sizes of the trees that are selected are controlled by two things. The minimum size is controlled by the economy while the maximum size is controlled by the capacity of the helicopter. Once the trees are selected they are climbed, the limbs are removed and the trees are topped. The length of the tree and the diameter at its top are then recorded. All the recorded data is then entered into a database which calculates volumes, weights, etc. The selected trees are then partially cut at the stem and supported by wooden wedges. The stem is then grappled by the helicopter and pulled until the wood breaks at the partial cut. The logged trees are then brought by helicopter to a predetermined roadside location or dropped into open water where they are collected.\n\nHeli-logging is efficient: a single S-64 Skycrane can extract 20 000 m (about 15,000 tonnes) of clean, undamaged timber per month. Conventional logging allows the stems to fall. On rocky terrains this often results in damage to the stems that makes them unusable. On steep terrains falling trees can slide downhill and become irretrievable. Heli-logging allows logging to take place in more remote places. It also allows certain trees to be logged that previously could not be due to their proximity to a structure or pipeline. Logging using helicopters is safer than conventional logging. Falling trees are dangerous for the loggers as well as for surrounding structures or utilities. Heli-logging also extends the logging season. This is due to the lack of snow load on a standing stem.\n\nHelicopter logging ground crews will cut, clean, and mark the trees before the helicopter starts to work. Ground crews may be able to prepare fewer than 6 trees per day, and the helicopter will only be needed every few days. Since fewer roads need to be built to the site where the logging is taking place, and trees are extracted vertically, there is reduced damage to the surrounding trees and ground surface.\n\nResearch by Roberts, Ward and Rollerson done in 2004 shows that post-logging landslides are more common after conventional cable-based logging than heli-logging. Landslide rates following conventional logging are one and a half times more common than landslide rates following heli-logging.\n\nAlthough there is no direct cost from road construction or expansion, heli-logging incurs high costs. Operation of a helicopter as well as the selection processes and methods increase the cost. The use of a helicopter to transport the stems limits the size and weight of the selected trees more than equipment would using conventional logging.\n"}
{"id": "1787746", "url": "https://en.wikipedia.org/wiki?curid=1787746", "title": "Hitec", "text": "Hitec\n\nHitec is a company based in South Korea that manufactures radio control devices, including transmitters, receivers, servos, electronics and model aircraft. Later products include robotics, servos with Karbonite gears and the Robonova—a humanoid robot accepted in the Robo one robot competition. Hitec is linked to Multiplex USA.\n\n"}
{"id": "18339085", "url": "https://en.wikipedia.org/wiki?curid=18339085", "title": "How'd That Get on My Plate?", "text": "How'd That Get on My Plate?\n\nHow'd That Get On My Plate? is a television series on Food Network.\n\nThe show premiered in July 2008, and hosted by Sunny Anderson. The program investigates how various foods are produced (including honey, milk, eggs, strawberries, and cocoa in the first season), from their rawest form to their finished state, and features visits to food production factories throughout the United States.\n"}
{"id": "3105389", "url": "https://en.wikipedia.org/wiki?curid=3105389", "title": "Iconoscope", "text": "Iconoscope\n\nThe Iconoscope (from the Greek: \"εἰκών\" \"image\" and \"σκοπεῖν\" \"to look, to see\") was the first practical video camera tube to be used in early television cameras. The iconoscope produced a much stronger signal than earlier mechanical designs, and could be used under any well-lit conditions. This was the first fully electronic system to replace earlier cameras, which used special spotlights or spinning disks to capture light from a single very brightly lit spot.\n\nSome of the principles of this apparatus were described when Vladimir Zworykin filed two patents for a \"Television system\" in 1923 and 1925. A research group at RCA headed by Zworykin presented the iconoscope to the general public in a press conference in June 1933, and two detailed technical papers were published in September and October of the same year. The German company Telefunken bought the rights from RCA and built the superikonoskop camera used for the historical TV transmission at the 1936 Summer Olympics in Berlin.\nThe iconoscope was replaced in Europe around 1936 by the much more sensitive Super-Emitron and Superikonoskop, while in the United States the Iconoscope was the leading camera tube used for broadcasting from 1936 until 1946, when it was replaced by the image orthicon tube.\n\nThe main image forming element in the iconoscope was a mica plate with a pattern of photosensitive granules deposited on the front using an electrically insulating glue. The granules were typically made of silver grains covered with caesium or caesium oxide. The back of the mica plate, opposite the granules, was covered with a thin film of silver. The separation between the silver on the back of the plate and the silver in the granules caused them to form individual capacitors, able to store electrical charge. These were typically deposited as small spots, creating pixels. The system as a whole was referred to as a \"mosaic\".\n\nThe system is first charged up by scanning the plate with an electron gun similar to one in a conventional television display tube. This process deposits charges into the granules, which in a dark room would slowly decay away at a known rate. When exposed to light, the photosensitive coating releases electrons which are supplied by the charge stored in the silver. The emission rate increases in proportion to the intensity of the light. Through this process, the plate forms an electrical analog of the visual image, with the stored charge representing the inverse of the average brightness of the image at that location.\n\nWhen the electron beam scans the plate again, any residual charge in the granules resists refilling by the beam. The beam energy is set so that any charge resisted by the granules is reflected back into the tube, where it is collected by the collector ring, a ring of metal placed around the screen. The charge collected by the collector ring varies in relation to the charge stored in that location. This signal is then amplified and inverted, and then represents a positive video signal.\n\nThe collector ring is also used to collect electrons being released from the granules in the photoemission process. If the gun is scanning a dark area few electrons would be released directly from the scanned granules, but the rest of the mosaic will also be releasing electrons that will be collected during that time. As a result, the black level of the image will float depending on the average brightness of the image, which caused the iconoscope to have a distinctive patchy visual style. This was normally combatted by keeping the image continually and very brightly lit. This also led to clear visually differences between scenes shot indoors and those shot outdoors in good lighting conditions.\n\nAs the electron gun and the image itself both have to be focused on the same side of the tube, some attention has to be paid to the mechanical arrangement of the components. Iconocopes were typically built with the mosaic inside a cylindrical tube with flat ends, with the plate positioned in front of one of the ends. A conventional movie camera lens was placed in front of the other end, focussed on the plate. The electron gun was then placed below the lens, tilted so that it was also aimed at the plate, although at an angle. This arrangement has the advantage that both the lens and electron gun lie in front of the imaging plate, which allows the system to be compartmentalized in a box-shaped enclosure with the lens completely within the case.\n\nAs the electron gun is tilted compared to the screen, its image of the screen is not as a rectangular plate, but a keystone shape. Additionally, the time needed for the electrons to reach the upper portions of the screen was longer than the lower areas, which were closer to the gun. Electronics in the camera adjusted for this effect by slightly changing the scanning rates.\n\nThe accumulation and storage of photoelectric charges during each scanning cycle greatly increased the electrical output of the iconoscope relative to non-storage type image scanning devices. In the 1931 version, the electron beam scanned the granules; while in the 1925 version, the electron beam scanned the back of the image plate.\n\nThe problem of low sensitivity to light resulting in low electrical output from transmitting or \"camera\" tubes would be solved with the introduction of charge-storage technology by the Hungarian engineer Kálmán Tihanyi in the beginning of 1925. His solution was a camera tube that accumulated and stored electrical charges (\"photoelectrons\") within the tube throughout each scanning cycle. The device was first described in a patent application he filed in Hungary in March 1926 for a television system he dubbed \"Radioskop\". After further refinements included in a 1928 patent application, Tihanyi's patent was declared void in Great Britain in 1930, and so he applied for patents in the United States.\n\nZworykin presented in 1923 his project for a totally electronic television system to the general manager of Westinghouse. In July 1925, Zworykin submitted a patent application for a \"Television System\" that includes a charge storage plate constructed of a thin layer of isolating material (aluminum oxide) sandwiched between a screen (300 mesh) and a colloidal deposit of photoelectric material (potassium hydride) consisting of isolated globules. The following description can be read between lines 1 and 9 in page 2: \"The photoelectric material, such as potassium hydride, is evaporated on the aluminum oxide, or other insulating medium, and treated so as to form a colloidal deposit of potassium hydride consisting of minute globules. Each globule is very active photoelectrically and constitutes, to all intents and purposes, a minute individual photoelectric cell\". Its first image was transmitted in late summer of 1925, and a patent was issued in 1928. However the quality of the transmitted image failed to impress to H P Davis, the general manager of Westinghouse, and Zworykin was asked \"to work on something useful\". A patent for a television system was also filed by Zworykin in 1923, but this file is not a reliable bibliographic source because extensive revisions were done before a patent was issued fifteen years later and the file itself was divided into two patents in 1931. \nThe first practical iconoscope was constructed in 1931 by Sanford Essig, when he accidentally left one silvered mica sheet in the oven too long. Upon examination with a microscope, he noticed that the silver layer had broken up into a myriad of tiny isolated silver globules. He also noticed that: \"the tiny dimension of the silver droplets would enhance the image resolution of the iconoscope by a quantum leap.\" As head of television development at Radio Corporation of America (RCA), Zworykin submitted a patent application in November 1931, and it was issued in 1935. Nevertheless, Zworykin's team was not the only engineering group working on devices that use a charge stage plate. In 1932, Tedham and McGee under the supervision of Isaac Shoenberg applied for a patent for a new device they dubbed \"the emitron\", a 405-line broadcasting service employing the super-emitron began at studios in Alexandra Palace in 1936, and a patent was issued in the USA in 1937. One year later, in 1933, Philo Farnsworth also applied for a patent for a device that use a charge storage plate and a low-velocity electron scanning beam, a patent was issued in 1937, but Farnsworth did not know that the low-velocity scanning beam must land perpendicular to the target and he never actually built such a tube.\n\nThe iconoscope was presented to the general public in a press conference in June 1933, and two detailed technical papers were published in September and October of the same year. Unlike the Farnsworth image dissector, the Zworykin iconoscope was much more sensitive, useful with an illumination on the target between 4ft-c (43lx) and 20ft-c (215lx). It was also easier to manufacture and produced a very clear image. The iconoscope was the primary camera tube used in American broadcasting from 1936 until 1946, when it was replaced by the image orthicon tube.\n\nOn the other side of the Atlantic Ocean, the British team formed by engineers Lubszynski, Rodda, and MacGee developed the super-emitron (also superikonoscop in Germany) in 1934, this new device is between ten and fifteen times more sensitive than the original emitron and iconoscope, and it was used for a public broadcasting by the BBC, for the first time, on Armistice Day 1937. The image iconoscope was the representative of the European tradition in electronic tubes competing against the American tradition represented by the image orthicon.\n\n\n"}
{"id": "56917282", "url": "https://en.wikipedia.org/wiki?curid=56917282", "title": "Linda Findley Kozlowski", "text": "Linda Findley Kozlowski\n\nChief Operating Officer of Etsy since May 2016. Findley Kozlowski was previously Evernote's COO and started her career in Public Relations.\n"}
{"id": "31887201", "url": "https://en.wikipedia.org/wiki?curid=31887201", "title": "Litton's Weekend Adventure", "text": "Litton's Weekend Adventure\n\nLitton's Weekend Adventure (originally known as ABC Weekend Adventure) is an American syndicated programming block that is produced by Litton Entertainment, and airs weekend mornings on the owned-and-operated stations and affiliates of ABC. The block features live-action documentary and lifestyle series aimed at a family audience that meet educational programming requirements defined by the Children's Television Act. Announced on May 24, 2011, \"Litton's Weekend Adventure\" premiered on September 3, 2011, succeeding the ABC Kids block.\n\nAs the block is syndicated to ABC stations rather than being part of the network's schedule, \"Litton's Weekend Adventure\" does not contain any ABC branding or promotions, and likewise is not promoted directly by ABC on-air or mentioned on the network's website.\n\nThe block came as a result of ABC's decision in early 2011 to no longer provide E/I programming as part of its Saturday morning network lineup to its affiliates; the network had not introduced any new E/I programs for its ABC Kids block since 2008, and those that had been airing on the network at the time of the decision consisted of reruns of Disney Channel sitcoms that had first aired on the block between September 2005 and May 2007, all of which were out of production by the time ABC Kids ended its run. In addition, before Haim Saban repurchased the rights to the \"Power Rangers\" franchise from The Walt Disney Company in 2010, several station groups that owned ABC affiliates (such as Hearst Television, which would later acquire a majority stake in Litton Entertainment in 2017 and Allbritton Communications) refused to carry any series from that franchise (or any other non-E/I-compliant shows within the block such as \"Kim Possible\") or chose to run them only in low-rated early morning timeslots, and had demanded any lineup be fully educational so the stations would not have to purchase E/I programming from syndication distributors.\n\nMost of the major commercial networks began restructuring their Saturday morning children's program blocks (with Fox dropping its outright) to comply to tightened educational content and advertising regulations in the Children's Television Act; cultural shifts and changes in viewing habits through the migration of younger viewers to cable channels, recordable and streaming media were also affecting viewership of children's lineups carried by broadcast television networks.\nAs a compromise, the network's affiliate board agreed to instead look for a syndication package that would air exclusively on ABC owned-and-operated and affiliate stations. Litton Entertainment was eventually selected by the ABC affiliate board to program the block, beating out two other competitors as a part of the winning presentation in which Litton suggested counterprogramming the then-usual Saturday morning fare by featuring unscripted and \"pro-social programming\" aimed at children and teenagers ages 7–17.\n\nABC and Litton Entertainment announced the block on May 17, 2011 for a fall 2011 launch, under the working title \"ABC Weekend Adventure\". ABC initially signed deals with its owned-and-operated station group ABC Owned Television Stations, as well as affiliates owned by Cox Broadcasting, The McGraw-Hill Companies, Newport Television and Post-Newsweek Stations to carry the block; these were followed by May 2011 with distribution agreements involving ABC stations owned by Belo, Bonten Media Group, Chambers Communications Corporation, Fisher Communications, Gannett Broadcasting, Hubbard Broadcasting, Journal Broadcast Group, LIN TV Corporation, News-Press & Gazette Company, Young Broadcasting and Weigel Broadcasting.\n\nThe renamed \"Litton's Weekend Adventure\" launched on September 3, 2011 with six series: \"Jack Hanna's Wild Countdown\", \"Ocean Mysteries with Jeff Corwin\", \"Born to Explore with Richard Wiese\", \"Culture Click\", \"Everyday Health\" and \"Food for Thought with Claire Thomas\" (originally titled \"The Delicious Adventures of Claire Thomas\" prior to its debut). Two other series were also initially announced to be in development: the environment-focused \"Agents of Change\" (from producer Mark Koops) and \"Earth: Angry Planet\"; however, neither show was picked up to series. When the block debuted, \"Litton's Weekend Adventure\" became the first Saturday morning block to present all of its programs in high definition. On May 2, 2012, ABC and Litton reached an agreement to broadcast \"Weekend Adventure\" worldwide on the American Forces Network, beginning that June.\n\nOn September 24, 2012, Litton announced that a television version of Everyday Health's YouTube series \"Recipe Rehab\" (one of several web series directly funded by the video sharing website as a part of a premium content initiative) would premiere on the block beginning on October 6, 2012 replacing the \"Everyday Health\" series.\n\nOn September 28, 2013, Litton launched a competing Saturday morning block for CBS, the \"CBS Dream Team\" (which replaced the \"Cookie Jar TV\" block). The following week on October 4, 2013, the \"Weekend Adventure\" block's \"Health and Wellness Hour\" (consisting of health and culinary programs that filled the third hour of the block) was discontinued as part of a refocusing towards exclusively wildlife-focused programs, with the move, \"Recipe Rehab\" migrated to CBS's \"Dream Team\" block\n\nSubsequently on October 4, 2014, \"Expedition Wild\" moved from \"Weekend Adventure\" to another Saturday morning block produced by Litton that launched on that date, \"One Magnificent Morning\" on The CW.\n\nIn 2016, two stations disaffiliated from ABC due to varied issues; WKPT-TV in the Tri-Cities region of Tennessee and Virginia, and WSVI in the U.S. Virgin Islands, but as the Litton syndication contract for \"Weekend Adventure\" is separate from their expired ABC affiliation agreements, were able to continue to air \"Weekend Adventure\" for the time being. The new Tri-Cities ABC affiliate, WJHL-DT2, used programming from the Fox-associated \"Xploration Station\" block (which was turned down by WEMT) and other syndicated programming for their E/I contributions instead. In April 2017, \"Weekend Adventure\" moved to WJHL-DT2 after WKPT voided all of their syndication contracts to become a full-time carrier of Cozi TV.\n\nPrograms featured on \"Litton's Weekend Adventure\" are designed to meet federally mandated educational programming guidelines, allowing ABC stations to comply with the three-hour weekly minimum for E/I content defined by the Federal Communications Commission. However, some ABC stations may carry syndicated educational programs to provide additional E/I content supplementary to the block. Programs aired within the block may be deferred to Sunday daytime slots, or (in the case of affiliates in the Western United States) Saturday afternoons due to breaking news or severe weather coverage or, more commonly, regional or select national sports telecasts (especially in the case of college football games) scheduled in earlier Saturday timeslots as makegoods to comply with the E/I regulations. Some stations may air the entirety of the \"Weekend Adventure\" block on tape delay to accommodate local news or other programs of local interest (such as public affairs shows, real estate or lifestyle programs).\n\n\n\nIn 2014, \"Ocean Mysteries with Jeff Corwin\" won two Creative Arts Daytime Emmy Awards for \"Outstanding Travel Program\".\n"}
{"id": "2359020", "url": "https://en.wikipedia.org/wiki?curid=2359020", "title": "Mathematical methods in electronics", "text": "Mathematical methods in electronics\n\nMathematical methods are integral to the study of electronics.\n\nElectronics Engineering careers usually include courses in Calculus (single and multivariable), Complex Analysis, Differential Equations (both ordinary and partial), Linear Algebra and Probability. Fourier Analysis and Z-Transforms are also subjects which are usually included in electrical engineering programs.\n\nA number of electrical laws apply to all electrical networks. These include\n\nCircuit analysis is the study of methods to solve linear systems for an unknown variable.\n\n\nThere are many electronic components currently used and they all have their own uses and particular rules and methods for use.\n\n\nIf you apply a voltage across a capacitor, it 'charges up' by storing the electrical charge as an electrical field inside the device. This means that while the voltage across the capacitor remains initially small, a large current flows. Later, the current flow is smaller because the capacity is filled, and the voltage raises across the device.\n\nA similar though opposite situation occurs in an inductor; the applied voltage remains high with low current as a magnetic field is generated, and later becomes small with high current when the magnetic field is at maximum.\n\nThe voltage and current of these two types of devices are therefore out of phase, they do not rise and fall together as simple resistor networks do. The mathematical model that matches this situation is that of complex numbers, using an imaginary component to describe the stored energy.\n\n"}
{"id": "5288134", "url": "https://en.wikipedia.org/wiki?curid=5288134", "title": "Memory controller", "text": "Memory controller\n\nThe memory controller is a digital circuit that manages the flow of data going to and from the computer's main memory. A memory controller can be a separate chip or integrated into another chip, such as being placed on the same die or as an integral part of a microprocessor; in the latter case, it is usually called an integrated memory controller (IMC). A memory controller is sometimes also called a memory chip controller (MCC) or a memory controller unit (MCU).\n\nMost modern desktop or workstation microprocessors use an \"integrated memory controller\" (IMC), including microprocessors from Intel, AMD, and those built around the ARM architecture.\n\nPrior to K8 (circa 2003), AMD microprocessors had a memory controller implemented on their motherboard's northbridge. In K8 and later, AMD employed an integrated memory controller. Likewise, until Nehalem (circa 2008), Intel microprocessors used memory controllers implemented on the motherboard's northbridge. Nehalem and later switched to an integrated memory controller.\n\nOther examples of microprocessors that use \"integrated memory controllers\" include IBM's POWER5, and Sun Microsystems's UltraSPARC T1.\n\nWhile an integrated memory controller has the potential to increase the system's performance, such as by reducing memory latency, it locks the microprocessor to a specific type (or types) of memory, forcing a redesign in order to support newer memory technologies. When DDR2 SDRAM was introduced, AMD released new Athlon 64 CPUs. These new models, with a DDR2 controller, use a different physical socket (known as Socket AM2), so that they will only fit in motherboards designed for the new type of RAM. When the memory controller is not on-die, the same CPU may be installed on a new motherboard, with an updated northbridge.\n\nSome microprocessors in the 1990s, such as the DEC Alpha 21066 and HP PA-7300LC, had integrated memory controllers; however, rather than for performance gains, this was implemented to reduce the cost of systems by eliminating the need for an external memory controller.\n\nSome CPUs are designed to have their memory controllers as dedicated external components that are not part of the chipset. An example is IBM POWER8, which uses external Centaur chips that are mounted onto DIMM modules and act as memory buffers, L4 cache chips, and as the actual memory controllers. The first version of the Centaur chip used DDR3 memory but an updated version was later released which can use DDR4.\n\nMemory controllers contain the logic necessary to read and write to DRAM, and to \"refresh\" the DRAM. Without constant refreshes, DRAM will lose the data written to it as the capacitors leak their charge within a fraction of a second (not more than 64 milliseconds according to JEDEC standards).\n\nReading and writing to DRAM is performed by selecting the row and column data addresses of the DRAM as the inputs to the multiplexer circuit, where the demultiplexer on the DRAM uses the converted inputs to select the correct memory location and return the data, which is then passed back through a multiplexer to consolidate the data in order to reduce the required bus width for the operation.\n\nBus width is the number of parallel lines available to communicate with the memory cell. Memory controllers' bus widths range from 8-bit in earlier systems, to 512-bit in more complicated systems and video cards (typically implemented as four 64-bit simultaneous memory controllers operating in parallel, though some are designed to operate in \"gang mode\" where two 64-bit memory controllers can be used to access a 128-bit memory device).\n\nSome memory controllers, such as the one integrated into PowerQUICC II processors, can be connected to different kinds of devices at the same time, including SDRAM, SRAM, ROM, and memory-mapped I/O; each kind of these devices requires a slightly different control bus, while the memory controller presents a common system bus / front-side bus to the processor. Some memory controllers, such as the one integrated into PowerQUICC II processors,\ninclude error detection and correction hardware.\n\nA few experimental memory controllers (mostly aimed at the server market where data protection is legally required) contain a second level of address translation, in addition to the first level of address translation performed by the CPU's memory management unit.\n\nMemory controllers integrated into certain Intel Core processors also provide \"memory scrambling\" as a feature that turns user data written to the main memory into pseudo-random patterns.\n\nMemory Scrambling (in Cryptographic Theory) is supposed to prevent forensic and reverse-engineering analysis based on DRAM data remanence by effectively rendering various types of cold boot attacks ineffective. In current practice this has not been achieved. \n\nHowever Memory Scrambling has only been designed to address DRAM-related electrical problems. The late 2010s Memory Scrambling Standards do not fix or prevent security issues or problems. The 2010s Memory Scrambling standards are not cryptographically secure, or necessarily open sourced or open to public revision or anlysis.\n\nASUS and Intel have their own memory scrambling standards. Currently ASUS motherboards have allowed the user to chose which memory scrambling standards to use [ASUS or Intel] or whether to turn the feature off entirely.\n\nDouble data rate (DDR) memory controllers are used to drive DDR SDRAM, where data is transferred on both rising and falling edges of the system's memory clock. DDR memory controllers are significantly more complicated when compared to single data rate controllers , but they allow for twice the data to be transferred without increasing the memory cell's clock rate or bus width.\n\nDual Channel memory controllers are memory controllers where the DRAM devices are separated on to two different buses to allow two memory controllers to access them in parallel. This doubles the theoretical amount of bandwidth of the bus. In theory, more channels can be built (a channel for every DRAM cell would be the ideal solution), but due to wire count, line capacitance, and the need for parallel access lines to have identical lengths, more channels are very difficult to add.\n\nFully buffered memory systems place a memory buffer device on every memory module (called an FB-DIMM when Fully Buffered RAM is used), which unlike traditional memory controller devices, use a serial data link to the memory controller instead of the parallel link used in previous RAM designs. This decreases the number of the wires necessary to place the memory devices on a motherboard (allowing for a smaller number of layers to be used, meaning more memory devices can be placed on a single board), at the expense of increasing latency (the time necessary to access a memory location). This increase is due to the time required to convert the parallel information read from the DRAM cell to the serial format used by the FB-DIMM controller, and back to a parallel form in the memory controller on the motherboard.\n\nIn theory, the FB-DIMM's memory buffer device could be built to access any DRAM cells, allowing for memory cell agnostic memory controller design, but this has not been demonstrated, as the technology is in its infancy.\n\nMany flash memory devices, such as USB memory sticks, include a flash memory controller on chip. Flash memory is inherently slower to access than RAM and often becomes unusable after a few million write cycles, which generally makes it unsuitable for RAM applications.\n\n\n"}
{"id": "19159342", "url": "https://en.wikipedia.org/wiki?curid=19159342", "title": "NAHBGreen", "text": "NAHBGreen\n\nNAHBGreen is another name for the National Green Building Program of the National Association of Home Builders, an organization based in the United States.\n\nGreen building as a process that incorporates environmental considerations into every aspect of the home building process – from choosing the lot and the house plan to material selection construction of the home and finally, its maintenance and operation. What constitutes \"green\" construction will vary according to the climate, geography and market preferences of the community in which the home will be built.\n\nNAHB members have been building green homes for years – each one appropriate to the climate, geography and market preferences of the communities where they build. Additionally, these builders certified more than 115,000 homes in local HBA green building programs between 1995 and 2008.\n\nThese programs have transformed the market because they are a cooperative effort among builders, designers, environmentalists and elected officials. Green building thrives when builders, developers and remodelers can go green voluntarily, without mandates and overbearing strictures. When that happens, there’s no limit on how green a home can be.\n\nThe NAHB National Green Building Program has several component parts:\n\n\nNAHBGreen homes and projects can come in all sizes, styles and price points – from starter homes to retirement villas. Each one incorporates the hallmarks of green building – energy, water, and resource efficiency, indoor environmental quality and effective lot design.\n\nState and local home builder associations \"affiliate\" with NAHBGreen by encouraging their members to seek National Green Building Certification and providing educational opportunities for builders, remodelers and consumers. As of June 2009, there were 102 state and local NAHBGreen affiliates.\n\nWorking with the International Code Council, NAHB spearheaded the development of the National Green Building Standard for all residential construction and renovation projects. This standard was approved in January 2009 by the American National Standards Institute, making it the benchmark for green homes. The standard development process was the latest in a series of initiatives designed to encourage education, networking and recognition for green builders.\n\nThe NAHB Green Building Subcommittee was formed in 1998 and the annual NAHB Green Building Conference was first held in 1999, when the first NAHB National Green Building Awards were given to a select group of builders, remodelers and advocates for their exemplary progress.\n\nIn 2005, NAHB introduced the NAHB Model Green Home Building Guidelines, allowing builders to \"score\" their projects in seven categories: energy efficiency, water efficiency, resource efficiency, indoor environmental quality, global impact, lot and site development and homeowner education. To score a home, builders had to achieve a minimum number of points in each of the seven categories and additional points in the categories of choice. The more points a project achieved across all categories, the higher the level.\n\nIn 2006, NAHB introduced the two-day \"Green Building for Building Professionals\" class. Home builders, remodelers, designers and suppliers immediately filled sessions held in home building associations all over the country.\n\nThere are two rating systems available to score green projects: The NAHB Model Green Building Guidelines for new single-family homes and the National Green Building Standard for new single-family and multifamily construction, residential remodeling and renovation, and subdivision development.\n\nBoth rating systems are used as design tools for building professionals to plan their green projects. They are also scoring tools, providing the list of green choices made so that inspectors can test and verify the results. Finally, they are used for certification, so that a third party, the NAHB Research Center, can review the inspector's documentation and certify that the project is authentically green. Builders can apply to certify their homes with both the National Green Building Standard and Builders Challenge using the free online Green Scoring Tool.\n\nThe NAHBGreen website provides instructions for the scoring tools and certification process. A list of accredited verifiers is also provided at the site.\n\nThe Certified Green Professional educational designation helps consumers recognize builders, remodelers and other industry professionals who incorporate green building principles into homes — without driving up the cost of construction. Requirements include 24 hours of classroom instruction, two years of industry experience, adherence to a code of ethics and a commitment to approved continuing education sessions.\n\nMore than 3,400 people have earned their CGPs since February 2008 – making it the largest and fastest growing NAHB designation in the history of the University of Housing. Consumers can access a Certified Green Professional at the Builder and Remodeler Online Designation Directory at the program's website.\n\nThe annual National Green Building Conference features educational seminars focusing on topics including Sales and Marketing, Design, Project Management and Building Science. A Tour of Green Homes includes new single-family homes and remodeling projects in various stages of construction.\n\nYou can become a fan of the NAHB National Green Building Conference on Facebook or Linkedin and share your thoughts on green with these online communities.\n\nThe National Green Building Awards focus upon innovative design and technology, and there is also a special category for affordable green homes.\n\n\n"}
{"id": "7655739", "url": "https://en.wikipedia.org/wiki?curid=7655739", "title": "Natural ventilation", "text": "Natural ventilation\n\nNatural ventilation is the process of supplying air to and removing air from an indoor space without using mechanical systems. It refers to the flow of external air to an indoor space as a result of pressure differences arising from natural forces. There are two types of natural ventilation occurring in buildings: \"wind driven ventilation\" and \"buoyancy-driven ventilation\". Wind driven ventilation arises from the different pressures created by wind around a building or structure, and openings being formed on the perimeter which then permit flow through the building. Buoyancy-driven ventilation occurs as a result of the directional buoyancy force that results from temperature differences between the interior and exterior. Since the internal heat gains which create temperature differences between the interior and exterior are created by natural processes, including the heat from people, and wind effects are variable, naturally ventilated buildings are sometimes called \"breathing buildings\".\n\nThe static pressure of air is the pressure in a free-flowing air stream and is depicted by isobars in weather maps. Differences in static pressure arise from global and microclimate thermal phenomena and create the air flow we call wind. Dynamic pressure is the pressure exerted when the wind comes into contact with an object such as a hill or a building and it is described by the following equation:\n\nwhere (using SI units):\n\nThe impact of wind on a building affects the ventilation and infiltration rates through it and the associated heat losses or heat gains. Wind speed increases with height and is lower towards the ground due to frictional drag.\n\nThe impact of wind on the building form creates areas of positive pressure on the windward side of a building and negative pressure on the leeward and sides of the building. Thus, the building shape and local wind patterns are crucial in creating the wind pressures that will drive air flow through its apertures. In practical terms wind pressure will vary considerably creating complex air flows and turbulence by its interaction with elements of the natural environment (trees, hills) and urban context (buildings, structures). Vernacular and traditional buildings in different climatic regions rely heavily upon natural ventilation for maintaining thermal comfort conditions in the enclosed spaces. \n\nDesign guidelines are offered in building regulations and other related literature and include a variety of recommendations on many specific areas such as:\n\nThe following design guidelines are selected from the Whole Building Design Guide, a program of the National Institute of Building Sciences:\n\nWind driven ventilation can be classified as cross ventilation and single-sided ventilation. Wind driven ventilation depends on wind behavior, on the interactions with the building envelope and on openings or other air exchange devices such as inlets or chimneys. For a simple volume with two openings, the cross wind flow rate can be calculated using the following equation:\n\nformula_2\n\nwhere formula_3 is the far-field wind speed; formula_4 is a local pressure drag coefficient for the building, defined at the location of the upstream opening; formula_5 is a local pressure drag coefficient for the building, defined at the location of the downstream opening; formula_6 is the cross-sectional area of the upstream opening; formula_7 is the cross-sectional area of the downstream opening; formula_8 is the discharge coefficient of the upstream opening; and formula_9 is the discharge coefficient of the downstream opening.\n\nFor rooms with single opening, the calculation of ventilation rate is more complicated than cross-ventilation due to the bi-directional flow and strong turbulent effect. The ventilation rate for single-sided ventilation can be accurately predicted by combining different models for mean flow, pulsating flow and eddy penetration.\n\nThe mean flow rate for single-sided ventilation is determined by\n\nformula_10\n\nwhere\n\n\"l\" = width of the window;\n\n\"h\" = elevation of the top edge of the window;\n\n\"z\" = elevation of neural level (where inside and outside pressure balance);\n\n\"z\" = reference elevation where the wind velocity is measured (at 10 m) and\n\nformula_11 = mean wind velocity at the reference elevation.\n\nThe knowledge of the urban climatology i.e. the wind around the buildings is crucial when evaluating the air quality and thermal comfort inside buildings as air and heat exchange depends on the wind pressure on facades. As we can see in the equation (1), the air exchange depends linearly on the wind speed in the urban place where the architectural project will be built. CFD (Computational Fluid Dynamics) tools and zonal modelings are usually used to design naturally ventilated buildings. Windcatchers are able to aid wind driven ventilation by directing air in and out of buildings.\n\nSome of the important limitations of wind driven ventilation:\n\nBuoyancy driven ventilation arise due to differences in density of interior and exterior air, which in large part arises from differences in temperature. When there is a temperature difference between two adjoining volumes of air the warmer air will have lower density and be more buoyant thus will rise above the cold air creating an upward air stream. Forced upflow buoyancy driven ventilation in a building takes place in a traditional fireplace. Passive stack ventilators are common in most bathrooms and other type of spaces without direct access to the outdoors.\n\n\nLimitations of buoyancy-driven ventilation:\n\nNatural ventilation in buildings can rely mostly on wind pressure differences in windy conditions, but buoyancy effects can a) augment this type of ventilation and b) ensure air flow rates during still days. Buoyancy-driven ventilation can be implemented in ways that air inflow in the building does not rely solely on wind direction. In this respect, it may provide improved air quality in some types of polluted environments such as cities. For example, air can be drawn through the backside or courtyards of buildings avoiding the direct pollution and noise of the street facade. Wind can augment the buoyancy effect, but can also reduce its effect depending on its speed, direction and the design of air inlets and outlets. Therefore, prevailing winds must be taken into account when designing for stack effect ventilation.\n\nThe natural ventilation flow rate for buoyancy-driven natural ventilation with vents at two different heights can be estimated with this equation:\n\nOne way to measure the performance of a naturally ventilated space is to measure the air changes per hour in an interior space. In order for ventilation to be effective, there must be exchange between outdoor air and room air. A common method for measuring ventilation effectiveness is to use a tracer gas. The first step is to close all windows, doors, and openings in the space. Then a tracer gas is added to the air. The reference, American Society for Testing and Materials (ASTM) Standard E741: Standard Test Method for Determining Air Change in a Single Zone by Means of a Tracer Gas Dilution, describes which tracer gases can be used for this kind of testing and provides information about the chemical properties, health impacts, and ease of detection. Once the tracer gas has been added, mixing fans can be used to distribute the tracer gas as uniformly as possible throughout the space. To do a decay test, the concentration of the tracer gas is first measured when the concentration of the tracer gas is constant. Windows and doors are then opened and the concentration of the tracer gas in the space is measured at regular time intervals to determine the decay rate of the tracer gas. The airflow can be deduced by looking at the change in concentration of the tracer gas over time. For further details on this test method, refer to ASTM Standard E741.\n\nWhile natural ventilation eliminates electrical energy consumed by fans, overall energy consumption of natural ventilation systems is often higher than that of modern mechanical ventilation systems featuring heat recovery. Typical modern mechanical ventilation systems use as little as 2000 J/m3 for fan operation, and in cold weather they can recover much more energy than this in the form of heat transferred from waste exhaust air to fresh supply air using recuperators.\n\nVentilation heat loss can be calculated as: theta=Cp*rho*dT*(1-eta).\n\nWhere:\n\nTheta is ventilation heat loss in W\n\nCp is specific heat capacity of air (~1000 J/(kg*K))\n\nRho is air density (~1.2 kg/m3)\n\ndT is the temperature difference between inside and outside air in °K or °C\n\nEta is the heat recovery efficiency - (typically around 0.8 with heat recovery and 0 if no heat recovery device is used).\n\nThe temperature differential needed between indoor and outdoor air for mechanical ventilation with heat recovery to outperform natural ventilation in terms of overall energy efficiency can therefore be calculated as:\n\ndT=SFP/(Cp*Rho*(1-eta))\n\nWhere:\n\nSFP is specific fan power in Pa, J/m^3, or W/(m^3/s)\n\nUnder typical comfort ventilation conditions with a heat recovery efficiency of 80% and a SFP of 2000 J/m3 we get:\n\ndT=2000/(1000*1.2*(1-0.8))=8.33 K\n\nIn climates where the mean absolute difference between inside and outside temperatures exceeds ~10K the energy conservation argument for choosing natural over mechanical ventilation might therefore be questioned. It should however be noted that heating energy might be cheaper and more environmentally friendly than electricity. This is especially the case in areas where district heating is available.\n\nTo develop natural ventilation systems with heat recovery two inherent challenges must first be solved:\n\n\nResearch aiming at the development of natural ventilation systems featuring heat recovery have been made as early as 1993 where Shultz et al proposed and tested a chimney type design relying on stack effect while recovering heat using a large counterflow recuperator constructed from corrugated galvanized iron. Both supply and exhaust happened through an unconditioned attic space, with exhaust air being extracted at ceiling height and air being supplied at floor level through a vertical duct.\n\nThe device was found to provide sufficient ventilation air flow for a single family home and heat recovery with an efficiency around 40%. The device was however found to be too large and heavy to be practical, and the heat recovery efficiency too low to be competitive with mechanical systems of the time.\n\nLater attempts have primarily focused on wind as the main driving force due to its higher pressure potential. This however introduces an issue of there being large fluctuations in driving pressure.\n\nWith the use of wind towers placed on the roof of ventilated spaces, supply and exhaust can be placed close to each other on opposing sides of the small towers. These systems often feature finned heat pipes although this limits the theoretical maximum heat recovery efficiency.\n\nLiquid coupled run around loops have also been tested to achieve indirect thermal connection between exhaust and supply air. While these tests have been somewhat successful, liquid coupling introduces mechanical pumps that consume energy to circulate the working fluid.\n\nWhile some commercially available solutions have been available for years, the claimed performance by manufacturers has yet to be verified by independent scientific studies. This might explain the apparent lack of market impact of these commercially available products claiming to deliver natural ventilation and high heat recovery efficiencies.\n\nA radically new approach to natural ventilation with heat recovery is currently being developed at Aarhus University, where heat exchange tubes are integrated into structural concrete slabs between building floors.\n\nWhile some commercially available solutions have been available for years, the claimed performance by manufacturers has yet to be verified by independent scientific studies. This might explain the apparent lack of market impact of these commercially available products claiming to deliver natural ventilation and high heat recovery efficiencies.\n\nFor standards relating to ventilation rates, in the United States refer to ASHRAE Standard 62.1-2010: Ventilation for Acceptable Indoor Air Quality. These requirements are for \"all spaces intended for human occupancy except those within single-family houses, multifamily structures of three stories or fewer above grade, vehicles, and aircraft.\" In the revision to the standard in 2010, Section 6.4 was modified to specify that most buildings designed to have systems to naturally condition spaces must also \"include a mechanical ventilation system designed to meet the Ventilation Rate or IAQ procedures [in ASHRAE 62.1-2010]. The mechanical system is to be used when windows are closed due to extreme outdoor temperatures noise and security concerns\". The standard states that two exceptions in which naturally conditioned buildings do not require mechanical systems are when:\n\nAlso, an authority having jurisdiction may allow for the design of conditioning system that does not have a mechanical system but relies only on natural systems. In reference for how controls of conditioning systems should be designed, the standard states that they must take into consideration measures to \"properly coordinate operation of the natural and mechanical ventilation systems.\"\n\nAnother reference is ASHRAE Standard 62.2-2010: Ventilation and Acceptable Indoor Air Quality in low-rise Residential Buildings. These requirements are for \"single-family houses and multifamily structures of three stories or fewer above grade, including manufactured and modular houses,\" but is not applicable \"to transient housing such as hotels, motels, nursing homes, dormitories, or jails.\"\n\nFor standards relating to ventilation rates, in the United States refer to ASHRAE Standard 55-2010: Thermal Environmental Conditions for Human Occupancy. Throughout its revisions, its scope has been consistent with its currently articulated purpose, “to specify the combinations of indoor thermal environmental factors and personal factors that will produce thermal environmental conditions acceptable to a majority of the occupants within the space.” The standard was revised in 2004 after field study results from the ASHRAE research project, RP-884: developing an adaptive model of thermal comfort and preference, indicated that there are differences between naturally and mechanically conditioned spaces with regards to occupant thermal response, change in clothing, availability of control, and shifts in occupant expectations. The addition to the standard, 5.3: Optional Method For Determining Acceptable Thermal Conditions in Naturally Ventilated Spaces, uses an adaptive thermal comfort approach for naturally conditioned buildings by specifying acceptable operative temperature ranges for naturally conditioned spaces. As a result, the design of natural ventilation systems became more feasible, which was acknowledged by ASHRAE as a way to further sustainable, energy efficient, and occupant-friendly design.\n\nUniversity-based research centers that currently conduct natural ventilation research:\nNatural Ventilation Guidelines:\n"}
{"id": "58298982", "url": "https://en.wikipedia.org/wiki?curid=58298982", "title": "Nina Roscher", "text": "Nina Roscher\n\nNina Matheny Roscher (1938—2001) was an American chemist and advocate for women and minorities in science. She also researched the history of women in chemistry, publishing the book \"Women Chemists\" (1995). She served as professor and chair of the chemistry department at American University in Washington, D.C. She received the ACS Award for Encouraging Women into Careers in the Chemical Sciences (1996) and the Presidential Award for Excellence in Science, Mathematics and Engineering Mentoring (1998).\n\nRoscher was born in 1938 in Uniontown, Pennsylvania and raised in Hershey, Pennsylvania. She received a B.S. in chemistry from the University of Delaware in 1960. She graduated from Purdue University with a doctorate in physical organic chemistry in 1964. While at Purdue, she founded the Iota Sigma Pi chapter of the Honor Society for Women in Chemistry.\n\nAfter graduating from Purdue in 1964, she taught at the University of Texas at Austin and Rutgers University, then joined the faculty of American University (AU) in Washington, D.C in 1974. At AU, she served in numerous administrative roles including associate dean for graduate affairs and research, vice provost for academic services, and dean for faculty affairs. She was active in the university senate, chaired a budget simplification task force, and served as the school's NCAA faculty representative. In 1991, she was appointed chair of AU's chemistry department, a position she held until her death in 2001.\n\nAt American University, she continued physical organic chemistry research, including research on sunscreens for Johnson and Johnson in the 1980s. Her primary focus was reactions of alcohols with silver and bromine salts, and she supervised numerous graduate students, more than half of whom were women.\n\nShe is better known for her administrative and advocacy work. She worked closely with her AU colleague, mathematician Mary Gray to improve resources for women and minorities in mathematics and science and prevent them from dropping classes. They created an apprenticeship program to help show first year female students an interdisciplinary, people-oriented perspective of scientists. The program, funded by a $95,000 grant from the NSF included a seminar course followed by a two-month apprenticeship working with a scientist engaged in science policy work.\n\nFrom 1976 to 1981, she administered a National Science Foundation (NSF)-funded reentry program to retrain women with degrees in chemistry or biology who had previously been discouraged from pursuing careers in those fields. The program involved a year of intensive coursework in chemistry or toxicology at American University for 75 women, with an average age of 40, some of whom had been out of school for 15 years. Five years after the program ended, of the 75 participants, nine had received a Ph.D. in chemistry, 25 had earned master's degrees, and eight were in graduate school. Later analysis showed the program had also succeeded in ensuring them job placement in diverse career paths.\n\nIn addition to her work at AU, she held a part-time position as program director of science education for the National Science Foundation (NSF) starting in 1986. At the NSF, she worked in the Instructional Laboratory Improvement Program, then became director of the Undergraduate Faculty Enhancement program in the Division of Undergraduate Science, Engineering, and Mathematics Education (USEME) in 1988.\n\nShe joined the American Chemical Society (ACS) in 1960 and was very active in the organization. She served on the ACS Women Chemists Committee from 1974 to 1979 (as chair 1976-1978) and was president of ACS' Washington, D.C. section (the Chemical Society of Washington) in 1995.\n\nShe was interested in the history of women in chemistry, and authored the book \"Women Chemists\" for the American Chemical Society in 1995. Much of her extensive research on female chemists is archived in the Archives of Women in Science and Engineering at Iowa State University; these \"Nina Matheny Roscher Papers\" are open for research and commonly cited.\n\nShe also looked to the present and future of women in chemistry, analyzing statistics on disparities in training, retention, and compensation of female scientists. She compiled a 1990 ACS survey evaluating salaries of members and women's perceptions and satisfaction with their employment situation and opportunities for advancement.\n\nRoscher's outside interests included landscaping and remodeling of a cabin she owned in Lost River, West Virginia. She died from breast cancer September 19, 2001 at Georgetown University Hospital at the age of 62.\n\nIn 1996 she received the ACS Award for Encouraging Women into Careers in the Chemical Sciences.\n\nIn 1998, she received the Presidential Award for Excellence in Science, Mathematics and Engineering Mentoring, a yearly award administered by the National Science Foundation (NSF) which recognizes up to ten \"outstanding individual efforts and organizational programs designed to increase the participation of underrepresented groups in mathematics, engineering, and science in kindergarten-12th grade and through the graduate level\". She was one of six chemists to receive the $10,000 grant award that year, which was presented by President Bill Clinton at a White House ceremony.\n\n\n\n<nowiki>*</nowiki> Nina Matheny Roscher Papers http://findingaids.lib.iastate.edu/spcl/manuscripts/MS578.html\n"}
{"id": "502152", "url": "https://en.wikipedia.org/wiki?curid=502152", "title": "Phragmites", "text": "Phragmites\n\nPhragmites is a genus of four species of large perennial grasses found in wetlands throughout temperate and tropical regions of the world. The World Checklist of Selected Plant Families, maintained by Kew Garden in London, accepts the following four species:\n\nThe cosmopolitan common reed has the generally accepted botanical name \"Phragmites australis\". About 130 other synonyms have been proposed, and some have been widely used. Examples include \"Phragmites communis\" , \"Arundo phragmites\" , and \"Phragmites vulgaris\" (illegitimate name).\n\nRecent studies have characterised morphological distinctions between the introduced and native stands of \"Phragmites australis\" in North America. The Eurasian phenotype can be distinguished from the North American phenotype by its shorter ligules of up to as opposed to over , shorter glumes of under against over (although there is some overlap in this character), and in culm characteristics.\n\n\nIn North America, the status of \"Phragmites australis\" was a source of confusion and debate. It was commonly considered an exotic species and often invasive species, introduced from Europe. However, there is evidence of the existence of \"Phragmites\" as a native plant in North America long before European colonization of the continent. It is now known that the North American native forms of \"P. a.\" subsp. \"americanus\" are markedly less vigorous than European forms. The recent marked expansion of \"Phragmites\" in North America may be due to the more vigorous, but similar-looking European subsp. \"australis\".\n\n\"Phragmites\" outcompetes native vegetation and lowers the local plant biodiversity. \"Phragmites\" forms dense thickets of vegetation that is unsuitable habitat for native fauna. \"Phragmites\" displaces native plants species such as wild rice, cattails, and native wetland orchids. \"Phragmites\" has a high above ground biomass that blocks light to other plants allowing areas to turn into \"Phragmites\" monoculture very quickly. Decomposing \"Phragmites\" increases the rate of marsh accretion more rapidly than would occur with native marsh vegetation.\n\n\"Phragmites australis\" subsp. \"australis\" is causing serious problems for many other North American hydrophyte wetland plants, including the native \"Phragmites australis\" subsp. \"americanus\". Gallic acid released by Phragmites is degraded by ultraviolet light to produce mesoxalic acid, effectively hitting susceptible plants and seedlings with two harmful toxins. \"Phragmites\" is so difficult to control that one of the most effective methods of eradicating the plant is to burn it over 2-3 seasons. The roots grow so deep and strong that one burn is not enough. Ongoing research suggests that goats could be effectively used to control the species.\n\nSince 2017, over 80% of the beds of \"Phragmites\" in the Pass a Loutre Wildlife Management Area have been damaged by the invasive \"roseau cane scale\", \"Nipponaclerda biwakoensis\", threatening wildlife habitat throughout the affected regions of the WMA. While typically considered a noxious weed, in Louisiana the reed beds are considered critical to the stability of the shorelines of wetland areas and waterways of the Mississippi Delta, and the die-off of reed beds is believed to accelerate coastal erosion.\n\n\"Phragmites australis\", common reed, commonly forms extensive stands (known as reed beds), which may be as much as or more in extent. Where conditions are suitable it can also spread at or more per year by horizontal runners, which put down roots at regular intervals. It can grow in damp ground, in standing water up to or so deep, or even as a floating mat. The erect stems grow to tall, with the tallest plants growing in areas with hot summers and fertile growing conditions.\n\nThe leaves are long for a grass, and broad. The flowers are produced in late summer in a dense, dark purple panicle, about 20–50 cm long. Later the numerous long, narrow, sharp pointed spikelets appear greyer due to the growth of long, silky hairs. These eventually help disperse the minute seeds.\n\nIt is a helophyte, especially common in alkaline habitats, and it also tolerates brackish water, and so is often found at the upper edges of estuaries and on other wetlands (such as grazing marsh) which are occasionally inundated by the sea. A study demonstrated that \"Phragmites australis\" has similar greenhouse gas emissions to native \"Spartina alterniflora\". However, other studies have demonstrated that it is associated with larger methane emissions and greater carbon dioxide uptake than native New England salt marsh vegetation that occurs at higher marsh elevations. \n\nCommon reed is suppressed where it is grazed regularly by livestock. Under these conditions it either grows as small shoots within the grassland sward, or it disappears altogether.\n\nIn Europe, common reed is rarely invasive, except in damp grasslands where traditional grazing has been abandoned.\n\nCommon reed is very important (together with other reed-like plants) for wildlife and conservation, particularly in Europe and Asia, where several species of birds are strongly tied to large \"Phragmites\" stands. These include:\nIn Australia, reedbeds provide cover for grassbirds (\"Megalurus spp\"), reed warblers (\"Acrocephalus spp\"), crakes (\"Porzana spp\") and bitterns (\"Ixobrychus spp\") and the Australian bittern (\"Botaurus poiciloptilus\").\n\n\"P. australis\" is cultivated as an ornamental plant in aquatic and marginal settings such as pond- and lakesides. Its aggressive colonisation means it must be sited with care.\n\n\"Phragmites australis\" is one of the main wetland plant species used for phytoremediation water treatment.\n\nWaste water from lavatories and greywater from kitchens is routed to an underground septic tank-like compartment where the solid waste is allowed to settle out. The water then trickles through a constructed wetland or \"artificial reed bed\", where bioremediation bacterial action on the surface of roots and leaf litter removes some of the nutrients in biotransformation. The water is then suitable for irrigation, groundwater recharge, or release to natural watercourses.\n\nReed is used in many areas for thatching roofs. In the British Isles, common reed used for this purpose is known as \"Norfolk reed\" or \"water reed\". However \"wheat reed\" and \"Devon reed\", also used for thatching, are not in fact reed, but long-stemmed wheat straw.\n\nIn Middle East countries \"Phragmites\" is used to create a small instrument similar to the clarinet called a sipsi, with either a single, as in the picture, or double pipes as in bagpipes. The reed of the zurna is made from the common reed which is flattened after removing its brittle outer glaze and the loose inner membrane, and after softening it by wetting. The result is a double reed with an elliptical opening that vibrates by closing and opening at a high speed. This is not to be confused with other double reeds like that of the oboe which uses two reeds made from the giant reed leaning against each other.\n\nNumerous parts of \"Phragmites\" can be prepared for consumption. For example, the young stems \"while still green and fleshy, can be dried and pounded into a fine powder, which when moistened is roasted [sic] like marshmallows.\" Also, the wheat-like seeds on the apex of the stems \"can be ground into flour or made into gruel.\" Rootstocks are used similarly.\n\nSome other uses for \"Phragmites australis\" and other reeds in various cultures include baskets, mats, pen tips, and a rough form of paper. Additionally, the reeds are used as nesting tubes by individuals keeping solitary bees such as mason bees.\n\nIn Egypt, the longer stems are dried and used as fishing poles. It is also used there for fences and cattle pens.\n\nIn the Philippines, \"Phragmites\" is known by the local name \"tambo\". Reed stands flower in December, and the blooms are harvested and bundled into brooms called \"walis\". Hence the common name of household brooms is \"walis tambo\".\n\nReeds have been used to make arrows and weapons such as spears for hunting game.\n\nIn Romania it is used to produce paper.\n\nWhen Midas had his ears transformed into donkey's ears, he concealed the fact and his barber was sworn to secrecy. However the barber could not contain himself and rather than confiding in another human, he spoke the secret into a hole in the ground. The reeds that grew in that place then repeated the secret in whispers.\n\nMoses was \"drawn out of the water where his mother had placed him in a reed basket to save him from the death that had been decreed by the Pharaoh against the firstborn of all of the children of Israel in Egypt\" (Exodus 2:10). However, the plant concerned may have been another reed-like plant, such as papyrus, which is still used for making boats.\n\nOne reference to reeds in European literature is Frenchman Blaise Pascal's saying that Man is but a 'thinking reed' — \"roseau pensant\". In Jean de La Fontaine's famous fable \"The Oak and the Reed\" — \"Le chêne et le roseau\", the reed tells the proud oak: \"I bend, and break not\" —\"Je plie, et ne romps pas\", \"before the tree's fall.\"\n\n\n"}
{"id": "38322873", "url": "https://en.wikipedia.org/wiki?curid=38322873", "title": "Plants for Human Health Institute", "text": "Plants for Human Health Institute\n\nThe Plants for Human Health Institute (PHHI) is a North Carolina State University research and education organization located at the North Carolina Research Campus in Kannapolis, North Carolina, United States. The institute researches food crops, like fruits and vegetables, and the potential health-promoting properties they may convey when consumed.\n\nPHHI is part of the North Carolina State University College of Agriculture and Life Sciences, which staffs the institute with faculty from the departments of horticultural science; food, bioprocessing and nutrition sciences; plant and microbial biology; genetics; and agricultural and resource economics. The institute has both research and Cooperative Extension components. Mary Ann Lila, a blueberry researcher, is director of the Plants for Human Health Institute.\n\nN.C. State began operations in Kannapolis in 2007 as the Fruit and Vegetable Science Institute. The university was one of the first organizations to join the biotech hub.\n\nThe program's name was changed to Plants for Human Health Institute when the N.C. Research Campus was dedicated on October 20, 2008, in order \"to more accurately reflect the groundbreaking research approach the institute will take. Institute research will focus on identifying and making available to consumers bioactive compounds in plants that prevent and treat disease.\"\n\nAs of May 2014, PHHI has about 50 faculty and staff in Kannapolis, not including seasonal staff.\n\nPlants for Human Health Institute researchers study the potential health-promoting properties of fruits and vegetables. The institute employs six lead researchers and has plans to expand to 14 researchers.\n\nThe institutes mission is to discover and deliver plant-based solutions to improve human health, PHHI researchers target naturally occurring chemical compounds in plants and fresh produce, known as phytochemicals, some of which convey health-promoting properties when ingested. Institute director, Lila, and other PHHI researchers have done research into phytochemicals, such as anthocyanins present in blueberries and other crops, indicating they provide health benefits against cancer, diabetes and other chronic human diseases when consumed.\n\nIn 2013, Lila was a lead researcher in a study involving athletes ingesting blueberry and green tea-infused drinks twice daily during a two-week supplementation period and then for three days of rigorous exercise. Among the results, participants experienced a prolonged spike in their metabolism (up to 14 hours) after exercise.\n\nPlants for Human Health Institute researchers integrate expertise in biochemistry, plant breeding, epigenetics, metabolomics, pharmacogenomics, postharvest physiology and systems biology. PHHI research faculty have: \n\nThe institute operates three greenhouses. At a cost of $340,000 the greenhouse complex provides about 10,000 square feet of space for plant trials on crops like broccoli and strawberry, and allow the institute to rent space or collaborate on research with other campus operations and businesses.\n\nResearchers also partner with the Piedmont Research Station, a research farm located near Salisbury, N.C., to grow and test field crops.\n\nFunded by a $1 million U.S. Department of Agriculture – Agriculture & Food Research Initiative (USDA-AFRI) the Kannapolis Scholars is a program for graduate students from multiple disciplines to participate in integrated research. Led by Jack Odle, William Neal Reynolds, Professor of Nutritional Biochemistry at N.C. State, the examines issuesin the broad domain of functional foods, bioactive food components and human health. 30 faculty members from eight universities in North Carolina act from multiple disciplines, including food science, nutritional science, plant science, animal science, microbiology, biochemistry and metabolomics as mentors to the Kannapolis Scholars. Some are resident at the N.C. Research Campus while others are at the associated university campuses.\n\nThe Plant Pathways Elucidation Project, or P2EP, is a $1.9 million program that engaging college students from across North Carolina in education and research. Started in June 2013, the program is supported by a consortium of academic and industry organizations, including the Plants for Human Health Institute. The program teams university scientists, industry leaders and college students to explore plant health benefits, prepare student scientists to pursue careers in STEM fields (Science, Technology, Engineering and Math), and create a research knowledge base.\n\nThe 2014 P2EP summer session includes doctoral candidates and graduate and undergraduate interns from 12 colleges and universities and two high schools in Cabarrus County.\n\nThe N.C. Cooperative Extension Service houses a multidisciplinary team at the N.C. Research Campus as part of the Plants for Human Health Institute. The team is an education and outreach component directed toward farm and agribusiness management, communications and marketing, and fresh produce safety.\n\nIn addition to and in partnership with PHHI research programs, the Cooperative Extension group coordinates educational and outreach efforts, secures grants and delivers practical applications of science-based research to strengthen the agriculture industry in North Carolina.\n\nThe N.C. Value-Added Cost Share Program (NCVACS), coordinated by the Cooperative Extension team at PHHI, provides assistance to agricultural operations in the form of cost share awards. The program has awarded more than $1 million to support agribusinesses in North Carolina since it began in 2009. The N.C. Tobacco Trust Fund Commission funds the program.\n\nThe N.C. Cooperative Extension component of PHHI is a cooperative development center for the state, supported by the U.S. Department of Agriculture Rural Development program, the group works with producer groups and cooperatives to expand economic activity.\n\nPHHI is home to the N.C. Fresh Produce Safety program, a program of the Cooperative Extension, established to educate fruit and vegetable growers about minimizing food safety risks. The program's training curriculum addresses Good Agricultural Practices (GAPs).\n\nBlake Brown, Hugh C. Kiger Professor in agricultural economics at N.C. State, started the Program for Value-Added and Alternative Agriculture in 2006 with support from the N.C. Tobacco Trust Fund Commission. The program was originally created to assist the transition of tobacco-farm families to other profitable enterprises after the Tobacco Buyout in 2005.\n\nAs part of N.C. State's development of the N.C. Research Campus, the program relocated to Kannapolis in 2008 as an on-site Cooperative Extension complement to the research personnel and programs with the institute. The program operated under the N.C. MarketReady brand from October 2009 until July 2012. The program has since dropped the name and been fully integrated into the institute as the N.C. Cooperative Extension component.\n\nThe N.C. Research Campus is a public-private venture including eight universities, one community college, the David H. Murdock Research Institute (DHMRI), the U.S. Department of Agriculture (USDA) and corporate entities that collaborate to advance the fields of human health, nutrition and agriculture. It was founded by David H. Murdock, CEO of Dole Foods. The campus is built upon the former site of the Cannon Textile Mill in Kannapolis, about 30 miles north of Charlotte.\n\nThe research campus represents an effort by the state of North Carolina to revitalize the region following the decline of the textile industry. The campus is supported mainly through annual funding from the state of North Carolina, federal research grants to university researchers located on the campus, and investment of real estate by Murdock, former owner of the Cannon textile mill that previously occupied the site.\n\nIt was announced in November 2013 that two new facilities were breaking ground at the Kannapolis campus, including a 50,000-square-foot data center (DataChambers) and a 100,000-square-foot municipal center (the new Kannapolis City Hall).\n\nThe Plants for Human Health Institute is housed on the campus in a 105,000-square-foot facility that includes research labs, lab support areas and an Advance II 700 US-2 Magnet nuclear magnetic resonance spectroscope.\n\nThe institute has received $2.1 million in gift donations and $7.8 million in federal and private competitive grants, $1.42 million from the N.C. Tobacco Trust Fund Commission, $2 million from the N.C. Department of Agriculture and Consumer Services and the U.S. Department of Agriculture, $780,000 from the University of North Carolina General Administration, and $1.05 million from commodity groups and other private sponsors. This funding is in addition to state appropriations. PHHI research programs have also received significant grant funding support from the Bill & Melinda Gates Foundation and the National Institutes of Health.\n\n"}
{"id": "47525563", "url": "https://en.wikipedia.org/wiki?curid=47525563", "title": "Production order", "text": "Production order\n\nA production order is an order issued within a company to produce a specific quantity of material within a certain timeframe. A production order may be issued pursuant to a sales order, and its issuance triggers a number of events. If components in the bill of materials are in stock, reservations are generated for those items; if they are not in stock, then requisition orders may be generated. Requisition orders may also be generated for production that occurs externally to the firm. Planned costs for the order are also generated and capacity requirements are generated for the work centers.\n"}
{"id": "35529218", "url": "https://en.wikipedia.org/wiki?curid=35529218", "title": "Promised Land (2012 film)", "text": "Promised Land (2012 film)\n\nPromised Land is a 2012 American drama film directed by Gus Van Sant and starring Matt Damon, John Krasinski, Frances McDormand, Rosemarie DeWitt and Hal Holbrook. The screenplay is written by Damon and Krasinski based on a story by Dave Eggers. \"Promised Land\" follows two corporate salespeople who visit a rural town in an attempt to buy drilling rights from the local residents.\n\nDamon was originally attached to direct the film, but he was replaced by Van Sant. Filming took place mainly in Pittsburgh from early to mid-2012. During filming and afterward, the film's highlighting of the resource extraction process hydraulic fracturing, known as \"fracking,\" emerged as a topic of debate.\n\nThe film had a limited release in the United States on , 2012 and followed with a nationwide expansion on , 2013. The film had its international premiere and received Special Mention Award at the 63rd Berlin International Film Festival in February 2013. It received mixed reviews from critics, although the National Board of Review named it one of the top ten films of 2012, and was a box office bomb, grossing just $8 million against a $15 million budget.\n\nSteve Butler has caught the eyes of top management at his employer, Global Crosspower Solutions, an energy company that specializes in obtaining natural gas trapped underground through a process known as fracking. Butler has an excellent track record for quickly and cheaply persuading land owners to sign mineral rights leases that grant drilling rights over to his employer. Butler and his partner Sue Thomason arrive in an economically struggling Pennsylvania farming town whose citizens are proud of having family farms passed from one generation to the next.\n\nComing from a town and a life very similar to that of the people he is now determined to win over on behalf of Global, Butler tells the story of how his own town died after the local Caterpillar assembly plant closed. The idea of a town surviving solely on family farms being passed down through generations as a viable economy is one that he can no longer accept. He claims to be offering the town its last chance. Butler spends some pleasant after-hours time with Alice, a teacher he meets in a bar.\n\nThe community seems willing to accept Global's offer, until an elderly, local high school science teacher, Frank Yates, who happened to be a successful engineer in his working life, raises the question of the safety of fracking during a town meeting. It's decided that the people will vote in a few weeks whether or not to take the offer. After hearing about the vote, Dustin Noble, an unknown environmental advocate, starts a grassroots campaign against Global, motivated by a tale of his family losing its Nebraska dairy farm after the herd died as a result of Global's industry-standard fracking process.\n\nButler begins to meet a great deal of resistance in town. Noble seems to be winning over nearly everyone, including Alice. One night Butler receives a package from Global that includes an enlarged copy of a photograph of dead cattle on a field that Noble said came from his family's Nebraska farm. The enlargement shows that an object thought to be a silo is,in fact, a lighthouse, which are nonexistent in Nebraska, revealing that Noble fabricated his story and deceived the people. Actually, the picture was from Lafayette, Louisiana, where Global is in the midst of a lawsuit over environmental complications that were probably caused by their fracking practices.\n\nButler informs the town's mayor of the deception, who then informs the rest of the town. He returns to the hotel to find Noble loading his truck, preparing to leave town. Noble accidentally reveals that he knows the picture with the lighthouse was taken in Lafayette. Butler realizes the only way Noble could have known this information is if he were also employed by Global, and that Noble's job had been to discredit the environmental movement and convince the town to vote in favor of Global's offer. He arranged for Butler to receive the \"confidential\" photos and engineered the entire public relations effort.\n\nAt a town meeting the next day, the citizens are prepared to vote on Global's efforts to buy drilling rights to their property. Butler talks to them about how the barn in the picture reminds him of his grandfather's barn. He reveals that Noble has manipulated them and is employed by Global. Butler leaves the meeting to find Thomason on the phone with Global. She tells him he's fired and that she is leaving for New York. Butler walks to Alice's home and she welcomes him in.\n\n\"Promised Land\" is directed by Gus Van Sant based on a screenplay by Matt Damon and John Krasinski, who are film producers along with Chris Moore. In interviews, Krasinski and Damon said that the idea for the movie was partially inspired by an investigative series of stories in The New York Times by Ian Urbina, called \"Drilling Down\", about fracking. The screenplay was based on a story by Dave Eggers. Krasinski came up with the film's premise and developed the idea with Eggers. They pitched the idea to Damon, suggesting that both Damon and Krasinski would write and star in the film. The project was set up at Warner Bros. with Damon attached as director in October 2011, in what would have been his directorial debut. Filming was scheduled to begin in early 2012.\n\nIn January 2012, Damon stepped down as director due to scheduling conflicts but remained involved with the project. Damon contacted Gus Van Sant, who directed him in the 1997 film \"Good Will Hunting\", and Van Sant joined the project as director. The project was in turnaround at Warner Bros., and by February, Focus Features and Participant Media acquired rights to produce the film. The title was announced to be \"Promised Land\". With a production budget of , filming began in Pennsylvania in late April 2012. The Commonwealth of Pennsylvania provided the production company in tax credits since filming would provide jobs and revenue. More than eighty percent of the crew were hired out of Pittsburgh. Filming mostly took place in Avonmore, Pennsylvania, which was the main setting for the film's rural town of McKinley. Additional filming locations for the town were locations in Armstrong County including Apollo, Worthington, and Slate Lick. Other filming locations in Pennsylvania were Alexandria, Delmont, Export, and West Mifflin. Filming also took place at the Grand Concourse at Station Square in Pittsburgh. Several hundred extras were hired for the film, and filming lasted for .\n\nThe movie was financed by Image Productions, a company owned by the Government of Abu Dhabi.\n\nThe film score was composed by Danny Elfman. Three songs by The Milk Carton Kids including Snake Eyes, The Ash & Clay and Jewel of June were also written for the film.\n\n\"Promised Land\" was criticized by the energy industry for its portrayal of the resource extraction process hydraulic fracturing, colloquially known as \"fracking\". The portrayal was first reported in April 2012 by filmmakers raising funds for the pro-fracking documentary \"FrackNation\". They said, \"\"Promised Land\" will increase unfounded concerns about fracking.\" Phelim McAleer, the director of \"FrackNation\", said Dimock, Pennsylvania was the likely inspiration for \"Promised Land\". McAleer said despite Dimock families' claims that fracking activity contaminated their water, the state and EPA scientists did not find anything wrong. In September 2012, CNBC reported that a group of residents from Armstrong County, Pennsylvania were protesting the film and formed a Facebook group. The group said, \"They filmed this movie in our backyard. They told us it would be fair to drilling. It’s not. We’re p*ssed [sic].\" Mike Knapp, one of the organizers of the Facebook group said, \"One of the things that really aggravates me, is that they seem to have a very condescending view\" of farmers as portrayed in the film.\n\nKrasinski, who co-wrote the screenplay and stars in \"Promised Land\", said the film's original premise involved wind power. Krasinski said wind power was replaced by fracking as a more relevant backdrop based on news coverage in recent years. \"The Huffington Post\" reported, \"The procedure has caused concern due in part to the chemicals injected into the wells for drilling, which may taint nearby drinking water.\" It said Damon had posted in 2010 a YouTube video to promote the Working Families Party, which works \"to prevent risky natural gas drilling\". \"Politico\" said \"Promised Land\" reflected a trend about fracking since the release of the 2010 documentary film \"Gasland\", which was nominated for an Academy Award for Best Documentary.\n\nLeading up to the film's release, a spokesperson for Independent Petroleum Association of America said, \"We have to address the concerns that are laid out in these types of films.\" The industry planned to send scientific studies to film critics, to distribute leaflets to film audiences, and to use social media like Facebook and Twitter as a response to the film. Where the industry launched \"direct attacks\" at \"Gasland\", it instead sought to portray \"Promised Land\" as \"derivative, condescending and cliched\". In Pennsylvania, the industry group Marcellus Shale Coalition bought a 16-second onscreen ad to be shown at 75 percent of theaters in the state at the same time \"Promised Land\" was released.\n\nJames Schamus, chief executive of the film's distributor Focus Features said, \"We've been surprised at the emergence of what looks like a concerted campaign targeting the film even before anyone's seen it.\" As the film was released, he said, \"Fracking is a great premise for real drama. It represents Americans deeply conflicted about how to deal with these issues.\" He compared the industry's stealth campaign against the film to the one depicted within the film.\n\nThe Heritage Foundation, a conservative think tank, reported that \"Promised Land\" was financed in part by Image Nation Abu Dhabi, a subsidiary of Abu Dhabi Media, which is wholly owned by the United Arab Emirates. The foundation said that the UAE, as a member of the Organization of Petroleum Exporting Countries (OPEC), has \"a direct financial interest... in slowing the development of America's natural gas industry\" and suggested that its financing of the film \"may have an impact on the public's view of the [fracking] practice\". Image Nation said it provided financing to the film as part of an ongoing partnership with Participant Media, \"regardless of genre or subject matter\".\n\n\"Promised Land\" had a limited release on , 2012, making it eligible for the 85th Academy Awards, but failed to win any. The film was released in and grossed an estimated $53,000 on its first day, a \"sobering\" average of $2,120. For the opening weekend, \"Promised Land\" grossed an estimated $190,000. Box Office Mojo reported before the film's wide release the following week, \"It's unlikely that it will be able to pull many people away from the various other appealing options in theaters right now.\" \"Promised Land\" expanded to on , 2013. It grossed over the weekend, which the \"Los Angeles Times\" judged as \"a bad start\" even with its budget. According to CinemaScore, audiences gave the film a \"B\" grade. The \"Times\" said the grade and \"middling reviews\" indicated the film was unlikely to be a success. By the end of its theatrical run, the film grossed $8.1 million, failing to make back its budget of $15 million.\n\nThe film had its international premiere at the 63rd Berlin International Film Festival in February 2013 where Gus Van Sant won a Special Mention.\n\n\"Promised Land\" received mixed reviews from critics.\" The Los Angeles Times\" reported that most critics felt that the film did not reach its full potential. On Rotten Tomatoes the film has an approval rating of 52%, based on 149 reviews, with an average rating of 5.9/10. The website's critical consensus reads, \"The earnest and well-intentioned \"Promised Land\" sports a likable cast, but it also suffers from oversimplified characterizations and a frustrating final act.\" Metacritic gave the film a weighted average score of 55 out of 100, based on 36 critics, indicating \"mixed or average reviews\".\n\n\"New York Times\" film critic A.O. Scott praised \"Promised Land\" as a film that \"works\" mainly \"by putting character ahead of story\" and by \"inviting the actors to be warm, funny and prickly\". Liam Lacey of \"The Globe and Mail\" is critical of the film: \"Apart from its warm, gentle tone, much about Promised Land simply isn’t good, especially the inconsistencies in the screenplay. After the mood-setting first half, things start to unravel.\"\n\n"}
{"id": "2211723", "url": "https://en.wikipedia.org/wiki?curid=2211723", "title": "Sampled data system", "text": "Sampled data system\n\nIn systems science, a sampled-data system is a control system in which a continuous-time plant is controlled with a digital device. Under periodic sampling, the sampled-data system is time-varying but also periodic; thus, it may be modeled by a simplified discrete-time system obtained by discretizing the plant. However, this discrete model does not capture the inter-sample behavior of the real system, which may be critical in a number of applications.\n\nThe analysis of sampled-data systems incorporating full-time information leads to challenging control problems with a rich mathematical structure. Many of these problems have only been solved recently.\n\n\n"}
{"id": "2167047", "url": "https://en.wikipedia.org/wiki?curid=2167047", "title": "Shell Eco-marathon", "text": "Shell Eco-marathon\n\nShell Eco-marathon is a world-wide energy efficiency competition sponsored by Shell. Participants build automotive vehicles to achieve the highest possible fuel efficiency. There are two vehicle classes within Shell Eco-marathon: Prototype and UrbanConcept. There are three energy categories within Shell Eco-marathon: battery-electric, hydrogen fuel cell, and internal combustion engine (gasoline, diesel, or ethanol). Prizes are awarded separately for each vehicle class and energy category. The pinnacle of the competition is the Shell Eco-marathon Drivers' World Championship, where the most energy efficient UrbanConcept vehicles compete in a race with a limited amount of energy.\n\nShell Eco-marathon competitions are held around the world with nine events as of 2018. The 2018 competition season includes events held in Singapore, California (US), Paris (France), London (UK), Istanbul (Turkey), Johannesburg (South Africa), Rio de Janeiro (Brasil), India (TBD), and China (TBD). Participants are students from various academic backgrounds including university teams such as past finalists Duke University, University of Toronto, University of Michigan, and University of California, Los Angeles.\n\nIn 2018, over 5,000 students from over 700 universities in 52 countries participated in Shell Eco-marathon. The digital reach of Shell Eco-marathon is estimated to be several million. \n\nIn 1939, a group of Shell scientists based in a research laboratory in Wood River, Illinois, USA, had a friendly bet to see who could drive their own car furthest on one gallon of fuel. The winner managed a fuel economy of . A repeat of the challenge yielded dramatically improved results over the years:\n\nA world record was set by a French team in 2003 called Microjoule with a performance of . The current record is , set in 2005 by the PAC-Car II. The world record in diesel efficiency was achieved by a team from the Universitat Politècnica de Valencia (Politechnical University of Valencia, Spain) in 2010 with 1396.8 kilometres per litre. In contrast, the most efficient production diesel passenger cars achieve , and some high-powered sports cars achieve as little as .\n\nThe current European Shell Eco-marathon record for a combustion engine entry was set in 2004 by the team from Lycée La Joliverie (France) at 3,410 km on the equivalent of a single litre of fuel. Prototype vehicles using fuel cells are capable of greater energy efficiency. In 2005, a hydrogen-powered vehicle built by Swiss team ETH Zurich achieved a projected 3,836 km on the equivalent of a single litre of fuel. This is equivalent to the distance between Paris and Moscow. In 2013, ethanol efficiency world record was set by Toulouse Ingenerie Multidisciplinarie with 3100 km of a single litre of ethanol. This is equivalent to the distance between Toulouse and Istanbul.\n\nThe Eco-Marathon has different classes of competition according to the energy source used: Fuel cells, solar cells, gasoline, diesel fuel and LPG. During the competition, cars must attain an average speed of at least 15 mph (23 km/h) over a distance of 10 miles (16 km). The course is typically a motor racing track or closed off city streets. The fuel is strictly measured out for each entrant at the start and end of the course. The difference is used to calculate the vehicle's average fuel consumption. Solar-powered vehicles are not eligible for the grand prize for fuel efficiency.\n\nIn 2017, more than 100 student teams from many countries across the Americas competed in the Shell-Eco Marathon Americas to a crowd of over 20,000 throughout the competitions at the Cobo Center in Detroit, Michigan.\n\nThe top performing vehicles are purpose designed for high efficiency. Some vehicles use a coast and burn technique whereby they briefly accelerate from 10 to 20 mph (from 16 to 32 km/h) and then switch the engine off and coast until the speed drops back down to 10 mph (16 km/h). This process is repeated resulting in average speed of 15 mph for the course. Typically the vehicles have:\n\nThe vehicles are highly specialized and optimized for the event and are not intended for everyday use. The designs represent what can be achieved with current technology and offer a glimpse into the future of car design based on minimal environmental impact in a world with reduced oil reserves. The work of the participants can be used to show ways manufacturers could redesign their products.\n\n"}
{"id": "55167937", "url": "https://en.wikipedia.org/wiki?curid=55167937", "title": "Ship Shore Ship Buffer", "text": "Ship Shore Ship Buffer\n\nThe Ship-Shore-Ship Buffer (SSSB) is a real-time data link buffer system supporting data exchange between naval forces, including airborne assets, and their associated air defence ground environment units.\n"}
{"id": "970663", "url": "https://en.wikipedia.org/wiki?curid=970663", "title": "Silicon Alley", "text": "Silicon Alley\n\nSilicon Alley, centered around the Flatiron district in Manhattan, is an area of high tech industries. The term was coined in the 1990s during the dot-com boom, as a reference to <nowiki>\"Silicon Valley\", the tech center in California. As the New York tech industries began a revival around 2003, the businesses spread outside of Manhattan making the term 'Silicon Alley'</nowiki> somewhat obsolete. \n\n, New York City hosted 300,000 employees in the tech sector. In 2015, New York generated over US$7.3 billion in venture capital investment. High technology startup companies and employment are growing in New York City and across the metropolitan region, bolstered by the city's emergence as a global node of creativity and entrepreneurship, social tolerance, and environmental sustainability, as well as New York's position as the leading Internet hub and telecommunications center in North America, including its vicinity to several transatlantic fiber optic trunk lines, the city's intellectual capital, and its extensive outdoor wireless connectivity.\n\nThe term \"Silicon Alley\" was derived from the long established Silicon Valley in California. It was originally centered in the Flatiron District, in the vicinity of the Flatiron Building at Fifth Avenue near Broadway and 23rd Street, straddling Midtown and Lower Manhattan. Silicon Alley initially also used to extend to Dumbo, a neighborhood in Brooklyn. Columbia University and NYU's leaderships were especially important in the alley's early development. \n\nThe term Silicon Alley may have originated in 1995 by a New York staffing recruiter, Jason Denmark, who was supporting clients in the newly dubbed technical hub in downtown Manhattan; in an effort to attract candidates who, at that time, were focusing on positions in Silicon Valley, he posted in public usenet postings of Object Technology Developers, job ads with the Silicon Alley label. \"Subject: NYC - silicon ALLEY\" shows up in an internet post by Jason Denmark on February 16, 1995; another Jason Denmark post on June 16, 1995, is \"Subject: SILICON 'ALLEY' POSITIONS.\"\n\nThe first publication to cover Silicon Alley was @NY, an online newsletter founded in the summer of 1995 by Tom Watson and Jason Chervokas. The first magazine to focus on venture capital opportunities in Silicon Alley, AlleyCat News co-founded by Anna Copeland Wheatley and Janet Stites, was launched in the fall of 1996. Courtney Pulitzer branched off from her @The Scene column with @NY and created Courtney Pulitzer's Cyber Scene and her popular networking events Cocktails with Courtney. First Tuesday, co-founded by Vincent Grimaldi de Puget and John Grossbart, became the largest gathering of Silicon Alley, welcoming 500 to 1000 venture capitalists and entrepreneurs every month. It was an initiative of law firm Sonnenschein and the Kellogg School of Management, as well as other corporate founders, including Accenture (then Andersen Consulting), AlleyCat News and Merrill Lynch. Silicon Alley Reporter started publishing in October 1996. It was founded by Jason Calacanis and was in business from 1996 to 2001. @NY, print magazines, and the attending media coverage by the larger New York press helped to popularize both the name, and the idea of New York City as a dot-com center.\n\nIn 1997, over 200 members and leaders of Silicon Alley joined NYC entrepreneurs, Andrew Rasiej and Cecilia Pagkalinawan to help wire Washington Irving High School to the Internet. This response and the Department of Education's growing need for technology integration marked the birth of Making Opportunities for Upgrading Schools and Education (MOUSE), an organization that today serves tens of thousands of underserved youth in schools in five states and over 20 countries.\n\nThe rapid growth of internet companies during the 1990s, known as the Dot-com bubble, came to a rapid halt during the early 2000s recession. During this economic contraction, many internet companies in Silicon Alley folded. The recession also affected publications that covered the sector. After the dot-com bust, the \"Silicon Alley Reporter\" was rebranded as \"Venture Reporter\", in September 2001, and sold to Dow Jones. Self-financed AlleyCat News ceased publication in October 2001.\n\nA couple of years after the dot-com bust, Silicon Alley began making its comeback with the help of NY Tech Meetup, and NextNY. On December 19, 2011, then Mayor Michael R. Bloomberg announced his choice of Cornell University and Technion-Israel Institute of Technology to build a US$2 billion graduate school of applied sciences on Roosevelt Island, with the goal of transforming New York City into the world's premier technology capital. As of 2013, Google's second largest office is located in New York. Verizon Communications, headquartered at 140 West Street in Lower Manhattan, was in 2014 in the final stages of completing a US$3 billion fiberoptic telecommunications upgrade throughout New York City.\n\nThis revival was not restricted to Lower Manhattan, but was spread throughout New York City. Hence \"Silicon Alley\" has been considered by some observers to be an obsolete term.\n\n"}
{"id": "49715097", "url": "https://en.wikipedia.org/wiki?curid=49715097", "title": "Silicon Markets", "text": "Silicon Markets\n\nSilicon Markets is a Fintech brokerage firm which focuses on technology that offers institutional-level tools for retail traders. Silicon Markets is based in Level 39 tech accelerator, Canary Wharf, London, England, and is an appointed representative of C B Financial Services, who are regulated by the Financial Conduct Authority.\n\nSilicon Markets was founded on 12 May 2015.\n\nThe founders of Silicon Markets include Premiership footballer Ryan Bertrand, Louis Bell and Matthew Kirkham. Silicon Markets received widespread press coverage in May 2016 when its founders launched another venture Footiemoji with Ryan's former teammate John Terry. Newspapers and publications such as City AM, the Sun and Business Wire covered the story of Bertrand's finance ventures and his explanation of his motivations for starting the company as \"I kind of wanted to go against the grain, the traditional footballer who reaches perhaps mid-30s, stops and then thinks 'what am I going to do now?'\".\n"}
{"id": "53726964", "url": "https://en.wikipedia.org/wiki?curid=53726964", "title": "Smarsh", "text": "Smarsh\n\nSmarsh is a multinational \"software as a service\" (SaaS) company headquartered in Portland, Oregon, with offices in New York, Boston, Raleigh, North Carolina and London. The company provides comprehensive archiving and has compliance, supervision and e-discovery solutions for companies in highly regulated industries, including public sector and financial services.\n\nThe company was founded in Brooklyn, New York in 2001. The founder, Stephen Marsh, believed that the financial industry needed a better way to archive, store, and regulate its data as regulations required. In 2004, the company relocated its headquarters to Portland, Oregon.\n\nIn 2012, Quest Software, which owned 60% of Smarsh, was sold to Dell Computer. In 2013, Dell sold its stake to California investment firm Toba Capital.\n\nIn 2015, the company used its social media archiving tools to assist with a study on the use of social media by adolescents. Smarsh was contracted by CNN to host a secure server where social media use by participating students was monitored and analyzed. The Anderson Cooper 360° special report, \"#Being13: Inside the Secret World of Teens\", was released in October 2015, and won an Emmy Award in the News and Documentary category.\n\nSmarsh has acquired a number of companies since its start in 2001. In 2008, it acquired the Connecticut-based CentraScan LLC, an email management service, and the California-based Financial Visions Inc., a website compliance company. In early 2012, the company acquired Perpetually, known for its web archiving technology. Smarsh acquired Presensoft, a cloud-based instant message archiving company, in 2015, and in December 2016, it acquired MobileGuard, a mobile communication monitoring and retention solutions provider.\n\nSmarsh has been named to the Inc. 5000 list of fastest growing private companies in America consecutively from 2008 through 2015. The company also made the Deloitte Fast 500 list from 2009 through 2015. In 2014, Marsh won the Financial Technologies Forum's Person of the year award. Smarsh was named a leader in the 2015 and 2016 magic Quadrant for Enterprise Information Archiving.\n\n"}
{"id": "29634391", "url": "https://en.wikipedia.org/wiki?curid=29634391", "title": "Structured Financial Messaging System", "text": "Structured Financial Messaging System\n\nStructured Financial Messaging System (SFMS) is a secure messaging standard developed to serve as a platform for intra-bank and inter-bank applications. It is an Indian standard similar to SWIFT (Society for World-wide Interbank Financial Telecommunications) which is the international messaging system used for financial messaging globally.\n\nSFMS can be used for secure communication within the bank and between banks. The SFMS was launched on December 14, 2001 at IDRBT. It allows the definition of message structures, message formats, and authorization of the same for usage by the financial community. SFMS has a number of features and it is a modularized and web enabled software, with a flexible architecture facilitating centralized or distributed deployment. The access control is through Smart Card based user access and messages are secured by means of standard encryption and authentication services conforming to ISO standards.\n\nThe intra-bank part of SFMS is used by banks to take full advantage of the secure messaging facility it provides. The inter-bank messaging part is used by applications like electronic funds transfer (EFT), real time gross settlement systems (RTGS), delivery versus payments (DVP), centralized funds management systems (CFMS) and others. The SFMS provides application program interfaces (APIs), which can be used to integrate existing and future applications with the SFMS. Several banks have integrated it with their core or centralized banking software.\n"}
{"id": "37319307", "url": "https://en.wikipedia.org/wiki?curid=37319307", "title": "Sumaya Kazi", "text": "Sumaya Kazi\n\nSumaya Kazi (Bengali: সুমাইয়া কাজী, born July 17, 1982) is an American entrepreneur. At the age of 23, Kazi founded her first company The CulturalConnect. She later founded and was the CEO of San Francisco-based technology company Sumazi, a social intelligence platform used by brands, celebrities and enterprises. Kazi held one of the first social media management positions at a Fortune 500 company leading social media at Sun Microsystems until its acquisition by Oracle.\n\nKazi was born in Hollywood, California in 1982 and grew up in Moreno Valley, California. She started taking college courses at Riverside Community College at the age of 11, advancing in mathematics while attending Landmark Middle School.\n\nKazi attended Canyon Springs High School, where she was voted \"Most Likely to Succeed\" by her senior class. At the age of 16, she won the title of Miss Inland Empire (California) and later was a top five finalist in the California Distinguished Young Women competition, winning her a scholarship toward college.\n\nShe attended the University of California, Berkeley graduating in 2004 with a degree in Interdisciplinary Studies in Business. While a student, Kazi worked at the University Human Rights Centers on campus under the leadership of Professor Eric Stover, transcribing interviews of war-torn victims from Bosnia and Croatia. Kazi, along with her team, won first place in the Haas School of Business Cisco & Deloitte E-Business case competition, which served as a catalyst for her career in technology.\n\nUpon graduation, Kazi worked at Sun Microsystems where she was the senior social media manager for the Global Communications division. Kazi, one of the first social media managers at a Fortune 500 company, was responsible for developing programs to capture, expand and socialize new and evolving media, analyst and influencer communities.\n\nWhile working at Sun Microsystems, at the age of 23, Kazi founded her first company The CulturalConnect, an online media company for young professionals aimed at redefining what success looks like in different ethnic diasporas. The CulturalConnect was made up of five online publications including: The DesiConnect, The MidEastConnect, The AsiaConnect, The AfricanaConnect, and The LatinConnect.\n\nIn April 2011, Sumaya founded Sumazi, the social intelligence platform used by brands, celebrities and enterprises. Sumazi was a finalist at the TechCrunch Disrupt Startup Battlefield, where it won the Omidyar Network award for \"Startup Most Likely to Change the World.\"\n\n\nKazi is a frequent speaker and panelist at technology conferences and educational institutions educating audiences on topics such as entrepreneurship, non-profit work, intrapreneurship, social entrepreneurship, young professional issues, social media, diversity and technology. She has presented at the World Islamic Economic Forum in Malaysia, Marketing 2.0 Conference in France, BlogWorld Expo in Las Vegas, National Society of Collegiate Scholars Conference in Florida, Google Girl Geek Dinners Panel in Mountain View, Congresswoman Jackie Speier's Job Hunter's Conference in San Mateo among many other speaking engagements. Additionally, Kazi has been a speaker at several TEDx conferences including TEDxYouth at Facebook, TEDxBayArea at Linkedin, and TEDxWomen.\n\nKazi has practiced an Intermittent Fasting lifestyle since 2015. She has written a popular how-to guide on her Intermittent Fasting schedule and how she lost over 55 pounds as a result. She has been interviewed by Quartz Magazine, HVMN, and Inc Magazine about her success with Intermittent Fasting. \n\nKazi is a Salsa and Bachata dancer. She was a competitive Salsa dancer with the RicaSalsa San Francisco-based dance troupe where they won 1st place at the United States Salsa Open Championships in the Amateur category. Kazi is currently performing with the Inessence Bachata dance troupe.\n\n"}
{"id": "1488382", "url": "https://en.wikipedia.org/wiki?curid=1488382", "title": "Sump pump", "text": "Sump pump\n\nA sump pump is a pump used to remove water that has accumulated in a water-collecting sump basin, commonly found in the basements of homes. The water may enter via the perimeter drains of a basement waterproofing system, funneling into the basin or because of rain or natural ground water, if the basement is below the water table level.\n\nSump pumps are used where basement flooding happens regularly and to solve dampness where the water table is above the foundation of a home. Sump pumps send water away from a house to any place where it is no longer problematic, such as a municipal storm drain or a dry well.\n\nPumps may discharge to the sanitary sewer in older installations. Once considered acceptable, this practice may now violate the plumbing code or municipal bylaws, because it can overwhelm the municipal sewage treatment system. Municipalities urge homeowners to disconnect and reroute sump pump discharge away from sanitary sewers. Fines may be imposed for noncompliance. Many homeowners have inherited their sump pump configurations and do not realize that the pump discharges into the sewer.\n\nUsually hardwired into a home's electrical system, sump pumps may have a battery backup. The home's pressurized water supply powers some pumps, eliminating the need for electricity at the expense of using potable water, potentially making them more expensive to operate than electrical pumps and creating an additional water disposal problem. Since a sump basin may overflow if not constantly pumped, a backup system is important for cases when the main power is out for prolonged periods of time, as during a severe storm.\n\nThere are generally two types of sump pumps—pedestal and submersible. In the case of the pedestal pump, the motor is mounted above the sump—where it is more easily serviced, but is also more conspicuous. The pump impeller is driven by a long, vertical extension shaft and the impeller is in a scroll housing in the base of the pump. The submersible pump, on the other hand, is entirely mounted inside the sump, and is specially sealed to prevent electrical short circuits. There is debate about which variety of sump pump is better. Pedestal sump pumps usually last longer (25 to 30 years) if they are installed properly and kept free of debris. They are less expensive and easier to remove. Submersible pumps will only last 5 to 15 years. They are more expensive to purchase but can take up debris without clogging.\n\nSump pump systems are also utilized in industrial and commercial applications to control water table-related problems in surface soil. An artesian aquifer or periodic high water table situation can cause the ground to become unstable due to water saturation. As long as the pump functions, the surface soil will remain stable. These sumps are typically ten feet in depth or more; lined with corrugated metal pipe that contains perforations or drain holes throughout. They may include electronic control systems with visual and audible alarms and are usually covered to prevent debris and animals from falling in.\n\nModern sump pump components in the United States are standardized. They consist of:\n\nSelection of a sump pump may consider:\n\nA secondary, typically battery-powered sump pump can operate if the first pump fails. A battery-powered secondary pump will have a separate battery and charger system to provide power if normal supply is interrupted. \n\nAlternative sump pump systems can be driven by municipal water pressure. Water-powered ejector pumps have a separate pump, float and check valve. The float controlling a backup pump is mounted in the sump pit above the normal high water mark. Under normal conditions, the main electric powered sump pump will handle all the pumping duties. When water rises higher than normal for any reason, the backup float in the sump is lifted and activates the backup sump pump. An ejector pump can also be connected to a garden hose to supply high-pressure water, with another hose to carry the water away. Although such ejector pumps waste water and are relatively inefficient, they have the advantage of having no moving parts and offer the utmost in reliability.\n\nIf the backup sump system is rarely used, a component failure may not be noticed, and the system may fail when needed. Some battery control units test the system periodically and alert on failed electrical components.\n\nA simple, battery-powered water alarm can be hung a short distance below the top of the sump to sound an alarm should the water level rise too high.\n\nSump basins and sump pumps must be maintained. Typical recommendations suggest examining equipment every year. Pumps running frequently due to higher water table, water drainage, or weather conditions should be examined more frequently. Sump pumps, being mechanical devices, will fail eventually, which could lead to a flooded basement and costly repairs. Redundancy in the system (multiple/secondary pumps) can help to avoid problems when maintenance and repairs are needed on the primary system.\n\nWhen examining a sump pump and cleaning it, dirt, gravel, sand, and other debris should be removed to increase efficiency and extend the life of the pump. These obstructions can also decrease the pump's ability to drain the sump, and can allow the sump to overflow. The check valve can also jam from the debris. Examine the discharge line opening, when applicable, to ensure there are no obstructions in the line. Even a partially obstructed discharge line can force a sump pump to work harder and increase its chance of overheating and failure.\n\nFloat switches are used to automatically turn the sump pump on when water rises to a preset level. Float switches must be clear of any obstructions within the sump. A float guard can be used to prevent the float switch from accidentally resting on the pump housing, and remaining on. As mechanical float switches can wear out, they should be periodically tested by actuating them manually to assure that they continue to move freely and that the switch contacts are opening and closing properly.\n\nIf left in standing water, pedestal pumps should be manually run from time to time, even if the water in the sump isn't high enough to trip the float switch. This is because these pumps are incapable of removing all the water in a sump and the lower bearing or bushing for the pump impeller shaft tends to remain submerged, making it prone to corrosion and eventually freezing the drive shaft in the bearing. In the alternative, a pedestal pump that is expected to remain idle for an extended time should be removed from the sump and stored out of water, or the sump should be mopped out to bring the level of the remaining water well below the lower shaft bearing.\n\n"}
{"id": "2228163", "url": "https://en.wikipedia.org/wiki?curid=2228163", "title": "Syphon recorder", "text": "Syphon recorder\n\nThe syphon or siphon recorder is an obsolete electromechanical device used as a receiver for submarine telegraph cables invented by William Thomson, 1st Baron Kelvin in 1867. It automatically records an incoming telegraph message as a wiggling ink line on a roll of paper tape. Later a trained telegrapher would read the tape, translating the pulses representing the \"dots\" and \"dashes\" of the Morse code to characters of the text message.\n\nThe syphon recorder replaced Thomson’s mirror galvanometer as the standard receiving instrument for submarine telegraph cables, allowing long cables to be worked using just a few volts at the sending end. The disadvantage of the mirror galvanometer was that it required two operators, one with a steady eye to read and call off the signal, the other to write down the characters received. Its use spread to ordinary telegraph lines and radiotelegraphy radio receivers. A major advantage of the syphon recorder was that no operator has to monitor the line constantly waiting for messages to come in. The paper tape preserved a record of the actual message before translation to text, so errors in translation could be checked.\n\nThe siphon recorder works on the principle of a d'Arsonval galvanometer. A light coil of wire is suspended between the poles of a permanent magnet so it can turn freely. The coil is attached via two wire linkages to the metal plate siphon support, which pivots on a horizontal suspension thread. From this plate a narrow glass siphon tube hangs down vertically with its end almost touching a paper tape. The paper tape is pulled by motorized rollers at a constant speed under the siphon pen. Ink is drawn up from a reservoir into the tube by siphon action and comes out a tiny orifice in the end of the siphon tube, drawing a line down the moving paper tape. In order not to affect the motion of the coil, the siphon tube itself never touches the paper, only the ink.\n\nThe current from the telegraph line is applied to the coil. The pulses of current representing the Morse code \"dots\" and \"dashes\" flowing through the coil create a magnetic field which interacts with the magnetic field of the magnet, creating a torque which causes the coil to rotate slightly about its vertical suspension axis. The wire linkages cause the siphon support plate to rotate about its horizontal axis, swinging the siphon tube across the paper tape. This draws a displacement in the ink line on the tape as long as the current is present in the coil. Thus the ink line on the tape forms a graph of the current in the telegraph line, with displacements representing the \"dots\" and \"dashes\" of the Morse code. An operator knowing Morse code later translates the line on the tape to characters of the text message, and types them onto a telegram form.\n\nThe siphon and an ink reservoir are together supported by an ebonite bracket, separate from the rest of the instrument, and insulated from it. This separation permits the ink to be electrified to a high potential while the body of the instrument, including the paper and metal writing tablet, are grounded, and at low potential. The tendency of a charged body is to move from a place of higher to a place of lower potential, and consequently the ink tends to flow downwards to the writing tablet. The only avenue of escape for it is by the fine glass siphon, and through this it rushes accordingly and discharges itself upon the paper. The natural repulsion between its like-electrified particles causes the shower to issue in spray. As the paper moves over the pulleys a delicate hair line is marked, straight when the syphon is stationary, but curved when the siphon is pulled from side to side by the oscillations of the signal coil.\n\nPower to pull the roll of paper tape through the syphon recorder was usually supplied by one Froment's mouse mill motors. These also drove an electrostatic machine to generate the electricity to power the syphon.\n\nA simpler mechanism was developed by Alexander Muirhead. This used a vibrating pen to avoid the same problem of the ink sticking to the paper. The recording pen was suspended on a thin wire, vibrated by an electromagnet mechanism similar to that of an electric bell, to break contact with the paper.\n"}
{"id": "513291", "url": "https://en.wikipedia.org/wiki?curid=513291", "title": "Telecommunications relay service", "text": "Telecommunications relay service\n\nA telecommunications relay service, also known as TRS, relay service, or IP-relay, or Web-based relay service, is an operator service that allows people who are deaf, hard of hearing, deafblind, or have a speech disorder to place calls to standard telephone users via a keyboard or assistive device. Originally, relay services were designed to be connected through a TDD, teletypewriter (TTY) or other assistive telephone device. Services gradually have expanded to include almost any real-time text capable technology such as a personal computer, laptop, mobile phone, PDA, and many other devices. The first TTY was invented by deaf scientist Robert Weitbrecht in 1964. The first relay service was established in 1974 by Converse Communications of Connecticut.\n\nDepending on the technical and physical abilities and physical environments of users, different call types are possible via relay services.\n\nOnce the most common type of TRS call, TTY calls involve a call from a deaf or hard-of-hearing person who utilizes a TTY to a hearing person. In this type of call, typed messages are relayed as voice messages by a TRS operator, (also known as \"Communication Assistant\" (CA), \"Relay Operator\" (RO), \"Relay Assistant\" (RA), or \"relay agent\" (agent)), and vice versa. This allows callers who are unable to use a regular telephone to be able to place calls to people who use a regular telephone and vice versa. When the person who is hearing is ready for a response, it is customary to say \"go ahead\" or \"GA\" to indicate that it is the TTY (teletypewriter) user's turn to talk and \"stop keying\", \"SK\", or \"ready to hang up\" when ending the call and vice versa. This mode of communication has largely been superseded by other modes of communications, including the utilization of IP relay, VPs, VRS, and VRI.\n\nA common type of call is \"voice carry over\", VCO. This allows a person who is hard of hearing or deaf but can speak to use their voice while receiving responses from a person who is hearing via the operator's typed text. There are many variations of VCO, including two-line VCO and VCO with privacy.\n\nThe operator will not hear the VCO user's voiced messages and the VCO user does not need to voice GA. The operator will hear the person who is hearing, and the person who is hearing must give the GA each time to alert the operator it is the VCO user's turn. The VCO user does not need to voice GA, because the VCO user types it or presses the \"VCO GA\" button on the VCO phone when it's the voice user's turn to talk.\n\nTwo-line VCO allows a VCO user using a TTY or computer to call a TRS operator, who in turn calls the VCO user on a second telephone line, which serves as the voice line. The user puts the operator on a brief hold to initiate a three-way call with the hearing person. This method is frequently used by people who are hard of hearing and like to use some of their residual hearing as well not having to say \"go ahead\". With two-line VCO, the VCO user and the voice user can interrupt each other. VCO with Privacy cannot be used with two-line VCO, because the operator, VCO user, and hearing person are on a three-way call.\n\nA less common call type is \"hearing carry over\" (HCO). HCO allows a person who is speech-disabled but can hear to use their hearing while sending responses to a person who is hearing via the HCO user's typed text. The operator voices the HCO user's typed messages, and then the HCO users picks up the handset and listens to the other voice user's response. There are many variations of HCO, including two-line HCO and HCO with privacy.\n\nThe operator will not hear the voice user's voiced messages and the voice user does not need to voice GA. The operator will voice for the person who is Speech-Disabled, and the person who is Speech–Disabled must give the GA each time to alert the operator it is the voice user's turn. The voice user does not need to voice GA, because the HCO user can hear when the voice user finishes talking.\n\nSimilar to 2-line VCO, 2-line HCO allows an HCO user using a TTY or computer to call a TRS operator, who in turn calls the HCO user on a second telephone line, which serves as the voice line. The user puts the operator on a brief hold to initiate a three-way call with the hearing person. This method is frequently used by people who are Speech-Disabled and like to use some of their residual speech as well not having to type \"GA\". With 2–Line HCO, the HCO user and the voice user can interrupt each other. HCO with Privacy cannot be used with 2–Line HCO, because the operator, HCO user, and hearing person are on a three–way call.\n\nSpeech to speech (STS) exists for people who have speech disabilities. A specially–trained STS TRS operator revoices what the person with a speech disability says. STS is often used in combination with VCO for people who are deaf and have somewhat understandable speech, as well as two–Line HCO users. STS enables people with speech disabilities to call others (able-bodied speakers and other people with speech disabilities). It also enables people without speech disabilities to call people with speech disabilities. Anyone can call 711 in the U.S. and ask for Speech to Speech. STS is also available in Australia, New Zealand and Sweden.\n\nMany STS users have Parkinson's disease, cerebral palsy, ALS, multiple sclerosis, muscular dystrophy or stroke. Other users stutter or have had a laryngectomy. STS also helps speech synthesizer users, users of Augmentative and Alternative Communication (AAC.) AAC users can set their device next to a speakerphone. They ask the STS CA set up the call, negotiate the menu, introduce the call explaining AAC and then go into the background. This enables AAC users to communicate independently once the other party is on the line. For more information visit .\n\nTelebraille also exists for people who are deafblind with the use of a TTY with a braille or regular keyboard and a refreshable braille display or LVD (Large Visual Display). A relay call of a user who is deafblind is directly related to a relay call of a TTY user, however, the text transmission speed is often reduced to increase the ability of the user who is deafblind to comprehend the moving braille on the braille TTY or large print on the LVD. Telebraille relay operators must be familiar with Braille contractions that users who are deafblind may use. Some TTY users with mobile disabilities may prefer to use a Telebraille, due to the smaller keyboard, regardless of a sight disability or lack thereof.\n\nCaptioned telephone is a hybrid communication method that enables people who are hard of hearing, oral deaf or late–deafened to speak directly to another party on a telephone call. Typically, a telephone that displays real-time captions of what the hearing party speaks during a conversation. The captions are displayed on a screen embedded in the telephone base. A captioned telephone can also function exactly like a VCO by switching the device to VCO mode, for example, to communicate with an HCO user directly, without relay. Captioned telephone services can be provided in traditional telephone environments as well as in VOIP environments.\n\nCaptions are created by a communications assistant using a computer with voice recognition software. The communications assistant listens to and revoices the hearing party's side of the conversation into the microphone of a headset. A voice recognition program creates the captions and they are sent out to the captioned telephone where they are read by the user.\n\nPrior to 2005, captioned telephone service was only available to people in states that had captioned telephone service as part of their state relay program. In 2005, the FCC made IP CTS a part of the federally mandated services. \n\nIP CTS Requires an internet connection to deliver the captions to the user. Most also rely on their regular land-line telephone for the audio portion of the call, but some configurations of IP CTS allow the use of VOIP to carry the call audio. IP CTS has allowed captioned telephone service to be provided on smartphones and tablets.\n\nCaptioned telephone can also be used with two lines. This is especially useful for users who prefer to give out their home phone number alone, instead of both the captioning service number and the toll-free captioning service number or for users who prefer to turn captions on and off anytime during the call. 2–Line captioned telephone can also be used with other relay services. For example, STS can be used with a 2–Line captioned telephone, for captioned telephone users with speech disabilities. 2–Line captioned telephone is only available to people in states that have 2–Line captioned telephone as part of their relay service or federal employees/contractors and American Indians.\n\nWeb-based captioned telephone enables telephone calls to be placed with captions, by utilizing the World Wide Web browser window of a computer or smart phone. It is similar to a traditional captioned phone call except the user's own telephone equipment is used, whilst the captions are viewed online instead of in the captioned telephone display screen.\n\nMany other call type variations are possible, including VCO to VCO, HCO to HCO, HCO to TTY, and VCO to TTY. Fundamentally, relay services have the ability to connect any two callers with different abilities over the telephone network. Voice callers in the United States can now access the service with a universal number: 711. After the number is dialled, the caller will receive instructions to complete the call to reach deaf callers.\n\nIP relay services are also called Web-based text relay services in Europe. These services provide functionality similar to TDD/TTY relay services, replacing the telephone line and TDD/TTY devices with an Internet connection and software running on a computer or smartphone .\n\nWhen using an IP relay service for an emergency call like 911 or 112, the relay operator will ask for the street address, city, and state from which the call is originating. If this information is not provided then the relay operator will be unable to complete the emergency call.\n\nMost IP relay services support many types of technologies, such as Web browser, mobile phone app, text messaging, WAP, instant messaging, and Text over IP (ToIP). Support for many technologies has made it possible to use almost any generic connected device to use a relay service, such as a personal computer, laptop, mobile phone, PDA, or other device capable of utilizing the connection methods provided by an IP relay provider.\n\nVideo relay service (VRS) allows people who use sign language to place phone calls by signing instead of typing. The VI (video interpreter) uses a webcam or videophone to voice the deaf, hard-of-hearing or, speech-disabled person's signs to a hearing person and sign the hearing person's words to the deaf, hard-of-hearing or speech-impaired person.\n\nVideo Remote Interpreting (VRI) allows deaf or hard-of-hearing people who use sign language to communicate with hearing people in the same room. VRI addresses one limitation to VRS, which is that VRS cannot be used if the hearing person is in the same room with the deaf or hard-of-hearing person. VRI has proven to be useful for deaf or hard-of-hearing people in business meetings, doctor appointments, minor surgical procedures, and court proceedings.\n\nAs much of the TRS system, particularly the Internet Relay Services, is open for public use; it is possible for anyone with the proper equipment to place calls. This includes people who are not members of the original intended user group, who are deaf, hard of hearing, or speech impaired. Some such users have noted its usefulness in making long-distance or local calls free of charge and without a telephone. Some providers have implemented long-distance billing, which bills long-distance calls just like a regular telephone. Providers defend the accessibility even to people who have neither hearing nor speech disabilities as a necessary evil. This is because the principle of \"transparency\" — the belief that the operator and the mechanics of relay should generally go as unnoticed as possible in the call — requires that relay be as easy to use as a normal telephone, which does not require any kind of verification for hearing people to use. Leaders in the deaf community defend this decision and generally retain strong support among service users with hearing and speech disabilities.\n\nThe open structure of relay services has led to a number of complaints regarding its use as a vehicle for fraud. In 2004, news outlets, such as MSNBC, and several newspapers, including the Baltimore City Paper, ran stories of reported abuse of the relay system, such as users from international locations calling businesses in the United States to fraudulently purchase goods. This has also generated numerous complaints, particularly by those who were employed as relay operators, that so-called \"prank calls,\" where neither user requires the service and the caller is just attempting to have fun with a novel mode of communication. In December 2006, NBC ran another story where former operators alleged that \"85 to 90 percent\" of calls were scams. Since it is illegal for relay service companies to keep records, fraudulent users can operate with impunity. Fraudulent calls of both types have been cited as reasons for further relay regulation, and as causes for long hold times that must be endured by many legitimate users. Most businesses legally cannot have relay calls blocked due to the need for legitimate users to be accommodated, although businesses that are repeatedly victimized by pranks and/or scams often stop trusting relay calls or hang up on them because it is difficult to distinguish legitimate users from illegitimate ones; this is another way that the abusers of the service ultimately victimize the legitimate users, in addition to tying up the service from them.\n\nIn 2006, the FCC launched a campaign to gather feedback from the various Internet Protocol relay-certified companies operating within the United States to fight the wave of relay scams and pranks being made over the service. As brought up in the FCC's released document, users on the IP-based relay services can thus place their calls anonymously, which cannot certify that the user in question really needs operator assistance or not. Furthermore, fraudulent calls of any nature cost millions to the American people yearly (based on the $1.293 per minute fee that is being paid for completed IP-based relay) to various relay providers for successfully completed calls.\n\nStarting in November 2009, to help counter the problem of fraudulent use, the FCC began requiring all users of IP Relay to register their screen names with a default IP Relay provider. This, along with many IP Relay providers working to educate hearing users of the risks of fraudulent users (making it less lucrative for fraudulent users who no longer have an uneducated population to target), and other efforts has greatly reduced the amount of fraudulent use of the IP Relay system.\n\nIn March 2012, the United States federal government announced a lawsuit against AT&T. The specific accusations state that AT&T \"violated the False Claims Act by facilitating and seeking federal payment for IP Relay calls by international callers who were ineligible for the service and sought to use it for fraudulent purposes. The complaint alleges that, out of fears that fraudulent call volume would drop after the registration deadline, AT&T knowingly adopted a non-compliant registration system that did not verify whether the user was located within the United States. The complaint further contends that AT&T continued to employ this system even with the knowledge that it facilitated use of IP Relay by fraudulent foreign callers, which accounted for up to 95 percent of AT&T’s call volume. The government’s complaint alleges that AT&T improperly billed the TRS Fund for reimbursement of these calls and received millions of dollars in federal payments as a result.\"\n\n"}
{"id": "35865171", "url": "https://en.wikipedia.org/wiki?curid=35865171", "title": "Tricouni", "text": "Tricouni\n\nA Tricouni is the brand name of a metal nail used on mountain climbing shoes. Widely used in the past by mountain climbers and soldiers, it offers improved gripping on various surfaces. The Tricouni nail was invented in 1912 by a jeweler from Geneva, Félix-Valentin Genecand, alias \"Tricouni\" (1878-1957). Genecand was also a well known alpinist (several mountains were named after him: Mount Genecand in Antarctica, Tricouni Peak in Canada). Tricouni nails are also referred to as hobnails, boot nails, cleats and shoe studs.\n\nTricouni is now the name of a British luxury fashion house, designing women’s luxury outerwear. Tricouni is a privately held company, headquartered in London, England. \n\n"}
{"id": "4583670", "url": "https://en.wikipedia.org/wiki?curid=4583670", "title": "Turboencabulator", "text": "Turboencabulator\n\nThe turboencabulator or turbo-encabulator (and its later incarnations, the retroencabulator or retro-encabulator and Micro Encabulator) is a fictional machine whose alleged existence became an in-joke and subject of professional humor among engineers. The explanation of the supposed product makes extensive use of technobabble.\n\nThe gag was popular for many years. The following quote is from the original \"Students’ Quarterly Journal\" article written by J. H. Quick in 1946. The citation in the later \"Time\" article misspells several of the technical terms. \"General Electric\", \"Chrysler\" and \"Rockwell Automation\" use many of the same words.\n\nThe original technical description of the \"turbo-encabulator\" was written by British graduate student John Hellins Quick (1923-1991). It was published in 1944 by the British Institution of Electrical Engineers Students’ Quarterly Journal [in an article titled \"The Turbo-Encabulator in Industry\" by \"J.H. Quick, Student\"] as also noted by consulting firm Arthur D. Little in a 1995 reprint of Quick's description, and giving Quick's full name.\n\nThe earliest written U.S. source may have been in 1946, in an Arthur D. Little Industrial Bulletin. An early popular American reference to the turbo-encabulator appeared in an article by New York lawyer Bernard Salwen in \"Time\" on April 15, 1946. Part of Salwen's job was to review technical manuscripts. He was amused by the jargon and passed on the description from the Arthur D. Little pamphlet.\n\n\"Time\" got with the gag, featuring the device in a May 6, 1946 issue, described as \"An adjunct to the turbo-encabulator, employed whenever a barescent skor motion is required.\" A month later a response to reader mail on the feature appeared in the June 3, 1946 issue:\nIn 1962 a turboencabulator data sheet was created by engineers at General Electric's Instrument Department, in West Lynn, Massachusetts. It quoted from the previous sources and was inserted into the General Electric Handbook. The turboencabulator data sheet had the same format as the other pages in the G.E. Handbook. The engineers added \"Shure Stat\" in \"Technical Features\", which was peculiar only to the Instrument Department, and included the first known graphic representation of a \"manufactured\" Turboencabulator using parts made at the Instrument Department.\n\nIn Bud Haggart, an actor who appeared in many industrial training films in and around Detroit, performed in the first film realization of the description and operation of the \"Turboencabulator\", using a truncated script adapted from Quick's article. Bud convinced director Dave Rondot and the film crew to stay after the filming of an actual GMC Trucks project training film to realize the Turboencabulator spot.\n\nIn the former Chrysler Corporation \"manufactured\" the Turboencabulator in a video spoof, with Haggart reprising his role from the GM film. Rockwell Automation \"manufactured\" the renamed Retro-Encabulator in another video spoof in . On April Fools' Day 2013, Hank Green released a \"SciShow\" episode on YouTube entitled \"The Retro-Proto-Turbo-Encabulator.\" On April 1, 2016, PATH \"introduced\" the Micro-Encabulator on their YouTube Channel as a \"new game-changing global health technology featuring hydrocoptic miniaturization and advanced panametric fam alignment.\"\n\n\n"}
{"id": "20734501", "url": "https://en.wikipedia.org/wiki?curid=20734501", "title": "Ursa tension leg platform", "text": "Ursa tension leg platform\n\nThe Ursa tension leg platform is an oil platform with a tension leg structure located at about southeast of New Orleans in the Gulf of Mexico. It is operated by Shell Oil Company. It has a total height from the seabed to its top of .\n\nShell Oil is the operator of the project with 45.39%. BP Exploration & Production Inc has 22.69% while Exxon Mobil Corp and ConocoPhillips each have 15.96%.\n\nThe discovery well was drilled in 1991, with Sonat's Discoverer Seven Seas drillship, on Mississippi Canyon block 854. Construction was finished in 1998.\n\nThe Ursa Tension Leg Platform was replaced as the tallest man-made structure in the world by the Magnolia Tension-leg Platform.\n\n\n"}
{"id": "42980569", "url": "https://en.wikipedia.org/wiki?curid=42980569", "title": "Vajazzle", "text": "Vajazzle\n\nA vajazzle (also spelled vagazzle) is a form of genital decoration, formed by the application of crystal ornaments on the shaved mons pubis of a woman. The process is known as vajazzling, a portmanteau of \"vagina\" and \"bedazzle\". The phenomenon was popularized by actress Jennifer Love Hewitt, who devoted a chapter in her book \"The Day I Shot Cupid\" to vajazzling. During a promotional interview on a US talk show in January 2010, she encouraged the female members of her audience \"to vajazzle their vajayjays\". Vajazzle became the most searched term on Google for the following day. In the United Kingdom, the concept was popularized when beautician Amy Childs appeared in the television show \"The Only Way Is Essex\" in 2010. By 2011, an Internet rating site for vajazzling called Rate My Vajazzle had been set up.\n\nVajazzling can increase risks of infection if not properly cleaned.\n\n"}
