{"id": "22239552", "url": "https://en.wikipedia.org/wiki?curid=22239552", "title": "Animal digest", "text": "Animal digest\n\nAnimal digest is a common ingredient used in pet foods. As defined by the Association of American Feed Control Officials, digest is produced by the chemical or enzymatic hydrolysis of clean animal tissue that has not undergone decomposition. These animal tissues may not include hair, horns, teeth, hooves, or feathers, with the exclusion of trace amounts that are unavoidable even after acceptable processing methods.\n\nAccording to the United States Food and Drug Administration (FDA), a digest is an additive that has been treated with heat, enzymes, or also acids to produce a concentrated product intended as a natural flavoring. Pet food may legally be labelled as \"Chicken Flavored\" regardless of the percentage of chicken-derived product it contains, so long as the chicken flavoring is deemed \"perceptible.\"\n\nIf a product is labeled as \"flavored\" by a certain type of meat, the digest it contains must have been produced from tissues pertaining to the listed animal species. Chicken flavored food must be flavored with chicken digest.\n"}
{"id": "18964603", "url": "https://en.wikipedia.org/wiki?curid=18964603", "title": "Bioreporter", "text": "Bioreporter\n\nBioreporters are intact, living microbial cells that have been genetically engineered to produce a measurable signal in response to a specific chemical or physical agent in their environment. Bioreporters contain two essential genetic elements, a promoter gene and a reporter gene. The promoter gene is turned on (transcribed) when the target agent is present in the cell’s environment. The promoter gene in a normal bacterial cell is linked to other genes that are then likewise transcribed and then translated into proteins that help the cell in either combating or adapting to the agent to which it has been exposed. In the case of a bioreporter, these genes, or portions thereof, have been removed and replaced with a reporter gene. Consequently, turning on the promoter gene now causes the reporter gene to be turned on. Activation of the reporter gene leads to production of reporter proteins that ultimately generate some type of a detectable signal. Therefore, the presence of a signal indicates that the bioreporter has sensed a particular target agent in its environment.\n\nOriginally developed for fundamental analysis of factors affecting gene expression, bioreporters were early on applied for the detection of environmental contaminants and have since evolved into fields as diverse as medical diagnostics, precision agriculture, food safety assurance, process monitoring and control, and bio-microelectronic computing. Their versatility stems from the fact that there exist a large number of reporter gene systems that are capable of generating a variety of signals. Additionally, reporter genes can be genetically inserted into bacterial, yeast, plant, and mammalian cells, thereby providing considerable functionality over a wide range of host vectors.\n\nSeveral types of reporter genes are available for use in the construction of bioreporter organisms, and the signals they generate can usually be categorized as either colorimetric, fluorescent, luminescent, chemiluminescent or electrochemical. Although each functions differently, their end product always remains the same – a measurable signal that is proportional to the concentration of the unique chemical or physical agent to which they have been exposed. In some instances, the signal only occurs when a secondary substrate is added to the bioassay (\"luxAB\", Luc, and aequorin). For other bioreporters, the signal must be activated by an external light source (GFP and UMT), and for a select few bioreporters, the signal is completely self-induced, with no exogenous substrate or external activation being required (\"luxCDABE\"). The following sections outline in brief some of the reporter gene systems available and their existing applications.\n\nLuciferase is a generic name for an enzyme that catalyzes a light-emitting reaction. Luciferases can be found in bacteria, algae, fungi, jellyfish, insects, shrimp, and squid, and the resulting light that these organisms produce is termed bioluminescence. In bacteria, the genes responsible for the light-emitting reaction (the \"lux\" genes) have been isolated and used extensively in the construction of bioreporters that emit a blue-green light with a maximum intensity at 490 nm. Three variants of \"lux\" are available, one that functions at < 30°C, another at < 37°C, and a third at < 45°C. The \"lux\" genetic system consists of five genes, \"luxA\", \"luxB\", \"luxC\", \"luxD\", and \"luxE\". Depending on the combination of these genes used, several different types of bioluminescent bioreporters can be constructed.\n\n\"luxAB\" bioreporters contain only the \"luxA\" and \"luxB\" genes, which together are responsible for generating the light signal. However, to fully complete the light-emitting reaction, a substrate must be supplied to the cell. Typically, this occurs through the addition of the chemical decanal at some point during the bioassay procedure. Numerous \"luxAB\" bioreporters have been constructed within bacterial, yeast, insect, nematode, plant, and mammalian cell systems.\n\nInstead of containing only the \"luxA\" and \"luxB\" genes, bioreporters can contain all five genes of the \"lux\" cassette, thereby allowing for a completely independent light generating system that requires no extraneous additions of substrate nor any excitation by an external light source. So in this bioassay, the bioreporter is simply exposed to a target analyte and a quantitative increase in bioluminescence results, often within less than one hour. Due to their rapidity and ease of use, along with the ability to perform the bioassay repetitively in real time and on-line, makes \"luxCDABE\" bioreporters extremely attractive. Consequently, they have been incorporated into a diverse array of detection methodologies ranging from the sensing of environmental contaminants to the real-time monitoring of pathogen infections in living mice.\n\nNonspecific \"lux\" bioreporters are typically used for the detection of chemical toxins. They are usually designed to continuously bioluminesce. Upon exposure to a chemical toxin, either the cell dies or its metabolic activity is retarded, leading to a decrease in bioluminescent light levels. Their most familiar application is in the Microtox assay where, following a short exposure to several concentrations of the sample, the decreased bioluminescence can be correlated to relative levels of toxicity.\n\nFirefly luciferase catalyzes a reaction that produces visible light in the 550 – 575 nm range. A click-beetle luciferase is also available that produces light at a peak closer to 595 nm. Both luciferases require the addition of an exogenous substrate (luciferin) for the light reaction to occur. Numerous \"luc\"-based bioreporters have been constructed for the detection of a wide array of inorganic and organic compounds of environmental concern. The most promising applications, however, probably rely on introducing the genetic code of the firefly luciferase into other eukaryotic cells and tissues. \n\nInsertion of the \"luc\" genes into a human cervical carcinoma cell line (HeLa) illustrated that tumor-cell clearance could be visualized within a living mouse by simply scanning with a charge-coupled device camera, allowing for chemotherapy treatment to rapidly be monitored on-line and in real-time. In another example, the \"luc\" genes were inserted into human breast cancer cell lines to develop a bioassay for the detection and measurement of substances with potential estrogenic and antiestrogenic activity.\n\nParticular promoters can be placed upstream of the \"luc\" gene, that is, the \"luc\" sequence can be fused to the promoter sequence at DNA level. If such construct is not too large in size, it can simply be introduced into eukaryotic cells using plasmids. This approach is widely used to study the activity of a given promoter in a given cell/tissue type, since the amount of light produced by the luciferase is directly proportional to the promoter activity . In addition to studying the promoters, firefly luciferase assays offer the option of studying transcriptional activators: in these experiments typically the GAL4/UAS_system is used and its Gal4 upstream activating DNA sequence (UAS) is placed upstream the \"luc\" gene while the different activators or the different variants/fragments of the same activator are fused to the GAL4 DNA binding module at protein level. This way the transcriptional activity of the different GAL4 fusion proteins can be directly compared using light as a readout. .\n\nAequorin is a photoprotein isolated from the bioluminescent jellyfish \"Aequorea victoria\". Upon addition of calcium ions (Ca2+) and coelenterazine, a reaction occurs whose end result is the generation of blue light in the 460 - 470 nm range. Aequorin has been incorporated into human B cell lines for the detection of pathogenic bacteria and viruses in what is referred to as the Cell CANARY assay (Cellular Analysis and Notification of Antigen Risks and Yields). The B cells are genetically engineered to produce aequorin. Upon exposure to antigens of different pathogens, the recombinant B cells emit light as a result of activation of an intracellular signaling cascade that releases calcium ions inside the cell.\n\nGreen fluorescent protein (GFP) is also a photoprotein isolated and cloned from the jellyfish \"Aequorea victoria\". Variants have also been isolated from the sea pansy \"Renilla reniformis\". GFP, like aequorin, produces a blue fluorescent signal, but without the required addition of an exogenous substrate. All that is required is an ultraviolet light source to activate the fluorescent properties of the photoprotein. This ability to autofluoresce makes GFP highly desirable in biosensing assays since it can be used on-line and in to monitor intact, living cells. Additionally, the ability to alter GFP to produce light emissions besides blue (i.e., cyan, red, and yellow) allows it to be used as a multianalyte detector. Consequently, GFP has been used extensively in bioreporter constructs within bacterial, yeast, nematode, plant, and mammalian hosts.\n\nUroporphyrinogen (urogen) III methyltransferase (UMT) catalyzes a reaction that yields two fluorescent products which produce a red-orange fluorescence in the 590 - 770 nm range when illuminated with ultraviolet light. So as with GFP, no addition of exogenous substrates is required. UMT has been used as a bioreporter for the selection of recombinant plasmids, as a marker for gene transcription in bacterial, yeast, and mammalian cells, and for the detection of toxic salts such as arsenite and antimonite.\n"}
{"id": "553897", "url": "https://en.wikipedia.org/wiki?curid=553897", "title": "Chemical oxygen demand", "text": "Chemical oxygen demand\n\nIn environmental chemistry, the chemical oxygen demand (COD) is an indicative measure of the amount of oxygen that can be consumed by reactions in a measured solution. It is commonly expressed in mass of oxygen consumed over volume of solution which in SI units is milligrams per litre (mg/L). A COD test can be used to easily quantify the amount of organics in water. The most common application of COD is in quantifying the amount of oxidizable pollutants found in surface water (e.g. lakes and rivers) or wastewater. COD is useful in terms of water quality by providing a metric to determine the effect an effluent will have on the receiving body, much like biochemical oxygen demand (BOD).\n\nThe basis for the COD test is that nearly all organic compounds can be fully oxidized to carbon dioxide with a strong oxidizing agent under acidic conditions. The amount of oxygen required to oxidize an organic compound to carbon dioxide, ammonia, and water is given by:\nThis expression does not include the oxygen demand caused by nitrification, the oxidation of ammonia into nitrate:\n\nDichromate, the oxidizing agent for COD determination, does not oxidize ammonia into nitrate, so nitrification is not included in the standard COD test.\n\nThe International Organization for Standardization describes a standard method for measuring chemical oxygen demand in ISO 6060 .\n\nPotassium dichromate is a strong oxidizing agent under acidic conditions. Acidity is usually achieved by the addition of sulfuric acid. The reaction of potassium dichromate with organic compounds is given by:\n\nwhere formula_4. Most commonly, a 0.25 N solution of potassium dichromate is used for COD determination, although for samples with COD below 50 mg/L, a lower concentration of potassium dichromate is preferred.\n\nIn the process of oxidizing the organic substances found in the water sample, potassium dichromate is reduced (since in all redox reactions, one reagent is oxidized and the other is reduced), forming Cr. The amount of Cr is determined after oxidization is complete, and is used as an indirect measure of the organic contents of the water sample.\n\nFor all organic matter to be completely oxidized, an excess amount of potassium dichromate (or any oxidizing agent) must be present. Once oxidation is complete, the amount of excess potassium dichromate must be measured to ensure that the amount of Cr can be determined with accuracy. To do so, the excess potassium dichromate is titrated with ferrous ammonium sulfate (FAS) until all of the excess oxidizing agent has been reduced to Cr. Typically, the oxidation-reduction indicator ferroin is added during this titration step as well. Once all the excess dichromate has been reduced, the ferroin indicator changes from blue-green to a reddish brown. The amount of ferrous ammonium sulfate added is equivalent to the amount of excess potassium dichromate added to the original sample. Note: Ferroin indicator is bright red from commercially prepared sources, but when added to a digested sample containing potassium dichromate it exhibits a green hue. During the titration the color of the indicator changes from a green hue to a bright blue hue to a reddish brown upon reaching the endpoint. Ferroin indicator changes from red to pale blue when oxidized.\n\nA solution of 1.485 g 1,10-phenanthroline monohydrate is added to a solution of 695 mg FeSO·7HO in distilled water, and the resulting red solution is diluted to 100 mL.\n\nThe following formula is used to calculate COD:\n\nwhere \"b\" is the volume of FAS used in the blank sample, \"s\" is the volume of FAS in the original sample, and \"n\" is the normality of FAS. If milliliters are used consistently for volume measurements, the result of the COD calculation is given in mg/L.\n\nThe COD can also be estimated from the concentration of oxidizable compound in the sample, based on its stoichiometric reaction with oxygen to yield CO (assume all C goes to CO), HO (assume all H goes to HO), and NH (assume all N goes to NH), using the following formula:\n\nWhere \n\nFor example, if a sample has 500 Wppm (Weight Parts per Million) of phenol:\n\nSome samples of water contain high levels of oxidizable inorganic materials which may interfere with the determination of COD. Because of its high concentration in most wastewater, chloride is often the most serious source of interference. Its reaction with potassium dichromate follows the equation:\n\nPrior to the addition of other reagents, mercuric sulfate can be added to the sample to eliminate chloride interference.\n\nThe following table lists a number of other inorganic substances that may cause interference. The table also lists chemicals that may be used to eliminate such interference, and the compounds formed when the inorganic molecule is eliminated.\n\nMany governments impose strict regulations regarding the maximum chemical oxygen demand allowed in waste water before they can be returned to the environment. For example, in Switzerland, a maximum oxygen demand between 200 and 1000 mg/L must be reached before waste water or industrial water can be returned to the environment .\n\nFor many years, the strong oxidizing agent potassium permanganate (KMnO) was used for measuring chemical oxygen demand. Measurements were called \"oxygen consumed\" from permanganate, rather than the \"oxygen demand\" of organic substances. Potassium permanganate's effectiveness at oxidizing organic compounds varied widely, and in many cases biochemical oxygen demand (BOD) measurements were often much greater than results from COD measurements. This indicated that potassium permanganate was not able to effectively oxidize all organic compounds in water, rendering it a relatively poor oxidizing agent for determining COD.\n\nSince then, other oxidizing agents such as ceric sulphate, potassium iodate, and potassium dichromate have been used to determine COD. Of these, potassium dichromate (KCrO) has been shown to be the most effective: it is relatively cheap, easy to purify, and is able to nearly completely oxidize almost all organic compounds.\n\nIn these methods, a fixed volume with a known excess amount of the oxidant is added to a sample of the solution being analyzed. After a refluxing digestion step, the initial concentration of organic substances in the sample is calculated from a titrimetric or spectrophotometric determination of the oxidant still remaining in the sample. As with all colorimetric methods blanks are used to control for contamination by outside material.\n\n\n"}
{"id": "42270558", "url": "https://en.wikipedia.org/wiki?curid=42270558", "title": "CinePlayer", "text": "CinePlayer\n\nCinePlayer is a software based media player used to review Digital Cinema Packages (DCP) without the need for a digital cinema server by Doremi Labs. CinePlayer can play back any DCP, not just those created by Doremi Mastering products. In addition to playing DCPs, CinePlayer can also playback JPEG2000 image sequences and many popular multimedia file types.\n\nThere are two versions of CinePlayer available, standard and Pro. The standard version supports playback of non-encrypted, 2D DCP’s up to 2K resolution. The Pro version supports playback of encrypted, 2D or 3D DCP’s with subtitles up to 4K resolution.\n\n\n\n\n\n\n"}
{"id": "317092", "url": "https://en.wikipedia.org/wiki?curid=317092", "title": "Cliff Shaw", "text": "Cliff Shaw\n\nJohn Clifford Shaw (1922–9 February 1991) was a systems programmer at the RAND Corporation. He is a coauthor of the first artificial intelligence program, the Logic Theorist, and was one of the developers of Information Processing Language, a programming language of the 1950s. It is considered the true \"father\" of the JOSS language. One of the most significant events that occurred in the programming was the development of the concept of list processing by Allen Newell, Herbert A. Simon and Cliff Shaw during the development of the language IPL-V. He invented the linked list, which remains fundamental in many strands of modern computing technology.\n\n"}
{"id": "14189946", "url": "https://en.wikipedia.org/wiki?curid=14189946", "title": "Constant Awake Mode", "text": "Constant Awake Mode\n\nIn the context of wireless networking, Constant Awake Mode (CAM) is a mode that is intended for devices when power is not an issue, such as when AC power is available to a device. This mode provides the best connectivity from the user perspective. CAM is also appropriate when a portable device will be used for only a short time that the battery can easily accommodate. This is the most commonly used mode, and can be contrasted with power saving modes, which may or may not be offered by a particular device.\n"}
{"id": "5304481", "url": "https://en.wikipedia.org/wiki?curid=5304481", "title": "Design competition", "text": "Design competition\n\nA design competition is a competition in which an entity solicits design proposals from the public for a specified purpose.\n\nAn architectural design competition solicits architects to submit design proposals for a building, bridge, or other structure. Such competitions may be \"open\", receiving bids internationally, domestically, or regionally. The competition may occur in a single stage, or involve two stages, the first of which eliminates non-viable candidates.\n\nFamous early examples of design competitions were for the Acropolis of Athens in 448 BCE, and the dome of the Florence Cathedral in 1418.\n\nCoin and stamp design contests solicit designs to appear on the face of stamps and usually the obverse of coins. In 1998, the Royal Canadian Mint held the Millennium Coin Design Contest, a competition for the design of 24 quarters, one for each month of 1999 and 2000.\n\nThe design of artistic objects and monuments is a common subject in design competitions. A well-known example is the Vietnam Veterans Memorial in Washington D.C. designed by Maya Lin.\n\nUrban and landscape projects may solicit design proposals in a competition. Among them are projects for urban parks, streetscapes, and rehabilitation of natural areas.\n\nA student design competition is a student competition to introduce students to real-world engineering practices and design.\n"}
{"id": "10319663", "url": "https://en.wikipedia.org/wiki?curid=10319663", "title": "DigRF", "text": "DigRF\n\nThe DigRF working group was formed as a MIPI Alliance (MIPI) working group in April 2007. The group is focused on developing specifications for wireless mobile RFIC to base-band IC (BBIC) interfaces in mobile devices.\n\nThe group's current charter is split into short-term and long-term development efforts. The short-term development will focus on a specification targeted for completion by end of 2007 for LTE and WiMax air interface standards. The longer term development will focus on future air interface standards which promise further improvements in high speed, data optimized traffic. In addition, the future work will seek to harmonize efforts with the MIPI's PHY and UniPro working groups.\n\nThese specifications will describe the logical, electrical and timing characteristics of the digital RF-BB Interface with sufficient detail to allow physical implementation of the interface, and with sufficient rigor that implementations of the interface from different suppliers are fully compatible at the physical level.\n\nThere is DigRF version v1.12 for usage in GSM/EDGE handsets, which was specified in 2004. DigRF v3.09 from the year 2006 with its 312 Mbit/s can additionally handle UMTS. The present DigRF v4 draft offers Gbit/s bandwidth for LTE and WiMax.\n"}
{"id": "42861897", "url": "https://en.wikipedia.org/wiki?curid=42861897", "title": "Driven to refusal", "text": "Driven to refusal\n\nThis is an engineering term for describing how far to drive piles. It is also used in surveying when driving metal posts and monuments that usually mark the corners of properties.\n\nA rod or pile has been \"driven to refusal\" when five more blows of an adequate hammer will not budge the rod or pile.\n"}
{"id": "6795600", "url": "https://en.wikipedia.org/wiki?curid=6795600", "title": "End-user development", "text": "End-user development\n\nEnd-user development (EUD) or end-user programming (EUP) refers to activities and tools that allow end-users – people who are not professional software developers – to program computers. People who are not professional developers can use EUD tools to create or modify \"software artifacts\" (descriptions of automated behavior) and complex data objects without significant knowledge of a programming language. In 2005 it was estimated (using statistics from the U.S. Bureau of Labor Statistics) that by 2012 there would be more than 55 million end-user developers in the United States, compared with fewer than 3 million professional programmers. Various EUD approaches exist, and it is an active research topic within the field of computer science and human-computer interaction. Examples include natural language programming, spreadsheets, scripting languages (particularly in an office suite or art application), visual programming, trigger-action programming and programming by example.\n\nThe most popular EUD tool is the spreadsheet. Due to their unrestricted nature, spreadsheets allow relatively un-sophisticated computer users to write programs that represent complex data models, while shielding them from the need to learn lower-level programming languages. Because of their common use in business, spreadsheet skills are among the most beneficial skills for a graduate employee to have, and are therefore the most commonly sought after In the United States of America alone, there are an estimated 13 million end-user developers programming with spreadsheets\n\nThe programming by example (\"PbE\") approach reduces the need for the user to learn the abstractions of a classic programming language. The user instead introduces some examples of the desired results or operations that should be performed on the data, and the PbE system infers some abstractions corresponding to a program that produces this output, which the user can refine. New data may then be introduced to the automatically created program, and the user can correct any mistakes made by the program in order to improve its definition. Low-code development platforms are also an approach to EUD.\n\nOne evolution in this area has considered the use of mobile devices to support end-user development activities. In this case previous approaches for desktop applications cannot be simply reproposed, given the specific characteristics of mobile devices. Desktop EUD environments lack the advantages of enabling end users to create applications opportunistically while on the move. \n\nMore recently, interest in how to exploit EUD to support development of Internet of Things applications has increased. In this area trigger-action programming seems a promising approach. \n\nLessons learned from EUD solutions can significantly influence the software life cycles for commercial software products, in-house intranet/extranet developments and enterprise application deployments.\n\nRoughly 40 vendors now offer solutions targeted at end users designed to reduce programming efforts. These solutions do not require traditional programming and may be based around relatively narrow functionality, e.g. contract management, customer relationships management, issue and bug tracking. Often referred to as low code development platforms, web based interactions guide a user to develop an application in as little as 40-80 hours.\n\nLieberman et al. propose the following definition:\nEnd-User Development can be defined as a set of methods, techniques, and tools that allow users of software systems, who are acting as non-professional software developers, at some point to create, modify or extend a software artifact.Ko et al. propose the following definition:\n\nEnd-user programming is programming to achieve the result of a program primarily for personal, rather [than] public use.\n\nArtifacts defined by end users may be objects describing some automated behavior or control sequence, such as database requests or grammar rules, which can be described with programming paradigms such as programming by demonstration, programming with\nexamples, visual programming, or macro generation. They can also be parameters that choose between alternative predefined behaviors of an application. Other artifacts of end-user development may also refer to the creation of user-generated content such as annotations, which may be or not computationally interpretable (i.e. can be processed by associated automated functions).\n\nExamples of end-user development include the creation and modification of:\n\n\nAccording to Sutcliffe, EUD essentially outsources development effort to the end user. Because there is always some effort to learn an EUD tool, the users' motivation depends on their confidence that it will empower their work, save time on the job or raise productivity. In this model, the benefits to users are initially based on marketing, demonstrations and word-of-mouth. Once the technology is put into use, experience of actual benefits becomes the key motivator.\n\nThis study defines costs as the sum of:\n\n\nThe first and second costs are incurred once during acquisition, whereas the third and fourth are incurred every time an application is developed. Benefits (which may be perceived or actual) are seen as:\n\n\nMany end-user development activities are collaborative in nature, including collaboration between professional developers and end-user developers and collaboration among end-user developers.\n\nMutual development is a technique where professional developers and end-user developers work together in creating software solutions. In mutual development, the professional developers often “under design” the system and provide the tools to allow the “owners of problems\" to create the suitable solution at use time for their needs, objectives and situational contexts. Then the communication between professional developers and end-user developers can often stimulate formalizing ad hoc modifications by the end users into software artifacts, transforming end-user developed solutions into commercial product features with impacts beyond local solutions.\n\nIn this collaboration, various approaches such as the Software Shaping Workshop are proposed to bridge the communication gap between professional developers and end-user developers. These approaches often provide translucency according to the social translucence model, enabling everyone in the collaboration to be aware of changes made by others and to be held accountable of their actions because of the awareness.\n\nBesides programming collaboration platforms like GitHub, which are mostly utilized by expert developers due to their steep learning curve, collaborations among end-user developers often take place on wiki platforms where the software artifacts created are shared. End-user development is also often used for creating automation scripts or interactive tutorials for sharing “how-to” knowledge. Examples of such application include CoScripter and HILC. In such applications, user can create scripts for tasks using pseudo-natural language or via programming by demonstration. The users can choose to upload the script to a wiki style repository of scripts. On this wiki, users can browse available scripts and extend existing scripts to support additional parameters, to handle additional conditions or to operate on additional objects.\n\nOnline and offline communities of end-user developers have also been formed, where end-user developers can collaboratively solve EUD problems of shared interest or for mutual benefit. In such communities, local experts spread expertise and advice. Community members also provide social support for each other to support the collaborative construction of software.\n\nCommentators have been concerned that end users do not understand how to test and secure their applications. Warren Harrison, a professor of computer science at Portland State University, wrote:\n\nIt’s simply unfathomable that we could expect security... from the vast majority of software applications out there when they’re written with little, if any, knowledge of generally accepted good practices such as specifying before coding, systematic testing, and so on... How many X for Complete Idiots (where \"X\" is your favorite programming language) books are out there? I was initially amused by this trend, but recently I’ve become uneasy thinking about where these dabblers are applying their newfound knowledge.\n\nThis viewpoint assumes that all end users are equally naive when it comes to understanding software, although Pliskin and Shoval argue this is not the case, that sophisticated end users are capable of end-user development. However, compared with expert programmers, end-user programmers rarely have the time or interest in systematic and disciplined software engineering activities, which makes ensuring the quality of the software artifact produced by end-user development particularly challenging.\n\nIn response to this, the study of end-user software engineering has emerged. It is concerned with issues beyond end-user development, whereby end users become motivated to consider issues such as reusability, security and verifiability when developing their solutions.\n\nAn alternative scenario is that end users or their consultants employ declarative tools that support rigorous business and security rules at the expense of performance and scalability; tools created using EUD will typically have worse efficiency than those created with professional programming environments. Though separating functionality from efficiency is a valid separation of concerns, it can lead to a situation where end users will complete and document the requirements analysis and prototyping of the tool, without the involvement of business analysts. Thus, users will define the functions required before these experts have a chance to consider the limitations of a specific application or software framework. Senior management support for such end-user initiatives depends on their attitude to existing or potential vendor lock-in.\n\n\n\n"}
{"id": "14050219", "url": "https://en.wikipedia.org/wiki?curid=14050219", "title": "Field-sequential color system", "text": "Field-sequential color system\n\nA field-sequential color system (FSC) is a color television system in which the primary color information is transmitted in successive images and which relies on the human vision system to fuse the successive images into a color picture. One field-sequential system was developed by Dr. Peter Goldmark for CBS, which was its sole user in commercial broadcasting. It was first demonstrated to the press on September 4, 1940, and first shown to the general public on January 12, 1950. The Federal Communications Commission adopted it on October 11, 1950 as the standard for color television in the United States, but it was later withdrawn.\n\nThe use of sequential color systems for moving images predates the invention of fully electronic television. Although usually known at the time simply as \"additive\" rather than sequential color systems, two-color Kinemacolor, in commercial use since 1906, and its predecessor three-color format, invented by Edward Raymond Turner and patented in 1899, were both sequential natural color systems for use with motion picture film. They utilized black-and-white film and rotating color filter wheels to record the amount of each color in the scene on alternating frames of the film, so that when the frames were projected by light of similar colors at a sufficiently rapid rate, those colors blended together in the viewer's eye and produced a wider range of hues. Due to litigation by William Friese-Greene, Kinemacolor ended up in the public domain in 1915, after which several derivative sequential color processes (such as Friese-Greene's \"Biocolour\" and the original Prisma Color) were developed. Some were brought to the point of being publicly shown, but during the 1920s they could not compete with rival bipack and other subtractive color processes, which were free of color flicker and did not require special projection equipment—the final multicolored images were right there on the film as transparent coloring matter.\n\nThe CBS field-sequential system was an example of a mechanical television system because it relied in part on a disc of color filters rotating at 1440 rpm inside the camera and the receiver, capturing and displaying red, green, and blue television images in sequence. The field rate was increased from 60 to 144 fields per second to overcome the flicker from the separate color images, resulting in 24 complete color frames per second (each of the three colors was scanned twice, double interlacing being standard for all electronic television: 2 scans × 3 colors × 24 frames per second = 144 fields per second), instead of the standard 30 frames/60 fields per second of monochrome. If the 144-field color signal were transmitted with the same detail as a 60-field monochrome signal, 2.4 times the bandwidth would be required. Therefore, to keep the signal within the standard 6-MHz bandwidth of a channel, the image's vertical resolution was reduced from 525 lines to 405. The vertical resolution was 77% of monochrome, and the horizontal resolution was 54% of monochrome.\n\nBecause of these variances in resolution and frame rate from the NTSC standards for television broadcasting, field-sequential color broadcasts could not be seen on existing black and white receivers without an adapter (to see them in monochrome), or adapter-converter (to see them in color).\n\nCBS purchased its own television manufacturer in April 1951 when no other company would produce color sets using the system. Production of CBS-Columbia color receivers began in September; they were first offered for retail sale in October.\n\nField-sequential color broadcasts were suspended by CBS on October 21, 1951, ostensibly by request of the National Production Authority, which in November 1951 prohibited the manufacture of color sets for the general public during the Korean War. Only 200 color sets had been manufactured for commercial sale, and only 100 of those had shipped, when CBS suspended its color broadcasts. CBS announced in March 1953 that it had abandoned any further plans for its color system. RCA was the leading company in the television field, with a larger technical staff, more development funds, and more political success in getting the NTSC compatible color television system. RCA developed the hardware for NTSC which superseded the field-sequential system as the U.S. standard in December 1953.\n\nAccording to television historian Albert Abramson, A. A. Polumordvinov invented the first field-sequential color system. Polumordvinov applied for his Russian patent 10738 in 1899. This system scanned images with two rotating cylinders. A later German patent by A. Frankenstein and Werner von Jaworski described another field-sequential system. Like the CBS System, this patent included a color wheel. Frankenstein and Jaworski applied for their patent 172376 in 1904. This patent probably inspired John Logie Baird to use a similar color wheel in his system.\n\nJohn Logie Baird demonstrated a version of field-sequential color television on July 3, 1928, using a mechanical television system before his use of cathode ray tubes, and producing a vertical color image about 4 inches (10 cm) high. It was described in the journal \"Nature\":\n\nBaird demonstrated a modified two-color version in February 1938, using a red and blue-green filter arrangement in the transmitter; on July 27, 1939 he further demonstrated that color scanning system in combination with a cathode ray tube with filter wheel as the receiver.\n\nFor the first nine months of NTSC color in 1953–1954, CBS continued to use its field-sequential color television cameras, with the field rate and signal adapted for NTSC standards, until RCA delivered its first production model of an NTSC color camera in time for the 1954–55 season.\n\nThe Soviet Union was the only other country to experiment with a field-sequential color system. It manufactured a small number of color receivers in 1954 that used a mechanical color disc.\n\nThe field-sequential system was used in specialized applications long after it had been replaced for broadcast television. A notable user of the technology was NASA. Field-sequential color cameras were used on the Apollo lunar landing cameras which transmitted color television images from the Moon during missions from 1969 to 1972. Another system was used for the Voyager program in 1979, to take pictures and video of Jupiter. Early Space Shuttle flights (from 1981 to 1995) used cameras with interchangeable lenses. For color transmissions, a field-sequential color system was built into the lens assembly. For the NASA transmissions, the video from space was field sequential, converted by a duty cycle extension technique to component RGB color video on the ground, and thereafter converted to NTSC and other world standards like PAL and SECAM.\n\nModern day Digital Light Processing (DLP) projectors commonly use color wheels to generate color images, typically running at a multiple of the video frame rate.\n\nModern day LCD displays implement FSC by using several colors of LED backlight, by cycling the backlights, and gain several advantages such as brighter colors, darker blacks, and lower cost. These displays are used in LCD Camera viewfinders and other industrial applications.\n\n\n"}
{"id": "20762753", "url": "https://en.wikipedia.org/wiki?curid=20762753", "title": "Glass crusher", "text": "Glass crusher\n\nA glass crusher provides for pulverization of glass to a yield size of 2\" or less.\nRecycling operations may range from simple, manually-fed, self-contained machines to extravagant crushing systems complete with screens, conveyors, crushers and separators. All non-glass contaminants must generally be removed from the glass prior to recycling. The processes used in glass crushing for recycling involves the same methods used by the aggregate industry for crushing rock into sand (rock crusher).\n\nThe use of VSI crushers in large scale operations allow the production of up to 125 tons per hour of crushed glass cullet.\nVSI crushers use a high speed rotor with wear-resistant tips and a crushing chamber designed to 'throw' the glass against. The VSI crushers utilize velocity rather than surface force as the predominant force to break glass as this allows the breaking force to be applied evenly both across the surface of the material as well as through the mass of the material. In its shattered state, glass has a jagged and uneven surface. Applying surface force (pressure) results in unpredictable and typically non-cubicle particles. As glass is 'thrown' by a VSI rotor against a solid anvil, it fractures and breaks along fissures. Final particle size can be controlled by 1) the velocity at which the glass is thrown against the anvil and 2) the distance between the end of the rotor and the impact point on the anvil. The product resulting from VSI crushing is generally of a consistent cubicle shape which may optimize yield in consumptive applications such as the fabrication of fiberglass, ceramic ware, flux agents and abrasives. Due to the highly abrasive nature of the glass material, a VSI crushing process is generally preferred over Horizontal Shaft Impact and most other crushing methods with higher maintenance and lower wear part lives.\n\nVSI crushers generally utilize a high speed spinning rotor at the center of the crushing chamber and an outer impact surface of either abrasive resistant metal anvils or crushed glass (or rock in an aggregate applications). Utilizing cast metal surfaces 'anvils' are traditionally referred to as a \"Shoe and Anvil VSI\". Utilizing crushed material on the outer walls of the crusher for new material to be crushed against is traditionally referred to as \"rock on rock VSI\".\n\n"}
{"id": "4495067", "url": "https://en.wikipedia.org/wiki?curid=4495067", "title": "Hot wire barretter", "text": "Hot wire barretter\n\nThe hot wire barretter was a demodulating detector, invented in 1902 by Reginald Fessenden, that found limited use in early radio receivers. In effect it was a highly sensitive thermoresistor which could recover amplitude modulated signals, something that the coherer (the standard detector of the time) could not do.\n\nThe first device used to demodulate audio signals, it was later superseded by the electrolytic detector, also generally attributed to Fessenden. The barretter principle is still used as a detector for microwave radiation, similar to a bolometer.\n\nFessenden's 1902 patent describes the construction of the device. A fine platinum wire, about in diameter, is embedded in the middle of a silver tube having a diameter of about . This compound wire is then drawn until the silver wire has a diameter of about ; as the platinum wire within it is reduced in the same ratio, it is drawn down to a final diameter of . The result is called Wollaston wire.\n\nThe silver cladding is etched off a short piece of the composite wire, leaving an extremely fine platinum wire; this is supported, on two heavier silver wires, in a loop inside a glass bulb. The leads are taken out through the glass envelope and the whole device is put under vacuum and then sealed.\n\nThe hot wire barretter depends upon the increase of a metal's resistivity with increasing temperature. The device is biased by a direct current adjusted to heat the wire to its most sensitive temperature. When there is an oscillating current from the antenna through the extremely fine platinum wire loop, the wire is further heated as the current increases and cools as the current decreases again. As the wire heats and cools, it varies its resistance in response to the signals passing through it. Because of the low thermal mass of the wire, it is capable of responding quickly enough to vary its resistance in response to audio signals. However, it cannot vary its resistance fast enough to respond to the much higher radio frequencies. The radio frequencies are essentially removed, and the sound is demodulated because the current through the circuit varies with the changing wire resistance. Headphones are connected in series with the D.C. circuit and the variations in the current are rendered as sound.\n\n\n\n"}
{"id": "17583550", "url": "https://en.wikipedia.org/wiki?curid=17583550", "title": "Hugh Bradner", "text": "Hugh Bradner\n\nHugh Bradner (November 5, 1915 – May 5, 2008) was an American physicist at the University of California who is credited with inventing the neoprene wetsuit, which helped to revolutionize scuba diving.\n\nA graduate of Ohio's Miami University, he received his doctorate from California Institute of Technology in Pasadena, California, in 1941. He worked at the US Naval Ordnance Laboratory during World War II, where he researched naval mines. In 1943, he was recruited by Robert Oppenheimer to join the Manhattan Project at the Los Alamos Laboratory. There, he worked with scientists including Luis Alvarez, John von Neumann and George Kistiakowsky on the development of the high explosives and exploding-bridgewire detonators required by atomic bombs.\n\nAfter the war, Bradner took a position studying high-energy physics at the University of California, Berkeley, under Luis Alvarez. Bradner investigated the problems encountered by frogmen staying in cold water for long periods of time. He developed a neoprene suit which could trap the water between the body and the neoprene, and thereby keep them warm. He became known as the \"father of the wetsuit.\"\n\nBradner worked on the 1951 Operation Greenhouse nuclear test series on Enewetak Atoll in the Marshall Islands. He joined the Scripps Institute of Geophysics and Planetary Physics as a geophysicist in 1961. He remained there for the rest of his career, becoming a full professor in 1963, and retiring in 1980. In retirement, continued to work both on oceanographic research, as well as on the DUMAND deep ocean neutrino astronomy project.\n\nHugh Bradner was born in Tonopah, Nevada, on November 5, 1915, but he was raised in Findlay, Ohio. His father, Donald Byal Bradner, was briefly director of the Chemical Warfare Service at Maryland's Edgewood Arsenal. His mother was Agnes Claire Bradner née Mead. He had an older brother, Mead Bradner. Bradner graduated from Ohio's Miami University in 1936 and later received his doctorate from California Institute of Technology in Pasadena, California, in 1941, writing his thesis on \"Electron-optical studies of the photoelectric effect\" under the supervision of William Vermillion Houston.\n\nAfter receiving his doctorate from Caltech, Bradner worked at the US Naval Ordnance Laboratory where he researched naval mines until 1943. He was recruited by Robert Oppenheimer to join the Manhattan Project in 1943 at the Los Alamos Laboratory in New Mexico, which helped to develop the first atomic bomb. Bradner helped to develop a wide range of technology needed for the bomb, including research on the high explosives and exploding-bridgewire detonators needed to implode the atomic bomb, developed the bomb's triggering mechanism, and even helped design the new town around the laboratory. He worked closely with some of the most prominent scientists including Luis Alvarez, John von Neumann and George Kistiakowsky. He witnessed the Trinity test, the first nuclear weapons test, at Alamogordo on July 16, 1945.\n\nBradner met his future wife, Marjorie Hall Bradner, who was also working as a secretary on the Manhattan Project at the Los Alamos Laboratory. The couple were married in Los Alamos in 1943. Security at the top secret facility was so tight that neither Bradner's nor Hall's parents were allowed to attend the ceremony, though Oppenheimer was among the wedding guests. The couple remained together for over 65 years until she died on April 10, 2008 at the age of 89.\n\nAfter the war, Bradner took a position studying high-energy physics at the University of California, Berkeley under Luis Alvarez, whom he had worked with at the Manhattan Project. He remained at the University until 1961. He worked on the 1951 atomic bombing test on Enewetak Atoll in the Marshall Islands, which was part of the Operation Greenhouse nuclear test series.\nBradner's job at Berkeley required him to do a number of underwater dives. He had previously talked to United States Navy frogmen during World War II concerning the problems of staying in cold water for long periods of time, which causes the diver to lose large amounts of body heat quickly. He worked on developing a new suit that would counter this in the basement of his family's home on Scenic Avenue in Berkeley, California, and researched the new wetsuit at a conference in Coronado, California, in December 1951. According to the San Francisco Chronicle, the wetsuit was invented in 1952. Bradner and other engineers founded the Engineering Development Company (EDCO) in order to develop it. He and his colleagues tested several versions and prototypes of the wetsuit at the Scripps Institution of Oceanography in La Jolla, California. Scripps scientist and engineer Willard Bascom advised Bradner to use neoprene for the suit material, which proved successful. He found that it \"would trap the water between the body and the neoprene, and the water would heat up to body temperature and keep you warm\".\n\nA 1951 letter showed that Bradner clearly understood that the insulation in such a suit was not provided by the water between the suit and the skin, but rather that this layer of water next to the skin, if trapped, would quickly heat to skin temperature, if the material in the suit were insulative. Thus, the suit only needed to limit purging by fresh cold water, and it did not need to be dry to work. He applied for a U.S. patent for the wetsuit, but his patent application was turned down due to its similar design with the flight suit. The United States Navy also did not adopt the new wetsuits because of worries that the neoprene in the wetsuits might make its swimmers easier to spot by underwater sonar and, thus, could not exclusively profit from his invention.\n\nBradner and his company, EDCO, tried to sell his wetsuits in the consumer market. However, he failed to successfully penetrate the wetsuit market the way others have done - including Bob Meistrell and Bill Meistrell, the founders of Body Glove, and Jack O'Neill. Various claims have been made over the years that it was the O'Neill or the Meistrell brothers who actually invented the wetsuit instead of Bradner, but recent researchers have concluded that it was Bradner who created the original wetsuit, and not his competitors. In 2005 the \"Los Angeles Times\" concluded that Bradner was the \"father of the wetsuit\", and a research paper published by Carolyn Rainey at the Scripps Institution of Oceanography in 1998 provided corroborating evidence.\n\nBradner joined the Scripps Institute of Geophysics and Planetary Physics as a geophysicist in 1961.\nHe became a full professor in 1963 and retired in 1980. He remained interested in oceanography, scuba diving, seashell collecting and the outdoors throughout his later years, and continued to work both on oceanographic research, as well as on the DUMAND deep ocean neutrino astronomy project, which combined his two careers in physics and oceanography.\n\nHugh Bradner died at the age of 92 at his home in San Diego, California, on May 5, 2008, from complications of pneumonia. He was survived by his daughter, Bari Cornet, three grandchildren and one great-granddaughter.\n\n"}
{"id": "11993641", "url": "https://en.wikipedia.org/wiki?curid=11993641", "title": "Hydrocollator", "text": "Hydrocollator\n\nThe hydrocollator, first introduced in 1947 by the Chattanooga Pharmacal Company, consists of a thermostatically controlled water bath for placing bentonite-filled cloth heating pads. When the pads are removed from the bath, they are placed in covers and placed on the patient. The device is primarily used by athletic trainers and physical therapists.\n\nThe evidence behind the use of the hydrocollator is primarily concerned with achieving rapid heating of the tissue due to the more efficient transfer of energy through water as compared to air. There is some concern that hydrocollator treatment may be less effective with overweight or obese patients.\n\nHeating methods are used commonly in patients with acute pain. It is recommended that heating pads be used at home on acute injuries for short term pain relief.\n"}
{"id": "1459479", "url": "https://en.wikipedia.org/wiki?curid=1459479", "title": "Individual Computers", "text": "Individual Computers\n\nIndividual Computers is a German computer hardware company specializing in retrocomputing accessories for the Commodore 64, Amiga, and PC platforms. Individual Computers produced the C-One reconfigurable computer in 2003. The company is owned and run by Jens Schönfeld.\n\n\n"}
{"id": "1517434", "url": "https://en.wikipedia.org/wiki?curid=1517434", "title": "International Union of Food, Agricultural, Hotel, Restaurant, Catering, Tobacco and Allied Workers' Association", "text": "International Union of Food, Agricultural, Hotel, Restaurant, Catering, Tobacco and Allied Workers' Association\n\nThe International Union of Food, Agricultural, Hotel, Restaurant, Catering, Tobacco and Allied Workers' Associations (IUF) is a global union federation of trade unions with members in a variety of industries, many of which relate to food processing.\n\nThe federation was founded in 1920 with the merger of three international organisations, representing bakers, brewers, and meat industry employees. Originally named the International Union of Food and Allied Workers' Associations (IUFAWA), it affiliates were all European until 1950, but it then rapidly expanded worldwide. By 1978, the federation was known as the IUF, and it had 2.1 million members.\n\nDuring the 1980s, the IUF campaigned against Coca-Cola, which it believed was exploiting plantation workers. In 1994, it merged with the International Federation of Plantation, Agricultural and Allied Workers, and took its present name. From 1997, it began signing collective bargaining agreements with various multinational companies.\n\nIn 2017, the IUF was composed of 430 member organisations in 130 countries, representing more than 12 million workers.\n\nThe organization represents workers employed in agriculture, the preparation and manufacture of food and beverages, hotels, restaurants and catering services and in tobacco processing.\n\nThe international headquarters of IUF is located in Geneva, Switzerland. Within the organization, there are autonomous regional organizations for Africa, Asia/Pacific, the Caribbean, Europe and Latin America.\n\n"}
{"id": "46773398", "url": "https://en.wikipedia.org/wiki?curid=46773398", "title": "Loci Controls", "text": "Loci Controls\n\nLoci Controls, Inc. is a developer of wireless sensor and actor network (WSAN) devices. Loci Controls develops hardware and software utilizing a wireless sensor network to optimize the extraction of methane from landfills through better landfill gas monitoring,\n\nThe company was founded by two MIT graduates, Andrew Campanella and Melinda Hale in 2012. Loci Controls received a grant from the Massachusetts Clean Energy Center in the amount of $40,000 USD in January 2014 as a partial section of its Catalyst Program. The program invests in new researchers and companies.\n\nLoci's technology is designed for energy producing landfills, by harvesting potentially toxic methane gas from landfills and has shown to increase efficiency by 25% in at least one location. The software and hardware provides an advancement over the existing technology that requires on-site monitoring and adjustments to optimally extract the methane utilizing wireless sensor networks. \"The Loci system offers tailored alerts, a custom algorithm that predicts needed adjustments to the gas collection system, and automatic controls to monitor gas production.\" The reduction in methane results in less pollution, toxins and odors.: With the Loci Controls solution, revenue from landfill gas-to-energy plants is increased, risk of noncompliance is mitigated, and odor complaints can be instantly addressed.\"\n\n"}
{"id": "25791266", "url": "https://en.wikipedia.org/wiki?curid=25791266", "title": "Marine sandglass", "text": "Marine sandglass\n\nA marine sandglass is a timepiece of simple design that is a relative of the common hourglass, a marine (nautical) instrument known since the 14th century (although reasonably presumed to be of very ancient use and origin). They were employed to measure the time at sea or on a given navigational course, in repeated measures of small time increments (e.g., 30 minutes). Used together with the chip log, smaller marine sandglasses were also used to measure the boat speed through the water in knots.\n\nAlthough vital to maritime navigation, marine sandglasses were not accurate measuring instruments for the passage of time; many design and environmental factors could affect the duration of sand's flow, and therefore its reported time. Their use continued through the early 19th century, when they were supplanted by reliable mechanical timepieces, and by other advances in marine navigation.\n\nMarine sandglasses were very popular on board ships, as they were the most dependable measurement of time while at sea. Unlike the clepsydra, the motion of the ship while sailing did not affect the hourglass. The fact that the hourglass also used granular materials instead of liquids gave it more accurate measurements, as the clepsydra was prone to get condensation inside it during temperature changes. In conjunction with a record of a ship's speed and direction, seamen used the hourglass to determine their position with reasonable accuracy.\n\nMarine sandglasses originally consisted of two glass bottles one inverted above the other, connected by a small tube, with the ends wrapped and so joined together. Over time, the later progress in the art of glassblowing allowed them to be made in a single piece. The marine glass was filled with sand or a suitable material such as finely ground eggshell, lead or tin chips (used to avoid humidity). This flowing material was chosen with two main objectives: to avoid the humidity and to absorb motion, both required for shipboard use.\n\nPlaced in the upper half, the sand would flow slowly and steadily towards the lower half by the action of gravity, taking a certain time to empty (that was calibrated during their design and manufacture). Once the upper portion of the glass was empty, the glass could be turned to measure another time period.\n\nThe origin of the hourglass is unclear, although unlike its predecessor the clepsydra, or water clock, which may have been invented in ancient Egypt, the first referenced use:\n\nFrom the Roman time it disappears completely from historical records until it is re-introduced in medieval Europe. By the 8th century it is mentioned by a monk named Luitprand, who served at the cathedral of Chartres, France. But it was not until the 14th century that the marine sandglass was seen commonly, the earliest firm evidence being a depiction in the 1338 fresco \"Allegory of Good Government\" by Ambrogio Lorenzetti.\n\nUse of the marine sandglass has been recorded since the 14th century; The written records about it were mostly from logbooks of European ships. In the same period it appears in other records and lists of ships stores. The earliest recorded reference that can be said with certainty to refer to a marine sandglass dates from c. 1345, in a receipt of Thomas de Stetesham, clerk of the King's ship \"La George\", in the reign of Edward III of England; translated from the Latin, the receipt says: in 1345:\nThe same Thomas accounts to have paid at Lescluse, in Flanders, for twelve glass horologes (\" pro xii. orlogiis vitreis \"), price of each 4½ gross', in sterling 9\"s.\" Item, For four horologes of the same sort (\" de eadem secta \"), bought there, price of each five gross', making in sterling 3\"s.\" 4\"d.\" \nAnother reference is found in an extensive inventory of the property of Charles V of France in his possession at the time of his death on September 16, 1380. One item is an hourglass from the king's study at his castle of St. Germain en Laye, described as follows:\nThis \"orloge de mer\" or \"heures de naviguer\" was sent to him, as a present, when he still was a prince (being therefore prior to 1356 when he took the place of his imprisoned father), by his aunt Yolande of Aragon, when asking him for a manuscript of John de Mandeville, to be translated to the Aragonese tongue.\n\nThe most interesting thing about the second reference, the one from King Charles, is that a common sand-glass is defined as \"ung grant orloge de mer\" or \"a large sea clock\", this together with the fact that the first explanation of its use at sea (found by M.Llauradó) appears in the Francesc Eiximenis work \"lo dotzé del crestià\" and that was given to him as a present by his aunt Yolande of Aragon, suggests that, at this period, the importance of a sand-glass was more commonly related to its use at sea and its fabrication demand may have been originated from the navigational needs from the Crown of Aragon a maritime power of the moment in the Mediterranean.\n\nIn long-distance navigation through the open ocean, the sandglass or \"glass\" used to measure the time was a tool as important as the compass (which indicated sailing direction, and so ship's course). Filled with the amount of sand suitable for measuring a lapse of half an hour, each time the sand emptied was also called a \"glass\"; eight glasses (four hours) defined a \"watch\". The times determined by the sandglass, along with the record in the logbook of the speed measured with the \"chip log\", permitted the ship's navigator to plot his map position. Multiplying the ship's speed by the time the course had been kept (measured with the glass), gave traveled distance, a simple, overall method termed dead reckoning.\n\nThe marine sandglass was critical for maritime navigation before the 19th century. At the beginning of that century it became possible to navigate by the lunar distances, thanks to the tables of haversines of Joseph de Mendoza y Ríos. Prior to this, dead reckoning navigation based on sandglass-determined times was used, alongside determination of latitude using the quadrant (see also backstaff, astrolabe, and octant); this was the only system available to mariners to navigate the globe. The parallel use of relative time measurements at sea, and time measurement by mechanical clocks on land continued from at least 1350 to 1805, i.e., for more than 450 years.\n\nAlthough vital to navigation, the marine glass was not an accurate instrument to measure the passage of time. The design of the glass affected its accuracy in time measurement; the uniformity in fineness of the sand, the inner diameter of the connecting tube, and design aspects allowing wear that would effect the flow of sand all could contribute. In addition, many shipboard factors could affect the duration of sand's flow and therefore influence the time measured, including the humidity inside the glass, the ability for it to be positioned in a perfectly vertical position, and the acceleration or deceleration of the ship's movements. Finally, the use of short duration glasses to measure long periods of time introduced further error. Marine glass use was supplanted by reliable mechanical timepieces, and by other advances in marine navigation.\n\nWatch sandglasses were used on ships to measure watch times, typically in half-hour periods. The helmsman or ship's page were the crewmen responsible for turning the watch sandglass, thus supplying the time to be registered on the ship's log; watch measurement began with the sun reaching its highest point—its zenith—at midday, which was likewise the essential time reference point for navigation. At that point in time, the ship's bell was struck eight times; after the first glass had emptied (half an hour), the ship's bell was struck once, after another glass, twice, and so on until four hours after midday, when it was again struck eight times. At that point, a new watch began, and the sequence was repeated.\n\nHence, in the voyages of Columbus, there are records that his crew logged the passage of time using a half-hour \"ampolleta\" (glass) that was turned every time it emptied to keep track of the \"canonical\" hours. Likewise, during the voyage of Ferdinand Magellan to circumnavigate the globe, 18 hourglasses from Barcelona were in the ship's inventory, after the trip being authorized by emperor Charles V.\n\nFrom the 16th century a much smaller 30-second \"glass\" was used along with the chip log, to measure the speed (in knots) of the vessel over the water. The procedure was as follows:\n\n"}
{"id": "1569089", "url": "https://en.wikipedia.org/wiki?curid=1569089", "title": "Membrane gas separation", "text": "Membrane gas separation\n\nGas mixtures can be effectively separated by synthetic membranes made from polymers such as polyamide or cellulose acetate, or from ceramic materials.\nWhile polymeric membranes are economical and technologically useful, they are bounded by their performance, known as the Robeson limit (permeability must be sacrificed for selectivity and vice versa). This limit affects polymeric membrane use for CO separation from flue gas streams, since mass transport becomes limiting and CO2 separation becomes very expensive due to low permeabilities. Membrane materials have expanded into the realm of silica, zeolites, metal-organic frameworks, and perovskites due to their strong thermal and chemical resistance as well as high tunability (ability to be modified and functionalized), leading to increased permeability and selectivity. Membranes can be used for separating gas mixtures where they act as a permeable barrier through which different compounds move across at different rates or not move at all. The membranes can be nanoporous, polymer, etc. and the gas molecules penetrate according to their size, diffusivity, or solubility.\n\nThere are 3 main diffusion mechanisms, the first (b), Knudsen diffusion holds at very low pressures where lighter molecules can move across a membrane faster than heavy ones, in a material with reasonably large pores. The second (c), molecular sieving, is the case where the pores of the membrane are too small to let one component pass, a process which is typically not practical in gas applications, as the molecules are too small to design relevant pores. In these cases the movement of molecules is best described by pressure-driven convective flow through capillaries, which is quantified by Darcy’s Law. However, the more general model in gas applications is the solution-diffusion (d) where particles are first dissolved onto the membrane and then diffuse through it both at different rates. This model is employed when the pores in the polymer membrane appear and disappear faster relative to the movement of the particles.\n\nIn a typical membrane system the incoming feed stream is separated into two components: permeant and retentate. Permeant is the gas that travels across the membrane and the retentate is what is left of the feed. On both sides of the membrane, a gradient of chemical potential is maintained by a pressure difference which is the driving force for the gas molecules to pass through. The ease of transport of each species is quantified by the permeability, P. With the assumptions of ideal mixing on both sides of the membrane, ideal gas law, constant diffusion coefficient and Henry’s Law, the flux of a species can be related to the pressure difference by Fick’s Law:\n\nwhere, (J) is the molar flux of species i across the membrane, (l) is membrane thickness, (P) is permeability of species i, (D) is diffusivity, (K) is the Henry coefficient, and (p) and (p) represent the partial pressures of the species i at the feed and permeant side respectively. The product of DK is often expressed as the permeability of the species i, on the specific membrane being used.\n\nThe flow of a second species, j, can be defined as:\n\nWith the expression above, a membrane system for a binary mixture can be sufficiently defined. it can be seen that the total flow across the membrane is strongly dependent on the relation between the feed and permeate pressures. The ratio of feed pressure (p) over permeate pressure (p) is defined as the membrane pressure ratio (θ).\n\nIt is clear from the above, that a flow of species i or j across the membrane can only occur when:\n\nIn other words, the membrane will experience flow across it when there exists a concentration gradient between feed and permeate. If the gradient is positive, the flow will go from the feed to the permeate and species i will be separated from the feed.\n\nTherefore, the maximum separation of species i results from:\n\nAnother important coefficient when choosing the optimum membrane for a separation process is the membrane selectivity α defined as the ratio of permeability of species i with relation to the species j.\n\nThis coefficient is used to indicate the level to which the membrane is able to separates species i from j. It is obvious from the expression above, that a membrane selectivity of 1 indicates the membrane has no potential to separate the two gases, the reason being, both gases will diffuse equally through the membrane.\n\nIn the design of a separation process, normally the pressure ratio and the membrane selectivity are prescribed by the pressures of the system and the permeability of the membrane . The level of separation achieved by the membrane (concentration of the species to be separated) needs to be evaluated based on the aforementioned design parameters in order to evaluate the cost effectiveness of the system.\n\nThe concentration of species i and j across the membrane can be evaluated based on their respective diffusion flows across it.\n\nIn the case of a binary mixture, the concentration of species i across the membrane:\n\nThis can be further expanded to obtain an expression of the form:\n\nUsing the relations:\n\nThe expression can be rewritten as:\n\nThen using formula_16\n\nThe solution to the above quadratic expression can be expressed as:\n\nFinally, an expression for the permeant concentration is obtained by the following:\n\nAlong the separation unit, the feed concentration decays with the diffusion across the membrane causing the concentration at the membrane to drop accordingly. As a result, the total permeant flow (q\") results from the integration of the diffusion flow across the membrane from the feed inlet (q') to feed outlet (q'). A mass balance across a differential length of the separation unit is therefore:\n\nwhere:\n\nBecause of the binary nature of the mixture, only one species needs to be evaluated. Prescribing a function n'=n'(x), the species balance can be rewritten as:\n\nWhere:\n\nLastly, the area required per unit membrane length can be obtained by the following expression:\n\nThe material of the membrane plays an important role in its ability to provide the desired performance characteristics. It is optimal to have a membrane with a high permeability and sufficient selectivity and it is also important to match the membrane properties to that of the system operating conditions (for example pressures and gas composition).\n\nSynthetic membranes are made from a variety of polymers including polyethylene, polyamides, polyimides, cellulose acetate, polysulphone and polydimethylsiloxan.\n\nPolymeric membranes are a common option for use in the capture of CO from flue gas because of the maturity of the technology in a variety of industries, namely petrochemicals. The ideal polymer membrane has both a high selectivity and permeability. Polymer membranes are examples of systems that are dominated by the solution-diffusion mechanism. The membrane is considered to have holes which the gas can dissolve (solubility) and the molecules can move from one cavity to the other (diffusion).\n\nIt was discovered by Robeson in the early 1990s that polymers with a high selectivity have a low permeability and opposite is true; materials with a low selectivity have a high permeability. This is best illustrated in a Robeson plot where the selectivity is plotted as a function of the CO permeation. In this plot, the upper bound of selectivity is approximately a linear function of the permeability. It was found that the solubility in polymers is mostly constant but the diffusion coefficients vary significantly and this is where the engineering of the material occurs. Somewhat intuitively, the materials with the highest diffusion coefficients have a more open pore structure, thus losing selectivity. There are two methods that researchers are using to break the Robeson limit, one of these is the use of glassy polymers whose phase transition and changes in mechanical properties make it appear that the material is absorbing molecules and thus surpasses the upper limit. The second method of pushing the boundaries of the Robeson limit is by the facilitated transport method. As previously stated, the solubility of polymers is typically fairly constant but the facilitated transport method uses a chemical reaction to enhance the permeability of one component without changing the selectivity.\n\nNanoporous membranes are fundamentally different than polymer-based membranes in that their chemistry is different and that they do not follow the Robeson limit for a variety of reasons. The simplified figure of a nanoporous membrane shows a small portion of an example membrane structure with cavities and windows. The white portion represents the area where the molecule can move and the blue shaded areas represent the walls of the structure. In the engineering of these membranes, the size of the cavity (L x L) and window region (L x L) can be modified so that the desired permeation is achieved. It has been shown that the permeability of a membrane is the production of adsorption and diffusion. In low loading conditions, the adsorption can be computed by the Henry coefficient.\n\nIf the assumption is made that the energy of a particle does not change when moving through this structure, only the entropy of the molecules changes based on the size of the openings. If we first consider changes the cavity geometry, the larger the cavity, the larger the entropy of the absorbed molecules which thus makes the Henry coefficient larger. For diffusion, an increase in entropy will lead to a decrease in free energy which in turn leads to a decrease in the diffusion coefficient. Conversely, changing the window geometry will primarily effect the diffusion of the molecules and not the Henry coefficient.\n\nIn summary, by using the above simplified analysis, it is possible to understand why the upper limit of the Robeson line does not hold for nanostructures. In the analysis, both the diffusion and Henry coefficients can be modified without affecting the permeability of the material which thus can exceed the upper limit for polymer membranes.\n\nSilica membranes are mesoporous and can be made with high uniformity (the same structure throughout the membrane). The high porosity of these membranes gives them very high permeabilities. Synthesized membranes have smooth surfaces and can be modified on the surface to drastically improve selectivity. Functionalizing silica membrane surfaces with amine containing molecules (on the surface silanol groups) allows the membranes to separate CO from flue gas streams more effectively. Surface functionalization (and thus chemistry) can be tuned to be more efficient for wet flue gas streams as compared to dry flue gas streams. While previously, silica membranes were impractical due to their technical scalability and cost (they are very difficult to produce in an economical manner on a large scale), there have been demonstrations of a simple method of producing silica membranes on hollow polymeric supports. These demonstrations indicate that economical materials and methods can effectively separate CO and N. Ordered mesoporous silica membranes have shown considerable potential for surface modification that allows for ease of CO separation. Surface functionalization with amines leads to the reversible formation of carbamates (during CO flow), increasing CO selectivity significantly.\n\nZeolites are crystalline aluminosilicates with a regular repeating structure of molecular-sized pores. Zeolite membranes selectively separate molecules based on pore size and polarity and are thus highly tunable to specific gas separation processes. In general, smaller molecules and those with stronger zeolite-adsorption properties are adsorbed onto zeolite membranes with larger selectivity. The capacity to discriminate based on both molecular size and adsorption affinity makes zeolite membranes an attractive candidate for CO separation from N, CH, and H.\n\nScientists have found that the gas-phase enthalpy (heat) of adsorption on zeolites increases as follows: H < CH < N < CO. It is generally accepted that CO has the largest adsorption energy because it has the largest quadrupole moment, thereby increasing its affinity for charged or polar zeolite pores. At low temperatures, zeolite adsorption-capacity is large and the high concentration of adsorbed CO molecules blocks the flow of other gases. Therefore, at lower temperatures, CO selectively permeates through zeolite pores. Several recent research efforts have focused on developing new zeolite membranes that maximize the CO selectivity by taking advantage of the low-temperature blocking phenomena.\n\nResearchers have synthesized Y-type (Si:Al>3) zeolite membranes which achieve room-temperature separation factors of 100 and 21 for CO/N and CO/CH mixtures respectively. DDR-type and SAPO-34 membranes have also shown promise in separating CO and CH at a variety of pressures and feed compositions.\n\nThere have been advances in zeolitic-imidazolate frameworks (ZIFs), a subclass of metal-organic frameworks (MOFs), that have allowed them to be useful for carbon dioxide separation from flue gas streams. Extensive modeling has been performed to demonstrate the value of using MOFs as membranes. MOF materials are adsorption-based, and thus can be tuned to achieve selectivity. The drawback to MOF systems is stability in water and other compounds present in flue gas streams. Select materials, such as ZIF-8, have demonstrated stability in water and benzene, contents often present in flue gas mixtures. ZIF-8 can be synthesized as a membrane on a porous alumina support and has proven to be effective at separating CO from flue gas streams. At similar CO/CH selectivity to Y-type zeolite membranes, ZIF-8 membranes achieve unprecedented CO permeance, two orders of magnitude above the previous standard.\nPerovskite are mixed metal oxide with a well-defined cubic structure and a general formula of ABO, where A is an alkaline earth or lanthanide element and B is a transition metal. These materials are attractive for CO separation because of the tunability of the metal sites as well as their stabilities at elevated temperatures.\n\nThe separation of CO from N was investigated with an α-alumina membrane impregnated with BaTiO. It was found that adsorption of CO was favorable at high temperatures due to an endothermic interaction between CO and the material, promoting mobile CO that enhanced CO adsorption-desorption rate and surface diffusion. The experimental separation factor of CO to N was found to be 1.1-1.2 at 100C to 500C, which is higher than the separation factor limit of 0.8 predicted by Knudsen diffusion. Though the separation factor was low due to pinholes observed in the membrane, this demonstrates the potential of perovskite materials in their selective surface chemistry for CO separation.\n\nIn special cases other materials can be utilized; for example, palladium membranes permit transport solely of hydrogen. In addition to palladium membranes (which are typically palladium silver alloys to stop embrittlement of the alloy at lower temperature) there is also a significant research effort looking into finding non-precious metal alternatives. Although slow kinetics of exchange on the surface of the membrane and tendency for the membranes to crack or disintegrate after a number of duty cycles or during cooling are problems yet to be fully solved.\n\nMembranes are typically contained in one of three modules:\n\nMembranes are employed in:\n\nA great deal of research has been undertaken to utilize membranes instead of absorption or adsorption for carbon capture from flue gas streams, however, no current projects exist that utilize membranes. Process engineering along with new developments in materials have shown that membranes have the greatest potential for low energy penalty and cost compared to competing technologies.\n\nToday, membranes are used for commercial separations involving: N from air, H from ammonia in the Haber-Bosch process, natural gas purification, and tertiary-level Enhanced Oil Recovery supply.\n\nSingle-stage membrane operations involve a single membrane with one selectivity value. Single-stage membranes were first used in natural gas purification, separating CO from methane. A disadvantage of single-stage membranes is the loss of product in the permeate due to the constraints imposed by the single selectivity value. Increasing the selectivity reduces the amount of product lost in the permeate, but comes at the cost of requiring a larger pressure difference to process an equivalent amount of a flue stream. In practice, the maximum pressure ratio economically possible is around 5:1.\n\nTo combat the loss of product in the membrane permeate, engineers use “cascade processes” in which the permeate is recompressed and interfaced with additional, higher selectivity membranes. The retentate streams can be recycled, which achieves a better yield of product.\n\nSingle stage membranes devices are not feasible for obtaining a high concentration of separated material in the permeate stream. This is due to the pressure ratio limit that is economically unrealistic to exceed. Therefore, the use of multi stage membranes is required to concentrate the permeate stream. The use of a second stage allows for less membrane area and power to be used. This is because of the higher concentration that passes the second stage, as well as the lower volume of gas for the pump to process. Other factors, such as adding another stage that uses air to concentrate the stream further reduces cost by increasing concentration within the feed stream. Additional methods such as combining multiple types of separation methods allow for variation in creating economical process designs.\n\nHybrid processes have long standing history with gas separation. Typically, membranes are integrated into already existing processes such that they can be retrofitted into already existing carbon capture systems.\n\nMTR, Membrane Technology and Research Inc., and UT Austin have worked to create hybrid processes, utilizing both absorption and membranes, for CO capture. First, an absorption column using piperazine as a solvent absorbs about half the carbon dioxide in the flue gas, then the use of a membrane results in 90% capture. A parallel setup is also, with the membrane and absorption processes occurring simultaneously. Generally, these processes are most effective when the highest content of carbon dioxide enters the amine absorption column. Incorporating hybrid design processes allows for retrofitting into fossil fuel power plants.\n\nHybrid processes can also use cryogenic distillation and membranes. For example, hydrogen and carbon dioxide can be separated, first using cryogenic gas separation, whereby most of the carbon dioxide exits first, then using a membrane process to separate the remaining carbon dioxide, after which it is recycled for further attempts at cryogenic separation.\n\nCost limits the pressure ratio in a membrane CO separation stage to a value of 5; higher pressure rations eliminate any economic viability for CO capture using membrane processes. Recent studies have demonstrated that multi-stage CO capture/separation processes using membranes can be economically competitive with older and more common technologies such as amine-based absorption. Currently, both membrane and amine-based absorption processes can be designed to yield a 90% CO capture rate. For carbon capture at an average 600 MW coal-fired power plant, the cost of CO capture using amine-based absorption is in the $40–100 per ton of CO range, while the cost of CO capture using current membrane technology (including current process design schemes) is about $23 per ton of CO. Additionally, running an amine-based absorption process at an average 600 MW coal-fired power plant consumes about 30% of the energy generated by the power plant, while running a membrane process requires about 16% of the energy generated. CO transport (e.g. to geologic sequestration sites, or to be used for EOR) costs about $2–5 per ton of CO. This cost is the same for all types of CO capture/separation processes such as membrane separation and absorption. In terms of dollars per ton of captured CO, the least expensive membrane processes being studied at this time are multi-step counter-current flow/sweep processes.\n\n"}
{"id": "13783191", "url": "https://en.wikipedia.org/wiki?curid=13783191", "title": "Mint.com", "text": "Mint.com\n\nMint.com is a free, web-based personal financial management service for the US and Canada, created by Aaron Patzer. Mint originally provided account aggregation through a deal with Yodlee, but has since moved to using Intuit for connecting to accounts. Mint's primary service allows users to track bank, credit card, investment, and loan balances and transactions through a single user interface, as well as create budgets and set financial goals. In 2009, Mint was acquired by Intuit, the makers of Quicken and TurboTax.\n\nAs of 2010, Mint.com claims to connect with more than 16,000 US and Canadian financial institutions, and to support more than 17 million individual financial accounts. , Mint.com claimed to have more than 10 million users. In 2016, Mint.com claimed to have over 20 million users.\n\nMint raised over $31M in venture capital funding from DAG Ventures, Shasta Ventures, and First Round Capital, as well as from angel investors including Ram Shriram, an early investor in Google. The latest round of $14M was closed on August 4, 2009, and reported by CEO Aaron Patzer as preemptive. TechCrunch later pegged the valuation of Mint at $140M.\n\nIn February 2008, revenue was generated through lead generation, earned via earning referral fees from recommendations of highly personalized, targeted financial products to its users.\n\nOn September 13, 2009, TechCrunch reported Intuit would acquire Mint for $170 million. An official announcement was made the following day.\n\nOn November 2, 2009, Intuit announced their acquisition of Mint.com was complete. The former CEO of Mint.com, Aaron Patzer, was named Vice President and General Manager of Intuit’s personal finance group, responsible for Mint.com and all Quicken online, desktop, and mobile offerings. Patzer further added the features of the online product Mint.com would be incorporated into the Quicken desktop product, and vice versa, as two collaborative aspects of the Intuit Personal Finance team. Patzer left Intuit in December 2012.\n\nMint asks users to provide both the user names and the passwords to their bank accounts, credit cards, and other financial accounts, which Mint then stores in their databases in a decryptable format. This has raised concerns that if the Mint databases were ever hacked, both user names and passwords would become available to rogue third parties. Some banks support a separate \"access code\" for read-only access to financial information, which reduces the risk to some degree.\n\nIn January 2017, Intuit and JPMorgan Chase settled a longstanding dispute, and agreed to develop software where Chase customers send their data, for financial purposes, to Mint without having Intuit store customers' names and passwords. It was also agreed Intuit would never sell Chase’s customer data.\n\n\n"}
{"id": "2759083", "url": "https://en.wikipedia.org/wiki?curid=2759083", "title": "Monomolecular wire", "text": "Monomolecular wire\n\nMonomolecular wire is a type of wire consisting of a single strand of strongly bonded atoms or molecules, like carbon nanotubes.\n\nOrganic molecular wires have been proposed for use in optoelectronics.\n\nSilver is ductile enough to be stretched into a monatomic wire.\n\nMonomolecular wire is often used as a weapon in fiction. It has applications in cutting objects and severing adjacent molecules. A similar or identical concept may be called a microfilament wire or, as a weapon, a microfilament whip.\n\nAmong the first references in fiction to a monofilament is in John Brunner's \"Stand on Zanzibar\" (1968), where hobby terrorists deploy this over-the-shelf General Technics product across roads to kill or injure the people passing there. According to Brunner, the monofilament will easily cut through glass, metal and flesh, but in any non-strained structure the molecules will immediately rebond. No harm is done if the cut object is not under mechanical stress.\n\nAn early example of a substance similar to monomolecular wire is 'borazon-tungsten filament' from G. Randall Garrett's \"Thin Edge.\" (Analog, Dec 1963) The main character uses a strand from an asteroid towing-cable to cut jail bars and to booby-trap the door of his room. Frank Herbert later described shigawire in his \"Dune\" novels. First making its appearance in \"Dune\" (1965), shigawire is a metallic extrusion produced naturally from a ground vine found on the planets Salusa Secundus and III Delta Kaising. It varies in diameter from approximately 1.5 cm down to monomolecular (micronic) diameters, and is notable for its incredible tensile and mechanical strength.\nShigawire is able to cut through almost any material cleanly, possessing edges that are incredibly sharp. It is a weapon of choice for assassins.\n\nMonomolecular wire is a plot element in the short story \"Johnny Mnemonic\" by William Gibson. The assassin following the protagonist has a diamond spindle of monomolecular wire (or filament) implanted in his thumb, the idea being that diamond is also made of a single molecule and thus hard enough to not be cut by a monomolecular wire. The top of a prosthesis, attached to the other side of the wire, was used as a weight and the wire could be used as a whip-like weapon or a garotte.\n\nMonomolecular wire (in the form of wide 'tapes' of a \"pseudo-one-dimensional modified diamond crystal\") is used as the basic building material of the space elevator in Arthur C. Clarke's novel \"The Fountains of Paradise\".\n\nMonomolecular wires are seen in the \"Star Wars\" expanded universe, \"Cyber City Oedo 808\", \"Hyperion Cantos\", Robert J. Sawyer's \"Illegal Alien\", \"Battle Angel Alita\", \"Naruto\", \"Akame ga Kill\", \"Hellsing\", \"Trinity Blood\", \"My-Hime\", Vampire Knight, Simon R. Green's \"Deathstalker\" series, Alastair Reynolds's \"Revelation Space\" universe, as well as the roleplaying games \"Shadowrun\", \"One Piece\" as Doflamingo's string-string devil fruit and \"Cyberpunk 2020\". Monomolecular wires are also seen in Larry Niven's \"Known Space\" universe as human-produced \"Sinclair Molecule Chain\".\n\nIn the One Piece manga, the character Donquixote Doflamingo ate the Ito Ito no Mi, a devil fruit that grants the user the ability to create and manipulate strings. He is capable of creating strings so thin that they cannot be seen, and he can use this ability to ensnare people and control them like a puppet. His strings are also incredibly strong, being able to cut through stone with ease.\n\nVarious Imperial and alien technologies in the \"Warhammer 40,000\" universe use monomolecular blades or wire offensively. Possibly the most notable example are Eldar Warp Spiders, whose Deathspinner weaponry traps targets in a mesh of such filaments or the Dark Eldar Shredder weapon which shoots meshes of it.\n\nThe game Chaos Overlords featured a weapon 'monom rod' which used this technology.\n\nSion Eltnam Atlasia wields a monofilament whip called the Etherlite in Melty Blood. \n\nIn the 2000 film \"XChange\", the main character acquires an Urban survival Kit which includes a monomolecular wire.\n\nMonomolecular swords are used by some Kzin in Larry Niven's \"Known Space\" series.\n\nMonomolecular wire ranks 14th on IGN's list of the \"25 Coolest Sci-Fi weapons\".\n"}
{"id": "1356243", "url": "https://en.wikipedia.org/wiki?curid=1356243", "title": "Moshe Bar (investor)", "text": "Moshe Bar (investor)\n\nMoshe Bar (born in Jerusalem, Israel in June 1971) is an Israeli author, investor and entrepreneur.\n\nHe is currently a general partner of Texas Atlantic Capital LP, a venture capital company. He was previously a co-founder of Qumranet. Qumranet was sold to Red Hat in 2008 for US$ 107 million. \n\nHe previously founded the company behind the Xen software, XenSource, which was sold to Citrix for US$ 500 million in 2007. Before that he founded Qlusters Inc, and was the founder, main developer and project manager of openMosix. Furthermore, he frequently acts as an angel investor in high-tech start-up companies such as Hyper9, Neebula, and Qlayer, which was sold to Sun Microsystems in January 2009.\n\nThe author of several books on Linux, file systems and open source development, he was also a senior editor at \"Byte Magazine\" for over eight years. He also taught at Tel Aviv University. \n\nBefore entering the high-tech business, he was a career officer in the Israel Defense Forces.\n"}
{"id": "26944086", "url": "https://en.wikipedia.org/wiki?curid=26944086", "title": "Multi-channel length", "text": "Multi-channel length\n\nMulti-channel length is a technique for reducing power leakage in both active and idle modes on CMOS technology. Other techniques to reduce leakage, like power gating and SRAM retention, are targeted at reducing leakage power when the device, or portions of it, are not operating. \n\nShort channel length devices provide higher performance than longer channel length devices, but the longer channel length has significantly reduced subthreshold leakage current. In this generation of the power management tool box, two channel lengths summarized in the table below were used for the speed vs. leakage trade-off.\n\nTiming-critical paths are constructed of short channel length cells, but for non timing-critical paths, the longer channel length cells can be used to trade off speed for lower leakage. Multiple channel length synthesis achieves up to 30% leakage reduction. One additional usage of longer channel length transistors is for always-on logic and for special power management cells (isolation cells, always on buffers, etc.) where speed is not critical.\n\n[1] Rusu, S.; Tam, S.; Muljono, H.; Ayers, D.; Chang, J.; Cherkauer, B.; Stinson, J.; Benoit, J.;\nVarada, R.; Leung, J.; Limaye, R. D.; Vora, S.; \"A 65-nm Dual-Core Multithreaded Xeon\nProcessor With 16-MB L3 Cache,\" Solid-State Circuits, IEEE Journal of, vol.42, no.1, pp. 17–\n25, Jan. 2007, http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4039601&isnumber=4039574\n\n[2] Gammie, G.; Wang, A.; Mair, H.; Lagerquist, R.; Minh Chau; Royannez, P.; Gururajarao, S.;\nUming Ko; \"SmartReflex Power and Performance Management Technologies for 90 nm, 65 nm,\nand 45 nm Mobile Application Processors,\" Proceedings of the IEEE, vol.98, no.2, pp. 144–159,\n\nFeb. 2010\n\n[3] 40-nm FPGA Power Management and Advantages. Altera Ic. December 2008, ver. 1.2.\nURL: http://www.altera.com/literature/wp/wp-01059-stratix-iv-40nm-power-management.pdf\n"}
{"id": "16785745", "url": "https://en.wikipedia.org/wiki?curid=16785745", "title": "Needlegun scaler", "text": "Needlegun scaler\n\nA needlegun scaler, needle scaler or needle-gun is a tool used to remove rust, mill scale, and old paint from metal surfaces. The tool is used in metalwork applications as diverse as home repair, automotive repair and shipboard preservation. \n\nA needle gun has a set of very fine chisels known as needles. The tool forces these needles against a work surface at variable speeds up to around 5,000 times per minute. Different models offer choices of number of needles, operating speed, and power levels. Many models use compressed air, although electrical needle-guns do exist.\n\nIn a pneumatic unit, compressed air forces a piston forwards and backwards. This movement causes the needles to move back and forth against the work surface.\n\nThe needle gun has advantages over other scaling tools. Its main advantage is that the needles automatically adjust themselves to contours, making the tool a good choice for cleaning irregular surfaces. A needle gun can clean an area to bare metal in seconds, and compares well to other scaling tools in terms of accuracy and precision.\n\nIt is recommended that before needlegunning, a surface should be prepared by removing oil, grease, dirt, chemicals and water-soluble contaminants. This can be done with solvents or with a combination of detergent and fresh water.\nThen, the needle gun is used to remove rust, loose scale, and paint, leaving bare metal. It is used most effectively by holding it at a 45° angle to the work surface. It is recommended that an area no larger than six to eight inches be cleared at once. Two to three passes over an area is generally sufficient to clean it. Then the process is repeated until the desired area is completed.\n\nPrior to painting, it is desirable to feather any edges between metal and old paint. It is also important to check the surface for oil deposited during chipping, and if necessary, clean the area with solvents. Since bare metal surfaces will flash rust soon after exposure to the atmosphere, paint should be applied as soon as possible after chipping. If flash rusting occurs prior to coating, further chipping, cleaning and sanding may be necessary.\n\n\n-- CHAP 7 LINK NO LONGER WORKS\n\n"}
{"id": "34907046", "url": "https://en.wikipedia.org/wiki?curid=34907046", "title": "Network Test Automation Forum", "text": "Network Test Automation Forum\n\nThe Network Test Automation Forum (NTAF), founded in 2010, is a nonprofit international industry alliance, dedicated to promoting interoperability of commercial network testing tools and testing infrastructure, by defining and facilitating adoption of technical specifications.\n\nThe forum is composed of leading service providers, network equipment vendors, and other networking companies that share an interest in test automation and interoperability. As of November 2012, it has 14 members.\n\nIn 2009, 11 founding members (BreakingPoint, BT, Cisco, Fanfare, Empirix, Ericsson, EXFO, Ixia, JDSU, Spirent and Verizon) met in Chicago and expressed an interest in forming an industry alliance to bring together commercial testing vendors, test equipment vendors, and other industry experts to create interoperable testing solutions for service providers, network equipment manufacturers (NEMs), and other enterprise organizations with large network deployments. The result was the Network Test Automation Forum entity, which was set up in 2010 following the first face-to-face meeting in Montreal.\n\nTo facilitate and promote the interoperability of commercial testing tools and test infrastructure for the data communications and telecommunications industry.\n\nNTAF will bring together commercial testing vendors, test equipment vendors, and other industry experts to create interoperable testing solutions for service providers, network equipment manufacturers (NEMs), and other enterprise organizations with large network deployments.\n\nThe objectives of NTAF are:\n\nAs of July 2013, NTAF has the following members:\n\nIn June 2011, NTAF ratified two sets of specifications dealing with registration, discovery and activation of tools and defining tool harnesses.\n\nThis specification describes an XMPP extension that allows an application or tool to register itself in a way that other interested entities can discover its existence. It also describes the mechanism by which a tool can be activated so that its automation harnesses are available for use.\n\nThis specification describes an XMPP extension that allows an application or tool, with or without its own specialized man-machine user interface to expose an \"automation harness\" that allows that tool to be controlled and/or monitored by another tool via XMPP packet exchanges.\n\nThe NTAF Technical Committee is currently working on draft specifications for resource and inventory management:\n\nThis working document describes an NTAF extension that allows tools to communicate resource data. It is based on the TS-001 and TS-002 specifications and its primary focus is to support automated inventory management.\n\nThis working document describes an NTAF extension that supports the automatic population of inventory records with key equipment/resource parameters within a test lab environment. It is based on the TS-001 and TS002 specifications and the WT-003 proposal.\n\n"}
{"id": "17748770", "url": "https://en.wikipedia.org/wiki?curid=17748770", "title": "Open Agent Architecture", "text": "Open Agent Architecture\n\nOpen Agent Architecture or OAA for short is a framework for integrating a community of heterogeneous software agents in a distributed environment. It is also a research project of the SRI International Artificial Intelligence Center.\n\nRoughly, the architecture is that a central \"blackboard\" server holds a list of tasks, while a group of agent machines executes these tasks based on their specific capabilities.\n\n"}
{"id": "904443", "url": "https://en.wikipedia.org/wiki?curid=904443", "title": "Outline of human–computer interaction", "text": "Outline of human–computer interaction\n\nThe following outline is provided as an overview of and topical guide to human–computer interaction:\n\nHuman–computer interaction – the intersection of computer science and behavioral sciences, this field involves the study, planning, and design of the interaction between people (users) and computers. Attention to human-machine interaction is important, because poorly designed human-machine interfaces can lead to many unexpected problems. A classic example of this is the Three Mile Island accident where investigations concluded that the design of the human–machine interface was at least partially responsible for the disaster.\n\nHuman–computer interaction can be described as all of the following:\n\n\nHuman–computer interaction draws from the following fields:\n\nHistory of human–computer interaction\n\n\n\n\nHardware input/output devices and peripherals:\n\n\n\n\nMotion pictures featuring interesting user interfaces:\n\nIndustrial labs and companies known for innovation and research in HCI:\n\n\n"}
{"id": "11183776", "url": "https://en.wikipedia.org/wiki?curid=11183776", "title": "Penetration (firestop)", "text": "Penetration (firestop)\n\nA penetration, in firestopping, is an \"opening\", such as one created by the use of a cast-in-place sleeve, in a wall or floor assembly required to have a fire-resistance rating, for the purpose of accommodating the passage of a mechanical, electrical or structural penetrant. The penetration may or may not contain a firestop system. A \"penetration\" is not a \"penetrant\". A penetration may or may not include a penetrant.\n\nThe nuclear industry in particular used to refer to firestops as \"penetration seals\" or \"penseals\". These terms are superseded by the term firestop. Whereas penetration seals or penseals only dealt with openings made to accommodate penetrants, firestops now also include Joint (building).\n\nIt is useful to have clarity in construction communications, to differentiate between the \"opening\", whether sealed or not, and the penetrants, which are optional components of a penetration, as sometimes openings (penetrations of the fire barrier) are created for future use, especially in electrical service rooms. A firestop, after all, tends to be easier to remove than concrete, which requires coredrilling equipment, cooling water, etc. A firestopped penetration may also be referred to as a firestop, as a firestop, by definition, is a system. Therefore, the terms \"firestop\" and \"penetration\" can at times be deemed to be interchangeable.\n\n"}
{"id": "5181068", "url": "https://en.wikipedia.org/wiki?curid=5181068", "title": "Pentolite", "text": "Pentolite\n\nPentolite is a composite high explosive used for military and civilian purposes, e.g., warheads and booster charges. It is made of PETN phlegmatized with TNT by melt casting.\n\nThe most common military variety of pentolite (designated \"Pentolite 50/50\") is a mixture of 50% pentaerythritol tetranitrate (PETN) and 50% trinitrotoluene (TNT). (Unlike other compound explosives, the number before the slash is the mass percentage of TNT and the second number is the mass percentage of PETN). This 50:50 mixture has a density of 1.65 g/cm and a detonation velocity of 7400 m/s. \n\nCivilian pentolite sometimes contains a lower percentage of PETN, usually around 2% (\"Pentolite 98/2\"), 5% (\"Pentolite 95/5\") or 10% (\"Pentolite 90/10\"). Civilian pentolites have a detonation velocity of about 7,800 metres per second.\n\n"}
{"id": "6545531", "url": "https://en.wikipedia.org/wiki?curid=6545531", "title": "Piper Bravo", "text": "Piper Bravo\n\nPiper Bravo is a North Sea oil production platform originally operated by Occidental Petroleum (Caledonia) Ltd, and now owned by Repsol Sinopec Energy UK.\n\nPiper Bravo is an eight-legged fixed steel jacket supported platform, located 193 kilometres northeast of Aberdeen in the central North Sea. It stands in 145 metres of water. It was installed in 1992, and commenced production in February 1993. It replaced the Piper Alpha platform which exploded in July 1988 killing 167 men. It is located approximately 800 metres from the wreck buoy marking the remains of its precursor (at ).\n"}
{"id": "11108817", "url": "https://en.wikipedia.org/wiki?curid=11108817", "title": "Portable emissions measurement system", "text": "Portable emissions measurement system\n\nA portable emissions measurement system (PEMS) is a vehicle emissions testing device that is small and light enough to be carried inside or moved with a motor vehicle that is being driven during testing, rather than on the stationary rollers of a dynamometer that only simulates real-world driving. \n\nEarly examples of mobile vehicle emissions equipment were developed and marketed in the early 1990s by Warren Spring Laboratory UK during the early 1990s, which was used to measure on-road emissions as part of the UK Environment Research Program. Governmental agencies like United States Environmental Protection Agency (USEPA), European Union, and various states and private entities have begun to use PEMS in order to reduce both the costs and time involved in making mobile emissions decisions.\n\nLeo Breton of the US EPA invented the Real-time On-road Vehicle Emissions Reporter (ROVER) in 1995. The first commercially available device was invented by Michal Vojtisek-Lom, and developed by David Miller of Clean Air Technologies International (CATI) Inc. in Buffalo, New York in 1999. These early field devices used engine data from either an on-board diagnostics (OBD) port, or directly from an engine sensor array. The first unit was developed for, and sold to - Dr. H. Christopher Frey of North Carolina State University (NCSU) for the first on-road testing project, which was sponsored by the North Carolina Department of Transportation. David W. Miller, who co-founded CATI, first coined the phrase \"Portable Emissions Measurement System\" and \"PEMS\" when working on a 2000 New York City Metropolitan Transportation Agency bus project with Dr. Thomas Lanni of the New York State Department of Environmental Conservation, as a short-hand description of the new device. Other governmental groups and universities soon followed, and quickly began to use the equipment due to its balance of accuracy, low cost, light weight, and availability. From 1999 through 2004, research groups such as Virginia Tech, Penn State, and Texas A&M Transportation Institute, Texas Southern University and others began to use PEMS in border crossing projects, roadway evaluations], traffic control methods, before-and-after scenarios, and ferries, planes, and off-road vehicles, to explore what was possible outside of a lab environment. A project performed in April 2002 by the California Air Resources Board(CARB) - using non-1065 PEMS equipment, tested 40 trucks over a period of 2½ days; of which, 22 trucks were tested on road in Tulare, California. During this time, a high-profile project performed with early PEMS equipment was the World Trade Center (WTC) Ground Zero Project in lower Manhattan, testing concrete pumpers, bulldozers, graders, and later - diesel cranes on Building #7 - 40 stories high. Other early PEMS projects such as Dr. Chris Frey's field work was used by the USEPA in the development of the MOVES Model. However, users such as regulators and vehicle manufacturers had to wait for ROVER to be commercialized to conduct actual measurements of mass emissions rather than depend on estimates of mass emissions using data the OBD port, or a direct engine measurement, in order to have a more defensible data set. This push led to a new 2005 standard known as CFR 40 Part 1065.\n\nMany governmental entities (such as the USEPA and the United Nations Framework Convention on Climate Change or UNFCCC) have identified target mobile-source pollutants in various mobile standards as CO2, NOx, Particulate Matter (PM), Carbon Monoxide (CO), Hydrocarbons(HC), to ensure that emissions standards are being met. Further, these governing bodies have begun adopting in-use testing program for non-road diesel engines, as well as other types of internal combustion engines, and are requiring the use of PEMS testing. It is important to delineate the various classifications of the latest 'transferable' emissions testing equipment from-time PEMS equipment, in order to best understand the desire of portability in field-testing of emissions.\n\nBecause a PEMS unit is able to be carried easily by one person from jobsite to jobsite, and can be used without the requirement of 'team lifting', the required emissions testing projects are economically viable. Simply put, more testing can be done more quickly, by less workers, dramatically increasing the amount of testing done in a certain time period. This in turn, significantly reduces the 'cost per test', yet at the same time increases the overall accuracy required in a 'real-world' environment. Because the law of large numbers will create a convergence of results, it means that repeatability, predictability, and accuracy are enhanced, while simultaneously reducing the overall cost of the testing.\n\nNearly all modern engines, when tested new and according to the accepted testing protocols in a laboratory, produce relatively low emissions well within the set standards. As all individual engines of the same series are supposed to be identical, only one or several engines of each series get tested. The tests have shown that:\n\n\nThese findings are consistent with published literature, and with the data from a myriad of subsequent studies. They are more applicable to spark-ignition engines and considerably less to diesels, but with the regulation-driven advances in diesel engine technology (comparable to the advances in spark-ignition engines since the 1970s) it can be expected that these findings are likely to be applicable to the new generation diesel engines. Since 2000, multiple entities have used PEMS data to measured in-use, on-road emissions on hundreds of diesel engines installed in school buses, transit buses, delivery trucks, plow trucks, over-the-road trucks, pickups, vans, forklifts, excavators, generators, loaders, compressors, locomotives, passenger ferries, and other on-road, off-road and non-road applications. All the previously listed findings were demonstrated; in addition, it was noticed that extended idling of engines can have a significant impact on the emissions during subsequent operation.\n\nAlso, PEMS testing identified several engine \"anomalies\"where fuel-specific NOx emissions were two to three times higher than expected during some modes of operation, suggesting deliberate alterations of the engine control unit (ECU) settings. Such data set can be readily used for developing emissions inventories, as well as to evaluate various improvements in engines, fuels, exhaust after-treatment and other areas. (Data collected on \"conventional\"fleets then serves as \"baseline\"data to which various improvements are compared.) This data set can also be examined for compliance with not-to-exceed (NTE) and in-use emissions standards, which are 'US-based' emission standards that require on-road testing.\n\nIt is often difficult for PEMS to offer the same accuracy and variety of species measured as is possible with top of the line laboratory instrumentation because PEMS are typically limited in size, weight and power consumption. For this reason, objections were raised against using PEMS for compliance verification. But there is also the potential for inaccuracy in fleet emissions deduced from laboratory measurements. For this reason, European WLTP results from PEMS will be weighted with a conformity factor of 2.1 (1.5 after 2019), i.e. the emissions measured by the PEMS are allowed to be a factor 2.1 higher than the limit.\n\nIt is expected that a variety of on-board systems will be designed, ranging from bread-box sized PEMS to instrumented trailers towed behind the tested truck. The benefits of each approach need to be considered in light of other sources of errors associated with emissions monitoring, notably vehicle-to-vehicle differences, and the emissions variability within the vehicle itself.\n\nPEMS need to be safe enough to use on public roads. During testing, portable emissions systems could attach extensions of the tailpipe, add lines and cables outside the vehicle, carry lead-acid batteries in the passenger compartment, have hot components accessible to bystanders, block emergency exits, or interfe with the driver, or have loose components that could be caught in moving parts. Modifications to or disassembly of the tested vehicle such as drilling into the exhaust, removing intake air system) need to be examined for their acceptance by both fleet managers and drivers, especially on passenger-carrying vehicles. The test equipment can not draw excessive electrical load from the test vehicle. Instead, sealed lead-acid batteries, fuel cells and generators have been used as external power sources, though they may add other hazards during driving.\n\nThe more time and expertise installation of the equipment requires, the greater the cost of testing, limiting the number of vehicles that can be tested. More testing is also possible with equipment that is versatile enough to be used on more than one type of vehicle. The weight and size of the equipment and consumables like calibration gases might limit moving to a sufficient number locations. Any restrictions on transport of hazardous materials (i.e.Flame ionization detector (FID) fuel or calibration gases) need to be taken into the account. The ability of the test crew to repair PEMS in the field using locally available resources can also be essential.\n\nUltimately, it should be demonstrated to show that a PEMS is suitable to the desired application. If the ultimate goal is to verify the compliance with in-use emissions requirements, a fleet of vehicles with known characteristics – including engines with dual-mapping and otherwise non-compliant engines – should be made available for testing. It should be then up to the PEMS manufacturers to practically demonstrate how these non-compliant vehicles can be identified using their system.\n\nIn order to achieve the required amount of 'testing volume' needed to validate real-world testing, three points must be considered:\n\nOnce a particular portable emissions system has been identified and pronounced as accurate, the next step is to ensure that the worker(s) are properly protected from work hazards associated with the task(s) being performed in the use of the testing equipment. For example, typical functions for a worker may be to transport the equipment to the jobsite (i.e. car, truck, train, or plane), carry the equipment to the jobsite, and lift the equipment into position.\n\nOn-road vehicle emissions testing is very different from the laboratory testing, bringing both considerable benefits and challenges: As the testing can take place during the regular operation of the tested vehicles, a large number of vehicles can be tested within a relatively short period of time and at relatively low cost. Engines than cannot be easily tested otherwise (i.e., ferry boat propulsion engines) can be tested. True real-world emissions data can be obtained. The instruments have to be small, lightweight, withstand difficult environment, and must not pose a safety hazard. Emissions data is subject to considerable variances, as real-world conditions are often neither well defined nor repeatable, and significant variances in emissions can exist even among otherwise identical engines.\n\nOn-road vehicle emissions testing is very different from the laboratory testing, bringing both considerable benefits and challenges: As the testing can take place during the regular operation of the tested vehicles, a large number of vehicles can be tested within a relatively short period of time and at relatively low cost. Engines than cannot be easily tested otherwise (i.e., ferry boat propulsion engines) can be tested. True real-world emissions data can be obtained. The instruments have to be small, lightweight, withstand difficult environment, and must not pose a safety hazard. Emissions data is subject to considerable variances, as real-world conditions are often neither well defined nor repeatable, and significant variances in emissions can exist even among otherwise identical engines.\nOn-road emissions testing therefore requires a different mindset than the traditional approach of testing in the laboratory and using models to predict real-world performance. In the absence of established methods, use of PEMS requires careful, thoughtful, broad approach. This should be considered when designing, evaluating and selecting PEMS for the desired application.\n\nA recent example of PEMS advantages over laboratory testing is the Volkswagen (VW) Scandal of 2015. Under a small grant from the International Council for Clean Transportation Dan Carder and Arvind Thiruvengadam of West Virginia University (WVU) uncovered on-board software \"cheats\" that VW had installed on some diesel passenger vehicles (Dieselgate scandal). The only way the discovery could have been made was by a non-programmed, random, on-road evaluation - utilizing a PEMS device. VW is now liable for over 14 billion USD in fines. In 2016, these latest developments led to a global resurgence of interest in smaller, lighter, integrated and cost-effective \"non-1065\" PEMS, similar to the demonstration on the Mythbusters 2011 Premiere Episode of \"Bikes and Bazookas\", in which a non-1065 PEMS was used to establish the difference between car and motorcycle pollution.\n\nOveriew of integrated PEMS (iPEMS) development\n\nIn response to Dieselgate, the \"Real Driving Emissions\" (RDE) standard has been developed in the European Union (EU) which has, in turn, increased the demand for smaller, lighter, more portable, less expensive and integrated PEMS equipment kits. It should be noted that iPEMS equipment is not presently able to be used as a \"certification\" device in the U.S. \nDefinition of iPEMS\n\nThe following features are common to the smaller and lighter class of iPEMS equipment: \n\nAdvantages of iPEMS over 1065 PEMS equipment \n\nThe advantage of iPEMS equipment is that they are designed to both complement 1065 PEMS in addition to providing expanded capabilities, which are being driven by the requirements for quicker decision-making compounded by the 2015 Volkswagen scandal. These devices are presently being pursued by both the European Union (EU) and China for their RDE Programs.\n\n\n"}
{"id": "28667", "url": "https://en.wikipedia.org/wiki?curid=28667", "title": "Principality of Sealand", "text": "Principality of Sealand\n\nThe Principality of Sealand, commonly known as Sealand, is a micronation that claims Roughs Tower, an offshore platform in the North Sea approximately off the coast of Suffolk, as its territory. Roughs Tower is a disused Maunsell Sea Fort, originally called HM Fort Roughs, built as an anti-aircraft gun platform by the British during World War II.\n\nSince 1967, the decommissioned HM Fort Roughs has been occupied by family and associates of Paddy Roy Bates, who claims that it is an independent sovereign state. Bates seized it from a group of pirate radio broadcasters in 1967 with the intention of setting up his own station at the site. He attempted to establish Sealand as a nation state in 1975 with the writing of a national constitution and establishment of other national symbols.\n\nWhile it has been described as the world's smallest country, Sealand is not officially recognised by any established sovereign state in spite of Sealand's government's claim that it has been \"de facto\" recognised by the United Kingdom and Germany. The United Nations Convention on the Law of the Sea, in force since 1994, states \"Artificial islands, installations and structures do not possess the status of islands. They have no territorial sea of their own, and their presence does not affect the delimitation of the territorial sea, the exclusive economic zone or the continental shelf\". Since 1987, Sealand has lain within the United Kingdom's territorial waters.\n\nBates moved to the mainland when he became elderly, naming his son, Michael, as regent. Bates died in October 2012 at the age of 91. Michael lives in Suffolk.\n\nIn 1943, during World War II, HM Fort Roughs (sometimes called Roughs Tower) was constructed by the United Kingdom as one of the Maunsell Forts, primarily to defend the vital shipping lanes in nearby estuaries against Nazi Kriegsmarine mine-laying aircraft. It consisted of a floating pontoon base with a superstructure of two hollow towers joined by a deck upon which other structures could be added. The fort was towed to a position above the Rough Sands sandbar, where its base was deliberately flooded to sink it on its final resting place. This is approximately from the coast of Suffolk, outside the then claim of the United Kingdom and, therefore, in international waters. The facility was occupied by 150–300 Royal Navy personnel throughout World War II; the last full-time personnel left in 1956.\n\nRoughs Tower was occupied in February and August 1965 by Jack Moore and his daughter Jane, squatting on behalf of the pirate station Wonderful Radio London.\n\nOn 2 September 1967, the fort was occupied by Major Paddy Roy Bates, a British subject and pirate radio broadcaster, who ejected a competing group of pirate broadcasters. Bates intended to broadcast his pirate radio station – called Radio Essex – from the platform. Despite having the necessary equipment, he never began broadcasting. Bates declared the independence of Roughs Tower and deemed it the Principality of Sealand.\n\nIn 1968, British workmen entered what Bates claimed to be his territorial waters to service a navigational buoy near the platform. Michael Bates (son of Paddy Roy Bates) tried to scare the workmen off by firing warning shots from the former fort. As Bates was a British subject at the time, he was summoned to court in England on firearms charges following the incident. But as the court ruled that the platform (which Bates was now calling \"Sealand\") was outside British territorial limits, being beyond the then limit of the country's waters, the case could not proceed.\nIn 1975, Bates introduced a constitution for Sealand, followed by a national flag, a national anthem, a currency and passports.\n\nIn August 1978, Alexander Achenbach, who describes himself as the Prime Minister of Sealand, hired several German and Dutch mercenaries to spearhead an attack on Sealand while Bates and his wife were in England. They stormed the platform with speedboats, Jet Skis and helicopters, and took Bates's son Michael hostage. Michael was able to retake Sealand and capture Achenbach and the mercenaries using weapons stashed on the platform. Achenbach, a German lawyer who held a Sealand passport, was charged with treason against Sealand and was held unless he paid DM 75,000 (more than US$35,000 or £23,000). The governments of the Netherlands, Austria and Germany petitioned the British government for his release, but the United Kingdom disavowed his imprisonment, citing the 1968 court decision. Germany then sent a diplomat from its London embassy to Sealand to negotiate for Achenbach's release. Roy Bates relented after several weeks of negotiations and subsequently claimed that the diplomat's visit constituted \"de facto\" recognition of Sealand by Germany.\n\nFollowing the former's repatriation, Achenbach and Gernot Pütz established a government in exile, sometimes known as the Sealand Rebel Government or Sealandic Rebel Government, in Germany. Achenbach's appointed successor, Johannes Seiger, continues to claim via his website that he is Sealand's legitimate ruling authority.\n\nIn 1997, the Bates family revoked all Sealand passports, including those that they themselves had issued over the previous 22 years. There were thought to have been about 150,000 in circulation. \n\nOn the afternoon of 23 June 2006, the top platform of the Roughs Tower caught fire due to an electrical fault. A Royal Air Force rescue helicopter transferred one person to Ipswich hospital, directly from the tower. The Harwich lifeboat stood by the Roughs Tower until a local fire tug extinguished the fire. All damage was repaired by November 2006. In January 2007, The Pirate Bay attempted to purchase Sealand after harsher copyright measures in Sweden forced them to look for a base of operations elsewhere. Between 2007 and 2010, Sealand was offered for sale through the Spanish estate company InmoNaranja, at an asking price of €750 million (£600 million, US$906 million).\n\nRoy Bates died at the age of 91 on 9 October 2012; he had been suffering from Alzheimer's disease for several years. He was succeeded by his son Michael. Joan Bates died in an Essex nursing home at the age of 86 on 10 March 2016.\n\nThe claim that Sealand is an independent sovereign state is based on an interpretation of a 1968 decision of an English court, in which it was held that Roughs Tower was in international waters and thus outside the jurisdiction of the domestic courts.\nIn international law, the most common schools of thought for the creation of statehood are the constitutive and declaratory theories of state creation. The constitutive theory is the standard nineteenth-century model of statehood, and the declaratory theory was developed in the twentieth century to address shortcomings of the constitutive theory. In the constitutive theory, a state exists exclusively via recognition by other states. The theory splits on whether this recognition requires 'diplomatic recognition' or merely 'recognition of existence'. No other state grants Sealand official recognition, but it has been argued by Bates that negotiations carried out by Germany following a brief hostage incident constituted 'recognition of existence' (and, since the German government reportedly sent an ambassador to the tower, diplomatic recognition). In the declaratory theory of statehood, an entity becomes a state as soon as it meets the minimal criteria for statehood. Therefore, recognition by other states is purely 'declaratory'.\n\nIn 1987, the UK extended its territorial waters from . Sealand now sits inside British waters. The United Kingdom is one of 165 parties to the United Nations Convention on the Law of the Sea (in force since 1994), which states in Part V, Article 60, that: 'Artificial islands, installations and structures do not possess the status of islands. They have no territorial sea of their own, and their presence does not affect the delimitation of the territorial sea, the exclusive economic zone or the continental shelf'. In the opinion of law academic John Gibson, there is little chance that Sealand would be recognised as a nation because it is a man-made structure.\n\nIn a 1990 court case (and a 1991 appeal) in the United States regarding registering ships in Sealand as a flag of convenience, the court ruled against allowing Sealand flagged vessels; the case was never contested by the Bateses.\nIrrespective of its legal status, Sealand is managed by the Bates family as if it were a recognised sovereign entity and they are its hereditary royal rulers. Roy Bates styled himself as 'Prince Roy' and his wife 'Princess Joan'. Their son is known as 'His Royal Highness Prince Michael' and has been referred to as the 'Prince regent' by the Bates family since 1999. In this role, he apparently serves as Sealand's acting 'Head of State' and also its 'Head of Government'. At a micronations conference hosted by the University of Sunderland in 2004, Sealand was represented by Michael Bates's son James. The facility is now occupied by one or more caretakers representing Michael Bates, who himself resides in Essex, England.\n\nSealand's constitution was instituted in 1974. It consists of a preamble and seven articles. The preamble asserts Sealand's independence, while the articles variously deal with Sealand's status as a constitutional monarchy, the empowerment of government bureaux, the role of an appointed, advisory senate, the functions of an appointed, advisory legal tribunal, a proscription against the bearing of arms except by members of a designated 'Sealand Guard', the exclusive right of the sovereign to formulate foreign policy and alter the constitution, and the hereditary patrilinear succession of the monarchy. Sealand's legal system is claimed to follow British common law, and statutes take the form of decrees enacted by the sovereign. Sealand has issued \"fantasy passports\" (as termed by the Council of the European Union), which are not valid for international travel, and holds the Guinness World Record for 'the smallest area to lay claim to nation status'. Sealand's motto is \"E Mare Libertas\" (\"From the Sea, Freedom\"). It appears on Sealandic items – such as stamps, passports and coins – and is the title of the Sealandic anthem. The anthem was composed by Londoner Basil Simonenko; being an instrumental anthem, it does not have lyrics. In 2005, the anthem was recorded by the Slovak Radio Symphony Orchestra and released on their CD \"National Anthems of the World, Vol. 7: Qatar – Syria\".\nSealand has been involved in several commercial operations, including the issuing of coins and postage stamps and the establishment of an offshore Internet hosting facility, or 'data haven'. Sealand also has an official website and publishes an online newspaper, \"Sealand News\". In addition, a number of amateur athletes 'represent' Sealand in sporting events, including unconventional events like the World Egg Throwing Championship, which the Sealand team won in 2008.\n\nSeveral dozen different Sealand coins have been minted since 1972. In the early 1990s, Achenbach's German group also produced a coin, featuring a likeness of 'Prime Minister Seiger'. Sealand's coins and postage stamps are denominated in 'Sealand dollars', which it deems to be at parity with the US dollar. Sealand first issued postage stamps in 1969, and issues through 1977. No further stamps were produced until 2010. Sealand is not a member of the Universal Postal Union, therefore its inward address is a PO Box in the British borough of Ipswich. Once an item is mailed to Sealand's tourist and government office, it will then be taken to Sealand. Sealand only has one street address, \"The Row\".\n\nA Sealand mailing address looks like this:\n\nBureau of Internal Affairs\n5, The Row\nSEALAND 1001\n\nSealand also sells titles of individual nobility including Lord, Baron, Count and those titles' distaff equivalents. Following Roy Bates's 2012 death, Sealand also began publicly offering knighthoods & Coats of Arms.\n\nIn 1978, following the invasion, the Knights of the Sovereign Military Order of Sealand were formed by Prince Roy and Prince Michael to provide for the Principality's defence should it come under threat or attack. In 2012, following the death of Prince Roy, membership in the Order was opened to sale to the general public.\n\nIn 2000, worldwide publicity was created about Sealand following the establishment of a new entity called HavenCo, a data haven, which effectively took control of Roughs Tower itself; however, Ryan Lackey, HavenCo's founder, later quit and claimed that Bates had lied to him by keeping the 1990–1991 court case from him and that, as a result, he had lost the money he had invested in the venture. In November 2008, operations of HavenCo ceased without explanation.\n\nSealand is not recognised by any major international sporting body, and its population is insufficient to maintain a team composed entirely of Sealanders in any team sport. However, Sealand claims to have official national athletes, including non-Sealanders. These athletes take part in various sports, such as curling, mini-golf, football, fencing, ultimate, table football and athletics, although all its teams compete out of the country. The Sealand National Football Association is an associate member of the Nouvelle Fédération-Board, a football sanctioning body for non-recognised states and states not members of FIFA. It administers the Sealand national football team. In 2004 the national team played its first international game against Åland Islands national football team, drawing 2–2.\n\nSealand claims that its first official athlete was Darren Blackburn of Oakville, Ontario, Canada, who was appointed in 2003. Blackburn has represented Sealand at a number of local sporting events, including marathons and off-trail races. In 2004, mountaineer Slader Oviatt carried the Sealandic flag to the top of Muztagh Ata. Also in 2007, Michael Martelle represented the Principality of Sealand in the World Cup of Kung Fu, held in Quebec City, Canada; bearing the designation of \"Athleta Principalitas Bellatorius\" (Principal Martial Arts Athlete and Champion), Martelle won two silver medals, becoming the first-ever Sealand athlete to appear on a world championship podium.\n\nIn 2008, Sealand hosted a skateboarding event with Church and East sponsored by Red Bull.\n\nIn 2009, Sealand announced the revival of the Football Association and their intention to compete in a future Viva World Cup. Scottish author Neil Forsyth was appointed as President of the Sealand Football Association. Sealand played the second game in their history against Chagos Islands on 5 May 2012, losing 3–1. The team included actor Ralf Little and former Bolton Wanderers defender Simon Charlton.\n\nIn 2009 and 2010, Sealand sent teams to play in various ultimate club tournaments in the United Kingdom, Ireland and the Netherlands. They came 11th at UK nationals in 2010.\n\nFrom early summer of 2012 Sealand has been represented in the flat track variant of roller derby, by a team principally composed of skaters from the South Wales area.\n\nSealand played a friendly match in aid of charity against an \"All Stars\" team from Fulham F.C. on 18 May 2013, losing 5–7.\n\nOn 22 May 2013, the mountaineer Kenton Cool placed a Sealand flag at the summit of Mount Everest.\n\nin 2015, the runner Simon Messenger ran a half-marathon on Sealand as part of his “round the world in 80 runs” challenge.\n\nIn 2018 competitive swimmer Richard Royal became the first person to swim the 12 km from Sealand to the mainland UK, finishing in a time of 3 hrs 29 mins. The swim was sanctioned and supported by the Sealand Government and Royal visited the micro nation prior to beginning the swim, getting his passport stamped. He entered the water from the ‘bosuns chair’, signalling the start of the swim, and finished on Felixstowe beach. Richard Royal was subsequently awarded with a Knighthood by Prince Michael.\n\n\n\n"}
{"id": "41233610", "url": "https://en.wikipedia.org/wiki?curid=41233610", "title": "RNB Research", "text": "RNB Research\n\nRNB Research is a global market research company, headquartered in New Delhi, India. RNB Research operates through its own offices in 15 cities across 10 countries - China, Egypt, GCC, India, Kenya, Philippines, Russia, South Africa, Thailand & Vietnam.\n\nRNB Research specializes in qualitative and quantitative custom market research. It has experience in most major sectors, particularly consumer products, media, retail, financial services, food and beverages, technology, telecommunications and internet research.\n\nRNB Research is a member of the American Marketing Association (AMA), Marketing Research Association (MRA), Council of American Survey Research Organizations (CASRO).\n\n"}
{"id": "55685094", "url": "https://en.wikipedia.org/wiki?curid=55685094", "title": "Rachel Skinner", "text": "Rachel Skinner\n\nRachel Susan Skinner (born December 1976) is a British civil engineer with Canadian-based consultant WSP Global. Named as one of the \"Daily Telegraph\" Top 50 Influential Women in Engineering in 2016 and as the most distinguished winner of 2017 at the European Women in Construction and Engineering Awards, she is set to become the youngest ever president of the Institution of Civil Engineers in 2020.\n\nSkinner was born in December 1976 and has a bachelor's degree with first-class honours in geography from Durham University. She states that she \"fell into engineering completely by chance\" and became an engineer \"by accident\" when she took a job as a transport planner in 1998. She had only intended the job to be a stop-gap for a few months before going travelling for a period. Skinner is a transport planning professional and a member of the Chartered Institution of Highways and Transportation (MCIHT). In 2001 she was awarded a master of science degree in transportation planning and engineering with a distinction by the University of Leeds.\n\nSkinner has been involved with the Institution of Civil Engineers since 2002 when she became a chartered engineer (CEng), and is now a fellow of the institution (FICE) and sits on its council. She chaired the ICE's London region for 2010–11 and is currently chair of its London Transport Expert Network. She was confirmed by the ICE council as succeeding vice president in April 2017 and, \"subject to interim annual election by Council,\" is set to become president in November 2020. She will be the second female president and the youngest ever to hold the post. Skinner is also chair of the advisory board of the \"New Civil Engineer\" magazine.\n\nSkinner has held several senior positions at WSP Global, the consultancy and design firm, including as UK director of transportation planning and European director of marketing and communications. She is currently an executive director and head of development at WSP|Parsons Brinckerhoff (WSP's UK subsidiary) where she leads around 800 staff in redevelopment and infrastructure projects for the public and private sectors.\n\nSkinner helped to set up the Women's Transportation Seminar network in London in June 2005, was a founding member of its board and president from 2009 to 2013. Skinner also works to encourage schoolgirls into taking up STEM subjects. She has written papers on the implementation of driverless vehicles and the application of digital technology to the construction industry and has acted as an expert witness at public inquiries.\n\nSkinner was one of the \"Daily Telegraph\" Top 50 Influential Women in Engineering in 2016 and was named as the most distinguished winner of 2017 at the European Women in Construction and Engineering Awards.\n"}
{"id": "1372275", "url": "https://en.wikipedia.org/wiki?curid=1372275", "title": "Radial tire", "text": "Radial tire\n\nA radial tire (more properly, a radial-ply tire) is a particular design of vehicular tire. In this design, the cord plies are arranged at 90 degrees to the direction of travel, or radially (from the center of the tire). Radial tire construction climbed to 100% market share in North America, following Consumer Reports finding the superiority of the radial design in 1968.\n\nThe first radial tire designs were patented in 1915 by Arthur W. Savage, a tire manufacturer (1915–1919), and inventor in San Diego, CA. Savage's patents expired in 1949.\n\nMichelin in France designed, developed, patented, and commercialized the radial tire. There is no evidence that Michelin had knowledge of Arthur Savage's earlier work. The first Michelin X radial tire for cars was developed in 1946 by Michelin researcher Marius Mignol. Michelin owned the leading automaker Citroën, so it was quickly able to introduce its new design, including on the new 1948 Citroën 2CV model. In 1952, Michelin developed a radial truck tire.\n\nBecause of its significant advantages in durability and fuel economy, this technology spread quickly in Europe and Asia in the 1950s and 1960s.\n\nIn 1968, Consumer Reports, an influential American magazine, acknowledged the superiority of the radial tire design, documenting its longer tread life, better steering characteristics, and less rolling resistance, which increases gas mileage.\n\nIn 1970, Ford Motor Company produced the first American-made vehicle with radial tires as standard equipment, Michelin tires fitted to the Continental Mark III.\n\nIn 1974, Charles J. Pilliod, Jr., the new CEO of Goodyear Tire and Rubber Company, faced a major investment decision regarding retooling for the radial tire, following the 1973 oil crisis. Despite heavy criticism at the time, Pilliod invested heavily in new factories and tooling to build the radial tire. Today, only Goodyear, Cooper, Titan and Specialty Tires of America remain independent among US tire manufacturers, and the radial has a market share of 100%. Sam Gibara, who headed Goodyear from 1996 to 2003, has noted that without the action of Pilliod, Goodyear \"wouldn't be around today.\" \n\nIn 1974, Leopoldo Pirelli created the \"wide radial tire\" in Italy, upon a request from the Lancia rally racing team for a tire sufficiently strong enough to withstand the power of the new Lancia Stratos. At that time, racing tires were either slick tires made with the cross ply technique (very wide tires with a reduced sidewall height), or radial tires, which were too narrow to withstand the Stratos' power and did not provide enough grip. Both were unusable for the Lancia Stratos, as the radials were destroyed within 10 km, and the slicks too stiff. Lancia asked Pirelli for a solution, and in the succeeding year Pirelli also made a wide tire with a reduced sidewall height like a slick, but with a radial structure.\n\nRadial technology is now the standard design for essentially all automotive tires.\n\nBias tires are still used on trailers due to their weight carrying ability and resistance to swaying when towed.\n\nFor aircraft, the transition is happening more slowly - tires are certified along with the airframe. A radial has less material in the sidewall, so it weighs less, runs cooler and lasts longer. For smaller planes, bias tires afford more stability at higher speeds and have stronger sidewalls.\n\nA series of plies of cord reinforces a tire. Without this, a tire would be flexible and weak. The network of cords that gives the tire strength and shape is called the carcass. Since the 1960s, all common tires have a carcass of cords of polyester, steel, or other textile materials, inlaid with several layers of rubber.\n\nIn the past, the fabric was built up on a flat steel drum, with the cords at angles of about +60 and −60 degrees from the direction of travel, so they criss-crossed over each other. They were called cross ply or bias ply tires. The plies were turned up around the steel wire beads and the combined tread/sidewall applied. The green (uncured) tire was loaded over a curing bladder and shaped into the mold. This shaping process caused the cords in the tire to assume an S-shape from bead to bead. The angle under the tread, the crown angle, stretched down to about 36 degrees. In the sidewall region the angle was 45 degrees, and in the bead it remained at 60 degrees. The low crown angle gave rigidity to support the tread and the high sidewall angle gave comfort. To increase strength, the manufacturer would increase the number of plies, and the heat buildup in the tire.\n\nBy comparison, radial tires lay all of the cord plies at 90 degrees to the direction of travel (that is, across the tire from lip to lip). This design avoids having the plies rub against each other as the tire flexes, reducing the tire's rolling friction. This allows vehicles with radial tires to achieve better fuel economy than with bias-ply tires. It also accounts for the slightly \"low on air\" (bulging) look that radial tire sidewalls have, especially when compared to bias-ply tires.\n\nWith only radial cords, a radial tire would not be sufficiently rigid at the contact with the ground. To add further stiffness, the entire tire is surrounded by additional belts oriented closer to the direction of travel, but usually at some \"spiral\" angle. These belts can be made of steel (hence the term steel-belted radial), polyester, or Aramid fibers such as Twaron or Kevlar.\n\nIn this way, low radial tires separate the tire carcass into two separate systems:\n\nEach system can then be individually optimized for best performance.\n\nRadial tires have different characteristics of springiness from those of bias-ply tires, and a different degree of slip while steering. A benefit was that cars could now be made lighter because they would not have to make up for the deficiencies of bias-ply tires.\n\nHowever, motorists were not accustomed to the feel, hence the suspension systems of cars had to be modified. Ford Motor Company engineer Jack Bajer experimented in the 1960s on a Ford Falcon, by giving it less tight steering, and adding both isolators to the drive shaft and bushings to the suspension, the latter being to absorb the thump of riding over asphalt expansion joints in a concrete roadway. \nRadial tires have occasionally found application on bicycles, used on the 1980s Miyata touring bicycle; models 1000 and 610, and more recently in 2009 on the Maxxis Radiale.\nPanaracer radial tires were also standard on the Jamis Gentry model bicycle in 1985.\n\nThe steel wires in radial tires become magnetized with use, so as they rotate, an alternating magnetic field is created. It is quite measurable with an EMF meter close to the wheel well when the wheel is rotating, and is rich in harmonics up to several hundred hertz.\n\nThe advantages of radial tires over bias ply :\n\n\n"}
{"id": "32634524", "url": "https://en.wikipedia.org/wiki?curid=32634524", "title": "Rice color sorting machine", "text": "Rice color sorting machine\n\nA rice color sorting machine, also named rice colour sorter, separates rice grains according to color differences in raw rice arising from anomalies like bits of stone, bad rice, black rice, half-husked rice, etc. A high-resolution CCD optical sensor drives a mechanical sorter to separate different granular materials, automatically sorting heterochromatic particles out of the batch of raw rice; removing such impurities in this process improves the quality of the rice.\n\nRice processing begins in a milling plant, where the harvested grains run through a production line where the rice is boiled, dried, de-stoned, husked, hulled and shelled. It then is taken to the color sorter machine. At this point, the rice mixture will travel by elevator belt into a hopper on top of the machine, from which it will flow down along chutes in the colour sorter, streamlining their flow to so that they may be scanned by CCD sensors. The moment the camera detects any color defects, the camera instructs ejectors fitted in the machine to open the nozzle. The nozzle is connected to valves containing compressed air. This air is then used to shoot out the color defected material from the input rice. The types of defects in rice include black tipped, chalky, yellow, mouse droppings, immature grain, etc.\n\n\n"}
{"id": "3287020", "url": "https://en.wikipedia.org/wiki?curid=3287020", "title": "Shared space", "text": "Shared space\n\nShared space is an urban design approach that minimises the segregation between modes of road user. This is done by removing features such as kerbs, road surface markings, traffic signs, and traffic lights. Hans Monderman and others have suggested that, by creating a greater sense of uncertainty and making it unclear who has priority, drivers will reduce their speed, in turn reducing the dominance of vehicles, reducing road casualty rates, and improving safety for other road users.\n\nShared space design can take many different forms depending on the level of demarcation and segregation between different transportation modes. Variations of shared space are often used in urban settings, especially those that have been made nearly car-free (\"autoluwe\"), and as part of living streets within residential areas. As a separate concept, \"shared space\" normally applies to semi-open spaces on busier roads, and here it is controversial.\n\nShared space is opposed in particular by organisations representing the interests of blind, partially sighted and deaf people, who often express a preference for the clear separation of pedestrian and vehicular traffic.\n\nThe origin of term is generally linked with the work of Dutch traffic engineer Hans Monderman, who pioneered the method in the Dutch province of Friesland. Prior to the adoption of the term, street design projects carried out in Chambéry, France, by Michel Deronzier from the 1980s used the term \"pedestrian priority\". The term was used by Tim Pharoah to describe informal street layouts with no traffic demarcation (for example \"Traffic Calming Guidelines\", Devon County Council, 1991).\n\nThe term has been widely applied, especially by Ben Hamilton-Baillie, since the preparation of a European co-operation project in 2003. The European Shared Space project (part of the Interreg IIIB-North Sea programme) developed new policies and methods for the design of public spaces with streets between 2004 and 2008 under the leadership of Hans Monderman until his death in 2008.\n\nA review of the evolution of the shared space concepts (2014) is offered in Transport Reviews: A Transnational Transdisciplinary Journal.\n\nThe Chartered Institution of Highways and Transportation has identified three broad types of street design approach that have been called shared space but which have a number of important differences. They suggest that the term \"shared space\" should be replaced by three new labels: pedestrian prioritised streets, informal streets and enhanced streets.\n\nThe goal of shared space is to improve the road safety and vibrancy of roads and junctions, particularly ones with high levels of pedestrian traffic, by encouraging negotiation of priority in shared areas between different road users. Shared space is a \"design approach rather than a design type characterised by standard features\".\n\nHans Monderman suggested that an individual's behavior in traffic is more positively affected by the built environment of the public space than by conventional traffic control devices and regulations. A reason for the apparent paradox that reduced regulation leads to safer roads may be found by studying the risk compensation effect.\n\n\nSuch schemes are claimed to have had positive effect on road safety, traffic volume, economic vitality, and community cohesion where a user's behaviour becomes influenced and controlled by natural human interactions rather than by artificial regulation. Monderman has stated that objections are more a matter of communication than design, stressing the importance of consulting all relevant groups during the design stage.\n\nThe UK's Department for Transport issued national guidance on shared space in 2011. However in July 2018 it reversed its position and instructed local authorities to halt all new shared space projects, with Transport Minister Nusrat Ghani stating they \"just don't work\" for blind and partially-sighted people.\n\nReviewing the research that underpinned national policy in the UK, Moody and Melia (2011) found that some of the claims made for shared space schemes were not justified by the evidence—particularly the claims that pedestrians are able to follow desire lines, and that shared space reduces traffic speeds. Their primary research in Ashford, Kent, suggested that in streets with high volumes of traffic, pedestrians are more likely to give way to vehicles than vice versa. Most people, but particularly women and older people, found the shared space intimidating and preferred the previous layout with conventional crossings. A study by Hammond and Musselwhite using a case study of Widemarsh Street in Hereford found that if traffic volume was relatively low and speeds of vehicles slow anyway then vulnerable road users found it easier to share the area with vehicles, including those blind or partially sighted and older people with mobility impairments.\n\nThere are wide-ranging reservations about the practicality of the shared space philosophy. In a 2006 report from the Associated Press, it was commented that traditionalists in town planning departments say the schemes rob the motorists of vital information, and reported that a spokesman for Royal National Institute of Blind People criticised the removal of familiar features such as railings, kerbs, and barriers. Shared space is opposed by many organisations representing blind, partially sighted and deaf people. Some of their members avoid shared space areas entirely. \"Shared surfaces\", which are generally used in shared space schemes, can cause concern for the blind and partially sighted who cannot visually negotiate their way with other road users, as the lack of separation implicit in these features has also removed their safe space. The UK's Guide Dogs for the Blind Associations \"Say No to Shared Streets\" campaign has the support of more than thirty other disability organisations. There have been similar concerns raised by other groups representing disabled people, including Leonard Cheshire Disability, the Royal National Institute for Deaf People, and Mencap, who have noted problems when negotiating a route with motor vehicle users, leading them to challenge its fundamental premise. Lord Holmes' 2015 report \"Accidents by Design\" found that sixty-three per cent of respondents reported a negative experience of shared space, and thirty-five per cent said they actively avoided it. Lord Holmes attacked the concept as a recipe for \"confusion, chaos and catastrophe\".. The Holmes report also noted serious issues for wheelchair users \"Respondents who used wheelchairs stated that it was virtually impossible to locate a safe crossing point on roads with shared space.\" In July 2018, the UK DfT reversed its position on shared spaces due to the risk to disabled people, with Transport Minister Nusrat Ghani stating \"they just don't work\". \n\nThe Dutch \"Fietsberaad\" (Centre of Expertise on Bicycle Policy) has demonstrated ambivalence over shared space schemes, describing some benefits but also some drawbacks for the less assertive cyclist. \"Fietsberaad\" has noted that shared space has decreased car speeds but that \"some cyclists do not dare take priority. Instead, they dismount and wait for priority to be clearly given, then walk or ride across the intersection. A problem may be that they are met halfway by cars from the other direction and must rely on the drivers to give way of their own volition. Owing to low speeds and the cyclists' defensive behaviour this crossing strategy need not be unsafe in itself, but it most certainly is not convenient.\"\n\nIn New Zealand, concerns about such limitations of the shared space concept have led, in cooperation with disability organisations, to the introduction of vehicle- and obstruction-free corridors (\"accessible zones\") along the building lines (i.e., in the areas where footpaths would normally be located), to provide a safe route in the shared spaces being introduced.\n\nThe British Transport Research Laboratory found that below flows of 90 vehicles per hour adult pedestrians were prepared to mingle with traffic. When flows reached 110 vehicles per hour, they used the width between frontages as if it were a traditional road. A similar value is used to define suitability for a woonerf.\n\nNumerous towns and cities around the world have implemented schemes with elements based on the shared space principles.\n\nBendigo, Victoria, plans (as of October 2007) to implement shared space in its city centre.\n\nIn October 2011, Graz opened a shared space zone around a five-point intersection known as Sonnenfelsplatz next to the University of Graz with the intention of easing congestion from 4 separate city bus lines and auto, bike and pedestrian traffic as well as reducing the number of accidents. This was the first shared space concept for Austria.\n\nEjby introduced a shared space project in Denmark. It was part of the European Interreg IIIB project with Province of Fyslän as lead partner. The project was led by urban planner Morten Mejsen Westergaard and Bjarne Winterberg. It was supervised by Hans Monderman.\n\nBohmte introduced a shared space road system in September 2007. One of project's goals was to improve road safety in the town.\n\nMakkinga has no road markings and no signs giving an order or direction signs visible in the streets. There is a traffic sign at the entrance to the town that reads \"Verkeersbordvrij\", meaning \"free of traffic signs\". Parking meters and stopping restrictions are also absent. Drachten is another pioneer town for such schemes. Accident figures at one junction where traffic lights were removed have dropped from thirty-six in the four years prior to the introduction of the scheme to two in the two years following it. Only three of the original fifteen sets of traffic lights remain. Tailbacks (traffic jams) are now almost unheard of at the town's main junction, which handles about 22,000 cars a day. An evaluation of the Laweiplein scheme in Drachten concluded that traffic now flows at a constant rate and at equal speeds for motor and bicycle traffic and more freely with reduced congestion, shorter delays and improved capacity including for pedestrians. Additionally, which ties in with the philosophy of shared space and which is evidenced by the reduction in recorded accidents, public perceptions of traffic safety have declined.\n\nSeveral of Auckland's streets have been turned into shared spaces. These include Elliot and Darby Streets, Lorne street, the Fort street areas, all near Queen Street, Auckland and Federal Street by the Skytower. However, Auckland's first shared space is Wairepo Swamp Walk, completed mid-2010. Wairepo Swamp Walk is one of a number of transport infrastructure projects improving transport services around Eden Park as part of the 2011 Rugby World Cup. A research study has been undertaken by Auckland Transport in conjunction with the University of Auckland to evaluate city centre shared spaces in the Auckland CBD.\n\nSince the zebra crossings and traffic signs were replaced with a spacious fountain, benches, and other street furniture, the Skvallertorget square in Norrköping has experienced no accidents, mean traffic speeds have dropped from 21 to 16 km/h (13 to 10 mph) and livability has increased.\n\nThe concept of a shared space where no right of way is defined for all participants is presently not legally possible. The Strassenverkehrsgesetz (SVG) requires that at least one of the participants has a right of way. As a result, the Swiss concept of \"Begegnungszone\" has become popular. However here pedestrians have right of way.\n\nIn London, Exhibition Road was developed into a shared space in 2012 after a design competition in 2003, a court case, and numerous community consultations.\n\nIn Seven Dials, London, the road surface has been re-laid to remove the distinction between the roadway and the footway and kerbs have been lowered to encourage people to wander across the street. A scheme implemented in London's Kensington High Street, dubbed \"naked streets\" in the pressreflecting the removal of markings, signage and pedestrian barriershas yielded significant and sustained reductions in injuries to pedestrians. It is reported that, based on two years of 'before and after' monitoring, casualties fell from 71 in the period before the street was remodelled to 40 afterwardsa drop of 43%.\n\nGwynedd Council rebuilt the foreground to Caernarfon Castle. The scheme uses local slate and granite surfacing and high-quality street furniture, and a new fountain, intended to create a change in the behaviour of drivers.\n\nBrighton City Council transformed the whole of New Road, adjacent to the Royal Pavilion, into a fully shared space designed by Landscape Projects and Gehl Architects, with no delineation of the carriageway except for subtle changes in materials. The route for vehicles along New Road is only suggested through the location of street furniture, such as public seating and street lights. The re-opening of the street has led to a 93% reduction in motor vehicle trips (12,000 fewer per day) and lower speeds (to around 10 MPH), alongside an increase in cyclist and pedestrian usage (93% and 162%, respectively).\n\nIn spring 2008, shared space was introduced in Ashford, Kent. The scheme replaced a section of Ashford's former four-lane ring road with two-way streets on which drivers, cyclists, and pedestrians have equal priority. Unnecessary street furniture, road markings and traffic lights have been removed and the speed limit cut to 20 mph.\nThe scheme has been claimed to have improved safety records. Between November 2008 and January 2011, there have been four road casualties there, resulting from the six reported accidents. Claims about the success of the Ashford scheme were called into question during 2011 by a study conducted by the University of the West of England.\n\nFollowing the initial reports claiming a success for the Ashford scheme, other UK local councils planned to use a similar approach; these include Southend-on-Sea, Staines, Newcastle-under-Lyme, Hereford, and Edinburgh.\n\nThere have also been trials in Ipswich, with \"shared space\" being a key feature of the design of the new Ravenswood community being built on the site of the former Ipswich Airport.\n\nAt Princess Royal Square (formerly Pier Square) in Weston-super-Mare, the conventional road system has been replaced by a seafront open area. This has been complemented by the restoration of the Coalbrookdale fountain in its centre.\n\nIn Poynton, Cheshire, it was found that as well as providing significant safety improvements, and regenerating the retail and social centre, the road capacity was not reduced after the redevelopment of a busy junction in the town incorporated shared space elements. In the scheme, the redevelopment of a multi-lane signalised crossroads, with a traffic flow of 26,000 vehicles per day, which was completed in March 2012, traffic lanes, signals, road markings, road signs and street clutter were all removed. In the first three years after the redevelopment there was one minor personal injury accident, compared to 4-7 serious incidents in each of the three years leading up to the project. Although no speed limit changes were made, average traffic speeds fell to around 20 mph and there were reductions in vehicle journey times as well as reductions in pedestrian delays at the junction.\n\nA pilot road layout project, which includes shared-space elements, is to be trialled in the Stobhill area of Morpeth, Northumberland. Opposition groups argue that the plans are unsafe for children and disabled people.\n\nIn West Palm Beach, Florida, removal of traffic signals and road markings brought pedestrians into much closer contact with cars. The result has been slower traffic, fewer accidents, and shorter trip times.\n\nIn Savannah, Georgia, the Oglethorpe Plan has been adapted to accommodate pedestrian and vehicular traffic throughout a network of wards, each with a central square. The size and configuration of the squares restrains vehicular traffic to speeds under 20 miles per hour, a threshold speed beyond which shared space tends to break down.\n\nShared streets have also been installed in the New York City neighborhoods of Jamaica, Financial District, and Flatiron.\n\nGeneral themes\nProponents\n\n"}
{"id": "46757420", "url": "https://en.wikipedia.org/wiki?curid=46757420", "title": "Shell tools in the Philippines", "text": "Shell tools in the Philippines\n\nShell tools, in the archaeological perspective, were tools fashioned by pre-historic humans from shells in lieu of stone tools. The use of shell tools during pre-historic times was a practice common to inhabitants of environments that lack the abundance of hard stones for making tools. This was the case with the islands surrounding the Pacific, including the Philippines.\nShells were fashioned into tools, as well as ornaments. From adzes, scoops, spoons, dippers and other tools to personal ornaments such as earrings, anklets, bracelets and beads. These different artefacts made of shells were unearthed from various archaeological sites from the country.\n\nShell adzes were made by percussion flaking and grinding. A piece of shell was extracted from the main shell by either direct percussion flaking or possibly by sticking against an anvil underneath as in bipolar percussion flaking. The final shaping and finishing work was done by either grinding the shell against a wet abrasive surface such as sandstone or by grinding against loose wet sand placed on a hard surface. There are two locations on a giant clam that produces the largest pieces of shell. One is at the hinge and the other is at the ribs. Sections cut from these locations provide the thickest pieces of shell and the largest adzes.\n\nThe shells of giant clams were fashioned into large spherical beads with holes drilled end to end at the center while pendants for the ear were ground from cone shells. Perforations were drilled at the center of the disk. Bracelets and anklets were both made from giant clams and cone shells. Shell bracelets made from the top shoulder of the body whorls of cone shells (Conus litteratus) are characteristic of the Late Neolithic Age. The natural spiral found along the shoulders of the shell serves as a decorative motif.\n\nThe oldest known ornaments made from cone shells were found in the early 1960s in the grave of an adult male in Duyong Cave in Palawan. A shell disk with a hole in the center was found next to his right ear and a disk with a hole by the edge was found on his chest. The shell ornaments were dated 4854 B.C.\n\nDuyong Cave, near the Tabon Caves of Palawan's western coast (Philippines) produced a \"Neolithic Burial\" with four Tridacna shell adzes and two different types of shell ornaments as well as other types of shell tools. The calibrated Carbon 14 date for the burial is 3,675 - 3,015 B.C. and 4,575 - 4,425 B.C. for a nearby fire hearth that also had shell debris associated with it.\n\nManufactured from the hinge line of a giant clam (Tridacna gigas), the shell adze was found associated with a Neolithic burial assemblage in Duyong Cave, Quezon, Palawan. This shell tool is similar to the shell adzes recovered in Okinawa, Japan. Shells were used as tools in the Pacific as a replacement for hard stones which were not available on the islands. The presence of shell adzes not only in Palawan but also in Tawi-Tawi is very significant in the study of movements of people from the insular Southeast Asia to the Pacific. This shell tool is similar to the shell adzes recovered in Micronesia and Ryukyu Islands in Okinawa, Japan.\n\nThe Manunggul Shell Spoon is a concave utensil with a sharp point at one end and a figure at the other end. The latter has a right extremity that forms to what appears like an arm with five digits. The left extremity and the head are missing. The outer surface of the body whorl near the figure has an angular shoulder. This shell spoon is not bilaterally symmetrical.\n\nThe Mataas shell scoop is a concave utensil with a sharp point at one end and a figure at the other end. The latter has a right extremity that forms to what appears like an arm with five digits. The left extremity and the head are missing. The outer surface of the body whorl near the figure has an angular shoulder. This shell scoop, recovered in Cagraray Island, Albay is not bilaterally symmetrical.\nShell scoops made from the body whorl of Turbo marmoratus first appeared in the Late Neolithic Period at Manunggul Cave, Quezon, Palawan.\n\nUp to the Metal Age, shells were the major material for the manufacture of both tools and ornaments but shell technology attained its highest development during the Neolithic Period.\nAt present, the people of Palawan living near Tabon Caves still fashion bracelets from shells. The boring and polishing of the shell ornaments is done with stone tools.\n\nShells were found to be useful during pre-historic times when they provided an alternative material for the production of tools which made the development of pre-historic humans possible. These tools were found in various sites which suggests the vast reaches of its utility. Even up to the present many cultures and traditions still make use of these shells as either tools or ornaments. Although the use of shells as tools may have become just a ceremonial practice but its use as ornamentation still persists.\n"}
{"id": "304716", "url": "https://en.wikipedia.org/wiki?curid=304716", "title": "Smart Personal Objects Technology", "text": "Smart Personal Objects Technology\n\nThe Smart Personal Objects Technology (SPOT) is a discontinued initiative by Microsoft to create intelligent and personal home appliances, consumer electronics, and other objects through new hardware capabilities and software features.\n\nDevelopment of SPOT began as an incubation project initiated by the Microsoft Research division. SPOT was first announced by Bill Gates at the COMDEX computer exposition event in 2002, and additional details were revealed by Microsoft at the 2003 Consumer Electronics Show where Gates demonstrated a set of prototype smart watches—the first type of device that would support the technology. Unlike more recent technologies, SPOT did not use more traditional forms of connectivity, such as 3G or Wi-Fi, but relied on FM broadcasting subcarrier transmission as a method of data distribution.\n\nWhile several types of electronics would eventually support the technology throughout its lifecycle, SPOT was considered a commercial failure. Reasons that have been cited for its failure include its subscription-based business model, support limited to North America, the emergence of more efficient and popular forms of data distribution, and mobile feature availability that surpasses the features that SPOT offered.\n\nDevelopment of SPOT began as an incubation project led by Microsoft engineer, Bill Mitchell, and initiated by the Microsoft Research division. Mitchell would enlist the help of Larry Karr, president of SCA Data Systems, to develop the project. Karr had previously worked in the 1980s to develop technology for Atari that would distribute games in a manner distinct from the company's competitors; Karr proposed FM broadcasting subcarrier transmission as a method of distribution, technology which would also be used by Microsoft's SPOT. Microsoft Research and SCA Data Systems would ultimately develop the DirectBand subcarrier technology for SPOT. National Semiconductor would aid in the development of device chipsets, which would feature a ARM7 CPU and ROM, SRAM, and a 100 MHz RF receiver chip.\n\nSPOT was unveiled by Bill Gates at the annual COMDEX computer exposition event in fall of 2002. Gates stated that \"new devices and technologies will help bring about the next computing revolution\" and demonstrated refrigerator magnets that displayed the current time and sports scores, and an alarm clock that could display a list of upcoming appointments, traffic updates, and weather forecasts.\nAt the Consumer Electronics Show of 2003, Microsoft announced that wristwatches would be the first type of device to utilize the technology in a partnership with watch manufacturers Citizen Watch Co., Fossil, and Suunto. Bill Gates also demonstrated a set of prototype smart watches. SPOT was not Microsoft's foray into the smartwatch business—the company previously co-developed the Timex Datalink with Timex in 1994. During CES, Microsoft claimed that the first SPOT-based smartwatches would be released in the fall of that year; the company would also release a promotional video that displayed an estimated delivery time of fall 2003, but the first devices would be delayed until the beginning of 2004.\n\nAt the Windows Hardware Engineering Conference of 2003, Gates unveiled a new set of hardware-based navigational controls codenamed XEEL, designed to create a consistent navigation experience across Windows-based devices, such as smart phones, tablet PCs, and those powered by SPOT. Microsoft intended for XEEL to create a consistent navigation experience across hardware devices that equaled the software interface navigation consistency introduced by the mouse scroll wheel.\n\nIn June 2003, Microsoft unveiled its MSN Direct wireless service developed specifically for SPOT, which would be made available across North America. The company stated that the service would enable the delivery of personalized information on devices and, as an example of this functionality, would allow users to receive messages sent from MSN Messenger or calendar appointment reminders from Microsoft Outlook. MSN Direct would use a subscription-based business model, available through monthly or yearly service plans. MSN Direct relied on the DirectBand subcarrier technology developed by Microsoft in conjunction with SCA Data Systems.\n\nThe first devices to make use of SPOT were released in 2004 by Fossil and Suunto. Tissot would later introduce the first compatible watch to feature a touchscreen, and Swatch would release the first compatible watch largely tailored towards younger consumers. As smartwatches were the first type of devices to make use of the technology, they became the \"de facto\" type of device that represented it.\n\nIn 2006, Oregon Scientific released the second type of SPOT device, a weather station that displayed regional weather forecasts and other various types of information. A second generation of smartwatches was also released, and were designed to address the shortcomings observed in first generation models. Later that year, Melitta released the third type of device to utilize the technology: a coffeemaker that displayed weather forecasts on an electronic visual display. Garmin released the first SPOT-compatible GPS navigation units in 2007.\n\nIn early 2008, Microsoft announced that MSN Direct would be available for Windows Mobile, and in early 2009, the service would receive additional location-based enhancements.\n\nProduction of SPOT watches ceased in 2008. In 2009, Microsoft announced that it would discontinue the MSN Direct service at the beginning of 2012. The company stated that this decision was due to decreased demand for the service and because of the emergence of more efficient and popular forms of data distribution, such as Wi-Fi. The MSN Direct service continued to support existing SPOT devices until transmissions ceased on January 1, 2012.\n\nSPOT extended functionality of traditional devices to include features not originally envisaged for them; a SPOT-powered coffeemaker, for example, would be able to display information such as weather forecasts on an electronic visual display. Smartwatches featured digital watch displays, referred to as \"Channels\", that presented information in a manner that could be customized by a user—a user could also specify the default channel to be displayed; this feature was functionally analogous with a home screen commonly seen in mobile operating systems. Additional channels could be downloaded from a specialized website, and a \"Glance\" feature would allow a user to cycle through downloaded information.\n\nManufacturers could also add their own features to SPOT-based devices; as an example, a manufacturer could create its own smartwatch channel in order to distinguish its product from a competitor's product. Each SPOT-based device included a unique identification number used to enable secure authentication and encryption of DirectBand signals. Microsoft also reportedly considered an alarm function for SPOT-based smartwatches that would activate in the event of theft.\n\nSPOT relied on the .NET Micro Framework for the creation and management of embedded device firmware. This technology would later be used for the Windows SideShow feature introduced in Windows Vista, which shares design similarities with SPOT. In 2007, five years after SPOT was announced, Microsoft released the first software development kit for the .NET Micro Framework.\n\n"}
{"id": "17112589", "url": "https://en.wikipedia.org/wiki?curid=17112589", "title": "Social viewing", "text": "Social viewing\n\nSocial viewing describes a recently developed practice revolving around the ability for multiple users to aggregate from multiple sources and view online videos together in a synchronized viewing experience.\n\nTypically the experience also involves some form of instant messaging or communication to facilitate discussion pertaining to the common viewing experience.\n\nThe term in this context originated with the Toronto and Los Angeles-based company View2Gether which has created proprietary technology for aggregating content from sources not controlled by the user for synchronized play and inclusion in common playlists by multiple participants with a commensurate instant messaging chat function. Other sites which provide similar functionality include Oortle (Photophlow), SeeToo and development of social viewing for existing portals such as Yahoo have recently been announced.\n\nThe term has been used in some cases to describe online viewing within the framework of a social network, however View2gether and similar sites have reconfigured the term to mean a common viewing experience as a social activity.\n\nSocial viewing has also been used in the past to describe activities such as gathering for the viewing of particular television programs, such as soap operas.\n\nSome examples of modern social viewing sites include Twitch, YouTube, Facebook, and Twitter.\n"}
{"id": "230708", "url": "https://en.wikipedia.org/wiki?curid=230708", "title": "Solera", "text": "Solera\n\nSolera is a process for aging liquids such as wine, beer, vinegar, and brandy, by fractional blending in such a way that the finished product is a mixture of ages, with the average age gradually increasing as the process continues over many years. The purpose of this labor-intensive process is the maintenance of a reliable style and quality of the beverage over time. \"Solera\" means \"on the ground\" in Spanish, and it refers to the lower level of the set of barrels or other containers used in the process; the liquid (traditionally transferred from barrel to barrel, top to bottom, the oldest mixtures being in the barrel right \"on the ground\"), although the containers in today's process are not necessarily stacked physically in the way that this implies, but merely carefully labeled. Products which are often \"solera\" aged include Sherry, Madeira, Lillet, Port wine, Marsala, Mavrodafni, Muscat, and Muscadelle wines; Balsamic, Commandaria, some Vins doux naturels, and Sherry vinegars; Brandy de Jerez; beer; rums; and whiskies. Since the origin of this process is out of the Iberian peninsula, most of the traditional terminology is in Spanish and Portuguese.\n\nIn the \"solera\" process, a succession of containers are filled with the product over a series of equal aging intervals (usually a year). A group of one or more containers, called scales, criaderas ('nurseries'), or clases are filled for each interval. At the end of the interval after the last scale is filled, the oldest scale in the \"solera\" is tapped for part of its content, which is bottled. Then that scale is refilled from the next oldest scale, and that one in succession from the second-oldest, down to the youngest scale, which is refilled with new product. This procedure is repeated at the end of each aging interval. The transferred product mixes with the older product in the next barrel.\nNo container is ever drained, so some of the earlier product always remains in each container. This remnant diminishes to a tiny level, but there can be significant traces of product much older than the average, depending on the transfer fraction. In theory traces of the very first product placed in the \"solera\" may be present even after 50 or more cycles. In Andalusia, Spain, the latest regulations for labeling requires careful labeling and record-keeping, usually via computer, allowing the winemaker or regulator to easily access the average age of each container, which depends not only on the refreshment interval and number of scales, but also the relative volumes that are chosen for the refreshment process—a larger refreshment and final removal for bottling will result in a younger average age (see Aging). The upper quality levels implied by the labeling system requires the bottled wine to be greater in age than the regulatory requirements.\n\nThe age of product from the first bottling is the number of containers times the aging interval. As the \"solera\" matures, the average age of product asymptotically approaches one plus the number of scales (excluding the top scale) (K) divided by the fraction of a scale transferred or bottled (α), or (1 + K/α).\n\nFor instance, suppose the \"solera\" consists of three barrels of wine, and half of each barrel is transferred once a year. At the end of the third year (and each subsequent year), half the third barrel is bottled. This first bottling is aged three years. The third barrel is then refilled with by transferring half of the wine from the second barrel. The wine transferred from the second barrel has an average age of 2.5 years (at the end of year 2, after barrel transfers, it was half 2-year old wine, half 1-year old wine, for an average age of 1.5 years; at the end of year 3, before barrel transfers, it will have aged another year for an average age of 2.5 years). The second bottling will then be half 3.5 years old and half four years old (the wine left in the last barrel at the previous cycle), for an average age of 3.75 years. The third bottling will be an average age of 4.25 years (one half wine that was left over from the second bottling - average age 4.75 years, and one half wine transferred from the second barrel after the second bottling - average age 3.75 years). After 20 years, the output of the \"solera\" would be a mix of wine from 3 to 20 years old, averaging very slightly under five years. The average age asymptotically converges on five years as the \"solera\" continues.\n\nThe output of the solera is the fraction of the last scale taken off for bottling each cycle. The amount of product tied up in the \"solera\" is usually many times larger than the production. This means that a \"solera\" is a very large capital investment for a winemaker. If done with actual barrels, the producer may have several \"soleras\" running in parallel. For a small producer, a \"solera\" may be the largest capital investment, and a valuable asset to be passed down to descendants. An economic concomitant of the Andalusian wine industry are Almacenistas ('warehousers', small or larger investors who purchase solera-produced material and carefully maintain it over many years so that it can be purchased for current needs by bodegas who are actively blending for the market.\nWine produced from a solera cannot formally have a vintage date because it is a blend of vintages from many years. However, some bottlings are labeled with an age for marketing reasons, which could be the date that the solera was founded. In most instances, It is unclear whether such age indications denotes the average age, or the age of the oldest batch. In Andalusia, the various average age categories, up to 30 years of age at present, are much better documented to the regulatory body and on the bottle labels at present than they were just a decade or two ago.\n\nThis process is known as \"solera\" in Spanish, and was developed by the producers of sherry. In a Spanish sherry \"solera\", the vintner may transfer about a third of each barrel a year. A solera sherry has to be at least three years old when bottled.\n\nA quite similar process is called sostrera, used to produce fortified wines in the Mediterranean regions of France.\n\nIn Sicily, where Marsala wine is made, the system is called \"in perpetuum\".\n\nSolera vinification is used in the making of Mavrodafni (\"Black Laurel\"), a fortified red dessert wine made in the Northern Peloponnese in Greece. Exceptional \"Mavrodafni\" vintages are released every 20 or 30 years: they are of minimal availability and expensive.\n\nVintners in Rutherglen, Australia produce fortified muscat-style and Tokay-style wines using the solera process. In South Australia, some fortified wines (akin to tawny port) are made from blends of Shiraz, Grenache and Mourvedre.\n\nGlenfiddich, a Speyside distillery in Scotland, has a 15-year-old whisky that uses a vatting process similar to the solera. The whisky is labelled as their \"15 year old single malt Scotch Whisky\". For Scotch whisky, the stated age must refer to the youngest of whisky's components. Barrels are emptied into the solera vat and mixed. Then whisky is drawn from the vat to be bottled, with the vat never being more than half emptied. Since the process began in 1998, the vat has never been emptied.\n\nIn France some producers use the \"perpétuelle\" method to blend base wines for Champagne across the years for non-vintage Champagne such as Francis Boulard Cuvée Petraea.\n\nThe oldest port wine producer in America, Old Vine Tinta Solera at Ficklin, has used a solera since 1948.\n\nIn Okinawa, Japan, where \"awamori\" is made, the traditional system similar to the solera is called \"shitsugi\".\n\nThe solera process has been used since the 17th century to produce sour ales in Sweden, where it is known as \"hundraårig öl\" (hundred-year beer). The beer is rarely commercially available, being instead made at the large manors for private consumption.\n"}
{"id": "528064", "url": "https://en.wikipedia.org/wiki?curid=528064", "title": "Sousveillance", "text": "Sousveillance\n\nSousveillance ( ) is the recording of an activity by a participant in the activity, typically by way of small wearable or portable personal technologies. The term \"sousveillance\", coined by Steve Mann, stems from the contrasting French words \"sur\", meaning \"above\", and \"sous\", meaning \"below\", i.e. \"surveillance\" denotes the \"eye-in-the-sky\" watching from above, whereas \"sousveillance\" denotes bringing the camera or other means of observation down to human level, either physically (mounting cameras on people rather than on buildings), or hierarchically (ordinary people doing the watching, rather than higher authorities or architectures doing the watching).\n\nWhile surveillance and sousveillance both generally refer to visual monitoring, the terms also denote other forms of monitoring such as audio surveillance or sousveillance. In the audio sense (e.g. recording of phone conversations), sousveillance is referred to as \"one party consent\".\n\nUndersight (inverse oversight) is sousveillance at high-level, e.g. \"citizen undersight\" being reciprocal to a congressional oversight committee or the like.\n\nInverse surveillance is a subset of sousveillance with a particular emphasis on the \"watchful vigilance from underneath\" and a form of surveillance inquiry or legal protection involving the recording, monitoring, study, or analysis of surveillance systems, proponents of surveillance, and possibly also recordings of authority figures and their actions. Inverse surveillance is typically an activity undertaken by those who are generally the subject of surveillance, and may thus be thought of as a form of an ethnography or ethnomethodology study (i.e. an analysis of the surveilled from the perspective of a participant in a society under surveillance).\n\nSousveillance typically involves community-based recording from first person perspectives, without necessarily involving any specific political agenda, whereas inverse-surveillance is a form of sousveillance that is typically directed at, or used to collect data to analyze or study, surveillance or its proponents (e.g., the actions of police or protestors at a protest rally).\n\nSousveillance is not necessarily counter-surveillance; i.e. sousveillance can be used to \"counter\" the forces of surveillance, or it can also be used together with surveillance to create a more complete \"veillance\" (\"Surveillance is a half-truth without sousveillance\"). The question of \"Who watches the watchers\" is dealt with more properly under the topic of metaveillance (the veillance of veillance) than sousveillance.\n\nInverse surveillance is a type of sousveillance. The more general concept of sousveillance goes beyond just inverse surveillance and the associated twentieth century political \"us \"versus\" them\" framework for citizens to photograph police, shoppers to photograph shopkeepers, or passengers to photograph taxicab drivers. Howard Rheingold commented in his book \"Smart Mobs\" that this is similar to the pedestrian−driver concept, i.e. these are roles that many of us take both sides of, from time to time. Many aspects of sousveillance were examined in the general category of \"reciprocal accountability\" in David Brin's 1997 non-fiction book The Transparent Society, and also in Brin's novels. The first \"International Workshop on Inverse Surveillance\", IWIS, took place in 2004, chaired by Dr. Jim Gemmell, (MyLifeBits), Joi Ito, Anastasios Venetsanopoulos, and Steve Mann, among others.\n\nOne of the things that brought inverse surveillance to light was the reactions of security guards to electric seeing aids and similar sousveillance practices. It seemed, early on, that the more cameras that were in an establishment, the more the guards disliked the use of an electric seeing aid, such as the EyeTap eyeglasses. It was through simply wearing electric seeing aids, as a passive observer, that it was discovered that surveillance and sousveillance can cause conflict and sometimes confrontation. This led some researchers to explore why the perpetuators of surveillance are suspicious of sousveillance, and thus defined the notion of inverse surveillance as a new and interesting facet of studies in sousveillance.\n\nSince the year 2001, December 24 has been World Sousveillance Day with groups of participants in New York City, Toronto, Boston, Florida, Vancouver, Japan, Spain and the United Kingdom. However, this designated day focuses only on hierarchical sousveillance, whereas there are a number of groups around the world working on combining the two forms of sousveillance.\n\nAn essay from Wired magazine predicts that sousveillance is an important development that will be on the rise in 2014.\n\nSousveillance of a state by its citizens has been credited with addressing many problems such as election fraud or electoral misdeeds, as well as providing good governance. For example, mobile phones were used in Sierra Leone and Ghana in 2007 for checking malpractices and intimidation during elections.\n\nA recent area of research further developed at IWIS was the equilibrium between surveillance and sousveillance. Current \"equiveillance theory\" holds that sousveillance, to some extent, often reduces or eliminates the need for surveillance. In this sense it is possible to replace the Panoptic God's eye view of surveillance with a more community-building ubiquitous personal experience capture. Crimes, for example, might then be solved by way of collaboration among the citizenry rather than through the watching over the citizenry from above. But it is not so black-and-white as this dichotomy suggests. In particular, citizens watching over their neighbors is not necessarily \"better\" than the alternative: an increase in community self-reliance might be offset by an uncomfortable \"nosy neighbor\" effect. \"Personal sousveillance\" has been referred to as \"coveillance\" by Mann, Nolan and Wellman.\n\nCopwatch is a network of American and Canadian volunteer organizations that \"police the police.\" Copwatch groups usually engage in monitoring of the police, videotaping police activity, and educating the public about police misconduct. Fitwatch is a group who photograph Forward Intelligence Teams (police photographers) in the United Kingdom.\n\nIn 2008, Cambridge researchers (in the MESSAGE project) have teamed with bicycle couriers to measure and transmit air pollution indicators as they travel the city.\n\nIn 2012 the Danish daily newspaper and online title Dagbladet Information crowdmapped the positions of surveillance cameras by encouraging readers to use a free Android and iOS app to photograph and geolocate CCTV cameras.\n\nPersonal sousveillance is the art, science, and technology of personal experience capture, processing, storage, retrieval, and transmission, such as lifelong audiovisual recording by way of cybernetic prosthetics, such as seeing-aids, visual memory aids, and the like. Even today's personal sousveillance technologies like camera phones and weblogs tend to build a sense of community, in contrast to surveillance that some have said is corrosive to community.\n\nThe legal, ethical, and policy issues surrounding personal sousveillance are largely yet to be explored, but there are close parallels to the social and legal norms surrounding recording of telephone conversations. When one or more parties to the conversation record it, it is called \"sousveillance\", whereas when the conversation is recorded by a person who is not a party to the conversation (such as a prison guard violating a client-lawyer relationship), the recording is called \"surveillance\".\n\n\"Targeted sousveillance\" refers to sousveillance of a specific individual by one or more other individuals. Usually, the targeted individual is a representative or proponent of surveillance, so targeted sousveillance is often inverse surveillance or hierarchical sousveillance. \"Hierarchical sousveillance\" refers, for example, to citizens photographing police, shoppers photographing shopkeepers, or taxicab passengers photographing cab drivers. So, for example, targeting former White House security official Admiral John Poindexter with sousveillance follows this more political narrative.\n\nClassy's Kitchen describes sousveillance as \"another way to add further introspection to the commons that keeps society open but still makes the world smaller and safer\". In this way sousveillance may be regarded as a possible replacement for surveillance. In this sur/sousveillance replacement, one can consider an operative social norm that would require cameras to be attached to a human operator. Under such a scenario, any objections to the camera could be raised by another human more easily than it would be to interact with a lamp post upon which is mounted a surveillance camera. Thus, the argument is that cameras attached to people ought to be less offensive than cameras attached to inanimate objects, because there is at least one responsible party present to operate the camera. This responsible-party argument is analogous to that used for operation of a motor vehicle, where a responsible driver is present, in contrast to remote or automated operation of a motor vehicle.\n\nBeyond the political or breaching of hierarchical structure explored in academia, the more rapidly emerging discourse on sousveillance within industry is \"personal sousveillance\", namely the recording of an activity by a participant in the activity.\n\nAs the technologies get smaller and easier to use, the capture, recording, and playback of everyday life gets that much easier to initiate spontaneously in unexpected situations. For example, David Ollila, a manufacturer of video camera equipment, was trapped for four hours aboard a Comair plane at JFK Airport in New York City. When he recorded an interview with the pilot about the situation, the pilot called the police who then removed Ollila for questioning and removed everyone from the plane.\n\nRecording a situation is only part of the sousveillance process. Communicating is also important. Video-sharing sites such as YouTube and photo-sharing sites such as Flickr play a vital role. For example, police \"agents provocateur\" were quickly revealed on YouTube when they infiltrated a demonstration in Montebello, Quebec, against the leaders of Canada, Mexico and the United States (August 2007). When the head of the Quebec police publicly stated that there was no police presence, a sousveillance video showed him to be wrong. When he revised his statement to say that the police provocateurs were peaceful observers, the same video showed them to be masked, wearing police boots, and in one case holding a rock.\n\nThere are many similar examples, such as the widely viewed YouTube video of UCLA campus policemen tasering a student. In Russia, as well as in some other countries where road users trust neither each other nor police, onboard cameras are so ubiquitous that thousands of videos of automobile accidents and near-miss incidents have been uploaded. The unanticipated 2013 Russian meteor event was well documented from a dozen angles via the use of these devices. Similarly, in February 2015, dashcams caught valuable footage of the crash of TransAsia Airways Flight GE235.\n\nAlibi sousveillance is a form of sousveillance activity aimed at generating an alibi as evidence to defend against allegations of wrongdoing.\n\nHasan Elahi, a University of Maryland professor, has produced a sousveillance for his entire life, after being detained at an airport because he was erroneously placed on the US terrorist watchlist. Some of his sousveillance activities include using his cell phone as a tracking device, and publicly posting debit card and other transactions that document his actions.\n\nOne specific use of alibi sousveillance is the growing trend of police officers wearing body cameras while on patrol. Well-publicized events involving police-citizen altercations (such as the case of Michael Brown in Ferguson, Missouri) have increased calls for police to wear body-cameras and so capture evidence of the incidents, for the benefit of them personally plus the criminal justice system as a whole. By having officers use sousveillance, police forces can generate hours of video evidence to be used in cases like that of Michael Brown, and the video evidence can act as an important alibi in the judicial proceedings in regards to who is truly at fault. Regardless of the outcome of such events, contemporaneous audio-video evidence can be extremely valuable in respect of compliance- and enforcement-related events.\n\nUse of wearable cameras by police officers combined with video streaming and recording in an archive results in a record of the interactions of the officer with civilians and criminals. The small cameras are made by Axon, Looxcie, and probably other firms. Experiments with police use in Rialto, California in 2012 to 2013 resulted in a reduction of both complaints against officers and reduction in use of violence by officers. The public is shielded from police misconduct and the police officer from bogus complaints.\n\nBecause these body cameras are turned on for every encounter with the public, privacy issues have been brought up with specific emphasis on special victim cases such as rape or domestic violence. Police worry that with a camera right in front of the victim, they will not feel comfortable in revealing all the information that they know. There have been two case studies done in the United States that have revealed that police officers who have cameras have fewer encounters with citizens than officers who do not have cameras, due to fear of being reprimanded for committing a mistake.\n\nIn the era of web-based participatory media and convergence cultures, non-governmental and non-state actors, with their own virtual communities and networks that cut across national borders, use what Bakir (2010) calls the sousveillant assemblage to wield discursive power. The sousveillant assemblage comprises Haggerty & Ericson's (2000) surveillant assemblage (or loosely linked, unstable, systems of data flows of people's activities, tracked by computers, and data-mined so that we are each reconfigured as (security) risks or (commercial) opportunities, but data-fattened by the proliferation of web-based participatory media and personal sousveillance that we willingly provide online).\n\nFeatures of sousveillance cultures:\nUndoubtedly, the urge and practice of dissent has always been with us, and people exploit the participatory media technologies at hand to mark and spread their dissent. However, the rise of web-based participatory media and sousveillance cultures have made it easier for many more to record and spread this dissent globally, unimpeded by traditional media's commercial distribution restrictions such as pre-defined circulation runs or paid-for airtime, or the need for expert knowledge in media production. Mann has long maintained that the 'informal nature of sousveillance, with its tendency to distribute recordings widely, will often expose inappropriate use to scrutiny, whereas the secret nature of surveillance will tend to prevent misuse from coming to light' (Mann, 2005, p. 641). \nJust as Foucault's Panopticon operates through potential or implied surveillance, so sousveillance might also operate through the credible threat of its existence. As the ubiquity and awareness of sousveillance widens, it is this that may most empower citizens – by making officials realise that their actions may, themselves, be monitored and exposed at any time. The permanent potential for sousveillance from so many (as opposed to more formalised exposés at the hands of investigative reporters, a small media elite) raises the likelihood that power abuses will be captured on record which can then be used to hold power-abusers and manipulators to account, providing of course, that there is a functioning legal system and/or public sphere (with mechanisms in place to translate popular demands and moral outrage into real-world change). \nIn the case of police body camera implementation in the US, there are multiple responses and social implications to this form of sousveillance. The case against police brutality and the Black Lives Matter movement has garnered an immense and impassioned following in a very short amount of time. There are two different social movements that have arisen in response to police body cameras. One school of thought that has manifested support is that police body cameras are necessary in fighting and ending police brutality. The other is the opposing stance to this one that raises the issue of privacy that police body cameras may violate. There have not been many case studies that have taken place in implementing police body cameras. This means that police worn body cameras have not been proven as a definite method to solve the problem of police brutality. Studies have also shown that people, both policemen and civilians, act differently when they are aware that they are being surveilled on camera. This leaves a lot of room for unpredictability surrounding the consequences of the use of this form of sousveillance.\n\nIn Mann's original conception, sousveillance had an emancipatory political thrust, with hierarchical sousveillance a conscious act of resistance to surveillance. Yet, the nature of the social change generated is unpredictable, and dependent on the sousveillant content, the context of its subsequent sharing, and, of course, the strength of the traditions of deliberation for democratic purposes. ISIS' use of sousveillance, then, may result in social change, but not in a progressive fashion.\nGiven the lack of secrecy inherent in placing sousveillant content online, the anonymity of the sousveillers is of prime importance if hierarchical (politically or legally motivated) sousveillance is to proliferate. There is a real need for spaces online that are willing to protect users' anonymity and keep their subversive content online despite political or corporate pressure. With this sort of situation in mind, whistle-blowing web sites have been set up that guarantee anonymity, such as Wiki-leaks, launched in December 2006. More such sites are needed.\nSocial media provide what could be described as a semi-permanent, and easily accessible, database of eyewitness accounts. Given that the web can be used and searched in the manner of a database to find examples of sousveillance; and given the recirculation of sousveillant footage in memes and in mainstream media, ever-hungry for new content in a media environment of convergence and expanding capacity, the longevity of sousveillant footage is perhaps what gives sousveillance its agenda-building power. It allows journalists, citizens, activists, insurgents, strategic communicators and researchers the opportunity to discover and partially relive both the eye-witnessed, sousveillant account, and the discourse surrounding specific moments of sousveillance, as well as reflecting on, and marshalling, their significance.\n\nReferred to as an early proponent of lifelogging and perhaps the most extreme example of self-tracking since 2003, conceptual media artist Alberto Frigo has embarked on an ambitious project, 2004–2040, to understand himself. Starting with tracking everything his right (dominant) hand has used, he's slowly added on different tracking and documentation projects. Keeping the focus on himself and his surrounding has helped him connect to himself and the world around him.\n\nArtist, scientist, and inventor S. Mann also created a wearable interactive art piece, the HeartCam, July 2001 in order to reverse the male gaze. Others, including Nestle, have built upon this concept of reversing the \"male gaze\" using a bra as a point-of-view for a camera.\n\nInvisibility/Aposematic Suit, S. Mann, 2001, is a wearable art piece that has two modes of operation: it either (1) becomes \"transparent\", suggestive of a chameleon's invisibility cloak (to hide from predators). In this mode of operation the video displays show what is behind the wearer, as if we can see through the wearer from both front and back; or\n(2) reflective like a mirror, thus aposematic, to deter predators (i.e., to let them know they're being watched by the many hidden wearable cameras). In this mode the wearer becomes like a two-sided video mirror. A potential attacker, whether approaching the wearer from the front, or sneaking up behind the wearer, sees themselves displayed on the aposematic suit, in a manner similar to the way that department stores often place large video displays of their surveillance camera feed at the entrance to let potential shoplifters know they are being watched.\n\nOther similar projects include the work of Shinseungback Kimyonghun: \"[the] Aposematic Jacket is a wearable computer for self-defense. The lenses on the jacket give off the warning signal, \" ... I can record you\"..., to prevent possible attack. When the wearer pushes a button under threat, the jacket records the scene in 360 degrees and sends the images to the Web.\"\n\nDavid Brin's 1989 novel \"Earth\" portrays citizens equipped with both augmented reality gear (\"Tru-Vu Goggles\") and cameras exercising reciprocal accountability, with each other and with authority figures, discussing effects on crime and presaging today's \"cop cam\" developments. Elites are allowed only temporary, cached secrecy. In Robert Sawyer's Neanderthal Parallax trilogy, the Homo neanderthalensis occupying a parallel universe have what are called companion implants. These are comprehensive recording and transmission devices, mounted in the forearm of each person. Their entire life is constantly monitored and sent to their alibi archive, a repository of recordings that are only accessible by their owner, or by the proper authorities when investigating an infraction, and in the latter case only in circumstances relevant to the investigation. Recordings are maintained after death; it is not made clear what the reasoning is for this and under what circumstances and or by whom a deceased person's archive can be accessed.\n\nThe plot of the 1995 movie \"Strange Days\" is based on a future where sousveillance recordings are made and sold as entertainment. The plot of the movie revolves around the murder of a celebrity by police officers that is recorded by a person secretly wearing one of the devices. In the movie, the recordings are made by a flat array of sensors that pick up signals from the brain stem. The sensors are usually hidden under a wig, and they record everything the person wearing them sees and hears. Recordings made while the person making them dies are called \"blackjack\" tapes.\n\nThe plot of the 1985 John Crowley short story \"Snow\" revolves around a suspended camera recording the whole of a subject's life being sold as a consumer product.\n\nThe 2007 novel \"Halting State\" by Charles Stross and its sequel \"Rule 34\" depict a 2020s Scotland in which wearable computing has a level of ubiquity similar to that of 2013's cell phones. The implications of a society in which anyone might be recording anything at any time are explored at length, particularly with respect to policing.\n\nThe open source science fiction role-playing game \"Eclipse Phase\" has sousveillance as a common part of life in the setting, as a result of data storage technology and high definition digital cameras becoming commonplace and often integrated into any and all objects.\n\nThere is a need for efficacy, efficiency or effectiveness of sousveillance,\nwhich can be met by social media, such as through widespread dissemination on social media, and when used as an output modality in conjunction with sousveillance as an input modality,\nis called \"swollag\", or gallows spelled backwards. For example, filming or streaming an abusive situation, like police abuse, doesn't always lead to justice and punishment of the abuser without some means (i.e. swollag) for sousveillance to take effect. For example, in 2014, a man named Eric Garner was choked to death by a police officer in Staten Island after being arrested on suspicion of selling loose cigarettes. \"Garner's death was documented by his friend Ramsey Orta, and the video was widely disseminated. Despite the video evidence, a grand jury declined to indict Garner's killer, leading to widespread outrage and protest. (In an ironic twist, the only person indicted in connection with Garner's death was Orta, who came under police scrutiny and was arrested on an \"unrelated\" weapons possession charge. Orta is now in prison in New York. Sousveillance is not without its costs.)\"\n\nHowever, it appeared that a filmed abusive behavior is more likely to be punished if the video is widely spread. This makes sousveillance more efficient and politically meaningful , insofar it shows to a significant proportion of the population the abuses of the authority. Thus, the development of video platforms, like Youtube and Snapchat, and streaming platforms like Periscope and Twitch, are key components to sousveillance's efficiency. This was shown during French demonstrations against the \"Loi Travail\" in 2016, during which a Periscope stream showing authority forces, called abusive by one part of the demonstrants, was watched by 93,362 people. This video was posted on Twitter. Nevertheless, it can be considered whether this creates a dangerous dependence on private platforms, often ruled by Internet giants (like Google, for YouTube) which have common interests with governments, and who adapt their content through algorithms users don't have control on.\n\nIn addition, some argue that sousveillance may aid in state surveillance, despite being conducted by the people. Examples include mobile apps used to help people signal public threats, such as the Israeli app c-Now (previously known as Reporty). In January 2018, c-Now was tested in Nice by mayor Christian Estrosi, sparking virulent public debates, with security advocates reporting spyware associated with the app Furthermore, the director of c-Now is Ehud Barack, former prime minister of Israel, who is suspected to have kept close links with Israeli and American governments. For these reasons, security advocates consider the app to serve America's global surveillance program (revealed by Edward Snowden in 2013), and raise the question of whether sousveillance really serves as \"inverse surveillance\".\n\n\n"}
{"id": "32473782", "url": "https://en.wikipedia.org/wiki?curid=32473782", "title": "St Albans Press", "text": "St Albans Press\n\nThe St Albans Press was the third printing press set up in England, in 1479. It was situated in the Abbey Gateway, St Albans, a part of the Benedictine Monastery of St Albans. The name of the printer is unknown, only referred to by Wynkyn de Worde in a reprinting of one of the St Albans books as 'Sometime schoolmaster'. He has sometimes been identified as John Marchall, master of St Albans School; however, a passage written by Worde in 1497 implies that the printer was deceased, and Marchall is known to have lived until 1501. Recent research has produced the name John Haule as a possible candidate for the Schoolmaster Printer. He presented the school with its first printed textbook, the \"Elegantiolae\", which was the first book printed at the press, and he was a printer, probably in St Albans in 1479.\n\nHowever, the historian Nicholas Orme, in his “Medieval Schools, From Roman Britain to Renaissance England”, states, “Books were also acquired by schools and institutions. One of the earliest known is a \"Priscian Major\" [the first sixteen books of Priscian's Latin grammar, the \"Institutiones grammaticae\"] given to St Albans school by John Haule, apparently before 1310.\" Orme was citing the register of the abbots of St Albans: “Item, Johannes Haule praedictis Scolis dedit Priscianum magnum.”\n\nLotte Hellinga has suggested that “there were several people working successively at the abbey.” Printing was done in St Albans in two distinct phases, probably by two printers or teams of printers. During the first phase, from 1479 to 1481, they printed six books in Latin for grammar school and university students, with a high standard of typesetting and printing. Then there was an interval of five years, after which printing resumed in 1486. During the second phase, they printed two books in English for a more general audience, with a lower standard of technical skill. \n\nOne possible candidate for the Schoolmaster Printer is William Waren. He was identified as William Waren, Master of Grammar and warden of the Grammar School of St Albans in a case in Common Pleas recorded from 1486 to 1489. He was the plaintiff against the Abbot of St Albans for a debt of 36 pounds. William Waren was awarded Master of Grammar at Cambridge in 1468-9. In his will, written in February and proven in March 1489/90, he requests to be buried in the nave of the Abbey church. \n\nThere was another printer active in St Albans in the 1530s. In cases in Common Pleas in 1535, he is recorded as Richard Baugh, of St Albans, printer, and as Richard Baugh alias Waters, of St Albans, stationer. \n\nThere are eight known printed works which came from the press:\n\n\nThe Press now exists as a holding company, John Insomuch Schoolmaster Printer 1479 Ltd, incorporated 1996, owned by St Albans School.\n"}
{"id": "1485054", "url": "https://en.wikipedia.org/wiki?curid=1485054", "title": "Sunless tanning", "text": "Sunless tanning\n\nSunless tanning, also known as UV filled tanning, self tanning, spray tanning (when applied topically), or fake tanning, refers to the application of chemicals to the skin to produce an effect similar in appearance to a suntan. The popularity of sunless tanning has risen since the 1960s after health authorities confirmed links between UV exposure (from sunlight or tanning beds) and the incidence of skin cancer.\n\nSince sunscreen absorbs ultraviolet light and prevents it from reaching the skin, it will prevent tanning. It has been reported that sunscreen with a sun protection factor (SPF) of 8 based on the UVB spectrum can decrease vitamin D synthetic capacity by 95 percent, whereas sunscreen with an SPF of 15 can reduce synthetic capacity by 98 percent.\n\nA safe and effective method of sunless tanning is consumption of certain carotenoids — antioxidants found in some fruits and vegetables such as carrots and tomatoes — which can result in changes to skin color when ingested chronically and/or in high amounts. Carotenoids are long-lasting. In addition, carotenoids have been linked to more attractive skin tone (defined as a more golden skin color) than suntan. Carotenes also fulfil the function of melanin in absorbing the UV radiation and protecting the skin. For example, they are concentrated in the macula of the eye to protect the retina from damage. They are used in plants both to protect chlorophyll from light damage and harvest light directly.\n\nCarotenaemia (xanthaemia) is the presence in blood of the yellow pigment carotene from excessive intake of carrots or other vegetables containing the pigment resulting in increased serum carotenoids. It can lead to subsequent yellow-orange discoloration (xanthoderma or carotenoderma) and their subsequent deposition in the outermost layer of skin. Carotenemia and carotenoderma is in itself harmless, and does not require treatment. In primary carotenoderma, when the use of high quantities of carotene is discontinued the skin color will return to normal. It may take up to several months, however, for this to happen.\n\nLycopene is a key intermediate in the biosynthesis of beta-carotene and xanthophylls.\n\nLycopene may be the most powerful carotenoid quencher of singlet oxygen.\n\nDue to its strong color and non-toxicity, lycopene is a useful food coloring (registered as E160d) and is approved for usage in the USA, Australia and New Zealand (registered as 160d) and the EU.\n\nSunless-tanning pills often contain β-carotene. The American Cancer Society states that \"Although the US Food and Drug Administration (FDA) has approved some of these additives for coloring food, they are not approved for use in tanning agents.\" Also that \"They may be harmful at the high levels that are used in tanning pills.\".\n\nChronic, high doses of synthetic β-carotene supplements have been associated with increased rate of lung cancer among those who smoke.\n\nCanthaxanthin is most commonly used as a color additive in certain foods. Although the FDA has approved the use of canthaxanthin in food, it does not approve its use as a tanning agent. When used as a color additive, only very small amounts of canthaxanthin are necessary. As a tanning agent, however, much larger quantities are used. After canthaxanthin is consumed, it is deposited throughout the body, including in the layer of fat below the skin, which turns an orange-brown color. These types of tanning pills have been linked to various side effects, including hepatitis and canthaxanthin retinopathy, a condition in which yellow deposits form in the retina of the eye. Other side effects including damage to the digestive system and skin surface have also been noted. The FDA withdrew approval for use of canthaxanthin as a tanning agent, and has issued warnings concerning its use.\n\nDHA (Dihydroxyacetone, also known as glycerone) is not a dye, stain or paint, but causes a chemical reaction with the amino acids in the dead layer on the skin surface. One of the pathways is a free radical-mediated Maillard reaction. The other pathway is the conventional Maillard reaction, a process well known to food chemists that causes the browning that occurs during food manufacturing and storage. It does not involve the underlying skin pigmentation nor does it require exposure to ultraviolet light to initiate the color change. However, for the 24 hours after self-tanner is applied, the skin is especially susceptible to ultraviolet, according to a 2007 study led by Katinka Jung of the Gematria Test Lab in Berlin. Forty minutes after the researchers treated skin samples with high levels of DHA they found that more than 180 percent additional free radicals formed during sun exposure compared with untreated skin. Another self-tanner ingredient, erythrulose, produced a similar response at high levels. For a day after self-tanner application, excessive sun exposure should be avoided and sunscreen should be worn outdoors, they say; an antioxidant cream could also minimize free radical production. Although some self-tanners contain sunscreen, its effect will not last long after application, and a fake tan itself will not protect the skin from UV exposure.\nThe study by Jung et al. further confirms earlier results demonstrating that dihydroxyacetone in combination with dimethylisosorbide enhances the process of (sun-based) tanning. This earlier study also found that dihydroxyacetone also has an effect on the amino acids and nucleic acids which is bad for the skin.\n\nThe free radicals are due to the action of UV light on AGE (advanced glycation end-products) as a result of the reaction of DHA with the skin, and the intermediates, such as Amadori products (a type of AGE), that lead to them. AGEs are behind the damage to the skin that occurs with high blood sugar in diabetes where similar glycation occurs. AGEs absorb and provide a little protection against some of the damaging factors of UV (up to SPF 3), However, they do not have melanin's extended electronic structure that dissipates the energy, so part of it goes towards starting free radical chain reactions instead, in which other AGEs participate readily. Overall tanner enhances free radical injury.\nAlthough some self-tanners contain sunscreen, its effect will not last as long as the tan. The stated SPF is only applicable for a few hours after application. Despite darkening of the skin, an individual is still susceptible to UV rays, therefore an overall sun protection is still very necessary. There may also be some inhibition of vitamin D production in DHA-treated skin.\n\nThe color effect is temporary and fades gradually over 3 to 10 days. Some of these products also use erythrulose which works identically to DHA, but develops more slowly. Both DHA and erythrulose have been known to cause contact dermatitis.\n\nProfessional spray tan applications are available from spas, salons and gymnasiums by both hand-held sprayers and in the form of sunless or UV-Free spray booths. Spray tan applications are also available through online retail distribution channels and are widely available to purchase for in home use. The enclosed booth, which resembles an enclosed shower stall, sprays the tanning solution over the entire body. The U.S. Food and Drug Administration (FDA) states when using DHA-containing products as an all-over spray or mist in a commercial spray \"tanning\" booth, it may be difficult to avoid exposure in a manner for which DHA is not approved, including the area of the eyes, lips, or mucous membrane, or even internally. DHA is not approved by the FDA for inhalation.\n\nAn opinion issued by the European Commission's Scientific Committee on Consumer Safety, concluding spray tanning with DHA did not pose risk, has been heavily criticized by specialists. This is because the cosmetics industry in Europe chose the evidence to review, according to the commission itself. Thus, nearly every report the commission's eventual opinion referenced came from studies that were never published or peer-reviewed and, in the majority of cases, were performed by companies or industry groups linked to the manufacturing of DHA. The industry left out nearly all of the peer-reviewed studies published in publicly available scientific journals that identified DHA as a potential mutagen. A study by scientists from the Department of Dermatology, Bispebjerg Hospital, published in Mutation Research has concluded DHA 'induces DNA damage, cell-cycle block and apoptosis' in cultured cells.\n\nA novel class of compounds has been found to stimulate melanogenesis in a mechanism that is independent from α-melanocyte-stimulating hormone (α-MSH) activation of the melanocortin 1 receptor (MC receptor). This is accomplished via small molecule inhibition of salt-inducible kinases (SIK). Inhibition of SIK increases transcription of MITF which is known to increase melanin production. Work published in Cell Reports in June 2017 by Mujahid et al. from Massachusetts General Hospital Department of Dermatology has demonstrated compounds that have efficacy when applied topically to human skin. These compounds are still however in pre-clinical stages of development. Future directions may include the incorporation of SIK-inhibitor compounds with traditional UV-blocking sunscreens to minimize UV-related DNA damage in the short term while providing longer term protection through endogenous melanin production.\n\nTanning accelerators—lotions or pills<ref name=\"US FDA/CFSAN - Tanning Pills\">US FDA/CFSAN - Tanning Pills</ref> that usually contain the amino acid tyrosine—claim that they stimulate and increase melanin formation, thereby accelerating the tanning process. These are used in conjunction with UV exposure. At this time, there is no scientific data available to support these claims.\n\nThe role of alpha-melnocyte-stimulating hormone (α-MSH) in promoting melanin diffusion has been known since the 1960s. In the 1980s, scientists at University of Arizona began attempting to develop α-MSH and analogs as potential sunless tanning agents, and synthesized and tested several analogs, including afamelanotide, then called melanotan-I.\n\nTo pursue the tanning agent, melanotan-I was licensed by Competitive Technologies, a technology transfer company operating on behalf of University of Arizona, to an Australian startup called Epitan, which changed its name to Clinuvel in 2006.\n\nA number of products are sold online and in gyms and beauty salons as \"melanotan\" or \"melanotan-1\" which discuss afamelanotide in their marketing. \n\nThe products are not legal in any jurisdiction and are dangerous.\n\nStarting in 2007 health agencies in various counties began issuing warnings against their use. \n\nEicosanoids, retinoids, oestrogens, melanocyte-stimulating hormone, endothelins, psoralens, hydantoin, forskolin, cholera toxin, isobutylmethylxanthine, diacylglycerol analogues, and UV irradiation all trigger melanogenesis and, in turn, pigmentation.\n\nBronzers are a temporary sunless tanning or bronzing option. These come in powders, sprays, mousse, gels, lotions and moisturizers. Once applied, they create a tan that can easily be removed with soap and water. Like make-up, these products tint or stain a person's skin only until they are washed off.\n\nThey are often used for \"one-day\" only tans, or to complement a DHA-based sunless tan. Many formulations are available, and some have limited sweat or light water resistance. If applied under clothing, or where fabric and skin edges meet, most will create some light but visible rub-off. Dark clothing prevents the rub-off from being noticeable. While these products are much safer than tanning beds, the color produced can sometimes look orangey and splotchy if applied incorrectly.\n\nA recent trend is that of lotions or moisturizers containing a gradual tanning agent. A slight increase in color is usually observable after the first use, but color will continue to darken the more the product is used.\n\nAir brush tanning is a spray on tan performed by a professional. An air brush tan can last five to ten days and will fade when the skin is washed. It is used for special occasions or to get a quick dark tan. At-home airbrush tanning kits and aerosol mists are also available.\n\nTanners usually contain a sunscreen. However, when avobenzone is irradiated with UVA light, it generates a triplet excited state in the keto form which can either cause the avobenzone to degrade or transfer energy to biological targets and cause deleterious effects.\nIt has been shown to degrade significantly in light, resulting in less protection over time. The UV-A light in a day of sunlight in a temperate climate is sufficient to break down most of the compound. It's important to continue wearing SPF while self-tanning, as self-tanner is generally a fake and temporary tan, and your skin is still sensitive to the sun.\n\nIf avobenzone-containing sunscreen is applied on top of tanner, the photosensitizer effect magnifies the free-radical damage promoted by DHA, as DHA may make the skin especially susceptible to free-radical damage from sunlight, according to a 2007 study led by Katinka Jung of the Gematria Test Lab in Berlin. Forty minutes after the researchers treated skin samples with 20% DHA they found that more than 180 percent additional free radicals formed during sun exposure compared with untreated skin.\n\nA toxicologist and lung specialist at the University of Pennsylvania's Perelman School of Medicine (Dr. Rey Panettieri) has commented, \"The reason I'm concerned is the deposition of the tanning agents into the lungs could really facilitate or aid systemic absorption -- that is, getting into the bloodstream. These compounds in some cells could actually promote the development of cancers or malignancies, and if that's the case then we need to be wary of them.\" A study by scientists from the Department of Dermatology, Bispebjerg Hospital, published in Mutation Research has concluded DHA 'induces DNA damage, cell-cycle block and apoptosis' in cultured cells.\n\nMany self tanners use chemical fragrances which may cause skin allergies or may trigger asthma. Furthermore, some of them contain parabens. Parabens are preservatives that can affect the endocrine system.\n\n\n"}
{"id": "32863514", "url": "https://en.wikipedia.org/wiki?curid=32863514", "title": "Travel Technology Interactive", "text": "Travel Technology Interactive\n\nTravel Technology Interactive Group (also known as TTI) is a French-based international company. It is specialized in IT software for the management of airlines. It provides an Airline Reservations System with an integrated Global Distribution System (GDS).\n\nThe company was originally created in 2001, as a dedicated IT company for Air Antilles Express.\nIn 2005, it became an Amadeus IT Group worldwide business partner. In August 2006, it became an IATA StB Preferred Partner. The next year, it acquired a competitor in Latin America, CIONS Software, a Brazilian IT company based in Ribeirao Preto (Brazil) and renamed it \"TTI do Brasil\". In November 2007, it opened its first subsidiary, \"TTI Caraïbes\", based in Baie-Mahault (Guadeloupe). In May 2008, Travel Technology Interactive signed a cooperation agreement with Hahn Air for it to provide complementary BSP distribution services to Travel Technology Interactive’s airline customers. In 2010, the company opened its subsidiary \"TTI Asia\" in Singapore.\nOn April 18, 2011, Travel Technology Interactive was listed on NYSE Alternext in Paris.\n\n"}
{"id": "174818", "url": "https://en.wikipedia.org/wiki?curid=174818", "title": "Wood gas", "text": "Wood gas\n\nWood gas is a syngas fuel which can be used as a fuel for furnaces, stoves and vehicles in place of gasoline, diesel or other fuels. During the production process biomass or other carbon-containing materials are gasified within the oxygen-limited environment of a wood gas generator to produce hydrogen and carbon monoxide. These gases can then be burnt as a fuel within an oxygen rich environment to produce carbon dioxide, water and heat. In some gasifiers this process is preceded by pyrolysis, where the biomass or coal is first converted to char, releasing methane and tar rich in polycyclic aromatic hydrocarbons.\n\nThe first wood gasifier was apparently built by Gustav Bischof in 1839. The first vehicle powered by wood gas was built by Thomas Hugh Parker in 1901. Around 1900, many cities delivered syngas (centrally produced, typically from coal) to residences. Natural gas began to be used only in 1930.\n\nWood gas vehicles were used during World War II as a consequence of the rationing of fossil fuels. In Germany alone, around 500,000 \"producer gas\" vehicles were in use at the end of the war. Trucks, buses, tractors, motorcycles, ships and trains were equipped with a wood gasification unit. In 1942, when wood gas had not yet reached the height of its popularity, there were about 73,000 wood gas vehicles in Sweden, 65,000 in France, 10,000 in Denmark, and almost 8,000 in Switzerland. In 1944, Finland had 43,000 \"woodmobiles\", of which 30,000 were buses and trucks, 7,000 private vehicles, 4,000 tractors and 600 boats.\n\nWood gasifiers are still manufactured in China and Russia for automobiles and as power generators for industrial applications. Trucks retrofitted with wood gasifiers are used in North Korea in rural areas, particularly on the roads of the east coast.\n\nWood gasifiers can power either spark ignition engines, where all of the normal fuel can be replaced with little change to the carburation, or in a Diesel engine, feeding the gas into the air inlet that is modified to have a throttle valve, if it didn't have it already. On Diesel engines the Diesel fuel is still needed to ignite the gas mixture, so a mechanically regulated Diesel engine's \"stop\" linkage and probably \"throttle\" linkage must be modified to always give the engine a little bit of injected fuel, often under the standard idle per-injection volume. Wood can be used to power cars with ordinary internal combustion engines if a wood gasifier is attached. This was quite popular during World War II in several European, African and Asian countries, because the war prevented easy and cost-effective access to oil. In more recent times, wood gas has been suggested as a clean and efficient method to heat and cook in developing countries, or even to produce electricity when combined with an internal combustion engine. Compared to World War II technology, gasifiers have become less dependent on constant attention due to the use of sophisticated electronic control systems, but it remains difficult to get clean gas from them. Purification of the gas and feeding it into natural gas pipelines is one variant to link it to the existing refueling infrastructure. Liquefaction by the Fischer–Tropsch process is another possibility.\n\nEfficiency of the gasifier system is relatively high. The gasification stage converts about 75% of fuel energy content into a combustible gas that can be used as a fuel for internal combustion engines. Based on long-term practical experiments and over driven with a wood gas-powered car, the energy consumption has been 1.54 times higher compared to the energy demand of the same car on petrol, excluding the energy needed to extract, transport and refine the oil from which petrol is derived, and excluding the energy to harvest, process, and transport the wood to feed the gasifier. This means that of wood combustible matter has been found to be equivalent to of petrol during real transportation in similar driving conditions and with the same, otherwise unmodified, vehicle. This can be considered to be a good result, because no other refining of the fuel is required. This study also considers all possible losses of the wood gas system, like preheating of the system and carrying of the extra weight of the gas-generating system. In power generation, reported demand of fuel is wood combustible matter per kilowatt-hour of electricity.\n\nGasifiers have been built for remote Asian communities using rice hulls, which in many cases have no other use. One installation in Burma uses an 80 kW modified Diesel-powered electric generator for about 500 people who are otherwise without power. The ash can be used as biochar fertilizer, so this can be considered a renewable fuel.\n\nExhaust gas emission from an internal combustion engine is significantly lower on wood gas than on petrol. Especially the hydrocarbon emissions are low on wood gas. A normal catalytic converter works well with wood gas, but even without it, emission levels less than 20 ppm HC and 0.2% CO can be easily achieved by most automobile engines. Combustion of wood gas generates no particulates, and the gas renders thus very little carbon black amongst motor oil.\n\nCertain stove designs are, in effect, gasifiers working on the updraft principle: The air passes up through the fuel, which can be a column of rice hulls, and is combusted, then reduced to carbon monoxide by the residual char on the surface. The resulting gas is then burnt by heated secondary air coming up a concentric tube. Such a device behaves very much like a gas stove. This arrangement is also known as a Chinese burner.\n\nAn alternative stove based on the down-draft principle and typically built with nested cylinders also provides high efficiency. Combustion from the top creates a gasification zone, with the gas escaping downwards through ports located at the base of the burner chamber. The gas mixes with additional incoming air to provide a secondary burn. Most of the CO produced by gasification is oxidized to in the secondary combustion cycle; therefore, gasification stoves carry lower health risks than conventional cooking fires.\n\nAnother application is the use of producer gas to displace light density fuel oil (LDO) in industrial furnaces.\n\nA wood gasifier takes wood chips, sawdust, charcoal, coal, rubber or similar materials as fuel and burns these incompletely in a fire box, producing wood gas, solid ash and soot, the latter of which have to be removed periodically from the gasifier. The wood gas can then be filtered for tars and soot/ash particles, cooled and directed to an engine or fuel cell. Most of these engines have strict purity requirements of the wood gas, so the gas often has to pass through extensive gas cleaning in order to remove or convert, \"i.e.\", \"crack\", tars and particles. The removal of tar is often accomplished by using a water scrubber. Running wood gas in an unmodified gasoline-burning internal combustion engine may lead to problematic accumulation of unburned compounds.\n\nThe quality of the gas from different gasifiers varies a great deal. Staged gasifiers, where pyrolysis and gasification occur separately, instead of in the same reaction zone as was the case in, \"e.g.\", the World War II gasifiers, can be engineered to produce essentially tar-free gas (less than 1 mg/m³), while single-reactor fluid-bed gasifiers may exceed 50,000 mg/m³ tar. The fluid bed reactors have the advantage of being much more compact, with more capacity per unit volume and price. Depending on the intended use of the gas, tar can be beneficial, as well by increasing the heating value of the gas.\n\nThe heat of combustion of \"producer gas\" — a term used in the United States meaning wood gas produced for use in a combustion engine — is rather low compared to other fuels. Taylor reports that producer gas has a lower heat of combustion of 5.7 MJ/kg versus 55.9 MJ/kg for natural gas and 44.1 MJ/kg for gasoline. The heat of combustion of wood is typically 15-18 MJ/kg. Presumably, these values can vary somewhat from sample to sample. The same source reports the following chemical composition by volume which most likely is also variable:\n\nDuring the production of charcoal for blackpowder, the volatile wood gas is vented. Extremely-high-surface-area carbon results, suitable for use as a fuel in black powder.\n\n\nIt is pointed out that the gas composition is strongly dependent on the gasification process, the gasification medium (air, oxygen or steam) and the fuel moisture. Steam-gasification processes typically yield high hydrogen contents, downdraft fixed bed gasifiers yield high nitrogen concentrations and low tar loads, while updraft fixed bed gasifiers yield high tar loads.\n\n\n"}
{"id": "296081", "url": "https://en.wikipedia.org/wiki?curid=296081", "title": "Yagi–Uda antenna", "text": "Yagi–Uda antenna\n\nA Yagi–Uda antenna, commonly known as a Yagi antenna, is a directional antenna consisting of multiple parallel elements in a line, usually half-wave dipoles made of metal rods. Yagi–Uda antennas consist of a single driven element connected to the transmitter or receiver with a transmission line, and additional \"parasitic elements\" which are not connected to the transmitter or receiver: a so-called \"reflector\" and one or more \"directors\". It was invented in 1926 by Shintaro Uda of Tohoku Imperial University, Japan, and (with a lesser role played by his colleague) Hidetsugu Yagi.\n\nThe reflector element is slightly longer than the driven dipole, whereas the directors are a little shorter. The parasitic elements absorb and reradiate the radio waves from the driven element with a different phase, modifying the dipole's radiation pattern. The waves from the multiple elements superpose and interfere to enhance radiation in a single direction, achieving a very substantial increase in the antenna's gain compared to a simple dipole.\n\nAlso called a \"beam antenna\", or \"parasitic array\", the Yagi is very widely used as a high-gain antenna on the HF, VHF and UHF bands. It has moderate to high gain which depends on the number of elements used, typically limited to about 20 dBi, linear polarization, unidirectional (end-fire) beam pattern with high front-to-back ratio of up to 20 db. and is lightweight, inexpensive and simple to construct. The bandwidth of a Yagi antenna, the frequency range over which it has high gain, is narrow, a few percent of the center frequency, and decreases with increasing gain, so it is often used in fixed-frequency applications. The largest and best-known use is as rooftop terrestrial television antennas, but it is also used for point-to-point fixed communication links, in radar antennas, and for long distance shortwave communication by shortwave broadcasting stations and radio amateurs.\n\nThe antenna was invented in 1926 by Shintaro Uda of Tohoku Imperial University, Japan, with a lesser role played by his colleague Hidetsugu Yagi.\n\nHowever the \"Yagi\" name has become more familiar with the name of Uda often omitted. This appears to have been due to Yagi filing a patent on the idea in Japan without Uda's name in it, and later transferring the patent to the Marconi Company in the UK.\n\nYagi antennas were first widely used during World War II in radar systems by the British, US, Germans and Japanese. After the war they saw extensive development as home television antennas.\n\nThe Yagi–Uda antenna consists of a number of parallel thin rod elements in a line, usually half-wave long, typically supported on a perpendicular crossbar or \"boom\" along their centers. There is a single driven element driven in the center (consisting of two rods each connected to one side of the transmission line), and a variable number of parasitic elements, a single \"reflector\" on one side and optionally one or more \"directors\" on the other side. The parasitic elements are not electrically connected to the transmitter or receiver, and serve as passive radiators, reradiating the radio waves to modify the radiation pattern. Typical spacings between elements vary from about to ¼ of a wavelength, depending on the specific design. The directors are slightly shorter than the driven element, while the reflector(s) are slightly longer. The radiation pattern is unidirectional, with the main lobe along the axis perpendicular to the elements in the plane of the elements, off the end with the directors.\n\nConveniently, the dipole parasitic elements have a node (point of zero RF voltage) at their centre, so they can be attached to a conductive metal support at that point without need of insulation, without disturbing their electrical operation. They are usually bolted or welded to the antenna's central support boom. The driven element is fed at centre so its two halves must be insulated where the boom supports them.\n\nThe gain increases with the number of parasitic elements used. Only one reflector is used since the improvement of gain with additional reflectors is negligible, but Yagis have been built with up to 30–40 directors.\n\nThe bandwidth of the antenna is the frequency range between the frequencies at which the gain drops 3 dB (one-half the power) below its maximum. The Yagi–Uda array in its basic form has very narrow bandwidth, 2–3 percent of the centre frequency. There is a tradeoff between gain and bandwidth, with the bandwidth narrowing as more elements are used. For applications that require wider bandwidths, such as terrestrial television, Yagi–Uda antennas commonly feature trigonal reflectors, and larger diameter conductors, in order to cover the relevant portions of the VHF and UHF bands. Wider bandwidth can also be achieved by the use of \"traps\", as described below.\n\nYagi–Uda antennas used for amateur radio are sometimes designed to operate on multiple bands. These elaborate designs create electrical breaks along each element (both sides) at which point a parallel LC (inductor and capacitor) circuit is inserted. This so-called \"trap\" has the effect of truncating the element at the higher frequency band, making it approximately a half wavelength in length. At the lower frequency, the entire element (including the remaining inductance due to the trap) is close to half-wave resonance, implementing a \"different\" Yagi–Uda antenna. Using a second set of traps, a \"triband\" antenna can be resonant at three different bands. Given the associated costs of erecting an antenna and rotor system above a tower, the combination of antennas for three amateur bands in one unit is a very practical solution. The use of traps is not without disadvantages, however, as they reduce the bandwidth of the antenna on the individual bands and reduce the antenna's electrical efficiency and subject the antenna to additional mechanical considerations (wind loading, water and insect ingress).\n\nConsider a Yagi–Uda consisting of a reflector, driven element and a single director as shown here. The driven element is typically a ½ \"λ\" dipole or folded dipole and is the only member of the structure that is directly excited (electrically connected to the feedline). All the other elements are considered \"parasitic\". That is, they reradiate power which they receive from the driven element (they also interact with each other).\n\nOne way of thinking about the operation of such an antenna is to consider a parasitic element to be a normal dipole element of finite diameter fed at its centre, with a short circuit across its feed point. As is well known in transmission line theory, a short circuit reflects all of the incident power 180 degrees out of phase. So one could as well model the operation of the parasitic element as the superposition of a dipole element receiving power and sending it down a transmission line to a matched load, and a transmitter sending the same amount of power up the transmission line back toward the antenna element. If the transmitted voltage wave were 180 degrees out of phase with the received wave at that point, the superposition of the two voltage waves would give zero voltage, equivalent to shorting out the dipole at the feedpoint (making it a solid element, as it is). Thus a half-wave parasitic element radiates a wave 180° out of phase with the incident wave.\n\nThe fact that the parasitic element involved is not exactly resonant but is somewhat shorter (or longer) than ½ \"λ\" modifies the phase of the element's current with respect to its excitation from the driven element. The so-called \"reflector\" element, being longer than ½ \"λ\" , has an inductive reactance which means the phase of its current lags the phase of the open-circuit voltage that would be induced by the received field. The \"director\" element, on the other hand, being shorter than ½ \"λ\" , has a capacitive reactance with the voltage phase lagging that of the current.\n\nThe elements are given the correct lengths and spacings so that the radio waves radiated by the driven element and those re-radiated by the parasitic elements all arrive at the front of the antenna in-phase, so they superpose and add, increasing signal strength in the forward direction. In other words, the crest of the forward wave from the reflector element reaches the driven element just as the crest of the wave is emitted from that element. These waves reach the first director element just as the crest of the wave is emitted from that element, and so on. The waves in the reverse direction interfere destructively, cancelling out, so the signal strength radiated in the reverse direction is small. Thus the antenna radiates a unidirectional beam of radio waves from the front (director end) of the antenna.\n\nWhile the above qualitative explanation is useful for understanding how parasitic elements can enhance the driven elements' radiation in one direction at the expense of the other, the assumptions used are quite inaccurate. Since the so-called reflector, the longer parasitic element, has a current whose phase lags that of the driven element, one would expect the directivity to be in the direction of the reflector, opposite of the actual directional pattern of the Yagi–Uda antenna. In fact, that would be the case were we to construct a phased array with rather closely spaced elements all driven by voltages in phase, as we posited.\n\nHowever these elements are not driven as such but receive their energy from the field created by the driven element, so we will find almost the opposite to be true. For now, consider that the parasitic element is also of length λ/2. Again looking at the parasitic element as a dipole which has been shorted at the feedpoint, we can see that if the parasitic element were to respond to the driven element with an open-circuit feedpoint voltage in phase with that applied to the driven element (which we'll assume for now) then the \"reflected\" wave from the short circuit would induce a current 180° out of phase with the current in the driven element. This would tend to cancel the radiation of the driven element. However, due to the reactance caused by the length difference, the phase lag of the current in the reflector, added to this 180° lag, results in a phase \"advance\", and vice versa for the director. Thus the directivity of the array indeed is in the direction towards the director.\n\nOne must take into account an additional phase delay due to the finite distance between the elements which further delays the phase of the currents in both the directors and reflector(s). The case of a Yagi–Uda array using just a driven element and a director is illustrated in the accompanying diagram taking all of these effects into account. The wave generated by the driven element (green) propagates in both the forward and reverse directions (as well as other directions, not shown). The director receives that wave slightly delayed in time (amounting to a phase delay of about 35° which will be important for the reverse direction calculations later), and generating a current that would be out of phase with the driven element (thus an additional 180° phase shift), but which is further \"advanced\" in phase (by about 70°) due to the director's shorter length. In the forward direction the net effect is a wave emitted by the director (blue) which is about 110° (180°–70°) retarded with respect to that from the driven element (green), in this particular design. These waves combine to produce the net forward wave (bottom, right) with an amplitude slightly larger than the individual waves.\n\nIn the reverse direction, on the other hand, the additional delay of the wave from the director (blue) due to the spacing between the two elements (about 35° of phase delay traversed twice) causes it to be about 180° (110° + 2  × 35°) out of phase with the wave from the driven element (green). The net effect of these two waves, when added (bottom, left), is almost complete cancellation. The combination of the director's position and shorter length has thus obtained a unidirectional rather than the bidirectional response of the driven (half-wave dipole) element alone.\n\nA full analysis of such a system requires computing the \"mutual impedances\" between the dipole elements which implicitly takes into account the propagation delay due to the finite spacing between elements. We model element number \"j\" as having a feedpoint at the centre with a voltage \"V\" and a current \"I\" flowing into it. Just considering two such elements we can write the voltage at each feedpoint in terms of the currents using the mutual impedances \"Z\":\n\n\"Z\" and \"Z\" are simply the ordinary driving point impedances of a dipole, thus 73 + j43 ohms for a half-wave element (or purely resistive for one slightly shorter, as is usually desired for the driven element). Due to the differences in the elements' lengths \"Z\" and \"Z\" have a substantially different reactive component. Due to reciprocity we know that \"Z\" = \"Z\". Now the difficult computation is in determining that mutual impedance \"Z\" which requires a numerical solution. This has been computed for two exact half-wave dipole elements at various spacings in the accompanying graph.\n\nThe solution of the system then is as follows. Let the driven element be designated 1 so that \"V\" and \"I\" are the voltage and current supplied by the transmitter. The parasitic element is designated 2, and since it is shorted at its \"feedpoint\" we can write that \"V\" = 0. Using the above relationships, then, we can solve for \"I\" in terms of \"I\":\n\nand so\nThis is the current induced in the parasitic element due to the current \"I\" in the driven element. We can also solve for the voltage \"V\" at the feedpoint of the driven element using the earlier equation:\nwhere we have substituted \"Z\" = \"Z\". The ratio of voltage to current at this point is the \"driving point impedance\" \"Z\" of the 2-element Yagi:\n\nWith only the driven element present the driving point impedance would have simply been \"Z\", but has now been modified by the presence of the parasitic element. And now knowing the phase (and amplitude) of \"I\" in relation to \"I\" as computed above allows us to determine the radiation pattern (gain as a function of direction) due to the currents flowing in these two elements. Solution of such an antenna with more than two elements proceeds along the same lines, setting each \"V\" = 0 for all but the driven element, and solving for the currents in each element (and the voltage \"V\" at the feedpoint).\n\nThere are no simple formulas for designing Yagi–Uda antennas due to the complex relationships between physical parameters such as\n\n\nHowever using the above kinds of iterative analysis one can calculate the performance of a given a set of parameters and adjust them to optimize the gain (perhaps subject to some constraints). Since with an element Yagi–Uda antenna, there are parameters to adjust (the element lengths and relative spacings).\nThis iterative analysis method is not a straightforward. The mutual impedances plotted above only apply to length elements, so these might need to be recomputed to get good accuracy. \n\nThe current distribution along a real antenna element is only approximately given by the usual assumption of a classical standing wave, requiring a solution of Hallen's integral equation taking into account the other conductors. Such a complete exact analysis considering all of the interactions mentioned is rather overwhelming, and approximations are inevitable on the path to finding a usable antenna.\n\nConsequently, these antennas are often empirical designs using an element of trial and error, often starting with an existing design modified according to one's hunch. The result might be checked by direct measurement or by computer simulation. \n\nA well-known reference employed in the latter approach is a report published by the National Bureau of Standards (NBS) (now the National Institute of Standards and Technology (NIST)) that provides six basic designs derived from measurements conducted at 400 MHz and procedures for adapting these designs to other frequencies. These designs, and those derived from them, are sometimes referred to as \"NBS yagis.\"\n\nBy adjusting the distance between the adjacent directors it is possible to reduce the back lobe of the radiation pattern.\n\nThe Yagi–Uda antenna was invented in 1926 by Shintaro Uda of Tohoku Imperial University, Sendai, Japan, with the collaboration of Hidetsugu Yagi, also of Tohoku Imperial University. Yagi and Uda published their first report on the wave projector directional antenna. Yagi demonstrated a proof of concept, but the engineering problems proved to be more onerous than conventional systems.\n\nYagi published the first English-language reference on the antenna in a 1928 survey article on short wave research in Japan and it came to be associated with his name. However, Yagi always acknowledged Uda's principal contribution to the design, and the proper name for the antenna is, as above, the Yagi–Uda antenna (or array).\n\nThe Yagi was first widely used during World War II for airborne radar sets, because of its simplicity and directionality. Despite being invented in Japan, many Japanese radar engineers were unaware of the design until very late in the war, partly due to rivalry between the Army and Navy. The Japanese military authorities first became aware of this technology after the Battle of Singapore when they captured the notes of a British radar technician that mentioned \"yagi antenna\". Japanese intelligence officers did not even recognise that Yagi was a Japanese name in this context. When questioned, the technician said it was an antenna named after a Japanese professor.\n\nA horizontally polarized array can be seen under the leading edge of Grumman TBF Avenger carrier-based US Navy aircraft and the Consolidated PBY Catalina long range patrol seaplane. Vertically polarized arrays can be seen on the cheeks of the P-61 and on the nose cones of many WWII aircraft, notably the Lichtenstein radar-equipped examples of the German Junkers Ju 88R-1 fighter-bomber, and the British Bristol Beaufighter night-fighter and Short Sunderland flying-boat. Indeed, the latter had so many antenna elements arranged on its back – in addition to its formidable turreted defensive armament in the nose and tail, and atop the hull – it was nicknamed the \"fliegendes Stachelschwein\", or \"Flying Porcupine\" by German airmen. The experimental \"Morgenstern\" German AI VHF-band radar antenna of 1943–44 used a \"double-Yagi\" structure from its 90° angled pairs of Yagi antennas formed from six discrete dipole elements, making it possible to fair the array within a conical, rubber-covered plywood radome on an aircraft's nose, with the extreme tips of the \"Morgenstern's\" antenna elements protruding from the radome's surface, with an NJG 4 Ju 88G-6 of the wing's staff flight using it late in the war for its Lichtenstein SN-2 AI radar.\n\nAfter World War 2, the advent of television broadcasting motivated extensive development of the Yagi–Uda antenna as a rooftop television reception antenna in the VHF and UHF bands, and to a lesser extent an FM radio antenna. Until the development of the log-periodic antenna in the 1960s, it was the only type of antenna that could give adequate fringe reception in areas far from the television transmitter. A major drawback was the Yagi's inherently narrow bandwidth. Very complicated Yagi designs were developed to give adequate gain over the broad television bands. TV antennas are still a major application of the Yagi antenna.\n\nThe Yagi–Uda antenna was named an IEEE Milestone in 1995.\n\n\n\n\n"}
{"id": "56778241", "url": "https://en.wikipedia.org/wiki?curid=56778241", "title": "ZPEB", "text": "ZPEB\n\nThe Zhongyuan Petroleum Exploration Bureau (or ZPEB) is a Chinese oilfield services company. It is a subsidiary of Sinopec, one of China's national oil companies.\n\nThe company was operating in 2007 in the volatile, predominantly Somali Ogaden region of Ethiopia in 2007. At the time the Ogaden National Liberation Front waged an insurgency against the Ethiopian government. The company and its employees suffered grievously as collateral damage in the war at 4:30 AM on April 24, 2007 when 200 ONLF militants attacked the company's camp in Abole, Somali Region. A firefight raged for 50 minutes between the attackers and 100 Ethiopian troops guarding the camp. The attack left 9 Chinese and 65 Ethiopians dead and 9 Chinese were taken as hostage.\n\n"}
{"id": "33761664", "url": "https://en.wikipedia.org/wiki?curid=33761664", "title": "Zyvex Marine", "text": "Zyvex Marine\n\nZyvex Marine is a division of Zyvex Technologies, a molecular engineering company. Zyvex Marine develops boats that use Zyvex Technologies' proprietary nanomaterials.\n\nZyvex Marine was formally announced as a division of Zyvex Technologies on November 4, 2011. It is headquartered in Bothell, Washington. Zyvex Marine launched its first production boat on November 4, 2011.\n\nIn 2009, prior to becoming a formal division, Zyvex Marine created the world's first commercialized carbon nanotube enhanced (CNTe) carbon fiber prototype vessel called the 540SE. It was designed to offer a 75% reduction in fuel consumption costs based on lightweight nanomaterials used in its hull design.\n\nIn 2010, it created the first prototype vessel called the Piranha Unmanned Surface Vessel, which is a 54-foot (16.4 meter) boat made out of the same lightweight nanomaterials as the 540SE.\n\nIn 2011, Zyvex shipped its first production craft, a 54-foot lightweight boat.\n\nThe Piranha Unmanned Surface Vessel is a 54-foot (16.4 meter) vessel created out of lightweight nanomaterials. It was announced on February 19, 2010. The first Piranha began construction in February 2010 and was completed and initiating sea trials by October 2010. The Piranha concluded approximately 6 months and 600 nautical miles of sea trials in Washington state and Oregon state on April 4, 2011.\n\n"}
