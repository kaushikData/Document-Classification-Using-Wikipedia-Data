{"id": "47866988", "url": "https://en.wikipedia.org/wiki?curid=47866988", "title": "Airbiquity", "text": "Airbiquity\n\nAirbiquity Inc. is a business-to-business (B2B) software development and engineering company operating in the automotive telematics industry. Airbiquity’s business model is to develop, deploy, and support the ongoing management of connected car programs for automotive industry customers using a software-as-a-service (SaaS) business model, and its Choreo cloud-based connected car service delivery platform.\n\nAirbiquity’s Choreo platform is claimed by the company to integrate the broad array of components needed to build and operate connected car programs such as mobile network connectivity; vehicle entertainment systems or \"head units\", cabin displays and instrumentation; telematics control units (TCU), on-board diagnostic dongles (OBD-II), smart-phone handsets; back-office IT systems; data analytics providers; software and firmware over-the-air (OTA) technology providers; software and firmware catalogs; emergency and concierge call centers; and content and service providers.\n\nThe company was founded in 1997 as Integrated Data Communications Inc. located on Bainbridge Island across the Puget Sound from Seattle. In 2000, the company changed its name to Airbiquity Inc. and later relocated to the Seattle downtown waterfront in 2006.\n\nDuring its early years Airbiquity’s primary product was aqLink, a patented in-band software modem enabling vehicle connectivity and two-way data transfer over cellular voice networks using embedded TCUs or consumer cell phones with Bluetooth connections. The introduction of aqLink was followed by a series of product upgrades and line extensions, including aqServer for transmission, receipt and processing of information transported to data and call center providers over UMTS, CDMA, TDMA or GSM wireless network voice channels.\n\nIn 2001, Airbiquity secured a contract with General Motors to license aqLink technology to support location-based communications for its OnStar service. Other automakers licensed aqLink technology for their connected car programs. According to Airbiquity, aqLink technology has been licensed for use in over 25 million production vehicles globally. The ability to provide voice and data services marked the start of branded connected car programs from automakers seeking to differentiate their vehicles from competitors. These programs have since expanded to include other features and services such as over-the-air (OTA) software and data management, infotainment delivery, remote vehicle management, electric vehicle management, and commercial fleet management.\n\nAirbiquity launched Choreo, a cloud-based connected car service delivery platform, in 2008. The first automaker program to deploy on Choreo was Ford Sync in 2008. Airbiquity provides service delivery for Choreo in over 60 countries, including translations into more than 30 local languages\n\nChoreo is composed of six services for established and newly emerging connected car services. Each product draws upon combinations of Choreo platform service delivery capability supplemented with custom software development and engineering to integrate with specified suppliers, mobile network operators, call centers, content providers, and back-end IT systems.\n\nAirbiquity has received the following telematics industry, technology, and business awards for software development, engineering and integration expertise, and general business success:\n"}
{"id": "7050656", "url": "https://en.wikipedia.org/wiki?curid=7050656", "title": "Aker Drilling", "text": "Aker Drilling\n\nAker Drilling, was a Norwegian drilling rig operation company; based in Stavanger, Norway and majority owned by the Aker Group. It was listed on Oslo Stock Exchange under the ticker - 'AKD'. \n\nIn October 2011, it was amalgamated into global operations of Transocean and renamed to Transocean Norway Drilling AS, after the completion of the US$1.43 billion acquisition of Aker Drilling by Transocean Ltd.\n\nThere was previously in the 1970s a different company called Aker Drilling, also part of the Aker Group, which later became part of Fred. Olsen Energy. \n\nThe history of the 2005 established Aker drilling is as follows;\n\nAker drilling was established in 2005, as part of the Aker Group controlled by the Norwegian billionaire Kjell Inge Røkke. The purpose of the new company was to place contracts for its two new-building semi-submersible drilling rigs. The two Aker H-6e type 6th generation semi-submersibles - \"Aker Barents\" and \"Aker Spitsbergen\", were designed by Aker Solutions and being built at Aker Stord AS shipyard. \nIn December 2005, Aker drilling went public and was listed on the Oslo Stock Exchange. In 2006, with the Aker Drilling’s management team in place, the company set up its head office in Stavanger, Norway. The same year, it secured long term contracts with Statoil ASA and Aker Exploration ASA (later merged with Det Norske Oljeselskap ASA).\n\nIn 2007, it was taken off the exchange to avoid a takeover by billionaire John Fredriksen’s Seadrill, which made a voluntary offer for all outstanding shares in Aker Drilling. Aker ASA, through its wholly owned subsidiary Aker Capital ASA, made a voluntary acquisition of a majority stake in Aker drilling, which subsequently led to the de-listing of the company in March 2008.\n\nIn 2009, the company took ownership of the semi submersibles - Aker Barents and Aker Spitsbergen. Aker Barents subsequently commenced drilling operations on the Norwegian continental shelf for Det Norske Oljeselskap ASA (earlier Aker Exploration ASA) in July 2009. And in 2010, Aker Spitsbergen commenced drilling operations for Statoil ASA.\n\nIn February 2011, Aker drilling was relisted in the Oslo stock exchange under the ticker - 'AKD', three years after being taken off the exchange.\n\nOn 15 August 2010, Transocean made a US$1.43 billion takeover bid for Aker Drilling. Under the transaction, Transocean made a voluntary NOK26.50 ($4.83) per share cash offer for all outstanding shares in the company. The company was delisted after the take over was completed in October 2011, and it was renamed Transocean Norway Drilling AS - a wholly owned subsidiary of Transocean. Aker Drilling used Goldman Sachs group Inc as its financial adviser, while Transocean was advised by Morgan Stanley and Fearnley Fonds AS.\n"}
{"id": "1651717", "url": "https://en.wikipedia.org/wiki?curid=1651717", "title": "Ambient device", "text": "Ambient device\n\n\"Not to be confused with the company named:\" Ambient Devices.\n\nAmbient devices are a type of consumer electronics, characterized by their ability to be perceived at-a-glance, also known as \"glanceable\". Ambient devices use pre-attentive processing to display information and are aimed at minimizing mental effort. Associated fields include ubiquitous computing and calm technology. The concept is closely related to the Internet of Things.\n\n\"The New York Times Magazine\" announced ambient devices as one of its Ideas of the Year in 2002. The award recognized a start-up company, Ambient Devices, whose first product Ambient Orb, was a frosted-glass ball lamp, which maps information to a linear color spectrum and displays the trend in the data. Other products in the genre include the 2008 Chumby, and the 2012 52-LED device MooresCloud (a reference to Moore's Law) from Australia.\n\nResearch on ambient devices began at Xerox Parc, with a paper co-written by Mark Weiser and John Seely Brown, entitled \"Calm Computing\". \n\nThe purpose of ambient devices is to enable immediate and effortless access to information. The original developers of the idea state that an ambient device is designed to provide support to people carrying out everyday activities. Ambient devices decrease the effort needed to process incoming data, thus rendering individuals more productive.\n\nThe key issue lies with taking Internet-based content (e.g. traffic congestion, weather condition, stock market quotes) and mapping it into a single, usually one-dimensional spectrum (e.g. angle, colour). According to Rose, this presents data to an end user seamlessly, with an insignificant amount of cognitive load.\n\nThe concept of ambient devices can be traced back to the early 2000s, when preliminary research was carried at Xerox PARC, according to the company’s official website. The MIT Media Lab website lists the venture as founded by David L. Rose, Ben Resner, Nabeel Hyatt and Pritesh Gandhi as a lab spin-off.\n\nAmbient Orb was introduced by Ambient Devices in 2002. The device was a glowing sphere that displayed data through changes in color. Ambient Orb was customizable in terms of content and its subsequent visual representation. For instance, when the device was set to monitor a stock market index (e.g. NASDAQ), the Orb glowed green/red to represent the upward/downward price movements; alternatively, it turned amber when the index is unchanged. Nabeel Hyatt stated that the device was marketed as an interior design item with additional functionality.\n\nAnother prominent ambient device is Chumby, released in 2008. It served as an at-a-glance widget station. Chumby was able to push relevant customizable data (weather, news, music, photos) to a touchscreen through Wi-Fi. It greatly surpassed the products resembling Ambient Orb, in terms of functionality, and was proclaimed one of the top gadgets of 2008, production ceased in April 2012. Since 1 July 2014 Chumby is available only as a paid subscription service.\n\nMore recent products such as Amazon Alexa can be seen as adopting the spirit of ambient devices, in that they operate in the background, responding to both users and external data sources.\n\n\n"}
{"id": "1190634", "url": "https://en.wikipedia.org/wiki?curid=1190634", "title": "Apocynum cannabinum", "text": "Apocynum cannabinum\n\nApocynum cannabinum (dogbane, amy root, hemp dogbane, prairie dogbane, Indian hemp, rheumatism root, or wild cotton) is a perennial herbaceous plant that grows throughout much of North America - in the southern half of Canada and throughout the United States. It is a poisonous plant: \"Apocynum\" means \"poisonous to dogs\". All parts of the plant are poisonous and can cause cardiac arrest if ingested. However, some lepidoptera feed on this plant, such as two hummingbird moths. The cannabinum in the scientific name and the common names hemp dogbane and Indian hemp refer to its similarity to \"Cannabis\" as a fiber plant (see Hemp), rather than as a source of a psychoactive drug (see Cannabis (drug))\n\nAlthough dogbane is poisonous to livestock, it likely got its name from its resemblance to a European species of the same name.\n\n\"Apocynum cannabinum\" grows in open wooded areas, ditches, and hillsides. It is found in gravelly or sandy soil, mainly near streams in shady or moist places.\n\n\"Apocynum cannabinum\" grows up to 2 meters/6 feet tall. The stems are reddish and contain a milky latex capable of causing skin blisters. The leaves are opposite, simple broad lanceolate, long and broad, entire, and smooth on top with white hairs on the underside. It flowers from July to August, has large sepals, and a five-lobed white corolla. The flowers are hermaphrodite (have both male and female organs) and are pollinated by moths and butterflies.\n\nThe plant serves as a larval host for the snowberry clearwing (\"Hemaris diffinis\") and hummingbird clearwing (\"Hemaris thysbe\") moths. These moths are pollinators that resemble small hummingbirds. The plant can be used for various purposes. The most used parts are the seeds, the root and the bark.\n\nThis species is native to North America. However, in gardens it can be unwanted, growing from spreading roots. When growing among corn, \"Apocynum cannabinum\" can reduce yields by up to 10% and when growing among soybeans, by up to 40%. It can be controlled through mechanical means, although it is difficult to control with herbicides.\n\nA very strong and good quality fiber obtained from the bark is a flax substitute that does not shrink and retains its strength in water. It is used for making clothes, twine, bags, linen, paper, etc. The plant yields a latex which is a possible source of rubber. \n\"Apocynum cannabinum\" was used as a source of fiber by Native Americans, to make hunting nets, fishing lines, clothing, and twine. It is called \"qéemu\" in Nez Perce and in Sahaptin. The Concow tribe call the plant pö (Konkow language).\n\nThe plant can be harvested for fiber, which can be used to make strong string and cordage for use in bows, fire-bows, nets and tie down straps. When harvested for fiber, dogbane is often left standing as late as mid-winter so that rain and snow will perform retting.\n\nThe seeds have an edible use as a meal (raw or cooked) when ground into a powder.\n\nAfter the latex has been squeezed from the plant, it is allowed to stand overnight to harden into a white gum which can be used (sometimes mixed with clean clay) as chewing gum.\n\n\"Apocynum cannabinum\" is a phytoremediation plant, a hyperaccumulator used to sequester lead in its biomass. \n\nIt is also used in herbal medicine to treat fever, and dysentery. Although the toxins from the plant can cause nausea and catharsis, it has also been used for slowing the pulse, and it is also a sedative and mild hypnotic. It is an unpleasantly bitter stimulant irritant herb that acts on the heart, respiratory and urinary systems, and also on the uterus. \"Apocynum cannabinum\" was much employed by various Native American tribes who used it to treat a wide variety of complaints including rheumatism, coughs, pox, whooping cough, asthma, internal parasites, diarrhoea and also to increase milk flow in lactating mothers. The root has been used as a tonic, cardiotonic, diaphoretic, diuretic, emetic (induces vomitting) and expectorant. It is harvested in the autumn and dried for later use. The fresh root is the most active part medicinally. A weak tea made from the dried root has been used for cardiac diseases and also as a vermifuge (an agent that expels parasitic worms). The milky sap is a (presumably topically applied) folk remedy for venereal warts. The plant is still used in modern herbalism, though it should be used with great caution and only under the supervision of a qualified practitioner if taken internally.\n\n\n\n"}
{"id": "22935904", "url": "https://en.wikipedia.org/wiki?curid=22935904", "title": "Arthur Dorman", "text": "Arthur Dorman\n\nSir Arthur John Dorman, 1st Baronet KBE (8 August 1848 – 12 February 1931) was an important British industrialist.\n\nHe was born at Ashford in Kent the son of Charles Dorman and Emma Page and educated at Christ's Hospital, then situated in Newgate, London.\n\nHe was sent, at the age of 22, by his family to work at a Stockton-on-Tees iron works where a relative was a partner. Dorman started as a puddler and rapidly progressed in his career. In 1875, he went into partnership with Albert de Lande Long to acquire the \"West Marsh\" Ironworks in Middlesbrough. During the 1880s they exploited the new steel making technologies being introduced at that time including use of Open hearth furnaces. Together they built a large industrial concern, Dorman Long, which by 1914 employed 20,000 people and during the World War I was a major supplier of shells.\n\nStood as the Conservative candidate for Cleveland.\n\nArthur Dorman was appointed a Knight Commander of the Order of the British Empire (KBE) in 1918 and created a baronet of Nunthorpe in the County of York on 21 July 1923.\n\nHe married Clara Lockwood in 1873 and together they had four sons and three daughters. His youngest son George Lockwood Dorman was killed in the Second Boer War, and is commemorated in the Dorman Museum.\n\nSir Arthur Dorman died in 1931 at Grey Towers, his home in Nunthorpe near Middlesbrough.\nHis title was inherited by his eldest son Bedford Lockwood Dorman.\n\n"}
{"id": "57196745", "url": "https://en.wikipedia.org/wiki?curid=57196745", "title": "Burke–Schumann limit", "text": "Burke–Schumann limit\n\nIn combustion, Burke–Schumann limit (or Large Damköhler number limit) describes the limit of infinitely fast chemistry (or in other words, infinite Damköhler number), named after S.P. Burke and T.E.W. Schumann, due to their pioneering work on Burke-Schumann flame. One important conclusion of infinitely fast chemistry is the non-co-existence of fuel and oxidizer simultaneously except in a thin reaction sheet. The inner structure of the reaction sheet is described by Liñán's equation.\n\nIn a typical non-premixed combustion (fuel and oxidizer are separated initially), mixing of fuel and oxidizer takes place based on the mechanical time scale formula_1dictated by the convection/diffusion (the relative importance between convection and diffusion depends on the Reynolds number) terms. Similarly, chemical reaction takes certain amount of time formula_2 to consume reactants. For one-step irreversible chemistry with Arrhenius rate, this chemical time is given by\n\nwhere is the pre-exponential factor, is the activation energy, is the universal gas constant and is the temperature. Similarly, one can define formula_1 appropriate for particular flow configuration. The Damköhler number is then\n\nDue to the large activation energy, the Damköhler number at unburnt gas temperature formula_6 is formula_7, because formula_8. On the other hand, the shortest chemical time is found at the flame (with burnt gas temperature formula_9), leading to formula_10. Regardless of Reynolds number, the limit formula_11 guarantees that chemical reaction dominates over the other terms. A typical conservation equation for the scalar formula_12 (species concentration or energy) takes the following form,\n\nwhere formula_14 is the convective-diffusive operator and formula_15 are the mass fractions of fuel and oxidizer, respectively. Taking the limit formula_16 in the above equation, we find that\n\ni.e., fuel and oxidizer cannot coexist, since far away from the reaction sheet, only one of the reactant is available (non premixed). On the fuel side of the reaction sheet, formula_18 and on the oxidizer side, formula_19. Fuel and oxygen can coexist (with very small concentrations) only in a thin reaction sheet, where formula_20 (diffuisve transport will be comparable to reaction in this zone). In this thin reaction sheet, both fuel and oxygen are consumed and nothing leaks to the other side of the sheet. Due to the instantaneous consumption of fuel and oxidizer, the normal gradients of scalars exhibit discontinuities at the reaction sheet.\n\n"}
{"id": "52789833", "url": "https://en.wikipedia.org/wiki?curid=52789833", "title": "CO-STAR", "text": "CO-STAR\n\nCO-STAR is an iterative innovation management methodology originating from silicon valley. The acronym stands for \"customer, opportunity, solution, team, advantages\" and \"results\". It was introduced in a 2012 book by Laszlo Gyorffy and Lisa Friedman.\n\nThe methodology is being used by several companies, for example by INNOArchitects, IdeaScale or the Swiss Post.\n"}
{"id": "147056", "url": "https://en.wikipedia.org/wiki?curid=147056", "title": "CQD", "text": "CQD\n\nCQD (transmitted in Morse code as ) is one of the first distress signals adopted for radio use. It was announced on 7 January 1904, by \"Circular 57\" of the Marconi International Marine Communication Company, and became effective beginning 1 February 1904 for Marconi installations.\n\nLand telegraphs had traditionally used \"CQ\" (\", from the French word \") to identify alert or precautionary messages of interest to all stations along a telegraph line, and CQ had also been adopted as a \"general call\" for maritime radio use. However, in landline usage there was no general emergency signal, so the Marconi company added a \"D\" (\"distress\") to CQ in order to create its distress call. Sending \"D\" was already used internationally to indicate an urgent message. Thus, \"CQD\" is understood by wireless operators to mean, \"All stations: distress.\" Contrary to popular belief, CQD does not stand for \"Come Quick, Danger\", \"Come Quickly: Distress\", \"Come Quick – Drowning!\", or \"C Q Danger\" (\"Seek You, Danger\"); these are backronyms.\n\nAlthough used worldwide by Marconi operators, CQD was never adopted as an international standard, since it could be mistaken for a general call \"CQ\" if the reception were poor. At the second International Radiotelegraphic Convention, held in Berlin in 1906, Germany's \"\" distress signal of three-dots/three-dashes/three-dots () was adopted as the international Morse code distress signal. (This distress signal soon became known as \"SOS\" because if gaps are inserted it can be thought of as the Morse codes for those letters – by contrast CQD is transmitted as three distinct letters with a short gap between each. Germany had first adopted this distress signal in regulations effective 1 April 1905.)\n\nBetween 1899 and 1908, nine documented rescues were made by the use of wireless. The earliest of these was a distress call from the \"East Goodwin\" lightship. However, for the earliest of these, there was no standardized distress signal. The first US ship to send a wireless distress call in 1905 simply sent HELP (in both International Morse and American Morse). By February 1904, the Marconi Wireless Company required all its operators to use CQD for a ship in distress or for requiring URGENT assistance. In the early morning of 23 January 1909, whilst sailing into New York from Liverpool, RMS \"Republic\" collided with the Italian liner SS \"Florida\" in fog off the island of Nantucket, Massachusetts, United States. Radio Operator Jack Binns sent the CQD distress signal by wireless transmission.\n\nOn April 15, 1912, RMS \"Titanic\" radio operator Jack Phillips initially sent \"CQD\", which was still commonly used by British ships. Harold Bride, the junior radio operator, suggested using \"SOS\", saying half-jokingly that it might be his last chance to use the new code. Phillips thereafter began to alternate between the two. Though Bride survived the sinking, Phillips did not.\n\n\n\n"}
{"id": "11302552", "url": "https://en.wikipedia.org/wiki?curid=11302552", "title": "Complex gain", "text": "Complex gain\n\nIn electronics, complex gain is the effect that circuitry has on the amplitude and phase of a sine wave signal. The term \"complex\" is used because mathematically this effect can be expressed as a complex number.\n\nConsidering the general LTI system\n\nwhere formula_2 is the input and formula_3 are given polynomial operators, while assuming that formula_4.\nIn case that formula_5, a particular solution to given equation is\n\nLet us consider the following concepts used in physics and signal processing mainly.\n\ninput units to output units.\n\nSuppose a circuit has an input voltage described by the equation\n\nwhere ω equals 2π×100Hz, i.e., the input signal is a 100Hz sine wave with an amplitude of 1 Volt.\n\nIf the circuit is such that for this frequency it doubles the signal's amplitude and causes a 90 degrees forward phase shift, then its output signal can be described by\n\nIn complex notation, these signals can be described as, for this frequency, \"j\"·1V and 2V, respectively.\n\nThe complex gain \"G\" of this circuit is then computed by dividing output by input:\n\nThis (unitless) complex number incorporates both the magnitude of the change in amplitude (as the absolute value) and the phase change (as the argument).\n"}
{"id": "5213", "url": "https://en.wikipedia.org/wiki?curid=5213", "title": "Computing", "text": "Computing\n\nComputing is any activity that uses computers. It includes developing hardware and software, and using computers to manage and process information, communicate and entertain. Computing is a critically important, integral component of modern industrial technology. Major computing disciplines include computer engineering, software engineering, computer science, information systems, and information technology.\n\nThe ACM \"Computing Curricula 2005\" defined \"computing\" as follows:\n\n\"In a general way, we can define computing to mean any goal-oriented activity requiring, benefiting from, or creating computers. Thus, computing includes designing and building hardware and software systems for a wide range of purposes; processing, structuring, and managing various kinds of information; doing scientific studies using computers; making computer systems behave intelligently; creating and using communications and entertainment media; finding and gathering information relevant to any particular purpose, and so on. The list is virtually endless, and the possibilities are vast.\"\n\nand it defines five sub-disciplines of the \"computing\" field: computer science, computer engineering, information systems, information technology, and software engineering.\n\nHowever, \"Computing Curricula 2005\" also recognizes that the meaning of \"computing\" depends on the context:\n\n\"Computing also has other meanings that are more specific, based on the context in which the term is used. For example, an information systems specialist will view computing somewhat differently from a software engineer. Regardless of the context, doing computing well can be complicated and difficult. Because society needs people to do computing well, we must think of computing not only as a profession but also as a discipline.\"\n\nThe term \"computing\" has sometimes been narrowly defined, as in a 1989 ACM report on \"Computing as a Discipline\":\n\n\"The discipline of computing is the systematic study of algorithmic\nprocesses that describe and transform information: their theory, analysis, design, efficiency, implementation, and application. The fundamental question underlying all computing is \"What can be (efficiently) automated?\"\n\nThe term \"computing\" is also synonymous with counting and calculating. In earlier times, it was used in reference to the action performed by mechanical computing machines, and before that, to human computers .\n\nThe history of computing is longer than the history of computing hardware and modern computing technology and includes the history of methods intended for pen and paper or for chalk and slate, with or without the aid of tables.\n\nComputing is intimately tied to the representation of numbers. But long before abstractions like \"the number\" arose, there were mathematical concepts to serve the purposes of civilization. These concepts include one-to-one correspondence (the basis of counting), comparison to a standard (used for measurement), and the \"3-4-5\" right triangle (a device for assuring a \"right angle\").\n\nThe earliest known tool for use in computation was the abacus, and it was thought to have been invented in Babylon circa 2400 BC. Its original style of usage was by lines drawn in sand with pebbles. Abaci, of a more modern design, are still used as calculation tools today. This was the first known calculation aid - preceding Greek methods by 2,000 years.\n\nThe first recorded idea of using digital electronics for computing was the 1931 paper \"The Use of Thyratrons for High Speed Automatic Counting of Physical Phenomena\" by C. E. Wynn-Williams. Claude Shannon's 1938 paper \"A Symbolic Analysis of Relay and Switching Circuits\" then introduced the idea of using electronics for Boolean algebraic operations.\n\nA computer is a machine that manipulates data according to a set of instructions called a computer program. The program has an executable form that the computer can use directly to execute the instructions. The same program in its human-readable source code form, enables a programmer to study and develop a sequence of steps known as an algorithm. Because the instructions can be carried out in different types of computers, a single set of source instructions converts to machine instructions according to the central processing unit type.\n\nThe execution process carries out the instructions in a computer program. Instructions express the computations performed by the computer. They trigger sequences of simple actions on the executing machine. Those actions produce effects according to the semantics of the instructions.\n\nComputer software or just \"software\", is a collection of computer programs and related data that provides the instructions for telling a computer what to do and how to do it. Software refers to one or more computer programs and data held in the storage of the computer for some purposes. In other words, software is a set of \"programs, procedures, algorithms\" and its \"documentation\" concerned with the operation of a data processing system. Program software performs the function of the program it implements, either by directly providing instructions to the computer hardware or by serving as input to another piece of software. The term was coined to contrast with the old term hardware (meaning physical devices). In contrast to hardware, software is intangible. Software is also sometimes used in a more narrow sense, meaning application software only.\n\nApplication software, also known as an \"application\" or an \"app\", is a computer software designed to help the user to perform specific tasks. Examples include enterprise software, accounting software, office suites, graphics software and media players. Many application programs deal principally with documents. Apps may be bundled with the computer and its system software, or may be published separately. Some users are satisfied with the bundled apps and need never install one.\n\nApplication software is contrasted with system software and middleware, which manage and integrate a computer's capabilities, but typically do not directly apply them in the performance of tasks that benefit the user. The system software serves the application, which in turn serves the user.\n\nApplication software applies the power of a particular computing platform or system software to a particular purpose. Some apps such as Microsoft Office are available in versions for several different platforms; others have narrower requirements and are thus called, for example, a Geography application for Windows or an Android application for education or Linux gaming. Sometimes a new and popular application arises that only runs on one platform, increasing the desirability of that platform. This is called a killer application.\n\nSystem software, or systems software, is computer software designed to operate and control the computer hardware and to provide a platform for running application software. System software includes operating systems, utility software, device drivers, window systems, and firmware. Frequently development tools such as compilers, linkers, and debuggers are classified as system software.\n\nA computer network, often simply referred to as a network, is a collection of hardware components and computers interconnected by communication channels that allow sharing of resources and information. Where at least one process in one device is able to send/receive data to/from at least one process residing in a remote device, then the two devices are said to be in a network.\n\nNetworks may be classified according to a wide variety of characteristics such as the medium used to transport the data, communications protocol used, scale, topology, and organizational scope.\n\nCommunications protocols define the rules and data formats for exchanging information in a computer network, and provide the basis for network programming. Well-known communications protocols are Ethernet, a hardware and Link Layer standard that is ubiquitous in local area networks, and the Internet Protocol Suite, which defines a set of protocols for internetworking, i.e. for data communication between multiple networks, as well as host-to-host data transfer, and application-specific data transmission formats.\n\nComputer networking is sometimes considered a sub-discipline of electrical engineering, telecommunications, computer science, information technology or computer engineering, since it relies upon the theoretical and practical application of these disciplines.\n\nThe Internet is a global system of interconnected computer networks that use the standard Internet protocol suite (TCP/IP) to serve billions of users that consists of millions of private, public, academic, business, and government networks, of local to global scope, that are linked by a broad array of electronic, wireless and optical networking technologies. The Internet carries an extensive range of information resources and services, such as the inter-linked hypertext documents of the World Wide Web (WWW) and the infrastructure to support email.\n\nComputer programming in general is the process of writing, testing, debugging, and maintaining the source code and documentation of computer programs. This source code is written in a programming language, which is an artificial language often more restrictive or demanding than natural languages, but easily translated by the computer. The purpose of programming is to invoke the desired behavior (customization) from the machine. The process of writing high quality source code requires knowledge of both the application's domain \"and\" the computer science domain. The highest-quality software is thus developed by a team of various domain experts, each person a specialist in some area of development. But the term \"programmer\" may apply to a range of program quality, from hacker to open source contributor to professional. And a single programmer could do most or all of the computer programming needed to generate the proof of concept to launch a new \"killer\" application.\n\nA programmer, computer programmer, or coder is a person who writes computer software. The term \"computer programmer\" can refer to a specialist in one area of computer programming or to a generalist who writes code for many kinds of software. One who practices or professes a formal approach to programming may also be known as a programmer analyst. A programmer's primary computer language (C, C++, Java, Lisp, Python, etc.) is often prefixed to the above titles, and those who work in a web environment often prefix their titles with \"web\". The term \"programmer\" can be used to refer to a software developer, software engineer, computer scientist, or software analyst. However, members of these professions typically possess other software engineering skills, beyond programming.\n\nThe computer industry is made up of all of the businesses involved in developing computer software, designing computer hardware and computer networking infrastructures, the manufacture of computer components and the provision of information technology services including system administration and maintenance.\n\nThe software industry includes businesses engaged in development, maintenance and publication of software. The industry also includes software services, such as training, documentation, and consulting.\n\nComputer engineering is a discipline that integrates several fields of electrical engineering and computer science required to develop computer hardware and software. Computer engineers usually have training in electronic engineering (or electrical engineering), software design, and hardware-software integration instead of only software engineering or electronic engineering. Computer engineers are involved in many hardware and software aspects of computing, from the design of individual microprocessors, personal computers, and supercomputers, to circuit design. This field of engineering not only focuses on how computer systems themselves work, but also how they integrate into the larger picture.\n\nSoftware engineering (SE) is the application of a systematic, disciplined, quantifiable approach to the design, development, operation, and maintenance of software, and the study of these approaches; that is, the application of engineering to software. In layman's terms, it is the act of using insights to conceive, model and scale a solution to a problem. The first reference to the term is the 1968 NATO Software Engineering Conference and was meant to provoke thought regarding the perceived \"software crisis\" at the time. \"Software development\", a much used and more generic term, does not necessarily subsume the engineering paradigm. The generally accepted concepts of Software Engineering as an engineering discipline have been specified in the Guide to the Software Engineering Body of Knowledge (SWEBOK). The SWEBOK has become an internationally accepted standard ISO/IEC TR 19759:2005.\n\nComputer science or computing science (abbreviated CS or Comp Sci) is the scientific and practical approach to computation and its applications. A computer scientist specializes in the theory of computation and the design of computational systems.\n\nIts subfields can be divided into practical techniques for its implementation and application in computer systems and purely theoretical areas. Some, such as computational complexity theory, which studies fundamental properties of computational problems, are highly abstract, while others, such as computer graphics, emphasize real-world applications. Still others focus on the challenges in implementing computations. For example, programming language theory studies approaches to description of computations, while the study of computer programming itself investigates various aspects of the use of programming languages and complex systems, and human–computer interaction focuses on the challenges in making computers and computations useful, usable, and universally accessible to humans.\n\n\"Information systems (IS)\" is the study of complementary networks of hardware and software (see information technology) that people and organizations use to collect, filter, process, create, and distribute data. The ACM's \"Computing Careers\" website says \n\n\"A majority of IS [degree] programs are located in business schools; however, they may have different names such as management information systems, computer information systems, or business information systems. All IS degrees combine business and computing topics, but the emphasis between technical and organizational issues varies among programs. For example, programs differ substantially in the amount of programming required.\"\nThe study bridges business and computer science using the theoretical foundations of information and computation to study various business models and related algorithmic processes within a computer science discipline.\n\nThis field studies computers and algorithmic processes, including their principles, their software and hardware designs, their applications, and their impact on society while IS emphasizes functionality over design.\n\nInformation technology (IT) is the application of computers and telecommunications equipment to store, retrieve, transmit and manipulate data, often in the context of a business or other enterprise. The term is commonly used as a synonym for computers and computer networks, but it also encompasses other information distribution technologies such as television and telephones. Several industries are associated with information technology, such as computer hardware, software, electronics, semiconductors, internet, telecom equipment, e-commerce and computer services.\n\nA system administrator, IT systems administrator, systems administrator, or sysadmin is a person employed to maintain and operate a computer system or network. The duties of a system administrator are wide-ranging, and may vary substantially from one organization to another. Sysadmins are usually charged with installing, supporting and maintaining servers or other computer systems, and planning for and responding to service outages and other problems. Other duties may include scripting or light programming, project management for systems-related projects, supervising or training computer operators, and being the consultant for computer problems beyond the knowledge of technical support staff.\n\nDNA-based computing and quantum computing are areas of active research in both hardware and software (such as the development of quantum algorithms). Potential infrastructure for future technologies includes DNA origami on photolithography and quantum antennae for transferring information between ion traps. By 2011, researchers had entangled 14 qubits. Fast digital circuits (including those based on Josephson junctions and rapid single flux quantum technology) are becoming more nearly realizable with the discovery of nanoscale superconductors.\n\nFiber-optic and photonic (optical) devices, which already have been used to transport data over long distances, have started being used by data centers, side by side with CPU and semiconductor memory components. This allows the separation of RAM from CPU by optical interconnects. IBM has created an integrated circuit with both electronic and optical information processing in one chip. This is denoted \"CMOS-integrated nanophotonics\" or (CINP). One benefit of optical interconnects is that motherboards which formerly required a certain kind of system on a chip (SoC) can now move formerly dedicated memory and network controllers off the motherboards, spreading the controllers out onto the rack. This allows standardization of backplane interconnects and motherboards for multiple types of SoCs, which allows more timely upgrades of CPUs.\n\n\n"}
{"id": "7035221", "url": "https://en.wikipedia.org/wiki?curid=7035221", "title": "Converters (industry)", "text": "Converters (industry)\n\nConverting companies are companies that specialize in combining raw materials such as polyesters, adhesives, silicone, adhesive tapes, foams, plastics, felts, rubbers, liners and metals, as well as other materials, to create new products.\n\nMaterials such as paper, plastic film, foil and cloth often are produced in long, continuous sheets that are rolled up for more convenient handling and transportation. These rolls of material vary significantly in size and weight — ranging from wide and weighing as much as several tons. The converting industry takes these continuous rolls of thin, flat materials — known as webs — threads them through processing machines (such as printing presses, laminating, coating and slitting machines) and converts or changes the web of material into an intermediate form or final product. For example, a converter’s equipment might take a web of plastic film, cut it into lengths, and fuse their edges, thus converting it into plastic bags. This activity is known as web processing.\n\nTypical converting processes are coating, laminating and printing. Coating technologies can include hot melt coating, gravure coating, curtain coating and slot-die coating. The most common printing techniques are flexo printing and rotogravure (gravure) printing. Both print processes are suited to high speed roll-to-roll processing.\n\nMany converting companies will process large diameter, wide rolls of material as this increases the converting efficiency by minimising changes. On completion of the converting process the rolls may be cut into smaller rolls on a slitting machine. These rolls are then a convenient size for handling on packaging and other machines. Alternatively, the rolls may be sheeted-cut into sheets — as happens in newspaper and book printing. Further processes such as collation may occur after sheeting.\n\nWeb alignment is an important part of a converting operation as a moving web of material has a tendency to track off course and wander out of alignment during the converting processes. To avoid these problems, engineers have developed a variety of automatic web-guiding systems that assure production accuracy and reduce waste. Web-guiding systems typically are positioned just before a critical stage on a converting machine (for example, just before a print station on a printing press).\n\nEach type of web guiding system uses a sensor to monitor the web position for lateral tracking, and each has an actuator to shift the running web mechanically back on course whenever the sensor detects movement away from the set path. Actuators may be pneumatic or hydraulic cylinders, or some kind of electromechanical device. Because the web may be fragile — particularly at its edge — non-contact sensors are used. These sensors may be pneumatic, photoelectric, ultrasonic, or infrared. The system’s controls must put the output signals from the sensors in to a form that can drive the actuator. Many controls today are electronic, typically using an amplifier to convert signals from the sensor, then commanding a special servo motor incorporating a lead or ball screw for guiding actuation. The latest web guiding systems have touch screen controls to simplify the setup procedure. Some web guiding systems have been designed specifically for the converting industry.\n\nMany converters specialize in \n\nSome converting companies now incorporate electronics in their finished products. For example, converters producing RFID stock labels must incorporate RFID chips and antenna inlays. The electronic components make up the RFID tag. The tag stores the information about the items that have been tagged. These converters therefore sometimes incorporate volume electronics manufacturing practices including controlling static electricity, electronic manufacturing test and similar processes. Solving some of the issues of inclusion of materials sensitive to external influences has led to more tech companies embracing roll-based manufacturing processes, with particular success in the lithium ion and solar cell manufacturing sectors.\n\nThe process of processing pre-cut cartons or \"blanks\" and folding them into the appropriate shape to become finished packaging containers is known as tray forming or carton erecting. These machines can create, for example, nacho trays, chinese noodle soup boxes, pizza boxes, french fry trays, hamburger clamshells, etc.\n\n"}
{"id": "2984191", "url": "https://en.wikipedia.org/wiki?curid=2984191", "title": "DFI", "text": "DFI\n\nDFI is an industrial computer company with headquarters in Taipei, Taiwan. It designs, develops, manufactures, and sells industrial motherboard, industrial PCs, System-on-Module, industrial displays, and ODM/OEM services. \n\nDFI was founded by Y.C Lu on July 14, 1981, developing and selling electronics components and add-on cards in the beginning. However, DFI switched to the production of motherboards after searching for potential markets and deciding to focus on the strengths of DFI. Targeting the new growing market in motherboard products, DFI announced a Patent License Agreement with Intel Corporation in 1990 and has been developing and manufacturing motherboard products since 1992. DFI was awarded Top 10 motherboard Manufacturer in CNR Magazine from the year 1997 to 1999. Starting from 1998, DFI began to follow the strategies of Intel by releasing Intel 440BX series motherboards, 810 motherboards, and 810e motherboards to worldwide markets. For its advances in manufacturing motherboards, DFI was awarded the Intel Global Demo Board manufacturer award in 1998 and 1999.\n\nCatering to the growing market of high-end motherboards, DFI developed advanced overclocking motherboards, the LanParty series, which has proven to be a valuable segment for small powerful computers that meet the requirements of end users in the 2000s. DFI introduced the junior lineup (“JR”) with two products, p45 and 790gx, in the beginning, which has since been extended with Nvidia and X58 chipsets. There are other LanParty series like LT, DK(Dark), and Lanparty UT.\n\nDFI launched its initial public offering (IPO) on January 15, 2000. As well as developing LanParty consumer products, DFI started to develop ACP (Application Control Platform) businesses, mainly targeted at vertical applications in slot machines, POS, security system, and so on since 2002. In 2005, DFI gained over 50% revenues from this new business. With this successful transformation, industrial PCs became the primary business of DFI. As of 2003, DFI’s overclocking gamer motherboard, LANPARTY NFII ULTRA, was awarded the Chief Editor Choice Award in \"PC Magazine\" and the Best Creativity Award in \"Tom's Hardware\". \n\nSince DFI planned to focus on developing embedded system products, not only did they stop developing consumer products, but also started establishing embedded system developments and designs in 2011 to expand their industrial computer business. Which later became the core value of DFI in the coming years. After three years of developing industrial computer products, DFI’s EC200-BT fanless embedded system and EC541-HD Modular-designed system was awarded the Computex d&i Award; EC541-HD Modular-designed system was awarded the Red Star Design Award; EC200-BT fanless embedded system was awarded the Golden Pin Design Award. As of 2015, DFI was recognized as a certified partner with Microsoft Azure IoT Platform, making it easier to provide software and hardware integration services for embedded systems. In order to provide more flexible embedded products and solutions to meet different areas of applications, DFI has joined Qisda/BenQ Group, who was acclaimed as a 2018 Top 100 Global Technology Leader by Thomson Reuters, at the end of 2017.\n\nIn 1981, Y.C Lu founded DFI Electronics Components Inc. in Taipei, Taiwan; mainly supplying and exporting electronics components with $1 million in capital. During the first year, DFI earned a revenue of $30 million. In 1984, DFI established facility in Taipei and began manufacturing and selling computers and peripherals. When the capital increased up to $10 million, the Sales (Revenue) Growth Rate of DFI also increased to 300% and DFI successfully expanded its operations to the American regions as well as earning nearly $1 billion in revenues. In 1987, with the capital of $30 million, DFI started to establish facility in Hsi-Chih City, Taiwan. At the same time, DFI planned to stretch its product line into  the European markets, starting with Germany and England. As of 1988, the facility relocated to Hsi-Chih City, which was the major facility of DFI. With the expansion of production line and the addition of Automatic Test Equipment (ATE), DFI not only upgraded the quality of products, but also released a world-leading handheld scanner with plans to lead in setting a standard of global specification. As of 1989, DFI added Computer Aided Design System (CAD) to its facility to manufacture more products like computer mouse, handheld scanner, personal computer, and add-on card, etc. In 1990, DFI announced its Patent License Agreement with Intel Corporation and became the first company with an assembly production line in America to enable technical support service in cooperation with Intel. DFI’s capital increased to $196 million and expanded its facility to 1,900 square feet in 1991. \n\nAs of 1992, DFI introduced ICT and SMT devices into its facility to increase the manufacturing quality and efficiency. In 1993, DFI continually expanded the facility, which was located in Hsi-Chih City and was 2,300 square feet. DFI’s business office and Research and Development Department moved to the facility and introduced Green PC with energy-efficiency design into the facility. As of 1994, DFI researched and developed CD-ROM, officially entered into multimedia system market. The revenue of the notebook increased to over $100 million and the overall revenue of 1994 increased by 25%, over $2 billion. As of 1996, DFI transformed the CD-ROM facility into an assembly system facility, designing and manufacturing the world’s first 75MHZ system bus motherboard, which supported the CYRIX PR 200+CPU. In the meantime, DFI began establishing the third SMT assembly and adopted Siemens SIPLACE80S-15 high speed CNC machine to increase the production of motherboards to 40,000 pcs per month, as well as increasing the self-production to 120, 000 per month. After successfully manufacturing 586 motherboards that supported dual CPU, DFI was dominant in the motherboard market and targeted developing countries, accommodating to Philips Asian marketing system. As of 1997, DFI expanded the facility in Hsi-Chih City for the third time, totaling the area to 2, 800 square feet. DFI also expanded 2 surface mount technology (SMT) high speed CNC machines to upgrade the production of motherboards to 180, 000 pcs per month. Devoted to developing Philips and Lemel assembly OEM business, DFI manufactured 10, 000 systems every month. At the same time, DFI established a third OEM assembly facility in Dongguan city, China and built a European branch office in Bremen, Germany in order to advance the quality of services in European regions. Being engaged in the server market, DFI got started in designing and developing motherboards that support SCSI onboard and Dual Pentium CPU in 1997. From the year of 1997 to 1999, DFI was awarded the Top 10 Motherboard Manufacturer in CNR (Computer Reseller New) Magazine, which had already gained attention by the worldwide market due to DFI’s motherboards’ design and development. In April, 1998, DFI was preparing to apply for becoming a listed company at Taipei Exchange（TPEx）and TWSE. In the same year, DFI released Intel 440BX series motherboard, which was in line with Intel. The 810 motherboard of DFI was awarded the Demo Board amongst Intel Asia-Pacific region. In February, 1999, P5BV3＋motherboards was awarded the high performance Socket7 motherboard in Computer World Magazine in China. In early May of the same year, DFI launched 810 motherboard to the market, following the release of Intel and had already gone into mass production worldwide. The 810e motherboard was re-awarded Intel Global Demo Board and was launched to the market in September, 1999. DFI went public and launched its initial public offering (IPO) on 15, January, 2000. During the same year, DFI founded Diamond Flower H.T. Group (BVI) Inc. \n\nIn April 2001, DFI’s facilities added the seventh SMT assembly line, increasing productivity to 30,000 pieces per month. As of 2002, DFI added the eighth SMT assembly line into factory. In the same year, DFI established worldwide office located in Tokyo, Japan, developing ACP (applied computing platform) businesses for vertical applications and starting to focus on high profit motherboards. In the same year, the local office in Europe relocated to Rotterdam-Hoogvliet in the Netherlands, setting a service center in Eastern Europe, Poland. In 2003, DFI’s renowned gamer overclocking motherboard, LANPARTY NFII ULTRA, was awarded LANPARTY.com Highly Commended Prize, PC Professionell Magazine Extreme Award, Chief Editor Choice Award in PC Magazine and awarded the Best Creativity Award in Tom’s Hardware Guild. In 2004, DFI launched a product line based on Intel 940 Series Chipsets (code name: Calistoga), covering different form factors from COM Express Basic, G5C900-B, Mini-ITX motherboard, CT132-B, to ST100-G5C embedded system. As of 2005, DFI’s capital increased to NTD 1.097 billion, profiting in ACP (Applied Computing Platform) business and gained over 50% revue from this new business. Through this increasingly developed new business, industrial computer has  become the major business of DFI. In 2005, DFI launched a product line based on Intel 960 Series Chipsets (code name: Broadwater,) including different form factors such as microATX motherboard, G7B336-P, ATX motherboard, G7B630-B/N. DFI also launched the panel PC, FS200-BMX5, which was based on ARM Cortex-A8 Freescale i.MX53 processors. \n\nAs of 2006, GE became the vital investor of DFI, benefiting from a large amount of DFI’s business as well as acquiring 100% equity of DFI-Japan. With the acquisition cost of NTD 24.55 million, it allowed DFI to completely devote itself to in-depth industrial computer market in Japan. In the following three years, the consolidated revenue growth rate in ACP (Applied Computing Platform) business increased over 51%, leading DFI’s business to a new milestone. DFI then launched a product line based on \n\nIntel 960 Series Chipsets (code name: Crestline), including different form factors consisting of SR100-L20C Mini-ITX motherboard and SR330-L microATX motherboard. In the same year, DFI also launched a product line based on Intel 945P Chipsets (code name: Lakeport), covering different form factors like G7L331-B microATX motherboard and LT600-D ATX motherboard. As of 2007, DFI’s capital increased to NTD1.14 billion as well as a 65.77% equity of DFI-ITOX with acquisition cost of NTD 234 million. To guarantee exceptional quality and reliability of products under rigorous quality standards, DFI’s products were approved by QC080000, WASO14001, and Green Partner certifications in 2007. DFI launched a product line based on Intel G41 Chipsets (code name: Eagle Lake), inclusive of EL109-N Mini-ITX motherboard , EL339-B microATX motherboard, and EL620-C ATX motherboard, as well as HNVR320-EL embedded system. In 2007, DFI also released a product line based on Intel Q35 Chipsets (code name: Bearlake), ranging from BL100-NE/PE Mini-ITX motherboard,  to BL330-B microATX motherboard, to BL631-D ATX motherboard, As of 2008, DFI’s capital increased to NTD 1.19 billion, acquiring 100% equity of YAN TONG TECHNOLOGYLTD with acquisition cost of NTD 187.26 million, as well as increasing the capital to DFI-Japan to JPY 280 million. In 2008, DFI released a product line based on Intel GM45 Chipsets (code name: Cantiga), ranging from CA900-B COM Express Basic, to small form factor CA230-BF Mini-DTX board,  to CA101-D Mini-ITX motherboard, to CA331-P microATX motherboard. Furthermore, DFI launched a product series based on Intel Atom Processor Z500 series (code name: Silverthorne), offering from ML905-B11C/B16C COM Express , to small form factor ML936-B11C/B16C board, to CS910-ML embedded system. In the same year, DFI also kicked off a full range of product series which were based on Intel 945GSE Chipsets (code name: Navy Pier), covering from NP102-N16C Mini-ITX motherboard , to NP905-B16C COM Express Compact , to NP951-B16C small form factor 3.5\" SBC, to ES122-NP embedded system. As of 2009, DFI’s capital increased to NTD 1.21 billion. And DFI launched a lineup including PT330-DRM microATX motherboard,  PT631-IPM ATX motherboard, and HNVR320-PT embedded system based on Intel Core™/Intel Pentium Processors (code name: Piketon). In 2010, DFI’s capital increased to NTD 1.202 billion. DFI also launched a product line including CP100-NRM Mini-ITX motherboard , CP330-NRM microATX motherboard , CP908-B COM Express Compact, and ST101-CP embedded system based on Intel Core™/Intel Celeron Processors with Mobile Intel QM57 Chipset (code name: Calpella). \n\nDFI also launched system-on-module Qseven, QB700-B + Q7951, which was powered by Intel Atom E600 series processors (code name: Queensbay). In the end of 2010, DFI launched LR100-N18D/S/M Mini-ITX motherboard,  LR905-B18D/S/M COM Express, and EC200/210/220/221 embedded system,  which were based on Intel Atom D525/D425 series processors (code name: Luna Pier).\n\n\nDFI caters to the enthusiast market with motherboards with advanced overclocking features and a design with ultraviolet-reactive connectors on a black PCB. There are two versions of the LANParty line with the UT similar to the full LANParty gear except for the omission of the PC Transpo bag, UV sleeving kit, FrontX Panel, and less UV-reactant cables.\n\nDFI introduced their Junior lineup in the mid summer of 2008 with two products, p45 and 790gx, but have somewhat been extended with a nvidia chipset and X58 chipset in late 2008.\nThe junior lineup \"JR\" is micro-ATX and they usually support Crossfire or SLI setups with dual-slot videocards.\nThis series has proven to be a valuable segment in the future for small, powerful computers. However, they don't contain the same power circuitry (\"VRM/PWM\") and BIOS options as their full-sized \"ATX\" counterparts.\n\nThere are other LanParty series like LT and DK(Dark).\nLanparty UT is still the most high end line of products and few chipsets are reserved under the name.\n\nThe different variants include some of these popular products in the Lanparty series:\n\nSocket AM3\n\nSocket AM2/AM2+\n\nSocket AM2\n\nSocket 939\n\nSocket 754\n\nSocket A (462)\n\nSocket T (LGA775)\n\nSocket (LGA1366)\n\nSocket (LGA1156)\n\nDFI also has another line primarily aimed at budget overclockers. This line is the \"Infinity\"/\"Bloodiron\", which started with the nForce 2.\nThe \"Bloodiron\" is just the Infinity series renamed.\n\nAMD lineup\n\nIntel lineup\n\nDFI is also manufacturing various motherboards for mainstream users. This product line is the \"General\" line. For those wanting to build silent computers, there is a product line called \"Silent PC\".\n\nDFI is also manufacturing motherboards for various industrial purposes. DFI-ACP is a Wintel based platform provider for non-PC business, products range from board level, open frame, add-on boards to barebone systems.\n\n\n"}
{"id": "43155338", "url": "https://en.wikipedia.org/wiki?curid=43155338", "title": "Data (word)", "text": "Data (word)\n\nThe word data has generated considerable controversy on whether it is an uncountable noun used with verbs conjugated in the singular, or should be treated as the plural of the now-rarely-used \"datum\".\n\nIn one sense, \"data\" is the plural form of \"datum\". \"Datum\" actually can also be a count noun with the plural \"datums\" (see usage in datum article) that can be used with cardinal numbers (e.g. \"80 datums\"); \"data\" (originally a Latin plural) is not used like a normal count noun with cardinal numbers and can be plural with such plural determiners as \"these\" and \"many\" or as an uncountable noun with a verb in the singular form. \nEven when a very small quantity of data is referenced (one number, for example), the phrase \"piece of data\" is often used, as opposed to \"datum\". The debate over appropriate usage continues, but \"data\" as a singular form is far more common.\n\nIn English, the word \"datum\" is still used in the general sense of \"an item given\". In cartography, geography, nuclear magnetic resonance and technical drawing, it is often used to refer to a single specific reference datum from which distances to all other data are measured. Any measurement or result is a \"datum\", though \"data point\" is now far more common.\n\n\"Data\" is most often used as a singular mass noun in everyday usage. Some major newspapers, such as \"The New York Times,\" use it either in the singular or plural. In the \"New York Times\" the phrases \"the survey data are still being analyzed\" and \"the first year for which data is available\" have appeared within one day. The \"Wall Street Journal\" explicitly allows this usage in its style guide.\nThe Associated Press style guide classifies \"data\" as a collective noun that takes the singular when treated as a unit but the plural when referring to individual items (e.g., \"The data is sound\" and \"The data have been carefully collected\").\n\nIn scientific writing \"data\" is often treated as a plural, as in \"These data do not support the conclusions\", but the word is also used as a singular mass entity like \"information\", for instance in computing and related disciplines. British usage now widely accepts treating \"data\" as singular in standard English, including everyday newspaper usage at least in non-scientific use. UK scientific publishing still prefers treating it as a plural. Some UK university style guides recommend using \"data\" for both singular and plural use, and others recommend treating it only as a singular in connection with computers. The IEEE Computer Society allows usage of \"data\" as either a mass noun or plural based on author preference, while IEEE in the editorial style manual indicates to always use the plural form. Some professional organizations and style guides require that authors treat \"data\" as a plural noun. For example, the Air Force Flight Test Center specifically states that the word \"data\" is always plural, never singular.\n"}
{"id": "13507050", "url": "https://en.wikipedia.org/wiki?curid=13507050", "title": "Dutch Design Week", "text": "Dutch Design Week\n\nDutch Design Week (also known as DDW) is an annual event about Dutch design, hosted in Eindhoven, Netherlands. The event takes place around the last week of October and is a nine-day event with exhibitions, workshops, seminars and parties at many venues.\n\nDue to its industrial character, hosting companies like Philips, Philips Design and DAF, Eindhoven sets itself the goal to become the national industry- and design capital. Also, hosting the Design Academy Eindhoven and the Eindhoven University of Technology, the city produces a profound bases for innovation. In order to communicate these outcomes, the Dutch design week is organized.\n\nThe initiative started twelve years ago as a non-commercial fair where design, industry and business could talk to each other on 'neutral' ground. Since then, the event grew rapidly each year, more than 250,000 visitors in 2013.\n\nThe DDW consists of around 80 venues. The main venues during the event are among others the Klokgebouw (Strijp-S), Design Academy Eindhoven and the Faculty of Industrial Design at the Eindhoven University of Technology, where successful and well-visited expositions were organized, like the \"do not disturb exhibition\" in 2004.\n\nWhereas the main goal remains to create a non-commercial event, many conflicts of interest and the rapid growth did contribute to a more commercial approach since 2007.\n\nPop venue Effenaar and classical music venue Muziekgebouw Frits Philips both organize the musical program DDW Music around the festival with live performances as well as exhibitions related to experimental musical instruments, sound art and sound installations.\n\n"}
{"id": "967844", "url": "https://en.wikipedia.org/wiki?curid=967844", "title": "Ellen Swallow Richards", "text": "Ellen Swallow Richards\n\nEllen Henrietta Swallow Richards (December 3, 1842 – March 30, 1911) was an industrial and safety engineer, environmental chemist, and university faculty member in the United States during the 19th century. Her pioneering work in sanitary engineering, and experimental research in domestic science, laid a foundation for the new science of home economics. She was the founder of the home economics movement characterized by the application of science to the home, and the first to apply chemistry to the study of nutrition.\n\nRichards graduated from Westford Academy (second oldest secondary school in Massachusetts) in 1862. She was the first woman admitted to the Massachusetts Institute of Technology. She graduated in 1873 and later became its first female instructor. Mrs. Richards was the first woman in America accepted to any school of science and technology, and the first American woman to obtain a degree in chemistry, which she earned from Vassar College in 1870.\n\nRichards was a pragmatic feminist, as well as a founding ecofeminist, who believed that women's work within the home was a vital aspect of the economy.\n\nRichards was born in Dunstable, Massachusetts. She was the only child of Peter Swallow (b. June 27, 1813, Dunstable; d. March 1871, Littleton, Massachusetts) and Fanny Gould Taylor (b. April 9, 1817, New Ipswich, New Hampshire), both of whom came from established families of modest means and were believers in the value of education.\n\nSwallow was home-schooled in her early years. In 1859 the family moved to Westford and she attended Westford Academy. Studies at the academy included mathematics, composition, and Latin, similar to other New England academies of the time. Swallow's Latin proficiency allowed her to study French and German, a rare language north of New York. Because of her language skills she was much in demand as a tutor, and the income earned doing this made it possible for Swallow to further her studies.\n\nIn March 1862, she left the academy. Two months later, in May, she developed the measles which set her back physically and interrupted her preparations to begin teaching.\nIn the spring of 1863 the family moved to Littleton, Massachusetts, where Mr. Swallow had just purchased a larger store and expanded his business. In June 1864, Swallow, now twenty-one, took a teaching position.\n\nShe did not teach again in 1865 but spent that year tending the family store and taking care of her ill mother. During the winter of 1865–66, Swallow studied and attended lectures in Worcester.\n\nIn September 1868 she entered Vassar College classified as a special student. Somewhat over a year later she was admitted to the senior class, graduating in 1870 with a bachelor's degree. She then earned a Master of Art's degree with a thesis on the chemical analysis of iron ore. The strongest personal influences during her college years were Maria Mitchell, the astronomer, and Professor Charles S. Farrar (1826-1908), who was at the head of the Department of Natural Sciences and Mathematics.\n\nIn 1870, she wrote to Merrick and Gray, commercial chemists in Boston, asking if they would take her on as an apprentice. They replied that they were not in a position to take pupils, and that her best course was to try to enter the Institute of Technology of Boston as a student.\nOn December 10, 1870, after some discussion and a vote, the Faculty of the Institute of Technology recommend to the Corporation the admission of Miss Swallow as a special student in Chemistry. Swallow thus became the first woman admitted to Massachusetts Institute of Technology where she was able to continue her studies, \"it being understood that her admission did not establish a precedent for the general admission of females\" according to the records of the meeting of the MIT Corporation on December 14, 1870.\nIn 1873, Swallow received a Bachelor of Science degree from MIT for her thesis, \"Notes on Some Sulpharsenites and Sulphantimonites from Colorado\". She continued her studies at MIT and would have been awarded its first advanced degree, but MIT balked at granting this distinction to a woman and did not award its first advanced degree, a Master of Science in Chemistry, until 1886.\n\nRichards served on the board of trustees of Vassar College for many years and was granted an honorary doctor of science degree in 1910.\n\nOn June 4, 1875, Miss Swallow married Robert H. Richards (1844-1945), chairman of the Mine Engineering Department at MIT, with whom she had worked in the mineralogy laboratory. They took up residence in Jamaica Plain, Massachusetts. With her husband's support she remained associated with MIT, volunteering her services and contributing $1,000 annually to the \"Woman's Laboratory,\" a program in which her students were mostly schoolteachers, whose training had lacked laboratory work, and who wanted to perform chemical experiments and learn mineralogy.\n\nHer first post-college career was as an unpaid chemistry lecturer at MIT from 1873 to 1878.\nFrom 1884 until her death, Swallow now Richards was an instructor at the newly founded laboratory of sanitary chemistry at the Lawrence Experiment Station, the first in the United States, headed by her former professor William R. Nichols.\n\nIn 1884 she was appointed as an instructor in sanitary chemistry at a newly formed MIT laboratory for the study of sanitation.\n\nMrs. Richards was a consulting chemist for the Massachusetts State Board of Health from 1872 to 1875, and the Commonwealth's official water analyst from 1887 until 1897. She also served as nutrition expert for the US Department of Agriculture.\n\nIn the 1880s, her interests turned toward issues of sanitation, in particular air and water quality. She performed a series of water tests on 40,000 samples of local waters which served as drinking water for their immediate populations. These led to the so-called \"Richards' Normal Chlorine Map\" which was predictive of inland water pollution in the state of Massachusetts. This map plotted the chloride concentrations in waters of the state. It illustrated the natural distribution of chlorides from the ocean. (Her survey long preceded the practice of road de-icing with chlorine derivative salts.) Her map plotted greater than 6.5 parts per million (ppm) of chloride near the coast, with Cape Cod concentrations well in excess of 10 ppm and with a near-steady decreasing gradient to less than 1 ppm about the Berkshire Hills in the extreme western end of the state. Thereby waters with chloride concentrations that deviated from the plot could be suspected of human pollution. As a result, Massachusetts established the first water-quality standards in America, and the first modern sewage treatment plant was created.\n\nRichards' master's thesis at Vassar was an analysis of the amount of vanadium in iron ore.\nShe performed numerous experiments in mineralogy, including the discovery of an insoluble residue of the rare mineral samarskite. This was later determined by other scientists to yield samarium and gadolinium. In 1879 she was recognized by the American Institute of Mining and Metallurgical Engineers as their first female member.\n\nRichards applied her scientific knowledge to the home. Since women were responsible for the home and family nutrition at the time, Richards felt that all women should be educated in the sciences. She wrote books about science for use in the home, such as \"The Chemistry of Cooking and Cleaning\", published in 1882. Her book \"Food Materials and Their Adulterations\"(1885) led to the passing of the first Pure Food and Drug Act in Massachusetts.\n\nShe used her own home as a kind of experimental laboratory for healthier living through science. Concerned with air quality in her home, she moved from coal heating and cooking oil to gas. She and her husband installed fans to pull air from the home to the outside to create a cleaner air environment within the home. She also determined the water quality of the property's well through chemical testing, and to insure that waste water was not contaminating the drinking water.\n\nRichards derived the term euthenics from the Greek verb Eutheneo, Εὐθηνέω (eu, well; the, root of tithemi, to cause). To be in a flourishing state, to abound in, to prosper.—\"Demosthenes\". To be strong or vigorous.—\"Herodotus\". To be vigorous in body.—\"Aristotle\". And from the Greek Euthenia, Εὐθηνία. Good state of the body: prosperity, good fortune, abundance.—\"Herodotus\". The opposite of Euthenia is Penia - Πενία (\"deficiency\" or \"poverty\") the personification of poverty and need.\n\nIn her book \"Euthenics: the science of controllable environment\" (1910), she defined the term as the betterment of living conditions, through conscious endeavor, for the purpose of securing efficient human beings.\n\nVigorous debate about its exact meaning, confusion with the term eugenics, followed by the Great Depression and two world wars, were among the many factors which led to the movement never really getting the funding, nor the attention needed to put together a lasting, vastly multidisciplinary curriculum as defined by Richards. Instead, different disciplines such as Child Study became one such curriculum.\n\nMartin Heggestad of the Mann Library notes that: Starting around 1920, however, home economists tended to move into other fields, such as nutrition and textiles, that offered more career opportunities, while health issues were dealt with more in the hard sciences and in the professions of nursing and public health. Also, improvements in public sanitation (for example, the wider availability of sewage systems and of food inspection) led to a decline in infectious diseases and thus a decreasing need for the largely household-based measures taught by home economists.\n\nRichards was the first writer to use the term euthenics, in \"The Cost of Shelter\" (1905), with the meaning \"the science of better living\".\n\nAfter her first experience as water analyst under Professor Nichols, Richards began a large, private practice in sanitary chemistry, including testing water, air and food, and the testing wallpapers and fabrics for arsenic. In 1878 and 1879 she examined a large number of staple groceries for the state. The results of her investigation were published in the first annual report of the Board of Health, Lunacy and Charity, which had succeeded the earlier Board of Health.\n\nShe also served as a consultant to the Manufacturers Mutual Fire Insurance Company and in 1900 wrote the textbook \"Air, Water, and Food from a Sanitary Standpoint\", with A. G. Woodman. Her interest in the environment led her to introduce the word ecology into English around 1892. The word had been coined by German biologist Ernst Haeckel to describe the \"household of nature\".\n\nRichards' interests also included applying scientific principles to domestic situations, such as nutrition, clothing, physical fitness, sanitation, and efficient home management, creating the field of home economics. \"Perhaps the fact that I am not a radical and that I do not scorn womanly duties but claim it as a privilege to clean up and sort of supervise the room and sew things is winning me stronger allies than anything else,\" she wrote to her parents. She published \"The Chemistry of Cooking and Cleaning: A Manual for House-keepers\" in 1881, designed and demonstrated model kitchens, devised curricula, and organized conferences.\n\nMrs. Richards appeared before the Woman's Education Association of Boston on November 11, 1875, and in an address, which made a deep impression, set forth the needs of women. She expressed the belief that the governing board of the Institute of Technology would provide space for a woman's laboratory if the Association would supply the necessary money for instruments, apparatus, and books. She said that scholarships would be indispensable.\n\nThe Woman's Education Association appointed a committee to enter into discussions with the Institute of Technology, which led to the creation of the MIT Woman's Laboratory in November 1876. The Institute provided a small building, planned for a gymnasium, as the location of the Laboratory. Mrs. Richards became an unpaid assistant instructor in 1879 in chemical analysis, industrial chemistry, mineralogy, and applied biology under Professor John M. Ordway. The Woman's Education Association agreed to raise money to buy equipment for the laboratory.\n\nA new building, erected by the Institute in 1883, reserved space for all laboratory students' use, women as well as men. The original Woman's Laboratory was closed and the building demolished.\n\nIn 1884, Mrs. Richards was appointed Instructor in Sanitary Chemistry in the Institute of Technology itself, a position which she filled until the time of her death. In addition to her faculty duties and instructional work, she was also the \"untitled\" Dean of Women.\n\nIn January 1876, Mrs. Richards began a long association with the first American correspondence school, the Society to Encourage Studies at Home, as an instructor, and developed its science department.\n\nIn 1886, a new section promoted by Richards, Sanitary Science, was established by the Society. This was at a time when household conveniences employing water, gas, or electricity were becoming more common, but housekeepers seldom understood the dangers or difficulties inherent in using these new appliances. She saw that instruction was needed and the Society began to provide information on how to organize a house on truly scientific principles.\n\nRichards and Marion Talbot (Boston University class of 1880) became the \"founding mothers\" of what was to become the American Association of University Women (AAUW) when they invited fifteen other women college graduates to a meeting at Talbot's home in Boston, on November 28, 1881. The group envisioned an organization in which women college graduates would band together to open the doors of higher education to other women and to find wider opportunities for their training. The Association of Collegiate Alumnae (ACA), AAUW's predecessor organization, was officially founded on January 14, 1882.\n\nLucretia Crocker, along with women's clubs and other help in the Boston area, created a \"Teachers' School of Science\" in Back Bay at the New Museum of the Boston society. Along with Mrs. Richards, Crocker created a mineralogy course for teachers. Teacher found such education in the Boston area because of area scientist that would teach their courses.\n\nIn January 1, 1890, Richards collaborated with Mary Hinman Abel (1850–1938) to found the New England Kitchen of Boston, at 142 Pleasant Street. Using volunteers of modest circumstances, they experimented with ways to prepare the most inexpensive, tasty and nutritious food.\n\nYears later, Mrs. Richards, herself, wrote in her preface to part one of \"The Rumford kitchen leaflets: No. 17, The Story of the New England Kitchen; Part II; A study in social economics\", by Mary Abel:\nThe story of the New England Kitchen ... is remarkable for two things: the new and valuable information which has been acquired, as the result of the daily work of the Kitchen, and the short time which has sufficed to put the enterprise on a business basis.\n\nIt is well to emphasize the causes of this success, that the lessons in social science and practical philanthropy be not lost. A large part of the credit is due ... to Mrs. Abel's hard work[.] [S]tarting the New England Kitchen ... was ... an experiment to determine the successful conditions of preparing, by scientific methods, from the cheaper food materials, nutritious and palatable dishes, which should find a ready demand at paying prices.\n\nMrs. Abel would doubtless give as the principal secret of her success, that she had everything necessary for the experiments, without giving a thought to the cost. ... In the New England Kitchen, the selection of the apparatus and material and the employment of labor have been without restriction. Without this freedom to carry on the experiments as seemed wise and prudent, the results detailed in the accompanying report could not have been attained.\n\nThe philanthropy of the scheme rests in the experimental stage of the development of the New England Kitchen. Whether the business can in the future take care of itself to the profit of those who conduct it remains to be seen ; but, in any event, kitchens of this kind cannot fail to be of great advantage to multitudes in moderate circumstances, who have hitherto been unable to buy good, nutritious, and tasteful cooked food.\n\nIn 1893, when Richards was in charge of the Rumford Kitchen at the World's Fair in Chicago, she accepted the added work and responsibility of arranging an exhibition of the work of Studies at Home.\n\nThe opening statement of the \"Guide to the Rumford Kitchen: An Exhibit made by the State of Massachusetts in connection with the Bureau of Hygiene and Sanitation\" (World's Columbian Exposition, Chicago, 1893) by General Francis A. Walker explains:\n\nThe exhibit known as the Rumford Kitchen is the outgrowth of the work, in the application of the principles of chemistry to the science of cooking, which has for three years been carried on as an educational agency by Mrs. Robert H. Richards and Mrs. Dr. John J. Abel, with pecuniary assistance from certain public-spirited citizens of Boston.\n\nThe Massachusetts Board of World's Fair Managers, ... believing that such practical demonstration of the usefulness of domestic science could not fail to be of advantage to multitudes of visitors to the Columbian Exposition, have invited the ladies named to open the Rumford Kitchen as a part of the exhibit of Massachusetts in connection with the Bureau of Hygiene and Sanitation.\n\nIn order to reduce, in some degree, the expenses of this exhibit, the food cooked in the Rumford Kitchen will be sold under a concession from the administration of the Exposition ; but it should be understood that this is not a money-making exhibit ; that nothing is cooked for the sake of being sold ; and that the enterprise is to be regarded as absolutely a scientific and educational one.\n\nThe purpose of the exhibit in the Rumford Kitchen is two-fold : First, to commemorate the services to the cause of domestic science rendered by Count Rumford one hundred years ago[;] ... second, to serve as an incentive to further work in the same direction, as he expressed it,\" to provoke men to investigation,\" \"to cause doubt, that first step toward knowledge.\"\n\nThe first commercially available \"modern\" kitchen ranges began to appear about 1800, they were the invention of an American named Sir Benjamin Thompson, Count von Rumford.\n\nA first, major program was started in some Boston high schools in 1894 to provide nutritional meals at low prices to children who would not normally have them. Due in large part to Ellen Richards and Edward Atkinson, the New England Kitchen ran the program as a 'private enterprise' that paid for itself many times over. The lunches never became effective instruments for teaching the New Nutrition the founders had envisaged. But, because the program provided nutritious meals children would otherwise not have, it became the main justification for similar lunch programs in other cities.\"\n\nIn 1946, President Harry S. Truman signed into law the National School Lunch Program to provide low-cost or free school lunch meals to qualified students through subsidies to schools. The program was established as a way to prop up food prices by absorbing farm surpluses, while at the same time providing food to school age children. It was named after Richard Russell, Jr.\n\nEarly in September, 1899, trustees of the Lake Placid Club (Morningside, New York) thought it was the right time to bring together those most interested in home science, or household economics and sent out many invitations for the Lake Placid Conference scheduled to take place Sept. 19-25, 1899. Melvil Dewey, one of the club's trustees, personally invited Richards to attend. She gave a lecture on standards of living and was elected chairman of the conference.\n\nIn 1908, Richards was chosen as the first president of the newly formed American Home Economics Association, which was renamed the American Association of Family and Consumer Sciences in 1994. She also founded and funded the Association's periodical, the \"Journal of Home Economics\", which began publication in 1909. It was renamed the \"Journal of Family and Consumer Sciences\" in 1994 when the Association changed its name.\n\nHer books and writings on this topic include \"Food Materials and their Adulterations\" (1886); \"Conservation by Sanitation\"; \"The Chemistry of Cooking and Cleaning\"; \"The Cost of Living\" (1899); \"Air, Water, and Food\" (1900); \"The Cost of Food\"; \"The Cost of Shelter\"; \"The Art of Right Living\"; \"The Cost of Cleanness\"; \"Sanitation in Daily Life\" (1907); and \"Euthenics, the Science of Controllable Environment\" (1910). Some of these went through several editions.\n\nRichards died on March 30, 1911 at her home in Jamaica Plain, Massachusetts after suffering with angina. She is buried in the family cemetery in Gardiner, Maine.\n\n\n\nRichards's manuscripts are contained in various collections throughout the United States and beyond. Aside from those listed below, manuscripts can be found within collections related to the organizations Richards was associated with, such as the American Association of Family and Consumer Sciences, whose manuscripts are housed in several collections at Cornell University, Iowa State University, etc.\n\n\n\n"}
{"id": "38604828", "url": "https://en.wikipedia.org/wiki?curid=38604828", "title": "Energy Logic", "text": "Energy Logic\n\nEnergy Logic is a vendor-neutral approach to achieving energy efficiency in data centers. Developed and initially released in 2007, the Energy Logic efficiency model suggests ten holistic actions – encompassing IT equipment as well as traditional data center infrastructure – guided by the principles dictated by the \"Cascade Effect.\"\n\nThe first iteration of the Energy Logic model was introduced by Emerson Network Power on November 29, 2007. Described as a “new approach to energy optimization,” the model was developed in response to industry feedback suggesting a growing emphasis on promoting efficiency initiatives, without compromising the performance and reliability of the data center.\n\nThe Energy Logic data center efficiency model was developed based on research and modeling of a 5,000 square foot data center, including average IT equipment densities, common data center and facility infrastructures (power, cooling, etc.) and their collective energy draw.\n\nEnergy draw for the 5,000 square foot data center model was based on the following assumptions:\n\n\nBased on the benchmarks established by the 5,000 sq. ft. model, Emerson Network Power recommended improvements to IT and data center infrastructures capable of maximizing total energy savings by leveraging the “cascade effect.”\nFor the purposes of the Energy Logic model, the cascade effect assumes that for every one watt of energy saved at the server component level, a data center can expect to realize up to 2.84 Watts in cumulative energy savings as the initial reduction “cascades” through the infrastructure (DC-DC, AC/DC, Power Distribution, etc.).\n\nThe Energy Logic model proposes ten vendor-neutral actions that are forecast to reduce cumulative energy consumption by up to 50 percent (reducing energy consumption to 585 kW from the data center's initial 1,127 kW load). The ten recommended actions prescribed in the Energy Logic model are:\n\n\nThe Energy Logic model also suggests additional opportunities for energy savings, including:\n\nIn 2012, Emerson Network Power introduced an update to the Energy Logic model, to take into consideration advances in IT and data center infrastructure technology.\n\nUsing the same 5,000 square foot data center benchmarked in the 2007 model, Energy Logic 2.0 updates the ten prescribed actions to reflect current technologies and average equipment efficiency. As a result, the updated actions are forecast to yield energy savings up to 74 percent (reducing energy consumption from 1,543 kW to 408 kW in the model data center).\n\nThe ten updated actions include:\n\n\n"}
{"id": "49076910", "url": "https://en.wikipedia.org/wiki?curid=49076910", "title": "European Biotechnology Association", "text": "European Biotechnology Association\n\nThe European Biotechnology Association (European Biotechnology Thematic Network Association- EBTNA) is an organization founded in 1996 and since presents both academic and industrial projects that help to establish connections between the biotech industry and science. Biotechnology is wide term which includes fields such as Animal Biotechnology, Medical Genetics, Biocatalysis/Biotransformation, Medicine & Biotechnology, Bioinformatics/System Biology, Metabolic Engineering, Bioprocess Engineering, Nanotechnology, Biosensors, Omics Sciences, Biotechnology & Ethics, Pharmaceutical Biotechnology, Plant Biotechnology, Environmental Biotechnology, Renewables, Biorefinery, Bioenergy, Biofuels, Bioproducts, Enzyme and Protein Engineering, Stem Cells, Biomaterials, Tissue Engineering, Food & Feed Biotechnology. That is why this innovative discipline is so important to humankind. So global tasks such as the announcement of the developments in the field of biotechnology, public education, and connection of scientists of different fields is undertaken by EBTNA. By using coordinating system EBTNA realizes activities in 47 countries worldwide.\n\na. to implement, consult or supervise programs for the assessment of skills and knowledge in sciences with an emphasis on biotechnology;\n\nb. to undertake programs concerning education, training and research, especially those concerning innovative approaches;\n\nc. to operate as a consultant or assessor in programs concerning education and training;\n\nd. to provide certification of achievement when assessments have been carried out under appropriate conditions;\n\ne. to co-operate with established professional or other associations in the furtherance of its objectives;\n\nf. to extend the reach of all aspects of education in biotechnology beyond national border.\n\n\nAssociation established in 1996 by Prof.Mariapia Viola Magni in Piazza University in Italy. First president of association were Prof. Mariapia Viola Magni, after her Prof. Fabrizio Bruschi was in charge as president. Prof. Magni still serves as General Secretary. The current board is;\n\nPresident: Prof. Munis Dündar- Erciyes University/Turkey\n\nGeneral Secretary: Prof.Mariapia Viola Magni- Piazza University/Italy\n\nVice President: Prof. Kevan Gartland- Glasgow Caledonia University/ U.K.\n\nTreasurer: Prof. Tommasso Beccari- Perugia University/Italy\n\nMember: Prof Oscar Vicente- Polytechnic University of Valencia/Spain\n\nMember: Prof Juraj Krajcovic- Comenius University/Slovakia\n\nMember: Prof Michelle Maffia- Salento University/Italy\n\nMember: Prof Michel Salzet- Lille University/France\n"}
{"id": "56057622", "url": "https://en.wikipedia.org/wiki?curid=56057622", "title": "European Union food quality scandal", "text": "European Union food quality scandal\n\nThe European Union food quality scandal is a controversy claiming that certain food brands and items targeted at Central and Eastern European Union countries' markets are of lower quality than their exact equivalent produced for the Western European Union markets.\n\nEuropean Commission President Jean-Claude Juncker acknowledged the issue in his State of the Union address pledging funding to help national food authorities test the inferior products and start tackle the food inequality and in April 2018 EU Justice and Consumers Commissioner Věra Jourová stated that \"“We will step up the fight against dual food quality. We have amended the Unfair Commercial Practice Directive to make it black and white that dual food quality is forbidden.\"\n"}
{"id": "34343481", "url": "https://en.wikipedia.org/wiki?curid=34343481", "title": "Feefighters", "text": "Feefighters\n\nFeeFighters is a comparison shopping website for credit card processing. The site was launched in 2009 and acquired by Groupon in April 2013. FeeFighters has been featured in The New York Times, Entrepreneur (magazine), Inc. (magazine) and TechCrunch, with BusinessWeek profiling it as \"One of America's Most Promising Startups.\"\n\n"}
{"id": "2035650", "url": "https://en.wikipedia.org/wiki?curid=2035650", "title": "Felice Matteucci", "text": "Felice Matteucci\n\nFelice Matteucci (February 12, 1808 – September 13, 1887) was an Italian hydraulic engineer who co-invented an internal combustion engine with Eugenio Barsanti. Their patent request was granted in London on June 12, 1854, and published in London's Morning Journal under the title \"Specification of Eugene Barsanti and Felix Matteucci, Obtaining Motive Power by the Explosion of Gases\", as documented by the Fondazione Barsanti e Matteucci.\n\nBorn in Lucca, Tuscany, Matteucci studied hydraulic and mechanical engineering, first in Paris, then in Florence. In 1851 he met Father Barsanti and appreciated his ideas for a new type of engine. They worked together to turn the primary concept into a manufacturable item, eventually developing a model suitable for mass production. Its construction was entrusted to Bauer & Co. of Milan, a company also known as Helvetica, which delivered the motor at the beginning of 1863.\n\nThe success of the engine, which was much more efficient that the steam-engine, was so great that orders started pouring in from as far away as Constantinople. Matteucci and Barsanti reached an agreement for the production of the motor with a company in Belgium, and Barsanti departed for Belgium on February 18, 1864 to oversee the work personally. On the following April 19, Barsanti died suddenly, and all their work came to an end.\n\nMatteucci returned to his previous work as a hydraulic engineer. He studied new hydrometers (to measure the level of a river), rain gauges, and hydraulic operations over rivers.\n\nIn 1877, Matteucci defended that he and Barsanti were the originators of the invention of the internal combustion engine. The patent registered by Nikolaus August Otto was indeed very similar to the Barsanti-Matteucci engine. This frustration contributed to Matteucci's illness that eventually caused his death, in his own home in Capannori, near Lucca. The documents concerning the priority of Barsanti and Matteucci’s engine and their patents in England, Piedmont, France, Belgium and Prussia are kept in the archive of the library of the Museo Galileo in Florence. \n\n\n\n"}
{"id": "1493194", "url": "https://en.wikipedia.org/wiki?curid=1493194", "title": "Infra-red search and track", "text": "Infra-red search and track\n\nAn infrared search and track (IRST) system (sometimes known as infrared sighting and tracking) is a method for detecting and tracking objects which give off infrared radiation (see Infrared signature) such as jet aircraft and helicopters.\n\nIRST is a generalized case of forward looking infrared (FLIR), i.e. from forward-looking to all-round situation awareness. Such systems are passive (thermographic camera), meaning they do not give out any radiation of their own, unlike radar. This gives them the advantage that they are difficult to detect.\n\nHowever, because the atmosphere attenuates infrared to some extent (although not as much as visible light) and because adverse weather can attenuate it also (again, not as badly as visible systems), the range compared to a radar is limited. Within range, angular resolution is better than radar due to the shorter wavelength.\n\nThe first use of an IRST system appears to be the F-101 Voodoo, F-102 Delta Dagger and F-106 Delta Dart interceptors. The F-106 had an early IRST mounting replaced in 1963 with a production retractable mount. The IRST was also incorporated into the Vought F-8 Crusader (F-8E variant) which allowed passive tracking of heat emissions and was similar to the later Texas Instruments AAA-4 installed on early F-4 Phantoms.\n\nThe F-4 Phantom had a Texas Instruments AAA-4 infrared seeker under the nose of early production aircraft F-4B's and F-4C's and not installed on later F-4-D's due to limited capabilities, but retained the bulge and indeed some F-4D's had the IRST receiver retrofitted in a modified form.\n\nThe F-4E eliminated the AAA-4 IRST bulge and received an internal gun mount which took up the area under the nose. The F-4J which had a pulse-doppler radar also eliminated the AAA-4 IRST receiver and bulge under the nose.\n\nThe first use of IRST in an Eastern European country was the Mikoyan-Gurevich MiG-23 The MiG-23 used the (TP-23ML) IRIST and later versions used the (26SH1) IRST. The Mikoyan-Gurevich MiG-25PD was also equipped with a small IRIST under the nose.\n\nThe Swedish Saab J-35F2 Draken (1965) also used an IRST, a Hughes Aircraft Company N71.\n\nThese were fairly simple systems consisting of an infra-red sensor with a horizontally rotating shutter in front of it. The shutter was slaved to a display under the main interception radar display in the cockpit. Any IR light falling on the sensor would generate a \"pip\" on the display, in a fashion similar to the B-scopes used on early radars.\n\nThe display was primarily intended to allow the radar operator to manually turn the radar to the approximate angle of the target, in an era when radar systems had to be \"locked on\" by hand. The system was considered to be of limited utility, and with the introduction of more automated radars they disappeared from fighter designs for some time.\n\nIRST systems re-appeared on more modern designs starting in the 1980s with the introduction of 2-D sensors, which cued both horizontal and vertical angle. Sensitivities were also greatly improved, leading to better resolution and range. In more recent years, new systems have entered the market. In 2015, Northrop Grumman introduced its OpenPod(TM) IRST pod, which uses a sensor by Leonardo.\n\nThe best known users of modern IRST systems are:\n\nThese fighter aircraft carry the IRST systems for use instead of radar when the situation warrants it, such as when shadowing other aircraft, under the control of Airborne Early Warning and Control(AWACS) aircraft, or executing a Ground-controlled interception(GCI), where an external radar is used to help vector the fighter to a target and the IRST is used to pick up and track the target once the fighter is in range.\n\nWith infrared homing or fire-and-forget missiles, the fighter may be able to fire upon the target without having to turn its radar sets on at all. Otherwise, the fighter can turn the radar on and achieve a lock immediately before firing if desired. The fighter could also close to within cannon range and engage that way.\n\nWhether or not they use their radar, the IRST system can still allow them to launch a surprise attack.\n\nAn IRST system may also have a regular magnified optical sight slaved to it, to help the IRST-equipped aircraft identify the target at long range. As opposed to an ordinary forward looking infrared system, an IRST system will actually scan the space around the aircraft similarly to the way in which mechanically (or even electronically) steered radars work. The exception to the scanning technique is the F-35 JSF's DAS, which stares in all directions simultaneously, and automatically detects and declares aircraft and missiles in all directions, without a limit to the number of targets simultaneously tracked.\n\nWhen they find one or more potential targets they will alert the pilot(s) and display the location of each target relative to the aircraft on a screen, much like a radar. Again similarly to the way a radar works, the operator can tell the IRST to track a particular target of interest, once it has been identified, or scan in a particular direction if a target is believed to be there (for example, because of an advisory from AWACS or another aircraft).\n\nIRST systems can incorporate laser rangefinders in order to provide full fire-control solutions for cannon fire or launching missiles (Optronique secteur frontal). The combination of an atmospheric propagation model, the apparent surface of the target, and target motion analysis (TMA) IRST can calculate the range.\n\nThe United States Air Force is currently seeking an IRST system for its F-15 aircraft.\n\nDetection range varies with\n\nThe higher the altitude, the less dense the atmosphere and the less infrared radiation it absorbs - especially at longer wavelengths. The effect of reduction in friction between air and aircraft does not compensate the better transmission of infrared radiation. Therefore, infrared detection ranges are longer at high altitudes.\n\nAt high altitudes, temperatures range from −30 to −50 °C - which provide better contrast between aircraft temperature and background temperature.\n\nThe Eurofighter Typhoon's PIRATE IRST can detect subsonic fighters from 50 km from front and 90 km from rear - the larger value being the consequence of directly observing the engine exhaust, with an even greater increase being possible if the target uses afterburners.\n\nThe range at which a target can be sufficiently confidently identified to decide on weapon release is significantly inferior to the detection range - manufacturers have claimed it is about 65% of detection range.\n\n\n\n"}
{"id": "1404538", "url": "https://en.wikipedia.org/wiki?curid=1404538", "title": "Inter-Connect Ltd", "text": "Inter-Connect Ltd\n\nInterconnect Limited is a Kenyan Internet Service Provider that has been in operation since 1997.\n"}
{"id": "26480717", "url": "https://en.wikipedia.org/wiki?curid=26480717", "title": "Intermodulation intercept point", "text": "Intermodulation intercept point\n\nThe intermodulation intercept point is a measure of an electrical device's linearity. When driven by two sinusoidal waveforms, it is the theoretical power level at which the power of the desired tone and the nth-order (where n is odd) intermodulation product intersect.\n\n"}
{"id": "6249276", "url": "https://en.wikipedia.org/wiki?curid=6249276", "title": "Isogrid", "text": "Isogrid\n\nIsogrid is a type of partially hollowed-out structure formed usually from a single metal plate (or face sheet) with triangular integral stiffening ribs (often called stringers). It is extremely light and stiff. Compared to other materials, it is expensive to manufacture, and so it is restricted to spaceflight applications and some particularly critical parts of more general aerospace use.\n\nIsogrid structures are related to sandwich-structured composite panels; both can be modeled using sandwich theory, which describes structures with separated, stiff face sheets and a lighter interconnecting layer. Isogrids are manufactured from single sheets of material and with large-scale triangular openings, and an open pattern to the flanges, compared to closed sheets and foam or honeycomb structures for the sandwich-composite structures.\n\nIsogrid structures are constituted by a thin skin reinforced with a lattice structure. Such structures are adopted in the aeronautical industry since they present both structural resistance and lightness.\n\nThe triangular pattern is very efficient because it retains rigidity while saving material and therefore weight. The term isogrid is used because the structure acts like an isotropic material, with equal properties measured in any direction, and grid, referring to the sheet and stiffeners structure.\n\nA similar variant is the Orthogrid which uses rectangular rather than triangular openings. This is not isotropic (has different properties from different angles) but matches many use cases well and is easier to manufacture.\n\nTraditionally, the equilateral triangle pattern was used because it was amenable to simplified analysis. Since the equilateral triangle pattern has isotropic strength characteristics (no preferential direction), it was named isogrid.\n\nThe stiffeners of an isogrid are generally machined from one face of a single sheet of material such as aluminum with a CNC milling machine. A thickness less than 0.040 in. (1.0 millimeter) might require chemical milling processes.\n\nComposite isogrids are rib-skin configurations, where at least a part of the rib is a different material from the skin, the composite assembled by various manual or automated processes. \nThis can give extremely high strength-weight ratios.\n\nIsogrid panels form self-stiffened structures where low weight, stiffness, strength and damage tolerance are important, such as in aircraft or space vehicles. \nAerospace isogrid structures include payload shrouds and boosters, which must support the full weight of upper stages and payloads under high G loads. Their open configuration with a single, sealed sheet facing the outside makes them especially useful for propellant tanks for rockets, where sealing the propellant in, but allowing it to drain in use or maintenance are necessary features.\n\nSome spacecraft and launch vehicles which use isogrid structures include:\n\n"}
{"id": "8767767", "url": "https://en.wikipedia.org/wiki?curid=8767767", "title": "JourneyWeb", "text": "JourneyWeb\n\nJourneyWeb is an XML protocol to allow distributed journey planning engines to communicate in order to provide multimodal journeys spanning different regions.\n\nThe protocol is a UK national de facto standard sponsored by the UK Department for Transport. It is used in the Transport Direct Portal.\n\nJourneyWeb makes use of uniform UK Stop Data from NaPTAN\n\n"}
{"id": "839321", "url": "https://en.wikipedia.org/wiki?curid=839321", "title": "Line level", "text": "Line level\n\nLine level is the specified strength of an audio signal used to transmit analog sound between audio components such as CD and DVD players, television sets, audio amplifiers, and mixing consoles.\n\nLine level sits amongst other signal strengths such as those from weaker audio signals i.e. microphones and instrument pickups, and stronger signals, such as those used to drive headphones and loudspeakers. The \"strength\" of these various signals does not necessarily refer to the output voltage of the source device; it also depends on its output impedance and output power capability.\n\nConsumer electronic devices concerned with audio (for example sound cards) often have a connector labeled \"line in\" and/or \"line out\". \"Line out\" provides an audio signal output and \"line in\" receives a signal input. The line in/out connections on consumer-oriented audio equipment are typically unbalanced, with a (0.14 inch, but commonly called \"eighth inch\") 3-conductor TRS minijack connector providing ground, left channel, and right channel, or stereo RCA jacks. Professional equipment commonly uses balanced connections on (1/4 inch) TRS phone jacks or XLR connectors. Professional equipment may also use unbalanced connections with (1/4 inch) TS phone jacks.\n\nA line level describes a line's nominal signal level as a ratio, expressed in decibels, against a standard reference voltage. The nominal level and the reference voltage against which it is expressed depend on the line level being used. While the nominal levels themselves vary, only two reference voltages are common: for consumer applications, and for professional applications.\n\nThe decibel volt reference voltage is . The decibel unloaded reference voltage, , is the AC voltage required to produce of power across a impedance (approximately ). This awkward unit is a holdover from the early telephone standards, which used 600 Ω sources and loads, and measured dissipated power in decibel-milliwatts (dBm). Modern audio equipment does not use 600 Ω matched loads, hence \"dBm unloaded\" (\"dBu\").\n\nThe most common nominal level for professional equipment is (by convention, decibel values are written with an explicit sign symbol). For consumer equipment it is , which is used to reduce manufacturing costs.\n\nExpressed in absolute terms, a signal at is equivalent to a sine wave signal with a peak amplitude (V) of approximately , or any general signal at root mean square (V). A signal at is equivalent to a sine wave signal with a peak amplitude of approximately , or any general signal at approximately 1.228 V.\n\nPeak-to-peak (sometimes abbreviated as \"p-p\") amplitude (V) refers to the total voltage swing of a signal, which is double the peak amplitude of the signal. For instance, a signal with a peak amplitude of has a of .\n\nThe line level signal is an alternating current signal without a DC offset, meaning that its voltage varies with respect to signal ground from the peak amplitude (for example ) to the equivalent negative voltage ().\n\nAs cables between line output and line input are generally extremely short compared to the audio signal wavelength in the cable, \ntransmission line effects can be disregarded and impedance matching need not be used. \nInstead, line level circuits use the impedance bridging principle, \nin which a low impedance output drives a high impedance input. \nA typical line out connection has an output impedance from 100 to 600 Ω, with lower values being more common in newer equipment. \nLine inputs present a much higher impedance, typically or more.\n\nThe two impedances form a voltage divider with a shunt element that is large relative to the size of the series element, which ensures that little of the signal is shunted to ground and that current requirements are minimized. \nMost of the voltage asserted by the output appears across the input impedance and almost none of the voltage is dropped across the output.\nThe line input acts similarly to a high impedance voltmeter or oscilloscope input, measuring the voltage asserted by the output while drawing minimal current (and hence minimal power) from the source. \nThe high impedance of the line in circuit does not load down the output of the source device.\n\nThese are voltage signals (as opposed to current signals) and it is the signal information (voltage) that is desired, not power to drive a transducer, such as a speaker or antenna. The actual information that is exchanged between the devices is the variance in voltage; it is this alternating voltage signal that conveys the information, making the current irrelevant.\n\n             Line-out symbol. PC Guide color lime green.\n\nLine outputs usually present a source impedance of from 100 to 600 ohms. The voltage can reach 2 volts peak-to-peak with levels referenced to −10 dBV (300 mV) at . The frequency response of most modern equipment is advertised as at least 20 Hz to 20 kHz, which corresponds to the range of human hearing. Line outputs are intended to drive a load impedance of \n10,000 ohms; with only a few volts, this requires only minimal current.\n\nConnecting a low-impedance load such as a loudspeaker (usually ) to a line out will essentially short circuit the output circuit. Such loads are around 1/1000 the impedance a line out is designed to drive, so the line out is usually not designed to source the current that would be drawn by a 4 to 8 ohm load at normal line out signal voltages. The result will be very weak sound from the speaker and possibly a damaged line out circuit.\n\nHeadphone outputs and line outputs are sometimes confused. \nDifferent make and model headphones have widely varying impedances, from as little as to a few hundred ohms; the lowest of these will have results similar to a speaker, while the highest may work acceptably if the line out impedance is low enough and the headphones are sensitive enough.\n\nConversely, a headphone output generally has a source impedance of only a few ohms (to provide a bridging connection with 32 ohm headphones) and will easily drive a line input.\n\nFor similar reasons, \"wye\"-cables (or \"Y-splitters\") should not be used to combine two line out signals into a single line in. \nEach line output would be driving the other line output as well as the intended input, \nagain resulting in a much heavier load than designed for. This will result in signal loss and possibly even damage.\nAn active mixer, using for example op-amps, \nshould be used instead. A large resistor in series with each output can be used to safely mix them together, but must be appropriately designed for the load impedance and cable length.\n\n             Line-in symbol. PC Guide color light blue.\n\nIt is intended by designers that the line out of one device be connected to the line input of another. Line inputs are designed to accept voltage levels in the range provided by line outputs. \nImpedances, on the other hand, are deliberately not matched from output to input. \nThe impedance of a line input is typically around . \nWhen driven by a line output's usual low impedance of 100 to 600 ohms, this forms a \"bridging\" connection in which most of the voltage generated by the source (the output) is dropped across the load (the input), and minimal current flows due to the load's relatively high impedance.\n\nAlthough line inputs have a high impedance compared to that of line outputs, \nthey should not be confused with so-called \"Hi-Z\" inputs (Z being the symbol for impedance) which have an impedance of to over . These \"Hi-Z\" or \"instrument\" inputs generally have higher gain than a line input.\nThey are designed to be used with, for example, electric guitar pickups and \"direct injection\" boxes. \nSome of these sources can provide only minimal voltage and current and the high impedance input is designed to not load them excessively.\n\nAcoustic sounds (such as voices or musical instruments) are often recorded with transducers (microphones and pickups) that produce weak electrical signals. These signals must be amplified to line level, where they are more easily manipulated by other devices such as mixing consoles and tape recorders. Such amplification is performed by a device known as a preamplifier or \"preamp\", \nwhich boosts the signal to line level. \nAfter manipulation at line level, signals are then typically sent to a power amplifier, where they are amplified to levels that can drive headphones or loudspeakers. These convert the signals back into sounds that can be heard through the air.\n\nMost phonograph cartridges also have a low output level and require a preamp; typically, a home stereo integrated amplifier or receiver will have a special phono input. This input passes the signal through a phono preamp, which applies RIAA equalization to the signal as well as boosting it to line level.\n\n\n"}
{"id": "45433228", "url": "https://en.wikipedia.org/wiki?curid=45433228", "title": "List of Mexican inventions and discoveries", "text": "List of Mexican inventions and discoveries\n\nMexican inventions and discoveries are objects, processes or techniques invented or discovered, partially or entirely, by a person from Mexico. These also include concepts or practices introduced by Mexican people and their indigenous ancestors. Some of the objects, processes or techniques developed in the Pre-Columbian era were also invented or discovered independently in other cultures. This list shows only inventions and discoveries first introduced in present-day Mexican territory, or those that vary significantly in concept, figure, or use. \n\n\n\n\n"}
{"id": "4080311", "url": "https://en.wikipedia.org/wiki?curid=4080311", "title": "List of PlayStation Portable system software compatibilities", "text": "List of PlayStation Portable system software compatibilities\n\nSony regularly released firmware updates for its PlayStation Portable system, and encouraged PSP owners to upgrade the PSP system software. To increase system software upgrades, Sony encoded their games so that some of them require newer versions of the system software. This is a list of PSP games having such requirements. All system software updates are backwards-compatible; that is, all games that work on system software version 1.5 will work on version 2.0, and so on.\n\n\"Unless otherwise noted, system software requirements for multi-region games are referring to the North American release.\"\n\n\"\"<br>\n\"Ape Escape Academy\"<br>\n\"Archer Maclean's Mercury\"<br>\n\"\"<br>\n\"ATV Offroad Fury: Blazin' Trails\"<br>\n\"\"<br>\n\"\"<br>\n\"\"<br>\n\"Burnout Legends\"<br>\n\"Bust-A-Move Pocket\"<br>\n\"Championship Manager\"<br>\n\"Coded Arms\"<br>\n\"Colin Mcrae Rally 2005\"<br>\n\"Con, The\"<br>\n\"\"<br>\n\"\"<br>\n\"Death, Jr.\"<br>\n\"Dynasty Warriors\"<br>\n\"Everybody's Golf\"<br>\n\"F1 Grand Prix\"<br>\n\"FIFA 06\"<br>\n\"Fired Up\"<br>\n\"Frantix\"<br>\n\"Frogger Helmet Chaos\"<br>\n\"\"<br>\n\"Go! Sudoku\"<br>\n\"Gretzky NHL\"<br>\n\"GripShift\"<br>\n\"\"<br>\n\"Kao Challengers\"<br>\n\"Lemmings\"<br>\n\"Lumines\"<br>\n\"Madden NFL 2006\"<br>\n\"\"<br>\n\"MediEvil Resurrection\"<br>\n\"Metal Gear Acid\"<br>\n\"Midway Arcade Treasures Extended Play\"<br>\n\"Namco Museum Battle Collection\"<br>\n\"NBA Street Showdown\"<br>\n\"\"<br>\n\"\"<br>\n\"Pac-Man World 3\"<br>\n\"\"<br>\n\"Pursuit Force\"<br>\n\"Puzzle Bobble\"<br>\n\"Ridge Racer\"<br>\n\"Smart Bomb\"<br>\n\"Spiderman 2\"<br>\n\"SSX On Tour\"<br>\n\"\"<br>\n\"\"<br>\n\"Tiger Woods PGA Tour\"<br>\n\"TOCA Race Driver 2\"<br>\n\"Tony Hawk's Underground 2 Remix\"<br>\n\"\"<br>\n\"\"<br>\n\"Wipeout Pure\"<br>\n\"World Series of Poker\"<br>\n\"World Tour Soccer\"\n\n\"Crash Tag Team Racing\"<br>\n\"\" (older, unpatched version)<br>\n\"Infected\"<br>\n\"Kingdom of Paradise\"<br>\n\"\"<br>\n\"\"<br>\n\"\"<br>\n\"\"<br>\n\"Tokobot\"<br>\n\"Ultimate Block Party\"<br>\n\n\"EXIT\"<br>\n\"\"<br>\n\"The Sims 2\"\n\n\"Astonishia Story\"<br>\n\"Boku no Natsuyasumi Portable\"<br>\n\"Bust-A-Move Deluxe\"<br>\n\"Capcom Classics Collection: Remixed\"<br>\n\"Daxter\"<br> \n\"Every Extend Extra\" (Japanese version)<br>\n\"Field Commander\"<br>\n\"Gradius Collection\"<br>\n\"\" (newer, patched version)<br>\n\"\"<br>\n\"Key of Heaven\"<br>\n\"Me & My Katamari\"<br>\n\"Mega Man Powered Up\"<br>\n\"Metal Gear Ac!d 2\"<br>\n\"\"<br>\n\"\"<br>\n\"Monster Hunter Freedom\"<br>\n\"MTX Mototrax\"<br>\n\"\"<br>\n\"\"<br>\n\"Street Fighter Alpha 3\"<br>\n\"Super Monkey Ball Adventure\"<br>\n\"\"<br>\n\"\"<br>\n\"\"<br>\n\"\"<br>\n\"\" (Japanese And American Version)\n\n\"\"<br>\n\"Activision Hits Remixed\" (EU 2.81)<br>\n\"\"<br>\n\"Every Extend Extra\"<br>\n\"FIFA 07\"<br>\n\"Gangs of London\"<br>\n\"Gunpey\"<br>\n\"LocoRoco\"<br>\n\"Lumines II\"<br>\n\"\"<br>\n\"Mercury Meltdown\"<br>\n\"NASCAR\"<br>\n\"Tama-Run\"\n\n\"\"<br>\n\"Marvel Ultimate Alliance\"<br>\n\n\"ATV Offroad Fury Pro\"<br>\n\"\"<br>\n\"\"<br>\n\"\"<br>\n\"\"<br>\n\"\"<br>\n\"MotoGP\"<br>\n\"Power Stone Collection\"<br>\n\"Ridge Racer 2\"<br>\n\"\"<br>\n\"\"<br>\n\"Sonic Rivals\"<br>\n\"Tony Hawk's Project 8\"<br>\n\"Yu-Gi-Oh! Duel Monsters GX: Tag Force\"\n\n\"\"<br>\n\"\"<br>\n\"Chotto Shot Edit\" (Japanese PSP Camera software)<br>\n\"Sid Meier's Pirates!\"<br>\n\"\"<br>\n\"\"<br>\n\n\"7 Wonders of the Ancient World\"\n\n\"Crush\"<br>\n\"Cube\"<br>\n\"PQ2\"<br>\n\"Transformers - The Game\"<br>\n\"Ultimate Board Game Collection\"\n\n\"Go!Edit\" <br>\n\"\"<br>\n\"\" <br>\n\"Hot Brain\"\n\n\"Alien Syndrome\"<br>\n\"\"<br>\n\"Xyanide Resurrection\"\n\n\"Anata wo Yurusanai\"<br>\n\"Kaitou Apricot Portable\"<br>\n\"Medal of Honor Heroes 2\"<br>\n\"\"<br>\n\"\"<br>\n\"The Simpsons Game\"\n\n\"\"<br>\n\"Smackdown Vs Raw 2008\"<br>\n\"\"<br>\n\"\"<br>\n\"Silverfall\"\n\n\"Patapon\"<br>\n\"Wipeout Pulse\"<br>\n\"\"<br>\n\"\"<br>\n\"\"<br>\n\"\"<br>\n\"FIFA 09\"<br>\n\"\"<br>\n\"Hot Wheels Ultimate Racing\"\n\n\"\"<br>\n\"Minna no Golf Portable 2\"\n\n\"PlayStation Network Collection - The Power Pack\"<br>\n\"WWE SmackDown vs. Raw 2009\"\n\n\"Gripshift\" <br>\n\"Final Fantasy VII International (PS1 version via PSN Japan)\" <br>\n\"Final Fantasy Dissidia\" but needs patching\nBuzz!:Master Quiz\n\n\"Disney Up\" <br>\n\"Petz My Puppy Family\" <br>\n\n\"\" - (EUR) needs patch <br>\n\"Madden NFL 10\" <br>\n\"\" - (EUR) needs patch\n\"fifa 10\"\n\n\"Tales Of Vs.\"<br>\n\"\"<br> \n\"Armored Core 3 Portable\"<br>\n\"\" <br>\n\"\"<br>\n\"\"<br>\n\"Cloudy with a Chance of Meatballs\"<br>\n\"\"<br>\n\"\"<br>\n\"Marvel Ultimate Alliance 2\"<br>\n\"\" <br>\n\" (5.51)\"<br> \n\"Beaterator\"<br>\n\"\" - (EUR)<br>\n\"Shin Megami Tensei Persona\"<br>\n\"Gran Turismo\" <br>\n\"FIFA 10\" <br>\n\"\" <br>\n\"WWE Smackdown vs Raw 2010\n\n<br>\"LittleBigPlanet\"\n<br>\"Pro Evolution Soccer 2010\"\n<br>\"Gran Turismo\"\n<br>\"Assassin's Creed Bloodlines\"\n\n\"Tekken 6\"\n<br>\"NBA LIVE 10\"\n<br>\"Manhunt 2\"\n<br>\"Street Fighter Alpha 3 Max\"\n<br>\"\"\n<br>\"\"\n<br>\"LocoRoco Midnight Carnival\"\n<br>\"NBA 2K10\"\n<br>\"Mega Man Maverick Hunter X\"\n\n<br>\"God Eater\"\n<br>\"Naruto Ultimate Ninja Heroes 3\"\n<br>\"\"\n<br>\"\"\n<br>\"Hexyz Force\"\n<br>\"Dante's Inferno\"\n<br>\"ModNation Racers\"\n<br>\"Pinball Heroes Bundle 2\"\n<br>\"\"\n<br>\"Metal Slug XX\"\n<br>\"Disgaea Infinite\"\n<br>\"\"\n<br>\"Midway Arcade Treasures Extended Play\"\n<br>\"\"\n<br>\"Bejeweled 2 PSP\"\n<br>\"\"\n<br>\"Despicable Me\"\n<br>\"Groovin’ Blocks PSP\"\n<br>\"\"\n<br>\"Gravity Crash Portable\"\n<br>\"Piyotama PSP\"\n<br>\"\"\n\n\"Warriors Of The Lost Empire\"\n<br>\"Madden NFL 11 PSP\"\n<br>\"YS Seven\"\n<br>\"Zuma PSP\"\n<br>\"Valkyria Chronicles 2\"\n<br>\"Ace Combat Joint Assault\"\n<br>\"Hannspree Ten Kate Honda SBK Superbike World Championship\"\n<br>\"Phantasy Star Portable 2\"\n<br>\"UFC Undisputed 2010\"\n<br>\"Cabela’s North American Adventures\"\n<br>\"Gladiator Begins\"\n<br>\"\"\n<br>\"101-in-1 Megamix\"\n<br>\"Rapala Pro Bass Fishing\"\n<br>\"\"\n<br>\"NBA 2k11\"\n<br>\"FIFA Soccer 11\"\n<br>\"DJ Max Portable 3\"\n<br>\"Blazing Souls Accelate\"\n<br>\"\"\n<br>\"Z.H.P. Unlosing Ranger VS Darkdeath Evilman\"\n<br>\"WWE SmackDown vs. Raw 2011\"\n<br>\"\"\n<br>\"\"\n<br>\"No Heroes Allowed!\"\n<br>\"Knights in the Nightmare\"\n<br>\"\"\n<br>\"Pro Evolution Soccer 2011 (Winning Eleven 2011)\"\n<br>\"Tom Clancy's Ghost Recon Predator\"\n<br>\"Peggle PSP\"\n<br>\"\"\n<br>\"Bomberman\"\n\n<br>\"Football Manager Handheld 2011\"\n<br>\"\"\n<br>\"\"\n<br>\"Michael Jackson The Experience\"\n<br>\"\"\n<br>\"\"\n<br>\"Auditorium\"\n<br>\"Hot Shots Shorties (Blue,Red,Green,Yellow)\"\n\n\"Lord of Arcana\"\n<br>\"\"\n<br>\"Patapon 3\"\n<br>\"The 3rd Birthday\"\n\n"}
{"id": "46455143", "url": "https://en.wikipedia.org/wiki?curid=46455143", "title": "List of oil refineries in India", "text": "List of oil refineries in India\n\nThe following is a list of oil refineries in India, per the Petroleum Planning and Analysis Cell of the Ministry of Petroleum and Natural Gas, Government of India, arranged in decreasing order of their capacity.\n\n2.http://petroleum.nic.in/refining/about-refining\n"}
{"id": "49811066", "url": "https://en.wikipedia.org/wiki?curid=49811066", "title": "MaxMyInterest", "text": "MaxMyInterest\n\nMaxMyInterest (Max) is a financial technology (FinTech) service operated by Six Trees Capital LLC. Max is a software platform that allocates individuals’ cash among their own bank accounts so that they earn the most interest possible while staying within the limits for FDIC government-deposit insurance. The service works for both individuals and their financial advisors. Headquartered in New York City, Six Trees was founded by former Citigroup investment banker Gary E. Zimmerman in 2013.\n\nThe Max service launched in April 2014.\n\nIn the spring of 2015, Max participated in the FinTech Innovation Lab, an accelerator program run by the Partnership Fund for New York City and Accenture, and presented at the Lab’s Demo Day in June.\n\nIn October 2015, Max began offering services to businesses that want to earn more on FDIC-insured cash, through a partnership with The American Deposit Management Co. of Delafield, Wisc.\n\nMax won a UBS Future of Finance Acceleration Award in December 2015.\n\nThe Max Advisor Dashboard, which allows financial advisors to oversee their clients’ Max accounts on their behalf, launched in January 2016.\n\n"}
{"id": "10433019", "url": "https://en.wikipedia.org/wiki?curid=10433019", "title": "Micro-Opto-Electro-Mechanical Systems", "text": "Micro-Opto-Electro-Mechanical Systems\n\nMicro-Opto-Electro-Mechanical Systems (MOEMS) are not a special class of Micro-Electro-Mechanical Systems (MEMS) but rather the combination of MEMS merged with Micro-optics; this involves sensing or manipulating optical signals on a very small size scale using integrated mechanical, optical, and electrical systems. MOEMS includes a wide variety of devices including optical switch, optical cross-connect, tunable VCSEL, microbolometers amongst others. These devices are usually fabricated using micro-optics and standard micromachining technologies using materials like silicon, silicon dioxide, silicon nitride and gallium arsenide.\n\nMOEMS includes two major technologies, MEMS and Micro-optics. Both these two technologies independently involve in batch processing similar to integrated circuits, and micromachining similar to fabrication of microsensor.\n\nMEMS offers inherently device miniaturization and wide applications in sensors and actuators, robotics, accelerometers, microvalves, flow controllers, global positioning systems (GPS) component miniaturization; and a host of other sensors and actuators for applications to space, air, land, and sea vehicles, as well as industrial, biotechnology, and consumer electronics\n\nDuring the 1980s the acronym of MEMS created a fortune for publication, getting government contracts and publicity. DARPA assigned a program manager for this field and significantly soon MEMS is promoted to be the king of the technology. Several high tech journals that were originated were attached to MEMS by supporting miniaturization and low cost manufacturing. Many private companies which did not have sufficient knowledge about MEMS also started jumping on the bandwagon.\n\nParallel with MEMS developments and even earlier, sensor technology advanced to microsensors and joining with microactuators. Development of microsensors and microactuators were also due to a mother technology of micromachining. Micromachining is the root of everything we have today in high technology. This technology was never credited in history as it deserved. It was commercially used during the 1960s in Switzerland, for micromachining quartz orders of magnitudes harder than micromachining silicon. MEMS acronym was so powerful during the 1980s, that with no choice microsensors and microactuators that included micromachining, all joined MEMS by a soft landing. As a result, the MEMS acronym was more attractive for publicity and even today MEMS, is dominating in microtechnologies without giving credit to its real parents.\n\nDuring the MEMS era, and before that time frame, Rockwell International was involved in commercial MEMS development under government contracts. During early 1980s Rockwell successfully built the first CMOS MEMS high performance and high G accelerometer chip for space applications. The wafer was processed inside Rockwell VLSI lab in Anaheim, CA. This was a breakthrough in MEMS technology, but it did not appear in literature until 1988.\n\nDuring the early 1990s, Rockwell Science Center, through internal research and commercial programs with government sponsors, contributed to the development of micro-optics technology Teamed with MIT/Lincoln-Lab. During 1992, Rockwell applied micro-optics to the system development of several industrial applications, including, microlenses for silicon focal planes, high speed binary microlens in GaAs, antireflection surfaces in silicon, thin film microlens arrays, beam steering device, microlens integration with focal plane arrays, and optical transformer and collimator. Rockwell Science Center also developed refractive microlens technology, including gray scale photolithography. Diffractive microlenses based on binary optic structures are typically fabricated in bulk material by multiple sequential layers of photoresist patterning and reactive ion etching (RIE), to form a multi-step phase profile. This profile approximates the ideal kinoform lens surface. A special staircase process, called binary optics, is used to fabricate diffractive components.\n\nWith so many successes in Micro-optics and MEMS, Rockwell researchers who were involved in both MEMS and Micro-optics, initiate development of several of innovative photonics ideas combining both technologies. This was behind the acronym of MOEMS, when both MEMS and Micro-optics were merged in one single IC processing lab.\n\nMOEMS is a promising multi technology for miniaturization of critical optical systems. The acronym is defined of three high tech fields of micro-optics, micromechanics, and microelectronics. MOEMS indirectly could merge in micromachining, microsensors and microactuators if their processes are compatible with integrated circuits.\n\nMerging all these multi technologies, made MOEMS an ideal knowhow for many industrial demonstrations of commercial devices, such as optical switches, digital micromirror devices or DMD (see DLP), bistable mirrors, laser scanners, optical shutters, and dynamic micromirror displays. All technologies of MOEMS have the potential of batch processing and embossed replication which, again, makes them highly attractive and necessary for commercial applications. MOEMS is an enabling technology for applications that cannot be addressed, using micro-optics alone and is currently playing a significant role in numerous optical applications. The trend toward miniaturization and integration of conventional optical systems will accelerate the adoption of MOEMS technology in commercialization of many industrial components which are today’s most desirable elements of optical communication.\n\nDuring 1991-1993, Dr. M. Edward Motamedi, a former Rockwell International innovator in the areas of both Micro-Electro-Mechanical Systems (MEMS) and Micro-optics, used internally the acronym of MOEMS for Micro-Opto-Electro-Mechanical Systems. This was to distinguish between Optical MEMS and MOEMS, where Optical MEMS could include bulk optics but MOEMS is truly based on microtechnology where MOEMS devices are batched processed exactly like integrated circuits, but this is not true in most cases for Optical MEMS.\n\nIn 1993, Dr. Motamedi officially introduced MOEMS for the first time, as the powerful combination of MEMS and Micro-optics, in an invited talk at the SPIE Critical Reviews of Optical Science and Technology conference in San Diego. In this talk Dr. Motamedi introduced the figure below, for showing that MOEMS is the interaction of three major microtechnologies; namely Micro-optics, Micromechanics, and Microelectronics.\n\n\n\n"}
{"id": "42691862", "url": "https://en.wikipedia.org/wiki?curid=42691862", "title": "Microwave imaging", "text": "Microwave imaging\n\nMicrowave imaging is a science which has been evolved from older detecting/locating techniques (e.g., radar) in order to evaluate hidden or embedded objects in a structure (or media)using electromagnetic (EM) waves in microwave regime (i.e., ~300 MHz-300 GHz). Engineering and application oriented microwave imaging for non-destructive testing is called microwave testing, see below. \n\nMicrowave imaging techniques can be classified as either quantitative or qualitative. Quantitative imaging techniques (are also known as inverse scattering methods) give the electrical (i.e., electrical and magnetic property distribution) and geometrical parameters (i.e., shape, size and location) of an imaged object by solving a nonlinear inverse problem. The nonlinear inverse problem is converted into a linear inverse problem (i.e., Ax=b where A and b are known and x (or image) is unknown) by using Born or distorted Born approximations. Despite the fact that direct matrix inversion methods can be invoked to solve the inversion problem, this will be so costly when the size of the problem is so big (i.e., when A is a very dense and big matrix). To overcome this problem, direct inversion is replaced with iterative solvers. Techniques in this class are called forward iterative methods which are usually time consuming.\nOn the other hand, qualitative microwave imaging methods calculate a qualitative profile (which is called as reflectivity function or qualitative image) to represent the hidden object. These techniques use approximations to simplify the imaging problem and then they use back-propagation (also called time reversal, phase compensation, or back-migration) to reconstruct the unknown image profile. Synthetic aperture radar (SAR), ground-penetrating radar (GPR), and frequency-wave number migration algorithm are some of the most popular qualitative microwave imaging methods.\n\nIn general, a microwave imaging system is made up of hardware and software components. The hardware collects data from the sample under test. A transmitting antenna sends EM waves towards the sample under test (e.g., human body for medical imaging). If the sample is made of only homogeneous material and is of infinite size, theoretically no EM wave will be reflected. Introduction of any anomaly which has different properties (i.e., electrical/magnetic) in comparison with the surrounding homogeneous medium may reflect a portion of the EM wave. The bigger the difference between the properties of the anomaly and the surrounding medium is, the stronger the reflected wave will be. This reflection is collected by the same antenna in a monostatic system, or a different receiver antenna in bistatic configurations.\n\nTo increase the cross-range resolution of the imaging system, several antennas should be distributed over an area (which is called the sampling area) with a spacing less than the operating wavelength. However, the mutual coupling between the antennas, which are placed close to each other, may degrade the accuracy of the collected signals. Moreover, the transmitter and receiver system will become very complex. To address these problems, one single scanning antenna is used instead of several antennas. In this configuration, the antenna scans over the entire sampling area, and the collected data is mapped together with their antenna position coordinates. In fact, a synthetic (virtual) aperture is produced by moving the antenna (similar to the synthetic aperture radar principle). \nLater, the collected data, which is sometimes referred to as raw data, is fed into the software for processing. Depending on the applied processing algorithm, microwave imaging techniques can be categorized as quantitative and qualitative.\n\nMicrowave imaging has been used in a variety of applications such as: nondestructive testing and evaluation (NDT&E, see below), medical imaging, concealed weapon detection at security check points, structural health monitoring, and through-the-wall imaging.\n\nMicrowave imaging for medical applications is also becoming of more interest. The dielectric properties of malignant tissue change significantly in comparison with the properties of normal tissue (e.g., breast tissue). This difference translates into a contrast which can be detected by microwave imaging methods. As one example, there are several research groups all around the world working on developing efficient microwave imaging techniques for early detection of breast cancer. \n\nAgeing of infrastructure is becoming a serious problem worldwide. For example, in reinforced concrete structures, corrosion of their steel reinforcements is the main cause of their deterioration. In U.S. alone, repair and maintenance cost due to such corrosion is about $276 billion per year, .\n\nRecently, microwave imaging has shown great potential to be used for structural health monitoring. Lower frequency microwaves (e.g., <10 GHz) can easily penetrate through concrete and reach objects of interest such as reinforcement bars (rebars). If there is any rust on the rebar, since rust reflects less EM waves in comparison with sound metal, the microwave imaging method can distinguish between rebars with and without rust (or corrosion). Microwave imaging also can be used to detect any embedded anomaly inside concrete (e.g., crack or air void).\n\nThese applications of microwave imaging are part of non-destructuve (NDT) testing in civil engineering. More on microwave imaging in NDT is described in the following.\n\nMicrowave testing uses the scientific basics of microwave imaging for the inspection of technical parts with harmless microwaves. Microwave testing is one of the methods of non-destructive testing (NDT). It is restricted to tests of dielectric, i. e. non-conducting material. It can be used to inspect components also in a built-in state, e. g. built-in non-visible gaskets in plastic valves.\n\nThe microwave frequencies extend from 300 MHz to 300 GHz corresponding to wavelengths between 1 m and 1 mm. The section from 30 GHz to 300 GHz with wavelengths between 10 mm and 1 mm is also called millimeter waves. Microwaves are in the order of the size of the components to be tested. In different dielectric media they propagate differently fast and at surfaces between them they are reflected. Another part propagates beyond the surface. The larger the difference in the wave impedance, the larger is the reflected part.\n\nIn order to find material defects, a test probe, attached or in a small distance, is moved over the surface of the device under test. This can be done manually or automatically. The test probe transmits and receives microwaves.\n\nChanges of the dielectric properties at surfaces (e. g. shrinkage cavities, pores, foreign material inclusion, or cracks) within the interior of the device under test reflect the incident microwave and send a part of it back to the test probe, which acts as a transmitter and as a receiver.\n\nThe electronic data evaluation leads to a display of the results, e. g. as a B-scan (cross sectional view) or as a C-scan (top view). These display methods are adopted from ultrasonic testing. \nBesides the reflection method also the through transmission method is possible, in which separate transmit and receive antennas are used. The backside of the device under test (DUT) must be accessible and the method gives no information about the depth of a defect within the DUT.\n\nMicrowave tests are possible with constant frequency (CW) or with continuously tuned frequency (FMCW). FMCW is advantageous to determine the depth of defects within the DUT.\n\nA test probe attached to the DUT's surface gives information about the material distribution below the point of contact. When moving over the DUT surface point by point many such information is stored and then evaluated to give an overall image. This takes time. Directly imaging procedures are faster: Microwave versions are either electronic or make use of planar microwave detector consisting of a microwave absorbing foil and an infrared camera (NIDIT procedure).\nMicrowave testing is a useful NDT method for dielectric materials. Among them are plastics, glass-fiber reinforced plastics (GFRP), plastic foams, wood, wood-plastic composites (WPC), and most types of ceramics. Defects interior in the DUT and at its surface can be detected, e. g. in semi-finished products or pipes.\n\n\"Special applications\" of microwave testing are non-destructive\nMicrowave testing is used in many industrial sectors:\nIn the last years the need for NDT has increased generally and especially also for dielectric materials. For this reason and because microwave technics more and more are used in consumer products and hereby became much less expensive, NDT with microwaves increases. In recognizing this growing importance, in 2011 the \"Expert committee for microwave and THz procedures\" of the German Society of Non-Destructive Testing (DGZfP) was founded as in 2014 the \"Microwave Testing Committee\" of the American Society for Non-Destructive Testing (ASNT). Standardization work is at the beginning.\n\n\n"}
{"id": "29588427", "url": "https://en.wikipedia.org/wiki?curid=29588427", "title": "Mikroelektronika", "text": "Mikroelektronika\n\nMikroElektronika (stylized as MikroE) is a Serbian manufacturer and retailer of hardware and software tools for developing embedded systems. The company headquarters is in Belgrade, Serbia.\n\nIts best known software products are mikroC, mikroBasic and mikroPascal compilers for programming microcontrollers. Its flagship hardware product line is Click boards, a range of more than 550 add-on boards for interfacing microcontrollers with peripheral sensors or transceivers. These boards conform to mikroBUS – a standard conceived by MikroElektronika and later endorsed by NXP Semiconductors and Microchip Technology, among others. MikroElektronika is also known for Hexiwear, an Internet of Things development kit developed in partnership with NXP Semiconductors.\n\nSerbian entrepreneur — and current company owner and CEO — Nebojša Matić started publishing an electronics magazine called \"MikroElektronika\" in 1997. In 2001, the magazine was shut down and MikroElektronika repositioned itself as a company focused on producing development boards for microcontrollers and publishing books for developing embedded systems.\n\nThe company started offering compilers in 2004, with the release of mikroPascal for PIC and mikroBasic for PIC — compilers for programming 8-bit microcontrollers from Microchip Technology. Between 2004 and 2015 the company released C, Basic and Pascal compilers for seven microcontroller architectures: PIC, PIC32, dsPIC/PIC24, FT90x, AVR, 8051, and ARM® (supporting STMicroelectronics, Texas Instruments and Mircochip-based ARM® Cortex microcontrollers).\n\nIn conjunction with compilers, MikroElektronika kept its focus on producing development boards while gradually ceasing its publishing activities. Its current generation of the \"Easy\" boards brand was released in 2012. One of the flagship models, EasyPIC Fusion v7 was nominated for best tool at the Embedded World 2013 exhibition in Nurembeg, an important embedded systems industry gathering. Other product lines were introduced as well, including the \"mikroProg\" line of hardware programmers and debuggers, and the range of sensor and transceiver add-on boards known as click boards.\n\nDuring this time span the company developed relationships with various semiconductor vendors and distributors. It became an official partner of Microchip Technology, NXP Semiconductors, Texas Instruments, STMicroelectronics, Imagination Technologies, Telit, Quectel, and U-blox. MikroElektronika also built up its worldwide distributor network by partnering with Digi-Key, Mouser Electronics, Future Electronics, RS Components as well as more than 50 local distributors in all continents.\n\nResponding to rising public interest in the Internet of things, in 2016 MikroElektronika released Hexiwear, a wearable development kit created in partnership with NXP Semiconductors. Hexiwear was funded through Kickstarter. Since its release on the market, it won four industry awards: Best in Show, Reader's choice, and Best IoT product at ARM TechCon 2016 Innovation Challenge, 2016 ECN Impact award, as well as Best for Rapid prototyping at the Hackster Maker Madness competition.\n\nMikroElektronika's catalog comprises more than 500 products. The following table lists its main product lines.\n"}
{"id": "1145887", "url": "https://en.wikipedia.org/wiki?curid=1145887", "title": "Mobile telephony", "text": "Mobile telephony\n\nMobile telephony is the provision of telephone services to phones which may move around freely rather than stay fixed in one location. Mobile phones connect to a terrestrial cellular network of base stations (cell sites), whereas satellite phones connect to orbiting satellites. Both networks are interconnected to the public switched telephone network (PSTN) to allow any phone in the world to be dialed.\n\nIn 2010 there were estimated to be five billion mobile cellular subscriptions in the world.\n\nAccording to internal memos, American Telephone & Telegraph discussed developing a wireless phone in 1915, but were afraid that deployment of the technology could undermine its monopoly on wired service in the U.S.\n\nPublic mobile phone systems were first introduced in the years after the Second World War and made use of technology developed before and during the conflict. The first system opened in St Louis, Missouri, USA in 1946 whilst other countries followed in the succeeding decades. The UK introduced its 'System 1' manual radiotelephone service as the South Lancashire Radiophone Service in 1958. Calls were made via an operator using handsets identical to ordinary phone handsets. The phone itself was a large box located in the boot (trunk) of the vehicle containing valves and other early electronic components. Although an uprated manual service ('System 3') was extended to cover most of the UK, automation did not arrive until 1981 with 'System 4'. Although this non-cellular service, based on German B-Netz technology, was expanded rapidly throughout the UK between 1982 and 1985 and continued in operation for several years before finally closing in Scotland, it was overtaken by the introduction in January 1985 of two cellular systems - the British Telecom/Securicor 'Cellnet' service and the Racal/Millicom/Barclays 'Vodafone' (from voice + data + phone) service. These cellular systems were based on US Advanced Mobile Phone Service (AMPS) technology, the modified technology being named Total Access Communication System (TACS).\n\nIn 1947 Bell Labs was the first to propose a cellular radio telephone network. The primary innovation was the development of a network of small overlapping cell sites supported by a call switching infrastructure that tracks users as they move through a network and passes their calls from one site to another without dropping the connection. In 1956 the MTA system was launched in Sweden. The early efforts to develop mobile telephony faced two significant challenges: allowing a great number of callers to use the comparatively few available frequencies simultaneously and allowing users to seamlessly move from one area to another without having their calls dropped. Both problems were solved by Bell Labs employee Amos Joel who, in 1970 applied for a patent for a mobile communications system. However, a business consulting firm calculated the entire U.S. market for mobile telephones at 100,000 units and the entire worldwide market at no more than 200,000 units based on the ready availability of pay telephones and the high cost of constructing cell towers. As a consequence, Bell Labs concluded that the invention was \"of little or no consequence,\" leading it not to attempt to commercialize the invention. The invention earned Joel induction into the National Inventors Hall of Fame in 2008. The first call on a handheld mobile phone was made on April 3, 1973 by Martin Cooper, then of Motorola to his opposite number in Bell Labs who were also racing to be first. Bell Labs went on to install the first trial cellular network in Chicago in 1978. This trial system was licensed by the FCC to ATT for commercial use in 1982 and, as part of the divestiture arrangements for the breakup of ATT, the AMPS technology was distributed to local telcos. The first commercial system opened in Chicago in October 1983. A system designed by Motorola also operated in the Washington D.C./Baltimore area from summer 1982 and became a full public service later the following year. Japan's first commercial radiotelephony service was launched by NTT in 1978.\n\nThe first fully automatic first generation cellular system was the Nordic Mobile Telephone (NMT) system, simultaneously launched in 1981 in Denmark, Finland, Norway and Sweden. NMT was the first mobile phone network featuring international roaming. The Swedish electrical engineer Östen Mäkitalo started to work on this vision in 1966, and is considered as the father of the NMT system and some consider him also the father of the cellular phone.\n\nThe advent of cellular technology encouraged European countries to co-operate in the development of a pan-European cellular technology to rival those of the US and Japan. This resulted in the GSM system, the initials originally from the Groupe Spécial Mobile that was charged with the specification and development tasks but latterly as the 'Global System for Mobile Communications'. The GSM standard eventually spread outside Europe and is now the most widely used cellular technology in the world and the de facto standard. The industry association, the GSMA, now represents 219 countries and nearly 800 mobile network operators. There are now estimated to be over 5 billion phone subscriptions according to the \"List of countries by number of mobile phones in use\" (although some users have multiple subscriptions, or inactive subscriptions), which also makes the mobile phone the most widely spread technology and the most common electronic device in the world.\n\nThe first mobile phone to enable internet connectivity and wireless email, the Nokia Communicator, was released in 1996, creating a new category of multi-use devices called smartphones. In 1999 the first mobile internet service was launched by NTT DoCoMo in Japan under the i-Mode service. By 2007 over 798 million people around the world accessed the internet or equivalent mobile internet services such as WAP and i-Mode at least occasionally using a mobile phone rather than a personal computer.\n\nMobile phones receive and send radio signals with any number of cell site base stations fitted with microwave antennas. These sites are usually mounted on a tower, pole or building, located throughout populated areas, then connected to a cabled communication network and switching system. The phones have a low-power transceiver that transmits voice and data to the nearest cell sites, normally not more than 8 to 13 km (approximately 5 to 8 miles) away. In areas of low coverage, a cellular repeater may be used, which uses a long distance high-gain dish antenna or yagi antenna to communicate with a cell tower far outside of normal range, and a repeater to rebroadcast on a small short-range local antenna that allows any cellphone within a few meters to function properly.\n\nWhen the mobile phone or data device is turned on, it registers with the mobile telephone exchange, or switch, with its unique identifiers, and can then be alerted by the mobile switch when there is an incoming telephone call. The handset constantly listens for the strongest signal being received from the surrounding base stations, and is able to switch seamlessly between sites. As the user moves around the network, the \"handoffs\" are performed to allow the device to switch sites without interrupting the call.\n\nCell sites have relatively low-power (often only one or two watts) radio transmitters which broadcast their presence and relay communications between the mobile handsets and the switch. The switch in turn connects the call to another subscriber of the same wireless service provider or to the public telephone network, which includes the networks of other wireless carriers. Many of these sites are camouflaged to blend with existing environments, particularly in scenic areas.\n\nThe dialogue between the handset and the cell site is a stream of digital data that includes digitised audio (except for the first generation analog networks). The technology that achieves this depends on the system which the mobile phone operator has adopted. The technologies are grouped by generation. The first-generation systems started in 1979 with Japan, are all analog and include AMPS and NMT. Second-generation systems, started in 1991 in Finland, are all digital and include GSM, CDMA and TDMA.\n\nThe nature of cellular technology renders many phones vulnerable to 'cloning': anytime a cell phone moves out of coverage (for example, in a road tunnel), when the signal is re-established, the phone sends out a 're-connect' signal to the nearest cell-tower, identifying itself and signalling that it is again ready to transmit. With the proper equipment, it's possible to intercept the re-connect signal and encode the data it contains into a 'blank' phone—in all respects, the 'blank' is then an exact duplicate of the real phone and any calls made on the 'clone' will be charged to the original account. This problem was widespread with the first generation analogue technology, however the modern digital standards such as GSM greatly improve security and make cloning hard to achieve.\n\nIn an effort to limit the potential harm from having a transmitter close to the user's body, the first fixed/mobile cellular phones that had a separate transmitter, vehicle-mounted antenna, and handset (known as \"car phones\" and \"bag phones\") were limited to a maximum 3 watts Effective Radiated Power. Modern \"handheld\" cellphones which must have the transmission antenna held inches from the user's skull are limited to a maximum transmission power of 0.6 watts ERP. Regardless of the potential biological effects, the reduced transmission range of modern handheld phones limits their usefulness in rural locations as compared to car/bag phones, and handhelds require that cell towers are spaced much closer together to compensate for their lack of transmission power.\n\nAn increasing number of countries, particularly in Europe, now have more mobile phones than people. According to the figures from Eurostat, the European Union's in-house statistical office, Luxembourg had the highest mobile phone penetration rate at 158 mobile subscriptions per 100 people, closely followed by Lithuania and Italy. In Hong Kong the penetration rate reached 139.8% of the population in July 2007. Over 50 countries have mobile phone subscription penetration rates higher than that of the population and the Western European average penetration rate was 110% in 2007 (source Informa 2007). Canada currently has the lowest rates of mobile phone penetrations in the industrialised world at 58%.\n\nThere are over five hundred million active mobile phone accounts in China, as of 2007, but the total penetration rate there still stands below 50%. The total number of mobile phone subscribers in the world was estimated at 2.14 billion in 2005. The subscriber count reached 2.7 billion by end of 2006 according to Information, and 3.3 billion by November, 2007, thus reaching an equivalent of over half the planet's population. Around 80% of the world's population has access to mobile phone coverage, as of 2006. This figure is expected to increase to 90% by the year 2010.\n\nIn some developing countries with little \"landline\" telephone infrastructure, mobile phone use has quadrupled in the last decade. The rise of mobile phone technology in developing countries is often cited as an example of the leapfrog effect. Many remote regions in the third world went from having no telecommunications infrastructure to having satellite based communications systems. At present, Africa has the largest growth rate of cellular subscribers in the world, its markets expanding nearly twice as fast as Asian markets.\nThe availability of prepaid or 'pay-as-you-go' services, where the subscriber is not committed to a long term contract, has helped fuel this growth in Africa as well as in other continents.\n\nOn a numerical basis, India is the largest growth market, adding about 6 million mobile phones every month. It currently has a mobile subscriber base of 937.06 million mobile phones.\n\nSince the world is operating quickly to 3G and 4G networks, mobile traffic through video is heading high. It is expected that by end of 2018, the global traffic will reach an annual rate of 190 exabytes/year. This is the result of people shifting to smartphones.\nIt is predicted by 2018, mobile traffic will reach by 10 billion connections with 94% traffic comes from Smartphones, laptops and tablets. Also 69% of mobile traffic from Videos since we have high definition screens available in smart phones and 176.9 wearable devices to be at use. Apparently, 4G will be dominating the traffic by 51% of total mobile data by 2018.\n\nLaw enforcement have used mobile phone evidence in a number of different ways. Evidence about the physical location of an individual at a given time can be obtained by triangulating the individual's cellphone between several cellphone towers. This triangulation technique can be used to show that an individual's cellphone was at a certain location at a certain time. The concerns over terrorism and terrorist use of technology prompted an inquiry by the British House of Commons Home Affairs Select Committee into the use of evidence from mobile phone devices, prompting leading mobile telephone forensic specialists to identify forensic techniques available in this area. NIST have published guidelines and procedures for the preservation, acquisition, examination, analysis, and reporting of digital information present on mobile phones can be found under the NIST Publication SP800-101.\n\nIn the UK in 2000 it was claimed that recordings of mobile phone conversations made on the day of the Omagh bombing were crucial to the police investigation. In particular, calls made on two mobile phones which were tracked from south of the Irish border to Omagh and back on the day of the bombing, were considered of vital importance.\n\nFurther example of criminal investigations using mobile phones is the initial location and ultimate identification of the terrorists of the 2004 Madrid train bombings. In the attacks, mobile phones had been used to detonate the bombs. However, one of the bombs failed to detonate, and the SIM card in the corresponding mobile phone gave the first serious lead about the terrorists to investigators. By tracking the whereabouts of the SIM card and correlating other mobile phones that had been registered in those areas, police were able to locate the terrorists.\n\nThe Finnish government decided in 2005 that the fastest way to warn citizens of disasters was the mobile phone network. In Japan, mobile phone companies provide immediate notification of earthquakes and other natural disasters to their customers free of charge. In the event of an emergency, disaster response crews can locate trapped or injured people using the signals from their mobile phones. An interactive menu accessible through the phone's Internet browser notifies the company if the user is safe or in distress. In Finland rescue services suggest hikers carry mobile phones in case of emergency even when deep in the forests beyond cellular coverage, as the radio signal of a cellphone attempting to connect to a base station can be detected by overflying rescue aircraft with special detection gear. Also, users in the United States can sign up through their provider for free text messages when an AMBER Alert goes out for a missing person in their area.\n\nHowever, most mobile phone networks operate close to capacity during normal times, and spikes in call volumes caused by widespread emergencies often overload the system just when it is needed the most. Examples reported in the media where this has occurred include the September 11, 2001 attacks, the 2003 Northeast blackouts, the 2005 London Tube bombings, Hurricane Katrina, the 2006 Kiholo Bay earthquake, and the 2007 Minnesota bridge collapse.\n\nUnder FCC regulations, all mobile telephones must be capable of dialing emergency telephone numbers, regardless of the presence of a SIM card or the payment status of the account.\n\nSince the introduction of mobile phones, concerns (both scientific and public) have been raised about the potential health impacts from regular use. But by 2008, American mobile phones transmitted and received more text messages than phone calls. Numerous studies have reported no significant relationship between mobile phone use and health, but the effect of mobile phone usage on health continues to be an area of public concern.\n\nFor example, at the request of some of their customers, Verizon created usage controls that meter service and can switch phones off, so that children could get some sleep. There have also been attempts to limit use by persons operating moving trains or automobiles, coaches when writing to potential players on their teams, and movie theater audiences. By one measure, nearly 40% of automobile drivers aged 16 to 30 years old text while driving, and by another, 40% of teenagers said they could text blindfolded.\n\n18 studies have been conducted on the link between cell phones and brain cancer; A review of these studies found that cell phone use of 10 years or more \"give a consistent pattern of an increased risk for acoustic neuroma and glioma\". The tumors are found mostly on the side of the head that the mobile phone is in contact with. In July 2008, Dr. Ronald Herberman, director of the University of Pittsburgh Cancer Institute, warned about the radiation from mobile phones. He stated that there was no definitive proof of the link between mobile phones and brain tumors but there was enough studies that mobile phone usage should be reduced as a precaution. To reduce the amount of radiation being absorbed hands free devices can be used or texting could supplement calls. Calls could also be shortened or limit mobile phone usage in rural areas. Radiation is found to be higher in areas that are located away from mobile phone towers.\n\nAccording to Reuters, The British Association of Dermatologists is warning of a rash occurring on people’s ears or cheeks caused by an allergic reaction from the nickel surface commonly found on mobile devices’ exteriors. There is also a theory it could even occur on the fingers if someone spends a lot of time text messaging on metal menu buttons. In 2008, Lionel Bercovitch of Brown University in Providence, Rhode Island, and his colleagues tested 22 popular handsets from eight different manufacturers and found nickel on 10 of the devices.\n\nBetween the 1980s and the 2000s, the mobile phone has gone from being an expensive item used by the business elite to a pervasive, personal communications tool for the general population. In most countries, mobile phones outnumber land-line phones, with fixed landlines numbering 1.3 billion but mobile subscriptions 3.3 billion at the end of 2007.\n\nIn many markets from Japan and South Korea, to Europe, to Malaysia, Singapore, Taiwan and Hong Kong, most children age 8-9 have mobile phones and the new accounts are now opened for customers aged 6 and 7. Where mostly parents tend to give hand-me-down used phones to their youngest children, in Japan already new cameraphones are on the market whose target age group is under 10 years of age, introduced by KDDI in February 2007. The USA also lags on this measure, as in the US so far, about half of all children have mobile phones. In many young adults' households it has supplanted the land-line phone. Mobile phone usage is banned in some countries, such as North Korea and restricted in some other countries such as Burma.\n\nGiven the high levels of societal mobile phone service penetration, it is a key means for people to communicate with each other. The SMS feature spawned the \"texting\" sub-culture amongst younger users. In December 1993, the first person-to-person SMS text message was transmitted in Finland. Currently, texting is the most widely used data service; 1.8 billion users generated $80 billion of revenue in 2006 (source ITU). Many phones offer Instant Messenger services for simple, easy texting. Mobile phones have Internet service (e.g. NTT DoCoMo's i-mode), offering text messaging via e-mail in Japan, South Korea, China, and India. Most mobile internet access is much different from computer access, featuring alerts, weather data, e-mail, search engines, instant messages, and game and music downloading; most mobile internet access is hurried and short.\n\nBecause mobile phones are often used publicly, social norms have been shown to play a major role in the usage of mobile phones. Furthermore, the mobile phone can be a fashion totem custom-decorated to reflect the owner's personality and may be a part of their self-identity. This aspect of the mobile telephony business is, in itself, an industry, e.g. ringtone sales amounted to $3.5 billion in 2005.\nMobile phone use on aircraft is starting to be allowed with several airlines already offering the ability to use phones during flights. Mobile phone use during flights used to be prohibited and many airlines still claim in their in-plane announcements that this prohibition is due to possible interference with aircraft radio communications. Shut-off mobile phones do not interfere with aircraft avionics. The recommendation why phones should not be used during take-off and landing, even on planes that allow calls or messaging, is so that passengers pay attention to the crew for any possible accident situations, as most aircraft accidents happen on take-off and landing.\n\nMobile phone use can be an important matter of social discourtesy: phones ringing during funerals or weddings; in toilets, cinemas and theatres. Some book shops, libraries, bathrooms, cinemas, doctors' offices and places of worship prohibit their use, so that other patrons will not be disturbed by conversations. Some facilities install signal-jamming equipment to prevent their use, although in many countries, including the US, such equipment is illegal.\n\nMany US cities with subway transit systems underground are studying or have implemented mobile phone reception in their underground tunnels for their riders, and trains, particularly those involving long-distance services, often offer a \"quiet carriage\" where phone use is prohibited, much like the designated non-smoking carriage of the past. Most schools in the United States and Europe and Canada have prohibited mobile phones in the classroom, or in school in an effort to limit class disruptions.\n\nA working group made up of Finnish telephone companies, public transport operators and communications authorities has launched a campaign to remind mobile phone users of courtesy, especially when using mass transit—what to talk about on the phone, and how to. In particular, the campaign wants to impact loud mobile phone usage as well as calls regarding sensitive matters.\n\nThe use of mobile phones by people who are driving has become increasingly common, for example as part of their job, as in the case of delivery drivers who are calling a client, or socially as for commuters who are chatting with a friend. While many drivers have embraced the convenience of using their cellphone while driving, some jurisdictions have made the practice against the law, such as Australia, the Canadian provinces of British Columbia, Quebec, Ontario, Nova Scotia, and Newfoundland and Labrador as well as the United Kingdom, consisting of a zero-tolerance system operated in Scotland and a warning system operated in England, Wales, and Northern Ireland. Officials from these jurisdictions argue that using a mobile phone while driving is an impediment to vehicle operation that can increase the risk of road traffic accidents.\n\nStudies have found vastly different relative risks (RR). Two separate studies using case-crossover analysis each calculated RR at 4, while an epidemiological cohort study found RR, when adjusted for crash-risk exposure, of 1.11 for men and 1.21 for women.\n\nA simulation study from the University of Utah Professor David Strayer compared drivers with a blood alcohol content of 0.08% to those conversing on a cell phone, and after controlling for driving difficulty and time on task, the study concluded that cell phone drivers exhibited greater impairment than intoxicated drivers. Meta-analysis by The Canadian Automobile Association and The University of Illinois found that response time while using both hands-free and hand-held phones was approximately 0.5 standard deviations higher than normal driving (i.e., an average driver, while talking on a cell phone, has response times of a driver in roughly the 40th percentile).\n\nDriving while using a hands-free device is not safer than driving while using a hand-held phone, as concluded by case-crossover studies. epidemiological studies, simulation studies, and meta-analysis. Even with this information, California initiated new Wireless Communications Device Law (effective January 1, 2009) makes it an infraction to write, send, or read text-based communication on an electronic wireless communications device, such as a cell phone, while driving a motor vehicle. Two additional laws dealing with the use of wireless telephones while driving went into effect July 1, 2008. The first law prohibits all drivers from using a handheld wireless telephone while operating a motor vehicle. The law allows a driver to use a wireless telephone to make emergency calls to a law enforcement agency, a medical provider, the fire department, or other emergency services agency. The base fine for the FIRST offense is $20 and $50 for subsequent convictions. With penalty assessments, the fine can be more than triple the base fine amount. videos about California cellular phone laws; with captions (California Vehicle Code [VC] §23123). Motorists 18 and over may use a “hands-free device. The second law effective July 1, 2008, prohibits drivers under the age of 18 from using a wireless telephone or hands-free device while operating a motor vehicle (VC §23124)The consistency of increased crash risk between hands-free and hand-held phone use is at odds with legislation in over 30 countries that prohibit hand-held phone use but allow hands-free. Scientific literature is mixed on the dangers of talking on a phone versus those of talking with a passenger, with the Accident Research Unit at the University of Nottingham finding that the number of utterances was usually higher for mobile calls when compared to blindfolded and non-blindfolded passengers, but the University of Illinois meta-analysis concluding that passenger conversations were just as costly to driving performance as cell phone ones.\n\nAs of 2007, several airlines are experimenting with base station and antenna systems installed on the airplane, allowing low power, short-range connection of any phones aboard to remain connected to the aircraft's base station. Thus, they would not attempt connection to the ground base stations as during take off and landing. Simultaneously, airlines may offer phone services to their travelling passengers either as full voice and data services, or initially only as SMS text messaging and similar services. The Australian airline Qantas is the first airline to run a test aeroplane in this configuration in the autumn of 2007. Emirates has announced plans to allow limited mobile phone usage on some flights. However, in the past, commercial airlines have prevented the use of cell phones and laptops, due to the assertion that the frequencies emitted from these devices may disturb the radio waves contact of the airplane.\n\nOn March 20, 2008, an Emirates flight was the first time voice calls have been allowed in-flight on commercial airline flights. The breakthrough came after the European Aviation Safety Agency (EASA) and the United Arab Emirates-based General Civil Aviation Authority (GCAA) granted full approval for the AeroMobile system to be used on Emirates. Passengers were able to make and receive voice calls as well as use text messaging. The system automatically came into operation as the Airbus A340-300 reached cruise altitude. Passengers wanting to use the service received a text message welcoming them to the AeroMobile system when they first switched their phones on. The approval by EASA has established that GSM phones are safe to use on airplanes, as the AeroMobile system does not require the modification of aircraft components deemed \"sensitive,\" nor does it require the use of modified phones.\n\nIn any case, there are inconsistencies between practices allowed by different airlines and even on the same airline in different countries. For example, Delta Air Lines may allow the use of mobile phones immediately after landing on a domestic flight within the US, whereas they may state \"not until the doors are open\" on an international flight arriving in the Netherlands. In April 2007 the US Federal Communications Commission officially prohibited passengers' use of cell phones during a flight.\n\nIn a similar vein, signs are put up in many countries, such as Canada, the UK and the U.S., at petrol stations prohibiting the use of mobile phones, due to possible safety issues. However, it is unlikely that mobile phone use can cause any problems, and in fact \"petrol station employees have themselves spread the rumour about alleged incidents.\"\n\nLike all high structures, cellular antenna masts pose a hazard to low flying aircraft. Towers over a certain height or towers that are close to airports or heliports are normally required to have warning lights. There have been reports that warning lights on cellular masts, TV-towers and other high structures can attract and confuse birds. US authorities estimate that millions of birds are killed near communication towers in the country each year.\n\nSome cellular antenna towers have been camouflaged to make them less obvious on the horizon, and make them look more like a tree.\n\nAn example of the way mobile phones and mobile networks have sometimes been perceived as a threat is the widely reported and later discredited claim that mobile phone masts are associated with the Colony Collapse Disorder (CCD) which has reduced bee hive numbers by up to 75% in many areas, especially near cities in the US. The Independent newspaper cited a scientific study claiming it provided evidence for the theory that mobile phone masts \"are\" a major cause in the collapse of bee populations, with controlled experiments demonstrating a rapid and catastrophic effect on individual hives near masts.\nMobile phones were in fact not covered in the study, and the original researchers have since emphatically disavowed any connection between their research, mobile phones, and CCD, specifically indicating that the Independent article had misinterpreted their results and created \"a horror story\".\nWhile the initial claim of damage to bees was widely reported, the corrections to the story were almost non-existent in the media.\n\nThere are more than 500 million used mobile phones in the US sitting on shelves or in landfills, and it is estimated that over 125 million will be discarded this year alone. The problem is growing at a rate of more than two million phones per week, putting tons of toxic waste into landfills daily. Several companies offer to buy back and recycle mobile phones from users. In the United States many unwanted but working mobile phones are donated to women's shelters to allow emergency communication.\n\nThere are two principal ways to pay for mobile telephony: the 'pay-as-you-go' model where conversation time is purchased and added to a phone unit via an Internet account or in shops or ATMs, or the contract model where bills are paid by regular intervals after the service has been consumed. It is increasingly common for a consumer to purchase a basic package and then bolt-on services and functionality to create a subscription customised to the users needs.\n\nPay as you go (also known as \"pre-pay\" or \"prepaid\") accounts were invented simultaneously in Portugal and Italy and today form more than half of all mobile phone subscriptions. USA, Canada, Costa Rica, Japan, Israel and Finland are among the rare countries left where most phones are still contract-based.\n\nIn the early days of mobile telephony, the operators (carriers) charged for all air time consumed by the mobile phone user, which included both outbound and inbound telephone calls. As mobile phone adoption rates increased, competition between operators meant that some decided not to charge for incoming calls in some markets (also called \"calling party pays\").\n\nThe European market adopted a calling party pays model throughout the GSM environment and soon various other GSM markets also started to emulate this model.\n\nIn Hong Kong, Singapore, Canada, and the United States, it is common for the party receiving the call to be charged per minute, although a few carriers are beginning to offer unlimited received phone calls. This is called the \"Receiving Party Pays\" model. In China, it was reported that both of its two operators will adopt the caller-pays approach as early as January 2007.\n\nOne disadvantage of the receiving party pays systems is that phone owners keep their phones turned off to avoid receiving unwanted calls, which results in the total voice usage rates (and profits) in Calling Party Pays countries outperform those in Receiving Party Pays countries. To avoid the problem of users keeping their phone turned off, most Receiving Party Pays countries have either switched to Calling Party Pays, or their carriers offer additional incentives such as a large number of monthly minutes at a sufficiently discounted rate to compensate for the inconvenience.\n\nNote that when a user roaming in another country, international roaming tariffs apply to all calls received, regardless of the model adopted in the home country.\n\n"}
{"id": "19307267", "url": "https://en.wikipedia.org/wiki?curid=19307267", "title": "Nana technology", "text": "Nana technology\n\n\"Nana\" Technology is microchip based technology designed, intended, or that can otherwise be used to improve quality of life for older adults.\n\nThe term “Nana” technology was coined in 2004 by Andrew Carle, an Assistant Professor at George Mason University in Fairfax, Virginia.\n\nCarle’s goal was to bridge what he referred to as the 'divide between Geeks and Grans', in which technology companies were failing to consistently develop products of practical value to older adults, with older adults simultaneously unaware of technologies that did exist and could be helpful in their daily lives. Carle additionally felt governments were not paying enough attention to issues relevant to aging populations worldwide – both in stresses on family caregivers struggling to allow aging parents to live independently for as long as possible, as well as on the critical shortage of long term care workers in both home and facility based environments.\n\nA word play on the scientific field of nanotechnology, “Nana” technology is loosely directed to imply technologies for someone’s grandmother, or “Nana”. Carle was the first person to advance the use of this phrase with a formal definition, and one focused exclusively on microchip technologies, with the end result of naming a new and distinct subset of the technology services industry. Carle’s term and specific application were first nationally published in a feature article in USA TODAY on August 9, 2006. Since that time Carle’s term and/or definition has been published, quoted, or featured in or on numerous media worldwide including but not limited to: CNN, CNBC, CBS News, Fox News, PBS, NPR, Forbes, Smart Money, BBC, Agence France-Presse, KYODO News Service, and the Australian Broadcast Corporation, among others.\n\nSince defining the sector, Carle has served as a consultant or adviser to a number of companies with an interest in developing technologies for older adults, including APPLE, Nintendo, Vigorous Mind, and GTX Corporation. With GTX, he helped develop the first GPS shoe for individuals with Alzheimer's and related dementia, who may be at risk of wandering and becoming lost. In 2012, the technology was recognized as one of the \"100 Most Important Inventions of Mankind\" by the National Museum of Science and Technology in Stockholm, Sweden.\n\nIn addition to the term and definition, Carle has established eight categories to date for “Nana” technologies, and as they pertain to areas most relevant to individuals over the age of 65:\n\nHealth and Wellness: Including technologies such as those for managing medications, monitoring vital signs, or treating medical conditions typically affecting older adults.\n\nSafety: Including technologies for preventing or reducing falls, monitoring for or requesting emergency assistance, or tracking or preventing wandering among individuals suffering from Alzheimer's related dementia.\n\nCognition: Includes technologies intended to improve overall cognitive functioning as affected by normal aging, Mild Cognitive Impairment (MCI), Alzheimer's Disease or related dementia.\nCommunication: Includes technologies that allow older adults to communicate electronically via phone, internet, video, or other forms of communication.\n\nSensory: Includes technologies that assist older adults affected by reduction or loss of vision, hearing, taste, touch, or smell.\n\nMobility: Includes technologies such as those that assist older adults in ambulation, transportation, or driving.\n\nLifestyle: Includes technologies that assist older adults in day-to-day functioning including meal preparation, housekeeping/home maintenance, bathing, dressing, etc.\nRobotics/Whole Home Systems: Includes technologies that can self perform assistive tasks, and/or which combine two or more of the above categories into a single system.\n\nCarle has released or presented multiple Top \"Nana\" Technologies opinion lists, which have been published in numerous national and international media. Featured below is a sample of technologies mentioned or similar to those identified during a presentation at the AARP Life@50+ National Event & Expo in Washington, DC:\n\n\n\n\n\nCarle has repeatedly referenced “Nana” Technologies being researched or developed for future application. Examples cited by Carle have included a medicine cabinet featuring both face recognition and voice communication capabilities, a “smart shirt” that can monitor vital signs and administer CPR in the event of an emergency, \"sensory\" shoe inserts that can provide older adults with the same balance as a 20-year-old, and a personal assistance robot that can hear, see, and smell.\n\nThe trade name \"Nana\" Technology is trademarked to Carle and used commercially, among other uses, as a licensed designation for \"best of show\" winners of an annual, national competition of technologies for older adults. No company or person may use the \"Nana\" Technology designation in commercial use for their products and/or personal gain without permission or licensure of such use from Andrew Carle.\n\nIntellectual property rights for the \"Nana\" Technology term, definition, and categories are additionally copyrighted to Carle (2004), as originally published and presented in his course lectures at George Mason University, and in subsequent articles published by Carle. In this regard, use of the term to describe such technologies must be properly sourced, as well as meet the definition and categories established by Carle.\n\n"}
{"id": "451502", "url": "https://en.wikipedia.org/wiki?curid=451502", "title": "Ocean Ranger", "text": "Ocean Ranger\n\nOcean Ranger was a semi-submersible mobile offshore drilling unit that sank in Canadian waters on 15 February 1982. It was drilling an exploration well on the Grand Banks of Newfoundland, east of St. John's, Newfoundland, for Mobil Oil of Canada, Ltd. (MOCAN) with 84 crew members on board when it sank. There were no survivors.\n\n\"Ocean Ranger\" was designed and owned by Ocean Drilling and Exploration Company, Inc. (ODECO) of New Orleans. The vessel was a self-propelled large semi-submersible design with a drilling facility and living quarters. It was capable of operation beneath of ocean water and could drill to a maximum depth of . It was described by ODECO as the world's largest semi-submersible oil rig to date.\n\nConstructed for ODECO in 1976 by Mitsubishi Heavy Industries in Hiroshima, Japan, \"Ocean Ranger\" was long, wide, and high. It had twelve anchors. The weight was 25,000 tons. It was floating on two long pontoons that rested below the surface.\n\nThe vessel was approved for 'unrestricted ocean operations' and designed to withstand extremely harsh conditions at sea, including winds and waves. Prior to moving to the Grand Banks area in November 1980, it had operated off the coasts of Alaska, New Jersey and Ireland.\n\nOn 26 November 1981, \"Ocean Ranger\" commenced drilling well J-34, its third well in the Hibernia Oil Field. \"Ocean Ranger\" was still working on this well in February 1982 when the incident occurred. Two other semi-submersible platforms were also drilling nearby: \"Sedco 706\", NNE, and \"Zapata\" \"Ugland\", N of \"Ocean Ranger\". On 14 February 1982, the platforms received reports of an approaching storm linked to a major Atlantic cyclone from NORDCO Ltd, the company responsible for issuing offshore weather forecasts. The usual method of preparing for bad weather involved hanging-off the drillpipe at the sub-sea wellhead and disconnecting the riser from the sub-sea blowout preventer. Due to surface difficulties and the speed at which the storm developed, the crew of \"Ocean Ranger\" were forced to shear the drillpipe after hanging-off, after which they disconnected the riser in the early evening.\n\nAt about 19:00 local time, the nearby \"Sedco 706\" experienced a large rogue wave which damaged some items on deck and caused the loss of a life raft. Soon after, radio transmissions were heard from \"Ocean Ranger\", describing a broken portlight (a porthole window) and water in the ballast control room, with discussions on how best to repair the damage. \"Ocean Ranger\" reported experiencing storm seas of , with the odd wave up to , thus leaving the unprotected portlight at above the water line vulnerable to wave damage. Some time after 21:00, radio conversations originating on \"Ocean Ranger\" were heard on \"Sedco 706\" and \"Zapata Ugland\", noting that valves on \"Ocean Ranger\"'s ballast control panel appeared to be opening and closing of their own accord. The radio conversations also discussed the winds and waves up to high. Through the remainder of the evening, routine radio traffic passed between \"Ocean Ranger\", its neighbouring rigs and their individual support boats. Nothing out of the ordinary was noted.\n\nAt 00:52 local time, on 15 February, a Mayday call was sent out from \"Ocean Ranger\", noting a severe list to the port side of the rig and requesting immediate assistance. This was the first communication from \"Ocean Ranger\" identifying a major problem. The standby vessel, the M/V \"Seaforth Highlander\", was requested to come in close as countermeasures against the 10–15-degree list were proving ineffective. The onshore MOCAN supervisor was notified of the situation, and the Canadian Forces and Mobil-operated helicopters were alerted just after 1:00 local time. The M/V \"Boltentor\" and the M/V \"Nordertor\", the standby boats of \"Sedco 706\" and \"Zapata Ugland\" respectively, were also dispatched to \"Ocean Ranger\" to provide assistance. At 1:30 local time, \"Ocean Ranger\" transmitted its last message: \"There will be no further radio communications from \"Ocean Ranger\". We are going to lifeboat stations.\" Shortly thereafter, in the middle of the night and in the midst of severe winter weather, the crew abandoned the platform. The platform remained afloat for another ninety minutes, sinking between 3:07 and 3:13 local time.\n\nAll of \"Ocean Ranger\" sank beneath the Atlantic: by the next morning all that remained was a few buoys. Her entire complement of 84 workers – 46 Mobil employees and 38 contractors from various service companies – were killed. While the rig was provided with an Emergency Procedures Manual which detailed evacuation procedures, it is unclear how effectively the platform evacuation was carried out. There is evidence that at least one lifeboat was successfully launched with up to 36 crew inside, and witnesses on the M/V \"Seaforth Highlander\" reported seeing at least 20 crew members in the water at the same time, indicating that at least 56 crew successfully evacuated the rig. The United States Coast Guard report speculated that 'these men either chose to enter the water directly or were thrown into the water as a result of unsuccessful lifesaving equipment launching'. Rescue attempts by the standby vessels were hampered by the adverse weather conditions and the conclusion that the standby boats were neither equipped nor configured to rescue casualties from a cold sea. As a result of the severe weather, the first helicopter did not arrive on scene until 2:30 local time, by which time most if not all of \"Ocean Ranger\"'s crew had succumbed to hypothermia and drowned. Over the next week, 22 bodies were recovered from the North Atlantic. Autopsies indicated that those men had died as a result of drowning while in a hypothermic state.\n\nIn related activity the following day, the Soviet container ship \"Mekhanik Tarasov\" was struck by the same weather conditions as \"Ocean Ranger\", approximately sixty-five miles to the east. The battered Soviet freighter listed dramatically for hours before sinking with the loss of 32 of 37 crew.\n\nThe remains of the platform were found by sonar search over the following weeks, resting in an inverted position approximately south-east of the wellhead, surrounded by major items of debris such as the derrick. The platform had capsized bow-first, turning over and striking the sea floor with the forward ends of the platform's pontoons. The United States Coast Guard Marine Board of Investigation report on the disaster summarised the chain of events as follows:\n\nA Canadian Royal Commission spent two years looking into the disaster. The joint Federal-Provincial Royal Commission on the Ocean Ranger Marine Disaster found that the crew were not trained, the safety equipment was inadequate, there were no safety protocols for the supply ship, and that the platform itself had a number of flaws. The Royal Commission concluded that \"Ocean Ranger\" had design and construction flaws, particularly in the ballast control room, and that the crew lacked proper safety training, survival suits and equipment. The Royal Commission also concluded that inspection and regulation by United States and Canadian government agencies was ineffective. In addition to key recommendations for Canada's offshore oil and gas industry, the commission recommended that the federal government invest annually in research and development for search and rescue technologies, such as improving the design of lifesaving equipment—a commitment that has been met in every fiscal year since 1982. \n\nIn August 1983, the wreck of \"Ocean Ranger\" was refloated and sunk in deeper waters by the Dutch firm Wijsmuller Salvage. Since its sinking the previous year, concerns over the wreck's position had been made by the federal government. As the Ocean Ranger was situated at an approximate 30 metres below the water, the wreck posed a danger to shipping. The operation saw \"Ocean Ranger\" towed upside down with her two pontoons breaking the surface.\n\nOperations had commenced earlier in June, however progress was halted when two salvage divers were killed on the wreck by an underwater explosion on 20 June. A stop-work order on refloating the wreck was declared and an investigation into the incident followed. However, exploratory diving was allowed to continue. A second incident on 26 June saw a third diver killed, believed to have been hit by a dropped object as he attempted to return to the surface.\n\nLawsuits arising from the sinking were settled out of court with a package cumulatively valued at $20 million.\n\nA permanent monument to those who died was created on the grounds of the Confederation Building, the seat of the provincial government of Newfoundland.\n\nA documentary film, \"The Ocean Ranger Disaster\" (2002), was released only in Canada. In fiction, Canadian author Lisa Moore's novel, \"February\" (2009), depicts the life of a woman whose husband died aboard the oil rig. Canadian folk singer-songwriter Ron Hynes wrote a song called \"Atlantic Blue\" (1988) as a tribute to the crew of \"Ocean Ranger\".\n\nIn January 2012, a non-fiction book, \"The Ocean Ranger: Remaking the Promise of Oil\" was published in Canada by Fernwood Publishing. The book's author, Susan Dodd, lost her older brother Jim with the sinking of the \"Ocean Ranger\" and watched, for years, as her parents pursued legal struggles with the oil companies.\n\nIan \"Scotty\" Morrison, former director of NHL officiating and a trustee of the Stanley Cup and Hockey Hall of Fame inductee, lost his son Perry. Perry worked as a deep-sea diver on the rig. His body was not recovered.\n\n\n"}
{"id": "28961455", "url": "https://en.wikipedia.org/wiki?curid=28961455", "title": "Petit Salé", "text": "Petit Salé\n\nPetit Salé is salted pork, usually produced according to a French method of immersing cuts of pork for up to two days in brine.\n\nPetit Salé is often used as an abbreviation for the recipe Petit Salé aux Lentilles, a dish containing pork, vegetables and lentils.\n\n"}
{"id": "37153787", "url": "https://en.wikipedia.org/wiki?curid=37153787", "title": "Plus (novel)", "text": "Plus (novel)\n\nPlus is Joseph McElroy's fifth novel. Set in some unspecified future, it tells the story of Imp Plus, a disembodied brain controlling IMP, the Interplanetary Monitoring Platform, in earth orbit. The novel consists of Imp Plus's thoughts as he tries to comprehend his limited existence, while struggling with language, limited memories, and communicating with Ground Control. The plot is driven by Imp Plus's recall of fragments of his past and of language, his improving comprehension of his present, all while his medical condition gradually deteriorates.\n\nMcElroy denies that the novel is science fiction, unless \"science\" is used in its etymological sense of \"knowing\".\n\nThe novel was reprinted as an e-book by Dzanc Books in 2014, with an introductory 2012 poem \"A Green of its Own Breathing\" by Sarah Grindley, dedicated to \"Joe McElroy & Imp Plus\".\n\nMcElroy acknowledges three technical sources:\n\nThe accompanying author photograph is the only such author photograph of McElroy sporting a beard.\n\n\n\nThe following articles appeared in the Joseph McElroy issue of \n\nIn addition, see these general works on McElroy's fiction.\n"}
{"id": "13874134", "url": "https://en.wikipedia.org/wiki?curid=13874134", "title": "Polespear", "text": "Polespear\n\nA polespear (hand spear or gidgee) is an underwater tool used in spearfishing, consisting of a pole, a spear tip, and a rubber loop. Polespears are often mistakenly called Hawaiian slings, but the tools differ. A Hawaiian sling is akin to a slingshot or an underwater bow and arrow, since the spear and the propelling device are separate, while a polespear has the sling (rubber loop) attached to the spear.\n\nThe pole is usually between four feet and ten feet long and made of fiberglass, carbon fibre, aluminum, graphite, or wood. Longer versions often break down into two or more pieces that screw together. The tip is either threaded to accept different kinds of spear tips or already has a fixed tip attached. The most popular spear tip on polespears are the paralyzer (often called a three-prong), and the Tahitian shaft (a single pivoting barb). Some more serious hunters will equip the polespear with a slip-tip (tip removes from the end and tethers to a fixed point). At the butt end of the spear is an elastic loop, usually made of surgical tubing or a band of rubber (a bicycle inner tube, for example).\n\nThe spear is operated by placing the rubber loop in the crook of the thumb, then reaching up the spear shaft to stretch the elastic band and grabbing the polespear to hold the band in tension. On flimsy spears, it's useful to twist the spear as the band stretches to keep the spear from bending. Shooting the spear involves releasing the grasp of the hand but still using the hand to guide the spear like a barrel to a gun. The firing distance of a polespear can be divided into two ranges. First, there is the overall distance of the stretch or the 'travel range'. This second range is the distance that most are interested in as it is more relevant to penetrating fish. For this reason, it is called the 'penetrating range.' Not all the travel of the spear being fired has the 'punch' to penetrate through fish. Depending on the polespear's attributes such as mass, drag, band strength, band stretch, etc., the penetrating range can be from a scant few inches to several feet. Other factors may include fish orientation, fish width, density, skin composition, etc. One would need to take all the attributes into account before firing a polespear towards a target. For example, the band pull on a 10-foot polespear may stretch up to 6-feet of the polespear. It actually requires about 8-feet of polespear, measured from the rear, to do this because the stretch doesn't start till the band begins to provide tension (typically, about 2-feet loop length on a 10-footer). However, the penetrating range may only be half of the pull. This equals about 3' for a 10 footer. Some fish, however, are thicker/denser and may require much closer shots.\n\nThe more mass a polespear contains, the more band power it will require to move the same speed as a polespear with less mass. However, some fiberglass or extremely lightweight polespears will have so little mass that there is little velocity or 'punch' behind them when it hits a fish.\n\nA hybrid polespear combines aluminum with a more flexible material such as a fiberglass rod. These polespears offer rigidity for loading, but still some flexibility in the front end to absorb the lateral movements of a fish once it is attached to the end.\n\n"}
{"id": "486432", "url": "https://en.wikipedia.org/wiki?curid=486432", "title": "Processor register", "text": "Processor register\n\nIn computer architecture, a processor register is a quickly accessible location available to a computer's central processing unit (CPU). Registers usually consist of a small amount of fast storage, although some registers have specific hardware functions, and may be read-only or write-only. Registers are typically addressed by mechanisms other than main memory, but may in some cases be assigned a memory address e.g. DEC PDP-10, ICT 1900.\n\nAlmost all computers, whether load/store architecture or not, load data from a larger memory into registers where it is used for arithmetic operations and is manipulated or tested by machine instructions. Manipulated data is then often stored back to main memory, either by the same instruction or by a subsequent one. Modern processors use either static or dynamic RAM as main memory, with the latter usually accessed via one or more cache levels.\n\nProcessor registers are normally at the top of the memory hierarchy, and provide the fastest way to access data. The term normally refers only to the group of registers that are directly encoded as part of an instruction, as defined by the instruction set. However, modern high-performance CPUs often have duplicates of these \"architectural registers\" in order to improve performance via register renaming, allowing parallel and speculative execution. Modern x86 design acquired these techniques around 1995 with the releases of Pentium Pro, Cyrix 6x86, Nx586, and AMD K5.\n\nA common property of computer programs is locality of reference, which refers to accessing the same values repeatedly and holding frequently used values in registers to improve performance; this makes fast registers and caches meaningful. Allocating frequently used variables to registers can be critical to a program's performance; this register allocation is performed either by a compiler in the code generation phase, or manually by an assembly language programmer.\n\nRegisters are normally measured by the number of bits they can hold, for example, an \"8-bit register\", \"32-bit register\" or a \"64-bit register\" or even more. In some instruction sets, the registers can operate in various modes breaking down its storage memory into smaller ones (32-bit into four 8-bit one for instance) to which multiple data (vector, or one dimensional array of data) can be loaded and operated upon at the same time. Typically it is implemented by adding extra registers that map their memory into bigger one. Processors that have the ability to execute single instruction on multiple data are called vector processors.\n\nA processor often contains several kinds of registers, which can be classified according to their content or instructions that operate on them:\n\n\nHardware registers are similar, but occur outside CPUs.\n\nIn some architectures (such as SPARC and MIPS), the first or last register in the integer register file is a pseudo-register in a way that it is hardwired to always return zero when read (mostly to simplify indexing modes), and it cannot be overwritten. In Alpha this is also done for the floating-point register file. As a result of this, register files are commonly quoted as having one register more than how many of them are actually usable; for example, 32 registers are quoted when only 31 of them fit within the above definition of a register.\n\nThe following table shows the number of registers in several mainstream CPU architectures. Note that in x86-compatible processors the stack pointer (ESP) is counted as an integer register, even though there are a limited number of instructions that may be used to operate on its contents. Similar caveats apply to most architectures.\n\nAlthough all of the above listed architectures are different, almost all are a basic arrangement known as the Von Neumann architecture, first proposed by the Hungarian-American mathematician John von Neumann. It is also noteworthy that the number of registers on GPUs is much higher than that on CPUs.\n\nThe number of registers available on a processor and the operations that can be performed using those registers has a significant impact on the efficiency of code generated by optimizing compilers. The Strahler number of an expression tree gives the minimum number of registers required to evaluate that expression tree.\n\n"}
{"id": "11347064", "url": "https://en.wikipedia.org/wiki?curid=11347064", "title": "Reversed electrodialysis", "text": "Reversed electrodialysis\n\nReverse electrodialysis (RED) is the salinity gradient energy retrieved from the difference in the salt concentration between seawater and river water. A method of utilizing the energy produced by this process by means of a heat engine was invented by Prof. Sidney Loeb in 1977 at the Ben-Gurion University of the Negev.\n--United States Patent US4171409\n\nIn reverse electrodialysis a salt solution and fresh water are let through a stack of alternating cation and anion exchange membranes. The chemical potential difference between salt and fresh water generates a voltage over each membrane and the total potential of the system is the sum of the potential differences over all membranes. The process works through difference in ion concentration instead of an electric field, which has implications for the type of membrane needed.\n\nIn RED, as in a fuel cell, the cells are stacked. A module with a capacity of 250 kW has the size of a shipping container.\n\nIn the Netherlands, for example, more than 3,300 m³ fresh water runs into the sea per second on average. The membrane halves the pressure differences which results in a water column of approximately 135 meters. The energy potential is therefore e=mgΔh=3.3*10 kg/s*10 m/s*135 meters ca.= 4.5*10 Joule per second, Power=4.5 gigawatts.\nIn 2006 a 50 kW plant was located at a coastal test site in Harlingen, the Netherlands, the focus being on prevention of biofouling of the anode, cathode, and membranes and increasing the membrane performance. In 2007 the Directorate for Public Works and Water Management, Redstack, and ENECO signed a declaration of intent for development of a pilot plant on the Afsluitdijk in the Netherlands. The plant was put into service on 26 November 2014 and produces 50 kW of electricity to show the technical feasibility in real-life conditions using fresh IJsselmeer water and salt water from the Wadden Sea. Theoretically, with 1m/s river water and an equal amount of sea water, approximately 1 MW of renewable electricity can be recovered at this location by upscaling the plant. It is to be expected that after this phase the installation could be further expanded to a final capacity of 200 MW.\n\n\n"}
{"id": "39799017", "url": "https://en.wikipedia.org/wiki?curid=39799017", "title": "Software-defined data center", "text": "Software-defined data center\n\nSoftware-defined data center (SDDC; also: virtual data center, VDC) is a marketing term that extends virtualization concepts such as abstraction, pooling, and automation to all data center resources and services to achieve IT as a service (ITaaS).\nIn a software-defined data center, \"all elements of the infrastructure — networking, storage, CPU and security – are virtualized and delivered as a service.\" While ITaaS may represent an outcome of SDDC, SDDC is differently cast toward integrators and datacenter builders rather than toward tenants. Software awareness in the infrastructure is not visible to tenants.\n\nSDDC support can be claimed by a wide variety of approaches. Critics see the software-defined data center as a marketing tool and \"software-defined hype,\" noting this variability.\n\nIn 2013, an analyst projected that at least some software-defined data center components would experience market growth. The software-defined networking market is expected to be valued at about USD $3.7 billion by 2016, compared to USD $360 million in 2013. IDC estimates that the software-defined storage market is poised to expand faster than any other storage market.\n\nThe software-defined data center encompasses a variety of concepts and data-center infrastructure components, with each component potentially provisioned, operated, and managed through an application programming interface (API). Core architectural components that comprise the software-defined data center include the following:\n\nA software-defined data center differs from a private cloud, since a private cloud only has to offer virtual-machine self-service, beneath which it could use traditional provisioning and management. Instead, SDDC concepts imagine a data center that can encompass private, public, and hybrid clouds.\n\nData centers traditionally lacked the capacity to accommodate total virtualization. By 2013, companies began laying the foundation for software-defined data centers with virtualization. Ben Cherian of Midokura considered Amazon Web Services as a catalyst for the move toward software-defined data centers because it \"convinced the world that the data center could be abstracted into much smaller units and could be treated as disposable pieces of technology, which in turn could be priced as a utility.\"\n\nIn 2013, the software-defined data center term was promoted as a paradigm shift. According to Steve Herrod, the promise of the software-defined data center was that companies would no longer need to rely on specialized hardware or hire consultants to install and program hardware in its specialized language. Rather, IT would define applications and all of the resources they require—including compute, storage, networking, security, and availability—and group all of the required components to create a “logical application.”\n\nCommonly cited benefits of software-defined data centers include improved efficiency from extending virtualization throughout the data center; increased agility from provisioning applications quickly; improved control over application availability and security through policy-based governance; and the flexibility to run new and existing applications in multiple platforms and clouds.\n\nIn addition, a software-defined data center implementation could reduce a company’s energy usage by enabling servers and other data center hardware to run at decreased power levels or be turned off. Some believe that software-defined data centers improve security by giving organizations more control over their hosted data and security levels, compared to security provided by hosted-cloud providers.\n\nThe software-defined data center was marketed to drive down prices for data center hardware and challenge traditional hardware vendors to develop new ways to differentiate their products through software and services.\n\nThe concepts of software-defined in general, and software-defined data centers in particular, have been dismissed by some as “nonsense,” “marketecture,” and “software-defined hype.” Some critics believe that only a minority of companies with “completely homogeneous IT systems’” already in place, such as Yahoo! and Google, can transition to software-defined data centers.\n\nAccording to some observers, software-defined data centers won’t necessarily eliminate challenges that relate to handling the differences between development and production environments; managing a mix of legacy and new applications; or delivering service-level agreements (SLAs).\n\nSoftware-defined networking was seen as essential to the software-defined data center, but it is also considered to be the “least mature technology” required to enable the software-defined data center. However, several companies, including Arista Networks, Cisco, Microsoft and VMware, market products to enable virtual networks that are provisioned, extended, and moved across existing physical networks.\n\nSeveral competing network virtualization standards already existed by 2012. Neutron, the networking component of the open-source software OpenStack project, provides an application-level abstraction of network resources and includes an interface for configuring virtual switches.\n\nThe software-defined data center approach will force IT organizations to adapt. Software-defined environments require rethinking many IT processes—including automation, metering, and billing—and executing service delivery, service activation, and service assurance.\nA widespread transition to the SDDC could take years.\n\n"}
{"id": "34666187", "url": "https://en.wikipedia.org/wiki?curid=34666187", "title": "SpaceX reusable launch system development program", "text": "SpaceX reusable launch system development program\n\nThe SpaceX reusable launch system development program is a privately funded program to develop a set of new technologies for an orbital launch system that may be reused many times in a manner similar to the reusability of aircraft. The company SpaceX is developing the technologies over a number of years to facilitate full and rapid reusability of space launch vehicles. The project's long-term objectives include returning a launch vehicle first stage to the launch site in minutes and to return a second stage to the launch pad following orbital realignment with the launch site and atmospheric reentry in up to 24 hours. SpaceX's long term goal is that both stages of their orbital launch vehicle will be designed to allow reuse a few hours after return.\n\nThe program was publicly announced in 2011. SpaceX first achieved a successful landing and recovery of a first stage in December 2015. The first re-flight of a landed first stage occurred in March 2017 with the second occurring in June 2017, that one only five months after the maiden flight of the booster. The third attempt occurred in October 2017 with the SES-11/EchoStar-105 mission. Second flights of refurbished first stages then became routine.\n\nThe reusable launch system technology was developed and initially used for the first stages of the Falcon family of rockets. After stage separation, the return process involves flipping the booster around, an optional boostback burn to reverse its course, a reentry burn, controlling direction to arrive at the landing site and a landing burn to effect the final low-altitude deceleration and touchdown. \n\nSpaceX intended (from at least 2014) to develop technology to extend reusable flight hardware to second stages, a more challenging engineering problem because the vehicle is travelling at orbital velocity,\nwhich is considered paramount to the plans Elon Musk is championing to enable the settlement of Mars. It is thus planned to be developed for all of the flight hardware for the new SpaceX vehicles planned to transit to Mars, with initial test flights expected no earlier than 2020. SpaceX will also experiment with second stage recovery on a few select Falcon 9 flights or Falcon Heavy flights. \nAfter 2017, much of the reusable technology development work and testing turned substantially toward advances in reusable second-stage-with-integrated-spaceship technology to support BFR use not merely in Earth's atmosphere, but also as intended to be used on Solar system celestial bodies such as the Moon and Mars with very diverse atmospheric characteristics. This includes the building of new test vehicles: the high-altitude mini-BFR test ship and the initial BFR development ship to be used initially for low-altitude, low-velocity testing. Flight testing is expected to begin in 2019.\n\nSpaceX initially attempted to land the first stage of the Falcon 1 by parachute, however the stage did not survive the re-entry into the atmosphere. They continued to experiment with parachutes on the earliest Falcon 9 flights after 2010. SpaceX subsequently switched its focus to developing a powered descent landing system.\n\nThe broad outline of the reusable launch system was first publicly described in September 2011. SpaceX said it would attempt to develop powered descent and recovery of both Falcon 9 stagesa fully vertical takeoff, vertical landing (VTVL) rocket. The company produced a computer-animated video depicting a notional view of the first stage returning tail-first for a powered descent and the second stage with a heat shield, reentering head first before rotating for a powered descent. In September 2012, SpaceX began flight tests on a prototype reusable first stage with the suborbital Grasshopper rocket. Those tests continued into 2014, including testing of a second and larger prototype vehicle, F9R Dev1.\n\nNews of the Grasshopper test rocket had become public a few days earlier, when the US Federal Aviation Administration released a draft Environmental Impact Assessment for the SpaceX Test Site in Texas, and the space media had reported it. In May 2012, SpaceX obtained a set of atmospheric test data for the recovery of the Falcon 9 first stage based on 176 test runs in the NASA Marshall Space Flight Center wind tunnel test facility. The work was contracted for by SpaceX under a reimburseable Space Act Agreement with NASA.\n\nIn 2012, it was projected that the first-stage separation of a reusable Falcon 9 rocket would occur at a velocity of approximately rather than for an expendable Falcon 9, to provide the residual fuel necessary for the deceleration and turnaround maneuver and the controlled descent and landing.\n\nIn November 2012, CEO Elon Musk announced SpaceX's plans to build a second, much larger, reusable rocket system, this one to be powered by LOX/methane rather than LOX/RP-1 used on Falcon 9 and Falcon Heavy. The new system was to be \"an evolution of SpaceX's Falcon 9 booster\", and SpaceX reiterated their commitment to develop a breakthrough in vertical landing technology. By the end of 2012, the demonstration test vehicle, Grasshopper, had made three VTVL test flightsincluding a 29-second hover flight to on December 17, 2012. In early March 2013, SpaceX successfully tested Grasshopper for a fourth time when it flew to an altitude of over .\n\nIn March 2013, SpaceX announced that it would instrument and equip subsequent Falcon 9 first-stages as controlled descent test vehicles, with plans for over-water propulsively-decelerated simulated landings beginning in 2013, with the intent to return the vehicle to the launch site for a powered landingpossibly as early as mid-2014. The April 2013 draft Environmental Impact Statement for the proposed SpaceX South Texas Launch Site includes specific accommodations for return of the Falcon 9 first-stage boosters to the launch site. Elon Musk first publicly referred to the reusable Falcon 9 as the Falcon 9-R in April 2013.\n\nIn September 2013, SpaceX successfully relit three engines of a spent booster on an orbital launch, and the booster re-entered the atmosphere at hypersonic speed without burning up. With the data collected from the first flight test of a booster-controlled descent from high altitude, coupled with the technological advancements made on the Grasshopper low-altitude landing demonstrator, SpaceX announced it believed it was ready to test a full land-recovery of a booster stage. Based on the positive results from the first high-altitude flight test, SpaceX advanced the expected date of a test from mid-2014 to early 2015, with the intention of doing so on the next Space Station cargo resupply flight pending regulatory approvals. That flight took place on April 18, 2014.\n\nMusk stated in May 2013 that the goal of the program is to achieve full and rapid reusability of the first stage by 2015, and to develop full launch vehicle reusability following that as \"part of a future design architecture\".\n\nIn February 2014, SpaceX made explicit that the newly defined super-heavy launch vehicle for what was then called Mars Colonial Transporter would also make use of the reusable technology.\nThis was consistent with Musk's strategic statement in 2012 that \"The revolutionary breakthrough will come with rockets that are fully and rapidly reusable. We will never conquer Mars unless we do that. It'll be too expensive. The American colonies would never have been pioneered if the ships that crossed the ocean hadn't been reusable.\"\n\nAlso in May 2014, SpaceX publicly announced an extensive test program for a related reusable technology: a propulsively-landed space capsule called \"DragonFly\". The tests were to be run in Texas at the McGregor Rocket Test Facility in 2014–2015.\n\nIn June 2014, COO Gwynne Shotwell clarified that all funding for development and testing of the reusable launch system technology development program is private funding from SpaceX, with no contribution by the US government.\nAs of 2017 SpaceX had spent over a billion dollars on the development program.\n\nFor the first time, SpaceX stated in July 2014 that they are \"highly confident of being able to land successfully on a floating launch pad or back at the launch site and refly the rocket with no required refurbishment.\"\n\nBy late 2014, SpaceX suspended or abandoned the plan to recover and reuse the Falcon 9 second stage; the additional mass of the required heat shield, landing gear, and low-powered landing engines would incur too great a performance penalty.\n\nIn September 2016, SpaceX announced that development was underway to extend the reusable flight hardware to second stages, a more challenging engineering problem because the vehicle is travelling at orbital velocity. The reusable technology was to have been extended to the 2016 designs of both the tanker and crewed spaceship upper stage variants as well as the first stage of the ITS launch vehicle for the Interplanetary Transport System,\nand is considered paramount to the plans Elon Musk is championing to enable the settlement of Mars. In 2016, initial test flights of an Interplanetary Transport System vehicle were expected no earlier than 2020.\n\nIn 2017 SpaceX was making test flight progress in incrementally and iteratively developing a fairing recovery system.\nIn July 2017, Musk said \"we are quite close to being able to recover the fairing. ... We've got a decent shot of recovering a fairing by the end of the year, and reflight by late this year or early next.\"\nThe cost savings to SpaceX of recovering the fairing is expected to be on the order of . Together, the booster stage and the fairing make up approximately 80 percent of the cost of a launch.\n\nDespite 2014 plans to suspend development of Falcon 9 second stage reuse,\nMusk further commented in July 2017 that a few experimental attempts would be made on particular future flights to bring a Falcon 9 second stage back.\n\nSeveral new technologies needed to be developed and tested to facilitate successful launch and recovery of both stages of the SpaceX reusable rocket launching system. Following the completion of the third high-altitude controlled-descent test, and the completion of the third low-altitude flight of the second-generation prototype test vehicle (plus eight flights of the first-generation Grasshopper prototype flight test vehicle), SpaceX indicated that they are now able to consistently \"reenter from space at hypersonic velocity, restart main engines twice, deploy landing legs and touch down at near zero velocity.\"\nThe technologies that were developed for this program, some of which are still being refined, include:\n\n\n\nIn order to make the Falcon 9 reusable and return to the launch site, extra propellant and landing gear must be carried on the first stage, requiring around a 30 percent reduction of the maximum payload to orbit in comparison with the expendable Falcon 9. Reflight of a previously used stage on a subsequent flight is dependent on the condition of the landed stage, and is a technique that has seen little use outside of the Space Shuttle's reusable solid rocket boosters. In September 2013, SpaceX said that if all aspects of the test program were successful and if a customer is interested, the first reflight of a Falcon 9 booster stage could happen as early as late 2014.\nIn December 2015, following the recovery of the first stage from December 22 launch, SpaceX projected that the first reflight of a recovered booster would likely occur in 2016, but that their plan was to not refly December 22 recovered stage for that purpose.\nMusk projected in 2015 that the reflight step of the program would be \"straightforward,\" because of the multiple full duration firings of the engines that had been done on the ground, and the multiple engine restarts that had been demonstrated by that time, with no significant degradation seen.\nIn 2015, industry analysts continued to forecast problems that could prevent economic reuse because costs to refurbish and relaunch the stage were not yet demonstrated, and the economic case for reuse would necessarily be highly dependent on launching frequently.\n\nIf SpaceX is successful in developing the reusable technology, it is expected to significantly reduce the cost of access to space, and change the increasingly competitive market in space launch services. Michael Belfiore wrote in \"Foreign Policy\" in 2013 that, at a published cost of per launch to low Earth orbit, \"Falcon 9 rockets are already the cheapest in the industry. Reusable Falcon 9s could drop the price by an order of magnitude, sparking more space-based enterprise, which in turn would drop the cost of access to space still further through economies of scale.\" Even for military launches, which have a number of contractual requirements for additional launch services to be provided, SpaceX's price is under .\nSpace industry analyst Ajay Kothari has noted that SpaceX reusable technology could do for space transport \"what jet engines did for air transportation sixty years ago when people never imagined that more than 500 million passengers would travel by airplanes every year and that the cost could be reduced to the level it is—all because of passenger volume and reliable reusability.\"\nSpaceX said in January 2014 that if they are successful in developing the reusable technology, launch prices of around for a reusable Falcon 9 were possible,\nand following the successful first stage recovery in December 2015, Musk said that \"the potential cost reduction over the long term is probably in excess of a factor of 100.\"\n\n, the Falcon 9 v1.1 rocket was designed with about 30 percent more capacity than its official payload specifications; the additional performance was reserved for SpaceX to perform first-stage re-entry and landing tests towards reusability while still achieving the specified orbital payload delivery for customers.\n\nIn order to achieve the full economic benefit of the reusable technology, it is necessary that the reuse be both rapid and complete—without the long and costly refurbishment period or partially reusable design that plagued earlier attempts at reusable launch vehicles. SpaceX has been explicit that the \"huge potential to open up space flight\" is dependent on achieving both complete and rapid reusability.\nCEO Musk stated in 2014 that success with the technology development effort could reduce \"the cost of spaceflight by a factor of 100\" because the cost of the propellant/oxidizer on the Falcon 9 is only 0.3 percent of the total cost of the vehicle.\n\nSeparate from the market competition brought about by SpaceX lower launch prices and the potential future of even more radically lower launch prices if the technology can be completed successfully, \"Aviation Week\" said in 2014 that \"SpaceX reusable launch work is an R&D model\"—\"The audacity of the concept and speed of the program’s progress make it an exemplar. ... [the] breakneck pace of development has been almost Apollo-like in its execution... [even while] success is far from guaranteed.\"\n\nOn March 9, 2016, SpaceX President Gwynne Shotwell gave a more realistic appraisal of the potential savings of a reused launch now that attempts to reuse the second stage had been abandoned due to cost and weight issues. She said at cost of refueling and cost of refurbishing a used first stage could potentially allow a launch to be priced as low as , a 30% saving. SpaceX biggest customer SES said it wants to be the first to ride a reused vehicle, however it wants a launch price of or a 50% saving to offset the risk of pioneering the process.\n\nAccording to Elon Musk, almost every piece of the Falcon should be reused over 100 times. Heat shields and a few other items should be reused over 10 times before replacement. In March 2017, SpaceX announced progress in their experiments to recover, and eventually reuse, the 6-million dollar payload fairing. On the SES-10 mission, one of the fairing halves performed a controlled atmospheric reentry and splashdown using thrusters and a steerable parachute; fairings are eventually slated to land on a floating \"bouncy castle\" structure.\n\nSpaceX began re-flight of previously-launched booster stages in 2017. The first re-flight was accomplished in March 2017, nearly a year after the booster's maiden flight; the second was in June 2017, only five months after its maiden flight. Both were successful, and both insurers and launch service customers are readily supporting the newly emerging market in launch services provided by multiple-use boosters.\n\nPrior to the reusability program's success in December 2015, the return of an orbital launch system booster rocket had never been accomplished, and many questioned both technical and economic feasibility. And even after this success, the \"rapid\" reuse of a rocket has not been attempted. Developing a reusable rocket is extremely challenging due to the small percentage of a rocket's mass that can make it to orbit. Typically, a rocket's payload is only about 3% of the mass of the rocket which is also roughly the amount of mass in fuel that is required for the vehicle's re-entry.\n\nElon Musk said at the beginning of the program that he believed the return, vertical landing and recovery was possible because the SpaceX manufacturing methodologies result in a rocket efficiency exceeding the typical 3% margin. A SpaceX rocket operating in the reusable configuration has approximately 30% less payload lift capacity than the same rocket in an expendable configuration.\n\nAlthough the reusable launch system technology was developed and initially used for the first stages of the Falcon family of rockets it is particularly well suited to the Falcon Heavy where the two outer cores separate from the rocket earlier in the flight, and are therefore moving more slowly at stage separation. For example, on Falcon 9 flight 20, the speed at separation was close to 6000 km/h and this allowed a return to near the launch site. On flight 22, going to a more-energetic GTO orbit, the higher velocity at separation was between 8000 and 9000 km/h. At these faster speeds it is not possible to return the booster to near the launch site for a landing; if a landing is attempted it needs to be hundreds of kilometers downrange on an autonomous droneship.\n\nIn 2013 SpaceX was testing reusable technologies both for its first-stage booster launch vehicle designs (with three test vehicles : Grasshopper, F9R Dev1, and F9R Dev2) — and for its new reusable Dragon V2 space capsule (with a low-altitude test vehicle called DragonFly).\n\nSpaceX has publicly disclosed a multi-element, incremental test program for booster stages that includes four aspects:\n\nEight low-altitude booster flight tests were made by Grasshopper in 2012 and 2013.\nThe first booster return controlled-descent test from high-altitude was made in September 2013, with a second test in April,\na third test flight in July\nand a fourth test in September 2014. All four test flights to date were intended to be over-water, simulated landings.\nFive low-altitude booster flight tests of F9R Dev1 were flown during April–August 2014, before the vehicle self-destructed for safety reasons on the fifth flight.\n\nSpaceX used a set of experimental technology-demonstrator, suborbital reusable launch vehicles (RLV) to begin flight testing their reusable booster technologies in 2012. Two versions of the prototype reusable test rockets were built—the 106-foot tall \"Grasshopper\" (formerly designated as \"Grasshopper v1.0\") and the 160-foot tall \"Falcon 9 Reusable Development Vehicle\", or \"F9R Dev1\"—formerly known as \"Grasshopper v1.1\"—as well as a capsule prototype for testing propulsive landings of the Dragon crew and cargo capsule for the Falcon 9—\"DragonFly\".\nGrasshopper was built in 2011–2012 for low-altitude, low-velocity hover testing that began in September 2012 and concluded in October 2013 after eight test flights.\nThe second prototype vehicle design, F9R Dev1, was built on the much larger Falcon 9 v1.1 booster stage was used to further extend the low-altitude flight testing envelope on a vehicle that better matched the actual flight hardware, and made five test flights in 2014. The low-altitude, low-speed flights of the test vehicle rockets and capsule were conducted at the SpaceX Rocket Test Facility in McGregor, Texas\n\nIn 2018, SpaceX is also developing a highly-modified Falcon 9 second stage to be used for testing of a number of reentry technologies needed for the full-scale BFR spaceship, as well as a BFR development vehicle to test propulsive landing technologies.\n\nGrasshopper, the company's first VTVL test vehicle, consisted of a Falcon 9 v1.0 first-stage tank, a single Merlin-1D engine, and four permanently attached steel landing legs. It stood tall. SpaceX built a concrete launch facility at its Rocket Development and Test Facility in McGregor, Texas to support the Grasshopper flight test program.\nGrasshopper was also known as Grasshopper version 1.0, or Grasshopper v1.0, prior to 2014 during the time the followon Grasshopper-class test vehicles were being built.\n\nIn addition to three test flights in 2012, five additional tests were successfully flown by the end of October 2013including the fourth test overall in March 2013in which Grasshopper doubled its highest leap to rise to with a 34-second flight. In the seventh test, in August 2013, the vehicle flew to during a 60-second flight and executed a lateral maneuver before returning to the pad. Grasshopper made its eighth and final test flight on October 7, 2013, flying to (0.46 miles) before making its eighth successful landing. The Grasshopper test vehicle is now retired.\n\nAs early as October 2012, SpaceX discussed development of a second-generation Grasshopper test vehicle, which was to have lighter landing legs that fold up on the side of the rocket, a different engine bay, and would be nearly 50% longer than the first Grasshopper vehicle. In March 2013, SpaceX announced that the larger Grasshopper-class suborbital flight vehicle would be constructed out of the first-stage tank that was used for qualification testing at the SpaceX Rocket Development and Test Facility in early 2013. It was rebuilt as the with extensible landing legs. Five test flights occurred in 2014.\n\nThe second VTVL flight test vehicle—F9R Dev1, built on the much longer Falcon 9 v1.1 first-stage tank, with retractable landing legs—made its first test flight on April 17, 2014. F9R Dev1 was used for low-altitude test flights in the McGregor, Texas area—projected maximum altitude below —with a total of five test flights, all made during 2014.\nThis vehicle self-destructed as a safety measure during its fifth test flight on August 22, 2014.\n\nBy April 2014, a third flight test vehicle—F9R Dev2—was being built and was planned to be flown at the high-altitude test range available at Spaceport America in New Mexico where it was expected to be flown at altitudes up to -plus. It was never flown as SpaceX moved the high-altitude testing program to its controlled-descent testing of used boosters following their use on a paid orbital launch and ascent.\n\nDragonFly was a prototype test article for a propulsively landed version of the SpaceX Dragon capsule, a suborbital reusable launch vehicle (RLV), intended for low-altitude flight testing. it was planned to undergo a test program in Texas at the McGregor Rocket Test Facility, during 2014–2015.\n\nThe DragonFly test vehicle is powered by eight SuperDraco engines, arranged in a redundant pattern to support fault-tolerance in the propulsion system design. SuperDracos utilize a storable propellant mixture of monomethyl hydrazine (MMH) fuel and nitrogen tetroxide oxidizer (NTO), the same propellants used in the much smaller Draco thrusters used for attitude control and maneuvering on the first-generation Dragon spacecraft.\nWhile SuperDraco engines are capable of of thrust, during use on DragonFly flight test vehicle each will be throttled to less than to maintain vehicle stability.\n\nA test flight program of thirty flights was proposed in 2013–2014, including two \"propulsive assist\" (parachutes plus thrusters) and two \"propulsive landing\" (no parachutes) on flights dropped from a helicopter at an altitude of approximately . The other 26 test flights were projected to take off from a pad: eight to be \"propulsive assist hops\" (landing with parachutes plus thrusters) and 18 to be \"full propulsive hops\", similar to the Grasshopper and F9R Dev booster stage test flights.\n, the DragonFly test program was not expected to start until after the completion of the F9R Dev1 booster testing at the McGregor facility.\n\nIn November 2018, SpaceX announced work on a heavily-modified Falcon 9 second stage that would be used for atmospheric reentry testing of a number of technologies needed for the full-scale BFR spaceship, including an ultra-light heat shield and high-Mach control surfaces. Musk indicated it would be \"upgraded to be like a mini-BFR ship\" but that the stage would not be used for landing tests, as the company already believes it has a good handle on propulsive landings. The first test flight of the modified stage is planned to be no earlier than mid-2019.\n\nAlso in November 2018, SpaceX announced that an initial \"BFR dev ship\" was under development to test landings of the -diameter ship design at the SpaceX South Texas Launch Site.\n\nIn an arrangement highly unusual for launch vehicles, SpaceX began in 2013 using some first stages of the Falcon 9 v1.1 rockets for propulsive-return controlled-descent flight tests after they completed the boost phase of an orbital flight. Since the advent of spaceflight in 1957, launch vehicle boosters would ordinarily just be discarded after setting their payloads on their way. The over-water tests started by SpaceX took place in the Pacific and Atlantic oceans south of Vandenberg Air Force Base and east of Cape Canaveral Air Force Station. The first flight test occurred on September 29, 2013, after the second stage with the CASSIOPE and nanosat payloads separated from the booster. These descent and simulated landing tests continued over the next two years, with the second flight test taking place on April 18, 2014, two more test in 2014, and four subsequent tests conducted in 2015. SpaceX continued to make iterative and incremental changes to the booster design, as well as the specific reusable technologies, descent profile and propellant margins, on some 2016-2018 Falcon 9 and Falcon Heavy flights to tweak the design and operational parameters. Many of these descent and landing tests were tested on active orbital spaceflight missions for SpaceX customers as the booster reentered the atmosphere and attempted recoverable landings. \n\nFollowing analysis of the flight test data from the first booster-controlled descent in September 2013, SpaceX announced it had successfully tested a large amount of new technology on the flight, and that coupled with the technology advancements made on the Grasshopper low-altitude landing demonstrator, they were ready to test a full recovery of the booster stage. The first flight test was successful; SpaceX said it was \"able to successfully transition from vacuum through hypersonic, through supersonic, through transonic, and light the engines all the way and control the stage all the way through [the atmosphere]\". Musk said, \"the next attempt to recovery [sic] the Falcon 9 first stage will be on the fourth flight of the upgraded rocket. This would be [the] third commercial Dragon cargo flight to ISS.\"\n\nThis second flight test took place during the April 2014 Dragon flight to the ISS. SpaceX attached landing legs to the first stage, decelerated it over the ocean and attempted a simulated landing over the water, following the ignition of the second stage on the third cargo resupply mission contracted to NASA. The first stage was successfully slowed down enough for a soft landing over the Atlantic Ocean. SpaceX announced in February 2014 the intent to continue the tests to land the first-stage booster in the ocean until precision control from hypersonic all the way through subsonic regimes has been proven.\nFive additional controlled-descent tests were conducted in the remainder of 2014 through April 2015, including two attempts to land on a floating landing platform—a SpaceX-built Autonomous Spaceport Drone Ship—on the Atlantic Ocean east of the launch site, both of which brought the vehicle to the landing platform, but neither of which resulted in a successful landing.\n\nDuring the 2015 launch hiatus, SpaceX requested regulatory approval from the FAA to attempt returning their next flight to Cape Canaveral instead of targeting a floating platform in the ocean. The goal was to land the booster vertically at the leased \"Landing Zone 1\" facility—the former Launch Complex 13 where SpaceX had recently built a large rocket landing pad.\nThe FAA approved the safety plan for the ground landing on December 18, 2015. The first stage landed successfully on target at 20:38 local time on December 21 (01:38 UTC on December 22).\n\nSpaceX does not plan to fly the \"Falcon 9 Flight 20\" first stage again. Rather, the rocket was moved a few miles north to the SpaceX hangar facilities at Launch pad 39A, recently refurbished by SpaceX at the adjacent Kennedy Space Center, where it was inspected before being used on January 15, 2016, to conduct a static fire test on its original launchpad, Launch Complex 40. This test aimed to assess the health of the recovered booster and the capability of this rocket design to fly repeatedly in the future. The tests delivered good overall results except for one of the outer engines experiencing thrust fluctuations. Elon Musk reported that this may have been due to debris ingestion.\n\nFalcon 9 Flight 21 launched the Jason-3 satellite on January 17, 2016, and attempted to land on the floating platform \"Just Read the Instructions\", located for the first time about out in the Pacific Ocean.\n\nApproximately 9 minutes into the flight, the live video feed from the drone ship went down due to the losing its lock on the uplink satellite.\nThe vehicle landed smoothly onto the vessel but one of the four landing legs failed to lock properly, reportedly due to ice from the heavy pre-launch fog preventing a lockout collet from latching.\nConsequently the booster fell over shortly after touchdown and was destroyed in a deflagration upon impact with the pad.\n\nFlight 22 was carrying a heavy payload of to geostationary transfer orbit (GTO). This was heavier than previously advertised maximum lift capacity to GTO being made possible by going slightly subsynchronous. Following delays caused by failure of Flight 19 SpaceX agreed to provide extra thrust to the SES-9 satellite to take it supersynchronous.\nAs a result of these factors, there was little propellant left to execute a full reentry and landing test with normal margins. Consequently the Falcon 9 first stage followed a ballistic trajectory after separation and re-entered the atmosphere at high velocity, making it less likely to land successfully. The atmospheric re-entry and controlled descent were successful despite the higher aerodynamical constraints on the first stage due to extra speed. However the rocket was moving too fast and was destroyed when it collided with the drone ship. SpaceX collected valuable data on the extended flight envelope required to recover boosters from GTO missions.\n\nStarting in January 2015, SpaceX positioned stable floating platforms a few hundred miles off the coast along the rocket trajectory; those transformed barges were called autonomous spaceport drone ships. On April 8, 2016, Falcon 9 Flight 23, the third flight of the full-thrust version, delivered the SpaceX CRS-8 cargo on its way to the International Space Station while the first stage conducted a boostback and re-entry maneuver over the Atlantic ocean. Nine minutes after liftoff, the booster landed vertically on the drone ship \"Of Course I Still Love You\", 300 km from the Florida coastline, achieving a long-sought-after milestone for the SpaceX reusability development program.\n\nA second successful drone ship landing occurred on May 6, 2016, with the next flight which launched JCSAT-14 to GTO. This second landing at sea was more difficult than the previous one because the booster at separation was traveling about compared to on the CRS-8 launch to low Earth orbit. Pursuing their experiments to test the limits of the flight envelope, SpaceX opted for a shorter landing burn with three engines instead of the single-engine burns seen in earlier attempts; this approach consumes less fuel by leaving the stage in free fall as long as possible and decelerating more sharply, thereby minimizing the amount of energy expended to counter gravity. Elon Musk indicated this first stage may not be flown again instead being used as a life leader for ground tests to confirm others are good.\n\nA third successful landing followed on 27 May, again following deceleration from the high speed required for a GTO launch. The landing crushed a \"crush core\" in one leg, leading to a notable tilt to the stage as it stood on the drone ship.\n\nOver the subsequent missions, landing of the first stage gradually became a routine procedure, and since January 2017 SpaceX ceased to refer to their landing attempts as \"experimental\". Low-energy missions to the ISS fly back to the launch site and land at LZ-1, whereas more demanding satellite missions land on drone ships a few hundred miles downrange. Occasional missions with heavy payloads, such as EchoStar 23, do not attempt to land, flying in expendable configuration without fins and legs.\n\nFurther successful landings occurred:\n\nDuring 2016 and 2017, SpaceX has recovered a number of first stages to both land and drone ships, helping them optimize the procedures needed to re-use the boosters rapidly. In January 2016 Elon Musk estimated the likelihood of success at 70 percent for all landing attempts in 2016, hopefully rising to 90 percent in 2017; he also cautioned that we should expect \"a few more RUDs\" (\"Rapid Unscheduled Disassembly\", Musk's euphemism to denote destruction of the vehicle on impact). Musk's prediction was vindicated, as 5 out of 8 flown boosters () were recovered in 2016, and 14 out of 14 () in 2017. Three GTO missions for heavy payloads (EchoStar 23 in March 2017, Inmarsat-5 F4 in May 2017 and Intelsat 35e in July 2017) were flown in an expendable configuration, not equipped for landing. One booster which could have been recovered was intentionally flown without legs and left to sink after a soft touchdown in the ocean (booster B1036 for the Iridium NEXT 31–40 mission in December 2017).\n\nSince late 2017, incremental testing with refinements to the fairing recovery design have been conducted. SpaceX has indicated that they expected to recover an intact fairing in 2017, and to fly a recovered fairing in 2018. , no official information on progress in the fairing recovery process was available.\n\n, SpaceX had recovered 21 first-stage boosters from previous missions, of which six were recovered twice, yielding a total 27 landings. In 2017, SpaceX flew a total of 5 missions out of 20 with re-used boosters (). In total, 14 boosters have been re-flown .\n\nOn July 28, 2016, the first stage from the JCSAT-2B mission was successfully test-fired for a full duration at the SpaceX McGregor facility. The first reuse attempt occurred on 30 March 2017 with the launch of SES-10, resulting in a successful flight and second landing of the B1021 first stage recovered from the CRS-8 mission of April 2016. Another reflight succeeded in June 2017 with BulgariaSat-1 riding the B1029 booster from the January 2017 Iridium NEXT mission. Booster B1031 flew the CRS-10 mission to the ISS in February 2017 and helped loft communications satellite SES-11 to geostationary orbit in October 2017. Boosters B1035 and B1036 were flown twice each for the same customer, B1035 for NASA missions CRS-11 and CRS-13 in June and December 2017, and B1036 for two batches of 10 Iridium NEXT satellites, also in June and December 2017. B1032 was re-used for GovSat-1 in January 2018 after NROL-76 in May 2017. Finally, B1023 and B1025 were re-used as side boosters on the Falcon Heavy test flight in February 2018.\n\nSpaceX spent four months refurbishing the first booster to be re-used, B1021, and launched it again after approximately one year. The second booster to be flown again, B1029, was refurbished in \"only a couple of months\" and re-launched after five months. Elon Musk initially stated a goal to turn around a first stage within 24 hours before the end of 2017. Musk remains convinced that this goal can be met, though SpaceX is now targeting 2019 to achieve it.\n\nBoosters B1019 and B1021 were retired and put on display. B1029 was also retired after the BulgariaSat-1 mission. B1023, B1025, B1031 and B1035 were recovered a second time, while B1032 and B1036 were deliberately sunk at sea after a soft ocean touchdown.\n\nWith a streak of 17 successful recovery attempts of the first stage throughout 2017, SpaceX has focused on rapid reusability of first stage boosters. Block 3 and Block 4 proved economically feasible to be flown twice, as 11 such boosters have been reflown in 2017 and 2018. Block 5 has been designed with multiple reuses in mind, up to 10 reuses with minimal inspection and up to 100 uses with refurbishment. New aggressive reentry profiles were experimented with expendable Block 3 and Block 4 boosters in early 2018, to test out the limitations on the range of recoverable launch margins that are potential for future Block 5.\n\nAs early as mid-2015, Musk hinted that SpaceX might be working on fairing reusability, following the discovery of wreckage of an unidentified Falcon 9 launch vehicle section off the coast of The Bahamas, and was subsequently confirmed by SpaceX to be a component of a payload fairing that had washed ashore. \nBy April 2016, they had publicly announced Falcon 9 fairing recovery as an objective. The cost of the fairing is about $6 million each, which accounts for 10 percent of the overall launch costs.\n\nIn March 2017, as part of the SES-10 mission, SpaceX for the first time performed a controlled landing of the payload fairing and successfully recovered a fairing half, aided by attitude-control thrusters and a steerable parachute, helping it glide towards a gentle touchdown on water.\nThe company announced intent to land the fairings eventually on a dry flexible structure, jokingly described by Musk as a \"floating bouncy-castle\", with the aim of full fairing reuse.\nWith successive tests and refinements on several flights, intact fairing recovery was stated as an objective for 2017, with reflight of a recovered fairing planned in 2018. \n\nThe \"bouncy castle\" idea was superseded by a net strung between large arms of a fast platform supply vessel named \"Mr. Steven\". The recovery vessel is equipped with dynamic positioning systems, and was tested after the launch of the Paz satellite from Vandenberg Air Force Base in that 2017. This mission was also the first to use a version 2 fairing, explicitly designed to \"improve survivability for post-launch recovery attempts, and to be reusable on future missions\". This recovery attempt was not fully successful; the fairing missed the boat by a few hundred meters but landed intact in the water before being recovered and taken back to port. , all four attempts by SpaceX to land a fairing on a recovery ship have failed, despite fitting \"Mr. Steven\" with larger nets before the July 2018 attempt.\n\nIn October 2018, at least two fairing recovery tests were performed, involving \"Mr. Steven\" and a helicopter, which would drop a fairing half from the height of about 3300 meters. The actual outcome of the tests is unclear.\n\nDespite early public statements that SpaceX would endeavor to make the Falcon 9 second-stage reusable as well, by late 2014, they determined that the mass needed for a re-entry heat shield, landing engines, and other equipment to support recovery of the second stage as well as the diversion of development resources from other company objectives was at that time prohibitive, and indefinitely suspended their second-stage reusability plans for the Falcon rockets.\nHowever, in July 2017 they indicated that they might do experimental tests on recovering one or more second-stages in order to learn more about reusability to inform their new, much-larger, \"BFR\" launch vehicle development process,\nand in May 2018 provided additional details about how they might carry out some of that testing.\n\nThe \"BFR\" is planned to replace all existing SpaceX launch and space vehicles after the mid-2020s: Falcon 9, Falcon Heavy and the Dragon spacecraft, aimed initially at the Earth-orbit launch market but with capability to support long-duration spaceflight in the cislunar and Mars mission environments.. Both stages will be fully reusable. The integrated second-stage-with-spaceship design has not been used in previous launch vehicles.\n\nIn the first year of successful stage return from the experimental test flights, SpaceX performed \"ad hoc\" and flight-specific evaluation and component testing on each successfully landed stage. Stages were processed and initially evaluated in either launch hangars, or for Cape Canaveral landings, in the new hangar SpaceX recently completed at Kennedy Space Center Launch Complex 39. Returned rocket parts have also been transported to SpaceX Hawthorne and SpaceX McGregor for engineering evaluation and testing.\n\nIn February 2017, after eight rocket cores had successfully landed — seven of them having launched from Cape Canaveral — SpaceX announced plans to expand their physical facilities to process and refurbish rockets. They will do so in both leased space and in a new building to be built in Port Canaveral, Florida, near the location where the Atlantic Autonomous Spaceport Drone Ship is berthed, and where stages that land on the east-coast droneship are now removed from the ship.\n\n\n"}
{"id": "47618653", "url": "https://en.wikipedia.org/wiki?curid=47618653", "title": "Stripped binary", "text": "Stripped binary\n\nCompiled binary files can contain debug information which is not necessary for program execution, rather it is useful for debugging and finding problems or bugs in the program. Stripped binary is a binary file without these debugging symbols and thus lesser in size and gives potentially better performance than a non-stripped binary.\n\nA stripped binary makes it hard to disassemble or reverse engineer which also in turn makes it difficult to find problems or bugs in the program.\n\nStripped binary can be produced with the help of the compiler itself, e.g. GNU GCC compilers' codice_1 flag, or with a dedicated tool like strip on Unix.\n\n"}
{"id": "10162367", "url": "https://en.wikipedia.org/wiki?curid=10162367", "title": "Sunset industry", "text": "Sunset industry\n\nA sunset industry is an industry in decline, one that has passed its peak or boom periods. As one example, analogue recording technologies for audio or video have been supplanted by digital equivalents; although analogue equipment is still offered, sales have declined dramatically and are not expected to recover, so this segment of the market has been branded a 'sunset industry'. Many countries try to protect domestic sunset industries as they still provide important employment. They use protectionism policies to slow down the decline whilst Sunrise industries develop.\n\n"}
{"id": "16943497", "url": "https://en.wikipedia.org/wiki?curid=16943497", "title": "TM Forum", "text": "TM Forum\n\nTM Forum is a non-profit industry association for service providers and their suppliers in the telecommunications industry. Members include communications and digital service providers, telephone companies, cable operators, network operators, software suppliers, equipment suppliers, systems integrators and management consultancies. , the Forum had over 850 member companies that collectively generate US$2 trillion in revenue and serve five billion customers across 180 countries.\n\nTM Forum provides an open, collaborative environment along with practical tools and information to help its members in their digital transformation initiatives. Its services include collaboration programs and proof-of-concept projects, industry research and benchmarks, technology roadmaps, best-practice guidebooks, business process guidelines and open APIs, as well as certified training, conferences and publications. The Forum also provides its member community with marketing and networking opportunities.\n\nTM Forum's work includes Frameworx, Business Process Framework (eTOM), Frameworx Shared Information/Data Model (SID) and Telecom Application Map (TAM).\n\nThe Object Management Group endorsed some of the TM Forum's specifications in a telecommunications special interest group by 2004.\nAs the term \"cloud computing\" became popular, in 2009 TM Forum joined a group called the Cloud Standards Coordination Working Group.\n\nThe TM Forum expanded its scope of activities to include digital transition. In this context, it defined in 2016 the Digital Maturity Model (DMM) and launched several initiatives and projects to address the sectorial or horizontal needs of digital consumers: \n\nThe OSI/Network Management Forum was founded in 1988 by eight companies to collaboratively solve systems and operational management issues with the OSI protocols.\nIn 1998 the name was changed to the TeleManagement Forum.\n\nA group called the Infranet Initiative Council was created by Juniper Networks in April 2004.\nThe group said it was concerned with quality, reliability and security interfaces between telecommunications service providers that were providing services for the Internet.\nPradeep Sindhu used the term \"infranet\" to compare the public Internet to more traditional physical infrastructure.\nJuniper was joined by British Telecom, China Unicom, Ericsson, France Télécom, Hewlett-Packard, KT Corporation, Siemens, Telenor, and Tellabs.\nThe IPsphere Forum was founded in June 2005 at the Supercomm 2005 trade show in Chicago with those members.\nCisco Systems and Alcatel were added when it adopted the IPsphere name.\nNippon Telegraph and Telephone (NTT) joined in 2007,\nand it established a liaison with the Tele-Management Forum later that year.\nIPsphere was mentioned by executives in a trade show during 2007.\nBy September 2008 IPsphere Forum merged with TM Forum.\n\nThe TM Forum held marketing events called \"Content Encounters\" at the Management World trade shows in 2007 through 2009.\n\n"}
{"id": "27452465", "url": "https://en.wikipedia.org/wiki?curid=27452465", "title": "Telecommunications equipment", "text": "Telecommunications equipment\n\nTelecommunications equipment (also telecoms equipment or communications equipment) is hardware used for the purposes of telecommunications. Since the 1990s the boundary between telecoms equipment and IT hardware has become blurred as a result of the growth of the internet and its increasing role in the transfer of telecoms data.\n\nTelecommunications equipment can be broadly broken down into the following categories:\n\n\nThe world's ten largest telecommunications equipment vendors, 2017 revenues are:\n"}
{"id": "288276", "url": "https://en.wikipedia.org/wiki?curid=288276", "title": "Usability", "text": "Usability\n\nUsability is the ease of use and learnability of a human-made object such as a tool or device. In software engineering, usability is the degree to which a software can be used by specified consumers to achieve quantified objectives with effectiveness, efficiency, and satisfaction in a quantified context of use.\n\nThe object of use can be a software application, website, book, tool, machine, process, vehicle, or anything a human interacts with. A usability study may be conducted as a primary job function by a \"usability analyst\" or as a secondary job function by designers, technical writers, marketing personnel, and others. It is widely used in consumer electronics, communication, and knowledge transfer objects (such as a cookbook, a document or online help) and mechanical objects such as a door handle or a hammer.\n\nUsability includes methods of measuring usability, such as needs analysis and the study of the principles behind an object's perceived efficiency or elegance. In human-computer interaction and computer science, usability studies the elegance and clarity with which the interaction with a computer program or a web site (web usability) is designed. Usability considers user satisfaction and utility as quality components, and aims to improve user experience through iterative design.\n\nThe primary notion of usability is that an object designed with a generalized users' psychology and physiology in mind is, for example:\n\nComplex computer systems find their way into everyday life, and at the same time the market is saturated with competing brands. This has made usability more popular and widely recognized in recent years, as companies see the benefits of researching and developing their products with user-oriented methods instead of technology-oriented methods. By understanding and researching the interaction between product and user, the \"usability expert\" can also provide insight that is unattainable by traditional company-oriented market research. For example, after observing and interviewing users, the usability expert may identify needed functionality or design flaws that were not anticipated. A method called \"contextual inquiry\" does this in the naturally occurring context of the users own environment. In the user-centered design paradigm, the product is designed with its intended users in mind at all times. In the user-driven or participatory design paradigm, some of the users become actual or de facto members of the design team.\n\nThe term \"user friendly\" is often used as a synonym for \"usable\", though it may also refer to accessibility. Usability describes the quality of user experience across websites, software, products, and environments. There is no consensus about the relation of the terms ergonomics (or human factors) and usability. Some think of usability as the software specialization of the larger topic of ergonomics. Others view these topics as tangential, with ergonomics focusing on physiological matters (e.g., turning a door handle) and usability focusing on psychological matters (e.g., recognizing that a door can be opened by turning its handle). Usability is also important in website development (web usability). According to Jakob Nielsen, \"Studies of user behavior on the Web find a low tolerance for difficult designs or slow sites. People don't want to wait. And they don't want to learn how to use a home page. There's no such thing as a training class or a manual for a Web site. People have to be able to grasp the functioning of the site immediately after scanning the home page—for a few seconds at most.\" Otherwise, most casual users simply leave the site and browse or shop elsewhere.\n\nISO defines usability as \"The extent to which a product can be used by specified users to achieve specified goals with effectiveness, efficiency, and satisfaction in a specified context of use.\" The word \"usability\" also refers to methods for improving ease-of-use during the design process. Usability consultant Jakob Nielsen and computer science professor Ben Shneiderman have written (separately) about a framework of system acceptability, where usability is a part of \"usefulness\" and is composed of:\n\nUsability is often associated with the functionalities of the product (cf. ISO definition, below), in addition to being solely a characteristic of the user interface (cf. framework of system acceptability, also below, which separates \"usefulness\" into \"usability\" and \"utility\"). For example, in the context of mainstream consumer products, an automobile lacking a reverse gear could be considered \"unusable\" according to the former view, and \"lacking in utility\" according to the latter view. When evaluating user interfaces for usability, the definition can be as simple as \"the perception of a target user of the effectiveness (fit for purpose) and efficiency (work or time required to use) of the Interface\". Each component may be measured subjectively against criteria, e.g., Principles of User Interface Design, to provide a metric, often expressed as a percentage. It is important to distinguish between usability testing and usability engineering. Usability testing is the measurement of ease of use of a product or piece of software. In contrast, usability engineering (UE) is the research and design process that ensures a product with good usability. Usability is a non-functional requirement. As with other non-functional requirements, usability cannot be directly measured but must be quantified by means of indirect measures or attributes such as, for example, the number of reported problems with ease-of-use of a system.\n\nThe term intuitive is often listed as a desirable trait in usable interfaces, often used as a synonym for learnable. Some experts such as Jef Raskin have discouraged using this term in user interface design, claiming that easy to use interfaces are often easy because of the user's exposure to previous similar systems, thus the term 'familiar' should be preferred. As an example: Two vertical lines \"||\" on media player buttons do not intuitively mean \"pause\"—they do so by convention. Aiming for \"intuitive\" interfaces (based on reusing existing skills with interaction systems) could lead designers to discard a better design solution only because it would require a novel approach. This position is sometimes illustrated with the remark that \"The only intuitive interface is the nipple; everything else is learned.\" Bruce Tognazzini even denies the existence of \"intuitive\" interfaces, since such interfaces must be able to intuit, i.e., \"perceive the patterns of the user's behavior and draw inferences.\" Instead, he advocates the term \"intuitable,\" i.e., \"that users could intuit the workings of an application by seeing it and using it.\" He continues, however, \"But even that is a less than useful goal since only 25 percent of the population depends on intuition to perceive anything.\"\n\nISO/TR 16982:2002 (\"Ergonomics of human-system interaction—Usability methods supporting human-centered design\") is an International Standards Organization (ISO) standard that provides information on human-centered usability methods that can be used for design and evaluation. It details the advantages, disadvantages, and other factors relevant to using each usability method. It explains the implications of the stage of the life cycle and the individual project characteristics for the selection of usability methods and provides examples of usability methods in context. The main users of ISO/TR 16982:2002 are project managers. It therefore addresses technical human factors and ergonomics issues only to the extent necessary to allow managers to understand their relevance and importance in the design process as a whole. The guidance in ISO/TR 16982:2002 can be tailored for specific design situations by using the lists of issues characterizing the context of use of the product to be delivered. Selection of appropriate usability methods should also take account of the relevant life-cycle process. ISO/TR 16982:2002 is restricted to methods that are widely used by usability specialists and project managers. It does \"not\" specify the details of how to implement or carry out the usability methods described.\n\nISO 9241 is a multi-part standard that covers a number of aspects of people working with computers. Although originally titled \"Ergonomic requirements for office work with visual display terminals (VDTs)\", it has been retitled to the more generic \"Ergonomics of Human System Interaction\". As part of this change, ISO is renumbering some parts of the standard so that it can cover more topics, e.g. tactile and haptic interaction. The first part to be renumbered was part 10 in 2006, now part 110.\n\nAny system or device designed for use by people should be easy to use, easy to learn, easy to remember (the instructions), and helpful to users. John Gould and Clayton Lewis recommend that designers striving for usability follow these three design principles\n\n\nThe design team should be user-driven and it should be in direct contact with potential users. Several evaluation methods, including personas, cognitive modeling, inspection, inquiry, prototyping, and testing methods may contribute to understanding potential users and their perceptions of how well the product or process works. Usability considerations, such as who the users are and their experience with similar systems must be examined. As part of understanding users, this knowledge must \"...be played against the tasks that the users will be expected to perform.\" This includes the analysis of what tasks the users will perform, which are most important, and what decisions the users will make while using your system. Designers must understand how cognitive and emotional characteristics of users will relate to a proposed system. One way to stress the importance of these issues in the designers' minds is to use personas, which are made-up representative users. See below for further discussion of personas. Another more expensive but more insightful method is to have a panel of potential users work closely with the design team from the early stages.\n\nTest the system early on, and test the system on real users using behavioral measurements. This includes testing the system for both learnability and usability. (See Evaluation Methods). It is important in this stage to use quantitative usability specifications such as time and errors to complete tasks and number of users to test, as well as examine performance and attitudes of the users testing the system. Finally, \"reviewing or demonstrating\" a system before the user tests it can result in misleading results. The emphasis of empirical measurement is on measurement, both informal and formal, which can be carried out through a variety of evaluation methods.\n\nIterative design is a design methodology based on a cyclic process of prototyping, testing, analyzing, and refining a product or process. Based on the results of testing the most recent iteration of a design, changes and refinements are made. This process is intended to ultimately improve the quality and functionality of a design. In iterative design, interaction with the designed system is used as a form of research for informing and evolving a project, as successive versions, or iterations of a design are implemented. The key requirements for Iterative Design are: identification of required changes, an ability to make changes, and a willingness to make changes. When a problem is encountered, there is no set method to determine the correct solution. Rather, there are empirical methods that can be used during system development or after the system is delivered, usually a more inopportune time. Ultimately, iterative design works towards meeting goals such as making the system user friendly, easy to use, easy to operate, simple, etc.\n\nThere are a variety of usability evaluation methods. Certain methods use data from users, while others rely on usability experts. There are usability evaluation methods for all stages of design and development, from product definition to final design modifications. When choosing a method, consider cost, time constraints, and appropriateness. For a brief overview of methods, see Comparison of usability evaluation methods or continue reading below. Usability methods can be further classified into the subcategories below.\n\nCognitive modeling involves creating a computational model to estimate how long it takes people to perform a given task. Models are based on psychological principles and experimental studies to determine times for cognitive processing and motor movements. Cognitive models can be used to improve user interfaces or predict problem errors and pitfalls during the design process. A few examples of cognitive models include:\n\nWith parallel design, several people create an initial design from the same set of requirements. Each person works independently, and when finished, shares concepts with the group. The design team considers each solution, and each designer uses the best ideas to further improve their own solution. This process helps generate many different, diverse ideas, and ensures that the best ideas from each design are integrated into the final concept. This process can be repeated several times until the team is satisfied with the final concept.\n\n\n\"GOMS\" stands for \"goals, operator, methods, and selection rules\". It is a family of techniques that analyzes the user complexity of interactive systems. Goals are what the user must accomplish. An operator is an action performed in pursuit of a goal. A method is a sequence of operators that accomplish a goal. Selection rules specify which method satisfies a given goal, based on context.\n\n\nSometimes it is useful to break a task down and analyze each individual aspect separately. This helps the tester locate specific areas for improvement. To do this, it is necessary to understand how the human brain processes information. A model of the human processor is shown below.\n\nMany studies have been done to estimate the cycle times, decay times, and capacities of each of these processors. Variables that affect these can include subject age, aptitudes, ability, and the surrounding environment. For a younger adult, reasonable estimates are:\n\nLong-term memory is believed to have an infinite capacity and decay time.\n\n\nKeystroke level modeling is essentially a less comprehensive version of GOMS that makes simplifying assumptions in order to reduce calculation time and complexity.\n\nThese usability evaluation methods involve observation of users by an experimenter, or the testing and evaluation of a program by an expert reviewer. They provide more quantitative data as tasks can be timed and recorded.\n\nCard sorting is a way to involve users in grouping information for a website's usability review. Participants in a card sorting session are asked to organize the content from a Web site in a way that makes sense to them. Participants review items from a Web site and then group these items into categories. Card sorting helps to learn how users think about the content and how they would organize the information on the Web site. Card sorting helps to build the structure for a Web site, decide what to put on the home page, and label the home page categories. It also helps to ensure that information is organized on the site in a way that is logical to users.\n\nTree testing is a way to evaluate the effectiveness of a website's top-down organization. Participants are given \"find it\" tasks, then asked to drill down through successive text lists of topics and subtopics to find a suitable answer. Tree testing evaluates the findability and labeling of topics in a site, separate from its navigation controls or visual design.\n\nEthnographic analysis is derived from anthropology. Field observations are taken at a site of a possible user, which track the artifacts of work such as Post-It notes, items on desktop, shortcuts, and items in trash bins. These observations also gather the sequence of work and interruptions that determine the user's typical day.\n\nHeuristic evaluation is a usability engineering method for finding and assessing usability problems in a user interface design as part of an iterative design process. It involves having a small set of evaluators examining the interface and using recognized usability principles (the \"heuristics\"). It is the most popular of the usability inspection methods, as it is quick, cheap, and easy. Heuristic evaluation was developed to aid in the design of computer user-interface design. It relies on expert reviewers to discover usability problems and then categorize and rate them by a set of principles (heuristics.) It is widely used based on its speed and cost-effectiveness. Jakob Nielsen's list of ten heuristics is the most commonly used in industry. These are ten general principles for user interface design. They are called \"heuristics\" because they are more in the nature of rules of thumb than specific usability guidelines.\n\nThus, by determining which guidelines are violated, the usability of a device can be determined.\n\nUsability inspection is a review of a system based on a set of guidelines. The review is conducted by a group of experts who are deeply familiar with the concepts of usability in design. The experts focus on a list of areas in design that have been shown to be troublesome for users.\n\nPluralistic Inspections are meetings where users, developers, and human factors people meet together to discuss and evaluate step by step of a task scenario. As more people inspect the scenario for problems, the higher the probability to find problems. In addition, the more interaction in the team, the faster the usability issues are resolved.\n\nIn consistency inspection, expert designers review products or projects to ensure consistency across multiple products to look if it does things in the same way as their own designs.\n\nActivity analysis is a usability method used in preliminary stages of development to get a sense of situation. It involves an investigator observing users as they work in the field. Also referred to as user observation, it is useful for specifying user requirements and studying currently used tasks and subtasks. The data collected are qualitative and useful for defining the problem. It should be used when you wish to frame what is needed, or \"What do we want to know?\"\n\nThe following usability evaluation methods involve collecting qualitative data from users. Although the data collected is subjective, it provides valuable information on what the user wants.\n\nTask analysis means learning about users' goals and users' ways of working. Task analysis can also mean figuring out what more specific tasks users must do to meet those goals and what steps they must take to accomplish those tasks. Along with user and task analysis, a third analysis is often used: understanding users' environments (physical, social, cultural, and technological environments).\n\nA focus group is a focused discussion where a moderator leads a group of participants through a set of questions on a particular topic. Although typically used as a marketing tool, Focus Groups are sometimes used to evaluate usability. Used in the product definition stage, a group of 6 to 10 users are gathered to discuss what they desire in a product. An experienced focus group facilitator is hired to guide the discussion to areas of interest for the developers. Focus groups are typically videotaped to help get verbatim quotes, and clips are often used to summarize opinions. The data gathered is not usually quantitative, but can help get an idea of a target group's opinion.\n\nSurveys have the advantages of being inexpensive, require no testing equipment, and results reflect the users' opinions. When written carefully and given to actual users who have experience with the product and knowledge of design, surveys provide useful feedback on the strong and weak areas of the usability of a design. This is a very common method and often does not appear to be a survey, but just a warranty card.\n\nIt is often very difficult for designers to conduct usability tests with the exact system being designed. Cost constraints, size, and design constraints usually lead the designer to creating a prototype of the system. Instead of creating the complete final system, the designer may test different sections of the system, thus making several small models of each component of the system. The types of usability prototypes may vary from using paper models, index cards, hand drawn models, or storyboards. Prototypes are able to be modified quickly, often are faster and easier to create with less time invested by designers and are more apt to change design; although sometimes are not an adequate representation of the whole system, are often not durable and testing results may not be parallel to those of the actual system.\n\nRapid prototyping is a method used in early stages of development to validate and refine the usability of a system. It can be used to quickly and cheaply evaluate user-interface designs without the need for an expensive working model. This can help remove hesitation to change the design, since it is implemented before any real programming begins. One such method of rapid prototyping is paper prototyping.\n\nThese usability evaluation methods involve testing of subjects for the most quantitative data. Usually recorded on video, they provide task completion time and allow for observation of attitude. Regardless to how carefully a system is designed, all theories must be tested using usability tests. Usability tests involve typical users using the system (or product) in a realistic environment [see simulation]. Observation of the user's behavior, emotions, and difficulties while performing different tasks, often identify areas of improvement for the system.\n\nWhile conducting usability tests, designers must use usability metrics to identify what it is they are going to measure, or the usability metrics. These metrics are often variable, and change in conjunction with the scope and goals of the project. The number of subjects being tested can also affect usability metrics, as it is often easier to focus on specific demographics. Qualitative design phases, such as general usability (can the task be accomplished?), and user satisfaction are also typically done with smaller groups of subjects. Using inexpensive prototypes on small user groups provides more detailed information, because of the more interactive atmosphere, and the designer's ability to focus more on the individual user.\n\nAs the designs become more complex, the testing must become more formalized. Testing equipment will become more sophisticated and testing metrics become more quantitative. With a more refined prototype, designers often test effectiveness, efficiency, and subjective satisfaction, by asking the user to complete various tasks. These categories are measured by the percent that complete the task, how long it takes to complete the tasks, ratios of success to failure to complete the task, time spent on errors, the number of errors, rating scale of satisfactions, number of times user seems frustrated, etc. Additional observations of the users give designers insight on navigation difficulties, controls, conceptual models, etc. The ultimate goal of analyzing these metrics is to find/create a prototype design that users like and use to successfully perform given tasks. After conducting usability tests, it is important for a designer to record what was observed, in addition to why such behavior occurred and modify the model according to the results. Often it is quite difficult to distinguish the source of the design errors, and what the user did wrong. However, effective usability tests will not generate a solution to the problems, but provide modified design guidelines for continued testing.\n\nRemote usability testing (also known as unmoderated or asynchronous usability testing) involves the use of a specially modified online survey, allowing the quantification of user testing studies by providing the ability to generate large sample sizes, or a deep qualitative analysis without the need for dedicated facilities. Additionally, this style of user testing also provides an opportunity to segment feedback by demographic, attitudinal and behavioral type. The tests are carried out in the user's own environment (rather than labs) helping further simulate real-life scenario testing. This approach also provides a vehicle to easily solicit feedback from users in remote areas. There are two types, quantitative or qualitative. Quantitative use large sample sized and task based surveys. These types of studies are useful for validating suspected usability issues. Qualitative studies are best used as exploratory research, in small sample sizes but frequent, even daily iterations. Qualitative usually allows for observing respondent's screens and verbal think aloud commentary (Screen Recording Video, SRV), and for a richer level of insight also include the webcam view of the respondent (Video-in-Video, ViV, sometimes referred to as Picture-in-Picture, PiP)\n\nThe growth in mobile and associated platforms and services (e.g.: Mobile gaming has experienced 20x growth in 2010-2012) has generated a need for unmoderated remote usability testing on mobile devices, both for websites but especially for app interactions. One methodology consists of shipping cameras and special camera holding fixtures to dedicated testers, and having them record the screens of the mobile smart-phone or tablet device, usually using an HD camera. A drawback of this approach is that the finger movements of the respondent can obscure the view of the screen, in addition to the bias and logistical issues inherent in shipping special hardware to selected respondents. A newer approach uses a wireless projection of the mobile device screen onto the computer desktop screen of the respondent, who can then be recorded through their webcam, and thus a combined Video-in-Video view of the participant and the screen interactions viewed simultaneously while incorporating the verbal think aloud commentary of the respondents.\n\nThe Think aloud protocol is a method of gathering data that is used in both usability and psychology studies. It involves getting a user to verbalize their thought processes as they perform a task or set of tasks. Often an instructor is present to prompt the user into being more vocal as they work. Similar to the Subjects-in-Tandem method, it is useful in pinpointing problems and is relatively simple to set up. Additionally, it can provide insight into the user's attitude, which can not usually be discerned from a survey or questionnaire.\n\nRapid Iterative Testing and Evaluation (RITE) is an iterative usability method similar to traditional \"discount\" usability testing. The tester and team must define a target population for testing, schedule participants to come into the lab, decide on how the users behaviors will be measured, construct a test script and have participants engage in a verbal protocol (e.g., think aloud). However it differs from these methods in that it advocates that changes to the user interface are made as soon as a problem is identified and a solution is clear. Sometimes this can occur after observing as few as 1 participant. Once the data for a participant has been collected the usability engineer and team decide if they will be making any changes to the prototype prior to the next participant. The changed interface is then tested with the remaining users.\n\nSubjects-in-tandem (also called co-discovery) is the pairing of subjects in a usability test to gather important information on the ease of use of a product. Subjects tend to discuss the tasks they have to accomplish out loud and through these discussions observers learn where the problem areas of a design are. To encourage co-operative problem-solving between the two subjects, and the attendant discussions leading to it, the tests can be designed to make the subjects dependent on each other by assigning them complementary areas of responsibility (e.g. for testing of software, one subject may be put in charge of the mouse and the other of the keyboard.)\n\nComponent-based usability testing is an approach which aims to test the usability of elementary units of an interaction system, referred to as interaction components. The approach includes component-specific quantitative measures based on user interaction recorded in log files, and component-based usability questionnaires.\n\nCognitive walkthrough is a method of evaluating the user interaction of a working prototype or final product. It is used to evaluate the system's ease of learning. Cognitive walk through is useful to understand the user's thought processes and decision making when interacting with a system, specially for first-time or infrequent users.\n\nBenchmarking creates standardized test materials for a specific type of design. Four key characteristics are considered when establishing a benchmark: time to do the core task, time to fix errors, time to learn applications, and the functionality of the system. Once there is a benchmark, other designs can be compared to it to determine the usability of the system. Many of the common objectives of usability studies, such as trying to understand user behavior or exploring alternative designs, must be put aside. Unlike many other usability methods or types of labs studies, benchmark studies more closely resemble true experimental psychology lab studies, with greater attention to detail on methodology, study protocol and data analysis.\n\nMeta-analysis is a statistical procedure to combine results across studies to integrate the findings. This phrase was coined in 1976 as a quantitative literature review. This type of evaluation is very powerful for determining the usability of a device because it combines multiple studies to provide very accurate quantitative support.\n\nPersonas are fictitious characters created to represent a site or product's different user types and their associated demographics and technographics. Alan Cooper introduced the concept of using personas as a part of interactive design in 1998 in his book \"The Inmates Are Running the Asylum\", but had used this concept since as early as 1975. Personas are a usability evaluation method that can be used at various design stages. The most typical time to create personas is at the beginning of designing so that designers have a tangible idea of who the users of their product will be. Personas are the archetypes that represent actual groups of users and their needs, which can be a general description of person, context, or usage scenario. This technique turns marketing data on target user population into a few physical concepts of users to create empathy among the design team, with the final aim of tailoring a product more closely to how the personas will use it. To gather the marketing data that personas require, several tools can be used, including online surveys, web analytics, customer feedback forms, and usability tests, and interviews with customer-service representatives.\n\nThe key benefits of usability are:\n\nAn increase in usability generally positively affects several facets of a company's output quality. In particular, the benefits fall into several common areas:\n\nIncreased usability in the workplace fosters several responses from employees: \"Workers who enjoy their work do it better, stay longer in the face of temptation, and contribute ideas and enthusiasm to the evolution of enhanced productivity.\" To create standards, companies often implement experimental design techniques that create baseline levels. Areas of concern in an office environment include (though are not necessarily limited to):\n\nBy working to improve said factors, corporations can achieve their goals of increased output at lower costs, while potentially creating optimal levels of customer satisfaction. There are numerous reasons why each of these factors correlates to overall improvement. For example, making software user interfaces easier to understand reduces the need for extensive training. The improved interface tends to lower the time needed to perform tasks, and so would both raise the productivity levels for employees and reduce development time (and thus costs). Each of the aforementioned factors are not mutually exclusive; rather they should be understood to work in conjunction to form the overall workplace environment. In the 2010s, usability is recognized as an important software quality attribute, earning its place among more traditional attributes such as performance, robustness and aesthetic appearance. Various academic programs focus on usability. Several usability consultancy companies have emerged, and traditional consultancy and design firms offer similar services.\n\nThere is some resistance to integrating usability work in organisations. Usability is seen as a vague concept, it is difficult to measure and other areas are prioritised when IT projects run out of time or money.\n\nUsability practitioners are sometimes trained as industrial engineers, psychologists, kinesiologists, systems design engineers, or with a degree in information architecture, information or library science, or Human-Computer Interaction (HCI). More often though they are people who are trained in specific applied fields who have taken on a usability focus within their organization. Anyone who aims to make tools easier to use and more effective for their desired function within the context of work or everyday living can benefit from studying usability principles and guidelines. For those seeking to extend their training, the Usability Professionals' Association offers online resources, reference lists, courses, conferences, and local chapter meetings. The UPA also sponsors World Usability Day each November. Related professional organizations include the Human Factors and Ergonomics Society (HFES) and the Association for Computing Machinery's special interest groups in Computer Human Interaction (SIGCHI), Design of Communication (SIGDOC) and Computer Graphics and Interactive Techniques (SIGGRAPH). The Society for Technical Communication also has a special interest group on Usability and User Experience (UUX). They publish a quarterly newsletter called \"Usability Interface\".\n\n\n"}
{"id": "616960", "url": "https://en.wikipedia.org/wiki?curid=616960", "title": "Watering can", "text": "Watering can\n\nA watering can (or watering pot) is a portable container, usually with a handle and a spout, used to water plants by hand. It has been in use since at least 79 A.D. and has since seen many improvements in design. Apart from watering plants, it has varied uses, as it is a fairly versatile tool.\n\nThe capacity of the container can be anywhere from 0.5 litres (for indoor household plants) to 10 litres (for general garden use). It is usually made of metal, ceramic or plastic. At the end of the spout, a \"rose\" (a device, like a cap, with small holes) can be placed to break up the stream of water into droplets, to avoid excessive water pressure on the soil or on delicate plants.\n\nThe term \"watering can\" first appeared in the 1000s\n. Earlier, it had been known as a \"watering pot\". \n\nIn 1886 the \"Haws\" watering can was patented by John Haws. The patent read \"This new invention forms a watering pot that is much easier to carry and tip, and at the same time being much cleaner, and more adapted for use than any other put before the public.\"\n\nWatering cans are used by gardeners for watering plants by road workers to apply bitumen to asphalt, as ornaments, and regularly in symbolic art pieces.\n\n"}
