{"id": "8105227", "url": "https://en.wikipedia.org/wiki?curid=8105227", "title": "Aleutia", "text": "Aleutia\n\nAleutia Computers Ltd. (pronounced \"al-oo-sha\") is a privately owned computer manufacturer based in London, United Kingdom. Its product range consists of low-power desktop and server computers. Its products are used in the developing world and as original base designs for externally branded products. Its computers have been purchased by Unicef, Tesco, Schlumberger, Pret a Manger, Virgin Media, and the National Health Service. All computers come with the option to ship a version of Ubuntu or Linux Mint, alongside the mainstream choice of Microsoft Windows.\n\nAleutia was founded in London by Michael Rosenberg in October 2006, motivated by the unreliability, inefficiency, and expense of the Hewlett-Packard PCs in the internet cafe he had set up in Takoradi, Ghana in the summer of 2006.\n\nIts first product was the E1, which was introduced for public sale in October 2007, was a fanless, low-power computer targeting the need for energy efficient computers in Africa.\n\nMost of the company's employees as shown on the website are now either retired or working elsewhere. The company stopped responding to telephone calls and emails in early 2018 and has effectively ceased trading.\n\nThe T series of Atom-based nettop PCs is the longest-running and most popular. It comprises the T1 and the All-in-One, and the discontinued T1-R and T2.\n\nThe discontinued D series of desktop PCs are more powerful than the T series. It comprises the D1, D2, and D3.\n\nAleutia supplies the T1 computers used as point-of-sale servers in every Pret a Manger store in the United Kingdom, United States and Hong Kong running Omnico Hospitality software.\n\nA project being run by the Uganda Communications Commission to provide ICT to all Ugandan schools has chosen the T1 over the Asus Eee due to the T1's fan-less design.\n\nThe Ethiopia ConnectED project aimed to \"build a solar-powered computer learning center that integrated the technology, theories of change, and pedagogical practices from the Hole-in-the-Wall, Education for All, and One Laptop Per Child initiatives.\" Aleutia supplied T1 PCs running Edubuntu, along with LED monitors, and solar kits.\n\nAleutia supplies the hardware and \"eClinic\" software used on the ground by the \"Access to Basic Care\" (ABC) programme, which runs 12 healthcare clinics in Oyo State, Nigeria.\n"}
{"id": "54300981", "url": "https://en.wikipedia.org/wiki?curid=54300981", "title": "Alison Vincent", "text": "Alison Vincent\n\nAlison Vincent is the Chief Technology Officer for Cisco in the UK and Ireland.\n\nVincent worked for NDS before it was acquired by Cisco in 2012 and has worked for Cisco since then. Previously, she worked at IBM and at Micro Focus. She specializes in introducing agile methodologies to organizations.\n\nShe holds a PhD in Mathematics and Cryptography and a BSc in Mathematics and Computer Science from Royal Holloway, University of London.\n"}
{"id": "96590", "url": "https://en.wikipedia.org/wiki?curid=96590", "title": "Ammonium nitrate", "text": "Ammonium nitrate\n\nAmmonium nitrate is a chemical compound, the nitrate salt of the ammonium cation. It has the chemical formula NHNO, simplified to NHO. It is a white crystal solid and is highly soluble in water. It is predominantly used in agriculture as a high-nitrogen fertilizer. Its other major use is as a component of explosive mixtures used in mining, quarrying, and civil construction. It is the major constituent of ANFO, a popular industrial explosive which accounts for 80% of explosives used in North America; similar formulations have been used in improvised explosive devices. Many countries are phasing out its use in consumer applications due to concerns over its potential for misuse.\n\nAmmonium nitrate is found as a natural mineral (gwihabaite — the ammonium analogue of saltpetre, which is correctly called niter, and other nitre minerals such as sodium nitrate known as nitratine) in the driest regions of the Atacama Desert in Chile, often as a crust on the ground and/or in conjunction with other nitrate, iodate, and halide minerals. Ammonium nitrate was mined there in the past, but virtually 100% of the chemical now used is synthetic.\n\nThe industrial production of ammonium nitrate entails the acid-base reaction of ammonia with nitric acid:\nAmmonia is used in its anhydrous form (i.e., gas form) and the nitric acid is concentrated. This reaction is violent owing to its highly exothermic nature. After the solution is formed, typically at about 83% concentration, the excess water is evaporated to an ammonium nitrate (AN) content of 95% to 99.9% concentration (AN melt), depending on grade. The AN melt is then made into \"prills\" or small beads in a spray tower, or into granules by spraying and tumbling in a rotating drum. The prills or granules may be further dried, cooled, and then coated to prevent caking. These prills or granules are the typical AN products in commerce.\n\nThe ammonia required for this process is obtained by the Haber process from nitrogen and hydrogen. Ammonia produced by the Haber process is oxidized to nitric acid by the Ostwald process. Another production method is a variant of the Odda process:\n\nThe products, calcium carbonate and ammonium nitrate, may be separately purified or sold combined as calcium ammonium nitrate.\n\nAmmonium nitrate can also be made via metathesis reactions:\n\nAmmonium nitrate reacts with metal hydroxides, releasing ammonia and forming alkali metal nitrate:\n\nAmmonium nitrate leaves no residue when heated:\n\nWhen rapidly heated or exploded the predominant reaction is:\n\nAmmonium nitrate is also formed in the atmosphere from emissions of NO, SO, and NH, and is a secondary component of some PM particulates.\n\nTransformations of the crystal states due to changing conditions (temperature, pressure) affect the physical properties of ammonium nitrate. These crystalline states have been identified:\n\nThe type V crystal is a quasicubic form related to caesium chloride, the nitrogen atoms of the nitrate anions and the ammonium cations are at the sites in a cubic array where Cs and Cl would be in the CsCl lattice.\n\nAmmonium nitrate is an important fertilizer with the NPK rating 34-0-0 (34% nitrogen). It is less concentrated than urea (46-0-0), giving ammonium nitrate a slight transportation disadvantage. Ammonium nitrate's advantage over urea is that it is more stable and does not rapidly lose nitrogen to the atmosphere.\n\nAmmonium nitrate is not, on its own, an explosive, but it readily forms explosive mixtures with varying properties when combined with primary explosives such as azides or with fuels such as aluminum powder or fuel oil.\n\nANFO is a mixture of 94% ammonium nitrate (\"AN\") and 6% fuel oil (\"FO\") widely used as a bulk industrial explosive. It is used in coal mining, quarrying, metal mining, and civil construction in undemanding applications where the advantages of ANFO's low cost and ease of use matter more than the benefits offered by conventional industrial explosives, such as water resistance, oxygen balance, high detonation velocity, and performance in small diameters.\n\nAmmonium nitrate-based explosives were used in the Sterling Hall bombing in Madison, Wisconsin, 1970, the Oklahoma City bombing in 1995, the 2011 Delhi bombings, the 2013 Hyderabad blasts, and the 2011 bombing in Oslo.\n\nIn November 2009, a ban on ammonium sulfate, ammonium nitrate, and calcium ammonium nitrate fertilizers was imposed in the former Malakand Division—comprising the Upper Dir, Lower Dir, Swat, Chitral, and Malakand districts of the North West Frontier Province (NWFP) of Pakistan—by the NWFP government, following reports that those chemicals were used by militants to make explosives. Due to these bans, \"Potassium chlorate — the stuff that makes matches catch fire — has surpassed fertilizer as the explosive of choice for insurgents.\"\n\nAmmonium nitrate is used in some instant cold packs, as its dissolution in water is highly endothermic. It also was used, in combination with independently explosive \"fuels\" such as guanidine nitrate, as a cheaper (but less stable) alternative to 5-aminotetrazole in the inflators of airbags manufactured by Takata Corporation, which were recalled as unsafe after killing 14 people.\n\nHealth and safety data are shown on the safety data sheets available from suppliers and found on the internet. In response to several explosions resulting in the deaths of numerous people, U.S. agencies of Environmental Protection (EPA), Occupational Health and Safety (OSHA) and the Bureau of Alcohol, Tobacco and Firearms jointly issued safety guidelines.\n\nHeating or any ignition source may cause violent combustion or explosion. Ammonium nitrate reacts with combustible and reducing materials as it is a strong oxidant. Although it is mainly used for fertilizer, it can be used for explosives. It was sometimes used to blast away earth to make farm ponds. Ammonium nitrate is also used to modify the detonation rate of other explosives, such as trinitrotoluene in the form of amatol.\n\nNumerous safety guidelines are available for storing and handling ammonium nitrate. It should not be stored near combustible substances. Ammonium nitrate is incompatible with certain substances such as chlorates, mineral acids and metal sulfides, contact with which can lead to vigorous or even violent decomposition.\n\nAmmonium nitrate has a critical relative humidity of 59.4%, above which it will absorb moisture from the atmosphere. Therefore, it is important to store ammonium nitrate in a tightly sealed container. Otherwise, it can coalesce into a large, solid mass. Ammonium nitrate can absorb enough moisture to liquefy. Blending ammonium nitrate with certain other fertilizers can lower the critical relative humidity.\n\nThe potential for use of the material as an explosive has prompted regulatory measures. For example, in Australia, the Dangerous Goods Regulations came into effect in August 2005 to enforce licensing in dealing with such substances. Licenses are granted only to applicants (industry) with appropriate security measures in place to prevent any misuse. Additional uses such as education and research purposes may also be considered, but individual use will not. Employees of those with licenses to deal with the substance are still required to be supervised by authorized personnel and are required to pass a security and national police check before a license may be granted.\n\nHealth and safety data are shown on the material safety data sheets, which are available from suppliers and can be found on the internet.\n\nAmmonium nitrate is not hazardous to health and is usually used in fertilizer products.\n\nAmmonium nitrate has an LD of 2217 mg/kg, which for comparison is about two-thirds that of table salt.\n\nAmmonium nitrate decomposes into the gases nitrous oxide and water vapor when heated (not an explosive reaction); however, it can be induced to decompose explosively by detonation. Large stockpiles of the material can be a major fire risk due to their supporting oxidation, and may also detonate, as happened in the Texas City disaster of 1947, which led to major changes in the regulations for storage and handling.\n\nTwo major classes of incidents resulting in explosions are:\n\n"}
{"id": "18940621", "url": "https://en.wikipedia.org/wiki?curid=18940621", "title": "Ammunition", "text": "Ammunition\n\nAmmunition (informally ammo) is the material fired, scattered, dropped or detonated from any weapon. Ammunition is both expendable weapons (e.g., bombs, missiles, grenades, land mines) and the component parts of other weapons that create the effect on a target (e.g., bullets and warheads). Nearly all mechanical weapons require some form of ammunition to operate.\n\nThe term ammunition can be traced back to the mid-17th century. The word comes from the French \"la munition,\" for the material used for war. Ammunition and munitions are often used interchangeably, although munition now usually refers to the actual weapons system with the ammunition required to operate it. In some languages other than English ammunition is still referred to as munition, such as French (\"munitions\"), German (\"Munition\") or Italian (\"munizione\").\n\nThe purpose of ammunition is to project a force against a selected target to have an effect (usually, but not always, lethal). The most iconic example of ammunition is the firearm cartridge, which includes all components required to deliver the weapon effect in a single package.\n\nAmmunition comes in a great range of sizes and types and is often designed to work only in specific weapons systems. However, there are internationally recognized standards for certain ammunition types (e.g., 5.56×45mm NATO) that enable their use across different weapons and by different users. There are also specific types of ammunition that are designed to have a specialized effect on a target, such as armor-piercing shells and tracer ammunition, used only in certain circumstances. Ammunition is commonly colored in a specific manner to assist in the identification and to prevent the wrong ammunition types from being used accidentally.\n\n\nAmmunition design has evolved throughout history as different weapons have been developed and different effects required. Historically, ammunition was of relatively simple design and build (e.g., sling-shot, stones hurled by catapults), but as weapon designs developed (e.g., rifling) and became more refined, the requirement for more specialized ammunition increased. Modern ammunition can vary significantly in quality but is usually manufactured to very high standards.\n\nFor example, ammunition for hunting can be designed to expand inside the target, maximizing the damage inflicted by a single round. Anti-personnel shells are designed to fragment into many pieces and can affect a large area. Armor-piercing rounds are specially hardened to penetrate armor, while smoke ammunition covers an area with a fog that screens people from view. More generic ammunition (e.g., 5.56×45mm NATO) can often be altered slightly to give it a more specific effect (e.g., tracer, incendiary), whilst larger explosive rounds can be altered by using different fuzes.\n\nThe components of ammunition intended for rifles and munitions may be divided into these categories:\n\nThe term \"fuze\" refers to the detonator of an explosive round or shell. The spelling is different in British English and American English (fuse/fuze respectively) and they are unrelated from a fuse (electrical). A fuse was earlier used to ignite the propellant (e.g., such as on a firework) until the advent of more reliable systems such as the primer or igniter that is used in most modern ammunitions.\n\nThe fuze of a weapon can be used to alter how the ammunition works. For example, a common artillery shell fuze can be set to 'point detonation' (detonation when it hits the target), delay (detonate after it has hit and penetrated the target), time-delay (explode a specified time after firing or impact) and proximity (explode above or next to a target without hitting it, such as for airburst effects or anti-aircraft shells). These allow a single ammunition type to be altered to suit the situation it is required for. There are many designs of a fuze, ranging from simple mechanical to complex radar and barometric systems.\n\nFuzes are usually armed by the acceleration force of firing the projectile, and usually arm several meters after clearing the bore of the weapon. This helps to ensure the ammunition is safer to handle when loading into the weapon and reduces the chance of the detonator firing before the ammunition has cleared the weapon.\n\nThe propellant is the component of ammunition that is activated inside the weapon and provides the kinetic energy required to move the projectile from the weapon to the target. Before the use of gunpowder, this energy would have been produced mechanically by the weapons system (e.g., a catapult or crossbow); in modern times, it is usually a form of chemical energy that rapidly burns to create kinetic force, and an appropriate amount of chemical propellant is packaged with each round of ammunition. In recent years, compressed gas, magnetic energy and electrical energy have been used as propellants.\n\nUntil the 20th-century, gunpowder was the most common propellant in ammunition. However, it has since been replaced by a wide range of fast-burning compounds that are more reliable and efficient.\n\nThe propellant charge is distinct from the projectile charge which is activated by the fuze, which causes the ammunition effect (e.g., the exploding of an artillery round).\n\nThe cartridge is the container that holds the projectile and propellant. Not all ammunition types have a cartridge case. In its place, a wide range of materials can be used to contain the explosives and parts. With some large weapons, the ammunition components are stored separately until loaded into the weapon system for firing. With small arms, caseless ammunition can reduce the weight and cost of ammunition, and simplify the firing process for increased firing rate, but the maturing technology has functionality issues.\n\nThe projectile is the part of the ammunition that leaves the weapon and has the effect on the target. This effect is usually either kinetic (e.g., as with a standard bullet) or through the delivery of explosives.\n\nSee ammunition dump and magazine for a discussion of modern ammunition storage facilities.\n\nThe standard weapon of a modern soldier is an assault rifle, which, like other small arms, uses cartridge ammunition in a size specific to the weapon. Ammunition is carried on the person in box magazines specific to the weapon, ammo boxes, pouches or bandoliers. The amount of ammo carried is dependent on the strength of the soldier, the expected action required, and the ability of ammunition to move forward through the logistical chain to replenish the supply. A soldier may also carry a smaller amount of specialized ammunition for heavier weapons such as machine guns and mortars, spreading the burden for squad weapons over many people. Too little ammunition poses a threat to the mission, while too much limits the soldier's mobility.\n\nA shell is a payload-carrying projectile which, as opposed to a shot, contains explosives or other fillings, in use since the 19th century.\n\nArtillery shells are ammunition that is designed to be fired from artillery which has an effect over long distances, usually indirectly (i.e., out of sight of the target). There are many different types of artillery ammunition, but they are usually high-explosive and designed to shatter into pieces of shrapnel on impact to maximize damage. The fuze used on an artillery shell can alter how it explodes or behaves so it has a more specialized effect. Common types of artillery ammunition include high explosive, smoke, illumination, and practice rounds. Some artillery rounds are designed as cluster munitions. Artillery ammunition will almost always include a projectile (the only exception being demonstration/blank rounds), fuze and propellant of some form. When a cartridge case is not used, there will be some other method of containing the propellant explosion, usually a breech-loading weapon.\nTank ammunition was developed in WWI as tanks first appeared on the battlefield. However, as tank-on-tank warfare developed (including the development of anti-tank artillery), more specialized forms of ammunition were developed such as high-explosive anti-tank warheads and armor-piercing discarding sabot rounds. The development of shaped charges has had a significant impact on anti-tank ammunition design, now common on both tank-fire ammunition and in anti-tank missiles.\n\nNaval weapons were originally the same as many land-based weapons, but the ammunition was designed for specific use, such as a solid shot designed to hole the enemy ship and chain-shot to cut the rigging and sails. Modern naval engagements have taken place over much larger distances than historic battles, so as ship armor has increased in strength and thickness, the ammunition to defeat it has also changed. Naval ammunition is now designed to reach very high velocities (to improve its armor-piercing capabilities) and may have specialized fuzes for defeating specific types of vessels. However, due to the extended ranges at which modern naval combat may take place, guided missiles have largely supplanted guns and shells.\n\nWith every successive improvement in military arms, there has been a corresponding modification in the method of supplying ammunition in the quantity required. As soon as projectiles were required (such as javelins and arrows), there needed to be a method of replenishment. When non-specialized, interchangeable or recoverable ammunition was used (e.g., arrows), it was possible to pick up spent arrows (both friendly and enemy) and reuse them. However, with the advent of explosive or non-recoverable ammunition, this was no longer possible and new supplies of ammunition would be needed.\n\nThe weight of ammunition required, particularly for artillery shells, can be considerable, causing a need for extra time to replenish supplies. In modern times, there has been an increase in the standardization of many ammunition types between allies (e.g., the NATO Standardization Agreement) that has allowed for shared ammunition types (e.g., 5.56×45mm NATO).\n\n lead-based ammunition production is the second-largest annual use of lead in the US, accounting for over 60,000 metric tons consumed in 2012. Lead bullets that miss their target or remain in a carcass or body that was never retrieved can enter environmental systems and become toxic to wildlife. The US military has experimented with replacing lead with copper as a slug in their green bullets which reduces the dangers posed by lead in the environment as a result of artillery. Since 2010, this has eliminated over 2000 tons of lead in waste streams.\n\nUnexploded ammunition can remain active for a very long time and poses a significant threat to both humans and the environment.\n\n\nUntil the 20th-century, gunpowder was the most common explosive used but has now been replaced in nearly all cases by modern compounds.\n"}
{"id": "17564368", "url": "https://en.wikipedia.org/wiki?curid=17564368", "title": "Arctic Sun medical device", "text": "Arctic Sun medical device\n\nThe Arctic Sun Temperature Management System is a non-invasive targeted temperature management system, a medical device used to modulate patient temperature with precision by circulating chilled water in pads directly adhered to the patient's skin. Using varying water temperatures and a sophisticated computer algorithm, a patient's body temperature can be controlled to the nearest 0.2 °C. It is produced by Medivance, Inc. of Louisville, Colorado.\n\nBody temperature, which is systematically measured and reported as a vital sign, contributes to maintenance of normal physiology and affects the processes that lead to recovery after illness. Complete and proper functioning of the body is dependent on maintaining a core temperature between . A core temperature above 41.5 °C or below 33.5 °C causes a fast decline in proper functioning of the body and may result in injury or death. Intentional manipulation of body temperature has been studied as a treatment strategy for head injuries since the 1900s. In the 1980s, the use of hypothermia on dogs after cardiac arrest demonstrated positive outcomes including neurological status and survival. In 2005, the American Heart Association implemented recommendations and guidelines for mild hypothermia in post-resuscitation support after cardiac arrest with return of spontaneous circulation.\n\nOne of the most common practices of targeted temperature management is to reduce body temperature to a “mild hypothermic state” (per the AHA guidelines is 33 °C (91.4 °F) for 12–24 hours and then slowly re-warm the body back to normal 37 °C (98.6 °F). The purpose of this is to slow the metabolic processes and the chemical cascade that occurs when the brain goes without oxygen for a period of time. A study conducted in 2002-2004 showed that treatment with therapeutic hypothermia for patients resuscitated after cardiac arrest due to ventricular fibrillation led to a positive outcome (Glasgow-Pittsburgh Cerebral Performance category 1 or 2) in 24 of 43 patients compared to only 11 of 43 patients in the standard resuscitation group where no hypothermia was used in treatment.\n\nTherapeutic hypothermia, which lowers the patient's body temperature to levels between , is used to help reduce the risk of the ischemic injury to the brain following a period of insufficient blood flow. Periods of insufficient blood flow may be caused by cardiac arrest, stroke, or brain trauma. Non-invasively induced therapeutic hypothermia has been shown to reduce mortality of successfully resuscitated cardiac arrest victims by 35 percent and increase the chance of a good neurologic outcome by 39 percent.\n\nThe Arctic Sun has been explained as dry water immersion. It is a non-invasive precision temperature management system that is used to induce hypothermia in comatose patients that have suffered from Sudden Cardiac Arrest (SCA) and patients at risk for ischemic brain damage. The Arctic Sun has distinctive gel pads, which stick to a patient’s body using an adhesive called hydrogel—a substance that adheres to the skin without removing hair follicles. The gel pads cover only a portion of a patient’s body and subsequently leave most of the body free for augmenting medical procedures. The device operates under negative pressure and circulates water through these pads at a temperature between . Water is pulled through the pads, which minimizes the risk of leakage. By controlling the temperature of the water running through the gel pads, the Arctic Sun’s adjusts a patient’s temperature. Arctic Sun can also rewarm patients. Controlled rewarming has been cited in the literature as beneficial in preventing reperfusion injury. Because of the Arctic Sun’s noninvasive nature, treatment can be delivered without the host of adverse events associated with invasive procedures such as cooling catheters.\n\nA former complaint levied against the Arctic Sun relates to the risk of skin injury. A study published in 2007 found that the Arctic Sun was, \"highly effective in lowering patients’ temperature rapidly without inducing skin irritations.\".\n\nInvasive cooling catheter companies have claimed that catheters can lower body temperature at a faster rate, which is relevant because most of the clinical data suggests that the sooner cooling initiates the better a patient’s outcome. However, there exists a 75 minute delay on average between admittance and catheter insertion. Even with a physician readily available to place the cooling catheter, the operating instructions underline the importance of the device set up with takes a minimum of 25 minutes. When objectively evaluating the published data the average cooling rate for cooling catheters is 1.12°C. Treatment with the Arctic Sun can be administered within 10 minutes by unsupervised nursing professionals.\n\nHistorically, clinicians reported that catheters cool at a quicker rate, however, a 2011 study published in the Society of Critical Care Medicine where 167 patients treated either with the Arctic Sun or the Alsius Coolgard Catheter showed the following:\n\nThere was no significant difference in survival with good neurologic function, either to hospital discharge or at follow-up. Time from cardiac arrest to achieving mild therapeutic hypothermia was equal with both devices (surface, 273 min, core, 270 min).”\nHowever, this could not be confirmed in the present study, because there was no difference in the rate of shivering in surface-cooled or core-cooled patients.”\n\nIt was concluded that “Surface and core cooling of out-of hospital cardiac arrest patients following the same established postresuscitation treatment protocol resulted in similar survival to hospital discharge and comparable neurologic function at follow-up.”\n\n\"Crit Care Med\" Vol 39 No 3\n\nIn May 2008, the Arctic Sun was used to induce hypothermia in a 59-year-old woman in West Virginia who had suffered 3 cardiac arrests within a 24-hour period. For more than 17 hours the woman had no measurable brain waves, according to her doctors, and her heart had been stopped for a prolonged period of time. The family decided to take her off life support. Shortly after being disconnected from the ventilator, the woman unexpectedly recovered, regaining consciousness, motor function, and speech.\n\n\n"}
{"id": "1524262", "url": "https://en.wikipedia.org/wiki?curid=1524262", "title": "Ascender (climbing)", "text": "Ascender (climbing)\n\nAn ascender is a device (usually mechanical) used for directly ascending a rope, or for facilitating protection with a fixed rope when climbing on very steep mountain terrain. \n\nAscenders can also be used as a braking component within a rope hauling system, often used in rescue situations. \n\nAscenders are usually used in pairs, and offer similar functionality to friction knots, but are faster, safer and easier to use, albeit still with consequences in weight and in security (as ascenders can, even with a locking carabiner, come off the rope, and fail by shredding the rope at high loads, rather than slipping and fusing as with friction knots). A mechanical ascender employs a cam which allows the device to slide freely in the intended direction of movement, but provide a firm grip on the rope when pulled in the opposite direction. To prevent an ascender from accidentally coming off the rope, a locking mechanism or trigger is deployed. The ascender is first attached to the climber's harness by a piece of webbing or sling, and then is clipped onto the rope and locked on. \n\nAscenders are usually used in pairs, so that one is free to be slid up the rope whilst the other bears the weight of the climber. The ascender which has just been slid upwards is then made to take the climbers load, so locking him to the rope, and freeing the other one so it, too, can then be slid upwards too. The process is then repeated to ascend the rope. \n\nFor climbing on with a fixed rope attached for security (for example, to snow anchors on a steep slope) only one ascender is used, keeping the other hand free for holding an ice axe.\n\nAscenders are not typically used on free climbing routes, where a climber uses his or her hands and feet on the rock, climbing the features, edges, cracks, and pockets that the route provides without artificial aids. Instead, they are more likely to be used in aid climbing.\n\nOne such ascender device is a jumar, named for its manufacturer Jümar Pangit, a company in turn named after jumar inventors Adolph Jüsi and Walter Marti. The first iteration of the tool was sold in 1958. The device's name also engendered the verb \"to jumar\" for the process of using such a device. In jumaring, the second climber (the one who belays the lead climber on the route) uses ascenders to climb the rope instead of climbing directly on the rock. Other terms for this process include ascending and jugging.. This process is similar to prusiking, except using an ascender device instead of friction knots.\n\nIn place of mechanical ascenders, one or more thin rope slings (or prusik loops) may be used which can be slid along the thicker climbing rope when not under tension. These friction knots will lock under load to enable the climber to use the strength of their leg to step up and ascend the rope. Prusik knots are much lighter, but are not capable of taking a dynamic load, such as arresting a falling climber, because they are prone to melting or fusing under such extreme forces.\n\nIn caving, ascending a rope by means of mechanical devices is often necessary and is the main alternative to ladder use. This is termed Single-rope technique. The rock which forms the cave is often wet, slippery, relatively featureless and often unreachable from the necessary rope locations. So climbing the rope may well be preferable to climbing the rock or a ladder, provided that a belay location that provides an ascent has already been found. Although climbers may regard a climb as a challenge to be tackled with minimal aids, cavers are likely to consider it as an obstacle to their progress to be overcome as conveniently as possible, and are more inclined to make use of mechanical ascenders.\nThe first mechanical rope ascending devices were created by Henri Brenot, and were used in France both for mountaineering and caving as early as 1934.\n\nJümar Pangit, a Swiss manufacturer located then in Reichenbach (Switzerland), was founded by Adolph Jüsi and Walter Marti. Jüsi was studying eagles for the Swiss government and needed to ascend on ropes in order to perform his work, so Marti developed the ascender for him. In 1958, the first jumar was introduced to the climbing market. This page (archived) gives an overview on the older jumar models. A current model is still in production.\n\nFrench caver Fernand Petzl developed a mechanical rope ascender in 1968, and his company Petzl continues to produce both handled and handleless models that are popular with mountaineers and cavers today.\n\nOther countries, notably the United States, have also produced rope ascenders. Other names for different styles of ascenders include 'ropeman' and 'tibloc'.\n"}
{"id": "1832490", "url": "https://en.wikipedia.org/wiki?curid=1832490", "title": "Association for the Advancement of Automotive Medicine", "text": "Association for the Advancement of Automotive Medicine\n\nThe Association for the Advancement of Automotive Medicine (AAAM) is a non-profit education and research organization founded in 1957 by the Medical Advisory committee to the Sports Car Club of America. It is the first and premier professional multidisciplinary organization dedicated entirely to the prevention and control of injuries from motor vehicle crashes.\n\nAAAM is an international association with professionals representing more than 20 countries committed to reducing motor vehicle trauma and improving highway safety around the world. Its strength lies in its membership representing medicine, engineering, biomechanics, law, education, and public policy. This combination of clinical, research and administrative backgrounds forms a unique blend of leaders in traffic injury control and it is these professionals who comprise the AAAM membership.\n\nThe AAAM has furthered the development and publishes the Abbreviated Injury Scale (AIS), a widely used description system for individual injuries. The Abbreviated Injury Scale is an internationally accepted tool for assessing the injury severity of individual injuries. It contains no information on injury aggregation. The AIS codebook is protected by copyright.\n"}
{"id": "2047180", "url": "https://en.wikipedia.org/wiki?curid=2047180", "title": "Baby powder", "text": "Baby powder\n\nBaby powder is an astringent powder used for preventing diaper rash, as a deodorant, and for other cosmetic uses. It may be composed of talcum (in which case it is also called talcum powder) or corn starch (in which case it is also called corn starch). Talcum powder is dangerous if inhaled since it may cause aspiration pneumonia or granuloma. Pediatricians generally prefer cornstarch to talc because it is unlikely to be easily inhaled. Baby powder can also be used as a shampoo, cleaning agent, and freshener.\n\nSome studies have found a statistical relationship between talc applied to the perineal area by women and incidence of ovarian cancer. However, there is not a consensus that the two are linked. In 2017, over 1,000 U.S. women sued Johnson & Johnson for covering up the possible cancer risk with its Baby Powder product.\n\nBaby powder is also efficient for removing greasy hair, or oil on clothes.\n\n"}
{"id": "12047145", "url": "https://en.wikipedia.org/wiki?curid=12047145", "title": "BlogHer", "text": "BlogHer\n\nBlogHer is a community and media company founded by Elisa Camahort Page, Jory des Jardins, and Lisa Stone in 2005. The company, Blogher LLC, includes conferences and a blog advertising network. In 2007, it expanded to include BlogHers Act, a political blogging network by and for women. Dan Gillmor quoted the site's community guideline \"We embrace the spirit of civil disagreement\" as an ideal.\n\nBlogHer began as a conference in 2005 in San José, California. It began with an idea and a blog, and once announced, quickly grew to a 300-person conference on women and blogging. \n\nThe second BlogHer conference was held in San José and was much larger than the first, with at least 750 attendees. \n\nBlogHer '07 keynote speakers in Chicago include Rashmi Sinha, Gina Bianchini, Annalee Newitz, Elizabeth Edwards, and Esther Dyson. In 2007, the community events also expanded to a business blogging conference in March in New York City. BlogHer Business keynote speakers included Elisa Camahort, Jeannette Gibson, Stephanie Bergman, Rachel Clarke, Lisa Weinstein, Lisa Stone, Debi Fine, Marissa Mayer, Stacy Morrison, and Caroline Little.\n\nIn 2008, the BlogHer cofounders were honored with the Social Impact ABIE Award from the Anita Borg Institute.\n\nOn July 16, 2008, iVillage, a network of online media outlets owned by NBC Universal, announced that it had reached a partnership with the BlogHer network to provide content for sites across the iVillage network. Additionally, BlogHer received $5 million in funding from Peacock Ventures, NBC Universal's venture investment arm.\n\nBlogher 2010 was held in New York City from August 6–7, at the Hilton New York. Blogher 2011 was held in San Diego in August. Blogher 2012 was held in New York City from August 2–5, at the Hilton New York. The conference was the largest ever, with more than 5,000 registered attendees. Many notable speakers were a part of the conference, including a live video appearance from President Barack Obama. Also featured were keynote sessions with Martha Stewart, Katie Couric, and a panel of celebrities-doing-good: Soledad O'Brien (moderator), former model Christy Turlington and Malaak-Compton Rock, a philanthropist and comedian Chris Rock's wife. Blogher 2013 was held in Chicago at McCormick Place from July 25–27, and featured speakers Guy Kawasaki and Sheryl Sandberg.\n\nOn November 3, 2014, BlogHer was bought by SheKnows Media.\n\nIn 2006, BlogHer started a group blog featuring over 60 women blogging on a variety of subjects. Its forums expanded to include a large worldwide community of bloggers who are women.\n\n\n"}
{"id": "41429700", "url": "https://en.wikipedia.org/wiki?curid=41429700", "title": "BuildDirect", "text": "BuildDirect\n\nBuildDirect is a technology company headquartered in Vancouver, British Columbia. It is an online marketplace for heavyweight home improvement products. The company was founded in 1999 by Jeff Booth and Rob Banks, and connects buyers (consumers and contractors) with sellers (suppliers and manufacturers). Categories include, but are not limited to, flooring, tile, decking, building materials, outdoor, kitchen & bath, molding & accessories and doors.\n\nPrior to co-founding BuildDirect, Jeff Booth was a home builder. After experiencing \"complexities and inefficiencies\", Booth founded BuildDirect in October 1999 with friend Rob Banks. Their goal was to simplify the home improvement industry. The first years focused on shipping heavyweight home improvement materials. In 2002 they launched www.Builddirect.com, an e-commerce site for home improvement products and building materials. The company grew quickly, doubling in size from 2002 to 2004.\n\nDuring the financial crisis in 2008, the company nearly went out of business but survived by changing their business model to include suppliers lending their product on consignment to BuildDirect warehouses. In 2010, the company built a supply chain for shipping heavy goods \"anywhere to anywhere\", and in 2016, they launched the BuildDirect Home Marketplace. The company initially sold home building materials but has since diversified to include other products such as furniture, home decor, lighting, and outdoor living items.\n\nOn June 10, 2015, Builddirect acquired DraftingSpace, a software company based in Waterloo.\n\nThe average weight of a BuildDirect product order is 1,500 pounds. To ship these heavy materials, BuildDirect built a new system. The company utilizes an existing network of primary transporters including freight, rail, and truck to import products to North America, move them to warehouses, and deliver them to customers. BuildDirect also uses technology and a competitive bidding process to calculate delivery methods.\n\nIn February 2017, BuildDirect opened its global supply chain platform for heavyweight goods. The BuildDirect Gateway provides any third party access to BuildDirect's network of warehousing services, ground and ocean logistics for any part of the shipping process, from point of manufacture through last-mile delivery.\n\nBuildDirect has built its own proprietary analytics and forecasting tools; BuildDirect Demand Rank, BuildDirect Product Rank, and BuildDirect Inventory Rank. These tools are used to analyze product specific data relating to consumer interest, market competitiveness, and geographic performance. This demand data is also available to suppliers, which provides opportunities for them to manage their own inventory planning, production and shipping.\n\nIn February 2016, BuildDirect launched the BuildDirect Home Marketplace; an online platform that connects consumers with home improvement products. The platform also offers a self-service model for sellers to onboard their products.\n\nBuildDirect has many distribution points across North America, with 6 super warehouses in Vancouver B.C., Los Angeles, Dallas, Atlanta, Chicago, and New Jersey. The company headquarters is located in Vancouver, B.C.\n\n\n"}
{"id": "224329", "url": "https://en.wikipedia.org/wiki?curid=224329", "title": "Ceilometer", "text": "Ceilometer\n\nA ceilometer is a device that uses a laser or other light source to determine the height of a cloud ceiling or cloud base. Ceilometers can also be used to measure the aerosol concentration within the atmosphere. When based on laser, it is a type of atmospheric lidar.\n\nCeilometers that use visible light can sometimes be fatal to birds, as the animals become disoriented by the light beams and suffer exhaustion and collisions with other birds and structures. In the worst recorded ceilometer non-laser light beam incident, approximately 50,000 birds from 53 different species died at Warner Robins Air Force Base in the United States during one night in 1954.\n\nLaser ceilometers use invisible lasers to observe the cloud base. Using optical instruments such as binoculars near ceilometers is not recommended, because lenses in instruments could concentrate the beam and damage one's eyes. Ceilometers can be installed on angles in the approach of aircraft to a runway.\n\nAn optical drum ceilometer uses triangulation to determine the height of a spot of light projected onto the base of the cloud. It consists essentially of a rotating projector, a detector, and a recorder. The projector emits an intense beam of light above into the sky at an angle that varies with the rotation. The detector, which is located at a fixed distance from the projector, uses a photodetector pointing vertically. When it detects the projected light return from the cloud base, the instrument notes the angle and the calculation gives the height of clouds.\n\nA laser ceilometer consists of a vertically pointing laser and a receiver in the same location. A laser pulse with a duration on the order of nanoseconds is sent through the atmosphere. As the beam travels through the atmosphere, tiny fractions of the light are scattered by aerosols. Generally, the size of the particles in question are similar in size to the wavelength of the laser. This situation leads to Mie scattering. A small component of this scattered light is directed back to the lidar receiver. The timing of the received signal can be transformed into a spatial range, \"z\", by using the speed of light. That is,\n\nwhere c is the light speed in the air.\n\nIn this way, each pulse of laser light results in a vertical profile of aerosol concentration within the atmosphere. Generally, many individual profiles will be averaged together in order to increase the signal-to-noise ratio and average profiles are reported on a time scale of seconds. The presence of clouds or water droplets leads to a very strong return signal compared to background levels, which allows for cloud heights to be easily identified.\n\nFor cloud base determination purpose, due to the ceilometer's ability to pick up any particle in the air (dust, precipitation, smoke, etc.), it will give occasional false readings. As an example, depending on the threshold used, falling diamond dust (ice crystals) may cause the ceilometer to report a cloud height of zero, even though the sky is clear.\n\nUsing these last properties, ceilometers will have other uses. Since the instrument will note any returns, it is possible to locate any faint layer where it occurs, additionally to the cloud's base, by looking at the whole pattern of returned energy. Furthermore, the rate at which diffusion happens can be noted by the diminishing part returned to the ceilometer in clear air, giving the coefficient of extinction of the light signal. Using these data could give the vertical visibility and the possible concentration of air pollutants. This has been developed in research and could be applied for operational purpose.\n\nIn New Zealand, MetService operates a network of laser ceilometers for cloud base measurements at commercial airports. These sensors are also used to map volcanic ash clouds to allow commercial air traffic to avoid damage caused by ash.\n\n\n"}
{"id": "55204891", "url": "https://en.wikipedia.org/wiki?curid=55204891", "title": "Chronology of bladed weapons", "text": "Chronology of bladed weapons\n\nThe different types of bladed weapons (swords, dress-swords, sabers, rapiers, foils, machetes, daggers, knives, arrowheads, etc..) have been of great importance throughout history. In addition to its use for fighting, or in wars, the \"bladed weapons\" have been the object of special considerations forming part of funerary rituals, mythology and other ancestral traditions.\n\nThe manufacture of a \"bladed weapon\" of a certain quality (either of bronze or iron alloy) requires a certain degree of mastery in metallurgy: obtaining metals and alloys from the minerals of the mines, mastery on forging, casting or forming techniques and heat treatments; without forgetting the artistic aspects or the crafts related to the complements (pods, belts, shawls, knobs, decoration, etc...).\n\nThe present chronology it's a compilation that includes diverse and relatively uneven documents about different families of \"bladed weapons\": swords, dress-swords, sabers, rapiers, foils, machetes, daggers, knives, arrowheads, etc..., with the sword references being the most numerous but not the unique included among the other listed references of the rest of \"bladed weapons\". The reason to group them into a single list responds to a goal for simplification, instead of making a different chronology article for each type of bladed weapon.\n\nThe first bronze swords with a length equal to or greater than 60 cm date from the 17th century BC in regions of the Black Sea and the Aegean Sea. They emerged as an evolution of shorter weapons of the type of the daggers or daggers. To make a sword useful in combat, you must have a correct alloy, give it the right shape and apply the necessary thermal (and finishing) treatments. The longer a sword, the stresses (bending and buckling) are more important. What is needed is a weapon that is hard enough (to cut), fairly flexible (without being fragile) and quite tenacious enough to withstand the blows in the fights.\n\nThe manufacturing process is summarized as follows: The bronze swords were cast into moulds, heated to a certain temperature and allowed to cool slowly. Finally they cold hammered (hitting them with a hammer on a type of anvil) to increase its hardness.\n\n\n\n...\"Item. Senyor los dits privilegis, capítols e ordinacions vees(?) plaurets a Déu a justícia (e) egualtat car axí son stats obtenguts per la spaseria de ciutat vostra de Barchinonae per vos atorgats (a) aquella segons han pres los prohomens de la spaseria de la dita vostra ciutat de Valencia...1425...Alfonsi Dei gratia Regis Aragonum, Sicilie, Valencie, Majoricam, Sardinie et ...\"\nThey had to present:\"“4 fulles d’espases e recapte per a guarniment de aquelles. Ço és la una fulla de dues mans la qual haie a guarnir vermella. E l’altra fulla sia de una mà la qual haie a esser guarnida mitadada de dues colors. E l’altra de una mà que sia buydada e guarnida tota negra. E la quarta ço és un estoch d’armes tot blanch los quals guarniments se vien(?) e haien a fer per lo volent usa(n)t de la dita spaseria dins la casa e habitació de un dels dits diputats...”\"\n\n\n\n"}
{"id": "2814867", "url": "https://en.wikipedia.org/wiki?curid=2814867", "title": "Complexity measure", "text": "Complexity measure\n\nComplexity measure / measure of complexity may refer to any measure defined in various branches of complexity theory, specifically:\n"}
{"id": "48507357", "url": "https://en.wikipedia.org/wiki?curid=48507357", "title": "DBMaestro", "text": "DBMaestro\n\nDBmaestro is computer software service company with sales headquartered near Boston, and development in Petah Tikva, Israel. It markets its services for DevOps: collaboration between development and IT operations teams.\n\nDBmaestro was co-founded in 2008 by Yariv Tabac who became chief executive, and Yaniv Yehuda who became chief technical officer.\nIt was founded in Israel, and competes with Redgate.\n\nDBmaestro's DevOps Suite software focuses on database development and controls application specific data.\nDBmaestro integrates with other technology such as Oracle Database and Microsoft SQL Server.\n\nDBmaestro software as a service is designed to reduce errors in database branch merges, prevent unintended database drift, expedite database changes, limit inter-team asynchronicity, ensure compliance, improve change logs and change storage, and decrease the responsibilities of database administrators.\n\nIn 2015, DBmaestro was recognized by the editors of SD Times, \"Computing\" magazine,\nand a market research company.\n\nTheir first venture capital funding was $3 million, announced in February 2016.\n\n"}
{"id": "6873069", "url": "https://en.wikipedia.org/wiki?curid=6873069", "title": "Domino computer", "text": "Domino computer\n\nA domino computer is a mechanical computer built using dominoes to represent mechanical amplification or logic gating of digital signals. Because of the existence of multiple schemes, domino computer will be used in this article to denote any particular scheme that uses the mentioned base phenomenon (of domino sequences) for building machines equivalent to a computer. This choice of terminology may be somewhat arbitrary, because only few resources write on this topic.\n\nSequences of standing dominoes (so that each topples the next one) can be arranged to demonstrate digital concepts such as amplification and digital signals. It is some digital information that is conducted by a string of dominoes, thus this effect differs from phenomena where:\n\nThe Domino Day event shows many constructs, mainly with purpose of entertainment. Some constructs may remind people of digital circuits. Some of them suggest that not only telegraph-like tools can be shown, but also simple information processing modules can be built.\n\nIt is possible to use this phenomenon for constructing unconventional computing tools. The base phenomenon is sufficient to achieve this goal, but also sophisticated “mechanical synapses” can be used (see online ), to the analogy of electrical synapses or chemical synapses.\n\nThe logic gate OR is very natural in dominoes.\nThe problem is which gate we should add to OR, and obtain a functionally complete set.\nNote that no domino gate can produce output 1 with all inputs 0,\nso we cannot make NOT, therefore we cannot even make IMPLIES without an external 'power source' sequence.\nOnce we admit it, NOT is realized and we have a complete set.\n\nBut it is however distant to lead in a sequence from one source to many gates in each suitable timing.\nLet us suppose we do not have one.\n\nA root breaking system is basically needed if one wants a logical connective with output 0 for input 1.\nLet P$Q be the gate in which the sequence to be turned down by P is broken by that by Q.\nThen P$Q is logically equivalent to P AND (NOT Q), if the input Q is earlier than P.\nThe set of OR and $ can represent any logical connectives in any arity except for ones which generates 1 with all inputs 0.\n\nSimilarly, XOR can be realized with the gate in a diagram above as a bi-root breaking system.\n\nThe problems of these two root breaking systems is that they heavily depend on the simultaneity of two inputs.\nIn the gate of XOR one input may destroy the opposite input root tracking back.\nNote that the expression of P AND Q, P$(P$Q) OR Q$(Q$P) is symmetric,\nhence does not depend on the simultaneity, and with no worry of tracking back, though it is complicated.\n\nThe current record for domino computers is a 5 bit adder.\n\nAt the Manchester Science Festival in 2012, mathematician Matt Parker and a team of volunteers worked together to build a domino binary adder which could add two three-bit inputs and produce a 4-bit output, which ran successfully. The following day, they attempted to build a 5-bit adder, which they completed, but the final test run had some errors (one due to signal bleed between chains of dominoes, and one timing issue).\n\nAt American British Academy (ABA), Muscat, a team of Grade 12 students lead by Saatvik Suryajit Korisepati, supported by Alex Freyer, Zoltan Sojitory and rest of computers students had executed a 5-bit adder which will be able to add any numbers up to the sum of 63. The previous world record is a 4-bit adder that can only add up numbers up to 31. They had used 15,000 dominoes to build the circuit at Bank Muscat headquarters Oman.\n\n"}
{"id": "5664562", "url": "https://en.wikipedia.org/wiki?curid=5664562", "title": "Dry run (testing)", "text": "Dry run (testing)\n\nA dry run (or a practice run) is a testing process where the effects of a possible failure are intentionally mitigated. For example, an aerospace company may conduct a “dry run” test of a jet’s new pilot ejection seat while the jet is parked on the ground, rather than while it is in flight.\n\nThe usage of “dry run” in acceptance procedures (for example in the so-called FAT = factory acceptance testing) is meant as following: the factory – which is a subcontractor – must perform a complete test of the system it has to deliver \"before\" the actual acceptance by customer.\n\n\n"}
{"id": "6748786", "url": "https://en.wikipedia.org/wiki?curid=6748786", "title": "FLARM", "text": "FLARM\n\nFLARM is an electronic system used to selectively alert pilots to potential collisions between aircraft. It is not formally an implementation of ADS-B, as it is optimized for the specific needs of light aircraft, not for long-range communication or ATC interaction. FLARM is a portmanteau of \"flight\" and \"alarm\". The installation of all FLARM devices is approved as a European Aviation Safety Agency Standard Change, and PowerFLARM Core specifically has been approved as a Minor Change by EASA. In addition to the Standard Change, the Minor Change approves PowerFLARM Core to be used during IFR and at night.\n\nFLARM obtains its position and altitude readings from an internal GPS and a barometric sensor and then broadcasts this together with forecast data about the future 3D flight track. At the same time, its receiver listens for other FLARM devices within range and processes the information received. Advanced motion prediction algorithms predict potential conflicts for up to 50 other aircraft and alert the pilot using visual and aural warnings. FLARM has an integrated obstacle collision warning system together with an obstacle database. The database includes both point and segmented obstacles, such as split power lines and cableways.\n\nUnlike conventional transponders, FLARM has low power consumption and is relatively inexpensive to purchase and install. Furthermore, conventional Airborne Collision Avoidance Systems (ACAS) are not effective in preventing light aircraft from colliding with each other as light aircraft can be close to each other without danger of collision. ACAS would issue continuous and unnecessary warnings about all aircraft in the vicinity, whereas FLARM only issues selective warnings about collision risks.\n\nFLARM Technology and the inventors of FLARM have won several awards. The Swiss Office of Civil Aviation (FOCA) also published in Dec 2010: \"\"The rapid distribution of such systems only a few months after their introduction was not accomplished through regulatory measures, but rather on a voluntary basis and as a result of the wish on the part of the involved players to contribute towards the reduction of collision risk. The FOCA recommends that glider tow planes and helicopters that operate in lower airspace should also use collision warning systems\".\"\n\nIn addition, FLARM is mandatory in several countries including France, and the Soaring Society of America (SSA) strongly recommends FLARM in lieu of ADS-B Out.\n\nVersions are sold for use in light aircraft, helicopters, and gliders. Newer PowerFLARM models extend the FLARM range to over 10 km. They also have an integrated ADS-B and transponder Mode-C/S receiver, making it possible to also avoid mid-air collisions with large aircraft.\n\nNewer devices can also act as authorized flight recorders by producing files in the IGC format defined by the FAI Gliding Commission. All FLARM devices can be connected to FLARM displays or compatible avionics (EFIS, moving map, etc.) to give visual and aural warnings and also to show the intruder's position on the map. Licensed manufacturers produce integrated FLARM devices in different avionics products. FLARM devices can issue spoken warnings similar to TCAS.\n\nA typical FLARM system consists of the following hardware components:\n\nThe FLARM radio protocol has always been encrypted, which is reasoned by the manufacturer to ensure the integrity of the system and also because of privacy and security considerations. Version 4 used in 2008 and Version 6 used in 2015 were reverse engineered despite its encryption. However, FLARM changes the protocol on a regular basis .\n\nThe decryption of the FLARM radio protocol might be illegal, especially in EU countries. Article 6 of EU Directive 2013/40/EU states that \"[...] intercepting, by technical means, non-public transmissions of computer data to, from or within an information system, including electromagnetic emissions from an information system carrying such computer data, intentionally and without right, is punishable as a criminal offence [...]\". \"Information system\" is defined in Article 2 as \"a device or group of interconnected or related devices, one or more of which, pursuant to a programme, automatically processes computer data, as well as computer data stored, processed, retrieved or transmitted by that device or group of devices for the purposes of its or their operation, use, protection and maintenance\". The Convention on Cybercrime has a similar text in its Article 3. The Convention on Cybercrime has been ratified by most signatory countries.\n\nThe radio protocol has been criticised for its proprietary encryption, including a petition encouraging a change to an open protocol. It has been argued that encryption increases processing time and contradicts the goal to increase aviation safety due to a closed monopoly market, because an open protocol could enable third party manufacturers to develop compatible devices, spreading the use of interoperable traffic advisory systems.\nFLARM Technology opposed these claims as published on the petition page and published a white paper explaining the design of the system. They offer the technology to third parties, which requires the implementation of the OEM circuit board in compatible devices. Radio protocol specifications and crypto keys are not shared to third party manufacturers.\n\nWhile the FLARM serial data protocol is public, the prediction engine of FLARM is patented by Onera (France) and proprietary. It is licensed to manufacturers by FLARM Technology in Switzerland.\n\nFLARM was founded by Urs Rothacher and Andrea Schlapbach in 2003, who were later joined by Urban Mäder in 2004. First sales were made in early 2004. Currently there are nearly 30,000 FLARM-compatible devices (around half of them produced by FLARM Technology, the rest by licensed manufacturers who have now overtaken FLARM in current sales) in use mainly in Switzerland, Germany, France, Austria, Italy, UK, the Benelux, Scandinavia, Hungary, Israel, Australia, New Zealand and South Africa.\n\nFLARM's technology is also used in ground-based vehicles including vehicles used in surface-mining. These products are designed and produced by the Swiss company SAFEmine, now being owned by Swedish Hexagon Group.\n\n"}
{"id": "8906061", "url": "https://en.wikipedia.org/wiki?curid=8906061", "title": "Foot towel", "text": "Foot towel\n\nA foot towel is a small, rectangular towel which, in the absence of a rug, carpet or bathroom mat, is placed onto the bathroom floor to dry the feet on emerging from the shower or bath.\n\nCraig Kelston is believed to be the inventor of the foot towel which dates back to 1532.\n\nThe use of the foot towel is not widespread. A reason for this may be the fact that it tends to slip and slide around on tiled floors and does not have the same grip or friction of a rug, carpet or mat. However, some of the more recently produced foot towels include a specially designed under-surface, which improves grip and makes use safer.\n\nThere are two main types of foot towel:\n\n\nBoth varieties of foot towel are widely available.\n\nAs with regular bath towels, foot towels come in a variety of colours. Decorative foot towels can be purchased, albeit at a higher price. Some foot towel manufacturers feature landscapes and cartoon characters on their products.\n\nThe Integrated Convertible Foot Towel, enables an individual to dry his or her feet without stooping or bending over, and without putting a towel or rug on the floor.\n"}
{"id": "19310977", "url": "https://en.wikipedia.org/wiki?curid=19310977", "title": "GamersGate", "text": "GamersGate\n\nGamersGate AB (formerly Gamer's Gate) is a Sweden-based online video game store offering electronic strategy guides and games for Windows, OS X, and Linux via direct download. It is a competitor to online video game services such as Steam, GOG.com, Direct2Drive, and Impulse.\n\nGamersGate sells games for over 250 publishers and developers, including Electronic Arts, Atari, Bethesda Softworks, 2K Games, Ubisoft, SEGA, Capcom, Paradox Interactive and Epic Games as well as smaller independent developers such as 2D Boy, Jonathan Blow and Amanita Design. , there are over 6000 games available through GamersGate.\n\nThe idea of GamersGate was conceived by Paradox Interactive in 2004 after numerous fan requests for better access to Paradox's games were finally answered in the form of direct downloads. After Paradox sold a game to an Argentine fan via a download link that was later removed, word spread on the Paradox forums and international fans began asking if they too could purchase video games through downloads. Seeking to provide cheap distribution of games to countries that did not offer them in physical retail stores, Paradox developed a digital distribution system called \"Paradox on Demand\" and commenced trial operations in April 2006. On 20 November 2006, the system was officially launched under the name \"Gamer's Gate\". Interest in the service grew such that in 2008, after other publishers requested that Gamer's Gate distribute their games as well, Paradox decided to separate the service into an independent company called \"GamersGate\". By April 2009, GamersGate was offering 1000 video game titles. By April of the following year, they had doubled their offering to 2000 titles. An additional 1000 games were added in 2011, bringing the company's total to 3000 games. This pattern has repeated each year with 4000 games offered in 2012, 5000 offered in 2013, and over 6000 .\n\nAs a digital distribution company, GamersGate offers digital rights management-free (DRM-free) games and downloadable content (DLC) for PC, Mac, Linux, and Android platforms. GamersGate is a client-free service that does not require users to log on in order to play purchased games. In a January 2012 article for \"Escapist\" magazine, columnist Shamus Young speculated that these features would appeal to gamers opposed to the passive DRM validation, always-on DRM, and mandatory client program downloads that were common to many of GamersGate's top competitors. GamersGate accepts online payment by credit card or cash via Rixty. From 2012-2013, it offered a catalog of free games via its Void system.\n\nGamersGate is one of the earliest digital distribution sites and has undergone major aesthetic redesigns over the years. The first major redesign occurred in May 2009 when they adopted a design that \"Rock, Paper, Shotgun\"'s Alec Meer described as \"GoG-esque\" and \"shiny\". The second redesign occurred in July 2011 and was interpreted by some as a response to changes in the industry including the launch of Origin and the acquisitions of Direct2Drive by GameFly and Impulse by GameStop.\n\nGamersGate was one of the earliest video game stores to offer downloadable content for PC games, starting with downloadable content for the \"Hearts of Iron\" and \"Europa Universalis\" series.\n\nIn December 2008, GamersGate began offering developers MicroSuite, a free in-game downloadable-content API that allows game companies to insert DLC microtransactions into gameplay. The release of MicroSuite came only a few months after GamersGate's release of the GameNerve Publishing Suite, a management tool allowing users to publish and digitally distribute newly created games in order to maximize profits for the creator rather than an intermediate distribution company.\n\nGamersGate initially required a software client for its customers to download their purchased games, but on 28 January 2009, the company began allowing customers to download games through a micro-download. Under this system, every game is associated with a small corresponding program that, when downloaded, will retrieve the install files for the customer's computer. Upon retrieval, the user installs the game and may then remove the downloader from the computer. CEO Theo Bergquist has touted the client-less feature of GamersGate as a way to distinguish it from more dominant video game distribution platforms like Valve's Steam.\n\nSince its inception, GamersGate has eschewed the use of controversial digital rights management (DRM) schemes common to other digital video game distribution services. Games downloaded from GamersGate are released free of passive DRM validation and always-on DRM, and GamersGate users have the option of transferring purchased games to other accounts. Company CEO Theo Bergquist has emphasized the need for digital distribution companies to trust consumers. Although the potential for video game piracy and similar abuses are present through its method, GamersGate believes that trust in consumers acts as \"a source of comfort\" for its customers. The company has sought to work against piracy by cultivating mutual respect between itself and its strong player community. In an article for \"Information & Communications Technology Law\", Peter Holm suggests that perhaps GamersGate's best DRM-free defense against piracy is simply that it makes the legal purchase of games easy and cheap.\n\nIn addition to GamersGate's customer-friendly policies, rulings by the Court of Justice of the European Union on the topic of digital right of first sale have clarified that lessors who indefinitely license software thereby exhaust their property rights to the software. The effect of this ruling is that European digital distribution customers may resell downloaded games on the secondary market. Because GamersGate is based in Sweden and serves French, German, Italian, Polish, Spanish, and Swedish customers, this ruling has significance for GamersGate's European sales.\n\nGamersGate has partnered with over 250 publishers and developers including 2K Games, Atari, Capcom, Electronic Arts, Epic Games, Koei, SEGA, THQ, Ubisoft, and Vivendi Games among many others. GamersGate has also signed distribution agreements with numerous smaller independent video game developers and a wide variety of international developers like the Russian 1C Company, the British Blitz Games, the German Crimson Cow and Kalypso Media, and the French Microïds.\n\nInitially distributing only PC games, GamersGate began offering Mac games in June 2009 and later added Linux games and Android games. , the site lists over 1500 Mac titles. As GamersGate has expanded its catalog to include OS X and indie games, it has been acknowledged as a good place to download Mac games and for new game developers to get published and to make early sales.\n\nBecause it was formed as a split from a strategy game developer, the majority of the company's initial offerings were strategy war games. However, as third party developers signed on to distribute with Gamersgate, the site's offerings became increasingly eclectic. \"Rock, Paper, Shotgun\"'s Kieron Gillen noted in 2008 that GamersGate's Top 10 Sales chart provided \"a snapshot of a completely alien PC gaming world\" with obscure but meritorious titles outperforming mainstream titles. Gillen suggested that this was evidence that \"downloadable games enable niches.\" This pattern has lessened through the years but has never entirely disappeared. \"New Tang Dynasty Television\" drew attention to GamersGate's charts in 2014, when the free-to-play co-op game \"Warframe\" ranked alongside \"Castle of Illusion\".\n\nGamersGate frequently offers special deals and sales on its inventory. It has been praised by critics for its innovative bundling that, during some sales, allows purchasers to opt out of individual games enclosed within the bundle for a reduction in the bundle's price.\n\nAt E3 2011, GamersGate announced that it would be offering free video games in exchange for advertisement views. Players could download a game for free but, prior to playing it, would have to watch a short advertisement selected by GamersGate's advertising partner, Blind Ferret Media. Advertisements would not be inserted during gameplay. The new program, called \"FreeGames\", was set for beta release in mid-June 2011. Interest among gamers was so high that 10 thousand beta signups were made within the first few hours. The official start of the program was intended to be 1 September 2011 and to offer some 200 games. GamersGate CEO Theo Bergquist stated that the company's long-term goal was to offer as many of its 3000 games as possible under the FreeGames program. Bergquist's claims that this was the first program of its kind were refuted by \"Shacknews\"' Alice O'Conner, who pointed to a similar failed experiment by Ubisoft in 2007. However, in the following weeks GamersGate's beta run proved to be a success.\n\nGamersGate officially launched the follow-up program to FreeGames, christened \"Void\", on 28 May 2012. Like FreeGames, the service allowed customers with an account to download certain games for free in exchange for watching a few short advertisements. At release, nearly 100 games were available in the Void catalogue. The company ended the Void service in January 2013.\n\nAs one of the earliest digital distribution services, GamersGate saw rapid expansion in its earlier years with over 100 percent in growth from launch through 2009. Contemporaneously, GamersGate's parent company, Paradox Interactive, saw digital distribution overtake retail sales. In January 2011, it reported that GamersGate digital downloads accounted for 70 percent of Paradox's total revenue, which had grown over 1000 percent since 2001. By July of the same year, Paradox reported that 90 percent of its sales were digital (through both Steam and GamersGate).\n\nThe total market share of digital downloads going to GamersGate, however, is considerably smaller than its major competitor, Steam. It has also faced competition from newer companies like GOG.com and from contemporaries like Impulse and Direct2Drive. Analysis by Impulse owner Stardock in December 2009 indicated that Steam controlled at least 70 percent of the market with the other big players (Direct2Drive, GamersGate, and Impulse) competing over the remaining 30 percent. Stardock's claim that Impulse controlled 10 percent of the market was vocally disputed by both Direct2Drive and GamersGate, with GamersGate's Theo Bergquist arguing that \"in many, many cases we know that GamersGate sell as many units as Steam for the mid-size segment of titles.\" Luke Plunkett, writing for \"Kotaku\", noted that \"none of this bickering involves serious competing with Steam, leading us to believe that the PC scene's pecking order is Steam first, daylight second, and these guys jostling over the last spot on the podium.\" A July 2010 study conducted by NPD Group failed to list GamersGate among the top 5 digital distribution companies. However, this study was disputed by both GamersGate and Impulse (which also failed to rank).\n\nLaunched on the World Wide Web from Stockholm, Sweden in 2006, GamersGate has expanded internationally both online and offline. One of its first expansions took place in September 2010 when it opened an online branch within Facebook. Starting with the Swedish site, se.gamersgate.com, Gamersgate launched localized websites throughout Europe in late 2010 and early 2011. Specific versions of GamersGate were made for French, German, Italian, Polish, and Spanish language customers. The following year, GamersGate announced that, due to a 50 percent growth in sales from the previous year and in anticipation of its upcoming Void advertising program, it would be opening a physical shop and office in New York in 2012.\n\nGamersGate has been in active competition with digital distributors including Steam, Impulse, Direct2Drive, and to a lesser extent OnLive, and Origin. Notably, GamersGate has gained a reputation for sharp criticism of Steam which in 2011 Theo Bergquist suggested was \"peaking\". Although market statistics convincingly show Steam to be the most dominant player in the digital distribution market, Bergquist argues that this is strictly due to the fact that the market is currently oriented toward the hardcore gamer subculture. Bergquist predicts that Steam will lose market share as the market widens in the future and that GamersGate, with its considerably less cumbersome client-free and DRM-free system, is well positioned to grow rapidly. Disagreement over Steam's embracing of DRM technologies has led GamersGate and others to boycott the distribution of popular titles like \"\" that contain software such as IWNET, a player matchmaking service that works through Steam and therefore requires a Steam client and account. Describing games containing such software as Trojan horses, GamersGate and other digital distributors have refused to carry certain games that mandate the installation of client software.\n\nGamersGate's criticism of Impulse has also received extensive coverage in the gaming press. As early as 2009, GamersGate criticized Impulse owner Stardock's analysis of its share of the digital download market as misleadingly self-aggrandizing. A series of back and forth comments between the companies prompted \"Kotaku\"'s Luke Plunkett to describe GamersGate, Impulse, and Direct2Drive as \"guys jostling over the last spot on the podium\". Criticism was again levied by GamersGate against Impulse in April 2011 in response to GameStop's acquisition of Impulse from Stardock. GamersGate's Theo Bergquist questioned the wisdom of the purchase, describing Impulse as Steam's \"lesser talented stepchild\" and summarizing GameStop's press release as \"we will do whatever we can to not be the next Blockbuster\". GamersGate specifically pointed to shortcomings in Impulse's technological capacities, describing the service as \"outdated\" and archaic. In response, Stardock CEO Bradley Wardell suggested that the comments from GamersGate were more likely revelatory of GamersGate's financial situation and that perhaps the company wasn't operating as profitably as it claimed.\n"}
{"id": "58588999", "url": "https://en.wikipedia.org/wiki?curid=58588999", "title": "Ground Based Strategic Deterrent", "text": "Ground Based Strategic Deterrent\n\nGround Based Strategic Deterrent is a US land-based intercontinental ballistic missile system in the early stages of development, slated to replace all 450 Minuteman III missiles in service with the United States Air Force from 2027 onward. \n\nA request for proposal for development and maintenance of a Ground Based Strategic Deterrent next-generation nuclear ICBM, was made by the US Air Force Nuclear Weapons Center, ICBM Systems Directorate, GBSD Division on 29 July 2016. The GBSD would replace the Minuteman III in the land based portion of the US Nuclear Triad. The new missile to be phased in over a decade from the late 2020s are estimated over a fifty-year life cycle to cost around $86 billion. Boeing, Lockheed Martin, and Northrop Grumman are competing for the contract.\nOn 21 August 2017 the US Air Force awarded 3-year development contracts to Boeing and Northrop Grumman, for $349 million and $329 million, respectively. One of these companies will be selected to produce this ground-based nuclear ICBM in 2020. In 2027 the GBSD program is expected to enter service and remain active until 2075.\n"}
{"id": "266717", "url": "https://en.wikipedia.org/wiki?curid=266717", "title": "Handkerchief", "text": "Handkerchief\n\nA handkerchief (; also called a hankie or, historically, a handkercher) is a form of a kerchief or bandanna, typically a hemmed square of thin fabric or paper which can be carried in the pocket or handbag, and which is intended for personal hygiene purposes such as wiping one's hands or face, or blowing one's nose. A handkerchief is also sometimes used as a purely decorative accessory in a suit pocket, it is then called a pocket square. It is also an important accessory in many folkdances in many regions like the Balkans and the Middle East; an example of a folkdance using handkerchiefs is Kalamatianos.\n\nThe material of a handkerchief can be symbolic of the socioeconomic class of the user, not only because some materials are more expensive, but because some materials are more absorbent and practical for those who use a handkerchief for more than style. Handkerchiefs can be made of cotton, cotton-synthetic blend, synthetic fabric, silk, or linen.\n\nHandkerchiefs are also used as an impromptu way to carry around small items when a bag or basket is unavailable. They could also serve as a substitute for a bandage over a small injury. In the United Kingdom, the habit of wearing a handkerchief with tied corners on one's head at the beach has become a seaside postcard stereotype.\n\nSignals may also be sent by handkerchief, such as the American LGBT (lesbian, gay, bisexual, and transgender) handkerchief codes. In Spanish football or in bullfighting, it is a common sight to see supporters waving white handkerchiefs as an expression of deep emotion. It is used both positively, in admiration of an exceptional performance by a team or player, or as a negative sign of disgust at an especially bad performance.\n\nFrom the late 18th century white handkerchiefs were waved, generally by women (men usually waved their hats), to demonstrate approval at public events such as processions or political rallies.\n\nUsing handkerchiefs to accentuate hand movements while dancing is a feature of both West African and African-American traditional dance, in the latter case especially in wedding celebrations. Handkerchiefs are also traditional accoutrements in certain kinds of English folk dance, such as the Morris dance.\n\nBesides their intended use, they could be used for cleaning equipment, polishing shoes, cleaning hands and face, signalling for attention, as a sweat band, neckerchief, as protection from dust inhalation, to repair footwear, cut out pieces to patch clothes, cut up as emergency firearms cleaning patches, Molotov cocktail wick (fire-bomb), hot cooking utensil holder, a makeshift bandage, tourniquet, or arm sling.\n\nBefore people used the word handkerchief, the word kerchief alone was common. This term came from two French words: couvrir, which means “to cover,” and chef, which means “head.”\n\nIn the times of ancient Greece and Rome, handkerchiefs were often used the way they are today. But in the Middle Ages, kerchiefs were usually used to cover the head.\n\nThen in the 16th century, people in Europe began to carry kerchiefs in their pockets to wipe their forehead or their nose. To distinguish this kind of kerchief from the one used to cover the head, the word \"hand\" was added to \"kerchief\".\n\nKing Richard II of England, who reigned from 1377 to 1399, is widely believed to have invented the cloth handkerchief, as surviving documents written by his courtiers describe his use of square pieces of cloth to wipe his nose. Certainly they were in existence by Shakespeare's time, and a handkerchief is an important plot device in his play \"Othello\".\n\nIn addition to carrying for practical purposes, handkerchiefs have long been displayed in the top pocket of men's jackets. Used in this way, they are referred to as a pocket handkerchief or pocket square. A traditional pocket square will have the hem rolled, contrary to handkerchiefs.\n\nThe trend of pocket squares as a fashion accessory really started during the 1920s, and continued until the 1960s. During that period, actors such as Cary Grant, Fred Astaire and Gary Cooper wore them regularly. The pocket square subsequently fell into disuse until the late 2000s when it made a comeback thanks in part to popular television shows such as \"Mad Men\".\n\nPocket squares are usually made in fabrics such as silk, cotton, linen or wool.\n\nAs a visible fashion item there are a wide variety of ways to fold a pocket square, ranging from the austere to the flamboyant:\n\n"}
{"id": "43576460", "url": "https://en.wikipedia.org/wiki?curid=43576460", "title": "Heterogeneous combustion", "text": "Heterogeneous combustion\n\nHeterogeneous combustion, otherwise known as combustion in porous media, is a type of combustion in which a solid and gas phase interact to promote the complete transfer of reactants to their lower energy potential products. In this type of combustion a high surface area solid is immersed into a gaseous reacting flow, additional fluid phases may or may not be present. Chemical reactions and heat transfer occur locally on each phase and between both phases. Heterogeneous Combustion differs from catalysis as there is no focus to either phase individually but rather both examined simultaneously. In some materials, such as silicon carbide (SiC), oxide layers, SiO and SiO, which form on the surface enable the adsorption of water vapor from the gas phase onto the solid lowering partial pressures.\nIn this regime of combustion, thermal heat released from the combustion byproducts are transferred into the solid phase by convection; conduction and radiation both then conduct heat upstream (along with adverse convection within the gas phase). Heat is then convectively transferred to the unburnt reactants.\n\nWithin the literature, there many applications of heterogeneous combustion which are derived from the unique manner in which this combustion process recirculates heat. These devices may be utilized as either stand alone devices, or in conjunction with other means of energy conversion for highly efficient combined heat and power (CHP) applications. For example, electricity production via both radiative and convective heat exchange with the combustion chamber can be accomplished using Organic Rankine Cycles in a multi step heating process, or using strictly radiative emissions via photovoltaic and thermionic generators. \nHeterogeneous combustors may be utilized for small-scale heating purposes, and as oxidizers of volatile organic compounds (VOCs). Heterogeneous combustion may also be combined in series and parallel with multiple injection stages for use in gas flares at chemical manufacturing plants or oil wells.\n\nWithin a combustion chamber containing porous media, structure of the environment can be assumed as follows. A preheating region exists prior to the surface of the flame front denoted by δ. Preheating length is marked by the beginning of the porous solid where appreciable heat transfer to the gas phase occurs and ends when the solid and gas phase reach equilibrium temperature. The region of chemical heat release, the flame, whose thickness can be given as δ, exists following the preheat region and its length is dependent upon mass flux, surface properties, and equivalence ratio. Beyond the flame, where minimal chemical heat release occurs, heat is convectively transferred from the post combustion gasses into the solid. Heat then conducts and radiates through the solid structure upstream through the flame. Within the preheating region, heat is again convectively transferred from the solid structure to the gas.\n"}
{"id": "11551989", "url": "https://en.wikipedia.org/wiki?curid=11551989", "title": "History of numerical solution of differential equations using computers", "text": "History of numerical solution of differential equations using computers\n\nDifferential equations, in particular Euler equations, rose in prominence during World War II in calculating the accurate trajectory of ballistics, both rocket-propelled and gun or cannon type projectiles. Originally, mathematicians used the simpler calculus of earlier centuries to determine velocity, thrust, elevation, curve, distance, and other parameters.\n\nNew weapons, however, such as Germany's giant cannons, the \"Paris Gun\" (Encyclopedia Astronautica) and \"Big Bertha,\" and the V-2 rocket, meant that projectiles would travel hundreds of miles in distance and dozens of miles in height, in all weathers. As a result, variables such as diminished wind resistance in thin atmospheres and changes in gravitational pull reduced accuracy using the historic methodology. There was the additional problem of planes that could now fly hundreds of miles an hour. Differential equations were applied to stochastic processes. Developing machines that could speed up human calculation of differential equations led in part to the creation of the modern computer through the efforts of Vannevar Bush, John von Neumann and others.\n\nAccording to Mary Croarken in her paper \"Computing in Britain During World War II,\" by 1945, the Cambridge Mathematical Laboratory created by John Lennard-Jones utilized the latest computing devices to perform the equations. These devices included a model \"differential analyser,\" and the Mallock machine, described as \"an electrical simultaneous equation solver.\" According to Croarken, the Ministry was also interested in the new arrival of a differential analyzer accommodating eight integrators. This exotic computing device built by Metropolitan-Vickers in 1939 consisted of wheel and disk mechanisms that could provide descriptions and solutions for differential equations. Output resulted in a plotted graph.\n\nAt the same time, in the United States, analog computer pioneer Vannevar Bush took on a similar role to that of Lennard-Jones in the military effort after President Franklin Delano Roosevelt entrusted him with the bulk of wartime research into automatic control of fire power using machines and computing devices.\n\nAccording to Sarah Bergbreiter in her paper \"Moving from Practice to Theory: Automatic Control after World War II,\" fire control for the downing of enemy aircraft by anti-aircraft guns was the priority. The analog electro-mechanical computing machines plotted the differential firing data while servos created by H.L. Hazen adapted the data to the guns for precise firing control and accuracy. Other improvements of a similar type by Bell Labs increased firing stability so that output from the differential engines could be fully used to compensate for stochastic behaviors of enemy aircraft and large guns. A new age of intelligent warfare had begun.\n\nThis work at MIT and Bell Labs would later lead to Norbert Wiener's development of the electronic computer and the science of cybernetics for the same purpose, speeding the differential calculation process exponentially and taking one more giant step toward the creation of the modern digital computer using von Neumann architecture. Dr. von Neumann was one of the original mathematicians employed in the development of differential equations for ballistic warfare.\n\n\n"}
{"id": "20320971", "url": "https://en.wikipedia.org/wiki?curid=20320971", "title": "Hydrogen purity", "text": "Hydrogen purity\n\nHydrogen purity or hydrogen quality is a term to describe the lack of impurities in hydrogen as a fuel gas. The purity requirement varies with the application, for example a H ICE can tolerate low hydrogen purity where a hydrogen fuel cell requires high hydrogen purity to prevent catalyst poisoning.\n\nIn the first generation of fuel cells catalysts like palladium, ruthenium and platinum are used in combination with hydrogen production from hydrocarbons which results in performance degradation. \n\nThe catalyst poisoning induced by some impurities like carbon monoxide, formic acid, or formaldehyde can be reversed with a high purity hydrogen stream. Presence of other impurities like sulfurs may lead to permanent degradation of the fuel cells The kind of impurities and their level depends on the H production process (e.g., steam methane reforming, electrolysis) but impurities can also be introduced due to transport, cleaning of the refueling station, leakages or maintenance. \n\nIn Europe, the Directive 2014/94/EU on the deployment of alternative fuels infrastructure states that the hydrogen purity dispensed by hydrogen refuelling points shall comply with the technical specifications included in the ISO 14687-2 standard. ISO 14687-2 specifies maximum impurities levels for particles and several gaseous impurities. For many compounds the limit values are very low including total sulfur (4 nmol/mol) or carbon monoxide (200 nmol/mol). The least stringent limits are for helium (300 µmol/mol) and total nitrogen/argon (300 µmol/mol).  The sum of the impurities should be less than 300 µmol/mol (e.g. H purity is 99.97%). \n\nAs the limit values for many impurities are very low this sets stringent demands on the sensitivity of the analytical methods. Moreover, the high reactivity of some impurities requires use of a properly passivated sampling and analytical systems. A combination of different instruments (e.g. gas chromatography, infrared spectroscopy and mass spectroscopy) is now needed to cover all components listed in ISO 14687-2. Currently, several research efforts are directed to address the existing problems focusing on new multi-component analytical methods, risk assessments to limit the number of impurities to be analyzed (e.g. by using information from the H production process) and lay the metrological foundation for H purity analysis (,).\n\n\n"}
{"id": "55726954", "url": "https://en.wikipedia.org/wiki?curid=55726954", "title": "Integrated route network", "text": "Integrated route network\n\nAn integrated route network is one that allows the traveller to experience a safe, convenient, and comfortable trip door-to-door. Segments of journeys are continuous in space, services are scheduled to minimize waiting times, and ticketing or other administrative tasks are reduced to the minimum. The concept may be applied to single transport modes or to combinations. Key elements include coordinated planning, continuous infrastructure, carefully-timed operations, and information to users. \n\nIn order to achieve an integrated network including different modes of transport, all agencies responsible for the various modes must work effectively together. If they are fragmented, and especially if they are in direct competition with each other, effective joint working is unlikely.\n\nProspective travellers must be able to access information about their possible journey. For public transport services, travellers should be able to access real-time information on services, or should (in high-use areas) be confident that the next service will arrive very shortly.\n"}
{"id": "44158633", "url": "https://en.wikipedia.org/wiki?curid=44158633", "title": "International Institute for Nanotechnology", "text": "International Institute for Nanotechnology\n\nThe International Institute for Nanotechnology (IIN) was established by Northwestern University in 2000. It was the first institute of its kind in the United States and is one of the premier nanoscience research centers in the world. Today, the IIN represents and unites more than $1 billion in nanotechnology research, educational programs, and supporting infrastructure.\n\nIIN faculty includes 85 members of the National Academy of Sciences, the National Academy of Engineering, and the Institute of Medicine. It brings together more than 240 chemists, engineers, biologists, physicians, and business experts, to focus on application of nanotechnology to improve society, creating a synergy essential to the progress of nanotechnology, that cannot be easily found elsewhere. It has developed collaborative partnerships with academic institutions around the world, including sister institutes at the Nanyang Technological University, Singapore, and the Hunan University, China. Over 100 corporations partner with the IIN through active research and the Nanotechnology Corporate Partners program.\n\nSince its inception, more than 2,000 products and systems have been commercialized worldwide. Twenty start-up companies have been launched based upon IIN research, and they have attracted over $700 million in venture capital funding. The IIN is changing the face of research in fields from medical diagnostics to materials science. The IIN drives innovation-based business formation, employment and economic growth.\n\nThe IIN has partnerships in 18 countries outside the United States, as well as connections with universities worldwide. For students, these relationships mean they can take advantage of postdoctoral exchange programs. Their annual symposium draws researchers from around the world.\n\nThe IIN embodies an extraordinary combination of scientific capabilities, outreach programs, and partnerships that provide a unique and fertile ground from which to continue to make substantial contributions to the field and ensure that the U.S. remains a world leader in nanotechnology. The role of the Institute is to support meaningful efforts in nanotechnology, house state-of-the-art nanomaterials characterization facilities, and nucleate individual and group efforts aimed at addressing and solving key problems in nanotechnology. The IIN positions Northwestern University and its partners in academia, industry, and national labs as leaders in this exciting field.\n\nResearch is organized into the following eight pillars, each focused on a critical societal issue:\n\n\nIIN faculty are drawn from 31 schools and departments at Northwestern:\nThe IIN Executive Council is a group of business people, led by David Kabiller, committed to advocating for nanotechnology research and education; promoting the IIN as a high-impact philanthropic opportunity; and advising IIN leadership on philanthropy, marketing, and bringing technology from the laboratory to market.\n\nNanomedicine is an emerging field that focuses on using nanotechnology to impact the field of medicine. Powerful new ways of studying, diagnosing, and treating diseases have been the dividends of basic research in the field of nanoscience. Indeed, this field and the materials devices that derive from it, have a chance to revolutionize medicine as we currently know it.\n\nThrough a generous donation from entrepreneur David Kabiller, the IIN established the $250,000 Kabiller Prize in Nanoscience and Nanomedicine and the $10,000 Kabiller Young Investigator Award in Nanoscience and Nanomedicine. Every other year, the Kabiller Prize recognizes individuals who have made a career-long, significant impact in the field of nanotechnology applied to medicine and biology. The Kabiller Young Investigator Award recognizes individuals who have made breaking discoveries within the last few years in the same area that have the potential to make a lasting impact.\n\nThe IIN seeks to develop and nurture the scientists, engineers, technicians, and teachers of tomorrow; enrich the academic environment; and inform and engage the public through the following programs:\n\n\nThe IIN has created a new kind of research coalition with a large precompetitive nanoscale science and engineering platform for developing applications, demonstrating manufacturability and training skilled researchers.\n\nThe IIN works on joint research initiatives with corporations including:\nThis program links institute researchers with venture capital experts and has resulted in the formation the 20 companies below, which have collectively raised over $700 million in financing:\n"}
{"id": "11263300", "url": "https://en.wikipedia.org/wiki?curid=11263300", "title": "Krakatoa (explosive)", "text": "Krakatoa (explosive)\n\nKrakatoa is a modular explosive device used for explosive ordnance disposal (EOD) or demolitions developed by the British company Alford Technologies. The device is designed to fire a number of different projectiles, operates both in air and underwater, and can be used in a vertical or horizontal orientation.\n\nThe device was featured during the second season of Discovery Channel's television series \"Future Weapons\", in which it was shown penetrating an inch of steel plate at 25 yards. The device's casing is made of plastic which is packed with plastique (C4) and capped with an inverted copper cone.\n\nThe device itself is \"no bigger than a standard can of coke.\"\n\nIt is named after the famous 1883 eruption of Krakatoa, which resulted in the loudest sound ever heard and was the second deadliest volcanic eruption in recorded history.\n\nThis explosive device was designed to play a role in covert operations, as a small but extremely powerful device that can disable tanks, vehicles, or even a warship. The device can be used underwater, at high altitudes, and in snow, hail, sleet, or any form of weather.\n\nThe device has copper cone with a driving charge of very fast high explosive behind it. The metal cone is the difference between a regular C4 'slappack' or hollow charge and a HEAT device.\n\nWhen detonated, the copper cone is inverted into a narrow stream of copper and fired at extremely high velocity at the target, this can pierce certain thicknesses of steel armor or concrete.\n\nThe weapon looks like a small circular tube, no wider than a tea-cup plate and no taller than a soft-drink can. On one end, it is covered with plastic, but the other end houses the copper cone. Inside the actual device is C4, and this is used to form the copper into an explosively formed penetrator and turn it into a weapon. So far unused in war, it is tested standing on a small pair of bipod legs, and the copper cone is faced toward the target. There is a 'stand off distance' to allow correct formation of the penetrator stream. This is the reason for its legs.\n\nFor a special ops team, the weapon will already have the C4 placed inside, about two pounds of it, and being a versatile explosive, the weapon will not set off in any condition. One uses it by placing it on the stand, moving far away from it and then pressing the detonator. The whole weapon itself explodes, so it is not a handheld weapon or a device to stand near when operating or firing.\n\n"}
{"id": "17081959", "url": "https://en.wikipedia.org/wiki?curid=17081959", "title": "LCR meter", "text": "LCR meter\n\nAn LCR meter is a type of electronic test equipment used to measure the inductance (L), capacitance (C), and resistance (R) of an electronic component. In the simpler versions of this instrument the impedance was measured internally and converted for display to the corresponding capacitance or inductance value. \nReadings should be reasonably accurate if the capacitor or inductor device under test does not have a significant resistive component of impedance. More advanced designs measure true inductance or capacitance, as well as the equivalent series resistance of capacitors and the Q factor of inductive components.\n\nUsually the device under test (DUT) is subjected to an AC voltage source. The meter measures the voltage across and the current through the DUT. From the ratio of these the meter can determine the magnitude of the impedance. The phase angle between the voltage and current is also measured in more advanced instruments; in combination with the impedance, the equivalent capacitance or inductance, and resistance, of the DUT can be calculated and displayed. The meter must assume either a parallel or a series model for these two elements. An ideal capacitor has no characteristics other than capacitance, but there are no physical ideal capacitors. All real capacitors have a little inductance, a little resistance, and some defects causing inefficiency. These can be seen as inductance or resistance in series with the ideal capacitor or in parallel with it. And so likewise with inductors. Even resistors can have inductance (especially if they are wire wound types) and capacitance as a consequence of the way they are constructed. The most useful assumption, and the one usually adopted, is that LR measurements have the elements in series (as is necessarily the case in an inductor's coil) and that CR measurements have the elements in parallel (as is necessarily the case between a capacitor's 'plates'). Leakage is a special case in capacitors, as the leakage is necessarily across the capacitor plates, that is, in series. \n\nAn LCR meter can also be used to measure the inductance variation with respect to the rotor position in permanent magnet machines. (However, care must be taken, as some LCR meters will be damaged by the generated EMF produced by turning the rotor of a permanent-magnet motor; in particular those intended for electronic component measurements.)\n\nHandheld LCR meters typically have selectable test frequencies of 100 Hz, 120 Hz, 1 kHz, 10 kHz, and 100 kHz for top end meters. The display resolution and measurement range capability will typically change with the applied test frequency since the circuitry is more sensitive or less for a given component (ie, an inductor or capacitor) as the test frequency changes.\n\nBenchtop LCR meters sometimes have selectable test frequencies of more than 100 kHz. They often include options to superimpose a DC voltage or current on the AC measuring signal. Lower end meters might offer the possibility to externally supply these DC voltages or currents while higher end devices can supply them internally. In addition benchtop meters typically allow the usage of special fixtures (ie, Kelvin wiring, that is to say, 4-wire connections) to measure SMD components, air-core coils or transformers.\n\nInductance, capacitance, resistance, and dissipation factor can also be measured by various bridge circuits. They involve adjusting variable calibrated elements until the signal at a detector becomes null, rather than measuring impedance and phase angle.\n\nEarly commercial LCR bridges used a variety of techniques involving the matching or \"nulling\" of two signals derived from a single source. The first signal was generated by applying the test signal to the unknown and the second signal was generated by using a combination of known-value R and C standards. The signals were summed through a detector (normally a panel meter with or without some level of amplification). When zero current was noted by changing the value of the standards and looking for a \"null\" in the panel meter, it could be assumed that the current magnitude through the unknown was equal to that of the standard and that the phase was exactly the reverse (180 degrees apart). The combination of standards selected could be arranged to read out C and DF directly which was the precise value of the unknown. An example of this is the GenRad/IET Labs Model 1620 and 1621 Capacitance Bridges.\n\n\n"}
{"id": "2053455", "url": "https://en.wikipedia.org/wiki?curid=2053455", "title": "Linens", "text": "Linens\n\nLinens are fabric household goods intended for daily use, such as bedding, tablecloths and towels. \"Linens\" may also refer to church linens, meaning the altar cloths used in church.\n\nThe earliest known household linens were made from thin yarn spun from flax fibres to make linen cloth. Ancient Egypt, Babylon, and Phoenicia all cultivated flax crops. The earliest surviving fragments of linen cloth have been found in Egyptian tombs and date to 4000 BCE. Flax fibres have been found in cloth fragments in Europe that date to the Neolithic prehistoric age.\n\nCotton is another popular fibre for making cloth used for household linens. Its use in cloth-making also dates back to prehistoric times, in Indian subcontinent, China, Peru and Egypt. The Indian subcontinent was especially well known for high quality cotton cloth as early as 1500 BCE.\n\nLinen was an especially popular cloth during the Middle Ages in Europe, when cotton was an exotic import. It was used for underclothing, chemises, shifts, shirts and blouses, in fact most clothing worn next to the skin, by those able to afford an extra layer of clothing. The tradition of calling household fabric goods \"linens\" dates from this period, but meant clothing as much as large sheets. According to medieval tradition, which survived up until the modern era, a bride would often be given a gift of linens made by the women in her family as a wedding present, to help her set up her new married home. In France this was called a trousseau, and was often presented to the bride in a wooden hope chest. \n\nThe Industrial Revolution brought huge changes to cloth manufacturing. The rise of European colonialism at the same time helped support the rapid growth of cloth production by creating many cheap sources of raw materials. British cloth manufacturers would import raw cotton from America and the British West Indies to Ireland, where it would be spun into yarn. The yarn would be imported into England, where mechanized factories employed thousands of workers, who would weave cloth on industrial looms. In 1781, a cloth producer from Manchester testified about his business to a committee of the House of Commons in the British Parliament. He stated that he employed 6000 workers, who would print and stamp 60,000 yards of cotton and linen fabric a year. Cotton gradually replaced linen for most uses in clothing, but remained preferred for bedsheets and tablecloths. Other European countries manufactured and traded their own types of household linens as well, and mass manufacturing techniques and trade competition gradually made affordable household linens common.\n\nToday, the term \"linen\" is still used for bedsheets, tablecloths and similar household textiles, even though most are made of cotton, synthetic fabrics, or blends. Especially in American English, they may be called \"white goods\", otherwise a term for kitchen major appliances.\n\nCleaning household linens is done as appropriate to the type of cloth. Household linens are most likely to have stains from organic sources such as food, blood, and soil. If the linens are made of natural fibres such as linen or cotton, the cloth will need to be rinsed as soon as possible in cold water to prevent the stain from becoming permanent. Stains from red wine, or red or purple berries and fruit are an exception and must be washed in boiling water, yet despite this, these stains may be impossible to remove. Otherwise, regular washing of household linens should be done in hot water for hygienic reasons, to destroy bacteria left on the linens from frequent use. Linen and cotton that are white may also become yellow over time, but this is eliminated by bleaching, either with liquid bleach, or by the traditional method of hanging the linens in the sun to let the sunlight bleach out the discoloration.\n\nHousehold linens are stored near the area where they are used, when possible, for convenience. Otherwise, bed and kitchen and dining linens may be stored together in a linen closet or cupboard. There are many methods of folding linens for storage. For formal occasions, table linens may be ironed before use. Traditionally, table linens could be starched while ironing, to decrease wrinkling and retain a smooth, pristine appearance. Seasonal storage of linens led to the development of natural pest control methods in Europe to prevent moth larvae and other insects or rodents from eating the cloth. Sachets made of dried Margosa (neem), cloves, lavender, and other herbs are traditional, as are cedar wood chips.\n\nIndustrial laundries were developed in the Middle Ages, when large convents and monasteries used their own facilities. Hospitals and boarding schools followed this example. Today, there are several types of industrial laundries. Hospitals often use laundry chutes to collect used linens. These are transported to an industrial laundry, where they are sorted into three categories: regularly soiled, infected, or staff uniforms. They are laundered as appropriate, usually at high temperatures, to ensure that viruses, bacteria, and soil are cleaned and that the linens are hygienic before being returned to the hospital.\n\nIn India, Dhobi ghats provide laundry service to both institutions and households. Household linens and clothing are both collected on a fixed day of the week by the Dhobi, who washes the laundry at a ghat, which is often in a large Dhobi ghat zone where many Dhobis work at their own stall. Each stall is approximately four square metres. Laundry is washed in large tubs, rinsed, cleaned by beating on a stone made for the purpose, and then the linens are hung on lines to dry. Industrial linens are treated in steamers for several hours for hygienic reasons. Dhobis also iron linens.\n\nThe collecting and restoring of antique linens can be complex, depending upon the condition of the cloth. Many old household linens were stored filled with starch, which damages the cloth over time since it hardens and causes wearing and tears in the fabric where it is folded and creased. The owner of an antique linen must determine if conserving, repairing, or mending are appropriate.\n\nTypes of antique linens may be identified by the place where they were made. Some well-known locations for making heirloom-quality household linens include Ireland, for its Irish linen and lace, and Madeira, known for a type of linen called Madeira cloth. The type of embellishment on the linens may make them collectable, especially embroidery, including Victorian-era redwork and bluework, which use only red or blue thread. Lace embellishments on linens also make them collectable, such as Battenberg lace.\n\nJanuary \"White sales\" have been a custom in the United States since the late 19th century. White sales are held by department stores to sell household linens, bedding and towels, at a price discount. The sales are called \"White sales\" since the sales started during an era when these items were only available in white.\n\nChurch linens are used in some Christian churches, with the Roman Catholic Church having perhaps the most elaborate use of them. Linens are used to represent the sacred nature of the altar and to protect the Eucharist. Church linens include:\n"}
{"id": "15007551", "url": "https://en.wikipedia.org/wiki?curid=15007551", "title": "List of gear nomenclature", "text": "List of gear nomenclature\n\nThe addendum is the height by which a tooth of a gear projects beyond (outside for external, or inside for internal) the standard pitch circle or pitch line; also, the radial distance between the pitch diameter and the outside diameter.\nAddendum angle in a bevel gear, is the angle between face cone and pitch cone.\n\nThe addendum circle coincides with the tops of the teeth of a gear and is concentric with the standard (reference) pitch circle and radially distant from it by the amount of the addendum. For external gears, the addendum circle lies on the outside cylinder while on internal gears the addendum circle lies on the internal cylinder.\n\nApex to back, in a bevel gear or hypoid gear, is the distance in the direction of the axis from the apex of the pitch cone to a locating surface at the back of the blank.\n\nThe back angle of a bevel gear is the angle between an element of the back cone and a plane of rotation, and usually is equal to the pitch angle.\n\nThe back cone of a bevel or hypoid gear is an imaginary cone tangent to the outer ends of the teeth, with its elements perpendicular to those of the pitch cone. The surface of the gear blank at the outer ends of the teeth is customarily formed to such a back cone.\n\nBack cone distance in a bevel gear is the distance along an element of the back cone from its apex to the pitch cone.\n\nIn mechanical engineering, backlash is the striking back of connected wheels in a piece of mechanism when pressure is applied. Another source defines it as the maximum distance through which one part of something can be moved without moving a connected part. It is also called lash or play. In the context of gears, backlash is clearance between mating components, or the amount of lost motion due to clearance or slackness when movement is reversed and contact is re-established. In a pair of gears, backlash is the amount of clearance between mated gear teeth.\n\nBacklash is unavoidable for nearly all reversing mechanical couplings, although its effects can be negated. Depending on the application it may or may not be desirable. Reasons for requiring backlash include allowing for lubrication and thermal expansion, and to prevent jamming. Backlash may also result from manufacturing errors and deflection under load.\n\nThe base circle of an involute gear is the circle from which involute tooth profiles are derived.\n\nThe base cylinder corresponds to the base circle, and is the cylinder from which involute tooth surfaces are developed.\n\nThe base diameter of an involute gear is the diameter of the base circle.\n\nThe term bull gear is used to refer to the larger of two spur gears that are in engagement in any machine. The smaller gear is usually referred to as a pinion.\n\nCenter distance (operating) is the shortest distance between non-intersecting axes. It is measured along the mutual perpendicular to the axes, called the line of centers. It applies to spur gears, parallel axis or crossed axis helical gears, and worm gearing.\n\nThe central plane of a worm gear is perpendicular to the gear axis and contains the common perpendicular of the gear and worm axes. In the usual case with axes at right angles, it contains the worm axis.\n\nThe composite action test (double flank) is a method of inspection in which the work gear is rolled in tight double flank contact with a master gear or a specified gear, in order to determine (radial) composite variations (deviations). The composite action test must be made on a variable center distance composite action test device.\nand this is composite action test for double flank\nCone distance in a bevel gear is the general term for the distance along an element of the pitch cone from the apex to any given position in the teeth.\n\nOuter cone distance in bevel gears is the distance from the apex of the pitch cone to the outer ends of the teeth. When not otherwise specified, the short term cone distance is understood to be outer cone distance.\n\nMean cone distance in bevel gears is the distance from the apex of the pitch cone to the middle of the face width.\n\nInner cone distance in bevel gears is the distance from the apex of the pitch cone to the inner ends of the teeth.\n\nConjugate gears transmit uniform rotary motion from one shaft to another by means of gear teeth. The normals to the profiles of these teeth, at all points of contact, must pass through a fixed point in the common centerline of the two shafts. Usually conjugate gear tooth is made to suit the profile of other gear which is not made based on standard practice.\n\nA crossed helical gear is a gear that operate on non-intersecting, non-parallel axes.\n\nThe term crossed helical gears has superseded the term \"spiral gears\". There is theoretically point contact between the teeth at any instant. They have teeth of the same or different helix angles, of the same or opposite hand. A combination of spur and helical or other types can operate on crossed axes.\n\nThe crossing point is the point of intersection of bevel gear axes; also the apparent point of intersection of the axes in hypoid gears, crossed helical gears, worm gears, and offset face gears, when projected to a plane parallel to both axes.\n\nThe crown circle in a bevel or hypoid gear is the circle of intersection of the back cone and face cone.\n\nCrowned teeth have surfaces modified in the lengthwise direction to produce localized contact or to prevent contact at their ends.\nDedendum angle in a bevel gear, is the angle between elements of the root cone and pitch cone.\n\nEquivalent pitch radius is the radius of the pitch circle in a cross section of gear teeth in any plane other than a plane of rotation. It is properly the radius of curvature of the pitch surface in the given cross section. Examples of such sections are the transverse section of bevel gear teeth and the normal section of helical teeth.\n\nFace (tip) angle in a bevel or hypoid gear, is the angle between an element of the face cone and its axis.\n\nThe face cone, also known as the tip cone is the imaginary surface that coincides with the tops of the teeth of a bevel or hypoid gear.\n\nA face gear set typically consists of a disk-shaped gear, grooved on at least one face, in combination with a spur, helical, or conical pinion. A face gear has a planar pitch surface and a planar root surface, both of which are perpendicular to the axis of rotation. It can also be referred to as a face wheel, crown gear, crown wheel, contrate gear or contrate wheel.\n\nThe face width of a gear is the length of teeth in an axial plane. For double helical, it does not include the gap.\n\nTotal face width is the actual dimension of a gear blank including the portion that exceeds the effective face width, or as in double helical gears where the total face width includes any distance or gap separating right hand and left hand helices.\n\nFor a cylindrical gear, effective face width is the portion that contacts the mating teeth. One member of a pair of gears may engage only a portion of its mate.\n\nFor a bevel gear, different definitions for effective face width are applicable.\n\nForm diameter is the diameter of a circle at which the trochoid (fillet curve) produced by the tooling intersects, or joins, the involute or specified profile. Although these terms are not preferred, it is also known as the true involute form diameter (TIF), start of involute diameter (SOI), or when undercut exists, as the undercut diameter. This diameter cannot be less than the base circle diameter.\n\nThe front angle, in a bevel gear, denotes the angle between an element of the front cone and a plane of rotation, and usually equals the pitch angle.\n\nThe front cone of a hypoid or bevel gear is an imaginary cone tangent to the inner ends of the teeth, with its elements perpendicular to those of the pitch cone. The surface of the gear blank at the inner ends of the teeth is customarily formed to such a front cone, but sometimes may be a plane on a pinion or a cylinder in a nearly flat gear.\n\nA gear center is the center of the pitch circle.\n\nThe gear range is difference between the highest and lowest gear ratios and may be expressed as a percentage (e.g., 500%) or as a ratio (e.g., 5:1).\n\nThe heel of a tooth on a bevel gear or pinion is the portion of the tooth surface near its outer end.\n\nThe toe of a tooth on a bevel gear or pinion is the portion of the tooth surface near its inner end.\n\nA helical rack has a planar pitch surface and teeth that are oblique to the direction of motion.\n\nHelix angle is the angle between the helical tooth face and an equivalent spur tooth face. For the same lead, the \"helix angle\" is greater for larger gear diameters. It is understood to be measured at the standard pitch diameter unless otherwise specified.\nHobbing is a machining process for making gears, splines, and sprockets using a cylindrical tool with helical cutting teeth known as a hob.\n\nThe displacement of any tooth flank from its theoretical position, relative to a datum tooth flank.\n\nDistinction is made as to the direction and algebraic sign of this reading. A condition wherein the actual tooth flank position was nearer to the datum tooth flank, in the specified measuring path direction (clockwise or counterclockwise), than the theoretical position would be considered a minus (-) deviation. A condition wherein the actual tooth flank position was farther from the datum tooth flank, in the specified measuring path direction, than the theoretical position would be considered a plus (+) deviation.\n\nThe direction of tolerancing for index deviation along the arc of the tolerance diameter circle within the transverse plane.\n\nThe inside cylinder is the surface that coincides with the tops of the teeth of an internal cylindrical gear.\n\nInside diameter is the diameter of the addendum circle of an internal gear, this is also known as minor diameter.\nExpressed as θ, the involute polar angle is the angle between a radius vector to a point, \"P\", on an involute curve and a radial line to the intersection, \"A\", of the curve with the base circle.\nExpressed as ε, the involute roll angle is the angle whose arc on the base circle of radius unity equals the tangent of the pressure angle at a selected point on the involute.\nInvolute teeth of spur gears, helical gears, and worms are those in which the profile in a transverse plane (exclusive of the fillet curve) is the involute of a circle.\nThe bottom land is the surface at the bottom of a gear tooth space adjoining the fillet.\n\nTop land is the (sometimes flat) surface of the top of a gear tooth.\nLead is the axial advance of a helix gear tooth during one complete turn (360°), that is, the \"Lead\" is the axial travel (length along the axle) for one single complete helical revolution about the pitch diameter of the gear.\n\nLead angle is 90° to the helix angle between the helical tooth face and an equivalent spur tooth face. For the same lead, the \"lead angle\" is larger for smaller gear diameters. It is understood to be measured at the standard pitch diameter unless otherwise specified.\n\nA spur gear tooth has a \"lead angle\" of 90°, and a \"helix angle\" of 0°.\n\nSee: Helix angle\n\nThe line of centers connects the centers of the pitch circles of two engaging gears; it is also the common perpendicular of the axes in crossed helical gears and wormgears. When one of the gears is a rack, the line of centers is perpendicular to its pitch line.\n\nMounting distance, for assembling bevel gears or hypoid gears, is the distance from the crossing point of the axes to a locating surface of a gear, which may be at either back or front.\nNormal module is the value of the module in a normal plane of a helical gear or worm.\n\nA normal plane is normal to a tooth surface at a pitch point, and perpendicular to the pitch plane. In a helical rack, a normal plane is normal to all the teeth it intersects. In a helical gear, however, a plane can be normal to only one tooth at a point lying in the plane surface. At such a point, the normal plane contains the line normal to the tooth surface.\n\nImportant positions of a normal plane in tooth measurement and tool design of helical teeth and worm threads are:\n\n\nIn a spiral bevel gear, one of the positions of a normal plane is at a mean point and the plane is normal to the tooth trace.\n\nOffset is the perpendicular distance between the axes of hypoid gears or offset face gears.\n\nIn the adjacent diagram, (a) and (b) are referred to as having an offset \"below center\", while those in (c) and (d) have an offset \"above center\". In determining the direction of offset, it is customary to look at the gear with the pinion at the right. For below center offset the pinion has a left hand spiral, and for above center offset the pinion has a right hand spiral.\n\nThe outside (tip or addendum) cylinder is the surface that coincides with the tops of the teeth of an external cylindrical gear.\n\nThe outside diameter of a gear is the diameter of the addendum (tip) circle. In a bevel gear it is the diameter of the crown circle. In a throated wormgear it is the maximum diameter of the blank. The term applies to external gears, this is can also be known from major diameter.\n\nA pinion is a round gear and usually refers to the smaller of two meshed gears.\n\nPitch angle in bevel gears is the angle between an element of a pitch cone and its axis. In external and internal bevel gears, the pitch angles are respectively less than and greater than 90 degrees.\nA pitch circle (operating) is the curve of intersection of a pitch surface of revolution and a plane of rotation. It is the imaginary circle that rolls without slipping with a pitch circle of a mating gear.\nThese are the outlines of mating gears. Many important measurements are taken on and from this circle.\n\nA pitch cone is the imaginary cone in a bevel gear that rolls without slipping on a pitch surface of another gear.\nThe pitch helix is the intersection of the tooth surface and the pitch cylinder of a helical gear or cylindrical worm.\nThe base helix of a helical, involute gear or involute worm lies on its base cylinder.\n\nBase helix angle is the helix angle on the base cylinder of involute helical teeth or threads.\n\nBase lead angle is the lead angle on the base cylinder. It is the complement of the base helix angle.\n\nThe outside (tip or addendum) helix is the intersection of the tooth surface and the outside cylinder of a helical gear or cylindrical worm.\n\nOutside helix angle is the helix angle on the outside cylinder.\nOutside lead angle is the lead angle on the outside cylinder. It is the complement of the outside helix angle.\n\nA normal helix is a helix on the pitch cylinder, normal to the pitch helix.\nThe pitch line corresponds, in the cross section of a rack, to the pitch circle (operating) in the cross section of a gear.\n\nThe pitch point is the point of tangency of two pitch circles (or of a pitch circle and pitch line) and is on the line of centers.\n\nPitch surfaces are the imaginary planes, cylinders, or cones that roll together without slipping. For a constant velocity ratio, the pitch cylinders and pitch cones are circular.\n\nThe pitch plane of a pair of gears is the plane perpendicular to the axial plane and tangent to the pitch surfaces. A pitch plane in an individual gear may be any plane tangent to its pitch surface.\n\nThe pitch plane of a rack or in a crown gear is the imaginary planar surface that rolls without slipping with a pitch cylinder or pitch cone of another gear. The pitch plane of a rack or crown gear is also the pitch surface.\n\nThe transverse plane is perpendicular to the axial plane and to the pitch plane. In gears with parallel axes, the transverse and the plane of rotation coincide.\n\nPrincipal directions are directions in the pitch plane, and correspond to the principal cross sections of a tooth.\n\nThe axial direction is a direction parallel to an axis.\n\nThe transverse direction is a direction within a transverse plane.\n\nThe normal direction is a direction within a normal plane.\nProfile radius of curvature is the radius of curvature of a tooth profile, usually at the pitch point or a point of contact. It varies continuously along the involute profile.\n\nTooth-to-tooth radial composite deviation (double flank) is the greatest change in center distance while the gear being tested is rotated through any angle of 360 degree/z during double flank composite action test.\n\nTooth-to-tooth radial composite tolerance (double flank) is the permissible amount of tooth-to-tooth radial composite deviation.\n\nTotal radial composite deviation (double flank) is the total change in center distance while the gear being tested is rotated one complete revolution during a double flank composite action test.\n\nTotal radial composite tolerance (double flank) is the permissible amount of total radial composite deviation.\nRoot angle in a bevel or hypoid gear, is the angle between an element of the root cone and its axis.\n\nThe root circle coincides with the bottoms of the tooth spaces.\n\nThe root cone is the imaginary surface that coincides with the bottoms of the tooth spaces in a bevel or hypoid gear.\n\nThe root cylinder is the imaginary surface that coincides with the bottoms of the tooth spaces in a cylindrical gear.\n\nA shaft angle is the angle between the axes of two non-parallel gear shafts. In a pair of crossed helical gears, the shaft angle lies between the oppositely rotating portions of two shafts. This applies also in the case of worm gearing. In bevel gears, the shaft angle is the sum of the two pitch angles. In hypoid gears, the shaft angle is given when starting a design, and it does not have a fixed relation to the pitch angles and spiral angles.\nSee: Crossed helical gear.\n\nA spur gear has a cylindrical pitch surface and teeth that are parallel to the axis.\nspur gear\n\nA spur rack has a planar pitch surface and straight teeth that are at right angles to the direction of motion.\n\nThe standard pitch circle is the circle which intersects the involute at the point where the pressure angle is equal to the profile angle of the basic rack.\n\nThe standard reference pitch diameter is the diameter of the standard pitch circle. In spur and helical gears, unless otherwise specified, the standard pitch diameter is related to the number of teeth and the standard transverse pitch. The diameter can be roughly estimated by taking the average of the diameter measuring the tips of the gear teeth and the base of the gear teeth.\n\nThe pitch diameter is useful in determining the spacing between gear centers because proper spacing of gears implies tangent pitch circles. The pitch diameters of two gears may be used to calculate the gear ratio in the same way the number of teeth is used.\n\nWhere formula_4 is the total number of teeth, formula_5 is the circular pitch, formula_6 is the diametrical pitch, and formula_7 is the helix angle for helical gears.\n\nThe standard reference pitch diameter is the diameter of the standard pitch circle. In spur and helical gears, unless otherwise specified, the standard pitch diameter is related to the number of teeth and the standard transverse pitch. It is obtained as:\n\nThe test radius (R) is a number used as an arithmetic convention established to simplify the determination of the proper test distance between a master and a work gear for a composite action test. It is used as a measure of the effective size of a gear. The test radius of the master, plus the test radius of the work gear is the set up center distance on a composite action test device. Test radius is not the same as the operating pitch radii of two tightly meshing gears unless both are perfect and to basic or standard tooth thickness.\n\nThe throat diameter is the diameter of the addendum circle at the central plane of a wormgear or of a double-enveloping wormgear.\n\nThroat form radius is the radius of the throat of an enveloping wormgear or of a double-enveloping worm, in an axial plane.\n\nTip radius is the radius of the circular arc used to join a side-cutting edge and an end-cutting edge in gear cutting tools. Edge radius is an alternate term.\n\nTip relief is a modification of a tooth profile whereby a small amount of material is removed near the tip of the gear tooth.\n\nThe tooth surface (flank) forms the side of a gear tooth.\n\nIt is convenient to choose one face of the gear as the reference face and to mark it with the letter “I”. The other non-reference face might be termed face “II”.\n\nFor an observer looking at the reference face, so that the tooth is seen with its tip uppermost, the right flank is on the right and the left flank is on the left. Right and left flanks are denoted by the letters “R” and “L” respectively.\n"}
{"id": "38574481", "url": "https://en.wikipedia.org/wiki?curid=38574481", "title": "Lockitron", "text": "Lockitron\n\nLockitron is a device which can lock and unlock doors via remote control, typically via a smartphone. Lockitron is made by Apigy, a start-up based in Mountain View, California. Apigy was a graduate of the Y Combinator start-up accelerator.\n\nMultiple models of Lockitron have been manufactured, including one that fits over the lock control mechanism on the inside of a door, and the door can then be unlocked via an app on the phone, or via web page control. Phones with Bluetooth Low Energy (4.0) can also automatically unlock a door when an authenticated device is nearby. A supplied NFC tag can be read to trigger a command to toggle the state of the lock.\n\nVirtual \"keys\" can also be created for guests or repair contractors etc., which allows access to the home. The virtual keys can be distributed over the internet on demand, and can also be revoked on demand. The door can also be locked or unlocked via an SMS \"key\" for those without smartphones.\n\nAll models of Lockitron allow for a traditional lock which continues to work with traditional metal keys. When a metal key is used, some models of Lockitron can send a notification to a smartphone.\n\nLockitron exposes an open, web-accessible API. Lockitron supports integration with the Ring Video Doorbell, a doorbell system that sends video and voice from the door to a smartphone. Other devices that have integrated with the Lockitron API include the Pebble Smartwatch, which allows you to directly lock and unlock a Lockitron from your wrist, and IFTTT, which connects Lockitron to platforms and devices like Amazon Alexa, Google Home, and Nest.\n\nFor a period of time Apigy developed Lockitron in an office that previously housed the Byte Shop where the first Apple I computers were sold. Apigy hosted an open house at the location where several working Apple II computers were set up for attendees to play classic games like TRON and Pacman.\n\nApigy originally offered a full replacement door lock version of Lockitron in 2011 before announcing a version of Lockitron in 2012 which fit over preexisting deadbolt locks. The 2012 version of Lockitron incorporated a number of improvements over the 2011 Lockitron deadbolt including built-in WiFi, replacing a wired basestation, built-in auto-unlock technology through Bluetooth Low Energy, and a simplified installation by making Lockitron a device that fits over a preexisting deadbolt lock. The crowdfunded Lockitron was built around an ATMega microprocessor meaning that it is Arduino compatible for other custom behavior.\n\nThe crowdfunded Lockitron was rejected from Kickstarter, after the crowdfunding changed their policies regarding hardware funding. The creators claim the rejection was due to Lockitron's status as a \"home improvement\" product, but this has not been confirmed by Kickstarter. \nAfter their rejection, the founders of Apigy, Cameron Robertson and Paul Gerhardt, built their own crowdfunding website in a matter of days and used it to garner over 1.5 million USD in preorders during the first week of their campaign in October 2012. Apigy subsequently open-sourced their crowdfunding software as Selfstarter, an alternative crowdfunding site. Selfstarter was used in the successful Tile crowdfunding campaign and later formed the basis of Crowdhoster and CrowdTilt Open.\n\nThe crowdfunded Lockitron was significantly delayed from its originally anticipated ship date of July 2013, shipping in small numbers through the end of 2013. By February 2014, the crowdfunded Lockitron had still not yet shipped in substantial numbers prompting coverage by the blog TechCrunch. By the end of 2014 thousands of units had been shipped. In early 2015, Apigy announced its new product, Lockitron Bolt, as a replacement for the crowdfunded Lockitron and that it had ceased production of the crowdfunded Lockitron due to manufacturing and product issues.\n\nLockitron Bolt is priced at 99 USD and offers Bluetooth only connectivity in comparison to its predecessor which was priced at 179 USD and offered built-in WiFi; an optional 79 USD device called Bridge connects Lockitron Bolt to WiFi networks giving it the same remote capabilities as the 2012 Lockitron.\n\nIn late 2015 Apigy announced that the first Lockitron Bolt devices would ship 24 November 2015 while also announcing an add-on to Lockitron Bolt, Keypad. A series of updates in late 2016 indicated that remaining Lockitron Bolt units owed to backers were produced and all remaining orders for U.S. customers had shipped to customers.\n\n"}
{"id": "1721135", "url": "https://en.wikipedia.org/wiki?curid=1721135", "title": "Low technology", "text": "Low technology\n\nLow technology, often abbreviated low tech (adjective forms low-technology, low-tech, lo-tech) is simple technology, often of a traditional or non-mechanical kind, such as crafts and tools that pre-date the Industrial Revolution. It is the opposite of high technology.\n\nLow technology can typically be practised or fabricated with a minimum of capital investment by an individual or small group of individuals. Also, the knowledge of the practice can be completely comprehended by a single individual, free from increasing specialization and compartmentalization. Low-tech techniques and designs may fall into disuse due to changing socio-economic conditions or priorities.\n\nNote: almost all of the entries in this section should be prefixed by the word \"traditional\".\n\n\n\nNote: home canning is a counter example of a low technology since some of the supplies needed to pursue this skill rely on a global trade network and an existing manufacturing infrastructure.\n\n\nBy federal law in the United States, only those articles produced with little or no use of machinery or tools with complex mechanisms may be stamped with the designation \"hand-wrought\" or \"hand-made\". Lengthy court-battles are currently underway over the precise definition of the terms \"organic\" and \"natural\" as applied to foodstuffs.\n\n\n\n"}
{"id": "24688403", "url": "https://en.wikipedia.org/wiki?curid=24688403", "title": "Martin Campbell-Kelly", "text": "Martin Campbell-Kelly\n\nMartin Campbell-Kelly is an Emeritus Professor at the University of Warwick who has specialised in the history of computing.\n\nCampbell-Kelly has served on the editorial board of the \"IEEE Annals of the History of Computing\" journal. He is a committee member of the Computer Conservation Society, a Specialist Group of the British Computer Society.\n\nCampell-Kelly was educated at Sunderland Polytechnic where he was awarded a PhD in 1980 on the \"Foundations of computer programming in Britain 1945–1955\".\n\nCampbell-Kelly has authored, edited numerous books and journal articles on the history of computing.\n\n"}
{"id": "41446565", "url": "https://en.wikipedia.org/wiki?curid=41446565", "title": "Ministry of Petroleum Resources Development", "text": "Ministry of Petroleum Resources Development\n\nThe Ministry of Petroleum Resources Development (Sinhala: ඛනිජ තෙල් සම්පත් සංවර්ධන අමාත්‍යාංශය \"Khanija Thel Sampath Sangwardhana Amathyanshaya\"; Tamil: பெற்றோலிய வள அபிவிருத்தி அமைச்சு) is the cabinet ministry of the Government of Sri Lanka responsible for oversight of the country's energy supply via crude oil import, storage and refining (carried out at the nation's sole refinery at Sapugaskanda), as well as sale (through the Ceylon Petroleum Corporation) of processed petroleum products. It is thus responsible for the maintenance of (and upgrades to) petroleum and petroleum product storage and transport facilities as well as for developing the country's possible natural gas and crude oil reserves.\n\nThe current minister and deputy minister are Arjuna Ranatunga and Anoma Gamage respectively. The ministry's secretary is Upali Marasinghe.\n\n\n"}
{"id": "3014542", "url": "https://en.wikipedia.org/wiki?curid=3014542", "title": "Motion detector", "text": "Motion detector\n\nA motion detector is a device that detects moving objects, particularly people. Such a device is often integrated as a component of a system that automatically performs a task or alerts a user of motion in an area. They form a vital component of security, automated lighting control, home control, energy efficiency and other useful systems.\n\nAn electronic motion detector contains an optical, microwave, or acoustic sensor, and in many cases a transmitter for illumination. However, a \"passive\" sensor senses a signature only from the moving object via emission or reflection, i.e., it can be emitted by the object, or by some ambient emitter such as the sun or a radio station of sufficient strength. Changes in the optical, microwave, or acoustic field in the device's proximity are interpreted by the electronics based on one of the technologies listed below. Most low-cost motion detectors can detect up to distances of at least . Specialized systems cost more, but have much longer ranges. Tomographic motion detection systems can cover much larger areas because the radio waves are at frequencies which penetrate most walls and obstructions, and are detected in multiple locations, not only at the location of the transmitter.\n\nMotion detectors have found wide use in domestic and commercial applications. One common application is activating automatic door openers in businesses and public buildings. Motion sensors are also widely used in lieu of a true occupancy sensor in activating street lights or indoor lights in walkways, such as lobbies and staircases. In such \"smart lighting\" systems, energy is conserved by only powering the lights for the duration of a timer, after which the person has presumably left the area. A motion detector may be among the sensors of a burglar alarm that is used to alert the home owner or security service when it detects the motion of a possible intruder. Such a detector may also trigger a security camera to record the possible intrusion.\n\nSeveral types of motion detection are in wide use:\n\nMany modern motion detectors use combinations of different technologies. While combining multiple sensing technologies into one detector can help reduce false triggering, it does so at the expense of reduced detection probabilities and increased vulnerability. For example, many dual-tech sensors combine both a PIR sensor and a microwave sensor into one unit. For motion to be detected, both sensors must trip together. This lowers the probability of a false alarm since heat and light changes may trip the PIR but not the microwave, or moving tree branches may trigger the microwave but not the PIR. If an intruder is able to fool either the PIR or microwave, however, the sensor will not detect it.\n\nOften, PIR technology is paired with another model to maximize accuracy and reduce energy use. PIR draws less energy than emissive microwave detection, and so many sensors are calibrated so that when the PIR sensor is tripped, it activates a microwave sensor. If the latter also picks up an intruder, then the alarm is sounded.\n\n"}
{"id": "32191953", "url": "https://en.wikipedia.org/wiki?curid=32191953", "title": "Mr. Louie", "text": "Mr. Louie\n\nMr. Louie is a former self-elevating drilling barge (jackup rig) converted into an oil platform. It was the first self-elevating drilling barge classed by the American Bureau of Shipping. As an oil platform, it operates at the Saltpond Oil Field, offshore Ghana.\n\n\"Mr. Louie\" weighs 6200 tons. Its minimal operational water depth is . It has five tugs which pulled her around, and twelve legs for standing on the seabed. It has rings welded onto its cylindrical legs to provide a positive jack connection. Its footing equivalent diameter is , and approximate footing load is .\n\n\"Mr Louie\" was designed by Emile Brinkmann between 1956 and 1958. The drilling barge was built by Universal Drilling Co. It was launched in 1958 and delivered in 1959. In 1958, \"Mr. Louie\" became the first self-elevating drilling barge classed by the American Bureau of Shipping.\n\nIn 1959, it was leased to Reading & Bates (now part of Transocean). The rig was valued by the leasing contract at US$4.75 million. This transaction was later challenged by the United States tax authorities as a sale agreement. In 1965, the barge was sold pursuant to contractual option to Reading & Bates.\n\n\"Mr. Louie\" first drilled at the Gulf of Mexico, where it drilled more than 40 wells. Later it was transferred to the North Sea. In 1963, while drilling on the German Bight, a pocket of very high pressure nitrogen struck the well, causing a blowout. The blowout created a wide and deep crater called \"Figge-Maar\".\n\nIn May 1964, \"Mr. Louie\" drilled the first offshore hole in the North Sea, off of Juist island. In June, it made the first North Sea gas discovery. Later it was used for natural gas exploration in the UK section of the North Sea. In 1967, \"Mr. Louie\" was a part of the unique action for that time when for the first time in the North Sea, it went to dock for reparations and maintenance and was replaced by another rig (\"Orion\") during the drilling. After the structural repairs and maintenance work at Bremerhaven, \"Mr. Louie\" continued drilling at the North Sea for the Gas Council – Amoco group.\n\nAfter the North Sea, \"Mr. Louie\" was moved to West Africa. Between 1977 and 1978 it drilled six appraisal wells at the Saltpond Oil Field in offshore Ghana. After completing the drilling in 1978, \"Mr. Louie\" was converted into an oil platform at this field. It was officially renamed APG-1.\n\n"}
{"id": "7062443", "url": "https://en.wikipedia.org/wiki?curid=7062443", "title": "Oil burner", "text": "Oil burner\n\nAn oil burner is a heating device which burns #1, #2 and #6 heating oils, diesel fuel or other similar fuels. In the United States ultra low #2 diesel is the common fuel used. It is dyed red to show that it is road-tax exempt. In most markets of the United States heating oil is the same specification of fuel as on-road un-dyed diesel. \n\nAn oil burner is a part attached to an oil furnace, water heater, or boiler. It provides the ignition of heating oil/biodiesel fuel used to heat either air or water via a heat exchanger. The fuel is atomized into a fine spray usually by forcing it under pressure through a nozzle which gives the resulting flame a specific flow rate, angle of spray and pattern (variations of a cone shape). This spray is usually ignited by an electric spark with the air being forced through around it at the end of a blast tube, by a fan driven by the oil burner motor. The fuel pump is typically driven via a coupling connecting its shaft to that of the motor's. Oil burners also include combustion-proving devices to prevent out-of-control combustion - Primary Control; Safety Control; Cad Cell Control; Master Control; Fire-Eye Control are all common names for the 'combustion safety control'.\n\nIn the United States residential home heating oil market the \"vaporizing gun burner\" is the most common mechanical device used to heat a home or small commercial forced air space with. Depending on the manufacturer these simple burners will see a lifespan if regularly maintained for decades. Currently, old installations from the 1950s and 1960s are still in operation today if they received regular maintenance. \n\nThe maintenance involved in a gun burner usually is a replacement of the nozzle used to atomize the fuel, replacing the filter located at the air handler, replacing the fuel filter on the heating oil system from the tank, cleaning out any soot or deposits in the heat exchanger of the furnace, and ensuring the system is in good working order, and also involves checking and adjusting the fuel-air mixture for efficiency with a combustion analyzer. \n\nIf a heating oil burner runs out of oil it often must be primed to be restarted. Priming involves purging any air from the fuel lines so that a steady flow of oil can find its way to the burner. \n\nIf an oil burner wears out it can usually be upgraded and replaced with a more efficient modern burner. If the heat exchanger wears out that requires a new furnace. Oil furnaces will last nearly forever if maintained regularly ensuring the heat exchanger is vacuumed out and cleaned. Oil burners deposit soot in the heat exchanger which is an un-even insulator. The heat distribution in the heat exchanger is un-even causing wear on this critical steel part causing an eventual cracking. Annual or every other year tune-ups guarantee this wear is far reduced. Oil furnace lifespans of fifty to seventy-five years with regular service is not uncommon compared to an average wear out of natural gas furnaces every twenty years. \n\nFuel is injected into the combustion chamber by a spray nozzle.\n\nThe nozzles are usually supplied with high pressure oil. Because erosion from friction with the oil, and possible blockage due to lumps in it, they need replacement when worn. Fuel nozzles are usually rated in fuel volume flow per unit time e.g. USGal/h (U.S. Gallons per hour).\n\nA fuel nozzle is characterized by three features:\n\nAlternatively fuel may be passed over a tiny orifice fed with compressed air. This arrangement is referred to as Babington atomiser/nozzle, named after its inventor Robert Babington. As the oil flows over the nozzle, the fuel needn't be under any great pressure. If the pump can handle such the oil may even contain lumps such as scraps of food. Because it is only compressed air that passes through the orifice hole, such nozzles do not suffer much from erosion.\n\nA gear pump of two parts:\n\nThis pumps the oil in and increases the pressure in the nozzles to 15 bar maximum (217.5 psi). Usually a gerotor of the sickle type is used. Gear pumps are used frequently in oil burners because of their simplicity, stability and low price.\n\nTo set the heat output of the burner, the rate of fuel delivery via the nozzle must be adjustable. This is often achieved by an adjustable pressure relief valve between the pump and the nozzle. When the set pressure is reached (usually 100psi), this valve opens and allows excess oil to flow through a bypass back to the fuel tank or the pump suction side.\n\nThis allows fuel to be shut off from the sprayer by electrical control. It helps avoid drips when the valve is closed. It also eases the purging of the burner (and any boiler) of fuel mist during startup, or while restarting after a misfire. If the burner were not purged the oil/air mixture could explode dangerously.\n\nThe fan blows air into the combustion chamber. The rotor of the fan is powered by an electric motor.\n\nSome oil burners use glow bars which operate much like the glow plugs of a diesel engine.\n\nMany use high voltage generated by a voltage-step up transformer to create a spark for ignition, somewhat similar to a spark plug.\n\nOriginal oil burner transformers were copper wire conductors wrapped around an iron core. A standard type of transformer to this day. In the mid-90s electronic igniters replaced the copper and iron transformer, solving many problems related to the old style transformer. This new technology in igniters would soon replace all old style transformers throughout the oil burner industry. The new igniters would run cooler so the output voltage could be increased from 10,000 to 20,000 VAC.\n\nThis increase of voltage would be more reliable, reduce delayed ignition, run cooler and all while using less energy. The voltage is high, but a standard igniter will only pull around 35 milliamps.\n\nOil-fired burners are fitted with a safety mechanism for determining if the fuel has ignited and a flame present. The terms \"primary control\", \"safety control\", \"cad cell control\", \"master control\", and \"fire-eye control\" are variously used to describe a light dependent electrical resistor (LDR) which detects the flame whose value changes by the amount of light it is exposed to. The resistance decreases as the LDR is exposed to more light. The material is usually cadmium sulfide, hence the name \"cad cell\" for this component. In darkness the resistance is around 1 MΩ, while when exposed to light from a properly ignited flame the resistance is significantly lower, around 75–300 Ω.\n\nOlder oil burners were equipped with a primary control installed on the exhaust stack with a bimetallic heat sensing element protruding into the stack, such a control was referred to as a \"stack relay\" or a \"stack control\". It performed the same function as the newer cad-cell control but instead of sensing light from the burner flame it sensed heat from the flame exhaust gases to prove that ignition took place.\n\nThe motor which drives the fan and the oil pump is usually a \ncapacitor start motor. It is a vortex shortage tank motor because it also contains a short cage or cage holds. The difference with a three-phase motor is in the stator. Where the vortex power motor has three coils aligned at 120° in the stator, the capacitor start motor holds one main winding and one auxiliary winding aligned at 90°. The phase shift of 90° between the main winding and the auxiliary winding is achieved by a connected capacitor which feeds the auxiliary winding and is connected on the single-phase AC mains. The capacitor will achieve a phase shift of 90° between the main and the auxiliary winding, producing an acceptable initial torque. This motor is intended for continuous operation.\n\n"}
{"id": "60549", "url": "https://en.wikipedia.org/wiki?curid=60549", "title": "Orrery", "text": "Orrery\n\nAn orrery is a mechanical model of the solar system that illustrates or predicts the relative positions and motions of the planets and moons, usually according to the heliocentric model. It may also represent the relative sizes of these bodies; but since accurate scaling is often not practical due to the actual large ratio differences, a subdued approximation may be used instead. Though the Greeks had working planetaria, the first orrery that was a planetarium of the modern era was produced in 1704, and one was presented to Charles Boyle, 4th Earl of Orrery – whence came the name. They are typically driven by a clockwork mechanism with a globe representing the Sun at the centre, and with a planet at the end of each of the arms.\n\nThe Antikythera mechanism, discovered in 1900 in a wreck off the Greek island of Antikythera and extensively studied, exhibited the diurnal motions of the Sun, Moon, and the five known planets. It has been dated between 150 and 100 BC. The Antikythera hand driven mechanism is now considered one of the first orreries, but for many decades was ignored as it was thought to be far too complex to be genuine. It was geocentric and used as a mechanical calculator designed to calculate astronomical positions.\n\nAccording to Cicero, the Roman philosopher who was writing in the first century BC, Posidonius constructed a planetary model.\n\nIn 1348, Giovanni Dondi built the first known clock driven mechanism which displays the ecliptical position of Moon, Sun, Mercury, Venus, Mars, Jupiter and Saturn according to the complicated ptolemeic planetary theories. The clock itself is lost, but Dondi left a complete description of the astronomic gear trains of his clock.\n\nAs late as 1650, P. Schirleus built a geocentric planetarium with the Sun as a planet, and with Mercury and Venus revolving around the Sun as its moons.\n\nAt the court of William IV, Landgrave of Hesse-Kassel two complicated astronomic clocks were built in 1561 and 1563-1568, which show on four sites the ecliptical position of Sun, Mercury, Venus, Mars, Jupiter and Saturn, the Moon, Sun and Dragon (Nodes of the Moon) according to Ptolemy, a Calendar, the Sunrise and Sunset and an automated celestial sphere with an animated Sun symbol which, for the first time on a celestial globe, show the real position of the sun, including the equation of time. The clocks are now on display in Kassel at the Astronomisch-Physikalisches Kabinett and in Dresden at the Mathematisch-Physikalischer Salon.\n\nIn \"De revolutionibus orbium coelestium\", published in Nuremberg in 1543, Nicolaus Copernicus challenged the Western teaching of a geocentric universe in which the Sun revolved daily around the Earth. He observed that some Greek philosophers had proposed a heliocentric universe. This simplified the apparent epicyclic motions of the planets, making it feasible to represent the planets' paths as simple circles. This could be modelled by the use of gears. Tycho Brahe's improved instruments made precise observations of the skies (1576–1601), and from these Johannes Kepler (1621) deduced that planets orbited the Sun in ellipses. In 1687 Isaac Newton explained the cause of elliptic motion in his theory of gravitation.\n\nClock makers George Graham and Thomas Tompion built the first modern orrery around 1704 in England. Graham gave the first model, or its design, to the celebrated instrument maker John Rowley of London to make a copy for Prince Eugene of Savoy. Rowley was commissioned to make another copy for his patron Charles Boyle, 4th Earl of Orrery, from which the device took its name in English. This model was presented to Charles' son John, later the 5th Earl of Cork and 5th Earl of Orrery. Independently, Christiaan Huygens published details of a heliocentric planetary machine in 1703, which he built while resident in Paris between 1665 and 1681. He calculated the gear trains needed to represent a year of 365.242 days, and used that to produce the cycles of the principal planets.\n\nJoseph Wright's painting \"A Philosopher giving a Lecture on the Orrery in which a lamp is put in place of the Sun\" (ca. 1766), which hangs in Derby Museum and Art Gallery, depicts a group listening to a lecture by a natural philosopher. The Sun in a brass orrery provides the only light in the room. The orrery depicted in the painting has rings, which give it an appearance similar to that of an armillary sphere. The demonstration was thereby able to depict eclipses.\n\nTo put this in chronological context, in 1762 John Harrison's marine chronometer first enabled accurate measurement of longitude. In 1766, astronomer Johann Daniel Titius first demonstrated that the mean distance of each planet from the Sun could be represented by the following progression:\n\nThat is, 0.4, 0.7, 1.0, 1.6, 2.8, 5.2 ... The numbers refer to astronomical units, the mean distance between Sun and Earth, which is 1.496 × 10⁸ km (93 × 10⁶ miles). The Derby Orrery does not show mean distance, but demonstrated the relative planetary movements.\n\nEisinga's Planetarium was built from 1774 to 1781 by Eise Eisinga in his home in Franeker, in the Netherlands. It displays the planets across the width of a room's ceiling, and has been in operation almost continually since it was created. This orrery is a planetarium in both senses of the word: a complex machine showing planetary orbits, and a theatre for depicting the planets' movement. Eisinga house was bought by the Dutch Royal family who gave him a pension.\nIn 1764, Benjamin Martin devised a new type of planetary model, in which the planets were carried on brass arms leading from a series of concentric or coaxial tubes. With this construction it was difficult to make the planets revolve, and to get the moons to turn around the planets. Martin suggested that the conventional orrery should consist of three parts: the planetarium where the planets revolved around the Sun, the tellurion (also \"tellurian\" or \"tellurium\") which showed the inclined axis of the Earth and how it revolved around the Sun, and the lunarium which showed the eccentric rotations of the Moon around the Earth. In one orrery, these three motions could be mounted on a common table, separately using the central spindle as a prime mover.\n\nAll orreries are \"planetariums\" or \"planetaria\" (alternative plural). The term orrery has only existed since 1714. A grand orrery is one that includes the outer planets known at the time of its construction. The word planetarium has been captured, and now usually refers to hemispherical theatres in which images of the night sky are projected onto an overhead surface. Planetariums (orreries) can range widely in size from hand-held to room-sized. An orrery is used to demonstrate the motion of the planets, while a mechanical device used to predict eclipses and transits is called an astrarium.\n\nAn orrery should properly include the Sun, the Earth and the Moon (plus optionally other planets). A model that only includes the Earth, the Moon and the Sun is called a tellurion or tellurium, and one which only includes the Earth and the Moon is a lunarium. A jovilabe is a model of Jupiter and its moons.\n\nA planetarium will show the \"orbital period\" of each planet and the \"rotation rate\", as shown in the table above. A tellurion will show the earth with the moon revolving around the sun. It will use the angle of \"inclination of the equator\" from the table above to show how it rotates around its own axis. It will show the earth's moon, rotating around the earth. A lunarium is designed to show the complex motions of the moon as it revolves around the earth.\n\nOrreries are usually not built to scale. Human orreries, where humans move about as the planets, have also been constructed, but most are temporary. There is a permanent human orrery at Armagh Observatory in Northern Ireland, which has the six ancient planets, Ceres, and comets Halley and Encke. Uranus and beyond are also shown, but in a fairly limited way. Another is at Sky's the Limit Observatory and Nature Center in Twentynine Palms, CA. This is a true to scale (20 billion to one), true to position (accurate to within four days) human orrery. The first four planets are relatively close to one another, but the next four require a certain amount of hiking in order to visit them.\n\nA normal mechanical clock could be used to produce an extremely simple orrery with the Sun in the centre, Earth on the minute hand and Jupiter on the hour hand; Earth would make 12 revolutions around the Sun for every 1 revolution of Jupiter. Note however that Jupiter's actual year is 11.86 Earth years long, so this particular example would lose accuracy rapidly. A real orrery would be more accurate and include more planets, and would perhaps make the planets rotate as well.\n\nMany planetariums (buildings) have a projection orrery, which projects onto the dome of the planetarium a Sun with either dots or small images of the planets. These usually are limited to the planets from Mercury to Saturn, although some include Uranus. The light sources for the planets are projected onto mirrors which are geared to a motor which drives the images on the dome. Typically the Earth will circle the Sun in one minute, while the other planets will complete an orbit in time periods proportional to their actual motion. Thus Venus, which takes 224.7 days to orbit the Sun, will take 37 seconds to complete an orbit on an orrery, and Jupiter will take 11 minutes, 52 seconds.\n\nSome planetariums have taken advantage of this to use orreries to simulate planets and their moons. Thus Mercury orbits the Sun in 0.24 of an Earth year, while Phobos and Deimos orbit Mars in a similar 4:1 time ratio. Planetarium operators wishing to show this have placed a red cap on the Sun (to make it resemble Mars) and turned off all the planets but Mercury and Earth. Similar tricks can be used to show Pluto and its five moons.\n\nShoemaker John Fulton of Fenwick, Ayrshire, built three between 1823 and 1833. The last is in Glasgow's Kelvingrove Art Gallery and Museum.\n\nThe Franeker Planetarium built by a wool carder named Eise Eisinga in his own living room, in the small city of Franeker in Friesland, is in fact an orrery. It was constructed between 1774 and 1781. The \"face\" of the model looks down from the ceiling of a room, with most of the mechanical works in the space above the ceiling. It is driven by a pendulum clock, which has 9 weights or ponds. The planets move around the model in real time.\n\nAn innovative concept is to have people play the role of the moving planets and other Solar System objects. Such a model, called a human orrery, has been laid out with precision at the Armagh Observatory.\n\n\n\n"}
{"id": "22202480", "url": "https://en.wikipedia.org/wiki?curid=22202480", "title": "Propellant depot", "text": "Propellant depot\n\nAn orbital propellant depot is a cache of propellant that is placed in orbit around Earth or another body to allow spacecraft or the transfer stage of the spacecraft to be fueled in space. It is one of the types of space resource depot that have been proposed for enabling infrastructure-based space exploration.\nMany different depot concepts exist depending on the type of fuel to be supplied, location, or type of depot which may also include a propellant tanker that delivers a single load to a spacecraft at a specified orbital location and then departs. In-space fuel depots are not necessarily located near or at a space station.\n\nPotential users of in-orbit refueling and storage facilities include space agencies, defense ministries and communications satellite or other commercial companies.\n\nSatellite servicing depots would extend the lifetime of satellites that have nearly consumed all of their orbital maneuvering fuel and are likely placed in a geosynchronous orbit. The spacecraft would conduct a space rendezvous with the depot, or \"vice versa\", and then transfer propellant to be used for subsequent orbital maneuvers. In 2011, Intelsat showed interest in an initial demonstration mission to refuel several satellites in geosynchronous orbit, but all plans have been since scrapped.\n\nA low earth orbit (LEO) depot's primary function would be to provide propellant to a transfer stage headed to the moon, Mars, or possibly a geosynchronous orbit. Since all or a fraction of the transfer stage propellant can be off-loaded, the separately launched spacecraft with payload and/or crew could have a larger mass or use a smaller launch vehicle. With a LEO depot or tanker fill, the size of the launch vehicle can be reduced and the flight rate increased—or, with a newer mission architecture where the beyond-Earth-orbit spacecraft also serves as the second stage, can facilitate much larger payloads—which may reduce the total launch costs since the fixed costs are spread over more flights and fixed costs are usually lower with smaller launch vehicles. A depot could also be placed at Earth-Moon Lagrange point 1 (EML-1) or behind the Moon at EML-2 to reduce costs to travel to the moon or Mars. Placing a depot in Mars orbit has also been suggested.\n\nFor rockets and space vehicles, propellants usually take up 2/3 or more of their total mass.\n\nLarge upper-stage rocket engines generally use a cryogenic fuel like liquid hydrogen and liquid oxygen (LOX) as an oxidizer because of the large specific impulse possible, but must carefully consider a problem called \"boil off\". The boil off from only a few days of delay may not allow sufficient fuel for higher orbit injection, potentially resulting in a mission abort. Lunar or Mars missions will require weeks to months to accumulate tens of thousands to hundreds of thousands of kilograms of propellant, so additional equipment may be required on the transfer stage or the depot to mitigate boiloff.\n\nNon-cryogenic, earth-storable liquid rocket propellants including RP-1 (kerosene), hydrazine and nitrogen tetroxide (NTO), and mildly cryogenic, space-storable propellants like liquid methane and liquid oxygen, can be kept in liquid form with less boiloff than the cryogenic fuels, but also have lower specific impulse. Additionally, gaseous or supercritical propellants such as those used by ion thrusters include xenon, argon, and bismuth.\n\nEx-NASA administrator Mike Griffin commented at the 52nd AAS Annual Meeting in Houston, November 2005, that \"at a conservatively low government price of $10,000/kg in LEO, 250 MT of fuel for two missions per year is worth $2.5 B, at government rates.\"\n\nIf one assumes that a 130 metric tonne launch vehicle could be flown twice a year for $2.5B, the price is about $10,000/kg.\n\nIn the depot-centric architecture, the depot is filled by tankers, and then the propellant is transferred to an upper stage prior to orbit insertion, similar to a gas station filled by tankers for automobiles. By using a depot, the launch vehicle size can be reduced and the flight rate increased. Since the accumulation of propellant may take many weeks to months, careful consideration must be given to boiloff mitigation.\n\nIn simple terms, a passive cryogenic depot is a transfer stage with stretched propellant tanks, additional insulation, and a sun shield. In one concept, hydrogen boiloff is also redirected to reduce or eliminate liquid oxygen boiloff and then used for attitude control, power, or reboost. An active cryogenic depot is a passive depot with additional power and refrigeration equipment/cryocoolers to reduce or eliminate propellant boiloff. Other active cryogenic depot concepts include electrically powered attitude control equipment to conserve fuel for the end payload.\n\nIn the heavy lift architecture, propellant, which can be two thirds or more of the total mission mass, is accumulated in fewer launches and possibly shorter time frame than the depot centric architecture. Typically the transfer stage is filled directly and no depot is included in the architecture. For cryogenic vehicles and cryogenic depots, additional boiloff mitigation equipment is typically included on the transfer stage, reducing payload fraction and requiring more propellant for the same payload unless the mitigation hardware is expended.\n\nHeavy lift advocates state that the total mass to orbit required for a mission can actually increase because of the need to launch more propellant tanks and boil-off mitigation hardware. Heavy launch vehicles are not developed, so these costs are added to the trade, rather than using existing smaller rockets. Heavy lift advocates question the cost model for propellant depots and cite the need for development and demonstration.\n\nDepot advocates claim this increase in mission mass would be offset by a decrease in the cost per launch and the elimination of the fixed costs of the heavy lift launch vehicle when not required in a given time frame. Further, long life components including insulation, power and cryocoolers could be placed on the depot and not expended, further reducing the mass per mission and hence costs.\n\nHeavy Lift is compared with using Commercial Launch and Propellant Depots in this power point by Dr. Alan Wilhite given at FISO Telecon.\n\nBoth theoretical studies and funded development projects that are currently underway aim to provide insight into the feasibility of propellant depots. Studies have shown that a depot-centric architecture with smaller launch vehicles could be less expensive than a heavy-lift architecture over a 20-year time frame. The cost of large launch vehicles is so high that a depot able to hold the propellant lifted by two or more medium-sized launch vehicles may be cost effective and support more payload mass on beyond-Earth orbit trajectories.\n\nIn a 2010 NASA study, an additional flight of an Ares V heavy launch vehicle was required to stage a US government Mars reference mission due to 70 tons of boiloff, assuming 0.1% boiloff/day for hydrolox propellant. The study clearly identified the need to decrease the design boiloff rate by an order of magnitude or more.\n\nApproaches to the design of low Earth orbit (LEO) propellant depots were also discussed in the 2009 Augustine report to NASA, which \"examined the [then] current concepts for in-space refueling.\" The report determined there are essentially two approaches to refueling a spacecraft in LEO:\nBoth approaches were considered feasible with 2009 spaceflight technology, but anticipated that significant further engineering development and in-space demonstration would be required before missions could depend on the technology. Both approaches were seen to offer the potential of long-term life-cycle savings.\n\nBeyond theoretical studies, since at least 2016, SpaceX has undertaken funded development of an interplanetary set of technologies called the Interplanetary Transport System (ITS). While the system consists of a combination of several elements that are considered by SpaceX to be key to making long-duration beyond Earth orbit (BEO) spaceflights possible by reducing the cost per ton delivered to Mars by multiple orders of magnitude over what NASA approaches have achieved,\nrefilling of propellants in orbit is one of the four key elements. In a novel mission architecture, the SpaceX design intends to enable the long-journey spacecraft to expend most all of its propellant load during the launch to low Earth orbit while it serves as the second stage of the launch vehicle, and then—after refilling on orbit by an \"ITS tanker\"—provide the significant amount of energy necessary to put the spacecraft onto an interplanetary trajectory. The \"ITS tanker\" is designed to transport approximately of propellant to low Earth orbit.\n\nA second propellant tanker concept is underway. United Launch Alliance (ULA) has a proposed Advanced Cryogenic Evolved Stage (ACES) tanker—a concept that dates back to work by Boeing in 2006, sized to transport up to of propellant—in early design with first flight planned for no earlier than 2023, with initial usage as a propellant tanker potentially beginning in the mid-2020s.\n\nBecause a large portion of a rocket is propellant at time of launch, proponents point out several advantages of using a propellant depot architecture. Spacecraft could be launched unfueled and thus require less structural mass, or the depot tanker itself could serve as the second-stage on launch when it is reusable. An on-orbit market for refueling may be created where competition to deliver propellant for the cheapest price takes place, and it may also enable an economy of scale by permitting existing rockets to fly more often to refuel the depot. If used in conjunction with a mining facility on the moon, water or propellant could be exported back to the depot, further reducing the cost of propellant. An exploration program based on a depot architecture could be cheaper and more capable, not needing a specific rocket or a heavy lift such as the SLS to support multiple destinations such as the Moon, Lagrange points, asteroids, and Mars.\n\nNASA studies in 2011 showed cheaper and faster alternatives than the Heavy Lift Launch System and listed the following advantages:\n\nPropellant depots were proposed as part of the Space Transportation System (along with nuclear \"tugs\" to take payloads from LEO to other destinations) in the mid-1960s.\n\nIn October 2009, the Air Force and United Launch Alliance (ULA) performed an experimental on-orbit demonstration on a modified Centaur upper stage on the DMSP-18 launch to improve \"understanding of propellant settling and slosh, pressure control, RL10 chilldown and RL10 two-phase shutdown operations.\" \"The light weight of DMSP-18 allowed of remaining LO and LH propellant, 28% of Centaur’s capacity,\" for the on-orbit demonstrations. The post-spacecraft mission extension ran 2.4 hours before executing the deorbit burn.\n\nNASA's Launch Services Program is working on an ongoing slosh fluid dynamics experiments with partners called CRYOTE. ULA is also currently planning additional in-space laboratory experiments to further develop cryogenic fluid management technologies using the Centaur upper stage after primary payload separation. Named CRYOTE, or CRYogenic Orbital TEstbed, it will be a testbed for demonstrating a number of technologies needed for cryogenic propellant depots, with several small-scale demonstrations planned for 2012-2014.\n, ULA says this mission could launch as soon as 2012 if funded.\nThe ULA CRYOTE small-scale demonstrations are intended to lead to a ULA large-scale cryo-sat flagship technology demonstration in 2015.\n\nThe Future In-Space Operations (FISO) Working Group, a consortium of participants from NASA, industry and academia, discussed propellant depot concepts and plans on several occasions in 2010,\nwith presentations of optimal depot locations for human space exploration beyond low Earth orbit,\na proposed simpler (single vehicle) first-generation propellant depot\nand six important propellant-depot-related technologies for reusable cislunar transportation.\n\nNASA also has plans to mature techniques for enabling and enhancing space flights that use propellant depots in the \"CRYOGENIC Propellant STorage And Transfer (CRYOSTAT) Mission\". The CRYOSTAT vehicle is expected to be launched to LEO in 2015.\n\nThe CRYOSTAT architecture comprises technologies in the following categories:\n\nThe \"Simple Depot\" mission was proposed by NASA in 2011 as a potential first PTSD mission, with launch no earlier than 2015, on an Atlas V 551. \"Simple Depot\" would utilize the \"used\" (nearly-emptied) Centaur upper stage LH2 tank for long-term storage of LO2 while LH2 will be stored in the Simple Depot LH2 module, which is launched with only ambient-temperature gaseous Helium in it. The SD LH2 tank was to be diameter and long, in volume, and store 5 mT of LH2. \"At a useful mixture ratio (MR) of 6:1 this quantity of LH2 can be paired with 25.7 mT of LO2, allowing for 0.7 mT of LH2 to be used for vapor cooling, for a total useful propellant mass of 30 mT. ... the described depot will have a boil-off rate of approaching 0.1 percent per day, consisting entirely of hydrogen.\"\n\nIn September 2010, ULA released a \"Depot-Based Space Transportation Architecture\" concept to propose propellant depots that could be used as way-stations for other spacecraft to stop and refuel—either in low Earth orbit (LEO) for beyond-LEO missions, or at Lagrangian point for interplanetary missions—at the AIAA Space 2010 conference. The concept proposes that waste gaseous hydrogen—an inevitable byproduct of long-term liquid hydrogen storage in the radiative heat environment of space—would be usable as a monopropellant in a solar-thermal propulsion system. The waste hydrogen would be productively utilized for both orbital stationkeeping and attitude control, as well as providing limited propellant and thrust to use for orbital maneuvers to better rendezvous with other spacecraft that would be inbound to receive fuel from the depot.\nAs part of the Depot-Based Space Transportation Architecture, ULA has proposed the Advanced Common Evolved Stage (ACES) upper stage rocket. ACES hardware is designed from the start to as an in-space propellant depot that could be used as way-stations for other rockets to stop and refuel on the way to beyond-LEO or interplanetary missions, and to provide the high-energy technical capacity for the cleanup of space debris.\n\nIn August 2011, NASA made a significant contractual commitment to the development of propellant depot technology by funding four aerospace companies to \"define demonstration missions that would validate the concept of storing cryogenic propellants in space to reduce the need for large launch vehicles for deep-space exploration.\"\nThese study contracts for storing/transferring cryogenic propellants and cryogenic depots were signed with Analytical Mechanics Associates, Boeing, Lockheed Martin and Ball Aerospace. Each company will receive under the contract.\n\nThe Chinese Space Agency (CNSA) performed its first satellite-to-satellite on-orbit refueling test in June 2016.\n\nThere are a number of design issues with propellant depots, as well as several tasks that have not, to date, been tested in space for on-orbit servicing missions. The design issues include propellant settling and transfer, propellant usage for attitude control and reboost, the maturity of the refrigeration equipment/cryocoolers, and the power and mass required for reduced or zero boiloff depots with refrigeration.\n\nTransfer of liquid propellants in microgravity is complicated by the uncertain distribution of liquid and gasses within a tank. Propellant settling at an in-space depot is thus more challenging than in even a slight gravity field. ULA plans to use the DMSP-18 mission to flight-test centrifugal propellant settling as a cryogenic fuel management technique that might be used in future propellant depots. The proposed Simple Depot PTSD mission utilizes several techniques to achieve adequate settling for propellant transfer.\n\nIn the absence of gravity, propellant transfer is somewhat more difficult, since liquids can float away from the inlet.\n\nAs part of the Orbital Express mission in 2007, hydrazine propellant was successfully transferred between two single-purpose designed technology demonstration spacecraft. The Boeing servicing spacecraft ASTRO transferred propellant to the Ball Aerospace serviceable client spacecraft NEXTSat. Since no crew were present on either spacecraft, this was reported as the first autonomous spacecraft-to-spacecraft fluid transfer.\n\nAfter propellant has been transferred to a customer the depot's tanks will need refilling. Organizing the construction and launch of the tanker rockets bearing the new fuel is the responsibility of the propellant depot's operator. Since space agencies like NASA hope to be purchasers rather than owners, possible operators include the aerospace company that constructed the depot, manufacturers of the rockets, a specialist space depot company, or an oil/chemical company that refines the propellant. By using several tanker rockets the tankers can be smaller than the depot and larger than the spacecraft they are intended to resupply. Short range chemical propulsion tugs belonging to the depot may be used to simplify docking tanker rockets and large vehicles like Mars Transfer Vehicles.\n\nTransfers of propellant between the LEO depot, reachable by rockets from Earth, and the deep space ones such as the Lagrange Points and Phobos depots can be performed using Solar electric propulsion (SEP) tugs.\n\nTwo missions are currently under development or proposed to support propellant depot refilling. In addition to refueling and servicing geostationary communications satellites with the fuel that is initially launched with the MDA Space Infrastructure Servicing vehicle, the SIS vehicle is being designed to have the ability to orbitally maneuver to rendezvous with a replacement fuel canister after transferring the of fuel in the launch load, enabling further refueling of additional satellites after the initial multi-satellite servicing mission is complete.\nThe proposed Simple Depot cryogenic PTSD mission utilizes \"remote berthing arm and docking and fluid transfer ports\" both for propellant transfer to other vehicles, as well as for refilling the depot up to the full 30 tonne propellant capacity.\n\nS.T. Demetriades proposed a method for refilling by collecting atmospheric gases. Moving in low Earth orbit, at an altitude of around 120 km, Demetriades' proposed depot extracts air from the fringes of the atmosphere, compresses and cools it, and extracts liquid oxygen. The remaining nitrogen is used as propellant for a nuclear-powered magnetohydrodynamic engine, which maintains the orbit, compensating for atmospheric drag. This system was called “PROFAC” (PROpulsive Fluid ACcumulator). There are, however, safety concerns with placing a nuclear reactor in low Earth orbit.\n\nDemetriades' proposal was further refined by Christopher Jones and others In this proposal, multiple collection vehicles accumulate propellent gases at around 120 km altitude, later transferring them to a higher orbit. However, Jones' proposal does require a network of orbital power-beaming satellites, to avoid placing nuclear reactors in orbit.\n\nAsteroids can also be processed to provide liquid oxygen.\n\nPropellant depots in LEO are of little use for transfer between two low earth orbits when the depot is in a different orbital plane than the target orbit. The delta-v to make the necessary plane change is typically extremely high. On the other hand, depots are typically proposed for exploration missions, where the change over time of the depot's orbit can be chosen to align with the departure vector. This allows one well-aligned departure time minimizing fuel use that requires a very precisely-timed departure. Less efficient departure times from the same depot to the same destination exist before and after the well-aligned opportunity, but more research is required to show whether the efficiency falls off quickly or slowly. By contrast, launching directly in only one launch from the ground without orbital refueling or docking with another craft already on orbit offers daily launch opportunities though it requires larger and more expensive launchers.\n\nThe restrictions on departure windows arise because low earth orbits are susceptible to significant perturbations; even over short periods they are subject to nodal regression and, less importantly, precession of perigee. Equatorial depots are more stable but also more difficult to reach.\n\nHowever, it is possible to do a three-burn orbital transfer which includes a plane change, and which wastes very little propellant to reach almost any final trajectory.\n\nBoil-off of cryogenic propellants in space may be mitigated by both technological solutions as well as system-level planning and design.\nFrom a technical perspective: for a propellant depot with passive insulation system to effectively store cryogenic fluids, boil-off caused by heating from solar and other sources must be mitigated, eliminated, or used for economic purposes. For non-cryogenic propellants, boil-off is not a significant design problem.\n\nBoil off rate is governed by heat leakage and by the quantity of propellant in the tanks. With partially filled tanks, the percentage loss is higher. Heat leakage depends on surface area, while the original mass of propellant in the tanks depends on volume. So by the cube-square law, the smaller the tank, the faster the liquids will boil off.\nSome propellant tank designs have achieved a liquid hydrogen boil off rate as low as approximately 0.13% per day (3.8% per month) while the much higher temperature cryogenic fluid of liquid oxygen would boil off much less, about 0.016% per day (0.49% per month).\n\nIt is possible to achieve zero boil-off (ZBO) with cryogenic propellant storage using an active thermal control system. Tests conducted at the NASA Lewis Research Center's Supplemental Multilayer Insulation Research Facility (SMIRF) over the summer of 1998 demonstrated that a hybrid thermal control system could eliminate boiloff of cryogenic propellants. The hardware consisted of a pressurized 50-ft³ (ca. 1416 litres) tank insulated with multi-layer insulation (MLI) of 34 layers, a condenser, and a Gifford-McMahon (GM) cryocooler that has a cooling capacity of 15 to 17.5 watt (W). Liquid hydrogen was the test fluid. The test tank was installed into a vacuum chamber, simulating space vacuum.\nIn 2001, a cooperative effort by NASA's Ames Research Center, Glenn Research Center, and Marshall Space Flight Center (MSFC) was implemented to develop zero-boiloff concepts for in-space cryogenic storage. Main program element was a large-scale, zero-boiloff demonstration using the MSFC multipurpose hydrogen test bed (MHTB) - 18.10 m3 LH2 tank (about 1300 kg of H2). A commercial cryocooler was interfaced with an existing MHTB spray bar mixer and insulation system in a manner that enabled a balance between incoming and extracted thermal energy.\n\nAnother NASA study in June 2003 for conceptual Mars mission showed mass savings over traditional, passive- only cryogenic storage when mission durations are 5 days in LEO for oxygen, 8.5 days for methane and 64 days for hydrogen. Longer missions equate to greater mass savings. Cryogenic xenon saves mass over passive storage almost immediately. When power to run the ZBO is already available, the break-even mission durations are even shorter, e.g. about a month for hydrogen. The larger the tank, the fewer days in LEO when ZBO has reduced mass.\n\nIn addition to technical solutions to the challenge of excessive boil-off of cryogenic rocket propellants, system-level solutions have been proposed. From a systems perspective, reductions in the standby time of the LH2 cryogenic storage in order to achieve, effectively, a just in time (JIT) delivery to each customer, matched with the balanced refinery technology to split the long-term storable feedstock—water—into the stoichiometric LOX/LH2 necessary, is theoretically capable of achieving a system-level solution to boil-off. Such proposals have been suggested as supplementing good technological techniques to reduce boil-off, but would not replace the need for efficient technological storage solutions.\n\nUnited Launch Alliance (ULA) has proposed a cryogenic depot which would use a conical sun shield to protect the cold propellants from solar and Earth radiation. The open end of the cone allows residual heat to radiate to the cold of deep space, while the closed cone layers attenuates the radiative heat from the Sun and Earth.\n\nOther issues are hydrogen embrittlement, a process by which some metals (including iron and titanium) become brittle and fracture following exposure to hydrogen. The resulting leaks makes storing cryogenic propellants in zero gravity conditions difficult.\n\nIn the early 2010s, several in-space refueling projects got under-way. Two private initiatives and a government-sponsored test mission were in some level of development or testing .\n\nThe NASA Robotic Refueling Mission was launched in 2011 and successfully completed a series of robotically-actuated propellant transfer experiments on the exposed facility platform of the International Space Station in January 2013.\n\nThe set of experiments included a number of propellant valves, nozzles and seals similar to those used on many satellites and a series of four prototype tools that could be attached to the distal end of a Space Station robotic arm. Each tool was a prototype of \"devices that could be used by future satellite servicing missions to refuel spacecraft in orbit. RRM is the first in-space refueling demonstration using a platform and fuel valve representative of most existing satellites, which were never designed for refueling. Other satellite servicing demos, such as the U.S. military's Orbital Express mission in 2007, transferred propellant between satellites with specially-built pumps and connections.\"\n\n, a small-scale refueling demonstration project for reaction control system (RCS) fluids is under development. Canada-based MDA Corporation announced in early 2010 that they were designing a single spacecraft that would refuel other spacecraft in orbit as a satellite-servicing demonstration. \"The business model, which is still evolving, could ask customers to pay per kilogram of fuel successfully added to their satellite, with the per-kilogram price being a function of the additional revenue the operator can expect to generate from the spacecraft’s extended operational life.\"\n\nThe plan is that the fuel-depot vehicle would maneuver to an operational communications satellite, dock at the target satellite’s apogee-kick motor, remove a small part of the target spacecraft’s thermal protection blanket, connect to a fuel-pressure line and deliver the propellant. \"MDA officials estimate the docking maneuver would take the communications satellite out of service for about 20 minutes.\"\n\n, MDA has secured a major customer for the initial demonstration project. Intelsat has agreed to purchase one-half of the propellant payload that the MDA spacecraft would carry into geostationary orbit. Such a purchase would add somewhere between two and four years of additional service life for up to five Intelsat satellites, assuming 200 kg of fuel is delivered to each one.\n, the spacecraft could be ready to begin refueling communication satellites by 2015.\n, no customers have signed up for an MDA refueling mission.\n\nCompetitive design alternatives to in-space RCS fuel transfer exist. It is possible to bring additional propellant to a space asset, and utilize the propellant for attitude control or orbital velocity change, without ever transferring the propellant to the target space asset.\n\nThe ViviSat Mission Extension Vehicle, also under development since the early 2010s, illustrates one alternative approach that would connect to the target satellite similarly to MDA SIS, via the kick motor, but will not transfer fuel. Rather, the Mission Extension Vehicle will use \"its own thrusters to supply attitude control for the target.\"\nViviSat believes their approach is more simple and can operate at lower cost than the MDA propellant transfer approach, while having the technical ability to dock with and service a greater number (90 percent) of the approximately 450 geostationary satellites in orbit.\n, no customers have signed up for a ViviSat-enabled mission extension.\n\nIn 2015, Lockheed Martin proposed the Jupiter space tug. If built, Jupiter would operate in low Earth orbit shuttling cargo carriers to and from the International Space Station, remaining on orbit indefinitely, and refueling itself from subsequent transport ships carrying later cargo carrier modules.\n\n\n\n"}
{"id": "1932188", "url": "https://en.wikipedia.org/wiki?curid=1932188", "title": "Radiolocation", "text": "Radiolocation\n\nRadiolocating is the process of finding the location of something through the use of radio waves. It generally refers to passive uses, particularly radar—as well as detecting buried cables, water mains, and other public utilities. It is similar to radionavigation, but radiolocation usually refers to passively finding a distant object rather than actively one's own position. Both are types of radiodetermination. Radiolocation is also used in real-time locating systems (RTLS) for tracking valuable assets.\n\nAn object can be located by measuring the characteristics of received radio waves. The radio waves may be transmitted by the object to be located, or they may be backscattered waves (as in radar or passive RFID). A stud finder uses radiolocation when it uses radio waves rather than ultrasound.\n\nOne technique measures a distance by using the difference in the power of the received signal strength (RSSI) as compared to the originating signal strength. Another technique uses the time of arrival (TOA), when the time of transmission and speed of propagation are known. Combining TOA data from several receivers at different known locations (time difference of arrival, TDOA) can provide an estimate of position even in the absence of knowledge of the time of transmission. The angle of arrival (AOA) at a receiving station can be determined by the use of a directional antenna, or by differential time of arrival at an array of antennas with known location. AOA information may be combined with distance estimates from the techniques previously described to establish the location of a transmitter or backscatterer. Alternatively, the AOA at two receiving stations of known location establishes the position of the transmitter. The use of multiple receivers to locate a transmitter is known as multilateration. \n\nEstimates are improved when the transmission characteristics of the medium is factored into the calculations. For RSSI this means electromagnetic permeability; for TOA it may mean non-line-of-sight receptions. \n\nUse of RSSI to locate a transmitter from a single receiver requires that both the transmitted (or backscattered) power from the object to be located are known, and that the propagation characteristics of the intervening region are known. In empty space, signal strength decreases as the inverse square of the distance for distances large compared to a wavelength and compared to the object to be located, but in most real environments, a number of impairments can occur: absorption, refraction, shadowing, and reflection. Absorption is negligible for radio propagation in air at frequencies less than about 10 GHz, but becomes important at multi-GHz frequencies where rotational molecular states can be excited. Refraction is important at long ranges (tens to hundreds of kilometers) due to gradients in moisture content and temperature in the atmosphere. In urban, mountainous, or indoor environments, obstruction by intervening obstacles and reflection from nearby surfaces are very common, and contribute to multipath distortion: that is, reflected and delayed replicates of the transmitted signal are combined at the receiver. Signals from different paths can add constructively or destructively: such variations in amplitude are known as fading. The dependence of signal strength on position of transmitter and receiver becomes complex and often non-monotonic, making single-receiver estimates of position inaccurate and unreliable. Multilateration using many receivers is often combined with calibration measurements (\"fingerprinting\") to improve accuracy.\n\nTOA and AOA measurements are also subject to multipath errors, particularly when the direct path from the transmitter to receiver is blocked by an obstacle. Time of arrival measurements are also most accurate when the signal has distinct time-dependent features on the scale of interest—for example, when it is composed of short pulses of known duration—but Fourier transform theory shows that in order to change amplitude or phase on a short time scale, a signal must use a broad bandwidth. For example, to create a pulse of about 1 ns duration, roughly sufficient to identify location to within 0.3 m (1 foot), a bandwidth of roughly 1 GHz is required. In many regions of the radio spectrum, emission over such a broad bandwidth is not allowed by the relevant regulatory authorities, in order to avoid interference with other narrowband users of the spectrum. In the United States, unlicensed transmission is allowed in several bands, such as the 902-928 MHz and 2.4-2.483 GHz Industrial, Scientific, and Medical ISM bands, but high-power transmission cannot extend outside of these bands. However, several jurisdictions now allow ultrawideband transmission over GHz or multi-GHz bandwidths, with constraints on transmitted power to minimize interference with other spectrum users. UWB pulses can be very narrow in time, and often provide accurate estimates of TOA in urban or indoor environments.\n\nRadiolocation is employed in a wide variety of industrial and military activities. Radar systems often use a combination of TOA and AOA to determine a backscattering object's position using a single receiver. In Doppler radar, the Doppler shift is also taken into account, determining velocity rather than location (though it helps determine future location). Real Time Location Systems RTLS using calibrated RTLS, and TDOA, are commercially available. The widely used Global Positioning System (GPS) is based on TOA of signals from satellites at known positions.\n\nRadiolocation is also used in cellular telephony via base stations. Most often, this is done through trilateration between radio towers. The location of the Caller or handset can be determined several ways:\n\nThe first two depend on a line-of-sight, which can be difficult or impossible in mountainous terrain or around skyscrapers. Location signatures actually work \"better\" in these conditions however. TDMA and GSM networks such as Cingular and T-Mobile use TDOA.\n\nCDMA networks such as Verizon Wireless and Sprint PCS tend to use handset-based radiolocation technologies, which are technically more similar to radionavigation. GPS is one of those technologies.\n\nComposite solutions, needing both the handset and the network include:\n\nInitially, the purpose of any of these in mobile phones is so that the public safety answering point (PSAP) which answers calls to an emergency telephone number can know where the caller is and exactly where to send emergency services. This ability is known within the NANP (North America) as wireless enhanced 911. Mobile phone users may have the option to permit the location information gathered to be sent to other phone numbers or data networks, so that it can help people who are simply lost or want other location-based services. By default, this selection is usually turned off, to protect privacy.\n\n\n\"Signal Processing Techniques in Network-Aided Positioning\", G. Sun, J. Chen, W. Guo and K. Liu, IEEE Signal Processing Magazine v. 22 #4, p. 12, July 2005\n\n\"Locating the nodes: cooperative localization in wireless sensor networks\", N. Patwari et al., IEEE Signal Processing Magazine v. 22 #4, p. 54, July 2005\n\n“The Indoor Radio Propagation Channel”, H. Hashemi, Proceedings of the IEEE, v. 81, #7, p. 943 (1993)\n\n“Outdoor/Indoor Propagation Modeling for Wireless Communications Systems”, M. Iskander, Z. Yun, and Z. Zhang, IEEE Antennas and Propagation Society, AP-S International Symposium (Digest) v 2 2001. p 150-153\n"}
{"id": "51474", "url": "https://en.wikipedia.org/wiki?curid=51474", "title": "Seat belt", "text": "Seat belt\n\nA seat belt (also known as a seatbelt or safety belt) is a vehicle safety device designed to secure the occupant of a vehicle against harmful movement that may result during a collision or a sudden stop. A seat belt functions to reduce the likelihood of death or serious injury in a traffic collision by reducing the force of secondary impacts with interior strike hazards, by keeping occupants positioned correctly for maximum effectiveness of the airbag (if equipped) and by preventing occupants being ejected from the vehicle in a crash or if the vehicle rolls over.\n\nWhen in motion, the driver and passengers are travelling at the same speed as the car. If the driver makes the car suddenly stop or crashes it, the driver and passengers continue at the same speed the car was going before it stopped. A seatbelt applies an opposing force to the driver and passengers to prevent them from falling out or making contact with the interior of the car. Seatbelts are considered Primary Restraint Systems (PRS), because of their vital role in occupant safety.\n\nAn analysis conducted in the United States in 1984 compared a variety of seat belt types alone and in combination with air bags. The range of fatality reduction for front seat passengers was broad, from 20% to 55%, as was the range of major injury, from 25% to 60%. More recently, the Centers for Disease Control and Prevention has summarized this data by stating \"seat belts reduce serious crash-related injuries and deaths by about half.\" Most seatbelt malfunctions are a result of there being too much slack in the seatbelt at the time of the accident.\n\nSeat belts were invented by English engineer George Cayley in the mid-19th century, though Edward J. Claghorn of New York, was granted the first patent (, on February 10, 1885 for a safety belt). Claghorn was granted United States Patent #312,085 for a Safety-Belt for tourists, painters, firemen, etc. who are being raised or lowered, described in the patent as \"designed to be applied to the person, and provided with hooks and other attachments for securing the person to a fixed object.\"\n\nIn 1946, Dr. C. Hunter Shelden opened a neurological practice at Huntington Memorial Hospital in Pasadena, California. In the early 1950s, Dr. Shelden made a major contribution to the automotive industry with his idea of retractable seat belts. This came about his from his care of the high number of head injuries coming through the emergency room. He investigated the early seat belts whose primitive designs were implicated in these injuries and deaths. To reduce the high level of injuries he was seeing, he proposed, in late 1955, retractable seat belts, recessed steering wheels, reinforced roofs, roll bars, automatic door locks, and passive restraints such as the air bag. Subsequently, in 1966, Congress passed the National Traffic and Motor Vehicle Safety Act requiring all automobiles to comply with certain safety standards.\n\nAmerican car manufacturers Nash (in 1949) and Ford (in 1955) offered seat belts as options, while Swedish Saab first introduced seat belts as standard in 1958. After the Saab GT 750 was introduced at the New York Motor Show in 1958 with safety belts fitted as standard, the practice became commonplace.\n\nGlenn Sheren, of Mason, Michigan, submitted a patent application on March 31, 1955 for an automotive seat belt and was awarded US Patent 2,855,215 in 1958. This was a continuation of an earlier patent application that Mr. Sheren had filed on September 22, 1952.\n\nHowever, the first modern three point seat belt (the so-called \"CIR-Griswold restraint\") used in most consumer vehicles today was patented in 1955 by the Americans Roger W. Griswold and Hugh DeHaven.\n\nThe Swedish national electric utility, did a study of all fatal, on-the-job accidents among their employees. The study revealed that the majority of fatalities occurred while the employees were on the road on company business. In response, two Vattenfall safety engineers, Bengt Odelgard and Per-Olof Weman, started to develop a seat belt. Their work was presented to Swedish manufacturer Volvo in the late 1950s, and set the standard for seat belts in Swedish cars. The three-point seatbelt was developed to its modern form by Swedish inventor Nils Bohlin for Volvo—who introduced it in 1959 as standard equipment. In addition to designing an effective three-point belt, Bohlin demonstrated its effectiveness in a study of 28,000 accidents in Sweden. Unbelted occupants sustained fatal injuries throughout the whole speed scale, whereas none of the belted occupants were fatally injured at accident speeds below 60 mph. No belted occupant was fatally injured if the passenger compartment remained intact. Bohlin was granted for the device.\n\nThe world's first seat belt law was put in place in 1970, in the state of Victoria, Australia, making the wearing of a seat belt compulsory for drivers and front-seat passengers. This legislation was enacted after trialing Hemco seatbelts, designed by Desmond Hemphill (1926–2001), in the front seats of police vehicles, lowering the incidence of officer injury and death.\n\nA 2-point belt attaches at its two endpoints, and was invented in the early 1900s by Jack Swearingen of Louisville, Kentucky.\n\nA lap belt is a strap that goes over the waist. This was the most commonly installed type of belt prior to legislation requiring three-point belts, and is primarily found in older cars. Coaches are equipped with lap belts (although many newer coaches have three-point belts), as are passenger aircraft seats.\n\nUniversity of Minnesota Professor James J. (Crash) Ryan was the inventor of and held the patent on the automatic retractable lap safety belt. Ralph Nader cited Ryan's work in Unsafe at Any Speed and in 1966 President Lyndon Johnson signed two bills requiring safety belts in all passenger vehicles starting in 1968.\n\nUntil the 1980s, three-point belts were commonly available only in the front outboard seats of cars; the back seats were only often fitted with lap belts. Evidence of the potential of lap belts to cause separation of the lumbar vertebrae and the sometimes associated paralysis, or \"seat belt syndrome\", led to progressive revision of passenger safety regulations in nearly all developed countries to require three-point belts first in all outboard seating positions and eventually in all seating positions in passenger vehicles. Since September 1, 2007, all new cars sold in the U.S. require a lap and shoulder belt in the center rear seat. \nBesides regulatory changes, \"seat belt syndrome\" has led to tremendous liability for vehicle manufacturers. One Los Angeles case resulted in a $45 million jury verdict against the Ford Motor Company; the resulting $30 million judgment (after deductions for another defendant who settled prior to trial) was affirmed on appeal in 2006.\n\nA \"sash\" or shoulder harness is a strap that goes diagonally over the vehicle occupant's outboard shoulder and is buckled inboard of his or her lap. The shoulder harness may attach to the lap belt tongue, or it may have a tongue and buckle completely separate from those of the lap belt. Shoulder harnesses of this separate or semi-separate type were installed in conjunction with lap belts in the outboard front seating positions of many vehicles in the North American market starting at the inception of the shoulder belt requirement of the U.S. National Highway Traffic Safety Administration's Federal Motor Vehicle Safety Standard 208 on 1 January 1968. However, if the shoulder strap is used without the lap belt, the vehicle occupant is likely to \"submarine\", or slide forward in the seat and out from under the belt, in a frontal collision. In the mid-1970s, three-point belt systems such as Chrysler's \"Uni-Belt\" began to supplant the separate lap and shoulder belts in American-made cars, though such three-point belts had already been supplied in European vehicles such as Volvos, Mercedes, and Saabs for some years.\n\nA three-point belt is a Y-shaped arrangement, similar to the separate lap and sash belts, but unitized. Like the separate lap-and-sash belt, in a collision the three-point belt spreads out the energy of the moving body over the chest, pelvis, and shoulders. Volvo introduced the first production three-point belt in 1959. The first car with a three-point belt was a Volvo PV 544 that was delivered to a dealer in Kristianstad on August 13, 1959. However, the first car model to feature the three-point seat belt as a standard item was the 1959 Volvo 122, first outfitted with a two-point belt at initial delivery in 1958, replaced with the three-point seat belt the following year. The three-point belt was developed by Nils Bohlin who had earlier also worked on ejection seats at Saab. Volvo then made the new seat belt design patent open in the interest of safety and made it available to other car manufacturers for free.\n\nThe BIS is a three-point harness with the shoulder belt attached to the seat itself, rather than to the vehicle structure. The first car using this system was the Range Rover Classic. Fitment was standard on the front seats from 1970. Some cars like the Renault Vel Satis use this system for the front seats. A General Motors assessment concluded seat-mounted three-point belts offer better protection especially to smaller vehicle occupants, though GM did not find a safety performance improvement in vehicles with seat-mounted belts versus belts mounted to the vehicle body.\n\nBIS type belts have been used by automakers in convertibles and pillarless hardtops, where there is no \"B\" pillar to affix the upper mount of the belt. Chrysler and Cadillac are well known for using this design. Antique auto enthusiasts sometimes replace original seats in their cars with BIS-equipped front seats, providing a measure of safety not available when these cars were new. However, modern BIS systems typically use electronics that must be installed and connected with the seats and the vehicle's electrical system in order to function properly.\n\nFive-point harnesses are typically found in child safety seats and in racing cars. The lap portion is connected to a belt between the legs and there are two shoulder belts, making a total of five points of attachment to the seat. A 4-point harness is similar, but without the strap between the legs, while a 6-point harness has two belts between the legs. In NASCAR, the 6-point harness became popular after the death of Dale Earnhardt, who was wearing a five-point harness when he suffered his fatal crash; as it was first thought that his belt had broken, and broke his neck at impact, some teams ordered a six-point harness in response.\n\nAerobatic aircraft frequently use a combination harness consisting of a five-point harness with a redundant lap-belt attached to a different part of the aircraft. While providing redundancy for negative-g manoeuvres (which lift the pilot out of the seat); they also require the pilot to un-latch two harnesses if it is necessary to parachute from a failed aircraft.\n\nThe purpose of locking retractors is to provide the seated occupant the convenience of some free movement of the upper torso within the compartment, while providing a method of limiting this movement in the event of a crash. Most modern seat belts are stowed on spring-loaded reels called \"retractors\" equipped with inertial locking mechanisms that stop the belt from extending off the reel during severe deceleration. There are two main types of inertial seat belt lock. A webbing-sensitive lock is based on a centrifugal clutch activated by rapid acceleration of the strap (webbing) from the reel. The belt can be pulled from the reel only slowly and gradually, as when the occupant extends the belt to fasten it. A sudden rapid pull of the belt—as in a sudden braking or collision event—causes the reel to lock, restraining the occupant in position.\n\nA vehicle-sensitive lock is based on a pendulum swung away from its plumb position by rapid deceleration or rollover of the vehicle. In the absence of rapid deceleration or rollover, the reel is unlocked and the belt strap may be pulled from the reel against the spring tension of the reel. The vehicle occupant can move around with relative freedom while the spring tension of the reel keeps the belt taut against the occupant. When the pendulum swings away from its normal plumb position due to sudden deceleration or rollover, a pawl is engaged, the reel locks and the strap restrains the belted occupant in position. Dual-sensing locking retractors use both vehicle G-loading and webbing payout rate to initiate the locking mechanism.\n\nSeatbelts in many newer vehicles are also equipped with \"pretensioners\" or \"web clamps\", or both.\n\nPretensioners preemptively tighten the belt to prevent the occupant from jerking forward in a crash. Mercedes-Benz first introduced pretensioners on the 1981 S-Class. In the event of a crash, a pretensioner will tighten the belt almost instantaneously. This reduces the motion of the occupant in a violent crash. Like airbags, pretensioners are triggered by sensors in the car's body, and many pretensioners have used explosively expanding gas to drive a piston that retracts the belt. Pretensioners also lower the risk of \"submarining\", which occurs when a passenger slides forward under a loosely fitted seat belt.\n\nSome systems also pre-emptively tighten the belt during fast accelerations and strong decelerations, even if no crash has happened. This has the advantage that it may help prevent the driver from sliding out of position during violent evasive maneuvers, which could cause loss of control of the vehicle. These pre-emptive safety systems may \"prevent\" some collisions from happening, as well as reducing injury in the event an actual collision occurs. Pre-emptive systems generally use electric pretensioners which can operate repeatedly and for a sustained period, rather than pyrotechnic pretensioners, which can only operate a single time.\n\nWebclamps clamp the webbing in the event of an accident, and limit the distance the webbing can spool out (caused by the unused webbing tightening on the central drum of the mechanism). These belts also often incorporate an energy management loop (\"rip stitching\") in which a section of the webbing is looped and stitched with a special stitching. The function of this is to \"rip\" at a predetermined load, which reduces the maximum force transmitted through the belt to the occupant during a violent collision, reducing injuries to the occupant.\n\nA study demonstrated that standard automotive three-point restraints fitted with pyrotechnic or electric pretensioners were not able to eliminate all interior passenger compartment head strikes in rollover test conditions. Electric pretensioners are often incorporated on vehicles equipped with precrash systems; they are designed to reduce seat belt slack in a potential collision and assist in placing the occupants in a more optimal seating position. The electric pretensioners also can operate on a repeated or sustained basis, providing better protection in the event of an extended rollover or a multiple collision accident.\n\nThe inflatable seatbelt was invented by Donald Lewis and tested at the Automotive Products Division of Allied Chemical Corporation. Inflatable seatbelts have tubular inflatable bladders contained within an outer cover. When a crash occurs the bladder inflates with a gas to increase the area of the restraint contacting the occupant and also shortening the length of the restraint to tighten the belt around the occupant, improving the protection. The inflatable sections may be shoulder-only or lap and shoulder. The system supports the head during the crash better than a web only belt. It also provides side impact protection. In 2013, Ford began offering rear seat inflatable seat belts on a limited set of models, such as the Explorer and Flex.\n\nSeatbelts that automatically move into position around a vehicle occupant once the adjacent door is closed and/or the engine is started were developed as a countermeasure against low usage rates of manual seat belts, particularly in the United States.\n\nThe 1972 Volkswagen ESVW1 Experimental Safety Vehicle presented passive seat belts. Volvo tried to develop a passive three point seatbelt. In 1973, Volkswagen announced they had a functional passive seat belt. The first commercial car to use automatic seat belts was the 1975 Volkswagen Golf.\n\nAutomatic seat belts received a boost in the United States in 1977 when Brock Adams, United States Secretary of Transportation in the Carter Administration, mandated that by 1983 every new car should have either airbags or automatic seat belts. There was strong lobbying against the passive restraint requirement by the auto industry. Adams was criticized by Ralph Nader, who said that the 1983 deadline was too late. The VW Rabbit also offered this safety feature. By early 1978, Volkswagen had reported 90,000 Rabbits sold with automatic seat belts. \nGeneral Motors introduced a three-point non-motorized passive belt system in 1980 to comply with the passive restraint requirement. However, it was used as an active lap-shoulder belt because of unlatching the belt to exit the vehicle. Despite this common practice, field studies of belt use still showed an increase in wearing rates with this door-mounted system. General Motors began offering automatic seat belts on the Chevrolet Chevette. However, the company reported disappointing sales because of this feature.\n\nA study released in 1978 by the United States Department of Transportation claimed that cars with automatic seat belts had a fatality rate of .78 per 100 million miles, compared with 2.34 for cars with regular, manual belts.\n\nIn 1981, Drew Lewis, the first Transportation Secretary of the Reagan Administration, influenced by studies done by the auto industry, dropped the mandate; the decision was overruled in a federal appeals court the following year, and then by the Supreme Court. In 1984, the Reagan Administration reversed its course, though in the meantime the original deadline had been extended; Elizabeth Dole, then Transportation Secretary, proposed that the two passive safety restraints be phased into vehicles gradually, from vehicle model year 1987 to vehicle model year 1990, when all vehicles would be required to have either automatic seat belts or driver side air bags. Though more awkward for vehicle occupants, most manufacturers opted to use less expensive automatic belts rather than airbags during this time period.\n\nWhen driver side airbags became mandatory on all passenger vehicles in model year 1995, most manufacturers stopped equipping cars with automatic seat belts. Exceptions include the 1995–96 Ford Escort/Mercury Tracer and the Eagle Summit Wagon, which had automatic safety belts along with dual airbags.\n\n\nAutomatic belt systems generally offer inferior occupant crash protection. In systems with belts attached to the door rather than a sturdier fixed portion of the vehicle body, a crash that causes the vehicle door to open leaves the occupant without belt protection. In such a scenario, the occupant may be thrown from the vehicle and suffer greater injury or death.\n\nBecause many automatic belt system designs compliant with the US passive-restraint mandate did not meet the safety performance requirements of Canada—which were not weakened to accommodate automatic belts—vehicle models which had been eligible for easy importation in either direction across the US-Canada border when equipped with manual belts became ineligible for importation in either direction once the U.S. variants obtained automatic belts and the Canadian versions retained manual belts. Two particular models included the Dodge Spirit and Plymouth Acclaim.\n\nAutomatic belt systems also present several operational disadvantages. Motorists who would normally wear seat belts must still fasten the manual lap belt, thus rendering redundant the automation of the shoulder belt. Those who do not fasten the lap belt wind up inadequately protected only by the shoulder belt; in a crash without a lap belt such a vehicle occupant is likely to \"submarine\" (be thrown forward under the shoulder belt) and be seriously injured. Motorized or door-affixed shoulder belts hinder access to the vehicle, making it difficult to enter and exit—particularly if the occupant is carrying items such as a box or a purse. Vehicle owners tend to disconnect the motorized or door-affixed shoulder belt to relieve the nuisance of entering and exiting the vehicle, leaving only a lap belt for crash protection. Also, many automatic seat belt systems are incompatible with child safety seats, or only compatible with special modifications.\n\nStarting in 1971 and ending in 1972, the United States conducted a research project on seat belt effectiveness on a total of 40,000 vehicle occupants using car accident reports collected during that time. Of these 40,000 occupants, 18% were reported wearing lap belts, or two-point safety belts, 2% were reported wearing a three-point safety belt, and the remaining 80% were reported as wearing no safety belt. The results concluded that users of the two-point lap belt had a 73% lower fatality rate, a 53% lower serious injury rate, and a 38% lower injury rate than the occupants that were reported unrestrained. Similarly, users of the three-point safety belt had a 60% lower serious injury rate and a 41% lower rate of all other injuries. Out of the 2% described as wearing a three-point safety belt, no fatalities were reported.\n\nThis study and others led to the Restraint Systems Evaluation Program (RSEP), started by the National Highway Traffic Safety Administration in 1975 to increase the reliability and authenticity of past studies. A study as part of this program used data taken from 15,000 tow-away accidents that involved only car models made between 1973 and 1975. The study found that for injuries considered “moderate” or worse, individuals wearing a three-point safety belt had a 56.5% lower injury rate than those wearing no safety belt. The study also concluded that the effectiveness of the safety belt did not differ with size of car. It was determined that the variation among results of the many studies conducted in the 1960s and 70s was due to the use of different methodologies, and could not be attributed to any significant variation in the effectiveness of safety belts.\n\nWayne State University’s Automotive Safety Research Group, as well as other researchers, are testing ways to improve seat belt effectiveness and general vehicle safety apparatuses. Wayne State’s Bioengineering Center uses human cadavers in their crash test research. The Center’s director, Albert King, wrote in 1995 that the vehicle safety improvements made possible since 1987 by the use of cadavers in research had saved nearly 8,500 lives each year, and indicated that improvements made to three-point safety belts save an average of 61 lives every year.\n\nThe New Car Assessment Program (NCAP) was put in place by the United States National Highway Traffic Safety Administration in 1979. The NCAP is a government program that evaluates vehicle safety designs and sets standards for foreign and domestic automobile companies. The agency developed a rating system and requires access to safety test results. , manufacturers are required to place a NCAP star rating on the automobile price sticker.\n\nResearch and development efforts are ongoing to improve the safety performance of vehicle seatbelts. Some experimental designs include:\n\nIn 1955 (as a 1956 package), Ford offered lap only seat belts in the rear seats as an option within the \"Lifeguard\" safety package. In 1967, Volvo started to install lap belts in the rear seats. In 1972, Volvo upgraded the rear seat belts to a three-point belt.\n\nIn crashes, unbelted rear passengers increase the risk of belted front seat occupants' death by nearly five times.\n\nAs with adult drivers and passengers, the advent of seat belts was accompanied by calls for their use by child occupants, including legislation requiring such use. Generally children using adult seat belts suffer significantly lower injury risk when compared to non-buckled children.\n\nThe UK extended compulsory seatbelt wearing to child passengers under the age of 14 in 1989. It was observed that this measure was accompanied by a 10% \"increase\" in fatalities and a 12% \"increase\" in injuries among the target population. In crashes, small children who wear adult seatbelts can suffer \"seat-belt syndrome\" injuries including severed intestines, ruptured diaphragms and spinal damage. There is also research suggesting that children in inappropriate restraints are at significantly increased risk of head injury, one of the authors of this research has been quoted as claiming that: \"The early graduation of kids into adult lap and shoulder belts is a leading cause of child-occupant injuries and deaths.\"\n\nAs a result of such findings, many jurisdictions now advocate or require child passengers to use specially designed child restraints. Such systems include separate child-sized seats with their own restraints and booster cushions for children using adult restraints. In some jurisdictions children below a certain size are forbidden to travel in front car seats.\"\n\nIn Europe, the US, and some other parts of the world, most modern cars include a seat-belt reminder light for the driver and some also include a reminder for the passenger, when present, activated by a pressure sensor under the passenger seat. Some cars will intermittently flash the reminder light and sound the chime until the driver (and sometimes the front passenger, if present) fasten their seatbelts.\n\nIn 2005, in Sweden, 70% of all cars that were newly registered were equipped with seat belt reminders for the driver.\nSince November 2014, seat belt reminders are mandatory for the driver's seat on new cars sold in Europe.\n\nTwo specifications define the standard of seat belt reminder: UN Regulation 16, Section 8.4 and the Euro NCAP assessment protocol (Euro NCAP, 2013).\n\nIn North America, cars sold since the early 1970s have included an audiovisual reminder system consisting of a tell-tale light on the dashboard and a buzzer or chime reminding the driver and passengers to fasten their belts. Originally, these lights were accompanied by a warning buzzer whenever the transmission was in any position except park if either the driver was not buckled up or, as determined by a pressure sensor in the passenger's seat, if there was a passenger there not buckled up. However, this was considered by many to be a major annoyance, as the light would be on and the buzzer would sound continuously if front-seat passengers were not buckled up. Therefore, people who did not wish to buckle up would defeat this system by fastening the seat belts with the seat empty and leaving them that way.\n\nTo combat this dangerous habit, in 1971 NHTSA amended Federal Motor Vehicle Safety Standard № 208 (FMVSS 208) to require a seat belt/starter interlock system to prevent passenger cars from being started with an unbelted front-seat occupant. This mandate applied to passenger cars built after August 1973, i.e., starting with the 1974 model year. The specifications required the system to permit the car to be started only if the belt of an occupied seat were fastened after the occupant sat down, so pre-buckling the belts would not defeat the system. \nThe interlock systems used logic modules complex enough to require special diagnostic computers, and were not entirely dependable—an override button was provided under the hood of equipped cars, permitting one (but only one) \"free\" starting attempt each time it was pressed. However, the interlock system spurred severe backlash from an American public who largely rejected seat belts. In 1974, Congress acted to prohibit NHTSA from requiring or permitting a system that prevents a vehicle from starting or operating with an unbelted occupant, or that gives an audible warning of an unfastened belt for more than 8 seconds after the ignition is turned on. This prohibition took effect on 27 October 1974, shortly after the 1975 model year began.\n\nIn response to the Congressional action, NHTSA once again amended FMVSS 208, requiring vehicles to come with a seat belt reminder system that gives an audible signal for 4 to 8 seconds and a warning light for at least 60 seconds after the ignition is turned on if the driver's seat belt is not fastened. This is called a seat belt reminder (SBR) system. In the mid-1990s, an insurance company from Sweden called Folksam worked with Saab and Ford to determine the requirements for the most efficient seat belt reminder. One characteristic of the optimal SBR, according to the research, is that the audible warning becomes increasingly penetrating the longer the seat belt remains unfastened.\n\nIn 2003, the Transportation Research Board Committee, chaired by two psychologists, reported that ESBRs could save an additional 1,000 lives a year. Research by the Insurance Institute for Highway Safety found that Ford's ESBR, which provides an intermittent chime for up to five minutes if the driver is unbelted, sounding for 6 seconds then pausing for 30, increased seat belt use by 5 percentage points. Farmer and Wells found that driver fatality rates were 6% lower for vehicles with ESBR compared with otherwise-identical vehicles without.\n\nIn 2001, Congress directed NHSTA to study the benefits of technology meant to increase the use of seat belts. NHSTA found that seat belt usage had increased to 73% since the initial introduction of the SBR system. In 2002, Ford demonstrated that seat belts were used more in Fords with seat belt reminders than in those without: 76% and 71% respectively. In 2007, Honda conducted a similar study and found that 90% of people who drove Hondas with seat belt reminders used a seat belt, while 84% of people who drove Hondas without seat belt reminders used a seat belt.\n\nObservational studies of car crash morbidity and mortality, experiments using both crash test dummies and human cadavers indicate that wearing seat belts greatly reduces the risk of death and injury in the majority of car crashes.\n\nThis has led many countries to adopt mandatory seat belt wearing laws. It is generally accepted that, in comparing like-for-like accidents, a vehicle occupant not wearing a properly fitted seat belt has a significantly and substantially higher chance of death and serious injury. One large observation studying using US data showed that the odds ratio of crash death is 0.46 with a three-point belt, when compared with no belt. In another study that examined injuries presenting to the ER pre- and post-seat belt law introduction, it was found that 40% more escaped injury and 35% more escaped mild and moderate injuries.\n\nThe effects of seat belt laws are disputed by those who observe that their passage did not reduce road fatalities. There was also concern that instead of legislating for a general protection standard for vehicle occupants, laws that required a particular technical approach would rapidly become dated as motor manufacturers would tool up for a particular standard which could not easily be changed. For example, in 1969 there were competing designs for lap and three-point seat belts, rapidly tilting seats, and airbags being developed. But as countries started to mandate seat belt restraints the global auto industry invested in the tooling and standardized exclusively on seat belts, and ignored other restraint designs such as air bags for several decades\n\nAs of 2016, seat belt laws can be divided into two categories: primary and secondary. A primary seat belt law allows an officer to issue a citation for lack of seatbelt use without any other citation, whereas a secondary seat belt law allows an officer to issue a seat belt citation only in the presence of a different violation. In the United States, fifteen states enforce secondary laws, while 34 states, as well as the District of Columbia, American Samoa, Guam, the Northern Mariana Islands, Puerto Rico and the Virgin Islands, enforce primary seat belt laws. New Hampshire lacks both a primary and secondary seat belt law.\n\nSome have proposed that the number of deaths was influenced by the development of risk compensation, which says that drivers adjust their behavior in response to the increased sense of personal safety wearing a seat belt provides.\n\nIn one trial subjects were asked to drive go-karts around a track under various conditions. It was found that subjects who started driving unbelted drove consistently faster when subsequently belted. Similarly, a study of habitual non-seatbelt wearers driving in freeway conditions found evidence that they had adapted to seatbelt use by adopting higher driving speeds and closer following distances. \nA 2001 analysis of US crash data aimed to establish the effects of seatbelt legislation on driving fatalities and found that previous estimates of seatbelts effectiveness had been significantly overstated. According to the analysis used, seatbelts were claimed to have decreased fatalities by 1.35% for each 10% increase in seatbelt use. The study controlled for endogenous motivations of seat belt use, which it is claimed creates an artificial correlation between seat belt use and fatalities, leading to the conclusion that seatbelts cause fatalities. For example, drivers in high risk areas are more likely to use seat belts, and are more likely to be in accidents, creating a non-causal correlation between seatbelt use and mortality. After accounting for the endogeneity of seatbelt usage, Cohen and Einav found no evidence that the risk compensation effect makes seatbelt wearing drivers more dangerous, a finding at variance with other research.\n\nOther statistical analyses have included adjustments for factors such as increased traffic, and other factors such as age, and based on these adjustments, a reduction of morbidity and mortality due to seat belt use has been claimed. However, Smeed's law predicts a fall in accident rate with increasing car ownership and has been demonstrated independently of seat belt legislation.\n\nIn the US, six states—California, Florida, Louisiana, New Jersey, New York, and Texas—require seat belts on school buses.\n\nPros and cons had been alleged about the use of seatbelts in school buses.\nSchool buses which are much bigger in size than the average vehicle allow for the mass transportation of students from place to place. The American School Bus Council states in a brief article saying that, “The children are protected like eggs in an egg carton – compartmentalized, and surrounded with padding and structural integrity to secure the entire container.” (ASBC). Although school buses are considered safe for mass transit of students this will not guarantee that the students will be injury free if an impact were to occur. Seatbelts in buses are sometimes believed to make recovering from a roll or tip harder for students and staff as they could be easily trapped in their own safety belt.\n\nIn 2015, for the first time, NHTSA endorsed seat belts on school buses.\n\nIn the European Union, all new long distance buses and coaches must be fitted with seat belts.\n\nAustralia has required lap/sash seat belts in new coaches since 1994. These must comply with Australian Design Rule 68, which requires the seat belt, seat and seat anchorage to withstand 20g deceleration and an impact by an unrestrained occupant to the rear.\n\nIn the United States, NHTSA has now required lap-shoulder seat belts in new \"over-the-road\" buses (includes most coaches) starting in 2016.\n\nThe use of seatbelts in trains has been investigated. Concerns about survival space intrusion in train crashes and increased injuries to unrestrained or incorrectly restrained passengers led the researchers to discourage the use of seat belts in trains.\n\nLap belts are found on all passenger aircraft. Many civil aviation authorities require a \"fasten seat belt\" sign in passenger aircraft that can be activated by a pilot during takeoff, turbulence, and landing. The International Civil Aviation Organization recommends the use of child restraints.\n\n\n"}
{"id": "18057299", "url": "https://en.wikipedia.org/wiki?curid=18057299", "title": "Simple Skincare", "text": "Simple Skincare\n\nSimple Skincare is a British brand of soap and skincare products, designed for sensitive skin. Simple has been owned by Unilever since 2010.\n\nThe brand was developed in 1960 by the Albion Group. In the late 1980s the business was acquired by Smith and Nephew. In June 2000, Smith and Nephew divested its consumer products division; a management buyout, led by CEO Geoff Percy and Finance Director Peter Hatherly, for £140m resulted in the formation of Accantia, owner of the Simple brand.\n\nIn January 2004, a secondary buyout was completed. Following an unsolicited approach, the board of Accantia sold the company to Duke Street Capital for £225m. Accantia's existing senior management team remained in place.\n\nIn April 2009, Accantia changed its name to Simple Health & Beauty Group Limited. Simple Health & Beauty Group Limited was bought by the US company Alberto-Culver for £240 million in December 2009. Alberto-Culver was bought by the Anglo–Dutch multinational consumer goods company Unilever in September 2010, and Simple was formally taken over around six months later.\n\nIn 1986, the company asked its advertising agency Deighton & Mullen to produce a TV commercial. Entitled 'Gilding the Lily', this ran on the newly launched Channel 4 and featured a pristine white lily being sprayed by robotic arms with colouring and perfume. It was created by Colin Underhay (art director) and Alex Pearl (copywriter) and directed by Len Fulford, while Lord David Dundas wrote the piano score in the style of Erik Satie, and Joanna Lumley provided the voice over.\n"}
{"id": "51013", "url": "https://en.wikipedia.org/wiki?curid=51013", "title": "Slurry pipeline", "text": "Slurry pipeline\n\nA slurry pipeline is a specially engineered pipeline used to move ores, such as coal or iron, or mining waste, called tailings, over long distances. A mixture of the ore concentrate and water, called slurry, is pumped to its destination and the water is filtered out. Due to the abrasive properties of slurry, the pipelines can be lined with high-density polyethylene (HDPE). Slurry pipelines are used as an alternative to railroad transportation when mines are located in remote, inaccessible areas.\nThe concentrate of the ore is mixed with water and then pumped over a long distance to a port where it can be shipped for further processing. At the end of the pipeline, the material is separated from the [slurry] in a filter press to remove the water. This water is usually subjected to a waste treatment process before disposal or return to the mine. Slurry pipelines offer an economic advantage over railroad transport and much less noise disturbance to the environment, particularly when mines are in extremely remote areas.\n\nPipelines must be suitably engineered to resist abrasion from the solids as well as corrosion from the soil. Some of these pipelines are lined with high-density polyethylene (HDPE).\n\nTypical materials that are transferred using slurry pipelines include coal, copper, iron, and phosphate concentrates, limestone, lead, zinc, nickel, bauxite and oil sands.\n\nSlurry pipelines are also used to transport tailings from a mineral processing plant after the ore has been processed in order to dispose of the remaining rocks or clays.\n\nFor oil sand plants, a mixture of oil sand and water may be pumped over a long distance to release the bitumen by ablation. These pipelines are also called hydrotransport pipelines.\n\nEarly modern slurry pipelines include The Ohio 'Consolidation' coal slurry pipeline (1957) and the Kensworth to Rugby limestone slurry pipeline (1965) \n\nThe 85 km Savage River Slurry pipeline in Tasmania, Australia, was possibly the world's first slurry pipeline to transport iron ore when it was built in 1967. It includes a 366m bridge span at 167m above the Savage River. It carries iron ore slurry from the Savage River open cut mine owned by Australian Bulk Minerals and was still operational as of 2011.\n\nOne of the longest slurry pipelines was to be the proposed ETSI pipeline, to transport coal from Wyoming to Louisiana over a distance of 1036 miles (1675 km). It was never commissioned. It is anticipated that in the next few years some long distance slurry pipelines will be constructed in Australia and South America where mineral deposits are often a few hundred kilometers away from shipping ports.\n\nA 525 km slurry pipeline is planned for the Minas-Rio iron ore mine in Brazil.\n\nSlurry pipelines are also being considered to desilt or remove silts from deposits behind dams in man-made lakes. After the Hurricane Katrina disaster there were proposals to remedy the environment by pumping silt to the shore. Proposals have also been made to de-silt Lake Nubia-Nasser in Egypt and Sudan by slurry pipelines, as Egypt is now deprived of 95% of its alluvium, which used to arrive every year. These projects to remedy the environment might alleviate one of the major problems associated with large dams and man-made lakes.\n\nESSAR Steel India Limited owns two 250 km+ slurry pipelines in India; the Kirandul-Vishakhapatnam (slurry pipeline) and Dabuna-Paradeep pipeline.\n\nCoal slurry pipeline\n\nEdward J. Wasp\n\nMiedema, S.A., Slurry Transport: Fundamentals, a Historical Overview and The Delft Head Loss & Limit Deposit Velocity Framework. http://www.dredging.org/media/ceda/org/documents/resources/othersonline/miedema-2016-slurry-transport.pdf\n\n"}
{"id": "201676", "url": "https://en.wikipedia.org/wiki?curid=201676", "title": "Stationery", "text": "Stationery\n\nStationery is a mass noun referring to commercially manufactured writing materials, including cut paper, envelopes, writing implements, continuous form paper, and other office supplies. Stationery includes materials to be written on by hand (e.g., letter paper) or by equipment such as computer printers.\n\nOriginally the term \"stationery\" referred to all products sold by a stationer, whose name indicated that his book shop was on a fixed spot, usually near a university, and permanent, while medieval trading was mainly carried on by itinerant peddlers (including chapmen, who sold books) and others (such as farmers and craftsmen) at markets and fairs. It was a special term used between the 13th and 15th centuries in the manuscript culture. The Stationers' Company formerly held a monopoly over the publishing industry in England and was responsible for copyright regulations.\n\nIn its modern sense including personal writing materials, stationery has been an important part of good social etiquette, particularly since the Victorian era. Some uses of stationery, such as sending a manufactured reply card to a wedding invitation, have changed from offensive to appropriate.\n\nThe use and marketing of stationery is being partly superseded by electronic media. Stationery is intrinsically linked to paper and the process of written, personalized communication, and many techniques of stationery manufacture are employed, of varying desirability and expense. The most familiar of these techniques are letterpress printing, embossing, engraving and thermographic printing (often confused with thermography). Flat printing and offset printing are regularly used, particularly for low-cost or informal needs.\n\nLetterpress is a method of printing many identical copies that requires characters being impressed upon the page. The print may be inked or blind but is typically done in a single color. Motifs or designs may be added as many letterpress machines use movable plates that must be hand-set.\n\nWhen a single document needs to be produced, it may be handwritten or printed typically by a computer printer. Several copies of one original can be produced by some printers using multipart stationery. Typing with a typewriter is obsolescent, having been largely superseded by preparing a document with a word processor and printing.\n\nThermographic printing is a process that involves several stages but can be implemented in a low-cost manufacturing process. The process involves printing the desired designs or text with an ink that remains wet, rather than drying on contact with the paper. The paper is then dusted with a powdered polymer that adheres to the ink. The paper is vacuumed or agitated, mechanically or by hand, to remove excess powder, and then heated to near combustion. The wet ink and polymer bond and dry, resulting in a raised print surface similar to the result of an engraving process.\n\nEmbossing is a printing technique used to create raised surfaces in the converted paper stock. The process relies upon mated dies that press the paper into a shape that can be observed on both the front and back surfaces.\nEngraving is a process that requires a design to be cut into a plate made of a relatively hard material. It is a technology with a long history and requires significant skill and experience. The finished plate is usually covered in ink, and then the ink is removed from all of the un-etched portions of the plate. The plate is then pressed into paper under substantial pressure. The result is a design that is slightly raised on the surface of the paper and covered in ink. Due to the cost of the process and expertise required, many consumers opt for thermographic printing, a process that results in a similarly raised print surface, but through different means at less cost.\n\nMany shops that sell stationery also sell other school supplies for students in primary and secondary education, including pocket calculators, display boards, compasses and protractors, lunchboxes, and the like.\n\nRetail dollar sales of back-to-school products from the office super stores grew 2 percent in August 2010 compared to August 2009, after July 2010 showed flat performance. The back-to-school season for school supplies had its best performance in the latter half of August, as many consumers waited until the last minute to purchase their supplies.\n\n\n"}
{"id": "52797937", "url": "https://en.wikipedia.org/wiki?curid=52797937", "title": "Sundial cannon", "text": "Sundial cannon\n\nA sundial cannon, sundial gun, noon cannon or meridian cannon, also noonday gun is a device consisting of a sundial incorporating a cannon with a fuse that is lit by an overhanging lens, concentrating the rays of the sun, and causing the cannon to fire at noon, when properly oriented along a north-south axis. The cannon sizes ranged from large to small depending on the location of their use. The household variety was used in estates to signal the time for the midday meal. Larger sizes were used in European parks to signal noon. \n\nThe cannons were used by European royalty in the 18th century. Cannons of this type are exhibited at the National Maritime Museum in Greenwich. The Hamilton Watch Company has a sundial cannon manufactured by Rousseau of Paris ca. 1650. The Rousseau cannon is mounted on a marble sundial and is made of brass. The Sultan of Morocco also owns one that was manufactured by Baker & Sons of London.\n\nThe earliest sundial cannons were used in Europe in the 1600s. They were also used in European parks during the 18th and early 19th centuries. The cannon-lens combination was mounted on a sundial. Sundial guns were also used in ships to mark noon. Miniaturized toy versions of the guns were sold in 1979 as unassembled kits by Dixie Gun Works.\n\nThe gun and the linear ignition groove of the fuse were aligned on a north-south axis, parallel to the one of the sundial, while the lens concentrated the sun rays on the fuse when the sun was directly above. Subsequently, the burning fuse ignited the powder placed in the barrel of the cannon. The lens was mounted on an adjustable frame, which enabled its position to be changed depending on the season. During winter, in December for example, for the small brass cannon manufactured by Rousseau of Paris, the lens had to be lowered by four inches, compared to its position in June as the position of the sun in the sky is lower in winter than during the summer. \n\nIn naval operations, the gun had to be mounted on a rotating base because its orientation had to be in the north-south direction. The directional axis of the gun was determined using the ship's compass. In such operation, the gun was frequently referred to as the \"noonday gun\" because it fired at noon. This practice became obsolete when the ship chronometer was invented. The use of the sundial cannon was subsequently confined to substandard ships.\n\nBenjamin Franklin wrote the following review about the cannons in \"Poor Richard's Almanack\": \n\nIn a section of the July 1911 issue of \"Popular Mechanics\" titled \"Women 'Insurgents' in the Farming Business\" the writer comments regarding the picture to the right: \n\nA sundial gun is mentioned in \"Ellery Queen's Mystery Magazine\".\n\n"}
{"id": "1511304", "url": "https://en.wikipedia.org/wiki?curid=1511304", "title": "Wetting layer", "text": "Wetting layer\n\nIn experimental physics, a wetting layer is an initial layer of atoms that is epitaxially grown on a surface upon which self-assembled quantum dots or thin films are created. The atoms composing a wetting layer can be semimetallic elements/compounds (usually InAs in the case of self-assembled quantum dots) or metallic alloys (for thin films). This article refers to the wetting layer used for quantum dot applications. By spraying a surface with layers of these atoms under high temperature, this wetting layer residue is produced on the surface. Wetting layers control the artificial atomic states of the quantum dot for uses in quantum information processing and quantum computation.\n\nThe wetting layer is epitaxially grown onto a surface using a molecular beam epitaxy (MBE) chamber at high temperatures. The temperatures required for wetting layer growth usually range from 400-500 degrees Celsius. If a self-assembled quantum dot is to form, an initial layer of atoms must first be placed on a surface. Due to the high elastic potential energy once a certain critical thickness is achieved, additional atoms group together to form the quantum dot to reduce this elastic energy. If further annealing of the quantum dot/wetting layer system is necessary, higher temperatures of up to 1100 degrees may be used.\n\nThe wetting layer serves as another parameter that can change the physics of a quantum dot. The thickness and composition determine the effect of the wetting layer on the quantum dot, however the thickness is usually roughly 0.5 nanometers. The electronic structure and strain of the quantum dot change as a result of the wetting layer. Theoretically, due to the lattice mismatch, finite thickness wetting layers are not stable and therefore admit some strain on the quantum dot.\n\nThe wetting layer serves as another parameter which can interfere with the quantum dots in order to control their state for quantum computation and other applications of quantum dots. \n"}
{"id": "8290217", "url": "https://en.wikipedia.org/wiki?curid=8290217", "title": "Yakov Rekhter", "text": "Yakov Rekhter\n\nYakov Rekhter is a well-known network protocol designer and software programmer. He was heavily involved in internet protocol development, and its predecessors, from their early stages.\n\nDr. Rekhter was one of the leading architects and a major software developer of the NSFNET Backbone Phase II. He co-designed the Border Gateway Protocol (BGP), the core routing protocol of the Internet. He was also one of the lead designers of Tag Switching (of which MPLS is one form), BGP/MPLS based VPNs, and MPLS Traffic Engineering. Among his most recent activities is the work on MPLS Multicast, Multicast in VPLS, and Multicast in BGP/MPLS VPNs (aka 2547 VPNs). His other contributions to contemporary Internet technology include: GMPLS, Classless Inter-Domain Routing (CIDR) and IP address allocation for private Internets.\n\nHe is the author or co-author of more than 80 IETF RFCs, and numerous papers and articles on TCP/IP and the Internet. His recent books include: \"MPLS: Technology and Applications\" (Morgan Kaufmann, 2000) and \"Switching in IP Networks: IP Switching, Tag Switching and Related Technologies\" (Morgan Kaufmann, 1998).\n\nRekhter joined Juniper Networks in December 2000, where he was a Juniper Fellow. Prior to joining Juniper, Yakov worked at Cisco Systems, where he was a Cisco Fellow. Prior to joining Cisco in 1995, he worked at IBM T.J. Watson Research Center.\n\nHe retired from Juniper Networks and the industry in January 2015.\n\nIn January 1989 at the 12th IETF meeting in Austin, Texas, Yakov Rekhter and Kirk Lougheed sat down at a table to design what ultimately became the Border Gateway Protocol (BGP). The initial BGP design was recorded on a napkin rumored to have been heavily spattered with ketchup. The design on the napkin was expanded to three hand-written sheets of paper from which the first interoperable BGP implementation was quickly developed. A photocopy of these 3 sheets of paper now hangs on the wall of a routing protocol development area at Cisco Systems in Milpitas, California.\n"}
{"id": "50616178", "url": "https://en.wikipedia.org/wiki?curid=50616178", "title": "YourCash Europe Ltd", "text": "YourCash Europe Ltd\n\nYourCash Europe Ltd is an independent automated teller machine (ATM) provider with operations in the UK, Netherlands, Belgium and Ireland. The company is owned by Euronet Worldwide Inc. and is headquartered in Milton Keynes, UK.\n\nYourCash machines are merchant-replenished ATMs, allowing businesses to fill the cash machines using cash takings from their own cash stocks and then be reimbursed electronically by YourCash.\n\nYourCash was established in 2000, as a private limited company under the name Hanco ATM Systems. It supplied machines in convenience locations such as grocers, corner shops, and garden centres.\n\nIn 2003 it opened operations in the Netherlands. In 2004, the Royal Bank of Scotland Group acquired Hanco ATM systems and by 2006 had begun rolling out free-to-use ATMs in the UK.\n\nIn October 2010 the business underwent a management buyout process that saw ownership divest from RBS and become a standalone Private Limited Company - YourCash Limited. During this time, YourCash also began expansion into Belgium which was completed in 2011.\n\nIn 2013, Managing Director Jenny Campbell led a secondary buy-out to enable the senior management team to take control of YourCash. This meant YourCash was now trading as a fully independent business with Campbell as the majority shareholder and CEO.\n\nFurther expansion into Ireland took place in 2016 and according to company officials; YourCash now controls 32 percent of the free-to-use ATM market in the United Kingdom.\n\nIn October 2016, YourCash was acquired by Euronet Worldwide Inc. Campbell remains the Chief Executive leading the business onto its next period of growth across the UK and Europe.\n\nYourCash is one of the 36 member institutions that comprise the LINK network. This is a shared interbank network of ATM providers operating in the UK and includes banks, building societies, and independent ATM operators.\nYourCash complete annual audits against LINK, MasterCard and Visa security practices and standards. This involves regular risk and compliance regimes that ensure best practices are achieved, and any non-compliances are raised and addressed accordingly.\n\nYourCash also complete Internal Control testing against its most important processes and procedures to ensure that they are fit-for-purpose and in scope with standards.\n"}
