{"id": "21397748", "url": "https://en.wikipedia.org/wiki?curid=21397748", "title": "ACube Systems Srl", "text": "ACube Systems Srl\n\nACube Systems Srl is a company that started in January 2007 from the synergy of the Italian companies Alternative Holding Group Srl, Soft3 and Virtual Works.\n\nThe three companies have been engaged in the areas of sale, distribution and engineering of hardware and software for mainstream systems and alternative platforms for years. They have joined their efforts in the realization of the Sam440ep platform. Then ongoing dispute over ownership of AmigaOS cast doubts about actual release of AmigaOS 4 for this new hardware, support for Sam440ep was later introduced in AmigaOS 4.1. Since November 2007 Acube Systems distributed AmigaOS 4.0 for Amiga computers with PowerPC CPU cards on behalf of Hyperion Entertainment.\nThey also built the very first Amiga redesign in hardware: the Minimig.\n\nIn September 2011, Acube Systems introduced AmigaOne 500 based on Sam460ex mainboard.\n"}
{"id": "21782967", "url": "https://en.wikipedia.org/wiki?curid=21782967", "title": "AMAX Information Technologies", "text": "AMAX Information Technologies\n\nAMAX Engineering Corporation is a privately held technology company based in Fremont, California. Founded in 1979, AMAX specializes in application-tailored Cloud, Data Center, Deep Learning, open architecture platforms, HPC and OEM solutions.\n\nAMAX was founded in 1979, in Fremont, California, part of the Silicon Valley in the United States. The company has offices in California USA, Texas USA, Suzhou China, Shanghai China, and Shannon, Ireland.\n\nAMAX designs and engineers customized platforms for data centers, cloud, big data, high-performance parallel computing and server-to-rack level OEM appliances.\nIt offers prototyping and a manufacturing process, including custom branding of bezels, faceplates, chassis, and custom box packaging.\n\n2016\n\nAMAX announced its product lines were upgraded with the Intel Xeon processor E5-2600 V4 family.\n\nAMAX launched [SMART] DC Data Center Manager, the premier out-of-band DCIM solution for high-efficiency data center.\n\nAMAX joined Intel Technology Provider Program as HPC Data Center Specialist.\n\nAMAX released its GPU Solutions and HPC Clusters, integrated with NVIDIA Tesla P100 GPU accelerator for PCIe, powered by the new NVIDIA Pascal architecture.\n\nAMAX announced its configure-to-order (CTO) service for security ISVs and startups.\n\n2015\n\nAMAX announced at IP EXPO 2015 show a deskside Deep Learning Engine from its Deep Learning product line.\n\n2014\n\nAMAX introduced the ServMax Open CloudServer (OCS) data center product based on the Microsoft Open Cloud Server version 2 specifications.\n\nAMAX announced at Supercomputing 2014(SC14) show the ClusterMax GPU cluster and ServMax GPU server platforms with NVIDIA Tesla K80 GPU accelerator board.\n\nAMAX introduced a line of computing products the Intel Xeon processor E5-2600 V3 product family.\n\nAMAX announced the CloudMax converged infrastructure product for data centers, based on OpenStack, featuring computing, networking and storage components. CloudMax was awarded the Intel Server Innovation Award at the Intel Solution Summit 2014, and Best of VMworld 2014 for Private Cloud at VMworld 2014.\n\n2013\n\nAMAX became a provider for the Open Compute Project initiated by Facebook.\n\n2012\n\nAMAX introduced a line of network-attached storage (NAS) appliances compatible with Microsoft Windows Storage Server 2012, and was listed as a Microsoft Gold Certified Partner to provide these storage systems in North America.\n\nAMAX announced a cluster product based on Apache Hadoop named the PHAT-Data (Peta-scale Hadoop Analytics Technology), and was awarded gold as the Best New Product of the Year in Hardware from the Stevie Awards. In a subsequent collaboration with Mellanox, STec, Inc. and Zettaset, AMAX added PHAT-Data 40G to the PHAT-Data Hadoop cluster product line which would be a performance-oriented Hadoop cluster featuring SSDs and 40G networking.\n\n2011\n\nAMAX announced the AMAX CloudMax private cloud appliance developed for businesses.\n\n2008\n\nIn 2008, AMAX introduced a line of high performance computing products based on the Nvidia Tesla Personal Supercomputer, with GPU technology. The systems were configured with Nvidia Tesla C1060/C2050/C2070/C2075 cards. Other servers and cluster platforms available are configured with the Nvidia Tesla M2075/M2090/K10/K20/K40.\n\n"}
{"id": "739588", "url": "https://en.wikipedia.org/wiki?curid=739588", "title": "Adaptive system", "text": "Adaptive system\n\nAn adaptive system is a set of interacting or interdependent entities, real or abstract, forming an integrated whole that together are able to respond to environmental changes or changes in the interacting parts, in a way analogous to either continuous physiological homeostasis or evolutionary adaptation in biology. Feedback loops represent a key feature of adaptive systems, such as ecosystems and individual organisms; or in the human world, communities, organizations, and families.\n\nArtificial adaptive systems include robots with control systems that utilize negative feedback to maintain desired states.\n\nThe law of adaptation can be stated informally as: \nFormally, the law can be defined as follows:\n\nGiven a system formula_1, we say that a physical event formula_2 is a stimulus for the system formula_1 if and only if the probability formula_4 that the system suffers a change or be perturbed (in its elements or in its processes) when the event formula_2 occurs is strictly greater than the prior probability that formula_1 suffers a change independently of formula_2:\n\n\"Let formula_1 be an arbitrary system subject to changes in time formula_10 and let formula_2 be an arbitrary event that is a stimulus for the system formula_1: we say that formula_1 is an adaptive system if and only if when t tends to infinity formula_14 the probability that the system formula_1 change its behavior formula_16 in a time step formula_17 given the event formula_2 is equal to the probability that the system change its behavior independently of the occurrence of the event formula_2. In mathematical terms:\"\n\n\nThus, for each instant formula_10 will exist a temporal interval formula_23 such that:\n\nIn an adaptive system, a parameter changes slowly and has no preferred value. In a self-adjusting system though, the parameter value “depends on the history of the system dynamics”. One of the most important qualities of \"self-adjusting systems\" is its “adaptation to the edge of chaos” or ability to avoid chaos. Practically speaking, by heading to the edge of chaos without going further, a leader may act spontaneously yet without disaster. A March/April 2009 Complexity article further explains the self-adjusting systems used and the realistic implications. Physicists have shown that adaptation to the edge of chaos occurs in almost all systems with feedback.\n\n\"Practopoiesis,\" a term due to its originator Danko Nikolić, is a reference to a kind of adaptive or self-adjusting system in which autopoiesis of an \"organism\" or a \"cell\" occurs through allopoietic interactions among its \"components\". The components are organized into a poietic hierarchy: one component creates another. The theory proposes that living systems exhibit a hierarchy of four such poietic operations in total:\n\nPractopoiesis challenges current neuroscience doctrine by asserting that mental operations primarily occur at the anapoietic level (iii) — i.e., that minds emerge from fast homeostatic (adaptive) mechanisms. This contrasts the widespread belief that thinking is synonymous with neural activity ('cell function' at level iv). \n\nEach lower level contains knowledge that is more general than the higher level; for example, genes contain more general knowledge than anapoietic mechanisms, which in turn contain more general knowledge than cell functions. This hierarchy of knowledge enables the anapoietic level to directly store concepts, which are necessary for the emergence of mind.\n\n"}
{"id": "4959339", "url": "https://en.wikipedia.org/wiki?curid=4959339", "title": "Anti-flash white", "text": "Anti-flash white\n\nAnti-flash white is a brilliant white colour commonly seen on British, Soviet, and U.S. nuclear bombers. The purpose of the colour was to reflect some of the thermal radiation from a nuclear explosion, protecting the aircraft and its occupants.\n\nSome variants of the Xian H-6 had the underside of the fuselage painted anti-flash white.\n\nSome nuclear bombers had the underside of the fuselage painted anti-flash white with the upper surfaces painted light silver-gray. This was true for the specially fitted, single Soviet Tu-95V bomber that test-deployed the most powerful bomb of any kind – the 50+ MT-rating \"Tsar Bomba\" on October 30, 1961 – as it had the anti-flash white on all its undersurfaces and sides. The Tupolev Tu-160 of the 1980s was the first series-built Soviet/Russian bomber aircraft to be painted anti-flash white all over, leading to its \"Beliy Lebed\" (\"White Swan\") Russian nickname.\n\nAnti-flash white was used on the Royal Air Force V bombers force and the Royal Navy Blackburn Buccaneer when used in the nuclear strike role. Nuclear bombers were given – though not at first, until the problem was considered – salmon pink and baby blue roundels and fin flash rather than the traditional dark red, white and blue.\n\nAnti-flash white was applied to several prototype aircraft, including the British Aircraft Corporation TSR-2. Paint used on the Avro Vulcan was manufactured by \"Cellon\", and that on the Handley Page Victor by Titanine Ltd.\n\nMany Strategic Air Command nuclear bombers carried anti-flash white without insignia on the underside of the fuselage with light silver-gray or natural metal (later light camouflage) on the upper surfaces.\n\nThe United States Navy A-5 Vigilante carried anti-flash white without insignia on the underside of the fuselage.\n\nThe Boeing E-6 in TACAMO role was painted anti-flash white but its roundels were not subdued.\n\nIn addition to these military aircraft, Concorde was painted white to reduce the additional heating effect on the aluminium skin caused by the sun whilst the aircraft was flying at high altitudes, the skin temperature already being raised to over at Mach 2 by aerodynamic heating.\n\nAircraft with at least part of the fuselage painted anti-flash white on nuclear delivery variants:\n\n\n\n\n"}
{"id": "24201048", "url": "https://en.wikipedia.org/wiki?curid=24201048", "title": "Aspirator (medical device)", "text": "Aspirator (medical device)\n\nA medical aspirator is a suction machine used to remove mucus, blood, and other bodily fluids from a patient. They can be used during surgical procedures but an operating theater is generally equipped with a central system of vacuum tubes. Most aspirators are therefore portable, for use in ambulances and nursing homes, and can run on AC/DC or battery power. They consist of a vacuum pump, a\nvacuum regulator and gauge, a collection canister, and sometimes a\nbacterial filter. Plastic tubing is used to continuously draw fluid into the collection canister.\n\nIn the past manually operated aspirators were used such as \"Potain's aspirator\". \n"}
{"id": "6146906", "url": "https://en.wikipedia.org/wiki?curid=6146906", "title": "Bias tee", "text": "Bias tee\n\nA bias tee is a three-port network used for setting the DC bias point of some electronic components without disturbing other components. The bias tee is a diplexer. The low-frequency port is used to set the bias; the high-frequency port passes the radio-frequency signals but blocks the biasing levels; the combined port connects to the device, which sees both the bias and RF. It is called a \"tee\" because the 3 ports are often arranged in the shape of a T.\n\nConceptually, the bias tee can be viewed as an ideal capacitor that allows AC through but blocks the DC bias and an ideal inductor that blocks AC but allows DC. Although some bias tees can be made with a simple inductor and capacitor, wideband bias tees are considerably more complicated because practical components have parasitic elements.\n\nBias tees are designed for transmission-line environments. Typically, the characteristic impedance \"Z\" will be 50 ohms or 75 ohms. The impedance of the capacitor (\"X\") is chosen to be much less than \"Z\", and the impedance of the inductor (\"X\") is chosen to be much greater than \"Z\":\n\nwhere \"ω\" is the angular frequency (in radians per second) and \"f\" is the frequency (in hertz).\n\nBias tees are designed to operate over a range of signal frequencies. The reactances are chosen to have minimal impact at the lowest frequency.\n\nFor wide-range bias tees, the inductor must be large at the lowest frequency. A large inductor will have a stray capacitance (which creates its self-resonant frequency). At a high enough frequency, the stray capacitance presents a low-impedance shunt path for the signal, and the bias tee becomes ineffective. Practical wide-band bias tees must use circuit topologies that avoid the shunt path. Instead of one inductor, there will be a series string of inductors. In addition, there will be additional resistors and capacitors to prevent resonances. For example, a Picosecond Pulse Labs model 5580 bias tee works from 10 kHz to 15 GHz. Consequently, the simple design would need an inductance of at least 800 μH (\"X\" about \"j\"50 ohms at 10 kHz), and that inductor must still look like an inductor at 15 GHz. However, a commercial 820 μH inductor has a self-resonant frequency of only 1.8 MHz – four orders of magnitude too low.\n\nJohnson gives an example of a wideband microstrip bias tee covering 50 kHz to 1 GHz using four inductors (330 nH, 910 nH, 18 µH, and 470 µH) in series. His design cribbed from a commercial bias tee. He modeled parasitic element values, simulated results, and optimized component selection. To show the advantage of additional components, Johnson provided a simulation of a bias tee that used just inductors and capacitors without \"Q\" suppression. Johnson provides both simulated and actual performance details. Girardi duplicated and improved on Johnson's design and points out some additional construction issues.\n\nA bias tee is used to insert DC power into an AC signal to power remote antenna amplifiers or other devices. It is usually positioned at the receiving end of the coaxial cable to pass DC power from an external source to the coaxial cable running to powered device. A bias “T” consists of a feed inductor to deliver DC to a connector on the device side and a blocking capacitor to keep DC from passing through to the receiver. The RF signal is connected directly from one connector to the other with only the blocking capacitor in series. The internal blocking diode prevents damage to the bias “T” if reverse supply voltage is applied.\n\nBias tees are used in a variety of applications, but are generally used to provide an RF signal and (DC) power to a remote device where running two separate cables would not be advantageous. Biasing is often used with photodiodes (vacuum and solid state), Microchannel plate detectors, transistors, and triodes, so that high frequencies from the signal do not leak into a common power supply rail. Conversely, noise from the power supply does not appear on the signal line. Other examples include: Power over Ethernet, active antennas, low-noise amplifiers, and down converters.\n\nThe telephone line for plain old telephone service and some early microphones use a bias tee circuit—often with a gyrator replacing the inductor—this enables a thin cable with only 2 conductors to send power from the system to the device, and send audio from the device back to the system.\nModern microphones often use 3 conductors in a phantom power circuit very similar to a bias tee circuit.\n\nThere are several bias tee designs.\n\nThe construction of the horizontal bar of the T is based on the rigid coaxial cable with air as dielectric. The radius is chosen to be as large as possible without allowing higher modes.\nThe design of a bias \"T\" is based upon power going out to the remote device, but not being seen by the base station or receiver. It does this by using a capacitor on the RF output terminal, effectively creating an open circuit for the DC current. The incoming RF signal, or the one from the antenna, is the output for the DC power. This front-end of a bias \"T\" typically consists of a bandpass filter, a low noise amplifier, and a mixer coupled to a local oscillator.\n\nAt one point a small slice is cut out of the center conductor, therefore a capacitor is formed and low frequencies are blocked. This kind of capacitor has the advantage that it is nearly invisible to higher frequencies. To pass frequencies down to 1 MHz the capacitance has to be increased. A dielectric like NPO multiplies the capacitance by a factor of 65. The thickness of the capacitor has to be minimal without leading to electric breakdown in the dielectric, this means to avoid any peaks in the electric field and this means smooth electrodes with rounded edges and a dielectric protruding between the electrodes (doorknob design). A stack of capacitors can be used, but every capacitor needs access to the surface of the inner conductor, because if it's hidden behind another capacitor the high frequencies won't see it, because the electric field needs a lot of time to travel through a dielectric with a high dielectric constant\n\nA small coil made of fine wire with an air core or MnFeZn-core connects the inner conductor of one of the sides of the capacitor with the a port in the outer conductor leading down the T. Frequencies above 1 GHz hit the coil from the side and apply an equal electric field to the whole coil. Therefore, no higher modes are excited within the coil. Because of the inductiveness of the coil almost no current leaks from the center conductor to the port. Frequencies between 1 MHz and 1 GHz do leak into this port, so there is a second coil with a cone shaped core outside of the outer conductor, but inside of a housing to avoid interference with other components. This cone acts like a tapered transmission line transformer. It starts with a high impedance, so a lot of power will be reflected, but the rest will travel down the coil and there is some leakage into the low frequency port.\n\nAny oscillations in the capacitor or the coil or the composed LC circuit are damped by the dielectric and the core. Also the small coil should have about 10 ohm resistance to further damp oscillations and avoid ripple on the transmitted spectrum.\n\n\n\n"}
{"id": "57078395", "url": "https://en.wikipedia.org/wiki?curid=57078395", "title": "Bicycle (film)", "text": "Bicycle (film)\n\nBicycle is a 2014 documentary film about the history and culture of the bicycle in Great Britain. Written and directed by Michael B. Clifford, the film features conversations with numerous historians, designers, Olympic athletes, and youth.\n\n"}
{"id": "13522458", "url": "https://en.wikipedia.org/wiki?curid=13522458", "title": "British telephone socket", "text": "British telephone socket\n\nBritish telephone sockets were introduced in their current plug and socket form on 19 November 1981 by British Telecom to allow subscribers to connect their own telephones. The connectors are specified in British Standard BS 6312. Electrical characteristics of the telephone interface are specified by individual network operators, e.g. in British Telecom's SIN 351. Electrical characteristics required of British telephones used to be specified in BS 6305.\n\nThey are similar to modular connectors (as used in RJ11), but feature a side-mounted hook, rather than a bottom-mounted one, and are physically incompatible.\n\nStandard sockets were introduced, as part of the 'New Plan' wiring policy, to allow customers to easily purchase their own telephones, as required by Oftel, the phone regulator. Thus any phone whose plug conformed to BS 6312 and met certain other regulatory standards, such as BABT, could be connected to the network, rather than British Telecom controlling the market. The 'New Plan' was only new to the UK and was based extensively on systems which had been available elsewhere for many years, especially in the US.\n\nThe new system replaced the older hard-wired system, which came in many 'flavours' (e.g., Plans 1, 1A, 1B, 1C, 2, 2A, 105, 107 etc.), which could be very complicated and required the attendance at the premises of a GPO telephone-engineer, who needed a complete set of 'N' (wiring) Diagrams, which was very extensive and ran to over 15 volumes of little black ring binders. N diagrams also had their own numbering system (e.g., a Plan 1A had an N diagram of N4502), and were frequently updated.\n\nFrom the early years of the 1900s, the GPO (subsequently British Telecom) had a plug and socket system available for rent. It was later called a \"Plan 4\" (N762—first edition), and employed a heavy-duty, four-way jack plug 404 (circular in cross-section), on the end of the standard, plaited, cotton-covered instrument cord. It also had to have a separate bell-set, which was permanently in-circuit to provide ringing if there were no telephones plugged in. This system survived through various models of telephones from the \"candlestick\" 200 and 300 type bakelite phones until the introduction of the 700 series in 1959, when a smaller \"Plug 420\" was introduced. The separate bell-set, with its on-board capacitor and coils, also provided a testing circuit for remote engineers, by providing the mandatory 1000 ohm capacitive loop-back. Rental had to be paid on each telephone and on all the sockets, and hence the system was not that common.\n\nA domestic single British telephone line installation will have a single master socket or line box in the premises, which is provided by BT or another service provider: this socket is the demarcation point between the customer-owned and maintained on-premises wiring, and the telephone network. For installations using the NTE5 line box (NTE for network termination equipment), the demarcation point is actually \"within\" the socket: the lower half of the front plate and associated wiring is the customer's, while the permanent wiring on the non-removable section behind this, remains the responsibility of the service provider. Customers are not permitted to access the wiring in a master socket without a removable lower section. Plug-in extension kits are available for customers with this type of installation. The two wires from the exchange are denoted the \"B\" leg at −48V relative to ground when the line is not in use and the \"A\" leg which is near ground potential when the line is not in use. The \"A\" leg goes to pin 5 and the \"B\" leg to pin 2 in the master socket. (Although all equipment will work with a reversed line, so a reverse wired socket is not strictly a fault.) When current is flowing on the line, the \"B\" leg voltage collapses to nearer ground and the \"A\" leg voltage moves nearer to the \"B\" leg voltage. The exact voltage drop is a function of the distance to the exchange, and the network wiring type.\n\nUntil recently, this socket contained an enclosed spark gap, SP1, that could safely flash over internally to provide high voltage surge protection. This component is no longer used due to negative effects on VDSL speeds. The socket includes a 1.8 µF capacitor (bell circuit) to feed the AC ringing and a 470 kΩ resistor (R1, out-of-service resistor) to permit remote testing when no telephones are plugged into any sockets. Additional internal extension (secondary) sockets are wired off the master socket (connected in parallel using the IDC system) but not containing the surge protector, bell circuit capacitor, and the out-of-service resistor.\n\nThe 'old style' fixed master socket had only one set of terminals on the back and customers were supposed to use extension kits plugged into the front socket; however, many customers hard-wired their own extensions anyway for neatness and robustness reasons, which was a poor arrangement since it provided no way to isolate the customer's internal extension wiring from BT's wiring.\n\nThe BT NTE 5 Linebox Socket allows easy disconnection of the internal wiring by removing the two screws and sliding out the bottom half of the socket.\n\nIn recent years NTE5 sockets have been fitted in place of master sockets. These have a front plate where the lower half is removable so allowing customer's access to the terminals required for connecting internal extension sockets; it also provides access to a test jack, to determine if line faults are due to the customer's wiring or BT's. The removable panel also allows the external telephone line to be easily disconnected from the internal wiring, provided the wiring of the premises has been correctly carried out. The terminals on the back part used to be large screw terminals; however, all BT NTE5 sockets now use insulation-displacement connectors (IDCs).\n\nNow that BT does not have a monopoly of internal wiring, they make a substantial charge if a fault reported to them turns out to be in the customer's internal/domestic wiring. It is therefore important for the customer to have the facility to check whether any problem or fault is in their internal wiring/equipment or externally in BT's cabling or systems. Since the NTE5 socket represents the official demarcation point between the internal/domestic wiring (at the removable front of the socket which is the customer's responsibility) and the external telephone line/cabling fixed at the rear (which is BT's responsibility) the physical disconnection of the two sets of wires (made possible by the NTE5's removable front plate) is crucial in identifying faults and allocating responsibility for their rectification.\n\nIn 2009, BT Introduced a vDSL service to the UK known as BT Infinity and at the same time introduced the BT vDSL Interstitial Faceplate, which performs two functions: DSL filter and Bell Wire noise suppression. The vDSL modem now plugs directly into the 6P6C modular socket on the faceplate. The faceplate can be easily fitted by removing the two bottom screws on a NTE5, sliding the bottom section out and fitting this in between. The result is that the entire extension circuit is filtered by the vDSL plate meaning that there is now no need for DSL filters on every Telephone Socket in the house. This product can also be fitted to ADSL lines and has been shown to improve connection speeds for vDSL and aDSL customers alike.\n\nThere are two types of modern British Telecom plugs in common use for connecting telephones, the 431A and 631A.\n\n431A is 4-way and 631A 6-way. There are also plugs with only two contacts commonly seen on modem leads. These are a recent introduction and do not seem to be easily available as separate parts. All fit any right-handed \"Type 600\" telephone socket.\n\nType 430A and 630A plugs have the latch on the opposite (left hand) side of the plug, and were used as headset plugs on some switchboards and as handset connectors on some telephones, e.g. Ambassador.\n\nThe 631A and 630A plugs are also used for connecting sensors to interfaces for computer based measurements in educational environments, the former for connecting analogue sensors and the latter for digital sensors. Companies using these plugs include Vernier, TI and Casio, for interfaces connecting to their graphical calculators, and in the Netherlands CMA.\n\nThe BS 6312 specification defines the terminal numbering of a socket-outlet in the opposite direction to the pin numbers of the socket. Thus terminal 1 is connected to pin 6, terminal 2 to pin 5 and so on. The pins of the 631A plug are numbered in ascending order from left to right with the contacts facing upwards and the latch on the right hand side.\n\nThe connector on the phone is not standardized: the connector at the wall is standardized by regulation, to allow individuals to use their own phones (interconnection), but the wire from the phone to the wall may be hard-wired to the phone, or use various connectors.\n\nTypically it will have a 6P4C or 6P2C modular connector at the telephone end: this latter may be wired as per the RJ11 standard (with pins 3 and 4), or it may be wired with pins 2 and 5, as a straight through cable from the BT plug (which uses pins 2 and 5 for the line, unlike RJ11, which uses pins 3 and 4). Thus cables are not in general compatible between different phones, as the phone base may have a socket with pins 2 and 5 (requiring a straight through cable), or have an RJ11 socket (requiring a crossover cable).\n\nThe BS 6312 jack has been used in New Zealand since the 1980s, replacing a number of other connectors and hard-wired connections, and was subsequently replaced by a \"2-wire\" version suited to daisy chain wiring that eliminated the 3rd ringing voltage wire. The \"BT Jack\" is still the most common phone jack in use, although many installations in business use structured cabling with \"RJ45\" 8P8C modular connectors for telephone as well as data services. Since 2010 the Telecommunications Carriers Forum Premises Wiring Code of Practice has deprecated BT jacks in favour of \"RJ45\" modular jacks for all new residential and SOHO phone/data networks, although not yet a mandatory standard in 2016.\n\nIt is also used in Bahrain, Bangladesh, Belize, Botswana, Brunei, Cyprus, Eritrea, the Falkland Islands, Ghana, Gibraltar, Israel, Jordan, Kenya, Kuwait, Lesotho, Malawi, Malta, Myanmar (Burma), Nigeria, Oman, Qatar, Saudi Arabia, Swaziland, Tanzania, the United Arab Emirates, Zambia, and Zimbabwe. The jack is still found in Hong Kong, where new installations ceased in 1998, while in Saint Vincent and the Grenadines, new installations ceased in 2001, with RJ11 now used instead.\n\n<BR>\nWhile BS 6312 was not adopted in the Republic of Ireland, Irish phone jacks have some similarity to their UK cousins due to GPO influences in the old Irish wiring systems. Ireland's P&T adopted Bell System style 6P6C sockets and 6P4C \"RJ11\" plugs in the late 1970, several years earlier than BS 6312 was rolled out by BT in the UK. Irish phone sockets are normally wired, as per the international standard, with the line carried on the centre pair (pin 3 and 4). Although it is rarely connected, Irish phone jacks also contain a ringing capacitor circuit very similar to their UK counterparts. This is carried on pin 5. Or, if wired for two-line service (rare), a second ring wire is carried on pin 2 for line 2, with the outer pair, pins 1 and 6 carrying the second line. \nThis arrangement was introduced for the same reason as the capacitor in BS 6313; to allow backwards compatibility with older GPO style type 3 wire phones that lacked an anti-tinkle circuit, which were common in the 1970s and into the 1980s. Modern Irish jacks also contain screw down lugs to connect extension phone wiring or a hardwired pre 1970s phone. The connection block has an “R” terminal for connecting the ringing wire to the capacitor. Despite the circuitry being available in the jack, UK phones should still be connected with an adapter with its own ringing capacitor, as the “R” wire typically is no longer connected in most homes, unless the wiring was originally used with rotary dial telephones.\n\nAs previously mentioned the actual connections are made using Insulation-displacement connectors (IDC). A punch down tool is required to do this and two sorts are available. One is of plastic construction and only intended for occasional use. The other is a professional tool used by installers, which is a spring loaded push down tool that both inserts the wire and trims it in one action : an example is shown in the photograph. It also comes with a tool for removing wires from sockets. From Q3 2016, Openreach started using a new, \"toolless\" version of the demarcation socket—the \"NTE5C\"—which does not require an IDC tool to make the connections. \nShown below are the cabling arrangements for both 4-wire and 6-wire cable. Initially 4-wire was used and many older installations still use it, then the 6-wire became the new standard, but the 4-wire has latterly been reissued to all Openreach technicians as part of cost savings. Modern 4-wire however is the same diameter as 6-wire to allow technicians to retain existing tacking guns and cable clips. Note that the wires in the 6-wire cable are coloured with two colours in a ratio of four to one in length, with the first colour mentioned being the predominant one, e.g. if the indicated colour of the wire is W-B then the wire will be coloured white for 12 mm, then blue for 3 mm and so on. (In other words, it looks like a white wire with blue patches on it.)\n\nStrictly speaking, a textbook installation will only actually use pins 2, 5 (for the voice) and 3 (for the ringer). Having said this, most modern telephones no longer require a ringing capacitor may have and 2-wire connections, which means that extension wiring can usually be run with only pins 2 and 5. Often where multi-core cable is used, the remaining cables are used for wiring extensions on additional incoming telephone lines.\n\nIn order to use Broadband Internet services simultaneously with voice telephony, it is necessary to use a DSL filter. This is a low pass filter in line with the phone outlet. This prevents high frequency data noise from affecting the lower frequency voice bandwidth and it also prevents the low impedance of the connected phone from attenuating or modulating the high speed DSL data Path. Enough bandwidth is retained for voice telephony and the majority is used for high speed data. \n\nAll phones (or other voice band devices) must be connected via a filter (either a separate filter for each phone or one filter covering multiple phones) to avoid interference between the phones and the DSL signal. If the data transmission is still audible, using two DSL filters, daisychained in series, should eliminate the problem. The RJ11 female port provided on the filter case simply connects the DSL router directly to the phone line (most DSL filters have a socket marked DSL or ADSL that just connects the DSL line pair directly through to the incoming phone line pair via the BT plug, without any filtering or processing of any kind). The ringer wire is unnecessary in unfiltered parts of the wiring and its removal can often improve performance and reliability of the broadband service. This is due to the unbalancing effect that the ringer wire (on long extensions) can have on the matched twisted pair. Thus reducing the signal to noise ratio and also the high frequency response of the subscriber line.\n\nWhen ADSL was first introduced in the UK it was installed by a technician who replaced the front part of the NTE5 (if the property still had an old style master socket it would be replaced with an NTE5) with one containing a filter. Any hardwired phone extensions were disconnected from the original front part and connected to filtered terminals on the back of the filter. The DSL modem (which at the time was also BT supplied) and, if present, a phone or plug-in extension, could then be plugged into the front. If it was desired to locate the DSL modem away from the master socket a plug-in ADSL extension kit could be purchased.\n\nBT also offered \"wires-only\" ADSL service and promoted the technique of using a separate plug-in filter on every socket. While both technically inferior and far less tidy than the solution BT engineers had used, it was usually adequate and was simple enough for a non-technical householder to understand. The more discerning customer can purchase a variety of hardwired filtering products, including replacement front plates for the NTE5, some of which have unfiltered as well as filtered terminals on the back to avoid the need to plug in the extension wiring that leads to the DSL modem.\n\nIn 2008 BT trialled and launched their 'IPlate'; the \"I\" is for interstitial, as it is fitted between the socket and the front panel. This plate is fitted by the consumer inside the NTE 5 and reduces interference carried by the 3rd (bell) wire. The reduced interference allows faster broadband speeds - BT claim a speed improvement of up to 1.5 Mbit/s with a theoretical 4 Mbit/s. By November 2009 BT were calling the I-plate a \"BT Broadband Accelerator\".\n\nStructured cabling systems are general-purpose communications wires installed in offices and increasingly also homes, which can be used for several different communication technologies (analog phone, ADSL, ISDN, Ethernet, video, etc.). The most common type uses Category 5 cables (four twisted pairs with 100 ohm impedance) between 8P8C (colloquially and incorrectly called RJ45) room sockets and a central patch panel.\n\nThe A and B wires of an analogue phone line appear in a structured cabling system usually on the centre pins of the 8P8C connector (pins 4 and 5; the blue/white TIA/EIA-568 pair 1 in Cat5 cables). In most other countries, those two wires are all that is needed to connect an analogue telephone. In the UK, however, many telephones expect the 25 Hz ring signal on a third wire. But such a 3-wire interface is not the symmetric interface needed for balanced twisted-pair transmission lines, and therefore prone to electromagnetic interference and crosstalk with nearby other wiring. Therefore, the capacitor that separates the bell signal from the A/B wires should be located close to the telephone. Any bell wire provided by the master socket is therefore not connected to the structured cabling, and the telephone is plugged at the other end into the structured cabling via a \"line adapter unit\" (LAU) / \"Mod-Tap\" / Molex that contains the capacitor needed to create the separate bell signal. Different types of LAUs are on the market:\n\n\nThere exists no well-established standard in which polarity pins 2 and 5 of the phone socket are connected to pins 4 and 5 of the 8P8C connector; both alternatives are common. This polarity is not normally important; BT does specify that the B wire is more negative than the A, though they no longer specify which of the A and B wires are connected to pins 2 and 5 of their master telephone socket, although earlier standards specified that the A wire be connected to 5 and the B wire to 2.\n\n\n\n"}
{"id": "254533", "url": "https://en.wikipedia.org/wiki?curid=254533", "title": "Cathodic protection", "text": "Cathodic protection\n\nCathodic protection (CP) is a technique used to control the corrosion of a metal surface by making it the cathode of an electrochemical cell. A simple method of protection connects the metal to be protected to a more easily corroded \"sacrificial metal\" to act as the anode. The sacrificial metal then corrodes instead of the protected metal. For structures such as long pipelines, where passive galvanic cathodic protection is not adequate, an external DC electrical power source is used to provide sufficient current.\n\nCathodic protection systems protect a wide range of metallic structures in various environments. Common applications are: steel water or fuel pipelines and steel storage tanks such as home water heaters; steel pier piles; ship and boat hulls; offshore oil platforms and onshore oil well casings; offshore wind farm foundations and metal reinforcement bars in concrete buildings and structures. Another common application is in galvanized steel, in which a sacrificial coating of zinc on steel parts protects them from rust.\n\nCathodic protection can, in some cases, prevent stress corrosion cracking.\n\nCathodic protection was first described by Sir Humphry Davy in a series of papers presented to the Royal Society in London in 1824. The first application was to in 1824. Sacrificial anodes made from iron attached to the copper sheath of the hull below the waterline dramatically reduced the corrosion rate of the copper. However, a side effect of cathodic protection was the increase in marine growth. Usually, copper when corroding releases copper ions which have an anti-fouling effect. Since excess marine growth affected the performance of the ship, the Royal Navy decided that it was better to allow the copper to corrode and have the benefit of reduced marine growth, so cathodic protection was not used further.\n\nDavy was assisted in his experiments by his pupil Michael Faraday, who continued his research after Davy's death. In 1834, Faraday discovered the quantitative connection between corrosion weight loss and electric current and thus laid the foundation for the future application of cathodic protection.\n\nThomas Edison experimented with impressed current cathodic protection on ships in 1890, but was unsuccessful due to the lack of a suitable current source and anode materials. It would be 100 years after Davy's experiment before cathodic protection was used widely on oil pipelines in the United States cathodic protection was applied to steel gas pipelines beginning in 1928 and more widely in the 1930s.\n\nIn the application of \"passive\" cathodic protection, a \"galvanic anode\", a piece of a more electrochemically \"active\" metal, is attached to the vulnerable metal surface where it is exposed to an electrolyte. Galvanic anodes are selected because they have a more \"active\" voltage (more negative electrode potential) than the metal of the target structure (typically steel). \n\nConcrete has a pH around 13. In this environment the steel reinforcement has a passive protective layer and remains largely stable. Galvanic systems are \"constant potential\" systems that aim to restore the concrete's natural protective environment by providing a high initial current to restore passivity. It then reverts to a lower sacrificial current while harmful negative Chloride ions migrate away from the steel and towards the positive anode. The anodes remain reactive through their lifetime (10-20 years typically) increasing current when the resistivity decreases due to corrosion hazards such as rainfall, temperature increases or flooding. The reactive nature of these anodes makes them an efficient choice.\n\nUnlike ICCP systems steel constant polarization is not the goal, rather the restoration of the environment. Polarization of the target structure is caused by the electron flow from the anode to the cathode, so the two metals must have a good electrically conductive contact. The driving force for the cathodic protection current is the difference in electrode potential between the anode and the cathode. During the initial phase of high current, the potential of the steel surface is polarized (pushed) more negative protecting the steel which hydroxide ion generation at the steel surface and ionic migration restore the concrete environment. \n\nOver time the galvanic anode continues to corrode, consuming the anode material until eventually it must be replaced.<br> \n\nGalvanic or sacrificial anodes are made in various shapes and sizes using alloys of zinc, magnesium and aluminium. ASTM International publishes standards on the composition and manufacturing of galvanic anodes.\n\nIn order for galvanic cathodic protection to work, the anode must possess a lower (that is, more negative) electrode potential than that of the cathode (the target structure to be protected). The table below shows a simplified galvanic series which is used to select the anode metal. The anode must be chosen from a material that is lower on the list than the material to be protected.\n\nIn some cases, \"impressed current cathodic protection\" (ICCP) systems are used. These consist of anodes connected to a DC power source, often a transformer-rectifier connected to AC power. In the absence of an AC supply, alternative power sources may be used, such as solar panels, wind power or gas powered thermoelectric generators.\n\nAnodes for ICCP systems are available in a variety of shapes and sizes. Common anodes are tubular and solid rod shapes or continuous ribbons of various materials. These include high silicon cast iron, graphite, mixed metal oxide, platinum and niobium coated wire and other materials.\n\nFor pipelines, anodes are arranged in groundbeds either distributed or in a deep vertical hole depending on several design and field condition factors including current distribution requirements.\n\nCathodic protection transformer-rectifier units are often custom manufactured and equipped with a variety of features, including remote monitoring and control, integral current interrupters and various type of electrical enclosures. The output DC negative terminal is connected to the structure to be protected by the cathodic protection system. The rectifier output DC positive cable is connected to the anodes. The AC power cable is connected to the rectifier input terminals.\n\nThe output of the ICCP system should be optimised to provide enough current to provide protection to the target structure. Some cathodic protection transformer-rectifier units are designed with taps on the transformer windings and jumper terminals to select the voltage output of the ICCP system. Cathodic protection transformer-rectifier units for water tanks and used in other applications are made with solid state circuits to automatically adjust the operating voltage to maintain the optimum current output or structure-to-electrolyte potential. Analog or digital meters are often installed to show the operating voltage (DC and sometime AC) and current output. For shore structures and other large complex target structures, ICCP system are often designed with multiple independent zones of anodes with separate cathodic protection transformer-rectifier circuits.\n\nHybrid systems have been used for over a decade and incorporate the coordination, monitoring and high restorative current flow of ICCP systems with the reactive, lower cost and easier to maintain galvanic anodes.\n\nThe system is made up of wired galvanic anodes in arrays typically 400mm apart which are then initially powered for a short period to restore the concrete and power ionic migration. The power supply is then taken away and the anodes simply attached to the steel as a galvanic system. More powered phases can be administered if needed. Like Galvanic systems corrosion rate monitoring from polarisation tests and half-cell potential mapping can be used to measure corrosion. Polarization is not the goal for the life of the system.\n\nHazardous product pipelines are routinely protected by a coating supplemented with cathodic protection. An impressed current cathodic protection system (ICCP) for a pipeline consists of a DC power source, often an AC powered transformer rectifier and an anode, or array of anodes buried in the ground (the anode groundbed).\n\nThe DC power source would typically have a DC output of up to 50 amperes and 50 volts, but this depends on several factors, such as the size of the pipeline and coating quality. The positive DC output terminal would be connected via cables to the anode array, while another cable would connect the negative terminal of the rectifier to the pipeline, preferably through junction boxes to allow measurements to be taken.\n\nAnodes can be installed in a groundbed consisting of a vertical hole backfilled with conductive coke (a material that improves the performance and life of the anodes) or laid in a prepared trench, surrounded by conductive coke and backfilled. The choice of groundbed type and size depends on the application, location and soil resistivity.\n\nThe DC cathodic protection current is then adjusted to the optimum level after conducting various tests including measurements of pipe-to-soil potentials or electrode potential.\n\nIt is sometimes more economically viable to protect a pipeline using galvanic (sacrificial) anodes. This is often the case on smaller diameter pipelines of limited length. Galvanic anodes rely on the galvanic series potentials of the metals to drive cathodic protection current from the anode to the structure being protected.\n\nWater pipelines of various pipe materials are also provided with cathodic protection where owners determine the cost is reasonable for the expected pipeline service life extension attributed to the application of cathodic protection.\n\nCathodic protection on ships is often implemented by galvanic anodes attached to the hull and ICCP for larger vessels. Since ships are regularly removed from the water for inspections and maintenance, it is a simple task to replace the galvanic anodes.\n\nGalvanic anodes are generally shaped to reduced drag in the water and fitted flush to the hull to also try to minimize drag.\n\nSmaller vessels, with non-metallic hulls, such as yachts, are equipped with galvanic anodes to protect areas such as outboard motors. As with all galvanic cathodic protection, this application relies on a solid electrical connection between the anode and the item to be protected.\n\nFor ICCP on ships, the anodes are usually constructed of a relatively inert material such as platinised titanium. A DC power supply is provided within the ship and the anodes mounted on the outside of the hull. The anode cables are introduced into the ship via a compression seal fitting and routed to the DC power source. The negative cable from the power supply is simply attached to the hull to complete the circuit. Ship ICCP anodes are flush-mounted, minimizing the effects of drag on the ship, and located a minimum 5 ft below the light load line in an area to avoid mechanical damage. The current density required for protection is a function of velocity and considered when selecting the current capacity and location of anode placement on the hull.\n\nSome ships may require specialist treatment, for example aluminium hulls with steel fixtures will create an electrochemical cell where the aluminium hull can act as a galvanic anode and corrosion is enhanced. In cases like this, aluminium or zinc galvanic anodes can be used to offset the potential difference between the aluminium hull and the steel fixture. If the steel fixtures are large, several galvanic anodes may be required, or even a small ICCP system.\n\nMarine cathodic protection covers many areas, jetties, harbours, offshore structures. The variety of different types of structure leads to a variety of systems to provide protection. Galvanic anodes are favored, but ICCP can also often be used. Because of the wide variety of structure geometry, composition, and architecture, specialized firms are often required to engineer structure-specific cathodic protection systems. Sometimes marine structures require retroactive modification to be effectively protected \n\nThe application to concrete reinforcement is slightly different in that the anodes and reference electrodes are usually embedded in the concrete at the time of construction when the concrete is being poured. The usual technique for concrete buildings, bridges and similar structures is to use ICCP, but there are systems available that use the principle of galvanic cathodic protection as well, although in the UK at least, the use of galvanic anodes for atmospherically exposed reinforced concrete structures is considered experimental.\n\nFor ICCP, the principle is the same as any other ICCP system. However, in a typical atmospherically exposed concrete structure such as a bridge, there will be many more anodes distributed through the structure as opposed to an array of anodes as used on a pipeline. This makes for a more complicated system and usually an automatically controlled DC power source is used, possibly with an option for remote monitoring and operation. For buried or submerged structures, the treatment is similar to that of any other buried or submerged structure.\n\nGalvanic systems offer the advantage of being easier to retrofit and do not need any control systems as ICCP does.\n\nFor pipelines constructed from pre-stressed concrete cylinder pipe (PCCP), the techniques used for cathodic protection are generally as for steel pipelines except that the applied potential must be limited to prevent damage to the prestressing wire.\n\nThe steel wire in a PCCP pipeline is stressed to the point that any corrosion of the wire can result in failure. An additional problem is that any excessive hydrogen ions as a result of an excessively negative potential can cause hydrogen embrittlement of the wire, also resulting in failure. The failure of too many wires will result in catastrophic failure of the PCCP. To implement ICCP therefore requires very careful control to ensure satisfactory protection. A simpler option is to use galvanic anodes, which are self-limiting and need no control.\n\nVessels, pipelines and tanks which are used to store or transport liquids can also be protected from corrosion on their internal surfaces by the use of cathodic protection. ICCP and galvanic systems can be used. A common application of internal cathodic protection is water storage tanks and power plant shell and tube heat exchangers.\n\nGalvanizing generally refers to hot-dip galvanizing which is a way of coating steel with a layer of metallic zinc or tin. Galvanized coatings are quite durable in most environments because they combine the barrier properties of a coating with some of the benefits of cathodic protection. If the zinc coating is scratched or otherwise locally damaged and steel is exposed, the surrounding areas of zinc coating form a galvanic cell with the exposed steel and protect it from corrosion. This is a form of localized cathodic protection - the zinc acts as a sacrificial anode.\n\nGalvanizing, while using the electrochemical principle of cathodic protection, is not actually cathodic protection. Cathodic protection requires the anode to be separate from the metal surface to be protected, with an ionic connection through the electrolyte and an electron connection through a connecting cable, bolt or similar. This means that any area of the protected structure within the electrolyte can be protected, whereas in the case of galvanizing, only areas very close to the zinc are protected. Hence, a larger area of bare steel would only be protected around the edges.\n\nSeveral companies market electronic devices claiming to mitigate corrosion for automobiles and trucks. Corrosion control professionals find they do not work. There is no peer reviewed scientific testing and validation supporting the use of the devices. In 1996 the FTC ordered David McCready, a person that sold devices claiming to protect cars from corrosion, to pay restitution and banned the names \"Rust Buster\" and \"Rust Evader.\" \n\nElectrode potential is measured with reference electrodes. Copper-copper sulphate electrodes are used for structures in contact with soil or fresh water. Silver/silver chloride/seawater electrodes or pure zinc electrodes are used for seawater applications. The methods are described in EN 13509:2003 and NACE TM0497 along with the sources of error in the voltage that appears on the display of the meter. Interpretation of electrode potential measurements to determine the potential at the interface between the anode of the corrosion cell and the electrolyte requires training and cannot be expected to match the accuracy of measurements done in laboratory work.\n\nA side effect of improperly applied cathodic protection is the production of atomic hydrogen, leading to its absorption in the protected metal and subsequent hydrogen embrittlement of welds and materials with high hardness. Under normal conditions, the atomic hydrogen will combine at the metal surface to create hydrogen gas, which cannot penetrate the metal. Hydrogen atoms, however, are small enough to pass through the crystalline steel structure, and lead in some cases to hydrogen embrittlement.\n\nThis is a process of disbondment of protective coatings from the protected structure (cathode) due to the formation of hydrogen ions over the surface of the protected material (cathode). Disbonding can be exacerbated by an increase in alkali ions and an increase in cathodic polarization. The degree of disbonding is also reliant on the type of coating, with some coatings affected more than others. Cathodic protection systems should be operated so that the structure does not become excessively polarized, since this also promotes disbonding due to excessively negative potentials. Cathodic disbonding occurs rapidly in pipelines that contain hot fluids because the process is accelerated by heat flow.\n\nEffectiveness of cathodic protection (CP) systems on steel pipelines can be impaired by the use of solid film backed dielectric coatings such as polyethylene tapes, shrinkable pipeline sleeves, and factory applied single or multiple solid film coatings. This phenomenon occurs because of the high electrical resistivity of these film backings. Protective electric current from the cathodic protection system is blocked or shielded from reaching the underlying metal by the highly resistive film backing. Cathodic shielding was first defined in the 1980s as being a problem, and technical papers on the subject have been regularly published since then.\n\nA 1999 report concerning a spill from a Saskatchewan crude oil line contains an excellent definition of the cathodic shielding problem:\n\nCathodic shielding is referenced in a number of the standards listed below. Newly issued USDOT regulation Title 49 CFR 192.112, in the section for \"Additional design requirements for steel pipe using alternative maximum allowable operating pressure\" requires that \"The pipe must be protected against external corrosion by a non-shielding coating\" (see coatings section on standard). Also, the NACE SP0169:2007 standard defines shielding in section 2, cautions against the use of materials that create electrical shielding in section 4.2.3, cautions against use of external coatings that create electrical shielding in section 5.1.2.3, and instructs readers to take 'appropriate action' when the effects of electrical shielding of cathodic protection current are detected on an operating pipeline in section 10.9.\n\n\n\n"}
{"id": "2104830", "url": "https://en.wikipedia.org/wiki?curid=2104830", "title": "Cursor (user interface)", "text": "Cursor (user interface)\n\nIn computer user interfaces, a cursor is an indicator used to show the current position for user interaction on a computer monitor or other display device that will respond to input from a text input or pointing device. The mouse cursor is also called a pointer, owing to its resemblance in usage to a pointing stick.\n\nCursor is Latin for 'runner.' A cursor is the name given to the transparent slide engraved with a hairline that is used for marking a point on a slide rule. The term was then transferred to computers through analogy.\n\nIn most command-line interfaces or text editors, the text cursor, also known as a caret, is an underscore, a solid rectangle, or a vertical line, which may be flashing or steady, indicating where text will be placed when entered (the insertion point). In text mode displays, it was not possible to show a vertical bar between characters to show where the new text would be inserted, so an underscore or block cursor was used instead. In situations where a block was used, the block was usually created by inverting the pixels of the character using the boolean math exclusive or function. On text editors and word processors of modern design on bitmapped displays, the vertical bar is typically used instead.\n\nIn a typical text editing application, the cursor can be moved by pressing various keys. These include the four arrow keys, the Page Up and Page Down keys, the Home key, the End key, and various key combinations involving a modifier key such as the Control key. The position of the cursor also may be changed by moving the mouse pointer to a different location in the document and clicking.\n\nThe blinking of the text cursor is usually temporarily suspended when it is being moved; otherwise, the cursor may change position when it is not visible, making its location difficult to follow.\n\nSome interfaces use an underscore or thin vertical bar to indicate that the user is in insert mode, a mode where text will be inserted in the middle of the existing text, and a larger block to indicate that the user is in overtype mode, where inserted text will overwrite existing text. In this way, a block cursor may be seen as a piece of selected text one character wide, since typing will replace the text \"in\" the cursor with the new text.\n\nA vertical line text cursor with a small left-pointing or right-pointing appendage are for indicating the direction of text flow on systems that support bi-directional text, and is thus usually known among programmers as a 'bidi cursor'. In some cases, the cursor may split into two parts, each indicating where left-to-right and right-to-left text would be inserted.\n\nThe pointer or mouse cursor echoes movements of the pointing device, commonly a mouse, touchpad or trackball.\nThis kind of cursor is used to manipulate elements of graphical user interfaces such as menus, buttons, scrollbars or any other widget. It may be called a \"mouse pointer,\" because the mouse is the dominant type of pointing device used with desktop computers.\n\nThe I-beam pointer (also called the I-cursor) is a cursor shaped like a serifed capital letter \"I\". The purpose of this cursor is to indicate that the text beneath the cursor can be highlighted, and sometimes inserted or changed.\n\nThe idea of a cursor being used as a marker or insertion point for new data or transformations, such as rotation, can be extended to a 3D modeling environment. Blender, for instance, uses a 3D cursor to determine where future operations are to take place.\n\n\n"}
{"id": "55507546", "url": "https://en.wikipedia.org/wiki?curid=55507546", "title": "Cybertonica", "text": "Cybertonica\n\nCybertonica is a FinTech company which detects and prevents fraudulent transactions and reduces risk for financial services organisations. The company uses machine learning and artificial intelligence (AI) to analyse data in real-time and help secure online transactions by identifying who is a fraudster and who is a good customer.\n\nCybertonica was named as the \"Best New Back Office Innovation\" at the tenth annual Emerging Payments Awards in 2017 with its fraud management solution designed to grow e-commerce and m-commerce businesses and build their customers’ trust.\n\nCybertonica is founded in 2015 and headquartered in London, United Kingdom. Founding members include Joshua Bower-Saul, Sergey Velts and Victor Orlovsky. In 2015, the company participated in startup accelerator programme, Startupbootcamp FinTech.\n\nIn 2016, Tech.London, which is supported by Mayor of London to promote London’s technology and entrepreneurship scene, announced Cybertonica as winner of \"Startup to Watch October 2016\".\n\nIn 2017, Cybertonica was selected as one of the \"European FinTech 100\" companies. In addition, New York-based research outfit CB Insights identified Cybertonica among more than 80 firms using AI to secure the future.\n\nCybertonica is backed by Digital Space Ventures, which is an investment company supporting early stage FinTech businesses, and other international investors.\n"}
{"id": "13774593", "url": "https://en.wikipedia.org/wiki?curid=13774593", "title": "Differential capacitance", "text": "Differential capacitance\n\nDifferential capacitance in physics, electronics, and electrochemistry is a measure of the voltage-dependent capacitance of a nonlinear capacitor, such as an electrical double layer or a semiconductor diode. It is defined as the derivative of charge with respect to potential.\n\nIn electrochemistry differential capacitance is a parameter introduced for characterizing electrical double layers:\n\nwhere σ is surface charge and ψ is electric surface potential\nCapacitance is usually defined as the stored charge between two conducting surfaces separated by a dielectric divided by the voltage between the surfaces.  Another definition is the rate of change of the stored charge or surface charge (σ) divided by the rate of change of the voltage between the surfaces or the electric surface potential (ψ).  The latter is called the \"differential capacitance,\" but usually the stored charge is directly proportional to the voltage, making the capacitances given by the two definitions equal.\n\nThis type of differential capacitance may be called \"parallel plate capacitance,\" after the usual form of the capacitor.  However, the term is meaningful when applied to any two conducting bodies such as spheres, and not necessarily ones of the same size, for example, the elevated terminals of a Tesla wireless system and the earth.  These are widely spaced insulated conducting bodies positioned over a spherically conducting ground plane.\n\n\"The differential capacitance between the spheres is obtained by assuming opposite charges ±q on them. . . .\" \n\nAnother form of differential capacitance refers to single isolated conducting bodies. It is usually discussed in books under the topic of \"electrostatics.\"  This capacitance is best defined as the rate of change of charge stored in the body divided by the rate of change of the potential of the body.  The definition of the absolute potential of the body depends on what is selected as a reference.  This is sometimes referred to as the \"self-capacitance\" of a body.  If the body is a conducting sphere, the self-capacitance is proportional to its radius, and is roughly 1pF per centimetre of radius.\n\n\n"}
{"id": "46296429", "url": "https://en.wikipedia.org/wiki?curid=46296429", "title": "Energy (journal)", "text": "Energy (journal)\n\nEnergy is a peer-reviewed academic journal covering research on energy engineering that was established in 1976. It is published by Elsevier and the editor-in-chief is Henrik Lund (Aalborg University). According to the \"Journal Citation Reports\", the journal has a 2013 impact factor of 4.159, ranking it 13th out of 83 journals in the category \"Energy & Fuels\" and second out of 55 journals in \"Thermodynamics\".\n\n"}
{"id": "34422219", "url": "https://en.wikipedia.org/wiki?curid=34422219", "title": "Eurasia Drilling Company Limited", "text": "Eurasia Drilling Company Limited\n\nEurasia Drilling Company Limited is a Publicly Traded retail company in Russia. Eurasia Drilling Company is Offshore & Onshore oil drilling services company.\n\nIn December 2004, Eurasia Drilling was formed after acquisition of onshore drilling business of LUKOIL. In 2006, Eurasia Drilling entered into offshore drilling business as well acquiring the offshore drilling business of LUKOIL.\n\nThe company is listed in the London Stock Exchange.\n"}
{"id": "243718", "url": "https://en.wikipedia.org/wiki?curid=243718", "title": "Flashlight", "text": "Flashlight\n\nA flashlight (more often called a torch outside North America) is a portable hand-held electric light. The source of the light is usually an incandescent light bulb (lamp) or light-emitting diode (LED). A typical flashlight consists of the light source mounted in a reflector, a transparent cover (sometimes combined with a lens) to protect the light source and reflector, a battery, and a switch. These are supported and protected by a case.\n\nThe invention of the dry cell and miniature incandescent electric lamps made the first battery-powered flashlights possible around 1899. Today, flashlights use mostly incandescent lamps or light-emitting diodes and run on disposable or rechargeable batteries. Some are powered by the user turning a crank or shaking the lamp, and some have solar panels to recharge a battery.\n\nIn addition to the general-purpose hand-held flashlight, many forms have been adapted for special uses. Head or helmet-mounted flashlights designed for miners and campers leave the hands free. Some flashlights can be used underwater or in flammable atmospheres. Flashlights are used as a light source when in a place with no power or during power outages.\n\nEarly flashlights ran on zinc-carbon batteries, which could not provide a steady electric current and required periodic \"rest\" to continue functioning. Because these early flashlights also used energy-inefficient carbon-filament bulbs, \"resting\" occurred at short intervals. Consequently, they could be used only in brief flashes, hence the common North American name \"flashlight\".\n\nThe first dry cell battery was invented in 1887. Unlike previous batteries, it used a paste electrolyte instead of a liquid. This was the first battery suitable for portable electrical devices, as it did not spill or break easily and worked in any orientation. The first mass-produced dry cell batteries came in 1896, and the invention of portable electric lights soon followed. Portable hand-held electric lights offered advantages in convenience and safety over (combustion) torches, candles and lanterns. The electric lamp was odorless, smokeless, and emitted less heat than combustion-powered lighting. It could be instantly turned on and off, and avoided fire risk.\n\nOn January 10, 1899, British inventor David Misell obtained U.S. Patent No. 617,592, assigned to American Electrical Novelty and Manufacturing Company. This \"electric device\" designed by Misell was powered by \"D\" batteries laid front to back in a paper tube with the light bulb and a rough brass reflector at the end. The company donated some of these devices to the New York City police, who responded favorably to them.\n\nCarbon-filament bulbs and fairly crude dry cells made early flashlights an expensive novelty with low sales and low manufacturer interest. Development of the tungsten-filament lamp in 1904, with three times the efficacy of carbon filament types, and improved batteries, made flashlights more useful and popular. The advantage of instant control, and the absence of flame, meant that hand-held electric lights began to replace combustion-based lamps such as the hurricane lantern. By 1922 several types were available; the tubular hand-held variety, a lantern style that could be set down for extended use, pocket-size lamps for close work, and large reflector searchlight-type lamps for lighting distant objects. In 1922 there were an estimated 10 million flashlight users in the United States, with annual sales of renewal batteries and flashlights at $20 million, comparable to sales of many line-operated electrical appliances. Flashlights became very popular in China; by the end of the 1930s, 60 companies made flashlights, some selling for as little as one-third the cost of equivalent imported models. Miniature lamps developed for flashlight and automotive uses became an important sector of the incandescent lamp manufacturing business.\n\nIncandescent flashlights use incandescent light bulbs which consists of a glass bulb and a tungsten filament. The bulbs are under vacuum or filled with argon, krypton or xenon. Some high-power incandescent flashlights use a halogen lamp where the bulb contains a halogen gas such as iodine or bromine to improve the life and efficacy of the bulb. In all but disposable or novelty flashlights, the bulb is user-replaceable; the bulb life may be only a few hours.\n\nThe light output of an incandescent lamp in a flashlight varies widely depending on the type of lamp. A miniature keychain lamp produces one or two lumens. A two D-cell flashlight using a common prefocus-style miniature lamp will produce on the order of 15 to 20 lumens of light and a beam of about 200 candlepower. One popular make of rechargeable focusing flashlight uses a halogen lamp and produces 218 lumens. By comparison, a 60-watt household incandescent lamp will produce about 900 lumens. The luminous efficacy or lumens produced per watt of input of flashlight bulbs varies over the approximate range of 8 to 22 lumens/watt, depending on the size of the bulb and the fill gas, with halogen-filled 12 volt lamps having the highest efficacy.\n\nPowerful white-light-emitting diodes (LED)s are increasingly replacing incandescent bulbs in practical flashlights. LEDs existed for decades, mainly as low-power indicator lights. In 1999, Lumileds Corporation of San Jose, California, introduced the Luxeon LED, a high-power white-light emitter. This made possible LED flashlights with power and running time better than incandescent lights. The first Luxeon LED flashlight was the Arc LS, designed in 2001. White LEDs in 5 mm diameter packages produce only a few lumens each; many units may be grouped together to provide additional light. LEDs, drawing more than 100 milliamperes each, simplify the optical design problem of producing a powerful and tightly-controlled beam.\n\nLEDs can be significantly more efficient than incandescent lamps, with white LEDs producing on the order of 100 lumens for every watt, compared to 8-10 lumens per watt of small incandescent bulbs. An LED flashlight will have a longer battery life than an incandescent flashlight with comparable output. LEDs are also less fragile than glass lamps. LED lamps have different spectra of light compared to incandescent sources, and are made in several ranges of color temperature and color rendering index. Since the LED has a long life compared to the usual life of a flashlight, very often it is permanently installed.\n\nLEDs generally must have some kind of control to limit current through the diode. Flashlights using one or two disposable 1.5 volt cells require a boost converter to provide the higher voltage required by a white LED, which need around 3.4 volts to function. Flashlights using three or more dry cells may only use a resistor to limit current. Some flashlights electronically regulate the current through the LEDs to stabilize light output as the batteries discharge. LEDs maintain nearly constant color temperature regardless of input voltage or current, while the color temperature of an incandescent bulb rapidly declines as the battery discharges, becoming redder and less visible. Regulated LED flashlights may also have user-selectable levels of output appropriate to a task, for example, low light for reading a map and high output for checking a road sign. This would be difficult to do with a single incandescent bulb since efficacy of the lamp drops rapidly at low output.\n\nLED flashlights may consume 1 watt or much more from the battery, producing heat as well as light. In contrast to tungsten filaments, which must be hot to produce light, both the light output and the life of an LED decrease with temperature. Heat dissipation for the LED often dictates that small high-power LED flashlights have aluminium or other high heat conductivity bodies, reflectors and other parts, to dissipate heat; they can become warm during use.\n\nLight output from LED flashlights varies even more widely than for incandescent lights. \"Keychain\" type lamps operating on button batteries, or lights using a single 5 mm LED, may only produce a couple of lumens. Even a small LED flashlight operating on an AA cell but equipped with a LED can emit 100 lumens. The most powerful LED flashlights produce more than 32,000 lumens and may use multiple LEDs.\n\nLEDs are highly efficient at producing colored light compared with incandescent lamps and filters. An LED flashlight may contain different LEDs for white and colored light, selectable by the user for different purposes. Colored LED flashlights are used for signalling, special inspection tasks, forensic examination, or to track the blood trail of wounded game animals. A flashlight may have a red LED intended to preserve dark adaptation of vision. Ultraviolet LEDs may be used for inspection lights, for example, detecting fluorescent dyes added to air conditioning systems to detect leakage, examining paper currency, or checking UV-fluorescing marks on laundry or event ticket holders. Infrared LEDs can be used for illuminators for night vision systems. LED flashlights may be specified to be compatible with night vision devices.\nA less common type of flashlight uses a High Intensity Discharge (HID) lamp as the light source. An HID gas discharge lamp uses a mixture of metal halide salts and argon as a filler. HID lamps produce more light than an incandescent flashlight using the same amount of electricity. The lamp will last longer and is more shock resistant than a regular incandescent bulb, since it lacks the relatively fragile electrical filament found in incandescent bulbs. However, they are much more expensive, due to the ballast circuit required to start and operate the lamp. An HID lamp requires a short warm-up time before it reaches full output.\nA typical HID flashlight would have a 35 watt lamp and produce more than 3,000 lumens.\n\nCertain accessories for a flashlight allow the color of the light to be altered or allow light to be dispersed differently. Translucent colored plastic cones slipped over the lens of a flashlight increase the visibility when looking at the side of the light. Such marshalling wands are frequently used for directing automobiles or aircraft at night. Colored lenses placed over the end of the flashlight are used for signalling, for example, in railway yards. Colored light is occasionally useful for hunters tracking wounded game after dusk, or for forensic examination of an area. A red filter helps preserve night vision after the flashlight is turned off, and can be useful to observe animals (such as nesting Loggerhead sea turtles) without disturbing them. \n\nDetachable light guides, consisting of rigid bent plastic rods or semi-rigid or flexible tubes containing optical fibers, are available for some flashlights for inspection inside tanks, or within walls or structures; when not required the light guide can be removed and the light used for other purposes.\n\nA penlight is a small, pen-sized flashlight, often containing two AA batteries or AAA batteries. In some types the incandescent light bulb has an integral lens that focuses the light, so no reflector is built into the penlight. Others use incandescent bulbs mounted in reflectors. LED penlights are becoming increasingly common. Low-cost units may be disposable with no provision to replace batteries or bulbs, and are sometimes imprinted with advertising for promotional purposes.\n\nA headlamp is designed to be worn on the head, often having separate lamp and battery components. The battery pack may be attached at the back of the head or in a pocket to improve balance. Headlamps leave the user's hands free. A headlamp can be clipped to the brim of a hat, or built to mount on a hard hat, instead of using straps; other types resemble eyeglass frames. Similar to the headlamp, an angle-head flashlight emits light perpendicular to the length of the battery tube; it can be clipped to a headband, belt, or webbing or set on a flat surface. Some types allow the user to adjust the angle of the head. The Fulton MX991/U Flashlight was an angle-head flashlight issued to US military personnel; similar style lights remain popular.\n\nTactical lights are sometimes mounted to a handgun or rifle. They allow momentary illumination of a target. They are small enough to be easily rail-mounted to a gun barrel. Tactical lights must withstand the impact of recoil, and must be easily controlled while holding the weapon.\n\nAlthough most flashlights are designed for user replacement of the batteries and the bulb as needed, fully sealed disposable flashlights, such as inexpensive keyring lights, are made. When the batteries are depleted or the bulb fails, the entire product is discarded.\n\nDiving lamps must be watertight under pressure and are used for night diving and supplemental illumination where surface light cannot reach. The battery compartment of a dive lamp may have a catalyst to recombine any hydrogen gas emitted from the battery, since gas cannot be vented in use.\n\nPeople working in hazardous areas with significant concentrations of flammable gases or dusts, such as mines, engine rooms of ships, chemical plants or grain elevators, use \"non-incendive\", \"intrinsically safe\" or \"explosion proof\" flashlights constructed so that any spark in the flashlight is not likely to set off an explosion outside the light. The flashlight may require approval by an authority for the particular service and particular gases or dusts expected. The external temperature rise of the flashlight must not exceed the autoignition point of the gas, so substitution of more powerful lamps or batteries may void the approval.\n\nInspection flashlights have permanently mounted light guides containing optical fibers or plastic rods. Another style has a lamp mounted at the end of a flexible cable, or a semi-rigid or articulated probe. Such lamps are used for inspection inside tanks, or inside structures such as aircraft. Where used for inspecting the interior of tanks containing flammable liquids, the inspection lights may also be rated as flame-proof (explosion-proof) so that they cannot ignite liquids or vapors.\n\nOtoscopes and ophthalmoscopes are medical instruments that combine a hand-held light source and magnifying lenses for examination of the ear canal and eyes, respectively.\n\nAboard naval ships, battle lanterns may be used as emergency portable lighting. Installed in major compartments of the ship, a battle lantern can be detached from its mounting and used as portable lighting in the event primary lighting is out of service. Battle lanterns may use either incandescent or LED lamps, and may have either disposable primary or rechargeable batteries. \n\nMany flashlights are cylindrical in design, with the lamp assembly attached to one end. However, early designs came in a variety of other shapes. Some resembled candlesticks, with a bulb mounted at the top of a battery tube fixed to a flat base, with a handle. Many resembled lanterns, consisting of a battery box with a handle and the lamp and reflector attached to the front. Electric lanterns are used for lighting the broad area immediately around the lantern, as opposed to forming a narrow beam; they can be set down on a level surface or attached to supports. Some electric lanterns use miniature fluorescent lamps for higher efficacy than incandescent bulbs. Portable hand-held electric spotlights can provide larger reflectors and lamps, and more powerful batteries than tubular flashlights meant to fit in a pocket.\n\nMultifunction portable devices may include a flashlight as one of their features; for example, a portable radio/flashlight combination. Many smartphones have a button or software application available to turn up their screen backlights to full intensity, or to switch on the camera flash or video light, providing a \"flashlight\" function.\n\nAs well as utilitarian flashlights, novelty, toy and ornamental portable electric lights have been made in a myriad of shapes; in the 1890s, one of the earliest portable battery light applications was a type of novelty porcelain tie pin with a concealed bulb and battery.\n\nThe most common power source for flashlights is the battery. Primary battery (disposable) types used in flashlights include button cells, carbon-zinc batteries in both regular and heavy duty types, alkaline, and lithium.\n\nSecondary, rechargeable, types include lead acid batteries, NiMH, NiCd batteries and lithium ion batteries. The choice of batteries will play a determining role in the size, weight, run time, and shape of the flashlight. Flashlight users may prefer a common battery type to simplify replacement.\n\nPrimary cells are most economical for infrequent use. Some types of lithium primary cell can be stored for years with less risk of leakage compared with zinc-type batteries. Long storage life is useful where flashlights are required only in emergencies. Lithium primary batteries are also useful at lower temperatures than zinc batteries, all of which have water-based electrolytes. Lithium primary batteries have a lower internal resistance than zinc primary batteries and so are more efficient in high-drain flashlights.\n\nFlashlights used for extended periods every day may be more economically operated on rechargeable (secondary) batteries. Flashlights designed for rechargeable batteries may allow charging without removing the batteries; for example, a light kept in a vehicle may be trickle-charged and always ready when needed. Some rechargeable flashlights have indicators for the state of charge of the battery. Power-failure lights are designed to keep their batteries charged from a wall plug and to automatically turn on after an AC power failure; the power-failure light can be removed from the wall socket and used as a portable flashlight. Solar powered flashlights use energy from a solar cell to charge an on-board battery for later use.\n\nOne type of mechanically powered flashlight has a winding crank and spring connected to a small electrical generator (dynamo). Some types use the dynamo to charge a capacitor or battery, while others only light while the dynamo is moving. Others generate electricity using electromagnetic induction. They use a strong permanent magnet that can freely slide up and down a tube, passing through a coil of wire as it does. Shaking the flashlight will charge a capacitor or a rechargeable battery that supplies current to a light source. Such flashlights can be useful during an emergency, when utility power and batteries may not be available. Dynamo-powered flashlights were popular during the Second World War since replacement batteries were difficult to find.\n\nAt least one manufacturer makes a rechargeable flashlight that uses a supercapacitor to store energy. The capacitor can be recharged more rapidly than a battery and can be recharged many times without loss of capacity; however, the running time is limited by the relative bulk of capacitors compared to electrochemical batteries.\n\nA reflector with an approximately parabolic shape concentrates the light emitted by the bulb into a directed beam. Some flashlights allow the user to adjust the relative position of the lamp and reflector, giving a variable-focus effect from a wide floodlight to a narrow beam. Reflectors may be made of polished metal, or glass or plastic with an aluminized reflective finish. Some manufacturers use a pebbled or \"orange peel\", instead of a smooth, reflector, to improve the uniformity of the light beam emitted. Where multiple LEDs are used, each one may be put in its own parabolic reflector. Flashlights using a \"total internal reflection\" assembly have a transparent optical element (light pipe) to guide light from the source into a beam; no reflector surface is required. For a given size of light source, a larger reflector or lens allows a tighter beam to be produced, while capturing the same fraction of the emitted light.\n\nThe reflector may have a flat transparent cover to keep out dirt and moisture, but some designs have a plastic or glass \"bulls-eye\" lens to form a concentrated beam. The lens or reflector cover must resist impacts and the heat of the lamp, and must not lose too much of the transmitted light to reflection or absorption. Very small flashlights may not have a reflector or lens separate from the lamp. Some types of penlight bulbs or small LEDs have a built-in lens.\n\nA reflector forms a narrow beam called the \"throw\", while light emitted forward misses the reflector and forms a wide flood or \"spill\" of light. Because LEDs emit most light in a hemisphere, lens lights with the LED facing forward or reflector lights with it facing backwards radiate less spill. Variable focus \"zoom\" or \"flood to throw\" lights may move the reflector or lens or they may move the emitter; moving the emitter presents the designer with the problem of maintaining heat dissipation for the LED.\n\nThe original 1890s flashlights used a metal ring around the fiber body of the flashlight as one contact of a switch, and the second contact was a movable metal loop that could be flipped down to touch the ring, completing the circuit. A wide variety of mechanical switch designs using slide switches, rocker switches, or side-mounted or end-mounted pushbuttons have been used in flashlights. A common combination is a slide switch that allows the light to be left on for an extended time, combined with a momentary button for intermittent use or signalling. (On earlier models, the button was a switch and the slider simply locked the button down.) Since voltages and currents are low, switch design is limited only by the available space and desired cost of production. Switches may be covered with a flexible rubber boot to exclude dirt and moisture. Another common type of switch relies on twisting the head of the light. Weapon-mounted lights may have remote switches for convenience in operation.\n\nElectronic controls allow the user to select variable output levels or different operating modes such as pre-programmed flashing beacon or strobe modes. Electronic controls may be operated by buttons, sliders, magnets, rotating heads, or rotating control rings. Some models of flashlight include an acceleration sensor to allow them to respond to shaking, or to select modes based on direction the light is held at switch on. At least one manufacturer allows user programming of the features of the flashlight through a USB port. An electronic control may also provide an indication of remaining battery capacity, or automatic step-down of brightness as the battery nears full discharge.\n\nEarly flashlights used vulcanized fiber or hard rubber tubes with metal end caps. Many other materials including drawn steel, plated brass, copper, silver, even wood and leather have been used. Modern flashlights are generally made of plastic or aluminum. Plastics range from low-cost polystyrene and polyethylene to more complex mixtures of ABS or glass-reinforced epoxies. Some manufacturers have proprietary plastic formulations for their products. A desirable plastic for manufacturing flashlights allows for ease of molding and adequate mechanical properties of the finished flashlight case. Aluminum, either plain, painted or anodized, is a popular choice. It is electrically conductive, can be easily machined, and dissipates heat well. Several standard alloys of aluminum are used. Other metals include copper, stainless steel, and titanium, which can be polished to provide a decorative finish. Zinc can be die-cast into intricate shapes. Magnesium and its alloys provide strength and heat dissipation similar to aluminum with less weight, but they corrode easily.\n\nMetals may be drawn into a tubular shape, or tubular extruded stock can be machined to add threads for the head and tail cap, knurling for grip, and decorative and functional flats or holes in the body. LED flashlights may have cooling fins machined into their metal cases. Plastics are often injection molded into nearly final shape, requiring only a few more process steps to complete assembly.\nMetal cases provide better heat dissipation for the LED, but plastics are not electrically conductive and may resist corrosion and wear.\n\nIndustrial, marine, public safety and military organizations develop specifications for flashlights in specialized roles. Typically, light output, overall dimensions, battery compatibility and durability are required to meet minimum limits. Flashlights may be tested for impact resistance, water and chemical resistance, and for the life span of the control switch.\n\nFlashlights intended for use in hazardous areas with flammable gas or dust are tested to ensure they cannot set off an explosion. Flashlights approved for flammable gas areas will have markings indicating the approving agency (MSHA, ATEX, UL etc.) and symbols for the conditions that were tested. Flashlights for hazardous areas may be designed to automatically disconnect the lamp if the bulb is broken, to prevent ignition of flammable gas.\n\nRegulations for ships and aircraft will specify the number and general properties of flashlights included as part of the standard safety equipment of the vessel. Flashlights for small boats may be required to be waterproof and to float. Uniformed services may issue particular models of flashlight, or may only provide minimum performance standards for the member to purchase his or her own flashlights.\n\nThe United States Army former standard MIL-F-3747E described the performance standard for plastic flashlights using two or three D cell dry batteries, in either straight or angle form, and in standard, explosion-proof, heat-resistant, traffic direction, and inspection types. The standard described only incandescent lamp flashlights and was withdrawn in 1996.\n\nIn the United States, ANSI in 2009 published \"FL1 Flashlight basic performance standard\". This voluntary standard defines test procedures and conditions for total light output, beam intensity, working distance, impact and water resistance, and battery running time to 10% of initial light output. The FL1 standard gives definitions for terms used in marketing flashlights, with the intention of allowing the consumer to compare products tested to the standard. The standard recommends particular graphic symbols and wording for the product package, so that the consumer can identify products tested to the standard. Testing may be carried out by the manufacturer itself or by a third-party test laboratory.\n\nThe FL1 standard requires measurements reported on the packaging to be made with the type of batteries packaged with the flashlight, or with an identified type of battery. Initial light output is measured with an integrating sphere photometer, 30 seconds after the light is switched on with fresh (or newly charged) batteries. The total light emitted is reported in lumens. Luminous intensity is determined by measuring the brightest spot in the beam produced by the flashlight, in candelas. Since this is a measure of all the light emitted in a solid angle (the \"cone\" of light in a particular direction), the beam intensity is independent of distance.\n\nThe working distance is defined as the distance at which the maximum light falling on a surface (illuminance) would fall to 0.25 lux. This is comparable to a full moon on a clear night. The distance is calculated from the square root of (the beam intensity in candelas divided by 0.25 lux); for example, a beam intensity of 1000 candelas produces a working range rating of the square root of (1000/0.25), or 63 meters. The result is reported in meters or feet. The working distance is from the point of view of the user of the flashlight. A light directly pointed at an observer may be visible against a dark background for many times this distance, especially if the observer has night-vision equipment.\n\nRun time is measured using the supplied or specified batteries and letting the light run until the intensity of the beam has dropped to 10% of the value 30 seconds after switching on. The standard does not evaluate the behavior of the flashlight output during run time. A regulated flashlight may run at only a slowly declining output and then abruptly cut off, but unregulated types may have steeply-declining light output after only a short time. Manufacturers of headlamps may use a different standard which rates run times until light output falls to 1 lux at 2 meters distance; this value is not comparable to the FL 1 runtime measurement.\n\nImpact resistance is measured by dropping the flashlight in six different orientations and observing that it still functions and has no large cracks or breaks in it; the height used in the test is reported. Water resistance, if specified, is evaluated after impact testing; no water is to be visible inside the unit and it must remain functional. Ratings are given in IP Code terms, where jet spray corresponds to IP X6, brief immersion to IPX7, 30 minutes immersion at 1 meter or more is IP X8; (the depth is reported if greater than 1 meter). An IP X8 rating by FL1 does not imply that the lamp is suitable for use as a diver's light since the test protocol examines function of the light only after immersion, not during immersion.\n\nThe consumer must decide how well the ANSI test conditions match their requirements, but all manufacturers testing to the FL1 standard can be compared on a uniform basis. The light measurements are more directly related to the use of flashlights than is the nominal power input to the lamp (watts), since different LED and incandescent lamp types vary widely in the amount of light produced per watt. Even the same LED or lamp in different optical systems will show different beam characteristics. The visibility of objects depends on many factors as well as the amount of light emitted by the flashlight.\n\nANSI standard FL1 does not specify measurements of the beam width angle but the candela intensity and total lumen ratings can be used by the consumer to assess the beam characteristics. Where two flashlights have similar total light (lumen) measures, the unit with the higher candela rating produces a more concentrated beam of light, suitable for lighting distant objects; it will also have a higher working distance. If two lights have similar candela ratings, the light with higher lumen value will produce a wider beam and will light a wider area overall. A beam width (containing most of the power of the beam, or \"hot spot\") of a few degrees corresponds to a spot light, useful for searching for distant objects; beam widths of 20 degrees or more are described as flood lights, suitable for lighting a wide nearby area. Typically even a flashlight beam with a small hot spot will have some light visible as \"spill\" around the spot.\n\n"}
{"id": "20275150", "url": "https://en.wikipedia.org/wiki?curid=20275150", "title": "Fotofinder", "text": "Fotofinder\n\nFotoFinder is a worldwide brand for medical imaging systems. The German company FotoFinder Systems GmbH was founded in 1991 and has developed imaging solutions for the early detection of melanoma and non-melanoma skin cancer as well as hair disorders diagnostics (TrichoLAB) and psoriasis assessment.\n\nFotoFinder methods for early skin cancer diagnosis:\n\n\nEach of the presented methods is a pillar in the early detection of skin cancer. In an overall view, the diagnostic accuracy will be improved with the use of special cameras, expert software and scientific-based analysis systems.\n\nExternal links\n"}
{"id": "31893908", "url": "https://en.wikipedia.org/wiki?curid=31893908", "title": "G.9963", "text": "G.9963\n\nRecommendation G.9963 is a home networking standard under development at the International Telecommunication Union standards sector, the ITU-T.\n\nIt was begun in 2010 by ITU-T to add multiple-input and multiple-output (known as MIMO) capabilities to the G.hn standard originally defined in Recommendation G.9960. The standard is also known as \"G.hn-mimo\".\n\nAs part of the family of G.hn standards, G.9963 was endorsed by the HomeGrid Forum.\n"}
{"id": "55943839", "url": "https://en.wikipedia.org/wiki?curid=55943839", "title": "GPS Block IIIF", "text": "GPS Block IIIF\n\nGPS Block IIIF, or GPS IIIF, is the second set of GPS III satellites, consisting of 22 space vehicles. The United States Air Force began the GPS Block IIIF acquisition effort in 2016, and awarded a 7.2 billion US dollar manufacturing contract for all 22 space vehicles to Lockheed Martin on September 14, 2018. The 22 satellites in Block IIIF are projected to delivered starting in 2026, with launches estimated to last through at least 2034.\n\nThe U.S. Air Force employed a two-phase competitive bid acquisition process for the GPS Block IIIF satellites.\n\nOn May 5, 2016, the U.S. Air Force awarded three Phase One Production Readiness Feasibility Assessment contracts for GPS III Space Vehicles (SV's) 11+, one each to Boeing Network and Space Systems, Lockheed Martin Space Systems Company, and Northrop Grumman Aerospace Systems. The phase one contracts were worth up to six million dollars each. During the phase one effort, both Boeing and Northrop Grumman successfully demonstrated working navigation payloads.\n\nOn April 19, 2017, the US Air Force Space Command announced the start of the second phase of its acquisition strategy with the publication of a special notice for an \"Industry Day\" for companies planning on bidding for the contract to manufacture GPS III vehicles 11+. During the Industry Day event, the Air Force shared the tentative acquisition strategy which it will use to evaluate proposals, then solicited feedback from potential bidders.\n\nIn July 2017, the Deputy Director of the U.S. Air Force GPS Directorate stated the acquisition strategy for GPS Block IIIF would be to award the manufacturing contracts for all 22 Block IIIF satellites to the same contractor.\n\nIn November 2017, the Deputy Director of the US Air Force's GPS Directorate announced the name of the second tranche of GPS III satellites was \"GPS Block IIIF.\"\n\nAlso in November 2017, it was announced that development of the fully digital navigation payload for GPS Block IIIF satellites had completed. The Block IIIA program schedule was delayed multiple times due to issues with the navigation payload.\n\nWhile the Air Force originally expected to publish the formal Request For Proposals (RFP) for GPS Block IIIF production in September 2017, it was not released until February 13, 2018. The RFP was for a firm-fixed price (FFP) contract for a single company to manufacture all 22 space vehicles. \n\nAll three participants from phase one (Boeing, Lockheed Martin, and Northrop Grumman) were believed to be likely to submit proposals.\n\nThe government held a pre-proposal conference in El Segundo, CA to be held on March 15, 2018 for potential bidders to ask the Air Force questions about the solicitation.\n\nThe submission deadline for proposals was 12:00pm Pacific Daylight Time on April 16, 2018.\n\nThe bid status of companies who participated in phase one, in alphabetical order:\n\n\nOn September 14, 2018, the Air Force awarded a $7.2 billion manufacturing contract to Lockheed Martin.\n\nProcurement funds for GPS Block IIIF satellite manufacturing will be allocated from the federal budget, starting with Fiscal Year 2018 (FY18).\n\nThe Air Force has identified four \"technology insertion points\" for GPS Block IIIF.\n\nThese four points are the only four times during the block's lifecycle where new capabilities will be allowed to be introduced to Block IIIF satellites.\n\n\n\n\n\nThe 22 GPS Block IIIF satellites are scheduled for launch between FY2025 and FY2034.\n\n"}
{"id": "23446427", "url": "https://en.wikipedia.org/wiki?curid=23446427", "title": "Gas combustion retort process", "text": "Gas combustion retort process\n\nThe gas combustion retort process (also referred as gas-combustion retorting process) was an above-ground retorting technology for shale oil extraction. It was a predecessor of the Paraho and Petrosix processes, and modern directly heated oil shale retorting technologies in general.\n\nThe gas combustion retort process was developed by the United States Bureau of Mines at the end of the 1940s. The first gas combustion retort, designed by Cameron Engineers, went into operation in 1949 and it was located in the United States Bureau of Mines' Oil Shale Experiment Station at Anvil Point in Rifle, Colorado. The Bureau of Mines tested this process in three retorts with capacity of 6, 10, and 25 ton of oil shale per day accordingly. The consortium of Mobil, Humble Oil, Continental Oil, Pan American Oil, Phillips Petroleum Company, and Sinclair Oil evaluated and improved this technology between 1964 and 1968.\n\nThe gas combustion retort process is classified as an internal combustion technology. For the oil shale pyrolysis it uses a vertical vessel retort.\n\nCrushed raw oil shale is fed into the top of the retort, and it moves downward by gravity. When moving downward, oil shale is heated by the rising recycled gases, which cause decomposition of the rock. Recycled gases enter the retort from the bottom. Gases are heated on the lower part of retort by descended spent shale. On their way up, gases move through the combustion zone, where air and dilution gases are injected causing combustion of gases and carbonaceous residue of spent shale (char). The heat from combustion brings the temperature in the retorting zone above of the burning zone to the necessary level for retorting. The incoming raw oil shale cool oil vapors and gases, which then leave the top of the retort as a mist.\n\nThe main advantage of this process was that it does not require cooling water, which made it suitable for using in the semi-arid regions.\n\n"}
{"id": "18823062", "url": "https://en.wikipedia.org/wiki?curid=18823062", "title": "GeoSmart", "text": "GeoSmart\n\nGeoSmart (NZ) Ltd is a provider of location-based services, digital mapping data and images for the Oceania area, notably New Zealand. The company is one of only a handful of global companies producing digital maps for use in GPS applications. \n\nCompanies such as TomTom and Navman, use mapping data from GeoSmart on their popular handheld GPS devices, as do motor manufacturers such as BMW. The company also provides mapping data via web services, with applications such as a website that allows users to send custom invitations that include mapping directions for guests as well as providing the mapping interface on New Zealand Automobile Association website.\n\nIn 2008, GeoSmart launched the RAPIDcV mapping car, which is an ongoing program to redrive all of New Zealand. This is to enhance the car navigation database used by brands including Navman, TomTom, Nav N Go, Siemens VDO and Horizon. The RAPIDcV (Road attributes, points of interest, imagery data capture vehicle) uses technology to capture the road centreline of all of New Zealand's roads to an accuracy of 0.15 metres. It does this with a number of technologies including inertial measurement unit (IMU) that uses gyroscopes and accelerometers. This technology compensates for situations where the traditional differential GPS accuracy is lost when the satellite signal is poor, such as behind volcanic hill shadows, dense forest canopies and high rise urban areas. It has a number of cameras on board capturing lane information, street signs, turn restrictions and points of interest to enhance and keep up to date GeoSmart's car navigation and web mapping products. It is also taking a 360 degree panoramic image every 50 metres. In order to support truck navigation as well as multi mode navigation it is collecting information on the incline and camber of each corner, a feature which is used for truck safety warnings in fleet management systems.\n\n\n"}
{"id": "50937678", "url": "https://en.wikipedia.org/wiki?curid=50937678", "title": "Glossary of electrical and electronics engineering", "text": "Glossary of electrical and electronics engineering\n\n\"Most of the terms listed in Wikipedia glossaries are already defined and explained within Wikipedia itself. However, glossaries like this one are useful for looking up, comparing and reviewing large numbers of terms together. You can help enhance this page by adding new terms or writing definitions for existing ones.\"\n\nThis glossary of electrical and electronics engineering pertains specifically to electrical and electronics engineering. For a broad overview of engineering, see glossary of engineering.\n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n"}
{"id": "29928760", "url": "https://en.wikipedia.org/wiki?curid=29928760", "title": "Highly accelerated stress audit", "text": "Highly accelerated stress audit\n\nHASA (highly accelerated stress audit) is a proven test method developed to find manufacturing/production process induced defects in electronics and electro-mechanical assemblies before those products are released to market. HASA is a form of HASS – a powerful testing tool for improving product reliability, reducing warranty costs and increasing customer satisfaction.\n\nSince HASS levels are more aggressive than conventional screening tools, a POS procedure is used to establish the effectiveness in revealing production induced defects. A POS is vital to determine that the HASS stresses are capable of revealing production defects, but not so extreme as to remove significant life from the test item. Instituting HASS to screen the product is an excellent tool to maintain a high level of robustness and it will reduce the test time required to screen a product resulting in long term savings. Ongoing HASS screening assures that any weak components or manufacturing process degradations are quickly detected and corrected. HASS is not intended to be a rigid process that has an endpoint. It is a dynamic process that may need modification or adjustment over the life of the product.\n\nHASS aids in the detection of early life failures. HASA's primary purpose is to monitor manufacturing and prevent any defects from being introduced during the process. A carefully determined HASA sampling plan must be designed that will quickly signal when process quality has been degraded.\n\n"}
{"id": "55125362", "url": "https://en.wikipedia.org/wiki?curid=55125362", "title": "Ice drilling", "text": "Ice drilling\n\nIce drilling allows scientists studying glaciers and ice sheets to gain access to what is beneath the ice, to take measurements along the interior of the ice, and to retrieve samples. Instruments can be placed in the drilled holes to record temperature, pressure, speed, direction of movement, and for other scientific research, such as neutrino detection.\n\nMany different methods have been used since 1840, when the first scientific ice drilling expedition attempted to drill through the Unteraargletscher in the Alps. Two early methods were percussion, in which the ice is fractured and pulverized, and rotary drilling, a method often used in mineral exploration for rock drilling. In the 1940s, thermal drills began to be used; these drills melt the ice by heating the drill. Drills that use jets of hot water or steam to bore through ice soon followed. A growing interest in ice cores, used for palaeoclimatological research, led to ice coring drills being developed in the 1950s and 1960s, and there are now many different coring drills in use. For obtaining ice cores from deep holes, most investigators use cable-suspended electromechanical drills, which use an armoured cable to carry electrical power to a mechanical drill at the bottom of the borehole.\n\nIn 1966, a US team successfully drilled through the Greenland ice sheet at Camp Century, at a depth of . Since then many other groups have succeeded in reaching bedrock through the two largest ice sheets, in Greenland and Antarctica. Recent projects have focused on finding drilling locations that will give scientists access to very old undisturbed ice at the bottom of the borehole, since an undisturbed stratigraphic sequence is required to accurately date the information obtained from the ice.\n\nThe first scientific ice drilling expeditions, led by Louis Agassiz from 1840 to 1842, had three goals: to prove that glaciers flowed, to measure the internal temperature of a glacier at different depths, and to measure the thickness of a glacier. Proof of glacier motion was achieved by placing stakes in holes drilled in a glacier and tracking their motion from the surrounding mountain. Drilling through glaciers to determine their thickness, and to test theories of glacier motion and structure, continued to be of interest for some time, but glacier thickness has been measured by seismographic techniques since the 1920s. Although it is no longer necessary to drill through a glacier to determine its thickness, scientists still drill shot holes in ice for these seismic studies. Temperature measurements continue to this day: modelling the behaviour of glaciers requires an understanding of their internal temperature, and in ice sheets, the borehole temperature at different depths can provide information about past climates. Other instruments may be lowered into the borehole, such as piezometers, to measure pressure within the ice, or cameras, to allow a visual review of the stratigraphy. IceCube, a large astrophysical project, required numerous optical sensors to be placed in holes 2.5 km deep, drilled at the South Pole.\n\nBorehole inclination, and the change in inclination over time, can be measured in a cased hole, a hole in which a hollow pipe has been placed as a \"liner\" to keep the hole open. This allows the three-dimensional position of the borehole to be mapped periodically, revealing the movement of the glacier, not only at the surface, but throughout its thickness. To understand whether a glacier is shrinking or growing, its mass balance must be measured: this is the net effect of gains from fresh snow, minus losses from melting and sublimation. A straightforward way to determine these effects across the surface of a glacier is to plant stakes (known as ablation stakes) in holes drilled in the glacier's surface, and monitor them over time to see if more snow is accumulating, burying the stake, or if more and more of the stake is visible as the snow around it disappears. The discovery of layers of aqueous water, and of more than a hundred subglacial lakes, beneath the Antarctic ice sheet, led to speculation about the existence of unique microbial environments that had been isolated from the rest of the biosphere, potentially for millions of years. These environments can be investigated by drilling.\n\nIce cores are one of the most important motivations for drilling in ice. Since ice cores retain environmental information about the time the ice in them fell as snow, they are useful in reconstructing past climates, and ice core analysis includes studies of isotopic composition, mechanical properties, dissolved impurities and dust, trapped atmospheric samples, and trace radionuclides. Data from ice cores can be used to determine past variations in solar activity, and is important in the construction of marine isotope stages, one of the key palaeoclimatic dating tools. Ice cores can also provide information about glacier flow and accumulation rates. IPICS (International Partnership in Ice Core Sciences) maintains a list of key goals for ice core research. Currently these are to obtain a 1.5 million year old core; obtain a complete record of the last interglacial period; use ice cores to assist with the understanding of climate change over long time scales; obtain a detailed spatial array of ice core climate data for the last 2,000 years; and continue the development of advanced ice core drilling technology.\n\nThe constraints on ice drill designs can be divided into the following broad categories.\n\nThe ice must be cut through, broken up, or melted. Tools can be directly pushed into snow and firn (snow that is compressed, but not yet turned to ice, which typically happens at a depth of to ); this method is not effective in ice, but it is perfectly adequate for obtaining samples from the uppermost layers. For ice, two options are percussion drilling and rotary drilling. Percussion drilling uses a sharp tool such as a chisel, which strikes the ice to fracture and fragment it. More common are rotary cutting tools, which have a rotating blade or set of blades at the bottom of the borehole to cut away the ice. For small tools the rotation can be provided by hand, using a T-handle or a carpenter's brace. Some tools can also be set up to make use of ordinary household power drills, or they may include a motor to drive the rotation. If the torque is supplied from the surface, then the entire drill string must be rigid so that it can be rotated; but it is also possible to place a motor just above the bottom of the drill string, and have it supply power directly to the drill bit.\n\nIf the ice is to be melted instead of cut, then heat must be generated. An electrical heater built into the drill string can heat the ice directly, or it can heat the material it is embedded in, which in turn heats the ice. Heat can also be sent down the drill string; hot water or steam pumped down from the surface can be used to heat a metal drillhead, or the water or steam can be allowed to emerge from the drillhead and melt the ice directly. In at least one case a drilling project experimented with heating the drillhead on the surface, and then lowering it into the hole.\n\nMany ice drilling locations are very difficult to access, and drills must be designed so that they can be transported to the drill site. The equipment should be as light and portable as possible. It is helpful if the equipment can be broken down so that the individual components can be carried separately, thus reducing the burden for hand-carrying, if required. Fuel, for steam or hot water drills, or for a generator to provide power, must also be transported, and this weight has to be taken into account as well.\n\nMechanical drilling produces pieces of ice, either as cuttings, or as granular fragments, which must be removed from the bottom of the hole to prevent them from interfering with the cutting or percussing action of the drill. An auger used as the cutting tool will naturally move ice cuttings up its helical flights. If the drill's action leaves the ice chips on top of the drill, they can be removed by simply raising the drill to the surface periodically. If not, they can be brought to the surface by lowering a tool to scoop them up, or the hole can be kept full of water, in which case the cuttings will naturally float to the top of the hole. If the chips are not removed, they must be compacted into the walls of the borehole, and into the core if a core is being retrieved.\n\nCuttings can also be moved to the surface by circulating compressed air through the hole, either by pumping the air through the drillpipe and out at the drillhead, forcing the chips up in the space between the drill string and the borehole wall, or by reverse air circulation, in which the air flows up through the drill string. Compressed air will be heated by the compression, and it must be cooled before being pumped downhole, or it will cause melting of the borehole walls and the core. If the air is circulated by creating a vacuum, rather than pumping air in, ambient air carries the cuttings, so no cooling is needed.\n\nA fluid can be used to circulate the cuttings away from the bit, or the fluid may be able to dissolve the cuttings. Rotary mineral drilling (through rock) typically circulates fluid through the entire hole, and separates solids from the fluid at the surface before pumping the fluid back down. In deep ice drilling it is usual to circulate the fluid only at the bottom of the hole, collecting cuttings in a chamber that is part of the downhole assembly. For a coring drill, the cuttings chamber can be emptied each time the drill is brought to the surface to retrieve a core.\n\nThermal drills will produce water, so there are no cuttings to dispose of, but the drill must be capable of working while submerged in water, or else the drill must have a method of removing and storing the meltwater while drilling.\n\nThe drilling mechanism must be connected to the surface, and there must be a method of raising and lowering the drill. If the drill string consists of pipes or rods that have to be screwed together, or otherwise assembled, as the hole gets deeper and the drill string lengthens, then there must be a way to hold the drill string in place as each length of rod or pipe is added or removed. If the hole is only a few metres deep, no mechanical assistance may be necessary, but drill strings can get very heavy for deep holes, and a winch or other hoisting system must be in place that is capable of lifting and lowering it.\n\nA \"trip\" in drilling refers to the task of pulling a drill string completely out of the hole (tripping out) and then reinserting it back into the hole (tripping in). Tripping time is the time taken to trip in and out of the hole; it is important for a drill design to minimize tripping time, particularly for coring drills, since they must complete a trip for each core.\n\nThe overburden pressure in a deep hole from the weight of the ice above will cause a borehole to slowly close up, unless something is done to counteract it, so deep holes are filled with a drilling fluid that is about the same density as the surrounding ice, such as jet fuel or kerosene. The fluid must have low viscosity to reduce tripping time. Since retrieval of each segment of core requires a trip, a slower speed of travel through the drilling fluid could add significant time to a project—a year or more for a deep hole. The fluid must contaminate the ice as little as possible; it must have low toxicity, for safety and to minimize the effect on the environment; it must be available at a reasonable cost; and it must be relatively easy to transport. The depth at which borehole closure prevents dry drilling is strongly dependent on the temperature of the ice; in a temperate glacier, the maximum depth might be , but in a very cold environment such as parts of East Antarctica, dry drilling to might be possible.\n\nSnow and firn are permeable to air, water, and drilling fluids, so any drilling method that requires liquid or compressed air in the hole needs to prevent them from escaping into the surface layers of snow and firn. If the fluid is only used in the lower part of the hole, permeability is not an issue. Alternatively the hole can be cased down past the point where the firn turns to ice. If water is used as a drilling fluid, in cold enough temperatures, it will turn to ice in the surrounding snow and firn and seal the hole.\n\nTools can be designed to be rotated by hand, via a brace or T-handle, or a hand crank gearing, or attached to a hand drill. Drills with powered rotation require an electrical motor at the rig site, which generally must have fuel, though in at least one case a drilling project was set up near enough to a permanent research station to run a cable to the research building for power. The rotation can be applied at the surface, by a rotary table, using a kelly, or by a motor in the drillhead, for cable-suspended drills; in the latter case the cable must carry power to the drillhead as well as support its weight. For rotary drills, gearing is required to reduce the engine's rotation to a suitable speed for drilling.\n\nIf torque is supplied at the bottom of the hole, the motor supplying it to the drillbit beneath it will have a tendency to rotate around its own axis, rather than imparting the rotation to the drillbit. This is because the drillbit will have a strong resistance to rotation since it is cutting ice. To prevent this, an anti-torque mechanism of some kind must be provided, typically by giving the motor some grip against the walls of the borehole.\n\nA thermal drill that uses electricity to heat the drill head so that it melts the ice must bring power down the hole, just as with rotary drills. If the drillhead is heated by pumping water or steam down to the bottom of the hole, then no downhole power is needed, but a pump at the surface is required for hot water. The water or steam can be heated at the surface by a fuel-powered boiler. Solar power can also be used.\n\nSome drills which are designed to rest on their tip as they drill will lean to one side in the borehole, and the hole they drill will gradually drift towards the horizontal unless some method of counteracting this tendency is provided. For other drills, directional control can be useful in starting additional holes at depth, for example to retrieve additional ice cores.\n\nMany glaciers are temperate, meaning that they contain \"warm ice\": ice that is at melting temperature (0 °C) throughout. Meltwater in boreholes in warm ice will not refreeze, but for colder ice, meltwater is likely to cause a problem, and may freeze the drill in place, so thermal drills that operate submerged in the meltwater they produce, and any drilling method that results in water in the borehole, are difficult to use in such conditions. Drilling fluids, or antifreeze additives to meltwater, must be chosen to keep the fluid liquid at the temperatures found in the borehole. In warm ice, ice tends to form on cutters and the drillhead, and to pack into spaces at the bottom of the hole, slowing down drilling.\n\nTo retrieve a core, an annulus of ice must be removed from around the cylindrical core. The core should be unbroken, which means that vibrations and mechanical shocks must be kept to a minimum, and changes in temperature which could cause thermal shock to the core must also be avoided. The core must be kept from melting caused by heat generated either mechanically from the drilling process, from the heat of compressed air if air is used as the drilling fluid, or from a thermal drill, and must not be contaminated by the drilling fluid. When the core is about to be retrieved, it is still connected to the ice beneath it, so some method of breaking it at the lower end must be provided, and of gripping it so it does not fall from the core barrel as it is brought to the surface, which must be done as quickly and safely as possible.\n\nMost coring drills are designed to retrieve cores that are no longer than , so drilling must stop each time the hole depth is extended by that amount, so that the core can be retrieved. A drill string that must be assembled and disassembled in segments, such as pipe sections that must be screwed together, takes a long time to trip in and out; a cable which can be continuously winched up, or a drill string that is flexible enough to be coiled, significantly reduces tripping time. Wireline drills have a mechanism that allows the core barrel to be detached from the drill head and winched directly to the surface without having to trip out the drill string. Once the core is removed, the core barrel is lowered to the bottom of the hole and reattached to the drill.\n\nOver a depth range known as the brittle ice zone, bubbles of air are trapped in the ice under great pressure. When a core is brought to the surface, the bubbles can exert a stress that exceeds the tensile strength of the ice, resulting in cracks and spall. At greater depths, the ice crystal structure changes from hexagonal to cubic, and the air molecules move inside the crystals, in a structure called a clathrate. The bubbles disappear, and the ice becomes stable again.\n\nThe brittle ice zone typically returns poorer quality samples than for the rest of the core. Some steps can be taken to alleviate the problem. Liners can be placed inside the drill barrel to enclose the core before it is brought to the surface, but this makes it difficult to clean off the drilling fluid. In mineral drilling, special machinery can bring core samples to the surface at bottom-hole pressure, but this is too expensive for the inaccessible locations of most drilling sites. Keeping the processing facilities at very low temperatures limits thermal shocks. Cores are most brittle at the surface, so another approach is to break them into 1 m lengths in the hole. Extruding the core from the drill barrel into a net helps keep it together if it shatters. Brittle cores are also often allowed to rest in storage at the drill site for some time, up to a full year between drilling seasons, to let the ice gradually relax. Core quality in the brittle ice zone is much improved when a drilling fluid is used, as opposed to dry hole drilling.\n\nA percussion drill penetrates ice by repeatedly striking it to fracture and fragment it. The cutting tool is mounted at the bottom of the drill string (typically connected metal rods), and some means of giving it kinetic energy must be provided. A tripod erected over the hole allows a pulley to be set up, and a cable can then be used to repeatedly raise and drop the tool. This method is known as cable tool drilling. A weight repeatedly dropped on to a rigid drill string can also be used to provide the necessary impetus. The pulverized ice collects at the bottom of the borehole, and must be removed. It can be collected with a tool capable of scooping it from the bottom of the hole, or the hole can be kept full of water, so that the ice floats to the top of the hole, though this retards the momentum of the drill striking the ice, reducing its effectiveness. A percussion drilling tool that is not mechanically driven requires some method of raising the drill so it can be released, to fall on the ice. To do this efficiently with manual labour, it is usual to set up a tripod or other supporting scaffold, and a pulley to allow the drill string to be raised by a rope. This arrangement, known as a cable-tool rig, can also be used for mechanical drilling, with a motor raising the drill string and allowing it to fall. An alternative approach is to leave the drill string at the bottom of the borehole, and to raise and let fall a hammer weight onto the drill string.\n\nThe earliest scientific ice drilling expedition used percussion drilling; Louis Agassiz used iron rods to drill holes in the Unteraargletscher, in the Alps, in the summer of 1840. Cable-tool rigs have been used for ice drilling in more recent times; Soviet expeditions in the 1960s drilled with cable-tool rigs in the Caucasus and the Tien Shan range, and US projects have drilled on the Blue Glacier in Washington between 1969 and 1976, and on the Black Rapids Glacier in Alaska in 2002.\n\nTwo other percussion methods have been tried. Pneumatic drills have been used to drill shallow holes in ice in order to set blast charges, and rotary percussion drills, a type of drilling tool once in common use in the mining industry, have also been used for drilling blasting holes, but neither approach has been used for scientific investigations of ice. Percussion drilling is now rarely used for scientific ice drilling, having been overtaken by more effective techniques for both ice and mineral drilling.\n\nA soil sampling auger contains a pair of blades at the bottom of an enclosed cylinder; it can be driven and rotated by hand to pick up soft soil. A similar design, called a spoon-borer, has been used for ice drilling, though it is not effective in hard ice. A version used by Erich von Drygalski in 1902 had two half-moon cutting blades set into the base of the cylinder in such a way as to allow the ice cuttings to accumulate in the cylinder, above the blades.\n\nAugers have long been used for drilling through ice for ice fishing. Augers can be rotated by hand, using a mechanism such as a T handle or a brace bit, or by attaching them to powered hand drills. Scientific uses for non-coring augers include sensor installation and determining ice thickness. Augers have a helical screw blade around the main drilling axis; this blade, called the \"flighting\", carries the ice cuttings up from the bottom of the hole. For drilling deeper holes, extensions can be added to the auger, but as the auger gets longer it becomes more difficult to rotate. With a platform such as a stepladder, a longer auger can be rotated from higher off the ground.\n\nCommercially available ice augers for winter fishing, powered by petrol, propane, or battery power, are available for hole diameters from 4.5 in to 10 in. For holes deeper than 2 m a tripod can be used to winch the auger from the hole. A folding brace handle with an offset design is common; this allows both hands to contribute to the torque.\n\nAugers that are capable of retrieving ice cores are similar to noncoring augers, except that the flights are set around a hollow core barrel. Augers have been devised that consist of the helical cutting blades and a space for a core, without the central supporting cylinder, but they are difficult to make sufficiently rigid. Coring augers typically produce cores with diameters in the range 75–100 mm, and with lengths up to 1 m. Coring augers were originally designed to be manually rotated, but over time they have been adapted for use with handheld drills or small engines.\n\nAs with noncoring augers, extensions can be added to drill deeper. Drilling deeper than 6 m requires more than one person because of the weight of the drill string. A clamp placed at the surface is useful for supporting the string, and a tripod and block and tackle can also be used for support and to increase the weight of string that can be handled. As the drill string gets longer, it takes more time to complete a trip to extract a core, since each extension rod must be separated from the drill string when tripping out, and re-attached when tripping in.\n\nDrilling with a tripod or other method of handling a long drill string considerably extends the depth limit for the use of a coring auger. The deepest hole drilled by hand with an auger was 55 m, in the Ward Hunt Ice Shelf on Ellesmere Island, in 1960. Usually a hole deeper than 30 m will be drilled with other methods, because of the weight of the drill string and the long trip time required.\n\nModern coring augers have changed little in decades: an ice coring auger patented in the US in 1932 closely resembles coring augers in use eighty years later. The US military's Frost Effects Laboratory (FEL) developed an ice mechanics testing kit that included a coring auger in the late 1940s; the Snow, Ice and Permafrost Research Establishment (SIPRE), a successor organization, refined the design in the early 1950s, and the resulting auger, known as the SIPRE auger, is still in wide use. It was modified slightly by the Cold Regions Research and Engineering Laboratory (CRREL), another successor organization, in the 1960s, and is sometimes known as the CRREL auger for that reason. An auger developed in the 1970s by the Polar Ice Core Office (PICO), then based in Lincoln, Nebraska, is also still widely used. A coring auger designed at the University of Copenhagen in the 1980s was used for the first time at Camp Century, and since then has been frequently used in Greenland. In 2009, the US Ice Drilling Design and Operations group (IDDO) began work on an improved hand auger design and a version was successfully tested in the field during the 2012–2013 field season at WAIS Divide. As of 2017 IDDO maintains both 3-inch and 4-inch diameter versions of the new auger for the use of US ice drilling research programs, and these are now the most-requested hand auger provided by IDDO.\n\nThe Prairie Dog auger, designed in 2007, adds an outer barrel to the basic coring auger design. Cuttings are captured between the auger flights and the outer barrel, which has an anti-torque section to prevent it from rotating in the hole. The goal of the outer barrel is to increase the efficiency of chip collection, since it is common to see chips from a hand auger run fall back into the hole from the auger flights, which means the next run has to redrill through these cuttings. The outer barrel also makes the auger effective in warm ice, which could easily cause an auger with no outer barrel to jam. The outside barrel of the Prairie Dog is the same as the diameter of the PICO auger, and since the Prairie Dog's anti-torque blades do not perform well in soft snow and firn, it is common to start a hole with the PICO auger and then continue it with the Prairie Dog once dense firn is reached. The Prairie Dog is relatively heavy, and can require two drillers to handle it as it is being removed from the hole. The IDDO maintains a Prairie Dog drill for the use of US ice drilling research programs.\n\nIDDO also provides a lifting system for use with hand augers, known as the Sidewinder. It is driven by an electric hand drill, which can be powered by a generator or by solar cells. The Sidewinder winds a rope around the hand auger as it is lowered into the hole, and assists in raising the auger back out of the hole. This extends the maximum practical depth for hand augering to about 40 m. Sidewinders have proved popular with researchers.\n\nA piston drill consists of a flat disc at the bottom of a long rod, with three or four radial slots in the disc, each of which has a cutting edge. The rod is rotated by hand, using a brace handle; the ice comes through the slots and piles up on top of the disc. Pulling the drill out of the borehole brings the cuttings up on the disc. In the 1940s some patents for piston drill designs were filed in Sweden and the U.S., but these drills are now rarely used. They are less efficient than auger drills, since the drill must be periodically removed from the hole to get rid of the cuttings.\n\nSome hand drills have been designed to retrieve cores without using auger flights to transport the cuttings up the hole. These drills typically have a core barrel with teeth at the lower end, and are rotated by a brace or T-handle, or by a small engine. The barrel itself can be omitted, so that the drill consists only of a ring with a cutting slot to cut the annulus around the core, and a vertical rod to attach the ring to the surface. A couple of small hand-held drills, or mini drills, have been designed to quickly collect core samples up to 50 cm long. A difficulty with all these designs is that as soon as cuttings are generated, if they are not removed they will interfere with the cutting action of the drill, making these tools slow and inefficient in use. A very small drill, known as the Chipmunk Drill, was designed by IDDO for use by a project in West Greenland in 2003 and 2004, and was subsequently used at the South Pole in 2013.\n\nRotary rigs used in mineral drilling use a string of drillpipe connected to a drillbit at the bottom of the hole, and to a rotary mechanism at the top of the hole, such as a top drive or rotary table and kelly. As the borehole deepens, drilling is paused periodically to add a new length of drill pipe at the top of the drill string. These projects have usually been undertaken with commercially available rotary rigs originally designed for mineral drilling, with adaptations to suit the special needs of ice drilling.\n\nWhen drilling in ice, the hole may be drilled dry, with no mechanism to dispose of the cuttings. In snow and firn this means that the cuttings simply compact into the walls of the borehole; and in coring drills they also compact into the core. In ice, the cuttings accumulate in the space between the drillpipe and the borehole wall, and eventually start to clog the drill bit, usually after no more than 1 m of progress. This increases the torque needed to drill, slows down progress, and can cause the loss of the drill. Dry core drilling generally produces a poor quality core that is broken into pieces.\n\nIn 1950, the French Expédition Polaires Françaises (EPF) drilled two dry holes in Greenland using a rotary rig, at Camp VI, on the west coast, and Station Centrale, inland, reaching 126 m and 151 m. Some shallow holes were also drilled that summer on Baffin Island, using a coring drill, and in the Antarctic, the Norwegian–British–Swedish Antarctic Expedition (NBSAE) drilled several holes between April 1950 and the following year, eventually reaching 100 m in one hole. The last expedition to try dry drilling in ice was the 2nd Soviet Antarctic Expedition (SAE), which drilled three holes between July 1957 and January 1958. Since that time dry drilling has been abandoned as other drilling methods have proved to be more effective.\n\nSeveral holes have been drilled in ice using direct air circulation, in which compressed air is pumped down the drillpipe, to escape through holes in the drillbit, and return up the annular space between the drillbit and the borehole, carrying the cuttings with it. The technique was first tried by the 1st Soviet Antarctic Expedition, in October 1956. There were problems with poor cuttings removal, and ice forming in the borehole, but the drill succeeded in reaching a depth of 86.5 m. Further attempts were made to use air circulation with rotary rigs by US, Soviet and Belgian expeditions, with a maximum hole depth of 411 m reached by a US team at Site 2 in Greenland in 1957. The last time a project used a conventional rotary rig with air circulation was 1961.\n\nIn mineral exploration, the most common drilling method is a rotary rig with fluid circulated down the drillpipe and back up between the drillpipe and the borehole wall. The fluid carries the cuttings to the surface, where the cuttings are removed, and the recycled fluid, known as mud, is returned to the hole. The first ice drilling project to try this approach was an American Geographical Society expedition to the Taku Glacier in 1950. Fresh water, drawn from the glacier, was used as the drilling fluid, and three holes were drilled, to a maximum depth of 89 m. Cores were retrieved, but in poor condition. Seawater has also been tried as a drilling fluid. The first time a fluid other than water was used with a conventional rotary rig was in late 1958, at Little America V, where diesel fuel was used for the last few metres of a 254 m hole.\n\nA wireline drill uses air or fluid circulation, but also has a tool that can be lowered into the drillpipe to retrieve a core without removing the drill string. The tool, called an overshot, latches onto the core barrel and pulls it up to the surface. When the core is removed, the core barrel is lowered back into the borehole and reattached to the drill. A wireline core drilling project was planned in the 1970s for the International Antarctic Glaciological Project, but was never completed, and the first wireline ice drilling project took place in 1976, as part of the Ross Ice Shelf Project (RISP). A hole was started in November of that year with a wireline drill, probably using air circulation, but problems with the overshot forced the project to switch to thermal drilling when the hole was 103 m deep. The RISP project reached over 170 m with another wireline drill the following season, and several 1980s Soviet expedition also used wireline drills, after starting the holes with an auger drill and casing the holes. The Agile Sub-Ice Geological (ASIG) drill, designed by IDDO to collect sub-glacial cores, is a recent wireline system; it was first used in the field in the 2016–2017 season, in West Antarctica.\n\nThere are many disadvantages to using conventional rotary rigs for ice drilling. When a conventional rotary rig is used for coring, the entire drill string must be hoisted out of the borehole each time the core is retrieved; each length of pipe in turn must be unscrewed and racked. As the hole gets deeper, this becomes very time-consuming. Conventional rigs are very heavy, and since many ice drilling sites are not easily accessible these rigs place a large logistical burden on an ice drilling project. For deep holes, a drilling fluid is required to maintain pressure in the borehole and prevent the hole from closing up because of the pressure the ice is under; a drilling fluid requires additional heavy equipment to circulate and store the fluid, and to separate the circulated material. Any circulation system also requires the upper part of the hole, through the snow and firn, to be cased, since circulated air or fluid would escape through anything more permeable than ice. Commercial rotary rigs are not designed for extremely cold temperatures, and in addition to problems with components such as the hydraulics and fluid management systems, they are designed to operate outdoors, which is impractical in extreme environments such as Antarctic drilling.\n\nCommercial rotary rigs can be effective for large-diameter holes, and can also be used for subglacial drilling into rock. They have also been used with some success for rock glaciers, which are challenging to drill because they contain a heterogeneous mixture of ice and rock.\n\nFlexible drillstem rigs use a drill string that is continuous, so that it does not have to be assembled or disassembled, rod by rod or pipe by pipe, when tripping in or out. The drill string is also flexible, so that when out of the borehole it can be stored on a reel. The drill string may be a reinforced hose, or it may be steel or composite pipe, in which case it is known as a coiled-tubing drill. Rigs designed along these lines began to appear in the 1960s and 1970s in mineral drilling, and became commercially viable in the 1990s.\n\nOnly one such rig, the rapid air movement (RAM) system developed at the University of Wisconsin-Madison by Ice Coring and Drilling Services (ICDS), has been used for ice drilling. The RAM drill was developed in the early 2000s, and was originally designed for drilling shot holes for seismic exploration. The drill stem is a hose through which air is pumped; the air drives a turbine that powers a downhole rotary drill bit. Ice cuttings are removed by the exhaust air and fountain out of the hole. The compressor increases the temperature of the air by about 50°, and it is cooled again before being pumped downhole, with a final temperature about 10° warmer than the ambient air. This means it cannot be used in ambient temperatures warmer than −10 °C. To avoid ice forming in the hose, ethanol is added to the compressed air. The system, which includes a winch to hold 100 m of hose, as well as two air compressors, is mounted on a sled. It has successfully drilling hundreds of holes in West Antarctica, and was easily able to drill to 90 m in only 25 minutes, making it the fastest ice drill. It was also used by the Askaryan Radio Array project in 2010–2011 at the South Pole, but was unable to drill below 63 m there because of variations in the local characteristics of the ice and firn. It cannot be used in a fluid-filled hole, which limits the maximum hole depth for this design. The main problem with the RAM drill is a loss of air circulation in firn and snow, which might be addressed by using reverse air circulation, via a vacuum pump drawing air up through the hose. As of 2017 IDDO is planning a revised design for the RAM drill to reduce the weight of the drill, which is currently 10.3 tonnes.\n\nOther flexible drill stem designs have been considered, and in some cases tested, but as of 2016 none had been successfully used in the field. One design suggested using hot water to drill via a hose, and replacing the drillhead with a mechanical drill for coring once the depth of interest is reached, using the hot water both to hydraulically power the down hole motor, and to melt the resulting ice cuttings. Another design, the RADIX drill, produces a very narrow hole (20 mm) and is intended for rapid drilling access holes; it uses a small hydraulic motor on a narrow hose. It was tested in 2015 but found to have difficulty with cuttings transport, probably because of the very narrow space available between the hose and the borehole wall.\n\nCoiled-tubing designs have never been successfully used for ice drilling. Coring operations would be particularly difficult, since a coring drill must trip out and in for each core, which would lead to fatigue; the tubing is typically rated for a lifetime of only 100 to 200 trips.\n\nA cable-suspended drill has a downhole system, known as a sonde, to drill the hole. The sonde is connected to the surface by an armoured cable, which provides power and enables the drill to be winched in and out of the hole. Electromechanical (EM) cable-suspended drills have a cutting head, with blades that shave the ice as they rotate, like a carpenter's plane. The depth of penetration of the cut is adjusted by a device called a shoe, which is part of the cutting head. The ice cuttings are stored in a chamber in the sonde, either in the core barrel, above the core, or in a separate chamber, further up the drill.\n\nThe cuttings can be transported by auger flights or by fluid circulation. Drills that rely on auger flights and which are not designed to work in a fluid-filled hole are limited to depths at which borehole closure is not a problem, so these are known as shallow drills. Deeper holes have to be drilled with drilling fluid, but whereas circulation in a rotary drill takes the fluid all the way down and then up the borehole, cable-suspended drills only need to circulate the fluid from the drill head up to the cuttings chamber. This is known as bottom-hole circulation.\n\nThe upper part of the sonde has an antitorque system, which most commonly consists of three or four leaf-springs that press out against the borehole walls. Sharp edges on the leaf springs catch in the walls and provide the necessary resistance to prevent this part of the drill from rotating. At the point where the cable connects to the sonde, most drills include a slip ring, to allow the drill to rotate independently of the cable. This is to prevent torque damage to the cable if the anti-torque system fails. Coring drills may also have a weight that can be used as a hammer to assist in breaking the core, and a chamber for any instrumentation or sensors needed.\n\nAt the bottom of the sonde is the cutting head, and above this is the core barrel, with auger flights around it on shallow drills, and typically an outer barrel around that, usually with internal vertical ribs or some other way of providing additional impetus to the upward-bound cuttings on the flights. If there is a separate chip chamber it will be above the core barrel. The motor, with suitable gearing, is also above the core barrel.\n\nShallow drills can retrieve cores up to 300–350 m deep, but core quality is much improved if drilling fluid is present, so some shallow drills have been designed to work in wet holes. Tests reported in 2014 showed that wet drilling, with the top of the drilling fluid no deeper than 250 m, would maintain good core quality.\n\nDrilling fluids are necessary for drilling deep holes, so the cable-suspended drills that are used for these projects use a pump to provide fluid circulation, in order to remove the cuttings from the bit. A few drills designed for use with drilling fluid also have auger flights on the inner barrel. As with shallow drills, the cuttings are stored in a chamber above the core. The circulation can be in either direction: down the inside of the drill string, and up between the core barrel and the borehole wall, or in the reverse direction, which has become the favoured approach in drill design as it gives better cuttings removal for a lower flow rate. Drills capable of reaching depths over 1500 m are known as deep drilling systems; they have generally similar designs to the intermediate systems that can drill from 400 m to 1500 m, but must have heavier and more robust systems such as winches, and have longer drills and larger drilling shelters. Core diameters for these drills have varied from 50 mm to 132 mm, and the core length from as short as 0.35 m up to 6 m. A common design feature of these deep drills is that they can be tipped to the horizontal to make it easier to remove the core and the cuttings. This reduces the required height of the mast, but requires a deep slot to be cut into the ice, to make room for the sonde to swing up.\n\nThe first cable-suspended electromechanical drill was invented by Armais Arutunoff for use in mineral drilling; it was tested in 1947 in Oklahoma, but did not perform well. CRREL acquired a reconditioned Arutunoff drill in 1963, modified it for drilling in ice, and in 1966 used it to extend a hole at Camp Century in Greenland to the base of the ice cap, at 1387 m, and 4 m further into the bedrock.\n\nMany other drills have since been based on this basic design. A recent variation on the basic EM drill design is the Rapid Access Isotope Drill, designed by the British Antarctic Survey to drill dry holes to 600 m. This drill does not collect a complete ice core; instead it will collect ice cuttings, using a cutting head similar to a spoonborer. The resulting access hole will be used for temperature profiling, and along with the isotope results which will indicate the age of the ice, the data will be used for modeling the ice profile down to bedrock in order to determine the best place to drill to obtain the oldest possible undisturbed basal ice. The drill is expected to reach 600 m in 7 days of drilling, rather than the 2 months which would be needed to drill a core; the speed is because the cutters can be more aggressive as core quality is not an issue, and because the borehole is narrow which reduces power requirements for the winch.\n\nThermal drills work by applying heat to the ice at the bottom of the borehole to melt it. Thermal drills in general are able to drill successfully in temperate ice, where an electromechanical drill is at risk of jamming because of ice forming in the borehole. When used in colder ice, some form of antifreeze is likely to be introduced into the borehole to prevent the meltwater from freezing in the drill.\n\nHot water can be used to drill in ice by pumping it down a hose with a nozzle at the end; the jet of hot water will quickly produce a hole. Letting the hose dangle freely will produce a straight hole; as the hole gets deeper the weight of the hose makes this hard to manage manually, and at a depth of about 100 m it becomes necessary to run the hose over a pulley and use counterweights. Since the pressure in the hose is proportional to the square of the flow, hose diameter is one of the limiting factors for a hot-water drill. To increase flow rate beyond a certain point, the hose diameter must be increased, but this will require significant capacity increases elsewhere in the drill design. Hoses that are wrapped around a drum before being pressurized will exert constricting force on the drum, so the drums must be of robust design. Hoses must wrap neatly when spooling up, to avoid damage; this can be done manually for smaller systems, but for very large drills a level-wind system has to be implemented. The hose ideally should have the tensile strength to support its weight when spooling into the hole, but for very deep holes a supporting cable may need to be used to support the hose.\n\nSteam can also be used in place of hot water, and does not need to be pumped. A handheld steam drill is able to rapidly drill short holes, for example for ablation stakes, and both steam and hotwater drills can be made light enough to be hand carried. A guide tube can be used to help keep the borehole straight.\n\nIn cold ice, a borehole drilled with hot water will close up as the water freezes. To avoid this, the drill can be run back down the hole, warming the water and hence the surrounding ice. This is a form of reaming. Repeated reamings will raise the temperature of the surrounding ice to the point where the borehole will stay open for longer periods. However, if the goal is to measure temperature in the borehole, then it is better to apply as little additional heat as possible to the surrounding ice, which means that a higher energy drill with a high water flow rate is desirable, since this will be more efficient. If there is a risk of the drill freezing in, a \"back drill\" can be included in the design. This is a mechanism which redirects the hot water jet upwards if the drill meets with resistance on tripping out. A separate hot water reamer can also be used, jetting hot water sideways onto the borehole walls as it passes.\n\nBoreholes drilled with hot water are rather irregular, which makes them unsuitable for certain kinds of investigations, such as speed of borehole closure, or inclinometry measurements. The warm water from the nozzle will continue to melt the borehole walls as it rises, and this will tend to make the hole cone-shaped—if the hole is being drilled at a location with no surface snow or firn, such as an ablation zone in a glacier, then this effect will persist to the top of the borehole.\n\nThe water supply for a hot water drill can come from water at the surface, if available, or melted snow. The meltwater in the borehole can be reused, but this can only be done once the hole penetrates below the firn to the impermeable ice layer, because above this level the meltwater escapes. The pump to bring the meltwater back to the surface must be placed below this level, and in addition, if there is a chance that the borehole will penetrate to the base of the ice, the drilling project must plan for the likelihood that this will change the water level in the hole, and ensure that the pump is below the lowest likely level. Heating systems are usually adapted from the heaters used in the pressure washer industry.\n\nWhen any thermal drilling method is used in dirty ice, the debris will accumulate at the bottom of the borehole, and start to impede the drill; enough debris, in the form of sand, pebbles, or a large rock, could completely stop progress. One way to avoid this is to have a nozzle angled at 45°; using this nozzle will create a side channel into which the obstructions will go. Vertical drilling can then start again, bypassing the debris. Another approach is to recirculate the water at the bottom of the hole, with an electrical heater embedded in the drill head and filters in the circulation. This can remove most of the small debris that impedes the drillhead.\n\nA different problem with impure ice comes from contaminants brought in by the project, such as clothing and wood fibres, dust, and grit. Using snow from around the campsite to supply the drill with water is often necessary at the start of drilling, as the hole will not yet have reached the impermeable ice, so water cannot be pumped back up from the bottom of the hole; shoveling this snow into the drill's water supply will pass these contaminants through the drill mechanism, and can damage the pumps and valves. A fine filter is required to avoid these problems.\n\nAn early expedition using hot water drills was in 1955, to the Mer de Glace; Électricité de France used hot water to reach the base of the glacier, and also used equipment that sprayed multiple jets simultaneously to create a tunnel under the ice. More development work was done in the 1970s. Hot water drills are now capable of drilling very deep holes: for example, between 2004 and 2011, a large hot water drill at the South Pole was used to drill 86 holes to a depth of 2.5 km to set strings of sensors in the boreholes, for the IceCube project. Hot water coring drills have also been developed.\n\nAn early steam drill was developed by F. Howorka in the early 1960s for work in the Alps. Steam drills are not used for holes deeper than 30 m, as they are quite inefficient due to thermal losses along the hose, and pressure losses with increasing depth under water. They are primarily used for quickly drilling shallow holes.\n\nInstead of using a jet of hot water or steam, thermal drills can also be constructed to provide heat to a durable drillhead, for example by pumping hot water down and back up again inside the drill string, and use that to melt the ice. Modern thermal drills use electrical power to heat the drillhead instead.\n\nIt is possible to drill with a hotpoint that consists of an electrical heating element, directly exposed to the ice; this means that the element must be able to work underwater. Some drills instead embed the heating element in a material such as silver or copper that will conduct the heat quickly to the hotpoint surface; these can be constructed so that the electrical connections are not exposed to water. Electrothermal drills require a cable to bring the power down the hole; the circuit can be completed via the drillpipe if one is present. A transformer is needed in the drill assembly since the cable must carry high voltage to avoid power dissipation. It is more difficult to arrange electrical power at a remote location than to generate heat via a gas boiler, so hotpoint drills are only used for boreholes up to a few hundred metres deep.\n\nThe earliest attempt to use heat to drill in ice was in 1904, when C. Bernard drilling at the Tête Rousse Glacier, tried using heated iron bars to drill with. The ends of the bars were heated until incandescent, and lowered into the borehole. The first true hotpoint was used by Mario Calciati in 1942 on the Hosand Glacier. Calciati pumped hot water from the surface down the drillstem, and back up after it had passed through the drillhead. Other hotpoint designs have used electrical heating to heat the drillhead; this was done in 1948 by a British expedition to the Jungfraujoch, and by many other drill designs since then. Hotpoints do not produce cores, so they are used primarily for creating access holes.\n\nThe development in the 1960s of thermal coring drills for intermediate depth holes was prompted by the problems associated with rotary coring drills, which were too costly to use for polar ice cores because of the logistical problems caused by their weight. The components of a thermal drill are generally the same as for a cable-suspended EM drill: both have a mast and winch, and an armoured cable to provide power downhole to a sonde, which includes a core barrel. No antitorque system is needed for a thermal drill, and instead of a motor that provides torque, the power is used to generate heat in the cutting head, which is ring shaped to melt an annulus of ice around the core. Some drills may also have a centralizer, to keep the sonde in the middle of the borehole.\n\nThe sonde of an electrothermal drill designed to run submerged in meltwater may consist almost entirely of the core barrel plus the heated cutting head (diagram (a) in the figure to the right). Alternative designs for use in colder ice (see diagram (b) at right) may have a compartment above the core barrel, and tubes that run down to just above the cutting head; a vacuum pump sucks up the meltwater. In these drills the meltwater must be emptied at the surface at the end of each coring run.\n\nAnother approach (see (c) at right) is to use a drilling fluid that is a mixture of ethanol and water, with the exact proportions determined by the ice temperature. In these drills there is a piston above the core barrel and at the start of a run the piston is at the bottom of the sonde, and the space above is filled with drilling fluid. As the drills cuts downwards, the core pushes the piston up, pumping the fluid down and out around the cutting head, where it mixes with the meltwater and prevents it from freezing. The piston is the only moving part, which simplifies the design; and the core barrel can take up much of the length of the sonde, whereas drills which suck out the meltwater in order to drill in a dry hole have to sacrifice a large section of the sonde for meltwater storage.\n\nThermal drills designed for temperate ice are light and straightforward to operate, which makes them suitable for use on high-altitude glaciers, though this also requires that the drill can be disassembled into components for human-powered transport to the most inaccessible locations, since helicopters may not be able to reach the highest glaciers.\n\nElectrothermal drill designs date back to the 1940s. An electrothermal drill was patented in Switzerland in May 1946 by René Koechlin, and was used in Switzerland, and in 1948 a British expedition to the Jungfraujoch drilled to the bed of the glacier using an electrothermal design. Twenty electrothermal coring drills were designed between 1964 and 2005, though many designs were abandoned because of the higher performance of EM coring drills.\n\nIf the goal is to obtain instrument readings from within the ice, and there is no need to retrieve either the ice or the drill system, then a probe containing a long spool of cable and a hotpoint can be used. The hotpoint allows the probe to melt its way through the ice, unreeling the cable behind it. The meltwater will refreeze, so the probe cannot be recovered, but it can continue to penetrate the ice until it reaches the limit of the cable it carries, and send instrument readings back up through the cable to the surface. Known as Philberth probes, these devices were designed by Karl and Bernhard Philberth in the 1960s as a way to store nuclear waste in the Antarctic, but were never used for that purpose. Instead, they were adapted to use for glaciological research, reaching a depth of 1005 metres and sending temperature information back to the surface when tested in 1968 as part of the Expédition Glaciologique Internationale au Groenland (EGIG).\n\nBecause thermal probes support their weight on the ice at the bottom of the borehole, they lean slightly out of the vertical, and this means they have a natural tendency to stray away from a vertical borehole towards the horizontal. Various methods have been proposed to address this. A cone-shaped tip, with a layer of mercury above the tip, will cause additional heat transfer to the lower side of a slanting borehole, increasing the speed of melting on that side, and returning the borehole to the vertical. Alternatively the probe can be constructed to be supported by ice above its centre of gravity, by providing two heating rings, one of which is towards the top of the probe, and has a greater diameter than the rest of the probe. Giving this upper ring a slightly lower heating power will cause the probe to have more bearing pressure on the upper ring, which will give it a natural tendency to swing back to vertical if the borehole starts to deviate. The effect is called pendulum steering, by analogy with the tendency of a pendulum always to swing back towards a vertical position.\n\nIn the 1990s NASA combined the Philberth probe design with ideas drawn from hot-water drills, to design a cryobot probe that had hot water jets in addition to a hotpoint nose. Once the probe was submerged in a thin layer of meltwater, the water was drawn in and reheated, emerging at the nose as a jet. This design was intended to help move particulate matter away from the nose, as a hot-water drill tends to. A version with no analytical tools on board was built and field tested in Svalbard, Norway, in 2001. It penetrated to 23 m, successfully passing through layers of particulates.\n\nCryobots remain in good thermal contact with the surrounding ice throughout their descent, and in very cold ice this can drain a substantial fraction of their power budget, which is finite since they must carry their power source with them. This makes them unsuitable for investigating the Martian polar ice cap. Instead, NASA added a pump to the cryobot design, to raise meltwater to the surface, so that the probe, known as the SIPR (for Subsurface Ice Probe) descends in a dry hole. The lower gravity on Mars means that the overburden pressure on the ice cap is much less, and an open borehole is expected to be stable to a depth of 3 km, the expected depth of the ice cap. The meltwater can then be analyzed at the surface. Pumping through a vertical tube will cause mixing, so to ensure discrete samples for analysis at the surface, a large bore and a small bore tube are used; the small bore tube is used for sampling, and then its contents are allowed to return to the probe and are pumped back up the large bore tube for use in experiments that do not depend on stratigraphy, such as searches for living organisms. Leaving the analytical instruments on the surface reduces the necessary size of the probe, which helps make this design more efficient.\n\nAlong with the water transport tubes, a heated wire ensures that the water stays liquid all the way to the surface, and power and telemetry is also carried from the surface. To keep the hole vertical the probe can sense when it is deviating, and the jets of hot water are adjusted to compensate. The drill is expected to make use of solar power in operation, meaning it must be able to function on less than 100 W when in sunlight. A fully built version of the probe was successfully tested in Greenland in 2006, drilling to a depth of 50 m. NASA has proposed a similar designed for drilling in the ice on Europa, a moon of Jupiter. Any such probe would have to survive temperatures of 500 °C while being sterilized to avoid biological contamination of the target environment.\n\nSnow samples are taken to measure the depth and density of the snow pack in a given area. Measurements of depth and density can be converted into a snow water equivalent (SWE) number, which is the depth of water that would result from converting the snow into water. Snow samplers are typically hollow cylinders, with toothed ends to help them penetrate the snow pack; they are used by pushing them into the snow, and then pulling them out along with the snow in the cylinder. Weighing the cylinder full of snow and subtracting the weight of the empty cylinder gives the snow weight; samplers usually have lengthwise slots to allow the depth of the snow to be recorded as well, though a sampler made of transparent material makes this unnecessary.\n\nThe sampler must grip the snow well enough to keep the snow inside the cylinder as it is removed from the snow, which is easier to accomplish with a smaller diameter cylinder; however, larger diameters give more accurate readings. Samples must avoid compacting the snow, so they have smooth inner surfaces (usually of anodized aluminium alloy, and sometimes waxed in addition) to prevent the snow from gripping the sides of the cylinder as it is pushed in. A sampler may penetrate light snow under its own weight; denser snow pack, firn, or ice, may require the user to rotate the sampler gently so that the cutting teeth are engaged. Pushing too hard without successfully cutting a dense layer may cause the sample to push the layer down; this situation can be identified because the snow level inside the sampler will be lower than the surrounding snow. Multiple readings are usually taken at each location of interest, and the results are averaged. Snow samplers are usually accurate to within about 5–10%.\n\nThe first snow sampler was developed by J.E. Church in the winter of 1908/1909, and the most common modern snow sampler, known as the Federal snow sampler, is based on Church's design, with some modifications by George D. Clyde and the U.S. Soil Conservation Service in the 1930s. It can be used for sampling snow up to 9 m in depth.\n\nPenetration testing involves inserting a probe into snow to determine the snow's mechanical properties. Experienced snow surveyors can use an ordinary ski pole to test snow hardness by pushing it into the snow; the results are recorded based on the change in resistance felt as the pole is inserted. A more scientific tool, invented in the 1930s but still in widespread use, is a ram penetrometer. This takes the form of a rod with a cone at the lower end. The upper end of the rod passes through a weight that is used as a hammer; the weight is lifted and released, and hits an anvil—a ledge around the rod which it cannot pass—which drives the rod into the snow. To take a measurement, the rod is placed on the snow and the hammer is dropped one or more times; the resulting depth of penetration is recorded. In soft snow a lighter hammer can be used to obtain more precise results; hammer weights range from 2 kg down to 0.1 kg. Even with lighter hammers, ram penetrometers have difficulty distinguishing thin layers of snow, which limits their usefulness with regard to avalanche studies, since thin and soft layers are often involved in avalanche formation.\n\nTwo lightweight tools are in wide use that are more sensitive than ram penetrometers. A snow micro-penetrometer uses a motor to drive a rod into snow, measuring the force required; it is sensitive to 0.01–0.05 newtons, depending on the snow strength. A SABRE probe consists of a rod that is inserted manually into snow; accelerometer readings are then used to determine the penetrative force needed at each depth, and stored electronically.\n\nFor testing dense polar snow, a cone penetrometer test (CPT) is use, based on the equivalent devices used for soil testing. CPT measurements can be used in hard snow and firn to depths of 5–10 m.\n\nCommercially available rotary rigs have been used with large augers to drill in ice, generally for construction or for holes to gain access below the ice. Although they are unable to produce cores, they have been intermittently used by US and Soviet scientific expeditions in the Antarctic. In 2012, a British Antarctic Survey expedition to drill down to Lake Ellsworth, two miles below the surface of the Antarctic ice, used an Australian earth auger driven by a truck-mounted top drive to help drill two 300 m holes as part of the project, though in the event the project was delayed.\n\nPowered augers designed to drill large holes through ice for winter fishing may be mounted on a snow vehicle, or a tractor or sled; hole diameters can be as high as 350 mm. These rigs have been produced commercially in both the US and the USSR, but are no longer in common use.\n\nA flame-jet drill, more usually used to drill through crystalline rocks, was used to drill through ice on the Ross Ice Shelf, in the 1970s. The drill burns fuel oil, and can be run under water as long as enough compressed air is available. It drills rapidly, but produces an irregular hole contaminated by soot and fuel oil.\n\nA Soviet-designed drill used a motor to provide vertical vibration to the barrel of the drill at 50 Hz; the drill had an outer diameter of 0.4 m, and in tests at Vostok Station in the Antarctic drilled a 6.5 m hole, with a 1.2 m drilling run taking between 1 and 5 minutes to complete. The drill's steel edges compacted snow into the core, which helped it stick to the inside of the barrel when the drill was winched out of the hole.\n\nMechanical drills typically have three cutters, spaced evenly around the drill head. Two cutters leads to vibration and poorer ice core quality, and tests of drillheads with four cutters have produced unsatisfactory performance. Geometric design varies, but the relief angle, α, varies from 5–15°, with 8–10° the most common range in cold ice, and the cutting angle, , varies from 45° (the most common in cold ice) up to 90°. The safety angle, between the underside of the cutting blade and the ice, can be as low as 0.8° in successful drill designs. Different shapes for the end of the blade have been tried: flat (the most common design), pointed, rounded, and scoop shaped.\n\nCutters have to be made of extremely strong materials, and usually have to be sharpened after every 10–20 m of drilling. Tool steels containing carbon are not ideal because the carbon makes the steel brittle in temperatures below −20 °C. Sintered tungsten carbide has been suggested for use in cutters, since it is extremely hard, but the best tool steels are more cost effective: carbide cutters are fixed to the body of the cutting tool by cold pressing or brass soldering, and cannot easily be unmounted and sharpened in the field.\n\nThe cutting depth is controlled by mounting shoes on the bottom of the drill head; these ride on the ice surface and so limit how deep the cutter can penetrate in each revolution of the drill. They are most commonly mounted just behind the cutters, but this position can lead to ice accumulating in the gap between the cutter and the shoe. So far it has not proved possible to correct this by modifying the shoe design.\n\nDrilling fluids are necessary for borehole stability in deep cores, and can also be used to circulate cuttings away from the bit. Fluids used include water, ethanol/water and water/ethylene glycol mixtures, petroleum fuels, non-aromatic hydrocarbons, and n-butyl acetate.\nDensifiers are used in drilling fluids to adjust the density of the fluid to match the surrounding ice. Perchloroethylene and trichloroethylene were often used in early drilling programs, in combination with petroleum fuels. These have been phased out for health reasons. Freon was a temporary replacement, but has been banned by the Montreal Protocol, as has HCFC-141b, a hydrochlorfluorocarbon densifier used once Freon was abandoned. Future options for drilling fluids include low molecular weight esters, such as ethyl butyrate, n-propyl propionate, n-butyl butyrate, n-amyl butyrate and hexyl acetate; mixtures of various kinds of ESTISOL; and dimethyl siloxane oils.\n\nThe two main requirements of an anti-torque system are that it should prevent rotation of the sonde, and it should allow easy movement of the drill up and down the borehole. Attempts have been made to design drills with counter-rotating components so that overall torque is minimized, but these have had limited success. Five kinds of anti-torque systems have been devised for use with cable-suspended EM drills, though not all are in current use, and some drills have used a combination of more than one design. The first drill to require an anti-torque system was used at Camp Century by CRREL in 1966; the drill incorporated a set of hinged friction blades that swung out from the sonde when the drill motor was started. These were found to have very weak friction against the borehole wall, and were ineffective; the drill had to be controlled carefully to prevent twisting the cable. No other drills have attempted to use this approach.\n\nFor the next deployment of the drill leaf springs were installed, and this has proved to be a more durable design. These are mounted vertically, with a curve outwards so that they are easily compressed by the borehole wall, and can slide up and down with the movement of the drill. They pass easily through any areas of irregularity in the borehole, but the edges of the springs cut into the borehole wall and prevent rotation. Leaf springs are very simple mechanically, with the additional benefit of being easy to adjust by changing the spacing between the end points. They can be placed anywhere on the drill that does not rotate, so they do not add length to the sonde. The shape is usually a fourth-order parabola, since this has been determined to provide the most even loading against the borehole wall. Leaf springs have been found to be so effective that they can prevent rotation even in heavy drills running at full power.\n\nSkate antitorque systems have blades attached to vertical bars which are pushed against the borehole wall; the blades dig into the wall and provide the anti-torque. Skates can be built with springs which allow them to keep the blades pressed against the wall in an irregular borehole, and to prevent problems in narrower parts of the borehole. Although skates are a popular design for anti-torque and have been used with success, they have difficulty preventing rotation in firn and at boundaries between layers of different densities, and can cause problems when drilling with high torque. When they fail, they act as reamers, removing chips from the wall which can fall to the drillbit and interfere with drilling.\nIn the 1970s, the Japanese Antarctic Research Expedition (JARE) group designed several drills using side-mill cutters. These are toothed gears that are driven from the rotation of the main drill motor via 45° spiral gears; their axis of rotation is horizontal, and they are placed so that the teeth cut four vertical slots in the borehole wall. Guide fins higher on the sonde travel in these slots and provide the antitorque. The design was effective at preventing rotation of the sonde, but it proved to be almost impossible to realign the guide fins with the existing slots when tripping in. Misalignment increased the chance of the drill getting stuck in the borehole; and there was also a risk of ice cuttings from the mill cutters jamming in between the drill and the borehole wall, causing the drill to get stuck. The system was used again in a drill developed in China in the 1980s and 1990s, but the problems inherent in the design are now considered insuperable and it is no longer in use.\n\nThe most recent anti-torque system design is the use of U-shaped blades, made of steel and fixed vertically to the sides of the sonde. Initial implementations ran into problems with thin blades bending too easily, and thick blades providing too much resistance to vertical movement of the sonde, but the final design can generate strong resistance to torque in both firn and ice.\n\nDrills may be designed with more than one anti-torque system in order to take advantage of the different performance of the different designs in different kinds of snow and ice. For example, a drill may have skates to be used in hard firn or ice, but also have a leaf-spring system, which will be more effective in soft firn.\n\nIn ice core drilling, when an annulus has been drilled around the core to be retrieved, the core is still attached to the ice sheet at its lower end, and this connection has to be broken before the core can be retrieved. One option is to use a collet, which is a tapered ring inside the cutting head. When the drill is pulled up, the collet compresses the core and holds it, with loose ice chips wedged in it increasing the compression. This breaks the core and holds it in the barrel once it has broken. Collets are effective in firn but less so in ice, so core dogs, also known as core catchers, are often used for ice cores.\n\nA typical ice drill core dog has a dog-leg shape, and will be built into the drill head with the ability to rotate, and with a spring supplying some pressure against the core. When the drill is lifted, the sharp point of the core dog engages and rotates around, causing the core to break. Some core dogs have a shoulder to stop them from over-rotating. Most drill heads have three core dogs, though having only two core dogs is possible; the asymmetric shearing force helps break the core. The angle, , between the core dog point and the core, has been the subject of some investigation; a study in 1984 concluded that the optimum angle was 55°, and a later study concluded that the angle should be closer to 80°. Core catchers are made from hardened steel, and need to be as sharp as possible. The force required to break the core varies with temperature and depth, and in warm ice the core dogs may gouge grooves up the core before they catch and it breaks. Some drills may also include a weight that can be used as a hammer, to provide an impact to help in breaking the core.\n\nFor snow and firn, where the core material may be at risk of falling out of the bottom of the core barrel, a basket catcher is a better choice. These catchers consist of spring wires or thin pieces of sheet metal, placed radially around the bottom of the core barrel and pressed against the side of the barrel by the core as the drill descends around it. When the drill is lifted, the ends of the catcher engage with the core and break it from the base, and act as a basket to hold it in place while it is brought to the surface.\n\nCasing, or lining a hole with a tube, is necessary whenever drilling operations require that the borehole be isolated from the surrounding permeable snow and firn. Uncased holes can be drilled with fluid by using a hose lowered into the hole, but this is likely to lead to increased drilling fluid consumption and environmental contamination from leaks. Steel casing was used in the 1970s, but rust from the casing caused damage to the drills, and the casing was not sealed, leading to fluid leaks. There were also problems with the casing tubes not being centered, which caused damage to the drill bit as it was lowered through the casing. Fibreglass and HDPE casing has become more common, with junctions sealed with PTFE tape, but leaks are frequent. Heat fusion welding for HDPE casing is a possible solution. To seal the bottom of the casing, water can be pumped to the bottom of the hole once the casing is set, or a thermal head can be used to melt ice around the casing shoe, creating a seal when the water freezes again. Another approach is to use a hotpoint drill, saturating the snow and firn with melted water, which will then freeze and seal the borehole.\n\nLow-temperature PVC tubing is not suitable for permanent casing, since it cannot be sealed at the bottom, but it can be used to pass drilling fluid through the permeable zone. Its advantage is that it requires no connections since it can be coiled on a reel for deployment.\n\n\n"}
{"id": "15598656", "url": "https://en.wikipedia.org/wiki?curid=15598656", "title": "Immersive design", "text": "Immersive design\n\nImmersive design describes the activity of a new generation of designers who work inclusively across all story-driven media, from film and interactive media to live audience environments. Immersive designers deal simultaneously with virtual and dimensional environments and who and what they contain; and with time-based narrative and story space.\n\nAlex McDowell coined the phrase 'immersive design' in 2007 in order to frame a new discussion around a design discipline that uniquely addresses story-based media within the context of digital and virtual technologies. Together McDowell and museum director Chris Scoates co-directed 5D | The Future of Immersive Design conference in Long Beach 2008, laying the groundwork for immersive design to be a distinct design philosophy and thus be subject to wider scrutiny, development and promotion. 5D has since become a forum and community representing a broad range of cross-media designers with its intent based in education, cross-pollination and the development of an expanding knowledge base.\n\nHaving only been actively promoted as a design philosophy to be discussed internationally in recent years, immersive design is very much in its infancy, but as a term it has already been appropriated for the purposes of describing design for narrative media and the process of Worldbuilding. The rapid rise and recognition of transmedia and virtual production emphasises the need for immersive design as the single most fluid cross-media discipline.\n\nThe immersive design process attempts to describe two simultaneous entwined tasks:\n\nMany in the industry believe that it is recent developments in technology that have enabled both of these aspects of immersive design to exist; technology consisting of design tools that create a virtual workspace (an intuitive three-dimensional design language and vision) that allows for non-linear workflows, broadening the opportunity of what can be created. However, others argue that both of these aspects have always existed, believing that recent developments in technology have simply allowed these aspects to fit more easily into conventional mainstream production workflow. In relation to this, Alex McDowell has commented that \"It is probably true to say that the designer has always harnessed the best tools available, but that the potential of design tools based in digital technology and allowing for the interaction and manipulation of dimensional space fundamentally advances the craft.\" \n\nOne issue within the philosophical discussion of immersive design is how much immersive design should define itself by new technology, and by doing so, whether it narrows down its own possibilities as well as broadening them. Alex McDowell expanded on this by commenting \"What is clear is that technology will keep changing, and that the designer must become increasingly adept and adaptative while remaining focused on the creative intent.\" \n\n\n"}
{"id": "54051270", "url": "https://en.wikipedia.org/wiki?curid=54051270", "title": "Independent Engineer", "text": "Independent Engineer\n\nAn Independent Engineer, also known as the Lender's Engineer, is a term often given to the engineering representative of the lender, or financier, of a large capital project. The key is to be independent so that opinions on the technical aspects of the project are not biased either in favor of the lenders or the developer/owners. In order to maintain independence, the Independent Engineer is typically selected by the lender, but paid by the developer/owner. \n\nThe role of the Independent Engineer is to provide an independent technical assessment of a project or technical due diligence. The qualifications of an Independent Engineer are unusual in that in addition to understanding the engineering aspects of a project, the Independent Engineer must also be well versed in the business aspects of project financing. This includes the assessment of the technical aspects of major contracts such as EPC Contracts, Power Purchase Agreement, Off-take Agreements, Long Term Service Agreements, O&M Agreements, etc. Furthermore, the Independent Engineer will review the technical inputs (i.e. output, efficiency, O&M expenses, availability, etc.) to the financial model used by the lender and the developer/owner to justify the financing of the project.\n\nWhile the role of the Independent Engineer is similar to an Owner's engineer, they are distinctly different. An Independent Engineer will deal with the lenders and legal counsel on a regular basis to evaluate the financial health of the project as well as the technical aspects. Conversely, the Owner's Engineer is more often dealing directly with the engineer of record, the constructor, and equipment suppliers with a focus on ensuring that the technical details of the project meet the specifications.\n\nTypical scopes of work for an Independent Engineer often include:\n\n"}
{"id": "37579562", "url": "https://en.wikipedia.org/wiki?curid=37579562", "title": "KeyedIn Solutions", "text": "KeyedIn Solutions\n\nKeyedIn Solutions is an international business software company based in Bloomington, Minnesota.\n\nKeyedIn Solutions was founded in 2011 by George and Lauri Klaus. George Klaus was previously CEO of Epicor, which was purchased by private equity firm Apax Partners in April, 2011. George Klaus currently serves as chairman of the board for KeyedIn Solutions. Lauri Klaus, former executive vice president for Epicor, currently serves as the CEO of KeyedIn Solutions. \n\nIn December 2011, George Klaus and a group of investors purchased a majority interest in and management of Minneapolis-based Datacom International, an enterprise software company with applications focussing on the manufacturing industry. Datacom was renamed KeyedIn Solutions.\n\nIn February 2012, KeyedIn Solutions acquired Atlantic Global PLC, a Yorkshire, UK-based maker of project management and automation software, for $8 million. The products and consulting services from the acquired companies were rebranded as KeyedIn Projects.\n"}
{"id": "26009338", "url": "https://en.wikipedia.org/wiki?curid=26009338", "title": "LLNL HRS process", "text": "LLNL HRS process\n\nLLNL HRS (hot recycled solid) process is an above-ground shale oil extraction technology. It is classified as a hot recycled solids technology. \n\nThe process was developed by the Lawrence Livermore National Laboratory. In 1984–1987, Lawrence Livermore National Laboratory operated a LLNL HRS process-based pilot pant at Parachute, Colorado, with capacity of one tonne of oil shale per day. In 1989, the pilot plant was upgraded to process four tonne of oil shale per day. The pilot plant was operated till 1993. Later the process was modified and tested in the field of waste treatment and environmental cleanup for removing organic compounds and for decomposing sodium nitrate in contaminated soils.\n\nAs a heat carrier, LLNL HRS process uses spent oil shale. Raw oil shale and spent oil shale are mixed in the fluidized bed mixer. The use of fluidized bed mixer results in better mixture, which in turn increases the mean quantity of oil yield and oil shale throughput. From the fluidized bed mixer oil shale moves downward to the packed-bed pyrolyzer. The heat is transferred from the heated spent oil shale to the raw oil shale causing pyrolysis. As a result, oil shale decomposes to shale oil vapors, oil shale gas and spent oil shale. Oil vapors are collected from the pyrolyzer. The spent oil shale, still including residual carbon (char), by the air pneumatic lift pipe to the delayed-fall combustor where it is combusted to heat the process. The delayed-fall combustor used in this process gives greater control over the combustion process as compared to a lift pipe combustor. From the delayed-fall combustor the oil shale ash and spent shale falls into a fluidized bed classifier where the finest parts of solids are removed and hot spent shale is forwarded to the fluidized bed mixer.\n\n"}
{"id": "19365219", "url": "https://en.wikipedia.org/wiki?curid=19365219", "title": "Mail chute", "text": "Mail chute\n\nA mail chute is a largely defunct letter collection device used in early multi-storey office buildings, hotels, apartment buildings and other high rise structures. Letters were dropped from the upper storeys and collected (usually at the ground level) at a central depository by the postal service. This innovation was before the time of the modern \"mail room\" normally associated nowadays with high rise buildings. It was for the convenience of the users of the building so they would not have to take their mail to an outside mail box or to the post office.\n\nJames Goold Cutler received on September 11, 1883 for the mail chute. The first one was installed in 1884 in the Elwood Building in Rochester, New York. Cutler ultimately received thirty patents for variations of his invention. The original approved patent No. 284,951 design stated that it must \"be of metal, distinctly marked U.S. Letter Box,\" and that the \"door must open on hinges on one side, with the bottom of the door not less than 2'6\" above the floor.\" If the building were more than two stories tall, the collection box was to be outfitted with a cushion to prevent injury to the mail. The mail chutes had to be accessible along its entire length so lodged mail could be removed.\n\nThe first experimental \"Cutler mail chute\" device was successful at the Elwood Building so later it was installed in two New York City office buildings. Additional ones were then installed in railroad stations and some public buildings as a test. Eventually Cutler Mail Box produced over 1,600 such devices in buildings over the next twenty years. Then the postal service allowed \"Cutler mail chutes\" to be placed in hotels taller than five storeys. They were also installed in public apartment buildings of more than fifty apartments.\n\nIt was announced on Sunday, May 9, 1909, by \"The New York Times\", \"Cutler and Other Companies Join in a $2,000,000 Corporation\".\n\nIt is possible for clogs to form in a mail chute. For two weeks in 1986, more than 40,000 letters accumulated in the mail chute of the McGraw-Hill Building in New York City. In 1999, a spokesperson for the New York district of the Postal Service claimed that the service responded to two or three calls to clear stuck mail chutes every week.\n\nIn more recent decades, buildings such as Chicago's John Hancock Center, the Chrysler Building, and the old RCA Building in New York City have shut down their chutes. The reason is the increase of modern mail rooms in the building lobby with associated mail boxes available for the building tenants. There remain, however, about 360 buildings in Chicago with mail chutes, and more than 900 active chutes exist in Manhattan and the Bronx of New York City alone, as well as elsewhere. Since 1997, however, the National Fire Protection Association has banned mail chutes in all new building construction. Buildings currently using mail chutes in New York include the Chanin Building, Trinity Building, Empire State Building, Port Authority Bus Terminal, and in Boston the historic Lenox Hotel in the Back Bay. \n\nThe London Transport HQ at 55 Broadway had a system installed. The chute slot for 'London & Abroad' mail plate says 'Cutler Mailing-System Cutler-Mail-Chute-Co Rochester,NY,USA'.(As shown BBC 'Art Deco Icons: London Transport' TV programme aired Nov 09.)\nThe 14-story Richmond Trust Company Building (629 E. Main St., Richmond, VA)[a.k.a. Southern States Building or Virginia Department of Environmental Health Building], completed in 1922, has an inactive Cutler mail chute system. Hotel Saskatchewan in Regina, Manitoba, Canada still has an operational mail cutler system. Stelco Tower in Hamilton, Ontario, Canada, completed in 1973, also has an operational mail chute; a rare example of a mail chute in a modern skyscraper.\n\n"}
{"id": "47972925", "url": "https://en.wikipedia.org/wiki?curid=47972925", "title": "Managed Mobility Services", "text": "Managed Mobility Services\n\nManaged Mobility Services (MMS) is a term used by analysts and businesses to describe the outsourcing and managing services that many businesses provide.\n\nMobility Managed Services includes the IT and process management service needed for a company to acquire, provision and support smartphones, tablets and other field force devices. These services are designed to support devices for corporations are liable and provide a level of control to companies that support them by accessing corporate resources and information.\n\nManaged Mobility Services has existed for some time, but organizations have increasingly shifted responsibility for logistics and management as the environments have become more diverse and updates more frequent. Android fragmentation is sometimes cited as a driver of this growth as is the consumerization of IT, including the adoption of mobile devices by IT departments. This accumulation of influences has been referred to as \"The 3 V's\": Volume (the number of devices and users involved); Variety (policy changes in order to fit changing standards) and Volatility (high rates of change that could threaten the business).\n\nGartner includes the following categories of services:\n\nGartner first officially produced research on MMS in 2011 with Critical Capabilities for Managed Mobility Services, 22 December 2011, G00225198 Analyst(s): Eric Goodness, Phillip Redman.\n\nSince then Gartner, Forrester Research, GigaOM and other analyst organizations have published research on these services, each with slight variations on what services are included.\n\n"}
{"id": "55987530", "url": "https://en.wikipedia.org/wiki?curid=55987530", "title": "Mars Environmental Dynamics Analyzer", "text": "Mars Environmental Dynamics Analyzer\n\nThe Mars Environmental Dynamics Analyzer (MEDA) is an instrument on board the Mars 2020 rover that will characterize the dust size and morphology, as well as surface weather. Specifically, the information obtained will help address future human exploration objectives, as dust sizes and shapes, daily weather report and information on the radiation and wind patterns on Mars, that are critical for proper design of in situ resource utilization systems. MEDA is a follow-on project from REMS, of the \"Curiosity\" rover mission. MEDA has an increased scope, with greater data collection on Mars dust which contributes to overall Mars program objectives and discovery goals.\n\nThe instrument suite is being developed and provided by the Astrobiology Center at the Spanish National Research Council in Madrid, Spain. The Principal Investigator is José Antonio Rodríguez Manfredi.\n\nDust dominates Mars' weather the way that water dominates Earth's weather. Martian weather cannot be predicted unless dust behavior is studied and understood in the weather context. MEDA is a suite of environmental sensors designed to record dust optical properties and six atmospheric parameters: wind speed/direction, pressure, relative humidity, air temperature, ground temperature, and radiation (UV, visible, and IR ranges of the spectrum).\n\nThe technology used on MEDA was inherited from the REMS package operating on the \"Curiosity\" rover and the TWINS package on InSight lander. The sensors are located on the rover's mast and on the deck, front and interior of the rover's body. It records data whether the rover is active or not, at both day and night. The instruments will collect data for 5 minutes every 30 minutes.\n\n"}
{"id": "12766427", "url": "https://en.wikipedia.org/wiki?curid=12766427", "title": "Microcosm Ltd", "text": "Microcosm Ltd\n\nMicrocosm Ltd is a UK company established in 1979. Its early claims to fame included Silicon Disk System in 1981 and Microcache (the world's first disk cache for microcomputers) in 1982. \n\nSince 1989, it has concentrated on computer security, firstly with CopyControl (a software-based copy protection system), then Dinkey Dongle (small hardware copy protection keys that connect to parallel or USB ports). In 2005, it produced CopyMinder (software-based copy protection that uses the Internet where possible to provide an 'intelligent' copy protection system). More recently, it has expanded its security products by producing SmartSign, a multi-factor authentication system that supports using mobile devices to control access to web pages.\n\n\n"}
{"id": "5070486", "url": "https://en.wikipedia.org/wiki?curid=5070486", "title": "Mormyshka", "text": "Mormyshka\n\nMormyshka (or Mormishka, or Marmooska, ) is a sort of fishing lure or a jig. The word is derived from Russian word Mormysh () meaning Freshwater Shrimp (Gammarus).\n\nMormyshka was invented in the 19th century in Russia. The prototypes were big spoon lures used for ice fishing. Trying to imitate shrimps, anglers made lures smaller and changed the way of fixing them on the line. As a result, efficient lures appeared and were spread quickly among ice fishermen all around Russia and Scandinavia.\n\nMormyshka consists of a metallic head, often made of tungsten, and a hook soldered in it. There is a small vertical hole in the middle of the head where the line passes through.\nThe way to knot Mormyshka to the line is unusual, but is not difficult. The line is put through the hole and tied to the hook.\nWhen suspended, Mormyshka keeps an almost horizontal position, and the point of the hook is above its shank.\n\nSome mormyshkas have a Bead Head on the hook.\n\nIn contrast to Jig Heads, original Russian Mormyshka jigs have no up eye;\nMormyshkas are not always globe-shaped. There are many forms that provide different presentations to fish;\nUsually, high quality Mormyshka is not painted, but coated or plated with Nickel, Brass, Copper, Gold, Silver, or combination of two metals, that provides better attraction to fish.\n\nFor the past few years Mormyshka has been used in summer fishing as well with long poles and a float or a nod. It is used either with live bait or alone. Also, anglers use palmers tied on Mormyshkas.\n\n"}
{"id": "47382925", "url": "https://en.wikipedia.org/wiki?curid=47382925", "title": "Oculus Story Studio", "text": "Oculus Story Studio\n\nOculus Story Studio was an original animated virtual-reality film studio that was a division of Oculus VR. The studio was started by Oculus VR to pioneer animated virtual reality filmmaking and educate, inspire, and foster community for filmmakers interested in VR.\n\nStory Studio was founded in 2014 by Pixar veterans Saschka Unseld and Max Planck, as well as producer Edward Saatchi. The studio was publicly announced and premiered its first film, Lost, at the 2015 Sundance Film Festival. In 2016 the studio's second film, \"Henry\", won the Emmy for Outstanding Original Interactive Program.\n\nOculus announced in May 2017 that the studio had been closed.\n\nThe studio produced three films before being shut down.\n\nLost was the first film released by Oculus Story Studio. Directed by studio Creative Director Saschka Unseld. The film drops viewers in the middle of the woods at night to witness a robot searching for its misplaced hand.\n\nHenry is the second film released by Oculus Story Studio, directed by Ramiro Lopes Dau and narrated by Elijah Wood. Henry is the story of a hedgehog who has trouble making friends. Henry premiered at an event in Hollywood on July 28, 2015.\n\nHenry became the first original VR short to win the Emmy for Outstanding Original Interactive Program.\n\nThe third project from Oculus Story Studio, Dear Angelica, premiered at the 2017 Sundance Film Festival. The film was directed by Saschka Unseld, produced by Edward Saatchi, illustrated by Wesley Allsbrook, and featured music by Drazen Bosnjak and Sarah Jaffe. It stars Geena Davis and Mae Whitman in a \"visually splendid and deeply human journey through memory, loss, and the magic of a valorous life.\" The film was animated entirely with the Oculus Quill, a VR drawing and sculpting application.\n"}
{"id": "2536075", "url": "https://en.wikipedia.org/wiki?curid=2536075", "title": "Oil depletion", "text": "Oil depletion\n\nOil depletion is the decline in oil production of a well, oil field, or geographic area. The Hubbert peak theory makes predictions of production rates based on prior discovery rates and anticipated production rates. Hubbert curves predict that the production curves of non-renewing resources approximate a bell curve. Thus, according to this theory, when the peak of production is passed, production rates enter an irreversible decline.\n\nThe United States Energy Information Administration predicted in 2006 that world consumption of oil will increase to (mbd) in 2015 and 118 million barrels per day in 2030. With 2009 world oil consumption at 84.4 mbd, reaching the projected 2015 level of consumption would represent an average annual increase between 2009 and 2015 of 2.7% per year.\n\nThe World's natural oil supply is fixed because petroleum is naturally formed far too slowly to be replaced at the rate at which it is being extracted. Over many millions of years, plankton, bacteria, and other plant and animal matter became buried in sediments on the ocean floor. When conditions were right – a lack of oxygen for decomposition, and sufficient depth and temperature of burial – these organic remains were converted into petroleum compounds, while the sediment accompanying them was converted into sandstone, siltstone, and other porous sedimentary rock. When capped by impermeable rocks such as shale, salt, or igneous intrusions, they formed the petroleum reservoirs which are exploited today.\n\nFor the short and medium-term, oil production decline occurs in a predictable manner based on geological circumstances, governmental policies, and engineering practices. The shape of the decline curve varies depending upon whether one considers a well, a field, or a set of fields. In the longer term, technological developments have defied some of the predictions.\n\nAn individual oil well usually produces at its maximum rate at the start of its life; the production rate eventually declines to a point at which it no longer produces profitable amounts. The shape of the decline curve depends on the oil reservoir and the reservoir drive mechanism. Wells in water-drive and gas-cap drive reservoirs often produce at a near constant rate until the encroaching water or expanding gas cap reaches the well, causing a sudden decline in oil production. Wells in gas solution drive and oil expansion drive reservoirs have exponential or hyperbolic declines: rapid declines at first, then leveling off.\n\nThe shape of production curve of an oil well can also be affected by a number of nongeologic factors:\n\nIndividual oil wells are typically within multi-well oil fields. As with individual wells, the production curves for oil fields vary depending on geology and how they are developed and produced. Some fields have symmetric bell-shaped production profiles, but it is more common that the period of inclining production is briefer and steeper than the subsequent decline. More than half the production usually occurs after a field has reached a peak or plateau. Production profiles of many fields show distinct peaks, but for giant oil fields, it is more common for production to reach and maintain a plateau before declining. Once a field declines, it usually follows an exponential decline. As this decline levels off, production can continue at relatively low rates. A number of oil fields in the U.S. have been producing for over 100 years.\n\nOil field production curves can be modified by a number of factors:\n\nMost oil is found in a small number of very large oil fields. According to Hubbert peak theory, production starts off slowly, rises faster and faster, then slows down and flattens until it reaches a peak, after which production declines. In the late stage, production often enters a period of exponential decline in which the decline becomes less and less steep. Oil production may never actually reach zero, but eventually becomes very low.\nFactors which can modify this curve include:\n\nOil production in the United States, provided one excludes Alaska, began by following the theoretical Hubbert curve for a few decades but is now deviating strongly from it. U.S. oil production reached a peak in 1970 and by the mid-2000s it had fallen to 1940s levels. In 1950, the United States produced over half the world's oil, but by 2005 that proportion had dropped to about 8%. In 2005, U.S. crude oil imports peaked at a rate twice as high as domestic production; since then, U.S. oil production has increased, and imports have fallen 41%.\n\nThe production peak in 1970 was predicted by one of the two projections put forward in 1956 by Hubbert. By 1972 all import quotas and controls on U.S. domestic production had been removed. Despite this, and despite the quadrupling of prices during the 1973 oil crisis, the production decline was not reversed in the lower 48 states until 2009. Crude oil production has since risen sharply from 2009 through 2014, so that the rate of US oil production in October 2014 was 81% higher than the average rate in 2008.\n\nThe actual U.S. production curve deviates from Hubbert's 1956 curve in significant ways:\n\nThe 1970 production peak in the U.S. caused many people to begin to question when the world production peak would occur. The peak of world production is known as Peak oil.\n\nA peak in oil production could result in a worldwide oil shortage, or it could not even be noticed as demand decreases in conjunction with increased prices. While past shortages stemmed from a temporary insufficiency of supply, crossing Hubbert's Peak would mean that the production of oil would continue to decline, and that demand for these products must be reduced to meet supply. The effects of such a shortage would depend on the rate of decline and the development and adoption of effective alternatives.\n\nThe use of fossil fuels allows humans to participate in takedown, which is the consumption of energy at a greater rate than it is being replaced. The industrial economy is currently heavily dependent on oil as a fuel and chemical feedstock. For example, over 90% of transportation in the United States relies on oil.\n\nSince the 1940s, agriculture has dramatically increased its productivity, due largely to the use of chemical pesticides, fertilizers, and increased mechanisation. This process has been called the Green Revolution. The increase in food production has allowed world population to grow dramatically over the last 50 years. Pesticides rely upon oil as a critical ingredient, and fertilizers require natural gas. Farm machinery also requires oil.\n\nMost or all of the uses of fossil fuels in agriculture can be replaced with alternatives. For example, by far the biggest fossil fuel input to agriculture is the use of natural gas as a hydrogen source for the Haber-Bosch fertilizer-creation process. Natural gas is used simply because it is the cheapest currently available source of hydrogen; were that to change, other sources, such as electrolysis powered by solar energy, could be used to provide the hydrogen for creating fertilizer without relying on fossil fuels.\n\nOil shortages may force a move to lower input \"organic agriculture\" methods, which may be more labor-intensive and require a population shift from urban to rural areas, reversing the trend towards urbanisation which has predominated in industrial societies; however, some organic farmers using modern organic-farming methods have reported yields as high as those available from conventional farming, but without the use of fossil-fuel-intensive artificial fertilizers or pesticides.\n\nAnother possible effect would derive from modern transportation and housing infrastructure. A large proportion of the developed world's population live in suburbs, a type of low-density settlement designed with the automobile in mind. A movement to deal with this problem early, called \"New Urbanism,\" seeks to develop the suburbs into higher density neighborhoods and use high density, mixed-use forms for new building projects.\n\nA more modest scenario, assuming a slower rate of depletion or a smoother transition to alternative energy sources, could still cause substantial economic hardship such as a recession or depression due to higher energy prices. Inflation has also been linked to oil price spikes. However, economists disagree on the strength and causes of this association. See Energy crisis.\n\nRising oil prices cause rising food prices in three ways. First, increased equipment fuel costs drive higher prices. Second, transportation costs increase retail prices. Third, higher oil prices are causing farmers to switch from producing food crops to producing biofuel crops.\n\nAn alternative considered likely by some is that oil will be replaced with renewable energy during the first half of the 21st century. The replacement fuel would likely be hydrogen. A hydrogen economy would then replace the current oil-based economy. Another possible replacement fuel is biogas, which is composed of methane. Methane has boiling point of −161 °C, rather than hydrogen's -252.87 °C, making methane a much easier fuel to condense.\n\nOther people consider that the whole idea of \"the hydrogen economy\" is flawed. Compressed hydrogen has an energy density of only 5.6 megajoules per liter. Robert Zubrin looks at the practical problems of using hydrogen as an energy storage medium in \"Energy Victory: Winning the War on Terror by Breaking Free of Oil\". He considers that hydrogen is a very poor form of storage, and that batteries, methanol or dimethyl ether would be better. This point is reiterated in \"Beyond Oil and Gas: The Methanol Economy\" and in David MacKay's book described below.\n\nGeothermal power is one source of sustainable energy that can produce hydrogen. Note that David MacKay has shown in his book \"Sustainable Energy: Without the Hot Air\" that geothermal can only provide a tiny fraction of the world's needs sustainably. In some areas located over geological hotspots (such as Iceland), geothermal makes more sense.\n\nSolar energy is a source of inexhaustible energy. There is more solar energy that reaches the surface of the Earth each hour than the amount of energy consumed by the world in a year. The challenges of using the sun's energy – energy which can be obtained either from wind power or from solar power – is that the energy needs to either be (1) stored in physical form of fuel for when it can be used in the future, or (2) transported directly as electricity, through transmission lines. Neither is dispatchable, as there is no control over when the sun will shine or when the wind will blow. There are, however, concentrated solar power plants using thermal storage that can store energy efficiently for up to 24 hours.\n\n\n\nOil Education Television: Series of video interviews with leading international oil experts: http://oileducation.tv, https://www.youtube.com/oileducationtv\n"}
{"id": "45017791", "url": "https://en.wikipedia.org/wiki?curid=45017791", "title": "Omni Processor", "text": "Omni Processor\n\nOmni Processor is a name proposed by the Bill & Melinda Gates Foundation for a group of physical, biological or chemical treatment processes to process fecal sludge – a mixture of human excreta and water – in developing countries. One of the main treatment aims is pathogen removal to stop the spread of disease from fecal sludge. The term was created by staff of the Water, Sanitation, Hygiene Program at the Bill & Melinda Gates Foundation in 2012. It is not a trade mark for one specific product or technology. Several research teams are currently developing various types of omni processors with funding from the foundation. Examples of technologies which Omni Processors may employ include combustion, supercritical water oxidation and pyrolysis.\n\nThe term \"omni\" in its name refers to the fact that an Omni Processor machine can process a variety of waste streams or fuel sources.\n\nSince 2012, the Bill & Melinda Gates Foundation has been funding research into what they have named \"Omni Processors\". An Omni Processor (OP) is any of various types of technologies that treat fecal sludge, also known as septage. The aim of the treatment is to remove all pathogens and at the same time to generate outputs of commercial value. These beneficial products can be energy and soil nutrients and might have the potential to allow a development of local business and revenue. The soil nutrients could be used as a form of reuse of excreta in agriculture. The Omni Processor program targets community scale solutions that may combine fecal sludge and solid waste processing. It complements the foundation's pit latrine emptying (\"Omni-Ingestor\") and \"Reinvent the Toilet\" investment programs.\n\nThe Omni Processor is targeted as a solution for developing countries, although challenges around technical and financial aspects remain. Omni Processors and Omni Ingestors are being designed to provide an alternative to sewerage system-based technologies. They are also intended to address the large number of existing pit latrines which lack a supporting infrastructure of fecal sludge collection and processing when the pits are full. Sludge from pit latrines has to be removed from the pits for treatment and disposal either by pumping (if the fecal sludge is sufficiently liquid) or by manual emptying with shovels or other devices (in India, this practice is called manual scavenging). Despite new low-cost pumps being developed, only a small fraction of sludge is safely extracted and treated currently in many African and Asian cities.\n\nIt will be necessary to adapt established technologies in ways to fit developing world communities. The success of such technologies will depend on how well the process is managed.\n\nThe U.S.-based company Janicki Bioenergy presented in 2014 a prototype using combustion. Their process is a sewage sludge treatment system that produces drinking water and electrical energy as end products from sewage sludge. Manufactured by Janicki Bioenergy, the proof of concept model was funded by the Bill and Melinda Gates Foundation. The S100 prototype model can produce 10,800 liters of drinking water per day and 100 kW net electricity. A larger model under development, the S200, is designed to handle the waste from 100,000 people, produce 86,000 litres of drinking water per day and 250 kW net output electricity. These systems are designed to provide a \"self-sustaining bioenergy\" process.\n\nThe treatment process first involves boiling the sewage sludge, during which water vapour is boiled off and recovered. A dry sludge is left behind which is then combusted as fuel to heat a boiler. This boiler produces steam and the heat necessary for the boiling process. The steam is then used to generate electrical energy. Some of this electrical energy is used for the final water reverse osmosis purification stages to produce safe drinking water, and to power ancillary pumps, fans and motors.\n\nA pilot project of Janicki Bioenergy's Omniprocessor was installed in Dakar, Senegal, in 2015 and can now treat the fecal sludge of 50,000-100,000 people.\n\nThe U.S.-based NGO Climate Foundation, in collaboration with Stanford University, has built several pilot-scale reactors to treat human waste and turn it into biochar, which can be used as an agricultural soil amendment.\n\nScientists at Duke University in the U.S. have developed and are testing a prototype fecal sludge treatment unit that fits in a 20-foot shipping container and treats the fecal matter of roughly 1000 people using supercritical water oxidation.\n\nUnilever PLC in the United Kingdom is developing a pyrolysis-based fecael sludge treatment unit designed to serve over 2000 people.\n\nThe Omni Processor initiative for processing fecal sludge is being complemented by an effort to develop new technologies for improved pit latrine emptying (called by the Gates Foundation the “Omni Ingestor”) and by the Reinvent the Toilet Challenge. The latter is a long-term research and development effort to develop a hygienic, stand-alone toilet. It is focused on \"reinventing the flush toilet\". The aim is to create a toilet that not only removes pathogens from human excreta, but also recovers resources such as energy, clean water, and nutrients (a concept also known as reuse of excreta). It should operate “off the grid” without connections to water, sewer, or electrical networks. Finally, it should cost less than 5 US-cents per user per day.\n\nIn a publicity stunt in late 2014, Bill Gates drank the water produced from Janicki Bioenergy's Omni Processor system, causing widespread media attention. In early 2015, Gates appeared on \"Late Night With Jimmy Fallon\" and challenged Fallon to see if he could taste the difference between water from this particular \"Omni Processor\" or bottled water.\n\n"}
{"id": "10697195", "url": "https://en.wikipedia.org/wiki?curid=10697195", "title": "Open Solutions Alliance", "text": "Open Solutions Alliance\n\nThe Open Solutions Alliance (OSA) is a trade association. The OSA works with ISVs, system integrators, and the broader open source software community to improve interoperability among software products by publishing best practices, promoting technical standards, and making tools and application programming interfaces available.\n\nIn early November 2006, a group of application developers got together to form an alliance dedicated to improving interoperability and awareness of their products. Open source development had proven itself at the operating system and middleware layers but had yet to make a significant impact at the application level. Founders identified three important areas where collective action could be successful in lowering barriers to adoption of open solutions by business users:\n\n\nAll of those present agreed that none of these challenges could be readily addressed by any one vendor in isolation. Issues of awareness, interoperability and community are inherently collective in nature, such that collective action is needed to address them. This led to the decision to create a trade association. The result was the OSA.\n\nIn December 2006, The Open Solutions Alliance was incorporated as a 501c6 in the State of California, and the initial founding members officially joined during January 2007.\n\nNotable members of OSA include Palamida, CSC, Concursive Corporation, Ingres Corporation, IONA, Jaspersoft, Openbravo, SourceForge.net, and Unisys.\n"}
{"id": "3132996", "url": "https://en.wikipedia.org/wiki?curid=3132996", "title": "Oxyhydrogen", "text": "Oxyhydrogen\n\nOxyhydrogen is a mixture of hydrogen (H) and oxygen (O) gases. This gaseous mixture is used for torches to process refractory materials and was the first\ngaseous mixture used for welding. Theoretically, a ratio of 2:1 hydrogen:oxygen is enough to achieve maximum efficiency; in practice a ratio 4:1 or 5:1 is needed to avoid an oxidizing flame.\n\nThis mixture may also be referred to as (Scandinavian and German Knallgas: \"bang-gas\"), although some authors define knallgas to be a generic term for the mixture of fuel with the precise amount of oxygen required for complete combustion, thus 2:1 oxyhydrogen would be called \"hydrogen-knallgas\".\n\nThe term Brown's gas refers to oxyhydrogen with a 2:1 molar ratio of H and O gases, the same proportion as in water. It was named after its Bulgarian inventor Yull Brown (born Iliya Valkov, ), who suggested it to be produced by the electrolysis of water to be used as a fuel for the internal combustion engine. Later \"Brown's gas\" and HHO has become a fringe science term for a 2:1 mixture of oxyhydrogen obtained under certain special conditions; its proponents claim that it has special properties.\n\nOxyhydrogen will combust when brought to its autoignition temperature. For the stoichiometric mixture, 2:1 hydrogen:oxygen, at normal atmospheric pressure, autoignition occurs at about 570 °C (1065 °F). The minimum energy required to ignite such a mixture with a spark is about 20 microjoules. At standard temperature and pressure, oxyhydrogen can burn when it is between about 4% and 95% hydrogen by volume.\n\nWhen ignited, the gas mixture converts to water vapor and releases energy, which sustains the reaction: 241.8 kJ of energy (LHV) for every mole of burned. The amount of heat energy released is independent of the mode of combustion, but the temperature of the flame varies. The maximum temperature of about is achieved with an exact stoichiometric mixture, about hotter than a hydrogen flame in air.\nWhen either of the gases are mixed in excess of this ratio, or when mixed with an inert gas like nitrogen, the heat must spread throughout a greater quantity of matter and the temperature will be lower.\n\nA pure stoichiometric mixture may be obtained by water electrolysis, which uses an electric current to dissociate the water molecules:\nWilliam Nicholson was the first to decompose water in this manner in 1800. In theory, the input energy of a closed system will always equal the output energy, as the first law of thermodynamics states. However, in practice no systems are perfectly closed, and the energy required to generate the oxyhydrogen will always exceed the energy released by combusting it, even at maximum practical efficiency, as the second law of thermodynamics implies. (See Electrolysis of water#Efficiency).\n\nMany forms of oxyhydrogen lamps have been described, such as the limelight, which used an oxyhydrogen flame to heat a piece of lime to white hot incandescence. Because of the explosiveness of the oxyhydrogen, limelights have been replaced by electric lighting.\n\n The foundations of the oxy-hydrogen blowpipe were laid down by Carl Wilhelm Scheele and Joseph Priestley around the last quarter of the eighteenth century. The oxy-hydrogen blowpipe itself was developed by the Frenchman Bochard-de-Saron, the English mineralogist Edward Daniel Clarke and the American chemist Robert Hare in the late eighteenth and early nineteenth centuries. It produced a flame hot enough to melt such refractory materials as platinum, porcelain, fire brick, and corundum, and was a valuable tool in several fields of science. It is used in the Verneuil process to produce synthetic corundum.\n\nAn \"oxyhydrogen torch\" (also known as \"hydrogen torch\") is an oxy-gas torch that burns hydrogen (the fuel) with oxygen (the oxidizer). It is used for cutting and welding, metals, glass, and thermoplastics.\n\nDue to competition from the acetylene-fueled cutting torch and from arc welding, the oxyhydrogen torch is seldom used today, but it remains the preferred cutting tool in some niche applications—see oxy-fuel welding and cutting.\n\nOxyhydrogen was once used in working platinum because at the time such a torch was the only device that could attain the temperature required to melt the metal . These techniques have been superseded by the electric arc furnace.\n\nBrown's gas has become associated with various exaggerated claims. It's also called \"HHO gas\" after the claims of fringe physicist Ruggero Santilli, who claims that his HHO gas, produced by a special apparatus, is \"a new form of water\", with new properties, based on his fringe theory of \"magnecules\". (\"MagneGas\" or \"MagneHydrogen\") .\n\nMany other pseudoscientific claims have been made about Brown's gas's pretended ability to neutralize radioactive waste, help plants to germinate, etc.\n\nOxyhydrogen is often mentioned in conjunction with vehicles that claim to use water as a fuel. The most common and decisive counter-argument against producing this gas on board to use as a fuel or fuel additive is that more energy is needed to split water molecules than is recouped by burning the resulting gas. Additionally, the volume of gas that can be produced for on-demand consumption through electrolysis is very small in comparison to the volume consumed by an internal combustion engine.\n\nAn article in \"Popular Mechanics\" reported that Brown's gas does not increase the fuel economy in automobiles.\n\n\"Water-fueled\" cars should not be confused with hydrogen-fueled cars, where the hydrogen is produced elsewhere and used as fuel or where it is used as fuel enhancement.\n"}
{"id": "55104779", "url": "https://en.wikipedia.org/wiki?curid=55104779", "title": "Poudrerie nationale de Vonges", "text": "Poudrerie nationale de Vonges\n\nThe Poudrerie nationale de Vonges (Vonges National Powder Mill) is a French powder mill established in 1691 in Vonges, Côte-d'Or.\nIt manufactured explosives for use in quarries, mines and fireworks.\nDuring World War I (1914–18) it manufactured munitions.\nIt expanded after the war, producing explosives for civil use. \nDuring World War II (1939–45) production was scaled back drastically, but expanded again after the war.\nThe powder mill was fully privatized in 2008.\n\nThe powder mill is located in the communes of Vonges and Pontailler-sur-Saône, east of Dijon in the department of the Côte d'Or. \nThe site is bounded by the Bèze and Saône rivers.\nEtienne Berthelot de Planeuf, Commissary General of Powders and Saltpeter, leased the site beside the Bèze river on 20 February 1691 to build two powder mills, a powder grinder, a winter dryer, a powder magazine and a small refinery. \nThe five year leases were renewed until July 1753, when the site was purchased outright by Charles-Emmanuel Pioche, Inspector-General of Powder and Saltpeter. \nA decree by the King in the Council of State of 18 January 1757 confirmed that the contract was perpetual.\nThe facilities were expanded with another powder mill, a moulder and a shed.\n\nThe General Services buildings were erected in 1810–13, and another powder magazine was built in 1825.\nFurther extensions began in 1839, and the facilities were completely overhauled.\nThere were offices, manufacturing buildings and dwellings to the east of the powder mill, and around a yard to the west there were storage buildings, carpentry and cooperage workshops.\nBetween 1840 and 1850 two canals were built to supply hydraulic machinery.\nEarth banks and rows of trees secured the site.\n\nThe main products produced by the Vonges powder mill were gunpowder, potassium chlorate powders (Cheddite type powders) and nitrogenous and chlorinated explosives.\nPrivate companies packaged the powders into cartridges for mine and quarry explosives.\nThe institution also conducted surveillance and inspection of industrial establishments and fireworks factories using the explosives.\nThe number of products increased through the 19th and early 20th century.\nThe facility developed manufacture of chlorate explosives, or \"mine powders\", for use in iron ore mines in the Briey basin.\nIn 1870 the mill was one of four military powder works, under the direction of an artillery colonel.\nOn 31 May 1873 the powder mill held an auction of of glycerol, of sulfuric acid and of nitric acid.\nIn the 1870s another were added for a dynamite factory.\nThe official composition of the dynamite at this and other French powder works was 75% nitroglycerin, 20.8% randanite silica, 3.8% Vierzon silica and 0.4% magnesium carbonate.\nThere were explosions in 1881 and 1882.\nProduction of dynamite was stopped in 1885.\nIn September 1887 the powder mill sold of dynamite to the Société générale de dynamite in Paris that was declared to be superior but was found to be inert.\nThe dynamite was of very low quality, with the cartridges holding about 30% nitroglycerin.\nIn 1875 the powder mill covered over .\nIn 1876 a small amount of land was acquired for more buildings.\nAn earth embankment was built in 1877.\nBuildings continued to be added or rebuilt in the years that followed, including factories, sheds and lodgings, and trees were planted.\nAs of 1890 the powder mill covered and employed 204 workers.\n\nBy 1891 the powder mill was one of ten in France, the others being at Esquerdes, Saint-Poncy, Le Ripault (Monts, Indre-et-Loire), Pont de Buis, Angoulême, Saint-Chamas, Toulouse, Saint-Médard and Sevran-Livry.\nAt the start of the 20th century the powder mill manufactured gunpowder, picric acid, cresylite (trinitrocresol and picric acid), TNT, Cheddites and the \"prométhée\" explosive.\n\nAt the start of the World War I (1914–18) the site covered , and had an interior network of Decauville railways between the facilities.\nThe daily production capacity was 4 tons of gunpowder, 7 tons of melinite, 5 tons of cheddite and 1 ton of nitronaphthalene, produced by 281 workers.\nCapacity expanded steadily to produce a greater quantity and variety of explosives.\nThe powder mill was connected to the Auxonne-Gray railway line, and the internal railway network was expanded.\nA wharf was built on the Saône for water transport.\nThe manufacturing and storage facilities were expanded and barracks were built to house a rapidly growing workforce.\nThe mining engineer Jules Aubrun was assigned to the powder mill in 1915–16.\n\nBy May 1918 the facility covered and employed 2,744 workers.\nOf these, 384 were civilian workers, 1,170 were enlisted workers and 1,142 were Algerians and colonials. \nThe others were managers, engineers and technicians.\nAfter the war production of gunpowder for use in the mines expanded, and production of \"Yonckite\" and Favier explosives began.\nThere was an explosion on 7 July 1920, after which the manufacture of chlorate explosives was reorganized.\nBetween 1920 and 1938 the number of employees and workers varied from 407 to 530.\nBy 1928 the site had been expanded through land purchases to .\nA decree of 23 September 1934 classified the mill as being used for storage, handling and manufacture of powders, ammunition, fireworks and explosives, and defined a polygon of isolation around it.\n\nLouis Jean Charles Maurel was the chief engineer at Vonges at the outbreak of World War II until June 1940. \nHe later joined the Armée secrète (AS), was arrested in October 1943 and was shot in February 1944.\nDuring World War II (1939-45) German troops entered Vonges on 15 June 1940, and the French retreated to Toulouse.\nItalian aircraft bombed the facility on 16 June 1940 and destroyed the General Service buildings.\nThe personnel returned from Toulouse in August 1940.\nProduction of explosives and gunpowder resumed in October 1940 at a reduced level, since the powder mill could not supply customers in the unoccupied zone of France.\nDelivery wagons were requisitioned by the German authorities, preventing deliveries, and the growth of stocks raised the risk of explosions.\n\nAfter December 1940 the Germans took control of the facility and authorized deliveries of powders and explosives to the mines.\nStarting in 1943 the operation was severely affected by workers being requisitioned to work in Germany, and others leaving the powder mill to avoid being sent to Germany.\nThe number of workers dropped from 311 to 174, and output dropped correspondingly.\nAfter the Liberation of France the personnel were purged before production was restarted.\n\nIn the 1950s the French powder mills expanded their exports.\nIn 1957 the Vonges facility covered , of which were wooded.\nIn the late 1960s there were 500 employees producing gunpowder and nitrate and chlorate explosives.\nAround this time the mill diversified into producing composite materials and industrial paint.\nA decree of 19 March 1963 extended the polygon of isolation.\nThe powder mill included a medical service, a social service and a school for apprentices.\nOn 28 February 1970 as part of a reform of the Powder Department the Esquerdes Powder Mill in the Pas de Calais was closed and annexed to the Vonges Powder Mill.\n\nIn 1971 the Société Nationale des Poudres et Explosifs (SNPE) took over all the manufacturing and sales of the government's powder department, including the Vonges Powder Mill, which continued to manufacture gunpowder and industrial explosives cartridges, as well as plastic parts for industrial use.\nThe state was the majority shareholder in the SNPE.\nIn 1995 Nobel explosifs France was created as a subsidiary of SNPE.\nIn 2008 this subsidiary was merged with the private company Titanite to create Titanobel, now fully private.\nAs of 2012 the Vonges Power Mill was operated by Titanobel.\nTitanobel SAS manufactures and markets explosives in France and abroad for use in mines, quarries and other works.\nA decree of 1 July 2013 repealed the repealed the decrees of 1934 and 1963 that defined the site's use and its polygons of isolation.\n\n"}
{"id": "1007030", "url": "https://en.wikipedia.org/wiki?curid=1007030", "title": "Project Longshot", "text": "Project Longshot\n\nProject Longshot was a conceptual interstellar spacecraft design. It would have been an unmanned probe, intended to fly to and enter orbit around Alpha Centauri B powered by nuclear pulse propulsion.\n\nDeveloped by the US Naval Academy and NASA, from 1987 to 1988, Longshot was designed to be built at Space Station \"Freedom\", the precursor to the existing International Space Station. Similar to Project Daedalus, Longshot was designed with existing technology in mind, although some development would have been required. For example, the Project Longshot concept assumes \"a three-order-of-magnitude leap over current propulsion technology\".\n\nUnlike Daedalus, which used an open-cycle fusion engine, Longshot would use a long-lived nuclear fission reactor for power. Initially generating 300 kilowatts, the reactor would power a number of lasers in the engine that would be used to ignite inertial confinement fusion similar to that in Daedalus. The main design difference is that Daedalus also relied on the fusion reaction to power the ship, whereas in the Longshot design the internal reactor would provide this power.\n\nThe reactor would also be used to power a laser for communications back to Earth, with a maximum power of 250 kW. For most of the journey, this would be used at a much lower power for sending data about the interstellar medium; but during the flyby, the main engine section would be discarded and the entire power capacity dedicated to communications at about 1 kilobit per second.\n\nLongshot would have a mass of at the start of the mission including 264 tonnes of helium-3/deuterium pellet fuel/propellant. The active mission payload, which includes the fission reactor but not the discarded main propulsion section, would have a mass of around 30 tonnes.\n\nA difference in the mission architecture between Longshot and the Daedalus study is that Longshot would go into orbit about the target star while the higher speed Daedalus would do a one shot fly-by lasting a comparatively short time.\n\nThe journey to Alpha Centauri B orbit would take about 100 years, at an average velocity of approximately 13,411 km/s (about 4.5% the speed of light) and another 4.39 years would be necessary for the data to reach Earth.\n\nAccording to the Journal article \"Alpha Centauri: Our First target for Interstellar Probes,\" after the completion of the New Horizons primary mission of Pluto Fly-By, we should set our sights at other star systems like Alpha Centauri. This would be a good target because of its proximity to Earth.\n\n\nBeals, K. A., M. Beaulieu, F. J. Dembia, J. Kerstiens, D. L. Kramer, J. R. West and J. A. Zito. \"Project Longshot: An Unmanned Probe To Alpha Centauri.\" U S Naval Academy. NASA-CR-184718. 1988.\n\n (Please note that the article cited here refers to an Alpha and Beta Centauri as the orbital target of the mission, but the correct nomenclature for these two components of the Alpha Centauri binary star system is Alpha Centauri A and B. Beta Centauri is an entirely different, unassociated star.)\n"}
{"id": "309987", "url": "https://en.wikipedia.org/wiki?curid=309987", "title": "Runt pulse", "text": "Runt pulse\n\nIn digital circuits, a runt pulse is a narrow pulse that, \ndue to non-zero rise and fall times of the signal, does not reach a valid \nhigh or low level. A runt pulse may occur when switching between \nasynchronous clocks; or as the result of a race condition in which a signal takes two separate paths through a circuit, which may have different delays, and is then recombined to form a glitch; or when the output of a flip-flop becomes metastable.\n\nSome oscilloscopes provide a method for triggering on runt pulses. The oscilloscope triggers when the signal crosses one of two voltage thresholds, but not both.\n"}
{"id": "276773", "url": "https://en.wikipedia.org/wiki?curid=276773", "title": "SAP SE", "text": "SAP SE\n\nSAP SE (; , \"Systems, Applications & Products in Data Processing\") is a German-based European multinational software corporation that makes enterprise software to manage business operations and customer relations. SAP is headquartered in Walldorf, Baden-Württemberg, Germany with regional offices in 180 countries. The company has over 335,000 customers in over 180 countries. The company is a component of the Euro Stoxx 50 stock market index.\n\nXerox aimed to exit to the computer industry in 1975, it asked IBM to migrate its business systems to IBM technology. As part of IBM's compensation for the migration, IBM was given the rights to the Scientific Data Systems (SDS)/SAPE software, reportedly for a contract credit of $80,000.\n\nFive IBM engineers from the AI department (Dietmar Hopp, Klaus Tschira, Hans-Werner Hector, Hasso Plattner, and Claus Wellenreuther, all from Mannheim, Baden-Württemberg) were working in an enterprise-wide system based on this software, only to be told that it would no longer be necessary. Rather than abandoning the project, they decided to leave IBM Tech and start another company.\n\nIn June 1972, they founded the (\"System Analysis and Program Development\" / \"SAPD\") company, as a private partnership under the German Civil Code.\n\nTheir first client was the German branch of Imperial Chemical Industries in Östringen, where they developed mainframe programs for payroll and accounting. Instead of storing the data on punch cards mechanically, as IBM did, they stored it locally in the Electronic System which using common Logical database for all activities of Organization. Therefore, they called their software a real-time system, since there was no need to process the punch cards overnight (for this reason their flagship product carried an R in its name until the late 1990s). This first version was also a standalone software that could be offered to other interested parties.\n\nIn 1973, the first commercial product was launched. It was called SAP R/98, and offered a common system for multiple tasks. This permitted the use of a centralized data storage, improving the maintenance of data. From a technical point of view, therefore, a database was necessary.\n\nIn 1976, SAP GmbH was founded, and moved its headquarters the following year to Walldorf, Germany. Three years later, in 1979, SAP launched SAP R/2, expanding the capabilities of the system to other areas, such as material management and production planning. In 1981, SAP brought a re-designed product to market. However, SAP R/2 did not improve until the period between 1985 and 1990. SAP released the new SAP R/3 in 1992. SAP developed and released several versions of R/3 through 1995. By the mid-1990s, SAP followed the trend from mainframe computing to client/server architectures. The development of SAP's internet strategy with mySAP.com redesigned the concept of business processes (integration via Internet). As a result, R/3 was replaced with the introduction of SAP ERP Central Component (ECC) 5.0 in 2004. Architectural changes were also made to support an enterprise service architecture to transition customers to a services-oriented architecture. The latest version, SAP ERP 6.0, was released in 2006. SAP ERP 6.0 has since then been updated through SAP enhancement packs, the most recent: SAP enhancement package 8 for SAP ERP 6.0 in 2016.\n\nIn August 1988, SAP GmbH became SAP AG, and public trading started on 4 November 1988. Shares were listed on the Frankfurt and Stuttgart stock exchanges. In 1995, SAP was included in the German stock index DAX and, on 22 September 2003, SAP was included in the STOXX Europe 50.\n\nThe company's official name became \"SAP AG\" (a public limited company) after the 2005 annual general meeting. In 2014, SAP changed from an AG to a European Company (Societas Europaea or SE).\n\nSince 2012, SAP has acquired several companies that sell cloud-based products, with several multibillion-dollar acquisitions seen by analysts as an attempt to challenge competitor Oracle. In 2014 SAP bought Concur Technologies, a provider of cloud-based travel and expense management software, for $8.3 billion, SAP's most expensive purchase to that date. Analysts' reactions to the purchase were mixed, with Thomas Becker of Commerzbank questioning whether Concur was the right choice for SAP, while Credit Suisse called the acquisition an \"aggressive\" move.\n\nIn 2014, IBM and SAP began a partnership to sell cloud-based services. Likewise, in 2015, SAP also partnered with HPE to provide secure hybrid cloud-based services running the SAP platform. Both HPE and IBM provide infrastructure services to SAP, and SAP runs its SAP HANA cloud solution on top. SAP has announced additional partnerships with Microsoft in order to give customers tools for data visualization, as well as improved mobile applications.\n\nSAP exceeded its revenue projections due to the expansion in its cloud business and the success of SAP HANA. The growth can also be partially attributed to the acquisitions of Concur and Fieldglass.\n\nThe company announced plans in 2016 to invest heavily into technology relating to Internet of Things (IoT) as part of a strategy to capitalize on the growth in that market. For that purpose, €2 billion is planned for investment in relevant sectors by the end of 2020. SAP will also launch a new product line called SAP IoT, which \"will combine large amounts of data from things connected to the Internet with machine learning and SAP's real-time database S/4 HANA.\"\n\nIn 2015, the company launched SAP S/4HANA, the newest generation of the SAP Business Suite. It was written natively for the SAP HANA platform. It offers cloud, on-premises and hybrid deployment options to customers, with its benefits including a smaller data footprint, higher throughput, faster analytics and faster access to data. It also allows existing SAP Business Suite customers to upgrade to this product from SAP Business Suite.\n\nIn 2016, SAP introduced SAP HANA, Express Edition which is meant to run on personal computers or on cloud computing platforms for students and other small-scale developers.\n\n, SAP is the world's third largest software and programming company. The corporation operates in Europe, Asia, Africa, the Middle East, North America, and South America.\n\nSAP focuses on 25 industries and six industry sectors: process industries, discrete industries, consumer industries, service industries, financial services and public services. It offers integrated product sets for large enterprises, mid-sized companies and small businesses.\n\nService-oriented architecture has been incorporated into the SAP ERP (Enterprise Resource Planning) system and other products defined within the SAP Enterprise Services Architecture (Enterprise SOA).\n\n\"SAP Enterprise Service Oriented Architecture\" (or \"Enterprise SOA\") is SAP SE's service-oriented architecture implementation. Enterprise SOA is enabled by the SAP NetWeaver platform and builds on the benefits of Web services. SAP has positioned Enterprise SOA to deliver the benefits offered by service-oriented architecture, including enabling both flexibility and business efficiency. SAP markets Enterprise SOA as a cost-effective way of adding new applications to existing infrastructure. SAP Solutions that currently use Enterprise SOA are mySAP CRM, mySAP ERP, and mySAP SRM.\n\nSAP partners include Global Services Partners with cross-industry multinational consulting capabilities, Global Software Partners providing integrated products that complement SAP Business Suite solutions, and Global Technology Partners providing user companies with a wide range of products to support SAP technology, including vendors of hardware, database, storage systems, networks, and mobile computing technology.\n\nExtensions partners are companies which provide functionality that complements SAP product capabilities. Their products are certified, sold, and supported by SAP. These partner companies include Adobe, CA Technologies, GK Software, Hewlett-Packard, IDS Scheer, Mendix, OpenText, Knoa Software, and BackOffice Associates.\n\nSAP has also partnered with Apple to work on the mobile experience for SAP enterprise customers. As part of the partnership, a new SAP HANA Cloud Platform SDK would be delivered exclusively for iOS. As a result, developers can build applications based on the SAP HANA Cloud Platform for the iPhone and iPad devices. The partnership was announced in May 2016.\n\nSAP products for small businesses and midsize companies are delivered through its global partner network. The SAP PartnerEdge programme, SAP's partner programme, offers a set of business enablement resources and program benefits to help partners including value-added resellers (VARs) and independent software vendors (ISVs) be profitable and successful in implementing, selling, marketing, developing and delivering SAP products to a broad range of customers.\n\nSAP Community Network (SCN) is a community of SAP customers, partners, employees, and influencers – typically in roles such as: developers, consultants, integrators, and business analysts – who gain and share knowledge about ABAP, Java, .NET, SOA, and other technologies, plus analytics and dashboards, business process best practices, cloud, mobile, big data, and a range of other topics via blogs, discussion forums, downloads and code samples, training materials, and a technical library.\n\nSAP uses a two-tier structure of boards, with an executive board and a supervisory board. As of 2016, members of the executive board were Bill McDermott (CEO and Chairman, joined in 2008), Robert Enslin (2014) Bernd Leukert (2014), Luka Mucic (CFO, 2014), Michael Kleinemeier (2015), Stefan Ries (2016), Steve Singh (2016), Gerhard Oswald (1996). Juergen Mueller will join the executive board in 2019. \n\nFunctional units of SAP are split across different organizational units for R&D needs, field activities and customer support. SAP Labs are mainly responsible for product development whereas the field organizations spread across each country are responsible for field activities such sales, marketing and consulting. Headquarters is responsible for overall management as well as core Engineering activities related to product development. Worldwide customer support is not provided by the field organizations but by a unified organization called Active Global Support (AGS).\n\nSAP Labs are R&D locations that develop and improve SAP core products. SAP Labs are strategically located in high-tech clusters around the globe.\n\nSAP Labs are located in Germany (main locations: Walldorf/Rot, Markdorf, Berlin), United States (main location: Silicon Valley), India (main location: Bangalore), China (main location: Shanghai), Brazil (main location: Sao Leopoldo), Bulgaria (main location: Sofia), Canada (main locations: Vancouver, Montreal), Vietnam (main location: Ho Chi Minh City), Israel (main location: Ra'anana), CIS (main location: Moscow), France (main location: Paris, Sophia Antipolis), Ireland (main location: Dublin), Hungary (main location: Budapest), Slovakia (main location: Bratislava), Czech Republic (main location: Brno), Poland (main location: Gliwice)，China (main location: Shanghai);\n\nThe four most prominent labs of SAP SE are located in Germany, India, China and the US. Labs Walldorf was founded in 1972 and became SAP's primary location. At the beginning, the focus of SAP's expansion was entering highly developed IT markets; in 1993 Palo Alto became a part of SAP Labs. Aiming to acquire talented employees, SAP opened another lab in Bangalore in 2003.\n\nAmong the latest SAP Labs are labs in Czech Republic, Slovakia and Poland. All three labs have been established in 2016. The labs in India are now the largest labs outside Germany. \n\nIn order to manage SAP Labs, SAP Labs Network (SLN) was created. SLN is a global unit that manages regional Labs and shares best business practices. It coordinates and distributes development projects among individual SAP Labs locations, accelerates product delivery, gives SAP full access to talent, and drives SAP corporate strategy regarding innovation and business growth.\n\nSAP User Groups are independent, nonprofit organizations of SAP customers and SAP partners. They serve as communications channel for their members towards SAP and for SAP towards the markets. The Americas' SAP Users' Group (ASUG) is the company's largest user group, with 100,000 individuals at 3,800 companies. ASUG members are professionals who work in more than 17 industries. Many are technical and business process experts in the SAP ecosystem; they have varied levels of experience, and come from small businesses to global corporations, as well as universities. In 2007, the SAP User Group Executive Network (SUGEN) was established.\n\nSAP provoked controversy and frustration among its users in 2008 by raising the cost of its maintenance contracts. The issue was the subject of intense discussion among user groups.\n\nSAP Cloud Platform is SAP's platform-as-a-service (PaaS) that is used to deliver in-memory capabilities and microservices for building and extending, mobile-enabled cloud applications. The infrastructure is offered through a global network of SAP managed data centers. SAP Cloud Platform is an open platform-as-a-service, which includes the in-memory SAP HANA database management system, connects to both on premises and cloud-based systems running SAP or other third-party software and relies on open standards, like Java, JavaScript, Node.js and Cloud Foundry for integration options.\n\nSAP Cloud Platform is promoted to build and extend business applications with rapid innovation cycles. SAP and Apple Inc. partnered to develop mobile applications on iOS using cloud-based software development kits (SDKs) for the SAP Cloud Platform. SAP founding development partners for their Cloud Platform include Accenture, Celonis, EnterpriseAlumni & Walmart\n\nSAP Cloud Platform is based on open source technology, developed & supported in partnership with SUSE. The company is also in partnership with Cloud Foundry for a beta offering of SAP Cloud Platform that enables customers to test out and give feedback for the functionalities coming with Cloud Foundry.\n\nSAP launched the SAP store in March 2015 as its principal e-commerce property to allow customers to buy its products directly on the Web rather than through traditional sales channels. Customers can purchase free trials or starter editions and can pay by credit card or PayPal.\n\nLaunched in 2016, the SAP App Center is an online application marketplace for third-party applications that integrate with and extend SAP products. Applications are available for free, as well as via yearly or monthly subscription models. Applications available range from integrations with content management software to mobile approval management and payment platforms. As of July 2018, it features over 1,500 applications.\n\nSAP has two annual conferences:\n\nSAP competitors are primarily in the enterprise resource planning software industry. In this field, Oracle Corporation is SAP's major competitor. SAP also competes in the customer relationship management, marketing & sales software, manufacturing, warehousing & industrial software, and supply chain management & logistics software sectors.\n\nOracle Corporation filed a lawsuit against SAP for malpractice and unfair competition in the California courts in 2007. SAP lost the case in 2010 and was ordered to pay $1.3 billion, which was cited as the largest copyright infringement judgment in history. The verdict was overturned in 2011, and the lawsuit was finally settled in 2014 for $356.7 million.\n\nThe resulting pressure saw SAP and SUGEN (SAP User Group Executive Network) agree to a major benchmarking exercise to prove the value of the new support pricing policy to customers. In December 2009, SAP delayed its Enterprise Support price rises until agreement had been reached on the benchmarks and KPIs (Key Performance Indicators).\n\nIn January 2010, SAP reversed its direction on Enterprise Support and reintroduced its standard support package for customers. The move to reinstate standard support – at 18 percent of annual license fees, \"will enable all customers to choose the option that best meets their requirements\", the company said.\n\nIn August 2013, SAP acquired German software company Hybris for eCommerce capabilities.\n\nSAP has donated several millions of dollars to a variety of global health causes including the Product Red campaign and the Global Fund. In addition, SAP has distributed free software in South Africa as part of an effort towards developing future markets there. The company also encourages employees to volunteer through social sabbaticals, sending teams of people to different countries to aid non-profits. SAP employees have volunteered in China, India, Brazil, and South Africa.\n\nSAP also engages in outreach activities within its company. In 2013, the company launched an initiative to hire employees with autism and Asperger syndrome, citing their undervalued ability to contribute to its workforce. SAP aims to compose 1% of its workforce with individuals with autism by the year 2020.\n\nIn July 2017, allegations were made that SAP had been involved in business transactions with the controversial and politically influential Gupta family in South Africa. SAP was accused of paying CAD House, a Gupta-controlled company, R100 million in order to secure a Transnet deal. SAP denied the allegations, claiming that the money was paid as \"an extension of the sales force\", despite CAD House having no prior SAP experience.\n\nThe Guptas' dealings with SAP were revealed in a widely publicised e-mail leak.\n\nAs a consequence of the allegations, SAP launched an investigation that led to four of its South African managers being placed on administrative leave along with the seizure of their mobile phones and computers. Claas Kuehnemann was named as acting managing director for Africa while the investigation continued.\n\nOn 26 October 2017, SAP announced that it had voluntarily reported itself to the U.S. Securities and Exchange Commission for a possible violation of US law, including the Foreign Corrupt Practices Act, related to the South African bribery allegations. SAP's own investigation, conducted by law firm Baker McKenzie, revealed that SAP had paid $7.7 million in commissions to third-parties linked to the Gupta family while securing contracts worth $48 million with Transnet and Eskom.\n\nIn May 2015, SAP agreed to pay $3.9 million to settle U.S. Securities and Exchange Commission civil charges over a former executive's scheme to bribe Panama government officials in order to win lucrative technology contracts.\n\n"}
{"id": "15079896", "url": "https://en.wikipedia.org/wiki?curid=15079896", "title": "Slovak Technical Museum", "text": "Slovak Technical Museum\n\nThe Slovak Technical Museum (, STM) is a major Slovak technology museum, based in the eastern Slovak city of Košice, with branches throughout Slovakia. It was established in 1947 and opened to the public in 1948, under the name Technical Museum (\"Technické múzeum\"). The museum was renamed to its current name in 1983. Its main exhibits and headquarters are located in the northern part of Košice's Main Street (\"Hlavná ulica\"), in the historical public building known as \"Kapitánsky palác\" (The Captain Palace).\n\nThe main museum in Košice's historical centre has collections and exhibits that focus on the history of industrial and technological topics such as mining, metallurgy, artistic crafts, physics, chemistry, steam engines, electrical engineering, energy production, typewriters, phonographs and other sound recording devices, telephones, radiotelegraphy and radios. The museum also includes a planetarium and exhibits related to astronomy and space research.\n\nThe museum's branches throughout Slovakia are as follows:\n\n\n"}
{"id": "31790769", "url": "https://en.wikipedia.org/wiki?curid=31790769", "title": "South American dreadnought race", "text": "South American dreadnought race\n\nA naval arms race among Argentina, Brazil and Chile—the most powerful and wealthy countries in South America—began in the early twentieth century when the Brazilian government ordered three dreadnoughts, formidable battleships whose capabilities far outstripped older vessels in the world's navies.\n\nIn 1904, the Brazilian Navy found itself well behind its Argentine and Chilean rivals in quality and total tonnage; few ships had been ordered since the fall of the Brazilian monarchy in 1889, while Argentina and Chile had just concluded a fifteen-year naval arms race which filled their navies with modern warships. Rising demand for coffee and rubber was fueling a large increase in the Brazilian government's revenue, and the country's legislature voted to devote some of the proceeds to address this naval imbalance. They believed that building a strong navy would play an essential role in remaking the country into an international power.\n\nThe Brazilian government ordered three small battleships from the United Kingdom in late 1905, but the appearance of the revolutionary British warship in 1906 quickly scrapped these plans. Instead, the Brazilians ordered three dreadnoughts—warships that would be the most powerful in the world, and of a type which quickly became a measure of international prestige, similar to nuclear weapons in the mid-twentieth century. This action focused the world's attention on the newly ascendant country: newspapers and politicians in the great powers fretted that Brazil would sell the ships to a belligerent nation, while the Argentine and Chilean governments immediately canceled their naval-limiting pact and ordered two dreadnoughts each (the and es, respectively).\n\nMeanwhile, Brazil's third dreadnought faced a good deal of political opposition after an economic downturn and a naval revolt: the crews of both of their brand-new battleships, along with several smaller warships, mutinied and threatened to fire on Rio de Janeiro if there was no end to what they called the \"slavery\" being practiced by the Brazilian Navy. Despite these pressures, the shipbuilder Armstrong Whitworth successfully held the Brazilians to their contractual obligations. Construction on the new ship, preliminarily named \"Rio de Janeiro\", was halted several times due to repeated design changes. Brazil's coffee and rubber booms collapsed soon after. Concerned that their ship would be outclassed by larger super-dreadnoughts, they sold the incomplete vessel to the Ottoman Empire in December 1913.\n\nThe First World War marked the end of the naval arms race, as the South American countries found themselves unable to purchase additional warships. The Brazilian government ordered a new battleship, \"Riachuelo\", in May 1914, but the conflict effectively canceled the ship. The British purchased the two Chilean battleships before they were completed; one was sold back to Chile in 1920. Argentina's two dreadnoughts, having been built in the neutral United States, escaped this fate and were commissioned in 1914–15. Although several South American called for dreadnoughts, no additional units were constructed.\n\nConflicting Argentine and Chilean claims to Patagonia, the southernmost region in South America, had been causing tension between the two countries since the 1840s. This tension was heightened in 1872 and 1878, when Chilean warships seized merchant ships which had been licensed to operate in the disputed area by the Argentine government. An Argentine warship did the same to a Chilean-licensed American ship in 1877. This action nearly led to war in November 1878, when the Argentines dispatched a squadron of warships to the Santa Cruz River. The Chilean Navy responded in kind, and war was only avoided by a hastily signed treaty. Each government was distracted in the next few years, Argentina's with intensified military operations against the indigenous population (1870–84), and Chile's with the War of the Pacific (\"Guerra del Pacífico\", 1879–83) against Bolivia and Peru. Still, several warships were ordered by both nations: the Chileans ordered a protected cruiser, , while the Argentines contracted for two warships, the central battery ironclad and protected cruiser \"Patagonia\".\n\nIn 1887, the Chilean government added £3,129,500 to the budget for its fleet, at the time still centered on two aging central battery ironclads, and , from the 1870s. They ordered the battleship , two protected cruisers, and two torpedo boats; their keels were laid in 1890. The Argentine government quickly responded with an order for two battleships, \"Independencia\" and \"Libertad\", beginning a naval arms race between the two countries. It continued through the 1890s, even after the expensive Chilean Civil War (1891). The two countries alternated cruiser orders between 1890 and 1895, each marking a small increase in capabilities from the ship previous. Argentina escalated the race in July 1895 by buying an armored cruiser, , from Italy. Chile responded by ordering its own armored cruiser, , and six torpedo boats; the Argentine government quickly ordered another armored cruiser from the Italian engineering company Ansaldo, and later ordered two more.\n\nThe race slowed for a few years after a boundary dispute in the Puna de Atacama region was successfully mediated in 1899 by the American ambassador to Argentina, William Paine Lord, but more ships were ordered by both countries in 1901. The Argentine Navy bought two more armored cruisers from Italy, and the Chilean Navy replied with orders for two \"Constitución\"-class pre-dreadnought battleships from British shipyards. The Argentines replied by signing letters of intent with Ansaldo in May 1901 to buy two larger battleships.\n\nThe growing dispute disturbed members of the British government, as war looked like a very real possibility, and an armed conflict would disrupt the extensive British commercial interests in the area. Argentina and Chile both imported British-made goods, while the United Kingdom imported large amounts of Argentine grain, most shipped through the River Plate, and Chilean nitrates. The British government mediated negotiations between the two countries through their envoy in Chile. These were successfully concluded on 28 May 1902 with three pacts. The third limited the naval armaments of both countries; both were barred from acquiring any further warships for five years without giving the other eighteen months' advance notice. The warships under construction were sold to the United Kingdom and Japan: Chile's battleships became the former's , and Argentina's armored cruisers the latter's . It is not clear if the two planned Argentine battleships were ordered, but in any case the plans were quickly scuttled. \"Capitán Prat\", \"Garibaldi\", and \"Pueyrredón\" were disarmed with the exception of their main batteries, as there was no crane capable of removing the cruisers' gun turrets.\n\nBrazil's navy fell into disrepair and obsolescence after an 1889 coup d'État, which deposed Emperor Dom Pedro II, two naval revolts (1891 and 1893–94), the Federalist Revolution (1893–95), and the War of Canudos (1896–97). The navy had just forty-five percent of its authorized personnel in 1896, and amid quickly improving naval technology, the only modern armored ships were two small coast-defense vessels launched in 1898. With such dilapidated defenses, José Paranhos Jr., the Baron of Rio Branco and Foreign Minister of Brazil, stated \"In such conditions, you ... understand how upset I am and all the worries I have. All that still protects [Brazil] is the moral force and old prestige still left from [the Imperial era] when there was still foresight in this land...\"\n\nMeanwhile, although the Argentine–Chilean agreement had limited their naval expansion, they still retained the numerous vessels built in the interim, so by the turn of the 20th century the Brazilian Navy lagged far behind its Argentine and Chilean counterparts in quality and total tonnage. Brazil's huge advantage in population—it had almost three times the population of Argentina, close to five times that of Chile, and nearly double of the two combined—led the Brazilian government to believe that it should assume a leading role in naval affairs on the continent.\n\nThe late nineteenth and early twentieth century demand for coffee and rubber led to Brazil's coffee economy and rubber boom. At the time, it was estimated that seventy-five to eighty percent of the world's coffee supply was grown in Brazil, particularly in São Paulo, Minas Geraes, and Rio de Janeiro. The resulting profits meant that the Brazilian government collected much more revenue than in previous years. Simultaneously, there was an effort on the part of prominent Brazilian politicians, most notably Pinheiro Machado and Rio Branco, to have the country recognized as an international power. A strong navy was seen as crucial to this goal.\nThe National Congress of Brazil passed a large naval acquisition program on 14 December 1904, but it was two years before any ships were ordered or purchased, and while Rio Branco suggested purchasing used warships to fill the gap, nothing came of it. By 1906, two factions had developed over which types of ships should be ordered. One, supported by the British armament company Armstrong Whitworth (which eventually received the order), favored a navy centered on a small number of large warships. The other, supported by Rio Branco, preferred a larger navy composed of smaller warships. Rio Branco, in support of this measure, stated that \"with six small battleships we would be much better. If we lost one or two in combat, there would be still four or five left to fight with. But with three [larger battleships]? With two damaged or destroyed, we would be left with one only.\"\n\nAt first, the smaller warships faction prevailed. After Law no. 1452 was passed on 30 December 1905, which authorized £4,214,550 for new warship construction (£1,685,820 in 1906), three small battleships, three armored cruisers, six destroyers, twelve torpedo boats, three submarines, a collier, and a training ship were ordered. Though the Brazilian government later eliminated the armored cruisers for monetary reasons, the Minister of the Navy, Admiral Júlio César de Noronha, signed a contract with Armstrong Whitworth for the planned battleships on 23 July 1906.\n\nThe British ambassador to Brazil was opposed to the planned naval expansion, even though the orders went to a British company, for its large cost and its negative effects on relations between Brazil and Argentina. He saw it as \"an embodiment of national vanity, combined with personal motives of a pecuniary character.\" The American ambassador to Brazil was alarmed, and sent a cablegram to his Department of State in September 1906, warning them of the destabilization that would occur if the situation devolved into a full naval arms race. At the same time, the American government under Theodore Roosevelt tried using diplomatic means to coerce the Brazilians into canceling their ships, but the attempts were dismissed, with the Baron of Rio Branco remarking that caving to the American demands would render Brazil as powerless as Cuba, whose new constitution allowed the American government to intervene in Cuban affairs. The new President of Brazil, Afonso Pena, supported the naval acquisitions in an address to the National Congress of Brazil in November 1906, as in his opinion the ships were necessary to replace \"Aquidabã\", which unexpectedly blew up that year, and the antiquated vessels composing the current navy.\n\nAfter construction began on Brazil's three new small battleships, the Brazilian government reconsidered their order and chosen battleship design (something that would happen during the construction of \"Rio de Janeiro\" in 1913). This was wrought by the debut of the United Kingdom's new dreadnought concept, which was represented by the surprisingly fast construction and commissioning of the eponymous ship in 1906. The hallmark of this new warship type was its \"all-big-gun\" armament, which utilized many more heavy-caliber weapons than previous battleships, and it rendered the Brazilian ships obsolete before they were completed.\n\nThe money authorized for naval expansion in 1905 was redirected to building three dreadnoughts (with the third to be laid down after the first was launched), three scout cruisers (later reduced to two, which became the ), fifteen destroyers (later reduced to ten, the ), three submarines (the \"F 1\" class), and two submarine tenders (later reduced to one, ). This move was made with the large-scale support of Brazilian politicians, including Pinheiro Machado and a nearly unanimous vote in the Senate; the navy, now with a large-ship advocate, Rear Admiral , in the influential post of minister of the navy; and the Brazilian press. Still, these changes were made with the stipulation that the total price of the new naval program not exceed the original limit, so the increase in battleship tonnage was bought with the previous elimination of armored cruisers and decreasing the number of destroyer-type warships. The three battleships on which construction had begun were scrapped beginning on 7 January 1907, and the design for the new dreadnoughts was approved on 20 February. Newspapers began covering the Brazilian warship order in March, and Armstrong laid down the first dreadnought on 17 April. The full order—including all three dreadnoughts and the two cruisers—was reported by the \"New York Herald\", \"Daily Chronicle\", and the \"Times\" later that year.\n\nThe Brazilian order for what contemporary commentators called \"the most powerful battleship[s] in the world\" came at a time when few countries in the world had contracted for such armament. Brazil was the third country to have a dreadnought under construction, behind the United Kingdom, with and the , and the United States, with the . This meant that Brazil was in line to have a dreadnought before many of the world's perceived powers, like France, the German Empire, the Russian Empire, and the Empire of Japan. As dreadnoughts were quickly equated with international status, somewhat similar to nuclear weapons today—that is, regardless of a state's need for such equipment, simply ordering and possessing a dreadnought increased the owner's prestige—the order caused a stir in international relations.\n\nNewspapers and journals around the world speculated that Brazil was acting as a proxy for a stronger country which would take possession of the two dreadnoughts soon after completion, as they did not believe that a previously insignificant geopolitical power would contract for such armament. Many American, British, and German sources variously accused the Americans, British, German, or Japanese governments of secretly plotting to purchase the vessels. The \"World's Work\" remarked:\n\nOn the other side of the Atlantic, in the midst of the Anglo–German naval arms race, members of the British House of Commons fretted over the battleships' possible destinations, though the Admiralty consistently stated that they did not believe any sale would occur. In mid-July and September 1908, the Commons discussed purchasing the ships to bolster the Royal Navy and ensure they would not be sold to a foreign rival, which would disrupt the British naval plan set in place by the \"two-power standard,\" though in March and late July 1908, the Brazilian government officially denied any sale was planned. In March 1909, the British press and House of Commons began pushing for more dreadnoughts after the First Lord of the Admiralty, Reginald McKenna, asserted that Germany had stepped up its building schedule and would complete thirteen dreadnoughts in 1911—four more than previously estimated. Naturally, the subject of purchasing the Brazilian dreadnoughts already being built was brought up, and McKenna had to officially deny that the government was planning to tender an offer for the warships. He also stated that a sale to a foreign nation would be inconsequential, as \"our present superiority in strength in 1909–10 is so great that no alarm would be created in the mind of the Board of Admiralty.\"\n\nDespite the plethora of rumors, the Brazilian government was not planning to sell their ships. Dreadnoughts formed an important role in Rio Branco's goal of raising Brazil's international status:\n\nArgentina was highly alarmed by the Brazilian move, and they quickly moved to nullify the remaining months of the naval-limiting restrictions in the 1902 pact with Chile. In November 1906, Argentina's Minister of Foreign Affairs, , remarked that any one of the new Brazilian vessels could destroy the entire Argentine and Chilean fleets. Despite the seeming hyperbole, his statement—made before the Brazilian government reordered the ships as dreadnoughts—ended up being close to the truth: in 1910, at least, the new Brazilian warships were seemingly stronger than any other vessel in the world, let alone any one ship in the Argentine or Chilean fleets. With this in mind, the \"Journal of the American Society of Naval Engineers\" opined that maintaining the older \"Libertad\" class or \"Capitán Prat\" (respectively) was now a waste of money.\n\nThe Argentine government's alarm continued under de Oca's successor, Estanislao Zeballos. In June 1908, Zeballos presented a plan to the Argentine Congress where they would offer the Brazilian government a chance to give one of their two unfinished dreadnoughts to Argentina. This would allow the two countries a chance to enjoy relative naval parity. Should the Brazilians refuse, Zeballos planned to issue an ultimatum: if they did not comply in eight days, the mobilized Argentine Army would invade what the army and navy ministers claimed was a defenseless Rio de Janeiro. Unfortunately for Zeballos, his plan was leaked to the media, and the resulting public outcry—Argentine citizens happened to not be in favor of their government borrowing large sums of money to mobilize the army and go to war—ensured his resignation.\n\nThe Argentine government was also deeply concerned with the possible effect on the country's large export trade, as a Brazilian blockade of the entrance to the River Plate would cripple the Argentine economy. The acquisition of dreadnoughts to maintain an equal footing with Brazil would, in the words of the Argentine admiral overseeing his countries' dreadnoughts while they were being constructed, avoid a \"preponderance of power on the other side, where a sudden gust of popular feeling or injured pride might make [a blockade] a dangerous weapon against us.\"\n\nBoth countries faced difficulty in financing their own dreadnoughts. Although in Argentina the ruling National Autonomist Party supported the purchases, they initially faced public resistance for such expensive acquisitions. An influx of inflammatory newspaper editorials supporting new dreadnoughts, especially from \"La Prensa\", and renewed border disputes, particularly Brazilian assertions that the Argentines were attempting to restore the Viceroyalty of the Río de la Plata, swayed the public to support the purchases. The Argentine President, José Figueroa Alcorta, attempted to ease the tensions with a message warning the Brazilians of a naval arms race should they continue on their present course. The Brazilian government replied with reasoning similar to Pena's speech in 1906, in that they believed the ships were necessary to replace the antiquated equipment left by the long-term neglect of the Brazilian Navy, and they repeatedly insisted that the ships were not meant for use against Argentina.\n\nIn August, a bill authorizing the Argentine Navy to acquire three dreadnoughts was passed by the Chamber of Deputies seventy-two to thirteen. Three months later, it was defeated in the Senate after they approved an arbitration treaty and the government made a last-ditch offer to purchase one of the two Brazilian dreadnoughts currently being constructed. The Brazilian government declined, so the bill was reintroduced and passed by the Senate on 17 December 1908 with forty-nine in support to thirteen opposed, over socialist objections that the country needed to be populated and the large sum of money (£14,000,000) could be better spent in other areas of the government.\n\nAfter the Argentine government sent a naval delegation to Europe to solicit and evaluate armament companies' offers, they received tenders from fifteen shipyards in five countries (the United States, Great Britain, Germany, France, and Italy), and conducted a drawn-out bidding process. The Argentine delegation rejected all of the bids twice, each time recycling the best technical aspects of the tendered designs when crafting new bidding requirements. The reason given for the first rejection was the appearance of the first super-dreadnought, . Still, the shipbuilders were furious, as the process of designing a major warship took large amounts of time and money, and they believed the Argentine tactic revealed their individual trade secrets. A British naval architect published a scathing condemnation of the Argentine tactics, albeit only after the contracts were not awarded to a British company:\n\nThe United States' Fore River Ship and Engine Company tendered the lowest bid—in part owing to the availability of cheap steel, though they were accused of quoting an unprofitable price so the ships could act as loss leaders—and was awarded the contract. This aroused further suspicion in the European bidders, who had previously believed that the United States was a non-contender, though Argentina did order twelve destroyers from British, French, and German shipyards to soften the blow. These bidders, along with newspapers like the \"Times\" (London), turned their anger on the American government under President William Howard Taft, whose so-called \"Dollar Diplomacy\" policy had led his State Department to go to great lengths to obtain the contracts. Their reactions may have been justified: Taft boasted in the high-profile 1910 State of the Union address that the Argentine dreadnought order was awarded to American manufacturers \"largely through the good offices of the Department of State.\"\nThe Argentine contract included an option for a third dreadnought in case the Brazilian government adhered to its contractual obligations to order a third dreadnought. Two newspapers, \"La Prensa\" and \"La Argentina\", heavily advocated for a third ship; the latter even started a petition to raise money for a new battleship. The American minister to Argentina, Charles H. Sherrill, cabled back to the United States that \"this newspaper rivalry promises the early conclusion of a movement which means a third battleship whether by public subscription or by Government funds.\" On 31 December 1910, the Argentine government decided against constructing the ship, after Roque Sáenz Peña, who had been making entreaties to Brazil to end the expensive naval race, was elected to the Presidency. In addition, the intended target of the third Argentine dreadnought, the third Brazilian dreadnought, had already been canceled multiple times.\n\nThe Chilean government delayed their naval plans after a financial depression brought on by the 1906 Valparaíso earthquake and a drastic fall in the nitrate market in 1907, but these economic problems were not enough to stop them from countering the dreadnoughts purchased by their traditional rival Argentina. While Argentina's principal concern was with Brazil, Chile also wished to respond to Peruvian military acquisitions.\n\nMoney for a naval building program was allocated in 1910. Although the Chilean government solicited bids from several armament companies, nearly all believed that a British company would win the contract; the American naval attaché opined that without anything short of a revolution the contracts were destined for the United Kingdom. The Chilean Navy had cultivated extensive ties with the United Kingdom's Royal Navy since the 1830s, when Chilean naval officers were given places on British ships to receive training and experience they could bring back to their country. This relationship had recently been cemented when a British naval mission was requested by Chile and sent in 1911. Still, the American and German governments attempted to swing sentiment to their side by dispatching modern naval vessels ( and , respectively) to Chilean ports. Their efforts were futile, and the design tendered by Armstrong Whitworth was chosen on 25 July 1911.\n\nOther South American navies, having limited resources and little expertise in operating large warships, were in no state to respond. The Peruvian Navy, fourth largest on the continent, had been decimated during the naval campaign of the War of the Pacific against Chile (1879–83). It took the Peruvian government more than twenty years to order new warships—the (\"Almirante Grau\" and \"Coronel Bolognesi\"), scout cruisers delivered in 1906 and 1907. They were augmented by two submarines and a destroyer ordered from France. \"Almirante Grau\" was only intended to be the fleet's flagship until a more powerful warship was purchased; along with \"Coronel Bolognesi\", they would be the \"pioneers\" of a modern navy. \"Proceedings\" reported in 1905 that this new navy would be composed of three \"Swiftsure\"-like pre-dreadnoughts, three armored cruisers, six destroyers, and numerous smaller warships, all acquired as part of a nine-year, $7 million outlay.\n\nNone of these plans came to fruition. The closest major expansion came in 1912, when the Peruvian Navy had an agreement to acquire an obsolete French armored cruiser in 1912 () for three million francs. The Peruvian government paid one of a planned three planned installments, but the purchase came under criticism at home for not being able to change any balance of power with Chile. When a potential cruiser purchase by Ecuador fell through, the Peruvians quit paying for the ship, which was later converted to a merchant ship and scrapped in 1923.\n\nOther South American navies also added smaller vessels to their naval forces in the same time period. The Uruguayan Navy acquired a gunboat in 1910, while the Venezuelan Navy bought an ex-Spanish protected cruiser, \"Mariscal Sucre\", from the United States in 1912. The Ecuadorian Navy added a Chilean torpedo boat to its fleet in 1907, complementing its fleet of two avisos, both around , two small steamers, and one minor coast guard ship.\n\nBrazil's , the lead ship, was laid down by Armstrong on 17 April 1907, while its sister followed thirteen days later at Vickers. Completion of the partial hull needed to launch \"Minas Geraes\" was delayed by a five-month strike to 10 September 1908. \"São Paulo\" followed on 19 April 1909. Both were christened in front of large crowds by the wife of Francisco Régis de Oliveira, the Brazilian ambassador to the United Kingdom. After fitting-out, the period after a warship's launch where it is completed, \"Minas Geraes\" was put through multiple trials of the speed, endurance, efficiency, and weaponry of the ship in September, including what was at that time the heaviest broadside ever fired off a warship. \"Minas Geraes\" was completed and handed over to Brazil on 5 January 1910. The trials proved that the blast from the class' superfiring upper turrets would not injure crewmen in the lower turrets. The ship itself managed to reach on an indicated horsepower (ihp) of 27,212. \"São Paulo\" followed its classmate in July, after its own trials at the end of May, where the ship reached at 28,645 ihp.\n\nArgentina's was built by the Fore River Ship and Engine Company at its shipyard in Massachusetts. As called for in the final contract, was subcontracted out to the New York Shipbuilding Corporation of New Jersey. The steel for the ships was largely supplied by the Bethlehem Steel Company of Pennsylvania. \"Rivadavia\" was laid down on 25 May 1910—one hundred years after the establishment of the first independent Argentine government, the \"Primera Junta\"—and launched on 26 August 1911. \"Moreno\" was laid down on 10 July 1910 and launched on 23 September 1911. Construction on both ships took longer than usual, and there were further delays during their sea trials when one of \"Rivadavia\"s turbines was damaged and one of \"Moreno\"s turbines failed. The two were only officially completed in December 1914 and February 1915. Even the departure of \"Moreno\" was marked by mishaps, as the ship sank a barge and ran aground twice.\n\nChile's was launched on 27 November 1913. After the First World War broke out in Europe, work on \"Almirante Latorre\" was halted in August 1914, and it was formally purchased on 9 September after the British Cabinet recommended it four days earlier. \"Almirante Latorre\" was not forcibly seized like the Ottoman \"Reşadiye\" and \"Sultân Osmân-ı Evvel\" (ex-\"Rio de Janeiro\"), two other ships being built for a foreign navy, as a result of Chile's \"friendly neutral\" status with the United Kingdom. The British needed to maintain this relationship owing to their dependence on Chilean nitrate imports, which were vital to the British armament industry. The former Chilean ship—the largest vessel built by Armstrong up to that time—was completed on 30 September 1915, commissioned into the Royal Navy on 15 October, and served in that navy in the First World War. Work on the other battleship, \"Almirante Cochrane\", was halted after the outbreak of war. The British purchased the incomplete hulk on 28 February 1918 for conversion to an aircraft carrier, as \"Almirante Cochrane\" was the only large and fast hull which was immediately available and capable of being modified into a carrier without major reconstruction. Low priority and quarrels with shipyard workers slowed completion of the ship; it was commissioned into the Royal Navy as in 1924.\n\nAfter the first Brazilian dreadnought, \"Minas Geraes\", was launched, the Brazilian government began an extended campaign to remove the third dreadnought from the contract because of political—backlash from the Revolt of the Lash coupled with warming relations with Argentina—and economic reasons. After much negotiating and attempts from Armstrong to hold the Brazilian government to the contract, the Brazilians relented, due in part to lower bond rates that made it possible for the government to borrow the necessary money. \"Rio de Janeiro\" was laid down for the first time in March 1910.\nBy May, the Brazilian government asked Armstrong to stop work on the new warship and to submit new designs which took in the most recent advance in naval technology, super-dreadnoughts. Eustace Tennyson-d'Eyncourt served as Armstrong's liaison to Brazil. The 1911 \"Encyclopædia Britannica\" specifies this design as a long overall, ship mounting twelve 14-inch guns and costing near £3,000,000. The many requests made by the Brazilian Navy for minor changes delayed the contract signing until 10 October 1910, and the battleship's keel laying was delayed further by a labor dispute with the Worshipful Company of Shipwrights, which led to a lockout. During these delays, a new Minister of the Navy, Admiral Marques Leão, was appointed to replace de Alencar—an important development, as the contract stipulated that the design could only proceed with the approval of the new Minister. Again, however, the Brazilian Navy found itself torn between two schools of thought: Leão and others in the navy favored a reversion to the 12-inch gun, but others, led by the outgoing Minister of the Navy (de Alencar) and the head of the Brazilian naval commission in the United Kingdom (Rear Admiral ), were strongly in favor of obtaining the ship with the largest armament—in this case, a design drawn up by Bacellar, carrying eight 16-inch guns, six 9.4-inch guns, and fourteen 6-inch guns.\n\nD'Eyncourt, who had departed Brazil in October immediately after the contract was signed, returned in March 1911 to display the various design options available to the Brazilian Navy. Armstrong evidently thought the second faction would prevail, so he also took with him everything needed to close a deal on Bacellar's design. By mid-March, Armstrong's contacts in Brazil reported that Leão had convinced the recently elected President Hermes Rodrigues da Fonseca to cancel the design with twelve 14-inch guns in favor of a smaller ship. The credit may not have laid with Leão alone, though; da Fonseca was already dealing with multiple issues. Most importantly, he had to deal with the fallout from a large naval revolt in November 1910 (the Revolt of the Lash), which had seen three of the new vessels just purchased by the navy, along with one older coast-defense ship, mutiny against the use of corporal punishment in the navy.\n\nTo make matters worse, the dreadnoughts' expense combined with loan payments and a worsening economy led to growing government debt compounded by budget deficits. By one measure of Brazil's GDP per capita, income in the country rose from $718 in 1905 to a high of $836 in 1911 before declining over the next three years to a low of $780 in 1914 (both measured in 1990 international dollars). It did not fully recover until after the First World War. At the same time, Brazil's external and internal debt reached $500 and $335 million (respectively, in contemporaneous dollar amounts) by 1913, partly through rising deficits, which were $22 million in 1908 and $47 million by 1912. In May, the president commented negatively on the new ship:\n\nD'Eyncourt probably avoided proposing any design with 16-inch guns when he saw the political situation. In meetings with Leão, designs of only ten 12-inch guns mounted on the centerline were quickly rejected, even though their broadside was as strong as that of the \"Minas Geraes\" class, but a design with no less than \"fourteen\" 12-inch guns emerged as the frontrunner. Author David Topliss attributes this to political necessity, as he believed the Minister of the Navy could not validate purchasing a seemingly less-powerful dreadnought than the \"Minas Geraes\" class: with larger guns ruled out, the only remaining choice was a larger number of guns.\nAfter numerous requests for design alterations from the Brazilian Navy were accommodated or rejected, a contract was signed for a ship with fourteen 12-inch guns on 3 June 1911 for £2,675,000, and \"Rio de Janeiro\"s keel was laid for the fourth time on 14 September. It did not take long for the Brazilian government to reconsider their decision again; by mid-1912, battleships with 14-inch guns were under construction, and suddenly it seemed that \"Rio de Janeiro\" would be outclassed upon completion. Making matters worse, a European depression after the end of the Second Balkan War in August 1913 reduced Brazil's ability to obtain foreign loans. This coincided with a collapse in Brazil's coffee and rubber exports, the latter due to the loss of the Brazilian rubber monopoly to British plantations in the Far East. The price of coffee declined by 20 percent and Brazilian exports of it dropped 12.5 percent between 1912 and 1913; rubber saw a similar decline of 25 and 36.6 percent, respectively. The Brazilian Navy later claimed that selling \"Rio de Janeiro\" was a tactical decision, so they could have two divisions of battleships: two with 12-inch guns (the \"Minas Geraes\" class), and two with 15-inch guns.\n\nArmstrong studied whether replacing the 12-inch guns with seven 15-inch guns would be feasible, but Brazil was probably already attempting to sell the ship. In the tension building up to the First World War, many countries, including Russia, Italy, Greece, and the Ottoman Empire, were interested in purchasing the ship. While Russia quickly dropped out, Italy and the rival Greeks and Ottomans were all highly interested. The Italians seemed close to purchasing the ship until the French government decided to back the Greeks—rather than allow the Italians, who were the principal naval rivals of the French, to obtain the ship. The Grecian government made an offer for the original purchase price plus an additional £50,000, but as the Greeks worked to obtain an initial installment, the Ottoman government was also making offers.\n\nThe Brazilian government rejected an Ottoman proposal to swap ships, with Brazil's \"Rio de Janeiro\" going to the Ottomans and \"Reşadiye\" going to Brazil, presumably with some amount of money. The Brazilian government would only accept a monetary offer. Lacking this, the Ottomans were forced to find a loan. Fortunately for them, they were able to obtain one from a French banker acting independent of his government, and the Ottoman Navy secured the \"Rio de Janeiro\" on 29 December 1913 for £1,200,000 as-is. As part of the purchase contract, the remainder of the ship was constructed with £2,340,000 in Ottoman money. Renamed \"Sultân Osmân-ı Evvel\", it was eventually taken over by the British shortly after the beginning of the First World War, serving with the Royal Navy as .\n\nThe Argentine government authorized a third dreadnought in October 1912 in case \"Rio de Janeiro\" was completed and delivered, but the ship was never named or built.\n\nAfter selling \"Rio de Janeiro\", the Brazilian government asked Armstrong and Vickers to prepare designs for a new battleship, something strongly supported by the Navy League of Brazil (\"Liga Maritima\"). Armstrong agreed to construct the ship without any further payments from Brazil. They replied with at least fourteen designs, six from Vickers (December 1913 through March 1914) and eight from Armstrong (February 1914). Vickers' designs varied between eight and ten 15-inch and eight 16-inch guns, with speeds between 22 and 25 knots (the lower-end ships having mixed firing, the higher using oil), and displacements between and . Armstrong took two basic designs, one with eight and the other with ten 15-inch guns, and varied their speed and firing.\n\nWhile most secondary sources do not mention that Brazil ordered a battleship, with the ship's entry in the warship encyclopedia \"Conway's All the World's Fighting Ships\" even remarking that \"Brazil had not selected from the four design variations,\" the Brazilian government chose what was labeled as Design 781, the first of the eight 15-inch designs tendered by Armstrong, which also shared characteristics with the \"Queen Elizabeth\" and \"Revenge\" classes then being built for the United Kingdom. They placed an order for one ship of this design, to be named \"Riachuelo\", at the Armstrong Whitworth shipyard in Elswick on 12 May 1914. Some preliminary gathering of materials was completed for a planned keel laying date of 10 September, but the beginning of the First World War in August 1914 delayed plans. \"Riachuelo\" was officially suspended on 14 January 1915 and canceled on 13 May 1915.\n\nIn late November 1910, a large naval revolt, later named the Revolt of the Lash, broke out in Rio de Janeiro. The tension was kindled by the racial makeup of the navy's regular crewmembers, who were heavily black or mulatto, whereas their officers were mostly white. The Baron of Rio Branco commented: \"For the recruitment of marines and enlisted men, we bring aboard the dregs of our urban centers, the most worthless \"lumpen\", without preparation of any sort. Ex-slaves and the sons of slaves make up our ships' crews, most of them dark-skinned or dark-skinned mulattos.\"\n\nThis kind of impressment, combined with the heavy use of corporal punishment for even minor offenses, meant that relations between the black crews and white officers was tepid at best. Crewmen aboard \"Minas Geraes\" began planning for a revolt in 1910. They chose João Cândido Felisberto, an experienced sailor, as their leader. The mutiny was delayed several times by disagreements among the participants. In a major meeting on 13 November, some of the revolutionaries expressed a desire to revolt when the president would be inaugurated (15 November), but another leader, Francisco Dias Martins, talked them out of the idea, insisting that their demands would be overshadowed by a perceived rebellion against the political system as a whole. The immediate catalyst for their revolt came on 21 November 1910, when an Afro-Brazilian sailor, Marcelino Rodrigues Menezes, was brutally flogged 250 times for insubordination. A Brazilian government observer, former navy captain José Carlos de Carvalho, stated that the sailor's back looked like \"a mullet sliced open for salting.\"\n\nThe revolt began aboard \"Minas Geraes\" at around 10 pm on 22 November; the ship's commander and several loyal crewmen were murdered in the process. Soon after, \"São Paulo\", the new cruiser \"Bahia\", the coast-defense ship , the minelayer , the training ship , and the torpedo boats and all revolted with relatively little violence. The first four ships represented the newest and strongest ships in the navy; \"Minas Geraes\", \"São Paulo\", and \"Bahia\" had been completed and commissioned only months before. \"Deodoro\" was twelve years old and had recently undergone a refit. The crews of the smaller warships made up only two percent of the mutineers, and some moved to the largest ships after the revolt began.\n\nKey warships that remained in government hands included the old cruiser , \"Bahia\"s sister , the eight new destroyers of the \"Pará\" class. Their crews were in a state of flux at the time: with nearly half of the navy's enlisted men in Rio at that time in open revolt, naval officers were suspicious of even those who remained loyal to the government. These suspicions were perhaps well-placed, given that radio operators on loyal ships passed on operational plans to the mutineers. Enlisted men on ships that remained in government hands were reduced wherever possible, and officers took over all of the positions that would be involved in direct combat. Further complicating matters were weapon supplies, such as the destroyer's torpedoes. These could not be fired without firing caps, yet the caps were not where they were supposed to be. When they were located and delivered, they did not fit the newer torpedoes on board the destroyers. The correct caps were fitted only 48 hours after the rebellion began.\n\nFelisberto and his fellow sailors demanded an end to what they called the \"slavery\" being practiced by the navy, most notably the continued use of whipping despite its ban in every other Western nation. Though navy officers and the president were staunchly opposed to any sort of amnesty and made plans to attack the rebel-held ships, many legislators were supportive. Over the next three days, both houses of the Brazilian National Congress, led by the influential senator Ruy Barbosa, passed a general bill granting amnesty to all involved and ending the use of corporal punishment.\n\nIn the aftermath of the revolt, the two Brazilian dreadnoughts were disarmed by the removal of their guns' breechblocks. The revolt and consequent state of the navy, which was essentially unable to operate for fear of another rebellion, caused many leading Brazilians, including the president, prominent politicians like Barbosa and the Baron of Rio Branco, and the editor of the most respected newspaper in Brazil, \"Jornal do Commercio\", to question the use of the new ships and support their sale to a foreign country. The British ambassador to Brazil, W.H.D. Haggard, was ecstatic at Rio Branco's about-face, saying \"This is indeed a wonderful surrender on the part of the man who was answerable for the purchase and who looked upon them as the most cherished offspring of his policy.\" Shortly before the vote on the amnesty bill, Ruy Barbosa emphatically outlined his opposition to the ships:\n\nIn the end, the president and cabinet decided against selling the ships because they feared it would hurt them politically. This came despite a consensus agreeing that the ships should be disposed of, possibly to fund smaller warships capable of traversing Brazil's many rivers. The executive's apprehension was heightened by Barbosa's speech given before the revolt's end, as he also used the occasion to attack the government, or what he called the \"brutal militaristic regime\". Still, the Brazilians ordered Armstrong to cease working towards laying down their third dreadnought, which induced the Argentine government to not pick up their contractual option for a third dreadnought, and the United States' ambassador to Brazil cabled home to state that the Brazilian desire for naval preeminence in Latin America was quelled, though this proved to be short-lived.\n\nAlthough the \"Minas Geraes\" class remained in Brazilian hands, the mutiny had a clear detrimental effect on the navy's readiness: by 1912, an Armstrong agent stated that the ships were in terrible condition, with rust already forming on turrets and boilers. The agent believed it would cost the Brazilian Navy around £700,000 to address these issues. Haggard tersely commented, \"These ships are absolutely useless to Brazil\", a sentiment echoed by \"Proceedings\". Despite the government's refusal to sell the two \"Minas Geraes\"-class ships and subsequent support for acquiring \"Rio de Janeiro\", some historians credit the rebellion, combined with the Baron of Rio Branco's death in 1912, as major factors in the Brazilian government's decision (which was possibly made by January 1913, but certainly by September) to sell the ship to the Ottomans.\n\nAfter \"Rio de Janeiro\" was purchased by the Ottoman Empire, the Argentine government bowed to popular demand and began to seek a buyer for their two dreadnoughts. The money received in return would have been devoted to internal improvements. Three bills directing that the battleships be sold were introduced into the Argentine National Congress in mid-1914, but all were defeated. Still, the British and Germans expressed worries that the ships could be sold to a belligerent nation, while the Russian, Austrian, Ottoman, Italian, and Greek governments were all reportedly interested in buying both ships, the latter as a counter to the Ottoman purchase of \"Rio de Janeiro\".\nThe \"New-York Tribune\" reported in late April that the Argentine government rejected a $17.5 million offer for \"Moreno\" alone, which would have netted them a large profit over the original construction cost of the ships ($12 million). The United States, worried that its neutrality would not be respected and its technology would be released for study to a foreign country, put diplomatic pressure on the Argentine government to keep the ships, which it eventually did. Similarly, news outlets reported in late 1913 and early 1914 that Greece had reached an accord to purchase Chile's first battleship as a counterbalance to the Ottoman acquisition of \"Rio de Janeiro\", but despite a developing sentiment within Chile to sell one or both of the dreadnoughts, no deal was made.\n\nIn each of the countries involved in the South American dreadnought arms race, movements arose that advocated the sale of the dreadnoughts to redirect the substantial amounts of money involved toward what they viewed as more worthy pursuits. These costs were rightfully viewed as enormous. After the \"Minas Geraes\" class was ordered, a Brazilian newspaper equated the initial purchase cost for the original three ships as equaling 3,125 miles of railroad tracks or 30,300 homesteads. Naval historian Robert Scheina put the price at £6,110,100 without accounting for ammunition, which was £605,520, or necessary upgrades to docks, which was £832,000. Costs for maintenance and related issues, which in the first five years of \"Minas Geraes\"s and \"São Paulo\"s commissioned lives was about 60 percent of the initial cost, only added to the already staggering sum of money. The two \"Rivadavia\"s were purchased for nearly a fifth of the Argentine government's yearly income, a figure which did not include the later in-service costs. Historian Robert K. Massie rounded the figure to a full quarter of each government's annual income.\n\nIn addition, the nationalistic sentiments that exacerbated the naval arms race gave way to slowing economies and negative public opinions which came to support investing inside the country instead. Commenting on this, the United States' Minister to Chile, Henry Prather Fletcher, wrote to Secretary of State William Jennings Bryan: \"Since the naval rivalry began in 1910, financial conditions, which were none too good then, have grown worse; and as time approaches for the final payment, feeling has been growing in these countries that perhaps they are much more in need of money than of battleships.\"\n\nThe First World War effectively ended the dreadnought race, as all three countries suddenly found themselves unable to acquire additional warships. After the conflict, the race never resumed, but many plans for post-war naval expansions and improvements were postulated by the Argentine, Brazilian, and Chilean governments.\n\nThe Brazilians modernized \"Minas Geraes\", \"São Paulo\", and the two cruisers acquired under the 1904 plan, and , between 1918 and 1926. This was sorely needed, as all four ships were not ready to fight a modern war. Although the Brazilian government intended to send \"São Paulo\" overseas for service in the Grand Fleet, both it and \"Minas Geraes\" had not been modernized since entering service, meaning they were without essential equipment like modern fire control. Maintenance on the two ships had also been neglected, which was most clearly illustrated when \"São Paulo\" was sent to New York for modernization: fourteen of its eighteen boilers broke down, and the ship required the assistance of the American battleship and cruiser to continue the voyage. The two cruisers were in \"deplorable\" condition, as they were able to steam at a top speed of only thanks to a desperate need for new condensers and boiler tubes. With repairs, though, both participated in the war as part of Brazil's main naval contribution to the conflict.\n\nThe Brazilian Navy also made plans to acquire additional ships in the 1920s and 30s, but both were sharply reduced from the original proposals. In 1924, they contemplated constructing a relatively modest number of warships, including a heavy cruiser, five destroyers, and five submarines. In the same year, the newly arrived American naval mission, led by Rear Admiral Carl Theodore Vogelgesang, tendered a naval expansion plan of 151,000 tons, divided between battleships (70,000), cruisers (60,000), destroyers (15,000), and submarines (6,000). The United States' State Department, led by Secretary of State Charles Evans Hughes and fresh from negotiating the Washington Naval Treaty, was not keen on seeing another dreadnought race, so Hughes quickly moved to thwart the efforts of the mission. Only one Italian-built submarine, , was acquired during this time.\n\nBy the 1930s, the international community believed that the bulk of the Brazilian Navy was \"obsolete\" and were old enough to no longer be \"considered effective\". Still, \"Minas Geraes\" was modernized a second time at the Rio de Janeiro Naval Yard from June 1931 to April 1938. Plans to give similar treatment to \"São Paulo\" were dropped due to the ship's poor material condition. During the same period, the Brazilian government looked into purchasing cruisers from the United States Navy but ran into the restrictions of the Washington and London Naval Treaties, which placed restrictions on the sale of used warships to foreign countries. The Brazilians eventually contracted for six destroyers from the United Kingdom. In the interim, a plan to lease six destroyers from the United States was abandoned after it was met with strong opposition from both international and American institutions. Three s, based on the American , were laid down in Brazil with six minelayers, all of which were launched between 1939 and 1941. Though both programs required foreign assistance and were consequently delayed by the war, all nine ships were completed by 1944.\n\nIn the 1920s, nearly all of the major warships of the Argentine Navy were obsolete; aside from \"Rivadavia\" and \"Moreno\", the newest major warship had been constructed at the end of the nineteenth century. The Argentine government recognized this, and as part of holding on to their naval superiority in the region, they sent \"Rivadavia\" and \"Moreno\" to the United States in 1924 and 1926 to be modernized. In addition, in 1926 the Argentine Congress allotted 75 million gold pesos for a naval building program. This resulted in the acquisition of three cruisers (the Italian-built and the British-built ), twelve destroyers (the Spanish-built and the British-built / classes), and three submarines (the Italian-built ).\n\nChile began to seek additional ships to bolster its fleet in 1919, and the United Kingdom eagerly offered many of its surplus warships. This action worried nearby nations, who feared that a Chilean attempt to become the region's most powerful navy would destabilize the area and start another naval arms race. Chile asked for \"Canada\" and \"Eagle\", the two battleships they ordered before the war, but the cost of converting the latter back to a battleship was too high. Planned replacements included the two remaining s, but a leak to the press of the secret negotiations to acquire them caused an uproar within Chile itself over the value of such ships. In the end, Chile only bought \"Canada\" and four destroyers in April 1920—all ships that had been ordered from British yards by the Chilean government before 1914 but were purchased by the Royal Navy after the British entered the First World War—for relatively low prices. \"Canada\", for instance, was sold for just £1,000,000, less than half of what had been required to construct the ship.\n\nOver the next several years, the Chileans continued to acquire more ships from the British, like six destroyers (the ) and three submarines (the ). \"Almirante Latorre\" was modernized in the United Kingdom from 1929 to 1931 at the Devonport Dockyard. A recession and a major naval revolt then led to the battleship's \"de facto\" inactivation in the early 1930s. In the late 1930s, the Chilean government inquired into the possibility of constructing an cruiser in the United Kingdom, Italy, Germany, or Sweden, but this did not lead to an order. A second plan to acquire two small cruisers was dropped with the beginning of the Second World War. Soon after the attack on Pearl Harbor, the United States attempted to purchase \"Almirante Latorre\", two destroyers, and a submarine tender, probably because the Chilean Navy had a reputation for keeping its ships in top-quality condition, but the offer was rejected.\n\nDuring the Second World War, the three major South American navies found themselves unable to acquire major warships; they were only able to do so again after the conflict, when the United States and United Kingdom had many unnecessary or surplus warships. The war had proved the obsolete status of battleships, so the South American navies were seeking cruisers, destroyers, and submarines, yet they ran into political difficulties in acquiring anything larger than s and s. They were only able to acquire them when the Red Scare began to strongly affect American and international politics. One of the deals reached under the Mutual Defense Assistance Act (1949) sold six American light cruisers to Argentina, Brazil, and Chile in January 1951. While this bolstered the navies of important South American allies of the United States, which would be treaty-bound to assist the United States in any war, naval historian Robert Scheina argues that the American government also used the opportunity to significantly affect the traditional naval rivalry among the three countries. The warships sold unilaterally changed the naval outlook of all three nations, leading them to accept parity (as opposed to the Argentine pre-war stipulation that its fleet be equal to Brazil's and Chile's combined).\n\nThe venerable dreadnoughts of South America soldiered on for a short time after the war. The US Navy's \"All Hands\" magazine reported in a series of 1948 articles that all save \"São Paulo\" and \"Almirante Latorre\" were still in active service; the former had been decommissioned and the latter undergoing repairs. With the influx of the modern cruisers, frigates, and corvettes, the battleships were quickly sold for scrap. The Brazilian Navy was the first to dispose of its dreadnoughts, the oldest in the world by that time. \"São Paulo\" was sold for scrap in 1951 but sank in a storm north of the Azores while under tow. \"Minas Geraes\" followed two years later and was broken up in Genoa beginning in 1954. Of the Argentine dreadnoughts, \"Moreno\" was towed to Japan for scrapping in 1957, and \"Rivadavia\" was broken up in Italy beginning in 1959. \"Almirante Latorre\", inactive and unrepaired after a 1951 explosion in its engine room, was decommissioned in October 1958 and followed \"Moreno\" to Japan in 1959.\n\n\n\n\n\n\n"}
{"id": "21255701", "url": "https://en.wikipedia.org/wiki?curid=21255701", "title": "Starshel", "text": "Starshel\n\nR-045/R-046 \"Starshel\" (Bulgarian: Стършел, \"Hornet\") is a type of electronic countermeasures ammunition, fired by 122 mm or 152 mm artillery guns. It is designed to completely disrupt enemy radio communications on the battlefield.\n\nThe Starshel rounds were developed and deployed in the early 1980s and were operationally deployed in the mid-80s. By the mid-1990s the rounds were issued to every artillery unit in the Bulgarian army as special ammunition. A full jamming kit consists of several rounds, covering a jamming range of 20 to 100 MHz (with 5 rounds) for the R-045 and from 1.5 to 120 MHz (with 8 rounds) for the R-046. The fins of the round are deployed in-flight. After contact with the ground, an automatic fuze fires the 1,5 meter-long antenna up, which is powered by a small lithium battery for at least an hour. The effective jamming range is at least 700 m. Usually 1 or 2 Starshel kits are used to completely jam enemy front-line communications on a tactical scale.\n\n\n\"Bold indicates equipment, which is currently in service with the Bulgarian military\"\n\n\n"}
{"id": "28325047", "url": "https://en.wikipedia.org/wiki?curid=28325047", "title": "Stealth ground vehicle", "text": "Stealth ground vehicle\n\nGround vehicles using stealth technology have come to fruition at various times in history.\n\nThe Challenger 2 features a redesigned hull and turret offering lower radar observability over its predecessor. More recently, the joint U.S./British Future Scout Cavalry System concept was experimented with and appeared in prototype form before being canceled. Other vehicles, particularly unmanned ground vehicles, may unintentionally have an undetectably low radar signature due to their small size. Various coatings and radar absorbing layers of material are available for combat vehicles.\n\nThe Armored Gun System program of the 1980s attempted to create a stealth vehicle. One of the competitors, the Stingray light tank later became Thailand's light tank. The M1A2 Abrams was also originally supposed to incorporate stealth. The U.S. Future Combat Systems manned ground vehicles family also incorporated a reduced cross section but was canceled in 2009.\n"}
{"id": "3326226", "url": "https://en.wikipedia.org/wiki?curid=3326226", "title": "Storm glass", "text": "Storm glass\n\nThe storm glass or chemical weather glass was an instrument which was proposed as a method for predicting weather. It consisted of a special liquid placed inside a sealed transparent glass. The state of crystallization within the liquid was believed to be related to the weather. The inventor is unknown but the device became popular in the 1860s after being promoted by Admiral Robert FitzRoy who claimed that The compositions of the liquid in a storm glass varied but usually contained \"camphor, nitrate of potassium and sal-ammoniac, dissolved by alcohol, with water and some air.\" These devices are now known to have little value in weather prediction but continue to be a curiosity.\n\nThe liquid within the glass is a mixture of several ingredients, most commonly distilled water, ethanol, potassium nitrate, ammonium chloride, and camphor. This specific mixture was promoted by Admiral Robert FitzRoy although similar devices existed even two decades earlier with variants in Italy, France and Germany.\n\nFitzRoy carefully documented how the storm glass would predict the weather:\n\nThe device was apparently available in the 18th century and the inventor is unknown. In 1859, violent storms struck the British Isles. In response, the British Crown distributed storm glasses, then known as \"FitzRoy's storm barometers,\" to many small fishing communities around the British Isles that were to be consulted by ships at port before setting sail.\n\nAn article in the \"Journal of Crystal Growth\" concluded that temperature change is the sole cause of crystal growth in storm glasses.\n\n\n"}
{"id": "44210874", "url": "https://en.wikipedia.org/wiki?curid=44210874", "title": "Taskara", "text": "Taskara\n\nTaskara is a 2016 Telugu, neo-noir cyber heist Geo political thriller film written by Kiriti Rambhatla . The film is directed by Chandra Sekhar, music by Rohit Kumar, and produced by Libra Media & Entertainment Motion Pictures. The movie is an adaptation of the vigilante hacker character of the graphic novel by Kiriti Rambhatla. \n\nThe teaser of the film was released on the eve of the Indian festival Diwali 22 October 2014 and the trailer came out on 15 January 2015. The trailer shows a mysterious man talking about how easy it is to loot as a bank rather than stepping inside one and looting it. The film had its premiere on December 19, 2015 in Hyderabad and theatrical release on January 8, 2016.\n\nIn a futuristic London of 2062, a Financial Times journalist is researching currencies. He finds a clue about an anonymous professor of Economics and leaves to meet him in India. The journalist is looking for reasons and asks the professor three questions: why World Bank and IMF no longer exist, why and how did the paper money come to an end and the world adopted cryptocurrency and what is Counter Economic Hitmen Agency. The professor explains to the journalist.\n\nA first narrator shows a video of Bretton Woods conference and explains how the present world financial system operates. A second narrator tells of a mysterious hacker. The Deputy Governor of Republican Bank of India discusses on an anonymous phone call about convincing the government. RAW agent Feroze and CBI Officer Mr. Ramayya meet Dr. Narayanan to warn him of a potential hacking attempt. Dr. Narayanan pays no heed and starts discussing the advanced seven layer security protocol of his bank.\n\nHe is informed someone hacked into the RBI system and a huge amount stolen. Dr. Narayanan meets Feroze in Delhi and asks for a high level delegation of members from Financial Intelligence Unit of India. They discuss what could be the potential path of the hacker. An expert says this is a master hacker. He is shown a mysterious hacker video which they record at the Central Cyber Control Room. Feroze and Ramayya move to a recruitment agency and look for clues and go to Financial Software Systems to find out aboutArjun who used to work there . Upon investigation, he threatened a colleague and find a clue to money bank on his desk. Through that clue they meet the manager of money bank. Gireesham has been cheated and his finger prints taken.\n\nDr Narayanan calls Feroze for the details of the hacker. They find the location of the hacker's garage, but the hacker, an ex IMF economist Dr. Arjun Kumar, has moved to an unknown airport. Kumar posts the Lehman Brothers crash is shown delivering to people the negative effects of the present day financial system and how Quantitative Easing a method followed by Central Banks is a bad economic tool. He is also of this opinion that IMF should be more proactive in helping poor nations . Arjun has a discussion with his boss and leaves the work place to meet his girlfriend. The next morning an unknown man tries to kill Dr. Ajun and accidentally kills his girlfriend. He escapes, his parents are taken into police custody and he has been branded a murderer and a cheat. A news segment which shows Dr Narayanan giving an interview about the situation.\n\nDr Narayanan met his boss Christina at IMF . He finds out the Economic Hitmen tried to engage him to convince RBI to introduce a hefty amount into the Indian economy through Quantitative Easing and upon his reluctance, Dr. Narayanan has been roped in to carry it out. Understanding the implications of an additional 10 trillion rupees injection into the Indian economy, Arjun hacks into the RBI portal to divert that money through a systeminto the stock exchanges around this world to invest in private companies helping third world companies. He meets his ex IMF director in Brazil who then tells him she is sorry for the trouble and loss Arjun faced because of her. She mentions how she repents what she did under the pressure of Economic Hit-men at IMF and she quit for another role at a Brazilian bank. Christina offers him a job at an agency she is about to begin. Arjun finds out it is about countering the Economic hitmen and their negative impacts of countries around the world.\n\nThe character of Taskara created by Kiriti Rambhatla appears as a superhero vigilante hacker in the graphic novel series by the same name under Fenil Comics in India. The graphic novel was launched as a 3 part series in various Indian cities like Bangalore & Delhi. The vigilante hacker is a part of the extended superhero universe of Fenil Comics along with other characters like Fualaad, Bajrangi & Stunt Girl.\n\nThe score was composed by Rohit Kumar. \n"}
{"id": "854871", "url": "https://en.wikipedia.org/wiki?curid=854871", "title": "Trivet", "text": "Trivet\n\nA trivet is an object placed between a serving dish or bowl, and a dining table, usually to protect the table from heat damage.\n\nTrivet also refers to a tripod used to elevate pots from the coals of an open fire (the word \"trivet\" itself ultimately comes from Latin \"tripes\" meaning \"tripod\"). Metal trivets are often tripod-like structures with three legs to support the trivet horizontally in order to hold the dish or pot above the table surface. These are often included with modern non-electric pressure cookers. A trivet may often contain a receptacle for a candle that can be lit to keep food warm. \n\nA three-legged design is optimal because it eliminates wobbling on uneven surfaces.\n\nModern trivets are made from metal, wood, ceramic, fabric, silicone or cork. \n\nWhen roasting any meat in an oven, trivet racks - which typically fit into roasting pans - are often used to enable the meat joint to be held above the direct heat of the roasting pan and allow the juices of the joint to drip into the roasting pan for the subsequent making of gravy. A trivet can also be made of freshly cut carrot, celery and onion. This not only raises the meat, i.e. chicken, it has the further advantage of providing a gravy-friendly liquid when the vegetables and juices are sieved at the end of cooking.\n\nA trivet is also a synonym of coaster in Indian English and British English.\n\n"}
{"id": "50973478", "url": "https://en.wikipedia.org/wiki?curid=50973478", "title": "Virtuozzo (company)", "text": "Virtuozzo (company)\n\nVirtuozzo is a privately held software company, specializing in virtualization software. It divested from the Parallels company in 2016. Virtuozzo developed the first commercially available operating system-level virtualization container technology in 2000 which was open-sourced in 2005 in the form of OpenVZ.\n\nThe company was founded in 1997 under the name SWsoft and maintained its headquarters in Herndon, Virginia with additional offices throughout North America, Europe, and Asia. Its research and development offices were located in Moscow, Russia, and it had sales offices in Germany and Singapore. In January 2002, the Virtuozzo 2.0 containers virtualization solution was released. In 2003, SWsoft acquired the makers of and Plesk web hosting products, and expanded its presence in Germany and Novosibirsk, Russia. In December 2007, after the acquisition of Parallels, Inc., SWsoft company announced its plans to change its name to Parallels and distribute its products under the Parallels brand name.\n\nIn December 2015, Virtuozzo spun off and became a standalone company. In May 2016, Virtuozzo announced its intention to join the Open Container Initiative and plans to develop dedicated cloud-based servers as well as a specialized Linux distribution. That same month, Virtuozzo launched the Virtuozzo Application Catalog, which was developed in partnership with Bitnami. Virtuozzo announced a strategic partnership with Jelastic in August 2016 to produce Virtuozzo DevOps, an application orchestration platform aimed at mid to large size companies. The company named George Karidis its CEO in November 2016. Karidis previously headed the cloud business unit at CompuCom.\n\nIn April 2017, Virtuozzo partnered with Packet.net to distribute Virtuozzo software through Packet.\n\nVirtuozzo is an operating system-level server virtualization solution designed to centralize server management and consolidate workloads by reducing the number of physical servers required. Organizations use Virtuozzo for server consolidation, disaster recovery, and server workload agility. Virtuozzo does not generate a virtual machine on a host OS like traditional VM software, but instead, it creates isolated virtual private servers (VPSs) on a single physical server. For instance, the software can run multiple Linux VPSs, but not Linux and Windows at the same time on the same server. Each VPS performs exactly like a stand-alone server and can be rebooted independently.\n\nVirtuozzo for Linux became available in 2001 while a version that supports 32- and 64-bit microprocessors became available in 2005. In 2002, Virtuozzo proved that the 2.5 version of its software could run 2,500 instances of Red Hat Linux on an eight-processor Dell server. As a result, Intel partnered with Virtuozzo in 2002 to develop a partitioning technology for IA-64 processors.\n\nLinux architectures that support Virtuozzo for Linux are x86, ia64, AMD64, EM64T, and Itanium. Virtuozzo for Linux enables multiple Linux distributions to exist simultaneously on one server. It is based on OpenVZ, a Linux-based OS-level virtualization technology, which allows a physical server to run multiple isolated operating system instances. In 2005, the company updated Virtuozzo to support 64-bit x86 processors. Virtuozzo requires at least a Pentium III server with at least 1 GB of memory and 4 GB available hard drive. Virtuozzo’s management tools will be compatible with Microsoft’s Viridian and Virtual Server software. Virtuozzo's container staging is processed through the company's container platform OpenVZ. Virtuozzo 7, which incorporated an optimized Kernel-based Virtual Machine, was released in July 2016.\n\nIn 2012, the company released Virtuozzo Storage, a targeted container storage. The second version of Virtuozzo Storage was released in 2017.\n"}
