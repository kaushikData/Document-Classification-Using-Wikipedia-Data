{"id": "23252526", "url": "https://en.wikipedia.org/wiki?curid=23252526", "title": "ASRock", "text": "ASRock\n\nASRock Inc. () is a Taiwanese manufacturer of motherboards, industrial PCs and home theater PCs (HTPC). Led by Ted Hsu, it was founded in 2002 and is currently owned by Taiwanese electronics company Pegatron.\n\nASRock Inc. is a Taiwan-based electronics manufacturer which focuses on the development of motherboards, industrial PCs and HTPCs.\n\nASRock was originally spun off from Asus in 2002 in order to compete with companies like Foxconn for the commodity OEM market. Since then, ASRock has also gained momentum in the DIY sector and plans for moving the company upstream began in 2007 following a successful IPO on the Taiwan Stock Exchange.\n\nIn 2010 it became part of Pegatron. Asrock currently produces consumer, server, workstation and HTPC motherboards.\n\nASRock has distributors in over 90 countries around the world and branches in Europe, US and China.\n\nASRock established itself as a server motherboard affiliate in April 2013, having received orders from 10 mid-size clients for server and industrial PC motherboards and forming partnerships with system integrators.\n\nASRock is the world's third largest motherboard manufacturer, having cooperated with Johnathan \"Fatal1ty\" Wendel - 12 times FPS World Games championship record holder - in the development of a gaming-oriented enthusiast motherboard in 2011. Additionally, in early 2012 ASRock enlisted the help of HWBOT world overclocking champion, Nick Shih.\n\nBesides motherboards, ASRock also sells desktop minicomputers. Three ASRock products were short-listed for the 2012 Taiwan Brand Award for the first time, and then became endorsed products of the External Trade Development Council when they were promoting the quality image of Taiwan brands globally. In 2012, ASRock stepped into the industrial PC and server motherboard market.\n\nASRock is the Worlds top 3 motherboard brand and the distribution channels cover electronics stores, PC stores, gadget retailers and online shops. Major sales regions in 2011 included Europe for 37.68%, Central and South America accounted for 21.13%, the Asia Pacific region accounted for 40.95% and other markets accounted for only 0.24%. As a whole, ASRock accounted for a large proportion of sales in Asia and Europe in terms of overall performance.\n\nThe Top 3 Motherboard Brand\n\nAccording to the annual report for Digitimes 2011, ASRock has been growing very fast in the past few years. ASRock has been one of the top 3 motherboard brands for 2 consecutive years.\n(\"Note: MSI and ECS' OEM shipments are not included in the figures.\nSource: Companies and market watchers, compiled by Digitimes, November 2012\")\n\nASRock received a \"Tom's Hardware\" 2012 Recommended Buy Award for their X79 Extreme4 motherboard, and also won the Xbit labs 2012 Editor Recommended Award with Z77 Extreme4. Furthermore, ASRock Z68 Extreme7 Gen3, Fatal1ty Z68 Professional Gen3 and the mini PC series was awarded three 2011 Taiwan Brand Awards.\n\nASRock is also the first and only manufacturer of a Mini ITX-sized X99 chipset-based motherboard, the X99E-ITX/ac. It supports Haswell-E and Broadwell-E Intel Core i7 and Haswell-EP Intel Xeon CPUs with CPU core support up to 18 cores.\n\n"}
{"id": "2842321", "url": "https://en.wikipedia.org/wiki?curid=2842321", "title": "American Water Works Association", "text": "American Water Works Association\n\nAmerican Water Works Association (AWWA) is an international non-profit, scientific and educational association founded to improve water quality and supply. Established in 1881, it has a membership (as of 2012) of around 50,000 members worldwide.\n\nIn reviewing the success of the Safe Drinking Water Act after 1974, senior EPA officials cite the vital role that AWWA played as kind of a non‐threatening meeting ground, particularly at the local level.\n\nAWWA members include: water utilities, treatment plant operators and managers, scientists, environmentalists, manufacturers, academics, regulators, and others with an interest in water supply and public health. AWWA works through advocacy, communications, conferences, education and training, science and technology, and local action among 43 AWWA Sections throughout North America.\n\nAWWA launched AWWAIndia, its first international community, in 2015. AWWAIndia's headquarters office is located in Mumbai, India. \n\nTo broaden distribution of information on water and related subjects, AWWA publishes the periodicals \"Journal AWWA\" and \"Opflow.\" AWWA also publishes a variety of books, training manuals, standards, reports and videos for use by water professionals and others. The Association also hosts an annual conference and exposition for the entire organization each summer in North America. Section conferences are also held in all parts of North America. Specialty conferences are held throughout the year on topics including water quality, distribution systems and utility management. Proceedings of the annual and specialty conferences are published by AWWA.\n\nThrough the Partnership for Safe Water AWWA also works with the United States Environmental Protection Agency and other water organizations to help water providers optimize system performance beyond existing regulatory levels.\n\nAWWA offers opportunities for people to meet, learn, and network at the international, national, and section levels. In addition to publications and conferences for water professionals, AWWA hosts a variety of workshops, symposia, teleconferences, and programs focused on specific aspects of water stewardship. In cooperation with other professional associations, AWWA is a resource for water professionals’ continuing education and development.\n\nAWWA presents a number of awards every year to individuals who provide notable service to the drinking water community. Among the major awards given are the Abel Wolman Award of Excellence, the George Warren Fuller Award, and the Dr. John L. Leal Award.\n\nIn 1908, AWWA began developing industry standards for products, processes and best practices. The AWWA Standards Program is recognized internationally as a source for scientific and management reference resources for the water community. Currently, there are over 150 AWWA Standards covering filtration materials, treatment chemicals, disinfection practices, meters, valves, utility management practices, storage tanks, pumps, and ductile iron, steel, concrete, asbestos-cement, and plastic pipe and fittings. Standing committees periodically review and update the standards as required.\n\nIn May 1985, the United States Environmental Protection Agency entered into a cooperative agreement with a consortium led by NSF International to develop voluntary third-party consensus standards and a certification program for all direct and indirect drinking water additives. Other members of the consortium include AWWA. The consortium is responsible for the cooperative effort of manufacturers, regulators, product users and other interested parties that develop and maintain the NSF standards.\n\nIn February 1991, AWWA founded Water For People, a non-profit international development organization that helps people in developing countries improve their quality of life by supporting the development of locally sustainable drinking water resources, sanitation facilities, and health and hygiene education programs.\n\nFor more than 35 years, AWWA has set aside a week in the spring to recognize the importance of safe drinking water throughout North America. In 1988, AWWA brought the event to the attention of the US government and formed a coalition along with the League of Women Voters, the Association of State Drinking Water Administrators and the US Environmental Protection Agency. Subsequently, AWWA worked with Representative Robert Roe and Senator Dennis DeConcini to sponsor a resolution naming the first week of May as \"Drinking Water Week.\" In 1988, a joint congressional resolution declaration was passed and signed by President Ronald Reagan.\n\nAWWA is an umbrella organization for 43 sections, each of whom represents a specific geographic region. There are 37 AWWA sections in the United States, 5 Canadian sections, and one each in Mexico and Puerto Rico. \n\nEPA Alumni Association: Drinking Water, Half Century of Progress – a brief history of U.S. efforts to protect drinking water\n\n"}
{"id": "871497", "url": "https://en.wikipedia.org/wiki?curid=871497", "title": "Atmospheric railway", "text": "Atmospheric railway\n\nAn atmospheric railway uses differential air pressure to provide power for propulsion of a railway vehicle. A static power source can transmit motive power to the vehicle in this way, avoiding the necessity of carrying mobile power generating equipment. The air pressure, or partial vacuum (i.e., negative relative pressure) can be conveyed to the vehicle in a continuous pipe, where the vehicle carries a piston running in the tube. Some form of re-sealable slot is required to enable the piston to be attached to the vehicle. Alternatively the entire vehicle may act as the piston in a large tube.\n\nSeveral variants of the principle were proposed in the early 19th century, and a number of practical forms were implemented, but all were overcome with unforeseen disadvantages and discontinued within a few years.\n\nA modern proprietary system has been developed and is in use for short-distance applications. Porto Alegre Metro airport connection is one of them.\n\nIn the early days of railways, single vehicles or groups were propelled by human power, or by horses. As mechanical power came to be understood, locomotive engines were developed; the \"iron horse\". These had serious limitations, in particular being much heavier than the wagons in use, they broke the rails; and adhesion at the iron-to-iron wheel-rail interface was a limitation, for example in trials on the Kilmarnock and Troon Railway.\n\nMany engineers turned their attention to transmitting power from a static power source, a \"stationary engine\", to a moving train. Such an engine could be more robust and with more available space, potentially more powerful. The solution to transmitting the power, before the days of practical electricity, was the use of either a cable system or air pressure.\n\nIn 1799, George Medhurst of London discussed the idea of moving goods pneumatically through cast iron pipes, and in 1812, he proposed blowing passenger carriages through a tunnel.\n\nMedhurst proposed two alternative systems: either the vehicle itself was the piston, or the tube was relatively small with a separate piston. He never patented his ideas and they were not taken further by him.\n\nIn 1824, a man called Vallance took out a patent and built a short demonstration line; his system consisted of a 6-ft diameter cast iron tube with rails cast in to the lower part; the vehicle was the full size of the tube and bear skin was used to seal the annular space. To slow the vehicle down, doors were opened at each end of the vehicle. Vallance's system worked, but was not adopted commercially.\n\nIn 1835, Henry Pinkus patented a system with a large (9 sq ft) square section tube with a low degree of vacuum, limiting leakage loss. He later changed to a small-bore vacuum tube. He proposed to seal the slot that enabled the piston to connect with the vehicle with a continuous rope; rollers on the vehicle lifted the rope in front of the piston connection and returned it afterwards.\n\nHe built a demonstration line alongside the Kensington Canal, and issued a prospectus for his \"National Pneumatic Railway Association\". He was unable to interest investors, and his system failed when the rope stretched. However his concept, a small bore pipe with a resealable slot was the prototype for many successor systems.\n\nJacob and Joseph Samuda were shipbuilders and engineers, and owned the Southwark Ironworks; they were both members of the Institution of Civil Engineers. Samuel Clegg was a gas engineer and they worked in collaboration on their atmospheric system. About 1835, they read Medhurst's writings, and developed a small bore vacuum pipe system. Clegg worked on a longitudinal flap valve, for sealing the slot in the pipe.\n\nIn 1838, they took out a patent \"for a new improvement in valves\" and built a full-scale model at Southwark. In 1840, Jacob Samuda and Clegg leased half a mile of railway line on the West London Railway at Wormholt Scrubs (later renamed Wormwood Scrubs), where the railway had not yet been opened to the public. In that year Clegg left for Portugal, where he was pursuing his career in the gas industry.\n\nSamuda's system involved a continuous (jointed) cast iron pipe laid between the rails of a railway track; the pipe had a slot in the top. The leading vehicle in a train was a \"piston carriage\", which carried a piston inserted in the tube. It was held by a bracket system that passed through the slot, and the actual piston was on a pole ahead of the point at which the bracket left the slot. The slot was sealed from the atmosphere by a continuous leather flap that was opened immediately in advance of the piston bracket and closed again immediately behind it. A pumping station ahead of the train would pump air from the tube, and air pressure behind the piston would push it forward.\n\nThe Wormwood Scrubbs demonstration ran for two years. The traction pipe was of 9 inches diameter, and a 16 hp stationary engine was used for power. The gradient on the line was a steady 1 in 115. In his treatise, described below, Samuda implies that the pipe would be used in one direction only, and the fact that only one pumping station was erected suggests that trains were gravitated back to the lower end of the run after the atmospheric ascent, as was later done on the Dalkey line (below). Many of the runs were public. Samuda quotes the loads and degree of vacuum and speed of some of the runs; there seems to be little correlation; for example:\n\n\nThere was enormous public interest in the ideas surrounding atmospheric railways, and at the same time as Samuda was developing his scheme, other ideas were put forward. These included:\n\n\nIn 1841, Joseph Samuda published \"A Treatise on the Adaptation of Atmospheric Pressure to the Purposes of Locomotion on Railways\".\n\nIt ran to 50 pages, and Samuda described his system; first the traction pipe:\nThe moving power is communicated to the train through a continuous pipe or main, laid between the rails, which is exhausted by air pumps worked by stationary steam engines, fixed on the road side, the distance between them varying from one to three miles, according to the nature and traffic of the road. A piston, which is introduced into this pipe, is attached to the leading carriage in each train, through a lateral opening, and is made to travel forward by means of the exhaustion created in front of it. The continuous pipe is fixed between the rails and bolted to the sleepers which carry them; the inside of the tube is unbored, but lined or coated with tallow 1/10th of an inch thick, to equalize the surface and prevent any unnecessary friction from the passage of the travelling piston through it.\n\nThe operation of the closure valve was to be critical:\nAlong the upper surface of the pipe is a continuous slit or groove about two inches wide. This groove is covered by a valve, extending the whole length of the railway, formed of a strip of leather riveted between iron plates, the top plates being wider than the groove and serving to prevent the external air forcing the leather into the pipe when the vacuum is formed within it; and the lower plates fitting into the groove when the valve is shut, makes up the circle of the pipe, and prevents the air from passing the piston; one edge of this valve is securely held down by iron bars, fastened by screw bolts to a longitudinal rib cast on the pipe, and allows the leather between the plates and the bar to act as a hinge, similar to a common pump valve; the other edge of the valve falls into a groove which contains a composition of beeswax and tallow: this composition is solid at the temperature of the atmosphere, and becomes fluid when heated a few degrees above it. Over this valve is a protecting cover, which serves to preserve it from snow or rain, formed of thin plates of iron about five feet long hinged with leather, and the end of each plate underlaps the next in the direction of the piston's motion, thus ensuring the lifting of each in succession.\n\nThe piston carriage would open and then close the valve:\nTo the underside of the first carriage in each train is attached the piston and its appurtenances; a rod passing horizontally from the piston is attached to a connecting arm, about six feet behind the piston. This connecting arm passes through the continuous groove in the pipe, and being fixed to the carriage, imparts motion to the train as the tube becomes exhausted; to the piston rod are also attached four steel wheels, (two in advance and two behind the connecting arm,) which serve to lift the valve, and form a space for the passage of the connecting arm, and also for the admission of air to the back of the piston; another steel wheel is attached to the carriage, regulated by a spring, which serves to ensure the perfect closing of the valve, by running over the top plates immediately after the arm has passed. A copper tube or heater, about ten feet long, constantly kept hot by a small stove, also fixed to the underside of the carriage, passes over and melts the surface of the composition (which has been broken by lifting the valve,) which upon cooling becomes solid, and hermetically seals the valve. Thus each train in passing leaves the pipe in a fit state to receive the next train.\n\nEntering and leaving the pipe was described:\nThe continuous pipe is divided into suitable sections (according to the respective distance of the fixed steam engines) by separating valves, which are opened by the train as it goes along: these valves are so constructed that no stoppage or diminution of speed is necessary in passing from one section to another. The exit separating valve, or that at the end of the section nearest to its steam engine, is opened by the compression of air in front of the piston, which necessarily takes place after it has passed the branch which communicates with the air-pump; the entrance separating valve, (that near the commencement of the next section of pipe,) is an equilibrium or balance valve, and opens immediately the piston has entered the pipe. The main pipe is put together with deep socket joints, in each of which an annular space is left about the middle of the packing, and filled with a semi-fluid: thus any possible leakage of air into the pipe is prevented.\n\nAt that time railway were developing rapidly, and solutions to the technical limitations of the day were eagerly sought, and not always rationally evaluated. Samuda's treatise put forward the advantages of his system:\n\n\nSamuda also rebutted criticisms of his system that had obviously become widespread:\n\n\nIn April 1844, Jacob and Joseph Samuda took out a patent for their system. Soon after this, Joseph Samuda died and it was left to his brother Jacob to continue the work. The patent was in three parts: the first describing the atmospheric pipe and piston system, the second describing how in areas of plentiful water supply, the vacuum might be created by using tanks of water at differing levels; and the third section dealt with level crossings of an atmospheric railway.\n\nThe Dublin and Kingstown Railway opened in 1834 connecting the port of Dún Laoghaire (then called Kingstown) to Dublin; it was a standard gauge line. In 1840, it was desired to extend the line to Dalkey, a distance of about two miles. A horse tramway on the route was acquired and converted: it had been used to bring stone from a quarry for the construction of the harbour. It was steeply graded (at 1 in 115 with a 440-yard stretch of 1 in 57) and heavily curved, the sharpest being 570 yards radius. This presented significant difficulties to the locomotives then in use. The treasurer of the company, James Pim, was visiting London and hearing of Samuda's project he viewed it. He considered it to be perfect for the requirements of his company, and after petitioning government for a loan of £26,000, it was agreed to install it on the Dalkey line. Thus became the Dalkey Atmospheric Railway.\n\nA 15-inch traction pipe was used, with a single pumping station at Dalkey, at the upper end of the 2,400-yard run. The engine created 110 ihp and had a flywheel of 36 feet diameter. Five minutes before the scheduled departure of a train from Kingstown, the pumping engine started work, creating a 15-inch vacuum in two minutes. The train was pushed manually to the position where the piston entered the pipe, and the train was held on the brakes until it was ready to start. When that time came, the brakes were released and the train moved off. (The electric telegraph was later installed, obviating reliance on the timetable for engine operation.)\n\nOn 17 August 1843, the tube was exhausted for the first time, and the following day a trial run was made. On Saturday 19 August, the line was opened to the public. In service, a typical speed of 30 mph was attained; return to Kingstown was by gravitation down the gradient, and slower. By March 1844, 35 train movements operated daily, and 4,500 passengers a week travelled on the line, mostly simply for the novelty.\n\nIt is recorded that a young man called Frank Elrington was on one occasion on the piston carriage, which was not attached to the train. On releasing the brake, the light vehicle shot off at high speed, covering the distance in 75 seconds, averaging 65 mph.\n\nAs this was the first commercially operating atmospheric railway, it attracted the attention of many eminent engineers of the day, including Isambard Kingdom Brunel, Robert Stephenson, and Sir William Cubitt.\n\nThe line continued to operate successfully for ten years, outliving the atmospheric system on British lines, although the Paris - St Germain line continued until 1860.\n\nWhen the system was abolished in 1855, a 2-2-2 steam locomotive called Princess was employed, incidentally the first steam engine to be manufactured in Ireland. Although a puny mechanism, the steam engine successfully worked the steeply graded line for some years.\n\nIn 1835, the brothers Pereire obtained a concession from the \"Compagnie du Chemin de fer de Paris à Saint-Germain\". They opened their 19 km line in 1837, but only as far as Le Pecq, a river quay on the left bank of the Seine, as a daunting incline would have been necessary to reach Saint-Germain-en-Laye, and locomotives of the day were considered incapable of climbing the necessary gradient, adhesion being considered the limiting factor.\n\nOn hearing of the success of the Dalkey railway, the French minister of public works (M. Teste) and under-secretary of state (M. Le Grande) dispatched M. Mallet, inspecteur général honoraire des Ponts et Chaussées, to Dalkey. He wrote an exhaustive technical evaluation of the system installed there, and its potential, which included the results of measurements made with Joseph Samuda.\n\nIt was through his interest that the Pereire brothers to adopt the system for an extension to St Germain itself, and construction started in 1845, with a wooden bridge crossing the Seine followed by a twenty-arch masonry viaduct and two tunnels under the castle. The extension was opened on 15 April 1847; it was 1.5 km in length on a gradient of 1 in 28 (35 mm/m).\n\nThe traction pipe was laid between the rails; it had a diameter of 63 cm (25 inches) with a slot at the top. The slot was closed by two leather flaps. The pumps are powered by two steam engines with a capacity of 200 hp, located between the two tunnels at Saint-Germain. Train speed on the ascent was 35 km/h (22 mph). On the descent the train ran by gravity as far as Pecq, where the steam locomotive took over for the run to Paris.\n\nThe system was technically successful, but the development of more powerful steam locomotives led to its abandonment from 3 July 1860, when steam locomotive ran throughout from Paris to St Germain, being assisted by a pusher locomotive up the gradient. This arrangement continued for more than sixty years until the electrification of the line.\n\nA correspondent of the \"Ohio State Journal\" described some details; there seem to have been two tube sections:\n\nAn iron tube is laid down in the centre of the track, which is sunk about one-third of its diameter in the bed of the road. For a distance of 5,500 yards the tube has a diameter of only 1¾ feet [i.e. 21 inches], the ascent here being so slight as not to require the same amount of force as is required on the steep grade to St Germain, where the pipe, for a distance of 3,800 yards, is 2 feet 1 inch [i.e. 25 inches] in diameter.\n\nThe steam engines had accumulators:\n\nTo each engine is adapted two large cylinders, which exhaust fourteen cubic feet of air per second. The pressure in the air cauldron (claudieres) attached to the exhausting machines is equal to six absolute atmospheres.\n\nHe described the valve:\n\nThroughout the entire length of the tube, a section is made in the top, leaving an open space of about five inches. In each cut edge of the section there is an offset, to catch the edges of a valve which fits down upon it. The valve is made of a piece of sole leather half an inch thick, having plates of iron attached to it on both the upper and corresponding under side to give it strength ... which are perhaps one-fourth of an inch in thickness ... The plates are about nine inches long, and their ends, above and below, are placed three quarters of an inch apart, forming joints, so as to give the leather valve pliability, and at the same time firmness.\n\nClayton records the name of the engineer, Mallet, who had been Inspector general of Public Works, and gives a slightly different account: Clayton says that Mallet used a plaited rope to seal the slot. He also says that vacuum was created by condensing steam in a vacuum chamber between runs, but that may have been a misunderstanding of the pressure accumulators.\n\nThe London and Croydon Railway (L&CR) obtained its authorising Act of Parliament in 1835, to build its line from a junction with the London and Greenwich Railway (L&GR) to Croydon. At that time the L&GR line was under construction, and Parliament resisted the building of two railway termini in the same quarter of London, so that the L&CR would have to share the L&GR's London Bridge station. The line was built for ordinary locomotive operation. A third company, the London and Brighton Railway (L&BR) was promoted and it too had to share the route into London by running over the L&CR.\n\nWhen the lines opened in 1839, it was found that congestion arose due to the frequent stopping services on the local Croydon line; this was particularly a problem on the 1 in 100 ascent from New Cross to Dartmouth Arms. The L&CR engineer, William Cubitt proposed a solution to the problem: a third track would be laid on the east side of the existing double track main line, and all the local trains in both directions would use it. The faster Brighton trains would be freed of the delay following a stopping train. Cubitt had been impressed during his visit to the Dalkey line, and the new L&CR third track would use atmospheric power. The local line would also be extended to Epsom, also as a single track atmospheric line. These arrangements were adopted and Parliamentary powers obtained on 4 July 1843, also authorising a line to a terminal at Bricklayers Arms. Arrangements were also made with the L&GR for them to add an extra track on the common section of their route. On 1 May 1844, the Bricklayers Arms terminus opened, and a frequent service was run from it, additional to the London Bridge trains.\n\nThe L&CR line diverged to the south-west at Norwood Junction (then called \"Jolly Sailor\", after an inn), and needed to cross the L&BR line. The atmospheric pipe made this impossible on the flat, and a flyover was constructed to enable the crossing: this was the first example in the railway world. This was in the form of a wooden viaduct with approach gradients of 1 in 50. A similar flyover was to be built at Corbetts Lane Junction, where the L&CR additional line was to be on the north-east side of the existing line, but this was never made.\n\nA 15-inch diameter traction pipe was installed between Forest Hill (then called \"Dartmouth Arms\", also after a local inn) and West Croydon. Although Samuda supervised the installation of the atmospheric apparatus, a weather flap, a hinged iron plate that covered the leather slot valve in the Dalkey installation, was omitted. The L&CR had an Atmospheric Engineer, James Pearson. Maudsley, Son and Field supplied the three 100 hp steam engines and pumps at Dartmouth Arms, Jolly Sailor and Croydon (later West Croydon), and elaborate engine houses had been erected for them. They were designed in a gothic style by W H Brakespear, and had tall chimneys which also exhausted the evacuated air at high level.\n\nA two-needle electric telegraph system was installed on the line, enabling station staff to indicate to the remote engine house that a train was ready to start.\n\nThis section, from Dartmouth Arms to Croydon started operation on the atmospheric system in January 1846.\n\nThe traction pipe slot and the piston bracket were handed; that is the slot closure flap was continuously hinged on one side, and the piston support bracket was cranked to minimise the necessary opening of the flap. This meant that the piston carriage could not simply be turned on a turntable at the end of a trip. Instead it was double ended, but the piston was manually transferred to the new leading end. The piston carriage itself had to be moved manually (or by horse power) to the leading end of the train. At Dartmouth Arms the station platform was an island between the two steam operated lines. Cubitt designed a special system of pointwork that enabled the atmospheric piston carriage to enter the ordinary track.\n\nThe Board of Trade inspector, General Pasley, visited the line on 1 November 1845 to approve it for opening of the whole line. The Times newspaper reported the event; a special train left London Bridge hauled by a steam locomotive; at Forest Hill the locomotive was detached and:\n\nthe piston carriage substituted and the train thence became actuated by atmospheric pressure. The train consisted of ten carriages (including that to which the piston is attached) and its weight was upward of fifty tons. At seven and a half minutes past two the train left the point of rest at the Dartmouth Arms, and at eight and three-quarter minutes past, the piston entered the valve, when it immediately occurred to us that one striking advantage of the system was the gentle, the almost imperceptible, motion on starting. On quitting the station on locomotive lines we have frequently experienced a \"jerk\" amounting at times to an absolute \"shock\" and sufficient to alarm the nervous and timid passenger. Nothing of the sort, however, was experienced here. Within a minute and a quarter of the piston entering the pipe, the speed attained against a strong headwind was at the rate of twelve miles an hour; in the next minute, viz. at eleven minutes past two, twenty-five miles an hour; at thirteen minutes past two, thirty-four miles an hour; fourteen minutes past two, forty miles an hour; and fifteen minutes past two, fifty-two miles an hour, which was maintained until sixteen minutes past two, when the speed began to diminish, and at seventeen and a half minutes past two, the train reached the Croydon terminus, thus performing the journey from Dartmouth Arms, five miles, in eight minutes and three-quarters. The barometer in the piston carriage indicated a vacuum of 25 inches and that in the engine house a vacuum of 28 inches.\n\nThe successful official public run was widely reported and immediately new schemes for long-distance railways on the atmospheric system were being promoted; the South Devon Railway's shares appreciated overnight.\n\nPasley's report of 8 November was favourable, and the line was clear to open. The directors hesitated, desiring to gain a little more experience beforehand. On 19 December 1845 the crankshaft of the Forest Hill stationary engine fractured, and the engine was unusable. However the part was quickly replaced and on 16 January 1846, the line opened.\n\nAt 11:00 that morning the crankshaft of one of the Croydon engines broke. Two engines had been provided, so traffic was able to continue using the other, until at 7:20 p.m. that engine suffered the same fate. Again repairs were made until 10 February 1846, when both of the Croydon engines failed.\n\nThis was a bitter blow for the adherents of the atmospheric system; shortcomings in the manufacture of the stationary engines procured from a reputable engine-maker said nothing about the practicality of the atmospheric system itself, but as Samuda said to the Board:\n\n\"The public cannot discriminate (because it cannot know) the cause of the interruptions, and every irregularity is attributed to the atmospheric system.\"\n\nTwo months later, the beam of one of the Forest Hill engines fractured. At this time the directors were making plans for the Epsom extension; they quickly revised their intended purchase of engines from Maudsley, and invited tenders; Boulton and Watt of Birmingham were awarded the contract, their price having been considerably less than their competitors'.\n\nThe London and Brighton Railway amalgamated with the L&CR on 6 July 1846, forming the London, Brighton and South Coast Railway (LB&SCR). For the time being the directors of the larger company continued with the L&CR's intentions to use the atmospheric system.\n\nThe summer of 1846 was exceptionally hot and dry, and serious difficulties with the traction pipe flap valve started to show themselves. It was essential to make a good seal when the leather flap was closed, and the weather conditions made the leather stiff. As for the tallow and beeswax compound that was supposed to seal the joint after every train, Samuda had originally said \"this composition is solid at the temperature of the atmosphere, and becomes fluid when heated a few degrees above it\" and the hot weather had that effect. Samuda's original description of his system had included a metal weather valve that closed over the flap, but this had been omitted on the L&CR, exposing the valve to the weather, and also encouraging the ingestion of debris, including, an observer reported, a handkerchief dropped by a lady on to the track. Any debris lodging in the seating of the flap could only have reduced its effectiveness.\n\nMoreover the tallow – that is, rendered animal fat – was attractive to the rat population; their bodies drawn in to the traction pipe at the beginning of pumping in the morning told its story. Delays became frequent, due to inability to create enough vacuum to move the trains, and stoppages on the steep approach inclines at the flyover were commonplace, and widely reported in the press.\n\nThe Directors now began to feel uneasy about the atmospheric system, and in particular the Epsom extension, which was to have three engines. In December 1846, they asked Boulton and Watt about cancelling the project, and were told that suspending the supply contract for a year would cost £2,300. The Directors agreed to this.\n\nThe winter of 1846/7 brought new meteorological difficulties: unusually cold weather made the leather flap stiff, and snow got into the tube resulting in more cancellations of the atmospheric service. A track worker was killed in February 1847 while steam substitution was in operation. This was tragically unfortunate, but it had the effect of widespread reporting that the atmospheric was, yet again, non-operational.\n\nThrough this long period, the Directors must have become less and less committed to pressing on with the atmospheric system, even as money was being spent on extending it towards London Bridge. (It opened from Dartmouth Arms to New Cross in January 1847, using gravitation northbound and the Dartmouth Arms pumping station southbound.) In a situation in which public confidence was important, the Directors could not express their doubts publicly, at least until a final decision had been taken. On 4 May 1847, the directors announced \"that the Croydon Atmospheric pipes were pulled up and the plan abandoned\".\n\nThe reason seems not to have been made public at once, but the trigger seems to have been the insistence of the Board of trade inspector on a second junction at the divergence of the Brighton and Epsom lines. It is not clear what this refers to, and may simply have been a rationalisation of the timing of a painful decision. Whatever the reason, there was to be no more atmospheric work on the LB&SCR.\n\nThe Great Western Railway (GWR) and the Bristol and Exeter Railway working collaboratively had reached Exeter on 1 May 1844, with a broad gauge railway connecting the city to London. Interested parties in Devonshire considered it important to extend the connection to Plymouth, but the terrain posed considerable difficulties: there was high ground with no easy route through.\n\nAfter considerable controversy, the South Devon Railway Company (SDR) obtained its Act of Parliament authorising a line, on 4 July 1844.\n\nThe Company's engineer was the innovative engineer Isambard Kingdom Brunel. He had visited the Dalkey line and he had been impressed with the capabilities of the atmospheric system on that line. Samuda had always put forward the advantages of his system, which (he claimed) included much better hill climbing abilities and lighter weight on the track. This would enable a line in hilly terrain to be planned with steeper than usual gradients, saving substantial cost of construction.\n\nIf Brunel had decided definitely to use the atmospheric system at the planning stage, it would have allowed him to strike a route that would have been impossible with the locomotive technology of the day. The route of the South Devon Railway, still in use today, has steep gradients and is generally considered \"difficult\". Commentators often blame this on it being designed for atmospheric traction; for example:\n\nSekon, describing the topography of the line, says that beyond Newton Abbot,\n\nthe conformation of the country is very unsuitable for the purpose of constructing a railway with good gradients. This drawback did not at the time trouble Mr. Brunel, the engineer to the South Devon Railway Company, since he proposed to work the line on the atmospheric principle, and one of the advantages claimed for the system being that steep banks were as easy to work as a level.\n\n\nIn fact the decision to \"consider\" the adoption of the atmospheric system came \"after\" Parliamentary authorisation, and the route must have been finalised before submission to Parliament.\n\nEight weeks after passage of the Act, the shareholders heard that \"Since the passing of the Act, a proposal has been received ... from Messrs. Samuda Brothers ... to apply their system of traction to the South Devon Line.\" Brunel and a deputation of the directors had been asked to visit the Dalkey line. The report went on that as a result,\n\nIn view of the fact that at many points of the line both the gradients and curves will render the application of this principle particularly advantageous, your directors have resolved that the atmospheric system, including an electric telegraph, should be adopted on the whole line of the South Devon Railway.\n\nConstruction started at once on the section from Exeter to Newton Abbot (at first called \"Newton\"); this first part is broadly level: it was the section onwards from Newton that was hilly. Contracts for the supply of the pumping engines and machinery were concluded on 18 January 1845, to be delivered by 1 July in the same year. Manufacture of the traction pipes ran into difficulties: they were to be cast with the slot formed, and distortion was a serious problem at first.\n\nDelivery of the machinery and laying of the pipes was much delayed, but on 11 August 1846, with that work still in progress, a contract was let for the engines required over the hilly section beyond Newton. These were to be more powerful, at , and in one case, and the traction pipe was to be of a larger diameter.\n\nThe train service started between Exeter and Teignmouth on 30 May 1846, but this was operated by steam engines, hired in from the GWR. At length, on 13 September 1847 the first passenger trains started operating on the atmospheric system. Atmospheric goods trains may have operated a few days previously.\n\nFour atmospheric trains ran daily in addition to the advertised steam service, but after a time they replaced the steam trains. At first the atmospheric system was used as far as Teignmouth only, from where a steam engine hauled the train including the piston carriage to Newton, where the piston carriage was removed, and the train continued on its journey. From 9 November some atmospheric working to Newton took place, and from 2 March 1848, all trains on the section were atmospheric.\n\nThrough that winter of 1847-8 a regular service was maintained to Teignmouth. The highest speed recorded was an average of over hauling , and when hauling .\n\nTwo significant limitations of the atmospheric system were overcome at this period. The first was an auxiliary traction pipe was provided at stations; it was laid outside the track, therefore not obstructing pointwork. The piston carriage connected to it by a rope—the pipe must have had its own piston—and the train could be hauled into a station and on to the start of the onward main pipe. The second development was a level crossing arrangement for the pipe: a hinged cover plate lay across the pipe for road usage, but when the traction pipe was exhausted, a branch pipe actuated a small piston which raised the cover, enabling the piston carriage to pass safely, and acting as a warning to road users. Contemporary technical drawings show the traction pipe considerably lower than normal, with its top about level with the rail heads, and with its centre at the level of the centre of the transoms. No indication is shown as to how track gauge was maintained.\n\nAlthough the trains were running ostensibly satisfactorily, there had been technical miscalculations. It seems that Brunel originally specified for the level section to Newton and pipes for the hilly part of the route, and in specifying the stationary engine power and vacuum pumps, he considerably underpowered them. The pipes seem to have been scrapped, and pipes installed in their place, and pipes started to be installed on the hilly sections. Changes to the engine control governors were made to uprate them to run 50% faster than designed. It was reported that coal consumption was much heavier than forecast, at 3s 1½d per train mile instead of 1s 0d (and instead of 2s 6d which was the hire charge for the leased GWR steam locomotives). This may have been partly due to the electric telegraph not yet having been installed, necessitating pumping according to the timetable, even though a train might be running late. When the telegraph was ready, on 2 August, coal consumption in the following weeks fell by 25%.\n\nDuring the winter of 1847–1848, the leather flap valve that sealed the traction pipe slot began to give trouble. During the cold days of winter, the leather froze hard in frost after saturation in rain. This resulted in its failing to seat properly after the passage of a train, allowing air into the pipe and reducing the effectiveness of pumping. In the following spring and summer, there was hot and dry weather and the leather valve dried out, with pretty much the same outcome. Brunel had the leather treated with whale oil in an attempt to maintain flexibility. There was said to be a chemical reaction between the tannin in the leather and iron oxide on the pipe. There were also difficulties with the leather cup seal on the pistons.\n\nCommentators observe that the South Devon system omitted the iron weather flap that was used on the Dalkey line to cover the flap valve. On that line iron plates were turned away immediately ahead of the piston bracket. It is not recorded why this was omitted in South Devon, but at speed that arrangement must have involved considerable mechanical force, and generated environmental noise.\n\nIn May and June, even more serious trouble was experienced when sections of the flap tore away from its fixing, and sections had to be quickly replaced. Samuda had a contract with the company to maintain the system, and he advised installation of a weather cover, but this was not adopted. This would not have rectified the immediate problem, and complete replacement of the leather flap was required; this was estimated to cost £32,000—a very large sum of money then—and Samuda declined to act.\n\nWith a contractual impasse during struggles to keep a flawed system in operation, it was inevitable that the end was near. At a shareholders' meeting on 29 August 1848, the directors were obliged to report all the difficulties, and that Brunel had advised abandonment of the atmospheric system; arrangements were being made with the Great Western Railway to provide steam locomotives, and the atmospheric system would be abandoned from 9 September 1848.\n\nBrunel's report to the Directors, now shown the meeting, was comprehensive, and he was also mindful of his own delicate position, and of the contractual obligations of Samuda. He described the stationary engines, obtained from three suppliers: \"These engines have not, on the whole, proved successful; none of them have as yet worked very economically, and some are very extravagant in the use of fuel.\" As to the difficulties with the leather valve in extremes of weather, heat, frost and heavy rain,\n\nThe same remedies apply to all three, keeping the leather of the valve oiled and varnished, and rendering it impervious to the water, which otherwise soaks through it in wet weather, or which freezes it in cold, rendering it too stiff to shut down; and the same precaution prevents the leather being dried up and shrivelled by the heat; for this, and not the melting of the composition, is the principal inconvenience resulting from heat. A little water spread on the valve from a tank in the piston carriage has also been found to be useful in very dry weather, showing that the dryness, and not the heat, was the cause of the leakage.\n\nBut there was a much more serious problem: \"A considerable extent of longitudinal valve failed by the tearing of the leather at the joints between the plates. The leather first partially cracked at these points, which caused a considerable leakage, particularly in dry weather. After a time it tears completely through.\"\n\nMaintenance of the traction pipe and the valve was Samuda's contractual responsibility, but Brunel indicated that he was blaming the company for careless storage, and for the fact that the valve had been installed for some time before being used by trains; Brunel declined to go into the liability question, alluding to possible palliative measures, but concluded:\n\nThe cost of construction has far exceeded our expectations, and the difficulty of working a system so totally different from that to which everybody—traveller as well as workmen—is accustomed, have (sic) proved too great; and therefore, although, no doubt, after some further trial, great reductions may be made in the cost of working the portion now laid, I cannot anticipate the possibility of any inducement to continue the system beyond Newton.\n\nHuge hostility was generated among some shareholders, and Samuda, and Brunel in particular were heavily criticised, but the atmospheric system on the line was finished.\n\nThomas Gill had been Chairman of the South Devon board and wished to continue with the atmospheric system. In order to press for this he resigned his position, and in November 1848, he published a pamphlet urging retention of the system. He created enough support for this that an Extraordinary General Meeting of the Company was held on 6 January 1849. Lengthy technical discussion took place, in which Gill stated that Clark and Varley were prepared to contract to complete the atmospheric system and maintain it over a section of the line. There were, Gill said, twenty-five other inventors anxious to have their creations tried out on the line. The meeting lasted for eight hours, but finally a vote was taken: a majority of shareholders present were in favour of continuing with the system, 645 to 567 shares. However a large block of proxies were held by shareholders who did not wish to attend the meeting, and with their votes abandonment was confirmed by 5,324 to 1,230.\n\nThat was the end of the atmospheric system on the South Devon Railway.\n\nIt is often asserted among enthusiasts' groups that the primary cause of the failure of the leather flap was rats, attracted to the tallow, gnawing at it. Although rats are said to have been drawn into the traction pipe in the early days, there was no reference to this at the crisis meeting described above.\n\nThe piston carriage on the demonstration line was an open four-wheeled track. No controls of any kind are shown on a drawing. The beam that carried the piston was called the \"perch\", and it was attached directly to the axles, and pivoted at its centre point; it had a counterweight to the rear of the attachment bracket (called a \"coulter\").\n\nThe customary train consist was two coaches, the piston carriage, which included a guard's compartment and third class accommodation, and a first class carriage, with end observation windows at the rear. The guard had a screw brake, but no other control. Returning (descending) was done under gravity, and the guard had a lever which enabled him to swing the piston assembly to one side, so that the descent was made with the piston outside the tube.\n\nThe section put into service, Le Pecq to Saint Germain, was almost exactly the same length as the Dalkey line, and was operated in a similar way except that the descent by gravity was made with the piston in the tube so that air pressure helped retard speed. The upper terminal had sidings, with switching managed by ropes.\n\nThe piston carriages were six-wheeled vans, with a driver's platform at each end, as they were double ended. The driver's position was within the carriage, not in the open. The centre axle was unsprung, and the piston assembly was directly connected to it. The driver had a vacuum gauge (a mercury manometer, connected by a metal tube to the head of the piston. Some vehicles were fitted with speedometers, an invention of Moses Ricardo. As well as a brake, the driver had a by-pass valve which admitted air to the partially exhausted traction tube ahead of the piston, reducing the tractive force exerted. This seems to have been used on the 1 in 50 descent from the flyover. The lever and valve arrangement are shown in a diagram in Samuda's \"Treatise\".\n\nPart of Samuda's patent included the variable diameter piston, enabling the same piston carriage to negotiate route sections with different traction tube sizes. Clayton describes it: the change could be controlled by the driver while in motion; a lever operated a device rather like an umbrella at the rear of the piston head; it had hinged steel ribs. To accommodate the bracket for the piston, the traction tube slot, and therefore the top of the tube, had to be at the same level whatever the diameter of the tube, so that all of the additional space to be sealed was downwards and sideways; the \"umbrella\" arrangement was asymmetrical. In fact this was never used on the South Devon Railway as the 22 inch tubes there were never opened; and the change at Forest Hill only lasted four months before the end of the atmospheric system there. A variable diameter piston was also intended to be used on the Saint-Germain railway, where a 15 inch pipe was to be used from Nanterre to Le Pecq, and then a 25 inch pipe on the three and half per cent grade up to Saint-Germain. Only the 25 inch section was completed, so a simple piston was used. \n\n\nIn the Dainton engine house, a vacuum receiver was to be installed in the inlet pipe to the pumps. This was apparently an interceptor for debris that might be ingested into the traction pipe; it had an openable door for staff to clear the debris from time to time.\n\n\nTwo demonstration railways were built with the entire car inside the tube rather than only a piston. In both cases the cars were pushed by atmospheric pressure in one direction and increased pressure in the other, and in both cases the object was to run cars underground without the smoke and gas of steam locomotives.\n\n\n\nThe nineteenth century attempts to make a practical atmospheric system (described below) were defeated by technological shortcomings. In the present day, modern materials have enabled a practical system to be implemented.\n\nTowards the end of the twentieth century the Aeromovel Corporation of Brazil developed an automated people mover that is atmospherically powered. Lightweight trains ride on rails mounted on an elevated hollow concrete box girder that forms the air duct. Each car is attached to a square plate—the piston—within the duct, connected by a mast running through a longitudinal slot that is sealed with rubber flaps. Stationary electric air pumps are located along the line to either blow air into the duct to create positive pressure or to exhaust air from the duct to create a partial vacuum. The pressure differential acting on the piston plate causes the vehicle to move.\n\nElectric power for lighting and braking is supplied to the train by a low voltage (50v) current through the track the vehicles run on; this is used to charge onboard batteries. The trains have conventional brakes for accurate stopping at stations; these brakes are automatically applied if there is no pressure differential acting on the plate. Fully loaded vehicles have a ratio of payload to dead-weight of about 1:1, which is up to three times better than conventional alternatives. The vehicles are driverless with motion determined by lineside controls. Aeromovel was designed in the late 1970s by Brazilian .\n\nThe system was first implemented in 1989 at Taman Mini Indonesia Indah, Jakarta, Indonesia. It was constructed to serve a theme park; it is a loop with six stations and three trains.\n\nThe Aeromovel system is in operation at Porto Alegre Airport, Brazil. A line connecting the Estação Aeroporto (Airport Station) on the Porto Alegre Metro) and Terminal 1 of Salgado Filho International Airport began operation on Saturday 10 August 2013. The single line is long with a travel time of 90 seconds. The first 150-passenger vehicle was delivered in April 2013 with a 300-passenger second vehicle delivered later.\n\nIn 2016, construction commenced on a 4.7 km single line with seven stations in the city of Canoas. Construction was due to be completed in 2017 but in March 2018 the new city administration announced that the project had been suspended pending endorsement from central government and that equipment already purchased had been placed in storage. The new installation is part of a planned 18 km, two line, twenty four station system in the city.\n\nFlight Rail Corp. in the USA has developed the concept of a high-speed atmospheric train that uses vacuum and air pressure to move passenger modules along an elevated guideway. Stationary power systems create vacuum (ahead of the piston) and pressure (behind the piston) inside a continuous pneumatic tube located centrally below rails within a truss assembly. The free piston is magnetically coupled to the passenger modules above; this arrangement allows the power tube to be closed, avoiding leakage. The transportation unit operates above the power tube on a pair of parallel steel rails.\n\nThe company currently has a 1/6 scale pilot model operating on an outdoor test guideway. The guideway is 2095 feet (639 m) long and incorporates 2%, 6% and 10% grades. The pilot model operates at speeds up to 25 mph (40 km/h). The Corporation claims that a full-scale implementation would be capable of speeds in excess of 200 mph (322 km/h).\n\n\n"}
{"id": "54282893", "url": "https://en.wikipedia.org/wiki?curid=54282893", "title": "Audio-Technica AT-LP120", "text": "Audio-Technica AT-LP120\n\nThe Audio-Technica AT-LP120 is a mid-range direct-drive turntable introduced in 2009 by the Japanese audio equipment manufacturer Audio-Technica. The AT-LP120 was intended to be a viable replacement for the long-running Technics SL-1200 series of turntables that was set to be discontinued in 2010. It supports both phono and line-level output using a built-in preamplifier.\n\nThe turntable also has the ability to dub records directly to a computer in real-time using a USB connection.\n\nSince it was designed to mimic the Technics SL-1200 series of turntables, the AT-120 shares many design traits with the older Technics models, including:\n\n"}
{"id": "7089455", "url": "https://en.wikipedia.org/wiki?curid=7089455", "title": "Australian Training Awards", "text": "Australian Training Awards\n\nhttps://www.education.vic.gov.au/about/awards/vta/Pages/vtaaustralian.aspxhttps://www.google.com/search?q=Aboriginal+and+Torres+Strait+Islander+Student+of+the+Year+Award&ie=utf-8&oe=utf-8&client=firefox-b-ab\n\nThe Australian Training Awards are the peak national awards for the vocational education and training (VET) sector, recognising organisations, registered training organisations and individuals for their contribution to skilling Australia.\n\nThere are 18 Australian Training Award categories. A majority of categories articulate from the state or territory training awards with the remainder available by direct entry to the Australian Training Awards.\n\n\n\n"}
{"id": "2473812", "url": "https://en.wikipedia.org/wiki?curid=2473812", "title": "Ball and beam", "text": "Ball and beam\n\nThe ball and beam system consists of a long beam which can be tilted by a servo or electric motor together with a ball\nrolling back and forth on top of the beam.\nIt is a popular textbook example in control theory.\n\nThe significance of the ball and beam system is that it is a simple system which is open-loop unstable.\nEven if the beam is restricted to be very nearly horizontal, without active feedback, it will swing to one side or the\nother, and the ball will roll off the end of the beam. To stabilize the ball, a control system which\nmeasures the position of the ball and adjusts the beam accordingly must be used.\n\nIn two dimensions, the ball and beam system becomes the ball and plate system, where a ball rolls on top of\na plate whose inclination can be adjusted by tilting it frontwards, backwards, leftwards, or rightwards.\n\n"}
{"id": "37097123", "url": "https://en.wikipedia.org/wiki?curid=37097123", "title": "Beaverslide", "text": "Beaverslide\n\nA beaverslide is a device for stacking hay made of wooden poles and planks that builds haystacks of loose, unbaled hay stored outdoors to be used as fodder for livestock. The beaverslide consists of a frame supporting an inclined plane up which a load of hay is pushed to a height of about , before dropping through a large gap. The resulting loaf-shaped haystacks can be up to 30 feet high, can weigh up to 20 tons, and can theoretically last up to five or six years. It was invented in the early 1900s and was first called the Beaverhead County Slide Stacker after its place of origin, the Big Hole Valley in Beaverhead County, Montana. The name was quickly shortened to \"beaverslide.\"\n\nEarly settlers in the American west initially stored hay for their livestock under shelter in barns and haylofts. However, unlike the east, where hay is fed as a supplemental form of forage, the northern plains had lengthy and severe winter weather and therefore large quantities of hay were needed to provide adequate forage for animals. Most haylofts were insufficient to store the quantities needed, but in the arid western United States, unlike the more humid east, hay could be stored without the protection of a barn. As a result, settlers used a variety of methods to stack and store large amounts of hay, inventing a number of agricultural machines to lift hay including hay derricks and various slides, including a predecessor to the beaverslide called a ram stacker.\n\nAbout 1908 the beaverslide was invented in Montana by two ranchers, Herbert S. Armitage and David J. Stephens, who ranched near Briston, in the Big Hole Valley, of Beaverhead County in southwestern Montana. Armitage and Stephens filed for a patent on September 7, 1909 and it was awarded on May 31, 1910. The beaverslide may have been called the \"Sunny Slope Slide Stacker\" at one time, but that name does not appear in the patent. Armitage and Stephens themselves referred to it as the \"Beaverhead County Slide Stacker\", which quickly became just \"beaverslide\".\n\nThe beaverslide was somewhat mobile, inexpensive, handled large amounts of hay, and was easily built. It was faster to use than early balers and made windproof haystacks. It rapidly gained popularity in southwestern Montana and adjacent parts of eastern Idaho, with its use spreading to other western states and Canada in places where light meadow grass was put up as hay. In regions where it had been adopted it remained in common use into the 1990s. While use of a beaverslide is labor-intensive, and it has not been commonly used in the 21st century, some ranchers are returning to it to save fuel costs. Still others never abandoned it because of the large cash outlay required to purchase modern mechanized balers.\n\nThe beaverslide is constructed of a rigid pole frame in the form of a right-angle triangle that supports a steeply inclined, slatted, plank ramp, with or without sides, approximately long. The size and angle of individual beaverslides varies greatly and reflects local needs. Beaverslides were originally of all-wooden construction, usually lodgepole pine, and could last 10 to 15 years. In the 1970s, some components began to be made of metal, which are longer-lasting. The inclined ramp, about wide, is made of smooth wooden or metal slats and is about two thirds the length of the poles. In the 1920s it became possible to extend the height of the slide so that the hay could be thrown further. In the 1950s movable wings were placed on either side of the ramp so that the hay could be stacked more neatly. A flat, toothed wooden platform called a \"basket\" or rack is suspended by a system of cables and pulleys from the poles. It is raised to bring hay to the top of the slide, and then lowered back down along the length of the ramp. A backstop, usually an open wooden grid held up by poles, is set at the far end of the stack helps hold the completed stack in place. A fence of wood panels or other materials is often placed around the stack to keep out livestock.\n\nA beaverslide will raise hay to a height that allows a haystack to be built as much as 30 feet high. A large hay crew is required, with a minimum of six people to operate all components. A load of hay is delivered to the base of the beaverslide, often pushed by a buckrake drawn by a team of horses or a tractor. The hay is loaded onto the rack, which when full is drawn up the inclined ramp by cables powered either by a second team of horses or a motorized vehicle such as a pickup or a tractor. At the top of the incline, the hay falls onto the stack and the rack is lowered for another load. The term \"butt\" describes the hay stacked by the beaverslide and has two meanings. A \"butt\" can be the amount of hay on a fully loaded rack, but the term also refers to the amount of hay that can be stacked by the beaverslide without moving it, roughly 24 tons of hay. The hay at the top of each haystack is stomped and piled higher towards the middle to allow rain to run off. Depending on the size of the field and the amount of hay produced per acre, once a beaverslide has created a stack, it can be moved a few feet to make a long, continuous haystack, or moved a longer distance to create multiple stacks within a field. Many are built on skids to facilitate being moved from field to field. If the hay is stacked properly, and remains uneaten, the hay in a beaverslide-constructed stack remains good at least two to three years, with some ranchers claiming it could last up to five or six years. In contrast, baled hay stored outdoors can begin to go bad after only one year.\n\nExplanatory notes\n\nCitations\n\n\n\nPhotos taken in Idaho in 1971\n"}
{"id": "55419075", "url": "https://en.wikipedia.org/wiki?curid=55419075", "title": "Berlebach", "text": "Berlebach\n\nBerlebach Stativtechnik from Mulda, Saxony in Germany, is a manufacturer of Tripods and Monopods for Photography, Telescope and Surveying made from ash (Fraxinus excelsior).\n\nThe company was founded by Peter Otto Berlebach in 1898.\nIn 1994 Berlebach had shown its products first time on the Photokina fare. Today Berlebach is a leading company for wood Tripods and is exporting to more than 40 nations. The main advantage of Berlebach-Tripods is the low Oscillation, which is especially important forTelephoto lenses.\n\nBerlebach is producing several lines of Photography Tripods and Monopods with a maximum working high between and , which can be extended by Centre Column.\n\nBerlebach also is producing different kind of Tripods for Telescope which can carry up to .\n\nBerlebach is producing special Tripods for Electromagnetic compatibility measurement purpose, which don’t contain any Metal.\n\n"}
{"id": "11550904", "url": "https://en.wikipedia.org/wiki?curid=11550904", "title": "Beyond Invention", "text": "Beyond Invention\n\nBeyond Invention is an 8-part documentary television series that premiered on February 12, 2004 on Discovery Channel Canada and, , airs on the Science Channel.\n\nThe series was produced by Mystique Films in partnership with Gryphon Productions and is narrated by John Payne. It primarily focuses on future and fictional technology that inspires many movies we see today.\n\n\n"}
{"id": "1251443", "url": "https://en.wikipedia.org/wiki?curid=1251443", "title": "Bolex", "text": "Bolex\n\nBolex is a trade mark registered October 1924 for Charles Haccius and Jacques Bogopolsky. The actual company Bolex International S. A. of Yverdon is a Swiss follow manufacturer of motion picture cameras, the most notable products of which are in the 16 mm and Super 16 mm formats. A first company Bol was founded by Haccius and Bogopolsky (a. k. a. Bolsey or Bolsky) in 1925 and Bolex is derived from Bogopolsky′s name. He had previously designed cameras for Alpa of Ballaigues. In 1923 he presented the Cinégraphe Bol at the Geneva fair, a reversible apparatus for taking, printing, and projecting pictures on 35-mm. film.\n\nPaillard-Bolex cameras were much used for nature films, documentaries and by the avant garde, and are still favoured by many animators. While some later models are electrically powered, the majority of those manufactured since the 1930s use a spring-wound clockwork power system. The 16 mm spring-wound Bolex is a popular introductory camera in film schools.\n\nBolex International no longer manufactures its cameras in series, but produces 16mm and Super 16 cameras for customers on special order. \n\nEffective September 30, 1930 Bogopolsky sold all assets except a few patents to Ernest Paillard & Cie which retained his services until 1935. Then the H-16 camera was put on the market, the 9.5mm version followed in 1936 and the Double-8mm version in 1938. The H-16 was highly successful. Paillard-Bolex introduced the L-8 for the market of pocket 8mm film cameras. With the postwar boom in home movie making, Paillard-Bolex continued to develop its 8mm and 16mm ranges with the H-16 increasingly adopted by professional film makers. The company also made a successful range of high-end movie projectors for all amateur film making gauges.\n\nIn 1952, during the golden era of 3D film, Bolex offered the Bolex Stereo: a 3D stereo kit for their H-16 camera and model G projectors. A number of technical changes was made to the H cameras in 1954, above all an entirely different claw drive together with a laterally inverted film gate and a 170 degrees opening angle shutter. In 1956 the first H-16 reflex viewfinder model was brought out. In reaction to the upcoming use of heavier varifocal or zoom lenses and the bigger synchronous electric motors attached to the body Paillard gave it a big rectangular base with three tapped bushings replacing the original single-tap “button” base in 1963 and soon afterwards a protruding 1-to-1 shaft for the ESM motor. A saddle for a 400-ft. film magazine finally allowed the H-16 to be used like professional synch-sound cameras.\n\nIn 1965 Kodak introduced the Super 8mm format. Paillard Bolex were slow to introduce a Super 8 camera although they quickly modified the 18-5 Auto 8mm projector for Super 8 as the 18-5 L. At about this time (1966) the Bolex 16 Pro Camera was introduced to compete with the Arriflex 16 BL camera, as a technically advanced professional camera more suited for television use than the H-16. Nevertheless the H-16 Standard camera was made until the last days of 1969. The H-16 and H-8 standard models afford the rackover critical focusing feature that had been first introduced with the Bell & Howell Standard camera in 1912.\n\nEffective January 1st, 1970 Paillard sold the Bolex division to Eumig of Vienna. In 1971 Eumig rationalised the Super 8 range and Super 8 equipment production in Switzerland was discontinued. The Bolex product brand was retained while being manufactured in Eumig or Chinon factories. The H-16 cameras were still made in Switzerland. \n\nIn 1981 Eumig went into liquidation and Bolex was bought by a management team which set up Bolex International in 1982.\nToday, the Bolex factory in Switzerland continues to produce new 16mm and Super 16 film cameras and also can convert Bolex H16 reflex models to Super 16mm.\n\nIn 2012, Cinemeridian, Inc. licensed the named Bolex from Bolex International to create a digital Super 16mm cinema camera called the Digital Bolex D16. Digital Bolex announced their collaboration with Bolex via the Kickstarter crowdfunding platform on March 12, 2012 at the SXSW Film Festival where they had a trade show booth.\n\nSwiss made with the year of introduction except for the Italian Silma made SM8\n\nThe camera′s capacity is 100 ft. A 400-ft magazine (on the Rex 5 - or converted Rex 3 or 4) can be attached to the top of the camera. From the beginning it offered automatic film threading, a clutch for disengaging the drive spring in order to crank the film by hand forward and backwards unlimited, and a cut-off turret disc that is not wider than the camera body in center position. Stepless speed control was available between 8 and 64 frames per second. Early cameras have a 190 degrees opening angle shutter. A few years after their introduction the H cameras could be equipped with an accurate single-frame counter. That accessory was incorporated into all H camera models since 1946.\n\nAs with a still reflex camera, the Bolex RX has a viewfinder, which allows the filmmaker to view what he or she is filming. This specific viewfinder is made up of a double prism that deflects 20 percent of the light going through the lens into the viewfinder.\n\nThe Paillard-Bolex H-16 usually has a turret for three C-mount lenses. Often, the camera was provided with a 16mm Switar or Yvar, a 25mm Switar or Yvar and the third lens was often a 75mm Yvar or 50mm Switar. It should be noted that only lenses with the designation \"RX\" in 50 mm or less can be used on the RX models. RX corrected lenses were also manufactured by Schneider, Berthiot, Angénieux, and Rodenstock. The single lens port H-16 M(arine) was made in conjunction with the first underwater housing. A second, later marine housing was made for the electric drive models.\n\nSome people had their H-16 camera converted to Super 16. This format is highly suited to telecine conversion, as Super 16 is close to the 16:9 electronic image format. Some conversions were more successful than others. Bolex (latterly) did offer a factory Super 16mm camera. This has the appropriate markings in the viewfinder and the film gate is machined and polished to professional standards.\n\nBolex did have a foray into purely professional cameras with the Bolex Pro 16. Again, they decided against a registration pin for mechanical simplicity, to keep the camera as quiet as possible for sync-sound filming. This camera was only offered with 400 ft magazine capacity.\n\nDirectors David Lynch, Jonas Mekas, Terry Gilliam, Will Vinton, Maya Deren, and Spike Lee all began their careers shooting on Paillard-Bolex Cameras , and the Paillard-Bolex has developed a cult following as the result of being used for decades as a beginner camera in film schools worldwide.\n\nThere are currently two documentaries in production about the history of the Bolex camera. Beyond The Bolex, a biographical film about Bolex founder Jacques Bogopolsky (later anglicized to Bolsey), is directed by his great-grand daughter Alyssa Bolsey, and features an in-depth look at the inventor's original notes, schematics, prototypes, and fotoage. A second product is being undertaken by Swiss director Alexandre Favre.\n\n\n\n"}
{"id": "12676084", "url": "https://en.wikipedia.org/wiki?curid=12676084", "title": "Cathedral of Light", "text": "Cathedral of Light\n\nThe Cathedral of Light or Lichtdom was a main aesthetic feature of the Nazi Party rallies in Nuremberg from 1934 to 1938. Designed by architect Albert Speer, it consisted of 152 anti-aircraft searchlights, at intervals of 12 metres, aimed skyward to create a series of vertical bars surrounding the audience. The effect was a brilliant one, both from within the design and on the outside. The Cathedral of Light was documented in the Nazi propaganda film \"Festliches Nürnberg\", released in 1937.\n\nSpeer had been commissioned by Adolf Hitler to build a stadium for the annual party rallies, but the stadium could not be completed in time for the 1933 rally. As a stopgap, he used 152 antiaircraft searchlights pointed upwards around the assembly area.\n\nThe searchlights were borrowed from the \"Luftwaffe\", which caused problems with its commander Hermann Göring, because they represented most of Germany's strategic reserve. Hitler overruled him, suggesting that it was a useful piece of disinformation. \"If we use them in such large numbers for a thing like this, other countries will think we're swimming in searchlights.\"\n\nThough they had originally been planned as a temporary measure until the stadium was completed, they continued to be used afterwards for the party rallies. A similar effect was created for the closing ceremony of the 1936 Olympic Games in Berlin by Eberhard von der Trappen with Speer's collaboration. Variants of the effect had the searchlights converge to a point above the spectators.\n\nThe Flak Searchlights used were developed in the late 1930s and used 150-centimeter-diameter parabolic glass reflectors with an output of 990 million candelas. The system was powered by a 24-kilowatt generator, based around a 51-horsepower (38 kW) 8-cylinder engine, giving a current of 200 amperes at 110 volts. The searchlight was attached to the generator by a cable 200 meters long. The system had a detection range of about 8 kilometers for targets at an altitude of between 4000 and 5000 meters.\n\nSpeer described the effect: \"The feeling was of a vast room, with the beams serving as mighty pillars of infinitely light outer walls\". The British Ambassador to Germany, Sir Nevile Henderson, described it as \"both solemn and beautiful... like being in a cathedral of ice\".\n\nIt is still considered amongst Speer's most important works.\n\n\n\n"}
{"id": "56397573", "url": "https://en.wikipedia.org/wiki?curid=56397573", "title": "Centre for Environmental Data Analysis", "text": "Centre for Environmental Data Analysis\n\nThe Centre for Environmental Data Analysis (CEDA) is a United Kingdom organisation that serves the environmental science community by provision of data centres, data analysis, data access and research project participation.\n\nCEDA responsibility includes three datacentres jointly funded by the Natural Environment Research Council (NERC) and the Science and Technology Facilities Council (STFC).\n\nCEDA is responsible for data archival on behalf of the environmental science community.\n\nCEDA is responsible for providing access to research data. Particular datasets may have different access or license restrictions. Many datasets are available under the United Kingdom Open Government License (OGL).\n\nCEDA operates The Joint Analysis System Meeting Infrastructure Needs super-data-cluster (JASMIN) e-infrastructure in collaboration with STFC's Scientific Computing Department. In 2017 the total storage capacity of the cluster was increased to 20 petabytes (PB).\n\nThe four JASMIN sites are Rutherford Appleton Laboratory, Bristol, Reading and Leeds linked over the JANET network. Remote paths linked by lightpaths are Edinburgh, the Met Office in Exeter and the Royal Netherlands Meteorological Institute (KNMI) in the Netherlands.\n"}
{"id": "147092", "url": "https://en.wikipedia.org/wiki?curid=147092", "title": "Cock ring", "text": "Cock ring\n\nA cock ring or cockring is a ring worn around the penis, usually at the base. The primary purpose of wearing a cock ring is to restrict the flow of blood from the erect penis in order to produce a stronger erection or to maintain an erection for a longer period of time. Genital adornment is another purpose, as is repositioning the genitals to provide an enhanced appearance.\n\nCock rings are also called C rings, penis rings or shaft rings. When used in cases of erectile dysfunction (ED), they are known by various other names, such as erection rings and tension rings.\n\nCock rings worn just behind the corona of the glans of the penis are known as glans rings, head rings or cock crowns.\n\nA ring that is worn around the penis and scrotum is also usually called a cock ring, but is sometimes referred to as a cock and ball ring.\n\nRings that are worn just round the scrotum, in order to hold the testicles, are usually called testicle cuffs or ball stretchers.\n\nA man may wear an erection ring because he has erectile dysfunction (ED). When used for ED, a purpose-designed vacuum pump is used to produce an erection by simple mechanical and hydrodynamical action in spite of vascular or nerve damage, and the ring is slid off the pump's cylinder onto the base of the penis to maintain the erection before it is lost. The testicles are not ringed in this case.\n\nA cock ring may be used to prolong erection in order to provide pleasure beyond their own orgasm or simply because the wearer likes the particular sensation of tightness and extreme engorgement that wearing one provides. It can be worn as a sex toy, as genital jewelry, or simply for the appearance. Some men enjoy using cock rings for masturbation, as wearing of this sex toy contributes to better erection and delays orgasm for themselves, thus it intensifies orgasmic sensations. Also, vibrating cock rings deliver a great range of very pleasurable vibrations that enhance enjoyment for the wearer and their partner.\n\nThe purpose of a cock ring is to trap blood inside the penis in order to maintain an erection, or encourage a stronger erection. In order to do this it must be placed at the base of the penis.\n\nA ring made of stretchy material is simply stretched over the penis (and optionally also the scrotum, except when used with a pump for impotence) and situated against the body. Rigid rings are used differently: first each testicle is fed through the ring and the entire scrotum is pulled through, then the flaccid penis is pushed through the ring and situated against the body.\nWhen used with a pump, a lubricating gel is always used to help the pump maintain a vacuum, in the same way vacuum grease is used with a vacuum pump in scientific applications. The gel also makes it easier for the ring to slide off the pump, and later, to remove it from the penis.\n\nSome models include a protruding clitoral stimulator, designed to tickle the clitoris, vulva, or anus during sex (and during masturbation on using them on a dildo). Others, such as the vibrating ring, vibrate, either vibrating the ring itself, or in a popular 'Dolphin' variant using two removable bullet vibrators to provide stimulation to the testicles and clitoris. Some cock rings have vibrators attached that can be worn to stimulate the scrotum or perineum of a partner during sexual intercourse. Many women find that rings with vibrator attachments provide clitoral stimulation that is needed for achieving orgasm. Cock ring users should keep in mind that any pain, discomfort, or feeling of coldness in genitals is a signal to take the cock ring off.\n\nAnother variation is an inflatable cock ring for added control of adjustment.\n\nA triple cock ring or triple crown is a cock ring that has additional rings for restraining the testicles. In orgasm, the testicles usually retract towards the body before ejaculation. A triple crown changes and intensifies the sensation of orgasm by forcing the testicles to stay away from the body.\n\nVendors of cock rings and medical sources always indicate that cock rings are not to be worn for more than about 30 minutes. Falling asleep or using illicit drugs at the same time is very dangerous. The first sign of pending problems is when the penis starts to become numb, painful, or cold. As soon as this happens, the cock ring must be removed.\n\nCock rings that are too tight, or worn for too long can be dangerous: this may cause priapism, a medical emergency that, if not treated promptly, can result in severe and permanent damage, including penile gangrene that can result in the destruction and possible amputation of the penis. Rings for erectile dysfunction are invariably supplied with the instruction that they should not be left on for more than thirty minutes. Falling asleep with a ring on is a particular danger. This may lead to temporary or permanent nerve damage. Numbness in the glans penis, penis becoming cold or penis becoming white may be signs that a cock ring has been worn for too long and medical advice should be sought.\n\nCock rings must not be used without medical advice by those who have cardiovascular problems or who take blood-thinning medication.\n\nCommercially available cock rings are made from many different materials, including: leather, rubber, silicone, neoprene, nylon, metals (including: aluminium, steel, titanium, silver, gold and platinum), wood, plastic, bone, horn, ceramic, glass, and semi precious stone. They also come in a range of sizes, particularly the rigid varieties which range in diameter from 35mm to at least 63mm.\nDesigns range from the simple to the complex. Simple rings may lie flat on a surface, while others are ergonomically curved to fit more comfortably on the wearer. Some designs are horseshoe shaped with a closure. in cross section the rings may vary from round to flatten oval, that latter offering more friction on the penis and are therefore less likely to slip. Many of the newer rings also have different accessories and projections.\n\nThere are also vibrating cock rings available which can stimulate the testes at the same time.\n\nToday, cock rings can be bought with accessories that stimulate the clitoris or anal area during intercourse. Other cock rings go around the scrotum and can significantly enhance erection and intensity of orgasms.\n\nHowever, there is one negative: the more accessories that are added on, the greater the chance of developing discomfort or cold sensations from the device.\n\nRings for ED must be able to be placed in position while a pump is connected; the erection is lost as soon as vacuum is removed unless the ring is already in place. This rules out most types other than simple elastic rings.\n\nSpecialized underwear is available which comes with pre-fitted cock rings. The underwear has a pouch with an internal fabric/elastic cock ring which either slides along the penis and encircles the scrotum or, alternatively, simply snaps around the base of the scrotum to snugly—but not in a constricting way—attach the pouch to the genitals. While this type of pouch permits the wearer to \"go backless\", C ring pouches can be attached to either a thong or traditional jockstrap.\n\n"}
{"id": "42384348", "url": "https://en.wikipedia.org/wiki?curid=42384348", "title": "Comparison of subtitle editors", "text": "Comparison of subtitle editors\n\nThe following table compares some characteristics of some subtitle editing software.\n\n\n"}
{"id": "14488117", "url": "https://en.wikipedia.org/wiki?curid=14488117", "title": "Electromechanical film", "text": "Electromechanical film\n\nElectromechanical Film is a thin membrane whose thickness is related to an electric voltage. It can be used as a pressure sensor, microphone, or a speaker. It can also convert electrical energy to vibration, functioning as an actuator.\n"}
{"id": "7505145", "url": "https://en.wikipedia.org/wiki?curid=7505145", "title": "Explosive Substances Act 1883", "text": "Explosive Substances Act 1883\n\nThe Explosive Substances Act 1883 (c. 3) is an Act of the Parliament of the United Kingdom. It makes it illegal to use (or conspire or intend to use) any explosive substance to cause an explosion likely to endanger life or cause serious injury to property, whether or not any explosion actually takes place. A person guilty of an offence under this law is liable to life imprisonment. \n\nUnder the Act, it is also an offence, subject to imprisonment for life, to possess explosives under suspicious circumstances.\n\nAnyone who helps someone to commit a crime under this law by providing money, materials, premises, or any other assistance is tried and punished as severely as the person who actually uses the explosives. \n\nWitnesses who are called during the official investigation or the trial can be arrested to prevent them from absconding and do not have the right of silence to protect themselves from self-incrimination. On the other hand, self-incriminating evidence from a witness cannot be used in a different criminal or civil proceeding.\n\nAny instance of terrorism involving any kind of bomb is necessarily a crime under Explosive Substances Act 1883 (as well as being a crime under the law against attempted murder). In fact, for many decades the Explosive Substances Act was the basis for the prosecution of terrorist cases, such as S-Plan in 1939, the Birmingham Six in 1975, Tony Lecomber in 1985, and the Talbot Street bomb-making haul in 2006. \n\nSince 2000, there has been a series of special terrorism laws which appear to supersede the Explosive Substances Act in that they can also be used to investigate and prosecute those who misuse explosives to endanger life and property for illegitimate purposes (usually to further their own political causes). \n\nThe terrorism acts have been applied in the cases such as the 2004 Financial buildings plot and 2006 transatlantic aircraft plot in which the intent to misuse explosives is alleged. However, since no actual explosive substances have been found, the Explosive Substances Act cannot be made to apply. \n\nA recent use of the Act was against Iraqi doctor Bilal Abdullah, who became the first person charged over the London and Glasgow car bomb attacks in 2007. Abdullah, who was arrested after a flaming Jeep was driven into the doors of the arrivals hall at Glasgow Airport. The 27-year-old, who was working as a doctor at the Royal Alexandra Hospital in Paisley, Scotland, before his arrest, was charged with conspiring to cause explosions under the Explosive Substances Act. The charge alleges he \"unlawfully and maliciously conspired with others to cause explosions of a nature likely to endanger life or cause serious injury to property in the United Kingdom\".\n\nIn April 2015, Faris al-Khori, a former Syrian doctor, was jailed for 40 months under the Explosives Substances Act for possessing explosive ingredients and bomb-making instructions in properties in Edinburgh.\n"}
{"id": "10773", "url": "https://en.wikipedia.org/wiki?curid=10773", "title": "Flying car", "text": "Flying car\n\nA flying car is a type of personal air vehicle or roadable aircraft that provides door-to-door transportation by both ground and air. The term \"flying car\" is also sometimes used to include hovercars.\n\nMany prototypes have been built since the first years of the twentieth century using a variety of flight technologies and some have true VTOL performance, but no flying car has yet reached production status.\n\nTheir appearance is often predicted by futurologists, with their failure ever to reach production leading to the catchphrase, \"Where's my flying car?\"\n\nFlying cars are also a popular theme in fantasy and science fiction stories.\n\nIn 1926, Henry Ford displayed an experimental single-seat aeroplane that he called the \"sky flivver\". The project was abandoned two years later when a distance-record attempt flight crashed, killing the pilot. The Flivver was not a flying car at all, but it did get press attention at the time, exciting the public that they would have a mass-produced affordable airplane product that would be made, marketed, sold, and maintained just like an automobile. The airplane was to be as commonplace in the future as the Model T of the time.\n\nIn 1940, Henry Ford famously predicted: \"Mark my word: a combination airplane and motorcar is coming. You may smile, but it will come.”\n\nThe Aerocar designed and built by Molt Taylor made a successful flight in December 1949, and in following years versions underwent a series of road and flying tests. Chuck Berry featured the concept in his 1956 song \"You Can't Catch Me\", and in December 1956 the Civil Aviation Authority approved the design for mass production, but despite wide publicity and an improved version produced in 1989, Taylor did not succeed in getting the flying car into production.\n\nIn the period between 1956 - 1958, Ford's Advanced Design studio built the Volante Tri-Athodyne, a 3/8 scale concept car model. It was designed to have three ducted fans, each with their own motor, that would lift it off the ground and move it through the air. In public relation release, Ford noted that \"the day where there will be an aero-car in every garage is still some time off\", but added that \"the Volante indicates one direction that the styling of such a vehicle would take\".\n\nIn 1957, Popular Mechanics reported that Hiller Helicopters was developing a ducted-fan aircraft that would be easier to fly than helicopters, and should cost a lot less. Hiller engineers expected that this type of an aircraft would become the basis for a whole family of special-purpose aircraft.\n\nIn 1956, the US Army's Transportation Research Command began an investigation into \"flying jeeps\", ducted-fan-based aircraft that were envisioned to be smaller and easier to fly than helicopters. In 1957, Chrysler, Curtiss-Wright, and Piasecki were assigned contracts for building and delivery of prototypes. They all delivered their prototypes; however, Piasecki's VZ-8 was the most successful of the three. While it would normally operate close to the ground, it was capable of flying to several thousand feet, proving to be stable in flight. Nonetheless, the Army decided that the \"Flying Jeep concept [was] unsuitable for the modern battlefield\", and concentrated on the development of conventional helicopters. In addition to the army contract, Piasecki was developing the Sky Car, a modified version of its VZ-8 for civilian use.\n\nIn the mid-1980s, former Boeing engineer, Fred Barker, founded Flight Innovations Inc. and began the development of the Sky Commuter, a small duct fans-based VTOL aircraft. It was a compact, two-passenger and was made primarily of composite materials. In 2008, the remaining prototype was sold for £86k on eBay.\n\nIn 1942, the Soviet armed forces experimented with a gliding tank, the Antonov A-40, but it was not capable of flying on its own.\n\nAeroMobil currently fly-tests a prototype that obtained Slovak ultralight certification. When the final product will be available or how much it will cost is not yet specified.\n\nUrban Aeronautics' X-Hawk is a VTOL turbojet powered aircraft announced in 2006 with a first flight planned for 2009. It was intended to operate much like a tandem rotor helicopter, but with ducted fans rather than exposed rotors. The requisite decrease in rotor size would also decrease fuel efficiency. The X-Hawk was being promoted for rescue and utility functions. As of 2013, no flights had been reported.\n\nTerrafugia have a flying road vehicle, the Terrafugia Transition On 7 May 2013, Terrafugia announced the TF-X, a plug-in hybrid tilt-rotor vehicle that would be the first fully autonomous flying car. It would have a range of per flight and batteries are rechargeable by the engine. Development of TF-X is expected to last 8–12 years, which means it will not come to market before 2019.\n\nThe Moller Skycar M400 is a prototype personal VTOL (vertical take-off and landing) aircraft which is powered by four pairs of in-tandem Wankel rotary engines, and is approaching the problems of satellite-navigation, incorporated in the proposed Small Aircraft Transportation System. Moller also advises that, currently, the Skycar would only be allowed to fly from airports & heliports. The Skycar M400 has tiny wheels and no road capability at all. Moller has been developing VTOL craft since the late 1960s, but no Moller vehicle has ever achieved free flight out of ground effect. The proposed Autovolantor model has an all-electric version powered by Altairnano batteries.\n\nThe Xplorair PX200 was a French project of single-seater VTOL aircraft without rotating airfoil, relying on the Coandă effect and using an array of small jet engines called \"thermoreactors\" embedded within tiltwings' body. Announced in 2007, the project has been funded by the Government of France and was supported by various aerospace firms. A full-scale drone was scheduled for flight at Paris Air Show 2017, followed by the commercialization of a single-seater flying car in the years after.\n\nThe SkyRider X2R is a prototype of a flying car developed by MACRO Industries, Inc. It is lighter than the Moller Skycar which has never successfully flown untethered.\n\nAlso notable is the roadable aircraft PAL-V ONE, which is an autogyro or gyrocopter that can be taken to the road, too.\n\nZee.Aero and Kitty Hawk Corporation are developing flying cars.\n\nFlying cars were planned to enter Russian market in 2018. Ride-sharing giant Uber is working on the electric eCRM-003 eVTOL, with first tests expected by 2020, and very limited UberAir service trials by 2023 (Los Angeles, Dallas, third international city), with 50 vehicles serving five skyports per city.\n\nA practical flying car must be capable of safe, reliable and environmentally-friendly operation both on public roads and in the air. For widespread adoption it must also be able to fly without a qualified pilot at the controls and come at affordable purchase and running costs.\n\nMany types of aircraft technologies and form factors have been tried. The simplest and earliest approach was to give a driveable car added, bolt-on fixed flying surfaces and propeller. However such a design must either tow its removable parts on a separate trailer behind it, or return to its last landing point before taking off again. Other conventional takeoff fixed-wing designs include folding wings, which the car carries with it when on the road.\n\nVertical takeoff and landing (VTOL) designs include rotorcraft with folding blades, as well as ducted-fan and tiltrotor vehicles. Most design concepts have inherent problems. Ducted-fan aircraft such as the Moller Skycar tend to easily lose stability and have been unable to travel at greater than 30–40 knots. Tiltrotors, such as the V-22 Osprey convertiplane, are generally noisy. To date, no vertical takeoff and landing (VTOL) vehicle has ever demonstrated adequate road capabilities.\n\nThe autogyro has an unpowered lifting rotor, relying on its forward airspeed to generate lift. For road use it requires a folding rotor. Designs such as the PAL-V are currently being explored.\n\nAlthough statistically, commercial flying is much safer than driving, unlike commercial planes personal flying cars might not have as many safety checks and their pilots would not be as well trained. Humans already have problems with the aspect of driving in two dimensions (forward and backwards, side to side), adding in the up and down aspect would make \"driving\" or flying as it would be, much more difficult; however, this problem might be solved via the sole use of self-flying and self-driving cars. In mid-air collisions and mechanical failures, the aircraft could fall from the sky or go through an emergency landing, resulting in deaths and property damage. In addition, poor weather conditions, such as low air density, lightning storms and heavy rain, snow or fog could be challenging and affect the aircraft's aerodynamics.\n\nA major problem, which increases rapidly with wider adoption, is the risk of mid-air collisions. Another is the unscheduled or emergency landing of a flying car on an unprepared location beneath, including the possibility of accident debris. Regulatory regimes are being developed in anticipation of a large increase in the numbers of roadable aircraft and personal air vehicles in the near future, and compliance with these regimes will be necessary for safe flight.\n\nMechanically, the challenges of flight are so strict that every opportunity must be taken to keep weight to a minimum and a typical airframe is lightweight and easily damaged. On the other hand a road vehicle must be able to withstand significant impact loads from casual incidents as well as low-speed and high-speed impacts, and the high strength this demands can add considerable weight. A practical flying car must be both strong enough to pass road safety standards and light enough to fly.\n\nA flying car capable of widespread use must operate safely within a heavily populated urban environment. The lift and propulsion systems must be quiet, and have safety shrouds around all moving parts such as rotors, and must not create excessive pollution.\n\nA basic flying car requires the person at the controls to be both a qualified road driver and aircraft pilot. This is impractical for the majority of people and so wider adoption will require computer systems to de-skill piloting. These include aircraft maneuvering, navigation and emergency procedures, all in potentially crowded airspace. Fly-by-wire computers can also make up for many deficiencies in flight dynamics, such as stability. A practical flying car may need to be a fully autonomous vehicle in which people are present only as passengers.\n\nThe need for the propulsion system to be both small and powerful can at present only be met using advanced and expensive technologies. The cost of manufacture could therefore be as much as 10 million dollars.\n\nFlying cars would be used for shorter distances, at higher frequency, and at lower speeds and lower altitudes than conventional passenger aircraft. However optimal fuel efficiency for airplanes is obtained at high altitudes and high subsonic speeds, so a flying car's energy efficiency would be low compared to a conventional aircraft. Similarly, the flying car's road performance would be compromised by the requirements of flight, so it would be less economical than a conventional motor car as well.\n\nThe flying car was and remains a common feature of conceptions of the future, including imagined near futures such as those of the 21st century. Complaints of the non-existence of flying cars have become nearly idiomatic as expressions of disappointment in the failure of the present to measure up to the glory of past predictions.\n\nIn 1999 the U.S. journalist Gail Collins noted:\nAs a result, flying cars have been referred to jokingly with the question \"Where's my flying car?\", emblematic of the supposed failure of modern technology to match futuristic visions that were promoted in earlier decades.\n\nAired on 8 January 1998, \"Seinfeld\"'s 167th episode, \"The Dealership\", featured George and Jerry complaining about the non-existence of the flying cars. Jerry says, \"It's like we're living in the '50s here.\"\n\nA 2001 IBM television commercial featured Avery Brooks complaining, \"It is the year 2000, but where are the flying cars? I was promised flying cars. I don’t see any flying cars. Why? Why? Why?\"\n\nComedian Lewis Black had a similar routine early in the decade, in which he says, \"This new millennium sucks! It's exactly the same as the old millennium! You know why? No flying cars!\"\n\n\"The Flying Car\" was a comedy short film written by Kevin Smith in 2002 for \"The Tonight Show with Jay Leno\". It featured Dante Hicks and Randal Graves stuck in traffic, discussing the lengths to which a man might go to obtain such a vehicle.\n\nIn 2008, \"Onion News Network\"'s 245th episode, titled \"Mean Automakers Dash Nation's Hope for Flying Cars\", featured The Onion's anchor Brandon Armstrong humorously arguing about the feasibility and existence of flying cars with representatives from General Motors, Toyota and Ford.\n\nThe flying car has been depicted in many works of fantasy and science fiction.\n\n\n\n\n\n\n\n\n"}
{"id": "578666", "url": "https://en.wikipedia.org/wiki?curid=578666", "title": "Frequency counter", "text": "Frequency counter\n\nA frequency counter is an electronic instrument, or component of one, that is used for measuring frequency. Frequency counters usually measure the number of cycles of oscillation, or pulses per second in a periodic electronic signal. Such an instrument is sometimes referred to as a cymometer, particularly one of Chinese manufacture.\n\nMost frequency counters work by using a counter which accumulates the number of events occurring within a specific period of time. After a preset period known as the \"gate time\" (1 second, for example), the value in the counter is transferred to a display and the counter is reset to zero. If the event being measured repeats itself with sufficient stability and the frequency is considerably lower than that of the clock oscillator being used, the resolution of the measurement can be greatly improved by measuring the time required for an entire number of cycles, rather than counting the number of entire cycles observed for a pre-set duration (often referred to as the \"reciprocal technique\"). The internal oscillator which provides the time signals is called the \"timebase\", and must be calibrated very accurately.\n\nIf the event to be counted is already in electronic form, simple interfacing to the instrument is all that is required. More complex signals may need some conditioning to make them suitable for counting. Most general purpose frequency counters will include some form of amplifier, filtering and shaping circuitry at the input. DSP technology, sensitivity control and hysteresis are other techniques to improve performance. Other types of periodic events that are not inherently electronic in nature will need to be converted using some form of transducer. For example, a mechanical event could be arranged to interrupt a light beam, and the counter made to count the resulting pulses.\n\nFrequency counters designed for radio frequencies (RF) are also common and operate on the same principles as lower frequency counters. Often, they have more range before they overflow. For very high (microwave) frequencies, many designs use a high-speed prescaler to bring the signal frequency down to a point where normal digital circuitry can operate. The displays on such instruments take this into account so they still display the correct value. Microwave frequency counters can currently measure frequencies up to almost 56 GHz. Above these frequencies the signal to be measured is combined in a mixer with the signal from a local oscillator, producing a signal at the difference frequency, which is low enough to be measured directly.\n\nThe accuracy of a frequency counter is strongly dependent on the stability of its timebase. A timebase is very delicate like the hands of a watch, and can be changed by movement, interference, or even drift due to age, meaning it might not \"tick\" correctly. This can make a frequency reading, when referenced to the timebase, seem higher or lower than the actual value. Highly accurate circuits are used to generate timebases for instrumentation purposes, usually using a quartz crystal oscillator within a sealed temperature-controlled chamber, known as an oven controlled crystal oscillator or crystal oven.\n\nFor higher accuracy measurements, an external frequency reference tied to a very high stability oscillator such as a GPS disciplined rubidium oscillator may be used. Where the frequency does not need to be known to such a high degree of accuracy, simpler oscillators can be used. It is also possible to measure frequency using the same techniques in software in an embedded system. A central processing unit (CPU) for example, can be arranged to measure its own frequency of operation provided it has some reference timebase to compare with.\n\nAccuracy is often limited by the available resolution of the measurement. Resolution of a single count is generally proportional to the timebase oscillator frequency and the gate time. Improved resolution can be obtained by several techniques such as oversampling/averaging.\n\nAdditionally, accuracy can be significantly degraded by jitter on the signal being measured. It is possible to reduce this error by oversampling/averaging techniques.\n\nI/O interfaces allow the user to send information to the frequency counter and receive information from the frequency counter. Commonly used interfaces include RS232, USB, GPIB and Ethernet. Besides sending measurement results, a counter can notify the user when user-defined measurement limits are exceeded. Common to many counters are the SCPI commands used to control them. A new development is built-in LAN-based control via Ethernet complete with GUI's. This allows one computer to control one or several instruments and eliminates the need to write SCPI commands.\n\n\n"}
{"id": "29469938", "url": "https://en.wikipedia.org/wiki?curid=29469938", "title": "Green Power Usage Effectiveness", "text": "Green Power Usage Effectiveness\n\nGreen Power Usage Effectiveness (GPUE) is a proposed measurement of both how much sustainable energy a computer data center uses, its carbon footprint per usable kilowatt hour (kWh) and how efficiently it uses its power; specifically, how much of the power is actually used by the computing equipment (in contrast to cooling and other overhead). It is an addition to the power usage effectiveness (PUE) definition and was first proposed by Greenqloud.\n\nThe Green Grid has developed the Power Usage Effectiveness metric or PUE to measure a data centers' effectiveness of getting power to IT equipment. What the PUE tells in simple terms is how much extra energy is needed for each usable kWh for the IT equipment due to the power going into cooling, power distribution loss etc. and it’s a simple formula (in theory):\n\nPUE = Total Facility Power/IT Equipment Power\n\nThe PUE can change depending on where measurements are made, when they are made and the timespan the measurements are made in.\nData centers are subtracting factors from their PUE to lower it e.g. district heating. Some of the issues with PUE are being addressed with the PUEx definition.\n\nGPUE is a way to \"weigh\" the PUE to better see which data centers are truly green in the sense that they indirectly cause the least amount of CO to be emitted by their use of sustainable or unsustainable energy sources.\n\nThis new metric GPUE or Green Power Usage Effectiveness is defined as:\n\nGPUE = G × PUEx (for inline comparison of data centers)<br>\nor = G @ PUEx (a better display and for CO emission calculations)\n\nThe \"G\" is the key factor here and it is a simple calculated value:\n\nG = Weighed sum of energy sources and their lifecycle KG CO/KWh\n\nG =∑( %EnergySource × ( 1 + weight) )\n\nAdding 1 to the weight is to \"weigh\" (multiply) with the PUE to get a number that is comparable to PUE. The weights taken directly from the \"lifecycle CO/kWh for electricity generation by power source\" table above we got from the 2008 Sovacool Study e.g. the weight for unscrubbed coal is e.g. 1.050 (kg of CO/kWh) while hydroelectric river generation has a weight of 0.013. An unknown energy source or a \"mix\" will get the same as the maximum value which for now is the same as coal.\n\nExample:\n\nPUE 1.20, 50/50 Coal/Hydro<br>\nG = 0.5*(1+1.050) + 0.5*(1+0.013)<br>\nG = 1.531, GPUEx = 1.84 or 1.531@1.20\n\nKg CO per usable kWh = (G-1) × PUEx = 0.64 kg\n\n"}
{"id": "3296793", "url": "https://en.wikipedia.org/wiki?curid=3296793", "title": "Hard and soft light", "text": "Hard and soft light\n\nHard and soft light are different types of lighting that are commonly used in photography and filmmaking. Soft light refers to light that tends to \"wrap\" around objects, casting diffuse shadows with soft edges. Soft light is when a light source is large relative to the subject; hard light is when the light source is small relative to the subject.\n\nThe hardness or softness of light depends mostly on the following two factors:\n\nThe softness of a light source can also be determined by the angle between the illuminated object and the 'length' of the light source (the longest dimension that is perpendicular to the object being lit). The larger this angle is, the softer the light source.\n\nSoft light use is popular in cinematography and film for a number of different reasons:\n\n\nHard light sources cast shadows whose appearance of the shadow depends on the lighting instrument. For example, fresnel lights can be focused such that their shadows can be \"cut\" with crisp shadows. That is, the shadows produced will have 'harder' edges with less transition between illumination and shadow. The focused light will produce harder-edged shadows. Focusing a fresnel makes the rays of emitted light more parallel. The parallelism of these rays determines the quality of the shadows. For shadows with no transitional edge/gradient, a point light source is required. Hard light casts strong, well defined shadows.\n\nWhen hitting a textured surface at an angle, hard light will accentuate the textures and details in an object.\n\nLight intensity tends to dim with distance. For a point source of light, intensity decreases as distance increases. Intensity (\"I\") is inversely proportional to the square of the distance (\"D\"), as expressed in the formula .\nFor a thin infinitely long light source, intensity is inversely proportional to distance. For a light source of infinite area, intensity does not decrease at all. Generally, a soft light source does not drop in intensity as quickly as a point light source would (as distance increases).\n\nCertain lensed lighting instruments (e.g. ellipsoidal reflector spotlights) have a good deal of \"throw\" and do not lose much intensity as distance increases. These light sources tend to be more effective at large distances than soft light sources. At large distances, an effective soft light source would have to be very large. The (mostly) parallel rays of such instruments tends to cast hard shadows, unlike soft light sources.\n\nMost light sources have a non-negligible size and therefore exhibit the properties of a soft light to some degree. Even the sun does not cast perfectly hard shadows.\n\nIn \"hard\" light sources, the parallelism of the rays is an important factor in determining shadow behaviour.\n\nThe quality of light can be altered by using diffusion gel or aiming a lighting instrument at diffusing material such as a silk. When shooting outdoors, cloud cover provides nature's version of a softbox.\n\n\n"}
{"id": "163711", "url": "https://en.wikipedia.org/wiki?curid=163711", "title": "Harrow (tool)", "text": "Harrow (tool)\n\nIn agriculture, a harrow (often called a set of harrows in a plurale tantum sense) is an implement for breaking up and smoothing out the surface of the soil. In this way it is distinct in its effect from the plough, which is used for deeper tillage. Harrowing is often carried out on fields to follow the rough finish left by plowing operations. The purpose of this harrowing is generally to break up clods (lumps of soil) and to provide a finer finish, a good tilth or soil structure that is suitable for seedbed use. Coarser harrowing may also be used to remove weeds and to cover seed after sowing. Harrows differ from cultivators in that they disturb the whole surface of the soil, such as to prepare a seedbed, instead of disturbing only narrow trails that skirt crop rows (to kill weeds). \n\nThere are four general types of harrows: disc harrows, tine harrows (including spring-tooth harrows, drag harrows, and spike harrows), chain harrows, and chain-disk harrows. Harrows were originally drawn by draft animals, such as horses, mules, or oxen, or in some times and places by manual labourers. In modern practice they are almost always tractor-mounted implements, either trailed after the tractor by a drawbar or mounted on the three-point hitch.\n\nA modern development of the traditional harrow is the rotary power harrow, often just called a power harrow.\n\nIn cooler climates the most common types are the \"disc harrow\", the \"chain harrow\", the \"tine harrow\" or \"spike harrow\" and the \"spring tine harrow\". Chain harrows are often used for lighter work such as levelling the tilth or covering seed, while disc harrows are typically used for heavy work, such as following ploughing to break up the sod. In addition, there are various types of \"power harrow\", in which the cultivators are power-driven from the tractor rather than depending on its forward motion.\n\nTine harrows are used to refine seed-bed condition before planting, to remove small weeds in growing crops and to loosen the inter-row soils to allow for water to soak into the subsoil. The fourth is a chain disk harrow. Disk attached to chains are pulled at an angle over the ground. These harrows move rapidly across the surface. The chain and disk rotate to stay clean while breaking up the top surface to about deep. A smooth seedbed is prepared for planting with one pass.\n\nChain harrowing can be used on pasture land to spread out dung, and to break up dead material (\"thatch\") in the sward, and similarly in sports-ground maintenance a light chain harrowing is often used to level off the ground after heavy use, to remove and smooth out boot marks and indentations. Used on tilled land in combination with the other two types, chain harrowing rolls remaining larger soil clumps to the surface where weather breaks them down and prevents interference with seed germination.\n\nAll four harrow types can be used in one pass to prepare soil for seeding. It is also common to use any combination of two harrows for a variety of tilling processes. Where harrowing provides a very fine tilth, or the soil is very light so that it might easily be wind-blown, a roller is often added as the last of the set. \n\nHarrows may be of several types and weights, depending on their purpose. They almost always consist of a rigid frame that holds discs, teeth, linked chains, or other means of moving soil—but tine and chain harrows are often only supported by a rigid towing-bar at the front of the set. \n\nIn the southern hemisphere, so-called \"giant discs\" are a specialised kind of disc harrows that can stand in for a plough in rough country where a mouldboard plough cannot handle tree-stumps and rocks, and a disc-plough is too slow (because of its limited number of discs). Giant scalloped-edged discs operate in a set, or frame, that is often weighted with concrete or steel blocks to improve penetration of the cutting edges. This sort of cultivation is usually followed by broadcast fertilisation and seeding, rather than drilled or row seeding. \n\nA drag is a heavy harrow.\nA rotary power harrow, or simply power harrow, has multiple sets of vertical tines. Each set of tines is rotated on a vertical axis and tills the soil horizontally. The result is that, unlike a rotary tiller, soil layers are not turned over or inverted, which is useful in preventing dormant weed seeds from being brought to the surface, and there is no horizontal slicing of the subsurface soil that can lead to hardpan formation. \n\nThe invention and use of the harrow was first written in the Chinese agricultural text \"Qimin Yaoshu\" written by the Northern Wei Dynasty official Jia Sixie. The harrow was used as a farm implement for breaking up soil chunks as well as eradicating weeds, suppressing pests, and diseases. Harrows were later used in Europe during the Middle Ages. The oldest known illustration of a harrow is in Scene 10 of the eleventh-century Bayeux Tapestry.\n\n\n"}
{"id": "18558517", "url": "https://en.wikipedia.org/wiki?curid=18558517", "title": "IPv6 deployment", "text": "IPv6 deployment\n\nDeployment of Internet Protocol Version 6 (IPv6), the next generation of the Internet Protocol, has been in progress since the mid-2000s.\n\nIPv6 was designed as a replacement for IPv4 which has been in use since 1982, and is in the final stages of exhausting its unallocated address space, but still carries most Internet traffic. Google's statistics show IPv6 availability of its users up to 25% depending on the day of the week (more use on weekends), with use over 20% any day of the week . Adoption is uneven across countries and Internet service providers.\nIn November 2016, 1491 (98.2%) of the 1519 top-level domains (TLDs) in the Internet supported IPv6 to access their domain name servers, and 1485 (97.8%) zones contained IPv6 glue records, and approximately 9.0 million domains (4.6%) had IPv6 address records in their zones. Of all networks in the global BGP routing table, 29.2% had IPv6 protocol support.\n\nBy 2011, all major operating systems in use on personal computers and server systems had production-quality IPv6 implementations. Cellular telephone systems present a large deployment field for Internet Protocol devices as mobile telephone service is making the transition from 3G to \"next-generation\" 4G technologies, in which voice is provisioned as a voice over IP (VoIP) service. This mandates the use of IPv6 for such networks. In 2009, the US cellular operator Verizon released technical specifications for devices to operate on its \"next-generation\" networks. The specification mandates IPv6 operation according to the \"3GPP Release 8 Specifications (March 2009)\", and deprecates IPv4 as an optional capability.\n\nGoogle publishes statistics on IPv6 adoption among Google users. A graph of IPv6 adoption since 2008 and a map of IPv6 deployment by country are available.\n\nAkamai publishes by-country and by-network statistics on IPv6 adoption for traffic it sees on its global Content Distribution Network (CDN). This set of data also shows graphs for each country and network over time.\n\nA global view into the history of the growing IPv6 routing tables can be obtained with the SixXS Ghost Route Hunter. This tool provided a list of all allocated IPv6 prefixes until 2014 and marks with colors the ones that were actually being announced into the Internet BGP tables. When a prefix was announced, it means that the ISP at least can receive IPv6 packets for their prefix.\n\nThe integration of IPv6 on existing network infrastructure may be monitored from other sources, for example:\n\nA few organizations are involved with international IPv6 test and evaluation, ranging from the United States Department of Defense to the University of New Hampshire.\n\n\nBy 2011, all major operating systems in use on personal computers and server systems had production-quality IPv6 implementations. Microsoft Windows has supported IPv6 since Windows 2000, and in production-ready state beginning with Windows XP. Windows Vista and later have improved IPv6 support. macOS since Panther (10.3), Linux 2.6, FreeBSD, and Solaris also have mature production implementations. Some implementations of the BitTorrent peer-to-peer file transfer protocol make use of IPv6 to avoid NAT issues common for IPv4 private networks.\n\nIn the early 2000s, governments increasingly required support for IPv6 in new equipment. The US government, for example, specified in 2005 that the network backbones of all federal agencies had to be upgraded to IPv6 by June 30, 2008; this was completed before the deadline. In addition, the US government in 2010 required federal agencies to provide native dual-stacked IPv4/IPv6 access to external/public services by 2012, and internal clients were to utilize IPv6 by 2014. Progress on the US government's external facing IPv6 services is tracked by NIST. The government of the People's Republic of China implemented a five-year plan for deployment of IPv6 called the \"China Next Generation Internet\" (see below).\n\nOn March 07, 2013, the Internet Engineering Task Force, created a working group for IPv4 sunset. However in May 2018 this working group was closed.\n\nAnwarNet (www.anwarnet.dz); AfriNIC has allocated range of IPv6 address space to AnwarNet. AnwarNet started IPV6 services in 2011.\n\n\n\n\nAs of 2017, Brazil has 20% IPv6 adoption, IPv6 being adopted by most universities, companies and made available for home users by larger ISPs.\n\nHas constructed a research center to study the possibilities of adopting IPv6 in the country. The center will operate alongside another facility, which is equipped with an IBM Blue Gene/P supercomputer.\n\nSince 2015 the ISP Blizoo enabled IPv6 for many home customers.\n\nAt the end of 2016, the ISP ComNet Bulgaria Holding Ltd. has provided complete IPv6 support for all customers and households within company network in Bulgaria.\n\nIPv6 deployment is slow but ongoing, with major Canadian ISPs (notably Bell Canada, Vidéotron, and Cogeco) lacking in support for its residential customers, and the majority of their business customers (including server packages). Canadian IPv6 usage jumped from 0.5% in July 2015 to 7% in Dec 2015 due to IPv6 deployment at Rogers and Telus.\n\nAccording to Google's statistics, Canada has reached an IPv6 adoption rate of 16% by December 2016.\n\n\nThe China Next Generation Internet (CNGI, 中国下一代互联网) project is a five-year plan initiated by the Chinese government with the purpose of gaining a significant position in the development of the Internet through the early adoption of IPv6. China showcased CNGI's IPv6 infrastructure during the 2008 Summer Olympic Games, being the first time a major world event has had a presence on the IPv6 Internet. At the time of the event, it was believed that the Olympics provided the largest showcase of IPv6 technology since the inception of IPv6. The deployment of IPv6 was widespread in all related applications, from data networking and camera transmissions for sporting events, to civil applications, such as security cameras and taxis. The events were streamed live over the Internet and networked cars were able to monitor traffic conditions readily, all network operations of the Games being conducted using IPv6.\n\nAlso, the CERNET (China Education and Research NETwork, 中国教育和科研计算机网, 教育网) set up native IPv6 (CERNET2), and since then many academic institutions in China joined CERNET2 for IPv6 connectivity. CERNET-2 is probably the widest deployment of IPv6 in China. It is managed and operated jointly by 25 universities. Students in Shanghai Jiao Tong University and Beijing University of Posts and Telecommunications, for example, get native IPv6.\n\nIn November 2017, the Communist party decreed a plan to get all its Internet users on IPv6 by 2025 with a quarter of them by the end of 2018.\n\nAs of December 2016, the country has only 2% IPv6 traffic (according to both Google and Apnic stats).\n\nA web page (in Danish) follows national IPv6 deployment.\n\nThe ISP Fullrate has begun offering IPv6 to its customers, on the condition that their router (provided by the ISP itself) is compatible. If the router is of a different version, the customer has to request a new router.\n\nEstonian Telekom is providing native IPv6 access on residential and business broadband connections since September 2014. According to Google's statistics, Estonia has reached an IPv6 adoption rate of 18% by end of June 2017.\n\nFICORA (Finnish Communications Regulatory Authority), the NIC for the .fi top level domain, has added IPv6 address to DNS servers, and allows entering IPv6 address when registering domains. The registration service domain.fi for new domains is also available over IPv6.\n\nA small Finnish ISP has offered IPv6 access since 2007.\n\nFICORA held national IPv6 day on June 9, 2015. At that time Elisa and DNA Oyj started providing IPv6 on mobile subscriptions, and Telia Company and DNA Oyj started providing IPv6 on fixed-line connections.\n\nAccording to Google's statistics, Finland has reached an IPv6 adoption rate of 15% by May 2017.\n\n\nAs of May 2017, France has 16% IPv6 traffic (according to Google and 20% Apnic stats).\n\nAccording to Google's statistics, Germany has reached an IPv6 adoption rate of 30% by end of May 2017.\n\n\nIn Hungary was the first ISP starting deploying IPv6 on its network in 2008 August. The service was commercially available since 2009 May.\n\nMagyar Telekom was running tests on its production environments since the beginning of 2009. Free customer trials started on November 2, 2009, for those on ADSL or Fiber Optic. Customers are given a /128 via DHCP-ND unless they register their DUID in which case they receive a /56 using a static configuration results in a single /64.\n\nAccording to information on telecompaper.com, UPC Hungary will start deploying IPv6 in mid-2013, finishing it in 2013.\n\nIn 2015, December RCS&RDS (Digi) has enabled native dual stack IPv6(customers receive dynamic /64 prefixes) for its FTTB/H customers. In November the same year UPC Hungary introduced DS Lite(with private IPv4 addresses) which can be enabled on a customer-to-customer basis if the customer asks for it.\n\nMagyar Telekom deployed dual stack IPv6 (using dynamic /56 prefixes on DSL and GPON and static /56 prefixes on DOCSIS) for all of its wired (and for all of its compatible mobile) customers in October 2016.\n\nAccording to the statistics of APNIC, IPv6 use in Hungary as of 2017 June has reached around 11%.\n\nAccording to Google's IPv6 statistics the adoption rate at 2017 June was 11%.\n\nAccording to Google's statistics, India has reached an IPv6 adoption rate of around 32% at the end of May 2018.\nAPNIC places India at more than 50% preferring IPv6.\n\n\n\nGrowth of IPv6 in Ireland as seen by Google.\n\n\nAccording to Google's statistics, Japan has reached an IPv6 adoption rate of 17% by May 2017.\n\n\nThe LITNET academic & research network has supported IPv6 since 2001. Most commercial ISPs have not publicly deployed IPv6 yet.\n\nAccording to Google's statistics, Luxembourg has reached an IPv6 adoption rate of 24% by May 2017.\n\n\n, surveys conducted by the New Zealand IPv6 Task Force indicated that awareness of IPv6 had reached a near-universal level among New Zealand's large public- and private-sector organisations, with adoption mostly occurring as part of normal network refresh cycles. Most of New Zealand's ISP and carrier community have a test environment for IPv6 and many have started bringing IPv6 products and services on-stream. An increasing number of New Zealand government websites are available over IPv6, including those of the Ministry of Defence (New Zealand), Ministry for Primary Industries (New Zealand) and the Department of Internal Affairs.\n\n\nThe government is in process of upgrading its facilities. Globe Telecom has already set in motion the transition of its core IP network to IPv6, noting that it is now fully prepared even as the Internet runs out of IPv4 addresses. Globe claims it is the first local telecommunication company to test IPv6 with Department of Science and Technology (Philippines). In some cases, like test networks or users, IPv6 or both maybe present.\n\n\n\n\nThe Sudanese IPv6 task Force SDv6TF was formed in 2010 to fellow the implementation of IPv6 migration plan (2011–2015).\n\nBy November 2012, all telecom operators are becoming IPv6 enabled, this was tested for the first time at the AFRINIC-17 meeting held in Khartoum.\n\nSudREN (Sudanese Research and Education Network) is the first ISP to provide native IPv6 connectivity of the member institution. By August 2014, SudREN.edu.sd is fully IPv6 Enabled.\nTwo certification received from IPv6 Forum, for WWW and ISP Enabled Logos.\n\n\nOperators offering native IPv6 access for business clients and collocation customers include Tele2 and Phonera.\n\n\nStarted deploying IPv6 in 2010. In 2011, ATI (Tunisian Internet Agency) obtained a new IPv6 bloc from Afrinic (2c0f:fab0::/28).\nIn 2013–2015, Gnet (Global Net), and CIMSP (Computing Departement of Health Ministry) received IPv6 prefixes from Afrinic.\nDeployment of an IPv6 tunnel between ATI and HE (Hurricane Electric).\nIn 2016, CCK (Centre de Calcul El Khawarizmi) obtains its own IPv6 (/32) bloc from Afrinic. In 2016, ISET Charguia (Higher Institute of Technologies in Tunisia) deployed its IPv6 network as end user.\n\n\nIn the United States the majority of smartphones use IPv6, but only a small percent of computers and tablets use IPv6.\n\nThe Internet Society promoted June 8, 2011, as \"World IPv6 Day\". The event was described as a \"test drive\" for full IPv6 rollouts.\n\nThe Internet Society declared June 6, 2012, to be the date for \"World IPv6 Launch\", with participating major websites enabling IPv6 permanently, participating ISPs offering IPv6 connectivity, and participating router manufacturers offering devices enabled for IPv6 by default.\n\n\n"}
{"id": "184092", "url": "https://en.wikipedia.org/wiki?curid=184092", "title": "JEDEC", "text": "JEDEC\n\nThe JEDEC Solid State Technology Association is an independent semiconductor engineering trade organization and standardization body.\n\nJEDEC has over 300 members, including some of the world's largest computer companies. Its scope and past activities includes standardization of part numbers, defining an electrostatic discharge (ESD) standard, and leadership in the lead-free manufacturing transition.\n\nThe origin of JEDEC traces back to 1944, when RMA (subsequently renamed EIA) and NEMA established the Joint Electron Tube Engineering Council (JETEC) to coordinate vacuum tube type numberings.\n\nIn 1958, with the advent of semiconductor technology, the joint JETEC-activity of EIA and NEMA was renamed into Joint Electron Device Engineering Council. NEMA discontinued its involvement in 1979. In the fall of 1999, JEDEC became a separate trade association under the current name, but maintained an EIA alliance, until EIA ceased operations in 2011.\n\nThe origin of JEDEC can be traced back to 1944, when the Radio Manufacturers Association (RMA), and the National Electrical Manufacturers Association (NEMA) established the \"Joint Electron Tube Engineering Council\" (\"JETEC\") to coordinate vacuum tube type numberings. The expansion of the radio industry caused JETEC to expand its scope to include solid state devices and develop standards for semiconductor devices. Eventually, the joint JETEC activity of EIA and NEMA was renamed into \"Joint Electron Device Engineering Council\" (\"JEDEC\") in 1958.\n\nThe early work began as a part numbering system for devices which became popular in the 1960s. The first semiconductor devices, such as the 1N23 silicon point contact diode, were still designated in the old \"RMA tube designation\" system, where the \"1\" stood for \"No filament/heater\" and the \"N\" stood for \"crystal rectifier\". The first RMA digit thus was re-allocated from \"heater power\" to \"p-n junction count\" to form the new EIA/JEDEC \"EIA-370\" standard; for example, the 1N4001 rectifier diode and 2N2222 transistor part numbers came from \"EIA-370\". They are still popular today. In February 1982, JEDEC issued \"JESD370B\", superseding the original \"EIA-370\" and introducing a new letter symbol \"C\" that denotes the die version, as opposed to \"N\", now meaning the packaged version. The Japanese JIS semiconductor designation system employs a similar pattern. JEDEC later developed a numbering system for integrated circuits, but this did not gain acceptance in the semiconductor industry. The European Pro Electron semiconductor numbering system originated in a similar way from the older Mullard–Philips tube designation.\n\nEarlier in the 20th century, the organization was known as JETEC, the Joint Electron Tube Engineering Council, and was responsible for assigning and coordinating RETMA tube designations to electron tubes (also called valves). The type 6L6, still to be found in electric-guitar amplifiers, typically has a type number that was assigned by JETEC.\n\nIn the fall of 1999, JEDEC became a separate trade association under the current name, but maintained an EIA alliance.\n\nThis early work was followed by a number of test methods, JESD22, and product standards. For example, the ESD caution symbol, which is the hand with the line drawn through it, was published by JEDEC and is used worldwide. JEDEC also has a dictionary of semiconductor terms. All of JEDEC standards are free on the Web for downloading after a free registration.\n\nJEDEC has issued widely used standards for device interfaces, such as the JEDEC memory standards for computer memory (RAM), including the DDR SDRAM standards.\n\nJEDEC also developed a number of popular package drawings for semiconductors such as TO-3, TO-5, etc. These are on the web under JEP-95. One hot issue is the development of lead-free packages that do not suffer from the tin whiskers problem that reappeared since the recent ban on lead content. JEDEC is working with iNemi on a joint interest group on lead-free issues.\n\nJEDEC's adoption of open industry standards (i.e., standards that permit any and all interested companies to freely manufacture in compliance with adopted standards) serves several vital functions for the advancement of electronic technologies. First and foremost, such standards allow for interoperability between different electrical components. JEDEC standards do not protect members from normal patent obligations. The designated representatives of JEDEC member companies are required to disclose patents and patent applications of which they personally are aware (assuming that this information is not considered proprietary). JEDEC patent policy requires that standards found to contain patents whose owners will not sign a standard JEDEC patent letter be withdrawn. Thus the penalty for a failure to disclose patents is retraction of the standard. Typically, standards will not be adopted to cover technology that will be subject to patent protection. In rare circumstances, standards covered by a patent may be adopted, but only on the understanding that the patent owner will not enforce such patent rights or, at a minimum, that the patent owner will provide a reasonable and non-discriminatory license to the patented technology.\n\n"}
{"id": "1031396", "url": "https://en.wikipedia.org/wiki?curid=1031396", "title": "Kitchenware", "text": "Kitchenware\n\nKitchenware is any tools, utensils, appliances, dishes, and cookware, that can be used in the process of food preparation, cooking or baking, or the serving of food. Kitchenware can also be used to hold or store food before or after preparation.\n\nKitchenware encompasses a wide range of tools. Some of the most common items of kitchenware are:\n"}
{"id": "9299230", "url": "https://en.wikipedia.org/wiki?curid=9299230", "title": "Koobox", "text": "Koobox\n\nThe Koobox was a product created by Linspire in conjunction with Mirus Innovations and AOpen to put the Linspire 5.0 distribution of Linux on OEM PCs. The three main PCs offered by Koobox are:\n\n"}
{"id": "15535222", "url": "https://en.wikipedia.org/wiki?curid=15535222", "title": "Mobile Electronic Signature Consortium", "text": "Mobile Electronic Signature Consortium\n\nMobile Electronic Signature Consortium (referred to as 'mSign') was founded in 1999 and comprised 35 member companies. In October 2000, the consortium published an XMl-interface defining a protocol allowing service providers to obtain a mobile (digital) signature from a mobile phone subscriber.\n\nIn 2001, mSign gained industry-wide coverage when it became apparent that Brokat, a company of one of the founders, also obtained a process patent in Germany for using the mobile phone to generate digital signatures.\n\nThe mSign consortium created the standards on the assumption that a WAP phone with a WAP 1.2 implementation and digital keys stored on the SIM card (i.e. WIM) would be used to generate a mobile (digital) signature. During the standardization process, room was given also to other mechanisms for authenticating the mobile phone subscriber such as the sending of a password via SMS or Dialtone communication and voice identification. The specification also allowed for server-based digital signatures. In other words, digital signatures not generated in the mobile phone but on a central server that would then communicate with the signature requesting Service Providers via the mSign interface.\n\nThe founding members were Siemens, E-Plus Mobilfunk, Mannesmann Mobilfunk, T-Mobile, VIAG Interkom, Schlumberger, Gemplus, T-Telesec, Trust Center of Deutsche Telekom, cv cryptovision and Brokat AG.\n\nLater members include Advance Bank, Bank of Tokyo-Mitsubishi Ltd., Cable & Wireless HKT, Carticom Corporation, Credit Agricole Indosuiez Luxembourg, EXCELSIS Informationssysteme GmbH, fun communications GmbH, Hewlett-Packard GmbH, Hypo Vereinsbank, IIS/GlobalSign Greece SA, InterCard POS–Service GmbH, ITFinity Solutions, Mitsubishi Electric Corporation, MyAlert.com, NSE Software AG, ORGA Kartensysteme GmbH, PAGO eTransaction Services GmbH & Co. KG, payitmobile AG i.G., RCM Technologies (Operational Headquarter, Siemens AG, ICP CD M EBO, SONERA SMARTTRUST GmbH, TC TrustCenter GmbH, WAYS INDIA Ltd. and West LB.\n\nUwe Mittelstaedt: Referat im Rahmen des SBWL-Seminars „MCommerce“ im Wintersemester 2000/01 \"Die Teilnahme an und die Gestaltung von Standardisierungsprozessen\" http://www.is-frankfurt.de/veranstaltung/SBWL-WS00-01/thema7_referate/mittelstaedt/Seminiararbeit%20Thema%207.htm#_ftn20\n\nAnnouncement that Brokat has obtained a patent, 19.2.2001\nhttp://www.golem.de/0102/12415.html\n\nTuvIT Arbeitspapier: \"Mobile elektronische Signatur\", Dec. 2002\nhttp://mediakomm.difu.de/documents/forschung/mobile---signatur.pdf\n"}
{"id": "2425087", "url": "https://en.wikipedia.org/wiki?curid=2425087", "title": "Museum of Transport and Technology", "text": "Museum of Transport and Technology\n\nThe Museum of Transport and Technology (MOTAT) is a science and technology museum located in Western Springs, Auckland, New Zealand. It is located close to the Western Springs Stadium, Auckland Zoo and the Western Springs Park. The museum has large collections of civilian and military aircraft and other land transport vehicles. An ongoing programme is in place to restore and conserve items in the collections. This work is largely managed by volunteers many of whom have been associated with MOTAT for upwards of four decades. Since the passing of the Museum of Transport and Technology Act in 2000, new management and the support of full-time professional museum staff and a large number of dedicated long term volunteers have ensured the Museum's future. New public programmes and facilities now promote the collections.\n\nMOTAT was established in 1960 by a combination of groups including the Old Time Transport Preservation League, which was formed in 1957 and preserved trams and railway locomotives. MOTAT was formally opened in 1964.\n\nMOTAT 1 was built around the site of a beam engine pump house, which originally provided Auckland's water supply (system similar to the Crofton Pumping Station and Markfield Beam Engine). The Council engaged the services of famed engineer, William Errington, to design and construct the Pumphouse and Boiler house to provide the first pressurised water supply to Auckland. Adjacent swampland was excavated creating a dammed lake, which is filled by three natural springs. This area is now the Western Springs Lake and parkland. The engine is a Double Woolf Compound built by John Key and Sons of Kirkcaldy in Scotland, who also built the long scrapped Lancashire boilers that originally provided the steam. The Western Springs Water Works officially opened in a small ceremony on 10 July 1877. The pumphouse was superseded by Auckland's extensive dam system and reticulation in 1928. Restoration and earthquake strengthening of the building was completed in 2002 and overhaul of the long dormant Beam Engine commenced at the start of 2005. On 11 October 2007 the engine moved under pneumatic pressure for the first time in 79 years and was finally tested under steam during the evening of 29 November the same year. The Beam engine was re-commissioned in a special public opening on 19 April 2008. A range of other early steam engines are kept in running order including a 1910 Tangye steam engine, an impressive 1911 triple-expansion engine built by Campbell Calderwood from Paisley, Scotland, which was formerly from the ill-fated Sydney Ferry The Greycliffe which sank on 3 November 1927 after being hit by the much larger Union Steam Ship Company’s Royal Mail Steamship Tahiti with the loss of 40 lives. The engine ended its commercial life in the Tirau dairy factory. Steam for the Beam Engine and other artifacts provided by a 1957 Daniel Adamson steam boiler, which was formerly used at Frankham's Mill, Te Puna.\n\nExhibits include trams, trains, vintage traction engines, carriages, cars, buses, trolleybuses and trucks, particularly fire engines, electrical equipment, space flight exhibits including a Corporal rocket and general science exhibits. There is also a 'colonial village' of early shops and houses, including a fencible cottage and a blacksmith shop.\n\nThe MOTAT printery demonstrates type making, type setting and printing on a variety of different manual and mechanical printing presses operated by Volunteers printing giveaways and small publications. A volunteer bindery group also demonstrate their talents and hold classes.\n\nIn the 1970s visitors to MOTAT were entertained by the MOTAT Chorus, a group of barbershop singers who later became the Auckland City of Sails Chorus.\n\nThe 'Pioneers of Aviation' Pavilion holds memorabilia of early aviators. The displays include miscellaneous parts from Richard Pearse's experimental aircraft, (together with research supporting the claim that he made uncontrolled hops/flights prior to the Wright brothers), a replica of the craft which was flown and his third aircraft (an attempt at a VTOL tilt rotor craft). The pavilion also holds relics from the Walsh Brothers' flights and school, and a library and archive of transport resources named in memory of the Walsh Brothers available to all MOTAT visitors and via the MOTAT website for virtual visitors. Also celebrated is Charles Kingsford-Smith's trans-Tasman flight in the Southern Cross, Jean Batten's England–New Zealand flight and later record breaking efforts (her Percival Gull is exhibited at Auckland Airport). The larger civil aviation exhibits continue over at MOTAT 2 with displays relating to the Pan American Airways and Imperial Airways flying boats of the late 1930s and TEAL flying boats of the 40s and 50s. The engine from Jean Batten's Percival Gull is displayed at MOTAT 2.\n\nThe Road transport collection rotationally displays in excess of 100 cars, trucks, motorbikes and emergency vehicles. Some of the iconic vehicles in the collection include one of the first Trekka utility vehicles, New Zealand's only homegrown production vehicle built between 1966 and 1973, based on Czechoslovakian Škoda engines and chassis. Other vehicles include a 1960s Cooper Climax race car, an early American Brush Motor Car Company runabout, an International horseless carriage, an Austin Motor Company beer tanker (the first in New Zealand) and a wide number of other vehicles. Also in the collection is one of the Ferguson Company tractors which Edmund Hillary used to lay supply depots for the Commonwealth Trans-Antarctic Expedition, and with which he beat British explorer Dr Vivian Fuchs Sno-Cats to the South Pole on 3 January 1958.\n\nMOTAT also houses a small collection of Police vehicles, including former New Zealand Transport Department, later New Zealand Ministry of Transport (M.O.T.) patrol cars and patrol motorbikes, the road policing duties of which were combined into the New Zealand Police in the early 1990s. The NZ Police Collection of 40 plus vehicles were housed at MOTAT for a number of years until 2011.\n\nTrams are displayed at MOTAT 1 and operate daily between MOTAT 1's Great North Road Site, via Western Springs Park and Auckland Zoo to MOTAT 2. The extended line was opened by Helen Clark on Friday 27 April 2007.\n\nMOTAT 2's NZ$15 million extended aviation pavilion housing the \"Sir Keith Park Memorial Aviation Collection\" opened Friday 9 September 2011.\n\nAlso known in the past as the 'Sir Keith Park Memorial Airfield', named after Keith Park, the Battle of Britain and Battle of Malta hero, MOTAT's aviation collection is on a separate site, neighbouring the Waitematā Harbour and Auckland Zoo. It contains memorials to Fleet Air Arm and RAF Bomber Command pilots, radar and other aviation related material, as well as workshops for work on other vehicles, but the main feature is the collection of New Zealand's civil and some Royal New Zealand Air Force aircraft. A Grumman Avenger TBF-1 NZ2527 1943 torpedo bomber was completed in December 2013 and is due to go on display in early 2014, it is a RNZAF Pacific combat veteran and representative of Avengers operated by the RN Fleet Air Arm. In November 2011 a Douglas A4K Skyhawk jetfighter was permanently loaned to MOTAT followed by a De Havilland Devon and Aermacchi MB-339 jet trainer in 2012. A BAC Strikemaster may join the collection from the RNZAF.\n\nThere is also a military section which restores and demonstrates a selection of Second World War military trucks, light tracked vehicles and tanks of Allied forces. The military section has regular open days when the Military Reenactment Society displays and demonstrates the vehicles and uniforms.\n\nMOTAT 2 also has an operational railway with 1 km of track, stations and a selection of former New Zealand Government Railways, light industrial locomotives, wagons and carriages.\n\nOn 9 September 2011 a new and larger display hangar was opened at MOTAT 2. The existing blister hangar was moved and restored as part of the same project. With the construction of the new hangar it was now possible to display the restored De Havilland Mosquito and Lockheed Hudson. Short S25 Sunderland Mk V and NAC DC3 Dakota were in moved inside as their overhauls and external painting was completed towards the end of summer 2012. The Short S45A Solent Mk 4, Ventura and top dressing Lodestar will be housed in due course as restorations and building provisions allow.\n\nMOTAT features several major collections of transport vehicles:\n\n\nTramlines on sleepered track set under bitumen were laid within the museum boundaries with trams commencing operation on 16 December 1967. The Museum tramline was later extended beyond the Museum grounds along Gt. North Road and opened on 19 December 1980. A further extension along Motions Road to Auckland Zoo commenced services on 5 December 1981 using rail set in mass concrete. In 2006–07 the tram line was further extended by a distance of 636 metres, to the aviation hangar at MOTAT 2, the service commencing on 27 April 2007. The tramway is dual gauge, employing 4-foot and 4-foot inches gauges, the rail welded and set in mass concrete.\n\nTrams are operated daily between MOTAT, alongside the Western Springs Park and precinct, past Auckland Zoo to MOTAT 2 and connect both Museum sites.\n\n\n"}
{"id": "1000634", "url": "https://en.wikipedia.org/wiki?curid=1000634", "title": "NesC", "text": "NesC\n\nnesC (pronounced \"NES-see\") is a component-based, event-driven programming language used to build applications for the TinyOS platform. TinyOS is an operating environment designed to run on embedded devices used in distributed wireless sensor networks. nesC is built as an extension to the C programming language with components \"wired\" together to run applications on TinyOS. The name \"nesC\" is an abbreviation of \"network embedded systems C\".\n\nnesC programs are built out of components, which are assembled (\"wired\") to form whole programs. Components have internal concurrency in the form of tasks. Threads of control may pass into a component through its interfaces. These threads are rooted either in a task or a hardware interrupt. \n\nInterfaces may be provided or used by components. The provided interfaces are intended to represent the functionality that the component provides to its user, the used interfaces represent the functionality the component needs to perform its job. \n\nIn nesC, interfaces are bidirectional: They specify a set of functions to be implemented by the interface's provider (commands) and a set to be implemented by the interface's user (events). This allows a single interface to represent a complex interaction between components (e.g., registration of interest in some event, followed by a callback when that event happens). This is critical because all lengthy commands in TinyOS (e.g. send packet) are non-blocking; their completion is signaled through an event (send done). By specifying interfaces, a component cannot call the send command unless it provides an implementation of the sendDone event. Typically commands call downwards, i.e., from application components to those closer to the hardware, while events call upwards. Certain primitive events are bound to hardware interrupts. \n\nComponents are statically linked to each other via their interfaces. This increases runtime efficiency, encourages robust design, and allows for better static analysis of programs. \n"}
{"id": "39070425", "url": "https://en.wikipedia.org/wiki?curid=39070425", "title": "Ocean Power Technologies Australasia", "text": "Ocean Power Technologies Australasia\n\nOcean Power Technologies Australasia Pty Ltd (OPTA) is an Australian company, a subsidiary of Ocean Power Technologies Inc (OPT) of the United States, a renewable energy company, providing power generation devices, services and related equipment for the extraction of energy from ocean waves. \n\nIn 2009 OPTA was part of Victorian Wave Partners formed to develop a 19 megawatt wave power project near Portland, Victoria connected to the grid. The project was to receive an AU$66.46 million grant from the Australia federal government. By 2014, the consortium had abandoned the project, saying it was not commercially viable. OPT had given up on plans to develop the project, which was to cost $232 million for which the Australian government had offered $66.5 million in funding support.\n\n\n"}
{"id": "44852866", "url": "https://en.wikipedia.org/wiki?curid=44852866", "title": "Performance gap", "text": "Performance gap\n\nThe performance gap is a term commonly used to denote the disparity that is found between the energy use predicted and carbon emissions in the design stage of buildings and the energy use of those buildings in operation. Research in the UK suggests that actual carbon emissions from new homes can be 2.5 times the design estimates, on average. For non-domestic buildings, the gap is even higher - actual carbon emissions as much as 3.8 times the design estimates, on average.\n\nThere are established tools for reducing the performance gap, by reviewing project objectives, outline and detailed design drawings, design calculations, implementation of designs on site, and post-occupancy evaluation. NEF's Assured Performance Process (APP) is one such tool, which is being used extensively on different sites that form part of East Hampshire's Whitehill and Bordon new town development, one of the largest regeneration projects anywhere in the UK, with high ambitions for both environmental performance and health.\n\nThe performance gap is produced mainly due to uncertainties. Uncertainties are found in any “real-world” system, and buildings are no exception. As early as 1978, Gero and Dudnik wrote a paper presenting a methodology to solve the problem of designing subsystems (HVAC) subjected to uncertain demands. After that, other authors have shown an interest in the uncertainties that are present in building design; Ramallo-González classified uncertainties in building design/construction in three different groups:\n\nThe type 1 from this grouping, have been divided here into two main groups: one concerning the uncertainty due to climate change; and the other concerning uncertainties due to the use of synthetic weather data files. Concerning the uncertainties due to climate change: buildings have long life spans, for example, in England and Wales, around 40% of the office blocks existing in 2004 were built before 1940 (30% if considered by floor area). and, 38.9% of English dwellings in 2007 were built before 1944. This long life span makes buildings likely to operate with climates that might change due to global warming. De Wilde and Coley showed how important is to design buildings that take into consideration climate change and that are able to perform well in future weathers.\nConcerning the uncertainties due to the use of synthetic weather data files: Wang et al. showed the impact that uncertainties in weather data (among others) may cause in energy demand calculations. The deviation in calculated energy use due to variability in the weather data were found to be different in different locations from a range of (-0.5% – 3%) in San Francisco to a range of (-4% to 6%) in Washington D.C. The ranges were calculated using TMY as the reference. These deviations on the demand were smaller than the ones due to operational parameters. For those, the ranges were (-29% – 79%) for San Francisco and (-28% – 57%) for Washington D.C. The operation parameters were those linked with occupants’ behaviour. The conclusion of this paper is that occupants will have a larger impact in energy calculations than the variability between synthetically generated weather data files.\nThe spatial resolution of weather data files was the concern covered by Eames et al. Eames showed how a low spatial resolution of weather data files can be the cause of disparities of up to 40% in the heating demand.\n\nIn the work of Pettersen, uncertainties of group 2 (workmanship and quality of elements) and group 3 (behaviour) of the previous grouping were considered (Pettersen, 1994). This work shows how important occupants’ behaviour is on the calculation of the energy demand of a building. Pettersen showed that the total energy use follows a normal distribution with a standard deviation of around 7.6% when the uncertainties due to occupants are considered, and of around 4.0% when considering those generated by the properties of the building elements. \nA large study was carried out by Leeds Metropolitan at Stamford Brook. This project saw 700 dwellings built to high efficiency standards. The results of this project show a significant gap between the energy used expected before construction and the actual energy use once the house is occupied. The workmanship is analysed in this work. The authors emphasise the importance of thermal bridges that were not considered for the calculations, and how those originated by the internal partitions that separate dwellings have the largest impact on the final energy use. The dwellings that were monitored in use in this study show a large difference between the real energy use and that estimated using SAP, with one of them giving +176% of the expected value when in use.\n\nHopfe has published several papers concerning uncertainties in building design that cover workmanship. A more recent publication at the time of writing looks into uncertainties of group 2 and 3. In this work the uncertainties are defined as normal distributions. The random parameters are sampled to generate 200 tests that are sent to the simulator (VA114), the results from which will be analysed to check the uncertainties with the largest impact on the energy calculations. This work showed that the uncertainty in the value used for infiltration is the factor that is likely to have the largest influence on cooling and heating demands. \nAnother study performed by de Wilde and Wei Tian, compared the impact of most of the uncertainties affecting building energy calculations taking into account climate change. De Wilde and Tian used a two dimensional Monte Carlo Analysis to generate a database obtained with 7280 runs of a building simulator. A sensitivity analysis was applied to this database to obtain the most significant factors on the variability of the energy demand calculations. Standardised Regression Coefficients and Standardised Rank Regression Coefficients were used to compare the impacts of the uncertainties. \n\nDe Wilde and Tian agreed with Hopfe on the impact of uncertainties in the infiltration over energy calculations, but also introduced other factors, including uncertainties in: weather, U-Value of windows, and other variables related with occupants’ behaviour (equipment and lighting). Their paper compares many of the uncertainties with a good sized database providing a realistic comparison for the scope of the sampling of the uncertainties. \nThe work of Schnieders and Hermelink showed a substantial variability in the energy demands of low-energy buildings designed under the same specification (Passivhaus).\n\nThe work of Schnieders and Hermelink showed a substantial variability in the energy demands of low-energy buildings designed under the same specification (Passivhaus). Although the passivhaus standard has a very controlled, high quality workmanship, large differences have been seen in energy demand in different houses.\nBlight and Coley showed that that variability can be occasioned due to variance in occupant behaviour (it should be noted that the use of windows and doors was included in this work). The work of Blight and Coley proves two things: (1) Occupants have a substantial influence on energy use; and (2) The model they used to generate occupants’ behaviour is accurate for the creation of behavioural patterns of inhabitants. \nThe method used in the previous paper to generate accurate profiles of occupants’ behaviour was the one developed by Richardson et al. The method was developed using the Time-Use Survey (TUS) of the United Kingdom as a reference of real behaviour of occupants, this database was elaborated after recording the activity of more than 6000 occupants in 24-hours diaries with a 10 minutes resolution . Richardson’s paper shows how the tool is able to generate behavioural patterns that correlate with the real data obtained from the TUS.\nThe availability of this tool allows scientist’s to model the uncertainty of occupants’ behaviour as a set of behavioural patterns that have been proven to correlate with real occupants’ behaviour. \nThere have been works published to take into account occupancy in optimisation using the so called robust optimisation \n\n"}
{"id": "16335526", "url": "https://en.wikipedia.org/wiki?curid=16335526", "title": "Pesticide drift", "text": "Pesticide drift\n\nPesticide drift refers to the unintentional diffusion of pesticides and the potential negative effects of pesticide application, including off-target contamination due to spray drift as well as runoff from plants or soil.This can lead to damage in human health, environmental contamination, and property damage. The California Department of Pesticide Regulation estimates that between 37-68% of pesticide illness among U.S. agricultural workers come as a result of pesticide drift.\n\nWith placement (localised) spraying of broad spectrum pesticides, wind drift must be minimized, and considerable efforts have been made to quantify and control spray drift from hydraulic nozzles. Conversely, wind drift is also an efficient mechanism for moving droplets of an appropriate size range to their targets over a wide area with ultra-low volume (ULV) spraying.\n\nHimel (1974) made a distinction between exo-drift (the transfer of spray out of the target area) and endo-drift, where the active ingredient (AI) in droplets falls into the target area, but does not reach the biological target. Endo-drift is volumetrically more significant and may therefore cause greater ecological contamination (e.g. where chemical pesticides pollute ground water).\n\nBystander exposure describes the event when individuals unintentionally come in contact with airborne pesticides. Bystanders include workers working at an area separate to the pesticide application are, individuals living in the surrounding areas of an application area, or individuals passing by fields as they are being treated with a pesticide.\nHerbicide volatilisation refers to evaporation or sublimation of a volatile herbicide. The effect of a gaseous chemical is lost at its intended place of application and may move downwind and affect other plants not intended to be affected causing crop damage. Herbicides vary in their susceptibility to volatilisation. Prompt incorporation of the herbicide into the soil may reduce or prevent volatilisation. Wind, temperature, and humidity also affect the rate of volatilisation, with humidity reducing it. 2,4-D and dicamba are commonly used chemicals that are known to be subject to volatilisation, but there are many others. Application of herbicides later in the season to protect herbicide-resistant genetically modified plants increases the risk of volatilisation as the temperature is higher and incorporation into the soil impractical.\nAlthough there has been much public concern and research into spray drift, point source pollution (e.g. pesticides entering bodies of water following spillage of concentrate or \"rinsate\") can also cause great environmental harm. Public concern for pesticide drift is not met with adequate regulatory response. Environmental justice advocates in California, for instance, consider moving up the scale of the discourse on pesticide drift by categorizing it as air pollution in order to receive attention from state environmental protection. \n\nFarm workers and communities surrounding large farms are at a high risk of coming in contact with pesticides. The San Joaquin valley in California has seen numerous cases of illnesses resulting from exposure to pesticides through pesticide drift. Organizations such as United Farm Workers Union have fought to implement legislation that would reduce and hold farmers accountable for pesticide drift. The California Department of Pesticide Regulation estimates that between 37-68% of pesticide illness among U.S. agricultural workers come as a result of pesticide drift. \n\nInsecticides sprayed on crop fields can also have detrimental effects on non-human life forms that are important to the surrounding ecosystems like bees and other insects. \n\nFrom 1998 to 2006, Environmental Health Perspectives found nearly 3,000 cases of pesticide drift, nearly half were workers on the fields treated with pesticides and 14% of cases were children under the age of 15. \n\nIn 2001, the Environmental Protection Agency published a guidance to “manufacturers, formulators, and registrants of pesticide products\" (EPA 2001) that stated the EPA’s stance against pesticide drift as well as suggested product labeling practices.\n\n\n\n"}
{"id": "733183", "url": "https://en.wikipedia.org/wiki?curid=733183", "title": "Polyacetylene", "text": "Polyacetylene\n\nPolyacetylene (IUPAC name: polyethyne) usually refers to an organic polymer with the repeating unit (CH). The name refers to its conceptual construction from polymerization of acetylene to give a chain with repeating olefin groups. This compound is conceptually important, as the discovery of polyacetylene and its high conductivity upon doping helped to launch the field of organic conductive polymers. The high electrical conductivity discovered by Hideki Shirakawa, Alan Heeger, and Alan MacDiarmid for this polymer led to intense interest in the use of organic compounds in microelectronics (organic semiconductors). This discovery was recognized by the Nobel Prize in Chemistry in 2000. Early work in the field of polyacetylene research was aimed at using doped polymers as easily processable and lightweight \"plastic metals\". Despite the promise of this polymer in the field of conductive polymers, many of its properties such as instability to air and difficulty with processing have led to avoidance in commercial applications.\n\nCompounds called polyacetylenes also occur in nature, although in this context the term refers to polyynes, compounds containing multiple acetylene groups (\"poly\" meaning \"many\"), rather than to chains of olefin groups (\"poly\" meaning \"polymerization of\").\n\nPolyacetylene consists of a long chain of carbon atoms with alternating single and double bonds between them, each with one hydrogen atom. The double bonds can have either \"cis\" or \"trans\" geometry. The controlled synthesis of each isomer of the polymer, \"cis\"-polyacetylene or \"trans\"-polyacetylene, can be achieved by changing the temperature at which the reaction is conducted. The \"cis\" form of the polymer is thermodynamically less stable than the \"trans\" isomer. Despite the conjugated nature of the polyacetylene backbone, not all of the carbon–carbon bonds in the material are equal: a distinct single/double alternation exists. Each hydrogen atom can be replaced by a functional group. Substituted polyacetylenes tend to be more rigid than saturated polymers. Furthermore, placing different functional groups as substituents on the polymer backbone leads to a twisted conformation of the polymer chain to interrupt the conjugation.\n\nCuprene was one of the earliest reported acetylene polymers. Its highly cross-linked nature led to no further studies in the field for quite some time. Linear polyacetylene was first prepared by Giulio Natta in 1958. The resulting polyacetylene was linear, of high molecular weight, displayed high crystallinity, and had a regular structure. X-ray diffraction studies demonstrated that the resulting polyacetylene was \"trans\"-polyacetylene. After this first reported synthesis, few chemists were interested in polyacetylene because the product of Natta’s preparation was an insoluble, air sensitive, and infusible black powder.\n\nThe next major development of polyacetylene polymerization was made by Hideki Shirakawa’s group who were able to prepare silvery films of polyacetylene. They discovered that the polymerization of polyacetylene could be achieved at the surface of a concentrated solution of the catalyst system of EtAl and Ti(OBu) in an inert solvent such as toluene. In parallel with Shirakawa's studies, Alan Heeger and Alan MacDiarmid were studying the metallic properties of polythiazyl [(SN)], a related but inorganic polymer. Polythiazyl caught Heeger's interest as a chain-like metallic material, and he collaborated with Alan MacDiarmid who had previous experience with this material. By the early 1970s, this polymer was known to be superconductive at low temperatures. Shirakawa, Heeger, and MacDiarmid collaborated on further development of polyacetylene.\n\nUpon doping polyacetylene with I, the conductivity increased seven orders of magnitude. Similar results were achieved using Cl and Br. These materials exhibited the largest room temperature conductivity observed for a covalent organic polymer, and this seminal report was key in furthering the development of organic conductive polymers. Further studies led to improved control of the \"cis\"/\"trans\" isomer ratio and demonstrated that \"cis\"-polyacetylene doping led to higher conductivity than doping of \"trans\"-polyacetylene. Doping \"cis\"-polyacetylene with AsF further increased the conductivities, bringing them close to that of copper. Furthermore, it was found that heat treatment of the catalyst used for polymerization led to films with higher conductivities.\n\nA variety of methods have been developed to synthesize polyacetylene, from pure acetylene and other monomers. One of the most common methods uses a Ziegler–Natta catalyst, such as Ti(O\"i\"Pr)/Al(CH), with gaseous acetylene. This method allows control over the structure and properties of the final polymer by varying temperature and catalyst loading. Mechanistic studies suggest that this polymerization involves metal insertion into the triple bond of the monomer. \nBy varying the apparatus and catalyst loading, Shirakawa and coworkers were able to synthesize polyacetylene as thin films, rather than insoluble black powders. They obtained these films by coating the walls of a reaction flask under inert conditions with a solution of the[Ziegler–Natta catalyst and adding gaseous acetylene, resulting in immediate formation of a film. Enkelmann and coworkers further improved polyacetylene synthesis by changing the catalyst to a Co(NO)/NaBH system, which was stable to both oxygen and water.\n\nPolyacetylene can also be produced by radiation polymerization of acetylene. Glow-discharge radiation, γ-radiation, and ultraviolet irradiation have been used. These methods avoid the use of catalysts and solvent, but require low temperatures to produce regular polymers. Gas-phase polymerization typically produces irregular cuprene, whereas liquid-phase polymerization, conducted at −78 °C produces linear \"cis\"-polyacetylene, and solid-phase polymerization, conducted at still lower temperature, produces \"trans\"-polyacetylene.\n\nPolyacetylene can be synthesized by ring-opening metathesis polymerization (ROMP) from cyclooctatetraene, a material easier to handle than the acetylene monomer. This synthetic route also provides a facile method for adding solubilizing groups to the polymer while maintaining the conjugation. Robert Grubbs and coworkers synthesized a variety of polyacetylene derivatives with linear and branched alkyl chains. Polymers with linear groups such as \"n\"-octyl had high conductivity but low solubility, while highly branched \"tert\"-butyl groups increased solubility but decreased conjugation due to polymer twisting to avoid steric crowding. They obtained soluble and conductive polymers with \"sec\"-butyl and neopentyl groups, because the methylene (CH) unit directly connected to the polymer reduces steric crowding and prevents twisting.\n\nPolyacetylene can also be synthesized from precursor polymers. This method enables processing of the polymer before conversion to insoluble polyacetylene. Short, irregular segments of polyacetylene can be obtained by dehydrohalogenation of poly(vinyl chloride).\n\nThermal conversion of precursor polymers is a more effective method for synthesizing long polyacetylene chains. In the Durham-precursor route, polymers are prepared by ring-opening metathesis polymerization, and a subsequent heat-induced reverse Diels–Alder reaction yields the final polymer, as well as a volatile side product.\n\nWhen polyacetylene films are exposed to vapors of electron-accepting compounds (p-type dopants), the electrical conductivity of the material increases by orders of magnitude over the undoped material. p-type dopants include Br, I, Cl, and AsF. These dopants act by abstracting an electron from the polymer chain. The conductivity of these polymers is believed to be a result of the creation of charge-transfer complexes between the polymer and halogen. Charge-transfer occurs from the polymer to the acceptor compound; the polyacetylene chain acts as a cation and the acceptor as an anion. The “hole” on the polymer backbone is weakly associated with the anionic acceptor by Coulomb potential. Polyacetylene doped with (p-type) dopants retain their high conductivity even after exposure to air for several days.\n\nElectron-donating (n-type) dopants can also be used to create conductive polyacetylene. n-Type dopants for polyacetylene include lithium, sodium, and potassium. As with p-type dopants, charge-transfer complexes are created, where the polymer backbone is anionic and the donor is cationic. The increase in conductivity upon treatment with an n-type dopant is not as significant as those achieved upon treatment with a p-type dopant. Polyacetylene chains doped with n-type dopants are extremely sensitive to air and moisture.\n\nThe conductivity of polyacetylene depends on structure and doping. Undoped \"trans\"-polyacetylene films have a conductivity of 4.4×10 Ωcm, while \"cis\"-polyacetylene has a lower conductivity of 1.7×10 Ωcm Doping with bromine causes an increase in conductivity to 0.5 Ωcm, while a higher conductivity of 38 Ωcm is obtained through doping with iodine. Doping of either \"cis\"- or \"trans\"-polyacetylene leads to an increase in their conductivities. Doped \"cis\"-polyacetylene films usually have conductivities two or three times greater than doped \"trans\"-polyacetylene even though the parent film has lower conductivity.\n\nThe structure of polyacetylene films have been examined by both infrared and Raman spectroscopy, and found that structure depends on synthetic conditions. When the synthesis is performed below −78 °C, the \"cis\" form predominates, while above 150 °C the \"trans\" form is favored. At room temperature, the polymerization yields a ratio of 60:40 \"cis\":\"trans\". Films containing the \"cis\" form appear coppery, while the \"trans\" form is silvery. Films of \"cis\"-polyacetylene are very flexible and can be readily stretched, while \"trans\"-polyacetylene is much more brittle. \nThe synthesis and processing of polyacetylene films affects the properties. Increasing the catalyst ratio creates thicker films with a greater draw ratio, allowing them to be stretched further. Lower catalyst loadings leads to the formation of dark red gels, which can be converted to films by cutting and pressing between glass plates. A foam-like material can be obtained from the gel by displacing the solvent with benzene, then freezing and subliming the benzene. Polyacetylene has a bulk density of 0.4 g/cm, while density of the foam is significantly lower, at 0.02–0.04 g/cm. The morphology consists of fibrils, with an average width of 200 Å. These fibrils form an irregular, web-like network, with some cross-linking between chains. The insolubility of polyacetylene makes it difficult to characterize this material and to determine the extent of cross-linking in the material.\n\nFor applications, polyacetylenes suffer from many drawbacks. They are insoluble in solvents, making it essentially impossible to process the material. While both \"cis\" and \"trans\"-polyacetylene show high thermal stability, exposure to air causes a large decrease in the flexibility and conductivity. When polyacetylene is exposed to air, oxidation of the backbone by O occurs. Infrared spectroscopy shows formation of carbonyl groups, epoxides, and peroxides. Coating with polyethylene or wax can slow the oxidation temporarily, while coating with glass increases stability indefinitely.\n\nPolyacetylene has no commercial applications, although the discovery of polyacetylene as a conductive organic polymer led to many developments in materials science. Conducting polymers are of interest for solution-processing for film-forming conductive polymers. Therefore, attention has shifted to other conductive polymers for application purposes including polythiophene and polyaniline.\n\n"}
{"id": "72718", "url": "https://en.wikipedia.org/wiki?curid=72718", "title": "Prototype", "text": "Prototype\n\nA prototype is an early sample, model, or release of a product built to test a concept or process or to act as a thing to be replicated or learned from. It is a term used in a variety of contexts, including semantics, design, electronics, and software programming. A prototype is generally used to evaluate a new design to enhance precision by system analysts and users. Prototyping serves to provide specifications for a real, working system rather than a theoretical one. In some design workflow models, creating a prototype (a process sometimes called materialization) is the step between the formalization and the evaluation of an idea.\n\nThe word \"prototype\" derives from the Greek πρωτότυπον \"prototypon\", \"primitive form\", neutral of πρωτότυπος \"prototypos\", \"original, primitive\", from πρῶτος \"protos\", \"first\" and τύπος \"typos\", \"impression\".\n\nPrototypes explore different aspects of an intended design: \n\nIn general, the creation of prototypes will differ from creation of the final product in some fundamental ways:\n\n\nEngineers and prototype specialists attempt to minimize the impact of these differences on the intended role for the prototype. For example, if a visual prototype is not able to use the same materials as the final product, they will attempt to substitute materials with properties that closely simulate the intended final materials.\n\nEngineers and prototyping specialists seek to understand the limitations of prototypes to exactly simulate the characteristics of their intended design.\n\nIt is important to realize that by their very definition, prototypes will represent some compromise from the final production design. Due to differences in materials, processes and design fidelity, it is possible that a prototype may fail to perform acceptably whereas the production design may have been sound. A counter-intuitive idea is that prototypes may actually perform acceptably whereas the production design may be flawed since prototyping materials and processes may occasionally outperform their production counterparts.\n\nIn general, it can be expected that individual prototype costs will be substantially greater than the final production costs due to inefficiencies in materials and processes. Prototypes are also used to revise the design for the purposes of reducing costs through optimization and refinement.\n\nIt is possible to use prototype testing to reduce the risk that a design may not perform as intended, however prototypes generally cannot eliminate all risk. There are pragmatic and practical limitations to the ability of a prototype to match the intended final performance of the product and some allowances and engineering judgement are often required before moving forward with a production design.\n\nBuilding the full design is often expensive and can be time-consuming, especially when repeated several times—building the full design, figuring out what the problems are and how to solve them, then building another full design. As an alternative, rapid prototyping or rapid application development techniques are used for the initial prototypes, which implement part, but not all, of the complete design. This allows designers and manufacturers to rapidly and inexpensively test the parts of the design that are most likely to have problems, solve those problems, and then build the full design.\n\nThis counter-intuitive idea—that the quickest way to build something is, first to build something else—is shared by scaffolding and the telescope rule.\n\nIn technology research, a technology demonstrator is a prototype serving as proof-of-concept and demonstration model for a new technology or future product, proving its viability and illustrating conceivable applications.\n\nIn large development projects, a testbed is a platform and prototype development environment for rigorous experimentation and testing of new technologies, components, scientific theories and computational tools.\n\nWith recent advances in computer modeling it is becoming practical to eliminate the creation of a physical prototype (except possibly at greatly reduced scales for promotional purposes), instead modeling all aspects of the final product as a computer model. An example of such a development can be seen in Boeing 787 Dreamliner, in which the first full sized physical realization is made on the series production line. Computer modeling is now being extensively used in automotive design, both for form (in the styling and aerodynamics of the vehicle) and in function—especially for improving vehicle crashworthiness and in weight reduction to improve mileage.\n\nThe most common use of the word prototype is a functional, although experimental, version of a non-military machine (e.g., automobiles, domestic appliances, consumer electronics) whose designers would like to have built by mass production means, as opposed to a mockup, which is an inert representation of a machine's appearance, often made of some non-durable substance.\n\nAn electronics designer often builds the first prototype from breadboard or stripboard or perfboard, typically using \"DIP\" packages.\n\nHowever, more and more often the first functional prototype is built on a \"prototype PCB\" almost identical to the production PCB, as PCB manufacturing prices fall and as many components are not available in DIP packages, but only available in SMT packages optimized for placing on a PCB.\n\nBuilders of military machines and aviation prefer the terms \"experimental\" and \"service test\".\n\nIn electronics, prototyping means building an actual circuit to a theoretical design to verify that it works, and to provide a physical platform for debugging it if it does not. The prototype is often constructed using techniques such as wire wrapping or using veroboard or breadboard, with the result being a circuit that is electrically identical to the design but not physically identical to the final product.\n\nOpen-source tools like Fritzing exist to document electronic prototypes (especially the breadboard-based ones) and move toward physical production. Prototyping platforms such as Arduino also simplify the task of programming and interacting with a microcontroller. The developer can choose to deploy their invention as-is using the prototyping platform, or replace it with only the microcontroller chip and the circuitry that is relevant to their product.\n\nA technician can quickly build a prototype (and make additions and modifications) using these techniques, but for volume production it is much faster and usually cheaper to mass-produce custom printed circuit boards than to produce these other kinds of prototype boards. The proliferation of quick-turn PCB fabrication and assembly companies has enabled the concepts of rapid prototyping to be applied to electronic circuit design. It is now possible, even with the smallest passive components and largest fine-pitch packages, to have boards fabricated, assembled, and even tested in a matter of days.\n\nIn many programming languages, a \"function prototype\" is the declaration of a subroutine or function (and should not be confused with software prototyping). This term is rather C/C++-specific; other terms for this notion are \"signature\", \"type\" and \"interface\". In prototype-based programming (a form of object-oriented programming), new objects are produced by cloning existing objects, which are called prototypes.\n\nThe term may also refer to the Prototype Javascript Framework.\n\nAdditionally, the term may refer to the prototype design pattern.\n\nPrototype software is often referred to as alpha grade, meaning it is the first version to run. Often only a few functions are implemented, the primary focus of the alpha is to have a functional base code on to which features may be added. Once alpha grade software has most of the required features integrated into it, it becomes beta software for testing of the entire software and to adjust the program to respond correctly during situations unforeseen during development.\n\nOften the end users may not be able to provide a complete set of application objectives, detailed input, processing, or output requirements in the initial stage. After the user evaluation, another prototype will be built based on feedback from users, and again the cycle returns to customer evaluation. The cycle starts by listening to the user, followed by building or revising a mock-up, and letting the user test the mock-up, then back. There is now a new generation of tools called Application Simulation Software which help quickly simulate application before their development.\n\nExtreme programming uses iterative design to gradually add one feature at a time to the initial prototype.\n\nContinuous learning approaches within organizations or businesses may also use the concept of business or process prototypes through software models.\n\nA \"data prototype\" is a form of \"functional \"or \"working\" prototype. The justification for its creation is usually a data migration, data integration or application implementation project and the raw materials used as input are an instance of all the relevant data which exists at the start of the project.\n\nThe objectives of \"data prototyping\" are to produce: \nTo achieve this, a data architect uses a graphical interface to interactively develop and execute transformation and cleansing rules using raw data. The resultant data is then evaluated and the rules refined. Beyond the obvious visual checking of the data \"on-screen\" by the data architect, the usual evaluation and validation approaches are to use Data profiling software and then to insert the resultant data into a test version of the target application and trial its use.\n\nIn the field of scale modeling (which includes model railroading, vehicle modeling, airplane modeling, military modeling, etc.), a prototype is the real-world basis or source for a scale model—such as the real EMD GP38-2 locomotive—which is the prototype of Athearn's (among other manufacturers) locomotive model. Technically, any non-living object can serve as a prototype for a model, including structures, equipment, and appliances, and so on, but generally prototypes have come to mean full-size real-world vehicles including automobiles (the prototype 1957 Chevy has spawned many models), military equipment (such as M4 Shermans, a favorite among US Military modelers), railroad equipment, motor trucks, motorcycles, and space-ships (real-world such as Apollo/Saturn Vs, or the ISS).\nAs of 2014, basic rapid prototype machines (such as 3D printers) cost about $2,000, but larger and more precise machines can cost as much as $500,000.\n\nIn the science and practice of metrology, a prototype is a human-made object that is used as the standard of measurement of some physical quantity to base all measurement of that physical quantity against. Sometimes this standard object is called an artifact. In the International System of Units (SI), the only prototype remaining in current use is the International Prototype Kilogram, a solid platinum-iridium cylinder kept at the Bureau International des Poids et Mesures (International Bureau of Weights and Measures) in Sèvres France (a suburb of Paris) that by definition is the mass of exactly one kilogram. Copies of this prototype are fashioned and issued to many nations to represent the national standard of the kilogram and are periodically compared to the Paris prototype.\n\nUntil 1960, the meter was defined by a platinum-iridium prototype bar with two scratch marks on it (that were, by definition, spaced apart by one meter), the International Prototype Metre, and in 1983 the meter was redefined to be the distance in free space covered by light in 1/299,792,458 of a second (thus \"defining\" the speed of light to be 299,792,458 meters per second).\n\nIt is widely believed that the kilogram prototype standard will be replaced. There are two likely replacements. One is a definition of the kilogram that will define another physical constant (likely either Planck's constant or the elementary charge) to a defined numerical value, thus obviating the need for the prototype and removing the possibility of the prototype (and thus the standard and definition of the kilogram) changing very slightly over the years because of loss or gain of atoms. The other definition is using a system that finds the amount of force needed to counteract the pull of earth's gravity on a one kilogram artifact.\n\nIn many sciences, from pathology to taxonomy, prototype refers to a disease, species, etc. which sets a good example for the whole category. In Biology, prototype is the ancestral or primitive form of a species or other group; an archetype. For example, the Senegal bichir is regarded as the prototypes of its genus, \"Polypterus\".\n\n"}
{"id": "46193861", "url": "https://en.wikipedia.org/wiki?curid=46193861", "title": "Russia–Ukraine barrier", "text": "Russia–Ukraine barrier\n\nRussia–Ukraine barrier, also known as Ukrainian Wall or European Wall, or as Project Wall in Ukraine is a fortified border barrier currently under construction by Ukraine on the Russia–Ukraine border. The aim of the project, according to Ukraine, is preventing Russian military intervention in Ukraine and to assist with obtaining visa-free travel with the European Union. The former Prime Minister of Ukraine Arseniy Yatsenyuk presented this project on 3 September 2014. On 12 September 2014, the Cabinet of Ministers of Ukraine has allocated 100 million hryvnia for the construction of fortifications on the border with Russia and on the border with Crimea. On 18 March 2015, the Ukrainian government allocated 865 million hryvnia to build fortifications on the border between Ukraine and Russia.\n\nFollowing the 2014–15 Russian military intervention in Ukraine, in June 2014, Ukrainian politician and business magnate Ihor Kolomoyskyi suggested that Ukraine should build a wall along the border with Russia. On 3 September 2014 Ukrainian Prime Minister Arseniy Yatsenyuk announced Ukraine would strengthen its border with Russia and called this \"Project Wall\". The command of Ukraine's anti-terrorist forces stated that \"Two defense lines have been planned, and their main goal is to prevent the infiltration by the adversary into the territory of Ukraine\". According to Yatsenyuk the project was needed \"to cut off Russian support for insurgents in eastern regions\" and also to obtain a visa-free regime with the European Union for Ukraine. It is also an employment project. Project \"Wall\" was officially started on 10 September 2014. \n\nOn September 12, 2014 The Cabinet of Ministers of Ukraine allocated 100 million hryvnia for the construction of fortifications on the border with Russia and on the border with Crimea. On 18 March 2015, the Ukrainian government allocated 865 million hryvnia to build fortifications on the border between Ukraine and Russia. On 10 April 2015, Poland allocated a loan of $100 million for the modernization of the energy sector and improvement of external borders of Ukraine. \n\nAs of May 2015, a walled defense system was under construction along the Russian border in Kharkiv Oblast. The project is planned to be finished in 2018.\n\nOn 20 August 2015, it was announced that Ukraine has completed 10% of the fortification line, stating that roughly 180 km of anti-tank ditches had been dug, 40 km of barbed wire fence and 500 fortification obstacles had been erected. 139 million hryvnia out of 300 million allocated has been used for construction of the wall at this point, and that another 460 million hryvnia were budgeted for 2016.\n\nIn August 2017 it became public that large amounts of the money intended to pay for the Wall project were misused and even stolen. The National Anti-Corruption Bureau (NABU) announced the arrest of several individuals involved in the building of the fortified border.\n\n"}
{"id": "294216", "url": "https://en.wikipedia.org/wiki?curid=294216", "title": "SWOT analysis", "text": "SWOT analysis\n\nSWOT analysis (or SWOT matrix) is a strategic planning technique used to help a person or organization identify strengths, weaknesses, opportunities, and threats related to business competition or project planning. It is intended to specify the objectives of the business venture or project and identify the internal and external factors that are favorable and unfavorable to achieving those objectives. Users of a SWOT analysis often ask and answer questions to generate meaningful information for each category to make the tool useful and identify their competitive advantage. SWOT has been described as the tried-and-true tool of strategic analysis. \n\nStrengths and weakness are frequently internally-related, while opportunities and threats commonly focus on the external environment. The name is an acronym for the four parameters the technique examines:\nThe degree to which the internal environment of the firm matches with the external environment is expressed by the concept of strategic fit. Identification of SWOTs is important because they can inform later steps in planning to achieve the objective. First, decision-makers should consider whether the objective is attainable, given the SWOTs. If the objective is \"not\" attainable, they must select a different objective and repeat the process.\n\nSome authors credit SWOT to Albert Humphrey, who led a convention at the Stanford Research Institute (now SRI International) in the 1960s and 1970s using data from Fortune 500 companies. However, Humphrey himself did not claim the creation of SWOT, and the origins remain obscure.\n\nSWOT analysis aims to identify the key internal and external factors seen as important to achieving an objective. SWOT analysis groups key pieces of information into two main categories:\n\n\nAnalysis may view the internal factors as strengths or as weaknesses depending upon their effect on the organization's objectives. What may represent strengths with respect to one objective may be weaknesses (distractions, competition) for another objective. The factors may include all of the 4Ps as well as personnel, finance, manufacturing capabilities, and so on.\n\nThe external factors may include macroeconomic matters, technological change, legislation, and sociocultural changes, as well as changes in the marketplace or in competitive position. The results are often presented in the form of a matrix.\n\nSWOT analysis is just one method of categorization and has its own weaknesses. For example, it may tend to persuade its users to compile lists rather than to think about actual important factors in achieving objectives. It also presents the resulting lists uncritically and without clear prioritization so that, for example, weak opportunities may appear to balance strong threats.\n\nIt is prudent not to eliminate any candidate SWOT entry too quickly. The importance of individual SWOTs will be revealed by the value of the strategies they generate. A SWOT item that produces valuable strategies is important. A SWOT item that generates no strategies is not important.\n\nThe usefulness of SWOT analysis is not limited to profit-seeking organizations. SWOT analysis may be used in any decision-making situation when a desired end-state (objective) is defined. Examples include non-profit organizations, governmental units, and individuals. SWOT analysis may also be used in pre-crisis planning and preventive crisis management. SWOT analysis may also be used in creating a recommendation during a viability study/survey.\n\nSWOT analysis can be used effectively to build organizational or personal strategy. Steps necessary to execute strategy-oriented analysis involve identification of internal and external factors (using the popular 2x2 matrix), selection and evaluation of the most important factors, and identification of relations existing between internal and external features.\n\nFor instance, strong relations between strengths and opportunities can suggest good conditions in the company and allow using an \"aggressive\" strategy. On the other hand, strong interactions between weaknesses and threats could be analyzed as a potential warning and advice for using a \"defensive\" strategy.\n\nOne way of using SWOT is matching and converting. Matching is used to find competitive advantage by matching the strengths to opportunities. Another tactic is to convert weaknesses or threats into strengths or opportunities. An example of a conversion strategy is to find new markets. If the threats or weaknesses cannot be converted, a company should try to minimize or avoid them.\n\nAs part of the development of strategies and plans to enable the organization to achieve its objectives, that organization will use a systematic/rigorous process known as corporate planning. SWOT alongside PEST/PESTLE can be used as a basis for the analysis of business and environmental factors.\n\nIn many competitor analysis, marketers build detailed profiles of each competitor in the market, focusing especially on their relative competitive strengths and weaknesses using SWOT analysis. Marketing managers will examine each competitor's cost structure, sources of profits, resources and competencies, competitive positioning and product differentiation, degree of vertical integration, historical responses to industry developments, and other factors.\n\nMarketing management often finds it necessary to invest in research to collect the data required to perform accurate marketing analysis. Accordingly, management often conducts market research (alternately marketing research) to obtain this information. Marketers employ a variety of techniques to conduct market research, but some of the more common include:\n\nBelow is an example SWOT analysis of a market position of a small management consultancy with specialism in HRM.\n\nThe SWOT analysis has been used in community work as a tool to identify positive and negative factors within organizations, communities, and the broader society that promote or inhibit successful implementation of social services and social change efforts. It is used as a preliminary resource, assessing strengths, weaknesses, opportunities, and threats in a community served by a nonprofit or community organization. This organizing tool is best used in collaboration with community workers and/or community members before developing goals and objectives for a program design or implementing an organizing strategy. The SWOT analysis is a part of the planning for social change process and will not provide a strategic plan if used by itself. After a SWOT analysis is completed, a social change organization can turn the SWOT list into a series of recommendations to consider before developing a strategic plan.\n\nStrengths and weaknesses (\"internal factors within an organization\"):\n\nOpportunities and threats (\"external factors stemming from community or societal forces\"):\n\nAlthough the SWOT analysis was originally designed as an organizational method for business and industries, it has been replicated in various community work as a tool for identifying external and internal support to combat internal and external opposition. The SWOT analysis is necessary to provide direction to the next stages of the change process. It has been used by community organizers and community members to further social justice in the context of Social Work practice.\n\nAs mentioned above, SWOT can be crucial to determining the success of a project, while factoring in funding, as well as accessibility and logic. Often, a city will spend a year weighing the Risk-benefits of a project before they even vote on it.\nElements to consider in a SWOT analysis include understanding the community that a particular organization is working with. This can be done via public forums, listening campaigns, and informational interviews. Data collection will help inform the community members and workers when developing the SWOT analysis. A needs and assets assessment is tooling that can be used to identify the needs and existing resources of the community. When these assessments are done and data has been collected, an analysis of the community can be made that informs the SWOT analysis.\n\nA SWOT analysis is best developed in a group setting such as a work or community meeting. A facilitator can conduct the meeting by first explaining what a SWOT analysis is as well as identifying the meaning of each term.\n\nOne way of facilitating the development of a SWOT analysis includes developing an example SWOT with the larger group then separating each group into smaller teams to present to the larger group after set amount of time. This allows for individuals, who may be silenced in a larger group setting, to contribute. Once the allotted time is up, the facilitator may record all the factors of each group onto a large document such as a poster board, and then the large group, as a collective, can go work through each of the threats and weaknesses to explore options that may be used to combat negative forces with the strengths and opportunities present within the organization and community. A SWOT meeting allows participants to creatively brainstorm, identify obstacles, and possibly strategize solutions/way forward to these limitations.\n\nThe uses of a SWOT analysis by a community organization are as follows: to organize information, provide insight into barriers that may be present while engaging in social change processes, and identify strengths available that can be activated to counteract these barriers.\n\n\"A SWOT analysis can be used to:\"\n\nThe SWOT analysis in social work practice framework is beneficial because it helps organizations decide whether or not an objective is obtainable and therefore enables organizations to set achievable goals, objectives, and steps to further the social change or community development effort. It enables organizers to take visions and produce practical and efficient outcomes that effect long-lasting change, and it helps organizations gather meaningful information to maximize their potential. Completing a SWOT analysis is a useful process regarding the consideration of key organizational priorities, such as gender and cultural diversity and fundraising objectives.\n\nSome findings from Menon et al. (1999) and Hill and Westbrook (1997) have suggested that SWOT may harm performance and that \"no-one subsequently used the outputs within the later stages of the strategy\". \n\nOther critiques include the misuse of the SWOT analysis as a technique that can be quickly designed without critical thought leading to a misrepresentation of strengths, weaknesses, opportunities, and threats within an organization's internal and external surroundings. If a firm becomes preoccupied with a single strength, such as cost control, they can neglect their weaknesses, such as product quality.\n\nAnother limitation includes the development of a SWOT analysis simply to defend previously decided goals and objectives. This misuse leads to limitations on brainstorming possibilities and \"real\" identification of barriers. This misuse also places the organization’s interest above the well-being of the community. Further, a SWOT analysis should be developed as a collaborative with a variety of contributions made by participants including community members. The design of a SWOT analysis by one or two community workers is limiting to the realities of the forces, specifically external factors, and devalues the possible contributions of community members.\n\nOverall, managers should remember that SWOT is a starting point for discussion and cannot, in itself, show managers how to achieve a competitive advantage. Because the SWOT analysis is a snapshot of the firm at a particular moment in time, the analysis might obscure the fact that both the internal and external environment are rapidly changing.\n\nIn project management, the alternative to SWOT known by the acronym SVOR (Strengths, Vulnerabilities, Opportunities, and Risks) compares the project elements along two axes: internal and external, and positive and negative. It takes into account the mathematical link that exists between these various elements, considering also the role of infrastructures. The SVOR table provides an intricate understanding of the elements at play in a given project:\nConstraints consist of: calendar of tasks and activities, costs, and norms of quality. The \"k\" constant varies with each project (for example, it may be valued at 1.3).\n\nMany reports have been published about the use of SWOT by real life companies, and how the idea is spreading. Coca-Cola has used this in their television ads in order to effectively target a customer, such as appeal to senses.\n\nIn the \"Silicon Valley\" episode \"Homicide\" (Season 2, Episode 6), Jared Dunn (Zach Woods) introduces the Pied Piper team to SWOT analysis. Later in that episode Dinesh (Kumail Nanjiani) and Gilfoyle (Martin Starr) employ the method when deciding whether or not to inform a stunt driver that the calculations for his upcoming jump were performed incorrectly.\n\n"}
{"id": "32305607", "url": "https://en.wikipedia.org/wiki?curid=32305607", "title": "Security Now", "text": "Security Now\n\nSecurity Now! is a weekly podcast hosted by Steve Gibson and Leo Laporte. It was the second show to premiere on the TWiT Network, launching in summer 2005. The first episode, “As the Worm Turns”, was released on August 19, 2005.\n\n\"Security Now!\" consists of a discussion between Gibson and Laporte on issues of computer security and, conversely, insecurity. Covered topics have included security vulnerabilities, firewalls, password security, spyware, rootkits, Wi-Fi, virtual private networks, and virtual machines.\n\n\"Security Now!\" is distributed via its main podcast RSS feed and on the GRC \"Security Now!\" page. In addition to audio, text transcriptions are published, along with Gibson distributing a low-bandwidth 16 kbit/s version of the show on his own for those with low-bandwidth sources such as satellite internet or dial-up.\n\nThe podcast runs for approximately two hours, typically starting with security news. Then Gibson reads a testimonial for his software SpinRite. The remainder of the show is spent on a particular theme. During the show some advertisements for 3rd party commercial products or services are read out, by co-host Leo Laporte.\n\nBi-weekly \"Mailbag\" episodes answer questions and respond to feedback submitted by listeners.\n\nIn August 2007, \"Security Now!\" won in the People's Choice Podcast Awards Technology/Science category. In August 2006, \"Security Now!\" ranked fourth in the \"Top 40\" of all podcasts listened to via the PodNova service. \"Security Now!\" averaged around 100,000 downloads per episode throughout 2006. \nAt the end of 2015, Security Now was number 4 on the Top 40 US Technology Podcasts, making it the highest weekly Twit.tv podcast.\n\nIn January 2006 Steve Gibson accused Microsoft of intentionally putting a backdoor into the Windows Metafile processing code in Windows 2000 and Windows XP. Gibson claimed that while reverse engineering the Windows Metafile format, he could run arbitrary code by using a \"nonsensical\" value in the metafile, and concluded Microsoft had intentionally designed Windows this way so it could run code on Windows computers without the user's knowledge. Microsoft's Stephen Toulouse responded in a Microsoft Security Response Center blog post the next day, saying the behavior was not intentional.\n\n"}
{"id": "4181933", "url": "https://en.wikipedia.org/wiki?curid=4181933", "title": "Standing order (banking)", "text": "Standing order (banking)\n\nA standing order (or a standing instruction) is an instruction a bank account holder (\"the payer\") gives to his or her bank to pay a set amount at regular intervals to another's (\"the payee's\") account. The instruction is sometimes known as a banker's order.\n\nThey are typically used to pay rent, mortgage or any other fixed regular payments. Because the amounts paid are fixed, a standing order is not usually suitable for paying variable bills such as credit cards or gas and electricity bills.\n\nStanding orders are available in the banking systems of a number of countries, including Germany, Bulgaria, the United Kingdom, Barbados, Ireland, India, Netherlands, Russia, Pakistan, Malaysia, Ukraine and presumably many others. In the United States, and other countries where cheques are more popular than bank transfers, a similar service is available, in which the bank automatically mails a cheque to the specified payee.\n\nA standing order (\"Dauerauftrag\") can run for a set number of payments, a set period of time, or until cancelled.\n\nStanding orders \"(periodieke overschrijvingen)\" are available for a set period of time or until cancelled, to any recipient in the SEPA space. They should not be confused with \"doorlopende machtigingen\" (periodic direct debits).\nAlle banken van NL\n\nA standing order \"(口座自動振替)\" runs until cancelled. They can be cancelled at the account holder's request\n\nA standing order \"(납부자자동이체)\" runs until cancelled. They can be cancelled at the account holder's request. The bank charges fees (average 3000KRW) per transfer.\n\nA standing order (\"adeudo por domiciliación\") can be set up to run for a set period of time, not indefinitely. They can be cancelled at the account holder's request.\n\nIn Switzerland standing orders are available for a set period of time or until cancelled. They can be made to any recipient in the SEPA space.\n\nA standing order can be set up to run for a set period of time, or indefinitely, and can be cancelled at the account holder's request. Standing orders are standardized by the trade body UK Payments Administration. In 2008 a number of banks began to introduce Faster Payments as the method of transfer for standing orders when available, in place of the slower BACS system; with this method payments reach the receiving account the same day, rather than after a delay of three days or more.\n\nStanding orders are distinct from direct debits; both are methods of setting up repeated transfers of money from one account to another, but they operate in different ways. The fundamental difference is that standing orders send payments arranged by the \"payer,\" while direct debits are specified and collected by the \"payee\". \n\n\n"}
{"id": "14871309", "url": "https://en.wikipedia.org/wiki?curid=14871309", "title": "TRESemmé", "text": "TRESemmé\n\nTRESemmé is an American multi-national brand of hair care products first manufactured in 1947 by the Godefroy Manufacturing Company in St. Louis, Missouri, United States. It was named after the renowned hair care expert Edna L. Emme. The brand name is a phonetic respelling of \"well-loved\" () that cleverly includes the surname of its namesake.\n\nThe TRESemmé product line was initially marketed only to beauty salons. The TRESemmé brand was purchased by Alberto-Culver in 1968, a company acquired by Unilever in 2010.\nThe TRESemmé brand was launched in 1947 by Godefroy Manufacturing, and was bought in 1968 by Alberto-Culver, a manufacturer of hair and skincare products. The original intention was to only distribute the products of the brand within beauty salons; however, as the product line became more popular, it was marketed to supermarkets and pharmacies.\n\nIn 2010, Alberto-Culver was then bought by Unilever, an Anglo–Dutch multinational consumer goods company. At that time, the product line was further developed and more products were added.\n\nTRESemmé creates formulas suited for different types of hair. TRESemmé products include: shampoos & conditioners, dry shampoos, mousse, gels, hair sprays, \"crème & milk\", and other styling sprays. TRESemmé's products are used in hair salons across the United States, Canada, the United Kingdom and Asia, particularly for \"hair repair treatment\" from heat damage caused by hair ironing and blowdrying.\n\n, a software tool called \"PROfiler\" on the TRESemmé website allowed consumers to find the right products for their hair. , the tool was no longer available.\n\nThe brand spent an estimated US$17 million on advertising in 2004. , advertisement campaigns included one promoted under \"Professional, Affordable\".\n\nTRESemmé was the official hair care sponsor of the Mercedes-Benz Fashion Week 2014 in New York in February, and had been since 2006.\n\nTRESemmé created a team called \"Runway Insiders\" that included American model and DJ Harley Viera-Newton, who gave women a personal point-of-view of the latest trends and how they could achieve various professional looks at home.\n\nAwards won by the TRESemmé brand include:\n\n\n"}
{"id": "28658647", "url": "https://en.wikipedia.org/wiki?curid=28658647", "title": "Telex", "text": "Telex\n\nThe telex network was a public switched network of teleprinters similar to a telephone network, for the purposes of sending text-based messages. Telex was a major method of sending written messages electronically between businesses in the post-World War II period. Its usage went into decline as the fax machine grew in popularity in the 1980s.\n\nThe \"telex\" term refers to the network, not the teleprinters; point-to-point teleprinter systems had been in use long before telex exchanges were built in the 1930s. Teleprinters evolved from telegraph systems, and, like the telegraph, they used binary signals, which means that symbols were represented by the presence or absence of a pre-defined level of electric current. This is significantly different from the analog telephone system, which used varying voltages to encode frequency information. For this reason, telex exchanges were entirely separate from the telephone system, with their own signalling standards, exchanges and system of \"telex numbers\" (the counterpart of telephone numbers).\n\nTelex provided the first common medium for international record communications using standard signalling techniques and operating criteria as specified by the International Telecommunication Union. Customers on any telex exchange could deliver messages to any other, around the world. To lower line usage, telex messages were normally first encoded onto paper tape and then read into the line as quickly as possible. The system normally delivered information at 50 baud or approximately 66 words per minute, encoded using the International Telegraph Alphabet No. 2. In the last days of the telex networks, end-user equipment was often replaced by modems and phone lines, reducing the telex network to what was effectively a directory service running on the phone network.\n\nTelex began in Germany as a research and development program in 1926 that became an operational teleprinter service in 1933. The service, operated by the (Reich postal service)\nhad a speed of 50 baud — approximately 66 words per minute.\n\nTelex service spread within Europe and (particularly after 1945) around the world.\nBy 1978, West Germany, including West Berlin, had 123,298 telex connections. Long before automatic telephony became available, most countries, even in central Africa and Asia, had at least a few high-frequency (shortwave) telex links. Often, government postal and telegraph services (PTTs) initiated these radio links. The most common radio standard, CCITT R.44 had error-corrected retransmitting time-division multiplexing of radio channels. Most impoverished PTTs operated their telex-on-radio (TOR) channels non-stop, to get the maximum value from them.\n\nThe cost of TOR equipment has continued to fall. Although the system initially required specialised equipment, many amateur radio operators operate TOR (also known as RTTY) with special software and inexpensive hardware to adapt computer sound cards to short-wave radios.\n\nModern cablegrams or \"telegrams\" actually operate over dedicated telex networks, using TOR whenever required.\n\nTelex served as the forerunner of modern fax, email, and text messaging — both technically and stylistically. Abbreviated English (like \"CU L8R\" for \"see you later\") as used in texting originated with telex operators exchanging informal messages in real time — they became the first \"texters\" long before the introduction of mobile phones. Telex users could send the same message to several places around the world at the same time, like email today, using the Western Union InfoMaster Computer. This involved transmitting the message via paper tape to the InfoMaster Computer (dial code 6111) and specifying the destination addresses for the single text. In this way, a single message could be sent to multiple distant Telex and TWX machines as well as delivering the same message to non-Telex and non-TWX subscribers via Western Union Mailgram.\n\nTelex messages are routed by addressing them to a telex address, e.g., \"14910 ERIC S\", where 14910 is the subscriber number, ERIC is an abbreviation for the subscriber's name (in this case Telefonaktiebolaget L.M. Ericsson in Sweden) and S is the country code. Solutions also exist for the automatic routing of messages to different telex terminals within a subscriber organization, by using different terminal identities, e.g., \"+T148\".\n\nA major advantage of telex is that the receipt of the message by the recipient could be confirmed with a high degree of certainty by the \"answerback\". At the beginning of the message, the sender would transmit a WRU (Who aRe yoU) code, and the recipient machine would automatically initiate a response which was usually encoded in a rotating drum with pegs, much like a music box. The position of the pegs sent an unambiguous identifying code to the sender, so the sender could verify connection to the correct recipient. The WRU code would also be sent at the end of the message, so a correct response would confirm that the connection had remained unbroken during the message transmission. This gave telex a major advantage over group 2 fax which had no inherent error-checking capability.\n\nThe usual method of operation was that the message would be prepared off-line, using paper tape. All common telex machines incorporated a 5-hole paper-tape punch and reader. Once the paper tape had been prepared, the message could be transmitted in minimum time. Telex billing was always by connected duration, so minimizing the connected time saved money. However, it was also possible to connect in \"real time\", where the sender and the recipient could both type on the keyboard and these characters would be immediately printed on the distant machine.\n\nTelex could also be used as a rudimentary but functional carrier of information from one IT system to another, in effect a primitive forerunner of Electronic Data Interchange. The sending IT system would create an output (e.g., an inventory list) on paper tape using a mutually agreed format. The tape would be sent by telex and collected on a corresponding paper tape by the receiver and this tape could then be read into the receiving IT system.\n\nOne use of telex circuits, in use until the widescale adoption of X.400 and Internet email, was to facilitate a message handling system, allowing local email systems to exchange messages with other email and telex systems via a central routing operation, or switch. One of the largest such switches was operated by Royal Dutch Shell as recently as 1994, permitting the exchange of messages between a number of IBM Officevision, Digital Equipment Corporation ALL-IN-1 and Microsoft Mail systems. In addition to permitting email to be sent to telex, formal coding conventions adopted in the composition of telex messages enabled automatic routing of telexes to email recipients.\n\nThe Teletypewriter Exchange Service (TWX) was developed by the AT&T Corporation in the United States. It originally transmitted at 45.45 baud or approximately 60 words per minute, using five level Baudot code. AT&T began TWX on November 21, 1931. AT&T later developed a second generation of TWX called \"four row\" that used the 110 baud, using eight level ASCII code. TWX was offered in both \"3-row\" Baudot and \"4-row\" ASCII versions up to the late 1970s.\n\nTWX used the public switched telephone network. In addition to having separate area codes (510, 610, 710, 810 and 910) for the TWX service, the TWX lines were also set up with a special Class of Service to prevent connections from POTS to TWX and vice versa.\n\nThe code/speed conversion between \"3-row\" Baudot and \"4-row\" ASCII TWX service was accomplished using a special Bell \"10A/B board\" via a live operator. A TWX customer would place a call to the 10A/B board operator for Baudot – ASCII calls, ASCII – Baudot calls and also TWX Conference calls. The code / speed conversion was done by a Western Electric unit that provided this capability. There were multiple code / speed conversion units at each operator position.\n\nAT&T published the trade magazine \"TWX\", related to the Teletypewriter Exchange Service from 1944 to 1952. It published articles that touched upon many aspects of the technology.\n\nWestern Union purchased the TWX system from AT&T in January 1969. The TWX system and the special US area codes (510, 710, 810 and 910) continued until 1981, when Western Union completed the conversion to the Western Union Telex II system. Any remaining \"3-row\" Baudot customers were converted to Western Union Telex service during the period 1979 to 1981. Bell Canada retained area code 610 until 1992; its remaining numbers were moved to non-geographic area code 600.\n\nThe modem for this service was the Bell 101 dataset, which is the direct ancestor of the Bell 103 modem that launched computer time-sharing. The 101 was revolutionary because it ran on ordinary unconditioned telephone subscriber lines, allowing the Bell System to run TWX along with POTS on a single public switched telephone network.\n\n\"Telex II\" was the name for the TWX network after it was acquired from AT&T by Western Union. It was re-acquired by AT&T in 1990 in the purchase of the Western Union assets that became AT&T EasyLink Services.\n\nIn 1958, Western Union started to build a telex network in the United States. This telex network started as a satellite exchange located in New York City and expanded to a nationwide network. Western Union chose Siemens & Halske AG, now Siemens AG, and ITT to supply the exchange equipment, provisioned the exchange trunks via the Western Union national microwave system and leased the exchange to customer site facilities from the local telephone company. Teleprinter equipment was originally provided by Siemens & Halske AG and later by Teletype Corporation. Initial direct international telex service was offered by Western Union, via W.U. International, in the summer of 1960 with limited service to London and Paris. In 1962, the major exchanges were located in New York City (1), Chicago (2), San Francisco (3), Kansas City (4) and Atlanta (5). The telex network expanded by adding the final parent exchanges cities of Los Angeles (6), Dallas (7), Philadelphia (8) and Boston (9) starting in 1966.\n\nThe telex numbering plan, usually a six-digit number in the United States, was based on the major exchange where the customer's telex machine terminated. For example, all telex customers that terminated in the New York City exchange were assigned a telex number that started with a first digit \"1\". Further, all Chicago-based customers had telex numbers that started with a first digit of \"2\". This numbering plan was maintained by Western Union as the telex exchanges proliferated to smaller cities in the United States. The Western Union Telex network was built on three levels of exchanges. The highest level was made up of the nine exchange cities previously mentioned. Each of these cities had the dual capability of terminating telex customer lines and setting up trunk connections to multiple distant telex exchanges. The second level of exchanges, located in large cities such as Buffalo, Cleveland, Miami, Newark, Pittsburgh and Seattle, were similar to the highest level of exchanges in capability of terminating telex customer lines and setting up trunk connections. However, these second level exchanges had a smaller customer line capacity and only had trunk circuits connected to regional cities. The third level of exchanges, located in small to medium-sized cities, could terminate telex customer lines and had a single trunk group running to its parent exchange.\n\nLoop signaling was offered in two different configurations for Western Union Telex in the United States. The first option, sometimes called local or loop service, provided a 60 milliampere loop circuit from the exchange to the customer teleprinter. The second option, sometimes called long distance or polar was used when a 60 milliampere connection could not be achieved, provided a ground return polar circuit using 35 milliamperes on separate send and receive wires. By the 1970s, under pressure from the Bell operating companies wanting to modernize their cable plant and lower the adjacent circuit noise that these telex circuits sometimes caused, Western Union migrated customers to a third option called F1F2. This F1F2 option replaced the DC voltage of the local and long distance options with modems at the exchange and subscriber ends of the telex circuit.\n\nWestern Union offered connections from Telex to the AT&T Teletypewriter eXchange (TWX) system in May 1966 via its New York Information Services Computer Center. These connections were limited to those TWX machines that were equipped with automatic answerback capability per CCITT standard.\n\nUSA based Telex users could send the same message to several places around the world at the same time, like email today, using the Western Union InfoMaster Computer. This involved transmitting the message via paper tape to the InfoMaster Computer (dial code 6111) and specifying the destination addresses for the single text. In this way, a single message could be sent to multiple distant Telex and TWX machines as well as delivering the same message to non-Telex and non-TWX subscribers via Western Union Mailgram.\n\n\"International Record Carrier\" (IRC) was a term created by the Federal Communications Commission (FCC) in the United States. Bell's original consent agreement limited it to international dial telephony, and the Western Union Telegraph Company had given up its international telegraphic operation in a 1939 bid to monopolize U.S. telegraphy by taking over ITT's Postal, telegraph and telephone service (PTT) business. The result was a de-emphasis on telex in the U.S. and the creation of several international telex and telegraphy companies, collectively called IRCs:\n\n\nBell Telex users had to select which IRC to use, and then append the necessary routing digits. The IRCs converted between TWX and Western Union Telegraph Co. standards.\n\nTelex began in the UK as an evolution from the 1930s Telex Printergram service, appearing in 1932 on a limited basis. This used the telephone network in conjunction with a Teleprinter 7B and signalling equipment to send a message to another subscriber with a Teleprinter, or to the Central Telegraph Office.\n\nIn 1945 as the traffic increased it was decided to have a separate network for Telex traffic and the first manual exchange opened in London. By 1954, the public inland Telex service opened via manually switched exchanges. A number of subscribers were served via automatic sub-centres which used relays and Type 2 uniselectors, acting as concentrators for a manual exchange.\n\nIn the late 1950s the decision was made to convert to automatic switching and this was completed by 1961; there were 21 exchanges spread across the country, with one international exchange in London. The equipment used the Strowger system for switching, as was the case for the telephone network. Conversion to Stored Programme Control (SPC) began in 1984 using exchanges made by Canadian Marconi, with the last Strowger exchange closing in 1992. User numbers increased over the following years into the 1990s.\n\nThe dominant supplier of the Telex machines was Creed, a division of ITT.\n\nA separate service \"Secure Stream 300\" (previously Circuit Switched Data Network) was a variant of Telex running at 300 baud, used for telemetry and monitoring purposes by utility companies and banks, among others. This was a high security virtual private wire system with a high degree of resilience through diversely routed dual-path network configurations.\n\nBritish Telecom stopped offering the Telex service to new customers in 2004 and discontinued the service in 2008, allowing users to transfer to Swiss Telex if they wished to continue to use Telex.\n\nCanada-wide automatic teleprinter exchange service was introduced by the CPR Telegraph Company and CN Telegraph in July 1957 (the two companies, operated by rivals Canadian National Railway and Canadian Pacific Railway, would join to form CNCP Telecommunications in 1967). This service supplemented the existing international telex service that was put in place in November 1956. Canadian telex customers could connect with nineteen European countries in addition to eighteen Latin American, African, and trans-Pacific countries. The major exchanges were located in Montreal (01), Toronto (02), and Winnipeg (03).\n\nTelex is still in operation but not in the sense described in the CCITT Blue Book documentation. iTelegram offers \"telex\" without subscriber telex lines. Individual subscribers can use Deskmail, a legacy Windows program that connects to the iTelegram telex network but this is via IP as the last mile. Telex has been mostly superseded by fax, email, and SWIFT, although radiotelex, telex via HF radio, is still used in the maritime industry and is a required element of the Global Maritime Distress and Safety System.\n\nSee for current status in different countries.\n"}
{"id": "41786", "url": "https://en.wikipedia.org/wiki?curid=41786", "title": "Terminal equipment", "text": "Terminal equipment\n\nIn telecommunication, the term terminal equipment has the following meanings:\n\n\n"}
{"id": "36969100", "url": "https://en.wikipedia.org/wiki?curid=36969100", "title": "Test equipment", "text": "Test equipment\n\nTest equipment is a general term describing equipment used in many fields. Types of test equipment include:\n\n\nElectronic test equipment is used to create signals and capture responses from electronic devices, to prove proper operation or trace faults. Types of electronic test equipment include:\n\n"}
{"id": "12037783", "url": "https://en.wikipedia.org/wiki?curid=12037783", "title": "The Semantic Turn", "text": "The Semantic Turn\n\nThe semantic turn refers to a paradigm shift in the design of artifacts – industrial, graphic, informational, architectural, and social – from an emphasis on how artifacts ought to function to what they mean to those affected by them – semantics being a concern for meaning. It provides a new foundation for professional design, a detailed design discourse, codifications of proven methods, compelling scientific justifications of its products, and a clear identity for professional designers working within a network of their stakeholders.\n\nThe semantic turn suggests a distinction between the technical and user-irrelevant working of artifacts and the human interactions with artifacts, individually, socially, and culturally. Attending to the technical dimension of artifacts, for example, by applied scientists, mechanical or electronic engineers, and experts in economics, production, and marketing, is called technology-centered design. It addresses its subject matter in terms that ordinary users may not understand and applies design criteria users of technology do not care about. Attending to the meanings that users bring to their artifacts, how they use them and talk about them and among various stakeholders, is the domain of human-centered design. For ordinary users, the makeup and technical functioning of artifacts is mere background of what really matters to them.\n\nA prime example for this distinction is the design of personal computers. For most people, the operations inside a computer are incomprehensible, but far from troubling because computers are designed to be experienced primarily through their interfaces. Human-computer interfaces consist of interactively rearrangeable icons, texts, and controls that users can understand in everyday terms and manipulate towards desirable ends. The design of intelligent artifacts suggests that the old adage of “form follows function” is no longer valid – except for the simplest of tools. The semantic turn suggests that human-centered designers’ unique expertise resides in the design of human interfaces with artifacts that are meaningful, easy to use, even enjoyable to experience, be it simple kitchen implements, public service systems, architectural spaces, or information campaigns. Although an automobile should obviously function as a means of transportation, human-centered designers emphasize the experiences of driving, ease of operation, feeling of safety, including the social meanings of driving a particular automobile. As artifacts have to work within many dimensions, human-centered designers must have a sense of and be able to work with all relevant stakeholders addressing different dimensions of the artifact.\n\nThe Semantic Turn is also the title of a book by Klaus Krippendorff, Professor of Communication at the University of Pennsylvania, cybernetician, degreed designer, and researcher who has published much to advance the science for design. The subtitle of the book, \"A new Foundation for Design\", suggests a redesign of design practices in a human-centered design culture. Krippendorff takes an encompassing view of design, centering it on the meanings that artifacts acquire and what is or should be designers' primary concern.\n\n\"The Semantic Turn\" represents an evolution from \"Product Semantics\" by Krippendorff and Butter, which was defined as \"A systematic inquiry into how people attribute meanings to artifacts and interact with them accordingly\" and \"a vocabulary and methodology for designing artifacts in view of the meanings they could acquire for their users and the communities of their stakeholders\". While retaining the emphasis on meaning and on the importance of both theory and practice, \"The Semantic Turn\" extends the concerns of designers first to the new challenges of design, including the design of ever more intangible artifacts such as services, identities, interfaces, multi-user systems, projects and discourses; and second, to consider the meaning of artifacts in use, in language, in the whole life cycle of the artifact, and in an ecology of artifacts.\n\nFor Krippendorff, design \"brings forth what would not come naturally (...); proposes realizable artifacts to others (...) must support the lives of ideally large communities (...) and must make sense to most, ideally to all who have a stake on them\". Design thus is intimatelly involved with the meaning that stakeholders attribute to artifacts. Designers \"consider possible futures (...) evaluate their desirability (...) and create and work out realistic paths from the present towards desirable futures, and propose them to those that can bring a design to fruition\". Acknowledging that all design serves others, \"The Semantic Turn\" does not treat THE user as statistical fiction, but as knowledgeable stakeholders and necessary partners in human-centered design processes.\n\nKrippendorff quotes the Greek philosopher Protagoras who is believed to have been the first to express human-centeredness in words by saying that \"Man is the measure of all things, of things that are (...) and of things that are not (...).\" Krippendorff goes on to cite the color theory of J. W. von Goethe who exposed Isaac Newton’s spectral theory of colors as epistemologically flawed by pointing out that color is the product of the human eye. Color does not exist without it. Krippendorff refers to the Italian philosopher G. Vico for opposing R. Descartes by claiming we humans know what we have constructed, made up, cognitively, materially, or socially, to the biologists J. Uexküll for his species-specific theory of meaning and H. Maturana and F. Varela for developing a biological foundation of cognition, to the psychologist J. J. Gibson for his conception of affordance, which acknowledges that our environment does not account for our perception, it merely affords our sensory-motor coordinations or it does not; and to the anthropological linguist B. L. Whorf for his recognition that our perceptions are correlated with language, its grammar and vocabulary. Most important, Krippendorff allies himself with L. Wittgenstein’s definition of meaning as use, culminating in the axiom that \"Humans do not see and act on the physical qualities of things, but on what they mean to them\".\n\nAttributing meaning to something follows from sensing it, and is a prelude to action. \" One always acts according to the meaning of whatever one faces \" and the consequences of these actions in turn become part of the meanings of what one interacts with. Meanings are always someone's construction and depend on context and culture. The same artifact may invoke different meanings at different times, in different contexts of use, and for different people. To design artifacts for use by others calls on designers to understand the understanding of others, a \"second order understanding\" that is fundamentally unlike the understanding of physical things. Since meanings cannot be observed directly, designers need to carefully observe the actions that imply certain meanings; involve themselves in dialog with their stakeholders; and invite them to participate in the design process.\n\nPeople acquire the meanings of artifacts by their interfacing with them, where meanings become anticipated usabilities. Krippendorff does not limit the concept of interfaces to human computer interactions, however. For him, the concept applies to any artifact one faces. To users, artifacts are perceived as affordances, as the kind of interactions they enable or prohibit. Thus scissors and coffee cups are experienced as interfaces, just as personal computers are. Their physical or computational makeup become background phenomena to use. The meaning of an artifact in use is then \"\" the range of imaginable senses and actions that users have reasons to expect\" \". Ideal interfaces are self-evident and \"\" intrinsically motivating interactions between users and their artifacts\" \".\n\nDrawing on Heidegger's explorations of the human use of technology, Krippendorff argues that all artifacts must be designed to afford three stages of use: initial recognition, intermediate exploration, and ideally, unproblematic reliance. The latter is achieved when the artifact is so incorporated into the user's world that it becomes hardly noticed, is taken for granted while looking through it to what is to be accomplished. Recognition involves users' categorizations, how close the artifact is to the \"ideal type\" of its kind. Exploration is facilitated by informatives such as state indicators, progress reports, confirmations of actions and readiness, alarm signals, close correlations between actions and their expected effects, maps of possibilities, instructions, error messages, and multi-sensory feedback. Users' intrinsic motivation arises from reliance, the seemingly effortless, unproblematic yet skillful engagement with artifacts free of disruptions. A well designed interface enables unambiguous recognition, effective exploration, and leads to enjoyable reliance. To accomplish these transitions, human-centered designers need to involve second-order understanding of users' cognitive models, cultural habits, and competencies.\n\nTypically, users approach their artifacts with very different competencies. \"The Semantic Turn\" offers the possibility of accommodating these differences by allowing the design of several semantic layers. For example, contemporary Xerox machines exhibit one layer for making copies, another for clearing paper jams, a third for replacing defective parts by trained service personnel, and a fourth is reserved for the factory repair of replaced components.\n\n\"\"The fate of all artifacts is decided in language\" \", says Krippedorff. Indeed, designers must pay attention to the narratives in which an artifact appears as soon as it enters the conversations among stakeholders, bystanders, critics, and users, to the names that categorize the artifact as being of one kind or another, and to the adjectives that direct perception to particular qualities (is it a \"fast\" car? a \"clumsy\" cell phone? a \"high class\" dress?). Such characterizations can make or break an artifact and designers cannot ignore how people talk about them. Krippendorff proposes that \"artifacts should be designed so that their interfaces are [easily] narratable\" and fit into social or communicational relationships.\n\nThe \"character\" of an artifact – the set of adjectives deemed appropriate to it – can be assessed by means of semantic differential scales – seven point scales between polar opposite attributes such as elegant––––graceless; by categorizing free associations elicited from users, whether as first impressions or after extended use; by examining the content of stories people tell about the artifacts for implied judgments; or by pair comparisons of similar artifacts. Such methods give human-centered designers ways to quantify meanings, to work towards defined design criteria, including pursuing quantifiable aesthetic objectives, and justify a design to potential stakeholders.\n\nLanguage permeates all of human life, including with artifacts. This applies not only to the users of artifacts but also to their designers. The narratives that evolve within design teams determine the direction a design is taking, and might end up convincing stakeholders to go along with a design project or oppose it, well before it is built, and influence designers in turn. What we know of current artifacts, ancient ones, outdated ones, antiques or museum pieces come to us in the form of stories. Designers need to analyse them for, as Krippendorff asserts, \" The meanings that artifacts acquire in use are largely framed in language\".\n\nHere, Krippendorff invites designers to consider artifacts in their whole life cycle. In the case of industrial products, the life cycle might start with an initial idea, then followed by design, engineering, production, sales, use, storage, maintenance and finally retirement, as recycled or as waste. Well, not so \"finally;\" designers may learn much about a product's performance, unintended uses, unexpected problems, and resulting social consequences, which can serve to improve the design of the next generation of that product – design never ends. In each phase of the life cycle of an artifact, that artifact will have to support diverse but subjectively meaningful interfaces for different communities of stakeholders. In such stakeholder networks, artifacts need to proceed from one to the next: \"\" no artifact can be realized within a culture without being meaningful to those who can move it through its various definitions\" \".\n\nDictionaries tend to define ecology as multi-species interaction in a common environment, the species being animals and plants. Humans, however, have created a perhaps greater diversity of \"species of artifacts\" than has nature. Krippendorff observes that species of artifacts too are born, grow in size and number, diversify into sub-species, associate with other species, adapt to each other and to their human environment, and either reproduce, evolve, or disappear – just as in nature. Species of artifacts may compete, cooperate or be parasitic on other artifacts. For an example of the latter, consider spam, which thrives in the email ecosystem and could not exist outside it. Whereas species of animals and plants interact with one another in their own terms, species of artifacts are brought into interaction through human agency. People arrange artifacts, like the furniture at home; connect them into networks, like computes in the internet; form large cultural cooperatives, like hospitals full of medical equipment, drugs, and treatments; retire one species in favor of another, like typewriters gave way to personal computers; or change their ecological meanings, like horses, originally used for work and transportation, found an ecological niche in sports.\n\nIn an ecology of artifacts, the meaning of one consists of the possible interactions with other artifacts: cooperation, competition (substitution), domination or submission, leading technological development, like computers do right now, supporting the leaders, like the gadgets found in computer stores. Similarly, roads and gas stations follow the development of automobiles and participate in a very large cultural complex, including the design of cities and the distribution of work, and affect nature through depletion of resources, creating waste and CO emissions. Clearly, \"\" designers who can handle the ecological meaning of their proposals have a better chance of keeping their designs alive\" \".\n\nIn 1969, Nobel laureate Herbert Simon called for a science of the artificial. Natural scientists, he argued, are concerned with what exists, whereas designers are concerned with what should be and how to achieve it. His conception of design was shaped by rational decision theory and early conceptions of computational logic, hence limited largely to technology-centered design. Krippendorff added the following contrasts to Simon’s:\n\nA science for design makes three contributions to design:\n\nGenerally, research is any inquiry that generates communicable knowledge. Human-centered design research typically involves\n\nHuman-centered design methods may aim at:\n\nIn a science for design, validation consists of generating compelling justifications for the claims that designers must make regarding the meaning, virtue, potential reality, costs and benefits of their design for particular communities. Inasmuch as any design can prove itself only in the future, \"post factum\", and with the collaboration of others, human-centered design is justifiable only by means of plausible arguments Issue-Based Information System that motivate its stakeholders to realize or use that design. The science for design, always concerned with not yet observable contingencies, cannot provide the simple truth claims of the kind that natural scientist aspire to for their theories. But it can provide several other human-centered ways to back the claims designers need to make:\n\nSince its coinage in 1984, the use of “product semantics” has mushroomed. In 2009, a Google search identified over 18,000 documents referring to it. However, it has been critiqued by advocates of a more critical approach to design as overly simplistic.\n\nThe semantics of artifacts has become of central importance in courses taught at leading design departments of many universities all over the world, among them at the Arizona State University; the Cranbrook Academy of Arts; The Ohio State University; the Savannah College of Art and Design; the University of the Arts in Philadelphia, USA; the Hochschule fűr Gestaltung Offenbach in Germany; the Hongik University in Seoul, Korea; the Indian Institute of Technology in Mumbai; the Musashino Art University in Tokyo, Japan; the National Taiwan University of Science and Technology; the University of Art and Design in Helsinki, Finland; and more. It has also permeated other disciplines, notably ergonomics, marketing, cognitive engineering.\n\nReviews can be found by writers on design theory, design history, corporate strategy, national design policy, design science studies, participatory design, interaction design, human-computer interaction, and cybernetics.\n\n\"The Semantic Turn\" has been translated into Japanese and is currently being translated into German.\n\n"}
{"id": "34122244", "url": "https://en.wikipedia.org/wiki?curid=34122244", "title": "Trekiz", "text": "Trekiz\n\nTrekiz is a technology company that provides customized travel planning and booking solutions through its web-based platforms. Trekiz was registered in Hong Kong and its operations center was established in Beijing in 2010. The company's main website, Trekiz.com, is an online travel platform for creating and booking customized, multi-destination travel itineraries in real time. At the time of its launch, Trekiz.com focused on tourism in China, but has since added activities, tours and hotel reservations in other international destinations. Trekiz also offers a business-to-business platform that allows travel industry professionals to expand their business's product base, adjust tour pricing and build more varied itineraries for customers.\n\nTrekiz was conceived as a “smart travel platform” in the early 2000s by CEO Wenqing Tian. However, it was not until March 2011 that the main website was finally launched. At the time, the Trekiz site featured more than 500 China activities provided by 117 tour operators. In addition to expanding its travel selection to include tours in global destinations such as Italy, Malaysia, Sweden, Kenya, South Africa and Morocco, Trekiz developed a business-to-business platform targeted at industry professionals.\n\nThe Trekiz website allows users to build multi-destination travel itineraries – including tours, activities, hotels and flights – in real time using Trekiz's patented “trip planner.” Users can manipulate and rearrange elements of the tour in the “trip planner,” which continuously updates the total cost of all the specified services. Once completed, the entire itinerary can be booked directly through the Trekiz website. Trekiz also provides detailed city guides.\n\nTrekiz identifies itself as a Web 3.0 “smart platform” for booking travel itineraries. The company states that its use of technology to “intuitively and seamlessly integrate things that were formerly separate” and “tailor [the Trekiz experience] to the user” reinforce their Web 3.0 claim. Because definitions of Web 3.0 tend to vary, it is not yet possible to determine whether Trekiz qualifies as a true Web 3.0 platform.\n\nTrekiz was recognized as a 2010 Red Herring Global Award Winner. The Red Herring Global Award is an award given to innovative startups.\n\n"}
{"id": "80506", "url": "https://en.wikipedia.org/wiki?curid=80506", "title": "Twisted pair", "text": "Twisted pair\n\nTwisted pair cabling is a type of wiring in which two conductors of a single circuit are twisted together for the purposes of improving electromagnetic compatibility. Compared to a single conductor or an untwisted balanced pair, a twisted pair reduces electromagnetic radiation from the pair and crosstalk between neighboring pairs and improves rejection of external electromagnetic interference. It was invented by Alexander Graham Bell.\n\nIn a balanced line, the two wires carry equal and opposite signals, and the destination detects the difference between the two. This is known as differential signaling. Noise sources introduce signals into the wires by coupling of electric or magnetic fields and tend to couple to both wires equally. The noise thus produces a common-mode signal which can be canceled at the receiver when the difference signal is taken.\n\nDifferential signaling starts to fail when the noise source is close to the signal wires; the closer wire will couple with the noise more strongly and the receiver will be unable to eliminate it. This problem is especially apparent in telecommunication cables where pairs in the same cable lie next to each other for many miles. Twisting the pairs counters this effect as on each half twist the wire nearest to the noise-source is exchanged. Provided the interfering source remains uniform, or nearly so, over the distance of a single twist, the induced noise will remain common-mode.\n\nThe twist rate (also called \"pitch\" of the twist, usually defined in twists per meter) makes up part of the specification for a given type of cable. When nearby pairs have equal twist rates, the same conductors of the different pairs may repeatedly lie next to each other, partially undoing the benefits of differential mode. For this reason it is commonly specified that, at least for cables containing small numbers of pairs, the twist rates must differ.\n\nIn contrast to shielded or foiled twisted pair (typically F/UTP or S/FTP cable shielding), UTP (unshielded twisted pair) cable is not surrounded by any shielding. UTP is the primary wire type for telephone usage and is very common for computer networking.\n\nThe earliest telephones used telegraph lines, or open-wire single-wire earth return circuits. In the 1880s electric trams were installed in many cities, which induced noise into these circuits. Lawsuits being unavailing, the telephone companies converted to balanced circuits, which had the incidental benefit of reducing attenuation, hence increasing range.\n\nAs electrical power distribution became more commonplace, this measure proved inadequate. Two wires, strung on either side of cross bars on utility poles, shared the route with electrical power lines. Within a few years, the growing use of electricity again brought an increase of interference, so engineers devised a method called wire transposition, to cancel out the interference.\n\nIn wire transposition, the wires exchange position once every several poles. In this way, the two wires would receive similar EMI from power lines. This represented an early implementation of twisting, with a twist rate of about four twists per kilometre, or six per mile. Such open-wire balanced lines with periodic transpositions still survive today in some rural areas.\n\nTwisted-pair cabling was invented by Alexander Graham Bell in 1881. By 1900, the entire American telephone line network was either twisted pair or open wire with transposition to guard against interference. Today, most of the millions of kilometres of twisted pairs in the world are outdoor landlines, owned by telephone companies, used for voice service, and only handled or even seen by telephone workers.\n\nUnshielded twisted pair (UTP) cables are found in many Ethernet networks and telephone systems. For indoor telephone applications, UTP is often grouped into sets of 25 pairs according to a standard 25-pair color code originally developed by AT&T Corporation. A typical subset of these colors (white/blue, blue/white, white/orange, orange/white) shows up in most UTP cables. The cables are typically made with copper wires measured at 22 or 24 American Wire Gauge (AWG), with the colored insulation typically made from an insulator such as polyethylene or FEP and the total package covered in a polyethylene jacket.\n\nFor urban outdoor telephone cables containing hundreds or thousands of pairs, the cable is divided into small but identical bundles. Each bundle consists of twisted pairs that have different twist rates. The bundles are in turn twisted together to make up the cable. Pairs having the same twist rate within the cable can still experience some degree of crosstalk. Wire pairs are selected carefully to minimize crosstalk within a large cable.\nUTP cable is also the most common cable used in computer networking. Modern Ethernet, the most common data networking standard, can use UTP cables. Twisted pair cabling is often used in data networks for short and medium length connections because of its relatively lower costs compared to optical fiber and coaxial cable.\n\nUTP is also finding increasing use in video applications, primarily in security cameras. Many cameras include a UTP output with screw terminals; UTP cable bandwidth has improved to match the baseband of television signals. As UTP is a balanced transmission line, a balun is needed to connect to unbalanced equipment, for example any using BNC connectors and designed for coaxial cable.\n\nTwisted pair cables often incorporate shielding in an attempt to prevent electromagnetic interference. Shielding provides an electrically conductive barrier to attenuate electromagnetic waves external to the shield; and provides a conduction path by which induced currents can be circulated and returned to the source via ground reference connection.\n\nSuch shielding can be applied to individual pairs or quads; or to a collection of pairs. Individual pairs are foil shielded, while an overall cable (of multiple pairs) may use any of braided screen or foil or braiding with foil.\n\nWhen shielding is applied to a collection of pairs, it is usually referred to as screening, but usage among vendors and authors in applying such words as \"screening\", \"shielding\", and \"STP (shielded twisted pair)\" can be subject to variability.\n\nISO/IEC 11801:2002 (Annex E) attempts to internationally standardize the various designations for shielded cables by using combinations of three letters - U for unshielded, S for braided shielding (in outer layer only), and F for foil shielding - to explicitly indicate the type of screen for overall cable protection and for protecting individual pairs or quads, using a two-part abbreviation in the form of \"x/xTP\".\n\nShielded Cat 5e, Cat 6/6, and Cat 8/8.1 cables typically have F/UTP construction, while shielded Cat 7/7 and Cat 8.2 cables use S/FTP construction.\n\nBecause the shielding is made of metal, it may also serve as a path to ground; usually a screen shielded, twisted pair cable has an integrally incorporated, grounding wire, called a \"drain wire\", which makes electrical contact with the shield or screen. The purpose of the drain wire is for easy connection of the screen to terminals, which are usually designed for connection of round wires.\n\nCommon shield construction types include:\n\n\n\nAn early example of shielded twisted-pair was IBM STP-A, which is a two-pair 150 ohm S/FTP cable defined in 1985 by the IBM Cabling System specifications, and used with token ring or FDDI networks.\n\nThe code before the slash designates the shielding for the cable itself, while the code after the slash determines the shielding for the individual pairs:\n\nBefore digital communication and ethernet became widespread there was no international standard for telephone cable. Standards were set at a national level. For instance, in the UK the General Post Office specified CW1293 and CW1308 cables. CW1308 was a similar specification to the earlier CW1293 but with an improved color code. CW1293 used mostly solid colors on the cores making it difficult to identify the pair it was twisted with without stripping back a large amount of sheath. CW1308 has narrow rings of the paired color printed over the base color to solve this problem. Both cables are a similar standard to category 3 cable.\n\nPrior to the common use of polyethylene and other plastics for insulation, telephone twisted pair cable was insulated with waxed paper or cotton with a wax coating applied to the copper. The overall sheath of this type of cable was usually lead. This style of cable came into use in the late 19th century shortly after the invention of the telephone. The cable termination in termination boxes were sealed with molten wax or epoxy resin to prevent the ingress of moisture which would seriously degrade the insulating properties of the paper insulation. However, such seals made future maintenance and changes more difficult. These cables are no longer made, but are still occasionally encountered in old buildings and in various external areas, commonly rural villages.\n\nA solid-core cable uses one solid wire per conductor and in a four pair cable there would be a total of eight solid wires. Stranded conductor uses multiple wires wrapped around each other in each conductor and in a four pair with seven strands per conductor cable, there would be a total of 56 wires (2 per pair × 4 pairs × 7 strands).\n\nSolid core cable is intended for permanently installed runs. It is less flexible than stranded cable and is more prone to failure if repeatedly flexed. Stranded cable is used for fly leads at patch panel and for connections from wall-ports to end devices, as it resists cracking of the conductors.\n\nConnectors are designed differently for solid core than for stranded. Use of a connector with the wrong cable type can lead to unreliable cabling. Plugs designed for solid and stranded core are readily available, and some vendors even offer plugs designed for use with both types. The punch-down blocks on patch-panel and wall-port jacks are designed for use with solid core cable, these work via a method known as insulation-displacement which pierces the sides of the insulation and \"bites\" in to the copper conductor to form a connection.\n\n\n\n\n\n"}
{"id": "587884", "url": "https://en.wikipedia.org/wiki?curid=587884", "title": "UMAX Technologies", "text": "UMAX Technologies\n\nUMAX Technologies (), originally known as UMAX Computer Corporation, is a manufacturer of computer products, including scanners, mice, and flash drives, based in Taiwan. The company also uses the Yamada and Vaova brand names.\n\nUMAX was formerly a maker of Apple Macintosh clones, using the \"SuperMac\" brand name outside of Europe. Some of their models included the SuperMac S900/S910, J700, C500 and C500e/i/LT, C600e/v/LT/x and Aegis 200. The C500 was marketed as the Apus 2000 in Europe. After Steve Jobs returned to Apple as the new CEO, he revoked all of the clone producers' licenses to produce Mac clones except for UMAX, due to their sub-US$1,000 low-end offerings, a market in which Apple was not strong, and UMAX's stated desire to expand the Macintosh platform's presence in East Asian markets. UMAX could not remain profitable selling only these systems, however; it briefly made IBM PC compatible computers in the mid-1990s, but since then UMAX has mainly concentrated on manufacturing scanners.\n\nIn 1995, UMAX was the leading Taiwanese scanner maker, with a market share of 13% second worldwide behind Hewlett-Packard (HP). This continued to be the case throughout 1996. According to \"PC Data\" figures, in 1997 UMAX briefly overtook HP in some monthly sales. According to the same source however, by 1999 UMAX was being \"eclipsed\" by HP whose scanner market share doubled that year from 13% to 26%. In some markets with high price-sensitivity like India for example, UMAX continued to have a slight lead on HP throughout 1999-2000 with the two companies claiming 44% and 40%, respectively, of the scanner sales in this country; 85% of which were for products costing less than 10,000 Rs.) By 2003, HP and Canon were dominating the world's flatbed scanner market, \"accounting for a combined unit market share of 81 per cent.\"\n\nIn 2002 UMAX started to charge its US customers for driver upgrades for its scanners—a practice that soon proved controversial.\n\nUntil their exit from the desktop scanner marked in 2002, Heidelberger Druckmaschinen used UMAX as its OEM for these products.\n\nUMAX also made a 1.3 megapixel digital camera called the AstraPix 490. It is capable of recording video clips, functioning as a webcam and can even be used to listen to music encoded in MP3 format.\n\n\nUMAX offers some semi-free (in the sense that some versions/updates cost money and some do not) basic scanner software for Microsoft Windows (up to Windows XP) and Mac OS:\n\nAdditionally, UMAX offers more sophisticated (typically non-free) third-party photo scanning/correction software:\n\nFor optical character recognition, some UMAX scanners came bundled with OmniPage and others with ABBYY FineReader.\n\nThe Unix SANE software generally supports well the UMAX SCSI scanners, with varying degrees of support for the other ones (USB, Firewire, parallel).\n\n\n"}
{"id": "6413844", "url": "https://en.wikipedia.org/wiki?curid=6413844", "title": "Underwater explosion", "text": "Underwater explosion\n\nAn underwater explosion (also known as an UNDEX) is a chemical or nuclear explosion that occurs under the surface of a body of water.\n\nUnderwater explosions differ from in-air explosions due to the properties of water:\n\n\nEffects of an underwater explosion depend on several things, including distance from the explosion, the energy of the explosion, the depth of the explosion, and the depth of the water.\n\nUnderwater explosions are categorized by the depth of the explosion. Shallow underwater explosions are those where a crater formed at the water's surface is large in comparison with the depth of the explosion. Deep underwater explosions are those where the crater is small in comparison with the depth of the explosion, or nonexistent.\n\nThe overall effect of an underwater explosion depends on depth, the size and nature of the explosive charge, and the presence, composition and distance of reflecting surfaces such as the seabed, surface, thermoclines, etc. This phenomenon has been extensively used in antiship warhead design since an underwater explosion (particularly one underneath a hull) can produce greater damage than an above-surface one of the same explosive size. Initial damage to a target will be caused by the first shockwave; this damage will be amplified by the subsequent physical movement of water and by the repeated secondary shockwaves or bubble pulse. Additionally, charge detonation away from the target can result in damage over a larger hull area.\n\nUnderwater nuclear tests close to the surface can disperse radioactive water and steam over a large area, with severe effects on marine life, nearby infrastructures and humans. The detonation of nuclear weapons underwater was banned by the 1963 Partial Nuclear Test Ban Treaty and it is also prohibited under the Comprehensive Nuclear-Test-Ban Treaty of 1996.\n\nThe Baker nuclear test at Bikini Atoll in July 1946 was a shallow underwater explosion, part of Operation Crossroads. A 20 kiloton warhead was detonated in a lagoon which was approximately deep. The first effect was illumination of the water because of the underwater fireball. A rapidly expanding gas bubble created a shock wave that caused an expanding ring of apparently dark water at the surface, called the \"slick\", followed by an expanding ring of apparently white water, called the \"crack\". A mound of water and spray, called the \"spray dome\", formed at the water's surface which became more columnar as it rose. When the rising gas bubble broke the surface, it created a shock wave in the air as well. Water vapor in the air condensed as a result of a Prandtl-Glauert singularity, making a spherical cloud that marked the location of the shock wave. Water filling the cavity formed by the bubble caused a hollow column of water, called the \"chimney\" or \"plume\", to rise in the air and break through the top of the cloud. A series of ocean surface waves moved outward from the center. The first wave was about high at from the center. Other waves followed, and at further distances some of these were higher than the first wave. For example, at from the center, the ninth wave was the highest at . Gravity caused the column to fall to the surface and caused a cloud of mist to move outward rapidly from the base of the column, called the \"base surge\". The ultimate size of the base surge was in diameter and high. The base surge rose from the surface and merged with other products of the explosion, to form clouds which produced moderate to heavy rainfall for nearly one hour.\n\nAn example of a deep underwater explosion is the Wahoo test, which was carried out in 1958 as part of Operation Hardtack I. A 9 kt Mk-7 was detonated at a depth of in deep water. There was little evidence of a fireball. The spray dome rose to a height of . Gas from the bubble broke through the spray dome to form jets which shot out in all directions and reached heights of up to . The base surge at its maximum size was in diameter and high.\n\nThe heights of surface waves generated by deep underwater explosions are greater because more energy is delivered to the water. During the Cold War, underwater explosions were thought to operate under the same principles as tsunamis, potentially increasing dramatically in height as they move over shallow water, and flooding the land beyond the shoreline. Later research and analysis suggested that water waves generated by explosions were different from those generated by tsunamis and landslides. Méhauté \"et al.\" conclude in their 1996 overview \"Water Waves Generated by Underwater Explosion\" that the surface waves from even a very large offshore undersea explosion would expend most of their energy on the continental shelf, resulting in coastal flooding no worse than that from a bad storm.\n\nThe Operation Wigwam test in 1955 occurred at a depth of , the deepest detonation of any nuclear device.\n\nUnless it breaks the water surface while still a hot gas bubble, an underwater nuclear explosion leaves no trace at the surface but hot, radioactive water rising from below. This is always the case with explosions deeper than about .\n\nDuring such an explosion, the hot gas bubble quickly collapses because:\n\n\nSince water is not readily compressible, moving this much of it out of the way so quickly absorbs a massive amount of energy—all of which comes from the pressure inside the expanding bubble. Eventually, the water pressure outside the bubble causes it to collapse back into a small sphere and then rebound, expanding again. This is repeated several times, but each rebound contains only about 40% of the energy of the previous cycle. At its maximum diameter (during the first oscillation), a very large nuclear bomb exploded in very deep water creates a bubble about a half-mile wide in about one second, and then contracts (which also takes one second).\n\nBlast bubbles from deep nuclear explosions become mere hot water in about six seconds and leave no \"regular\" bubbles to float up to the surface. This is sooner than blast bubbles from conventional explosives.\n\nThis drastic loss of energy between cycles is caused in part by the extreme force of a nuclear explosion pushing the bubble wall outward supersonically (faster than the speed of sound in saltwater). This causes Rayleigh–Taylor instability. That is, the smooth inner wall surface becomes turbulent and fractal, with fingers and branches of cold ocean water extending into the bubble. That cold water cools the hot gas inside and causes it to condense. The bubble becomes less of a sphere and looks more like the Crab Nebula, the deviation of which from a smooth surface is also due to Rayleigh–Taylor instability.\n\nAs one might expect, large, shallow explosions expand faster than deep, small ones.\n\nDeep explosions have longer oscillations.\n\nThe water pressure just outside the bubble varies dramatically.\n\nDespite being in direct contact with a nuclear explosion, the water of the expanding bubble wall does not boil. This is because the pressure inside the bubble exceeds (by far) the vapor pressure of ocean water. The water touching the blast can only boil during contraction. This boiling is like evaporation, cooling the bubble wall, and it is another reason that an oscillating blast bubble contains only 40% of the energy it had in the previous cycle.\n\nDuring these hot gas oscillations, the bubble continually rises (\"migrates\") for the same reason a mushroom cloud rises: it is less dense. This causes the blast bubble never to be perfectly spherical. Instead, the bottom of the bubble is flatter, and during contraction, it even tends to \"reach up\" toward the blast center. In the last contraction cycle, the bottom of the bubble touches the top before the sides have fully collapsed, and the bubble becomes a torus in its last second of life. After that, all that remains of a large nuclear explosion is a mass of hot water, slowly rising from the cold depths of the ocean.\n\nRelatively few underwater nuclear tests were performed before they were banned by the Partial Test Ban Treaty. They are:\n\nNote: it is often believed that the French did extensive underwater tests in French West Polynesia on the Moruroa and Fangataufa Atolls. This is incorrect; the bombs were placed in shafts drilled into the underlying coral and volcanic rock, and they did not intentionally leak fallout.\n\nThere are several methods of detecting nuclear detonations. Hydroacoustics is the primary means of determining if a nuclear detonation has occurred underwater. Hydrophones are used to monitor the change in water pressure as sound waves propagate through the world's oceans. Sound travels through 20 °C water at approximately 1482 meters per second, compared to the 332 m/s speed of sound through air. In the world's oceans, sound travels most efficiently at a depth of approximately 1000 meters. Sound waves that travel at this depth travel at minimum speed and are trapped in a layer known as the Sound Fixing and Ranging Channel (SOFAR). Sounds can be detected in the SOFAR from large distances, allowing for a limited number of monitoring stations required to detect oceanic activity. Hydroacoustics was originally developed in the early 20th century as a means of detecting objects like icebergs and shoals to prevent accidents at sea.\n\nThree hydroacoustic stations were built before the adoption of the Comprehensive Nuclear-Test-Ban Treaty. Two hydrophone stations were built in the North Pacific Ocean and Mid-Atlantic Ocean, and a T-phase station was built off the west coast of Canada. When the CTBT was adopted, 8 more hydroacoustic stations were constructed to create a comprehensive network capable of identifying underwater nuclear detonations anywhere in the world. These 11 hydroacoustic stations, in addition to 326 monitoring stations and laboratories, comprise the International Monitoring System (IMS), which is monitored by the Preparatory Commission for the Comprehensive Nuclear-Test-Ban Treaty Organization (CTBTO).\n\nThere are two different types of hydroacoustic stations currently used in the IMS network; 6 hydrophone monitoring stations and 5 T-phase stations. These 11 stations are primarily located in the southern hemisphere, which is primarily ocean. Hydrophone monitoring stations consist of an array of three hydrophones suspended from cables tethered to the ocean floor. They are positioned at a depth located within the SOFAR in order to effectively gather readings. Each hydrophone records 250 samples per second, while the tethering cable supplies power and carries information to the shore. This information is converted to a usable form and transmitted via secure satellite link to other facilities for analysis. T-phase monitoring stations record seismic signals generate from sound waves that have coupled with the ocean floor or shoreline. T-phase stations are generally located on steep-sloped islands in order to gather the cleanest possible seismic readings. Like hydrophone stations, this information is sent to the shore and transmitted via satellite link for further analysis. Hydrophone stations have the benefit of gathering readings directly from the SOFAR, but are generally more expensive to implement than T-phase stations. Hydroacoustic stations monitor frequencies from 1 to 100 Hertz to determine if an underwater detonation has occurred. If a potential detonation has been identified by one or more stations, the gathered signals will contain a high bandwidth with the frequency spectrum indicating an underwater cavity at the source.\n\n\n"}
{"id": "3301527", "url": "https://en.wikipedia.org/wiki?curid=3301527", "title": "Ventricular assist device", "text": "Ventricular assist device\n\nA ventricular assist device (VAD) is an electromechanical device for assisting cardiac circulation, which is used either to partially or to completely replace the function of a failing heart. The function of VADs is different from that of artificial cardiac pacemakers; some are for short-term use, typically for patients recovering from myocardial infarction (heart attack) and for patients recovering from cardiac surgery; some are for long-term use (months to years to perpetuity), typically for patients suffering from advanced heart failure.\n\nVADs are designed to assist either the right ventricle (RVAD) or the left ventricle (LVAD), or to assist both ventricles (BiVAD). The type of ventricular assistance device applied depends upon the type of underlying heart disease, and upon the pulmonary arterial-resistance, which determines the workload of the right ventricle. The left-ventricle assistance device (LVAD) is the most common device applied to a defective heart (as it is sufficient in most cases -the right side of the heart is then often already able to make use of the heavily increased blood flow-), but when the pulmonary arterial-resistance is high, then an (additional) right-ventricle assistance device (RVAD) might be necessary to resolve the problem of cardiac circulation. If both a LVAD and a RVAD is needed a BiVAD is normally used, rather than a separate LVAD and an RVAD.\n\nNormally, the long-term VAD is used as a bridge to transplantation (BTT)—keeping the patient alive, and in reasonably good condition, and able to await the heart transplant outside of the hospital.\nOther \"bridges\" include bridge to candidacy, bridge to decision, and bridge to recovery. \nIn some instances VAD's are also used as destination therapy (DT). In this instance, the patient shall not undergo a heart transplantion and the VAD is what the patient will use for the remainder of his life.\n\nVADs are distinct from artificial hearts, which are designed to assume cardiac function, and generally require the removal of the patient's heart.\n\nThe pumps used in VADs can be divided into two main categories—pulsatile pumps, that mimic the natural pulsing action of the heart, and continuous flow pumps. Pulsatile VADs use positive displacement pumps. In some pulsatile pumps (that use compressed air as the/a energy source), the volume occupied by blood varies during the pumping cycle. If the pump is contained inside the body then a vent tube to the outside air is required.\n\nContinuous-flow VADs are smaller and have proven to be more durable than pulsatile VADs. They normally use either a centrifugal pump or an axial flow pump. Both types have a central rotor containing permanent magnets. Controlled electric currents running through coils contained in the pump housing apply forces to the magnets, which in turn cause the rotors to spin. In the centrifugal pumps, the rotors are shaped to accelerate the blood circumferentially and thereby cause it to move toward the outer rim of the pump, whereas in the axial flow pumps the rotors are more or less cylindrical with blades that are helical, causing the blood to be accelerated in the direction of the rotor's axis.\n\nAn important issue with continuous flow pumps is the method used to suspend the rotor. Early versions used solid bearings; however, newer pumps, some of which are approved for use in the EU, use either magnetic levitation (\"maglev\") or hydrodynamic suspension. These pumps contain only one moving part (the rotor).\n\nThe first successful implantation of a left ventricular assist device was completed in 1966 by Dr. Michael E. DeBakey to a 37-year-old woman. A paracorporeal (external) circuit was able to provide mechanical support for 10 days after the surgery. The first successful long-term implantation of an artificial LVAD was conducted in 1988 by Dr. William F. Bernhard of Boston Children's Hospital Medical Center and Thermedics, Inc of Woburn, MA under a National Institutes of Health (NIH) research contract which developed Heart-mate, an electronically controlled assist device. This was funded by a three-year $6.2 million contract to Thermedics and Children's Hospital, Boston MA from the National Heart and Lung and Blood Institute, a program of the NIH. The early VADs emulated the heart by using a \"pulsatile\" action where blood is alternately sucked into the pump from the left ventricle then forced out into the aorta. Devices of this kind include the HeartMate IP LVAS, which was approved for use in the US by the Food and Drug Administration (FDA) in October 1994. These devices began to gain acceptance in the late 1990's as heart surgeons including Eric Rose, O. H. Frazier and Mehmet Oz began popularizing the concept that patients could live outside the hospital. Media coverage of outpatients with VADs underscored these arguments.\n\nMore recent work has concentrated on continuous flow pumps, which can be roughly categorized as either centrifugal pumps or axial flow impeller driven pumps. These pumps have the advantage of greater simplicity resulting in smaller size and greater reliability. These devices are referred to as second generation VADs. A side effect is that the user will not have a pulse,\nor that the pulse intensity will be seriously reduced.\n\nThird generation VADs suspend the impeller in the pump using either hydrodynamic or electromagnetic suspension, thus removing the need for bearings and reducing the number of moving parts to one.\n\nAnother technology undergoing clinical trials is the use of trans cutaneous induction to power and control the device rather than using percutaneous cables. Apart from the obvious cosmetic advantage this reduces the risk of infection and the consequent need to take preventative action. A pulsatile pump using this technology has CE Mark approval and is in clinical trials for US FDA approval.\n\nA very different approach in the early stages of development is the use of an inflatable cuff around the aorta. Inflating the cuff contracts the aorta and deflating the cuff allows the aorta to expand—in effect the aorta becomes a second left ventricle. A proposed refinement is to use the patient's skeletal muscle, driven by a pacemaker, to power this device which would make it truly self-contained. However a similar operation (cardiomyoplasty) was tried in the 1990s with disappointing results. In any case, it has substantial potential advantages in avoiding the need to operate on the heart itself and in avoiding any contact between blood and the device. This approach involves a return to a pulsatile flow.\n\nPeter Houghton was the longest surviving recipient of a VAD for permanent use. He received an experimental Jarvik 2000 LVAD in June 2000. Since then, he completed a 91-mile charity walk, published two books, lectured widely, hiked in the Swiss Alps and the American West, flew in an ultra-light aircraft, and traveled extensively around the world. He died of acute renal failure in 2007 at the age of 69.\n\n\nThe majority of VADs on the market today are somewhat bulky. The smallest device approved by the FDA, the HeartMate II, weighs about and measures . This has proven particularly important for women and children, for whom alternatives would have been too large. As of 2017, Heartmate III has been approved by the FDA. It is smaller than its predecessor HeartMate II, and uses a full maglev impeller instead of the cup-and-ball bearing system found in HeartMate II.\n\nOne device gained CE Mark approval for use in the EU and began clinical trials in the US (VentrAssist). As of June 2007 these pumps had been implanted in over 100 patients. In 2009, Ventracor was placed into the hands of Administrators due to financial problems and was later that year liquidated. No other companies purchased the technology, so as a result the VentrAssist device was essentially defunct. Around 30–50 patients worldwide remain supported on VentrAssist devices as of January 2010.\n\nThe Heartware HVAD works similarly to the VentrAssist—albeit much smaller and not requiring an abdominal pocket to be implanted into. The device has obtained CE Mark in Europe, and FDA approval in the U.S. Recently, it was shown that the Heartware HVAD can be implanted through limited access without sternotomy.\n\nIn a small number of cases left ventricular assist devices, combined with drug therapy, have enabled the heart to recover sufficiently for the device to be able to be removed (\"explanted\").\n\nA series of studies involving the use of the HeartMate II LVAD have proven useful in establishing the viability and risks of using LVADs for bridge-to-transplantation and destination therapy.\n\n\nThe Harefield Recovery Protocol Study (HARPS) is a clinical trial to evaluate whether advanced heart failure patients requiring VAD support can recover sufficient myocardial function to allow device removal (known as explantation). HARPS combines an LVAD (the HeartMate XVE) with conventional oral heart failure medications, followed by the novel β2 agonist clenbuterol. This opens the possibility that some advanced heart failure patients may forgo heart transplantation.\n\nTo date, 73% (11 of 15) of patients who underwent the combination therapy regimen demonstrated sufficient recovery to allow explantation and avoid heart transplantation; freedom from recurrent heart failure in surviving patients was 100% and 89% at one and four years after explantation, respectively; average ejection fraction was 64% at 59 months after explantation—all patients were NYHA Class I; and no significant adverse effects were reported with clenbuterol therapy.\n\nThe REMATCH (Randomized Evaluation of Mechanical Assistance for the Treatment of Congestive Heart Failure) clinical trial began in May 1998 and ran through July 2001 in 20 cardiac transplant centers around the USA. The trial was designed to compare long-term implantation of left ventricular assist devices with optimal medical management for patients with end-stage heart failure who require, but do not qualify to receive cardiac transplantation. As a result of the clinical outcomes, the device received FDA approval for both indications, in 2001 and 2003, respectively.\n\nThe trial demonstrated an 81% improvement in two-year survival among patients receiving HeartMate XVE compared to optimal medical management. In addition, a destination therapy study following the REMATCH trial demonstrated an additional 17% improvement (61% vs. 52%) in one-year survival of patients that were implanted with a VAD (HeartMate XVE), with an implication for the appropriate selection of candidates and timing of VAD implantation.\n\nA test carried out in 2001 by Dr. Eric A. Rose and REMATCH study group with patients with congestive heart failure that were ineligible for a transplant showed a survival at two years of 23% for those implanted with an LVAD compared with 8% for those who were treated with drugs. The two major complications of VAD implantation were infection and mechanical failure (see below).\n\nAccording to a retrospective cohort study comparing patients treated with a left ventricular assist device versus inotrope therapy while awaiting heart transplantation, the group treated with LVAD had improved clinical and metabolic function at the time of transplant with better blood pressure, sodium, blood urea nitrogen, and creatinine. After transplant, 57.7% of the inotrope group had renal failure versus 16.6% in the LVAD group; 31.6% of the inotrope group had right heart failure versus 5.6% in the LVAD group; and event-free survival was 15.8% in the inotrope group versus 55.6% in the LVAD group.\n\nBleeding is the most common postoperative early complication after implantation or explantation of LVADs, necessitating reoperation in up to 60% of recipients. The implications of massive blood transfusions are great and include infection, pulmonary insufficiency, increased costs, right heart failure, allosensitization, and viral transmission, some of which can prove fatal or preclude transplantation. When bleeding occurs, it impacts the one year Kaplan-Meier mortality. In addition to complexity of the patient population and the complexity of these procedures contributing to bleeding, the devices themselves may contribute to the severe coagulopathy that can ensue when these devices are implanted.\n\nBecause the devices generally result in blood flowing over a non-biologic surface, predisposing the blood to clotting, there is need for anticoagulation measures. One device, the HeartMate XVE, is designed with a biologic surface derived from fibrin and does not require long term anticoagulation (except aspirin); unfortunately, this biologic surface may also predispose the patient to infection through selective reduction of certain types of leukocytes.\n\nNew VAD designs which are now approved for use in the European Community and are undergoing trials for FDA approval have all but eliminated mechanical failure.\n\nVAD-related infection can be caused by a large number of different organisms:\n\nTreatment of VAD-related infection is exceedingly difficult and many patients die of infection despite optimal treatment. Initial treatment should be with broad spectrum antibiotics, but every effort must be made to obtain appropriate samples for culture. A final decision regarding antibiotic therapy must be based on the results of microbiogical cultures.\n\nOther problems include immunosuppression, clotting with resultant stroke, and bleeding secondary to anticoagulation. Some of the polyurethane components used in the devices cause the deletion of a subset of immune cells when blood comes in contact with them. This predisposes the patient to fungal and some viral infections necessitating appropriate prophylactic therapy.\n\nConsidering the multitude of risks and lifestyle modifications associated with ventricular assist device implant, it is important for prospective patients to be informed prior to decision making. In addition to physician consult, various Internet-based patient directed resources are available to assist in patient education.\n\n\"This is a partial list and may never be complete\"\n\"Referenced additions are welcome\"\n\n\n"}
{"id": "6071056", "url": "https://en.wikipedia.org/wiki?curid=6071056", "title": "Water thief", "text": "Water thief\n\nThe term \"water thief\" refers to three devices – one ancient and two modern.\n\n\n"}
{"id": "31696361", "url": "https://en.wikipedia.org/wiki?curid=31696361", "title": "Winnie Byanyima", "text": "Winnie Byanyima\n\nWinifred Byanyima (born 13 January 1959) is a Ugandan-born aeronautical engineer, politician, and diplomat. She is the executive director of Oxfam International, to which she was appointed in May 2013. Before that, she served as the director of the Gender Team in the Bureau for Development Policy at the United Nations Development Programme (UNDP) from 2006.\n\nShe was born in Mbarara District in the Western Region of Uganda, a British protectorate at the time. Her parents are Boniface Byanyima, one-time national chairman of the Democratic Party in Uganda, and Gertrude Byanyima, a former schoolteacher who died in November 2008. Winnie Byanyima attended Mount Saint Mary's College Namagunga in Mukono District. She went on to obtain a bachelor's degree in aeronautical engineering from the University of Manchester, becoming the first female Ugandan to become an aeronautical engineer. She later received a master's degree in mechanical engineering, specializing in energy conservation from Cranfield University.\n\nFollowing the completion of her training as an aeronautical engineer, Byanyima worked as a flight engineer for Uganda Airlines. When Yoweri Museveni started the 1981–1986 Ugandan Bush War, Byanyima left her job and joined the armed rebellion. Museveni and Byanyima had been raised together at the Byanyima household as children, with the Byanyima family paying for all Museveni's education and scholastic needs.\n\nMuseveni, Byanyima, and her husband Kizza Besigye were combatants in the National Resistance Army (NRA) during that war. Though both Byanyima and her husband have since fallen out with the Ugandan president because of his repressive undemocratic rule despite his earlier stated convictions.\n\nAfter the NRA won that war, Byanyima served as Uganda's ambassador to France from 1989 until 1994. She then returned home and became an active participant in Ugandan politics. She served as a member of the Constituent Assembly that drafted the 1995 Ugandan Constitution. She then served two consecutive terms as a member of parliament, representing Mbarara Municipality from 1994 until 2004. She was then appointed director of the Directorate of Women, Gender and Development at the headquarters of the African Union in Addis Ababa, Ethiopia. She served in that capacity until she was appointed as director of the Gender Team in the Bureau for Development Policy at UNDP in November 2006.\n\nIn January 2013, Byanyima was announced as the next executive director of Oxfam International, replacing Jeremy Hobbs. Byanyima began her five-year directorship at Oxfam on 1 May 2013. In December 2017, she announced acceptance of an offer from Oxfam’s Board of Supervisors to serve a second five-year term as Oxfam International’s Executive Director.\n\nIn January 2015, Byanyima co-chaired the World Economic Forum in Davos. She used the forum to press for action to narrow the gap between rich and poor. The charity’s research claims that the share of the world's wealth owned by the richest 1 percent of the world population had increased to nearly 50 percent in 2014, whereas 99 percent shares the other half. Oxfam's figures are strongly contested by several economists.\n\nIn November 2016, Byanyima was appointed by United Nations Secretary-General Ban Ki-moon to the High-Level Panel on Access to Medicines, co-chaired by Ruth Dreifuss, former President of Switzerland, and Festus Mogae, former President of Botswana.\n\nByanyima is married to political opposition figure Kizza Besigye, the former chairman of the Forum for Democratic Change (FDC) political party in Uganda. They are the parents of one son named Anselm. Byanyima is a member of the FDC, although she has significantly reduced her participation in partisan Ugandan politics since she became a Ugandan diplomat in 2004. She has five siblings: Edith, Anthony, Martha, Abraham, and Olivia.\n\n"}
{"id": "21323231", "url": "https://en.wikipedia.org/wiki?curid=21323231", "title": "Zakuski", "text": "Zakuski\n\nZakuski (plural from Russian: закуски ; singular zakuska from закуска) is a Slavic term of Russian origin for hot and cold hors d'oeuvres, entrées and snacks, either as a course as it is or \"intended to follow each shot of vodka or another alcoholic drink.\" The word literally means \"something to bite after\". It probably originated through the fusion of Viking-Nordic and Slavic cultures in the early Rus' Novgorod Republic.\n\nThereby this custom was probably also influenced from Swedish and Finnish \"brännvinsbord\" which was also the ancestor of modern smörgåsbord. A table with zakuski was kept in the houses of the Russian gentry for feeding casual visitors who travelled long distances and whose arrival time was often unpredictable. At banquets and parties, zakuski were often served in a separate room adjacent to the dining room or on a separate table in the dining room. The tradition eventually spread to other layers of society and remained in the Soviet times, but due to lack of space, they were served on the dinner table. Zakuski became thus the first course of a festive dinner.\n\nNowadays, these appetizers are commonly served at banquets, dinners, parties and receptions in countries which were formerly part of the Russian Empire including some post-Soviet states and Poland (Polish: \"zakąski\"). A broad selection of zakuski constitutes a standard first course at any feast table. Usually, zakuski are already laid on the table when guests are called to the dining room.\n\nTypical zakuski consist of cold cuts, cured fishes, mixed salads, kholodets (meat jelly), pirogs (varenyky) or pirozhki, various pickled vegetables such as tomatoes, beets, cucumbers, sauerkraut, pickled mushrooms, deviled eggs, hard cheeses, caviar, canapés, open sandwiches, and breads.\n\n"}
