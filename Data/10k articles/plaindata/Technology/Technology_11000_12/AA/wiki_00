{"id": "4155777", "url": "https://en.wikipedia.org/wiki?curid=4155777", "title": "Akhtar Hameed Khan", "text": "Akhtar Hameed Khan\n\nAkhter Hameed Khan (, pronounced ; 15 July 1914 – 9 October 1999) was a Pakistani and social scientist. He promoted participatory rural development in Pakistan and other developing countries, and widely advocated community participation in development. His particular contribution was the establishment of a comprehensive project for rural development, the Comilla Model (1959). It earned him the Ramon Magsaysay Award from the Philippines and an honorary Doctorate of law from Michigan State University.\n\nIn the 1980s he started a bottom-up community development initiative of Orangi Pilot Project, based in the outskirts of Karachi, which became a model of participatory development initiatives. He also directed many programmes, from microcredit to self-finance and from housing provision to family planning, for rural communities and urban slums. It earned him international recognition and high honours in Pakistan. Khan was fluent in at least seven languages and dialects. Apart from many scholarly books and articles, he also published a collection of poems and travelogues in Urdu.\n\nKhan was born on 15 July 1914 in Agra. He was among the four sons and three daughters of Khansaahib Ameer Ahmed Khan and Mehmoodah Begum. His father, a police inspector, was inspired by the reformist thinking of Syed Ahmed Khan. In his early age, Khan's mother introduced him to the poetry of Maulana Hali and Muhammad Iqbal, the sermons of Abul Kalam Azad, and the Sufist philosophy of Rumi. This upbringing influenced his interest in historical as well as contemporary social, economic, and political affairs.\n\nKhan attended Government High School at Jalam (Uttar Pradesh), and completed his education in 1930 at Agra College where he studied English literature and history. He read English literature, history, and philosophy for a Bachelor of Arts degree at Meerut College in 1932. At that point, his mother was diagnosed with tuberculosis. She died in the same year at the age of 36. Khan continued his studies and was awarded a Master of Arts in English Literature from Agra University in 1934. He worked as a lecturer at Meerut College before joining the Indian Civil Service (ICS) in 1936. As part of the ICS training, he was sent to read literature and history at Magdalene College, Cambridge, England. During the stay, he developed a close friendship with Choudhary Rahmat Ali.\n\nKhan married Hameedah Begum (the eldest daughter of Allama Mashriqi) in 1940. Together, they had three daughters (Mariam, Amina, and Rasheeda) and a son (Akbar). After Hameedah Begum's death in 1966, he married Shafiq Khan and had one daughter, Ayesha. During his ICS career, Khan worked as collector of revenue, a position that brought him into regular contact with living conditions in rural areas of East Bengal. The Bengal famine of 1943 and subsequent inadequate handling of the situation by the colonial rulers led him to resign from the Indian Civil Service in 1945. He wrote, \"I realised that if I did not escape while I was young and vigorous, I will forever remain in the trap, and terminate as a bureaucratic big wig.\" During this period, he was influenced by the philosophy of Nietzsche and Mashriqi, and joined the Khaksar Movement. This attachment was brief. He quit the movement and turned to Sufism. According to Khan, \"I had a profound personal concern; I wanted to live a life free from fear and anxiety, a calm and serene life, without turmoil and conflict. ... when I followed the advice of old Sufis and sages, and tried to curb my greed, my pride and aggression, fears, anxieties and conflict diminished.\"\n\nFor the next two years, Khan worked in Mamoola village near Aligarh as a labourer and locksmith, an experience that provided him with firsthand knowledge of the problems and issues of rural communities. In 1947, he took up a teaching position at the Jamia Millia, Delhi, where he worked for three years. In 1950, Khan migrated to Pakistan to teach at Islamia College, Karachi. In the same year, he was invited by the Government of Pakistan to take charge as Principal of Comilla Victoria College in East Pakistan, a position he held until 1958. During this time (1950–58) he also served as President of the East Pakistan Non-Government Teachers' Association.\n\nDuring his tenure as principal of Comilla Victoria College, Khan developed a special interest in grassroots actions. Between 1954 and 1955, he took a break to work as director of the Village Agricultural and Industrial Development (V-AID) Programme. However, he was not satisfied with the development approach adopted in the programme that was limited to the training of villagers. In 1958, he went to Michigan State University to acquire education and training in rural development. Returning in 1959, he established the Pakistan Academy for Rural Development (PARD) at Comilla on 27 May 1959 and was appointed as its founding director. He also laid foundations for the Comilla Cooperative Pilot Project in 1959. In 1963, he received a Ramon Magsaysay Award from the Government of the Philippines for his services in rural development. Khan became Vice-chairman of the board of Governors of PARD in 1964, and in the same year, was awarded an honorary Doctorate of law by Michigan State University. In 1969, he delivered a series of lectures at Woodrow Wilson School, Princeton University, based on his experience with rural cooperatives. During the visit, he established collaborative links with Arthur Lewis.\n\nOn his return to East Pakistan, Khan remained attached to the Comilla Project until 1971 when East Pakistan became Bangladesh. Eventually, Khan moved to Pakistan. PARD was renamed as Bangladesh Academy for Rural Development (BARD).\n\nFollowing his move to Pakistan, Khan was asked to implement the Comilla Model in rural settlements of North-West Frontier Province (now Khyber Pakhtunkhwa), Punjab, and Sindh. He declined the offer on the grounds that the proposals were predominantly motivated by political interests rather than the common well-being. However, he continued to advise the authorities on various aspects of rural development, such as participatory irrigation management. He worked as a research fellow at the University of Agriculture, Faisalabad from 1971 to 1972, and as Director of Rural Economics Research Project at Karachi University from 1972 to 1973. Khan went to Michigan State University as a visiting professor in 1973 and remained there until 1979. During this time, he carried on advising the Rural Development Academy at Bogra in northern Bangladesh, and the Pakistan Academy for Rural Development, Peshawar, on the Daudzai Integrated Rural Development Programme. He also travelled extensively during this period in the capacities of speaker, advisor, or consultant on rural development programmes across the world. In 1974, he was appointed as a World Bank consultant to survey rural development situations in Java, Indonesia. He also briefly worked as a visiting professor at Lund University, Harvard University, and Oxford University.\n\nIn 1980, Khan moved to Karachi and started working on the improvement of sanitary conditions in Karachi suburbs. He laid the foundations of the Orangi Pilot Project for the largest squatter community of Orangi in the city. He remained associated with this project until his death in 1999. Meanwhile, he maintained his support for rural communities around Karachi, and also helped to develop the Aga Khan Rural Support Programme. OPP became a model for participatory bottom-up development initiatives.\n\nThe Comilla Model (1959) was Khan's initiative in response to the failure of a Village Agricultural and Industrial Development (V-AID) programme that was launched in 1953 in East and West Pakistan with technical assistance from the US government. V-AID remained a government-level attempt to promote citizen participation in the sphere of rural development. Khan launched the project in 1959 on his return from Michigan, and developed a methodology of implementation in the areas of agricultural and rural development on the principle of grassroots-level participation. Initially, the aim was to provide a development model of programmes and institutions that could be replicated across the country. Advisory support in this respect was provided by experts from Harvard and Michigan State Universities, the Ford Foundation, and USAID. Practical help was also sought from Japan to improve the local farming techniques.\n\nComilla Model simultaneously addressed the problems that were caused by the inadequacy of both local infrastructure and institutions through a range of integrated programmes. The initiatives included the establishment of: a training and development centre; a road-drainage embankment works programme; a decentralized, small scale irrigation programme; and, a two-tiered cooperative system with primary cooperatives operating in the villages, and federations operating at sub-district level.\n\nAfter Khan's departure from Comilla, the cooperative's model failed in independent Bangladesh because only a few occupational groups managed to achieve the desired success. By 1979, only 61 of the 400 cooperatives were functioning. The model actually fell prey to the ineffective internal and external controls, stagnation, and diversion of funds. This prompted the subsequent scholars and practitioners in microfinance, such as Muhammad Yunus of Grameen Bank and Fazle Hasan Abed of BRAC, to abandon the cooperative approach in favour of more centralised control and service delivery structures. The new strategy targeted the poorest villagers, while excluding the 'less poor'. However, Khan's leadership skills during the course of his association with the project remained a source of inspiration for these leaders, as well as other participatory development initiatives in the country.\n\nThe Orangi poverty alleviation project (known as the Orangi Pilot Project, or OPP) was initiated by Khan as an NGO in 1980. Orangi is located on the northwest periphery of Karachi. At that time, it was the largest of the city's approximately 650 low-income squatter settlements (known as \"katchi abadi\"). The locality was first developed in 1963 as a government township of . The influx of migrants after the creation of Bangladesh swelled the settlement to about one million people crowded over an area of more than . The working class multi-ethnic population was predominantly composed of day labourers, skilled workers, artisans, small shopkeepers, peddlers and low-income white collar workers. The project proved an impetus to the socio-economic development of the population of the area. As the project director, Khan proved to be a dynamic and innovative leader. The project initially focused on creating a system of underground sewers, using local materials and labour, and succeeded in laying hundreds of kilometres of drainage pipes along with auxiliary facilities. Within a decade of the initiative, local residents had established schools, health clinics, women's work centres, cooperative stores and a credit organisation to finance enterprise projects. By 1993, OPP had managed to provide low-cost sewers to more than 72,000 houses. The project subsequently diversified into a number of programmes, including a people's financed and managed low-cost sanitation programme; a housing programme; a basic health and family planning programme; a programme of supervised credit for small family enterprise units; an education programme; and a rural development programme in the nearby villages.\n\nComparing the OPP with Comilla project, Akhter Hameed Khan once commented:\n\nThe Orangi Pilot Project was very different from the Comilla Academy. OPP was a private body, dependent for its small fixed budget on another NGO. The vast resources and support of the government, Harvard advisors, MSU, and Ford Foundation was missing. OPP possessed no authority, no sanctions. It may observe and investigate but it could only advise, not enforce.\n\nThe successful OPP model became an inspiration for other municipalities around the country. In 1999, Khan helped to create Lodhran Pilot Project (LPP) to collaborate with Lodhran municipal committee. Learning from past experiences, the project extended its scope to the whole town instead of concentrating on low-income settlements only. The municipal partnership was itself a new initiative that ensured wider civic co-operation.\n\nThe success of OPP did come at a cost for Dr Khan as his liberal views and self-help initiatives were questioned and criticised by certain interest groups. At two occasions, he was accused of blasphemy. However, all allegations against him were acquitted by the courts of law and cleared by independent religious scholars.\n\nIn 1999, Khan was visiting his family in the United States when he suffered from kidney failure. He died of myocardial infarction on 9 October in Indianapolis at the age of 85. His body was flown to Karachi on 15 October, where he was buried on the grounds of the OPP office compound.\n\nKhan's ideology and leadership skills were a source of inspiration for his students and colleagues, and continue to serve as guiding principles even after his death. Edgar Owens, who became an admirer of Khan's ideology while working at USAID's Asia Bureau, co-authored a book with Robert Shaw as a result of observations and discussions with Khan at Comilla Academy. A later study of various rural development experiences from South Asia, edited by Uphoff and Cambell (1983) was jointly dedicated to Khan and Owens.\n\nSoon after Khan's death, on 10 April 2000, the Government of Pakistan renamed the National Centre for Rural Development the Akhter Hameed Khan National Centre for Rural Development and Municipal Administration.\n\nLater in 2005, the Council of Social Sciences, Pakistan, in collaboration with the National Rural Support Programme and other institutions, announced the Akhter Hameed Khan Memorial Award. The annual cash award is given on Khan's birthday to a Pakistani author for a book on issues related to rural and urban development, peace, poverty alleviation, or gender discrimination. At the occasion of the award ceremony in 2006, a documentary film about the life and times of Akhter Hameed Khan was premiered. The film includes archival footage and interviews with family members, colleagues, and contributors and beneficiaries of the Comilla and OPP projects.\n\nThe Akhter Hameed Khan Resource Centre was established in Islamabad, under the auspices of the Institute of Rural Management, as a repository of published and digital resources on rural development. Although the Akhter Hameed Khan Resource Center (AHKRC) was initially formed in 2010 as a repository of works and writings by Khan and his mentee Shoaib Sultan Khan; since 2015 the resource center transitioned into an NGO that has established an experimental site in urban development in Dhok Hassu, Rawalpindi. The site builds on lessons from the OPP and Commilla Academy and uses the research and extension and participatory development approaches.\n\nKhan received the following civil awards:\n\nKhan was fluent in Arabic, Bengali, English, Hindi, Pali, Persian, and Urdu. He wrote several reports and monographs, mostly relating to rural development in general or his various successful and model initiatives in particular. He also published collections of poems and travelogues in Urdu.\n\n\n\n\n"}
{"id": "27105769", "url": "https://en.wikipedia.org/wiki?curid=27105769", "title": "American Council for Technology and Industry Advisory Council", "text": "American Council for Technology and Industry Advisory Council\n\nThe American Council for Technology (ACT) and Industry Advisory Council (IAC) is a non-profit public-private partnership dedicated to improving government through the application of information technology. ACT-IAC provides a forum where government and industry exchange information and collaborate on technology issues in the public sector. \n\nEstablished in 1979 as the Federation of Government Information Processing Councils (FGIPC), the ACT mission is to assist government in using information technology to improve government operations and serve the public. Governed by a board of directors composed of government executives, ACT provides a forum for government employees to collaborate on high-priority IT issues. In 1989 ACT established the Industry Advisory Council (IAC) to bring the private sector IT industry into this unique collaborative forum.\n\nACT-IAC sponsors two major events each year, the 30-year-old Management of Change Conference (MOC) and the 20-year-old Executive Leadership Conference (ELC). Other events include the three-year-old Small Business Conference (SBC) and the decades-old High Performance Computing Conference. \n"}
{"id": "44331442", "url": "https://en.wikipedia.org/wiki?curid=44331442", "title": "Architectural style", "text": "Architectural style\n\nAn architectural style is characterized by the features that make a building or other structure notable or historically identifiable. A style may include such elements as form, method of construction, building materials, and regional character. Most architecture can be classified within a chronology of styles which changes over time reflecting changing fashions, beliefs and religions, or the emergence of new ideas, technology, or materials which make new styles possible.\n\nStyles therefore emerge from the history of a society. They are documented in the subject of architectural history. At any time several styles may be fashionable, and when a style changes it usually does so gradually, as architects learn and adapt to new ideas. The new style is sometimes only a rebellion against an existing style, such as post-modernism (meaning \"after modernism\"), which has in recent years found its own language and split into a number of styles which have acquired other names.\n\nStyles often spread to other places, so that the style at its source continues to develop in new ways while other countries follow with their own twist. For instance, Renaissance ideas emerged in Italy around 1425 and spread to all of Europe over the next 200 years, with the French, Belgian, German, English, and Spanish Renaissances showing recognisably the same style, but with unique characteristics. A style may also spread through colonialism, either by foreign colonies learning from their home country, or by settlers moving to a new land. One example is the Spanish missions in California, brought by Spanish priests in the late 18th century and built in a unique style.\n\nAfter a style has gone out of fashion, revivals and re-interpretations may occur. For instance, classicism has been revived many times and found new life as neoclassicism. Each time it is revived, it is different. The Spanish mission style was revived 100 years later as the Mission Revival, and that soon evolved into the Spanish Colonial Revival.\n\nVernacular architecture works slightly differently and is listed separately. It is the native method of construction used by local people, usually using labour-intensive methods and local materials, and usually for small structures such as rural cottages. It varies from region to region even within a country, and takes mini account of national styles or technology. As western society has developed, vernacular styles have mostly become outmoded due to new technology and to national building standards.\n\nConstructing schemes of the period styles of historic art and architecture was a major concern of 19th century scholars in the new and initially mostly German-speaking field of art history. Important writers on the broad theory of style including Carl Friedrich von Rumohr, Gottfried Semper, and Alois Riegl in his \"Stilfragen\" of 1893, with Heinrich Wölfflin and Paul Frankl continued the debate into the 20th century. Paul Jacobsthal and Josef Strzygowski are among the art historians who followed Riegl in proposing grand schemes tracing the transmission of elements of styles across great ranges in time and space. This type of art history is also known as formalism, or the study of forms or shapes in art.\n\nSemper, Wölfflin, and Frankl, and later Ackerman, had backgrounds in the history of architecture, and like many other terms for period styles, \"Romanesque\" and \"Gothic\" were initially coined to describe architectural styles, where major changes between styles can be clearer and more easy to define, not least because style in architecture is easier to replicate by following a set of rules than style in figurative art such as painting. Terms originated to describe architectural periods were often subsequently applied to other areas of the visual arts, and then more widely still to music, literature and the general culture. In architecture stylistic change often follows, and is made possible by, the discovery of new techniques or materials, from the Gothic rib vault to modern metal and reinforced concrete construction. A major area of debate in both art history and archaeology has been the extent to which stylistic change in other fields like painting or pottery is also a response to new technical possibilities, or has its own impetus to develop (the \"kunstwollen\" of Riegl), or changes in response to social and economic factors affecting patronage and the conditions of the artist, as current thinking tends to emphasize, using less rigid versions of Marxist art history.\n\nAlthough style was well-established as a central component of art historical analysis, seeing it as the over-riding factor in art history had fallen out of fashion by World War II, as other ways of looking at art were developing, and a reaction against the emphasis on style developing; for Svetlana Alpers, \"the normal invocation of style in art history is a depressing affair indeed\". According to James Elkins \"In the later 20th century criticisms of style were aimed at further reducing the Hegelian elements of the concept while retaining it in a form that could be more easily controlled\".\n\nWhile many architectural styles explore harmonious ideals, Mannerism wants to take style a step further and explores the aesthetics of hyperbole and exaggeration. Mannerism is notable for its intellectual sophistication as well as its artificial (as opposed to naturalistic) qualities. Mannerism favours compositional tension and instability rather than balance and clarity. The definition of Mannerism, and the phases within it, continues to be the subject of debate among art historians.\n\nAn example of mannerist architecture is the Villa Farnese at Caprarola in the rugged country side outside of Rome. The proliferation of engravers during the 16th century spread Mannerist styles more quickly than any previous styles. A center of Mannerist design was Antwerp during its 16th-century boom. Through Antwerp, Renaissance and Mannerist styles were widely introduced in England, Germany, and northern and eastern Europe in general. Dense with ornament of \"Roman\" detailing, the display doorway at Colditz Castle exemplifies this northern style, characteristically applied as an isolated \"set piece\" against unpretentious vernacular walling.\nDuring the Mannerist Renaissance period, architects experimented with using architectural forms to emphasize solid and spatial relationships. The Renaissance ideal of harmony gave way to freer and more imaginative rhythms. The best known architect associated with the Mannerist style was Michelangelo (1475–1564), who is credited with inventing the giant order, a large pilaster that stretches from the bottom to the top of a façade. He used this in his design for the Campidoglio in Rome.\n\nPrior to the 20th century, the term \"Mannerism\" had negative connotations, but it is now used to describe the historical period in more general non-judgmental terms.\n\n\n"}
{"id": "8280424", "url": "https://en.wikipedia.org/wiki?curid=8280424", "title": "Ascom B8050 Quickfare", "text": "Ascom B8050 Quickfare\n\nAscom B8050, usually known by the name QuickFare, is an early example of a passenger-operated railway ticket issuing system, consisting of a series of broadly identical machines installed at British railway stations from 1989 onwards. The machines allow passengers to buy the most popular types of ticket themselves, without having to go to a booking office, and are therefore useful at unstaffed, partly staffed or busy stations. All QuickFare machines have now been replaced by more modern technology.\n\nThe system had its origins in various rudimentary computer-based systems developed for British Rail in the early and mid-1980s, both by Ascom Autelca and by other companies. These were classified by British Rail under the general acronym POTIS (Passenger Operated Ticket Issuing System).\n\nIllustrations of these early tickets\n\nThe tickets were printed on simple card stock with no magnetic stripe on the reverse - so data was merely printed on the front, not separately encoded as well.\n\nAutelca AG developed the B8011 and B8020 machines from the B100 Agiticket. A wider range of tickets could be purchased from these: a row of 32 buttons was programmed with various combinations of destination and ticket type (for example, \"Child Single to Gatwick Airport\" or \"Adult Cheap Day Return to Brighton\"). Coins were inserted by the passenger after the appropriate button was pressed, and tickets and change were collected from a hatch at the bottom. A separate button could be pressed to cancel the transaction at any stage. Many of these features were carried forward to the B8050 machine.\n\nA B8011 ticket<br> A B8011 machine, showing many similarities to the B8050\n\nThe B100 machine was the intermediate stage between the B8011/B8020 (which were essentially identical) and the B8050. Although most were found in the former Network SouthEast (NSE) area, a few persisted in urban areas elsewhere in England until around 2000. Such machines are believed to have been moved from NSE stations when they were supplanted by B8050s, being reprogrammed with different destination and fare information accordingly.\nA B100 ticket\n\nAfter the B8050 was developed, it was chosen by the Network SouthEast sector of British Rail as the standard self-service ticket issuing system. There were 2 variants of the B8050 machine which had either 40 or 92 destination buttons. It was decided that a large number of machines should be provided, with almost every station having at least one and major commuter and terminal stations having many. The following stations, for example, had at least eight separate machines at some point - in some cases, for many years:\n\nExisting B100 machines at NSE stations were replaced on a rolling basis between 1990 and 1994. In some cases, usually for a short time only, both types of machine would be in place simultaneously at a given station.\n\nB8050 machines offer a wider range of journey combinations than their predecessors, as they have separate sets of buttons for destinations and ticket types. A set of machines was produced with 92 destination buttons, arranged in four columns of 23, and 18 ticket type buttons in a single column. Another set of machines was manufactured with a restricted set of destination buttons (40, in four columns of ten) but the same 18 ticket type buttons. In all cases, a \"Cancel\" button is available as well. Destination buttons are green, while those for the ticket type are yellow and the \"Cancel\" button is red.\n\nTickets are credit card sized with square corners. They are printed on a continuous roll of ticket stock, which is aligned within the machine by way of a rectangular notch a quarter of the way down each ticket on the left-hand side. The machine cuts off each individual ticket from the roll after the printing process finishes, after which they drop into a large plastic-fronted hatch at the bottom (along with any change).\n\nThe tickets have orange bands at the top and bottom, in common with the stock used for travel tickets in other British railway ticket issuing systems. In British Rail days, they were identified by batch reference BR 3595/3; this changed to RSP 3595/3 after privatisation, following the creation of Rail Settlement Plan Ltd to administer the ticketing and revenue allocation systems of the post-privatisation rail network. Machines on the South West Trains network sometimes use stock with reference RSP 3595/30; a VAT number is printed on the reverse of these, above the batch reference.\n\nBefore the machine or machines at a given station were installed, an analysis was undertaken of the most popular destinations for tickets bought from that station (or, strictly speaking, tickets issued \"with that station as an origin point\" - encompassing tickets bought at the station's ticket office, if applicable; those issued on trains by conductors using SPORTIS machines; and those issued remotely). It is believed that these statistics were used in conjunction with a more long-term forecast of the most likely destinations passengers would choose, in order to establish a set of destinations to be programmed into the machine. It was not straightforward to delete, add or change destinations once they had been set: as well as the manual reprogramming required, the station names were displayed to the passenger in the form of sheets of paper pre-printed with the relevant names and aligned (behind clear plastic panels) with the buttons. These had to be reprinted whenever any details changed. As a result, it was relatively rare for the range of destinations to change.\n\nAt most stations, the range provided was largely appropriate, with all nearby stations and more distant larger places being available. There was usually a reasonable balance between places served by regular direct train services and more \"unusual\" locations. However, this was not always the case: a notable example was Portslade, near Brighton, which offered Wimbledon, more than 50 miles and at least one change of train away, but not Fishersgate - the next stop.\n\nAt many Thameslink stations north of London (West Hampstead Thameslink to Bedford), the machines were installed with many destinations in the Catford/Bromley South/Orpington areas of south-east London, because at the time these places were served by direct Thameslink services running via the Catford Loop Line. Soon afterwards, in the early 1990s, the Thameslink service pattern was considerably altered, with services south of London being concentrated on south-west London and Surrey in addition to the Brighton Main Line. Machines at affected stations were not updated with more appropriate destinations (such as Sutton), and retained the incongruous south-east London destinations until the removal of the machines in late 2006.\n\nAll stations in the Network SouthEast area offered the London \"station group\" and the One Day Travelcard. Many also featured Gatwick Airport - an important destination throughout the year, with a larger proportion of journeys than usual happening at times such as very early morning or late evening, when booking offices are more likely to be shut.\n\nEighteen \"ticket type\" buttons were provided on all machines at the time of manufacture, but in most cases a number of those have been left blank and non-functioning, albeit with the ability to be programmed with a \"ticket type\" if necessary. Typical combinations available are:\n\nMachines are time-sensitive. Thus, all Day Return buttons issue a Cheap Day Return (reduced-fare off-peak ticket) at the appropriate times of day; and tickets with Railcard discounts do not become available until the time from which the Railcard is valid. Messages concerning the validity or otherwise of tickets appear in a green LCD panel below the \"Amount to pay\" display.\n\nAll machines offer Seven Day Season Tickets, printed on separate dedicated ticket stock (batch reference BR 3595/4, and later RSP 3595/4) with dark green upper and lower bands, a white box in which \"SEASON\" or \"TRAVELCARD\" would be printed by the machine, and an area for the passenger's Photocard number to be entered manually. Because the machines take cash only and Season Tickets are expensive compared to ordinary travel tickets, it is relatively unusual to see an issued Season Ticket.\n\nIn addition, some machines have buttons (usually in the \"destinations\" section) for one or more of the following:\n\nReceipts are not issued in any format.\n\nThere are very few Ascom B8050 QuickFare machines left on the National Rail network. There are at least three machines still in use by Island Line Trains, on the Isle of Wight, at Ryde Pier Head, Ryde Esplanade and Shanklin. One at the back entrance to Birmingham New Street station, that had been out-of-use for at least a year, was eventually removed February 2009.\n\n"}
{"id": "2341226", "url": "https://en.wikipedia.org/wiki?curid=2341226", "title": "Bit-Tech", "text": "Bit-Tech\n\nbit-tech is an online magazine for computer hardware enthusiasts, gamers and case modders, based in the UK. It was founded in 2000, became a fully professional online publication in 2005, and announced its acquisition by Dennis Publishing in October 2008. Dennis Publishing then partnered the site with existing monthly publication Custom PC magazine, making Bit-Tech the online version of the magazine. At this point the two editorial teams were totally integrated. However, due to a restructure in January 2012 the website and magazine now have separate editors again, although several of the writers still contribute material to both publications. It is now owned by The Media Team.\n\nThe website caters specifically for the computer hardware enthusiast market, providing reviews and articles on higher end hardware and games. Bit-Tech is also prominent in the custom case modding scene, providing a focus point for professional and amateur case modders. Much of the site’s content and writing style revolve around this particular reader-base, and its regular readers have been responsible for some of the most well known case mods, such as Orac3 and the Blackmesa HL2 mod.\n\nOriginally bit-tech.net was designed to be a small site where people who were interested in case modding could see new ideas from the team and discuss them in the forums, due to the relatively small presence of modding at the time.\n\nIt has since diversified and, along with the trend-setting case mods, bit-tech now also features detailed reviews of computer hardware and video games, industry news and editorials. There is now increased coverage of console games, though PC games are still the major focus.\n\nWil Harris was Editor-in-Chief of bit-tech for almost six years and in February 2007, he announced that he was stepping down the end of March 2007 to move onto a fresh challenge. At the time, Wil's successor was not announced and it was not until April 2007 that Tim Smalley announced that he would be taking over as Editor with immediate effect. After Tim had successfully led the site to acquisition by Dennis Publishing in October 2008, he integrated it into the new owner's technology portfolio and then stood down as Editor in April 2010 after launching a new consumer technology website at Dennis, Expert Reviews, at the start of the year. Alex Watson took over as bit-tech's Editor with immediate effect and was replaced by former deputy editor of Custom PC James Gorbold in December 2010. In January 2012, Dennis publishing restructured the editorial team and Simon Brew took on the role of managing editor of the site. In February 2013, Simon Brew stepped down and Dennis publishing appointed Edward Chester as Editor.\n\nIn April 2014 bit-tech was acquired by David Ross, who operates HEXUS and BOXFX as brands.\n\n\"bit-tech\" first became widely known for its community of PC case modders who would re-shape and decorate PC hardware into a variety of more creative forms. Although the site has since expanded to include hardware and games reviews, it still runs regular modding coverage including the very popular Mod of the Month and Mod of the Year competitions and regular project articles. In 2012, \"bit-tech\" launched the Case Mod Index - an ever-growing database of computer mods, sorted by case manufacturers such as Cooler Master or SilverStone. You're able to see all computer mods based on a specific case, as well as browse dozens of completed projects.\n\n\"bit-tech\" has been host to some of the most popular and striking mods on the Internet, including the BlackMesa Mod (currently on show at Valve), Cygnus X1, Anemone Mod, Macro Black and Lian-Li GOO Mod.\n\n\"bit-tech\" uses an arguably more in-depth review model than many other review sites and has a strong focus on PC titles, though console and handheld reviews are increasingly common. Video game reviews do not just provide a commentary of gameplay but also include graphical analysis and a breakdown of how the game will look on different hardware. This review model means that video game reviews are typically much longer than reviews from other sites, though console reviews are a more traditional length.\n\n\"bit-tech\" employs a percentage scoring system with 'Approved' and 'Premium' awards. Unlike many review sites, \"bit-tech\" uses the full range of this scale and scores poor games harshly, with 50% used to represent average games. While the writing style of the site often leans towards New Games Journalism, this has mostly been downplayed since the site was bought by Dennis Publishing and the current writing style is similar to that of partnered magazine, Custom PC Magazine as the site and magazine are written by the same editorial team.\n\nRecently the site has moved to embrace the indie games community and has run several features exploring and supporting this side of the PC industry. Several prominent independent developers, including Introversion Software and writers from Free Radical Design have written columns for the site which explore a number of issues in and around the games industry.\n\nIn 2011 bit-tech's games section was rebranded as bit-gamer and now sits alongside the main site as a separate games website.\n\n\n"}
{"id": "598401", "url": "https://en.wikipedia.org/wiki?curid=598401", "title": "Bonnie J. Dunbar", "text": "Bonnie J. Dunbar\n\nBonnie Jeanne Dunbar (born March 3, 1949) is a former NASA astronaut. She retired from NASA in September 2005 then served as president and CEO of The Museum of Flight until April 2010. From January 2013 - December 2015, Dr. Dunbar lead the University of Houston's STEM Center (science, technology, engineering and math) and was a faculty member in the Cullen College of Engineering. Currently, she is a professor of aerospace engineering at Texas A&M University and serves as Director of the Institute for Engineering Education and Innovation (IEEI), a joint entity in the Texas A&M Engineering Experiment Station (TEES) and the Dwight Look College of Engineering at Texas A&M University.\n\nDunbar was born in Sunnyside, Washington. In 1967, she graduated from Sunnyside High School, Sunnyside, Washington. Following graduation in 1971 from the University of Washington, Dunbar worked for Boeing Computer Services for two years as a systems analyst. From 1973 to 1975, she conducted research for her master's thesis in the field of mechanisms and kinetics of ionic diffusion in sodium beta-alumina. She is a member of Kappa Delta Sorority.\n\nIn 1975, she was invited to participate in research at the Atomic Energy Research Establishment, Harwell near Oxford, England, as a visiting scientist. Her work there involved the wetting behavior of liquids on solid substrates. Following her work in England, she accepted a senior research engineer position with Rockwell International Space Division in Downey, California. Her responsibilities there included developing equipment and processes for the manufacture of the Space Shuttle thermal protection system in Palmdale, California. She also represented Rockwell International as a member of the Dr. Kraft Ehricke evaluation committee on prospective space industrialization concepts. Dunbar completed her doctorate at the University of Houston in Houston, Texas. Her multi-disciplinary dissertation (materials science and physiology) involved evaluating the effects of simulated space flight on bone strength and fracture toughness. These results were correlated to alterations in hormonal and metabolic activity. Dr. Dunbar has served as an adjunct assistant professor in Mechanical Engineering at the University of Houston.\n\nDunbar is a private pilot with over 200 hours in single engine land aircraft, has logged more than 700 hours flying time in T-38 jets as a back-seater, and has over 100 hours as co-pilot in a Cessna Citation jet. She was married to fellow astronaut Ronald M. Sega.\n\nDunbar accepted a position as a payload officer/flight controller at the Lyndon B. Johnson Space Center in 1978. She served as a guidance and navigation officer/flight controller for the Skylab reentry mission in 1979 and was subsequently designated project officer/payload officer for the integration of several Space Shuttle payloads.\n\nDunbar became a NASA astronaut in August 1981. Her technical assignments have included assisting in the verification of Shuttle flight software at the Shuttle Avionics Integration Laboratory (SAIL), serving as a member of the Flight Crew Equipment Control Board, participation as a member of the Astronaut Office Science Support Group, supporting operational development of the remote manipulator system (RMS). She has served as chief of the Mission Development Branch, as the Astronaut Office interface for \"secondary\" payloads, and as lead for the Science Support Group. In 1993, Dr. Dunbar served as Deputy Associate Administrator, Office of Life and Microgravity Sciences, NASA Headquarters, Washington, D.C. In February 1994, she traveled to Star City, Russia, where she spent 13-months training as a back-up crew member for a 3-month flight on the Russian Space Station, Mir. In March 1995, she was certified by the Russian Gagarin Cosmonaut Training Center as qualified to fly on long duration Mir Space Station flights. From October 1995 to November 1996, she was detailed to the NASA JSC Mission Operations Directorate as Assistant Director where she was responsible for chairing the International Space Station Training Readiness Reviews, and facilitating Russian/American operations and training strategies.\n\nA veteran of five space flights, Dunbar has logged more than 1,208 hours (50 days) in space. She served as a mission specialist on STS-61-A in 1985, STS-32 in 1990, and STS-71 in 1995, and was the Payload Commander on STS-50 in 1992, and STS-89 in 1998.\n\nSTS-61-A \"Challenger\" (October 30-November 6, 1985), was the West German D-1 Spacelab mission. It was the first to carry eight crew members, the largest to fly in space, and was also the first in which payload activities were controlled from outside the United States. More than 75 scientific experiments were completed in the areas of physiological sciences, materials science, biology, and navigation. During the flight, Dunbar was responsible for operating Spacelab and its subsystems and performing a variety of experiments. Her mission training included six months of experiment training in Germany, France, Switzerland, and The Netherlands. STS-61-A launched from the Kennedy Space Center, Florida, and returned to land at Edwards Air Force Base, California. Mission duration was 7 days, 44 minutes 51 seconds, traveling 2.5 million miles in 111 orbits of the Earth.\n\nSTS-32 \"Columbia\" (January 9–20, 1990), launched from the Kennedy Space Center, Florida, and returned to a night landing at Edwards Air Base in California. During the flight, the crew successfully deployed the Syncom IV-F5 satellite, and retrieved the 21,400-pound Long Duration Exposure Facility (LDEF) using the RMS. They also operated a variety of middeck experiments including the Microgravity Disturbance Experiment (MDE) using the Fluids Experiment Apparatus (FEA), Protein Crystal Growth (PCG), American Flight Echocardiograph (AFE), Latitude/Longitude Locator (L3), Mesoscale Lightning Experiment (MLE), Characterization of Neurospora Circadian Rhythms (CNCR), and the IMAX Camera. Dunbar was principal investigator for the MDE/FEA Experiment. Additionally, numerous medical test objectives, including in-flight lower body negative pressure (LBNP), in-flight aerobic exercise and muscle performance were conducted to evaluate human adaptation to extended duration missions. Mission duration was 10 days, 21 hours, 01 minute, 38 seconds, traveling 4.5 million miles in 173 orbits of the Earth.\n\nSTS-50 \"Columbia\" (June 25 to July 9, 1992). Dunbar was the Payload Commander on STS-50, the United States Microgravity Lab-1 mission which was dedicated to microgravity fluid physics and materials science. Over 30 experiments sponsored by over 100 investigators were housed in the Spacelab in the Shuttle's Payload Bay. A payload crew of four operated around-the-clock for 13 days performing experiments in scientific disciplines such as protein crystal growth, electronic and infrared detector crystal growth, surface tension physics, zeolite crystal growth, and human physiology. Mission duration was 13 days, 19 hours, 30 minutes and 4 seconds, traveling 5.7 million miles in 221 orbits of the Earth.\n\nSTS-71 \"Atlantis\" (June 27 to July 7, 1995), was the first Space Shuttle mission to dock with the Russian Space Station Mir, and involved an exchange of crews. The \"Atlantis\" was modified to carry a docking system compatible with the Russian Mir Space Station. Dunbar served as MS-3 on this flight which also carried a Spacelab module in the payload bay in which the crew performed medical evaluations on the returning Mir crew. These evaluations included ascertaining the effects of weightlessness on the cardio/vascular system, the bone/muscle system, the immune system, and the cardio/pulmonary system. Mission duration was 9 days, 19 hours, 23 minutes and 8 seconds, traveling 4.1 million miles in 153 orbits of the earth.\n\nSTS-89 \"Endeavour\" (January 22–31, 1998), was the eighth Shuttle-Mir docking mission during which the crew transferred more than 9,000 pounds of scientific equipment, logistical hardware and water from Space Shuttle \"Endeavour\" to Mir. In the fifth and last exchange of a U.S. astronaut, STS-89 delivered Andy Thomas to Mir and returned with David Wolf. Mission duration was 8 days, 19 hours and 47 seconds, traveling 3.6 million miles in 138 orbits of the Earth. Dunbar was the Payload Commander, responsible for all payload activities including the conduct of 23 technology and science experiments.\n\n\n\n"}
{"id": "12369961", "url": "https://en.wikipedia.org/wiki?curid=12369961", "title": "Butter dish", "text": "Butter dish\n\nA butter dish is defined as \"a usually round or rectangular dish often with a drainer and a cover for holding butter at table\". Before refrigerators existed, a covered dish made of crystal, silver, or china housed the butter. The first butter dish was made by Simpson, Hall, Miller, and Co. around 1880 in Connecticut, out of silver. These butter dishes were made to hold the traditional round shape of butter at the time and came with an \"ice chamber\" to keep the butter cold. Another type of butter dish, a French butter dish, keeps butter fresh by using water to keep the butter away from the air, thereby keeping it fresh. The water is placed into the base of the dish and the butter is put into a bell-shaped lid, creating an air seal. \n"}
{"id": "58411753", "url": "https://en.wikipedia.org/wiki?curid=58411753", "title": "CalAmp", "text": "CalAmp\n\nCalAmp is an Irvine, California-based provider of IoT software applications, cloud services, data intelligence and networked telematics products and services. The company's technology includes edge computing devices and SaaS-based applications for remotely tracking and managing vehicles and consumer products. The company also owns the LoJack Stolen Vehicle Recovery System and provides connected car and lot management products. \n\nCalAmp was founded as California Amplifier Inc. in Newbury Park, California in 1981, by Jacob Inbar and David Nichols, who worked together at a microwave division of Eaton Corporation. The company originally made amplifiers and other equipment used to transmit microwave signals for satellite video and broadband communications. The company began trading on NASDAQ in 1983.\n\nBy 1986, the company had relocated to Camarillo, California, and stopped making amplifiers for the consumer market.\n\nIn 1999, the company entered the direct broadcast satellite (DBS) market by acquiring Texas-based Gardiner Group, a satellite dish component provider.\n\nIn December 2003, the company acquired communications software company Vytek Corp, for $USD76.8 million.\n\nIn March 2004, the company relocated to Oxnard, California. In August, the company changed its name to CalAmp Corp.\n\nIn May 2006, the company acquired Montreal, Canada-based wireless radio company Dataradio, to expand its wireless data communications business for public safety and machine to machine (M2M) applications. It also acquired the mobile resource management line from Carlsbad, California-based location tracking company TechnoCom to offer enterprise asset tracking and fleet management applications.\n\nIn 2007, the company acquired the Aercept Vehicle Tracking business from wireless telematics service provider AirIQ. \n\nBy 2010, the company was focused on selling IoT hardware and DBS solutions.\n\nIn December 2012, the company announced the acquisition of Herndon, Virginia-based fleet management application provider Wireless Matrix Corp for $USD53 million. \n\nIn February 2013, the company announced a stock offering that was intended in part to fund the Wireless Matrix Corp purchase. \n\nIn April 2015, CalAmp bought telematics startup Crashboxx, a provider of a vehicle risk management system for insurance companies and fleet operators. The product is used for crash response and accident reconstruction to minimize costs and mitigate fraud.\n\nBy 2016, the company had phased out its DBS business and shifted its focus to SaaS-based telematics products and services. In February, CalAmp announced it was acquiring stolen vehicle recovery company LoJack Corporation, for USD$134 million, and the deal closed in March. In April, the company announced it was moving its headquarters from Oxnard to Irvine, California, to take advantage of the area's tech environment. In September, the company introduced the LoJack LotSmart automotive dealer inventory management solution and LoJack SureDrive connected car app.\n\nThe company combines connected telematics products and cloud technology with Software as a Service (SaaS) applications to collect and assess data from mobile assets, cargo and companies. Micro services for specific tasks are delivered through the company's applications or as standalone services.\n\n\n\n\n\nLoJack Corporation was founded in 1986 in Medfield, Massachusetts, by William Reagan, a former Medfield police commissioner. Reagan had patented the LoJack system in 1979, and chose its name to imply the opposite of \"hijack\". The system used a hidden car-mounted transceiver, and a tracking computer installed in police cars and aircraft, operating on a dedicated tracking frequency set aside by the Federal Communications Commission. Reagan served as the company's first CEO and Chairman.\n\nIn 1998, the company began offering its tracking system to the heavy machinery and construction industry, including entering into an agreement with Caterpillar.\n\nIn March 2012, the company moved its headquarters to Canton, Massachusetts.\n\nBy 2013, the LoJack system was reportedly operating in 28 states and the District of Columbia and in more than 30 countries. The company reported that more than 1,800 U.S. law enforcement agencies had LoJack tracking computers in their police vehicles. In November 2013, the company announced they were expanding tracking capabilities to parents, auto makers and insurance companies.\n\nIn March 2016, the company was acquired by CalAmp for $134 million.\n\n"}
{"id": "11111531", "url": "https://en.wikipedia.org/wiki?curid=11111531", "title": "Chip heater", "text": "Chip heater\n\nThe chip heater is a single point, tankless, domestic hot water system popular in Australia and New Zealand from the 1880s until the 1960s. Examples of this form of domestic water heating are still in current use.\n\nThe chip heater consisted of a cylindrical unit with a fire box and flue, through which a water pipe was run. Water was drawn from a cold water tank and circulated through the fire box. When heated, the water was drawn off to the area where it was used, typically in a bath or shower. There often was an ash box under the fire box, which allowed air under the fire, as well as various dampers in the flue.\n\nThe fire box was relatively small and fed by tinder, such as newspaper, pine cones, small twigs or chips from a wood heap. The use of \"chips\" from the wood pile gave the chip heater its name.\n\nWater had to be run at a trickle in order to heat up to a desirable temperature. The rate of combustion was controlled by the flues and the ash box. With lots of fuel and open flues the water could boil quickly, which was not a desirable result. With practice the correct combination of fuel, flue settings and water flow could result in enough hot water for a shower or bath in approximately 20 minutes.\n\nThe chip heater is embedded in Australian and New Zealand social history as many people can remember using one or someone who had one. The precise history of the chip heater is unclear.\n\nThe original idea surely must be derived from vertical steam boilers. Miles Lewis notes that the \"instantaneous water heaters,\" which were being sold by Douglas & Sons of Melbourne by 1888 were probably chip heaters. In 1892, an advertisement in Melbourne promised that Fischer's Patent Bath Heater could be heated with wood in three minutes at the cost of one farthing.\n\nCatalogs from the National Radiator Company between 1913 and 1919, which were marketed in Australia, do not show chip heaters. This suggests that the chip heater was a local innovation.\n\nThe chip heater was very similar to the gas and kerosene powered “geyser” hot water heaters popular in Australian suburban residences from the 1920s. The main difference was the fuel source. The Australian producer Metters Limited supplied gas geysers for city clients (who had access to gas) and chip heaters for country clients.\n\nThere were a number of manufacturers and brands. According to Professor Miles Lewis, the early twentieth century brands included the Royal, Little Hero, Silver Ace, Kangaroo, Empire and Little Wonder. Peter Wood recalls a “Torrens” brand being popular in Adelaide.\n\nMetters had a variety of chip heaters in its 1936 catalog, including oil and kerosene-powered chip heaters. Metters claimed a flow of 2 gallons of “very hot water” per minute.\n\nArcher, John, 1998, Your home: the inside story of the Australian house, Port Melbourne, Lothian.\n\nMetters Ltd 1936 \"Metters' bath heater and hot water service : sectional catalogue\", Metters Ltd.\n\nOliver, Julie. \"The Australian home beautiful: from Hills hoist to high rise\", McMahon's Point, N.S.W. Home Beautiful, 1999.\n\nPostings on the NSW Heritage Office Heritage Advisors Discussion Group by Peter Benkendorff, David Beauchamp, Susan Duyker, Elizabeth Roberts and Peter Woods, April 2007.\n\nPosting on Engineering Heritage discussion group by Professor Miles Lewis 26 April 2007\n"}
{"id": "10998605", "url": "https://en.wikipedia.org/wiki?curid=10998605", "title": "Currency-counting machine", "text": "Currency-counting machine\n\nA currency-counting machine is a machine that counts money—either stacks of banknotes or loose collections of coins. Counters may be purely mechanical or use electronic components. The machines typically provide a total count of all money, or count off specific batch sizes for wrapping and storage.\n\nCurrency counters are commonly used in vending machines to determine what amount of money has been deposited by customers.\n\nIn some modern automated teller machines, currency counters allow for cash deposits without envelopes, since they can identify which bills have been inserted instead of just how many. The user is given the chance to review the automatic counter's idea of the quantity and kinds of the inserted banknotes before the deposit is complete.\n\nBasic banknote counters provide a total count of the notes in the supply hopper. More advanced counters can identify different bill denominations to provide a total currency value of mixed banknotes, including those that are upside down. Some banknote counters can also detect counterfeit bills either magnetically and/or using blacklight. Blacklight (UV) based detectors exploit the fact that in many countries, real banknotes have fluorescent symbols on them that only show under a black light. Also, the paper used for printing money does not contain any of the brightening agents which make commercially available papers fluoresce under black light. Both features make counterfeit notes both easier to detect and more difficult to successfully produce.\n\nA stack of bills are placed in a compartment of the machine, and then one bill at a time is mechanically pulled through the machine. By counting the number of times a beam of light is interrupted, the machine can count the bills. By comparing an image of each bill to pattern recognition criteria, the machine can figure out the denominations of the bills and how much genuine money was placed in the compartment.\n\nFully electronic counters that are able to count batches of notes or of coins without having to process them individually, were introduced in Great Britain in 1980 and are now widely used by banks, retailers and food service outlets in many parts of the world. They are faster and more versatile than the traditional notes-only & coins-only equipments, but cannot detect counterfeits.\n\nA coin sorter is a device which sorts a random collection of coins into separate bins for various denominations. Coin sorters are typically specific to the currency of certain countries due to different currencies often issuing similarly sized coins of different value. A sorter usually makes no attempt at counting, providing only collections of uncounted coins to be separately passed through a counter.\n\nThe phrase \"coin counter\" may refer to a device which both sorts and counts coins at the same time, or only counts presorted coins that are all the same size..\n\nA typical counter of presorted coins uses a bowl with flat spinning disc at the bottom to distribute coins around the bowl perimeter. An opening in the edge of the bowl is only wide enough to accept one coin at a time. Coins either pass through a light-beam counter, or are pushed through a spring-loaded cam that only accepts one coin at a time.\n\nThe first ever recorded currency-counting machine was invented in 1958 in China, created by a small-time banker Zhi Tian Sie, who entered it in a contest. He won 3rd place. Zhi died at the age of 30 and his model was lost until recently rediscovered by the EPR when tearing down his home.\n\n\n"}
{"id": "21784317", "url": "https://en.wikipedia.org/wiki?curid=21784317", "title": "Direct and indirect band gaps", "text": "Direct and indirect band gaps\n\nIn semiconductor physics, the band gap of a semiconductor is of two types, a direct band gap or an indirect band gap. The minimal-energy state in the conduction band and the maximal-energy state in the valence band are each characterized by a certain crystal momentum (k-vector) in the Brillouin zone. If the k-vectors are the same, it is called a \"direct gap\". If they are different, it is called an \"indirect gap\". The band gap is called \"direct\" if the crystal momentum of electrons and holes is the same in both the conduction band and the valence band; an electron can directly emit a photon. In an \"indirect\" gap, a photon cannot be emitted because the electron must pass through an intermediate state and transfer momentum to the crystal lattice. \n\nExamples of direct bandgap material includes some III-V materials such as InAs, GaAs. Indirect bandgap materials include Si, Ge. Some III-V materials are indirect bandgap as well, for example AlSb.\n\nInteractions among electrons, holes, phonons, photons, and other particles are required to satisfy conservation of energy and crystal momentum (i.e., conservation of total k-vector). A photon with an energy near a semiconductor band gap has almost zero momentum. One important process is called radiative recombination, where an electron in the conduction band annihilates a hole in the valence band, releasing the excess energy as a photon. This is possible in a direct band gap semiconductor if the electron has a k-vector near the conduction band minima (the hole will share the same k-vector), but not possible in an indirect band gap semiconductor, as photons cannot carry crystal momentum, and thus conservation of crystal momentum would be violated. For radiative recombination to occur in an indirect band gap material, the process must also involve the absorption or emission of a phonon, where the phonon momentum equals the difference between the electron and hole momentum. (It can also, instead, involve a crystallographic defect, which performs essentially the same role.) The involvement of the phonon makes this process much less likely to occur in a given span of time, which is why \"radiative recombination is far slower in indirect band gap materials than direct band gap ones\". This is why light-emitting and laser diodes are almost always made of direct band gap materials, and not indirect band gap ones like silicon.\n\nThe fact that radiative recombination is slow in indirect band gap materials also means that, under most circumstances, radiative recombinations will be a small proportion of total recombinations, with most recombinations being non-radiative, taking place at point defects or at grain boundaries. However, if the excited electrons are prevented from reaching these recombination places, they have no choice but to eventually fall back into the valence band by radiative recombination. This can be done by creating a dislocation loop in the material. At the edge of the loop, the planes above and beneath the \"dislocation disk\" are pulled apart, creating a negative pressure, which raises the energy of the conduction band substantially, with the result that the electrons cannot pass this edge. Provided that the area directly above the dislocation loop is defect-free (no non-radiative recombination possible), the electrons will fall back into the valence shell by radiative recombination, thus emitting light. This is the principle on which \"DELEDs\" (Dislocation Engineered LEDs) are based.\n\nThe exact reverse of radiative recombination is light absorption. For the same reason as above, light with a photon energy close to the band gap can penetrate much farther before being absorbed in an indirect band gap material than a direct band gap one (at least insofar as the light absorption is due to exciting electrons across the band gap).\n\nThis fact is very important for photovoltaics (solar cells). Silicon is the most common solar-cell material, despite the fact that it is indirect-gap and therefore does not absorb light very well. Silicon solar cells are typically hundreds of microns thick; if it was much thinner, much of the light (particularly in the infrared) would simply pass through. By comparison, thin-film solar cells are made of direct band gap materials (such as CdTe, CIGS or CZTS), which absorb the light in a much thinner region, and consequently can be made with a very thin active layer (often less than 1 micron thick).\n\nThe absorption spectrum of an indirect band gap material usually depends more on temperature than that of a direct material, because at low temperatures there are fewer phonons, and therefore it is less likely that a photon and phonon can be simultaneously absorbed to create an indirect transition. For example, silicon is opaque to visible light at room temperature, but transparent to red light at liquid helium temperatures, because red photons can only be absorbed in an indirect transition.\n\nA common and simple method for determining whether a band gap is direct or indirect uses absorption spectroscopy. By plotting certain powers of the absorption coefficient against photon energy, one can normally tell both what value the band gap has, and whether or not it is direct.\n\nFor a direct band gap, the absorption coefficient formula_1 is related to light frequency according to the following formula:\nwhere:\n\nThis formula is valid only for light with photon energy larger, but not too much larger, than the band gap (more specifically, this formula assumes the bands are approximately parabolic), and ignores all other sources of absorption other than the band-to-band absorption in question, as well as the electrical attraction between the newly created electron and hole (see exciton). It is also invalid in the case that the direct transition is forbidden, or in the case that many of the valence band states are empty or conduction band states are full.\n\nOn the other hand, for an indirect band gap, the formula is:\nwhere:\n\nTherefore, if a plot of formula_7 versus formula_26 forms a straight line, it can normally be inferred that there is a direct band gap, measurable by extrapolating the straight line to the formula_27 axis. On the other hand, if a plot of formula_7 versus formula_29 forms a straight line, it can normally be inferred that there is an indirect band gap, measurable by extrapolating the straight line to the formula_27 axis (assuming formula_31).\n\nIn some materials with an indirect gap, the value of the gap is negative. The top of the valence band is higher than the bottom of the conduction band in energy. Such materials are known as semimetals.\n\n"}
{"id": "3167251", "url": "https://en.wikipedia.org/wiki?curid=3167251", "title": "Electrolier", "text": "Electrolier\n\nElectrolier was the name for a fixture, usually pendent from the ceiling, for holding electric lamps. The word is analogous to chandelier, from which it was formed. For a fine poetical if somewhat confusing description of such a lamp in a Metropolitan Railway (\"Early Electric\") station dining room, see Sir John Betjeman's poem \"The Metropolitan Railway - Baker Street Station Buffet\" from his collection \"A Few Late Chrysanthemums\" (1954): \n\"Early Electric! With what radiant hope / Men formed this many-branched electrolier, / Twisted the flex around the iron rope / And let the dazzling vacuum globes hang clear, / And then with hearts the rich contrivance fill’d / Of copper, beaten by the Bromsgrove Guild.\"\n"}
{"id": "3631020", "url": "https://en.wikipedia.org/wiki?curid=3631020", "title": "Extract", "text": "Extract\n\nAn extract is a substance made by extracting a part of a raw material, often by using a solvent such as ethanol or water. Extracts may be sold as tinctures, absolutes or in powder form.\n\nThe aromatic principles of many spices, nuts, herbs, fruits, etc., and some flowers, are marketed as extracts, among the best known of true extracts being almond, cinnamon, cloves, ginger, lemon, nutmeg, orange, peppermint, pistachio, rose, spearmint, vanilla, violet, and wintergreen.\n\nThe majority of natural essences are obtained by extracting the essential oil from the blossoms, fruit, roots, etc., or the whole plants, through four techniques:\n\n\nThe distinctive flavors of nearly all fruits, in the popular acceptance of the word, are desirable adjuncts to many food preparations, but only a few are practical sources of sufficiently concentrated flavor extract. The most important among those that lend themselves to \"pure\" extract manufacture include lemons, oranges, and vanilla beans.\n\nThe majority of concentrated fruit flavors such as banana, cherry, peach, pineapple, raspberry and strawberry, are produced by combining a variety of esters with special oils. The desired colors are generally obtained by the use of dyes. Among the esters most generally employed are ethyl acetate and ethyl butyrate. The chief factors in the production of artificial banana, pineapple, and strawberry extract are amyl acetate and amyl butyrate.\n\nArtificial extracts generally do not possess the delicacy of natural fruit flavor, but usually taste sufficiently similar to be useful when true essences are unobtainable or too expensive.\n\n\n"}
{"id": "43471605", "url": "https://en.wikipedia.org/wiki?curid=43471605", "title": "Extraordinary magnetoresistance", "text": "Extraordinary magnetoresistance\n\nExtraordinary magnetoresistance (EMR) is a geometrical magnetoresistance effect discovered in 2000, where the change in electrical resistance upon the application of a large magnetic field can be greater than 1,000,000% at room temperature (orders of magnitude greater than other magnetoresistance effects such as GMR and CMR). The effect occurs in semiconductor-metal hybrid systems when a transverse magnetic field is applied. Without a magnetic field the system is in a low-resistance state with most of the current flow directed through the metallic region. Upon the application of a large magnetic field the system switches to a state of much higher electrical resistance, due to the Hall angle approaching 90°, with the current flow inside the metallic region dramatically reduced. The effect is influenced greatly by the system geometry, with an enhancement of over four orders of magnitude shown to be possible with an alternative branched geometry. Since the EMR effect occurs at room temperature and does not rely on magnetic materials it has many possible benefits for applications including in the read heads of future hard disk drives.\n"}
{"id": "40248160", "url": "https://en.wikipedia.org/wiki?curid=40248160", "title": "Field-programmable object array", "text": "Field-programmable object array\n\nA field-programmable object array (FPOA) is a class of programmable logic device designed to be modified or programmed after manufacturing. They are designed to bridge the gap between ASIC and FPGA. They contain a grid of programmable silicon objects. Arrix range of FPOA contained three types of silicon objects arithmetic logic units (ALUs), register files (RFs) and multiply-and-accumulate units (MACs). Both the objects and interconnects are programmable.\n\nThe device was intended to bridge the gap between field-programmable gate arrays (FPGAs) and application-specific integrated circuits (ASICs). The design goal was to combine the programmability of FPGAs and the performance of ASICs. FPGAs, although programmable, lack performance; they may only be clocked to few hundreds of megahertz and most FPGAs operated below 100 MHz. FPGAs did not offer deterministic timing and the maximum operating frequency depends on the design. ASICs offered good performance but they could not be modified and they were very costly. The FPOA had a programmable architecture deterministic timing and gigahertz performance. The FPOA was designed by Douglas Pihl who had this idea when working on a DARPA funded project. He founded MathStar in 1997 to manufacture FPOAs and the idea was patented in 2004. The first FPOA prototypes were made in 2005 and first batch of FPOA chips were fabricated in 2006.\n\nFPOAs have a core grid of silicon objects or core objects. These objects are connected through a synchronous interconnect. Each core object also has a supporting structures for clock synchronization,BIST and the like .The core is surrounded by peripheral circuitry that contains memory and I/O. An interface circuitry connects the objects to rest of FPOA. Exact number of each type of object and its arrangement are specific to a given family. There are two types of communication: nearest member and \"party-line\". Nearest member is used to connect a core to nearest core object and party line is used to connect remote objects. There are 8 nearest neighbor interconnects per object and offers transmission speed on one object hop per clock cycle. There are 10 party line interconnect per object that offers transmission speed of four object hops per clock cycle.\n\nFPOAs may be used almost anywhere an FPGA is used, broadly in all hardware acceleration tasks including digital signal processing, medical imaging, computer vision, speech recognition, cryptography, bioinformatics, computer hardware emulation, and aerospace. Since FPOAs are build around fast and optimized silicon objects they offer higher performance in flat field error correction, fast Fourier transform computation, medical imaging, machine vision, image encoding and decoding, video encoding and decoding and artificial intelligence acceleration to name a few.\n\nIn FPOA we work at silicon object level a higher level than the gate level used in FPGA. This eases the learning curve and also speeds up development. Programming is done in System C. The Arrix Family released in 2006 was supported by FPOA design software, which enabled designers to create, verify, program and debug their algorithms on the devices.Summit Design's Visual Elite tool was used for behavioural simulation. MathStar's COAST (COnnection and ASsignment Tool) offered a graphical environment for floor-planning and placement it compiled to an intermediate code that maps to hardware resources. The Object compiler generated the file to be loaded into the FPGA. In 2007 MathStar struck a partnership with mentor graphics and subsequent release use Visual Elite editor from Mentor Graphics for behavioural simulation and functional verification. FPOAs also offered IP core library IP partners included professionals in the video market as well as machine vision market.\n\nMathStar the producer of FPOAs never posted a profit and the company decided to shut down production in May 2008. MathStar was merged into Sajan Inc. in 2010 and Sajan thus acquired MathStar's patent including that of FPOAs. In November 2011 Sajan sold several of MathStar's patent including some on FPOAs to OLK Grun GmbH.\n"}
{"id": "8925435", "url": "https://en.wikipedia.org/wiki?curid=8925435", "title": "Field dressing (hunting)", "text": "Field dressing (hunting)\n\nField dressing is the process of removing the internal organs of hunted game, and is a necessary step in preserving meat from animals harvested in the wild. Field dressing must be done as soon as possible in order to ensure rapid body heat loss, and prevent bacteria from growing on the surface of the carcass. Field dressing helps maintain the overall quality of the meat. It also makes it considerably easier for a hunter to carry larger game from the hunt area.\n\nMost hunters use a sharp knife to accomplish their purpose. Other tools can be used such as axes or saws. However, the fact that harvesting locations are generally in remote areas makes the transporting and use of larger tools impractical.\n\nUsing a knife specifically designed for field dressing and the use of surgical gloves can greatly aid in sanitation.\n\nChronic wasting disease (CWD) is a rare neurological disease and has been found in a minute percentage of deer and elk in certain geographical areas in Canada and the United States. Although there have been reports in the popular press of humans being affected by CWD, a study by the Centers for Disease Control and Prevention (CDC) suggests that \"[m]ore epidemiologic and laboratory studies are needed to monitor the possibility of such transmissions.\"\nThe epidemiologcial study further concludes that, \"[a]s a precaution, hunters should avoid eating deer and elk tissues known to harbor the CWD agent (e.g., brain, spinal cord, eyes, spleen, tonsils, lymph nodes) from areas where CWD has been identified.\" Tests have also been developed to check for the presence of CWD.\n\n"}
{"id": "13695130", "url": "https://en.wikipedia.org/wiki?curid=13695130", "title": "FilterKeys", "text": "FilterKeys\n\nFilterKeys is a feature of Microsoft Windows. It is an accessibility function that tells the keyboard to ignore brief or repeated keystrokes, in order to make typing easier for users with hand tremors.\n\nMicrosoft first introduced FilterKeys with Windows 95. The feature is also used on later versions of Windows.\n\nHold the right key for 8 seconds. This feature can also be turned on and off via the Accessibility icon in the Windows Control Panel.\n\n\n"}
{"id": "53738672", "url": "https://en.wikipedia.org/wiki?curid=53738672", "title": "Gel wipe", "text": "Gel wipe\n\nGel wipe is a moisturizing gel applied to dry toilet paper for cleaning purposes like personal hygiene or to reduce skin irritation from diarrhea. It is an alternative to wet wipes.\n\nEstonian Siim Saat is seen as the inventor of gel wipe in 2011. In 2016 he was nominated among 7 healthcare startup entrepreneurs in the world by HSC1 (Healthcare Startup Society in London) Gel wipe is seen as the solution to wet wipe pollution.\n\nAlthough marketed primarily for wiping adults and baby’s bottoms, it’s not uncommon to use it against skin rash, in the case of diarrhea or even as a substitute for water and soap on hiking trips.\n\nGel Wipes began to be marketed as complimentary hygiene product for toilet paper by SATU laboratory, as a luxury option by St Joseph’s Toiletries or hipster product by Zum Bum. and Zero Taboos that makes Wipegel Many adults now use gel wipe with toilet paper as an alternative to wet wipe that are causing a lot of environmental and sewer problems. All wet wipes sold as \"flushable\" in the UK have so far failed the water industry's disintegration tests, the BBC has found.\nGel wipe is popular among travelers and hikers, outdoor festivals as an upgrade for communal toilet and toilets.\n\n"}
{"id": "2955951", "url": "https://en.wikipedia.org/wiki?curid=2955951", "title": "Grid-leak detector", "text": "Grid-leak detector\n\nA grid leak detector is an electronic circuit that demodulates an amplitude modulated alternating current and amplifies the recovered modulating voltage. The circuit utilizes the non-linear cathode to control grid conduction characteristic and the amplification factor of a vacuum tube. Invented by Lee De Forest around 1912, it was used as the detector (demodulator) in the first vacuum tube radio receivers until the 1930s.\n\nEarly applications of triode tubes (\"Audions\") as detectors usually did not include a resistor in the grid circuit. First use of a resistance to discharge the grid condenser in a vacuum tube detector circuit may have been by Sewall Cabot in 1906. Cabot wrote that he made a pencil mark to discharge the grid condenser, after finding that touching the grid terminal of the tube would cause the detector to resume operation after having stopped. \nEdwin H. Armstrong, in 1915, describes the use of \"a resistance of several hundred thousand ohms placed across the grid condenser\" for the purpose of discharging the grid condenser.\nThe heyday for grid leak detectors was the 1920s, when battery operated, multiple dial tuned radio frequency receivers using low amplification factor triodes with directly heated cathodes were the contemporary technology. The Zenith Models 11, 12, and 14 are examples of these kinds of radios. When screen-grid tubes became available for new designs in 1927, most manufacturers switched to plate detectors, and later to diode detectors. \nThe grid leak detector has been popular for many years with amateur radio operators and shortwave listeners who construct their own receivers.\n\nThe stage performs two functions:\n\n\nThe control grid and cathode are operated as a diode while at the same time the control grid voltage exerts its usual influence on the electron stream from cathode to plate.\n\nIn the circuit, a capacitor (the \"grid condenser\") couples a radio frequency signal (the carrier) to the control grid of an electron tube. The capacitor also facilitates development of dc voltage on the grid. The impedance of the capacitor is small at the carrier frequency and high at the modulating frequencies.\n\nA resistor (the \"grid leak\") is connected either in parallel with the capacitor or from the grid to the cathode. The resistor permits dc charge to \"leak\" from the capacitor and is utilized in setting up the grid bias.\n\nAt small carrier signal levels, the grid to cathode space exhibits non-linear resistance. Grid current occurs during 360 degrees of the carrier frequency cycle. The grid current increases more during the positive excursions of the carrier voltage than it decreases during the negative excursions, due to the parabolic grid current versus grid voltage curve in this region. This asymmetrical grid current develops a dc grid voltage that includes the modulation frequencies. In this region of operation, the demodulated signal is developed in series with the dynamic grid resistance formula_1, which is typically in the range of 50,000 to 250,000 ohms. formula_1 and the grid leak resistance along with the grid condenser and the grid capacitance form a low pass filter that determines the audio frequency bandwidth at the grid.\n\nAt carrier signal levels large enough to make conduction from cathode to grid cease during the negative excursions of the carrier, the detection action is that of a linear diode detector. Grid current occurs only on the positive peaks of the carrier frequency cycle. The coupling capacitor will acquire a dc charge due to the rectifying action of the cathode to grid path. The capacitor discharges through the resistor (thus \"grid leak\") during the time that the carrier voltage is decreasing. The dc grid voltage will vary with the modulation envelope of an amplitude modulated signal.\n\nThe plate current is passed through a load impedance chosen to produce the desired amplification in conjunction with the tube characteristics. In non-regenerative receivers, a capacitor of low impedance at the carrier frequency is connected from the plate to cathode to prevent amplification of the carrier frequency.\n\nThe capacitance of the grid condenser is chosen to be around ten times the grid input capacitance and is typically 100 to 300 picofarads (pF), with the smaller value for screen grid and pentode tubes.\n\nThe resistance and electrical connection of the grid leak along with the grid current determine the grid bias. For operation of the detector at maximum sensitivity, the bias is placed near the point on the grid current versus grid voltage curve where maximum rectification effect occurs, which is the point of maximum rate of change of slope of the curve. If a dc path is provided from the grid leak to an indirectly heated cathode or to the negative end of a directly heated cathode, negative initial velocity grid bias is produced relative to the cathode determined by the product of the grid leak resistance and the grid current. For certain directly heated cathode tubes, the optimum grid bias is at a positive voltage relative to the negative end of the cathode. For these tubes, a dc path is provided from the grid leak to the positive side of the cathode or the positive side of the \"A\" battery; providing a positive fixed bias voltage at the grid determined by the dc grid current and the resistance of the grid leak.\n\nAs the resistance of the grid leak is increased, the grid resistance formula_1 increases and the audio frequency bandwidth at the grid decreases, for a given grid condenser capacitance.\n\nThe dc voltage at the plate is chosen for operation of the tube at the same plate current usually used in amplifier operation and is typically less than 100 volts.\n\nThe grid leak detector can be optimized for maximum input signal capability rather than detection sensitivity, in which case the time constant of the grid leak and condenser must be shorter than the period of the highest audio frequency to be reproduced. Grid leak detection optimized for larger input signals is known as \"power grid detection\" or \"grid leak power detection\". A grid leak of around 250,000 ohms is suitable and a tube requiring comparatively large grid voltage for plate current cutoff is of advantage (usually a low amplification factor triode). The peak 100 percent modulated input signal voltage the grid leak detector can demodulate without excess distortion is about one half of the projected cutoff bias voltage formula_4, corresponding to a peak unmodulated carrier voltage of about one quarter of the projected cutoff bias.\n\nTetrode and pentode tubes provide significantly higher grid input impedance than triodes, resulting in less loading of the circuit providing the signal to the detector. Tetrode and pentode tubes also produce significantly higher audio frequency output amplitude at small carrier input signal levels (around one volt or less) in grid leak detector applications than triodes.\n\n\nOne potential disadvantage of the grid leak detector, primarily in non-regenerative circuits, is that of the load it can present to the preceding circuit. The radio frequency input impedance of the grid leak detector is dominated by the tube's grid input impedance, which can be on the order of 6000 ohms or less for triodes, depending on tube characteristics and signal frequency. Other disadvantages are that it can produce more distortion and is less suitable for input signal voltages over a volt or two than the plate detector or diode detector .\n\n\n"}
{"id": "48708998", "url": "https://en.wikipedia.org/wiki?curid=48708998", "title": "Human resource management system", "text": "Human resource management system\n\nA Human Resource Management System or HRIS (Human Resource Information System) is a form of HR software that combines a number of systems and processes to ensure the easy management of human resources, business processes and data. Human Resources software is used by businesses to combine a number of necessary HR functions, such as storing employee data, managing payrolls, recruitment processes, benefits administration, and keeping track of attendance records. It ensures everyday Human Resources processes are manageable and easy to access. It merges human resources as a discipline and, in particular, its basic HR activities and processes with the information technology field, whereas the programming of data processing systems evolved into standardized routines and packages of Enterprise Resource Planning (ERP) software. On the whole, these ERP systems have their origin from software that integrates information from different applications into one universal database. The linkage of its financial and human resource modules through one database is the most important distinction to the individually and proprietarily developed predecessors, which makes this software application both rigid and flexible.\n\nHuman Resource Information Systems provide a means of acquiring, storing, analyzing and distributing information to various stakeholders. HRIS enable improvement in traditional processes and enhance strategic decision-making. The wave of technological advancement has revolutionized each and every space of life today, and HR in its entirety was not left untouched. Early systems were narrow in scope, typically focused on a single task, such as improving the payroll process or tracking employees' work hours. Today's systems cover the full spectrum of tasks associated with Human Resources departments, including tracking and improving process efficiency, managing organizational hierarchy, and simplifying financial transactions of all types. In short, as the role of Human Resources departments expanded in complexity, HR technology systems evolved to fit these needs.\n\nThe trend of automating payroll and workforce management processes began during the 1970s when due to limited technology and Mainframe computers, companies were still relying on manual entry to conduct employee evaluation and to digitize reporting.\n\nThe first ERP system which integrated HR functions was SAP R/2 (later to be replaced by R/3 and S/4hana), introduced in 1979. This system gave users the possibility to combine corporate data in real time, and regulate processes from a single mainframe environment. Many of today’s popular HR systems still offer considerable ERP and payroll functionality.\n\nThe first completely HR-centered client-server system for the enterprise market was PeopleSoft, released in 1987 and later bought by Oracle. (In the UK 'Compel' was released by CIPHR in 1983 as a dedicated HR Management System). Hosted and updated by clients, PeopleSoft replaced the mainframe environment concept and gained a huge popularity that preserved it on the scene for many years to come. The system is still active today, while Oracle has also developed multiple similar BPM systems to automate essential corporate operations.\n\nBeginning with the late 1990s, HR vendors started offering cloud-hosted HR solutions to make this technology more accessible to small and remote teams. Instead of a client-server, companies began using online accounts on web-based portals to access their employees’ performance, and track accomplishments regardless of their location.\n\nThe beginning of 2000 marked a new and advantageous concept in HR development. More and more systems were tackling specific tasks such as recruitment or benefits administration, including best of breed systems that replaced the one-size-fits-all ERP + HR formula.\n\nIn 2014, companies used the benefits from the cloud hosting milestone to transfer HR functionality on mobile devices. Ever since popular vendors have been releasing special Android and iPad/iPhone applications to meet the needs of all teams and businesses.\n\nIn 2015, HR software users got acquainted with gamification technology namely systems that attach an entertaining dimension to traditional HR operations, and motivate employees to perform better by awarding them with badges and bonuses.\n\nAnother popular innovation related to specialized HR systems is video hiring, as most providers embed web conferencing widgets in their products, allowing managers to locate and attract talents without geographical limitations.\n\nIn the future, Human Resources Management software is expected to reinvent its capacity, boost efficiency with more personalized and candidate-centric recruiting, streamlined interfaces, and automation of more HR-related processes that are currently performed manually.\n\nThe function of human resources departments is administrative and common to all organizations. Organizations may have formalized selection, evaluation, and payroll processes. Management of \"human capital\" progressed to an imperative and complex process. The HR function consists of tracking existing employee data which traditionally includes personal histories, skills, capabilities, accomplishments, and salary. To reduce the manual workload of these administrative activities, organizations began to electronically automate many of these processes by introducing specialized human resource management systems. HR executives rely on internal or external IT professionals to develop and maintain an integrated HRMS. Before client–server architectures evolved in the late 1980s, many HR automation processes were relegated to mainframe computers that could handle large amounts of data transactions. In consequence of the high capital investment necessary to buy or program proprietary software, these internally developed HRMS were limited to organizations that possessed a large amount of capital. The advent of client-server, application service provider, and software as a service (SaaS) or human resource management systems enabled higher administrative control of such systems. Currently, human resource management systems encompass:\n\nThe payroll module automates the pay process by gathering data on employee time and attendance, calculating various deductions and taxes, and generating periodic pay cheques and employee tax reports. Data is generally fed from the human resources and timekeeping modules to calculate automatic deposit and manual cheque writing capabilities. This module can encompass all employee-related transactions as well as integrate with existing financial management systems.\nThe time and attendance module gathers standardized time and work related efforts. The most advanced modules provide broad flexibility in data collection methods, labor distribution capabilities and data analysis features. Cost analysis and efficiency metrics are the primary functions.\nThe benefits administration module provides a system for organizations to administer and track employee participation in benefits programs. These typically encompass insurance, compensation, profit sharing, and retirement.\nThe HR management module is a component covering many other HR aspects from application to retirement. The system records basic demographic and address data, selection, training and development, capabilities and skills management, compensation planning records and other related activities. Leading edge systems provide the ability to \"read\" applications and enter relevant data to applicable database fields, notify employers and provide position management and position control. Human resource management function involves the recruitment, placement, evaluation, compensation, and development of the employees of an organization. Initially, businesses used computer-based information systems to:\n\nOnline recruiting has become one of the primary methods employed by HR departments to garner potential candidates for available positions within an organization. Talent management systems, or recruitment modules, offer an integrated hiring solution for HRMS which typically encompass:\n\nThe significant cost incurred in maintaining an organized recruitment effort, cross-posting within and across general or industry-specific job boards and maintaining a competitive exposure of availabilities has given rise to the development of a dedicated applicant tracking system (ATS) module.\n\nThe training module provides a system for organizations to administer and track employee training and development efforts. The system, normally called a \"learning management system\" (LMS) if a standalone product, allows HR to track education, qualifications, and skills of the employees, as well as outlining what training courses, books, CDs, web-based learning or materials are available to develop which skills. Courses can then be offered in date specific sessions, with delegates and training resources being mapped and managed within the same system. Sophisticated LMSs allow managers to approve training, budgets, and calendars alongside performance management and appraisal metrics.\n\nThe employee self-service module allows employees to query HR related data and perform some HR transactions over the system. Employees may query their attendance record from the system without asking the information from HR personnel. The module also lets supervisors approve O.T. requests from their subordinates through the system without overloading the task on HR department.\nMany organizations have gone beyond the traditional functions and developed human resource management information systems, which support recruitment, selection, hiring, job placement, performance appraisals, employee benefit analysis, health, safety, and security, while others integrate an outsourced applicant tracking system that encompasses a subset of the above.\nThe Analytics module enables organizations to extend the value of an HRMS implementation by extracting HR related data for use with other business intelligence platforms. For example, organizations combine HR metrics with other business data to identify trends and anomalies in headcount in order to better predict the impact of employee turnover on future output.\n\nThere are now many types of HRMS or HRIS, some of which are typically local-machine-based software packages; the other main type is an online cloud-based system that can be accessed via a web browser.\n\nThe Staff Training Module enables organizations the ability to enter, track and manage employee and staff training. Each type of activity can be recorded together with the additional data. The performance of each employee or staff member is then stored and can be accessed via the Analytics module.\n\nEmployee Re-Assign module is a recent additional functionality of HRMS. This module has the functions of Transfer, Promotion, Pay revision, Re-designation, Deputation, Confirmation, Pay mode change and Letter Form.\n\n\n\n"}
{"id": "235968", "url": "https://en.wikipedia.org/wiki?curid=235968", "title": "Hydrogenation", "text": "Hydrogenation\n\nHydrogenation – meaning, to treat with hydrogen – is a chemical reaction between molecular hydrogen (H) and another compound or element, usually in the presence of a catalyst such as nickel, palladium or platinum. The process is commonly employed to reduce or saturate organic compounds. Hydrogenation typically constitutes the addition of pairs of hydrogen atoms to a molecule, often an alkene. Catalysts are required for the reaction to be usable; non-catalytic hydrogenation takes place only at very high temperatures. Hydrogenation reduces double and triple bonds in hydrocarbons.\n\nIt has three components, the unsaturated substrate, the hydrogen (or hydrogen source) and, invariably, a catalyst. The reduction reaction is carried out at different temperatures and pressures depending upon the substrate and the activity of the catalyst.\n\nThe same catalysts and conditions that are used for hydrogenation reactions can also lead to isomerization of the alkenes from cis to trans. This process is of great interest because hydrogenation technology generates most of the trans fat in foods (see below). A reaction where bonds are broken while hydrogen is added is called hydrogenolysis, a reaction that may occur to carbon-carbon and carbon-heteroatom (oxygen, nitrogen or halogen) bonds. Some hydrogenations of polar bonds are accompanied by hydrogenolysis.\n\nFor hydrogenation, the obvious source of hydrogen is H gas itself, which is typically available commercially within the storage medium of a pressurized cylinder. The hydrogenation process often uses greater than 1 atmosphere of H, usually conveyed from the cylinders and sometimes augmented by \"booster pumps\". Gaseous hydrogen is produced industrially from hydrocarbons by the process known as steam reforming. For many applications, hydrogen is transferred from donor molecules such as formic acid, isopropanol, and dihydroanthracene. These hydrogen donors undergo dehydrogenation to, respectively, carbon dioxide, acetone, and anthracene. These processes are called transfer hydrogenations.\n\nAn important characteristic of alkene and alkyne hydrogenations, both the homogeneously and heterogeneously catalyzed versions, is that hydrogen addition occurs with \"syn addition\", with hydrogen entering from the least hindered side. This reaction can be performed on a variety of different functional groups.\nWith rare exceptions, H is unreactive toward organic compounds in the absence of metal catalysts. The unsaturated substrate is chemisorbed onto the catalyst, with most sites covered by the substrate. In heterogeneous catalysts, hydrogen forms surface hydrides (M-H) from which hydrogens can be transferred to the chemisorbed substrate. Platinum, palladium, rhodium, and ruthenium form highly active catalysts, which operate at lower temperatures and lower pressures of H. Non-precious metal catalysts, especially those based on nickel (such as Raney nickel and Urushibara nickel) have also been developed as economical alternatives, but they are often slower or require higher temperatures. The trade-off is activity (speed of reaction) vs. cost of the catalyst and cost of the apparatus required for use of high pressures. Notice that the Raney-nickel catalysed hydrogenations require high pressures:\n\nCatalysts are usually classified into two broad classes: homogeneous catalysts and heterogeneous catalysts. Homogeneous catalysts dissolve in the solvent that contains the unsaturated substrate. Heterogeneous catalysts are solids that are suspended in the same solvent with the substrate or are treated with gaseous substrate.\n\nSome well known homogeneous catalysts are indicated below. These are coordination complexes that activate both the unsaturated substrate and the H. Most typically, these complexes contain platinum group metals, especially Rh and Ir. \n\nHomogeneous catalysts are also used in asymmetric synthesis by the hydrogenation of prochiral substrates. An early demonstration of this approach was the Rh-catalyzed hydrogenation of enamides as precursors to the drug L-DOPA. To achieve asymmetric reduction, these catalyst are made chiral by use of chiral diphosphine ligands. Rhodium catalyzed hydrogenation has also been used in the herbicide production of S-metolachlor, which uses a Josiphos type ligand (called Xyliphos). In principle asymmetric hydrogenation can be catalyzed by chiral heterogeneous catalysts, but this approach remains more of a curiosity than a useful technology.\n\nHeterogeneous catalysts for hydrogenation are more common industrially. In industry, precious metal hydrogenation catalysts are deposited from solution as a fine powder on the support, which is a cheap, bulky, porous, usually granular material, such as activated carbon, alumina, calcium carbonate or barium sulfate. For example, platinum on carbon is produced by reduction of chloroplatinic acid \"in situ\" in carbon. Examples of these catalysts are 5% ruthenium on activated carbon, or 1% platinum on alumina. Base metal catalysts, such as Raney nickel, are typically much cheaper and do not need a support. Also, in the laboratory, unsupported (massive) precious metal catalysts such as platinum black are still used, despite the cost.\n\nAs in homogeneous catalysts, the activity is adjusted through changes in the environment around the metal, i.e. the coordination sphere. Different faces of a crystalline heterogeneous catalyst display distinct activities, for example. This can be modified by mixing metals or using different preparation techniques. Similarly, heterogeneous catalysts are affected by their supports.\n\nIn many cases, highly empirical modifications involve selective \"poisons\". Thus, a carefully chosen catalyst can be used to hydrogenate some functional groups without affecting others, such as the hydrogenation of alkenes without touching aromatic rings, or the selective hydrogenation of alkynes to alkenes using Lindlar's catalyst. For example, when the catalyst palladium is placed on barium sulfate and then treated with quinoline, the resulting catalyst reduces alkynes only as far as alkenes. The Lindlar catalyst has been applied to the conversion of phenylacetylene to styrene.\n\nTransfer hydrogenation uses other hydrogen donor molecules in place of H itself. These reactants, which can also serve as solvents for the reaction, include hydrazine, dihydronaphthalene, dihydroanthracene, isopropanol, and formic acid. The reaction involves an outer-sphere mechanism.\n\nIn organic synthesis, transfer hydrogenation is useful for the asymmetric reduction of polar unsaturated substrates, such as ketones, aldehydes, and imines. The hydrogenation of polar substrates such as ketones and aldehydes typically requires transfer hydrogenation, at least reactions that use homogeneous catalysts. These catalysts are readily generated in chiral forms, which is the basis of asymmetric hydrogenation of ketones.\n\nPolar substrates such as nitriles can be hydrogenated electrochemically, using protic solvents and reducing equivalents as the source of hydrogen.\n\nThe addition of hydrogen to double or triple bonds in hydrocarbons is a type of redox reaction that can be thermodynamically favorable. For example, the addition of hydrogen to an alkene has a Gibbs free energy change of -101 kJ·mol. However, the reaction rate for most hydrogenation reactions is negligible in the absence of catalysts.\nHydrogenation is a strongly exothermic reaction. In the hydrogenation of vegetable oils and fatty acids, for example, the heat released is about 25 kcal per mole (105 kJ/mol), sufficient to raise the temperature of the oil by 1.6–1.7 °C per iodine number drop. The mechanism of metal-catalyzed hydrogenation of alkenes and alkynes has been extensively studied. First of all isotope labeling using deuterium confirms the regiochemistry of the addition:\n\nOn solids, the accepted mechanism is the Horiuti-Polanyi mechanism:\n\nIn the second step, the metallointermediate formed is a saturated compound that can rotate and then break down, again detaching the alkene from the catalyst. Consequently, contact with a hydrogenation catalyst necessarily causes \"cis-trans\"-isomerization, because the isomerization is thermodynamically favorable. This is a problem in partial hydrogenation, while in complete hydrogenation the produced \"trans\"-alkene is eventually hydrogenated.\n\nFor aromatic substrates, the first bond is hardest to hydrogenate because of the free energy penalty for breaking the aromatic system. The product of this is a cyclohexadiene, which is extremely active and cannot be isolated; in conditions reducing enough to break the aromatization, it is immediately reduced to a cyclohexene. The cyclohexene is ordinarily reduced immediately to a fully saturated cyclohexane, but special modifications to the catalysts (such as the use of the anti-solvent water on ruthenium) can preserve some of the cyclohexene, if that is a desired product.\n\nIn many homogeneous hydrogenation processes, the metal binds to both components to give an intermediate alkene-metal(H) complex. The general sequence of reactions is assumed to be as follows or a related sequence of steps:\n\nThe hydrogenation of nitrogen to give ammonia is conducted on a vast scale by the Haber-Bosch process, consuming an estimated 1% of the world's energy supply.\n</chem>\nOxygen can be partially hydrogenated to give hydrogen peroxide, although this process has not been commercialized\n\nCatalytic hydrogenation has diverse industrial uses. Most frequently, industrial hydrogenation relies on heterogeneous catalysts.\n\nThe largest scale application of hydrogenation is for the processing of vegetable oils. Typical vegetable oils are derived from polyunsaturated fatty acids (containing more than one carbon-carbon double bond). Their partial hydrogenation reduces most, but not all, of these carbon-carbon double bonds. The degree of hydrogenation is controlled by restricting the amount of hydrogen, reaction temperature and time, and the catalyst.\n\nHydrogenation converts liquid vegetable oils into solid or semi-solid fats, such as those present in margarine. Changing the degree of saturation of the fat changes some important physical properties, such as the melting range, which is why liquid oils become semi-solid. Solid or semi-solid fats are preferred for baking because the way the fat mixes with flour produces a more desirable texture in the baked product. Because partially hydrogenated vegetable oils are cheaper than animal fats, are available in a wide range of consistencies, and have other desirable characteristics (such as increased oxidative stability and longer shelf life), they are the predominant fats used as shortening in most commercial baked goods.\n\nA side effect of incomplete hydrogenation having implications for human health is the isomerization of some of the remaining unsaturated carbon bonds to their trans isomers. Trans fats (resulting from partial hydrogenation) have been implicated in circulatory diseases including heart disease. The conversion from cis to trans bonds is favored because the trans configuration has lower energy than the natural cis one. At equilibrium, the trans/cis isomer ratio is about 2:1. Many countries and regions have introduced mandatory labeling of trans fats on food products and appealed to the industry for voluntary reductions. The food industry has moved away from partially hydrogenated fats (i.e. trans fats) and towards fully hydrogenated fats and interesterified fats in response to bad publicity about trans fats, labeling requirements, and removal of trans fats from the FDA list of foods Generally Recognized as Safe.\n\nIn petrochemical processes, hydrogenation is used to convert alkenes and aromatics into saturated alkanes (paraffins) and cycloalkanes (naphthenes), which are less toxic and less reactive. Relevant to liquid fuels that are stored sometimes for long periods in air, saturated hydrocarbons exhibit superior storage properties. On the other hand, alkene tend to form hydroperoxides, which can form gums that interfere with fuel handing equipment. For example, mineral turpentine is usually hydrogenated. Hydrocracking of heavy residues into diesel is another application. In isomerization and catalytic reforming processes, some hydrogen pressure is maintained to hydrogenolyze coke formed on the catalyst and prevent its accumulation.\n\nHydrogenation is a useful means for converting unsaturated compounds into saturated derivatives. Substrates include not only alkenes and alkynes, but also aldehydes, imines, and nitriles, which are converted into the corresponding saturated compounds, i.e. alcohols and amines. Thus, alkyl aldehydes, which can be synthesized with the oxo process from carbon monoxide and an alkene, can be converted to alcohols. E.g. 1-propanol is produced from propionaldehyde, produced from ethene and carbon monoxide. Xylitol, a polyol, is produced by hydrogenation of the sugar xylose, an aldehyde. Primary amines can be synthesized by hydrogenation of nitriles, while nitriles are readily synthesized from cyanide and a suitable electrophile. For example, isophorone diamine, a precursor to the polyurethane monomer isophorone diisocyanate, is produced from isophorone nitrile by a tandem nitrile hydrogenation/reductive amination by ammonia, wherein hydrogenation converts both the nitrile into an amine and the imine formed from the aldehyde and ammonia into another amine.\n\nThe earliest hydrogenation is that of platinum catalyzed addition of hydrogen to oxygen in the Döbereiner's lamp, a device commercialized as early as 1823. The French chemist Paul Sabatier is considered the father of the hydrogenation process. In 1897, building on the earlier work of James Boyce, an American chemist working in the manufacture of soap products, he discovered that traces of nickel catalyzed the addition of hydrogen to molecules of gaseous hydrocarbons in what is now known as the Sabatier process. For this work, Sabatier shared the 1912 Nobel Prize in Chemistry. Wilhelm Normann was awarded a patent in Germany in 1902 and in Britain in 1903 for the hydrogenation of liquid oils, which was the beginning of what is now a worldwide industry. The commercially important Haber–Bosch process, first described in 1905, involves hydrogenation of nitrogen. In the Fischer–Tropsch process, reported in 1922 carbon monoxide, which is easily derived from coal, is hydrogenated to liquid fuels.\n\nIn 1922, Voorhees and Adams described an apparatus for performing hydrogenation under pressures above one atmosphere. The Parr shaker, the first product to allow hydrogenation using elevated pressures and temperatures, was commercialized in 1926 based on Voorhees and Adams' research and remains in widespread use. In 1924 Murray Raney developed a finely powdered form of nickel, which is widely used to catalyze hydrogenation reactions such as conversion of nitriles to amines or the production of margarine.\n\nIn the 1930s, Calvin discovered that copper(II) complexes oxidized H. The 1960s witnessed the development of well defined homogeneous catalysts using transition metal complexes, e.g., Wilkinson's catalyst (RhCl(PPh)). Soon thereafter cationic Rh and Ir were found catalyze the hydrogenation of alkenes and carbonyls. In the 1970s, asymmetric hydrogenation was demonstrated in the synthesis of L-DOPA, and the 1990s saw the invention of Noyori asymmetric hydrogenation. The development of homogeneous hydrogenation was influenced by work started in the 1930s and 1940s on the oxo process and Ziegler–Natta polymerization.\n\nFor most practical purposes, hydrogenation requires a metal catalyst. Hydrogenation can, however, proceed from some hydrogen donors without catalysts, illustrative hydrogen donors being diimide and aluminium isopropoxide, the latter illustrated by the Meerwein–Ponndorf–Verley reduction. Some metal-free catalytic systems have been investigated in academic research. One such system for reduction of ketones consists of \"tert\"-butanol and potassium tert-butoxide and very high temperatures. The reaction depicted below describes the hydrogenation of benzophenone:\nA chemical kinetics study found this reaction is first-order in all three reactants suggesting a cyclic 6-membered transition state.\n\nAnother system for metal-free hydrogenation is based on the phosphine-borane, compound 1, which has been called a \"frustrated Lewis pair\". It reversibly accepts dihydrogen at relatively low temperatures to form the phosphonium borate 2 which can reduce simple hindered imines.\n\nThe reduction of nitrobenzene to aniline has been reported to be catalysed by fullerene, its mono-anion, atmospheric hydrogen and UV light.\n\nToday's bench chemist has three main choices of hydrogenation equipment:\n\nThe original and still a commonly practised form of hydrogenation in teaching laboratories, this process is usually effected by adding solid catalyst to a round bottom flask of dissolved reactant which has been evacuated using nitrogen or argon gas and sealing the mixture with a penetrable rubber seal. Hydrogen gas is then supplied from a H-filled balloon. The resulting three phase mixture is agitated to promote mixing. Hydrogen uptake can be monitored, which can be useful for monitoring progress of a hydrogenation. This is achieved by either using a graduated tube containing a coloured liquid, usually aqueous copper sulfate or with gauges for each reaction vessel.\n\nSince many hydrogenation reactions such as hydrogenolysis of protecting groups and the reduction of aromatic systems proceed extremely sluggishly at atmospheric temperature and pressure, pressurised systems are popular. In these cases, catalyst is added to a solution of reactant under an inert atmosphere in a pressure vessel. Hydrogen is added directly from a cylinder or built in laboratory hydrogen source, and the pressurized slurry is mechanically rocked to provide agitation, or a spinning basket is used. Heat may also be used, as the pressure compensates for the associated reduction in gas solubility.\n\nFlow hydrogenation has become a popular technique at the bench and increasingly the process scale. This technique involves continuously flowing a dilute stream of dissolved reactant over a fixed bed catalyst in the presence of hydrogen. Using established HPLC technology, this technique allows the application of pressures from atmospheric to . Elevated temperatures may also be used. At the bench scale, systems use a range of pre-packed catalysts which eliminates the need for weighing and filtering pyrophoric catalysts.\n\nCatalytic hydrogenation is done in a tubular plug-flow reactor (PFR) packed with a supported catalyst. The pressures and temperatures are typically high, although this depends on the catalyst. Catalyst loading is typically much lower than in laboratory batch hydrogenation, and various promoters are added to the metal, or mixed metals are used, to improve activity, selectivity and catalyst stability. The use of nickel is common despite its low activity, due to its low cost compared to precious metals.\n\nGas Liquid Induction Reactors (Hydrogenator) are also used for carrying out catalytic hydrogenation.\n\n\n"}
{"id": "16337341", "url": "https://en.wikipedia.org/wiki?curid=16337341", "title": "Injection well", "text": "Injection well\n\nAn injection well is a device that places fluid deep underground into porous rock formations, such as sandstone or limestone, or into or below the shallow soil layer. The fluid may be water, wastewater, brine (salt water), or water mixed with chemicals.\n\nThe U.S. Environmental Protection Agency (EPA) defines an injection well as \"a bored, drilled, or driven shaft, or a dug hole that is deeper than it is wide, or an improved sinkhole, or a subsurface fluid distribution system\". Well construction depends on the injection fluid injected and depth of the injection zone. Deep wells that are designed to inject hazardous wastes or carbon dioxide deep below the Earth's surface have multiple layers of protective casing and cement, whereas shallow wells injecting non-hazardous fluids into or above drinking water sources are more simply constructed.\n\nInjection wells are used for many purposes.\n\nIn waste water disposal, treated waste water is injected into the ground between impermeable layers of rocks to avoid polluting fresh water supplies or adversely affecting quality of receiving waters. Injection wells are usually constructed of solid walled pipe to a deep elevation in order to prevent injectate from mixing with the surrounding environment. Unlike outfalls or other direct disposal techniques, injection wells utilize the earth as a filter to further clean the treated wastewater before it reaches the receiving water. This method of waste water disposal also serves to spread the injectate over a wide area, further decreasing environmental impacts.\n\nCritics of waste water injection wells cite concerns relating to the injectate polluting receiving waters. Most environmental engineering professionals, however, consider waste water treatment followed by disposal through injection wells to be the most cost effective and environmentally responsible method of waste water treatment. The only known alternatives to injection wells are direct discharge of treated waste water to receiving waters or utilization of the treated water for irrigation. Direct discharge does not disperse the water over a wide area; the environmental impact is focused on a particular segment of a river and its downstream reaches or on a coastal waterbody. Extensive irrigation is often prohibitively expensive and requires ongoing maintenance and large electricity usage.\n\nSince the early 1990s, Maui County, Hawaii has been engaged in a struggle over the 3-5 million gallons per day of wastewater that it injects below the Lahaina sewage treatment plant, over the claim that the water was emerging in seeps that were causing algae blooms and other environmental damage. After some twenty years, it was sued by environmental groups after multiple studies showed that more than half the injectate was appearing in nearby coastal waters. The judge in the suit rejected the County's arguments, potentially subjecting it to millions of dollars in federal fines. A 2001 consent decree required the county to obtain a water quality certification from the Hawaii Department Of Health, which it failed to do until 2010, after the suit was filed.\n\nAnother use of injection wells is in natural gas and petroleum production. Steam, carbon dioxide, water, and other substances can be injected into an oil-producing unit in order to maintain reservoir pressure, heat the oil or lower its viscosity, allowing it to flow to a producing well nearby.\n\nYet another use for injection wells is in environmental remediation, for cleanup of either soil or groundwater contamination. Injection wells can insert clean water into an aquifer, thereby changing the direction and speed of groundwater flow, perhaps towards extraction wells downgradient, which could then more speedily and efficiently remove the contaminated groundwater. Injection wells can also be used in cleanup of soil contamination, for example by use of an ozonation system. Complex hydrocarbons and other contaminants trapped in soil and otherwise inaccessible can be broken down by ozone, a highly reactive gas, often with greater cost-effectiveness than could be had by digging out the affected area. Such systems are particularly useful in built-up urban environments where digging may be impractical due to overlying buildings.\n\nRecently the option of refilling natural aquifers with injection or percolation has become more important, particularly in the driest region of the world, the MENA region (Middle East and North Africa).\n\nSurface runoff can also be recharged into dry wells, or simply barren wells that have been modified to functions as cisterns. These hybrid stormwater management systems, called recharge wells, have the advantage of aquifer recharge and instantaneous supply of potable water at the same time. They can utilize existing infrastructure and require very little effort for the modification and operation. The activation can be as simple as inserting a polymer cover (foil) into the well shaft. Vertical pipes for conduction of the overflow to the bottom can enhance performance. The area around the well acts as funnel. If this area is maintained well the water will require little purification before it enters the cistern.\n\nInjection wells are used to tap geothermal energy in hot, porous rock formations below the surface by injecting fluids into the ground, which is heated in the ground, then extracted from adjacent wells as fluid, steam, or a combination of both. The heated steam and fluid can then be utilized to generate electricity or directly for geothermal heating.\n\nIn the United States, injection well activity is regulated by EPA and state governments under the Safe Drinking Water Act (SDWA). EPA has issued Underground Injection Control (UIC) regulations in order to protect drinking water sources.\n\nEPA regulations define six classes of injection wells. Class I wells are used for the injection of municipal and industrial wastes beneath underground sources of drinking water. Class II wells are used for the injection of fluids associated with oil and gas production, including waste from hydraulic fracturing. Class III wells are used for the injection of fluids used in mineral solution mining beneath underground sources of drinking water. Class IV wells, like Class I wells, were used for the injection of hazardous wastes but inject waste into or above underground sources of drinking water instead of below. EPA banned the use of Class IV wells in 1984. Class V wells are those used for all non-hazardous injections that are not covered by Classes I through IV. Examples of Class V wells include stormwater drainage wells and septic system leach fields. Finally, Class VI wells are used for the injection of carbon dioxide for sequestration, or long term storage. Currently, there are no Class VI wells in operation, but 6 to 10 wells are expected to be in use by 2016.\n\nA July 2013 study by US Geological Survey scientist William Ellsworth links earthquakes to wastewater injection sites. In the four years from 2010-2013 the number of earthquakes of magnitude 3.0 or greater in the central and eastern United States increased dramatically. After decades of a steady earthquake rate (average of 21 events/year), activity increased starting in 2001 and peaked at 188 earthquakes in 2011, including a record-breaking 5.7-magnitude earthquake near Prague, Oklahoma which was the strongest earthquake ever recorded in Oklahoma. USGS scientists have found that at some locations the increase in seismicity coincides with the injection of wastewater in deep disposal wells. Injection-induced earthquakes are thought to be caused by pressure changes due to excess fluid injected deep below the surface and are being dubbed “man-made” earthquakes. On September 3, 2016, a 5.8-magnitude earthquake occurred near Pawnee, Oklahoma, followed by nine aftershocks between magnitudes 2.6 and 3.6 within three and one-half hours. The earthquake broke the previous record set five years earlier. Tremors were felt as far away as Memphis, Tennessee, and Gilbert, Arizona. Mary Fallin, the Oklahoma governor, declared a local emergency and shutdown orders for local disposal wells were ordered by the Oklahoma Corporation Commission. Results of ongoing multi-year research on induced earthquakes by the United States Geological Survey (USGS) published in 2015 suggested that most of the significant earthquakes in Oklahoma, such as the 1952 magnitude 5.5 El Reno earthquake may have been induced by deep injection of waste water by the oil industry.\n\n"}
{"id": "63438", "url": "https://en.wikipedia.org/wiki?curid=63438", "title": "Jack Tramiel", "text": "Jack Tramiel\n\nJack Tramiel ( ; born Idek Trzmiel; December 13, 1928 – April 8, 2012) was a Polish American businessman, best known for founding Commodore International. The Commodore PET, Commodore VIC-20 and Commodore 64 are some home computers produced while he was running the company. Tramiel later formed Atari Corporation after he purchased the remnants of the original Atari, Inc. from its parent company.\n\nTramiel was born as Idek Trzmiel (some sources also list Juda Trzmiel, Jacek Trzmiel, or Idek Tramielski) into a Jewish family, the son of Abram Josef Trzmiel and Rifka Bentkowska.\n\nAfter the German invasion of Poland in 1939 his family was transported by German occupiers to the Jewish ghetto in Łódź, where he worked in a garment factory. When the ghettos were liquidated, his family was sent to the Auschwitz concentration camp. He was examined by Josef Mengele and selected for a work party, after which he and his father were sent to the labor camp Ahlem near Hanover, while his mother remained at Auschwitz. Like many other inmates, his father was reported to have died of typhus in the work camp; however, Tramiel believed he was killed by an injection of gasoline. Tramiel was rescued from the labor camp in April 1945 by the 84th Infantry Division of the US army.\n\nOn 10 November 1947, Tramiel immigrated to the United States. He soon joined the U.S. Army, where he learned how to repair office equipment, including typewriters.\n\nIn 1953, while working as a taxi driver, Tramiel bought a shop in the Bronx to repair office machinery, securing a $25,000 loan for the business from a U.S. Army entitlement. He named it Commodore Portable Typewriter. Tramiel wanted a military-style name for his company, but names such as Admiral and General were already taken, so he settled on the Commodore name.\n\nIn 1955, Tramiel signed a deal with a Czechoslovak typewriter manufacturer Zbrojovka Brno NP to assemble and sell their typewriters in North America. However, as Czechoslovakia was part of the Warsaw Pact, they could not be imported directly into the U.S., so Tramiel used parts from Zbrojovka's Consul typewriters and set up Commodore Business Machines in Toronto, Ontario, Canada. After Zbrojovka began developing their own hardware Commodore signed an agreement in 1962 with Rheinmetall-Borsig AG and began to sell Commodore portable typewriters made from the parts of older Rheinmetall-Borsig typewriters. In 1962, Commodore went public, but the arrival of Japanese typewriters in the U.S. market made the selling of Czechoslovakian typewriters unprofitable. Struggling for cash, the company sold 17% of its stock to Canadian businessman Irving Gould, taking in $400,000 and using the money to re-launch the company in the adding machine business, which was profitable for a time before the Japanese entered that field as well. Stung twice by the same source, Gould suggested that Tramiel travel to Japan to learn why they were able to outcompete North Americans in their own local markets. It was during this trip that Tramiel saw the first digital calculators, and decided that the mechanical adding machine was a dead end.\n\nWhen Commodore released its first calculators, combining an LED display from Bowmar and an integrated circuit from Texas Instruments (TI), it found a ready market. However, after slowly realizing the size of the market, TI decided to cut Commodore out of the middle, and released their own calculators at a price point below Commodore's cost of just the chips. Gould once again rescued the company, injecting another $3 million, which allowed Commodore to purchase MOS Technology, Inc. an IC design and semiconductor manufacturer, a company which had also supplied Commodore with calculator ICs. When their lead designer, Chuck Peddle, told Tramiel that calculators were a dead end and computers were the future, Tramiel told him to build one to prove the point.\n\nPeddle responded with the Commodore PET, based on his company's MOS Technology 6502 processor. It was first shown, privately, at the Chicago Consumer Electronics Show in 1977, and soon the company was receiving 50 calls a day from dealers wanting to sell the computer. The PET became a success—especially in the education field, where its all-in-one design was a major advantage. Much of their success with the PET came from the business decision to sell directly to large customers, instead of selling to them through a dealer network. The first PET computers were sold primarily in Europe, where Commodore had also introduced the first wave of digital handheld calculators.\n\nAs prices dropped and the market matured, the monochrome (green text on black screen) PET was at a disadvantage in the market when compared to machines like the Apple II and Atari 800, which offered color graphics and could be hooked to a television as an inexpensive display. Commodore responded with the VIC-20, and then the Commodore 64, which became the best-selling home computer of all time. The Commodore VIC-20 was the first computer to sell one million units. The Commodore 64 sold several million units. It was during this time that Tramiel coined the phrase, \"We need to build computers for the masses, not the classes.\" An industry executive attributed to Tramiel the discontinuation of the TI-99/4A home computer in 1983, after the company had lost hundreds of millions of dollars, stating that \"TI got suckered by Jack\".\n\nGould had controlled the company since 1966. He and Tramiel often argued, but Gould usually let Tramiel run Commodore by himself. Tramiel was a micromanager who did not believe in budgets; he wanted to approve every expense greater than $1,000, which meant that operations stopped when Tramiel went on vacation. Adam Osborne wrote in 1981:\n\nTramiel angrily left a 13 January 1984 meeting of Commodore's board of directors led by chairman Gould, and never returned to the company. What happened at the meeting remains unclear. Neil Harris, editor of \"Commodore Magazine\" at the time, recalled:\n\nTramiel later said that he had resigned from Commodore because he disagreed with Gould \"on the basic principles — how to run the company\". Their disagreement was so bitter that, after Tramiel's departure, \"Commodore Magazine\" was forbidden to quote Tramiel or mention his name. \"Ahoy!\" wrote after his departure that although Tramiel's \"obsession with controlling the cost of every phase of the manufacturing process\" had led to record profits during the home computer price war, his \"inflexible one-man rule\" had resulted in poor dealer relations and \"a steady turnover of top executives at Commodore\". The magazine concluded \"it has become increasingly clear that the company is just too big for one man, however talented, to run\".\n\nDuring a question and answer session at CommVEx v11 (July 18, 2015), Leonard Tramiel finally revealed to the crowd, what really transpired between Jack and Irving Gould during the 1984 C.E.S. show resulting in Tramiel leaving Commodore: On the 13th January 1984 during a meeting with Irving, Jack told Irving that treating the assets of the company as his own and using them for personal use was wrong. He said to Irving, \"you can't do that while I'm still president\" to which Irving responded by saying \"Goodbye\". Three days after the show, Jack announced to the public that he was resigning from the company.\n\nIn an interview with Fortune magazine on 1998-04-13 Tramiel said \"Business is war, I don't believe in compromising, I believe in winning.\" \n\nAfter a short break from the computer industry, he formed a new company named Tramel Technology, Ltd., in order to design and sell a next-generation home computer. The company was named \"Tramel\" to help ensure that it would be pronounced correctly (i.e., \"tra - mel\" instead of \"tra - meal\").\n\nIn July 1984, Tramel Technology bought the Consumer Division of Atari Inc. from Warner Communications. The division had fallen on hard times due to the video game crash of 1983. TTL was then renamed Atari Corporation, and went on to produce the 16/32-bit Atari ST computer line based on Motorola's MC68000 CPU, directly competing with Apple, which also used it. Under Tramiel's direction, the Atari ST was a considerable success in Europe, and globally in the professional music market.\n\nDespite successfully shipping the ST, Tramiel's poor personal reputation hurt Atari. One retailer said in 1985 about the ST that because of its prior experience with Tramiel \"Our interest in Atari is zero, zilch\". A software company executive said \"Dealing with Commodore was like dealing with Attila the Hun. I don't know if Tramiel will be following his old habits ... I don't see a lot of people rushing to get software on the machine.\" (One ex-Commodore employee said that to Tramiel \"software wasn't tangible—you couldn't hold it, feel it, or touch it—so it wasn't worth spending money for\".) Steve Arnold of LucasArts said after meeting with Tramiel that he reminded him of Jabba the Hutt, while within Atari Darth Vader was often the comparison. Another executive was more positive, stating \"Jack Tramiel is a winner. I wouldn't bet against him.\" In 1988 Stewart Alsop II called Tramiel and Alan Sugar \"the world's two leading business-as-war entrepreneurs\".\n\nIn the late 1980s, Tramiel decided to step away from day-to-day operations at Atari, naming his son, Sam, President and CEO. In 1995, Sam suffered a heart attack, and his father returned to oversee operations. In 1996, Tramiel sold Atari to disk-drive manufacturer Jugi Tandon Storage in a reverse merger deal. The newly merged company was named JTS Corporation, and Tramiel joined the JTS board.\n\nTramiel was a co-founder of the United States Holocaust Memorial Museum, which was opened in 1993. He was among many other survivors of the Ahlem labor camp who tracked down U.S. Army veteran Vernon Tott, who was among the 84th Division which rescued survivors from the camp and had taken and stored photographs of at least 16 of the survivors. Tott, who died of cancer in 2003, was personally commemorated by Tramiel with an inscription on one of the Holocaust Museum's walls saying \"To Vernon W. Tott, My Liberator and Hero\".\n\nTramiel retired in 1996 and moved to Monte Sereno, California.\n\nTramiel died on April 8, 2012, of heart failure at the age of 83.\n\n\n"}
{"id": "44383541", "url": "https://en.wikipedia.org/wiki?curid=44383541", "title": "John Morris Scientific", "text": "John Morris Scientific\n\nJohn Morris Scientific is an Australian firm engaged in the distribution, installation & servicing of laboratory, Environmental, Petrochemical, Vacuum and Industrial instrumentation & consumables to aid researchers and engineers in diverse industry sectors throughout Australia, New Zealand & the South West Pacific region. Their represented brands include famous scientific manufacturers and suppliers such as Cole-Parmer, Advanced Instruments, Gilson, PAC, Stanhope Seta, Isco, Sigma, Martin Christ, Masterflex, PCB Piezotronics, MTS and Kurt J. Lesker. \nThe John Morris Group principally serves the life sciences, vacuum research, environmental, petroleum, industrial and pharmaceutical industries.\n\nWith original roots in Holland for 2 generations - John Morris Scientific was founded in April 1956 by John Leon Wyzenbeek and Morris Garlick to supply Australian research laboratories with quality products not available in the region. The original roots stem back to John's wife Hetty. Her father owned and ran a second generation, chemical and glassware distributor in Holland which was forced into closure during the second world war. The shell of this company was sold after the war and the proceeds were used to establish new roots in Australia.\n\nAfter working for a range of established Australian Scientific Instrument distributors including Townsend Mercer John Leon Wyzenbeek began a partnership with Morris Garlic leveraging the relationships from Hetty's childhood.\n\nSince inception, three generations of the Wyzenbeek family have worked in John Morris Scientific. At present, John's son Norbert is Chairman of the Board and Norbert's eldest son Andre is the Managing Director.\nIn the early days, John would ride a bicycle to customers selling glassware until he had enough orders to place a shipment with his European suppliers. In 1987 John Morris transitioned from \"Glassware and Chemicals\" into instrumentation – investing in product specialist staff and service infrastructure. John Morris Scientific maintains knowledge of the latest technologies by providing personnel with regular factory training, attending vendors’ facilities regularly and through involvement in key industry events.\n\nThis company is the only third generation, privately owned, scientific instrument supplier in the South West Pacific region. John Morris Scientific has remained under the same family ownership for over 60 years.\n\nIn 2016 John Morris Scientific changed its name to the John Morris Group to better reflect their growth and diversification into technical industries outside of the Laboratory.\n\nTheir technical services team is composed of 5 graduate application engineers, 15 product specialists and 15 technical engineers. These staff are regularly factory trained on specific instrumentation ensuring that their knowledge remains current. The John Morris Group team share expertise through user training (with installation) and ongoing support specific to application requirements.\n\n"}
{"id": "21267151", "url": "https://en.wikipedia.org/wiki?curid=21267151", "title": "Log splitter", "text": "Log splitter\n\nA log splitter is a piece of machinery or equipment used for splitting firewood from softwood or hardwood logs that have been pre-cut into sections (rounds), usually by chainsaw or on a saw bench. Many log splitters consist of a hydraulic or electrical rod and piston assembly and these are often rated by the tons of force they can generate. The higher the force rating, the greater the thickness or length of the rounds that can be split. The log splitter consists of all four major hydraulic components.\n\nMost log splitter models for home use have a rating around 10 tons, but professional hydraulic models may exert 30 tons of force or more. There are also manual log splitters, which use mechanical leverage to force logs through a sharpened blade assembly; and screw or 'corkscrew' types that are driven directly from an agricultural tractor's power take-off shaft where the splitter is mounted on the three point linkage.\n\nA simple log splitter may be powered by an electric motor driving a hydraulic pump or by gasoline or diesel engine with or without a tractor. The non-electric versions can be used remotely where the splitter can be moved to the location of the cut wood source. Split logs can then be loaded into trucks, trailers or bulk bags.\n\nNo matter what the power source, a log splitter either uses a hydraulic piston to drive the log through a stationary blade or a rotating cone shaped screw mandrel that pulls the log up over a wedge. Some models have attachments that prevent the split logs from falling to the ground allowing the operator to reposition the logs quickly for a second pass on the log splitter. Some cone or screw splitters are mounted on steel platforms mounted on a 3-point linkage that allow the log to be repeatedly split into smaller pieces without putting the wood down and up again.\n\nAlthough smaller firewood splitters are intended for home, there are now many commercial units available. Some commercial splitters are part of a 'firewood processor' that saw logs of timber into lengths, split them, and then carry the wood up an inclined conveyor onto a pile or into a bag, truck or trailer. Specialty producers such as those producing maple syrup use units that split 4 foot lengths. Machines that split and point wood for fence post also exist though they are few in number as it is generally safer and more convenient to saw the posts.\n\nThe rising cost of domestic heating gas oil has reawakened a desire for alternative fuel sources and burning wood is carbon neutral. Modern wood burning stoves are efficient and safe. Many consumers that would not have considered splitting their own logs a few years ago are now burning wood fuel for both ecological and economical reasons.\n\nAlthough a good log splitter can save the operator hours of labor, it is not possible to make it completely safe. Only trained adults should operate a log splitter, since anything caught between the log and the splitting blade will be subjected to a force of at least 10 tons. Most hydraulic machines now have 'two handed operation' for safety which means that both of the operator's hands are needed to actuate the splitter thus keeping them out of the way of the moving blade.\n\nThe behavior of each log cannot be predicted, so a safety zone should be established around the splitter to prevent injury from flying splinters of wood. Helpers can pick up the individual pieces of firewood, but should not stand near the log splitter while it is in operation.\n"}
{"id": "5005431", "url": "https://en.wikipedia.org/wiki?curid=5005431", "title": "MEDFORIST", "text": "MEDFORIST\n\nMEDFORIST is a project aimed at implementing a Euro-Mediterranean network for sharing information systems and technology (IST) resources. Started in August 2002, MEDFORIST is a project of the Euro-Mediterranean Information Society (EUMEDIS), an initiative of the European Union, ultimately aimed at establishing an EU-MED free trade zone by 2010 and setting up an information network system among European and Mediterranean universities and institutes in the field of information technology (IT). The project is coordinated by Centre TIME of the Grenoble école de management.\n\n\nFollowing the completion of the project the following goals are hoped to have been met:\n\nThe integrating activities have two levels: \n\n\n"}
{"id": "27341309", "url": "https://en.wikipedia.org/wiki?curid=27341309", "title": "Medici Oriental Press", "text": "Medici Oriental Press\n\nThe Medici Oriental Press (also Typographia Medicea) was a press established by Ferdinand de Medici in the 16th century. This press produced some of the earliest books printed in Arabic. The press was active from 1584 to 1614. \n\nThe press initially benefited from the oriental manuscripts contributed by Ignatius Nemet Allah I, Patriarch of the Syriac Orthodox Patriarch of Antioch, then in exile in Italy. \n\nThe Medici Oriental Press published Christian religious works in oriental languages, such as the Gospels which were printed in Arabic in 1591, with the objective of converting Muslims.\n\nThe Press also produced scientific books in the original Arabic language, possibly for European scientist to gain direct access to Arabic works.\n\nThe Press received from the Pope a monopoly to print books in \"foreign languages\".\n\nRobert Granjon of Paris (who also worked for the \"Typographia Vaticana\") was employed to cut Oriental typefaces, and Giovan Battista Raimondi from Cremona was designated as the manager of the Press. \n\n"}
{"id": "7375898", "url": "https://en.wikipedia.org/wiki?curid=7375898", "title": "Microwave limb sounder", "text": "Microwave limb sounder\n\nThe microwave limb sounder (MLS) experiments measure (naturally occurring) microwave thermal emission from the limb (edge) of Earth's upper atmosphere. The data is used to create vertical profiles of atmospheric gases, temperature, pressure, and cloud ice.\n\n\n\n"}
{"id": "3561094", "url": "https://en.wikipedia.org/wiki?curid=3561094", "title": "Modifiable areal unit problem", "text": "Modifiable areal unit problem\n\nThe modifiable areal unit problem (MAUP) is a source of statistical bias that can significantly impact the results of statistical hypothesis tests. MAUP affects results when point-based measures of spatial phenomena are aggregated into districts, for example, population density or illness rates. The resulting summary values (e.g., totals, rates, proportions, densities) are influenced by both the shape and scale of the aggregation unit.\n\nFor example, census data may be aggregated into county districts, census tracts, postcode areas, police precincts, or any other arbitrary spatial partition. Thus the results of data aggregation are dependent on the mapmaker's choice of which \"modifiable areal unit\" to use in their analysis. A census choropleth map calculating population density using state boundaries will yield radically different results than a map that calculates density based on county boundaries. Furthermore, census district boundaries are also subject to change over time, meaning the MAUP must be considered when comparing past data to current data.\n\nThe issue was first recognized by Gehlke and Biehl in 1934 and later described in detail in a famous article by Openshaw (1984) and in the book by Arbia (1988). In particular, Openshaw (1984) observed that \"the areal units (zonal objects) used in many geographical studies are arbitrary, modifiable, and subject to the whims and fancies of whoever is doing, or did, the aggregating\". The problem is especially apparent when the aggregate data are used for cluster analysis for spatial epidemiology, spatial statistics or choropleth mapping, in which misinterpretations can easily be made without realizing it. Many fields of science, especially human geography are prone to disregard the MAUP when drawing inferences from statistics based on aggregated data. MAUP is closely related to the topic of ecological fallacy and ecological bias (Arbia, 1988).\n\nEcological bias caused by MAUP has been documented as two separate effects that usually occur simultaneously during the analysis of aggregated data. The scale effect causes variation in statistical results between different levels of aggregation. Therefore, the association between variables depends on the size of areal units for which data are reported. Generally, correlation increases as areal unit size increases. The zone effect describes variation in correlation statistics caused by the regrouping of data into different configurations at the same scale.\n\nSince the 1930s, research has found extra variation in statistical results because of the MAUP. The standard methods of calculating within-group and between-group variance do not account for the extra variance seen in MAUP studies as the groupings change. MAUP can be used as a methodology to calculate upper and lower limits as well as average regression parameters for multiple sets of spatial groupings.\n\nSeveral suggestions have been made in literature to reduce aggregation bias during regression analysis. A researcher might correct the variance-covariance matrix using samples from individual-level data. Alternatively, one might focus on local spatial regression rather than global regression. A researcher might also attempt to design areal units to maximize a particular statistical result. Others have argued that it may be difficult to construct a single set of optimal aggregation units for multiple variables, each of which may exhibit non-stationarity and spatial autocorrelation across space in different ways. Others have suggested developing statistics that change across scales in a predictable way, perhaps using fractal dimension as a scale-independent measure of spatial relationships. Others have suggested Bayesian hierarchical models as a general methodology for combining aggregated and individual-level data for ecological inference.\n\nStudies of the MAUP based on empirical data can only provide limited insight due to an inability to control relationships between multiple spatial variables. Data simulation is necessary to have control over various properties of individual-level data. Simulation studies have demonstrated that the spatial support of variables can affect the magnitude of ecological bias caused by spatial data aggregation.\n\nUsing simulations for univariate data, Larsen advocated the use of a Variance Ratio to investigate the effect of spatial configuration, spatial association, and data aggregation. A detailed description of the variation of statistics due to MAUP is presented by Reynolds, who demonstrates the importance of the spatial arrangement and spatial autocorrelation of data values. Reynold’s simulation experiments were expanded by Swift, who in which a series of nine exercises began with simulated regression analysis and spatial trend, then focused on the topic of MAUP in the context of spatial epidemiology. A method of MAUP sensitivity analysis is presented that demonstrates that the MAUP is not entirely a problem. MAUP can be used as an analytical tool to help understand spatial heterogeneity and spatial autocorrelation.\n\nThis topic is of particular importance because in some cases data aggregation can obscure a strong correlation between variables, making the relationship appear weak or even negative. Conversely, MAUP can cause random variables to appear as if there is a significant association where there is not. Multivariate regression parameters are more sensitive to MAUP than correlation coefficients. Until a more analytical solution to MAUP is discovered, spatial sensitivity analysis using a variety of areal units is recommended as a methodology to estimate the uncertainty of correlation and regression coefficients due to ecological bias. An example of data simulation and re-aggregation using the ArcPy library is available.\nIn transport planning, MAUP is associated to Traffic Anaisis Zoning (TAZ). A major point of departure in understanding problems in transportation analysis is the recognition that spatial analysis has some limitations associated with the discretization of space. Among them, modifiable areal units and boundary problems are directly or indirectly related to transportation planning and analysis through the design of traffic analysis zones (TAZs) - most of transport studies require directly or indirectly the definition of TAZs. The modifiable boundary and the scale issues should all be given specific attention during the specification of a TAZ because of the effects these factors exert on statistical and mathematical properties of spatial patterns (ie the modifiable areal unit problem—MAUP). In the studies of Viegas, Martinez and Silva (2009, 2009b) the authors propose a method where the results obtained from the study of spatial data are not independent of the scale, and the aggregation effects are implicit in the choice of zonal boundaries. The delineation of zonal boundaries of TAZs has a direct impact on the reality and accuracy of the results obtained from transportation forecasting models. In this paper the MAUP effects on the TAZ definition and the transportation demand models are measured and analyzed using different grids (in size and in origin location). This analysis was developed by building an application integrated in commercial GIS software and by using a case study (Lisbon Metropolitan Area) to test its implementabiity and performance. The results reveal the conflict between statistical and geographic precision, and their relationship with the loss of information in the traffic assignment step of the transportation planning models.\n\nGeneral topics\n\nSpecific applications\n\n\n"}
{"id": "50224430", "url": "https://en.wikipedia.org/wiki?curid=50224430", "title": "Nanoelectromechanical systems mass spectrometer", "text": "Nanoelectromechanical systems mass spectrometer\n\nA nanoelectromechanical systems mass spectrometer (NEMS-MS) is an instrument measuring the mass of analyte particles by detecting the frequency shift caused by the adsorption of the particles on a NEMS resonator.\n\nNEMS-MS was invented by Prof. Michael Roukes and Dr. Kamil Ekinci at the California Institute of Technology in 1999.\nFirst attainment of attogram-scale mass sensitivity was documented in their 2001 patent disclosure. Successive NEMS-MS sensitivity milestones were reported by the Caltech researchers in publications appearing in 2004 (attogram-scale sensitivity) \nand in 2006 (zeptogram-scale sensitivity).\nThey later developed single molecule analysis in 2009.\nSingle-biomolecule mass measurements were first accomplished by this team in 2012.\nA hybrid NEMS-MS/TOF-MS instrument was reported in 2015.\n\n\n"}
{"id": "7985488", "url": "https://en.wikipedia.org/wiki?curid=7985488", "title": "OpenLayers", "text": "OpenLayers\n\nOpenLayers is an open-source (provided under the 2-clause BSD License) JavaScript library for displaying map data in web browsers as slippy maps. It provides an API for building rich web-based geographic applications similar to Google Maps and Bing Maps.\n\nOpenLayers supports GeoRSS, KML (Keyhole Markup Language), Geography Markup Language (GML), GeoJSON and map data from any source using OGC-standards as Web Map Service (WMS) or Web Feature Service (WFS).\n\nThe library was originally based on the Prototype JavaScript Framework.\n\nOpenLayers was created by MetaCarta after the O'Reilly Where 2.0 conference of June 29–30, 2005, and released as open source software before the Where 2.0 conference of June 13–14, 2006, by MetaCarta Labs. Two other open-source mapping tools released by MetaCarta are FeatureServer and TileCache. Since November 2007, OpenLayers has been an Open Source Geospatial Foundation project.\n"}
{"id": "2259607", "url": "https://en.wikipedia.org/wiki?curid=2259607", "title": "Pickling", "text": "Pickling\n\nPickling is the process of preserving or extending the lifespan of food by either anaerobic fermentation in brine or immersion in vinegar. The resulting food is called a \"pickle\", or, to prevent ambiguity, prefaced with \"pickled\". The pickling procedure will typically affect the food's texture and flavor. In East Asia, vinaigrette (vegetable oil and vinegar) is also used as a pickling medium. Foods that are pickled include meats, fruits, eggs, and vegetables.\n\nAnother distinguishing characteristic is a pH of 4.6 or lower, which is sufficient to kill most bacteria. Pickling can preserve perishable foods for months. Antimicrobial herbs and spices, such as mustard seed, garlic, cinnamon or cloves, are often added. If the food contains sufficient moisture, a pickling brine may be produced simply by adding dry salt. For example, German sauerkraut and Korean kimchi are produced by salting the vegetables to draw out excess water. Natural fermentation at room temperature, by lactic acid bacteria, produces the required acidity. Other pickles are made by placing vegetables in vinegar. Like the canning process, pickling (which includes fermentation) does not require that the food be completely sterile before it is sealed. The acidity or salinity of the solution, the temperature of fermentation, and the exclusion of oxygen determine which microorganisms dominate, and determine the flavor of the end product.\n\nWhen both salt concentration and temperature are low, \"Leuconostoc mesenteroides\" dominates, producing a mix of acids, alcohol, and aroma compounds. At higher temperatures \"Lactobacillus plantarum\" dominates, which produces primarily lactic acid. Many pickles start with \"Leuconostoc\", and change to \"Lactobacillus\" with higher acidity.\n\nThe exact origins of pickling are unknown, but the ancient Mesopotamians may have used the process around 2400 B.C. Pickling was used as a way to preserve food for out-of-season use and for long journeys, especially by sea. Salt pork and salt beef were common staples for sailors before the days of steam engines. Although the process was invented to preserve foods, pickles are also made and eaten because people enjoy the resulting flavors. Pickling may also improve the nutritional value of food by introducing B vitamins produced by bacteria.\n\nThe term \"pickle\" is derived from the Dutch word \"pekel\", meaning \"brine\". In the U.S. and Canada, and sometimes Australia and New Zealand, the word \"pickle\" alone almost always refers to a pickled cucumber, except when it is used figuratively. It may also refer to other types of pickles such as \"pickled onion\", \"pickled cauliflower\", etc. In the UK, pickle, as in a \"cheese and pickle sandwich\", may also refer to Ploughman's pickle, a kind of chutney.\n\nSouth Asia has a large variety of pickles (known as \"achar\" (आचार) in Assamese, Bengali, Hindi, Punjabi, \"uppinakaayi\" in Kannada, \"lonacha\" (लोणचं) in Marathi, \"uppilittathu\" or \"achar\" in Malayalam, \"oorukai\" in Tamil, \"ooragaya\" in Telugu), which are mainly made from varieties of mango, lemon, lime, goongura(a sour leafy shrub), tamarind and Indian gooseberry (amla), chilli. Vegetables such as eggplant, carrots, cauliflower, tomato, bitter gourd, green tamarind, ginger, garlic, onion, and citron are also occasionally used. These fruits and vegetables are generally mixed with ingredients like salt, spices, and vegetable oils and are set to mature in a moistureless medium.\n\nIn Pakistan, pickles are known locally as \"achaar\" (in Urdu) and come in a variety of flavors. A popular item is the traditional mixed Hyderabadi pickle, a common delicacy prepared from an assortment of fruits (most notably mangoes) and vegetables blended with selected spices.\n\nIn Sri Lanka, \"achcharu\" is traditionally prepared from carrots, onions, and ground dates that are mixed with mustard powder, ground pepper, crushed ginger, garlic, and vinegar, and left to sit in a clay pot.\n\nSingapore, Indonesian and Malaysian pickles, called \"acar\", are typically made out of cucumber, carrot, bird's eye chilies, and shallots, these items being seasoned with vinegar, sugar and salt. Fruits, such as papaya and pineapple, are also sometimes pickled.\n\nIn the Philippines, \"achara\" is primarily made out of green papaya, carrots, and shallots, with cloves of garlic and vinegar. Other versions could include ginger, bell peppers, white radishes, cucumbers or bamboo shoots. Separately, in some provinces, unripe mangoes or \"burong mangga\", unripe tomatoes, guavas, jicama, bitter gourd and other fruit and vegetables are also pickled. Siling labuyo, sometimes with garlic and red onions, are also pickled in bottled vinegar. The spiced vinegar itself is a staple condiment in Filipino cuisine.\n\nIn Vietnamese cuisine, vegetable pickles are called (\"salted vegetables\") or (\"sour vegetables\"). or is made from a variety of fruits and vegetables, including , eggplant, Napa cabbage, kohlrabi, carrots, radishes, papaya, cauliflower, and . made from carrots and radishes are commonly added to sandwiches. is made by pressing and sun-drying vegetables such as and bok choy. is a specialty of Nghệ An and Hã Tĩnh provinces made from jackfruit.\n\nIn Burma, tea leaves are pickled to produce lahpet, which has strong social and cultural importance.\n\nChina is home to a huge variety of pickled vegetables, including radish, \"baicai\" (Chinese cabbage, notably \"suan cai\", \"la bai cai\", \"pao cai\", and Tianjin preserved vegetable), \"zha cai\", chili pepper, and cucumbers, among many others.\n\nJapanese \"tsukemono\" (pickled foods) include \"takuan\" (daikon), \"umeboshi\" (ume plum), \"gari\" & \"beni shōga\" (ginger), turnip, cucumber, and Chinese cabbage.\n\nThe Korean staple kimchi is usually made from pickled napa cabbage and radish, but is also made from green onions, garlic stems, chives and a host of other vegetables. Kimchi is popular throughout East Asia. Jangajji is another example of pickled vegetables.\n\nIn Iran, Turkey, Arab countries, the Balkans, and the Caucasus, pickles (called torshi in Persian, \"turşu\" in Turkish language and \"mekhallel\" in Arabic) are commonly made from turnips, peppers, carrots, green olives, cucumbers, cabbage, green tomatoes, lemons, and cauliflower.\n\nIn Hungary the main meal \"(lunch)\" usually goes with some kind of pickles \"(savanyúság)\" but they are commonly consumed at other times of the day too. The most commonly consumed pickles are sauerkraut \"(savanyú káposzta)\", the different kinds of pickled cucumbers and peppers and \"csalamádé\" but tomatoes, carrots, beetroot, baby corn, onions, garlic, certain squashes and melons and a few fruits like plums and apples are used to make pickles too. Stuffed pickles are specialties usually made of peppers or melons pickled after being stuffed with a cabbage filling. Pickled plum stuffed with garlic is a unique Hungarian type of pickle just like \"csalamádé\" and leavened cucumber \"(kovászos uborka)\". \"Csalamádé\" a type of mixed pickle made of cabbage, cucumber, paprika, onion, carrot, tomatoes and bay leaf mixed up with vinegar as the fermenting agent. Leavened cucumber, unlike other types of pickled cucumbers that are around all year long, is rather a seasonal pickle produced in the summer. Cucumbers, spices, herbs and slices of bread are put in a glass jar with salt water and kept in direct sunlight for a few days. The yeast from the bread, along with other pickling agents and spices fermented under the hot sun, give the cucumbers a unique flavor, texture and slight carbonation. Its juice can be used to make a special type of spritzer \"('Újházy fröccs')\" instead of carbonated water.\nIt is common for Hungarian households to produce their own pickles. Different regions or towns have their special recipes unique to them. Among them all the Vecsési Sauerkraut \"(Vecsési savanyú káposzta)\" is the most famous.\nRomanian pickles (murături) are made out of beetroot, cucumbers, green tomatoes (\"gogonele\"), carrots, cabbage, garlic, sauerkraut (bell peppers stuffed with cabbage), bell peppers, melons, mushrooms, turnips, celery and cauliflower. Meat, like pork, can also be preserved in salt and lard.\n\nPolish, Czech and Slovak traditional pickles are cucumbers and sauerkraut, but other pickled fruits and vegetables, including plums, pumpkins and mushrooms are also common.\n\nRussian, Ukrainian and Belarusian pickled items include beets, mushrooms, tomatoes, sauerkraut, cucumbers, ramsons, garlic, eggplant (which is typically stuffed with julienned carrots), custard squash, and watermelon. Garden produce is commonly pickled using salt, dill, blackcurrant leaves, bay leaves and garlic and is stored in a cool, dark place. The leftover brine (called \"rassol\" (рассол) in Russian) has a number of culinary uses in these countries, especially for cooking traditional soups, such as shchi, rassolnik, and solyanka. \"Rassol\", especially cucumber or sauerkraut rassol, is also a favorite traditional remedy against morning hangover.\n\nAn Italian pickled vegetable dish is giardiniera, which includes onions, carrots, celery and cauliflower. Many places in southern Italy, particularly in Sicily, pickle eggplants and hot peppers.\n\nIn Albania, Bulgaria, Serbia, Macedonia and Turkey, mixed pickles, known as \"turshi\", \"tursija\" or \"turshu\" form popular appetizers, which are typically eaten with \"rakia\". Pickled green tomatoes, cucumbers, carrots, bell peppers, peppers, eggplants, and sauerkraut are also popular.\n\nTurkish pickles, called \"turşu\", are made out of vegetables, roots, and fruits such as peppers, cucumber, Armenian cucumber, cabbage, tomato, eggplant (aubergine), carrot, turnip, beetroot, green almond, baby watermelon, baby cantaloupe, garlic, cauliflower, bean and green plum. A mixture of spices flavor the pickles.\n\nIn Greece, pickles, called \"τουρσί(α)\", are made out of carrots, celery, eggplants stuffed with diced carrots, cauliflower, tomatoes, and peppers.\n\nIn Britain, pickled onions and pickled eggs are often sold in pubs and fish and chip shops. Pickled beetroot, walnuts, and gherkins, and condiments such as Branston Pickle and piccalilli are typically eaten as an accompaniment to pork pies and cold meats, sandwiches or a ploughman's lunch. Other popular pickles in the UK are pickled mussels, cockles, red cabbage, mango chutney, sauerkraut, and olives. Rollmops are also quite widely available under a range of names from various producers both within and out of the UK.\n\nPickled herring, rollmops, and salmon are popular in Scandinavia. Pickled cucumbers and red garden beets are important as condiments for several traditional dishes. Pickled capers are also common in Scandinavian cuisine.\n\nIn the United States and Canada, pickled cucumbers (most often referred to simply as \"pickles\" in Canada and the United States), olives, and sauerkraut are most commonly seen, although pickles common in other nations are also available.\n\nCanadian pickling is similar to that of Britain. Through the winter, pickling is an important method of food preservation. Pickled cucumbers, onions, and eggs are common individual pickled foods seen in Canada. Chow-chow is a tart vegetable mix popular in the Maritime Provinces and the Southern United States, similar to piccalilli. Pickled fish is commonly seen, as in Scotland. Meat is often also pickled or preserved in different brines throughout the winter, most prominently in the harsh climate of Newfoundland.\n\nGiardiniera, a mixture of pickled peppers, celery and olives, is a popular condiment in Chicago and other cities with large Italian-American populations, and is often consumed with Italian beef sandwiches. Pickled eggs are common in the Upper Peninsula of Michigan. Pickled herring is available in the Upper Midwest. Pennsylvania Dutch Country has a strong tradition of pickled foods, including chow-chow and red beet eggs. In the Southern United States, pickled okra and watermelon rind are popular, as are deep-fried pickles and pickled pig's feet, pickled chicken eggs, pickled quail eggs, pickled garden vegetables and pickled sausage. In Mexico, chili peppers, particularly of the Jalapeño and serrano varieties, pickled with onions, carrots and herbs form common condiments. Various pickled vegetables, fish, or eggs may make a side dish to a Canadian lunch or dinner. Popular pickles in the Pacific Northwest include pickled asparagus and green beans. Pickled fruits like blueberries and early green strawberries are paired with meat dishes in restaurants. \n\nIn the United States, National Pickle Day is recognized as a food \"holiday\" every year on November 14.\n\nIn the Mesoamerican region pickling is known as \"encurtido\" or \"curtido\" for short. The pickles or \"curtidos\" as known in Latin America are served cold, as an appetizer, as a side dish or as a tapas dish in Spain. In several Central American countries it is prepared with cabbage, onions, carrots, lemon, vinegar, oregano, and salt. In Mexico, \"curtido\" consists of carrots, onions, and jalapeño peppers and used to accompany meals still common in taquerias and restaurants. In order to prepare a carrot \"curtido\" simply add carrots to vinegar and other ingredients that are common to the region such as chilli, tomato, and onions. Varies depending on the food, in the case of sour. Another example of a type of pickling which involves the pickling of meats or seafood is the \"escabeche\" or \"ceviches\" popular in Peru, Ecuador, and throughout Latin America and the Caribbean. These dishes include the pickling of pig's feet, pig's ears, and gizzards prepared as an \"escabeche\" with spices and seasonings to flavor it. The ceviches consists of shrimp, octopus, and various fishes seasoned and served cold.\n\nIn traditional pickling, fruit or vegetables are submerged in brine (20-40 grams/L of salt (3.2–6.4 oz/imp gal or 2.7–5.3 oz/US gal)), or shredded and salted as in sauerkraut preparation, and held underwater by flat stones layered on top. Alternatively, a lid with an airtrap or a tight lid may be used if the lid is able to release pressure which may result from carbon dioxide buildup. Mold or (white) kahm yeast may form on the surface; kahm yeast is mostly harmless but can impart an off taste and may be removed without affecting the pickling process.\n\nIn chemical pickling, the fruits or vegetables to be pickled are placed in a sterilized jar along with brine, vinegar, or both, as well as spices, and are then allowed to mature until the desired taste is obtained.\n\nThe food can be pre-soaked in brine before transferring to vinegar. This reduces the water content of the food, which would otherwise dilute the vinegar. This method is particularly useful for fruit and vegetables with a high natural water content.\n\nIn commercial pickling, a preservative such as sodium benzoate or EDTA may also be added to enhance shelf life. In fermentation pickling, the food itself produces the preservation agent, typically by a process involving \"Lactobacillus\" bacteria that produce lactic acid as the preservative agent.\n\nAlum is used in pickling to promote crisp texture and is approved as a food additive by the United States Food and Drug Administration.\n\n\"Refrigerator pickles\" are unfermented pickles made by marinating fruit or vegetables in a seasoned vinegar solution. They must be stored under refrigeration or undergo canning to achieve long-term storage.\n\nJapanese Tsukemono use a variety of pickling ingredients depending on their type , and are produced by combining these ingredients with the vegetables to be preserved and putting the mixture under pressure.\n\nThe World Health Organization has listed pickled vegetables as a possible carcinogen, and the \"British Journal of Cancer\" released an online 2009 meta-analysis of research on pickles as increasing the risks of esophageal cancer. The report, citing limited data in a statistical meta analysis, indicates a potential two-fold increased risk of oesophageal cancer associated with Asian pickled vegetable consumption. Results from the research are described as having \"high heterogeneity\" and the study said that further well-designed prospective studies were warranted. However, their results stated \"The majority of subgroup analyses showed a statistically significant association between consuming pickled vegetables and Oesophageal Squamous Cell Carcinoma\".\n\nThe 2009 meta-analysis reported heavy infestation of pickled vegetables with fungi. Some common fungi can facilitate the formation of N-nitroso compounds, which are strong oesophageal carcinogens in several animal models. Roussin red methyl ester, a non-alkylating nitroso compound with tumour-promoting effect in vitro, was identified in pickles from Linxian in much higher concentrations than in samples from low-incidence areas. Fumonisin mycotoxins have been shown to cause liver and kidney tumours in rodents.\n\nA 2017 study in \"Chinese Journal of Cancer\" has linked salted vegetables (common among Chinese cuisine) to a 4-fold increase in nasopharynx cancer, where fermentation was a critical step in creating nitrosamines, which some are confirmed carcinogens, as well as activation of Epstein–Barr virus by fermentation products.\n\n"}
{"id": "14341044", "url": "https://en.wikipedia.org/wiki?curid=14341044", "title": "Preselector", "text": "Preselector\n\nA preselector is a name for an electronic device that connects between a radio antenna and a radio receiver. The preselector is a band-pass filter that blocks troublesome out-of-tune frequencies from passing through from the antenna into the radio receiver (or preamplifier) that otherwise would be directly connected to the antenna.\n\nA preselector improves the performance of nearly any receiver, but is especially helpful to receivers with broadband front-ends that are prone to overload, such as scanners and ordinary consumer-market shortwave and AM broadcast receivers. However, receivers and preamps get no benefit from preselection if they are fed from a narrow-band source, such as a small loop antenna.\nA preselector typically is tuned to have a narrow bandwidth, centered on the receiver’s operating frequency. The preselector passes through the signal on the frequency it is tuned to unchanged, or only slightly diminished, but it reduces or removes off-frequency signals, cutting down or eliminating unwanted interference. However, a preselector does \"not\" remove interference on the \"same\" frequency that it and the receiver are both tuned to.\n\nExtra filtering can be useful because the first input stage (“front end”) of receivers contains at least one RF amplifier, which has a limited capacity (dynamic range). Most radios’ front ends amplify \"all\" radio frequencies delivered to the antenna connection. So off-frequency signals constitute a load on the RF amplifier, using part of its dynamic range for unused signals. “Limited dynamic range” means that the amplifier circuits have a limit to the total amount of incoming RF energy they can handle without overloading, symptoms of which are nonlinearity and ultimately clipping.\n\nWhen the front-end overloads, the performance of the receiver is severely reduced, and in extreme cases can damage the receiver. In situations with noisy and crowded bands, or where there are strong local stations, the dynamic range of the receiver can quickly be exceeded. Extra filtering by the preselector limits frequency range and power demands that are applied to all later stages of the receiver, only loading it with signals within the preselected band.\n\nA preselector can be engineered so that in addition to attenuating interference from unwanted frequencies, it will perform other services which may be helpful for a receiver: It can limit input signal voltage to protect a sensitive receiver from damage caused by static discharge, nearby voltage spikes, and overload from nearby transmitters’ signals. It can also incorporate a small radio frequency amplifier stage to boost the filtered signal, although for typical use, amplification at the preselector is unnecessary. None of these extra conveniences is an essential part of preselection.\n\nAntenna preamplifiers (preamps) can be made “tunable” by incorporating a front-end preselector circuit to improve their performance. The integrated device is \"both\" a preamplifier and a preselector, and either name is correct. This ambiguity sometimes leads to confusion. A \"passive preselector\" has no power and no internal amplifier, and typically works quite well with modern receivers, with negligible signal-loss.\n\nWith all preselectors there is some loss at the tuned frequency; usually, most of the loss is in the inductor (the tuning coil). Tuning the preselector for narrower bandwidth (or higher \", or greater selectivity) increases this loss.\n\nMost preselectors have separate settings for an inductor and (at least) one capacitor. So with at least two adjustments available to tune to just one frequency, there are often a variety of settings that will tune the preselector to a frequency in its middle-range.\n\nFor the narrowest bandwidth (highest \"), the preselector is tuned using the highest inductance and lowest capacitance for the desired frequency, but this produces the greatest loss. It also requires retuning the preselector more often while searching for faint signals, to keep the preselector’s pass-through frequency closely aligned with the receiver’s working frequency.\n\nFor lowest loss (and widest bandwidth), the preselector is tuned using the lowest inductance and highest capacitance (and the lowest \"\", or least selectivity) for the desired frequency. The wider bandwidth allows interference through from more nearby frequencies, but reduces the need to retune the preselector while tuning the receiver, since any one low-inductance setting for the preselector will pass many nearby frequencies.\n\nAlthough a preselector is placed in the same location as an antenna tuner, it serves a different purpose: An antenna tuner or “transmatch” connects two signal lines with different signal impedances and only blocks out-of-tune frequencies incidentally (if it blocks any at all).\n\nA transmatch matches transmitter impedance to feedline impedance, so that signal power from the radio transmitter smoothly transfers into the antenna’s feed cable; a properly adjusted transmatch prevents transmitted power from being reflected back into the transmitter (called \"‘backlash current’\"). Some antenna tuner circuits can both impedance match and preselect, for example the \"Series Parallel Capacitor\" (SPC) tuner, and most circuits for \"balanced line\" (BLT) tuners can be adjusted to also function as band-pass filters.\n\nSome simpler types of antenna tuners that are not band-pass circuits can also provide limited preselection. The now-common ‘T’-network is a high-pass circuit which always essentially eliminates frequencies \"below\" the operating frequency, and can be adjusted for high operating \"\" that might attenuate noise by as much as 20 dB \"above\" the operating frequency. The complementary ‘π’-network, customarily incorporated in the final stage of ‘vintage’ tube transmitters and amplifiers, is low-pass and always essentially eliminates frequencies \"above\" the tuned frequency; it can be similarly adjusted to provide as much as 20 dB attenuation below the tuned frequency.\n\n\n"}
{"id": "1217160", "url": "https://en.wikipedia.org/wiki?curid=1217160", "title": "Prompt criticality", "text": "Prompt criticality\n\nIn nuclear engineering, prompt criticality is said to be reached during a nuclear fission event if one or more of the immediate or prompt neutrons released by an atom in the event causes an additional fission event resulting in a rapid, exponential increase in the number of fission events. Prompt criticality is a special case of supercriticality.\n\nAn assembly is critical if each fission event causes, on average, exactly one additional such event in a continual chain. Such a chain is a self-sustaining fission chain reaction. When a uranium-235 (U-235) atom undergoes nuclear fission, it typically releases between one and seven neutrons (with an average of 2.4). In this situation, an assembly is critical if every released neutron has a 1/2.4 = 0.42 = 42% probability of causing another fission event as opposed to either being absorbed by a non-fission capture event or escaping from the fissile core.\n\nThe average number of neutrons that cause new fission events is called the effective neutron multiplication factor, usually denoted by the symbols \"k-effective\", \"k-eff\" or \"k\". When \"k-effective\" is equal to 1, the assembly is called critical, if \"k-effective\" is less than 1 the assembly is said to be subcritical, and if \"k-effective\" is greater than 1 the assembly is called supercritical.\n\nIn a supercritical assembly the number of fissions per unit time, \"N\", along with the power production, increases exponentially with time. How fast it grows depends on the average time it takes, \"T\", for the neutrons released in a fission event to cause another fission. The growth rate of the reaction is given by:\n\nMost of the neutrons released by a fission event are the ones released in the fission itself. These are called prompt neutrons, and strike other nuclei and cause additional fissions within nanoseconds (an average time interval used by scientists in the Manhattan Project was one shake, or 10 nanoseconds). A small additional source of neutrons is the fission products. Some of the nuclei resulting from the fission are radioactive isotopes with short half-lives, and nuclear reactions among them release additional neutrons after a long delay of up to several minutes after the initial fission event. These neutrons, which on average account for less than one percent of the total neutrons released by fission, are called delayed neutrons. The relatively slow timescale on which delayed neutrons appear is an important aspect for the design of nuclear reactors, as it allows the reactor power level to be controlled via the gradual, mechanical movement of control rods. Typically, control rods contain neutron poisons (substances, for example boron or hafnium, that easily capture neutrons without producing any additional ones) as a means of altering \"k-effective\". With the exception of experimental pulsed reactors, nuclear reactors are designed to operate in a delayed-critical mode and are provided with safety systems to prevent them from ever achieving prompt criticality.\n\nIn a delayed-critical assembly, the delayed neutrons are needed to make \"k-effective\" greater than one. Thus the time between successive generations of the reaction, \"T\", is dominated by the time it takes for the delayed neutrons to be released, on the order of seconds or minutes. Therefore, the reaction will increase slowly, with a long time constant. This is slow enough to allow the reaction to be controlled with electromechanical control systems such as control rods, and as such all nuclear reactors are designed to operate in the delayed-criticality regime.\n\nIn contrast, a critical assembly is said to be prompt-critical if it is critical (\"k=1\") without any contribution from delayed neutrons and prompt-supercritical if it is supercritical (the fission rate growing exponentially, \"k>1\") without any contribution from delayed neutrons. In this case the time between successive generations of the reaction, \"T\", is only limited by the fission rate from the prompt neutrons, and the increase in the reaction will be extremely rapid, causing a rapid release of energy within a few milliseconds. Prompt-critical assemblies are created by design in nuclear weapons and some specially designed research experiments.\n\nWhen differentiating between a prompt neutron versus a delayed neutron, the difference between the two has to do with the source from which the neutron has been released into the reactor. The neutrons, once released, have no difference except the energy or speed which have been imparted to them. A nuclear weapon relies heavily on prompt-supercriticality (to produce a high peak power in a fraction of a second), whereas nuclear power reactors use delayed-criticality to produce controllable power levels for months or years.\n\nIn order to start up a controllable fission reaction, the assembly must be delayed-critical. In other words, \"k\" must be greater than 1 (supercritical) without crossing the prompt-critical threshold. In nuclear reactors this is possible due to delayed neutrons. Because it takes some time before these neutrons are emitted following a fission event, it is possible to control the nuclear reaction using control rods.\n\nA steady-state (constant power) reactor is operated so that it is critical due to the delayed neutrons, but would not be so without their contribution. During a gradual and deliberate increase in reactor power level, the reactor is delayed-supercritical. The exponential increase of reactor activity is slow enough to make it possible to control the criticality factor, \"k\", by inserting or withdrawing rods of neutron absorbing material. Using careful control rod movements, it is thus possible to achieve a supercritical reactor core without reaching an unsafe prompt-critical state.\n\nOnce a reactor plant is operating at its target or design power level, it can be operated to maintain its critical condition for long periods of time.\n\nNuclear reactors can be susceptible to prompt-criticality accidents if a large increase in reactivity (or \"k-effective\") occurs, e.g., following failure of their control and safety systems. The rapid uncontrollable increase in reactor power in prompt-critical conditions is likely to irreparably damage the reactor and in extreme cases, may breach the containment of the reactor. Nuclear reactors' safety systems are designed to prevent prompt criticality and, for defense in depth, reactor structures also provide multiple layers of containment as a precaution against any accidental releases of radioactive fission products.\n\nWith the exception of research and experimental reactors, only a small number of reactor accidents are thought to have achieved prompt criticality, for example Chernobyl #4, the U.S. Army's SL-1, and Soviet submarine \"K-431\". In all these examples the uncontrolled surge in power was sufficient to cause an explosion that destroyed each reactor and released radioactive fission products into the atmosphere.\n\nAt Chernobyl in 1986, an unusual and unsafe test was performed that resulted in an overheated reactor core. This led to the rupturing of the fuel elements and water pipes, vaporization of water, a steam explosion, and a graphite fire. Estimated power levels prior to the incident suggest that it operated in excess of 30 GW, ten times its 3 GW maximum thermal output. The reactor chamber's 2000-ton lid was lifted by the steam explosion. Since the reactor was not designed with a containment building capable of containing this catastrophic explosion, the accident released large amounts of radioactive material into the environment. The catastrophic fire in the graphite neutron moderator compounded the problem, sending massive amounts of radioactive debris into the atmosphere.\n\nIn the other two incidents, the reactor plants failed due to errors during a maintenance shutdown that was caused by the rapid and uncontrolled removal of at least one control rod. The SL-1 was a prototype reactor intended for use by the US Army in remote polar locations. At the SL-1 plant in 1961, the reactor was brought from shutdown to prompt critical state by manually extracting the central control rod too far. As the water in the core quickly converted to steam and expanded (in just a few milliseconds), the reactor vessel jumped , leaving impressions in the ceiling above. All three men performing the maintenance procedure died from injuries. 1,100 curies of fission products were released as parts of the core were expelled. It took 2 years to investigate the accident and clean up the site. The excess prompt reactivity of the SL-1 core was calculated in a 1962 report:\n\nIn the \"K-431\" reactor accident, 10 were killed during a refueling operation. The \"K-431\" explosion destroyed the adjacent machinery rooms and ruptured the submarine's hull. In these two catastrophes, the reactor plants went from complete shutdown to extremely high power levels in a fraction of a second, damaging the reactor plants beyond repair.\n\nA number of research reactors and tests have purposely examined the operation of a prompt critical reactor plant. CRAC, KEWB, SPERT-I, Godiva device, and BORAX experiments contributed to this research. However, many accidents have also occurred, primarily during research and processing of nuclear fuel. SL-1 is the notable exception.\n\nThe following list of prompt critical power excursions is adapted from a report submitted in 2000 by a team of American and Russian nuclear scientists who studied criticality accidents, published by the Los Alamos Scientific Laboratory, the location of many of the excursions. A typical power excursion is about 1 x 10 fissions.\n\nIn the design of nuclear weapons, on the other hand, achieving prompt criticality is essential. Indeed, one of the design problems to overcome in constructing a bomb is to compress the fissile materials enough to achieve prompt criticality before the chain reaction has a chance to produce enough energy to cause the core to expand. A good bomb design must therefore win the race to a dense, prompt critical core before a less-powerful chain reaction disassembles the core without allowing a significant amount of fuel to fission (known as a fizzle). This generally means that nuclear bombs need special attention paid to the way the core is assembled, such as the implosion method invented by Richard C. Tolman, Robert Serber, and other scientists at the University of California, Berkeley in 1942.\n\n\n"}
{"id": "14353255", "url": "https://en.wikipedia.org/wiki?curid=14353255", "title": "Rotary cutter", "text": "Rotary cutter\n\nA rotary cutter is a tool generally used by quilters to cut fabric. It consists of a handle with a circular blade that rotates, thus the tool's name. Rotary cutter blades are very sharp, can be resharpened, and are available in different sizes: usually smaller blades are used to cut small curves, while larger blades are used to cut to straight lines and broad curves. Several layers of fabric can be cut simultaneously with a sharp (fresh) blade, making it easier to cut out patchwork pieces of the same shape and size than with scissors. Quilters use rotary cutters with specially designed templates and rulers made of approximately 1/8-inch thick clear or color-tinted plastic. \n\nThe first rotary cutter was introduced by the Olfa company in 1979 for garment making, however, it was quickly adopted by quilters. Prior to the invention of the rotary cutter, quilters traced handmade templates of the necessary shapes onto the wrong side of the fabric and added 1/4-inch seam allowances all around. Templates were often handmade of (cereal box type) cardboard and the pencil wore down the edges with repeated tracings, rendering them inaccurate; new templates would be made several times until all the patchwork pieces were cut. Pieces were usually cut one at a time with dressmaking scissors, which were often heavy and had long blades that were designed for cutting large pieces for garments but were cumbersome to use for cutting small pieces for patchwork. The rotary cutter gained almost immediate widespread use among quilters after its introduction and, along with the accompanying development of strip techniques, revolutionized quilting. \n\nToday there are many companies making rotary cutters. Cutters come in a variety of handle types and some include specialty blades to cut curved or zigzagged lines. Most have retractable blades that can be locked to prevent injury. \n"}
{"id": "5556351", "url": "https://en.wikipedia.org/wiki?curid=5556351", "title": "Royal National College for the Blind", "text": "Royal National College for the Blind\n\nThe Royal National College for the Blind (RNC) is a co-educational specialist residential college of further education based in the English city of Hereford. Students who attend the college are aged over 16 and blind or partially sighted. They can study a wide range of qualifications at RNC, from academic subjects such as English and mathematics to more vocational topics such as performing arts. Alongside regular further education subjects and vocational training, the College offers training in mobility, independent living and personal development.\n\nFounded in 1872 in London as the Royal Normal College and Academy for the Blind, the college had a number of homes before moving to its campus in Hereford; it was renamed the Royal National College for the Blind in the late 1970s. It has been a pioneer in the education of visually impaired people in Britain since the Victorian era, and, as of 2010, is the only college for visually impaired students in the United Kingdom to have been awarded Beacon Status in recognition of its outstanding teaching and learning.\n\nRNC hosts the UK's first VI Sports Academy, having begun as the home of the first football academy for visually impaired players and the England blind football team. It hosted the 2010 World Blind Football Championship and also served as a training facility for participants in the 2012 Paralympic Games. The college is actively involved in the development of assistive technology, including student participation in the Tech Novice Cafe, run for members of the public who are not confident in computer use. Two notable devices were developed at RNC; the Mountbatten Brailler, an electronic braille writer, and the T3, a talking tactile device that helped with the reading of maps and diagrams.\n\nEarly in the 21st century, there was dramatic departmental restructuring at the college, and a significant redevelopment and modernisation of the Hereford campus. The campus, located on Venns Lane, Hereford, is home to RNC's teaching, residential and leisure facilities. Students live in halls of residence, which enable them to gain a level of independence within the college environment. RNC operates a leisure facility, thePoint4, which is open to the public, and conferencing and hotel accommodation under the name Gardner Hall.\n\nThe college is a registered charity (number 1000388), and its Patron is Charles, Prince of Wales. There are several high-profile supporters, including Dave Clarke, former captain of the England and Great Britain blind football teams. RNC has a number of notable people among its alumni, including former Home Secretary David Blunkett. The college was the subject of a 2007 film for the Channel 4 \"Cutting Edge\" documentary strand, which followed three students through their first term of study. The film won a 2008 Royal Television Society Award.\n\nThe college was established in 1871 by the English philanthropist Thomas Rhodes Armitage and the American anti-slavery campaigner Francis Joseph Campbell, who lost his sight as a young boy. Campbell had originally planned to establish a college for the blind in the United States, but was persuaded by Armitage that London would be a more suitable location. At the time, English schools for the blind did not provide their students with the skills to become independent and, dissatisfied with this situation, Armitage dreamed of establishing a school whose emphasis was on music and which would prepare its students for careers as organists, piano tuners, and music teachers.\n\nWith donations of £3,000, the college enrolled its first two students on 1 March 1872. Queen Victoria became its first Patron, while several prominent members of her family became Vice-Patrons. Among those to become governors of the College were Duke of Westminster, Lord Shaftesbury, Lord Lichfield and the Right Hon. W. H. Smith, M.P. At the time of its founding it was called \"The Royal Normal College and Academy for the Blind\", the word \"Normal\" being an American expression referring to teacher training offered by the college, with Campbell recruiting many of his teaching staff from the United States.\n\nOriginally located in two small buildings on Anerley Hill near London's Crystal Palace, the college later moved to larger accommodation at Westow Street, Upper Norwood after rapidly outgrowing its original premises. In its early days, the college was considered very progressive and experimental in its approach to education. A history of the college on its website describes the curriculum as \"liberal and advanced for its day\", and emphasis was placed on physical activities such as swimming, cycling and roller-skating. Students even took part in a morning of tobogganing following a heavy fall of snow. By the end of the 19th century, the college had over 200 students. Until the Second World War the college admitted 11- to 15-year-olds, but in 1945 the principal of RNC and headmaster of Worcester College for the Blind came to an agreement that Worcester would provide secondary education and RNC would take students over the age of 16.\n\nAs well as being one of its founders, Francis Joseph Campbell served as RNC's first principal, from 1871 until his retirement in 1912. He was knighted as a Knight Bachelor by King Edward VII in 1909, for his services to blind people. He was succeeded by his son, Guy Marshall Campbell, and following his death in 1929 Guy's widow, Louie Bealby Campbell took over the position. The role of principal passed outside the Campbell family for the first time upon Louie Bealby Campbell's retirement in 1934.\n\nIn the 20th century, the college moved location several times before establishing itself at its present campus in Hereford. The first of these moves occurred at the beginning of the Second World War, when the college was evacuated from its London site and moved to a mansion named Great Maytham in Rolvenden in west Kent. However, because of the threat of a German invasion, the authorities soon advised another move, and this time, with 24 hours notice and the help of the London Society for the Blind, a temporary home was found for RNC in Dorton, near Aylesbury, Buckinghamshire. At the time of the move most of the students were on holiday, although some thirty had remained at the college along with several staff members.\n\nThe college did not return to London because the Upper Norwood site – which was being used as a hospital following RNC's move to Kent – was bombed in 1940 during the Blitz, then acquired by the authorities. The college had to close temporarily, until a permanent new home could be found, but in 1941 it purchased new premises at Rowton Castle near Shrewsbury and relocated there. The castle was built in the 17th Century and is situated in of grounds six miles (10 km) west of Shrewsbury. This accommodation had limited space, and throughout its time in Shrewsbury RNC acquired other premises in and around the town. Albrighton Hall, about three miles (5 km) from Shrewsbury, was acquired in 1955 and adapted for residential and training purposes for male students, and Hardy House was obtained as a new residential area for female students in 1958. Plans to enlarge the Rowton site were seriously affected when, in 1953, fire destroyed much of the buildings and 38 pianos and organs. The alarm was raised by one of the students, and everybody present was evacuated to safety. Training was able to continue after Henshaw's Institution for the Blind took students and staff as a temporary measure.\n\nRNC remained in Shropshire for many years until, in 1978, more suitable accommodation was found that would enable RNC to consolidate its teaching and residential accommodation into one campus, and the college moved to its current home in Hereford. The site had previously been the campus of Hereford College of Education, a former teacher training college. In 1978 the college adopted its present name, the Royal National College for the Blind. RNC was opened at its new campus by Prince Charles, who arrived in Hereford by helicopter to perform the ceremony in 1979.\n\nIn the early 2000s the halls of residence at the Hereford campus underwent an extensive £1.5 million upgrade. The blocks were originally built when the campus was being used as a teacher training college during the 1960s and were updated to include modern facilities such as larger student bedrooms with en-suite bathrooms and space for televisions and computers, and improved social areas.\n\nIn 2006 the college announced an extensive expansion of its campus, including new halls of residence, a sports and complementary therapy building and a new outdoor floodlit sports pitch. The £21.5m sports development would be the venue for the 2010 World Blind Football Championship. A £10 million fundraising campaign, Building Brighter Futures, was created to raise the funds required to complete the project, and construction work began in the summer of 2007. The complex, thePoint4, was originally named The Point after a nearby block of flats. It includes a bistro and conference facilities, and commenced operation in April 2009, and was officially opened on 24 June by BBC sports presenter and \"Daily Mail\" columnist Des Kelly. In 2008 the college was nominated as one of the sites for the 2012 Paralympic Games and acted as a pre-Games training camp for Paralympic athletes.\n\nRNC was the subject of a 2007 documentary for the Channel Four series \"Cutting Edge\", which followed three young students (Steve Markham, Daniel Angus and Selina Litt) during their first term at the college. The film examines their individual journeys towards greater independence as they encounter the unique challenges that being visually impaired presents, as well as how they deal with the everyday issues that affect all teenagers, such as sex, relationships, partying and their future plans after graduation. The documentary, \"Blind Young Things\", was first aired on 30 April 2007, and won a Royal Television Society award for Channel Four and the Cutting Edge team in 2008.\n\nIn September 2009 the college became the permanent home of the National BlindArt Collection, a collection of paintings, sculptures, installations and other works of art designed to engage all the senses and to provide people who are visually impaired with greater accessibility to art. In November 2009 RNC announced that it had been forced to send a third of its students home following an outbreak of swine flu on campus. During the heavy winter snowfall of 2009–2010 the college's sports facilities were utilised by the Hereford United team for training after the bad weather conditions made using their own grounds at Edgar Street difficult.\n\nIn January 2010 two students from the college appeared with the fashion consultant Gok Wan in an edition of the Channel 4 series \"How to Look Good Naked...with a Difference\", where they took part in a photo shoot. The series sought to highlight confidence issues among people with disabilities. In February 2010 the college secured a £90,000 grant from the Learning and Skills Improvement Service to install a music video production studio enabling bands to record material and showcase their work.\n\nRNC celebrated its 140th anniversary in March 2012 with a day of events at its campus and a street collection in Hereford.\n\nIn the late 2000s RNC underwent significant restructuring as it responded to changes in the world of employment and therefore the courses that it offered its students. However, some of the college's changes provoked criticism from staff and students who argued these were not in RNC's best interest. There was some controversy over the college's decision to reduce the availability of courses in piano tuning, traditionally regarded as a secure profession for visually impaired people, while fears were expressed that the decrease in A Level subjects would lead to RNC becoming a sport rather than an academic orientated college. Responding to these concerns in July 2008, the then principal Christine Steadman told \"In Touch\", the BBC Radio 4 news programme for visually impaired listeners; \"It's about what the local authorities, what the learning and skills council, what the Welsh Assembly for government will purchase from us. And at the moment we are reducing a small number of A Level courses but at the same time we're extending other courses, for example we've got level 3 Braille being taught for the first time at the college, we're not cutting A Levels, we're just responding to the needs of the learners that are coming through our doors.\" In an interview in January 2010, the then principal Geoff Draper said that piano tuning would be taught at the college if there was a demand for it, and suggested RNC could look to bringing in international students to fill places.\n\nThe changes led to significant department reorganisations within RNC, with several dozen staff members being summarily dismissed without explanation; some were replaced by volunteers. A number of former college employees made complaints regarding the manner in which their employment was ended. In July 2008 the college lecturers union, the University and College Union, called for greater consultation between management and staff at the college. Speaking in a 2009 interview with \"In Touch\" Ian Pickford, who was brought in as interim principal following Christine Steadman's departure, claimed that the atmosphere of the college had changed and issued a challenge to any student or member of staff who was still unhappy to meet with him to discuss their concerns.\n\nFinancial concerns were raised in 2009 over the cost of the new leisure complex, and because of a change in the source of student funding from the Learning and Skills Council to Local Education Authorities. The college was facing a shortfall of at least £500,000 in 2009 and its auditors expressed doubt about RNC's ability to continue as a going concern. In response Ian Pickford said that much of thePoint4's costs had been paid for through donations and that the shortfall issue was being addressed through cutbacks, including some redundancies. Of the auditors' concerns he said; \"I think post the banking crisis a lot of auditors are incredibly nervous about making bland statements in terms of the future of organisations and therefore they frequently now put those sort of caveats in to protect their position going forward.\"\n\nThe college is actively involved in the development and use of assistive technology to aid visually impaired people in their everyday lives. For example, working with a United States-based software engineer, RNC produced the T3 (Talking Tactile Tablet), a touch sensitive device for interpreting tactile images such as diagrams, charts and maps. The device is connected to a computer and run with a programme CD, and has a tactile surface which produces touchable icons that provide audio feedback when they are pressed. The device was originally developed for educational purposes but can be adapted for other uses. In 2005 Hereford Museum and Art Gallery became the first in the United Kingdom to invest in the technology. The T3 was later marketed internationally with the help of the UK Trade & Investment's passport initiative – a scheme which gives new exporters the training, planning and support they need to succeed in overseas markets.\n\nThe Mountbatten, an electronic Braille writing machine and embosser, was pioneered and developed at the college by Ernest Bate. Work began on the project following a bequest in the will of the late Lord Louis Mountbatten for the development of\na modern, low cost, portable brailler. It has been available since 1991, and is manufactured by Quantum Technology, a company based in Australia. In the early 1990s two RNC lecturers, Clive Ellis and Tony Larkin, invented the Hoople, a hoop-shaped mobility aid for blind people which performs a similar role to a white cane, but is designed for use in a rural environment and on rough terrain. RNC lecturer Nigel Berry designed the Fingerprints Braille course, which was first published in 1993 and is now widely used to teach adult beginners to touch-read and write grade 2 Braille.\n\nRNC is involved in the RoboBraille project which allows visually impaired Internet users to have text translated into Braille and MP3 audio format via email. The system, developed in Denmark, was launched in June 2006 and won a British Computer Society Social Contribution Project Award in 2007.\nClearText, which enables visually impaired users to browse the web more easily by making text easier for them to read, was developed in conjunction with the college. In 2009 RNC lecturer Tony Sales developed Vinux, an accessible version of the Linux operating system for the visually impaired.\n\nRNC provides full-time and shorter courses in vocational and academic subjects for approximately 200 students aged 16 and above. In 2008 there were 196 students in attendance, 74 of whom were aged 16 to 18 and 122 aged 19 years and over. Younger students often join the college straight from school, while adult students are from a diverse range of backgrounds. Students have often been visually impaired since birth or may have lost their sight in later life as a result of illness or accident. Some students have additional disabilities such as autistic spectrum disorder\nand other medical needs. They can attend the college on a daily or residential basis, and accommodation is provided for those who board. There were 152 residential and 44 day students in 2008.\n\nCourses vary in length from a few weeks to two years. There are no formal academic requirements for entry into RNC, but potential students are invited to attend an assessment at the college before being offered a place to determine the level of support they will need during their studies. The assessment typically includes an evaluation of a person's level of vision, their mobility and independence skills, any residential support they may require, basic literacy and numeracy skills tests, and an interview with the leader of the course they wish to take.\n\nStudy programmes at RNC are designed to prepare visually impaired students for progression into further education, university or employment. The development of independent living and personal skills is also encouraged. The college is divided into several different areas of study. These include Leisure, Therapies and Sport (including courses and qualifications in massage, complementary therapies, and sport treatment and management); Music, Media, Performance and Art (including courses and qualifications in music technology, media and art); Information and Communication Technology (including courses and qualifications in office skills and the European Computer Driving Licence); Business, Administration and Customer Service; Secondary level qualifications – General Certificate of Secondary Education (GCSE) and General Certificate of Education Advanced Level (A-Level) qualifications in subjects such as English, mathematics, French and psychology; and Braille reading. On top of academic and vocational study students are also taught to develop independence and mobility skills for day-to-day living. Topics covered here include the use of a white cane and becoming familiar with the surrounding environment, using public transport safely and confidently, cooking and laundry skills, and using cash machines or making Chip and PIN credit card transactions.\n\nTraditionally courses in Piano Tuning and Piano Technology were also available at the college. However, these were significantly reduced in the late 2000s because of a decline in the number of students studying the subjects. There has also been a reduction in the number of A-levels available for study owing to changes in the types of courses that education funding bodies supporting students at RNC are willing to pay for.\n\nRNC began to offer its first Higher Education (or university level) qualification in January 2010 with the launch of the Certificate in Higher Education: Working with People with Visual Impairment Programme. The qualification is offered in collaboration with St Joseph's Centre for the Visually Impaired in Dublin and the University of Worcester.\n\nFollowing an inspection by the Office for Standards in Education, Children's Services and Skills (Ofsted) in 2004 the quality of the college's teaching was graded as \"outstanding\", and in 2005 RNC was one of only eight colleges in the UK to be awarded Learning and Skills Beacon Status. It is the only college for visually impaired students to have Beacon status, which is only given to educational establishments which have received a first-class Ofsted inspection report. RNC was again praised by Ofsted in 2009 for its continued good progress when Inspectors graded the college as \"outstanding\" across all six areas inspected and said it had gained ground since its last inspection in 2006.\n\nRNC has four halls of residence, three of which (Armitage, Campbell and Dowdell) have been updated in recent years to include modern facilities in accordance with Care Standards and Disability Discrimination Act requirements. Specific accommodation has been adapted for wheelchair users, while some rooms have sensory fire alarm calls to alert those who are hard of hearing. Halls are divided into flats accommodating several students. Each flat has a number of single rooms with shared kitchen and dining facilities, and a central lounge.\n\nBecause it was not possible to upgrade Gardner Hall, a new modern block, Orchard Hall, was built to replace it. Gardner became an assessment centre for prospective students. In September 2009 Gardner was made available as a venue for hire for functions such as weddings. In addition to the halls of residence, the college also owns several houses both on and off campus which enable students to gain a greater level of independent living. There is a restaurant which provides meals, or students can choose to be self-catering. All accommodation has kitchen facilities.\n\nOn-campus facilities include a gym, sports hall, a floodlit all-weather football pitch and tennis courts. RNC's thePoint4 complex offers sporting, leisure and conference facilities, as well as a bistro, and is open to both students and members of the general public. Other facilities at RNC include the Flexible Learning Centre, which features the latest assistive technology and learning resources and is open seven days a week, a student social club which is licensed to sell alcohol to students who are 18 and over, and a student common room. The college has an active Students' Union which plays an important role in college life, being responsible for organising leisure activities both on and off campus. There are also on-campus medical facilities.\n\nIn December 2008 the \"Hereford Times\" reported that the college would be home to a sculpture by the Herefordshire-based contemporary artist Walenty Pytel that he would create using an original drawing produced by an RNC student. The piece, depicting a man running in a Futurist style and titled the \"4Runner\" was unveiled in September 2009 and stands on a plinth outside the entrance of the sports and leisure complex.\n\nRNC is the home of the first football academy for visually impaired players. The Football Academy was officially opened in August 2008 by former England footballer Sir Trevor Brooking and offers visually impaired students the opportunity to include football as part of their study programme with a view to playing the game at a national level. The college is the home of the England blind football team, which is supported by the Football Association and coached by former professional footballer Tony Larkin. The game is played as a five-a-side match using a ball filled with ballbearings to enable players to hear its position. Teams consist of four blind players and a sighted goalkeeper who offers directions along with the coach and a sighted guide behind the opposition goalpost. RNC is helping to develop a national blind football league. In 2010 RNC hosted the World Blind Football Championship at its campus. The tournament got under way on Saturday 14 August with the opening match between England and Spain, and was won by Brazil following a 2–0 win against Spain in the final on 22 August. Members of England's blind football team travelled to Los Angeles in November 2011 to promote the sport in the United States, and took part in a day's training with former England captain David Beckham. The trip was organised by supermarket chain Sainsbury's as part of their sponsorship deal with the footballer.\n\nBlind cricket, which is played basically the same as conventional cricket but using larger stumps and wickets and a white ball so that players may see it much more easily, is also played at the college, and RNC has its own cricket team, which competes in the British Blind Sport (BBS) National Cricket League. The college also features acoustic shooting, a sport which uses air rifles fitted with photoelectric cells which convert light reflected from targets into sound.\n\nAs well as football, cricket and acoustic shooting, students at RNC can participate in a wide range of other sporting and athletic activities, including horse riding, swimming, ten pin bowling, weight training, circuit training and martial arts. Away from sport, other activities include art and design, ceramics, drama and dance, photography and gardening. There are shopping excursions and trips to the cinema and theatre, while clubs and societies include a dining club and the RNC choir.\n\nThe college is a charitable organisation and is registered with the Charity Commission, the government body which oversees charities in England and Wales. It has a number of high-profile supporters which include Charles, Prince of Wales, who is the current Patron, a position he has held since 1997. The current president is Mrs Jessica White, and there are several public figures who serve as vice presidents. These include the Archbishop of Canterbury, the Archbishop of York, the Archbishop of Westminster, Countess Mountbatten of Burma and Michael Buerk. In 2008 the BBC sports presenter Gabby Logan and Daily Mail columnist Des Kelly both became Patrons of the England Blind Football team.\n\nSince the Principalship passed outside the Campbell family in 1934 a number of individuals have held the position. Among them are Lance Marshall who was principal at the time the college moved to its Hereford campus in 1978, followed by Colin Housby-Smith and then Roisin Burge. Christine Steadman oversaw the college's restructuring during her tenure in the late 2000s and proved to be unpopular with staff and students; Steadman resigned in November 2008. Geoff Draper, a former Colonel in the British Army, was appointed to the position on 7 December 2009. Sheila Tallon succeeded Draper in September 2011. Mark Fisher took over from Tallon after her retirement in December 2015.\n\nGraduates of the college include David Blunkett, British Labour Party politician and former Home Secretary, and Alfred Hollins, English composer and organist. Giles McKinley, who starred in a groundbreaking television commercial for Sauza Tequila during the 1990s, is a former RNC student. The actor Ryan Kelly, who in 1997, became the first completely blind student to join the Bristol Old Vic Theatre School, and plays the role of Jack \"Jazzer\" McCreary in Radio 4's \"The Archers\", attended RNC. The Paralympic cyclist Anthony Kappes also studied at the college.\n"}
{"id": "410530", "url": "https://en.wikipedia.org/wiki?curid=410530", "title": "Sanitary sewer", "text": "Sanitary sewer\n\nA sanitary sewer or foul sewer is an underground pipe or tunnel system for transporting sewage from houses and commercial buildings (but not stormwater) to treatment facilities or disposal. Sanitary sewers are part of an overall system called a sewage system or sewerage.\n\nSewage may be treated to control water pollution before discharge to surface waters. Sanitary sewers serving industrial areas also carry industrial wastewater.\n\nSeparate sanitary sewer systems are designed to transport sewage alone. In municipalities served by sanitary sewers, separate storm drains may convey surface runoff directly to surface waters. Sanitary sewers are distinguished from combined sewers, which combine sewage with stormwater runoff in one pipe. Sanitary sewer systems are beneficial because they avoid combined sewer overflows.\n\nSewage treatment is less effective when sanitary waste is diluted with stormwater, and combined sewer overflows occur when runoff from heavy rainfall or snowmelt exceeds the hydraulic capacity of sewage treatment plants. To overcome these disadvantages, some cities built separate sanitary sewers to collect only municipal wastewater and exclude stormwater runoff collected in separate storm drains. The decision between a combined sewer system or two separate systems is mainly based on need for sewage treatment and cost of providing treatment during heavy rain events. Many cities with combined sewer systems built prior to installing sewage treatment have not replaced those sewer systems.\n\nIn the developed world, sewers are pipes from buildings to one or more levels of larger underground trunk mains, which transport the sewage to sewage treatment facilities. Vertical pipes, usually made of precast concrete, called manholes, connect the mains to the surface. Depending upon site application and use, these vertical pipes can be cylindrical, eccentric, or concentric. The manholes are used for access to the sewer pipes for inspection and maintenance, and as a means to vent sewer gases. They also facilitate vertical and horizontal angles in otherwise straight pipelines. \n\nPipes conveying sewage from an individual building to a common gravity sewer line are called laterals. Branch sewers typically run under streets receiving laterals from buildings along that street and discharge by gravity into trunk sewers at manholes. Larger cities may have sewers called interceptors, receiving flow from multiple trunk sewers.\n\nDesign and sizing of sanitary sewers considers the population to be served over the anticipated life of the sewer, per capita wastewater production, and flow peaking from timing of daily routines. Minimum sewer diameters are often specified to prevent blockage by solid materials flushed down toilets; and gradients may be selected to maintain flow velocities generating sufficient turbulence to minimize solids deposition within the sewer. Commercial and industrial wastewater flows are also considered, but diversion of surface runoff to storm drains eliminates wet weather flow peaks of inefficient combined sewers.\n\nPumps may be necessary where gravity sewers serve areas at lower elevations than the sewage treatment plant, or distant areas at similar elevations. A lift station is a sewer sump that lifts accumulated sewage to a higher elevation. The pump may discharge to another gravity sewer at that location or may discharge through a pressurized force main to some distant location.\n\nEffluent sewer systems, also called septic tank effluent drainage (STED) or solids-free sewer (SFS) systems, have septic tanks that collect sewage from residences and businesses, and the effluent that comes out of the tank is sent to either a centralized sewage treatment plant or a distributed treatment system for further treatment. Most of the solids are removed by the septic tanks, so the treatment plant can be much smaller than a typical plant. In addition, because of the vast reduction in solid waste, a pumping system can be used to move the wastewater rather than a gravity system. The pipes have small diameters, typically . Because the waste stream is pressurized, they can be laid just below the ground surface along the land's contour.\n\nSimplified sanitary sewers consist of small-diameter pipes, typically around , often laid at fairly flat gradients (1 in 200). Although the investment cost for simplified sanitary sewers can be about half the cost of conventional sewers, the requirements for operation and maintenance are usually higher. Simplified sewers are most common in Brazil and are also used in a number of other developing countries.\n\nIn low-lying communities, wastewater is often conveyed by vacuum sewer. Pipelines range in size from pipes of in diameter to concrete-lined tunnels of up to in diameter. A low pressure system uses a small grinder pump located at each point of connection, typically a house or business. Vacuum sewer systems use differential atmospheric pressure to move the liquid to a central vacuum station.\n\nSanitary sewer overflow can occur due to blocked or broken sewer lines, infiltration of excessive stormwater or malfunction of pumps. In these cases untreated sewage is discharged from a sanitary sewer into the environment prior to reaching sewage treatment facilities. To avoid this, maintenance is required.\n\nThe maintenance requirements vary with the type of sanitary sewer. In general, all sewers deteriorate with age, but infiltration and inflow are problems unique to sanitary sewers, since both combined sewers and storm drains are sized to carry these contributions. Holding infiltration to acceptable levels requires a higher standard of maintenance than necessary for structural integrity considerations of combined sewers. A comprehensive construction inspection program is required to prevent inappropriate connection of cellar, yard, and roof drains to sanitary sewers. The probability of inappropriate connections is higher where combined sewers and sanitary sewers are found in close proximity, because construction personnel may not recognize the difference. Many older cities still use combined sewers while adjacent suburbs were built with separate sanitary sewers.\n\nFor decades, when sanitary sewer pipes cracked or experienced other damage, the only option was an expensive excavation, removal and replacement of the damaged pipe, typically requiring street repavement afterwards. In the mid-1950s a unit was invented where two units at each end with a special cement mixture in between was pulled from one manhole cover to the next, coating the pipe with the cement under high pressure, which then cured rapidly, sealing all cracks and breaks in the pipe. Today, a similar method using epoxy resin is used by some municipalities to re-line aging or damaged pipes, effectively creating a \"pipe in a pipe\". These methods may be unsuitable for locations where the full diameter of the original pipe is required to carry expected flows, and may be an unwise investment if greater wastewater flows may be anticipated from population growth, increased water use, or new service connections within the expected service life of the repair.\n\nAnother popular method for replacing aged or damaged lines is called pipe bursting, where a new pipe, typically PVC or ABS plastic, is drawn through the old pipe behind an \"expander head\" that breaks apart the old pipe as the new one is drawn through behind it.\n\nThese methods are most suitable for trunk sewers, since repair of lines with lateral connections is complicated by making provisions to receive lateral flows without accepting undesirable infiltration from inadequately sealed junctions.\n\nSanitary sewers evolved from combined sewers built where water was plentiful. Animal feces accumulated on city streets while animal-powered transport moved people and goods. Accumulations of animal feces encouraged dumping chamber pots into streets where night soil collection was impractical. Combined sewers were built to use surface runoff to flush waste off streets and move it underground to places distant from populated areas. Sewage treatment became necessary as population expanded, but increased volumes and pumping capacity required for treatment of diluted waste from combined sewers is more expensive than treating undiluted sewage.\n\n"}
{"id": "37058845", "url": "https://en.wikipedia.org/wiki?curid=37058845", "title": "Scottish Centre for Regenerative Medicine", "text": "Scottish Centre for Regenerative Medicine\n\nThe Scottish Centre for Regenerative Medicine (SCRM) is a stem cell research centre at the University of Edinburgh in Scotland, dedicated to the study and development of new regenerative treatments for human diseases. The £54 million facility is part of a total £600 million joint investment in stem cell biology and medicine by the Scottish Government and the University of Edinburgh. Designed by Sheppard Robson, the SCRM is part of the BioQuarter cluster at Little France.\n\nThe 9000 m building, which can house up to 250 scientists, is home to biologists and clinical academics from the MRC Centre for Regenerative Medicine (CRM), and applied scientists working with the Scottish National Blood Transfusion Service and Roslin Cells. It contains laboratory and support space, a company incubator unit, and a clinical translation unit which enables the production of cells at Good Manufacturing Practice (GMP) grade.\n\nConditions being researched at the SCRM include multiple sclerosis and heart and liver disease.\n\nThe Scottish Centre for Regenerative Medicine was officially opened by the Princess Royal on 28 May 2012.\n\nOn 25 August 2014, the centre grew the first working organ, a thymus, from scratch inside an animal.\n\n\nSCRM Homepage\n"}
{"id": "27107962", "url": "https://en.wikipedia.org/wiki?curid=27107962", "title": "Sexual division of labour", "text": "Sexual division of labour\n\nThe sexual division of labour (SDL) is the delegation of different tasks between males and females. Among human foragers, males and females target different types of foods and share them with each other for a mutual or familial benefit. In some species, males and females eat slightly different foods, while in other species, males and females will routinely share food; but only in humans are these two attributes combined. The few remaining hunter-gatherer populations in the world serve as evolutionary models that can help explain the origin of the sexual division of labor. Many studies on the sexual division of labor have been conducted on hunter-gatherer populations, such as the Hadza, a hunter-gatherer population of Tanzania.\n\nBoth men and women have the option of investing resources either to provision children or to have additional offspring based on life history theory. Males and females monitor costs and benefits of each alternative to maximize reproductive fitness; however, trade-off differences do exist between sexes. Females are likely to benefit most from parental effort because they are certain which offspring are theirs and have relatively few reproductive opportunities, each of which is relatively costly and risky. In contrast, males do not have an absolute certainty of paternity, but may have many more mating opportunities bearing relatively low costs and risks. Though not every hunter-gatherer population pinpoints females to gathering and males to hunting (most notably the Aeta and Ju'/hoansi), the norm of most current populations divide the roles of labor in this manner. Natural selection is more likely to favor male reproductive strategies that stress mating effort and female strategies that emphasize parental investment. As a result, women do the low-risk task of gathering vegetation and underground storage organs that are rich in energy to provide for themselves and offspring. Since women provide a reliable source of caloric intake, men are able to afford a higher risk of failure by hunting animals.\n\nThis classic theory of natural selection positing a difference in male and female reproductive strategies has recently been reexamined, with an alternate theory being proposed that promiscuity was encouraged among women and men alike, causing uncertainty among males of the paternity of their offspring, allowing for group cooperation in raising all offspring due to the possibility that any child could be the descendant of a male, similar to observations of the closest relative of humans, the bonobo. Moreover, recent archaeological research done by the anthropologist and archaeologist Steven Kuhn from the University of Arizona suggests that the sexual division of labor did not exist prior to the Upper Paleolithic (50,000 and 10,000 years ago) and developed relatively recently in human history. The sexual division of labor may have arisen to allow humans to acquire food and other resources more efficiently.\n\nThe traditional explanation of the sexual division of labor finds that males and females cooperate within pair bonds by targeting different foods so that everyone in the household benefits. Females may target foods that do not conflict with reproduction and child care, while males will target foods that females do not gather, which will reduce variance in daily consumption and provide a broader diet for the family. Foraging specialization in particular food groups should increase skill level and thus foraging success rates for targeted foods.\n\nThe \"show‐off\" hypothesis proposes that men hunt to gain social attention and mating benefits by widely sharing game. This model proposes that hunting functions mainly to provide an honest signal of the underlying genetic quality of hunters, which later yields a mating advantage or social deference. Females tend to target the foods that are most reliable, while men tend to target difficult-to-acquire foods to \"signal\" their abilities and genetic quality. Hunting is thus viewed as a form of mating or male-male status competition, not familial provisioning. Recent studies on the Hadza have revealed that men hunt mainly to distribute food to their own families rather than sharing with other members of the community. This conclusion suggests evidence against hunting for signaling purposes.\n\nThe Victorian era that has been so closely examined by Sally Shuttleworth and company shed light on women during the Victorian era. They played dual roles and were expected to deliver with conviction in the aspects in which they were required to perform duties in and outside of the household. She states, \"Two traditional tropes are here combined: Victorian medical textbooks demonstrated not only woman's biological fitness and adaptation to the sacred role of homemaker, but also her terrifying subjection to the forces of the body. At once angel and demon, woman came to represent both the civilizing power that would cleanse the male from contamination in the brutal world of the economic market and also the rampant, uncontrolled excesses of the material economy.\"\n\nOptimal foraging theory (OFT) states that organisms forage in such a way as to maximize their energy intake per unit time. In other words, animals behave in such a way as to find, capture, and consume food containing the most calories while expending the least amount of time possible in doing so. The sexual division of labor provides an appropriate explanation as to why males forgo the opportunity to gather any items with caloric value- a strategy that would seem suboptimal from an energetic standpoint. The OFT suggests that the sexual division of labor is an adaptation that benefits the household; thus, foraging behavior of males will appear optimal at the level of the family. If a hunter-gatherer man does not rely on resources from others and passes up a food item with caloric value, it can be assumed that he is foraging at an optimal level. But, if he passes up the opportunity because it is a food that women routinely gather, then as long as men and women share their spoils, it will be optimal for men to forgo the collection and continue searching for different resources to complement the resources gathered by women.\n\nThe emergence of cooking in early Homo may have created problems of food theft from women while food was being cooked. As a result, females would recruit male partners to protect them and their resources from others. This concept, known as the theft hypothesis, accommodates an explanation as to why the labor of cooking is strongly associated with the status of women. Women are forced to gather and cook foods because they will not acquire food otherwise and access to resources is critical for their reproductive success. On the contrary, men do not gather because their physical dominance allows them to scrounge cooked foods from women. Thus, women's foraging and food preparation efforts allow men to participate in the high-risk, high-reward activities of hunting. Females, in turn, become increasingly sexually attractive as a means to exploit male interest in investing in her protection.\n\nMany studies investigating the spatial abilities of men and women have found no significant differences, though metastudies show a male advantage in mental rotation and assessing horizontality and verticality, and a female advantage in spatial memory. The sexual division of labor has been proposed as an explanation for these cognitive differences. Those differences disappear with a short training or when given a favorable image of woman ability. Furthermore, the individual differences are greater than the average differences, which isn't therefore a valid prediction of a man or woman cognitive ability. This hypothesis argues that males needed the ability to follow prey over long distances and to accurately target their game with projectile technology, and, as a result, male specialization in hunting prowess would have spurred the selection for increased spatial and navigational ability. Similarly, the ability to remember the locations of underground storage organs and other vegetation would have led to an increase in overall efficiency and decrease in total energy expenditure since the time spent searching for food would decrease. Natural selection based on behaviors that increase hunting success and energetic efficiency would bear a positive influence on reproductive success. However, recent research suggests that the sexual division of labor developed relatively recently and that gender roles were not always the same in early-human cultures, contradicting the theory that each sex is naturally predisposed to different types of work.\n\nThe discussion of the division of gender roles have been an ongoing debate and Gerda Lerner quotes the philosopher Socrates to demonstrate that the idea of defined gender roles is patriarchal. It also identifies how men and women are capable of performing the same job descriptions with the exception of when it calls for anatomical differences, such as giving birth. \"In Book V of the Republic, Plato—in the voice of Socrates—sets down the conditions for the training of the guardians, his elite leadership group. Socrates proposes that women should have the same opportunity as men to be trained as guardians. In support of this he offers a strong statement against making sex differences the basis for discrimination: if the difference [between men and women] consists only in women bearing and men begetting children, this does not amount to proof that a woman differs from a man in respect to the sort of education she should receive; and we shall therefore continue to maintain that our guardians and their wives ought to have the same pursuits.\n\nHe continues to add that with the same set of established resources such as education, training and teaching, it creates an atmosphere of equity which helps to further the cause of gender equality. \"Socrates proposes the same education for boys and girls, freeing guardian women from housework and child-care. But this female equality of opportunity will serve a larger purpose: the destruction of the family. Plato's aim is to abolish private property, the private family, and with it self-interest in his leadership group, for he sees clearly that private property engenders class antagonism and disharmony. Therefore \"men and women are to have a common way of life. . . —common education, common children; and they are to watch over the citizens in common. \"\n\nSome researchers, such as Cordelia Fine, argue that available evidence does not support a biological basis for gender roles.\n\nBased on the current theories and research on the sexual division of labor, four critical aspects of hunter‐gatherer socioecology led to the evolutionary origin of the SDL in humans: (1) long‐term dependency on high‐cost offspring, (2) optimal dietary mix of mutually exclusive foods, (3) efficient foraging based on specialized skill, and (4) sex‐differentiated comparative advantage in tasks. These combined conditions are rare in nonhuman vertebrates but common to currently-existing populations of human foragers, which, thus, gives rise to a potential factor for the evolutionary divergence of social behaviors in \"Homo\".\n\n"}
{"id": "140447", "url": "https://en.wikipedia.org/wiki?curid=140447", "title": "Stanford torus", "text": "Stanford torus\n\nThe Stanford torus is a proposed NASA design for a space habitat capable of housing 10,000 to 140,000 permanent residents.\n\nThe Stanford torus was proposed during the 1975 NASA Summer Study, conducted at Stanford University, with the purpose of exploring and speculating on designs for future space colonies (Gerard O'Neill later proposed his Island One or Bernal sphere as an alternative to the torus). \"Stanford torus\" refers only to this particular version of the design, as the concept of a ring-shaped rotating space station was previously proposed by Wernher von Braun and Herman Potočnik.\n\nIt consists of a torus, or doughnut-shaped ring, that is 1.8 km in diameter (for the proposed 10,000 person habitat described in the 1975 Summer Study) and rotates once per minute to provide between 0.9g and 1.0g of artificial gravity on the inside of the outer ring via centrifugal force.\n\nSunlight is provided to the interior of the torus by a system of mirrors, including a large non-rotating primary solar mirror.\n\nThe ring is connected to a hub via a number of \"spokes\", which serve as conduits for people and materials travelling to and from the hub. Since the hub is at the rotational axis of the station, it experiences the least artificial gravity and is the easiest location for spacecraft to dock. Zero-gravity industry is performed in a non-rotating module attached to the hub's axis.\n\nThe interior space of the torus itself is used as living space, and is large enough that a \"natural\" environment can be simulated; the torus appears similar to a long, narrow, straight glacial valley whose ends curve upward and eventually meet overhead to form a complete circle. The population density is similar to a dense suburb, with part of the ring dedicated to agriculture and part to housing.\n\nThe torus would require nearly 10 million tons of mass. Construction would use materials extracted from the Moon and sent to space using a mass driver. A mass catcher at L2 would collect the materials, transporting them to L5 where they could be processed in an industrial facility to construct the torus. Only materials that could not be obtained from the Moon would have to be imported from Earth. Asteroid mining was an alternative source of materials.\n\n\n"}
{"id": "215750", "url": "https://en.wikipedia.org/wiki?curid=215750", "title": "Steadicam", "text": "Steadicam\n\nSteadicam is a brand of camera stabilizer mounts for motion picture cameras invented by Garrett Brown and introduced in 1975 by Cinema Products Corporation. It mechanically isolates the operator's movement, allowing for a smooth shot, even when the camera moves over an irregular surface.\n\nBefore the camera stabilizing system, a director had two choices for moving (or \"tracking\") shots:\n\nWhile these cinematic techniques are still common, the Steadicam has added another dimension to motion picture cinematography and videography.\n\nA Steadicam combines the stabilized steady footage of a conventional tripod mount with the fluid motion of a dolly shot and the flexibility of hand-held camera work. While smoothly following the operator's broad movements, the Steadicam's arm absorbs jerks, bumps, and shakes, while its almost frictionless gimbal gives precise control of the camera and framing.\n\nThe Steadicam was introduced to the industry in 1975 by inventor and cameraman Garrett Brown, who originally named the invention the \"Brown Stabilizer\". After completing the first working prototype, Brown shot a ten-minute demo reel of the revolutionary moves this new device could produce. This reel was seen by numerous directors, including Stanley Kubrick and John G. Avildsen. The Steadicam was subsequently licensed to and manufactured by Cinema Products Corporation, which later diversified the brand into a consumer line for DV cameras.\n\nThe Steadicam was first used in the Best Picture–nominated Woody Guthrie biopic \"Bound for Glory\" (1976), debuting with a shot that compounded the Steadicam's innovation: cinematographer Haskell Wexler had Brown start the shot on a fully elevated platform crane which jibbed down, and when it reached the ground, Brown stepped off and walked the camera through the set. This technically audacious and previously impossible shot created considerable interest in how it had been accomplished, and impressed the Academy enough for Wexler to win the Oscar for Best Cinematography that year.\n\nIt was then used in extensive running and chase scenes on the streets of New York City in \"Marathon Man\" (1976), which was released two months before \"Bound for Glory\". It landed a notable third credit in Avildsen's Best Picture–winning \"Rocky\" in 1976, where it was an integral part of the film's Philadelphia street jogging/training sequences and the run up the Art Museum's flight of stairs, as well as the fight scenes where it can even be plainly seen in operation at the ringside during some wide shots of the final fight. \"Rocky\" was also released before \"Bound for Glory\". Garrett Brown was the Steadicam operator on all of these.\n\n\"The Shining\" (1980) pushed Brown's innovations even further, when director Stanley Kubrick requested that the camera shoot from barely above the floor. This prompted the innovation of \"low mode\" to mount the top of the camera to the bottom of an inverted post, which substantially increased the creative angles of the system which previously could not go much lower than the operator's waist height. This low-mode concept remains the most important extension to the system since its inception.\n\nA Steadicam rig was also employed during the filming of \"Return of the Jedi\" (1983), in conjunction with two gyroscopes for extra stabilization, to film the background plates for the speeder bike chase. Brown, who personally operated the shot, walked through a redwood forest, with the camera running at a speed of less than one frame per second. The end result, when projected at 24 frames per second, gave the impression of flying through the air at perilous speeds. In the Michael Crichton film \"Runaway\" (1984), a Steadicam rig was used to simulate the point of view of a futuristic smart bullet in flight while targeting specific individuals by their heat signature.\n\nThe operator wears a harness, the Steadicam \"vest\", which is attached to an iso-elastic arm. This is connected by a multiaxis and ultra-low friction gimbal to the Steadicam \"sled\" which has the camera mounted at one end and counterbalancing weight (the monitor and batteries) at the other. The monitor substitutes for the camera's viewfinder, since the range of motion of the camera relative to the operator makes the camera's own viewfinder unusable. In the film industry the armature and weight are traditionally called the \"sled\", as the two units combined resembled a sled in an early model of the Steadicam. The sled includes the top \"stage\" where the camera is attached, the \"post\" which in most models can be extended, with the monitor and batteries at the bottom to counterbalance the camera weight. This is how the Steadicam stays upright, by simply making the bottom slightly heavier than the top, pivoting at the gimbal. This leaves the center of gravity of the whole rig, however heavy it may be, exactly at the operator's fingertip, allowing deft and finite control of the whole system with the lightest of touches on the gimbal. The skill of the operator is to keep the desired framing and composition by feathering his touch on the gimbal, while the rig and operator is in motion, and, indeed, when still.\n\nThe combined weight of the counterbalance and camera means that the armature bears a relatively high inertial mass which is not easily moved by small body movements from the operator (much as it is difficult to quickly shake a bowling ball). The freely pivoting armature adds additional stabilization to the photographed image, and makes the weight of the camera-sled assembly acceptable by allowing the body harness to support it.\n\nWhen the armature is correctly adjusted, operators can remove their hands from the Steadicam entirely and the camera stays in place. During operation, the operator usually rests a hand on the camera gimbal and applies force at that point to move the camera. To avoid shaking the camera when lens adjustments are made, a wireless remote operated by the camera assistant is used to control focus and iris.\n\nFor low-angle shots, the Steadicam sled can be inverted vertically, putting the camera on the bottom, and the monitor and batteries on the top. This is referred to as \"low mode\" operation.\n\nThe newest generation is the Tango. A body-supported camera-stabilization-system, its horizontal mechanism makes it possible to move the camera freely while staying horizontal. A Steadicam operator can change from low mode to high mode without any alteration. Dimensions are not limited to ups and downs, but also in depth and over or through obstacles.\n\nThe smallest, lightest Steadicam that can be used with a support arm and vest is the Merlin. It is light enough to be hand held with cameras weighing up to about 5.5 pounds (2.5 kg), and may carry cameras up to about 7 pounds (3.2 kg) when used with the arm. The Merlin may be folded and carried in comparatively small spaces such as medium-size camera bags. In its lightest configuration, the Merlin weighs just 12.5 ounces (0.35 kg). Photographers who shoot with HDSLR cameras that combine still and motion photography most often work with the Merlin. Since the Merlin has no facility to carry a separate monitor, cameras suitable for it must have built-in monitors.\n\nSteadicam introduced a camera mount for smartphones, called the Smoothee, in 2012. Marketed to consumers instead of video professionals, its tubular frame supports iPhone and Android phones that are 4.53\" to 6.26\" long by 2.32\" to 3.27\" wide (115 to 159 mm long by 59 to 83 mm wide). An adapter can be used to fit a GoPro camera to it. An even smaller, camera-specific Steadicam Curve (a single, curved aluminum slash) is available for GoPro cameras. It is also marketed to consumers.\n\n\n\n\n\n\n\n"}
{"id": "37830742", "url": "https://en.wikipedia.org/wiki?curid=37830742", "title": "Surtout de table", "text": "Surtout de table\n\nA surtout de table is an ornamental centrepiece displayed on a formal dining table. Evolving from a simple plate or bowl on which to stand candlesticks and condiments, a surtout de table often took the form of a long galleried tray made of precious or gilded metals, on which a series of other objects were placed for display. It was often made in sections allowing its length to be determined by the leaves added to the table. During the later half of the 18th century and throughout the 19th century, no formal table was considered compete without one. Today, they are still seen and used in the most formal dining rooms.\n\nThe term can refer either to a large centrepiece object, or the tray type on which objects are placed, or the two in combination.\n\nThe surtout de table first appeared in the 17th century and was a utilitarian object designed to hold candles, and protect a polished wooden table from the staining caused by spillage from the salt and vinegars in the condiments. As the great central and ceremonial salt cellars fell from favour, to be replaced by smaller individual salt cellars, during the first half of the 18th century, the surtout de table evolved to fill the role of ornamental table centrepiece. It often took the form of a raised galleried tray which would be filled with matching candelabra, figurines, vases and epergnes, the gallery itself sometimes containing candle sconces. They were not always constructed from precious metals; porcelain and glass were often used, as might be sculptures made from sugar. The top of the tray was often a mirror, to show the underside of the objects on it, and increase reflected light.\n\nIt was not uncommon, if a surtout de table were commissioned for a specific house, for an indigenous theme to be used in the style. Hence, a hunting lodge may have a surtout de table with figurines of dogs and their quarry while a grander town palace would feature the most fashionable Rococo or Baroque styles of the day.\n\nDuring the 1850s, the fashion for themed dining table decoration reached its apogee and the surtout de table reflected this. Porcelain factories such as Meissen produced elaborate models and figurines which replaced the classical statuary of the Empire style with coloured porcelain mountains, rustic scenes with cattle and goats and, occasionally, even a jungle theme complete with lifelike porcelain snakes.\n\nNotable examples of surtouts de table include those made the Italian goldsmith Luigi Valadier, often designed by his son, the architect Giuseppe Valadier. These monumental surtouts de table often represent Roman cities in miniature, complete with temples, colonnades and triumphal arches of coloured marbles and alabaster mounted on gold and mosaic pediments.\n\nWaddesdon Manor in England is now home to a vast 6.7 metre long gilt tray surtout de table made by Pierre-Philippe Thomire (1751-1843). Made circa 1818, it was given to Prince Ruffo della Scaletta by Louis XVIII.\n\nFrance distributing wreaths of glory is the name and theme of a large silver plate on bronze surtout de table commissioned from the Parisian jeweller Charles Christofle by Napoleon III in 1852. Intended for use at state banquets at the Tuileries Palace, the gilded tray contains a garniture of fifteen sculptures. The central figure is a winged Victory bearing laurel leaves which she awards to two horse-drawn chariots representing war and peace. At Victory's feet sit figurines representing Justice, Concord, Force and Religion.\n\nThe surtout de table was still in situ when the palace caught fire in 1871. It was pulled from the smoking debris damaged but intact. It has never been restored and is today displayed with its smoke-blackened gilt and dents at the Musée des Arts Décoratifs in Paris.\n"}
{"id": "41783", "url": "https://en.wikipedia.org/wiki?curid=41783", "title": "Teleconference", "text": "Teleconference\n\nA teleconference or teleseminar is the live exchange and mass articulation of information among several persons and machines remote from one another but linked by a telecommunications system. Terms such as audio conferencing, telephone conferencing and phone conferencing are also sometimes used to refer to teleconferencing.\n\nThe telecommunications system may support the teleconference by providing one or more of the following: audio, video, and/or data services by one or more means, such as telephone, computer, telegraph, teletypewriter, radio, and television.\n\nInternet teleconferencing includes internet telephone conferencing, videoconferencing, web conferencing, and augmented reality conferencing.\n\nInternet telephony involves conducting a teleconference over the Internet or a Wide Area Network. One key technology in this area is Voice over Internet Protocol (VOIP). Popular software for personal use includes Skype, Google Talk, Windows Live Messenger and Yahoo! Messenger.\n\nA working example of an augmented reality conferencing was demonstrated at the Salone di Mobile in Milano by AR+RFID Lab. is another AR teleconferencing tool.\n\nNotable vendors with articles:\n\n"}
{"id": "3385905", "url": "https://en.wikipedia.org/wiki?curid=3385905", "title": "Television interference", "text": "Television interference\n\nTelevision interference (TVI) is a particular case of electromagnetic interference which affects television reception. Many natural and man-made phenomena can disrupt the reception of television signals. These include naturally occurring and artificial spark discharges, and effects due to the operation of radio transmitters.\n\nAnalog television broadcasts display different effects due to different kinds of interference. Digital television reception generally gives a good quality picture until the interference is so large that it can no longer be eliminated by the error checking systems in the receiver, at which point the video display becomes pixelated, distorts, or goes blank.\n\nDuring unusual atmospheric conditions, a distant station normally undectable at a particular location may provide a much stronger signal than usual. The analog television picture may display the sum of the two signals, producing an image from the strong local signal with traces or \"ghosts\" from the distant, weaker signal. Television broadcast stations are located and assigned to channels so that such events are rare. Readjustment of the receiving antenna may allow more of the distant signal to be rejected, improving image quality.\n\nA local signal may travel by more than one path from the transmitter to receiving antenna. \"Multipath\" reception is visible as multiple impressions of the same image, slightly shifted along the width of the screen due to the varying transmission path. Some multipath reception is momentary due to road vehicles or aircraft passing; other multipath problems may persist due to reflection off tall buildings or other landscape features. Strong multipath can cause the analog picture to \"tear\" or momentarily lose synchronization, causing it to roll or flip.\n\nThe sparks generated by static electricity can generate interference.\n\nMany systems where radio frequency interface is caused by sparking can be modeled as the following circuit. The source of energy charges C1 via a resistance, and when the spark gap breaks down, the electricity passes through L and excites the resonant LC circuit. The energy in the LC circuit is then radiated through the aerial.\nAs an example, when a person walks over a nylon carpet, the rubbing of shoes on carpet performs the role of a battery and resistor, while the person acts as a capacitor (C1 and C2), and the air between a hand and a door knob is a spark gap. Stray inductance acts as L.\n\nHorizontal lines randomly arranged on a television screen may be caused by sparking in a malfunctioning electrical device. Electric railways can also be a strong source of this type of interference.\n\nOther possible sources of such interference include:\n\n\nThyristor and Triac regulators without proper chokes are a common source of EMI as well. It is likely that a thyristor (SCR) power controller using the variable phase angle method will generate harmonics of the mains supply, while the spark at a contact will be a very wide band source whose frequency is not related to the power supply frequency. In Thyristor control systems the potential for EMI problems can be minimised by using zero crossing switching where the thyristor is switched on at the moment of time when the AC voltage changes from one direction to the other.\n\n\nE = E sin (ωt) - {E sin (2ωt)}/2 + {E sin (3ωt)}/3 ...\n\nAs the term goes on for ever to higher and higher frequencies the square wave contains harmonics of the fundamental which go on upwards in frequency for ever, these harmonics are responsible for much of the interference created by computers. A modern PC is a device which is operating in the VHF/UHF frequency range using square waves. As the cases on many computers are not perfect shields, some of this radio frequency energy can leak out and cause interference to radio (and sometimes TV) reception.\n\n\nIt is possible to also get a bad picture if the signal strength of the TV transmitter is too high. An attenuator inserted in the antenna lead-in wire may be used if the television receiver displays signs of overload in the RF front end. Strong out-of-band signals may also affect television reception and may require band-pass filters to reduce the level of the undesired signal at the receiver.\n\n"}
{"id": "1134910", "url": "https://en.wikipedia.org/wiki?curid=1134910", "title": "Toilet roll holder", "text": "Toilet roll holder\n\nA toilet-roll holder, also known as a toilet paper dispenser, is an item that holds a roll of toilet paper. Common models include a hinged length of wire mounted horizontally on a wall, a thicker axle either recessed into a wall or mounted on a frame, or a freestanding vertical pole on a base. In recent years, automatic toilet paper dispensers which automatically fold and cut the toilet paper are being installed in public toilets.\n\nIn the first case, the idea is that the toilet roll maintains contact with the door or wall as the roll's radius decreases. This provides enough friction to allow the user to tear off a piece of tissue. More sophisticated designs include a curved horizontal plate that covers the roll, thus removing the necessity of touching the roll. These roll holders can be used in both orientations, but may be difficult to use in the \"under\" orientation.\n\nThe horizontal axle design is found in most homes, and also in many schools. It is easy to use due to its low friction and ease of refilling. This is the type of holder most commonly assumed about when toilet paper orientation is mentioned.\n\nThis type of holder is not common, probably because it can get in the way of traffic getting on and off the toilet more than the horizontal axle in the wall.\n\nOriginally intended to hold a stock of replacement rolls, the vertical pole has become the only paper holder in some households. It is particularly useful in homes where the family has mixed handedness. Its drawbacks include that there is a lot more friction than in other types of toilet roll holders, and thus not as easy to use.\n\nThe holders in many public toilets are designed to make it difficult for patrons to steal the toilet rolls. Various contraptions have been devised to lock the spare rolls away, and release them only when the active roll is used up.\n\nAn increasing number of public toilets are furnished with holders that hold very large rolls of toilet paper. These are designed to save money by reducing the frequency of janitorial services to restock the paper.\n\nIn many toilets, especially in elementary schools, a dispenser releases only a small square of toilet paper to prevent a user from intentionally clogging the toilet with large amounts of paper.\n\n"}
{"id": "32288", "url": "https://en.wikipedia.org/wiki?curid=32288", "title": "Usability testing", "text": "Usability testing\n\nUsability testing is a technique used in user-centered interaction design to evaluate a product by testing it on users. This can be seen as an irreplaceable usability practice, since it gives direct input on how real users use the system. This is in contrast with usability inspection methods where experts use different methods to evaluate a user interface without involving users.\n\nUsability testing focuses on measuring a human-made product's capacity to meet its intended purpose. Examples of products that commonly benefit from usability testing are food, consumer products, web sites or web applications, computer interfaces, documents, and devices. Usability testing measures the usability, or ease of use, of a specific object or set of objects, whereas general human–computer interaction studies attempt to formulate universal principles.\n\nSimply gathering opinions on an object or document is market research or qualitative research rather than usability testing. Usability testing usually involves systematic observation under controlled conditions to determine how well people can use the product. However, often both qualitative and usability testing are used in combination, to better understand users' motivations/perceptions, in addition to their actions.\n\nRather than showing users a rough draft and asking, \"Do you understand this?\", usability testing involves watching people trying to \"use\" something for its intended purpose. For example, when testing instructions for assembling a toy, the test subjects should be given the instructions and a box of parts and, rather than being asked to comment on the parts and materials, they are asked to put the toy together. Instruction phrasing, illustration quality, and the toy's design all affect the assembly process.\n\nSetting up a usability test involves carefully creating a scenario, or realistic situation, wherein the person performs a list of tasks using the product being tested while observers watch and take notes (dynamic verification). Several other test instruments such as scripted instructions, paper prototypes, and pre- and post-test questionnaires are also used to gather feedback on the product being tested (static verification). For example, to test the attachment function of an e-mail program, a scenario would describe a situation where a person needs to send an e-mail attachment, and ask him or her to undertake this task. The aim is to observe how people function in a realistic manner, so that developers can see problem areas, and what people like. Techniques popularly used to gather data during a usability test include think aloud protocol, co-discovery learning and eye tracking.\n\nHallway testing is a quick and cheap method of usability testing in which randomly-selected people—e.g., those passing by in the hallway—are asked to try using the product or service. This can help designers identify \"brick walls\", problems so serious that users simply cannot advance, in the early stages of a new design. Anyone but project designers and engineers can be used (they tend to act as \"expert reviewers\" because they are too close to the project).\n\nIn a scenario where usability evaluators, developers and prospective users are located in different countries and time zones, conducting a traditional lab usability evaluation creates challenges both from the cost and logistical perspectives. These concerns led to research on remote usability evaluation, with the user and the evaluators separated over space and time. Remote testing, which facilitates evaluations being done in the context of the user's other tasks and technology, can be either synchronous or asynchronous. The former involves real time one-on-one communication between the evaluator and the user, while the latter involves the evaluator and user working separately. Numerous tools are available to address the needs of both these approaches.\n\nSynchronous usability testing methodologies involve video conferencing or employ remote application sharing tools such as WebEx. WebEx and GoToMeeting are the most commonly used technologies to conduct a synchronous remote usability test. However, synchronous remote testing may lack the immediacy and sense of \"presence\" desired to support a collaborative testing process. Moreover, managing inter-personal dynamics across cultural and linguistic barriers may require approaches sensitive to the cultures involved. Other disadvantages include having reduced control over the testing environment and the distractions and interruptions experienced by the participants' in their native environment. One of the newer methods developed for conducting a synchronous remote usability test is by using virtual worlds.\n\nAsynchronous methodologies include automatic collection of user's click streams, user logs of critical incidents that occur while interacting with the application and subjective feedback on the interface by users. Similar to an in-lab study, an asynchronous remote usability test is task-based and the platform allows researchers to capture clicks and task times. Hence, for many large companies, this allows researchers to better understand visitors' intents when visiting a website or mobile site. Additionally, this style of user testing also provides an opportunity to segment feedback by demographic, attitudinal and behavioral type. The tests are carried out in the user's own environment (rather than labs) helping further simulate real-life scenario testing. This approach also provides a vehicle to easily solicit feedback from users in remote areas quickly and with lower organizational overheads. In recent years, conducting usability testing asynchronously has also become prevalent and allows testers to provide feedback in their free time and from the comfort of their own home.\n\nExpert review is another general method of usability testing. As the name suggests, this method relies on bringing in experts with experience in the field (possibly from companies that specialize in usability testing) to evaluate the usability of a product.\n\nA heuristic evaluation or usability audit is an evaluation of an interface by one or more human factors experts. Evaluators measure the usability, efficiency, and effectiveness of the interface based on usability principles, such as the 10 usability heuristics originally defined by Jakob Nielsen in 1994.\n\nNielsen's usability heuristics, which have continued to evolve in response to user research and new devices, include:\n\nSimilar to expert reviews, automated expert reviews provide usability testing but through the use of programs given rules for good design and heuristics. Though an automated review might not provide as much detail and insight as reviews from people, they can be finished more quickly and consistently. The idea of creating surrogate users for usability testing is an ambitious direction for the artificial intelligence community.\n\nIn web development and marketing, A/B testing or split testing is an experimental approach to web design (especially user experience design), which aims to identify changes to web pages that increase or maximize an outcome of interest (e.g., click-through rate for a banner advertisement). As the name implies, two versions (A and B) are compared, which are identical except for one variation that might impact a user's behavior. Version A might be the one currently used, while version B is modified in some respect. For instance, on an e-commerce website the purchase funnel is typically a good candidate for A/B testing, as even marginal improvements in drop-off rates can represent a significant gain in sales. Significant improvements can be seen through testing elements like copy text, layouts, images and colors.\n\nMultivariate testing or bucket testing is similar to A/B testing but tests more than two versions at the same time.\n\nIn the early 1990s, Jakob Nielsen, at that time a researcher at Sun Microsystems, popularized the concept of using numerous small usability tests—typically with only five test subjects each—at various stages of the development process. His argument is that, once it is found that two or three people are totally confused by the home page, little is gained by watching more people suffer through the same flawed design. \"Elaborate usability tests are a waste of resources. The best results come from testing no more than five users and running as many small tests as you can afford.\"\n\nThe claim of \"Five users is enough\" was later described by a mathematical model which states for the proportion of uncovered problems U\n\nformula_1\n\nwhere p is the probability of one subject identifying a specific problem and n the number of subjects (or test sessions). This model shows up as an asymptotic graph towards the number of real existing problems (see figure below).\n\nIn later research Nielsen's claim has eagerly been questioned with both empirical evidence and more advanced mathematical models. Two key challenges to this assertion are:\n\nIt is worth noting that Nielsen does not advocate stopping after a single test with five users; his point is that testing with five users, fixing the problems they uncover, and then testing the revised site with five different users is a better use of limited resources than running a single usability test with 10 users. In practice, the tests are run once or twice per week during the entire development cycle, using three to five test subjects per round, and with the results delivered within 24 hours to the designers. The number of users actually tested over the course of the project can thus easily reach 50 to 100 people.\n\nIn the early stage, when users are most likely to immediately encounter problems that stop them in their tracks, almost anyone of normal intelligence can be used as a test subject. In stage two, testers will recruit test subjects across a broad spectrum of abilities. For example, in one study, experienced users showed no problem using any design, from the first to the last, while naive user and self-identified power users both failed repeatedly. Later on, as the design smooths out, users should be recruited from the target population.\n\nWhen the method is applied to a sufficient number of people over the course of a project, the objections raised above become addressed: The sample size ceases to be small and usability problems that arise with only occasional users are found. The value of the method lies in the fact that specific design problems, once encountered, are never seen again because they are immediately eliminated, while the parts that appear successful are tested over and over. While it's true that the initial problems in the design may be tested by only five users, when the method is properly applied, the parts of the design that worked in that initial test will go on to be tested by 50 to 100 people.\n\nA 1982 Apple Computer manual for developers advised on usability testing:\n\n\nApple advised developers, \"You should begin testing as soon as possible, using drafted friends, relatives, and new employees\":\n\nDesigners must watch people use the program in person, because\n\nUsability testing has been a formal subject of academic instruction in different disciplines.\n\n"}
{"id": "34401991", "url": "https://en.wikipedia.org/wiki?curid=34401991", "title": "Versatile Laboratory Aid", "text": "Versatile Laboratory Aid\n\nThe Versatile Laboratory Aid (VELA) is a 4-channel data logging tool that was created as part of a joint venture by Ashley Clarke and David Binney of Leeds University and Educational Electronics. The VELA was designed to be used as a stand-alone data logger that could be used out in the field and it could then be taken back to the laboratory where it could be connected to a chart printer, oscilloscope or microcomputer for data analysis purposes.\n\nThe VELA was designed and built with the intention that it would be used in schools and Universities to monitor Physics and Chemistry experiments as it could be attached to all manner or analogue probes and sensors such as pH meters, temperature sensors, light gates, Signal generator and microphones. Each of the VELA's four channels can be independently set to record voltages in the ranges of +/-250mV, +/-2.5V and +/-25V allowing a range of different input devices to be connected simultaneously.\n\nThe basic VELA carries a single 4KB EPROM (ISL1 or ISL1*) which contains the basic input and output routines that handle the keyboard input and 8-digit LED display output together with seventeen user selectable programs which range from a 4-channel digital volt meter to a random event monitor which could be used with a Geiger Counter Probe to measure and log radiation levels from a source material.\n\nIn total, the VELA could record a maximum of 4096 data points either from one channel or split equally between the four channels depending on the selected monitoring program. In later versions of the VELA firmware (ISL1*), the number of data points was reduced by 7 bytes per data channel as these bytes were reserved for storing channel and program configuration data when transferring data to a microcomputer.\n\nThe VELA went through at least two hardware revisions going from the Mark I to Mark II and subsequently the VELA PLUS but the ISL ROMs remained compatible between all three devices although the Mark I VELA required a daughter board to carry the extra ROMs that were developed after the VELA's initial release.\n\nThe VELA Mark I was based around the Motorola MC6802 central processor and carried 4KB of RAM. It shipped with the original ISL1 ROM fitted and has space for a further 2 ROMs to be fitted on board. The PCB of the Mark I was split into two parts which connected to each other through a ribbon cable. The ROMs were generally shipped on 2732 EPROM chips and they could be sent back to Educational Electronics to be updated with enhanced firmware when it became available.\n\nThe VELA Mark II was a refinement to the Mark I design and was based on the same processor and hardware. The Mark II PCB was condensed onto a single board and carried space for a further three EPROM's to be fitted in addition to the ISL1* EPROM that it shipped with. There were modifications to the connectors on the VELA Mark II with the addition of a 5V 70mA output and a revised power supply connector although early Mark II VELA's continued to use the original 3.5mm power supply plug socket as used on the VELA Mark I.\n\nThe VELA PLUS was again a refinement on the Mark II VELA and the PCB carried alterations to the op-amps and circuitry associated with the channel inputs. The VELA front panel was also revised to make it clearer to understand as the usability of the VELA had been a source of issues amongst the teaching community.\n\nWith the advent of the VELA PLUS, the name Versatile Laboratory Aid\" which was displayed on the front panel was changed to Versatile Laboratory Instrument\" whilst retaining the VELA contraction.\n\nThe VELA was 50/50 subsidised by the DTI, an arm of the British Government to encourage take up within the education sector and many thousands of VELA units were sold to schools.\n\nIn 1986 an article in the Electronic Systems News Spring Journal stated \"4000 teachers now possess a VELA, but it is suspected that more than half of these have never been used.\"\n\nThe VELA was designed to be connected to three different types of device, being a chart printer, an oscilloscope or a microcomputer. Connecting the VELA to a chart printer allowed the captured data to be printed directly from the VELA for analysis and making a permanent record of the data captured. Connecting the VELA to an oscilloscope allowed users to have a real-time view of the data the VELA was recording or a playback view of pre-existing captured data. When connected to a microcomputer, the data captured could be stored and manipulated using a variety of different software applications that were available for the VELA.\n\nUsing the Digital Out port, the VELA can also be used as a control device using 8 of the 16 data lines provided.\n\nSoftware was produced for several microcomputers including the Apple II, BBC Micro, Commodore PET, Commodore 64, Research Machines 380Z and early IBM-PC compatible. A partial list of known software titles is listed below.\n\n"}
{"id": "19025220", "url": "https://en.wikipedia.org/wiki?curid=19025220", "title": "Virtway", "text": "Virtway\n\nVirtway is a serious game developer located in Oviedo, Spain. It was founded in 1999 as a general IT consulting firm, but in 2006 it spun off from its parent company to focus on 3D development and serious gaming as an independent branch of the Indigo Group holding.\n\nThe main focus of the company has been developing an advanced simulation system to empower learning through gaming, called VTS (Virtual Training System). The platform was presented at the 2008 Games+Learning+Society conference in partnership with Robb Lindgren from Stanford University.\n\nVTS is built on top of the Gamebryo game engine and uses NVIDIA PhysX for the physics simulation (Formerly known as Ageia).\n\nApparently VTS is being applied to several areas of training, such as Firefighting (a teaser video depicting firefighters appeared on the company's YouTube channel) or Iron/Steel Industry.\n\nVirtway has an extensive experience in developing 3D simulations/recreations of realistic scenarios distributed by several means (such as web pages).\n\n\"Molina Digital\" was the first large scale 3D project developed by Virtway. It was the recreation of a Spanish town (Molina de Segura, Murcia) where users could chat, drive cars and play Pétanque, all in 3D and through an Internet browser, leveraging the Quest3D technology.\n\nPart of the Molina Digital project was the development of an \"Interactive Theatre\", a pioneer application where users could take a role in a virtual play. Each user handles an avatar on stage, and controls its body language and facial expression while he talks with his mates. Everything is recorded by another user -the director- who edits the footage later, in a way similar to a machinima production.\n\nVirtway has also been contracted by the regional government of Asturias to develop a 3D virtual visit of the city of Llanes. The result of this contract is a website where users can visit said town in 3D using x3d technology and a port of the landmarks to Google Earth KML models.\n\nVirtway started the development of a project called \"Born To Run\" in 2004, and presented it in late 2006. It was aimed to be one of the first First Person Shooters with photo-realistic levels of quality made in Spain, and slated to hit \"next-gen\" systems (PC, PlayStation 3 and Xbox 360). There has been no more information about the game since its announcement, so it is probably cancelled by now.\n\nOn 6 October 2008, Virtway entered into partnership with ICYou, a Swedish company, to further develop their so-called Interactive City platform, a persistent virtual world with tie-ins to the real world of its players through a blend of virtual and real economy.\n\nAs a member of the Indigo Group Holding, Virtway collaborates with some strategic partners which share their knowledge and allow them to offer better services.\n\nAs one of their partners Alletrust offers experience to Virtway improving their process and services.\n\nICYou AB (Publ) is a strategic partners that develops the Interactive City on the Virtway platform.\n\nVirtway has maintained collaborations through the Índigo Group with University of Oviedo and Stanford University in different research and development projects.\n\n"}
{"id": "521801", "url": "https://en.wikipedia.org/wiki?curid=521801", "title": "Water heating", "text": "Water heating\n\nWater heating is a heat transfer process that uses an energy source to heat water above its initial temperature. Typical domestic uses of hot water include cooking, cleaning, bathing, and space heating. In industry, hot water and water heated to steam have many uses.\n\nDomestically, water is traditionally heated in vessels known as \"water heaters\", \"kettles\", \"cauldrons\", \"pots\", or \"coppers\". These metal vessels that heat a batch of water do not produce a continual supply of heated water at a preset temperature. Rarely, hot water occurs naturally, usually from natural hot springs. The temperature varies with the consumption rate, becoming cooler as flow increases.\n\nAppliances that provide a continual supply of hot water are called \"water heaters\", \"hot water heaters\", \"hot water tanks\", \"boilers\", \"heat exchangers\", \"geysers\", or \"calorifiers\". These names depend on region, and whether they heat potable or non-potable water, are in domestic or industrial use, and their energy source. In domestic installations, potable water heated for uses other than space heating is also called \"domestic hot water\" (\"DHW\").\n\nFossil fuels (natural gas, liquefied petroleum gas, oil), or solid fuels are commonly used for heating water. These may be consumed directly or may produce electricity that, in turn, heats water. Electricity to heat water may also come from any other electrical source, such as nuclear power or renewable energy. Alternative energy such as solar energy, heat pumps, hot water heat recycling, and geothermal heating can also heat water, often in combination with backup systems powered by fossil fuels or electricity.\n\nDensely populated urban areas of some countries provide district heating of hot water. This is especially the case in Scandinavia, Finland and Poland. District heating systems supply energy for water heating and space heating from combined heat and power (CHP) plants, waste heat from industries, incinerators, geothermal heating, and central solar heating. Actual heating of tap water is performed in heat exchangers at the consumers' premises. Generally the consumer has no in-building backup system, due to the expected high availability of district heating systems.\n\nHot water used for space heating may be heated by fossil fuels in a boiler, while potable water may be heated in a separate appliance. This is common practice in the US, especially when warm-air space heating is usually employed.\n\nIn household and commercial usage, most North American and Southern Asian water heaters are the tank type, also called \"storage water heaters\", these consist of a cylindrical vessel or container that keeps water continuously hot and ready to use. Typical sizes for household use range from 75 to 400 liters (20 to 100 US gallons). These may use electricity, natural gas, propane, heating oil, solar, or other energy sources. Natural gas heaters are most popular in the US and most European countries, since the gas is often conveniently piped throughout cities and towns and currently is the cheapest to use. In the United States, typical natural gas water heaters for households without unusual needs are 40 or 50 US gallons with a burner rated at 34,000 to 40,000 BTU/hour. Some models offer \"High Efficiency and Ultra Low NOx\" emissions.\n\nThis is a popular arrangement where higher flow rates are required for limited periods. Water is heated in a pressure vessel that can withstand a hydrostatic pressure close to that of the incoming mains supply. A pressure reducing valve is sometimes employed to limit the pressure to a safe level for the vessel. In North America, these vessels are called \"hot water tanks\", and may incorporate an electrical resistance heater, a heat pump, or a gas or oil burner that heats water directly.\n\nWhere hot-water space heating boilers are installed, domestic hot water cylinders are usually heated indirectly by primary water from the boiler, or by an electric immersion heater (often as backup to the boiler). In the UK these vessels are called \"indirect cylinders\", or \"direct cylinders\", respectively. Additionally, if these cylinders form part of a sealed system, providing mains-pressure hot water, they are known as unvented cylinders. In the US, when connected to a boiler they are called \"indirect-fired water heaters\".\n\nCompared to tankless heaters, storage water heaters have the advantage of using energy (gas or electricity) at a relatively slow rate, storing the heat for later use. The disadvantage is that over time, heat escapes through the tank wall and the water cools down, activating the heating system to heat the water back up, so investing in a tank with better insulation improves this standby efficiency. Additionally, when heavy use exhausts the hot water, there is a significant delay before hot water is available again. Larger tanks tend to provide hot water with less temperature fluctuation at moderate flow rates.\n\nVolume storage water heaters in the United States and New Zealand are typically vertical, cylindrical tanks, usually standing on the floor or on a platform raised a short distance above the floor. Volume storage water heaters in Spain are typically horizontal. In India, they are mainly vertical. In apartments they can be mounted in the ceiling space over laundry-utility rooms. In Australia, gas and electric outdoor tank heaters have mainly been used (with high temperatures to increase effective capacity), but solar roof tanks are becoming fashionable.\n\nTiny \"point-of-use\" (POU) electric storage water heaters with capacities ranging from 8 to 32 liters (2 to 6 gallons) are made for installation in kitchen and bath cabinets or on the wall above a sink. They typically use low power heating elements, about 1 kW to 1.5 kW, and can provide hot water long enough for hand washing, or, if plumbed into an existing hot water line, until hot water arrives from a remote high capacity water heater. They may be used when retrofitting a building with hot water plumbing is too costly or impractical. Since they maintain water temperature thermostatically, they can only supply a continuous flow of hot water at extremely low flow rates, unlike high-capacity tankless heaters.\n\nIn tropical countries, like Singapore and India, a storage water heater may vary from 10 L to 35 L. Smaller water heaters are sufficient, as ambient weather temperatures and incoming water temperature are moderate.\n\nA locational design decision may be made between point-of-use and centralized water heaters. Centralized water heaters are more traditional, and are still a good choice for small buildings. For larger buildings with intermittent or occasional hot water use, multiple POU water heaters may be a better choice, since they can reduce long waits for hot water to arrive from a remote heater. The decision where to locate the water heater(s) is only partially independent of the decision of a tanked vs. tankless water heater, or the choice of energy source for the heat.\n\nTankless water heaters—also called \"instantaneous\", \"continuous flow\", \"inline\", \"flash\", \"on-demand\", or \"instant-on\" water heaters—are gaining in popularity. These high-power water heaters instantly heat water as it flows through the device, and do not retain any water internally except for what is in the heat exchanger coil. Copper heat exchangers are preferred in these units because of their high thermal conductivity and ease of fabrication.\n\nTankless heaters may be installed throughout a household at more than one point-of-use (POU), far from a central water heater, or larger centralized models may still be used to provide all the hot water requirements for an entire house. The main advantages of tankless water heaters are a plentiful continuous flow of hot water (as compared to a limited flow of continuously heated hot water from conventional tank water heaters), and potential energy savings under some conditions. The main disadvantage is their much higher initial costs, a US study in Minnesota reported a 20- to 40-year payback for the tankless water heaters. In a comparison to a less efficient natural gas fired hot water tank, on-demand natural gas will cost 30% more over its useful life.\n\nStand-alone appliances for quickly heating water for domestic usage are known in North America as \"tankless\" or \"on demand\" water heaters. In some places, they are called \"multipoint heaters\", \"geysers\" or \"ascots\". In Australia and New Zealand they are called \"instantaneous hot water units\". In Argentina they are called \"calefones\". In that country \"calefones\" use gas instead of electricity. A similar wood-fired appliance was known as the chip heater.\n\nA common arrangement where hot-water space heating is employed, is for a boiler to also heat potable water, providing a continuous supply of hot water without extra equipment. Appliances that can supply both space-heating and domestic hot water are called \"combination\" (or \"combi\") boilers. Though on-demand heaters provide a continuous supply of domestic hot water, the rate at which they can produce it is limited by the thermodynamics of heating water from the available fuel supplies.\n\nAn electric shower head has an electric heating element which heats water as it passes through. These self-heating shower heads are specialized point-of-use (POU) tankless water heaters, and are widely used in some countries.\n\nInvented in Brazil in the 1930s and used frequently since the 1940s, the electric shower is a home appliance often seen in South American countries due to the higher costs of gas distribution. Earlier models were made of chromed copper or brass, which were expensive, but since 1970, units made of injected plastics are popular due to low prices similar to that of a hair dryer. Electric showers have a simple electric system, working like a coffee maker, but with a larger water flow. A flow switch turns on the device when water flows through it. Once the water is stopped, the device turns off automatically. An ordinary electric shower often has three heat settings: high (5.5 kW), low (2.5 kW), or cold (0 W) to use when a central heater system is available or in hot seasons.\n\nThe power consumption of electric showers in the maximum heating setting is about 5.5 kW for 120 V and 7.5 kW for 220 V. The lower costs with electric showers compared to the higher costs with boilers is due to the time of use: an electric shower uses energy only while the water flows, while a boiler works many times a day to keep a quantity of standing water hot for use throughout the day and night. Moreover, the transfer of electric energy to the water in an electric shower head is very efficient, approaching 100%. Electric showers may save energy compared to electric tank heaters, which lose some standby heat.\nThere is a wide range of electric showers, with various types of heating controls. The heating element of an electric shower is immersed in the water stream, using a nichrome resistance element which is sheathed and electrically isolated, like the ones used in oil heaters, radiators or clothes irons, providing safety. Due to electrical safety standards, modern electric showers are made of plastic instead of using metallic casings like in the past. As an electrical appliance that uses more electric current than a washer or a dryer, an electric shower installation requires careful planning, and generally is intended to be wired directly from the electrical distribution box with a dedicated circuit breaker and ground system. A poorly installed system with old aluminum wires or bad connections may be dangerous, as the wires can overheat or electric current may leak via the water stream through the body of the user to earth.\n\nIncreasingly, solar powered water heaters are being used. Their solar collectors are installed outside dwellings, typically on the roof or walls or nearby, and the potable hot water storage tank is typically a pre-existing or new conventional water heater, or a water heater specifically designed for solar thermal.\n\nThe most basic solar thermal models are the direct-gain type, in which the potable water is directly sent into the collector. Many such systems are said to use \"integrated collector storage\" (ICS), as direct-gain systems typically have storage integrated within the collector. Heating water directly is inherently more efficient than heating it indirectly via heat exchangers, but such systems offer very limited freeze protection (if any), can easily heat water to temperatures unsafe for domestic use, and ICS systems suffer from severe heat loss on cold nights and cold, cloudy days.\n\nBy contrast, \"indirect\" or \"closed-loop\" systems do not allow potable water through the panels, but rather pump a heat transfer fluid (either water or a water/antifreeze mix) through the panels. After collecting heat in the panels, the heat transfer fluid flows through a heat exchanger, transferring its heat to the potable hot water. When the panels are cooler than the storage tank or when the storage tank has already reached its maximum temperature, the controller in closed-loop systems stops the circulation pumps. In a \"drainback\" system, the water drains into a storage tank contained in conditioned or semi-conditioned space, protected from freezing temperatures. With antifreeze systems, however, the pump \"must\" be run if the panel temperature gets too hot (to prevent degradation of the antifreeze) or too cold (to prevent the water/antifreeze mixture from freezing.)\n\n\"Flat panel collectors\" are typically used in closed-loop systems. Flat panels, which often resemble skylights, are the most durable type of collector, and they also have the best performance for systems designed for temperatures within of ambient temperature. Flat panels are regularly used in both pure water and antifreeze systems.\n\nAnother type of solar collector is the \"evacuated tube collector\", which are intended for cold climates that do not experience severe hail and/or applications where high temperatures are needed (i.e., over ). Placed in a rack, evacuated tube collectors form a row of glass tubes, each containing absorption fins attached to a central heat-conducting rod (copper or condensation-driven). The \"evacuated\" description refers to the vacuum created in the glass tubes during the manufacturing process, which results in very low heat loss and lets evacuated tube systems achieve extreme temperatures, far in excess of water's boiling point.\n\nIn countries like Iceland and New Zealand, and other volcanic regions, water heating may be done using geothermal heating, rather than combustion.\n\nWhere a space-heating water boiler is employed, the traditional arrangement in the UK is to use boiler-heated (\"primary\") water to heat potable (\"secondary\") water contained in a cylindrical vessel (usually made of copper)—which is supplied from a cold water storage vessel or container, usually in the roof space of the building. This produces a fairly steady supply of DHW (Domestic Hot Water) at low static pressure head but usually with a good flow. In most other parts of the world, water heating appliances do not use a cold water storage vessel or container, but heat water at pressures close to that of the incoming mains water supply.\n\nOther improvements to water heaters include check valve devices at their inlet and outlet, cycle timers, electronic ignition in the case of fuel-using models, sealed air intake systems in the case of fuel-using models, and pipe insulation. The sealed air-intake system types are sometimes called \"band-joist\" intake units. \"High-efficiency\" condensing units can convert up to 98% of the energy in the fuel to heating the water. The exhaust gases of combustion are cooled and are mechanically ventilated either through the roof or through an exterior wall. At high combustion efficiencies a drain must be supplied to handle the water condensed out of the combustion products, which are primarily carbon dioxide and water vapor.\n\nIn traditional plumbing in the UK, the space-heating boiler is set up to heat a separate \"hot water cylinder\" or \"water heater\" for potable hot water. Such water heaters are often fitted with an auxiliary electrical \"immersion heater\" for use if the boiler is out of action for a time. Heat from the space-heating boiler is transferred to the water heater vessel/container by means of a heat exchanger, and the boiler operates at a higher temperature than the potable hot water supply. Most potable water heaters in North America are completely separate from the space heating units, due to the popularity of HVAC/forced air systems in North America.\n\nResidential combustion water heaters manufactured since 2003 in the United States have been redesigned to resist ignition of flammable vapors and incorporate a thermal cutoff switch, per ANSI Z21.10.1. The first feature attempts to prevent vapors from flammable liquids and gases in the vicinity of the heater from being ignited and thus causing a house fire or explosion. The second feature prevents tank overheating due to unusual combustion conditions. These safety requirements were made in response to homeowners storing, or spilling, gasoline or other flammable liquids near their water heaters and causing fires. Since most of the new designs incorporate some type of flame arrestor screen, they require monitoring to make sure they do not become clogged with lint or dust, reducing the availability of air for combustion. If the flame arrestor becomes clogged, the thermal cutoff may act to shut down the heater.\n\nA \"wetback stove\" (NZ), \"wetback heater\" (NZ), or \"back boiler\" (UK), is a simple household secondary water heater using incidental heat. It typically consists of a hot water pipe running behind a fireplace or stove (rather than hot water storage), and has no facility to limit the heating. Modern wetbacks may run the pipe in a more sophisticated design to assist heat-exchange. These designs are being forced out by government efficiency regulations that do not count the energy used to heat water as 'efficiently' used.\n\nThough not very popular in North America, another type of water heater developed in Europe predated the storage model. In London, England, in 1868, a painter named Benjamin Waddy Maughan invented the first instantaneous domestic water heater that did not use solid fuel. Named the \"geyser\" after an Icelandic gushing hot spring, Maughan's invention made cold water at the top flow through pipes that were heated by hot gases from a burner at the bottom. Hot water then flowed into a sink or tub. The invention was somewhat dangerous because there was no flue to remove heated gases from the bathroom. A water heater is still sometimes called a \"geyser\" in the UK.\n\nMaughn's invention influenced the work of a Norwegian mechanical engineer named Edwin Ruud. The first automatic, storage tank-type gas water was invented around 1889 by Ruud after he immigrated to Pittsburgh, Pennsylvania (US). The Ruud Manufacturing Company, still in existence today, made many advancements in tank-type and tankless water heater design and operation.\n\nWater typically enters residences in the US at about , depending on latitude and season. Hot water temperatures of are usual for dish-washing, laundry and showering, which requires that the heater raise the water temperature about if the hot water is mixed with cold water at the point of use. The Uniform Plumbing Code reference shower flow rate is per minute. Sink and dishwasher usages range from per minute.\n\nNatural gas in the US is measured in CCF (100 cubic feet), which is converted to a standardized energy unit called the therm, which is equal to 100,000 British thermal units (BTU). A BTU is the energy required to raise one pound of water by one degree Fahrenheit. A US gallon of water weighs . To raise 60 gallons of water from to requires , or approximately 0.359 CCF (35,856/100,000), at 88% efficiency. A 157,000 BTU/h heater (as might exist in a tankless heater) would take 15.6 minutes to do this, at 88% efficiency. At $1 per therm, the cost of the gas would be about 41 cents.\n\nIn comparison, a typical 60 gallon tank electric water heater has a 4500 watt (15,355BTU) heating element, which at 100% efficient results in a heating time of about 2.34 hours. At 16 cents/kWh the electricity would cost $1.68.\n\nEnergy efficiencies of water heaters in residential use can vary greatly, particularly depending on manufacturer and model. However, electric heaters tend to be slightly more efficient (not counting power station losses) with recovery efficiency (how efficiently energy transfers to the water) reaching about 98%. Gas fired heaters have maximum recovery efficiencies of only about 82–94% (the remaining heat is lost with the flue gasses). Overall energy factors can be as low as 80% for electric and 50% for gas systems. Natural gas and propane tank water heaters with energy factors of 62% or greater, as well as electric tank water heaters with energy factors of 93% or greater, are considered high-efficiency units. Energy Star-qualified natural gas and propane tank water heaters (as of September 2010) have energy factors of 67% or higher, which is usually achieved using an intermittent pilot together with an automatic flue damper, baffle blowers, or power venting. Direct electric resistance tank water heaters are not included in the Energy Star program, however, the Energy Star program does include electric heat pump units with energy factors of 200% or higher. Tankless gas water heaters (as of 2015) must have an energy factor of 90% or higher for Energy Star qualification. Since electricity production in thermal plants has efficiency levels ranging from only 15% to slightly over 55% (combined cycle gas turbine), with around 40% typical for thermal power stations, direct resistance electric water heating may be the least energy efficient option. However, use of a heat pump can make electric water heaters much more energy efficient and lead to a decrease in carbon dioxide emissions, even more so if a low carbon source of electricity is used.\n\nUnfortunately, it takes a great deal of energy to heat water, as one may experience when waiting to boil a gallon of water on a stove. For this reason, tankless on-demand water heaters require a powerful energy source. A standard 120-V, 15-ampere rated wall electric outlet, by comparison, only sources enough power to warm a disappointingly small amount of water: about per minute at temperature elevation.\n\nOn April 16, 2015, as part of the National Appliance Energy Conservation Act (NAECA), new minimum standards for efficiency of residential water heaters set by the United States Department of Energy went into effect. All new gas storage tank water heaters with capacities smaller than sold in the United States in 2015 or later shall have an energy factor of at least 60% (for 50-US-gallon units, higher for smaller units), increased from the pre-2015 minimum standard of 58% energy factor for 50-US-gallon gas units. Electric storage tank water heaters with capacities less than 55 US gallons sold in the United States shall have an energy factor of at least 95%, increased from the pre-2015 minimum standard of 90% for 50-US-gallon electric units.\n\nUnder the 2015 standard, for the first time, storage water heaters with capacities of 55 US gallons or larger now face stricter efficiency requirements than those of 50 US gallons or less. Under the pre-2015 standard, a gas storage water heater with a nominal input of or less was able to have an energy factor as low as 53%, while under the 2015 standard, the minimum energy factor for a 75-US-gallon gas storage tank water heater is now 74%, which can only be achieved by using condensing technology. Storage water heaters with a nominal input of 75,000 btu or greater are not currently affected by these requirements, since energy factor is not defined for such units. An electric storage tank water heater was able to have a minimum energy factor of 86% under the pre-2015 standard, while under the 2015 standard, the minimum energy factor for an 80-gallon electric storage tank water heater is now 197%, which is only possible with heat pump technology. This rating measures efficiency at the point of use. Depending on how electricity is generated, overall efficiency may be much lower. For example, in a traditional coal plant, only about 30–35% of the energy in the coal ends up as electricity on the other end of the generator. Losses on the electrical grid (including line losses and voltage transformation losses) reduce electrical efficiency further. According to data from the Energy Information Administration, transmission and distribution losses in 2005 consumed 6.1% of net generation. In contrast, 90% of natural gas’ energy value is\ndelivered to the consumer. (In neither case is the energy expended exploring, developing and extracting coal or natural gas resources included in the quoted efficiency numbers.) Gas tankless water heaters shall have an energy factor of 82% or greater under the 2015 standards, which corresponds to the pre-2015 Energy Star standard.\n\nWater heaters potentially can explode and cause significant damage, injury, or death if certain safety devices are not installed. A safety device called a temperature and pressure relief (T&P or TPR) valve, is normally fitted on the top of the water heater to dump water if the temperature or pressure becomes too high. Most plumbing codes require that a discharge pipe be connected to the valve to direct the flow of discharged hot water to a drain, typically a nearby floor drain, or outside the living space. Some building codes allow the discharge pipe to terminate in the garage.\n\nIf a gas or propane fired water heater is installed in a garage or basement, many plumbing codes require that it be elevated at least above the floor to reduce the potential for fire or explosion due to spillage or leakage of combustible liquids in the garage. Furthermore, certain local codes mandate that tank-type heaters in new and retrofit installations must be secured to an adjacent wall by a strap or anchor to prevent tipping over and breaking the water and gas pipes in the event of an earthquake.\n\nFor older houses where the water heater is part of the space heating boiler, and plumbing codes allow, some plumbers install an automatic gas shutoff (such as the \"Watts 210\") in addition to a TPR valve. When the device senses that the temperature reaches , it shuts off the gas supply and prevents further heating. In addition, an expansion tank or exterior pressure relief valve must be installed to prevent pressure buildup in the plumbing from rupturing pipes, valves, or the water heater.\n\nScalding is a serious concern with any water heater. Human skin burns quickly at high temperature, in less than 5 seconds at , but much slower at — it takes a full minute for a second degree burn. Older people and children often receive serious scalds due to disabilities or slow reaction times. In the United States and elsewhere it is common practice to put a tempering valve on the outlet of the water heater. The result of mixing hot and cold water via a tempering valve is referred to as \"tempered water\".\n\nA tempering valve mixes enough cold water with the hot water from the heater to keep the outgoing water temperature fixed at a more moderate temperature, often set to . Without a tempering valve, reduction of the water heater's setpoint temperature is the most direct way to reduce scalding. However, for sanitation, hot water is needed at a temperature that can cause scalding. This may be accomplished by using a supplemental heater in an appliance that requires hotter water.\nMost residential dishwashing machines, for example, include an internal electric heating element for increasing the water temperature above that provided by a domestic water heater.\n\nTwo conflicting safety issues affect water heater temperature—the risk of scalding from excessively hot water greater than , and the risk of incubating bacteria colonies, particularly \"Legionella\", in water that is not hot enough to kill them. Both risks are potentially life-threatening and are balanced by setting the water heater's thermostat to . The European Guidelines for Control and Prevention of Travel Associated Legionnaires’ Disease recommend that hot water should be stored at and distributed so that a temperature of at least and preferably is achieved within one minute at points of use.\n\nIf there is a dishwasher without a booster heater, it may require a water temperature within a range of for optimum cleaning, but tempering valves set to no more than can be applied to faucets to avoid scalding. Tank temperatures above may produce limescale deposits, which could later harbor bacteria, in the water tank. Higher temperatures may also increase etching of glassware in the dishwasher.\n\nTank thermostats are not a reliable guide to the internal temperature of the tank. Gas-fired water tanks may have no temperature calibration shown. An electric thermostat shows the temperature at the elevation of the thermostat, but water lower in the tank can be considerably cooler. An outlet thermometer is a better indication of water temperature.\n\nIn the renewable energy industry (solar and heat pumps, in particular) the conflict between daily thermal Legionella control and high temperatures, which may drop system performance, is subject to heated debate. In a paper seeking a green exemption from normal Legionellosis safety standards, Europe's top CEN solar thermal technical committee TC 312 asserts that a 50% fall in performance would occur if solar water heating systems were heated to the base daily. However some solar simulator analysis work using Polysun 5 suggests that an 11% energy penalty is a more likely figure. Whatever the context, both energy efficiency and scalding safety requirements push in the direction of considerably lower water temperatures than the legionella pasteurization temperature of around .\n\nHowever, legionella can be safely and easily controlled with good design and engineering protocols. For instance raising the temperature of water heaters once a day or even once every few days to at the coldest part of the water heater for 30 minutes effectively controls legionella. In all cases and in particular energy efficient applications, Legionnaires' disease is more often than not the result of engineering design issues that do not take into consideration the impact of stratification or low flow.\n\nIt is also possible to control Legionella risks by chemical treatment of the water. This technique allows lower water temperatures to be maintained in the pipework without the associated Legionella risk. The benefit of lower pipe temperatures is that the heat loss rate is reduced and thus the energy consumption is reduced.\n\n"}
{"id": "37273576", "url": "https://en.wikipedia.org/wiki?curid=37273576", "title": "Well cementing", "text": "Well cementing\n\nWell cementing is the process of introducing cement to the annular space between the well-bore and casing or to the annular space between two successive casing strings.. Personnel who conduct this job are called \"Cementers\".\n\n\nCement is introduced into the well by means of a cementing head. It helps in pumping cement between the running of the top and bottom plugs.\n\nThe most important function of cementing is to achieve zonal isolation. Another purpose of cementing is to achieve a good cement-to-pipe bond. Too low an effective confining pressure may cause the cement to become ductile.\n\nFor cement, one thing to note is that there is no correlation between the shear and compressive strength. Another fact to note is that cement strength ranges between 1000 and 1800 psi, and for reservoir pressures > 1000 psi; this means that the pipe cement bond will fail first. This would lead to the development of micro-annuli along the pipe.\n\nA. 0–6000 ft used when special properties are not required.\n\nB. 0–6000 ft used when conditions require moderate to high sulfate resistance\n\nC. 0–6000 ft used when conditions require high early strength\n\nD. 6000–10000 ft used under moderately high temperatures and pressures\n\nE. 10000–14000 ft used under conditions of high temperatures and pressures\n\nF. 10000–16000 ft used under conditions of extremely high temperatures and pressures\n\nG. 0–8000 ft can be used with accelerators and retarders to cover a wide range of well depths and temperatures.\nH. 0–8000 ft can be used with accelerators and retarders to cover a wide range of well depths and temperatures.\nJ. 12000–16000 ft can be used under conditions of extremely high temperatures and pressures or can be mixed with accelerators and retarders to cover a range of well depth and temperatures.\n\nAPI cement grades A, B and C correspond to ASTM type I, II and III.\n\n\nGiven the multitude of cement parameters the best and most thorough and practical method of designing a cement blend is through laboratory testing.\n\nThe tests should be conducted on a sample that represents the cement to be used on the job site.\n\nThere are 8 general categories of additives.\n\n\nCan be added to shorten the setting time or to accelerate the hardening process.\n\nCalcium chloride, under the right conditions, tends to improve the compressive strength and significantly reduces the thickening and setting time. Used in concentrations of up to 4.0%. The mechanism of this process is debated, but there are four major theories put forward.\n\n\nCalcium chloride also produces a high amount of heat during hydration. This heat could accelerate the hydration process.\n\nThis heat causes the casing to expand and contract as it dissipates. The differing rates of expansion and contraction could result in the casing pulling away from the cement and lead to the formation of micro-annuli. It also has the ability to affect the cement rheology, the compressive strength development, produce shrinkage by 10–15%, increases the permeability with time, and lowers the sulphate resistance.\n\nThey work by one of 4 main theories;\n\n\nLignosulphonates: Wood pulp derived polymers. Effective in all Portland cements and added in concentrations of 0.1% to 1.5% BWOC. It absorbs into the C-S-H gel and causes a change of morphology to a more impermeable structure.\n\nHydroxycarboxylic Acids – They have hydroxyl carboxyl groups in their molecular structure. Below 93 °C they can cause over-retardation. They are efficient to a temperature of 150 °C. One acid used in citric acid with an effective concentration of 0.1% to 0.3% BWOC.\n\nSaccharide Compounds: sugars are excellent retarders of Portland cement. Such compounds are not commonly used due to the degree of retardation being very sensitive to variation of concentration. It also depends on the compound’s susceptibility to alkaline hydrolysis.\n\nCellulose Derivatives: Polysaccharides derived from wood or vegetable matter, and are stable to the alkali conditions of the cement slurry.\n\nOrganophosphates: Alkylene phosphonic acids.\n\nInorganic Compounds: \n\nReduce slurry density – reduces hydrostatic pressure during cementing. \nIncreases slurry yield – reduces the amount of cement required to produce a given volume.\n\nWater extenders – Allow/facilitate the addition of water to help extend the cement blend/slurry.\n\nLow-density aggregates – Materials with densities less than Portland cement (3.15 g/cm3)\n\nGaseous extenders – Nitrogen or air can be used to prepare foam.\n\nClays – Hydrous aluminum silicates. Most common is bentonite (85% mineral clay smectite). Can be used to obtain a cement of density 11.5 to 15.0 ppg, with concentrations up to 20%. Used with an API ratio of 5.3% water to 1.0% bentonite.\nBentonite – this is added in conjunction with additional water, used for specific weight control but makes poor cement.\n\nPozzolan – finely ground pumice of fly ash. Pozzolan costs very little, but does not achieve much weight reduction of the slurry.\n\nDiatomaceous earth – also requires additional water to be added. Properties are similar to those of bentonite.\n\nSilica – α quartz and condensed silica fume. α quartz is used to prevent strength retrogression in thermal wells. Silica fume (micro fume) is highly reactive, and is regarded as the most effective pozzolanic material available. The high surface area increases the water demand to get pumpable slurry. Such a mixture can produce a cement slurry as low as 11.0 ppg.\n\nNormal concentration = 15% BWOC but can be as high as 28% BWOC. Can sometimes be used to prevent annular fluid migration.\n\nExpanded Pearlite—Used to reduce the weight as water is added with its addition. Without bentonite the pearlite separates and floats to the upper part of the slurry. Can be used to achieve a slurry weight as low as 12.0ppg. Bentonite in concentrations of 2–4% is also added to prevent segregation of particles and slurry.\n\nGilsonite – Used to obtain slurry weights as low as 12.0ppg. In high concentrations, mixing is a problem.\n\nPowdered coal – Can be used to obtain a slurry with a density as low as 11.9ppg, 12.5–25 lbs per sack are usually added.\n\nUses latex additives to achieve fluid loss. Emulsion polymers are supplied as suspensions of polymer particles. They contain about 50% solids. Such particles can physically plug the pores in the filter cake.\n\nThey increase the viscosity of the aqueous phase and decrease the filter cake permeability.\n\nOrganic proteins (polypeptides). Not used above temperatures of 93 °C.\n\nNon-ionic synthetic polymers Can lower fluid loss rates from 500 ml/30 min to 20 ml/30 min.\n\nThere are also anionic synthetic polymers and cationic polymers.\n\nCan lower fluid loss rates from 500ml/30min to 20ml/30min.\n\nThere are also anionic synthetic polymers and cationic polymers.\n\nThe addition of materials that can physically bridge fractured or weak zones. E.g. gilsonite and cellophane flakes added in quantities of 0.125–0.500 lbs/sack.\n\nThese are cement slurries that upon entering the formation they begin the gel and eventually become self-supporting.\n\n\n"}
