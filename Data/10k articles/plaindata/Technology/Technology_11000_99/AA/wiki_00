{"id": "59052343", "url": "https://en.wikipedia.org/wiki?curid=59052343", "title": "2018 in technology and computing", "text": "2018 in technology and computing\n\nSignificant events that have occurred in 2018 in all fields of technology, including computing, robotics, electronics, as well as any other areas of technology as well, including any machines, devices, or other technological developments, occurrences, and items. \n\n\n"}
{"id": "52723433", "url": "https://en.wikipedia.org/wiki?curid=52723433", "title": "Air stripline", "text": "Air stripline\n\nAir stripline is a form of electrical planar transmission line whereby a conductor in the form of a thin metal strip is suspended between two ground planes. The idea is to make the dielectric essentially air. Mechanical support of the line may be a thin substrate, periodical insulated supports, or the device connectors and other electrical items.\n\nAir stripline is most commonly used at microwave frequencies, especially in the C band. Its advantage over standard stripline and other planar technologies is that its air dielectric avoids dielectric loss. Many useful circuits can be constructed with air stripline and it is also easier to achieve strong coupling between components in this technology than with other planar formats. It was invented by Robert M. Barrett in the 1950s.\n\nAir stripline is a form of stripline using air as the dielectric material between the central conductor and the ground planes. Using air as the dielectric has the advantage that it avoids the transmission losses usually associated with dielectric materials.\n\nThere are two basic ways that air stripline is constructed. In dielectric supported stripline, also called suspended stripline or suspended substrate, the strip conductor is deposited on a thin solid dielectric substrate, sometimes on both sides and connected together to form a single conductor. This substrate is then clamped in place between the walls supporting the two ground planes. In this method the strip can be manufactured by printed circuit techniques making it cheap and leading to the further advantage that other components can be printed on the dielectric in the same operation. The purpose of the solid dielectric is mechanical support for the conductor, but it is made as thin as possible to minimise its electrical effect. The flimsy nature of the substrate means that it can easily be distorted. Because of this, the design needs to take account of thermal stability issues. High end designs may use a crystalline substrate, such as boron nitride or sapphire, as the suspended substrate.\n\nThe other method of construction uses a more substantial solid metal bar as the strip, supported on periodically spaced insulators. This method may be more suitable for high power applications. In such applications the corners of the conductor cross-section may be rounded to prevent high field intensities and arcing occurring at those points. The insulators are electrically undesirable; they detract from the goal of having a purely air dielectric, add discontinuities to the line, and are potentially a point at which tracking can occur. In some components, there are points at which the lines need to be grounded, either directly or through a discrete component. In such circuits these grounding points can double as mechanical supports and the need for supporting insulators avoided.\n\nAir stripline finds its greatest use at microwave frequencies in the C band (). At these frequencies and below it has the advantage of compactness over waveguide. Air stripline can be used outside the C band, but at the higher Ku band () waveguide tends to dominate because of its lower loss.\n\nAt microwave frequencies, passive circuits such as filters, power dividers and directional couplers tend to be constructed as distributed element circuits. These circuits can be constructed using any transmission line format. The coaxial line format commonly used for interconnecting devices has been used for this kind of device construction but is not the most convenient format for manufacturing. Stripline was developed as a better solution for circuit construction and air stripline too fills this role. Air stripline is particularly useful in the C band for creating beam forming networks from these components.\n\nAir stripline can achieve strong indirect coupling in these components more easily than other planar formats. In standard stripline, coupling is usually achieved by running the lines side-by-side for a distance. Coupling between the edges of the lines in this way is relatively weak and is limited by the closest distance the lines can be set together. This limit is governed by the maximum resolution of the printing process and, in power applications, by the electric field strength between the lines. For this reason, stripline parallel coupled lines are used in directional couplers with a coupling factor no more than . Power splitters, with their coupling factor , use a direct coupling technique. Air stripline makes use of an alternative arrangement, with lines stacked one atop of the other. This \"broadside coupling\" is much stronger than edge coupling so the lines do not need to be so close to achieve the same coupling factor. In dielectric supported stripline, this can be achieved by printing the two lines on opposite sides of the dielectric. Broadside coupling can, of course, be achieved in solid dielectric filled stripline as well with buried line techniques, but that requires additional dielectric layers and additional manufacturing processes. Another technique available to air stripline to increase coupling is the use of thick rectangular strips to increase side coupling. This also makes mechanical support easier because the lines are more rigid.\n\nStripline was invented by Robert M Barrett of the US Air Force Cambridge Research Center in the early 1950s. Air stripline under the registered mark \"Stripline\" was first manufactured commercially by Airborne Instruments Laboratory (AIL) in the form of suspended stripline. However, \"stripline\" has since become a generic term for that structure with any dielectric. The unadorned term \"stripline\" would now likely be assumed to mean stripline with a solid dielectric. Early on, stripline was the planar technology of choice, but has now been superseded by microstrip for most general purpose applications, especially mass-produced items.\n\n"}
{"id": "9206763", "url": "https://en.wikipedia.org/wiki?curid=9206763", "title": "American Dairy Science Association", "text": "American Dairy Science Association\n\nThe American Dairy Science Association (ADSA) is a non-profit professional organization for the advancement of dairy science. ADSA is headquartered in Champaign, Illinois.\n\nConsisting of 4500 members, ADSA is involved in research, education, and industry relations. Areas of ADSA focus include:\n\nADSA's top priorities are the \"Journal of Dairy Science\", annual meetings, scientific liaisons with other organizations and agencies, and international development. ADSA is attempting to add value to potential new members through an emphasis on \"integration of dairy disciplines from the farm to the table.\"\n\nIn the summer of 1905, the Graduate School of Agriculture was held at Ohio State University. Professor Wilber J. Fraser of the University of Illinois at Urbana-Champaign suggested a permanent \"Dairy Instructors and Investigators Association\". Attendees decided that Professor Fraser should discuss the matter further with university leaders and, if enough interest was indicated, call an organizational meeting at the 1906 Graduate School of Agriculture to be held at the University of Illinois, Urbana. Apparently, sufficient interest was raised, because Professor Fraser called interested parties to attend an inaugural meeting on July 17, 1906. Although 19 persons appear on the photograph of that first meeting, records indicate only 17 or 18 charter members joined what was then called \"National Association of Dairy Instructors and Investigators\". At this time, dairy schools existed at Cornell, Iowa State, Wisconsin, Purdue, Penn State, Ohio State, Missouri, Minnesota, Guelph (Ontario), and Illinois.\n\nThe second meeting was at the National Dairy Show in Chicago on 11 Oct 1907. Only 11 members were present when the meeting was called to order and 21 attended the banquet. At this meeting, the name of the organization changed to \"Official Dairy Instructors Association\".\n\nThe third meeting, held July 22 and 23, 1908 at Cornell University, was a significant success. 69 persons from Canada, 26 states, and the District of Columbia attended. By this time, the committees had become cohesive engines of change, developing score cards for consistently evaluating dairies and rules for judging contests.\n\nAt the 10th annual joint meeting in Amherst and Springfield, Massachusetts, on October 17, 1916, the organization voted to change its name to its current name. The name change was effective May 1, 1917.\n\nADSA's scientific journal is the \"Journal of Dairy Science\" (\"JDS\"). Volume I, Number 1 appeared on May 1, 1917 (also the effective birth date of the association's current name). Initially publishing bimonthly, \"JDS\" began monthly publication in 1934 and remains so today. \"JDS\" is among the top 5 most-cited scientific journals in the agriculture category.\n\nBy 1945, ADSA had 1,407 members. By 1985, ADSA had 3,000 members in 50 countries, owned a headquarters building with a staff of 19, provided management services for 6 other organizations, and published the Journal of Dairy Science and 5 journals for other organizations. FASS Inc., which was founded in 1998, currently provides association management services to ADSA and other clients. \n\nFrom 1927 to 1997, ADSA held its annual meetings on college campuses. Since 1998, ADSA has held its annual meetings in convention centers.\n\nFormer presidents of the association include:\n\n\n\n"}
{"id": "23125145", "url": "https://en.wikipedia.org/wiki?curid=23125145", "title": "Ammonium azide", "text": "Ammonium azide\n\nAmmonium azide is the chemical compound with the formula NHN, being the salt of ammonia and hydrazoic acid. Like other inorganic azides, this colourless crystalline salt is a powerful explosive, although it has a remarkably low sensitivity. NHN is physiologically active and inhalation of small amounts causes headaches and palpitations. It was first obtained by Theodor Curtius in 1890, along with other azides.\n\nAmmonium azide is ionic. Ammonium azide contains about 93% nitrogen by weight as ammonium cation and azide anion. It is a structural isomer of tetrazene.\n\n"}
{"id": "1864056", "url": "https://en.wikipedia.org/wiki?curid=1864056", "title": "Aracruz Celulose", "text": "Aracruz Celulose\n\nAracruz Celulose S.A. was a Brazilian manufacturer of pulp and paper. In 2009 the company merged with VCP and renamed Fibria. The new company maintained its headquarters in Sao Paulo, and is a supplier of bleached eucalyptus pulp. The current presidents are members of the Hungarian family, Ersching.\n\nThe company has two pulp making plants, one in Aracruz city in Espírito Santo state and the other at Guaíba in the state of Rio Grande do Sul. It also has forestry operations in these states as well as in the states of Bahia and Minas Gerais.\n\nThe major shareholders control the company's voting shares: the Votorantim and BNDES, the Brazilian National Economic and Social Development Bank. ARACRUZ's preferred shares, which constitute over half the company's total outstanding shares, are traded on the São Paulo (Bovespa), New York and Madrid stock exchanges. These remain the two shareholders of Fibria.\n\nThe company was listed on the Stock Exchange of Sao Paulo, New York City and Madrid and now as Fibria remains on the BM&F Bovespa stock exchange of Sao Paulo.\n\n\n"}
{"id": "31196402", "url": "https://en.wikipedia.org/wiki?curid=31196402", "title": "Biopreservation", "text": "Biopreservation\n\nBiopreservation is the use of natural or controlled microbiota or antimicrobials as a way of preserving food and extending its shelf life. The biopreservation of food, especially utilizing lactic acid bacteria (LAB) that are inhibitory to food spoilage microbes, has been practiced since early ages, at first unconsciously but eventually with an increasingly robust scientific foundation. Beneficial bacteria or the fermentation products produced by these bacteria are used in biopreservation to control spoilage and render pathogens inactive in food. There are a various modes of action through which microorganisms can interfere with the growth of others such as organic acid production, resulting in a reduction of pH and the antimicrobial activity of the un-dissociated acid molecules, a wide variety of small inhibitory molecules including hydrogen peroxide, etc. It is a benign ecological approach which is gaining increasing attention.\n\nOf special interest are lactic acid bacteria (LAB). Lactic acid bacteria have antagonistic properties which make them particularly useful as biopreservatives. When LABs compete for nutrients, their metabolites often include active antimicrobials such as lactic and acetic acid, hydrogen peroxide, and peptide bacteriocins. Some LABs produce the antimicrobial nisin which is a particularly effective preservative. \nThese days LAB bacteriocins are used as an integral part of hurdle technology. Using them in combination with other preservative techniques can effectively control spoilage bacteria and other pathogens, and can inhibit the activities of a wide spectrum of organisms, including inherently resistant Gram-negative bacteria.\" Lactic acid bacteria and\npropionibacteria have been extensively studies for their efficacy against spoilage causing yeasts and molds in food spoilage.\n\nIn addition to lactic acid bacteria, yeasts also have been reported to have a biopreservation effect due to their antagonistic activities relying on the competition for nutrients, production and tolerance of high concentrations of ethanol, as well as the synthesis of a large class of antimicrobial compounds exhibiting large spectrum of activity against food spoilage microorganisms, but also against plant, animal and human pathogen.\n\nA bacterium/yeast that is a suitable candidate for use as a biopreservative does not necessarily have to ferment the food. However, if conditions are suitable for microbial growth, then a biopreservative bacterium will compete well for nutrients with the spoilage and pathogenic bacteria in the food. As a product of its metabolism, it should also produce acids and other antimicrobial agents, particularly bacteriocins. Biopreservative bacteria, such as lactic acid bacteria, must be harmless to humans.\n\nBacteriophages (Greek for 'bacteria eater'), or simply phages, are viruses which infect bacteria. The majority of all bacteriophages known exhibit a double-stranded DNA genome inside the virion capsid and belong to the order of tailed phages, Caudovirales. The tailed phages can be further separated into three families: Podoviridae, which are characterized by very short tails; Myoviridae, which exhibit longer, straight and contractile tails; and Siphoviridae, which can be identified due to their long and flexible tails. Another well studied group of phages with many applications, although minor in terms of species diversity, is represented by filamentous phages which exhibit a single stranded DNA genome decorated by a helical protein layer surrounding the DNA molecule. Bacteriophages are ubiquitously distributed in nature and can also be isolated from human or animal associated microflora. They outnumber their bacterial host species by a factor of ten representing the most abundant self-replicating entities on earth with an estimated 1031 phages in total. The idea of using phages against unwanted bacteria developed shortly after their discovery. With the improvements in organic chemistry during the 1950s, exploration and development of broad spectrum antibiotics displaced interest in bacteriophage research. Several laboratories have been testing suitability of bacteriophage isolates to control certain bacterial pathogens. Significant advancements in this research have been made at the Bacteriophage Institute in Tbilisi, Georgia, where phage therapy is routinely applied in medicine research field. Today treatment of antibiotic resistant bacteria is a challenging task. Recently, research on bacteriophages has gained additional momentum in light of the identification of antibiotic-resistant pathogens of infectious diseases, wherein the application of antibiotics is not effectively working, therefore research on the application of bacteriophages is being reviewed intensely.\nBacteriophages have recently received a generally recognized as safe status based on their lack of toxicity and other detrimental effects to human health for application in meat products in USA.\n\nPhage preparations specific for \"L. monocytogenes,\" \"E. coli\" O157:H7, and \"S. enterica\" serotypes have been commercialized and approved for application in foods or as part of surface decontamination protocols.\n\nIn meat processing, biopreservation has been extensively studied in fermented meat products and ready to eat meat products. The use of native or artificially-introduced microbial population to improve animal health and productivity, and/or to reduce pathogenic organisms, has been termed a probiotic or competitive enhancement approach. Competitive enhancement strategies that have been developed include competitive exclusion, addition of a microbial supplement (probiotic) that improves gastrointestinal health, and adding a limiting, non-host digestible nutrient (prebiotic) that provides an existing (or introduced) commensal microbial population a competitive advantage in the gastrointestinal tract. Each of these approaches utilizes the activities of the native microbial ecosystem against pathogens by capitalizing on the natural microbial competition. Generally speaking, competitive enhancement strategies offer a natural 'green' method to reduce pathogens in the gut of food animals.\n\nFishery products are a source of wide variety of valuable nutrients such as proteins, vitamins, minerals, omega-3 fatty acids, taurine, etc. Fishery products, however, are also associated with human intoxication and infection. Approximately 10 to 20% of food-borne illnesses are attributed to fish consumption. Changing consumer demand has driven the appeal of traditional processes applied to seafood (e.g. salting, smoking and canning) lower compared to mild technologies involving lower salt content, lower cooking temperature and vacuum packing (VP)/modified atmosphere packing (MAP). These products, designed as lightly preserved fish products (LPFP), are usually produced from fresh seafood and further processing increases risk of cross contamination. These milder treatments are usually not sufficient to destroy microorganisms, and in some cases psychrotolerant pathogenic and spoilage bacteria can develop during the extended shelf-life of LPFP. Many of these products are also eaten raw, so minimizing the presence and preventing growth of microorganisms is essential for the food quality and safety. \nThe microbial safety and stability of food are based on an application of preservative factors called hurdles. The delicate texture and flavor of seafood are very sensitive to the decontamination technologies such as cooking, and more recent mild technologies such as pulsed light, high pressure, ozone, and ultrasound. Chemical preservatives, which are not processes but ingredients, are out of favor with consumers due to natural preservatives demand. An alternative solution that is gaining more and more attention is biopreservation technology. In fish processing, biopreservation is achieved by adding antimicrobials or by increasing the acidity of the fish muscle. Most bacteria stop multiplying when the pH is less than 4.5. Traditionally, acidity has been increased by fermentation, marination or by directly adding acetic, citric or lactic acid to food products. Other preservatives include nitrites, sulphites, sorbates, benzoates and essential oils. The main reason for less documented studies for application of protective microorganisms, bacteriophages or bacteriocins on seafood products for biopreservation compared to dairy or meat products is probably that the early stages of biopreservation have occurred mainly in fermented foodstuffs that are not so developed among seafood products. The selection of potential protective bacteria in seafood products is challenging due to the fact that they need adaptation to the seafood matrix (poor in sugar and their metabolic activities should not change the initial characteristics of the product, i.e. by acidification, and not induce spoilage that could lead to a sensory rejection. Among the microbiota identified in fresh or processed seafood, LAB remains the category that offers the highest potential for direct application as a bioprotective culture or for bacteriocin production.\n\nThere has been successful implementation of various phage preparation around the globe. Various applications/delivery methods in food have been developed. Bacteriophages and their endolysins can be incorporated into food systems in several ways such as spraying, dipping or immobilization, singly or in combination with other hurdles. The phage preparation LMP-1O2 has been subsequently commercialized as \"ListShield\" Intralyx, Inc. It has been shown to be effective against 170 different strains of \"L. monocytogenes\", reducing significantly (10 to 1000-fold) the Listeria contamination when sprayed onto ready-to-eat foods, without changing the food general composition, taste, odor or color.\nThe Intralytix company has also commercialized phage-based antimicrobial preparations like SalmoFresh and SalmoLyse for controlling \"S. enterica\". SalmoFresh is prepared with a cocktail of naturally occurring lytic bacteriophages that selectively and specifically kill Salmonella, including strains belonging to the most common/highly pathogenic serotypes Typhimurium, Enteritidis, Heidelberg, Newport, Hadar, Kentucky and Thompson. According to the manufacturer, SalmoFresh is specifically designed for treating foods that are at high risk for \"Salmonella\" contamination. In particular, red meat and poultry can be treated prior to grinding for significant reductions in Salmonella contamination. SalmoLyse is a reformulated phage cocktail derived from SalmoFresh in which two of the six phages in the original cocktail have been replaced. Additional bacteriophage preparations have been formulated and referenced to be used to reduce the microbial load of animals prior to slaughter and are commercially available from Omnilytics such as the BacWash product line against Salmonella Omnilytics. Another commercial application has been developed, Listex_ P100 by Micreos in The Netherlands and was granted generally recognized as safe (GRAS) status by the FDA and USDA for use in all food products.\n\nAnother significant commercial bacteriophage application is ELICOSALI, a wide range of anti-\"Salmonella\" and \"E. coli\" phage cocktail, for treatment of agricultural products developed by Eliava Institute at Tbilisi, Republic of Georgia Eliava Institute.\n\nBiopreservation judiciously exploits the antimicrobial potential of naturally occurring microorganisms in food and/or their metabolites with a long history of safe use. Bacteriocins, bacteriophages and bacteriophage-encoded enzymes fall in this theory. The long and traditional role of Lactic acid bacteria on food and feed fermentations is the main factor related to the use of bacteriocins in biopreservation. LAB and their bacteriocins have been consumed unintentionally for ages, laying down a long history of safe use. Their antimicrobial spectrum of inhibition, bactericidal mode of action, relative tolerance to processing conditions (pH, NaCl, heat treatments) and the lack of toxicity towards eukaryotic cells enforces their role as biopreservatives in food. The evaluation of any new antimicrobial actives is done in meat by USDA which relies on the GRAS assessment by FDA among other suitability data.\n"}
{"id": "38753450", "url": "https://en.wikipedia.org/wiki?curid=38753450", "title": "COCOA (digital humanities)", "text": "COCOA (digital humanities)\n\nCOCOA was an early text file utility and associated file format for digital humanities, then known as humanities computing. It was approximately 4000 punched cards of FORTRAN and created in the late 1960s and early 1970s at University College London and the Atlas Computer Laboratory in Harwell, Oxfordshire. Functionality included word-counting and concordance building.\n\nThe Oxford Concordance Program (OCP) format was a direct descendent of COCOA developed at Oxford University. The Oxford Text Archive holds items in this format.\n\nThe COCOA file format bears at least a passing similarity to the later markup languages such as SGML and XML. A noticeable difference with its successors is that COCOA tags are flat and not tree structured. In that format, every information type and value encoded by a tag should be considered true until the same tag changes its value. Members of the Text Encoding Initiative community maintain legacy support for COCOA, although most in-demand texts and corpora have already been migrated to more widely understand formats such as TEI XML\n"}
{"id": "12749473", "url": "https://en.wikipedia.org/wiki?curid=12749473", "title": "CandyFab", "text": "CandyFab\n\nThe CandyFab is a method of producing physical objects out of a computer representation of the structure. It differs from some other 3D printing methods in the following aspects:\n\n\nThe CandyFab uses a heat source mounted on a computer-controlled X-Y positioning head to fuse the surface of a granular bed of the print media. The only thing which comes into contact with the media is heated air, which is turned on and off by the software synchronously with the motion of the positioning head. Fabrication of the shape of the part being produced progresses in layers; after each complete pass, the bed is lowered and a fresh layer of granular media is applied on top. The unfused media serves to support overhangs and thin walls in the part being produced, reducing the need for auxiliary temporary supports for the workpiece. The movable bed is of a size suitable for producing finished parts several kilograms in weight.\n\nThe resolution of features produced correspond to a smallest volume element of 2.5 x 2.5 x 2.7 mm or less. Pieces produced from ordinary granular sugar have fairly good strength and feature an amber to brown surface color owing to caramelization of the sugar. Special attention has been paid to the selection of all materials coming into contact with the sugar bed or with the hot air stream to make it possible to fabricate food-grade pieces if desired.\n\nThere is an effort to encourage further work on improving the technology in the following areas:\n\n\nIn addition, the inventors Windell Oskay and Lenore Edman of candyfab.org have organized teams to explore applications, gastronomy, and post processing.\n\nSeveral large pieces of sculpture have been produced using the CandyFab, including one of a mathematical object designed by sculptor Bathsheba Grossman. This and other pieces were shown by inventors Windell Oskay and Lenore Edman of candyfab.org at the Bay Area Maker Faire 2007. \n\n\n"}
{"id": "100515", "url": "https://en.wikipedia.org/wiki?curid=100515", "title": "Carl Wilhelm Siemens", "text": "Carl Wilhelm Siemens\n\nSir Charles William Siemens FRSA (originally Carl Wilhelm Siemens; 4 April 1823 – 19 November 1883) was a German-born engineer and entrepreneur who for most of his life worked in Britain and later became a British subject.\n\nSiemens was born in the village of Lenthe, today part of Gehrden, near Hanover where his father, Christian Ferdinand Siemens (31 July 1787 – 16 January 1840), a tenant farmer, farmed an estate belonging to the Crown. The Siemens family is an old family of Goslar which has been documented since 1384. His mother was Eleonore Deichmann (1792–8 July 1839), and William, or Carl Wilhelm, was the fourth son of a family of fourteen children. Of his siblings, Ernst Werner Siemens, the fourth child, became a famous electrician and was associated with William in many of his inventions. He was also the brother of Carl Heinrich von Siemens and a cousin of Alexander Siemens.\n\nOn 23 July 1859, Siemens was married at St James's, Paddington, to Anne Gordon, the youngest daughter of Mr Joseph Gordon, Writer to the Signet, Edinburgh, and brother to Mr Lewis Gordon, Professor of Engineering in the University of Glasgow and became a naturalised British subject. He used to say that on 19 March of that year he took oath and allegiance to two ladies in one day – to The Queen and to his betrothed. He was knighted – becoming Sir William – a few months before his death. He died on the evening of Monday 19 November 1883, at nine o'clock and was buried on Monday 26 November, in Kensal Green Cemetery, London. A glass window installed in Westminster Abbey in his honour commemorated him.\n\nIn the autumn of 1838 when William was fifteen years old, he began his studies to become an engineer. He attended a highly respected School of Trade and Commerce, the \"Gewerbe-Schule Magdeburg\". William had a particularly close relationship with his eldest brother; Ernst Werner Siemens had decided to teach William mathematics so that he could learn English at school instead. This programme helped them both and William's knowledge of English proved an incalculable advantage to them both. He went on to pass his examination easily. Less than a year later, their mother died and their father soon afterwards in 1840.\n\nOnce William had completed his course at the Magdeburg school he went on to the University of Göttingen where he attended lectures on physical geography and technology, high mathematics, theoretical chemistry and practical chemistry and physics. He was also able for a short time to work with Wilhelm Weber, the renowned scientist and inventor, in his Magnetic Observatory.\n\nWilliam was nearly nineteen when he left university to become an apprentice engineer. He also found time for more artistic pursuits such as taking dancing lessons and even painting a landscape of Nordhausen for the wife of the factory manager. His progress in the engineering factory was so rapid that his two-year apprenticeship was cut down to one.\n\nDue to the education of the younger members of the family becoming a financial worry, on 10 March 1843, Carl Wilhelm Siemens left for London. He was acting as an agent for his brother Werner, and he hoped to earn enough money by selling a patent in England to help support and educate his many brothers and sisters. He felt a keen desire to see England and the journey cost him £1. William had already shown himself to be an enthusiastic businessman, having financed his trip by selling an invention of his brother's, an improvement to the gold and silver plating process, to George Richards Elkington. He was well aware, as he wrote to Werner, that his visit might achieve nothing, but if all went well he intended to remain. This indeed proved to be the case.\n\nSiemens had been trained as a mechanical engineer, and his most important work at this early stage was non-electrical; the greatest achievement of his life, the regenerative furnace. Though in 1847 he published a paper in Liebig's \"Annalen der Chemie\" on the 'Mercaptan of Selenium,' his mind was busy with the new ideas upon the nature of heat which were promulgated by Carnot, Clapeyron, Joule, Clausius, Mayer, Thomson, and Rankine. He discarded the older notions of heat as a substance, and accepted it as a form of energy. Working on this new line of thought, which gave him an advantage over other inventors of his time, he made his first attempt to economise heat, by constructing, in 1847, at the factory of John Hick, of Bolton, an engine of four horse-power, having a condenser provided with regenerators, and using superheated steam. Two years later he continued his experiments at the works of Messrs. Fox, Henderson, and Co., of Smethwick, near Birmingham, who had taken the matter in hand. The use of superheated steam was attended with many practical difficulties, and the invention was not entirely successful; nevertheless, the Society of Arts, in 1850, acknowledged the value of the principle, by awarding Siemens a gold medal for his regenerative condenser.\n\nIn 1850 he established the London sales office of Siemens & Halske, the engineering company producing telegraphs, which his brother Werner had founded in 1847 at Berlin. He started selling such devices to the wire rope producer \"R. S. Newall & Co\" in Dundee, of which his friend (and uncle of his later wife) Lewis Gordon was the co-owner. Newall & Co also outsourced test jobs for cables to Siemens and such enabled the new company to enter the ocean cable-laying business. The branch office became Siemens Brothers in 1858. In the 1850s, the company was involved in building long distance telegraph networks in Russia. In 1855, a company branch headed by another brother, Carl Heinrich von Siemens, opened in St Petersburg, Russia. By 1863, Sir William had his own cable factory built at Charlton, London. In 1867, Siemens completed the monumental Indo-European (Calcutta to London) telegraph line.\n\nIn 1859 William Siemens devoted a great part of his time to electrical invention and research; and the number of telegraph apparatus of all sorts – telegraph cables, land lines, and their accessories – which have emanated from the Siemens Telegraph Works (at Charlton, SE London) has been remarkable. In 1872 Sir William Siemens became the first President of the Society of Telegraph Engineers which became the Institution of Electrical Engineers, the forerunner of the Institution of Engineering and Technology \nIn 1860 William Siemens constructed a remarkable gas engine (the same year the very first commercial engine was produced by Lenoir). It didn't get beyond the experimental stage, though its principle of operation (described in Siemens British patent 2074 of 1860, and by Siemens in \"The Theory of the Gas Engine\") appears to be similar to the commercially successful Brayton engine of 1872. In the discussion section of \"The Theory of the Gas Engine\" Siemens discloses that :\n\"The engine promised to give very good results, but about the same time he began to give his attention to the production of intense heat in furnaces, and having to make his choice between the two subjects, he selected the furnace and the metallurgic process leading out of it ; and that was why the engine had remained where it was for so long a time.\"\n\nSiemens was also responsible for the hot tube ignition system used on many of the early gas engines.\n\nIn June 1862 he was elected a Fellow of the Royal Society and in 1871 delivered their Bakerian Lecture.\n\nThe regenerative furnace is the greatest single invention of Charles William Siemens, using a process known as the Siemens-Martin process. The electric pyrometer, which is perhaps the most elegant and original of all William Siemens's inventions, is also the link which connects his electrical with his metallurgical researches. Siemens pursued two major themes in his inventive efforts, one based upon the science of heat, the other based upon the science of electricity; and the electric thermometer was, as it were, a delicate cross-coupling which connected both. \nIn 1874 he had a special cable ship built, according to his design, for \"Siemens Brothers\", the CS \"Faraday\". In 1881, a Siemens AC Alternator driven by a watermill was used to power the world's first electric street lighting in the town of Godalming, United Kingdom.\n\n\n\n"}
{"id": "28320473", "url": "https://en.wikipedia.org/wiki?curid=28320473", "title": "Casing cutter", "text": "Casing cutter\n\nA Casing-Cutter is a device used in petroleum industry to cut a complete section of a casing, a liner or all others tubular components in a well bore.\nThis cutting tool is composed by several cutting blades (reinforced with Tungsten carbide) pivotally mounted on support body.\nDuring cutting operations, the cutting blades are gradually deployed outside the support body by hydraulic pressure or mechanical action\n\n\n"}
{"id": "3078218", "url": "https://en.wikipedia.org/wiki?curid=3078218", "title": "Castellane", "text": "Castellane\n\nCastellane (; Provençal: \"Castelana\") is a commune in the Alpes-de-Haute-Provence department in southeastern France. With about 1,600 inhabitants, Castellane has the distinction of being the least-populated sub-prefecture of France.\n\nIts inhabitants are referred to as \"Castellanais\".\n\nCastellane is a very old city located upstream of the Gorges du Verdon. The city is above sea level.\n\nThe Roc, or the Roc of Notre-Dame, overlooks the city from above. It has been occupied since the High Middle Ages and is a registered historical site. It can be accessed from the centre of town behind the old Church of St. Andrew. The walk takes about 25 minutes.\n\nTwo reservoirs are located in the territory of Castellane:\nThe area has two water gaps: \n\nThe GR 4 hiking trail crosses through the town. The neighboring municipalities are:\n\nThe commune is part of the Jurassic limestone area of the French Prealps in Provence, formed by the tectonic upheaval of the Alps during the Tertiary. Limestone deposits run the length of the Verdon river, giving rise to spectacular gorges formed through karst erosion. Around Castellane older formations surface, such as gypsum and Triassic black marl.\n\nNeighboring mountains and passes\n\nThe commune contains of wood and forests (about 59% of its surface area). The extends over the western part of the commune (former communes of Taulanne, Chasteuil and Villars-Brandis).\n\nCastellane's name appeared in texts for the first time circa 965-977 as \"Petra Castellana\". The name breaks down into three Occitan terms, \"pèira\", \"castel\" and the suffix \"-ana,\" which means fortified rock and village, and could be translated as \"Castellane rock\", in other words, the rock that has a fortified village, or simply the stronghouse or stronghold. Castellane is called \"Castelana\" in the Provençal dialect in the classical norm, or \"Castelano\" in the Mistralian.\n\nThe former commune of Castillon, now beneath the lake, appeared around 1300 as \"de Castilhone\", an Occitan word for a small castle.\n\nThe first part of the name \"Chasteuil\" is obscure, but the second, \"-ialo\", is a Celtic suffix for \"clearing\".\n\nThe village of \"Robion\" has the same name as the river that and flows through it into the and takes its source from the Massif du Robion to the east of the village. The name \"in Rubione\", which first appeared for it in 1045, is derived from the vulgar Latin \"robigonem\", a distortion of the classical Latin \"robiginem\" for rust, according to Ernest Nègre. Charles Rostaing, on the other hand, believed that the name might predate the Gauls and designate a steep-sided ravine.\n\n, was first mentioned in 1095 when the château of Taloire was given to the Abbey of St. Victor, Marseille, which became the lay \"seigneur\" of the fief. It derived its name from the Occitan \"\", meaning soldiers especially recruited to devastate the land of an adversary. Adding the -ia suffix designates, either a land inhabited by these devastators, or a land devastated by the \"taladors\". Rostaing thought this name also probably also predated the Gauls. noted a tautology: *Tal- et *Tor-, the \"teo\" roots. The name \"Taloire\" contains two terms designating a mountain.\n\nIn 2009, the unemployment rate of the Castellane population was 12.4%, and there were 45 businesses in the secondary sector, with 84 paid workers.\n\nThe inhabitants of Castellane are known back to a very early date. Neolithic nomads came through the area; the oldest traces date back to 6000 BC. A grotto with cave paintings exists in the commune but its location is kept confidential to protect the artwork; Bronze Age tombs have also been discovered in a cave in Castillon. Ligurian tribes occupied the territory. The Suetrii or Suètres later created an \"oppidum\" named \"Ducelia\", near the Roc. They mined salt in the area and sold it. Most of the communes attached to Castellane today were peopled by the Suetrii. Taulanne was the exception, inhabited by the people who had their capital in Senez. (Their name is uncertain and Roman historians differ on the subject.)\n\nThe region was conquered by Augustus in 14 BC. Castellane was attached to the Roman province of Alpes-Maritimes and began to grow. Homes were established in the plain, and the city was named \"Civitas Saliniensum\" (city of salt merchants). The name of the town later became Salinae.\n\nSeveral roads left from or passed through the town:\n\nResidents first settled on the bank of the Verdon to mine the saline sources which are still visible today. A treasure of antiquity, 34 gold coins issued by Arcadius and Honorius, were discovered in 1797 in Taloire. A limestone funerary stele for one Julius Trofimus, dating back to Roman times, was discovered near the old chapel of Notre-Dame-du-Plan. Until 1942 it was used in a retaining wall, and can be found today in the public garden of the savings bank. The inscription is included in the (ILGN) collection of Gallia Narbonensis Roman inscriptions and is listed on the historic register.\n\nA diocese was founded in the fifth century: its seat was transferred to Senez before the 6th century however and despite all attempts to have it return to Castellan it remained there until it was closed in the French Revolution.\n\nIn the early ninth century, the area around the current town of Castellane was inhabited by only 84 people.In 812 the area was invaded by Moors, also sometimes called Saracens; they destroyed \"Salines\", the early settlement near the salt marshes. The inhabitants of Salines took refuge on the summit of the Roc and built a stronghold there, building the first Notre-Dame there, inaugurated in 852, in thanks for the refuge. Some vestiges of this site, which was named \"Sinaca\" in 813 and \"Petra Castellana\" in 965, are still visible at the place now known as \"Le Signal\". People later also settled at the foot of the Roc in the valley bottom.\n\nIn 852 a lord of Castellane, possibly named Guillaume won a victory against the Moors and put together a barony of 46 village communities stretching from Cotignac in Var to the south, to Thorame-Haute in the north, and from Soleilhas to Esparron-de-Verdon. Over time Castellane came to have three co-existing sites:\n\nIn 1189, Baron de Castellane Boniface III was attacked by Alfonso I of Provence. He had refused to do homage, explaining that he was a vassal of the Holy Roman Empire. But in the face of brute force he was forced to bend the knee. Another war broke out in 1227 between the Provence and Boniface of Castellane, presumably the son. In 1257 Charles II—then still just prince of Salernes, gave the castle to the Austinian monks. In 1262, Charles I of Anjou defeated Boniface of Castellane and made Castelle the seat of a . In the thirteenth century, the family of Castellane lost possession of the city to the Counts of Provence. To protect themselves from attack, in addition to the protections for the city, Castellane built a series of fortified outposts at Demandolx, La Garde, , Rougon, and perhaps Taloire. In 1300 a small Jewish community of eight households was established in the area.\n\nThe Black Death reached Castellane in 1348, and was followed by a devastating flood of the Verdon River. The capture and death of Queen Joanna I of Naples created a succession issue in the county of Provence, the cities of the Union of Aix (1382-1387) supporting Charles de Duras against Louis I of Anjou.\n\nLord of Castellane Louis d'Anduse, also often known as Lord of La Voulte, sided with the Duke of Anjou from the spring of 1382, supporting him on condition he participate in an expedition to rescue the queen. Castellane itself initially also backed the Duke, but changed allegiance in February 1386 after the Duke died, and rallied to the cause of the queen-regent, Marie de Blois. She negotiated with them, hoping to set off a chain of similar declarations of support. Guillaume de Forcalquier and his son Jean Raynaut, lords of Eoulx, submitted to the Duchess in July 1386. In 1390, ravaged the surrounding territory and the village of Taulanne and failed to take the city, but did destroy the wooden bridge over the Verdon River.\n\nThe wooden bridge over the Verdon was rebuilt in stone in the 15th century. A monastery took care of its maintenance. The bridge on the Place Castellane put Castellane on the frequently travelled routes between the Mediterranean and the bridge over the Durance river at Sisteron. The bridge toll for the Verdon and the fair began at the end of the Middle Ages. The fair continued until the end of the \"Ancien Régime\", assuring the town relative prosperity.\n\nIn the fifteenth century, a community settled on the present site of Taloire. In the middle of the fifteenth century, the upper village was completely abandoned in favor of the lowland site.\n\nAt the end of the Middle Ages, the transhumance system developed enormously, herds of sheep from the coast going up into the high Alpine valleys in the summer. Some \"drailles\" (herding routes) crossed the Castellane bridge, where a toll was instituted. At the beginning of the 16th century, between 78,000 and 120,000 head were crossing each year during May and June.\n\nThe imperial army of Charles V pillaged the town en 1536.\n\nReligious unrest broke out in 1559. Brun de Caille had converted some of the townspeople of Castellane, who gathered at his home for services. A sectarian skirmish took place at his home. Huguenot captain , of another rich Protestant family, sacked the town in the summer of 1560, then established himself there after reaching an armistice with the governor of Provence, the count of Tende, Claude of Savoy. The town was attacked by Protestants on 4 October 1574, but the residents of Castellane and its surroundings chased them off, pursuing them as far as the \"clue de Taulanne\".\nOn 30 January 1586, the and the Duke of Lesdiguières tried to surprise the town. The sneak attack was repulsed and the Baron d'Allemagne was injured by a bullet in his back, which caused the assailants to retreat. The Baron was killed in September of that year trying to lift the siege of his own castle, shot in the head by an arquebus.\nThe end of the siege of Castellane has since been celebrated every year in the last weekend of January with the \"Pétardiers\" ceremony reenacting the attack, and notably the episode of Judith André or Andrau, the goodwife of Barrême, who killed \"pétardier\" captain Jean Motte by pouring a kettle of boiling peas over him from the top of the \"porte de l'Annonciade\", reputed to be the weak point in the defenses.\ns1z\n\nThe plague struck the town again in 1630.\n\nThe Jansenist bishop Jean Soanen tried to make the celebrations of Saint-Sacrement, Saint-Jean and Saint-Éloi more sedate and less unbridled, the youth of the town having a tradition of celebrating with drums, music and gunshots. The youth refused, resisted, made even more noise and even revolted, preventing the procession of the octave du Saint-Sacrement from leaving the church on June 22, 1710. In 1726 the youth of Robion, whom the priest wanted to prevent from dancing on Sunday, also revolted.\n\nThe Austrian-Sardinian army briefly occupied the town in 1746 during the war of the Austrian Succession. In December 1746, Provence was invaded by an Austrian-Sardinian army. A troop of 2,000 men took Castellane, then the surrounding villages, as far as the château of Trigance. After some difficulty, the Spanish and French armies coordinated a counteroffensive, which began at the start of January when French soldiers under the orders of the Count of Maulévrier took an Austrian outpost in Chasteuil. The Austrian commander, Maximilian Ulysses Browne, reinforced his right wing with four battalions garrisoned at Castellane, and six on the south bank of the Verdon. Seven other battalions formed a second available squadron. Nine battalions and ten squads of Spaniards were stationed in Riez and 2,500 Swiss paid by Spain were stationed at Senez. The 21st of January, Hispano-French troops went on the offensive, commanded by the Frenchman Maulévrier and the Spanish Marquis of Taubin. The Spanish left their quarters by night and advanced on Castellane through the \"clue de Taulanne\", while the French passing through the Vodon gorge. The difficult marches necessary to approach in this way nonetheless allowed a coordinated attack around 7am.\n\nThe first outposts were taken without difficulty, which allowed Maulévrier to connect on his left with Taubin, and to send a column of dragoons onto the right bank to cut the Austrians' retreat. This assault took the Austrian-Sardinians fortifications without difficulty, the French-Spanish entered the town and did prevent the last Austrians from retreating. In all, they took 287 Austrians prisoner, including the baron de Neuhaus, the lieutenant-general in command. The Austrian-Sardinians also had a hundred-odd dead, versus twenty Franco-Spanish soldiers. The villages of La Garde, Eoulx, Robion, Taloire, Trigance and Comps were evacuated on January 22.\n\nIn 1760, a tax imposed by the king of Piedmont-Sardinia on sales of cloth brought a large reduction in the town's textile production. Production of , a local form of wool, and of \"cordeillat\", a coarse woolen fabric, continued until the Revolution, and was used by the local residents.\n\nUntil the Revolution salt was produced from two local salt marshes.\n\nOn the eve of the French Revolution, several fiefs existed on the actual territory of the commune: Éoulx, Le Castellet-de-Robion (which became a barony in 1755), Chasteuil, Taulanne and Castillon, plus Castellane. On the same territory there were nine parishes: Castillon, La Baume, Taulanne, La Palud, Chasteuil, Taloire, Villars-Brandis, Robion, et Castellane. The parish of Éoulx overlapped the community of La Garde.\n\nThe city of Castellane alone paid more tax than Digne; it was an important rural town, both for its judiciary functions (with eight lawyers and five prosecutors) and for its production, with twelve factories: among which were six hat shops, two wax factories, one faïence works, one tile factory, one silk fabrication works, and the leather industry was also represented. A royal post office was also installed in Castellane near the end of the \"Ancien Régime\".\n\nThe cloth industry, already well established in the preceding century, prospered in the first half of the 19th century. But cottage industries were replaced by the Barneaud factory, built in the late 1830s on the model of the Honnorat factory in Saint-André-de-Méouilles. It employed nine workers in 1872, then disappeared in 1878.\n\nThe Revolution and the Empire brought social reforms, including proportional taxation based on the assets. In order to put this in place on a precise basis, a land registry was drawn up. The \"loi de finances du 15 septembre 1807\" specified its methods, but its accomplishment took time to get started, since the officials conducting the \"cadastre\" dealt with the \"communes\" in successive geographic groups. Not until 1834-1835 was the land registry known as the Napoleonic cadastre of Castellane and its associated communes finished.\n\nThe coup d'état of 2 December 1851 committed by Louis-Napoléon Bonaparte against the Second Republic provoked an armed uprising in the Basses-Alpes in defense of the Constitution. Insurgent republicans took a number of cities in the center and south of France, including Digne, the prefecture of the Basses-Alpes, and held them for several days. The local fighters held out the longest, almost three weeks. But this allowed Bonaparte to portray himself as the protector of France, and many participants were sent to penal colonies in Lambesa and Cayenne, banished or less permanently exiled. Eight inhabitants of Castellane were brought before the \"commission mixte\"; their most common penalty was deportation to Algeria.\n\nOn 10 September 1926, the sous-préfecture was eliminated in the economic plan of Raymond Poincaré, then re-established by the Vichy government in June 1942.\n\nAn internment camp was built in Chaudanne during World War II. Seventeen Jews were arrested in Castellane and deported. On 9 December 1943, the French armée secrète (AS) and the Francs-tireurs et partisans (FTP) attacked the construction site at the Castillon dam and seized five tonnes of explosives.\n\nThe \"commune\" was liberated 18 August 1944 by the 36th division of British infantry.\n\nIn the mid-20th century wine growing for local consumption ended.\n\nThe Rock which dominates the city, rising to (over above the Verdon), is a listed historical site.\n\nThe oldest monument in the territory of the commune is the dolmen of Pierres Blanches Neolithic-Chalcolithic, a registered historical site on private property. The Roc towers above the community of Castellane.\n\nThe Musée des sirènes et fossiles and the Moyen Verdon is networked with other museums in the Gorges du Verdon, including the home of Pauline Gréoux-les-Bains, the museum of the life of yesteryear Esparron-de-Verdon, home gorges du Verdon in La Palud-sur-Verdon and the Museum of prehistory in Quinson gorges du Verdon.\n\nThe bridge of the Roc, which carries the Sisteron-Vence road across the river, was built in the first decade of the fifteenth century, replacing a succession of several wooden bridges, the last spanning the Verdon in 1300 and destroyed by in 1390. The construction of the new bridge parallels that of Nyons (built in 1401, long), Pont de Claix (built in 1607-13, long), Tournon (built in the sixteenth century, long) and Entrechaux ( long). Pope Benedict XIII granted indulgences to anyone who gave alms to finance its construction. The rearguard of the Austrian-Sardinian army was caught there by a sortie from the garrison.\n\nThe tympana of the Roc bridge have been restored several times. Metal tie rods were laid in 1697-99. The bridge as a whole was restored in 2008 and closed to traffic. It was decommissioned in 1967 and delisted in 1982. The bridge and its approaches have been a registered historical site since 1940.\n\nThe library is in the former convent of the Visitation, founded in 1644. The eighteenth-century castle at Éoulx is richly decorated with plasterwork, including the first floor ceilings, the panels surrounding the doors, the rosette in the second-floor ceilings. Externally, it has two towers, with arched openings. The town hall is housed in the building that used to be the savings bank. It resembles a villa: balconies supported by large corbels and thick balusters, and a façade adorned with a pediment.\n\nCatellane's largest fountain, in the main square, features a pyramid on which is carved a compass crossed by a carpenter's square, two chisels and a mallet, emblems of the Freemasons. At the top of the pyramid is a pedestal with a ball. On National Street, two doors have transoms or capitals with volutes, and one lintel is decorated with carved foliage. In the town, several buildingss, mostly dry stone, have been recorded in the inventory of topographic DRAC. One of them, in Rayaup, dates from the eighteenth century (the inscription that says 1586 is very recent).\n\nThe Chapel of Our Lady of the Rock, dating from the High Middle Ages, dominates the city from atop the Rock and belongs to the former Convent of Mercy. But only the wall and the south façade date from the twelfth century; the building was half demolished during the wars of religion and rebuilt in 1590.\n\nCrumbling by 1703, the chapel was again rebuilt in the early eighteenth century and once more in 1860. A capital adorned with foliage and scrolls dates from the Renaissance.\n\nThe furnishings include:\n\nIt received numerous votive offerings in the 19th and 20th centuries, including:\n\n\nParts of the old parish church of Saint-Victor date from the mid-11th century. It is listed as an historical building. It was constructed in a similar manner and on the same plane as the Church of St. Andrew in the old village above the modern-day town, and was formerly the seat of a priory of the Abbey of St. Victor in Marseille.\n\nThe apse is decorated with Lombard bands, which have been described as remarkable, each arch carved from a single stone. Unusually for the region, it has a Roman nave, with arches rebuilt in the 17th century. The base of the tower dates from 1445, but its top was rebuilt in the 18th century following damage by Protestants in 1560.\n\nThe altar dates from 1724. The choir is adorned with paintings framed in wood, and an Annunciation carved in relief from gilded wood (18th century, on historical register). The wooden furniture, the stalls, the pulpit and the lectern with its hexagonal base, form an interesting 18th and 19th-century set, some of which is on the historic register. The furnishings also include an early 17th-century silver chalice with an unusual multilobed foot, also on the historic register.\n\n\n\n\nThe outline of the walls of Petra Castellana, the ancient city beneath the current one, is still visible, and in places they reach seven meters in height. The walls are thought to date from the 12th century, although a June 2016 archeological excavation sought to date them more precisely. Only one tower survives of the fourteen that originally reinforced these walls: the 14th-century pentagonal keep. This keep, which dominates the town center, is on private property but was declared a historic monument in 1921.\n\nConstruction on the wall enclosing the lower town began in 1359, with the permission of the Count of Provence, Louis I of Naples. Traces of this wall are still visible in the square towers on the front of the houses on the square. Corbels, which could support defenses (brattices or simple parapets with battlements) are visible on their façades.\n\nTwo of the original gates in the wall remain:\n\nOne of the towers in the Saint-Michel neighborhood has been home to a dovecote since 1585.\n\nCastellane is twinned with:\n\n\n\n\n→\n"}
{"id": "47000", "url": "https://en.wikipedia.org/wiki?curid=47000", "title": "Colocation centre", "text": "Colocation centre\n\nA colocation centre (also spelled co-location, or colo) or \"carrier hotel\", is a type of data centre where equipment, space, and bandwidth are available for rental to retail customers. Colocation facilities provide space, power, cooling, and physical security for the server, storage, and networking equipment of other firms—and connect them to a variety of telecommunications and network service providers—with a minimum of cost and complexity.\n\nMany colocation providers sell to a wide range of customers, ranging from large enterprises to small companies. Typically, the customer owns the IT equipment and the facility provides power and cooling. Customers retain control over the design and usage of their equipment, but daily management of the data center and facility are overseen by the multi-tenant colocation provider.\n\n\nBuildings with data centres inside them are often easy to recognize due to the amount of cooling equipment located outside or on the roof.\n\nColocation facilities have many other special characteristics:\n\nColocation data centres are often audited to prove that they live up to certain standards and levels of reliability; the most commonly seen systems are SSAE 16 SOC 1 Type I and Type II (formerly SAS 70 Type I and Type II) and the tier system by the Uptime Institute or TIA. For service organizations today, SSAE 16 calls for a description of its \"system\". This is far more detailed and comprehensive than SAS 70's description of \"controls\". Other data center compliance standards include Health Insurance Portability and Accountability Act (HIPAA) audit and PCI DSS Standards.\n\nColocation facilities generally have generators that start automatically when utility power fails, usually running on diesel fuel. These generators may have varying levels of redundancy, depending on how the facility is built. Generators do not start instantaneously, so colocation facilities usually have battery backup systems. In many facilities, the operator of the facility provides large inverters to provide AC power from the batteries. In other cases, customers may install smaller UPSes in their racks.\n\nSome customers choose to use equipment that is powered directly by 48 VDC (nominal) battery banks. This may provide better energy efficiency, and may reduce the number of parts that can fail, though the reduced voltage greatly increases necessary current, and thus the size (and cost) of power delivery wiring. An alternative to batteries is a motor–generator connected to a flywheel and diesel engine.\n\nMany colocation facilities can provide redundant, A and B power feeds to customer equipment, and high end servers and telecommunications equipment often can have two power supplies installed.\n\nColocation facilities are sometimes connected to multiple sections of the utility power grid for additional reliability.\n\nColocation facility owners have differing rules regarding cross-connects between their customers, some of whom may be carriers. These rules may allow customers to run such connections at no charge, or allow customers to order such connections for a monthly fee. They may allow customers to order cross-connects to carriers, but not to other customers. Some colocation centres feature a \"meet-me-room\" where the different carriers housed in the centre can efficiently exchange data.\n\nMost peering points sit in colocation centres and because of the high concentration of servers inside larger colocation centres, most carriers will be interested in bringing direct connections to such buildings. In many cases, there will be a larger Internet Exchange hosted inside a colocation centre, where customers can connect for peering.\n\n\n"}
{"id": "13515630", "url": "https://en.wikipedia.org/wiki?curid=13515630", "title": "Culinary theatre", "text": "Culinary theatre\n\nCulinary theatre is the creation or enhancement of a spectacle during the service of food and beverages. This form of theatrics aims to excite or even entertain the diner, patron or customer, usually without affecting the flavour of the food(s) and/or beverage(s) to be consumed. In its simplest form, this may include candles and/or sparklers placed on a birthday cake, which give a dining room an exciting ambiance.\n\nIt is a long established practice in many restaurants and eateries to combine some element of theatrics into the dining experience for their patrons. Crêpes Suzette, when served in medium to high-end restaurants, is traditionally served by being bussed out from the kitchen, and set alight just before being placed on the patron's table.\n\nThe practice of enhancing the presentation of beverages, and especially cocktails, by use of theatrics became increasingly elaborate over the 20th century. Such enhancement may include highly skilled and very fast-paced throwing, spinning, catching and juggling of liquor bottles (to the point of being a feature of the 1988 film \"Cocktail\").\n\n"}
{"id": "306685", "url": "https://en.wikipedia.org/wiki?curid=306685", "title": "Deflagration", "text": "Deflagration\n\nDeflagration (Lat: \"de + flagrare\", \"to burn down\") is subsonic combustion propagating through heat transfer; hot burning material heats the next layer of cold material and ignites it. Most \"fires\" found in daily life, from flames to explosions such as that of Black powder, are deflagrations. This differs from detonation, which propagates supersonically through shock waves, decomposing a substance extremely quickly.\n\nIn engineering applications, deflagrations are easier to control than detonations. Consequently, they are better suited when the goal is to move an object (a bullet in a gun, or a piston in an internal combustion engine) with the force of the expanding gas. Typical examples of deflagrations are the combustion of a gas-air mixture in a gas stove or a fuel-air mixture in an internal combustion engine, and the rapid burning of gunpowder in a firearm or of pyrotechnic mixtures in fireworks.\nDeflagration systems and products can also be used in mining, demolition and stone quarrying via gas pressure blasting as a beneficial alternative to high explosives.\n\nAdding water to a burning hydrocarbon such as oil or wax produces a deflagration. The water boils rapidly and ejects the burning material as a fine spray of droplets. A deflagration then occurs as the fine mist of oil ignites and burns extremely rapidly. These are particularly common in chip pan fires, which are responsible for one in five household fires in Britain.\n\nThe underlying flame physics can be understood with the help of an idealized model consisting of a uniform one-dimensional tube of unburnt and burned gaseous fuel, separated by a thin transitional region of width formula_1 in which the burning occurs. The burning region is commonly referred to as the flame or flame front. In equilibrium, thermal diffusion across the flame front is balanced by the heat supplied by burning.\n\nThere are two characteristic timescales which are important here. The first is the thermal diffusion timescale formula_2, which is approximately equal to\n\nwhere formula_4 is the thermal diffusivity. The second is the burning timescale formula_5 that strongly decreases with temperature, typically as\n\nwhere formula_7 is the activation barrier for the burning reaction and formula_8 is the temperature developed as the result of burning; the value of this so-called \"flame temperature\" can be determined from the laws of thermodynamics.\n\nFor a stationary moving deflagration front, these two timescales must be equal: the heat generated by burning is equal to the heat carried away by heat transfer. This makes it possible to calculate the characteristic width formula_9 of the flame front:\n\nthus\n\nNow, the thermal flame front propagates at a characteristic speed formula_12, which is simply equal to the flame width divided by the burn time:\n\nThis simplified model neglects the change of temperature and thus the burning rate across the deflagration front. This model also neglects the possible influence of turbulence. As a result, this derivation gives only the laminar flame speed -- hence the designation formula_12.\n\nDamage to buildings, equipment and people can result from a large-scale, short-duration deflagration. The potential damage is primarily a function of the total amount of fuel burned in the event (total energy available), the maximum flame velocity that is achieved, and the manner in which the expansion of the combustion gases is contained.\n\nIn free-air deflagrations, there is a continuous variation in deflagration effects relative to the maximum flame velocity. When flame velocities are low, the effect of a deflagration is to release heat. Some authors use the term flash fire to describe these low-speed deflagrations. At flame velocities near the speed of sound, the energy released is in the form of pressure and the results resemble a detonation. Between these extremes, both heat and pressure are generated.\n\nWhen a low-speed deflagration occurs within a closed vessel or structure, pressure effects can produce damage due to expansion of gases as a secondary effect. The heat released by the deflagration causes the combustion gases and excess air to expand thermally. The net result is that the volume of the vessel or structure must expand to accommodate the hot combustion gases, or the vessel must be strong enough to withstand the additional internal pressure, or it fails, allowing the gases to escape. The risks of deflagration inside waste storage drums is a growing concern in storage facilities.\n\n"}
{"id": "18900272", "url": "https://en.wikipedia.org/wiki?curid=18900272", "title": "Deutscher Verein des Gas- und Wasserfaches", "text": "Deutscher Verein des Gas- und Wasserfaches\n\nThe Deutscher Verein des Gas- und Wasserfaches (DVGW) is the German association for gas and water with headquarters in Bonn. Its official English translation is the German Technical and Scientific Association for Gas and Water. The DVGW was founded in 1859. Its main task is to create the technical regulations for safety and reliability of gas and water supply.\n\nIn addition to the preparation of the national DVGW rules it also imports the DIN, EN and ISO standards.\nThe certification activities are done by DVGW CERT GmbH, a wholly owned subsidiary of DVGW.\n\n\n"}
{"id": "43683079", "url": "https://en.wikipedia.org/wiki?curid=43683079", "title": "Distributed Processing Technology", "text": "Distributed Processing Technology\n\nDistributed Processing Technology (DPT) was founded in 1977, in Maitland, Florida. DPT was an early pioneer in computer storage technology, popularizing the use of disk caching in the 1980s and 1990s. DPT was the first company to design, manufacture and sell microprocessor-based intelligent caching disk controllers to the OEM computer market. Prior to DPT, disk caching technology had been implemented in proprietary hardware in mainframe computing to improve the speed of disk access.\n\nDPT's products popularized the use of disk caching in the 1980s. According to Bill Brothers, Unix product manager at the Santa Cruz Operation (SCO), a computer operating system vendor, \"The kind of performance those guys (DPT) produce is phenomenal. It's unlike any other product on the market.\"\n\nDPT was founded by Steve Goldman, who served as the President and Chief Executive Officer until DPT was acquired by Adaptec in November 1999.\n\n"}
{"id": "32569980", "url": "https://en.wikipedia.org/wiki?curid=32569980", "title": "Halda", "text": "Halda\n\nHalda was founded in 1887 by Henning Hammarlund in Svängsta and was a Swedish manufacturer of pocketwatches. In 2009, Halda was given new life at the initiative of the watch entrepreneur and engineer Mikael Sandström\n\nHalda was founded in 1887 by the factory owner Henning Hammarlund (1857-1922) in order to primarily produce pocket watches. Its name is formed by a contraction of the founder's surname -Hammarlund( a).\n\nHammarlund had, after an education in particularly Switzerland, returned to Sweden determined to start a Swedish pocketwatch factory. The location of this purpose he found in the small community of Svängsta by Mörrumsån in Blekinge.\nThe first pocketwatches, \"Haldauren\" was presented 1889. In 1893, they were rewarded two medals at the World Exhibition in Chicago. In 1890, Halda also began to produce typewriters and taximeters.\n\nTo cope with the ever-decreasing demand for pocket watches during World War I, Hammarlund developed new ideas for the manufacturing of typewriters and taxi meters. After financial problems however, the pocket watch production was put down in 1917 (about 8,000 pocket watches was manufactured from 1888 to 1917) and in 1920 the company was liquidated. Instead, a new company, \"AB\" Halda Fabriker, took over the manufacturing of typewriters. The successful production of taximeters, took the \"Fabriks AB Halda taximeter\" (which is the origin of today's Haldex AB (gearboxes, four-wheel drive, etc.) and Halda Trancometer AB (taximeters)) and production was moved to Halmstad.\n\nEven the production of pocket watches lived on under the watchmaker Carl Borgström's housing, an employee of the Halda Fickursfabrik since 1904. Borgström bought up the remaining stock of watch parts and some machinery and again, along with some watchmakers from Fickursfabriken, started produce watches. The company, \"AB\" Urfabriken (ABU), came to produce pocketwatches until 1926 and then included fishing equipment. ABU, now ABU-Garcia AB, is still located in Svängsta.\n\nAB Halda Fabriker went bankrupt in 1927 each after the company name was changed again, this time to \"Halda AB\". The business grew throughout the 1930s. In 1938 Halda was taken over by AB Åtvidabergs Industrier and converted to a subsidiary under the name \"Facit-Halda AB\". Halda, however, had remained as a typewriter brand in the Åtvidaberg Group to the year 1957 when it switched to Facit AB. During the early 1970s, over 1,000 employees worked at the factory in Svängsta. During the late 1970s and 1980s, business was worse, and in 1987 (the same year as Halda turned 100 years old) the former owner, Ericsson announced that they sold Facit to the Norwegian Design Data. Facit Holding AB was formed in connection with this. Despite the production of electronic typewriters and focus on manufacturing personal computers and printed circuit boards the company's position deteriorated further. At the end of 1992-1993, the company went bankrupt, and the typewriter production in Svängsta was put down.\n\nIn 2009, Halda was given new life at the initiative of the watch entrepreneur and engineer Mikael Sandström who developed a new watch with an innovative concept of a time-platform and two interchangeable time-modules. The 21st century Halda-watches are based on the same drive that Henning Hammarlund established: there is never room for compromise in quality or function. In developing the first modern Halda-watch, the company worked with the Swedish astronaut Christer Fuglesang who tested the watch on his space mission, STS-128.\n\nUsing their knowledge of taximeters the company created a series of trip computers for use in rallying. The Halda Speedpilot was called \"a considerable advance upon anything of the kind previously marketed, as regards usefulness, compactness, mechanical simplicity (and hence reliability), simplicity of operation and price\" by Autosport.\n"}
{"id": "4459336", "url": "https://en.wikipedia.org/wiki?curid=4459336", "title": "Hand dryer", "text": "Hand dryer\n\nHand dryers are electric machines found in public bathrooms. They may either operate with the push of a button or automatically using a sensor. Hand washing is an important part of hygiene, and so an effective method of drying the hands is necessary.\n\nHand dryers have been popular with industries for their apparent economies. According to manufacturers, hand dryers can cut costs by as much as 99.5% (for example a company may spend $2340.00 per year on paper towels, where as the hand dryer expenditure would be as low as $14.00 per year - this will vary according to the cost of paper towels and electricity). They require very little maintenance compared to paper towels, which must be replaced. An added benefit is the removal of the paper waste. Hand dryers represent a larger initial investment, so those responsible for facility management must do a careful cost analysis to determine whether they are cost effective in their building. Costs are always relative to the kWh cost that the facility is charged by its provider. In the UK, this will typically be around 10-12p, the only way to compare costs accurately is to work out the rated energy consumption and divide it by the number of drys the hand dryer is capable of performing back to back in 1 hour, this will give the energy consumption per dry. The world's lowest energy hand dryer uses just 1 watt-hour per dry and is rated at 0.24 kW.\n\nDue to the reduction in litter and waste in comparison with paper towels, which cannot be recycled, hand dryers are claimed to be better for the environment. Another study shows that whereas the majority of the environmental impact of a hand dryer occurs during its use, the environmental impact of paper towels is predominantly in the material production and manufacturing stages. It is estimated that hand dryers use 5% less energy than paper towels in the first year, and 20% less over five years. A World Dryer study of 102 hand dryers installed in public schools in Topeka, Kansas, claimed an annual savings of 34.5 tons of solid waste, 690,000 gallons of water,and 587 trees; another World Dryer study of 153 hand dryers in the Iowa state capitol showed an annual savings of 10.5 tons of solid waste and 176 trees. However, a Dutch study published in March 1995 indicated that there was environmental parity between hand dryers and paper towels as hand drying methods when all factors were taken into consideration.\n\nIn 2009 a published study was conducted by the University of Westminster to compare the levels of hygiene offered by paper towels, warm air hand dryers and the more modern jet-air hand dryers. It found that after washing and drying hands with the warm air dryer, the total number of bacteria was found to \"increase\" on average on the finger pads by 194% and on the palms by 254%; drying with the jet air dryer resulted in an \"increase\" on average of the total number of bacteria on the finger pads by 42% and on the palms by 15%; and after washing and drying hands with a paper towel, the total number of bacteria was \"reduced\" on average on the finger pads by up to 76% and on the palms by up to 77%.\n\nThe scientists also carried out tests to establish whether there was the potential for cross contamination of other washroom users and the washroom environment as a result of each type of drying method. They found that:\n\nIn 2005, in a study conducted by TÜV Produkt und Umwelt, different hand drying methods were evaluated. The following changes in the bacterial count after drying the hands were observed:\n\nAnother paper found that air dryers dispersed marker bacteria in a radius of three feet (one metre) and onto the investigator's laboratory coat. Another study found that hot air dryers had the capacity to increase the bacterial count on the skin, and that paper towel drying decreased skin bacterial count. This is corroborated by another study which found that the mechanical action of paper towel drying removed bacteria, something air dryers cannot do.\n\nDoctors at the University of Ottawa claim that \"the blowing of warm air may lead to an accelerated dehydration of the skin surface, thereby affecting the viability\" of the microorganisms, and that the warm air may \"penetrate all the crevices in the skin, whereas absorbent towels may not reach such areas, even though the skin appears dryer\".\n\nThe European Tissue Symposium, a trade body, has produced a position statement on the hygiene standards of different hand drying systems. This summarises some of the scientific research undertaken.\n\nDyson (creators of the Dyson Airblade dryer) have countered the claims presented, suggesting that the results were intentionally falsified.\n\nMany people object to the loud noise that hand dryers make. Typically, installed hand dryers make over 80 decibels of sound at a distance of while in operation.\n\nResearch conducted in 2008 indicated that European consumers much prefer hand towels over hand dryers in public washrooms. 63% of respondents said paper towels were their preferred drying method, while just 28% preferred a hand dryer. Respondents overwhelmingly considered paper towels to offer faster hand drying than electric hand dryers (68% vs 14%). On the whole they also considered paper towels to be the most hygienic form of hand drying in public washrooms (53% vs 44%).\n\nThe earliest hand dryer was patented in 1921 by R.B. Hibbard, D. J. Watrous and J.G. Bassett for the Airdry Corporation of Groton New York. This machine was sold as a built in model or freestanding floor unit that consisted of an inverted blower (much like a handheld blow dryer) that was controlled by a floor pedal. Known as \"Airdry The Electric Towel\", these units were used in restrooms, barbershops and factories. Airdry Corporation moved to Chicago and San Francisco in 1924 to centralize their distribution. \n\nThe hand dryer was later popularized in 1948 by George Clemens. In 1993, Mitsubishi Electric introduced a new type of hand dryer that blows jets of air on both sides of the hand, pushing the water off rather than evaporating it.\n\n"}
{"id": "5514502", "url": "https://en.wikipedia.org/wiki?curid=5514502", "title": "Helicopter Aircrew Breathing Device", "text": "Helicopter Aircrew Breathing Device\n\nThe Helicopter Aircrew Breathing Device or HABD (also known as a HEED or SEA ) is a piece of military survival gear which was adopted in order to increase the chances of survival for embarked troops and aircrew trapped in an aircraft which has ditched (crashed into a body of water.) Similar in function to SCUBA gear, it consists of a small cylinder pressurized with atmospheric air and first stage regulator worn in a pouch on the user's life vest; a pressure gauge; an air hose and a special second-stage regulator (the part that delivers air via the user's mouth). The regulator is on-demand (it only delivers air when the user breathes in) and is designed to be highly rugged in order to survive impacts associated with emergency ditchings.\n\nSince a full-size SCUBA cylinder would be prohibitively bulky, especially for troops already laden with full combat gear, the HABD must be small and thus limited in capacity. It provides roughly two minutes of air at the surface. This decreases rapidly with depth and with the heightened breathing rate that accompanies stress. Still, even a few breaths in such a situation can mean the difference between life and death.\n\nHelicopter ditchings usually come with little warning, often while the pilot is attempting a ship landing or other low-altitude maneuver. Because they are top-heavy, ditched helicopters invariably flip upside-down upon hitting the water. The crew and embarked troops will be bombarded with violent jerking motions and several tons of incoming water, which causes unsecured gear to fly uncontrolled throughout the cabin and can knock troops unconscious. Jet fuel and hydraulic fluid often seep into the cabin and can cause blindness to open eyes and lung damage if inhaled. Troops unfortunate enough to find themselves in a ditched helicopter will be upside-down, disoriented, often in the dark and in a rapidly sinking bird. Immersion in cold water evokes a \"gasp\" response in humans, which limits their breath-holding ability to as little as 15 seconds. Panic is fatal. The HABD, properly used, provides troops with an invaluable tool to help ward off panic and buys them precious extra time to escape.\n\nThe Helicopter Emergency Egress Device (HEED) was introduced to the USAF by MSgt Andre' K. Leamons after losing a helicopter and crew off Kadena Japan in the late 1980s. Sergeant Leamons was the Life Support Superintendent for Air Rescue Service and introduced the HEED bottle to be included on crewmember survival vest for all Air Rescue Service members who flew over water. In the event of ditching, the HEED would provide additional time to escape from a submerged helicopter. MSgt Leamons found that the helicopter would turn over because the weight of the motor and rotor blades and sink upside down until it reached neutral buoyancy, which would leave the aircraft just below the surface. The HEED bottle would supply about 2–3 minutes of air, just enough to allow the crew to escape the aircraft and swim to the surface.\n"}
{"id": "34580566", "url": "https://en.wikipedia.org/wiki?curid=34580566", "title": "Iamus (computer)", "text": "Iamus (computer)\n\nIamus is a computer cluster (a half-cabinet encased in a custom shell) located at Universidad de Málaga. Powered by Melomics' technology, the composing module of Iamus takes 8 minutes to create a full composition in different musical formats, although the native representation can be obtained by the whole system in less than a second (on average). Iamus only composes full pieces of contemporary classical music.\n\nIamus' \"Opus one\", created on October 15, 2010 is the first fragment of professional contemporary classical music ever composed by a computer in its own style (rather than attempting to emulate the style of existing composers as was previously done by David Cope). Iamus's first full composition, \"Hello World!\", premiered exactly one year after the creation of \"Opus one\", on October 15, 2011. Four of Iamus's works premiered on July 2, 2012, and were broadcast live from the School of Computer Science at Universidad de Málaga as part of the events included in the Alan Turing year. The compositions performed at this event were later recorded by the London Symphony Orchestra, creating the album \"Iamus\", which \"New Scientist\" reported as the \"first complete album to be composed solely by a computer and recorded by human musicians.\"\n\nCommenting on the authenticity of the music, Stephen Smoliar, critic of classical music at \"The San Francisco Examiner\", commented \"What is primary is the act of making the music itself engaged by the performers and how the listener responds to what those performers do... what is most interesting about the documents generated by Iamus is their capacity to challenge the creative talents of performing musicians\".\n\n"}
{"id": "25146110", "url": "https://en.wikipedia.org/wiki?curid=25146110", "title": "Instrument Driver", "text": "Instrument Driver\n\nAn Instrument Driver, in the context of test and measurement (T&M) application development, is a set of software routines that simplifies remote instrument control. Instrument Drivers are specified by the IVI Foundation and define an I/O abstraction layer using Virtual Instrument Software Architecture (VISA). The VISA hardware abstraction layer provides an interface-independent communication channel to T&M instruments. Furthermore, the Instrument Drivers encapsulate the Standard Commands for Programmable Instruments (SCPI) commands, which are an ASCII-based set of commands for reading and writing instrument settings and measurement data. This standard allows an abstract way of using various programming languages to program remote-control applications instead of using SCPI commands. An Instrument Driver usually has a well-defined API.\n\nThe VXIplug&play Systems Alliance was founded in 1993 with the aim of unifying VXI hardware and software to achieve 'plug and play' interoperability for VXI and GPIB instruments. As part of the unifying process, VXIplug&play instrument drivers were also defined.\n\nWhen the IVI Foundation took over the Alliance in 2002, it defined a new generation of instrument drivers to replace the VXIplug&play standard. The IVI instrument driver specification intends to overcome the drawbacks of VXIplug&play. These IVI (Interchangeable Virtual Instrumentation) drivers are currently defined in three different architectures:\n\n\nInstrument Drivers allow quicker development of remote-control applications for instrumentation. The drivers reduce the difficulty of string formatting when using SCPI commands by providing a well-defined API. The IVI and VXIplug&play Instrument Drivers use the VISA as the hardware abstraction layer so that hardware-independent applications can be developed.\n\nThe VISA library allows test & measurement equipment to be connected through various hardware interfaces. The following interfaces are available:\n\n\nThe LAN eXtensions for Instrumentation (LXI) standard defines the communications protocols for controlling test and measurement systems using Ethernet. The standard requires vendors to offer IVI compliant instrument drivers.\n\n"}
{"id": "16236775", "url": "https://en.wikipedia.org/wiki?curid=16236775", "title": "Integrative level", "text": "Integrative level\n\nAn integrative level, or level of organization, is a set of phenomena emerging from pre-existing phenomena of a lower level. The levels concept is an intellectual framework for structuring reality. It arranges all material entities and all processes in the universe into a hierarchy based on how complex the entity's organization is. When arranged this way, each entity is three things at the same time: It is made up of parts from the previous level below. It is a whole in its own right. And it is a part of the whole that is on the next level above. Typical examples include life emerging from non-living substances, and consciousness emerging from nervous systems. \n\nThe main levels usually acknowledged are those of matter, life, mind, and society. These are called \"strata\" in Nicolai Hartmann's ontology. They can be further analyzed into more specific \"layers\", such as those of particles, atoms, molecules, and rocks forming the material stratum, or those of cells, organisms, populations, and ecosystems forming the life stratum.\n\nThe sequence of levels is often described as one of increasing complexity, although it is not clear whether this is always true: for example, parasitism emerges on pre-existing organisms, although parasites are often simpler than their originating forms.\n\nIdeas connected to integrative levels can be found in the works of both materialist philosophers, and anti-materialist ones.\n\n\n"}
{"id": "844525", "url": "https://en.wikipedia.org/wiki?curid=844525", "title": "Japanese kitchen", "text": "Japanese kitchen\n\nThe Japanese kitchen () is the place where food is prepared in a Japanese house. Until the Meiji era, a kitchen was also called \"kamado\" (; lit. stove) and there are many sayings in the Japanese language that involve kamado as it was considered the symbol of a house. The term could even be used to mean \"family\" or \"household\" (much as \"hearth\" does in English). Separating a family was called \"kamado wo wakeru\", or \"divide the stove\". \"Kamado wo yaburu\" (lit. \"break the stove\") means that the family was broken.\n\nIn the Jōmon period, from the 10,000 BC to 300 BC, people gathered into villages, where they lived in shallow pit dwellings. These simple huts were between 10 and 30 square meters and had a hearth in the center. Early stoves were nothing more than a shallow pit (\"jikaro\" 地床炉), but they were soon surrounded by stones to catch the fire sparks. A bottomless clay vase soon replaced the stones as these became hot quickly and occupants had to be careful around a stove. This type of stove is called \"umigamero\" (埋甕炉; lit. \"buried vase stove\"). As the stove became safer, it was moved from the center of house to the side and, by the late Kofun period (6th century), almost all houses had a stove at one end of the house. Some rich families in the Kofun period built a separate house where cooking was done. In these houses, food was stored in sacks and pots in a hole dug on the floor. Houses were constructed near a river or a spring for easy access to water.\n\nIn the Yayoi period (300 BC to AD 250) the cultivation of rice became widespread, and villages would be constructed near a marsh and a lowland. The water was muddy and \"Asaido\" (浅井戸) were constructed. An asaido was filled with sand and pebbles through which the water flowed to filter out mud and larger organisms. Some villages stored food outside a house in a large storehouse.\n\nThe kitchen remained unchanged for over 500 years, between the Nara period in the 8th century until the Muromachi period (1336–1573). Kitchens were furnished with the following items:\n\nIn the Heian period (794–1185), the first usage of the precursor to \"daidokoro\", or pantry, was recorded. The imperial palace of Heian had four rooms dedicated to preparing foods, \"oni no ma\" (鬼の間), \"daibandokoro\" (台盤所), \"asagarei no ma\" (朝餉の間), and \"Ōidono\" (大炊殿). \"Oni no ma\" was the room used for checking for poison and tasting before serving. \"Asagarei no ma\" was the room for eating breakfast. \"Ōidono\" was the room to cook foods and was placed to the north and as far away as possible from living quarters. \"Daibandokoro\" was the room used to serve foods onto a \"daiban\" (台盤), a lacquered wooden table. Maid servants also ate and waited to serve meals in the daibandokoro.\nIn the Kamakura period (1185–1333), as the Shoinzukuri style of housing became common, the kitchen was gradually absorbed into the house. Until then, a kitchen was built as a separate house whenever possible to avoid smells and smoke, and to prevent possible kitchen fires from spreading to the primary residence. Kamakura era kitchens did not include essential kitchen furnishings, such as a sink or a well.\n\nThe earliest dwellings in Japan used an open fire hearth for cooking. The first stove was recorded in the Kofun period, between the 3rd to 6th century. These stoves, called \"kamado\", were typically made of clay and sand; they were fired through a hole in the front and had a hole in the top, into which a pot could be suspended from its rim. This type of stove remained in use for centuries to come, with only minor modifications. In the 14th century, in the Muromachi period, stoves with two holes were recorded in drawings. By the early 17th century, the beginning of the Edo period, large stoves with several cooking holes were common in the kitchens of the upper class house as well as in large restaurants. It is believed these multiple hole types appeared earlier than recorded but were omitted from drawings of the time because inclusion of a single hole stove was sufficient to indicate a kitchen. The stove was low, meaning cooks had to squat to cook. In the larger kitchens, especially those of palaces and temples, raised \"kamado\" that could be operated while standing up were developed in the Edo period (1603–1867).\n\n\"Irori\" (囲炉裏) appeared in the Kofun period and served as a secondary stove. A section of wooden panels were removed from the floor and a lacquered square wooden frame was fitted in the place. The frame was filled with sand and an iron hook was lowered from the ceiling. Foods were reheated or cooked over in an iron pot hung from a hook and the fire served as a heat source. This type of stove became common in many homes by the early Nara period and a smaller irori is the center piece of a tea house.\n\nA third type of stove, a \"hibachi\" (火鉢) lit. \"fire pot\", appeared as late as the early Heian period but is likely to have been used earlier. A hibachi is a deep small pot half filled with sand and ash and a small fire was started in the pot. It was used as a safer form of heating equipment than was available previously and could be used to cook small morsels of food.\n\nFire was a part of a kitchen from the start, but water was late in becoming a part.\n\nIn the Yayoi period (300 B.C. to A.D. 250), the cultivation of rice became widespread, and villages would be constructed near a marsh and a lowland. The water was muddy and \"asaido\" (浅井戸) lit.) shallow wells, were constructed. An asaido was filled with sand and pebbles through which the water flowed to filter out mud and larger organisms. A deeper well was also dug and sometimes a hollowed log was inserted into the well to prevent the walls' collapse. A pot was used to scoop water.\n\nIt was not long before people started improving on these primitive wells. The area around a well was tiled with stones, then \"fune\" (水船) was invented. Wooden or bamboo shafts were used to carry water from nearby wells and springs to a fune or manually filled by women. Water was carried from these fune to a water vase from where it was used. Sometimes a fune was made inside a house, but it did not have the function of a sink. It was used to collect and store water and nothing more. Fune later became a part of a Japanese garden.\n\nThe first time that a sink appeared in a drawing was in the \"Bokie\" (慕帰絵) written in the early Muromachi period. The kitchen of the Nanrou temple (南瀧院) had a large \"sunokoyuka\" (すのこ床) lit. drainboard floor, next to a stove with a water filled \"oke\" and \"hisyaku\" (\"syaku\") for washing. This sunokoyuka was made with split bamboo and water would drain through gaps between the canes. Even though in many places a sunokoyuka was made over a river and washing was done, to make a part of the kitchen floor into sunokoyuka to use as a drain was an innovation. This did not pose a health problem as kitchen scraps were meticulously collected and used to make a compost. Few Japanese ate meat due to the Emperor's decree in the 8th century and animals and birds were slaughtered away from a house. Until late Edo period, this type of kitchen was widely used.\n\nShoinzukuri became the standard style of building a house beginning in 13th century and it was revolutionary for combining fire (stove) and water (well and drain) into a single place. It was still few steps short of a kitchen. In the early stage of Shoinzukuri style, instead of the kitchen being a room inside the \"omoya\" (母屋) or the main building, it was connected by a corridor and existed inside one of many sub-buildings. However, it did have a \"kamado\", a \"irori\", a well, and a \"sunokoyuka\" in the same room.\n\nIn the Edo period (1603 to 1868), \"daidokoro\" came to mean \"kitchen\" and became an integrated part of the house. It was, however, more common to call it \"katte\" (勝手) which is used to mean the \"back door.\" The pantry room was called \"ozenntate\" (御膳立). Upper class houses were well stocked and extremely large by today's standard. The country house of Tokugawa Mitsukuni, known as a gourmet of Edo period, had kitchen spaces at least 34 \"jyou\" or about 53 square metres. This is more than one-third of the entire house and does not include the sake storage room or the pantry. Some kitchens had running water by having bamboo shafts connected to the water source extend into the kitchen; users of less well equipped kitchens fetched water from a common well. A separate kitchen within the house had become customary and all but the smallest single-room houses had one.\n\nStorage in kitchens was provided by \"mizuya tansu\". These are Japanese style chests, often with a mix of compartments behind sliding doors and drawers of varying sizes. These are still available today as antiques, or altered reproductions tailored to a more modern/western style of kitchen.\n\nAn American scientist, Edward S. Morse, recorded many of the kitchens in urban and rural areas in the early Meiji period (1868–1912). These kitchens were not much different from those in the Edo period as home use of gas and electricity had only just begun in America and Europe. Though it was costly to lay down infrastructures, these were dutifully laid down, with heavy subsidization by semi-private and national companies.\n\nThe early 1900s brought a change in Japanese cuisine. Foreign cuisines from every part of the world flooded Japanese cookbooks, part of the \"haikara\" boom (ハイカラ, literally high collared, taken from high-collared coats popular in Europe). Popular dishes like curried rice, sukiyaki, ramen, and gyūdon appeared during the Meiji period as a part of the haikara movement and represented a fusing of traditional Japanese cuisines with other cuisines. Kitchens were completely reorganized to cook these foods; kitchens of the Edo period were used for simple menus of rice, broiled fish, vegetable soup, and pickled vegetables.\n\nThe first gas light was installed in Yokohama by 1873, but it would be more than 30 years before advertisements for the gas started appearing in newspapers. These ads were not directed at middle to lower classes. In the 1908 study of how gas was used in Tokyo, 57% was for lighting, 14% was for fuel, 19% was for powering motors, and 3% was for streetlights. This meant that gas was used to light only 1 out of 9 households and only 1 out of 100 households used gas for cooking. Gas companies realized this, and early appliances were directly imported from England which made them too costly for all but the richest citizens.\n\nThe Japanese kitchen turned away from American and European kitchens at this point. The first item of the industrialization to be introduced to most houses was the gas-heated rice cooker. A gas stove were introduced much later as the cost of gas was still too high for most homes. A gas oven, often an essential part of the kitchen in many American and European houses, never made it into most Japanese households because dishes requiring cooking in an oven, such as roasted chicken and baked pies, became popular only much later. Instead of an oven, a smaller fish oven was fitted into a gas stove. The gas-heated rice cooker remained in use until the 1970s in many houses and was eventually be replaced by the electric rice cooker.\n\nIn the 1920s, electricity became more widespread in homes in Japan. In \"Nihonkatei daihyakkajiten\" (literally \"Encyclopedia of Japanese Household\") published in 1927, there is already an entry of \"katei denka\" meaning a completely electric house. It says,\n\nThis, however, did not mean that a completely electric house had become common. On 1937, J. G. Douglass from General Electric conducted a half-year research on how many electric appliances made into a common household. According to this report:\n\n\nThis research project also predicted that four years later, in 1941, electric appliances should be much more widely used. A 490% increase was predicted for the refrigerator, 470% increase for the vacuum cleaner, and 150% increase for iron.\n\nThe first public water service began on October 17, 1887 in Yokohama. By the early 1900s, most major cities had water services. However, these water pipes often led to public water taps. In 1892, a survey conducted in Yokohama revealed that less than 1 in 4 households had a private water tap. 18,184 households used public water taps, while only 5,120 household used private water taps. By the 1930s, most new houses were constructed with a private water taps, but it would take another 30 years to become available in a village far from a city.\n\nIn 1912, a progressive woman's magazine \"Fujin no tomo\" (婦人の友) ran a contest for a \"heiminteki risouno daidokoro\" (平民的理想の台所), or \"average person's dream kitchen.\" \"Heimin,\" literally \"average person,\" was a popular phrase in the 1910s and 1920s, and it implied a well-educated and progressive person. Fifty-two contest entries were sent by readers, and two were awarded grand prizes. These winners were called \"the city kitchen\" and \"the village kitchen\".\n\nThe city kitchen was about 15.5 square metres in size and was intended to be used by a wife and her mother-in-law. The kitchen had doors leading to the dining room, the bath, and the laundry area. It had a wooden floor, roughly one-fourth of which included underfloor food storage lined with concrete. Two kamado were at one end, and a separate portable stove using charcoal was set up in the middle of the room. Next to the kamado was a stone sink without a water tap. Next to this sink were storage shelves with pots and pans on top, washed dishes in the middle, and vegetables and miso on the bottom. Next to the portable stove was a large food preparation table, with several drawers to store cooking utensils. Staples such as rice, sugar, and flour were kept in pots beneath this table. Additional shelves at the other end of the room could be accessed from both the kitchen and the dining room. Next to these shelves was another preparation table where foods were served onto individual dishes and then carried to the dining room. Kitchen windows and shoji were installed with glass panes to make the kitchen brighter, and electric lights were hung from the ceiling. This \"dream kitchen\" was spacious by today's standards, yet it lacked most modern post-industrial conveniences, although many smaller improvements had been made.\n\nAlso around this time, many families started to use a low table called \"chabudai\". Everyone sat around it, rather than using individual \"daiban\". Until the 1960s, sitting on chairs and eating around a dining table was considered \"haikara\".\n\nIn the Taishō period (1912–1926), a popular movement called \"Taishō Democracy\" began. Its main focus was on universal suffrage for males, and this movement extended into other fields, serving as a modernization effort similar to the Meiji Restoration. The kitchen was affected.\n\nBefore the Taishō period, the kitchen was constructed so that most tasks could be done while sitting, crouching, or kneeling. This was due to long preparation and cooking times and helped keep the stove low to prevent the spread of fire. As gas stoves and European-style clothes became popular, kitchens were redesigned so they could be used while standing. A second innovation was that instead of placing the stove and water sink in a sunken, dirt-floored section of the kitchen, the stove was constructed on the same level as the rest of the kitchen, eliminating the need for stepping into footwear to attend it.\n\nIn 1922, Suzuki Shougyou began marketing a customizable kitchen set that came to be called the \"System Kitchen.\" Many of its parts were prefabricated, and it could be made to fit in a space anywhere from 1.8 to 2.7 metres, the length of one to one-and-one-half tatami mats. The System Kitchen had a water sink, a cutting board, two or more gas stoves (not included), and cabinets for storage. This Suzuki kitchen was expensive, costing 120 yen at a time when a first-year bank worker earned only 50 yen per month. Today the same worker earns over 240,000 yen or about 2,400 dollars in a month.\n\nBy the end of the Taishō period, it was becoming increasingly difficult to have a maid to help around the house. This means that the kitchen had to be smaller for a housewife working alone. Whereas a European Frankfurt kitchen measured 1.9m by 3.4m, or 6.46 square metres, Japanese pushed for an even smaller size, 1 tsubo or 3.3 square metres, the area of two tatami mats. Three sides of these kitchens were filled with cupboards, stoves, storage areas, and a water sink.\n\nMany Japanese houses were destroyed in World War II. Rebuilding allowed architects to freely redesign houses as well as kitchens. The influence of Edo-period lifestyles was now nearly gone. Electricity and gas were built into kitchens, and designs reflected this change. An electric refrigerator, a luxury item before the war, became a standard item in the 1950s, along with an electric washing machine and a black-and-white television. However, early post-war housing projects were often poorly designed. Sometimes architects simply copied plans for American or European housing projects, with only minor modifications to better suit Japanese families. Kitchens were small and soon became cluttered with new electric appliances.\n\nThe \"System Kitchen\" approach to design was intended to make the kitchen easier for the average housewife to use. Since most families cook many types of cuisine in their kitchens, a streamlined cooking process was studied, focusing on how the kitchen was actually used. In a system kitchen, the refrigerator and other electrical appliances were placed in predesigned locations, and storage spaces were subdivided to house pots, pans and kitchen utensils.\n\nA typical modern Japanese kitchen includes the following:\n\nNotably absent are a large oven and dishwasher. Large gas ovens are found in some kitchens, particularly in the higher-end dwellings, but in the most kitchens, convection microwave are used instead. Dishwashers can be found in the kitchens for house and condominium, but rarely found in the apartments.\n\nPortable vacuum flasks are popular for carrying home-brewed tea, particularly hot tea in the winter and cold tea in the summer, particularly cold oolong tea.\n\n\n"}
{"id": "182745", "url": "https://en.wikipedia.org/wiki?curid=182745", "title": "Johnson–Nyquist noise", "text": "Johnson–Nyquist noise\n\nJohnson–Nyquist noise (thermal noise, Johnson noise, or Nyquist noise) is the electronic noise generated by the thermal agitation of the charge carriers (usually the electrons) inside an electrical conductor at equilibrium, which happens regardless of any applied voltage. Thermal noise is present in all electrical circuits, and in sensitive electronic equipment such as radio receivers can drown out weak signals, and can be the limiting factor on sensitivity of an electrical measuring instrument. Thermal noise increases with temperature. Some sensitive electronic equipment such as radio telescope receivers are cooled to cryogenic temperatures to reduce thermal noise in their circuits. The generic, statistical physical derivation of this noise is called the fluctuation-dissipation theorem, where generalized impedance or generalized susceptibility is used to characterize the medium.\n\nThermal noise in an ideal resistor is approximately white, meaning that the power spectral density is nearly constant throughout the frequency spectrum (however see the section below on extremely high frequencies). When limited to a finite bandwidth, thermal noise has a nearly Gaussian amplitude distribution.\n\nThis type of noise was discovered and first measured by John B. Johnson at Bell Labs in 1926. He described his findings to Harry Nyquist, also at Bell Labs, who was able to explain the results.\n\nThermal noise is distinct from shot noise, which consists of additional current fluctuations that occur when a voltage is applied and a macroscopic current starts to flow. For the general case, the above definition applies to charge carriers in any type of conducting medium (e.g. ions in an electrolyte), not just resistors. It can be modeled by a voltage source representing the noise of the non-ideal resistor in series with an ideal noise free resistor.\n\nThe one-sided power spectral density, or voltage variance (mean square) per hertz of bandwidth, is given by\n\nwhere \"k\" is Boltzmann's constant in joules per kelvin, \"T\" is the resistor's absolute temperature in kelvins, and \"R\" is the resistor value in ohms (Ω).\nUse this equation for quick calculation, at room temperature:\n\nFor example, a 1 kΩ resistor at a temperature of 300 K has\n\nFor a given bandwidth, the root mean square (RMS) of the voltage, formula_4, is given by\n\nwhere Δ\"f\" is the bandwidth in hertz over which the noise is measured. For a 1 kΩ resistor at room temperature and a 10 kHz bandwidth, the RMS noise voltage is 400 nV. A useful rule of thumb to remember is that 50 Ω at 1 Hz bandwidth correspond to 1 nV noise at room temperature.\n\nA resistor in a short circuit dissipates a noise power of\n\nThe noise generated at the resistor can transfer to the remaining circuit; the maximum noise power transfer happens with impedance matching when the Thévenin equivalent resistance of the remaining circuit is equal to the noise generating resistance. In this case each one of the two participating resistors dissipates noise in both itself and in the other resistor. Since only half of the source voltage drops across any one of these resistors, the resulting noise power is given by\n\nwhere \"P\" is the thermal noise power in watts. Notice that this is independent of the noise generating resistance.\n\nThe noise source can also be modeled by a current source in parallel with the resistor by taking the Norton equivalent that corresponds simply to dividing by \"R\". This gives the root mean square value of the current source as:\n\ni_n = \\sqrt \n"}
{"id": "31514327", "url": "https://en.wikipedia.org/wiki?curid=31514327", "title": "Lake Champlain Seaway", "text": "Lake Champlain Seaway\n\nThe Lake Champlain Seaway was a canal project proposed in the late 19th century and considered as late as the 1960s to connect New York State's Hudson River and Quebec's St. Lawrence River with a deep-water canal. The objective was to allow easy ship traffic from New York City to Montreal through Lake Champlain, lowering transportation costs between the two cities.\n\nThough supported by business groups in New York and Quebec, it proved economically unfeasible. Prohibitive costs (estimated at $100 million in 1900), opposition from railroads, and the diminishing utility of canal transportation prevented the project from advancing beyond the early planning stages. The Great Depression cut the project's planning budget, while World War II and completion of the St. Lawrence Seaway delayed matters. The growth of road and air transportation reduced the need for a canal, but the project was still under serious consideration as late as 1962.\n\nAs proposed, ships would have used a dredged channel in the Hudson River, transferred to an upgraded Champlain Canal, navigated Lake Champlain, traversed an upgraded Chambly Canal and St Ours Canal, and traveled a dredged route up the Richelieu River to Montreal. Today, the seaway's planned route is covered by the Lakes to Locks Passage.\n"}
{"id": "5832894", "url": "https://en.wikipedia.org/wiki?curid=5832894", "title": "Lightning detection", "text": "Lightning detection\n\nA lightning detector is a device that detects lightning produced by thunderstorms. There are three primary types of detectors: \"ground-based\" systems using multiple antennas, \"mobile systems\" using a direction and a sense antenna in the same location (often aboard an aircraft), and \"space-based systems\".\n\nThe first such device was invented in 1894 by Alexander Stepanovich Popov. It also was the first radio receiver in the world.\n\nGround-based and mobile detectors calculate the direction and severity of lightning from the current location using radio direction-finding techniques along with an analysis of the characteristic frequencies emitted by lightning. Ground-based systems use triangulation from multiple locations to determine distance, while mobile systems estimate distance using signal frequency and attenuation. Space-based detectors on satellites can be used to locate lightning range, bearing and intensity by direct observation.\n\nGround-based lightning detector networks are used by meteorological services like the National Weather Service in the United States, the Meteorological Service of Canada, the European Cooperation for Lightning Detection, the Institute for Ubiquitous Meteorology (Ubimet) and by other organizations like electrical utilities and forest fire prevention services.\n\nEach system used for lightning detection has its own limitations. These include:\n\n\nLightning detectors and weather radar work together to detect storms. Lightning detectors indicate electrical activity, while weather radar indicates precipitation. Both phenomena are associated with thunderstorms and can help indicate storm strength.\n\nThe first image on the right shows the life cycle of a thunderstorm:\n\n\nThe cloud must develop to a certain vertical extent before lightning is produced, so generally weather radar will indicate a developing storm before a lightning detector does. It is not always clear from early returns if a shower cloud will develop into a thunderstorm, and weather radar also sometimes suffers from a \"masking\" effect by attenuation, where precipitation close to the radar can hide (perhaps more intense) precipitation further away. Lightning detectors do not suffer from a masking effect and can provide confirmation when a shower cloud has evolved into a thunderstorm.\n\nLightning may be also located outside the precipitation recorded by radar. The second image shows that this happens when strikes originate in the anvil of the thundercloud (top part blown ahead of the cumulonimbus cloud by upper winds) or on the outside edge of the rain shaft. In both cases, there is still an area of radar echoes somewhere nearby.\n\nLarge airliners are more likely to use weather radar than lightning detectors, since weather radar can detect smaller storms that also cause turbulence; however, modern avionics systems often include lightning detection as well, for additional safety.\n\nFor smaller aircraft, especially in general aviation, there are two main brands of lightning detectors (often referred to as sferics, short for radio atmospherics): \"Stormscope\", produced originally by Ryan (later B.F. Goodrich) and currently by L-3 Communications, and the \"Strikefinder\", produced by Insight. \"Strikefinder\" can detect and properly display IC (intracloud) and CG (cloud to ground) strikes as well as being able to differentiate between real strikes and signal bounces reflected off the Ionosphere. Lightning detectors are inexpensive and lightweight, making them attractive to owners of light aircraft (particularly of single-engine aircraft, where the aircraft nose is not available for installation of a radome).\n\nInexpensive portable lightning detectors as well as other single sensor , such as used on aircraft, have limitations including detection of and poor sensitivity, particularly for . Professional-quality portable lightning detectors improve performance in these areas by several techniques which facilitate each other, thus magnifying their effects:\n\nHowever, since RF signals and light pulses rarely occur simultaneously except when produced by lightning, RF sensors and light pulse sensors can usefully be connected in a “coincidence circuit” which requires both kinds of signals simultaneously in order to produce an output. If such a system is pointed toward a cloud and lightning occurs in that cloud, both signals will be received; the coincidence circuit will produce an output; and the user can be sure the cause was lightning.\nWhen a lightning discharge occurs within a cloud at night, the entire cloud appears to illuminate. In daylight these intracloud flashes are rarely visible to the human eye; nevertheless, optical sensors can detect them. Looking through the window of the space shuttle in early missions, astronauts used optical sensors to detect lightning in bright sunlit clouds far below. This application led to development of the dual signal portable lightning detector which utilizes light flashes as well as the “” signals detected by previous devices.\n\n\nThe improvements described above significantly extend the detector’s utility in many areas:\n\n\nWhen an RF lightning signal is detected at a single location, one can determine its direction using a but it is difficult to determine its distance. Attempts have been made using the amplitude of the signal but this does not work very well because lightning signals greatly vary in their intensity. Thus, using amplitude for distance estimation, a strong flash may appear to be nearby and a weaker signal from the same flash – or from a weaker flash from the same storm cell – appears to be farther away. One can tell where lightning will strike within a mile radius by measuring ionization in the air to improve the accuracy of the prediction.\n\nTo understand this aspect of lightning detection one needs to know that a lightning 'flash' generally consists of several strokes, a typical number of strokes from a CG flash is in the range 3 to 6 but some flashes can have more than 10 strokes.\n\nThe initial stroke leaves an ionized path from the cloud to ground and subsequent 'return strokes', separated by an interval of about 50 milliseconds, go up that channel. The complete discharge sequence is typically about ½ second in duration while the duration of the individual strokes varies greatly between 100 nanoseconds and a few tens of microseconds. The strokes in a CG flash can be seen at night as a non-periodic sequence of illuminations of the lightning channel. This can also be heard on sophisticated lightning detectors as individual staccato sounds for each stroke, forming a distinctive pattern.\n\nSingle sensor lightning detectors have been used on aircraft and while the lightning direction can be determined from a crossed loop sensor, the distance can not be determined reliably because the signal amplitude varies between the individual strokes described above,\n\nand these systems use amplitude to estimate distance. Because the strokes have different amplitudes, these detectors provide a line of dots on the display like spokes on a wheel extending out radially from the hub in the general direction of the lightning source. The dots are at different distances along the line because the strokes have different intensities. These characteristic lines of dots in such sensor displays are called “radial spread”.\n\nThese sensors operate in the very low frequency (VLF) and low frequency (LF) range (below 300 kHz) which provides the strongest lightning signals: those generated by return strokes from the ground. But unless the sensor is close to the flash they do not pick up the weaker signals from IC discharges which have a significant amount of energy in the high frequency (HF) range (up to 30 MHz).\n\nAnother issue with VLF lightning receivers is that they pick up reflections from the ionosphere so sometimes can not tell the difference in distance between lightning 100 km away and several hundred km away. At distances of several hundred km the reflected signal (termed the “sky wave”) is stronger than the direct signal (termed the “ground wave”).\nThe Earth-ionosphere waveguide traps electromagnetic VLF- and ELF waves. Electromagnetic pulses transmitted by lightning strikes propagate within that waveguide. The waveguide is dispersive, which means that their group velocity depends on frequency. The difference of the group time delay of a lighting pulse at adjacent frequencies is proportional to the distance between transmitter and receiver. Together with the direction finding method, this allows locating lightning strikes by a single station up to distances of 10000 km from their origin. Moreover, the eigenfrequencies of the Earth-ionospheric waveguide, the Schumann resonances\nat about 7.5 Hz, are used to determine the global thunderstorm activity.\n\nBecause of the difficulty in obtaining distance to lightning with a single sensor, the only current reliable method for positioning lightning is through interconnected networks of spaced sensors covering an area of the Earth’s surface using time-of-arrival differences between the sensors and/or crossed-bearings from different sensors. Several such national networks currently operating in the U.S. can provide the position of CG flashes but currently cannot reliably detect and position IC flashes.\n\nThere are a few small area networks (such as Kennedy Space Center's LDAR network, one of whose sensors is pictured at the top of this article) that have VHF time of arrival systems and can detect and position IC flashes. These are called \"arrays\". They typically cover a circle 30–40 miles in diameter.\n\n\n"}
{"id": "8873033", "url": "https://en.wikipedia.org/wiki?curid=8873033", "title": "List of home computers by video hardware", "text": "List of home computers by video hardware\n\nThis is a list of home computers, sorted alphanumerically, which lists all relevant details of their video hardware.\n\nA home computer was the description of the second generation of desktop computers, entering the market in 1977 and becoming common during the 1980s. A decade later they were generally replaced by IBM PC compatible \"PCs\", although in actuality home computers are also members of the class known as personal computers.\n\nExamples of typical early home computers are the TRS-80, Atari 400/800, BBC Micro, the ZX Spectrum, the MSX 1, the Amstrad CPC 464 and the Commodore 64. Examples of typical late home computers are MSX 2 systems, and the Amiga and Atari ST systems.\n\nNote: in cases of manufacturers who have made both home and personal computers, only machines fitting into the \"home\" computer category are listed. Systems in the personal computer category, except for Early Macintosh personal computers, are generally all based on the VGA standard, and use a video chip known as a Graphics processing unit. Although very early PCs used one of the much simpler (even compared to most home computer video hardware) video display controller cards, using standards such as the MDA, Hercules Graphics Card, CGA and EGA standard). Only after the introduction of the VGA standard could PCs really compete with the home computers of the same era, such as the Amiga and Atari ST, or even with the MSX-2. Also not listed are systems that are typically only gaming systems, like the Atari 2600 and the Bally Astrocade, even though these systems could sometimes be upgraded to resemble a home computer.\n\nEarly home computers all had quite similar hardware, (and software) mostly using the 6502, the Z80, or in a few cases the 6809 microprocessor. They could have only as little as 1 KB of RAM or as much as 128K, and software wise, they could use a small 4K BASIC interpreter, or an extended 12K or more BASIC. So the basic systems were quite similar, except for one part of the system, the video display hardware. Some systems proved to be much more successful than others, and careful observers will see that the most successful systems had the most capable video hardware. The reason for that is that the success of the home computer was mostly determined by the kind of games you could play on it.\n\nIf you wanted to run a nice video game on a home computer, all the other specifications of the system, such as the CPU, the kind of BASIC, even to a degree how much memory the system had (if had at least 32K or more) did not matter much. What mattered most was what kind of picture could be put on the screen, and how easy or hard it was for a programmer to get enough capabilities out of the video hardware to create the effects necessary for the game.\n\nA case in point is the Commodore 64. Its microprocessor lacked advanced math functions and was relatively slow. In addition, the built-in BASIC interpreter lacked any sort of graphics commands, as it was the same version that was developed for the older Commodore PET (a computer without any high resolution graphics capabilities at all). However, these drawbacks were of little consequence, because the C64 had the VIC-II chip. When accessed by machine language programs, the graphic capabilities of this chip made it practical to develop arcade-style games. Additionally, specific machine language coding exploiting quirks of the VIC-II chip allowed for special tricks to draw even better pictures out of the VIC-II chip. The comparatively large memory and the audio capabilities of the C64 also lent themselves well toward the production of desirable games.\nA negative example was the Aquarius by Mattel which had such incredibly limited video hardware (for the time period) that it was retracted from the market after only four months due to bad sales.\n\nOne major problem that early computer video hardware had to overcome was the \"video bus arbitration\" problem. The problem was to give the video hardware (VDU) continuous read access to the video RAM, while at the same time the CPU also had to access the same RAM. The obvious solution, using interleaving time slots for the VDU and RAM was hard to implement because the logic circuits and video memory chips of the time did not have the switching speed they have now. For higher resolutions the logic and the memory chips were barely fast enough to support reading the display data, let alone for dedicating half the available time for the slow 8-bit CPU. That said, there was one system, the Apple II, that was one of the first to use a feature of the data-bus logic of the 6502 processor to implement a very early interleaving time slot mechanism to eliminate this problem. The BBC Microcomputer used 4 MHz RAM with a 2 MHz 6502 in order to interleave video accesses with CPU accesses.\n\nMost other systems used a much simpler approach, and the TRS-80's video logic was so primitive that it simply did not have any bus arbitration at all. The CPU had access to the video memory at all times. Writing to the video RAM simply disabled the video display logic. The result was that the screen often displayed random horizontal black stripes on the screen when there was heavy access to the video RAM, like during a video game.\n\nMost systems avoided the problem by having a status register that the CPU could read, and which showed when the CPU could safely write to the video memory. That was possible because a composite video signal blanks the video output signal during the \"blanking periods\" of the horizontal and especially the long vertical video sync pulses. So by simply waiting for the next blanking period the stripes could be avoided. This approach did have one disadvantage, it relied on the software not to write to the screen during the non-blanking periods. If the software ignored the status register the stripes would re-appear. Another approach, used by most other machines of the time, was to temporarily stop the CPU using the \"WAIT/BUSRQ\" (Z80) \"WAIT\" (6809) or \"SYNC\" (6502) control signal whenever the CPU tried to write to the screen during a non-blanking period. Yet another, more advanced, solution was to add a hardware FIFO so that the CPU could write to the FIFO instead of directly to the RAM chips, which were updated from the FIFO during a blanking interval by special logic circuitry. Some later systems started using special \"two port\" video memory, called VRAM, that had independent data output pins for the CPU interface and the video logic.\n\nThere are two main categories of solutions for a home computer to generate a video signal:\n\nSystems in the first category were the most flexible, and could offer a wide ranges of (sometimes unique) capabilities, but generally speaking the second category could offer a much more complex system for a comparable lower price.\n\nThe VDC based systems can be divided into four sub-categories:\n\n\n\"A \"-\" in a table cell means that the answer is irrelevant, unknown or in another way has no meaning, for example the sprite size of a system that does not support hardware sprites.\"\n\n\"A \"?\" in a table cell means that the entry has not yet been determined. if a ? follows an entry it means that other options than the listed ones may also exist\"\n\n\"\"Mono\" in a table cell means monochrome that is for example black on white, or black on green.\"\n\nFor these systems it is established that they are simultaneously based on multiple technologies. The hardware chosen to be used by these systems may have substantial or insubstantial impact on the video they output.\n\nFor these systems it could not be established on what technology they are based. If you know more about the actual hardware used by these systems, then please move them to the correct class.\n\n"}
{"id": "12220461", "url": "https://en.wikipedia.org/wiki?curid=12220461", "title": "List of hyperboloid structures", "text": "List of hyperboloid structures\n\nThis page is a list of hyperboloid structures. These were first applied in architecture by Russian engineer Vladimir Shukhov (1853–1939). Shukhov built his first example as a water tower (hyperbolic shell) for the 1896 All-Russian Exposition. Subsequently, more have been designed by other architects, including Le Corbusier, Antoni Gaudí, Eduardo Torroja, Oscar Niemeyer and Ieoh Ming Pei.\n\nThe shapes are doubly ruled surfaces, which can be classed as:\n"}
{"id": "35456317", "url": "https://en.wikipedia.org/wiki?curid=35456317", "title": "Load–store unit", "text": "Load–store unit\n\nIn computer engineering a load–store unit is a specialized execution unit responsible for executing all load and store instructions, generating virtual addresses of load and store operations and loading data from memory or storing it back to memory from registers.\n\nThe load–store unit usually includes a queue which acts as a waiting area for memory instructions, and the unit itself operates independently of other processor units.\n\nLoad–store units may also be used in vector processing, and in such cases the term \"load–store vector\" may be used.\n\nSome load-store units are also capable of executing simple fixed-point and/or integer operations.\n\n"}
{"id": "732167", "url": "https://en.wikipedia.org/wiki?curid=732167", "title": "Machine Intelligence Research Institute", "text": "Machine Intelligence Research Institute\n\nThe Machine Intelligence Research Institute (MIRI), formerly the Singularity Institute for Artificial Intelligence (SIAI), is a non-profit organization founded in 2000 by Eliezer Yudkowsky, originally to accelerate the development of artificial intelligence, but focused since 2005 on identifying and managing the potential risks to humanity that future AI systems could become superintelligent. MIRI's work has focused on a friendly AI approach to system design and on predicting the rate of technology development.\n\nIn 2000, Eliezer Yudkowsky, who was mostly self-educated and had been involved in the Extropian group, founded the Singularity Institute for Artificial Intelligence with funding from Brian and Sabine Atkins; the original purpose of the institute was to accelerate the development of artificial intelligence (AI). Yudkowsky began to be concerned that AI systems developed in the future could become superintelligent and pose risks to humanity, and in 2005 the institute moved to Silicon Valley and began to focus on ways to identify and manage those risks; this was at a time when the scientists in the field were largely unconcerned with them but a group known as transhumanists were expressing concerns. \n\nStarting in 2006, the Institute organized the Singularity Summit to discuss the future of AI including its risks, initially in cooperation with Stanford University and funding from Peter Thiel; the \"San Francisco Chronicle\" described the first conference as a \"Bay Area coming-out party for the tech-inspired philosophy called transhumanism\". In 2011, its offices were four apartments in downtown Berkeley. In December 2012, the institute sold its name, web domain, and the Singularity Summit to Singularity University, and the next month took the name \"Machine Intelligence Research Institute\".\n\nIn 2014 and 2015 public and scientific interest in the risks of AI grew; this shift from something once considered \"crackpot\" to the mainstream spurred further donations to fund research at MIRI and similar organizations.\n\nMIRI's approach to identify and manage the risks of AI, led by Yudkowsky, is mostly about how to design friendly AI - both initial design of AI systems and mechanisms to ensure that evolving AI systems remain friendly. \n\nMIRI researchers advocate early safety work as a precautionary measure, before it is too late. However MIRI researchers have expressed skepticism about the views of singularity advocates like Ray Kurzweil that superintelligence is \"just around the corner\". MIRI has funded forecasting work through an initiative called AI Impacts, which studies historical instances of discontinuous technological change, and has developed new measures of the relative computational power of humans and computer hardware.\n\n\n"}
{"id": "21395192", "url": "https://en.wikipedia.org/wiki?curid=21395192", "title": "Microwave thermotherapy", "text": "Microwave thermotherapy\n\nMicrowave thermotherapy, also called microwave therapy, is a type of treatment in which body tissue is heated by microwave irradiation to damage and kill cancer cells or to make cancer cells more sensitive to the effects of radiation and certain anticancer drugs.\n\n"}
{"id": "31896179", "url": "https://en.wikipedia.org/wiki?curid=31896179", "title": "MobileNotifier", "text": "MobileNotifier\n\nMobileNotifier was a free open-source alert messaging system, written by Peter Hajas, for jailbroken iOS devices including iPhone, iPod touch, and iPad, for iOS 4.0. Mobile Notifier was written as a reproduction of Android notifications. It is currently released under the BSD License. The lead developer, Peter Hajas, left to work for Apple but the project was continued by other developers.\n\nThe software hooks into the operating system to replace the built-in modal notification user interface, and maintains a queue of unread messages for the user.\n\nAs of late May 2011, MobileNotifier has had over 230,000 downloads.\n\nMobileNotifier was developed in conjunction with the Rensselaer Center for Open Source Software at Rensselaer Polytechnic Institute.\n\nMobileNotifier is in beta.\n\nReleased 29 May 2011.\n\nThis included the following new features:\n\nIt solved the following issues:\n\nReleased 4 May 2011.\n\nThis included the following new features:\n\nIt solved the following issues:\n\nReleased 27 February 2011.\n\nThis included the following new features:\n\nIt solved the following issues:\n\nReleased 18 February 2011\n\nThis included the following new features:\n\nIt solved the following issues:\n\nMobileNotifier beta1 was not officially released.\n\nIt solved the following issues:\n\n\n"}
{"id": "5520917", "url": "https://en.wikipedia.org/wiki?curid=5520917", "title": "Multimedia over Coax Alliance", "text": "Multimedia over Coax Alliance\n\nThe Multimedia over Coax Alliance (MoCA) is an international standards consortium publishing specifications for networking over coaxial cable.\n\nThere are three versions of the specification currently available, MoCA 1.1, MoCA 2.0, and MoCA 2.5.\n\nMoCA was established in 2004.\n\nMoCA 1.0 was approved in 2006, MoCA 1.1 in April 2010, MoCA 2.0 in June 2010, and MoCA 2.5 in April 2016.\n\nThe Alliance currently has 45 members including pay TV operators, OEMs, CE manufacturers and IC vendors.\n\nMoCA’s board of directors consists of Arris, Broadcom, Comcast, Cox Communications, DirecTV, Echostar, Intel, MaxLinear and Verizon.\n\nWithin the scope of the Internet protocol suite, MoCA is a protocol that provides the link layer. In the 7-layer OSI model, it provides definitions within the data link layer (layer 2) and the physical layer (layer 1). DLNA approved of MoCA as a layer 2 protocol.\nMoCA 1.1 provides 175 Mbit/s net throughputs (275 Mbit/s PHY rate) and operates in the 500 to 1500 MHz frequency range.\n\nMoCA 2.0 offers actual throughputs (MAC rate) up to 1 Gbps. Operating frequency range is 500 to 1650 MHz. Packet error rate is 1 packet error in 100 million.\n\nMoCA 2.0 also offers lower power modes of sleep and standby and is backward interoperable with MoCA 1.1.\n\nIn March 2017, SCTE/ISBE society and MoCA consortium began creating a new \"standards operational practice\" (SCTE 235) to provide MoCA 2.0 with Docsis 3.1 interoperability. Interoperability is necessary because both MoCA 2.0 and Docsis 3.1 may operate in the frequency range above 1 GHz. The standard \"addresses the need to prevent degradation or failure of signals due to a shared frequency range above 1 GHz\". \n\nMoCA 2.5 (introduced April 13, 2016) offers actual data rates up to 2.5 Gbit/s, continues to be backward interoperable with MoCA 2.0 and MoCA 1.1, and adds MoCA protected setup (MPS), Management Proxy, Enhanced Privacy, Network wide Beacon Power, and Bridge detection.\n\nMoCA Access is intended for multiple dwelling units (MDUs) such as hotels, resorts, hospitals, or educational facilities. It is based on the current MoCA 2.0 standard which is capable of 1 Gbps net throughputs, and MoCA 2.5 which is capable of 2.5 Gbps.\n\nNotes:\n\n"}
{"id": "53144", "url": "https://en.wikipedia.org/wiki?curid=53144", "title": "Nuclear explosive", "text": "Nuclear explosive\n\nA nuclear explosive is an explosive device that derives its energy from nuclear reactions. Almost all nuclear explosive devices that have been designed and produced are nuclear weapons intended for warfare.\n\nOther, non-warfare, applications for nuclear explosives have occasionally been proposed. For example, nuclear pulse propulsion is a form of spacecraft propulsion that would use nuclear explosives to provide impulse to a spacecraft. A similar application is the proposal to use nuclear explosives for asteroid deflection. From 1958 to 1965 the United States government ran a project to design a nuclear explosive powered nuclear pulse rocket called Project Orion. Never built, this vessel would use repeated nuclear explosions to propel itself and was considered surprisingly practical. It is thought to be a feasible design for interstellar travel.\nNuclear explosives were once considered for use in large-scale excavation. A nuclear explosion could be used to create a harbor, or a mountain pass, or possibly large underground cavities for use as storage space. It was thought that detonating a nuclear explosive in oil-rich rock could make it possible to extract more from the deposit, e.g. note the Canadian Project Oilsand. From 1958 to 1973 the U.S. government exploded 28 nuclear test-shots in a project called the Operation Plowshare. The purpose of the operation was to use peaceful nuclear explosions for moving and lifting enormous amounts of earth and rock during construction projects such as building reservoirs. The Soviet Union conducted a much more vigorous program of 122 nuclear tests, some with multiple devices, between 1965 and 1989 under the auspices of Program No. 7 – Nuclear Explosions for the National Economy.\n\nAs controlled nuclear fusion has proven difficult to use as an energy source, an alternate proposal for producing fusion power has been to detonate nuclear fusion explosives inside very large underground chambers and then using the heat produced, which would be absorbed by a molten salt coolant which would also absorb neutrons. The 1970s PACER (fusion) project investigated fusion detonation as a power source.\n\nFailure to meet objectives, along with the realization of the dangers of nuclear fallout and other residual radioactivity, and with the enactment of various agreements such as the Partial Test Ban Treaty and the Outer Space Treaty, has led to the termination of most of these programs.\n\n"}
{"id": "29874455", "url": "https://en.wikipedia.org/wiki?curid=29874455", "title": "PCI Geomatica", "text": "PCI Geomatica\n\nPCI Geomatica is a remote sensing desktop software package for processing earth observation data, designed by PCI Geomatics. The latest version of the software is Geomatica 2017. Geomatica is aimed primarily at faster data processing and allows users to load satellite and aerial imagery where advanced analysis can be performed. Geomatica has been used by many educational institutions and scientific programs throughout the world to analyze satellite imagery and trends, such as the GlobeSAR Program, a program which was carried out by the Canada Centre for Remote Sensing in the 1990s.\n\nA very popular edition of Geomatica is known as Freeview, which permits users to load multiple types of satellite images as well as geospatial data that is stored in different formats. The software is available for download over the web, and has registered several thousands of downloads. CNET Download page for Freeview\n\nGeomatica is one of several software packages available to the educational, commercial, and military users. Other similar packages include Erdas Imagine, Envi, and SocetSet (or Socet GXP). An independent review of the software and its functionality written by Directions Magazine is included here: http://www.directionsmag.com/articles/product-review-pci146s-geomatica-10/123136. Geomatica has also been compared to Envi and Erdas Imagine as it relates to orthorectification. http://www.isprs.org/proceedings/XXXVII/congress/4_pdf/283.pdf\n\nOver 2,700 educational institutions worldwide have used Geomatica as part of their Remote Sensing course delivery, some of which are listed here\n\nGeomatica includes a web coverage service interface that complies with the OGC Web Coverage Service (WCS) Interface Standard, which is a key area in which PCI Geomatics has contributed. Remote Sensing data providers distribute data in diverse formats, which makes sharing information across many different platforms challenging. WCS seeks to alleviate some of the data sharing challenges by publishing the geographic information and layers openly over the web.\n\nGeomatica adheres to open standards to promote sharing and collaboration of earth observation data. An SDK that makes the PCIDSK file format available to the community is available through the GDAL website here: \nhttps://archive.is/20130414193214/http://home.gdal.org/projects/pcidsk/\n\n"}
{"id": "7998349", "url": "https://en.wikipedia.org/wiki?curid=7998349", "title": "Packed lunch", "text": "Packed lunch\n\nA packed lunch (also called pack lunch, sack lunch or bag lunch in North America, or pack up in the United Kingdom, as well as the regional variations: packed lunch in Lancashire, Merseyside and Yorkshire, as well as a pack up in York) is a lunch prepared at home and carried to be eaten elsewhere, such as school, a workplace, or at an outing. The food is usually wrapped in plastic, aluminum foil, or paper and can be carried (\"packed\") in a lunch box, paper bag (a \"sack\"), or plastic bag. While packed lunches are usually taken from home by the people who are going to eat them, in Mumbai, India, tiffin boxes are most often picked up from the home and brought to workplaces later in the day by so-called dabbawallas. It is also possible to buy packed lunches from stores in several countries. Lunch boxes made out of metal, plastic or vinyl are now popular with today's youth. Lunch boxes provide a way to take heavier lunches in a sturdier box or bag. It is also environmentally friendly.\n\nIn the United States, an informal meeting at work, over lunch, where everyone brings a packed lunch, is a brown-bag lunch or colloquially a \"brown bag\". There are also white and other color bags for seasonal use.\n\nOne such brown bag lunch was used as a deliberate rebuff of the Chinese hosts, by the United States delegation, at peace negotiations in Kaesong during the Korean War. The Chinese hosts offered lunch and watermelon to the U.S. guests, which the U.S. delegates, who considered lunching with one's opposition to be fraternizing with the enemy, rejected in favor of their own packed lunches.\n\n"}
{"id": "7371620", "url": "https://en.wikipedia.org/wiki?curid=7371620", "title": "Peg (unit)", "text": "Peg (unit)\n\nA peg is a unit of volume, typically used to measure amounts of liquor in the Indian subcontinent. Equal to 30 mL, the terms \"large peg\" and \"small peg\" are also the time of the British Raj, and presumably for the sake of convenience was later standardised to 30 mL.\n\nIn India, liquor's alcohol content is typically 42.8% ABV. It then follows that a peg of liquor usually contains 12.84 mL of pure alcohol, roughly equal to 1.3 alcoholic units.\n\nInformally, a peg is also understood to be a single shot of any alcoholic drink.\n\nIn England the mine owners would give a drink to miners at the end of the shift to get some relief from cold. Workers would eagerly look forward to it and would call it ‘Precious Evening Glass’ which in short became ‘peg’.\n"}
{"id": "26162831", "url": "https://en.wikipedia.org/wiki?curid=26162831", "title": "Primer (cosmetics)", "text": "Primer (cosmetics)\n\nA cosmetic primer is a cream or lotion applied before another cosmetic to improve coverage and lengthen the amount of time the cosmetic lasts on the face.\n\nThere are different kinds of cosmetic primers such as foundation primer, eyelid primer, lip primer, and mascara primer.\n\nA foundation primer may work like a moisturizer only different, or it may absorb oil with salicylic acid or aid in creating a less oily, more matte appearance. It aids in applying the foundation more evenly and smoothly, and increases the longevity of the foundation. Some contain antioxidants such as A, C, and E, or other ingredients such as grape seed extract and green tea extract. There are water-based and silicon-based foundation primers. Ingredients may include cyclomethicone and dimethicone. Some primers do not contain preservative, oil or fragrance. Some may also have sun protection factor (SPF). Some foundation primers are tinted to even out or improve skin tone or color. Others give a pearlized finish to make the complexion more light reflective. There are also foundation primers which are mineral-based primers, which contain mica and silica.\n\nEyelid or eye shadow primers are similar, but made specifically for use near the eyes. An eyelid primer may help even the color of the lid and upper eye area, may reduce oiliness, may add shimmer, or inversely may mattify. Eye primers aid in the smooth application of eye shadow, prevent it from accumulating in eyelid creases, and improve its longevity. \nEye shadow primers are applied to the eyelid and lower eye area prior to the application of eye shadow. They even out the skin tone of the eyelids hide eyelid veins, and smooth out the skin of the eyelids. Eye shadow primers help with the application of eye shadows. They intensify the color of the eye shadows and keep them from smearing or creasing by reducing the oiliness of the lids. Some eye shadows even state in the instruction sheet, that they are recommended for usage over the eye shadow primer. There is a real difference in the eye shadow color and time of wear when it is used over the primer on bare skin. The effect of eye shadow primers is not limited to eye shadows. They also work for eye liners and eye shadow bases. \n\nMascara primer is sometimes colorless. It usually thickens and/or lengthens the lashes before the application of mascara for a fuller finished look. It may also help keep mascara from smudging or flaking, and some claim to improve the health of the lashes.\n\nLip primers are intended to smooth the lips and help improve the application of lipstick or lip gloss, although exfoliating the lips is often recommended before applying. They also are intended to increase the longevity of lip color, and to prevent lipstick from \"feathering\", that is, smearing past the lip vermilion, and especially from migrating into any fine lines around the lips.\n\n"}
{"id": "3732486", "url": "https://en.wikipedia.org/wiki?curid=3732486", "title": "Quantum mirage", "text": "Quantum mirage\n\nIn physics, a quantum mirage is a peculiar result in quantum chaos. Every system of quantum dynamical billiards will exhibit an effect called \"scarring\", where the quantum probability density shows traces of the paths a classical billiard ball would take. For an elliptical arena, the scarring is particularly pronounced at the foci, as this is the region where many classical trajectories converge. The scars at the foci are colloquially referred to as the \"quantum mirage\".\n\nThe quantum mirage was first experimentally observed by Hari Manoharan, Christopher Lutz and Donald Eigler at the IBM Almaden Research Center in San Jose, California in 2000. The effect is quite remarkable but in general agreement with prior work on the quantum mechanics of dynamical billiards in elliptical arenas.\n\nThe mirage occurs at the foci of a quantum corral, a ring of atoms arranged in an arbitrary shape on a substrate. The quantum corral was demonstrated in 1993 by Lutz, Eigler, and Crommie using an ellipitical ring of iron atoms on a copper surface using the tip of a low-temperature scanning tunneling microscope to manipulate individual atoms. The ferromagnetic iron atoms reflected the surface electrons of the copper inside the ring into a wave pattern, as predicted by the theory of quantum mechanics.\n\nThe size and shape of the corral determine its quantum states, including the energy and distribution of the electrons. To make conditions suitable for the mirage the team at Almaden chose a configuration of the corral which concentrated the electrons at the foci of the ellipse.\n\nWhen scientists placed a magnetic cobalt atom at one focus of the corral, a mirage of the atom appeared at the other focus. Specifically the same electronic properties were present in the electrons surrounding both foci, even though the cobalt atom was only present at one focus. In scanning tunneling microscopy, an atomically sharp metal tip is advanced towards the atomically flat sample surface until electron tunneling out of the atom and into the advancing tip becomes effective. Using the sharp tip we can also arrange atoms adsorbed on the surface into unique shapes; for example, 48 adsorbed iron atoms on Cu(111) arranged into a 14.26 nm diameter circle. The electrons on the copper surface are trapped inside the circle formed by the iron atoms. A standing wave pattern emerges with a large peak at the center due to the constructive interference of electrons on the copper surface as they scatter off the adsorbed iron atoms.\n\nIBM scientists are hoping to use quantum mirages to construct atomic scale processors in the future.\n\n"}
{"id": "589755", "url": "https://en.wikipedia.org/wiki?curid=589755", "title": "Retrocomputing", "text": "Retrocomputing\n\nRetrocomputing is the use of older computer hardware and software in modern times. Retrocomputing is usually classed as a hobby and recreation rather than a practical application of technology; enthusiasts often collect rare and valuable hardware and software for sentimental reasons. However, some do make use of it.\nA more serious line of retrocomputing is part of the history of computer hardware. It can be seen as the analogue of experimental archaeology in computing. Some notable examples include the reconstruction of Babbage's Difference engine (more than a century after its design) and the implementation of Plankalkül in 2000 (more than half a century since its inception).\n\nSome retrocomputing enthusiasts also consider the 'Homebrewing' \n(designing and building of retro- and retro-styled computers or kits), to be an important aspect of the hobby, giving new enthusiasts an opportunity to experience more fully what the early years of hobby computing were like. There are several different approaches to this end. Some are exact replicas of older systems, and some are newer designs based on the principles of retrocomputing, while others combine the two, with old and new features in the same package. Examples include:\n\nThe personal computer has been around since approximately 1976. But in that time, numerous technological revolutions have left generations of obsolete computing equipment on the junk heap. Nevertheless, in that time, these otherwise useless computers have spawned a sub-culture of vintage computer collectors, who often spend large sums to acquire the rarest of these items, not only to display but restore to their fully functioning glory, including active software development and adaptation to modern uses. This often includes so-called hackers who add-on, update and create hybrid composites from new and old computers for uses for which they were otherwise never intended. Ethernet interfaces have been designed for many vintage 8-bit machines to allow limited connectivity to the Internet; where users can access user groups, bulletin boards and databases of software. Most of this hobby centers on those computers manufactured after 1960, though some collectors specialize in pre-1960 computers as well.\n\nMicro Instrumentation and Telemetry Systems (MITS) produced the Altair 8800 in 1975, which is widely regarded as starting the microcomputer revolution.\n\nIMSAI produced a machine similar to the Altair 8800, though considered by many to be a more robust design.\n\nProcessor Technology produced the Sol-20. This was one of the first machines to have a case that included a keyboard; a design feature copied by many of later \"home computers\".\nSouthwest Technical Products Corporation (SWTPC) produced the SWTPC 6800 and later the SWTPC 6809 kits that employed the Motorola 68xx series microprocessors. The 68xx line was to be followed later by the 6502 processor that was used in many early \"home computers\", such as the Apple II.\n\nThe earliest of the Apple Inc. personal computers are among some of the most collectible. They are relatively easy to maintain in an operational state thanks to Apple's use of readily available off-the-shelf parts.\n\n\n\n\n\n\n\n\nIn an interview with Conan O'Brien in May 2014, George R. R. Martin revealed that he writes his books using WordStar 4.0, an MS-DOS application dating back to 1987.\n\nRetrocomputing (and retrogaming as aspect) has been described in one paper as preservation activity and as aspect of the remix culture.\n\n\n\n"}
{"id": "7003375", "url": "https://en.wikipedia.org/wiki?curid=7003375", "title": "Rice huller", "text": "Rice huller\n\nA rice huller or rice husker is an agricultural machine used to automate the process of removing the chaff (the outer husks) of grains of rice. Throughout history, there have been numerous techniques to hull rice. Traditionally, it would be pounded using some form of mortar and pestle. An early simple machine to do this is a rice pounder. Later even more efficient machinery was developed to hull and polish rice. These machines are most widely developed and used throughout Asia where the most popular type is the Engelberg huller designed by German Brazilian engineer Evaristo Conrado Engelberg in Brazil and first patented in 1885.\n\nThe Engelberg huller uses steel rollers to remove the husk. Other types of huller include the disk or \"cono\" huller which uses an abrasive rotating disk to first remove the husk before passing the grain to conical rollers which polish it, this is done repeatedly since other sides of circular side of rice are not husked. Rubber rollers may be used to reduce the amount of breakage of the grains, so increasing the yield of the best quality \"head rice\", but the rubber rollers tend to require frequent replacement, which can be a significant drawback.\n\n"}
{"id": "3531281", "url": "https://en.wikipedia.org/wiki?curid=3531281", "title": "SWR meter", "text": "SWR meter\n\nThe SWR meter or VSWR (voltage standing wave ratio) meter measures the standing wave ratio in a transmission line. The meter can be used to indicate the degree of mismatch between a transmission line and its load (usually a radio antenna), or evaluate the effectiveness of impedance matching efforts.\n\nA directional SWR meter measures the magnitude of the forward & reflected waves by sensing each one individually, with directional couplers. A calculation can then be performed to arrive at the SWR.\n\nReferring to the above diagram, the transmitter (TX) and antenna (ANT) terminals are connected via an internal transmission line. This main line is electromagnetically coupled to two smaller sense lines (directional couplers) which are terminated with resistors at one end, and diode rectifiers at the other. Sometimes a printed circuit board using three parallel traces is used to make the transmission line and the two sensing lines. The resistors are chosen to match the characteristic impedance of the sense lines. The diodes convert the magnitudes of the forward & reverse waves to FWD and REV DC voltages, respectively, which are then smoothed by the capacitors.\n\nTo calculate the VSWR, first calculate the reflection coefficient:\n\nThen calculate the VSWR:\n\nIn a passive meter, this is usually indicated on a non-linear scale.\nSWR can also be measured using an impedance bridge circuit. The bridge is balanced (0 volts across the detector) only when the test impedance exactly matches the reference impedance. When a transmission line is mismatched (SWR > 1:1), its input impedance deviates from its characteristic impedance; thus, a bridge can be used to determine the presence or absence of a low SWR.\n\nTo test for a match, the reference impedance of the bridge is set to the expected load impedance (for example, 50 ohms), and the transmission line connected as the unknown impedance. RF power is applied to the circuit. The voltage at the line input represents the vector sum of the forward wave, and the wave reflected from the load. If the characteristic impedance of the line is known to be 50 ohms, we know the magnitude and phase of the forward wave; it is the same wave present on the other side of the detector. Subtracting this known wave from the wave present at the line input yields the reflected wave. Properly designed, a bridge circuit can be used not only to indicate a match, but the degree of mismatch - thus making it possible to calculate the SWR. This usually involves alternately connecting the reference wave and the reflected wave to a power meter, and comparing the magnitudes of the resulting deflections.\n\nAn SWR meter does not measure the actual impedance of a load (the resistance and reactance), but only the mismatch ratio. To measure the actual impedance, an antenna analyzer or other similar RF measuring device is required. For accurate readings, the SWR meter must be matched to the line impedance, usually 50 or 75 ohms. To accommodate multiple impedances, some SWR meters have switches on the rear, to select the resistance appropriate for the sense lines.\n\nAn SWR meter should be connected to the line as close as possible to the antenna: All practical transmission lines have a certain amount of loss, which causes the reflected wave to be attenuated as it travels back along the line. Thus, the SWR is highest closest to the load, and only improves as the distance from the load increases, creating the false impression of a matched system.\n"}
{"id": "50235446", "url": "https://en.wikipedia.org/wiki?curid=50235446", "title": "Send My Bag", "text": "Send My Bag\n\nSend My Bag is a luggage shipping company for students, business professionals, relocators, travelers, sports enthusiasts and holiday makers. Their delivery of belongings is designed to allow travelers to travel light at a lower cost than airline fees. \n\nSend My Bag was formed after founder Adam Ewart was charged excess baggage fees when helping his girlfriend travel home from university. After paying the fee Ewart returned home and searched the web for a service which offered to deliver luggage at a lower cost. With nothing found, he decided to start Send My Bag. Setting up just one web page for under £100, he created a simple booking system for the business venture.\n\nPrior to 2011 Send My Bag primarily existed as a niche luggage shipper for students. From 2011 onwards, their focus broadened as airlines such as Ryanair took additional steps to dissuade passengers from checking bags, and as airline revenue from baggage fees worldwide dramatically increased.\n\nThe service is available as an iOS app.\n\nOn 9 September 2012, Ewart appeared on the BBC television program \"Dragons' Den\" in search of an investment for his door to door baggage service. \n\nFollowing the unsuccessful appearance on \"Dragons' Den\", Send My Bag announced a £100k funding from investors Lough Shore Investments. \n\nOn 24 November 2014 on CNBC news Ewart announced the launch of US worldwide services. In 2015 Send My Bag further expanded launching a US domestic service and worldwide services from Australia.\n\nSend My Bag provides 24hr worldwide support from offices in Bangor, Northern Ireland and New York City.\n\nIn celebration of Queen Elizabeth II's 92nd birthday, on 21 April 2018, Send My Bag was announced as winner of the Queen's Awards for Enterprise. At the time of winning the award Send My Bag had shipped 250,000 pieces of luggage in the previous 12 months and collected over 30,000 online reviews.\n"}
{"id": "58752874", "url": "https://en.wikipedia.org/wiki?curid=58752874", "title": "Service design sprint", "text": "Service design sprint\n\nA Service design sprint is a time-constrained, service design project that uses design thinking and service design tools to create a new service or improve an existing one. The name Service Design Sprint was first mentioned in 2014 in the book The Service Startup: Design Thinking Gets Lean written by Tenny Pinheiro.(Elsevier 2014. The MVS - Minimum Valuable Service - model to Service Design Sprint described in the book combine Agile based approaches with design tools to help product development teams understand, co-design and prototype complex service scenarios with low resources and within the timespan of a week. Since then, the Service Design Sprint approach has become popular with many different approaches surfacing and being used by startup incubators, institutions like the university of Lapland in Finland, the MIT along with service-driven corporations in many different sectors of the economy. \n\nThe Minimum Valuable Service model is divided into four phases each containing a set of Design Sprint tools.\n"}
{"id": "12978137", "url": "https://en.wikipedia.org/wiki?curid=12978137", "title": "Solid ground floor", "text": "Solid ground floor\n\nA solid ground floor consists of a layer of concrete, which in the case of a domestic building will be the surface layer brought up to ground floor level with hardcore filling under it. The advantage of a solid ground floor is the elimination of dry rot and other problems normally associated with hollow joisted floors. The disadvantage is that the floor is less resilient to walk upon and may be more tiring for the user. Solid ground floors are usually found or situated in a kitchen but will be necessary for other rooms where wood blocks and other similar finishes are required. \nCement screed: The concrete floor may be topped with a 25 mm thick cement and sand screed trowelled to a smooth finish. The usual mix is 1:3 and a colouring agent may be added to the mix to obtain a more attractive finish. The mix should be as dry as possible and the sand should be coarsely graded and clean to avoid shrinkage and cracking which might occur with a wet mix. The floor finish is carefully cured after laying.\n\nGranolithic: Granolithic is composed of cement and fine aggregate mortar, the aggregate being granite chippings, which will give the hard wearing quality of the finish. It will be laid with screed, trowelled or floated to an even and fine finish. Granolithic paving will be suitable in areas which are to receive hard wear although its appearance would not normally be suitable for internal domestic work. \n\nPVC tiles: Polyvinyl chloride tiles -These are another commonly used floor finish. After the floor has been laid with screed, these tiles are fixed with adhesive. They are attractive, smooth and cool, and damage can be repaired very easily as they are made in small square size, usually 150 mm to 225 mm. Though due to poor workmanship and dust this type of floor finish fails through lifting.\n\nTerrazo: Terrazo consists of a coloured element binder or matrix and marble chips mixed to specified proportions. The finish is hardwearing, attractive and resistant to chemical attack. Ebonite strips divide the terrazo into bays to avoid shrinkage and expansion.\n\n"}
{"id": "18348644", "url": "https://en.wikipedia.org/wiki?curid=18348644", "title": "Soundcast", "text": "Soundcast\n\nSoundcast LLC is a privately funded company that creates wireless audio technologies for the consumer & commercial markets. The company is headquartered in San Diego, California.\n\nSoundcast is a producer of wireless audio transmission systems that overcome 2.4GHz band interference, and allow digital music to be listened to in stereo throughout the home or building through its proprietary wireless technology, Bluetooth®, DTS Play-Fi® and can be paired with Alexa®. \n\nThe Soundcast product line has grown in stages since 2006. The first product, the AudioCast, was designed to create a bridge between an audio source and an audio speaker. With this creation came the G2 systems technology. Since then, the list of products has expanded by building on the G2 system first developed for the AudioCast. \nSome of the current products are:\n\nThe Take Anywhere, Everywhere, Premium Waterproof Speaker\n\nStunning audio performance belies its hand-held form. Dual aluminum drivers and weighted rear-firing passive radiator deliver rich, studio accuracy audio with real bass response you can hear. The VG1 is a rugged take-anywhere, everywhere design and fully waterproof. Whether it’s at the pool, the gym, hiking or just hanging at the hotel, the VG1 is the perfect travel companion no matter the destination. \n\nIt streams music from a mobile device. No additional software necessary. It also has a plug in audio source via 3.5mm mini jack and an output plug as well. The VG1 not only works as a hands free Bluetooth speakerphone, it can also communicate and issue commands with Siri. Sync two VG1 speakers together for dedicated left and right playback with Bluetooth True Wireless Stereo (TWS). No additional software necessary!\n\n\nMelody streams music wirelessly and delivers omni-directional beautifully precise sound out of its 8-speaker bi-amped system with the latest Bluetooth® v3.0 technology. Some of its many features:\n\nThe OutCast is SoundCast Systems flagship product and perhaps the most well known of all their products. It is a weather-resistant, wireless speaker that lets you enjoy rich multi-directional stereo sound throughout the house, the yard, the patio and even on a boat/RV. With broadcast range of up to 300 feet, this powerful wireless speaker receives transmissions through walls, floors, and ceilings without the hassle of running wires.\n\nOutCast Jr. is a highly portable wireless speaker system that features multiple drivers, 3-amplifiers, a down-firing built-in subwoofer, volume/track control with Soundcast’s optional UAT and iCast transmitters – Pick it up, move it and listen to music anywhere! It's Weather-Resistant, plays on included rechargeable batteries up to 20 hours.\n\nSurroundCast - a wireless rear or side speaker amplifier system. It consists of a transmitter with speaker level inputs and an amplified receiver module with 60 watts of digital power and speaker level outputs. The system allows you to set up any brand of surround speakers without the need for front to back of room wires. The system has a low latency (15 ms) and is a quick and easy installation. No programming, no fuss. Just great audio.\nNote: SurroundCast is not compatible with any other Soundcast wireless products\n\nAn exciting alternative to WIRES! SubCast allows any subwoofer to play wireless. It is also a full range transmitter - receiver system. It will transmit 20-20K Hertz and can be used to support full audio, not just Low Frequency Effects. It is marketed as a Sub kit but has many more very flexible uses. There is latency adjustment to 64Ms for longer range applications. No programming, no assigning IP addresses, just plug Sub \"out\" into SubCast transmitter and power it up, then plug Receiver module into Subwoofer inputs and power it up.\n\nSoundcast forms a wireless bridge between an audio source like an MP3 player and an audio sound system with plug-n-play setup. Soundcast's audio products incorporate 2.4 GHz wireless technology. The Soundcast engineering team refined this wireless technology to avoid interference from other appliances like the microwave oven or the cordless phone. The wireless range is reported to be up to 350 feet.\n\nSoundcast employs Spread Spectrum technology. This is widely regarded as the most effective method of achieving effective communication in the 2.4GHz ISM band. There are two principle ways this can be done: Frequency Hopping Spread Spectrum (FHSS)—such as used by Bluetooth, and Direct Sequencing Spread Spectrum (DSSS)—such as used by 802.11b. Soundcast G2 transceivers use FHSS. This allows as many as three Soundcast G2 systems to operate in close proximity to each other. This also allows for wireless audio to be securely used in high density multi-unit dwellings (MUD). The platform also provides the flexibility of being configured as a one transmitter one receiver system or a one transmitter multiple receiver system. The Soundcast G2 module integrates the RF physical layer, baseband, MAC protocol, audio CODEC, and dynamic error correction functions. Hardware forward error correction, adaptive frequency hopping, and dynamic hopping channel diversity are all built into the protocol of the system. The system also supports bi-directional communication for acknowledging and retransmission should packet loss occur.\n\nSoundcast's products are RoHS compliant. This is a directive which restricts the use of certain hazardous substances in electrical and electronic equipment. This directive bans from the market new electrical and electronic equipment containing more than agreed to levels of lead, cadmium, mercury hexavalent chromium, polybrominated biphenyl (PBB) and polybrominated biphenyl Ether (PBDE) flame retardants.\n\n"}
{"id": "313416", "url": "https://en.wikipedia.org/wiki?curid=313416", "title": "Spectrum analyzer", "text": "Spectrum analyzer\n\nA spectrum analyzer measures the magnitude of an input signal versus frequency within the full frequency range of the instrument. The primary use is to measure the power of the spectrum of known and unknown signals. The input signal that a spectrum analyzer measures is electrical; however, spectral compositions of other signals, such as acoustic pressure waves and optical light waves, can be considered through the use of an appropriate transducer. Optical spectrum analyzers also exist, which use direct optical techniques such as a monochromator to make measurements.\n\nBy analyzing the spectra of electrical signals, dominant frequency, power, distortion, harmonics, bandwidth, and other spectral components of a signal can be observed that are not easily detectable in time domain waveforms. These parameters are useful in the characterization of electronic devices, such as wireless transmitters.\n\nThe display of a spectrum analyzer has frequency on the horizontal axis and the amplitude displayed on the vertical axis. To the casual observer, a spectrum analyzer looks like an oscilloscope and, in fact, some lab instruments can function either as an oscilloscope or a spectrum analyzer.\n\nThe first spectrum analyzers, in the 1960s, were swept-tuned instruments.\n\nFollowing the discovery of the fast Fourier transform (FFT) in 1965, the first FFT-based analyzers were introduced in 1967.\n\nToday, there are three basic types of analyzer: the swept-tuned spectrum analyzer, the vector signal analyzer, and the real-time spectrum analyzer.\n\nSpectrum analyzer types are distinguished by the methods used to obtain the spectrum of a signal. There are swept-tuned and Fast Fourier Transform (FFT) based spectrum analyzers:\n\n\nSpectrum analyzers tend to fall into four form factors: benchtop, portable, handheld and networked.\n\nThis form factor is useful for applications where the spectrum analyzer can be plugged into AC power, which generally means in a lab environment or production/manufacturing area. Bench top spectrum analyzers have historically offered better performance and specifications than the portable or handheld form factor. Bench top spectrum analyzers normally have multiple fans (with associated vents) to dissipate heat produced by the processor. Due to their architecture, bench top spectrum analyzers typically weigh more than . Some bench top spectrum analyzers offer optional battery packs, allowing them to be used away from AC power. This type of analyzer is often referred to as a \"portable\" spectrum analyzer.\n\nThis form factor is useful for any applications where the spectrum analyzer needs to be taken outside to make measurements or simply carried while in use. Attributes that contribute to a useful portable spectrum analyzer include:\n\nThis form factor is useful for any application where the spectrum analyzer needs to be very light and small. Handheld analyzers usually offer a limited capability relative to larger systems. Attributes that contribute to a useful handheld spectrum analyzer include:\n\nThis form factor does not include a display and these devices are designed to enable a new class of geographically-distributed spectrum monitoring and analysis applications. The key attribute is the ability to connect the analyzer to a network and monitor such devices across a network. While many spectrum analyzers have an Ethernet port for control, they typically lack efficient data transfer mechanisms and are too bulky or expensive to be deployed in such a distributed manner. Key applications for such devices include RF intrusion detection systems for secure facilities where wireless signaling is prohibited. As well cellular operators are using such analyzers to remotely monitor interference in licensed spectral bands. The distributed nature of such devices enable geo-location of transmitters, spectrum monitoring for dynamic spectrum access and many other such applications.\n\nKey attributes of such devices include:\n\nAs discussed above in types, a swept-tuned spectrum analyzer down-converts a portion of the input signal spectrum to the center frequency of a band-pass filter by sweeping the voltage-controlled oscillator through a range of frequencies, enabling the consideration of the full frequency range of the instrument.\n\nThe bandwidth of the band-pass filter dictates the resolution bandwidth, which is related to the minimum bandwidth detectable by the instrument. As demonstrated by the animation to the right, the smaller the bandwidth, the more spectral resolution. However, there is a trade-off between how quickly the display can update the full frequency span under consideration and the frequency resolution, which is relevant for distinguishing frequency components that are close together. For a swept-tuned architecture, this relation for sweep time is useful:\n\nWhere ST is sweep time in seconds, k is proportionality constant, Span is the frequency range under consideration in hertz, and RBW is the resolution bandwidth in Hertz.\nSweeping too fast, however, causes a drop in displayed amplitude and a shift in the displayed frequency.\n\nAlso, the animation contains both up- and down-converted spectra, which is due to a frequency mixer producing both sum and difference frequencies. The local oscillator feedthrough is due to the imperfect isolation from the IF signal path in the mixer.\n\nFor very weak signals, a pre-amplifier is used, although harmonic and intermodulation distortion may lead to the creation of new frequency components that were not present in the original signal.\n\nWith an FFT based spectrum analyzer, the frequency resolution is formula_2, the inverse of the time \"T\" over which the waveform is measured and Fourier transformed.\n\nWith Fourier transform analysis in a digital spectrum analyzer, it is necessary to sample the input signal with a sampling frequency formula_3 that is at least twice the bandwidth of the signal, due to the Nyquist limit. A Fourier transform will then produce a spectrum containing all frequencies from zero to formula_4. This can place considerable demands on the required analog-to-digital converter and processing power for the Fourier transform, making FFT based spectrum analyzers limited in frequency range.\nSince FFT based analyzers are only capable of considering narrow bands, one technique is to combine swept and FFT analysis for consideration of wide and narrow spans. This technique allows for faster sweep time.\n\nThis method is made possible by first down converting the signal, then digitizing the intermediate frequency and using superheterodyne or FFT techniques to acquire the spectrum.\n\nOne benefit of digitizing the intermediate frequency is the ability to use digital filters, which have a range of advantages over analog filters such as near perfect shape factors and improved filter settling time. Also, for consideration of narrow spans, the FFT can be used to increase sweep time without distorting the displayed spectrum.\n\nA realtime spectrum analyser does not have any such blind time—up to some maximum span, often called the \"realtime bandwidth\". The analyser is able to sample the incoming RF spectrum in the time domain and convert the information to the frequency domain using the FFT process. FFT's are processed in parallel, gapless and overlapped so there are no gaps in the calculated RF spectrum and no information is missed.\n\nIn a sense, any spectrum analyzer that has vector signal analyzer capability is a realtime analyzer. It samples data fast enough to satisfy Nyquist Sampling theorem and stores the data in memory for later processing. This kind of analyser is only realtime for the amount of data / capture time it can store in memory and still produces gaps in the spectrum and results during processing time.\n\nMinimizing distortion of information is important in all spectrum analyzers. The FFT process applies windowing techniques to improve the output spectrum due to producing less side lobes. The effect of windowing may also reduce the level of a signal where it is captured on the boundary between one FFT and the next. For this reason FFT's in a Realtime spectrum analyzer are overlapped. Overlapping rate is approximately 80%. An analyzer that utilises a 1024-point FFT process will re-use approximately 819 samples from the previous FFT process.\n\nThis is related to the sampling rate of the analyser and the FFT rate. It is also important for the realtime spectrum analyzer to give good level accuracy.\n\nExample: for an analyser with of realtime bandwidth (the maximum RF span that can be processed in realtime) approximately (complex) are needed. If the spectrum analyzer produces an FFT calculation is produced every For a FFT a full spectrum is produced approximately every This also gives us our overlap rate of 80% \n\nRealtime spectrum analyzers are able to produce much more information for users to examine the frequency spectrum in more detail. A normal swept spectrum analyzer would produce max peak, min peak displays for example but a realtime spectrum analyzer is able to plot all calculated FFT's over a given period of time with the added colour-coding which represents how often a signal appears. For example, this image shows the difference between how a spectrum is displayed in a normal swept spectrum view and using a \"Persistence\" view on a realtime spectrum analyzer.\n\nRealtime spectrum analyzers are able to see signals hidden behind other signals. This is possible because no information is missed and the display to the user is the output of FFT calculations. An example of this can be seen on the right.\n\nIn a typical spectrum analyzer there are options to set the start, stop, and center frequency. The frequency halfway between the stop and start frequencies on a spectrum analyzer display is known as the center frequency. This is the frequency that is in the middle of the display’s frequency axis. Span specifies the range between the start and stop frequencies. These two parameters allow for adjustment of the display within the frequency range of the instrument to enhance visibility of the spectrum measured.\n\nAs discussed in the operation section, the resolution bandwidth filter or RBW filter is the bandpass filter in the IF path. It's the bandwidth of the RF chain before the detector (power measurement device). It determines the RF noise floor and how close two signals can be and still be resolved by the analyzer into two separate peaks. Adjusting the bandwidth of this filter allows for the discrimination of signals with closely spaced frequency components, while also changing the measured noise floor. Decreasing the bandwidth of an RBW filter decreases the measured noise floor and vice versa. This is due to higher RBW filters passing more frequency components through to the envelope detector than lower bandwidth RBW filters, therefore a higher RBW causes a higher measured noise floor.\n\nThe video bandwidth filter or VBW filter is the low-pass filter directly after the envelope detector. It's the bandwidth of the signal chain after the detector. Averaging or peak detection then refers to how the digital storage portion of the device records samples—it takes several samples per time step and stores only one sample, either the average of the samples or the highest one. The video bandwidth determines the capability to discriminate between two different power levels. This is because a narrower VBW will remove noise in the detector output. This filter is used to “smooth” the display by removing noise from the envelope. Similar to the RBW, the VBW affects the sweep time of the display if the VBW is less than the RBW. If VBW is less than RBW, this relation for sweep time is useful:\n\nHere \"t\" is the sweep time, \"k\" is a dimensionless proportionality constant, \"f\" − \"f\" is the frequency range of the sweep, RBW is the resolution bandwidth, and VBW is the video bandwidth.\n\nWith the advent of digitally based displays, some modern spectrum analyzers use analog-to-digital converters to sample spectrum amplitude after the VBW filter. Since displays have a discrete number of points, the frequency span measured is also digitised. Detectors are used in an attempt to adequately map the correct signal power to the appropriate frequency point on the display. There are in general three types of detectors: sample, peak, and average\n\nThe Displayed Average Noise Level (DANL) is just what it says it is—the average noise level displayed on the analyzer. This can either be with a specific resolution bandwidth (e.g. −120 dBm @1 kHz RBW), or normalized to 1 Hz (usually in dBm/Hz) e.g. −170 dBm(Hz).This is also called the sensitivity of the spectrum analyzer. If a signal level equal to the average noise level is fed there will be a 3 dB display. To increase the sensitivity of the spectrum analyzer a preamplifier with lower noise figure may be connected at the input of the spectrum analyzer. co\n\nSpectrum analyzers are widely used to measure the frequency response, noise and distortion characteristics of all kinds of radio-frequency (RF) circuitry, by comparing the input and output spectra.For example, in RF mixers, spectrum analyzer is used to find the levels of third order inter-modulation products and conversion loss. In RF oscillators, spectrum analyzer is used to find the levels of different harmonics.\n\nIn telecommunications, spectrum analyzers are used to determine occupied bandwidth and track interference sources. For example, cell planners use this equipment to determine interference sources in the GSM frequency bands and UMTS frequency bands.\n\nIn EMC testing, a spectrum analyzer is used for basic precompliance testing; however, it can not be used for full testing and certification. Instead, an EMI receiver is used.\n\nA spectrum analyzer is used to determine whether a wireless transmitter is working according to defined standards for purity of emissions. Output signals at frequencies other than the intended communications frequency appear as vertical lines (pips) on the display. A spectrum analyzer is also used to determine, by direct observation, the bandwidth of a digital or analog signal.\n\nA spectrum analyzer interface is a device that connects to a wireless receiver or a personal computer to allow visual detection and analysis of electromagnetic signals over a defined band of frequencies. This is called panoramic reception and it is used to determine the frequencies of sources of interference to wireless networking equipment, such as Wi-Fi and wireless routers.\n\nSpectrum analyzers can also be used to assess RF shielding. RF shielding is of particular importance for the siting of a magnetic resonance imaging machine since stray RF fields would result in artifacts in an MR image.\n\nSpectrum analysis can be used at audio frequencies to analyse the harmonics of an audio signal. A typical application is to measure the distortion of a nominally sinewave signal; a very-low-distortion sinewave is used as the input to equipment under test, and a spectrum analyser can examine the output, which will have added distortion products, and determine the percentage distortion at each harmonic of the fundamental. Such analysers were at one time described as \"wave analysers\". Analysis can be carried out by a general-purpose digital computer with a sound card selected for suitable performance and appropriate software. Instead of using a low-distortion sinewave, the input can be subtracted from the output, attenuated and phase-corrected, to give only the added distortion and noise, which can be analysed.\n\nAn alternative technique, total harmonic distortion measurement, cancels out the fundamental with a notch filter and measures the total remaining signal, which is total harmonic distortion plus noise; it does not give the harmonic-by-harmonic detail of an analyser.\n\nSpectrum analyzers are also used by audio engineers to assess their work. In these applications, the spectrum analyzer will show volume levels of frequency bands across the typical range of human hearing, rather than displaying a wave. In live sound applications, engineers can use them to pinpoint feedback.\n\nAn optical spectrum analyzer uses reflective or refractive techniques to separate out the wavelengths of light. An electro-optical detector is used to measure the intensity of the light, which is then normally displayed on a screen in a similar manner to a radio- or audio-frequency spectrum analyzer.\n\nThe input to an optical spectrum analyzer may be simply via an aperture in the instrument's case, an optical fiber or an optical connector to which a fiber-optic cable can be attached.\n\nDifferent techniques exist for separating out the wavelengths. One method is to use a monochromator, for example a Czerny–Turner design, with an optical detector placed at the output slit. As the grating in the monochromator moves, bands of different frequencies (colors) are 'seen' by the detector, and the resulting signal can then be plotted on a display. More precise measurements (down to MHz in the optical spectrum) can be made with a scanning Fabry–Pérot interferometer along with analog or digital control electronics, which sweep the resonant frequency of an optically resonant cavity using a voltage ramp to piezoelectric motor that varies the distance between two highly reflective mirrors. A sensitive photodiode embedded in the cavity provides an intensity signal, which is plotted against the ramp voltage to produce a visual representation of the optical power spectrum.\n\nThe frequency response of optical spectrum analyzers tends to be relatively limited, e.g. (near-infrared), depending on the intended purpose, although (somewhat) wider-bandwidth general purpose instruments are available.\n\nA vibration spectrum analyzer allows to analyze vibration amplitudes at various component frequencies, In this way, vibration occurring at specific frequencies can be identified and tracked. Since particular machinery problems generate vibration at specific frequencies, machinery faults can be detected or diagnosed. Vibration Spectrum Analyzers use the signal from different types of sensor, such as: accelerometers, velocity transducers and proximity sensors. The uses of a vibration spectrum analyzer in machine condition monitoring allows to detect and identify machine faults such as: rotor imbalance, shaft misalignment, mechanical looseness, bearing defects, among others. Vibration analysis can also be used in structures to identify structural resonances or to perform modal analysis.\n\n\n"}
{"id": "23922168", "url": "https://en.wikipedia.org/wiki?curid=23922168", "title": "Telepresence technology", "text": "Telepresence technology\n\nTelepresence technology is a term used by the National Oceanic and Atmospheric Administration (NOAA) to refer to the combination of satellite technology with the Internet to broadcast information, including video in real-time from cameras used on its remotely operated vehicle (ROV) on \"Okeanos Explorer\". Its ROV will be operating working in a deep sea environment. Data from the ROV is transmitted to a hub based on the land, which then send it to scientists and to the public.\n\nThis effort of the \"Okeanos Explorer\" has been compared to the lunar landing.\n\nThe telepresence technology used by NOAA includes the following:\nThe \"Okeanos Explorer\" is designed as an educational tool that can be followed on Twitter.\n"}
{"id": "7105786", "url": "https://en.wikipedia.org/wiki?curid=7105786", "title": "Trans-Pacific Profiler Network", "text": "Trans-Pacific Profiler Network\n\nThe Trans-Pacific Profiler Network (usually abbreviated as TPPN) is a system in which wind profilers are installed on six remote island sites to collect information from data sparse areas in the tropical Pacific Ocean. It is operated by the Aeronomy Laboratory of the National Oceanic and Atmospheric Administration (NOAA) together with the Joint Institute at the University of Colorado.\n\nVarious types of Information about the atmosphere, such as precipitation and wind motions, are recorded. These data help in weather forecasting as well as predicting meteorological phenomena like El Niño.\n"}
{"id": "827863", "url": "https://en.wikipedia.org/wiki?curid=827863", "title": "Transfer case", "text": "Transfer case\n\nA transfer case is a part of the drivetrain of four-wheel-drive, all-wheel-drive, and other multiple powered axle vehicles. The transfer case transfers power from the transmission to the front and rear axles by means of drive shafts. It also synchronizes the difference between the rotation of the front and rear wheels, and may contain one or more sets of low range gears for off-road use.\n\n\nTransfer cases used on \"part-time\" four-wheel-drive off-road vehicles such as trucks, truggies, rock-crawling vehicles, and some military vehicles generally allow the driver to select 2WD or 4WD, as well as high or low gear ranges. Those used in sports cars and performance sedans are usually \"transparent\" to the driver; there is no shifter or select lever.\n\nThere are two different types of internal power-transfer mechanism found in most transfer cases. Gear-driven transfer cases use sets of gears to drive either the front or both the front and rear driveshafts. These are generally strong, heavy units that are used in large trucks, but there are currently several gear drive cases in production for passenger cars.\n\nChain-driven transfer cases use a chain to drive most often only one axle, but can drive both axles. Chain-driven transfer cases are quieter and lighter than gear-driven ones. They are used in vehicles such as compact trucks, full size trucks, Jeeps and SUVs. Some off-road driving enthusiasts modify their vehicles to use gear-driven transfer cases, accepting the additional weight and noise to gain the extra strength they generally provide.\n\nTransfer cases are also classified as either \"divorced\"/independent or \"married\". Married transfer cases are bolted directly to the transmission, usually between the transmission's output shaft and the rear or main driveshaft. Sometimes a married transfer case is an integral part of the transmission and the two components share the same housing or \"case\", as is commonly found on recent Subaru products and some other all-wheel-drive cars.\n\nA divorced or independent transfer case is completely separate from the transmission. It is located further down the driveline than a married transfer case and connected to the transmission output shaft by a short driveshaft. Independent transfer cases are used on very long wheelbase vehicles, such as commercial trucks or military trucks.\n\nManual Shift On-the-Fly transfer cases have a selector lever on the driver's side floor transmission hump and may also have either two sealed automatic front axle locking hubs or two manual front axle hub selectors of \"LOCK\" and \"UNLOCK\" or \"FREE\". To engage the four-wheel-drive system the vehicle must be moving at a low speed, the speed at which 4x4 can be engaged depends on the vehicle. This is only for the four-wheel-drive high setting. To engage the four-wheel-drive low setting, the vehicle must be stopped and the transmission must be shifted to neutral, then the four-wheel-drive low can be selected.\n\nElectronic Shift On-the-Fly (ESOF) transfer cases have a dash-mounted selector switch or buttons with front sealed automatic locking axle hubs or drive flanges. Unlike the manual transfer case, this system has a transfer case motor. To engage the four-wheel-drive system the vehicle must be moving at a lower speeds, the speed at which 4x4 can be engaged depends on the vehicle. This is only for the four-wheel-drive high setting. To engage the four-wheel-drive low setting, the vehicle must be stopped and the transmission must be shifted to neutral, then the four-wheel-drive low can be selected.\n\n"}
