{"id": "8340209", "url": "https://en.wikipedia.org/wiki?curid=8340209", "title": "Alternative fuel vehicle", "text": "Alternative fuel vehicle\n\nAn alternative fuel vehicle is a vehicle that runs on a fuel other than traditional petroleum fuels (petrol or Diesel fuel); and also refers to any technology of powering an engine that does not involve solely petroleum (e.g. electric car, hybrid electric vehicles, solar powered). Because of a combination of factors, such as environmental concerns, high oil prices and the potential for peak oil, development of cleaner alternative fuels and advanced power systems for vehicles has become a high priority for many governments and vehicle manufacturers around the world.\n\nHybrid electric vehicles such as the Toyota Prius are not actually alternative fuel vehicles, but through advanced technologies in the electric battery and motor/generator, they make a more efficient use of petroleum fuel. Other research and development efforts in alternative forms of power focus on developing all-electric and fuel cell vehicles, and even the stored energy of compressed air.\n\nAn environmental analysis extends beyond just the operating efficiency and emissions. A life-cycle assessment of a vehicle involves production and post-use considerations. A cradle-to-cradle design is more important than a focus on a single factor such as the type of fuel.\n\n, there were more than 1.4 billion motor vehicles on the world's roads, compared with just more than 116 million alternative fuel and advanced technology vehicles that had been sold or converted worldwide at the end of 2016 and consisting of:\n\n\n\nThe air engine is an emission-free piston engine that uses compressed air as a source of energy. The first compressed air car was invented by a French engineer named Guy Nègre. The expansion of compressed air may be used to drive the pistons in a modified piston engine. Efficiency of operation is gained through the use of environmental heat at normal temperature to warm the otherwise cold expanded air from the storage tank. This non-adiabatic expansion has the potential to greatly increase the efficiency of the machine. The only exhaust is cold air (−15 °C), which could also be used to air condition the car. The source for air is a pressurized carbon-fiber tank. Air is delivered to the engine via a rather conventional injection system. Unique crank design within the engine increases the time during which the air charge is warmed from ambient sources and a two-stage process allows improved heat transfer rates.\n\nBattery electric vehicles (BEVs), also known as all-electric vehicles (AEVs), are electric vehicles whose main energy storage is in the chemical energy of batteries. BEVs are the most common form of what is defined by the California Air Resources Board (CARB) as zero emission vehicle (ZEV) because they produce no tailpipe emissions at the point of operation. The electrical energy carried on board a BEV to power the motors is obtained from a variety of battery chemistries arranged into battery packs. For additional range genset trailers or pusher trailers are sometimes used, forming a type of hybrid vehicle. Batteries used in electric vehicles include \"flooded\" lead-acid, absorbed glass mat, NiCd, nickel metal hydride, Li-ion, Li-poly and zinc-air batteries.\n\nAttempts at building viable, modern battery-powered electric vehicles began in the 1950s with the introduction of the first modern (transistor controlled) electric car – the Henney Kilowatt, even though the concept was out in the market since 1890. Despite the poor sales of the early battery-powered vehicles, development of various battery-powered vehicles continued through the mid-1990s, with such models as the General Motors EV1 and the Toyota RAV4 EV.\n\nBattery powered cars had primarily used lead-acid batteries and NiMH batteries. Lead-acid batteries' recharge capacity is considerably reduced if they're discharged beyond 75% on a regular basis, making them a less-than-ideal solution. NiMH batteries are a better choice, but are considerably more expensive than lead-acid. Lithium-ion battery powered vehicles such as the Venturi Fetish and the Tesla Roadster have recently demonstrated excellent performance and range, and nevertheless is used in most mass production models launched since December 2010.\n\n, several neighborhood electric vehicles, city electric cars and series production highway-capable electric cars and utility vans have been made available for retails sales, including Tesla Roadster, GEM cars, Buddy, Mitsubishi i MiEV and its rebadged versions Peugeot iOn and Citroën C-Zero, Chery QQ3 EV, JAC J3 EV, Nissan Leaf, Smart ED, Mia electric, BYD e6, Renault Kangoo Z.E., Bolloré Bluecar, Renault Fluence Z.E., Ford Focus Electric, BMW ActiveE, Renault Twizy, Tesla Model S, Honda Fit EV, RAV4 EV second generation, Renault Zoe, Mitsubishi Minicab MiEV, Roewe E50, Chevrolet Spark EV, Fiat 500e, BMW i3, Volkswagen e-Up!, Nissan e-NV200, Volkswagen e-Golf, Mercedes-Benz B-Class Electric Drive, Kia Soul EV, BYD e5, and Tesla Model X. The world's all-time top selling highway legal electric car is the Nissan Leaf, released in December 2010, with global sales of more than 250,000 units through December 2016. The Tesla Model S, released in June 2012, ranks second with global sales of over 158,000 cars delivered . The Renault Kangoo Z.E. utility van is the leader of the light-duty all-electric segment with global sales of 25,205 units through December 2016.\n\nA solar car is an electric vehicle powered by solar energy obtained from solar panels on the car. Solar panels cannot currently be used to directly supply a car with a suitable amount of power at this time, but they can be used to extend the range of electric vehicles. They are raced in competitions such as the World Solar Challenge and the North American Solar Challenge. These events are often sponsored by Government agencies such as the United States Department of Energy keen to promote the development of alternative energy technology such as solar cells and electric vehicles. Such challenges are often entered by universities to develop their students engineering and technological skills as well as motor vehicle manufacturers such as GM and Honda.\nThe North American Solar Challenge is a solar car race across North America. Originally called Sunrayce, organized and sponsored by General Motors in 1990, it was renamed American Solar Challenge in 2001, sponsored by the United States Department of Energy and the National Renewable Energy Laboratory. Teams from universities in the United States and Canada compete in a long distance test of endurance as well as efficiency, driving thousands of miles on regular highways.\n\nNuna is the name of a series of manned solar powered vehicles that won the World solar challenge in Australia three times in a row, in 2001 (Nuna 1 or just Nuna), 2003 (Nuna 2) and 2005 (Nuna 3). The Nunas are built by students of the Delft University of Technology.\n\nThe World solar challenge is a solar powered car race over through central Australia from Darwin to Adelaide. The race attracts teams from around the world, most of which are fielded by universities or corporations although some are fielded by high schools.\n\nTrev (two-seater renewable energy vehicle) was designed by the staff and students at the University of South Australia. Trev was first displayed at the 2005 World Solar Challenge as the concept of a low-mass, efficient commuter car. With 3 wheels and a mass of about 300 kg, the prototype car had maximum speed of 120 km/h and acceleration of 0–100 km/h in about 10 seconds. The running cost of Trev is projected to be less than 1/10 of the running cost of a small petrol car.\nDimethyl ether (DME) is a promising fuel in diesel engines, petrol engines (30% DME / 70% LPG), and gas turbines owing to its high cetane number, which is 55, compared to diesel's, which is 40–53. Only moderate modification are needed to convert a diesel engine to burn DME. The simplicity of this short carbon chain compound leads during combustion to very low emissions of particulate matter, NO, CO. For these reasons as well as being sulfur-free, DME meets even the most stringent emission regulations in Europe (EURO5), U.S. (U.S. 2010), and Japan (2009 Japan). Mobil is using DME in their methanol to gasoline process.\n\nDME is being developed as a synthetic second generation biofuel (BioDME), which can be manufactured from lignocellulosic biomass. Currently the EU is considering BioDME in its potential biofuel mix in 2030; the Volvo Group is the coordinator for the European Community Seventh Framework Programme project BioDME where Chemrec's BioDME pilot plant based on black liquor gasification is nearing completion in Piteå, Sweden.\n\nAmmonia is produced by combining gaseous hydrogen with nitrogen from the air. Large-scale ammonia production uses natural gas for the source of hydrogen. Ammonia was used during World War II to power buses in Belgium, and in engine and solar energy applications prior to 1900. Liquid ammonia also fuelled the Reaction Motors XLR99 rocket engine, that powered the X-15 hypersonic research aircraft. Although not as powerful as other fuels, it left no soot in the reusable rocket engine and its density approximately matches the density of the oxidizer, liquid oxygen, which simplified the aircraft's design.\n\nAmmonia has been proposed as a practical alternative to fossil fuel for internal combustion engines. The calorific value of ammonia is 22.5 MJ/kg (9690 BTU/lb), which is about half that of diesel. In a normal engine, in which the water vapour is not condensed, the calorific value of ammonia will be about 21% less than this figure. It can be used in existing engines with only minor modifications to carburettors/injectors.\n\nIf produced from coal, the CO can be readily sequestered (the combustion products are nitrogen and water).\n\nAmmonia engines or ammonia motors, using ammonia as a working fluid, have been proposed and occasionally used. The principle is similar to that used in a fireless locomotive, but with ammonia as the working fluid, instead of steam or compressed air. Ammonia engines were used experimentally in the 19th century by Goldsworthy Gurney in the UK and in streetcars in New Orleans. In 1981 a Canadian company converted a 1981 Chevrolet Impala to operate using ammonia as fuel.\n\nAmmonia and GreenNH3 is being used with success by developers in Canada, since it can run in spark ignited or diesel engines with minor modifications, also the only green fuel to power jet engines, and despite its toxicity is reckoned to be no more dangerous than petrol or LPG. It can be made from renewable electricity, and having half the density of petrol or diesel can be readily carried in sufficient quantities in vehicles. On complete combustion it has no emissions other than nitrogen and water vapour. The combustion chemical formula is 4 NH3 + 3 O2 → 2 N2 + 6 H2O, 75% water is the result.\n\nThe first commercial vehicle that used ethanol as a fuel was the Ford Model T, produced from 1908 through 1927. It was fitted with a carburetor with adjustable jetting, allowing use of gasoline or ethanol, or a combination of both. Other car manufactures also provided engines for ethanol fuel use. In the United States, alcohol fuel was produced in corn-alcohol stills until Prohibition criminalized the production of alcohol in 1919. The use of alcohol as a fuel for internal combustion engines, either alone or in combination with other fuels, lapsed until the oil price shocks of the 1970s. Furthermore, additional attention was gained because of its possible environmental and long-term economical advantages over fossil fuel.\n\nBoth ethanol and methanol have been used as an automotive fuel. While both can be obtained from petroleum or natural gas, ethanol has attracted more attention because it is considered a renewable resource, easily obtained from sugar or starch in crops and other agricultural produce such as grain, sugarcane, sugar beets or even lactose. Since ethanol occurs in nature whenever yeast happens to find a sugar solution such as overripe fruit, most organisms have evolved some tolerance to ethanol, whereas methanol is toxic. Other experiments involve butanol, which can also be produced by fermentation of plants. Support for ethanol comes from the fact that it is a biomass fuel, which addresses climate change and greenhouse gas emissions, though these benefits are now highly debated, including the heated 2008 food vs fuel debate.\n\nMost modern cars are designed to run on gasoline are capable of running with a blend from 10% up to 15% ethanol mixed into gasoline (E10-E15). With a small amount of redesign, gasoline-powered vehicles can run on ethanol concentrations as high as 85% (E85), the maximum set in the United States and Europe due to cold weather during the winter, or up to 100% (E100) in Brazil, with a warmer climate. Ethanol has close to 34% less energy per volume than gasoline, consequently fuel economy ratings with ethanol blends are significantly lower than with pure gasoline, but this lower energy content does not translate directly into a 34% reduction in mileage, because there are many other variables that affect the performance of a particular fuel in a particular engine, and also because ethanol has a higher octane rating which is beneficial to high compression ratio engines.\n\nFor this reason, for pure or high ethanol blends to be attractive for users, its price must be lower than gasoline to offset the lower fuel economy. As a rule of thumb, Brazilian consumers are frequently advised by the local media to use more alcohol than gasoline in their mix only when ethanol prices are 30% lower or more than gasoline, as ethanol price fluctuates heavily depending on the results and seasonal harvests of sugar cane and by region. In the US, and based on EPA tests for all 2006 E85 models, the average fuel economy for E85 vehicles was found 25.56% lower than unleaded gasoline. The EPA-rated mileage of current American flex-fuel vehicles could be considered when making price comparisons, though E85 has octane rating of about 104 and could be used as a substitute for premium gasoline. Regional retail E85 prices vary widely across the US, with more favorable prices in the Midwest region, where most corn is grown and ethanol produced. In August 2008 the US average spread between the price of E85 and gasoline was 16.9%, while in Indiana was 35%, 30% in Minnesota and Wisconsin, 19% in Maryland, 12 to 15% in California, and just 3% in Utah.</small> Depending of the vehicle capabilities, the break even price of E85 usually has to be between 25 and 30% lower than gasoline.\nReacting to the high price of oil and its growing dependence on imports, in 1975 Brazil launched the Pro-alcool program, a huge government-subsidized effort to manufacture ethanol fuel (from its sugar cane crop) and ethanol-powered automobiles. These ethanol-only vehicles were very popular in the 1980s, but became economically impractical when oil prices fell – and sugar prices rose – late in that decade. In May 2003 Volkswagen built for the first time a commercial ethanol flexible fuel car, the Gol 1.6 Total Flex. These vehicles were a commercial success and by early 2009 other nine Brazilian manufacturers are producing flexible fuel vehicles: Chevrolet, Fiat, Ford, Peugeot, Renault, Honda, Mitsubishi, Toyota, Citroën, and Nissan. The adoption of the flex technology was so rapid, that flexible fuel cars reached 87.6% of new car sales in July 2008. As of August 2008, the fleet of \"flex\" automobiles and light commercial vehicles had reached 6 million new vehicles sold, representing almost 19% of all registered light vehicles. The rapid success of \"flex\" vehicles, as they are popularly known, was made possible by the existence of 33,000 filling stations with at least one ethanol pump available by 2006, a heritage of the \"Pro-alcool\" program.\n\nIn the United States, initial support to develop alternative fuels by the government was also a response to the 1973 oil crisis, and later on, as a goal to improve air quality. Also, liquid fuels were preferred over gaseous fuels not only because they have a better volumetric energy density but also because they were the most compatible fuels with existing distribution systems and engines, thus avoiding a big departure from the existing technologies and taking advantage of the vehicle and the refueling infrastructure. California led the search of sustainable alternatives with interest in methanol.\nIn 1996, a new FFV Ford Taurus was developed, with models fully capable of running either methanol or ethanol blended with gasoline. This ethanol version of the Taurus was the first commercial production of an E85 FFV. The momentum of the FFV production programs at the American car companies continued, although by the end of the 90's, the emphasis was on the FFV E85 version, as it is today. Ethanol was preferred over methanol because there is a large support in the farming community and thanks to government's incentive programs and corn-based ethanol subsidies. Sweden also tested both the M85 and the E85 flexifuel vehicles, but due to agriculture policy, in the end emphasis was given to the ethanol flexifuel vehicles.\n\nThe main benefit of Diesel combustion engines is that they have a 44% fuel burn efficiency; compared with just 25–30% in the best gasoline engines. In addition diesel fuel has slightly higher Energy Density by volume than gasoline. This makes Diesel engines capable of achieving much better fuel economy than gasoline vehicles.\n\nBiodiesel (Fatty acid methyl ester), is commercially available in most oilseed-producing states in the United States. As of 2005, it is somewhat more expensive than fossil diesel, though it is still commonly produced in relatively small quantities (in comparison to petroleum products and ethanol). Many farmers who raise oilseeds use a biodiesel blend in tractors and equipment as a matter of policy, to foster production of biodiesel and raise public awareness. It is sometimes easier to find biodiesel in rural areas than in cities. Biodiesel has lower Energy Density than fossil diesel fuel, so biodiesel vehicles are not quite able to keep up with the fuel economy of a fossil fuelled diesel vehicle, if the diesel injection system is not reset for the new fuel. If the injection timing is changed to take account of the higher Cetane value of biodiesel, the difference in economy is negligible. Because biodiesel contains more oxygen than diesel or vegetable oil fuel, it produces the lowest emissions from diesel engines, and is lower in most emissions than gasoline engines. Biodiesel has a higher lubricity than mineral diesel and is an additive in European pump diesel for lubricity and emissions reduction.\n\nSome Diesel-powered cars can run with minor modifications on 100% pure vegetable oils. Vegetable oils tend to thicken (or solidify if it is waste cooking oil), in cold weather conditions so vehicle modifications (a two tank system with diesel start/stop tank), are essential in order to heat the fuel prior to use under most circumstances. Heating to the temperature of engine coolant reduces fuel viscosity, to the range cited by injection system manufacturers, for systems prior to 'common rail' or 'unit injection ( VW PD)' systems. Waste vegetable oil, especially if it has been used for a long time, may become hydrogenated and have increased acidity. This can cause the thickening of fuel, gumming in the engine and acid damage of the fuel system. Biodiesel does not have this problem, because it is chemically processed to be PH neutral and lower viscosity. Modern low emission diesels (most often Euro -3 and -4 compliant), typical of the current production in the European industry, would require extensive modification of injector system, pumps and seals etc. due to the higher operating pressures, that are designed thinner (heated) mineral diesel than ever before, for atomisation, if they were to use pure vegetable oil as fuel. Vegetable oil fuel is not suitable for these vehicles as they are currently produced. This reduces the market as increasing numbers of new vehicles are not able to use it. However, the German Elsbett company has successfully produced single tank vegetable oil fuel systems for several decades, and has worked with Volkswagen on their TDI engines. This shows that it is technologically possible to use vegetable oil as a fuel in high efficiency / low emission diesel engines.\n\nGreasestock is an event held yearly in Yorktown Heights, New York, and is one of the largest showcases of vehicles using waste oil as a biofuel in the United States.\n\nCompressed Biogas may be used for Internal Combustion Engines after purification of the raw gas. The removal of H2O, H2S and particles can be seen as standard producing a gas which has the same quality as Compressed Natural Gas. The use of biogas is particularly interesting for climates where the waste heat of a biogas powered power plant cannot be used during the summer.\n\nIn the 1930s Tang Zhongming made an invention using abundant charcoal resources for Chinese auto market. The Charcoal-fuelled car was later used intensively in China, serving the army and conveyancer after the breakout of World War II.\n\nHigh-pressure compressed natural gas, mainly composed of methane, that is used to fuel normal combustion engines instead of gasoline. Combustion of methane produces the least amount of CO of all fossil fuels. Gasoline cars can be retrofitted to CNG and become bifuel Natural gas vehicles (NGVs) as the gasoline tank is kept. The driver can switch between CNG and gasoline during operation. Natural gas vehicles (NGVs) are popular in regions or countries where natural gas is abundant. Widespread use began in the Po River Valley of Italy, and later became very popular in New Zealand by the eighties, though its use has declined.\n, there were 17.8 million natural gas vehicles worldwide, led by Iran with 3.30 million, followed by Pakistan (2.79 million), Argentina (2.29 million), Brazil (1.75 million), China (1.58 million) and India (1.5 million). As of 2010, the Asia-Pacific region led the global market with a share of 54%. In Europe they are popular in Italy (730,000), Ukraine (200,000), Armenia (101,352), Russia (100,000) and Germany (91,500), and they are becoming more so as various manufacturers produce factory made cars, buses, vans and heavy vehicles. In the United States CNG powered buses are the favorite choice of several public transit agencies, with an estimated CNG bus fleet of some 130,000. Other countries where CNG-powered buses are popular include India, Australia, Argentina, and Germany.\n\nCNG vehicles are common in South America, where these vehicles are mainly used as taxicabs in main cities of Argentina and Brazil. Normally, standard gasoline vehicles are retrofitted in specialized shops, which involve installing the gas cylinder in the trunk and the CNG injection system and electronics. The Brazilian GNV fleet is concentrated in the cities of Rio de Janeiro and São Paulo. Pike Research reports that almost 90% of NGVs in Latin America have bi-fuel engines, allowing these vehicles to run on either gasoline or CNG.\n\nIn 2006 the Brazilian subsidiary of FIAT introduced the Fiat Siena Tetra fuel, a four-fuel car developed under Magneti Marelli of Fiat Brazil. This automobile can run on 100% ethanol (E100), E25 (Brazil's normal ethanol gasoline blend), pure gasoline (not available in Brazil), and natural gas, and switches from the gasoline-ethanol blend to CNG automatically, depending on the power required by road conditions. Other existing option is to retrofit an ethanol flexible-fuel vehicle to add a natural gas tank and the corresponding injection system. Some taxicabs in São Paulo and Rio de Janeiro, Brazil, run on this option, allowing the user to choose among three fuels (E25, E100 and CNG) according to current market prices at the pump. Vehicles with this adaptation are known in Brazil as \"tri-fuel\" cars.\n\nHCNG or Hydrogen enriched Compressed Natural Gas for automobile use is premixed at the hydrogen station.\n\nFormic acid is used by converting it first to hydrogen, and using that in a fuel cell. Formic acid is much easier to store than hydrogen.\n\nA hydrogen car is an automobile which uses hydrogen as its primary source of power for locomotion. These cars generally use the hydrogen in one of two methods: combustion or fuel-cell conversion. In combustion, the hydrogen is \"burned\" in engines in fundamentally the same method as traditional gasoline cars. In fuel-cell conversion, the hydrogen is turned into electricity through fuel cells which then powers electric motors. With either method, the only byproduct from the spent hydrogen is water, however during combustion with air NOx can be produced.\n\nHonda introduced its fuel cell vehicle in 1999 called the FCX and have since then introduced the second generation FCX Clarity. Limited marketing of the FCX Clarity, based on the 2007 concept model, began in June 2008 in the United States, and it was introduced in Japan in November 2008. The FCX Clarity was available in the U.S. only in Los Angeles Area, where 16 hydrogen filling stations are available, and until July 2009, only 10 drivers have leased the Clarity for US$600 a month. At the 2012 World Hydrogen Energy Conference, Daimler AG, Honda, Hyundai and Toyota all confirmed plans to produce hydrogen fuel cell vehicles for sale by 2015, with some types planned to enter the showroom in 2013. From 2008 to 2014, Honda leased a total of 45 FCX units in the US.\n\nA small number of prototype hydrogen cars currently exist, and a significant amount of research is underway to make the technology more viable. The common internal combustion engine, usually fueled with gasoline (petrol) or diesel liquids, can be converted to run on gaseous hydrogen. However, the most efficient use of hydrogen involves the use of fuel cells and electric motors instead of a traditional engine. Hydrogen reacts with oxygen inside the fuel cells, which produces electricity to power the motors. One primary area of research is hydrogen storage, to try to increase the range of hydrogen vehicles while reducing the weight, energy consumption, and complexity of the storage systems. Two primary methods of storage are metal hydrides and compression. Some believe that hydrogen cars will never be economically viable and that the emphasis on this technology is a diversion from the development and popularization of more efficient hybrid cars and other alternative technologies.\n\nA study by The Carbon Trust for the UK Department of Energy and Climate Change suggests that hydrogen technologies have the potential to deliver UK transport with near-zero emissions whilst reducing dependence on imported oil and curtailment of renewable generation. However, the technologies face very difficult challenges, in terms of cost, performance and policy.\n\nBuses, trains, PHB bicycles, canal boats, cargo bikes, golf carts, motorcycles, wheelchairs, ships, airplanes, submarines, and rockets can already run on hydrogen, in various forms. NASA used hydrogen to launch Space Shuttles into space. A working toy model car runs on solar power, using a regenerative fuel cell to store energy in the form of hydrogen and oxygen gas. It can then convert the fuel back into water to release the solar energy.\n\nBMW's Clean Energy internal combustion hydrogen car has more power and is faster than hydrogen fuel cell electric cars. A limited series production of the 7 Series Saloon was announced as commencing at the end of 2006. A BMW hydrogen prototype (H2R) using the driveline of this model broke the speed record for hydrogen cars at 300 km/h (186 mi/h), making automotive history. Mazda has developed Wankel engines to burn hydrogen. The Wankel uses a rotary principle of operation, so the hydrogen burns in a different part of the engine from the intake. This reduces pre-detonation, a problem with hydrogen fueled piston engines.\n\nThe other major car companies like Daimler, Chrysler, Honda, Toyota, Ford and General Motors, are investing in hydrogen fuel cells instead. VW, Nissan, and Hyundai/Kia also have fuel cell vehicle prototypes on the road. In addition, transit agencies across the globe are running prototype fuel cell buses. Fuel cell vehicles, such as the new Honda Clarity, can get up to on a kilogram of hydrogen. \n\nThe Hyundai ix35 FCEV fuel cell vehicle is available for lease in the U.S. In 2014, a total of 54 units were leased. Sales of the Toyota Mirai to government and corporate customers began in Japan on December 15, 2014. Toyota delivered the first market placed Mirai to the Prime Minister's Official Residence and announced it got 1,500 orders in Japan in one month after sales began against a sales target of 400 for 12 months.\n\nDeliveries to retail customers began in California in October 2015. A total of 57 units were delivered between October and November 2015. Toyota scheduled to release the Mirai in the Northeastern States in the first half of 2016. The market launch in Europe is slated for September 2015.\n\nLiquid nitrogen (LN2) is a method of storing energy. Energy is used to liquefy air, and then LN2 is produced by evaporation, and distributed. LN2 is exposed to ambient heat in the car and the resulting nitrogen gas can be used to power a piston or turbine engine. The maximum amount of energy that can be extracted from LN2 is 213 Watt-hours per kg (W·h/kg) or 173 W·h per liter, in which a maximum of 70 W·h/kg can be utilized with an isothermal expansion process. Such a vehicle with a 350-liter (93 gallon) tank can achieve ranges similar to a gasoline powered vehicle with a 50-liter (13 gallon) tank. Theoretical future engines, using cascading topping cycles, can improve this to around 110 W·h/kg with a quasi-isothermal expansion process. The advantages are zero harmful emissions and superior energy densities compared to a Compressed-air vehicle as well as being able to refill the tank in a matter of minutes.\n\nLiquefied natural gas is natural gas that has been cooled to a point at which it becomes a cryogenic liquid. In this liquid state, natural gas is more than 2 times as dense as highly compressed CNG. LNG fuel systems function on any vehicle capable of burning natural gas. Unlike CNG, which is stored at high pressure (typically 3000 or 3600 psi) and then regulated to a lower pressure that the engine can accept, LNG is stored at low pressure (50 to 150 psi) and simply vaporized by a heat exchanger before entering the fuel metering devices to the engine. Because of its high energy density compared to CNG, it is very suitable for those interested in long ranges while running on natural gas.\n\nIn the United States, the LNG supply chain is the main thing that has held back this fuel source from growing rapidly. The LNG supply chain is very analogous to that of diesel or gasoline. First, pipeline natural gas is liquefied in large quantities, which is analogous to refining gasoline or diesel. Then, the LNG is transported via semi trailer to fuel stations where it is stored in bulk tanks until it is dispensed into a vehicle. CNG, on the other hand, requires expensive compression at each station to fill the high-pressure cylinder cascades.\n\nLPG or liquefied petroleum gas is a low pressure liquefied gas mixture composed mainly of propane and butane which burns in conventional gasoline combustion engines with less CO than gasoline. Gasoline cars can be retrofitted to LPG aka Autogas and become bifuel vehicles as the gasoline tank stays. You can switch between LPG and gasoline during operation. Estimated 10 million vehicles running worldwide.\n\nThere are 17.473 million LPG powered vehicles worldwide as of December 2010, and the leading countries are Turkey (2.394 million vehicles), Poland (2.325 million), and South Korea (2.3 million). In the U.S., 190,000 on-road vehicles use propane, and 450,000 forklifts use it for power. Whereas it is banned in Pakistan(DEC 2013) as it is considered a risk to public safety by OGRA.\n\nHyundai Motor Company began sales of the Elantra LPI Hybrid in the South Korean domestic market in July 2009. The Elantra LPI (Liquefied Petroleum Injected) is the world's first hybrid electric vehicle to be powered by an internal combustion engine built to run on liquefied petroleum gas (LPG) as a fuel.\n\nA steam car is a car that has a steam engine. Wood, coal, ethanol, or others can be used as fuel. The fuel is burned in a boiler and the heat converts water into steam. When the water turns to steam, it expands. The expansion creates pressure. The pressure pushes the pistons back and forth. This turns the driveshaft to spin the wheels forward. It works like a coal-fueled steam train, or steam boat. The steam car was the next logical step in independent transport.\n\nSteam cars take a long time to start, but some can reach speeds over 100 mph (161 km/h) eventually. The late model Doble Steam Cars could be brought to operational condition in less than 30 seconds, had high top speeds and fast acceleration, but were expensive to buy.\n\nA steam engine uses external combustion, as opposed to internal combustion. Gasoline-powered cars are more efficient at about 25–28% efficiency. In theory, a combined cycle steam engine in which the burning material is first used to drive a gas turbine can produce 50% to 60% efficiency. However, practical examples of steam engined cars work at only around 5–8% efficiency.\n\nThe best known and best selling steam-powered car was the Stanley Steamer. It used a compact fire-tube boiler under the hood to power a simple two-piston engine which was connected directly to the rear axle. Before Henry Ford introduced monthly payment financing with great success, cars were typically purchased outright. This is why the Stanley was kept simple; to keep the purchase price affordable.\n\nSteam produced in refrigeration also can be use by a turbine in other vehicle types to produce electricity, that can be employed in electric motors or stored in a battery.\n\nSteam power can be combined with a standard oil-based engine to create a hybrid. Water is injected into the cylinder after the fuel is burned, when the piston is still superheated, often at temperatures of 1500 degrees or more. The water will instantly be vaporized into steam, taking advantage of the heat that would otherwise be wasted.\n\nWood gas can be used to power cars with ordinary internal combustion engines if a wood gasifier is attached. This was quite popular during World War II in several European and Asian countries because the war prevented easy and cost-effective access to oil.\n\nHerb Hartman of Woodward, Iowa currently drives a wood powered Cadillac. He claims to have attached the gasifier to the Cadillac for just $700. Hartman claims, “A full hopper will go about fifty miles depending on how you drive it,” and he added that splitting the wood was “labor-intensive. That’s the big drawback.”\n\nDual fuel vehicle is referred as the vehicle using two types of fuel in the same time (can be gas + liquid, gas + gas, liquid + liquid) with different fuel tank.\n\nDiesel-CNG Dual Fuel is a system using two type of fuel which are diesel and Compressed Natural Gas (CNG) at the same time. It is because of CNG need a source of ignition for combustion in diesel engine.\n\nA flexible-fuel vehicle (FFV) or dual-fuel vehicle (DFF) is an alternative fuel automobile or light duty truck with a multifuel engine that can use more than one fuel, usually mixed in the same tank, and the blend is burned in the combustion chamber together. These vehicles are colloquially called flex-fuel, or flexifuel in Europe, or just flex in Brazil. FFVs are distinguished from bi-fuel vehicles, where two fuels are stored in separate tanks. The most common commercially available FFV in the world market is the ethanol flexible-fuel vehicle, with the major markets concentrated in the United States, Brazil, Sweden, and some other European countries. In addition to flex-fuel vehicles running with ethanol, in the US and Europe there were successful test programs with methanol flex-fuel vehicles, known as M85 FFVs, and more recently there have been also successful tests using p-series fuels with E85 flex fuel vehicles, but as of June 2008, this fuel is not yet available to the general public.\n\nEthanol flexible-fuel vehicles have standard gasoline engines that are capable of running with ethanol and gasoline mixed in the same tank. These mixtures have \"E\" numbers which describe the percentage of ethanol in the mixture, for example, E85 is 85% ethanol and 15% gasoline. (See common ethanol fuel mixtures for more information.) Though technology exists to allow ethanol FFVs to run on any mixture up to E100, in the U.S. and Europe, flex-fuel vehicles are optimized to run on E85. This limit is set to avoid cold starting problems during very cold weather. The alcohol content might be reduced during the winter, to E70 in the U.S. or to E75 in Sweden. Brazil, with a warmer climate, developed vehicles that can run on any mix up to E100, though E20-E25 is the mandatory minimum blend, and no pure gasoline is sold in the country.\n\nAbout 48 million automobiles, motorcycles and light duty trucks manufactured and sold worldwide by mid 2015, and concentrated in four markets, Brazil (29.5 million by mid 2015), the United States (17.4 million by the end of 2014), Canada (1.6 million by 2014), and Sweden (243,100 through December 2014). The Brazilian flex fuel fleet includes over 4 million flexible-fuel motorcycles produced since 2009 through March 2015. In Brazil, 65% of flex-fuel car owners were using ethanol fuel regularly in 2009, while, the actual number of American FFVs being run on E85 is much lower; surveys conducted in the U.S. have found that 68% of American flex-fuel car owners were not aware they owned an E85 flex. This is thought to be due to a number of factors, including:\n\nBy contrast, automakers selling FFVs in Brazil commonly affix badges advertising the car as a flex-fuel vehicle. As of 2007, new FFV models sold in the U.S. were required to feature a yellow gas cap emblazoned with the label \"E85/gasoline\", in order to remind drivers of the cars' flex-fuel capabilities. Use of E85 in the U.S. is also affected by the relatively low number of E85 filling stations in operation across the country, with just over 1,750 in August 2008, most of which are concentrated in the Corn Belt states, led by Minnesota with 353 stations, followed by Illinois with 181, and Wisconsin with 114. By comparison, there are some 120,000 stations providing regular non-ethanol gasoline in the United States alone.\n\nThere have been claims that American automakers are motivated to produce flex-fuel vehicles due to a loophole in the Corporate Average Fuel Economy (CAFE) requirements, which gives the automaker a \"fuel economy credit\" for every flex-fuel vehicle sold, whether or not the vehicle is actually fueled with E85 in regular use. This loophole allegedly allows the U.S. auto industry to meet CAFE fuel economy targets not by developing more fuel-efficient models, but by spending between US$100 and US$200 extra per vehicle to produce a certain number of flex-fuel models, enabling them to continue selling less fuel-efficient vehicles such as SUVs, which netted higher profit margins than smaller, more fuel-efficient cars.\n\nIn the United States, E85 FFVs are equipped with sensor that automatically detect the fuel mixture, signaling the ECU to tune spark timing and fuel injection so that fuel will burn cleanly in the vehicle's internal combustion engine. Originally, the sensors were mounted in the fuel line and exhaust system; more recent models do away with the fuel line sensor. Another feature of older flex-fuel cars is a small separate gasoline storage tank that was used for starting the car on cold days, when the ethanol mixture made ignition more difficult.\n\nModern Brazilian flex-fuel technology enables FFVs to run an any blend between E20-E25 gasohol and E100 ethanol fuel, using a lambda probe to measure the quality of combustion, which informs the engine control unit as to the exact composition of the gasoline-alcohol mixture. This technology, developed by the Brazilian subsidiary of Bosch in 1994, and further improved and commercially implemented in 2003 by the Italian subsidiary of Magneti Marelli, is known as \"Software Fuel Sensor\". The Brazilian subsidiary of Delphi Automotive Systems developed a similar technology, known as \"Multifuel\", based on research conducted at its facility in Piracicaba, São Paulo. This technology allows the controller to regulate the amount of fuel injected and spark time, as fuel flow needs to be decreased to avoid detonation due to the high compression ratio (around 12:1) used by flex-fuel engines.\n\nThe first flex motorcycle was launched by Honda in March 2009. Produced by its Brazilian subsidiary Moto Honda da Amazônia, the CG 150 Titan Mix is sold for around US$2,700. Because the motorcycle does not have a secondary gas tank for a cold start like the Brazilian flex cars do, the tank must have at least 20% of gasoline to avoid start up problems at temperatures below 15 °C (59 °F). The motorcycle’s panel includes a gauge to warn the driver about the actual ethanol-gasoline mix in the storage tank.\n\nA hybrid vehicle uses multiple propulsion systems to provide motive power. The most common type of hybrid vehicle is the gasoline-electric hybrid vehicles, which use gasoline (petrol) and electric batteries for the energy used to power internal-combustion engines (ICEs) and electric motors. These motors are usually relatively small and would be considered \"underpowered\" by themselves, but they can provide a normal driving experience when used in combination during acceleration and other maneuvers that require greater power.\n\nThe Toyota Prius first went on sale in Japan in 1997 and it is sold worldwide since 2000. By 2017 the Prius is sold in more than 90 countries and regions, with Japan and the United States as its largest markets. In May 2008, global cumulative Prius sales reached the 1 million units, and by September 2010, the Prius reached worldwide cumulative sales of 2 million units, and 3 million units by June 2013. , global hybrid sales are led by the Prius family, with cumulative sales of 6.0361 million units, excluding its plug-in hybrid variant. The Toyota Prius liftback is the leading model of the Toyota brand with cumulative sales of 3.985 million units, followed by the Toyota Aqua/Prius c, with global sales of 1.380 million units, the Prius v/α/+ with 671,200, the Camry Hybrid with 614,700 units, the Toyota Auris with 378,000 units, and the Toyota Yaris Hybrid with 302,700. The best-selling Lexus model is the Lexus RX 400h/RX 450h with global sales of 363,000 units.\n\nThe Honda Insight is a two-seater hatchback hybrid automobile manufactured by Honda. It was the first mass-produced hybrid automobile sold in the United States, introduced in 1999, and produced until 2006. Honda introduced the second-generation Insight in Japan in February 2009, and the new Insight went on sale in the United States on April 22, 2009. Honda also offers the Honda Civic Hybrid since 2002.\n\n, there are over 50 models of hybrid electric cars available in several world markets, with more than 12 million hybrid electric vehicles sold worldwide since their inception in 1997. , Japan ranked as the market leader with more than 5 million hybrids sold, followed by the United States with cumulative sales of over 4 million units since 1999, and Europe with about 1.5 million hybrids delivered since 2000. Japan has the world's highest hybrid market penetration. By 2013 the hybrid market share accounted for more than 30% of new standard passenger car sold, and about 20% new passenger vehicle sales including kei cars. The Netherlands ranks second with a hybrid market share of 4.5% of new car sales in 2012.\n\n, global sales are by Toyota Motor Company with more than 10 million Lexus and Toyota hybrids sold, followed by Honda Motor Co., Ltd. with cumulative global sales of more than 1.35 million hybrids ; Ford Motor Corporation with over 424 thousand hybrids sold in the United States through June 2015, of which, around 10% are plug-in hybrids; Hyundai Group with cumulative global sales of 200 thousand hybrids , including both Hyundai Motors and Kia Motors hybrid models; and PSA Peugeot Citroën with over 50,000 diesel-powered hybrids sold in Europe through December 2013.\n\nThe Elantra LPI Hybrid, launched in the South Korean domestic market in July 2009, is a hybrid vehicle powered by an internal combustion engine built to run on liquefied petroleum gas (LPG) as a fuel. The Elantra PLI is a mild hybrid and the first hybrid to adopt advanced lithium polymer (Li–Poly) batteries.\n\nUntil 2010 most plug-in hybrids on the road in the U.S. were conversions of conventional hybrid electric vehicles, and the most prominent PHEVs were conversions of 2004 or later Toyota Prius, which have had plug-in charging and more batteries added and their electric-only range extended. Chinese battery manufacturer and automaker BYD Auto released the F3DM to the Chinese fleet market in December 2008 and began sales to the general public in Shenzhen in March 2010. General Motors began deliveries of the Chevrolet Volt in the U.S. in December 2010. Deliveries to retail customers of the Fisker Karma began in the U.S. in November 2011.\nDuring 2012, the Toyota Prius Plug-in Hybrid, Ford C-Max Energi, and Volvo V60 Plug-in Hybrid were released. The following models were launched during 2013 and 2015: Honda Accord Plug-in Hybrid, Mitsubishi Outlander P-HEV, Ford Fusion Energi, McLaren P1 (limited edition), Porsche Panamera S E-Hybrid, BYD Qin, Cadillac ELR, BMW i3 REx, BMW i8, Porsche 918 Spyder (limited production), Volkswagen XL1 (limited production), Audi A3 Sportback e-tron, Volkswagen Golf GTE, Mercedes-Benz S 500 e, Porsche Cayenne S E-Hybrid, Mercedes-Benz C 350 e, BYD Tang, Volkswagen Passat GTE, Volvo XC90 T8, BMW X5 xDrive40e, Hyundai Sonata PHEV, and Volvo S60L PHEV.\n\n, about 500,000 highway-capable plug-in hybrid electric cars had been sold worldwide since December 2008, out of total cumulative global sales of 1.2 million light-duty plug-in electric vehicles. , the Volt/Ampera family of plug-in hybrids, with combined sales of about 134,500 units is the top selling plug-in hybrid in the world. Ranking next are the Mitsubishi Outlander P-HEV with about 119,500, and the Toyota Prius Plug-in Hybrid with almost 78,000.\n\nIn very small vehicles, the power demand decreases, so human power can be employed to make a significant improvement in battery life. Two such commercially made vehicles are the Sinclair C5 and TWIKE.\n\nAccording to a recent comparative energy and environmental analysis of the vehicle fuel end use (petroleum and natural gas derivatives & hydrogen; biofuels like ethanol or biodiesel, and their mixtures; as well as electricity intended to be used in plug-in electric vehicles), the renewable and non-renewable unit energy costs and CO2 emission cost are suitable indicators for assessing the renewable energy consumption intensity and the environmental impact, and for quantifying the thermodynamic performance of the transportation sector. This analysis allows ranking the energy conversion processes along the vehicle fuels production routes and their end-use, so that the best options for the transportation sector can be determined and better energy policies may be issued. Thus, if a drastic CO2 emissions abatement of the transportation sector is pursued, a more intensive utilization of ethanol in the Brazilian transportation sector mix is advisable. However, as the overall exergy conversion efficiency of the sugar cane industry is still very low, which increases the unit energy cost of ethanol, better production and end-use technologies are required. Nonetheless, with the current scenario of a predominantly renewable Brazilian electricity mix, based on more than 80% of renewable sources, this source consolidates as the most promising energy source to reduce the large amount of greenhouse gas emissions which transportation sector is responsible for.\n\n\n"}
{"id": "23788991", "url": "https://en.wikipedia.org/wiki?curid=23788991", "title": "American Ninja Warrior", "text": "American Ninja Warrior\n\nAmerican Ninja Warrior (sometimes abbreviated as ANW) is an American sports entertainment competition that is a spin-off of the Japanese television series \"Sasuke\". It features hundreds of competitors attempting to complete a series of obstacle courses of increasing difficulty in various cities across the United States, in hopes of advancing to the national finals on the Las Vegas Strip, in hopes of becoming an \"American Ninja Warrior\".\n\nTo date only two competitors, rock-climbers Isaac Caldiero and Geoff Britten, have finished the course and achieved \"Total Victory\". Caldiero is the only competitor to win the cash prize. The series premiered on December 12, 2009 on the now-defunct cable channel G4 and now airs on NBC with encore episodes airing on USA Network and NBCSN, G4, and Esquire Network.\n\n\"American Ninja Warrior\" succeeded G4's \"American Ninja Challenge\" as the qualifying route for Americans to enter \"Sasuke\". Beginning with the fourth season in 2012, regional finalists and wild card competitors competed on a nearly identical Mount Midoriyama course in Las Vegas, Nevada, rather than traveling to Japan to compete on \"Sasuke\".\n\n\"American Ninja Warrior\" was originally hosted by G4's American television personality Blair Herter, and actress and former television correspondent Alison Haislip. In the second season, American actor, comedian, and television host Matt Iseman joined the show, replacing Herter. Additionally, Jimmy Smith was brought in as a co-host, while Haislip was the sideline reporter. The panel remained the same throughout season three.\n\nFor season four, skier Jonny Moseley was brought in as the new co-host, replacing Smith. American journalist, sportscaster, and documentary filmmaker Angela Sun replaced Haislip.\n\nFor season five, two newcomers were added. Sports analyst and former NFL football player Akbar Gbaja-Biamila replaced Moseley, while ESPN sportscaster and model Jenn Brown replaced Sun as sideline reporter. The season five panel remained the same through the sixth season.\n\nFor season seven, CBS Sports reporter Kristine Leahy joined the show as the new sideline reporter, replacing Brown. The roster has stayed the same as of season ten, consisting of Iseman, Gbaja-Biamila, and Leahy.\n\nPotential contestants go through a series of steps before possibly becoming an \"American Ninja Warrior\". Over 3,500 athletes have attempted to conquer Mount Midoriyama and become one since the series began in 2009.\n\nThere are some requirements contestants must meet before participating at a regional qualifier. Contestants must be legal residents of the United States and be in decent physical shape. There is no upper age limit, though participants must be at least 19 years old (21 years old during the first nine seasons). Contestants must fill out a 20-page questionnaire and make a video about themselves. The required length of the video has differed over the years. Submission video length requirements have varied from 2 to 8 minutes, depending on the season.\n\n1,000 people applied to compete in season one, 5,000 people in season six, 50,000 in season seven, 70,000 in season eight, and 77,000 in season nine. Producers then select 100 contestants from the thousands of applicants to participate in each regional qualifier. They also select 20 to 30 \"walk-ons\" who may wait weeks camping outside to get a chance on the course.\n\nIn each city qualifier course, the competitors that the producers have selected compete on an obstacle course consisting of six obstacles. Descriptions of each obstacle in each course are provided by the sideline reporter at the beginning of an episode.\n\nAt the beginning of each run, a buzzer sounds off, allowing a competitor to begin the course. A timer begins simultaneously. The first obstacle on any city qualifying course is the quintuple steps or floating steps, in which competitors must run across. This is followed by four different obstacles that test a competitors balance, upper-body strength and grip. These five obstacles are built above water. If a competitor falls into the water or touches it, their run ends immediately and the timer records their time.\n\nUntil season nine, the sixth and final obstacle was the 14'6\" warped wall, in which competitors are given three chances to reach the top. In season ten, the 18-foot \"Mega Wall\" was introduced adjacent to the warped wall. Competitors have only one attempt to reach the top of the Mega Wall, and if successful, will win $10,000. However, if unsuccessful, the competitor will only get one attempt at the warped wall. Competitors are given the choice of which to climb.\n\nAt the top of both walls, there is a buzzer a competitor presses which stops the timer and records their time, ending their run on the course. The top 30 competitors who go the farthest the fastest advance to the city finals course. Since season nine, the top five women also advance to the city finals, regardless if they finished in the top 30.\n\nCity finals courses are the follow-up to each city qualifying course. They contain four new obstacles, in addition to the six obstacles featured in the city qualifying course. These four obstacles are all placed after the original six obstacles. As of season ten, two of the original six obstacles are replaced with new obstacles for the city finals course.\n\nThe top 15 competitors who go the farthest the fastest from each city finals course move on to compete on the National Finals course. As of season nine, the top two women in each city finals course also move on to compete on the National Finals course, even if they do not finish in the top 15. Small prizes ranging from $1,000 to $5,000 are awarded to first, second, and third finishers who complete the city finals course.\n\nQualifying and finals courses are filmed back-to-back, usually over two nights. Obstacles are designed and produced in the five months prior to an episode taping, with 3–4 new ones per city. In season eight, 18 obstacles were debuted.\n\nThe National Finals takes place at \"Mount Midoriyama\", the final course for \"American Ninja Warrior\". Located on the Las Vegas Strip, it consists of four stages, each containing various obstacles of increasing difficulty. Competitors must complete all of the 23 obstacles. Should they complete the first three stages, competitors will advance to Stage 4, where competitors attempt to climb the 75-foot rope climb, known as Mount Midoriyama, in 30 seconds or less. Should a competitor achieve Total Victory, he or she receives a money prize of $500,000 from season four to season six, and $1,000,000 from season seven. Beginning in season eight, if multiple competitors complete stage 4, the competitors split the prize money, although in prior years the fastest competitor would receive the full amount.\n\n\nThe first season of \"American Ninja Warrior\" was held in Los Angeles, where hundreds of competitors came to challenge themselves against the course and qualify for a shot at making it to Japan to compete in \"Sasuke 23\" later in the year. The special premiered on December 12, 2009, on G4 TV and was hosted by G4's Blair Herter and Alison Haislip. Notable competitors this season included freerunners Levi Meeuwenberg and Brian Orosco, mixed martial artist Jason \"Mayhem\" Miller, and Hollywood stuntman Rich King. Along with competitors on every season, Lorin Ball, Brian Kretsch, Ryan Stratis, and David Campbell.\n\nOut of the ten Americans who qualified to compete at Mount Midori in Japan, only Rich King, Levi Meeuwenberg and Brian Orosco successfully completed Stage 1. The majority of the \"American Ninja Warrior\" competitors ran out of time or failed the obstacles. Levi Meeuwenberg was the only American competitor to complete Stage 2. The sole American competitor on Stage 3 fell on the \"Shin-Cliffhanger\" and his run came to an end.\n\nThe second season premiered on December 8, 2010, on G4, and concluded on December 23, 2010 after 10 episodes. The city qualifiers were held near the beach in Venice, California, where 300 competitors took on the qualifiers course. 30 competitors advanced to the city finals course. The top 15 competitors in the city finals course then moved on to participate in \"Ninja Warrior Boot Camp\" in Simi Valley, where they competed in a series of team challenges for five days. The 10 finalists then moved on to compete in the season finale as part of \"Sasuke 26\" in Japan. Five competitors completed Stage 1, while four competitors completed Stage 2. No competitor made it beyond Stage 3. David Campbell was the Last Ninja Standing, having gone the farthest the fastest among the American competitors in \"Sasuke 26\".\n\nThe third season began airing on July 31, 2011, on G4 and concluded with the finale airing on August 22, 2011, as a two-hour primetime special on NBC. Tryouts took place in May 2011 at Venice Beach, California. After the tryouts, the top 15 competitors competed in Ninja Warrior Boot Camp with the top 10 moving on to Japan for the finals of the competition as a part of \"Sasuke 27\" and a chance at becoming the first American to conquer the course and win a $500,000 endorsement deal with K-Swiss. No competitors made it beyond Stage 3.\n\nThe fourth season of \"American Ninja Warrior\" began airing on May 20, 2012, on both G4 and NBC. There were six regional competitions held in three locations: Venice Beach (Southwest and Northwest), Dallas (Midwest and Midsouth), and Miami (Northeast and Southeast), that determined the 100 competitors to participate in the qualifying rounds. The winner of the \"ANW\" season four competition would receive $500,000 and the coveted \"American Ninja Warrior\" title. The season finale, held in Las Vegas, was the first time that Mount Midori was held on U.S. soil. Submission videos for \"American Ninja Warrior\" season 4 had been collected since January 25, 2012.\n\nThe entire format was changed as well – regional qualifiers in different parts of the country were aired, and the Mt. Midori course was recreated just off the Las Vegas Strip for the national finals. The regional qualifiers would narrow down its selections down to 30 contestants who finished its qualifying course in the fastest time as well as the contestants who finished the furthest the fastest. Qualifying obstacles would include common Stage 1 obstacles such as the Quintuple steps and the Warped wall, but its contents would change from city to city. The 30 contestants were then cut in half in the regional finals where the course would extend to include common Stage 2 and Stage 3 obstacles such as the Salmon Ladder, Cliffhanger and Body Prop. The 100 contestants who qualified (including wild cards) earned tickets to Las Vegas to challenge Mt. Midori. Brent Steffensen was the first American to defeat the Ultimate Cliffhanger on Stage 3, and he made it the farthest that season, falling on the Hang Climb. He was the only competitor to reach Stage 3 in this competition.\n\nThe fifth season of \"American Ninja Warrior\" premiered on June 30, 2013, on G4 with subsequent shows airing on NBC and G4. Notably, the sideboard advertising along the course listed Esquire Network as the broadcaster as the fifth season was to premiere after G4's transition to Esquire on April 22, 2013. The network switch was eventually delayed to September 23, 2013, and Esquire took over Style Network's channel space instead. Because of this, additional reruns of the season aired on Saturday nights on NBC through the summer to maintain ratings momentum due to G4's lame duck status, with \"ANW\" being their only new program since they wound down all their original programming in January 2013. The success of the NBC re-airings led to the series being considered for NBC's main summer schedule for the next season.\n\nRegional competitions were held in Venice Beach, Baltimore, Miami, and Denver. Tryouts for the season began in February 2013 and ended with the last of the regional rounds taking place the following May. The finale was once again held in Las Vegas. No one defeated Stage 3, but Brian Arnold fell on the last obstacle, the Flying Bar, making him the farthest-going American on the Mount Midori course since Kane Kosugi reached the final stage on \"Sasuke 8\".\n\nThe sixth season of \"American Ninja Warrior\" premiered on May 26, 2014, on NBC with subsequent shows airing on Monday nights at 9:00 pm EST and Tuesday nights at 8:00 pm EST on Esquire Network. Regional competitions were held at Venice Beach, Dallas, St. Louis, Miami, and Denver. The season finale was again held in Las Vegas, the permanent home of the U.S. version of Mount Midori. Notable competitors this season included \"The Biggest Loser\" personal trainer Kim Lyons, U.S. Olympic gymnasts Jonathan Horton and Terin Humphrey, among others. Female competitor Kacy Catanzaro became the first female to make it up the \"Warped Wall\" in the Dallas Qualifiers. Later in the Dallas Finals, she became the first woman to complete that finals course, in 8 minutes, 59 seconds. Again, no competitor achieved \"total victory\". Kacy's run has over ten million views. Joe Moravsky, the \"Weatherman\", made it farther than anyone on season six, falling on the Hang Climb, where Brent Steffensen failed two years ago.\n\nThe seventh season of \"American Ninja Warrior\" premiered on NBC on May 25, 2015. This season's grand prize was increased from $500,000 to $1,000,000. Qualifying and finals courses were held in Venice Beach, Kansas City, Houston, Orlando, Pittsburgh, as well as a special military-only course in San Pedro. Stage 1 had a total of 38 finishers including Brent Steffensen and Dustin McKinney. In Stage 2, 30 of the 38 competitors failed. Only eight were remaining in Stage 3 including Drew Dreschel, Abel Gonzalez, Isaac Caldiero, Ian Dory, Jeremiah Morgan, Kevin Bull, Joe Moravsky and Geoff Britten. Only two competitors finished the course: Isaac Caldiero and Geoff Britten. It was the first time that any American had finished Stage 3. The season concluded with a victory: Geoff Britten was the first to complete Stage 4 with a second remaining; however, Isaac Caldiero achieved the Stage 4 rope climb in a faster time and was awarded the grand prize of $1,000,000 and the title of \"American Ninja Warrior\". Geoff Britten was the first Ninja to complete all six courses in a single season.\n\nSeason eight of \"American Ninja Warrior\" began on June 1, 2016, on NBC, with encore episodes airing the following day on Esquire Network. Regional competitions were held in Los Angeles, Atlanta, Indianapolis, Oklahoma City, and Philadelphia, with 28 new obstacles. Over 40 percent more women registered for season eight compared to the previous season. Additionally, prize money for possible Stage 4 winners would now be split equally among competitors who complete the rope climb in under 30 seconds.\n\nIn Philadelphia's city finals, no competitors completed the finals course, a first in \"American Ninja Warrior\" history. In Stage 1 of the National Finals, many veterans of the show such as Geoff Britten and Brent Steffensen were eliminated early, while Jessie Graff became the first woman to complete Stage 1, placing fifth. Tyler Yamauchi became the shortest person ever to complete the Jumping Spider obstacle at 5'1\". Only 17 competitors successfully completed Stage 1, the lowest in \"ANW\" history. On Stage 2, all athletes were eliminated except Drew Drechsel and Daniel Gil. During Stage 3, both Drechsel and Gil could not complete the course. Gil fell on the Ultimate Cliffhanger, while Drechsel went the farthest, but fell on the Hang Climb. Contrary to season seven's multiple winners, no season eight competitor made it past Stage 3.\n\nSeason nine of \"American Ninja Warrior\" began on June 12, 2017, on NBC; Esquire Network ended operations fifteen days later on June 27, thus encore episodes shifted over to NBCSN on non-event nights with this season. The premiere was preceded by a special episode, \"Celebrity Ninja Warrior\" on May 25, 2017, the U.S. Red Nose Day, which was followed by a \"USA vs. the World\" special on June 4. New for season nine, the top five women in each city qualifying course qualified for the city finals course, and the top two women in each city finals qualified for national finals, regardless of their placement overall. Also this season, fans were given the opportunity to design their own obstacles through \"ANW Obstacle Design Challenge\" and seven fan-submitted obstacles have been featured on the show.\n\nIn the national finals, a record 41 competitors successfully completed Stage 1, including Allyssa Beird, the second woman to complete Stage 1. On Stage 2, all athletes were eliminated except Joe Moravsky, Sean Bryan and Najee Richardson. During Stage 3, none of the three could complete the course. Richardson and Bryan fell on the Ultimate Cliffhanger, while Moravsky went the farthest, but failed Time Bomb. As in season eight, no competitor was able to complete Stage 3.\n\nSeason ten of \"American Ninja Warrior\" began airing on May 30, 2018, with new changes including a $10,000 bonus for clearing the new 18-foot Mega Wall and $100,000 prize money for the \"Last Ninja Standing\". Drew Drechsel and Sean Bryan, the only two who made it to stage 3, both fell on the Ultimate Cliffhanger, however Drechsel made it faster, crowning him the Last Ninja Standing. Drechsel was also the first to win the $100,000 prize money.\n\nNBC has aired a series of 5 specials in which \"ANW\" fan favorites compete in a team against teams of competitors from regions across the world, including Japan, Europe, Latin America, and most recently, Asia. The competitors race on the same course used in the \"ANW\" finals.\n\nThe first special was entitled \"USA vs. Japan\", while the rest have been named \"USA vs. The World\". The inaugural competition was aired on January 13, 2014, and was won by Team USA. The second special aired on September 15, 2014, and was won by Team Europe. The third special aired on January 31, 2016, and was won by Team USA. The fourth international competition was aired on June 4, 2017, and was again won by Team USA. The most recent special aired on March 11, 2018, and was won by Team Europe.\n\nAll of the specials have been hosted by Matt Iseman and Akbar Gbaja-Biamila. The first two included sideline reporter Jenn Brown. Since the 2016 special, Kristine Leahy has sideline reported.\n\nOn May 29, 2016, prior to the premiere of season eight, NBC aired a two-hour all-star special in which hosts Matt Iseman and Akbar Gbaja-Biamila chose their own all-star teams composed of three veterans, one rookie, and one woman. Teams competed on stages two, three, and four of the regular season finals course, Mt. Midoriyama, as well as competitions on a supersized course by testing their skills in competitions on the giant pegboard, 40-foot Salmon Ladder, Flying Shelf Grab, and Jump Hang, concluding with a race to the top of the \"Mega\" Warped Wall.\n\nThe all-star winners were Team Akbar who won the team competition, beating Team Matt 5-3. Additionally, competitor Joe Moravsky completed Stage 2 in a record time of 1:08:52.\n\nOn February 20, 2017, NBC aired a second two-hour all-star special. Like the previous year's competition, \"ANW\" hosts Matt Iseman and Akbar Gbaja-Biamila chose their own all-star teams, this year composed of one veteran, one breakout star, and one woman. Team Matt featured Chris Wilczewski, Najee Richardson, and Jesse \"Flex\" Lebreck. Team Akbar featured Grant McCartney, Neil \"Crazy\" Craver, and Meagan Martin. Also, sideline interviewer Kristine Leahy got to pick her own team, which consisted of Jessie Graff, Flip Rodriguez, and Nicholas Coolridge. Teams competed as a relay race to finish sections of stages one, two, and three of the regular season finals course, Mt. Midoriyama. Next, was the skills competition on a supersized course where individual contestants tested their skills in competition on the 75-feet tall Endless Invisible Ladder, the 4-story high Super Salmon Ladder, Supersonic Shelf Grab, Striding Steps, and the Mega Wall, which is now 20 feet high.\n\nThe all-star winners were Team Kristine, who won the team relay race competition, beating Team Matt and last year's champions Team Akbar. Their highlight of the night was completing Stage 3 in a record time of 5:30:62, making this the \"POM Wonderful\" Run of the Night.\n\nOn May 17, 2018, NBC aired a third two-hour all-star special. Like the last two seasons' competition, \"ANW\" hosts Matt Iseman and Akbar Gbaja-Biamila, along with Kristine Leahy, chose their own all-star teams, composed of two male veterans, and one female veteran. The reigning champs, Team Kristine (gray/pink) featured: Jessie Graff, Flip Rodriguez, and J.J. Woods. Team Matt (blue) featured: Jamie Rahn, Lance Pekus, and Jesse LaBreck. However, Team Akbar featured first-time all-stars: Allyssa Beird, Jon Alexis Jr., and Tyler Yamauchi.\n\nFor the first half of the special, the athletes competed individuality, earning \"skills medals\". First was the \"Skills Competition\", which consisted of who can make it up the Super Salmon Ladder, 4 stories high and 35 rungs in the fastest time. Winner: Sean Bryan (19.39). And a test of how far the all-star ninjas can fly on the Wicked Wingnuts obstacle. Winner: Drew Drechsel (20 feet). They tested their upper body strength by racing head-to-head on the Thunderbolt. Winner: Jamie Rahn. Then, it was a speed and balance challenge on the Striding Steps. Winner: Jake Murray (28.76) This year, \"ANW\" debuted a new obstacle, the Mega Spider Climb, where the eight women all-stars raced side-by-side 80 feet up to the top of the Stage 4 tower. Winner: Jessie Graff, who won the tournament-style Stage 4 competition in a time of 24:03, making this the \"POM Wonderful\" Run of the Night.\n\nThe second half showcased the team competition: Stage 1 featured a relay race through the obstacles course. First racer goes through Snake Run, Propeller Bar and Double Dipper. Next racer tackles the Jumping Spider, Parkour Run and the Warped Wall. And the anchor runs through the Domino Pipes, and the Flying Squirrel. The other two teams compete on Stage 2 for the other spot in the finals. Team Kristine won Stage 1 and got a bye into Stage 3. Stage 2 featured the Giant Ring Swing, Criss Cross Salmon Ladder, Wave Runner, Swing Surfer, Wingnut Alley and the Wall Flip. Team Matt won and moved onto Stage 3, which featured Floating Boards, Key Lock Hang, the Nail Clipper, Ultimate Cliffhanger, the Body Prop, Peg Cloud, the Time Bomb and the Floating Bar.\n\nThe all-star winners were once again Team Kristine, who won the team relay race competition with a time of 6:12.06, beating Team Matt by only 5 seconds (6:17.96).\n\n\"Celebrity Ninja Warrior\" features celebrities competing on the \"American Ninja Warrior\" course while being coached by \"ANW\" favorites.\n\nNBC announced a special entitled \"Celebrity Ninja Warrior for Red Nose Day\" which aired on May 25, 2017. The course featured modified obstacles: Floating Steps, Cannonball Drop, Fly Wheels, Block Run, Battering Ram, and the Warped Wall. After completing the course, Stephen Amell also completed the Salmon Ladder (which he performed in a scene on \"Arrow\") and unsuccessfully attempted a new obstacle, the Swinging Pegboard; Amell's run was named the M&M's \"Run of the Night.\"\n\nFor every obstacle the celebrities completed, M&M's and The Rockefeller Foundation pledged to donate $5,000 to Red Nose Day.\n\nIn March 2018, NBC announced a second \"Celebrity Ninja Warrior\" special will air during a three-hour U.S. Red Nose Day special on May 24, 2018. On April 2, 2018, the celebrities competing were announced. Like last year's competition, ANW hosts Matt Iseman and Akbar Gbaja-Biamila, who ran the course this year, were the hosts, along with special correspondent, actress Zooey Deschanel and sideline reporter Kristine Leahy. The course featured six modified obstacles: Floating Steps, Grab Bag, Spinning Bridge, Flying Shelf Grab, Doorknob Drop, and the 14 1/2-foot Warped Wall.\n\nEach obstacle a celebrity completed raised $5,000 for Red Nose Day; earning up to $30,000 for finishing the whole course. A total of $185,000 was raised, courtesy of Comcast.\n\nFollowing the inception of \"American Ninja Warrior\", \"ANW\" competitors have also continued to enter other obstacle course competitions around the world, including \"Sasuke\":\n\n\nOn October 9, 2015, Esquire Network announced a spin-off of \"American Ninja Warrior\" which would feature 24 three-person teams (two men and one woman) of popular \"ANW\" alumni, initially titled \"Team Ninja Warrior\". The teams compete head-to-head against each other, running the course simultaneously, thus creating a new live duel dynamic (including crossing points where the two competitors can affect the other's progress.) The two teams with the fastest times advance to the finale where one team will be crowned the winners and receive a cash prize. Matt Iseman and Akbar Gbaja-Biamila host alongside actor and journalist, Alex Curry. The series is Esquire Network's most-watched program in the channel's history.\n\nOn May 31, 2016, Esquire Network ordered a sixteen-episode second season that also included a five-episode special college edition that had college-aged competitors go head-to-head against rival schools. On March 6, 2017, it was announced that \"Team Ninja Warrior\" will be moving to sibling cable channel USA Network as Esquire Network winds down its linear channel operations and relaunches as an online only service. The show's second season premiered proper on April 18. Ahead of its third season, the show was also re-titled \"American Ninja Warrior: Ninja vs. Ninja\".\n\nOn May 2, 2018, the second spin-off of \"American Ninja Warrior\", entitled \"American Ninja Warrior Junior\", was announced. Set to premiere on Universal Kids on October 13, 2018, Matt Iseman and Akbar Gbaja-Biamila will reprise their roles from \"ANW\" as hosts, with Olympic 2016 gold medalist Laurie Hernandez joining as co-host, guiding competitors in head-to-head challenges. The series will feature 200 kids age 9–14 competing along a course of miniature, kid-friendly \"ANW\" obstacles such as the warped wall. Similar to \"ANW\", males and females will run along the same course, and similarly to \"Ninja vs. Ninja\" and \"College Madness\", competitors compete head-to-head. However, they will be divided into three age groups: 9–10, 11–12 and 13–14, with each category coached by fan-favorite athletes: Drew Dreschel, Kevin Bull, Natalie Duran, Meagan Martin, Najee Richardson, and Barclay Stockett.\n\nIn Australia and New Zealand, the show is broadcast on SBS2 (2013–2017), 9Go! (2018), TV3 and Four. On April 25, 2016, it was announced Canadian broadcaster CTV picked up \"American Ninja Warrior\" for its 2016 summer broadcast schedule. In the United Kingdom and Ireland, the show is broadcast on Challenge. In Israel, the show is broadcast on Yes Action and Keshet 12. In 2016 Croatian RTL started broadcasting the show. The show is also shown in Finland on Sub-TV. In the Netherlands the show was first broadcast in 2017 on SBS 6, where their own \"Ninja Warrior NL\" has been broadcast.\n\nThe show is in syndication markets throughout the US and airs on local broadcast channels. As of August 18th 2018 the syndicated episodes are airing on MTV2 on Saturdays.\n\n\n"}
{"id": "408381", "url": "https://en.wikipedia.org/wiki?curid=408381", "title": "Anal beads", "text": "Anal beads\n\nAnal beads are a sex toy consisting of multiple spheres or balls attached together in series which are continuously inserted through the anus into the rectum and then removed with varying speeds depending on the desired effect (commonly at orgasm to enhance climax). Anal bead users enjoy the pleasurable feeling of the ball passing through the narrow sphincter of the anus.\n\nAnal beads are available in many sizes, with individual beads measuring from 25 mm in diameter to 125 mm diameter or larger. Most users enjoy beads of approximately 45 mm, but most will become more adventurous with experience, and try larger sizes. Anal beads are commonly made of silicone, plastic, rubber, latex, glass or metal and end with a ring or similar handle designed for pulling. The purpose of this ring is to prevent the beads from becoming fully lodged in the rectum, and to ease removal. The beads may either be joined flexibly, requiring individual insertion, or by a semi-rigid thin shaft, allowing anal insertion in a single motion. Both arrangements are forms of the sexual art of \"beading off\".\n\nThe many nerve endings of the sphincter provide arousal both during insertion and removal, and larger beads may create feelings of pressure while in the rectum.\n\nSome anal beads are enhanced with vibration technology to enhance pleasure.\n\nAnal beads can be incorporated into many fetishes that involve anal sex, ass worship, spanking, enemas or anything involving the buttocks, anus, or the anal area.\n\nAs with all anal sexual activity, the anal beads and the rectum should be well-lubricated with a sexual lubricant intended for anal sex. It is important to do this as the rectum can be easily ripped, torn or injured. Anal sex toys should be well washed with warm soapy water and left to dry naturally after use. Alternatively, they can be placed inside a condom, which is recommended if they are shared with a partner.\n\nCare must also be taken to count the beads before and after use to ensure they are all removed from the anus. String have reportedly broken during intense rectal movements. If a bead gets stuck in the rectum and cannot be expelled naturally, medical intervention may be necessary.\n\nIf the beads are threaded onto a string, which is a porous material, they cannot be fully disinfected. They should not be shared between partners without using a physical barrier such as a latex or neoprene condom to prevent the transfer of faeces. Sharing unsterilized anal toys can expose users to various sexually transmitted diseases.\n\n\n"}
{"id": "31082764", "url": "https://en.wikipedia.org/wiki?curid=31082764", "title": "Andrew Pritchard", "text": "Andrew Pritchard\n\nAndrew Pritchard FRSE (14 December 1804 – 24 November 1882) was an English naturalist and natural history dealer who made significant improvements to microscopy and studied microscopic organisms. His belief that God and nature were one led him to the Unitarians, a religious movement to which he and his family devoted much energy. He became a leading member of Newington Green Unitarian Church in north London, and worked to build a school there.\n\nAndrew Pritchard was born in Hackney, then a village just north of London on 14 December 1804, the son of John Pritchard and his wife, Ann Fleetwood. He was educated at St Saviour's Grammar School in Southwark.\n\nPritchard was apprenticed to his cousin Cornelius Varley, an artist deeply interested in science. For his improvements in the \"camera lucida\", the \"camera obscura\" and the microscope, he received the Isis Gold Medal of the Society of Arts and later, at the Great Exhibition, he gained a medal for his invention of the graphic telescope. Cornelius's brother was the painter John Varley, but Pritchard would have seen more of Cornelius's son Cromwell Fleetwood Varley, an engineer who pioneered the transatlantic telegraph cable.\n\nPritchard set up as an optician, and also sold microscopes and microslide preparations. These slides he prepared by studying the microscopic organisms that he saw, and identifying and labelling them. Starting in 1830, he collaborated with C.R. Goring to produce beautifully illustrated books showing the \"animalcules\" visible through the microscope. His shops were in central London, more towards The City than the West End, variously at 162 Fleet Street, Pickett Street and 312 & 263 The Strand. The \"Oxford Dictionary of National Biography\" says his \"List of 2000 Microscopic Objects\" (1835) \"is very important in the history of microscopy... his \"History of the Infusoria\" (1841) was long a standard work, and the impetus it gave to the study of biological science cannot be overestimated.\" (\"Infusoria\" is a term then current for aquatic micro-organisms.) This latter book was enlarged and revised by John Ralfs and other botanists; Pritchard in turn condensed Ralfs's contribution on the diatomaceæ (diatoms, a type of phytoplankton), and wrote many books and articles on \"natural history as seen through the microscope, on optical instruments, and on patents\"\n\nPritchard held various Dissenting religious views over his lifetime, holding that science and religion were one. Through the Varleys he attended a Sandemanian church, where he became acquainted with Michael Faraday. In the end he joined a Unitarian congregation, because religious freedom and self-improvement were the watchwords of the movement, which still struggled against civil disabilities. Money aside, Pritchard would not have been able to attend an English university as a young man, for example, because the only two, Oxford and Cambridge, restricted entry to members of the Church of England. \"No-one exists divorced from immediate and larger social environments. Dissenters led educational reform, especially in giving \"lower orders\" scientific knowledge and skill.\"\n\nPritchard joined the congregation of Newington Green Unitarian Church, an establishment long connected with scientific enquiry (Joseph Priestley), education (Mary Wollstonecraft), and political dissent (Richard Price). He is described in the church's history as \"the leading member of the congregation\". From 1850 to 1873 he was its treasurer, during which time donations doubled. Before the passage of the Elementary Education Act 1870, compulsory schooling did not exist, so the church started a school to offer education to the village children. He led the Newington Green Conversation Society, membership restricted to 16, a successor to the Mutual Instruction Society. Faraday was a frequent visitor.\n\nPritchard died in Highbury in London on 24 November 1882.\n\nHe married Caroline Isabella Straker in 1829 and they had several children. His wife was chair of the chapel organisation, and after a few decades there were 20 Pritchards involved in the chapel. Their son Henry Baden Pritchard (1841–1884) was a chemist, traveller, and photographer. Their son Andrew Goring Pritchard, a solicitor, was a leading light of the Association of Municipal Corporations; his son, Clive Fleetwood Pritchard, a barrister, became mayor of Hampstead; \"his\" son Jack Pritchard (1899-1992) co-founded the Isokon design company, famous for the Lawn Road Flats.\n\nAndrew and Caroline's son, Ion (died 1929) and daughter Marian (died 1908), continued the work of their parents at the Newington Green Unitarian Church. The cause of liberal religion in general, and the development of the General Assembly of Unitarian and Free Christian Churches, were overarching themes. Ion was President of the Sunday School Association, one of the precursors to the General Assembly. Marian in particular is described as an unsung heroine, and \"one of the leaders of modern Unitarianism\". She set up Oxford Summer Schools for the training of Sunday School teachers, and Winifred House Invalid Children's Convalescent Home.\n\n\n\n\n"}
{"id": "2119717", "url": "https://en.wikipedia.org/wiki?curid=2119717", "title": "Audio converter", "text": "Audio converter\n\nAn audio converter is a device or software that converts an audio signal from one format to another.\n\nHardware audio converters include analog to digital converters (ADCs), which convert analog audio to uncompressed digital form (e.g., PCM), and their reciprocal partners, digital to analog converters (DACs), which convert uncompressed digital audio to analog form. ADCs and DACs are usually components of hardware products. For example, sound cards and capture cards both include ADCs to allow a computer to record audio. Sound cards also feature DACs for audio playback.\n\nSome audio conversion functions can be performed by software or by specialized hardware. For example, an audio transcoder converts from one compressed audio format to another (e.g., MP3 to AAC) by means of two audio codecs: One for decoding (uncompressing) the source and one for encoding (compressing) the destination file or stream.\n\n"}
{"id": "350239", "url": "https://en.wikipedia.org/wiki?curid=350239", "title": "Basket", "text": "Basket\n\nA basket is a container which is traditionally constructed from stiff fibers, which can be made from a range of materials, including wood splints, runners, and cane. While most baskets are made from plant materials, other materials such as horsehair, baleen, or metal wire can be used. Baskets are generally woven by hand. Some baskets are fitted with a lid, others are left open.\n\nBaskets serve utilitarian as well as aesthetic purposes. Some baskets are ceremonial, that is religious, in nature. While baskets are typically used for storage and transport, specialized baskets are as sieves, for cooking, for processing seeds or grains, for tossing gambling pieces, rattles, fans, fish traps, laundry, and other uses.\n\nPrior to the invention of woven baskets, people used tree bark to make simple containers. These containers could be used to transport gathered food and other items, but crumble after only a few uses. Weaving strips of bark or other plant material to support the bark containers would be the next step, followed by entirely woven baskets. The last innovation appears to be baskets so tightly woven that they could hold water.\n\nDepending on soil conditions, baskets may or may not be preserved in the archaeological record. Sites in the Middle East show that weaving techniques were used to make mats and possibly also baskets, circa 8000 BCE. Twined baskets date back to 7000 BCE in Oasisamerica. Baskets made with interwoven techniques were common at 3000 BCE.\n\nBaskets were originally designed as multi-purpose baskets to carry and store and to keep stray items about the home. The plant life available in a region affects the choice of material, which in turn influences the weaving technique. Rattan and other members of the Arecaceae or palm tree family, the thin grasses of temperate regions, and broad-leaved tropical bromeliads each require a different method of twisting and braiding to be made into a basket. The practice of basket making has evolved into an art. Artistic freedom allows basket makers a wide choice of colors, materials, sizes, patterns, and details.\n\nThe carrying of a basket on the head, particularly by rural women, has long been practised. Representations of this in Ancient Greek art are called Canephorae.\n\nThe phrase \"to hell in a handbasket\" means \"to rapidly deteriorate\". The origin of this use is unclear.\n\"Basket\" is sometimes used as an adjective towards a person who is born out of wedlock. This occurs more commonly in British English. \"Basket\" also refers to a bulge in a man's crotch.\n\nMaterials have been used by basket makers:\n\n\n"}
{"id": "33946169", "url": "https://en.wikipedia.org/wiki?curid=33946169", "title": "Belmal", "text": "Belmal\n\nBelMal is a private museum located in Belgium, with twin locations in the Durbuy and Manhay municipalities of the province of Luxembourg.\n\nThe museum comprises antique travelling trunks and related baggage and travel equipment from around the globe, and the world's most important collection of trunks made by Belgian trunk-makers of the 19th century. \n\nThe BelMal Archives include the lists (registries) of the names and brands of trunk makers (malletier) that were active in Europe and around the globe. There is a separate registry of Belgian trunk makers and manufacturers of travel objects.\n\nIn the restoration workshop, led by a person of authority in the field of travel trunks restoration and history, travel trunks are restored for the collection and for third parties. In the same workshop new trunks are made to order; some of the specially commissioned ones carry the BelMal Malletier brand name.\n\nCourses in the restoration and in the manufacture of trunks, and in the travel equipment history, are part of the educational activity of the affiliate Ecole des Malletiers (formerly called BelMal Conservatory) tribute to 16th century trunk-makers Nicolas Gilbert of Belgium and Jean Paré of France. \n\n"}
{"id": "188543", "url": "https://en.wikipedia.org/wiki?curid=188543", "title": "Biofuel", "text": "Biofuel\n\nA biofuel is a fuel that is produced through contemporary biological processes, such as agriculture and anaerobic digestion, rather than a fuel produced by geological processes such as those involved in the formation of fossil fuels, such as coal and petroleum, from prehistoric biological matter.\n\nBiofuels can be derived directly from plants (i.e. energy crops), or indirectly from agricultural, commercial, domestic, and/or industrial wastes. Renewable biofuels generally involve contemporary carbon fixation, such as those that occur in plants or microalgae through the process of photosynthesis. Other renewable biofuels are made through the use or conversion of biomass (referring to recently living organisms, most often referring to plants or plant-derived materials). This biomass can be converted to convenient energy-containing substances in three different ways: thermal conversion, chemical conversion, and biochemical conversion. This biomass conversion can result in fuel in solid, liquid, or gas form. This new biomass can also be used directly for biofuels.\n\nBiofuels are in theory carbon-neutral because the carbon dioxide that is absorbed by the plants is equal to the carbon dioxide that is released when the fuel is burned. However, in practice, whether or not a biofuel is carbon-neutral also depends greatly on whether the land which is used to grow the biofuel (with 1st and 2nd generation biofuel) needed to be cleared of carbon-holding vegetation or not.\n\nBioethanol is an alcohol made by fermentation, mostly from carbohydrates produced in sugar or starch crops such as corn, sugarcane, or sweet sorghum. Cellulosic biomass, derived from non-food sources, such as trees and grasses, is also being developed as a feedstock for ethanol production. Ethanol can be used as a fuel for vehicles in its pure form (E100), but it is usually used as a gasoline additive to increase octane and improve vehicle emissions. Bioethanol is widely used in the United States and in Brazil. Current plant design does not provide for converting the lignin portion of plant raw materials to fuel components by fermentation.\n\nBiodiesel can be used as a fuel for vehicles in its pure form (B100), but it is usually used as a diesel additive to reduce levels of particulates, carbon monoxide, and hydrocarbons from diesel-powered vehicles. Biodiesel is produced from oils or fats using transesterification and is the most common biofuel in Europe.\n\nIn 2010, worldwide biofuel production reached 105 billion liters (28 billion gallons US), up 17% from 2009, and biofuels provided 2.7% of the world's fuels for road transport. Global ethanol fuel production reached 86 billion liters (23 billion gallons US) in 2010, with the United States and Brazil as the world's top producers, accounting together for about 90% of global production. The world's largest biodiesel producer is the European Union, accounting for 53% of all biodiesel production in 2010. , mandates for blending biofuels exist in 31 countries at the national level and in 29 states or provinces. The International Energy Agency has a goal for biofuels to meet more than a quarter of world demand for transportation fuels by 2050 to reduce dependence on petroleum and coal. The production of biofuels also led into a flourishing automotive industry, where by 2010, 79% of all cars produced in Brazil were made with a hybrid fuel system of bioethanol and gasoline.\n\nThere are various social, economic, environmental and technical issues relating to biofuels production and use, which have been debated in the popular media and scientific journals.\n\n\"First-generation\" or conventional biofuels are biofuels made from food crops grown on arable land. With this biofuel production generation, food crops are thus explicitly grown for fuel production, and not anything else. The sugar, starch, or vegetable oil obtained from the crops is converted into biodiesel or ethanol, using transesterification, or yeast fermentation.\n\nSecond generation biofuels are fuels manufactured from various types of biomass. Biomass is a wide-ranging term meaning any source of organic carbon that is renewed rapidly as part of the carbon cycle. Biomass is derived from plant materials, but can also include animal materials.\n\nWhereas first generation biofuels are made from the sugars and vegetable oils found in arable crops, second generation biofuels are made from lignocellulosic biomass or woody crops, agricultural residues or waste plant material (from food crops that have already fulfilled their food purpose). The feedstock used to generate second-generation biofuels thus either grows on arable lands, but are just byproducts of the actual harvest (main crop) or they are grown on lands which cannot be used to effectively grow food crops and in some cases neither extra water or fertilizer is applied to them. Non-human food second generation feedstock sources include grasses, jatropha and other seed crops, waste vegetable oil, municipal solid waste and so forth.\n\nThis has both advantages and disadvantages. The advantage is that, unlike with regular food crops, no arable land is used solely for the production of fuel. The disadvantage is that unlike with regular food crops, it may be rather difficult to extract the fuel. For instance, a series of physical and chemical treatments might be required to convert lignocellulosic biomass to liquid fuels suitable for transportation.\n\nFrom 1978 to 1996, the US NREL experimented with using algae as a biofuels source in the \"Aquatic Species Program\". A self-published article by Michael Briggs, at the UNH Biofuels Group, offers estimates for the realistic replacement of all vehicular fuel with biofuels by using algae that have a natural oil content greater than 50%, which Briggs suggests can be grown on algae ponds at wastewater treatment plants. This oil-rich algae can then be extracted from the system and processed into biofuels, with the dried remainder further reprocessed to create ethanol. The production of algae to harvest oil for biofuels has not yet been undertaken on a commercial scale, but feasibility studies have been conducted to arrive at the above yield estimate. In addition to its projected high yield, algaculture – unlike crop-based biofuels – does not entail a decrease in food production, since it requires neither farmland nor fresh water. Many companies are pursuing algae bioreactors for various purposes, including scaling up biofuels production to commercial levels. Prof. Rodrigo E. Teixeira from the University of Alabama in Huntsville demonstrated the extraction of biofuels lipids from wet algae using a simple and economical reaction in ionic liquids.\n\nSimilarly to third-generation biofuels, fourth-generation biofuels are made using non-arable land. However, unlike third-generation biofuels, they do not require the destruction of biomass. This class of biofuels includes electrofuels and photobiological solar fuels. Some of these fuels are carbon-neutral.\n\nThe following fuels can be produced using first, second, third or fourth-generation biofuel production procedures. Most of these can even be produced using two or three of the different biofuel generation procedures.\n\nBiogas is methane produced by the process of anaerobic digestion of organic material by anaerobes. It can be produced either from biodegradable waste materials or by the use of energy crops fed into anaerobic digesters to supplement gas yields. The solid byproduct, digestate, can be used as a biofuel or a fertilizer.\n\nBiogas can be recovered from mechanical biological treatment waste processing systems. Landfill gas, a less clean form of biogas, is produced in landfills through naturally occurring anaerobic digestion. If it escapes into the atmosphere, it is a potential greenhouse gas.\n\nFarmers can produce biogas from manure from their cattle by using anaerobic digesters.\n\nSyngas, a mixture of carbon monoxide, hydrogen and other hydrocarbons, is produced by partial combustion of biomass, that is, combustion with an amount of oxygen that is not sufficient to convert the biomass completely to carbon dioxide and water. Before partial combustion, the biomass is dried, and sometimes pyrolysed. The resulting gas mixture, syngas, is more efficient than direct combustion of the original biofuel; more of the energy contained in the fuel is extracted.\n\nSyngas may be burned directly in internal combustion engines, turbines or high-temperature fuel cells. The wood gas generator, a wood-fueled gasification reactor, can be connected to an internal combustion engine.\n\nSyngas can be used to produce methanol, DME and hydrogen, or converted via the Fischer-Tropsch process to produce a diesel substitute, or a mixture of alcohols that can be blended into gasoline. Gasification normally relies on temperatures greater than 700 °C.\n\nLower-temperature gasification is desirable when co-producing biochar, but results in syngas polluted with tar.\n\nBiologically produced alcohols, most commonly ethanol, and less commonly propanol and butanol, are produced by the action of microorganisms and enzymes through the fermentation of sugars or starches (easiest), or cellulose (which is more difficult). Biobutanol (also called biogasoline) is often claimed to provide a direct replacement for gasoline, because it can be used directly in a gasoline engine.\nEthanol fuel is the most common biofuel worldwide, particularly in Brazil. Alcohol fuels are produced by fermentation of sugars derived from wheat, corn, sugar beets, sugar cane, molasses and any sugar or starch from which alcoholic beverages such as whiskey, can be made (such as potato and fruit waste, etc.). The ethanol production methods used are enzyme digestion (to release sugars from stored starches), fermentation of the sugars, distillation and drying. The distillation process requires significant energy input for heat (sometimes unsustainable natural gas fossil fuel, but cellulosic biomass such as bagasse, the waste left after sugar cane is pressed to extract its juice, is the most common fuel in Brazil, while pellets, wood chips and also waste heat are more common in Europe) Waste steam fuels ethanol factory – where waste heat from the factories also is used in the district heating grid.\n\nEthanol can be used in petrol engines as a replacement for gasoline; it can be mixed with gasoline to any percentage. Most existing car petrol engines can run on blends of up to 15% bioethanol with petroleum/gasoline. Ethanol has a smaller energy density than that of gasoline; this means it takes more fuel (volume and mass) to produce the same amount of work. An advantage of ethanol () is that it has a higher octane rating than ethanol-free gasoline available at roadside gas stations, which allows an increase of an engine's compression ratio for increased thermal efficiency. In high-altitude (thin air) locations, some states mandate a mix of gasoline and ethanol as a winter oxidizer to reduce atmospheric pollution emissions.\n\nEthanol is also used to fuel bioethanol fireplaces. As they do not require a chimney and are \"flueless\", bioethanol fires are extremely useful for newly built homes and apartments without a flue.\nThe downsides to these fireplaces is that their heat output is slightly less than electric heat or gas fires, and precautions must be taken to avoid carbon monoxide poisoning.\n\nCorn-to-ethanol and other food stocks has led to the development of cellulosic ethanol. According to a joint research agenda conducted through the US Department of Energy, the fossil energy ratios (FER) for cellulosic ethanol, corn ethanol, and gasoline are 10.3, 1.36, and 0.81, respectively.\n\nEthanol has roughly one-third lower energy content per unit of volume compared to gasoline. This is partly counteracted by the better efficiency when using ethanol (in a long-term test of more than 2.1 million km, the BEST project found FFV vehicles to be 1–26% more energy efficient than petrol cars, but the volumetric consumption increases by approximately 30%, so more fuel stops are required).\n\nWith current subsidies, ethanol fuel is slightly cheaper per distance traveled in the United States.\n\nMethanol is currently produced from natural gas, a non-renewable fossil fuel. In the future it is hoped to be produced from biomass as biomethanol. This is technically feasible, but the production is currently being postponed for concerns of Jacob S. Gibbs and Brinsley Coleberd that the economic viability is still pending. The methanol economy is an alternative to the hydrogen economy, compared to today's hydrogen production from natural gas.\n\nButanol () is formed by ABE fermentation (acetone, butanol, ethanol) and experimental modifications of the process show potentially high net energy gains with butanol as the only liquid product. Butanol will produce more energy and allegedly can be burned \"straight\" in existing gasoline engines (without modification to the engine or car), and is less corrosive and less water-soluble than ethanol, and could be distributed via existing infrastructures. DuPont and BP are working together to help develop butanol. \"Escherichia coli\" strains have also been successfully engineered to produce butanol by modifying their amino acid metabolism. One drawback to butanol production in E. coli remains the high cost of nutrient rich media, however, recent work has demonstrated E. coli can produce butanol with minimal nutritional supplementation.\n\nBiodiesel is the most common biofuel in Europe. It is produced from oils or fats using transesterification and is a liquid similar in composition to fossil/mineral diesel. Chemically, it consists mostly of fatty acid methyl (or ethyl) esters (FAMEs). Feedstocks for biodiesel include animal fats, vegetable oils, soy, rapeseed, jatropha, mahua, mustard, flax, sunflower, palm oil, hemp, field pennycress, \"Pongamia pinnata\" and algae. Pure biodiesel (B100, also known as \"neat\" biodiesel) currently reduces emissions with up to 60% compared to diesel Second generation B100.\n\nBiodiesel can be used in any diesel engine when mixed with mineral diesel. It can also be used in its pure form (B100) in diesel engines, but some maintenance and performance problems may then occur during wintertime utilization, since the fuel becomes somewhat more viscous at lower temperatures, depending on the feedstock used. In some countries, manufacturers cover their diesel engines under warranty for B100 use, although Volkswagen of Germany, for example, asks drivers to check by telephone with the VW environmental services department before switching to B100. In most cases, biodiesel is compatible with diesel engines from 1994 onwards, which use 'Viton' (by DuPont) synthetic rubber in their mechanical fuel injection systems. Note however, that no vehicles are certified for using pure biodiesel before 2014, as there was no emission control protocol available for biodiesel before this date.\n\nElectronically controlled 'common rail' and 'unit injector' type systems from the late 1990s onwards may only use biodiesel blended with conventional diesel fuel. These engines have finely metered and atomized multiple-stage injection systems that are very sensitive to the viscosity of the fuel. Many current-generation diesel engines are made so that they can run on B100 without altering the engine itself, although this depends on the fuel rail design.\nSince biodiesel is an effective solvent and cleans residues deposited by mineral diesel, engine filters may need to be replaced more often, as the biofuel dissolves old deposits in the fuel tank and pipes. It also effectively cleans the engine combustion chamber of carbon deposits, helping to maintain efficiency. In many European countries, a 5% biodiesel blend is widely used and is available at thousands of gas stations. Biodiesel is also an oxygenated fuel, meaning it contains a reduced amount of carbon and higher hydrogen and oxygen content than fossil diesel. This improves the combustion of biodiesel and reduces the particulate emissions from unburnt carbon. However, using pure biodiesel may increase NO-emissions\n\nBiodiesel is also safe to handle and transport because it is non-toxic and biodegradable, and has a high flash point of about 300 °F (148 °C) compared to petroleum diesel fuel, which has a flash point of 125 °F (52 °C).\n\nIn the US, more than 80% of commercial trucks and city buses run on diesel. The emerging US biodiesel market is estimated to have grown 200% from 2004 to 2005. \"By the end of 2006 biodiesel production was estimated to increase fourfold [from 2004] to more than\" .\n\nIn France, biodiesel is incorporated at a rate of 8% in the fuel used by all French diesel vehicles. Avril Group produces under the brand Diester, a fifth of 11 million tons of biodiesel consumed annually by the European Union. It is the leading European producer of biodiesel.\n\nGreen diesel is produced through hydrocracking biological oil feedstocks, such as vegetable oils and animal fats. Hydrocracking is a refinery method that uses elevated temperatures and pressure in the presence of a catalyst to break down larger molecules, such as those found in vegetable oils, into shorter hydrocarbon chains used in diesel engines. It may also be called renewable diesel, hydrotreated vegetable oil or hydrogen-derived renewable diesel. Unlike biodiesel, green diesel has exactly the same chemical properties as petroleum-based diesel. It does not require new engines, pipelines or infrastructure to distribute and use, but has not been produced at a cost that is competitive with petroleum. Gasoline versions are also being developed. Green diesel is being developed in Louisiana and Singapore by ConocoPhillips, Neste Oil, Valero, Dynamic Fuels, and Honeywell UOP as well as Preem in Gothenburg, Sweden, creating what is known as Evolution Diesel.\n\nStraight unmodified edible vegetable oil is generally not used as fuel, but lower-quality oil has been used for this purpose. Used vegetable oil is increasingly being processed into biodiesel, or (more rarely) cleaned of water and particulates and then used as a fuel.\n\nAs with 100% biodiesel (B100), to ensure the fuel injectors atomize the vegetable oil in the correct pattern for efficient combustion, vegetable oil fuel must be heated to reduce its viscosity to that of diesel, either by electric coils or heat exchangers. This is easier in warm or temperate climates. MAN B&W Diesel, Wärtsilä, and Deutz AG, as well as a number of smaller companies, such as Elsbett, offer engines that are compatible with straight vegetable oil, without the need for after-market modifications.\n\nVegetable oil can also be used in many older diesel engines that do not use common rail or unit injection electronic diesel injection systems. Due to the design of the combustion chambers in indirect injection engines, these are the best engines for use with vegetable oil. This system allows the relatively larger oil molecules more time to burn. Some older engines, especially Mercedes, are driven experimentally by enthusiasts without any conversion, a handful of drivers have experienced limited success with earlier pre-\"Pumpe Duse\" VW TDI engines and other similar engines with direct injection. Several companies, such as Elsbett or Wolf, have developed professional conversion kits and successfully installed hundreds of them over the last decades.\n\nOils and fats can be hydrogenated to give a diesel substitute. The resulting product is a straight-chain hydrocarbon with a high cetane number, low in aromatics and sulfur and does not contain oxygen. Hydrogenated oils can be blended with diesel in all proportions. They have several advantages over biodiesel, including good performance at low temperatures, no storage stability problems and no susceptibility to microbial attack.\n\nBioethers (also referred to as fuel ethers or oxygenated fuels) are cost-effective compounds that act as octane rating enhancers.\"Bioethers are produced by the reaction of reactive iso-olefins, such as iso-butylene, with bioethanol.\" Bioethers are created by wheat or sugar beet. They also enhance engine performance, while significantly reducing engine wear and toxic exhaust emissions. Although bioethers are likely to replace petroethers in the UK, it is highly unlikely they will become a fuel in and of itself due to the low energy density. Greatly reducing the amount of ground-level ozone emissions, they contribute to air quality.\n\nWhen it comes to transportation fuel there are six ether additives: dimethyl ether (DME), diethyl ether (DEE), methyl teritiary-butyl ether (MTBE), ethyl \"ter\"-butyl ether (ETBE), t\"er\"-amyl methyl ether (TAME), and \"ter\"-amyl ethyl ether (TAEE).\n\nThe European Fuel Oxygenates Association (EFOA) credits methyl Ttertiary-butyl ether (MTBE) and ethyl ter-butyl ether (ETBE) as the most commonly used ethers in fuel to replace lead. Ethers were introduced in Europe in the 1970s to replace the highly toxic compound. Although Europeans still use bio-ether additives, the US no longer has an oxygenate requirement therefore bio-ethers are no longer used as the main fuel additive.\n\nExamples include wood, sawdust, grass trimmings, domestic refuse, charcoal, agricultural waste, nonfood energy crops, and dried manure.\n\nWhen solid biomass is already in a suitable form (such as firewood), it can burn directly in a stove or furnace to provide heat or raise steam. When solid biomass is in an inconvenient form (such as sawdust, wood chips, grass, urban waste wood, agricultural residues), the typical process is to densify the biomass. This process includes grinding the raw biomass to an appropriate particulate size (known as hogfuel), which, depending on the densification type, can be from , which is then concentrated into a fuel product. The current processes produce wood pellets, cubes, or pucks. The pellet process is most common in Europe, and is typically a pure wood product. The other types of densification are larger in size compared to a pellet and are compatible with a broad range of input feedstocks. The resulting densified fuel is easier to transport and feed into thermal generation systems, such as boilers.\n\nSawdust, bark and chips are already used for decades for fuel in industrial processes; examples include the pulp and paper industry and the sugar cane industry. Boilers in the range of 500,000 lb/hr of steam, and larger, are in routine operation, using grate, spreader stoker, suspension burning and fluid bed combustion. Utilities generate power, typically in the range of 5 to 50 MW, using locally available fuel. Other industries have also installed wood waste fueled boilers and dryers in areas with low-cost fuel.\n\nOne of the advantages of solid biomass fuel is that it is often a byproduct, residue or waste-product of other processes, such as farming, animal husbandry and forestry. In theory, this means fuel and food production do not compete for resources, although this is not always the case.\n\nA problem with the combustion of solid biomass fuels is that it emits considerable amounts of pollutants, such as particulates and polycyclic aromatic hydrocarbons. Even modern pellet boilers generate much more pollutants than oil or natural gas boilers. Pellets made from agricultural residues are usually worse than wood pellets, producing much larger emissions of dioxins and chlorophenols.\n\nA derived fuel is biochar, which is produced by biomass pyrolysis. Biochar made from agricultural waste can substitute for wood charcoal. As wood stock becomes scarce, this alternative is gaining ground. In eastern Democratic Republic of Congo, for example, biomass briquettes are being marketed as an alternative to charcoal to protect Virunga National Park from deforestation associated with charcoal production.\n\nThere are international organizations such as IEA Bioenergy, established in 1978 by the OECD International Energy Agency (IEA), with the aim of improving cooperation and information exchange between countries that have national programs in bioenergy research, development and deployment. The UN International Biofuels Forum is formed by Brazil, China, India, Pakistan, South Africa, the United States and the European Commission. The world leaders in biofuel development and use are Brazil, the United States, France, Sweden and Germany. Russia also has 22% of world's forest, and is a big biomass (solid biofuels) supplier. In 2010, Russian pulp and paper maker, Vyborgskaya Cellulose, said they would be producing pellets that can be used in heat and electricity generation from its plant in Vyborg by the end of the year. The plant will eventually produce about 900,000 tons of pellets per year, making it the largest in the world once operational.\n\nBiofuels currently make up 3.1% of the total road transport fuel in the UK or 1,440 million litres. By 2020, 10% of the energy used in UK road and rail transport must come from renewable sources – this is the equivalent of replacing 4.3 million tonnes of fossil oil each year. Conventional biofuels are likely to produce between 3.7 and 6.6% of the energy needed in road and rail transport, while advanced biofuels could meet up to 4.3% of the UK's renewable transport fuel target by 2020.\n\nBiofuels are similar to fossil fuels in that biofuels contribute to air pollution. Burning produces carbon dioxide, airborne carbon particulates, carbon monoxide and nitrous oxides. The WHO estimates 3.7 million premature deaths worldwide in 2012 due to air pollution. Brazil burns significant amounts of ethanol biofuel. Gas chromatograph studies were performed of ambient air in São Paulo, Brazil, and compared to Osaka, Japan, which does not burn ethanol fuel. Atmospheric Formaldehyde was 160% higher in Brazil, and Acetaldehyde was 260% higher.\n\nThe Environmental Protection Agency has acknowledged in April 2007 that the increased use of bio-ethanol will lead to worse air quality. The total emissions of air pollutants such as nitrogen oxides will rise due the growing use of bio-ethanol. There is an increase in carbon dioxide from the burning of fossil fuels to produce the biofuels as well as nitrous oxide from the soil, which has most likely been treated with nitrogen fertilizer. Nitrous oxide is known to have a greater impact on the atmosphere in relation to global warming, as it is also an ozone destroyer.\n\nThere are various social, economic, environmental and technical issues with biofuel production and use, which have been discussed in the popular media and scientific journals. These include: the effect of moderating oil prices, the \"food vs fuel\" debate, food prices, poverty reduction potential, energy ratio, energy requirements, carbon emissions levels, sustainable biofuel production, deforestation and soil erosion, loss of biodiversity, impact on water resources, the possible modifications necessary to run the engine on biofuel, as well as energy balance and efficiency. The International Resource Panel, which provides independent scientific assessments and expert advice on a variety of resource-related themes, assessed the issues relating to biofuel use in its first report \"Towards sustainable production and use of resources: Assessing Biofuels\". \"Assessing Biofuels\" outlined the wider and interrelated factors that need to be considered when deciding on the relative merits of pursuing one biofuel over another. It concluded that not all biofuels perform equally in terms of their impact on climate, energy security and ecosystems, and suggested that environmental and social impacts need to be assessed throughout the entire life-cycle.\n\nAnother issue with biofuel use and production is the US has changed mandates many times because the production has been taking longer than expected. The Renewable Fuel Standard (RFS) set by congress for 2010 was pushed back to at best 2012 to produce 100 million gallons of pure ethanol (not blended with a fossil fuel).\n\nIn the EU, the revised renewable energy directive calls for a complete ban on first-generation biofuels by 2030. Particularly fuels made from such oils such as palm oil and soy oil are being targeted.\n\nMany of the biofuels that were being supplied in 2008 (using the first-generation biofuel production procedure) have been criticised for their adverse impacts on the natural environment, food security, and land use. In 2008, the Nobel-prize winning chemist Paul J. Crutzen published findings that the release of nitrous oxide (NO) emissions in the production of biofuels means that overall they contribute more to global warming than the fossil fuels they replace.\nIn 2008, the challenge was to support biofuel development, including the development of new cellulosic technologies, with responsible policies and economic instruments to help ensure that biofuel commercialization is sustainable. Responsible commercialization of biofuels represented an opportunity to enhance sustainable economic prospects in Africa, Latin America and Asia.\nNow, biofuels in the form of liquid fuels derived from plant materials are entering the market, driven by the perception that they reduce climate gas emissions, and also by factors such as oil price spikes and the need for increased energy security.\n\nAccording to the Rocky Mountain Institute, sound biofuel production practices would not hamper food and fibre production, nor cause water or environmental problems, and would enhance soil fertility. The selection of land on which to grow the feedstocks is a critical component of the ability of biofuels to deliver sustainable solutions. A key consideration is the minimisation of biofuel competition for prime cropland.\n\nSome scientists have expressed concerns about land-use change in response to greater demand for crops to use for biofuel and the subsequent carbon emissions. The payback period, that is, the time it will take biofuels to pay back the carbon debt they acquire due to land-use change, has been estimated to be between 100 and 1000 years, depending on the specific instance and location of land-use change. However, no-till practices combined with cover-crop practices can reduce the payback period to three years for grassland conversion and 14 years for forest conversion.\n\nA study conducted in the Tocantis State, in northern Brazil, found that many families were cutting down forests in order to produce two conglomerates of oilseed plants, the J. curcas (JC group) and the R. communis (RC group). This region is composed of 15% Amazonian rainforest with high biodiversity, and 80% Cerrado forest with lower biodiversity. During the study, the farmers that planted the JC group released over 2193 Mg CO, while losing 53-105 Mg CO sequestration from deforestation; and the RC group farmers released 562 Mg CO, while losing 48-90 Mg CO to be sequestered from forest depletion. The production of these types of biofuels not only led into an increased emission of carbon dioxide, but also to lower efficiency of forests to absorb the gases that these farms were emitting. This has to do with the amount of fossil fuel the production of fuel crops involves. In addition, the intensive use of monocropping agriculture requires large amounts of water irrigation, as well as of fertilizers, herbicides and pesticides. This does not only lead to poisonous chemicals to disperse on water runoff, but also to the emission of nitrous oxide (NO) as a fertilizer byproduct, which is three hundred times more efficient in producing a greenhouse effect than carbon dioxide (CO).\n\nConverting rainforests, peatlands, savannas, or grasslands to produce food crop–based biofuels in Brazil, Southeast Asia, and the United States creates a “biofuel carbon debt” by releasing 17 to 420 times more CO than the annual greenhouse gas (GHG) reductions that these biofuels would provide by displacing fossil fuels. Biofuels made from waste biomass or from biomass grown on abandoned agricultural lands incur little to no carbon debt.\n\nIn addition to crop growth requiring water, biofuel facilities require significant process water.\n\nScientific research (20th century) shows that carbon dioxide emissions from all forms of surface transport are converted in a few weeks by forests, farms and oceans into biomass. This implies that a greater emphasis on sustainable forestry is very relevant for climate protection and sustainable, energy-efficient transport.\n\nResearch is ongoing into finding more suitable biofuel crops and improving the oil yields of these crops. Using the current yields, vast amounts of land and fresh water would be needed to produce enough oil to completely replace fossil fuel usage. It would require twice the land area of the US to be devoted to soybean production, or two-thirds to be devoted to rapeseed production, to meet current US heating and transportation needs. \n\nSpecially bred mustard varieties can produce reasonably high oil yields and are very useful in crop rotation with cereals, and have the added benefit that the meal left over after the oil has been pressed out can act as an effective and biodegradable pesticide.\n\nThe NFESC, with Santa Barbara-based Biodiesel Industries, is working to develop biofuels technologies for the US navy and military, one of the largest diesel fuel users in the world.\nA group of Spanish developers working for a company called Ecofasa announced a new biofuel made from trash. The fuel is created from general urban waste which is treated by bacteria to produce fatty acids, which can be used to make biofuels. Before its shutdown, Joule Unlimited was attempting to make cheap ethanol and biodiesel from a genetically modified photosynthetic bacterium.\n\nAs the primary source of biofuels in North America, many organizations are conducting research in the area of ethanol production. The National Corn-to-Ethanol Research Center (NCERC) is a research division of Southern Illinois University Edwardsville dedicated solely to ethanol-based biofuel research projects.\nOn the federal level, the USDA conducts a large amount of research regarding ethanol production in the United States. Much of this research is targeted toward the effect of ethanol production on domestic food markets. A division of the U.S. Department of Energy, the National Renewable Energy Laboratory (NREL), has also conducted various ethanol research projects, mainly in the area of cellulosic ethanol.\n\nCellulosic ethanol commercialization is the process of building an industry out of methods of turning cellulose-containing organic matter into fuel. Companies, such as Iogen, POET, and Abengoa, are building refineries that can process biomass and turn it into bioethanol. Companies, such as Diversa, Novozymes, and Dyadic, are producing enzymes that could enable a cellulosic ethanol future. The shift from food crop feedstocks to waste residues and native grasses offers significant opportunities for a range of players, from farmers to biotechnology firms, and from project developers to investors.\n\nAs of 2013, the first commercial-scale plants to produce cellulosic biofuels have begun operating. Multiple pathways for the conversion of different biofuel feedstocks are being used. In the next few years, the cost data of these technologies operating at commercial scale, and their relative performance, will become available. Lessons learnt will lower the costs of the industrial processes involved.\n\nIn parts of Asia and Africa where drylands prevail, sweet sorghum is being investigated as a potential source of food, feed and fuel combined. The crop is particularly suitable for growing in arid conditions, as it only extracts one seventh of the water used by sugarcane. In India, and other places, sweet sorghum stalks are used to produce biofuel by squeezing the juice and then fermenting into ethanol.\n\nA study by researchers at the International Crops Research Institute for the Semi-Arid Tropics (ICRISAT) found that growing sweet sorghum instead of grain sorghum could increase farmers incomes by US$40 per hectare per crop because it can provide fuel in addition to food and animal feed. With grain sorghum currently grown on over 11 million hectares (ha) in Asia and on 23.4 million ha in Africa, a switch to sweet sorghum could have a considerable economic impact.\n\nSeveral groups in various sectors are conducting research on \"Jatropha curcas\", a poisonous shrub-like tree that produces seeds considered by many to be a viable source of biofuels feedstock oil. Much of this research focuses on improving the overall per acre oil yield of Jatropha through advancements in genetics, soil science, and horticultural practices.\n\nSG Biofuels, a San Diego-based jatropha developer, has used molecular breeding and biotechnology to produce elite hybrid seeds that show significant yield improvements over first-generation varieties. SG Biofuels also claims additional benefits have arisen from such strains, including improved flowering synchronicity, higher resistance to pests and diseases, and increased cold-weather tolerance.\n\nPlant Research International, a department of the Wageningen University and Research Centre in the Netherlands, maintains an ongoing Jatropha Evaluation Project that examines the feasibility of large-scale jatropha cultivation through field and laboratory experiments.\nThe Center for Sustainable Energy Farming (CfSEF) is a Los Angeles-based nonprofit research organization dedicated to jatropha research in the areas of plant science, agronomy, and horticulture. Successful exploration of these disciplines is projected to increase jatropha farm production yields by 200-300% in the next 10 years.\n\nA group at the Russian Academy of Sciences in Moscow, in a 2008 paper, stated they had isolated large amounts of lipids from single-celled fungi and turned it into biofuels in an economically efficient manner. More research on this fungal species, \"Cunninghamella\" \"japonica\", and others, is likely to appear in the near future.\nThe recent discovery of a variant of the fungus \"Gliocladium roseum\" (later renamed Ascocoryne sarcoides) points toward the production of so-called myco-diesel from cellulose. This organism was recently discovered in the rainforests of northern Patagonia, and has the unique capability of converting cellulose into medium-length hydrocarbons typically found in diesel fuel. Many other fungi that can degrade cellulose and other polymers have been observed to produce molecules that are currently being engineered using organisms from other kingdoms, suggesting that fungi may play a large role in the bio-production of fuels in the future (reviewed in ).\n\nMicrobial gastrointestinal flora in a variety of animals have shown potential for the production of biofuels. Recent research has shown that TU-103, a strain of \"Clostridium\" bacteria found in Zebra feces, can convert nearly any form of cellulose into butanol fuel. Microbes in panda waste are being investigated for their use in creating biofuels from bamboo and other plant materials. There has also been substantial research into the technology of using the gut microbiomes of wood-feeding insects for the conversion of lignocellulotic material into biofuel.\n\n\n"}
{"id": "48834013", "url": "https://en.wikipedia.org/wiki?curid=48834013", "title": "DAVI", "text": "DAVI\n\nThe Dutch Automated Vehicle Initiative (DAVI) is a research and demonstration initiative developing automated vehicles for use on public roads.\n\nThe project is special in that, besides simply making driverless cars, it also focuses on having the automated vehicles share information amongst each other. The aim is to have the cars helping to avoid traffic congestion, by reducing the safety distance between the cars (from 2 seconds drive distance now to just 0.5 seconds) and avoiding sudden traffic slow-downs (due to manoeuvres undertaken by drivers).\n"}
{"id": "34296790", "url": "https://en.wikipedia.org/wiki?curid=34296790", "title": "Data infrastructure", "text": "Data infrastructure\n\nA data infrastructure is a digital infrastructure promoting data sharing and consumption. \n\nSimilarly to other infrastructures, it is a structure needed for the operation of a society as well as the services and facilities necessary for an economy to function, the data economy in this case.\n\nThere is an intense discussion at international level on e-infrastructures and data infrastructure serving scientific work. \nThe European Strategy Forum on Research Infrastructures (ESFRI) presented the first European roadmap for large-scale Research Infrastructures. \nThese are modeled as layered hardware and software systems which support sharing of a wide spectrum of resources, spanning from networks, storage, computing resources, and system-level middleware software, to structured information within collections, archives, and databases. The e-Infrastructure Reflection Group (e-IRG) has proposed a similar vision. \nIn particular, it envisions e-Infrastructures where the principles of global collaboration and shared resources are intended to encompass the sharing needs of all research activities. \n\nIn the framework of the Joint Information Systems Committee (JISC) e-infrastructure programme, e-Infrastructures are defined in terms of integration of networks, grids, data centers and collaborative environments, and are intended to include supporting operation centers, service registries, credential delegation services, certificate authorities, training and help desk services. The Cyberinfrastructure programme launched by the US National Science Foundation (NSF) plans to develop new research environments in which advanced computational, collaborative, data acquisition and management services are made available to researchers connected through high-performance networks. \n\nMore recently, the vision for “global research data infrastructures” has been drawn by identifying a number of recommendations for developers of future research infrastructures. \nThis vision document highlighted the open issues affecting data infrastructures development – both technical and organizational – and identified future research directions. \nBesides these initiatives targeting “generic” infrastructures there are others oriented to specific domains, e.g. the European commission promotes the INSPIRE initiative for an e-Infrastructure oriented to the sharing of content and service resources of European countries in the ambit of geospatial datasets.\n\n\n"}
{"id": "28043264", "url": "https://en.wikipedia.org/wiki?curid=28043264", "title": "Diamond grinding", "text": "Diamond grinding\n\nDiamond grinding is a grinding process that can be applied to a variety of surfaces including floors, stones and engineering ceramics. It takes advantage of the fact that diamond has the highest hardness of any bulk material.\n\n"}
{"id": "31890739", "url": "https://en.wikipedia.org/wiki?curid=31890739", "title": "EIDR", "text": "EIDR\n\nEIDR, or the Entertainment Identifier Registry, is a global unique identifier system for a broad array of audio visual objects, including motion pictures, television, and radio programs. The identification system resolves an identifier to a metadata record that is associated with top-level titles, edits, DVDs, encodings, clips, and mash-ups. EIDR also provides identifiers for Video Service providers, such as broadcast and cable networks.\n\nAs of February, 2018, EIDR contains over 1.8 million records, including 298K movies, and 794K episodes of over 25K TV series.\nEIDR is an implementation of a Digital Object Identifier (DOI).\n\nMedia asset identification systems have existed for decades. The common motivation for their creation is to enable the management of media assets through the assignment of a unique id to a set of metadata representing salient characteristics of each asset. Over time such systems tend to proliferate, with each arising to deal with a specific set of issues. As a result, there is considerable variation between systems in terms of which assets are categorized, which metadata is associated with each asset, and the very definition of an asset. To name a few examples, should a “director’s cut” of a movie be distinct from the original theatrical release? How should regional variations (e.g. translation of the title or dialog into foreign languages) be accounted for? Further complications include the procedures (and required credentials) for adding new assets, editing existing assets, and creating derivative assets.\n\nEIDR was created to address these issues, as well as others encountered in video asset workflows, both in a B2B context and the intramural post-production activities of content producers. EIDR has the following characteristics:\n\nEIDR is intended to supplement —not replace— existing asset identification systems. To the contrary, a key feature is to allow an EIDR record to include references to that asset’s ID under other systems. This feature is particularly useful for film and television archives, making it easy for them to cross-reference their holdings with other sources for the work and metadata about it. By design, EIDR does not replicate features of other asset ID systems, e.g. commercial systems that seek to add value through enhanced metadata (e.g. plot summaries, production details). It is also a non-goal to track ownership and rights information, which can, however, be implemented as applications that use the EIDR ID.\n\nEIDR is built on a collection of records (which are further sub-divided into fields) that are stored in a central registry. These records are referenced externally by DOIs, which are assigned when a record is created, and each identifier is immutable thereafter. The identifier resolution system underlying DOIs is the Handle System and so each native EIDR Content ID is a handle formatted, in increasing specificity, to handle, DOI and EIDR standards.\n\nThe canonical form of an EIDR Content ID is an instance of a Handle and has the format:\n\nwhere\nThere is also a 96-bit Compact Binary form that is intended for embedding in small payloads such as watermarks. This form is generated from the canonical format as follows:\nThe URN form for an EIDR ID is specified in IETF RFC 7302.\n\nFor use on the web an EIDR content ID can be represented as a URI in one of these forms:\n\nThere are four types of content records, each associated with a reserved prefix:\n\nThe sub-prefixes 5237, 5238, 5239, and 5240 are all assigned to the EIDR Association.\n\nContent records are objects categorized by their types and relationships. Each has three different (orthogonal) kinds of type:\n\nThe following fields (taken from a larger set) comprise the base object data of a content record:\n\nAn EIDR ID must be always resolvable, thus under normal circumstances the corresponding Content Record will be permanent. There are two mechanisms available to deal with errors or other unusual circumstances. The preferred one is aliasing, whereby an EIDR ID is transparently redirected to another content record. Aliasing is commonly employed to deal with an asset being registered twice.\n\nThe other mechanism is the use of tombstone records. This is employed when the Content Record is corrupted, or an otherwise invalid asset was accidentally registered. In this case the ID will be aliased to a special tombstone record. The tombstone can be recognized by applications because its EIDR ID field will be set to the distinguished value “10.5240/0000-0000-0000-0000-0000-X”. Note that “X” means the 24th letter of the Latin alphabet (ASCII 0x58 or U+0058).\n\nHaving a rich set of Alternate IDs for content is one of the primary goals of EIDR. This allows EIDR IDs to be used everywhere in content workflows; if an alternate ID is needed it can be found in the metadata for the EIDR ID. EIDR supports the inclusion both proprietary and other standard (e.g. ISAN) ID references. Additional Alternate IDs can be added when needed (e.g. by parties wanting to support new workflows). Below is an example of alternate IDs for the EIDR asset 10.5240/EA73-79D7-1B2B-B378-3A73-M (the movie “Blade Runner”). If an Alternate ID is resolvable algorithmically, for example by placing it appropriately in a template URL, EIDR makes that link available.\n\nAlternate IDs are partitioned into non-proprietary and proprietary. The former have distinguished, predefined types (e.g. those issued by ISAN, IMDb, and IVA), whereas proprietary IDs are all of type “Proprietary”, and are further distinguished by an associated DNS domain. As of July, 2017, there are over 2 million Alternate IDs directly available through EIDR.\n\nContent objects can be related to each other according to the following table. These relations are expressed as additional fields in the content record and are thus relative to that object. Note that the subject object is the child and the target is the parent (e.g. subject is<relation-type>Of parent). Additional constraints are noted in the table.\n\nUse in Standards & Applications\nEIDR has been incorporated into many standards. A few of the more significant ones are listed here:\nEIDR identifiers have found their way into an increasing number of commercial applications. The following are illustrative of some of the advantages of using EIDR:\n\nEIDR is administered by the non-profit EIDR Association, which was founded in October 2010 by MovieLabs, CableLabs, Comcast and Rovi. Membership has grown steadily since then: as of late-2014 it has 79 members divided between the Industry Promoters and Industry Contributor levels. The fastest growing category is non-US companies, which now accounts for about 20% of membership.\nThe EIDR Association operates two EIDR registries: Production and Sandbox. The former is the official site, and the latter is reserved for test and development. Both systems are available publicly online, but the contents of the sandbox are not guaranteed to be correct, complete, or even to refer to assets that exist. Only members of the EIDR association may modify the registry.\n\nRegistration of new assets can be done individually or in bulk (up to 100,000 assets at a time). In either case, the workflow comprises a combination of automated (to perform well-defined but tedious tasks) and manual (where human judgment is called for) processes. It is also iterative, as the initial matching process may identify a variety of gaps and errors that need to be dealt with.\n\nRegistering new assets is a complex process that requires some preparation, particularly in the case of bulk submission. The automated processes will check syntax, make sure that the basic metadata is supplied, and that any dependencies (e.g. series records created before constituent episodes) are honored. Manual steps include making sure the correct Parties are associated with the asset. One of the most important steps is ensuring that a new asset does not already exist in the registry: this is covered in the next section.\n\nIn order to register a new asset a user must be associated with a party that has been granted the “Registrant” role by the EIDR operator. A registrant may be a principal agent, such as a studio or an encoding house, but it may also be a Party doing bulk registration of back‐catalogue items, or a Party acting on behalf of someone else. It is also a requirement that a registrant be an EIDR member. In general, content ownership, metadata authority, and registration capability are separate and unrelated concepts.\n\nThis refers to flagging assets being submitted to the registry as falling into one of the following three categories:\nThis assessment is based on applying a (large) set of rules to the candidate asset, which results a numerical score. Bucketing occurs as the result of comparing the score to two thresholds:\nAssets falling between the low and high threshold are deemed to have a high possibility of being a duplicate: the proposed record addition/modification will not proceed until manually reviewed by EIDR operations staff.\n\nThe components of the EIDR system are shown below.\nThe principal functional blocks are as follows:\n\nAn EIDR ID is a specialized example of a Digital Object Identifier (DOI), which in turn is built on top of the Handle System developed by the Corporation for National Research Initiatives (CNRI). The EIDR-specific aspects of the lower layers are described in more detail below.\n\nA Digital Object Identifier, standardized as ISO 26324, seeks to uniquely identify a wide range of digital artifacts including books, recordings, research data, and other digital content. The goal is not just for the IDs to be unique, but persistent and immutable. As opposed to URLs, DOI identifiers stay the same even if the objects move to another location, or become owned by another organization. Here are some of the characteristics of DOI:\nThe DOI data model provides the means to associate metadata with each object, as well as policies governing its use. In the words of the DOI Handbook, metadata may include “names, identifiers, descriptions, types, classifications, locations, times, measurements, relationships and any other kind of information related to [an object].” Metadata flows between the following entities:\nTo foster interoperability between RAs, DOI has the concept of a metadata Kernel. This is a core set of metadata that all objects stored within the DOI framework should have. The full set may be found in the DOI handbook. Interoperability is a large topic extending beyond the scope of EIDR, but the following subset is particularly relevant to EIDR assets:\nEIDR metadata is available in standard DOI kernel metadata format as well as EIDR-specific formats. The DOI for the DOI metadata schema is doi:10.1000/276 .\n\nDOI is in turn implemented on top of the Handle System, a distributed, highly scalable, name resolution service. A handle is defined as:\n\nThe Naming Authority is globally unique and defines both an administrative space and the syntax of the Handle Local Name. For EIDR in the definition above, the “10.5240” is the EIDR Naming Authority, and is responsible for resolving the suffix (including that it conforms to the expected syntax for an EIDR asset). The range of allowable Naming Authorities is more general than is employed by DOI (or EIDR).\n\nThe distributed nature of the Handle System allows each local namespace to be hosted on multiple geographically distributed service sites. This is a federated model where each local name space has complete control over the placement and operation of its service sites. Furthermore, each service site may contain multiple resolution servers: requests directed to a particular service site will be dispatched evenly across its constituent servers.\n\nThe data model of the Handle System is simple but flexible. An arbitrary number of values may be associated with each handle. Over time, these values may be created, modified, and destroyed. Each such datum has the following attributes:\n\nAccessing the Handle System is done via a wire protocol defined in RFC 3652; EIDR applications don’t have to be concerned with this because of the layering of protocols.\n\n\n\n"}
{"id": "28270727", "url": "https://en.wikipedia.org/wiki?curid=28270727", "title": "EMML (Motorola)", "text": "EMML (Motorola)\n\nEMML (Enterprise Mobility Mark-up Language) is an extension of the HTML language. It is less of a strict set of functions and tags, but more a standard for providing developers of web-based mobility applications a means to configure, control and retrieve information from additional input devices and features of rugged mobile computers.\n\nEMML was first devised by James Morley-Smith in 2001, when working as a Software Developer at Symbol Technologies (now a wholly owned subsidiary of Motorola, Inc). As part of the first version of Symbol’s PocketBrowser, EMML was originally a mechanism for providing access to the barcode scanner built into many of Symbol's enterprise mobility devices. It was extended to include features such as WLAN signal indicators, power statistics and access to the communications port to allow for input from custom devices such as magnetic card readers and temperature probes.\n\nEMML 1.0 support is currently offered by commercial browsers and development tools from companies such as Naurtech, Intermec, Wavelink, and Georgia Softworks \n\nIn 2009 Motorola created an updated version of EMML in order to co-ordinate it with other Internet standards, most notably CSS. There was a clear focus on simplifying the standard and reducing the amount of redundant code. In doing so, the number of bytes required to be downloaded was reduced and the readability of the language was vastly improved.\n\nPreviously, all parameters had to be supplied to each META function individually. This meant that each module might have several META tags, each taking up several bytes worth of data. In EMML 1.1, parameters can be supplied in a semi-colon delimited list, much like styles in a CSS style block in HTML.\n\nEMML utilizes the META tag from the HTML language to set properties and specify callback functions by which the browser returns information. According to the W3C the META Tag is: \"an extensible container for use in identifying specialized document meta-information\".\n\nIn EMML, the codice_1 parameter is primarily used to identify the module of functionality. The codice_2 parameter is used to set properties, methods, and associated events.\n\nThere are three main actions in the EMML language:\n\nIn EMML, setting properties is a case of providing the module and property to set, followed by the value.\n\nExample 1. The following is an example of setting the x-position in pixels of the on screen battery indicator in EMML 1.0:\n<meta http-equiv=\"battery\" content=\"x=100\" /> \nExample 2. This is an example of several parameters being applied to the battery module using EMML 1.0:\n<meta http-equiv=\"battery\" content=\"x=10\" />\n<meta http-equiv=\"battery\" content=\"y=10\" />\n<meta http-equiv=\"battery\" content=\"rgb:ff,00,00\" />\nThe example shown in Example 2. in In EMML 1.0 can be written this way in EMML 1.1:\n<meta http-equiv=\"battery\" content=\"left:10; top:10; color:#ff0000;\" /> \nIt is immediately apparent in the example from EMML 1.1 that there is less redundant information. It may also be observed that the codice_3 and codice_4 parameters from EMML 1.0 have been substituted for the codice_5 and codice_6 parameters familiar to CSS. This is also true for the codice_7 and codice_8 EMML 1.0 parameters that have become codice_9 and codice_10 in EMML 1.1. The way in which color is described was also changed to the codice_11 format of HTML and CSS.\n\nMethods are written in a way similar to setting a property. Again, the module appears in the codice_1 parameter, and the action in the codice_2 parameter.\n\nThe following would cause the on screen battery indicator to be displayed:\n<meta http-equiv=\"battery\" content=\"show\" />\nThe codice_14 method from EMML 1.0 was dropped in favor of the codice_15 parameter with the codice_16 value, similarly codice_17 is now the codice_18 value of the codice_15 parameter.\n<meta http-equiv=\"battery\" content=\"left:10; top:10; color:#ff0000; visibility:visible;\" />\nRetrieving information is carried out by specifying a callback function to which the EMML browser returns information. Typically, META functions which return information were named as the module name followed by the word \"navigate\". The callback function could be a URL, where the data is passed as named-value pairs in the query string, or a JavaScript function or variable.\n\nThe following is how you would set all of these for the codice_20 function in EMML 1.0\n\n\"Note: all of these methods would not be included in one document, they are included here as an example.\"\n<!-- A call-back to a URL -->\n<meta http-equiv=\"batterynavigate\" content=\"http://myserver/mypage.html?ACLineStatus=%s&BatteryLifePercent=%s&BackupBatteryLifePercent=%s\" />\n<!-- A call-back to a JavaScript function -->\n<meta http-equiv=\"batterynavigate\" content=\"Javascript:doBattery('%s', '%s', '%s');\" />\n<!-- A call-back to a JavaScript variable -->\n<meta http-equiv=\"batterynavigate\" content=\"Javascript:var bACLine = '%s'; var iBattPC = '%s'; var iBkUpPC ='%s';\" />\nIn EMML 1.0, you specify a place holder for each value you are interested in using a codice_21. This has the drawback of requiring the developer to supply a placeholder for inconsequential values. For example, placeholders would be required for 8 values, even if only the 1st and 8th values were of interest.\n\nIn EMML 1.1 events have a parameter value for each event and each module can therefore support more than one event.\n<meta http-equiv=\"battery\" content=\"batteryevent:url('http://myserver/mypage.html?ACLineStatus=%s&BatteryLifePercent=%s&BackupBatteryLifePercent=%s');\" />\nOr\n<meta http-equiv=\"battery\" content=\"batteryevent:url('Javascript:doBatt('%s', '%s');');\" />\nIn EMML 1.1, the codice_22 can be substituted for a numerical value representing the position of the value of interest. Therefore, if requesting the 1st and 8th values from the codice_23 of the codice_24 module, the tag might be written as follows:\n<meta http-equiv=\"signal\" content=\"signalevent:url('Javascript:doWLAN('%1', '%8');');\" />\nAlso added in EMML 1.1 were EMML Profiles. EMML Profiles are similar to CSS style sheets. An EMML Profile allows for the creation of EMML classes—a common set of EMML META tags which can be applied to a page or element.\n\nBelow is an example of an EMML Profile Page:\n.inventoryBarcodes {\n\n.inventoryBattery {\n\nEMML Profiles are stored in codice_25 files; these can be linked to the HTML document using the codice_26 method of the codice_27 module. This is an example of how an EMMP file would be linked:\n<META HTTP-Equiv=\"emmlprofile\" Content=\"source:url('http://myserver/inventoryprofiles.emmp'); import;\">\n\"Note: Each META tag is parsed from left to right applying each component part in turn. Therefore, in the above example, the \"codice_28 \"parameter will be set before the \"codice_26\" method is called. The same is true for EMML Profiles which are applied from top downwards.\"\n\nWhen a profile page is linked, the class name can simply be referenced, and with that, all the parameters in the profile can be applied with one command.\n<meta http-equiv=\"emmlprofile\" content=\"apply:inventoryBarcode; apply:inventoryBattery\" />\nAs can be seen from the example above, it is possible to set any number of profiles. When doing this, however, one should be aware of conflicting parameters.\n\nRhodes Framework\n\n"}
{"id": "38281216", "url": "https://en.wikipedia.org/wiki?curid=38281216", "title": "EM Microelectronic-Marin", "text": "EM Microelectronic-Marin\n\nEM Microelectronic-Marin SA, based in Marin near Neuchâtel in Switzerland, is a developer and semiconductor manufacturer specialized in the design and production of ultra low power, low voltage integrated circuits for battery-operated and field-powered applications in consumer, automotive and industrial areas. EM Microelectronic-Marin SA is a subsidiary of The Swatch Group.\n\nEM Microelectronic-Marin (also known as EM Micro, EM-Marin or simply EM) was founded in 1975 as a division of the Swiss Ebauches Electronics SA (a member of the ASUAG group of companies). Subsequently ASUAG became part of SMH Swiss Corporation for Microelectronics and Watchmaking Industries Ltd. In 1998 SMH became known as The Swatch Group.\n\nEM Microelectronic has a design center at its headquarters in Marin, in the French speaking part of Switzerland near the city and lake of Neuchâtel. In order to support its activities worldwide, EM has subsidiaries and additional design centers: \n\nEM Micro specialises in the design and production of ultra low power, low voltage integrated circuits for battery-operated and field-powered applications in consumer, automotive and industrial products. EM Micro has in-house semiconductor fabrication facilities and also uses external foundries.\n\nEM Micro's product portfolio encompasses RFID circuits, smart cards ICs, ultra-low power microcontrollers, power management, LCD drivers and displays, sensor and opto-electronic ICs, mixed-mode arrays and standard analog ICs. EM manufacture not only standard circuits and ASICs, but also system solutions and modules for applications such as access control, radio frequency identification, mobile phones, mass-market consumer appliances, alarm and security systems, utility and heating meters, sensor signal processing, controlling, car immobilization, electronic automotive subsystems and many more.\n\nEM Microelectronic design and develop Bluetooth Low Energy products such as the EM9301. EM is an associate member of the Bluetooth® SIG and is contributing through several working group to improve global specification and expertise in ultra-low power design for Bluetooth low energy wireless technology.\nEM Micro has also a proprietary link family of products with 1Mbits, 2Mbit/s and Long range solutions.\n\nThe popularity of EM Micro's range of ~125 kHz RFID devices has led to product from other manufacturers being advertised as \"EM4100 compatible\" although this may simply mean that the active device embedded in the RFID tag/card is an EM Micro product.\n\n\n"}
{"id": "652109", "url": "https://en.wikipedia.org/wiki?curid=652109", "title": "Edge case", "text": "Edge case\n\nAn edge case is a problem or situation that occurs only at an extreme (maximum or minimum) operating parameter. For example, a stereo speaker might noticeably distort audio when played at maximum volume, even in the absence of any other extreme setting or condition.\n\nAn edge case can be expected or unexpected. In engineering, the process of planning for and gracefully addressing edge cases can be a significant task, and yet this task may be overlooked or underestimated.\n\nNon-trivial edge cases can result in the failure of an object that is being engineered. They may not have been foreseen during the design phase. And they may not have been thought possible during normal use of the object. For this reason, attempts to formalize good engineering standards often include information about edge cases.\n\nIn programming, an edge case typically involves input values that require special handling in an algorithm behind a computer program. As a measure for validating the behavior of computer programs in such cases, unit tests are usually created; they are testing boundary conditions of an algorithm, function or method. A series of edge cases around each \"boundary\" can be used to give reasonable coverage and confidence using the assumption that if it behaves correctly at the edges, it should behave everywhere else.\n\nFor example, a function that divides two numbers might be tested using both very large and very small numbers. This assumes that if it works for both ends of the magnitude spectrum, it should work correctly in between.\n\n"}
{"id": "25280299", "url": "https://en.wikipedia.org/wiki?curid=25280299", "title": "European Association for Structural Dynamics", "text": "European Association for Structural Dynamics\n\nThe European Association for Structural Dynamics (\"EASD\") is a professional body founded in 1990 to bring together members of structural dynamics community from all over Europe.\n\nEASD oversees the organization of the European Conferences on Structural Dynamics (EURODYN) that will be held at three (or four) year intervals. These conferences shall be devoted to theoretical developments and applications of structural dynamics to all types of structures and structural materials.\n\n"}
{"id": "506682", "url": "https://en.wikipedia.org/wiki?curid=506682", "title": "Fluid power", "text": "Fluid power\n\nFluid power is the use of fluids under pressure to generate, control, and transmit power. Fluid power is subdivided into hydraulics using a liquid such as mineral oil or water, and pneumatics using a gas such as air or other gases. Compressed-air and water-pressure systems were once used to transmit power from a central source to industrial users over extended geographic areas; fluid power systems today are usually within a single building or mobile machine. \n\nFluid power systems perform work by a pressurized fluid bearing directly on a piston in a cylinder or in a fluid motor. A fluid cylinder produces a force resulting in linear motion, whereas a fluid motor produces torque resulting in rotary motion. Within a fluid power system, cylinders and motors (also called actuators) do the desired work. Control components such as valves regulate the system. \n\nA fluid power system has a pump driven by a prime mover (such as an electric motor or internal combustion engine) that converts mechanical energy into fluid energy, Pressurized fluid is controlled and directed by valves into an actuator device such as a hydraulic cylinder or pneumatic cylinder, to provide linear motion, or a hydraulic motor or pneumatic motor, to provide rotary motion or torque. Rotary motion may be continuous or confined to less than one revolution.\n\nDynamic (non positive displacement) Pumps\n\nThis type is generally used for low-pressure, high volume flow applications. Since they are not capable of withstanding high pressures, there is little use in the fluid power field. Their maximum pressure is limited to 250-300 psi. This type of pump is primarily used for transporting fluids from one location to another. Centrifugal and axial flow propeller pumps are the two most common types of dynamic pumps.\n\nPositive Displacement Pumps\nThis type is universally used for fluid power systems. With this pump, a fixed amount of fluid is ejected into the hydraulic system per revolution of pump shaft rotation. These pumps are capable of overcoming the pressure resulting from the mechanical loads on the system as well as the resistance to flow due to friction. These two features are highly desirable in fluid power pumps. These pumps also have the following advantages over non positive displacement pumps:\n\nFluid power systems can produce high power and high forces in small volumes, compared with electrically-driven systems. The forces that are exerted can be easily monitored within a system by gauges and meters. In comparison to systems that provide force through electricity or fuel, fluid power systems are known to have long service lives if maintained properly. The working fluid passing through a fluid motor inherently provides cooling of the motor, which must be separately arranged for an electric motor. Fluid motors normally produce no sparks, which are a source of ignition or explosions in hazardous areas containing flammable gases or vapors. \n\nFluid power systems are susceptible to pressure and flow losses within pipes and control devices. Fluid power systems are equipped with filters and other measures to preserve the cleanliness of the working fluid. Any dirt in the system can cause wear of seals and leakage, or can obstruct control valves and cause erratic operation. The hydraulic fluid itself is sensitive to temperature and pressure along with being somewhat compressible. These can cause systems to not run properly. If not run properly, cavitation and aeration can occur.\n\nMobile applications of fluid power are widespread. Nearly every self-propelled wheeled vehicle has either hydraulically-operated or pneumatically-operated brakes. Earthmoving equipment such as bulldozers, backhoes and others use powerful hydraulic systems for digging and also for propulsion. A very compact fluid power system is the automatic transmission found in many vehicles, which includes a hydraulic torque converter. \n\nFluid power is also used in automated systems, where tools or work pieces are moved or held using fluid power. Variable-flow control valves and position sensors may be included in a servomechanism system for precision machine tools. Below is a more detailed list of applications and categories that fluid power is used for:\n\n\n\nThis circuit works off of synchronization. As a cylinder reaches a certain point another will be activated, either by a hydraulic limit switch valve or by the build-up of pressure in the cylinder. These circuits are used in manufacturing. An example of this would be on an assembly line. As a hydraulic arm is activated to grab an object. It then will reach a point of extension or retraction, where the other cylinder is activated to screw a cap or top onto the object. Hence the term Synchronizing.\n\nIn a regenerative circuit, a double acting cylinder is used. This cylinder has a pump that has a fixed output. The use of a regenerative circuit permits use of a smaller size pump for any given application. This works by re-routing the fluid to the cap instead of back to the tank . For example, in a drilling process a regenerative circuit will allow drilling at a consistent speed, and retraction at a much faster speed. This gives the operator a faster and more precise production. \n\nCombinations of electrical control of fluid power elements are widespread in automated systems. A wide variety of measuring, sensing, or control elements are available in electrical form. These can be used to operate solenoid valves or servo valves that control the fluid power element. Electrical control may be used to allow, for example, remote control of a fluid power system without running long control lines to a remotely located manual control valve. \n\n\n"}
{"id": "850048", "url": "https://en.wikipedia.org/wiki?curid=850048", "title": "Gas lighting", "text": "Gas lighting\n\nGas lighting is production of artificial light from combustion of a gaseous fuel, such as hydrogen, methane, carbon monoxide, propane, butane, acetylene, ethylene, or natural gas.\n\nThe light is produced either directly by the flame, generally by using special mixes of illuminating gas to increase brightness, or indirectly with other components such as the gas mantle or the limelight, with the gas primarily functioning as a fuel source.\n\nBefore electricity became sufficiently widespread and economical to allow for general public use, gas was the most popular method of outdoor and indoor lighting in cities and suburbs. Early gas lights were ignited manually, but many later designs are self-igniting.\n\nGas lighting today is generally used for camping, where the high energy density of a hydrocarbon fuel, combined with the modular nature of canisters (a strong metal container) allows bright and long lasting light to be produced cheaply and without complex equipment. In addition, some urban historical districts retain gas street lighting, and gas lighting is used indoors or outdoors to create or preserve a nostalgic effect.\n\nEarly lighting fuels consisted of olive oil, beeswax, fish oil, whale oil, sesame oil, nut oil, and similar substances. These were the most commonly used fuels until the late 18th century. Chinese records dating back 1,700 years note the use of natural gas in the home for light and heat via bamboo pipes to the dwellings. The ancient Chinese of the Spring and Autumn period made the first practical use of natural gas for lighting purposes around 500 B.C. where they used bamboo pipelines to transport and carry both brine and natural gas for many miles.\n\nPublic illumination preceded the discovery and adoption of gaslight by centuries. In 1417, Sir Henry Barton, Lord Mayor of London, ordained \"lanterns with lights to be hung out on the winter evenings between Hallowtide and Candlemasse.\" Paris was first lit by an order issued in 1524, and, in the beginning of the 16th century, the inhabitants were ordered to keep lights burning in the windows of all houses that faced the streets. In 1668, when some regulations were made for improving the streets of London, the residents were reminded to hang out their lanterns at the usual time, and, in 1690, an order was issued to hang out a light, or lamp, every night as soon as it was dark, from Michaelmas to Christmas. By an Act of the Common Council in 1716, all housekeepers, whose houses faced any street, lane, or passage, were required to hang out, every dark night, one or more lights, to burn from six to eleven o'clock, under the penalty of one shilling as a fine for failing to do so.\n\nIn coal mining, accumulating and escaping gases were known originally for their adverse effects rather than their useful qualities. Coal miners described two types of gases, one called the \"choke damp\" and the other \"fire damp\". In 1667, a paper detailing the effects of these gases was entitled, \"A Description of a Well and Earth in Lancashire taking Fire, by a Candle approaching to it. Imparted by Thomas Shirley, Esq an eye-witness.\"\n\nStephen Hales was the first person who procured a flammable fluid from the actual distillation of coal. His experiments with this object are related in the first volume of his \"Vegetable Statics\", published in 1726. From the distillation of \"one hundred and fifty-eight grains [10.2 g] of Newcastle coal, he states that he obtained one hundred and eighty cubic inches [2.9 L] of air, which weighed fifty-one grains [3.3 g], being nearly one third of the whole.\" These results seemed to have passed without notice for several years.\n\nIn the \"Philosophical Transactions of the Royal Society\" in 1733, some properties of coal-gas are detailed in a paper called, \"An Account of the Damp Air in a Coal-pit of Sir James Lowther, sunk within Twenty Yards of the Sea.\" This paper contained some striking facts relating to the flammability and other properties of coal-gas.\n\nThe principal properties of coal-gas were demonstrated to different members of the Royal Society, and showed that after keeping the gas some time, it still retained its flammability. The scientists of the time still saw no useful purpose for it.\n\nJohn Clayton, in an extract from a letter in the \"Philosophical Transactions\" for 1735, calls gas the \"spirit\" of coal and discovered its flammability by an accident. This \"spirit\" happened to catch fire, by coming in contact with a candle as it escaped from a fracture in one of his distillatory vessels. By preserving the gas in bladders, he entertained his friends, by exhibiting its flammability.\n\nWilliam Murdoch (sometimes spelled \"Murdock\") was the first to exploit the flammability of gas for the practical application of lighting. He worked for Matthew Boulton and James Watt at their Soho Foundry steam engine works in Birmingham, England. In the early 1790s, while overseeing the use of his company's steam engines in tin mining in Cornwall, Murdoch began experimenting with various types of gas, finally settling on coal-gas as the most effective. He first lit his own house in Redruth, Cornwall in 1792. In 1798, he used gas to light the main building of the Soho Foundry and in 1802 lit the outside in a public display of gas lighting, the lights astonishing the local population. One of the employees at the Soho Foundry, Samuel Clegg, saw the potential of this new form of lighting. Clegg left his job to set up his own gas lighting business, the Gas Lighting and Coke Company.\n\nA \"thermolampe\" using gas distilled from wood was patented in 1799, whilst German inventor Friedrich Winzer (Frederick Albert Winsor) was the first person to patent coal-gas lighting in 1804.\n\nIn 1801, Phillipe Lebon of Paris had also used gas lights to illuminate his house and gardens, and was considering how to light all of Paris. In 1820, Paris adopted gas street lighting.\n\nIn 1804, Dr. Henry delivered a course of lectures on chemistry, at Manchester, in which he showed the mode of producing gas from coal, and the facility and advantage of its use. Dr. Henry analyzed the composition and investigated the properties of carburetted hydrogen gas. His experiments were numerous and accurate and made upon a variety of substances; having obtained the gas from wood, peat, different kinds of coal, oil, wax, &c. he quantified the intensity of the light from each source.\n\nJosiah Pemberton, an inventor, had for some time been experimenting on the nature of gas. A resident of Birmingham, his attention may have been roused by the exhibition at Soho. About 1806, he exhibited gas-lights in a variety of forms and with great brilliance at the front of his manufactory in Birmingham. In 1808 he constructed an apparatus, applicable to several uses, for Benjamin Cooke, a manufacturer of brass tubes, gilt toys, and other articles.\n\nIn 1808, Murdoch presented to the Royal Society a paper entitled \"Account of the Application of Gas from Coal to Economical Purposes\" wherein he described his successful application of coal-gas to lighting the extensive establishment of Messrs. Phillips and Lea. For this paper he was awarded Count Rumford's gold medal. Murdoch's statements threw great light on the comparative advantage of gas and candles and contained much useful information on the expenses of production and management.\n\nAlthough the history is uncertain, David Melville has been credited with the first house and street lighting in the United States, in either 1805 or 1806 in Newport, Rhode Island. The first well-recorded public street lighting with gas was demonstrated in Pall Mall, London, on January 28, 1807, by Frederick Albert Winsor. In 1812, Parliament granted a charter to the London and Westminster Gas Light and Coke Company, and the first gas company in the world came into being. Less than two years later, on December 31, 1813, the Westminster Bridge was lit by gas.\n\nAs artificial lighting became more common, desire grew for it to become readily available to the public. This was in part because towns became much safer places to travel around after gas lamps were installed in the streets, reducing crime rates. In 1809, accordingly, the first application was made to Parliament to incorporate a company in order to accelerate the process, but failed to pass. In 1810, however, the application was renewed by the same parties, and though some opposition was encountered and considerable expense incurred, the bill passed, but not without great alterations; and the London and Westminster Chartered Gas-Light and Coke Company was established. By 1816, Samuel Clegg obtained the patent for his horizontal rotative retort, his apparatus for purifying coal-gas with cream of lime, and for his rotative gas meter and self-acting governor.\n\nAmong the economic impacts of gas lighting was much longer work hours in factories. This was particularly important in Great Britain during the winter months when nights are significantly longer. Factories could even work continuously over 24 hours, resulting in increased production. Following successful commercialization, gas lighting spread to other countries.\n\nIn England, the first place outside London to have gas lighting was Preston, Lancashire, in 1816; this was due to the Preston Gaslight Company run by revolutionary Joseph Dunn, who found the most improved way of brighter gas lighting. The parish church there was the first religious building to be lit by gas lighting. \n\nIn America, Seth Bemis lit his factory with gas illumination from 1812 to 1813. The use of gas lights in Rembrandt Peale's Museum in Baltimore in 1816 was a great success. Baltimore was the first American city with gas streetlights; Peale's Gas Light Company of Baltimore on February 7, 1817 lit its first street lamp at Market and Lemon Streets (currently Baltimore and Holliday Streets). The first private residence in the US illuminated by gas has been variously identified as that of David Melville (c. 1806), as described above, or of William Henry, a coppersmith, at 200 Lombard Street, Philadelphia, Pennsylvania, in 1816.\n\nThe history of the Russian gas industry began with retired Lieutenant Pyotr Sobolevsky (1782–1841), who improved Philippe le Bon's design for a \"thermolamp\" and presented it to Emperor Alexander I in 1811; in January 1812, Sobolevsky was instructed to draw up a plan for gas street-lighting for St. Petersburg. The French invasion of Russia delayed implementation, but St. Petersburg's Governor General Mikhail Miloradovich, who had seen the gas lighting of Vienna, Paris and other European cities, initiated experimental work on gas lighting for the capital, using British apparatus for obtaining gas from pit coal, and by the autumn of 1819, Russia's first gas street light was lit on one of the streets on Aptekarsky Island.\n\nIn February 1835, the Company for Gas Lighting St. Petersburg was founded; towards the end of that year, a factory for the production of lighting gas was constructed near the Obvodny Canal, using pit coal brought in by ship from Cardiff; and, on September 27, 1839, 204 gas lamps were ceremonially lit in St. Petersburg.\nOver the next 10 years, their numbers almost quadrupled, to reach 800. By the middle of the 19th century, the central streets and buildings of the capital were illuminated: the Palace Square, Bolshaya and Malaya Morskaya streets, Nevsky and Tsarskoselsky Avenues, Passage Arcade, Noblemen's Assembly, the Technical Institute and Peter and Paul Fortress.\n\nIn 1817, at the three stations of the Chartered Gas Company, 25 chaldrons (24 m³) of coal were carbonized daily, producing 300,000 cubic feet (8,500 m³) of gas. This supplied gas lamps equal to 75,000 Argand lamps each yielding the light of six candles. At the City Gas Works, in Dorset Street, Blackfriars, three chaldrons of coal were carbonized each day, providing the gas equivalent of 9,000 Argand lamps. So 28 chaldrons of coal were carbonized daily, and 84,000 lights supplied by those two companies only.\n\nAt this period the principal difficulty in gas manufacture was purification. Mr. D. Wilson, of Dublin, patented a method for purifying coal-gas by means of the chemical action of ammoniacal gas. Another plan was devised by Mr. Reuben Phillips, of Exeter, who patented the purification of coal-gas by the use of dry lime. Mr. G. Holworthy, in 1818, patented a method of purifying it by causing the gas, in a highly condensed state, to pass through iron retorts heated to a dark red.\n\nBy 1823, numerous towns and cities throughout Britain were lit by gas. Gaslight cost up to 75% less than oil lamps or candles, which helped to accelerate its development and deployment. By 1859, gas lighting was to be found all over Britain and about a thousand gas works had sprung up to meet the demand for the new fuel. The brighter lighting which gas provided allowed people to read more easily and for longer. This helped to stimulate literacy and learning, speeding up the second Industrial Revolution.\n\nOil-gas appeared in the field as a rival of coal-gas. In 1815, John Taylor patented an apparatus for the decomposition of \"oil\" and other animal substances. Public attention was attracted to \"oil-gas\" by the display of the patent apparatus at Apothecary's Hall, by Taylor & Martineau.\n\nIn 1891 the gas mantle was invented by the Austrian chemist Carl Auer von Welsbach. This eliminated the need for special illuminating gas – a synthetic mixture of hydrogen and hydrocarbon gases produced by destructive distillation of bituminous coal or peat, to get bright shining flames. Acetylene was also used from about 1898 for gas lighting on a smaller scale.\n\nIlluminating gas was used for gas lighting, as it produces a much brighter light than natural gas or water gas. Illuminating gas was much less toxic than other forms of coal-gas, but less could be produced from a given quantity of coal. The experiments with distilling coal were described by John Clayton in 1684. George Dixon's pilot plant exploded in 1760, setting back the production of illuminating gas a few years. The first commercial application was in a Manchester cotton mill in 1806. In 1901, studies of the defoliant effect of leaking gas pipes led to the discovery that ethylene is a plant hormone.\n\nThroughout the 19th century and into the first decades of the 20th, the gas was manufactured by the gasification of coal. In the latter years of the nineteenth century, natural gas began to replace coal-gas, first in the US, and then in other parts of the world. In the United Kingdom, coal-gas was used until the early 1970s.\n\nIt took many years of development and testing before gas lighting for the stage would be commercially available for use in theatres. Gas technology would then be installed in just about every major theatre in the world. However, lighting with means of gas would be short lived because the invention of the electric light bulb would be soon to follow.\n\nIt would take close to two hundred years for gas to become accessible for commercial use. A Flemish alchemist, Jan Baptista van Helmont, was the first person to formally recognize gas as a state of matter. He would go on to identify several types of gases, including carbon dioxide. Over one hundred years later in 1733, Sir James Lowther had some of his miners working on a water pit for his mine. While digging the pit they hit a pocket of gas. Lowther took a sample of the gas and took it home to do some experiments. He noted, \"The said air being put into a bladder … and tied close, may be carried away, and kept some days, and being afterwards pressed gently through a small pipe into the flame of a candle, will take fire, and burn at the end of the pipe as long as the bladder is gently pressed to feed the flame, and when taken from the candle after it is so lighted, it will continue burning till there is no more air left in the bladder to supply the flame.\" Lowther had basically discovered the principle behind gas lighting.\n\nLater in the eighteenth Century William Murdoch would state: \"the gas obtained by distillation from coal, peat, wood and other inflammable substances burnt with great brilliancy upon being set fire to … by conducting it through tubes, it might be employed as an economical substitute for lamps and candles.\" Murdoch’s first invention was a lantern with a gas-filled bladder attached to a jet. He would use this to walk home at night. After seeing how well this worked he decided to light his home with gas. In 1797, Murdoch would install gas lighting into his new home as well as the workshop in which he worked. “This work was of a large scale, and he next experimented to find better ways of producing, purifying, and burning the gas.” The foundation had been laid for companies to start producing gas and other inventors to start playing with ways of using the new technology. This new technology would quickly find its way to the stage.\n\nIn the 19th century, gas stage lighting would go from a crude experiment to the most popular way of lighting theatrical stages. In 1804, Frederick Albert Winsor, a German, first demonstrated the way to use gas to light the stage in London at the Lyceum Theatre. Although the demonstration and all the lead research were being done in London, “in 1816 at the Chestnut Street Theatre in Philadelphia was the earliest gas lit theatre in world”. In 1817 the Lyceum, Drury Lane, and Covent Garden theatres were all lit by gas. Gas would be brought into the building by \"Miles of rubber tubing from outlets in the floor called 'water joints' carried the gas to border-lights and wing lights\". But before it was distributed, the gas came through a central distribution point called a “gas table”.\nThe gas table was how the brightness could be \"varied by regulating the gas supply, and the gas table, which allowed control of separate parts of the stage, became the first stage 'switchboard'\".\n\nBy the 1850s, gas lighting in theatres had spread practically all over the United States and Europe. Some of the largest installations of gas lighting would be in large auditoriums, like the Theatre de Chatelet, built in 1862. In 1875, the new Paris Opera was constructed. “Its lighting system contained more than twenty-eight miles [] of gas piping, and its gas table had no fewer than eighty-eight stopcocks, which controlled nine hundred and sixty gas jets.” The theatre that used the most gas lighting was the Astley’s Equestrian Amphitheatre in London. According to the Illustrated London News “Everywhere white and gold meets the eye, and about 200,000 gas jets add to the glittering effect of the auditorium … such a blaze of light and splendour has scarcely ever been witnessed, even in dreams.”\n\nTheatres were switching over to gas lighting not just because it was more economical than using candles but also required less labor to operate. With gas lighting, theatres would no longer need to have people tending to candles during a performance, or having to light each candle individually. “It was easier to light a row of gas jets than a greater quantity of candles high in the air.” Theatres also no longer needed to worry about wax dripping on the actors during a show.\n\nGas lighting also had an effect on the actors. The actors now could use less make-up and their motions did not have to be as exaggerated. The reasoning for this was because the stage was now brighter than it had ever been before. What had once been on half-lit stages was now on in fully lit stages. Production companies were so impressed with the new technology that some would go as far to say, “This light is perfect for the stage. One can obtain gradation of brightness that is really magical.”\n\nThe best thing that happened due to this change was the respect from the audience. There was no more shouting or riots. The light pushed the actors more up stage behind the proscenium helping the audience concentrate more on the action that was taking place on stage rather than what was going on in the house. Management had more authority on what went on during the show because they could see. Gaslight was the leading cause of behavior change in theaters. It was no longer a place for mingling and orange selling; it was now a place of respected entertainment.\n\nThere were six types of burners but four burners were really experimented with. The first burner used with this system was the single-jet burner that produced a small flame. The tip of the burner was made out of lead which absorbed heat causing the flame to be smaller in size. It was discovered that the flame would burn brighter if straight metal was mixed with other components, such as porcelain. Flat burners were invented mainly to evenly distribute gas and light to the systems. The fishtail burner is a relative to the flat burner but it managed to create a brighter flame and conducted less heat. The last burner that was experimented with was the Welsbach burner. Around this time the Bunsen burner was in use along with some forms of electricity. The Welsbach was based on the idea of the Bunsen burner, still using gas, a cotton mesh with cerium and thorium was imbedded into the Welsbach. This source of light was named the “gas mantle” which created three times more light than the naked flame.\n\nInstruments that were used to light the stage during the nineteenth century fell under different classifications. Footlights, border lights, groundrows, lengths, bunch lights, conical reflector floods, and limelight spots were mainly used during this period. These mechanisms sat directly on the stage blinding the eyesight of the audience. Footlights caused the actors’ costumes to catch fire if they got too close to the lights. These lights also caused bothersome heat that affected both audience members and actors. Again, the actors had to adapt to these changes. They started fireproofing their costumes and placing wire mesh in front of the footlights.\n\nBorder lights, also known as striplights, were a row of lights that hung horizontally in the flies. Color was added later by dying cotton, wool, and silk cloth. Lengths were constructed the same way as the border light, only these lights were mounted vertically in the rear where the wings were. Bunch lights are a cluster of burners that sat on a vertical base that was fueled directly from the gas line. The conical reflector can be related to Fresnels that are currently used today. This adjustable box of light reflected a beam in which the size could be altered by a barndoor. Limelight spots are similar to today’s current spotlighting system. This instrument was used in scene shops, as well as the stage.\n\nGas lighting did have some disadvantages. \"Several hundred theatres are said to have burned down in America and Europe between 1800 and the introduction of electricity in the late 1800s. The increased heat was objectionable, and the border lights and wing lights had to be lighted by a long stick with a flaming wad of cotton at the end. For many years, an attendant or gas boy moved along the long row of jets, lighting them individually while gas was escaping from the whole row. Both actors and audiences complained of the escaping gas, and explosions sometimes resulted from its accumulation.\"\n\nThese problems with gas lighting led to the rapid adoption of electric lighting. By 1881, the Savoy Theatre in London was using incandescent lighting. As electric lighting was being introduced to theatre stages, people who still were using gas theatre lighting developed the gas mantle in 1885. “This was a beehive-shaped mesh of knitted thread impregnated with lime that, in miniature, converted the naked gas flame into in effect, a lime-light.” Electric lighting would slowly take over theatre lighting. In the twentieth century, electric lighting would lead to even better and safer theater productions. These productions would be comfortable to watch with no smell, relatively very little heat, and more freedom for designers.\n\nIn the early 20th century, most cities in North America and Europe had gaslit streets. However, around 1880 gas lighting for streets began giving way to high voltage (3000–6000 volt) direct current and alternating current arc lighting systems. This time period also saw the development of the first electric power utility designed for indoor use. The new system by inventor Thomas Edison was designed to function similar to gas lighting. For reasons of safety and simplicity it used direct current (DC) at a relatively low 110 volts to light incandescent light bulbs. Voltage in wires steadily declines as distance increases, and at this low voltage power plants needed to be within about of the lamps. This voltage drop problem made DC distribution relatively expensive and gas lighting retained widespread usage with new buildings sometimes constructed with dual systems of gas piping and electrical wiring connected to each room, to diversify the power sources for lighting.\n\nThe development of new alternating current power transmission systems in the 1880s and 90s by companies such as Ganz and AEG in Europe and Westinghouse Electric and Thomson-Houston in the US solved the voltage and distance problem by using high transmission line voltages, and transformers to drop the voltage for distribution for indoor lighting. Alternating current technology overcame many of the limitations of direct current, enabling the rapid growth of reliable, low-cost electrical power networks which finally spelled the end of widespread usage of gas lighting.\n\nIn the 20th century, most cities with gas streetlights replaced them with new electric streetlights. For example, Baltimore, the first US city to install gas streetlights, removed nearly all of them. A sole, token gas lamp is located at N. Holliday Street and E. Baltimore Street as a monument to the first gas lamp in America, erected at that location.\n\nHowever, gas lighting of streets has not disappeared completely from some cities, and the few municipalities that retained gas lighting now find that it provides a pleasing nostalgic effect. Gas lighting is also seeing a resurgence in the luxury home market for those in search of historical authenticity.\n\nThe largest gas lighting network in the world is that of Berlin. With about 37,000 lamps (2014), it holds more than half of all working gas street lamps in the world. In central London around 1500 gas lamps still operate, lighting the Royal Parks, the exterior of Buckingham Palace and almost the entire Covent Garden area. The Park Estate in Nottingham retains much of its original character, including the original gas lighting network.\n\nIn the United States, more than 2800 gas lights in Boston operate in the historic districts of Beacon Hill, Back Bay, Bay Village, Charlestown, and parts of other neighborhoods. In Cincinnati, Ohio, more than 1100 gas lights operate in areas that have been named historic districts. Gas lights also operate in parts of the famed French Quarter and outside historic homes throughout the city in New Orleans.\n\nSouth Orange, New Jersey, has adopted the gaslight as the symbol of the town, and uses them on nearly all streets. Several other towns in New Jersey also retain gas lighting: Glen Ridge, Palmyra, Riverton, and some parts of Orange, Cape May and Cherry Hill. The village of Riverside, Illinois, still uses its original gas street lights that are an original feature of the Frederick Law Olmsted planned community. Manhattan Beach, California, has a gas lamp section in which all the sidewalks are lit by public gas lamps. Disneyland has authentic 19th century gas lamps from Baltimore along the \"Main Street, U.S.A.\" section of the theme park.\n\nMany gas utility companies will still quote a fixed periodic rate for a customer-maintained gas lamp, and some homeowners still use such devices. However, the high cost of natural gas lighting at least partly explains why a large number of older gas lamps have been converted to electricity. Solar-rechargeable battery-powered gas light controllers can be easily retrofitted into existing gas lamps to keep the lights off during daylight hours and cut energy consumption and green-house gas carbon emissions by 50%.\n\nThe use of natural gas (methane) for \"indoor\" lighting is nearly extinct. Besides producing a lot of heat, the combustion of methane tends to release significant amounts of carbon monoxide, a colorless and odorless gas which is more readily absorbed by the blood than oxygen, and can be deadly. Historically, the use of lamps of all types was of shorter duration than we are accustomed to with electric lights, and in the far more draughty buildings, it was of less concern and danger. There are no suppliers of new mantle gas lamps set up for use with natural gas; however, some old homes still have fixtures installed, and some period restorations have salvaged fixtures installed, more for decoration than use.\n\nNew fixtures are still made and available for propane (sometimes called \"bottle(d) gas\"), a product of oil refining, which under most circumstances burns more completely to carbon dioxide and water vapor. In some locations where public utility electricity or kerosene are not readily accessible or desirable, propane gas mantle lamps are still used, although the increased availability of alternative energy sources, such as solar panels and small scale wind generators, combined with increasing efficiency of lighting products, such as compact fluorescent lamps and LEDs are also in use. For occasional use in remote cabins and cottages, propane mantle lamps may still be more economical and less labor-intensive than an alternative energy system.\n\nPerforated tubes bent into the shape of letters were used to form gas lit advertising signs, prior to the introduction of neon lights, as early as 1857 in Grand Rapids, Michigan. Gas lighting is still in common use for camping lights. Small portable gas lamps, connected to a portable gas cylinder, are a common item on camping trips. Mantle lamps powered by vaporized petrol, such as the Coleman lantern, are also available.\n\n\n\n\n"}
{"id": "712727", "url": "https://en.wikipedia.org/wiki?curid=712727", "title": "Heliograph", "text": "Heliograph\n\nA heliograph (\"helios\" (), meaning \"sun\", and \"graphein\" (), meaning \"write\") is a wireless telegraph that signals by flashes of sunlight (generally using Morse code) reflected by a mirror. The flashes are produced by momentarily pivoting the mirror, or by interrupting the beam with a shutter. The heliograph was a simple but effective instrument for instantaneous optical communication over long distances during the late 19th and early 20th century. Its main uses were military, survey and forest protection work. Heliographs were standard issue in the British and Australian armies until the 1960s, and were used by the Pakistani army as late as 1975.\n\nThere were many heliograph types. Most heliographs were variants of the British Army Mance Mark V version (Fig.1). It used a mirror with a small unsilvered spot in the centre. The sender aligned the heliograph to the target by looking at the reflected target in the mirror and moving their head until the target was hidden by the unsilvered spot. Keeping their head still, they then adjusted the aiming rod so its cross wires bisected the target. They then turned up the sighting vane, which covered the cross wires with a diagram of a cross, and aligned the mirror with the tangent and elevation screws so the small shadow that was the reflection of the unsilvered spot hole was on the cross target. This indicated that the sunbeam was pointing at the target. \nThe flashes were produced by a keying mechanism that tilted the mirror up a few degrees at the push of a lever at the back of the instrument. If the sun was in front of the sender, its rays were reflected directly from this mirror to the receiving station. If the sun was behind the sender, the sighting rod was replaced by a second mirror, to capture the sunlight from the main mirror and reflect it to the receiving station. The U. S. Signal Corps heliograph mirror did not tilt. This type produced flashes by a shutter mounted on a second tripod (Fig 4).\n\nThe heliograph had some great advantages. It allowed long distance communication without a fixed infrastructure, though it could also be linked to make a fixed network extending for hundreds of miles, as in the fort-to-fort network used for the Geronimo campaign. It was very portable, did not require any power source, and was relatively secure since it was invisible to those not near the axis of operation, and the beam was very narrow, spreading only 50 feet per mile of range. However, anyone in the beam with the correct knowledge could intercept signals without being detected. In the Boer War, where both sides used heliographs, tubes were sometimes used to decrease the dispersion of the beam. In some other circumstances, though, a narrow beam made it difficult to stay aligned with a moving target, as when communicating from shore to a moving ship, so the British issued a dispersing lens to broaden the heliograph beam from its natural diameter of 0.5 degrees to 15 degrees.\n\nThe distance that heliograph signals could be seen depended on the clarity of the sky and the size of the mirrors used. A clear line of sight was required, and since the Earth's surface is curved, the highest convenient points were used. Under ordinary conditions, a flash could be seen 30 miles (48 km) with the naked eye, and much farther with a telescope. The maximum range was considered to be 10 miles for each inch of mirror diameter. Mirrors ranged from 1.5 inches to 12 inches or more. The record distance was established by a detachment of U.S. signal sergeants by the inter-operation of stations on Mount Ellen, Utah, and Mount Uncompahgre, Colorado, 183 miles (295 km) apart on September 17, 1894, with Signal Corps heliographs carrying mirrors only 8 inches square.\n\nThe German professor Carl Friedrich Gauss of the University of Göttingen developed and used a predecessor of the heliograph (the heliotrope) in 1821. His device directed a controlled beam of sunlight to a distant station to be used as a marker for geodetic survey work, and was suggested as a means of telegraphic communications. This is the first reliably documented heliographic device, despite much speculation about possible ancient incidents of sun-flash signalling, and the documented existence of other forms of ancient optical telegraphy.\n\nFor example, one author in 1919 chose to \"hazard the theory\" that the mainland signals Roman emperor Tiberius watched for from Capri were mirror flashes, but admitted \"there are no references in ancient writings to the use of signaling by mirrors\", and that the documented means of ancient long-range visual telecommunications was by beacon fires and beacon smoke, not mirrors.\n\nSimilarly, the story that a shield was used as a heliograph at the Battle of Marathon is a modern myth, originating in the 1800s. Herodotus never mentioned any flash. What Herodotus did write was that someone was accused of having arranged to \"hold up a shield as a signal\". Suspicion grew in the 1900s that the flash theory was implausible.<ref name=\"http://www.jstor.org/stable/625005\"></ref> The conclusion after testing the theory was \"Nobody flashed a shield at the Battle of Marathon\".\n\nIn a letter dated 3 June 1778, John Norris, High Sheriff of Buckinghamshire, England, notes: \"Did this day heliograph intelligence from Dr [Benjamin] Franklin in Paris to Wycombe\". However, there is little evidence that \"heliograph\" here is other than a misspelling of \"holograph\". The term \"heliograph\" for solar telegraphy did not enter the English language until the 1870s—even the word \"telegraphy\" was not coined until the 1790s.\n\nHenry Christopher Mance (1840–1926), of the British Government Persian Gulf Telegraph Department, developed the first widely accepted heliograph about 1869 while stationed at Karachi, in the Bombay Presidency in British India. Mance was familiar with heliotropes by their use for the Great India Survey. The Mance Heliograph was operated easily by one man, and since it weighed about seven pounds, the operator could readily carry the device and its tripod. The British Army tested the heliograph in India at a range of 35 miles with favorable results. During the Jowaki Afridi expedition sent by the British-Indian government in 1877, the heliograph was first tested in war.\nThe simple and effective instrument that Mance invented was to be an important part of military communications for more than 60 years. The usefulness of heliographs was limited to daytimes with strong sunlight, but they were the most powerful type of visual signalling device known. In pre-radio times heliography was often the only means of communication that could span ranges of as much as 100 miles with a lightweight portable instrument.\n\nIn the United States military, by mid-1878, Colonel Nelson A. Miles had established a line of heliographs connecting Fort Keogh and Fort Custer, Montana, a distance of 140 miles. In 1886, General Nelson A. Miles set up a network of 27 heliograph stations in Arizona and New Mexico during the hunt for Geronimo.In 1890, Major W. J. Volkmar of the US Army demonstrated in Arizona and New Mexico the possibility of performing communication by heliograph over a heliograph network aggregating 2,000 miles in length. The network of communication begun by General Miles in 1886, and continued by Lieutenant W. A. Glassford, was perfected in 1889 at ranges of 85, 88, 95, and 125 miles over a rugged and broken country, which was the stronghold of the Apache and other hostile Indian tribes.\n\nBy 1887, heliographs in use included not only the British Mance and Begbie heliographs, but also the American Grugan, Garner and Pursell heliographs. The Grugan and Pursell heliographs used shutters, and the others used movable mirrors operated by a finger key. The Mance, Grugan and Pursell heliographs used two tripods, and the others one. The signals could either be momentary flashes, or momentary obscurations. In 1888, the US Signal Service reviewed all of these devices, as well as the Finley Helio-Telegraph, and finding none completely suitable, developed the US Signal Service heliograph, a two-tripod, shutter-based machine of 13 7/8 lb. total weight, and ordered 100 for a total cost of $4,205. In 1893, the number of heliographs manufactured for the US Signal Service was 133.\n\nThe heyday of the heliograph was probably the Second Boer War in South Africa, where it was much used by both the British and the Boers. The terrain and climate, as well as the nature of the campaign, made heliography a logical choice. For night communications, the British used some large Aldis lamps, brought inland on railroad cars, and equipped with leaf-type shutters for keying a beam of light into dots and dashes. During the early stages of the war, the British garrisons were besieged in Kimberley, Ladysmith, and Mafeking. With land telegraph lines cut, the only contact with the outside world was via light-beam communication, helio by day, and Aldis lamps at night.\n\nIn 1909, the use of heliography for forestry protection was introduced in the United States. By 1920 such use was widespread in the US and beginning in Canada, and the heliograph was regarded as \"next to the telephone, the most useful communication device that is at present available for forest-protection services\". D.P. Godwin of the US Forestry Service invented a very portable (4.5 lb) heliograph of the single-tripod, shutter plus mirror type for forestry use.\n\nImmediately prior to the outbreak of World War I, the cavalry regiments of the Russian Imperial Army were still being trained in heliograph communications to augment the efficiency of their scouting and reporting roles. The Red Army during the Russian Civil War made use of a series of heliograph stations to disseminate intelligence efficiently about basmachi rebel movements in Turkestan in 1926.\n\nDuring World War II, South African and Australian forces used the heliograph against German forces in Libya and Egypt in 1941 and 1942.\n\nThe heliograph remained standard equipment for military signallers in the Australian and British armies until the 1940s, where it was considered a \"low probability of intercept\" type of communication. The Canadian Army was the last major army to have the heliograph as an issue item. By the time the mirror instruments were retired, they were seldom used for signalling. However, as recently as the 1980s, heliographs were used by Afghan forces during the Soviet invasion of Afghanistan. Signal mirrors are still included in survival kits for emergency signaling to search and rescue aircraft.\n\nMost heliographs of the 19th and 20th century were completely manual. The steps of aligning the heliograph on the target, co-aligning the reflected sunbeam with the heliograph, maintaining the sunbeam alignment as the sun moved, transcribing the message into flashes, modulating the sunbeam into those flashes, detecting the flashes at the receiving end, and transcribing the flashes into the message, were all manual steps. One notable exception – many French heliographs used clockwork heliostats to automatically steer out the sun's motion. By 1884, all active units of the \"Mangin apparatus\" (a dual-mode French military field optical telegraph that could use either lantern or sunlight) were equipped with clockwork heliostats. The Mangin apparatus with heliostat was still in service in 1917. Proposals to automate both the modulation of the sunbeam (by clockwork) and the detection (by electrical selenium photodetectors, or photographic means) date back to at least 1882. In 1961, the US Air Force was working on a space heliograph to signal between satellites\n\nIn May 2012, \"Solar Beacon\" robotic mirrors designed at UC Berkeley were mounted on the towers of the Golden Gate bridge, and a web site set up where the public could schedule times for the mirrors to signal with sun-flashes, entering the time and their latitude, longitude and altitude. The solar beacons were later moved to Sather Tower at UC Berkeley. By June 2012, the public could specify a \"custom show\" of up to 32 \"on\" or \"off\" periods of 4 seconds each, permitting the transmission of a few characters of Morse Code. The designer described the Solar Beacon as a \"heliostat\", not a \"heliograph\".\n\nThe first digitally controlled heliograph was designed and built in 2015. It was a semi-finalist in the Broadcom MASTERS competition.\n\n\n\n\n"}
{"id": "38800134", "url": "https://en.wikipedia.org/wiki?curid=38800134", "title": "High-CRI LED lighting", "text": "High-CRI LED lighting\n\nHigh-CRI LED lighting is a light-emitting diode (LED) lighting source that offers a high color rendering index (CRI).\n\nCRI is a quantitative measure of a light's ability to reproduce the colors of objects faithfully in comparison with an ideal or natural light source. In general terms, CRI is a measure of a light source's ability to show object colors \"realistically\" or \"naturally\" compared to a familiar reference source, either incandescent light or sunlight. \n\nEfficiently achieving an acceptable CRI has been the most difficult metric for light bulbs attempting to replace incandescent bulbs. It is therefore frequently ignored in marketing (the CRI value only occasionally appears on product packaging). Light bulbs with a high CRI can be acceptable replacements for incandescent bulbs. Most LED lights do not have a CRI above 90. For example, the top bulbs listed in the 2016 Consumer Review have a CRI of 80.\n\nIn 2008, the US Department of Energy created the L Prize to find an incandescent light bulb replacement that met efficiency metrics and had a CRI above 90.\n\nCRI is calculated from the differences in the chromaticities of eight CIE standard color samples (CIE 1995) when illuminated by a light source and by a reference illuminant of the same correlated color temperature (CCT), commonly measured in Kelvins, indicating the light color produced by a radiating black body at a certain temperature; the smaller the average difference in chromaticities, the higher the CRI. A CRI of 100 represents the maximum possible value. Lower CRI values indicate that some colors appear unnatural. Incandescent lamps have a CRI above 95. Cool white fluorescent lamps have a CRI of 62, however fluorescent lamps containing rare-earth phosphors are available with CRI values of 80 and above.\n\nFor CCTs less than 5000 K, the reference illuminants used in the CRI calculation procedure are the SPDs (Spectral Power Distribution) of blackbody radiators; for CCTs above 5000 K, imaginary SPDs calculated from a mathematical model of sunlight are used. These reference sources were selected to approximate incandescent lamps and sunlight, respectively.\n\nThe CRI measure in use in 2017 was developed by the CIE in 1974 and slightly updated in 1995. The measure has two main flaws. Its color differences are measured in a nonuniform color space. Its color sample set has just 8 items, which is too few to test lights with complex spectra. A light manufacturer can tune its SPD to the sample set so as to achieve an artifically high CRI. In 2015 the IES (Illumination Engineering Society) produced a replacement to the CRI measure that uses a newer color space and 99 color samples. In 2017 the CIE published an almost identical measure, but it did not deprecate its 1995 CRI measure.\n\nCRI has been challenged because fidelity to reference illuminants such as correlated color temperature (CCT) is not all that measures the quality of illumination. Various CCTs are preferred, and scoring 100 at one CCT does not imply equal illumination quality as scoring 100 at another CCT. The \"warmer\" light colors, such as a 2700K incandescent bulb or a 1700K candlelight are more easily reproduced than more neutral white lights, such as 4800K direct sunlight, and thus usually have higher CRI ratings in alternative light sources such as CFL and LED bulbs; \"warmer\" light (redder) naturally renders colors less accurately. Think of how the world looks at sunset (2000K) compared to high noon (5600K).\n\nProblems have been encountered attempting to use LED lighting on film and video sets. The color spectra of LED lighting primary colors does not match the expected color wavelength bandpasses of film emulsions and digital sensors. As a result, color rendition can be unpredictable in optical prints, transfers to digital media from film and video camera recordings. This phenomenon with respect to motion picture film has been documented in an LED lighting evaluation series of tests produced by the Academy of Motion Picture Arts and Sciences scientific staff.\n\n"}
{"id": "57742002", "url": "https://en.wikipedia.org/wiki?curid=57742002", "title": "Jabbertalky", "text": "Jabbertalky\n\nJabbertalky is a 1981 video game published by Automated Simulations.\n\n\"Jabbertalky\" is programmable word game which includes three games and a method of creating a vocabulary for use in these games.\n\nRon Boerger reviewed \"Jabbertalky\" in \"The Space Gamer\" No. 48. Boerger commented that \"Unless you are (a) crazy about word games, (b) want to buy every game for the Apple, or (c) both of the above, don't waste your money on this one.\"\n"}
{"id": "813244", "url": "https://en.wikipedia.org/wiki?curid=813244", "title": "Jet pack", "text": "Jet pack\n\nA jet pack, rocket belt, or rocket pack is a device worn on the back which uses jets of gas or liquid to propel the wearer through the air. The concept has been present in science fiction for almost a century and became widespread in the 1960s. Real jet packs have been developed using a variety of mechanisms, but their uses are much more limited than their fictional counterparts because of the challenges of Earth's atmosphere, gravity, low energy density of available fuels, and the human body not being suited to fly, and they are principally used for stunts. A practical use for the jet pack has been in extra-vehicular activities for astronauts.\n\nIn the most general terms, a jet pack is a wearable device which allows the user to fly by providing thrust. With the exception of use in a microgravity environment, this thrust must be upwards so as to overcome the force of gravity, and must be enough to overcome the weight of the user, the jet pack itself and its fuel. This necessarily requires the jet pack to continually push mass in a downwards direction.\n\nWhile some designs have power and/or mass supplied from an external, ground-based source, untethered flight requires all of a flight's fuel to be carried within the pack. This results in problems relating to the overall mass ratio, which limits the maximum flight time to tens of seconds, rather than the sustained flight envisaged in science fiction.\n\nThe first jet pack design was developed in 1919 by the Russian inventor Aleksandr Fyodorovich Andreyev. The project was well regarded by Nikolai Rynin and technology historians Yu. V. Biryukov and S. V. Golotyuk. Later it was issued a patent but apparently was not built or tested. It was oxygen-and-methane-powered (likeliest a rocket) with wings each roughly long!\n\nA hydrogen peroxide-powered engine is based on the decomposition reaction of hydrogen peroxide. Nearly pure (90% in the Bell Rocket Belt) hydrogen peroxide is used. Pure hydrogen peroxide is relatively stable, but in contact with a catalyst (for example, silver) it decomposes into a mixture of superheated steam and oxygen in less than 1/10 millisecond, increasing in volume 5,000 times: 2 HO → 2 HO + O. The reaction is exothermic, i.e., accompanied by the liberation of much heat (about ), forming in this case a steam-gas mixture at . This hot gas is used exclusively as the reaction mass and is fed directly to one or more jet nozzles.\n\nThe great disadvantage is the limited operating time. The jet of steam and oxygen can provide significant thrust from fairly lightweight rockets, but the jet has a relatively low exhaust velocity and hence a poor specific impulse. Currently, such rocket belts can only fly for about 30 seconds (because of the limited amount of fuel the user can carry unassisted).\n\nA more conventional bipropellant could more than double the specific impulse. However, although the exhaust gases from the peroxide-based engine are very hot, they are still significantly cooler than those generated by alternative propellants. Using a peroxide-based propellant greatly reduces the risk of a fire/explosion which would cause severe injury to the operator.\n\nIn contrast to, for example, turbojet engines, which mainly expel atmospheric air to produce thrust, rocket packs are far simpler to build than devices using turbojets. The classical rocket pack construction of Wendell Moore can be made under workshop conditions, given good engineering training and a high level of tool-making craftsmanship.\n\nThe main disadvantages of this type of rocket pack are:\nThese circumstances limit the sphere of the application of rocket packs to very spectacular public demonstration flights, i.e., stunts; for example, a flight was arranged in the course of the opening ceremony of the 1984 Summer Olympic Games in Los Angeles, USA.\n\nJustin Capră claimed that he invented a \"flying rucksack\" (Romanian: \"rucsac zburator\") in 1956 in Romania, and, without arousing any apparent interest, informed the American Embassy of his idea. In 1962 a backpack was created at Bell Laboratories, following Justin Capră’s prototype. The backpack is now displayed in a museum where it's kept safe.\n\nIn 1958, Garry Burdett and Alexander Bohr, Thiokol Corporation engineers, created a Jump Belt which they named Project Grasshopper. Thrust was created by high-pressure compressed nitrogen. Two small nozzles were affixed to the belt and directed vertically downward. The wearer of the belt could open a valve, letting out nitrogen from the gas cylinder through the nozzles, which tossed him upward to a height of . After leaning forward, it was possible with the aid of the jump belt's thrust to run at . Later, Burdett and Bohr tested a hydrogen peroxide-powered version. The jump belt was demonstrated by a serviceman in action, but as no financing was forthcoming, there was no further testing.\n\nIn 1959 Aerojet General Corporation won a U.S. Army contract to devise a jet pack or rocket pack. At the start of 1960 Richard Peoples made his first tethered flight with his Aeropack.\n\nThe military did not lose interest in this type of flight vehicle. Transport studies of the U.S. Army Transportation Research Command (TRECOM) determined that personal jet devices could have diverse uses: for reconnaissance, crossing rivers, amphibious landing, accessing steep mountain slopes, overcoming minefields, tactical maneuvering, etc. The concept was named \"Small Rocket Lift Device\", SRLD.\n\nWithin the framework of this concept the administration concluded a big contract with the Aerojet General company in 1959 to research the possibility of designing an SRLD suitable for army purposes. Aerojet came to the conclusion that the version with the engine running on hydrogen peroxide was most suitable. However, it soon became known to the military that engineer Wendell Moore of the Bell Aerosystems company had for several years been carrying out experiments to make a personal jet device. After becoming acquainted with his work, servicemen during August 1960 decided to commission Bell Aerosystems with developing an SRLD. Wendell Moore was appointed chief project engineer.\n\nIn 1960, the Bell Rocketbelt was presented to the public. The jet of gas was provided by a hydrogen peroxide-powered rocket, but the jet could also be provided by a turbojet engine, a ducted fan, or other kinds of rockets powered by solid fuel, liquid fuel or compressed gas (usually nitrogen).\n\nThis is the oldest known type of jet pack or rocket pack. One Bell Rocket Belt is on display at the Smithsonian Institution's National Air and Space Museum annex, the Steven F. Udvar-Hazy Center, located near Dulles Airport.\n\nThis was a successor to the Bell Rocket Belt.\n\nThe Bell Pogo was a small rocket-powered platform that two people could ride on. Its design used features from the Bell Rocket Belt.\n\nMore commonly known as \"The Rocketman\", Powerhouse Productions, owned and operated by Kinnie Gibson, manufactures the 30 second flying Rocketbelt (June 1994) and organizes Rocketbelt performances. Since 1983 Powerhouse Productions has performed show flights in over 40 countries such as the Carnival in Rio de Janeiro, Super Bowls, the Rose Parade, Daytona 500, and the Michael Jackson Dangerous World Tour, as well as many television shows including Walker Texas Ranger, The Fall Guy and NCIS. Powerhouse Rocketbelt pilots include stuntman Kinnie Gibson and Dan Schlund.\n\nJetpack International made three types of wingless jet packs:\n\nA Jet Pack H202 was flown for 34 seconds in Central Park on the 9 April 2007 episode of the Today Show and sold for $150,000. As of January 2009 their H202 jet packs are for demonstration only, not for sale. Details of the likely consumer model \"Falcon\" were scheduled for an official announcement on May 1, 2012, but the company is currently behind schedule.\n\nAt the TechCrunch Disrupt conference in 2014, Astro Teller, head of Google X (Google's research laboratory), said they investigated jetpacks but found them too inefficient to be practical, with fuel consumption as high as , and were as loud as a motorcycle, so they decided not to pursue developing them.\n\nIn recent years, the rocket pack has become popular among enthusiasts, and some have built them for themselves. The pack's basic construction is rather simple, but its flying capability depends on two key parts: the gas generator, and the thrust control valve. The rocket packs being built today are largely based on the research and inventions of Wendell Moore at Bell Helicopter.\n\nOne of the largest stumbling blocks that would-be rocket pack builders have faced is the difficulty of obtaining concentrated hydrogen peroxide, which is no longer produced by many chemical companies. The few companies that produce high-concentration hydrogen peroxide only sell to large corporations or governments, forcing some amateurs and professionals to set up their own hydrogen peroxide distillation installations. High-concentration hydrogen peroxide for rocket belts was produced by Peroxide Propulsion (Gothenburg, Sweden) from 2004 to 2010, but after a serious accident Peroxide Propulsion stopped making it.\n\nPacks with a turbojet engine are fueled with traditional kerosene-based jet fuel. They have higher efficiency, greater height and a duration of flight of many minutes, but they are complex in construction and very expensive. Only one working model of this pack was made; it underwent flight tests in the 1960s and at present it no longer flies.\nJet packs and rocket packs have much better flight time on a tankful of fuel if they have wings like an aeroplane's.\n\nIn 1965 Bell Aerosystems concluded a new contract with the Defense Advanced Research Projects Agency (DARPA) to develop a jet pack with a turbojet engine. This project was called the \"Jet Flying Belt\", or simply the \"Jet Belt\". Wendell Moore and John K. Hulbert, a specialist in gas turbines, worked to design a new turbojet pack. Williams Research Corporation (now Williams International) in Walled Lake, Michigan, designed and built a new turbojet engine to Bell's specifications in 1969. It was called the WR19, had a rated thrust of and weighed . The Jet Belt first flew free on 7 April 1969 at the Niagara Falls Municipal Airport. Pilot Robert Courter flew about in a circle at an altitude of , reaching a speed of . The following flights were longer, up to 5 minutes. Theoretically, this new pack could fly for 25 minutes at velocities up to .\n\nIn spite of successful tests, the U.S. Army lost interest. The pack was complex to maintain and too heavy. Landing with its weight on their back was hazardous to the pilot, and catastrophic loss of a turbine blade could have been lethal.\n\nThus, the Bell Jet Flying Belt remained an experimental model. On 29 May 1969, Wendell Moore died of complications from a heart attack he had suffered six months earlier, and work on the turbojet pack was ended. Bell sold the sole version of the \"Bell pack\", together with the patents and technical documentation, to Williams Research Corporation. This pack is now in the Williams International company museum.\n\nThe \"Jet Belt\" used a small turbofan engine which was mounted vertically, with its air intake downward. Intake air was divided into two flows. One flow went into the combustion chamber, the other flow bypassed the engine, then mixed with the hot turbine gases, cooling them and protecting the pilot from the high temperatures generated. In the upper part of the engine the exhaust was divided and entered two pipes which led to jet nozzles. The construction of the nozzles made it possible to move the jet to any side. Kerosene fuel was stored in tanks beside the engine. Control of the turbojet pack was similar to the rocket pack, but the pilot could not tilt the entire engine. Maneuvering was by deflecting the nozzles. By inclining levers, the pilot could move the jets of both nozzles forward, back, or sideways. The pilot rotated left/right by turning the left handle. The right handle governed the engine thrust. The jet engine was started with the aid of a powder cartridge. While testing this starter, a mobile starter on a special cart was used. There were instruments to control the power of the engine, and a portable radio to connect and transmit telemetry data to ground-based engineers. On top of the pack was a standard auxiliary landing parachute; it was effective only when opened at altitudes above . This engine was later the basis for the propulsion units of Tomahawk and other cruise missiles.\n\nOn 25 October 2005 in Lahti in Finland, Visa Parviainen jumped from a hot air balloon in a wingsuit with two small turbojet jet engines attached to his feet. Each turbojet provided approximately of thrust and ran on kerosene (Jet A-1) fuel. Parviainen apparently achieved approximately 30 seconds of horizontal flight with no noticeable loss of altitude.\n\nSwiss ex-military and commercial pilot Yves Rossy developed and built a winged pack with rigid aeroplane-type carbon-fiber wings spanning about and four small kerosene-burning Jetcat P400 jet engines underneath; these engines are large versions of a type designed for model aeroplanes. He wears a heat-resistant suit similar to that of a firefighter or racing driver to protect him from the hot jet exhaust. Similarly, to further protect the wearer, the engines are modified by adding a carbon fibre heat shield extending the jet nozzle around the exhaust tail.\n\nRossy claims to be \"the first person to gain altitude and maintain a stable horizontal flight thanks to aerodynamic carbon foldable wings\", which are folded by hinges at their midpoint. After being lifted to altitude by a plane, he ignites the engines just before he exits the plane with the wings folded. The wings unfold while in free-fall, and he then can fly horizontally for several minutes, landing with the help of a parachute. He achieves true controlled flight using his body and a hand throttle to maneuver; jet wingsuits use small turbojets, but differ from other aircraft in that the fuselage and flight control surfaces consist of a human.\n\nThe system is said by Rossy to be highly responsive and reactive in flight, to the point where he needs to closely control his head, arm and leg movements to avoid an uncontrolled spin. The engines on the wing must be aligned precisely during set-up, also to prevent instability. An electronic starter system ensures that all four engines ignite simultaneously. In the event of a spin, the wing unit can be detached from the pilot, and pilot and wing unit descend to Earth separately, each with a parachute.\n\nSince 2007, Rossy has conducted some of his flight tests from a private airfield, Skydive Empuriabrava, in Empuriabrava (Girona, Costa Brava), Spain. Rossy's jet pack was exhibited on 18 April 2008 on the opening day of the 35th Exhibition of Inventions at Geneva. Rossy and his sponsors spent over $190,000 to build the device. His first successful trial flight was on 24 June 2004 near Geneva, Switzerland. Rossy has made more than 30 powered flights since. In November 2006 he flew with a later version of his jet pack. On 14 May 2008 he made a successful 6-minute flight from the town of Bex near Lake Geneva. He exited a Pilatus Porter at with his jet pack. It was the first public demonstration before the world's press. He made effortless loops from one side of the Rhone valley to the other and rose .\n\nIt has been claimed that the military was impressed and asked for prototypes for the powered wings, but that Rossy kindly refused the request stating that the device was only intended for aviation enthusiasts.\n\nOn 26 September 2008, Yves successfully flew across the English Channel from Calais, France, to Dover, England, in 9 minutes, 7 seconds. His speed reached during the crossing and was when he deployed the parachute.\nSince then he has—in several flights—managed to fly in a formation with three military jets and cross the Grand Canyon, but he failed to fly across the Strait of Gibraltar—he made an emergency landing in the water.\n\nOn 13 October 2015 a show flight was performed in Dubai. Two jet packs operated by Rossy and Vince Reffet flew in formation with an Airbus A380 jetliner.\n\nIn 2008 Troy Hartman started designing a wingless jetpack with two turbojet motors strapped to his back; later he added a parafoil as a wing.\n\nAs at 2013 Fritz Unger in Germany is developing a jetpack called Skyflash with rigid wings about wingspan and two turbojets designed to run on diesel fuel. It is designed for takeoff from the ground using four undercarriage wheels on the front of his chest and abdomen.\n\nOn 3 November 2015, Jetpack Aviation demonstrated the JB-9 in Upper New York Bay in front of the Statue of Liberty. The JB-9 carries of kerosene fuel that burns through two vectored thrust AMT Nike jet engines at a rate of per minute for up to ten minutes of flying time, depending on pilot weight. Weight of fuel is a consideration, but it is reported to start with per minute climb rate that doubles as the fuel burns off. While this model has been limited to , the prototype of the JB-10 is reported to fly at over .\n\nThis is a true jetpack: a backpack that provides jet-powered flight. Most of the volume is the fuel tank, with twin turbine jet engines gimbal-mounted on each side. The control system is identical to the Bell Rocket Belt: tilting the handgrips vectors the thrust – left-right & forward-back – by moving the engines; twisting left hand moves two nozzle skirts for yaw; twisting the right hand counterclockwise increases throttle. Jetpack Aviation was started by Australian businessman David Mayman with the technical knowhow coming from Nelson Tyler, prolific inventor of helicopter-mounted camera stabilizers and one of the engineers that worked on the Bell Rocketbelt that was used in the 1984 Olympics.\n\nFlyboard Air, invented by Franky Zapata, allows flight up to and has a top speed of . It also has 10 minutes autonomy.\n\nSee full article Daedalus Flight Pack\n\nThis particular innovation saw two jets attached to the back of an exoskeleton, worn by the operator. At the same time, two additional jets were added to the arms, and could be moved with the arms to control movement. It was devised by Richard Browning of Gravity Industries.\n\nRocket packs can be useful for spacewalks. While near Earth a jet pack has to produce a g-force of at least 1g (a smaller g-force, providing only some deviation from free fall is of little use here), for excursions outside a free falling spaceship, a small g-force providing a small deviation from free fall is quite useful. Hence much less delta-v is consumed per unit time, and not during the whole EVA. With only small amounts of thrust needed, safety and temperature are much more manageable than in the atmosphere in Earth's gravity field.\n\nNevertheless, it is currently worn to be used only in case of emergency: the Simplified Aid For EVA Rescue (SAFER).\n\nThe 21st century has seen a new approach to jet packs where water is used as a high-density propulsion fluid. This requires a very large mass of fluid that makes a self-contained jetpack infeasible. Instead, this approach separates the engine, fuel and fluid supply from the pilot's flying apparatus, using a long flexible hose to feed the water to the jet nozzle pack attached to the pilot's body. These inventions are known as \"hydro jet packs\", and successful designs have used jetski technology as the powerplant operating in a body of water (an ocean, lake, or pool) to provide the needed propulsion. Several hydro jet pack approaches have been successfully tested and put into production. Flow rate can be controlled by a throttle operator on the jetski, or by the pilot using a remote actuator.\n\nAnother significant difference with hydro jet packs is that they can be operated below the surface as well as above it. As of 2013, many hydro jet pack rental businesses are operating in various locations around the world.\n\nThe JetLev was the first hydroflight jetpack on the market, and its makers were awarded the first patents, in 2008, for hydrojetpacks. The JetLev has the appearance of a typical jet pack, with two nozzles on a backpack propelling the rider upwards. It just has an umbilicus to the powering jetski that provides the water for the thrust used.\n\nA Flyboard has water jets under each of the pilot's feet. An optional feature is a lower-thrust water jet for each arm for greater control. The powerplant is a regular jetski. Development for this approach was started in the spring of 2011.\n\nEpisode 32 of \"MythBusters\" investigates the urban legend of an affordable jet pack or rocket pack that can be built from plans purchased on the Internet. Extensive modifications were made by the MythBusters team due to vagueness in the plans and because of the infeasibility of the specified engine mounting system. The jet pack produced by the MythBusters had two ducted fans powered by ultralight-type piston engines. (Fans complained that the use of piston engines destroyed the whole idea of the pack's being truly based on jets, by which, presumably, they meant self-contained gas turbines.) They found it was not powerful enough to lift a person off the ground, and was expensive to build. The plans specified a Rotax 503 ultralight engine, but they intended to use the more powerful and lighter Rotax 583 engine before a similar lighter unnamed engine was substituted.\n\nThe concept of jet packs appeared in popular culture, particularly science fiction, long before the technology became practical. Perhaps the first appearance was in pulp magazines. The 1928 cover of \"Amazing Stories\" featured a man flying with a jet pack.\n\nWhen Republic Pictures planned to produce a superhero serial using its renowned \"flying man\" scenes as used in \"The Adventures of Captain Marvel\", the character of Captain Marvel was tied up in litigation with the owners of the character of Superman. For its postwar superhero serial, Republic used a jet pack in \"King of the Rocket Men\". The same stock special effects were used in other serials.\n\nWhile several science fiction novels from the 1950s featured jetpacks, it was not until the \"Bell Rocket Belt\" in the 1960s that the jet pack caught the imagination of the mainstream. Bell's demonstration flights in the U.S. and other countries created significant public enthusiasm.\n\nJetpacks were featured in two episodes (\"Turu the Terrible\" and \"The Invisible Monster\"), of the original \"Jonny Quest\" (1964-1965) animated television series, and are seen at the end of the closing credits.\n\nIn 1965 a jetpack appeared in the James Bond movie \"Thunderball\" when James Bond played by Sean Connery used a jet pack in the pre-title sequence to escape the bad guys and rendezvous with his French contact. The pack was piloted by Gordon Yaeger and Bill Suitor.\n\nIn the Irwin Allen television series \"Lost in Space\" (1965-1968), a jetpack was used by members of the Jupiter II expedition on several occasions.\n\nIn 1966 the plot of the 21st book in the Rick Brant series titled \"Rocket Jumper\" was based on a hydrogen peroxide fueled jet pack, The book included a relatively detailed description of the design including use of a platinum-metal screen catalyst.\n\nIn the 1997 video game Crash Bandicoot 2: Cortex Strikes Back, the titular character Crash, operates a jetpack in two main levels, \"Rock It\" and \"Pack Attack\". He also uses the jetpack in the final boss fight against Dr. Neo Cortex.\n\nThe 1976 television series \"Ark II\" featured a jetpack called the Jet Jumper.\n\nIn the \"Star Wars\" original trilogy, the bounty hunter Boba Fett used a jet pack. In the prequel trilogy, Jango Fett also used a jet pack.\nIn the 1982-1995 comics book series, \"The Rocketeer\", the protagonist, Cliff Secord, acquires a stolen military jet pack and uses it to become the eponymous superhero. It was later adapted into a motion picture in 1991.\n\nThe G.I. Joe action figure launch in 1982 included the JUMP (Jet Mobile Propulsion Unit) jet pack as an accessory. It was also featured prominently in the related \"G.I. Joe\" comic book series and cartoon.\n\nJetpacks have been used by the title characters in several episodes of \"SWAT Kats\" cartoon series (1993–94).\n\nJetpacks appear in the popular video game \"\". On September 13, 2010, during a \"Halo: Reach\" launch party at London, England's Trafalgar Square, stuntman Dan Schlund of Powerhouse Productions Inc \"Rocketman\" firm (which provides jet packs for use by marketing and sporting companies) donned a Halo-esque \"Spartan armor\" suit and a jet pack and maintained flight for 30 seconds before landing safely.\nThe jet-pack also appears in the 2012 video game \"Halo 4\", developed by 343 Industries.\n\nJetpacks also appeared in other video games, including \"BloodRayne\" (worn by Nazi troopers), \"Tribes\", \"\", \"Armed and Dangerous\", and the \"Pilotwings\" series, in which it is referred to as a \"Rocket Belt\". It is also accessible in the video game \"\". \"Fallout 4\" also has a jetpack power armor feature. Grand Theft Auto Online added a jetpack called \"Thruster\" as an usable vehicle on a content update on December 12, 2017.\n\nMany science fiction movies have included jet packs, most notably \"Minority Report\", \"Sky Captain and the World of Tomorrow\", and \"Tomorrowland\".\n\n\n"}
{"id": "670650", "url": "https://en.wikipedia.org/wiki?curid=670650", "title": "List of MOTU products", "text": "List of MOTU products\n\nThe following is a partial list of products that Mark of the Unicorn (MOTU) supplies to the public. Some of these are no longer in production.\n\n\n\n\n\n\n"}
{"id": "4529555", "url": "https://en.wikipedia.org/wiki?curid=4529555", "title": "MacvsWindows", "text": "MacvsWindows\n\nMac vs Windows (formerly XvsXP) was an online operating system comparison wiki run by James Scariati and Michael Moriarty. The site is no longer active and its domains now point to spam blogs.\n\nThe site compares competing operating systems Windows Vista and Mac OS X v10.5 through over 100 different topics. The site explicitly includes only the \"out-of-the-box\" experience of each OS, as well as any freely released updates from the manufacturer. A unique feature of the site over many other OS comparison sites is that it features a forum to encourage readers to voice any concerns or comments about the site, as well as any suggestions for additions.\n\nThe site was originally launched in March 2003 by Dan Pouliot, with the scope of the site explicit also to the concerns of the \"creative professional\". The site was originally intended to advocate OS X by virtue of a fair comparison to Windows XP. Pouliot acknowledged that such a fair comparison was difficult, and he relied on debates within the site's own online forum to refine and expand the site. A PDF version of the site was available, and Pouliot reports it was downloaded 250,000 times between the launch of the site and the time the PDF was removed in January 2005.\n\nThe site was almost closed down in January 2005, including a brief period when XvsXP was converted to a pay site. Pouliot at that time decided he needed to move on, so a change of ownership was negotiated.\n\nIn November 2005, the site officially changed hands to the current owners, James Scariati and Michael Moriarty, and a rewrite of the site began, with a renewed objective of an unbiased comparison. The point of view was changed away from first person. Content considered to be editorial in nature was removed.\n\nThe site officially relaunched in March 2006, sporting a refreshed look and updated sections, as well as a format that was reportedly designed for ease of updating due to the upcoming releases of both operating systems, Windows Vista and Mac OS X v10.5.\n\nOn June 20, 2007, XvsXP.com owners announced they were moving to a new website, \"Mac vs. Windows\" (www.macvswindows.com). One of the main new features introduced with their new website was the transition to a wiki model.\n\nThe website does not take into account factors such as software availability, total cost of ownership, hardware interoperability and so forth. The owners contend that such topics fall outside of the site's scope as an operating system comparison and fall into a broader platform comparison. Both owners have stated that even the current comparison is a large amount of work, so a truly objective comparison of all aspects of each platform would require a team of full-time employees. In addition, the current \"1 to 10\" scoring system has been viewed as being too definitive for a subjective review. This is also compounded in the \"Final Score\" page where there is no option to weigh the scores based on the user's concerns. (e.g. security is given as much weight as icons).\n\nFurther criticism of XvsXP can be lodged for the continued delays in providing coverage of the Windows side of the comparison. As of June 10, 2007, the site still fails to show data on Windows Vista, over seven months after Vista’s Release to Manufacturing (RTM). This even though one of the XvsXP admins acknowledged (over four months ago) that Vista was released (their initial acknowledgement [February 8, 2007] of Vista came three months after it went RTM).\n\n\n"}
{"id": "6726416", "url": "https://en.wikipedia.org/wiki?curid=6726416", "title": "Mobile equipment identifier", "text": "Mobile equipment identifier\n\nA mobile equipment identifier (MEID) is a globally unique number identifying a physical piece of CDMA2000 mobile station equipment. The number format is defined by the 3GPP2 report S.R0048 but in practical terms, it can be seen as an IMEI but with hexadecimal digits.\n\nAn MEID is 56 bits long (14 hex digits). It consists of three fields, including an 8-bit regional code (RR), a 24-bit manufacturer code, and a 24-bit manufacturer-assigned serial number. The check digit (CD) is not considered part of the MEID.\n\nThe MEID was created to replace ESNs, whose virgin form was exhausted in November 2008. As of TIA/EIA/IS-41 Revision D and TIA/EIA/IS-2000 Rev C, the ESN is still a required field in many messages—for compatibility, devices with an MEID can use a pseudo-ESN (pESN), which is a manufacturer code of 0x80 (formerly reserved) followed by the least significant 24 bits of the SHA-1 hash of the MEID. MEIDs are used on CDMA mobile phones. GSM phones do not have ESN or MIN, only an International Mobile Station Equipment Identity (IMEI) number.\n\nOpen your phone's dialler and type *#06# to get its MEID number.\n\nThe separation between international mobile equipment identifiers (IMEIs) used by GSM/UMTS and MEIDs is based on the number ranges. There are two administrators: the global decimal administrator (GDA) for IMEIs and the global hexadecimal administrator (GHA).\n\nAs of August 2006, the TIA acts as the GHA to assign MEID code prefixes (0xA0 and up), and the GSM Association acts as the global decimal administrator. http://www.babt.com/gsm-imei-number-allocation.asp\n\nThe TIA also allocates IMEI codes, specifically destined for dual-technology phones, out of the RR=99 range. Other administrators working under GSMA may also allocate any IMEI for use in dual-technology phones. Every IMEI can also be used as an MEID in CDMA2000 devices (as well as in single-mode devices designed with GSM or other 3GPP protocols) but MEID codes may also contain hexadecimal digits and this class of MEID codes cannot be used as an IMEI.\n\nThere are two standard formats for MEIDs, and both can include an optional check-digit. This is defined by 3GPP2 standard X.S0008.\n\nThe hexadecimal form is specified to be 14 digits grouped together and applies whether all digits are in the decimal range or whether some are in the range 'A'-'F'. In the first case, all digits are in the range '0'-'9', the check-digit is calculated using the normal base 10 Luhn algorithm, but if at least one digit is in the range 'A'-'F' this check digit algorithm uses base 16 arithmetic. The check-digit is never transmitted or stored. It is intended to detect most (but not all) input errors, it is not intended to be a checksum or CRC to detect transmission errors. Consequently, it may be printed on phones or their packaging in case of manual entry of an MEID (e.g. because there is no bar code or the bar code is unreadable).\n\nThe decimal form is specified to be 18 digits grouped in a 5 5 4 4 pattern and is calculated by converting the manufacturer code portion (32 bits) to decimal and padding on the left with '0' digits to 10 digits and separately converting the serial number portion to decimal and padding on the left to 8 digits. A check-digit can be calculated from the 18 digit result using the standard base 10 Luhn algorithm and appended to the end. Note that to produce this form the MEID digits are treated as base 16 numbers even if all of them are in the range '0'-'9'.\n\nBecause the pESN is formed by a hash on the MEID there is the potential for hash collisions. These will cause an extremely rare condition known as a 'collision' on a pure ESN-only network as the ESN is used for the calculation of the Public Long Code Mask (PLCM) used for communication with the base-station. Two mobiles using the same pESN within the same base-station area (operating on the same frequency) can result in call setup and page failures.\n\nThe probability of a collision has been carefully examined. Roughly, it is estimated that even on a heavily loaded network the frequency of this situation is closer to 1 out of 1 million calls than to 1 out of 100 000.\n\n3GPP2 specification C.S0072 provides a solution to this problem by allowing the PLCM to be established by the base station. It is easy for the base station to ensure that all PLCM codes are unique when this is done. This specification also allows the PLCM to be based on the MEID or IMSI.\n\nA different problem occurs when ESN codes are stored in a database (such as for OTASP). In this situation, the risk of at least two phones having the same pseudo-ESN can be calculated using the birthday paradox and works out to about a 50 per cent probability in a database with 4,800 pseudo-ESN entries. 3GPP2 specifications C.S0016 (Revision C or higher) and C.S0066 have been modified to allow the replacement MEID identifier to be transmitted, resolving this problem.\n\nAnother problem is that messages delivered on the forward paging channel using the pESN as an address could be delivered to multiple mobiles seemingly randomly. This problem can be avoided by using mobile identification number (MIN) or IMSI based addressing instead.\n\nThis short Python script will convert an MEID to a pESN.\nThe CDG also provides a javascript calculator with more conversion options.\n\n"}
{"id": "5612879", "url": "https://en.wikipedia.org/wiki?curid=5612879", "title": "Moisture sorption isotherm", "text": "Moisture sorption isotherm\n\nAt equilibrium, the relationship between water content and equilibrium humidity of a material can be displayed graphically by a curve, the so-called moisture sorption isotherm. \nFor each humidity value, a sorption isotherm indicates the corresponding water content value at a given, constant temperature. If the composition or quality of the material changes, then its sorption behaviour also changes. Because of the complexity of sorption processes, the isotherms cannot be determined by calculation, but must be recorded experimentally for each product.\n\nThe relationship between water content and water activity (a) is complex. An increase in a is usually accompanied by an increase in water content, but in a non-linear fashion. This relationship between water activity and moisture content at a given temperature is called the moisture sorption isotherm. These curves are determined experimentally and constitute the fingerprint of a food system.\n\n\n"}
{"id": "1600356", "url": "https://en.wikipedia.org/wiki?curid=1600356", "title": "Mud engineer", "text": "Mud engineer\n\nA mud engineer (correctly called a Drilling Fluids Engineer, but most often referred to as the \"Mud Man\") works on an oil well or gas well drilling rig, and is responsible ensuring the properties of the drilling fluid, also known as drilling mud, are within designed specifications.\n\nMud is a vital part of drilling operations. It provides hydrostatic pressure on the borehole wall to prevent uncontrolled production of reservoir fluids, lubricates and cools the drill bit, carries the drill cuttings up to the surface, forms a \"filter-cake\" on the borehole wall to prevent drilling fluid invasion, provides an information medium for well logging, and helps the drilling by fracturing the rock from the jets in the bit. To fulfill these tasks effectively, the mud contains carefully chosen additives to control its chemical and rheological properties.\n\nDrilling mud is usually a shear thinning non-Newtonian fluid of variable viscosity. When it is under more shear, such as in the pipe to the bit and through the bit nozzles, viscosity is lower which reduces pumping-power requirements. When returning to the surface through the much roomier annulus it is under less shear stress and becomes more viscous, and hence better able to carry the rock cuttings. Bentonite is commonly used as an additive to control and maintain viscosity, and also has the additional benefit of forming a mud-cake (also known as a filter cake) on the bore-hole wall, preventing fluid invasion.\n\nBarite is commonly used to \"weight\" the mud to maintain adequate hydrostatic pressure down-hole. This is critical in a drilling operation to avoid a kick and ultimately a blowout from uncontrolled production of formation fluids. The \"mud-pits\" at the surface have their levels carefully monitored, since an increase in the mud level indicates a kick is taking place, and may require shutting in the well and circulating heavier weighted drilling mud to prevent further formation fluid or gas production.\n\nDrilling fluid must be chemically compatible with the formations being drilled. Salinity must be chosen so as not to cause clay swelling or other problems. Mud can be \"oil-based\" or \"water-based\". In many areas oil-based muds are being phased out, as they are less environmentally friendly, although in some formations they are necessary because of chemical compatibility issues. Offshore rigs typically use synthetic oil based mud.\n\nThe mud engineer (or drilling fluids engineer) may be a university, college, or technical institute graduate, having gained experience working on rigs. On land, this experience would come from being a derrick hand, and offshore, the experience would come from being a pump man. Prior to working on his own, he has been on a special training course, known as \"mud school\", and often spends time working with a senior mud engineer to gain experience. \n\nBefore the mid-1940s, the driller dealt with drilling mud; but specialization occurred with the increasing complexity and overlapped more with the geologist.\n\nPrior to drilling a well, a \"mud program\" will be worked out according to the expected geology, in which products to be used, concentrations of those products, and fluid specifications at different depths are all predetermined. As the hole is drilled and gets deeper, more mud is required, and the mud engineer is responsible for making sure that the new mud to be added is made up to the required specifications. The chemical composition of the mud will be designed so as to stabilize the hole. It is sometimes necessary to completely change the mud to drill through a particular subsurface layer. \n\nAs drilling proceeds, the mud engineer will get information from other service providers such as the mud logger (mud logging technician) about progress through the geological zones, and will make regular physical and chemical checks on the drilling mud. In particular the Marsh funnel viscosity and the density are frequently checked. As drilling proceeds, the mud tends to accumulate small particles of the rocks which are being drilled through, and its properties change. It is the job of the mud engineer to specify additives to correct these changes, or to partially or wholly replace the mud when necessary. He or she must also keep an eye on the equipment which is used to pump the mud and to remove particles, and be prepared if the geologists' predictions are not entirely correct, or if other problems arise.\n\nIt is sometimes necessary to stabilize the wall of a borehole at a particular depth by pumping cement down through the mud system, and the mud engineer is sometimes in charge of this process.\n\nThe mud engineer is well supported by the mud supply company with computer aids and manuals dealing with all known problems and their solution, but it is his or her responsibility to get it right in a situation where mistakes can be very costly indeed.\n\nA mud engineer's job may involve long shifts of over 12 hours a day. Typical offshore and foreign work schedules are four weeks working and four weeks off.\n\nOne of the most important mud properties is the mud weight (density). If the mud weight exceeds the fracture pressure of the formation, the formation may fracture and large quantities of mud are lost to it, in a situation referred to as lost circulation. These cracks can also cause water to seep into the well bore or into a hydrocarbon bearing zone, which would likely impede the ability of the formation to produce oil (or require the separation of large quantities of water).\n\nConversely, if the mud weight is too low it will have a hydrostatic pressure that is less than the formation pressure. This will cause pressurized fluid in the formation to flow into the wellbore and make its way to the surface. This is referred to as a formation \"kick\" and can lead to a potentially deadly blowout if the invading fluid reaches the surface uncontrolled.\n\nOther important mud properties to be maintained are the YP (Yield Point) which determines the carrying capacity of the mud to carry the drill cuttings to the surface. Mud should be capable of forming a thin \"mud cake\" which forms a lining of the borehole walls.\n\nDrilling fluids operations are often contracted to service companies, a trend commonly observed in the oil industry for most of it operations. The largest four companies for mud services are M-I SWACO (A Schlumberger Company), Baroid Drilling Fluids (Halliburton Oilfield Services), Baker Hughes Drilling Fluids, and Weatherford International Drilling Fluids and Drilling Waste Management. There are, however, many smaller companies providing drilling fluid services as well. Independent companies can provide a localized knowledge, and quality services and mud products.\nHamilton Technologies is also the largest independent drilling fluids company presently in West Africa\n\n"}
{"id": "10038978", "url": "https://en.wikipedia.org/wiki?curid=10038978", "title": "NE1000", "text": "NE1000\n\nThe NE1000/NE2000 is an early line of low cost Ethernet network cards originally produced by Novell by 1987. Its popularity had a significant impact on the pervasiveness of networks in computing. They are based on a National Semiconductor prototype design using their 8390 Ethernet chip.\n\nIn the late 1980s, Novell was looking to shed its hardware server business and transform its flagship NetWare product into a PC-based server operating system that was agnostic and independent of the physical network implementation and topology (Novell even referred to NetWare as a NOS, or \"network operating system\"). To do this, Novell needed networking technology in general — and networking cards in particular — to become a commodity, so that the server operating system and protocols would become the differentiating technology.\n\nMost of the key pieces of this strategy were already in place: Ethernet and token ring (among others) had been codified by the IEEE 802 standards committee — the draft was not formally adopted until 1990, but was already in widespread use, and cards from one vendor were, on the whole, wire-compatible with cards complying with the same 802 working group. However, networking hardware vendors in general, and industry leaders 3Com and IBM in particular, were charging high prices for their hardware.\n\nTo combat this, Novell decided to develop its own line of cards. In order to create these at minimal R&D, engineering and production costs, Novell simply implemented, almost verbatim, a prototype design created by National Semiconductor using the 8390 Ethernet chip. National Semiconductor, for its part, had no qualms about the use of the design; the use of National Semiconductor chips made the proposal almost pure profit. However, since the design had been intended only as a proof-of-concept prototype, it implemented bare-minimum functionality: PIO was used instead of DMA, no buffering was provided and no provision was made for the use of a transceiver.\n\nThe original card, the NE1000 (8-bit ISA; announced as \"E-Net adapter\" in February 1987 for ) The \"NE\" prefix stood for \"Novell Ethernet\".\n\nThe NE2000, using the 16-bit ISA bus of the PC AT followed in 1988. It uses thin Ethernet; the second (\"B\") revision added an Attachment Unit Interface (AUI) port to support a transceiver, and later models NE1000T and NE2000T added built-in 10BASE-T support. \n\nWith the launch of the NE1000 / NE2000, Novell took two significant steps.\n\nThe first was a program under which other vendors were invited to manufacture the cards with no royalty as \"NE1000-compatible\" cards. Vendors were required to submit their cards to Novell for certification which focused on whether the standard Novell driver worked with the card. In a sense, this was a first step toward open-source hardware. Interested manufacturers were given a complete package of manufacturing documentation to allow them to start building NE1000/2000 compatible cards without having to do any design work. The primary intent of this program was to drive down the cost of network hardware to promote the adoption of PC networking.\n\nThe second innovation taken, primarily to deal with internal management issues, was to allow Novell's distributors to buy the cards directly from its manufacturer, Eagle, a contract manufacturing subsidiary of Anthem Technologies, the industrial distributor which provided the components for the NE1000/2000. Novell received a royalty on each card, but was no longer involved in scheduling and ordering manufacturing.\n\nIn order to remain competitive with Novell's bargain-price cards, 3Com and other vendors were forced to cut the pricing of their entry-level network cards, contributing greatly to the networking boom of the 1990s. To a lesser extent, it is arguable that the success of the NE1000/2000 cards helped to tip the scale of the \"LAN wars\" in favor of Ethernet (championed by 3Com) over token ring (championed by IBM), though its main impact was to significantly lower the cost of PC networks.\n\nIn 2003 National Semiconductor ceased manufacturing of the 8390 chip.\n\nMany other manufacturers copied the design labeling under their own brand, while still claiming NE1000/NE2000 compatibility. However, in reality this was not always the case. For instance, the Winbond 83C901 ignores the reset signal.\n\nBesides NetWare, driver support for these cards was (and still is) available for a variety of operating systems, including DOS, Microsoft Windows, UNIX, FreeBSD, QNX, and Linux. Note that Windows XP does not support non-Plug and Play versions and Windows Vista does not support the NE2000 at all. Windows 2000 appears to have a working driver.\n\n\n\n"}
{"id": "26968133", "url": "https://en.wikipedia.org/wiki?curid=26968133", "title": "Nanonetwork", "text": "Nanonetwork\n\nA nanonetwork or nanoscale network is a set of interconnected nanomachines (devices a few hundred nanometers or a few micrometers at most in size), which are able to perform only very simple tasks such as computing, data storing, sensing and actuation. Nanonetworks are expected to expand the capabilities of single nanomachines both in terms of complexity and range of operation by allowing them to coordinate, share and fuse information. Nanonetworks enable new applications of nanotechnology in the biomedical field, environmental research, military technology and industrial and consumer goods applications. Nanoscale communication is defined in IEEE P1906.1.\n\nClassical communication paradigms need to be revised for the nanoscale. The two main alternatives for communication in the nanoscale are based either on electromagnetic communication or on molecular communication.\n\nThis is defined as the transmission and reception of electromagnetic radiation from components based on novel nanomaterials. Recent advancements in carbon and molecular electronics have opened the door to a new generation of electronic nanoscale components such as nanobatteries, nanoscale energy harvesting systems, nano-memories, logical circuitry in the nanoscale and even nano-antennas. From a communication perspective, the unique properties observed in nanomaterials will decide on the specific bandwidths for emission of electromagnetic radiation, the time lag of the emission, or the magnitude of the emitted power for a given input energy, amongst others.\n\nFor the time being, two main alternatives for electromagnetic communication in the nanoscale have been envisioned. First, it has been experimentally demonstrated that is possible to receive and demodulate an electromagnetic wave by means of a nanoradio, i.e., an electromechanically resonating carbon nanotube which is able to decode an amplitude or frequency modulated wave. Second, graphene-based nano-antennas have been analyzed as potential electromagnetic radiators in the Terahertz band\n\nMolecular communication is defined as the transmission and reception of information by means of molecules. The different molecular communication techniques can be classified according to the type of molecule propagation in walkaway-based, flow-based or diffusion-based communication.\n\nIn walkway-based molecular communication, the molecules propagate through pre-defined pathways by using carrier substances, such as molecular motors. This type of molecular communication can also be achieved by using E. coli bacteria as chemotaxis.\n\nIn flow-based molecular communication, the molecules propagate through diffusion in a fluidic medium whose flow and turbulence are guided and predictable. The hormonal communication through blood streams inside the human body is an example of this type of propagation. The flow-based propagation can also be realized by using carrier entities whose motion can be constrained on the average along specific paths, despite showing a random component. A good example of this case is given by pheromonal long range molecular communications.\n\nIn diffusion-based molecular communication, the molecules propagate through spontaneous diffusion in a fluidic medium. In this case, the molecules can be subject solely to the laws of diffusion or can also be affected by non-predictable turbulence present in the fluidic medium. Pheromonal communication, when pheromones are released into a fluidic medium, such as air or water, is an example of diffusion-based architecture. Other examples of this kind of transport include calcium signaling among cells , as well as quorum sensing among bacteria.\n\nBased on the macroscopic theory of ideal (free) diffusion the impulse response of a unicast molecular communication channel was reported in a paper that identified that the impulse response of the ideal diffusion based molecular communication channel experiences temporal spreading. Such temporal spreading has a deep impact in the performance of the system e.g. in creating the intersymbol interference (ISI) at the receiving nanomachine. In order to detect the concentration-encoded molecular signal two detection methods named sampling-based detection (SD) and energy-based detection (ED) have been proposed. While the SD approach is based on the concentration amplitude of only one sample taken at a suitable time instant during the symbol duration, the ED approach is based on the total accumulated number of molecules received during the entire symbol duration. In order to reduce the impact of ISI a controlled pulse-width based molecular communication scheme has been analysed. The work presented in showed that it is possible to realize multilevel amplitude modulation based on ideal diffusion. A comprehensive study of pulse-based binary and sinus-based, concentration-encoded molecular communication system have also been investigated.\n\n\n"}
{"id": "54198736", "url": "https://en.wikipedia.org/wiki?curid=54198736", "title": "New Cinema History", "text": "New Cinema History\n\nNew Cinema History is a movement of media historians dedicated to rewriting film history as a social history of film cultures, instead of merely an art history of the moving image. The term was coined by Richard Maltby as \"a body of work that focuses on the circulation and consumption of film and examines cinema as a site of social and cultural exchange.\" Maltby's terminology partly aimed to institutionalize and expand to an international scale his prior decade-long collaboration with Melvyn Stokes researching Hollywood film audiences, and coincided with the formation of the HoMER Network: History of Moviegoing, Exhibition and Reception.\n"}
{"id": "23618578", "url": "https://en.wikipedia.org/wiki?curid=23618578", "title": "Nutrient pollution", "text": "Nutrient pollution\n\nNutrient pollution, a form of water pollution, refers to contamination by excessive inputs of nutrients. It is a primary cause of eutrophication of surface waters, in which excess nutrients, usually nitrogen or phosphorus, stimulate algal growth. Sources of nutrient pollution include surface runoff from farm fields and pastures, discharges from septic tanks and feedlots, and emissions from combustion. Excess nutrients have been summarized as potentially leading to:\n\nIn a 2011 United States Environmental Protection Agency (EPA) report, the agency's Science Advisory Board succinctly stated: “Excess reactive nitrogen compounds in the environment are associated with many large-scale environmental concerns, including eutrophication of surface waters, toxic algae blooms, hypoxia, acid rain, nitrogen saturation in forests, and global warming.”\n\nUse of synthetic fertilizers, burning of fossil fuels, and agricultural animal production, especially concentrated animal feeding operations (CAFO), have added large quantities of reactive nitrogen to the biosphere.\n\nPhosphorus pollution is caused by excessive use of fertilizers and manure, particularly when compounded by soil erosion. Phosphorus is also discharged by municipal sewage treatment plants and some industries.\n\nThe principal source(s) of nutrient pollution in an individual watershed depend on the prevailing land uses. The sources may be point sources, nonpoint sources, or both:\nNutrient pollution from some air pollution sources may occur independently of the local land uses, due to long-range transport of air pollutants from distant sources.\n\nAgricultural nonpoint source (NPS) pollution is the largest source of water quality impairments throughout the U.S., based on surveys by state environmental agencies. NPS pollution is not subject to discharge permits under the federal Clean Water Act (CWA). EPA and states have used grants, partnerships and demonstration projects to create incentives for farmers to adjust their practices and reduce surface runoff.\n\nMany point source dischargers in the U.S., while not necessarily the largest sources of nutrients in their respective watersheds, are required to comply with nutrient effluent limitations in their permits, which are issued through the National Pollutant Discharge Elimination System (NPDES), pursuant to the CWA. Some large municipal sewage treatment plants, such as the Blue Plains Advanced Wastewater Treatment Plant in Washington, D.C. have installed biological nutrient removal (BNR) systems to comply with regulatory requirements. Other municipalities have made adjustments to the operational practices of their existing secondary treatment systems to control nutrients.\n\nDischarges from large livestock facilities (CAFO) are also regulated by NPDES permits. Surface runoff from farm fields, the principal source of nutrients in many watersheds, is classified as NPS pollution and is not regulated by NPDES permits.\n\nA Total Maximum Daily Load (TMDL) is a regulatory plan that prescribes the maximum amount of a pollutant (including nutrients) that a body of water can receive while still meeting CWA water quality standards. Specifically, Section 303 of the Act requires each state to generate a TMDL report for each body of water impaired by pollutants. TMDL reports identify pollutant levels and strategies to accomplish pollutant reduction goals. EPA has described TMDLs as establishing a \"pollutant budget\" with allocations to each of the pollutant's sources. For many coastal water bodies, the main pollutant issue is excess nutrients, also termed \"nutrient over-enrichment.\"\n\nA TMDL can prescribe the minimum level of dissolved oxygen (DO) available in a body of water, which is directly related to nutrient levels. (\"See\" Aquatic Hypoxia.) In 2010, 18 percent of TMDLs nationwide were related to nutrient levels including organic enrichment/oxygen depletion, noxious plants, algal growth, and ammonia.\n\nTMDLs identify all point source and nonpoint source pollutants within a watershed. To implement TMDLs with point sources, wasteload allocations are incorporated into their NPDES permits. NPS discharges are generally in a voluntary compliance scenario.\n\nIn Long Island Sound, the TMDL development process enabled the Connecticut Department of Energy and Environmental Protection and the New York State Department of Environmental Conservation to incorporate a 58.5 percent nitrogen reduction target into a regulatory and legal framework.\n\nInnovative solutions have been conceived to deal with nutrient pollution in aquatic systems by altering or enhancing natural processes to shift nutrient effects away from detrimental ecological impacts. Nutrient remediation is a form of environmental remediation, but concerns only biologically active nutrients such as nitrogen and phosphorus. “Remediation” refers to the removal of pollution or contaminants, generally for the protection of human health. In environmental remediation nutrient removal technologies include biofiltration, which uses living material to capture and biologically degrade pollutants. Examples include green belts, riparian areas, natural and constructed wetlands, and treatment ponds. These areas most commonly capture anthropogenic discharges such as wastewater, stormwater runoff, or sewage treatment, for land reclamation after mining, refinery activity, or land development. Biofiltration utilizes biological assimilation to capture, absorb, and eventually incorporate the pollutants (including nutrients) into living tissue. Another form of nutrient removal is bioremediation, which uses microorganisms to remove pollutants. Bioremediation can occur on its own as natural attenuation or intrinsic bioremediation or can be encouraged by the addition of fertilizers, a strategy called biostimulation.\n\nNutrient bioextraction is bioremediation involving cultured plants and animals. Nutrient bioextraction or bioharvesting is the practice of farming and harvesting shellfish and seaweed for the purpose of removing nitrogen and other nutrients from natural water bodies. It has been suggested that nitrogen removal by oyster reefs could generate net benefits for sources facing nitrogen emission restrictions, similar to other nutrient trading scenarios. Specifically, if oysters maintain nitrogen levels in estuaries below thresholds that would lead to the imposition of emission limits, oysters effectively save the sources the compliance costs they otherwise would incur. Several studies have shown that oysters and mussels have the capacity to dramatically impact nitrogen levels in estuaries. Additionally, studies have demonstrated seaweed's potential to improve nitrogen levels.\n\nThe basic requirements for states to develop nutrient criteria and standards were mandated in the 1972 Clean Water Act. Implementing this water quality program has been a major scientific, technical and resource-intensive challenge for both EPA and the states, and development is continuing well into the 21st century.\n\nEPA published a wastewater management regulation in 1978 to begin to address the national nitrogen pollution problem, which had been increasing for decades. In 1998, the agency published a \"National Nutrient Strategy\" with a focus on developing nutrient criteria.\n\nBetween 2000 and 2010 EPA published federal-level nutrient criteria for rivers/streams, lakes/reservoirs, estuaries and wetlands; and related guidance. \"Ecoregional\" nutrient criteria for 14 ecoregions across the U.S. were included in these publications. While states may directly adopt the EPA-published criteria, in many cases the states need to modfiy the criteria to reflect site-specific conditions. In 2004, EPA stated its expectations for numeric criteria (as opposed to less-specific narrative criteria) for total nitrogen (TN), total phosphorus (TP), chlorophyll a(chl-a), and clarity, and established \"mutually-agreed upon plans\" for state criteria development. In 2007, the agency stated that progress among the states on developing nutrient criteria had been uneven. EPA reiterated its expectations for numeric criteria and promised its support for state efforts to develop their own criteria.\n\nIn 2008 EPA published a progress report on state efforts to develop nutrient standards. A majority of states had not developed numeric nutrient criteria for rivers and streams; lakes and reservoirs; wetlands and estuaries (for those states that have estuaries). In the same year, EPA also established a Nutrient Innovations Task Group (NITG), composed of state and EPA experts, to monitor and evaluate the progress of reducing nutrient pollution. In 2009 the NTIG issued a report, \"An Urgent Call to Action,\" expesssing concern that water quality continued to deteriorate nationwide due to increasing nutrient pollution, and recommending more vigorous development of nutrient standards by the states.\n\nIn 2011 EPA reiterated the need for states to fully develop their nutrient standards, noting that drinking water violations for nitrates had doubled in eight years, that half of all streams nationwide had medium to high levels of nitrogen and phosphorus, and harmful algal blooms were increasing. The agency set out a framework for states to develop priorities and watershed-level goals for reductions of nutrients.\n\nAfter the EPA had introduced watershed-based NPDES permitting in 2007, interest in nutrient removal and achieving regional TMDLs led to the development of nutrient trading schemes. Nutrient trading is a type of water quality trading, a market-based policy instrument used to improve or maintain water quality. Water quality trading arose around 2005 and is based on the fact that different pollution sources in a watershed can face very different costs to control the same pollutant. Water quality trading involves the voluntary exchange of pollution reduction credits from sources with low costs of pollution control to those with high costs of pollution control, and the same principles apply to nutrient water quality trading. The underlying principle is “polluter pays”, usually linked with a regulatory driver for participating is the trading program.\nA 2013 Forest Trends report summarized water quality trading programs and found three main types of funders: beneficiaries of watershed protection, polluters compensating for their impacts and ‘public good payers’ that may not directly benefit, but fund the pollution reduction credits on behalf of a government or NGO. As of 2013, payments were overwhelmingly initiated by public good payers like governments and NGOs.\n\nNutrient source apportionment is used to estimate the nutrient load from various sectors entering water bodies, following attenuation or treatment. Agriculture is typically the principal source of nitrogen in water bodies in Europe, whereas in many countries households and industries tend to be the dominant contributors of phosphorus. Where water quality is impacted by excess nutrients, load source apportionment models can support the proportional and pragmatic management of water resources by identifying the pollution sources. There are two broad approaches to load apportionment modelling, (i) load-orientated approaches which apportion origin based on in-stream monitoring data and (ii) source-orientated approaches where amounts of diffuse, or nonpoint source pollution, emissions are calculated using models typically based on export coefficients from catchments with similar characteristics. For example, the Source Load Apportionment Model (SLAM) takes the latter approach, estimating the relative contribution of sources of nitrogen and phosphorus to surface waters in Irish catchments without in-stream monitoring data by integrating information on point discharges (urban wastewater, industry and septic tank systems), diffuse sources (pasture, arable, forestry, etc.), and catchment data, including hydrogeological characteristics.\n\n\n"}
{"id": "9830917", "url": "https://en.wikipedia.org/wiki?curid=9830917", "title": "OAXAL", "text": "OAXAL\n\nOAXAL: Open Architecture for XML Authoring and Localization is an Organization for the Advancement of Structured Information Standards (OASIS) standards-based initiative to encourage the development of an open Standards approach to XML Authoring and Localization. OAXAL is an official OASIS Reference Architecture Technical Committee. \n\nOn 11 December 2009, the OASIS OAXAL TC approved the OAXAL v1.0 Reference Model as an official OASIS Committee Specification. \n\nThe Open Architecture for XML Authoring and Localization (OAXAL) represents a comprehensive, efficient, and cost-effective model regarding the authoring and translation aspects of XML publishing. OAXAL encompasses the following key Open Standards:\n\nThe full version of the OAXAL Reference Architecture is available online in wiki or PDF form.\n\n"}
{"id": "12755108", "url": "https://en.wikipedia.org/wiki?curid=12755108", "title": "Patterning by etching at the nanoscale", "text": "Patterning by etching at the nanoscale\n\nPatterning by Etching at the nanoscale (PENs) is a soft lithographic technique in which the bonds in the polydimethylsiloxane (PDMS) matrix are broken to controlably etch PDMS (i.e. dissolve) at a slow rate along the outside of a PDMS channel formed with a patterned PDMS stamp applied to a surface. The channel in the stamp can be enlarged in the order of tens of nanometers to several micrometres. Exposing a fresh area of a surface that can be reacted with.\n\nPDMS contains polymer chains of silicon-oxygen bonds, these bonds can be broken by fluoride containing species, in the same way that silicon wafers are prepared by etching with hydrofluoric acid, ammonium fluoride and related compounds. By placing a PDMS stamp that contains a channel that can be externally filled on to a surface, that surface can be functionalised in the area of the channel. By then running an etching solution through the channel, part of the PDMS will be removed. Exposing a fresh area of the surface. This can then be functionaliesd by appropriate chemistry. The width of feature produced is controlled by etchant and time.\n\nTo apply this technique for the production of small patterned features it is necessary that the surface can be reacted to passivate it in the area exposed by the channel, followed by etching and then reacted in away that will only occur in the newly exposed area.\n\nPerring M., Mitchell, M., Kenis P. J. A., Bowden N. B., \"Chem. Mat\" 2007 \"19\"(11), 2903\n"}
{"id": "58665925", "url": "https://en.wikipedia.org/wiki?curid=58665925", "title": "Photoalignment", "text": "Photoalignment\n\nPhotoalignment is a technique for orienting liquid crystals to desired alignment by exposure to polarized light and a photo reactive alignment chemical. It is usually performed by exposing the alignment chemical ('command surface') to polarized light with desired orientation which then aligns the liquid crystal cells or domains to the exposed orientation. The advantages of photoalignment technique over conventional methods are non-contact high quality alignment, reversible alignment and micro-patterning of liquid crystal phases.\n\nPhotoalignment was first demonstrated in 1988 by K. Ichimura on Quartz substrates with an azobenzene compound acting as the command surface. Since then several chemical combinations have been demonstrated for photoalignment and applied in production of liquid crystal devices like modern displays. \n\nTraditionally, liquid crystals are aligned by rubbing electrodes on polymer covered glass substrates. Rubbing techniques are widely used in mass production of liquid crystal displays and small laboratories as well. Due to the mechanical contact during rubbing, often debris are formed resulting in impurities and damaged products. Also, static charge is generated by rubbing which can damage sensitive and increasingly miniature electronics in displays.\n\nMany of these problems can be addressed by photoalignment.\n\n"}
{"id": "7338545", "url": "https://en.wikipedia.org/wiki?curid=7338545", "title": "Quincha", "text": "Quincha\n\nQuincha is a traditional construction system that uses, fundamentally, wood and cane or giant reed forming an earthquake-proof framework that is covered in mud and plaster.\n\nQuincha is a Spanish term widely known in Latin America, borrowed from Quechua \"qincha\" (\"kincha\" in Kichwa), which means \"fence, wall, enclosure, corral, animal pen\". Historically, this type of construction has been utilized in the Spanish and Portuguese colonies throughout the different regions of the Americas.\n\nEven though Spanish and Portuguese are closely related languages, in this case, the Portuguese equivalent is completely different: \"Pau-a-pique\".\n\n"}
{"id": "374999", "url": "https://en.wikipedia.org/wiki?curid=374999", "title": "Ray Crist", "text": "Ray Crist\n\nRay Crist (March 8, 1900 – July 23, 2005) was an American chemist who participated in the Manhattan Project. When he retired from teaching at the age of 104 in 2004, Crist is widely believed to have been America's oldest worker at the time.\n\nCrist was a graduate of the former Messiah School (1916), now known as Messiah College, Dickinson College (B.A., 1920) and Columbia University (Ph.D., 1925). Crist joined the faculty at Columbia University where he was a teacher and researcher from 1925 to 1941. He joined the Manhattan Project in 1941 and was among the leading scientists who developed the critical initial step of the separation of uranium isotopes. He was director of the Manhattan Project, Columbia University Group, 1945-6, after which he joined the Union Carbide Corporation in Charleston, West Virginia, first as Manager of the Coal Hydrogenation Plant, and then as Director of Research of the Olefins Division.\n\nBetween 1959 and 1963, he was Director of the Union Carbide Research Institute at Tarrytown, New York. Crist turned to volunteer teaching in 1963, following the death of his beloved wife, Dorothy Lenhart Crist, formerly of New Cumberland. As a voluntary educator, Crist pursued his mission of introducing today's students, especially non-science majors, to the impact of science and technology on culture and the environment.\n\nFrom 1963-1970, he taught at Dickinson College. There, he taught mostly upper level chemistry courses. However, his favorite course was on the history of science; it was a course for non-majors where he \"helped students to understand some of the basic laws of the natural world around them.\" In 1970, Crist was forced to resign due to the since repealed mandatory retirement age of 70.\n\nFrom 1971 until his retirement in 2004, he continued his academic career at Messiah College. He taught mostly environmental chemistry and was a major force behind the development of the Environmental Sciences program. During the final two decades of his work at Messiah, up to the age of 104, he worked on experiments involving adsorption of toxic metals by plant material and the use of living plants for purifying the environment (phytoremediation). The results of these experiments appeared in twenty-seven journal articles and were reported at ten international conferences. Messiah professor of the history of science Edward B. Davis believes that he may have been the oldest publishing research scientist in history.\n\nHis academic achievements and his overcoming the challenges of aging were recognized by numerous events and awards such as America's Outstanding Older Worker (2002), the PBS series \"The Living Century\" in the episode \"A Teacher and Student for Life\", and the editorial \"Phytoremediation's Centenarian\" (International Journal of Phytoremediation, 2002), as well as extensive additional press and television coverage both in the United States and abroad. His memoir - Listening to Nature: My Century in Science (Seaburn Publications) - appeared in 2005. Crist died in Carlisle, Pennsylvania on July 23, 2005, at the age of 105.\n"}
{"id": "1680216", "url": "https://en.wikipedia.org/wiki?curid=1680216", "title": "Register file", "text": "Register file\n\nA register file is an array of processor registers in a central processing unit (CPU). Modern integrated circuit-based register files are usually implemented by way of fast static RAMs with multiple ports. Such RAMs are distinguished by having dedicated read and write ports, whereas ordinary multiported SRAMs will usually read and write through the same ports.\n\nThe instruction set architecture of a CPU will almost always define a set of registers which are used to stage data between memory and the functional units on the chip. In simpler CPUs, these \"architectural registers\" correspond one-for-one to the entries in a physical register file (PRF) within the CPU. More complicated CPUs use register renaming, so that the mapping of which physical entry stores a particular architectural register changes dynamically during execution. The register file is part of the architecture and visible to the programmer, as opposed to the concept of transparent caches.\n\nRegister files may be clubbed together as register banks. Some processors have several register banks.\n\nARM processors use ARM register banks for fast interrupt request. x86 processors use context switching and fast interrupt for switching between instruction, decoder, GPRs and register files, if there is more than one, before the instruction is issued, but this is only existing on processors that support superscalar. However, context switching is a totally different mechanism to ARM's register bank within the registers.\n\nThe MODCOMP and the later 8051-compatible processors use bits in the program status word to select the currently active register bank.\n\nThe usual layout convention is that a simple array is read out vertically. That is, a single word line, which runs horizontally, causes a row of bit cells to put their data on bit lines, which run vertically. Sense amps, which convert low-swing read bitlines into full-swing logic levels, are usually at the bottom (by convention). Larger register files are then sometimes constructed by tiling mirrored and rotated simple arrays.\n\nRegister files have one word line per entry per port, one bit line per bit of width per read port, and two bit lines per bit of width per write port. Each bit cell also has a Vdd and Vss. Therefore, the wire pitch area increases as the square of the number of ports, and the transistor area increases linearly.\nAt some point, it may be smaller and/or faster to have multiple redundant register files, with smaller numbers of read ports, rather than a single register file with all the read ports. The MIPS R8000's integer unit, for example, had a 9 read 4 write port 32 entry 64-bit register file implemented in a 0.7 µm process, which could be seen when looking at the chip from arm's length.\n\nTwo popular approaches to dividing registers into multiple register files are the distributed register file configuration and the partitioned register file configuration.\n\nIn principle, any operation that could be done with a 64-bit-wide register file with many read and write ports could be done with a single 8-bit-wide register file with a single read port and a single write port. However, the bit-level parallelism of wide register files with many ports allows them to run much faster and thus, they can do operations in a single cycle that would take many cycles with fewer ports or a narrower bit width or both.\n\nThe width in bits of the register file is usually the number of bits in the processor word size.\nOccasionally it is slightly wider in order to attach \"extra\" bits to each register, such as the poison bit.\nIf the width of the data word is different than the width of an address—or in some cases, such as the 68000, even when they are the same width—the address registers are in a separate register file than the data registers.\n\n\nThe basic scheme for a bit cell:\nMany optimizations are possible:\n\nMost register files make no special provision to prevent multiple write ports from writing the same entry simultaneously. Instead, the instruction scheduling hardware ensures that only one instruction in any particular cycle writes a particular entry. If multiple instructions targeting the same register are issued, all but one have their write enables turned off.\n\nThe crossed inverters take some finite time to settle after a write operation, during which a read operation will either take longer or return garbage. It is common to have bypass multiplexers that bypass written data to the read ports when a simultaneous read and write to the same entry is commanded. These bypass multiplexers are often part of a larger bypass network that forwards results which have not yet been committed between functional units.\n\nThe register file is usually pitch-matched to the datapath that it serves. Pitch matching avoids having many busses passing over the datapath turn corners, which would use a lot of area. But since every unit must have the same bit pitch, every unit in the datapath ends up with the bit pitch forced by the widest unit, which can waste area in the other units. Register files, because they have two wires per bit per write port, and because all the bit lines must contact the silicon at every bit cell, can often set the pitch of a datapath.\n\nArea can sometimes be saved, on machines with multiple units in a datapath, by having two datapaths side-by-side, each of which has smaller bit pitch than a single datapath would have. This case usually forces multiple copies of a register file, one for each datapath.\n\nThe Alpha 21264 (EV6), for instance, was the first large micro-architecture to implement \"Shadow Register File Architecture\". It had two copies of the integer register file and two copies of floating point register that locate in its front end (future and scaled file, each contain 2 read and 2 write port), and took an extra cycle to propagate data between the two during context switch. The issue logic attempted to reduce the number of operations forwarding data between the two and greatly improved its integer performance and help reduce the impact of limited number of GPR in superscalar and speculative execution. The design was later adapted by SPARC, MIPS and some later x86 implementation.\n\nThe MIPS uses multiple register file as well, R8000 floating-point unit had two copies of the floating-point register file, each with four write and four read ports, and wrote both copies at the same time with context switch. However it does not support integer operation and integer register file still remain one. Later shadow register file was abandoned in newer design in favor of embedded market.\n\nThe SPARC uses \"Shadow Register File Architecture\" as well for its high end line, It had up to 4 copies of integer register files (future, retired, scaled, scratched, each contain 7 read 4 write port) and 2 copies of floating point register file. but unlike Alpha and x86, they are locate in back end as retire unit right after its Out of Order Unit and renaming register files and do not load instruction during instruction fetch and decoding stage and context switch is needless in this design.\n\nIBM uses the same mechanism as many major microprocessors, deeply merging the register file with the decoder but its register file are work independently by the decoder side and do not involve context switch, which is different from Alpha and x86. most of its register file not just serve for its dedicate decoder only but up to the thread level. For example, POWER8 has up to 8 instruction decoders, but up to 32 register files of 32 general purpose registers each (4 read and 4 write port), to facilitate simultaneous multithreading, which its instruction cannot be used cross any other register file (lack of context switch.).\n\nIn the x86 processor line, a typical pre-486 CPU did not have an individual register file, as all general purpose register were directly work with its decoder, and the x87 push stack was located within the floating-point unit itself. Starting with Pentium, a typical Pentium-compatible x86 processor is integrated with one copy of the single-port architectural register file containing 8 architectural registers, 8 control registers, 8 debug registers, 8 condition code registers, 8 unnamed based register, one instruction pointer, one flag register and 6 segment registers in one file.\n\nOne copy of 8 x87 FP push down stack by default, MMX register were virtually simulated from x87 stack and require x86 register to supplying MMX instruction and aliases to exist stack. On P6, the instruction independently can be stored and executed in parallel in early pipeline stages before decoding into micro-operations and renaming in out-of-order execution. Beginning with P6, all register files do not require additional cycle to propagate the data, register files like architectural and floating point are located between code buffer and decoders, called \"retire buffer\", Reorder buffer and OoOE and connected within the ring bus (16 bytes). The register file itself still remains one x86 register file and one x87 stack and both serve as retirement storing. Its x86 register file increased to dual ported to increase bandwidth for result storage. Registers like debug/condition code/control/unnamed/flag were stripped from the main register file and placed into individual files between the micro-op ROM and instruction sequencer. Only inaccessible registers like the segment register are now separated from the general-purpose register file (except the instruction pointer); they are now located between the scheduler and instruction allocator, in order to facilitate register renaming and out-of-order execution. The x87 stack was later merged with the floating-point register file after a 128-bit XMM register debuted in Pentium III, but the XMM register file is still located separately from x86 integer register files.\n\nLater P6 implementations (Pentium M, Yonah) introduced \"Shadow Register File Architecture\" that expanded to 2 copies of dual ported integer architectural register file and consist with context switch (between future&retirered file and scaled file using the same trick that used between integer and floating point). It was in order to solve the register bottleneck that exist in x86 architecture after micro op fusion is introduced, but it is still have 8 entries 32 bit architectural registers for total 32 bytes in capacity per file (segment register and instruction pointer remain within the file, though they are inaccessible by program) as speculative file. The second file is served as a scaled shadow register file, which without context switch the scaled file cannot store some instruction independently. Some instruction from SSE2/SSE3/SSSE3 require this feature for integer operation, for example instruction like PSHUFB, PMADDUBSW, PHSUBW, PHSUBD, PHSUBSW, PHADDW, PHADDD, PHADDSW would require loading EAX/EBX/ECX/EDX from both of register file, though it was uncommon for x86 processor to take use of another register file with same instruction; most of time the second file is served as a scale retirered file. The Pentium M architecture still remains one dual-ported FP register file (8 entries MM/XMM) shared with three decoder and FP register does not have shadow register file with it as its Shadow Register File Architecture did not including floating point function. Processor after P6, the architectural register file are external and locate in processor's backend after retired, opposite to internal register file that are locate in inner core for register renaming/reorder buffer. However, in Core 2 it is now within a unit called \"register alias table\" RAT, located with instruction allocator but have same size of register size as retirement. Core 2 increased the inner ring bus to 24 bytes (allow more than 3 instructions to be decoded) and extended its register file from dual ported (one read/one write) to quad ported (two read/two write), register still remain 8 entries in 32 bit and 32 bytes (not including 6 segment register and one instruction pointer as they are unable to be access in the file by any code/instruction) in total file size and expanded to 16 entries in x64 for total 128 bytes size per file. From Pentium M as its pipeline port and decoder increased, but they're located with allocator table instead of code buffer. Its FP XMM register file are also increase to quad ported (2 read/2 write), register still remain 8 entries in 32 bit and extended to 16 entries in x64 mode and number still remain 1 as its shadow register file architecture is not including floating point/SSE functions.\n\nIn later x86 implementations, like Nehalem and later processors, both integer and floating point registers are now incorporated into a unified octa-ported (six read and two write) general-purpose register file (8 + 8 in 32-bit and 16 + 16 in x64 per file), while the register file extended to 2 with enhanced \"Shadow Register File Architecture\" in favorite of executing hyper threading and each thread uses independent register files for its decoder. Later Sandy bridge and onward replaced shadow register table and architectural registers with much large and yet more advance physical register file before decoding to the reorder buffer. Randered that Sandy Bridge and onward no longer carry an architectural register.\n\nOn the Atom line was the modern simplified revision of P5. It includes single copies of register file share with thread and decoder. The register file is a dual-port design, 8/16 entries GPRS, 8/16 entries debug register and 8/16 entries condition code are integrated in the same file. However it has an eight-entries 64 bit shadow based register and an eight-entries 64 bit unnamed register that are now separated from main GPRs unlike the original P5 design and located after the execution unit, and the file of these registers is single-ported and not expose to instruction like scaled shadow register file found on Core/Core2 (shadow register file are made of architectural registers and Bonnell did not due to not have \"Shadow Register File Architecture\"), however the file can be use for renaming purpose due to lack of out of order execution found on Bonnell architecture. It also had one copy of XMM floating point register file per thread. The difference from Nehalem is Bonnell do not have a unified register file and has no dedicated register file for its hyper threading. Instead, Bonnell uses a separate rename register for its thread despite it is not out of order. Similar to Bonnell, Larrabee and Xeon Phi also each have only one general-purpose integer register file, but the Larrabee has up to 16 XMM register files (8 entries per file), and the Xeon Phi has up to 128 AVX-512 register files, each containing 32 512-bit ZMM registers for vector instruction storage, which can be as big as L2 cache.\n\nThere are some other of Intel's x86 lines that don't have a register file in their internal design, Geode GX and Vortex86 and many embedded processors that aren't Pentium-compatible or reverse-engineered early 80x86 processors. Therefore, most of them don't have a register file for their decoders, but their GPRs are used individually. Pentium 4, on the other hand, does not have a register file for its decoder, as its x86 GPRs didn't exist within its structure, due to the introduction of a physical unified renaming register file (similar to Sandy Bridge, but slightly different due to the inability of Pentium 4 to use the register before naming) for attempting to replace the architectural register file and skip the x86 decoding scheme. Instead it uses SSE for integer execution and storage before the ALU and after result, SSE2/SSE3/SSSE3 use the same mechanism as well for its integer operation.\n\nAMD's early design like K6 do not have a register file like Intel and do not support \"Shadow Register File Architecture\" as its lack of context switch and bypass inverter that are necessary require for a register file to function appropriately. Instead they use a separate GPRs that directly link to a rename register table for its OoOE CPU with a dedicated integer decoder and floating decoder. The mechanism is similar to Intel's pre-Pentium processor line. For example, the K6 processor has four int (one eight-entries temporary scratched register file + one eight-entries future register file + one eight-entries fetched register file + an eight-entries unnamed register file) and two FP rename register files (two eight-entries x87 ST file one goes fadd and one goes fmov) that directly link with its x86 EAX for integer renaming and XMM0 register for floating point renaming, but later Athlon included \"shadow register\" in its front end, it's scaled up to 40 entries unified register file for in order integer operation before decoded, the register file contain 8 entries scratch register + 16 future GPRs register file + 16 unnamed GPRs register file. In later AMD designs it abandons the shadow register design and favored to K6 architecture with individual GPRs direct link design. Like Phenom, it has three int register files and two SSE register files that are located in the physical register file directly linked with GPRs. However, it scales down to one integer + one floating-point on Bulldozer. Like early AMD designs, most of the x86 manufacturers like Cyrix, VIA, DM&P, and SIS used the same mechanism as well, resulting in a lack of integer performance without register renaming for their in-order CPU. Companies like Cyrix and AMD had to increase cache size in hope to reduce the bottleneck. AMD's SSE integer operation work in a different way than Core 2 and Pentium 4; it uses its separate renaming integer register to load the value directly before the decode stage. Though theoretically it will only need a shorter pipeline than Intel's SSE implementation, but generally the cost of branch prediction are much greater and higher missing rate than Intel, and it would have to take at least two cycles for its SSE instruction to be executed regardless of instruction wide, as early AMDs implementations could not execute both FP and Int in an SSE instruction set like Intel's implementation did.\n\nUnlike Alpha, Sparc, and MIPS that only allows one register file to load/fetch one operand at the time; it would require multiple register files to achieve superscale. The ARM processor on the other hand does not integrate multiple register files to load/fetch instructions. ARM GPRs have no special purpose to the instruction set (the ARM ISA does not require accumulator, index, and stack/base points. Registers do not have an accumulator and base/stack point can only be used in thumb mode). Any GPRs can propagate and store multiple instructions independently in smaller code size that is small enough to be able to fit in one register and its architectural register act as a table and shared with all decoder/instructions with simple bank switching between decoders. The major difference between ARM and other designs is that ARM allows to run on the same general-purpose register with quick bank switching without requiring additional register file in superscalar. Despite x86 sharing the same mechanism with ARM that its GPRs can store any data individually, x86 will confront data dependency if more than three non-related instructions are stored, as its GPRs per file are too small (eight in 32 bit mode and 16 in 64 bit, compared to ARM's 13 in 32 bit and 31 in 64 bit) for data, and it is impossible to have superscalar without multiple register files to feed to its decoder (x86 code is big and complex compared to ARM). Because most x86's front-ends have become much larger and much more power hungry than the ARM processor in order to be competitive (example: Pentium M & Core 2 Duo, Bay Trail). Some third-party x86 equivalent processors even became noncompetitive with ARM due to having no dedicated register file architecture. Particularly for AMD, Cyrix and VIA that cannot bring any reasonable performance without register renaming and out of order execution, which leave only Intel Atom to be the only in-order x86 processor core in the mobile competition. This was until the x86 Nehalem processor merged both of its integer and floating point register into one single file, and the introduction of a large physical register table and enhanced allocator table in its front-end before renaming in its out-of-order internal core.\n\nProcessors that perform register renaming can arrange for each functional unit to write to a subset of the physical register file. This arrangement can eliminate the need for multiple write ports per bit cell, for large savings in area. The resulting register file, effectively a stack of register files with single write ports, then benefits from replication and subsetting the read ports. At the limit, this technique would place a stack of 1-write, 2-read regfiles at the inputs to each functional unit. Since regfiles with a small number of ports are often dominated by transistor area, it is best not to push this technique to this limit, but it is useful all the same.\n\nThe SPARC ISA defines register windows, in which the 5-bit architectural names of the registers actually point into a window on a much larger register file, with hundreds of entries. Implementing multiported register files with hundreds of entries requires a large area. The register window slides by 16 registers when moved, so that each architectural register name can refer to only a small number of registers in the larger array, e.g. architectural register r20 can only refer to physical registers #20, #36, #52, #68, #84, #100, #116, if there are just seven windows in the physical file.\n\nTo save area, some SPARC implementations implement a 32-entry register file, in which each cell has seven \"bits\". Only one is read and writeable through the external ports, but the contents of the bits can be rotated. A rotation accomplishes in a single cycle a movement of the register window. Because most of the wires accomplishing the state movement are local, tremendous bandwidth is possible with little power.\n\nThis same technique is used in the R10000 register renaming mapping file, which stores a 6-bit virtual register number for each of the physical registers. In the renaming file, the renaming state is checkpointed whenever a branch is taken, so that when a branch is detected to be mispredicted, the old renaming state can be recovered in a single cycle. (See Register renaming.)\n\n"}
{"id": "9484892", "url": "https://en.wikipedia.org/wiki?curid=9484892", "title": "Remediation of contaminated sites with cement", "text": "Remediation of contaminated sites with cement\n\nRemediation of contaminated sites with cement, also called solidification/stabilization with cement (S/S with cement) is a common method for the safe environmental remediation of contaminated land with cement. The cement solidifies the contaminated soil and prevents pollutants from moving, such as rain causing leaching of pollutants into the groundwater or being carried into streams by rain or snowmelt. Developed in the 1950s, the technology is widely used today to treat industrial hazardous waste and contaminated material at brownfield sites i.e. abandoned or underutilized properties that are not being redeveloped because of fears that they may be contaminated with hazardous waste. S/S provides an economically viable means of treating contaminated sites. This technology treats and contains contaminated soil on site thereby reducing the need for landfills.\n\nThe Solidification/Stabilization method utilizes chemically reactive formulations that form stable solids that are non-hazardous or less-hazardous than the original materials.<ref name= \"http://www.sciencedirect.com\"> </ref> Solidification refers to the physical changes in the contaminated material when a certain binding agent is added. These changes include an increase in compressive strength, a decrease in permeability, and condensing of hazardous materials. Stabilization refers to the chemical changes between the stabilizing agent (binding agent) and the hazardous constituent. These changes should include a less soluble, less toxic constituent with hindered mobility.<ref name= \"http://www.frtr.gov/matrix2/section4/4-21.html\" > 4.20 solidification/stabilization. (n.d.).</ref> Common bonding agents include, but are not limited to, portland cement, lime, limestone, fly ash, slag, clay, and gypsum. Because of the vast types of hazardous materials, each agent should be tested on the site before a full-scale project is put under way. Most binding agents used are a blend of various single binding agents, depending on the hazardous material it will be used on. Portland cement has been used to treat more contaminated material than any other S/S binding agent because of its ability to bind free liquids, reduce permeability, encapsulate hazardous materials, and reduce the toxicity of certain contaminants. Lime can be used to adjust the pH of the substance of drive off water by using high heats of hydration. Limestone can also be used to adjust pH levels. Slag is often used for economical purposes because of its low cost.\n\nIn situ is a Latin phrase meaning “in the place”. When referred to chemistry or chemical reactions it means “in the reaction mixture”. In situ S/S, accounting for 20% of S/S projects from 1982-2005, is used to mix binding agents into the contaminated material while remaining on the site. Outside benefits of in situ mixing include conserving transportation costs, no landfill usage, and lesser risk to surrounding communities to be exposed to the hazardous materials while in transport. In-situ mixing treatments can also have the added benefit of improving soil conditions on the site.<ref name= \"http://www.cement.org/waste/wt_ss.asp\">Solidification/stabilization. (n.d.). Portland Cement Association</ref>\n\nEx situ is a Latin phrase meaning “off site”. In ex situ mixing, the hazardous materials are excavated, then machine-mixed with a certain bonding agent. This new, less-hazardous material is then deposited in a designated area, or reused on the initial site.<ref name=\"http://www.cpeo.org/techtree/ttdescript/solidsta.htm\">Physical solidification/stabilization. (2002, June). </ref> From 1982-2005, ex-situ S/S technologies have accounted for 80% of the 217 projects that were completed.\n\nProlonged use of the treated site and environmental and weather conditions may cause the materials used to stabilize the contaminants to erode, limiting the effect of the stabilization on the hazardous materials. Because of this, continuous monitoring of the site is required in order to ensure the contaminants have not re-assembled. Environmental factors such as freezing–thawing and wetting–drying were the focus of many studies dealing with the strength of S/S. It was found that freezing and thawing had the most adverse effects on the durability of the treated materials.\n\nWhen dealing with a radioactive contaminant, the solidification process may be interfered by various other types of hazardous waste. Most S/S processes have little or limited effects on organics and pesticides. Only by destroying these wastes by heating at very high temperatures will organics and pesticides be immobilized. Prior to performing the process to these types of sites, treatability studies need to be conducted in order to conclude if the solidification/stabilization process will be beneficial. These cement processes can result in major volume changes to the site, often up to double its original volume.\n\nThe governments of Canada and the province of Nova Scotia agreed in January 2007 to clean up the infamous Sydney Tar Ponds contaminated site using S/S technology. Cement was mixed into the contaminated waste to solidify and stabilize it. When the S/S process was complete, the solidified areas were covered with an engineered cap consisting of a clay, followed by layers of gravel and soil. Finally, the surface was planted with grass and other vegetation.<ref name=\"http://www.tarpondscleanup.ca/index.php?sid=2&cid=46\">Tar ponds solidification/stabilization. (n.d.).</ref>\n\nS/S technologies were used to treat a contaminated former wood treating facility in Port Newark, New Jersey. Approximately of soil was contaminated by wood with arsenic, chromium, and polycyclic aromatic hydrocarbons. 8% of Portland cement was used by wet weight of contaminated soil. Both in situ and ex situ processes were utilized to treat over 35,000 cubic meters of contaminated soil. The ex situ treated soil was mixed with Portland cement by a pugmill then placed on top of the in situ treated soil. This created an excellent base for pavement to be placed over the site. The proposed use for the treated site is a shipping container storage area.<ref name=\"http://www.pollutionengineering.com/PE/Home/Files/PDFs/PCA_S-S_Whitepaper.pdf\" > Wilk, C. M. (n.d.). Applying solidification/stabilization for sustainable redevelopment of contaminated property.</ref>\n\nAbandoned warehouses in Boston, Massachusetts are being renovated or torn down in order to build new structures. On this site is the former Central Power System, built in 1890. When built, this power station was considered to be the biggest electric generating plant in the world. This building has been abandoned since the 1950s and has not produced electricity in over 90 years. In the early 90s, renovations were started but were quickly shut down when free-floating oil was discovered in the sewers. Cleanup efforts were unsuccessful as they brought more oil onto the site. In 1999, cement-based S/S treatments were utilized to treat 2,100 cubic meters of contaminated materials. Lead and Petroleum contaminated soils were managed and treated successfully at this site.\n\nA complex of mixed residential, office, retail and commercial space is being built on of former industrial land in downtown Victoria that was contaminated by lead. 10 tonnes of soil was treated with cement, which was mixed into the soil on site simply by using an excavator bucket. The soil was thus rendered completely safe as was shown by tests on soil samples. \nA 10,000 square metre lot formerly occupied by the Brandon Scrap Metal and Iron Company was chosen by the City of Brandon for the site for its new fire and police headquarters. For many years, lead cell batteries were destroyed there and the lead was extracted, leaving the untreated cases on site. An environmental assessment showed that the site was contaminated due to the presence of heavy metals, lead and hydrocarbon pollution. Cement based S/S was employed to successfully remediate 600 tonnes of contaminated soil.\nA vacant 5-hectare property near the Welland Canal in St. Catharines had surface soil containing dangerous concentrations of lead and polycyclic aromatic hydrocarbons (PAHs) to a depth up to 0.4 m due the past operations of an adjacent skeet shooting range. About 26,000 tonnes of soil were treated using S/S to bring the contamination levels below the Ontario Land Disposal Regulations criteria.\n\n\n"}
{"id": "6871224", "url": "https://en.wikipedia.org/wiki?curid=6871224", "title": "Sales engineering", "text": "Sales engineering\n\nSales engineering is a hybrid of sales and engineering that exists in industrial and commercial markets. Buying decisions in these markets are made differently than those in many consumer contexts, being based more on technical information and rational analysis and less on style, fashion, or impulse. Therefore, selling in these markets cannot depend on consumer-type sales methods alone, and instead it relies heavily on technical information and problem-solving to convince buyers that they should spend money on the seller's products or services, in order to meet a business need (that is, to satisfy a business case). A sales engineer is thus both \"a salesperson that understands and can apply engineering\" and \"an engineer that understands how to sell engineered systems\". They thus not only sell but also provide advice and support. They provide this service to various internal or external customers, and they may work for a manufacturer (servicing its industrial-account/business-to-business customers), for a distributor (which in turn services the industrial-account/business-to-business customers), or for a third party such as an engineering consultancy or a systems integrator.\n\nSales Engineers are a critical sales team member in many companies and industries around the world. They are more than just technical experts in their respective industries. Highly successful sales engineers must build and maintain parallel expertise in \"soft skill\" disciplines such as business acumen, presentation skills, building customer relationships, developing an engagement strategy, and having a thorough understanding of the targeted industry. Many companies have difficulty finding people who possess these qualities, plus have extensive technical knowledge. \n\nThe essence of the sales engineering role can be called by various names. Which name is most apt can even depend on which industry it is used in. Some common job titles that involve the essence of sales engineering include sales engineer, solutions engineer, systems engineer, customer engineer, pre-sales consultant, technical account manager, applications engineer or field applications engineer. The term systems engineering has various shades of meaning, however, as it is often more or less synonymous with industrial engineering; but in any market economy, industrial engineers will often end up providing some sales engineering as a necessary portion of their work. Service technicians in industrial fields may also find that their work challenges them to provide some sales engineering, to whatever extent they are capable of providing it, because they interface with customers having problems with equipment (or lacking the right equipment) and seeking solutions (anywhere from diagnosis and repair, to identifying entirely different systems that could be used instead).\n\nThe purpose of the job is to help potential customers understand, compare, and contrast the solutions that are available for buying (the pre-sales role); to troubleshoot problems with their implementations—that is, to help ensure that the solutions work successfully once the buying decision has been made (the post-sales role); and to maximize sales for the sales engineer's employer by providing such help to the customers (the aspect of the job that puts the \"sales\" in the title sales engineer).\n\nIt is understood in the market, by both the sales engineer and his or her wary industrial client, that the sales portion of the sales engineering role inherently involves conflict of interest (COI), because it is always possible that the \"ideal\" solutions and troubleshooting could involve recommending a competitor's products or services, yet the sales engineer is under pressure not to steer the customer in that direction, and, conversely, to find reasons to steer them toward the employer's products. Thus, customers weigh the advice of sales engineers with a predisposition of caveat emptor. Nevertheless, sales engineers do usually provide real value to customers, which is why the role can endure despite the customers' perennial taking of a grain of salt. The customer's only motivation to participate in the encounter is to achieve return on investment (ROI) in one way or another. Toward that end, sales engineering increasingly relies on any information technology that can help quantify ROI even from the first encounter. This is summed up in the aphorism that \"at the end of the day, the customer just wants to know for sure that they will gain A dollars over the next B years (via reduced expenses or increased sales) if they pay C dollars up front for product D.\"\n\nAnother function of the sales engineer is to introduce modified, improved, and/or advanced technology to potential users who may have an application but who have not yet acquired knowledge of the material or technique in question. The sales engineer may conduct training sessions or demonstrations to accomplish this. The task of seeking out industries, firms, or business models that do not yet use a certain product (for example, a CAx system or a CRM system) and causing them to adopt a new approach using that product is what puts the \"applications\" in \"applications engineering\" or \"application development\" (not to be confused with another common sense of that term, which refers to software development and programming). The task is to seek out and develop new applications for the product, in order to increase sales. The customer's only motivation for adopting it is \"what it can do for me\", such as same-output-lower-costs, more-output-same-cost, etc. Thus, when things work out correctly, both firms profit from the application development.\n\nThis result also has broader economic implications, as it is a mechanism by which economic efficiency increases, productivity grows, and economic growth is encouraged. Inventors and R&D people create new tools and processes; but they do not disseminate into the business world (to do any economic good) without some amount of applications development, teaching (from exposing decision-makers via trade shows to providing workers with training), and sales.\n\nMany products and services purchased by large companies and institutions are highly complex. Examples include airliners, weapons systems, and IT systems (such as telecommunications, or databases and their dependent applications for purposes such as logistics or customer relationship management). Sales engineers advise customers on how best to use the products or services provided.\n\nThe sales process also may require some technical proof of concept or tech demo to be assured of the practicality of the solution. Sales engineers normally will ensure these efforts are successful.\n\nSales engineers also collaborate with the design, production, engineering, or R&D departments of their companies to determine how products and services could be made or modified to suit customers' needs. This aspect of sales engineering is important, because it is what allows the sales engineer to feel that they can maintain their personal integrity (ethically speaking) in the face of the inherent COI of the job (explained earlier). The sales engineer does not have to lie (ignore or negatively misrepresent the competitor's products or services) if they can reasonably tell the customer that their employer can tailor its solutions to the customer's particular requirements. Doing that may not be easy or cheap, which means that there is always a line to be walked to avoid overpromising-and/or-underdelivering.\n\nThe companies that employ sales engineers need to sell their products or services to generate income, but since engineers and scientists usually have substantially different personality traits than those required for sales work, there is a role for people with a combination of abilities. These individuals must have technical understanding of the complexities of what their company supplies together with sales skills. This combination of traits is not common.\n\nSales engineers may spend 20% to 70% of their time traveling, and they may work a flexible schedule due to the needs of the sales organization they support. Most sales engineers telecommute or spend a limited amount of time in the office. Skills with IT that help remote people communicate better, such as teleconferencing, videoconferencing, web conferencing, and telepresence (e.g., GoToMeeting, WebEx, Live Meeting, Fuze Meeting) are put to good use both on and off the road.\n\nSales engineers, like their sales representative counterparts, are hired based on their geographic location rather than their proximity to the corporate, or even regional, office. Working in another part of the country, or even outside the country, where the corporate offices are, a sales engineer may only make it to corporate headquarters once or twice each year.\n\nA key differentiator between sales engineers and other roles within the organization is that a sales engineer is usually compensated by salary plus commission, as most sales representatives are. This commission is usually paid out when the sales representative is paid. Far less common is the case where a sales engineer is compensated with a base salary plus bonus. The bonus can be based upon the revenue generated within an assigned territory, set up as a Management By Objective (MBO) bonus, or a combination of the two. In both cases a sales engineer will make a base salary that is proportionally higher than their sales representative counterparts, and significantly more than the traditional engineers in an organization.\n\nSales engineering is different from traditional sales roles. The systems and technology that a sales engineer sells are often complex and expensive. Traditional sales strategies including closing techniques, do not typically work and can even hurt a sale. As technology advances, so must the sales strategy of a sales engineer.\n\n"}
{"id": "6311700", "url": "https://en.wikipedia.org/wiki?curid=6311700", "title": "Salt spray test", "text": "Salt spray test\n\nThe salt spray (or salt fog) test is a standardized and popular corrosion test method, used to check corrosion resistance of materials and surface coatings. Usually, the materials to be tested are metallic (although stone, ceramics, and polymers may also be tested) and finished with a surface coating which is intended to provide a degree of corrosion protection to the underlying metal. \nSalt spray testing is an accelerated corrosion test that produces a corrosive attack to coated samples in order to evaluate (mostly comparatively) the suitability of the coating for use as a protective finish. The appearance of corrosion products (rust or other oxides) is evaluated after a pre-determined period of time. Test duration depends on the corrosion resistance of the coating; generally, the more corrosion resistant the coating is, the longer the period of testing before the appearance of corrosion/ rust.\nThe salt spray test is one of the most widespread and long established corrosion tests. ASTM B117 was the first internationally recognized salt spray standard, originally published in 1939. Other important relevant standards are ISO9227, JIS Z 2371 and ASTM G85.\n\nSalt spray testing is popular because it is relatively inexpensive, quick, well standardized, and reasonably repeatable. Although there may be a weak correlation between the duration in salt spray test and the expected life of a coating in certain coatings such as hot dip galvanized steel, this test has gained worldwide popularity due to low cost and quick results. Most Salt Spray Chambers today are being used NOT to predict the corrosion resistance of a coating, but to maintain coating processes such as pre-treatment and painting, electroplating, galvanizing, and the like, on a comparative basis. For example, pre-treated + painted components must pass 96 hours Neutral Salt Spray, to be accepted for production. Failure to meet this requirement implies instability in the chemical process of the pre-treatment, or the paint quality, which must be addressed immediately, so that the upcoming batches are of the desired quality. The longer the accelerated corrosion test, the longer the process remains out of control, and larger is the loss in the form of non-conforming batches.\nThe principle application of the salt spray test is therefore enabling quick comparisons to be made between actual and expected corrosion resistance. Most commonly, the time taken for oxides to appear on the samples under test is compared to expectations, to determine whether the test is passed or failed. For this reason the salt spray test is most often deployed in a quality audit role, where, for example, it can be used to check the effectiveness of a production process, such as the surface coating of a metallic part.\nThe salt spray test has little application in predicting how materials or surface coatings will resist corrosion in the real-world, because it does not create, replicate or accelerate real-world corrosive conditions. Cyclic corrosion testing is better suited to this.\n\nThe apparatus for testing consists of a closed testing cabinet/chamber, where a salt water (5% NaCl) solution is atomized by means of spray nozzle(s) using pressurized air. This produces a corrosive environment of dense salt water fog (also referred to as a mist or spray) in the chamber, so that test samples exposed to this environment are subjected to severely corrosive conditions. Chamber volumes vary from supplier to supplier. If there is a minimum volume required by a particular salt spray test standard, this will be clearly stated and should be complied with. There is a general historical consensus that larger chambers can provide a more homogeneous testing environment.\n\nVariations to the salt spray test solutions depend upon the materials to be tested. The most common test for steel based materials is the Neutral Salt Spray test (often abbreviated to NSS) which reflects the fact that this type of test solution is prepared to a neutral pH of 6.5 to 7.2. Results are represented generally as testing hours in NSS without appearance of corrosion products (e.g. 720 h in NSS according to ISO 9227). Synthetic seawater solutions are also commonly specified by some companies and standards. Other test solutions have other chemicals added including acetic acid (often abbreviated to ASS) and acetic acid with copper chloride (often abbreviated to CASS) each one chosen for the evaluation of decorative coatings, such as electroplated copper-nickel-chromium, electroplated copper-nickel or anodized aluminum. These acidified test solutions generally have a pH of 3.1 to 3.3\n\nSome sources do not recommend using ASS or CASS test cabinets interchangeably for NSS tests, due to the risk of cross-contamination, it is claimed that a thorough cleaning of the cabinet after CASS test is very difficult. ASTM does not address this issue, but ISO 9227 does not recommend it and if it is to be done, advocates a thorough cleaning.\n\nAlthough the majority of salt spray tests are continuous, i.e.; the samples under test are exposed to the continuous generation of salt fog for the entire duration of the test, a few do not require such exposure. Such tests are commonly referred to as modified salt spray tests. ASTM G85 is an example of a test standard which contains several modified salt spray tests which are variations to the basic salt spray test.\n\nASTM G85 is the most popular global test standard covering modified salt spray tests. There are five such tests altogether, referred to in ASTM G85 as annexes A1 through to A5. Many of these modified tests originally arose within particular industry sector, in order to address the need for a corrosion test capable of replicating the effects of naturally occurring corrosion and accelerate these effects.\nThis acceleration arises through the use of chemically altered salt spray solutions, often combined with other test climates and in most cases, the relatively rapid cycling of these test climates over time. Although popular in certain industries, modified salt spray testing has in many cases been superseded by Cyclic corrosion testing (CCT) \nThe type of environmental test chambers used for modified salt spray testing to ASTM G85 are generally similar to the chambers used for testing to ASTM B117, but will often have some additional features, such as an automatic climate cycling control system.\n\nASTM G85 annex A1 – Acetic Acid Salt Spray Test (non-cyclic) \nThis test can be used to determine the relative resistance to corrosion of decorative chromium plating on steel and zinc based die casting when exposed to an acetic acid salt spray climate at an elevated temperature. This test is also referred to as an ASS test.\nTest specimens are placed in an enclosed chamber and exposed to a continuous indirect spray of salt water solution, prepared in accordance with the requirements of the test standard and acidified (to pH 3.1 to 3.3) by the addition of acetic acid. This spray is set to fall-out on to the specimens at a rate of 1.0 to 2.0ml/80 cm²/hour, in a chamber temperature of +35C. This climate is maintained under constant steady state conditions. The test duration is variable.\n\nASTM G85 annex A2 – Acidified Salt Fog Test (cyclic).\n\nThis test can be used to test the relative resistance to corrosion of aluminium alloys when exposed to a changing climate of acetic acid salt spray, followed by air drying, followed by high humidity, all at an elevated temperature. This test is also referred to as a MASTMAASIS test.\nTest specimens are placed in an enclosed chamber, and exposed to a changing climate that comprises the following 3 part repeating cycle. 0.75 hours exposure to a continuous indirect spray of salt water solution, prepared in accordance with the requirements of the test standard and acidified (to pH 2.8 to 3.0) by the addition of acetic acid. This spray is set to fall-out on to the specimens at a rate of 1.0 to 2.0ml/80 cm²/hour. This is followed by 2.0 hours exposure to an air drying (purge) climate. This is followed by 3.25 hours exposure to a high humidity climate which gradually rises to between 65%RH and 95%RH. The entire test cycle is at a constant chamber temperature of +49C. The number of cycle repeats and therefore the test duration is variable.\n\nASTM G85 annex A3 – Seawater Acidified Test (cyclic)\n\nThis test can be used to test the relative resistance to corrosion of coated or uncoated aluminium alloys and other metals, when exposed to a changing climate of acidified synthetic seawater spray, followed by a high humidity, both at an elevated temperature. This test is also referred to as a SWAAT test.\nTest specimens are placed in an enclosed chamber, and exposed to a changing climate that comprises the following 2 part repeating cycle. 30 minutes exposure to a continuous indirect spray of synthetic seawater solution, prepared in accordance with the requirements of the test standard and acidified (to pH 2.8 to 3.0) by the addition of acetic acid. This spray is set to fall-out on to the specimens at a rate of 1.0 to 2.0ml/80 cm²/hour. This is followed by 90 minutes exposure to a high humidity climate of above 98%RH. The entire test cycle is at a constant chamber temperature of +49C (may be reduced to +24 to +35C for organically coated specimens). The number of cycle repeats and therefore the test duration is variable.\n\nASTM G85 annex A4 – SO2 Salt Spray Test (cyclic)\n\nThis test can be used to test the relative resistance to corrosion of product samples that are likely to encounter a combined SO2(sulfur dioxide)/salt spray/acid rain environment during their usual service life.\nTest specimens are placed in an enclosed chamber, and exposed to 1 of 2 possible changing climate cycles. In either case, the exposure to salt spray may be salt water spray or synthetic sea water prepared in accordance with the requirements of the test standard. The most appropriate test cycle and spray solutions are to be agreed between parties.\n\nThe first climate cycle comprises a continuous indirect spray of neutral (pH 6.5 to 7.2) salt water/synthetic seawater solution, which falls-out on to the specimens at a rate of 1.0 to 2.0ml/80 cm²/hour. During this spraying, the chamber is dosed with SO2 gas at a rate of 35 cm³/minute/m³ of chamber volume, for 1 hour in every 6 hours of spraying. The entire test cycle is at a constant chamber temperature of +35C. The number of cycle repeats and therefore the test duration is variable.\n\nThe second climate cycle comprises 0.5 hours of continuous indirect spray of neutral (pH 6.5 to 7.2) salt water/synthetic seawater solution, which falls-out on to the specimens at a rate of 1.0 to 2.0ml/80 cm²/hour. This is followed by 0.5 hours of dosing with SO2 gas at a rate of 35 cm³/minute/m³ of chamber volume. This is followed by 2.0 hours of high humidity soak. The entire test cycle is at a constant chamber temperature of +35C. The number of cycle repeats and therefore the test duration is variable.\nASTM G85 annex A5 - Dilute Electrolyte Salt Fog/Dry Test (cyclic)\n\nThis test can be used to test the relative resistance to corrosion paints on steel, when exposed to a changing climate of dilute salt spray at ambient temperature, followed by air drying at and elevated temperature. It is a popular test in the surface coatings industry, where it is also referred to as the PROHESION™ test.\nTest specimens are placed in an enclosed chamber, and exposed to a changing climate that comprises the following 2 part repeating cycle. 1.0 hour exposure to a continuous indirect spray of salt water solution, prepared in accordance with the requirements of the test standard and acidified (to pH 3.1 to 3.3) by the addition of acetic acid. This spray is set to fall-out on to the specimens at a rate of 1.0 to 2.0ml/80 cm²/hour, in an ambient chamber temperature (21 to 27C). This is followed by 1.0 hour exposure to an air drying (purge) climate, in a chamber temperature of +35C. The number of cycle repeats and therefore the test duration is variable.\n\nChamber construction, testing procedure and testing parameters are standardized under national and international standards, such as ASTM B 117 and ISO 9227. These standards describe the necessary information to carry out this test; testing parameters such as temperature, air pressure of the sprayed solution, preparation of the spraying solution, concentration, pH, etc. Daily checking of testing parameters is necessary to show compliance with the standards, so records shall be maintained accordingly. ASTM B117 and ISO 9227 are widely used as reference standards. Testing cabinets are manufactured according to the specified requirements here. \n\nHowever, these testing standards neither provide information of testing periods for the coatings to be evaluated, nor the appearance of corrosion products in form of salts. Requirements are agreed between customer and manufacturer. In the automotive industry requirements are specified under material specifications. Different coatings have different behavior in salt spray test and consequently, test duration will differ from one type of coating to another. For example, a typical electroplated zinc and yellow passivated steel part lasts 96 hours in salt spray test without white rust. Electroplated zinc-nickel steel parts can last more than 720 hours in NSS test without red rust (or 48 hours in CASS test without red rust) Requirements are established in test duration (hours) and coatings shall comply with minimum testing periods.\n\nArtificial seawater which is sometimes used for Salt Spray Testing can be found at ASTM International. The standard for Artificial Seawater is ASTM D1141-98 which is the standard practice for the preparation of substitute ocean water.\n\nTypical coatings that can be evaluated with this method are:\n\n\nHot-dip galvanized surfaces are not generally tested in a salt spray test (see ISO 1461 or ISO 10684). Hot-dip galvanizing produces zinc carbonates when exposed to a natural environment, thus protecting the coating metal and reducing the corrosion rate. The zinc carbonates are not produced when a hot-dip galvanized specimen is exposed to a salt spray fog, therefore this testing method does not give an accurate measurement of corrosion protection. ISO 9223 gives the guidelines for proper measurement of corrosion resistance for hot-dip galvanized specimens.\n\nPainted surfaces with an underlying hot-dip galvanized coating can be tested according to this method. See ISO 12944-6.\n\nTesting periods range from a few hours (e.g. 8 or 24 hours of phosphated steel) to more than a month (e.g. 720 hours of zinc-nickel coatings, 1000 hours of certain zinc flake coatings).\n\n\n\n"}
{"id": "1697664", "url": "https://en.wikipedia.org/wiki?curid=1697664", "title": "Skilcraft", "text": "Skilcraft\n\nSkilcraft, often stylized as SKILCRAFT, is the registered trade name of the National Industries for the Blind (NIB). Products made by Skilcraft are created largely by visually impaired or severely disabled individuals. Products bearing the Skilcraft brand are commonly used in United States federal government institutions, including the United States Postal Service. They are also commonly sold in U.S. military base exchanges.\n\nIn 1938, President Roosevelt signed the Wagner-O'Day Act which directed the government to purchase products manufactured by blind Americans. Robert Irwin, who was the executive director of the American Foundation for the Blind, and Peter Salmon who was the assistant director for the Industrial Home for the Blind promoted the bill in Washington, D.C. This act gave non-profit organizations for the blind the ability to sell to the federal government. It also provided the creation of a committee, known as the Committee on Purchases of Blind-Made Products, which had providentially appointed members representing various federal departments and private citizens.\n\nThe National Industries for the Blind (NIB) incorporated as a nonprofit organization on August 10, 1938, and was created as a result of the Wagner-O'Day Act. NIB helps coordinate orders and allocate orders to different workshops for the blind. The first president of NIB was Chester C. Kleber, who held that position until 1960.\n\nAfter World War II, the Committee on Purchases of Blind-Made Products decided that NIB should begin to sell in commercial markets. In 1952, NIB created the brand name, Skilcraft, which created a uniform label and emphasized the quality of the product. The brand name also allowed the company to be better able to expand into the commercial marketplace.\n\nBy 1960, NIB had 62 affiliated workshops. In 1970, black blind workers went on strike at a Skilcraft plant in Greensboro, North Carolina, citing poor working conditions, discrimination and low wages.\n\nIn 1971, Senator Jacob Javits introduced legislation extending the act to \"individuals with other severe disabilities.\" The Javits-Wagner-O'Day Act (JWOD) also gave workshops for the blind a \"five-year priority on service contracts.\" JWOD also created a committee, the Committee for Purchase from People who are Blind or Severely Disabled.The committee would be made of 15 members appointed by the president, with each individual representing different federal agencies. The committee also had a budget, as described by JWOD.\n\nThe Committee for Purchase designated NIB and National Industries for the Severely Handicapped (NISH) to be the two central, non-profit organizations which coordinate government acquisitions from hundreds of independent organizations for the blind and severely handicapped.\n\nBy 1998, there were 85 agencies who were associated with NIB.\n\nThe first products manufactured under the program were mops and brooms for cleaning government offices. The federal government awarded around $220,000 in contracts to 36 workshops to manufacture the mops and brooms. By 1939, NIB expanded to sell pillowcases, sanitary swabs, and fiber door mats.\n\nLater, pens and office supplies were introduced. NIB would supply the government with 70 million ballpoint pens a year by 1969. These pens have certain requirements, which include the ability to \"write continuously for a mile and in temperatures up to 160 degrees and down to 40 degrees below zero.\" The ballpoint pen contract helped create jobs for 125 new workers with disabilities. By 2014, sales of the pens reached around five million dollars, with 60% of purchases from the U.S. military.\n\nIn 1990, there were 400 different items added to the list of items manufactured. In 2015, Skilcraft introduced a new line of products which included screwdrivers and socket wrenches.\n\nToday, the Skilcraft name encompasses more than 3,500 products including office supplies, janitorial equipment, uniforms, and hospital supplies. Skilcraft also provides services, such as call centers, on a contract basis to government agencies.\n\nNearly 70% of blind individuals in the United States who are of working age are unemployed. Being able to work allows the blind to be both self-supporting and able to support others. The Skilcraft trade helps employ more than 5,000 blind Americans working for local agencies in 44 states. Affiliates who make the Skilcraft brand, such as Lighthouse for the Blind are able to pay their employees between $8 and $12 an hour, provide health insurance and 401(k) options.\n\n\n"}
{"id": "23164292", "url": "https://en.wikipedia.org/wiki?curid=23164292", "title": "Smoke &amp; Mirrors E-zine", "text": "Smoke &amp; Mirrors E-zine\n\nSmoke & Mirrors E-zine is a monthly, international, electronic magazine for professional and semi-professional magicians and mentalists. It was originally meant to serve a small group of magicians in New York City about upcoming events. It has subsequently become more international in scope.\n\nSmoke & Mirrors is the Internet's largest monthly magic e-zine in terms of readership. It is also the Net's oldest, monthly magic e-zine. Subscription is free.\n\nSmoke & Mirrors' mission is to provide an accurate and timely source of pertinent information for professional and semi-professional magicians and mentalists. Smoke & Mirrors also offers opportunities for magicians who wish to publish their articles and reviews for the benefit of the greater international magic community.\n\nSmoke & Mirrors lists all major magic performances, lectures and conventions throughout the world. The e-zine is approximately 200KB of information taking up approximately 180-200 pages if printed out. It provides reviews and articles on important magic topics and serves to remind magicians and mentalists as to holidays pertinent to the profession.\n\nContributing editors for the e-zine include: \n\nEditors Emeriti:\n\nSmoke & Mirrors is published by Kismet Magic Publishing (New York City.) The e-zine in currently in its 11th year of continual publication. As of January 2009, the e-zine is published on or around the beginning of every month and is sent directly to subscribers' email accounts.\n\nAngelo Stagnaro is the current editor-in-chief and publisher. He has been so since its inception in 1998.\n\nCurrent readership exceeds 4500 readers from 67 countries.\n"}
{"id": "9121299", "url": "https://en.wikipedia.org/wiki?curid=9121299", "title": "Space Imaging", "text": "Space Imaging\n\nSpace imaging may refers to:\n\n\n"}
{"id": "2377150", "url": "https://en.wikipedia.org/wiki?curid=2377150", "title": "Sunita Williams", "text": "Sunita Williams\n\nSunita Pandya Lyn Williams (born September 19, 1965) is an American astronaut and United States Navy officer of Indo-Slovenian descent. She formerly held the records for total spacewalks by a woman (seven) and most spacewalk time for a woman (50 hours, 40 minutes). Williams was assigned to the International Space Station as a member of Expedition 14 and Expedition 15. In 2012, she served as a flight engineer on Expedition 32 and then commander of Expedition 33.\n\nSunita Williams was born in Euclid, Ohio, to Indian American neuroanatomist Deepak Pandya and Slovene American Ursuline Bonnie (Zalokar) Pandya, who reside in Falmouth, Massachusetts. She is the youngest of three children. Her brother Jay Thomas is four years older and her sister Dina Annadj is \nthree years older. Williams' paternal family is from Jhulasan, Mehsana district in Gujarat, India, while her maternal great-grandmother Mary Bohinc (originally Marija Bohinjec), born in Leše, Slovenia, immigrated to America as an eleven-year-old with her mother, 1891 Slovene emigrant Ursula (Strajhar) Bohinac.\n\nWilliams graduated from Needham High School in Needham, Massachusetts, in 1983. She received a Bachelor of Science degree in physical science from the United States Naval Academy in 1987, and a Master of Science degree in Engineering Management from Florida Institute of Technology in 1995.\n\nWilliams was commissioned an ensign in the United States Navy in May 1987. After a six-month temporary assignment at the Naval Coastal System Command, she was designated a Basic Diving Officer. She next reported to the Naval Air Training Command, where she was designated a Naval Aviator in July 1989. She received initial H-46 Sea Knight training in Helicopter Combat Support Squadron 3 (HC-3), and was then assigned to Helicopter Combat Support Squadron 8 (HC-8) in Norfolk, Virginia, with which she made overseas deployments to the Mediterranean, Red Sea and the Persian Gulf for Operation Desert Shield and Operation Provide Comfort. In September 1992, she was the Officer-in-Charge of an H-46 detachment sent to Miami, Florida, for Hurricane Andrew relief operations aboard . In January 1993, Williams began training at the U.S. Naval Test Pilot School. She graduated in December, and was assigned to the Rotary Wing Aircraft Test Directorate as an H-46 Project Officer and V-22 chase pilot in the T-2. Later, she was assigned as the squadron Safety Officer and flew test flights in the SH-60B/F, UH-1, AH-1W, SH-2, VH-3, H-46, CH-53, and the H-57. In December 1995, she went back to the Naval Test Pilot School as an instructor in the Rotary Wing Department and as the school's Safety Officer. There she flew the UH-60, OH-6, and the OH-58. She was then assigned to as the Aircraft Handler and the Assistant Air Boss. Williams was deployed on \"Saipan\" in June 1998 when she was selected by NASA for the astronaut program. She has logged more than 3,000 flight hours in more than 30 aircraft types.\n\nSunita Williams began her Astronaut Candidate training at the Johnson Space Center in August 1998.Following are the space mission undertaken by Sunita Williams\n\nWilliams was launched to the International Space Station (ISS) with STS-116, aboard the Space Shuttle \"Discovery\", on December 9, 2006, to join the Expedition 14 crew. In April 2007, the Russian members of the crew rotated, changing to Expedition .\n\nAfter launching aboard the Shuttle \"Discovery\", Williams arranged to donate her pony tail to Locks of Love. Fellow astronaut Joan Higginbotham cut her hair aboard the International Space Station and the ponytail was brought back to Earth by the STS-116 crew. Williams performed her first extra-vehicular activity on the eighth day of the STS-116 mission. On January 31, February 4, and February 9, 2007, she completed three spacewalks from the ISS with Michael López-Alegría. During one of these walks, a camera became untethered, probably because the attaching device failed, and floated off to space before Williams could react.\n\nOn the third spacewalk, Williams was outside the station for 6 hours and 40 minutes to complete three spacewalks in nine days. She has logged 29 hours and 17 minutes in four spacewalks, eclipsing the record held by Kathryn C. Thornton for most spacewalk time by a woman. On December 18, 2007, during the fourth spacewalk of Expedition 16, Peggy Whitson surpassed Williams, with a cumulative EVA time of 32 hours, 36 minutes. In early March 2007, she received a tube of wasabi in a Progress spacecraft resupply mission in response to her request for more spicy food. When she opened the tube, which was packaged at one atmospheric pressure, the gel-like paste was forced out in the lower pressure of the ISS. In the free-fall environment, the spicy geyser was difficult to contain.\n\nOn April 26, 2007, NASA decided to bring Williams back to Earth on the STS-117 mission aboard \"Atlantis\". She did not break the U.S. single spaceflight record that was recently broken by former crew member Commander Michael López-Alegría, but did break the record for longest single spaceflight by a woman. Williams served as a mission specialist and returned to Earth on June 22, 2007, at the end of the STS-117 mission. Poor weather at the Kennedy Space Center in Cape Canaveral forced mission managers to skip three landing attempts there over previous 24 hours. They then diverted \"Atlantis\" to Edwards Air Force Base in California, where the shuttle touched down at 3:49 p.m. EDT, returning Williams home after a record 192-day stay in space.\n\nOn April 16, 2007, she ran the first marathon by any person in space. Williams was listed as an entrant for the 2007 Boston Marathon, and completed the distance in four hours and 24 minutes. The other crew members cheered her on and gave her oranges during the race. Williams' sister, Dina Pandya, and fellow astronaut Karen L. Nyberg ran the marathon on Earth, and Williams received updates on their progress from Mission Control. In 2008, Williams participated in the Boston Marathon again, this time on Earth.\n\nWilliams launched from the Baikonur Cosmodrome on July 15, 2012, as part of Expedition 32/33. Her Russian spacecraft Soyuz TMA-05M docked with the ISS for a four-month stay at the orbiting outpost on July 17, 2012. The docking of the Soyuz occurred at 4:51 GMT as the ISS flew over Kazakhstan at an altitude of 252 miles. The hatchway between the Soyuz spacecraft and the ISS was opened at 7:23 GMT and Williams floated into the ISS to begin her duties as a member of the Expedition 32 crew. She was accompanied on the Soyuz TMA-05M spacecraft by Japan Aerospace Exploration Agency (JAXA) astronaut Aki Hoshide and Russian cosmonaut Yuri Malenchenko. Williams served as commander of the ISS during her stay onboard ISS Expedition 33, succeeding Gennady Padalka. She became the commander of the International Space Station on September 17, 2012, being only the second woman to achieve the feat. Also in September 2012, she became the first person to do a triathlon in space, which coincided with the Nautica Malibu Triathlon held in Southern California. She used the International Space Station's own treadmill and stationary bike, and for the swimming portion of the race, she used the Advanced Resistive Exercise Device (ARED) to do weightlifting and resistance exercises that approximate swimming in microgravity. After 'swimming' half a mile (0.8 km), 'biking' 18 miles (29 km), and 'running' 4 miles (6.4 km), Williams finished with a time of one hour, 48 minutes and 33 seconds, as she reported.\n\nShe returned to earth with fellow astronauts Flight Engineers Yuri Malenchenko and Aki Hoshide on November 19, 2012, touching down in the town of Arkalyk, Kazakhstan. Helicopters joined the search-and-recovery crew to assist them, as their capsule parachuted down some from the planned touchdown site due to a procedural delay.\n\n, Williams has made seven spacewalks totaling 50 hours and 40 minutes, putting Williams in No. 9 on the list of most experienced spacewalkers. On August 30, 2012, Williams and JAXA astronaut Hoshide ventured outside the ISS to conduct US EVA-18. They removed and replaced the failing Main Bus Switching Unit-1 (MBSU-1), and installed a thermal cover onto Pressurized Mating Adapter-2 (PMA-2).\n\nIn July 2015, NASA announced Williams as one of the first astronauts for U.S. Commercial spaceflights. Subsequently, she has started working with Boeing and SpaceX to train in their commercial crew vehicles, along with other chosen astronauts. In August 2018 she was assigned to the first mission flight, CTS-1, to the International Space Station of the Boeing CST-100 Starliner.\n\nShe was a member of Society of Experimental Test Pilots.\n\nWilliams is married to Michael J. Williams, a Federal police officer in Oregon. The two have been married for more than 20 years, and both flew helicopters in the early days of their careers. She had a pet Jack Russell Terrier named Gorby (deceased) who was featured with her on the \"Dog Whisperer\" television show on the National Geographic Channel on November 12, 2010. In 2012, Williams expressed a desire to adopt a girl from Ahmedabad.\n\nIn September 2007, Williams visited India. She went to the Sabarmati Ashram and her ancestral village Jhulasan in Gujarat. She was awarded the Sardar Vallabhbhai Patel Vishwa Pratibha Award by the World Gujarati Society, the first person of Indian descent who was not an Indian citizen to be presented the award. On October 4, 2007, Williams spoke at the American Embassy School, and then met Manmohan Singh, the then Prime Minister of India.\n\nIn October 2014, Williams visited Slovenia. During her stay, amongst other things, she paid a visit to the Astronomical Society Vega in Ljubljana.\n\nOn June 7, 2017, The Needham School Committee voted unanimously to name the town's new elementary school the Sunita L. Williams Elementary School.\n\n\n\n"}
{"id": "310342", "url": "https://en.wikipedia.org/wiki?curid=310342", "title": "TOPS", "text": "TOPS\n\nTotal Operations Processing System, or TOPS, is a computer system for managing the locomotives and rolling stock (railroad cars) owned by and/or operated on a rail system. It was originally developed by the American-based Southern Pacific Railroad and was widely sold; it is best known in Britain for its use by British Rail (BR) and its successors.\n\nThe Southern Pacific Railroad was ahead of the pack in its embracing of technology. In the early 1960s, it developed a computer system called 'Total Operations Processing System', or 'TOPS'. The purpose was to take all the paperwork associated with a locomotive or rolling stock - its maintenance history, its allocation to division and depot and duty, its status, its location, and much more - and keep it in computer form, constantly updated by terminals at every maintenance facility. On paper, this information was difficult to keep track of, difficult to keep up to date, and difficult to query; requiring many telephone calls. Computerizing this information enabled a railroad to keep better track of its assets, and to use them better.\n\nIn order to offset the development costs of the system, Southern Pacific sold it to other railroads. A number of American railroads took to the system, as did many others around the world.\n\nIn the mid to late 1960s, British Rail (BR) was searching around for ways to increase efficiency, and came across the TOPS system in a 1968 presentation by an IBM US Transportation Industry Representative, who shortly after, formed IBM World Trade Corp's Transportation Industry Centre in Brussels (E. Wrathall). They purchased the system (along with source code, as was typical for such a large mainframe-based system in those days) and implemented it, assisted by Southern Pacific data processing experts. At the time, the British Government operated a 'Buy British' policy for the nationalised industries, and the purchase of an IBM System/360 mainframe to operate TOPS had to be approved by the Cabinet of Prime Minister Edward Heath.\n\nThe adoption of the TOPS system made for some changes in the way the railway system in Britain worked. Hitherto, locomotives were numbered in three different series. Steam locomotives carried unadorned numbers up to five digits long. Diesel locomotives carried one to four-digit numbers prefixed with a letter 'D', and electric locomotives with a letter 'E'. Thus, up to three locomotives could carry the same number. TOPS could not handle this, and it also required similar locomotives to be numbered in a consecutive series in terms of classification, in order that they might be treated together as a group.\n\nSequentiality was all that was required, but with the requirement to renumber, it was decided to adopt a logical system for classification, and the five- or six-digit TOPS number was divided into two parts. No class of locomotive or multiple unit numbered over 1000 examples, so the last three digits were used for the individual number between 001 and 999 (Although Class 43 goes down to 000, it being the HST Prototype power Cars) in that class. The first two or three digits were used to denote the class of locomotive or multiple unit. The numbers were often written in two space separated groups, such as \"47 401\" to highlight that division, but the TOPS system actually stored and displayed them without the space: \"47401\". Sub-classifications were indicated in the TOPS system with a slash and a subclass number, e.g. \"47/4\". It was convention, though not enforced within the TOPS system, that subclass numbers were boundaries in the locomotive numbering system, such that class \"47/4\" started with number \"47 401\". If there were more than 99 numbers in a subclass, the number series extended to the next value of the third digit; thus, since there were more than 200 locomotives in class \"47/4\", subclasses \"47/5\" and \"47/6\" did not exist, and the next valid subclass by convention was \"47/7\" starting with \"47 701\". However, in some cases, the sequences do not match, e.g. 158/0 numbers start at 158 701.\n\nLocomotives are assigned classes 01–98: diesel locomotives 01–79 (originally 01–69), AC electric locomotives 80–96, departmental locos (those not in revenue-earning use) 97, and steam locomotives 98. DC electric locomotives were originally allocated classes 70–79 but this was modified in 2011 (see British Rail locomotive and multiple unit numbering and classification); the sole relic of this is Class 73 which continues unrenumbered, probably because it can be considered equally a diesel locomotive as it is a DC electric. One oddity was the inclusion of British Rail's shipping fleet in the system as Class 99. Diesel multiple units (DMUs) with mechanical or hydraulic transmission are classified 100–199, with electric transmission 200–299. Electric multiple units (EMUs) are given the subsequent classes; 300–399 are overhead AC units (including AC/DC dual-voltage units, and new DC only units with pantogaph wells allowing for conversion to AC), while Southern Region DC third rail EMUs are 400–499, other DC EMUs 500–599. Selected numbers in the 900 series have been used for departmental multiple units, mostly converted from former passenger units. \n\nThere are also a number of electric and bi-mode (diesel-electric) units in service, under construction or being planned that use the 700 and 800 series, which include:\n\nCoaching stock and individual multiple unit cars are allocated five-digit numbers; since the early 1980s, it has been forbidden for them to have the same numbers as locomotives, but before then duplication was possible because they carried a prefix letter, which was considered part of the number. More recent EMU deliveries have six-figure coach numbers.\n\nTOPS has grown very out of date in recent decades. It is a text-terminal, mainframe-driven system; which is regarded as not very user-friendly, and hard to use compared with contemporary computer user-interfaces. In addition, it is written in its own programming language, TOPSTRAN (not strictly speaking a separate language but a set of IBM Assembler macros), and it is increasingly hard to find and train developers to maintain it. The division of British Rail and privatisation has also hurt TOPS, because it was never really designed for that; some freight operating companies do not keep information as up to date as they should.\n\nAttempts have been made to 'skin' the system with a more user-friendly interface, called TOPS 2000; in addition, there are other parallel systems now, such as TRUST, Genius and the Mobile Consisting Application, but none has yet fully supplanted the TOPS system.\n\nThis is a typical report that a TOPS clerk could generate. The train in question is a 25 wagon freight train travelling from Over & Wharton, near Winsford, to Reading West Junction, Berkshire.\n"}
{"id": "3050114", "url": "https://en.wikipedia.org/wiki?curid=3050114", "title": "Targeting (warfare)", "text": "Targeting (warfare)\n\nTargeting is the process of selecting objects or installations to be attacked, taken, or destroyed in warfare. Targeting systematically analyzes and prioritizes targets and matches appropriate lethal and nonlethal actions to those targets to create specific desired effects that achieve the joint force commander’s (JFC’s) objectives, accounting for operational requirements, capabilities, and the results of previous assessments. The emphasis of targeting is on identifying resources (targets) the enemy can least afford to lose or that provide him with the greatest advantage (high-value target [HVT]), then further identifying the subset of those targets which\nmust be acquired and engaged to achieve friendly success (high-payoff target [HPT]). Targeting links\nthe desired effects to actions and tasks.\n\nThe targeting process can be generally grouped into two categories: deliberate and dynamic. Deliberate targeting prosecutes anticipated or known targets within a given operational area and timeframe, and normally supports the joint force’s future plans effort, which is overseen by the plans directorate of a joint staff (J-5). (Normally, the future operations directorate focuses on 24 hours up to 72 hours. This is a critical linkage during targeting execution.) By contrast, dynamic targeting prosecutes targets that were not included in the deliberate targeting process, possibly because they were not known or not initially selected for prosecution. Dynamic targeting is normally employed in current operations planning because the nature and time frame associated with current operations (usually the current 24-hour period) typically requires more immediate responsiveness compared to deliberate targeting.\n\nTechnologically advanced countries can generally select their targets in such a way as to minimize collateral damage and civilian casualties. This can fall by the wayside, however, during unrestricted warfare.\n\nTargeting may also refer to the targeting of the actual objective to be destroyed by military personnel, such as \"painting\" a target with a laser for laser guided munitions, estimating range for artillery, etc.\n\nA target is an entity (person, place, or thing) considered for possible engagement or action to alter or neutralize the function it performs for the adversary. Every target has distinct intrinsic or acquired characteristics that form the basis for target detection, location, identification, and classification for ongoing and future surveillance, analysis, engagement, and assessment. Physical, functional, cognitive, environmental, and temporal are broad categories that help define the characteristics of a target.\n\nThe joint targeting cycle is a six phase iterative process: Phase 1 - End state and commander’s objectives, Phase 2 - Target development and prioritization, Phase 3 - Capabilities analysis, Phase 4 - Commander’s decision and force assignment, Phase 5 - Mission planning and force execution, Phase 6 - Assessment.\n\nGeneral Stanley A. McChrystal wrote in 2014 about a targeting cycle called \"F3EA\" used in the Iraq War, which stands for:\n\n\n"}
{"id": "608168", "url": "https://en.wikipedia.org/wiki?curid=608168", "title": "Titadine", "text": "Titadine\n\nTitadyn 30 AG (often referred to as Titadine) is a type of compressed dynamite used in mining and manufactured in southern France by Titanite S.A. The explosive comes in the form of salmon-coloured tubes of a range of diameters, from 50 to 120 mm. Titadine is very powerful and fast-burning, with an energy rating of 4650 J/g and a speed of detonation of over 6,000 m/s.\n\nIn recent years, it has been used in bomb attacks by the separatist group ETA in Spain. In September 1999 a combined group of ETA members and Breton separatists raided a factory at Plevin, Brittany, stealing over eight tonnes of Titadyn (some of which was subsequently sold to the Islamist resistance group Hamas, according to Spain's \"El Mundo\" newspaper). Another raid took place in March 2001 when an explosives factory near Grenoble in France was targeted and 1.6 tonnes of Titadyn was stolen. Much of it was later recovered by Spanish police in raids, or was used by ETA in car bomb attacks in Spanish cities.\n\n"}
{"id": "16718997", "url": "https://en.wikipedia.org/wiki?curid=16718997", "title": "Toshiba Samsung Storage Technology", "text": "Toshiba Samsung Storage Technology\n\nToshiba Samsung Storage Technology Corporation (abbreviated TSST) is an international joint venture company of Toshiba (Japan) and Samsung Electronics (South Korea). Toshiba owns 51% of its stock, while Samsung owns the remaining 49%. The company specialises in optical disc drive manufacturing. The company was established in 2004.\n\nThe company's headquarters is located in Shibaura, Minato, Tokyo, Japan with Hiroshi Suzuki as its President and CEO. Its subsidiary, Toshiba Samsung Storage Technology Korea Corporation is located in Suwon, South Korea, and headed by Dae Sung Kim.\n\nEach corporation in Japan and Korea has the individual directorate system. For the business issues, TSST has been discussing it through the common relevant organization for mutual consent. TSST is currently responsible for the product development, marketing and sales, and has been taking advantage of the existing network of Samsung Electronics and Toshiba for manufacturing, sales, and after-sales service.\n\nIn October 2009, TSST had received a subpoena from the U.S. Justice Department for possibly violating the antitrust laws.\n\nSamsung and Toshiba sold their stake in TSST to Optis Co., Ltd., a Korean manufacturer that made products for TSST under contract.\n\nIn 2016 TSST entered Chapter 15 bankruptcy protection in Delaware US, shielding it from most U.S. creditor actions while the company reorganizes its business in Korea’s court system and restructures a $78 million debt.\n\n"}
