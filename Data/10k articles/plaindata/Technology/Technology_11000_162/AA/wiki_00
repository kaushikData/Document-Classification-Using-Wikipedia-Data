{"id": "17606723", "url": "https://en.wikipedia.org/wiki?curid=17606723", "title": "3D city models", "text": "3D city models\n\n3D city models are digital models of urban areas that represent terrain surfaces, sites, buildings, vegetation, infrastructure and landscape elements in three-dimensional scale as well as related objects (e.g., city furniture) belonging to urban areas. Their components are described and represented by corresponding two-dimensional and three-dimensional spatial data and geo-referenced data. 3D city models support presentation, exploration, analysis, and management tasks in a large number of different application domains. In particular, 3D city models allow \"for visually integrating heterogeneous geoinformation within a single framework and, therefore, create and manage complex urban information spaces.\" \n\nTo store 3D city models, both file-based and database approaches are used. There is no single, unique representation schema due to the heterogeneity and diversity of 3d city model contents.\n\nComponents of 3D city models are encoded by common file and exchange formats for 2D raster-based GIS data (e.g., GeoTIFF), 2D vector-based GIS data (e.g., AutoCAD DXF), 3D models (e.g., .3DS, .OBJ), and 3D scenes (e.g., Collada, Keyhole Markup Language) such as supported by CAD, GIS, and computer graphics tools and systems. All components of a 3D city model have to be transformed into a common geographic coordinate system.\n\nA database for 3D city models stores its components in a hierarchically structured, multi-scale way, which allows for a stable and reliable data management and facilitates complex GIS modeling and analysis tasks. For example, the 3D City Database is a free 3D geo database to store, represent, and manage virtual 3D city models on top of a standard spatial relational database. A database is required if 3D city models have to be continuously managed. 3D city model databases form a key element in 3D spatial data infrastructures that require support for storing, managing, maintenance, and distribution of 3D city model contents. Their implementation requires support of a multitude of formats (e.g., based on FME multi formats). As common application, geodata download portals can be set up for 3D city model contents (e.g., virtualcityWarehouse).\n\nThe Open Geospatial Consortium (OGC) defines an explicit XML-based exchange format for 3D city models, CityGML, which supports not only geometric descriptions of 3D city model components but also the specification of semantics and topology information.\n\n3D city models are typically constructed at various levels of detail (LOD) to provide notions of multiple resolutions and at different levels of abstraction. Other metrics such as the level of spatio-semantic coherence and resolution of the texture can be considered a part of the LOD. For example, CityGML defines five LODs for building models: \n\nThere exist also approaches to generalize a given detailed 3D city model by means of automated generalization. For example, a hierarchical road network (e.g., OpenStreetMap) can be used to group 3D city model components into \"cells\"; each cell is abstracted by aggregating and merging contained components.\n\nGIS data provide the base information to build a 3D city model such as by digital terrain models, road networks, land use maps, and related geo-referenced data. GIS data also includes cadastral data that can be converted into simple 3D models as, for example, in the case of extruded building footprints. Core components of 3D city models form digital terrain models (DTM) represented, for example, by TINs or grids.\n\nTypical sources of data for 3D city model also include CAD models of buildings, sites, and infrastructure elements. They provide a high level of detail, possible not required by 3D city model applications, but can be incorporated either by exporting their geometry or as encapsulated objects.\n\nBuilding information models represent another category of geo-spatial data that can be integrated into a 3D city model providing the highest level of detail for building components.\n\nComplex 3D city models typically are based on different sources of geodata such as geodata from GIS, building and site models from CAD and BIM. It is one of their core properties to establish a common reference frame for heterogeneous geo-spatial and geo-referenced data, i.e., the data need not to be merged or fusioned based on one common data model or schema. The integration is possible by sharing a common geo-coordinate system at the visualization level.\n\nThe simplest form of building model construction consist in extruding the footprint polygons of buildings, e.g., taken from the cadaster, by pre-compute average heights. In practice, 3D models of buildings of urban regions are generated based on capturing and analyzing 3D point clouds (e.g., sampled by terrestrial or aerial laser scanning) or by photogrammetric approaches. To achieve a high percentage of geometrically and topologically correct 3D building models, digital terrain surfaces and 2D footprint polygons are required by automated building reconstruction tools such as BREC. One key challenge is to find building parts with their corresponding roof geometry. \"Since fully automatic image understanding is very hard to solve, semi-automatic components are usually required to at least support the recognition of very complex buildings by a human operator.\" Statistical approaches are common for roof reconstruction based on airborne laser scanning point clouds. \nFully automated processes exist to generate LOD1 and LOD2 building models for large regions. For example, the Bavarian Office for Surveying and Spatial Information is responsible for about 8 million building models at LOD1 and LOD2.\n\nThe visualization of 3D city models represents a core functionality required for interactive applications and systems based on 3D city models.\n\nProviding high quality visualization of massive 3D city models in a scalable, fast, and cost efficient manner is still a challenging task due to the complexity in terms of 3D geometry and textures of 3D city models. Real-time rendering provides a large number of specialized 3D rendering techniques for 3D city models. \nExamples of specialized real-time 3D rendering include: \n\nReal-time rendering algorithms and data structures are listed by the virtual terrain project.\n\nService-oriented architectures (SOA) for visualizing 3D city models offer a separation of concerns into management and rendering and their interactive provision by client applications. For SOA-based approaches, 3D portrayal services are required, whose main functionality represents the portrayal in the sense of 3D rendering and visualization. SOA-based approaches can be distinguished into two main categories, currently discussed in the Open Geospatial Consortium:\n\n\nA map-based technique, the \"smart map\" approach, aims at providing \"massive, virtual 3D city models on different platforms namely web browsers, smartphones or tablets, by means of an interactive map assembled from artificial oblique image tiles.\" The map tiles are synthesized by an automatic 3D rendering process of the 3D city model; the map tiles, generated for different levels-of-detail, are stored on the server. This way, the 3D rendering is completely performed on the server's side, simplifying access and usage of 3D city models. The 3D rendering process can apply advanced rendering techniques (e.g., global illumination and shadow calculation, illustrative rendering), but does not require client devices to have advanced 3D graphics hardware. Most importantly, the map-based approach allows for distributing and using complex 3D city models with having to stream the underlying data to client devices - only the pre-generated map tiles are sent. This way, \"(a) The complexity of the 3D city model data is decoupled from data transfer complexity (b) the implementation of client applications is simplified significantly as 3D rendering is encapsulated on server side (c) 3D city models can be easily deployed for and used by a large number of concurrent users, leading to a high degree of scalability of the overall approach.\" \n\n3D city models can be used for a multitude of purposes in a growing number of different application domains. Examples:\n\n\n"}
{"id": "54457921", "url": "https://en.wikipedia.org/wiki?curid=54457921", "title": "Alternating current electrospinning", "text": "Alternating current electrospinning\n\nAlternating current electrospinning is a fiber formation technique to produce micro- and nanofibers from polymer solutions under the dynamic drawing force of the electrostatic field with periodically changing polarity. The main benefit of alternating current electrospinning is that multiple times higher productivities are achievable compared to widely used direct current electrospinning setups.\n"}
{"id": "15595741", "url": "https://en.wikipedia.org/wiki?curid=15595741", "title": "Automatic system recovery", "text": "Automatic system recovery\n\nAutomatic system recovery is a device or process that detects a computer failure and attempts recovery. The device may make use of a Watchdog timer. This may also refer to a Microsoft recovery technology by the same name.\n\n"}
{"id": "45473832", "url": "https://en.wikipedia.org/wiki?curid=45473832", "title": "Beyond CMOS", "text": "Beyond CMOS\n\nBeyond CMOS refers to the possible future digital logic technologies beyond the CMOS scaling limits which limits device density and speeds due to heating effects.\n\n\"Beyond CMOS\" is the name of one of the 7 focus groups in ITRS 2.0 (2013) and in its successor, the International Roadmap for Devices and Systems.\n\nCPUs using CMOS were released from 1986 (e.g. 12 MHz Intel 80386). As CMOS transistor dimensions were shrunk the clock speeds also increased. Since about 2004 CMOS CPU clock speeds have leveled off at about 3.5 GHz.\n\nCMOS devices sizes continue to shrink – see Intel tick–tock and ITRS :\n\nCMOS transistors may not work below 10 nm. See 10 nanometer and 7 nanometer.\n\nAbout 2010 the Nanoelectronic Research Initiative (NRI) studied various circuits in various technologies.\n\nNikonov & Young benchmarked (theoretically) many technologies in 2012, and updated it in 2014. The 2014 benchmarking included 11 electronic, 8 spintronic, 3 orbitronic, 2 ferroelectric, and 1 straintronic technology.\n\nThe 2015 ITRS 2.0 report included a detailed chapter on \"Beyond CMOS\", covering RAM and logic gates.\n\n\nSuperconducting computing includes several beyond-CMOS technologies that use superconducting devices, namely Josephson junctions, for electronic signals processing and computing. One variant called rapid single-flux quantum (RSFQ) logic was considered promising by the NSA in a 2005 technology survey despite the drawback that available superconductors require cryogenic temperatures. More energy-efficient superconducting logic variants have been developed since 2005 and are being considered for use in large scale computing.\n\n\n"}
{"id": "311287", "url": "https://en.wikipedia.org/wiki?curid=311287", "title": "Charge card", "text": "Charge card\n\nA charge card is a card that provides a payment method enabling the cardholder to make purchases which are paid for by the card issuer, to whom the cardholder becomes indebted. The cardholder is obligated to repay the debt to the card issuer in full by the due date, usually on a monthly basis, or be subject to late fees and restrictions on further card use. It can also be a smart card.\n\nThough the terms \"charge card\" and \"credit card\" are sometimes used interchangeably, they are distinct protocols of financial transactions. Credit cards are revolving credit instruments that do not need to be paid in full every month. There is no late fee payable so long as the minimum payment is made at specified intervals (usually every thirty days). The balance of the account accrues interest, which may be backdated to the date of initial purchase. Charge cards are typically issued without spending limits, but credit cards usually have a specified credit limit that the cardholder may not exceed.\n\nThough originally charge account identification was paper-based, in 1959 American Express became the first charge card operator to issue embossed plastic cards to ISO/IEC 7810 ID-1 standard. Cards have an embossed bank card number complying with the ISO/IEC 7812 numbering standard.\n\nIn 1914, Western Union opened the first charge account for its customers and provided them with a paper identification. There were many larger department stores which opened store charge accounts for their customers with paper identification, enabling the customer to make purchases on credit provided by the store. However, these accounts could be used only within the store which issued them. In 1950, Diners Club began opening charge accounts with paper identification cards, directed at the travel and entertainment markets. The novel feature of these cards was that the charge card could be used in a large number of stores. These stores had to enter an agreement with Diners Club, and pay a fee to the company. For the fee, Diners Club carried the cost of setting up accounts, authorizing each transaction, processing transactions and collections, bore the financing costs and assumed the risk of cardholders defaulting. The new system was especially appealing to smaller stores in competition with the larger stores but who could not justify setting up their own charge account facilities. Eventually the larger stores began accepting these cards, testifying that the fees charged by the card operator were lower than the store's cost in running their own store accounts. In 1957, American Express also entered the field, and in 1959 was the first company to issue embossed plastic charge cards to ISO/IEC 7810 standards.\n\nIn Europe, the MasterCard-affiliated Maestro brand (which is a debit card rather than a charge card) replaced the European Eurocheque brand for payment cards in 2002. Many Eurocheque cards, particularly in such countries as Austria and Germany, were charge cards branded with the Eurocheque logo. In addition, the European Eurocard, issued as the competitor for American Express was, and in some countries (such as the Nordic countries) still is, a charge card. Therefore, the majority of MasterCards in these countries still are charge cards. Visa charge cards are also available in Europe.\n\nThe user of the charge card has to pay the balance of their account at the end of each month and the charge card company, unlike a credit card, does not charge interest. A charge card company's main source of revenue is the merchant fee, which is a percentage of the transaction value which typically ranges between 1 and 4%, plus an interchange or minimum fee.\n\nMany charge cards have the option for users to pay for some purchases over time. American Express charge card customers, for instance, can enroll in the Extended Payment Option (internally referred to as ExPO) to be able to pay for purchases over $200 over time, or in Sign & Travel to be able to pay for eligible travel-related expenses over time.\n\nMost charge cards also have a feature called No Preset Spending Limit (NPSL). While consumers often take NPSL to mean that their cards are without limits, NPSL really means that a card's limit changes, often from month-to-month, based on factors such as consumer charging and payment history as well overall economic trends. According to a CardHub.com NPSL study, the way NPSL charge cards are reported to the major credit bureaus varies by issuer and can lead to artificial increases in credit utilization, thereby lowering one's FICO Score.\n\nGovernments and large businesses often use charge cards to pay for and keep track of expenses related to official business; these are often referred to as purchasing cards. Some retailers issue charge cards to customers. Some American Express and Diners Club cards are also charge cards, rather than credit or debit cards such as VISA and MasterCard.\n"}
{"id": "2507132", "url": "https://en.wikipedia.org/wiki?curid=2507132", "title": "Cleanroom suit", "text": "Cleanroom suit\n\nA cleanroom suit, clean room suit, or bunny suit, is an overall garment worn in a cleanroom, an environment with a controlled level of contamination. One common type is an all-in-one coverall worn by semiconductor and nanotechnology line production workers, technicians, and process / equipment engineers, as well as people in similar roles creating sterile products for the medical device industry.\n\nThe suit covers the wearer to prevent skin and hair being shed into a clean room environment. The suit may be in one piece or consist of several separate garments worn tightly together. The suit incorporates both boots and hood. It must also incorporate a properly fitted bouffant cap or mob cap.\n\nMore advanced designs with face covers were introduced in the 1990s (like the Intel fab worker-style suits seen on the Pentium product advertisements).\n\nSuits are usually deposited in a store after being contaminated for dry cleaning, autoclaving and/or repair.\n\nSimilar suits are worn in the containment areas of nuclear power plants. These suits consist of the main garment, hood, thin cotton gloves, rubber gloves, plastic bags over normal work shoes, and rubber booties. The wrists and ankles are taped down with masking tape. Occasionally a plastic raincoat is also worn. Removal of the garments (into several barrels) is a complicated process which must be performed in an exact sequence. Often a health physicist is present in the work area to observe good anti-contamination practices.\n"}
{"id": "1625481", "url": "https://en.wikipedia.org/wiki?curid=1625481", "title": "Crystal bar process", "text": "Crystal bar process\n\nThe crystal bar process (also known as iodide process or the van Arkel–de Boer process) was developed by Anton Eduard van Arkel and Jan Hendrik de Boer in 1925. This process was the first industrial process for the commercial production of pure ductile metallic zirconium. It is used in the production of small quantities of ultra-pure titanium and zirconium. It primarily involves the formation of the metal iodides and their subsequent decomposition to yield pure metal. This process was superseded commercially by the Kroll process.\n\nAs seen in the diagram below, impure titanium, zirconium, hafnium, vanadium, thorium or protactinium is heated in an evacuated vessel with a halogen at 50–250 °C. The patent specifically involved the intermediacy of TiI and ZrI, which were volatilized (leaving impurities as solid). At atmospheric pressure TiI melts at 150 °C and boils at 377 °C, while ZrI melts at 499 °C and boils at 600 °C. The boiling points are lower at reduced pressure. The gaseous metal tetraiodide is decomposed on a white hot tungsten filament (1400 °C). As more metal is deposited the filament conducts better and thus a greater electric current is required to maintain the temperature of the filament. The process can be performed in the span of several hours or several weeks, depending on the particular setup.\n\nGenerally, the crystal bar process can be performed using any number of metals using whichever halogen or combination of halogens is most appropriate for that sort of transport mechanism, based on the reactivities involved. The only metals it has been used to purify on an industrial scale are titanium, zirconium and hafnium, and in fact is still in use today on a much smaller scale for special purity needs.\n\nSeveral metals purified via this process:\n"}
{"id": "2288590", "url": "https://en.wikipedia.org/wiki?curid=2288590", "title": "Crystal earpiece", "text": "Crystal earpiece\n\nA crystal earpiece is a type of piezoelectric earphone, producing sound by using a piezoelectric crystal, a material that changes its shape when electricity is applied to it. It is usually designed to plug into the ear canal of the user.\n\nA crystal earpiece typically consists of a piezoelectric crystal with metal electrodes attached to either side, glued to a conical plastic or metal foil diaphragm, enclosed in a plastic case. The piezoelectric material used in early crystal earphones was Rochelle salt, but modern earphones use barium titanate, or less often quartz. When the audio signal is applied to the electrodes, the crystal bends back and forth a little with the signal, vibrating the diaphragm. The diaphragm pushes on the air, creating sound waves. The plastic earpiece casing confines the sound waves and conducts them efficiently into the ear canal, to the eardrum. The diaphragm is generally fixed at its outer edge, relying on bending to operate. The air path in the earpiece is generally a horn shape, with a narrowing column of air which increases the air displacement at the eardrum, increasing the volume.\n\nCrystal earpieces are usually monaural devices with very low sound fidelity, but high sensitivity and impedance. Their peak use was probably with 1960s era transistor radios and hearing aids. They are not used with modern portable media players due to unacceptable sound quality. The main causes of poor performance with these earpieces are low diaphragm excursion, nonlinearity, in-band resonance and the very short horn shape of the earpiece casing. The resulting sound is very tinny and lacking in bass. Modern headphones use electromagnetic drivers that work similarly to speakers, with moving coils or moving iron cores in a magnetic field.\n\nOne remaining use for crystal earpieces is in crystal radios. Their very high sensitivity enables them to use the very weak signals produced by crystal radios, and their high impedance (on the order of 20 kilohms) is a good match for the typical crystal radio. They have also been used as microphones, with their high output requiring less amplification.\n"}
{"id": "457320", "url": "https://en.wikipedia.org/wiki?curid=457320", "title": "Defensive design", "text": "Defensive design\n\nDefensive design is the practice of planning for contingencies in the design stage of a project or undertaking. Essentially, it is the practice of anticipating all possible ways that an end-user could misuse a device, and designing the device so as to make such misuse impossible, or to minimize the negative consequences. For example, if it is important that a plug is inserted into a socket in a particular orientation, the socket and plug should be designed so that it is physically impossible to insert the plug incorrectly. Power sockets are often keyed in such a manner, to prevent the transposition of live and neutral.\n\nDefensive design in software engineering is called defensive programming. Murphy's law is a well-known statement of the need for defensive design. It is considered the opposite approach to design by contract.\n\n\n"}
{"id": "10974032", "url": "https://en.wikipedia.org/wiki?curid=10974032", "title": "Dishcloth", "text": "Dishcloth\n\nA dishcloth is used in the kitchen to clean dishes and other surfaces. Typically they are made of cotton or other cloth, such as microfiber, and measure 11\" to 13\" inches square.\n\nDishcloths are often left damp and provide a breeding ground for bacteria. Since the kitchen sink is used to clean food, dishcloths are routinely infected with E. coli and salmonella. In 2007 a study from the Journal of Environmental Health found that putting a damp dishcloth (or sponge) in the microwave for 2 minutes killed 99% of living pathogens. However, fire departments have subsequently warned people not to do this as it can be a fire hazard, especially if the dishcloth or sponge is not sufficiently wet. Several small fires have been started as a result of people following the advice from the study.\n"}
{"id": "8120812", "url": "https://en.wikipedia.org/wiki?curid=8120812", "title": "Dobson ozone spectrophotometer", "text": "Dobson ozone spectrophotometer\n\nThe Dobson spectrophotometer, also known as Dobsonmeter, Dobson spectrometer, or just Dobson is one of the earliest instruments used to measure atmospheric ozone.\n\nThe Dobson spectrometer was invented in 1924 by Gordon Dobson. A history of the development of the instrument is here and an example of one of Dobson's own instruments remains on display in the University of Oxford Department of Physics.\n\nDobson spectrophotometers can be used to measure both total column ozone and profiles of ozone in the atmosphere. Ozone is tri-atomic oxygen, O; ozone molecules absorb harmful UV light in the atmosphere before it reaches the surface of the earth. No UVC radiation penetrates to the ground as it is absorbed in the ozone-oxygen cycle. However some longer-wave and less harmful UVB and most of the UVA is not absorbed as ozone is less opaque to these frequencies, so they penetrate to the ground level of Earth in higher quantities. The sources of light used may vary. Beside the direct sun light, the light from the clear sky, moon or stars may be used.\n\nThe Dobson Spectrometer measures the total ozone by measuring the relative intensity of the UVB radiation that reaches the Earth and comparing it to that of UVA radiation at ground level. If all of the ozone were removed from the atmosphere, the amount of UVB radiation would equal the amount of UVA radiation on the ground. As ozone does exist in the atmosphere, the Dobson Spectrometer can use the ratio between UVA and UVB radiation on the ground to determine how much ozone is present in the upper atmosphere to absorb the UVC radiation. \n\nThe ratio is determined by turning the R-dial, which can be rotated a full 300°, on the instrument. The spectrometer compares two different wavelength intensities, UVB (305 nm) and UVA (325 nm), in order to calculate the amount of ozone. When turned, the R-dial filters and blocks out the light of the UVC wavelength until the intensity of the two wavelengths of light are equal. The ratio of the two wavelengths at incidence can be calculated once the filtered intensities are the same. The results are measured in Dobson Units, equal to 10 µm thickness of ozone compressed to Standard conditions for temperature and pressure (STP) in the column. If all of the ozone in the atmospheric column one was measuring were compressed to STP, the thickness of the compressed atmosphere in mm would equal an answer in Dobson Units divided by 100. \n\nThe vertical distribution of ozone is derived using the Umkehr method. This method relies on the intensities of reflected, rather than direct, UV light. Ozone distribution is derived from the change in the ratio of the same UV-pair frequencies with time as the sun sets. An \"Umkehr\" measurement takes about three hours, and provides data up to an altitude of 48 km, with the most accurate information for altitudes above 30 km. \n\nThe Dobson method has its drawbacks. It is strongly affected by aerosols and pollutants in the atmosphere, because they also absorb some of the light at the same wavelength. Measurements are made over a small area in the direction of the sun. Today this method is often used to calibrate data obtained by other methods, including satellites. \n\nSome modernized versions of Dobson spectrophotometer exist and continue to provide data. \n\nAbout 120 Dobsonmeters have been made, mostly by R&J Beck of London, of which about 50 remain in use today. The most famous ones are probably Nos. 31 and 51 with which Joe Farman of the British Antarctic Survey discovered the Ozone Hole in 1984. The \"World Standard Dobson\", No. 83, is owned and operated by the US Dept of Commerce's, NOAA, as is the secondary standard, No. 65.\n\nThe oldest instrument still in use is No.8 located at the roof of the Norwegian Polar Institute at Ny Ålesund, Svalbard. This instrument has the last reported data for 1997.\n\nThe instrument D003, operated in Kunming, China reported data to August 2009. The history of the stations and instruments can be found at the World Ozone and UV Data Centre.\n\nThe Environment Canada (Alan Brewer) developed double- and single- monochromator spectrophotometers known as the \"Brewer\" Spectrophotometer produced by Kipp & Zonen.\n\n"}
{"id": "2373929", "url": "https://en.wikipedia.org/wiki?curid=2373929", "title": "E-plane and H-plane", "text": "E-plane and H-plane\n\nThe E-plane and H-plane are reference planes for linearly polarized waveguides, antennas and other microwave devices.\n\nIn waveguide systems, as in the electric circuits, it is often desirable to be able to split the circuit power into two or more fractions. In a waveguide system, an element called a junction is used for power division.\n\nIn a low frequency electrical network, it is possible to combine circuit elements in series or in parallel, thereby dividing the source power among several circuit components.\nIn microwave circuits, a waveguide with three independent ports is called a TEE junction. The output of E-Plane Tee is 180° out of phase where the output of H-plane Tee is in phase.\n\nFor a linearly-polarized antenna, this is the plane containing the electric field vector (sometimes called the E aperture) and the direction of maximum radiation. The electric field or \"E\" plane determines the polarization or orientation of the radio wave. For a vertically polarized antenna, the E-plane usually coincides with the vertical/elevation plane. For a horizontally polarized antenna, the E-Plane usually coincides with the horizontal/azimuth plane.\nE- plane and H-plane should be 90 degrees apart.\n\nIn the case of the same linearly polarized antenna, this is the plane containing the magnetic field vector (sometimes called the H aperture) and the direction of maximum radiation. The magnetizing field or \"H\" plane lies at a right angle to the \"E\" plane. For a vertically polarized antenna, the H-plane usually coincides with the horizontal/azimuth plane. For a horizontally polarized antenna, the H-plane usually coincides with the vertical/elevation plane.\n\nCo-polarization (Co-pol) on cross-polarization (X-pol) are defined for the radiating E and H planes. These directions are defined in spherical coordinates to correspond to the spherical wavefronts of the propagating wave. By convention the co-pol direction is the direction of the E field while the cross pol direction is the direction of the H field. Receive power for an co-pol oriented antenna is maximum while receive power is minimum for cross-pol orientation.\n\n"}
{"id": "13543193", "url": "https://en.wikipedia.org/wiki?curid=13543193", "title": "Eleutherian Mills", "text": "Eleutherian Mills\n\nFrom 1802 to 1921, Eleutherian Mills was a gunpowder mill site used for the manufacture of explosives by the Du Pont family business. The name also refers to the house on the hill above the mills, which was the first Du Pont family home in America. The business was founded by Eleuthère Irénée du Pont. In 1952, the site became an outdoor museum and the Hagley Museum and Library was founded.\n\nJacob Broom built a cotton mill on the site in 1795. The mill burned down in 1797 and in 1802 he sold the site, complete with a working dam and millrace to Eleuthère Irénée du Pont, who paid $6,740 for the .\n\nThe first domestic supplies of high-quality gunpowder were made in the US by E. I. du Pont de Nemours and Company. The company was founded in 1802 by E.I. du Pont, two years after he and his family left France to escape the French Revolution.\nThey set up the Eleutherian gunpowder mill on the Brandywine Creek just north of Wilmington, Delaware, based on gunpowder machinery bought from France and site plans for a gunpowder mill supplied by the French Government. They also built housing for 30 workers.\n\nStarting, initially, by reworking damaged gunpowder and refining saltpetre for the US government they quickly moved into gunpowder manufacture.\n\nSaltpetre was refined in an area between the house and the mills that now is occupied by a formal garden. Charcoal was produced from the willow trees that lined the Brandywine.\n\nBy the end of 1804, DuPont had sold 39,000 pounds of powder; the following year sales tripled. The federal government and John Jacob Astor's American Fur Company became regular customers. In 1813 the Hagley property, just downstream from the original mills, was purchased, doubling the size and capacity of the mills. Sales grew during the Mexican-American War and the Crimean War. During the American Civil War, the firm sold 4,000,000 barrels of powder to the federal government.\n\nA major explosion killed 33 people in 1818. Another major explosion occurred on the site in 1847. In 1854 three gunpowder wagons exploded in the city of Wilmington.\n\nThe mill buildings used in the manufacture of gunpowder were built with strong stone-walled structures on three sides; but were only covered by light wood structures on the fourth side, which faced out onto the Brandywine Creek. When an accident occurred, the explosion was directed away from the other mills and storage areas and over the creek.\n\nWater power was provided from a mill race behind the mills, thus further isolating the mills in case of accident. One water wheel was often used to provide power to two mills. Water turbines were introduced in the 1840s.\nAlfred Victor du Pont acquired additional property, down stream from the Eleutherian Mills, to add to the manufacturing site. One of these properties was called \"Hagley\", and it became known as the Hagley Yard.\nMost of the industrial remains are located in the Hagley Yard. The mills were used in the purification, crushing, and mixing of charcoal, sulfur, and saltpeter. Other mills in the complex were used for glazing and corning, making metal powder kegs, and in cotton and woolen manufacturing. Stables, offices, a machine shop, and a steam powerhouse from the late 19th century also were located in the complex, as was a narrow gauge railway.\n\nAfter the introduction of smokeless powder, the mills were to be closed in the 1910s, but were kept open at the request of the federal government until after the end of World War I.\n\nIn 1952 family members donated of land and the DuPont company established a $6,000,000 endowment for the Eleutherian Mill-Hagley Foundation for a museum of industrial history.\n\nThe site was declared a National Historic Landmark in 1966.\n\nIt is located on Delaware Route 141 at the Tyler Mcconnell Bridge spanning the Brandywine Creek.\n\n\n\n\n"}
{"id": "4524118", "url": "https://en.wikipedia.org/wiki?curid=4524118", "title": "Engine shaft", "text": "Engine shaft\n\nAn engine shaft is a mine shaft used for the purpose of pumping, irrespective of the prime mover.\n"}
{"id": "20598133", "url": "https://en.wikipedia.org/wiki?curid=20598133", "title": "Financial intelligence (business)", "text": "Financial intelligence (business)\n\nFinancial intelligence is a type of business intelligence constituted of the knowledge and skills gained from understanding finance and accounting principles in the business world. Although a fairly new term, financial intelligence has its roots in organizational development research, mostly in the field of employee participation. Financial intelligence has emerged as a best practice and core competency in many organizations leading to improved financial results, increased employee morale, and reduced employee turnover. Many organizations include financial intelligence programs in their leadership development curriculum. Financial intelligence is not an innate skill, rather it is a learned set of skills that can be developed at all levels.\n\nThe four areas of understanding that make up financial intelligence are:\n\"Understanding the foundation.\" Financial intelligence requires an understanding of the basics of financial measurement including the income statement, the balance sheet, and the cash flow statement. It also requires knowing the difference between cash and profit and why a balance sheet balances.\n\n\"Understanding the art.\" Finance and accounting are an art as well as a science. The two disciplines must try to quantify what can't always be quantified, and so must rely on rules, estimates, and assumptions. Financial intelligence ensures people are able to identify where the artful aspects of finance have been applied to the numbers, and know how applying them differently might lead to different conclusions.\n\n\"Understanding analysis.\" Financial intelligence includes the ability to analyze the numbers in greater depth. This includes being able to calculate profitability, leverage, liquidity and efficiency ratios and understanding the meaning of the results. Conducting ROI analysis and interpreting the results are also part of financial intelligence.\n\n\"Understanding the big picture.\" Financial intelligence also means being able to understand a business's financial results in context - that is, within the framework of the big picture. Factors such as the economy, the competitive environment, regulations and changing customer needs and expectations as well as new technologies all affect how the numbers are interpreted.\n\nFinancial intelligence is not just theoretical book learning. It also requires practice and real world application. In the corporate world, managers can display financial intelligence by speaking the language, that is, asking questions about the numbers when something doesn't make sense, reviewing financial reports and using the information to understand the company's strengths and weaknesses, using ROI analysis, working capital management, and ratio analysis to make decisions, and identifying where the art of finance has been applied.\n\nIn 1954, Peter F. Drucker, in his groundbreaking book, \"The Practice of Management\", wrote the following. \n\"[The worker] should know how his work relates to the work of the whole. He should know what he contributes to the enterprise...if he lacks information, he will lack both incentive and means to improve his performance.\" \n\n\"It is in the best interest of the organization that the worker have the information.\"\nThe concept of financial intelligence in organizations comes from the research of several well-known organizational development academics, including Dennis Denison, Edward Lawler and Jeffrey Pfeffer. For example, the research of Lawler, Mohrman and Ledford found that the indices that have the most impact on both direct performance outcomes in organizations (productivity, customer satisfaction, quality and speed) and on profitability and competitiveness were sharing information and developing knowledge.\n\nKaren Berman's research, asked specifically if information (operationalized by teaching business basics to improve financial intelligence and sharing information on a regular basis) improves the results of employee participation, as seen through organizational performance improvement and employee attitude improvement. The results of the study found that certain financial performance measures improved and that employee turnover decreased. \nFinancial literacy also has its roots in open book management. A core tenet of open-book management is business literacy, that is, ensuring everyone understands how the business measures financial success.\n\nMany companies, (Southwest Airlines being a prime example) consider financial intelligence a core competency or best practice. Several universities, including Harvard Business School, Wharton and Stanford have programs targeted at the corporate world, mostly at the leadership level, to increase the financial intelligence in organizations. There are a variety of methods to increase financial intelligence in organizations, including classroom training, webinar training, and business simulations. Training companies have supported these efforts as well, including Business Literacy Institute, Paradigm Learning, and Workplace Development.\n\nProponents of financial intelligence in organizations believe that if employees, managers and leaders understand financial information and how financial success is measured, they will make decisions and take action based on an understanding of the financial impact of those decisions. If everyone knows the financial goals of the company, for example, and knows how to make decisions that support those financial goals, then the company is going to be more financially successful.\n\nEmployee owned companies are one group of organizations that are focused on ensuring everyone in the company is financially intelligent, as employees are owners and therefore must understand the financial side of the business.\n\n"}
{"id": "48221941", "url": "https://en.wikipedia.org/wiki?curid=48221941", "title": "Fishkill Farms", "text": "Fishkill Farms\n\nFishkill Farms is an apple orchard and small-scale farm located in Hopewell Junction, a hamlet of East Fishkill in Dutchess County, New York. Founded by family friends of President Franklin D. Roosevelt, Fishkill Farms is one of the Hudson Valley's oldest apple orchards. Organic Authority LLC named Fishkill Farms its 2010 \"top pick\" apple farm in the New York City area.\n\nFishkill Farms was founded by U.S. Secretary of the Treasury Henry Morgenthau, Jr., who purchased the land in 1914. The farm has been handed down through family members, including former Manhattan District Attorney Robert M. Morgenthau. The farm is now run by his son, Joshua Morgenthau.\n\nThe farm originally produced apples, chickens and dairy but ceased dairy farming during World War II when hired help was hard to find. In 1980, a hailstorm damaged the apples and rendered them unsellable to wholesale distributors so the orchard was opened up to the local public for U-pick harvesting. The farm has been doing U-pick ever since.\n\nFishkill Farms' 130 acre property offers U-pick services for produce including blueberries, blackberries, cherries, peaches, nectarines, pears and vegetables. Pasture-raised hens also produce eggs for the farm. It also sells produce in Brooklyn farmers markets and an order-fulfillment service called Good Eggs. The farm offers community-supported agriculture shares for Hudson Valley residents. Numerous events such as weddings and private affairs are hosted on site, including a recent Autumn Orchard Dinner which was reported upon by the gourmet aficionado Williams-Sonoma.\n\nFarming practices at Fishkill operate with the goal of sustainability and carbon neutrality in mind., with an effort to grow as many foods as possible organically. The farm intend to consciously select crop varieties which are most suited to the effects of climate change over the next twenty years.\n"}
{"id": "30310193", "url": "https://en.wikipedia.org/wiki?curid=30310193", "title": "GSP Saturn", "text": "GSP Saturn\n\nGSP Saturn is a semi-submersible, jackup independent leg cantilever drilling rig operated by GSP Drilling, a Grup Servicii Petroliere subsidiary, and currently contracted by Wintershall Noordzee for drilling in the North Sea. The drilling unit is registered in Panama.\n\n\"GSP Saturn\" drilling rig was designed by Sonnat Offshore and was built by Petrom at the Galaţi Shipyard in 1988. The rig was completely reconstructed and refurbished in 2009 at a cost of US$50 million. The rig was owned and operated by Petrom from 1988 to 2005 when the company sold its six offshore platforms (including Atlas, Jupiter, Orizont, Prometeu and Saturn) to Grup Servicii Petroliere for US$100 million.\n\n\"GSP Saturn\" has a length of , breadth of , draft of , height of and depth of . She has a maximum drilling depth of and she could operate at a water depth of . As a drilling rig, \"GSP Saturn\" is equipped with advanced drilling equipment and has to meet strict levels of certification under international law. \"GSP Saturn\" is able to maneuver with its own engines (to counter drift and ocean currents), but for long-distance relocation it must be moved by specialist tugboats. The rig is capable of withstanding severe sea conditions including waves and winds.\n\nCurrently the GSP Saturn is operated by the Dutch company Wintershall Noordzee\n\n"}
{"id": "13537211", "url": "https://en.wikipedia.org/wiki?curid=13537211", "title": "General content descriptor", "text": "General content descriptor\n\nA General Content Descriptor (GCD) is a file which describes downloads like ringtones and pictures to wireless devices. GCD's are plain text files. They are required by many wireless carriers to install applications on devices. The name of the file will end with a \".gcd\" extension.\n"}
{"id": "48574697", "url": "https://en.wikipedia.org/wiki?curid=48574697", "title": "Grana (fashion company)", "text": "Grana (fashion company)\n\nGrana is an online fashion company based in Hong Kong. In addition to operating online, Grana has an offline showroom called “The Fitting Room” in Hong Kong, where people can try on the products and order online. Grana was co-founded by Luke Grana and Pieter-Paul Wittgen and officially launched in October 2014. Grana opened their first brick-and-mortar store in Hong Kong in September 2015.\n\nThe company sources its products directly from fabric mills, which reduces markup pricing.\n\nGrana raised the initial seed round of US $1 million from Bluebell group and angel investors in October 2014, and in July 2015, closed another seed funding round of US $1.5 million involving investors from Singaporean VC Golden Gate Ventures. Grana recently announced their Series A funding round of US $10 million led by Alibaba Group under The Hong Kong Entrepreneurs Fund, with participation from existing investors.\n\n\n"}
{"id": "1142483", "url": "https://en.wikipedia.org/wiki?curid=1142483", "title": "Hillclimbing (railway)", "text": "Hillclimbing (railway)\n\nHillclimbing is a problem faced by railway systems when a load must be carried up an incline. While railways have a great ability to haul very heavy loads, this advantage is only significant when the tracks are fairly level. As soon as the gradients increase, the tonnage that can be hauled is greatly diminished.\n\nEarly tramways and railways were laid out with very gentle grades because locomotive and horse haulage were so low in tractive effort. The only exception would be with a line that was downhill all the way for loaded traffic. Brakes were very primitive at this early stage.\n\nWhere a railway has to cross a range of mountains, it is important to lower the summit as much as possible, as this reduces the steepness of the gradients on either side. This can be done with a summit tunnel or a deep summit cutting.\n\nA summit tunnel can lower the summit even more, and steeper hills result in shorter tunnels. Also, tunnels cost the same no matter how much overburden there is, while cuttings tend to increase in cost with the square of the overburden.\n\nCare had to be taken with summit tunnels in the early days of steam with designs that suffered from problems with smoke and slippery rail.\n\nThe ruling gradient of a section of railway line between two major stations is the gradient of the steepest stretch. The ruling gradient governs the tonnage of the load that the locomotive can haul reliably.\n\nSome of the techniques that can be used to overcome steep hills include:\n\nThe pioneering Liverpool and Manchester Railway was built at a time when choice between locomotive and cable haulable was not clear cut. Therefore, all hill climbing (1 in 100) sections was concentrated in one place where cable haulage by stationary engines could be used if necessary, while the rest of the line was engineered to be so gently graded (say 1 in 2000) that even primitive locomotives would have a chance of succeeding. As it turned out at the Rainhill Trials of 1829, locomotives proved capable of handling the short 1.6-km length of 1 in 100 gradients on either side of the Rainhill level.\n\nSince the early trains had primitive brakes, it was also necessary to have very gentle gradients to reduce the need for strong brakes. Sudden changes in gradients would have also overstressed the primitive couplings between the carriages.\n\nThe gentle 1 in 2000 gradients were made possible by very substantial earthworks and bridges.\n\nThe Cromford and High Peak Railway, which mainly hauled coal, also opened in 1830 but had gradients so steep - 1 in 8 - that cable haulage was essential.\nThe Redruth and Chasewater Railway, a narrow gauge route across the Cornish peninsula (planned in 1818, opened in 1825) used a significant incline to access the harbour at Portreath, which like many in Cornwall sits in a steep valley.\n\nOn the Lancaster and Carlisle Railway (L&CR) of 1847 a deep cutting was cut at the Shap Summit. This cutting was cut through rock, about 0.5 mile (800 m) in length, and is between 50–60 feet (15–20 m) deep.\n\nOn the Docklands Light Railway the entrance to the tunnel from the original London and Blackwall railway viaduct to the tunnel to Bank has the steepest gradient on any British railway at 1 in 17 (5.88%). A zig zag stripe has been welded to the rail surface to allow trains to gain a satisfactory grip, and prevent slipping.\n\ndetail in hindi \n"}
{"id": "5640467", "url": "https://en.wikipedia.org/wiki?curid=5640467", "title": "Holmes' Marine Life Protection Association", "text": "Holmes' Marine Life Protection Association\n\nThe Holmes' Marine Life Protection Association was a United Kingdom company set up in the 19th century to produce marine signal lights and foghorns. It was founded by Nathaniel John Holmes, a telegraph engineer from Middlesex; and it passed to his son Joseph R. Holmes. The company was taken over by Albright and Wilson in 1919.\n\nIn 1875 Holmes obtained a British Patent for a marine audible alarm signal (B.P. 2564 of 1875); and in 1877 he bought, for £80 Pound Sterling, a half-share of John Grey's Patent (B.P. 2564 of 1868) for \"Improvements in fog alarms\".\n\nIn 1876 he obtained, with J.H. Player as co-applicant, a provisional application for \"Improvements in self-igniting and inextinguishable signal lights for marine and other purposes\"; it became British Patent 4215 of 1876.\n\nFurther patents were taken out by Holmes in 1885 and 1887; and his company up to 1906.\n\nIn July 1873 he demonstrated his Patent Signal Light to the Liverpool shipping company P and W Maclellan and was awarded a Certificate of Merit. It was based on the use of Calcium phosphide; which they initially made themselves at Feltham, Middlesex, before moving to Barking. Up to the end of World War I the Holmes' Marine Life Protection Association sold lifebuoy lights and distress lights; and sales increased dramatically during the war.\n\nThe provision of Lifebuoy lights was mandatory for British seagoing vessels under Board of Trade Regulations. Holmes' lights were sold under various Trade names: The Handyman's Light for lifebuoys; the Manwell-Holmes Marine Light distress light for merchant vessels; and a modified Handyman Light for lifebuoys for the Admiralty. They also produced a distress signal, the Deck Flare. They were all charged with calcium carbide, it produced acetylene gas when water was dripped onto it. They also included a small quantity of calcium phosphide, which in contact with water produced impure phosphine, it spontaneously ignited, thereby igniting the acetylene.\n\nThe Handyman lifebuoy light had a buoyancy chamber filled with air to keep it afloat. It was attached to the lifebuoy with a long cord, and to the boat with a shorter cord. When the lifebuoy was thrown overboard, the short cord pulled away two plugs, one to let sea water in and one to let gas out. For the mast-head distress signal light and the Deck Flare the two plugs were removed by hand and the units placed in a bucket of water.\n\nAlbright and Wilson bought the company after the end of World War I, they had large stocks of produced and sales had dropped substantially.\n\n\n"}
{"id": "3973933", "url": "https://en.wikipedia.org/wiki?curid=3973933", "title": "Hydrogen breath test", "text": "Hydrogen breath test\n\nA hydrogen breath test (or HBT) is used as a diagnostic tool for small intestine bacterial overgrowth and carbohydrate malabsorption, such as lactose, fructose, and sorbitol malabsorption. The test is simple, non-invasive, and is performed after a short period of fasting (typically 8–12 hours). Even though the test is normally known as a \"hydrogen breath test\", some physicians may also test for methane in addition to hydrogen. Many studies have shown that some patients (approximately 35% or more) do not produce hydrogen but actually produce methane. Some patients produce a combination of the two gases. Other patients, who are known as \"non-responders\", don't produce any gas; it has not yet been determined whether they may actually produce another gas. In addition to hydrogen and methane, some facilities also utilize carbon dioxide (CO) in the patient's breath to determine if the breath samples that are being analyzed are contaminated (either with room air or bronchial dead space air).\n\nTesting may be administered at hospitals, clinics, physician offices or if the physician/laboratory has the proper equipment and breath collection kit, patients can collect samples at home to then be mailed in for analysis.\n\nTests vary from country to country, so the following information is provided as a rough guide to typical uses of the hydrogen breath test:\n\nFructose malabsorption – the patient takes a base reading of hydrogen levels in his/her breath. The patient is then given a small amount of fructose, and then required to take readings every 15, 30 or 60 minutes for two to three hours. The basis of the test is a failure to absorb the given sugar, which is then metabolized by bacteria that give off either hydrogen or methane. Therefore, the more gas that is produced, the less absorption has occurred. If the level of hydrogen rises above 20 ppm (parts per million) over the lowest preceding value within the test period, the patient is typically diagnosed as a fructose malabsorber. If the patient produces methane then the parts per million for the methane typically rises 12 ppm over the lowest preceding value to be considered positive. If the patient produces both hydrogen and methane then the values are typically added together and the mean of the numbers is used to determine positive results, usually 15 ppm over the lowest preceding value.\n\nLactose malabsorption – the patient takes a base reading of hydrogen levels in his/her breath. The patient is then given a small amount of pure lactose (typically 20 to 25 g), and then required to take readings every 15, 30 or 60 minutes for two to three hours. If the level of hydrogen rises above 20 ppm (parts per million) over the lowest preceding value within the test period, the patient is typically diagnosed as a lactose malabsorber. If the patient produces methane then the parts per million for the methane typically rises 12 ppm over the lowest preceding value to be considered positive. If the patient produces both hydrogen and methane then the values are typically added together and the mean of the numbers is used to determine positive results, usually 15 ppm over the lowest preceding value.\n\nSmall bowel bacterial overgrowth syndrome (SBBOS) or small intestinal bacterial overgrowth (SIBO) – the patient is either given a challenge dose of glucose, also known as dextrose (75–100 grams), or lactulose (10 grams). A baseline breath sample is collected, and then additional samples are collected at 15 minute or 20 minute intervals for 3–5 hours. Positive diagnosis for a lactulose SIBO breath test – typically positive if the patient produces approximately 20 ppm of hydrogen and/or methane within the first two hours (indicates bacteria in the small intestine), followed by a much larger peak (colonic response). This is also known as a biphasic pattern. Lactulose is not absorbed by the digestive system and can help determine distal end bacterial overgrowth, which means the bacteria are lower in the small intestine.\n\nThe idea that a SIBO test should be several hours long and that distal overgrowth is important is wrong and is not supported by the scientific literature. The optimal testing is 1 hour. Small intestinal bacterial overgrowth (SIBO) occurs as a result of excessive numbers of bacteria inhabiting the proximal small intestine. Bacterial concentrations greater than 10 organisms per milliliter is diagnostic for SIBO. We know bacteria are colonizing the proximal and not the distal small intestine for several reasons. First, the gold standard method for detection of SIBO is jejunal aspirates. Intestinal fluid of the proximal intestine is sampled, not distal intestinal fluid. Secondly, the consequences of SIBO are the result of competition between bacteria and the human host for ingested nutrients in the intestine. Various functional consequences of bacterial infiltration cause enterocyte damage in the jejunum such as diminished disaccharidase activity, fat malabsorption, decreased amino acid transport and decreased vitamin B absorption. Thus, detection of proximal bacterial overgrowth is critical.\n\nThe SIBO breath test typically uses a 10 gram oral dose of lactulose for detection of proximal bacterial overgrowth. The best practice is to have breath samples collected at 20, 40, and 60 minutes after dosing. Since SIBO occurs in the proximal intestine, breath samples should be collected only within 1 hour after lactulose ingestion. This truly reflects proximal intestinal bacterial activity, not distal or colonic activity. The same argument is true if glucose is the substrate.\n\nLactulose is a carbohydrate that is not absorbed by humans. Lactulose is well known to measure oro-cecal transit time. The mean oro-cecal transit time in normal healthy individuals is 70 to 90 minutes. By 90 minutes, at least 50% of individuals would have delivered the lactulose dose to the colon. Approximately 90 to 95% of individuals have colonic bacteria that can metabolize lactulose to hydrogen or methane gas. Thus, any SIBO breath test that collects longer than 60 minutes may be measuring colonic activity. Diagnostic criteria of 20 ppm hydrogen and/or methane changes within 90 or 120 minutes will have higher positive rates of SIBO but this will reflect colonic activity not jejunal metabolism. A one-hour SIBO breath test avoids false positive results by collecting breath up to 60 minutes.\n\nPositive diagnosis for a glucose SIBO breath test – glucose is absorbed by the digestive system so studies have shown it to be harder to diagnose distal end bacterial overgrowth since the glucose typically doesn't reach the colon before being absorbed. An increase of approximately 12 ppm or more in hydrogen and/or methane during the breath test could conclude bacterial overgrowth. Recent study indicates \"The role of testing for SIBO in individuals with suspected IBS remains unclear.\"\n\nThe excess hydrogen or methane is assumed to be typically caused by an overgrowth of otherwise normal intestinal bacteria.\n\nOther breath tests that can be taken include: sucrose intolerance, d-xylose and sorbitol.\n\n"}
{"id": "10367565", "url": "https://en.wikipedia.org/wiki?curid=10367565", "title": "IEC 61030", "text": "IEC 61030\n\nD²B (Domestic Digital Bus, IEC 61030) is an IEC standard for a low-speed multi-master serial communication bus for home automation applications. It was originally developed by Philips in the 1980s. In 2006 it has been withdrawn by IEC because another standard was proposed, JTC1 SC 83/WG1. There remain many IEC61030-compliant devices, such as some Philips-branded head units and CD changers from car stereos.\n\nThe SCART connector provides a D²B connection for inter-device communication.\n\n\n"}
{"id": "12743409", "url": "https://en.wikipedia.org/wiki?curid=12743409", "title": "Kno", "text": "Kno\n\nKno, Inc. was a software company that worked with publishers to offer digital textbooks and other educational materials. In November 2013, after raising nearly $100 million in venture capital, the company was acquired by Intel. The website was stopped and the service renamed to Intel Education Study later on.\n\nFounded in May 2009, Kno was headed by CEO Osman Rashid., the co-founder of Chegg, and CTO Babur Habib, a consumer electronics veteran. The firm received funding from Andreessen Horowitz, Intel Capital, Goldman Sachs, FLOODGATE and GSV Capital, and was based in Santa Clara, California.\n\nThe company initially announced, in June 2010, a line of tablet computers. Its goal was to offer a \"digital textbook/student platform\" aimed at the academic market. The textbook tablet was available either with a single panel 14.1\" touchscreen or with dual 14.1\" touchscreens. The operating system was based on Linux and Webkit.\n\nIn April 2011, the company announced that it had licensed its hardware design to Intel and would instead focus on developing software. Two months later, the company released an iPad application, followed by versions for the Galaxy Note 10.1, Android Jelly Bean, Windows 7 & 8, and Web platforms and devices.\n\nIn August 2012 the company expanded its catalog of titles from college textbooks to include the K-12 market.\n\nThe company was acquired by Intel the following year.\nKno currently addresses its product to three different audiences; Kno for College, offering higher education eTextbooks, Kno for School, covering K-12 learning material, and Kno for Publishers, providing publishers with the tools to add textbooks to Kno and add interactive content.\n\nEach eTextbook comes with interactive features (videos, 3D models and simulations), a personal journal, Kno Me (for students to track and monitor their progress), social sharing features, and sometimes flashcards and other learning aids. .\n\n"}
{"id": "44086826", "url": "https://en.wikipedia.org/wiki?curid=44086826", "title": "LinguaLeo", "text": "LinguaLeo\n\nLingualeo is an educational online platform offering an English language learning service based on gamification methods. Initially a Russian-language service, it is now localized for Turkey and Brazil. As of December 2015, over 13 million people worldwide have used this online service to learn English, 9 million of which are from The Commonwealth of Independent States (CIS) countries. In May 2017, Lingualeo announced its expansion to Spain and Spanish-speaking countries in Latin America. Total number of users reached 17,5 million people. Lingualeo is available as an app on iOS, Android, and Windows Phone. There is also a web version and as a browser extension for Google Chrome. The company is named after its mascot, Leo the Lion.\n\nLingualeo is Aynur Abdulnasurov’s second educational project. He sold his share in his first project called “Native Speakers Club” (which helped students find teachers) for $250,000 in order to start working on Lingualeo. The service was meant to be a set of creative approaches to learning English online.\n\nIn October 2009, Aynur Abdulnasurov traveled to Koh Chang, Thailand with a team of developers in order to work on the service. In the future, this practice became a kind of a tradition. They launched a blog on Habrahabr, describing the process of app development on a tropic island. Lingualeo first came into the spotlight thanks to this blog, which in turn became a prototype for many tech startups and company blogs. In Thailand they came up with an idea to use Leo the lion as a symbol of a student who gets lost in a jungle of new information.\n\nThe first version, released in March 2010, didn’t do enough to prompt people to upgrade to the paid service. The company failed to strike a deal with a huge linguistic company, so development was put on hold for six months. In November, Lingualeo received a high rating at Strogino technopark. At the Youth Innovation Congress in Perm, Aynur Abdulnasurov met Sergey Kuznetsov and Egor Rudy (founders of the educational project Eruditor Group), who introduced him to Igor Ryabenky, an angel investor. Lingualeo was valued at $1 million, and the company also raised $200,000 in funding from investors. Also in November, the platform was nominated for the Runet Prize for the first time.\n\nIn May 2011, Lingualeo was ranked eighth in a ranking of startup companies compiled by the recruiting agency Pruffi. From December to July, the number of users grew to 200,000 (compared to just 60,000 in December) and paid-service sales increased by 15 times since July. Lingualeo reached a break-even point. The company was named ‘best web-application’ by Mail.ru for the ‘Soft of the year - 2011’ Award. And in August 2011, Lingualeo received a 4.2 million ruble subsidy from The Department of Science, Industrial Policy and Entrepreneurship of the Moscow Government. By May 2012, Lingualeo was valued at $10 million. In June, the startup raised $3 million from the venture fund Runa Capital. A team of developers travelled to Sveti Stefan, Montenegro and created a new version of the service for Portuguese speakers in 2.5 months. Lingualeo launched its service in Brazil.\n\nBy the end of 2012, Lingualeo’s revenue grew sevenfold. According to Aynur Abdulnasurov, he remained the company’s controlling shareholder. The number of users reached 3 million people, including 100,000 Brazilian users.\n\nIn 2013, Lingualeo was listed in Kommersant’s ‘TOP Mobile Apps Pack’ ranking, took third place in Kommersant’s general startup research ranking, and won first place in the ‘Consumer Services’ category. The startup was nominated for the ‘Made in Russia’ award in the “Entrepreneurship” category and for the ‘Runet Prize’ award in the ‘Technologies and Innovations’ category. According to Wired, Lingualeo took seventh place in ‘the hottest Russian startup’ ranking. The service also received the Russian Startup Award in 2013.\n\nIn the beginning of 2014, Lingualeo’s founder Aynur Abdulnasurov was ranked 81st on the list of Russian internet-millionaires, compiled by ‘The Firm’s Secret’. The company announced a partnership with Evernote in May, and with TED Conferences in July. As a result, Lingualeo added grammar rules, vocabulary notes, and an interactive video player that enabled users to le.arn English by watching TED Talks.\n\nIn the fall, Lingualeo released a TOEFL prep program. By the end of October 2014, the number of users reached 10 million.\n\nIn April 2015, Lingualeo introduced its new B2B sales product based on the ilingin.com platform. The product let corporate customers’ staff members to get personalized learning programs that take into account industry specifics, job functions, and language skills of the employee. Lingualeo succeeded in raising $500,000 from Social Discovery Ventures and Runa Capital in May 2015. In August, Pavel Gushin (former Head Editor of Yandex.Maps) joined the team as a Vice-President of Development. In December, Lingualeo made it to Google’s ‘Best apps for Android 2015’ list in the ‘Made in Russia’ category. According to a report from 2015, the company reached a break-even point in July and saw a 7% revenue growth compared to 2014.\n\nIn March 2016 Dmitry Stavisky resigned as CEO and Irina Shashkina took over the position. On April 25, Lingualeo announced a relaunch of the platform: now, vocabulary and grammar skills sections are formed automatically. 30 new grammar rules were added to grammar trainings, so all basic grammar structures were covered with more than 500 examples for each rule. New vocabulary trainings were introduced - ‘Savanna’ (aimed at enlarging active vocabulary) and ‘Audiocall’ (aimed at training active listening skills). ‘Gold status’ was replaced by ‘Lingualeo Premium’ and together with ‘Lingualeo Basic’ they presented two ways to use the platform: paid and free, respectively.\n\nIn honour of its 6th birthday, Lingualeo held a competition and the winner was awarded two weeks of English learning at a language school in Manchester. In June, Lingualeo was listed in Google Play’s collection in the ‘Best from Russia’ category. In the beginning of 2017, a new section aimed at developing reading comprehension skills was launched on the Lingualeo app for iOS. The set of exercises suits everyone regardless of the user’s language level. In May 2017, Lingualeo announced its expansion to Spain and Spanish-speaking countries in Latin America.\n\n\n"}
{"id": "502839", "url": "https://en.wikipedia.org/wiki?curid=502839", "title": "List of crew-served weapons of the U.S. Armed Forces", "text": "List of crew-served weapons of the U.S. Armed Forces\n\nThis list contains weapons that are classified as crew-serve or crew service, often mislabeled as crew-served, as the term is used in the United States military.\n\nWhile the general understanding is that crew-serve weapons, unlike individual service weapons, require more than one person to operate them, there are important exceptions in the case of both squad automatic weapons (SAW) and special application rifles (SAR). Within the Table of Organization and Equipment for both the United States Army and the U.S. Marine Corps, these two classes of weapons are understood to be crew-serve, as the operator of the weapon (identified as a marksman or as a SAW gunner) has an assistant, who carries additional ammunition and associated equipment, acts as a spotter, and is also fully qualified in the operation of the weapon.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "71916", "url": "https://en.wikipedia.org/wiki?curid=71916", "title": "List of operating systems", "text": "List of operating systems\n\nThis is a list of operating systems. Computer operating systems can be categorized by technology, ownership, licensing, working state, usage, and by many other characteristics. In practice, many of these groupings may overlap. Criteria for inclusion is notability, as shown either through an existing Wikipedia article or citation to a reliable source.\n\n\n\n\n\n\n\n\n\n\nNon-Unix Operating Systems:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSee also Mobile Operating systems\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "10284248", "url": "https://en.wikipedia.org/wiki?curid=10284248", "title": "Ministry of Industry and Technology (Turkey)", "text": "Ministry of Industry and Technology (Turkey)\n\nThe Ministry of Science, Industry and Technology () is a government ministry office of the Republic of Turkey, responsible for industrial and commercial affairs in Turkey. The ministry is headed by Faruk Özlü.\n\n"}
{"id": "4981482", "url": "https://en.wikipedia.org/wiki?curid=4981482", "title": "Multimedia computer", "text": "Multimedia computer\n\nA multimedia computer is a computer that is optimized for high multimedia performance.\n\nEarly home computers lacked the power and storage necessary for true multimedia. The games for these systems, along with the demo scene were able to achieve high sophistication and technical polish using only simple, blocky graphics and digitally generated sound.\nThe Amiga 1000 from Commodore International has been called the first multimedia computer. Its groundbreaking animation, graphics and sound technologies enabled multimedia content to flourish. Famous demos such as the Boing Ball and Juggler showed off the Amiga's abilities. Later the Atari ST series and Apple Macintosh II extended the concept; the Atari integrated a MIDI port and was the first computer under US$1000 to have 1 megabyte of RAM which is a realistic minimum for multimedia content and the Macintosh was the first computer able to display true photorealistic graphics as well as integrating a CD-ROM drive, whose high capacity was essential for delivering multimedia content in the pre-Internet era.\n\nMultimedia capabilities were not common on IBM PC compatibles until the advent of Windows 3.0 and the MPC standards in the early 1990s. The original PCs were devised as \"serious\" business machines and colorful graphics and powerful sound abilities weren't a priority. The few games available suffered from slow video hardware, PC speaker sound and limited color palette when compared to its contemporaries. But as PCs penetrated the home market in the late 1980s, a thriving industry arose to equip PCs to take advantage of the latest sound, graphics and animation technologies. Creative's SoundBlaster series of sound cards, as well as video cards from ATi, nVidia and Matrox soon became standard equipment for most PCs sold.\n\nMost PCs today have good multimedia features. They have dual- or single-core CPUs clocked at 3.0 GHz or faster, at least 1GB of RAM and a 128 MB or higher video card. Popular graphics cards include Nvidia Gforce or ATI Radeon. The Intel Viiv platform, and Microsoft Windows XP Media Center Edition are some of today's products aimed at multimedia computing. \n\nMore recently, high-performance devices have become more compact, and multimedia computer capabilities are found in mobile devices such as the Apple iPhone and Nokia Nseries, featuring DVD-like video quality, megapixel class cameras, fully capable browser, music and video players, podcasting, blogging, as well as e-mail, instant messaging, presence and internet call (VoIP) functionality. Multiradios help to offer broadband wireless connectivity, including for instance WCDMA/HSDPA and WLAN/Wifi. Devices are also increasingly equipped with GPS receivers and maps applications, providing new capabilities for location-aware services. The Nseries devices are also expandable, allowing for the addition of multiple applications and multimedia content.\n"}
{"id": "21880823", "url": "https://en.wikipedia.org/wiki?curid=21880823", "title": "Nano-scaffold", "text": "Nano-scaffold\n\nNano-scaffolding (or nanoscaffolding) is a medical process used to regrow tissue and bone, including limbs and organs. The nano-scaffold is a three-dimensional structure composed of polymer fibers very small that are scaled from a Nanometer (10 m) scale. Developed by the American military, the medical technology uses a microscopic apparatus made of fine polymer fibers called a scaffold. Damaged cells grip to the scaffold and begin to rebuild missing bone and tissue through tiny holes in the scaffold. As tissue grows, the scaffold is absorbed into the body and disappears completely.\n\nNano-scaffolding has also been used to regrow burned skin. The process cannot grow complex organs like hearts.\n\nHistorically, research on nano-scaffolds dates back to at least the late 1980s when Simon showed that electrospinning could be used to produced nano- and submicron-scale polymeric fibrous scaffolds specifically intended for use as \"in vitro\" cell and tissue substrates. This early use of electrospun fibrous lattices for cell culture and tissue engineering showed that various cell types would adhere to and proliferate upon polycarbonate fibers. It was noted that as opposed to the flattened morphology typically seen in 2D culture, cells grown on the electrospun fibers exhibited a more rounded 3-dimensional morphology generally observed of tissues \"in vivo\".\n\nNano-scaffolding is very small, 100 times smaller than the human hair and is built out of biodegradable fibers. The use of this scaffolding allows more effective use of stem cells and quicker regeneration. Electrospun nanofibers are prepared using microscopic tubes that range between 100 and 200 nanometers in diameter. These entangle with each other in the form of a web as they're produced. Electrospinning allows the construction of these webs to be controlled in the sense of the tube's diameter, thickness, and the material being used. Nano-scaffolding is placed into the body at the site where the regeneration process will occur. Once injected, stem cells are added to the scaffolding. Stem cells that are attached to a scaffold are shown to be more successful in adapting to their environment and performing the task of regeneration. The nerve ends in the body will attach to the scaffolding by weaving in-between the openings. This will cause them to act as a bridge to connect severed sections. Over time the scaffolding will dissolve and safely exit the body leaving healthy nerves in its place.\n\nThis technology is the combination of stem cell research and nanotechnology. The ability to be able to repair damaged nerves is the greatest challenge and prize for many researchers as well as a huge step for the medical field. This would allow doctors to repair nerves damaged in an extreme accident, like third degree burns. The technology however, is still in its infancy and is still not capable of regenerating complex organs like a heart, although it can already be used to create skin, bone and nails. Nano scaffolding has been shown to be four to seven times more effective in keeping the stem cells alive in the body, which would allow them to perform their job more effectively. This technology can be used to save limbs that would otherwise need amputation. Nanoscaffolding provides a large surface area for the material being produced, along with changeable chemical and physical properties. This allows them to be applicable in many different types of technological fields.\n\nMechanical properties are one of the most important considerations when designing scaffolds for medical use. If the mechanical properties, in particular the elastic modulus, of the scaffold do not align with those of the host tissue, the scaffold is more likely to inhibit regeneration or mechanically fail.\n\nAs with natural bone, the primary issue with bone scaffolds is brittle failure. They typically follow linear elastic behavior, and under compressive forces experiences a plateau and recovery reminiscent of cellular solids as well as trabecular bone. The elastic modulus of natural bone ranges from 10 to 20 GPa; it requires a high stiffness to withstand constant mechanical load. Bone scaffolds must therefore be as stiff as natural bone, or the scaffold will fail through crack nucleation and propagation before the host tissue can regenerate. However, if the scaffold is significantly stiffer than the surrounding tissue, the elastic mismatch and continuity at the scaffold boundary with cause strain in the natural bone and could create unwanted defects.\n\nCardiac muscle, on the other hand, has an elastic modulus of only around 10 MPa, 3 orders of magnitude smaller than bone. However, it experiences constant cyclic loading as the heart pumps. This means that the scaffold must be both tough and elastic, a property achieved using polymeric materials.\n\nThe spinal cord presents yet another challenge in the engineering of mechanical properties for tissue engineering. Discs in the spine are stiff like bone, and must withstand high mechanical loading; this part of the spine must be engineered with a high elastic modulus. The discs are filled with white and grey matter, which are gel-like and much less stiff. In repairing a defect in the grey matter, the modulus must be matched precisely so that the shock-absorbing properties are not affected. A mismatch in elastic modulus will also hinder contact between the regenerative material and the host grey matter as well as the exterior bone layer.\n"}
{"id": "47510418", "url": "https://en.wikipedia.org/wiki?curid=47510418", "title": "OpenDataSoft", "text": "OpenDataSoft\n\nOpenDataSoft is a private software company specialized in transforming structured data into API and visualizations. Founded in 2011, OpenDataSoft targets non-technical users who wish to share and visualize data related to various topics (government data, economy, health, education, culture, transport, energy and environment).\n\nOpenDataSoft allows restricted and open sharing ecosystems like open data portals.\n\nOpenDataSoft is headquartered in Boston, Massachusetts and Paris, France, with offices also in Cary (North Carolina) and San Francisco (California).\n\nIn 2014, the company joined the ODI start-up program to promote open data for public organizations. \nIn November 2014, the Electronic Business Group nominated OpenDataSoft in its top-ten most innovative French startups. In May 2016, the company was named an IDC Innovator in the IDC Innovators: Smart City Open Data Platforms, 2016 report.\n\nIn February 2015, the company signed its first contract in the United States of America with the city and the county of Durham, North Carolina, USA.\n\nOpenDataSoft received an initial venture capital round of $1.7 million from Aurinvest in June 2015.\n\nIn September 2016, the company opened a North American headquarter in Boston, USA.\n\nIn October 2016, OpenDataSoft raised $5.4 Million in Series A funding. Backers included Aster Capital, Salesforce Ventures et Aurinvest.\n\nIn October 2017, According to the reports, OpenDataSoft would be launching Open Data America, to release data portals for more than 500 cities across the United States.\n\nOpenDataSoft provides a cloud-based software for cities, public organizations and companies to host and share their data. Data type includes temporal data, cartographic data (tiles, shapes, clustering), graphs and real-time data (M2M logs).\n\nThese data can be made publicly available to citizens, commuters, associations and businesses in order to generate public-interest services. They can also be shared privately within an organization and then be used by employees or business partners.\n\nThe company currently provides data portals for Paris, Brussels, Durham County and City, Cary and Chapel Hill.\n"}
{"id": "35368283", "url": "https://en.wikipedia.org/wiki?curid=35368283", "title": "OpenPicus", "text": "OpenPicus\n\nOpenPicus is an Italian hardware company who designs and produce Internet of Things system on modules called Flyport. Flyport is open hardware and the openPicus framework and IDE are open software.\nFlyport is a stand-alone system on module, no external processor is needed to create IoT applications.\n\nOpenPicus was founded by Claudio Carnevali and Gabriele Allegria during 2011. The idea was to create a hardware and software open platform to speed up the development of professional IoT devices and services.\n\nFlyport is a smart and connected system on modules for the Internet of Things. Flyport is powered by a powerful and light open source framework (based on FreeRTOS) that manages the TCP/IP software stack, the user application and the integrated \"web server\"'.\nFlyport is available in 3 pin compatible versions:\n\nFlyport system on module is based on Microchip Technology PIC24 low power processor. It is used to connect and control systems over Internet through an embedded customizable web server or the standard TCP/IP services. The integrated microcontroller runs the customer application, so no host processor is needed. The pinout is very flexible since it is customizable by software.\nFlyport can connect with several cloud servers such as Evrthng, Xively, ThingSpeak and many more.\n\nHardware: Schematics are released under CC-BY 3.0 \nSoftware: Framework is released under LGPL 3.0\n\n"}
{"id": "28787278", "url": "https://en.wikipedia.org/wiki?curid=28787278", "title": "Oscar Pedersen (businessman)", "text": "Oscar Pedersen (businessman)\n\nOscar Eugen Nicolai Pedersen (6 November 1857 – 5 March 1913) was a Norwegian industrialist.\n\nHe was born in Fredrikshald. He attended middle school in Fredrikshald and technical school in Horten, and then studied chemistry at the Dresden University of Applied Sciences. He graduated in 1880, and worked as an engineer and chemist at the Hafslund Chemical Wood Pulp Factory () from 1883 to 1889. He came in contact with Carl Kellner, and in 1888 Kellner and Edward Partington bought the Borregård farm, acquired rights in Sarp Falls, and established the Kellner-Partington Paper Pulp Co. Ltd. Pedersen was hired as company manager. The company became Borregaard, which Pedersen developed until his relatively early death.\n\nHe married Swedish citizen Polly Wennberg (1866–1920) in April 1884. He died in March 1913 near Holmenkollen.\n"}
{"id": "14938066", "url": "https://en.wikipedia.org/wiki?curid=14938066", "title": "Projection augmented model", "text": "Projection augmented model\n\nA projection augmented model (PA model) is an element sometimes employed in virtual reality systems. It consists of a physical three-dimensional model onto which a computer image is projected to create a realistic looking object. Importantly, the physical model is the same geometric shape as the object that the PA model depicts.\n\nSpatially augmented reality (SAR) renders virtual objects directly within or on the user's physical space. A key benefit of SAR is that the user does not need to wear a head-mounted display. Instead, with the use of spatial displays, wide field of view and possibly high-resolution images of virtual objects can be integrated directly into the environment. For example, the virtual objects can be realized by using digital light projectors to paint 2D/3D imagery onto real surfaces, or by using built-in flat panel displays.\n\nReal objects can be physically handled and naturally manipulated to be viewed from any direction, which is essential for ergonomic evaluation and provides a strong sense of palpability. Although simulated haptic feedback devices enable some aspects of computer-generated objects to be touched, they can not match this level of functionality. It is, therefore, unsurprising that physical objects are still used for many applications, such as product design. However, computer-generated objects have a key advantage; they provide a level of flexibility that cannot be matched by physical objects. Therefore, a display is needed that somehow joins the real physical world and computer-generated objects together, thus enabling them to be experienced simultaneously.\n\nTangible user interfaces (TUI) and augmented reality both aim to address this issue. TUI systems use real physical objects to both represent and also interact with computer-generated information (Figure 1). However, while TUIs create a physical link between real and computer-generated objects, they do not create the illusion that the computer-generated objects are actually in a user’s real environment. That is the aim of augmented reality.\n\n\"Figure 1 Continuum of advanced computer interfaces, based on Milgram and Kishino (1994). \"\n\nUnlike virtual reality (VR), which immerses a user in a computer-generated environment, augmented reality (AR) joins together physical and virtual spaces by creating the illusion that computer-generated objects are actually real objects in a user’s environment (Figure 1). Furthermore, head-mounted-display based AR and VR systems can directly incorporate physical objects. Thus, as a user reaches out to a computer-generated object that they can see, they touch an equivalent physical model that is placed at the same spatial location. Such systems enable the computer-generated visual appearance of the object to be dynamically altered, while the physical model provides haptic feedback for the object’s underlying form. However, head-mounted-display based systems require users to wear equipment, which limits the number of people who can simultaneously use the display.\n\nA variant of the AR paradigm that does not suffer from these limitations is spatially augmented reality (Figure 1). Spatially augmented reality displays project computer-generated information directly into the user’s environment. Although there are several possible display configurations, the most natural type is the projection augmented model.\n\n\"Figure 2 The Projection Augmented model concept\"\n\nA projection augmented model (PA model) consists of a physical three-dimensional model, onto which a computer image is projected to create a realistic looking object (Figure 2). Importantly, the physical model is the same geometric shape as the object that the PA model depicts. For example, the image projected onto the objects shown in Figure 3 provides colour and visual texture, which makes them appear to be made from different materials.\n\n\"Figure 3 An example of a Projection Augmented model (inset - with the projection off).\"\n\nPA models use a unique combination of physical objects and computer-generated information, and hence they inherit advantages from both. \"“The human interface to a physical model is the essence of ‘intuitive’. There are no widgets to manipulate, no sliders to move, and no displays to look through (or wear). Instead, we walk around objects, moving in and out to zoom, gazing and focusing on interesting components, all at very high visual, spatial, and temporal fidelity”\". PA models combine the high level of intuitiveness of physical models with the flexibility and functionality of computer graphics, such as the ability to be quickly altered, animated, saved and updated (Jacucci, Oulasvirta, Psik, Salovaara & Wagner, 2005). Thus, a PA model essentially gives a physical form to a computer-generated object, which a user can touch and grasp with their bare hands. It is therefore unsurprising that user studies, which compared PA models to other Virtual and Augmented Reality displays, found PA models to be a natural and intuitive type of display (Nam & Lee, 2003; Stevens et al., 2002).\n\nHowever, the PA model concept is not new. In fact, one of the first PA model type displays was created over twenty years ago when Naimark built the ‘Displacements’ art installation (Naimark, 1984) and more recently in the “Haunted Mansion” attraction in Disney World (Liljegren & Foster, 1990). At the time technology did not exist for a PA model to be much more than an artistic statement. However, given the technology available today and a little “unfettered imagination”, exploring novel projection displays is now “potentially boundless”.\n\nThe growth in PA model technology has been marked by the recent recreation of Naimark’s ‘Displacements’ installation at SIGGRAPH (Displacements, 2005). Specifically, new technology has been developed that semi-automates the process of both creating and aligning the physical model and projected image. This supports multiple projectors, which enables a PA model to be illuminated from every direction. Furthermore, powerful projectors (2000-3000 lumens) can be used to allow a PA model to be located in a well-lit room (Nam, 2005; Umemoro, Keller & Stappers, 2003). However, whilst this technology enables a PA model to be a viable and useful type of display, it does not address its main aim.\n\nA PA model aims to create the illusion of actually being the object that it depicts. For example, when used for a product design application, it is important that a PA model provides a convincing perceptual impression of actually being the final product (Nam, 2006; Saakes, 2006; Verlinden, Horváth & Edelenbos, 2006; Keller & Stappers, 2001). Similarly, when used for a museum display application to create a replica of an artefact, a PA model aims to create the illusion of being the real artefact (Hirooka & Satio, 2006; Senckenberg Museum, 2006; Bimber, Gatesy, Witmer, Raskar & Encarnacao, 2002; Museum of London, 1999).\n\nHowever, no previous research has specifically considered this illusion. Therefore, this thesis defines the ‘Projection Augmented model illusion’ as the situation in which a PA model is perceived to actually be the object that it depicts. For example, this illusion occurs when a user perceives the PA model in Figure 3 to be real bricks, flower pots, and pieces of wood, as opposed to white models with an image projected onto them. However, the essence of this illusion does not involve deceiving the user. A user can perceive a PA model to be the object that it depicts, whilst knowing that it is actually a white model and a projected image.\n\nTechnology has been developed to enhance this illusion by increasing the physical similarity between the PA model and the object that it depicts, or in other words, increasing the fidelity of the PA model. For example, the way in which the specular highlights on an object move as the viewer changes position can be dynamically simulated. This enables a PA model to appear to be made from a wide range of materials. For example, a dull clay vase can appear to be made from a shiny plastic material.\n\nHowever, whether or not the PA model illusion occurs is entirely dependent on a user’s subjective perceptual impression. Therefore, increasing the fidelity of different aspects of a PA model may each have a different effect on the strength of the illusion. This is essentially the same as the way in which increasing the fidelity of different aspects of a computer-generated photorealistic image, may each have a different effect on the degree to which the image is perceived to be a real photograph (Longhurst, Ledda & Chalmers, 2003; Rademacher, Lengyel, Cutrell, & Whitted, 2001). For example, increasing the fidelity of the textures in the image may typically be more important than increasing the fidelity of the shadows.\nIt cannot therefore be assumed that increasing the fidelity of any aspect of a PA model will automatically strengthen the PA model illusion, and similarly it cannot be assumed that decreasing the fidelity of any aspect will automatically weaken it. Therefore, given that no previous research has investigated this illusion, it is difficult to determine the success of the technology that aims to enhance it, and difficult to make informed decisions when developing new technology. The capabilities of the human perceptual system should guide the development of any advanced interface (Stanney et al., 2004), hence this issue needs to be addressed.\n\nNote: Projection Augmented models are sometimes referred to as 'Shader Lamps' (Raskar, Welch, Low & Bandyopadhyay, 2001, p. 89).\n\nAzuma, R., Baillot, Y., Behringer, R., Feiner, S., Julier, S., & MacIntyre, B. (2001). Recent Advances in Augmented Reality. IEEE Computer Graphics and Applications, 21(6), 34-47.\n\nBaradaran, H., & Stuerzlinger, W. (2005). A Comparison of Real and Virtual 3D Construction Tools with Novice Users. In Proceedings of International Conference on Computer Graphics & Virtual Reality – CGVR’06 – part of 2006 World Congress in Computer Science, Computer Engineering, and Applied Computing - WORLDCOMP'06. World Academy of Science.\n\nBillingshurst, M., Grasset, R., & Looser, J. (2005). Designing Augmented Reality Interfaces. In Proceedings of Annual Conference on Computer Graphics and Interactive Techniques – SIGGRAPH’05 (pp. 17–22). New York: ACM Press.\n\nBimber, O., Gatesy, S., Witmer, L., Raskar, R., & Encarnacao, L. (2002). Merging Fossil Specimens with Computer-Generated Information. IEEE Computer, 35(9), 25-30.\n\nBimber, O., & Raskar, R. (2005). Spatial Augmented Reality: A Modern Approach to Augmented Reality. In Proceedings of Annual Conference on Computer Graphics and Interactive Techniques - SIGGRAPH’05. New York: ACM Press.\n\nBorst, C., & Volz, R. (2005). Evaluation of a Haptic Mixed Reality System for Interactions with a Virtual Control Panel. Presence: Teleoperators and Virtual Environments, 14(6), 677-696.\n\nBrooks, F. (1999). What’s real about virtual reality? IEEE Computer Graphics and Applications, 19(6), 16-27.\n\nBurdea, G., & Coffet, P. (2003). Virtual Reality Technology, 2nd Edition. Washington: Wiley-IEEE Press.\n\nCruz-Neira, C., Sandin, D., & DeFanti, T. (1993). Surround-screen projection-based virtual reality: the design and implementation of the CAVE. In Proceedings of Annual Conference on Computer Graphics and Interactive Techniques - SIGGRAPH’93 (pp. 135–142). New York: ACM Press.\n\nDisplacements (2005). Michael Naimark: Interactive and Immersive Film Environments, 1977–1997. An Exhibition at Annual Conference on Computer Graphics and Interactive Techniques – SIGGRAPH’05. Retrieved September 20, 2006, from http://www.siggraph.org/s2005/main.php?f=conference&p=art&s=outreach\n\nDrettakis, G., Roussou, M., Tsingos, N., Reche, A., & Gallo, E. (2004). Image-based Techniques for the Creation and Display of Photorealistic Interactive Virtual Environments. In Proceedings of the 10th Eurographics Symposium on Virtual Environments – EGVE’04 (pp. 157–166).\n\nDutson, A., & Wood, K. (2005). Using rapid prototypes for functional evaluation of evolutionary product designs. Rapid Prototyping Journal, 11 (3), 125-11.\n\nEvans, M., Wallace, D., Cheshire, D., & Sener, B. (2005). An evaluation of haptic feedback modelling during industrial design practice. Design Studies, 26,487-508.\n\nFakeSpace (2006). CAVE: The Most Widely Installed Fully Immersive Visualization System in the World. Retrieved September 20, 2006, from https://web.archive.org/web/20080108092841/http://www.fakespace.com/cave.htm\n\nFischer, J., Bartz, D., & Straßer, W. (2006). Enhanced Visual Realism by Incorporating Camera Image Effects. In Proceedings of International Symposium on Mixed and Augmented Reality - ISMAR’06. Washington: IEEE Computer Society Press.\n\nGibson, I., Gao, Z., & Campbell, I. (2004). A Comparative Study of Virtual prototyping and Physical Prototyping. International Journal of Manufacturing Technology and Management, 6(6), 503-522.\n\nHirooka, S., & Saito, H. (2006). Calibration Free Virtual Display System Using Video Projector onto Real Object Surface. IEICE-Transactions on Info and Systems - Special Section on Artificial Reality and Telexistence, E89-D(1), 88-97.\n\nHoffman, H., Garcia-Palacios, A., Carlin, C., Furness, T., Botella-Arbona, C. (2003). Interfaces that heal: Coupling real and virtual objects to cure spider phobia. International Journal of Human-Computer Interaction, 16, 283-300.\n\nIchida, H., Itoh, Y., Kitamura, Y., & Kishino, F. (2004). ActiveCube and its 3D Applications. In Proceedings of IEEE Virtual Reality Conference – VR’04. Washington: IEEE Computer Society Press.\n\nIshii, H., & Ullmer, B. (1997). Tangible Bits: Towards Seamless Interfaces between People, Bits and Atoms. In Proceedings Conference on Human Factors in Computing Systems – CHI-97 (pp. 234–241). New York: ACM Press.\n\nIshii, H., & Ullmer, B. (2001). Emerging Framework for Tangible User Interfaces. In J. Carroll (Eds.), Human-Computer Interaction in the New Millennium (pp. 579–601). Addison-Wesley.\n\nJacucci, G., Oulasvirta, A., Psik, T., Salovaara, A., & Wagner, I. (2005). Augmented reality painting and collage: Evaluating tangible interaction in a field study. In Proceedings of Tenth IFIP-TC13 International Conference on Human-Computer Interaction INTERACT'05 (pp. 43–56).\n\nKeller, I., & Stappers, P. (2001). TRI: Inspiration Support for a design studio environment. International Journal of Design Computing, 3, 1-17.\n\nKhoudja M., Hafez M., & Kheddar A. (2004). Tactile Interfaces. A State of the Art Survey. In Proceedings of 35th International Symposium on Robotics (pp. 721–726).\n\nKölsch, M., Bane, R., Höllerer, T., & Turk, M. (2006). Multimodal interaction with a wearable augmented reality system. IEEE Computer Graphics and Applications, 26(3), 62 -71.\n\nLee, S., Chen, T., Kim, J., Han, S., & Pan, Z. (2004). Affective Property Evaluation of Virtual Product Designs. In Proceedings of IEEE Virtual Reality Conference – VR’04 (pp. 207–216). Washington: IEEE Computer Society Press.\n\nLee, W., & Park, J. (2006) Augmented Foam: Touchable and Graspable Augmented Reality for Product Design Simulation. Bulletin of Japanese Society for the Design Science, 52(6), 17-26.\n\nLiljegren, G., & Foster, E. (1990). Figure with Back Projected Image Using Fibre Optics. US Patent # 4,978.216, Walt Disney Company, Burbank California, USA, December 18, 1990.\n\nLonghurst, P., Ledda, P., & Chalmers, A. (2003). Psychophysically based artistic techniques for increased perceived realism of virtual environments, In Proceedings of Proceedings of the 4th International Conference on Computer Graphics, Virtual Reality, Visualisation and Interaction in Africa - AFRIGRAPH '03 (pp. 123–132). New York: ACM Press.\n\nMilgram, P., & Kishino, F. (1994). A taxonomy of mixed reality visual displays. IEICE Transactions on Information and Systems Special Issue on Networked Reality (E77D), 12, 1321-1329.\n\nNaimark, M. (2005). Two Unusual Projection Spaces. Presence: Teleoperators and Virtual Environments, Special Issue on Projection, 14(5), 597-506.\n\nNaimark, M. (1984). ‘Displacements’. An exhibit at San Francisco Museum of Modern Art. Retrieved September 20, 2006, from http://www.naimark.net/projects/displacements.html.\n\nNam, T. (2005). Sketch-Based Rapid Prototyping Platform for Hardware-Software Integrated Interactive Products. In Proceedings of the Third Symposium on Applied Perception in Graphics and Visualization at SIGGRAPH – APGV’05 (pp. 1689–1692). New York: ACM Press.\n\nNam. T. (2006). Sketching for Hardware Software Integrated Interactive Product Design. In Proceedings Conference on Human Factors in Computer Systems - CHI’06, Workshop on “Sketching\" Nurturing Creativity: Commonalities in Art, Design, Engineering and Research. New York: ACM Press.\n\nNam, T., & Lee, W. (2003). Integrating hardware and software: augmented reality based on prototyping method for digital products. In Proceedings of Conference on Human Factors in Computing Systems CHI’03 (pp. 956–957). New York: ACM Press.\n\nNi, T., Schmidt, G., Staadt, O., Livingston, M., Ball, R., &\nMay, R. (2006). A Survey of Large High-Resolution Display Technologies, Techniques, and Applications. In Proceedings of IEEE Virtual Reality Conference – VR’06 (pp. 223–236). Washington: IEEE Computer Society Press.\n\nRademacher, P., Lengyel, J., Cutrell, E., & Whitted, T. (2001). Measuring the perception of visual realism in images. In Proceedings of the 12th Eurographics Workshop on Rendering Techniques (pp. 235–248). Springer.\n\nRaskar, R., Welch, G., Low K., & Bandyopadhyay, D. (2001). Shader Lamps: Animating Real Objects With Image-Based Illuminations. In Proceedings of the 12th Eurographics Workshop on Rendering Techniques (pp. 89–102). Springer.\n\nSaakes, D. (2006). Material light: exploring expressive materials. Personal Ubiquitous Computing, 10(2), 144-147.\n\nSenckenberg Museum (2006). Senckenberg Museum - Dinosaur Fossil Exhibit. Retrieved September 20, 2006, from http://www.edt2006.org/media/oliver/EDT06-print-noanim-compress.pdf#search=%22A%20Virtual%20Color%20Reconstruction%20System%20for%20Real%20Heritage%20with%20Light%20Projection%22\n\nStanney, K., Samman, S., Reeves, L., Hale, K., Buff, W., Bowers, C., Goldiez, B., Nicholson, D., & Lackey, S. (2004). A paradigm shift in interactive computing: Deriving multimodal design principles from behavioural and neurological foundations. International Journal of Human-Computer Interaction, 17(2), 229-257.\n\nStevens, B., Jerrams-Smith, J., Heathcote, D., & Callear, D. (2002). Putting the Virtual into Reality: Assessing Object-Presence with Projection-Augmented Models. Presence: Teleoperators and Virtual Environments, 11(1), 79-92.\n\nUmemoro, H., Keller, I., & Stappers, P. (2003). More light on your table: Table-sized Sketchy VR in support of fluid collaboration. In Proceedings of the 6th Asian Design International Conference.\n\nVerlinden, J., Horváth, I., & Edelenbos, E. (2006). Treatise of technologies for interactive augmented prototyping. Proceedings of the 7th International Symposium on Tools and Methods of Competitive Engineering – TMCE’06. Rotterdam: Millpress.\n\nWhitton, M., Lok, B., Insko, B., & Brooks, F. (2005). Integrating Real and Virtual Objects in Virtual Environments – Invited Paper. In Proceedings of HCI International Conference.\n\nBennett, E., & Stevens, B. (2006). The effect that the visual and haptic problems associated with touching a Projection Augmented model have on object-presence. Journal of Presence: Teleoperators and Virtual Environments, special edition of the best papers from the International Presence Conference, 15(4), 419-437, MIT Press.\n\nBennett, E., & Stevens, B. (2006). The ‘Detection, Perception and Object-Presence framework’: A unified structure for investigating illusory representations of reality. In Proceedings of SIGGRAPH’s Computer Graphics and Applied Perception Symposium.\n"}
{"id": "36477635", "url": "https://en.wikipedia.org/wiki?curid=36477635", "title": "Qiu Shi Science and Technology Prize", "text": "Qiu Shi Science and Technology Prize\n\nQiu Shi Prizes are awarded on an annual basis in recognition of advances in science and technology. The Qiu Shi Science and Technology Foundation was established by Mr. Cha Chi Ming 查濟民 (1914-2007) in 1994 in Hong Kong, with the intention of promoting science and technology research in China, and to encourage and reward successful Chinese scientists and scholars. Prizes are awarded each year Prize categories include Physics, Chemistry, Physiology or Medicine, Mathematics or Information Technology.\n\nQiu Shi (Chinese: 求是； pinyin Qiu2 shi4; pronounced ch-OO/sh-ER) means “seeking truth”. The Qiu Shi Foundation was named after the famous Qiu Shi Academy (求是书院) in Hangzhou, which was subsequently renamed Zhejiang University 浙江大学. Qiu Shi Science and Technology Foundation is not related to the Qiushi Journal, the political theory periodical.\n\nCha Chi-ming, GBM, JP, was born in 1914, in Haining County, Jiaxing, Zhejiang province. He studied textile technology and graduated from Zhejiang University in 1931. Cha was best known for his industrial prowess, building a multinational textile conglomerate. He was the chairman of CDW International Limited, The Mingly Corporation Limited and Hong Kong Resort International Limited.\n\nMembers:\n\nChen Ning Yang (a Nobel laureate in physics),\nZhou Guangzhao (physician, and honorary chairman of China Association for Science and Technology),\nYuan T. Lee (a Nobel laureate in chemistry),\nYuet Wai Kan (genetic researcher),\nDavid Ho (physician and innovator of the \"cocktail\" therapy for HIV),\nAndrew Yao (computer scientist and the first Asian A.M. Turing Award recipient).\n\nAlumni\n"}
{"id": "23531710", "url": "https://en.wikipedia.org/wiki?curid=23531710", "title": "Railway archaeology", "text": "Railway archaeology\n\nRailway archaeology is the study and enjoyment of relics from past eras of rail transportation (including railways and tramways of all gauges and sizes). The aim of railway archaeology is to learn about the history and see images of the previous appearance of a defunct rail system that became redundant or abandoned and to enjoy searching out these remains and exploring them.\n\nRailway archaeology comes under the general ambit of the study of the industrial past and therefore is a sub-set of Industrial archaeology.\n\nThe Railway Archaeological Society, a UK-based group that seems to be defunct.\n\nLight Railway Research Society of Australia is an Australian-based society that was formed in 1961 to promote interest in special-purpose railways. Much of its members' work would fall into the category of Railway archaeology.\n\n\n\n"}
{"id": "11486445", "url": "https://en.wikipedia.org/wiki?curid=11486445", "title": "Railway costing", "text": "Railway costing\n\nRailway costing is the calculation of the variable and fixed costs of rail movements. Variable costs are those that increase or decrease with changes in the traffic volumes or service levels and include fuel, maintenance and train crew costs, for example. Fixed costs are normally associated with items such as head office, interest charges and other overhead. Unit costs can then be calculated based on the expenses of the railway divided into standard categories.\n\nIn order to assist in its deliberations regarding rate and service complaints, the Canadian Transportation Agency has identified various types of costs. These costs include: \n\n\nThe methodology used in railway costing breaks down the costs of rail traffic to their unit value and from there determines their relationship to traffic handled and service provided. Therefore, as traffic and services change, the effect of these changes can be estimated from the unit values previously determined. The costing model methodology allows for variable costs to increase as traffic increases, whereas the fixed costs will remain constant, regardless of the overall level of traffic.\n\nRailway costing is typically performed using mathematical models. Using unit costs from current operating data and current accounting and operating information, it is possible to develop costing information for the railway. This costing information may be used to estimate the operating cost of a new line and to determine whether it is economically viable. Alternatively, the model could be used to estimate the cost effects of changing speed limits along a route. The savings that can be achieved with a railway costing model are endless. For example, by knowing the costs of doing business, a railway can appropriately determine the tariffs to be charged.\n\nIn addition, railway costing models typically handle passenger and freight traffic, making them applicable in more situations, including mixed traffic situations.\n\nsome commercial variations of railway costing models have been implemented, including the OSCAR railway costing model developed by CPCS Transcom Limited. CPCS is an international infrastructure development firm and has successfully used this model in dozens of its projects worldwide.\n\nThe Cartage railway costing model was developed by Vectorail, a global supplier of railway costing solutions with more than forty years of experience in the field.\n\n"}
{"id": "35393043", "url": "https://en.wikipedia.org/wiki?curid=35393043", "title": "Richard Goldstein (astronomer)", "text": "Richard Goldstein (astronomer)\n\nRichard M. \"Dick\" Goldstein (born April 1927) is an American radar astronomer and planetary scientist, who has been called \"The Father of Radar Interferometry.\"\n\nRichard Goldstein was born in Indianapolis, Indiana. He studied Electrical Engineering at Purdue. After working at his family furniture store for eleven years, he followed his brother (astronomer Samuel J. Goldstein, Jr.) to California and NASA's Jet Propulsion Laboratory. He is married to Ruth Goldstein (née Lowenstam).\n\nAs a graduate student at Caltech in 1961, Goldstein used the antenna at the Goldstone Tracking Station to obtain the first realtime radar echos from the planet Venus. By 1963, Goldstein and co-author had measured the period and retrograde rotation of Venus. Using his same techniques, he confirmed Soviet experiments that acquired radar echoes from Mercury and he was first to obtain echos from Mars in 1963. In 1968, Goldstein was the first to obtain a radar echo from an asteroid, when he measured the radar cross section of Icarus. Later he also measured the size and rotational period of the nucleus of a comet.\n\nIn 1964, Goldstein had analyzed the spectrum of radar echos from Venus to obtain the first images of features on the surface of that planet. Later, using range-Doppler and radar interferometric techniques, he was able to create some of the first maps of the planet. Goldstein was also first to get echos from Ganymede and later other moons of Jupiter. He also detected Saturn’s rings using radar.\n\nGoldstein began work in the mid 1980s on topographical mapping techniques using synthetic aperture radar. Initially using two antennas (and later a single antenna with a repeated track), he was able to use the phase interferometry to improve over stereoscopic optical mapping techniques. Goldstein then developed his revolutionary \"crabgrass growing\" algorithm for phase unwrapping, which resolves ambiguities in phase data and isolates local noise and errors that would otherwise cause global errors. This algorithm simplified the creation of accurate elevation maps, and made possible many new applications for radar interferometry, including satellite detection and quantification of small changes such as land subsidence, ice flow motion, ocean currents, and geological fault shifts. Subsequent work includes algorithms for mitigating thermal noise in the phase data, yielding dramatic improvements in the quality of measurement and phase data.\n\nIn the 1990s, Goldstein also worked on applying radar techniques for detecting orbital debris. Previous radar approaches were able to detect orbiting objects as small as 5mm. By using short wavelength pulses and a separate antenna to detect echos, Goldstein was able to improve the detection of objects to less than 2mm at a 600 km altitude. In the process, he discovered that the Earth has rings of debris (some apparently left over from the West Ford Project). He has continued to refine the technique, extending the capabilities to detect 3mm objects as far away as 3200 km.\n\nGoldstein is a regular participant and frequent award-winner in the annual JPL Invention Challenge.\n\nNASA Honors Award, Exceptional Engineering Achievement Medal, 2000\n\nAsteroid 5393 named 5393 Goldstein\n"}
{"id": "26779790", "url": "https://en.wikipedia.org/wiki?curid=26779790", "title": "Satellite emergency notification device", "text": "Satellite emergency notification device\n\nA Satellite Emergency Notification Device or SEND is a portable emergency notification and locating device which uses commercial satellite systems rather than the COSPAS-SARSAT satellite system. An example of this device is SPOT.\n\nThe devices use an internal GPS chip to gather location information. When the SEND is triggered, this information is sent via commercial satellite to a commercial monitoring agency whose role is to pass the information to an appropriate responding agency. The responding agency contacted depends, in part, on the location. Examples of responding agencies would be military Search and Rescue, Coast Guard, local police, voluntary Search and Rescue.\n\nTypical users/purchasers of these devices are participants in activities such as hiking, mountain biking, climbing, boating and flying. They are also useful for those who work in remote areas (loggers, foresters, geologists, fisheries and wildlife staff).\n\nAdditional features are increasingly being offered: sending preprogrammed messages, breadcrumb tracking via Google Earth. Some newer devices offer two-way communication via satellite, for example DeLorme's inReach Communicator and the Yellowbrick 3 Messenger/Tracker.\n\nThe considerations when buying them, is ensuring that the International Emergency Response Coordination Centre (IERCC) which receives a distress call maintains an accurate and up-to-date database of response agencies to contact and can quickly determine which is appropriate to the situation/location. The commercial, IERCC is GEOS, used by both SPOT and DeLorme SENDs.\n\nThe US Coast Guard's National Search and Rescue Committee (NSARC) set up a working group which includes representation from other US agencies, international organizations and device manufacturers to discuss how these \"technologies can be properly reviewed and integrated with the SAR response system in the United States\" and to aid the Radio Technical Commission for Maritime Services (RTCM) in \"development of a minimum operating and performance specification for such devices\". The RTCM working group SC has completed and approved a standard for Emergency Satellite Notification Systems, which was published in August 2011.\n\nBriarTek was granted a US Patent on August 2, 2011 for a \"Global Birectional Locator Beacon and Emergency Communications System\", which covers SENDs with Receive / Transmit capabilities such as the DeLorme inReach unit.\n\ninReach, like SPOT, does not use the 406 MHz signal nor the system of satellites. Instead, it depends on the Iridium satellite system. Unlike SPOT, inReach is a two way system capable of receiving confirmation that the message was received. Like SPOT, the message is transmitted to the private GEOS International Emergency Response Center who then notifies the appropriate SAR authorities.\n\ninReach also provides tracking capability and two way SMS text messages.\n\nSPOT does not use the 406 MHz signal nor the system of satellites. Instead, it depends on the GlobalStar satellite system. It has richer features (for instance, can send many non-emergency signals) - but it does not work in as many places as 406 MHz PLBs - for instance under dense forest canopy or steep canyons. When a user presses the \"911\" button on a SPOT device an emergency message containing the unit's identification and GPS location is transmitted to the GEOS International Emergency Response Center who then notifies the appropriate emergency agency for the region after first calling the user to ensure the transmission is not accidental.\n\nSPOT additionally has the ability to provide non-emergency web based tracking information. This allows family or friends at home to track the holder's progress. The tracking operates by sending a tracking signal to the GlobalStar network every 10 minutes. This feature can additionally be useful to provide location of an individual even if the individual is unable to activate the emergency '911' button.\n\nTypical costs are $169 plus a $99/year service fee for basic services or $150/yr for basic services and tracking services, as compared to around $250 for a 406-MHz PLB with no service fee.\n\nYellowbrick, like SPOT, does not use the 406 MHz signal nor the system of satellites. Instead, it depends on the Iridium satellite system. Unlike SPOT, Yellowbrick is a two way system capable of receiving confirmation that the message was received and exchange two-way messages via short emails and SMS. Alert messages are transmitted to destinations specified by the owner.\n\n\n"}
{"id": "4107858", "url": "https://en.wikipedia.org/wiki?curid=4107858", "title": "Semiconductor fabrication plant", "text": "Semiconductor fabrication plant\n\nIn the microelectronics industry a semiconductor fabrication plant (commonly called a fab; sometimes foundry) is a factory where devices such as integrated circuits are manufactured.\n\nA business that operates a semiconductor fab for the purpose of fabricating the designs of other companies, such as fabless semiconductor companies, is known as a foundry. If a foundry does not also produce its own designs, it is known as a pure-play semiconductor foundry.\n\nFabs require many expensive devices to function. Estimates put the cost of building a new fab over one billion U.S. dollars with values as high as $3–4 billion not being uncommon. TSMC invested $9.3 billion in its \"Fab15\" 300 mm wafer manufacturing facility in Taiwan. The same company estimations suggest that their future fab might cost $20 billion. \n\nThe central part of a fab is the clean room, an area where the environment is controlled to eliminate all dust, since even a single speck can ruin a microcircuit, which has features much smaller than dust. The clean room must also be damped against vibration and kept within narrow bands of temperature and humidity. Controlling temperature and humidity is critical for minimizing static electricity.\n\nThe clean room contains the steppers for photolithography, etching, cleaning, doping and dicing machines. All these devices are extremely precise and thus extremely expensive. Prices for most common pieces of equipment for the processing of 300 mm wafers range from $700,000 to upwards of $4,000,000 each with a few pieces of equipment reaching as high as $130,000,000 each (e.g. steppers). A typical fab will have several hundred equipment items.\n\nTypically an advance in chip-making technology requires a completely new fab to be built. In the past, the equipment to outfit a fab was not very expensive and there were a huge number of smaller fabs producing chips in small quantities. However, the cost of the most up-to-date equipment has since grown to the point where a new fab can cost several billion dollars.\n\nAnother side effect of the cost has been the challenge to make use of older fabs. For many companies these older fabs are useful for producing designs for unique markets, such as embedded processors, flash memory, and microcontrollers. However, for companies with more limited product lines, it's often best to either rent out the fab, or close it entirely. This is due to the tendency of the cost of upgrading an existing fab to produce devices requiring newer technology to exceed the cost of a completely new fab.\n\nThere has been a trend to produce ever larger wafers, so each process step is being performed on more and more chips at once. The goal is to spread production costs (chemicals, fab time) over a larger number of saleable chips. It is impossible (or at least impracticable) to retrofit machinery to handle larger wafers. This is not to say that foundries using smaller wafers are necessarily obsolete; older foundries can be cheaper to operate, have higher yields for simple chips and still be productive.\n\nThe current, as of 2014, state-of-the-art for wafer size is 300 mm (12 in). The industry is aiming to move to the 450 mm wafer size by 2018. As of March 2014, Intel expects 450 mm deployment by 2020. Additionally, there is a large push to completely automate the production of semiconductor chips from beginning to end. This is often referred to as the \"lights-out fab\" concept. \n\nThe International Sematech Manufacturing Initiative (ISMI), an extension of the US consortium SEMATECH, is sponsoring the \"300 mm Prime\" initiative. An important goal of this initiative is to enable fabs to produce greater quantities of smaller chips as a response to shorter lifecycles seen in consumer electronics. The logic is that such a fab can produce smaller lots more easily and can efficiently switch its production to supply chips for a variety of new electronic devices. Another important goal is to reduce the waiting time between processing steps.\n\n\n\n\n"}
{"id": "2601173", "url": "https://en.wikipedia.org/wiki?curid=2601173", "title": "Short Message service center", "text": "Short Message service center\n\nA Short Message Service Center (SMSC) is a network element in the mobile telephone network. Its purpose is to store, forward, convert and deliver Short Message Service (SMS) messages.\n\nThe full designation of an SMSC according to 3GPP is \"Short Message Service - Service Center (SMS-SC).\"\n\nBasic Trajectories of SMS are\n\nThe tasks of an SMSC can be described as\n\nWhen a user \"sends\" a text message (SMS message) to another user, the message gets stored in the SMSC (short message service centre), which delivers it to the destination user when they are available. This is a store and forward option.\n\nAn SMS centre (SMSC) is responsible for handling the SMS operations of a wireless network. \n\n\nSMSCs can be used to interface with other applications, for example a spreadsheet can interface with the SMSC allowing messages to be sent SMS from an Excel spreadsheet, or to send an SMS from Excel. Inbound messages to a long number or short code can also be passed through the SMSC allowing m2m communications or Telematics.\n\nAn SMS message is stored temporarily in the SMS center if the recipient mobile phone is unavailable. It is possible on most mobile handsets to specify an expiry period after which the SMS message will be deleted from the SMS center. Once deleted, the SMS message will no longer be available for dispatch to the recipient mobile phone (even if it comes on line). The validity period should be regarded by the handset user as a request, as the SMSC itself can be configured to ignore or otherwise handle message delivery schedules.\n\nThe SMS sender needs to set a flag in the SMS message to notify the SMS centre that they want the status report about the delivery of this SMS message. This is usually done by changing a Setting on the mobile handset.\n\n"}
{"id": "2823731", "url": "https://en.wikipedia.org/wiki?curid=2823731", "title": "Simulated pregnancy", "text": "Simulated pregnancy\n\nA simulated pregnancy is a deliberate attempt to create the impression of pregnancy.\n\nIt should not be confused with false pregnancy, where a person mistakenly believes that they are pregnant.\n\nPeople who wish to \"look\" pregnant, generally for social, sexual, entertainment, or psychological purposes, have the option of body suits and the like to wear under their clothes. It can be done by using pillows or pads, or light-weighing, small balls with a round shape to simulate a pregnant abdomen. A common practice is to place a form replicating a belly (rolled up clothes, deflated ball, etc.) under a skin colored, tight bodysuit. This creates a realistic color and shape.\n\nThe reasons for a person to desire a simulated pregnancy vary greatly from one individual to another. It could be an intellectual curiosity, a cosmetic effect or social experiment, an erotic or sexual experience, or part of a larger psychological issue. A simulated pregnancy may in some cases be a manifestation of factitious disorder.\n\n"}
{"id": "23008710", "url": "https://en.wikipedia.org/wiki?curid=23008710", "title": "Snoot", "text": "Snoot\n\nIn photography, a snoot is a tube or similar object that fits over a studio light or portable flash and allows the photographer to control the direction and radius of the light beam. These may be conical, cylindrical, or rectangular in shape. Snoots can isolate a subject when using a flash. They help by stopping \"light spill\", or when lighting falls in a larger footprint than intended.\n\n"}
{"id": "3459188", "url": "https://en.wikipedia.org/wiki?curid=3459188", "title": "Sony Watchman", "text": "Sony Watchman\n\nThe Sony Watchman is a line of portable pocket televisions trademarked and produced by Sony. The line was introduced in 1982 and discontinued in 2000.\n\nThe initial model was introduced in 1982 as the FD-210, which had a grayscale five centimeter display. The device weighed around 650 grams, with a measurement of 87 x 198 x 33 millimeters. The device was sold in Japan with a price of 54,800 yen. Roughly two years later, in 1984, the device was introduced to Europe and North America.\n\nSony manufactured more than 65 models of the Watchman before its discontinuation in 2000. Upon the release of further models after the FD-210, the display size increased, and new features were introduced. The FD-3, introduced in 1987, had a built-in digital clock. The FD-30, introduced in 1984 had a built-in AM/FM Stereo radio. The FD-40/42/44/45 were among the largest Watchmen, utilizing a 4\" CRT display. The FD-40 introduced a single composite A/V input. The FD-45, introduced in 1986, was water-resistant. In 1988/1989, the FDL 330S color Watchman TV/Monitor with LCD display was introduced. In 1990, the FDL-310, a Watchman with a color LCD display was introduced. The FD-280/285, made from 1990 to 1994, was the last Watchman to use a black and white CRT display. One of the last Watchmen was the FDL-22 introduced in 1998, which featured an ergonomic body which made it easier to hold, and introduced Sony's \"Straptenna\", where the wrist strap served as the antenna.\n\nDue to the switch of television broadcasts to digital, most models of the Sony Watchman have lost their usefulness, because they now require to be connected to a digital converter box.\n\nA model of the Sony Watchman is seen multiple times in the film Rain Man.\n\n"}
{"id": "52780566", "url": "https://en.wikipedia.org/wiki?curid=52780566", "title": "Tuniu", "text": "Tuniu\n\nTuniu Corporation () is a Chinese online travel agency. Products and services include packaged tours, accommodation reservation, airline and railway ticketing, car rentals, and corporate travel. The company listed on the Nasdaq Stock Exchange on May 9, 2014. The company headquarters are located in Nanjing with offices in Shanghai and Beijing.\n\nFounded in 2006 in Nanjing by current CEO Donald Dunde Yu and current COO Alex Haifeng Yan, the company was fully incorporated on June 1, 2008.\n\nOn May 9, 2014, Tuniu was listed on the Nasdaq Stock Exchange under TOUR, co-managed by Morgan Stanley & Co, Credit Suisse Securities LLC and China Renaissance Securities. Tuniu raised $72 million in its initial public offering, pricing 8 million shares at $9 per share. CEO Donald Dunde Yu rang the opening bell at the Nasdaq MarketSite in Times Square.\n\nIn April 2015, Tuniu was the subject of a boycott by seventeen Chinese travel agencies over a pricing dispute. The issue was settled a few days later following an investigation by the China National Tourism Administration, with partner relations returning to normal. Tuniu's share price fell 4.7% following news of the dispute.\n\nOn August 23, 2016, Tuniu’s Board of Directors authorized a share repurchase program to repurchase up to $150 million worth of shares. Tuniu’s share price had fallen below opening price.\n\nOn July 1, 2014, Ctrip CEO James Jianzhang Liang was appointed to Tuniu’s Board of Directors. On December 10, 2014, Tuniu and Ctrip signed a strategic collaboration agreement to share travel resources.\n\nOn December 15, 2014, Tuniu announced $148 million investment in aggregate from a group that included the investment arms of Hony Capital, JD.com, Ctrip Investment Holding Ltd, and the personal holding companies of Tuniu’s CEO and COO. Ctrip acquired $15 million Tuniu shares during their IPO, and currently owns over 3% of Tuniu’s outstanding shares.\n\nIn May, 2015, Tuniu announced the investment of $500 million from a group of investors led by JD.com. JD.com became the largest shareholder in Tuniu with 27.5% stake.\n\nOn March 9, 2015, Tuniu announced the acquisition of majority stakes in two Chinese travel agencies, Hangzhou-based Zhejiang Zhongshan International Services and Tianjin-based China Classical Holiday.\n\nOn January 21, 2016, Tuniu announced the completion of a US$500 million investment from HNA Tourism Group. Transaction purchase price was US$5.50 per Class A ordinary share. HNA Tourism Group bought 24.1% share of Tuniu.\n\nIn July 2016, Tuniu announced the signing of Taiwanese pop stars Jay Chou and Jimmy Lin as its celebrity brand ambassadors.\n\n"}
{"id": "29313782", "url": "https://en.wikipedia.org/wiki?curid=29313782", "title": "Turn-by-turn navigation", "text": "Turn-by-turn navigation\n\nTurn-by-turn Navigation is a feature of some GPS navigation devices where directions for a selected route are continually presented to the user in the form of spoken or visual instructions. The system keeps the user up-to-date about the best route to the destination, and is often updated according to changing factors such as traffic and road conditions. Turn-by-turn systems typically use an electronic voice to inform the user whether to turn left or right, the street name, and how much distance to the turn.\nMathematically, turn by turn navigation is based on the shortest path problem within graph theory, which examines how to identify the path that best meets some criteria (shortest, cheapest, fastest, etc.) between two points in a large network.\n\nMajor mapping services that offer turn-by-turn navigation, grouped by map data provider:\n"}
{"id": "26185098", "url": "https://en.wikipedia.org/wiki?curid=26185098", "title": "University18 Business School", "text": "University18 Business School\n\nUniversity18 Business School is a 'not for profit' Online Management Education Institution based out of India.\n\nA collaboration between the Sampuran Prakash Foundation and University18, UBS in partnership with the Karnataka State Open University, India, provides accredited post graduate degree programs to working professionals and other distance learners.\n\nSet up in 2009, UBS currently offers the following MBA Programs:\n\nUBS has students from across the Indian Sub-Continent, besides America, the Middle East, United Kingdom, and Africa.\n\nKarnataka State Open University has been de-recognized and any admission after 2012 if considered to be in-valid. The related links can be found at the end of the page.\n\n\n"}
{"id": "57481189", "url": "https://en.wikipedia.org/wiki?curid=57481189", "title": "Viscous damping", "text": "Viscous damping\n\nViscous damping force is a formulation of the damping phenomena, in which the source of damping force is modeled as a function of the volume, shape, and velocity of an object traversing through a real fluid with viscosity.\n\nTypical examples of viscous damping in mechanical systems include:\n\n"}
{"id": "14334912", "url": "https://en.wikipedia.org/wiki?curid=14334912", "title": "Visionarium (Portugal)", "text": "Visionarium (Portugal)\n\nVisionarium is a science museum with interactive displays in Portuguese and English covering subjects ranging from the Portuguese voyages of discoveries to the interiors of microchips and cells. It is located in Santa Maria da Feira, Portugal.\n\nClosed since April 2018\n\nIt was inspired on the \"Cité des Sciences et de l'Industrie\" (France) and the Exploratorium (USA).\n\nThe \"Visionarium — Centro de Ciência do Europarque\" is an interactive museum located in Espargo, Santa Maria da Feira, in its congressial perimeter Europarque, and is owned by \"Associação Empresarial de Portugal\" (Entrepreneurship Association of Portugal). Situated from only 15 minutes of Porto, it explains every detail about knowledge. With six divided rooms (odissey), an auditorium, it contains more than over 25.000 m2 of green space and services.\n\nVisionarium as a token of its outlooks won the \"European Museum of the Year Award\" from the \"European Museum Forum\" in 2000.\n\nIn 1999, RTP launched a 90 episodes mini-series containing its characters, with Portuguese voices.\nGoing years into the future, and they will appear on books.\n\nIn 2006, they launched a series of 12 books containing 12 CDs, with many of the mini-series shown, containing its characters.\n\nBut not only do they make experiences multimedia, they also make experiments in the outdoors.\nSince its launch, there have been made countless experiments and experiences whether they are on Summer vacation or where the kids are in classes.\nAll ages are suitable.\n\nThere are characters describing each part that the museum has:\n\nFrom the Universe Odyssey (a part of the museum in which it contains all the explanations of the Universe) is most described in which he appears in the books, which is only 2.\n\nFrom the Information Odyssey (a part of the museum in which it explains all technological explanations, and other stuff like speaking into a virtual character from a screen and seeing yourself on front) knows all the technological explanations like binary numbers.\n\nFrom the Matter Odyssey (a part of the museum in which it explains all molecular explanations) knows everything in this part.\nHe knows the periodic table even backwards and forwards.\n\nFrom the Life Odyssey (a part of the museum in which its explained the meanings of life and even other simple stuff of the human body) knows all explainable reasons, in here.\n\nFrom the Earth Odyssey (a part of the museum in which its known all of the Earth's history) knows everything in this manner.\n\nHe is the center of all of Visionarium's facility, since, he's never seen in any odyssey room, or since he's always seen (in books) in which you have to make experiments in your own house.\n\n"}
{"id": "2665777", "url": "https://en.wikipedia.org/wiki?curid=2665777", "title": "Zenrin", "text": "Zenrin\n\nZenrin's head office is in the Zenrin-Asahi Building at 1-1-1, Muromachi, Kokura-Kita Ward, Kitakyūshū. The building stands on the spot where noted Edo period mapmaker Inō Tadataka began his mapping of Kyūshū, in the midst of a modern shopping and cultural center called Riverwalk Kitakyushu. The company also has a development center (Techno Center) at Nakabaru Shinmachi 3-1, Tobata Ward, Kitakyushu.\n\nIn the U.S., Zenrin provides navigation software and expertise to Nissan North America, Honda's Internavi in car telematics service in Japan, and other automobile and navigation systems hardware manufacturers. Zenrin is also continuing to explore collaborative efforts with other electronic and auto manufacturers. Field research crews collect data throughout the United States, Canada, Mexico, Brazil, and survey businesses along America’s Interstate's to integrate into their navigation software and databases. Businesses, organizations, and travelers nationwide utilize this data in a variety of applications and settings.\n\nZenrin USA, Inc., located between San Francisco and Silicon Valley at 851 Traeger Avenue, Suite 210, San Bruno, CA, 94066 USA (650-615-4200).\n\nZenrin Europe GmbH, located in Münsterstr. 306, 40470 Düsseldorf, Germany (+49-211-369-780).\n\n has been the President and CEO of Zenrin Co. Ltd., since April 1, 2008. Mr. Takayama joined Zenrin Co. Ltd. in 1986 and has been its Director since 2006. He graduated from the Seinan Gakuen University.\n\nA map museum is located on the on 14th floor of the company’s home office building. It is open 10:00-17:00 weekdays, closed weekends and Japanese national holidays. Admission is ¥100.\n\n"}
