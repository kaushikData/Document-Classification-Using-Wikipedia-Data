{"id": "41763134", "url": "https://en.wikipedia.org/wiki?curid=41763134", "title": "Abel Assessment", "text": "Abel Assessment\n\nThe Abel Assessment for Sexual Interest (also Abel Assessment for Interest in Paraphilias) is an assessment test that purports to measure sexual interest in various subjects – and especially to measure a tendency toward pedophilia. The test was created by Dr. Gene G. Abel in 1995, and has been subsequently revised several times. It has been used as evidence in Northern America when prosecuting sex offenders, although its reliability has since been disputed and it has been declared inadmissible in court in various jurisdictions.\n\nThe Abel Assessment is controversial, because its results, although subjective, are presented as cut and dried. Some experts question its methodology.\n\nDespite the test's uncertainty, mental health professionals have used the Abel Assessment to civilly commit sex offenders.\n\nDr. Gene Abel began researching sexual interest in the early 1990s. It was reported that he previously used the penile plethysmograph before developing the Abel Assessment.\n\nIn the Abel Assessment, the subject is shown a series of slides in two separate processes. The first measures each slide's viewing time, determining the subject's reaction vis-à-vis the mean reaction. If the subject's viewing time is longer than the mean, it is said that he has a sexual interest in the image shown. For example, if the subject looks at children in bathing suits for longer than average, the Abel Assessment shows him as having an interest in children.\n\nDuring the second process, the individual must rate the images from 1 to 7, with 1 being revolting and 7 being sexually exciting.\n\nThe validity of the Abel Assessment has been questioned; it has struggled at times to pass the Daubert standard for admissibility in federal and state courts.\n\nIn 2002, the Abel Assessment was found to be inadmissible in court cases in Massachusetts, a ruling that was upheld by the Massachusetts Court of Appeals in 2005.\n\nThe validity of the test's methodology has been criticized. Abel is said to have exaggerated various statistics in order to prove his point. In the early 90s, he announced that he had figures suggesting sex offenders commonly have multiple paraphilias. However, Marshall and Eccles found in 1991 that he had not mentioned that he had concentrated on any offender reporting multiple deviant acts as more than one person. This greatly increased his findings.\n\nAbel made this assertion from the results of the report \"The Abel and Harlow Child Molestation Prevention Study\". The report was never subject to peer review or published in any professional journal. There is also no in-depth detail about his methodology available. The Abel Assessment is based on these findings.\n\nIn a 2002 decision on the admissibility of the test by Texas appellate judge Brian Quinn, the court said that since Abel's proprietary scoring methodology is not publicly known, it \"could be mathematically based, founded upon indisputable empirical research, or simply the magic of young Harry Potter's mixing potions at the Hogwarts School of Witchcraft and Wizardry\".\n\nAbel states in his book that a therapist can use the test as a tool to determine if a child is attracted to other children. The 9th Circuit Court of Appeals also ruled in 2004 that the Abel Assessment is a tool that is used only as treatment, and that it cannot detect whether a person has sexually abused children. Independent studies of the Abel Assessment have concluded it to be unreliable in adults and that there is not yet enough information to support its use with adolescents.\n\nThe Diana Screen is another test developed by Abel and his associates. It, too, has been a source of controversy for Abel due to it being a pass/fail test.\n\n"}
{"id": "56364466", "url": "https://en.wikipedia.org/wiki?curid=56364466", "title": "Allard Prize for International Integrity", "text": "Allard Prize for International Integrity\n\nThe Allard Prize for International Integrity is one of the world's largest prizes dedicated to the fight against corruption and the protection of human rights. The prize is awarded biennially to an individual, movement or organization that has \"demonstrated exceptional courage and leadership in combating corruption, especially through promoting transparency, accountability and the Rule of Law.\" The winner receives the Allard Prize Award, a uniquely crafted brass artwork, and CAD$100,000. Honourable mention recipients are awarded a unique nickel-plated artwork, and may also receive a cash award.\n\nAt the 2017 Award Ceremony, Pulitzer Prize-winning journalist Glenn Greenwald stated that the Allard Prize “is important … and isn't devoted just to honouring anti-corruption crusaders, but to constructing and fortifying a framework that really does protect them and enables the work to proceed much more safely,\" and \"this kind of courage can be very contagious.\" Past Allard Prize winners and others have said that the Allard Prize assists, supports and protects those working in anti-corruption and their work. Canada's National Observer calls The Allard Prize 'The Oscars of anti-corruption'.\n\nThe Allard Prize and Allard Prize Foundation, the charitable organization that supports the Allard Prize, were founded in 2011 and are funded by lawyer and businessman Peter A. Allard, Q.C.. The Allard Prize Committee is responsible for the oversight, organization and selection of the Prize winner and honourable mention recipients. The Prize is administered at the Peter A. Allard School of Law at the University of British Columbia, Vancouver, Canada.\n\nSome Allard Prize nominees and winners have previously been subjected to threats, violence, torture, imprisonment and other attacks associated with their anti-corruption and human rights activities. One honourable mention recipient, Russian lawyer Sergei Magnitsky, was nominated posthumously after being tortured to death in prison.\n\nThe Allard Prize winner and any honourable mention recipients are chosen through a comprehensive nomination and selection process involving the Allard Prize Committee, sub-committees and an Advisory Board. For the 2015 Allard Prize, over 140 people were nominated from 50 countries. In 2017, the number of nominations grew to 244 from 70 countries, with 42 nominations (17 percent) from North America.\n\nThere are no restrictions as to who may submit a nominee for consideration. Nominations may come from anywhere including from members of the Allard Prize Committee. Self-nominations are allowed for both individuals and organizations. Nominees range from neighbourhood activists to prominent world leaders, academics, social movements, political organizations and charitable groups.\n\nNominations are accepted on a rolling basis, with a new nomination cycle beginning with the announcement of finalists in the Prize year. Previously nominated candidates can be re-nominated, but new nomination forms must be submitted. There are no minimum or maximum age limits or any other limiting characteristics as to eligibility, with the exception that members of the Allard Prize Committee, Advisory Board and members of their immediate families may not be awarded the Allard Prize during their respective terms and for one year following the end of their terms.\n\nThe Allard Prize Committee reviews all nominations and is responsible for selecting the Prize winner and any honourable mention recipients. The selection process involves research, subcommittees and due diligence, two levels of short-listing, and a requirement to submit short-listed of nominees to the Allard Prize Advisory Board for review and comment prior to the selection of the winner and honourable mention recipients.\n\nThe 2015 and 2017 Allard Prize public awards ceremonies were held at the University of British Columbia's Old Auditorium and were live-streamed over the Internet.\n\nThe list of Allard Prize 'finalists' is released approximately one month prior to the Prize Ceremony. The public announcement identifying the Allard Prize winner is made at the Prize Ceremony, typically held in September or October of the award year. Finalists attend the ceremony in Vancouver, British Columbia, Canada, and become part of the growing Allard Prize anti-corruption network. Travel expenses are paid by the Allard Prize. Past award ceremony keynote speakers include Canadian diplomat Stephen Lewis (2013), Lieutenant-General Roméo Dallaire (2015) and Pulitzer Prize winning journalist Glenn Greenwald (2017).\n\nAs of 2017, the Allard Prize has been awarded to four individuals. Two organizations, one government office and three individuals (one posthumously) have received Honourable Mention.\n\nThe selection of Brazil's Car Wash Task Force (Operação Lava Jato) as a 2017 Allard Prize finalist triggered objections in Brazil and Canada. A group of Brazilian lawyers wrote to the Allard Prize Committee demanding the Committee rescind their finalist status and alleging \"numerous abuses, arbitrariness and legal violations\" by the Task Force. A group of University of British Columbia faculty and students supported the Brazilian lawyer group. During the September 28, 2017 Prize Ceremony, several audience members made vocal outbursts against the Car Wash Task Force.\n\nIn response, 2017 Allard Prize keynote speaker Glenn Greenwald said in his keynote address that while the Operation Car Wash Task Force had made some mistakes, powerful investigative work often creates controversy and enemies. In a post-award open discussion at the Allard School of Law, opponents confronted the Task Force's lead prosecutor Deltan Dallagnol with their criticisms, who responded during a recorded video session.\n\nShortly after the 2017 Allard Prize finalists were announced, journalist Russell Mokhiber noted in an article published in Corporate Crime Reporter that the Allard Prize has \"a bias in favour of anti-corruption fighters in the Third World\" rather than selecting nominees from Western developed countries. Mokhiber speculated that the bias might be due to a heavy representation of corporate lawyers, World Bank and Asian Development Bank personnel on the selection and advisory committees. In an interview with Mokhiber, Allard Prize Executive Director Nicole Barrett acknowledged that none of the previous finalists have been from North America. Noting that the majority of nominees are from the developing world, she said that the Allard Prize may consider developing a formal requirement of geographical balance to address this concern.\n\n"}
{"id": "30863737", "url": "https://en.wikipedia.org/wiki?curid=30863737", "title": "American Bar Association Model Rules of Professional Conduct", "text": "American Bar Association Model Rules of Professional Conduct\n\nThe ABA Model Rules of Professional Conduct, created by the American Bar Association (ABA), are a set of rules that prescribe baseline standards of legal ethics and professional responsibility for lawyers in the United States. They were promulgated by the ABA House of Delegates upon the recommendation of the Kutak Commission in 1983. The rules are merely recommendations, or models, (hence the name \"Model Rules\") and are not themselves binding. However, having a common set of Model Rules facilitates a common discourse on legal ethics, and simplifies professional responsibility training as well as the day-to-day application of such rules. , 49 states and four territories have adopted the rules in whole or in part, of which the most recent to do so was the Commonwealth of the Northern Mariana Islands in March 2015. California is the only state that has not adopted the ABA Model Rules, while Puerto Rico is the only U.S. jurisdiction outside of confederation has not adopted them but instead has its own \"Código de Ética Profesional\".\n\nThe American Bar Association is a private sector voluntary professional association. As such, it has no lawmaking power or regulatory authority, but it is just like any other nongovernmental bar association. Accordingly, the Model Rules are not legally binding on ABA members or within any particular jurisdiction. However, the Model Rules have been adopted, in whole or in part, and sometimes in variation, as the rules of professional conduct for attorneys in 49 states, the District of Columbia, and four of the five inhabited U.S. territories. The rules of professional conduct or professional responsibility adopted in a particular state \"are\" legally enforceable against the lawyers of that state as well as any lawyer practicing there on a \"pro hac vice\" basis.\n\nOn December 17, 2008, New York announced that it would finally abandon the old ABA Model \"Code\" of Professional Responsibility (the last state to do so) and adopt a heavily modified version of the ABA Model \"Rules\", effective April 1, 2009. New York's version of the Model Rules was created by adjusting the standard Model Rules to reflect indigenous New York rules that had been incorporated over the years into its version of the Model Code. Even though New York did not adopt the Model Rules verbatim, the advantage of adopting its overall structure is that it simplifies the professional responsibility training of New York lawyers, and makes it easier for out-of-state lawyers to conform their conduct to New York rules by simply comparing their home state's version of the Model Rules to New York's version.\n\nIn June 2009, the Supreme Court of Maine approved the adoption of the Model Rules in that state, effective August 1, 2009. Among the portions of the Model Rules that the Maine Rules of Professional Conduct do not include is Model Rule 1.8(j) (2002) categorically prohibiting sexual relations between lawyer and client.\n\nIn March 2015, the Supreme Court of the Commonwealth of the Northern Mariana Islands adopted its current \"Rules of Attorney Discipline and Procedure,\" which incorporates the ABA Model Rules by reference and expands upon them by adding another 22 local rules of professional conduct.\n\nCalifornia still has its own set of unique rules governing professional attorney conduct. Although many of the rules are similar and sometimes identical to the ABA Model Rules, the California rules differ markedly from the ABA models in both format, scope and content. For example, under the ABA Model Rules, an attorney may be disciplined for the \"appearance\" of impropriety, regardless whether any actual impropriety occurred; whereas the California rules permit discipline for only \"actual\" impropriety. This reflects the nature of California law.\n\nIt is unlikely that California will ever adopt the ABA Model Rules apart beyond harmonising the format and existing California rules that are identical or nearly identical to ABA Model Rules. Reasons for this reluctance include the fact there are more than 280,000 attorneys licensed in California, so a drastic change from the existing rules to completely different rules would shock the profession and, ultimately, would most likely fail. Additionally, many of California's rules of professional conduct are established by statute and, thus, would require action by the California Legislature to change them; or, alternatively, action by the people of California through the voter initiative process.\n\nAnother important factor is that the legal profession is regulated very differently in California than it is in the rest of the United States. Outside of California, the profession is regulated solely by the judicial branch of state government. Within California, the State Bar of California operates as a state government agency under the supervision of the California Supreme Court; but the State Bar was created by the California Legislature, and the Legislature has full power to regulate the legal profession, if it so wishes. In particular, the State Bar cannot collect annual member dues unless and until the California Legislature passes an annual State Bar Dues Bill, which the governor must sign into law. When Governor Pete Wilson vetoed the dues bill in 1997, the State Bar effectively shut down operations except for self-funded activities like the California Bar Exam. In 2010, Governor Arnold Schwarzenegger vetoed the dues bill but a crisis was averted on that occasion.\n\nBut the most important reason the California Bar is reluctant to adopt the ABA Model Rules is that most members believe the ABA Model Rules would not sufficiently protect the California public from harm. This is due to California law and public policy being so markedly different from the rest of the country in so many ways. For example, California is one of only four states where covenants not to compete are void as against public policy; and it is one of only three states where trusts are presumed to be revocable unless the trust instrument explicitly states the trust is irrevocable (whereas the opposite is true in the other 47 states).\n\nBy way of comparative example, California has long held the position that clients must be encouraged to speak candidly to their legal counsel about both past and future actions knowing their statements will be held in complete confidence. Their counsel can then explain the relevant law to them and urge them to conform their future conduct to the law, thus promoting lawful conduct. In contrast, ABA Model Rule 1.6 contains exceptions to confidentiality for both violent and nonviolent (e.g. financial) future crimes, which California believes creates a strong disincentive for clients to discuss their future plans with their attorneys - but for which the client might chose to comply with the law instead of violating it.\n\nAnother notable difference is that ABA Model Rule 1.8(j) contains an outright ban on sexual relations between attorney and client (unless the relationship predated the legal representation), while California Rule 3-120 only prohibits sexual relationships, that Require or demand sexual relations with a client incident to or as a condition of any professional representation; or, 2) Employ coercion, intimidation, or undue influence in entering into sexual relations with a client; or, 3) Continue representation of a client with whom the member has sexual relations if such sexual relations cause the member to perform legal services incompetently. The rule does not mention contracts for sexual services (i.e. prostitution) but as these contracts are criminally illegal in California, it is arguably not necessary to specify them.\n\nA third major difference is that ABA Model Rule 4.1 prohibits an attorney from making a \"false statement of material fact or law to a third person.\" While the ABA model expressly applies to \"any\" context in which a lawyer acts in a representative capacity, California Rule 5-200 prohibits an attorney only from making false statements before a court. \nIn 2001, the Commission for the Revision of the Rules of Professional Conduct of the State Bar of California began a comprehensive revision of the California rules that would, among other things, convert them into a localized version of the ABA Model Rules. However, the Commission's progress had been extremely slow, simply because there are so many substantive and structural differences between the California rules and the ABA models. In October 2010, the State Bar of California formally adopted the Commission's report, recommending adoption of 67 proposed changes to harmonise the California Rules of Professional Conduct with the ABA Model Rules of Professional Responsibility.\n\nOn September 19, 2014, however, for reasons that were not fully explained, the Supreme Court of California rejected all of the proposed revisions and returned them to the State Bar. The Court's letter directed the State Bar to start the process all over again with a new Commission, and to submit a new set of revised rules by March 31, 2017.\n\nExcept for the Patent Bar, there is no national legal profession in the United States but there are 56 separate legal professions. In contrast to most Commonwealth countries, where transactional lawyers and litigators are separately licensed as \"solicitors\" and \"barristers,\" respectively; all American attorneys are licensed to practice as both solicitors and barristers (therefore these terms are almost never used). Likewise, whereas solicitors in England and Wales are professionally self-regulated by the private-sector Law Society of England and Wales while barristers are self-regulated by the private-sector General Council of the Bar, attorneys in all states except California, all territories and the District of Columbia are generally regulated by the \"public sector\" judicial branch of state, district or territorial government, as officers of the court. The legal profession in California is regulated jointly by the California Supreme Court, mostly through its agency the State Bar of California and by the California Legislature, which exercises legislative control over all professions.\n\nWithin the public sector regulatory agencies, boards and organisations, officers are invariably licensed members of the pertinent profession while key managerial and general staff typically are not. The Executive Director and Deputy Executive Director of the State Bar of California, for example, are active members of the State Bar. While either of their secretaries \"could\" be a member of the State Bar, they most likely are not. Similarly, the Board of Trustees that oversee the business operations of the State Bar of California under supervision of the California Supreme Court is legally required to be a mix of attorneys licensed to practice in California and \"public members\" who may not be licensed attorneys.\n\nSo, while American attorneys are regulated by public sector agencies instead of private sector law societies, most of the people who develop the regulatory policies are practising attorneys and sitting judges, so there \"is\" a degree of self-regulation but not nearly to the same degree that solicitors and barristers in England and Wales, and other Commonwealth jurisdictions are self-regulated by private sector associations.\n\n\n"}
{"id": "6216698", "url": "https://en.wikipedia.org/wiki?curid=6216698", "title": "Androcide", "text": "Androcide\n\nAndrocide refers to the systematic killing of men, boys, or males in general.\n\"Androcide\" is a coordinate term of femicide and a hyponym of \"gendercide\". The etymological root of the hybrid word is derived from a combination of the Greek prefix \"andro\" meaning \"man\" or boy, with the Latin suffix \"cide\", meaning killing.\n\nIn the proactive scenario of human societies, androcide may be a deliberate goal, perhaps with the goal of degrading the offensive capabilities of an adversary. In a more passive scenario androcide has been likened to misandry when society in general participate or permit the decimation of a significant proportion of men and boys during conscriptions for military service. In fruit flies an androcidal animosity towards males may be due to rivalry, a perception of a challenge to their dominance or a combination of the two. Some organizations that are critical of feminism as well as some publishers have argued that the targeting of men is a contemporary issue in war. Androcide has also been a feature of literature in ancient Greek mythology and in hypothetical situations wherein there is discord between the sexes.\n\nWith regards to plants, androcide may refer to efforts to direct pollination through emasculating certain crops.\n\n"}
{"id": "3104813", "url": "https://en.wikipedia.org/wiki?curid=3104813", "title": "Anthony Sawoniuk", "text": "Anthony Sawoniuk\n\nAnthony Sawoniuk, formerly Andrei Andreeovich Sawoniuk (; 7 March 1921 – 6 November 2005) was a Belarusian Nazi collaborator from the town of Domaczewo in interwar Poland. \n\nAfter taking part in the murder of the Jewish community in his home town, Sawoniuk served in the SS until November 1944 when he defected to the Polish II Corps in the British Eighth Army. After the war, he settled in Britain, became a British subject, and became the first and only person to be convicted under the UK's War Crimes Act 1991, when he was found guilty of war crimes in 1999. He died in prison six years later, aged 84.\n\nAndrei Sawoniuk was born in Domaczewo, Poland (now Damachava, Belarus), a spa town on the Bug River. At that time 90% of the town's population were ethnic Jews, with the remainder being Poles, Ukrainians, Belorussians and German Volksdeutsche. Sawoniuk, nicknamed \"Andrusha\" (a Russian and Belarusian diminutive of Andrey), has been described as Belorussian, some newspaper reports say that his mother was Polish, Sawoniuk never knew the identity of his father, although townspeople believed him to be Josef Jakubiak, the town's Jewish schoolmaster, because his mother Pelagia had been working as a cleaner at Jakubiak's school and home during the months when Sawoniuk was conceived. Sawoniuk's half-brother Nikolai said to the British \"Daily Mail\" newspaper: \"People in the village said that my brother was the son of the schoolmaster. I think the same.\" Andrei used the patronymic \"Andreeovich\", which does not appear in the Polish language. His mother's former husband had also had the name Andrei.\n\nThe family were poor: his mother worked washing clothes while Sawoniuk and his half-brother collected firewood to sell. Sawonuik also worked as a sabbath goy: a gentile employed by Orthodox Jews to carry out Sabbath tasks that were forbidden to them, such as lighting fires or chopping wood. He learnt basic Yiddish from his employers.\n\nDuring World War II Sawonuik was a member of the local Nazi-supported Belarusian Auxiliary Police and rose to the rank of Commandant. While serving in the police he participated in the murdering of Jews.\n\nIn 1944 Sawoniuk fled westwards when the Red Army advanced towards Domaczewo and in July 1944 joined the German armed forces, serving in the 30th Waffen Grenadier Division of the SS. He deserted from the SS in November 1944 and changed sides, using his Polish birth certificate to join the 10th Hussar Regiment of the Polish II Corps.\n\nAfter the war Sawoniuk settled in England in 1946, posing as a Polish patriot. In 1951 he wrote a letter to his half-brother, Nikolai. The KGB, who already suspected him of being a war criminal, intercepted the letter and noted that he was now living in the UK. It was not until the 1980s that the KGB started sharing such information with the UK. However, even then, due to a misspelling of his name, it took until 1993 for authorities to realise that Sawoniuk, then working for British Rail, was one of the people on the KGB list and was duly arrested.\n\nSawoniuk had by that time become a British citizen. He was tried at the Old Bailey in London in 1999 on two specimen charges of murder with regard to the murder of Jews in his German-occupied hometown during World War II. The jury found him guilty of one charge by unanimous decision and of the other by a ten to one majority. A further two charges of murder were withdrawn by the prosecution due to procedural errors with evidence. However, both of the murders of which Sawoniuk was convicted were individual elements of two group murders: in the first Sawoniuk, according to eyewitnesses, shot 15 Jews; in the second he shot three Jews.\n\nAt his trial Sawoniuk said of his accusers \"They are professional liars. They have criminal records. Some of the witnesses at the magistrates court have done 25 years, alcoholics. I was the best friend of the Jews.\" He also stated that \"Everyone is telling lies. They have been told by the Russian KGB to say there was a ghetto. These devils came here with their lies against me.\" and \"I have done no crime whatsoever. My conscience is clear. I killed no one. I would not dream of doing it. I am not a monster I am an ordinary working-class poor man.\" He also denied having been a member of the German armed forces, stating \"I have never been in the German army\". In court, he accused a member of the Metropolitan Police of fabricating a Waffen-SS document which contained his details. He speculated that the Metropolitan Police had conspired against him with the help of the KGB.\n\nHe was given two life sentences and trial judge Mr Justice Potts recommended that Sawoniuk should spend the rest of his life in prison.\n\nHe was the first and the only person in United Kingdom to be convicted under the War Crimes Act 1991. From a legal perspective this case is interesting as it was also the first time that a British jury had travelled overseas to view the scene of a crime.\n\nIn 2000 the House of Lords refused him permission to appeal.\n\nSawoniuk died in Norwich Prison of natural causes aged 84.\n\n"}
{"id": "2897114", "url": "https://en.wikipedia.org/wiki?curid=2897114", "title": "Boundary commission", "text": "Boundary commission\n\nA boundary commission is a legal entity that determines borders of nations, states, constituencies.\n\nNotable boundary commissions have included:\n"}
{"id": "22214911", "url": "https://en.wikipedia.org/wiki?curid=22214911", "title": "California Public Records Act", "text": "California Public Records Act\n\nThe California Public Records Act (Statutes of 1968, Chapter 1473; currently codified as California Government Code §§ 6250 through 6276.48) was a law passed by the California State Legislature and signed by the governor in 1968 requiring inspection or disclosure of governmental records to the public upon request, unless exempted by law.\n\nThe law is similar to the Freedom of Information Act, except that \"the people have the right of access to information concerning the conduct of the people's business\" is enshrined in Article 1 of the California Constitution due to California Proposition 59 (the Sunshine Amendment, 2004).\n\nWhen the legislature enacted CPRA, it expressly declared that \"access to information concerning the conduct of the people's business is a fundamental and necessary right of every person in this state.\" Indeed, in California \"access to government records has been deemed a fundamental interest of citizenship\" and has emphasized that \"maximum disclosure of the conduct of governmental operations [is] to be promoted by the act.\" By promoting prompt public access to government records, the CPRA is \"intended to safeguard the accountability of government to the public.\" As the California Supreme Court recognized in CBS v. Block:\n\nIn accordance with this policy, public records are broadly defined to include \"any writing containing information relating to the conduct of a public's business prepared, owned, used or retained by any state or local agency regardless of physical form or characteristic[.]\" Citing with approval an even broader definition of public records adopted by the California Attorney General, another court has stated:\nMoreover, unless the public records of a local agency are exempt from the provisions of the CPRA, they must be made available for public inspection. Exemptions must be narrowly construed and the public agency bears the burden of proving that an exemption applies.\n\nMost of the exemptions under the CPRA are set forth under Section 6254 and are specific as to certain records or types of records, but under Section 6255 a general exemption exists where, on the facts of the particular case, \"the public interest served by not making the record public clearly outweighs the public interest served by disclosure of the record\". In reviewing the propriety of an agency decision to withhold records, a court is charged with ascertaining whether nondisclosure was justified under either of these statutes.\n\nBecause the CPRA was modeled after the federal Freedom of Information Act (\"FOIA\"), 5 U.S.C. Section 552 et seq, courts may look to case law under FOIA in construing the CPRA.\n\nThe California Supreme Court held that when a public official or employee uses a \"personal\" account and/or device to communicate about the conduct of public business, such as e-mails or text messages, the applicable writings may be subject to disclosure under the California Public Records Act.\n\nTo facilitate prompt public access to public records, court orders either directing disclosure of public records or supporting an agency's decision of nondisclosure are immediately reviewable by an appellate court by way of an emergency petition seeking issuance of an extraordinary writ. In 1991, the California Supreme Court made clear that under this writ procedure, trial court orders are reviewable on their merits. Thus, when a trial court order under the CPRA is reviewed by an appellate court, the independent review standard is employed for legal issues and factual findings made by the trial court will be upheld if they are based on substantial evidence.\n\nIn 2013, as part of budget negotiations, the Legislature approved a plan to make certain provisions in the Act optional for local agencies. The move was done in order to save \"tens of millions of dollars\" in state reimbursements to local agencies that comply with the Act, according to Legislative Analyst's Office projections.\n\nThe changes were added to the 2013 budget as rider bills AB 76 and SB 71, the former of which was vetoed by Jerry Brown. According to the bills, local agencies would no longer be required to provide the following, but are encouraged to follow them as \"best practices\":\n\nOpen government advocates and several California newspapers came out strongly against the measure. Jim Ewert, general counsel of the California Newspaper Publisher's Association, called the move \"the worst assault on the public's right to know I have seen in my 18 years of doing this.\" Several newspapers, including the Oakland Tribune, Fresno Bee, and Visalia Times-Delta, published editorials against the changes.\n\nBecause of the outcry from the media, state leaders backed down within the week and reversed the changes. The Assembly passed a measure to revoke that provision in the budget bill, which Jerry Brown signed into law.\n\nIn September 2013 the legislature approved a constitutional amendment proposal, authored by state senator Mark Leno, which would incorporate the Public Records Act into the California State Constitution. The amendment clarifies that local governments must comply with requests for publicly available documents, and requires local governments to pay the costs of those requests in full. The proposed amendment went to the voters for approval in June 2014, and was passed with 61.8% of the vote.\n\n\n\n"}
{"id": "4456077", "url": "https://en.wikipedia.org/wiki?curid=4456077", "title": "Central Elections Committee (Israel)", "text": "Central Elections Committee (Israel)\n\nThe Israeli Central Elections Committee (, \"Va'adet HaBehirot HaMerkazit\") is the body charged under the Knesset Elections Law of 1969 to carry out the elections for the upcoming Knesset. The committee is composed of Knesset members (and delegates) representing various parliamentary groups and is chaired by a Supreme Court Justice (currently Salim Joubran). Tasks for the committee include the authorization of party lists running for the Knesset, election financing, and publication and appeals of election results.\n\nIn 1985, the Knesset approved a law which, for the first time, allowed the committee to disqualify a party list on the grounds of its ideological platform. The law allowed the committee to bar parties from elections that negate the existence of Israel as a Jewish and democratic state, made incitements to racism, or supported the armed struggle of an enemy state or terrorist organization against the state of Israel. The first provision, dealing with the existence of Israel as a Jewish state, has been the most controversial since it is possible that parties favoring a one-state solution could be banned under it.\n\nThe committee decided to ban the Progressive List for Peace (PLP) and the Kach Party in 1988. The former was banned for allegedly negating the existence of Israel as a Jewish and democratic state; the later party was banned because of incitements to racism. The Supreme Court of Israel sustained the ban against Kach, but overturned the ban on the PLP reasoning that it was impossible to determine that \"the real, central and active purpose [of the list] is to bring about the elimination of the State of Israel as the state of the Jewish people\".\n\nIn 2003, Likud MK Michael Eitan initiated a move to ban the Ta'al Party from participating in that year's Knesset elections. MK Michael Kleiner, the leader of the right-wing Herut Party, initiated a similar move against the Balad Party, arguing that Balad was \"a cover-up for illegal activity\" and that it \"supports terror organizations, identifies with the enemy and acts against Israel as a Jewish and democratic state.\"\n\nThe Central Election Committee proceeded to vote by a one-vote majority to disqualify Balad and Ta'al lists from the elections. Supreme Court Justice Michael Cheshin, who chaired the committee, voted against the ban, stating that there was insufficient evidence to sustain the claims against the parties and individuals within those parties, but also said that Balad's leader Azmi Bishara's past expressions of support of the militant pro-Iranian Hezbollah in Lebanon had angered him.\n\nThe bans were appealed to the Israeli Supreme Court, where the Court unanimously overturned the bans on the Ta'al list and party leader Ahmad Tibi. The Court also overturned the ban on Balad and party leader Azmi Bishara by a 7-4 majority.\n\nOn 12 January 2009 the Committee voted to ban two Arab political parties, Balad and the United Arab List—Ta'al, from participating in the February elections. The vote passed 26-3 with one abstention to ban Balad from the elections and 21-3 with eight abstentions to disqualify UAL—Ta'al.\n\nThe measure was proposed by the National Union and Yisrael Beiteinu parties, who accused Balad and UAL—Ta'al of supporting terrorism and failing to recognise Israel as a democratic Jewish state. Yisrael Beitenu chairman Avigdor Lieberman, stated that \"The next step is to declare Balad illegal because it's a terror organisation that seeks to hurt Israel.\"\n\nThe leaders of the Arab parties denied the charges and appealed the decision to the Supreme court. Tibi described the vote as \"a political trial led by a group of fascists and racists who are willing to see the Knesset without Arabs and want to see the country without Arabs.\" Jamal Zahalka, chairman of Balad, warned that the decision would lead to a deeper crisis between Israel's Jewish and Arab citizens.\n\nOn 21 January 2009, the Supreme Court overturned the ban.\n\n"}
{"id": "4319429", "url": "https://en.wikipedia.org/wiki?curid=4319429", "title": "Chambers (law)", "text": "Chambers (law)\n\nIn law, a chambers is a room or office used by barristers or a judge. A barrister's chambers or barristers' chambers are the rooms used by a barrister or a group of barristers. A judge's chambers, on the other hand, is the office of a judge, where the judge may hear certain types of cases, instead of in open court.\n\nA judge's chambers is the office of a judge, where certain types of matters can be heard \"in chambers\", also known as \"in camera\", rather than in open court. Generally, cases heard in chambers are cases, or parts of cases, in which the public and press are not allowed to observe the procedure. Judge's chambers are often located on upper floors of the court house, away from the courtrooms, sometimes in groupings of judge's chambers.\nIn some jurisdictions, a courtroom, rather than the judge's actual chambers, are used to hear matters \"in chambers\". Such courtrooms may also be called \"chambers\".\n\nIn England and Wales, New Zealand, Australia, India, Pakistan and Hong Kong, chambers may refer to the office premises used by a barrister or to a group of barristers, especially in the Inns of Court. To share costs and expenses, barristers typically operate fraternally with each other, as unincorporated associations known as \"chambers\". The term \"Chambers\" is used to refer both to the physical premises where the Barrister's Set conduct most of their work from., as well as the 'set' or unincorporated association itself. Most prosperous Chambers typically have office spaces for the barristers to work from, conference rooms with infrastructure to conduct video conferencing for a large audience, printing and photocopying sections, a substantially large and updated Library, as well as rooms for the Barristers' and clients' dining and entertainment. Most Chambers have a staff to look after administrative matters, including a full-fledged kitchen and dining hall to serve up meals and refreshments. The transactional side of chambers are administered by barristers' clerks who receive cases from Solicitors and agree on matters such as fees on behalf of their employers; they then provide case details to the barristers and conduct office management for them. Some chambers specialise in particular areas of law. Members are known as tenants, and can only be dismissed for gross misconduct. \n\nThere are chambers all over England and Wales; however, the largest concentration of them is in London. A report by the General Council of the Bar in 2006, showed that of the 355 practising chambers in the United Kingdom, 210 were based in London. \n\nIn Hong Kong, the 133 chambers within the special administrative region are almost exclusively located in the City of Victoria.\n"}
{"id": "1261118", "url": "https://en.wikipedia.org/wiki?curid=1261118", "title": "Church of the Lukumi Babalu Aye v. City of Hialeah", "text": "Church of the Lukumi Babalu Aye v. City of Hialeah\n\nChurch of the Lukumi Babalu Aye, Inc. v. Hialeah, 508 U.S. 520 (1993), was a case in which the Supreme Court of the United States held that an ordinance passed in Hialeah, Florida, forbidding the \"unnecessar[y]\" killing of \"an animal in a public or private ritual or ceremony not for the primary purpose of food consumption\", was unconstitutional.\n\nSantería is an Afro-American religion developed as a syncretism of Roman Catholicism and Yoruba religion by Yoruba people brought as slaves from Yorubaland to Cuba by the Atlantic slave trade. Adherents believe they can fulfill their destiny through the aid of beings known as orishas, who subsist off blood from animal sacrifice. Animals, usually chickens, killed during ritual slaughter are then cooked and eaten by the celebrants, except during death and healing rituals, where sick energy is believed to have passed into the sacrifice. Santeria has been subject to widespread persecution in Cuba, so it is traditionally practiced in secret, employing saint symbolism.\n\nThe Church of Lukumi Babalu Aye, Inc., is a Florida nonprofit organized in 1973 by Ernesto Pichardo, who was an Italero-level priest in the Santeria faith. The Lucumí language is used in the Santeria liturgy and Babalú-Ayé is the spirit of wrath and disease. In April 1987, the Church leased a property at 173 W. 5th Street, Hialeah, in Miami-Dade County, Florida and announced its intention to use the site to openly practice the faith.\n\nThe Hialeah City Council held an emergency public session on June 9, 1987. At the session, Councilman Silvio Cardoso stated that the religion is \"in violation of everything this country stands for\"; Councilman Andres Mejides observed that the Bible does not allow this particular type of animal sacrifice; and Councilman Julio Martinez noted (to audience applause) that in Cuba \"people were put in jail for practicing this religion.\" Hialeah's police chaplain testified that the Church worshiped \"demons\" and the city attorney testified that \"This community will not tolerate religious practices abhorrent to its citizens.\" Pichardo’s brief testimony was met with taunts from the audience.\n\nAt the end of the session the city council passed a resolution announcing its commitment to prohibit \"all religious groups which are inconsistent with public morals, peace or safety”. The city further passed a resolution incorporating Florida’s animal cruelty statute into the city code and the city attorney obtained a Florida Attorney General's Opinion from Bob Butterworth concluding that the state statute did not permit ritual animal sacrifice. \n\nIn September 1987, the city council unanimously passed three new ordinances that criminalized “sacrifices of animals for any type of ritual, regardless of whether or not the flesh or blood of the animal is to be consumed.” The city council exempted Kosher slaughterhouses, regular slaughterhouses, hunting, fishing, pest extermination, euthanasia of stray animals, and feeding live rabbits to greyhounds.\n\nThe Church sued in the United States District Court for the Southern District of Florida. On June 10, 1988, U.S. District Judge Eugene P. Spellman granted absolute immunity to the individual city council members and the mayor. On October 5, 1989, after a nine-day bench trial, Judge Spellman granted summary judgment to the city. In 1991, the United States Court of Appeals for the Eleventh Circuit affirmed in an unsigned one-paragraph per curiam decision, where it noted that Judge Spellman \"employed an arguably stricter standard\" than that applied in \"Employment Division v. Smith\" (1990), which had in the interim found Native Americans could be fired for their ritual use of peyote. In \"Smith\", Justice Antonin Scalia had even cited Judge Spellman’s opinion as authority, which the city highlighted in their appeals brief.\n\nThe Court in \"Wisconsin v. Yoder\" (1972) had explicitly provided Amish parents a religious exemption from mandatory school attendance under the Free Exercise Clause. However, in the years since, free-exercise claimants had lost every case before the Court, with the exception of a line of employment decisions cases terminated by \"Smith\". The Church's petition for certiorari from the Supreme Court of the United States was granted, with Douglas Laycock appearing for the Church during oral arguments on November 4, 1992.\n\nOn June 11, 1993, the Supreme Court unanimously reversed. Justice Anthony Kennedy, in an Opinion of the Court joined in parts by Chief Justice William Rehnquist, and Justices Byron White, John Paul Stevens, Antonin Scalia, David Souter, and Clarence Thomas concluded that the city’s ordinances violated the Free Exercise Clause of the United States Constitution.\n\nKennedy read the \"Smith\" decision as requiring a compelling governmental interest if a law is not of neutral and general applicability. Kennedy went on, in a section Souter and White refused to join, to conclude that although the ordinances were facially neutral, they were religiously “gerrymandered with care” to only apply to religious killings. Kennedy, in a section only joined by Stevens, details the ordinances’ legislative history, even citing taped excerpts of the Hialeah City Council Meeting. Next, in a section Souter refused to join, Kennedy notes the numerous exemptions in the Florida statute, concluding the law is not generally applicable because it effectively applies “only against conduct motivated by religious belief.” Finally, in a section joined by the full seven justice majority, Kennedy applies strict scrutiny, which the city ordinances fail.\n\nBecause the ordinance suppressed more religious conduct than was necessary to achieve its stated ends, it was deemed unconstitutional, with Justice Anthony Kennedy stating in the decision, “religious beliefs need not be acceptable, logical, consistent or comprehensible to others in order to merit First Amendment protection”.\n\nJustice Scalia joined by Chief Justice Rehnquist, defended the \"Smith\" decision and attacked the use of legislative intent, opining that there would be no constitutional violation if “the Hialeah City Council set out resolutely to suppress the practices of Santeria, but ineptly adopted ordinances that failed to do so”.\n\nJustice Souter, writing alone for eighteen pages, noted that “The \"Smith\" rule, in my view, may be reexamined consistently with principles of \"stare decisis\".”\n\nJustice Harry Blackmun, joined by Justice Sandra Day O'Connor, concurred in the judgment only. Refusing to endorse the approach used in the majority opinion, Blackmun wrote, “I continue to believe that \"Smith\" was wrongly decided”. Blackmun goes on, citing an \"amicus curiae\" brief by People for the Ethical Treatment of Animals, to observe that had this case presented “a law that sincerely pursued the goal of protecting animals from cruel treatment”, the result may have been different.\n\nSomewhat similarly in 2009, a freedom of religion case related to animal sacrifice was taken to the U.S. Court of Appeals for the Fifth Circuit in the case of \"Merced v. Kasson.\" Merced was a Santeria priest and the president of Templo Yoruba Omo Orisha Texas, Inc., a Santeria religious group. He challenged Euless, Texas city ordinances prohibiting the slaughter of four-legged animals. The court ruled that the ordinances \"substantially burden plaintiff's free exercise of religion without advancing a compelling governmental interest using the least restrictive means\" and that Merced was entitled under the Texas Religious Freedom Restoration Act (TRFRA) to an injunction preventing the city from enforcing its ordinances that burdened his religious practices relating to the use of animals. The court did not reach Merced's claims under the First and Fourteenth Amendments.\n\n\n"}
{"id": "17005363", "url": "https://en.wikipedia.org/wiki?curid=17005363", "title": "Citizenship of Russia", "text": "Citizenship of Russia\n\nCitizenship of Russia is regulated by the federal act regarding citizenship of the Russian Federation (of 2002, with the amendments of 2003, 2004, 2006), Constitution of the Russian Federation (of 1993), and the international treaties that cover citizenship questions to which the Russian Federation is a party. In accordance with the supremacy clause of the Constitution, international treaties of the Russian Federation have precedence over Russian domestic law. \n\nIn the Russian language, there is a distinction between citizens of Russia, referred to as \"Rossiyane\" (plural, ; masc. singular россиянин \"Rossiyanin\" and fem. singular россиянка \"Rossiyanka\"), and ethnic Russians, referred to as \"Russkie\" (). The word \"Rossiyane\" is used much more often than \"Russkie\" in media and official documents. Those who have received Russian citizenship via naturalisation are also called Rossiyane, regardless of ethnicity and mother tongue (for example, Gérard Depardieu or Viktor Ahn). The word \"Rossiyane\" was coined by Mikhail Lomonosov in the 18th century.\n\nThe Tsardom of Russia became a multinational state in the 16th century. The word \"Rossiyane\", coined by Lomonosov, has been widely used since then. After the fall of the Russian Empire, the expression \"Soviet people\" was used for the population of the Soviet Union, regardless of ethnicity. After the dissolution of the USSR, the word \"Rossiyane\" became widely used again. \n\nUntil 1990, the Russian Soviet Federated Socialist Republic (RSFSR) was a subject of the Soviet federation. In 1990, state sovereignty of the RSFSR was declared, though the USSR was not abolished until the end of 1991. Article 11 of the declaration of state sovereignty introduced RSFSR citizenship. The text of the citizenship act was ready in the summer of 1991, but was not adopted by the Supreme Council (the legislative body of the RSFSR) until November 28, 1991. On January 23, 1992 some changes with respect to the dissolution of the USSR were applied to the text; the result was signed by the President and finally came into force after publication on February 6, 1992.\n\nIn accordance with Article 13, former Soviet citizens among permanent residents on February 6, 1992 of the RSFSR were recognized as RSFSR citizens. Those who expressed their will not to become RSFSR citizens until February 6, 1993 were not recognized as RSFSR citizens. Supreme Council decree N 5206/1-1 recognized the following as Russian citizens:\n\n\nFormer Soviet citizens who were born on December 30, 1922 or later on Russian territory or to a Soviet citizen who was a permanent resident of the RSFSR at the birth of his or her were recognized as if they had been RSFSR citizens by birth (see Case of Smirnov).\n\nRussian citizenship could be acquired:\n\n\nIn 1999, in spite of the veto of the President, the Federal Assembly adopted the Act on the state policy on compatriots abroad. Article 11 stated that all former Soviet citizens and their descendants should be recognized as Russian citizens unless they had declared their intentions to be citizens of foreign states. However, this article was revoked in 2002 and persons under this article are not generally recognized by executive or court authorities of Russia as citizens of the Russian Federation unless they received documents of Russian citizenship before the article's revocation. No official comments have been given as to how this article should be interpreted. Oleg Kutafin, the chairman of the Presidential Committee on citizenship, criticized this Act in his book \"Russian Citizenship\" (), but the legal consequences of this Act were not analyzed there.\n\nIn 2002, a new citizenship act, supported by President Vladimir Putin, replaced the act of 1991.\n\nRussian citizenship could be acquired:\n\nThe rules of citizenship by birth generally follow the principle of jus sanguinis, though a child can be recognized as a Russian citizen in several special cases:\n\nNaturalization is usually granted if the applicant meets the following requirements:\n\nIn certain cases, some or even all of the above requirements can be waived by an Executive Order of the Russian President, as happened on 3 January 2013, when Russian President Vladimir Putin signed an Executive Order granting Russian citizenship to French-born actor Gérard Depardieu, citing authority granted under Article 89(a) of the Constitution of the Russian Federation.\n\nRestoration of citizenship is granted under the same rules as naturalization; the only exception is the residence term requirement (three years in this case). Although not in compliance with law, executive agencies (such as the federal migration service and Russian diplomatic and consular departments abroad) usually do not grant Russian citizenship to former Russian citizens if they do not satisfy citizenship restoration requirements, even if they satisfy requirements for facilitated naturalization.\n\nA special provision of law made it possible for former citizens of the USSR to apply for Russian citizenship before 2009. The only requirements were holding a temporary residence permit or a permanent residence permit, or being registered as a permanent resident of Russia as of July 1, 2002 and meeting the naturalization requirements of p. 2 and p. 4.\n\nCitizenship of children (persons under 18 years of age) generally follows the citizenship of their parents. If one or both parents obtain Russian citizenship, their children become Russian citizens as well. If one or both parents lose Russian citizenship, their children lose it too. A child can acquire or relinquish Russian citizenship by the application of his parents, but at least one parent must be a Russian citizen in this case.\n\nVisa requirements for Russian citizens are administrative entry restrictions by the authorities of other countries placed on citizens of Russia. In 2016, Russian citizens had visa-free or visa-on-arrival access to 105 countries and territories, ranking the Russian passport 48th in the world according to the Visa Restrictions Index.\n\nSmirnov was born on RSFSR territory in 1950. In 1979, he married and moved his permanent residence to the Lithuanian SSR. He divorced in 1992 and returned to the RSFSR on December 8, 1992. He then applied for a notice of Russian citizenship in his passport, but this was rejected by executive officers. His claim was also rejected by common jurisdiction courts, including the Supreme Court of the Russian Federation.\n\nThe position of the executive officers and the courts was that Smirnov, in accordance with Article 13 of the Citizenship Act, was a former citizen of the Russian Federation, but not a citizen of the Russian Federation since February 6, 1992. He did have the option to apply for Russian citizenship through registration.\n\nHowever, the Constitutional Court ruled that Article 18 of the Citizenship Act was not in conformance with the Constitution, as the registration procedure of Article 18 could be applied to Russian citizens by birth; that is, those persons who:\n\nThere is an opinion that this ruling determines that every former citizen of the USSR who was born in the territory of the RSFSR and never renounced Russian citizenship is a Russian citizen by birth, even if he also has foreign citizenship. This opinion is based on the Court's interpretation of Article 6 of the Constitution given in the text of the decision: \"such persons... cannot lose Russian citizenship unless they explicitly expressed their will to give it up\". A notable advocate of this position is Anatoly Mostovoy, who published the book \"Get Your Citizenship Back!\" ().\n\n1) incorrect interpretation of Article 13 of the Citizenship Act of 1991\n\n2) incorrect interpretation of constitutional articles\n\n3) there were no constitutional issues in this case\n\nUntil 2001-2002, former Soviet citizens could register their permanent residence on the territory of Russia in the same way as Russian citizens.\n\nThe federal act regarding Russian citizenship (2002) was amended several times to allow former Soviet citizens who had had their permanent residence registered on July 1, 2002 to apply for Russian citizenship.\n\nFatullaeva had been living in Russia up to this date but had never registered permanent residence.\n\nShe challenged the requirement of permanent residence registration at the Constitutional Court. The Court rejected her claim for the following reasons:\n\nThe Act on the Legal Status of Foreigners in the USSR (1981) was in force until 2002. According to this act, permanent residents of the USSR were persons who received permanent residence permits. Other foreigners were those with temporary residences in the USSR. However, former Soviet citizens did not apply for residence permits; they registered their permanent residence in the same manner as Russian citizens, in accordance with the Decree of Government N 290 of March 12, 1997. Therefore, registration of permanent residence was equivalent to obtaining residence permits in Russia.\n\nThe Russian Federation has a treaty with Kazakhstan and a treaty with Kyrgyzstan. There is also a multilateral treaty among the Russian Federation, Kazakhstan, Kyrgyzstan and the Republic of Belarus.\n\nCitizens of the respective states that come to Russia for permanent residence have the right to obtain Russian citizenship if they:\n\nUntil the end of 2003, those treaties were ignored by Russian executive authorities. Presidential Decree N 1545 provided some means for implementation of the treaties. However, the decree requires that the applicant provide evidence that the state of his citizenship allows him to reside in Russia (such as a special stamp in a passport or an exit document). This does not conform to the treaties and makes obtaining citizenship significantly more difficult or even impossible in some cases. The Supreme Court of the Russian Federation stated in its decision that one must prove, in accordance with the treaties, that he came to Russia for permanent and not temporary residence. This can be proved in accordance with Russian law. In accordance with the \"Act on the Status of Foreign Citizens in the Russian Federation\", obtaining temporary or permanent residence permission in Russia does not require any permission from foreign states, so technically every person who lawfully resides in Russia is able to apply for a temporary residence permit and then for a permanent residence permit. Although the interpretation of the Federal Act given by the Supreme Court is incompatible with the Presidential Decree, the article was not declared void.\n\nThe following international treaties contain rules related to dual citizenship:\n\nThe Treaty of Friendship, Cooperation, and Mutual Security between the Russian Federation and the Republic of Armenia, signed December 29, 1991, grants the right to acquire citizenship of both Russia and Armenia to the citizens of Russia and Armenia.\n\nAs the Russian Federation is the successor state to the Soviet Union, some Soviet treaties on dual citizenship are still in force. For this reason, the Convention on the Nationality of Married Women is in force.\n\nThe European Convention on Nationality has been signed but not ratified by the Russian Federation. It is binding to the extent of the provisions of the Vienna Convention on the Law of Treaties. Domestic citizenship legislation is usually considered to conform to the convention.\n\n"}
{"id": "168221", "url": "https://en.wikipedia.org/wiki?curid=168221", "title": "Constitutional convention (political meeting)", "text": "Constitutional convention (political meeting)\n\nA constitutional convention is a gathering for the purpose of writing a new constitution or revising an existing constitution. \nMembers of a constitutional convention (sometimes referred to as \"delegates\" to a constitutional convention) are often, though not necessarily or entirely, elected by popular vote. However, a wholly popularly-elected constitutional convention can also be referred to as a Constituent assembly.\n\nExamples of constitutional conventions to form or revise the constitution of a nation include:\n\nConstitutional conventions have also been used by constituent states of federations — such as the individual states of the United States — to create, replace, or revise their own constitutions. Several U.S. states have held multiple conventions over the years to change their particular state's constitutions.\n\n"}
{"id": "21521268", "url": "https://en.wikipedia.org/wiki?curid=21521268", "title": "Copyright Act 1911", "text": "Copyright Act 1911\n\nThe Copyright Act 1911, also known as the Imperial Copyright Act of 1911, is an Act of the Parliament of the United Kingdom (UK) which received Royal Assent on 16 December 1911. The act established copyright law in the UK and the British Empire. The act amended existing UK copyright law, as recommended by a Royal Commission in 1878 and repealed all previous copyright legislation that had been in force in the UK. The act also implemented changes arising from the first revision of the Berne Convention for the Protection of Literary and Artistic Works in 1908.\n\nThe act came into force in the UK on 1 July 1912, in the Channel Islands (except Jersey) on 1 July 1912, in Jersey on 8 March 1913, and in the Isle of Man on 5 July 1912. The Copyright Act 1911 applied or extended to all parts of the British Empire. In India the act came into force on 30 October 1912, in Papua on 1 February 1931, and all other British possessions on 1 July 1912. It was subsequently enacted on various dates in the self-governing dominions and \"territories under protection\" of the British Empire. \"The Copyright Act 1911 (extension to Palestine), 1924 Ordinance\" covered Mandatory Palestine and later the State of Israel, where in the latter it remained the governing statute until the Israeli 2007 Copyright Act took effect on 25 May 2008.\n\nIn the two centuries after the Statute of Anne of 1710, which afforded copyright protection to books, other works were afforded copyright protection either through case law, as in the case of music, or through Acts of Parliament, as in the case of engravings, paintings, drawings and photographs, in legislation such as the Engraving Copyright Act 1734 and the Fine Arts Copyright Act 1862.\n\nThe Copyright Act 1911 consolidated previous copyright statutes, and apart from minor exceptions, the Copyright Act 1911 repealed all previous copyright legislation and established a single statute covering all forms of copyright.\n\nThe 1911 Act implemented the Berne Convention, which abolished the common law copyright in unpublished works and responded to technological developments by conferring copyright on a new type of works not mentioned in the Berne Convention, namely sound recordings.\n\nThe 1911 Act abolished the need for registration at the Stationers' Hall and provided that copyright is established upon the creation of a work. However, as the 1911 Act come into effect at different times in different countries of the Commonwealth, registration at Stationers' Hall continued to be required in some Commonwealth countries after 1911. The Act also stated that copyright arose in the act of creation, not the act of publishing.\n\nThe scope of copyright was further widened and producers of sound recordings were granted the exclusive right to prevent others reproducing their recordings, or playing them in public. The act provided that the copyright in literary, dramatic and music works could be infringed by the making of a film or other mechanical performance incorporating the copyrighted works.\n\nIn Israel, the bulk of amendments were made by the Knesset not to the 1911 Act itself, but to the 1924 Ordinance applying it, resulting in a situation in which the two legal instruments were in conflict - for instance, while the Act set a copyright term of 50 years after the author's death, the Ordinance set a term of 70. Because the Knesset did not amend the Act to respond to further technological developments, the Courts had to apply the Act's definitions, which were centered on artistic works, or types of works not mentioned in it - for instance, phone books, newspapers, restaurant menus and even the codes of Computer Programs were legally deemed \"books\" for copyright purposes, regardless of their (usually nonexistent) artistic value. These \"stretched-boundaries\" definitions are maintained in the Copyright Act 5778-2007.\n\nBritish lawyer Evan James Macgillivray summarised the changes in the introduction of his annotated edition of the 1911 Act as follows:\n\nWith the exception of provisions that were expressly restricted to the United Kingdom by the act, all provisions of the Copyright Act 1911 applied \"throughout His Majesty's dominions\" and self-governing dominions if enacted by the parliament of that dominion without modifications that were not necessary to adapt the act \"to the circumstances of the dominion\". The Copyright Act 1911 was adapted to circumstances and enacted by the then self-governing dominions of Australia (Copyright Act 1912), Newfoundland (Newfoundland Copyright Act 1912) and the Union of South Africa (Patents, Designs, Trade Marks and Copyright Act 1916).\nThe Copyright Act 1911 also provided that the UK Secretary of State could certify copyright laws passed in any self-governing dominion if the copyright legislation was “substantially identical” to those of the Copyright Act 1911. Though the Secretary of State could certify copyright law even if their provisions on copyright enforcement and the restriction on importation of works manufactured in “foreign countries” were not identical to that of the Copyright Act 1911. Such self-governing dominions were then treated as if the Copyright Act 1911 extended to the self-governing dominion. The Secretary of State certified the copyright laws of New Zealand (New Zealand Copyright Act 1913, certified April 1914) and Canada (Copyright Act of Canada 1923, certified 1923).\n\nThe Copyright Act 1911 also provided that “His Majesty may, by Order in Council, extend this Act to any territories under his protection and to Cyprus” and the act would then apply to these countries as if they were dominions of the British Empire. In 1912 an Order in Council extended the Copyright Act 1911 to Cyprus and the following territories: Bechuanaland, East Africa, The Gambia, the Gilbert and Ellice Islands, Northern Nigeria, the Northern Territories of the Gold Coast, Nyasaland, Northern Rhodesia, Southern Rhodesia, Sierra Leone, Somaliland, Southern Nigeria, the Solomon Islands, Swaziland, Uganda and Weihaiwei. The Copyright Act 1911 was extended to Palestine by an Order in Council in 1924, it was extended to Tanganyika by an Order in Council in 1924 and 1931, it was extended to the Federated Malay States by an Order in Council in 1931 and 1932, and it was extended to the Cameroons under British Mandate by an Order in Council in 1933.\n\nThe Copyright Act 1911 provided the template for an approach to copyright exceptions where a specific list of exceptions carefully defines permitted uses of the copyrighted work. The 1911 Act formed the basis of UK copyright law and, as an imperial measure, formed the basis for copyright law in most of what were then British colonies and dominions. While many of these countries have had their own copyright law for a considerable number of years, most have followed the imperial model developed in 1911. Australia, Canada, India, New Zealand, Singapore and South Africa define the limits on and exceptions to copyright by providing an exhaustive list of specifically defined exceptions.\n\nThis \"Commonwealth approach\" to copyright is in contrast with that adopted in US copyright law. US copyright does contain a number of specific exceptions, as well as providing for a fair use defence in section 107 of the Copyright Act 1976. The Section provides a list of illustrative example of uses under this defence, such as criticism, comment and research. In contrast to the Commonwealth fair dealing exceptions, the fair use defence allows US courts to find that a defendant's use is fair and hence not an infringement of copyright, even though the use does not fall within the statutory list provided for in Section 107.\n\n\n"}
{"id": "10402528", "url": "https://en.wikipedia.org/wiki?curid=10402528", "title": "Cross-Strait charter", "text": "Cross-Strait charter\n\nThe cross-strait charters () are special flights between Taiwan and Mainland China, across the Taiwan Strait. After the Chinese Civil War, no direct flights were allowed between Taiwan and Mainland China due to mistrust and security concerns; this remained the case until 2003. Passengers had to transfer in a third city, such as Hong Kong, to complete their trip.\n\nFor the years 2003 and 2005, the scheme was restricted for the Chinese New Year period, so it was then called the Lunar New Year cross-strait charter () in Taiwan, and the charter for Taiwan residents () in Mainland China. For these years, the scheme was restricted for Taiwanese businessmen and their family members (excluding students and tourists) who are in Mainland China to travel to and from Taiwan.\n\nIn 2006, the service was opened to all residents of Taiwan for the first time. From the Mid-Autumn Festival on 2006, the valid period of the agreement was expanded to four main Chinese festivals: Qingming Festival, Dragon Boat Festival, Mid-Autumn Festival, and the original Chinese New Year.\n\nIn July 2008, charter flights expanded to weekends. Flight restrictions on nationalities were removed and Mainland China residents as well as foreign citizens were able to take the flights.\n\nIn November 2008, flights became daily instead only for the weekends. 108 weekly flights were established and the planes no longer had to travel through Hong Kong airspace, cutting travel times by two thirds in some cases such as flying from Taipei to Shanghai.\n\nIn April 2009, a new agreement was reached to allow cross-strait flights to become regularly scheduled instead of chartered. The cap on the flights was also raised to 270 flights per week, effective 31 August 2009. On 22 May 2010, another 100 additional weekly flights were permitted to be operated effective 14 June 2010, and Shanghai Hongqiao International Airport and Shijiazhuang Airport were added to the list of allowed destinations.\n\nThere was no official contact for over 50 years between the governments of Taiwan — where the Kuomintang (KMT) had retreated — and Mainland China since the Communist Party of China established the People's Republic of China in 1949, after the Chinese Civil War. However, when the Chinese Economic Reform began welcoming foreign funds in the 1980s, Mainland China sought greater contact with Taiwan. Chiang Ching-kuo refused, beginning a policy of \"Three Noes\". The Three Noes policy was abandoned, however, when a Taiwan flight was hijacked and Taiwan was forced to negotiate with Mainland China, beginning a series of negotiations. Merchants started investing in Mainland China and people visited their relatives. Air traffic between Taiwan and Mainland China grew dramatically, but no direct flights were allowed. Passengers traveling to Mainland China had to travel via an intermediate destination such as Hong Kong or Macau, or via South Korea and Japan. The travel time usually took more than a half day, especially during the holidays such as the Spring Festival.\n\nIn the 1990s, the government of Mainland China proposed the 'three direct links' - including direct air flights between Mainland China and Taiwan - to ease the travel problem. However, Taiwanese government rejected this idea.\n\nIn 2002, Taiwan legislator John Chiang proposed that there should be special charters across the strait, and received support from the public and the aviation industry in Taiwan.\n\nThe previous regime of negotiations via the Straits Exchange Foundation and the Association for Relations Across the Taiwan Straits had broken down by the time Chen Shui-bian came to office. A political impasse prevented the resumption of semi-official dialogue, because the People's Republic of China government insisted on the recognition of the one China principle or the more ambiguous 1992 consensus as the basis for the talks. By contrast, the Republic of China government under Chen Shui-bian did not recognise the one China principle and repudiated the 1992 consensus reached under the previous administration. As a result, aviation industry bodies were accredited by the respective governments to negotiate only on the technical and operational aspects of the charter flights.\n\nThe governmental bodies politically responsible for the talks were the ROC Affairs Office of the State Council of the People's Republic of China, led by Chen Yunlin.\n\nFrom 2000 to 2008, progress of talks were often severely affected by the political climate in Taiwan. After the re-election of the Chen Shui-bian government in 2004, the talks for the 2004 Chinese New Year charter flights were aborted when the PRC government was offended by Chen's independence-leaning rhetoric talks.\n\nAviation companies operated at a huge loss for the 2003 charter flights due to the fact that all passengers could only travel one-way - that is, the flights traveled with no passengers for half the journey. Moreover, due to complicated procedures set out in the talks, the aviation companies could not hold direct-flights and had to travel through Hong Kong or Macau, greatly increasing their cost. Nonetheless, the aviation companies were glad to provide the services, in part due to the historical nature and in part due to the possible promotional benefits from participating in the events, which were widely reported by the media.\n\nThe Pan-Blue coalition, which led the talks from Taiwan, supported the charter flights. The majority Pan-Green coalition, however, saw it as \"step towards reunification \" which Taiwanese people do not prefer and criticized the Pan-Blue coalition for holding talks with the PRC without government permissions. The Taiwanese public at large, and especially the merchants who benefited the most, supported the charter flights, and the Pan-Blue coalition benefited from the positive response.\n\n\n\nThe period of 16 charter flights occurred between January 26 and February 9, 2003.\n\n\n\n\nThe six mainland Chinese airlines originated in three cities in Mainland China: Beijing (Air China, Hainan Airlines), Shanghai (China Eastern Airlines), and Guangzhou (China Southern Airlines, Xiamen Airlines). All Air China's flight are operated by Shandong Airlines' aircraft to avoid Air China's livery which features the \"Five Star Red Flag\".\n\nThe Taiwanese airlines were the same as in 2003. Most Taiwanese flights departed for Guangzhou (TransAsia Airways), and Kaohsiung was mainly serviced by Uni Air.\n\n\n\nAs the charter flight was only for Taiwanese merchants returning home for the Chinese New Year, there would not be a demand to travel from Taiwan to Mainland China before the New Year's Day. Neither would there be people needing to travel on the flights from Mainland China to Taiwan that operated on dates after the New Year period.\n\nIn order to make sure the original purpose was not violated, in the 2003 case, the ROC government ensured that passengers could only travel one way, that meant no one was allowed to fly from Taiwan to Mainland China before the festival, and no one could travel on the return flight after the festival.\n\nHowever, since the 2005 charters, the ROC government later approved of passengers traveling the entire round-trip though there were still other limits.\n\n\n\n\nDate: May 16, 2008\n\nAirlines: EVA Air (Chongqing), China Airlines (Chongqing), TransAsia Airways (Chongqing), Mandarin Airlines (Chengdu)\n\nDue to the Sichuan earthquake, many Taiwan travelers were unable to get flights out of the quake region. Both governments reached a deal and chartered four flights to depart from Chengdu and Chongqing to Taiwan on May 16, 2008.\n\nUnder the agreement reached on June 13, 2008, charter flights began on weekends starting July 4, 2008. A total of 18 flights per weekend (Friday to Monday) are allowed under this agreement. Unlike previous charters, anyone with legal traveling documents, regardless of nationality, was allowed to travel on these charter flights. Initially, Mainland China permitted flights from Beijing, Shanghai (Pudong Airport), Guangzhou, Xiamen, and Nanjing airports, and the plan was to permit flights from Chengdu, Chongqing, Dalian, Guilin, Shenzhen, Shenyang, Xian and other spots with market demand in the future, while the ROC government permitted flights from Taiwan Taoyuan Airport, Taipei Songshan Airport, Kaohsiung, Taichung, Makung, Hualien, Kinmen, and Taitung.\n\nOn July 4, 2008, the first flight carrying 230 passengers belonging to China Southern Airlines arrived at Taoyuan International Airport.\n\nStarted on 15 December 2008, direct flights, direct shippings and direct mail are fully restored between Mainland China and Taiwan per the Three Links agreement. It marks the end of cross-strait charter flights and marks the beginning of regular scheduled flights. Shanghai and Taipei Area Control Center can pass traffic to each other at SULEM in the northern flight path while no direct pass-off for southern flight path.\n\n"}
{"id": "34326487", "url": "https://en.wikipedia.org/wiki?curid=34326487", "title": "Directive on intra-EU-transfers of defence-related products (ICT)", "text": "Directive on intra-EU-transfers of defence-related products (ICT)\n\nDirective on intra-EU-transfers of defence-related products (officially: Directive 2009/43/EC of the European Parliament and of the Council of the European Union of 6 May 2009 simplifying terms and conditions of transfers of defence-related products within the Community) is a European Union Directive with relevance for the European Economic Area (EEA). It is also known as the \"ICT-Directive\". \n\nThe Directive entered into force at the end of June in 2009. The deadline for transposition in the Member States was 30 June 2011. The national laws, regulations and administrative provisions necessary to comply with this Directive shall apply from 30 June 2012 (Article 18). There is also an amending act, the Directive 2010/80/EU. With this act the Annex to Directive 2009/43/EC was amended.\n\nThe Directive 2009/43/EC defines a \"European licence system\" for the transfer of defence-related-products within the European Union. Defence-related products mean any products listed in the Annex of the Directive. All these products correspond to those listed in the Common Military List of the European Union.\n\nThe main objective of the Directive 2009/43/EC is to build an internal market for defence-related products.\n\nThe member states of the European Union each have their own licensing system concerning the export of defence-related products. There are differences in terms of procedures, scope and duration. These disparities can destroy the competitiveness of European defence industry and can create barriers that hamper exports of defence-related products in the internal market.\n\nAccording to Article 1 of the Directive \"the aim of the directive is to simplify the rules and procedures applicable to the intra-EU-transfer of defence-related products in order to ensure the proper functioning of the internal market\" Furthermore the conditions for SMEs’ participation in armament development and production shall be improved. In addition with respect to this Directive, the Commission intends to increase the industrial cooperation of defence-related products to generate economies of scale Overall, the Directive aims to facilitate the intra-EU-transfer of defence-related products and to improve the competitiveness of the European defence industry on an international level.\n\nIn accordance with Article 4 of the Directive the movement of defence-related products between EU Member States is subject to prior authorisation. For the whole intra-EU-transfer only one transfer licence is necessary. There are three types of export licences: the general transfer licence; the global transfer licence as well as the individual transfer licence. The individual transfer licences would remain the exception.\n\nAccording to Article 6 of the Directive a global transfer licence shall be granted on request to individual suppliers. With such a licence the supplier can deliver products to one or more recipients in other Member States during a period of three years. The licence is renewable.\n\nArticle 7 of the Directive describes the usage of an individual transfer licence. Such a licence shall be granted on request. With an individual transfer licence a supplier can deliver products only once to only one recipient in another Member State.\n\nAccording to Article 5 of the Directive general transfer licences are granted ex officio. A request for them is not needed. All movements, which meet the given legal conditions of the licence, are authorized automatically.\nSuch licences give suppliers the chance and the opportunity to export different kinds of defence-related products to different recipients placed in different Member States without a request. \n\nUnder Article 5 of the Directive general transfer licences shall be published at least in the following cases:\n\nFor transfer\n\nArticle 9 of the Directive lays down the rules for the \"certification of recipients\" and provides some criteria, which have to be considered during the certification process. Furthermore there is the Commission Recommendation 2011/24/EU on the certification of defence undertakings under Article 9 of Directive 2009/43/EC.\nIn each Member State there is a competent authority, which has to carry out the certification of companies based on certain criteria. If a company is certified, suppliers from other Member States can deliver defence-related products to this company by using a general transfer licence. The certification will be valid for five years.\n\nArticle 8 (3) of the Directive foresees the obligation for the suppliers to keep certain records of their transfers. \n\nAccording to Article 8 (1,2) of the Directive suppliers have to inform \n\n"}
{"id": "34630062", "url": "https://en.wikipedia.org/wiki?curid=34630062", "title": "Electronic process of law", "text": "Electronic process of law\n\nElectronic process of law or Electronic lawsuit is an up-to-date phenomenon, concerning the use of computer programs in courts and public departments in sue activities. It is a theme of worldwide scope. In Portugal, it is known as the concept of \"processo eletrônico\". In India, known as \"Electronic Judicial Resource Management\". In France, it is called \"Dématerialisation du processus judiciaire\". It is a polissemic expression related to interdisciplinarity between the information technologies and branches of law that govern the lawsuits that take place in departments of public administration; more specifically, the control, follow-up, searches and practices of juridical acts helped by computer systems. Its universal definition can be found in various sources.\n\nInternationally, there is, in Virginia State, the \"Records Managements System\". In Pakistan, the \"Court Automation\". In England, the \"Legal Case Management Software\" There are sources of compared legislation about the matter, but it is certain that this phenomenon takes places in United States, Europe and also in Latin America.\n\nIn a wide sense, it is the use of computers and specific software for the activities in process of law, relative to management, legislation or jurisdiction. In a strict sense, it is a kind of management of the process of law in which media have the format of electronic files (text, pictures and audiovisual elements).\n\nThe electronic process of law has been referred as recurrently as a necessary phenomenon to lower the costs of the public finances, dealing with direct mechanisms, as well as indirect ones like the consequences of the gains with accelerating the lawsuits. These waited cause-effect relation and the best form to achieve them are object of discussions in the Public powers and in the social networks.\n\n"}
{"id": "5538465", "url": "https://en.wikipedia.org/wiki?curid=5538465", "title": "Endowment tax", "text": "Endowment tax\n\nEndowment tax is a US taxation of some endowments. Typically endowment payments, because of their attachment to non-profit organizations, are not taxed. Endowments can be up to several billion dollars at some of the richest universities in the United States. The non-profit status of some institutions like hospitals has been questioned in the United States House Ways and Means Committee.\n\nAs enacted in the Tax Cuts and Jobs Act of 2017 and amended by the Bipartisan Budget Act of 2018, a proposed excise tax of 1.4% will be levied on endowments supported by institutions who have at least 500 tuition-paying students with a resulting net asset of $500,000 per student. In turn, without adjusting the $500,000 for inflation, more institutions will result in being subject to this tax over time. Thus the tax applies to the wealthiest large institutions as well as some smaller colleges with small enrollments as of present day.\n\nTypically, a donation made to an endowment fund can be tax-deductible for those who give the contribution.\n\nThe city of Cambridge, Massachusetts, has proposed taxing MIT and other major universities on these previously exempt, non-profit earnings, however most organizations still fight against the introduction of this tax.\n\n\nWhen a donation exceeds 50 percent of the donor's adjusted gross income (AGI), the IRS will limit the amount of money donated by the donor.\nSome donors are likely to have a 20% to 30% tax exemption, and marital status may affect that amount, so it is best to consult a tax adviser before making a big charitable donation.\nIn addition, the life insurance death claim donation is not restricted by AGI.\n\nIn addition to donating money, many charities accept donations in kind, such as cars, houses and art.\nWhen a donation is made in kind, the donor must demonstrate the value of the donation in the open market to obtain the corresponding allowance.\nBefore donating to an asset that has increased in value since the purchase, it is important to consider whether it is better to donate directly to the asset or to donate after the sale.\nDirect donations can be taxed at the original purchase price without paying more tax on any potential profits.\n\nIf a donor receives an income tax credit on the day's value of the share transfer, he does not have to pay VAT on the added value of the donated stock.\nAnd after giving away the stock, the donor can buy back the stock at any time, so if you can buy back the stock, it will bring a significant amount of income.\nBut only 30 percent of the tax allowance is given, often less than cash donations.\nA property held for more than a year can be used as a charitable donation to be taxed at market prices.\nThe allowance is 30% of the adjusted gross income, but can be assessed within five years and can be deducted from the federal estate tax.\nDonors at the same time, also need not pay property taxes, maintenance fees, property tax and donors after donation will also retain rights in their lifetime, just put the permanent transfer of the land can get tax breaks.\n\nThe related expenses incurred in the donation can also be used to offset tax.\nThis is similar to the reimbursement of related expenses at work, which maximizes the benefit of the donor.\n\nIn order to encourage enterprises and individuals to donate to the public in the affected areas, the State Administration of Taxation stipulates that individuals should use their income for donation expenditures. The donation amount does not exceed 30% of the taxable income declared by the taxpayer, and the taxable income can be taxable from it. Deductions are made from the amount of income so as to offset part of the tax. The current tax law stipulates that public welfare donation expenses incurred by an enterprise shall be deducted from the calculation of taxable income in the portion of the total annual profit of less than 12%.\n\nNon-profit donations (through non-profit social organizations or the people's government departments at the county level and donations for prescribed public welfare undertakings) that occur in an enterprise can be used to calculate the amount of taxable income within 12% of the total annual profit.\nIndividual donations for public welfare donations that don't exceed 30% of the taxable income can be deducted; individuals donate real estate in the following cases: The parties do not levy individual income tax: Free the housing property to the spouse, parents, children, and the like. The grandparents, grandchildren, grandchildren, brothers and sisters, who directly support or support the family, shall obtain the inheritor of the house property rights, the heirs to the testator, or the bequeathor according to law. In the case of the above, the recipient's donated income received from the unpaid house is paid personal income tax in accordance with the “Other income taxed by the financial department of the State Council.”\n\nIndividuals may pass their income through social groups and state agencies in China to education and other social public welfare undertakings, as well as donations that have suffered serious natural disasters in areas and impoverished areas. The donation amount does not exceed 30% of the taxable income declared by taxpayers. It is deducted from its taxable income.\nIndividuals donating to rural compulsory education through non-profit social organizations and state agencies are allowed to fully deduct the amount of income before the individual income tax is paid.\n\n"}
{"id": "6503757", "url": "https://en.wikipedia.org/wiki?curid=6503757", "title": "Federal Rules of Appellate Procedure", "text": "Federal Rules of Appellate Procedure\n\nThe Federal Rules of Appellate Procedure (officially abbreviated Fed. R. App. P.; colloquially FRAP) are a set of rules, promulgated by the Supreme Court of the United States on recommendation of an advisory committee, to govern procedures in cases in the United States Courts of Appeals. \n\nThe Federal Rules of Appellate Procedure were originally adopted in 1967 and have been amended regularly since then. Prior to 1967, some aspects of appellate procedure were covered in the Federal Rules of Civil Procedure. \n\nIn addition to these rules, procedure in the Courts of Appeals is governed by applicable statutes (particularly Title 28 of the United States Code) and by local rules adopted by each individual court. Many of these local rules incorporate Federal Rules of Appellate Procedure by reference.\n\n"}
{"id": "15707077", "url": "https://en.wikipedia.org/wiki?curid=15707077", "title": "Frontier justice", "text": "Frontier justice\n\nFrontier justice (also called vigilante justice or street justice) is extrajudicial punishment that is motivated by the nonexistence of law and order or dissatisfaction with justice. The phrase can also be used to describe a prejudiced judge. Lynching and gunfighting are considered forms of frontier justice.\n\n\n\n"}
{"id": "11145743", "url": "https://en.wikipedia.org/wiki?curid=11145743", "title": "Furnival's Inn", "text": "Furnival's Inn\n\nFurnival's Inn was an Inn of Chancery which formerly stood on the site of the present Holborn Bars building (the former Prudential Assurance Company building) in Holborn, London, England.\n\nFurnival's Inn was founded about 1383 when William de Furnival, 4th Lord Furnival leased a boarding facility to Clerks of Chancery, who prepared writs for the king’s courts, assisted by apprentices who, as such, received a preliminary legal training.\nBy the 15th century the Inns of Chancery had become preparatory schools for students wishing to be called to the bar by the Inns of Court. In 1548 it was affiliated to Lincoln's Inn through a long term lease. Sir Thomas More was Reader at the Inn from 1504 to 1507.\n\nBy the seventeenth century, the Inns of Chancery began to turn into societies for attorneys and solicitors; they became residences, offices and dining clubs. The greater part of the old Inn was taken down in Charles I.'s time, and a new building erected in its stead. Although it survived the Great Fire of London, the Inn, together with the other Inns of Chancery, ceased to exist in the 19th century. According to the \"Gentleman's Magazine\" of June 1818, \"'Furnival's Inn Cellar' was a place well known to the professional gentlemen, where a good dinner may be had at a reasonable price.\" The Inn was dissolved as a society in 1817 when Lincoln's Inn did not renew its lease and the medieval building was demolished in 1818. The building was rebuilt as apartments by a new owner who retained the old name.\nCharles Dickens rented rooms here between December 1834 and throughout the first year of his marriage, until 1837. He began the \"Pickwick Papers\" while a tenant there. The character John Westlock in \"Martin Chuzzlewit\" lives in Furnival’s Inn, and describes it as \"...a shady, quiet place, echoing to the footsteps of the stragglers who have business there; and rather monotonous and gloomy on summer evenings. ... there are snug chambers in those Inns where the bachelors live, and, for the desolate fellows they pretend to be, it is quite surprising how well they get on\".\n\nJ.M. Barrie lived in a set of chambers at No. 7 Furnival's Inn from 1888 to 1889. The site was redeveloped again, in 1879, as the headquarters of the Prudential Assurance. A plaque marks the site where Furnival's Inn stood.\n\nFurnival's Inn was an area for local government partly in the City of London and partly in Middlesex. It was an extra-parochial area and became a civil parish in 1858 within the Holborn Poor Law Union. The part within the City of London was transferred to St Andrew Holborn in 1900. The remaining parish was part of the Metropolitan Borough of Holborn from 1900 and was abolished as a civil parish in 1930. It was unpopulated after the construction of Holborn Bars.\n\n\n\n"}
{"id": "52716809", "url": "https://en.wikipedia.org/wiki?curid=52716809", "title": "Genetic privacy", "text": "Genetic privacy\n\nGenetic privacy involves the right or mandate of personal privacy concerning the storing, repurposing, provision to third parties, and displaying of information pertaining to one's genetic information. The advent of new technologies streamline high-throughput, low-cost sequencing of human genomes that raises important ethical concerns about the future of healthcare. \n\nDr. Yaniv Erlich conducted a study in 2013 that revealed vulnerabilities in the security of public databases that contain genetic data. Erlich's study reported a method to discover the identity of anonymous research subjects whose genomes had been sequenced as part of a genomics project. As a result, research subjects could sometimes be identified by their DNA alone. \n\nMark Bender Gerstein, a Yale professor who studies large genetic databases notes that \"research subjects who share their DNA may risk a loss of not just their own privacy but also that of their children and grandchildren, who will inherit many of the same genes\".\n\nFurthermore, the vast databases of corporations or states are susceptible to get breached by criminals or governments. There is a controversy regarding the responsibility that a DNA testing company has to ensure that leaks and breaches do not happen. Regulation rules are not clearly laid out. What is still not determined is who legally owns the genome information: the company or the individual whose genome has been read. There have been published examples of personal genome information being exploited. Additional privacy concerns, related to, e.g., genetic discrimination, loss of anonymity, and psychological impacts, have been increasingly pointed out by the academic community as well as government agencies.\n\nDr. David Altshuler of the Broad Institute of Harvard and M.I.T. notes that the amount of genetic data that has been gathered so far () is minuscule compared with what will be coming in the next few years, making it important to address the problems before the data deluge makes them worse, saying that they \"see substantial issues\" and \"want to have serious discussions now\".\n\nThe American Society of Human Genetics has brought up issues about administering genetic tests on children. Moreover, they infer that this could lead to negative consequences for the children. Some of the negative consequences that this could lead to include the child’s likelihood of getting adopted which as a result could lead the child to suffer from self esteem issues; the child’s well-being could also suffer because of things like paternity testing or a custody battle requiring this type of information.\n\nA 2015 study found that state genetic privacy laws take three alternative approaches to protecting patient privacy: requiring informed consent on the part of the individual; restricting discriminatory usage of genetic data by employers, health care providers or insurance companies; or limiting redisclosure without the consent of the individual or defining genetic data as the 'property' of the individual\" and that \"giving users control over redisclosure encourage the spread of genetic testing, but that\nthe informed consent approach deters individuals from obtaining genetic tests\".\n\nWhen the access of genetic information is regulated it can prevent insurance companies and employers from reaching such data. Further, this could avoid issues of discrimination which could oftentimes leave an individual whose information has been breached without a job or without insurance.\n\nThe Genetic Information Nondiscrimination Act of 2008 (GINA) protects the genetic privacy of the public, including research participants. The passage of GINA makes it illegal for health insurers or employers to request or require genetic information of an individual or of family members (and further prohibits the discriminatory use of such information). More information on GINA is available here.\n\nIn the United States, biomedical research containing human subjects is governed by a baseline standard of ethics known as The Common Rule, which aims to protect a subject's privacy by requiring \"identifiers\" such as name or address to be removed from collected data. A 2012 report by the Presidential Commission for the Study of Bioethical Issues stated, however, that \"what constitutes 'identifiable' and 'de-identified' data is fluid and that evolving technologies and the increasing accessibility of data could allow de-identified data to become re-identified\". In fact, research has already shown that it is \"possible to discover a study participant's identity by cross-referencing research data about him and his DNA sequence … [with] genetic genealogy and public-records databases\". This has led to calls for policy-makers to establish consistent guidelines and best practices for the accessibility and usage of individual genomic data collected by researchers.\n\nPrivacy protections for genetic research participants were strengthened by provisions of the 21st Century Cures Act (H.R.34) passed on 7 December 2016 for which the American Society of Human Genetics (ASHG) commended Congress, Senator Warren and Senator Enzi.\n\nTo balance data sharing with the need to protect the privacy of research subjects geneticists are considering to move more data behind controlled-access barriers, authorizing trusted users to access the data from many studies, rather than \"having to obtain it piecemeal from different studies\".\n\nIn October 2005, IBM became the world's first major corporation to establish a genetics privacy policy. Its policy prohibits using employees' genetic information in employment decisions.\n\nAccording to a 2014 study genetic privacy breaching by Yaniv Erlich and Arvind Narayanan techniques fall into three categories:\n\n\n\n"}
{"id": "42148961", "url": "https://en.wikipedia.org/wiki?curid=42148961", "title": "Instituto Nacional del Derecho de Autor", "text": "Instituto Nacional del Derecho de Autor\n\nThe Instituto Nacional del Derecho de Autor is Mexico's Copyright office. It works at a federal level.\n"}
{"id": "47955481", "url": "https://en.wikipedia.org/wiki?curid=47955481", "title": "Intellectual Property and Technology Forum", "text": "Intellectual Property and Technology Forum\n\nThe Intellectual Property & Technology Forum & Journal, (\"Boston Coll. Intell. Prop. & Tech. F.\"), at Boston College Law School is an academic journal dedicated to technology law and intellectual property.\n\nThe journal publishes an online blog and a legal publication called the \"Intellectual Property and Technology Forum Journal\", which is currently ranked in the Washington and Lee School of Law Law Journal Rankings. The journal publishes two issues each year, and is designed, edited and published by second and third-year law students.\n"}
{"id": "7198484", "url": "https://en.wikipedia.org/wiki?curid=7198484", "title": "Internal security", "text": "Internal security\n\nInternal security, or IS, is the act of keeping peace within the borders of a sovereign state or other self-governing territories, generally by upholding the national law and defending against internal security threats. Responsibility for internal security may range from police to paramilitary forces, and in exceptional circumstances, the military itself.\n\nThreats to the general peace may range from low-level civil disorder, large scale violence, or even an armed insurgency. Threats to internal security may be directed at either the state's citizens, or the organs and infrastructure of the state itself, and may range from petty crime, serious organised crime, political or industrial unrest, or even domestic terrorism. Foreign powers may also act as a threat to internal security, by either committing or sponsoring terrorism or rebellion, without actually declaring war.\n\nGovernmental responsibility for internal security will generally rest with an interior ministry, as opposed to a defence ministry. Depending on the state, a state's internal security will be maintained by either the ordinary police or law enforcement agencies or more militarised police forces (known as Gendarmerie or, literally, the Internal Troops.). Other specialised internal security agencies may exist to augment these main forces, such as border guards, special police units, or aspects of the state's intelligence agencies. In some states, internal security may be the primary responsibility of a secret police force.\n\nThe level of authorised force used by agencies and forces responsible for maintaining internal security might range from unarmed police to fully armed paramilitary organisations, or employ some level of less-lethal weaponry in between. For violent situations, internal security forces may contain some element of military type equipment such as non-military armored vehicles.\n\nDepending on the organisation of the state, internal security forces may have jurisdiction on national or federal levels. As the concept of internal security refers to the entity of the state and its citizens, persons who are threats to internal security may be designated as an enemy of the state or enemy of the people.\n\nPersons detained by internal security forces may either be dealt with by the normal criminal justice system, or for more serious crimes against internal security such as treason, they may face special measures such as secret trials. In times of extreme unrest, internal security actions may include measures such as internment (detention without trial).\n\nDepending on the nature of the specific state's form of government, enforcing internal security will generally not be carried out by a country's military forces, whose primary role is external defence, except in times of extreme unrest or other state of emergency, short of civil war. Often, military involvement in internal security is explicitly prohibited, or is restricted to authorised military aid to the civil power as part of the principle of civilian control of the military. Military special forces units may in some cases be put under the temporary command of civilian powers, for special internal security situations such as counter terrorism operations.\n\n"}
{"id": "1673120", "url": "https://en.wikipedia.org/wiki?curid=1673120", "title": "International Centre for Settlement of Investment Disputes", "text": "International Centre for Settlement of Investment Disputes\n\nThe International Centre for Settlement of Investment Disputes (ICSID) is an international arbitration institution established in 1966 for legal dispute resolution and conciliation between international investors. The ICSID is part of and funded by the World Bank Group, headquartered in Washington, D.C., in the United States. It is an autonomous, multilateral specialized institution to encourage international flow of investment and mitigate non-commercial risks by a treaty drafted by the International Bank for Reconstruction and Development's executive directors and signed by member countries. , 153 contracting member states agreed to enforce and uphold arbitral awards in accordance with the ICSID Convention.\n\nThe center performs advisory activities and maintains several publications.\n\nIn the 1950s and 1960s, the Organization for European Economic Cooperation (now the Organisation for Economic Co-operation and Development) had made several attempts to create a framework to protect international investments, but its efforts revealed conflicting views on how to provide compensation for the expropriation of foreign direct investment.\n\nIn 1961, then-General Counsel of the International Bank for Reconstruction and Development (IBRD) Aron Broches developed the idea for a multilateral agreement on a process for resolving individual investment disputes on a case by case basis as opposed to imposing outcomes based on standards. Broches held conferences to consult legal experts from all parts of the world, including Europe, Africa, and Asia, to discuss and compose a preliminary agreement. The IBRD staff wrote an official draft of the agreement and consulted with legal representatives of the IBRD's board of directors to finalize the draft and have it approved.\n\nThe board of directors approved the final draft of the agreement, titled \"Convention on the Settlement of Investment Disputes between States and Nationals of Other States\", and the Bank president disseminated the convention to its member states for signature on 18 March 1965. Twenty states immediately ratified the convention. The convention established the ICSID would become officially active on 14 October 1966.\n\nThe Indonesian government was sued in June 2012 by a London-based mining company Churchill Mining after the local government revoked the concession rights held by a local company in which the firm had invested. The government is countering the Churchill case, claiming that Churchill did not have the correct type of mining licenses.\n\nIn October 2012, an ICSID tribunal awarded a judgment of $1.8 billion for Occidental Petroleum against the government of Ecuador. Additionally, Ecuador had to pay $589 million in backdated compound interest and half of the costs of the tribunal, making its total penalty around $2.4 billion. The South American country annulled a contract with the oil firm on the grounds that it violated a clause that the company would not sell its rights to another firm without permission. The tribunal agreed the violation took place but judged that the annulment was not fair and equitable treatment to the company.\n\nIrish oil firm Tullow Oil took the Ugandan government to court in November 2012 after value-added tax (VAT) was placed on goods and services the firm purchased for its operations in the country. The Ugandan government responded that the company had no right to claim tax on such goods prior to commencement of drilling.\n\nTobacco major Philip Morris sued Uruguay for alleged breaches to the Uruguay-Swiss BIT for requiring cigarette packs to display graphic health warnings and sued Australia under the Australia-Hong Kong BITS for requiring plain packaging for its cigarettes. The company claimed that the packaging requirements in both countries violate its investment.\n\nIn the context of Nuclear power phase-out in Germany, Swedish Energy company Vattenfall sought compensation from the German government for the premature shut-down of nuclear plants.\n\nBilateral investment treaties (BITs) proliferated during the first decade of the 21st century, reaching more than 2,500 by 2007. Many such treaties contain text that refers present and future investment disputes to the ICSID.\n\nFrom its launch to 30 June 2012, the ICSID has registered 390 dispute cases. The ICSID's caseload consisted of 88% convention arbitration cases, 2% convention conciliation cases, as well as 9% additional facility arbitration cases, and 1% additional facility conciliation cases. The ICSID's registered cases were distributed across oil, gas and mining (25%), electricity and other energy (13%), other industries (12%), transportation industry (11%), construction industry (7%), financial industry (7%), information industry and communication industry (6%), water industry, sanitation, and food protection (6%), agriculture, fishing, and forestry (5%), services and trade (4%), and tourism industry (4%).\n\n, 246 of 390 registered arbitration cases were concluded, , the ICSID's tribunal had resolved nearly two thirds (62%) of disputes while the remainder (38%) were settled or discontinued. \n, 362 of 574 (62%) registered arbitration cases were concluded .\nConciliation commission reports were issued for 67% of the conciliation proceedings, while 33% of proceedings were discontinued. In 75% of the conciliation reports, parties failed to reach agreement, and only 25% recorded agreement among parties.\n\nThe ICSID is governed by its Administrative Council which meets annually and elects the center's secretary-general and deputy secretary-general, approves rules and regulations, conducts the center's case proceedings, and approves the center's budget and annual report. The council consists of one representative from each of the center's contracting member states and is chaired by the President of the World Bank Group, although the president may not vote. The ICSID's normal operations are carried out by its secretariat, which comprises 40 employees and is led by the secretary-general of the ICSID. The secretariat provides support to the Administrative Council in conducting the center's proceedings. It also manages the center's Panel of Conciliators and Panel of Arbitrators. Each contracting member state may appoint four persons to each panel. In addition to serving as the center's principal, the secretary-general is responsible for legally representing the ICSID and serving as the registrar of its proceedings. , Meg Kinnear serves as the center's secretary-general.\n\nICSID's 161 member states which have signed the center's convention include 160 United Nations member states plus Kosovo. Of these member states, only 153 are \"contracting member states\", that is they have ratified the contract. Former members are Bolivia, Ecuador (withdrew 2009), and Venezuela, which withdrew in 2012. \nAll ICSID contracting member states, whether or not they are parties to a given dispute, are required by the ICSID Convention to recognize and enforce ICSID arbitral awards.\n\nThe following member states have signed the ICSID convention (date in parentheses), but have not ratified it.\n\nBrazil, India, Mexico and South Africa are countries with large economies that have never been ICSID members, until January 2018 when Mexico joined the ICSID.\n\nThe ICSID does not conduct arbitration or conciliation proceedings itself, but offers institutional and procedural support to conciliation commissions, tribunals, and other committees which conduct such matters. The center has two sets of rules that determine how cases will be initiated and conducted, either under the ICSID's Convention, Regulations and Rules or the ICSID's Additional Facility Rules. To be processed in accordance with the ICSID Convention, a legal dispute has to exist between one of the center's contracting member states and a national of another contracting member state. It must also be of a legal nature and relate directly to an investment. A case can be processed under the ICSID Additional Facility Rules if one of the parties to the dispute is either not a contracting member state or a national of a contracting member state. However, most cases are arbitrated under the ICSID Convention. Recourse to ICSID conciliation and arbitration is entirely voluntary. However, once the parties have consented to arbitration under the ICSID Convention, neither party can unilaterally withdraw its consent.\n\nThe ICSID Secretariat may also administer dispute resolution proceedings under other treaties and regularly assists tribunals or disputing parties in arbitrations among investors and states under the United Nations Commission on International Trade Law (UNCITRAL)'s arbitration regulations. The center provides administrative and technical support for a number of international dispute resolution proceedings through alternative facilities such as the Permanent Court of Arbitration in The Hague, Netherlands, the London Court of International Arbitration, and the International Chamber of Commerce in Paris, France.\n\nThe ICSID also conducts advisory activities and research and publishes \"Investment Laws of the World and of Investment Treaties\". Since April 1986, the center has published a semi-annual law journal entitled \"ICSID Review: Foreign Investment Law Journal\".\n\nAlthough the ICSID's proceedings generally take place in Washington, D.C., parties may agree that proceedings be held at one of a number of possible alternative locations, including the Permanent Court of Arbitration, the Regional Arbitration Centres of the Asian-African Legal Consultative Committee in Cairo, in Kuala Lumpur, or in Lagos, the Australian Centre for International Commercial Arbitration in Melbourne, the Australian Commercial Disputes Centre in Sydney, the Singapore International Arbitration Centre, the Gulf Cooperation Council Commercial Arbitration Centre in Bahrain, the German Institution of Arbitration, the Maxwell Chambers in Singapore, the Hong Kong International Arbitration Centre, and the Centre for Arbitration and Conciliation at the Chamber of Commerce of Bogota.\n\n\n"}
{"id": "13064676", "url": "https://en.wikipedia.org/wiki?curid=13064676", "title": "Jose L. Torero", "text": "Jose L. Torero\n\nJosé Luis Torero (born in Lima, Peru) is the John L. Bryan Chair in the Department of Fire Protection Engineering and Director of the Center for Disaster Resilience in the Department of Civil and Environmental Engineering at the University of Maryland (USA). He was formerly the Head of the School of Civil Engineering at the University of Queensland (2012-2017). He is Fellow of the Royal Academy of Engineering (UK) since 2010, the Australian Academy of Technological Sciences and Engineering since 2014 and The Royal Society of Edinburgh (UK) since 2008. He held the BRE/RAE Chair in Fire Safety Engineering and directed the BRE Centre for Fire Safety Engineering from 2004 to 2012.\n\nHe was co-Chair of Fire Safety at the Council on Tall Buildings and Urban Habitat from 2009-2015.\n\nHe was the Editor-in-Chief of \"Fire Safety Journal\" (2010 - 2016) and a member of the editorial board member of numerous journals including \"Fire Technology\", and \"Progress in Energy and Combustion Science\".\n\nTorero has contributed mainly to the fields of combustion and fire sciences. His research work is in fire dynamics, flame spread, smouldering, combustion in microgravity, smoke detection, protection and suppression systems, and professional education in fire safety engineering. Since moving to Edinburgh in 2001 he has developed expertise in the behaviour of structures in fire and the use of combustion to remediate contaminated land.\n\nHe has received several awards that include the Tam Dalyell science prize (2010), Lord Ezra Award by the Combustion Engineering Association (2009), the Arthur B. Guise Medal from the Society of Fire Protection Engineers (2008), Bodycote Warrington Fire Research Prize (2007), FM Global Award at the 5th Fire and Explosions Hazard International Seminar (2007), William M. Carey (2001) and Harry C. Bigglestone (2001) best paper awards, the Lilly-Center for Teaching Excellence (1996) and E. Robert Kent (1998) Outstanding Teaching awards and honorary membership to the Salamander Fire Protection Engineering Society.\n\nTorero has served as a consultant to numerous organisations around the world. He has been an invited researcher at NIST, at the University of Texas at Austin, the University of California at Berkeley, the University of Bremen, the Catholic University of Santiago (Chile), the Instituto Nacional de Tecnica Aeroespacial (INTA, Spain), and the Universities of Poitiers, Bourges, Ecole de Mines de Saint Etienne and Aix-Marseille (France) . In 2011 he held the Landolt & Cia. Chair in Innovations for a Sustainable Future at the Ecole Polytechnique Fédérale de Lausanne.\n\nTorero has returned to the University of Maryland. Currently, he is the John L. Bryan Chair of the Department of Fire Protection Engineering in the A. James Clark School of Engineering, and the Director of the Center for Disaster Resilience within the school's Department of Civil and Environmental Engineering. Torero comes to the Clark School from the University of Queensland in Australia, where he chaired the School of Civil Engineering. Prior to that, he held the BRE Trust/Royal Academy of Engineering Chair in Fire Safety Engineering at the University of Edinburgh and worked as an associate professor at UMD’s Department of Fire Protection Engineering. Torero has also served as Chargé de Recherche at the French National Centre for Scientific Research. He obtained his PhD in 1992 from the University of California, Berkeley, where he studied smoldering combustion and fire safety. He graduated with a B.S. in Mechanical Engineering from Pontificia Universidad Católica del Perú.\n\n"}
{"id": "55290879", "url": "https://en.wikipedia.org/wiki?curid=55290879", "title": "Journal of Law and Religion", "text": "Journal of Law and Religion\n\nThe Journal of Law and Religion is a peer-reviewed, interdisciplinary journal published through Cambridge University Press and edited by the Center for the Study of Law and Religion at Emory University School of Law. Its primary interests include topics related to the relationship between religion and law, including subjects related to theological jurisprudence and political theology.\n\nThe journal was founded at Hamline University School of Law by the Harvard Law professor Harold J. Berman in 1982 along with Stephen B.Young, then Dean of the law school. The Council on Religion and Law and Harvard Divinity School Professor James Luther Adams were also instrumental in starting the Journal. The goal of the Journal was to provide multiple frameworks of analysis for the study and discussion of structures of positive law. The Journal moved to the Center for the Study of Law and Religion at Emory in 2013, two years prior to Hamline's merger with William Mitchell College of Law.\n\nThe Journal's co-editors include Silas Allard, Abdullahi Ahmed An-Na'im, Michael Broyde, M. Christian Green, Michael J. Perry, and John Witte, Jr.\n"}
{"id": "14624336", "url": "https://en.wikipedia.org/wiki?curid=14624336", "title": "Jus tertii", "text": "Jus tertii\n\nJus tertii (Latin, “\"third party rights\"”) is the legal classification for an argument made by a third party (as opposed to the legal title holder) which attempts to justify entitlement to possessory rights based on the showing of legal title in another person. By showing legitimate title in another person, \"jus tertii\" arguments imply that the present possessor’s interest is illegitimate or that the present possessor is a thief.\n\nUnder United States law, \"jus tertii\" arguments are generally insufficient to support actions for replevin because they fail to show that possession is \"more\" legitimate in the third party than in the present possessor. However, a bailee or other legal agent of the owner may successfully assert the argument.\n\nThe principle is sometimes used to allow one person to enforce or test the constitutional rights of another, which usually can't be done due to lack of standing. This is only possible for fundamental rights, where there is a close connection between the person whose rights are violated and the person wishing to enforce them, and the constitutional right being enforced is a fundamental right. See, e.g., \"Singleton v. Wulff\" Et Al., 96 S. Ct. 2868, 428 U.S. 106 (U.S. 1976).\n\nArt brings an action for replevin against Burt, seeking to recover a bicycle. In support for the action, Art presents evidence that Cathy is in fact the true owner of the bicycle in question, not Burt. A US court would reject Art’s \"jus tertii\" argument for replevin because he has failed to show that he has a more legitimate interest in the bike than Burt.\n\nIn \"Gissel v. State\", 727 P.2d 1153 (Idaho 1986), Gissel unlawfully harvested wild rice growing on land jointly owned by the state of Idaho and the National Forest Service. An Idaho Court convicted Gissel of trespass, and Idaho officials seized and sold the rice at auction. Because Idaho had only one half interest in the land, Gissel challenged the state’s authority to seize, sell, and keep the profits from all of the rice. The Idaho Supreme Court held that Gissel was entitled to half of the profits because Idaho did not effectively make the \"jus tertii\" argument on behalf of the federal government, “the Gissels, though trespassers and without legal title, which title rests with the Forest Service, still by mere possession have greater rights superior to that of the state.”\n\nThe \"jus tertii\" principle also extends to criminal law. For example, in \"Anic, Stylianou & Suleyman v R\", three men were charged with larceny (among other things) after breaking into a house to steal drugs. The men argued that they should not be charged with stealing something which is unlawfully possessed. The court rejected this argument on the basis that larceny has always been an offence against possession. The common law has never recognised an absolute right of ownership. The owner is merely the person who has the best right to possession. Therefore, a person can be guilty of larceny by stealing from someone who had stolen the thing from someone else. The right to possess drugs is limited by statute but the occupant of the house had a better right to possession than the defendants.\n\n"}
{"id": "16775", "url": "https://en.wikipedia.org/wiki?curid=16775", "title": "Kyoto Protocol", "text": "Kyoto Protocol\n\nThe Kyoto Protocol is an international treaty which extends the 1992 United Nations Framework Convention on Climate Change (UNFCCC) that commits state parties to reduce greenhouse gas emissions, based on the scientific consensus that (part one) global warming is occurring and (part two) it is extremely likely that human-made CO emissions have predominantly caused it. The Kyoto Protocol was adopted in Kyoto, Japan on 11 December 1997 and entered into force on 16 February 2005. There are currently 192 parties (Canada withdrew from the protocol, effective December 2012) to the Protocol.\n\nThe Kyoto Protocol implemented the objective of the UNFCCC to reduce the onset of global warming by reducing greenhouse gas concentrations in the atmosphere to \"a level that would prevent dangerous anthropogenic interference with the climate system\" (Article 2). The Kyoto Protocol applies to the six greenhouse gases listed in Annex A: Carbon dioxide (CO2), Methane (CH4), Nitrous oxide (N2O), Hydrofluorocarbons (HFCs) Perfluorocarbons (PFCs) and Sulphur hexafluoride (SF6). \n\nThe Protocol is based on the principle of common but differentiated responsibilities: it acknowledges that individual countries have different capabilities in combating climate change, owing to economic development, and ergo puts the obligation to reduce current emissions on developed countries on the basis that they are historically responsible for the current levels of greenhouse gases in the atmosphere.\n\nThe Protocol's first commitment period started in 2008 and ended in 2012. A second commitment period was agreed on in 2012, known as the Doha Amendment to the Kyoto Protocol, in which 37 countries have binding targets: Australia, the European Union (and its 28 member states), Belarus, Iceland, Kazakhstan, Liechtenstein, Norway, Switzerland and Ukraine. Belarus, Kazakhstan and Ukraine have stated that they may withdraw from the Kyoto Protocol or not put into legal force the Amendment with second round targets. Japan, New Zealand and Russia have participated in Kyoto's first-round but have not taken on new targets in the second commitment period. Other developed countries without second-round targets are Canada (which withdrew from the Kyoto Protocol in 2012) and the United States (which has not ratified). As of November 2018, 122 states have accepted the Doha Amendment, while entry into force requires the acceptances of 144 states. Of the 37 countries with binding commitments, 7 have ratified.\n\nNegotiations were held in the framework of the yearly UNFCCC Climate Change Conferences on measures to be taken after the second commitment period ends in 2020. This resulted in the 2015 adoption of the Paris Agreement, which is a separate instrument under the UNFCCC rather than an amendment of the Kyoto Protocol.\n\nThe view that human activities are likely responsible for most of the observed increase in global mean temperature (\"global warming\") since the mid-20th century is an accurate reflection of current scientific thinking. Human-induced warming of the climate is expected to continue throughout the 21st century and beyond.\n\nThe Intergovernmental Panel on Climate Change (IPCC, 2007) have produced a range of projections of what the future increase in global mean temperature might be. The IPCC's projections are \"baseline\" projections, meaning that they assume no future efforts are made to reduce greenhouse gas emissions. The IPCC projections cover the time period from the beginning of the 21st century to the end of the 21st century. The \"likely\" range (as assessed to have a greater than 66% probability of being correct, based on the IPCC's expert judgement) is a projected increase in global mean temperature over the 21st century of between 1.1 and 6.4 °C.\n\nThe range in temperature projections partly reflects different projections of future greenhouse gas emissions. Different projections contain different assumptions of future social and economic development (economic growth, population level, energy policies), which in turn affects projections of future greenhouse gas (GHG) emissions. The range also reflects uncertainty in the response of the climate system to past and future GHG emissions (measured by the climate sensitivity).\n\n1992 The UN Conference on the Environment and Development is held in Rio de Janeiro. It results in the Framework Convention on Climate Change (\"FCCC\" or \"UNFCCC\") among other agreements.\n\n1995 Parties to the UNFCCC meet in Berlin (the 1st Conference of Parties (COP) to the UNFCCC) to outline specific targets on emissions.\n\n1997 In December the parties conclude the Kyoto Protocol in Kyoto, Japan, in which they agree to the broad outlines of emissions targets.\n\n2004 Russia and Canada ratify the Kyoto Protocol to the UNFCCC bringing the treaty into effect on 16 February 2005.\n\n2011 Canada became the first signatory to announce its withdrawal from the Kyoto Protocol.\n\n2012 On 31 December 2012, the first commitment period under the Protocol expired.\n\nMost countries are Parties to the United Nations Framework Convention on Climate Change (UNFCCC). Article 2 of the Convention states its ultimate objective, which is to stabilize the concentration of greenhouse gases in the atmosphere \"at a level that would prevent dangerous anthropogenic (human) interference with the climate system.\"\n\nThe natural, technical and social sciences can provide information on decisions relating to this objective including the possible magnitude and rate of future climate changes. However, the IPCC has also concluded that the decision of what constitutes \"dangerous\" interference requires value judgements, which will vary between different regions of the world. Factors that might affect this decision include the local consequences of climate change impacts, the ability of a particular region to adapt to climate change (adaptive capacity), and the ability of a region to reduce its GHG emissions (mitigative capacity).\n\nThe main goal of the Kyoto Protocol is to control emissions of the main anthropogenic (human-emitted) greenhouse gases (GHGs) in ways that reflect underlying national differences in GHG emissions, wealth, and capacity to make the reductions. The treaty follows the main principles agreed in the original 1992 UN Framework Convention. According to the treaty, in 2012, Annex I Parties who have ratified the treaty must have fulfilled their obligations of greenhouse gas emissions limitations established for the Kyoto Protocol's first commitment period (2008–2012). These emissions limitation commitments are listed in Annex B of the Protocol.\n\nThe Kyoto Protocol's first round commitments are the first detailed step taken within the UN Framework Convention on Climate Change. The Protocol establishes a structure of rolling emission reduction commitment periods. It set a timetable starting in 2006 for negotiations to establish emission reduction commitments for a second commitment period. The first period emission reduction commitments expired on 31 December 2012.\n\nThe ultimate objective of the UNFCCC is the \"stabilization of greenhouse gas concentrations in the atmosphere at a level that would stop dangerous anthropogenic interference with the climate system.\" Even if Annex I Parties succeed in meeting their first-round commitments, much greater emission reductions will be required in future to stabilize atmospheric GHG concentrations.\n\nFor each of the different anthropogenic GHGs, different levels of emissions reductions would be required to meet the objective of stabilizing atmospheric concentrations (see United Nations Framework Convention on Climate Change#Stabilization of greenhouse gas concentrations). Carbon dioxide () is the most important anthropogenic GHG. Stabilizing the concentration of in the atmosphere would ultimately require the effective elimination of anthropogenic emissions.\n\nSome of the principal concepts of the Kyoto Protocol are:\n\nUnder the Kyoto Protocol, 37 industrialized countries and the European Community (the European Union-15, made up of 15 states at the time of the Kyoto negotiations) commit themselves to binding targets for GHG emissions. The targets apply to the four greenhouse gases carbon dioxide (), methane (), nitrous oxide (), sulphur hexafluoride (), and two groups of gases, hydrofluorocarbons (HFCs) and perfluorocarbons (PFCs). The six GHG are translated into CO equivalents in determining reductions in emissions. These reduction targets are in addition to the industrial gases, chlorofluorocarbons, or CFCs, which are dealt with under the 1987 Montreal Protocol on Substances that Deplete the Ozone Layer.\n\nUnder the Protocol, only the Annex I Parties have committed themselves to national or joint reduction targets (formally called \"quantified emission limitation and reduction objectives\" (QELRO) – Article 4.1). Parties to the Kyoto Protocol not listed in Annex I of the Convention (the non-Annex I Parties) are mostly low-income developing countries, and may participate in the Kyoto Protocol through the Clean Development Mechanism (explained below).\n\nThe emissions limitations of Annex I Parties varies between different Parties. Some Parties have emissions limitations reduce below the base year level, some have limitations at the base year level (no permitted increase above the base year level), while others have limitations above the base year level.\n\nEmission limits do not include emissions by international aviation and shipping. Although Belarus and Turkey are listed in the Convention's Annex I, they do not have emissions targets as they were not Annex I Parties when the Protocol was adopted. Kazakhstan does not have a target, but has declared that it wishes to become an Annex I Party to the Convention.\n\nFor most state parties, 1990 is the base year for the national GHG inventory and the calculation of the assigned amount. However, five state parties have an alternative base year:\n\nAnnex I Parties can use a range of sophisticated \"flexibility\" mechanisms (see below) to meet their targets. Annex I Parties can achieve their targets by allocating reduced annual allowances to major operators within their borders, or by allowing these operators to exceed their allocations by offsetting any excess through a mechanism that is agreed by all the parties to the UNFCCC, such as by buying emission allowances from other operators which have excess emissions credits.\n\nThe Protocol defines three \"flexibility mechanisms\" that can be used by Annex I Parties in meeting their emission limitation commitments. The flexibility mechanisms are International Emissions Trading (IET), the Clean Development Mechanism (CDM), and Joint Implementation (JI). IET allows Annex I Parties to \"trade\" their emissions (Assigned Amount Units, AAUs, or \"allowances\" for short).\n\nThe economic basis for providing this flexibility is that the marginal cost of reducing (or abating) emissions differs among countries. \"Marginal cost\" is the cost of abating the last tonne of -eq for an Annex I/non-Annex I Party. At the time of the original Kyoto targets, studies suggested that the flexibility mechanisms could reduce the overall (aggregate) cost of meeting the targets. Studies also showed that national losses in Annex I gross domestic product (GDP) could be reduced by use of the flexibility mechanisms.\n\nThe CDM and JI are called \"project-based mechanisms,\" in that they generate emission reductions from projects. The difference between IET and the project-based mechanisms is that IET is based on the setting of a quantitative restriction of emissions, while the CDM and JI are based on the idea of \"production\" of emission reductions. The CDM is designed to encourage production of emission reductions in non-Annex I Parties, while JI encourages production of emission reductions in Annex I Parties.\n\nThe production of emission reductions generated by the CDM and JI can be used by Annex I Parties in meeting their emission limitation commitments. The emission reductions produced by the CDM and JI are both measured against a hypothetical baseline of emissions that would have occurred in the absence of a particular emission reduction project. The emission reductions produced by the CDM are called Certified Emission Reductions (CERs); reductions produced by JI are called Emission Reduction Units (ERUs). The reductions are called \"credits\" because they are emission reductions credited against a hypothetical baseline of emissions.\n\nEach Annex I country is required to submit an annual report of inventories of all anthropogenic greenhouse gas emissions from sources and removals from sinks under UNFCCC and the Kyoto Protocol. These countries nominate a person (called a \"designated national authority\") to create and manage its greenhouse gas inventory. Virtually all of the non-Annex I countries have also established a designated national authority to manage their Kyoto obligations, specifically the \"CDM process\". This determines which GHG projects they wish to propose for accreditation by the CDM Executive Board.\n\nA number of emissions trading schemes (ETS) have been, or are planned to be, implemented.\n\n\n\n\n\nThe design of the European Union Emissions Trading Scheme (EU ETS) implicitly allows for trade of national Kyoto obligations to occur between participating countries (Carbon Trust, 2009, p. 24). Carbon Trust (2009, pp. 24–25) found that other than the trading that occurs as part of the EU ETS, no intergovernmental emissions trading had taken place.\n\nOne of the environmental problems with IET is the large surplus of allowances that are available. Russia, Ukraine, and the new EU-12 member states (the Kyoto Parties Annex I Economies-in-Transition, abbreviated \"IET\": Belarus, Bulgaria, Croatia, Czech Republic, Estonia, Hungary, Latvia, Lithuania, Poland, Romania, Russia, Slovakia, Slovenia, and Ukraine) have a surplus of allowances, while many OECD countries have a deficit. Some of the EITs with a surplus regard it as potential compensation for the trauma of their economic restructuring. When the Kyoto treaty was negotiated, it was recognized that emissions targets for the EITs might lead to them having an excess number of allowances. This excess of allowances were viewed by the EITs as \"headroom\" to grow their economies. The surplus has, however, also been referred to by some as \"hot air,\" a term which Russia (a country with an estimated surplus of 3.1 billion tonnes of carbon dioxide equivalent allowances) views as \"quite offensive.\"\n\nOECD countries with a deficit could meet their Kyoto commitments by buying allowances from transition countries with a surplus. Unless other commitments were made to reduce the total surplus in allowances, such trade would not actually result in emissions being reduced (see also the section below on the Green Investment Scheme).\n\nA Green Investment Scheme (GIS) refers to a plan for achieving environmental benefits from trading surplus allowances (AAUs) under the Kyoto Protocol. The Green Investment Scheme (GIS), a mechanism in the framework of International Emissions Trading (IET), is designed to achieve greater flexibility in reaching the targets of the Kyoto Protocol while preserving environmental integrity of IET. However, using the GIS is not required under the Kyoto Protocol, and there is no official definition of the term.\n\nUnder the GIS a Party to the Protocol expecting that the development of its economy will not exhaust its Kyoto quota, can sell the excess of its Kyoto quota units (AAUs) to another Party. The proceeds from the AAU sales should be \"greened\", i.e. channeled to the development and implementation of the projects either acquiring the greenhouse gases emission reductions (hard greening) or building up the necessary framework for this process (soft greening).\n\nLatvia was one of the front-runners of GISs. World Bank (2011) reported that Latvia has stopped offering AAU sales because of low AAU prices. In 2010, Estonia was the preferred source for AAU buyers, followed by the Czech Republic and Poland.\n\nJapan's national policy to meet their Kyoto target includes the purchase of AAUs sold under GISs. In 2010, Japan and Japanese firms were the main buyers of AAUs. In terms of the international carbon market, trade in AAUs are a small proportion of overall market value. In 2010, 97% of trade in the international carbon market was driven by the European Union Emission Trading Scheme (EU ETS). However, firms regulated under the EU ETS are unable to use AAUs in meeting their emissions caps.\n\nBetween 2001, which was the first year Clean Development Mechanism (CDM) projects could be registered, and 2012, the end of the first Kyoto commitment period, the CDM is expected to produce some 1.5 billion tons of carbon dioxide equivalent (COe) in emission reductions. Most of these reductions are through renewable energy commercialisation, energy efficiency, and fuel switching (World Bank, 2010, p. 262). By 2012, the largest potential for production of CERs are estimated in China (52% of total CERs) and India (16%). CERs produced in Latin America and the Caribbean make up 15% of the potential total, with Brazil as the largest producer in the region (7%).\n\nThe formal crediting period for Joint Implementation (JI) was aligned with the first commitment period of the Kyoto Protocol, and did not start until January 2008 (Carbon Trust, 2009, p. 20). In November 2008, only 22 JI projects had been officially approved and registered. The total projected emission savings from JI by 2012 are about one tenth that of the CDM. Russia accounts for about two-thirds of these savings, with the remainder divided up roughly equally between the Ukraine and the EU's New Member States. Emission savings include cuts in methane, HFC, and NO emissions.\n\nAs noted earlier on, the first-round Kyoto emissions limitation commitments are not sufficient to stabilize the atmospheric concentration of GHGs. Stabilization of atmospheric GHG concentrations will require further emissions reductions after the end of the first-round Kyoto commitment period in 2012.\n\nAnalysts have developed scenarios of future changes in GHG emissions that lead to a stabilization in the atmospheric concentrations of GHGs. Climate models suggest that lower stabilization levels are associated with lower magnitudes of future global warming, while higher stabilization levels are associated with higher magnitudes of future global warming (see figure opposite).\n\nTo achieve stabilization, global GHG emissions must peak, then decline. The lower the desired stabilization level, the sooner this peak and decline must occur (see figure opposite). For a given stabilization level, larger emissions reductions in the near term allow for less stringent emissions reductions later. On the other hand, less stringent near term emissions reductions would, for a given stabilization level, require more stringent emissions reductions later on.\n\nThe first period Kyoto emissions limitations can be viewed as a first-step towards achieving atmospheric stabilization of GHGs. In this sense, the first period Kyoto commitments may affect what future atmospheric stabilization level can be achieved.\n\nAt the 16th Conference of the Parties held in 2010, Parties to the UNFCCC agreed that future global warming should be limited below 2°C relative to the pre-industrial temperature level. One of the stabilization levels discussed in relation to this temperature target is to hold atmospheric concentrations of GHGs at 450 parts per million (ppm) - eq. Stabilization at 450 ppm could be associated with a 26 to 78% risk of exceeding the 2 °C target.\n\nScenarios assessed by Gupta \"et al.\" (2007) suggest that Annex I emissions would need to be 25% to 40% below 1990 levels by 2020, and 80% to 95% below 1990 levels by 2050. The only Annex I Parties to have made voluntary pledges in line with this are Japan (25% below 1990 levels by 2020) and Norway (30-40% below 1990 levels by 2020).\n\nGupta \"et al.\" (2007) also looked at what 450 ppm scenarios projected for non-Annex I Parties. Projections indicated that by 2020, non-Annex I emissions in several regions (Latin America, the Middle East, East Asia, and centrally planned Asia) would need to be substantially reduced below \"business-as-usual\". \"Business-as-usual\" are projected non-Annex I emissions in the absence of any new policies to control emissions. Projections indicated that by 2050, emissions in all non-Annex I regions would need to be substantially reduced below \"business-as-usual\".\n\nThe agreement is a protocol to the United Nations Framework Convention on Climate Change (UNFCCC) adopted at the Earth Summit in Rio de Janeiro in 1992, which did not set any legally binding limitations on emissions or enforcement mechanisms. Only Parties to the UNFCCC can become Parties to the Kyoto Protocol. The Kyoto Protocol was adopted at the third session of the Conference of Parties to the UNFCCC (COP 3) in 1997 in Kyoto, Japan.\n\nNational emission targets specified in the Kyoto Protocol exclude international aviation and shipping. Kyoto Parties can use land use, land use change, and forestry (LULUCF) in meeting their targets. LULUCF activities are also called \"sink\" activities. Changes in sinks and land use can have an effect on the climate, and indeed the Intergovernmental Panel on Climate Change's Special Report on Land use, land-use change, and forestry estimates that since 1750 a third of global warming has been caused by land use change. Particular criteria apply to the definition of forestry under the Kyoto Protocol.\n\nForest management, cropland management, grazing land management, and revegetation are all eligible LULUCF activities under the Protocol. Annex I Parties use of forest management in meeting their targets is capped.\n\nArticle 4.2 of the UNFCCC commits industrialized countries to \"[take] the lead\" in reducing emissions. The initial aim was for industrialized countries to stabilize their emissions at 1990 levels by the year 2000. The failure of key industrialized countries to move in this direction was a principal reason why Kyoto moved to binding commitments.\n\nAt the first UNFCCC Conference of the Parties in Berlin, the G77 was able to push for a mandate (the \"Berlin mandate\") where it was recognized that:\nDuring negotiations, the G-77 represented 133 developing countries. China was not a member of the group but an associate. It has since become a member.\n\nThe Berlin mandate was recognized in the Kyoto Protocol in that developing countries were not subject to emission reduction commitments in the first Kyoto commitment period. However, the large potential for growth in developing country emissions made negotiations on this issue tense. In the final agreement, the Clean Development Mechanism was designed to limit emissions in developing countries, but in such a way that developing countries do not bear the costs for limiting emissions. The general assumption was that developing countries would face quantitative commitments in later commitment periods, and at the same time, developed countries would meet their first round commitments.\n\nViews on the Kyoto Protocol#Commentaries on negotiations contains a list of the emissions cuts that were proposed by UNFCCC Parties during negotiations. The G77 and China were in favour of strong uniform emission cuts across the developed world. The US originally proposed for the second round of negotiations on Kyoto commitments to follow the negotiations of the first. In the end, negotiations on the second period were set to open no later than 2005. Countries over-achieving in their first period commitments can \"bank\" their unused allowances for use in the subsequent period.\n\nThe EU initially argued for only three GHGs to be included – , , and – with other gases such as HFCs regulated separately. The EU also wanted to have a \"bubble\" commitment, whereby it could make a collective commitment that allowed some EU members to increase their emissions, while others cut theirs.\n\nThe most vulnerable nations – the Alliance of Small Island States (AOSIS) – pushed for deep uniform cuts by developed nations, with the goal of having emissions reduced to the greatest possible extent. Countries that had supported differentiation of targets had different ideas as to how it should be calculated, and many different indicators were proposed. Two examples include differentiation of targets based on gross domestic product (GDP), and differentiation based on energy intensity (energy use per unit of economic output).\n\nThe final targets negotiated in the Protocol are the result of last minute political compromises. The targets closely match those decided by Argentinian Raul Estrada, the diplomat who chaired the negotiations. The numbers given to each Party by Chairman Estrada were based on targets already pledged by Parties, information received on latest negotiating positions, and the goal of achieving the strongest possible environmental outcome. The final targets are weaker than those proposed by some Parties, e.g., the Alliance of Small Island States and the G-77 and China, but stronger than the targets proposed by others, e.g., Canada and the United States.\n\nThe Protocol also reaffirms the principle that developed countries have to pay billions of dollars, and supply technology to other countries for climate-related studies and projects. The principle was originally agreed in UNFCCC. One such project is The Adaptation Fund\"\", that has been established by the Parties to the Kyoto Protocol of the UN Framework Convention on Climate Change to finance concrete adaptation projects and programmes in developing countries that are Parties to the Kyoto Protocol.\n\nThe protocol left several issues open to be decided later by the sixth Conference of Parties of the UNFCCC, which attempted to resolve these issues at its meeting in the Hague in late 2000, but it was unable to reach an agreement due to disputes between the European Union (who favoured a tougher implementation) and the United States, Canada, Japan and Australia (who wanted the agreement to be less demanding and more flexible).\n\nIn 2001, a continuation of the previous meeting (COP6bis) was held in Bonn where the required decisions were adopted. After some concessions, the supporters of the protocol (led by the European Union) managed to get the agreement of Japan and Russia by allowing more use of carbon dioxide sinks.\n\nThe first Meeting of the Parties to the Kyoto Protocol (MOP1) was held in Montreal from 28 November to 9 December 2005, along with the 11th conference of the Parties to the UNFCCC (COP11). See United Nations Climate Change Conference.\n\nDuring COP13 in Bali, 36 developed Contact Group countries (plus the EU as a party in the European Union) agreed to a 10% emissions increase for Iceland; but, since the EU's member states each have individual obligations, much larger increases (up to 27%) are allowed for some of the less developed EU countries (see below Kyoto Protocol#Increase in greenhouse gas emission since 1990). Reduction limitations expired in 2013.\n\nThe protocol defines a mechanism of \"compliance\" as a \"monitoring compliance with the commitments and penalties for non-compliance.\" According to Grubb (2003), the explicit consequences of non-compliance of the treaty are weak compared to domestic law. Yet, the compliance section of the treaty was highly contested in the Marrakesh Accords.\n\nIf the enforcement branch determines that an Annex I country is not in compliance with its emissions limitation, then that country is required to make up the difference during the second commitment period plus an additional 30%. In addition, that country will be suspended from making transfers under an emissions trading program.\n\nThe Protocol was adopted by COP 3 of UNFCCC on 11 December 1997 in Kyoto, Japan. It was opened on 16 March 1998 for signature during one year by parties to UNFCCC, when it was signed Antigua and Barbuda, Argentina, the Maldives, Samoa, St. Lucia and Switzerland. At the end of the signature period, 82 countries and the European Community had signed. Ratification (which is required to become a party to the Protocol) started on 17 September with ratification of Fiji. Countries that did not sign acceded to the convention, which has the same legal effect.\n\nArticle 25 of the Protocol specifies that the Protocol enters into force \"on the ninetieth day after the date on which not less than 55 Parties to the Convention, incorporating Parties included in Annex I which accounted in total for at least 55% of the total carbon dioxide emissions for 1990 of the Annex I countries, have deposited their instruments of ratification, acceptance, approval or accession.\"\n\nThe EU and its Member States ratified the Protocol in May 2002. Of the two conditions, the \"55 parties\" clause was reached on 23 May 2002 when Iceland ratified the Protocol. The ratification by Russia on 18 November 2004 satisfied the \"55%\" clause and brought the treaty into force, effective 16 February 2005, after the required lapse of 90 days.\n\nAs of May 2013, 191 countries and one regional economic organization (the EC) have ratified the agreement, representing over 61.6% of the 1990 emissions from Annex I countries. One of the 191 ratifying states—Canada—has renounced the protocol.\n\nThe US signed the Protocol on 12 November 1998, during the Clinton presidency. To become binding in the US, however, the treaty had to be ratified by the Senate, which had already passed the 1997 non-binding Byrd-Hagel Resolution, expressing disapproval of any international agreement that did not require developing countries to make emission reductions and \"would seriously harm the economy of the United States\". The resolution passed 95–0. Therefore, even though the Clinton administration signed the treaty, it was never submitted to the Senate for ratification.\n\nWhen George W. Bush was elected US president in 2000, he was asked by US Senator Chuck Hagel what his administration's position was on climate change. Bush replied that he took climate change \"very seriously\", but that he opposed the Kyoto treaty because \"it exempts 80% of the world, including major population centers such as China and India, from compliance, and would cause serious harm to the US economy.\" The Tyndall Centre for Climate Change Research reported in 2001:This policy reversal received a massive wave of criticism that was quickly picked up by the international media. Environmental groups blasted the White House, while Europeans and Japanese alike expressed deep concern and regret. [...] Almost all world leaders (e.g. China, Japan, South Africa, Pacific Islands, etc.) expressed their disappointment at Bush's decision.In response to this criticism, Bush stated: \"I was responding to reality, and reality is the nation has got a real problem when it comes to energy.\" The Tyndall Centre called this \"an overstatement used to cover up the big benefactors of this policy reversal, i.e., the US oil and coal industry, which has a powerful lobby with the administration and conservative Republican congressmen.\"\n\nAs of 2016, the US is the only signatory that has not ratified the Protocol. The US accounted for 36% of emissions in 1990. As such, for the treaty to go into legal effect without US ratification, it would require a coalition including the EU, Russia, Japan, and small parties. A deal, without the US Administration, was reached in the Bonn climate talks (COP-6.5), held in 2001.\n\nIn 2011, Canada, Japan and Russia stated that they would not take on further Kyoto targets. The Canadian government announced its withdrawal—possible at any time three years after ratification—from the Kyoto Protocol on 12 December 2011, effective 15 December 2012. Canada was committed to cutting its greenhouse emissions to 6% below 1990 levels by 2012, but in 2009 emissions were 17% higher than in 1990. The Harper government prioritized oil sands development in Alberta, and deprioritized improving the environment. Environment minister Peter Kent cited Canada's liability to \"enormous financial penalties\" under the treaty unless it withdrew. He also suggested that the recently signed Durban agreement may provide an alternative way forward. The Harper government claimed it would find a \"Made in Canada\" solution, but never found any such solution. Canada's decision received a generally negative response from representatives of other ratifying countries.\n\nAndorra, Palestine, South Sudan, the United States and, following their withdrawal on 15 December 2012, Canada are the only UNFCCC Parties that are not party to the Protocol. Furthermore, the Protocol is not applied to UNFCCC observer the Holy See. Although the Kingdom of the Netherlands approved the protocol for the whole Kingdom, it did not deposit an instrument of ratification for Aruba, Curaçao, Sint Maarten or the Caribbean Netherlands.\n\nTotal aggregate GHG emissions excluding emissions/removals from land use, land use change and forestry (LULUCF, i.e., carbon storage in forests and soils) for all Annex I Parties (see list below) including the United States taken together decreased from 19.0 to 17.8 thousand teragrams (Tg, which is equal to 10 kg) equivalent, a decline of 6.0% during the 1990-2008 period. Several factors have contributed to this decline. The first is due to the economic restructuring in the Annex I Economies in Transition (the EITs – see Intergovernmental Emissions Trading for the list of EITs). Over the period 1990-1999, emissions fell by 40% in the EITs following the collapse of central planning in the former Soviet Union and east European countries. This led to a massive contraction of their heavy industry-based economies, with associated reductions in their fossil fuel consumption and emissions.\n\nEmissions growth in Annex I Parties have also been limited due to policies and measures (PaMs). In particular, PaMs were strengthened after 2000, helping to enhance energy efficiency and develop renewable energy sources. Energy use also decreased during the economic crisis in 2007-2008.\n\nUNFCCC (2011) made projections of changes in emissions of the Annex I Parties and the effectiveness of their PaMs. It was noted that their projections should be interpreted with caution. For the 39 Annex I Parties, UNFCCC (2011) projected that existing PaMs would lead to annual emissions in 2010 of 17.5 thousand Tg eq, excluding LULUCF, which is a decrease of 6.7% from the 1990 level. Annual emissions in 2020 excluding LULUCF were projected to reach 18.9 thousand Tg eq, which is an increase of 0.6% on the 1990 level.\n\nUNFCCC (2011) made an estimate of the total effect of implemented and adopted PaMs. Projected savings were estimated relative to a reference (baseline) scenario where PaMs are not implemented. PaMs were projected to deliver emissions savings relative to baseline of about 1.5 thousand Tg eq by 2010, and 2.8 thousand Tg eq by 2020. In percentage terms, and using annual emissions in the year 1990 as a reference point, PaMs were projected to deliver at least a 5.0% reduction relative to baseline by 2010, and a 10.0% reduction relative to baseline in 2020. Scenarios reviewed by UNFCCC (2011) still suggested that total Annex I annual emissions would increase out to 2020 (see the preceding paragraph).\n\n\"Data given in the table above may not be fully reflective of a country's progress towards meeting its first-round Kyoto target. The summary below contains more up-to-date information on how close countries are to meeting their first-round targets.\"\n\nCollectively the group of industrialized countries committed to a Kyoto target, i.e., the Annex I countries excluding the US, have a target of reducing their GHG emissions by 4.2% on average for the period 2008-2012 relative to the base year, which in most cases is 1990. According to Olivier \"et al.\" (2011), the Kyoto Parties will comfortably exceed their collective target, with a projected average reduction of 16% for 2008-2012. This projection excludes both LULUCF and credits generated by the Clean Development Mechanism (CDM).\n\nAs noted in the preceding section, between 1990–1999, there was a large reduction in the emissions of the EITs. The reduction in the EITs is largely responsible for the total (aggregate) reduction (excluding LULUCF) in emissions of the Annex I countries, excluding the US. Emissions of the Annex II countries (Annex I minus the EIT countries) have experienced a limited increase in emissions from 1990–2006, followed by stabilization and a more marked decrease from 2007 onwards. The emissions reductions in the early nineties by the 12 EIT countries who have since joined the EU, assist the present EU-27 in meeting its collective Kyoto target.\n\nAlmost all European countries are on track to achieve their first-round Kyoto targets. Spain plans to meet its target by purchasing a large quantity of Kyoto units through the flexibility mechanisms. Australia, Canada (Canada withdrew from the Kyoto treaty in 2012), and Italy are not on course to meet their first-round Kyoto targets. In order to meet their targets, these countries would need to purchase emissions credits from other Kyoto countries. As noted in the section on Intergovernmental Emissions Trading, purchasing surplus credits from the EIT countries would not actually result in total emissions being reduced. An alternative would be the purchase of CDM credits or the use of the voluntary Green Investment Scheme.\n\nIn December 2011, Canada's environment minister, Peter Kent, formally announced that Canada would withdraw from the Kyoto accord a day after the end of the 2011 United Nations Climate Change Conference (see the section on the withdrawal of Canada).\n\nBelarus, Malta, and Turkey are Annex I Parties but do not have first-round Kyoto targets. The US has a Kyoto target of a 6% reduction relative to the 1990 level, but has not ratified the treaty. Emissions in the US have increased 11% since 1990, and according to Olivier \"et al.\" (2011), it will be unable to meet its original Kyoto target.\n\nIf the US had ratified the Kyoto Protocol, the average percentage reduction in total GHG emissions for the Annex I group would have been a 5.2% reduction relative to the base year. Including the US in their calculation, Olivier \"et al.\" (2011) projected that the Annex I countries would collectively achieve a 7% reduction relative to the base year, which is lower than the original target of a 5.2% reduction. This projection excludes expected purchases of emissions credits.\n\nUNFCCC (2005) compiled and synthesized information reported to it by non-Annex I Parties. Most non-Annex I Parties belonged in the low-income group, with very few classified as middle-income. Most Parties included information on policies relating to sustainable development. Sustainable development priorities mentioned by non-Annex I Parties included poverty alleviation and access to basic education and health care. Many non-Annex I Parties are making efforts to amend and update their environmental legislation to include global concerns such as climate change.\n\nA few Parties, e.g., South Africa and Iran, stated their concern over how efforts to reduce emissions by Annex I Parties could adversely affect their economies. The economies of these countries are highly dependent on income generated from the production, processing, and export of fossil fuels.\n\nEmissions\n\nGHG emissions, excluding land use change and forestry (LUCF), reported by 122 non-Annex I Parties for the year 1994 or the closest year reported, totalled 11.7 billion tonnes (billion = 1,000,000,000) of CO-eq. CO was the largest proportion of emissions (63%), followed by methane (26%) and nitrous oxide (NO) (11%).\n\nThe energy sector was the largest source of emissions for 70 Parties, whereas for 45 Parties the agriculture sector was the largest. Per capita emissions (in tonnes of CO-eq, excluding LUCF) averaged 2.8 tonnes for the 122 non-Annex I Parties.\n\nParties reported a high level of uncertainty in LUCF emissions, but in aggregate, there appeared to only be a small difference of 1.7% with and without LUCF. With LUCF, emissions were 11.9 billion tonnes, without LUCF, total aggregate emissions were 11.7 billion tonnes.\n\n\"Trends\"\n\nIn several large developing countries and fast growing economies (China, India, Thailand, Indonesia, Egypt, and Iran) GHG emissions have increased rapidly (PBL, 2009). For example, emissions in China have risen strongly over the 1990–2005 period, often by more than 10% year. Emissions per-capita in non-Annex I countries are still, for the most part, much lower than in industrialized countries. Non-Annex I countries do not have quantitative emission reduction commitments, but they are committed to mitigation actions. China, for example, has had a national policy programme to reduce emissions growth, which included the closure of old, less efficient coal-fired power plants.\n\nBarker \"et al.\" (2007, p. 79) assessed the literature on cost estimates for the Kyoto Protocol. Due to non-US participation in the Kyoto treaty, costs estimates were found to be much lower than those estimated in the previous IPCC Third Assessment Report. Without US participation, and with full use of the Kyoto flexible mechanisms, costs were estimated at less than 0.05% of Annex B GDP. This compared to earlier estimates of 0.1–1.1%. Without use of the flexible mechanisms, costs without US participation were estimated at less than 0.1%. This compared to earlier estimates of 0.2–2%. These cost estimates were viewed as being based on much evidence and high agreement in the literature.\n\nGupta \"et al.\" (2007) assessed the literature on climate change policy. They found that no authoritative assessments of the UNFCCC or its Protocol asserted that these agreements had, or will, succeed in solving the climate problem. In these assessments, it was assumed that the UNFCCC or its Protocol would not be changed. The Framework Convention and its Protocol include provisions for future policy actions to be taken.\n\nGupta \"et al.\" (2007) described the Kyoto first-round commitments as \"modest,\" stating that they acted as a constraint on the treaty's effectiveness. It was suggested that subsequent Kyoto commitments could be made more effective with measures aimed at achieving deeper cuts in emissions, as well as having policies applied to a larger share of global emissions. In 2008, countries with a Kyoto cap made up less than one-third of annual global carbon dioxide emissions from fuel combustion.\n\nWorld Bank (2010) commented on how the Kyoto Protocol had only had a slight effect on curbing global emissions growth. The treaty was negotiated in 1997, but in 2006, energy-related carbon dioxide emissions had grown by 24%. World Bank (2010) also stated that the treaty had provided only limited financial support to developing countries to assist them in reducing their emissions and adapting to climate change.\n\nSome of the criticism of the Protocol has been based on the idea of climate justice (Liverman, 2008, p. 14).\nThis has particularly centered on the balance between the low emissions and high vulnerability of the developing world to climate change, compared to high emissions in the developed world. Another criticism of the Kyoto Protocol and other international conventions, is the right of indigenous peoples right to participate. Quoted here from The Declaration of the First International Forum of Indigenous Peoples on Climate Change, it says \"Despite the recognition of our role in preventing global warming, when it comes time to sign international conventions like the United Nations Framework Convention on Climate Change, once again, our right to participate in national and international discussions that directly affect or Peoples and territories is denied.\" Additionally, later in the declaration, it reads \"We denounce the fact that neither the [United Nations] nor the Kyoto Protocol recognizes the existence or the contributions of Indigenous Peoples. Furthermore, the debates under these instruments have not considered the suggestions and proposals of the Indigenous Peoples nor have the appropriate mechanisms to guarantee our participation in all the debates that directly concern the Indigenous Peoples has been established.\"Some environmentalists have supported the Kyoto Protocol because it is \"the only game in town,\" and possibly because they expect that future emission reduction commitments may demand more stringent emission reductions (Aldy \"et al.\"., 2003, p. 9). In 2001, seventeen national science academies stated that ratification of the Protocol represented a \"small but essential first step towards stabilising atmospheric concentrations of greenhouse gases.\" Some environmentalists and scientists have criticized the existing commitments for being too weak (Grubb, 2000, p. 5).\n\nThe United States (under former President George W. Bush) and Australia (initially, under former Prime Minister John Howard) did not ratify the Kyoto treaty. According to Stern (2006), their decision was based on the lack of quantitative emission commitments for emerging economies (see also the 2000 onwards section). Australia, under former Prime Minister Kevin Rudd, has since ratified the treaty, which took effect in March 2008.\n\nAnother area which has been commented on is the role of the Kyoto flexibility mechanisms – emissions trading, Joint Implementation, and the Clean Development Mechanism (CDM). The flexibility mechanisms have attracted both positive and negative comments.\n\nAs mentioned earlier, a number of Annex I Parties have implemented emissions trading schemes (ETSs) as part of efforts to meet their Kyoto commitments. General commentaries on emissions trading are contained in emissions trading and carbon emission trading. Individual articles on the ETSs contain commentaries on these schemes (see Kyoto Protocol#International Emissions Trading for a list of ETSs).\n\nOne of the arguments made in favour of the flexibility mechanisms is that they can reduce the costs incurred by Annex I Parties in meeting their Kyoto commitments. Criticisms of flexibility have, for example, included the ineffectiveness of emissions trading in promoting investment in non-fossil energy sources, and adverse impacts of CDM projects on local communities in developing countries.\n\nAs the Kyoto Protocol seeks to reduce environmental pollutants while at the same time altering the freedoms of some citizens.\n\nAs discussed by Milton Friedman, one can achieve both economic and political freedom through capitalism; nonetheless, it is never guaranteed that one is going to have equality of wealth of those on top of the \"food chain\" of this capitalistic world. All these alterations come to what the leaders of the citizens choose to impose in means of improving ones lifestyle. In the case of the Kyoto Protocol, it seeks to impose regulations that will reduce production of pollutants towards the environment. Furthermore, seeking to compromise the freedoms of both private and public citizens. In one side it imposes bigger regulations towards companies and reducing their profits as they need to fulfill such regulations with, which are oftentimes more expensive, alternatives for production. On the other hand, it seeks to reduce the emissions that potentially cause the rapid environmental change called climate change.\n\nThe conditions of the Kyoto Protocol consist of mandatory targets on greenhouse gas emissions for the world's leading economies. As provided by the United Nations Framework Convention on Climate Change, \"These targets range from -8 per cent to +10 per cent of the countries' individual 1990 emissions levels with a view to reducing their overall emissions of such gases by at least 5 per cent below existing 1990 levels in the commitment period 2008 to 2012.\" \n\nThese goals are challenged, however, by climate change deniers, who condemn strong scientific evidence of the human impact on climate change. One prominent scholar opines that these climate change deniers \"arguably\" breach Rousseau's notion of the social contract, which is an implicit agreement among the members of a society to coordinate efforts in the name of overall social benefit. The climate change denial movement hinders efforts at coming to agreements as a collective global society on climate change.\n\nThe official meeting of all states party to the Kyoto Protocol is the \"Conference of the Parties\". It is held every year as part of the United Nations Climate Change conference, which also serves as the formal meeting of UNFCCC. The first Meetings of Parties of the Kyoto Protocol (CMP) was held in 2005 in conjunction with the eleventh Conferences of parties to UNFCCC (COP). Also parties to the Convention that are not parties to the Protocol can participate in Protocol-related meetings as observers. The first conference was held in 1995 in Berlin, while the 2013 conference was held in Warsaw. Later COPs were held in Lima, Peru in 2014 and in Paris, France in 2015. COP 21 aims to hold the increase in the global average rise in temperature below 2 degree. COP 22 Marakash, Morocco and COP 23 in Bonn, Germany.\n\nIn the non-binding \"Washington Declaration\" agreed on 16 February 2007, heads of governments from Canada, France, Germany, Italy, Japan, Russia, the United Kingdom, the United States, Brazil, China, India, Mexico and South Africa agreed in principle on the outline of a successor to the Kyoto Protocol. They envisaged a global cap-and-trade system that would apply to both industrialized nations and developing countries, and initially hoped that it would be in place by 2009.\n\nThe United Nations Climate Change Conference in Copenhagen in December 2009 was one of the annual series of UN meetings that followed the 1992 Earth Summit in Rio. In 1997 the talks led to the Kyoto Protocol, and the conference in Copenhagen was considered to be the opportunity to agree a successor to Kyoto that would bring about meaningful carbon cuts.\n\nThe 2010 Cancún agreements include voluntary pledges made by 76 developed and developing countries to control their emissions of greenhouse gases. In 2010, these 76 countries were collectively responsible for 85% of annual global emissions.\n\nBy May 2012, the US, Japan, Russia, and Canada had indicated they would not sign up to a second Kyoto commitment period. In November 2012, Australia confirmed it would participate in a second commitment period under the Kyoto Protocol and New Zealand confirmed that it would not.\n\nNew Zealand's climate minister Tim Groser said the 15-year-old Kyoto Protocol was outdated, and that New Zealand was \"ahead of the curve\" in looking for a replacement that would include developing nations. Non-profit environmental organisations such as the World Wildlife Fund criticised New Zealand's decision to pull out.\n\nOn 8 December 2012, at the end of the 2012 United Nations Climate Change Conference, an agreement was reached to extend the Protocol to 2020 and to set a date of 2015 for the development of a successor document, to be implemented from 2020 (see lede for more information). The outcome of the Doha talks has received a mixed response, with small island states critical of the overall package.The Kyoto second commitment period applies to about 11% of annual global emissions of greenhouse gases. Other results of the conference include a timetable for a global agreement to be adopted by 2015 which includes all countries. At the Doha meeting of the parties to the UNFCCC on 8 December 2012, the European Union chief climate negotiator, Artur Runge-Metzger, pledged to extend the treaty, binding on the 27 European Member States, up to the year 2020 pending an internal ratification procedure.\n\nBan Ki Moon, Secretary General of the United Nations, called on world leaders to come to an agreement on halting global warming during the 69th Session of the UN General Assembly on 23 September 2014 in New York. UN member states have been negotiating a future climate deal over the last five years. A preliminary calendar was adopted to confirm \"national contributions\" to the reduction of CO2 emissions by 2015 before the UN climate summit which was held in Paris at the 2015 United Nations Climate Change Conference.\n\n\n\n\n"}
{"id": "28230692", "url": "https://en.wikipedia.org/wiki?curid=28230692", "title": "Law and motion calendar", "text": "Law and motion calendar\n\nEach judge or courtroom will have a law and motion calendar, setting aside the times when only motions and special legal arguments are heard. These items consist of pretrial motions (such as a motion to compel relating to discovery requests) or other legal requests that are not connected to a trial, and do not include trials themselves.\n"}
{"id": "46716047", "url": "https://en.wikipedia.org/wiki?curid=46716047", "title": "LexML Brasil", "text": "LexML Brasil\n\nLexML Brasil (or \"LexML-BR\" or \"LexML Brazil\") is a project of Brazil's Electronic Government initiative. Its objective is to establish open data systems, integrate work processes and share data, in the context of identifying and structuring executive, legislative and judiciary documents. The \"LexML-BR\" standards define a set of simple technology-neutral electronic protocols and representations, based on XML and HTTP ecossistem.\n\nWhile the project was officially launched on June 30, 2009, Brazil has been participating in the LexML community since 2006. In 2009, LexML became an explicit national data standard in the \"\".\n\nIn May, 2012, Brazil's \"Public Access to Information\" law (\"Lei de Acesso a Informações Públicas\") entered into force, which strengthened the standing of LexML as a transparency tool that could assist in carrying out the obligation to publish government data in the areas of legislative and court documents.\n\nLexML's technical standards allow efficient handling of an enormous quantity of legislative and court information available in Brasil. These include:\n\n\nThe main resources needed for the project are already in place:\n\nAn early development at Brazil occurred at 1997, in a scholar initiative, with the modeling of the structure of Brazilians legislative documents, and the demonstration that all legislative documents can be automatically translated to HTML hypertext, with intra and inter links. The seminal algorithms (implemented as Perl scripts and regular expressions) was lost one decade, rediscovered during the development of an important LexML tool, the \"lexml-linker\". Some scholar studies continued, and served as support to redirect the initial LexML-BR focus on \"XML schemas\" to metadata and \"URN schemas\".\n\nThe \"LexML-BR Project\" was started in ~2006, and had the LexML-IT as an antecedent, as well public as consultings. \nOn June 30, 2009, it was launched officially.\n\nIt is now a joint initiaitve of many administrative bodies, including Brazil's legislature, executive and judiciary branches, part of the IT Management Community, which combines the areas of legislative and court information.\n\nThe goals of the LexML Brazil project can be divided into two main areas:\n\nIn addition to the legal requirements in Brazil for transparency and publication of government documents (see ), the sheer volume of legislation places a premium on digitization and better public access to digital forms of the law.\n\nIn 20 years, Brazil has produced approximately:\n\nThere has been some research identifying this proliferation of laws and bureaucracy as partly responsible for many economic activities going 'underground'.\n\n"}
{"id": "7163020", "url": "https://en.wikipedia.org/wiki?curid=7163020", "title": "List of parties to international copyright agreements", "text": "List of parties to international copyright agreements\n\nBelow is a list of countries which have signed and ratified one or more multilateral international copyright treaties. This list covers only multilateral treaties (i.e., treaties by more than two countries). It does not include bilateral treaties (treaties between only two countries). Related rights provide intellectual property rights for performers, producers of sound recordings (phonograms) and broadcasting organisations. In some countries these rights are known simply as copyright, while other countries distinguish them from authors' rights: in either case, the international laws which are concerned with them are distinct from those concerned with literary and artistic works under the Berne Convention for the Protection of Literary and Artistic Works and other treaties.\n\nIn addition to these treaties, the Anti-Counterfeiting Trade Agreement (ACTA) is a multilateral treaty governing multiple aspects of intellectual property, including copyright. , ACTA has been signed by 31 countries, but only ratified by Japan. If ACTA is ratified by six or more signatories, it will enter into force thirty days later.\n\nThe list below was taken from details supplied by WIPO, UNESCO and the WTO (see references): they are\ncorrect as of 2005-12-11 (2000-01-01 for the Universal Copyright Convention), and include some accessions after that date. Dates quoted are the date on which the treaty\ncame into effect for a given country.\n\n"}
{"id": "2275798", "url": "https://en.wikipedia.org/wiki?curid=2275798", "title": "Michigan Law Review", "text": "Michigan Law Review\n\nThe Michigan Law Review is an American law review that was established in 1902 and is completely run by law students. It is the flagship law journal of the University of Michigan Law School and one of the top law journals in the United States.\n\nThe \"Michigan Law Review\" was established in 1902, after Gustavus Ohlinger, a student in the Law Department (now the Law School) of the University of Michigan, approached the dean with a proposal for a law journal. The \"Michigan Law Review\" was originally intended as a forum in which the faculty of the Law Department could publish its legal scholarship. The faculty resolution creating the \"Michigan Law Review\" required every faculty member to submit two articles per year to the new journal.\n\nFrom its inception until 1940, the \"Michigan Law Review\"'s student members worked under the direction of faculty members who served as editor-in-chief. The first of these was Floyd Mechem, the last Paul Kauper. In 1940, the first student editor-in-chief was selected. During the years that followed, student editors were given increasing responsibility and autonomy; today, the \"Michigan Law Review\" is run with no faculty supervision. The current editor-in-chief is Megan Brown. Day-to-day production operations are overseen by the current managing editor, Kristin Froehle. Seven of each volume's eight issues ordinarily are composed of two major parts: \"Articles\" by legal scholars and practitioners and \"Notes\" written by the student editors. One issue in each volume is devoted to book reviews. Occasionally special issues are devoted to symposia or colloquia.\n\nIn 2016, PrawfsBlawg ranked the \"Michigan Law Review\" as the 6th best law journal by weighing its Google Scholar Metrics law journal ranking, US News Peer Reputation Ranking, US News Overall Ranking, and the W&L Combined Ranking. Based on data from 2009 through 2016, Washington and Lee University School of Law ranked the \"Michigan Law Review\" as the 7th best law journal. According to Google Scholar Metrics, the \"Michigan Law Review\" was the 7th best law journal in 2015 and the 6th best law journal in 2014.\n\nAccording to Washington and Lee University School of Law's Law Library, the \"Michigan Law Review\" is the 7th most cited law journal in academic works, being cited in journals 3888 times between 2009 and 2016, and the 6th most cited law journal by courts, being cited in 128 cases between 2009 and 2016. As of 2012, the \"Michigan Law Review\" has published 4 of the 100 most cited law journal articles of all time—the 5th highest of any law journal. Of the 95 articles that constitute the 5 most cited law journal articles from each year between 1991 and 2009, 9 of them were published by the \"Michigan Law Review\"—the 5th most of any law journal.\n\n\nThe \"Michigan Raw Review\", a parody of the \"Michigan Law Review\", was published annually by the Barristers Society, a self-styled honorary at the University of Michigan Law School. The \"Raw Review\" used the same cover, layout, and typeface, but contained content totally dissimilar, leaning to the \"insulting and semi-pornographic\".\n"}
{"id": "31740802", "url": "https://en.wikipedia.org/wiki?curid=31740802", "title": "Miller v. Skumanick", "text": "Miller v. Skumanick\n\n'Miller v. Skumanick' was a 2010 Third Circuit Court of Appeals case regarding the practice of sexting and its legal relationship to child pornography.\n\nIn October 2008, Tunkhannock Area School District officials confiscated several students' cellphones and found photographs of three female students, two were in their underwear and one was topless. No photos were exposed below the waist and no sexual acts were portrayed. He gave those photos as to Wyoming County District Attorney George Skumanick, Jr. Skumanick promised to file charges against those posing in the photographs for production of child pornography unless they agreed to probation, completed a six to nine month educational program which would require participants to submit an essay explaining why their actions were wrong. No actions were proposed against the male students possessing and distributing the images. The three families collectively filed for a temporary restraining order in district court to prevent the prosecution from taking place while they seek an injunction. The restraining order was granted, and Skumanick appealed.\n\nThe plaintiffs argued that prosecution would amount to retaliation against their children's First Amendment right to free expression and against compelled speech, and the parents' Fourteenth Amendment substantive due process right to direct the upbringing of their children. The appellate court upheld the temporary restraining order based on the second and third claims. Specifically, the court affirmed that the students' First Amendment right against compelled speech would be violated by the program's requirement that the student involve explain why their actions were wrong, and the parents' Fourteenth Amendment rights would be violated by the program's moral nature.\n\nThe appellate court opinion in this matter did not address whether the pictures in question were pornographic in nature, as it instead ruled that there was no evidence that the plaintiffs ever possessed or distributed the photos.\n\nSexting\n\n"}
{"id": "31578945", "url": "https://en.wikipedia.org/wiki?curid=31578945", "title": "Nude Nuns with Big Guns", "text": "Nude Nuns with Big Guns\n\nNude Nuns with Big Guns is a 2010 nunsploitation thriller film directed by Joseph Guzman and starring Asun Ortega, David Castro, and Perry D'Marco.\n\nThe film was the subject of one of the largest copyright lawsuits in California. The two lawsuits are the first time that two different companies claiming the intellectual-property rights of the same movie are each suing the same alleged 5,865 BitTorrent downloaders.\n\nA young Mexican nun, named Sister Sarah, is neglected and abused by a corrupt clergy that produces and distributes heroin. After a bad drug deal, she is handed over to thugs to be used as an instrument as sex for money. On the verge of death after being heavily drugged and wounded and fingered, the nun receives a commandment from God to take revenge. Acquiring heavy weapons (including big guns and vibrators), Sister Sarah sets out to kill those who had abused her and are using the church for their own personal gain. The frightened drug lords in the church hires \"Los Muertos\", a violent motorcycle gang, to track her down and eliminate her. Los Muertos' base of operations is the local brothel \"Titty Flickers\", where they to try and gather more information on the vigilante nun. After being wounded in a shootout, Sister Sarah hides out in a fleabag motel where she recovers and finally achieves vengeance by killing Los Muertos, degenitalizing Chavo (the brutal leader of Los Muertos), and saving her female lover who had been raped. But in the final scene, the clergy drug lord, known only as the Monsignor, hires another hit man to track down the vigilante nun, leaving the door wide open for a sequel.\n\n\nOn March 7, 2011, Camelot Entertainment Group, a film company based in Los Angeles, filed a federal lawsuit, Case No. CV 11-1949 DDP (FMOx), in the District Court for the Central District of California, against BitTorrent users who allegedly downloaded the movie between January and . The lawsuit which targets 5,865 IP addresses, seeks to compel ISPs to identify the defendants from their IP addresses. The company has until May 13 to \"show cause why the Doe defendants should not be severed and/or dismissed from this action based on improper joinder of parties or lack of personal jurisdiction\". The Electronic Frontier Foundation will act as amicus counsel on the side of the defendants, who at this stage are known only by their internet IP addresses and rough geographic location.\n\nThe lawsuit is seen as part of a courtroom based strategy in which defendants are asked to settle or risk being named in a public lawsuit. If successful, the lawsuit could end up collecting more money than the movie earned at the box office.\n\nIncentive Capital of Utah also filed a nearly identical lawsuit against the same IP addresses with the same judge on May 6, 2011.\n\nOn May 23, 2011, Camelot filed to dismiss their case, though the distribution group stated that they may refile the case in San Francisco. The lawsuit filed by Incentive Capital was dropped on June 10, 2011.\n\nFollowing the filing of the BitTorrent lawsuit, concerns have been raised as to whether Camelot Distribution Group actually owns the rights to the film. Camelot defaulted on a loan financed by Incentive Capital used to purchase the movie rights. Though Incentive Capital has already foreclosed on the film, Camelot has stated that the foreclosure was an improper \"usurpation of its assets\".\n"}
{"id": "4341180", "url": "https://en.wikipedia.org/wiki?curid=4341180", "title": "Phonographic Performance Ireland", "text": "Phonographic Performance Ireland\n\nPhonographic Performance Ireland CLG (PPI) controls the public performance, broadcasting, and other rights in hundreds of thousands of different recordings on thousands of different labels in Ireland. \n\nThese include not only Irish recordings but also most recordings available worldwide. A \"public performance\" occurs whenever recordings are played to anyone outside the family or domestic circle for profit. The list of recordings in PPI's repertoire is constantly increasing as new titles are released. \n\n"}
{"id": "8937262", "url": "https://en.wikipedia.org/wiki?curid=8937262", "title": "Policy by press release", "text": "Policy by press release\n\nPolicy by press release refers to the act of attempting to influence public policy by press releases intended to alarm the public into demanding action from their elected officials. In modern times, the term is used to dismiss an opponent's claims by suggesting the arguments to be lacking in substance and created solely to generate media attention.\n\nPerhaps the most common use of the term refers to an infamous period during the Eisenhower administration when \"leaked\" documents were a common way for the various branches of the US military to attempt to garner funding for their pet projects when traditional chains of command failed, or they actively ended them. Practically any idea, no matter how outlandish, could gain some traction by simply claiming that the Soviet Union was working on a similar device.\n\nThe first and most costly example of this behavior was the mythical \"bomber gap.\" After seeing the latest Soviet designs in 1955, a clamor broke out in Washington about the Soviets developing a lead in deploying strategic bombers, with estimates that hundreds would be available shortly. The result was a massive expansion of the US building program, which led to the eventual introduction of about 2,500 jet bombers. Although it was not revealed at the time, US intelligence services had actually made real estimates of the size of the Soviet fleet as early as 1956 by placing it at around 20 aircraft.\n\nNevertheless, the tactic of claiming the gap existed and then brushing aside any criticism as being \"weak on defense,\" was so successful it led to a wave of similar claims.\n\nAnother famous case was a claim that suggested the Soviets were working on a global-range nuclear aircraft. An article, complete with images claimed to be leaked by a spy agency, appeared in the December 1958 issue of \"Aviation Week\". The article described a system that was suspiciously similar to some of the designs that were currently under consideration by large US aviation companies. Concerns were soon expressed that \"the Russians were from three to five years ahead of the US in the field of atomic aircraft engines and that they would move even further ahead unless the US pressed forward with its own program.\" In fact, the entire article was a hoax; third parties later revealed that the aircraft appearing in the pictures was the entirely-conventional Myasishchev M-50 \"Bounder\", which never entered production. The rumored aircraft was a nuclear-powered version of the Tupolev Tu-95 bomber, called Tupolev Tu-119. The controversy managed to secure, for a time, continued funding of US efforts, which culminated in the NB-36 testbed aircraft.\n\nAnother apparent case of policy by press release was the famous \"Look\" article on flying saucers. At the time, the US Air Force and then the US Army were funding the development of the Avrocar at Avro Canada in Toronto. The article, in the 14 June 1955 edition, suggested that the recent wave of saucer reports were possibly caused by Soviet flying saucers, and the article went on to describe them and their capabilities. It included several images that appeared to be provided to them by Avro Canada, or someone in contact with them, including a description of the control system, which was identical to the one used on the Avrocar. In the end, the concept proved unfeasible, and the Avrocar project was eventually cancelled in 1961. The article nevertheless remains famous, as it is often presented as a US government misinformation campaign to deflect attention away from \"real\" UFO's: to exactly what end varies by the source.\n\nThe term is now more commonly used, especially in the US, to refer to environmental policy, but it is still used in discussions of defense policy. Myriad claims asserting global warming or ozone depletion have been described by editorialists, such as Mark Martin, the Chronicle Sacramento Bureau, and Hugh Ellsaesser, as \"policy by press release.\"\n\nLikewise, the implication that Iraq was involved in the 9-11 attacks\nor had weapons of mass destruction, based on evidence that the CIA's own reports had dismissed, was described as \"policy by press release\" by John Kerry and Lou Dobbs.\n\nA related term, \"public health by press release\", is occasionally used ironically to imply official pronouncements or media campaigns belie inadequate effort or funding, but the term appeared in an article warning against a pitfall from the opposite direction (potential misassessment of limited clinical studies by press and policymakers).\n"}
{"id": "55810", "url": "https://en.wikipedia.org/wiki?curid=55810", "title": "Reciprocal Tariff Act", "text": "Reciprocal Tariff Act\n\nThe Reciprocal Tariff Act (enacted June 12, 1934, ch. 474, , ) provided for the negotiation of tariff agreements between the United States and separate nations, particularly Latin American countries. The Act served as an institutional reform intended to authorize the president to negotiate with foreign nations to reduce tariffs in return for reciprocal reductions in tariffs in the United States. It resulted in a reduction of duties.\n\nPresident Franklin D. Roosevelt signed the Reciprocal Trade Agreements Act (RTAA) into law in 1934. RTAA gave the president power to negotiate bilateral, reciprocal trade agreements with other countries. This law enabled Roosevelt to liberalize American trade policy around the globe. It is widely credited with ushering in the era of liberal trade policy that persisted through the 20th century.\n\nTariffs in the United States were at historically high levels from the post-Civil War period through the 1920s. In response to the Great Depression, Congress accelerated its protectionist policies, culminating in the Smoot–Hawley Act of 1930. The Smoot-Hawley Act was a smorgasbord of high tariffs across many American industries. At the same time, countries in Europe enacted protectionist policies. The RTAA marked a sharp departure from the era of protectionism in the United States. American duties on foreign products declined from an average of 46% in 1934 to 12% by 1962.\n\nBefore the RTAA, if Congress wanted to establish a lower tariff for particular imports, it would act unilaterally, taking the foreign country's tariff rate as fixed. Congress would choose a tariff rate that was either a little higher or lower than the median preferred tariff, depending upon the composition of the Congress. Generally, a Republican controlled Congress would prefer higher tariffs and a Democrat controlled Congress would prefer lower tariffs. Thus, tariffs were chosen based on the domestic politics of the United States. Individual members of Congress were under great pressure from industry lobbyists to raise tariffs to protect them from the negative effects of foreign imports. \nThe RTAA’s novel approach freed Roosevelt and Congress to break this trend of tariff increases. First, it tied tariff reductions by the United States to reciprocal tariff reductions with international partners. It also allowed Congress to approve the tariffs with a simple majority, as opposed to the requisite two-thirds majority necessary for other treaties. Lastly, the president had the authority to negotiate the terms. These three innovations in trade policy created the political will and feasibility to enact a more liberal American trade policy. \nReciprocity was an important tenet of the trade agreements brokered under RTAA because it gave Congress more of an incentive to lower tariffs. As more foreign countries entered into bilateral tariff reduction deals with the United States, American exporters had more incentive to lobby Congress for even lower tariffs across many industries. \nBy giving the President the authority to negotiate these deals, the Congress effectively ceded a part of their power (authorized under US Constitution, Article I, Section VIII) to the executive branch. The President had to consider the aggregate welfare of all Americans, his foreign policy priorities, and what was feasible with other countries in making his decisions on tariffs. These considerations generally left presidents more inclined to reduce tariffs than the Congress. Whether Roosevelt or Congress foresaw this result is a matter of historical debate.\n\nAfter the Civil War, Democrats were generally the party of trade liberalization, while Republicans were generally for higher tariffs. This pattern was clear in congressional votes for tariffs from 1860 until 1930. Democrats were the congressional minority in the majority of Congresses between the Civil War and the election of Roosevelt. During their brief stints in the majority, Democrats passed several tariff reduction bills. Examples include the Wilson–Gorman Act of 1894 and the Underwood Tariff Act of 1913. However, subsequent Republican majorities always undid these unilateral tariff reductions. \nBy the Great Depression, tariffs were at historic highs. Members of Congress commonly entered in informal \"quid pro quo\" agreements where they voted for other members’ preferred tariffs in order to secure support for their own. At no point did anyone take into account the aggregate toll on American consumers or exporters. This practice is commonly referred to as logrolling. President Roosevelt and key members of his administration were intent on stopping this practice. \nThough Democrats voted for trade liberalization far more often than Republicans, they were not uniform in their preferences. Democrats skeptical of reducing tariffs during the Depression included Representative Henry Rainey (D-IL) and members of Roosevelt’s own administration – Rexford Tugwell, Raymond Moley and Adolf Berle. However, the administration decided to take advantage of having a Democratic-controlled Congress and Presidency to push through the RTAA. In 1936 and 1940, the Republican Party ran on a platform of repealing the tariff reductions secured under the RTAA. But when they won back Congress in 1946, they did not act to remove the tariffs. In the years since the enactment of the RTAA in 1934, the economies of Europe and East Asia had been decimated by the violence of World War II. This left a huge global production vacuum that was filled by American exporters. In the World War II period, the United States had its highest positive account balance in its history. Republican preferences for tariffs started shifting as exporters from their home districts began to benefit from increased international trade. By the 1950s, there was no statistically significant difference between Republicans and Democrats on tariff policies. This change has endured to the present day.\n\nAnother key feature of the RTAA was the fact that if Congress wanted to repeal a tariff reduction, it would take a two-thirds supermajority. That means that the tariff would have to be especially onerous and that the Congress would have to be especially protectionist. Once enacted, tariff reductions tended to stick. \nAs more American industries began to benefit from tariff reductions, some of them began to lobby Congress for lower tariffs. Prior to RTAA, Congress was mostly lobbied by industries seeking to create or increase tariffs to protect their industry. This change also helped to lock in many of the gains in trade liberalization. In short, the political incentive to raise tariffs decreased while the political incentive to lower tariffs increased.\n\nAs American duties dropped off dramatically, global markets also increasingly liberalized. World trade expanded at a rapid pace. The RTAA, though a law of the United States, provided the first widespread system of guidelines for bilateral trade agreements. The United States and the European nations began avoiding beggar thy neighbour policies (which pursued national trade objectives at the expense of other nations). Instead, countries started to realize the gains from trade cooperation.\nLed by the United States and the United Kingdom, international cooperation flourished and concrete institutions were created. In talks begun at the Bretton Woods Conference of 1944, the International Monetary Fund was created. By 1949, the first international board governing trade, the General Agreement on Tariffs and Trade (GATT) was established. In 1994, GATT was replaced with the World Trade Organization (WTO), which oversees international trade agreements today. \nThe United States Department of State also found good use of the expansion of free trade after World War II. Many in the State Department saw multilateral trade agreements as a way to engage the world in accordance with the Marshall Plan and the Monroe Doctrine. US trade policy became an integral part of US foreign policy. This pursuit of free-trade-cum-diplomacy intensified during the Cold War, as the United States competed with the Soviet Union for relationships around the globe.\n"}
{"id": "2231110", "url": "https://en.wikipedia.org/wiki?curid=2231110", "title": "Saudi–Kuwaiti neutral zone", "text": "Saudi–Kuwaiti neutral zone\n\nThe Saudi–Kuwaiti neutral zone, also known as the Divided Zone, was an area of between the borders of Saudi Arabia and Kuwait that was left undefined when the border was established by the Uqair Convention of 2 December 1922.\n\nIn the area, which was later called the \"Neutral Zone\" or \"Divided Zone\", the Uqair Convention stated that \"the Government of Najd and Kuwait will share equal rights until through the good offices of the Government of Great Britain a further agreement is made between Najd and Kuwait concerning it\".\n\nHowever, there was little interest in a more definitive settlement in the so-called \"Neutral Zone\" until the discovery, in 1938, of oil in the Burgan (Burqan) of Kuwait. With the possibility of oil discovery within the \"Neutral Zone\" itself, concessions were granted in 1948–1949 by each government to private companies. Later the two countries exploited the oil under a joint operating agreement.\n\nIn 1957, Saudi Arabia signed a concession agreement with the Japanese-owned Arab Oil Co., and Kuwait signed in 1958. That concession expired in 2000.\n\nThe partitioning negotiations commenced shortly after the rulers of Kuwait and Saudi Arabia met and decided, in October 1960, that the Neutral Zone should be divided. On 7 July 1965, the two governments signed an agreement (which took effect on 25 July 1966) to partition the Neutral Zone adjoining their respective territories. A demarcation agreement dividing the Neutral Zone was signed on 17 December 1967 but did not formally take effect until the exchange of instruments and signing which took place in Kuwait on 18 December 1969. Ratification followed on 18 January 1970, and the agreement was published in the \"Kuwaiti Official Gazette\" on 25 January 1970.\n\nThe zone was never assigned an ISO 3166 code since it was partitioned before the adoption of ISO 3166 in 1974.\n\n\n"}
{"id": "28230024", "url": "https://en.wikipedia.org/wiki?curid=28230024", "title": "Secret rebate", "text": "Secret rebate\n\nA secret rebate is a kick-back that is made available to some customers or business partners but concealed from others, to the detriment of competition. The practice is usually illegal under state unfair business practice laws.\n\nCalifornia offers an example of a law banning secret rebates:\nCases interpreting California's provision include Eddins v. Redstone, 134 Cal. App. 4th 290 (2005) and Cleveland v. Viacom Inc., 73 F. App’x 736 (5th Cir. 2003).\n\n"}
{"id": "7116485", "url": "https://en.wikipedia.org/wiki?curid=7116485", "title": "Single Audit", "text": "Single Audit\n\nIn the United States, the Single Audit, Subpart F of the OMB Uniform Guidance, is a rigorous, organization-wide audit or examination of an entity that expends $750,000 or more of federal assistance (commonly known as federal funds, federal grants, or federal awards) received for its operations. Usually performed annually, the Single Audit's objective is to provide assurance to the US federal government as to the management and use of such funds by recipients such as states, cities, universities, non-profit organizations, and Indian Tribes. The audit is typically performed by an independent certified public accountant (CPA) and encompasses both financial and compliance components. The Single Audits must be submitted to the Federal Audit Clearinghouse along with a data collection form, Form SF-SAC.\n\nBefore implementing the Single Audit, the federal government relied on numerous audits carried out on individual federally funded programs to ensure these funds were spent properly. Because the government had numerous agencies awarding hundreds of different programs, the task of auditing all programs became increasingly difficult and time consuming. To improve this situation, the Single Audit Act of 1984 standardized audit requirements for States, local governments, and Indian tribal governments that receive and use federal financial assistance programs.\n\nIn 1985, the United States Office of Management and Budget (OMB) issued OMB Circular A-128, \"Audits of State and Local Governments,\" to help recipients and auditors implement the new Single Audit. In 1990, OMB administratively extended the Single Audit process to non-profit organizations by issuing OMB Circular A-133, \"Audits of Institutions of Higher Education and Other Non-Profit Organizations\" which superseded OMB A-128. These new guides and provisions standardized the Single Audit in the United States to include all states, local governments, non-profit organizations, and institutions that receive federal funds from the US government. On December 26, 2013, OMB issued the Uniform Administrative Requirements, Cost Principles, and Audit Requirements for Federal Awards, which standardized compliance and audit requirements for government entities, non-profit organizations and institutions of higher education. These consolidated requirements are codified in Title 2 of the Code of Federal Regulations (CFR), part 200 with the single audit requirements in Subpart F of this section. The terms 2 CFR 200 and Uniform Guidance can be used interchangeably.\n\nThe federal government provides an extensive array of federal assistance to recipients reaching over $400 billion annually. This assistance is provided through thousands of individual grants and awards annually for the purpose of benefiting the general public in the areas of education, health, public safety, welfare, and public works, among others. However, as a condition of receiving this assistance recipients must comply with applicable federal and state laws and regulations, as well as any particular provisions tied with the specific assistance. The Single Audit provides the Federal government with assurance that these recipients comply with such directives by having an independent external source (the CPA) report on such compliance. However, it only applies to state, local government, and nonprofit recipients that expend $750,000 or more of such assistance in one year.\n\nA Single Audit encompasses an examination of a recipient's financial records, financial statements, federal award transactions and expenditures, the general management of its operations, internal control systems, and federal assistance it received during the audit period (the time period of recipient operations examined in the Single Audit, which is usually covers a natural or fiscal year). The Single Audit is divided into two areas: Compliance and Financial.\n\nThe compliance component of a Single Audit covers the study and understanding (planning stage) as well as the testing and evaluation (exam stage) of the recipient with respect to federal assistance usage, operations and compliance with laws and regulations. The financial component is exactly like a financial audit of a non-federal entity which includes the audit of the financial statements and accompanying notes. Depending on the recipient, the Single Audit can be simple and straightforward, or it could be complex and troublesome. This is because there are millions of federal grants awarded each year to thousands of recipients, each with its own independent way of operating. Therefore, the Single Audit differs from recipient to recipient and from federal program to program.\n\nFor these reasons, the federal government requires auditors to perform the compliance audit of a recipient with a planning stage and an exam stage. During the first stage, or planning stage, the auditor must study the recipient, determine whether there is a high or low risk that the recipient does not comply with laws and regulations, identify federal programs, and evaluate such programs. The second stage, or exam or audit stage, is where the auditor actually audits the federal assistance and programs. The planning stage is considered an integral part of the Single Audit because it allows the auditor to design and perform the audit based on the qualities, characteristics and needs of the recipient to be audited.\n\nBefore determining which federal programs to examine, the auditor must first determine, based on specific criteria, whether the recipient is a high-risk auditee or a low-risk auditee. A high-risk auditee is a recipient which has a high risk of not complying with federal laws and regulations, while a low-risk auditee is the exact opposite. The Uniform Guidance has set certain requirements a recipient must meet to be considered a low-risk auditee. This includes the following to be evaluated for each of the preceding two audit periods:\n\n\nThe Uniform Guidance uses the high and low risk determination to regulate the dollar amount of federal expenditures to be audited. Although the actual work necessary for a Single Audit is established by the auditor, the OMB has set a limit for auditing high-risk and low-risk auditees. For high-risk auditees, the auditor is required to audit not less than 40% of all the federal assistance received during the year. For low-risk auditees, that limit is decreased to 20%.\n\nThis determination affects the entire Single Audit because the auditor adjusts the scope of the audit accordingly. Since the auditor must provide an opinion to the federal government on whether the recipient and its programs complied with laws and regulations, the auditor performs sufficient procedures to confirm the opinion is correct.\n\nTo determine which federal programs to audit under the compliance audit, federal assistance expended by the recipient (also called federal expenditures) during one year is identified by federal program name, Federal agency and CFDA number. These federal expenditures are then combined to determine the total amount expended during the year. Any recipient whose total federal expenditures during a year equal or exceed $750,000 requires a Single Audit. If the recipient does not meet this threshold, a Single Audit is not required, although the recipient may elect to have a program-specific audit (an audit of a single federal program, without auditing the entire entity). Once this determination is performed, 2 CFR 200.518 requires that federal programs be categorized in two groups: Type A programs and Type B programs.\n\nIn other words, if a recipient expended a total of $25 million or less in federal assistance, then any single program which expended $750,000 or more is considered a Type A. If a recipient expended $30 million in federal assistance, then any single program which expended $900,000 or more (3% × $30,000,000) is considered a Type A program. Special consideration must be given to large loan programs in determining the Type A threshold.\nExample 1 – The City of Example operates a Section 8 program, and expended $950,000 in Section 8 funds and $5,000,000 of total federal assistance during the year. Since this amount does not exceed $25,000,000, the Section 8 program is considered a Type A program because $950,000 exceeds the $750,000 threshold.\n\nExample 2 – Using the same data in Example 1 with the exception that the City of Example now expended a total of $30,000,000 in federal assistance, the Section 8 program would meet the Type A threshold because $950,000 is greater than $30,000,000 x 3% ($900,000).\n\nExample 3 – Using the same data in Example 1 with the exception that the City of Example now expended a total of $100,000,000 in federal assistance, the Section 8 program would not meet the Type A threshold because $950,000 is less than $3 million, and would be considered a Type B program.\n\nAfter determining which programs are Type A and Type B, the Uniform Guidance requires that the auditor study and understand the operations and internal controls of such programs within the entity, and perform and document a risk assessment based on such study to determine whether each program has either a high or low risk of not complying with laws and regulations. Auditor may consider numerous factors including current and prior audit experience, good or poor internal controls over Federal programs, many or no prior audit findings, continuous or lack of oversight exercised by the federal government over the recipient, evidence or knowledge of fraud, and the inherent risk of the Federal program.\n\nFor a Type A program to be considered low risk according to 2 CFR 200.518, it must have been audited as a major program at least once in the past two years and must not have had:\n\nFor any Type A program considered to be a high risk of not complying, the Uniform Guidance requires that the auditor to perform a compliance audit on that program. For a Type A program that is considered to be of low risk, then the auditor is not required to perform a compliance audit, although the Uniform Guidance allows the auditor to do so if he/she chooses to. Although the risk assessment is performed by the auditor based on his/her judgment, the Uniform Guidance does have two requirements for a program to be considered low risk.\n\nIn assessing the risk of Type B programs, auditors should use professional judgement and criteria established in the Uniform Guidance. According to 2 CFR 200.518, a minimum number of Type B programs must be identified as high risk, calculated as 25% of the number of low-risk Type A programs (rounded up). In assessing risk, auditors are encouraged to use an approach that allows different programs to be identified as high risk over time. The auditor is not expected to perform risk assessments on smaller Type B programs with expenditures that do not exceed 25% of the Type A threshold determined in step 1. Type B programs which have a low risk of not complying are not required to be audited.\n\nHigh-risk Type A and high-risk Type B programs are considered major programs and must be audited. The auditor then totals all of the federal award expenditures for the identified major programs and divides by the total federal award expenditures for the entity as a whole. For low-risk auditees, major program expenditures as a percentage of total award expenditures must be at least 20%. For high-risk auditees, the required coverage percentage is increased to 40%. If the identified major programs do not meet the required coverage percentage, then the auditor must select additional programs to audit until the required coverage percentage is met.\n\nAfter the auditor determines which federal programs to audit, the auditor performs a compliance audit that scrutinizes operations of the program—examining files, documents, contracts, checks, etc. The auditor investigates, to some degree, transactions between the federal program and other parties. These functions are compared with the laws and regulations applicable to a program to see if they complied or not. The examination does not require observing every single document and every single process generated by the program, nevertheless the auditor is required to perform enough procedures to form an opinion on whether the program (as a whole) complied with laws and regulations.\n\nDue to the amount of federal regulations, the federal government has provided certain guides and literature to assist the auditor in the examination, which includes the OMB Compliance Supplement and the Compliance requirements:\n\nThe OMB Compliance Supplement is a large and extensive guide created by the OMB for Single Audits, and is considered the most important tool of both the auditor and the recipient when performing, or being subject to, a Single Audit. It was created following amendments in 1996 to the Single Audit Act and serves to identify existing important compliance requirements that the Federal Government expects to be considered as part of a Single Audit. Without it, auditors would need to research thousands of laws and regulations for each single program of a recipient to determine which compliance requirements are important to the Federal Government. For Single Audits, the Supplement replaces any agency audit guides and other audit requirement documents for individual Federal programs.\n\nCompliance requirements are series of directives provided by Federal agencies that summarize hundreds of laws and regulations applicable to federal assistance and are important to the successful management of such assistance. The OMB created 14 basic and standard compliance requirements for which recipients must always comply with when receiving and using federal assistance, and provided detailed explanations, discussions, and guidance about them in the OMB Compliance Supplement. These compliance requirements only serve as guidelines for compliance with the specific laws and regulations applicable to the assistance and their objectives are designed to be generic in nature, because of the amount of different federal programs provided by the government. For example, many federal programs have eligibility requirements for individuals or organizations to participate in such programs because they have been established by either laws, regulations, or contract provisions. However, while the criterion for determining eligibility varies from program to program, the objective of the Eligibility compliance requirement that \"only eligible and qualified individuals or organizations participate\" is consistent and universal across all federal assistance programs. This eligibility universal criteria is called the Eligibility compliance requirement.\n\nThe Single Audit requires that a recipient prepare financial statements that reflect its financial position, results of operations or changes in net assets, and, where appropriate, cash flows for the fiscal year audited. It also requires that a financial audit be performed on the recipient, which includes the federal assistance operations as well as the non-federal assistance operations. Tests of transactions and account balances are performed to ensure that the information presented in the financial statements, and notes thereof, are presented fairly in all material respects in accordance with generally accepted accounting principles. Additionally, the recipient must prepare a Schedule of Expenditures of Federal Awards (SEFA), which is supplementary information to the financial statements unique to recipients of federal assistance that details all the federal assistance expended by the recipient during the year, categorized by federal program. The auditor must then audit and report on this Schedule \"in relation to\" the financial statements as a whole.\n\nAfter the Single Audit is concluded, the recipient prepares two documents: a \"Data Collection Form and a \"Reporting Package\". The data collection form, Form SF-SAC, is a standard form which is basically a summary of the Single Audit. It includes details of the auditor, a list of the federal programs audited, and a summary of any audit findings reported by the auditor. The Reporting Package includes all the auditor's final reports along with the recipient's financial statements. It includes:\n\n\nBoth the Data Collection and the Reporting Package are kept by the recipient with copies submitted to the Federal Audit Clearinghouse (FAC), and to any Federal agency who specifically requests it. Federal guidelines require recipients to submit the documents no more than 30 days after the auditor submits his reports or 9 months after the final day of the audit period, whichever comes first.\n\nThe auditor is responsible for conducting the actual audit of the recipient in accordance with Generally Accepted Government Auditing Standards (GAGAS) and using the guidance provided by the OMB Circular A-133 and its Compliance Supplement, all of which establish certain rules to follow during the Single Audit. The auditor must establish audit objectives that determine whether the recipient complied with laws and regulations. They must research the recipient's federal assistance awards and programs to determine applicability of specific laws and regulations. They must understand the recipient, its organization, operations, internal control systems, and ability to responsibly manage federal assistance. They must perform audit procedures (some of which are suggested by the Compliance Supplement) to meet these audit objectives.\n\nThe auditor must understand the recipient's internal control system to determine if the recipient has proper safeguards that help manage federal assistance responsibly. After obtaining sufficient knowledge of that system, the auditor must perform audit procedures to verify the recipient's internal control system works properly, and the recipient's federal program operations comply with laws and regulations (e.g., the compliance audit portion of the Single Audit).\n\nAs part of the Single Audit, the auditor must prepare and submit three individual reports to the recipient and to the federal government. The first report is an opinion, or a disclaimer thereof, on whether the recipient's financial statements are presented in conformity with US Generally Accepted Accounting Principles, identical to a financial audit's report on a non-recipient entity. The second report is about the status of internal controls relative to the financial statements and major programs. The third report is an opinion, or a disclaimer thereof, on the degree to which the recipient has complied with laws, regulations, and the terms and conditions of the federal assistance awards. Following the last two reports, if the Single Audit produced audit findings, the auditor must prepare the Schedule of Findings and Questioned Costs discussed earlier.\n\nThe auditor's judgment is necessary to determine which audit procedures are sufficient to achieve the audit objectives, and whether additional or alternative audit procedures are needed to achieve such objectives. The auditor is responsible for determining the nature, timing, and extent of the audit procedures necessary to meet the audit objectives (i.e., it is the auditor who determines the necessary amount of his/her audit work needed to form an opinion on whether the recipient complied with laws and regulations).\n\n\n\n\n"}
{"id": "31668", "url": "https://en.wikipedia.org/wiki?curid=31668", "title": "Sixteenth Amendment to the United States Constitution", "text": "Sixteenth Amendment to the United States Constitution\n\nThe Sixteenth Amendment (Amendment XVI) to the United States Constitution allows the Congress to levy an income tax without apportioning it among the states or basing it on the United States Census. This amendment exempted income taxes from the constitutional requirements regarding direct taxes, after income taxes on rents, dividends, and interest were ruled to be direct taxes in the court case of \"Pollock v. Farmers' Loan & Trust Co.\" (1895). The amendment was adopted on February 3, 1913.\n\nArticle I, Section 2, Clause 3:\n\nArticle I, Section 8, Clause 1:\n\nArticle I, Section 9, Clause 4:\n\nThis clause basically refers to a tax on property, such as a tax based on the value of land, as well as a capitation.\n\nArticle I, Section 9, Clause 5:\n\nUntil 1913, customs duties (tariffs) and excise taxes were the primary sources of federal revenue. During the War of 1812, Secretary of the Treasury Alexander J. Dallas made the first public proposal for an income tax, but it was never implemented. The Congress did introduce an income tax to fund the Civil War through the Revenue Act of 1861. It levied a flat tax of three percent on annual income above $800. This act was replaced the following year with the Revenue Act of 1862, which levied a graduated tax of three to five percent on income above $600 and specified a termination of income taxation in 1866. The Civil War income taxes, which expired in 1872, proved to be both highly lucrative and drawing mostly from the more industrialized states, with New York, Pennsylvania, and Massachusetts generating about 60 percent of the total revenue that was collected. During the two decades following the expiration of the Civil War income tax, the Greenback movement, the Labor Reform Party, the Populist Party, the Democratic Party and many others called for a graduated income tax.\n\nThe Socialist Labor Party advocated a graduated income tax in 1887. The Populist Party \"demand[ed] a graduated income tax\" in its 1892 platform. The Democratic Party, led by William Jennings Bryan, advocated the income tax law passed in 1894, and proposed an income tax in its 1908 platform.\n\nBefore \"Pollock v. Farmers' Loan & Trust Co.\", all income taxes had been considered to be indirect taxes imposed without respect to geography, unlike direct taxes, that have to be apportioned among the states according to population.\n\nIn 1894, an amendment was attached to the Wilson–Gorman Tariff Act that attempted to impose a federal tax of two percent on incomes over $4,000 (equal to $,000 in ). The federal income tax was strongly favored in the South, and it was moderately supported in the eastern North Central states, but it was strongly opposed in the Far West and the Northeastern States (with the exception of New Jersey). The tax was derided as \"un-Democratic, inquisitorial, and wrong in principle\".\n\nIn \"Pollock v. Farmers' Loan & Trust Co.\", the U.S. Supreme Court declared certain taxes on incomes – such as those on property under the 1894 Act – to be unconstitutionally unapportioned direct taxes. The Court reasoned that a tax on \"income from property\" should be treated as a tax on \"property by reason of its ownership\" and so should be required to be apportioned. The reasoning was that taxes on the rents from land, the dividends from stocks, and so forth, burdened the property generating the income in the same way that a tax on \"property by reason of its ownership\" burdened that property.\n\nAfter \"Pollock\", while income taxes on wages (as indirect taxes) were still not required to be apportioned by population, taxes on interest, dividends, and rental income were required to be apportioned by population. The \"Pollock\" ruling made the \"source of the income\" (e.g., property versus labor, etc.) relevant in determining whether the tax imposed on that income was deemed to be \"direct\" (and thus required to be apportioned among the states according to population) or, alternatively, \"indirect\" (and thus required only to be imposed with geographical uniformity).\n\nDissenting in \"Pollock\", Justice John Marshall Harlan stated:\n\nMembers of Congress responded to \"Pollock\" by expressing widespread concern that many of the wealthiest Americans had consolidated too much economic power.\n\nOn June 16, 1909, President William Howard Taft, in an address to the Sixty-first Congress, proposed a two percent federal income tax on corporations by way of an excise tax and a constitutional amendment to allow the previously enacted income tax.\n\nAn income tax amendment to the Constitution was first proposed by Senator Norris Brown of Nebraska. He submitted two proposals, Senate Resolutions Nos. 25 and 39. The amendment proposal finally accepted was Senate Joint Resolution No. 40, introduced by Senator Nelson W. Aldrich of Rhode Island, the Senate majority leader and Finance Committee Chairman.\n\nOn July 12, 1909, the resolution proposing the Sixteenth Amendment was passed by the Congress and was submitted to the state legislatures. Support for the income tax was strongest in the western and southern states, while opposition was strongest in the northeastern states. Supporters of the income tax believed that it would be a much better method of gathering revenue than tariffs, which were the primary source of revenue at the time. From well before 1894, Democrats, Progressives, Populists and other left-oriented parties argued that tariffs disproportionately affected the poor, interfered with prices, were unpredictable, and were an intrinsically limited source of revenue. The South and the West tended to support income taxes because their residents were generally less prosperous, more agricultural and more sensitive to fluctuations in commodity prices. A sharp rise in the cost of living between 1897 and 1913 greatly increased support for the idea of income taxes, including in the urban Northeast. A growing number of Republicans also began supporting the idea, notably Theodore Roosevelt and the \"Insurgent\" Republicans (who would go on to form the Progressive Party). These Republicans were driven mainly by a fear of the increasingly large and sophisticated military forces of Japan, Britain and the European powers, their own imperial ambitions and the perceived need to defend American merchant ships. Moreover, these progressive Republicans were, as the name suggests, convinced that central governments could play a positive role in national economies. A bigger government and a bigger military, of course, required a correspondingly larger and steadier source of revenue to support it.\n\nOpposition to the Sixteenth Amendment was led by establishment Republicans because of their close ties to wealthy industrialists, although not even they were uniformly opposed to the general idea of a permanent income tax. In 1910, New York Governor Charles Evans Hughes, shortly before becoming a Supreme Court Justice, spoke out against the income tax amendment. Hughes supported the idea of a federal income tax, but believed the words \"from whatever source derived\" in the proposed amendment implied that the federal government would have the power to tax state and municipal bonds. He believed this would excessively centralize governmental power and \"would make it impossible for the state to keep any property\".\n\nBetween 1909 and 1913, several conditions favored passage of the Sixteenth Amendment. Inflation was high and many blamed federal tariffs for the rising prices. The Republican Party was divided and weakened by the loss of Roosevelt and the Insurgents who joined the Progressive Party, a problem that blunted opposition even in the Northeast. In 1912, the Democrats won the presidency and control of both houses of Congress. The country was generally in a left-leaning mood, with the Socialist Party winning a seat in the House in 1910 and polling six percent of the popular presidential vote in 1912.\n\nThree advocates for a federal income tax ran in the presidential election of 1912. On February 25, 1913, Secretary of State Philander Knox proclaimed that the amendment had been ratified by three-fourths of the states and so had become part of the Constitution. The Revenue Act of 1913 was enacted shortly thereafter.\n\nAccording to the United States Government Publishing Office, the following states ratified the amendment:\n\n\nRatification (by the requisite 36 states) was completed on February 3, 1913 with the ratification by Delaware. The amendment was subsequently ratified by the following states, bringing the total number of ratifying states to forty-two of the forty-eight then existing:\n\nThe legislatures of the following states rejected the amendment without ever subsequently ratifying it:\n\nThe legislatures of the following states never considered the proposed amendment:\n\nThe Sixteenth Amendment removed the precedent set by the \"Pollock\" decision.\n\nProfessor Sheldon D. Pollack at the University of Delaware wrote:\n\nFrom William D. Andrews, Professor of Law, Harvard Law School:\n\nFrom Professor Boris Bittker, who was a tax law professor at Yale Law School:\n\nProfessor Erik Jensen at Case Western Reserve University Law School has written:\n\nProfessor Calvin H. Johnson, a tax professor at the University of Texas School of Law, has written:\n\nFrom Gale Ann Norton:\n\nFrom Alan O. Dixler:\n\nCongress may impose taxes on income from any source without having to apportion the total dollar amount of tax collected from each state according to each state's population in relation to the total national population.\n\nIn \"Wikoff v. Commissioner\", the United States Tax Court said:\n\nIn \"Abrams v. Commissioner\", the Tax Court said:\n\nThe federal courts' interpretations of the Sixteenth Amendment have changed considerably over time and there have been many disputes about the applicability of the amendment.\n\nIn \"Brushaber v. Union Pacific Railroad\", , the Supreme Court ruled that (1) the Sixteenth Amendment removes the \"Pollock\" requirement that certain income taxes (such as taxes on income \"derived from real property\" that were the subject of the \"Pollock\" decision), be apportioned among the states according to population; (2) the federal income tax statute does not violate the Fifth Amendment's prohibition against the government taking property without due process of law; (3) the federal income tax statute does not violate the Article I, Section 8, Clause 1 requirement that excises, also known as indirect taxes, be imposed with geographical uniformity.\n\nIn \"Bowers v. Kerbaugh-Empire Co.\", , the Supreme Court, through Justice Pierce Butler, stated:\n\nIn \"Commissioner v. Glenshaw Glass Co.\", , the Supreme Court laid out what has become the modern understanding of what constitutes \"gross income\" to which the Sixteenth Amendment applies, declaring that income taxes could be levied on \"accessions to wealth, clearly realized, and over which the taxpayers have complete dominion\". Under this definition, \"any\" increase in wealth – whether through wages, benefits, bonuses, sale of stock or other property at a profit, bets won, lucky finds, awards of punitive damages in a lawsuit, qui tam actions – are all within the definition of income, unless the Congress makes a specific exemption, as it has for items such as life insurance proceeds received by reason of the death of the insured party, gifts, bequests, devises and inheritances, and certain scholarships.\n\nFederal courts have ruled that the Sixteenth Amendment allows a direct tax on \"wages, salaries, commissions, etc. without apportionment\".\n\nAlthough the Sixteenth Amendment is often cited as the \"source\" of the congressional power to tax incomes, at least one court has reiterated the point made in \"Brushaber\" and other cases that the Sixteenth Amendment itself did not grant the Congress the power to tax incomes, a power the Congress had since 1789, but only removed the possible requirement that any income tax be apportioned among the states according to their respective populations. In \"Penn Mutual Indemnity\", the United States Tax Court stated:\n\nThe United States Court of Appeals for the Third Circuit agreed with the Tax Court, stating:\n\nOn December 22, 2006, a three-judge panel of the United States Court of Appeals for the District of Columbia Circuit vacated its unanimous decision (of August 2006) in \"Murphy v. Internal Revenue Service and United States\". In an unrelated matter, the court had also granted the government's motion to dismiss Murphy's suit against the Internal Revenue Service. Under federal sovereign immunity, a taxpayer may sue the federal government, but not a government agency, officer, or employee (with some exceptions). The Court ruled:\n\nAn exception to federal sovereign immunity is in the United States Tax Court, in which a taxpayer may sue the Commissioner of Internal Revenue. The original three-judge panel then agreed to rehear the case itself. In its original decision, the Court had ruled that was unconstitutional under the Sixteenth Amendment to the extent that the statute purported to tax, as income, a recovery for a nonphysical personal injury for mental distress and loss of reputation not received in lieu of taxable income such as lost wages or earnings.\n\nBecause the August 2006 opinion was vacated, the Court of Appeals did not hear the case \"en banc\".\n\nOn July 3, 2007, the Court (through the original three-judge panel) ruled (1) that the taxpayer's compensation was received on account of a nonphysical injury or sickness; (2) that gross income under section 61 of the Internal Revenue Code does include compensatory damages for nonphysical injuries, even if the award is not an \"accession to wealth\", (3) that the income tax imposed on an award for nonphysical injuries is an indirect tax, regardless of whether the recovery is restoration of \"human capital\", and therefore the tax does not violate the constitutional requirement of Article I, Section 9, Clause 4, that capitations or other direct taxes must be laid among the states only in proportion to the population; (4) that the income tax imposed on an award for nonphysical injuries does not violate the constitutional requirement of Article I, Section 8, Clause 1, that all duties, imposts and excises be uniform throughout the United States; (5) that under the doctrine of sovereign immunity, the Internal Revenue Service may not be sued in its own name.\n\nThe Court stated that \"[a]lthough the 'Congress cannot make a thing income which is not so in fact', ... it can \"label\" a thing income and tax it, so long as it acts within its constitutional authority, which includes not only the Sixteenth Amendment but also Article I, Sections 8 and 9.\" The court ruled that Ms. Murphy was not entitled to the tax refund she claimed, and that the personal injury award she received was \"within the reach of the Congressional power to tax under Article I, Section 8 of the Constitution\" – even if the award was \"not income within the meaning of the Sixteenth Amendment\". See also the \"Penn Mutual\" case cited above.\n\nOn April 21, 2008, the U.S. Supreme Court declined to review the decision by the Court of Appeals.\n\n\n"}
{"id": "56790716", "url": "https://en.wikipedia.org/wiki?curid=56790716", "title": "State unemployment tax act", "text": "State unemployment tax act\n\nTaxes under State Unemployment Tax Act (or SUTA) are those designed to finance the cost of state unemployment insurance benefits in the United States, which make up all of unemployment insurance expenditures in normal times, and the majority of unemployment insurance expenditures during downturns, with the remainder paid in part by the federal government for \"emergency\" benefit extensions.\n\nThe tax is unique in two primary aspects. First, the tax is experience rated which means that tax rates are firm-specific and the rate a firm faces updates each year to reflect the cost of the benefits that firm's former employees have received recently. Because it is primarily firms in stress that generate layoffs, these tax increases target firms that are already under strain. For this reason, states limit how high they allow taxes to rise, but these limits vary by almost an order of magnitude from state to state.\n\nThe second unique feature of UI taxes under SUTA is that the taxable base is ~$10,000 (on average, varies by state) per employee, much less than the average yearly earnings of a given worker. Because of this feature, firms pay a fixed \"lump sum\" tax per worker they employ. This provides a modest incentive for firms to reduce unskilled and part-time work in favor of skilled and full-time work.\n\nOne interesting feature of the UI tax is that it targets firms that have recently had layoffs, potentially hitting distressed firms. Recent work shows that UI tax increases significantly reduce hiring and employment in affected firms, potentially eroding the macroeconomics stabilizing influence of the UI program.\n"}
{"id": "42337835", "url": "https://en.wikipedia.org/wiki?curid=42337835", "title": "Terms of Service; Didn't Read", "text": "Terms of Service; Didn't Read\n"}
{"id": "30875", "url": "https://en.wikipedia.org/wiki?curid=30875", "title": "Theocracy", "text": "Theocracy\n\nTheocracy is a form of government in which a religious institution is the source from which all authority derives. The \"Oxford English Dictionary\" has this definition:\nAn ecclesiocracy is a situation where the religious leaders assume a leading role in the state, but do not claim that they are instruments of divine revelation: for example, the prince-bishops of the European Middle Ages, where the bishop was also the temporal ruler. Such a state may use the administrative hierarchy of the religion for its own administration, or it may have two \"arms\"—administrators and clergy—but with the state administrative hierarchy subordinate to the religious hierarchy. Theocracy differs from theonomy, the latter of which is government based on divine law.\n\nThe papacy in the Papal States occupied a middle ground between theocracy and ecclesiocracy, since the Pope did not claim he was a prophet who received revelation from God and translated it into civil law.\n\nReligiously endorsed monarchies fall between theocracy and ecclesiocracy, according to the relative strengths of the religious and political organs.\n\nMost forms of theocracy are oligarchic in nature, involving rule of the many by the few, some of whom so anointed under claim of divine commission.\n\nThe word \"theocracy\" originates from the Greek θεοκρατία meaning \"the rule of God\". This in turn derives from θεός (\"theos\"), meaning \"god\", and κρατέω (\"krateo\"), meaning \"to rule\". Thus the meaning of the word in Greek was \"rule by god(s)\" or human incarnation(s) of god(s).\n\nThe term was initially coined by Flavius Josephus in the first century A.D. to describe the characteristic government of the Jews. Josephus argued that while mankind had developed many forms of rule, most could be subsumed under the following three types: monarchy, oligarchy, and democracy. The government of the Jews, however, was unique. Josephus offered the term \"theocracy\" to describe this polity, ordained by Moses, in which God is sovereign and his word is law.\n\nJosephus' definition was widely accepted until the Enlightenment era, when the term started to collect more universalistic and negative connotations, especially in Hegel's hands. The first recorded English use was in 1622, with the meaning \"sacerdotal government under divine inspiration\" (as in Biblical Israel before the rise of kings); the meaning \"priestly or religious body wielding political and civil power\" is recorded from 1825.\n\nIn some religions, the ruler, usually a king, was regarded as the chosen favorite of God (or gods) who could not be questioned, sometimes even being the descendant of, or a god in their own right. Today, there is also a form of government where clerics have the power and the supreme leader could not be questioned in action. From the perspective of the theocratic government, \"God himself is recognized as the head\" of the state, hence the term \"theocracy\", from the Koine Greek \"rule of God\", a term used by Josephus for the kingdoms of Israel and Judah.\nTaken literally, \"theocracy\" means rule by God or gods and refers primarily to an internal \"rule of the heart\", especially in its biblical application. The common, generic use of the term, as defined above in terms of rule by a church or analogous religious leadership, would be more accurately described as an \"ecclesiocracy\".\n\nIn a pure theocracy, the civil leader is believed to have a personal connection with the civilization's religion or belief. For example, Moses led the Israelites, and Muhammad led the early Muslims. There is a fine line between the tendency of appointing religious characters to run the state and having a religious-based government. According to the Holy Books, Prophet Joseph was offered an essential governmental role just because he was trustworthy, wise and knowledgeable (Quran 12: 54–55). As a result of the Prophet Joseph's knowledge and also due to his ethical and genuine efforts during a critical economic situation, the whole nation was rescued from a seven-year drought (Quran 12: 47–48).\n\nWhen religions have a \"holy book\", it is used as a direct message from God. Law proclaimed by the ruler is also considered a divine revelation, and hence the law of God. As to the Prophet Muhammad ruling, \"The first thirteen of the Prophet's twenty-three year career went on totally apolitical and non-violent. This attitude partly changed only after he had to flee from Mecca to Medina.This \"hijra\", or migration, would be a turning point in the Prophet's mission and would mark the very beginning of the Muslim calendar. Yet the Prophet did not establish a theocracy in Medina. Instead of a polity defined solely by Islam, he founded a territorial polity based on religious pluralism. This is evident in a document called the ’Charter of Medina’, which the Prophet signed with the leaders of the other community in the city.\"\n\nAccording to the Quran, Prophets were not after power or material resources. For example in surah 26 verses (109, 127, 145, 164, 180), the Koran repeatedly quotes from Prophets, Noah, Hud, Salih, Lut, and Shu'aib that: \"I do not ask you for it any payment; my payment is only from the Lord of the worlds.\" While, in theocracy many aspects of the holy book are overshadowed by material powers. Due to be considered divine, the regime entitles itself to interpret verses to its own benefit and abuse them out of the context for its political aims. An ecclesiocracy, on the other hand, is a situation where the religious leaders assume a leading role in the state, but do not claim that they are instruments of divine revelation. For example, the prince-bishops of the European Middle Ages, where the bishop was also the temporal ruler. Such a state may use the administrative hierarchy of the religion for its own administration, or it may have two \"arms\"—administrators and clergy—but with the state administrative hierarchy subordinate to the religious hierarchy. The papacy in the Papal States occupied a middle ground between theocracy and ecclesiocracy, since the pope did not claim he was a prophet who received revelation from God and translated it into civil law.\n\nReligiously endorsed monarchies fall between these two poles, according to the relative strengths of the religious and political organs.\n\nTheocracy is distinguished from other, secular forms of government that have a state religion, or are influenced by theological or moral concepts, and monarchies held \"By the Grace of God\". In the most common usage of the term, some civil rulers are leaders of the dominant religion (e.g., the Byzantine emperor as patron and defender of the official Church); the government proclaims it rules on behalf of God or a higher power, as specified by the local religion, and divine approval of government institutions and laws. These characteristics apply also to a caesaropapist regime. The Byzantine Empire however was not theocratic since the patriarch answered to the emperor, not vice versa; similarly in Tudor England the crown forced the church to break away from Rome so the royal (and, especially later, parliamentary) power could assume full control of the now Anglican hierarchy and confiscate most church property and income.\n\nSecular governments can also co-exist with a state religion or delegate some aspects of civil law to religious communities. For example, in Israel marriage is governed by officially recognized religious bodies who each provide marriage services for their respected adherents, yet no form of civil marriage (free of religion, for atheists, for example) exists nor marriage by non-recognized minority religions.\n\nFollowing the Capture of Rome on 20 September 1870, the Papal States including Rome with the Vatican were annexed by the Kingdom of Italy. In 1929, with the Lateran Treaty signed with the Italian Government, the new state of Vatican City (population 842) – with no connection with the former Papal States – was formally created and recognized as an independent state. The head of state of the Vatican is the pope, elected by the College of Cardinals, an assembly of Senatorial-princes of the Church. They are usually clerics, appointed as Ordinaries, but in the past have also included men who were not bishops nor clerics. A pope is elected for life, and either dies or may resign. The cardinals are appointed by the popes, who therefore choose the electors of their successors.\n\nVoting is limited to cardinals under 80 years of age. A Secretary for Relations with States, directly responsible for international relations, is appointed by the pope. The Vatican legal system is rooted in canon law but ultimately is decided by the pope; the Bishop of Rome as the Supreme Pontiff, \"has the fullness of legislative, executive and judicial powers.\" Although the laws of Vatican City come from the secular laws of Italy, under article 3 of the Law of the Sources of the Law, provision is made for the supplementary application of the \"laws promulgated by the Kingdom of Italy\". The government of the Vatican can also be considered an ecclesiocracy (ruled by the Church).\n\nMount Athos is a mountain peninsula in Greece which is an Eastern Orthodox autonomous region consisting of 20 monasteries under the direct jurisdiction of the Ecumenical Patriarch of Constantinople. There has been almost 1,800-years of continuous Christian presence on Mount Athos and it has a long history of monastic traditions, which dates back to at least 800 A.D. The origins of self-rule are originally from an edict by the Byzantine Emperor Ioannis Tzimisces in 972, which was later reaffirmed by the Emperor Alexios I Komnenos in 1095. After Greece's independence from the Ottoman Empire, Greece claimed mount Athos but after a diplomatic dispute with Russia the region was formally recognised as Greek after World War 1.\n\nMount Athos is specifically exempt from the free movement of people and goods required by Greece's membership of the European Union and entrance is only allowed with express permission from the monks. The number of daily visitors to Mount Athos is restricted, with all visitors required to obtain an entrance permit. Only men are permitted to visit and Orthodox Christians take precedence in permit issuing. Residents of Mount Athos must be men aged 18 and over who are members of the Eastern Orthodox Church and also either monks or workers.\n\nAthos is governed jointly by a 'Holy Community' consisting of representatives from the 20 monasteries and a Civil Governor, appointed by the Greek Ministry of Foreign Affairs. The Holy Community also has a four-member executive committee called the 'Holy Administration' which is led by a Protos.\n\nIran has been described as a \"theocratic republic\" (by the CIA World Factbook), and its constitution a \"hybrid\" of \"theocratic and democratic elements\" by Francis Fukuyama. Like other Islamic states, it maintains religious laws and has religious courts to interpret all aspects of law. According to Iran's constitution, \"all civil, penal, financial, economic, administrative, cultural, military, political, and other laws and regulations must be based on Islamic criteria.\"\n\nIn addition, Iran has a religious ruler and many religious officials in powerful government posts. The head of state, or \"Supreme Leader\", is a \"faqih\" (scholar of Islamic law),\nand possesses more power than Iran's president. The Leader appoints the heads of many powerful posts: the commanders of the armed forces, the director of the national radio and television network, the heads of the powerful major religious foundations, the chief justice, the attorney general (indirectly through the chief justice), special tribunals, and members of national security councils dealing with defence and foreign affairs. He also co-appoints the 12 jurists of the Guardian Council.\n\nThe Leader is elected by the Assembly of Experts which is made up of mujtahids, who are Islamic scholars competent in interpreting \"Sharia\".\n\nThe Guardian Council, has the power to veto bills from majlis (parliament), approve or disapprove candidates who wish to run for high office (president, majlis, the Assembly of Experts). The council supervises elections, and can greenlight or ban investigations into the election process. Six of the Guardians (half the council) are faqih empowered to approve or veto all bills from the majlis (parliament) according to whether the faqih believe them to be in accordance with Islamic law and customs (\"Sharia\"). The other six members are lawyers appointed by the head of the judiciary (who is also a cleric and also appointed by the Leader).\n\nAn Islamic republic is the name given to several states that are officially ruled by Islamic laws, including the Islamic Republics of Afghanistan, Iran, Pakistan, and Mauritania. Pakistan first adopted the title under the constitution of 1956. Mauritania adopted it on 28 November 1958. Iran adopted it after the 1979 Iranian Revolution that overthrew the Pahlavi dynasty. Afghanistan adopted it in 2004 after the fall of the Taliban government. Despite having similar names the countries differ greatly in their governments and laws.\n\nThe term \"Islamic republic\" has come to mean several different things, some contradictory to others. To some Muslim religious leaders in the Middle East and Africa who advocate it, an Islamic republic is a state under a particular Islamic form of government. They see it as a compromise between a purely Islamic caliphate and secular nationalism and republicanism. In their conception of the Islamic republic, the penal code of the state is required to be compatible with some or all laws of Sharia, and the state may not be a monarchy, as many Middle Eastern states are presently.\n\nThe Central Tibetan Administration, colloquially known as the Tibetan government in exile, is a Tibetan exile organisation with a state-like internal structure. According to its charter, the position of head of state of the Central Tibetan Administration belongs \"ex officio\" to the current Dalai Lama, a religious hierarch. In this respect, it continues the traditions of the former government of Tibet, which was ruled by the Dalai Lamas and their ministers, with a specific role reserved for a class of monk officials.\n\nOn March 14, 2011, at the 14th Dalai Lama's suggestion, the parliament of the Central Tibetan Administration began considering a proposal to remove the Dalai Lama's role as head of state in favor of an elected leader.\n\nThe first directly elected Kalön Tripa was Samdhong Rinpoche, who was elected August 20, 2001.\n\nBefore 2011, the Kalön Tripa position was subordinate to the 14th Dalai Lama who presided over the government in exile from its founding. In August of that year, Lobsang Sangay polled 55 percent votes out of 49,189, defeating his nearest rival Tethong Tenzin Namgyal by 8,646 votes, becoming the second popularly elected Kalon Tripa. The Dalai Lama announced that his political authority would be transferred to Sangay.\n\nOn September 20, 2012, the 15th Tibetan Parliament-in-Exile unanimously voted to change the title of Kalön Tripa to \"Sikyong\" in Article 19 of the Charter of the Tibetans in exile and relevant articles. The Dalai Lama had previously referred to the Kalon Tripa as Sikyong, and this usage was cited as the primary justification for the name change. According to \"Tibetan Review\", \"Sikyong\" translates to \"political leader\", as distinct from \"spiritual leader\". Foreign affairs Kalon Dicki Chhoyang stated that the term \"Sikyong\" has had a precedent dating back to the 7th Dalai Lama, and that the name change \"ensures historical continuity and legitimacy of the traditional leadership from the fifth Dalai Lama\". The online Dharma Dictionary translates sikyong (\"srid skyong\") as \"secular ruler; regime, regent\". The title \"sikyong\" had previously been used by regents who ruled Tibet during the Dalai Lama's minority.\n\nHaving a state religion is not sufficient to be a theocracy in the narrow sense. Many countries have a state religion without the government directly deriving its powers from a divine authority or a religious authority directly exercising governmental powers. Since the narrow sense has few instances in the modern world, the more common usage is the wider sense of an enforced state religion.\n\nThe pharaoh was the offspring of the sungod.\n\nThe emperor was the offspring of the sungoddess.\n\nThe imperial cults in Ancient Egypt and the Roman Empire, as well as numerous other monarchies, deified the ruling monarch. The state religion was often dedicated to the worship of the ruler as a deity, or the incarnation thereof.\n\nEarly Israel was ruled by Judges before instituting a monarchy. The Judges were believed to be representatives of YHVH Yahweh (also translated as, Jehovah).\n\nIn ancient and medieval Christianity, Caesaropapism is the doctrine where a head of state is at the same time the head of the church.\n\nUnified religious rule in Tibet began in 1642, when the Fifth Dalai Lama allied with the military power of the Mongol Gushri Khan to consolidate the political power and center control around his office as head of the Gelug school.\nThis form of government is known as the dual system of government. Prior to 1642, particular monasteries and monks had held considerable power throughout Tibet, but had not achieved anything approaching complete control, though power continued to be held in a diffuse, feudal system after the ascension of the Fifth Dalai Lama. Power in Tibet was held by a number of traditional elites, including members of the nobility, the heads of the major Buddhist sects (including their various tulkus), and various large and influential monastic communities.\n\nPolitical power was sometimes used by monastic leaders to suppress rival religious schools through the confiscation of property and direct violence. Social mobility was somewhat possible through the attainment of a monastic education, or recognition as a reincarnated teacher, but such institutions were dominated by the traditional elites and governed by political intrigue. Non-Buddhists in Tibet were members of an outcast underclass.\n\nThe Bogd Khaanate period of Mongolia (1911–19) is also cited as a former Buddhist theocracy.\n\nSimilar to the Roman Emperor, the Chinese sovereign was historically held to be the Son of Heaven. However, from the first historical Emperor on, this was largely ceremonial and tradition quickly established it as a posthumous dignity, like the Roman institution. The situation before Qin Shi Huang Di is less clear.\n\nThe Shang dynasty essentially functioned as a theocracy, declaring the ruling family the sons of heaven and calling the chief sky god Shangdi after a word for their deceased ancestors. After their overthrow by the Zhou, the royal clan of Shang were not eliminated but instead moved to a ceremonial capital where they were charged to continue the performance of their rituals.\n\nThe titles combined by Shi Huangdi to form his new title of emperor were originally applied to god-like beings who ordered the heavens and earth and to culture heroes credited with the invention of agriculture, clothing, music, astrology, &c. Even after the fall of Qin, an emperor's words were considered sacred edicts () and his written proclamations \"directives from above\" ().\n\nAs a result, some Sinologists translate the title \"huangdi\" (usually rendered \"emperor\") as thearch. The term properly refers to the head of a thearchy (a kingdom of gods), but the more accurate \"theocrat\" carries associations of a strong priesthood that would be generally inaccurate in describing imperial China. Others reserve the use of \"thearch\" to describe the legendary figures of Chinese prehistory while continuing to use \"emperor\" to describe historical rulers.\n\nThe Heavenly Kingdom of Great Peace in 1860s Qing China was a heterodox Christian theocracy led by a person who said that he was the younger brother of Jesus Christ, Hong Xiuquan. This theocratic state fought one of the most destructive wars in history, the Taiping Rebellion, against the Qing dynasty for fifteen years before being crushed following the fall of the rebel capital Nanjing.\n\nThe Sunni branch of Islam stipulates that, as a head of state, a Caliph should be elected by Muslims or their representatives. Followers of Shia Islam, however, believe a Caliph should be an Imam chosen by God from the Ahl al-Bayt (the \"Family of the House\", Muhammad's direct descendants).\n\nThe Byzantine Empire ( 324–1453) operated under caesaropapism, meaning that the emperor was both the head of civil society and the ultimate authority over the ecclesiastical authorities, or patriarchates. The emperor was considered to be God's omnipotent representative on earth and he ruled as an absolute autocrat.\n\nJennifer Fretland VanVoorst argues, “the Byzantine Empire became a theocracy in the sense that Christian values and ideals were the foundation of the empire's political ideals and heavily entwined with its political goals\". Steven Runciman says in his book on \"The Byzantine Theocracy\" (2004):\nHistorians debate the extent to which Geneva, Switzerland, in the days of John Calvin (1509–64) was a theocracy. On the one hand, Calvin's theology clearly called for separation between church and state. Other historians have stressed the enormous political power wielded on a daily basis by the clerics.\n\nIn nearby Zurich, Switzerland, Protestant reformer Huldrych Zwingli (1484-1531) built a political system that many scholars have called a theocracy, while others have denied it.\n\nThe question of theocracy has been debated at extensively by historians regarding the Mormon communities in Illinois, and especially in Utah.\n\nJoseph Smith, mayor of Nauvoo, Illinois, and founder of the Latter Day Saint movement, ran as an independent for president in 1844. He proposed the redemption of slaves by selling public lands; reducing the size and salary of Congress; the closure of prisons; the annexation of Texas, Oregon, and parts of Canada; the securing of international rights on high seas; free trade; and the re-establishment of a national bank. His top aide Brigham Young campaigned for Smith saying, \"He it is that God of Heaven designs to save this nation from destruction and preserve the Constitution.\" The campaign ended when Smith was killed by a mob while in the Carthage, Illinois, jail on June 27, 1844.\n\nAfter severe persecution, the Mormons left the United States and resettled in a remote part of Utah, which was then part of Mexico. However the United States took control in 1848 and would not accept polygamy. The Mormon State of Deseret was short-lived. Its original borders stretched from western Colorado to the southern California coast. When the Mormons arrived in the valley of the Great Salt Lake in 1847, the Great Basin was still a part of Mexico and had no secular government. As a result, Brigham Young administered the region both spiritually and temporally through the highly organized and centralized Melchizedek Priesthood. This original organization was based upon a concept called theodemocracy, a governmental system combining Biblical theocracy with mid-19th-century American political ideals.\n\nIn 1849, the Saints organized a secular government in Utah, although many ecclesiastical leaders maintained their positions of secular power. The Mormons also petitioned Congress to have Deseret admitted into the Union as a state. However, under the Compromise of 1850, Utah Territory was created and Brigham Young was appointed governor. In this situation, Young still stood as head of The Church of Jesus Christ of Latter-day Saints (LDS Church) as well as Utah's secular government.\n\nAfter the abortive Utah War of 1857–1858, the replacement of Young by an outside Federal Territorial Governor, intense federal prosecution of LDS Church leaders, and the eventual resolution of controversies regarding plural marriage, and accession by Utah to statehood, the apparent temporal aspects of LDS theodemocracy receded markedly.\n\nDuring the Achaemenid Empire, Zoroastrianism was the state religion and included formalized worship. The Persian kings were known to be pious Zoroastrians and also ruled with a Zoroastrian form of law called \"asha\". However, Cyrus the Great, who founded the empire, avoided imposing the Zoroastrian faith on the inhabitants of conquered territory. Cyrus's kindness towards Jews has been cited as sparking Zoroastrian influence on Judaism.\n\nUnder the Seleucids, Zoroastrianism became autonomous. During the Sassanid period, the Zoroastrian calendar was reformed, image-use was banned, Fire Temples were increasingly built and intolerance towards other faiths prevailed.\n\nThe short reign (1494–1498) of Girolamo Savonarola, a Dominican priest, over the city of Florence had features of a theocracy. During his rule, \"un-Christian\" books, statues, poetry, and other items were burned (in the Bonfire of the Vanities), sodomy was made a capital offense, and other Christian practices became law.\n\n\n"}
{"id": "702398", "url": "https://en.wikipedia.org/wiki?curid=702398", "title": "Trademark dilution", "text": "Trademark dilution\n\nTrademark dilution is a trademark law concept giving the owner of a famous trademark standing to forbid others from using that mark in a way that would lessen its uniqueness. In most cases, trademark dilution involves an unauthorized use of another's trademark on products that do not compete with, and have little connection with, those of the trademark owner. For example, a famous trademark used by one company to refer to hair care products might be \"diluted\" if another company began using a similar mark to refer to breakfast cereals or spark plugs. Dilution is a basis of trademark infringement that applies only to famous marks. With non-famous marks, the owner of the mark must show that the allegedly infringing use creates a likelihood of confusion as to the source of the product or service being identified by the allegedly infringing use. With non-famous marks, it is highly unlikely a likelihood of confusion will be found if the products or services are in unrelated markets. However, with famous marks, any use by another person of the mark has the potential for confusion, since a famous mark is so well known among the consuming public that people will assume affiliation with the owner of the mark regardless of the product or service being sold under the infringing use.\n\nTrademark law traditionally concerned itself with situations where an unauthorized party sold goods that are directly competitive with or at least related to those sold by the trademark owner. A trademark is diluted when the use of similar or identical trademarks in other non-competing markets means that the trademark in and of itself will lose its capacity to signify a single source. In other words, unlike ordinary trademark law, dilution protection extends to trademark uses that do not confuse consumers regarding who has made a product. Instead, dilution protection law aims to protect sufficiently strong trademarks from losing their singular association in the public mind with a particular product, perhaps imagined if the trademark were to be encountered independently of any product (e.g., just the word Pepsi spoken, or on a billboard).\n\nThe strength required for a trademark to deserve dilution protection differs among jurisdictions, though it generally includes the requirement that it must be distinctive, famous, or even unique. Such trademarks would include instantly recognizable brand names, such as Coca-Cola, Kleenex, Kool-Aid, or Sony, and unique terms that were invented (such as Exxon) rather than surnames (such as Ford or Zamboni) or ordinary words in language. Some jurisdictions require additional registration of these trademarks as defensive marks in order to qualify for dilution protection.\n\nAnother way of describing the necessary strength of a trademark may establish some basis for dilution protection from a consumer-confusion standpoint. Truly famous trademarks are likely to be seen in many different contexts due to branching out or simple sponsorship, to the extent that there may be very few markets, if any, that a consumer would be surprised to see that famous trademark involved in. A prime example may be the past involvement of Coca-Cola in clothing lines.\n\nDilution is sometimes divided into two related concepts: blurring, or essentially basic dilution, which \"blurs\" a mark from association with only one product to signify other products in other markets (such as \"Kodak shoes\"); and tarnishment, which is the weakening of a mark through unsavory or unflattering associations. Not all dilution protection laws recognize tarnishment as an included concept.\n\nIn Canada, the legal basis can be found in s. 22 of the \"Trade-marks Act\":\nIt is commonly acknowledged that goodwill is constituted by the reputation of a trade mark and its persuasive effect.\n\nIn the \"Clairol\" case, the court stated that goodwill can be depreciated through \"reduction of the esteem in which the mark itself is held or through the direct persuasion and enticing of customers who could otherwise be expected to buy or continue to buy goods bearing the trade mark\". The court added that the test of confusion is irrelevant here and that the \"test is the likelihood of depreciating the value of the goodwill attaching to the trade mark\" and that this result could be obtained without actual deception/confusion.\n\nS. 22 thus steps where confusion fails to tread. Even if there is no actual risk that the consumer might be confused between the two products, the trade mark owner will still be able to prevent another person from using his/her trade mark if that use is likely to depreciate the value of the trade mark.\n\nIn the \"Veuve Clicquot\" case, the trade mark of the famous French champagne was used by a small chain of women's clothing store that was trading in eastern Quebec and Ottawa. According to the court, s. 22 applies even where a defendant's wares or services do not compete with the plaintiff's and their mark are not identical. The marks were not identical (\"Cliquot\" and \"Veuve clicquot\") and the risk of confusing the champagne brand and a clothing store was low. However the court ruled that the only element needed was the ability of an average consumer to recognize the first distinctive character. Even if the trade mark is not that well known, the fact that a significant goodwill is attached to it might be enough for the court to find the use by another person unlawful. However, in that particular case, the court claimed that the plaintiff Veuve Clicquot failed to prove that the linkage between Champagne and clothing was likely to cause depreciation.\n\nIn the \"Perrier\" case, the plaintiff, a French company, was the bottler and distributor of spring water. It sought an injunction to restrain another company base in Ontario from advertising and distributing bottled water in association with the name \"Pierre eh!\" claiming that the value of the goodwill attached to the French trade mark would likely be depreciated. The plaintiff succeeded on section 22 to stop the use of \"Pierre Eh!\" on bottled water.\n\nThe plaintiff has to prove the elements of section 22, particularly that the use would likely depreciate the value of the goodwill of the claimant's mark. A precision has been made by Vaver, that the fact \"that the use could well cause depreciation is not enough. The use must actually have caused depreciation\".\n\nThe use of Section 22 was restricted in the Clairol case to the use \"in the technical trade-mark sense\". For example, unions are allowed to use the trade mark to caricature because caricature or criticism is not a trade mark infringement, nor event a use of the trade mark, if it occurs outside \"the normal course of trade\". (see also The Michelin v CAW case. In that case, the court rejected the trade mark infringement argument because no one was planning on using the trade mark to sell a product).\n\nPrior to specifically targeted laws being adopted, dilution protection was used in some U.S. jurisdictions to attack domain name infringement of trademarks (see Cybersquatting). For example, in the 1998 case of \"Panavision International v. Toeppen\", defendant Dennis Toeppen registered the domain name www.panavision.com, and posted aerial views of the city of Pana, Illinois on the site. The Ninth Circuit Court of Appeals found that trademark dilution occurred when potential customers of Panavision could not find its web site at panavision.com, and instead were forced to search through other (less obvious) domain names. The fact that potential customers might be discouraged from locating Panavision's legitimate website, coupled with evidence that Toeppen was in the business of registering domain names for profit, led the court to find that Toeppen's conduct \"diminished the capacity of the Panavision marks to identify and distinguish Panavision's goods and services on the Internet\", and thus constituted dilution.\n\nLately, the Trademark Dilution Revision Act of 2006 (H.R. 683), was signed into law, which overturned \"Moseley v. V Secret Catalogue, Inc.\", . \"Moseley\" held the plaintiff needed to prove \"actual\" dilution under the Federal Trademark Dilution Act (\"FTDA\"). The new law revises the FTDA, requiring the plaintiff to show only that the defendant's mark is \"likely\" to cause dilution. However, the revision also reduced the universe of marks falling under its protection, requiring that marks be nationally well known to qualify for protection from dilution.\n\nFor example, when Wolfe's Borough Coffee, Inc., a New Hampshire-based coffee company, sold its coffee under the trademarks that included the words \"Charbucks Blend\" and \"Mr. Charbucks,\" Starbucks Corporation sued, claiming that the use of the word \"Charbucks\" diluted the \"Starbucks\" mark by both blurring and tarnishment. The Second Circuit Court of Appeals decided that marks need not be \"substantially similar\" under the FTDA for dilution to occur when other factors supporting a finding of dilution, such as the distinctiveness of the famous mark and the degree of its recognition, were present. In its decision, the court found that these other factors may be sufficient to support a dilution claim and remanded the case to the district court in order to determine whether dilution had in fact occurred. The district court ruled that sales of Charbucks did not violate the trademark and could continue.\n\n\n\n"}
{"id": "32237", "url": "https://en.wikipedia.org/wiki?curid=32237", "title": "UMTS", "text": "UMTS\n\nThe Universal Mobile Telecommunications System (UMTS) is a third generation mobile cellular system for networks based on the GSM standard. Developed and maintained by the 3GPP (3rd Generation Partnership Project), UMTS is a component of the International Telecommunications Union IMT-2000 standard set and compares with the CDMA2000 standard set for networks based on the competing cdmaOne technology. UMTS uses wideband code division multiple access (W-CDMA) radio access technology to offer greater spectral efficiency and bandwidth to mobile network operators.\n\nUMTS specifies a complete network system, which includes the radio access network (UMTS Terrestrial Radio Access Network, or UTRAN), the core network (Mobile Application Part, or MAP) and the authentication of users via SIM (subscriber identity module) cards.\n\nThe technology described in UMTS is sometimes also referred to as Freedom of Mobile Multimedia Access (FOMA) or 3GSM.\n\nUnlike EDGE (IMT Single-Carrier, based on GSM) and CDMA2000 (IMT Multi-Carrier), UMTS requires new base stations and new frequency allocations.\n\nUMTS supports maximum theoretical data transfer rates of 42 Mbit/s when Evolved HSPA (HSPA+) is implemented in the network. Users in deployed networks can expect a transfer rate of up to 384 kbit/s for Release '99 (R99) handsets (the original UMTS release), and 7.2 Mbit/s for High-Speed Downlink Packet Access (HSDPA) handsets in the downlink connection. These speeds are significantly faster than the 9.6 kbit/s of a single GSM error-corrected circuit switched data channel, multiple 9.6 kbit/s channels in High-Speed Circuit-Switched Data (HSCSD) and 14.4 kbit/s for CDMAOne channels.\n\nSince 2006, UMTS networks in many countries have been or are in the process of being upgraded with High-Speed Downlink Packet Access (HSDPA), sometimes known as 3.5G. Currently, HSDPA enables downlink transfer speeds of up to 21 Mbit/s. Work is also progressing on improving the uplink transfer speed with the High-Speed Uplink Packet Access (HSUPA). Longer term, the 3GPP Long Term Evolution (LTE) project plans to move UMTS to 4G speeds of 100 Mbit/s down and 50 Mbit/s up, using a next generation air interface technology based upon orthogonal frequency-division multiplexing.\n\nThe first national consumer UMTS networks launched in 2002 with a heavy emphasis on telco-provided mobile applications such as mobile TV and video calling. The high data speeds of UMTS are now most often utilised for Internet access: experience in Japan and elsewhere has shown that user demand for video calls is not high, and telco-provided audio/video content has declined in popularity in favour of high-speed access to the World Wide Web—either directly on a handset or connected to a computer via Wi-Fi, Bluetooth or USB.\n\nUMTS combines three different terrestrial air interfaces, GSM's Mobile Application Part (MAP) core, and the GSM family of speech codecs.\n\nThe air interfaces are called UMTS Terrestrial Radio Access (UTRA). All air interface options are part of ITU's IMT-2000. In the currently most popular variant for cellular mobile telephones, W-CDMA (IMT Direct Spread) is used.\n\nPlease note that the terms W-CDMA, TD-CDMA and TD-SCDMA are misleading. While they suggest covering just a channel access method (namely a variant of CDMA), they are actually the common names for the whole air interface standards.\n\nW-CDMA or WCDMA (Wideband Code Division Multiple Access), along with UMTS-FDD, UTRA-FDD, or IMT-2000 CDMA Direct Spread is an air interface standard found in 3G mobile telecommunications networks. It supports conventional cellular voice, text and MMS services, but can also carry data at high speeds, allowing mobile operators to deliver higher bandwidth applications including streaming and broadband Internet access.\n\nW-CDMA uses the DS-CDMA channel access method with a pair of 5 MHz wide channels. In contrast, the competing CDMA2000 system uses one or more available 1.25 MHz channels for each direction of communication. W-CDMA systems are widely criticized for their large spectrum usage, which delayed deployment in countries that acted relatively slowly in allocating new frequencies specifically for 3G services (such as the United States).\n\nThe specific frequency bands originally defined by the UMTS standard are 1885–2025 MHz for the mobile-to-base (uplink) and 2110–2200 MHz for the base-to-mobile (downlink). In the US, 1710–1755 MHz and 2110–2155 MHz are used instead, as the 1900 MHz band was already used. While UMTS2100 is the most widely deployed UMTS band, some countries' UMTS operators use the 850 MHz and/or 1900 MHz bands (independently, meaning uplink and downlink are within the same band), notably in the US by AT&T Mobility, New Zealand by Telecom New Zealand on the XT Mobile Network and in Australia by Telstra on the Next G network. Some carriers such as T-Mobile use band numbers to identify the UMTS frequencies. For example, Band I (2100 MHz), Band IV (1700/2100 MHz), and Band V (850 MHz).\n\nUMTS-FDD is an acronym for Universal Mobile Telecommunications System (UMTS) - frequency-division duplexing (FDD) and a 3GPP standardized version of UMTS networks that makes use of frequency-division duplexing for duplexing over an UMTS Terrestrial Radio Access (UTRA) air interface.\n\nW-CDMA is the basis of Japan's NTT DoCoMo's FOMA service and the most-commonly used member of the Universal Mobile Telecommunications System (UMTS) family and sometimes used as a synonym for UMTS. It uses the DS-CDMA channel access method and the FDD duplexing method to achieve higher speeds and support more users compared to most previously used time division multiple access (TDMA) and time division duplex (TDD) schemes.\n\nWhile not an evolutionary upgrade on the airside, it uses the same core network as the 2G GSM networks deployed worldwide, allowing dual mode mobile operation along with GSM/EDGE; a feature it shares with other members of the UMTS family.\n\nIn the late 1990s, W-CDMA was developed by NTT DoCoMo as the air interface for their 3G network FOMA. Later NTT DoCoMo submitted the specification to the International Telecommunication Union (ITU) as a candidate for the international 3G standard known as IMT-2000. The ITU eventually accepted W-CDMA as part of the IMT-2000 family of 3G standards, as an alternative to CDMA2000, EDGE, and the short range DECT system. Later, W-CDMA was selected as an air interface for UMTS.\n\nAs NTT DoCoMo did not wait for the finalisation of the 3G Release 99 specification, their network was initially incompatible with UMTS. However, this has been resolved by NTT DoCoMo updating their network.\n\nCode Division Multiple Access communication networks have been developed by a number of companies over the years, but development of cell-phone networks based on CDMA (prior to W-CDMA) was dominated by Qualcomm, the first company to succeed in developing a practical and cost-effective CDMA implementation for consumer cell phones and its early IS-95 air interface standard has evolved into the current CDMA2000 (IS-856/IS-2000) standard. Qualcomm created an experimental wideband CDMA system called CDMA2000 3x which unified the W-CDMA (3GPP) and CDMA2000 (3GPP2) network technologies into a single design for a worldwide standard air interface. Compatibility with CDMA2000 would have beneficially enabled roaming on existing networks beyond Japan, since Qualcomm CDMA2000 networks are widely deployed, especially in the Americas, with coverage in 58 countries . However, divergent requirements resulted in the W-CDMA standard being retained and deployed globally. W-CDMA has then become the dominant technology with 457 commercial networks in 178 countries as of April 2012. Several CDMA2000 operators have even converted their networks to W-CDMA for international roaming compatibility and smooth upgrade path to LTE.\n\nDespite incompatibility with existing air-interface standards, late introduction and the high upgrade cost of deploying an all-new transmitter technology, W-CDMA has become the dominant standard.\n\nW-CDMA transmits on a pair of 5 MHz-wide radio channels, while CDMA2000 transmits on one or several pairs of 1.25 MHz radio channels. Though W-CDMA does use a direct sequence CDMA transmission technique like CDMA2000, W-CDMA is not simply a wideband version of CDMA2000. The W-CDMA system is a new design by NTT DoCoMo, and it differs in many aspects from CDMA2000. From an engineering point of view, W-CDMA provides a different balance of trade-offs between cost, capacity, performance, and density; it also promises to achieve a benefit of reduced cost for video phone handsets. W-CDMA may also be better suited for deployment in the very dense cities of Europe and Asia. However, hurdles remain, and cross-licensing of patents between Qualcomm and W-CDMA vendors has not eliminated possible patent issues due to the features of W-CDMA which remain covered by Qualcomm patents.\n\nW-CDMA has been developed into a complete set of specifications, a detailed protocol that defines how a mobile phone communicates with the tower, how signals are modulated, how datagrams are structured, and system interfaces are specified allowing free competition on technology elements.\n\nThe world's first commercial W-CDMA service, FOMA, was launched by NTT DoCoMo in Japan in 2001.\n\nElsewhere, W-CDMA deployments are usually marketed under the UMTS brand.\n\nW-CDMA has also been adapted for use in satellite communications on the U.S. Mobile User Objective System using geosynchronous satellites in place of cell towers.\n\nJ-Phone Japan (once Vodafone and now SoftBank Mobile) soon followed by launching their own W-CDMA based service, originally branded \"Vodafone Global Standard\" and claiming UMTS compatibility. The name of the service was changed to \"Vodafone 3G\" (now \"SoftBank 3G\") in December 2004.\n\nBeginning in 2003, Hutchison Whampoa gradually launched their upstart UMTS networks.\nMost countries have, since the ITU approved of the 3G mobile service, either \"auctioned\" the radio frequencies to the company willing to pay the most, or conducted a \"beauty contest\"—asking the various companies to present what they intend to commit to if awarded the licences. This strategy has been criticised for aiming to drain the cash of operators to the brink of bankruptcy in order to honour their bids or proposals. Most of them have a time constraint for the rollout of the service—where a certain \"coverage\" must be achieved within a given date or the licence will be revoked.\n\nVodafone launched several UMTS networks in Europe in February 2004. MobileOne of Singapore commercially launched its 3G (W-CDMA) services in February 2005. New Zealand in August 2005 and Australia in October 2005.\n\nAT&T Wireless (now a part of Cingular Wireless) has deployed UMTS in several cities. Though advancements in its network deployment have been delayed due to the merger with Cingular, Cingular began offering HSDPA service in December 2005.\n\nRogers in Canada March 2007 has launched HSDPA in the Toronto Golden Horseshoe district on W-CDMA at 850/1900 MHz and plan the launch the service commercial in the top 25 cities October, 2007.\n\nTeliaSonera opened W-CDMA service in Finland October 13, 2004 with speeds up to 384 kbit/s. Availability only in main cities. Pricing is approx. €2/MB. \n\nSK Telecom and KTF, two largest mobile phone service providers in South Korea, have each started offering W-CDMA service in December 2003. Due to poor coverage and lack of choice in handhelds, the W-CDMA service has barely made a dent in the Korean market which was dominated by CDMA2000. By October 2006 both companies are covering more than 90 cities while SK Telecom has announced that it will provide nationwide coverage for its WCDMA network in order for it to offer SBSM (Single Band Single Mode) handsets by the first half of 2007. KT Freecel will thus cut funding to its CDMA2000 network development to the minimum.\n\nIn Norway, Telenor introduced W-CDMA in major cities by the end of 2004, while their competitor, NetCom, followed suit a few months later. Both operators have 98% national coverage on EDGE, but Telenor has parallel WLAN roaming networks on GSM, where the UMTS service is competing with this. For this reason Telenor is dropping support of their WLAN service in Austria (2006).\n\nMaxis Communications and Celcom, two mobile phone service providers in Malaysia, started offering W-CDMA services in 2005.\n\nIn Sweden, Telia introduced W-CDMA March 2004.\n\nUMTS-TDD, an acronym for Universal Mobile Telecommunications System (UMTS) - time-division duplexing (TDD), is a 3GPP standardized version of UMTS networks that use UTRA-TDD. UTRA-TDD is a UTRA that uses time-division duplexing for duplexing. While a full implementation of UMTS, it is mainly used to provide Internet access in circumstances similar to those where WiMAX might be used. UMTS-TDD is not directly compatible with UMTS-FDD: a device designed to use one standard cannot, unless specifically designed to, work on the other, because of the difference in air interface technologies and frequencies used. It is more formally as IMT-2000 CDMA-TDD or IMT 2000 Time-Division (IMT-TD).\n\nThe two UMTS air interfaces (UTRAs) for UMTS-TDD are TD-CDMA and TD-SCDMA. Both air interfaces use a combination of two channel access methods, code division multiple access (CDMA) and time division multiple access (TDMA): the frequency band is divided into time slots (TDMA), which are further divided into channels using CDMA spreading codes. These air interfaces are classified as TDD, because time slots can be allocated to either uplink or downlink traffic.\n\nTD-CDMA, an acronym for Time-division-Code division multiple access, is a channel access method based on using spread spectrum multiple access (CDMA) across multiple time slots (TDMA). TD-CDMA is the channel access method for UTRA-TDD HCR, which is an acronym for UMTS Terrestrial Radio Access-Time Division Duplex High Chip Rate.\n\nUMTS-TDD's air interfaces that use the TD-CDMA channel access technique are standardized as UTRA-TDD HCR, which uses increments of 5 MHz of spectrum, each slice divided into 10 ms frames containing fifteen time slots (1500 per second). The time slots (TS) are allocated in fixed percentage for downlink and uplink. TD-CDMA is used to multiplex streams from or to multiple transceivers. Unlike W-CDMA, it does not need separate frequency bands for up- and downstream, allowing deployment in tight frequency bands.\n\nTD-CDMA is a part of IMT-2000, defined as IMT-TD Time-Division (IMT CDMA TDD), and is one of the three UMTS air interfaces (UTRAs), as standardized by the 3GPP in UTRA-TDD HCR. UTRA-TDD HCR is closely related to W-CDMA, and provides the same types of channels where possible. UMTS's HSDPA/HSUPA enhancements are also implemented under TD-CDMA.\n\nIn the United States, the technology have been used for public safety and government use in the New York City and a few other area. In Japan, IPMobile planned to provide TD-CDMA service in year 2006, but it was delayed, changed to TD-SCDMA, and bankrupt before the service officially started.\n\nTime Division Synchronous Code Division Multiple Access (TD-SCDMA) or UTRA TDD 1.28 mcps low chip rate (UTRA-TDD LCR) is an air interface found in UMTS mobile telecommunications networks in China as an alternative to W-CDMA.\n\nTD-SCDMA uses the TDMA channel access method combined with an adaptive synchronous CDMA component on 1.6 MHz slices of spectrum, allowing deployment in even tighter frequency bands than TD-CDMA. It is standardized by the 3GPP and also referred to as \"UTRA-TDD LCR\". However, the main incentive for development of this Chinese-developed standard was avoiding or reducing the license fees that have to be paid to non-Chinese patent owners. Unlike the other air interfaces, TD-SCDMA was not part of UMTS from the beginning but has been added in Release 4 of the specification.\n\nLike TD-CDMA, TD-SCDMA is known as IMT CDMA TDD within IMT-2000.\n\nThe term \"TD-SCDMA\" is misleading. While it suggests covering only a channel access method, it is actually the common name for the whole air interface specification.\n\nTD-SCDMA / UMTS-TDD (LCR) networks are incompatible with W-CDMA / UMTS-FDD and TD-CDMA / UMTS-TDD (HCR) networks.\n\nTD-SCDMA was developed in the People's Republic of China by the Chinese Academy of Telecommunications Technology (CATT), Datang Telecom, and Siemens AG in an attempt to avoid dependence on Western technology. This is likely primarily for practical reasons, since other 3G formats require the payment of patent fees to a large number of Western patent holders.\n\nTD-SCDMA proponents also claim it is better suited for densely populated areas. Further, it is supposed to cover all usage scenarios, whereas W-CDMA is optimised for symmetric traffic and macro cells, while TD-CDMA is best used in low mobility scenarios within micro or pico cells.\nTD-SCDMA is based on spread spectrum technology which makes it unlikely that it will be able to completely escape the payment of license fees to western patent holders. The launch of a national TD-SCDMA network was initially projected by 2005 but only reached large scale commercial trials with 60,000 users across eight cities in 2008.\n\nOn January 7, 2009, China granted a TD-SCDMA 3G licence to China Mobile.\n\nOn September 21, 2009, China Mobile officially announced that it had 1,327,000 TD-SCDMA subscribers as of the end of August, 2009.\n\nWhile TD is primarily a China-only system, it may well be exported to developing countries. It is likely to be replaced with a newer TD-LTE system over the next 5 years.\n\nTD-SCDMA uses TDD, in contrast to the FDD scheme used by W-CDMA. By dynamically adjusting the number of timeslots used for downlink and uplink, the system can more easily accommodate asymmetric traffic with different data rate requirements on downlink and uplink than FDD schemes. Since it does not require paired spectrum for downlink and uplink, spectrum allocation flexibility is also increased. Using the same carrier frequency for uplink and downlink also means that the channel condition is the same on both directions, and the base station can deduce the downlink channel information from uplink channel estimates, which is helpful to the application of beamforming techniques.\n\nTD-SCDMA also uses TDMA in addition to the CDMA used in WCDMA. This reduces the number of users in each timeslot, which reduces the implementation complexity of multiuser detection and beamforming schemes, but the non-continuous transmission also reduces coverage (because of the higher peak power needed), mobility (because of lower power control frequency) and complicates radio resource management algorithms.\n\nThe \"S\" in TD-SCDMA stands for \"synchronous\", which means that uplink signals are synchronized at the base station receiver, achieved by continuous timing adjustments. This reduces the interference between users of the same timeslot using different codes by improving the orthogonality between the codes, therefore increasing system capacity, at the cost of some hardware complexity in achieving uplink synchronization.\n\nOn January 20, 2006, Ministry of Information Industry of the People's Republic of China formally announced that TD-SCDMA is the country's standard of 3G mobile telecommunication. On February 15, 2006, a timeline for deployment of the network in China was announced, stating pre-commercial trials would take place starting after completion of a number of test networks in select cities. These trials ran from March to October, 2006, but the results were apparently unsatisfactory. In early 2007, the Chinese government instructed the dominant cellular carrier, China Mobile, to build commercial trial networks in eight cities, and the two fixed-line carriers, China Telecom and China Netcom, to build one each in two other cities. Construction of these trial networks was scheduled to finish during the fourth quarter of 2007, but delays meant that construction was not complete until early 2008.\n\nThe standard has been adopted by 3GPP since Rel-4, known as \"UTRA TDD 1.28Mbps Option\".\n\nOn March 28, 2008, China Mobile Group announced TD-SCDMA \"commercial trials\" for 60,000 test users in eight cities from April 1, 2008. Networks using other 3G standards (WCDMA and CDMA2000 EV/DO) had still not been launched in China, as these were delayed until TD-SCDMA was ready for commercial launch.\n\nIn January 2009 the Ministry of Industry and Information Technology (MIIT) in China took the unusual step of assigning licences for 3 different third-generation mobile phone standards to three carriers in a long-awaited step that is expected to prompt $41 billion in spending on new equipment. The Chinese-developed standard, TD-SCDMA, was assigned to China Mobile, the world's biggest phone carrier by subscribers. That appeared to be an effort to make sure the new system has the financial and technical backing to succeed. Licences for two existing 3G standards, W-CDMA and CDMA2000 1xEV-DO, were assigned to China Unicom and China Telecom, respectively. Third-generation, or 3G, technology supports Web surfing, wireless video and other services and the start of service is expected to spur new revenue growth.\n\nThe following is a list of mobile telecommunications networks using third-generation TD-SCDMA / UMTS-TDD (LCR) technology.\n\nIn Europe, CEPT allocated the 2010-2020 MHz range for a variant of UMTS-TDD designed for unlicensed, self-provided use. Some telecom groups and jurisdictions have proposed withdrawing this service in favour of licensed UMTS-TDD, due to lack of demand, and lack of development of a UMTS TDD air interface technology suitable for deployment in this band.\n\nOrdinary UMTS uses UTRA-FDD as an air interface and is known as UMTS-FDD. UMTS-FDD uses W-CDMA for multiple access and frequency division for duplexing, meaning that the up-link and down-link transmit on different frequencies. UMTS is usually transmitted on frequencies assigned for 1G, 2G, or 3G mobile telephone service in the countries of operation.\n\nUMTS-TDD uses time division duplexing, allowing the up-link and down-link to share the same spectrum. This allows the operator to more flexibly divide the usage of available spectrum according to traffic patterns. For ordinary phone service, you would expect the up-link and down-link to carry approximately equal amounts of data (because every phone call needs a voice transmission in either direction), but Internet-oriented traffic is more frequently one-way. For example, when browsing a website, the user will send commands, which are short, to the server, but the server will send whole files, that are generally larger than those commands, in response.\n\nUMTS-TDD tends to be allocated frequency intended for mobile/wireless Internet services rather than used on existing cellular frequencies. This is, in part, because TDD duplexing is not normally allowed on cellular, PCS/PCN, and 3G frequencies. TDD technologies open up the usage of left-over unpaired spectrum.\n\nEurope-wide, several bands are provided either specifically for UMTS-TDD or for similar technologies. These are 1900 MHz and 1920 MHz and between 2010 MHz and 2025 MHz. In several countries the 2500-2690 MHz band (also known as MMDS in the USA) have been used for UMTS-TDD deployments. Additionally, spectrum around the 3.5 GHz range has been allocated in some countries, notably Britain, in a technology-neutral environment. In the Czech Republic UTMS-TDD is also used in a frequency range around 872 MHz.\n\nUMTS-TDD has been deployed for public and/or private networks in at least nineteen countries around the world, with live systems in, amongst other countries, Australia, Czech Republic, France, Germany, Japan, New Zealand, Botswana, South Africa, the UK, and the USA.\n\nDeployments in the US thus far have been limited. It has been selected for a public safety support network used by emergency responders in New York, but outside of some experimental systems, notably one from Nextel, thus far the WiMAX standard appears to have gained greater traction as a general mobile Internet access system.\n\nA variety of Internet-access systems exist which provide broadband speed access to the net. These include WiMAX and HIPERMAN. UMTS-TDD has the advantages of being able to use an operator's existing UMTS/GSM infrastructure, should it have one, and that it includes UMTS modes optimized for circuit switching should, for example, the operator want to offer telephone service. UMTS-TDD's performance is also more consistent. However, UMTS-TDD deployers often have regulatory problems with taking advantage of some of the services UMTS compatibility provides. For example, UMTS-TDD spectrum in the UK cannot be used to provide telephone service, though the regulator OFCOM is discussing the possibility of allowing it at some point in the future. Few operators considering UMTS-TDD have existing UMTS/GSM infrastructure.\n\nAdditionally, the WiMAX and HIPERMAN systems provide significantly larger bandwidths when the mobile station is in close proximity to the tower.\n\nLike most mobile Internet access systems, many users who might otherwise choose UMTS-TDD will find their needs covered by the ad hoc collection of unconnected Wifi access points at many restaurants and transportation hubs, and/or by Internet access already provided by their mobile phone operator. By comparison, UMTS-TDD (and systems like WiMAX) offers mobile, and more consistent, access than the former, and generally faster access than the latter.\n\nUMTS also specifies the Universal Terrestrial Radio Access Network (UTRAN), which is composed of multiple base stations, possibly using different terrestrial air interface standards and frequency bands.\n\nUMTS and GSM/EDGE can share a Core Network (CN), making UTRAN an alternative radio access network to GERAN (GSM/EDGE RAN), and allowing (mostly) transparent switching between the RANs according to available coverage and service needs. Because of that, UMTS's and GSM/EDGE's radio access networks are sometimes collectively referred to as UTRAN/GERAN.\nUMTS networks are often combined with GSM/EDGE, the latter of which is also a part of IMT-2000.\n\nThe UE (User Equipment) interface of the RAN (Radio Access Network) primarily consists of RRC (Radio Resource Control), PDCP (Packet Data Convergence Protocol), RLC (Radio Link Control) and MAC (Media Access Control) protocols. RRC protocol handles connection establishment, measurements, radio bearer services, security and handover decisions. RLC protocol primarily divides into three Modes—Transparent Mode (TM), Unacknowledge Mode (UM), Acknowledge Mode (AM). The functionality of AM entity resembles TCP operation whereas UM operation resembles UDP operation. In TM mode, data will be sent to lower layers without adding any header to SDU of higher layers. MAC handles the scheduling of data on air interface depending on higher layer (RRC) configured parameters.\n\nThe set of properties related to data transmission is called Radio Bearer (RB). This set of properties decides the maximum allowed data in a TTI (Transmission Time Interval). RB includes RLC information and RB mapping. RB mapping decides the mapping between RB<->logical channel<->transport channel. Signaling messages are sent on Signaling Radio Bearers (SRBs) and data packets (either CS or PS) are sent on data RBs. RRC and NAS messages go on SRBs.\n\nSecurity includes two procedures: integrity and ciphering. Integrity validates the resource of messages and also makes sure that no one (third/unknown party) on the radio interface has modified the messages. Ciphering ensures that no one listens to your data on the air interface. Both integrity and ciphering are applied for SRBs whereas only ciphering is applied for data RBs.\n\nWith Mobile Application Part, UMTS uses the same core network standard as GSM/EDGE. This allows a simple migration for existing GSM operators. However, the migration path to UMTS is still costly: while much of the core infrastructure is shared with GSM, the cost of obtaining new spectrum licenses and overlaying UMTS at existing towers is high.\n\nThe CN can be connected to various backbone networks, such as the Internet or an Integrated Services Digital Network (ISDN) telephone network. UMTS (and GERAN) include the three lowest layers of OSI model. The network layer (OSI 3) includes the Radio Resource Management protocol (RRM) that manages the bearer channels between the mobile terminals and the fixed network, including the handovers.\n\nA UARFCN (abbreviation for UTRA Absolute Radio Frequency Channel Number, where UTRA stands for UMTS Terrestrial Radio Access) is used to identify a frequency in the UMTS frequency bands.\n\nTypically channel number is derived from the frequency in MHz through the formula Channel Number = Frequency * 5. However, this is only able to represent channels that are centered on a multiple of 200 kHz, which do not align with licensing in North America. 3GPP added several special values for the common North American channels.\n\nOver 130 licenses have already been awarded to operators worldwide (as of December 2004), specifying W-CDMA radio access technology that builds on GSM. In Europe, the license process occurred at the tail end of the technology bubble, and the auction mechanisms for allocation set up in some countries resulted in some extremely high prices being paid for the original 2100 MHz licenses, notably in the UK and Germany. In Germany, bidders paid a total €50.8 billion for six licenses, two of which were subsequently abandoned and written off by their purchasers (Mobilcom and the Sonera/Telefonica consortium). It has been suggested that these huge license fees have the character of a very large tax paid on future income expected many years down the road. In any event, the high prices paid put some European telecom operators close to bankruptcy (most notably KPN). Over the last few years some operators have written off some or all of the license costs. Between 2007 and 2009, all three Finnish carriers began to use 900 MHz UMTS in a shared arrangement with its surrounding 2G GSM base stations for rural area coverage, a trend that is expected to expand over Europe in the next 1–3 years.\n\nThe 2100 MHz band (downlink around 2100 MHz and uplink around 1900 MHz) allocated for UMTS in Europe and most of Asia is already used in North America. The 1900 MHz range is used for 2G (PCS) services, and 2100 MHz range is used for satellite communications. Regulators have, however, freed up some of the 2100 MHz range for 3G services, together with a different range around 1700 MHz for the uplink.\n\nAT&T Wireless launched UMTS services in the United States by the end of 2004 strictly using the existing 1900 MHz spectrum allocated for 2G PCS services. Cingular acquired AT&T Wireless in 2004 and has since then launched UMTS in select US cities. Cingular renamed itself AT&T Mobility and rolled out some cities with a UMTS network at 850 MHz to enhance its existing UMTS network at 1900 MHz and now offers subscribers a number of dual-band UMTS 850/1900 phones.\n\nT-Mobile's rollout of UMTS in the US was originally focused on the 1700 MHz band. However, T-Mobile has been moving users from 1700 MHz to 1900 MHz (PCS) in order to reallocate the spectrum to 4G LTE services.\n\nIn Canada, UMTS coverage is being provided on the 850 MHz and 1900 MHz bands on the Rogers and Bell-Telus networks. Bell and Telus share the network. Recently, new providers Wind Mobile, Mobilicity and Videotron have begun operations in the 1700 MHz band.\n\nIn 2008, Australian telco Telstra replaced its existing CDMA network with a national UMTS-based 3G network, branded as NextG, operating in the 850 MHz band. Telstra currently provides UMTS service on this network, and also on the 2100 MHz UMTS network, through a co-ownership of the owning and administrating company 3GIS. This company is also co-owned by Hutchison 3G Australia, and this is the primary network used by their customers. Optus is currently rolling out a 3G network operating on the 2100 MHz band in cities and most large towns, and the 900 MHz band in regional areas. Vodafone is also building a 3G network using the 900 MHz band.\n\nIn India, BSNL has started its 3G services since October 2009, beginning with the larger cities and then expanding over to smaller cities. The 850 MHz and 900 MHz bands provide greater coverage compared to equivalent 1700/1900/2100 MHz networks, and are best suited to regional areas where greater distances separate base station and subscriber.\n\nCarriers in South America are now also rolling out 850 MHz networks.\n\nUMTS phones (and data cards) are highly portable—they have been designed to roam easily onto other UMTS networks (if the providers have roaming agreements in place). In addition, almost all UMTS phones are UMTS/GSM dual-mode devices, so if a UMTS phone travels outside of UMTS coverage during a call the call may be transparently handed off to available GSM coverage. Roaming charges are usually significantly higher than regular usage charges.\n\nMost UMTS licensees consider ubiquitous, transparent global roaming an important issue. To enable a high degree of interoperability, UMTS phones usually support several different frequencies in addition to their GSM fallback. Different countries support different UMTS frequency bands – Europe initially used 2100 MHz while the most carriers in the USA use 850 MHz and \n1900 MHz. T-Mobile has launched a network in the US operating at 1700 MHz (uplink) /2100 MHz (downlink), and these bands also have been adopted elsewhere in the US and in Canada and Latin America. A UMTS phone and network must support a common frequency to work together. Because of the frequencies used, early models of UMTS phones designated for the United States will likely not be operable elsewhere and vice versa. There are now 11 different frequency combinations used around the world—including frequencies formerly used solely for 2G services.\n\nUMTS phones can use a Universal Subscriber Identity Module, USIM (based on GSM's SIM) and also work (including UMTS services) with GSM SIM cards. This is a global standard of identification, and enables a network to identify and authenticate the (U)SIM in the phone. Roaming agreements between networks allow for calls to a customer to be redirected to them while roaming and determine the services (and prices) available to the user. In addition to user subscriber information and authentication information, the (U)SIM provides storage space for phone book contact. Handsets can store their data on their own memory or on the (U)SIM card (which is usually more limited in its phone book contact information). A (U)SIM can be moved to another UMTS or GSM phone, and the phone will take on the user details of the (U)SIM, meaning it is the (U)SIM (not the phone) which determines the phone number of the phone and the billing for calls made from the phone.\n\nJapan was the first country to adopt 3G technologies, and since they had not used GSM previously they had no need to build GSM compatibility into their handsets and their 3G handsets were smaller than those available elsewhere. In 2002, NTT DoCoMo's FOMA 3G network was the first commercial UMTS network—using a pre-release specification, it was initially incompatible with the UMTS standard at the radio level but used standard USIM cards, meaning USIM card based roaming was possible (transferring the USIM card into a UMTS or GSM phone when travelling). Both NTT DoCoMo and SoftBank Mobile (which launched 3G in December 2002) now use standard UMTS.\n\nAll of the major 2G phone manufacturers (that are still in business) are now manufacturers of 3G phones. The early 3G handsets and modems were specific to the frequencies required in their country, which meant they could only roam to other countries on the same 3G frequency (though they can fall back to the older GSM standard). Canada and USA have a common share of frequencies, as do most European countries. The article UMTS frequency bands is an overview of UMTS network frequencies around the world.\n\nUsing a cellular router, PCMCIA or USB card, customers are able to access 3G broadband services, regardless of their choice of computer (such as a tablet PC or a PDA). Some software installs itself from the modem, so that in some cases absolutely no knowledge of technology is required to get online in moments. Using a phone that supports 3G and Bluetooth 2.0, multiple Bluetooth-capable laptops can be connected to the Internet. Some smartphones can also act as a mobile WLAN access point.\n\nThere are very few 3G phones or modems available supporting all 3G frequencies (UMTS850/900/1700/1900/2100 MHz). Nokia has recently released a range of phones that have Pentaband 3G coverage, including the N8 and E7. Many other phones are offering more than one band which still enables extensive roaming. For example, Apple's iPhone 4 contains a quadband chipset operating on 850/900/1900/2100 MHz, allowing usage in the majority of countries where UMTS-FDD is deployed.\n\nThe main competitor to UMTS is CDMA2000 (IMT-MC), which is developed by the 3GPP2. Unlike UMTS, CDMA2000 is an evolutionary upgrade to an existing 2G standard, cdmaOne, and is able to operate within the same frequency allocations. This and CDMA2000's narrower bandwidth requirements make it easier to deploy in existing spectra. In some, but not all, cases, existing GSM operators only have enough spectrum to implement either UMTS or GSM, not both. For example, in the US D, E, and F PCS spectrum blocks, the amount of spectrum available is 5 MHz in each direction. A standard UMTS system would saturate that spectrum. Where CDMA2000 is deployed, it usually co-exists with UMTS. In many markets however, the co-existence issue is of little relevance, as legislative hurdles exist to co-deploying two standards in the same licensed slice of spectrum.\n\nAnother competitor to UMTS is EDGE (IMT-SC), which is an evolutionary upgrade to the 2G GSM system, leveraging existing GSM spectrums. It is also much easier, quicker, and considerably cheaper for wireless carriers to \"bolt-on\" EDGE functionality by upgrading their existing GSM transmission hardware to support EDGE rather than having to install almost all brand-new equipment to deliver UMTS. However, being developed by 3GPP just as UMTS, EDGE is not a true competitor. Instead, it is used as a temporary solution preceding UMTS roll-out or as a complement for rural areas. This is facilitated by the fact that GSM/EDGE and UMTS specification are jointly developed and rely on the same core network, allowing dual-mode operation including vertical handovers. \n\nChina's TD-SCDMA standard is often seen as a competitor, too. TD-SCDMA has been added to UMTS' Release 4 as UTRA-TDD 1.28 Mcps Low Chip Rate (UTRA-TDD LCR). Unlike TD-CDMA (UTRA-TDD 3.84 Mcps High Chip Rate, UTRA-TDD HCR) which complements W-CDMA (UTRA-FDD), it is suitable for both micro and macro cells. However, the lack of vendors' support is preventing it from being a real competitor.\n\nWhile DECT is technically capable of competing with UMTS and other cellular networks in densely populated, urban areas, it has only been deployed for domestic cordless phones and private in-house networks.\n\nAll of these competitors have been accepted by ITU as part of the IMT-2000 family of 3G standards, along with UMTS-FDD.\n\nOn the Internet access side, competing systems include WiMAX and Flash-OFDM.\n\nFrom a GSM/GPRS network, the following network elements can be reused:\n\nFrom a GSM/GPRS communication radio network, the following elements cannot be reused:\nThey can remain in the network and be used in dual network operation where 2G and 3G networks co-exist while network migration and new 3G terminals become available for use in the network.\n\nThe UMTS network introduces new network elements that function as specified by 3GPP:\n\nThe functionality of MSC and SGSN changes when going to UMTS. In a GSM system the MSC handles all the circuit switched operations like connecting A- and B-subscriber through the network. SGSN handles all the packet switched operations and transfers all the data in the network. In UMTS the Media gateway (MGW) take care of all data transfer in both circuit and packet switched networks. MSC and SGSN control MGW operations. The nodes are renamed to MSC-server and GSN-server.\n\nSome countries, including the United States, have allocated spectrum differently from the ITU recommendations, so that the standard bands most commonly used for UMTS (UMTS-2100) have not been available. In those countries, alternative bands are used, preventing the interoperability of existing UMTS-2100 equipment, and requiring the design and manufacture of different equipment for the use in these markets. As is the case with GSM900 today, standard UMTS 2100 MHz equipment will not work in those markets. However, it appears as though UMTS is not suffering as much from handset band compatibility issues as GSM did, as many UMTS handsets are multi-band in both UMTS and GSM modes. Penta-band (850, 900, 1700, 2100, and 1900 MHz bands), quad-band GSM (850, 900, 1800, and 1900 MHz bands) and tri-band UMTS (850, 1900, and 2100 MHz bands) handsets are becoming more commonplace.\n\nIn its early days, UMTS had problems in many countries: Overweight handsets with poor battery life were first to arrive on a market highly sensitive to weight and form factor. The Motorola A830, a debut handset on Hutchison's 3 network, weighed more than 200 grams and even featured a detachable camera to reduce handset weight. Another significant issue involved call reliability, related to problems with handover from UMTS to GSM. Customers found their connections being dropped as handovers were possible only in one direction (UMTS → GSM), with the handset only changing back to UMTS after hanging up. In most networks around the world this is no longer an issue.\n\nCompared to GSM, UMTS networks initially required a higher base station density. For fully-fledged UMTS incorporating video on demand features, one base station needed to be set up every 1–1.5 km (0.62–0.93 mi). This was the case when only the 2100 MHz band was being used, however with the growing use of lower-frequency bands (such as 850 and 900 MHz) this is no longer so. This has led to increasing rollout of the lower-band networks by operators since 2006.\n\nEven with current technologies and low-band UMTS, telephony and data over UMTS requires more power than on comparable GSM networks. Apple Inc. cited UMTS power consumption as the reason that the first generation iPhone only supported EDGE. Their release of the iPhone 3G quotes talk time on UMTS as half that available when the handset is set to use GSM. Other manufacturers indicate different battery lifetime for UMTS mode compared to GSM mode as well. As battery and network technology improve, this issue is diminishing.\n\nAs early as 2008 it was known that carrier networks can be used to surreptitiously gather user location information. In August 2014, the Washington Post reported on widespread marketing of surveillance systems using Signalling System No. 7 (SS7) protocols to locate callers anywhere in the world.\n\nIn December 2014, news broke that SS7's very own functions can be repurposed for surveillance, because of its lax security, in order to listen to calls in real time or to record encrypted calls and texts for later decryption, or to defraud users and cellular carriers.\n\nDeutsche Telekom and Vodafone declared the same day that they had fixed gaps in their networks, but that the problem is global and can only be fixed with a telecommunication system-wide solution.\n\nThe evolution of UMTS progresses according to planned releases. Each release is designed to introduce new features and improve upon existing ones.\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "39729265", "url": "https://en.wikipedia.org/wiki?curid=39729265", "title": "United States–Hong Kong Agreement for the Surrender of Fugitive Offenders", "text": "United States–Hong Kong Agreement for the Surrender of Fugitive Offenders\n\nThe United States–Hong Kong Agreement for the Surrender of Fugitive Offenders was an extradition treaty signed by the United States and Hong Kong in 1996.\n"}
{"id": "52834080", "url": "https://en.wikipedia.org/wiki?curid=52834080", "title": "Unsplash", "text": "Unsplash\n\nUnsplash is a website dedicated to sharing stock photography under the Unsplash license. The website claims over 100,000 contributing photographers and generates more than 9 billion photo impressions per month on their growing library of over 690,000 photos. Unsplash has been cited as one of the world's leading photography websites by Forbes, Entrepreneur Magazine, CNET, Medium and The Next Web.\n\nUnsplash allows photographers to upload photos to its website, which are then curated by a team of photo editors. The permissive copyright terms on its photos has led to Unsplash becoming one of the largest photography suppliers on the internet, with its members’ photos frequently appearing on articles.\n\nAs from 18th February 2018 Unsplash changed their license terms to restrict the sale of photos without first updating, modifying, or otherwise incorporating new creative elements into the photos, prohibiting selling unaltered copies, including selling the photos as prints or printed on physical goods.\n\nOne of the pioneers of the copyright-free photography model, Unsplash was created in 2013 by Montreal-based entrepreneur Mikael Cho. While creating a new homepage for his company Crew, Cho was unable to find a suitable stock photo and hired a photographer instead. Afterwards, Cho posted the outtakes from his company photoshoot on Tumblr, inviting people to use them as they saw fit.\n\nBefore June 2017, photos uploaded to Unsplash were made available under the Creative Commons zero license, which is a public domain equivalent license and a waiver, which allowed individuals to freely reuse, repurpose and remix photos for their own projects. This was changed in June 2017, and photos are now made available under the Unsplash license, which imposes some additional restrictions. Unsplash received more than 50,000 visits on its first day.\n\nOn 18th February 2018 Unsplash changed their license terms to restrict the sale of photos without first updating, modifying, or otherwise incorporating new creative elements into the photos, prohibiting selling unaltered copies, including selling the photos as prints or printed on physical goods.\n\nWhile Cho supplied the first batch of Unsplash photos, the site is now sustained by community contributions from amateur and professional photographers. Due to the volume of photo submissions, the site employs an editorial team and “curators” picked from the Unsplash community, including Guy Kawasaki, Nas, Khoi Vinh, Amanda Hesser and Om Malik.\n\nUnsplash photos are covered by the Unsplash license, which is similar to a Creative Commons zero license. The difference between a CC0 license and the Unsplash license is the Unsplash license does not include the right to compile photos from Unsplash to replicate a similar or competing service. Both licenses give viewers the right to \"copy, modify, distribute and use the photos for free, including commercial purposes, without asking permission from or providing attribution to the photographer or Unsplash” but the Unsplash licence, prohibits selling unaltered copies, including selling the photos as prints or printed on physical goods. Until June 2017, Unsplash photos were covered by the Creative Commons zero license itself.\n\nThe lack of attribution for Unsplash photos has been the subject of controversy among photography circles, due to some companies using free Unsplash photography for profit without compensating the photographers. Unsplash itself has stated that it does not support the practice.\n\nIn 2016, Unsplash released the Unsplash Book, the world's “first ever fully crowd-sourced” book. The book's photos, essays, and funding were all contributed by Unsplash's community. The book raised $106,000 on Kickstarter and included contributions from Harvard law professor and CC0 inventor Lawrence Lessig, and designer Tobias van Schneider.\n\nIn addition to its website, Unsplash provides a public Application programming interface (API) that powers more than 140 million photo requests per month. Some of the products relying on the Unsplash API include Unsplash Instant, an extension for Google Chrome that loads Unsplash photos in new tabs, Unsplash for Apple TV, and Pablo by Buffer.\n\nBeyond its website and API, Unsplash hosts photo walks in cities around the world including Tokyo, Montreal, and Boston. The photo walks are hosted by guides from the Unsplash community who show participants the best places to take photos in their city, how to use their cameras, and how to compose better photos.\n"}
{"id": "45538753", "url": "https://en.wikipedia.org/wiki?curid=45538753", "title": "Varatuomari", "text": "Varatuomari\n\nVaratuomari (lit. \"vice-judge\", Swedish: \"vicehäradshövding\") or Master in Law with court training or trained on the bench is a Finnish legal title. The degree consists of a master's degree in law and one year of court training as a Trainee District Judge in a district court, usually done very soon after graduation. The title is granted by the local appeals court, on a recommendation of the chief judge (\"laamanni\"). Thus, it can be considered a specially regulated legal externship. Officially, the degree is no longer a formal requirement to any state office, but it remains a \"de facto\" requirement for applying into the positions of a judge or a prosecutor, and is usually held also by defense attorneys. It is recognized as a relevant master's degree for purposes of police officer promotions.\n"}
