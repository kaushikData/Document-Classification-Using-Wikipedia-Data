{"id": "53251063", "url": "https://en.wikipedia.org/wiki?curid=53251063", "title": "Access to public information in the Republic of Macedonia", "text": "Access to public information in the Republic of Macedonia\n\nAccess to public information and freedom of information (FOI) refer to the right of access to information held by public bodies also known as \"right to know\". Access to public information is considered of fundamental importance for the effective functioning of democratic systems, as it enhances governments' and public officials' accountability, boosting people participation and allowing their informed participation into public life. The fundamental premise of the right of access to public information is that the information held by governmental institutions is in principle public and may be concealed only on the basis of legitimate reasons which should be detailed in the law.\n\nAccess to public information is guaranteed by the Constitution of the Republic of Macedonia (Article 16). To implement this constitutional right, the Parliament of the Republic of Macedonia in January 2006 adopted the Law on Free Access to Public Information defining the procedures for exercising this right. The Law has been significantly amended at the beginning of 2010. According to a research carried out by the Centre for Law and Democracy, Macedonia is in the high 14th place on the world ranking list of states having the most functional law on free access to public information, despite the fact that this right has been introduced into Macedonian legal system in a relatively recent period. However, according to the European Commission, the implementation of the Law on Free Access to Public Information remains ineffective.\n\nThe Law on Free Access to Information stresses the obligation of the institutions to provide information with precise deadlines: it allows individuals and legal entities to exercise their right of access to public information and obliges the holders of information to provide information to the public.\n\nThe public authorities subject to the law are governmental institutions and other bodies and institutions set by law, municipal bodies, public institutions and services, public enterprises and natural persons and legal entities performing a public service. In general, all information available to the public authorities holding the information is public. Access to them may be refused in exceptional cases determined by law.\n\nThe holders of information are obliged to keep records and to update the list of information in their disposal and to publish them in a manner available to the public. Also, they are obliged to provide premises for inspection of the requested information.\n\nAll institutions subject to the law are required to appoint officials for handling access to information requests. They are the reference point for the citizens willing to exercise their right to access public information. The holder of the information is obliged to inform the public on the official person responsible for mediating information. The appointed person for mediating information shall provide the necessary information, help the applicant and keep special records for receipt of the applications for information.\n\nApplicants can submit the requests in writing or orally. Reviewing the documents at the institution's building is free of charge. Costs of photocopying, transcribing, translating or delivering the documents can be charged to the applicant. A decision on the request should be made within 30 days. Access to information can be refused if it threatens national or public security; the economy; the environment; commercial or private legitimate interests; monetary and exchange policies; or if interferes with the prevention of criminal offences.\n\nThe Commission for Protection of the Right to Free Access to Public Information (KOMSPI) is in charge for providing information to the citizens regarding access to information, monitoring the implementation of the law and delivering regular annual reports on the application of the Law to the Parliament. Also, the Commission conducts seminars and trainings aiming at educating public officials in their duties to implement the access to public information law. According to the 2015 European Commission Progress Report 2015 the Commission does not have sufficient capacity to monitor compliance with proactive disclosure of information, and has not the power to impose sanctions to better enforce the legislation.\n\nThe applicant has the right to appeal against a refusal. The first complaint is to the Commission for Protection of the Right to Free Access to Public Information; in case the applicant is not satisfied with the decision, he/she can launch a judicial review.\n\nDespite the good legal framework, the implementation of the Law on Free Access to Public Information remains ineffective. Penalties are not imposed for failure to comply. Political parties are excluded from the list of holders of information, thus they are outside the scope of the law.\n\nAccording to journalists, there is a tendency by public authorities to over-use the \"classification\" of documents to prevent public access to information. According to Freedom House, the law is unevenly and selectively enforced, with official denying responses and shunning independent or critical media outlets.\n\nTo monitor and test the implementation of the law, in 2012 the Macedonian Young Lawyers Association (MYLA) submitted 145 requests for free access to information of public interest to a number of state institutions. More than two thirds of the information holders responded within the legal time limit and delivered the requested information. However, some problems of implementation and difficulties emerged, such as the practice of redirecting the requests towards other state institutions, instead of delivering it.\n\nAccording to a survey conducted in 2013 by the Foundation Open Society - Macedonia, a significant share of Macedonian citizens does not believe they are entitled to have the right of access to public information and request informations of public interest. According to the survey, more than half of citizens had never heard and were unaware of the Law on Free Access to Public Information; only 13% of them were well knowledgeable about the Law.\n\n"}
{"id": "23151158", "url": "https://en.wikipedia.org/wiki?curid=23151158", "title": "Arbitration Committee", "text": "Arbitration Committee\n\nAn Arbitration Committee is a dispute resolution panel of editors, used on several projects of the Wikimedia Foundation. The first project to use an arbitration committee, and the most widely covered of these, is the English Wikipedia, the first project where such a structure was used, and this is the committee mainly covered in this article. Each of Wikimedia's projects are editorially autonomous and independent. Therefore, over time some other Wikimedia projects have established arbitration committees, while others have not. Arbitration committees, where they exist, are established by a project's editors, and are usually elected by their community in annual elections. As well as serious disputes, they often address misconduct by administrators, access to various advanced tools, and a range of \"real world\" issues related to harmful conduct, when these arise in the context of a Wikipedia project.\n\nArbitration committees generally have the authority to impose binding sanctions, and also to determine which users have access to special permissions.\n\nThe first such committee was created by Jimmy Wales on December 4, 2003, as an extension of the decision-making power he formerly held as owner of the site. The committee acts as a court of last resort (described in the media variously as 'quasi-judicial' or a Wikipedian 'High/Supreme Court', though the Committee states that it is not, nor pretends to be, a court of law in the formal sense) for disputes among editors. It has decided several hundred cases in its history. Members of the Committee are appointed by Wales either in person or email following advisory elections; Wales generally chooses to appoint arbitrators who were among those who received the most votes.\n\nThe Committee has been examined by academics researching dispute resolution, and also reported in public media in connection with various case decisions and Wikipedia-related controversies.\n\nIn October 2003, as part of an etiquette discussion on Wikipedia, Alex T. Roshuk, then legal adviser to the Wikimedia Foundation, drafted a 1,300 word outline of mediation and arbitration. This outline evolved into the twin Mediation Committee and Arbitration Committee, formally announced by Jimmy Wales on December 4, 2003. Over time the concept of an \"Arbitration Committee\" was adopted by other communities within the Wikimedia Foundation's hosted projects.\n\nWhen founded, the Committee consisted of 12 arbitrators divided into three groups of four members each. , it had decided around 371 conduct cases, with remedies varying from warnings to bans.\n\nA statistical study published in the \"Emory Law Journal\" in 2010 indicated that the Committee has generally adhered to the principles of ignoring the content of user disputes and focusing on user conduct. The same study also found that despite every case being assessed on its own merits, a correlation emerged between the types of conduct found to have occurred and the remedies and decisions imposed by the Committee.\n\nIn 2007, an arbitrator using the username Essjay resigned from the Committee after it was found that he had made false claims about his academic qualifications and professional experiences in a \"New York Times\" interview. Also in 2007, the committee banned Massachusetts Institute of Technology professor Carl Hewitt from editing the online encyclopedia. In May 2009, an arbitrator who edited under the username Sam Blacketer resigned from the Committee after it became known that he had concealed his past editing in obtaining the role.\n\nIn 2009, the Committee was brought to media attention as a result of its decision to ban \"all IP addresses owned or operated by the Church of Scientology and its associates, broadly interpreted\", as part of the fourth Scientology-related case. Such an action had \"little precedent\" in the eight-year history of Wikipedia and was reported on several major news services such as \"The New York Times\", \"ABC News\", and \"The Guardian\". Satirical news-show host Stephen Colbert ran a segment on \"The Colbert Report\" parodying the ban.\n\nIn 2015, the Committee received attention for its ruling pertaining to Gamergate, in which one editor was banned from the site indefinitely and several others were banned from topics relating to Gamergate or gender.\n\nIn June 2015, the committee removed advanced permissions from Richard Symonds, an activist for the British party the Liberal Democrats. Symonds had improperly blocked a Wikipedia account, and associated its edits with former Chairman of the Conservative Party Grant Shapps, and leaked this to \"The Guardian\". Shapps denied ownership of the account, calling the allegations \"categorically false and defamatory\". Symonds said in an interview that he stands by his actions.\n\nA 2017 study found that the Committee's decision-making was mostly unaffected by extra-legal factors such as nationality, activity/experience, conflict avoidance, and time constraints. The same study found that the Committee's decision-making was affected much more by time constraints than that of conventional courts.\n\nIn 2004 an Arbitration Committee was founded on the French Wikipedia, and in 2007, on the German and Polish Wikipedias.\n"}
{"id": "20573745", "url": "https://en.wikipedia.org/wiki?curid=20573745", "title": "Arizona Bar Exam", "text": "Arizona Bar Exam\n\nThe Arizona Bar Exam is the exam administered by the Admissions Unit of the Certification and Licensing Division of the Supreme Court of Arizona. A satisfactory score on the Arizona Bar Exam is one of numerous requirements for admission to be admitted as an attorney in the State of Arizona.\n\nThe Arizona Bar Exam is a two-day exam. The first day of the exam consists of 6 essay questions testing common law and legal principles generally recognized throughout the United States, and 2 MPT questions testing legal analysis and writing. The second day of the exam consists of the Multistate Bar Exam, a multiple choice examination administered by the National Conference of Bar Examiners (NCBE).\n\nThe essay portion of the Arizona Bar Exam may test the following subjects: \n\nAs of the July, 2012 exam, Arizona is now administering the Uniform Bar Examination (UBE) which does not include:\n\nDay two of the exam consists of the Multistate Bar Exam or MBE. This is the multiple-choice portion of the bar exam. The MBE is a six-hour, exam consisting of two hundred multiple-choice questions covering Contracts and Sales, Torts, Constitutional law, Criminal law, Evidence, and Real Property, Federal civil procedure. The MBE is divided into two period of three hours each, one in the morning and one in the afternoon. There are 100 questions administered in each 3-hour period. There are 34 questions each in Contracts and Torts, and 33 questions each in Constitutional Law, Criminal Law (including aspects of Criminal Procedure), Evidence, and Real Property.\n\nA new scoring system will be effective from July 2012 forward. The Multistate Bar Exam is scaled from 1-200. The highest possible Arizona essay exam score is 120 for the essay portion and 80 for the MPT. Arizona combines the three sections for a total of 400 points. In order to be deemed successful on the Arizona Bar Exam, applicants must achieve a combined score of 273 or higher.\n\nIn addition to successfully passing the Arizona Bar Exam, an applicant must attain a scaled score of 85 on the Multistate Professional Responsibility Exam within two (2) years before the successful bar exam or within the time frame for taking the oath of admission after the successful bar exam (An applicant must pass MPRE prior to being sworn in). The MPRE is administered separately from the Arizona Bar Exam.\n\n\n"}
{"id": "28962490", "url": "https://en.wikipedia.org/wiki?curid=28962490", "title": "Cargo 10", "text": "Cargo 10\n\nCargo 10 (or Cargo X) is a joint railway company set up by the national railway companies of Croatia, Serbia and Slovenia. The name is a reference to the Pan-European Corridor X. Cargo 10 aims to shorten the distance and increase efficiency of rail freight transport along Corridor X, by speeding up border proceedings, and attract traffic from Corridor IV.\n\n"}
{"id": "50229592", "url": "https://en.wikipedia.org/wiki?curid=50229592", "title": "Certificate of appealability", "text": "Certificate of appealability\n\nIn the most common types of habeas corpus proceedings in the United States federal courts, a certificate of appealability is a legal document that must be issued before a petitioner may appeal from a denial of the writ. The certificate may only be issued when the petitioner has made a \"substantial showing of the denial of a constitutional right.\"\n\nThe application may be made explicitly, but a notice of appeal made without a certificate of appealability is treated as an implicit application for the certificate. \"To obtain a [certificate of appealability], the [petitioner] must make a request to a district or circuit court judge. In the application, the [petitioner] includes the issues he wishes to raise on appeal. In general, the application process is informal, there is no hearing, and the government rarely files a brief in response to the prisoner's request. The determination is simply made in chambers. If the district court judge denies the request, the [petitioner] may apply to the circuit judge. In addition, a notice of appeal to the circuit court can be treated as a request for a COA.\"\n\nUnder Rule 22 of the Federal Rules of Appellate Procedure, \"a certificate of appealability is not required when a state or its representative or the United States or its representative appeals.\" A certificate of appealability is also not required for petitioners seeking a writ of coram nobis; however, the writ of coram nobis is only available for those who are no longer in-custody (or on probation) and the issues raised in the petition could not have been known while the petitioner was in-custody.\n\nThe Antiterrorism and Effective Death Penalty Act of 1996 changed the procedures for issuing a certificate of appealability in federal court. Under the 1996 law, \"there can be no appeal from a final order in a §2255 proceeding unless a circuit justice or judge issues a certificate of appealability.\"\n\nThe United States Supreme Court held in \"Slack v. McDaniel\", 529 U.S. 473 (2000), that the standard for issuing a certificate is whether \"reasonable jurists could debate whether (or, for that matter, agree that) the petition should have been resolved in a different manner.\"\n"}
{"id": "2675619", "url": "https://en.wikipedia.org/wiki?curid=2675619", "title": "Colex Enterprises", "text": "Colex Enterprises\n\nColex Enterprises was a joint venture company between Columbia Pictures Television and LBS Communications, Inc., active from January 30, 1984 to January 1, 1988. The name of the joint venture is a portmanteau of the two companies' names (Columbia and Lexington, the latter coming from LBS' original name of Lexington Broadcast Services).\n\nThe company was responsible for distributing the Screen Gems television output, as well as many of the post-1948 Bob Hope theatrical output, with the exception of Hanna-Barbera produced programs. Colex also distributed the syndicated sitcom series \"What's Happening Now!!\", which was later distributed by LBS and Coca-Cola Telecommunications on its final season.\n\n"}
{"id": "485573", "url": "https://en.wikipedia.org/wiki?curid=485573", "title": "Commodity Futures Modernization Act of 2000", "text": "Commodity Futures Modernization Act of 2000\n\nThe Commodity Futures Modernization Act of 2000 (CFMA) is United States federal legislation that officially ensured modernized regulation of financial products known as over-the-counter (OTC) derivatives. It was signed into law on December 21, 2000 by President Bill Clinton. It clarified the law so most OTC derivative transactions between \"sophisticated parties\" would not be regulated as \"futures\" under the Commodity Exchange Act of 1936 (CEA) or as \"securities\" under the federal securities laws. Instead, the major dealers of those products (banks and securities firms) would continue to have their dealings in OTC derivatives supervised by their federal regulators under general \"safety and soundness\" standards. The Commodity Futures Trading Commission's (CFTC) desire to have \"functional regulation\" of the market was also rejected. Instead, the CFTC would continue to do \"entity-based supervision of OTC derivatives dealers.\" These derivatives, including the credit default swap, are a few of the many causes of the financial crisis of 2008 and the subsequent 2008–2012 global recession.\n\nBefore and after the CFMA, federal banking regulators imposed capital and other requirements on banks that entered into OTC derivatives. The United States Securities and Exchange Commission (SEC) and CFTC had limited \"risk assessment\" authority over OTC derivatives dealers affiliated with securities or commodities brokers and also jointly administered a voluntary program under which the largest securities and commodities firms reported additional information about derivative activities, management controls, risk and capital management, and counterparty exposure policies that were similar to, but more limited than, the requirements for banks. Banks and securities firms were the dominant dealers in the market, with commercial bank dealers holding by far the largest share. To the extent insurance company affiliates acted as dealers of OTC derivatives rather than as counterparties to transactions with banks or security firm affiliates, they had no such federal \"safety and soundness\" regulation of those activities and typically conducted the activities through London-based affiliates.\n\nThe CFMA continued an existing 1992 preemption of state laws enacted in the Futures Trading Practices Act of 1992 which prevented the law from treating eligible OTC derivatives transactions as gambling or otherwise illegal. It also extended that preemption to security-based derivatives that had previously been excluded from the CEA and its preemption of state law.\n\nThe CFMA, as enacted by President Clinton, went beyond the recommendations of a Presidential Working Group on Financial Markets (PWG) Report titled \"Over-the Counter Derivatives and the Commodity Exchange Act.\" (the \"PWG Report \").\n\nPresident's Working Group on Financial Markets, November 1999:\n\nAlthough hailed by the PWG on the day of congressional passage as \"important legislation\" to allow \"the United States to maintain its competitive position in the over-the-counter derivative markets\", by 2001 the collapse of Enron brought public attention to the CFMA's treatment of energy derivatives in the \"Enron Loophole.\" Following the Federal Reserve's emergency loans to \"rescue\" American International Group (AIG) in September, 2008, the CFMA has received even more widespread criticism for its treatment of credit default swaps and other OTC derivatives.\n\nIn 2008 the \"Close the Enron Loophole Act\" was enacted into law to regulate more extensively \"energy trading facilities.\" On August 11, 2009, the Treasury Department sent Congress draft legislation to implement its proposal to amend the CFMA and other laws to provide \"comprehensive regulation of all over-the counter derivatives.\" This proposal was revised in the House and, in that revised form, passed by the House on December 11, 2009, as part of H.R. 4173 (Wall Street Reform and Consumer Protection Act of 2009). Separate, but similar, proposed legislation was introduced in the Senate and still awaiting Senate action at the time of the House action.\n\nThe PWG Report was directed at ending controversy over how swaps and other OTC derivatives related to the CEA. A derivative is a financial contract or instrument that \"derives\" its value from the price or other characteristic of an underlying \"thing\" (or \"commodity\"). A farmer might enter into a \"derivative contract\" under which the farmer would sell from next summer's harvest a specified number of bushels of wheat at a specified price per bushel. If this contract were executed on a commodity exchange, it would be a \"futures contract.\"\n\nBefore 1974, the CEA only applied to agricultural commodities. \"Future delivery\" contracts in agricultural commodities listed in the CEA were required to be traded on regulated exchanges such as the Chicago Board of Trade.\n\nThe Commodity Futures Trading Commission Act of 1974 created the CFTC as the new regulator of commodity exchanges. It also expanded the scope of the CEA to cover the previously listed agricultural products and \"all other goods and articles, except onions, and all services, rights, and interests in which contracts for future delivery are presently or in the future dealt in.\" Existing non-exchange traded financial \"commodity\" derivatives markets (mostly \"interbank\" markets) in foreign currencies, government securities, and other specified instruments were excluded from the CEA through the \"Treasury Amendment\", to the extent transactions in such markets remained off a \"board of trade.\" The expanded CEA, however, did not generally exclude financial derivatives.\n\nAfter the 1974 law change, the CEA continued to require that all \"future delivery\" contracts in commodities covered by the law be executed on a regulated exchange. This meant any \"future delivery\" contract entered into by parties off a regulated exchange would be illegal and unenforceable. The term \"future delivery\" was not defined in the CEA. Its meaning evolved through CFTC actions and court rulings.\n\nNot all derivative contracts are \"future delivery\" contracts. The CEA always excluded \"forward delivery\" contracts under which, for example, a farmer might set today the price at which the farmer would deliver to a grain elevator or other buyer a certain number of bushels of wheat to be harvested next summer. By the early 1980s a market in interest rate and currency \"swaps\" had emerged in which banks and their customers would typically agree to exchange interest or currency amounts based on one party paying a fixed interest rate amount (or an amount in a specified currency) and the other paying a floating interest rate amount (or an amount in a different currency). These transactions were similar to \"forward delivery\" contracts under which \"commercial users\" of a commodity contracted for future deliveries of that commodity at an agreed upon price.\n\nBased on the similarities between swaps and \"forward delivery\" contracts, the swap market grew rapidly in the United States during the 1980s. Nevertheless, as a 2006 Congressional Research Service report explained in describing the status of OTC derivatives in the 1980s: \"if a court had ruled that a swap was in fact an illegal, off-exchange futures contract, trillions of dollars in outstanding swaps could have been invalidated. This might have caused chaos in financial markets, as swaps users would suddenly be exposed to the risks they had used derivatives to avoid.\"\n\nTo eliminate this risk, the CFTC and the Congress acted to give \"legal certainty\" to swaps and, more generally, to the OTC derivatives market activities of \"sophisticated parties.\"\n\nFirst, the CFTC issued \"policy statements\" and \"statutory interpretations\" that swaps, \"hybrid instruments\" (i.e., securities or deposits with a derivative component), and certain \"forward transactions\" were not covered by the CEA. The CFTC issued the forward transactions \"statutory interpretation\" in response to a court ruling that a \"Brent\" (i.e., North Sea) oil \"forward delivery\" contract was, in fact, a \"future delivery\" contract, which could cause it to be illegal and unenforceable under the CEA. This, along with a court ruling in the United Kingdom that swaps entered into by a local UK government unit were illegal, elevated concerns with \"legal certainty.\"\n\nSecond, in response to this concern about \"legal certainty\", Congress (through the Futures Trading Practices Act of 1992 (FTPA)) gave the CFTC authority to exempt transactions from the exchange trading requirement and other provisions of the CEA. The CFTC used that authority (as Congress contemplated or \"instructed\") to exempt the same three categories of transactions for which it had previously issued policy statements or statutory interpretations. The FTPA also provided that such CFTC exemptions preempted any state law that would otherwise make such transactions illegal as gambling or otherwise. To preserve the 1982 Shad-Johnson Accord, which prohibited futures on \"non-exempt securities\", the FTPA prohibited the CFTC from granting an exemption from that prohibition. This would later lead to concerns about the \"legal certainty\" of swaps and other OTC derivatives related to \"securities.\"\n\nSimilar to the existing statutory exclusion for \"forward delivery\" contracts, the 1989 \"policy statement\" on swaps had required that swaps covered by the \"policy statement\" be privately negotiated transactions between sophisticated parties covering (or \"hedging\") risks arising from their business (including investment and financing) activities. The new \"swaps exemption\" dropped the \"hedging\" requirement. It continued to require the swap be entered into by \"sophisticated parties\" (i.e., \"eligible swap participants\") in private transactions.\n\nAlthough OTC derivatives were subject to criticism in the 1990s and bills were introduced in Congress to regulate aspects of the market, the 1993 exemptions remained in place. Bank regulators issued guidelines and requirements for bank OTC derivatives activities that responded to many of the concerns raised by Congress, the General Accounting Office (GAO), and others. Securities firms agreed with the Securities and Exchange Commission (SEC) and CFTC to establish a Derivatives Policy Group through which six large securities firms conducting the great majority of securities firm OTC derivatives activities reported to the CFTC and SEC about their activities and adopted voluntary principles similar to those applicable to banks. Insurance companies, which represented a much smaller part of the market, remained outside any federal oversight of their OTC derivatives activities.\n\nIn 1997 and 1998 a conflict developed between the CFTC and the SEC over an SEC proposal to ease its broker-dealer regulations for securities firm affiliates that engaged in OTC derivatives activities. The SEC had long been frustrated that those activities were conducted outside the regulated broker-dealer affiliates of securities firms, often outside the United States in London or elsewhere. To bring the activities into broker-dealer supervision, the SEC proposed relaxed net capital and other rules (known as \"Broker-Dealer Lite\") for OTC derivatives dealers. The CFTC objected that some activities that would be authorized by this proposal were not permitted under the CEA. The CFTC also issued a \"concept release\" requesting comments on whether the OTC derivatives market was properly regulated under the existing CEA exemptions and on whether market developments required regulatory changes.\n\nThe CFTC's actions were widely viewed as a response to the SEC's Broker-Dealer Lite proposal and, at least by Professor John C. Coffee, as perhaps an attempt to force the SEC to withdraw the proposal. The CFTC expressed dismay over the Broker-Dealer Lite proposal and the manner in which it was issued, but also noted it was 18 months into a \"comprehensive regulatory reform effort.\" The same day the CFTC issued its \"concept release\" Treasury Secretary Robert Rubin, Federal Reserve Board Chair Alan Greenspan, and SEC Chair Arthur Levitt (who, along with CFTC Chair Brooksley Born, were the members of the PWG) issued a letter asking Congress to prevent the CFTC from changing its existing treatment of OTC derivatives. They argued that, by calling into question whether swaps and other OTC derivatives were \"futures\", the CFTC was calling into question the legality of security related OTC derivatives for which the CFTC could not grant exemptions (as described in Section 1.1.2 above) and, more broadly, undermining an \"implicit agreement\" not to raise the question of the CEA's coverage of swaps and other established OTC derivatives.\n\nIn the ensuing Congressional hearings, the three members of the PWG dissenting from the CFTC's \"unilateral\" actions argued the CFTC was not the proper body, and the CEA was not the proper statute, to regulate OTC derivatives activities. Banks and securities firms dominated the OTC derivatives market. Their regulators needed to be involved in any regulation of the market. Bank regulators and the SEC already monitored and regulated bank and broker-dealer OTC Derivatives activities. The dissenting PWG members explained that any effort to regulate those activities through the CEA would only lead to the activities moving outside the United States. In the 1980s banks had used offshore branches to book transactions potentially covered by the CEA. Securities firms were still using London and other foreign offices to book at least securities related derivatives transactions. Any change in regulation of OTC derivatives should only occur after a full study of the issue by the entire PWG.\n\nCFTC Chair Brooksley Born replied that the CFTC had exclusive authority over \"futures\" under the CEA and could not allow the other PWG members to dictate the CFTC's authority under that statute. She pointed out the \"concept release\" did not propose, nor presuppose the need for, any change in the regulatory treatment of OTC derivatives. She noted, however, that changes in the OTC derivatives market had made that market more similar to futures markets.\n\nCongress passed a law preventing the CFTC from changing its treatment of OTC derivatives through March 1999. CFTC Chair Born lost control of the issue at the CFTC when three of her four fellow Commissioners announced they supported the legislation and would temporarily not vote to take any action concerning OTC derivatives. CFTC Chair Born resigned effective June 1999. Her successor, William Rainer, was CFTC Chair when the PWG Report was issued in November 1999.\n\nWhile the dispute between the SEC and CFTC over OTC derivatives jurisdiction was at the core of pre-2008 narrations of the events leading to the CFMA, two other noteworthy background events occurred. First, in early 1997 CFTC Chairperson Born testified forcefully to Congress against a Senate bill that would have authorized futures exchanges to establish \"professional markets\" exempt from many regulatory requirements in a manner similar to the \"regulatory relief\" ultimately provided for an \"exempt board of trade\" under the CFMA. In her testimony to the Senate Agriculture Committee and in several subsequent speeches during the first half of 1997, Chairperson Born argued OTC derivatives did not create the same \"concentration of financial risk\" as exchange traded futures and did not perform the \"unique price discovery\" function of exchange traded contracts. She argued these differences justified different regulatory treatment.\n\nChairperson Born's 1997 testimony on the difference between exchange and OTC markets was consistent with her first speech as CFTC Chair, on October 24, 1996, in which she stated her belief that regulation of the OTC derivatives market should be limited to fraud and manipulation. While her 1997 testimony opposed the Senate bill's provision to codify in law the existing CFTC regulatory exemptions for OTC derivatives, she also stated the CFTC was \"watching\" the OTC derivatives market with the PWG and had no plans to modify the existing CFTC exemptions for that market.\n\nThe futures exchanges argued they needed permission to operate \"professional markets\" free of \"regulatory burdens\" in order to compete with foreign exchanges and the OTC derivatives market that catered to the same professionals. 1997 news reports attributed the failure of the \"professional markets\" legislation to disagreements concerning equity derivatives between the Chicago Board of Trade and the OTC derivatives dealers, on the one side, and the Chicago Mercantile Exchange and others futures exchanges, on the other.\n\nSecond, after the 1998 CFTC \"concept release\" controversy arose, Long-Term Capital Management (LTCM) became headline news with the near collapse of a hedge fund it managed. The near collapse was widely attributed to OTC derivatives transactions. At an October 1, 1998, hearing before the House Banking Committee, Chairperson Born received complements from some members of the Committee for having raised important issues in the May \"concept release.\" The hearing, however, focused on issues with regulatory oversight of the banks and security firms that had given the LTCM fund high leverage through both loans and OTC derivative transactions.\n\nThe 1999 GAO Report that analyzed the LTCM experience criticized federal regulators for not coordinating their oversight of LTCM's activities with banks and securities firms. The Report also recommended \"consideration of\" legislation to grant the SEC and CFTC consolidated supervision authority for securities and commodities firms in order to supervise the OTC derivatives activities of those consolidated entities in a manner similar to the Federal Reserve's authority over bank holding companies. The GAO Report did not consider, and did not recommend, CFTC regulation of OTC derivatives.\n\nAn effect of the LTCM experience was that the conference committee report adopting the six-month moratorium on CFTC action affecting OTC derivative regulation included a statement that \"the conferees strongly urge\" the PWG to study OTC derivatives transactions of hedge funds and others. Although Chairperson Born had explained at the October 1, 1998, House Banking Committee hearing that the CFTC's supervisory authority over the LTCM fund as a \"commodity pool operator\" was limited to monitoring its exchange trading activities, the CFTC's possession of financial statements for the fund received negative news coverage in November 1998 based on the fact the CFTC was the only federal regulator to receive such reports directly from LTCM and had not shared the information with other members of the PWG. When the LTCM matter was investigated at a December 16, 1998, Senate Agriculture Committee hearing, the three CFTC Commissioners that had supported the Congressional moratorium, as described in Section 1.2.1 above, reiterated their support and their position that the entire PWG should study the OTC derivatives market and the issues raised in the CFTC's \"concept release.\"\n\nThe PWG Report recommended: (1) the codification into the CEA, as an \"exclusion\", of existing regulatory exemptions for OTC financial derivatives, revised to permit electronic trading between \"eligible swaps participants\" (acting as \"principals\") and to even allow standardized (i.e. \"fungible\") contracts subject to \"regulated\" clearing; (2) continuation of the existing CFTC authority to exempt other non-agricultural commodities (such as energy products) from provisions of the CEA; (3) continuation of existing exemptions for \"hybrid instruments\" expanded to cover the Shad-Johnson Accord (thereby exempting from the CEA any hybrid that could be viewed as a future on a \"non-exempt security\"), and a prohibition on the CFTC changing the exemption without the agreement of the other members of the PWG; (4) continuation of the preemption of state laws that might otherwise make any \"excluded\" or \"exempted\" transactions illegal as gambling or otherwise; (5) as previously recommended by the PWG in its report on hedge funds, the expansion of SEC and CFTC \"risk assessment\" oversight of affiliates of securities firms and commodity firms engaged in OTC derivatives activities to ensure they did not endanger affiliated broker-dealers or futures commission merchants; (6) encouraging the CFTC to grant broad \"deregulation\" of existing exchange trading to reflect differences in (A) the susceptibility of commodities to price manipulation and (B) the \"sophistication\" and financial strength of the parties permitted to trade on the exchange; and (7) permission for single stock and narrow index stock futures on terms to be agreed between the CFTC and SEC.\n\nIn 1998 the CFTC had disagreed with the other members of the PWG about the scope and purposes of the CEA. Whereas the CFTC saw broad purposes in protecting \"fair access\" to markets, \"financial integrity\", \"price discovery and transparency\", \"fitness standards,\" and protection of \"market participants from fraud and other abuses,\" other members of the PWG (particularly the Federal Reserve through Alan Greenspan) found the more limited purposes of (1) preventing price manipulation and (2) protecting retail investors.\n\nThe PWG Report ended that disagreement by analyzing only four issues in deciding not to apply the CEA to OTC derivatives. By finding (1) the sophisticated parties participating in the OTC derivatives markets did not require CEA protections, (2) the activities of most OTC derivatives dealers were already subject to direct or indirect federal oversight, (3) manipulation of financial markets through financial OTC derivatives had not occurred and was highly unlikely, and (4) the OTC derivatives market performed no significant \"price discovery\" function, the PWG concluded \"there is no compelling evidence of problems involving bilateral swap agreements that would warrant regulation under the CEA.\" By essentially adopting the views of the other members of the PWG concerning the scope and application of the CEA, the CFTC permitted a \"remarkable\" agreement \"on a redrawing of the regulatory lines.\"\n\nRather than treat the \"convergence' of OTC derivatives and futures markets as a basis for CFTC regulation of OTC derivatives, the PWG Report acknowledged and encouraged the growth in similarities between the OTC derivatives market and the regulated exchange traded futures market. Standardized terms and centralized clearing were to be encouraged, not prohibited. Price information could be broadly disseminated through \"electronic trading facilities.\" The PWG hoped these features would (1) increase \"transparency\" and liquidity in the OTC derivatives market by increasing the circulation of information about market pricing and (2) reduce \"systemic risk\" by reducing credit exposures between parties to OTC derivatives transactions.\n\nThe PWG Report also emphasized the desire to \"maintain U.S. leadership in these rapidly developing markets\" by discouraging the movement of such transactions \"offshore.\" In the 1998 Congressional hearings concerning the CFTC \"concept release\" Representative James A. Leach (R-IA) had tied the controversy to \"systemic risk\" by arguing the movement of transactions to jurisdictions outside the United States would replace U.S. regulation with laxer foreign supervision.\n\nIt can be argued that the PWG Report recommendations and the CFMA as enacted did not change the \"regulation\" of OTC derivatives because there was no existing regulation under the CEA or securities laws. The change to the CEA, however, would be the elimination of existing criteria for distinguishing OTC derivatives from \"futures.\"\n\nTitle I of the CFMA adopted recommendations of the PWG Report by broadly excluding from the CEA transactions in financial derivatives (i.e. \"excluded commodities\") between \"eligible contract participants.\" The definition of \"eligible contract participant\" covered the same types of \"sophisticated\" parties as the existing \"swaps exemption\" in its definition of \"eligible swap participants\", but was broader, particularly by adding permission for individuals with assets of $5 million rather than $10 million, if the transaction related to managing asset or liability \"risk.\" The PWG had recommended \"considering\" an increase in this threshold to $25 million, not a reduction for actual hedging.\n\nSuch \"eligible contract participants\" could enter into transactions on or off \"electronic trading facilities\" without being subject to any of the regulatory oversight applicable to futures. The only exception was that the transactions would be subject to the rules for the new \"Derivative Clearing Organizations\" authorized by the CFMA, if the transaction used such a clearing facility. The CFMA did not require that standardized transaction use a clearing facility. It only authorized their existence, subject to regulatory oversight. The PWG Report had recommended permitting \"standardized\" contracts, so long as they were subject to regulated clearing.\n\nTitle I's biggest departure from the PWG Report recommendations was in extending most of the same exclusions to non-financial commodities that were not agricultural. These \"exempt commodities\" were, in practice, mostly energy and metal commodities. As discussed below in Section 4, these transactions were subject to the \"anti-fraud\" and \"anti-manipulation\" provisions of the CEA in some, but not all, circumstances. The PWG Report had recommended that exemptions for such transactions remain in the control of the CFTC, although it had recommended the continuation of those regulatory exemptions.\n\nTitle I also resolved the issue of \"hybrid instruments\" by defining when such an instrument would be considered a \"security\" subject to security laws and excluded from the CEA even though it had a \"commodity component.\" Equivalent treatment of bank products was provided in Title IV.\n\nTitle I retained the CEA's existing preemption of state gambling and other laws that could render a CFTC exempted transaction illegal. It made that preemption applicable to all exempted or excluded transactions.\n\nTitle I also created a new system under which three different types of exchanges could be established based on the types of commodities and participants on such exchanges.\n\nTitle II of the CFMA repealed the 1982 Shad-Johnson Accord that had prohibited single stock and narrow stock index futures and replaced that with a joint CFTC and SEC regulated \"security futures\" system.\n\nTitle III established a framework for SEC regulation of \"security-based swaps.\" The PWG Report had not addressed this issue.\n\nTitle IV established a framework for CFTC regulation of \"bank products.\" This included coverage of deposit based \"hybrid instruments\", but went further. The PWG Report had not dealt with these issues beyond how Title IV overlapped with Title I.\n\nThe CFMA did not provide the CFTC or SEC the broader \"risk assessment\" authority over affiliates of futures commission merchants or broker-dealers that the PWG Report had recommended.\n\nH.R. 4541 was introduced in the House of Representatives on May 25, 2000, as the Commodities Futures Modernization Act of 2000. Three separate House Committees held hearings on the bill. Each Committee reported out a different amended version of H.R. 4541 by September 6, 2000.\n\nAnother Commodity Futures Modernization Act of 2000 was introduced in the Senate on June 8, 2000, as S. 2697. A joint hearing of the Senate Agriculture and Banking Committees was held to consider that bill. The Senate Agriculture Committee reported out an amended version of S. 2697 on August 25, 2000.\n\nDuring the House and Senate committee hearings on these bills, Committee Chairs and Ranking Members described a tight legislative schedule for the bills because of the election year's short Congressional schedule. Sponsors had delayed introduction of the bills as they vainly awaited agreement between the CFTC and SEC on how to regulate the single stock futures contemplated by the PWG Report. That issue dominated the hearings.\n\nOn September 14, 2000, the SEC and CFTC announced they had agreed on a joint regulation approach for \"security futures.\" Senior Treasury Department officials hailed the \"historic agreement\" as eliminating \"the major obstacles to forming a consensus bill.\" At the same time, Senator Phil Gramm (R-TX), the Chair of the Senate Banking Committee, was quoted as insisting that any bill brought to the Senate Floor would need to be expanded to include prohibitions on SEC regulation of the swaps market.\n\nDemocratic members of Congress later described a period in late September through early October during which they were excluded from negotiations over reconciling the three committee versions of H.R. 4541, followed by involvement in reaching an acceptable compromise that left some Republicans unhappy with the final version of the bill and some Democrats upset over the \"process\", particularly the involvement of Sen. Gramm and House Republican leadership in the negotiations. Despite indications no agreement would be reached, on October 19, 2000, the White House announced its \"strong support\" for the version of H.R. 4541 scheduled to reach the House Floor that day. The House approved H.R. 4541 in a 377-4 vote.\n\nAs so passed by the House, H.R. 4541 contained, in Title I, the language concerning OTC derivatives that became the source for Title I of the CFMA and, in Title II, the language regulating \"security futures\" that became the source for Title II of the CFMA. Titles III and IV would be added when the CFMA was enacted into law two months later.\n\nAfter the House passed H.R. 4541, press reports indicated Sen. Gramm was blocking Senate action based on his continued insistence that the bill be expanded to prevent the SEC from regulating swaps, and the desire to broaden the protections against CFTC regulation for \"bank products.\" Nevertheless, with Congress adjourned for the 2000 elections, but scheduled to return for a \"lame duck\" session, Treasury Secretary Summers \"urged\" Congress to move forward with legislation on OTC derivatives based on the \"extraordinary bipartisan consensus this year on these very complex issues.\".\n\nWhen Congress returned into session for two days in mid-November, the sponsor of H.R. 4541, Representative Thomas Ewing (R-IL), described Senator Gramm as the \"one man\" blocking Senate passage of H.R. 4541. Senator Richard G. Lugar (R-IN), the sponsor of S. 2697, was reported to be considering forcing H.R. 4541 to the Senate Floor against Senator Gramm's objections.\n\nAfter Congress returned into session on December 4, 2000, there were reports Senator Gramm and the Treasury Department were exchanging proposed language to deal with the issues raised by Sen. Gramm, followed by a report those negotiations had reached an impasse. On December 14, however, the Treasury Department announced agreement had been reached the night before and urged Congress to enact into law the agreed upon language.\n\nThe \"compromise language\" was introduced in the House on December 14, 2000, as H.R. 5660. The same language was introduced in the Senate on December 15, 2000 as S. 3283. The Senate and House conference that was called to reconcile differences in H.R. 4577 appropriations adopted the \"compromise language\" by incorporating H.R. 5660 (the \"CFMA\") into H.R. 4577, which was titled \"Consolidated Appropriations Act for FY 2001\". The House passed the Conference Report and, therefore, H.R. 4577 in a vote of 292-60. Over \"objection\" by Senators James Inhofe (R-OK) and Paul Wellstone (D-MN), the Senate passed the Conference Report, and therefore H.R. 4577, by \"unanimous consent.\" The Chairs and Ranking members of each of the five Congressional Committees that considered H.R. 4541 or S. 2697 supported, or entered into the Congressional Record statements in support of, the CFMA. The PWG issued letters expressing the unanimous support of each of its four members for the CFMA. H.R. 4577, including H.R. 5660, was signed into law, as CFMA, on December 21, 2000.\n\nWith the 2008 emergence of widespread concerns about credit default swaps, the CFMA's treatment of those instruments has become controversial. Title I of the CFMA broadly excludes from the CEA financial derivatives, including specifically any index or measure tied to a \"credit risk or measure.\" In 2000, Title I's exclusion of financial derivatives from the CEA was not controversial in Congress. Instead, it was widely hailed for bringing \"legal certainty\" to this \"important market\" permitting \"the United States to retain its leadership in the financial markets\", as recommended by the PWG Report.\n\nThe CFMA's treatment of credit default swaps has received the most attention for two issues. First, former New York Insurance Superintendent Eric Dinallo has argued credit default swaps should have been regulated as insurance and that the CFMA removed a valuable legal tool by preempting state \"bucket shop\" and gaming laws that could have been used to attack credit default swaps as illegal. In 1992, the FTPA had preempted those state laws for financial derivatives covered by the CFTC's \"swaps exemption.\" As described in Section 1.1.2 above, however, a \"gap\" in the CFTC's powers prohibited it from exempting futures on \"non-exempt securities.\" This \"loophole\" (which was intended to preserve the Shad-Johnson Accord's prohibition on single stock futures) meant that, before the CFMA, the CEA's preemption of state gaming and \"bucket shop\" laws would not have protected a credit default swap on a \"non-exempt security\" (i.e. an equity security or a \"non-exempt\" debt obligation that qualified as a \"security\"). As before 1992, the application of such state laws to a credit default swap (or any other swap) would depend upon a court finding the swap was a gambling, \"bucket shop\", or otherwise illegal transaction. As described in Section 1.2.1 above, legal uncertainty for security-based swaps was an important issue in the events that led to the PWG Report. The PWG Report recommended eliminating that uncertainty by excluding credit default swaps and all security-based swaps from the CEA and by adding to the \"hybrid instrument\" exemption an exclusion from the Shad-Johnson Accord.\n\nFormer Superintendent Dinallo has written that the CFMA was enacted in part to avoid having OTC derivatives transactions move offshore. He has not, however, addressed whether that could have been avoided if the CFMA had not been enacted. AIG (the insurance company addressed by Mr. Dinallo's commentary) located its controversial derivatives dealer (AIG Financial Products) in London and conducted its \"regulatory CDS\" transactions through a French bank (Banque AIG) because of the bank regulatory capital provision that banks (not AAA rated parties) received a reduced credit risk \"weighting\" for their obligations, including CDS, owed to other banks. General Re, the other insurance company with a very active derivatives dealer affiliate, similarly established that dealer in London.\n\nSecond, Title II of the CFMA treated credit default swaps tied to \"securities\" as \"security-related swaps\" for which the SEC was granted limited authority to enforce \"insider trading\", fraud, and anti-manipulation provisions of the securities laws. Before the CFMA, it was generally agreed most swaps were not securities, but the SEC had always maintained that swaps tied to securities were securities, particularly when such swaps could reproduce the attributes of owning the underlying security. In granting the SEC authority over \"security-related swaps\", the CFMA specifically prohibited applying any \"prophylactic\" anti-fraud or anti-manipulation measures. The SEC has complained this has prevented it from collecting information, and requiring disclosures, regarding credit default positions of investors. The SEC has argued this handicaps its ability to monitor possible manipulations of security markets through credit default swaps.\n\nThe SEC, the PWG, and others have also expressed concern about the \"systemic risk\" created by a lack of centralized clearing of credit default swaps. Although (as noted in Section 2 above) the CFMA created the possibility of centralized clearing by removing the pre-CFMA requirements that OTC derivatives not be subject to centralized clearing, the CFMA did not require such clearing, even for \"standardized\" transactions.\n\nOn August 11, 2009, the Treasury Department sent to Congress proposed legislation titled the \"Over-the-Counter Derivatives Markets Act of 2009.\" The Treasury Department stated that under this proposed legislation \"the OTC derivative markets will be comprehensively regulated for the first time.\"\nTo accomplish this \"comprehensive regulation\", the proposed legislation would repeal many of the provisions of the CFMA, including all of the exclusions and exemptions discussed in Sections 4 above that have been identified as the \"Enron Loophole.\" While the proposed legislation would generally retain the \"legal certainty\" provisions of the CFMA, it would establish new requirements for parties dealing in non-\"standardized\" OTC derivatives and would require that \"standardized\" OTC derivatives be traded through a regulated trading facility and cleared through regulated central clearing. The proposed legislation would also repeal the CFMA's limits on SEC authority over \"security-based swaps.\"\n\nOn December 11, 2009, the House passed H.R. 4173, the so-called Wall Street Reform and Consumer Protection Act of 2009, which included a revised version of the Treasury Department's proposed legislation that would repeal the same provisions of the CFMA noted above. At that time, similar legislation was pending in the Senate.\n\nIn late April, 2010, debate began on the floor of the Senate over their version of the reform legislation and on July 21, 2010, H.R.4173 passed in the Senate and was signed into law as the Dodd–Frank Wall Street Reform and Consumer Protection Act.\n\nThe first provision of the CFMA to receive widespread popular attention was the \"Enron Loophole\". In most accounts, this \"loophole\" was the CEA's new section 2(h). Section 2(h) created two exemptions from the CEA for \"exempt commodities\" such as oil and other \"energy\" products.\n\nFirst, any transaction in exempt commodities not executed on a \"trading facility\" between \"eligible contract participants\" (acting as principals) was exempted from most CEA provisions (other than fraud and anti-manipulation provisions). This exemption in Section 2(h)(1) of the CEA covered the \"bilateral swaps market\" for exempt \"trading facilities.\"\n\nSecond, any transaction in exempt commodities executed on an \"electronic trading facility\" between \"eligible commercial entities\" (acting as principals) was also exempted from most CEA provisions (other than those dealing with fraud and manipulation). The \"trading facility\", however, was required to file with the CFTC certain information and certifications and to provide trading and other information to the CFTC upon any \"special call.\" This exemption in Section 2(h)(2) of the CEA covered the \"commercial entities\" for exempt \"electronic trading facilities.\"\n\nWhile the language of Section 2(h) was in H.R. 4541 as passed by the House, the portion of Section 2(h) dealing with the exempt commercial market had been deleted from S. 2697 when the Senate Agriculture Committee reported out an amended version of that bill. H.R. 4541 served as the basis for Titles I and II of the CFMA. The Senate Agriculture Committee's removal of the Section 2(h) language from S. 2697, however, served as the basis for later Senate concern over the origins of Section 2(h).\n\nIn 2008 Congress enacted into law over President Bush's veto an Omnibus Farm Bill that contained the \"Close the Enron Loophole Act.\" This added to CEA Section 2(h)(2) a new definition of \"electronic trading facility\" and imposed on such facilities requirements applicable to fully regulated exchanges (i.e. \"designated contract markets\") such as the NYMEX. The legislation did not change Section 2(h)(1) exemption for the \"bilateral swaps market\" in exempt commodities.\n\nSection 2(g) of the CEA is also sometimes called the \"Enron Loophole\". It is a broader exclusion from the CEA than the Section 2(h)(1) exemption for the \"bilateral swaps market\" in exempt commodities. It excludes from even the fraud and manipulation provisions of the CEA any \"individually negotiated\" transaction in a non-agricultural commodity between \"eligible contract participants\" not executed on a \"trading facility.\" Thus, the exclusion from provisions of the CEA for \"eligible contract participants\" is broader than the Section 2(h)(1) exemption for \"bilateral swaps\" of energy commodities. The criteria for this exclusion, however, are narrower in requiring \"individual negotiation.\"\n\nThis exclusion was not contained in either H.R. 4541 or S. 2697 as introduced in Congress. The House Banking and Financial Services Committee added this provision to the amended H.R. 4541 it reported to the House. That language was included in H.R. 4541 as passed by the House. Its final version was modified to conform to the Gramm-Leach-Bliley Act definition of \"swap agreement.\" That definition requires that the swap be \"individually negotiated.\" H.R. 4541 had required that each \"material economic term\" be individually negotiated.\n\n2002 Senate hearings indicated CEA Section 2(h)(2) was not the\"Enron Loophole\" used by EnronOnline. That facility was not required to qualify as an \"electronic trading facility\" under Section 2(h)(2) of the CEA because Enron Online was only used to enter into transactions with Enron affiliates. There were not \"multiple participants\" on both the buy and sell sides of the trades. Whether such Enron-only trades were covered by the Section 2(h)(1) \"bilateral swaps market\" exemption for energy products or the broader Section 2(g) exclusion for swaps generally depended whether there was \"individual negotiation.\"\n\nInstitutions such as hedge funds, pension funds and investment banks have been instrumental in pushing up world food prices in the last five years, with investment in food solely as a commodity rising from $65bn to $126bn (£41bn to £79bn) between 2007 and 2012, contributing to 30-year highs. Financial institutions now make up 61% of all investment in wheat futures. According to Olivier De Schutter, the UN special rapporteur on food, there was a rush by institutions to enter the food market following the Commodity Futures Modernization Act.\n\nDe Schutter told the \"Independent\" in March 2012: What we are seeing now is that these financial markets have developed massively with the arrival of these new financial investors, who are purely interested in the short-term monetary gain and are not really interested in the physical thing – they never actually buy the ton of wheat or maize; they only buy a promise to buy or to sell. The result of this financialisation of the commodities market is that the prices of the products respond increasingly to a purely speculative logic. This explains why in very short periods of time we see prices spiking or bubbles exploding, because prices are less and less determined by the real match between supply and demand. In 2011, 450 economists from around the world called on the G20 to regulate the commodities market more. Rising food prices over recent years have been linked with social unrest around the world, including rioting in Bangladesh and Mexico, and the Arab Spring.\n\nIn June 2013, film producer Charles Ferguson interviewed Bill Clinton who said he and Larry Summers couldn't change Alan Greenspan's mind and Congress then passed the Act with a veto-proof supermajority. Ferguson revealed that this was inaccurate and, he said, a lie, while commenting that he thought Clinton was \"a really good actor\". In fact, Ferguson wrote, the Clinton Administration and Larry Summers lobbied for the Act and joined Robert Rubin in both privately and publicly attacking advocates of regulation.\n\n\n\n"}
{"id": "37802439", "url": "https://en.wikipedia.org/wiki?curid=37802439", "title": "Common Penny", "text": "Common Penny\n\nThe Common Penny ( or \"Reichspfennig\") was an imperial tax (\"Reichssteuer\") that was agreed at the instigation of Maximilian I in 1495 at the Diet of Worms, in order to give the emperor the means to wage war against France and against the Osman regime in the Ottoman Empire. \n\nThe tax was to be paid by all subjects of the Holy Roman Empire of the German Nation aged 15 years or more. It was designed as a poll tax, income tax and property tax that depended on personal status and wealth. Its recovery ran into so many difficulties everywhere that it was explicitly abandoned in 1505. After the Hussite Penny (\"Hussitenpfennig\") in 1427, it was another attempt to introduce an imperial tax and was part of the comprehensive, but ultimately unsuccessful Imperial Reform under Emperor Maximilian. The successor of the Common Penny as an imperial tax was the Kammerzieler.\n\n\n"}
{"id": "40781579", "url": "https://en.wikipedia.org/wiki?curid=40781579", "title": "Conference of the parties", "text": "Conference of the parties\n\nA conference of the parties (COP; , CP) is the governing body of an international convention. Conventions with a COP include:\n\n\n"}
{"id": "252145", "url": "https://en.wikipedia.org/wiki?curid=252145", "title": "Connecticut River", "text": "Connecticut River\n\nThe Connecticut River is the longest river in the New England region of the United States, flowing roughly southward for through four states. It rises at the U.S. border with Quebec, Canada, and discharges at Long Island Sound. Its watershed encompasses five U.S. states and one Canadian province, via 148 tributaries, 38 of which are major rivers. It produces 70% of Long Island Sound's fresh water, discharging at per second.\n\nThe Connecticut River Valley is home to some of the northeastern United States' most productive farmland, as well as a metropolitan region of approximately two million people surrounding Springfield, Massachusetts and Hartford, Connecticut.\n\nThe word \"Connecticut\" is a French corruption of the Mohegan word \"quinetucket\", which means \"beside the long, tidal river\". The word came into English during the early 1600s to name the river, which was also called simply \"The Great River\".\n\nPrior to Dutch exploration beginning in 1614, numerous indigenous tribes lived throughout the fertile Connecticut River valley. Information concerning how these tribes lived and interacted stems mostly from English accounts written during the 1630s.\n\nThe Pequots dominated a territory in the southernmost region of the Connecticut River valley, stretching roughly from the river's mouth at Old Saybrook, Connecticut northward to just below the Big Bend at Middletown. They warred with and attempted to subjugate neighboring agricultural tribes such as the Western Niantics, while maintaining an uneasy stand-off with their rivals the Mohegans. The Mattabesset (Tunxis) tribe takes its name from the place where its sachems ruled at the Connecticut River's Big Bend at Middletown, in a village sandwiched between the territories of the aggressive Pequots to the south and the more peaceable Mohegans to the north.\n\nThe Mohegans dominated the region due north, where Hartford and its suburbs sit, particularly after allying themselves with the Colonists against the Pequots during the Pequot War of 1637.<ref name=\"http://www.dickshovel.com/moh.html\"></ref> Their culture was similar to that of the Pequots, as they had split off from them and become their rivals some time prior to European exploration of the area. The agricultural Pocomtuc tribe lived in unfortified villages alongside the Connecticut River north of the Enfield Falls on the fertile stretch of hills and meadows surrounding Springfield, Massachusetts. The Pocomtuc village of Agawam eventually became Springfield, situated on the Bay Path where the Connecticut River meets the western Westfield River and eastern Chicopee River. The Pocomtuc villagers at Agawam helped Puritan explorers settle this site and remained friendly with them for decades, unlike tribes farther north and south along the Connecticut River. The region stretching from Springfield north to the New Hampshire and Vermont state borders fostered many agricultural Pocomtuc and Nipmuc settlements, with its soil enhanced by sedimentary deposits. Occasionally, these villages endured invasions from more aggressive confederated tribes living in New York, such as the Mohawk, Mahican, and Iroquois tribes.\n\nThe Pennacook tribe mediated many early disagreements between colonists and other Indian tribes, with a territory stretching roughly from the Massachusetts border with Vermont and New Hampshire, northward to the rise of the White Mountains in New Hampshire. The Western Abenaki (Sokoki) tribe lived in the Green Mountains region of Vermont but wintered as far south as the Northfield, Massachusetts area. They later merged with members of other Algonquin tribes displaced by wars and famines.\n\nIn 1614, Dutch explorer Adriaen Block became the first European to chart the Connecticut River, sailing as far north as Enfield Rapids. He called it the \"Fresh River\" and claimed it for the Netherlands as the northeastern border of the New Netherland colony. In 1623, Dutch traders constructed a fortified trading post at the site of Hartford, Connecticut called the \"Fort Huys de Hoop\" (\"Fort House of Hope\").\n\nFour separate Puritan-led groups also settled the fertile Connecticut River Valley, and they founded the two large cities that continue to dominate the Valley today: Hartford (est. 1635) and Springfield (est. 1636). The first group of pioneers left the Plymouth Colony in 1632 and ultimately founded the village of Matianuck (which became Windsor, Connecticut) several miles north of the Dutch fort. A group left the Massachusetts Bay Colony from Watertown, seeking a site where they could practice their religion more freely. With this in mind, they founded Wethersfield, Connecticut in 1633, several miles south of the Dutch fort at Hartford.\n\nIn 1635, Reverend Thomas Hooker led settlers from Cambridge, Massachusetts, where he had feuded with Reverend John Cotton, to the site in Connecticut of the Dutch Fort House of Hope, where he founded Newtowne. Shortly after Hooker's arrival, Newtowne annexed Matianuck based on laws articulated in Connecticut's settlement charter, the Warwick Patent of 1631. The patent, however, had been physically lost, and the annexation was almost certainly illegal.\n\nThe fourth English settlement along the Connecticut River came out of a 1635 scouting party commissioned by William Pynchon to find the most advantageous site for commerce and agriculture, hoping to found a city there. His scouts located the Pocumtuc village of Agawam, where the Bay Path trade route crossed the Connecticut River at two of its major tributaries—the Chicopee River to the east and Westfield River to the west—and located just north of Enfield Falls, the river's first unnavigable waterfall. Pynchon surmised that traders using any of these routes would have to dock and change ships at his site, thereby granting the settlement a commercial advantage. It was initially named Agawam Plantation and was allied with the settlements to the south that became the state of Connecticut, but it switched allegiances in 1641 and was renamed Springfield in honor of Pynchon's native town in England.\n\nOf these settlements, Hartford and Springfield quickly emerged as powers. In 1641, Springfield splintered off from the Hartford-based Connecticut Colony, allying itself with the Massachusetts Bay Colony. For decades, Springfield remained the Massachusetts Bay Colony's westernmost settlement, on the northern border of the Connecticut Colony. By 1654, however, the success of these English settlements rendered the Dutch position untenable on the Connecticut River. A treaty moved the boundary westward between the Connecticut Colony and New Netherland Colony to a point near Greenwich, Connecticut. The treaty allowed the Dutch to maintain their trading post at Foot Huys de Hoop, which they did until the 1664 British takeover of New Netherland.\n\nThe Connecticut River Valley's central location, fertile soil, and abundant natural resources made it the target of centuries of border disputes, beginning with Springfield's defection from the Connecticut Colony in 1641, which brought the Massachusetts Bay Colony to the river. Conflicting royal treaties of 1764 sparked the river's east-siders to unite with Ethan Allen and the west-siders against New York and the British. The 1783 Treaty of Paris created a disputed border with Canada from the Connecticut's \"northernmost headwaters\". A 1933 U.S. Supreme Court decision settled a contentious boundary dispute between Vermont and New Hampshire. The Connecticut River's history is characterized by both political intrigue and technological innovation.\n\nDuring 1640 and 1641, two controversies took place that altered the political boundaries of the Lower Connecticut River region, preventing it from administration by a single political body. The Connecticut Colony administered Springfield during the 1630s, in addition to Hartford, Wethersfield, and Windsor; however, by 1640, Springfield's advantageous geography enabled it to become the Connecticut Colony's most commercially prosperous settlement. The Colony endured a crippling grain shortage during the spring of 1640 which caused many cattle to die of starvation. The grain shortage became a matter of survival for the Colony but not for Springfield, due to its prosperity.\nIn response to the shortage, leading citizens of Wethersfield and Hartford gave power to Pynchon, Springfield's founder, to purchase corn for all of the Connecticut Colony's settlements from the Pocumtuc. Colony leaders authorized him to offer large sums of money to the Indians, far above market prices; however, the Indians refused to sell at even \"reasonable\" prices, and thus he refused to buy the corn altogether. Pynchon argued that it was best not to broadcast the Connecticut Colonists' weaknesses to the Indians, who he believed might capitalize on it; likewise, he aimed to keep market values and trade with the Indians steady in the future.\n\nHartford's leading citizens were furious with Pynchon's willingness to further imperil the starving settlements. With Windsor's and Wethersfield's consent, they commissioned Captain John Mason who had fought in the Pequot War to travel to Springfield with \"money in one hand and a sword in the other\" to make a deal with the Indians, and also to rebuke Pynchon. On reaching Springfield, Mason threatened the Indians with war if they did not sell their corn at reasonable prices. The Indians capitulated and ultimately sold the corn to the Colonists. However, Mason's violent approach aroused distrust among the Pocumtuc tribe. Mason also upbraided Pynchon in public. This incident arose partly from differences of opinion regarding how to interact with the Indian tribes. Pynchon had achieved mutual benefits by trading with the Pocumtucs, whereas Mason had used force. Nevertheless, it caused Springfield's settlers to rally around the humiliated Pynchon, and led to the settlement severing ties with the Connecticut Colony.\n\nAs this controversy was heating up, the Massachusetts Bay Colony saw an opportunity to gain a foothold along the fertile Connecticut River Valley. In 1640, Boston asserted a claim to jurisdiction over lands surrounding the river; however, Springfield remained politically independent until tensions with the Connecticut Colony were exacerbated by a final confrontation later that year.\n\nHartford kept a fort at the mouth of the Connecticut River at Old Saybrook for protection against the Pequots, Wampanoags, Mohegans, and the New Netherland Colony. After Springfield broke ties with the Colony, the remaining Connecticut settlements demanded that Springfield's ships pay tolls when passing the mouth of the river. The ships refused to pay this tax without representation at Connecticut's fort, but Hartford refused to grant it. In response, the Massachusetts Bay Colony solidified its friendship with Springfield by levying a toll on Connecticut Colony ships entering Boston Harbor. Connecticut was largely dependent on sea trade with Boston and therefore permanently dropped its tax on Springfield, but Springfield allied with Boston nonetheless, drawing the first state border across the Connecticut River.\n\nThe Fort at Number 4 in Charlestown, New Hampshire was the northernmost English settlement on the Connecticut River until the end of the French and Indian War in 1763. Abenaki Indians resisted British attempts at colonization, but Colonists began settling north of Brattleboro, Vermont following the war. Settlement of the Upper Connecticut River Valley increased quickly, with population assessments of 36,000 by 1790.\n\nThe area that is now Vermont was claimed by both New Hampshire and New York, and was settled primarily through the issuance of land grants by New Hampshire Governor Benning Wentworth beginning in the 1740s. New York protested these grants, and King George III decided in 1764 that the border between the provinces should be the western bank of the Connecticut River. Ethan Allen, the Green Mountain Boys, and other residents of the disputed area resisted attempts by New York to exercise authority over the area, which resulted in the establishment of the independent Vermont Republic in 1777 and its eventual accession to the United States in 1791 as the fourteenth state. Boundary disputes between Vermont and New Hampshire lasted for nearly 150 years and were finally settled in 1933, when the U.S. Supreme Court reaffirmed King George's boundary as the ordinary low-water mark on the Vermont shore. In some places, the state line is now inundated by the impoundments of dams built after this time.\n\nThe Treaty of Paris (1783) that ended the American Revolutionary War created a new international border between New Hampshire and the Province of Canada at \"northwesternmost headwaters of the Connecticut\". Several streams fit this description, and thus a boundary dispute led to the short-lived Indian Stream Republic, which existed from 1832 to 1835.\nThe broad, fertile Connecticut River Valley attracted agricultural settlers and colonial traders to Hartford, Springfield, and the surrounding region. The high volume and numerous falls of the river led to the rise of industry along its banks during the Industrial Revolution. The cities of Springfield and Hartford in particular became centers of innovation and \"intense and concentrated prosperity.\"\n\nThe Enfield Falls Canal was opened in 1829 to circumvent shallows around Enfield Falls, and the locks built for this canal gave their name to the town of Windsor Locks, Connecticut. The Connecticut River Valley functioned as America's hub of technical innovation into the 20th century, particularly the cities of Springfield and Hartford, and thus attracted numerous railroad lines. The proliferation of the railroads in Springfield and Hartford greatly decreased the economic importance of the Connecticut River. From the late 1800s until today, it has functioned largely as a center of wildlife and recreation.\n\nStarting about 1865, the river was used for massive logging drives from Third Connecticut Lake to initially water powered sawmills near Enfield Falls. Trees cut adjacent to tributary streams including Perry Stream and Indian Stream in Pittsburg, New Hampshire, Halls Stream on the Quebec–New Hampshire border, Simms Stream, the Mohawk River, and the Nulhegan River basin in Essex County, Vermont, would be flushed into the main river by the release of water impounded behind splash dams. Several log drivers died trying to move logs through Perry Falls in Pittsburg. Teams of men would wait at Canaan, Vermont, to protect the bridges from log jams. Men guided logs through a drop along the length of Fifteen-Mile Falls (now submerged under Moore and Comerford reservoirs), and through Logan's Rips at Fitzdale, Mulligan's Lower Pitch, and Seven Islands. The White River from Vermont and Ammonoosuc River from New Hampshire brought more logs into the Connecticut. A log boom was built between Wells River, Vermont, and Woodsville, New Hampshire, to hold the logs briefly and release them gradually to avoid jams in the Ox Bow. Men detailed to this work utilized Woodsville's saloons and red-light district. Some of the logs were destined for mills in Wilder and Bellows Falls, Vermont, while others were sluiced over the Bellows Falls dam. North Walpole, New Hampshire, contained twelve to eighteen saloons, patronized by the log drivers. Mount Tom was the landmark the log drivers used to gauge the distance to the final mills near Holyoke, Massachusetts. These spring drives were stopped after 1915, when pleasure boat owners complained about the hazards to navigation. The final drive included 500 workers controlling 65 million feet of logs. A final pulp drive consisted of 100,000 cords of four-foot logs in 1918. This was to take advantage of the wartime demand.\n\nIn March 1936, due to a winter with heavy snowfall, an early spring thaw and torrential rains, the Connecticut River flooded, overflowing its banks, destroying numerous bridges and isolating hundreds of people who had to be rescued by boat.\n\nThe dam at Vernon, Vermont, was topped by . Sandbagging by the National Guard and local volunteers helped prevent the dam's powerhouse from being overwhelmed, despite blocks of ice breaking through the upstream walls.\n\nIn Northampton, Massachusetts, looting during the flood became a problem, causing the mayor of the city to deputize citizen patrols to protect flooded areas. Over 3,000 refugees from the area were housed in Amherst College and the Massachusetts State Agricultural College (now UMass Amherst).\n\nUnprecedented accumulated ice jams compounded the problems created by the flood, diverting water into unusual channels and damming the river, raising water levels even further. When the jam at Hadley, Massachusetts, gave way, the water crest overflowed the dam at Holyoke, overwhelming the sandbagging there. The village of South Hadley Falls was essentially destroyed, and the southern parts of Holyoke were severely damaged, with 500 refugees.\n\nIn Springfield, Massachusetts, , and of streets, were flooded, and 20,000 people lost their homes. The city lost power, and nighttime looting caused the police to issue a \"shoot on sight\" edict; 800 National Guard troops were brought in to help maintain order. Rescue efforts using a flotilla of boats saved people trapped in upper stories of buildings, bringing them to local fraternal lodges, schools, churches and monasteries for lodging, medical care, and food. The American Red Cross and local, state and Federal agencies, including the WPA and the CCC, contributed aid and manpower to the effort. Flooding of roads isolated the city for a time. When the water receded, it left behind silt-caused mud which in places was thick; the recovery effort in Springfield, at the height of the American Great Depression, took approximately a decade.\n\nOverall, the flood caused 171 deaths and US$500 million (US$ with inflation) in damages. Across the northeast, over 430,000 people were made homeless or destitute by flooding that year.\n\nThe Connecticut River Flood Control Compact between the states of Connecticut, Massachusetts, New Hampshire, and Vermont was established in 1953 to help prevent serious flooding.\n\nThe creation of the Quabbin Reservoir in the 1930s diverted the Swift River, which feeds the Chicopee River, a tributary of the Connecticut. This resulted in an unsuccessful lawsuit by the state of Connecticut against the diversion of its riparian waters.\n\nDemand for drinking water in eastern Massachusetts passed the sustainable supply from the existing system in 1969. Diverting water from the Connecticut River was considered several times, but in 1986 the Massachusetts Water Resources Authority instead undertook a campaign of water conservation. Demand was reduced to sustainable levels by 1989, reaching approximately a 25% margin of safety by 2009.\n\nBy far the largest river ecosystem in New England, the Connecticut River watershed spans five of the six New England states – New Hampshire, Vermont, Massachusetts, Connecticut, as well as small portions of Maine and the Canadian province of Quebec.\n\nThe Connecticut River rises from Fourth Connecticut Lake, a small pond that sits south of the Canada–United States border in the town of Pittsburg, New Hampshire, at an elevation of above sea level. It flows through the remaining Connecticut Lakes and Lake Francis for , all within the town of Pittsburg, and then widens as it delineates of the border between New Hampshire and Vermont. The river drops more than in elevation as it winds south to the border of Massachusetts where it sits above sea level.\n\nThe region along the river upstream and downstream from Lebanon, New Hampshire, and White River Junction, Vermont, is known as the \"Upper Valley\". The exact definition of the region varies, but it generally is considered to extend south to Windsor, Vermont and Cornish, New Hampshire, and north to Bradford, Vermont and Piermont, New Hampshire. In 2001, The Trust for Public Land purchased of land in New Hampshire from International Paper, allowing the Connecticut Lakes Headwaters Partnership Task Force to plan the future protection of the land. The property spans the towns of Pittsburg, Clarksville, and Stewartstown, New Hampshire, nearly 3 percent of the land in the state of New Hampshire. The Trust for Public Land worked in partnership with the Society for the Protection of New Hampshire Forests, The Nature Conservancy of New Hampshire, and others to raise around $42 million. A conservation easement over of the property prohibits development of the land while allowing public access. The forest is managed by the Lyme Timber Company, and the conservation easement over the land ensures sustainable forest management of the property.\n\nFollowing the most recent ice age, the Middle Connecticut River Valley sat at the bottom of Lake Hitchcock. Its lush greenery and rich, almost rockless soil comes from the ancient lake's sedimentary deposits. In the Middle Connecticut region, the river reaches its maximum depth – – at Gill, Massachusetts, around the French King Bridge, and its maximum width – – at Longmeadow, directly across from the Six Flags New England amusement park. The Connecticut's largest falls – South Hadley Falls – features a vertical drop of . Lush green forests and agricultural hamlets dot this middle portion of the Connecticut River; however, the region is best known for its numerous college towns, such as Northampton, South Hadley, and Amherst, as well as the river's most populous city, Springfield. The city sits atop bluffs beside the Connecticut's confluence with two major tributaries, the Chicopee River to the east and Westfield River to the west.\n\nThe Connecticut River is influenced by the tides as far north as Enfield Rapids in Windsor Locks, Connecticut, approximately north of the river's mouth. Two million residents live in the densely populated Hartford-Springfield region, which stretches roughly between the college towns of Amherst, Massachusetts, and Middletown, Connecticut. Hartford, the Connecticut River's second largest city and only state capital, is located at the southern end of this region on an ancient floodplain that stretches to Middletown.\n\n south of Hartford, at Middletown, the Lower Connecticut River section begins with a narrowing of the river, and then a sharp turn southeast. Throughout southern Connecticut, the Connecticut passes through a thinly populated, hilly, wooded region before again widening and discharging into Long Island Sound between Old Saybrook and Old Lyme. Due to the presence of large, shifting sandbars at its mouth, the Connecticut is the only major river in the Northeastern United States without a port at its mouth.\n\nThe Connecticut River carries a heavy amount of silt, especially during the spring snow melt, from as far north as Quebec. This heavy silt concentration manifests in a large sandbar near the Connecticut's mouth, which has, historically, provided a formidable obstacle to navigation. Due to the difficulty it presents to ships, the Connecticut is one of the few major rivers in the United States without a major city at its mouth. The Connecticut's major cities – Hartford and Springfield – lie upriver, respectively.\n\nThe Nature Conservancy named the Connecticut River's tidelands one of the Western Hemisphere's \"40 Last Great Places\", while the Ramsar Convention on Wetlands listed its estuary and tidal wetlands complex as one of 1,759 wetlands of international importance.\n\nIn 1997, the Connecticut River was designated one of only 14 American Heritage Rivers, which recognized its \"distinctive natural, economic, agricultural, scenic, historic, cultural and recreational qualities.\" In May 2012, the Connecticut River was designated America's first National Blueway, in recognition of the restoration and preservation efforts on the river.\n\nThe Connecticut River's flow is slowed by main stem dams, which create a series of slow-flowing basins from Lake Francis Dam in Pittsburg, New Hampshire, to the Holyoke Dam at South Hadley Falls in Massachusetts. Among the most extensively dammed rivers in the United States, the Connecticut may soon flow at a more natural pace, according to scientists at the University of Massachusetts at Amherst, who have devised a computer that – \"in an effort to balance human and natural needs\" – coordinates the holding and releasing of water between the river's 54 largest dams.\n\nThe Connecticut River watershed encompasses , connecting 148 tributaries, including 38 major rivers and numerous lakes and ponds. Major tributaries include (from north to south) the Passumpsic, Ammonoosuc, White, Black, West, Ashuelot, Millers, Deerfield, Chicopee, Westfield, and Farmington rivers. The Swift River, a tributary of the Chicopee, has been dammed and largely replaced by the Quabbin Reservoir which provides water to the Massachusetts Water Resources Authority district in eastern Massachusetts, including Boston and its metropolitan area.\n\nThere are several species of anadromous and catadromous fish, including brook trout, winter flounder, blueback herring, alewife, rainbow trout, large brown trout, American shad (\"Alosa sapidissima\"), hickory shad, smallmouth bass, Atlantic sturgeon, striped bass (\"Morone saxatilis\"), American eel, sea lamprey, and endangered shortnose sturgeon and dwarf wedgemussels. Additionally, the United States Fish and Wildlife Service has repopulated the river with another species of migratory fish, the Atlantic salmon, which for more than 200 years had been extinct from the river due to damming. Several fish ladders and fish elevators have been built to allow fish to resume their natural migration upriver each spring.\n\nFresh and brackish water residents of the main branch and tributaries include common carp, white catfish, brown bullhead, fallfish, yellow perch, smallmouth bass, largemouth bass, northern pike, chain pickerel, bluegill, pumpkinseed sunfish, golden shiner, and rock bass.\n\nMuch of the beginning of the river's course in the town of Pittsburg is occupied by the Connecticut Lakes, which contain lake trout and landlocked salmon. Landlocked salmon make their way into the river during spring spawning runs of bait fish and during their fall spawn. The river has fly-fishing-only regulations on of river. Most of the river from Lake Francis south is open to lure and bait as well. Two tail-water dams provide cold river water for miles downstream, making for bountiful summer fishing on the Connecticut.\n\nAfter the first major dam was built near Turners Falls, Massachusetts, thirteen additional dams have ended the Connecticut River's great anadromous fish runs. Fish ladders constructed since the first fish passage in 1980 at Turners Falls, have enabled migrating fish to return to some of their former spawning grounds. In addition to dams, warm water discharges between 1978 and 1992 from Vermont Yankee Nuclear Power Plant in Vernon, Vermont released water up to degrees and the thermal plume reached downstream to Holyoke. This thermal pollution appears to be associated with an 80% decline in American shad fish numbers from 1992 to 2005 at Holyoke dam. This decline may have been exacerbated by over-fishing in the mid-Atlantic and predation from resurging striped bass populations. The nuclear plant was closed at the end of 2014 but the 2015 shad run at Vernon numbered only 42,000 shad.\n\nThere are 12 species of freshwater mussels. Of those, 11 occur in the mainstem of the Connecticut, all but the brook floater, which is found only in small streams and rivers. Species diversity is higher in the southern part of the watershed (Connecticut and Massachusetts) than in the northern part (Vermont and New Hampshire), largely due to differences in stream gradient and substrate. Eight of the 12 species in the watershed are listed as endangered, threatened, or of Special Concern in one or more of the states in the watershed.\n\nThe mouth of the river up to Essex is thought to be one of the busiest stretches of waterway in Connecticut. Some local police departments and the state Environmental Conservation Police patrol the area a few times a week. Some towns keep boats available if needed. In Massachusetts, the most active stretch of the Connecticut River is centered on the Oxbow, north of Springfield in the college town of Northampton.\n\nCamping is available along much of the river, for non-motorized boats, via the Connecticut River Paddlers' Trail. The Paddlers' Trail currently includes campsites on over of the river.\n\nThe Water Quality Act of 1965 had a major impact on controlling water pollution in the Connecticut River and its tributaries.\n\nSince then, the river has been restored from Class D to Class B (fishable and swimmable). Many towns along the Lower Connecticut River have enacted a cap on further development along the banks, so that no buildings may be constructed except on existing foundations. Currently, a website provides water quality reports twice a week, indicating whether various portions of the river are safe for swimming, boating and fishing.\n\nListed from south to north by location of mouth:\n\nThe Connecticut River is a barrier to travel between western and eastern New England. Several major transportation corridors cross the river including Amtrak's Northeast Corridor, Interstate 95 (Connecticut Turnpike), Interstate 90 (Massachusetts Turnpike), Interstate 89, Interstate 93, and Interstate 84. In addition, Interstate 91, whose route largely follows the river north-south, crosses it twice – once in Connecticut and once in Massachusetts.\n\n\n\n\n"}
{"id": "39314328", "url": "https://en.wikipedia.org/wiki?curid=39314328", "title": "Eco-industrial development", "text": "Eco-industrial development\n\nEco-industrial development (EID) is a framework for industry to develop while reducing its impact on the environment. It uses a closed loop production cycle to tackle a broad set of environmental challenges such as soil and water pollution, desertification, species preservation, energy management, by-product synergy, resource efficiency, air quality, etc.\n\nMutually beneficial connections among industry, natural systems, energy, material and local communities become central factors in designing industrial production processes.\n\nThe approach itself is largely voluntary and market-driven but often pressed ahead by favorable government treatment or efforts of development co-operation.\n\nSince the early 1990s the idea of EID evolved from biological symbiosis. This concept was adapted by industrial ecologists in the search for innovative approaches to solve problems of waste, energy shortage and degradation of the environment. A continuous approach towards improving both environmental and economic outcomes is used.\n\nIn 1992, the international community officially connected development co-operation to sustainable environmental protection for the first time. At the United Nations Conference on Environment and Development (UNCED) in Rio de Janeiro, Brazil nearly 180 states signed the conference’s Rio Declaration. Although non-binding, the Rio Declaration on Environment and Development laid out 27 principles that shall guide the increasing inter-connectedness of development cooperation and sustainability. Moreover, the documents drafting was accompanied by a presentation describing the idea of eco-industrial development for the first time.\n\nIn the following years, EID became popular throughout the United States. The recently elected Clinton administration installed a summit of business, labor, government and environmental protection representatives to further develop the approach. This summit established the idea of eco-industrial parks but soon realized that at first a more efficient management of raw materials, energy and waste has to be achieved.\n\nSince then, the broad goals and application principles of EID have hardly changed and only became adapted to the rapid technological progress.\n\nIn 2012 the IGEP Foundation, for the promotion of trade, published a report called \"Pathway to Eco Industrial Development in India – Concepts and Cases\".\n\nThe field is researched by the Nation Centre for Eco-Industrial Development, a joint project by the University of Southern California and Cornell University.\n\nThe primary goal of eco-industrial development is a significant and continuous improvement in both business and environmental performance. Herein, the notion of industry not only relates to private-sector manufacturing but also covers state-owned enterprise, the service sector as well as transportation. EID’s twin guideline is reflected specifically in the “eco” of eco-industrial as it resembles ecology (decrease in pollution and waste) and economy (increase in commercial success) at the same time. In order to build a framework of defining an enterprise’s sustainable performance at the micro level, resource use optimization, minimization of waste, cleaner technologies and pollution limits are used in achieving a broad range of goals in EID: \nEco-industrial development hence explores the possibility of improvement at the local level. In unique case-to-case analyses, particular geography, human potential or business climate are investigated. In contrast to the widespread race for top-down governmental support such as tax cuts, EID emphasizes locally achievable success and rooms for improvement. As a result, purposeful enforcements of action plans can make a large difference by optimizing the interaction of business, community and ecological systems.\n\nEco-industrial development includes and employs four major conceptual instruments. Each of the approaches intends to combine the seemingly antithetic processes of industrial development and bolstering sustainability.\n\n\n\n"}
{"id": "7372773", "url": "https://en.wikipedia.org/wiki?curid=7372773", "title": "Employment discrimination law in the United States", "text": "Employment discrimination law in the United States\n\nEmployment discrimination law in the United States derives from the common law, and is codified in numerous state and federal laws, particularly the Civil Rights Act of 1964, as well as in the ordinances of counties and municipalities. These laws prohibit discrimination based on certain characteristics or protected categories. The United States Constitution also prohibits discrimination by federal and state governments against their public employees. Discrimination in the private sector is not directly constrained by the Constitution, but has become subject to a growing body of federal and state law. Federal law prohibits discrimination in a number of areas, including recruiting, hiring, job evaluations, promotion policies, training, compensation and disciplinary action. State laws often extend protection to additional categories or employers.\n\nUnder Federal law, employers generally cannot discriminate against employees on the basis of:\n\nSome studies have found declining gaps in earnings by race as access to high quality education has improved and anti-discrimination and affirmative action policies have been implemented.\n\nThe United States Constitution does not directly address employment discrimination, but its prohibitions on discrimination by the federal government have been held to protect federal government employees.\n\nThe Fifth and Fourteenth Amendments to the United States Constitution limit the power of the federal and state governments to discriminate. The Fifth Amendment has an explicit requirement that the federal government does not deprive individuals of \"life, liberty, or property\", without due process of the law. It also contains an implicit guarantee that the Fourteenth Amendment explicitly prohibits states from violating an individual's rights of due process and equal protection. In the employment context, these Constitutional provisions would limit the right of the state and federal governments to discriminate in their employment practices by treating employees, former employees, or job applicants unequally because of membership in a group (such as a race or sex). Due process protection requires that government employees have a fair procedural process before they are terminated if the termination is related to a \"liberty\" (such as the right to free speech) or property interest. As both Due Process and Equal Protection Clauses are passive, the clause that empowers Congress to pass anti-discrimination bills (so they are not unconstitutional under Tenth Amendment) is Section 5 of Fourteenth Amendment.\n\nEmployment discrimination or harassment in the private sector is not unconstitutional because Federal and most State Constitutions do not expressly give their respective government the power to enact civil rights laws that apply to the private sector. The Federal government's authority to regulate a private business, including civil rights laws, stems from their power to regulate all commerce between the States. Some State Constitutions do expressly afford some protection from public and private employment discrimination, such as Article I of the California Constitution. However, most State Constitutions only address discriminatory treatment by the government, including a public employer.\n\nAbsent of a provision in a State Constitution, State civil rights laws that regulate the private sector are generally Constitutional under the \"police powers\" doctrine or the power of a State to enact laws designed to protect public health, safety and morals. All States must adhere to the Federal Civil Rights laws, but States may enact civil rights laws that offer additional employment protection.\n\nFor example, some State civil rights laws offer protection from employment discrimination on the basis of sexual orientation, gender identity or political affiliation, even though such forms of discrimination are not yet covered in federal civil rights laws.\n\nFederal law governing employment discrimination has developed over time.\n\nThe Equal Pay Act amended the Fair Labor Standards Act in 1963. It is enforced by the Wage and Hour Division of the Department of Labor. The Equal Pay Act prohibits employers and unions from paying different wages based on sex. It does not prohibit other discriminatory practices in hiring. It provides that where workers perform equal work in the corner requiring \"equal skill, effort, and responsibility and performed under similar working conditions,\" they should be provided equal pay. The Fair Labor Standards Act applies to employers engaged in some aspect of interstate commerce, or all of an employer's workers if the enterprise is engaged as a whole in a significant amount of interstate commerce.\n\nTitle VII of the Civil Rights Act of 1964 prohibits discrimination in many more aspects of the employment relationship. \"Title VII created the Equal Employment Opportunity Commission (EEOC) to administer the act\". It applies to most employers engaged in interstate commerce with more than 15 employees, labor organizations, and employment agencies. Title VII prohibits discrimination based on race, color, religion, sex or national origin. It makes it illegal for employers to discriminate based upon protected characteristics regarding terms, conditions, and privileges of employment. Employment agencies may not discriminate when hiring or referring applicants, and labor organizations are also prohibited from basing membership or union classifications on race, color, religion, sex, or national origin. The Pregnancy Discrimination Act amended Title VII in 1978, specifying that unlawful sex discrimination includes discrimination based on pregnancy, childbirth, and related medical conditions.\nA related statute, the Family and Medical Leave Act, sets requirements governing leave for pregnancy and\npregnancy-related conditions.\n\nExecutive Order 11246 in 1965 \"prohibits discrimination by federal contractors and subcontractors on account of race, color, religion, sex, or national origin [and] requires affirmative action by federal contractors\".\n\nThe Age Discrimination in Employment Act (ADEA), enacted in 1968 and amended in 1978 and 1986, prohibits employers from discriminating on the basis of age. The prohibited practices are nearly identical to those outlined in Title VII, except that the ADEA protects workers in firms with 20 or more workers rather than 15 or more. An employee is protected from discrimination based on age if he or she is over 40. Since 1978, the ADEA has phased out and prohibited mandatory retirement, except for high-powered decision-making positions (that also provide large pensions). The ADEA contains explicit guidelines for benefit, pension and retirement plans. Though ADEA is the center of most discussion of age discrimination legislation, there is a longer history starting with the abolishment of \"maximum ages of entry into employment in 1956\" by the United States Civil Service Commission. Then in 1964, Executive Order 11141 \"established a policy against age discrimination among federal contractors\".\n\nThe Rehabilitation Act of 1973 prohibits employment discrimination on the basis of disability by the federal government, federal contractors with contracts of more than $10,000, and programs receiving federal financial assistance. It requires affirmative action as well as non-discrimination. Section 504 requires reasonable accommodation, and Section 508 requires that electronic and information technology be accessible to disabled employees.\n\nThe Black Lung Benefits Act of 1973 prohibits discrimination by mine operators against miners who suffer from \"black lung disease\" (pneumoconiosis).\n\nThe Vietnam Era Readjustment Act of 1974 \"requires affirmative action for disabled and Vietnam era veterans by federal contractors\".\n\nThe Bankruptcy Reform Act of 1978 prohibits employment discrimination on the basis of bankruptcy or bad debts.\n\nThe Immigration Reform and Control Act of 1986 prohibits employers with more than three employees from discriminating against anyone (except an unauthorized immigrant) on the basis of national origin or citizenship status.\n\nThe Americans with Disabilities Act of 1990 (ADA) was enacted to eliminate discriminatory barriers against qualified individuals with disabilities, individuals with a record of a disability, or individuals who are regarded as having a disability. It prohibits discrimination based on real or perceived physical or mental disabilities. It also requires employers to provide reasonable accommodations to employees who need them because of a disability to apply for a job, perform the essential functions of a job, or enjoy the benefits and privileges of employment, unless the employer can show that undue hardship will result. There are strict limitations on when an employer can ask disability-related questions or require medical examinations, and all medical information must be treated as confidential. A disability is defined under the ADA as a mental or physical health condition that \"substantially limits one or more major life activities.\"\n\nThe Nineteenth Century Civil Rights Acts, amended in 1993, ensure all persons equal rights under the law and outline the damages available to complainants in actions brought under Title VII of the Civil Rights Act of 1964, the Americans with Disabilities Act, and the 1973 Rehabilitation Act.\n\nThe Genetic Information Nondiscrimination Act of 2008 bars employers from using individuals' genetic information when making hiring, firing, job placement, or promotion decisions.\n\nThe proposed US Equality Act of 2015 would ban discrimination on the basis of sexual orientation or gender identity. , 28 US states do not explicitly include sexual orientation and 29 US states do not explicitly include gender identity within anti-discrimination statutes.\n\nThe regulation of LGBT employment discrimination in the United States varies by jurisdiction. Many states and localities prohibit bias in hiring, promotion, job assignment, termination, and compensation, as well as harassment on the basis of one's sexual orientation. Fewer extend those protections to cover sexual identity. Some cover government employees but do not extend their protections to the private sector. Protections at the national level are limited.\n\nThere is no federal statute addressing employment discrimination based on sexual orientation or gender identity. During President Obama's tenure Congress came close to enactment of the Employment-Non-Discrimination Act (ENDA), a federal statute explicitly prohibiting discrimination against LGBT workers. The \"Washington Blade\" noted that the Employment Non-Discrimination Act (ENDA) has had strong bipartisan support, and even Democratic leadership has signed on. Although the Senate passed ENDA it did not survive the House. In March 2014, 195 lawmakers, 148 House members, and 47 Senators, all Democrats, signed an appeal to President Obama, encouraging him to enact protections for LGBT workers in an executive order. (Executive Order 13672.)\n\nFederal courts have generally agreed that Title VII of the Civil Rights Act of 1964, which prohibits sex discrimination in the workplace, does not prohibit discrimination on the basis of sexual orientation although some courts following Pricewaterhouse v. Hopkins support protecting transgender employees from discrimination as a form of sex stereotyping. In early 2018 two federal appellate courts (Second Circuit and Seventh Circuit) reversed circuit precedent on sexual orientation discrimination to hold Title VII prohibits sexual orientation discrimination. The Sixth Circuit also reversed precedent finding Title VII prohibits transgender discrimination in the workplace.\n\nAccording to Crosby Burns and Jeff Krehely: \"Studies show that anywhere from 15 percent to 43 percent of gay people have experienced some form of discrimination and harassment at the workplace. Moreover, a staggering 90 percent of transgender workers report some form of harassment or mistreatment on the job.\" Many people in the LGBT community have lost their job, including Vandy Beth Glenn, a transgender woman who claims that her boss told her that her presence may make other people feel uncomfortable.\n\nAlmost half of the United States has laws banning the discrimination of gender non-conforming and transgender people in both public and private workplaces. A few more states ban LGBT discrimination in only public workplaces. Some opponents of these laws believe that it would intrude on religious liberty, even though these laws are focused more on discriminatory actions, not beliefs. Courts have also identified that these laws do not infringe free speech or religious liberty.\n\nState statutes also provide extensive protection from employment discrimination. Some laws extend similar protection as provided by the federal acts to employers who are not covered by those statutes. Other statutes provide protection to groups not covered by the federal acts. Some state laws provide greater protection to employees of the state or of state contractors.\n\nThe following table lists protected categories not included in federal law. Age is included as well, since federal law only covers workers over 40.\n\nIn addition,\n\nEmployees of federal and state governments have additional protections against employment discrimination.\n\nThe Civil Service Reform Act of 1978 prohibits discrimination in federal employment on the basis of conduct that does not affect job performance. The Office of Personnel Management has interpreted this as prohibiting discrimination on the basis of sexual orientation. In June 2009, it was announced that the interpretation would be expanded to include gender identity.\n\nEmployers are generally allowed to consider characteristics that would otherwise be discriminatory if they are bona fide occupational qualifications (BFOQ). For example, a manufacturer of men's clothing may lawfully advertise for male models.\n\n“Religious discrimination is treating individuals differently in their employment because of their religion, their religious beliefs and practices, and/or their request for accommodation (a change in a workplace rule or policy) of their religious beliefs and practices. It also includes treating individuals differently in their employment because of their lack of religious belief or practice” (Workplace Fairness). According to The U.S. Equal Employment Opportunity Commission, employers are prohibited from refusing to hire an individual based on their religion- alike race, sex, age, and disability. If an employee believes that they have experienced religious discrimination, they should address this to the alleged offender. On the other hand, employees are protected by the law for reporting job discrimination and are able to file charges with the EEOC. Some locations in the U.S. now have clauses that ban discrimination against atheists. The courts and laws of the United States give certain exemptions in these laws to businesses or institutions that are religious or religiously-affiliated, however, to varying degrees in different locations, depending on the setting and the context; some of these have been upheld and others reversed over time.\n\nTitle VII of the Civil Rights Act of 1964 explicitly permits discrimination against members of the Communist Party.\n\nThe military has faced criticism for prohibiting women from serving in combat roles. In 2016, however, the law was amended to allow them to serve.\n\nIn the article posted on the PBS website, Henry Louis Gates Jr. writes about the way in which black men were treated in the military during the 1940s. According to Gates, during that time the whites gave the African Americans a chance to prove themselves as Americans by having them participate in the war. The National Geographic website states, however, that when black soldiers joined the Navy, they were only allowed to work as servants; their participation was limited to the roles of mess attendants, stewards, and cooks. Even when African Americans wanted to defend the country they lived in, they were denied the power to do so.\n\nEmployment practices that do not directly discriminate against a protected category may still be illegal if they produce a disparate impact on members of a protected group. Title VII of the Civil Rights Act of 1964 prohibits employment practices that have a discriminatory impact, unless they are related to job performance.\n\nThe Act requires the elimination of artificial, arbitrary, and unnecessary barriers to employment that operate invidiously to discriminate on the basis of race, and, if, as here, an employment practice that operates to exclude Negroes cannot be shown to be related to job performance, it is prohibited, notwithstanding the employer's lack of discriminatory intent.\n\nHeight and weight requirements have been identified by the EEOC as having a disparate impact on national origin minorities.\n\nHowever, when defending against a disparate impact claim that alleges age discrimination, an employer does not need to demonstrate necessity; rather, it must simply show that its practice is reasonable.\n\nThe Equal Employment Opportunity Commission (EEOC) interprets and enforces the Equal Pay Act, Age Discrimination in Employment Act, Title VII of the Civil Rights Act of 1964, Title I and V of the Americans With Disabilities Act, Sections 501 and 505 of the Rehabilitation Act, and the Civil Rights Act of 1991. The Commission was established by the Civil Rights Act of 1964. Its enforcement provisions are contained in section 2000e-5 of Title 42, and its regulations and guidelines are contained in Title 29 of the Code of Federal Regulations, part 1614. Persons wishing to file suit under Title VII and/or the ADA must exhaust their administrative remedies by filing an administrative complaint with the EEOC prior to filing their lawsuit in court.\n\nThe Office of Federal Contract Compliance Programs enforces Section 503 of the Rehabilitation Act, which prohibits discrimination against qualified individuals with disabilities by federal contractors and subcontractors.\n\nUnder Section 504 of the Rehabilitation Act, each agency has and enforces its own regulations that apply to its own programs and to any entities that receive financial assistance.\n\nThe Office of Special Counsel for Immigration-Related Unfair Employment Practices (OSC) enforces the anti-discrimination provisions of the Immigration and Nationality Act (INA), 8 U.S.C. § 1324b, which prohibits discrimination based on citizenship status or national origin.\n\nState Fair Employment Practices (FEP) offices take the role of the EEOC in administering state statutes.\n\n\n"}
{"id": "58874307", "url": "https://en.wikipedia.org/wiki?curid=58874307", "title": "Enrique Bolín", "text": "Enrique Bolín\n\nEnrique Bolín Pérez-Argemí (27 February 1940 – 17 October 2018) was a Spanish industrialist and People's Party politician who served as Mayor of Benalmádena and Senator. \n\nIn 1989 he was sentenced to prison for the crime of possession of cocaine, for which he was expelled from the party despite reducing the penalty to a fine, and in 2008 he was sentenced to eight years of disqualification for a crime of urban trespass.\n\nHe was the son of Enrique Bolín Bidwell, promoter of tourism and hospitality on the Costa del Sol, and nephew of Luis Bolín, correspondent in London of the newspaper ABC, who rented the Dragon Rapide plane that took Francisco Franco from the Canaries to Tetouan so he could join to the coup d'état in Spain in July 1936 that led to the Spanish Civil War and the fall of the Second Republic.\n"}
{"id": "53661720", "url": "https://en.wikipedia.org/wiki?curid=53661720", "title": "European Journal of Health Law", "text": "European Journal of Health Law\n\nEuropean Journal of Health Law is published by Brill Publishers. It was first published in 1994 and replaced a journal entitled \"Medicine and Law\" to reflect a move away from focusing only on clinical negligence litigation. The journal publishes peer-reviewed scholarly articles, notes, reports, and book reviews. It is currently edited by Jos Dute, Herman Nys (Editor-in-chief), and Henriette Roscam Abbing. It is the official journal of the European Association of Health Law.\n"}
{"id": "33182259", "url": "https://en.wikipedia.org/wiki?curid=33182259", "title": "Heritage Railway Stations Protection Act", "text": "Heritage Railway Stations Protection Act\n\nThe Heritage Railway Stations Protection Act was enacted in 1988 in response to a long-standing and widespread concern that Canada’s heritage railway stations were not being protected. Bill C-205, An Act to protect heritage railway stations, was proposed by MP Gordon Taylor in a private member's bill which received support of all parties in the House of Commons.\n\nThe railway was once the backbone of Canada. This changed with widespread adoption of the automobile. The Trans-Canada Highway opened in 1962; Highway 2, the congested Main Street in every town in the busy Quebec City–Windsor Corridor, was bypassed by the 401/20 freeway in 1968. Passenger train ridership dropped from a World War II peak of 60 million to less than 5 million in 1977. Federally owned Via Rail provided CN and CP an exit from the long-unprofitable passenger rail business in 1978. The railways retained ownership of tracks, railway stations and freight operations. A long series of Via Rail budget cuts from 1981 onward eventually left countless small villages stranded in the wilderness with no passenger rail service.\n\nThe railways had little incentive to preserve or re-purpose abandoned passenger stations. Municipalities found provincial heritage preservation laws inadequate to protect railway history as interprovincial rail is within federal jurisdiction. \nCP's West Toronto station, closed when its last passenger train was rerouted in 1978, was unlawfully demolished on November 25, 1982\nas one of multiple closed stations demolished in that era, occasionally using similar tactics.\n\nDesignation of heritage railway stations and specific heritage features is made on the recommendation of the Historic Sites and Monuments Board of Canada by the minister responsible for Parks Canada. Requests to the Board, in turn, typically originate from local entities such as municipalities and historic preservation groups.\n\nThe protection of heritage railway stations applies to all railway companies under the \"Canada Transportation Act\". No railway company may in any way alter, demolish, or transfer ownership of a designated heritage railway station without the authorization of the Government of Canada. There is a process in place through which any proposed changes can be reviewed and approved; public notice must be given to allow objections to be heard.\n\nViolations of the \"Act\" are punishable by fines of not less than fifty thousand dollars and not more than one million dollars.\n\nEligibility is limited to stations owned by federally licensed railway companies. A municipally owned station on an active rail line of federal importance (such as the 1856 Napanee railway station) therefore would not qualify regardless of historic notability or age. The protection ends when a historic station is sold.\n\nThe \"Act\" only protects railway stations; it does not extend to other historic railway structures, such as roundhouses.\n\nThe legislation also does nothing to require a railway to maintain a property to Heritage Canada guidelines or repair any damage, even as the structure declines to the point of violating municipal standards. By inaction, a railway can leave a historic structure in ruins. Kingston, Ontario mayor Mark Gerretsen has denounced this situation as a \"loophole\" as an 1856 Grand Trunk Railway station in that city is designated as being historic but \"when CN lost its Crown corporation status they put in legislation that says if the building is ever sold the normal heritage act kicks in. Until it is sold, CN is not required to maintain it.\"\n\n\n"}
{"id": "20838049", "url": "https://en.wikipedia.org/wiki?curid=20838049", "title": "IT-Political Association of Denmark", "text": "IT-Political Association of Denmark\n\nThe IT-Political Association (Danish: IT-Politisk Forening, commonly known as IT-Pol) is a Danish non-profit NGO, which works to collect information on IT and convey this to politicians and the society to get the best possible grounds for legislation. The association is independent of political parties and communicates with politicians from all political parties. Membership is open to anyone.\n\nIT-Pol is the Danish equivalent of the Electronic Frontier Foundation.\n\nThe Free Software privacy CD, Polippix, was started by and is still maintained by IT-Political Association.\n\nIT-Pol is primarily concerned with issues that restricts citizens and innovation.\nDenmark is one of the countries in which most ISPs filters DNS traffic by default. IT-Pol regards this policy as censorship, as the filter filters content that is legal to view in Denmark.\n\nThe Danish surveillance law, was actively fought by IT-Pol. IT-Pol developed a CD called Polippix that can mitigate most of the Internet related surveillance included in the surveillance law.\n\nIT-Pol believes software patents are not beneficial for innovation and therefore fights Software Patents.\n\nIT-Pol believes the balance between society and rights holder should be pushed more towards the society.\n\nIT-Pol believes Digital Rights Management causes problems for normal citizens and therefore is not in the interest of the citizens. IT-Pol therefore fights DRM.\n\nIT-Pol believes open standards will foster innovation and remove lock-in. IT-Pol therefore promotes Open Standards and fights proprietary standards.\n\nIT-Pol believes E-voting should only be allowed if the election has an analog audit trail (paper trail).\n\nIT-Pol believes the public sector should use IT that makes interoperation with the citizens easier.\n\nIT-Pol supports the ban on E-mail spam.\n"}
{"id": "32845646", "url": "https://en.wikipedia.org/wiki?curid=32845646", "title": "I Am Equal", "text": "I Am Equal\n\nI Am Equal is a photo documentary created by Jason Beckett and fashion photographer Matt Spencer in late 2009. The project has the stated intention of collecting more than 100,000 individual photos from 175 cities around the world and using them to build one of the largest photo mosaics in history. In 2011, the project launched the official world tour in Sacramento, California. The project is estimated to take more than 7 years to complete and has the ultimate goal of unveiling an 8,000sq/ft mosaic in Washington DC containing all the photos collected during the world tour.\n\nThe documentary was created by Jason Beckett and fashion photographer Matt Spencer who said the campaign was meant to encourage individuals to get more active in educating, inspiring, and empowering their friends and family to make a positive difference in their communities and the world.\n\nCreated in Salt Lake City, Utah in late 2009, the campaign was developed in response to the founder's perceptions of a general social apathy prevailing in the world. They built the documentary with the intention of giving participants a reason to talk about the unique issues or causes they support, and to encourage those participants to take an active roll in improving their community.\n\nIn December 2009 Beckett and Spencer conceptualized the documentary project as a world tour campaign that would visit approximately 25 cities a year for 7 years and capture as many as 100,000 individual photos of people from all walks of life.\n\nBeginning in January 2010, Spencer started taking photos and testing the concept at his studio in Salt Lake City, Utah with only a few dozen photos at a time while Beckett started to build the associated websites and social media pages .\n\nIn January 2011, after 8 small events in Utah, the project launched its official world tour in Sacramento, California at The Citizen Hotel.\n\nTo participate in the campaign, individuals are encouraged to wear a solid brightly colored shirt and go to a public photo event in their area where a temporary tattoo with the logo \"I AM =\" is applied to the palm of their hand. They stand in front of the camera with the instructions to have the palm of their hand facing the camera as close to the face as possible, and they may be as creative as they want. The photographer snaps the photo and the entire process takes less than 5 minutes. Two weeks after the photo event, each participant receives an email with instructions on how to find their photo in the online gallery and social networks along with ideas on how to share it with friends and family. Each individual is also invited to share a \"PhotoStory\" as part of the photo essay project, where participants discuss the unique issues and causes they support.\n\nThe project creators said it is their first priority to ensure that it represents all people, issues, and causes rather than just the popular equality topic of the day. The expressed intention of the campaign is to get participants to speak up and discuss, with friends and family, the humanitarian, civil rights, conservation, and equality issues they support. They point out that through history the conversation of \"equality\" has had many causal champions such as the Women's Suffragette Movement, the Abolitionist movement, the Women's Rights movement, the Civil Rights, and the Gay & Lesbian movement, so the I Am Equal Photo Documentary was built to connect all of the issues of equality, human rights, civil liberties, and conservation into one massive conversation of mutual respect for all people while uniting individual participants in a common initiative to break a world record.\n\nSome of the issues and causes already represented by individuals participating in the I AM EQUAL Photo Documentary include autism, marriage equality, drug addiction, immigration reform, atheism, religious freedom, teen suicide, Downs Syndrome, gender equality, racism, poverty, incest rape, gay adoption, deaf/hearing impaired, bigotry, pansexuality, obesity, free speech, senior rights.\n\nThe campaign leverages the popularity of social networks to fuel the viral expansion of the project; participants are encouraged to use their photo on social media networks as a way to initiate conversations about the issue or cause represented by the individual. Some participants have taken their photo beyond the social networks by printing it on business cards or framing it in their house as a way to open a casual dialogue about their participation in the campaign.\n\nThe project founders assert that the simple act of sharing the photo or putting it on display may be all that is needed to open new conversations with co-workers, friends, family, and even perfect strangers about the big and small issues that these participants feel are facing the world today. Some participants have suggested that their I AM EQUAL photo has been an effective way to begin a dialogue on weightier human rights issues such as female genital mutilation, sex trafficking, rape incest, polygamy, and many other topics they feel would not normally be discussed in casual conversations.\n\nIn conjunction with Mayor Kevin Johnson's office and coordinating with the local Pride! Center, NAACP, Big Brothers Big Sisters, and the United Way, the photo documentary launched its first official tour stop on January 6, 2011, at The Citizen Hotel in Sacramento, California, the city TIME Magazine voted it to be the most diverse city in America.\n\nThe project returned to Salt Lake City and held a general public photo event on February 5, 2011, at The Sheraton Downtown Hotel where an additional 650 photos were added to the documentary collection. The project made its way to Las Vegas, Nevada, in partnership with MGM Resorts International for an event at The New York New York Hotel & Casino on February 19, 2011, where more than 500 resort employees participated in the documentary project along with the then Mayor Oscar Goodman, County Commissioner Chris Giunchigliani, the dance troop The Jabbawockeez, as well as Terry Fator, and the Las Vegas cast of The Lion King at Mandalay Bay. While in Las Vegas, project founder Jason Beckett was invited to discuss the photo documentary project as a speaker at the annual Martin Luther King Jr. Day celebrations, Jazzitudes at UNLV.\n\nThe project made its first stop outside the United States in Calgary, Alberta, Canada on May 28, 2011. During this stop, hundreds participated in the project including United States Olympic Gold Medalist, Steve Mesler on behalf of his non-profit organization Classroom Champions. Local service groups and organizations including the United Way of Canada, Child Find Alberta, AIDS Calgary, and the Calgary Scope Society all participated in the documentary project.\n\nWorking with the North Texas chapter of Get Equal, the I Am Equal Photo Documentary set up at the Aloft Dallas Hotel and took photos of more than 300 people. Project founder Beckett was invited to address the assembled crowd at the annual North Texas March for Equality on the steps of City Hall as the keynote speaker for the event.\n\nThe project was invited to the University of North Florida as part of their first annual 'Week of One' diversity celebration, created in part as a vehicle to showcase the project and allow students the opportunity to take part in the record-breaking campaign.\n\nIn February, the campaign made stops in Raleigh, North Carolina, Knoxville, Tennessee, and Columbus, Ohio. While in Tennessee, the project founders made a detour to stop in the small town of Whitwell to include this community of 1,600 people in the project. The founders wanted to include the people responsible for creating the Children's Holocaust Memorial (Paper Clips Project), created by students at the local middle school who collected more than 11 million paperclips from around the world and placed them into a rail car used to transport Jews, blacks, homosexuals, Jehova's Witnesses, and other people to concentration camps. The original teacher from the project, David Alan Smith, as well as the local elected and school officials took part in the campaign by getting their photo taken at the City Hall Court Room.\n\nJason Beckett is a marketing and brand developer who has created and managed multimillion-dollar campaigns for authors, manufactures, gurus, and corporations across the United States. He was the Director of Original Programming for Turner Media, writer/producer for Dream Big Productions, and programming developer for Primedia.\n\nBeckett created the I Am Equal project and built the record-breaking I Am Equal Photo Documentary with Matt Spencer as a way to highlight and showcase the unique human rights and social issues that unite the human family.\n\nTo further support the photo documentary project and associated foundation, Beckett also produced the 'Live For Love' Charity mini album and donated all the proceeds to the campaign. The album includes the original songs Live For Love and Will You Stand By, along with a cover of the Elton John classic, 'The Last Song.'\n\nMatt Spencer is a commercial fashion photographer who works with Fortune 500 companies and various international publications. Publications including Women’s Fitness Magazine, Seventeen Magazine, V.I.P. Zone, M the Book, Launchpad Magazine, PDN have featured his work. Some campaign members have said that his photographic style become as recognizable as the campaign logo itself.\n\nAfter collecting nearly 500 photos in the testing phase of the documentary project, organizers began planning the first \"official\" tour event in Sacramento, California, with the help of former NBA All Star and current Sacramento City Mayor, Kevin Johnson. Working closely with his entire staff, the details were set in place to open the official I Am Equal Photo Documentary world tour at The Citizen Hotel, across the street from City Hall and the California State Capital. The documentary creators have said that they intend to visit between 20 and 25 cities each year for at least 7 years in order to collect their target goal of more than 100,000 individual photos.\n\n"}
{"id": "23569003", "url": "https://en.wikipedia.org/wiki?curid=23569003", "title": "Internet Gambling Regulation, Consumer Protection, and Enforcement Act", "text": "Internet Gambling Regulation, Consumer Protection, and Enforcement Act\n\nThe Internet Gambling Regulation, Consumer Protection, and Enforcement Act was a proposed 2009 bill in the United States House of Representatives that is intended \"to provide for the licensing of Internet gambling activities by the Secretary of the Treasury, to provide for consumer protections on the Internet, to enforce the tax code, and for other purposes.\" The bill was originally introduced by Representative Barney Frank (D-MA) on June 12, 2009 and as of July 20, 2009 had bipartisan support from 47 co-sponsors. The bill was held in the House Financial Services Committee.\n\nThe bill would have found the following:\n\nThe bill then discussed the qualifications an organization would need to possess in order to operate an online poker site, legal requirements, fees and taxes, penalties, and regulations.\n\nHad H.R. 2267 passed, it would have automatically created an exception for poker to the Unlawful Internet Gambling Enforcement Act of 2006 (UIGEA). In the meantime, Frank also proposed another bill, the Internet Gambling Regulation, Consumer Protection, and Enforcement Act (H.R. 2266) which would have delayed the full implementation of the UIGEA until 2010.\n\nOn July 5, 2009, Frank addressed the players at the 2009 World Series of Poker Main Event (day 1-c) concerning the status of this bill. During his address, he accused the Republican Party of being behind the Department of Justice's seizure of poker players' bank accounts in early June. After his address, Frank initiated the third day of the tournament with the words, \"Shuffle up and deal.\"\n\nGoldman Sachs issued a notice to its investors that online gambling would be legal in the U.S., and that the only question is when. They believe that the tax ramifications alone make the passage of regulated poker a foregone conclusion. \"Were the market to be legalized,\" the Sachs report stated, \"we believe that the size of the revenue opportunity could increase materially... Based on an assumption of 30% penetration of offline poker players and $300 gross gaming revenue (GGR) per player, we estimate that a legal poker market could be worth $3bn.\"\n\n"}
{"id": "47369185", "url": "https://en.wikipedia.org/wiki?curid=47369185", "title": "James Shannon Dempsey", "text": "James Shannon Dempsey\n\nJames Shannon Dempsey (February 9, 1887 – October 24, 1955) was a Canadian politician who was a Member of Provincial Parliament in Legislative Assembly of Ontario from 1945 to 1955. He represented the riding of Renfrew South for the Ontario Progressive Conservative Party.\n\nHe was born in Calabogie, Ontario and was a contractor and lumberman. He died in office of a heart attack in 1955.\n"}
{"id": "38497600", "url": "https://en.wikipedia.org/wiki?curid=38497600", "title": "Jural relationship", "text": "Jural relationship\n\nJural Relationship is a type of legal relationship existing between the landlord and tenant as long as the valid tenancy shall continue between them with regard to the demised premises.\nBefore going to analyse the term Jural Relationship we have to discuss the terminologies about the Landlord and Tenant with reference to the Rent Control Act. So it is better to take into assistance of two enactments from the State of Tamil Nadu and the Union Territory of Pondicherry. The phraseology of the said Acts are: (1) The Tamil Nadu Buildings (Lease and Rent Control) Act, 1960 [Tamil Nadu Act No. XVIII of 1960]. and (2) The Puducherry Buildings (Lease and Rent Control) Act, 1969 [Puducherry Act No. V of 1969].\n\nThe term Landlord with reference to the Tamil Nadu Buildings (Lease and Rent Control) Act, 1960 under Section 2(6) which runs as follows:\n\"Sec.2(6) landlord includes the person who is receiving or is entitled to receive the rent of a building, whether on his own account or on behalf of another or on behalf of himself and others or as an agent, trustee, executor, administrator, receiver or guardian or who would so receive the rent to be entitled to receive the rent, if the building were let to a tenant:\"\n\"Explanation: A tenant who sub-let shall be deemed to be a landlord within the meaning of this Act in relation to the sub-tenant.\"\n\nLikewise the term Tenant with reference to the Tamil Nadu Buildings (Lease and Rent Control) Act, 1960 under Section 2(8) which runs as follows:\n\"(8) \"tenant\" means any person by whom or on whose account rent is payable for a building and includes the surviving spouse, or any son, or daughter, or the legal representative of a deceased tenant who-\"\n\"(i) in the case of a residential building, had been living with the tenant in the building as a member of the tenant's family upto the death of the tenant, and\"\n\"(ii) in the case of a non-residential building, had been in continuous association with the tenant for the purpose of carrying on business of the, tenant upto the death of the tenant and continues to carry on such business thereafter, and \"\n\"a person continuing in possession after the termination of the tenancy in his favour, but does not include a person placed in occupation of a building by its tenant or a person to whom the collection of rents or fees in a public market, cart stand or slaughter-house or of rents for shops, has been framed out or leased by a Municipal Council or a Panchayat Union Council or the Municipal Corporation of Madras or the Municipal Corporation of Madurai.\"\n\nAs stated above as long as the existence of valid tenancy between the parties then they are implied to be discharging their part of statutory obligations of \"give and take\" policy of \"payments of rent\" and \"receipt of rent\" towards the demised premises and that of amenities attached with the demised premises.\n\nSo as long as the parties are \"paying and receiving\" the rents then they are comes under a single roof of landlord and tenant for which it is pertinent point to go through the landmark decision dated 7 August 2009 as rendered by the Hon'ble Madras High Court in its Judgment in M.S.Venkatesh Kumar and another Vs. M/s.Prasath Associates which is reported in 2001(4) CTC 371 in para 9 has held as follows: \"the term \"Rent\" would include all payments agreed to be paid by the tenant to his landlord for the use and occupation, not only of the building and furniture, but also for electricity, water and other amenities and that in other words, any sum of money which the tenant agrees to pay as consideration for the tenancy would be rent. So, in the aforesaid judgments rendered by this Court and the Honourable Apex Court it has been categorically mentioned that the rent means any sum of money as agreed as rent and other amenities payable for the occupation of the tenant in the demised premises.\"\n\nSimilarly in yet another decision the Hon'ble Madras High Court further held that, \"the term \"amenity\" shall means and includes as follows: “Any facility afforded for the pleasurable enjoyment by the tenants of the premises would constitute an amenity\" which is reported in 1972 TLNJ 186.\n\n\nhttp://courtverdict.com/\n\n"}
{"id": "37039766", "url": "https://en.wikipedia.org/wiki?curid=37039766", "title": "Kuching Declaration", "text": "Kuching Declaration\n\nThe Kuching Declaration (Iban: \"Jaku penetap Kuching\", Malay: \"Perisytiharan Kuching\") is a declaration in English was adopted by the three component parties of the Pakatan Rakyat (i.e. People's Justice Party (PKR) signed by Anwar Ibrahim and Baru Bian, Democratic Action Party (DAP) signed by Lim Kit Siang and Wong Ho Leng, Pan-Malaysian Islamic Party (PAS) signed by Abdul Hadi Awang and Adam Ahid, ) coincide with Malaysia Day celebrations on 16 September 2012 held at Chonglin Park, Kuching, Sarawak, the declaration pledge and promise will honour the spirit of the Malaysia Agreement of 1963 to the nations and the peoples of the States of Sarawak and Sabah that when they form the next government of the Malaysia they will honour all its pledges and promises in this declaration.\n\nLest we forget, and lest all the peoples of our great Nation of Malaysia forget, we the undersigned do once again firmly, resolutely and unequivocally pledge and promise before the whole Nation of Malaysia as our witness, on this historically day 16 September 2012, in the City of Kuching, and on behalf of our respective parties and Pakatan Rakyat will honour all its pledges and promises to the peoples of Malaysia.\n\nWe will honourably execute all the policies set forth in the Buku Jingga so that Malaysia will once again be a great Nation, her peoples prosperous, her future secure and peaceful, and her name celebrated by all the nations of the world.\n\nWe will honour the spirit of the Malaysia Agreement of 1963 which our founding fathers put their hands to, and as a sign of our deep commitment to the peoples of Sarawak and Sabah, consistent with democratic principles and justice for all Malaysians, in particular:\n\nWe, the undersigned, make this declaration as an incontrovertible contract between the Pakatan Rakyat and the peoples of Malaysia, this historic day of 16 September 2012 on Malaysia Day, so that it may ring out resoundingly from Malaysia’s high forest hills down to the open sea; so that freedom may ever reign; and our peoples live in unity!\n\nIn witness whereof the undersigned, being duly authorised thereto, have signed this Declaration, and all the peoples of Malaysia being witnesses thereof.\n\nDone at Kuching, this 16th day of September, 2012, in six copies of which one shall be deposited with each of the signatories.\n\n\n"}
{"id": "48641005", "url": "https://en.wikipedia.org/wiki?curid=48641005", "title": "Law Commission of Canada", "text": "Law Commission of Canada\n\nThe Law Commission of Canada was an independent law commission that gave advice to the Canadian government on matters of law. The body was created in 1971 as the Law Reform Commission of Canada and was disbanded in 1992. The body was reestablished as the Law Commission of Canada in 1996. On September 26, 2006, the Conservative government announced it was cutting the LCC's funding.\n\nDecades before it was established, since at least 1955, there were calls for the creation of a federal law reform commission. The federal law commission was preceded by the Ontario Law Reform Commission, which was created in 1964. In 1966, the Canadian Bar Association passed a resolution at its annual meeting calling for the creation of a federal law reform commission. On February 16, 1970, the then Liberal Minister of Justice John Turner introduced Bill C-186, which called for the establishment of a national law reform agency. The bill successfully passed and the Law Reform Commission of Canada was created.\n\nThe LRCC was meant to provide expert advice on reformations of legislation. It was to study and review on an ongoing basis the laws of Canada, and to make recommendations for their improvement.\n\nNo legislation based on the LRCC's recommendations were enacted during the first ten years of the Commission's existence. The Commission did not issue a final report until its fifth year. Finally, in 1983, legislation was enacted that implemented one of its reports.\n\nIn February 1992, the Conservative government announced that it was to close the LRCC, along with five other organisations, as a cost savings measure.\n\nIn 1996, Liberal Minister of Justice Allan Rock reintroduced Bill C-9 to create the Law Commission of Canada. On May 29, 1996, Bill C-9 received royal assent. The LCC commenced operations during 1997. Its mandate was different than under the former LRCC. The LCC was meant to be inclusive to Canadians, and to adopt a multidisciplinary approach. It was made up of five commissioners appointed by the Cabinet of Canada on the recommendations of the Minister of Justice. The president was a full-time commissioner, while the other four commissioners served on a part-time basis.\n\nIn 2002, it released a report recommending Parliament remove restrictions on same-sex marriage. In 2004, it released a report on electoral reform that suggested introducing mixed member proportional representation.\n\nOn September 26, 2006, the Federal Government announced it would be cutting funding for the LCC. It said that the cuts would save $4.19 million for the government over the next two years.\n"}
{"id": "267793", "url": "https://en.wikipedia.org/wiki?curid=267793", "title": "Legal tender", "text": "Legal tender\n\nLegal tender is a medium of payment recognized by a legal system to be valid for meeting a financial obligation. Paper currency and coins are common forms of legal tender in many countries. Legal tender is variously defined in different jurisdictions. Formally, it is anything which when offered in payment extinguishes the debt. Thus, personal cheques, credit cards, and similar non-cash methods of payment are not usually legal tender. The law does not relieve the debt obligation until payment is tendered. Coins and banknotes are usually defined as legal tender. Some jurisdictions may forbid or restrict payment made other than by legal tender. For example, such a law might outlaw the use of foreign coins and bank notes or require a license to perform financial transactions in a foreign currency.\n\nGenerally, designation of a particular form of money as legal tender means \"that the designated money is valid payment for all debts unless there is a specific agreement to the contrary\". In some jurisdictions legal tender can be refused as payment if no debt exists prior to the time of payment (where the obligation to pay may arise at the same time as the offer of payment). For example, vending machines and transport staff do not have to accept the largest denomination of banknote. Shopkeepers may reject large banknotes: this is covered by the legal concept known as invitation to treat. Under the law, United States money as identified above is a valid and legal offer of payment for antecedent debts when tendered to a creditor. By contrast, federal statutes do not require that someone who is not a pre-existing creditor must accept currency or coins as payment for goods or services. Private businesses may formulate their own policies on whether to accept cash unless state law requires otherwise.\n\nThe right, in many jurisdictions, of a trader to refuse to do business with any person, means a purchaser may not insist on making a purchase and so declaring a legal tender in law, as anything other than an offered payment for debts already incurred would not be effective.\n\nThe term \"legal tender\" is from Middle English \"tendren\", French \"tendre\" (verb form), meaning \"to offer\". The \"Latin\" root is \"tendere\" (to stretch out), and the sense of \"tender\" as an \"offer\" is related to the etymology of the English word \"extend\" (to hold outward).\n\nDemonetization is the act of stripping a currency unit of its status as legal tender. It occurs whenever there is a change of national currency: The current form or forms of money is pulled from circulation and retired, often to be replaced with new notes or coins. Sometimes, a country completely replaces the old currency with new currency.\n\nThe opposite of demonetization is remonetization, in which a form of payment is restored as legal tender.\n\nCoins and banknotes may cease to be legal tender if new notes of the same currency replace them or if a new currency is introduced replacing the former one. Examples of this are:\n\n\nIndividual coins or banknotes can be demonetised and cease to be legal tender (for example, the pre-decimal United Kingdom farthing or the Bank of England 1 pound note), but the Bank of England does redeem all Bank of England banknotes by exchanging them for legal tender currency at its counters in London (or by post) regardless of how old they are. Banknotes issued by retail banks in the UK (Scotland and Northern Ireland) are not legal tender, but one of the criteria for legal protection under the Forgery and Counterfeiting Act is that banknotes must be payable on demand, therefore withdrawn notes remain a liability of the issuing bank without any time limits.\n\nIn the case of the euro, coins and banknotes of former national currencies were in some cases considered legal tender from 1 January 1999 until 28 February 2002. Legally, those coins and banknotes were considered non-decimal sub-divisions of the euro.\n\nWhen the Iraqi Swiss dinar ceased to be legal tender in Iraq, it still circulated in the northern Kurdish regions, and despite lacking government backing, it had a stable market value for more than a decade. This example is often cited to demonstrate that the value of a currency is not derived purely from its legal status (but this currency would not be legal tender).\n\nThis is also true of the paper money issued by the Confederate States of America during the American Civil War. The Confederate currency became worthless by its own terms after the war, since it could only be redeemed a stated number of years after a peace treaty was signed between the Confederacy and the United States (which never happened, as the Confederacy was defeated and dissolved).\n\nDemonetisation is currently prohibited in the United States, and the Coinage Act of 1965 applies to all US coins and currency regardless of age. The closest historical equivalent in the US, other than Confederate money, was from 1933 to 1974, when the government banned most private ownership of gold bullion, including gold coins held for non-numismatic purposes. Now, however, even surviving pre-1933 gold coins are legal tender under the 1964 act.\n\nBanknotes and coins may be withdrawn from circulation, but remain legal tender. United States banknotes issued at any date remain legal tender even after they are withdrawn from circulation. Canadian 1- and 2-dollar bills remain legal tender even if they have been withdrawn and replaced by coins, but Canadian $1,000 bills remain legal tender even if they are removed from circulation as they arrive at a bank. However, Bank of England notes that are withdrawn from circulation generally cease to be legal tender but remain redeemable for current currency at the Bank of England itself or by post. All paper and polymer issues of New Zealand banknotes issued from 1967 onwards (and 1- and 2-dollar notes until 1993) are still legal tender; however, 1-, 2- and 5-cent coins are no longer used in New Zealand.\n\nA cashless society describes an economic state whereby financial transactions are not conducted with money in the form of physical banknotes or coins, but rather through the transfer of digital information (usually an electronic representation of money) between the transacting parties. Cashless societies have existed, based on barter and other methods of exchange, and cashless transactions have also become possible using digital currencies such as bitcoin. However this article discussesand focuses on the term \"cashless society\" in the sense of a move towards, and implications of, a society where cash is replaced by its digital equivalent – in other words, legal tender (money) exists, is recorded, and is exchanged only in electronic digital form.\n\nSometimes currency issues such as commemorative coins or transfer bills may be issued that are not intended for public circulation but are nonetheless legal tender. An example of such currency is Maundy money. Some currency issuers, particularly the Scottish banks, issue special commemorative banknotes which are intended for ordinary circulation (though no Scottish banknotes nor notes from Northern Ireland are legal tender in the United Kingdom). As well, some standard coins are minted on higher-quality dies as 'uncirculated' versions of the coin, for collectors to purchase at a premium; these coins are nevertheless legal tender. Some countries issue precious-metal coins which have a currency value indicated on them which is far below the value of the metal the coin contains: these coins are known as \"non-circulating legal tender\" or \"NCLT\".\n\nIn Australia, the creation of legal tender, in the form of notes and base metal coins, is the exclusive right of the Commonwealth (Federal) Government. According to section 115 of the Australian Constitution, \"A State shall not coin money, nor make anything but gold and silver coin a legal tender in payment of debts.\" Under this provision the Perth Mint, owned by the Western Australian Government, still produces gold and silver coins with legal tender status, the Australian Gold Nugget and Australian Silver Kookaburra. These, however, although having the status of legal tender, are almost never circulated or used in payment of debts, and are mostly considered bullion coins.\n\nAustralian notes are legal tender for all amounts, as established by the \"Reserve Bank Act 1959\". Under the provisions of the \"Currency Act 1965\" Australian coins intended for general circulation, which are now produced at the Royal Australian Mint in Canberra, are also legal tender, but only for the following amounts:\n\nThe one cent and two cent coins have been withdrawn from circulation since February 1992 but remain legal tender.\n\nAlthough the Reserve Bank Act 1959 and the Currency Act 1965 establishes that Australian banknotes and coins have legal tender status, Australian banknotes and coins do not necessarily have to be used in transactions and refusal to accept payment in legal tender is not unlawful. It appears that a provider of goods or services is at liberty to set the commercial terms upon which payment will take place before the \"contract\" for supply of the goods or services is entered into. If a provider of goods or services specifies other means of payment prior to the contract, then there is usually no obligation for legal tender to be accepted as payment. This is the case even when an existing debt is involved. However, refusal to accept legal tender in payment of an existing debt, where no other means of payment/settlement has been specified in advance, conceivably could have consequences in legal proceedings.\n\nAustralia Post prohibits the sending of coins or banknotes, of any country, except via Registered Post.\n\nIn 1901, notes in circulation in Australia consisted of bank notes payable in gold coin and issued by the trading banks, and Queensland Treasury notes. Bank notes circulated in all States except Queensland, but were not legal tender except for a brief period in 1893 in New South Wales. There were, however, some restrictions on their issue and other provisions for the protection of the public. Queensland Treasury notes were issued by the Queensland Government and were legal tender in that state. Notes of both categories continued in circulation until 1910, when the Commonwealth Parliament passed the \"Australian Notes Act 1910\" and the \"Bank Notes Tax Act 1910\". The \"Australian Notes Act 1910\" prohibited the circulation of state notes as money, and the \"Bank Notes Tax Act 1910\" imposed a tax of ten per cent, per annum, on \"all bank notes issued or re-issued by any bank in the Commonwealth after the commencement of this Act, and not redeemed\". These Acts effectively put an end to the issue of notes by the trading banks and the Queensland Treasury. \"The Reserve Bank Act 1959\" expressly prohibits persons and states from issuing \"a bill or note for the payment of money payable to bearer on demand and intended for circulation\".\n\nIn general, Canadian dollar banknotes issued by the Bank of Canada and coins issued under the authority of the Royal Canadian Mint Act are legal tender in Canada. However, commercial transactions may legally be settled in any manner agreed by the parties involved with the transactions. For example, convenience stores may refuse $100 bank notes if they feel that would put them at risk of being counterfeit victims; however, official policy suggests that the retailers should evaluate the impact of that approach. In the case that no mutually acceptable form of payment can be found for the tender, the parties involved should seek legal advice.\n\nAs outlined in the Currency Act, there is a limit to the value of a transaction for which one may use only coins. A payment in coins is a legal tender for no more than the following amounts for the following denominations of coins:\n\n\nIn the case of coins of a denomination greater than ten dollars, a payment is a legal tender for no more than the value of a single coin of that denomination. Where more than one amount is payable by one person to another on the same day under one or more obligations, the total of those amounts is deemed to be one amount due and payable on that day.\n\nIn the People's Republic of China, the official currency renminbi serves as the unlimited legal tender for all transactions. It is by law that any public institution or individual must not refuse using the currency to settle public or private domestic owing.\n\nEuro coins and banknotes became legal tender in most countries of the Eurozone on 1 January 2002. Although one side of the coins is used for different national marks for each country, all coins and all banknotes are legal tender throughout the eurozone. Therefore, it is possible to find Irish euro coins in Greece and Finnish euro coins in Portugal, for instance. Although some eurozone countries do not put 1 cent and 2 cent coins into general circulation (prices in those countries are by general understanding always rounded to whole multiples of 5 cent), 1 cent and 2 cent coins from other eurozone countries remain legal tender in those countries.\n\nCouncil Regulation (EC) No 974/98 limits the number of coins that can be offered for payment to fifty. Governments that issue the coins must establish the euro as the only legal tender. Due to variations on the legislative meaning of legal tender in various member states and the ability of contract law to overrule the status of legal tender, it is possible for merchants to choose to refuse to accept euro banknotes and coins within specific countries within the Eurozone (the Netherlands, Germany, Finland and Ireland). National laws may also impose restrictions as to maximal amounts that can be settled by coins or notes.\n\nLegal tender was enacted the first time for gold and silver coins in the French Penal Code of 1807 (art. 475, 11°). In 1870, legal tender was extended to all notes of the Banque de France. Anyone refusing such monies for their whole value would be prosecuted (French Penal Code art. R. 642-3).\n\nAccording to the \"Economic and Monetary Union Act, 1998\" of the Republic of Ireland which replaced the legal tender provisions that had been re-enacted in Irish legislation from previous British enactments, \"No person, other than the Central Bank of Ireland and such persons as may be designated by the Minister by order, shall be obliged to accept more than 50 coins denominated in euro or in cent in any single transaction.\"\n\nThe \"Decimal Currency Act, 1970\" governed legal tender prior to the adoption of the euro and laid down the analogous provisions as in United Kingdom legislation (all inherited from previous British law), namely: coins denominated above 10 pence became legal tender for payment not exceeding 10 pounds, coins denominated not more than 10 pence became legal tender for payment not exceeding 5 pounds, and bronze coins became legal tender for payment not exceeding 20 pence.\n\nThe Indian rupee is the \"de facto\" legal tender currency in India. The Indian rupee is also legal tender in Nepal and Bhutan, but the Nepalese rupee and Bhutanese ngultrum are not legal tender in India. Both the Nepalese rupee and Bhutanese ngultrum are pegged with the Indian rupee.\n\nThe Indian rupee used to be an official currency of other countries, including the Straits Settlements (now Singapore and parts of Malaysia), Kuwait, Bahrain, Qatar, and the Trucial States (now the UAE).\n\nIn 1837, the Indian rupee was made the sole official currency of the Straits Settlements, as it was administered as a part of India. In 1845, the British replaced the Indian rupee with the Straits dollar after administration of the Straits Settlements separated from India earlier in that same year.\nAfter partition of India and Pakistan in 1947, the Pakistani rupee came into existence, initially using Indian coins and Indian currency notes simply overstamped with the word \"Pakistan\". New coins and banknotes were issued in 1948.\n\nThe Gulf rupee, also known as the Persian Gulf rupee (XPGR), was introduced by the Government of India as a replacement for the Indian rupee for circulation exclusively outside the country with the Reserve Bank of India Amendment Act of 1 May 1959. This creation of a separate currency was an attempt to reduce the strain put on India's foreign reserves by gold smuggling.\n\nTwo states, Kuwait and Bahrain eventually replaced the Gulf rupee with their own currencies (the Kuwaiti dinar and the Bahraini dinar) after gaining independence from Britain in 1961 and 1965, respectively.\n\nOn 6 June 1966, India devalued the rupee. To avoid following this devaluation, several of the states using the rupee adopted their own currencies. Qatar and most of the Trucial States adopted the Qatar and Dubai riyal, whilst Abu Dhabi adopted the Bahraini dinar. Only Oman continued to use the Gulf rupee until 1970, with the government backing the currency at its old peg to the pound. Oman later replaced the Gulf rupee with its own rial in 1970.\n\nOn 8 November 2016, Prime Minister Narendra Modi announced that existing INR 500 and INR 1000 banknotes would no longer be accepted as legal tender with a view to curb counterfeiting, tax evasion and the parallel economy. The Reserve Bank of India outlined a scheme for holders of such banknotes to either deposit them into their bank accounts for full, unlimited value, or to exchange the banknotes for new, subject to a cap.\n\nNew Zealand has a complex history of legal tender. English law applied, as applicable to local circumstances, from either 6 January 1840, when the Governor of New South Wales by proclamation annexed New Zealand, or from 14 January 1840 when Captain Hobson Royal Navy was sworn in as Lieutenant-Governor. The English Laws Act 1858 subsequently confirmed that English legislation passed prior to 14 January 1840 was and had been the law of New Zealand, as applicable to local circumstances. \nThe (UK) Coinage Act 1816 therefore applied and British coins were confirmed as legal tender in New Zealand. Unusually, until 1989, the Reserve Bank did not have the right to issue coins as legal tender. Coins had to be issued by the Minister of Finance.\n\nThe history of bank notes was considerably more complex. In 1840, the Union Bank of Australia started issuing bank notes under provisions of British law, but these were not automatically legal tender.\n\nIn 1844, ordinances were passed making the Union Bank banknotes legal tender and authorising the government to issue debentures in small denominations, thus creating two sets of legal tender. These debentures were circulated but were traded at a discount to their face value because of distrust of the colonial government by the settler population. In 1845, the Ordinance was disallowed by the British Colonial office and they were recalled, not without first causing a panic among holders of the debentures.\n\nIn 1847, the Colonial Bank of Issue became the only issuer of legal tender. In 1856, however the Colonial Bank of Issue was disbanded and through the Paper Currency Act 1856, the Union Bank was confirmed once again as an issuer of legal tender. The Act also authorised the Oriental Bank to issue legal tender but this bank ceased operations in 1861.\n\nBetween 1861 and 1874, a number of other banks including the Bank of New Zealand, Bank of New South Wales, National Bank of New Zealand and Colonial Bank of New Zealand were created by Acts of Parliament and authorised to issue bank notes backed by gold, however these notes were not legal tender.\n\nThe 1893 Bank Note Issue Act allowed the government to declare a bank's right to issue legal tender. This enabled the government to make such a declaration to assist the Bank of New Zealand when in 1895 the bank encountered financial difficulties that could have led to its failure.\n\nIn 1914, the Banking Amendment Act gave legal tender status to bank notes from any issuer and removed the requirement that banks authorised to issue bank notes must redeem them on demand for gold (the gold standard).\n\nIn 1933, the Coinage Act created a specific New Zealand coinage and removed legal tender status from British coins. In the same year the Reserve Bank of New Zealand was established. The bank was given a monopoly on the issue of legal tender. The Reserve Bank also provided a mechanism through which the other issuers of legal tender could phase out their bank notes. These banknotes were convertible into British legal tender on demand at the Reserve Bank and remained so until the 1938 Sterling Exchange Suspension Notice that suspended provisions of a 1936 amendment of the 1933 Reserve Bank of New Zealand Act.\n\nIn 1964, the Reserve Bank of New Zealand Act restated that only notes issued by the Reserve Bank were legal tender. The Act also ended the right of individuals to redeem their bank notes for coin, effectively ending the distinction between coin and notes in New Zealand. The Act came into force in 1967 establishing as legal tender all New Zealand dollar five dollars banknotes and greater, all decimal coins, the pre-decimal sixpence, the shilling, and the florin. Also passed in 1964 was the Decimal Currency Act, which created the basis for a decimal currency, introduced in 1967.\n\nAs of 2005, banknotes were legal tender for all payments, and $1 and $2 coins were legal tender for payments up to $100, and 10c, 20c, and 50c silver coins were legal tender for payments up to $5. These older style silver coins were legal tender until October 2006, after which only the new 10c, 20c and 50c coins, introduced in August 2006, are legal.\n\nThe Norwegian krone (NOK) is legal tender in Norway according to the Central Bank () of 24 May 1985. However, no-one is obliged to accept more than 25 coins of each denomination (of which currently 1, 5, 10 and 20 NOK denominations are in common circulation).\n\nSingapore and Brunei have a Currency Interchangeability Agreement since 12 June 1967. Under the agreement, Singapore dollar and Brunei dollar are exchangeable at par without charge in both countries. As such, the currency of one country is accepted in the other country as \"customary tender\".\n\nThe Swiss franc is the only legal tender in Switzerland. Any payment consisting of up to 100 Swiss coins is legal tender; banknotes are legal tender for any amount.\n\nThe sixth series of Swiss bank notes from 1976, recalled by the National Bank in 2000, is no longer legal tender, but can be exchanged in banks for current notes until April 2020.\n\nThe Swiss franc is also the legal tender of the Principality of Liechtenstein, which is joined to Switzerland in a customs union.\n\nThe Swiss franc is also the currency used for administrative and accounting purposes by most of the numerous international organisations that are headquartered in Switzerland.\n\nThe New Taiwan dollar issued by the Central Bank of the Republic of China (Taiwan) is legal tender for all payments within the territory of the Republic of China, Taiwan. However, since 2007, candidates to become civil servants in elections in the Republic of China may no longer pay any deposit in coinage.\n\nSeries 2 banknotes first issued in 1925 during the reign of Rama VI and continuing into the reign of Rama VII added the legend, \n\"Promise to pay\" (silver to) \"bearer on demand in\" (silver) \"currency of Siam\";\n\n\"This note is legal tender \" (literal translation, \"silver in payment of debt\") \"according to law\".\n\nLegal tender is solely for the guaranteed settlement of debts and does not affect any party's right of refusal of service in any transaction.\n\nIn the 19th century, gold coins were legal tender to any amount, but silver coins were not legal tender for sums over 2 pounds nor bronze for sums over 1 shilling. This provision was retained in revised form at the introduction of decimal currency, and the Coinage Act 1971 laid down that coins denominated above 10 pence became legal tender for payment not exceeding 10 pounds, non-bronze coins denominated not more than 10 pence became legal tender for payment not exceeding 5 pounds, and bronze coins became legal tender for payment not exceeding 20 pence.\n\nThroughout the United Kingdom, coins valued 1 pound, 2 pounds, and 5 pounds Sterling are legal tender in unlimited amounts. Twenty pence pieces and fifty pence pieces are legal tender in amounts up to 10 pounds; five pence pieces and ten pence pieces are legal tender in amounts up to 5 pounds; and pennies and two pence coins are legal tender in amounts up to 20 pence. In accordance with the Coinage Act 1971, gold sovereigns are also legal tender for any amount. Although it is not specifically mentioned on them, the face values of gold coins are 50p; £1; £2; and £5, a mere fraction of their worth as bullion. Five pound coins, although legal tender, are intended as souvenirs and are almost never seen in circulation.\n\nMaundy money is legal tender but may not be accepted by retailers and is worth much more than face value due to its rarity value and silver content.\n\nBank of England notes are legal tender in England and Wales and are issued in the denominations of £5, £10, £20 and £50. They can always be redeemed at the Bank of England even if discontinued. Banknotes issued by Scottish and Northern Irish banks are not legal tender anywhere but are widely accepted with agreement between parties. Thus legal tender in Scotland is limited to coin.\n\nIn a 1976 case, Miliangos v George Frank Ltd, the House of Lords established that the English courts could order debts to be paid in currencies other than the pound sterling under certain circumstances, overturning two centuries of precedent.\n\nBefore the Civil War (1861 to 1865), silver coins were legal tender only up to the sum of $5. Before 1853, when U.S. silver coins were reduced in weight 7%, coins had exactly their value in metal (from 1830 to 1852). Two silver 50 cent coins had exactly $1 worth of silver. A gold U.S. dollar of 1849 had $1 worth of gold. With the flood of gold coming out of the California mines in the early 1850s, the price of silver rose (gold went down). Thus, 50 cent coins of 1840 to 1852 were worth 53 cents if melted down. The government could increase the value of the gold coins (expensive) or reduce the size of all U.S. silver coins. With the reduction of 1853, a 50-cent coin now had only 48 cents of silver. This is the reason for the $5 limit of silver coins as legal tender; paying somebody $100 in the new silver coins would be giving them $96 worth of silver. Most people preferred bank check or gold coins for large purchases.\n\nDuring the early American Civil War, the federal government first issued United States Notes (the first greenback notes), which were not redeemable in gold and silver coins but could be used to pay \"all dues\" to the federal government. Since land purchases and duties on imports were payable only in gold or the new Demand Notes, the Demand Notes were bought by importers and land speculators for about 97 cents on the gold dollar and never lost value. 1862 greenbacks (Legal Tender Notes) at first traded for 97 cents on the dollar but gained/lost value depending on fortunes of the Union army. The value of Legal Tender Greenbacks swung wildly but trading was from 85 to 33 cents on the gold dollar.\n\nThis resulted in a situation in which the greenback \"Legal Tender\" notes of 1862 were fiat, and so gold and silver were held and paper circulated at a discount because of Gresham's Law. The 1861 Demand Notes were a huge success but robbed the customs house of much needed gold coin (interest on most bonds back then was paid in gold). A money-strapped Congress, which had to pay for the war, eventually adopted the Legal Tender Act of 1862, issuing United States Notes backed only by treasury securities, and compelled the people to accept the new notes at a discount; prices rose except for those who had gold and/or silver coins.\n\nFollowing the Civil War, paper currency was disputed as to if it must be accepted as payment. In 1869, Hepburn v. Griswold found that Henry Griswold would not have to accept paper currency because it could not truly be \"legal tender\" and was unconstitutional as a legally enforceable means to pay debts. This led to the Legal Tender Cases in 1870, which overturned the previous ruling and established the paper currency as constitutional and proper legal tender that must be accepted in all situations.\n\nWith the 1884 Supreme Court ruling in \"Juilliard v. Greenman\", the \"Supreme Court ruled that Congress had the right to issue notes to be legal tender for the payment of public and private debt. Legal-tender notes are treasury notes or banknotes that, in the eyes of the law, must be accepted in the payment of debts.\" The ruling in the Legal Tender Cases (which include \"Juilliard v. Greenman\") led later courts to \"support the federal government's invalidation of gold clauses in private contracts in the 1930s.\"\n\nOn the other hand, coins made of gold or silver may not necessarily be legal tender, if they are not fiat money in the jurisdiction where they are proffered as payment. The Coinage Act of 1965 states (in part):\n\nContrary to common misconception, there is no federal law stating that a private business, a person, or a government organization must accept currency or coins for payment. Private businesses are free to create their own policies on whether or not they accept cash, unless there is a specific state law which says otherwise. For example, a bus line may prohibit payment of fares in cents or dollar bills. In addition, movie theaters, convenience stores, and gas stations may refuse to accept large denomination currency as a matter of policy or safety.\n\nThe principal purpose of that statute is to ensure the nationwide acceptance of U.S. currency, consistent with constitutional language that reserves to Congress the power to create a uniform currency that holds the same value throughout the United States. While the statute provides that U.S. money is legal tender that may be accepted for the payment of debts, it does not require \"acceptance\" of cash payments, nor does it provide that restrictions cannot be imposed upon the acceptance of cash.\n\nOn 11 December 2016, the Venezuelan Government announced demonetisation following almost 500% inflation in the country. People of the country were given 3 days to get rid of the 100 Bolivar notes (most widely used currency) post the introduction of new note of higher denominations. As of 15 June 2017, there has been 7 extensions (one per month) of the legal use of the 100 bolivares bill notes. The 100 Bolivar notes are still legal tender up today 30 December 2017.\nMaduro prorrogó la vigencia del billete de 100 hasta el 20 de abril\n\n\n"}
{"id": "42064948", "url": "https://en.wikipedia.org/wiki?curid=42064948", "title": "Lessor (leasing)", "text": "Lessor (leasing)\n\nLessor is a participant of the lease who takes possession of the property and provides it as a leasing subject to the lessee for temporary possession. For example, in leasehold estate, the landlord is the lessor and the tenant is the lessee. The lessor may be the owner of the property or an agent authorized on the owner's behalf. Commercial banks, credit non-bank organizations, leasing companies often act as lessors.\n\nA lessor can be both legal entity and individual. Nevertheless, the term “leasing company” sometimes is used as a synonym to the term “lessor”.\n\nThe Seller of the property and the lessor can be one and the same person.\n\nThe process of interaction of the lessor with other participants of the Leasing Contract is as follows:\n\nFor the whole time period of the Leasing Contract the property is in the ownership of the lessor.\nIn case of failure of reimbursements of lease payments under the schedule specified in the contract the lessor has the right to exempt the property from the Lessee. In case of bankruptcy of the Lessee the lessor has the priority right for payments.\n\nIf the lessor contrary to the contract has interfered with the choice of the seller or leasing subject, he bears the responsibility for non-delivery of the equipment, personal injury of citizens while using the leasing subject, damage which is caused to the property of the Lessee and the third Parties. There are however exceptions from this norm.\n\nIn case of implementation of a high-priced project the lessor may involve into the transaction additional sources of financial assets (through banks, insurance companies, investment funds, etc.).\n\nOfficial leasing provider (dealer) is a special type of lessor. This is the official supplier of specialized machinery, transport and equipment directly to the final consumer or through a leasing company. Official leasing operator cooperates with manufacturers (subsidiary offices) of prime machinery under the operator (dealer) agreement.\n\nFor the leasing company the official leasing operator acts as:\n\nFor consumers, the official leasing operator acts as: \n\nRights and obligations of the lessor in the Russian Federation are regulated by the contract, under the Federal Law “On financial rent (leasing)”, the Tax Code of the Russian Federation, the Civil Code, and others, in Ukraine – by the Law “On Financial Leasing” and many others, in Uzbekistan – by Chapter 34 of the Civil Code of Uzbekistan and others. International leasing contracts are regulated under the UNIDROIT Convention on International Financial Leasing.\n\n"}
{"id": "296045", "url": "https://en.wikipedia.org/wiki?curid=296045", "title": "Libertarian theories of law", "text": "Libertarian theories of law\n\nLibertarian theories of law build upon classical liberal and individualist doctrines.\n\nThe defining characteristics of libertarian legal theory are its insistence that the amount of governmental intervention should be kept to a minimum and the primary functions of law should be enforcement of contracts and social order, though \"social order\" is often seen as a desirable side effect of a free market rather than a philosophical necessity.\n\nHistorically, the Austrian economist Friedrich Hayek is the most important libertarian legal theorist. Another important predecessor was Lysander Spooner, a 19th-century American individualist anarchist and lawyer. John Locke was also an influence on libertarian legal theory (see \"Two Treatises of Government)\".\n\nIdeas range from anarcho-capitalism to a minimal state providing physical protection and enforcement of contracts. Some advocate regulation, including the existence of a police force, military, public land, and public infrastructure. Geolibertarians oppose absolute ownership of land on Georgist grounds.\n\nAuthors discussing libertarian legal theory include:\n\n\n\n"}
{"id": "24793920", "url": "https://en.wikipedia.org/wiki?curid=24793920", "title": "Limitation Act 1939", "text": "Limitation Act 1939\n\nThe Limitation Act 1939 (2 & 3 Geo.6 c.21) was an Act of the Parliament of the United Kingdom that simplified the law relating to limitation periods in England & Wales. The Act was based on the fifth report of the Law Revision Committee and is divided into 3 parts, with Part I dealing with limitation periods, Part II dealing with exceptions and Part III dealing with general matters.\n\nSection 2 of Part I introduces a new limitation period; six years for all cases in tort and contract. The period runs from the point where the injury or problem was created, not from when it was discovered; thus, the Act replicates problems later solved by the Limitation Act 1963. Part II allows for a \"resetting\" of the limitation period in situations where the party is insane, not a legal adult or imprisoned for either the death penalty or for penal servitude.\n"}
{"id": "29585516", "url": "https://en.wikipedia.org/wiki?curid=29585516", "title": "Malian Family Code", "text": "Malian Family Code\n\nThe Malian Family Code () is the family law in Mali, passed in 1962. \n\nIn 2009, an amendment was proposed (which has not yet been enacted) as widespread protests forced the president to send the bill back to parliament for review. The bill sought to increase women's rights in the country, but was still opposed by some women. The bill was condemned by most religious scholars. It was passed in 2009, but withdrawn later the same year.\n\nIn 1962, Mali passed its first Family Code. \n\nThe proposed amendment would have recognised only civil marriages, while defining marriage as a secular institution, thus entitling a divorcee to a share of inheritance. Women would have also been allowed greater inheritance rights than what was stipulated by Shariah law, as they would not be required to obey their husbands. The \"paternal power\" would be replaced with \"parental authority,\" and also said \"no marriage can be renounced.\" Furthermore, the bill raised the legal age for marriage to 18 and allowed divorce if a couple had lived apart for at least three years. A child born outside of marriage would also be entitled to a share of any inheritance.\n\nPresident Toumani Touré supported the bill, which was seen as a move toward secularism. The law was initially adopted by the National Assembly on August 3, 2009.\n\nDuring the \"NGO Forum of the African Commission on Human and Peoples' Rights\" in Banjul, an African women's rights groups called for the adoption of the bill, saying it \"provides some crucial guarantees for Malian women's universal rights, [and] would constitute a fundamental first step towards bringing Malian laws into compliance with international and regional standards.\" The group cited Mali's ratification of the United Nations Convention on the Elimination of All Forms of Discrimination against Women in 1985, the Protocol to the African Charter on Human and Peoples' Rights on the Rights of Women in Africa in 2005, and the UN Convention on the Rights of the Child in 1990. It further said: \"We are thus deeply concerned that the enactment of this legislation...is in suspense. Violations of Malian women's human rights are favored by this legislative gap. We stress the urgent need to adopt such a code...by ensuring that the second reading takes place without further delay and that the Family Code is enacted in its present form, without weakening of any of its provisions.\"\n\nMamadou Diamouténé, the head of a task group from the council, said that without the recommended changes, the bill would be \"open road to debauchery. It is not that anyone can go wherever she wishes without her husband’s approval, because we cannot forget that the man is the head of the family.\"\n\nMuslim leaders and other youth groups vowed to block the law and even threatened a campaign of violence. Threats against legislators, angry sermons, organised protest meetings and radio and television campaigns all attempted to rally opposition to the bill. Some Muslim leaders went so far as to call the law the work of the devil and against Islam. Tens of thousands marched in the streets to protest the law. In one such demonstration, 50,000 people rallied amidst calls that the bill was \"an insult to the Koran.\"\n\nSome women's groups were also opposed to the law. The president of the National Union of Muslim Women said that \"only a tiny minority of woman here who want this new law. The poor and illiterate women of this country, the real Muslims, are against it\".\n\nOne imam who spoke in support of the code went into hiding.\n\nPresident Touré reasserted that the struggle to pursue \"the dual objective of promoting a wave of modernization while preserving the foundations of our society\" would continue. He also said that failures to update and enforce the law \"proves that societal change is not ordered by decree. [The] door of debate is still open.\"\n\nMountaga Tall, an MP, said: \"We demonstrated intellectual laziness in adopting the last code so quickly. This time, the assembly will start from zero.\"\n\nAs a result of public outcry, President Touré sent the bill back to parliament on August 27, 2009. \"I have taken this decision to send the family code for a second reading to ensure calm and a peaceful society, and to obtain the support and understanding of our fellow citizens.\" \n\nAn amended version, endorsed by the High Islamic Council, the highest authority on Islam in the country, was tabled. This new bill included the reintroduction of religious marriage, altered the previous version's enhancement of women's inheritance rights, and changed the recognition of an illegitimate child. Other amendments being proposed, despite being blocked in the initial version, include:\n\nHowever these three proposals have not been made a part of law, whereas religious marriage is still going to be maintained \n\nThe debate over the bill included \"civil society\" groups in the first phase, and religious groups in the amendment phase.\n"}
{"id": "30555697", "url": "https://en.wikipedia.org/wiki?curid=30555697", "title": "Max Planck Institute for Tax Law and Public Finance", "text": "Max Planck Institute for Tax Law and Public Finance\n\nThe Max Planck Institute for Tax Law and Public Finance is an interdisciplinary research center in Munich. The Institute is part of the Max Planck Society, Germany’s foremost provider of basic research in science and humanities, funded largely from public resources.\n\nThe Senate of the Max Planck Society has founded the Max Planck Institute for Tax Law and Public Finance in Munich as of \n1 January 2011. It consists of the Department of Public Economics, headed by Kai A. Konrad, and the Department of Business and Tax Law, headed by Wolfgang Schön.\n\nThe Institute was founded by spinning-off the tax departments of the former Max Planck Institute for Intellectual Property, Competition and Tax Law, which was located at the same place. Together with the Max Planck Institute for Intellectual Property and Competition Law and the Max Planck Institute for Foreign and International Social Law, the Institute founded the Munich Max Planck Campus for Legal and Economic Research.\n\nAbout 50 lawyers and economists, from Germany and abroad, work at the Institute. They do basic research on taxation but also in associated fields of research. The Institute’s work breeds scientific journals, articles and monographs, the Institute is involved in academic conferences, lectures and cooperation with other academic institutions and it also publishes comments on matters of fiscal policy and advises legislatures on the national as well as on the international level. The Institute’s mission is not limited to producing internationally visible research output in the respective disciplines but it also encompasses the advancement of interdisciplinary exchange. The Institute hosts visiting scholars and visiting researchers from all over the world and supports the research of PhD-students and post-docs by granting generous scholarships.\n\n\n"}
{"id": "15017307", "url": "https://en.wikipedia.org/wiki?curid=15017307", "title": "Military Administration (Nazi Germany)", "text": "Military Administration (Nazi Germany)\n\nDuring World War II, Nazi Germany created military-led regimes in occupied territories which were known as a Military administration or Military administration authority (de: \"Militärverwaltung\"). These differed from \"Reichskommissariate\" which were led by Nazi Party officials. A \"Military administration\" was normally led by a \"military commander\" (\"Militärbefehlshaber\", official acronym \"MilBfh.\").\n\nOfficials of the \"Military administration\", regardless serving in the Wehrmacht, war economy, military education facilities, or in the military-led regimes in occupied territories, etc., wore military rank insignias similar to these of the Wehrmacht, characterised by the main corps colour dark-green, and various secondary colours as well.\n\nThe ranks and rank insignias of the \"Military administration\" were as follows.\n\n\n\n"}
{"id": "22527525", "url": "https://en.wikipedia.org/wiki?curid=22527525", "title": "Military Selective Service Act", "text": "Military Selective Service Act\n\nThe Selective Service Act of 1948, also known as the Elston Act, was a major revision of the Articles of War of the United States enacted June 24, 1948 that established the current implementation of the Selective Service System.\n\nThe previous iteration of the Selective Service System was established by the Selective Training and Service Act of 1940. After two extensions, the Selective Training and Service Act was allowed to expire on March 31, 1947. In 1948, it was replaced by a new and distinct Selective Service System established by this Act. The Selective Service Act of 1948 was originally intended to remain in effect for two years (i.e., until June 24, 1950), but was extended multiple times, usually immediately before its two-year period of effectiveness was due to expire.\n\nThe act has had amendments, extensions, and changes of name since 1948, including:\n\n\n"}
{"id": "1704998", "url": "https://en.wikipedia.org/wiki?curid=1704998", "title": "Mine Safety and Health Administration", "text": "Mine Safety and Health Administration\n\nThe Mine Safety and Health Administration (MSHA) () is an agency of the United States Department of Labor which administers the provisions of the Federal Mine Safety and Health Act of 1977 (Mine Act) to enforce compliance with mandatory safety and health standards as a means to eliminate fatal accidents, to reduce the frequency and severity of nonfatal accidents, to minimize health hazards, and to promote improved safety and health conditions in the nation's mines. MSHA carries out the mandates of the Mine Act at all mining and mineral processing operations in the United States, regardless of size, number of employees, commodity mined, or method of extraction. David Zatezalo is Assistant Secretary of Labor for Mine Safety and Health, and the head of MSHA.\n\nMSHA is organized into several divisions. The Coal Mine Safety and Health division is divided into 12 districts covering coal mining in different portions of the United States. The Metal-Nonmetal Mine Safety and Health division covers six regions of the United States.\n\nIn 1891, Congress passed the first federal statute governing mine safety. The 1891 law was relatively modest legislation that applied only to mines in U.S. territories, and, among other things, established minimum ventilation requirements at underground coal mines and prohibited operators from employing children under 12 years of age.\n\nIn 1910, Congress established the Bureau of Mines as a new agency in the Department of the Interior. The Bureau was charged with the responsibility to conduct research and to reduce accidents in the coal mining industry, but was given no inspection authority until 1941, when Congress empowered federal inspectors to enter mines. In 1947, Congress authorized the formulation of the first code of federal regulations for mine safety.\n\nThe Federal Coal Mine Safety Act of 1952 provided for annual inspections in certain underground coal mines, and gave the Bureau limited enforcement authority, including power to issue violation notices and imminent danger withdrawal orders. The 1952 Act also authorized the assessment of civil penalties against mine operators for noncompliance with withdrawal orders or for refusing to give inspectors access to mine property, although no provision was made for monetary penalties for noncompliance with the safety provisions. In 1966, Congress extended coverage of the 1952 Coal Act to all underground coal mines.\n\nThe first federal statute directly regulating non-coal mines did not appear until the passage of the Federal Metal and Nonmetallic Mine Safety Act of 1966. The 1966 Act provided for the promulgation of standards, many of which were advisory, and for inspections and investigations; however, its enforcement authority was minimal.\n\nThe Coal Mine Safety and Health Act of 1969, generally referred to as the Coal Act, was more comprehensive and more stringent than any previous federal legislation governing the mining industry. The Coal Act included surface as well as underground coal mines within its scope, required two annual inspections of every surface coal mine and four at every underground coal mine, and dramatically increased federal enforcement powers in coal mines. The Coal Act also required monetary penalties for all violations, and established criminal penalties for knowing and willful violations. The safety standards for all coal mines were strengthened, and health standards were adopted. The Coal Act included specific procedures for the development of improved mandatory health and safety standards, and provided compensation for miners who were totally and permanently disabled by the progressive respiratory disease caused by the inhalation of fine coal dust pneumoconiosis or \"black lung.\"\n\nIn 1973, the Secretary of the Interior, through administrative action, created the Mining Enforcement and Safety Administration (MESA) as a new departmental agency separate from the Bureau of Mines. MESA assumed the safety and health enforcement functions formerly carried out by the Bureau to avoid any appearance of a conflict of interest between the enforcement of mine safety and health standards and the Bureau's responsibilities for mineral resource development. (MESA was the predecessor organization to MSHA, prior to March 9, 1978.)\n\nMore recently, Congress passed the Federal Mine Safety and Health Act of 1977, the legislation which currently governs MSHA's activities. The Mine Act amended the 1969 Coal Act in a number of significant ways, and consolidated all federal health and safety regulations of the mining industry, coal as well as non-coal mining, under a single statutory scheme. The Mine Act strengthened and expanded the rights of miners, and enhanced the protection of miners from retaliation for exercising such rights. Mining fatalities dropped sharply under the Mine Act from 272 in 1977 to 45 in 2014. The Mine Act also transferred responsibility for carrying out its mandates from the Department of the Interior to the Department of Labor, and created MSHA. Additionally, the Mine Act established the independent Federal Mine Safety and Health Review Commission to provide for independent review of the majority of MSHA's enforcement actions.\n\nCongress passed the Mine Improvement and New Emergency Response Act (MINER Act) in 2006. The MINER Act amended the Mine Act to require mine-specific emergency response plans in underground coal mines; added new regulations regarding mine rescue teams and sealing of abandoned areas; required prompt notification of mine accidents; and enhanced civil penalties.\n\nModern mining regulation in the United States is carried out by MSHA and governed by The Federal Mine Safety and Health Act of 1977 and MSHA's Program Policy Manual Volume III. \n\nOn January 27, 2012 as required under the Dodd–Frank Wall Street Reform and Consumer Protection Act, the Securities and Exchange Commission adopted final rules which require covered SEC-reporting issuers that are “operator(s)” (or that has a subsidiary that is an “operator”) of a “coal or other mine” to disclose certain mine safety violations, citations and orders and related matters for each coal or other mine that they operate. Covered mine “operator(s)” are also required to file a current report on Form 8-K to disclose the receipt of certain orders and notices from the U.S. Labor Department’s Mine Safety and Health Administration (MSHA) related to a coal or other mine that they operate.\n\nMSHA regulations state an action level (AL) and a permissible exposure level (PEL) which set standards for when a hearing conservation program need to be put into place. The action level is an 8-hour time-weighted average sound level (TWA) of 85 dBA, or a dose of 50%, integrating all sound levels from 80 dBA to at least 130 dBA. A permissible exposure level (PEL) is a TWA of 90 dBA, or equivalently, a dose of 100% , integrating all sound levels from 90 dBA to at least 140 dBA. In the hearing conservation program the company must try all feasible engineering and administrative controls before they provide hearing protective devices.\n\nIf a miner's noise exposure exceeds the PEL despite the use of all feasible engineering and administrative controls, Section 62.130 requires the company to:\n\n·        continue to use the controls to maintain the miner's exposure as low as feasible;\n\n·        provide and require the use of hearing protectors;\n\n·        enroll the miner in a hearing conservation program; and\n\n·        post procedures for administrative controls on the mine bulletin board and provide a copy to the affected miners.\n\nAlthough hearing protectors must be provided and used if the engineering and administrative controls fail to reduce the miner's noise exposure to the PEL, they are not accepted in lieu of such controls.\n\nin regards to hearing protectors OSHA requires the company to provide hearing protectors to any miner whose noise exposure equals or exceeds the action level. The miner must also be trained on the \"types of hearing protectors, the value of wearing hearing protection and of audiometric tests\". The company must also provide the miner a choice of hearing protectors, including at least two muff type and two plug type hearing protectors.\n\nThe hearing protectors that you provide must be \"in good condition, fitted, and maintained in accordance with the manufacturer's instructions\". If a miner's noise exposure exceeds the dual hearing protector level, the company must provide both a muff type and plug type protector. \n\nMine operators are required by law to report all mining accidents within 15 minutes of when the operator knew or should have known about the accident. \n\nImmediately reportable accidents and injuries are:\n\nStatistical analyses performed by MSHA show that between 1990 and 2004, the industry cut the rate of injuries (a measure comparing the rate of incidents to overall number of employees or hours worked) by more than half and fatalities by two-thirds following three prior decades of steady improvement.\n\nMSHA employs nearly one safety inspector for every four coal mines. Underground coal mines are thoroughly inspected at least four times annually by MSHA inspectors. In addition, miners can report violations, and request additional inspections. Miners with such concerns for their work safety cannot be penalized with any threat to the loss of employment.\n\nAdditionally, the Mine Safety and Health Act authorizes the National Institute for Occupational Safety and Health (NIOSH), part of the Centers for Disease Control and Prevention under the U.S. Department of Health and Human Services to develop recommendations for mine health standards for the Mine Safety and Health Administration; administer a medical surveillance program for miners, including chest X-rays to detect pneumoconiosis (black lung disease) in coal miners; conduct on-site investigations in mines; and test and certify personal protective equipment and hazard-measurement instruments.\n\n\n"}
{"id": "11477230", "url": "https://en.wikipedia.org/wiki?curid=11477230", "title": "Minimum wage in the United States", "text": "Minimum wage in the United States\n\nThe minimum wage in the United States is set by US labor law and a range of state and local laws. Employers generally have to pay workers the highest minimum wage prescribed by federal, state, and local law. Since July 24, 2009, the federal government has mandated a nationwide minimum wage of $7.25 per hour. As of January 2018, there were 29 states with a minimum wage higher than the federal minimum. From 2017 to 2018, eight states increased their minimum wage levels through automatic adjustments, while increases in eleven other states occurred through referendum or legislative action. \n\nUsing 2018 inflation-adjusted dollars, the federal minimum wage peaked at $11.77 per hour in 1968. If the minimum wage in 1968 had kept up with labor's productivity growth, it would have reached $19.33 in 2017. There is a racial difference in support for a higher minimum wage with most Black and Latino individuals supporting a $15.00 federal minimum wage, and 54% of Whites opposing it. In 2015, about 3% of White, Asian, and Latino workers earned the federal minimum wage or less. Amongst Black workers, the percentage was about 4%.\n\nMinimum wage legislation emerged at the end of the nineteenth century from the desire to end sweated labor which had developed in the wake of industrialization. Sweatshops employed large numbers of women and young workers, paying them what were considered nonliving wages that did not allow workers to afford the necessaries of life. Besides substandard wages, sweating was also associated with long work hours and unsanitary work conditions. From the 1890s to the 1920s, during the Progressive Era, a time of social activists and political reform across the United States, progressive reformers, women's organizations, religious figures, academics, and politicians all played an important role in getting state minimum wage laws passed throughout the United States.\n\nThe first successful attempts at using minimum wage laws to ameliorate the problem of nonliving wages occurred in the Australian state of Victoria in 1896. Factory inspector reports and newspaper reporting on the conditions of sweated labor in Melbourne, Victoria led in 1895 to the formation of the National Anti-Sweating League which pushed the government aggressively to deal legislatively with the problem of substandard wages. The government, following the recommendation of the Victorian Chief Secretary Alexander Peacock, established wage boards which were tasked with establishing minimum wages in the labor trades which suffered from nonlivable wages. During the same time period, campaigns against sweated labor were occurring in the United States and England.\n\nIn the United States in 1890, a group of concerned female reformers who wanted to improve the harsh conditions of sweated workers formed the Consumer's League of the City of New York. The consumer group sought to improve working conditions by boycotting products which were made under sweated conditions and did not conform to a code of \"fair house\" standards drawn up by them. Similar, consumer leagues formed throughout the United States, and in 1899, they united under the National Consumer League (NCL) parent organization. Consumer advocacy, however, was extremely slow at changing conditions in the sweated industries. When NCL leaders in 1908 went to an international anti-sweatshop conference in Geneva, Switzerland and were introduced to Australian minimum wage legislation, which had successfully dealt with sweated labor, they came home believers and made minimum wage legislation part of their national platform.\nIn 1910, in conjunction with advocacy work led by Florence Kelley of the National Consumer League, the Women's Trade Union League (WTLU) of Massachusetts under the leadership of Elizabeth Evans took up the cause of minimum wage legislation in Massachusetts. Over the next two years, a coalition of social reform groups and labor advocates in Boston pushed for minimum wage legislation in the state. On June 4, 1912, Massachusetts passed the first minimum wage legislation in the United States, which established a state commission for recommending non-compulsory minimum wages for women and children. The passage of the bill was significantly assisted by the Lawrence textile strike which had raged for ten weeks at the beginning of 1912. The strike brought national attention to the plight of the low wage textile workers, and pushed the state legislatures, who feared the magnitude of the strike, to enact progressive labor legislation.\n\nBy 1923, fifteen U.S. states and the District of Columbia had passed minimum wage laws, with pressure being placed on state legislatures by the National Consumers League in a coalition with other women's voluntary associations and organized labor. The United States Supreme Court of the \"Lochner\" era (1897–1937), however, consistently invalidated labor regulation laws. Advocates for state minimum wage laws hoped that they would be upheld under the precedent of \"Muller v. Oregon\" (1908), which upheld maximum working hours laws for women on the grounds that women required special protection that men did not. The Supreme Court, however, did not extend this principle to minimum wage laws. The court ruled in \"Adkins v. Children's Hospital\" (1923) that the District of Columbia's minimum wage law was unconstitutional, because the law interfered with the ability of employers to freely negotiate wage contracts with employees. The court also noted that women did not require anymore special protection by the law, following the passage in 1920 of the Nineteenth Amendment, which gave women the right to vote and equal legal status.\n\nIn 1933, the Roosevelt administration during the New Deal made the first attempt at establishing a national minimum wage regiment with the National Industrial Recovery Act, which set minimum wage and maximum hours on an industry and regional basis. The Supreme Court, however, in \"Schechter Poultry Corp. v. United States\" (1935) ruled the act unconstitutional, and the minimum wage regulations were abolished. Two years later after President Roosevelt's overwhelming reelection in 1936 and discussion of judicial reform, the Supreme Court took up the issue of labor legislation again in \"West Coast Hotel Co. v. Parrish\" (1937) and upheld the constitutionality of minimum wage legislation enacted by Washington state and overturned the \"Adkins\" decision which marked the end of the \"Lochner\" era. In 1938, the minimum wage was re-established pursuant to the Fair Labor Standards Act, this time at a uniform rate of $0.25 per hour ($4.78 in 2017 dollars). The Supreme Court upheld the Fair Labor Standards Act in \"United States v. Darby Lumber Co.\" (1941), holding that Congress had the power under the Commerce Clause to regulate employment conditions.\n\nThe 1938 minimum wage law only applied to \"employees engaged in interstate commerce or in the production of goods for interstate commerce,\" but in amendments in 1961 and 1966, the federal minimum wage was extended (with slightly different rates) to employees in large retail and service enterprises, local transportation and construction, state and local government employees, as well as other smaller expansions; a grandfather clause in 1990 drew most employees into the purview of federal minimum wage policy, which now set the wage at $3.80.\n\nThe federal minimum wage in the United States was reset to its current rate of $7.25 per hour in July 2009. Some U.S. territories (such as American Samoa) are exempt. Some types of labor are also exempt: Employers may pay tipped labor a minimum of $2.13 per hour, as long as the hour wage plus tip income equals at least the minimum wage. Persons under the age of 20 may be paid $4.25 an hour for the first 90 calendar days of employment (sometimes known as a youth, teen, or training wage) unless a higher state minimum exists. The 2009 increase was the last of three steps of the Fair Minimum Wage Act of 2007, which was signed into law as a rider to the U.S. Troop Readiness, Veterans' Care, Katrina Recovery, and Iraq Accountability Appropriations Act, 2007, a bill that also contained almost $5 billion in tax cuts for small businesses.\n\nSome politicians in the United States advocate linking the minimum wage to the consumer price index, thereby increasing the wage automatically each year based on increases to the consumer price index. Linking the minimum wage to the consumer price index avoids the erosion of the purchasing power of the minimum wage with time because of inflation. In 1998 Washington state became the first state to approve consumer price indexing for its minimum wage. In 2003 San Francisco, California and Santa Fe, New Mexico were the first cities to approve consumer price indexing for their minimum wage. Oregon and Florida were the next states to link their minimum wages to the consumer price index. Later in 2006, voters in six states (Arizona, Colorado, Missouri, Montana, Nevada, and Ohio) approved statewide increases in the state minimum wage. The amounts of these increases ranged from $1 to $1.70 per hour, and all increases were designed to annually index to inflation. As of 2018, the minimum wage is indexed to inflation in 17 states.\n\nSince 2012, a growing protest and advocacy movement called \"Fight for $15\", initially growing out of fast food worker strikes, has advocated for an increase in the minimum wage to a living wage. Since the start of these protests, a number of states and cities have increased their minimum wage. In 2014 Connecticut for instance passed legislation to raise the minimum wage from $8.70 to $10.10 per hour by 2017, making it one of about six states at the time to aim at or above $10.00 per hour. In 2014 and 2015, several cities, including San Francisco, Seattle, Los Angeles, and Washington D.C. passed ordinances that gradually increase the minimum wage to $15.00 per hour. In 2016 New York and California became the first states to pass legislation that would gradually raise the minimum wage to $15 per hour in each state, followed by Massachusetts in 2018.\n\nIn April 2014, the U.S. Senate debated the minimum wage on the federal level by way of the Minimum Wage Fairness Act. The bill would have amended the Fair Labor Standards Act of 1938 (FLSA) to increase the federal minimum wage for employees to $10.10 per hour over the course of a two-year period. The bill was strongly supported by President Barack Obama and many of the Democratic Senators, but strongly opposed by Republicans in the Senate and House. Later in 2014, voters in the Republican-controlled states of Alaska, Arkansas, Nebraska and South Dakota considered ballot initiatives to raise the minimum wage above the national rate of $7.25 per hour, which were successful in all four states. The results provided evidence that raising minimum wage has support across party lines.\n\nIn April 2017, Senator Bernie Sanders and Senator Patty Murray, backed by 28 of the Senate's Democrats, introduced new federal legislation which would raise the minimum wage to $15 per hour by 2024 and index it to inflation. The Raise the Wage Act of 2017, which was simultaneously introduced in the House of Representatives with 166 Democratic cosponsors, would raise the minimum wage to $9.25 per hour immediately, and then gradually increase it to $15 per hour by 2024, while simultaneously raising the minimum wage for tipped workers and phasing it out. The legislation was introduced according to Senator Bernie Sanders to make sure that every worker has at least a modest and decent standard of living.\n\nIn the United States, different states are able to set their own minimum wages independent of the federal government. When the state and federal minimum wage differ the higher wage prevails. As of January 2018, there were 29 states with a minimum wage higher than the federal minimum. Washington has the highest state minimum wage at $11.50 per hour. A number of states have also in recent years enacted state preemption laws, which restrict local community rights, and bar local governments from setting their own minimum wage amounts. As of 2017, state preemption laws for local minimum wages have passed in 25 states.\n\nLegislation has passed recently in multiple states that significantly raises the minimum wage. California is set to raise its minimum wage to $15.00 per hour by January 1, 2023. Colorado is set to raise its minimum wage from $9.30 per hour to $12 per hour by January 1, 2020, rising $0.90 per year. New York has also passed legislation to increase its minimum wage to $15.00 per hour over time, certain counties and larger companies are set on faster schedules than others. A number of other cities and states across the country are also debating and enacting legislation to increase the minimum wage for low wage workers to a livable wage.\n\nSome government entities, such as counties and cities, observe minimum wages that are higher than the state as a whole. In 2003 San Francisco, California and Santa Fe, New Mexico were the first two cities to introduce local minimum wage ordinances. Another device to increase wages locally are living wage ordinances, which generally apply only to businesses that are under contract to the local government itself. In 1994 Baltimore, Maryland was the first city in the United States to pass such a living wage ordinance. These targeted living wage ordinances for city contract workers have led in subsequent years to citywide local minimum wage laws which apply to all workers.\n\nIn the current wave of minimum wage legislative action, Seattle, Washington was the first city to pass on June 2, 2014 a local ordinance to increase the minimum wage for all workers to $15.00 per hour, which phases in over seven years. This ordinance followed the referendum in SeaTac, Washington in November 2013, which raised on a more limited scale the local minimum wage to $15.00 for transportation and hospitality workers. Numerous other cities have followed Seattle's example since. San Francisco became the first major city in the U.S. to reach a minimum wage of $15.00 per hour on July 1, 2018. New York City's minimum wage will be $15.00 per hour by the end of 2018. The minimum wage in Los Angeles and Washington, D.C., will be $15.00 per hour in 2020. Similarly, the minimum wage in Minneapolis, Minnesota will be $15.00 per hour by 2022. A growing number of other California cities have also enacted local minimum wage ordinances to increase the minimum wage to $15.00 per hour, including Berkeley, El Cerrito, Emeryville, Mountain View, Oakland, Richmond, and San Jose.\n\nSome minimum wage ordinances have an exemption for unionized workers. For instance, the Los Angeles City Council approved a minimum salary in 2014 for hotel workers of $15.37 per hour which has such an exemption. This led in some cases to longtime workers at unionized hotels such as the Sheraton Universal making $10.00 per hour, whereas non-union employees at a non-union Hilton less than 500 feet away making at least $15.37 as mandated by law for non-unionized employees. Similar exemptions have been adopted in other cities. As of December 2014, unions were exempt from minimum wage ordinances in Chicago, Illinois, SeaTac, Washington, and Milwaukee County, Wisconsin, as well as the California cities of Los Angeles, San Francisco, Long Beach, San Jose, Richmond, and Oakland. In 2016, the Washington, D.C. Council passed a minimum wage ordinance that included a union waiver, but Mayor Vincent Gray vetoed it. Later that year, the council approved an increase without the union waiver.\n\nThe federal minimum wage was introduced in 1938 at the rate of $0.25 per hour ($4.78 in 2018 dollars). By 1950 the minimum wage had risen to $0.75 per hour. The minimum wage had its highest purchasing power in 1968, when it was $1.60 per hour ($11.65 in 2018 dollars). The real value of the Federal minimum wage in 2016 dollars has decreased by one-third since 1968. The minimum wage would be $11 in 2016 if its real value had remained at the 1968 level. From January 1981 to April 1990, the minimum wage was frozen at $3.35 per hour, then a record-setting minimum wage freeze. From September 1, 1997 through July 23, 2007, the federal minimum wage remained constant at $5.15 per hour, breaking the old record. In 2009 the minimum wage was adjusted to $7.25 where it has remained fixed for the past nine years.\n\nThe purchasing power of the federal minimum wage has fluctuated. Since 1984, the purchasing power of the federal minimum wage has decreased. Measured in real terms (adjusted for inflation) using 1984 dollars, the real minimum wage was $3.35 in 1984, $2.33 in 1994, $1.84 in 2004, and $1.46 in 2014. If the minimum wage had been raised to $10.10 in 2014, that would have equated to $4.40 in 1984 dollars. This would have been equal to a 31% increase in purchasing power, despite the nominal value of the minimum wage increasing by 216% in the same time period.\n\nThe economic effects of raising the minimum wage are controversial. Adjusting the minimum wage may affect current and future levels of employment, prices of goods and services, economic growth, income inequality, and poverty. The interconnection of price levels, central bank policy, wage agreements, and total aggregate demand creates a situation in which conclusions drawn from macroeconomic analysis are highly influenced by the underlying assumptions of the interpreter.\n\nIn neoclassical economics, the law of demand states that—all else being equal—raising the price of any particular good or service reduces the quantity demanded. Therefore, neoclassical economists argue that—all else being equal—raising the minimum wage will have adverse effects on employment. Conceptually, if an employer does not believe a worker generates value equal to or in excess of the minimum wage, they do not hire or retain that worker.\n\nOther economists of different schools of thought argue that a limited increase in the minimum wage does not affect or increases the number of jobs available. Economist David Cooper for instance estimates that a higher minimum wage would support the creation of at least 85,000 new jobs in the United States. This divergence of thought began with empirical work on fast food workers in the 1990s which challenged the neoclassical model. In 1994, economists David Card and Alan Krueger studied employment trends among 410 restaurants in New Jersey and eastern Pennsylvania following New Jersey's minimum wage hike (from $4.25 to $5.05) in April 1992. They found \"no indication that the rise in the minimum wage reduced employment.\" In contrast, a 1995 analysis of the evidence by David Neumark found that the increase in New Jersey's minimum wage resulted in a 4.6% decrease in employment. Neumark's study relied on payroll records from a sample of large fast-food restaurant chains, whereas the Card-Krueger study relied on business surveys.\nA literature review conducted by David Neumark and William Wascher in 2007 (which surveyed 101 studies related to the employment effects of minimum wages) found that about two-thirds of peer-reviewed economic research showed a positive correlation between minimum wage hikes and increased unemployment—especially for young and unskilled workers. Neumark's review further found that, when looking at only the most credible research, 85% of studies showed a positive correlation between minimum wage hikes and increased unemployment.\n\nStatistical meta-analysis conducted by Tom Stanley in 2005 in contrast found that there is evidence of publication bias in minimum wage literature, and that correction of this bias shows no relationship between the minimum wage and unemployment. In 2008 Hristos Doucouliagos and Tom Stanley conducted a similar meta-analysis of 64 U.S. studies on disemployment effects and concluded that Card and Krueger's initial claim of publication bias was correct. Moreover, they concluded, \"Once this publication selection is corrected, little or no evidence of a negative association between minimum wages and employment remains.\"\nThe Congressional Budget Office (CBO) in 2014 estimated the theoretical effects of a federal minimum wage increase under two scenarios: an increase to $9.00 and an increase to $10.10. According to the report, approximately 100,000 jobs would be lost under the $9.00 option, whereas 500,000 jobs would be lost under the $10.10 option (with a wide range of possible outcomes). The Center for Economic and Policy Research (CEPR) in contrast in 2013 found in a review of multiple studies since 2000 that there was \"little or no employment response to modest increases in the minimum wage.\" CEPR found in a later study that job creation within the United States is faster within states that raised their minimum wage. In 2014 the state with the highest minimum wage in the nation, Washington, exceeded the national average for job growth in the United States. Washington had a job growth rate 0.3% faster than the national average job growth rate.\n\nA 2012 study led by Joseph Sabia estimated that the 2004-6 New York State minimum wage increase (from $5.15 to $6.75) resulted in a 20.2% to 21.8% reduction in employment for less-skilled, less-educated workers. Similarly, a study led by Richard Burkhauser in 2000 concluded that minimum wage increases \"significantly reduce the employment of the most vulnerable groups in the working-age population—young adults without a high school degree (aged 20-24), young black adults and teenagers (aged 16-24), and teenagers (aged 16-19).\"\n\n\"The Economist\" wrote in December 2013 in sum that: \"A minimum wage, providing it is not set too high, could thus boost pay with no ill effects on jobs...Some studies find no harm to employment from federal or state minimum wages, others see a small one, but none finds any serious damage...High minimum wages, however, particularly in rigid labour markets, do appear to hit employment. France has the rich world's highest wage floor, at more than 60% of the median for adults and a far bigger fraction of the typical wage for the young. This helps explain why France also has shockingly high rates of youth unemployment: 26% for 15- to 24-year-olds.\"\n\nConceptually, raising the minimum wage increases the cost of labor, ceteris paribus. Thus, employers may accept lower profits, raise their prices, or both. If prices increase, consumers may demand a lesser quantity of the product, substitute other products, or switch to imported products, due to the effects of price elasticity of demand. Marginal producers (those who are barely profitable enough to survive) may be forced out of business if they cannot raise their prices sufficiently to offset the higher cost of labor. Federal Reserve Bank of Chicago research from 2007 has shown that restaurant prices rise in response to minimum wage increases. However, there are studies that show that higher prices for products due to increased labor cost are usually only by about 0.4% of the original price.\n\nA 2016 White House report based on \"back of envelope calculations and literature review\" argued that higher hourly wages led to less crime. The study by the Council of Economic Advisers calculated that \"raising the minimum wage reduces crime by 3 to 5 percent.\" To get those numbers, the study assumed that \"such a minimum wage increase would have no employment impacts, with an employment elasticity of 0.1 the benefits would be somewhat lower.\"\n\nIn contrast in a 1987 journal article, Masanori Hashimoto noted that minimum wage hikes lead to increased levels of property crime in areas affected by the minimum wage after its increase. According to the article, by decreasing employment in poor communities, total legal trade and production are curtailed. The report also argued that to compensate for the decrease in legal avenues for production and consumption, poor communities increasingly turn to illegal trade and activity.\n\nWhether growth (GDP, a measure of both income and production) increases or decreases depends significantly on whether the income shifted from owners to workers results in an overall higher level of spending. The tendency of a consumer to spend their next dollar is referred to as the marginal propensity to consume or MPC. The transfer of income from higher income owners (who tend to save more, meaning a lower MPC) to lower income workers (who tend to save less, with a higher MPC) can actually lead to an increase in total consumption and higher demand for goods, leading to increased employment. Recent research has shown that higher wages lead to greater productivity.\n\nThe CBO reported in February 2014 that income (GDP) overall would be marginally higher after raising the minimum wage, indicating a small net positive increase in growth. Raising the minimum wage to $10.10 and indexing it to inflation would result in a net $2 billion increase in income during the second half of 2016, while raising it to $9.00 and not indexing it would result in a net $1 billion increase in income.\n\nAn increase in the minimum wage is a form of redistribution from higher-income persons (business owners or \"capital\") to lower income persons (workers or \"labor\") and therefore should reduce income inequality. The CBO estimated in February 2014 that raising the minimum wage under either scenario described above would improve income inequality. Families with income more than 6 times the poverty threshold would see their incomes fall (due in part to their business profits declining with higher employee costs), while families with incomes below that threshold would rise.\n\nAmong hourly-paid workers In 2016, 701,000 earned the federal minimum wage and about 1.5 million earned wages below the minimum.Together, these 2.2 million workers represented 2.7% of all hourly-paid workers.\n\nThe CBO estimated in February 2014 that raising the minimum wage would reduce the number of persons below the poverty income threshold by 900,000 under the $10.10 option versus 300,000 under the $9.00 option. Similarly, Arindrajit Dube, professor of economics at University of Massachusetts Amherst, found in a 2017 study \"robust evidence that higher minimum wages lead to increases in incomes among families at the bottom of the income distribution and that these wages reduce the poverty rate.\" According to the study \"a 10 percent increase in the minimum wage reduces the nonelderly poverty rate by about 5 percent.\"\n\nIn contrast, research conducted by David Neumark and colleagues in 2004 found that minimum wages are associated with reductions in the hours and employment of low-wage workers. A separate study by the same researchers found that minimum wages tend to increase the proportion of families with incomes below or near the poverty line. Similarly, a 2002 study led by Richard Vedder, professor of economics at Ohio University, concluded that \"The empirical evidence is strong that minimum wages have had little or no effect on poverty in the U.S. Indeed, the evidence is stronger that minimum wages occasionally increase poverty…\"\n\nWhen minimum wage increases; workers who have a lower income might lose their job. \n\nThe CBO reported in February 2014 that \"[T]he net effect on the federal budget of raising the minimum wage would probably be a small decrease in budget deficits for several years but a small increase in budget deficits thereafter. It is unclear whether the effect for the coming decade as a whole would be a small increase or a small decrease in budget deficits.\" On the cost side, the report cited higher wages paid by the government to some of its employees along with higher costs for certain procured goods and services. This might be offset by fewer government benefits paid, as some workers with higher incomes would receive fewer government transfer payments. On the revenue side, some would pay higher taxes and others less.\n\nAccording to a survey conducted by economist Greg Mankiw, 79% of economists agreed that \"a minimum wage increases unemployment among young and unskilled workers.\"\n\nA 2015 survey conducted by the University of New Hampshire Survey Center found that a majority of economists believes raising the minimum wage to $15 per hour would have negative effects on youth employment levels (83%), adult employment levels (52%), and the number of jobs available (76%). Additionally, 67% of economists surveyed believed that a $15 minimum wage would make it harder for small businesses with less than 50 employees to stay in business.\n\nA 2006 survey conducted by economist Robert Whaples of a sample of 210 Ph.D. economists randomly selected from the American Economic Association, found that, regarding the U.S. minimum wage:\n\nIn 2014, over 600 economists signed a letter in support of increasing the minimum wage to $10.10 with research suggesting that a minimum wage increase could have a small stimulative effect on the economy as low-wage workers spend their additional earnings, raising demand and job growth. Also, seven recipients of the Nobel Prize in Economic Sciences were among 75 economists endorsing an increase in the minimum wage for U.S. workers and said \"the weight\" of economic research shows higher pay doesn't lead to fewer jobs.\n\nAccording to a February 2013 survey of the University of Chicago IGM Forum, which includes approximately 40 economists:\n\nAccording to a fall 2000 survey conducted by Fuller and Geide-Stevenson, 73.5% (27.9% of which agreed with provisos) of American economists surveyed agreed that minimum wage laws increase unemployment among unskilled and young workers, while 26.5% disagreed with the statement.\n\nEconomist Paul Krugman advocated raising the minimum wage moderately in 2013, citing several reasons, including:\n\nDemocratic candidates, elected officials, and activists support an increase in the minimum wage. In his 2013 State of the Union Address, President Barack Obama called for an increase in the federal minimum wage to $9 an hour; several months later, Democrats Tom Harkin and George Miller proposed legislation to increase the federal minimum wage to $10.10; and in 2015, congressional Democrats introduced a proposal to increase the federal minimum wage to $12 an hour. These efforts did not succeed, but increases in city and state minimum wages prompted congressional Democrats to continue fighting for an increase on the federal level. After much internal party debate, the party's official platform adopted at the 2016 Democratic National Convention stated: \"We should raise the federal minimum wage to $15 an hour over time and index it, give all Americans the ability to join a union regardless of where they work, and create new ways for workers to have power in the economy so every worker can earn at least $15 an hour.\"\n\nMost Republican elected officials oppose action to increase the minimum wage, and have blocked Democratic efforts to increase the minimum wage. Republican leadership such as Speakers of the House John Boehner and Paul Ryan have opposed minimum wage increases. Some Republicans oppose having a minimum wage altogether, while a few, conversely, have supported minimum wage increases or indexing the minimum wage to inflation.\n\nThe Pew Center reported in January 2014 that 73% of Americans supported raising the minimum wage from $7.25 to $10. By party, 53% of Republicans and 90% of Democrats favored this action. Pew found a racial difference for support of a higher minimum wage in 2017 with most blacks and Hispanics supporting a $15.00 federal minimum wage, and 54% of whites opposing it.\n\nA Lake Research Partners poll in February 2012 found the following:\n\nThis is a list of the minimum wages (per hour) in each state and territory of the United States, for jobs covered by federal minimum wage laws. If the job is not subject to the federal Fair Labor Standards Act, then state, city, or other local laws may determine the minimum wage. A common exemption to the federal minimum wage is a company having revenue of less than $500,000 per year while not engaging in any interstate commerce.\n\nUnder the federal law, workers who receive a portion of their salary from tips, such as waitstaff, are required only to have their total compensation, including tips, meet the minimum wage. Therefore, often, their hourly wage, before tips, is less than the minimum wage. Seven states, and Guam, do not allow for a tip credit. Additional exemptions to the minimum wage include many seasonal employees, student employees, and certain disabled employees as specified by the FLSA.\n\nIn addition, some counties and cities within states may implement a higher minimum wage than the rest of their state. Sometimes this higher wage applies only to businesses that contract with the local government, while in other cases the higher minimum applies to all work.\n\nThe average US minimum wage per capita (2017) is $8.49 based on the population size of each state and generally represents the average minimum wage experienced by a person working in one of the fifty US states. Cities, counties, districts, and territories are not included in the calculation.\nAs of October 2016, there have been 29 states with a minimum wage higher than the federal minimum. From 2014 to 2015, nine states increased their minimum wage levels through automatic adjustments, while increases in 11 other states occurred through referendum or legislative action.\nBeginning in January 2017, Massachusetts and Washington state have the highest minimum wages in the country, at $11.00 per hour. New York City's minimum wage will be $15.00 per hour by the end of 2018.\n\nSome large employers in the traditionally low-paying retail sector have declared an internal minimum wage. As of 2018:\n\nJobs that a minimum wage is most likely to directly affect are those that pay close to the minimum.\n\nAccording to the May 2006 National Occupational Employment and Wage Estimates, the four lowest-paid occupational sectors in May 2006 (when the federal minimum wage was $5.15 per hour) were the following:\n\nTwo years later, in May 2008, when the federal minimum wage was $5.85 per hour and was about to increase to $6.55 per hour in July 2008, these same sectors were still the lowest-paying, but their situation (according to Bureau of Labor Statistics data) was:\n\nIn 2006, workers in the following 13 individual occupations received, on average, a median hourly wage of less than $8.00 per hour:\n\nIn 2008, only two occupations paid a median wage less than $8.00 per hour:\n\nAccording to the May 2009 National Occupational Employment and Wage Estimates, the lowest-paid occupational sectors in May 2009 (when the federal minimum wage was $7.25 per hour) were the following:\n\n"}
{"id": "38709540", "url": "https://en.wikipedia.org/wiki?curid=38709540", "title": "New Hire Registry", "text": "New Hire Registry\n\nThe New Hire Registry is a program established in the United States pursuant to the \"Personal Responsibility and Work Opportunity Reconciliation Act\" (PRWORA) of 1996, 42 U.S.C. 653a, which required each state, the District of Columbia, and the Federal Government for its own employees, to establish - or contract with a provider to operate - a system where all new hires by any employer must be reported to a state-established New Hire Registry for that state. All employers of employees for wages have been required since 1997 to register with their state for reporting, and to report new hires within 20 days of employment, except employers who file new hire reports electronically, who must file a report every 12 to 16 days. The ostensible purpose of the program is to check for \"deadbeat parents\", e.g. persons not paying required child support orders, but may also be used for abuse of other payment-related programs such as unemployment insurance.\n\nAll employers of employees for wages must register with their state's New Hire Registry, and are required to report to the registry all new hires or all rehires of former employees who have been separated from the employer for more than 60 days. All employees must be reported, including employees who were hired or worked for less than one day, domestic employees such as a maid, gardener, cook, etc., and seasonal employees. The law's reporting requirements strictly include all employees for wages. An employer must report all persons who would be considered employees under federal rules for withholding of employment taxes to the state's New Hire Registry. Reporting of independent contractors is not required, but is encouraged.\n\nWhile reporting of employees who are no longer working for the employer may not seem to be helpful, since the report includes the address of the employee, it may be useful in tracking down an employee who has unpaid child support payments or might be committing unemployment insurance fraud.\n\nNo employer is exempt from reporting new hires, with the exception of Federal intelligence agencies where the director of the agency has determined that reporting may jeopardize the safety of certain employees or may compromise National Security.\n\nThe report which is required to be filed includes the name, address and social security number of every new hire, as well as the name, address, and Federal Employer Identification Number of the employer, for each new hire made within the last 20 days or within the last two weeks for employers filing electronically.\n\nAn employer within a single state files with the New Hire Registry of the state where they operate; multistate employers may choose to either file new hire reports with each state where the employee works, or instead may file a single combined report for all employees for all states where it operates with one state's New Hire Registry, but must not make both reports.\n"}
{"id": "29094247", "url": "https://en.wikipedia.org/wiki?curid=29094247", "title": "Northwestern Journal of Technology and Intellectual Property", "text": "Northwestern Journal of Technology and Intellectual Property\n\nThe Northwestern Journal of Technology and Intellectual Property is a law review published by an independent student organization at Northwestern University School of Law. The current editor-in-chief is Heath Ingram.\n\nThe \"Northwestern Journal of Technology and Intellectual Property\" covers academic, business, and legal issues concerning intellectual property and technology law. It publishes articles on a variety of topics including: copyright, trademark, patents, the Internet, media, telecommunications, health care, antitrust, e‑discovery, and trial and litigation technology.\n\nThe \"Northwestern Journal of Technology and Intellectual Property\" publishes three full issues each year and five \"perspectives\" issues. Perspectives issues contain shorter articles detailing a new development in the law of intellectual property or offering a new perspective on more developed issues within the law.\n\nEvery Spring, the journal hosts a symposium on emerging areas of technology and intellectual property law. Recent symposia have included: \"New Rules for a New Day: Examining Recent Trends in IP Law\" (2010) and \"Riding the Wave: Understanding Recent Developments in IP Law\" (2009).\n\n\n"}
{"id": "30938791", "url": "https://en.wikipedia.org/wiki?curid=30938791", "title": "Paris v Stepney BC", "text": "Paris v Stepney BC\n\nParis v Stepney Borough Council [1950] UKHL 3 was a decision of the House of Lords that significantly affected the concept of Standard of care in common law. The plaintiff Paris was employed by the then Stepney Borough Council as a general garage-hand. He had sight in only one eye, and his employer was aware of this. The council only issued eye protection goggles to its employees who were welders or tool-grinders. In the course of his usual work, Paris received an injury to his sighted eye. He sued the council for damages in the tort of negligence. On appeal it was decided that Stepney Borough Council was aware of his special circumstances and failed in their duty of care to give him protective goggles.\n\nParis was employed by Stepney Borough Council as garage-hand. He had suffered a war injury that left him with sight in only one eye. While Paris was attempting to loosen a rusted car axle bolt with a hammer, he caused a chip of metal to fly into his sighted eye, and as a result was permanently blinded in both eyes.\n"}
{"id": "677754", "url": "https://en.wikipedia.org/wiki?curid=677754", "title": "Power of the purse", "text": "Power of the purse\n\nThe power of the purse is the ability of one group to manipulate and control the actions of another group by withholding funding, or putting stipulations on the use of funds. The power of the purse can be used positively (e.g. awarding extra funding to programs that reach certain benchmarks) or negatively (e.g. removing funding for a department or program, effectively eliminating it). The power of the purse is most often utilized by forces within a government that do not have direct executive power, but have control over budgets and taxation.\n\nIn colonial Canada, the fight for \"responsible government\" in the 1840s centered on question of whether elected parliaments or appointed governors would have control over the purse strings, mirroring earlier fights between Parliament and the Crown in Britain.\n\nAfter confederation, the phrase \"power of the purse\" took on a particular meaning. It now primarily refers to the federal government's superior tax-raising abilities compared to the provinces, and the consequent ability of the federal government to compel provincial governments to adopt certain policies in exchange for transfer payments. Most famously, the Canada Health Act sets rules that provinces adhere to receive health transfers (the largest such transfers). Opponents of this arrangement refer to this situation as the \"fiscal imbalance\", while others argue for the federal government's role in setting minimum standards for social programs in Canada.\n\nThe power of the purse's earliest examples in a modern sense occurred in the English Parliament, which gained the exclusive power to authorise taxes and thus could control the nation's cash flow. Through this power, Parliament slowly subverted the executive strength of the crown; King Charles II was limited in his powers to engage in various war efforts by a refusal by Parliament to authorise further taxes and by his inability to secure loans from foreign nations, making him much less powerful.\n\nIn recent years as a result of devolution, funding for devolved issues to the Scottish Parliament as well as the Welsh and Northern Irish assemblies has been determined through the Barnett Formula. This formula determines the overall budget of the devolved parliaments for devolved issues proportionally relative to spending on those issues in England. As a result, while responsibility for funding of devolved matters rests with the devolved bodies themselves, they in effect must enact policies of a broadly similar cost to those decided by the UK parliament for England and maintain that broad proportionality in order to ensure the long term financial viability of such policies.\n\nIn the federal government of the United States, the power of the purse is vested in the Congress as laid down in the Constitution of the United States, Article I, Section 9, Clause 7 (the Appropriations Clause) and Article I, Section 8, Clause 1 (the Taxing and Spending Clause).\n\nThe power of the purse plays a critical role in the relationship of the United States Congress and the President of the United States, and has been the main historic tool by which Congress has limited executive power. One of the most prominent examples is the Foreign Assistance Act of 1974, which eliminated all military funding for the government of South Vietnam and thereby ended the Vietnam War. Other recent examples include limitations on military funding placed on Ronald Reagan by Congress, which led to the withdrawal of United States Marines from Lebanon.\n\nThe power of the purse in military affairs was famously subverted during the Iran-Contra scandal in the 1980s. Congress denied further aid to the Contras in Nicaragua. Unwilling to accept the will of Congress, members of the Reagan administration solicited private donations, set up elaborate corporate schemes and brokered illegal arms deals with Iran in order to generate unofficial funds that could not be regulated by Congress.\n\nMore recently, budget limitations and using the power of the purse formed a controversial part of discussion regarding Congressional opposition to the Iraq War. On March 23, 2007, the U.S. House of Representatives passed a supplemental war budget that imposed a timeline on the presence of American combat troops in Iraq, but the legislation was not passed.\n\nThe power of the purse has also been used to compel the U.S. states to pass laws, in cases where Congress does not have the desire or constitutional power to make it a federal matter. The most well-known example of this is regarding the drinking age, where Congress passed a law to withhold 10% of federal funds for highways in any state that did not raise the age to 21. The law was upheld by the U.S. Supreme Court in the \"South Dakota v. Dole\" case. Congress was not allowed to change the drinking age directly because the 21st Amendment (which ended Prohibition in the U.S.) gave control of alcohol to the states. In 2009, Congress considered similar legislation regarding texting while driving.\n\nThis power was curtailed somewhat in a case regarding the Affordable Care Act, in which the Supreme Court ruled in June 2012 that the law's withholding of all existing Medicaid funding for states that failed or refused to expand their Medicaid programs to cover the uninsured poor was \"unduly coercive\", despite the fact that the federal government would pay the entirety of the states' expansion for the first years, and 90% thereafter. It was left unclear what percentage would be considered acceptable.\n\nIn the US Congress or Senate, the chairperson of a legislative committee may refuse to give funding to a senator or other delegate or representative, or deny his or her appropriations bill or amendment a vote, because he or she refused to support a bill which the chairperson wanted (a tit-for-tat retaliation). While typically applied to \"pork barrel\" spending for special interests, it may also block funding for genuine needs of a constituency or the general public.\n\nThe administration or student government at a college or university may revoke some or even all funding for a student newspaper or student radio station, because it has printed or aired an editorial or a news article or segment critical of it. This is also an example of censorship.\n\n"}
{"id": "10039586", "url": "https://en.wikipedia.org/wiki?curid=10039586", "title": "Production write-through contract", "text": "Production write-through contract\n\nA production write-through contract is an arrangement, specific to the film industry, where a screenwriter enters into a commercial agreement with a studio that guarantees the screenwriter the right to do all the necessary rewrites to his or her screenplay. The screenwriter will be on the set throughout the production of the film, and will do the rewrites that a production rewriter would otherwise do.\n"}
{"id": "26187730", "url": "https://en.wikipedia.org/wiki?curid=26187730", "title": "Russian competition law", "text": "Russian competition law\n\nAntitrust issues in Russia are regulated by one law: Federal Law No. 135-FZ, “On the Protection of Competition\", which entered into force on 26 October 2006.\n\nThe “3rd antimonopoly package”, which entered into force in January 2012, is indicative of a general trend of liberalization of antimonopoly regulation. Indeed, its stated aim was to bring Russia more in line with European competition regulations.\n\nRussian competition law was ratified by the Supreme Soviet of the USSR in March 1991. In the final stages of glasnost and the deteriorating tethering of the USSR, the various member soviet republics saw the need for regulation and stabilisation of trade. The representatives to the Supreme Soviet of the USSR ratified the Law on Competition and Limitation of Monopolistic Activity in Goods Market in March 1991 which became anti-monopoly policies within Russia after secession from the USSR. \nThe Law on the Protection of Competition of 2006 is legislation pursued to translate those policies back into law.\n\nFederal Law No. 135-FZ, “On the Protection of Competition\", was legislated on July 26, 2006, and entered into force on October 26, 2006.\n\nThe law was \"initiated and developed\" by the Federal Antimonopoly Service of Russia (FAS) (), the federal-level executive governmental organ that controls the execution of antitrust and competition. Headed by Igor Artemyev, it had been established by the Decree of President of Russia №314 on March 9, 2004.\n\nThe law also gives the FAS authority over approval of company mergers stipulating various combinations of thresholds of assets of merging companies, an excess of which would require prior approval from the FAS. The scope of regulation of the FAS is focused on the commodity market and financial services with mandates over operations and transactions not just within the Russian Federation but also those taking place outside the boundaries of Russia which would have anti-competitive effects on the Russian market place. As with the trend in the United States and the European Union, the FAS has also taken Microsoft to task for anti-competitive behaviour by bringing Microsoft to court on 4 June 2009.\n\nBeyond western European competition laws against dominance, the Competition Law in Russia expressly presumes the existence of dominance by defining thresholds.\n\nThe law also places restrictions on aids from, and public procurement policies of, federal, provincial, or municipal governments that otherwise would encourage anti-competition.\n\nIn addition to a distinct competition law, the Code of Administrative Offences has also been amended to increase liability of anti-competitive practices. Punitive measures against anti-competitive practices are meted out in terms of percentages of revenues of a company. Company directors can be criminally liable in cases of a repeated abuse—e.g., establishing high monopoly or low monopoly prices, unjustified evasion from the execution of contracts with individual customers, creation of obstacles for other entities entering the market—and can be sentenced to up to 7 years in prison.\n\n"}
{"id": "1482294", "url": "https://en.wikipedia.org/wiki?curid=1482294", "title": "Seniority (financial)", "text": "Seniority (financial)\n\nIn finance, seniority refers to the order of repayment in the event of a sale or bankruptcy of the issuer. Seniority can refer to either debt or preferred stock. Senior debt must be repaid before subordinated (or junior) debt is repaid. Each security, either debt or equity, that a company issues has a specific seniority or ranking. Bonds that have the same seniority in a company's capital structure are described as being pari passu. Preferred stock is senior to common stock in a sale when preferred shareholders must receive back their preference, typically their original investment amount, before the common shareholders receive anything.\n\nThe seniority of bonds recognised in FpML (Financial products Markup Language) are as follows:\n"}
{"id": "35890754", "url": "https://en.wikipedia.org/wiki?curid=35890754", "title": "Sharism", "text": "Sharism\n\nSharism is a philosophy on sharing content and ideas, developed by Isaac Mao. Inspired by user-generated content, sharism states that the act of sharing something within a community produces a proper value for each of its participants: \"the more you share, the more you receive\". As knowledge is produced through crowdsourcing, this new kind of shared ownership leads to the production of goods and services where value is distributed through the contributions of everyone involved.\n\n\"Sharism\" was coined by Isaac Mao in the essay \"Sharism: A Mind Revolution\" which was originally published in the book \"Freesouls\". Mao draws a comparison between the open distribution model of online information sharing and the neurological networks of the human brain. Following the analogy of an emerging Social Brain, Mao argues that the process of empowering people through sharing leads to collective ways of rethinking social relationships.\n\nSharism has been particularly focused in China in order to promote the Open Web and combat Internet censorship. Notable proponents of sharism as both a term and practice have included Larry Lessig and Ou Ning. In 2010 during a Creative Commons lecture in Beijing, Lessig mentioned sharism in the context of openness and innovation in creative industries and intellectual property law in China. Also in 2010, Ou in his role as a curator choose sharism as the unifying theme for the Shanghai biennale exhibition \"Get It Louder\". In an interview about the exhibition, Ou discussed sharism at length and described it as an \"Internet concept\" that explores the increasingly convoluted relationship between public and private realms.\"\n\nSharism Lab was created in 2012 with the purpose of providing experimental and theoretical background for a real-world implementation of sharism.\n\nSeveral types of sharism events have been created for people to meet and share things they like or things they make. Sharism Forum was held in October 2010 at the Get It Louder festival in Shanghai, and gathered international speakers, practitioners and activists to discuss the idea of sharism. \n\nAnother event called \"Sharism Presents\" offers an informal setup for people to share whatever they want with the attending audience. Since 2010, Sharism Presents have been hosted in many cities throughout the world, included: Amsterdam, Shanghai, Beijing, Madrid, Barcelona, Brussels, Berlin, Montreal, Singapore, Hong Kong, Tokyo and Seoul.\n\nSharism Workshops provide a framework for collective production through the act of sharing. Workshops have been held in Beijing, Doha and Warsaw and have included musicians, digital artists, and designers.\n\nIn order to offer an easy way to share any kind of work online, the Sharing Agreement has been created in order to work around the increasing complexity of licenses.\n\nMany academics point to the downsides of such uncritical belief in the transformative power of technology. User generated content has been reframed as \"Loser Generated Content\", as the value of this sharing often ends up with companies, and not in the public domain.\nWithin the art world, it has been suggested that there are \"dangers of 'sharism\", which \"lead people to believe that whatever is contemporary must also be avantgarde.\"\n\n\n"}
{"id": "37738", "url": "https://en.wikipedia.org/wiki?curid=37738", "title": "Soil", "text": "Soil\n\nSoil is a mixture of organic matter, minerals, gases, liquids, and organisms that together support life. Earth's body of soil is the pedosphere, which has four important functions: it is a medium for plant growth; it is a means of water storage, supply and purification; it is a modifier of Earth's atmosphere; it is a habitat for organisms; all of which, in turn, modify the soil.\n\nThe pedosphere interfaces with the lithosphere, the hydrosphere, the atmosphere, and the biosphere. The term \"pedolith\", used commonly to refer to the soil, translates to \"ground stone\". Soil consists of a solid phase of minerals and organic matter (the soil matrix), as well as a porous phase that holds gases (the soil atmosphere) and water (the soil solution). Accordingly, soils are often treated as a three-state system of solids, liquids, and gases.\n\nSoil is a product of the influence of climate, relief (elevation, orientation, and slope of terrain), organisms, and its parent materials (original minerals) interacting over time. It continually undergoes development by way of numerous physical, chemical and biological processes, which include weathering with associated erosion. Given its complexity and strong internal connectedness, it is considered an ecosystem by soil ecologists.\n\nMost soils have a dry bulk density (density of soil taking into account voids when dry) between 1.1 and 1.6 g/cm, while the soil particle density is much higher, in the range of 2.6 to 2.7 g/cm. Little of the soil of planet Earth is older than the Pleistocene and none is older than the Cenozoic, although fossilized soils are preserved from as far back as the Archean.\n\nSoil science has two basic branches of study: edaphology and pedology. Edaphology is concerned with the influence of soils on living things. Pedology is focused on the formation, description (morphology), and classification of soils in their natural environment. In engineering terms, soil is included in the broader concept of regolith, which also includes other loose material that lies above the bedrock, as can be found on the Moon and other celestial objects, as well. Soil is also commonly referred to as earth or dirt; some scientific definitions distinguish \"dirt\" from \"soil\" by restricting the former term specifically to the displaced soil.\n\nSoil is a major component of the Earth's ecosystem. The world's ecosystems are impacted in far-reaching ways by the processes carried out in the soil, from ozone depletion and global warming to rainforest destruction and water pollution. With respect to Earth's carbon cycle, soil is an important carbon reservoir, and it is potentially one of the most reactive to human disturbance and climate change. As the planet warms, it has been predicted that soils will add carbon dioxide to the atmosphere due to increased biological activity at higher temperatures, a positive feedback (amplification). This prediction has, however, been questioned on consideration of more recent knowledge on soil carbon turnover.\n\nSoil acts as an engineering medium, a habitat for soil organisms, a recycling system for nutrients and organic wastes, a regulator of water quality, a modifier of atmospheric composition, and a medium for plant growth, making it a critically important provider of ecosystem services. Since soil has a tremendous range of available niches and habitats, it contains most of the Earth's genetic diversity. A gram of soil can contain billions of organisms, belonging to thousands of species, mostly microbial and in the main still unexplored. Soil has a mean prokaryotic density of roughly 10 organisms per gram, whereas the ocean has no more than 10 procaryotic organisms per milliliter (gram) of seawater. Organic carbon held in soil is eventually returned to the atmosphere through the process of respiration carried out by heterotrophic organisms, but a substantial part is retained in the soil in the form of soil organic matter; tillage usually increases the rate of soil respiration, leading to the depletion of soil organic matter. Since plant roots need oxygen, ventilation is an important characteristic of soil. This ventilation can be accomplished via networks of interconnected soil pores, which also absorb and hold rainwater making it readily available for uptake by plants. Since plants require a nearly continuous supply of water, but most regions receive sporadic rainfall, the water-holding capacity of soils is vital for plant survival.\n\nSoils can effectively remove impurities, kill disease agents, and degrade contaminants, this latter property being called natural attenuation. Typically, soils maintain a net absorption of oxygen and methane and undergo a net release of carbon dioxide and nitrous oxide. Soils offer plants physical support, air, water, temperature moderation, nutrients, and protection from toxins. Soils provide readily available nutrients to plants and animals by converting dead organic matter into various nutrient forms.\n\nA typical soil is about 50% solids (45% mineral and 5% organic matter), and 50% voids (or pores) of which half is occupied by water and half by gas. The percent soil mineral and organic content can be treated as a constant (in the short term), while the percent soil water and gas content is considered highly variable whereby a rise in one is simultaneously balanced by a reduction in the other. The pore space allows for the infiltration and movement of air and water, both of which are critical for life existing in soil. Compaction, a common problem with soils, reduces this space, preventing air and water from reaching plant roots and soil organisms.\n\nGiven sufficient time, an undifferentiated soil will evolve a soil profile which consists of two or more layers, referred to as soil horizons, that differ in one or more properties such as in their texture, structure, density, porosity, consistency, temperature, color, and reactivity. The horizons differ greatly in thickness and generally lack sharp boundaries; their development is dependent on the type of parent material, the processes that modify those parent materials, and the soil-forming factors that influence those processes. The biological influences on soil properties are strongest near the surface, while the geochemical influences on soil properties increase with depth. Mature soil profiles typically include three basic master horizons: A, B, and C. The solum normally includes the A and B horizons. The living component of the soil is largely confined to the solum, and is generally more prominent in the A horizon.\n\nThe soil texture is determined by the relative proportions of the individual particles of sand, silt, and clay that make up the soil. The interaction of the individual mineral particles with organic matter, water, gases via biotic and abiotic processes causes those particles to flocculate (stick together) to form aggregates or peds. Where these aggregates can be identified, a soil can be said to be developed, and can be described further in terms of color, porosity, consistency, reaction (acidity), etc.\n\nWater is a critical agent in soil development due to its involvement in the dissolution, precipitation, erosion, transport, and deposition of the materials of which a soil is composed. The mixture of water and dissolved or suspended materials that occupy the soil pore space is called the soil solution. Since soil water is never pure water, but contains hundreds of dissolved organic and mineral substances, it may be more accurately called the soil solution. Water is central to the dissolution, precipitation and leaching of minerals from the soil profile. Finally, water affects the type of vegetation that grows in a soil, which in turn affects the development of the soil, a complex feedback which is exemplified in the dynamics of banded vegetation patterns in semi-arid regions.\n\nSoils supply plants with nutrients, most of which are held in place by particles of clay and organic matter (colloids) The nutrients may be adsorbed on clay mineral surfaces, bound within clay minerals (absorbed), or bound within organic compounds as part of the living organisms or dead soil organic matter. These bound nutrients interact with soil water to buffer the soil solution composition (attenuate changes in the soil solution) as soils wet up or dry out, as plants take up nutrients, as salts are leached, or as acids or alkalis are added.\n\nPlant nutrient availability is affected by soil pH, which is a measure of the hydrogen ion activity in the soil solution. Soil pH is a function of many soil forming factors, and is generally lower (more acid) where weathering is more advanced.\n\nMost plant nutrients, with the exception of nitrogen, originate from the minerals that make up the soil parent material. Some nitrogen originates from rain as dilute nitric acid and ammonia, but most of the nitrogen is available in soils as a result of nitrogen fixation by bacteria. Once in the soil-plant system, most nutrients are recycled through living organisms, plant and microbial residues (soil organic matter), mineral-bound forms, and the soil solution. Both living microorganisms and soil organic matter are of critical importance to this recycling, and thereby to soil formation and soil fertility. Microbial activity in soils may release nutrients from minerals or organic matter for use by plants and other microorganisms, sequester (incorporate) them into living cells, or cause their loss from the soil by volatilisation (loss to the atmosphere as gases) or leaching.\n\nThe history of the study of soil is intimately tied to humans' urgent need to provide food for themselves and forage for our animals. Throughout history, civilizations have prospered or declined as a function of the availability and productivity of their soils.\n\nThe Greek historian Xenophon (450–355 BCE) is credited with being the first to expound upon the merits of green-manuring crops: \"But then whatever weeds are upon the ground, being turned into earth, enrich the soil as much as dung.\"\n\nColumella's \"Husbandry,\" circa 60 CE, advocated the use of lime and that clover and alfalfa (green manure) should be turned under, and was used by 15 generations (450 years) under the Roman Empire until its collapse. From the fall of Rome to the French Revolution, knowledge of soil and agriculture was passed on from parent to child and as a result, crop yields were low. During the European Dark Ages, Yahya Ibn al-'Awwam's handbook, with its emphasis on irrigation, guided the people of North Africa, Spain and the Middle East; a translation of this work was finally carried to the southwest of the United States when under Spanish influence. Olivier de Serres, considered as the father of French agronomy, was the first to suggest the abandonment of fallowing and its replacement by hay meadows within crop rotations, and he highlighted the importance of soil (the French terroir) in the management of vineyards. His famous book \"Le Théâtre d’Agriculture et mesnage des champs\" contributed to the rise of modern, sustainable agriculture and to the collapse of old agricultural practices such as the lifting of forest litter for the amendment of crops (the French \"soutrage\") and assarting, which ruined the soils of western Europe during Middle Ages and even later on according to regions.\n\nExperiments into what made plants grow first led to the idea that the ash left behind when plant matter was burned was the essential element but overlooked the role of nitrogen, which is not left on the ground after combustion, a belief which prevailed until the 19th century. In about 1635, the Flemish chemist Jan Baptist van Helmont thought he had proved water to be the essential element from his famous five years' experiment with a willow tree grown with only the addition of rainwater. His conclusion came from the fact that the increase in the plant's weight had apparently been produced only by the addition of water, with no reduction in the soil's weight. John Woodward (d. 1728) experimented with various types of water ranging from clean to muddy and found muddy water the best, and so he concluded that earthy matter was the essential element. Others concluded it was humus in the soil that passed some essence to the growing plant. Still others held that the vital growth principal was something passed from dead plants or animals to the new plants. At the start of the 18th century, Jethro Tull demonstrated that it was beneficial to cultivate (stir) the soil, but his opinion that the stirring made the fine parts of soil available for plant absorption was erroneous.\n\nAs chemistry developed, it was applied to the investigation of soil fertility. The French chemist Antoine Lavoisier showed in about 1778 that plants and animals must [combust] oxygen internally to live and was able to deduce that most of the 165-pound weight of van Helmont's willow tree derived from air. It was the French agriculturalist Jean-Baptiste Boussingault who by means of experimentation obtained evidence showing that the main sources of carbon, hydrogen and oxygen for plants were air and water, while nitrogen was taken from soil. Justus von Liebig in his book \"Organic chemistry in its applications to agriculture and physiology\" (published 1840), asserted that the chemicals in plants must have come from the soil and air and that to maintain soil fertility, the used minerals must be replaced. Liebig nevertheless believed the nitrogen was supplied from the air. The enrichment of soil with guano by the Incas was rediscovered in 1802, by Alexander von Humboldt. This led to its mining and that of Chilean nitrate and to its application to soil in the United States and Europe after 1840.\n\nThe work of Liebig was a revolution for agriculture, and so other investigators started experimentation based on it. In England John Bennet Lawes and Joseph Henry Gilbert worked in the Rothamsted Experimental Station, founded by the former, and (re)discovered that plants took nitrogen from the soil, and that salts needed to be in an available state to be absorbed by plants. Their investigations also produced the \"superphosphate\", consisting in the acid treatment of phosphate rock. This led to the invention and use of salts of potassium (K) and nitrogen (N) as fertilizers. Ammonia generated by the production of coke was recovered and used as fertiliser. Finally, the chemical basis of nutrients delivered to the soil in manure was understood and in the mid-19th century chemical fertilisers were applied. However, the dynamic interaction of soil and its life forms still awaited discovery.\n\nIn 1856 J. Thomas Way discovered that ammonia contained in fertilisers was transformed into nitrates, and twenty years later Robert Warington proved that this transformation was done by living organisms. In 1890 Sergei Winogradsky announced he had found the bacteria responsible for this transformation.\n\nIt was known that certain legumes could take up nitrogen from the air and fix it to the soil but it took the development of bacteriology towards the end of the 19th century to lead to an understanding of the role played in nitrogen fixation by bacteria. The symbiosis of bacteria and leguminous roots, and the fixation of nitrogen by the bacteria, were simultaneously discovered by the German agronomist Hermann Hellriegel and the Dutch microbiologist Martinus Beijerinck.\n\nCrop rotation, mechanisation, chemical and natural fertilisers led to a doubling of wheat yields in western Europe between 1800 and 1900.\n\nThe scientists who studied the soil in connection with agricultural practices had considered it mainly as a static substrate. However, soil is the result of evolution from more ancient geological materials, under the action of biotic and abiotic (not associated with life) processes. After studies of the improvement of the soil commenced, others began to study soil genesis and as a result also soil types and classifications.\n\nIn 1860, in Mississippi, Eugene W. Hilgard studied the relationship among rock material, climate, and vegetation, and the type of soils that were developed. He realised that the soils were dynamic, and considered soil types classification. Unfortunately his work was not continued. At the same time Vasily Dokuchaev (about 1870) was leading a team of soil scientists in Russia who conducted an extensive survey of soils, finding that similar basic rocks, climate and vegetation types lead to similar soil layering and types, and established the concepts for soil classifications. Due to language barriers, the work of this team was not communicated to western Europe until 1914 through a publication in German by Konstantin Dmitrievich Glinka, a member of the Russian team.\n\nCurtis F. Marbut was influenced by the work of the Russian team, translated Glinka's publication into English, and as he was placed in charge of the U. S. National Cooperative Soil Survey, applied it to a national soil classification system.\n\nSoil formation, or pedogenesis, is the combined effect of physical, chemical, biological and anthropogenic processes working on soil parent material. Soil is said to be formed when organic matter has accumulated and colloids are washed downward, leaving deposits of clay, humus, iron oxide, carbonate, and gypsum, producing a distinct layer called the B horizon. This is a somewhat arbitrary definition as mixtures of sand, silt, clay and humus will support biological and agricultural activity before that time. These constituents are moved from one level to another by water and animal activity. As a result, layers (horizons) form in the soil profile. The alteration and movement of materials within a soil causes the formation of distinctive soil horizons. However, more recent definitions of soil embrace soils without any organic matter, such as those regoliths that formed on Mars and analogous conditions in planet Earth deserts.\n\nAn example of the development of a soil would begin with the weathering of lava flow bedrock, which would produce the purely mineral-based parent material from which the soil texture forms. Soil development would proceed most rapidly from bare rock of recent flows in a warm climate, under heavy and frequent rainfall. Under such conditions, plants (in a first stage nitrogen-fixing lichens and cyanobacteria then epilithic higher plants) become established very quickly on basaltic lava, even though there is very little organic material. The plants are supported by the porous rock as it is filled with nutrient-bearing water that carries minerals dissolved from the rocks. Crevasses and pockets, local topography of the rocks, would hold fine materials and harbour plant roots. The developing plant roots are associated with mineral-weathering mycorrhizal fungi that assist in breaking up the porous lava, and by these means organic matter and a finer mineral soil accumulate with time. Such initial stages of soil development have been described on volcanoes, inselbergs, and glacial moraines.\n\nHow soil formation proceeds is influenced by at least five classic factors that are intertwined in the evolution of a soil. They are: parent material, climate, topography (relief), organisms, and time. When reordered to climate, relief, organisms, parent material, and time, they form the acronym CROPT.\n\nThe mineral material from which a soil forms is called parent material. Rock, whether its origin is igneous, sedimentary, or metamorphic, is the source of all soil mineral materials and the origin of all plant nutrients with the exceptions of nitrogen, hydrogen and carbon. As the parent material is chemically and physically weathered, transported, deposited and precipitated, it is transformed into a soil.\n\nTypical soil parent mineral materials are:\nParent materials are classified according to how they came to be deposited. Residual materials are mineral materials that have weathered in place from primary bedrock. Transported materials are those that have been deposited by water, wind, ice or gravity. Cumulose material is organic matter that has grown and accumulates in place.\n\nResidual soils are soils that develop from their underlying parent rocks and have the same general chemistry as those rocks. The soils found on mesas, plateaux, and plains are residual soils. In the United States as little as three percent of the soils are residual.\n\nMost soils derive from transported materials that have been moved many miles by wind, water, ice and gravity.\n\nCumulose parent material is not moved but originates from deposited organic material. This includes peat and muck soils and results from preservation of plant residues by the low oxygen content of a high water table. While peat may form sterile soils, muck soils may be very fertile.\n\nThe weathering of parent material takes the form of physical weathering (disintegration), chemical weathering (decomposition) and chemical transformation. Generally, minerals that are formed under high temperatures and pressures at great depths within the Earth's mantle are less resistant to weathering, while minerals formed at low temperature and pressure environment of the surface are more resistant to weathering. Weathering is usually confined to the top few meters of geologic material, because physical, chemical, and biological stresses and fluctuations generally decrease with depth. Physical disintegration begins as rocks that have solidified deep in the Earth are exposed to lower pressure near the surface and swell and become mechanically unstable. Chemical decomposition is a function of mineral solubility, the rate of which doubles with each 10 °C rise in temperature, but is strongly dependent on water to effect chemical changes. Rocks that will decompose in a few years in tropical climates will remain unaltered for millennia in deserts. Structural changes are the result of hydration, oxidation, and reduction. Chemical weathering mainly results from the excretion of organic acids and chelating compounds by bacteria and fungi, thought to increase under present-day greenhouse effect.\n\n\nOf the above, hydrolysis and carbonation are the most effective, in particular in regions of high rainfall, temperature and physical erosion. Chemical weathering becomes more effective as the surface area of the rock increases, thus is favoured by physical disintegration. This stems in latitudinal and altitudinal climate gradients in regolith formation.\n\nSaprolite is a particular example of a residual soil formed from the transformation of granite, metamorphic and other types of bedrock into clay minerals. Often called [weathered granite], saprolite is the result of weathering processes that include: hydrolysis, chelation from organic compounds, hydration (the solution of minerals in water with resulting cation and anion pairs) and physical processes that include freezing and thawing. The mineralogical and chemical composition of the primary bedrock material, its physical features, including grain size and degree of consolidation, and the rate and type of weathering transforms the parent material into a different mineral. The texture, pH and mineral constituents of saprolite are inherited from its parent material. This process is also called \"arenization\", resulting in the formation of sandy soils (granitic arenas), thanks to the much higher resistance of quartz compared to other mineral components of granite (micas, amphiboles, feldspars).\n\nThe principal climatic variables influencing soil formation are effective precipitation (i.e., precipitation minus evapotranspiration) and temperature, both of which affect the rates of chemical, physical, and biological processes. Temperature and moisture both influence the organic matter content of soil through their effects on the balance between primary production and decomposition: the colder or drier the climate the lesser atmospheric carbon is fixed as organic matter while the lesser organic matter is decomposed.\n\nClimate is the dominant factor in soil formation, and soils show the distinctive characteristics of the climate zones in which they form, with a feedback to climate through transfer of carbon stocked in soil horizons back to the atmosphere. If warm temperatures and abundant water are present in the profile at the same time, the processes of weathering, leaching, and plant growth will be maximized. According to the climatic determination of biomes, humid climates favor the growth of trees. In contrast, grasses are the dominant native vegetation in subhumid and semiarid regions, while shrubs and brush of various kinds dominate in arid areas.\n\nWater is essential for all the major chemical weathering reactions. To be effective in soil formation, water must penetrate the regolith. The seasonal rainfall distribution, evaporative losses, site topography, and soil permeability interact to determine how effectively precipitation can influence soil formation. The greater the depth of water penetration, the greater the depth of weathering of the soil and its development. Surplus water percolating through the soil profile transports soluble and suspended materials from the upper layers (eluviation) to the lower layers (illuviation), including clay particles and dissolved organic matter. It may also carry away soluble materials in the surface drainage waters. Thus, percolating water stimulates weathering reactions and helps differentiate soil horizons. Likewise, a deficiency of water is a major factor in determining the characteristics of soils of dry regions. Soluble salts are not leached from these soils, and in some cases they build up to levels that curtail plant and microbial growth. Soil profiles in arid and semi-arid regions are also apt to accumulate carbonates and certain types of expansive clays (calcrete or caliche horizons). In tropical soils, when the soil has been deprived of vegetation (e.g. by deforestation) and thereby is submitted to intense evaporation, the upward capillary movement of water, which has dissolved iron and aluminum salts, is responsible for the formation of a superficial hard pan of laterite or bauxite, respectively, which is improper for cutivation, a known case of irreversible soil degradation (lateritization, bauxitization).\n\nThe direct influences of climate include:\n\nClimate directly affects the rate of weathering and leaching. Wind moves sand and smaller particles (dust), especially in arid regions where there is little plant cover, depositing it close or far from the entrainment source. The type and amount of precipitation influence soil formation by affecting the movement of ions and particles through the soil, and aid in the development of different soil profiles. Soil profiles are more distinct in wet and cool climates, where organic materials may accumulate, than in wet and warm climates, where organic materials are rapidly consumed. The effectiveness of water in weathering parent rock material depends on seasonal and daily temperature fluctuations, which favour tensile stresses in rock minerals, and thus their mechanical disaggregation, a process called \"thermal fatigue\". By the same process freeze-thaw cycles are an effective mechanism which breaks up rocks and other consolidated materials.\n\nClimate also indirectly influences soil formation through the effects of vegetation cover and biological activity, which modify the rates of chemical reactions in the soil.\n\nThe topography, or relief, is characterized by the inclination (slope), elevation, and orientation of the terrain. Topography determines the rate of precipitation or runoff and rate of formation or erosion of the surface soil profile. The topographical setting may either hasten or retard the work of climatic forces.\n\nSteep slopes encourage rapid soil loss by erosion and allow less rainfall to enter the soil before running off and hence, little mineral deposition in lower profiles. In semiarid regions, the lower effective rainfall on steeper slopes also results in less complete vegetative cover, so there is less plant contribution to soil formation. For all of these reasons, steep slopes prevent the formation of soil from getting very far ahead of soil destruction. Therefore, soils on steep terrain tend to have rather shallow, poorly developed profiles in comparison to soils on nearby, more level sites.\n\nIn swales and depressions where runoff water tends to concentrate, the regolith is usually more deeply weathered and soil profile development is more advanced. However, in the lowest landscape positions, water may saturate the regolith to such a degree that drainage and aeration are restricted. Here, the weathering of some minerals and the decomposition of organic matter are retarded, while the loss of iron and manganese is accelerated. In such low-lying topography, special profile features characteristic of wetland soils may develop. Depressions allow the accumulation of water, minerals and organic matter and in the extreme, the resulting soils will be saline marshes or peat bogs. Intermediate topography affords the best conditions for the formation of an agriculturally productive soil.\n\nSoil is the most abundant ecosystem on Earth, but the vast majority of organisms in soil are microbes, a great many of which have not been described. There may be a population limit of around one billion cells per gram of soil, but estimates of the number of species vary widely from 50,000 per gram to over a million per gram of soil. The total number of organisms and species can vary widely according to soil type, location, and depth.\n\nPlants, animals, fungi, bacteria and humans affect soil formation (see soil biomantle and stonelayer). Soil animals, including soil macrofauna and soil mesofauna, mix soils as they form burrows and pores, allowing moisture and gases to move about, a process called bioturbation. In the same way, plant roots penetrate soil horizons and open channels upon decomposition. Plants with deep taproots can penetrate many metres through the different soil layers to bring up nutrients from deeper in the profile. Plants have fine roots that excrete organic compounds (sugars, organic acids, mucigel), slough off cells (in particular at their tip) and are easily decomposed, adding organic matter to soil, a process called \"rhizodeposition\". Micro-organisms, including fungi and bacteria, effect chemical exchanges between roots and soil and act as a reserve of nutrients in a soil biological \"hotspot\" called rhizosphere. The growth of roots through the soil stimulates microbial populations, stimulating in turn the activity of their predators (notably amoeba), thereby increasing the mineralization rate, and in last turn root growth, a positive feedback called the soil microbial loop. Out of root influence, in the bulk soil, most bacteria are in a quiescent stage, forming microaggregates, i.e. mucilaginous colonies to which clay particles are glued, offering them a protection against desiccation and predation by soil microfauna (bacteriophagous protozoa and nematodes). Microaggregates (20-250 µm) are ingested by soil mesofauna and macrofauna, and bacterial bodies are partly or totally digested in their guts.\n\nHumans impact soil formation by removing vegetation cover with erosion, waterlogging, lateritization or podzolization (according to climate and topography) as the result. Their tillage also mixes the different soil layers, restarting the soil formation process as less weathered material is mixed with the more developed upper layers, resulting in net increased rate of mineral weathering.\n\nEarthworms, ants, termites, moles, gophers, as well as some millipedes and tenebrionid beetles mix the soil as they burrow, significantly affecting soil formation. Earthworms ingest soil particles and organic residues, enhancing the availability of plant nutrients in the material that passes through their bodies. They aerate and stir the soil and create stable soil aggregates, after having disrupted links between soil particles during the intestinal transit of ingested soil, thereby assuring ready infiltration of water. In addition, as ants and termites build mounds, they transport soil materials from one horizon to another. Other important functions are fulfilled by earthworms in the soil ecosystem, in particular their intense mucus production, both within the intestine and as a lining in their galleries, exert a priming effect on soil microflora, giving them the status of ecosystem engineers, which they share with ants and termites.\n\nIn general, the mixing of the soil by the activities of animals, sometimes called pedoturbation, tends to undo or counteract the tendency of other soil-forming processes that create distinct horizons. Termites and ants may also retard soil profile development by denuding large areas of soil around their nests, leading to increased loss of soil by erosion. Large animals such as gophers, moles, and prairie dogs bore into the lower soil horizons, bringing materials to the surface. Their tunnels are often open to the surface, encouraging the movement of water and air into the subsurface layers. In localized areas, they enhance mixing of the lower and upper horizons by creating, and later refilling, underground tunnels. Old animal burrows in the lower horizons often become filled with soil material from the overlying A horizon, creating profile features known as crotovinas.\n\nVegetation impacts soils in numerous ways. It can prevent erosion caused by excessive rain that might result from surface runoff. Plants shade soils, keeping them cooler and slow evaporation of soil moisture, or conversely, by way of transpiration, plants can cause soils to lose moisture, resulting in complex and highly variable relationships between leaf area index (measuring light interception) and moisture loss: more generally plants prevent soil from desiccation during driest months while they dry it during moister months, thereby acting as a buffer against strong moisture variation. Plants can form new chemicals that can break down minerals, both directly and indirectly through mycorrhizal fungi and rhizosphere bacteria, and improve the soil structure. The type and amount of vegetation depends on climate, topography, soil characteristics and biological factors, mediated or not by human activities. Soil factors such as density, depth, chemistry, pH, temperature and moisture greatly affect the type of plants that can grow in a given location. Dead plants and fallen leaves and stems begin their decomposition on the surface. There, organisms feed on them and mix the organic material with the upper soil layers; these added organic compounds become part of the soil formation process.\n\nHuman activities widely influence soil formation. For example, it is believed that Native Americans regularly set fires to maintain several large areas of prairie grasslands in Indiana and Michigan, although climate and mammalian grazers (e.g. bisons) are also advocated to explain the maintenance of the Great Plains of North America. In more recent times, human destruction of natural vegetation and subsequent tillage of the soil for crop production has abruptly modified soil formation. Likewise, irrigating soil in an arid region drastically influences soil-forming factors, as does adding fertilizer and lime to soils of low fertility.\n\nTime is a factor in the interactions of all the above. While a mixture of sand, silt and clay constitute the texture of a soil and the aggregation of those components produces peds, the development of a distinct B horizon marks the development of a soil or pedogenesis. With time, soils will evolve features that depend on the interplay of the prior listed soil-forming factors. It takes decades to several thousand years for a soil to develop a profile, although the notion of soil development has been criticized, soil being in a constant state-of-change under the influence of fluctuating soil-forming factors. That time period depends strongly on climate, parent material, relief, and biotic activity. For example, recently deposited material from a flood exhibits no soil development as there has not been enough time for the material to form a structure that further defines soil. The original soil surface is buried, and the formation process must begin anew for this deposit. Over time the soil will develop a profile that depends on the intensities of biota and climate. While a soil can achieve relative stability of its properties for extended periods, the soil life cycle ultimately ends in soil conditions that leave it vulnerable to erosion. Despite the inevitability of soil retrogression and degradation, most soil cycles are long.\n\nSoil-forming factors continue to affect soils during their existence, even on \"stable\" landscapes that are long-enduring, some for millions of years. Materials are deposited on top or are blown or washed from the surface. With additions, removals and alterations, soils are always subject to new conditions. Whether these are slow or rapid changes depends on climate, topography and biological activity.\n\nThe physical properties of soils, in order of decreasing importance for ecosystem services such as crop production, are texture, structure, bulk density, porosity, consistency, temperature, colour and resistivity. Soil texture is determined by the relative proportion of the three kinds of soil mineral particles, called soil separates: sand, silt, and clay. At the next larger scale, soil structures called peds or more commonly \"soil aggregates\" are created from the soil separates when iron oxides, carbonates, clay, silica and humus, coat particles and cause them to adhere into larger, relatively stable secondary structures. Soil bulk density, when determined at standardized moisture conditions, is an estimate of soil compaction. Soil porosity consists of the void part of the soil volume and is occupied by gases or water. Soil consistency is the ability of soil materials to stick together. Soil temperature and colour are self-defining. Resistivity refers to the resistance to conduction of electric currents and affects the rate of corrosion of metal and concrete structures which are buried in soil. These properties vary through the depth of a soil profile, i.e. through soil horizons. Most of these properties determine the aeration of the soil and the ability of water to infiltrate and to be held within the soil.\n\nThe mineral components of soil are sand, silt and clay, and their relative proportions determine a soil's texture. Properties that are influenced by soil texture include porosity, permeability, infiltration, shrink-swell rate, water-holding capacity, and susceptibility to erosion. In the illustrated USDA textural classification triangle, the only soil in which neither sand, silt nor clay predominates is called loam. While even pure sand, silt or clay may be considered a soil, from the perspective of conventional agriculture a loam soil with a small amount of organic material is considered \"ideal\", inasmuch as fertilizers or manure are currently used to mitigate nutrient losses due to crop yields in the long term. The mineral constituents of a loam soil might be 40% sand, 40% silt and the balance 20% clay by weight. Soil texture affects soil behaviour, in particular, its retention capacity for nutrients (e.g., cation exchange capacity) and water.\n\nSand and silt are the products of physical and chemical weathering of the parent rock; clay, on the other hand, is most often the product of the precipitation of the dissolved parent rock as a secondary mineral, except when derived from the weathering of mica. It is the surface area to volume ratio (specific surface area) of soil particles and the unbalanced ionic electric charges within those that determine their role in the fertility of soil, as measured by its cation exchange capacity. Sand is least active, having the least specific surface area, followed by silt; clay is the most active. Sand's greatest benefit to soil is that it resists compaction and increases soil porosity, although this property stands only for pure sand, not for sand mixed with smaller minerals which fill the voids among sand grains. Silt is mineralogically like sand but with its higher specific surface area it is more chemically and physically active than sand. But it is the clay content of soil, with its very high specific surface area and generally large number of negative charges, that gives a soil its high retention capacity for water and nutrients. Clay soils also resist wind and water erosion better than silty and sandy soils, as the particles bond tightly to each other,\nand that with a strong mitigation effect of organic matter.\n\nSand is the most stable of the mineral components of soil; it consists of rock fragments, primarily quartz particles, ranging in size from in diameter. Silt ranges in size from . Clay cannot be resolved by optical microscopes as its particles are or less in diameter and a thickness of only 10 angstroms (10 m). In medium-textured soils, clay is often washed downward through the soil profile (a process called eluviation) and accumulates in the subsoil (a process called illuviation). There is no clear relationship between the size of soil mineral components and their mineralogical nature: sand and silt particles can be calcareous as well as siliceous, while textural clay () can be made of very fine quartz particles as well as of multi-layered secondary minerals. Soil mineral components belonging to a given textural class may thus share properties linked to their specific surface area (e.g. moisture retention) but not those linked to their chemical composition (e.g. cation exchange capacity).\n\nSoil components larger than are classed as rock and gravel and are removed before determining the percentages of the remaining components and the textural class of the soil, but are included in the name. For example, a sandy loam soil with 20% gravel would be called gravelly sandy loam.\n\nWhen the organic component of a soil is substantial, the soil is called organic soil rather than mineral soil. A soil is called organic if:\n\n\nThe clumping of the soil textural components of sand, silt and clay causes aggregates to form and the further association of those aggregates into larger units creates soil structures called peds (a contraction of the word pedolith). The adhesion of the soil textural components by organic substances, iron oxides, carbonates, clays, and silica, the breakage of those aggregates from expansion-contraction caused by freezing-thawing and wetting-drying cycles, and the build-up of aggregates by soil animals, microbial colonies and root tips shape soil into distinct geometric forms. The peds evolve into units which have various shapes, sizes and degrees of development. A soil clod, however, is not a ped but rather a mass of soil that results from mechanical disturbance of the soil such as cultivation. Soil structure affects aeration, water movement, conduction of heat, plant root growth and resistance to erosion. Water, in turn, has a strong effect on soil structure, directly via the dissolution and precipitation of minerals, the mechanical destruction of aggregates (slaking) and indirectly by promoting plant, animal and microbial growth.\n\nSoil structure often gives clues to its texture, organic matter content, biological activity, past soil evolution, human use, and the chemical and mineralogical conditions under which the soil formed. While texture is defined by the mineral component of a soil and is an innate property of the soil that does not change with agricultural activities, soil structure can be improved or destroyed by the choice and timing of farming practices.\n\nSoil structural classes:\n\n\nAt the largest scale, the forces that shape a soil's structure result from swelling and shrinkage that initially tend to act horizontally, causing vertically oriented prismatic peds. This mechanical process is mainly exemplified in the development of vertisols. Clayey soil, due to its differential drying rate with respect to the surface, will induce horizontal cracks, reducing columns to blocky peds. Roots, rodents, worms, and freezing-thawing cycles further break the peds into smaller peds of a more or less spherical shape.\n\nAt a smaller scale, plant roots extend into voids (macropores) and remove water causing macroporosity to increase and microporosity to decrease, thereby decreasing aggregate size. At the same time, root hairs and fungal hyphae create microscopic tunnels that break up peds.\n\nAt an even smaller scale, soil aggregation continues as bacteria and fungi exude sticky polysaccharides which bind soil into smaller peds. The addition of the raw organic matter that bacteria and fungi feed upon encourages the formation of this desirable soil structure.\n\nAt the lowest scale, the soil chemistry affects the aggregation or dispersal of soil particles. The clay particles contain polyvalent cations which give the faces of clay layers localized negative charges. At the same time, the edges of the clay plates have a slight positive charge, thereby allowing the edges to adhere to the negative charges on the faces of other clay particles or to flocculate (form clumps). On the other hand, when monovalent ions, such as sodium, invade and displace the polyvalent cations, they weaken the positive charges on the edges, while the negative surface charges are relatively strengthened. This leaves negative charge on the clay faces that repel other clay, causing the particles to push apart, and by doing so deflocculate clay suspensions. As a result, the clay disperses and settles into voids between peds, causing those to close. In this way the open structure of the soil is destroyed and the soil is made impenetrable to air and water. Such sodic soil (also called haline soil) tends to form columnar peds near the surface.\n\nSoil particle density is typically 2.60 to 2.75 grams per cm and is usually unchanging for a given soil. Soil particle density is lower for soils with high organic matter content, and is higher for soils with high iron-oxides content. Soil bulk density is equal to the dry mass of the soil divided by the volume of the soil; i.e., it includes air space and organic materials of the soil volume. Thereby soil bulk density is always less than soil particle density and is a good indicator of soil compaction. The soil bulk density of cultivated loam is about 1.1 to 1.4 g/cm (for comparison water is 1.0 g/cm). Contrary to particle density, soil bulk density is highly variable for a given soil, with a strong causal relationship with soil biological activity and management strategies. However, it has been shown that, depending on species and the size of their aggregates (faeces), earthworms may either increase or decrease soil bulk density. A lower bulk density by itself does not indicate suitability for plant growth due to the confounding influence of soil texture and structure. A high bulk density is indicative of either soil compaction or a mixture of soil textural classes in which small particles fill the voids among coarser particles. Hence the positive correlation between the fractal dimension of soil, considered as a porous medium, and its bulk density, that explains the poor hydraulic conductivity of silty clay loam in the absence of a faunal structure.\n\nPore space is that part of the bulk volume of soil that is not occupied by either mineral or organic matter but is open space occupied by either gases or water. In a productive, medium-textured soil the total pore space is typically about 50% of the soil volume. Pore size varies considerably; the smallest pores (cryptopores; <0.1 µm) hold water too tightly for use by plant roots; plant-available water is held in ultramicropores, micropores and mesopores (0.1–75 µm); and macropores (>75 µm) are generally air-filled when the soil is at field capacity.\n\nSoil texture determines total volume of the smallest pores; clay soils have smaller pores, but more total pore space than sands, despite of a much lower permeability. Soil structure has a strong influence on the larger pores that affect soil aeration, water infiltration and drainage. Tillage has the short-term benefit of temporarily increasing the number of pores of largest size, but these can be rapidly degraded by the destruction of soil aggregation.\n\nThe pore size distribution affects the ability of plants and other organisms to access water and oxygen; large, continuous pores allow rapid transmission of air, water and dissolved nutrients through soil, and small pores store water between rainfall or irrigation events. Pore size variation also compartmentalizes the soil pore space such that many microbial and faunal organisms are not in direct competition with one another, which may explain not only the large number of species present, but the fact that functionally redundant organisms (organisms with the same ecological niche) can co-exist within the same soil.\n\nConsistency is the ability of soil to stick to itself or to other objects (cohesion and adhesion, respectively) and its ability to resist deformation and rupture. It is of approximate use in predicting cultivation problems and the engineering of foundations. Consistency is measured at three moisture conditions: air-dry, moist, and wet. In those conditions the consistency quality depends upon the clay content. In the wet state, the two qualities of stickiness and plasticity are assessed. A soil's resistance to fragmentation and crumbling is assessed in the dry state by rubbing the sample. Its resistance to shearing forces is assessed in the moist state by thumb and finger pressure. Additionally, the cemented consistency depends on cementation by substances other than clay, such as calcium carbonate, silica, oxides and salts; moisture content has little effect on its assessment. The measures of consistency border on subjective compared to other measures such as pH, since they employ the apparent feel of the soil in those states.\n\nThe terms used to describe the soil consistency in three moisture states and a last not affected by the amount of moisture are as follows:\n\n\nSoil consistency is useful in estimating the ability of soil to support buildings and roads. More precise measures of soil strength are often made prior to construction.\n\nSoil temperature depends on the ratio of the energy absorbed to that lost. Soil has a temperature range between -20 to 60 °C, with a mean annual temperature from -10 to 26 °C according to biomes. Soil temperature regulates seed germination, breaking of seed dormancy, plant and root growth and the availability of nutrients. Soil temperature has important seasonal, monthly and daily variations, fluctuations in soil temperature being much lower with increasing soil depth. Heavy mulching (a type of soil cover) can slow the warming of soil in summer, and, at the same time, reduce fluctuations in surface temperature.\n\nMost often, agricultural activities must adapt to soil temperatures by:\n\n\nSoil temperatures can be raised by drying soils or the use of clear plastic mulches. Organic mulches slow the warming of the soil.\n\nThere are various factors that affect soil temperature, such as water content, soil color, and relief (slope, orientation, and elevation), and soil cover (shading and insulation), in addition to air temperature. The color of the ground cover and its insulating properties have a strong influence on soil temperature. Whiter soil tends to have a higher albedo than blacker soil cover, which encourages whiter soils to have lower soil temperatures. The specific heat of soil is the energy required to raise the temperature of soil by 1 °C. The specific heat of soil increases as water content increases, since the heat capacity of water is greater than that of dry soil. The specific heat of pure water is ~ 1 calorie per gram, the specific heat of dry soil is ~ 0.2 calories per gram, hence, the specific heat of wet soil is ~ 0.2 to 1 calories per gram (0.8 to 4.2 kJ per kilogram). Also, a tremendous energy (~540 cal/g or 2260 kJ/kg) is required to evaporate water (known as the heat of vaporization). As such, wet soil usually warms more slowly than dry soil – wet surface soil is typically 3 to 6 °C colder than dry surface soil.\n\nSoil heat flux refers to the rate at which heat energy moves through the soil in response to a temperature difference between two points in the soil. The heat flux density is the amount of energy that flows through soil per unit area per unit time and has both magnitude and direction. For the simple case of conduction into or out of the soil in the vertical direction, which is most often applicable the heat flux density is:\n\nIn SI units\n\nHeat flux is in the direction opposite the temperature gradient, hence the minus sign. That is to say, if the temperature of the surface is higher than at depth x the negative sign will result in a positive value for the heat flux q, and which is interpreted as the heat being conducted into the soil.\n\nSoil temperature is important for the survival and early growth of seedlings. Soil temperatures affect the anatomical and morphological character of root systems. All physical, chemical, and biological processes in soil and roots are affected in particular because of the increased viscosities of water and protoplasm at low temperatures. In general, climates that do not preclude survival and growth of white spruce above ground are sufficiently benign to provide soil temperatures able to maintain white spruce root systems. In some northwestern parts of the range, white spruce occurs on permafrost sites and although young unlignified roots of conifers may have little resistance to freezing, the root system of containerized white spruce was not affected by exposure to a temperature of less than 30 °C.\n\nOptimum temperatures for tree root growth range between 10 °C and 25 °C in general and for spruce in particular. In 2-week-old white spruce seedlings that were then grown for 6 weeks in soil at temperatures of 15 °C, 19 °C, 23 °C, 27 °C, and 31 °C; shoot height, shoot dry weight, stem diameter, root penetration, root volume, and root dry weight all reached maxima at 19 °C.\n\nHowever, whereas strong positive relationships between soil temperature (5 °C to 25 °C) and growth have been found in trembling aspen and balsam poplar, white and other spruce species have shown little or no changes in growth with increasing soil temperature. Such insensitivity to soil low temperature may be common among a number of western and boreal conifers.\n\nSoil temperatures are increasing worldwide under the influence of present-day global climate warming, with opposing views about expected effects on carbon capture and storage and feedback loops to climate change Most threats are about permafrost thawing and attended effects on carbon destocking and ecosystem collapse.\n\nSoil colour is often the first impression one has when viewing soil. Striking colours and contrasting patterns are especially noticeable. The Red River of the South carries sediment eroded from extensive reddish soils like Port Silt Loam in Oklahoma. The Yellow River in China carries yellow sediment from eroding loess soils. Mollisols in the Great Plains of North America are darkened and enriched by organic matter. Podsols in boreal forests have highly contrasting layers due to acidity and leaching.\n\nIn general, color is determined by the organic matter content, drainage conditions, and degree of oxidation. Soil color, while easily discerned, has little use in predicting soil characteristics. It is of use in distinguishing boundaries of horizons within a soil profile, determining the origin of a soil's parent material, as an indication of wetness and waterlogged conditions, and as a qualitative means of measuring organic, iron oxide and clay contents of soils. Color is recorded in the Munsell color system as for instance 10YR3/4 \"Dusky Red\", with 10YR as \"hue\", 3 as \"value\" and 4 as \"chroma\". Munsell color dimensions (hue, value and chroma) can be averaged among samples and treated as quantitative parameters, displaying significant correlations with various soil and vegetation properties.\n\nSoil color is primarily influenced by soil mineralogy. Many soil colours are due to various iron minerals. The development and distribution of colour in a soil profile result from chemical and biological weathering, especially redox reactions. As the primary minerals in soil parent material weather, the elements combine into new and colourful compounds. Iron forms secondary minerals of a yellow or red colour, organic matter decomposes into black and brown humic compounds, and manganese and sulfur can form black mineral deposits. These pigments can produce various colour patterns within a soil. Aerobic conditions produce uniform or gradual colour changes, while reducing environments (anaerobic) result in rapid colour flow with complex, mottled patterns and points of colour concentration.\n\nSoil resistivity is a measure of a soil's ability to retard the conduction of an electric current. The electrical resistivity of soil can affect the rate of galvanic corrosion of metallic structures in contact with the soil. Higher moisture content or increased electrolyte concentration can lower resistivity and increase conductivity, thereby increasing the rate of corrosion. Soil resistivity values typically range from about 1 to 100000 Ω·m, extreme values being for saline soils and dry soils overlaying cristalline rocks, respectively.\n\nWater that enters a field is removed from a field by runoff, drainage, evaporation or transpiration. Runoff is the water that flows on the surface to the edge of the field; drainage is the water that flows through the soil downward or toward the edge of the field underground; evaporative water loss from a field is that part of the water that evaporates into the atmosphere directly from the field's surface; transpiration is the loss of water from the field by its evaporation from the plant itself.\n\nWater affects soil formation, structure, stability and erosion but is of primary concern with respect to plant growth. Water is essential to plants for four reasons:\n\n\nIn addition, water alters the soil profile by dissolving and re-depositing minerals, often at lower levels, and possibly leaving the soil sterile in the case of extreme rainfall and drainage. In a loam soil, solids constitute half the volume, gas one-quarter of the volume, and water one-quarter of the volume of which only half will be available to most plants, with a strong variation according to matric potential.\n\nA flooded field will drain the gravitational water under the influence of gravity until water's adhesive and cohesive forces resist further drainage at which point it is said to have reached field capacity. At that point, plants must apply suction to draw water from a soil. The water that plants may draw from the soil is called the available water. Once the available water is used up the remaining moisture is called unavailable water as the plant cannot produce sufficient suction to draw that water in. A plant must produce suction that increases from zero for a flooded field to 1/3 bar at field dry condition (one bar is a little less than one atmosphere pressure). At 15 bar suction, wilting point, seeds will not germinate, plants begin to wilt and then die. Water moves in soil under the influence of gravity, osmosis and capillarity. When water enters the soil, it displaces air from interconnected macropores by buoyancy, and breaks aggregates into which air is entrapped, a process called slaking.\n\nThe rate at which a soil can absorb water depends on the soil and its other conditions. As a plant grows, its roots remove water from the largest pores (macropores) first. Soon the larger pores hold only air, and the remaining water is found only in the intermediate- and smallest-sized pores (micropores). The water in the smallest pores is so strongly held to particle surfaces that plant roots cannot pull it away. Consequently, not all soil water is available to plants, with a strong dependence on texture. When saturated, the soil may lose nutrients as the water drains. Water moves in a draining field under the influence of pressure where the soil is locally saturated and by capillarity pull to drier parts of the soil. Most plant water needs are supplied from the suction caused by evaporation from plant leaves (transpiration) and a lower fraction is supplied by suction created by osmotic pressure differences between the plant interior and the soil solution. Plant roots must seek out water and grow preferentially in moister soil microsites, but some parts of the root system are also able to remoisten dry parts of the soil. Insufficient water will damage the yield of a crop. Most of the available water is used in transpiration to pull nutrients into the plant.\n\nWater is retained in a soil when the adhesive force of attraction that water's hydrogen atoms have for the oxygen of soil particles is stronger than the cohesive forces that water's hydrogen feels for other water oxygen atoms. When a field is flooded, the soil pore space is completely filled by water. The field will drain under the force of gravity until it reaches what is called field capacity, at which point the smallest pores are filled with water and the largest with water and gases. The total amount of water held when field capacity is reached is a function of the specific surface area of the soil particles. As a result, high clay and high organic soils have higher field capacities. The total force required to pull or push water out of soil is termed suction and usually expressed in units of bars (10 pascal) which is just a little less than one-atmosphere pressure. Alternatively, the terms \"soil moisture tension\" or water potential may be used.\n\nThe forces with which water is held in soils determine its availability to plants. Forces of adhesion hold water strongly to mineral and humus surfaces and less strongly to itself by cohesive forces. A plant's root may penetrate a very small volume of water that is adhering to soil and be initially able to draw in water that is only lightly held by the cohesive forces. But as the droplet is drawn down, the forces of adhesion of the water for the soil particles produce increasingly higher suction, finally up to 15 bar. At 15 bar suction, the soil water amount is called wilting point. At that suction the plant cannot sustain its water needs as water is still being lost from the plant by transpiration, the plant's turgidity is lost, and it wilts, although stomatal closure may decrease transpiration and thus may retard wilting below the wilting point, in particular under adaptation or acclimatization to drought. The next level, called air-dry, occurs at 1000 bar suction. Finally the oven dry condition is reached at 10,000 bar suction. All water below wilting percentage is called unavailable water.\n\nWhen the soil moisture content is optimal for plant growth, the water in the large and intermediate size pores can move about in the soil and be easily used by plants. The amount of water remaining in a soil drained to field capacity and the amount that is available are functions of the soil type. Sandy soil will retain very little water, while clay will hold the maximum amount. The time required to drain a field from flooded condition for a clay loam that begins at 43% water by weight to a field capacity of 22% is six days, whereas a sand loam that is flooded to its maximum of 22% water will take two days to reach field capacity of 11% water. The available water for the clay loam might be 11% whereas for the sand loam it might be only 8% by weight.\n\nThe above are average values for the soil textures as the percentages of sand, silt and clay vary.\n\nWater moves through soil due to the force of gravity, osmosis and capillarity. At zero to one-third bar suction, water is pushed through soil from the point of its application under the force of gravity and the pressure gradient created by the pressure of the water; this is called saturated flow. At higher suction, water movement is pulled by capillarity from wetter toward drier soil. This is caused by water's adhesion to soil solids, and is called unsaturated flow.\n\nWater infiltration and movement in soil is controlled by six factors:\n\n\nWater infiltration rates range from per hour for high clay soils to per hour for sand and well stabilised and aggregated soil structures. Water flows through the ground unevenly, in the form of so-called \"gravity fingers\", because of the surface tension between water particles.\n\nTree roots, whether living or dead, create preferential channels for rainwater flow through soil, magnifying infiltration rates of water up to 27 times.\n\nFlooding temporarily increases soil permeability in river beds, helping to recharge aquifers.\n\nWater applied to a soil is pushed by pressure gradients from the point of its application where it is saturated locally, to less saturated areas, such as the vadose zone. Once soil is completely wetted, any more water will move downward, or percolate out of the range of plant roots, carrying with it clay, humus, nutrients, primarily cations, and various contaminants, including pesticides, pollutants, viruses and bacteria, potentially causing groundwater contamination. In order of decreasing solubility, the leached nutrients are:\n\nIn the United States percolation water due to rainfall ranges from zero inches just east of the Rocky Mountains to twenty or more inches in the Appalachian Mountains and the north coast of the Gulf of Mexico.\n\nSoil physics (Darcy-type model) predicts that at suctions less than one-third bar, water moves theoretically in all directions via unsaturated flow at a rate that is dependent on the square of the diameter of the water-filled pores, but there is still not an adequate physical theory linking all types of waterflow in soil. Preferential flow occurs along interconnected macropores, crevices, root and worm channels, which drain water under gravity. Water is also pulled by capillary action due to the adhesion force of water to the soil solids, producing a suction gradient from wet towards drier soil and from macropores to micropores. Water flow (also called hydraulic conductivity) is primarily from coarse-textured soil into fine-textured soil horizons and is slowest in fine-textured soils such as clay.\n\nOf equal importance to the storage and movement of water in soil is the means by which plants acquire it and their nutrients. Most soil water is taken up by plants as passive absorption caused by the pulling force of water evaporating (transpiring) from the long column of water (xylem sap flow) that leads from the plant's roots to its leaves, according to the cohesion-tension theory. The upward movement of water and solutes (hydraulic lift) is regulated in the roots by the endodermis and in the plant foliage by stomatal conductance, and can be interrupted in root and shoot xylem vessels by cavitation, also called \"xylem embolism\". In addition, the high concentration of salts within plant roots creates an osmotic pressure gradient that pushes soil water into the roots. Osmotic absorption becomes more important during times of low water transpiration caused by lower temperatures (for example at night) or high humidity, and the reverse occurs under high temperature or low humidity. It is these process that cause guttation and wilting, respectively.\n\nRoot extension is vital for plant survival. A study of a single winter rye plant grown for four months in one cubic foot of loam soil showed that the plant developed 13,800,000 roots, a total of 385 miles in length with 2,550 square feet in surface area; and 14 billion hair roots of 6,600 miles total length and 4,320 square feet total area; for a total surface area of 6,870 square feet (83 ft squared). The total surface area of the loam soil was estimated to be 560,000 square feet. In other words, the roots were in contact with only 1.2% of the soil. However, root extension should be viewed as a dynamic process, allowing new roots to explore a new volume of soil each day, increasing dramatically the total volume of soil explored over a given growth period, and thus the volume of water taken up by the root system over this period. Root architecture, i.e. the spatial configuration of the root system, plays a prominent role in the adaptation of plants to soil water and nutrient availabiity, and thus in plant productivity.\n\nRoots must seek out water as the unsaturated flow of water in soil can move only at a rate of up to 2.5 cm (one inch) per day; as a result they are constantly dying and growing as they seek out high concentrations of soil moisture. Insufficient soil moisture, to the point of causing wilting, will cause permanent damage and crop yields will suffer. When grain sorghum was exposed to soil suction as low as 13.0 bar during the seed head emergence through bloom and seed set stages of growth, its production was reduced by 34%.\n\nOnly a small fraction (0.1% to 1%) of the water used by a plant is held within the plant. The majority is ultimately lost via transpiration, while evaporation from the soil surface is also substantial, the transpiration:evaporation ratio varying according to vegetation type and climate, peaking in tropical rainforests and dipping in steppes and deserts. Transpiration plus evaporative soil moisture loss is called evapotranspiration. Evapotranspiration plus water held in the plant totals to consumptive use, which is nearly identical to evapotranspiration.\n\nThe total water used in an agricultural field includes surface runoff, drainage and consumptive use. The use of loose mulches will reduce evaporative losses for a period after a field is irrigated, but in the end the total evaporative loss (plant plus soil) will approach that of an uncovered soil, while more water is immediately available for plant growth. Water use efficiency is measured by the transpiration ratio, which is the ratio of the total water transpired by a plant to the dry weight of the harvested plant. Transpiration ratios for crops range from 300 to 700. For example, alfalfa may have a transpiration ratio of 500 and as a result 500 kilograms of water will produce one kilogram of dry alfalfa.\n\nThe atmosphere of soil, or soil gas, is radically different from the atmosphere above. The consumption of oxygen by microbes and plant roots, and their release of carbon dioxide, decrease oxygen and increase carbon dioxide concentration. Atmospheric CO concentration is 0.04%, but in the soil pore space it may range from 10 to 100 times that level, thus potentially contributing to the inhibition of root respiration. Calcareous soils regulate CO concentration thanks to carbonate buffering, contrary to acid soils in which all CO respired accumulates in the soil pore system. At extreme levels CO is toxic. This suggests a possible negative feedback control of soil CO concentration through its inhibitory effects on root and microbial respiration (also called 'soil respiration'). In addition, the soil voids are saturated with water vapour, at least until the point of maximal hygroscopicity, beyond which a vapour-pressure deficit occurs in the soil pore space. Adequate porosity is necessary, not just to allow the penetration of water, but also to allow gases to diffuse in and out. Movement of gases is by diffusion from high concentrations to lower, the diffusion coefficient decreasing with soil compaction. Oxygen from above atmosphere diffuses in the soil where it is consumed and levels of carbon dioxide in excess of above atmosphere diffuse out with other gases (including greenhouse gases) as well as water. Soil texture and structure strongly affect soil porosity and gas diffusion. It is the total pore space (porosity) of soil, not the pore size, and the degree of pore interconnection (or conversely pore sealing), together with water content, air turbulence and temperature, that determine the rate of diffusion of gases into and out of soil. Platy soil structure and soil compaction (low porosity) impede gas flow, and a deficiency of oxygen may encourage anaerobic bacteria to reduce (strip oxygen) from nitrate NO to the gases N, NO, and NO, which are then lost to the atmosphere, thereby depleting the soil of nitrogen. Aerated soil is also a net sink of methane CH but a net producer of methane (a strong heat-absorbing greenhouse gas) when soils are depleted of oxygen and subject to elevated temperatures.\n\nSoil atmosphere is also the seat of emissions of volatiles other than carbon and nitrogen oxides from various soil organisms, e.g. roots, bacteria, fungi, animals. These volatiles are used as chemical cues, making soil atmosphere the seat of interaction networks playing a decisive role in the stability, dynamics and evolution of soil ecosystems. Biogenic soil volatile organic compounds are exchanged with the aboveground atmosphere, in which they are just 1–2 orders of magnitude lower than those from aboveground vegetation.\n\nWe humans can get some idea of the soil atmosphere through the well-known 'after-the-rain' scent, when infiltering rainwater flushes out the whole soil atmosphere after a drought period, or when soil is excavated, a bulk property attributed in a reductionist manner to particular biochemical compounds such as petrichor or geosmin.\n\nSoil particles can be classified by their chemical composition (mineralogy) as well as their size. The particle size distribution of a soil, its texture, determines many of the properties of that soil, in particular hydraulic conductivity and water potential but the mineralogy of those particles can strongly modify those properties. The mineralogy of the finest soil particles, clay, is especially important.\n\nGravel, sand and silt are the larger soil particles, and their mineralogy is often inherited from the parent material of the soil, but may include products of weathering (such as concretions of calcium carbonate or iron oxide), or residues of plant and animal life (such as silica phytoliths). Quartz is the most common mineral in the sand or silt fraction as it is resistant to chemical weathering, except under hot climate; other common minerals are feldspars, micas and ferromagnesian minerals such as pyroxenes, amphiboles and olivines, which are dissolved or transformed in clay under the combined influence of physico-chemical and biological processes.\n\nDue to its high specific surface area and its unbalanced negative electric charges, clay is the most active mineral component of soil. It is a colloidal and most often a crystalline material. In soils, clay is a soil textural class and is defined in a physical sense as any mineral particle less than in effective diameter. Many soil minerals, such as gypsum, carbonates, or quartz, are small enough to be classified as clay based on their physical size, but chemically they do not afford the same utility as do mineralogically-defined clay minerals. Chemically, clay minerals are a range of phyllosilicate minerals with certain reactive properties.\n\nBefore the advent of X-ray diffraction clay was thought to be very small particles of quartz, feldspar, mica, hornblende or augite, but it is now known to be (with the exception of mica-based clays) a precipitate with a mineralogical composition that is dependent on but different from its parent materials and is classed as a secondary mineral. The type of clay that is formed is a function of the parent material and the composition of the minerals in solution. Clay minerals continue to be formed as long as the soil exists. Mica-based clays result from a modification of the primary mica mineral in such a way that it behaves and is classed as a clay. Most clays are crystalline, but some clays or some parts of clay minerals are amorphous. The clays of a soil are a mixture of the various types of clay, but one type predominates.\n\nTypically there are four main groups of clay minerals: kaolinite, montmorillonite-smectite, illite, and chlorite. Most clays are crystalline and most are made up of three or four planes of oxygen held together by planes of aluminium and silicon by way of ionic bonds that together form a single layer of clay. The spatial arrangement of the oxygen atoms determines clay's structure. Half of the weight of clay is oxygen, but on a volume basis oxygen is ninety percent. The layers of clay are sometimes held together through hydrogen bonds, sodium or potassium bridges and as a result will swell less in the presence of water. Clays such as montmorillonite have layers that are loosely attached and will swell greatly when water intervenes between the layers.\n\nIn a wider sense clays can be classified as:\n\n\nAlumino-silica clays or aluminosilicate clays are characterised by their regular crystalline or quasi-crystalline structure. Oxygen in ionic bonds with silicon forms a tetrahedral coordination (silicon at the center) which in turn forms sheets of silica. Two sheets of silica are bonded together by a plane of aluminium which forms an octahedral coordination, called alumina, with the oxygens of the silica sheet above and that below it. Hydroxyl ions (OH) sometimes substitute for oxygen. During the clay formation process, Al may substitute for Si in the silica layer, and as much as one fourth of the aluminium Al may be substituted by Zn, Mg or Fe in the alumina layer. The substitution of lower-valence cations for higher-valence cations (isomorphous substitution) gives clay a local negative charge on an oxygen atom that attracts and holds water and positively charged soil cations, some of which are of value for plant growth. Isomorphous substitution occurs during the clay's formation and does not change with time.\n\nThe carbonate and sulfate minerals are much more soluble and hence are found primarily in desert soils where leaching is less active.\n\nAmorphous clays are young, and commonly found in volcanic ash. They are mixtures of alumina and silica which have not formed the ordered crystal shape of alumino-silica clays which time would provide. The majority of their negative charges originates from hydroxyl ions, which can gain or lose a hydrogen ion (H) in response to soil pH, in such way was as to buffer the soil pH. They may have either a negative charge provided by the attached hydroxyl ion (OH), which can attract a cation, or lose the hydrogen of the hydroxyl to solution and display a positive charge which can attract anions. As a result, they may display either high CEC in an acid soil solution, or high anion exchange capacity in a basic soil solution.\n\nSesquioxide clays are a product of heavy rainfall that has leached most of the silica from alumino-silica clay, leaving the less soluble oxides iron hematite (FeO), iron hydroxide (Fe(OH)), aluminium hydroxide gibbsite (Al(OH)), hydrated manganese birnessite (MnO). It takes hundreds of thousands of years of leaching to create sesquioxide clays. \"Sesqui\" is Latin for \"one and one-half\": there are three parts oxygen to two parts iron or aluminium; hence the ratio is one and one-half (not true for all). They are hydrated and act as either amorphous or crystalline. They are not sticky and do not swell, and soils high in them behave much like sand and can rapidly pass water. They are able to hold large quantities of phosphates. Sesquioxides have low CEC but are able to hold anions as well as cations. Such soils range from yellow to red in colour. Such clays tend to hold phosphorus so tightly that it is unavailable for absorption by plants.\n\nHumus is the final state of decomposition of organic matter. While it may linger for a thousand years, on the larger scale of the age of the mineral soil components, it is temporary. It is composed of the very stable lignins (30%) and complex sugars (polyuronides, 30%), proteins (30%), waxes, and fats that are resistant to breakdown by microbes. Its chemical assay is 60% carbon, 5% nitrogen, some oxygen and the remainder hydrogen, sulfur, and phosphorus. On a dry weight basis, the CEC of humus is many times greater than that of clay.\n\nIn the extreme environment of high temperatures and the leaching caused by the heavy rain of tropical rain forests, the clay and organic colloids are largely destroyed. The heavy rains wash the alumino-silicate clays from the soil leaving only sesquioxide clays of low CEC. The high temperatures and humidity allow bacteria and fungi to virtually dissolve any organic matter on the rain-forest floor overnight and much of the nutrients are volatilized or leached from the soil and lost. However, carbon in the form of charcoal is far more stable than soil colloids and is capable of performing many of the functions of the soil colloids of sub-tropical soils. Soil containing substantial quantities of charcoal, of an anthropogenic origin, is called terra preta. Research into terra preta is still young but is promising. Fallow periods \"on the Amazonian Dark Earths can be as short as 6 months, whereas fallow periods on oxisols are usually 8 to 10 years long\"\n\nThe chemistry of a soil determines its ability to supply available plant nutrients and affects its physical properties and the health of its microbial population. In addition, a soil's chemistry also determines its corrosivity, stability, and ability to absorb pollutants and to filter water. It is the surface chemistry of mineral and organic colloids that determines soil's chemical properties. \"A colloid is a small, insoluble, nondiffusible particle larger than a molecule but small enough to remain suspended in a fluid medium without settling. Most soils contain organic colloidal particles called humus as well as the inorganic colloidal particles of clays.\" The very high specific surface area of colloids and their net charges, gives soil its ability to hold and release ions. Negatively charged sites on colloids attract and release cations in what is referred to as cation exchange. Cation-exchange capacity (CEC) is the amount of exchangeable cations per unit weight of dry soil and is expressed in terms of milliequivalents of positively charged ions per 100 grams of soil (or centimoles of positive charge per kilogram of soil; cmol/kg). Similarly, positively charged sites on colloids can attract and release anions in the soil giving the soil anion exchange capacity (AEC).\n\nThe cation exchange, that takes place between colloids and soil water, buffers (moderates) soil pH, alters soil structure, and purifies percolating water by adsorbing cations of all types, both useful and harmful.\n\nThe negative or positive charges on colloid particles make them able to hold cations or anions, respectively, to their surfaces. The charges result from four sources.\n\n\nCations held to the negatively charged colloids resist being washed downward by water and out of reach of plants' roots, thereby preserving the fertility of soils in areas of moderate rainfall and low temperatures.\n\nThere is a hierarchy in the process of cation exchange on colloids, as they differ in the strength of adsorption by the colloid and hence their ability to replace one another. If present in equal amounts in the soil water solution:\n\nAl replaces H replaces Ca replaces Mg replaces K same as NH replaces Na\n\nIf one cation is added in large amounts, it may replace the others by the sheer force of its numbers. This is called mass action. This is largely what occurs with the addition of fertiliser.\n\nAs the soil solution becomes more acidic (low pH, and an abundance of H), the other cations more weakly bound to colloids are pushed into solution as hydrogen ions occupy those sites. A low pH may cause hydrogen of hydroxyl groups to be pulled into solution, leaving charged sites on the colloid available to be occupied by other cations. This ionisation of hydroxyl groups on the surface of soil colloids creates what is described as pH-dependent charges. Unlike permanent charges developed by isomorphous substitution, pH-dependent charges are variable and increase with increasing pH. Freed cations can be made available to plants but are also prone to be leached from the soil, possibly making the soil less fertile. Plants are able to excrete H into the soil and by that means, change the pH of the soil near the root and push cations off the colloids, thus making those available to the plant.\n\nCation exchange capacity should be thought of as the soil's ability to remove cations from the soil water solution and sequester those to be exchanged later as the plant roots release hydrogen ions to the solution. CEC is the amount of exchangeable hydrogen cation (H) that will combine with 100 grams dry weight of soil and whose measure is one milliequivalents per 100 grams of soil (1 meq/100 g). Hydrogen ions have a single charge and one-thousandth of a gram of hydrogen ions per 100 grams dry soil gives a measure of one milliequivalent of hydrogen ion. Calcium, with an atomic weight 40 times that of hydrogen and with a valence of two, converts to (40/2) x 1 milliequivalent = 20 milliequivalents of hydrogen ion per 100 grams of dry soil or 20 meq/100 g. The modern measure of CEC is expressed as centimoles of positive charge per kilogram (cmol/kg) of oven-dry soil.\n\nMost of the soil's CEC occurs on clay and humus colloids, and the lack of those in hot, humid, wet climates, due to leaching and decomposition respectively, explains the relative sterility of tropical soils. Live plant roots also have some CEC.\n\nAnion exchange capacity should be thought of as the soil's ability to remove anions from the soil water solution and sequester those for later exchange as the plant roots release carbonate anions to the soil water solution. Those colloids which have low CEC tend to have some AEC. Amorphous and sesquioxide clays have the highest AEC, followed by the iron oxides. Levels of AEC are much lower than for CEC. Phosphates tend to be held at anion exchange sites.\n\nIron and aluminum hydroxide clays are able to exchange their hydroxide anions (OH) for other anions. The order reflecting the strength of anion adhesion is as follows:\n\nThe amount of exchangeable anions is of a magnitude of tenths to a few milliequivalents per 100 g dry soil. As pH rises, there are relatively more hydroxyls, which will displace anions from the colloids and force them into solution and out of storage; hence AEC decreases with increasing pH (alkalinity).\n\nSoil reactivity is expressed in terms of pH and is a measure of the acidity or alkalinity of the soil. More precisely, it is a measure of hydrogen ion concentration in an aqueous solution and ranges in values from 0 to 14 (acidic to basic) but practically speaking for soils, pH ranges from 3.5 to 9.5, as pH values beyond those extremes are toxic to life forms.\n\nAt 25 °C an aqueous solution that has a pH of 3.5 has 10 moles H (hydrogen ions) per litre of solution (and also 10 mole/litre OH). A pH of 7, defined as neutral, has 10 moles hydrogen ions per litre of solution and also 10 moles of OH per litre; since the two concentrations are equal, they are said to neutralise each other. A pH of 9.5 has 10 moles hydrogen ions per litre of solution (and also 10 mole per litre OH). A pH of 3.5 has one million times more hydrogen ions per litre than a solution with pH of 9.5 (9.5 - 3.5 = 6 or 10) and is more acidic.\n\nThe effect of pH on a soil is to remove from the soil or to make available certain ions. Soils with high acidity tend to have toxic amounts of aluminium and manganese. Plants which need calcium need moderate alkalinity, but most minerals are more soluble in acid soils. Soil organisms are hindered by high acidity, and most agricultural crops do best with mineral soils of pH 6.5 and organic soils of pH 5.5.\n\nIn high rainfall areas, soils tend to acidity as the basic cations are forced off the soil colloids by the mass action of hydrogen ions from the rain as those attach to the colloids. High rainfall rates can then wash the nutrients out, leaving the soil sterile. Once the colloids are saturated with H, the addition of any more hydrogen ions or aluminum hydroxyl cations drives the pH even lower (more acidic) as the soil has been left with no buffering capacity. In areas of extreme rainfall and high temperatures, the clay and humus may be washed out, further reducing the buffering capacity of the soil. In low rainfall areas, unleached calcium pushes pH to 8.5 and with the addition of exchangeable sodium, soils may reach pH 10. Beyond a pH of 9, plant growth is reduced. High pH results in low micro-nutrient mobility, but water-soluble chelates of those nutrients can correct the deficit. Sodium can be reduced by the addition of gypsum (calcium sulphate) as calcium adheres to clay more tightly than does sodium causing sodium to be pushed into the soil water solution where it can be washed out by an abundance of water.\n\nThere are acid-forming cations (hydrogen and aluminium) and there are base-forming cations. The fraction of the base-forming cations that occupy positions on the soil colloids is called the base saturation percentage. If a soil has a CEC of 20 meq and 5 meq are aluminium and hydrogen cations (acid-forming), the remainder of positions on the colloids (20-5 = 15 meq) are assumed occupied by base-forming cations, so that the percentage base saturation is 15/20 x 100% = 75% (the compliment 25% is assumed acid-forming cations). When the soil pH is 7 (neutral), base saturation is 100 percent and there are no hydrogen ions stored on the colloids. Base saturation is almost in direct proportion to pH (increases with increasing pH). It is of use in calculating the amount of lime needed to neutralise an acid soil. The amount of lime needed to neutralize a soil must take account of the amount of acid forming ions on the colloids not just those in the soil water solution. The addition of enough lime to neutralize the soil water solution will be insufficient to change the pH, as the acid forming cations stored on the soil colloids will tend to restore the original pH condition as they are pushed off those colloids by the calcium of the added lime.\n\nThe resistance of soil to change in pH, as a result of the addition of acid or basic material, is a measure of the buffering capacity of a soil and (for a particular soil type) increases as the CEC increases. Hence, pure sand has almost no buffering ability, while soils high in colloids have high buffering capacity. Buffering occurs by cation exchange and neutralisation.\n\nThe addition of a small amount highly basic aqueous ammonia to a soil will cause the ammonium to displace hydrogen ions from the colloids, and the end product is water and colloidally fixed ammonium, but little permanent change overall in soil pH.\n\nThe addition of a small amount of lime, Ca(OH), will displace hydrogen ions from the soil colloids, causing the fixation of calcium to colloids and the evolution of CO and water, with little permanent change in soil pH.\n\nThe above are examples of the buffering of soil pH. The general principal is that an increase in a particular cation in the soil water solution will cause that cation to be fixed to colloids (buffered) and a decrease in solution of that cation will cause it to be withdrawn from the colloid and moved into solution (buffered). The degree of buffering is often related to the CEC of the soil; the greater the CEC, the greater the buffering capacity of the soil.\n\nSixteen elements or nutrients are essential for plant growth and reproduction. They are carbon C, hydrogen H, oxygen O, nitrogen N, phosphorus P, potassium K, sulfur S, calcium Ca, magnesium Mg, iron Fe, boron B, manganese Mn, copper Cu, zinc Zn, molybdenum Mo, nickel Ni and chlorine Cl. Nutrients required for plants to complete their life cycle are considered essential nutrients. Nutrients that enhance the growth of plants but are not necessary to complete the plant's life cycle are considered non-essential. With the exception of carbon, hydrogen and oxygen, which are supplied by carbon dioxide and water, and nitrogen, provided through nitrogen fixation, the nutrients derive originally from the mineral component of the soil.\n\nPlant uptake of nutrients can only proceed when they are present in a plant-available form. In most situations, nutrients are absorbed in an ionic form from (or together with) soil water. Although minerals are the origin of most nutrients, and the bulk of most nutrient elements in the soil is held in crystalline form within primary and secondary minerals, they weather too slowly to support rapid plant growth. For example, The application of finely ground minerals, feldspar and apatite, to soil seldom provides the necessary amounts of potassium and phosphorus at a rate sufficient for good plant growth, as most of the nutrients remain bound in the crystals of those minerals.\n\nThe nutrients adsorbed onto the surfaces of clay colloids and soil organic matter provide a more accessible reservoir of many plant nutrients (e.g. K, Ca, Mg, P, Zn). As plants absorb the nutrients from the soil water, the soluble pool is replenished from the surface-bound pool. The decomposition of soil organic matter by microorganisms is another mechanism whereby the soluble pool of nutrients is replenished – this is important for the supply of plant-available N, S, P, and B from soil.\n\nGram for gram, the capacity of humus to hold nutrients and water is far greater than that of clay minerals. All in all, small amounts of humus may remarkably increase the soil's capacity to promote plant growth.\n\nNutrients in the soil are taken up by the plant through its roots. To be taken up by a plant, a nutrient element must be located near the root surface; however, the supply of nutrients in contact with the root is rapidly depleted. There are three basic mechanisms whereby nutrient ions dissolved in the soil solution are brought into contact with plant roots:\n\n\nAll three mechanisms operate simultaneously, but one mechanism or another may be most important for a particular nutrient. For example, in the case of calcium, which is generally plentiful in the soil solution, mass flow alone can usually bring sufficient amounts to the root surface. However, in the case of phosphorus, diffusion is needed to supplement mass flow. For the most part, nutrient ions must travel some distance in the soil solution to reach the root surface. This movement can take place by mass flow, as when dissolved nutrients are carried along with the soil water flowing toward a root that is actively drawing water from the soil. In this type of movement, the nutrient ions are somewhat analogous to leaves floating down a stream. In addition, nutrient ions continually move by diffusion from areas of greater concentration toward the nutrient-depleted areas of lower concentration around the root surface. That process is due to random motion of molecules. By this means, plants can continue to take up nutrients even at night, when water is only slowly absorbed into the roots as transpiration has almost stopped. Finally, root interception comes into play as roots continually grow into new, undepleted soil.\n\nIn the above table, phosphorus and potassium nutrients move more by diffusion than they do by mass flow in the soil water solution, as they are rapidly taken up by the roots creating a concentration of almost zero near the roots (the plants cannot transpire enough water to draw more of those nutrients near the roots). The very steep concentration gradient is of greater influence in the movement of those ions than is the movement of those by mass flow. The movement by mass flow requires the transpiration of water from the plant causing water and solution ions to also move toward the roots. Movement by root interception is slowest as the plants must extend their roots.\n\nPlants move ions out of their roots in an effort to move nutrients in from the soil. Hydrogen H is exchanged for other cations, and carbonate (HCO) and hydroxide (OH) anions are exchanged for nutrient anions. As plant roots remove nutrients from the soil water solution, they are replenished as other ions move off of clay and humus (by ion exchange or desorption), are added from the weathering of soil minerals, and are released by the decomposition of soil organic matter. Plants derive a large proportion of their anion nutrients from decomposing organic matter, which typically holds about 95 percent of the soil nitrogen, 5 to 60 percent of the soil phosphorus and about 80 percent of the soil sulfur. Where crops are produced, the replenishment of nutrients in the soil must usually be augmented by the addition of fertilizer or organic matter.\n\nBecause nutrient uptake is an active metabolic process, conditions that inhibit root metabolism may also inhibit nutrient uptake. Examples of such conditions include waterlogging or soil compaction resulting in poor soil aeration, excessively high or low soil temperatures, and above-ground conditions that result in low translocation of sugars to plant roots.\n\nPlants obtain their carbon from atmospheric carbon dioxide. About 45% of a plant's dry mass is carbon; plant residues typically have a carbon to nitrogen ratio (C/N) of between 13:1 and 100:1. As the soil organic material is digested by arthropods and micro-organisms, the C/N decreases as the carbonaceous material is metabolized and carbon dioxide (CO) is released as a byproduct which then finds its way out of the soil and into the atmosphere. The nitrogen is sequestered in the bodies of the living matter of those decomposing organisms and so it builds up in the soil. Normal CO concentration in the atmosphere is 0.03%, this can be the factor limiting plant growth. In a field of maize on a still day during high light conditions in the growing season, the CO concentration drops very low, but under such conditions the crop could use up to 20 times the normal concentration. The respiration of CO by soil micro-organisms decomposing soil organic matter contributes an important amount of CO to the photosynthesising plants. Within the soil, CO concentration is 10 to 100 times that of atmospheric levels but may rise to toxic levels if the soil porosity is low or if diffusion is impeded by flooding.\n\nNitrogen is the most critical element obtained by plants from the soil and nitrogen deficiency often limits plant growth. Plants can use the nitrogen as either the ammonium cation (NH) or the anion nitrate (NO). Usually, most of the nitrogen in soil is bound within organic compounds that make up the soil organic matter, and must be mineralized to the ammonium or nitrate form before it can be taken up by most plants. The total nitrogen content depends largely on the soil organic matter content, which in turn depends on the climate, vegetation, topography, age and soil management. Soil nitrogen typically decreases by 0.2 to 0.3% for every temperature increase by 10 °C. Usually, grassland soils contain more soil nitrogen than forest soils. Cultivation decreases soil nitrogen by exposing soil organic matter to decomposition by microorganisms, and soils under no-tillage maintain more soil nitrogen than tilled soils.\n\nSome micro-organisms are able to metabolise organic matter and release ammonium in a process called \"mineralisation\". Others take free ammonium and oxidise it to nitrate. Nitrogen-fixing bacteria are capable of metabolising N into the form of ammonia in a process called nitrogen fixation. Both ammonium and nitrate can be \"immobilized\" by their incorporation into the microbes' living cells, where it is temporarily sequestered in the form of amino acids and protein. Nitrate may also be lost from the soil when bacteria metabolise it to the gases N and NO. The loss of gaseous forms of nitrogen to the atmosphere due to microbial action is called \"denitrification\". Nitrogen may also be \"leached\" from the soil if it is in the form of nitrate or lost to the atmosphere as ammonia due to a chemical reaction of ammonium with alkaline soil by way of a process called \"volatilisation\". Ammonium may also be sequestered in clay by \"fixation\". A small amount of nitrogen is added to soil by rainfall.\n\nIn the process of mineralisation, microbes feed on organic matter, releasing ammonia (NH), ammonium (NH) and other nutrients. As long as the carbon to nitrogen ratio (C/N) of fresh residues in the soil is above 30:1, nitrogen will be in short supply and other bacteria will feed on the ammonium and incorporate its nitrogen into their cells in the immobilization process. In that form the nitrogen is said to be \"immobilised\". Later, when such bacteria die, they too are \"mineralised\" and some of the nitrogen is released as ammonium and nitrate. If the C/N is less than 15, ammonia is freed to the soil, where it may be used by bacteria which oxidise it to nitrate (nitrification). Bacteria may on average add nitrogen per acre, and in an unfertilised field, this is the most important source of usable nitrogen. In a soil with 5% organic matter perhaps 2 to 5% of that is released to the soil by such decomposition. It occurs fastest in warm, moist, well aerated soil. The mineralisation of 3% of the organic material of a soil that is 4% organic matter overall, would release of nitrogen as ammonium per acre.\n\nIn nitrogen fixation, rhizobium bacteria convert N to ammonia (NH). Rhizobia share a symbiotic relationship with host plants, since rhizobia supply the host with nitrogen and the host provides rhizobia with nutrients and a safe environment. It is estimated that such symbiotic bacteria in the root nodules of legumes add 45 to 250 pounds of nitrogen per acre per year, which may be sufficient for the crop. Other, free-living nitrogen-fixing bacteria and blue-green algae live independently in the soil and release nitrate when their dead bodies are converted by way of mineralisation.\n\nSome amount of usable nitrogen is fixed by lightning as nitric oxide (NO) and nitrogen dioxide (NO). Nitrogen dioxide is soluble in water to form nitric acid (HNO) solution of H and NO. Ammonia, NH, previously released from the soil or from combustion, may fall with precipitation as nitric acid at a rate of about five pounds nitrogen per acre per year.\n\nWhen bacteria feed on soluble forms of nitrogen (ammonium and nitrate), they temporarily sequester that nitrogen in their bodies in a process called \"immobilisation\". At a later time when those bacteria die, their nitrogen may be released as ammonium by the processes of mineralisation.\n\nProtein material is easily broken down, but the rate of its decomposition is slowed by its attachment to the crystalline structure of clay and when trapped between the clay layers. The layers are small enough that bacteria cannot enter. Some organisms can exude extracellular enzymes that can act on the sequestered proteins. However, those enzymes too may be trapped on the clay crystals.\n\nAmmonium fixation occurs when ammonium pushes potassium ions from between the layers of clay such as illite or montmorillonite. Only a small fraction of soil nitrogen is held this way.\n\nUsable nitrogen may be lost from soils when it is in the form of nitrate, as it is easily leached. Further losses of nitrogen occur by denitrification, the process whereby soil bacteria convert nitrate (NO) to nitrogen gas, N or NO. This occurs when poor soil aeration limits free oxygen, forcing bacteria to use the oxygen in nitrate for their respiratory process. Denitrification increases when oxidisable organic material is available and when soils are warm and slightly acidic. Denitrification may vary throughout a soil as the aeration varies from place to place. Denitrification may cause the loss of 10 to 20 percent of the available nitrates within a day and when conditions are favourable to that process, losses of up to 60 percent of nitrate applied as fertiliser may occur.\n\n\"Ammonium volatilisation\" occurs when ammonium reacts chemically with an alkaline soil, converting NH to NH. The application of ammonium fertiliser to such a field can result in volatilisation losses of as much as 30 percent.\n\nAfter nitrogen, phosphorus is probably the element most likely to be deficient in soils. The soil mineral apatite is the most common mineral source of phosphorus. While there is on average 1000 lb of phosphorus per acre in the soil, it is generally in the form of phosphates with low solubility. Total phosphorus is about 0.1 percent by weight of the soil, but only one percent of that is available. Of the part available, more than half comes from the mineralisation of organic matter. Agricultural fields may need to be fertilised to make up for the phosphorus that has been removed in the crop.\n\nWhen phosphorus does form solubilised ions of HPO, they rapidly form insoluble phosphates of calcium or hydrous oxides of iron and aluminum. Phosphorus is largely immobile in the soil and is not leached but actually builds up in the surface layer if not cropped. The application of soluble fertilisers to soils may result in zinc deficiencies as zinc phosphates form. Conversely, the application of zinc to soils may immobilise phosphorus again as zinc phosphate. Lack of phosphorus may interfere with the normal opening of the plant leaf stomata, resulting in plant temperatures 10 percent higher than normal. Phosphorus is most available when soil pH is 6.5 in mineral soils and 5.5 in organic soils.\n\nThe amount of potassium in a soil may be as much as 80,000 lb per acre-foot, of which only 150 lb is available for plant growth. Common mineral sources of potassium are the mica biotite and potassium feldspar, KAlSiO. When solubilised, half will be held as exchangeable cations on clay while the other half is in the soil water solution. Potassium fixation often occurs when soils dry and the potassium is bonded between layers of illite clay. Under certain conditions, dependent on the soil texture, intensity of drying, and initial amount of exchangeable potassium, the fixed percentage may be as much as 90 percent within ten minutes. Potassium may be leached from soils low in clay.\n\nCalcium is one percent by weight of soils and is generally available but may be low as it is soluble and can be leached. It is thus low in sandy and heavily leached soil or strongly acidic mineral soil. Calcium is supplied to the plant in the form of exchangeable ions and moderately soluble minerals. Calcium is more available on the soil colloids than is potassium because the common mineral calcite, CaCO, is more soluble than potassium-bearing minerals.\n\nMagnesium is one of the dominant exchangeable cations in most soils (as are calcium and potassium). Primary minerals that weather to release magnesium include hornblende, biotite and vermiculite. Soil magnesium concentrations are generally sufficient for optimal plant growth, but highly weathered and sandy soils may be magnesium deficient due to leaching by heavy precipitation.\n\nMost sulfur is made available to plants, like phosphorus, by its release from decomposing organic matter. Deficiencies may exist in some soils (especially sandy soils) and if cropped, sulfur needs to be added. The application of large quantities of nitrogen to fields that have marginal amounts of sulfur may cause sulfur deficiency in the rapidly growing plants by the plant's growth outpacing the supply of sulfur. A 15-ton crop of onions uses up to 19 lb of sulfur and 4 tons of alfalfa uses 15 lb per acre. Sulfur abundance varies with depth. In a sample of soils in Ohio, United States, the sulfur abundance varied with depths, 0-6 inches, 6-12 inches, 12-18 inches, 18-24 inches in the amounts: 1056, 830, 686, 528 lb per acre respectively.\n\nThe micronutrients essential in plant life, in their order of importance, include iron, manganese, zinc, copper, boron, chlorine and molybdenum. The term refers to plants' needs, not to their abundance in soil. They are required in very small amounts but are essential to plant health in that most are required parts of some enzyme system which speeds up plants' metabolisms. They are generally available in the mineral component of the soil, but the heavy application of phosphates can cause a deficiency in zinc and iron by the formation of insoluble zinc and iron phosphates. Iron deficiency may also result from excessive amounts of heavy metals or calcium minerals (lime) in the soil. Excess amounts of soluble boron, molybdenum and chloride are toxic.\n\nNutrients which enhance the health but whose deficiency does not stop the life cycle of plants include: cobalt, strontium, vanadium, silicon and nickel. As their importance are evaluated they may be added to the list of essential plant nutrients.\n\nSoil organic matter is made up of organic compounds and includes plant, animal and microbial material, both living and dead. A typical soil has a biomass composition of 70% microorganisms, 22% macrofauna, and 8% roots. The living component of an acre of soil may include 900 lb of earthworms, 2400 lb of fungi, 1500 lb of bacteria, 133 lb of protozoa and 890 lb of arthropods and algae.\n\nA small part of the organic matter consists of the living cells such as bacteria, molds, and actinomycetes that work to break down the dead organic matter. Were it not for the action of these micro-organisms, the entire carbon dioxide part of the atmosphere would be sequestered as organic matter in the soil.\n\nChemically, organic matter is classed as follows:\n\n\nMost living things in soils, including plants, insects, bacteria, and fungi, are dependent on organic matter for nutrients and/or energy. Soils have organic compounds in varying degrees of decomposition which rate is dependent on the temperature, soil moisture, and aeration. Bacteria and fungi feed on the raw organic matter, which are fed upon by amoebas, which in turn are fed upon by nematodes and arthropods. Organic matter holds soils open, allowing the infiltration of air and water, and may hold as much as twice its weight in water. Many soils, including desert and rocky-gravel soils, have little or no organic matter. Soils that are all organic matter, such as peat (histosols), are infertile. In its earliest stage of decomposition, the original organic material is often called raw organic matter. The final stage of decomposition is called humus.\n\nIn grassland, much of the organic matter added to the soil is from the deep, fibrous, grass root systems. By contrast, tree leaves falling on the forest floor are the principal source of soil organic matter in the forest. Another difference is the frequent occurrence in the grasslands of fires that destroy large amounts of aboveground material but stimulate even greater contributions from roots. Also, the much greater acidity under any forests inhibits the action of certain soil organisms that otherwise would mix much of the surface litter into the mineral soil. As a result, the soils under grasslands generally develop a thicker A horizon with a deeper distribution of organic matter than in comparable soils under forests, which characteristically store most of their organic matter in the forest floor (O horizon) and thin A horizon.\n\nHumus refers to organic matter that has been decomposed by soil flora and fauna to the point where it is resistant to further breakdown. Humus usually constitutes only five percent of the soil or less by volume, but it is an essential source of nutrients and adds important textural qualities crucial to soil health and plant growth. Humus also hold bits of undecomposed organic matter which feed arthropods and worms which further improve the soil. The end product, humus, is soluble in water and forms a weak acid that can attack silicate minerals. Humus is a colloid with a high cation and anion exchange capacity that on a dry weight basis is many times greater than that of clay colloids. It also acts as a buffer, like clay, against changes in pH and soil moisture.\n\nHumic acids and fulvic acids, which begin as raw organic matter, are important constituents of humus. After the death of plants and animals, microbes begin to feed on the residues, resulting finally in the formation of humus. With decomposition, there is a reduction of water-soluble constituents, cellulose and hemicellulose, and nutrients such as nitrogen, phosphorus, and sulfur. As the residues break down, only stable molecules made of aromatic carbon rings, oxygen and hydrogen remain in the form of humin, lignin and lignin complexes collectively called humus. While the structure of humus has few nutrients, it is able to attract and hold cation and anion nutrients by weak bonds that can be released into the soil solution in response to changes in soil pH.\n\nLignin is resistant to breakdown and accumulates within the soil. It also reacts with amino acids, which further increases its resistance to decomposition, including enzymatic decomposition by microbes. Fats and waxes from plant matter have some resistance to decomposition and persist in soils for a while. Clay soils often have higher organic contents that persist longer than soils without clay as the organic molecules adhere to and are stabilised by the clay. Proteins normally decompose readily, but when bound to clay particles, they become more resistant to decomposition. Clay particles also absorb the enzymes exuded by microbes which would normally break down proteins. The addition of organic matter to clay soils can render that organic matter and any added nutrients inaccessible to plants and microbes for many years. High soil tannin (polyphenol) content can cause nitrogen to be sequestered in proteins or cause nitrogen immobilisation.\n\nHumus formation is a process dependent on the amount of plant material added each year and the type of base soil. Both are affected by climate and the type of organisms present. Soils with humus can vary in nitrogen content but typically have 3 to 6 percent nitrogen. Raw organic matter, as a reserve of nitrogen and phosphorus, is a vital component affecting soil fertility. Humus also absorbs water, and expands and shrinks between dry and wet states, increasing soil porosity. Humus is less stable than the soil's mineral constituents, as it is reduced by microbial decomposition, and over time its concentration diminshes without the addition of new organic matter. However, humus may persist over centuries if not millennia.\n\nThe production, accumulation and degradation of organic matter are greatly dependent on climate. Temperature, soil moisture and topography are the major factors affecting the accumulation of organic matter in soils. Organic matter tends to accumulate under wet or cold conditions where decomposer activity is impeded by low temperature or excess moisture which results in anaerobic conditions. Conversely, excessive rain and high temperatures of tropical climates enables rapid decomposition of organic matter and leaching of plant nutrients; forest ecosystems on these soils rely on efficient recycling of nutrients and plant matter to maintain their productivity. Excessive slope may encourage the erosion of the top layer of soil which holds most of the raw organic material that would otherwise eventually become humus.\n\nCellulose and hemicellulose undergo fast decomposition by fungi and bacteria, with a half-life of 12–18 days in a temperate climate. Brown rot fungi can decompose the cellulose and hemicellulose, leaving the lignin and phenolic compounds behind. Starch, which is an energy storage system for plants, undergoes fast decomposition by bacteria and fungi. Lignin consists of polymers composed of 500 to 600 units with a highly branched, amorphous structure. Lignin undergoes very slow decomposition, mainly by white rot fungi and actinomycetes; its half-life under temperate conditions is about six months.\n\nA horizontal layer of the soil, whose physical features, composition and age are distinct from those above and beneath, is referred to as a soil horizon. The naming of a horizon is based on the type of material of which it is composed. Those materials reflect the duration of specific processes of soil formation. They are labelled using a shorthand notation of letters and numbers which describe the horizon in terms of its colour, size, texture, structure, consistency, root quantity, pH, voids, boundary characteristics and presence of nodules or concretions. No soil profile has all the major horizons. Some may have only one horizon.\n\nThe exposure of parent material to favourable conditions produces mineral soils that are marginally suitable for plant growth. That growth often results in the accumulation of organic residues. The accumulated organic layer called the O horizon produces a more active soil due to the effect of the organisms that live within it. Organisms colonise and break down organic materials, making available nutrients upon which other plants and animals can live. After sufficient time, humus moves downward and is deposited in a distinctive organic surface layer called the A horizon.\n\nSoil is classified into categories in order to understand relationships between different soils and to determine the suitability of a soil for a particular use. One of the first classification systems was developed by Russian scientist Dokuchaev around 1880. It was modified a number of times by American and European researchers, and developed into the system commonly used until the 1960s. It was based on the idea that soils have a particular morphology based on the materials and factors that form them. In the 1960s, a different classification system began to emerge which focused on soil morphology instead of parental materials and soil-forming factors. Since then it has undergone further modifications. The World Reference Base for Soil Resources (WRB) aims to establish an international reference base for soil classification.\n\nThere are fourteen soil orders at the top level of the Australian Soil Classification. They are: Anthroposols, Organosols, Podosols, Vertosols, Hydrosols, Kurosols, Sodosols, Chromosols, Calcarosols, Ferrosols, Dermosols, Kandosols, Rudosols and Tenosols.\n\nThe EU's soil taxonomy is based on a new standard soil classification in the World Reference Base for Soil Resources produced by the UN's Food and Agriculture Organization. According to this, the major soils in the European Union are:\n\nA taxonomy is an arrangement in a systematic manner; the USDA soil taxonomy has six levels of classification. They are, from most general to specific: order, suborder, great group, subgroup, family and series. Soil properties that can be measured quantitatively are used in this classification system – they include: depth, moisture, temperature, texture, structure, cation exchange capacity, base saturation, clay mineralogy, organic matter content and salt content. There are 12 soil orders (the top hierarchical level) in soil taxonomy. The names of the orders end with the suffix \"-sol\". The criteria for the different soil orders include properties that reflect major differences in the genesis of soils. The orders are:\n\nThe percentages listed above are for land area free of ice. \"Soils of Mountains\", which constitute the balance (11.6%), have a mixture of those listed above, or are classified as \"Rugged Mountains\" which have no soil.\n\nThe above soil orders in sequence of increasing degree of development are Entisols, Inceptisols, Aridisols, Mollisols, Alfisols, Spodosols, Ultisols, and Oxisols. Histosols and Vertisols may appear in any of the above at any time during their development.\n\nThe soil suborders within an order are differentiated on the basis of soil properties and horizons which depend on soil moisture and temperature. Forty-seven suborders are recognized in the United States.\n\nThe soil great group category is a subdivision of a suborder in which the kind and sequence of soil horizons distinguish one soil from another. About 185 great groups are recognized in the United States. Horizons marked by clay, iron, humus and hard pans and soil features such as the expansion-contraction of clays (that produce self-mixing provided by clay), temperature, and marked quantities of various salts are used as distinguishing features.\n\nThe great group categories are divided into three kinds of soil subgroups: typic, intergrade and extragrade. A typic subgroup represents the basic or 'typical' concept of the great group to which the described subgroup belongs. An intergrade subgroup describes the properties that suggest how it grades towards (is similar to) soils of other soil great groups, suborders or orders. These properties are not developed or expressed well enough to cause the soil to be included within the great group towards which they grade, but suggest similarities. Extragrade features are aberrant properties which prevent that soil from being included in another soil classification. About 1,000 soil subgroups are defined in the United States.\n\nA soil family category is a group of soils within a subgroup and describes the physical and chemical properties which affect the response of soil to agricultural management and engineering applications. The principal characteristics used to differentiate soil families include texture, mineralogy, pH, permeability, structure, consistency, the locale's precipitation pattern, and soil temperature. For some soils the criteria also specify the percentage of silt, sand and coarse fragments such as gravel, cobbles and rocks. About 4,500 soil families are recognised in the United States.\n\nA family may contain several soil series which describe the physical location using the name of a prominent physical feature such as a river or town near where the soil sample was taken. An example would be Merrimac for the Merrimack River in New Hampshire. More than 14,000 soil series are recognised in the United States. This permits very specific descriptions of soils.\n\nA soil phase of series, originally called 'soil type' describes the soil surface texture, slope, stoniness, saltiness, erosion, and other conditions.\n\nSoil is used in agriculture, where it serves as the anchor and primary nutrient base for plants; however, as demonstrated by hydroponics, it is not essential to plant growth if the soil-contained nutrients can be dissolved in a solution. The types of soil and available moisture determine the species of plants that can be cultivated.\n\nSoil material is also a critical component in the mining, construction and landscape development industries. Soil serves as a foundation for most construction projects. The movement of massive volumes of soil can be involved in surface mining, road building and dam construction. Earth sheltering is the architectural practice of using soil for external thermal mass against building walls. Many building materials are soil based.\n\nSoil resources are critical to the environment, as well as to food and fibre production. Soil provides minerals and water to plants. Soil absorbs rainwater and releases it later, thus preventing floods and drought. Soil cleans water as it percolates through it. Soil is the habitat for many organisms: the major part of known and unknown biodiversity is in the soil, in the form of invertebrates (earthworms, woodlice, millipedes, centipedes, snails, slugs, mites, springtails, enchytraeids, nematodes, protists), bacteria, archaea, fungi and algae; and most organisms living above ground have part of them (plants) or spend part of their life cycle (insects) below-ground. Above-ground and below-ground biodiversities are tightly interconnected, making soil protection of paramount importance for any restoration or conservation plan.\n\nThe biological component of soil is an extremely important carbon sink since about 57% of the biotic content is carbon. Even on desert crusts, cyanobacteria, lichens and mosses capture and sequester a significant amount of carbon by photosynthesis. Poor farming and grazing methods have degraded soils and released much of this sequestered carbon to the atmosphere. Restoring the world's soils could offset the effect of increases in greenhouse gas emissions and slow global warming, while improving crop yields and reducing water needs.\n\nWaste management often has a soil component. Septic drain fields treat septic tank effluent using aerobic soil processes. Landfills use soil for daily cover. Land application of waste water relies on soil biology to aerobically treat BOD.\n\nOrganic soils, especially peat, serve as a significant fuel resource; but wide areas of peat production, such as sphagnum bogs, are now protected because of patrimonial interest.\n\nGeophagy is the practice of eating soil-like substances. Both animals and human cultures occasionally consume soil for medicinal, recreational, or religious purposes. It has been shown that some monkeys consume soil, together with their preferred food (tree foliage and fruits), in order to alleviate tannin toxicity.\n\nSoils filter and purify water and affect its chemistry. Rain water and pooled water from ponds, lakes and rivers percolate through the soil horizons and the upper rock strata, thus becoming groundwater. Pests (viruses) and pollutants, such as persistent organic pollutants (chlorinated pesticides, polychlorinated biphenyls), oils (hydrocarbons), heavy metals (lead, zinc, cadmium), and excess nutrients (nitrates, sulfates, phosphates) are filtered out by the soil. Soil organisms metabolise them or immobilise them in their biomass and necromass, thereby incorporating them into stable humus. The physical integrity of soil is also a prerequisite for avoiding landslides in rugged landscapes.\n\nLand degradation refers to a human-induced or natural process which impairs the capacity of land to function. Soils degradation involves the acidification, contamination, desertification, erosion or salination.\n\nSoil acidification is beneficial in the case of alkaline soils, but it degrades land when it lowers crop productivity and increases soil vulnerability to contamination and erosion. Soils are often initially acid because their parent materials were acid and initially low in the basic cations (calcium, magnesium, potassium and sodium). Acidification occurs when these elements are leached from the soil profile by rainfall or by the harvesting of forest or agricultural crops. Soil acidification is accelerated by the use of acid-forming nitrogenous fertilizers and by the effects of acid precipitation.\n\nSoil contamination at low levels is often within a soil's capacity to treat and assimilate waste material. Soil biota can treat waste by transforming it; soil colloids can adsorb the waste material. Many waste treatment processes rely on this treatment capacity. Exceeding treatment capacity can damage soil biota and limit soil function. Derelict soils occur where industrial contamination or other development activity damages the soil to such a degree that the land cannot be used safely or productively. Remediation of derelict soil uses principles of geology, physics, chemistry and biology to degrade, attenuate, isolate or remove soil contaminants to restore soil functions and values. Techniques include leaching, air sparging, chemical amendments, phytoremediation, bioremediation and natural degradation.\n\nDesertification is an environmental process of ecosystem degradation in arid and semi-arid regions, often caused by human activity. It is a common misconception that droughts cause desertification. Droughts are common in arid and semiarid lands. Well-managed lands can recover from drought when the rains return. Soil management tools include maintaining soil nutrient and organic matter levels, reduced tillage and increased cover. These practices help to control erosion and maintain productivity during periods when moisture is available. Continued land abuse during droughts, however, increases land degradation. Increased population and livestock pressure on marginal lands accelerates desertification.\n\nErosion of soil is caused by water, wind, ice, and movement in response to gravity. More than one kind of erosion can occur simultaneously. Erosion is distinguished from weathering, since erosion also transports eroded soil away from its place of origin (soil in transit may be described as sediment). Erosion is an intrinsic natural process, but in many places it is greatly increased by human activity, especially poor land use practices. These include agricultural activities which leave the soil bare during times of heavy rain or strong winds, overgrazing, deforestation, and improper construction activity. Improved management can limit erosion. Soil conservation techniques which are employed include changes of land use (such as replacing erosion-prone crops with grass or other soil-binding plants), changes to the timing or type of agricultural operations, terrace building, use of erosion-suppressing cover materials (including cover crops and other plants), limiting disturbance during construction, and avoiding construction during erosion-prone periods.\n\nA serious and long-running water erosion problem occurs in China, on the middle reaches of the Yellow River and the upper reaches of the Yangtze River. From the Yellow River, over 1.6 billion tons of sediment flow each year into the ocean. The sediment originates primarily from water erosion (gully erosion) in the Loess Plateau region of northwest China.\n\nSoil piping is a particular form of soil erosion that occurs below the soil surface. It causes levee and dam failure, as well as sink hole formation. Turbulent flow removes soil starting at the mouth of the seep flow and the subsoil erosion advances up-gradient. The term sand boil is used to describe the appearance of the discharging end of an active soil pipe.\n\nSoil salination is the accumulation of free salts to such an extent that it leads to degradation of the agricultural value of soils and vegetation. Consequences include corrosion damage, reduced plant growth, erosion due to loss of plant cover and soil structure, and water quality problems due to sedimentation. Salination occurs due to a combination of natural and human-caused processes. Arid conditions favour salt accumulation. This is especially apparent when soil parent material is saline. Irrigation of arid lands is especially problematic. All irrigation water has some level of salinity. Irrigation, especially when it involves leakage from canals and overirrigation in the field, often raises the underlying water table. Rapid salination occurs when the land surface is within the capillary fringe of saline groundwater. Soil salinity control involves watertable control and flushing with higher levels of applied water in combination with tile drainage or another form of subsurface drainage.\n\nSoils which contain high levels of particular clays, such as smectites, are often very fertile. For example, the smectite-rich clays of Thailand's Central Plains are among the most productive in the world.\n\nMany farmers in tropical areas, however, struggle to retain organic matter in the soils they work. In recent years, for example, productivity has declined in the low-clay soils of northern Thailand. Farmers initially responded by adding organic matter from termite mounds, but this was unsustainable in the long-term. Scientists experimented with adding bentonite, one of the smectite family of clays, to the soil. In field trials, conducted by scientists from the International Water Management Institute in cooperation with Khon Kaen University and local farmers, this had the effect of helping retain water and nutrients. Supplementing the farmer's usual practice with a single application of 200 kg bentonite per rai (6.26 rai = 1 hectare) resulted in an average yield increase of 73%. More work showed that applying bentonite to degraded sandy soils reduced the risk of crop failure during drought years.\n\nIn 2008, three years after the initial trials, IWMI scientists conducted a survey among 250 farmers in northeast Thailand, half of whom had applied bentonite to their fields. The average improvement for those using the clay addition was 18% higher than for non-clay users. Using the clay had enabled some farmers to switch to growing vegetables, which need more fertile soil. This helped to increase their income. The researchers estimated that 200 farmers in northeast Thailand and 400 in Cambodia had adopted the use of clays, and that a further 20,000 farmers were introduced to the new technique.\n\nIf the soil is too high in clay, adding gypsum, washed river sand and organic matter will balance the composition. Adding organic matter (like ramial chipped wood for instance) to soil which is depleted in nutrients and too high in sand will boost its quality.\n\n"}
{"id": "43738402", "url": "https://en.wikipedia.org/wiki?curid=43738402", "title": "Stringer v Peat Marwick Mitchell &amp; Co", "text": "Stringer v Peat Marwick Mitchell &amp; Co\n\nStringer v Peat Marwick Mitchell & Co [2000] 1 NZLR 450 is a cited case in New Zealand regarding liability for negligent misstatements \n\nStringer was a partner at a law firm where it was discovered that a fellow partner had embezzled 1 million dollars from the firm, which had gone unnoticed by the auditors Peat Marwick\n\nStringer sued the auditors for negligence for the loss.\n\nPeat Marwick argued that they were hired by the New Zealand Law Society and not by the law firm itself, although the law firm did pay for their audit fees.\n\nThe court held that despite the primary purpose of the auditing was to protect the firms clients, they were also protecting the partnership's interests as well, meaning that they were liable for the partners losses from the fraud. The court did say however, that they could possibly mitigate the amount of damages through contributory negligence, if the partners were negligent as well.\n"}
{"id": "5759887", "url": "https://en.wikipedia.org/wiki?curid=5759887", "title": "The Caine Mutiny", "text": "The Caine Mutiny\n\nThe Caine Mutiny is the 1951 Pulitzer Prize–winning novel by Herman Wouk. The novel grew out of Wouk's personal experiences aboard a destroyer-minesweeper in the Pacific Theater in World War II. Among its themes, it deals with the moral and ethical decisions made at sea by ship captains. The mutiny of the title is legalistic, not violent, and takes place during Typhoon Cobra, in December 1944. The court-martial that results provides the dramatic climax to the plot.\n\nThe story is told through the eyes of Willis Seward \"Willie\" Keith, an affluent, callow young man who signs up for midshipman school with the United States Navy to avoid being drafted into the United States Army during World War II. The novel describes the tribulations he endures because of inner conflicts over his relationship with his domineering mother and with May Wynn, a beautiful red-haired nightclub singer, the daughter of Italian immigrants. After barely surviving a series of misadventures that earn him the highest number of demerits in his midshipman's class, he is commissioned as an ensign and assigned to the destroyer minesweeper USS \"Caine\", an obsolete warship converted from a World War I-era destroyer.\n\nWillie, with a low opinion of the ways of the Navy, misses his ship when it leaves on a combat assignment, and rather than catch up with it, ducks his duties to play piano for an admiral who has taken a shine to him. He has second thoughts after reading a last letter from his father, who has died of melanoma, but soon forgets his guilt in the round of parties at the admiral's house. Eventually, he reports aboard \"Caine\". Although the ship has successfully carried out its combat missions in Willie's absence, the ensign immediately disapproves of its decaying condition and slovenly crew, which he attributes to a slackness of discipline by the ship's longtime captain, Lieutenant Commander William De Vriess.\n\nWillie's lackadaisical attitude toward what he considers menial duties brings about a humiliating clash with De Vriess when Willie forgets to decode a communications message which serves notice that De Vriess will soon be relieved. While Willie is still pouting over his punishment, De Vriess is relieved by Lieutenant Commander Philip Francis Queeg, a strong, by-the-book figure, whom Willie at first believes to be just what the rusty \"Caine\" and its rough-necked crew needs. But Queeg has never handled a ship like this before, and he soon makes errors, to which he is unwilling to admit. \"Caine\" is sent to San Francisco for an overhaul, in an admiral's hope that the captain will make further mistakes someplace else. Before the ship departs, Queeg browbeats his officers into selling their liquor rations to him. In a breach of regulations, Queeg smuggles the liquor off the ship, and when it is lost, blackmails Willie into paying for it. Willie sees May on leave, and after sleeping with her, decides he has no future with a woman of a lower social class. He resolves to let the relationship die by not replying to her letters.\n\nAs \"Caine\" begins its missions under his command, Queeg loses the respect of the crew and loyalty of the wardroom through a series of incidents. Tensions aboard the ship cause Queeg to isolate himself from the other officers, who snub him as unworthy, believing him an oppressive coward. Queeg is dubbed \"Old Yellowstain\" by the officers following the invasion of Kwajalein. Ordered to escort low-lying landing craft to their line of departure, \" Caine\" instead drops a yellow dye marker to mark the spot, and hastily leaves the battle area.\n\nCommunications officer Lieutenant Thomas Keefer, an intellectual and initially a sympathetic character, plants the suggestion that Queeg might be mentally ill in the mind of \"Caine\"s executive officer, Lieutenant Stephen Maryk. He steers Maryk to \"Section 184\" of the Navy Regulations, according to which a subordinate can relieve a commanding officer in extraordinary circumstances.\n\nMaryk keeps a secret log of Queeg's eccentric behavior and decides to bring it to the attention of Admiral Halsey, commanding the Third Fleet. Keefer reluctantly supports Maryk, then gets cold feet and backs out, warning Maryk that his actions will be seen as mutiny. Soon after, \"Caine\" is caught in the path of a typhoon, an ordeal that sinks three destroyers. At the height of the storm, Queeg's paralysis of action convinces Maryk that he must relieve the captain of command to prevent the loss of the ship. Willie Keith, as Officer of the Deck, supports the decision. Maryk turns \"Caine\" into the wind and rides out the storm.\n\nMaryk is tried by court-martial for \"conduct to the prejudice of good order and discipline\" instead of \"making a mutiny\". Willie and Stilwell, the enlisted helmsman during the typhoon, are to be tried depending on the outcome of Maryk's trial. In the courtroom, Keefer distances himself from any responsibility for the relief. Lieutenant Barney Greenwald, a naval aviator who was an attorney in civilian life, is appointed to represent Maryk. His opinion, after the captain was found to be sane by three Navy psychiatrists, is that Maryk was legally unjustified in relieving Queeg. Despite his own disgust with Maryk's and Willie's actions, Greenwald decides to take the case after deducing Keefer's role.\n\nDuring the trial, Greenwald unrelentingly cross-examines Queeg until he is overcome by the stress. Greenwald's tactic of attacking Queeg results in Maryk's acquittal and the dropping of charges against Willie. Maryk, who had aspired to a career in the regular navy, is later sent to command a Landing Craft Infantry, a humiliation which ends his naval career ambitions, while Queeg is transferred to a naval supply depot in Iowa.\n\nAt a party celebrating both the acquittal and Keefer's success at selling his novel to a publisher, an intoxicated Greenwald calls Keefer a coward. He tells the gathering that he feels ashamed of having destroyed Queeg on the stand because Queeg did the necessary duty of guarding America in the peacetime Navy, which people like Keefer saw as beneath them. Greenwald asserts that men like Queeg kept Greenwald's Jewish mother from being \"melted down into a bar of soap\" by the Nazis. Greenwald had to \" Queeg\" because \"the wrong man was on trial\"—that it was Keefer, not Maryk, who was \"the true author of 'The \"Caine\" Mutiny'\". Greenwald throws a glass of \"the yellow wine\" in Keefer's face, thereby bringing the term \"Old Yellowstain\" full circle back to the novelist.\n\nWillie returns to \"Caine\" in the last days of the Okinawa campaign as its executive officer. Keefer is now the captain, and his behavior as captain is similar to Queeg's. \"Caine\" is struck by a kamikaze, an event in which Willie discovers that he has matured into a naval officer. Keefer panics and orders the ship abandoned, but Willie remains aboard and rescues the situation.\n\nKeefer is sent home after the war ends, ashamed of his cowardly behavior during the kamikaze attack. Keefer's brother Roland had died saving his ship from a kamikaze fire. Willie becomes the last captain of \"Caine\". He receives a Bronze Star Medal for his actions following the kamikaze—and a letter of reprimand for his part in unlawfully relieving Queeg. The findings of the court-martial have been overturned after a review by higher authority. Willie agrees in retrospect that the relief was unjustified and probably unnecessary.\n\nWillie keeps \"Caine\" afloat during another typhoon and brings it back to Bayonne, New Jersey, for decommissioning after the end of the war. On reflection, he decides to ask May (now a blonde and using her real name of Marie Minotti) to marry him. However, this will not be as easy as he once thought, as she is now the girlfriend of a popular bandleader.\n\nWouk himself served during World War II aboard two destroyer-minesweepers converted from World War I-era s, being the first and being the second. (Wouk uses the latter name for one of his characters in the novel, Captain Randolph Patterson Southard. In an allusion to history professor Jacques Barzun of his alma mater, Columbia University, Wouk also has Queeg refer to a previous assignment he had on a ship named \"Barzun\".)\n\nUSS \"Caine\" is a fictional depiction of a DMS (destroyer-minesweeper) conversion. The \"Clemson\" class was named for Midshipman Henry A. Clemson, lost at sea on 8 December 1846 during the Mexican war, when the brig capsized off Vera Cruz in a sudden squall while chasing a blockade runner. In November 1842 \"Somers\" was the scene of the only recorded conspiracy to mutiny in U.S. Naval history when three members of the crew—a midshipman, a boatswain's mate, and a seaman—were clapped in irons and subsequently hanged for planning a takeover of the vessel.\n\nMany of the incidents and plot details are autobiographical. Like both Keefer and Willie, Wouk rose through the ship's wardroom of \"Zane\" from assistant communications officer to first lieutenant, and then was executive officer of \"Southard,\" recommended to captain the ship home to the United States at the end of the war before it was beached at Okinawa in a typhoon.\n\n\"The Caine Mutiny\" reached the top of the \"New York Times\" best seller list on August 12, 1951, after 17 weeks on the list, replacing \"From Here to Eternity\". It remained atop the list for 33 weeks until March 30, 1952, when it was replaced by \"My Cousin Rachel\". It moved back to first place on May 25, 1952, and remained another 15 weeks, before being supplanted by \"The Silver Chalice\", and last appeared on August 23, 1953, after 122 weeks on the list.\n\nIn 1954 Columbia Pictures released the film \"The Caine Mutiny\" starring Humphrey Bogart as Queeg in a widely acclaimed performance that earned him the third and final Academy Award nomination of his career.\n\nAfter the novel's success, Wouk adapted the court-martial sequence into a full-length, two-act Broadway play, \"The Caine Mutiny Court Martial\". Directed by Charles Laughton, it was a success on the stage in 1954, opening five months before the release of the film and starring Lloyd Nolan as Queeg, John Hodiak as Maryk, and Henry Fonda as Greenwald. It has been revived twice on Broadway, and was presented on television live in 1955, and in 1988 as a made-for-television film.\n\nThe stage script was translated into Chinese in 1988 by Ying Ruocheng, a famous Chinese actor, director, playwright and Vice Minister of Culture. At Ying's invitation, Charlton Heston directed the translated play in a successful run at the Beijing People's Art Theatre, opening on October 18, 1988. The play was revived in 2006, again under Heston, and has been revived there twice more (2009, 2012) since his death.\n\n\n"}
{"id": "34494350", "url": "https://en.wikipedia.org/wiki?curid=34494350", "title": "The Final Rule", "text": "The Final Rule\n\nThe Final Rule is a national policy in the United States that dictates the protocol for all cadaveric organ donation. The Final Rule replaced a variety of local and regional protocol with a unified policy for the first time. It also increased Department of Health and Human Services' control of organ donation.\n\nThe Final Rule was issued by the U.S. Department of Health and Human Services (DHHS) and dictates the process to be taken by organ procurement organizations in conjunction with United Network for Organ Sharing to match donors with potential recipients.The Final Rule dramatically changed the way organ donations were allocated in the United States, moving away from a system that favored geographic areas with large donor banks towards a system that prioritized a patient's need for organ transplant over their proximity to the donor. This move reflects increased ability to successfully preserve and transfer organs for Organ transplantation farther than was previously possible. This move was controversial among areas with larger donor banks because there were concerns that the rule would disincentivize organ donation. Donor banks believed donors would be less likely to donate if the organs were being transferred out of state.\n\nOriginally proposed in 1998, the Final Rule was not implemented until March 2000. Implementation was delayed in order to collect public input and due to lawsuits including two brought by the State of Wisconsin and State of New Jersey seeking injunctive relief from the ruling. The Final Rule as it stands today allows for local recipients to be considered first but directs organ procurement organizations to offer organs nationally if a local match cannot be made, taking urgency of need into account. \nThe current ruling also gives DHHS veto power over any policies created by the Organ Procurement and Transplantation Network, administered by the United Network for Organ Sharing, increasing the direct role of DHHS in organ donation.\n"}
{"id": "2044549", "url": "https://en.wikipedia.org/wiki?curid=2044549", "title": "Trespasser", "text": "Trespasser\n\nIn the law of tort, property, and criminal law a trespasser is a person who commits the act of trespassing on a property, that is, without the permission of the owner. Being present on land as a trespasser thereto creates liability in the trespasser, so long as the trespass is intentional. At the same time, the status of a visitor as a trespasser (as opposed to an invitee or a licensee) defines the legal rights of the visitor if they are injured due to the negligence of the property owner.\n\nThe tort of trespass to land requires an intentional physical invasion of the plaintiff's real property by the defendant or a refusal to leave when ordered to leave.\n\nFor example, a person walking in a public park who trips and rolls down a hill will not be liable for trespass just because the bottom of the hill is on private land.\n\nThe trespasser need not enter the land in person. Indeed, if A and B are standing next to C's land, and A pushes B onto the land without entering it himself, it is A (and not B, who did not intend to enter that space) who is liable for the trespass to C's land. There must be some physical entry, however. Causing noise, light, odors, or smoke to enter the land of another is not a trespass, but is instead a different tort, nuisance.\n\nFor purposes of determining liability, the landowner's property rights extend above and below the land to as much distance as the landowner can beneficially use. Even a low-flying plane can trespass if it enters this usable space.\n\nA constructive trespass occurs when a person who has permission to be on the land overstays their welcome. A person who stays in a business after its closing time, or who goes to a dinner party but refuses to leave long after the other guests have gone home, is a trespasser despite his initially proper presence. Furthermore, a guest's status as a trespasser arises as soon as he resists when the property owner tells him to leave the property. This is not a constructive trespass if the guest is unconscious.\n\nAs a broad general rule, property owners owe few duties to trespassers to safeguard them from injuries that may occur on their property. \n\nWith respect to the duties owed to trespassers, there are two types of trespassers to consider:\n\nFor injury claims by trespassers, the concept of traps was narrowly defined. More recently, courts in some jurisdictions have engaged in some creativity, adopting a broader interpretation of a trap.\n\nA warning sign at the entrance to the land is generally sufficient to warn trespassers of possible hazards on a property or land. However, a property owner is under no duty to ascertain hazards on his property for the benefit of trespassers, and cannot be held liable for failing to discover a previously unknown hazard that injures a trespasser.\n\nIn some jurisdictions an adult trespasser who is injured while on a defendant's property cannot sue under a theory of strict liability, even if the landowner was engaged in ultrahazardous activities, such as the keeping of wild animals, or the use of explosives. Instead, the trespasser must prove that the property owner intentionally or wantonly injured the plaintiff to recover.\n\nSome jurisdictions extend additional protections to children who trespass on the properly of others. For example, if there is a potentially hazardous object or condition on the land that might be attractive to young children, the trespass may be deemed \"anticipated\" under the doctrine of attractive nuisance such that the child may be able to succeed with an injury claim.\n\nIn some regions of the world, a property owner may use reasonable (typically meaning non-deadly) force to prevent a person from trespassing on their land, or to expel a trespasser. However, a property owner may by restricted from expelling a trespasser if doing so would expose the trespasser to a risk of serious injury. For example, a trespasser who takes shelter in a stranger's barn during a powerful storm cannot be expelled until the storm is over.\n\nMany jurisdictions within the United States have passed statutes to modify or clarify the common law duties owed by a property owner to a trespasser (for example, by explicitly permitting the property owner to use deadly force to expel trespassers).\n\n"}
{"id": "993845", "url": "https://en.wikipedia.org/wiki?curid=993845", "title": "United States nationality law", "text": "United States nationality law\n\nThe United States nationality law is a uniform rule of naturalization of the United States set out in the Immigration and Nationality Act of 1952, enacted under the power of Article I, section 8, clause 4 of the United States Constitution (also referred to as the Nationality Clause), which reads: Congress shall have Power - \"To establish a uniform Rule of Naturalization...\" The 1952 Act sets forth the legal requirements for the acquisition of, and divestiture from, American nationality. The requirements have become more explicit since the ratification of the Fourteenth Amendment to the Constitution, with the most recent changes to the law having been made by Congress in 2001.\n\nAdult citizens of the United States who are residents of one of the 50 states or the District of Columbia (Washington, D.C.) have the right to participate in the political system of the United States, as well as their state and local governments, (with most states having restrictions on voting by persons convicted of felonies, and a federal constitutional prohibition on naturalized persons running for President and Vice President of the United States), to be represented and protected abroad by the United States (through U.S. embassies and consulates), and to live in the United States and certain territories without any immigration requirements.\nFelons can vote in over 40 states, and in at least 2 while incarcerated. Felons can also serve jury duty if approved.\n\nSome U.S. citizens have the obligation to serve in a jury, if selected and legally qualified.\nCitizens are also required (under the provisions of the Internal Revenue Code) to pay taxes on their total income from all sources worldwide, including income earned abroad while living abroad. Under certain circumstances, however, U.S. citizens living and working abroad may be able to reduce or eliminate their U.S. federal income tax via the Foreign Earned Income Exclusion or the Foreign Tax Credit.\nU.S. taxes payable may be alternatively reduced by credits for foreign income taxes regardless of the length of stay abroad. The United States Government also insists that U.S. citizens travel into and out of the United States on a U.S. passport, regardless of any other nationality they may possess.\n\nMale U.S. citizens (including those living permanently abroad and those with multiple citizenships) from 18–25 years of age are required to register with the Selective Service System at age 18 for possible conscription into the armed forces. Although no one has been drafted in the U.S. since 1973, draft registration continues in the case of a possible reinstatement on some future date.\n\nIn the Oath of Citizenship, immigrants becoming naturalized U.S. citizens swear that when required by law they will bear arms on behalf of the United States, will perform noncombatant service in the U.S. Armed Forces, and will perform work of national importance under civilian direction. In some cases, the USCIS allows the oath to be taken without the clauses regarding the first two of these three sworn commitments.\n\nThere are various ways a person can acquire United States citizenship, either at birth or later on in life.\n\nSection 1 of the Fourteenth Amendment to the United States Constitution provides that \"All persons born or naturalized in the United States, and subject to the jurisdiction thereof, are citizens of the United States and of the State wherein they reside.\"\n\nBecause Native American tribes within the geographical boundaries of the U.S. held a special sovereignty status, the tribes were not \"subject to the jurisdiction thereof\" and thus Native Americans who were born into tribes were not considered citizens, even if they left the tribe and settled in white society, which the Supreme Court upheld in \"Elk v. Wilkins\". However, in 1924, Congress granted birthright citizenship to Native Americans through the Indian Citizenship Act. Furthermore, some U.S. territories are not considered part of the United States for application of the Constitution. Congress has conferred birthright citizenship, through legislation, to persons born in all inhabited territories except American Samoa and Swains Island, who are granted the status of U.S. Nationals. (See .)\n\nIn the case of \"United States v. Wong Kim Ark\", the Supreme Court ruled that a person becomes a citizen of the United States at the time of birth, by virtue of the first clause of the 14th Amendment, if at a minimum that person:\n\nThe Supreme Court has never explicitly ruled on whether children born in the United States to illegal immigrant parents are entitled to birthright citizenship via the 14th Amendment, but it has generally been assumed that they are.\n\nA child is automatically granted citizenship if:\nThe FAM (Foreign Affairs Manual) states \"no amount of time specified.\"\n\nA person's record of birth abroad, if registered with a U.S. consulate or embassy, is proof of citizenship. They may also apply for a passport or a Certificate of Citizenship as proof of citizenship.\n\nA person born on or after November 14, 1986, is a U.S. citizen if all of the following are true:\n\nINA 301(g) makes additional provisions to satisfy the physical-presence requirements for periods citizens spent abroad in \"honorable service in the Armed Forces of the United States, or periods of employment with the United States Government or with an international organization.\" Additionally citizens, who spent time living abroad as the \"dependent unmarried son or daughter and a member of the household of a person\" in any of the previously mentioned organizations can also be counted.\n\nA person's record of birth abroad, if registered with a U.S. consulate or embassy, is proof of citizenship. Such a person may also apply for a passport or a Certificate of Citizenship to have a record of citizenship. Such documentation is often useful to prove citizenship in lieu of the availability of an American birth certificate.\n\nDifferent rules apply for persons born abroad to one U.S. citizen before November 14, 1986. United States law on this subject changed multiple times throughout the twentieth century, and the law is applicable as it existed at the time of the individual's birth.\n\nFor persons born between December 24, 1952 and November 14, 1986, a person is a U.S. citizen if all of the following are true:\n\n\nFor persons born to two people who are not married to each other, the person is a U.S. citizen if all the following apply:\n\nThe Child Citizenship Act of 2000 (CCA), which went into effect on February 27, 2001, amends the Immigration and Nationality Act (INA) to provide U.S. citizenship to certain foreign-born children—including adopted children—of U.S. citizens.\n\nA person who was not born a U.S. citizen may acquire U.S. citizenship through a process known as naturalization.\n\nTo become a naturalized United States citizen, one must be at least eighteen years of age at the time of filing, a legal permanent resident (or non-citizen national) of the United States, and have had a status of a legal permanent resident in the United States for five years before they apply. (This 5-year requirement is reduced to three years if they (a) acquired legal permanent resident status, (b) have been married to and living with a citizen for the past three years and (c) the spouse has been a U.S. citizen for at least three years prior to the applicant applying for naturalization.) They must have been physically present for at least 30 months of 60 months prior to the date of filing their application. Also during those 60 months if the legal permanent resident was outside of the U.S. for a continuous period of 6 months or more they are disqualified from naturalizing (certain exceptions apply for those continuous periods of six months to 1 year).\n\nThe territory of the United States, for the purposes of determining one's period of residence, includes the fifty states, District Columbia, Puerto Rico, U.S. Virgin Islands, Guam, and the Northern Mariana Islands. The Commonwealth of the Northern Mariana Islands has been added to this list effective November 28, 2009. Prior to that date, residence in the CNMI normally did not count as residence in the United States for naturalization purposes. American Samoa is not included into the territory of the United States for the purposes of determining one's period of residence (unless the person being naturalized is a US national, rather than a permanent resident alien; see below).\n\nAn applicant for citizenship must be a \"person of good moral character\", and must pass a test on United States history and government.\nMost applicants must also have a working knowledge of the English language. There are exceptions, introduced in 1990, for long-resident older applicants and those with mental or physical disabilities.\n\nSome exemptions from permanent residency exist for certain qualifying naturalization applicants. For example, an undocumented immigrant who served in the US military during a designated period of hostility may naturalize without having first been a permanent resident. An immigrant who successfully completes the MAVNI program may naturalize in 10 weeks without first having been a permanent resident. Similarly, an immigrant who has made extraordinary contributions can be exempted from residency as well as the physical presence requirement and prohibitions for support of totalitarianism and or communism.\n\nA non-citizen U.S. national (see below) is also eligible for naturalization after becoming a resident of any state. For such persons (unlike most other applicants for naturalization), time spent in American Samoa counts as time spent in the United States for the purposes of determining residence and physical presence.\n\nThe entire citizenship test is in the form of a one-on-one interview. The citizenship test has four components: a speaking/comprehension test, a reading test, a writing test and a civics test. For the civics test, applicants for citizenship are asked ten questions, and must answer at least six with the expected answers. U.S. Citizenship and Immigration Services has published a list of 100 sample questions (with the answers that should be given when taking the test), from which the questions asked are always drawn. The full list of questions is in the document \"A Guide to Naturalization\", available for free from the USCIS. The test examines the applicant's knowledge of American society and the English language. Sample questions and answers are published by the USCIS in English, Spanish, and Chinese.\n\nBesides passing the citizenship test, citizenship applicants must also satisfy other specific requirements of naturalization to successfully obtain U.S. citizenship.\n\nA person who becomes a U.S. citizen through naturalization is not considered a natural born citizen. Consequently, naturalized U.S. citizens are not eligible to become President of the United States or Vice President of the United States, which would ordinarily be the case as established by the Presidential Succession Act. For example, though the Secretary of Commerce and the Secretary of Labor are tenth and eleventh in the presidential line of succession, Elaine Chao and Carlos Gutierrez (respectively former U.S. Secretaries of Labor and Commerce under President George W. Bush) would have been unable to succeed to the presidency because they became U.S. citizens through naturalization. The highest-ranking naturalized citizens to have been excluded from the Presidential Line of Succession were Henry Kissinger and Madeleine Albright, each of whom would have been fourth in line as Secretary of State had they been natural born citizens.\n\nWhether this restriction applies to children born to non-U.S. citizens but adopted as minors by U.S. citizens is a matter of some debate, since the Child Citizenship Act of 2000 is ambiguous as to whether acquisition of citizenship by that route is to be regarded as naturalized or natural-born. Those who argue that the restriction does not apply point out that the child automatically becomes a citizen even though violating every single requirement of eligibility for naturalization, and thus the case falls closer to the situation of birth abroad to U.S. citizens than to naturalization.\n\nSome argue that the phrase \"natural born citizen\" describes a category of citizenship distinct from that described by the phrase \"U.S. Citizen\" in Article Two of the United States Constitution, and this was discussed during the constitutional convention of 1787. While it is true that \"natural born citizen\" is not defined anywhere within the text of the Constitution and that the Constitution makes use of the phrase \"citizen\" and \"natural born citizen\", Supreme Court Decisions from United States v. Wong Kim Ark to the present have considered the distinction to be between natural-born and naturalized citizenship.\n\nIn her 1988 article in the Yale Law Journal, Jill Pryor wrote, \"It is well settled that 'native-born' citizens, those born in the United States, qualify as natural born. It is also clear that persons born abroad of alien parents, who later become citizens by naturalization, do not. But whether a person born abroad of American parents, or of one American and one alien parent, qualifies as natural born has never been resolved.\"\n\nAn April 2000 CRS report by the Congressional Research Service, asserts that most constitutional scholars interpret the phrase \"natural born citizen\" as including citizens born outside the United States to parents who are U.S. citizens under the \"natural born\" requirement.\n\nChester Arthur, born in the U.S. state of Vermont of an American mother and Irish father, was sworn in as president, but his status as a \"natural-born citizen\" was challenged on the grounds that he was allegedly born in Canada or Ireland. Presidential candidates George W. Romney (born in Mexico), Ted Cruz (born in Canada), Barry Goldwater and John McCain (born in U.S. territories), were never seriously challenged on the basis of their \"natural born\" citizenship, but no candidate falling under this classification has been elected president. Charles Curtis falls under this classification by birth in Kansas Territory, was elected and served as vice president, proving constitutional eligibility for president. Similarly, Al Gore was born in Washington, D.C., and yet was elected and served as vice president, provides additional evidence of Constitutional eligibility even though he too was born outside a US state.\n\nEffective April 1, 1995, a child born outside the U.S. to a U.S. citizen parent, if not already a citizen by birth because the parent does not meet the residency requirement (see above), may qualify for expeditious naturalization based on the physical presence of the child's grandparent in the U.S. In general the grandparent should have spent five years in the U.S., at least two of which were after the age of 14.\n\nThe process of naturalization, including the oath of allegiance, must be completed before the child's 18th birthday. It is not necessary for the child to be admitted to the U.S. as a lawful permanent resident.\n\nEffective February 27, 2001, the Child Citizenship Act of 2000 provided that a non-U.S. citizen child (aged under 18) with a U.S. citizen parent, and in the custody of that parent while resident in the United States, automatically acquired U.S. citizenship.\nTo be eligible, a child must meet the definition of \"child\" for naturalization purposes under immigration law, and must also meet the following requirements:\n\nBased on the U.S. Department of State regulation on dual citizenship (7 FAM 082), the Supreme Court of the United States has stated that dual citizenship is a \"status long recognized in the law\" and that \"a person may have and exercise rights of nationality in two countries and be subject to the responsibilities of both. The mere fact he asserts the rights of one citizenship does not, without more, mean that he renounces the other\", \"Kawakita v. U.S.\", 343 U.S. 717 (1952). In \"Schneider v. Rusk\", 377 U.S. 163 (1964), the U.S. Supreme Court ruled that a naturalized U.S. citizen has the right to return to his native country and to resume his former citizenship, and also to remain a U.S. citizen even if he never returns to the United States.\n\nThe Immigration and Nationality Act (INA) neither defines dual citizenship nor takes a position for it or against it. There has been no prohibition against dual citizenship, but some provisions of the INA and earlier U.S. nationality laws were designed to reduce situations in which dual citizenship exists. Although naturalizing citizens are required to undertake an oath renouncing previous allegiances, the oath has never been enforced to require the actual termination of original citizenship.\n\nAlthough the U.S. government does not endorse dual citizenship as a matter of policy, it recognizes the existence of dual citizenship and completely tolerates the maintenance of multiple citizenship by U.S. citizens. In the past, claims of other countries on dual-national U.S. citizens sometimes placed them in situations where their obligations to one country were in conflict with the laws of the other. However, as fewer countries require military service and most base other obligations (such as the payment of taxes) on residence and not citizenship, these conflicts have become less frequent.\n\nA U.S. citizen may lose his or her dual citizenship by obtaining naturalization in a foreign state, by taking an oath or making an affirmation or other formal declaration of allegiance to a foreign state or political subdivision thereof, by serving in the armed forces of a foreign state, or by performing certain other acts, but only if the act was performed \"voluntarily and with the intention to relinquish U.S. nationality\".\n\nOne circumstance where dual citizenship may run counter to expectations of government agencies is in matters of security clearance. For example, any person granted a Yankee White vetting must be absolutely free of foreign influence, and for other security clearances one of the grounds that may result in a rejected application is an actual or potential conflict of national allegiances.\n\nVisa requirements for the United States citizens are administrative entry restrictions by the authorities of other states placed on citizens of United States. According to the 2017 Visa Restrictions Index, holders of a United States passport can visit 174 countries and territories visa-free or with visa on arrival. The United States passport is currently ranked joint 3rd alongside in terms of travel freedom in the world.\n\nIn 2017, the United States nationality is ranked twenty-seventh in the Nationality Index (QNI). This index differs from the Visa Restrictions Index, which focuses on external factors including travel freedom. The QNI considers, in addition to travel freedom, on internal factors such as peace & stability, economic strength, and human development as well. \n\nAlthough all U.S. citizens are also U.S. nationals, the reverse is not true. As specified in , a person whose only connection to the U.S. is through birth in an outlying possession (which is defined in as American Samoa and Swains Island (which is administered as part of American Samoa)), or through descent from a person so born, acquires U.S. nationality but not U.S. citizenship. This was formerly the case in only four other current or former U.S. overseas possessions.\n\nThe nationality status of a person born in an unincorporated U.S. Minor Outlying Island is not specifically mentioned by law, but under Supreme Court decision they are also regarded as non-citizen U.S. nationals.\n\nIn addition, residents of the Northern Mariana Islands who automatically gained U.S. citizenship in 1986 as a result of the Covenant between the Northern Marianas and the U.S. could elect to become non-citizen nationals within 6 months of the implementation of the Covenant or within 6 months of turning 18.\nThe U.S. passport issued to non-citizen nationals contains the endorsement code 9 which states: \"THE BEARER IS A UNITED STATES NATIONAL AND NOT A UNITED STATES CITIZEN.\" on the annotations page.\n\nNon-citizen U.S. nationals may reside and work in the United States without restrictions, and may apply for citizenship under similar rules as foreign nationals or citizens, except that they do not need to hold U.S. permanent resident status when they apply or to have held it for any length of time before applying. Like permanent residents, they are not currently allowed by any U.S. state to vote in federal or state elections, although, as with permanent residents, there is no constitutional prohibition against their doing so.\n\nLike U.S. citizens, non-citizen U.S. nationals may transmit their non-citizen U.S. nationality to children born abroad, although the rules are somewhat different from the rules for U.S. citizens.\n\nThe 14th amendment applies to incorporated territories, so people born in incorporated territories of the U.S. (currently, only the Palmyra Atoll) are automatically U.S. citizens at birth.\n\nSeparate sections of law handle territories that the United States has acquired over time, such as Alaska and Hawaii , both incorporated, and unincorporated Puerto Rico , the U.S. Virgin Islands , and Guam . Each of these sections confer citizenship on persons living in these territories as of a certain date, and usually confer native-born status on persons born in incorporated territories after that date.\n\nFor example, for Puerto Rico, all persons born in Puerto Rico between April 11, 1899, and January 12, 1941, were automatically conferred U.S. citizenship as of the date the law was signed by the President Harry S. Truman on June 27, 1952. Additionally, all persons born in Puerto Rico on or after January 13, 1941, are citizens at birth of the United States. Note that because of when the law was passed, for some, the citizenship status was retroactive.\n\nThe law contains one other section of historical note, concerning the Panama Canal Zone and the nation of Panama. In , the law states that anyone born in the Canal Zone or in Panama itself, on or after February 26, 1904, to a mother or father who is a United States citizen, was \"declared\" to be a United States citizen at birth.\n\nAll persons born in the U.S. Virgin Islands on or after February 25, 1927, are native-born citizens of the United States. The also indicate that all the persons and their children born in the U.S. Virgin Islands subsequent to January 17, 1917, and prior to February 25, 1927, are declared to be citizens of the United States as of February 25, 1927 if complied with the U.S. law dispositions.\n\nAll persons born in Alaska on or after June 2, 1924, are native-born citizens of the United States. Alaska was declared a U.S. state on January 3, 1959.\n\nAll persons born in Hawaii on or after April 30, 1900, are native-born citizens of the United States. Hawaii was declared a U.S. state on August 21, 1959.\n\nAll persons born in the island of Guam on or after April 11, 1899 (whether before or after August 1, 1950) subject to the jurisdiction of the United States, are declared to be citizens of the United States.\n\nCurrently under the Immigration and Nationality Act of 1952 (INA) effective from December 24, 1952 to present the definition of the \"United States\" for nationality purposes, was expanded to add Guam; and, effective November 3, 1986, the Northern Mariana Islands (in addition to Puerto Rico and the Virgin Islands of the United States). Persons born in these territories on or after December 24, 1952 acquire U.S. citizenship at birth on the same terms as persons born in other parts of the United States; and \"Outlying possessions of the United States\" was restricted to American Samoa and Swains Island.\n\nCongressional Research Service Report number RL30527 of April 17, 2000, titled \"Presidential Elections in the United States: A Primer\" asserts that citizens born in Guam, Puerto Rico, and the U.S. Virgin Islands are legally defined as natural born citizens, and are, therefore, also eligible to be elected president.\n\nAs a historical matter, U.S. citizenship could be forfeited upon the undertaking of various acts, including naturalization in a foreign state (with a willful intent to renounce U.S. citizenship) or service in foreign armed forces. In addition, before 1967 it was possible to lose the citizenship due to voting in foreign elections. However, the Supreme Court ruled unconstitutional the provisions of Section 349(a) which provided for loss of nationality by voting in a foreign election in the case \"Afroyim v. Rusk\", 387 U.S. 253,\n\nIn 1990, the U.S. State Department adopted new regulations which presume that an individual does not intend to give up citizenship when performing one of the above potentially expatriating acts. If asked, the individual can always answer that they did not intend to give it up; this is sufficient to retain their citizenship. Hence, the U.S. effectively allows citizens to acquire new citizenships while remaining a U.S. citizen, becoming a dual citizen.\n\nAfter a U.S. citizen satisfies the Department of State procedures, the Department of State issues a Certificate of Loss of Nationality (CLN) signifying that the Department of State has accepted the U.S. Embassy/Consulate's recommendation to allow the renunciation. Renunciation of citizenship includes renunciation of all rights and privileges of citizenship. A person who wants to renounce U.S. citizenship cannot decide to retain some of the privileges of citizenship, as the State Department regards this as logically inconsistent with the concept of renunciation. Thus, such a person can be said to lack a full understanding of renouncing citizenship or lack the necessary intent to renounce citizenship, and the Department of State will not approve a loss of citizenship in such instances.\n\nPeople giving up U.S. citizenship may be subject to an expatriation tax. Originally, under the Foreign Investors Tax Act of 1966, people determined to be giving up citizenship for the purpose of avoiding U.S. taxation were subject to 10 years of continued taxation on their U.S.-source income, to prevent ex-citizens from taking advantage of special tax incentives offered to foreigners investing in the United States. Since 2008, these provisions no longer apply; instead, ex-citizens who meet certain asset or tax liability thresholds pay a one-time capital gains tax on a deemed sale of their U.S. and non-U.S. assets, regardless of their reasons for giving up citizenship. The Reed Amendment, a 1996 law, makes former citizens inadmissible to the U.S. if the Attorney General finds that they renounced citizenship for purposes of avoiding taxes; however, it has never been enforced. Proposals such as the Ex-PATRIOT Act to rewrite the Reed Amendment and make it enforceable failed in 2012 and 2013.\n\nIt is also possible to forfeit U.S. citizenship upon conviction for an act of treason against the United States. Prominent former Nazi officers who acquired American citizenship have also had it revoked if the Office of Special Investigations has been able to prove that the citizenship was obtained by concealing their involvement in war crimes committed by the Nazis in World War II.\n\n\n"}
{"id": "59045771", "url": "https://en.wikipedia.org/wiki?curid=59045771", "title": "We the Corporations", "text": "We the Corporations\n\nWe the Corporations: How American Businesses Won Their Civil Rights is a book-length history of American corporate personhood and other rights of corporations written by constitutional law professor Adam Winkler and published by W. W. Norton in 2018.\n\nThe title was a 2018 National Book Award for Nonfiction finalist.\n\n"}
{"id": "24812678", "url": "https://en.wikipedia.org/wiki?curid=24812678", "title": "World Human Rights Moot Court Competition", "text": "World Human Rights Moot Court Competition\n\nThe Nelson Mandela World Human Rights Moot Court Competition is a moot court competition on international human rights law. In 2009, the University of Pretoria Faculty of Law's Centre for Human Rights, with the assistance of the Office of the United Nations High Commissioner for Human Rights, organised the inaugural World Human Rights Moot Court Competition. The oral rounds of the competition are held annually on 8th and 9 December in Pretoria, the administrative and de facto capital of South Africa.\n\nThe moot involves a written round after which teams are selected for the oral round. Teams argue a hypothetical case on issues of international human rights law in either English or French as if it will be adjudicated by a hypothetical International Human Rights Court, on the basis of the Universal Declaration of Human Rights and other applicable (such as regional) human rights instruments. A winner is announced for each United Nations world region.\n\nThe regional rounds are judged by distinguished legal academics and legal professionals from around the world. In the final round, the panel is made up of eminent jurists and judges from international tribunals and bodies such as the different regional human rights courts and UN human rights treaty bodies. The inaugural presiding judge was Navi Pillay and Judge Mark Villiger of the European Court of Human Rights presided in the 2010 final.\n\n\n"}
{"id": "54367124", "url": "https://en.wikipedia.org/wiki?curid=54367124", "title": "ZeniMax v. Oculus", "text": "ZeniMax v. Oculus\n\nZeniMax v. Oculus is a civil lawsuit filed by ZeniMax Media against Oculus VR on charges of theft of intellectual property relating to Oculus' virtual reality device, the Oculus Rift.\n\nThe Oculus Rift is a virtual reality headset that was developed by Oculus VR. The company was founded by Palmer Luckey, who had a keen interest in head-mounted displays and had developed a prototype of the Oculus Rift by 2012. Concurrently, John Carmack, at the time of id Software, a subsidiary under ZeniMax Media, also was interested in head-mounted displays, saw Luckey's prototype for the Rift and modified it, showcasing the updated prototype at Electronic Entertainment Expo 2012 (E3) that June using a modified version of id's \"Doom 3\".\n\nFollowing E3 2012, Oculus VR launched a Kickstarter to fund further development of the Rift, ultimately raising more than $2.4 million through it, one of the largest crowdfunding ventures at that time. The attention led to additional venture funding, with more than $91 million invested by 2013. During this, Carmack left id Software to become the Chief Technology Officer for Oculus VR. In March 2014, Mark Zuckerberg announced that Facebook had acquired Oculus VR for $2 billion.\n\nAround May 2014, shortly after Facebook made its deal to acquire Oculus VR, the \"Wall Street Journal\" reported that ZeniMax had sent two letters to Facebook and Oculus VR, asserting that any technology contributions Carmack had made towards VR while he was still an employee of id Software, including the \"VR testbed\" that Carmack had frequently demonstrated, were within the intellectual property (IP) of id and ZeniMax. In a statement, ZeniMax said that they \"provided necessary VR technology and other valuable assistance to Palmer Luckey and other Oculus employees in 2012 and 2013 to make the Oculus Rift a viable VR product, superior to other VR market offerings.\"\n\nZeniMax stated that a 2012 non-disclosure agreement (NDA) and a non-ownership agreement that covered VR technology and signed by Luckey, prior to Oculus VR's formation, would cover any of Carmack's contributions to VR.\n\nZeniMax contends that they had attempted to resolve these issues with Oculus prior to their acquisition by Facebook \"whereby ZeniMax would be compensated for its intellectual property through equity ownership in Oculus but were unable to reach a satisfactory resolution\". Oculus denied the claims, stating that \"It's unfortunate, but when there's this type of transaction, people come out of the woodwork with ridiculous and absurd claims\".\n\nZeniMax formally filed a lawsuit against Luckey and Oculus VR on May 21, 2014 in the United States District Court for the Northern District of Texas and seeking a jury trial. The lawsuit contended that Luckey and Oculus used ZeniMax's \"trade secrets, copyrighted computer code, and technical know-how relating to virtual reality technology\", as provided by Carmack, to develop the Oculus Rift product, and sought for financial damages for contract breach, copyright infringement, and unfair competition. ZeniMax also charged that Oculus, through Carmack, were able to hire several former ZeniMax/id Software employees who also had technical knowledge of its VR technology, which would allow them to rapidly fine-tune the VR testbed system to create the Rift. In its files, ZeniMax revealed it has \"invested tens of millions of dollars in research and development\" into VR technology, and that because they felt \"Oculus and Luckey lacked the necessary expertise and technical know-how to create a viable virtual reality headset\", they \"sought expertise and know-how from Zenimax\".\n\nOculus initially responded to the charges as \"The lawsuit filed by ZeniMax has no merit whatsoever. As we have previously said, ZeniMax did not contribute to any Oculus technology. Oculus will defend these claims vigorously.\" The company filed its formal response on June 25, 2014, stating that ZeniMax \"falsely claims ownership in Oculus VR technology in a transparent attempt to take advantage of the Oculus VR sale to Facebook\". Oculus stated that prior to the acquisition by Facebook, \"ZeniMax never raised any claim of infringement against Oculus VR, undoubtedly because ZeniMax never has contributed any intellectual property or technology to Oculus VR\".\n\nThe response stated that ZeniMax's filing \"deliberately misstating some facts and omitting others\" and that \"there is not a line of ZeniMax code or any of its technology in any Oculus VR product\". Oculus' response included photographs and documents that demonstrated they had been working on their own VR technology as early as August 2010. The response further contended that the key document of ZeniMax's suit, the NDA signed by Luckey, was \"never finalized\", and thus is not a \"valid and enforceable agreement\".\n\nZeniMax amended the case to include Facebook among the defendants on August 29, 2014. ZeniMax charged that Facebook intended to \"leverage and commercially exploit Oculus’s virtual reality technology — which is built upon ZeniMax’s unlawfully misappropriated intellectual property — for the financial benefit of Facebook’s core business of online social networking and advertising.\"\n\nOculus and Facebook attempted to have the case dismissed, but the presiding judge disagreed, and, in August 2015, allowed the case to proceed to a jury trial expected to start in August 2016.\n\nDuring the discovery phase, ZeniMax had sought a deposition from Zuckerberg, believing he had \"unique knowledge\" of the Facebook-Oculus deal. At request from Facebook, the judge ruled that Zuckerberg must provide a deposition, but only after lesser-ranking employees had been deposed as to have a \"less intrusive discovery\" process.\n\nIn August 2016, it was discovered that ZeniMax had further modified their complaint, specifically adding by name Carmack as Oculus's CTO, and Brendan Iribe as Oculus' CEO. The updated complaint alleged that during his last days at id Software, Carmack \"copied thousands of documents from a computer at ZeniMax to a USB storage device\", and later after his employment was terminated he \"returned to ZeniMax's premises to take a customized tool for developing VR Technology belonging to ZeniMax that itself is part of ZeniMax's VR technology\". ZeniMax's complaint charged that Iribe had directed Oculus to \"[disseminate] to the press the false and fanciful story that Luckey was the brilliant inventor of VR technology who had developed that technology in his parents' garage\", when \"Luckey lacked the training, expertise, resources, or know-how to create commercially viable VR technology\", thus aiding in the IP theft from ZeniMax.\n\nFurther, the updated complaint asserts Facebook had more involvement as it knew or had reason to know that Oculus' claims on the VR IP was false. Oculus responded, \"This complaint filed by ZeniMax is one-sided and conveys only ZeniMax's interpretation of the story. The court had a computer forensic expert evaluate the contents of Carmack's computer, and on October 28, 2016, the expert reported that from their findings \"statements and representations that have been sworn to and are before the court are factually inaccurate\". The court ordered Oculus to comply with providing previously-redacted communications it had with Carmack as a result, as well as requesting Samsung to provide information on its Samsung Gear VR which was co-created with Oculus.\n\nThe jury trial started on January 9, 2017. During the trial, Zuckerberg testified in court that he believed the allegations from ZeniMax Media were false. In the plaintiff's closing arguments, ZeniMax's lawyers believed that they should receive $2 billion in compensation for Oculus' actions, and an additional $4 billion in punitive damages.\n\nThe jury trial completed on February 2, 2017, with the jury finding that Luckey had violated the NDA he had with ZeniMax, and awarding $500 million to ZeniMax. However, the jury found that Oculus, Facebook, Luckey, Iribe, and Carmack did not misappropriate or steal trade secrets, though ZeniMax continued to publicly assert otherwise. Oculus will have to pay $200 million for breaking the non-disclosure agreement, and additional $50 million for copyright infringement; for false designation of origin charges, Oculus and Luckey will have to pay $50 million each, while Iribe will be responsible for $150 million.\n\nWhile Oculus said \"the jury found decisively in our favor\" over the issue of trade secrets, the company plans to file an appeal on the other charges. Carmack stated that he disagreed with the decision, particularly on ZeniMax's \"characterization, misdirection, and selective omissions\" regarding his behavior, adding that he had accounted for all the data in his possession. Carmack took issue with one of ZeniMax's expert witnesses who testified that non-literal copying, the act of creating a program with similar functions but using different computer code, constitutes a copyright violation.\n\nZeniMax stated that it is considering a court-ordered halt to all Oculus Rift units in light of the jury decision; and on February 24, 2017, filed an injunction to have the court halt sales of the Oculus Rift and development kits. Oral arguments for these injunctions were held on June 19, 2017. ZeniMax argued that either Oculus should halt sales of the Rift, or otherwise receive 20% of all Rift sales over the next ten years. Oculus, in addition to its own filings towards a new trial, requested the judge throw out the jury verdict, or reduced the penalty to $50 million. In June 2018, the judge overseeing the case agreed to cut the damages owed by Oculus in half to (with an additional in interest), while denying Zenimax their request to halt Oculus sales.\n\nIn a separate lawsuit filed in March 2017, Carmack asserted that ZeniMax did not complete its payment to him of the acquisition of id Software, and asked the court to find for him for the remaining $22 million he states the company owes him. ZeniMax's lawyers asserted that from the Oculus case, they had not been found in violation of Carmack's employment after ZeniMax acquired id Software and that this new suit was \"without merit\". By October 2018, Carmack stated that he and ZeniMax reached an agreement and that \"Zenimax has fully satisfied their obligations to me\", and this lawsuit was subsequently dropped.\n\nIn May 2017, ZeniMax filed a new lawsuit towards Samsung over the Gear VR. In addition to the previous legal decision over IP issues related to the Oculus technology used in the Gear VR, ZeniMax also contends in the new suit that Carmack had allowed Matt Hooper, who had been recently fired as a creative director from id, into id's facilities after hours without permission to work out an \"attack plan\" for developing mobile VR, which would ultimately lead to the Gear VR device. ZeniMax seeks punitive damages as well as a share of profits from Gear VR.\n"}
