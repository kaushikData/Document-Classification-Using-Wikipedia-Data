{"id": "433607", "url": "https://en.wikipedia.org/wiki?curid=433607", "title": "African socialism", "text": "African socialism\n\nAfrican socialism is a belief in sharing economic resources in a traditional African way, as distinct from classical socialism. Many African politicians of the 1950s and 1960s professed their support for African socialism, although definitions and interpretations of this term varied considerably.\n\nAs many African countries gained independence during the 1960s, some of these newly formed governments rejected the ideas of capitalism in favour of a more afrocentric economic model. Leaders of this period professed that they were practising 'African Socialism'.\n\nJulius Nyerere of Tanzania, Modibo Keita of Mali, Léopold Senghor of Senegal, Kwame Nkrumah of Ghana and Sékou Touré of Guinea, were the main architects of African Socialism according to William H. Friedland and Carl G. Rosberg Jr., editors of the book \"African Socialism\".\n\nCommon principles of various versions of African socialism were: social development guided by a large public sector, incorporating the African identity and what it means to be African, and the avoidance of the development of social classes within society. Senghor claimed that \"Africa’s social background of tribal community life not only makes socialism natural to Africa but excludes the validity of the theory of class struggle,\" thus making African socialism, in all of its variations, different from Marxism and European socialist theory\n\nThe first influential publication of socialist thought for Africa occurred in 1956 with the release of Senegalese intellectual Abdoulaye Ly's \"Les masses africaines et l'actuelle condition humaine\".\n\nThe Concept or politic ideology of Ujamaa formed the basis of Julius Nyerere's autarkic social and economic development policies in Tanzania after Tanganyika gained independence from its colonial power Britain in 1961 and its union with Zanzibar to form Tanzania in 1964. The word Ujamaa comes from the Swahili word for extended family or familyhood and is distinguished by several key characteristics, namely that a person becomes a person through the people or community.\n\nIn 1967, President Nyerere published his development blueprint, which was titled the Arusha Declaration, in which Nyerere pointed out the need for an African model of development. That formed the basis of African socialism for Tanzania. The Arusha Declaration sparked international discussions and debates about African socialism in the academic and economic world.\n\nHowever, according to the BBC, \"while he united his nation and made major advances in the fields of health and education,\" Julius Nyerere's African socialist \"Ujamaa\" collectives \"proved disastrous for Tanzania's economy\".\n\nThe ancient Ubuntu philosophy of South Africa recognizes the humanity of a person through their interpersonal relationships. The word comes from the Zulu and Xhosa languages. Ubuntu believes in a bond that ties together all of humanity and the fact that a human being is of a high value. According to Archbishop Desmond Tutu, A man with ubuntu is open and accessible to others, confirming of others, doesn't feel debilitated that others are capable and great, for he or she has a legitimate confidence that originates from realizing that he or she has a place in a more noteworthy entire and is decreased when others are mortified or reduced, when others are tormented or abused.\n\nHarambee is a term that originated among natives, specifically Swahili porters of East Africa and the word Harambee traditionally means \"let us pull together\". It was taken as an opportunity for local Kenyans to self-develop their communities without waiting on government. This helped build a sense of togetherness in the Kenyan community but analyst state that it has brought about class discrepancies due to the fact that some individuals use this as an opportunity to generate wealth\n\n\nSocialism\", Stanford University press, California, 1964.\n"}
{"id": "2350935", "url": "https://en.wikipedia.org/wiki?curid=2350935", "title": "Alastair Hannay", "text": "Alastair Hannay\n\nRobert Alastair Hannay (born 1932) is Professor emeritus at the University of Oslo. Educated in Edinburgh, where his early interest in philosophy was roused by John Macmurray, and London, where he studied under A. J. Ayer and Bernard Williams. Hannay's book \"The Public\" (2004) brings several Kierkegaardian insights to bear on contemporary political life and examines the roles of the 'public' as audience as well as political participant. Hannay is also a member of a team translating Kierkegaard's complete journals and notebooks.\n\n\n\n\n"}
{"id": "2627607", "url": "https://en.wikipedia.org/wiki?curid=2627607", "title": "Andrew Seth Pringle-Pattison", "text": "Andrew Seth Pringle-Pattison\n\nAndrew Seth, FBA, DCL (1856, Edinburgh – 1931, The Haining, Selkirkshire), who changed his name to Andrew Seth Pringle-Pattison in 1898 to fulfill the terms of a bequest, was a Scottish philosopher. \nHis brother was James Seth, also a philosopher.\n\nTheir father, Smith Kinmont Seth, was the son of a farmer from Fife and a bank clerk in the head office of the Commercial Bank of Scotland. Their mother, Margaret, was the daughter of Andrew Little a farmer from Berwickshire. An elder brother died in infancy.\n\nSeth was educated at High School and the University of Edinburgh. In 1878 he was awarded a Hibbert Travelling Fellowship. He spent two years abroad, chiefly at German universities. On his return in 1880 he was appointed assistant to Professor Campbell Fraser, Professor of Logic and Metaphysics at Edinburgh. He became Balfour Lecturer in Philosophy in 1883. From 1883–87 he was Professor of Logic and Philosophy at the newly created University College of Cardiff. He returned to Scotland in 1887 when he was appointed Professor of Logic, Rhetoric and Metaphysics at St Andrews (1887–91). He was Gifford Lecturer, University of Aberdeen, 1911–13, Hibbert Lecturer (1921) and Gifford Lecturer, University of Edinburgh (1921–23). \n\nPringle-Pattison received the degree Doctor of Civil Law (DCL) \"honoris causa\" from the University of Durham in June 1902.\n\nIn 1884 he married Eva (d. 1928), daughter of Albrecht Stropp. The couple had two daughters and three sons\n\nHe is buried with his wife and family in Morningside Cemetery, Edinburgh against the south wall towards the south-west.\n\nSeth's twin enemies were English Empiricism and the Anglo variant of Hegelianism. According to Seth, both manner of philosophy degraded the independence of the individual. \"Each self,\" he wrote in \"Hegelianism and Personality\", \"is a unique existence, which is perfectly impervious ... to other selves – impervious in a fashion of which the impenetrability of matter is a faint analogue.\" Seth's comments here stand in stark contrast to the British and American Hegelianism of the turn of the 20th century.\n\nSeth was a personal idealist and was critical of Absolute idealism, according to Seth personality should not be merged into the Absolute. Seth's views have also been described as panentheistic.\n\nIt was F. H. Bradley's and Josiah Royce's primary contention that the Self is permeable to all manner of imitation, and that the self as Seth describes is a harmful fiction. At the heart of Seth's analysis was a defence of the necessity of anthropomorphism, John Ruskin's \"pathetic fallacy.\" \"We are anthropomorphic,\" he affirmed, \"and necessarily so, to the inmost fibre of our thinking.\" He continues: \"Every category ... every description of existence or relation, is necessarily a transcript from our own nature and our own experience. Into some of our conceptions we put more, into others less, of ourselves; but all modes of existence and forms of action are necessarily construed by us in terms of our own life. Everything, down to the atom, is constructed upon the scheme of the conscious self, with its multiplicity of states and its central interpenetrating unity. We cannot rid our thought of its inevitable presupposition.\" Personality, the true a priori, stands walled off against external phenomenon either in terms of the Absolute, or from the influx of sensation. Seth's defence of personality had a dramatic effect on later, anti-Hegelian and pluralist, thinkers in the United States in particular. William James, George Santayana, Bertrand Russell and George Herbert Mead, all borrowed his concept of the personality, or psyche, and sought it as a barrier against the claims of Gabriel Tarde, F. H. Bradley, and Josiah Royce.\n\n\nFurther reading\n"}
{"id": "44388778", "url": "https://en.wikipedia.org/wiki?curid=44388778", "title": "Chester M. Southam", "text": "Chester M. Southam\n\nChester Milton Southam (October 4, 1919 – April 5, 2002) was an immunologist and oncologist at Memorial Sloan Kettering Cancer Center and Cornell University Medical College; he went to Thomas Jefferson University in 1971 and worked there until the end of his career.\n\nSoutham earned a bachelor of science degree and a master's degree from University of Idaho and his medical degree from Columbia University, graduating in 1947. He became an intern at Presbyterian Hospital in New York City in 1947. In the following year he was promoted from clinical fellow to attending physician at the Memorial Hospital for Cancer and also received a promotion from research fellow to full member at the Chief Division Virology/Immunology. He joined the faculty of Cornell's medical college in 1951 and was eventually promoted to full professor.\n\nFrom the mid-1950s to the mid-1960s, Southam conducted clinical research on people without their informed consent, in which he injected cancer cells (HeLa cells) into their skin, to see if their immune system would reject the cancer cells or if the cells would grow. He did this to patients under his care or others' care, and to prisoners. In 1963, doctors Avir Kagan, David Leichter and Perry Fersko of Jewish Chronic Disease Hospital objected to the lack of consent in his experiments and reported him to the Regents of the University of the State of New York which found him guilty of fraud, deceit, and unprofessional conduct, and in the end he was placed on probation for a year. Southam's research was conducted in an era when cancer research was closely followed in the mainstream media; his experiments and the case at the Regents were reported in \"The New York Times\".\n\nIn the 1950s, Southam also tested the West Nile Virus as a potential virotherapy; he injected it into over 100 cancer patients who had terminal cancer and few treatment options. This work had some good results and was also reported in \"The New York Times\", but some people he injected got severe cases of West Nile fever; he went on to do further research to see if he could \"train\" the virus to kill cancer without the common side effects of chemotherapy.\n\nSoutham was later elected president of the American Association for Cancer Research. In 1971, Southam left his positions at Memorial Sloan Kettering and Cornell and became an attending physician in the Department of Medicine and Head of the Division of Medical Oncology at Thomas Jefferson University Hospital and a professor of medicine at Thomas Jefferson University Medical College; he held these positions until the end of his career in 1979.\n"}
{"id": "31506035", "url": "https://en.wikipedia.org/wiki?curid=31506035", "title": "Claus Dierksmeier", "text": "Claus Dierksmeier\n\nClaus Dierksmeier (born May 17, 1971 in Pforzheim) is a German philosopher. He holds a Chair for Globalization Ethics at the University of Tübingen and works as a strategic consultant in politics and business. \n\nAfter finishing his dissertation at the University of Hamburg in 1997, Dierksmeier obtained a Dr. phil. habil. degree from the University of Jena in 2002. In 2001 and 2002 he was a visiting scholar at various universities in Spain, Uruguay and Argentina before becoming an Associate Professor at the Institute for Philosophy at Stonehill College, Boston, where he was subsequently a Full Professor and \"Distinguished Professor of Globalization Ethics\" since 2011. In the same year he was appointed as Research Director of the \"Sustainable Management and Measurement Institute (SUMMIT)\" at Stonehill College. From 2012 to 2018 he was the Academic Director of the Weltethos-Institut (Global Ethic Institute) at the University of Tübingen before taking on a Chair for Globalization Ethics at the university's Institute for Political Science.\n\nDierksmeier is a board member of the international think tank \"The Humanistic Management Network\" and Academic Director of the \"Humanistic Management Center\". He is a member of the research group \"Ethics in Action for Sustainable Development\" summoned by Jeffrey Sachs on part of the Sustainable Development Solutions Network and the Pontifical Academy of Sciences and he works on the advisory councils of various academic journals and political foundations. In March 2018 he was appointed as a member of the European Academy of Sciences and Arts. As a strategic consultant he has worked, among other things, for the Bruce Henderson Institute of the Boston Consulting Group.\n\nDierksmeier conducts research on topics of economic and political philosophy as well as globalization ethics. One of his central fields of interest is the concept of \"Humanistic Management\", which he has advanced through various publications. This theory criticizes the 'mechanistic' conception of human behavior in neoclassical economics and advocates for a reorentation towards a 'humanistic' paradigm in management theory and practice.\n\nThe foundation of this humanist approach is his theory of \"Qualitative Freedom\". This theory discards the classical dichotomy between positive and negative freedom in order to retrace the history of the idea of liberty along the distinction between quantitative and qualitative freedom. Quantitative conceptions of freedom, Dierksmeier argues, aim principally at maximizing the number of options available to individuals, whereas qualitative approaches are based on the supposition that certain kinds of freedoms have a higher value than others, resulting in different priorities for different liberties. As the required process of assigning different values to different liberties has to follow a liberal procedure itself, it can yield different outcomes in different societies based on the respective societies' conceptions of freedom, which makes the abstract concept of quantitative freedom compatible with various specific implementations in different cultures around the globe.\n\n\n"}
{"id": "43284588", "url": "https://en.wikipedia.org/wiki?curid=43284588", "title": "Così parlò Bellavista", "text": "Così parlò Bellavista\n\nCosì parlò Bellavista is a 1984 Italian comedy film based on the novel of the same name by Luciano De Crescenzo. De Crescenzo directed the film and also played the main role. For this film De Crescenzo won David di Donatello and Nastro d'Argento for best new director, while Marina Confalone won the same awards in the best supporting actress category.\n\nIn Naples, Professor Bellavista is a retired man, passionate about the philosophy and thought of Ancient Greece. He helds every day, in his luxurious apartment, his lessons of life to the poor-nothing (his friends), who are dazzled by his reasoning. One day, however, the quiet life of the building of Bellavista will be disturbed by the arrival of a director of Milan. Between Naples and Milan there contrast, because the Neapolitans are accustomed to enjoy a quiet life, always based on the \"philosophy of pleasure and delay\", while the northern Italians are very strict and punctual.\n\n"}
{"id": "173905", "url": "https://en.wikipedia.org/wiki?curid=173905", "title": "David Baltimore", "text": "David Baltimore\n\nDavid Baltimore (born March 7, 1938) is an American biologist, university administrator, and 1975 Nobel laureate in Physiology or Medicine. He served as president of the California Institute of Technology (Caltech) from 1997 to 2006, and is currently the President Emeritus and Robert Andrews Millikan Professor of Biology at Caltech. He also served as president of Rockefeller University from 1990 to 1991, and was president of the American Association for the Advancement of Science in 2007. Baltimore has profoundly influenced international science, including key contributions to immunology, virology, cancer research, biotechnology, and recombinant DNA research, through his accomplishments as a researcher, administrator, educator, and public advocate for science and engineering. He has trained many doctoral students and postdoctoral fellows, several of whom have gone on to notable and distinguished research careers. In addition to the Nobel Prize, he has received a number of awards, including the U.S. National Medal of Science in 1999. Baltimore currently sits on the Board of Sponsors for the \"Bulletin of the Atomic Scientists\" and is a consultant to the Science Philanthropy Alliance.\n\nBaltimore was born on March 7, 1938 in New York City to Gertrude (Lipschitz) and Richard Baltimore. Raised in the Queens neighborhoods of Forest Hills and Rego Park, Queens, he moved with his family to suburban Great Neck, New York while he was in second grade because his mother felt that the city schools were inadequate. His father had been raised as an Orthodox Jew and his mother was an atheist, and Baltimore observed Jewish holidays and would attend synagogue with his father through his Bar Mitzvah. He graduated from Great Neck North High School in 1956, and credits his interest in biology to a high-school summer spent at the Jackson Laboratory's Summer Student Program in Bar Harbor, Maine.\n\nBaltimore earned his Bachelor's degree with high honors at Swarthmore College in 1960. He credits his interest in molecular biology to George Streisinger under whose mentorship he worked for one summer at Cold Spring Harbor Laboratory. Baltimore's future promise was evident in his work as a graduate student when he entered MIT's graduate program in biology in 1960 with a brash and brilliant approach to learning science. His early interest in phage genetics quickly yielded to a passion for animal viruses. He took the Cold Spring Harbor course on animal virology in 1961 and he moved to Richard Franklin's lab at the Rockefeller Institute at New York City which was one of the few labs pioneering molecular research on animal virology. There he made fundamental discoveries on virus replication and its effect on cell metabolism, including the first description of an RNA replicase. He completed his PhD thesis work in 1964.\n\nAfter his PhD, Baltimore returned to MIT for postdoctoral research with James Darnell in 1963. He continued his work on virus replication using poliovirus and pursued training in enzymology with Jerard Hurwitz at Albert Einstein College of Medicine in 1964/1965.\n\nIn February, 1965, Baltimore was recruited by Renato Dulbecco to the newly established Salk Institute for Biological Studies in La Jolla as an independent research associate. There he investigated poliovirus RNA replication and began a long and storied career of mentoring other scientists' early careers including Marc Girard, and Michael Jacobson. They discovered the mechanism of proteolytic cleavage of viral polyprotein precursors, pointing to the importance of proteolytic processing in the synthesis of eukaryotic proteins. He also met his future wife, Alice Huang, who began working with Baltimore at Salk in 1967. He and Alice together carried out key experiments on defective interfering particles and viral pseudo types. During this work, he made a key discovery that polio produced its viral proteins as a single large polyprotein that was subsequently processed into individual functional peptides.\n\nIn 1968, he was recruited by Nobel laureate Salvador Luria to the Department of Biology at MIT as an Associate Professor of Microbiology. Alice S. Huang also moved to MIT to continue her research on vesicular stomatitis virus (VSV). They became a couple, and married in October 1968. At MIT, Huang, Baltimore, and graduate student Martha Stampfer discovered that VSV involved an RNA-dependent RNA polymerase within the virus particle, and used a novel replication strategy to replicate its RNA genome. VSV entered a host cell as a single negative strand of RNA, but brought with it RNA polymerase to stimulate the processes of transcription and replication of more RNA.\n\nBaltimore extended this work and examined two RNA tumor viruses, Rauscher murine leukemia virus and Rous sarcoma virus. He went on to discover reverse transcriptase (RTase or RT) - the enzyme that polymerizes DNA from an RNA template. In doing so, he discovered a distinct class of viruses, later name retroviruses, that use an RNA template to catalyze synthesis of viral DNA. This overturned a \"central dogma\" of genetic theory, the belief that genetic information flowed unidirectionally from DNA to RNA (and thence to proteins). Reverse transcriptase is essential for the reproduction of retroviruses, allowing such viruses to turn viral RNA strands into viral DNA strands. The viruses that fall into this category include HIV.\n\nThe discovery of reverse transcriptase, made contemporaneously with Howard Temin, who had proposed the provirus hypothesis, overturned the central dogma of molecular biology by showing that genetic information could traffic bidirectionally between DNA and RNA. They published these findings in back-to-back papers in the prestigious journal, Nature. This discovery was heralded as evidence that molecular and virological approaches to understanding cancer would yield new cures for the dreaded disease. This may have influenced President Richard Nixon's War on Cancer which was launched in 1971 and substantially increased research funding for the disease. In 1972, at the age of 34, Baltimore was awarded tenure as a Professor of Biology at MIT, a post that he held until 1997. In 1975, at the age of 37, Baltimore shared the Nobel Prize for Physiology or Medicine with Howard Temin and Renato Dulbecco. The citation reads, \"for their discoveries concerning the interaction between tumor viruses and the genetic material of the cell.\" At the time, Baltimore's greatest contribution to virology was his discovery of reverse transcriptase.\n\nBaltimore also helped Paul Berg and Maxine Singer to organize the Asilomar Conference on Recombinant DNA, held in February 1975. The conference discussed possible dangers of new biotechnology, drew up voluntary safety guidelines, and issued a call for an ongoing moratorium on certain types of experiments and review of possible experiments. Baltimore was well aware of the importance of the changes occurring in the laboratory: \"The whole Asilomar process opened up to the world that modern biology had new powers that you had never conceived of before.\"\n\nAfter winning the Nobel Prize, Baltimore reorganized his laboratory, refocusing on immunology and virology, with immunoglobulin gene expression as a major area of interest. In 1973, he was awarded a prestigious American Cancer Society Professor of Microbiology that provided substantial salary support. Also in 1973, he became one of the early faculty members in the newly organized MIT Center for Cancer capping a creative and industrious period of his career with nearly fifty research publications including the paradigm-shifting paper on reverse transcriptase. The MIT CRC was led by Salvador E. Luria and quickly achieved pre-eminence with a remarkable group of faculty including Baltimore, Phillips Robbins, Herman Eisen, Philip Sharp, and Robert Weinberg, who all went on to illustrious research careers. Baltimore was honored as a Fellow of the American Academy of Arts and Sciences in 1974. He returned to New York City in 1975, for a year-long sabbatical at Rockefeller University working with Jim Darnell. In 1975, at the age of 37, he shared the Nobel Prize for Physiology or Medicine with Howard Temin and Renato Dulbecco. The citation reads, \"for their discoveries concerning the interaction between tumor viruses and the genetic material of the cell.\" At the time, Baltimore's greatest contribution to virology was his discovery of reverse transcriptase (Rtase or RT) which is essential for the reproduction of retroviruses such as HIV and was discovered independently, and at about the same time, by Mizutani and Temin. Following this, his lab and intellectual interests expanded tackling new problems such as the pathogenesis of Abelson murine leukemia virus (AMuLV), lymphocyte differentiation and related topic in immunology. In 1980, his group isolated the oncogene in AMuLV and showed it was a member of a new class of protein kinases that used the amino acid tyrosine as a phosphoacceptor. This type of enzymatic activity was also discovered by Tony Hunter, who has done extensive work in the area. He also continued to pursue fundamental questions in RNA viruses and in 1981, Baltimore and Vincent Racaniello, a post-doctoral fellow in his laboratory, used recombinant DNA technology to generate a plasmid encoding the genome of poliovirus, an animal RNA virus. The plasmid DNA was introduced into cultured mammalian cells and infectious poliovirus was produced. The infectious clone, DNA encoding the genome of a virus, is a standard tool used today in virology.\n\nIn 1982, with a charitable donation by businessman and philanthropist Edwin C. \"Jack\" Whitehead, Baltimore was asked to help establish a self-governed research institute dedicated to basic biomedical research. They devised a unique structure of an independent research institute composed of \"members\" with a close relationship with the Department of Biology of MIT. The Whitehead Institute for Biomedical Research (WIBR) was launched with $35 million to construct and equip a new building located across the street from the MIT cancer center in Cambridge Massachusetts. The institute also received $5 million per year in guaranteed income and a substantial endowment in his will (for a total gift of $135 million). Under Baltimore's leadership, a distinguished group of founding members including Gerald Fink, Rudolf Jaenisch, Harvey Lodish, and Robert Weinberg was assembled and eventually grew to 20 members in disciplines ranging from immunology, genetics, and oncology to fundamental developmental studies in mice and fruit flies. Whitehead Institute's contributions to bioscience have long been second to none. Less than a decade after its founding with continued leadership by Baltimore, the Whitehead Institute was named the top research institution in the world in molecular biology and genetics, and over a recent 10-year period, papers published by Whitehead scientists were the most cited papers of any biological research institute.\n\nAfter establishing the Institute in a beautiful newly constructed research building across the street from the MIT cancer center, he served as Director of the WIBR serving to expand the faculty and research areas into key areas of research including mouse and drosophila genetics. The Whitehead Institute has been rated as doing \"World leading research in genetics and molecular biology\", and was an important partner in the Human Genome Project.\n\nDuring this time, Baltimore's own research program thrived in the new Institute. Important breakthroughs from Baltimore's lab include the discovery of the key transcription factor NF-κB by Dr. Ranjan Sen and David Baltimore in 1986. Their intention was to identify nuclear factors required for lg gene expression in B lymphocytes. What they discovered, NF-κB, turned out to have much broader importance. NF-κB is involved in regulating cellular responses and belongs to the category of \"rapid-acting\" primary transcription factors. Their discovery led to an \"information explosion\" involving \"one of the most intensely studied signaling paradigms of the last two decades.\"\n\nAs early as 1984, Rudolf Grosschedl and David Weaver, postdoctoral fellows, in Baltimore's laboratory, were experimenting with the creation of transgenic mice as a model for the study of disease. They suggested that \"control of lg gene rearrangement might be the only mechanism that determines the specificity of heavy chain gene expression within the lymphoid cell lineage.\" in 1987, they created transgenic mice with the fused gene that developed fatal leukemia.\n\nDavid G. Schatz and Marjorie Oettinger, as students in Baltimore's research group in 1988 and 1989, identified the protein pair that rearranges immunoglobulin genes, the recombination-activating gene RAG-1 and RAG-2. this was a key discovery in determining how the immune system can have specificity for a given molecule out of many possibilities, and was considered by Baltimore as of 2005 to be \"our most significant discovery in immunology\".\n\nIn 1990, as a student in David Baltimore's laboratory at MIT, George Q. Daley demonstrated that a fusion protein called bcr-abl is sufficient to stimulate cell growth and cause chronic myelogenous leukemia (CML). This work helped to identify a class of proteins that become hyperactive in specific types of cancer cells. It helped to lay the groundwork for a new type of drug, attacking cancer at the genetic level: Brian Druker's development of the anti-cancer drug Imatinib (Gleevec), which deactivates bcr-abl proteins. Gleevec has shown impressive results in treating chronic myelogenous leukemia and also promise in treating gastrointestinal stromal tumor (GIST).\n\nBaltimore served as the Director of the Whitehead Institute until July 1, 1990 when he was appointed the sixth President of Rockefeller University in New York City. He moved his research group to New York and continued to make creative contributions to virology and cellular regulation. He also began important reforms in faculty management and promoted the status of junior faculty at the University. After resigning on December 3, 1991, Baltimore remained on the Rockefeller University faculty and continued research until spring of 1994. He then rejoined the MIT faculty as the Ivan R. Cottrell Professor of Molecular Biology and Immunology.\n\nOn May 13, 1997, Baltimore was appointed president of the California Institute of Technology (Caltech). He began serving in the office 15 October 1997 and was inaugurated 9 March 1998.\n\nDuring Baltimore's tenure at Caltech, United States President Bill Clinton awarded Baltimore the National Medal of Science in 1999 for his numerous contributions to the scientific world. In 2004, Rockefeller University gave Baltimore its highest honor, Doctor of Science (\"honoris causa\").\n\nIn October 2005, Baltimore resigned the office of the president at Caltech (see Luk van Parijs case). Former Georgia Tech Provost Jean-Lou Chameau succeeded Baltimore as president of Caltech. Baltimore remains the Millikan Professor of Biology at Caltech and is an active member of the Institute's community.\n\nHis laboratory at Caltech is focused on two major research areas: understanding the mammalian immune system and creating viral vectors to make the immune system more effective in resisting cancer. Understanding the diverse activity of the NF-κB transcription factor is one focus. NF-κB is now known to activate as many as 1000 genes in response to various stimuli. It is also known to play different roles in different cells.\n\nAnother focus is understanding the functions of microRNA. MicroRNAs provide fine control over gene expression by regulating the amount of protein made by particular messenger RNAs.\nIn recent research led by Jimmy Zhao, Baltimore's team has discovered a small RNA molecule called microRNA-146a (miR-146a) and bred a strain of mice that lacks miR146a. They have used the miR146a(-) mice as a model to study the effects of chronic inflammation on the activity of hematopoietic stem cells (HSCs). Their results suggest that microRNA-146a protects HSCs during chronic inflammation, and that its lack may contribute to blood cancers and bone marrow failure.\n\nBaltimore recently joined with other scientists to call for a worldwide moratorium on use of a new genome-editing technique to alter inheritable human DNA. A key step enabling researchers to slice up any DNA sequence they choose was developed by Emmanuelle Charpentier, then at Umea University in Sweden, and Jennifer A. Doudna of the University of California, Berkeley. Reminiscent of the Asilomar conference on recombinant DNA in 1975, those involved want both scientists and the public to be more aware of the ethical issues and risks involved with new techniques for genome modification.\n\nIn addition to his influence on public policy for recombinant DNA research, Baltimore has influenced national policy concerning the AIDS epidemic. In 1986, he and Sheldon M. Wolff were invited by the National Academy of Sciences and the Institute of Medicine to coauthor an independent report: \"Confronting AIDS\" (1986), in which they called for a $1 billion research program for HIV/AIDS. As of 1996 he was appointed head of the National Institutes of Health (NIH) AIDS Vaccine Research Committee (AVRC).\n\nBaltimore is a member of the National Academy of Sciences USA (NAS), 1974; the American Academy of Arts and Sciences, 1974; the NAS Institute of Medicine (IOM), 1974; the American Association of Immunologists, 1984. He was elected a Foreign Member of the Royal Society (ForMemRS) in 1987; the French Academy of Sciences, 2000; and the American Association for Cancer Research (AACR). He is also a member of the Pontifical Academy of Sciences, 1978. In 2006 Baltimore was elected to a three-year term as president of the American Association for the Advancement of Science (AAAS).\n\nBaltimore is a member of the USA Science and Engineering Festival's Advisory Board and an Xconomist (an editorial advisor for the tech news and media company, Xconomy). Baltimore also serves on The Jackson Laboratory's board of trustees, the Bulletin of the Atomic Scientists' Board of Sponsors, Amgen, Inc.'s board of directors, and numerous other organizations and their boards.\n\nDuring the late 1980s and early 1990s, Thereza Imanishi-Kari, a scientist who was not in Baltimore's laboratory but in a separate, independent laboratory at MIT, was implicated in a case of scientific fraud. The case received extensive news coverage and a Congressional investigation. The case was linked to Baltimore's name because of his scientific collaboration with and later his strong defense of Imanishi-Kari against accusations of fraud.\n\nIn 1986, while a Professor of Biology at MIT and Director at Whitehead, Baltimore co-authored a scientific paper on immunology with Thereza Imanishi-Kari (an Assistant Professor of Biology who had her own laboratory at MIT) as well as four others. A postdoctoral fellow in Imanishi-Kari's laboratory, Margot O'Toole, who was not an author, reported concerns about the paper, ultimately accusing Imanishi-Kari of fabricating data in a cover-up. Baltimore, however, refused to retract the paper.\n\nO'Toole soon dropped her challenge, but the NIH, which had funded the contested paper's research, began investigating, at the insistence of Walter W. Stewart, a self-appointed fraud buster, and Ned Feder, his lab head at the NIH. Representative John Dingell (D-MI) also aggressively pursued it, eventually calling in U.S. Secret Service (USSS; U.S. Treasury) document examiners.\n\nAround October 1989, when Baltimore was appointed president of Rockefeller University, around a third of the faculty opposed his appointment because of concerns about his behaviour in the Imanishi-Kari case. He visited every laboratory, one by one, to hear those concerns directly from each group of researchers.\n\nIn a draft report dated March 14, 1991 and based mainly on USSS forensics findings, NIH's fraud unit, then called the Office of Scientific Integrity (OSI), accused Imanishi-Kari of falsifying and fabricating data. It also criticized Baltimore for failing to embrace O'Toole's challenge. Less than a week later, the report was leaked to the press. Baltimore and three co-authors then retracted the paper; Imanishi-Kari and Moema H. Reis did not sign the retraction. In the report, Baltimore admitted that he was \"too willing to accept\" Imanishi-Kari's explanations, and felt he \"did too little to seek an independent verification of her data and conclusions.\" Baltimore publicly apologized for not taking a whistle-blower's charge seriously.\n\nAmid concerns raised by negative publicity in connection with the scandal, Baltimore resigned as president of Rockefeller University and rejoined the MIT Biology faculty.\n\nIn July 1992, the US Attorney for the District of Maryland, who had been investigating the case, announced he would bring neither criminal nor civil charges against Imanishi-Kari. In October 1994, however, OSI's successor, the Office of Research Integrity (ORI; HHS) found Imanishi-Kari guilty on 19 counts of research misconduct, basing its conclusions largely on Secret Service analysis of laboratory notebooks.\n\nAn HHS appeals panel began meeting in June 1995 to review all charges in detail. In June 1996, the panel ruled that the ORI had failed to prove even one of its 19 charges. After throwing out much of the documentary evidence gathered by the ORI, the panel dismissed all charges against Imanishi-Kari. As their final report stated, the HHS panel \"found that much of what ORI presented was irrelevant, had limited probative value, was internally inconsistent, lacked reliability or foundation, was not credible or not corroborated, or was based on unwarranted assumptions.\" It did conclude that \"The Cell paper as a whole is rife with errors of all sorts ... [including] some which, despite all these years and layers of review, have never previously been pointed out or corrected. Responsibility ... must be shared by all participants.\" Neither OSI nor ORI ever accused Baltimore of research misconduct. The reputations of Stewart and Feder, who had pushed for the investigation, were very damaged.\n\nBaltimore has been both defended and criticized for his actions in this matter. In 1993, Yale University mathematician Serge Lang strongly criticized Baltimore's behavior. Historian of science Daniel Kevles, writing after the exoneration of Imanishi-Kari, recounted the affair in his 1998 book, \"The Baltimore Case\". Horace Freeland Judson also gives a critical assessment of Baltimore's actions in \"\". Baltimore has also written his own analysis.\n\nIn October 2005, Baltimore resigned the office of the president of Caltech, saying, \"This is not a decision that I have made easily, but I am convinced that the interests of the Institute will be best served by a presidential transition at this particular time in its history...\" Soon after, at Baltimore's request, Caltech began investigating the work Luk van Parijs had conducted while a postdoc in Baltimore's laboratory. Van Parijs first came under suspicion at MIT, for work done after he had left Baltimore's lab. After van Parijs had been fired by MIT, his doctoral supervisor also noted problems with work van Parijs did at the Brigham and Women's Hospital, before leaving Harvard to go to Baltimore's lab. Concluding in March 2007, the Caltech investigation found van Parijs alone committed research misconduct and that four papers co-authored by Baltimore, van Parijs, and others required correction.\n\n\nBaltimore was married in 1968 to Dr. Alice S. Huang. They have one daughter.\n\n\n\n \n"}
{"id": "1150164", "url": "https://en.wikipedia.org/wiki?curid=1150164", "title": "Dorothy Edgington", "text": "Dorothy Edgington\n\nDorothy Margaret Doig Edgington FBA (née Milne, born 29 April 1941) is a philosopher active in metaphysics and philosophical logic. She is particularly known for her work on the logic of conditionals and vagueness.\n\nDorothy Edgington was born on 29 April 1941 to Edward Milne and his wife Rhoda née Blair. She attended St Leonards School before going to St Hilda's College, Oxford to read PPE. She obtained her BA in 1964, followed in 1967 by a BPhil at Nuffield College, Oxford. \n\nThe Majority of Edgington's career was spent at Birkbeck College. Her first academic post in 1968, was as Lecturer in Philosophy at Birkbeck and she remained there until 1996. From 1996 until 2001 she was appointed Fellow of University College, Oxford. This was followed by a professorship at Birkbeck from 2001–03. She was then Waynflete Professor of Metaphysical Philosophy at the University of Oxford from 2003 until 2006. She is now Emeritus Professor, and Fellow of Magdalen College, Oxford and teaches at Birkbeck again part-time. \n\nBirkbeck College hosts a lecture series named after Edgington; in 2012, the lectures were given by John McDowell, in 2014 they were given by Rae Langton, and in 2016 the Edgington Lectures were given by Kit Fine.\n\nFrom 2004- 2005 she was President of the Mind Association 2004–5 and she was President of the Aristotelian Society for 2007-8. She is a Fellow of the British Academy.\n\n\n"}
{"id": "30862583", "url": "https://en.wikipedia.org/wiki?curid=30862583", "title": "Eggshell skull", "text": "Eggshell skull\n\nThe eggshell rule (or thin skull rule) is a well-established legal doctrine in common law, used in some tort law systems, with a similar doctrine applicable to criminal law. The rule states that, in a tort case, the unexpected frailty of the injured person is not a valid defense to the seriousness of any injury caused to them.\n\nThis rule holds that a tortfeasor is liable for all consequences resulting from their tortious (usually negligent) activities leading to an injury to another person, even if the victim suffers an unusually high level of damage (e.g. due to a pre-existing vulnerability or medical condition). The eggshell skull rule takes into account the physical, social and economic attributes of the plaintiff which might make them more susceptible to injury. It may also take into account the family and cultural environment. The term implies that if a person had a skull as delicate as that of the shell of an egg, and a tortfeasor who was unaware of the condition injured that person's head, causing the skull unexpectedly to break, the defendant would be held liable for all damages resulting from the wrongful contact, even if the tortfeasor did not intend to cause such a severe injury.\n\nIn criminal law, the general maxim is that the defendant must \"take their victims as they find them\", as echoed in the judgment of Lord Justice Lawton in \"R v. Blaue\" (1975), in which the defendant was held responsible for killing his victim, despite his contention that her refusal of a blood transfusion constituted \"novus actus interveniens\".\n\nThe doctrine is applied in all areas of torts – intentional torts, negligence, and strict liability cases – as well as in criminal law. There is no requirement of physical contact with the victim – if a trespasser's wrongful presence on the victim's property so terrifies the victim that he has a fatal heart attack, the trespasser will be liable for the damages stemming from his original tort. The foundation for this rule is based primarily on policy grounds. The courts do not want the defendant or accused to rely on the victim's own vulnerability to avoid liability.\n\nThe thin skull rule is not to be confused with the related crumbling skull rule in which the plaintiff suffers from a detrimental position (from a prior injury, for instance) pre-existent to the occurrence of the present tort. In the \"crumbling skull\" rule, the prior condition is only to be considered with respect to distinguishing it from any new injury arising from the present tort – as a means of apportioning damages in such a way that the defendant would not be liable for placing the plaintiff in a better position than they were in prior to the present tort.\n\nIn an example, a person who has Osteogenesis Imperfecta (OI; also known as \"Brittle Bone Syndrome\") is more likely to be injured in a motor vehicle accident. If the person with OI is hit from behind in a motor vehicle collision and suffers medical damages (such as clavicle fracture), it would not be a prudent defense to state that the Osteogenesis Imperfecta was the cause of the fracture.\n\n(UK) In the case of \"Smith v Leech Brain & Co\", an employee in a factory was splashed with molten metal. The metal burned him on his lip, which happened to be premalignant tissue. He died three years later from cancer triggered by the injury. The judge held that as long as the initial injury was foreseeable, the defendant was liable for all the harm.\n\n(US) In 1891, the Wisconsin Supreme Court came to a similar result in \"Vosburg v. Putney\". In that case, a boy threw a small kick at another from across the aisle in the classroom. It turned out that the victim had an unknown microbial condition that was irritated, and resulted in him entirely losing the use of his leg. No one could have predicted the level of injury. Nevertheless, the court found that the kicking was unlawful because it violated the \"order and decorum of the classroom\", and the perpetrator was therefore fully liable for the injury.\n\n(US) In \"Benn v. Thomas\", the appellate court determined that the eggshell rule should have been applied to a case in which a man had a heart attack and died after being bruised in the chest during a rear-end car accident.\n\n(Aus) In the case of \"Nader v Urban Transit Authority of NSW\", the plaintiff was a 10 year old boy who struck his head on a bus stop pole while alighting from a slowly moving bus. He developed a rare psychological condition known as Ganser Syndrome. The defendant argued that the illness resulted from his family’s response to the accident. McHugh JA said (at 537), \"The defendant must take the plaintiff with all his weaknesses, beliefs and reactions as well as his capacities and attributes, physical, social and economic. If the result of an accident is that a ten year old boy reacts to his parents’ concern over his injuries and develops an hysterical condition, no reason of justice, morality or entrenched principle appears to me to prevent his recovery of compensation.\"\n\n(Aus) In the case of \"Kavanagh v Akhtar\", the court held the tortfeasor should take into account the plaintiff's family and cultural setting. Equality before the law puts a heavy onus on the person who would argue that the \"unusual\" reaction of an injured plaintiff should be disregarded because a minority religious or cultural situation may not have been foreseeable.\n\nIntervening cause is typically an exception to the eggshell skull rule. If an injury is not immediate, but a separate situation agitates the injury (such as the injured party being involved in a vehicular collision while being taken to a hospital), the tortfeasor is not liable under common law in Australia (see \"Haber v Walker\", and \"Mahoney v Kruschich Demolitions\"). In \"Haber v Walker\" it was held that a plaintiff will not be liable for a novus actus interveniens (intervening act) if the chain of causation was broken by a voluntary, human act or, an independent event, which in conjunction with the wrongful act, was so unlikely as to be termed a coincidence. In \"Mahoney v Kruschich Demolitions\" the plaintiff, Glogovic, was injured while working on the demolition of a power house for the respondent. While being treated for his injuries, his injuries were exacerbated by the negligent medical treatment of the appellant, Mahony. It was held that there was no novus actus as a result of medical treatment of injuries caused by the defendant’s negligence, unless such treatment is inexcusably bad or completely outside the bounds of what a reputable medical practitioner might prescribe.\n"}
{"id": "44950364", "url": "https://en.wikipedia.org/wiki?curid=44950364", "title": "Ensoji il Cerchio", "text": "Ensoji il Cerchio\n\nThe zen monastery Enso-ji Il Cerchio (Japanese: 円相寺, \"Ensō-ji\"; eng.: \"Temple of the Circle\") refers to a buddhist community and a cultural association recognised by the Italian Government, according to Soto Zen Buddhism, founded by the Italian Zen Master Carlo Zendo Tetsugen Serra (1953-), He was disciple of the Japanese Zen Master Ban Tetsugyu Soin (伴鐵牛, 1910-1996), between the late 1980s and the early 1990s. Later, he would be recognised as Zen Master in his lineage by his direct heir, the current abbot of Tosho-ji (東照寺), Tetsujyo Deguchi.\n\"Il Cerchio Enso-ji\" is also member of the Italian Buddhist Union (UBI), that collects in a federation the principal buddhist centers in Italy and of European Buddhist Union (EBU).\n\n\"Il Cerchio\" is a creation of the \"Sangha della Foresta di Bambù\" (literally: Sangha of the bamboo forest) and, inside a Zen Soto lineage, follows the teachings of Harada Daiun Sogaku (原田祖岳, 1871-1961).\nThe school of Harada Daiun Sogaku distinguishes itself from the usual Soto traditional methods, based exclusively on the practice of sitting meditation, \"zazen\" (坐禅) known as \"shikantaza\" (只管打坐, \"simply sitting\"). The peculiarity of the School of Daiun Sogaku was the adoptation of frequent and intense use of \"kōans\", questions or paradoxical sentences with the purpose to let go a severe rational approach to the practice, helping practitioners to obtain the kensho. Koans are still peculiar today of Rinzai and Obaku traditions.\n\nThe \"sangha\" of \"Il Cerchio\" is located in two places: the Monastery \"Ensoji – il Cerchio\", founded in Milan, in 1988, and the Monastery \"Sanbo-ji – Tempio dei Tre Gioielli,\" (三寶寺), founded 1996 nearly Berceto, Parma.\n\n\n"}
{"id": "35496566", "url": "https://en.wikipedia.org/wiki?curid=35496566", "title": "Formula Comitis Archiatrorum", "text": "Formula Comitis Archiatrorum\n\nFormula Comitis Archiatrorum is the earliest known code of medical ethics. It was written in the 5th century, during the reign of the Ostrogothic king Theodoric, and is preserved in the works of Cassiodorus. It demands from physicians that they widen and deepen their knowledge and enacts the consultation with other physicians.\n"}
{"id": "3060983", "url": "https://en.wikipedia.org/wiki?curid=3060983", "title": "Francisco Romero (philosopher)", "text": "Francisco Romero (philosopher)\n\nFrancisco Romero (1891–1962) was a Latin American philosopher who spearheaded a reaction against positivism.\n\nRomero was born in Seville, Spain, but spent much of his adult life in Latin America, especially Argentina, where he emigrated in 1904. He entered the Argentine army in 1910 and retired with the rank of major in 1931. He became a friend of the Argentine philosopher Alejandro Korn, and when he left military service he took over Korn's professorships at the universities of La Plata and Buenos Aires. Due to his strong disapproval of the Peronist government, he resigned his university positions in 1946, not returning until 1955. \n\nRomero began to publish on literary subjects during the First World War. Known as the \"dean of Ibero-American philosophers,\" he became an influential critic, philosopher, and translator. Romero is interested in examining the space of human culture, especially with respect to creativity and social responsibility. A strongly anti-ideological humanist, he argues against Humean rationalism and all deterministic conceptions of the universe. True being is identified by Romero with transcendence, spiritual and moral aspiration, and intentionality. His writing is marked by a balance between philosophical rigor and literary sophistication, and \"Theory of Man\" (1952; English translation in 1964) is considered his master work.\n\nRomero was also editor in charge of philosophical publications at the Losada publishing house. \n\nHe died in Buenos Aires in 1962.\n\n\n"}
{"id": "5250937", "url": "https://en.wikipedia.org/wiki?curid=5250937", "title": "Freedom in the World", "text": "Freedom in the World\n\nFreedom in the World is a yearly survey and report by the U.S.-based non-governmental organization Freedom House that measures the degree of civil liberties and political rights in every nation and significant related and disputed territories around the world.\n\n\"Freedom in the World\" was launched in 1973 by Raymond Gastil. It produces annual scores representing the levels of political rights and civil liberties in each state and territory, on a scale from 1 (most free) to 7 (least free). Depending on the ratings, the nations are then classified as \"Free\", \"Part(ial)ly Free\", or \"Not Free\". The report is often used by researchers in order to measure democracy and correlates highly with several other measures of democracy such as the Polity data series.\n\nThe Freedom House rankings are widely reported in the media and used as sources by political researchers. Their construction and use has been evaluated by critics and supporters.\n\nThe rankings below are from the \"Freedom in the World\" 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017 and 2018 surveys, each reflecting findings covering the previous year. Each pair of political rights and civil liberties ratings is averaged to determine an overall status of \"Free\" (1.0–2.5), \"Part(ial)ly Free\" (3.0–5.0), or \"Not Free\" (5.5–7.0).\n\nAn asterisk (*) indicates countries which are \"electoral democracies\". To qualify as an \"electoral democracy\", a state must have satisfied the following criteria:\n\n\nAn electoral democracy must have a score of 7 or more out of 12 in political rights subcategory A (Electoral Progress), an overall aggregate score of 20 in their political rights rating and an overall aggregate score of 30 in their civil liberties rating.\n\nFreedom House's term \"electoral democracy\" differs from \"liberal democracy\" in that the latter also implies the presence of a substantial array of civil liberties. In the survey, all Free countries qualify as both electoral and liberal democracies. By contrast, some Partly Free countries qualify as electoral, but not liberal, democracies.\n\nNote: The Middle East countries of Turkey, Cyprus, Georgia, Azerbaijan and Armenia can be found in the \"Europe\" and \"Eurasia\" sections of Freedom House's \"Freedom in the World\" report.\n\nAccording to Freedom House, a quarter of all declines of freedom in the world in 2016 took place in Europe.\n\nPercentage of countries in each category, from the 1973 through 2014 reports:\n\nSources: Country Status and ratings overview 1973–2016, Number and percentages of electoral democracies 1989–2016, \"Freedom in the World 2018\" report covering 2017.\n\nNotes:\n\nThere is some debate over the neutrality of Freedom House and the methodology used for the \"Freedom in the World\" report, which has been written by Raymond D. Gastil and his colleagues. The neutrality and biases of human-rights indices have been discussed in several publications by Kenneth A. Bollen. Bollen wrote that \"Considered together these criticisms suggest that some nations may have been incorrectly rated on Gastil's measures. However, none of the criticisms have demonstrated a systematic bias in all the ratings. Most of the evidence consists of anecdotal evidence of relatively few cases. Whether there is a systematic or sporadic slant in Gastil's ratings is an open question\" (Bollen, 1986, p. 586). The freedom index of \"Freedom in the World\" has a very strong and positive (at least an 80%) correlation with three other democracy-indices studied in Mainwaring (2001, p. 53).\n\nIn his 1986 study, Bollen discussed reviews of measurements of human rights, including the index reported in \"Freedom in the World\" (Bollen, 1986, p. 585). Criticisms of \"Freedom in the World\" during the 1980s were discussed by Gastil (1990), who stated that \"generally such criticism is based on opinions about Freedom House rather than detailed examination of survey ratings\", a conclusion disputed by Giannone. The definition of Freedom in Gastil (1982) and Freedom House (1990) emphasized liberties rather than the exercise of freedom, according to Adam Przeworski, who gave the following example: In the United States, citizens are free to form political parties and to vote, yet even in presidential elections only half of U.S. \"citizens\" vote; in the U.S., \"the same two parties speak in a commercially sponsored unison\", wrote .\n\nMore recent charges of ideological bias prompted Freedom House to issue this 2010 statement:\nFreedom House does not maintain a culture-bound view of freedom. The methodology of the survey is grounded in basic standards of political rights and civil liberties, derived in large measure from relevant portions of the Universal Declaration of Human Rights. These standards apply to all countries and territories, irrespective of geographical location, ethnic or religious composition, or level of economic development.\nMainwaring et alia (2001, p. 52) wrote that Freedom House's index had \"two systematic biases: scores for leftist were tainted by political considerations, and changes in scores are sometimes driven by changes in their criteria rather than changes in real conditions.\" Nonetheless, when evaluated in Latin American countries yearly, Freedom House's index was very strongly and positively correlated with the index of Adam Przeworski and with the index of the authors themselves: They evaluated Pearson's coefficient of linear correlation between their index and Freedom House's index, which was 0.82; among these indices and the two others studied, the correlations were all between 0.80 and 0.86 (Mainwaring et alia, 2001, p. 53).\n\nAs previously quoted, Bollen criticized previous studies of \"Freedom in the World\" as anecdotal and inconclusive; they raised issues needing further study by scientific methods rather than anecdotes. Bollen studied the question of ideological bias using multivariate statistics. Using their factor-analytic model for human-rights measurements, Bollen and Paxton estimate that Gastil's method produces a bias of -0.38 standard deviations (s.d.) against Marxist–Leninist countries and a larger bias, +0.5 s.d., favoring Christian countries; similar results held for the methodology of Sussman (Bollen and Paxton, 2000, p. 585). In contrast, another method by a critic of \"Freedom in the World\" produced a bias for Leftist countries during the 1980s of at least +0.8 s.d., a bias that is \"consistent with the general finding that political scientists are more favorable to leftist politics than is the general population\" (Bollen and Paxton, p. 585).\n\nCriticisms of the reception and uses of the \"Freedom in the World\" report have been noted by Diego Giannone:\n\nIn \"Political and ideological aspects in the measurement of democracy: the Freedom House case\" (2010) which reviewed changes to the methodology since 1990, Diego Giannone concluded that \"because of the changes in methodology over time and the strict interconnection between methodological and political aspects, the FH data do not offer an unbroken and politically neutral time series, such that they should not be used for cross-time analyses even for the development of first hypotheses. The internal consistency of the data series is open to question.\"\n\nOn this topic, the Freedom House website replies that they have \"made a number of modest methodological changes to adapt to evolving ideas about political rights and civil liberties. At the same time, the time series data are not revised retroactively, and any changes to the methodology are introduced incrementally in order to ensure the comparability of the ratings from year to year.\"\n\n\n\n"}
{"id": "192355", "url": "https://en.wikipedia.org/wiki?curid=192355", "title": "Functionalism (philosophy of mind)", "text": "Functionalism (philosophy of mind)\n\nFunctionalism is a view in the theory of the mind. It states that mental states (beliefs, desires, being in pain, etc.) are constituted solely by their functional role – that is, they have causal relations to other mental states, numerous sensory inputs, and behavioral outputs. Functionalism developed largely as an alternative to the identity theory of mind and behaviorism.\n\nFunctionalism is a theoretical level between the physical implementation and behavioral output. Therefore, it is different from its predecessors of Cartesian dualism (advocating independent mental and physical substances) and Skinnerian behaviorism and physicalism (declaring only physical substances) because it is only concerned with the effective functions of the brain, through its organization or its \"software programs\".\n\nSince mental states are identified by a functional role, they are said to be realized on multiple levels; in other words, they are able to be manifested in various systems, even perhaps computers, so long as the system performs the appropriate functions. While computers are physical devices with electronic substrate that perform computations on inputs to give outputs, so brains are physical devices with neural substrate that perform computations on inputs which produce behaviors.\n\nAn important part of some accounts of functionalism is the idea of multiple realizability. Since, according to standard functionalist theories, mental states are the corresponding functional role, mental states can be sufficiently explained without taking into account the underlying physical medium (e.g. the brain, neurons, etc.) that realizes such states; one need only take into account the higher-level functions in the cognitive system. Since mental states are not limited to a particular medium, they can be realized in multiple ways, including, theoretically, within non-biological systems, such as computers. In other words, a silicon-based machine could, in principle, have the same sort of mental life that a human being has, provided that its cognitive system realized the proper functional roles. Thus, mental states are individuated much like a valve; a valve can be made of plastic or metal or whatever material, as long as it performs the proper function (say, controlling the flow of liquid through a tube by blocking and unblocking its pathway).\n\nHowever, there have been some functionalist theories that combine with the identity theory of mind, which deny multiple realizability. Such \"Functional Specification Theories\" (FSTs) (Levin, § 3.4), as they are called, were most notably developed by David Lewis and David Malet Armstrong. According to FSTs, mental states are the particular \"realizers\" of the functional role, not the functional role itself. The mental state of belief, for example, just is whatever brain or neurological process that realizes the appropriate belief function. Thus, unlike standard versions of functionalism (often called \"Functional State Identity Theories\"), FSTs do not allow for the multiple realizability of mental states, because the fact that mental states are realized by brain states is essential. What often drives this view is the belief that if we were to encounter an alien race with a cognitive system composed of significantly different material from humans' (e.g., silicon-based) but performed the same functions as human mental states (e.g., they tend to yell \"Yowzass!\" when poked with sharp objects, etc.) then we would say that their type of mental state is perhaps similar to ours, but too different to say it's the same. For some, this may be a disadvantage to FSTs. Indeed, one of Hilary Putnam's arguments for his version of functionalism relied on the intuition that such alien creatures would have the same mental states as humans do, and that the multiple realizability of standard functionalism makes it a better theory of mind.\n\nThe broad position of \"functionalism\" can be articulated in many different varieties. The first formulation of a functionalist theory of mind was put forth by Hilary Putnam in the 1960s. This formulation, which is now called machine-state functionalism, or just machine functionalism, was inspired by the analogies which Putnam and others noted between the mind and the theoretical \"machines\" or computers capable of computing any given algorithm which were developed by Alan Turing (called Turing machines). It should be noted that Putnam himself, by the mid-1970s, had begun questioning this position. The beginning of his opposition to machine-state functionalism can be read about in his Twin Earth thought experiment.\n\nIn non-technical terms, a Turing machine is not a physical object, but rather an abstract machine built upon a mathematical model. Typically, a Turing Machine has a horizontal tape divided into rectangular cells arranged from left to right. The tape itself is infinite in length, and each cell may contain a symbol. The symbols used for any given \"machine\" can vary. The machine has a \"read-write head\" that scans cells and moves in left and right directions. The action of the machine is determined by the symbol in the cell being scanned and a table of transition rules that serve as the machine's programming. Because of the infinite tape, a traditional Turing Machine has an infinite amount of time to compute any particular function or any number of functions. In the below example, each cell is either blank (\"B\") or has a \"1\" written on it. These are the inputs to the machine. The possible outputs are:\n\n\nAn extremely simple example of a Turing machine which\nwrites out the sequence '111' after scanning three blank squares and then stops as specified by the following machine table:\n\nThis table states that if the machine is in state one and scans a blank square (\"B\"), it will print a \"1\" and remain in state one. If it is in state one and reads a \"1\", it will move one square to the right and also go into state two. If it is in state two and reads a \"B\", it will print a \"1\" and stay in state two. If it is in state two and reads a \"1\", it will move one square to the right and go into state three. If it is in state three and reads a \"B\", it prints a \"1\" and remains in state three. Finally, if it is in state three and reads a \"1\", then it will stay in state three.\n\nThe essential point to consider here is the \"nature of the states\" of the Turing machine. Each state can be defined exclusively in terms of its relations to the other states as well as inputs and outputs. State one, for example, is simply the state in which the machine, if it reads a \"B\", writes a \"1\" and stays in that state, and in which, if it reads a \"1\", it moves one square to the right and goes into a different state. This is the functional definition of state one; it is its causal role in the overall system. The details of how it accomplishes what it accomplishes and of its material constitution are completely irrelevant. \n\nThe above point is critical to an understanding of machine-state functionalism. Since Turing machines are not required to be physical systems, \"anything capable of going through a succession of states in time can be a Turing machine\". Because biological organisms “go through a succession of states in time”, any such organisms could also be equivalent to Turing machines. \n\nAccording to machine-state functionalism, the nature of a mental state is just like the nature of the Turing machine states described above. If one can show the rational functioning and computing skills of these machines to be comparable to the rational functioning and computing skills of human beings, it follows that Turing machine behavior closely resembles that of human beings. Therefore, it is not a particular physical-chemical composition responsible for the particular machine or mental state, it is the programming rules which produce the effects that are responsible. To put it another way, any rational preference is due to the rules being followed, not to the specific material composition of the agent.\n\nA second form of functionalism is based on the rejection of behaviorist theories in psychology and their replacement with empirical cognitive models of the mind. This view is most closely associated with Jerry Fodor and Zenon Pylyshyn and has been labeled psycho-functionalism.\n\nThe fundamental idea of psycho-functionalism is that psychology is an irreducibly complex science and that the terms that we use to describe the entities and properties of the mind in our best psychological theories cannot be redefined in terms of simple behavioral dispositions, and further, that such a redefinition would not be desirable or salient were it achievable. Psychofunctionalists view psychology as employing the same sorts of irreducibly teleological or purposive explanations as the biological sciences. Thus, for example, the function or role of the heart is to pump blood, that of the kidney is to filter it and to maintain certain chemical balances and so on—this is what accounts for the purposes of scientific explanation and taxonomy. There may be an infinite variety of physical realizations for all of the mechanisms, but what is important is only their role in the overall biological theory. In an analogous manner, the role of mental states, such as belief and desire, is determined by the functional or causal role that is designated for them within our best \"scientific\" psychological theory. If some mental state which is postulated by folk psychology (e.g. hysteria) is determined not to have any fundamental role in cognitive psychological explanation, then that particular state may be considered not to exist .\nOn the other hand, if it turns out that there are states which theoretical cognitive psychology posits as necessary for explanation of human behavior but which are not foreseen by ordinary folk psychological language, then these entities or states exist.\n\nA third form of functionalism is concerned with the meanings of theoretical terms in general. This view is most closely associated with David Lewis and is often referred to as analytic functionalism or conceptual functionalism. The basic idea of analytic functionalism is that theoretical terms are implicitly defined by the theories in whose formulation they occur and not by intrinsic properties of the phonemes they comprise. In the case of ordinary language terms, such as \"belief\", \"desire\", or \"hunger\", the idea is that such terms get their meanings from our common-sense \"folk psychological\" theories about them, but that such conceptualizations are not sufficient to withstand the rigor imposed by materialistic theories of reality and causality. Such terms are subject to conceptual analyses which take something like the following form:\n\nFor example, the state of pain is \"caused\" by sitting on a tack and \"causes\" loud cries, and higher order mental states of anger and resentment directed at the careless person who left a tack lying around. These sorts of functional definitions in terms of causal roles are claimed to be \"analytic\" and \"a priori\" truths about the submental states and the (largely fictitious) propositional attitudes they describe. Hence, its proponents are known as \"analytic\" or \"conceptual\" functionalists. The essential difference between analytic and psychofunctionalism is that the latter emphasizes the importance of laboratory observation and experimentation in the determination of which mental state terms and concepts are genuine and which functional identifications may be considered to be genuinely contingent and \"a posteriori\" identities. The former, on the other hand, claims that such identities are necessary and not subject to empirical scientific investigation.\n\nHomuncular functionalism was developed largely by Daniel Dennett and has been advocated by William Lycan. It arose in response to the challenges that Ned Block's China Brain (a.k.a. Chinese nation) and John Searle's Chinese room thought experiments presented for the more traditional forms of functionalism (see below under \"Criticism\"). In attempting to overcome the conceptual difficulties that arose from the idea of a nation full of Chinese people wired together, each person working as a single neuron to produce in the wired-together whole the functional mental states of an individual mind, many functionalists simply bit the bullet, so to speak, and argued that such a Chinese nation would indeed possess all of the qualitative and intentional properties of a mind; i.e. it would become a sort of systemic or collective mind with propositional attitudes and other mental characteristics. Whatever the worth of this latter hypothesis, it was immediately objected that it entailed an unacceptable sort of mind-mind supervenience: the \"systemic\" mind which somehow emerged at the higher-level must necessarily supervene on the individual minds of each individual member of the Chinese nation, to stick to Block's formulation. But this would seem to put into serious doubt, if not directly contradict, the fundamental idea of the supervenience thesis: there can be no change in the mental realm without some change in the underlying physical substratum. This can be easily seen if we label the set of mental facts that occur at the higher-level \"M1\" and the set of mental facts that occur at the lower-level \"M2\". Given the transitivity of supervenience, if \"M1\" supervenes on \"M2\", and \"M2\" supervenes on \"P\" (physical base), then \"M1\" and \"M2\" both supervene on \"P\", even though they are (allegedly) totally different sets of mental facts.\n\nSince mind-mind supervenience seemed to have become acceptable in functionalist circles, it seemed to some that the only way to resolve the puzzle was to postulate the existence of an entire hierarchical series of mind levels (analogous to homunculi) which became less and less sophisticated in terms of functional organization and physical composition all the way down to the level of the physico-mechanical neuron or group of neurons. The homunculi at each level, on this view, have authentic mental properties but become simpler and less intelligent as one works one's way down the hierarchy.\n\nMechanistic functionalism, originally formulated and defended by Gualtiero Piccinini and Carl Gillett independently, augments previous functionalist accounts of mental states by maintaining that any psychological explanation must be rendered in mechanistic terms. That is, instead of mental states receiving a purely functional explanation in terms of their relations to other mental states, like those listed above, functions are seen as playing only a part—the other part being played by structures— of the explanation of a given mental state.\nA mechanistic explanation involves decomposing a given system, in this case a mental system, into its component physical parts, their activities or functions, and their combined organizational relations. On this account the mind remains a functional system, but one that is understood mechanistically. This account remains a sort of functionalism because functional relations are still essential to mental states, but it is mechanistic because the functional relations are always manifestations of concrete structures—albeit structures understood at a certain level of abstraction. Functions are individuated and explained either in terms of the contributions they make to the given system or in teleological terms. If the functions are understood in teleological terms, then they may be characterized either etiologically or non-etiologically. \nMechanistic functionalism leads functionalism away from the traditional functionalist autonomy of psychology from neuroscience and towards integrating psychology and neuroscience. By providing an applicable framework for merging traditional psychological models with neurological data, mechanistic functionalism may be understood as reconciling the functionalist theory of mind with neurological accounts of how the brain actually works. This is due to the fact that mechanistic explanations of function attempt to provide an account of how functional states (mental states) are physically realized through neurological mechanisms.\n\nThere is much confusion about the sort of relationship that is claimed to exist (or not exist) between the general thesis of functionalism and physicalism. It has often been claimed that functionalism somehow \"disproves\" or falsifies physicalism \"tout court\" (i.e. without further explanation or description). On the other hand, most philosophers of mind who are functionalists claim to be physicalists—indeed, some of them, such as David Lewis, have claimed to be strict reductionist-type physicalists.\n\nFunctionalism is fundamentally what Ned Block has called a broadly metaphysical thesis as opposed to a narrowly ontological one. That is, functionalism is not so much concerned with \"what there is\" than with what it is that characterizes a certain type of mental state, e.g. pain, as the type of state that it is. Previous attempts to answer the mind-body problem have all tried to resolve it by answering \"both\" questions: dualism says there are two substances and that mental states are characterized by their immateriality; behaviorism claimed that there was one substance and that mental states were behavioral disposition; physicalism asserted the existence of just one substance and characterized the mental states as physical states (as in \"pain = C-fiber firings\").\n\nOn this understanding, type physicalism can be seen as incompatible with functionalism, since it claims that what characterizes mental states (e.g. pain) is that they are physical in nature, while functionalism says that what characterizes pain is its functional/causal role and its relationship with yelling \"ouch\", etc. However, any weaker sort of physicalism which makes the simple ontological claim that everything that exists is made up of physical matter is perfectly compatible with functionalism. Moreover, most functionalists who are physicalists require that the properties that are quantified over in functional definitions be physical properties. Hence, they \"are\" physicalists, even though the general thesis of functionalism itself does not commit them to being so.\n\nIn the case of David Lewis, there is a distinction in the concepts of \"having pain\" (a rigid designator true of the same things in all possible worlds) and just \"pain\" (a non-rigid designator). Pain, for Lewis, stands for something like the definite description \"the state with the causal role x\". The referent of the description in humans is a type of brain state to be determined by science. The referent among silicon-based life forms is something else. The referent of the description among angels is some immaterial, non-physical state. For Lewis, therefore, \"local\" type-physical reductions are possible and compatible with conceptual functionalism. (See also Lewis's mad pain and Martian pain.) There seems to be some confusion between types and tokens that needs to be cleared up in the functionalist analysis.\n\nNed Block argues against the functionalist proposal of multiple realizability, where hardware implementation is irrelevant because only the functional level is important. The \"China brain\" or \"Chinese nation\" thought experiment involves supposing that the entire nation of China systematically organizes itself to operate just like a brain, with each individual acting as a neuron. (The tremendous difference in speed of operation of each unit is not addressed.). According to functionalism, so long as the people are performing the proper functional roles, with the proper causal relations between inputs and outputs, the system will be a real mind, with mental states, consciousness, and so on. However, Block argues, this is patently absurd, so there must be something wrong with the thesis of functionalism since it would allow this to be a legitimate description of a mind.\n\nSome functionalists believe China would have qualia but that due to the size it is impossible to imagine China being conscious. Indeed, it may be the case that we are constrained by our theory of mind and will never be able to understand what Chinese-nation consciousness is like. Therefore, if functionalism is true either qualia will exist across all hardware or will not exist at all but are illusory.\n\nThe Chinese room argument by John Searle is a direct attack on the claim that thought can be represented as a set of functions. The thought experiment asserts that it is possible to mimic intelligent action without any interpretation or understanding through the use of a purely functional system. In short, Searle describes a person who only speaks English who is in a room with only Chinese symbols in baskets and a rule book in English for moving the symbols around. The person is then ordered by people outside of the room to follow the rule book for sending certain symbols out of the room when given certain symbols. Further suppose that the people outside of the room are Chinese speakers and are communicating with the person inside via the Chinese symbols. According to Searle, it would be absurd to claim that the English speaker inside knows Chinese simply based on these syntactic processes. This thought experiment attempts to show that systems which operate merely on syntactic processes (inputs and outputs, based on algorithms) cannot realize any semantics (meaning) or intentionality (aboutness). Thus, Searle attacks the idea that thought can be equated with following a set of syntactic rules; that is, functionalism is an insufficient theory of the mind.\n\nAs noted above, in connection with Block's Chinese nation, many functionalists responded to Searle's thought experiment by suggesting that there was a form of mental activity going on at a higher level than the man in the Chinese room could comprehend (the so-called \"system reply\"); that is, the system does know Chinese. Of course, Searle responds that there is nothing more than syntax going on at the higher-level as well, so this reply is subject to the same initial problems. Furthermore, Searle suggests the man in the room could simply memorize the rules and symbol relations. Again, though he would convincingly mimic communication, he would be aware only of the symbols and rules, not of the meaning behind them.\n\nAnother main criticism of functionalism is the inverted spectrum or inverted qualia scenario, most specifically proposed as an objection to functionalism by Ned Block. This thought experiment involves supposing that there is a person, call her Jane, that is born with a condition which makes her see the opposite spectrum of light that is normally perceived. Unlike normal people, Jane sees the color violet as yellow, orange as blue, and so forth. So, suppose, for example, that you and Jane are looking at the same orange. While you perceive the fruit as colored orange, Jane sees it as colored blue. However, when asked what color the piece of fruit is, both you and Jane will report \"orange\". In fact, one can see that all of your behavioral as well as functional relations to colors will be the same. Jane will, for example, properly obey traffic signs just as any other person would, even though this involves the color perception. Therefore, the argument goes, since there can be two people who are functionally identical, yet have different mental states (differing in their qualitative or phenomenological aspects), functionalism is not robust enough to explain individual differences in qualia.\n\nDavid Chalmers tries to show that even though mental content cannot be fully accounted for in functional terms, there is nevertheless a \"nomological correlation\" between mental states and functional states in this world. A silicon-based robot, for example, whose functional profile matched our own, would \"have\" to be fully conscious. His argument for this claim takes the form of a \"reductio ad absurdum\". The general idea is that since it would be very unlikely for a conscious human being to experience a change in its qualia which it utterly fails to notice, mental content and functional profile appear to be inextricably bound together, at least in the human case. If the subject's qualia were to change, we would expect the subject to notice, and therefore his functional profile to follow suit. A similar argument is applied to the notion of \"absent\" qualia. In this case, Chalmers argues that it would be very unlikely for a subject to experience a fading of his qualia which he fails to notice and respond to. This, coupled with the independent assertion that a conscious being's functional profile just could be maintained, irrespective of its experiential state, leads to the conclusion that the subject of these experiments would remain fully conscious. The problem with this argument, however, as Brian G. Crabb (2005) has observed, is that it begs the central question: How could Chalmers \"know\" that functional profile can be preserved, for example while the conscious subject's brain is being supplanted with a silicon substitute, unless he already assumes that the subject's possibly changing qualia would not be a determining factor? And while changing or fading qualia in a conscious subject might force changes in its functional profile, this tells us nothing about the case of a permanently inverted or unconscious robot. A subject with inverted qualia from birth would have nothing to notice or adjust to. Similarly, an unconscious functional simulacrum of ourselves (a zombie) would have no experiential changes to notice or adjust to. Consequently, Crabb argues, Chalmers' \"fading qualia\" and \"dancing qualia\" arguments fail to establish that cases of permanently inverted or absent qualia are nomologically impossible.\n\nA related critique of the inverted spectrum argument is that it assumes that mental states (differing in their qualitative or phenomenological aspects) can be independent of the functional relations in the brain. Thus, it begs the question of functional mental states: its assumption denies the possibility of functionalism itself, without offering any independent justification for doing so. (Functionalism says that mental states are produced by the functional relations in the brain.) This same type of problem—that there is no argument, just an antithetical assumption at their base—can also be said of both the Chinese room and the Chinese nation arguments. Notice, however, that Crabb's response to Chalmers does not commit this fallacy: His point is the more restricted observation that \"even if\" inverted or absent qualia turn out to be nomologically impossible, and it is perfectly possible that we might subsequently discover this fact by other means, Chalmers' argument fails to demonstrate that they are impossible.\n\nThe Twin Earth thought experiment, introduced by Hilary Putnam, is responsible for one of the main arguments used against functionalism, although it was originally intended as an argument against semantic internalism. The thought experiment is simple and runs as follows. Imagine a Twin Earth which is identical to Earth in every way but one: water does not have the chemical structure H₂O, but rather some other structure, say XYZ. It is critical, however, to note that XYZ on Twin Earth is still called \"water\" and exhibits all the same macro-level properties that H₂O exhibits on Earth (i.e., XYZ is also a clear drinkable liquid that is in lakes, rivers, and so on). Since these worlds are identical in every way except in the underlying chemical structure of water, you and your Twin Earth doppelgänger see exactly the same things, meet exactly the same people, have exactly the same jobs, behave exactly the same way, and so on. In other words, since you share the same inputs, outputs, and relations between other mental states, you are functional duplicates. So, for example, you both believe that water is wet. However, the content of your mental state of believing that water is wet differs from your duplicate's because your belief is of H₂O, while your duplicate's is of XYZ. Therefore, so the argument goes, since two people can be functionally identical, yet have different mental states, functionalism cannot sufficiently account for all mental states.\n\nMost defenders of functionalism initially responded to this argument by attempting to maintain a sharp distinction between internal and external content. The internal contents of propositional attitudes, for example, would consist exclusively in those aspects of them which have no relation with the external world \"and\" which bear the necessary functional/causal properties that allow for relations with other internal mental states. Since no one has yet been able to formulate a clear basis or justification for the existence of such a distinction in mental contents, however, this idea has generally been abandoned in favor of externalist \"causal theories of mental contents\" (also known as informational semantics). Such a position is represented, for example, by Jerry Fodor's account of an \"asymmetric causal theory\" of mental content. This view simply entails the modification of functionalism to include within its scope a very broad interpretation of input and outputs to include the objects that are the causes of mental representations in the external world.\n\nThe twin earth argument hinges on the assumption that experience with an imitation water would cause a different mental state than experience with natural water. However, since no one would notice the difference between the two waters, this assumption is likely false. Further, this basic assumption is directly antithetical to functionalism; and, thereby, the twin earth argument does not constitute a genuine argument: as this assumption entails a flat denial of functionalism itself (which would say that the two waters would not produce different mental states, because the functional relationships would remain unchanged).\n\nAnother common criticism of functionalism is that it implies a radical form of semantic holism. Block and Fodor referred to this as the \"damn/darn problem\". The difference between saying \"damn\" or \"darn\" when one smashes one's finger with a hammer can be mentally significant. But since these outputs are, according to functionalism, related to many (if not all) internal mental states, two people who experience the same pain and react with different outputs must share little (perhaps nothing) in common in any of their mental states. But this is counterintuitive; it seems clear that two people share something significant in their mental states of being in pain if they both smash their finger with a hammer, whether or not they utter the same word when they cry out in pain.\n\nAnother possible solution to this problem is to adopt a moderate (or molecularist) form of holism. But even if this succeeds in the case of pain, in the case of beliefs and meaning, it faces the difficulty of formulating a distinction between relevant and non-relevant contents (which can be difficult to do without invoking an analytic–synthetic distinction, as many seek to avoid).\n\nAccording to Ned Block, if functionalism is to avoid the chauvinism of type-physicalism, it becomes overly liberal in \"ascribing mental properties to things that do not in fact have them\". As an example, he proposes that the economy of Bolivia might be organized such that the economic states, inputs, and outputs would be isomorphic to a person under some bizarre mapping from mental to economic variables.\n\nHilary Putnam, John Searle, and others have offered further arguments that functionalism is trivial, i.e. that the internal structures functionalism tries to discuss turn out to be present everywhere, so that either functionalism turns out to reduce to behaviorism, or to complete triviality and therefore a form of panpsychism. These arguments typically use the assumption that physics leads to a progression of unique states, and that functionalist realization is present whenever there is a mapping from the proposed set of mental states to physical states of the system. Given that the states of a physical system are always at least slightly unique, such a mapping will always exist, so any system is a mind. Formulations of functionalism which stipulate absolute requirements on interaction with external objects (external to the functional account, meaning not defined functionally) are reduced to behaviorism instead of absolute triviality, because the input-output behavior is still required.\n\nPeter Godfrey-Smith has argued further that such formulations can still be reduced to triviality if they accept a somewhat innocent-seeming additional assumption. The assumption is that adding a \"transducer layer\", that is, an input-output system, to an object should not change whether that object has mental states. The transducer layer is restricted to producing behavior according to a simple mapping, such as a lookup table, from inputs to actions on the system, and from the state of the system to outputs. However, since the system will be in unique states at each moment and at each possible input, such a mapping will always exist so there will be a transducer layer which will produce whatever physical behavior is desired.\n\nGodfrey-Smith believes that these problems can be addressed using causality, but that it may be necessary to posit a continuum between objects being minds and not being minds rather than an absolute distinction. Furthermore, constraining the mappings seems to require either consideration of the external behavior as in behaviorism, or discussion of the internal structure of the realization as in identity theory; and though multiple realizability does not seem to be lost, the functionalist claim of the autonomy of high-level functional description becomes questionable.\n\n\n"}
{"id": "52584607", "url": "https://en.wikipedia.org/wiki?curid=52584607", "title": "Gustavo Bontadini", "text": "Gustavo Bontadini\n\nGustavo Bontadini (27 March 1903 – 12 April 1990) was an Italian philosopher, writer, and a teacher. He was born in Milan and died in 1990, aged 87. Bontadini was also an influential representative known for Neo-Scholasticism in the 20th century. From 1951 to 1973, he became a professor of Theoretical philosophy in the Catholic university in Milan. He was also a teacher of Emanuele Severino, Angelo Scola and other Italian people.\n\n"}
{"id": "48407923", "url": "https://en.wikipedia.org/wiki?curid=48407923", "title": "Hume Feldman", "text": "Hume Feldman\n\nHume A. Feldman is a physicist specializing in cosmology and astrophysics. He is a Fellow of the American Physical Society and a professor and chair of the Department of Physics and Astronomy at the University of Kansas. \nFeldman graduated from the University of California at Santa Cruz in 1983. He got his PhD at Stony Brook University in NY, 1989 working with Robert Brandenberger. He was then a postdoc at the Canadian Institute for Theoretical Astrophysics, Toronto, 1989–91, a research fellow at the University of Michigan 1991-94 and a Prof. Research in the Physics Department at Princeton University 1994-96.\n\nHume has been a researcher in the study of the large-scale peculiar velocity field for the past two decades. His explanation of the systematic errors, aliasing and incomplete cancellations of small-scale noise masquerading as large-scale signal lead to the reemergence of peculiar velocities as a premier tool in our arsenal to probe the dynamics and statistics of the large-scale structure of the Universe. He developed a formalism to optimize the determination of cosmic flows from proper distance surveys and enabled for the first time direct comparison of independent surveys and cosmological models as a function of scale, thus establishing the cosmological significance of flow probes.\n\nHis work has led to many widely cited results (such as a nearly 3-sigma flows on 100 Mpc/h scales), renewed discussion of imposing flow constraints on cosmological models and the redesign of proper distance surveys. He is the coauthor of two recent papers that brought back this field from a decade with no new data (with over 200 and 100 citations in the last five and four years, respectively).\nHume was a coauthor of the best-cited article on cosmological perturbations (>3000 citations) developing a gauge invariant formalism that is widely considered to be the gold standard in this sub- discipline. His seminal work on the approximation of the matter power spectrum from redshift surveys (>800 citations) has opened the door to a whole industry of cosmological probes and N-point functions determination in Fourier space. He was a coauthor on the \"Loitering Universe\" series of papers that predicted an accelerating universe as a solution to the age problem in 1992 and which included a scalar field that acted like an effective cosmological constant or a quintessence field years before the supernovae type IA results.\n\nHe worked extensively on the constraints on galaxy bias, matter density, and primordial non-Gaussianity in redshift surveys and his detection of the bispectrum signal was the first observational confirmation of the Gravitational Instability Model. He helped develop an artificial neural network formalism to interpolate the fully non-linear power spectrum of matter fluctuation and provided the community with a fast and accurate (<1% errors) software to determine the non-linear power spectrum given an input cosmology.\n\nHis APS Fellow Citation reads: \n\nHe travels widely for presentations to a diverse array of groups, from elementary to high school students to churches, interest groups, legislators and professional societies. He became involved in the Creationism/Intelligent Design in Kansas in 1999 when the nearly successful attempts of various fundamentalist groups to force the teaching of religion in public schools began in earnest. Hume was one of the leaders of a group of academics and educators that addressed, publicized and confronted the issue head on by organizing conferences, public forums and workshops, and through political advocacy including testimonials to the Kansas legislatures, providing high school science teachers with the tools and knowledge to discuss these issues locally to parents, students and the interested public.\n"}
{"id": "34397409", "url": "https://en.wikipedia.org/wiki?curid=34397409", "title": "Im Sahong", "text": "Im Sahong\n\nIm Sahong (; 1445–1506) was a member of the Korean Joseon Dynastys royal family. His courtesy name was Iui(이의).\n\n"}
{"id": "40291525", "url": "https://en.wikipedia.org/wiki?curid=40291525", "title": "Jenann Ismael", "text": "Jenann Ismael\n\nJenann Ismael is a Professor of Philosophy at Columbia University and a member of the Foundational Questions Institute (FQXi.) Ismael has been described by John Perry as a leading philosopher of her generation, and her work has been influential in the scholarship of metaphysics and the philosophy of physics. Currently, she holds the position of Professor of Philosophy at Columbia University.\n\nIsmael earned her M.A. and PhD from Princeton University in 1994 and 1997, where her dissertation advisor was Bas van Fraassen. In 1996, she was awarded a two-year Mellon Postdoctoral Fellowship. In 2003, she was awarded an NEH Research fellowship at the National Humanities Center. Ismael worked at Stanford University from 1996-1998, and at University of Arizona from 1998 to the present, taking a 5-year leave from 2005-2010 to be a senior research associate at the Centre for Time at the University of Sydney after the Australian Research Council awarded her a five-year-long Queen Elizabeth II research fellowship. In 2011 Ismael was awarded a Big Questions in Free Will Grant from the Templeton Foundation. In 2012 she was awarded a Scholarly Conversation Grant from the National Humanities Center.\n\nIsmael's research focuses on the philosophy of physics and metaphysics, especially areas involving the structure of space and time, quantum mechanics, and the foundations of physical laws. She has also published on such issues as the conflict between lived experience and physics, the implications of physics on issues of freedom, death, the nature of the self, and the problem of free will.\n\nIsmael has published three books, \"Essays on Symmetry\" in 2001, \"The Situated Self\" in 2007 (with a second edition released in 2009,) and \"How Physics Makes Us Free\" in 2016, as well as a number of peer-reviewed papers. In \"Essays on Symmetry\" Ismael aims to draw connections between the concept of symmetry as it is used in philosophy and the concept of symmetry as it is used in physics.\nHow Physics Makes Us Free was selected by John Farrell of Forbes Magazine as 2016 Book of the Year. https://www.forbes.com/sites/johnfarrell/2016/12/31/book-of-the-year-how-physics-makes-us-free/#d95a90e4b950\n\nIn \"The Situated Self\", Ismael presents a naturalistic account of the self, focusing on the construction of internal models that represent the external world, and attempting to explain the relationship between the self and the outside world. The book has three distinct parts: the first part deals primarily with reflexive representation and its uses, the second part applies the idea of reflexive representation to famous problems of the philosophy of mind, and the third attempts to lay out a new conception of what the self is.\n"}
{"id": "311188", "url": "https://en.wikipedia.org/wiki?curid=311188", "title": "John Lucas (philosopher)", "text": "John Lucas (philosopher)\n\nJohn Randolph Lucas (born 18 June 1929) is a British philosopher.\n\nJohn Lucas was educated at Winchester College and Balliol College, Oxford, where he studied first mathematics, then Greats (Greek, Latin, Philosophy and Ancient History), obtaining first class honours, and taking the Oxford MA in 1954. He spent the 1957–58 academic year at Princeton University, studying mathematics and logic. For 36 years, until his 1996 retirement, he was a Fellow and Tutor of Merton College, Oxford, and he remains an emeritus member of the University Faculty of Philosophy. He is a Fellow of the British Academy.\n\nLucas is perhaps best known for his paper \"Minds, Machines and Gödel,\" arguing that an automaton cannot represent a human mathematician, essentially refuting computationalism.\n\nAn author with diverse teaching and research interests, Lucas has written on the philosophy of mathematics, especially the implications of Gödel's incompleteness theorem, the philosophy of mind, free will and determinism, the philosophy of science including two books on physics coauthored with Peter E. Hodgson, causality, political philosophy, ethics and business ethics, and the philosophy of religion.\n\nThe son of a Church of England clergyman, and an Anglican himself, Lucas describes himself as \"a dyed-in-the-wool traditional Englishman.\" He and Morar Portal have four children, among them Edward Lucas, a former journalist at \"The Economist\".\n\nIn addition to his philosophical career, Lucas has a practical interest in business ethics. He helped found the Oxford Consumers' Group, and was its first chairman in 1961-3, serving again in 1965.\n\nLucas (1961) began a lengthy and heated debate over the implications of Gödel's incompleteness theorems for the anthropic mechanism thesis, by arguing that:\n\nHis argument was strengthened by the discovery by Hava Siegelmann in the 1990s that sufficiently complex analogue recurrent neural networks are equivalent to Turing Machines.\n\nLucas wrote several books on the philosophy of science and space-time (see below). In \"A treatise on time and space\" he introduced a transcendental derivation of the Lorenz Transformations based on Red and Blue exchanging messages (in Russian and Greek respectively) from their respective frames of reference which demonstrates how these can be derived from a minimal set of philosophical assumptions.\n\nIn \"The Future\" Lucas gives a detailed analysis of tenses and time, arguing that \"the Block universe gives a deeply inadequate view of time. It fails to account for the passage of time, the pre-eminence of the present, the directedness of time and the difference between the future and the past\" and in favour of a tree structure in which there is only one past or present (at any given point in spacetime) but a large number of possible futures. \"We are by our own decisions in the face of other men's actions and chance circumstances weaving the web of history on the loom of natural necessity\"\n\n\n\n"}
{"id": "34383299", "url": "https://en.wikipedia.org/wiki?curid=34383299", "title": "John Shand", "text": "John Shand\n\nJohn Shand (22 January 1834 – 30 November 1914) was a New Zealand university professor, educationalist and administrator. He was one of the three foundation professors at the University of Otago.\n\nShand was born in Elgin, Morayshire, Scotland, in 1834. He was educated at Elgin Academy and the University of Aberdeen, from which he graduated as a Master of Arts in 1854. He held the position of mathematical master for nine years at the Ayr Academy and then a similar position at the Edinburgh Academy. On 8 February 1871, he married Annie Bell at Glasgow.\n\nIn 1870, Shand was appointed in to the Chair of Mathematics and Natural Philosophy at the University of Otago, and he travelled to New Zealand on the ship \"Wild Deer\" in 1871, becoming one of the first three professors at that university. The dual professorship was divided in 1876, and he opted to retain the Chair of Natural Philosophy, which he kept till his retirement in October 1913. He was a member of the New Zealand Institute and of the Australasian Association for the Advancement of Science. In 1877 he served on the Royal Commission to enquire into the operation of the University of New Zealand.\n\nHe became a member of the Senate in 1877. He sat on the Otago Education Board from 1876 to 1896, and was chairman from 1882 to 1885. He served on the High Schools Board of Governors from 1878 to 1890 and 1898 to 1904. In 1889 the honorary degree of LL.D. was conferred upon him. Following his retirement from Otago in 1913, Shand was appointed a Companion of the Order of St Michael and St George in the 1914 New Year Honours.\n\nShand died on 30 November 1914 at Dunedin, about a year after his retirement, and he was buried at the Dunedin Northern Cemetery.\n"}
{"id": "2127356", "url": "https://en.wikipedia.org/wiki?curid=2127356", "title": "Jonathan Bennett (philosopher)", "text": "Jonathan Bennett (philosopher)\n\nJonathan Francis Bennett (born 17 February 1930) is a British philosopher of language and metaphysics, and a historian of early modern philosophy.\n\nJonathan Bennett was born in Greymouth, New Zealand to Francis Oswald Bennett and Pearl Allan Brash Bennett. His father was doctor and his mother a homemaker. He read philosophy at the University of Canterbury (formerly Canterbury University College) and was awarded his MA there in 1953. He then went to the University of Oxford where he was a member of Magdalen College, Oxford. He obtained his BPhil in 1955.\n\nBennett's first academic post was as a Junior Lecturer at the University of Auckland, New Zealand (then Auckland University College) (1952). He was an instructor in Philosophy at Haverford College (Pennsylvania) (1955-56), then a lecturer in Moral Science (Philosophy) at the University of Cambridge (1956–68), then at Simon Fraser University (1968–70), the University of British Columbia (1970–79), and in 1979 he went to Syracuse University as Professor of Philosophy. He remained in this position until his retirement in 1997.\n\nIn 1980, he was the Tanner Lecturer at Brasenose College of Oxford University. His lectures were refined and published in his 1995 book \"The Act Itself\". In this work he argues that letting someone die is as immoral as killing someone. This also applies to other harms that one commits or fails to prevent. This view has been widely discussed for example by Judith Jarvis Thomson\n\nIn 1992, he was the John Locke Lecturer at the University of Oxford giving lectures on 'Judging Behaviour: Analysis in Moral Theory'. \n\nIn 1985, he was elected a Fellow of the American Academy of Arts and Sciences. The British Academy extended him the same honour in 1991. In the same year he was awarded a LittD from the University of Cambridge.\nBennett has written extensively on philosophy of mind, philosophy of language, events, conditionals, and consequentialist ethics. He is particularly renowned for his interpretations of major early modern philosophers and he has written five books in this area.. A Festschrift to commemorate his 60th birthday was published in 1990.\n\nBennett's website is devoted to making the texts of early modern philosophers more accessible to today's students.\n\nBooks\n\nSelected journal articles\n\n\n"}
{"id": "57805098", "url": "https://en.wikipedia.org/wiki?curid=57805098", "title": "List of doctoral programs in bioethics", "text": "List of doctoral programs in bioethics\n\nThis is a list of Doctorate degree programs (PhD or professional doctorate) with formal specializations / concentrations in Bioethics, by country. These may be dedicated degrees in Bioethics, or specializations within other disciplinary programs, such as philosophy, law or health sciences. They may refer to bioethics, health ethics, healthcare ethics, etc.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "38813239", "url": "https://en.wikipedia.org/wiki?curid=38813239", "title": "Litigation strategy", "text": "Litigation strategy\n\nLitigation strategy is the process by which counsel for one party to a lawsuit intends to integrate their actions with anticipated events and reactions to achieve the overarching goal of the litigation. The strategic goal may be the verdict, or the damages or sentence awarded in the case. Alternatively, in the case of impact litigation (also known as strategic litigation) the goal may be more far-reaching, such as setting legal precedent, affecting consumer-safety standards, or reshaping the public’s perception of a societal issue. Broader goals and more challenging cases require a strategist with a greater understanding of, and facility with, the tools of litigation strategy.\n\nAttorneys who apply advanced strategic concepts (such as Maneuver and the Boyd Loop), which are not taught in most law schools, may gain a decisive advantage over attorneys who are unfamiliar with the skill set and who, because of their unfamiliarity, can be unwittingly maneuvered into disadvantageous actions. The resulting imbalance has led to academic criticism of the use of advanced strategic techniques. Professor Hugh Selby of Australian National University's College of Law has been particularly critical of its use by prosecutors, who already wield the massive power of the state against often poorly resourced defendants. The counterargument is that strategy can correct already-existing imbalances in the system, allowing a sole or two-attorney law firm with an indigent client to level the playing field against a large law firm with a wealthy corporate client, and allowing attorneys with little trial experience to effectively try cases against vastly more experienced opposing counsel.\n\nStrategy is the process of designing and achieving a desired final outcome. Basic litigation strategies organize a case so that it has a cohesive focus. Advanced strategies will anticipate and even shape events, decisively guiding the situation to the desired outcome. \nLitigation strategies are either primarily direct or primarily indirect, though they usually include elements of both. In litigation, direct strategies argue what the law does or does not say; what the facts are or are not; or who has the more believable witnesses. Indirect strategies, on the other hand, shift the point of conflict, alter perceptions of what is central, or undermine the opposing counsels’ case without direct confrontation, often through deception, surprise or misdirection of the opponent—though never of the jury.\n\nTrial advocacy offers a number of tools and methods for constructing sound strategies.\n\nWith this organizational tool, attorneys list the elements of the case they are required to prove (or intend to disprove) then list all the evidence they intend to leverage in support of each element. The purpose is to ensure they address all the issues of the case, and make certain that meeting one element does not require undercutting the evidence in support of another.\n\nThese messaging tools bring force and greater direction to the evidence. The theme is a sound bite that encapsulates logic or emotional force of the attorney’s case. The theory of the case is a logical description of events that the attorney wants the judge or jury to adopt as their own perception of the underlying situation. The theory is often expressed in a story that should be compellingly probable.\n\nTheme and theory become strategic tools when they serve as the core for the organization of the case; when every aspect of the trial, including the actions and reactions of the adversary, are organized and incorporated in support of them. Practically, this is usually accomplished by writing the desired closing argument first, and backward planning from that argument.\n\nManeuver is a strategic philosophy that leverages the indirect approach through its focus on individual decision making and perception. It is ideally suited to litigation, wherein the jury’s perception decides the outcome. The core of maneuver is the decision cycle as described in Boyd’s OODA Loop.\n\nThis model notes that in decision-making, individuals (witness, opposing counsel, jurors) go through a process of observation (receiving information), orientation (deciding what the information means to them and what they might do about it), decision (picking a course of action from among the possibilities), and then acting (taking the course of action). Like most models, the OODA Loop is not a technical description, but rather is a tool for illustrating important points for strategists. \n\nWhile litigation presents opportunities for information denial through the rules of privilege and work product, even more opportunities to shape the conduct of opposing counsel and hostile witnesses arise in the orientation phase. Psychology offers deep insights into how individuals perceive and misperceive information. Moreover, an individual’s perception of a situation affects how he frames his decisions. By altering perceptions, litigators can shape the decision the party will make. Coupling this understanding of psychology with utility theory / economic game theory, attorneys can set the stage for adversarial parties to take actions that serve the attorneys’ plan.\nAt the same time, the attorneys must protect their own decision-making while retaining a degree of control over the evolving situation. The methods for protecting one’s own decision-making include making accurate predictions (using tools from psychology and utility theory), validating planned actions, having a clear focus of effort and information flow, and building sound, powerful, and flexible plans, as can be done using a “line of effort.”\n\nA line of effort can organize the attorneys' planned actions in the way a case diagram organizes their evidence. Because of the uncertainty inherent in trial practice, the litigators’ strategic plan must be powerful, yet flexible, to remain effective. The line of effort produces the needed power and flexibility by structuring the plan around the \"purpose\" and an achievable \"end state\" that realizes the purpose, the \"aims\" (the elements necessary, or chosen to achieve the end state), and the \"levers\" or \"effects\" (the actions the counsel can take that are likely to bring about the targeted aims). \n\nThe visual nature a line of effort allows the attorneys using it to see the entirety of the trial, ensuring their plan comprehensively addresses the situation, and identifying points of high uncertainty where having prepared branch plans would be prudent. It further allows the attorney to exploit unexpected opportunities with an understanding of what elements of his/her plan will be enhanced and which will require further adaptation, making the opportunistic action not only clear-sighted, but focused and efficient.\n\nIn a fluid situation, any levers or aims rendered obsolete by changes in the situation are swapped out, retaining the bulk of the previously analyzed and validated plan intact, and providing a clear focus for the branch plan or substituted actions.\n\n"}
{"id": "9528787", "url": "https://en.wikipedia.org/wiki?curid=9528787", "title": "Maurice Cranston", "text": "Maurice Cranston\n\nMaurice William Cranston (8 May 1920 – 5 November 1993) was an English philosopher, professor and author. He served for many years as Professor of Political Science at the London School of Economics, and was also known for his popular publications. In the late 1970s and early 1980s he was Professor of Political Theory at the European University Institute in Florence (Italy).\n\nHe was born at 53 Harringay Road, Harringay and educated at South Harringay School, the University of London and the St Catherine's College, Oxford. As a young\nman, Cranston was a friend of the painter Denton Welch. During the Second World War, Cranston was a conscientious objector, active in the Peace Pledge Union, \nand a \"frequent contributor\" to its newspaper \"Peace News\".\n\nCranston's major works include biographies of John Locke, for which he received the 1957 James Tait Black Memorial Prize, and Rousseau, Jean-Paul Sartre and others addressing the history of liberty.\nHe contributed to many publications in both Britain and the United States and wrote scripts for the BBC. In 1946 two of his detective novels were published by John Westhouse: \"Tomorrow We'll Be Sober\" and \"Philosopher's Hemlock\". Under the name Michael Stone, he also wrote a children's school story \"The Master of Magic\", published by Peter Lunn in 1947.\n\nCranston's intellectual abilities were varied. His first academic book, \"Freedom: A New Analysis\" (1954), covered history (the history of liberalism), politics (a precursive discussion of what Sir Isaiah Berlin would later analyse as negative and positive liberty) and a philosophical attempt to resolve or at least elucidate freedom of the will. The philosophical section was the least successful; and Cranston never again attempted pure philosophy. His main academic strengths were as a biographer and as an intellectual historian.\n\nIn a controversial paper, Cranston argued that the scarcity of welfare goods and services meant that supposed welfare rights are not really rights at all.\n\nIn his later years, Cranston moved to the political right, and expressed admiration for Margaret Thatcher. Cranston also contributed to \"The American Spectator\" magazine.\n\nCranston had a keen aesthetic sensibility. This was shown not only in his clothes but also in his elegant literary style. Elegance extended also to his conversation. At a party for politics students at the London School of Economics in 1965, sherry was much in demand. Professor Kingsley Smellie pointed to a bottle and said to Cranston: \"I hope you've ordered buckets of that stuff\". \"I have\", Cranston replied without malice, \"not quite in those terms\".\n\nHe died 5 November 1993 of a heart attack while taping a television production in London for the BBC. He was 73.\n\n\n\n"}
{"id": "4473928", "url": "https://en.wikipedia.org/wiki?curid=4473928", "title": "Michał Heller", "text": "Michał Heller\n\nMichał Kazimierz Heller (born 12 March 1936 in Tarnów) is a Polish professor of philosophy at the Pontifical University of John Paul II in Kraków, Poland, and an adjunct member of the Vatican Observatory staff. He also serves as a lecturer in the philosophy of science and logic at the Theological Institute in Tarnów. A Roman Catholic priest belonging to the diocese of Tarnów, Heller was ordained in 1959. In 2008 he received the Templeton Prize for his works in the field of philosophy.\n\nMichał Heller attended high school in Mościce, graduated from the Catholic University of Lublin, where he earned a master's degree in philosophy in 1965 and a Ph.D. in cosmology in 1966.\n\nAfter beginning his teaching career at Tarnów, he joined the faculty of the Pontifical Academy of Theology in 1972 and was appointed to a full professorship in 1985. He has been a visiting professor at the Catholic University of Louvain in Belgium and a visiting scientist at Belgium's University of Liège, the University of Oxford, the University of Leicester, Ruhr University in Germany, The Catholic University of America, and the University of Arizona among others.\n\nHis current research is concerned with the singularity problem in general relativity and the use of noncommutative geometry in seeking the unification of general relativity and quantum mechanics into quantum gravity. His model gives new perspectives on quantum entanglement and the EPR paradox.\n\nIn March 2008, Heller was awarded the $1.6 million (£820,000) Templeton Prize for his extensive philosophical and scientific probing of \"big questions\". His works have sought to reconcile the \"known scientific world with the unknowable dimensions of God.\" On receiving the Templeton Prize, Heller said:\n\nHeller used the prize money to establish the Copernicus Center for Interdisciplinary Studies – an institute named after Nicholas Copernicus aimed at research and popularisation of science and philosophy. Heller himself is the director of the Center, as well as the program director of Copernicus Festival.\n\nHonorary degrees from:\nOther distinctions:\n\n\nMichael Heller has published nearly 200 scientific papers, not only in general relativity and relativistic cosmology, but also in philosophy, history of science and theology. He authored more than 50 books. In his volume, \"Is Physics an Art?\" (Biblos, 1998), he writes about mathematics as the language of science and also explores such humanistic issues as beauty as a criterion of truth, creativity, and transcendence.\n\n\n\n\n\n"}
{"id": "27987730", "url": "https://en.wikipedia.org/wiki?curid=27987730", "title": "Mindfulness-based stress reduction", "text": "Mindfulness-based stress reduction\n\nMindfulness-based stress reduction (MBSR) is a program that incorporates mindfulness to assist people with pain and a range of conditions and life issues that were initially difficult to treat in a hospital setting. Developed at the University of Massachusetts Medical Center in the 1970s by Professor Jon Kabat-Zinn, MBSR uses a combination of mindfulness meditation, body awareness, and yoga to help people become more mindful. In recent years, meditation has been the subject of controlled clinical research. This suggests it may have beneficial effects, including stress reduction, relaxation, and improvements to quality of life, but that it does not help prevent or cure disease. While MBSR has its roots in spiritual teachings, the program itself is secular.\n\nIn 1979 Kabat-Zinn founded the Mindfulness Based Stress Reduction Clinic at the University of Massachusetts Medical Center, and nearly twenty years later the Center for Mindfulness in Medicine, Health Care and Society at the University of Massachusetts Medical School. Both these institutions supported the successful growth and implementation of MBSR into hospitals worldwide. In 2015, MBSR is practiced as a complementary medicine, commonly in the field of oncology; in the same year, 2015, close to 80% of medical schools are reported to offer some element of mindfulness training and research and education centers dedicated to mindfulness have proliferated.\n\nMBSR has been described as \"a group program that focuses upon the progressive acquisition of mindful awareness, of mindfulness\". The MBSR program is an eight-week workshop taught by certified trainers that entails weekly group meetings (two-hour classes) and a one-day retreat (six-hour mindfulness practice) between sessions six and seven, homework (45 minutes daily), and instruction in three formal techniques: mindfulness meditation, body scanning and simple yoga postures. Body scanning is the first prolonged formal mindfulness technique taught during the first four weeks of the workshop, and entails quietly lying on one's back and focusing one's attention on various regions of the body, starting with the toes and moving up slowly to the top of the head.\nMBSR is based on the following tenets: non-judging, non-striving, acceptance, letting go, beginner’s mind, patience, trust, and non-centering.\n\nAccording to Kabat-Zinn, the basis of MBSR is mindfulness, which he defined as \"moment-to-moment, non-judgmental awareness.\" During the program, participants are asked to focus on informal practice as well by incorporating mindfulness into their daily routines. Focusing on the present is thought to heighten sensitivity to the environment and one’s own reactions to it, consequently enhancing self-management and coping. It also provides an outlet from ruminating on the past or worrying about the future, breaking the cycle of these maladaptive cognitive processes.\n\nScientific evidence of the debilitating effects of stress on human body and its evolutionary origins were pinpointed by the ground-breaking work of Robert Sapolsky, and explored for lay readers in the book \"Why Zebras Don't Get Ulcers\". Sapolsky's work consequently promotes mindfulness-based techniques for a better lifestyle and healthy stress management.\n\nAccording to a 2014 article in \"Time\" magazine, mindfulness meditation is becoming popular among people who would not normally consider meditation. The curriculum started by Kabat-Zinn at University of Massachusetts Medical Center has produced nearly 1,000 \ncertified MBSR instructors who are in nearly every state in the US and more than 30 countries. Corporations such as General Mills have made it available to their employees or set aside rooms for meditation. Democratic Congressman Tim Ryan published a book in 2012 titled \"A Mindful Nation\" and he has helped organize regular group meditation periods on Capitol Hill.\n\nMindfulness-based stress reduction classes and programs are offered by various facilities including hospitals, retreat centers, and various yoga facilities. Typically the programs focus on teaching,\n\nMindfulness-based approaches have been tested for a range of health problems including anxiety disorder, mood disorder, substance abuse disorder, eating disorders, chronic pain, ADHD, insomnia, coping with medical conditions, with many populations including children, adolescents, parents, teachers, therapists, and physicians. As a major subject of increasing research interest, 52 papers were published in 2003, rising to 477 by 2012. Nearly 100 randomized controlled trials had been published by early 2014.\n\nResearch suggests mindfulness training improves focus, attention, and ability to work under stress.\n\nA 2013 statement from the American Heart Association on alternative approaches to lowering blood pressure concluded that MBSR was not recommended in clinical practice to lower blood pressure. MBSR can have a beneficial effect helping with the depression and psychological distress associated with chronic illness. \n\nPreliminary evidence suggests efficacy of mindfulness meditation in the treatment of substance use disorders; however, further study is required. MBSR might be beneficial for people with fibromyalgia: there is no evidence of long-term benefit but low-quality evidence of a small short-term benefit.\n\nIn 2010, a meta-analysis was conducted by Hoffman and colleagues exploring the efficacy of MBSR and similarly structured programs for adults with symptoms of anxiety and depression. The meta-analysis showed that between pre and post testing there was significant medium within in-group effect sizes observed on anxiety and depression and also small to medium between-group effect sizes when comparing wait-list, treatment as usual, and active treatment (MBSR), further supporting the literature that states mindfulness-based therapies can be beneficial in treating symptoms of depression and anxiety. A broader meta-analysis conducted in 2004 by Grossman and colleagues found similar effect sizes when testing the physical and mental health outcomes following MBSR treatment.\n\n\n"}
{"id": "23913626", "url": "https://en.wikipedia.org/wiki?curid=23913626", "title": "Oksan Seowon, Gyeongju", "text": "Oksan Seowon, Gyeongju\n\nThe Oksan Seowon is a \"seowon\" (a private educational institution in Korea which functioned as both an academy and a Confucian shrine) located at Oksan-ri, Angang-eup in the city of Gyeongju, North Gyeongsang Province, South Korea. Seowon is a type of local academy during the Joseon Dynasty (1392–1897). It was established by Yi Je-min, (李齊閔), the minister of Gyeongju and local Confucian scholars in 1572, the fifth year of King Seonjo's reign, to commemorate the scholarly achievement and virtue of Confucian scholar and politician Yi Eon-jeok (1491–1553).\n\nHoejae Yeongjeok left office and built the main building as the main building in the stream of Oksan in Gyeongju's Angang-eup near Yangdong Village. For this reason, after Hoejae died, Oksan Seowon was built near Dokrakdang. Oksan Seowon is located in Seshimdae, and it means to wash one's mind with water falling from Yongchu and seek learning through nature.\n\n\n"}
{"id": "32024788", "url": "https://en.wikipedia.org/wiki?curid=32024788", "title": "Opinio tolerata", "text": "Opinio tolerata\n\nIn Catholic theology, opinio tolerata refers to pious beliefs with a low degree of theological certainty, but which are tolerated by the magisterium of the Catholic Church. These are ranked less certain than \"sententia probabilis\" and hold the least degree of certainty in the hierarchy of dogmatic teachings for Catholics.\n\n"}
{"id": "34537282", "url": "https://en.wikipedia.org/wiki?curid=34537282", "title": "Overurbanization", "text": "Overurbanization\n\nOverurbanization is a thesis originally developed by scholars of demography, geography, ecology, economics, political science, and sociology in the 20th century to describe cities whose rate of urbanization outpaces their industrial growth and economic development. Overurbanized countries are characterized by an inability to provide for their populations in terms of employment and resources. The term is intentionally comparative and has been used to differentiate between developed and developing countries. Several causes have been suggested, but the most common is rural-push and urban-pull factors in addition to population growth.\n\nThe concept of overurbanization first emerged in the mid-20th century to describe cities whose rate of industrialization was growing more slowly than their rate of urbanization. According to sociologist Josef Gugler, the concept was \"widely accepted in the 1950s and into the 1960s\" and was split into two approaches, a diachronic and a synchronic approach. The synchronic approach, the main one taken in the 1950s, was proposed by sociologists Kingsley Davis and Hilda Golden who defined whether a country was overurbanized based on how its relationship between industrialization and urbanization compared to that of other countries during the same time period. Specifically, countries considered part of the Third World were compared to countries deemed part of the First World. Davis and Golden used data on \"the percentage of economically active males not engaged in agriculture and the percentage of the population in cities of 100,000 or above in a large number of the countries in the world,\" in order to define the normal relationship between industrialization and urbanization. They then determine that countries whose rate of urbanization is significantly higher than normal in relation to their rate of industrialization are \"overurbanized.\" The authors calculate an \"expected\" level of urbanization based on the rates of urbanization of other countries of the world at similar levels of industrialization (measured by percentage of males not engaged in agriculture). A few countries in particular that Davis and Golden measured as having higher levels of urbanization than expected were Egypt, Greece, and South Korea. Davis and Golden did not see overurbanization as a necessarily negative phenomenon, but rather a statistical reality that could have its challenges but would ultimately be self-correcting as an appropriate balance was found between levels of urbanization and industrialization. Scholars on overurbanization agree that N.V. Sovani was one of the first to discount Davis and Golden's argument, as he found that the connection between urbanization and industrialization was more significant in underdeveloped countries than developed ones, suggesting that Davis and Golden's measure of a \"normal\" relationship between urbanization and industrialization was not valid.\n\nThe definition offered by the United Nations and UNESCO in 1956 took a different approach to measuring overurbanization: the diachronic approach. A 1956 UNESCO report measured overurbanization historically, emphasizing that \"at comparable levels of urbanization developed countries of today had a correspondingly greater proportion of their labour force engaged in non-agricultural occupations\" than underdeveloped countries. Authors on overurbanization give the examples of France, the United States, Germany, and Canada as developed and often mention the continents of Asia and Africa as well as the region of Latin America as underdeveloped. This historical approach was applied to Asia in the report, which argued that because a smaller percentage of the labor force was engaged in non-agricultural activities than certain Western developed countries had at similar levels of urbanization, Asia was overurbanized. However, this method has been criticized by scholars who argue that it supports an ethnocentric idea that all countries follow the same path of development. Furthermore, economist N.V. Sovani argued that the evidence offered is not consistent with the development trajectories of developed countries, pointing out specific examples of developed countries such as Switzerland where high levels of industrialization did not correspond with high levels of urbanization. Sociologists John D. Kasarda and Edward Crenshaw pointed out that it was not so much the rate of urbanization of developing countries that was greater, but the absolute numbers of people migrating.\n\nScholars reference N.V. Sovani as a researcher who questioned whether to accept the 1950s definition of overurbanization. His debunking of the formerly accepted definitions of overurbanization encouraged further scholarly analysis and attempts to redefine the term. Sovani suggested that claims of overurbanization in underdeveloped countries stemmed from the perception that rapid urbanization had negative consequences. However, he claimed that there still lacked evidence for the idea that rapid urbanization actually made areas worse off. Economist David R. Kamerschen found that there was little statistical evidence to support that \"rapid urbanization in underdeveloped countries hampers economic growth,\" suggesting that the phenomenon of overurbanization is questionable.\n\nFollowing Sovani's work, several scholars offered alternative definitions, many of which included not just the relationship between population growth and their means of employment but also the ability of the urban area to provide public services, reflecting that economic development lagged behind population growth in a multitude of ways. Several scholars also increasingly embraced a negative connotation for the term. Urban planner John Dyckman suggested that inability to accommodate the expectations of migrants to the city made overurbanization a threat to social order. Economists Philip Graves and Robert Sexton argue that the definition of overurbanization must \"involve the presence of negative net external effects for the city size in question,\" suggesting that as long as \"positive external social benefits\" from rapid urbanization dominate negative externalities, overurbanization is not at play. Gugler defined overurbanization by two factors: that migration to cities led to a \"less than optimal allocation of labor between the rural and urban sectors\" and that migration to cities \"increases the costs of providing for a country's growing population.\" Sociologist Glenn Firebaugh disagreed, arguing that if overurbanization is caused by overpopulation, that overpopulation of rural areas could be worse than overpopulation of urban areas.\n\nFrom its origins, the term has been used to differentiate between countries that are considered developed and underdeveloped. Davis and Golden considered a country to be underdeveloped if over half its economically active males were employed in agriculture. The UNESCO report frequently used the terms \"developed\" and \"Western\" in conjunction. Gugler and others use the terms \"third world\" and \"first world\" in their discussion.\n\nSociologist John Shandra states that arguments about the causes of overurbanization fall into five groups:\nShandra's analysis of several variables related to each of these categories suggested that all of these arguments have significant evidence except for the economic modernization perspective. Recent scholars believe that a variety of these factors are relevant.\n\nThe biggest cause of overurbanization emphasized by scholars is rural-urban migration and the \"push\" factors associated with it, including \"increased population, diminished size of holdings, and absentee landlord exactions.\" Specifically, lower death rates as a result of demographic transition lead to less available land and fewer opportunities for rural residents. The larger process of urbanization is characterized both by these factors that \"push\" migrants away from their homes as well as factors that \"pull\" them towards new areas. Davis and the UNESCO report both discuss that overurbanization is affected by the \"push\" factors away from rural areas being stronger than the \"pull\" factors. Pull factors towards urban areas include expansion of economic opportunity and the infrastructure of cities as administrative centers Shandra recognizes the relationship between push and pull factors, arguing that rural conditions, specifically environmental scarcity, cause decreasing income, decreased stability, and increased health risks, leading many to respond by migrating to urban areas. For example, drought in Brazil and Deforestation in the Philippines has made many rural residents' former manner of livelihood impossible, forcing them to move to the nearest city. Because migrants are primarily motivated by factors pushing them out of rural areas rather than factors such as demand for labor pulling them to the city, these rural-urban migrants often find themselves unemployed or quitting \"low productive agricultural employment to [enter] yet another section marked by low productivity employment, namely handicraft production, retail trading, domestic services in urban areas.\" A study done by sociologist Glenn Firebaugh showed that agricultural density, a strong indicator of land constraint, and the presence plantation agriculture both have significant effects on overurbanization. These findings were later reversed by sociologist Bruce London, who emphasized that urban migration was not the only potential response to agricultural density.\n\nSovani argues that there is little evidence for the greater role of \"push\" factor of increased population in rural areas, as even countries where there is little pressure for land experience this phenomenon, but that instead the opportunity for higher income is responsible for the excessive migration and pressure on cities, as the salary for an unproductive job in an urban area was almost always higher than the salary for unproductive work in a rural area. Graves and Sexton also emphasize that individuals move despite negative factors such as overcrowding, suggesting that individuals still see urban migration as an overall benefit. They argue that if the benefits do indeed outweigh the costs for society as a whole, then the term \"overurbanization\" is not appropriate to describe the phenomenon. Gugler argues that while the benefits outweigh the costs for an individual migrating to an urban area, greater costs such as resource scarcity and widespread unemployment and poverty are present when this occurs at a larger scale.\n\nSovani also argues that the definition of overurbanization as developed by scholars in the 1950s and 1960s suggests some sort of limits to population density \"beyond which the resulting social situation is abnormal,\" which he argues need to be defined more clearly. Such unsupportable growth would suggest that the cause of overurbanization is urbanization happening too rapidly for a city's level of economic development. Dyckman would call this the \"pre-takeoff period.\" However, several scholars have questioned the validity of the connection between urbanization and industrialization.\n\nThe economic modernization perspective on the causes of overurbanization is based on modernization theory, which argues that a hierarchical progression exists from pre-modern to modern society. An explanation of overurbanization from this perspective was given by sociologist Jeffrey Kentor, who wrote that under modernization theory, urbanization results from development and industrialization creating jobs and infrastructure. This argument has been criticized by those who do not ascribe to the assumption that there is a linear path of development that all countries follow.\n\nShandra's take on the political modernization perspective asserts that environmental degradation causes overurbanization, because the destruction of natural resources in rural areas lowers production and increases poverty and health risks. Supporters of the political modernization perspective suggest that a strong civil society supports lower levels of overurbanization. The presences of international non-governmental organizations (INGOs) in rural areas, political protests, and democratic government all have the ability of limiting rural-push factors by limiting factors that lead to resource scarcity. INGOs can reduce overurbanization by stimulating alternative employment outside of agriculture, supporting grassroots movements, and improving rural conditions, such as by providing clean water. Considering the role of political protest, Shandra offers the example of the Chipko movement in India, where local women protested deforestation. Protection of this natural resource \"eliminated the causes (i.e., income risk and health effects) that facilitate rural to urban migration by protecting a natural resource base by which rural residents in India depended for their existence.\" Given these considerations, Shandra argues that repressive regimes that do not respond to the desires of the public are more likely to cause higher rates of urbanization than democratic governments.\n\nThe neo-Malthusian perspective is closely related to rural-push and urban-pull factors, but it suggests that the cause behind these factors is population growth, which leads to ecological problems, decreasing agricultural activity, and increased rural poverty. These factors then push rural residents to the city.\n\nThe dependency perspective on the causes of overurbanization is based on dependency theory, which argued that economic and political systems rendered less developed countries dependent on developed countries, which used developing countries for resources, labor, and markets.\nProponents of the dependency perspective argue that rural-push and urban-pull factors are not only a result of population growth and resource scarcity, but that these factors, among others, are caused by the exploitation of developed countries and the capitalist principles they operate under. This is to say that \"a comprehensive understanding of Third World urbanization cannot focus solely on intra-national, rural-push, urban-pull explanations...but must explicitly incorporate the impact of international capitalist forces.\" This holds that the negative rural-push factors are a result of the manipulation of developed countries. Michael Kentor found that dependence on foreign investment had a lagged effect on urbanization, meaning that urbanization rates increased a few years after foreign companies began profiting in developing countries. Jeffrey Timberlake and Michael Kentor found in their analysis of 69 less developed countries that there was a significant relationship between dependence, as measured by level of foreign investment, and overurbanization. Additionally, a study done by Bruce London found that factors related to dependency were not only connected to rapid urbanization, but also the negative aspects of urbanization such as urban inequality.\n\nDavis and Golden did not see overurbanization as an inherently negative phenomenon, but as a statistical fact that would likely correct itself, as \"urbanization will fall off sharply or industrialization will gain a new impetus.\" Expanding on the latter, they suggest that overurbanization could spur industrial growth, modernization of agriculture, and social change. Even in the case of overurbanization, some of the positive effects of urbanization could be present in regards to economic growth, such as the development of more efficient economics due to scale, technological developments, diversity of both products and occupations, as well as \"the greater opportunity of occupational and social mobility and greater readiness to adapt.\" For example, they argue that industrialization supports greater efficiency of agriculture through technology, an advantage for the productivity of rural farmers as well as urban consumers. However, Firebaugh argues that great efficiency is often a result of an increasingly capital-intensive system, which creates inequality between large and small landowners, such as in the Latin American latifundia system. Furthermore, Timberlake and Kentor found in their analysis of economic growth and overurbanization that countries that experienced increases in levels of overurbanization experienced less economic growth. Economic opportunities are lacking due to \"saturated urban labor markets\" that exclude much of both the rural and urban populations truncated opportunity structures in rural areas. Furthermore, high infrastructural costs stymie growth.\n\nThe UNESCO report emphasized the negative effects of overurbanization, detailing \"low levels of living\" as \"inadequate housing, the almost complete absence of mass sanitary facilities, the presence of filth, squalor, repugnant odours, disease and high mortality\" and \"large urban groups who have little or no access to educational facilities.\" Several scholars have agreed that overurbanization puts a strain on the wellbeing of urban residents due to the lack of adequate public services.\n\nDavis and Golden also argue that greater density of dissatisfied impoverished masses could improve conditions to the extent that it provokes the government to enact change to avoid revolution. Dyckman agreed that overurbanization lends itself to the potential for revolution, though he saw this as a potentially destabilizing factor as the conditions would lead to social dissatisfaction and seizure of control by revolutionary leaders. He saw informal squatter settlements as breeding ground for revolutionary activity.\n\nDespite arguing the potential for economic growth, the UNESCO report also states that overurbanization prevents urban areas and countries from utilizing their \"potential human and physical resources\" due to unemployment, under-employment, and misemployment. The idea that rural-push factors are stronger than urban-pull factors in cases of overurbanization suggests that it is population pressure in rural areas rather than the pull of urban jobs that leads to rural-urban migration. Migrants often end up unemployed, as overall urbanization rates rise faster than industrialization and the expansion of the urban job base.\n\nIn addition to high levels of unemployment, overurbanization is characterized by underemployment and misemployment. Underemployment is defined as the \"underutilization of labor,\" or when available laborers are not working at their full capacity due to seasonal variation in production or excess employment of laborers for the amount of work that needs to be done. Misemployment is defined as unproductive labor, meaning that efforts are considered to \"contribute little to social welfare,\" such as the full-time labor of begging.\n\nWhile these phenomena are all caused by excessive rates of migration to cities, it is notable that unemployment and underemployment are also problems in rural areas as well. Often unemployment in rural areas is what pushes residents to the city, where better economic opportunities are expected.\n\nA UNESCO report that discussed overurbanization in Asia suggested initial proposals that addressed rural-push factors such as lack of economic opportunity and low productivity by improving agricultural technology and supporting rural industries. Furthermore, rural misery could be reduced by bringing industrialization into rural areas to increase employment and wages and to support the development of infrastructure that creates a \"more desirable community environment.\" The UNESCO report also considers the role of governments in committing to providing adequate housing as well as regional planning that takes into consideration social concerns. However, these considerations, among others that propose dealing with unemployment, have been criticized as \"skirting the issue by addressing 'symptoms' of overurbanization\" rather than the root cause.\n\nLater authors also emphasized improving rural conditions to combat overurbanization. Gugler suggested channeling more resources to rural areas and fighting the tendency to neglect rural areas with what economist Michael Lipton deemed \"urban bias,\" the tendency to allocate funds and public works to cities, where the elite and middle classes reside. For example, monetary policies that create artificially low prices for agricultural products harm farmers while creating a surplus for the government. Thus a reallocation of resources to agricultural workers would help shift this system that favors urban elites over the rural poor. Sociologists York Bradshaw and Mark Schafer studied the relationship between INGOs and overurbanization and found that state expenditures towards development were less effective than the role of INGOs. While INGOs were shown statistically to decrease overurbanization, the presence of INGOS did not decrease the effects of foreign capital investment, which is considered one of the root causes of overurbanization by dependency theorists. They and Shandra agree that INGOs can play an important role in decreasing overurbanization by supporting rural communities by promoting both economic and infrastructural development as well as the role of civic society.\n\nDavis and Golden offered the example of Egypt as a country that significantly deviated from the normal relationship between urbanization and economic development. They argue that population growth in rural areas created congestion, poverty, and unemployment. They point out that only 10 percent of economically active males in rural areas are employed in non-agricultural work, compared to 50 percent in France, suggesting that there are no economic opportunities in rural areas in Egypt outside of farming. Egypt had similar levels of urbanization in the late 1940s to Sweden, Switzerland, and France, but significantly lower levels of industrialization. Based on the normal relationship Davis and Golden found between urbanization and industrialization, Egypt had higher levels of urbanization than expected. Dyckman gives an example of a consequence of urbanization in Cairo when he explains that urban dwellers actually have lower literacy rates than those in surrounding villages due to a lack of development.\n\nBoth the UNESCO report and Davis and Golden identify South Korea as an example of an overurbanized country. Davis and Golden discussed how following the removal of the Japanese after World War II, urbanization continued, but economic growth stagnated. Population growth and urbanization were driven by migration from overpopulated rural areas, even though the majority of jobs available were still in the agricultural sector. The 17.2 percent of Korea's population that were urban dwellers in 1949 were attributed largely to the presence of rural migrants.\n\n\n"}
{"id": "35259083", "url": "https://en.wikipedia.org/wiki?curid=35259083", "title": "Oxford Philosophical Club", "text": "Oxford Philosophical Club\n\nThe Oxford Philosophical Club refers to a group of natural philosophers, mathematicians, physicians, virtuosi and dilettanti gathering around John Wilkins FRS (1614–1672) at Oxford in the period 1649 to 1660. It is documented in particular by John Aubrey: he refers to it as an \"experimental philosophical club\" run weekly by Wilkins, who successfully bridged the political divide of the times. There is surviving evidence that the Club was formally constituted, and undertook some projects in Oxford libraries. Its historical importance is that members formed one of the major groups that came together in the early 1660s to form the Royal Society of London.\n\nWilkins was Warden of Wadham College, and the circle around him is also known as the Wadham Group, though it was not restricted to members of the College. It included William Petty, Jonathan Goddard and John Wallis from the 1645 group in London.\n\nThe term Oxford Philosophical Society may refer to this club, or at least two later societies.\n\nA number of the Club's leading members showed a united front in opposition to Thomas Hobbes, from 1654, as they resisted external pressures for university reform. In the longer term the Hobbes-Wallis controversy developed out of the \"Vindiciae academiarum\" (1654) of Wilkins and Seth Ward. Generally Wilkins with Goddard and a few other allies were active on the traditionalist side of the debates on academia of the time, a point emphasised later by Thomas Sprat and Walter Pope, as well as trying to keep a calm approach on divisive issues. Wilkins and Ward sympathised with Puritan views, as followers of the line of John Conant, but not with the wish for open theological clashes. One of the aims of the group was in theology, however: to develop a natural philosophy which would be at the same time \"mechanical\" and providential.\n\nThose attracted to Oxford directly by the presence of Wilkins include Ward, William Neile, Laurence Rooke, and Christopher Wren. Others who became involved were Ralph Bathurst, Thomas Willis, and Matthew Wren. Robert Boyle moved to Oxford in 1655/6 and joined the group; when Wilkins moved to Cambridge in 1659 Boyle accommodated the continuing meetings. Around 1652 Wilkins was very active on behalf of the club and Wadham as a scientific centre, bringing in technical expertise including that of Ralph Greatorex, and finding ways to finance equipment. Eventually Wadham had a laboratory area. Wilkins continued to assemble his group, and it came to include also Richard Lower, his relation Walter Pope, William Holder, and Nathaniel Hodges. Robert Hooke became involved, through his work for Willis and then Boyle. It has been suggested that Daniel Coxe was also linked to the club in the later 1650s.\n"}
{"id": "23012", "url": "https://en.wikipedia.org/wiki?curid=23012", "title": "Philosophical methodology", "text": "Philosophical methodology\n\nPhilosophical method (or philosophical methodology) is the study of how to do philosophy. A common view among philosophers is that philosophy is distinguished by the ways that philosophers follow in addressing philosophical questions. There is not just one method that philosophers use to answer philosophical questions.\n\nSystematic philosophy attempts to provide a framework in reason that can explain all questions and problems related to human life. Examples of systematic philosophers include Plato, Aristotle, Descartes, Spinoza, and Hegel. In many ways, any attempts to formulate a philosophical method that provides the ultimate constituents of reality, a metaphysics, can be considered systematic philosophy. In modern philosophy the reaction to systematic philosophy began with Kierkegaard and continued in various forms through analytic philosophy, existentialism, hermeneutics, and deconstructionism.\n\nSome common features of the methods that philosophers follow (and discuss when discussing philosophical method) include:\n\n\nPlato said that \"philosophy begins in wonder\", a view which is echoed by Aristotle: \"It was their wonder, astonishment, that first led men to philosophize and still leads them.\" Philosophizing may begin with some simple doubts about accepted beliefs. The initial impulse to philosophize may arise from suspicion, for example that we do not fully understand, and have not fully justified, even our most basic beliefs about the world.\n\nAnother element of philosophical method is to formulate questions to be answered or problems to be solved. The working assumption is that the more clearly the question or problem is stated, the easier it is to identify critical issues.\n\nA relatively small number of major philosophers prefer not to be quick, but to spend more time trying to get extremely clear on what the problem is all about.\n\nAnother approach is to enunciate a theory, or to offer a definition or analysis, which constitutes an attempt to solve a philosophical problem. Sometimes a philosophical theory by itself can be stated quite briefly. All the supporting philosophical text is offered by way of hedging, explanation, and argument.\n\nNot all proposed solutions to philosophical problems consist of definitions or generalizations. Sometimes, what is called for, is a certain sort of explanation — not a causal explanation, but an explanation for example of how two different views, which seem to be contrary to one another, can be held at the same time, consistently. One can call this a philosophical explanation.\n\nAn argument is a set of statements, one of which (the conclusion), it is said or implied, follows from the others (the premises). One might think of arguments as bundles of reasons — often not just a list, but logically interconnected statements — followed by the claim they are reasons for. The reasons are the premises, the claim they support is the conclusion; together they make an argument.\n\nPhilosophical arguments and justifications are another important part of philosophical method. It is rare to find a philosopher, particularly in the Western philosophical tradition, who lacks many arguments. Philosophers are, or at least are expected to be, very good at giving arguments. They constantly demand and offer arguments for different claims they make. This therefore indicates that philosophy is a quest for arguments.\n\nA good argument — a clear, organized, and sound statement of reasons — may ultimately cure the original doubts that motivated us to take up philosophy. If one is willing to be satisfied without any good supporting reasons, then a Western philosophical approach may not be what one actually requires.\n\nIn philosophy concerning the most fundamental aspects of the universe, the experts all disagree. It follows that another element of philosophical method, common in the work of nearly all philosophers, is philosophical criticism. It is this that makes much philosophizing a social endeavor.\n\nPhilosophers offer definitions and explanations in solution to problems; they argue for those solutions; and then other philosophers provide counter arguments, expecting to eventually come up with better solutions. This exchange and resulting revision of views is called dialectic. Dialectic (in one sense of this history-laden word) is simply philosophical conversation amongst people who do not always agree with each other about everything.\n\nOne can do this sort of harsh criticism on one's own, but others can help greatly, if important assumptions are shared with the person offering the criticisms. Others are able to think of criticisms from another perspective.\n\nSome philosophers and ordinary people dive right in and start trying to solve the problem. They immediately start giving arguments, pro and con, on different sides of the issue. Doing philosophy is different from this. It is about questioning assumptions, digging for deeper understanding. Doing philosophy is about the journey, the process, as much as it is about the destination, the conclusion. Its method differs from other disciplines, in which the experts can agree about most of the fundamentals.\n\nMethod in philosophy is in some sense rooted in motivation, only by understanding why people take up philosophy can one properly understand what philosophy is. People often find themselves believing things that they do not understand. For example, about God, themselves, the natural world, human society, morality and human productions. Often, people fail to understand what it is they believe, and fail to understand the reasons they believe in what they do. Some people have questions about the meaning of their beliefs and questions about the justification (or rationality) of their beliefs. A lack of these things shows a lack of understanding, and some dislike not having this understanding.\n\nThese questions are only the tip of the philosophical iceberg. There are many other things about this universe about which people are also fundamentally ignorant. Philosophers are in the business of investigating all sorts of those areas of ignorance.\n\nA bewilderingly huge number of basic concepts are poorly understood. For example:\n\nOne might also consider some of the many questions about justification. Human lives are deeply informed with many basic assumptions. Different assumptions would lead to different ways of living.\n\n\n"}
{"id": "39098", "url": "https://en.wikipedia.org/wiki?curid=39098", "title": "Physical law", "text": "Physical law\n\nA physical law or a law of physics is a statement \"inferred from particular facts, applicable to a defined group or class of phenomena, and expressible by the statement that a particular phenomenon always occurs if certain conditions be present.\" Physical laws are typically conclusions based on repeated scientific experiments and observations over many years and which have become accepted universally within the scientific community. The production of a summary description of our environment in the form of such laws is a fundamental aim of science. These terms are not used the same way by all authors.\n\nThe distinction between natural law in the political-legal sense and law of nature or physical law in the scientific sense is a modern one, both concepts being equally derived from \"physis\", the Greek word (translated into Latin as \"natura\") for \"nature\".\n\nSeveral general properties of physical laws have been identified. Physical laws are:\n\n\nSome of the more famous laws of nature are found in Isaac Newton's theories of (now) classical mechanics, presented in his \"Philosophiae Naturalis Principia Mathematica\", and in Albert Einstein's theory of relativity. Other examples of laws of nature include Boyle's law of gases, conservation laws, the four laws of thermodynamics, etc.\n\nMany scientific laws are couched in mathematical terms (e.g. Newton's Second law \"F\" = , or the uncertainty principle, or the principle of least action, or causality). While these scientific laws explain what our senses perceive, they are still empirical, and so are not \"mathematical\" laws. (Mathematical laws can be proved purely by mathematics and not by scientific experiment.)\n\nOther laws reflect mathematical symmetries found in Nature (say, Pauli exclusion principle reflects identity of electrons, conservation laws reflect homogeneity of space, time, Lorentz transformations reflect rotational symmetry of space–time). Laws are constantly being checked experimentally to higher and higher degrees of precision. This is one of the main goals of science. Just because laws have never been observed to be violated does not preclude testing them at increased accuracy or in new kinds of conditions to confirm whether they continue to hold, or whether they break, and what can be discovered in the process. It is always possible for laws to be invalidated or proven to have limitations, by repeatable experimental evidence, should any be observed.\n\nWell-established laws have indeed been invalidated in some special cases, but the new formulations created to explain the discrepancies can be said to generalize upon, rather than overthrow, the originals. That is, the invalidated laws have been found to be only close approximations (see below), to which other terms or factors must be added to cover previously unaccounted-for conditions, e.g. very large or very small scales of time or space, enormous speeds or masses, etc. Thus, rather than unchanging knowledge, physical laws are better viewed as a series of improving and more precise generalizations.\n\nMany fundamental physical laws are mathematical consequences of various symmetries of space, time, or other aspects of nature. Specifically, Noether's theorem connects some conservation laws to certain symmetries. For example, conservation of energy is a consequence of the shift symmetry of time (no moment of time is different from any other), while conservation of momentum is a consequence of the symmetry (homogeneity) of space (no place in space is special, or different than any other). The indistinguishability of all particles of each fundamental type (say, electrons, or photons) results in the Dirac and Bose quantum statistics which in turn result in the Pauli exclusion principle for fermions and in Bose–Einstein condensation for bosons. The rotational symmetry between time and space coordinate axes (when one is taken as imaginary, another as real) results in Lorentz transformations which in turn result in special relativity theory. Symmetry between inertial and gravitational mass results in general relativity.\n\nThe inverse square law of interactions mediated by massless bosons is the mathematical consequence of the 3-dimensionality of space.\n\nOne strategy in the search for the most fundamental laws of nature is to search for the most general mathematical symmetry group that can be applied to the fundamental interactions.\n\nSome laws are only approximations of other more general laws, and are good approximations with a restricted domain of applicability. For example, Newtonian dynamics (which is based on Galilean transformations) is the low-speed limit of special relativity (since the Galilean transformation is the low-speed approximation to the Lorentz transformation). Similarly, the Newtonian gravitation law is a low-mass approximation of general relativity, and Coulomb's law is an approximation to Quantum Electrodynamics at large distances (compared to the range of weak interactions). In such cases it is common to use the simpler, approximate versions of the laws, instead of the more accurate general laws.\n\nCompared to pre-modern accounts of causality, laws of nature fill the role played by divine causality on the one hand, and accounts such as Plato's theory of forms on the other.\n\nThe observation that there are underlying regularities in nature dates from prehistoric times, since the recognition of cause-and-effect relationships is an implicit recognition that there are laws of nature. The recognition of such regularities as independent scientific laws \"per se\", though, was limited by their entanglement in animism, and by the attribution of many effects that do not have readily obvious causes—such as meteorological, astronomical and biological phenomena—to the actions of various gods, spirits, supernatural beings, etc. Observation and speculation about nature were intimately bound up with metaphysics and morality.\n\nIn Europe, systematic theorizing about nature (\"physis\") began with the early Greek philosophers and scientists and continued into the Hellenistic and Roman imperial periods, during which times the intellectual influence of Roman law increasingly became paramount.The formula \"law of nature\" first appears as \"a live metaphor\" favored by Latin poets Lucretius, Virgil, Ovid, Manilius, in time gaining a firm theoretical presence in the prose treatises of Seneca and Pliny. Why this Roman origin? According to [historian and classicist Daryn] Lehoux's persuasive narrative, the idea was made possible by the pivotal role of codified law and forensic argument in Roman life and culture.\n\nFor the Romans . . . the place par excellence where ethics, law, nature, religion and politics overlap is the law court. When we read Seneca's \"Natural Questions\", and watch again and again just how he applies standards of evidence, witness evaluation, argument and proof, we can recognize that we are reading one of the great Roman rhetoricians of the age, thoroughly immersed in forensic method. And not Seneca alone. Legal models of scientific judgment turn up all over the place, and for example prove equally integral to Ptolemy's approach to verification, where the mind is assigned the role of magistrate, the senses that of disclosure of evidence, and dialectical reason that of the law itself.\n\nThe precise formulation of what are now recognized as modern and valid statements of the laws of nature dates from the 17th century in Europe, with the beginning of accurate experimentation and development of advanced forms of mathematics. During this period, natural philosophers such as Isaac Newton were influenced by a religious view which held that God had instituted absolute, universal and immutable physical laws. In chapter 7 of \"The World\", René Descartes described \"nature\" as matter itself, unchanging as created by God, thus changes in parts \"are to be attributed to nature. The rules according to which these changes take place I call the 'laws of nature'.\" The modern scientific method which took shape at this time (with Francis Bacon and Galileo) aimed at total separation of science from theology, with minimal speculation about metaphysics and ethics. Natural law in the political sense, conceived as universal (i.e., divorced from sectarian religion and accidents of place), was also elaborated in this period (by Grotius, Spinoza, and Hobbes, to name a few).\n\nSome mathematical theorems and axioms are referred to as laws because they provide logical foundation to empirical laws.\n\nExamples of other observed phenomena sometimes described as laws include the Titius–Bode law of planetary positions, Zipf's law of linguistics, Moore's law of technological growth. Many of these laws fall within the scope of uncomfortable science. Other laws are pragmatic and observational, such as the law of unintended consequences. By analogy, principles in other fields of study are sometimes loosely referred to as \"laws\". These include Occam's razor as a principle of philosophy and the Pareto principle of economics.\n\n\n\n"}
{"id": "23476", "url": "https://en.wikipedia.org/wiki?curid=23476", "title": "Plea bargain", "text": "Plea bargain\n\nThe plea bargain (also plea agreement or plea deal) is any agreement in a criminal case between the prosecutor and defendant whereby the defendant agrees to plead guilty or nolo contendere to a particular charge in return for some concession from the prosecutor. This may mean that the defendant will plead guilty to a less serious charge, or to one of the several charges, in return for the dismissal of other charges; or it may mean that the defendant will plead guilty to the original criminal charge in return for a more lenient sentence.\n\nA plea bargain allows both parties to avoid a lengthy criminal trial and may allow criminal defendants to avoid the risk of conviction at trial on a more serious charge. For example, in the U.S. legal system, a criminal defendant charged with a felony theft charge, the conviction of which would require imprisonment in state prison, may be offered the opportunity to plead guilty to a misdemeanor theft charge, which may not carry a custodial sentence.\n\nIn cases such as an automobile collision when there is a potential for civil liability against the defendant, the defendant may agree to plead no contest or \"guilty with a civil reservation\", which essentially is a guilty plea without admitting civil liability.\n\nPlea bargaining can present a dilemma to defense attorneys, in that they must choose between vigorously seeking a good deal for their present client, or maintaining a good relationship with the prosecutor for the sake of helping future clients. However, defense attorneys are required by the ethics of the bar to defend the present client's interests over the interests of others. Violation of this rule may result in disciplinary sanctions being imposed against the defense attorney by the appropriate state's bar association.\n\nIn charge bargaining, defendants plead guilty to a less serious crime than the original charge. In count bargaining, they plead guilty to a subset of multiple original charges. In sentence bargaining, they plead guilty agreeing in advance what sentence will be given; however, this sentence can still be denied by the judge. In fact bargaining, defendants plead guilty but the prosecutor agrees to stipulate (i.e., to affirm or concede) certain facts that will affect how the defendant is punished under the sentencing guidelines.\n\nPlea bargaining has been defended as a voluntary exchange that leaves both parties better off, in that defendants have many procedural and substantive rights, but by pleading guilty, defendants \"sell\" these rights to the prosecutor. For a defendant who believes that conviction is almost certain, a discount to the sentence is more useful than an unlikely chance of acquittal. For the prosecutor, it means that a conviction is guaranteed. By allowing a quicker trial, it saves money and resources for the courts and prosecutors. It also means that victims and witnesses do not have to testify at the trial, which in some cases can be traumatic.\n\nPlea bargaining is criticized, particularly outside the United States, on the grounds that its close relationship with rewards, threats and coercion potentially endanger the correct legal outcome.\n\nAuthor Martin Yant discusses the use of coercion in plea bargaining:\n\nEven when the charges are more serious, prosecutors often can still bluff defense attorneys and their clients into pleading guilty to a lesser offense. As a result, people who might have been acquitted because of lack of evidence, but also who are in fact truly innocent, will often plead guilty to the charge. Why? In a word, fear. And the more numerous and serious the charges, studies have shown, the greater the fear. That explains why prosecutors sometimes seem to file every charge imaginable against defendants.\n\nThis tactic is prohibited in some other countries—for example in the United Kingdom the prosecutor's code states:\n\nProsecutors should never go ahead with more charges than are necessary just to encourage a defendant to plead guilty to a few. In the same way, they should never go ahead with a more serious charge just to encourage a defendant to plead guilty to a less serious one.\n\nalthough it adds that in some kinds of complex cases such as major fraud trials:\n\nThe over-riding duty of the prosecutor is ... to see that justice is done. The procedures must command public and judicial confidence. Many defendants in serious and complex fraud cases are represented by solicitors experienced in commercial litigation, including negotiation. This means that the defendant is usually protected from being put under improper pressure to plead. The main danger to be guarded against in these cases is that the prosecutor is persuaded to agree to a plea or a basis that is not in the public interest and interests of justice because it does not adequately reflect the seriousness of the offending ... Any plea agreement must reflect the seriousness and extent of the offending and give the court adequate sentencing powers. It must consider the impact of an agreement on victims and also the wider public, whilst respecting the rights of defendants.\n\nJohn H. Langbein argues that the modern American system of plea bargaining is comparable to the medieval European system of torture:\nThere is, of course, a difference between having your limbs crushed if you refuse to confess, or suffering some extra years of imprisonment if you refuse to confess, but the difference is of degree, not kind. Plea bargaining, like torture, is coercive. Like the medieval Europeans, the Americans are now operating a procedural system that engages in condemnation without adjudication.\n\nTheoretical work based on the prisoner's dilemma is one reason that, in many countries, plea bargaining is forbidden. Often, precisely the prisoner's dilemma scenario applies: it is in the interest of both suspects to confess and testify against the other suspect, irrespective of the innocence of the accused. Arguably, the worst case is when only one party is guilty: here, the innocent one has no incentive to confess, while the guilty one has a strong incentive to confess and give testimony (including \"false\" testimony) against the innocent.\n\nA 2009 study by the European Association of Law and Economics observed that innocent defendants are consistently more likely than guilty defendants to reject otherwise-favorable pleas proposals, even when theoretically disadvantageous to do so, because of perceived unfairness, and would do so even if the expected sanction would be worse if they proceeded to trial. The study concluded that \"[t]his somewhat counterintuitive 'cost of innocence', where the preferences of innocents lead them collectively to fare worse than their guilty counterparts, is further increased by the practice of imposing much harsher sentences at trial on defendants who contest the charges. This 'trial penalty' seeks to facilitate guilty pleas by guilty defendants [...and ironically...] disproportionately, collectively, penalizes innocents, who reject on fairness grounds some offers their guilty counterparts accept.\"\n\nThe extent to which innocent people will accept a plea bargain and plead guilty is contentious and has been subjected to considerable research. Much research has focused on the relatively few actual cases where innocence was subsequently proven, such as successful appeals for murder and rape based upon DNA evidence, which tend to be atypical of trials as a whole (being by their nature only the most serious kinds of crime). Other studies have focused on presenting hypothetical situations to subjects and asking what choice they would make. More recently some studies have attempted to examine actual reactions of innocent persons generally, when faced with actual plea bargain decisions. A study by Dervan and Edkins (2013) attempted to recreate a real-life controlled plea bargain situation, rather than merely asking theoretical responses to a theoretical situation—a common approach in previous research. It placed subjects in a situation where an accusation of academic fraud (cheating) could be made, of which some subjects were in fact by design actually guilty (and knew this), and some were innocent but faced seemingly strong evidence of guilt and no verifiable proof of innocence. Each subject was presented with the evidence of guilt and offered a choice between facing an academic ethics board and potentially a heavy penalty in terms of extra courses and other forfeits, or admitting guilt and accepting a lighter \"sentence\". The study found that as expected from court statistics, around 90% of accused subjects who were actually guilty chose to take the plea-bargain and plead guilty. It also found that around 56% of subjects who were actually innocent (and privately knew it) also to take the plea-bargain and plead guilty, for reasons including avoiding formal quasi-legal processes, uncertainty, possibility of greater harm to personal future plans, or deprivation of home environment due to remedial courses. The authors stated:\n\nPrevious research has argued that the innocence problem is minimal because defendants are risk-prone and willing to defend themselves before a tribunal. Our research, however, demonstrates that when study participants are placed in real, rather than hypothetical, bargaining situations and are presented with accurate information regarding their statistical probability of success, just as they might be so informed by their attorney or the government during a criminal plea negotiation, innocent defendants are highly risk-averse.\n\nMore pressure to plea bargain may be applied in weak cases (where there is less certainty of both guilt and jury conviction) than strong cases. Prosecutors tend to be strongly motivated by conviction rates, and \"there are many indications that prosecutors are willing to go a long way to avoid losing cases, [and that] when prosecutors decide to proceed with such weak cases they are often willing to go a long way to assure that a plea bargain is struck\". Prosecutors often have great power to procure a desired level of incentive, as they select the charges to be presented. For this reason,\n\n[P]lea bargains are just as likely in strong and weak cases. Prosecutors only need to adjust the offer to the probability of conviction in order to reach an agreement. Thus, weaker cases result in more lenient plea bargains, and stronger ones in relative harshness, but both result in an agreement. [... W]hen the case is weak, the parties must rely on charge bargaining ... But [charge bargaining] is hardly an obstacle. Charge bargaining in weak cases is not the exception; it is the norm all around the country. Thus, even if the evidence against innocent defendants is, on average, weaker, the likelihood of plea bargains is not dependent on guilt.\n\nAnother situation in which an innocent defendant may plead guilty is in the case of a defendant who cannot raise bail, and who is being held in custody in a jail or detention facility. Because it may take months, or even years, for criminal cases to come to trial or even indictment in some jurisdictions, an innocent defendant who is offered a plea bargain that includes a sentence of less time than he would otherwise spend in jail awaiting an indictment or a trial may choose to accept the plea arrangement and plead guilty.\n\nAgency problems sometimes arise in plea bargaining in that although the prosecutor represents the people and the defense attorney represents the defendant, these agents' goals may be far from congruent with those of their principals. Moreover, prosecutors and defense attorneys often view each other as colleagues and generally wish to maintain good relations with one another. A defense attorney often receives a flat fee or in any event will not receive enough additional money if he goes to trial to cover the costs of doing so; this can create an incentive to plea bargain, even at the expense of the defense attorney's client's interests.\n\nOn the other hand, the prosecutor may wish to maintain a high conviction rate and avoid losing high-profile trials; thus, settling a case by plea bargain may further his interests, even if the resulting sentence would not effectively deter crime. As many crimes have very narrow sentencing bands, a prosecutor often has scope to propose whatever degree of \"discounted\" charges, or substitution of misdemeanor rather than felony charges, to whatever extent they believe would incentivise a defendant to make a guilty plea and accept a speedy conviction, regardless of actual guilt.\n\nAnother argument against plea bargaining is that it may not actually reduce the costs of administering justice. For example, if a prosecutor has only a 25% chance of winning his case and sending the defendant away to prison for 10 years, he may make a plea agreement for a sentence of one year; but if plea bargaining is unavailable, a prosecutor may drop the case completely.\n\nPlea bargaining is a significant part of the criminal justice system in the United States; the vast majority (roughly 90%) of criminal cases in the United States are settled by plea bargain rather than by a jury trial. Plea bargains are subject to the approval of the court, and different States and jurisdictions have different rules. The Federal Sentencing Guidelines are followed in federal cases and have been created to ensure a standard of uniformity in all cases decided in the federal courts. A two- or three-level offense level reduction is usually available for those who accept responsibility by not holding the prosecution to the burden of proving its case; this usually amounts to a complete sentence reduction had they gone to trial and lost.\n\nThe Federal Rules of Criminal Procedure provide for two main types of plea agreements. An 11(c)(1)(B) agreement does not bind the court; the prosecutor's recommendation is merely advisory, and the defendant cannot withdraw his plea if the court decides to impose a sentence other than what was stipulated in the agreement. An 11(c)(1)(C) agreement, however, binds the court once the court accepts the agreement. When such an agreement is proposed, the court can reject it if it disagrees with the proposed sentence, in which case the defendant has an opportunity to withdraw his plea.\n\nPlea bargains are so common in the Superior Courts of California (the general trial courts) that the Judicial Council of California has published an optional seven-page form (containing all mandatory advisements required by federal and state law) to help prosecutors and defense attorneys reduce such bargains into written plea agreements.\n\nCertain aspects of the American justice system serve to promote plea bargaining. For example, the adversarial nature of the U.S. criminal justice system puts judges in a passive role, in which they have no independent access to information with which to assess the strength of the case against the defendant. The prosecutor and defense may thus control the outcome of a case through plea bargaining. The court must approve a plea bargain as being within the interests of justice.\n\nThe lack of compulsory prosecution also gives prosecutors greater discretion as well as the inability of crime victims to mount a private prosecution and their limited ability to influence plea agreements. Defendants who are held in custody—who either do not have the right to bail or cannot afford bail, or who do not qualify for release on their own recognizance—may get out of jail immediately following the judge’s acceptance of a plea.\n\nGenerally, once a plea bargain is made and accepted by the courts, the matter is final and cannot be appealed. However, a defendant may withdraw his plea for certain legal reasons, and a defendant may agree to a \"conditional\" plea bargain, whereby s/he pleads guilty and accepts a sentence, but reserves the right to appeal a specific matter (such as violation of a constitutional right). If the defendant does not win on appeal the agreement is carried out; if the defendant is successful on appeal the bargain is terminated. The defendant in \"Doggett v. United States\" made such a bargain, reserving the right to appeal solely on the grounds that he was not given a speedy trial as required by the United States Constitution; Doggett's claim was upheld by the United States Supreme Court and he was freed.\n\nIn Canada, the courts always have the final say with regard to sentencing. Nevertheless, plea bargaining has become an accepted part of the criminal justice system although judges and Crown attorneys are often reluctant to refer to it as such. In most Canadian criminal proceedings, the Crown has the ability to recommend a lighter sentence than it would seek following a guilty verdict in exchange for a guilty plea.\n\nLike other common law jurisdictions, the Crown can also agree to withdraw some charges against the defendant in exchange for a guilty plea. This has become standard procedure for certain offences such as impaired driving. Note that in the case of hybrid offences, the Crown must make a binding decision as to whether to proceed summarily or by indictment prior to the defendant making his or her plea. If the Crown elects to proceed summarily and the defendant then pleads not guilty, the Crown cannot change its election. Therefore, the Crown is not in a position to offer to proceed summarily in exchange for a guilty plea.\n\nCanadian judges are not bound by the Crown's sentencing recommendations and could impose harsher (or more lenient) penalties. Therefore, the Crown and the defence will often make a \"joint submission\" with respect to sentencing. While a joint submission can entail both the Crown and defence recommending exactly the same disposition of a case, this is not common except in cases that are sufficiently minor that the Crown is willing to recommend a discharge. In more serious cases, a joint submission normally call for a sentence within relatively narrow range, with the Crown arguing for a sentence at the upper end of the range and the defence arguing for a sentence at the lower end, so as to maintain the visibility of the judge's ability to exercise discretion.\n\nJudges are not bound to impose a sentence within the range of a joint submission, and a judge's disregard for a joint submission is not in itself grounds for the sentence to be altered on appeal. However, if a judge routinely disregards joint submissions, that judge would compromise the ability of the Crown to offer meaningful incentives for defendants to plead guilty. Defence lawyers would become reluctant to enter into joint submissions if they were thought to be of little value with a particular judge, which would thus result in otherwise avoidable trials. For these reasons, Canadian judges will normally impose a sentence within the range of any joint submission.\n\nFollowing a Supreme Court of Canada ruling that imposes strict time limits on the resolution of criminal cases (eighteen months for cases in provincial court and thirty months for cases in Superior Court), several provinces have initiated and/or intensified measures intended to maximize the number of minor criminal cases resolved by a plea bargain.\n\nLargely unique to the Canadian justice system is that further negotiations concerning the final disposition of a criminal case may also arise even after a sentence has been passed. This is because in Canada the Crown has (by common law standards) a very broad right to appeal acquittals, and also a right to appeal for harsher sentences except in cases where the sentence imposed was maximum allowed. Therefore, in Canada, after sentencing the defence sometimes has an incentive to try and persuade the Crown to not appeal a case, in exchange for the defence also declining to appeal. While, strictly speaking, this is not plea bargaining, it is done for largely the same reasons.\n\nPlea bargaining is permitted in the legal system of England and Wales. The guidelines by the Sentencing Council require that the discount it gives to the sentence are determined by the timing of the plea and no other factors. The guidelines state that the earlier the guilty plea is entered, the greater the discount to the sentence. The maximum discount permitted is one third, for a plea entered at the earliest stage. There is no minimum discount; a guilty plea entered on the first proper day of the trial would be expected provide a discount of one tenth. The discount can sometimes involve changing the type of punishment, such as substituting a prison sentence for community service.\n\nPlea bargaining in Magistrates' Court trials is permitted only to the extent that the prosecutors and the defence can agree that the defendant will plead guilty to some charges and the prosecutor will drop the remainder. However, although this is not conducting a plea bargain, in cases before the Crown Court, the defence can request an indication from the judge of the likely maximum sentence that would be imposed should the defendant decide to plead guilty.\n\nIn the case of hybrid offences in England and Wales, the decision whether to deal with a case in Magistrates Court or Crown Court is not made by magistrates until after a plea has been entered. A defendant is thus unable to plead guilty in exchange for having a case dealt with in Magistrates' Court (which has lesser sentencing powers).\n\nPlea bargaining was introduced in India by \"The Criminal Law (Amendment) Act, 2005\", which amended the Code of Criminal Procedure and introduced a new chapter XXI(A) in the code, enforceable from July 5, 2006. It allows plea bargaining for cases in which the maximum punishment is imprisonment for 7 years; however, offenses affecting the socio-economic condition of the country and offenses committed against a woman or a child below 14 are excluded.\n\nIn 2007, Sakharam Bandekar case became the first such case in India where the accused Sakharam Bandekar requested lesser punishment in return for confessing to his crime (using plea bargaining). However, the court rejected his plea and accepted CBI's argument that the accused was facing serious charges of corruption. Finally, the court convicted Bandekar and sentenced him to 3 years imprisonment.\n\nPlea bargain as a formal legal provision was introduced in Pakistan by the National Accountability Ordinance 1999, an anti-corruption law. A special feature of this plea bargain is that the accused applies for it, accepting guilt, and offers to return the proceeds of corruption as determined by investigators/prosecutors. After an endorsement by the Chairman National Accountability Bureau, the request is presented before the court, which decides whether it should be accepted or not. If the request for plea bargain is accepted by the court, the accused stands convicted but neither is sentenced if in trial nor undergoes any sentence previously pronounced by a lower court if in appeal. The accused is disqualified to take part in elections, hold any public office, or obtain a loan from any bank; the accused is also dismissed from service if a government official.\n\nIn other cases, formal plea bargains in Pakistan are limited, but the prosecutor has the authority to drop a case or a charge in a case and, in practice, often does so, in return for a defendant pleading guilty on some lesser charge. No bargaining takes place over the penalty, which is the court's sole privilege.\n\nIn some common law jurisdictions, such as Singapore and the Australian state of Victoria, plea bargaining is practiced only to the extent that the prosecution and the defense can agree that the defendant will plead guilty to some charges and/or to reduced charges in exchange for the prosecutor withdrawing the remaining and/or more serious charges. In New South Wales, a 10-25% discount on the sentence is customarily given in exchange for an early guilty plea, but this concession is expected to be granted by the judge as a way of recognizing the utilitarian value of an early guilty plea to the justice system - it is never negotiated with a prosecutor. The courts in these jurisdictions have made it plain that they will always decide what the appropriate penalty is to be. No bargaining takes place between the prosecution and the defence over criminal penalties.\n\nPlea bargaining is extremely difficult in jurisdictions based on the civil law. This is because unlike common law systems, civil law systems have no concept of plea—if the defendant confesses; a confession is entered into evidence, but the prosecution is not absolved of the duty to present a full case. A court may decide that a defendant is innocent even though they presented a full confession. Also, unlike common law systems, prosecutors in civil law countries may have limited or no power to drop or reduce charges after a case has been filed, and in some countries their power to drop or reduce charges \"before\" a case has been filed is limited, making plea bargaining impossible. Since the 1980s, many civil law nations have adapted their systems to allow for plea bargaining.\n\nIn 2013 Brazil passed a law allowing plea bargains, which have been used in the political corruption trials taking place since then.\n\nIn the Central African Republic, witchcraft carries heavy penalties but those accused of it typically confess in exchange for a modest sentence.\n\nIn China, a plea bargaining pilot scheme has been introduced by the Standing Committee of the National People's Congress in 2016. For defendants that faces jail terms of three years or below, agrees to plea guilty voluntarily and agree with prosecutors' crime and sentencing proposals, will be given mitigated punishments.\n\nIn 2009, in a case about whether witness testimony originating from a plea deal in the United States was admissible in a Danish criminal trial \"(297/2008 H)\", the Supreme Court of Denmark (Danish: Højesteret) unanimously ruled that plea bargains are \"prima facie\" not legal under Danish law, but that the witnesses in the particular case would be allowed to testify regardless (with the caveat that the lower court consider the possibility that the testimony was untrue or at least influenced by the benefits of the plea bargain). The Supreme Court did however point out that Danish law contains mechanisms similar to plea bargains, such as of the Danish Penal Code (Danish: Straffeloven) which states that a sentence may be reduced if the perpetrator of a crime provides information that helps solve a crime perpetrated by others, or of the Danish Competition Law (Danish: Konkurrenceloven) which states that someone can apply to avoid being fined or prosecuted for participating in a cartel if they provide information about the cartel that the authorities did not know at the time.\n\nIf a defendant admits to having committed a crime, the prosecution doesn't have to file charges against them, and the case can be heard as a so-called \"admission case\" (Danish: tilståelsessag) under of the Law on the Administration of Justice (Danish: Retsplejeloven) provided that: the confession is supported by other pieces of evidence (meaning that a confession is not enough to convict someone on its own); both the defendant and the prosecutor consent to it; the court does not have any objections; §§ 68, 69, 70 and 73 of the Penal Code do not apply to the case.\n\nIn Estonia, plea bargaining was introduced in the 1990s: the penalty is reduced in exchange for confession and avoiding most of the court proceedings. Plea bargaining is permitted for the crimes punishable by no more than four years of imprisonment. Normally, a 25% reduction of the penalty is given.\n\nThe introduction of a limited form of plea bargaining (\"comparution sur reconnaissance préalable de culpabilité\" or CRPC, often summarized as \"plaider coupable\") in 2004 was highly controversial in France. In this system, the public prosecutor could propose to suspects of relatively minor crimes a penalty not exceeding one year in prison; the deal, if accepted, had to be accepted by a judge. Opponents, usually lawyers and leftist political parties, argued that plea bargaining would greatly infringe on the rights of defense, the long-standing constitutional right of presumption of innocence, the rights of suspects in police custody, and the right to a fair trial.\n\nFor instance, Robert Badinter argued that plea bargaining would give too much power to the public prosecutor and would encourage defendants to accept a sentence only to avoid the risk of a bigger sentence in a trial, even if they did not really deserve it. Only a minority of criminal cases are settled by that method: in 2009, 77,500 out of the 673,700 or 11.5% of the decisions by the correctional courts.\n\nPlea bargaining (Georgian: საპროცესო შეთანხმება, literally \"plea agreement\") was introduced in Georgia in 2004. The substance of the Georgian plea bargaining is similar to the United States and other common law jurisdictions.\n\nA plea bargaining, also called a plea agreement or negotiated plea, is an alternative and consensual way of criminal case settlement. A plea agreement means settlement of case without main hearing when the defendant agrees to plead guilty in exchange for a lesser charge or for a more lenient sentence and/or for dismissal of certain related charges. (Article 209 of the Criminal Procedure Code of Georgia)\n\nThe main principle of the plea bargaining is that it must be based on the free will of the defendant, equality of the parties and advanced protection of the rights of the defendant:\na) In order to avoid fraud of the defendant or insufficient consideration of his/her interests, legislation foresees obligatory participation of the defense council; (Article 210 of the Criminal Procedure Code of Georgia)<br>\nb) The defendant has the right to reject the plea agreement on any stage of the criminal proceedings before the court renders the judgment. (Article 213 of the Criminal Procedure Code of Georgia)<br>\nc) In case of refusal, it is prohibited to use information provided by the defendant under the plea agreement against him in the future. (Article 214 of the Criminal Procedure Code of Georgia)<br>\nd) The defendant has the right to appeal the judgment rendered consequent to the plea agreement if the plea agreement was concluded by deception, coercion, violence, threat, or violence. (Article 215 of the Criminal Procedure Code of Georgia)\n\nWhile concluding the plea agreement, the prosecutor is obliged to take into consideration public interest, severity of the penalty, and personal characteristics of the defendant. (Article 210 of the Criminal Procedure Code of Georgia)\nTo avoid abuse of powers, legislation foresees written consent of the supervisory prosecutor as necessary precondition to conclude plea agreement and to amend its provisions. (Article 210 of the Criminal Procedure Code of Georgia)\n\nPlea agreement without the approval of the court doesn’t have the legal effect. \nThe court must satisfy itself that the plea agreement is concluded on the basis of the free will of the defendant, that the defendant fully acknowledges the essence of the plea agreement and its consequences. (Article 212 of the Criminal Procedure Code of Georgia)\n\nGuilty plea of the defendant is not enough to render guilty judgment. (Article 212 of the Criminal Procedure Code of Georgia) Consequently, court is obliged to discuss 2 important issues:\n\na) Whether irrefutable evidence is presented which proves the defendant’s guilt beyond reasonable doubt.<br>\nb) Whether sentence provided for in the plea agreement is legitimate. (Article 212 of the Criminal Procedure Code of Georgia)\nAfter both criteria are satisfied the court additionally checks whether formalities related to the legislative requirements are followed and only then makes decision.\n\nIf the court finds that presented evidence is not sufficient to support the charges or that a motion to render a judgment without substantial consideration of a case is submitted in violation of the requirements stipulated by the Criminal Procedure Code of Georgia, it shall return the case to the prosecution. The court before returning the case to the prosecutor offers the parties to change the terms of the agreement. If the changed terms do not satisfy the court, then it shall return the case to the prosecution. (Article 213 of the Criminal Procedure Code of Georgia)\n\nIf the court satisfies itself that the defendant fully acknowledges the consequences of the plea agreement, and he/she was represented by the defense council, his/her will is expressed in full compliance with the legislative requirements without deception and coercion, also if there is enough body of doubtless evidence for the conviction and the agreement is reached on legitimate sentence - the court approves the plea agreement and renders guilty judgment. If any of the abovementioned requirements are not satisfied, the court rejects to approve the plea agreement and returns the case to the prosecutor. (Article 213 of the Criminal Procedure Code of Georgia)\n\nThe plea agreement is concluded between the parties - the prosecutor and the defendant. Notwithstanding the fact that the victim is not party to the criminal case and the prosecutor is not a tool in the hands of the victim to obtain revenge against the offender, the attitude of the victim in relation to the plea agreement is still important.\n\nUnder Article 217 of the Criminal procedure Code of Georgia, the prosecutor is obliged to consult with the victim prior to concluding the plea agreement and inform him/her about this. In addition, under the Guidelines of the Prosecution Service of Georgia, the prosecutor is obliged to take into consideration the interests of the victim and as a rule conclude the plea agreement after the damage is compensated.\n\nPlea agreements have made a limited appearance in Germany. However, there is no exact equivalent of a guilty plea in German criminal procedure.\n\nItaly has a form of bargaining, popularly known as \"patteggiamento\" but that has a technical name of penalty application under request of the parts. In fact, the bargaining is not about the charges, but about the penalty applied in sentence, reduced up to one third.\n\nWhen the defendant deems that the punishment that would, concretely, be handed down is less than a five-year imprisonment (or that it would just be a fine), the defendant may request to plea bargain with the prosecutor. The defendant is rewarded with a reduction on the sentence and has other advantages (such as that the defendant does not pay the fees on the proceeding). The defendant must accept the penalty for the charges (even if the plea-bargained sentence has some particular matters in further compensation proceedings), no matter how serious the charges are.\n\nSometimes, the prosecutor agrees to reduce a charge or to drop some of multiple charges in exchange for the defendant's acceptance of the penalty. Defendant, in the request, could argue with the penalty and aggravating and extenuating circumstancing with the prosecutor, that can accept or refuse. The request could also be made by the prosecutor. The plea bargaining could be granted if the penalty that could be concretely applied is, after the reduction of one third, inferior to five-year imprisonment (so called \"patteggiamento allargato\", wide bargaining); When the penalty applied, after the reduction of one third, is inferior of two years imprisonment or is only a fine (so called \"patteggiamento ristretto\" limited bargaining), the defendant can have other advantages, like sentence suspended and the effacement of the crime if in five year of the sentence, the defendant doesn't commit a similar crime.\n\nIn the request, when it could be applied the conditional suspension of the penalty according to the article 163 and following of Italian penal code, the defendant could subordinate the request to the grant of the suspension; if the judge rejects the suspension, the bargaining is refused. When both the prosecutor and the defendant have come to an agreement, the proposal is submitted to the judge, who can refuse or accept the plea bargaining.\n\nAccording to Italian law, a bargain doesn't need a guilty plea (in Italy there is no plea declaration); for this reason, a bargaining sentence is only an acceptance of the penalty in exchange with the stop of investigation and trial and has no binding cogency in other trials, especially in civil trials in which parts argue of the same facts at the effects of civil liability and in other criminal trials in which are processed the accomplices of the defendant that had requested and got a bargaining sentence.\n\nPoland also adopted a limited form of plea bargaining, which is applicable only to minor felonies (punishable by no more than 10 years of imprisonment). The procedure is called “voluntary submission to a penalty” and allows the court to pass an agreed sentence without reviewing the evidence, which significantly shortens the trial.\nThere are some specific conditions that have to be simultaneously met:\nHowever, the court may object to the terms of proposed plea agreement (even if already agreed between the defendant, victim and prosecutor) and suggest changes (not specific but rather general). If the defendant accepts these suggestions and changes his penalty proposition, the court approves it and passes the verdict according to the plea agreement. In spite of the agreement, all the parties of the trial: prosecution, defendant and the victim as an auxiliary prosecutor (in Poland, the victim may declare that he wants to act as an \"auxiliary prosecutor\" and consequently gains the rights similar to official prosecutor) - have the right to appeal.\n\nIn Japan, plea bargaining was previously forbidden by law, although sources reported that prosecutors illegally offered defendants plea bargains in exchange for their confessions.\n\nPlea bargaining was introduced in Japan in June 2018. The first case of plea bargaining under this system, in July 2018, involved allegations of bribery by Mitsubishi Hitachi Power Systems in Thailand. The second case was a November 2018 deal to obtain evidence of accounting and securities law violations against Nissan executives Carlos Ghosn and Greg Kelly.\n\n"}
{"id": "1043618", "url": "https://en.wikipedia.org/wiki?curid=1043618", "title": "Predeterminism", "text": "Predeterminism\n\nPredeterminism is the idea that all events are determined in advance. Predeterminism is the philosophy that all events of history, past, present and future, have been already decided or are already known (by God, fate, or some other force), including human actions.\n\nPredeterminism is closely related to determinism. The concept of predeterminism is often argued by invoking causal determinism, implying that there is an unbroken chain of prior occurrences stretching back to the origin of the universe. In the case of predeterminism, this chain of events has been pre-established, and human actions cannot interfere with the outcomes of this pre-established chain. Predeterminism can be used to mean such pre-established causal determinism, in which case it is categorised as a specific type of determinism. It can also be used interchangeably with causal determinism—in the context of its capacity to determine future events. Despite this, predeterminism is often considered as independent of causal determinism. The term predeterminism is also frequently used in the context of biology and hereditary, in which case it represents a form of biological determinism.\n\nPredeterminism is difficult to discuss because its simple definition can logically lead to a variety of similar, complex (and, perhaps, better defined) concepts in metaphysics, theology, and the philosophy of free will. The term \"predeterminism\" suggests not just a determining of all events, but the prior and deliberately conscious determining of all events (therefore done, presumably, by a conscious being). Due to this, predeterminism and the similar term predetermination are easily and often confused or associated with ideas ranging, for instance, from the physicalist (and often scientific) notion of \"causal determinism\" to even the theological (and often religious) notion of \"predestination\".\n\nA secular example to try to illustrate predeterminism is that a fetus's future physical, emotional, and other personal characteristics as a matured human being may be considered \"predetermined\" by heredity, i.e. derived from a chain of events going back long before her eventual birth. However, one of the difficulties with defining predeterminism using this example is that the word \"predetermine\" necessarily implies a conscious being \"doing\" the determining ahead of time. With regards to predetermined heredity, a conscious being (perhaps a genetic scientist) is presumed to be the one speculating on what the fetus's personal characteristics will turn out to be, for example, based on looking at the genomes of the fetus and its ancestors. If there were not this conscious entity, the scientist, then one could say merely that the fetus's characteristics are \"determined\" by heredity, rather than \"pre\"determined. Predeterminism necessarily implies, at the very least, a passive but all-knowing observer, if not an active planner, designer, or manipulator (of the fetus's personal characteristics). This basic scientific idea of hereditary determination, though, already fulfills the definition of causal determinism, a metaphysical concept.\n\nWhile determinism usually refers to a naturalistically explainable causality of events, predeterminism seems by definition to suggest a person or a \"someone\" who is controlling or planning the causality of events \"before\" they occur and who then perhaps resides beyond the natural, causal universe. This creates a definitional conflict because predeterminism, by this understanding, logically leads to a belief in the existence of a conscious being who must determine \"all\" actions and events in advance and who, possessing such seeming omnipotence, almost certainly operates outside of the laws of nature. This conscious entity is probably, then, a being who is omnipotent as well as presumably supernatural and omniscient. The definitional confusion here is that there is already a name for this very concept: predestination. Predestination asserts that a supremely powerful being has, in advance, fixed all events and outcomes in the universe; it is a famous doctrine of the Calvinists in Christian theology.\n\nLikewise, the doctrine of fatalism already explicitly attributes all events and outcomes to the will of a (vaguer) higher power such as fate or destiny. Furthermore, in philosophic debates about the compatibility of free will and determinism, some argue that \"predeterminism\" back to the origin of the universe is simply what philosophers mean by the more common term \"determinism.\" Others have suggested that the term \"self-determination\" be used to describe actions as merely \"determined\" by an agent's reasons, motives, and desires.\n\nWhen various interpretation of the word \"predeterminism\" can be defined even better by other terms, such as the aforementioned determinism, predestination, or fatalism, then the definition of predeterminism itself appears awkward, unclear, and perhaps even worthless in terms of practical or philosophic discussion.\n\nR. E. Hobart is the pseudonym of Dickinson S. Miller, a student of William James who was later one of James' closest personal friends and for some years a colleague in the Harvard philosophy department. Hobart (Miller) criticized the core idea of James' \"The Will to Believe\", namely that it was acceptable to hold religious faith in the absence of evidence for or against that faith. James referred to Miller as \"my most penetrating critic and intimate enemy.\"\n\nNearly 25 years after James' death, R. E. Hobart published a short article in \"Mind\" in 1934 that is considered one of the definitive statements of determinism and compatibilism. It was entitled \"Free Will as Involving Determination and Inconceivable Without It\".\n\nHobart's compatibilism was similar to earlier landmark positions by Thomas Hobbes and David Hume, as refined in the 19th-century compatibilist views of John Stuart Mill, Henry Sidgwick, and F. H. Bradley. But unlike them Hobart explicitly did not endorse \"strict\" logical or physical determinism, and he explicitly did endorse the existence of alternative possibilities, which can depend on absolute chance.\n\nHe was writing just a few years after the discovery of quantum mechanics and indeterminacy, and also makes passing mention of the ancient \"swerve\" of the atoms espoused by Epicurus:\n\n'I am not maintaining that determinism is true...it is not here affirmed that there are no small exceptions, no slight undetermined swervings, no ingredient of absolute chance.'\n\n'\"We say,\" I can will this or I can will that, whichever I choose\". Two courses of action present themselves to my mind. I think of their consequences, I look on this picture and on that, one of them commends itself more than the other, and I will an act that brings it about. I knew that I could choose either. That means that I had the power to choose either.'\n\nHobart supports the existence of alternative possibilities for action and the capability to do otherwise.\n\nAnd he clearly prefers \"determination\" to \"determinism.\" Hobart's article is frequently misquoted as \"Free Will as Involving Determinism.\"\n\nPhilippa Foot is one who misquoted Hobart's title, but who had the same misgivings about determinism.\n\nIn 1957 she wrote an article in The Philosophical Review entitled \"Free Will As Involving Determinism.\"\n\nNevertheless, she criticized arguments that free will requires indeterminism, and in particular the idea that one could not be held responsible for \"chance\" actions chosen for no particular reason.\n\nHer article begins with the observation that determinism has become widely accepted as compatible with free will.\n\n\"The idea that free will can be reconciled with the strictest determinism is now very widely accepted. To say that a man acted freely is, it is often suggested, to say that he was not constrained, or that he could have done otherwise if he had chosen, or something else of that kind; and since these things could be true even if his action was determined it seems that there could be room for free will even within a universe completely subject to causal laws.\"\n\nFoot doubted that the ordinary language meaning of saying our actions are \"determined\" by motives has the same meaning as strict physical determinism, which assumes a causal law that determines every event in the future of the universe.\n\nShe notes that our normal use of \"determined\" does not imply universal determinism.\n\n\"For instance, an action said to be determined by the desires of the man who does it is not necessarily an action for which there is supposed to be a sufficient condition. In saying that it is determined by his desires we may mean merely that he is doing something that he wants to do, or that he is doing it for the sake of something else that he wants. There is nothing in this to suggest determinism in Russell's sense.\"\n\nFoot cited Bertrand Russell's view of causal determinism:\n\n\"The law of universal causation . . . may be enunciated as follows:...given the state of the whole universe...every previous and subsequent event can theoretically be determined.\"\n\n"}
{"id": "45477986", "url": "https://en.wikipedia.org/wiki?curid=45477986", "title": "Princesses combinées", "text": "Princesses combinées\n\nLes princesses combinées (\"the combined princesses\") was a group of French aristocrats during the reign of Louis XVI of France.\nSome authors named two, three or four members of the coterie.\nThey were:\n\nThey were close friends since childhood.\nThey followed Rousseau, Voltaire and the Encyclopedistes, supported each other and were discreet in their love affairs, contrasting with other ladies of the court.\nTheir social circle included the De Lameth brothers, the duke of Guines and Henriette-Lucy, Marquise de La Tour du Pin Gouvernet.\n\n"}
{"id": "35335662", "url": "https://en.wikipedia.org/wiki?curid=35335662", "title": "Rein Raud", "text": "Rein Raud\n\nRein Raud (born 21 December 1961) is an Estonian scholar and author.\n\nHe was born in 1961 in the family of Eno Raud and Aino Pervik, both children's authors. He is the eldest of three children. His younger brother Mihkel Raud is a playwright, television personality, singer, guitarist, journalist and member of the Estonian Parliament; his sister Piret Raud is an artist. He is the grandson of playwright, poet and writer Mart Raud.\n\nHe graduated from the Leningrad State University (now called Saint Petersburg State University) in 1985 in Japanese Studies and earned a PhD degree in Literary Theory at the University of Helsinki in 1994.\n\nRaud is an honorary doctor of the University of Latvia and the Vytautas Magnus University.\n\nRaud has worked in the Estonian Institute of Humanities (now a part of Tallinn University) and the University of Helsinki, where he served as a professor in the Department of World Cultures till 2016. From 2006 to 2011 Raud served as the first rector of the Tallinn University. In 2011-14 he was the President of the European Association of Japanese Studies. Currently he is a research professor at the School of Humanities, Tallinn University.\n\nAs a scholar, Raud has published on a wide range of subjects from cultural theory to pre-modern Japanese literature and philosophy, both in English and Estonian. His theoretical project combines the cultural semiotics of the Eco and Lotman traditions with anthropological and sociological approaches (particularly those of Bourdieu and Alexander) in order to achieve a more holistic understanding of cultural phenomena. His work on Japan has dealt with some of the most important philosophical thinkers, notably Dōgen and Nishida Kitarō.\n\nAs an author, Raud has published five collections of poetry, seven novels and several collections of short stories and plays. He has received the Estonian Cultural Endowment Annual Prize for \"Hektor and Bernard\" (2004) and \"The Reconstruction\" (2012) as well as the Vilde Prize for \"Vend\" (\"Brother\", 2008). \"The Reconstruction\", \"The Brother\" and \"The Death of the Perfect Sentence\", his latest novel to date, have been published in English.\n\nRaud has also frequently contributed to the Estonian public debate by opinion pieces, essays and critical newspaper columns, in which he has expressed left-liberal views and criticised nationalist attitudes. In 2003, he received the prize of the Estonian Journalists' Union for a series of articles criticising the American invasion of Iraq and the Estonian support to it. In 2003-2004 he hosted a philosophical talk show on the Estonian TV called \"Vita brevis\".\n\nRaud is also well known for his translations of Japanese classical literature into Estonian. These include \"Süda on ainuke lill\" (\"Heart is the Only Flower\", anthology of waka poetry, 1994), \"Hullunud pilv\" (\"The Crazy Cloud\" by Ikkyu, 2010) and \"Mäetipp järve põhjas\" (\"The Mountain Peak on the Bottom of the Lake\", anthology of haiku poetry, 2008). He has also translated Dante Alighieri's \"Vita Nova\" into Estonian.\n\nRaud has been awarded the Order of the Rising Sun, 2nd Class, Gold and Silver Star (Japan, 2011), the Order of the White Star, 3rd Class (Estonia, 2001) and the Commander's Cross for services to Lithuania (2009).\n\n\n"}
{"id": "142345", "url": "https://en.wikipedia.org/wiki?curid=142345", "title": "Sandra Faber", "text": "Sandra Faber\n\nSandra Moore Faber is an astrophysicist known for her research on the evolution of galaxies. She is the University Professor of Astronomy and Astrophysics at the University of California, Santa Cruz, and works at the Lick Observatory. She has made important discoveries linking the brightness of galaxies to the speed of stars within them and was the co-discoverer of the Faber–Jackson relation. Faber was also instrumental in designing the Keck telescopes in Hawaii.\n\nFaber studied at Swarthmore College, majoring in Physics and minoring in Mathematics and Astronomy. She earned her bachelor's degree in 1966. She then earned her Ph.D. in 1972 from Harvard University, specializing in Optical Observational Astronomy under the direction of I. John Danziger. During this time the only observatory open to her was the Kitt Peak National Observatory, which had inadequate technology for the complexity of her thesis.\n\nFaber married Andrew Leigh Faber, a fellow Swarthmore physics major one year her junior, on June 9, 1967. They have two daughters, Robin and Holly.\n\nIn 1972, Faber joined the faculty of the Lick Observatory at University of California, Santa Cruz, becoming the first woman on staff. In 1976, Faber observed the relationship between the brightness and spectra of galaxies and the orbital speeds and motions of the stars within them. The law that resulted would become known as the Faber-Jackson relation, after herself and the co-author, graduate student Robert Jackson. Three years later, she and collaborator John S. Gallagher published a seminal paper collecting all of the evidence for the existence of dark matter that had been published at that point. In 1983, she published original research showing that dark matter was not composed of fast-moving neutrinos (\"hot dark matter\") and that instead, it was likely composed of slow-moving particles yet to be discovered (\"cold dark matter\").\n\nAround 1984, Faber collaborated with Joel Primack, George Blumenthal, and Martin Rees to elucidate their theory of how dark matter was part of galaxy formation and evolution. This was the first proposal of how galaxies have formed and evolved from the Big Bang to today. While some details have been proven wrong, the paper still stands as the current working paradigm for structure information in the universe. She and her collaborators discovered high-speed galaxy flows.\n\nIn 1985, Faber was involved with the construction of the Keck Telescope and building the first wide-field planetary camera for the Hubble Space Telescope. UC Berkeley physicist Jerry Nelson designed the Keck telescope, but Faber helped to sell the idea of large optical telescopes all over the world. The Keck telescope is the second largest optical telescope in the world, with a 10-meter primary mirror of a novel type that consists of 36 hexagonal segments.\n\nSandra Faber co-chaired the Science Steering Committee, which oversaw the first-light instrument for Keck I. She also continued to insist on high optical quality for the primary mirror of the Keck I, and went on to work on the Keck II as well.\n\nDuring the later 1980s, Faber got involved in an eight-year project called the \"Seven Samurai\" collaboration, which attempted to catalogue the size and orbital speeds of 400 galaxies. Though this goal was not met, the group developed a way to estimate the distance to any galaxy, which became one of the most reliable ways to measure the total density of the universe.\n\nIn 1990, she assisted with the on-orbit commissioning of the wide field planetary camera for the Hubble Space Telescope. She lists this as one of the most exhilarating and well-known phases of her career. The optics of the Hubble were flawed, and Faber and her team helped to diagnose the cause as spherical aberration. In 1995, Faber was appointed University Professor at UCSC.\n\nFaber was also the principal investigator of the Nuker Team, which used the Hubble Space Telescope to search for supermassive black holes at the centers of galaxies. One of her most recent works include the addition of a new optical spectrograph for the Keck II telescope, which saw its first light in 1996. The new addition would increase the Keck II's power for observing far-away galaxies by 13-fold. She has also joined up with other scientists to create the CANDELS project, which is the largest survey of the universe taken by the Hubble Telescope.\n\nAt UCSC she focuses her research on the evolution of structure in the universe and the evolution and formation of galaxies. In addition to this, she led the development of the DEIMOS instrument on the Keck telescopes to obtain spectra of cosmologically distant galaxies. On August 1, 2012 she became the Interim Director of the University of California Observatories.\n\nSandra Faber is co-editor of the \"Annual Review of Astronomy and Astrophysics\".\n\nMinor planet #283277 Faber is named for her.\n\n\n"}
{"id": "47626263", "url": "https://en.wikipedia.org/wiki?curid=47626263", "title": "Santiago Zabala", "text": "Santiago Zabala\n\nSantiago Zabala (born 1975) is a European philosopher (raised in Rome, Vienna, and Geneva) and ICREA Research Professor of Philosophy at the Pompeu Fabra University. \n\nZabala is ICREA Research Professor at the Pompeu Fabra University, where he currently teaches contemporary and political philosophy, supervises Ph.D. students and directs the UPF Center for Vattimo’s Archives and Philosophy. In addition to an extensive speaking schedule at conferences, festivals, and art Biennales, Zabala is also visiting professor at Renmin University, IDSVA, and several other international institutions.\nZabala's books have been translated into several languages and his articles have been published in \"The Guardian\", \"Al Jazeera English\", \"E-Flux\",' 'The New York Times\", \"\"Boston Review\"\", \"La Maleta\", and \"The Los Angeles Review of Books\"\n\nIn 2017 S. Mazzini and O. Glyn-Williams released a book on \"Hermeneutic Communism\" published by Springer Verlag, \"Making Communism Hermeneutic: Reading Vattimo and Zabala\", with critical contributions from 17 renown scholars from all over the world as well as Vattimo and Zabala's responses.\n\nAccording to Hamid Dabashi \"European thinkers like Žižek and Zabala, important and insightful as they are in their own immediate circles, are out of touch with these realities, and to the degree that they are they cannot come to terms with their unfolding particularities in terms immediate to their idiomaticities. For them \"Philosophy\" is a mental gymnastics performed with the received particulars of European philosophy in its postmodern or poststructuralist registers – exciting and productive to the degree that they can be.\" Zabala's response to Dabashi in Al-Jazeera\n\nAlso Brian Leiter criticized Zabala on his blog (Leiter Reports). Zabala's response to Leiter on Columbia University Press Blog.\n\nAuthor:\n\nEditor\n\n\n"}
{"id": "644374", "url": "https://en.wikipedia.org/wiki?curid=644374", "title": "Science of Logic", "text": "Science of Logic\n\nScience of Logic (SL; , WdL), first published between 1812 and 1816, is the work in which Georg Wilhelm Friedrich Hegel outlined his vision of logic. Hegel's logic is a system of \"dialectics\", i.e., a dialectical metaphysics: It is a development of the principle that thought and being constitute a single and active unity. \"Science of Logic\" also incorporates the traditional Aristotelian syllogism: It is conceived as a phase of the “original unity of thought and being” rather than as a detached, formal instrument of inference.\n\nFor Hegel, the most important achievement of German idealism, starting with Immanuel Kant and culminating in his own philosophy, was the argument that reality (\"being\") is shaped through and through by thought and is, in a strong sense, identical to thought. Thus ultimately the structures of thought and being, subject and object, are identical. Since for Hegel the underlying structure of all of reality is ultimately rational, logic is not merely about reasoning or argument but rather is also the rational, structural core of all of reality and every dimension of it. Thus Hegel's \"Science of Logic\" includes among other things analyses of being, nothingness, becoming, existence, reality, essence, reflection, concept, and method. As developed, it included the fullest description of his dialectic.\n\nHegel considered it one of his major works and therefore kept it up to date through revision.\n\n\"Science of Logic\" is sometimes referred to as the Greater Logic to distinguish it from the \"Lesser Logic\", the moniker given to the condensed version Hegel presented as the \"Logic\" section of his \"Encyclopedia of the Philosophical Sciences\".\n\nHegel wrote \"Science of Logic\" after he had completed his \"Phenomenology of Spirit\" and while he was in Nuremberg working at a secondary school and courting his fiancée. It was published in two volumes. The first, ‘The Objective Logic’, has two parts (the Doctrines of Being and Essence) and each part was published in 1812 and 1813 respectively. The second volume, ‘The Subjective Logic’, was published in 1816 the same year he became a professor of philosophy at Heidelberg. \"Science of Logic\" is too advanced for undergraduate students so Hegel wrote an Encyclopaedic version of the logic which was published in 1817.\n\nIn 1826, the book went out of stock. Instead of reprinting, as requested, Hegel undertook some revisions. By 1831, Hegel completed a greatly revised and expanded version of the ‘Doctrine of Being’, but had no time to revise the rest of the book. The Preface to the second edition is dated 7 November 1831, just before his death on 14 November 1831. This edition appeared in 1832, and again in 1834–5 in the posthumous Works. Only the second edition of \"Science of Logic\" is translated into English.\n\nAccording to Hegel, logic is the form taken by the science of thinking in general. He thought that, as it had hitherto been practiced, this science demanded a total and radical reformulation “from a higher standpoint.” His stated goal with \"The Science of Logic\" was to overcome what he perceived to be a common flaw running through all other former systems of logic, namely that they all presupposed a complete separation between the \"content\" of cognition (the world of objects, held to be entirely independent of thought for their existence), and the \"form\" of cognition (the thoughts about these objects, which by themselves are pliable, indeterminate and entirely dependent upon their conformity to the world of objects to be thought of as in any way true). This unbridgeable gap found within the science of reason was, in his view, a carryover from everyday, phenomenal, \"un\"philosophical consciousness.\n\nThe task of extinguishing this opposition within consciousness Hegel believed he had already accomplished in his book Phänomenologie des Geistes (1807) with the final attainment of Absolute Knowing: “Absolute knowing is the \"truth\" of every mode of consciousness because ... it is only in absolute knowing that the separation of the \"object\" from the \"certainty of itself\" is completely eliminated: truth is now equated with certainty and certainty with truth.” Once thus liberated from duality, the science of thinking no longer requires an object or a matter outside of itself to act as a touchstone for its truth, but rather takes the form of its own self-mediated exposition and development which eventually comprises within itself every possible mode of rational thinking. “It can therefore be said,” says Hegel, “that this content is the exposition of God as he is in his eternal essence before the creation of nature and a finite mind.” The German word Hegel employed to denote this post-dualist form of consciousness was \"Begriff\" (traditionally translated either as Concept or Notion).\n\nThe self-exposition of this unified consciousness, or Notion, follows a series of necessary, self-determined stages in an inherently logical, dialectical progression. Its course is from the objective to the subjective \"sides\" (or \"judgements\" as Hegel calls them) of the Notion. The objective side, its \"Being\", is the Notion as it is \"in itself\" [\"an sich\"], its reflection in nature being found in anything inorganic such as water or a rock. This is the subject of Book One: The Doctrine of Being. Book Three: The Doctrine of the Notion outlines the subjective side of the Notion \"as\" Notion, or, the Notion as it is \"for itself\" [\"für sich\"]; human beings, animals and plants being some of the shapes it takes in nature. The process of Being's transition to the Notion as fully aware of itself is outlined in Book Two: The Doctrine of Essence, which is included in the Objective division of the Logic. The \"Science of Logic\" is thus divided like this:\n\nThis division, however, does not represent a strictly linear progression. At the end of the book Hegel wraps all of the preceding logical development into a single Absolute Idea. Hegel then links this final absolute idea with the simple concept of Being which he introduced at the start of the book. Hence the \"Science of Logic\" is actually a circle and there is no starting point or end, but rather a totality. This totality is itself, however, but a link in the chain of the three sciences of Logic, Nature and Spirit, as developed by Hegel in his Encyclopedia of the Philosophical Sciences (1817), that, when taken as a whole, comprise a “circle of circles.”\n\nA. Being\n\n\"Being\", specifically \"Pure\" Being, is the first step taken in the scientific development of \"Pure Knowing\", which itself is the final state achieved in the historical self-manifestation of \"Geist\" (Spirit/Mind) as described in detail by Hegel in Phänomenologie des Geistes (1807). This Pure Knowing is simply \"Knowing as Such\", and as such, has for its first thought product \"Being as Such\", i.e., the purest abstraction from all that is (although, importantly, not \"distinct\" from, or \"alongside\", all that is), having \"no diversity within itself nor with any reference outwards. ... It is pure indeterminateness and emptiness.\"\n\nB. Nothing\n\n\"Nothing\", specifically \"Pure\" Nothing, \"is simply equality with itself, complete emptiness, absence of all determination and content.\" It is therefore identical with Being, except that it is \"thought of\" as its very opposite. This distinction is therefore meaningful as posited by thought.\n\nC. Becoming\n\nPure Being and Pure Nothing are the same, and yet absolutely distinct from each other. This contradiction is resolved by their immediate vanishing, one into the other. The resultant movement, called \"Becoming\", takes the form of reciprocal \"Coming-to-Be\" and \"Ceasing-to-Be\".\n\nThe transition between Becoming and (a) \"Determinate Being as Such\" is accomplished by means of \"sublation\". This term, the traditional English translation of the German word \"aufheben\", means to preserve, to maintain, but also to cease, to put an end to. Hegel claims that it is “one of the most important notions in philosophy.” Being and Nothing were complete opposites whose inner unity needed to be expressed, or \"mediated\", by a third term: Becoming. Once having been accomplished through mediation, their unity then becomes \"immediate\". Their opposition, still extant in Becoming, has been “put an end to.” From the newly acquired standpoint of immediacy, Becoming becomes Determinate Being as Such, within which Being and Nothing are no longer discrete terms, but necessarily linked \"moments\" that it has “preserved” within itself. Sublation, then, is the ending of a logical process, yet at the same time it is its beginning again from a new point of view.\n\nSo, \"as\" moments of Determinate Being, Being and Nothing take on new characteristics as aspects of (b) \"Quality. Being becomes emphasized, and, as Quality, is \"Reality\"; Nothing, or \"Non-Being\", is concealed in Being's background serving only to delimit it as a specific Quality distinct from others, and, in so doing, is \"Negation in General\", i.e., Quality in the form of a deficiency. Quality, then, comprises both what a Determinate Being \"is\" and \"is not\", viz., that which makes it determinate in the first place. Within Quality, however, Reality and Negation are still distinct from one another, are still \"mediated\", just like Being and Nothing were in Becoming. Taken in their \"unity\", that is, in their immediacy as, again, sublated, they are now only moments of (c) \"Something.\n\nSomething is the first instance in \"The Science of Logic\" of the “negation of the negation”. The first negation, Negation in General, is simply what a Determinate Being is \"not\". Hegel calls this “abstract negation”. When this negation itself is negated, which is called “absolute negation,” what a Determinate Being \"is\", is no longer dependent on what it is \"not\" for its own determination, but becomes an actual particular Something in its own right: a \"Being-Within-Self\". Its negation, what it is not, is now “cut off” from it and becomes another Something, which, from the first Something's point of view, is an \"Other\" in general. Finally, just as Becoming mediated between Being and Nothing, \"Alteration\" is now the mediator between Something and Other.\n\nSomething is now no longer only an isolated something, but is in both positive and negative relationship to the Other. This relationship, however, is then reflected back into the Something \"as\" isolated, i.e., \"in-itself\", and bestows upon it further determinations. \"What\" a Something \"is\" in \"opposition\" to an Other is its (b) \"Determination; what it is in \"relation\" to an Other is its Constitution\".\n\nThe point at which Something ceases to be itself and becomes an Other is that Something's Limit. This Limit is also shared by its Other which is itself an other Something only insofar as it is on the far side of this Limit. It is therefore by their common Limits that Somethings and Others are mediated with one another and mutually define each other's inner Qualities.\n\nFrom the perspective of the Limit, a Something \"is\" only a particular Something insofar as it is \"not\" something else. This means that the Something's self-determination (inherited from Determined Being as Such) is only relative, entirely dependent on what it isn’t to be what it is, and entirely dependent on Something posited as the contradiction of itself, of its own Limit. Something is thus only temporary, contains its own Ceasing-to-Be within itself and so is (c) \"Finite\", i.e., doomed to eventually cease to be. For Finite things, “the hour of their birth is the hour of their death.” At this point the Limit ceases to play its mediating role between Something and Other, i.e., is \"negated\", and is taken back into the self-identity―the Being-Within-Self―of the Something to become that Something’s \"Limitation\", the point beyond which that Something will cease to be. The flip side of this, though, is that the Limit also takes its negative along with it back into the Something, this (the result of negating the Limit) being the Other yet now as posited \"in\" the Something as that Something’s very own Determination. What this means is that, in the face of its own Limitation, the very Quality that defined the Something in the first place ceases to be in any opposition to the Other, which is to say that it no longer strictly \"is\" this Quality but now \"Ought\" to be this Quality. Limitation and the Ought are the twin, self-contradictory moments of the Finite.\n\nOnce again, sublation occurs. Both Limitation and the Ought point beyond the Finite something, the one negatively and the other positively. This beyond, in which they are unified, is the \"Infinite\".\n\nThe negation that Being-in-Itself experienced in the Limitation, the negation that made it Finite, is again negated resulting in the affirmative determination of (a) the \"Infinite in General\" which now reveals itself, not as something distinct from, but as the true nature of the Finite. “At the name of the infinite, the heart and the mind light up, for in the infinite the spirit is not merely abstractly present to itself, but rises to its own self, to the light of thinking, of its universality, of its freedom.”\n\nThis affirmation of the Infinite, however, carries with it a negative relation to an other, the Finite. Because of this, it falls back into the determination of the Something with a Limit peculiar to itself. This \"In\"-finite, then, is not the pure Infinite, but merely the non-Finite. Hegel calls this the \"Spurious Infinite\" and it is this that is spoken of whenever the Infinite is held to be over and above―separated from―the Finite. This separateness is in itself false since the Finite naturally engenders the Infinite through Limitation and the Ought, while the Infinite, thus produced, is bounded by its Other, the Finite, and is therefore itself Finite. Yet they are \"held\" to be separate by this stage of thought and so the two terms are eternally stuck in an empty oscillation back and forth from one another. This Hegel calls (b) the \"Infinite Progress\".\n\nThis impasse can only be overcome, as usual, via sublation. From the standpoint of the Finite, the Infinite cannot break free into independence, but must always be bounded, and therefore finitized, by its Other, the Finite. For further logical development to be possible, this standpoint must shift to a new one where the Infinite is no longer simply a derivation of the Finite, but where the Finite, as well as the Infinite in General, are but moments of (c) the \"True Infinite\". The True infinite bears the same relation of mediation to these moments as Becoming did to Being and Nothing and as Alteration did to Something and Other.\n\nThis move is highly significative of Hegel's philosophy because it means that, for him, “[it] is not the finite which is the real but the infinite.” The reality of the True Infinite is in fact “more real” than the Reality of Determinate Being. This higher, and yet more concrete, reality is the \"Ideal\" [\"das Ideell\"]: “The idealism of philosophy consists in nothing else than in recognizing that the finite has no veritable being.”\n\nAs having been sublated, the mediation which was performed by the True Infinite between the Finite and the Infinite now has resulted in their \"immediate\" unity. This unity is called \"Being-for-Self\".\n\nAt this point we have arrived back at simple Being from which all the previous developments had initially proceeded. This Being, though, is now in the standpoint of Infinity from which these developments can be seen as moments of itself and so it is (a) \"Being-for-Self as Such\". Until this point Determinate Being was burdened with Finitude, depended on the Other for its own determination, and so was only \"relatively\" determined Being. From the Ideal standpoint of Infinity, Being-for-Self has become free from this burden and so is \"absolutely\" determined Being.\n\nAs a consequence of having overcome this relativity, however, both sides of the relationship between Something and Other are now also in equal relation to the Infinite Being that they have become Ideal moments of. So, although through their relationship Something and Other mutually determine \"each other's\" inner Qualities, they do not have the same effect on the Infinite Being―be it God, spirit or ego (in the Fichtean sense)―to which they are now objects. This Being is not just another Finite Other, but is the One for which they are and of which they are a part. The Being-for-Other of Finitude has become the (b) \"Being-for-One\" of Infinity.\n\nIf we now take in isolation that to which all the preceding moments refer, i.e., that which we now have immediately before us, we end up with (c) the \"One\".\n\nThis (a) \"One in its Own Self, standing in negative relation to \"all\" its preceding moments, is entirely differentiated from each of them. It is neither a Determinate Being, nor a Something, nor a Constitution, etc. It is therefore indeterminate and unalterable. There is Nothing in it. Just as there is no criterion to distinguish Being and Nothing despite the fact that they are opposites, the One is also identical with \"its\" opposite, (b) the \"Void. The Void can be said to be the Quality of the One.\n\nThe original transition of Being and Nothing to Determinate Being is again echoed here in the sphere of Being-for-Self. The One, though, as negatively related to all aspects of Quality excepting its own Quality of being the Void, cannot take on a Qualitative determinateness like Determinate Being did. In its own self-differentiation, it can only relate to itself as another self identical to it, that is, as another One. Since no new Quality has been taken on, we cannot call this transition a Becoming, but rather a \"Repulsion\", i.e., the positing of (c) \"Many\" Ones.\n\nOnce these many Ones have been posited, the nature of their relationship begins to unfold. Because it is the nature of the One to be purely \"self\"-related, their relation to one another is in fact a \"non\"-relation, i.e., takes place externally in the Void. From the standpoint of the one One, then, \"there are no other Ones\", that is, its relation to them is one of (a) \"Exclusion\". Seen from \"within\" the One there is only \"one\" One, but at the same time the One only exists in the first place through its negative external relation to \"other\" Ones, i.e., for there to \"be\" the one One there \"must\" be Many Ones that mutually Exclude one another.\n\nNow that Many Ones have been posited out of their Repulsion from the One, their original Oneness reasserts itself and their Repulsion passes over to (b) \"Attraction\". Attraction presupposes Repulsion: for the Many to be Attracted by the One, they must have at first been Repulsed by it.\n\nThe One having been restored to unity by Attraction now contains Repulsion and Attraction within it as moments. It is the \"Ideal\" One of Infinite Being, which, for Hegel, actually makes it \"more\" “real” than the merely \"Real\" Many. From the standpoint of this Ideal One, both Repulsion and Attraction now presuppose each other, and, taken one step further, each presupposes \"itself\" as mediated by the other. The One is only a One with reference to another One―Repulsion; but this “other” One is in itself identical to, \"is\" in fact, the original One―Attraction: each is the moment of the other. This is the (c) \"Relation of Repulsion and Attraction\", which at this point is only \"relative\".\n\nRepulsion and Attraction are relative to one another insofar as the One is taken either as the beginning or result of their mediation with one another. Imparted with continuous, Infinite motion, the One, Repulsion and Attraction become the sublated moments of \"Quantity\".\n\nA. Pure Quantity\n\nThe previous determinations of Being-for-Self have now become the sublated moments of \"Pure Quantity\". Pure Quantity is a One, but a One made up of the Many having been Attracted back into each other out of their initial Repulsion. It therefore contains Many identical Ones, but in their coalescence, they have lost their mutual Exclusion, giving us a simple, undifferentiated sameness. This sameness is \"Continuity\", the moment of Attraction within Quantity. The other moment, that of Repulsion, is also retained in Quantity as \"Discreteness\". Discreteness is the expansion of the self-sameness of the Ones into Continuity. What the unity of Continuity and Discreteness, i.e., Quantity, results in is a continual outpouring of something out of itself, a perennial self-production.\n\nB. Continuous and Discrete Magnitude\n\nAlthough unified in Quantity, Continuity and Discreteness still retain their distinction from one another. They cannot be cut off from each other, but either one can be foregrounded leaving the other present only implicitly. Quantity is a \"Continuous Magnitude\" when seen as a coherent whole; as a collection of identical Ones, it is a \"Discrete Magnitude\".\n\nC. Limitation of Quantity\n\nQuantity is the One, but containing within it the moments of the Many, Repulsion, Attraction, etc. At this point the negative, Excluding nature of the One is reasserted within Quantity. The Discrete Ones within Quantity now become Limited, isolated Somethings: \"Quanta\".\n\nThe first determination of quantum is \"Number\". Number is made up of a One or Many Ones—which, as quanta, are called \"Units\"—each of which is identical to the other. This identity in the Unit constitutes the Continuity of Number. However, a Number is also a specific Determinate Being that encloses an aggregate of Units while excluding from itself other such aggregates. This, the \"Amount\", is the moment of Discreteness within Number. Both Qualitative and Quantitative Determinate Being have Limits that demarcate the boundary between their affirmative presence and their negation, but in the former the Limit determines its Being to be of a specific Quality unique to itself, whereas in the latter, made up as it is of homogeneous Units that remain identical to each other no matter which side of the Limit they fall upon, the Limit serves only to enclose a specific Amount of Units, e.g., a hundred, and to distinguish it from other such aggregates.\n\nTaken in its immediacy, a Number is an \"Extensive Magnitude\", that is, a collection of a certain Amount of self-same Units. These Units, say ten or twenty of them, are the sublated moments of the Extensive Magnitudes ten or twenty. However, the Number ten or twenty, though made up of Many, is also a self-determining One, independent of other Numbers for its determination. Taken in this way, ten or twenty (a) differentiates itself from Extensive Magnitude and becomes an \"Intensive Magnitude\", which is expressed as the tenth or twentieth \"Degree\". Just as the One was completely indifferent to the other Ones of the Many yet depended on them for its existence, each Degree is indifferent to every other Degree, yet they are externally related to one another in ascending or descending flow through a scale of Degrees.\n\nAlthough thus differentiated from each other, Extensive and Intensive magnitude are essentially (b) the same. “[T]hey are only distinguished by the one having amount within itself and the other having amount outside itself.” It is at this point that the moment of the Something reasserts itself having remained implicit over the course of the development of Quantity. This Something, which reappears when the negation between Extensive and Intensive Magnitude is itself negated, is the re-emergence of Quality within the dialectic of Quantity.\n\nIn the realm of Quantity, the relationship between Something and Other lacked any mutual Qualitative Determinateness. A One could only relate to another One identical to itself. Now, however, that Qualitative Determinateness has returned, the Quantum loses its simple self-relation and can relate to itself only through a Qualitative Other that is beyond itself. This Other is another Quantum, of a greater or lesser Amount, which, in turn, immediately points beyond itself to yet an Other Quantum \"ad infinitum\". This is what constitutes the self-propelled (c) Alteration of Quantum.\n\nAlthough a particular Quantum, of its own inner necessity, points beyond itself, this beyond is necessarily an Other Quantum. This fact, that Quantum eternally repulses itself, yet equally eternally remains Quantum, demonstrates the (a) Notion of Quantitative Infinity, which is the self-related, affirmative opposition between Finitude and Infinity that lies within it. This irresolvable self-contradiction within Quantum yields (b) the Quantitative Infinite Progress. This progress can take place in one of two directions, the greater or the smaller, giving us the so-called “infinitely great” or “infinitely small.” That these “infinites” are each the \"Spurious Quantitative Infinite\" is evident in the fact that “great” and “small” designate Quanta, whereas the Infinite by definition is \"not\" a Quantum.\n\nThe Quantitative Infinite negates Quantum, and Quantum in turn negates Infinity. As occurs so often in \"The Science of Logic\", a negation that is itself negated produces a new affirmative standpoint, the formerly negated terms having become the unified moments thereof. This standpoint is (c) the Infinity of Quantum from where it is seen that Infinity, initially the absolute Other of Quantum, essentially \"belongs\" to it and in fact \"determines\" it as a particular Quality alongside all the other Determinate Beings that had long since been sublated. This particular Quality which distinguishes Quantum from any other Qualitatively Determined Being is in fact the total lack of explicit self-determinateness that differentiated Quantity from Quality in the first place. The repulsion of Quantum from itself out into the beyond of Infinity, is actually a gesture \"back\" towards the world of Qualitative Determination, thus bridging once again the two worlds. This gesture is made explicit in the \"Quantitative Ratio\", where two Quanta are brought into relationship with one another in such a way that neither one in itself is self-determined, but in relating to each other, they Qualitatively determine something beyond themselves, e.g., a line or a curve.\n\nA. The Direct Ratio\n\nA ratio, such as \"x\":\"y\", is a \"Direct Ratio\" if both terms of the ratio are delimited by a single Quantum, a constant, \"k\" (what Hegel calls in the language of his day the \"exponent\" of the ratio),\nIn the Direct Ratio, the previously sublated Quantitative moments of Amount and Unit are retrieved and brought into immediate relation with each other. One side of the ratio, \"y\", is a certain Amount relative to the other side, \"x\", which serves as the Unit whereby this Amount is measured. If the constant is given, then the Quantum on any one side of the ratio could be any Number, and the Number on the other side will automatically be determined. Therefore, the first Number of the ratio completely loses its independent significance and only functions as a determinate Quantum in relation to an other. Formerly, any single Number could simultaneously denote either an Amount or a Unit; now, it must serve exclusively as the one \"or\" the other in relation to another Number serving as the opposite. The constant would seem to bring these moments back into unity with each other, but in actuality, it too can serve \"only\" as either Amount \"or\" Unit. If \"x\" is Unit and \"y\" Amount, then \"k\" is the Amount of such Units,\nif \"x\" is Amount, then \"k\" is the Unit, the amount of which, \"y\", determines it,\nAs in themselves \"incomplete\" in this way, these Quanta serve only as the Qualitative moments of one another.\n\nB. Inverse Ratio\n\nThe \"Inverse Ratio\" is a ratio, \"x\":\"y\", in which the relation between both sides is expressed in a constant which is their \"product\", i.e.,\nor\nWhereas formerly with the Direct Ratio, the quotient between the two terms was \"fixed\", in the Inverse Ratio it becomes \"alterable\". Because the Inverse Ratio confines within itself many Direct Ratios, the constant of the former displays itself not merely as a Quantitative, but also as a Qualitative Limit. It is therefore a Qualitative Quantum. The Spurious Infinity/True Infinity dialectic again makes an appearance here as either term of the ratio is only capable of infinitely approximating the ratio's constant, the one increasing in proportion to a decrease in the other, but never actually reaching it (neither \"x\" nor \"y\" may equal zero). The constant is nonetheless \"present\" as a simple Quantum, and is not an eternal beyond, making its self-mediation through the two terms of the ratio an example of True Infinity.\n\nC. The Ratio of Powers\n\nThe \"Ratio of Powers\" takes the following form:\nIt is in this form of the Ratio, says Hegel, that “quantum has reached its Notion and has completely realized it.” In the Direct and Inverse Ratios, the relation between the constant and its variables was not continuous, the former only being a fixed proportionality between them, and the latter relating itself to them only negatively. With the Ratio of Powers, however, this relationship is not simply one of external limitation, but, as a Quantum brought into relationship with itself through the power, it is \"self-determining\" Limit. This self-determination constitutes the Quality of the Quantum, and finally demonstrates the full significance of the essential identity of Quality and Quantity. Originally, Quantity differentiated itself from Quality in that it was indifferent to what was external to it, that which it quantified. Now however, in the Ratio of Powers, what it relates itself to externally is determined by its \"own\" self, and that which relates externally to its own self has long since been defined as Quality. “But quantity is not only \"a\" quality; it is the truth of quality itself.” Quantum, having sublated the moment of Quantity that originally defined it and returned to Quality, is now what it is in its truth: \"Measure\".\n\n“Measure is the simple relation of the quantum to itself ... ; the quantum is thus qualitative.” Previously, Quantum was held to be indifferent to the Quality of that which it quantified. Now, as Measure, Quality and Quantity though still distinct from one another are inseparable and in their unity comprise a specific Determinate Being: “Everything that exists has a magnitude and this magnitude belongs to the nature of the something itself.” The indifference of Quantum is retained in Measure insofar as the magnitude of things can increase or decrease without fundamentally altering their Quality, and yet their essential unity nevertheless manifests at the Limit where an alteration in Quantity \"will\" bring about a change in Quality.\n\nInsofar as Quantity describes the upper and lower Limits between which a specific Quality can maintain itself, it serves as a (a) \"Rule. The Rule is an arbitrary external standard or Amount that measures something other than itself. Although it is often tempting to assume so, there is in actuality no object that can serve as a completely universal standard of measurement, i.e., be pure Quantity. Rather, what is involved in measurement is a ratio between two Qualities and their inherent Quantities, the one made to act as the (b) \"Specifying Measure of the other, this other, however, being itself just as capable of measuring that which it is being measured by.\n\nSo long as we arbitrarily use the Quantitative properties of some Quality or other as a Rule to Measure the magnitude of other Qualities, we abstract from it its Qualitative nature. However, once we have established a Quantitative ratio between two or more Qualities, we can give this ratio an independent existence that Quantitatively unites things that are Qualitatively distinct. We can thus take the Qualities of both sides into account, the independent, or \"Realized\", Measure serving as their (c) \"Relation\". This Measure necessarily involves variable magnitudes since the Qualitatively distinct ways in which different things relate to Quantity can only be registered in their respective rates of increase or decrease relative to each other. Further, in order for each side of the ratio to fully reflect the distinctiveness of the Quality it represents, both sides must be Quantitatively self-related, i.e., take the form of powers as in the case of the Ratio of Powers explicated above.\n\nAlthough now united by the Quantitative Ratio, the two or more Qualities thus brought into relation retain their mutual separation as distinct Qualities. For example, even though we can determine the Quantitative relationship between space and time in the example of a falling body, each of them can still be considered on its own, independent of the other. However, if we then take the constant produced by the ratio of the two sides as a self-subsistent Something in its own right, that is, a \"Being-for-Self\", then the two formerly entirely distinct Qualities become its own sublated moments, their very natures now seen to have been in fact derived from this relation of Measure in the first place.\n\n\"Real Measure\" gives us a new standpoint external to the different Measures being brought into relation with each other, this relation now designating the independent existence of an actual physical Something. This Something gains its Qualitative determination from the Quantitative (a) combination between two Measures immanent in it, i.e., volume and weight. One designates an inner Quality, in this case weight; the other designates an external Quality, in this case volume, the amount of space it takes up. Their combination gives us the ratio of weight to volume which is its specific gravity. The constant that results from this ratio is the inner characteristic Real Measure of the thing in question, but, taking the form as it does of a mere number, a Quantum, this constant is likewise subject to alteration, i.e., addition, subtraction, etc. Unlike mere Quantum, however, the Real Measure of a thing is inwardly determined, and so preserves itself somewhat in alteration. If two material things are combined, the dual Measures of the one are added to those of the other. The degree to which they exhibit self-preservation is registered in the \"internal\" Measure—weight in this case—which ends up being equal, after combination, to the sum of the original two Measures; the degree to which they exhibit Qualitative alteration is registered in the \"external\" Measure—space in this case—which does \"not\" necessarily result in a sum equal to its parts, but often in the case of material substances exhibits a diminution in overall volume.\n\nIf we adopt the constant of one specific Real Measure as our Unit, the constants of other Real Measures can be brought into relation to it as Amounts in a (b) \"series of Measure relations. Since it is arbitrary which one Real Measure in such a series will serve as the Unit, there are as many incommensurable series of Measure relations as there are individual Real Measures. However, when two Real Measures, which are themselves ratios, are combined, the result is a new ratio of those ratios, itself designated by a constant in the form of a Quantum. If \"this\" constant is adopted as the Unit, instead of an individual Real Measure, then what were two incommensurable series are now made commensurable with each other in a common denominator. Since each Real Measure within a series forms such a constant with every other member in that series, \"any\" individual series in which a particular Real Measure serves as the Unit can be made commensurable with any \"other\" series with a \"different\" Real Measure as Unit. Since it is a thing’s Real Measure that determines its specific Quality, and since that Real Measure is in turn derived from the Quantitative relation it has with other Real Measures in the form of a series of constants, it would appear that, as in Determinate Being above, Quality is only relative and externally determined. However, as we have seen, a Real Measure also has an \"internal\" relation that gives it a self-subsistence that is indifferent to any external relation. Therefore, the series of Quantitative relationships between these Real Measures only determines the (c) \"Elective Affinity between their different Qualities, but not these Qualities themselves.\n\nThe Quantity/Quality dialectic manifests itself in the realm of Elective Affinity in that a Real Measure within in a series will not necessarily resonate Qualitatively with those in another series even if they bear a proportional Quantitative relationship. In fact, the specific Quality of a particular Real Measure is in part registered by the other Real Measures it has a special Affinity for, that is, \"how\" it responds to Quantitative Alteration. It is the Intensive side of Quantity (see above) such as it relates to specific Real Measures that determines its Qualitative behaviour when subject to changes in Extensive Quantity.\n\nThe relation of Elective Affinity is an external relation between two Real Measures that is determined by their Quantitative aspects. In and of themselves, each Real Measure retains its Qualitative indifference to all others, even those it has Affinity for. Real Measures, however, are also subject to \"internal\" alteration akin to what has already been discussed in “Measure” above, i.e., that its Quality can be maintained only within a certain Quantitative range beyond which it undergoes a sudden “leap” into another Quality. These different Qualities form \"Nodes\" on a line of gradual Quantitative increase or decrease.\n\nMeasure, being the unity of Quality and Quantity, now transitions into its version of the Infinite, the \"Measureless\", which accordingly is the unity of the Qualitative and Quantitative Infinites. In the Measureless, the Quantitative Infinite is manifested in the potential of the Nodal line to increase endlessly; the Qualitative Infinite is manifested as the eternal beyond of any particular Qualitative determination. Seeing as the successive determinations are self-generated by an internal Quantitative Alteration of Measure, they can now be seen, from the standpoint of the Measureless, to be different \"States\" of one and the same \"Substrate\". The nature of the Substrate is not tied, like the Something was, to a merely external Qualitative appearance, but represents the underlying unity of a variety of internally determined appearances, which are its States.\n\nA. Absolute Indifference\n\nThis Substrate, as what persists through the succession of States, is in a relation of \"Absolute Indifference\" to every particular determination—be it of quality, quantity or measure—that it contains. It is merely the abstract expression of the unity that underlies their totality.\n\nB. Indifference as Inverse Ratio of its Factors\n\nTaken in its immediacy, this Indifference is simply the result of all the different determinatenesses that emerge within it. It itself does not determine its own inner fluctuations, i.e., is not \"self\"-determining. However, in accordance with the measure relations developed so far, each of its moments are in reciprocal, quantitatively determined ratios with one another. Formerly, from the standpoint of Quality, a sufficient Quantitative increase or decrease would result in a sudden transition from one Quality to another. Now, with Absolute Indifference as our standpoint, every possible Qualitative determination is already implicitly related to every other by means of a Quantitative ratio. Every Quality is connected to, and in equilibrium with, its corresponding other. It is therefore no longer meaningful to say that something can have “more” or “less” of one Quality than another as if each Quality were absolutely distinct from each other. Whatever Quality there is “more” of in one thing than another can be equally said to be a “less” of whatever Quality exists in its stead in the other, i.e., there is an \"Inverse Ratio of their Factors\". So, with a so-called “Quantitative” change, “one factor becomes preponderant as the other diminishes with accelerated velocity and is overpowered by the first, which therefore constitutes itself the sole self-subsistent Quality.” The two Qualities are no longer distinct, mutually exclusive determinations, but together comprise a single whole.\n\nC. Transition into Essence\n\nStrictly within the realm of Being, the underlying unity behind all its determinations necessarily stands externally, and in contradiction, to those determinations themselves. The transition to Essence occurs when these determinations reabsorb this unity back into themselves, i.e., they sublate it. The inherent contradiction between difference and unity is resolved when the latter is posited as the \"negative\" of the former. So, from henceforth it cannot be said that they simply emerge \"within\" the Substrate of Indifference, but that this “substrate” itself \"is\" their very own living self-relation. In other words, the differences between all the determinations of Being, namely the Quantitative difference and the inverse ratio of factors, are no longer self-subsistent, but in fact are mere moments in the expression of the implicit unity that rules them and, themselves, “\"are\" only through their repulsion from themselves.” Being has finally determined itself to no longer be simply affirmative Being, i.e., that which characterized Being as Being in the first place, but as a \"relation\" with itself, as \"Being-With-Self\", or \"Essence\".\n\nThe immediate characteristic displayed by Essence, once it finally emerges from Being, is simply that it is \"not\" Being. This apparently puts us back into the sphere of Determinate Being (see above), where each side of a relation mutually determined the Other side as being \"not\" what \"it\" is. In this immediate, merely relative relation, Essence and Being thus become the \"Essential\" and the \"Unessential\", respectively. There is nothing arising within this relation, however, to tell us \"what\" it is about something that is Essential and what Unessential. Those that apply this mode of thinking to something are making an arbitrary distinction, the opposite of which could always be claimed with equal justification. What saves Essence from falling back into the relativism of Determinate Being is the very radical and absolute distinction from Being that defines it as Essence in the first place. Being cannot therefore simply preserve itself as an Other relative to Essence, but, having been sublated by Essence, it has for that very reason itself become \"nothingness\", a \"non-essence\", \"Illusory Being\".\n\nSo in its relation to Essence, Being has lost its being, has become Illusory. All the determinations of Being covered in the first third of the Science of Logic are no longer self-subsistent, but only “are” at all as negations of Essence. This total dependence on Essence means that there is nothing any longer in Being itself upon which any of its own determinations can be based, i.e., there is no longer any \"mediation\" within Being. This role is entirely taken up by Essence which is \"pure\" mediation relative to Illusory Being's \"pure\" immediacy. Hegel claims this is the mode of thought that corresponds to ancient skepticism as well as the “modern” idealism of Leibniz, Kant, and Fichte. Illusory Being, though not Essence itself, nevertheless \"belongs\" entirely to Essence. It is that through which Essence generates itself as what it is, namely, the \"purely negative\" as regards Being. The constant appearance and disappearance of the empty manifestations of Illusory Being can now be seen as Essence's \"own\" self-generating movement, its own \"Reflection\".\n\nReflection in the sphere of Essence corresponds to Becoming in the sphere of Being. However, in Being, this movement was between a positive—pure Being—and a negative—pure Nothingness. Here however, the two terms are Illusory Being and Essence. Illusory Being, as has already been established, is a nullity, nothingness. Essence, by definition, is non-being, \"absolute negativity\". So Reflection, the movement between them, is the movement of \"nothing to nothing\" and so back to itself. Both these terms, in being \"absolutely negative\", are identical to one another: Essence \"is\" Illusory Being and Illusory Being \"is\" Essence. They are, however, also \"relatively negative\", in that the one is, by definition, \"not\" what the other is. This contradiction manifests in Essence in that it \"presupposes\" or \"posits\", \"on its own\", that which it immediately differentiates itself from: Illusory Being. This absolute recoil upon itself is Essence as a) \"Positing Reflection\".\n\nThe next determination of Reflection, b) \"External Reflection\", shifts the emphasis from the absolute negativity, or nothingness, in which the posited Illusory Being and its positing Essence find their \"identity\", to the relative negativity upon which their \"opposition\" is based. Although it “knows” that the Illusory Being it finds immediately before it has been posited by none other than \"itself\", External Reflection nevertheless regards this Being as something \"external\" to it from which it returns to itself. What concerns it, therefore, is no longer the act of positing itself, but the specific \"determinateness\" of that which is posited, since it is this and nothing else that establishes its externality in the first place.\n\nWith Positing Reflection, the Illusory Being that was posited was only a means for Essence's mediation with itself. Now, with c) \"Determining Reflection\", not only is the moment of Illusory Being foregrounded again, but the specific determinations of this Being come into play as well. The absolute nothingness of Essence forms the background to any and all of the determinations it chooses to Reflect itself off of. These Determinations of Reflection—formerly known as Determinate Beings when they were in the realm of Quality (see above)—therefore share in the nullity that undergirds them. This nullity actually serves to fix them eternally in their specific determination and preserve them from Alteration, because they no longer relate to each other externally as Others to one another, but \"internally\" as equals in Essence's nothingness. All the possible determinations of Being are thus preserved negatively in Essence as free \"Essentialities\" “floating in the void without attracting or repelling one another.”\n\nIn the sphere of Being, above, Qualities were determined only \"relatively\". What something \"was\", was determined entirely by that which differentiated it from what it \"wasn't\", i.e., it was \"negatively\" determined by its Other. Here in Essence however, the negativity necessary to establish determination is no longer directed outward, towards an Other, but \"inward\". This is because Essence is in itself \"absolute negativity\", nothingness, and it follows that any determination made therein will share in this negativity and itself be essentially nothing. Therefore, an \"Essentiality\", as opposed to a Quality, is essentially \"the same\" as its other—they are both essentially nothing. As self-determining, whatever determination Essence takes on is freely self-generated, it “is what it is,” and so is simple \"Identity-with-self\". This absolute Identity rests on the \"absolute\" negativity that unites Essence with its Essentialities. However, if we recall from “Reflection” above, Essence is also negative \"relative\" to its Essentialities. The Essentialities are \"determined\" Essence and, as we know, determination by definition involves negation. Therefore, while the Essentialities are absolutely Identical in their shared nothingness, their \"absolute\" negativity, they are equally absolutely \"Different\" in their determinations, their \"relative\" negativity.\n\nThe Difference of Reflection must be distinguished from the Otherness of Determinate Being. The latter is a relative relation between two Determinate Beings whereby they distinguish themselves one from another and in turn determine themselves as specific Beings based on this distinction. In the sphere of Reflection, however, any determination \"posited\" by Essence is, \"as\" a determination, necessarily Different from the absolute negativity that is its Essence. The Difference of Reflection, therefore, is different in relation to its \"own self\", and so it is not relative but a) \"Absolute Difference\".\n\nAbsolute Difference contains both Difference \"and\" Identity within it as \"moments\" just as, conversely, Identity contains itself and Difference as \"its\" moments. The relation between Identity and Difference takes the form of one term reflecting off the other back into itself: Difference off of Identity back into itself or Identity off of Difference back into itself. “This is to be considered as the essential nature of reflection and as the \"specific, original ground of all activity and self-movement\".” Because each of these two moments are self-related in this way, they do \"not\" mutually determine one another. Instead, they are indifferent to one another. Therefore, Difference is b) \"Diversity\".\n\nYet another duality emerges at this point. \"As moments\", Identity and Difference require each other and are bound up with one another: one term could not exist without the other. But at the same time, they absolutely \"negate\" one another and only \"are\" at all by virtue of their mutual negation of each other. So if we are an external party concerned with a specific determination of Identity, the moment of Difference, though intrinsic to the fact of this Identity, is very far from our minds. That it is Different from other things does not concern us or it at the moment: it is \"implicit\". The category of Identity itself, however, is \"not\" determined by whatever it is that it is applied to, but by its reflection off of Difference back into itself. So if, from our external standpoint, that which comprises the \"Identity\" of something cannot be established without a Comparison of \"Likeness\" with something else. What specifically is \"Different\" about something can similarly only be determined by a Comparison of \"Unlikeness\" between it and something else. Like and Unlike, being external to the things they refer to, can each be equally applied to one and the same Determination. Things are Like each other insofar as they are not Unlike each other and vice versa: the two terms are mutually exclusive insofar as they refer to the same thing, but \"in themselves\", apart from the things they refer to, there is no difference between them. Since any aspect may be externally selected to demonstrate the Likeness and Unlikeness of any two things, these terms really only refer, not intrinsically to their objects, but to \"themselves\" only and, as likewise self-referred, are indistinguishable from each other independent of their objects. Likeness and Unlikeness are both in fact only \"Likeness\". The \"internal\" union that existed between Identity and Difference which is merely implicit to the outside observer, therefore emerges again in external reflection between Likeness and Unlikeness, and thus overcomes the \"external\" Diversity that held Identity and Difference indifferently apart from each other. This reconstituted unity that thus comes out of Diversity is c) \"Opposition\".\n\nThe hidden, internal unity that bound the two moments of Identity and Difference together despite their apparent mutual indifference becomes explicit once they are mediated from the outside by Likeness and Unlikeness. They are no longer indifferent to one another but relate to each other intrinsically as Opposites. A given determination, as seen from its \"Positive\" aspect, is Likeness reflected back onto itself off of Unlikeness. Seen from its \"Negative\" aspect, it is Unlikeness reflected back onto itself off of Likeness. These two aspects, however, are the constitutive moments of one and the same overall determination. Although \"as a whole\", the Positive and Negative comprise a unity, the Positive \"on its own\" is also a self-subsistent being, as is the Negative \"on its own\". Because of this, the Negative can equally well be regarded as positive and vice versa. They are not Positive and Negative merely in comparison with one another, but each contains within itself the other as an essential element of its own determination.\n\nBoth the Positive and the Negative are self-subsistent determinations: each side can stand on its own without explicit reference to the other. At the same time, however, they completely exclude one another and in fact rely on this exclusion for their self-subsistence. In that sense, the Positive itself is constituted by the very Negative that it excludes; it is \"based\" on this exclusion and thus contains what it excludes it within itself. Ditto the Negative. This inclusion of what is excluded is what constitutes the Positive and the Negative as what they are. This is \"Contradiction\". (In the Negative, this self- contradiction is explicit, but it is no less the nature of the Positive.)\n\nSo, similar to Becoming above, the Positive and the Negative immediately transition the one into the other: the Positive \"includes\" the Negative which immediately \"excludes\" the Positive; the resulting Negative however also \"includes\" the Positive which in turn \"excludes\" the Negative and so on \"ad infinitum\". This mutual inclusion and exclusion cancels out the both of them. This results in nullity. Out of this nullity, the unity of the two sides is restored in the following way. As stated above, both the Positive and the Negative are each self-subsistent on their own, but it is a self-subsistence that is immediately obliterated by the other's. Now, however, arising out of their mutual destruction comes a self-subsistence that is common to the both of them. Instead of merely excluding each other, each side \"sublates\" the other, meaning that whatever is posited as Positive is \"at the same time\" equally the Negative of its Negative, and whatever is Negative is \"at the same time\" equally a Positive. The two sides posit and negate each other simultaneously, and in doing so they no longer destroy each other, but \"preserve\" one another. Therefore, the Positive and Negative are in fact the \"same\" and this, their sameness—which nevertheless includes their Contradiction—is their Essence as \"Ground\".\n\nSimply put ground is the \"essence of essence,\" which for Hegel arguably means the lowest, broadest rung in his ontology because ground appears to fundamentally support his system. Hegel says, for example, that ground is \"that from which phenomena is understood.\" Within ground Hegel brings together such basic constituents of reality as form, matter, essence, content, relation, and condition. The chapter on ground concludes by describing how these elements, properly conditioned, ultimately will bring a fact into existence (a segue to the subsequent chapter on existence).\n\nHegel considers form to be the focal point of \"absolute ground,\" saying that form is the \"completed whole of reflection.\" Broken into components, form taken together with essence gives us \"a substrate for the ground relation\" (Hegel seems to mean relation in a quasi-universal sense). When we combine form with matter the result is \"determinate matter.\" Hegel thinks that matter itself \"cannot be seen\": only a determination of matter resulting from a specific form can be seen. Thus the only way to see matter is by combining matter with form (given a literal reading of his text). Finally, content is the unity of form and determinate matter. Content is what we perceive.\n\n\"Determinate ground\" consists of \"formal ground,\" \"real ground,\" and \"complete ground.\" Remember with Hegel that when we classify something as determinate we are not referring to absolute abstractions (as in absolute ground, above) but now (with determinate ground) have some values attached to some variables—or to put it in Hegel's terminology, ground is now \"posited and derived\" with \"determinate content.\"\n\nIn formal ground Hegel seems to be referring to those causal explanations of some phenomena that make it what it is. In a (uncharacteristically) readable three paragraph remark, Hegel criticizes the misuse of formal grounds, claiming that the sciences are basically built upon empty tautologies. Centrifugal force, Hegel states as one of several examples drawn from the physical sciences,\nmay be given as prime grounds (i.e. \"explanation of\") some phenomena, but we may later find upon critical examination that this phenomenon supposedly explained by centrifugal force is actually used to infer centrifugal force in the first place. Hegel characterizes this sort of reasoning as a \"witch's circle\" in which \"phenomena and phantoms run riot.\"\n\nReal ground is external and made up of two substrates, both directly applicable to content (which evidently is what we seem to perceive). The first is the relation between the ground and the grounded and the second substrate handles the diversity of content. As an example Hegel says that an official may hold an office for a variety of reasons—suitable connections, made an appearance on such and such occasion, and so forth. These various factors are the grounds for his holding office. It is real ground that serves to firstly make the connection between holding office and these reasons, and secondly to bind the various reasons, i.e. diverse content, together. Hegel points out that \"the door is wide open\" to infinite determinations that are external to the thing itself (recall that real ground is external). Potentially any set of reasons could be given for an official to be holding office.\n\nIn complete ground Hegel brings together formal and real ground, now saying that formal ground presupposes real ground and vice versa. Complete ground Hegel says is the \"total ground-relation.\"\n\nThis \"volume\" is the third major piece within the \"Science of Logic\". Here Hegel introduces his Notion within which he extends Kant's basic schemes of judgement and syllogism classification. Hegel shows that the true idea can only be based upon valid reasoning and objectivity.\n\n\n\n\n"}
{"id": "201232", "url": "https://en.wikipedia.org/wiki?curid=201232", "title": "Siddhi", "text": "Siddhi\n\n\"Siddhi\" is a Sanskrit noun which can be translated as \"perfection\", \"accomplishment\", \"attainment\", or \"success\".\nIn Tamil the word Siddhar/Chitthar refers to someone who has attained siddhis and other kinds of mystical knowledge.\n\nThe \"Visuddhimagga\" is one of the texts to give explicit details about how spiritual masters were thought to actually manifest supernormal abilities. It states that abilities such as flying through the air, walking through solid obstructions, diving into the ground, walking on water and so forth are achieved through changing one element, such as earth, into another element, such as air. The individual must master \"kasina\" meditation before this is possible. Dipa Ma, who trained via the \"Visuddhimagga\", was said to demonstrate these abilities.\n\nIn the \"Panchatantra\", an ancient Indian collection of moral fables, a siddhi may be the term for any unusual skill or faculty or capability.\n\nIn Shaivism, siddhi are defined as \"Extraordinary powers of the soul, developed through consistent meditation and often uncomfortable and grueling tapas, or awakened naturally through spiritual maturity and yogic sādhanā.\" \n\nAccording to some forms of Shaivism, the eight classical siddhis (\"Ashta Siddhi\") or eight great perfections are:\n\nIn Vaishnavism, The term \"siddhi\" is used in the \"Sarva-darśana-saṃgraha\" of Madhvacharya (1238–1317), the founder of Dvaita (dualist) philosophy.\n\nIn the \"Bhagavata Purana\", the five siddhis brought on by yoga and meditation are:\n\nIn the \"Bhagavata Purana\", Krishna describes the ten secondary siddhis:\n\nIn the \"Samkhyakarika\" and \"Tattvasamasa\", there are references to the attainment of eight siddhis by which \"one becomes free of the pain of ignorance, one gains knowledge, and experiences bliss.\"\nThe eight siddhis hinted at by Kapila in the \"Tattvasamasa\" are, as explained in verse 51 of the \"Samkhyakarika\":\n\nIt is believed that the attainment of these eight siddhis renders one free of the pain of ignorance, and gives one knowledge and bliss. \n\nIn Patañjali's \"Yoga Sutras\" IV.1 it is stated, \"Janma auṣadhi mantra tapaḥ samādhijāḥ siddhayaḥ\", \"Accomplishments may be attained through birth, the use of herbs, incantations, self-discipline or samadhi\".\n\nGanesha, Hanuman, various forms of Devi and various other deities are popularly seen as the keepers of siddhis, with the ability to grant them to the worshipper.\n\nIn Sikhism, siddhi means \"insight\". \"Eight Siddhis\" is used for insight of the eight qualities of Nirankar or a.k.a. Akal Purakh mentioned in the \"Mul Mantar\" in the Guru Granth Sahib. God has eight qualities: Oankar, Satnam, Kartapurakh, Nirbhao, Nirvair, AkaalMurat, Ajooni and Svaibhang. The one who has insight of these qualities is called \"Sidh\" or \"Gurmukhi\".\n\nIn Tantric Buddhism, siddhi specifically refers to the acquisition of supernatural powers by psychic or magical means or the supposed faculty so acquired. These powers include items such as clairvoyance, levitation, bilocation, becoming as small as an atom, materialization, and having access to memories from past lives.\n\n\n\n"}
{"id": "1002066", "url": "https://en.wikipedia.org/wiki?curid=1002066", "title": "Superflat", "text": "Superflat\n\nSuperflat is a postmodern art movement, founded by the artist Takashi Murakami, which is influenced by manga and anime. It is also the name of a 2001 art exhibition, curated by Murakami, that toured West Hollywood, Minneapolis and Seattle.\n\n\"Superflat\" is used by Murakami to refer to various flattened forms in Japanese graphic art, animation, pop culture and fine arts, as well as the \"shallow emptiness of Japanese consumer culture.\" Superflat has been embraced by American artists, who have created a hybrid called \"SoFlo Superflat\".\n\n\"Superflat\" Artists include Chiho Aoshima, Mahomi Kunikata, Sayuri Michima, Yoshitomo Nara, Aya Takano and Takashi Murakami. In addition, some animators within \"anime\" and some manga artist have had their past and present work exhibited in Superflat exhibitions, especially Kōji Morimoto, and the work of Hitoshi Tomizawa, author of \"Alien 9\" and \"Milk Closet\".\n\nMurakami defines \"Superflat\" in broad terms, so the subject matter is very diverse. Some works explore the consumerism and sexual fetishism that is prevalent in post-war Japanese culture. This often includes \"lolicon\" art, which is parodied by works such as those by Henmaru Machino. These works are an exploration of \"otaku\" sexuality through grotesque and/or distorted images. Other works are more concerned with a fear of growing up. For example, Yoshitomo Nara’s work often features playful graffiti on old Japanese \"ukiyo-e\" executed in a childish manner. And some works focus on the structure and underlying desires that comprise \"otaku\" and overall post-war Japanese culture. Murakami is influenced by directors such as Hideaki Anno.\n\nA subversive look at otakuism is not a defining factor of Kaikai Kiki's galleries; Bome, one of the most important artists involved with the very first Superflat exhibition, is a famous otaku figure sculptor and his work based on existing bishoujo anime characters has been showcased in multiple galleries including a solo exhibition in the Kaikai Kiki Gallery. The artist \"Mr.\" is a self-described lolicon and views his artwork to be not a cultural commentary but a portrayal of his own personal fantasies.\n\n\n"}
{"id": "40705054", "url": "https://en.wikipedia.org/wiki?curid=40705054", "title": "Sölvi Helgason", "text": "Sölvi Helgason\n\nSölvi Helgason (August 16, 1820 – November 27, 1895) was an artist, philosopher and drifter in Iceland in the 19th century. If he hadn't been arrested, we might not know anything more about Sölvi than folk tales about his life. He never went to school, but was known to always be painting and writing. It is posited from his writings that he was mentally ill and suffered from paranoia; he was known to accuse people of stealing his work. He often referred to himself by made-up names as well as names of playwrights, artists, musicians and philosophers: Sókrates, Plato, Sólon, Melanchthon, Sölvi Spekingur, Sjúlvi, Húsfriður, Sjúlvi Hinn Vitri, Húmboldt, Spinoza, Göte, Hegel, Schiller, Schott, Newton, Caesar, Leonardo da Vinci, Vasco da Gama, Kant, Lamertine, Skagfjörð Norðlandíus, Beethoven and Shakespeare. Sölvi was convicted several times for vagrancy, falsifying his traveling papers or passport and for petty theft. He was often flogged and spent three years in prison in Denmark. Today approximately 100 of Sölvi's artworks and manuscripts are in the collection of the National and University Library of Iceland and the National Museum of Iceland.\n\nThere are no known artworks dated prior to 1854, when Sölvi first went to prison. Although it is believed that he was drawing from a young age, Sölvi claimed in legal documents that his early artwork was destroyed.\n\nSölvi's artwork falls into two visual themes: 1) floral patterns with decorative capital letters and 2) figurative drawings.\n\nHis floral patterns don't change at all in the documented 30 years. These pieces were typically gifts to the people he was staying with.\n\nThe figurative drawings are mainly of people that Sölvi had conflict with. He would add horns and extra eyes in an attempt to portray these people as demonic. These artworks show a more creative and emotional side to Sölvi's artwork.\n\nSölvi Helgason was born on a farm called Fjall in Sléttuhliíð in the eastern part of Skagafjörður on August 16, 1820. The day after he was born, he was baptized at the nearest church. Sölvi's father was called Helgi Guðmundsson and his mother was called Ingiríður Gísladóttir, they were young, poor farmers who moved often between farms. When Sölvi was 4 his father died. He didn't live with his mother from the age of 6, he was fostered at various farms in the area around his home. His mother died when he was 14 years old.\n\nOral history describes Sölvi as reckless and unruly but that he showed signs of intelligence. There are also stories of a harsh upbringing. When Sölvi was 11, he was fostered for two years by a reverend called Ólafur Hjaltason Thorberg in Hvanneyri in Siglufjörður. The reverend he lived with had a library and it is thought that Sölvi got his inspiration for his artwork from viewing illustrated books; he also stated in legal documents that he learned to read both in Icelandic and Danish at this farm.\n\nAt the age of 15 Sölvi was fostered at a farm called Undhóll in Óslandshlíð, which wasn't far from a regional trading center in Kolkúos, where Sölvi may have purchased watercolor materials.\n\nBjörn Þórðarson, District Administrative Officer at Ystahóll helped Sölvi get confirmed at a local church when he was 16 years old. When he was 18 years old, he was sent to Möðruvellir in Hörgádalur to stay with Bjarni Thorarensen who was a prefect and poet. He stayed there for at least one year before he went east to Þingeyjar and Múlasýslu. From there he started drifting around the country.\n\nSölvi traveled around Iceland trading drawings of people and decorative letter forms for food and a place to sleep. In October 1843, Sölvi got arrested in Staðarsveit in Snæfellsnes. At that time, it was mandatory to have written permission from the sheriff in order to travel around Iceland; traveling papers or passport. Sölvi's traveling papers weren't acceptable because they contained strange praising writings about him and had an obviously forged signature of the local sheriff. He later admitted that he had falsified this passport. On March 8, 1825, Sölvi was sentenced for carrying a fake passport and for being a drifter. His punishment was 40 lashes and one year of supervision by the authorities. The punishment was reduced by the supreme court to 27 lashes and 8 months of supervision.\n\nIn March 1850, Sölvi was arrested again after being accused of stealing books and clothing. The authorities couldn't prove he had done so, however because of his history of petty theft and his continual illegal drifting around Iceland, he was sentenced in 1854 to spend three years in a prison in Copenhagen. In 1858 he came back to Iceland and was sent back to his home region. When he discussed his stay in Denmark, he pretended that he had been a free man.\n\nAfter his imprisonment in Denmark, sometime after 1860, Sölvi stayed at a farm in Húnavatnssýsla. There he met the Júlíana Sveinbjörnsdóttir, who is described as being both physically and mentally disabled, and who became his lover and traveling partner. Sölvi would carry Júlíana in a sack on his back while they traveled around Iceland; people would laugh and make fun of the pair, but Sölvi and Júlíana ignored the mockery, because there was no better way to travel. Together Sölvi and Júlíana had one daughter, Stefanía Kristín Sölvadóttir, in 1867. Because of his constant drifting, Sölvi didn't raise his daughter; she was considered to look very much like him, but they probably didn't know each other well. Stefanía had two children in Iceland, then just before 1900, she moved to America and had more children.\n\n"}
{"id": "3101936", "url": "https://en.wikipedia.org/wiki?curid=3101936", "title": "Terenzio, Count Mamiani della Rovere", "text": "Terenzio, Count Mamiani della Rovere\n\nTerenzio, Count Mamiani della Rovere (19 September 1799 – 21 May 1885) was an Italian writer, academic and politician, and was committed to the cause of the unification of Italy under ethe Sardinian monarchy.\n\nHe was born in Pesaro in 1799 during the Napoleonic upheaval in territory that had since 1631 belonged to the Papal States, but had earlier in its history been dominated for a time by the clan Della Rovere. He himself became the last to hold the title Count of Sant'Angelo in Lizzola.\n\nHe took part in the unrest at Bologna (also part of the Papal States) in reaction to the election of Pope Gregory XVI in February 1831, and was elected deputy for Pesaro to the assembly, and subsequently appointed minister of the interior; but on the collapse of the revolutionary movement he was exiled. He did not return to Italy with the amnesty that was offered upon the accession of Pope Pius IX in 1846, because he refused to sign the declaration of loyalty that was required as a condition of the amnesty. Pressure by the revolutionaries of 1848 forced the Pope to allow the Count to return to Rome to form a ministry on May 4, 1848, but he resigned later that year due to conflicts with the Pope.\n\nHe subsequently retired to Genoa where he worked for Italian unification, was elected deputy in 1856, and in 1860 became minister of education of the Kingdom of Sardinia under Cavour. In 1863 he was made minister (ambassador) of the recently declared Kingdom of Italy to Greece, and in 1865 to Switzerland, and later senator and councillor of state.\n\nMeanwhile, he had founded at Genoa in 1849 the Academy of Philosophy, and in 1855 had been appointed professor of the history of philosophy at Turin; and he published several volumes, not only on philosophical and social subjects, but of poetry, among them \"Rinnovamento della filosofia antica italiana\" (1836), \"Teoria della Religione e dello slato\" (1869), \"Kant e l'ontologia\" (1879), \"Religione deli avenire\" (1880), \"Di un nuovo diritto europeo\" (1843, 1857). He died at Rome on 21 May 1885.\n\nOn 15 August 1896, in connection with the solemn commemoration of Mamiani decreed by the city of Pesaro, the “11 September 1860\" Masonic Lodge made public his membership of freemasonry and on 20 August that year had affixed to his monument a bronze crown with the wording “To Brother Terenzio Mamiani, the Freemasonry of Italy\".\n"}
{"id": "32562272", "url": "https://en.wikipedia.org/wiki?curid=32562272", "title": "Toby Ord", "text": "Toby Ord\n\nToby David Godfrey Ord (born 18 July 1979) is an Australian philosopher. He is the founder of Giving What We Can, an international society dedicated to the elimination of poverty in the developing world.\n\nOrd attended the University of Melbourne, where he initially studied computer science. On completing his first degree, he switched to studying philosophy to pursue his interest in ethics: \"At this stage I knew that I wanted to make a large positive difference in the world and it seemed that studying ethics would help.\"\n\nFor his graduate studies, Ord moved to the University of Oxford, where he obtained both a B.Phil., and a D.Phil. in philosophy. Having submitted his doctoral thesis, 'Beyond Action: applying consequentialism to decision making and motivation’, Ord was retained as a junior research fellow by Balliol College, Oxford. Ord holds the position of a Research Fellow at Oxford's Future of Humanity Institute. He has published articles on ethics and the philosophy of computation. He promotes consequentialist ethics and his research interests include questions around global poverty, moral uncertainty and catastrophic risks.\n\nAt Oxford, Ord resolved to give a significant proportion of his income to the most cost-effective charities he could find. Following a number of enquiries from people interested in making a similar commitment, Ord decided to set up an organisation geared towards supporting like-minded donors. \n\nIn 2009, Ord launched Giving What We Can, an international society whose members have each pledged to donate at least 10% of their income to anti-poverty charities. The organisation is aligned with and part of the effective altruism movement. Giving What We Can seeks not only to encourage people to give more of their money to charity, but also stresses the importance of giving to cost-effective charities, arguing that \"research shows that some are up to 1,000 times as effective as others.\" While it does not collect money or undertake charity work directly, Giving What We Can carries out original research and recommends charities it believes to be particularly efficient. Ord remains director of Giving What We Can, and is closely involved in its day-to-day running.\n\nOrd himself decided initially to cap his income at £20,000 per year, and to give away everything he earned above that to well-researched charities, in line with the commitment Giving What We Can members make, of donating at least ten per cent of their incomes to the charities they believe to be the most effective. A year later, he revised this figure down to £18,000. Over the course of his career, he expects his donations to total around £1 million.\n\nOrd lives in Oxford with his wife, Bernadette Young, a medical doctor. She is also a member of Giving What We Can.\n\n"}
{"id": "1694384", "url": "https://en.wikipedia.org/wiki?curid=1694384", "title": "Tự Đức", "text": "Tự Đức\n\nTự Đức (, 22 September 1829 – 17 July 1883) (full name: Nguyễn Phúc Hồng Nhậm , also Nguyễn Phúc Thì) was the fourth emperor of the Nguyễn dynasty of Vietnam; he ruled from 1847 to 1883.\n\nThe son of Emperor Thiệu Trị, Prince Nguyễn Phúc Hồng Nhậm was born on 22 September 1829, and succeeded his father on the throne, with the reigning title of Tự Đức, but family troubles caused his era to have a violent start. Gia Long had passed over his more moderate eldest son, Quang Bảo, to give the throne to Tự Đức, known for his staunch Confucianism and opposition to foreigners and innovation. As a result, and due to the repressive policies of the previous Nguyễn Dynasty emperor, there was now a great deal of dissatisfaction with Nguyễn rule and a legitimate royal figure to rally this opposition.\n\nPrince Nguyễn Phúc Hồng Bảo became the leader of a rebellion against Tự Đức, consisting of Confucian scholars who were angered that the family hierarchy had been dishonored (by passing over the eldest son) some remaining supporters of the Lê Dynasty (who many still considered the legitimate dynasty of Vietnam) as well as the usual peasants angry over Nguyễn taxation and the usual corrupt mandarins as well as the Roman Catholic missionaries and Christian converts who had been so persecuted by Minh Mạng and Thiệu Trị. With swift military force, Tự Đức suppressed the rebellion and was set to execute his brother, but was dissuaded by his mother, Dowager queen Từ Dũ, and Hồng Bảo killed himself in prison.\nEmperor Tự Đức continued the policies of his predecessors, shutting Vietnam off from the outside world and refusing all efforts to modernize the country. Accounts of his personal life show a gentle and educated man, but his policies brought on conflict with Europe that Vietnam could not win. He oppressed all foreigners in Vietnam, especially the Christian community, who had tried to overthrow his father, such as in the Lê Văn Khôi revolt, calling their religion a \"perverse doctrine\". The Christian mandarin Nguyễn Trường Tộ tried to convince Tự Đức that this was a suicidal policy, but he did not listen, confident that France was too involved with the chaos in Europe in 1848 to respond, but he was mistaken.\n\nFrance responded with a large military expeditionary force and attacked up from southern Vietnam. The Nguyễn army fought bravely for some time, but their antiquated weapons and tactics were no match for the French, who suffered more from the climate and disease than from enemy resistance. With French forces moving closer against him, Tự Đức called upon his Manchu over-lord, the Qing Emperor, for help and so ensued the Sino-French War. The fighting around Hanoi against China and the Black Flag pirates ended with France victorious and China gave up their position as feudal master of Vietnam and recognized France as the ruling power over the region.\n\nTo make matters worse, Emperor Tự Đức had to deal with renewed internal rebellions which had become commonplace for the Nguyễn Dynasty. There were literally hundreds of small rebellions and uprisings against Nguyễn rule. Ineffective attempts to enforce the ban on Christian missionaries were also the biggest source of trouble, including the execution of a Spanish bishop which was used to justify the French and Spanish invasion that led to the fall of Saigon. By an order of 1848 Tự Đức commanded all Vietnamese Catholic converts to renounce their religion, otherwise they would be branded on the face with the mark of a heretic and surrender all of their rights and privileges. This rallied most of the European powers against Vietnam, and Tự Đức by doing this had given up any hope of Vietnam gaining help as a victim from the outside world.\n\nWhen further rebellions broke out as the French were advancing on the capital, Tự Đức feared that his authority was crumbling. He preferred to make a deal with the French so that he could crush the rebellion since while France may demand humiliating concessions, the rebels would most likely depose and/or kill him. He signed away the southernmost of Vietnam, Cochinchina, to be a French colony and accepted the status of a French protectorate for his country. This caused a huge uproar, and many, such as the famous mandarin Trương Định, refused to recognize the treaty and fought on in defense of their country, denouncing Tự Đức for surrendering any part of their homeland.\n\nEmperor Tự Đức did not live to see the worst effects of colonialism on his country, but he is often regarded as the last Emperor of Vietnam to rule independently. A case of smallpox left him impotent so he had no children despite a huge harem of wives he kept in his palace. According to legend, he died in 1883, cursing the French with his dying breath. After his death his adopted son Dục Đức was deposed by court officials after a reign of three days.\n\n"}
{"id": "10980467", "url": "https://en.wikipedia.org/wiki?curid=10980467", "title": "Unate function", "text": "Unate function\n\nA unate function is a type of boolean function which has monotonic properties.\nThey have been studied extensively in switching theory.\n\nA function formula_1 is said to be positive unate in formula_2\nif for all possible values of formula_3, formula_4\nLikewise, it is negative unate in formula_2 if\nIf for every formula_2 \"f\" is either positive or negative unate in the variable formula_2 then it is said to be unate (note that some formula_2 may be positive unate and some negative unate to satisfy the definition of unate function). A function is binate if it is not unate (i.e., is neither positive unate nor negative unate in at least one of its variables).\n\nFor example, the Logical disjunction function \"or\" with boolean values used for true (1) and false (0) is positive unate. Conversely, Exclusive or is non-unate, because the transition from 0 to 1 on input x0 is both positive unate and negative unate, depending on the input value on x1.\n\nNB: positive unateness can also be considered as passing the same slope (no change in the input) and negative unate is passing the opposite slope...\nnon unate is dependence on more than one input (of same or different slopes)\n"}
{"id": "28602266", "url": "https://en.wikipedia.org/wiki?curid=28602266", "title": "Werturteilsstreit", "text": "Werturteilsstreit\n\nThe Werturteilsstreit (German for \"value judgment dispute\") is a \"Methodenstreit\", a quarrel in German sociology and economics around the question whether the social sciences are a normative obligatory statement in politics and its measures applied in political actions, and whether their measures can be justified scientifically.\n\nThe quarrel took place in the years before World War I, between the members of the Verein für Socialpolitik. Main opponents were Max Weber, Werner Sombart and Gustav Schmoller.\n\nThe \"Zweiter Werturteilsstreit\" is the debate between the supporter of the Kritische Theorie and the Kritischer Rationalismus during the 1960s — better known as \"Positivismusstreit\".\n\n"}
{"id": "12152471", "url": "https://en.wikipedia.org/wiki?curid=12152471", "title": "Zhegalkin polynomial", "text": "Zhegalkin polynomial\n\nZhegalkin (also Žegalkin, Gégalkine or Shegalkin) polynomials form one of many possible representations of the operations of Boolean algebra. Introduced by the Russian mathematician Ivan Ivanovich Zhegalkin in 1927, they are the polynomials of ordinary high school algebra interpreted over the integers mod 2. The resulting degeneracies of modular arithmetic result in Zhegalkin polynomials being simpler than ordinary polynomials, requiring neither coefficients nor exponents. Coefficients are redundant because 1 is the only nonzero coefficient. Exponents are redundant because in arithmetic mod 2, \"x\" = \"x\". Hence a polynomial such as 3\"x\"\"y\"\"z\" is congruent to, and can therefore be rewritten as, \"xyz\".\n\nPrior to 1927 Boolean algebra had been considered a calculus of logical values with logical operations of conjunction, disjunction, negation, etc. Zhegalkin showed that all Boolean operations could be written as ordinary numeric polynomials, thinking of the logical constants 0 and 1 as integers mod 2. The logical operation of conjunction is realized as the arithmetic operation of multiplication \"xy\", and logical exclusive-or as arithmetic addition mod 2, (written here as \"x\"⊕\"y\" to avoid confusion with the common use of + as a synonym for inclusive-or ∨). Logical complement ¬\"x\" is then derived from 1 and ⊕ as \"x\"⊕1. Since ∧ and ¬ form a sufficient basis for the whole of Boolean algebra, meaning that all other logical operations are obtainable as composites of these basic operations, it follows that the polynomials of ordinary algebra can represent all Boolean operations, allowing Boolean reasoning to be performed reliably by appealing to the familiar laws of high school algebra without the distraction of the differences from high school algebra that arise with disjunction in place of addition mod 2.\n\nAn example application is the representation of the Boolean 2-out-of-3 threshold or median operation as the Zhegalkin polynomial \"xy\"⊕\"yz\"⊕\"zx\", which is 1 when at least two of the variables are 1 and 0 otherwise.\n\nFormally a \"Zhegalkin monomial\" is the product of a finite set of distinct variables (hence square-free), including the empty set whose product is denoted 1. There are 2 possible Zhegalkin monomials in \"n\" variables, since each monomial is fully specified by the presence or absence of each variable. A \"Zhegalkin polynomial\" is the sum (exclusive-or) of a set of Zhegalkin monomials, with the empty set denoted by 0. A given monomial's presence or absence in a polynomial corresponds to that monomial's coefficient being 1 or 0 respectively. The Zhegalkin monomials, being linearly independent, span a 2-dimensional vector space over the Galois field GF(2) (NB: not GF(2), whose multiplication is quite different). The 2 vectors of this space, i.e. the linear combinations of those monomials as unit vectors, constitute the Zhegalkin polynomials. The exact agreement with the number of Boolean operations on \"n\" variables, which exhaust the \"n\"-ary operations on {0,1}, furnishes a direct counting argument for completeness of the Zhegalkin polynomials as a Boolean basis.\n\nThis vector space is not equivalent to the free Boolean algebra on \"n\" generators because it lacks complementation (bitwise logical negation) as an operation (equivalently, because it lacks the top element as a constant). This is not to say that the space is not closed under complementation or lacks top (the all-ones vector) as an element, but rather that the linear transformations of this and similarly constructed spaces need not preserve complement and top. Those that do preserve them correspond to the Boolean homomorphisms, e.g. there are four linear transformations from the vector space of Zhegalkin polynomials over one variable to that over none, only two of which are Boolean homomorphisms.\n\nThere are three known methods generally used for the computation of the Zhegalkin polynomial. \n\nUsing the method of indeterminate coefficients, a linear system consisting of all the tuples of the function and their values is generated. Solving the linear system gives the coefficients of the Zhegalkin polynomial.\n\nUsing this method, the canonical disjunctive normal form (a fully expanded disjunctive normal form) is computed first. Then the negations in this expression are replaced by an equivalent expression using the mod 2 sum of the variable and 1. The disjunction signs are changed to addition mod 2, the brackets are opened, and the resulting Boolean expression is simplified. This simplification results in the Zhegalkin polynomial.\n\nLet formula_1 be the outputs of a truth table for the function \"P\" of \"n\" variables, such that the index of the formula_2's corresponds to the binary indexing of the minterms. Define a function ζ recursively like so:\nNote that\nwhere the binomial coefficient formula_6 is reduced modulo 2.\nThen\nis the \"i\" coefficient of a Zhegalkin polynomial whose literals in the \"i\" monomial are the same as the literals in the \"i\" minterm, except that the negative literals are removed (or replaced by 1).\n\nThe ζ-transformation is its own inverse, so the same kind of table can be used to compute the coefficients formula_1 given the coefficients formula_9. Just let\n\nIn terms of the table in the figure, copy the outputs of the truth table (in the column labeled \"P\") into the leftmost column of the triangular table. Then successively compute columns from left to right by applying XOR to each pair of vertically adjacent cells in order to fill the cell immediately to the right of the top cell of each pair. When the entire triangular table is filled in then the top row reads out the coefficients of a linear combination which, when simplified (removing the zeroes), yields the Zhegalkin polynomial.\n\nTo go from a Zhegalkin polynomial to a truth-table, it is possible to fill out the top row of the triangular table with the coefficients of the Zhegalkin polynomial (putting in zeroes for any combinations of positive literals not in the polynomial). Then successively compute rows from top to bottom by applying XOR to each pair of horizontally adjacent cells in order to fill the cell immediately to the bottom of the leftmost cell of each pair. When the entire triangular table is filled then the leftmost column of it can be copied to column \"P\" of the truth table.\n\nIn the same year as Zhegalkin's paper (1927) the American mathematician Eric Temple Bell published a sophisticated arithmetization of Boolean algebra based on Richard Dedekind's ideal theory and general modular arithmetic (as opposed to arithmetic mod 2). The much simpler arithmetic character of Zhegalkin polynomials was first noticed in the west (independently, communication between Soviet and Western mathematicians being very limited in that era) by the American mathematician Marshall Stone in 1936 when he observed while writing up his celebrated Stone duality theorem that the supposedly loose analogy between Boolean algebras and rings could in fact be formulated as an exact equivalence holding for both finite and infinite algebras, leading him to substantially reorganize his paper.\n\n\n"}
{"id": "40979611", "url": "https://en.wikipedia.org/wiki?curid=40979611", "title": "Étienne Balibar", "text": "Étienne Balibar\n\nÉtienne Balibar (; ; born 23 April 1942) is a French philosopher. He has taught at the University of Paris X-Nanterre, at the University of California Irvine and is currently an Anniversary Chair Professor at the Centre for Research in Modern European Philosophy (CRMEP) at Kingston University and a Visiting Professor at the Department of French and Romance Philology at Columbia University.\n\nBalibar was born in Avallon, Yonne, Burgundy, France in 1942, and first rose to prominence as one of Althusser's pupils at the École normale supérieure. He entered the École normale supérieure in 1960.\n\nIn 1961, Balibar joined the \"Parti communiste français\". He was expelled in 1981 for critiquing the party's policy on immigration in an article.\n\nBalibar participated in Louis Althusser's seminar on Karl Marx's \"Das Kapital\" in 1965. This seminar resulted in the book \"Reading Capital\", co-authored by Althusser and his students. Balibar's chapter, \"On the Basic Concepts of Historical Materialism,\" was republished along with those of Althusser in the book's abridged version (trans. 1970), until a complete translation was published in 2016.\n\nIn 1987, he received his doctorate degree in philosophy from the \"Katholieke Universiteit Nijmegen\" in the Netherlands. He received his habilitation from the Université Paris I in 1993. Balibar joined the University of Paris X-Nanterre as a professor in 1994, and the University of California, Irvine in 2000. He became Professor Emeritus of Paris X in 2002.\n\nHis daughter with the physicist Françoise Balibar is the actress Jeanne Balibar.\n\nIn \"Masses, Classes and Ideas\", Balibar argues that in \"Das Kapital\" (or \"Capital\"), the theory of historical materialism comes into conflict with the critical theory that Marx begins to develop, particularly in his analysis of the category of labor, which in capitalism becomes a form of property. This conflict involves two distinct uses of the term \"labor\": labor as the revolutionary class subject (i.e., the \"proletariat\") and labor as an objective condition for the reproduction of capitalism (the \"working class\"). In \"The German Ideology\", Marx conflates these two meanings, and treats labor as, in Balibar’s words, the \"veritable site of truth as well as the place from which the world is changed...\"\n\nIn \"Capital\", however, the disparity between the two senses of labor becomes apparent. One manifestation of this is the virtual disappearance in the text of the term \"proletariat.\" As Balibar points out, the term appears only twice in the first edition of \"Capital\", published in 1867: in the dedication to Wilhelm Wolff and in the two final sections on the \"General Law of Capitalist Accumulation\". For Balibar, this implies that \"the emergence of a revolutionary form of subjectivity (or identity)... is never a specific property of nature, and therefore brings with it no guarantees, but obliges us to search for the conditions in a conjuncture that can precipitate class struggles into mass movements...\". Moreover, \"[t]here is no proof… that these forms are always and eternally the same (for example, the party-form, or the trade union).\"\n\nIn \"The Nation Form: History and Ideology,\" Balibar critiques modern conceptions of the nation-state. He states that he is undertaking a study of the contradiction of the nation-state because \"Thinking about racism led us back to nationalism, and nationalism to uncertainty about the historical realities and categorization of the nation\" (329).\n\nBalibar contends that it is impossible to pinpoint the beginning of a nation or to argue that the modern people who inhabit a nation-state are the descendants of the nation that preceded it. Balibar argues that, because no nation-state has an ethnic base, every nation-state must create fictional ethnicities in order to project stability on the populace: \n\n\"the idea of nations without a state, or nations 'before' the state, is thus a contradiction in terms, because a state always is implied in the historic framework of a national formation (even if not necessarily within the limits of its territory). But this contradiction is masked by the fact that national states, whose integrity suffers from internal conflicts that threaten its survival (regional conflicts, and especially class conflicts), project beneath their political existence to a preexisting 'ethnic' or 'popular' unity\" (331)\n\nIn order to minimize these regional, class, and race conflicts, nation-states fabricate myths of origin that produce the illusion of shared ethnicity among all their inhabitants. In order to create these myths of origins, nation-states scour the historical period during which they were \"formed\" to find justification for their existence. They also create the illusion of shared ethnicity through linguistic communities: when everyone has access to the same language, they feel as if they share an ethnicity. Balibar argues that \"schooling is the principal institution which produces ethnicity as linguistic community\" (351). In addition, this ethnicity is created through the \"nationalization of the family,\" meaning that the state comes to perform certain functions that might traditionally be performed by the family, such as the regulation of marriages and administration of social security.\n\n\n\n\n\n\n"}
