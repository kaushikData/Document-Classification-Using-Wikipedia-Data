{"id": "44538513", "url": "https://en.wikipedia.org/wiki?curid=44538513", "title": "(a, b)-decomposition", "text": "(a, b)-decomposition\n\nIn graph theory, the (\"a\", \"b\")-decomposition of an undirected graph is a partition of its edges into \"a\" + 1 sets, each one of them inducing a forest, except one who induces a graph with maximum degree \"b\". If this graph is also a forest, then we call this a F(\"a\", \"b\")-decomposition.\n\nA graph with arboricity \"a\" is (\"a\", 0)-decomposable. Every (\"a\", \"0\")-decomposition or (\"a\", \"1\")-decomposition is a F(\"a\", \"0\")-decomposition or a F(\"a\", \"1\")-decomposition respectively.\n\n\n"}
{"id": "9233578", "url": "https://en.wikipedia.org/wiki?curid=9233578", "title": "Assertion definition language", "text": "Assertion definition language\n\nThe Assertion Definition Language (ADL) is a specification language providing a formal grammar to specify behaviour and interfaces for computer software. ADL uses function pre- and postconditions to specify interfaces and is designed to provide an intermediary between informal English language specifications and formal programmatic test specifications. Tool support exists both to convert ADL specifications into natural language, and to generate test systems against which implementation code can be verified.\n\nADL is developed cooperatively by The Open Group and SunTest of Sun Microsystems \n\n\n"}
{"id": "2082354", "url": "https://en.wikipedia.org/wiki?curid=2082354", "title": "Bézout matrix", "text": "Bézout matrix\n\nIn mathematics, a Bézout matrix (or Bézoutian or Bezoutiant) is a special square matrix associated with two polynomials, introduced by and and named after Étienne Bézout. Bézoutian may also refer to the determinant of this matrix, which is equal to the resultant of the two polynomials. Bézout matrices are sometimes used to test the stability of a given polynomial.\n\nLet formula_1 and formula_2 be two complex polynomials of degree at most \"n\",\n(Note that any coefficient formula_4 or formula_5 could be zero.) The Bézout matrix of order \"n\" associated with the polynomials \"f\" and \"g\" is \nwhere the entries formula_7 result from the identity\n\nIt is in formula_9 and the entries of that matrix are such that if we let formula_10 for each formula_11, then:\n\nTo each Bézout matrix, one can associate the following bilinear form, called the Bézoutian:\n\n\nThe last row and column are all zero as \"f\" and \"g\" have degree strictly less than \"n\" (equal 4). The other zero entries are because for each formula_18, either formula_4 or formula_5 is zero.\n\n\nAn important application of Bézout matrices can be found in control theory. To see this, let \"f\"(\"z\") be a complex polynomial of degree \"n\" and denote by \"q\" and \"p\" the real polynomials such that \"f\"(i\"y\") = \"q\"(\"y\") + i\"p\"(\"y\") (where \"y\" is real). We also note \"r\" for the rank and \"σ\" for the signature of formula_31. Then, we have the following statements:\n\nThe third statement gives a necessary and sufficient condition concerning stability. Besides, the first statement exhibits some similarities with a result concerning Sylvester matrices while the second one can be related to Routh–Hurwitz theorem.\n\n"}
{"id": "1181756", "url": "https://en.wikipedia.org/wiki?curid=1181756", "title": "Carmichael function", "text": "Carmichael function\n\nIn number theory, the Carmichael function associates to every positive integer \"n\" a positive integer formula_1, defined as the smallest positive integer \"m\" such that\n(Dropping the phrase \"between 1 and \"n\"\" leads to an equivalent definition.) \nIn algebraic terms, formula_1 equals the exponent of the multiplicative group of integers modulo \"n\". \n\nThe Carmichael function is named after the American mathematician Robert Carmichael and is also known as the reduced totient function or the least universal exponent function.\n\nThe first 36 values of formula_1 compared to Euler's totient function formula_5. (in bold if they are different, the \"n\"s such that they are different are listed in )\n\nCarmichael's function at 8 is 2, i.e. formula_6, because for any number \"a\" co-prime to 8 it holds that \"a\" ≡ 1 (mod 8). Namely, 1 = 1 (mod 8), 3 = 9 ≡ 1 (mod 8), 5 = 25 ≡ 1 (mod 8) and 7 = 49 ≡ 1 (mod 8). Euler's totient function at 8 is 4, i.e. formula_7, because there are 4 numbers lesser than and coprime to 8 (1, 3, 5, and 7). Euler's theorem assures that \"a\" ≡ 1 (mod 8) for all \"a\" coprime to 8, but 4 is not the smallest such exponent.\n\nBy the fundamental theorem of arithmetic any \"n\" > 1 can be written in a unique way as\nwhere \"p\" < \"p\" < ... < \"p\" are primes and \"r\" , ..., \"r\" are positive integers. It is then the case that \"λ\"(\"n\") is the least common multiple of the \"λ\" of each of its prime power factors:\nThis can be proved using the Chinese Remainder Theorem.\n\nCarmichael's theorem explains how to compute \"λ\" of a prime power: for a power of an odd prime and for 2 and 4, \"λ\"(\"n\") is equal to the Euler totient \"φ\"(\"n\"); for powers of 2 greater than 4 it is equal to half of the Euler totient.\n\nEuler's function for prime powers is given by\n\nThis follows from elementary group theory, because the exponent of any finite abelian group must divide the order of the group. \"λ\"(\"n\") is the exponent of the multiplicative group of integers modulo \"n\" while \"φ\"(\"n\") is the order of that group.\n\nWe can thus view Carmichael's theorem as a sharpening of Euler's theorem. \n\nSuppose formula_12 for all numbers \"a\" coprime with \"n\". Then formula_13.\n\nProof. If formula_14 with formula_15, then formula_16 for all numbers \"a\" coprime with \"n.\" It follows formula_17 , since formula_18 and formula_1 the minimal positive such number.\n\nProof. The result follows from the formula\n\nformula_21\n\nmentioned above.\n\nFor all positive integers formula_22 and formula_23 it holds\nThis is an immediate consequence of the recursive definition of the Carmichael function.\n\nLet formula_22 and formula_26 be coprime and\nlet formula_27 be the smallest exponent with formula_2,\nthen it holds\nThat is, the orders of primitive roots of unity in the ring of integers modulo formula_26 are divisors of formula_31.\n\nIf formula_26 has maximum prime exponent formula_33 under prime factorization, then for all formula_22 (including those not co-prime to formula_26) and all formula_36,\n\nIn particular, for squarefree formula_26 (formula_39), for all formula_22\n\nFor any \"x\" > 16:\n\nWhere \"B\" is a constant,\n\nFor all numbers \"N\" and all except \"o\"(\"N\") positive integers \"n ≤ \"N\":\nwhere \"A\" is a constant,\n\nFor any sufficiently large number \"N\" and for any formula_46, there are at most\npositive integers formula_48 such that formula_49.\n\nFor any sequence formula_50 of positive integers, any constant formula_51, and any sufficiently large \"i\":\n\nFor a constant \"c\" and any sufficiently large positive \"A\", there exists an integer formula_53 such that formula_54.\nMoreover, \"n\" is of the form\nfor some square-free integer formula_56.\n\nThe set of values of the Carmichael function has counting function \nwhere formula_58….\n\nThe Carmichael function is important in cryptography due its use in\nthe RSA encryption algorithm.\n\n\n"}
{"id": "15510395", "url": "https://en.wikipedia.org/wiki?curid=15510395", "title": "Chaplygin problem", "text": "Chaplygin problem\n\nIn mathematics, particularly in the fields of nonlinear dynamics and the calculus of variations, the Chaplygin problem is an isoperimetric problem with a differential constraint. Specifically, the problem is to determine what flight path an airplane in a constant wind field should take in order to encircle the maximum possible area. The airplane is assumed to be constrained to move in a plane, moving at a constant airspeed \"v\", and the wind is assumed to move in a constant direction with speed \"w\".\n\nThe solution of the problem is that the airplane should travel in an ellipse whose eccentricity is \"w\"/\"v\".\n\n"}
{"id": "48088710", "url": "https://en.wikipedia.org/wiki?curid=48088710", "title": "Chordal completion", "text": "Chordal completion\n\nIn graph theory, a branch of mathematics, a chordal completion of a given undirected graph is a chordal graph, on the same vertex set, that has as a subgraph.\nA minimal chordal completion is a chordal completion such that any graph formed by removing an edge would no longer be a chordal completion. The minimum chordal completion is a chordal completion with as few edges as possible. \n\nA different type of chordal completion, one that minimizes the size of the maximum clique in the resulting chordal graph, can be used to define the treewidth of . Chordal completions can also be used to characterize several other graph classes including AT-free graphs, claw-free AT-free graphs, and cographs.\n\nThe minimum chordal completion was one of twelve computational problems whose complexity was listed as open in the 1979 book \"Computers and Intractability\".\nApplications of chordal completion include modeling the problem of minimizing fill-in when performing Gaussian elimination on sparse symmetric matrices, and reconstructing phylogenetic trees.\n\nChordal completions of a graph are sometimes called triangulations, but this term is ambiguous even in the context of graph theory, as it can also refer to maximal planar graphs.\n\nA graph is an AT-free graph if and only if all of its minimal chordal completions are interval graphs. is a claw-free AT-free graph if and only if all of its minimal chordal completions are proper interval graphs. And is a cograph if and only if all of its minimal chordal completions are trivially perfect graphs.\n\nA graph has treewidth at most if and only if has at least one chordal completion whose maximum clique size is at most . It has pathwidth at most if and only if has at least one chordal completion that is an interval graph with maximum clique size at most . It has bandwidth at most if and only if has at least one chordal completion that is a proper interval graph with maximum clique size at most . And it has tree-depth if and only if it has at least one chordal completion that is a trivially perfect graph with maximum clique size at most .\n\nThe original application of chordal completion described in \"Computers and Intractability\" involves Gaussian elimination for sparse matrices. During the process of Gaussian elimination, one wishes to minimize fill-in, coefficients of the matrix that were initially zero but later become nonzero, because the need to calculate the values of these coefficients slows down the algorithm. The pattern of nonzeros in a sparse symmetric matrix can be described by an undirected graph (having the matrix as its adjacency matrix); the pattern of nonzeros in the filled-in matrix is always a chordal graph, any minimal chordal completion corresponds to a fill-in pattern in this way. If a chordal completion of a graph is given, a sequence of steps in which to perform Gaussian elimination to achieve this fill-in pattern can be found by computing an elimination ordering of the resulting chordal graph. In this way, the minimum fill-in problem can be seen as equivalent to the minimum chordal completion problem. In this application, planar graphs may arise in the solution of two-dimensional finite element systems; it follows from the planar separator theorem that every planar graph with vertices has a chordal completion with at most edges.\n\nAnother application comes from phylogeny, the problem of reconstructing evolutionary trees, for instance trees of organisms subject to genetic mutations or trees of sets of ancient manuscripts copied one from another subject to scribal errors. If one assumes that each genetic mutation or scribal error happens only once, one obtains a perfect phylogeny, a tree in which the species or manuscripts having any particular characteristic always form a connected subtree. As describes, the existence of a perfect phylogeny can be modeled as a chordal completion problem. One draws an \"overlap graph\" in which the vertices are attribute values (specific choices for some characteristic of a species or manuscript) and the edges represent pairs of attribute values that are shared by at least one species. The vertices of the graph can be colored by the identities of the characteristics that each attribute value comes from, so that the total number of colors equals the number of characteristics used to derive the phylogeny. Then a perfect phylogeny exists if and only if has a chordal completion that respects the coloring.\n\nAlthough listed as an open problem in the 1979 book \"Computers and Intractability\", the computational complexity of the minimum chordal completion problem (also called the minimum fill-in problem) was quickly resolved: showed it to be NP-complete. If the minimum chordal completion adds edges to a graph , then it is possible to find a chordal completion using at most added edges, in polynomial time. The problem of finding the optimal set of edges to add can also be solved by a fixed-parameter tractable algorithm, in time polynomial in the graph size and subexponential in .\n\nThe treewidth (minimum clique size of a chordal completion) and related parameters including pathwidth and tree-depth are also NP-complete to compute, and (unless P=NP) cannot be approximated in polynomial time to within a constant factor of their optimum values; however, approximation algorithms with logarithmic approximation ratios are known for them.\n\nBoth the minimum fill-in and treewidth problems can be solved in exponential time. More precisely, for an -vertex graph, the time is .\n"}
{"id": "5893760", "url": "https://en.wikipedia.org/wiki?curid=5893760", "title": "Claude Berge", "text": "Claude Berge\n\nClaude Jacques Berge (5 June 1926 – 30 June 2002) was a French mathematician, recognized as one of the modern founders of combinatorics and graph theory.\n\nClaude Berge was the son of André Berge and Geneviève Fourcade, and the great-grandson of French President Félix Faure. Claude was the second of six children; his siblings were Nicole, Antoine, Philippe, Edith and Patrick. He married Jane Gentaz on December 29, 1952 and had one child, Delphine, born March 1, 1964.\nAlthough Claude Berge was unsure if he wanted study mathematics, instead often leaning towards literature, after studying at the in Verneuil-sur-Avre, he attended the University of Paris to study mathematics and earned his Ph.D. in 1953, advised by André Lichnerowicz. At the University of Paris, Berge wrote several papers including his doctorate thesis paper \"Sur une théorie ensembliste des jeux alternatifs.\" In this paper, Berge examines properties of games where there is perfect information available and there are infinite choices for each move. This thesis served as the basis of a 55-page paper published in 1953.\n\nBeginning in 1952 he was a Research Assistant at the French National Centre for Scientific Research (CNRS), and from 1957 to 1964 he was a Professor at the Institute of Statistics at the University of Paris. From 1965 to 1967 he directed the International Computing Center in Rome. He was also associated with the Centre d'Analyse et de Mathématique Sociales (CAMS), a research center of École des hautes études en sciences sociales. He held visiting positions at Princeton University in 1957, Pennsylvania State University in 1968, and New York University in 1985, and was a frequent visitor to the Indian statistical institute, Calcutta.\n\nBerge wrote five books, on game theory (1957), graph theory and its applications (1958), topological spaces (1959), principles of combinatorics (1968) and hypergraphs (1970), each being translated in several languages. These books helped bring the subjects of graph theory and combinatorics out of disrepute by highlighting the successful practical applications of the subjects. He is particularly remembered for two conjectures on perfect graphs that he made in the early 1960s but were not proved until significantly later:\n\nHe is also known for his maximum theorem in optimization and for Berge's lemma, which states that a matching \"M\" in a graph \"G\" is maximum if and only if there is in \"G\" no augmenting path with respect to \"M\".\n\nIn addition to mathematics, Claude Berge enjoyed literature, sculpture, and art. Berge co-founded the French literary group Oulipo with novelists and other mathematicians in 1960 to create new forms of literature. In this association, he wrote a murder mystery based on a mathematical theorem: \"Who killed the Duke of Densmore?\" In an adaptation of this story, the Duke of Densmore is killed by an explosion. 10 years later, Sherlock Holmes and Watson are called to investigate this unsolved case. Using the testimonies of the Duke's seven ex-wives and his knowledge of interval graphs, Holmes is able to determine which one made multiple visits to the Duke and was able to plant the bomb.\n\nBerge won the EURO Gold Medal from the Association of European Operational Research Societies in 1989, and (with Ronald Graham) the inaugural\nEuler Medal from the Institute of Combinatorics and its Applications in 1993.\n\n\n\n"}
{"id": "46450960", "url": "https://en.wikipedia.org/wiki?curid=46450960", "title": "Consecutive sampling", "text": "Consecutive sampling\n\nIn the design of experiments, consecutive sampling, also known as total enumerative sampling, is a sampling technique in which every subject meeting the criteria of inclusion is selected until the required sample size is achieved. Along with convenience sampling and snowball sampling, consecutive sampling is one of the most commonly used kinds of nonprobability sampling. Consecutive sampling is typically better than convenience sampling in controlling sampling bias.\nCare needs to be taken with consecutive sampling, however, in the case that the quantity of interest has temporal or seasonal trends. Bias can also occur in consecutive sampling when consecutive samples have some common similarity, such as consecutive houses on a street.\n"}
{"id": "7489059", "url": "https://en.wikipedia.org/wiki?curid=7489059", "title": "Constraint (information theory)", "text": "Constraint (information theory)\n\nConstraint in information theory is the degree of statistical dependence between or among variables. \n\nGarner provides a thorough discussion of various forms of constraint (internal constraint, external constraint, total constraint) with application to pattern recognition and psychology.\n\n"}
{"id": "38279132", "url": "https://en.wikipedia.org/wiki?curid=38279132", "title": "Convergent encryption", "text": "Convergent encryption\n\nConvergent encryption, also known as content hash keying, is a cryptosystem that produces identical ciphertext from identical plaintext files. This has applications in cloud computing to remove duplicate files from storage without the provider having access to the encryption keys. The combination of deduplication and convergent encryption was described in a backup system patent filed by Stac Electronics in 1995. This combination has been used by Farsite, Permabit, Freenet, MojoNation, GNUnet, flud, and the Tahoe Least-Authority File Store.\n\nThe system gained additional visibility in 2011 when cloud storage provider Bitcasa announced they were using convergent encryption to enable de-duplication of data in their cloud storage service.\n\n\nConvergent encryption is open to a \"confirmation of a file attack\" in which an attacker can effectively confirm whether a target possesses a certain file by encrypting an unencrypted, or plain-text, version and then simply comparing the output with files possessed by the target. This attack poses a problem for a user storing information that is non-unique, i.e. also either publicly available or already held by the adversary - for example: banned books or files that cause copyright infringement. An argument could be made that a confirmation of a file attack is rendered less effective by adding a unique piece of data such as a few random characters to the plain text before encryption; this causes the uploaded file to be unique and therefore results in a unique encrypted file. However, some implementations of convergent encryption where the plain-text is broken down into blocks based on file content, and each block then independently convergently encrypted may inadvertently defeat attempts at making the file unique by adding bytes at the beginning or end.\n\nEven more alarming than the confirmation attack is the \"learn the remaining information attack\" described by Drew Perttula in 2008. This type of attack applies to the encryption of files that are only slight variations of a public document. For example, if the defender encrypts a bank form including a ten digit bank account number, an attacker that is aware of generic bank form format may extract defender's bank account number by producing bank forms for all possible bank account numbers, encrypt them and then by comparing those encryptions with defender's encrypted file deduce the bank account number. Note that this attack can be extended to attack a large number of targets at once (all spelling variations of a target bank customer in the example above, or even all potential bank customers), and the presence of this problem extends to any type of form document: tax returns, financial documents, healthcare forms, employment forms, etc. Also note that there is no known method for decreasing the severity of this attack -- adding a few random bytes to files as they are stored does not help, since those bytes can likewise be attacked with the \"learn the remaining information\" approach. The only effective approach to mitigating this attack is to encrypt the contents of files with a non-convergent secret before storing (negating any benefit from convergent encryption), or to simply not use convergent encryption in the first place.\n\n"}
{"id": "447020", "url": "https://en.wikipedia.org/wiki?curid=447020", "title": "Dedekind eta function", "text": "Dedekind eta function\n\nIn mathematics, the Dedekind eta function, named after Richard Dedekind, is a modular form of weight 1/2 and is a function defined on the upper half-plane of complex numbers, where the imaginary part is positive.\n\nFor any complex number formula_1 with formula_2, let formula_3, then the eta function is defined by,\n\nThe notation formula_5 is now standard in number theory, though many older books use \"q\" for the nome formula_6. Raising the eta equation to the 24th power and multiplying by (2π) gives\n\nwhere Δ is the modular discriminant. The presence of 24 can be understood by connection with other occurrences, such as in the 24-dimensional Leech lattice.\n\nThe eta function is holomorphic on the upper half-plane but cannot be continued analytically beyond it.\n\nThe eta function satisfies the functional equations\n\nMore generally, suppose \"a\", \"b\", \"c\", \"d\" are integers with \"ad\" − \"bc\" = 1, so that\n\nis a transformation belonging to the modular group. We may assume that either \"c\" > 0, or \"c\" = 0 and \"d\" = 1. Then\n\nwhere\n\nHere formula_14 is the Dedekind sum\n\nBecause of these functional equations the eta function is a modular form of weight 1/2 and level 1 for a certain character of order 24 of the metaplectic double cover of the modular group, and can be used to define other modular forms. In particular the modular discriminant of Weierstrass can be defined as\n\nand is a modular form of weight 12. (Some authors omit the factor of (2π), so that the series expansion has integral coefficients).\n\nThe Jacobi triple product implies that the eta is (up to a factor) a Jacobi theta function for special values of the arguments:\n\nwhere formula_18 is \"the\" Dirichlet character modulo 12 with formula_19,\nformula_20. Explicitly,\n\nThe Euler function\n\nrelated to formula_23 by formula_24, has a power series\nby the Euler identity:\n\nBecause the eta function is easy to compute numerically from either power series, it is often helpful in computation to express other functions in terms of it when possible, and products and quotients of eta functions, called eta quotients, can be used to express a great variety of modular forms.\n\nThe picture on this page shows the modulus of the Euler function: the additional factor of formula_26 between this and eta makes almost no visual difference whatsoever (it only introduces a tiny pinprick at the origin). Thus, this picture can be taken as a picture of eta as a function of \"q\".\n\nThe theory of the algebraic characters of the affine Lie algebras gives rise to a large class of previously unknown identities for the eta function. These identities follow from the Weyl-Kac character formula, and more specifically from the so-called \"denominator identities\". The characters themselves allow the construction of generalizations of the Jacobi theta function which transform under the modular group; this is what leads to the identities. An example of one such new identity is\n\nwhere formula_28 is the q-analog or \"deformation\" of the highest weight of a module.\n\nThe above connection with the Euler function together with the special values of the latter, it can be easily deduced that\n\nQuotients of the Dedekind eta function at imaginary quadratic arguments may be algebraic, while combinations of eta quotients may even be integral. For example, define,\n\nthen,\n\nand so on, values which appear in Ramanujan–Sato series.\n\n\n"}
{"id": "2878111", "url": "https://en.wikipedia.org/wiki?curid=2878111", "title": "Developable surface", "text": "Developable surface\n\nIn mathematics, a developable surface (or torse: archaic) is a smooth surface with zero Gaussian curvature. That is, it is a surface that can be flattened onto a plane without distortion (i.e. \"stretching\" or \"compressing\"). Conversely, it is a surface which can be made by transforming a plane (i.e. \"folding\", \"bending\", \"rolling\", \"cutting\" and/or \"gluing\"). In three dimensions all developable surfaces are ruled surfaces (but not vice versa). There are developable surfaces in R which are not ruled.\n\nThe developable surfaces which can be realized in three-dimensional space include:\n\n\nFormally, in mathematics, a developable surface is a surface with zero Gaussian curvature. One consequence of this is that all \"developable\" surfaces embedded in 3D-space are ruled surfaces (though hyperboloids are examples of ruled surfaces which are not developable). Because of this, many developable surfaces can be visualised as the surface formed by moving a straight line in space. For example, a cone is formed by keeping one end-point of a line fixed whilst moving the other end-point in a circle.\n\nDevelopable surfaces have several practical applications. Many cartographic projections involve projecting the Earth to a developable surface and then \"unrolling\" the surface into a region on the plane. Since they may be constructed by bending a flat sheet, they are also important in manufacturing objects from sheet metal, cardboard, and plywood. An industry which uses developed surfaces extensively is shipbuilding.\n\nMost smooth surfaces (and most surfaces in general) are not developable surfaces. Non-developable surfaces are variously referred to as having \"double curvature\", \"doubly curved\", \"compound curvature\", \"non-zero Gaussian curvature\", etc.\n\nSome of the most often-used non-developable surfaces are:\n\n\nMany gridshells and tensile structures and similar constructions gain strength by using (any) doubly curved form.\n\n\n"}
{"id": "50999104", "url": "https://en.wikipedia.org/wiki?curid=50999104", "title": "DogTag", "text": "DogTag\n\nDogtag Certificate System is an open source certificate authority (CA), which is a full-featured system. It supports all aspects of certificate life cycle management. It includes certificate authority, key archival, OCSP and smart card management.\n"}
{"id": "30315256", "url": "https://en.wikipedia.org/wiki?curid=30315256", "title": "Donald B. Johnson", "text": "Donald B. Johnson\n\nDonald Bruce Johnson (December 16, 1933 – September 10, 1994) was an American computer scientist, a researcher in the design and analysis of algorithms, and the founding chair of the computer science department at Dartmouth College.\n\nJohnson received his Ph.D. from Cornell University in 1973 under the supervision of David Gries. He took a faculty position in the computer science department at Pennsylvania State University, and later moved to the department of mathematics at Dartmouth. When the Dartmouth computer science department was founded in 1994, he became its first chair.\n\nJohnson invented the -ary heap data structure, and is also known for Johnson's algorithm for the all-pairs shortest path problem.\n"}
{"id": "1754365", "url": "https://en.wikipedia.org/wiki?curid=1754365", "title": "Dual pair", "text": "Dual pair\n\nIn functional analysis and related areas of mathematics a dual pair or dual system is a pair of vector spaces with an associated bilinear map to the base field.\n\nA common method in functional analysis, when studying normed vector spaces, is to analyze the relationship of the space to its continuous dual, the vector space of all possible continuous linear forms on the original space. A dual pair generalizes this concept to arbitrary vector spaces, with the duality being expressed as a bilinear map. Using the bilinear map, semi norms can be constructed to define a polar topology on the vector spaces and turn them into locally convex spaces, generalizations of normed vector spaces.\n\nA dual pair is a 3-tuple formula_1 consisting of two vector spaces formula_2 and formula_3 over the same field formula_4 and a bilinear map\nwith\nand \n\nIf the vector spaces are finite dimensional this means that the bilinear form is non-degenerate.\n\nWe call formula_8 the duality pairing, and say that it puts formula_2 and formula_3 in duality.\n\nWhen the two spaces are a vector space formula_2 (or a module over a ring in general) and its dual formula_12, we call the canonical duality pairing formula_13 the natural pairing.\n\nWe call two elements formula_14 and formula_15 orthogonal if\nWe call two sets formula_17 and formula_18 orthogonal if each pair of elements from formula_19 and formula_20 are orthogonal.\n\nA vector space formula_21 together with its algebraic dual formula_22 and the bilinear map defined as\nforms a dual pair.\n\nA locally convex topological vector space formula_24 together with its topological dual formula_25 and the bilinear map defined as \nforms a dual pair. (To show this, the Hahn–Banach theorem is needed.)\n\nFor each dual pair formula_1 we can define a new dual pair formula_28 with\n\nA sequence space formula_24 and its beta dual formula_31 with the bilinear map defined as\nform a dual pair.\n\nAssociated with a dual pair formula_1 is an injective linear map from formula_2 to formula_35 given by\nThere is an analogous injective map from formula_3 to formula_12.\n\nIn particular, if either of formula_2 or formula_3 is finite-dimensional, these maps are isomorphisms.\n\n"}
{"id": "481988", "url": "https://en.wikipedia.org/wiki?curid=481988", "title": "Engineering technologist", "text": "Engineering technologist\n\nAn engineering technologist is a professional trained in certain aspects of development and implementation of a respective area of technology. Engineering technology education is even more \"applied\" and less theoretical than engineering science education, though in a broad sense both have a focus on practical application. Engineering Technologists often assist professional engineers but after years of experience they can also lead engineers. Like engineers, areas where engineering technologists work can include product design (including improvement), fabrication, and testing. Also as with engineers, engineering technologists sometimes rise to senior management positions in industry, or become entrepreneurs.\n\nEngineering technology often overlaps with many of the same general areas (e.g. design/development, testing), but the focus is even more on application than in engineering science (which is, in a somewhat different sense, also about application of science). Technologists are more likely than engineers to focus on (post-development) implementation or operation of a technology but this is not a strict rule as Technologists often do design original concepts. The National Society of Professional Engineers (NSPE) in the USA summarizes the distinction as being that engineers are trained more with conceptual skills to \"function as designers,\" while technologists \"apply others' designs.\" The mathematics and sciences, as well as other technical courses, in \"technology\" programs, tend to be taught with more application-based examples, whereas \"engineering\" coursework provides a more theoretical foundation in math and science (because those are the very subjects that engineers apply directly). Moreover, engineering coursework tends to require higher-level mathematics, including calculus and beyond, as well as more extensive knowledge of the natural sciences applied in design, which also serve to prepare students for research (whether in graduate studies, or industrial R&D). Engineering technology courses generally have more labs associated with their undergraduate courses that require hands-on application of the studied topics.\nTechnologists are employed in a wide array of industries and areas - including product development, manufacturing, technology operation, and maintenance. They may be managers, depending on the technologist's experience, and educational emphasis on management. Entry-level positions relating in various ways to product design, testing, product development, systems development, field engineering, technical operations, and quality control are common for engineering technology graduates.\n\nIn general, the work of engineering technologists focuses more often on practical application of engineered products and processes\" for a range of purposes, whereas the work of engineers emphasizes application of math and science\" for design/development purposes (in ways that tend to require a more extensive theoretical foundation of mathematics and the natural sciences). The National Society of Professional Engineers (NSPE) describes the difference between engineering and engineering technology as follows:\n\nThe Accreditation Board for Engineering and Technology (ABET) summarizes engineering technology as \"the application of scientific and engineering knowledge and methods combined with technical skills in support of engineering activities; it lies in the occupational spectrum between the craftsman and the engineer at the end of the spectrum closest to the engineer.\" \n\nIn addition, ABET has stated: \"Engineering and technology are separate, but intimately related professions. Here are some of the ways they differ:\n\nEngineers generally focus more on conceptual design and product development, while technologists are more likely to work in testing, fabrication/construction, or field work. Of course, those areas overlap considerably (e.g., testing and fabrication are often integral to the overall product development process, and can involve engineers as well as technologists). In 2012, The Journal of Engineering Technology, published results that show \"that a very broad range of engineering companies operating across the full spectrum of engineering services and products, baccalaureate engineering technology graduates are operating as engineers. Moreover, these graduates function in many engineering roles equally as well as their contemporaries from engineering.\"\n\nBeginning in the 1950s and 1960s, some post-secondary institutions in the U.S.and Canada began offering degrees in engineering technology, focusing on applied study rather than the more theoretical engineering science degrees. The focus on applied study addressed a need within the scientific, manufacturing, and engineering communities, as well as other industries, for professionals with hands-on and applications-based engineering knowledge. Depending on the institution, associate's and/or bachelor's degrees are offered, with some institutions also offering advanced degrees in technology.\n\nIn general, an engineering technologist receives a broad range of applied science and applied mathematics training, as well as the fundamentals of engineering in the student's area of focus. Engineering technology programs typically include instruction in various engineering support functions for research, production, and operations, and applications to specific engineering specialties. Information technology is primarily involved with the management, operation, and maintenance of computer systems and networks, along with an application of technology in diverse fields such as architecture, engineering, graphic design, telecommunications, computer science and network security. A technologist is also expected to have had some coursework in ethics.\n\nInternational technology organizations from eight nations have signed a mutual recognition agreement called the Sydney Accord, which represents an understanding that the academic awards of technologists can be recognized in all signatory states. The recognition of the Sydney Accord for technologists can be compared to the Washington Accord for engineers and the Dublin Accord for engineering technicians. The Engineering Technologist Mobility Forum is an international forum held by signatories of the Sydney Accord to explore mutual recognition for experienced engineering technologists and to remove artificial barriers to the free movement and practice of engineering technologists amongst their countries.\n\nGraduates acquiring an associate degree or lower typically find careers as engineering technicians. According to the United States Bureau of Labor Statistics: \"Many four-year colleges offer bachelor's degrees in engineering technology, and graduates of these programs are hired to work as entry-level electrical or electronics engineers or applied engineers, but not technicians.\" Technicians typically hold a two-year associate degree, while technologists likewise hold a bachelor's degrees.\n\nInternationally, the Sydney Accord is an agreement signed in 2001 acknowledging the academic equivalence of accredited engineering technology programs in the signatory nations. In some countries, only those individuals who have graduated from an accredited curriculum in engineering technology and have a significant amount of work experience in their field may become registered technologists. A technologist's recognition may be in the form of a certification or a professional registration.\n\nIn Canada, the new occupational category of \"technologist\" was established in the 1960s in conjunction with an emerging system of community colleges and technical institutes. It was designed to effectively bridge the gap between the increasingly theoretical nature of engineering science degrees and the predominantly practical approach of technician and trades programs. Provincial associations may certify individuals as a Professional Technologist (P.Tech), Certified Engineering Technologist (C.E.T.), Registered Engineering Technologist (R.E.T.), Applied Science Technologist (AScT) or Technologue Professionel [T.P.]. These provincial associations are constituent members of the Canadian Council of Technicians and Technologists (CCTT), which nationally accredits technology programs across Canada through its Canadian Technology Accreditation Board (CTAB). Nationally accredited engineering technology programs range from two to three years in length, depending on the province, often containing as many classroom hours as a 4-year degree program.\n\nIn the United States, the hierarchy of educational structure and acknowledgement start at the U.S. Department of Education or the Council for Higher Education Accreditation (CHEA). The U.S. Department of Education acknowledges regional and national accreditations, and CHEA recognizes specialty accreditations. Two technology accreditations are currently recognized by CHEA: The Association of Technology, Management, and Applied Engineering (ATMAE) and the Accreditation Board for Engineering and Technology (ABET). Specifically, CHEA recognizes ABET internationally and in the U.S. for accrediting engineering technology programs at the associate and baccalaureate level. CHEA also recognizes ATMAE for accrediting associate, baccalaureate, and master's degree programs in technology, applied technology, engineering technology, and technology-related disciplines delivered by national or regional accredited institutions in the United States. (2011).\n\nABET has been accrediting engineering technology programs in the United States since 1946, with a total of over 600 programs at more than 230 institutions. In response to heavy demand, ABET began accrediting engineering technology programs internationally in 2007. Depending on the institution, associate's and/or bachelor's degrees are offered, with a few institutions also offering advanced degrees. The type, length, and quality of education offered can vary greatly depending on the educational institution and the specialty pursued within engineering technology. ATMAE-accredited engineering technology programs require a management core.\n\nThe Engineering Technology Accreditation Commission (ETAC) of Accreditation Board for Engineering and Technology was admitted as a provisional member of International Technology Accords in 2007, and it signed the Sydney Accord in 2009.\n\nOther U.S. Secretary of Education and CHEA-recognized accrediting agencies in the U.S.—(such as the Distance Education and Training Council (DETC) Accrediting Council and the Accrediting Council for Independent Colleges and Schools (ACICS)—accredit colleges and universities with programs leading to bachelor's and master's degrees in engineering and engineering technologies.\n\nThe publication of the US Department of Education and the National Science Foundation known as Mapping The World of Education indicates that an engineering technologist degree is at the same academic level (60) as an ABET/EAC engineering degree.\n\nProfessional certification is the registration of engineering technologists to assure their qualification within their countries or territories. The Sydney Accord and the Engineering Technologist Mobility Forum (ETMF) are two international efforts to improve cross-border recognition for technologists.\n\nA certified engineering technologist is usually required to apprentice for a term before being able to apply for certification through a local governing body. In that time, the technologist must have completed tasks which directly apply to his or her area of study.\n\nIn Canada, the regulated title for technologists is Certified Engineering Technologist. Technology program accreditation is administered through the Canadian Technology Accreditation Board (CTAB), often in conjunction with provincial associations affiliated with the Canadian Council of Technicians and Technologists. Graduated technologists are certified by their provincial bodies.\n\nIn the United States, technologist certification requires a bachelor's degree in an engineering technology program accredited by the Engineering Technology Accreditation Commission of the Accreditation Board for Engineering and Technology (ETAC/ABET). One may also obtain a degree from an institution accredited through The Association of Technology, Management, and Applied Engineering (formerly known as the National Association of Industrial Technology). Technologist registration in the United States is conducted by many independent societies and organizations. A government-sponsored registration is opposed by the National Council of Examiners for Engineering and Surveying (NCEES) and NSPE. As a result, the profession is often not seen as an independent field separate from design engineering.\n\nThe National Institute for Certification in Engineering Technologies (NICET) awards certification at two levels depending on work experience: the Associate Engineering Technologist (AT) and the Certified Engineering Technologist (CT). The Association of Technology, Management, and Applied Engineering (ATMAE) awards two levels of certification in technology management: Certified Technology Manager (CTM) and Certified Senior Technology Manager (CSTM). ATMAE also awards two levels of certification in manufacturing specialist: Certified Manufacturing Specialist (CMS) and Certified Senior Manufacturing Specialist (CSMS). While the CTM and CMS certification are obtained through examination, the CSTM and CSMS require industry experience and continuous improvement via the obtainment of professional development units (PDUs).\n\nAmerican Society of Certified Engineering Technicians (ASCET) is a membership organization that issues Certified Member certifications to engineering technicians and engineering technologists. Professional engineers are issued Registered Member certification.\n\nThe United Kingdom has a decades-long tradition of producing engineering technologists via the apprenticeship system of learning. U.K. engineering technologists have always been designated as \"engineers\". The term \"engineer\" in the UK is used to describe the entire range of skilled worker, and professionals from trades people through to the highly educated Chartered Engineer. In fact up until the 1960s professional engineers in the UK were often referred to as \"Technologists\" to distinguish them from scientists, technicians and craftsmen. The modern term for an engineering technologist is \"incorporated engineer\" (IEng), although since 2000 the normal route to achieving IEng is with a Bachelors or Honours Degree in engineering. Modern technical apprenticeships would normally lead to the EngTech professional qualification and with further studies at higher apprenticeship level an IEng. Since 2015 the UK government (UCAS) has introduced engineering degree (Bachelors and Masters) apprenticeships. The title \"incorporated engineer\" is protected by civil law. Prior to the title \"incorporated engineer\", U.K. technologists were known as \"technician engineers\" a designation introduced in the 1960s.\n\nIn the United Kingdom, an incorporated engineer is accepted as a \"professional engineer\", registered by the Engineering Council, although the term \"professional engineer\" has no legal meaning in the U.K., and there are no restrictions on practice. In fact, anyone in the U.K. can call themselves an \"engineer\" or \"professional engineer\" without any qualifications or proven competencies in engineering, and most U.K. skilled trades are sometimes referred to as \"professional\" or \"accredited\" engineers. Examples are \"Registered Gas Engineer\" (gas installer) or \"Professional Telephone Engineer\" (phone line installer or fault diagnosis).\n\nIncorporated engineers are recognized internationally through the Sydney Accord academic agreement as engineering technologists.\nOne of the professional titles for engineers in the United Kingdom, recognized in the Washington Accord is the chartered engineer. The incorporated engineer is a professional engineer as declared by the Engineering Council of the United Kingdom, and the European definition as demonstrated by the prescribed title under 2005/36/EC as an \"engineer\". The incorporated engineer operates autonomously and directs activities independently. They do not necessarily need the support of chartered engineers because they are often acknowledged as full engineers in the U.K. (but not in Canada or the U.S.). The United Kingdom incorporated engineer may also contribute to the design of new products and systems.\n\nThe chartered engineer and incorporated engineer are recognized as broadly comparable in stature, but with separate functions. As a result, the chartered and incorporated engineer are placed under the same directive, 2005/36/EC. The incorporated engineer can practice autonomously without the oversight of a chartered engineer.\n\nIncorporated engineers currently require an IEng accredited bachelors or honours degree in engineering (prior to 1997 the B.Sc. and B.Eng. degrees satisfied the academic requirements for \"chartered engineer\" registration), a Higher National Certificate or diploma, City and Guilds higher diploma / Full Technological Cert Diploma or a Foundation Degree in engineering, plus appropriate further learning to degree level or an NVQ4 or SVQ4 approved for the purpose by a licensed engineering institution.\n\nThe academic requirements must be accompanied by the appropriate peer reviewed experience in employment-typical 4 years post qualification. In addition to the experience and academic requirements, the engineering candidate must have three referees (themselves CEng or IEng) that vouch for the performance of the individual being considered for professional recognition. There are a number of alternative ways to achieve IEng status for those that do not have the necessary qualifications for applicants, that can clearly show they have achieved the same level as those with qualifications, including:\n\n\nThe title 'state-certified engineer BVT' is awarded to qualified engineering technologists (staatlich gepruefter Techniker) by the Bundesverband höherer Berufe der Technik, Wirtschaft und Gestaltung e.V. (\"Association of Higher Professions for Technology and Design\") or BVT, conditional on two years of professional experience, current BVT membership and payment of an administration fee.\n\nThe engineering technologist is a vocational, continuous professional development non-academic but equivalent qualification, awarded after successfully passing state examinations governed by German federal rules. To be eligible for the engineering technologist examination, candidates must fulfill the following requirements: completion of one of the school systems (Hauptschule, Realschule, Gymnasium), an apprenticeship of at least two years duration, one year of completed professional work experience and attendance of a taught programme with a course load of 2400–3000 hours, usually completed within two years in full-time or 3.5 – 4 years part-time at vocational colleges.\n\nAs of January 2012, the state-certified engineer/engineering technologist was allocated to level 6 of the European Qualifications Framework, equivalent to undergraduate degrees (Bachelor's level). Furthermore, the engineering technologist constitutes an advanced entry qualification for German universities and in principal permits entry into any undergraduate academic degree program. The engineering technologist/state-certified engineer should not be confused with academically qualified engineers, which previously graduated from Universities as Diplom-Ingenieur (Diploma in Engineering) and following the Bologna process with BEng + MEng degrees.\n\nAs of January 31, 2012, state certified engineers, state certified business managers, and state certified designers are at level 6-Bachelor on the DQF and EQF. The qualifications more than a decade ago were entered into EU Directives as recognized regulated professions in Germany and the EU. Annexes C and D were added to Council Directive 92/51/EEC on a second general system for the recognition of professional education and training to supplement Directive 89/48/EEC.\n\nTop institutions involved included the federal government (the Federal Ministry of Education and Research and the Federal Ministry of Economics and Technology), EU Standing Conference and Economic Ministerial Meeting of Countries, the German Confederation of Hand-plant, the Confederation of German Employers' Associations, German Chambers of Industry and Commerce, Confederation of German Trade Unions, and Federal Institute for Vocational Application. These government institutions agreed on a common position on the implementation of the EQF and a German qualifications framework (DQR).\n\nEuropean Union law and other documents considered to be public include:\n\nThe qualifications framework requires: \"regulated courses for the professions of state-certified ('staatlich gepruefte(r)') technician/engineer ('Techniker(in)'), business economist (business manager), ('Betriebswirt(in)'), designer ('Gestalter(in)') and family assistant ('Familiepfleger(in)'), of a total duration not less than 16 years, a prerequisite of which is successful completion of compulsory schooling or equivalent education and training (of a duration of not less than nine years) and successful completion of a course at a trade school ('Berufsschule') of a duration of not less than three years and comprising, upon completion of at least two years of work experience, full-time education and training of a duration of not less than two years or part-time education and training of equivalent duration.\"\n\nThe international engineering technologist (IntET) qualification was launched in late 2007 by the Engineering Technologists Mobility Forum (ETMF), which is part of the International Engineering Alliance (IEA). The qualification is awarded by each member jurisdiction followed by a jurisdictional identifier, such as IntET (UK) for the U.K.\n\nIn addition to the benefits gained through IEng professional qualification (an eligibility requirement), IntET (UK) offers additional benefits, including letters after name (such as \"J. Smith IEng IntET (UK)\") and easier admission to National Registers of IntET register member jurisdictions. The Engineering Council and its fellow ETMF members are pursuing the possibility of future mutual recognition of professional titles, which would further enhance the benefits of IntET qualification.\n\nThe IntET (UK) qualification is open to U.K.-registered incorporated engineers who have met the requirements: seven years post-graduate experience, two years responsibility of significant engineering work, and maintaining continuing professional development. Incorporated engineers who do not hold an accredited degree recognised under the Sydney Accord, or equivalent academic qualification, are currently not eligible to apply for IntET (UK) qualification.\n\n\n"}
{"id": "19509", "url": "https://en.wikipedia.org/wiki?curid=19509", "title": "Finitary relation", "text": "Finitary relation\n\nIn mathematics, a finitary relation has a finite number of \"places\". In set theory and logic, a \"relation\" is a property that assigns truth values to formula_1-tuples of individuals. Typically, the property describes a possible connection between the components of a formula_1-tuple. For a given set of formula_1-tuples, a truth value is assigned to each formula_1-tuple according to whether the property does or does not hold.\n\nAn example of a \"ternary relation\" (i.e., between three individuals) is: \"formula_5 was introduced to formula_6 by formula_7\", where formula_8 is a 3-tuple of persons; for example, \"Beatrice Wood was introduced to Henri-Pierre Roché by Marcel Duchamp\" is true, while \"Karl Marx was introduced to Friedrich Engels by Queen Victoria\" is false.\n\n\"Relation\" is formally defined in the next section. In this section we introduce the concept of a relation with a familiar everyday example. Consider the relation involving three roles that people might play, expressed in a statement of the form \"\"X\" thinks that \"Y\" likes \"Z\" \". The facts of a concrete situation could be organized in a table like the following:\n\nEach row of the table records a fact or makes an assertion of the form \"\"X\" thinks that \"Y\" likes \"Z\" \". For instance, the first row says, in effect, \"Alice thinks that Bob likes Denise\". The table represents a relation \"S\" over the set \"P\" of people under discussion:\n\nThe data of the table are equivalent to the following set of ordered triples:\n\nIt is usual to write \"S\"(Alice, Bob, Denise) to say the same thing as the first row of the table. The relation \"S\" is a \"ternary\" relation, since there are \"three\" items involved in each row. The relation itself is a mathematical object defined in terms of concepts from set theory (i.e., the relation is a subset of the Cartesian product on {Person X, Person Y, Person Z}), that carries all of the information from the table in one neat package. Mathematically, then, a relation is simply an \"ordered set\".\n\nThe table for relation \"S\" is an extremely simple example of a relational database. The theoretical aspects of databases are the specialty of one branch of computer science, while their practical impacts have become all too familiar in our everyday lives. Computer scientists, logicians, and mathematicians, however, tend to see different things when they look at these concrete examples and samples of the more general concept of a relation.\n\nFor one thing, databases are designed to deal with empirical data, and experience is always finite, whereas mathematics at the very least concerns itself with potential infinity. This difference in perspective brings up a number of ideas that may be usefully introduced at this point, if by no means covered in depth.\n\nThe variable formula_1 giving the number of \"places\" in the relation, 3 for the above example, is a non-negative integer, called the relation's \"arity\", \"adicity\", or \"dimension\". A relation with formula_1 places is variously called a formula_1\"-ary\", a formula_1\"-adic\", or a formula_1\"-dimensional\" relation. Relations with a finite number of places are called \"finite-place\" or \"finitary\" relations. It is possible to generalize the concept to include \"infinitary\" relations between infinitudes of individuals, for example infinite sequences; however, in this article only finitary relations are discussed, which will from now on simply be called relations.\n\nSince there is only one 0-tuple, the so-called empty tuple ( ), there are only two zero-place relations: the one that always holds, and the one that never holds. They are sometimes useful for constructing the base case of an induction argument. One-place relations are called unary relations. For instance, any set (such as the collection of Nobel laureates) can be viewed as a collection of individuals having some property (such as that of having been awarded the Nobel prize). Two-place relations are called binary relations or, in the past, \"dyadic relations\". Binary relations are very common, given the ubiquity of relations such as:\n\nA formula_1\"-ary\" relation is a straightforward generalization of a binary relation.\n\nThe simpler of the two definitions of \"k\"-place relations encountered in mathematics is:\n\nDefinition 1. A relation \"L\" over the sets \"X\", …, \"X\" is a subset of their Cartesian product, written \"L\" ⊆ \"X\" × … × \"X\".\n\nRelations are classified according to the number of sets in the defining Cartesian product, in other words, according to the number of terms following \"L\". Hence:\nRelations with more than four terms are usually referred to as \"k\"-ary or \"n\"-ary, for example, \"a 5-ary relation\". A \"k\"-ary relation is simply a set of \"k\"-tuples.\n\nThe second definition makes use of an idiom that is common in mathematics, stipulating that \"such and such is an \"n\"-tuple\" in order to ensure that such and such a mathematical object is determined by the specification of \"n\" component mathematical objects. In the case of a relation \"L\" over \"k\" sets, there are \"k\" + 1 things to specify, namely, the \"k\" sets plus a subset of their Cartesian product. In the idiom, this is expressed by saying that \"L\" is a (\"k\" + 1)-tuple.\n\nDefinition 2. A relation \"L\" over the sets \"X\", …, \"X\" is a (\"k\" + 1)-tuple \"L\" = (\"X\", …, \"X\", \"G\"(\"L\")), where \"G\"(\"L\") is a subset of the Cartesian product \"X\" × … × \"X\". \"G\"(\"L\") is called the \"graph\" of \"L\".\n\nElements of a relation are more briefly denoted by using boldface characters, for example, the constant element a = (a, …, a) or the variable element x = (\"x\", …, \"x\").\n\nA statement of the form \"a is in the relation \"L\" \" or \"a satisfies \"L\" \" is taken to mean that a is in \"L\" under the first definition and that a is in \"G\"(\"L\") under the second definition.\n\nThe following considerations apply under either definition:\n\nAs a rule, whatever definition best fits the application at hand will be chosen for that purpose, and anything that falls under it will be called a relation for the duration of that discussion. If it becomes necessary to distinguish the two definitions, an entity satisfying the second definition may be called an \"embedded\" or \"included\" relation.\n\nIf \"L\" is a relation over the domains \"X\", …, \"X\", it is conventional to consider a sequence of terms called \"variables\", \"x\", …, \"x\", that are said to \"range over\" the respective domains.\n\nLet a Boolean domain B be a two-element set, say, B = {0, 1}, whose elements can be interpreted as logical values, typically 0 = false and 1 = true. The characteristic function of the relation \"L\", written \"ƒ\" or χ(\"L\"), is the Boolean-valued function \"ƒ\" : \"X\" × … × \"X\" → B, defined in such a way that \"ƒ\"(formula_23) = 1 just in case the \"k\"-tuple formula_23 is in the relation \"L\". Such a function can also be called an indicator function, particularly in probability and statistics, to avoid confusion with the notion of a characteristic function in probability theory.\n\nIt is conventional in applied mathematics, computer science, and statistics to refer to a Boolean-valued function like \"ƒ\" as a \"k\"-place predicate. From the more abstract viewpoint of formal logic and model theory, the relation \"L\" constitutes a \"logical model\" or a \"relational structure\" that serves as one of many possible interpretations of some \"k\"-place predicate symbol.\n\nBecause relations arise in many scientific disciplines as well as in many branches of mathematics and logic, there is considerable variation in terminology. This article treats a relation as the set-theoretic extension of a relational concept or term. A variant usage reserves the term \"relation\" to the corresponding logical entity, either the logical comprehension, which is the totality of intensions or abstract properties that all of the elements of the relation in extension have in common, or else the symbols that are taken to denote these elements and intensions. Further, some writers of the latter persuasion introduce terms with more concrete connotations, like \"relational structure\", for the set-theoretic extension of a given relational concept.\n\nThe logician Augustus De Morgan, in work published around 1860, was the first to articulate the notion of relation in anything like its present sense. He also stated the first formal results in the theory of relations (on De Morgan and relations, see Merrill 1990). Charles Sanders Peirce restated and extended De Morgan's results.\n\nIn the 19th century Peirce, Gottlob Frege, Georg Cantor, Richard Dedekind, and others advanced the theory of relations. Many of their ideas, especially on relations called orders, were summarized in Principles of Mathematics (1903) by Bertrand Russell. Russell and A. N. Whitehead made free use of these results in their \"Principia Mathematica\".\n\n\n"}
{"id": "492616", "url": "https://en.wikipedia.org/wiki?curid=492616", "title": "Flat module", "text": "Flat module\n\nIn homological algebra and algebraic geometry, a flat module over a ring \"R\" is an \"R\"-module \"M\" such that taking the tensor product over \"R\" with \"M\" preserves exact sequences. A module is faithfully flat if taking the tensor product with a sequence produces an exact sequence if and only if the original sequence is exact.\n\nVector spaces over a field are flat modules. Free modules, or more generally projective modules, are also flat, over any \"R\". For finitely generated modules over a Noetherian ring, flatness and projectivity are equivalent. For finitely generated modules over local rings, flatness, projectivity and freeness are all equivalent. The field of quotients of an integral domain, and, more generally, any localization of a commutative ring are flat modules. The product of the local rings of a commutative ring is a faithfully flat module.\n\nFlatness was introduced by in his paper \"Géometrie Algébrique et Géométrie Analytique\". See also flat morphism.\n\nLet \"M\" be an \"R\"-module. The following conditions are all equivalent, so \"M\" is flat if it satisfies any (thus all) of them:\n\nWhen \"R\" isn't commutative one needs the more careful statement that, if \"M\" is a flat left \"R\"-module, the tensor product with \"M\" maps exact sequences of right \"R\"-modules to exact sequences of abelian groups.\n\nTaking tensor products (over arbitrary rings) is always a right exact functor. Therefore, the \"R\"-module \"M\" is flat if and only if for any injective homomorphism \"K\" → \"L\" of \"R\"-modules, the induced homomorphism \"K\"formula_45\"M\" → \"L\"formula_45\"M\" is also injective.\n\n\nWhen M is a finitely-generated R-module, being flat is the same as being locally free in the following sense: M is a flat R-module if and only if for every prime ideal (or even just for every maximal ideal) P of R, the localization formula_89 is free as a module over the localization formula_90\n\nLet \"R\" be a local ring with nilpotent maximal ideal (e.g., an artinian local ring) and \"M\" a module over it. Then \"M\" flat implies \"M\" free.\n\nThe local criterion for flatness states:\nThe significance of this is that \"S\" need not be finite over \"R\" and we only need to consider the maximal ideal of \"R\" instead of an arbitrary ideal of \"R\".\n\nThe next criterion is also useful for testing flatness:\n\nFlat modules over commutative rings are always torsion-free (that is, the multiplication by any regular element of the ring in injective in the module). Projective modules (and thus free modules) are always flat. For certain common classes of rings, these statements can be reversed (for example, every torsion-free module over a Dedekind ring is automatically flat and flat modules over perfect rings are always projective), as is subsumed in the following diagram of module properties:\n\nAn integral domain is called a Prüfer domain if every torsion-free module over it is flat.\n\nLet \"A\" be a commutative ring and \"B\" a commutative \"A\"-algebra, i.e., a ring homomorphism formula_94. Then \"B\" has the structure of an \"A\"-module. Then \"B\" is said to be flat over \"A\" (resp. faithfully flat) if it is flat (resp. faithfully flat) as an \"A\"-module. \n\nThere is a basic characterization of a faithfully flat ring homomorphism: given a flat ring homomorphism formula_95, the following are equivalent.\n\nThe condition 2. implies that a flat local homomorphism between local rings is faithfully flat. It follows from the condition 5. that formula_107 for every ideal formula_76 of formula_70 (take formula_110); in particular, if formula_111 is a Noetherian ring, then formula_70 is a Noetherian ring.\n\nThe condition 4. can be stated in the following strengthened form: formula_113 is submersive: the topology of formula_114 is the quotient topology of formula_115 (this is a special case of the fact that a faithfully flat quasi-compact morphism of schemes has this property.) It compares to an integral extension of an integrally closed domain.\n\nExample: For a ring formula_70, formula_117 is faithfully flat. More generally, an formula_70-algebra that is free as an formula_70-module is faithfully flat.\n\nSee also flat morphism#Properties of flat morphisms.\n\nTo a given ring homomorphism formula_95, there is an associated complex called the Amitsur complex:\nwhere the coboundary operators formula_122 are the alternating sums of the maps obtained by inserting 1 in each spot; e.g., formula_123 Then (Grothendieck) this complex is exact if formula_41 is faithfully flat.\n\nIn general, arbitrary direct sums and direct limits of flat modules are flat, a consequence of the fact that the tensor product commutes with direct sums and direct limits (in fact with all colimits), and that both direct sums and direct limits are exact functors. Submodules and factor modules of flat modules need not be flat in general (e.g. Z/nZ is not a flat Z-module for n>1). However we have the following result: the homomorphic image of a flat module \"M\" is flat if and only if the kernel is a pure submodule of \"M\".\n\nDaniel Lazard proved in 1969 that a module \"M\" is flat if and only if it is a direct limit of finitely-generated free modules. As a consequence, one can deduce that every finitely-presented flat module is projective.\n\nAn abelian group is flat (viewed as a Z-module) if and only if it is torsion-free.\n\nFlatness may also be expressed using the Tor functors, the left derived functors of the tensor product. A left \"R\"-module \"M\" is flat if and only if Tor(–, \"M\") = 0 for all formula_125 (i.e., if and only if Tor(\"X\", \"M\") = 0 for all formula_125 and all right \"R\"-modules \"X\"). Similarly, a right \"R\"-module \"M\" is flat if and only if Tor(\"M\", \"X\") = 0 for all formula_125 and all left \"R\"-modules \"X\". Using the Tor functor's long exact sequences, one can then easily prove facts about a short exact sequence\nIf \"A\" and \"B\" are flat, \"C\" need not be flat in general. However, it can be shown that\n\nA flat resolution of a module \"M\" is a resolution of the form\nwhere the \"F\" are all flat modules. Any free or projective resolution is necessarily a flat resolution. Flat resolutions can be used to compute the Tor functor.\n\nThe \"length\" of a finite flat resolution is the first subscript \"n\" such that \"F\" is nonzero and \"F\" = 0 for \"i\" greater than \"n\". If a module \"M\" admits a finite flat resolution, the minimal length among all finite flat resolutions of \"M\" is called its flat dimension and denoted fd(\"M\"). If \"M\" does not admit a finite flat resolution, then by convention the flat dimension is said to be infinite. As an example, consider a module \"M\" such that fd(\"M\") = 0. In this situation, the exactness of the sequence 0 → \"F\" → \"M\" → 0 indicates that the arrow in the center is an isomorphism, and hence \"M\" itself is flat.\n\nIn some areas of module theory, a flat resolution must satisfy the additional requirement that each map is a flat pre-cover of the kernel of the map to the right. For projective resolutions, this condition is almost invisible: a projective pre-cover is simply an epimorphism from a projective module. These ideas are inspired from Auslander's work in approximations. These ideas are also familiar from the more common notion of minimal projective resolutions, where each map is required to be a projective cover of the kernel of the map to the right. However, projective covers need not exist in general, so minimal projective resolutions are only of limited use over rings like the integers.\n\nWhile projective covers for modules do not always exist, it was speculated that for general rings, every module would have a flat cover, that is, every module \"M\" would be the epimorphic image of a flat module \"F\" such that every map from a flat module onto \"M\" factors through \"F\", and any endomorphism of \"F\" over \"M\" is an automoprhism. This flat cover conjecture was explicitly first stated in . The conjecture turned out to be true, resolved positively and proved simultaneously by L. Bican, R. El Bashir and E. Enochs. This was preceded by important contributions by P. Eklof, J. Trlifaj and J. Xu.\n\nSince flat covers exist for all modules over all rings, minimal flat resolutions can take the place of minimal projective resolutions in many circumstances. The measurement of the departure of flat resolutions from projective resolutions is called \"relative homological algebra\", and is covered in classics such as and in more recent works focussing on flat resolutions such as .\n\nFlat modules have increased importance in constructive mathematics, where projective modules are less useful. For example, that all free modules are projective is equivalent to the full axiom of choice, so theorems about projective modules, even if proved constructively, do not necessarily apply to free modules. In contrast, no choice is needed to prove that free modules are flat, so theorems about flat modules can still apply.\n\n\n"}
{"id": "1643236", "url": "https://en.wikipedia.org/wiki?curid=1643236", "title": "GXL", "text": "GXL\n\nGXL (Graph eXchange Language) is designed to be a standard exchange format for graphs. GXL is an extensible markup language (XML) sublanguage and the syntax is given by an XML document type definition (DTD). This exchange format offers an adaptable and flexible means to support interoperability between graph-based tools.\n\nIn particular, GXL was developed to enable interoperability between software reengineering tools and components, such as code extractors (parsers), analyzers and visualizers. GXL allows software reengineers to combine single-purpose tools especially for parsing, source code extraction, architecture recovery, data flow analysis, pointer analysis, program slicing, query techniques, source code visualization, object recovery, restructuring, refactoring, remodularization, etc., into a single powerful reengineering workbench.\n\nThere are two innovative features in GXL that make it well-suited to an exchange format for software data.\n\nSince GXL is a general graph exchange format, it can also be used to interchange any graph-based data, including models between computer-aided software engineering (CASE) tools, data between graph transformation systems, or graph visualization tools. GXL includes support for hypergraphs and hierarchical graphs, and can be extended to support other types of graphs.\n\nGXL originated in the merger of GRAph eXchange format (GraX: University of Koblenz, DE) for exchanging typed, attributed, ordered, directed graphs (TGraphs), Tuple Attribute Language (TA: University of Waterloo, CA), and the graph format of the PROGRES graph rewriting system (University Bw München, DE). Furthermore, GXL includes ideas from exchange formats from reverse engineering, including Relation Partition Algebra (RPA: Philips Research Eindhoven, NL) and Rigi Standard Format (RSF: University of Victoria, CA). The development of GXL was also influenced by various formats used in graph drawing (e.g. daVinci, Graph Modelling Language (GML), Graphlet, GraphXML) and current discussions on exchange formats for graph transformation systems.\n\nAt the 2000 International Conference on Software Engineering (ICSE 2000) Workshop on Standard Exchange Formats (WoSEF), GXL was accepted as working draft for an exchange format by numerous research groups working in the domain of software reengineering and graph transformation.\n\nDuring the APPLIGRAPH Subgroup Meeting on Exchange Formats for Graph Transformation, an overview of GXL was given [Schürr, 2000] and participants decided to use GXL to represent graphs within their exchange format for graph transformation systems (GTXL).\n\nThe 2000 IBM Centers for Advanced Studies Conference (CASCON 2000) included two half-day workshops on GXL. In the morning, 'Software Data Interchange with GXL: Introduction and Tutorial' gave a primer on the syntax and concepts in the format, while the afternoon workshop, 'Software Data Interchange with GXL: Implementation Issues' discussed the development of converters and standard schemas.\n\nAt the Seventh Working Conference on Reverse Engineering (WCRE 2000), GXL was presented in a tutorial [Holt \"et al.\", 2000] and during the workshop on exchange formats [Holt/Winter, 2000]. Central results were a simpler representation of ordering information, the usage of UML class diagrams to present graph schemata and the representation of UML class diagrams by GXL graphs.\n\nThe Dagstuhl Seminar on Interoperability of Reengineering Tools ratified GXL 1.0 as a standard interchange format for exchanging reengineering related data. Numerous groups from industry and research committed to using GXL, to import and export GXL documents to their tools, and to write various GXL tools.\n\nDuring various conferences and workshops the following groups from industry and academics committed to refining GXL to be the standard graph exchange format, write GXL filters and tools or use GXL as exchange format in their tools:\n\n\n"}
{"id": "38500906", "url": "https://en.wikipedia.org/wiki?curid=38500906", "title": "Gagliardo–Nirenberg interpolation inequality", "text": "Gagliardo–Nirenberg interpolation inequality\n\nIn mathematics, the Gagliardo–Nirenberg interpolation inequality is a result in the theory of Sobolev spaces that estimates the weak derivatives of a function. The estimates are in terms of \"L\" norms of the function and its derivatives, and the inequality “interpolates” among various values of \"p\" and orders of differentiation, hence the name. The result is of particular importance in the theory of elliptic partial differential equations. It was proposed by Louis Nirenberg and Emilio Gagliardo.\n\nThe inequality concerns functions \"u\": R → R. Fix 1 ≤\"q\", \"r\" ≤ ∞ and a natural number \"m\". Suppose also that a real number \"α\" and a natural number \"j\" are such that\nand\nThen \n\nThe result has two exceptional cases:\n\nFor functions \"u\": Ω → R defined on a bounded Lipschitz domain Ω ⊆ R, the interpolation inequality has the same hypotheses as above and reads\n\nwhere \"s\" > 0 is arbitrary; naturally, the constants \"C\" and \"C\" depend upon the domain Ω as well as \"m\", \"n\" etc.\n\n\n"}
{"id": "1180916", "url": "https://en.wikipedia.org/wiki?curid=1180916", "title": "Garrett Birkhoff", "text": "Garrett Birkhoff\n\nGarrett Birkhoff (January 19, 1911 – November 22, 1996) was an American mathematician. He is best known for his work in lattice theory.\n\nThe mathematician George Birkhoff (1884–1944) was his father.\n\nThe son of the mathematician George David Birkhoff, Garrett was born in Princeton, New Jersey. He began the Harvard University BA course in 1928 after less than seven years of prior formal education. Upon completing his Harvard BA in 1932, he went to Cambridge University in England to study mathematical physics but switched to studying abstract algebra under Philip Hall. While visiting the University of Munich, he met Carathéodory who pointed him towards two important texts, Van der Waerden on abstract algebra and Speiser on group theory.\n\nBirkhoff held no Ph.D., a qualification British higher education did not emphasize at that time, and did not even bother obtaining an M.A. Nevertheless, after being a member of Harvard's Society of Fellows, 1933–36, he spent the rest of his career teaching at Harvard. From these facts can be inferred the number and quality of Birkhoff's papers published by his 25th year.\n\nDuring the 1930s, Birkhoff, along with his Harvard colleagues Marshall Stone and Saunders Mac Lane, substantially advanced American teaching and research in abstract algebra. In 1941 he and Mac Lane published \"A Survey of Modern Algebra\", the second undergraduate textbook in English on the subject (Cyrus Colton MacDuffee's \"An Introduction to Abstract Algebra\" was published in 1940). Mac Lane and Birkhoff's \"Algebra\" (1967) is a more advanced text on abstract algebra. A number of papers he wrote in the 1930s, culminating in his monograph, \"Lattice Theory\" (1940; the third edition remains in print), turned lattice theory into a major branch of abstract algebra. His 1935 paper, \"On the Structure of Abstract Algebras\" founded a new branch of mathematics, universal algebra. Birkhoff's approach to this development of universal algebra and lattice theory acknowledged prior ideas of Charles Sanders Peirce, Ernst Schröder, and Alfred North Whitehead; in fact, Whitehead had written an 1898 monograph entitled \"Universal Algebra\". Further, in 1935, Birkoff showed that any equivalence between expressions that holds for all possible forms of operator must have a finite proof using certain underlying rules about equality. However, as soon as one introduces actual axioms that constrain the operators this is no longer true—and in general it can be undecidable whether or not a particular equivalence holds.\n\nDuring and after World War II, Birkhoff's interests gravitated towards what he called \"engineering\" mathematics. During the war, he worked on radar aiming and ballistics, including the bazooka. In the development of weapons, mathematical questions arose, some of which had not yet been addressed by the literature on fluid dynamics. Birkhoff's research was presented in his texts on fluid dynamics, \"Hydrodynamics\" (1950) and \"Jets, Wakes and Cavities\" (1957).\n\nBirkhoff, a friend of John von Neumann, took a close interest in the rise of the electronic computer. Birkhoff supervised the Ph.D. thesis of David M. Young on the numerical solution of the partial differential equation of Poisson, in which Young proposed the successive over-relaxation (SOR) method. Birkhoff then worked with Richard S. Varga, a former student, who was employed at Bettis Atomic Power Laboratory of the Westinghouse Electronic Corporation in Pittsburgh and was helping to design nuclear reactors. Extending the results of Young, the Birkhoff-Varga collaboration led to many publications on positive operators and iterative methods for \"p\"-cyclic matrices.\n\nBirkhoff's research and consulting work (notably for General Motors) developed computational methods besides numerical linear algebra, notably the representation of smooth curves via cubic splines.\n\nBirkhoff published more than 200 papers and supervised more than 50 Ph.D.s. He was a member of the National Academy of Sciences and the American Academy of Arts and Sciences. He was a Guggenheim Fellow for the academic year 1948–1949 and the president of the Society for Industrial and Applied Mathematics for 1966–1968. He won a Lester R. Ford Award in 1974.\n\n\n\n"}
{"id": "3045205", "url": "https://en.wikipedia.org/wiki?curid=3045205", "title": "Gibbs state", "text": "Gibbs state\n\nIn probability theory and statistical mechanics, a Gibbs state is an equilibrium probability distribution which remains invariant under future evolution of the system. For example, a stationary or steady-state distribution of a Markov chain, such as that achieved by running a Markov chain Monte Carlo iteration for a sufficiently long time, is a Gibbs state.\n\nPrecisely, suppose formula_1 is a generator of evolutions for an initial state formula_2, so that the state at any later time is given by formula_3. Then the condition for formula_4 to be a Gibbs state is\n\nIn physics there may be several physically distinct Gibbs states in which a system may be trapped, particularly at lower temperatures. \n\nThey are named after Josiah Willard Gibbs, for his work in determining equilibrium properties of statistical ensembles. Gibbs himself referred to this type of statistical ensemble as being in \"statistical equilibrium\". \n\n"}
{"id": "3799993", "url": "https://en.wikipedia.org/wiki?curid=3799993", "title": "Glossary of Unified Modeling Language terms", "text": "Glossary of Unified Modeling Language terms\n\nThis glossary of Unified Modeling Language terms covers all versions of UML. Individual entries will point out any distinctions that exist between versions.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "35708348", "url": "https://en.wikipedia.org/wiki?curid=35708348", "title": "Harcourt's theorem", "text": "Harcourt's theorem\n\nHarcourt's theorem is a formula in geometry for the area of a triangle, as a function of its side lengths and the perpendicular distances of its vertices from an arbitrary line tangent to its incircle. \n\nThe theorem is named after J. Harcourt, an Irish professor.\n\nLet a triangle be given with vertices \"A\", \"B\", and \"C\", opposite sides of lengths \"a\", \"b\", and \"c\", area \"K\", and a line that is tangent to the triangle's incircle at any point on that circle. Denote the signed perpendicular distances of the vertices from the line as \"a\" ', \"b\" ', and \"c\" ', with a distance being negative if and only if the vertex is on the opposite side of the line from the incenter. Then\n\nIf the tangent line contains one of the sides of the triangle, then two of the distances are zero and the formula collapses to the familiar formula that twice the area of a triangle is a base (the coinciding triangle side) times the altitude from that base.\n\nIf the line is instead tangent to the excircle opposite, say, vertex \"A\" of the triangle, then\n\nIf rather than \"a', b', c' \" referring to distances from a vertex to an arbitrary incircle tangent line, they refer instead to distances from a sideline to an arbitrary point, then the equation\n\nremains true.\n"}
{"id": "59595", "url": "https://en.wikipedia.org/wiki?curid=59595", "title": "Heine–Borel theorem", "text": "Heine–Borel theorem\n\nIn real analysis the Heine–Borel theorem, named after Eduard Heine and Émile Borel, states:\n\nFor a subset \"S\" of Euclidean space R, the following two statements are equivalent:\n\nThe history of what today is called the Heine–Borel theorem starts in the 19th century, with the search for solid foundations of real analysis. Central to the theory was the concept of uniform continuity and the theorem stating that every continuous function on a closed interval is uniformly continuous. Peter Gustav Lejeune Dirichlet was the first to prove this and implicitly he used the existence of a finite subcover of a given open cover of a closed interval in his proof. He used this proof in his 1852 lectures, which were published only in 1904. Later Eduard Heine, Karl Weierstrass and Salvatore Pincherle used similar techniques. Émile Borel in 1895 was the first to state and prove a form of what is now called the Heine–Borel theorem. His formulation was restricted to countable covers. Pierre Cousin (1895), Lebesgue (1898) and Schoenflies (1900) generalized it to arbitrary covers.\n\nIf a set is compact, then it must be closed.\n\nLet \"S\" be a subset of R. Observe first the following: if \"a\" is a limit point of \"S\", then any finite collection \"C\" of open sets, such that each open set \"U\" ∈ \"C\" is disjoint from some neighborhood \"V\" of \"a\", fails to be a cover of \"S\". Indeed, the intersection of the finite family of sets \"V\" is a neighborhood \"W\" of \"a\" in R. Since \"a\" is a limit point of \"S\", \"W\" must contain a point \"x\" in \"S\". This \"x\" ∈ \"S\" is not covered by the family \"C\", because every \"U\" in \"C\" is disjoint from \"V\" and hence disjoint from \"W\", which contains \"x\".\n\nIf \"S\" is compact but not closed, then it has an accumulation point \"a\" not in \"S\". Consider a collection consisting of an open neighborhood \"N\"(\"x\") for each \"x\" ∈ \"S\", chosen small enough to not intersect some neighborhood \"V\" of \"a\". Then is an open cover of \"S\", but any finite subcollection of has the form of \"C\" discussed previously, and thus cannot be an open subcover of \"S\". This contradicts the compactness of \"S\". Hence, every accumulation point of \"S\" is in \"S\", so \"S\" is closed.\n\nThe proof above applies with almost no change to showing that any compact subset \"S\" of a Hausdorff topological space \"X\" is closed in \"X\".\n\nIf a set is compact, then it is bounded.\n\nLet formula_1 be a ball of radius 1 centered at x. Then the set of all such balls centered at formula_2 is clearly an open cover of \"X\", since formula_3 contains all of \"X\". Since \"X\" is compact, take a finite subcover of this cover. This subcover is the finite union of balls of radius 1, so its diameter is bounded (by 2 times the size of the finite subcover). Therefore, any set covered by this subcover must also be bounded.\n\nA closed subset of a compact set is compact.\n\nLet \"K\" be a closed subset of a compact set \"T\" in R and let \"C\" be an open cover of \"K\". Then is an open set and\n\nis an open cover of \"T\". Since \"T\" is compact, then \"C\" has a finite subcover formula_5 that also covers the smaller set \"K\". Since \"U\" does not contain any point of \"K\", the set \"K\" is already covered by formula_6 that is a finite subcollection of the original collection \"C\". It is thus possible to extract from any open cover \"C\" of \"K\" a finite subcover.\n\nIf a set is closed and bounded, then it is compact.\n\nIf a set \"S\" in R is bounded, then it can be enclosed within an \"n\"-box\n\nwhere \"a\" > 0. By the property above, it is enough to show that \"T\" is compact.\n\nAssume, by way of contradiction, that \"T\" is not compact. Then there exists an infinite open cover \"C\" of \"T\" that does not admit any finite subcover. Through bisection of each of the sides of \"T\", the box \"T\" can be broken up into 2 sub \"n\"-boxes, each of which has diameter equal to half the diameter of \"T\". Then at least one of the 2 sections of \"T\" must require an infinite subcover of \"C\", otherwise \"C\" itself would have a finite subcover, by uniting together the finite covers of the sections. Call this section \"T\".\n\nLikewise, the sides of \"T\" can be bisected, yielding 2 sections of \"T\", at least one of which must require an infinite subcover of \"C\". Continuing in like manner yields a decreasing sequence of nested \"n\"-boxes:\n\nwhere the side length of \"T\" is , which tends to 0 as \"k\" tends to infinity. Let us define a sequence (\"x\") such that each \"x\" is in \"T\". This sequence is Cauchy, so it must converge to some limit \"L\". Since each \"T\" is closed, and for each \"k\" the sequence (\"x\") is eventually always inside \"T\", we see that \"L\" ∈ \"T\" for each \"k\".\n\nSince \"C\" covers \"T\", then it has some member \"U\" ∈ \"C\" such that \"L\" ∈ \"U\". Since \"U\" is open, there is an \"n\"-ball . For large enough \"k\", one has , but then the infinite number of members of \"C\" needed to cover \"T\" can be replaced by just one: \"U\", a contradiction.\n\nThus, \"T\" is compact. Since \"S\" is closed and a subset of the compact set \"T\", then \"S\" is also compact (see above).\n\nThe Heine-Borel theorem does not hold as stated for general metric and topological vector spaces, and this gives rise to the necessity to consider special classes of spaces where this proposition is true. They are called the spaces with the Heine-Borel property.\n\nA metric space formula_9 is said to have the Heine-Borel property if each closed bounded set in formula_10 is compact. \n\nMany metric spaces fail to have the Heine–Borel property, for instance, the metric space of rational numbers (or indeed any incomplete metric space). Complete metric spaces may also fail to have the property, for instance, no infinite-dimensional Banach spaces have the Heine–Borel property (as metric spaces). Even more trivially, if the real line is not endowed with the usual metric, it may fail to have the Heine-Borel property.\n\nA metric space formula_9 has a Heine-Borel metric which is Cauchy locally identical to formula_12 if and only if it is complete, formula_13-compact, and locally compact.\n\nA topological vector space formula_10 is said to have the Heine-Borel property (R.E. Edwards uses the term \"boundedly compact space\") if each closed bounded set in formula_10 is compact. No infinite-dimensional Banach spaces have the Heine-Borel property (as topological vector spaces). But some infinite-dimensional Fréchet spaces do have, for instance, the space formula_16 of smooth functions on an open set formula_17 and the space formula_18 of holomorphic functions on an open set formula_19. More generally, any quasi-complete nuclear space has the Heine–Borel property. All Montel spaces have the Heine-Borel property as well.\n\n\n\n"}
{"id": "2810996", "url": "https://en.wikipedia.org/wiki?curid=2810996", "title": "ISO/IEC 10967", "text": "ISO/IEC 10967\n\nISO/IEC 10967, Language independent arithmetic (LIA), is a series of\nstandards on computer arithmetic. It is compatible with ,\nmore known as IEEE 754-2008, and much of the\nspecifications are for IEEE 754 special values\n(though such values are not required by LIA itself, unless the parameter \"iec\" is true).\nIt was developed by the working group ISO/IEC JTC1/SC22/WG11, which was disbanded in 2011.\n\nLIA currently consists of three parts:\n\nPart 1 deals with the basic integer and floating point datatypes (for multiple radices, including 2 and 10),\nbut unlike IEEE 754-2008 not the representation of the values. Part 1 also\ndeals with basic arithmetic, including comparisons, on values of such\ndatatypes. The parameter \"iec\" is expected to be\ntrue for most implementations of LIA-1.\n\nPart 1 was revised, to the second edition, to become more in line with the specifications\nin parts 2 and 3.\n\nPart 2 deals with some additional \"basic\" operations on integer and floating point\ndatatype values, but focuses primarily on specifying requirements on numerical\nversions of elementary functions. Much of the specifications in LIA-2 are inspired\nby the specifications in Ada for elementary functions.\n\nPart 3 generalizes parts 1 and 2 to deal with imaginary and complex\ndatatypes and arithmetic and elementary functions on such values.\nMuch of the specifications in LIA-3 are inspired by the specifications\nfor imaginary and complex datatypes and operations in\nC, Ada and\nCommon Lisp.\n\nEach of the parts provide suggested bindings for a number of\nprogramming languages. These are not part of the LIA standards,\njust suggestions, and are not complete. Authors of a programming\nlanguage standard may wish to alter the suggestions before any\nincorporation in the programming language standard.\n\nCurrently (2013) the standards for C,\nC++, and Modula-2 have partial bindings to LIA-1.\n\n\n"}
{"id": "21648167", "url": "https://en.wikipedia.org/wiki?curid=21648167", "title": "Indistinguishability quotient", "text": "Indistinguishability quotient\n\nIn combinatorial game theory, and particularly in the theory of impartial games in misère play, an indistinguishability quotient is a commutative monoid\nthat generalizes and localizes the Sprague–Grundy theorem for a specific game's rule set.\n\nIn the specific case of misere-play impartial games, such commutative monoids have become known as misere quotients.\n\nSuppose the game of Nim is played as usual with heaps of objects, but that at the start of play, \nevery heap is restricted to have either one or two objects in it. In the normal-play convention, players take turns to remove any number of objects from a heap, and the last player to take an object from a heap is declared the winner of the game; in Misere play, that player is the loser of the game. \n\nRegardless of whether the normal or misere play convention is in effect, the outcome of such a position is necessarily of one\nof two types:\n\n\n\nWe can write down a commutative monoid presentation for the misere quotient of this 1- and 2-pile Nim game by \nfirst recasting its conventional nimber-based solution into a multiplicative form, \nand then modifying that slightly for misere play.\n\nThe nimbers that occur in the normal play of such positions are *0, *1, *2, and *3.\n\nThese four nim values combine according to the Klein four-group:\n\nThe Klein four-group is also defined by the commutative group presentation\n\nThe elements of formula_3 can be thought of as in one-to-correspondence with the nim values\nformula_4 that occur in the play of this simplified Nim game; they combine exactly in the same way.\n\nSo far, this formal introduction of the Klein four-group has added nothing new to the conventional analysis of 1- and 2-pile Nim using nimbers and nim-addition. \nInstead, we have merely recast the theory into a multiplicative form.\n\nThe advantage of the multiplicative form is that it allows us to write down a similar solution for the misere quotient of Nim played with heaps of size one and two only.\n\nWe introduce the commutative monoid presentation\n\nwhose six elements are formula_6\n\nThe solution to the correct play of misere Nim was already fully described by Bouton in 1902. In the final sentence of that paper, Bouton writes that in misere Nim, \"the safe combinations are the same as before, except that an odd number of piles, each containing one, is now safe [ie, is an P-position], while an even number of ones is not safe [ie, is an N-position].\" The misere quotient formulation above is easily seen to be equivalent in the case of Nim played with heaps of size one and two only.\n\nSuppose formula_7 is a set of impartial combinatorial games that is finitely-generated with respect to disjunctive sums and closed in both of the following senses:\n\n(1) Additive closure: If formula_8 and formula_9 are games in formula_7, then their disjunctive sum formula_11 is also in formula_7.\n\n(2) Hereditary closure: If formula_8 is a game in formula_7 and formula_9 is an option of formula_8, then formula_9 is also in formula_7.\n\nNext, define on formula_7 the indistinguishability congruence ≈ that relates two games formula_8 and formula_9 if for every choice of a game formula_22 in formula_7, the two positions formula_24 and formula_25 have the same outcome (i.e., are either both first-player wins in best play of formula_7, or alternatively are both second-player wins).\n\nOne easily checks that ≈ is indeed a congruence on the set of all disjunctive position sums in formula_7, and that this is true regardless of whether the game is played in normal or misere play. The totality of all the congruence classes form the indistinguishability quotient.\n\nIf formula_7 is played as a normal-play (last-playing winning) impartial game, then the congruence classes of formula_7 are in one-to-one correspondence with the nim values that occur in the play of the game (themselves determined by the Sprague–Grundy theorem).\n\nIn misere play, the congruence classes form a commutative monoid, instead, and it has become known as a misere quotient.\n\nMany more complicated and intricate misere quotients have been calculated for various impartial games, and particularly for octal games.\nA general-purpose algorithm for computing the misere quotient monoid presentation of a given a finite set of misere impartial game positions has been devised by Aaron N. Siegel and is described in its Appendix C.\n\n\n"}
{"id": "41385213", "url": "https://en.wikipedia.org/wiki?curid=41385213", "title": "Integral of inverse functions", "text": "Integral of inverse functions\n\nIn mathematics, integrals of inverse functions can be computed by means of a formula that expresses the antiderivatives of the inverse formula_1 of a continuous and invertible function formula_2, in terms of formula_1 and an antiderivative of formula_2. This formula was published in 1905 by Charles-Ange Laisant.\n\nLet formula_5 and formula_6 be two intervals of formula_7. \nAssume that formula_8 is a continuous and invertible function, and let formula_1 denote its inverse formula_10.\nThen formula_2 and formula_1 have antiderivatives, and if formula_13 is an antiderivative of formula_2, the possible antiderivatives of formula_1 are:\nwhere formula_17 is an arbitrary real number.\n\nIn his 1905 article, Laisant gave three proofs. First, under the additional hypothesis that formula_1 is differentiable, one may differentiate the above formula, which completes the proof immediately. His second proof was geometric. If formula_19 and formula_20, the theorem can be written: \nThe figure on the right is a proof without words of this formula. Laisant does not discuss the hypotheses necessary to make this proof rigorous, but it can be made explicit with the help of the Darboux integral (or Fubini's theorem if a demonstration based on the Lebesgue integral is desired). Laisant's third proof uses the additional hypothesis that formula_2 is differentiable. Beginning with formula_23, one multiplies by formula_24 and integrates both sides. The right-hand side is calculated using integration by parts to be formula_25, and the formula follows.\n\nNevertheless, it can be shown that this theorem holds even if formula_2 or formula_1 is not differentiable: it suffices, for example, to use the Stieltjes integral in the previous argument. On the other hand, even though general monotonic functions are differentiable almost everywhere, the proof of the general formula does not follow, unless formula_1 is absolutely continuous.\n\nIt is also possible to check that for every formula_29 in formula_6, the derivative of the function formula_31 is equal to formula_32. In other words:\nTo this end, it suffices to apply the mean value theorem to formula_13 between formula_35 and formula_36, taking into account that formula_2 is monotonic.\n\n\nApparently, this theorem of integration was discovered for the first time in 1905 by Charles-Ange Laisant, who \"could hardly believe that this theorem is new\", and hoped its use would henceforth spread out among students and teachers. This result was published independently in 1912 by an Italian engineer, Alberto Caprilli, in an opuscule entitled \"Nuove formole d'integrazione\". It was rediscovered in 1955 by Parker, and by a number of mathematicians following him. Nevertheless, they all assume that or is differentiable. \nThe general version of the theorem, free from this additional assumption, was proposed by Michael Spivak in 1965, as an exercise in the \"Calculus\", and a fairly complete proof following the same lines was published by Eric Key in 1994.\nThis proof relies on the very definition of the Darboux integral, and consists in showing that the upper Darboux sums of the function are in 1-1 correspondence with the lower Darboux sums of . \nIn 2013, Michael Bensimhoun, estimating that the general theorem was still insufficiently known, gave two other proofs: The second proof, based on the Stieltjes integral and on its formulae of integration by parts and of homeomorphic change of variables, is the most suitable to establish more complex formulae.\n\nThe above theorem generalizes in the obvious way to holomorphic functions:\nLet formula_47 and formula_48 be two open and simply connected sets of formula_49, and assume that formula_50 is a biholomorphism. Then formula_2 and formula_1 have antiderivatives, and if formula_13 is an antiderivative of formula_2, the general antiderivative of formula_1 is\n\nBecause all holomorphic functions are differentiable, the proof is immediate by complex differentiation.\n\n"}
{"id": "502323", "url": "https://en.wikipedia.org/wiki?curid=502323", "title": "Inverse kinematics", "text": "Inverse kinematics\n\nInverse kinematics is the mathematical process of recovering the movements of an object in the world from some other data, such as a film of those movements, or a film of the world as seen by a camera which is itself making those movements. This is useful in robotics and in film animation.\n\nIn robotics, inverse kinematics makes use of the kinematics equations to determine the joint parameters that provide a desired position for each of the robot's end-effectors. Specification of the movement of a robot so that its end-effectors achieve the desired tasks is known as motion planning. Inverse kinematics transforms the motion plan into joint actuator trajectories for the robot. Similar formulae determine the positions of the skeleton of an animated character that is to move in a particular way in a film, or of a vehicle such as a car or boat containing the camera which is shooting a scene of a film. Once a vehicle's motions are known, they can be used to determine the constantly-changing viewpoint for computer-generated imagery of objects in the landscape such as buildings, so that these objects change in perspective while themselves not appearing to move as the vehicle-borne camera goes past them.\n\nThe movement of a kinematic chain, whether it is a robot or an animated character, is modeled by the kinematics equations of the chain. These equations define the configuration of the chain in terms of its joint parameters. Forward kinematics uses the joint parameters to compute the configuration of the chain, and inverse kinematics reverses this calculation to determine the joint parameters that achieve a desired configuration.\n\nKinematic analysis is one of the first steps in the design of most industrial robots. Kinematic analysis allows the designer to obtain information on the position of each component within the mechanical system. This information is necessary for subsequent dynamic analysis along with control paths.\n\nInverse kinematics is an example of the kinematic analysis of a constrained system of rigid bodies, or kinematic chain. The kinematic equations of a robot can be used to define the loop equations of a complex articulated system. These loop equations are non-linear constraints on the configuration parameters of the system. The independent parameters in these equations are known as the degrees of freedom of the system.\n\nWhile analytical solutions to the inverse kinematics problem exist for a wide range of kinematic chains, computer modeling and animation tools often use Newton's method to solve the non-linear kinematics equations.\n\nOther applications of inverse kinematic algorithms include interactive manipulation, animation control and collision avoidance.\n\nInverse kinematics is important to game programming and 3D animation, where it is used to connect game characters physically to the world, such as feet landing firmly on top of terrain (see for a comprehensive survey on Inverse Kinematics methods used in Computer Graphics).\n\nAn animated figure is modeled with a skeleton of rigid segments connected with joints, called a kinematic chain. The kinematics equations of the figure define the relationship between the joint angles of the figure and its pose or configuration. The forward kinematic animation problem uses the kinematics equations to determine the pose given the joint angles. The \"inverse kinematics problem\" computes the joint angles for a desired pose of the figure.\n\nIt is often easier for computer-based designers, artists, and animators to define the spatial configuration of an assembly or figure by moving parts, or arms and legs, rather than directly manipulating joint angles. Therefore, inverse kinematics is used in computer-aided design systems to animate assemblies and by computer-based artists and animators to position figures and characters.\n\nThe assembly is modeled as rigid links connected by joints that are defined as mates, or geometric constraints. Movement of one element requires the computation of the joint angles for the other elements to maintain the joint constraints. For example, inverse kinematics allows an artist to move the hand of a 3D human model to a desired position and orientation and have an algorithm select the proper angles of the wrist, elbow, and shoulder joints. Successful implementation of computer animation usually also requires that the figure move within reasonable anthropomorphic limits.\n\nAn analytic solution to an inverse kinematics problem is a closed-form expression that takes the end-effector pose as input and gives joint positions as output, formula_1. Analytical inverse kinematics solvers can be significantly faster than numerical solvers and provide more than one solution for a given end-effector pose.\n\nThe IKFast open-source program can solve for the complete analytical solutions of most common robot manipulators and generate C++ code for them. The generated solvers cover most degenerate cases and can finish in microseconds on recent computers.\n\nThere are many methods of modelling and solving inverse kinematics problems. The most flexible of these methods typically rely on iterative optimization to seek out an approximate solution, due to the difficulty of inverting the forward kinematics equation and the possibility of an empty solution space. The core idea behind several of these methods is to model the forward kinematics equation using a Taylor series expansion, which can be simpler to invert and solve than the original system.\n\nThe Jacobian inverse technique is a simple yet effective way of implementing inverse kinematics. Let there be formula_2 variables that govern the forward-kinematics equation, i.e. the position function. These variables may be joint angles, lengths, or other arbitrary real values. If the IK system lives in a 3-dimensional space, the position function can be viewed as a mapping formula_3. Let formula_4 give the initial position of the system, and \n\nformula_5\n\nbe the goal position of the system. The Jacobian inverse technique iteratively computes an estimate of formula_6 that minimizes the error given by formula_7.\n\nFor small formula_6-vectors, the series expansion of the position function gives:\n\nformula_9\n\nWhere formula_10 is the (3 x m) Jacobian matrix of the position function at formula_11.\n\nNote that the (i, k)-th entry of the Jacobian matrix can be determined numerically:\n\nformula_12\n\nWhere formula_13 gives the i-th component of the position function, formula_14 is simply formula_11 with a small delta added to its k-th component, and formula_16 is a reasonably small positive value.\n\nTaking the Moore-Penrose pseudoinverse of the Jacobian (computable using a singular value decomposition) and re-arranging terms results in:\n\nformula_17\n\nWhere formula_18.\n\nApplying the inverse Jacobian method once will result in a very rough estimate of the desired formula_6-vector. A line search should be used to scale this formula_6 to an acceptable value. The estimate for formula_6 can be improved via the following algorithm (known as the Newton-Raphson method):\n\nformula_22\n\nOnce some formula_6-vector has caused the error to drop close to zero, the algorithm should terminate. Existing methods based on the Hessian matrix of the system have been reported to converge to desired formula_6 values using fewer iterations, though, in some cases more computational resources.\n\nThe Inverse Kinematics problem can also be approximated using heuristic methods. These methods perform simple, iterative operations to gradually lead to an approximation of the solution. The heuristic algorithms have low computational cost (return the final pose very quickly), and usually support joint constraints. The most popular heuristic algorithms are: Cyclic Coordinate Descent (CCD), and Forward And Backward Reaching Inverse Kinematics (FABRIK).\n\n"}
{"id": "51028897", "url": "https://en.wikipedia.org/wiki?curid=51028897", "title": "Kazuo Iwama (computer scientist)", "text": "Kazuo Iwama (computer scientist)\n\nKazuo Iwama (, born January 1, 1951) is a Japanese computer scientist who works at Kyoto University. Topics in his research include stable marriage, quantum circuits, the Boolean satisfiability problem, and algorithms on graphs.\n\nIwama earned bachelor's, master's, and doctoral degrees from Kyoto University in 1973, 1975, and 1980 respectively. He taught at Kyoto Sangyo University from 1978 to 1990, when he moved to Kyushu University. In 1997 he returned as a professor to Kyoto University.\n\nIwama became the founding president of the Asian Association for Algorithms and Computation in 2007.\nHe was the founding editor-in-chief of the journal \"Algorithms\", in 2008.\nSince 2013 he has been editor-in-chief of the \"Bulletin of the European Association for Theoretical Computer Science\".\n\nIwama received an honorary doctorate from the University of Latvia in 2008, and was elected to the Academia Europaea in 2012.\n\n\n"}
{"id": "153788", "url": "https://en.wikipedia.org/wiki?curid=153788", "title": "Kőnig's lemma", "text": "Kőnig's lemma\n\nKőnig's lemma or Kőnig's infinity lemma is a theorem in graph theory due to . It gives a sufficient condition for an infinite graph to have an infinitely long path. The computability aspects of this theorem have been thoroughly investigated by researchers in mathematical logic, especially in computability theory. This theorem also has important roles in constructive mathematics and proof theory.\n\nLet \"G\" be a connected, locally finite, infinite graph (this means, in particular, that each vertex is adjacent to only finitely many other vertices). Then \"G\" contains a ray: a simple path (a path with no repeated vertices) that starts at one vertex and continues from it through infinitely many vertices.\n\nA common special case of this is that every infinite tree contains either a vertex of infinite degree or an infinite simple path.\n\nLet \"v\" be the set of vertices. As premise, we assume that this set is infinite and the graph is connected.\n\nStart with any vertex \"v\". Every one of the infinitely many vertices of \"G\" can be reached from \"v\" with a simple path, and each such path must start with one of the finitely many vertices adjacent to \"v\". There must be one of those adjacent vertices through which infinitely many vertices can be reached without going through \"v\". If there were not, then the entire graph would be the union of finitely many finite sets, and thus finite, contradicting the assumption that the graph is infinite. We may thus pick one of these vertices and call it \"v\".\n\nNow infinitely many vertices of \"G\" can be reached from \"v\" with a simple path which does not include the vertex \"v\". Each such path must start with one of the finitely many vertices adjacent to \"v\". So an argument similar to the one above shows that there must be one of those adjacent vertices through which infinitely many vertices can be reached; pick one and call it \"v\".\n\nContinuing in this fashion, an infinite simple path can be constructed using mathematical induction and a weak version of the axiom of dependent choice. At each step, the induction hypothesis states that there are infinitely many nodes reachable by a simple path from a particular node \"v\" that does not go through one of a finite set of vertices. The induction argument is that one of the vertices adjacent to \"v\" satisfies the induction hypothesis, even when \"v\" is added to the finite set.\n\nThe result of this induction argument is that for all \"n\" it is possible to choose a vertex \"v\" as the construction describes. The set of vertices chosen in the construction is then a chain in the graph, because each one was chosen to be adjacent to the previous one, and the construction guarantees that the same vertex is never chosen twice.\n\nThis proof is not generally considered to be constructive, because at each step it uses a proof by contradiction to establish that there exists an adjacent vertex from which infinitely many other vertices can be reached, and because of the reliance on a weak form of the axiom of choice. Facts about the computational aspects of the lemma suggest that no proof can be given that would be considered constructive by the main schools of constructive mathematics.\n\nThe computability aspects of Kőnig's lemma have been thoroughly investigated. The form of Kőnig's lemma most convenient for this purpose is the one which states that any infinite finitely branching subtree of formula_1 has an infinite path. Here formula_2 denotes the set of natural numbers (thought of as an ordinal number) and formula_1 the tree whose nodes are all finite sequences of natural numbers, where the parent of a node is obtained by removing the last element from a sequence. Each finite sequence can be identified with a partial function from formula_2 to itself, and each infinite path can be identified with a total function. This allows for an analysis using the techniques of computability theory.\n\nA subtree of formula_1 in which each sequence has only finitely many immediate extensions (that is, the tree has finite degree when viewed as a graph) is called finitely branching. Not every infinite subtree of formula_1 has an infinite path, but Kőnig's lemma shows that any finitely branching subtree must have such a path.\n\nFor any subtree \"T\" of formula_1 the notation Ext(\"T\") denotes the set of nodes of \"T\" through which there is an infinite path. Even when \"T\" is computable the set Ext(\"T\") may not be computable. Every subtree \"T\" of\nformula_1 that has a path has a path computable from Ext(\"T\").\n\nIt is known that there are non-finitely branching computable subtrees of formula_1 that have no arithmetical path, and indeed no hyperarithmetical path. However, every computable subtree of formula_1 with a path must have a path computable from Kleene's O, the canonical formula_11 complete set. This is because the set Ext(\"T\") is always formula_12 (see analytical hierarchy) when \"T\" is computable.\n\nA finer analysis has been conducted for computably bounded trees. A subtree of formula_1 is called computably bounded or recursively bounded if there is a computable function \"f\" from formula_2 to formula_2 such that for every sequence in the tree and every \"n\", the \"n\"th element of the sequence is at most \"f\"(\"n\"). Thus \"f\" gives a bound for how “wide” the tree is. The following basis theorems apply to infinite, computably bounded, computable subtrees of formula_16.\n\nA weak form of Kőnig's lemma which states that every infinite binary tree has an infinite branch is used to define the subsystem WKL of second-order arithmetic. This subsystem has an important role in reverse mathematics. Here a binary tree is one in which every term of every sequence in the tree is 0 or 1, which is to say the tree is computably bounded via the constant function 2. The full form of Kőnig's lemma is not provable in WKL, but is equivalent to the stronger subsystem ACA.\n\nThe fan theorem of is, from a classical point of view, the contrapositive of a form of Kőnig's lemma. A subset \"S\" of formula_19 is called a \"bar\" if any function from formula_2 to the set formula_21 has some initial segment in \"S\". A bar is \"detachable\" if every sequence is either in the bar or not in the bar (this assumption is required because the theorem is ordinarily considered in situations where the law of the excluded middle is not assumed). A bar is \"uniform\" if there is some number \"N\" so that any function from formula_2 to formula_21 has an initial segment in the bar of length no more than formula_24. Brouwer's fan theorem says that any detachable bar is uniform.\n\nThis can be proven in a classical setting by considering the bar as an open covering of the compact topological space formula_25. Each sequence in the bar represents a basic open set of this space, and these basic open sets cover the space by assumption. By compactness, this cover has a finite subcover. The \"N\" of the fan theorem can be taken to be the length of the longest sequence whose basic open set is in the finite subcover. This topological proof can be used in classical mathematics to show that the following form of Kőnig's lemma holds: for any natural number \"k\", any infinite subtree of the tree formula_26 has an infinite path.\n\nKőnig's lemma may be considered to be a choice principle; the first proof above illustrates the relationship between the lemma and the axiom of dependent choice. At each step of the induction, a vertex with a particular property must be selected. Although it is proved that at least one appropriate vertex exists, if there is more than one suitable vertex there may be no canonical choice. In fact, the full strength of the axiom of dependent choice is not needed; as described below, the axiom of countable choice suffices.\n\nIf the graph is countable, the vertices are well-ordered and one can canonically choose the smallest suitable vertex. In this case, Kőnig's lemma is provable in second-order arithmetic with arithmetical comprehension, and, a fortiori, in ZF set theory (without choice).\n\nKőnig's lemma is essentially the restriction of the axiom of dependent choice to entire relations \"R\" such that for each \"x\" there are only finitely many \"z\" such that \"xRz\". Although the axiom of choice is, in general, stronger than the principle of dependent choice, this restriction of dependent choice is equivalent to a restriction of the axiom of choice.\nIn particular, when the branching at each node is done on a finite subset of an arbitrary set not assumed to be countable, the form of Kőnig's lemma that says \"Every infinite finitely branching tree has an infinite path\" is equivalent to the principle that every countable set of finite sets has a choice function, that is to say, the axiom of countable choice for finite sets. This form of the axiom of choice (and hence of Kőnig's lemma) is not provable in ZF set theory.\n\n\n\n"}
{"id": "1551440", "url": "https://en.wikipedia.org/wiki?curid=1551440", "title": "Leonard Courtney, 1st Baron Courtney of Penwith", "text": "Leonard Courtney, 1st Baron Courtney of Penwith\n\nLeonard Henry Courtney, 1st Baron Courtney of Penwith, PC (6 July 183211 May 1918) was a radical British politician, and an academic, who became famous after being advocate of proportional representation in Parliament and acting as an opponent of imperialism and militarism.\n\nHe was a member of William Ewart Gladstone's second administration from 1880 to 1883 and served as Chairman of Ways and Means (Deputy Speaker of the House of Commons) between 1886 and 1893. He was the first and the last Baron Courtney of Penwith.\n\nCourtney was born at Penzance, Cornwall. He was the eldest son of John Sampson Courtney, a banker, and Sarah, daughter of John Mortimer. Two of his brothers, John Mortimer Courtney (1838–1920), and William Prideaux Courtney (1845–1913), also attained public distinction, the former in the government service in Canada (from 1869, retiring in 1906), rising to be deputy-minister of finance, and the latter in the British civil service (1865–1892), and as a prominent man of letters and bibliographer. He was educated at St John's College, Cambridge, where he was Second Wrangler and first Smith's prizeman, and elected a fellow of his college. He was called to the Bar at Lincoln's Inn in 1858. From 1872 to 1875 he was professor of political economy at University College, London. He was president of the Royal Geological Society of Cornwall from 1881-82.\n\nIn December 1876, after a previous unsuccessful attempt, Courtney was elected to parliament for Liskeard as a Liberal. He continued to represent the borough, and Bodmin into which it was merged by the Reform Act of 1885, until 1900, when his attitude towards the South African War (he and his wife Catherine were one of the foremost of the so-called Pro-Boer Party) compelled his retirement.\n\nUntil 1885, he was a devoted adherent of William Ewart Gladstone, particularly in finance and foreign affairs. In 1880 he was appointed Under-Secretary of State for the Home Department, in 1881 Under-Secretary of State for the Colonies and in 1882 Financial Secretary to the Treasury. He was known as a stubborn fighter for principle, and after finding that the government's Reform Bill in 1884 contained no recognition of the scheme for proportional representation, to which he was deeply committed, he resigned office. He refused to support Gladstone's Home Rule Bill in 1886 and was one of those who chiefly contributed to its rejection, whose reputation for unbending integrity and intellectual eminence gave solidity to the Liberal Unionist party.\n\nIn 1886, Courtney was elected Chairman of Ways and Means (Deputy Speaker of the House of Commons) and was sworn of the Privy Council in 1889. His efficiency in this office seemed to mark him out for the speakership after the 1895 general election. A Liberal Unionist, however, could be elected only by Conservative votes, and he had made himself objectionable to a large section of the Conservative Party by his independent attitude on various questions, on which his liberalism outweighed his party loyalty. He, would in any case, have been incapacitated by an affection of the eyesight, which for a while threatened to withdraw him from public life altogether.\n\nAfter 1895, Courtney's divergences from the Unionist party on questions other than Irish politics became gradually more marked. He became known in the House of Commons principally for his candid criticism of the measures introduced by his nominal leaders, and he was rather to be ranked among the Opposition than as a Ministerialist. When the crisis with the Transvaal came in 1899, Courtney's views, which remained substantially what they were when he supported the settlement after Majuba in 1881, had plainly become incompatible with his position even as a nominal follower of Lord Salisbury and Joseph Chamberlain. \nHe led the work of the South African Conciliation Committee which brought the sufferings of the Boers to the attention of British people.\n\nHe gradually reverted to formal membership of the Liberal party and, in January 1906, unsuccessfully contested Edinburgh West as a supporter of Sir Henry Campbell-Bannerman at the general election. Among the birthday honours of 1906 he was elevated to the peerage as Baron Courtney of Penwith, in the County of Cornwall.\n\nCourtney was a prominent supporter of the women's movement through the influence of his wife and sister-in-law. In his earlier years, he was a regular contributor to \"The Times\", and he wrote numerous essays in the principal reviews on political and economic subjects. In 1901 he published a book on \"The Working Constitution of the United Kingdom\". He was President of the Royal Statistical Society, 1897-9. He was a great friend of the artist Norman Garstin.\n\nCourtney married Catherine Potter, daughter of Richard Potter and an elder sister of Beatrice Webb, in 1883. They had no children.\n\nIn May 1918, aged 85, he was living at 15 Cheyne Walk at the time of his death. He left effects totalling £56,672 2s 6d. The peerage became extinct.\n\n\n"}
{"id": "18814960", "url": "https://en.wikipedia.org/wiki?curid=18814960", "title": "List of mathematical series", "text": "List of mathematical series\n\nThis list of mathematical series contains formulae for finite and infinite sums. It can be used in conjunction with other tools for evaluating sums.\n\nSee Faulhaber's formula.\nThe first few values are:\n\nSee zeta constants.\nThe first few values are:\n\nFinite sums:\n\nInfinite sums, valid for formula_26 (see polylogarithm):\nThe following is a useful property to calculate low-integer-order polylogarithms recursively in closed form:\n\n\nwhere formula_41 is the Touchard polynomials.\n\n\n\n\n\n\nSums of sines and cosines arise in Fourier series.\n\n\n\n\n"}
{"id": "10614602", "url": "https://en.wikipedia.org/wiki?curid=10614602", "title": "Minkowski's first inequality for convex bodies", "text": "Minkowski's first inequality for convex bodies\n\nIn mathematics, Minkowski's first inequality for convex bodies is a geometrical result due to the German mathematician Hermann Minkowski. The inequality is closely related to the Brunn–Minkowski inequality and the isoperimetric inequality.\n\nLet \"K\" and \"L\" be two \"n\"-dimensional convex bodies in \"n\"-dimensional Euclidean space R. Define a quantity \"V\"(\"K\", \"L\") by\n\nwhere \"V\" denotes the \"n\"-dimensional Lebesgue measure and + denotes the Minkowski sum. Then\n\nwith equality if and only if \"K\" and \"L\" are homothetic, i.e. are equal up to translation and dilation.\n\n\nOne can show that the Brunn–Minkowski inequality for convex bodies in R implies Minkowski's first inequality for convex bodies in R, and that equality in the Brunn–Minkowski inequality implies equality in Minkowski's first inequality.\n\nBy taking \"L\" = \"B\", the \"n\"-dimensional unit ball, in Minkowski's first inequality for convex bodies, one obtains the isoperimetric inequality for convex bodies in R: if \"K\" is a convex body in R, then\n\nwith equality if and only if \"K\" is a ball of some radius.\n"}
{"id": "21177402", "url": "https://en.wikipedia.org/wiki?curid=21177402", "title": "Niederreiter cryptosystem", "text": "Niederreiter cryptosystem\n\nIn cryptography, the Niederreiter cryptosystem is a variation of the McEliece cryptosystem developed in 1986 by Harald Niederreiter. It applies the same idea to the parity check matrix, H, of a linear code. Niederreiter is equivalent to McEliece from a security point of view. It uses a syndrome as ciphertext and the message is an error pattern. The encryption of Niederreiter is about ten times faster than the encryption of McEliece. Niederreiter can be used to construct a digital signature scheme.\n\nA special case of Niederreiter's original proposal was broken but the system is secure when used with a Binary Goppa code.\n\n\nSuppose Bob wishes to send a message, \"m\", to Alice whose public key is (\"H\", \"t\"):\n\n\nUpon receipt of \"c\" = \"H\"\"m\" from Bob, Alice does the following to retrieve the message, \"m\".\n\nCourtois, Finiasz and Sendrier showed how the Niederreiter cryptosystem can be used to derive a signature scheme\n\n\nVerification then applies the public encryption function to the signature and checks whether or not this equals the hash value of the document. When using Niederreiter, or in fact any cryptosystem based on error correcting codes, the second step in the signature scheme almost always fails. This is because a random syndrome usually corresponds to an error pattern of weight greater than \"t\". The system then specifies a deterministic way of tweaking d until one is found which can be decrypted.\n\nThe choice of the code parameters is related to the probability that a random syndrome is decodable. Courtois, Finiaz, and Sendrier suggest the parameter values \"n\" = 2 and \"t\" = 9. Then the probability to decode a random syndrome is formula_1. Therefore, a decodable syndrome is found after an expected number of 9! attempts. Add a counter, \"i\", to the original document d, to produce a slightly altered document, d. Hashing d gives a syndrome that depends on \"i\". Let \"i\" run from 0 to \"i\", with \"i\" the first value of \"i\" for which d is decodable. In this case the decrypted message is a word, \"z\", of length \"n\" and weight 9, such that \"Hz\" equals the hash value of d. The signature will be \"z\" combined with the value \"i\" for verification. This signature is attached to the original document, d.\n\n"}
{"id": "46968203", "url": "https://en.wikipedia.org/wiki?curid=46968203", "title": "Patrick Michael Grundy", "text": "Patrick Michael Grundy\n\nPatrick Michael Grundy (16 November 1917, Yarmouth, Isle of Wight – 4 November 1959) was an English mathematician and statistician. He was one of the eponymous co-discoverers of the Sprague–Grundy function and its application to the analysis of a wide class of combinatorial games.\n\nGrundy received his secondary education from Malvern College, to which he had obtained a Major Scholarship in 1931, and from which he graduated in 1935. While there, he demonstrated his aptitude for mathematics by winning three prizes in that subject. After leaving school he entered Clare College, Cambridge, on a Foundation Scholarship, where he read for the Mathematical Tripos from 1936 to 1939, earning first class honours in part 2 and a distinction in part 3.\n\nThe work for which he is best known appeared in his first paper, \"Mathematics and Games\", first published in the Cambridge University Mathematical Society's magazine, \"Eureka\" in 1939, and reprinted by the same magazine in 1964. The main results of this paper were discovered independently by Grundy and by Roland Sprague, and had already been published by the latter in 1935. The key idea is that of a function which assigns a non-negative integer to each position of a class of combinatorial games, now called impartial games, and which greatly assists in the identification of winning and losing positions, and of the winning moves from the former. The number assigned to a position by this function is called its Grundy value (or Grundy number), and the function itself is called the Sprague–Grundy function, in honour of its co-discoverers. The procedures developed by Sprague and Grundy for using their function to analyse impartial games are collectively called Sprague–Grundy theory, and at least two different theorems concerning these procedures have been called Sprague–Grundy theorems. The maximum number of colors used by a greedy coloring algorithm is called the Grundy number, also after this work on games, as its definition has some formal similarities with the Sprague–Grundy theory.\n\nIn 1939 Grundy began research in algebraic geometry as a research student at the University of Cambridge, eventually specialising in the theory of ideals. In 1941 he won a Smith's Prize for an essay entitled \"On the theory of R-modules\", and his first research paper in the area, \"A generalisation of additive ideal theory\", was published in the following year. In 1943 he was appointed to an assistant lectureship at the University College of Hull, which he left in 1944. He was awarded a Ph.D. from the University of Cambridge in 1945.\n\nShortly after the end of World War II, Grundy moved away from the field of algebra to take up work in statistics. In 1947 he began formal training in the latter discipline at the Rothamsted Experimental Station under a Ministry of Agriculture scholarship, graduating in 1949, when he then joined the permanent staff of the former organisation as an Experimental Officer. In 1951 he was promoted to Senior Experimental Officer. During his time at Rothamsted he performed most of his published statistical research, which included investigations of problems in the design and analysis of experiments, sampling, composition of animal populations, and fitting truncated distributions.\n\nFrom 1954 to 1958 Grundy worked as a statistician at the National Institute for Educational Research. During this period, he collaborated with Michael Healy and D.H. Rees to extend Frank Yates's work on cost–benefit analysis of experimentation. The results of this collaboration were reported in an influential paper, \"Economic choice of the amount of experimentation\", published in series B of the \"Journal of the Royal Statistical Society\" in 1956. In 1958 Grundy moved to a position in the Biometry Unit at Oxford. However, he retired from this position after only one term, due to ill health.\n\nEarly in 1959 Grundy married Hilary Taylor, a former colleague from the National Institute of Educational Research. Although his health then greatly improved throughout 1959, he was unfortunately killed in an accident in November of that year.\n\nWith the exception of the final item, this list is taken from Smith's obituary (1960). The first item is missing from Goddard's (1960) list, which is otherwise the same as Smith's.\n\n"}
{"id": "22674877", "url": "https://en.wikipedia.org/wiki?curid=22674877", "title": "Paul Chester Kainen", "text": "Paul Chester Kainen\n\nPaul Chester Kainen is an American mathematician, an adjunct associate professor of mathematics and director of the Lab for Visual Mathematics at Georgetown University. Kainen is the author of a popular book on the four color theorem, and is also known for his work on book embeddings of graphs.\n\nKainen received his Bachelor of Arts degree from George Washington University in 1966 and was awarded the Ruggles Prize for Excellence in Mathematics. He went on to get his Ph.D. from Cornell University in 1970 with Peter Hilton as his thesis advisor. Kainen's father was the American artist Jacob Kainen.\n\n\n"}
{"id": "17905449", "url": "https://en.wikipedia.org/wiki?curid=17905449", "title": "Prediction Suffix Tree", "text": "Prediction Suffix Tree\n\nA Prediction Suffix Tree is a mathematical technique for modelling sequences.\n\n"}
{"id": "3909097", "url": "https://en.wikipedia.org/wiki?curid=3909097", "title": "Projection (mathematics)", "text": "Projection (mathematics)\n\nIn mathematics, a projection is a mapping of a set (or other mathematical structure) into a subset (or sub-structure), which is equal to its square for mapping composition (or, in other words, which is idempotent). The restriction to a subspace of a projection is also called a \"projection\", even if the idempotence property is lost.\nAn everyday example of a projection is the casting of shadows onto a plane (paper sheet). The projection of a point is its shadow on the paper sheet. The shadow of a point on the paper sheet is this point itself (idempotence). The shadow of a three-dimensional sphere is a closed disk. Originally, the notion of projection was introduced in Euclidean geometry to denote the projection of the Euclidean space of three dimensions onto a plane in it, like the shadow example. The two main projections of this kind are: \n\nThe concept of projection in mathematics is a very old one, most likely having its roots in the phenomenon of the shadows cast by real world objects on the ground. This rudimentary idea was refined and abstracted, first in a geometric context and later in other branches of mathematics. Over time differing versions of the concept developed, but today, in a sufficiently abstract setting, we can unify these variations.\n\nIn cartography, a map projection is a map of a part of the surface of the Earth onto a plane, which, in some cases, but not always, is the restriction of a projection in the above meaning. The 3D projections are also at the basis of the theory of perspective. \n\nThe need for unifying the two kinds of projections and of defining the image by a central projection of any point different of the center of projection are at the origin of projective geometry. However, a projective transformation is a bijection of a projective space, a property \"not\" shared with the \"projections\" of this article.\n\nIn an abstract setting we can generally say that a \"projection\" is a mapping of a set (or of a mathematical structure) which is idempotent, which means that a projection is equal to its composition with itself. A projection may also refer to a mapping which has a right inverse. Both notions are strongly related, as follows. Let \"p\" be an idempotent map from a set \"A\" into itself (thus \"p\"∘\"p\" = \"p\") and \"B\" = \"p\"(\"A\") be the image of \"p\". If we denote by π the map \"p\" viewed as a map from \"A\" onto \"B\" and by \"i\" the injection of \"B\" into \"A\", then we have π.\"i\"= Id. Conversely, π.\"i\" = Id implies that π∘\"i\" is idempotent.\n\nThe original notion of projection has been extended or generalized to various mathematical situations, frequently, but not always, related to geometry, for example:\n\n\n\n\n\n\n\n\n\n"}
{"id": "56036557", "url": "https://en.wikipedia.org/wiki?curid=56036557", "title": "Proof-of-authority", "text": "Proof-of-authority\n\nProof-of-authority (PoA) is an algorithm used with blockchains that delivers comparatively fast transactions through a consensus mechanism based on identity as a stake.\n\nIn PoA-based networks, transactions and blocks are validated by approved accounts, known as validators. Validators run software allowing them to put transactions in blocks. The process is automated and does not require validators to be constantly monitoring their computers. It, however, does require maintaining the computer (the authority node) uncompromised. The term was coined by Gavin Wood, co-founder of Ethereum and Parity Technologies.\n\nWith PoA, individuals earn the right to become validators, so there is an incentive to retain the position that they have gained. By attaching a reputation to identity, validators are incentivized to uphold the transaction process, as they do not wish to have their identities attached to a negative reputation. This is considered more robust than PoS (proof-of-stake), as:\nOn the other hand, PoA only allows non-consecutive block approval from any one validator, meaning that the risk of serious damage is centralized to the authority node.\n\nPoA is suited for both private networks and public networks, like POA Network, where trust is distributed.\n\n\n"}
{"id": "44120129", "url": "https://en.wikipedia.org/wiki?curid=44120129", "title": "Revolving rivers", "text": "Revolving rivers\n\nRevolving rivers are a surprising, uncommon way of sand pile growth that can be found in a few sands around the world, but has been studied in detail only for one Cuban sand from a place called Santa Teresa (Pinar del Rio province).\n\nWhen pouring \"revolving\" sand on a flat surface from a fixed position, the growth of a conical pile does not occur by the common avalanche mechanism, where sand slides down the pile in a more or less random fashion. What happens in that a relatively thin \"river\" of flowing sand travels from the pouring point at the apex of the pile to its base, while the rest of the sand at the surface is static. In addition, the river \"revolves\" around the pile either in clockwise or counter-clockwise directions (looking from top) depending on the initial conditions of the experiment. Actually the river constitutes the \"cutting edge\" of a layer of sand that deposits as a helix on the conical pile, and makes it grow.\nFor small sandpiles, rivers are continuous, but they become intermittent\nfor larger piles.\n\nThe phenomenon was observed first by E. Altshuler at the University of Havana in 1995, but at the time he assumed that it was well known, and temporarily forgot about it. In 2000, being at the University of Houston, he told K. E. Bassler, who showed a vivid interest in the matter. Embarrassingly enough, Altshuler was unable to demonstrate it before Bassler using a random sand from Houston, so he had to send him a video from Cuba after his return to the island.\n\nOnce the existence of the strange phenomenon was confirmed for everyone, E. Altshuler and a number of collaborators performed a systematic study in Havana, which was then jointly published with Bassler.\nFurther work has been done to understand in more detail the\nphenomenon, and it has been found in other sands from different parts of the world. \nHowever, the connection between the physical, chemical (and possibly biological) properties of the grains in a specific sand, the nature of the inter-grain interactions, and the emergence of the revolving rivers is still an open question.\n\nSand from Santa Teresa is made of almost pure silicon dioxide grains with an average grain size of 0.2 mm approximately and no visible special features regarding grain shape. But in spite of its apparent simplicity, many puzzles still remain. For example, after many experiments one batch of sand may stop showing revolving rivers (just as singing sand eventually stops singing), which suggests that the decay is connected to certain properties of the surface of the grains that degrade by continued friction.\n\nVideos of the effect are available on YouTube.\n"}
{"id": "39228990", "url": "https://en.wikipedia.org/wiki?curid=39228990", "title": "Riesz rearrangement inequality", "text": "Riesz rearrangement inequality\n\nIn mathematics, the Riesz rearrangement inequality (sometimes called Riesz-Sobolev inequality) states that for any three non-negative functions formula_1, formula_2 and formula_3 satisfies the inequality\nwhere formula_5, formula_6 and formula_7 are the symmetric decreasing rearrangements of the functions formula_8, formula_9 and formula_10 respectively.\n\nThe inequality was first proved by Frigyes Riesz in 1930, \nand independently reproved by S.L.Sobolev in 1938. It can be generalized to arbitrarily (but finitely) many functions acting on arbitrarily many variables.\n\nThe Riesz rearrangement inequality can be used to prove the Pólya–Szegő inequality.\n\nIn the one-dimensional case, the inequality is first proved when the functions formula_8, formula_9 and formula_10 are characteristic functions of a finite unions of intervals. Then the inequality can be extended to characteristic functions of measurable sets, to measurable functions taking a finite number of values and finally to nonnegative measurable functions.\n\nIn order to pass from the one-dimensional case to the higher-dimensional case, the spherical rearrangement is approximated by Steiner symmetrization for which the one-dimensional argument applies directly by Fubini's theorem.\n\nIn the case where any one of the three functions is a strictly symmetric-decreasing function, equality holds only when the other two functions are equal, up to translation, to their symmetric-decreasing rearrangements.\n"}
{"id": "26452", "url": "https://en.wikipedia.org/wiki?curid=26452", "title": "Riesz representation theorem", "text": "Riesz representation theorem\n\nThere are several well-known theorems in functional analysis known as the Riesz representation theorem. They are named in honor of Frigyes Riesz.\n\nThis article will describe his theorem concerning the dual of a Hilbert space, which is sometimes called the Fréchet–Riesz theorem. For the theorems relating linear functionals to measures, see Riesz–Markov–Kakutani representation theorem.\n\nThis theorem establishes an important connection between a Hilbert space and its continuous dual space. If the underlying field is the real numbers, the two are isometrically isomorphic; if the underlying field is the complex numbers, the two are isometrically anti-isomorphic. The (anti-) isomorphism is a particular natural one as will be described next; a natural isomorphism.\n\nLet \"H\" be a Hilbert space, and let \"H*\" denote its dual space, consisting of all continuous linear functionals from \"H\" into the field formula_1 or formula_2. If formula_3 is an element of \"H\", then the function formula_4 for all formula_5 in \"H\" defined by:\n\nformula_6\n\nwhere formula_7 denotes the inner product of the Hilbert space, is an element of \"H*\". The Riesz representation theorem states that \"every\" element of \"H*\" can be written uniquely in this form. Given any continuous linear functional \"g\" in \"H*\", the corresponding element formula_8 can be constructed uniquely by formula_9, where formula_10 is an orthonormal basis of \"H\", and the value of formula_11 does not vary by choice of basis. Thus, if formula_12, then formula_13 \n\nTheorem. The mapping formula_14: \"H\" → \"H*\" defined by formula_15 = formula_16 is an isometric (anti-) isomorphism, meaning that:\n\nThe inverse map of formula_14 can be described as follows. Given a non-zero element formula_30 of \"H*\", the orthogonal complement of the kernel of formula_30 is a one-dimensional subspace of \"H\". Take a non-zero element \"z\" in that subspace, and set formula_32. Then formula_15 = formula_30.\n\nHistorically, the theorem is often attributed simultaneously to Riesz and Fréchet in 1907 (see references).\n\nIn the mathematical treatment of quantum mechanics, the theorem can be seen as a justification for the popular bra–ket notation. The theorem says that, every bra formula_35 has a corresponding ket formula_36, and the latter is unique.\n\n"}
{"id": "30537795", "url": "https://en.wikipedia.org/wiki?curid=30537795", "title": "Skew binary number system", "text": "Skew binary number system\n\nThe skew binary number system is a non-standard positional numeral system in which the \"n\"th digit contributes a value of formula_1 times the digit (digits are indexed from 0) instead of formula_2 times as they do in binary. Each digit has a value of 0, 1, or 2. Notice that a number can have many skew binary representations. For example, a decimal number 15 can be written as 1000, 201 and 122. Each number can be written uniquely in skew binary canonical form where there is only at most one instance of the digit 2, which must be the first non-zero least significant digit. In this case 15 is written canonically as 1000.\n\nSkew binary representations of the numbers from 0 to 15 are shown in following table:\n\nThe advantage of skew binary is that each increment operation can be done with at most one carry operation. This exploits the fact that formula_3. Incrementing a skew binary number is done by setting the only two to a zero and incrementing the next digit from zero to one or one to two. \nWhen numbers are represented using a form of run-length encoding as linked lists of the non-zero digits, a form called the sparse representations of numbers by Okasaki, incrementation and decrementation can be performed in constant time.\n\nOther arithmetic operations are performed by switching between the skew binary representation and the binary representation.\n\nGiven a skew binary number, its value can be computed by a loop, computing the successive values of formula_4 and adding it once or twice for each formula_5 such that the formula_5th digit is 1 or 2 respectively. A more efficient method is now given, with only bit representation and one substraction.\n\nThe skew binary number of the form formula_7 without 2 and with formula_8 1s is equal to the binary number formula_9 minus formula_8. Let formula_11 represents the digit formula_12 repeated formula_13 times. The skew binary number of the form formula_14 with formula_8 1s is equal to the binary number formula_16 minus formula_8.\n\nSimilarly to the preceding section, the binary number formula_18 of the form formula_7 with formula_8 1s equals the skew binary number formula_21 plus formula_8. Note that since addition is not defined, adding formula_8 corresponds to incrementing the number formula_8 times. However, formula_8 is bounded by the logarithm of formula_18 and incrementation takes constant time. Hence transforming a binary number into a skew binary number runs in time linear in the length of the number.\n\nSkew binary numbers find applications in skew binomial heaps, a variant of binomial heaps that support worst-case O(1) insertion, and in skew binary random access lists, a purely functional data structure. They also find use in bootstrapped skew binomial heaps, which have excellent asymptotic guarantees.\n\nIf smoothsort is implemented using perfect binary trees (rather than the more common Leonardo trees), the heap is divided into trees which correspond to the digits of the skew binary representation of the heap size.\n\n\n"}
{"id": "22228915", "url": "https://en.wikipedia.org/wiki?curid=22228915", "title": "Solution of triangles", "text": "Solution of triangles\n\nSolution of triangles () is the main trigonometric problem of finding the characteristics of a triangle (angles and lengths of sides), when some of these are known. The triangle can be located on a plane or on a sphere. Applications requiring triangle solutions include geodesy, astronomy, construction, and navigation.\n\nA general form triangle has six main characteristics (see picture): three linear (side lengths ) and three angular (). The classical plane trigonometry problem is to specify three of the six characteristics and determine the other three. A triangle can be uniquely determined in this sense when given any of the following:\n\n\nFor all cases in the plane, at least one of the side lengths must be specified. If only the angles are given, the side lengths cannot be determined, because any similar triangle is a solution.\n\nThe standard method of solving the problem is to use fundamental relations.\nThere are other (sometimes practically useful) universal relations: the law of cotangents and Mollweide's formula.\n\n\nLet three side lengths be specified. To find the angles , the law of cosines can be used:\n\nThen angle .\n\nSome sources recommend to find angle from the law of sines but (as Note 1 above states) there is a risk of confusing an acute angle value with an obtuse one.\n\nAnother method of calculating the angles from known sides is to apply the law of cotangents.\n\nHere the lengths of sides and the angle between these sides are known. The third side can be determined from the law of cosines:\nNow we use law of cosines to find the second angle:\nFinally, .\n\nThis case is not solvable in all cases; a solution is guaranteed to be unique only if the side length adjacent to the angle is shorter than the other side length. Assume that two sides and the angle are known. The equation for the angle can be implied from the law of sines:\nWe denote further (the equation's right side). There are four possible cases:\n\nOnce is obtained, the third angle .\n\nThe third side can then be found from the law of sines:\n\nor\n\nThe known characteristics are the side and the angles . The third angle .\n\nTwo unknown sides can be calculated from the law of sines:\n\nor \n\nThe procedure for solving an AAS triangle is same as that for an ASA triangle: First, find the third angle by using the angle sum property of a triangle, then find the other two sides using the law of sines.\n\nThe general spherical triangle is fully determined by three of its six characteristics (3 sides and 3 angles). Note that the sides of a spherical triangle are measured by angular rather than linear units, based on the corresponding central angles.\n\nThe solution of triangles for non-Euclidean spherical geometry has some differences from the planar case. For example, the sum of the three angles depends on the triangle. In addition, there are no unequal similar triangles, and so the problem of constructing a triangle with specified three angles has a unique solution. The basic relations used to solve a problem are similar to those of the planar case: see Law of cosines (spherical) and Law of sines (spherical).\n\nAmong other relationships that may be useful are the half-side formula and Napier's analogies:\n\nKnown: the sides (in angular units). The triangle's angles are computed from the spherical law of cosines:\n\nKnown: the sides and the angle between them. The side can be found from the law of cosines:\n\nThe angles can be calculated as above, or by using Napier's analogies:\n\nThis problem arises in the navigation problem of finding the great circle between two points on the earth specified by their latitude and longitude; in this application, it is important to use formulas which are not susceptible to round-off errors. For this purpose, the following formulas (which may be derived using vector algebra) can be used:\nwhere the signs of the numerators and denominators in these expressions should be used to determine the quadrant of the arctangent.\n\nThis problem is not solvable in all cases; a solution is guaranteed to be unique only if the side length adjacent to the angle is shorter than the other side length. Known: the sides and the angle not between them. A solution exists if the following condition holds:\nThe angle can be found from the spherical law of sines:\nAs for the plane case, if then there are two solutions: and .\n\nWe can find other characteristics by using Napier's analogies:\n\nKnown: the side and the angles . First we determine the angle using the law of cosines:\n\nWe can find the two unknown sides from the law of cosines (using the calculated angle ):\n\nor by using Napier's analogies:\n\nKnown: the side and the angles . The side can be found from the law of sines:\n\nIf the angle for the side is acute and , another solution exists:\n\nWe can find other characteristics by using Napier's analogies:\n\nKnown: the angles . From the law of cosines we infer:\nThe above algorithms become much simpler if one of the angles of a triangle (for example, the angle ) is the right angle. Such a spherical triangle is fully defined by its two elements, and the other three can be calculated using Napier's Pentagon or the following relations.\n\nIf one wants to measure the distance from shore to a remote ship via triangulation, one marks on the shore two points with known distance between them (the baseline). Let be the angles between the baseline and the direction to the ship.\n\nFrom the formulae above (ASA case) one can compute the distance as the triangle height:\n\nThis method is used in cabotage. The angles are defined by observation of familiar landmarks from the ship.\nAs another example, if one wants to measure the height of a mountain or a high building, the angles from two ground points to the top are specified. Let be the distance between these points. From the same ASA case formulas we obtain:\n\nTo calculate the distance between two points on the globe,\nwe consider the spherical triangle , where is the North Pole. Some characteristics are:\nIf two sides and the included angle given, we obtain from the formulas\nHere is the Earth's radius.\n\n\n"}
{"id": "3724075", "url": "https://en.wikipedia.org/wiki?curid=3724075", "title": "Typographical Number Theory", "text": "Typographical Number Theory\n\nTypographical Number Theory (TNT) is a formal axiomatic system describing the natural numbers that appears in Douglas Hofstadter's book \"Gödel, Escher, Bach\". It is an implementation of Peano arithmetic that Hofstadter uses to help explain Gödel's incompleteness theorems.\n\nLike any system implementing the Peano axioms, TNT is capable of referring to itself (it is self-referential).\n\nTNT does not use a distinct symbol for each natural number. Instead it makes use of a simple, uniform way of giving a compound symbol to each natural number:\n\nThe symbol S can be interpreted as \"the successor of\", or \"the number after\". Since this is, however, a number theory, such interpretations are useful, but not strict. It cannot be said that because four is the successor of three that four is SSSS0, but rather that since three is the successor of two, which is the successor of one, which is the successor of zero, which has been described as 0, four can be \"proved\" to be SSSS0. TNT is designed such that everything must be proven before it can be said to be true.\n\nIn order to refer to unspecified terms, TNT makes use of five variables. These are\nMore variables can be constructed by adding the prime symbol after them; for example,\n\nIn the more rigid version of TNT, known as \"austere\" TNT, only\n\nIn Typographical Number Theory, the usual symbols of \"+\" for additions, and \"·\" for multiplications are used. Thus to write \"b plus c\" is to write\n\nand \"a times d\" is written as\n\nThe parentheses are required. Any laxness would violate TNT's formation system (although it is trivially proved this formalism is unnecessary for operations which are both commutative and associative). Also only two terms can be operated on at once. Therefore, to write \"a plus b plus c\" is to write either\n\nor\n\nThe \"Equals\" operator is used to denote equivalence. It is defined by the symbol \"=\", and takes roughly the same meaning as it usually does in mathematics. For instance,\nis a theorem statement in TNT, with the interpretation \"3 plus 3 equals 6\".\n\nIn Typographical Number Theory, negation, i.e. the turning of a statement to its opposite, is denoted by the \"~\" or negation operator. For instance,\n\nis a theorem in TNT, interpreted as \"3 plus 3 is not equal to 7\".\n\nBy negation, this means negation in Boolean logic (logical negation), rather than simply being the opposite. For example, if I were to say \"I am eating a grapefruit\", the opposite is \"I am not eating a grapefruit\", rather than \"I am eating something other than a grapefruit\". Similarly \"The Television is on\" is negated to \"The Television is not on\", rather than \"The Television is off\". This is a subtle difference, but an important one.\n\nIf x and y are well-formed formulas, and provided that no variable which is free in one is quantified in the other, then the following are all well-formed formulas\n\nExamples:\n\n\nThe quantification status of a variable doesn't change here.\n\nThere are two quantifiers used: \"∀\" and \"∃\".\n\nNote that unlike most other logical systems where qualifiers over sets require a mention of the element's existence in the set, this is not required in TNT because all numbers and terms are strictly natural numbers or logical boolean statements. It is therefore equivalent to say ∀a:(a ∈ N):∀b:(b ∈ N): (a + b) = (b + a)  and ∀a:∀b:(a + b) = (b + a)\n\n\nFor example:\n\nAll the symbols of propositional calculus apart from the Atom symbols are used in Typographical Number Theory, and they retain their interpretations.\n\nAtoms are here defined as strings which amount to statements of equality, such as\n\n2 plus 3 equals five:\n2 plus 2 is equal to 4:\n"}
{"id": "50652", "url": "https://en.wikipedia.org/wiki?curid=50652", "title": "Uniform convergence", "text": "Uniform convergence\n\nIn the mathematical field of analysis, uniform convergence is a type of convergence of functions stronger than pointwise convergence. A sequence of functions formula_1 converges uniformly to a limiting function formula_2 on a set formula_3 if, given any arbitrarily small positive number formula_4, a number formula_5 can be found such that each of the functions formula_6 differ from formula_2 by no more than formula_4 \"at every point\" formula_9 \"in\" formula_3. Described in an informal way, if formula_11 converges to formula_2 uniformly, then the rate at which formula_13 approaches formula_14 is \"uniform\" throughout its domain in the following sense: in order to determine how large formula_15 needs to be to guarantee that formula_13 falls within a certain distance formula_4 of formula_14, we do not need to know the value of formula_19 in question — there is a single value of formula_20 \"independent of formula_9\", such that choosing formula_15 to be larger than formula_5 will suffice. \n\nThe difference between uniform convergence and pointwise convergence was not fully appreciated early in the history of calculus, leading to instances of faulty reasoning. The concept, which was first formalized by Karl Weierstrass, is important because several properties of the functions formula_11, such as continuity, Riemann integrability, and, with additional hypotheses, differentiability, are transferred to the limit formula_2 if the convergence is uniform, but not necessarily if the convergence is not uniform.\n\nIn 1821 Augustin-Louis Cauchy published a proof that a convergent sum of continuous functions is always continuous, to which Niels Henrik Abel in 1826 found purported counterexamples in the context of Fourier series, arguing that Cauchy's proof had to be incorrect. Completely standard notions of convergence did not exist at the time, and Cauchy handled convergence using infinitesimal methods. When put into the modern language, what Cauchy proved is that a uniformly convergent sequence of continuous functions has a continuous limit. The failure of a merely pointwise-convergent limit of continuous functions to converge to a continuous function illustrates the importance of distinguishing between different types of convergence when handling sequences of functions.\n\nThe term uniform convergence was probably first used by Christoph Gudermann, in an 1838 paper on elliptic functions, where he employed the phrase \"convergence in a uniform way\" when the \"mode of convergence\" of a series formula_26 is independent of the variables formula_27 and formula_28 While he thought it a \"remarkable fact\" when a series converged in this way, he did not give a formal definition, nor use the property in any of his proofs.\n\nLater Gudermann's pupil Karl Weierstrass, who attended his course on elliptic functions in 1839–1840, coined the term \"gleichmäßig konvergent\" () which he used in his 1841 paper \"Zur Theorie der Potenzreihen\", published in 1894. Independently, similar concepts were articulated by Philipp Ludwig von Seidel and George Gabriel Stokes. G. H. Hardy compares the three definitions in his paper \"Sir George Stokes and the concept of uniform convergence\" and remarks: \"Weierstrass's discovery was the earliest, and he alone fully realized its far-reaching importance as one of the fundamental ideas of analysis.\"\n\nUnder the influence of Weierstrass and Bernhard Riemann this concept and related questions were intensely studied at the end of the 19th century by Hermann Hankel, Paul du Bois-Reymond, Ulisse Dini, Cesare Arzelà and others.\n\nWe first define uniform convergence for real-valued functions, although the concept is readily generalized to functions mapping to metric spaces and, more generally, uniform spaces (see below). \n\nSuppose formula_3 is a set and formula_30 (for formula_31) are real-valued functions. We say that the sequence formula_32 is uniformly convergent on formula_3 with limit formula_34 if for every formula_35, there exists a natural number formula_36 such that for all formula_37 and formula_38\n\nThe notation for uniform convergence of formula_11 to formula_2 is not quite standardized and different authors have used a variety of symbols, including (in roughly decreasing order of popularity) formula_42, formula_43, formula_44. Frequently, no special symbol is used, and authors simply write formula_45 to indicate that convergence is uniform. (In contrast, the expression formula_46 on formula_3 without an adverb is taken to mean pointwise convergence on formula_3: for all formula_38, formula_50 as formula_51.)\n\nSince formula_52 is a complete metric space, the Cauchy criterion can be used to give an equivalent alternative formulation for uniform convergence: formula_53 converges uniformly on formula_3 (in the previous sense) if and only if for every formula_35, there exists a natural number formula_36 such that\n\nIn yet another equivalent formulation, if we define formula_58, then formula_59 converges to formula_60 uniformly if and only if formula_61 as formula_51. Thus, we can characterize uniform convergence of formula_32 on formula_3 as (simple) convergence of formula_32 in the function space formula_66 with respect to the \"uniform metric\" (also called the supremum metric), defined by formula_67. Symbolically, \n\nThe sequence formula_69 is said to be locally uniformly convergent with limit formula_60 if formula_71 is a metric space and for every formula_72, there exists an formula_73 such that formula_74 converges uniformly on formula_75. It is clear that uniform convergence implies local uniform convergence, which implies pointwise convergence.\n\nIntuitively, a sequence of functions formula_11 converges uniformly to formula_2 if, given an arbitrarily small formula_78, we can find an formula_79 so that the functions formula_80 all fall within a \"tube\" of width formula_81 centered around formula_2 (i.e., between formula_83 and formula_84) for the \"entire domain\" of the function.\n\nNote that interchanging the order of quantifiers in the definition of uniform convergence by moving \"for all formula_19\" in front of \"there exists a natural number formula_5\" results in a definition of pointwise convergence of the sequence. To make this difference explicit, in the case of uniform convergence, formula_20 can only depend on formula_4, and the choice of formula_5 has to work for all formula_19, for a specific value of formula_4 that is given. In contrast, in the case of pointwise convergence, formula_92 may depend on both formula_4 and formula_9, and the choice of formula_5 only has to work for the specific values of formula_4 and formula_9 that are given. Thus uniform convergence implies pointwise convergence, however the converse is not true, as the example in the section below illustrates.\n\nOne may straightforwardly extend the concept to functions \"E\" → \"M\", where (\"M\", \"d\") is a metric space, by replacing formula_98 with formula_99.\n\nThe most general setting is the uniform convergence of nets of functions \"E\" → \"X\", where \"X\" is a uniform space. We say that the net formula_100 \"converges uniformly\" with limit \"f\" : \"E\" → \"X\" if and only if for every entourage \"V\" in \"X\", there exists an formula_101, such that for every \"x\" in \"E\" and every formula_102, formula_103 is in \"V\".\nIn this situation, uniform limit of continuous functions remain continuous.\n\nUniform convergence admits a simplified definition in a hyperreal setting. Thus, a sequence formula_11 converges to \"f\" uniformly if for all \"x\" in the domain of \"f*\" and all infinite \"n\", formula_105 is infinitely close to formula_106 (see microcontinuity for a similar definition of uniform continuity).\n\nGiven a topological space \"X\", we can equip the space of bounded real or complex-valued functions over \"X\" with the uniform norm topology, with the uniform metric defined by formula_107. Then uniform convergence simply means convergence in the uniform norm topology: formula_108.\n\nThe sequence of functions formula_1 with formula_110 defined by formula_111 is a classic example of a sequence of functions that converges to a function formula_112 pointwise but not uniformly. To show this, we first observe that the pointwise limit of formula_1 as formula_51 is the function formula_112, given by\n\n\"Pointwise convergence:\" Convergence is trivial for formula_117 and formula_118, since formula_119 and formula_120, for all formula_15. For formula_122 and given formula_78, we can ensure that formula_124 whenever formula_125 by choosing formula_126 (here the upper square brackets indicate rounding up, see ceiling function). Hence, formula_46 pointwise for all formula_128. Note that the choice of formula_5 depends on the value of formula_4 \"and\" formula_9. Moreover, for a fixed choice of formula_4, formula_5 (which cannot be defined to be smaller) grows without bound as formula_9 approaches 1. These observations preclude the possibility of uniform convergence.\n\n\"Non-uniformity of convergence:\" The convergence is not uniform, because given formula_78, no \"single choice\" of formula_5 can ensure that formula_124 \"for all\" formula_128, whenever formula_125. To see this, we note that regardless of how large formula_15 becomes, there is always an formula_141 such that formula_142 (or any other positive value less than 1). Thus, if we choose formula_143, we can never find an formula_5 such that formula_124 for all formula_128 and formula_125. Explicitly, given any candidate for formula_5, consider the value of formula_149 at formula_150. Since formula_151, we have found an example of an formula_128 that \"escaped\" our attempt to \"confine\" each formula_80 to within formula_4 of formula_112 for all formula_128. In fact, it is easy to see that formula_157, contrary to the requirement that formula_158 if formula_42.\n\nIn this example one can easily see that pointwise convergence does not preserve differentiability or continuity. While each function of the sequence is smooth, that is to say that for all \"n\", formula_160, the limit formula_161 is not even continuous.\n\nThe series expansion of the exponential function can be shown to be uniformly convergent on any bounded subset formula_162 using the Weierstrass M-test.\n\nTheorem (Weierstrass M-test). \"Let formula_74 be a sequence of functions formula_164 and let formula_165 be a sequence of positive real numbers such that formula_166 for all formula_72 and formula_31. If formula_169 converges, then formula_170 converges uniformly on formula_71.\"\n\nThe complex exponential function can be expressed as the series:\n\nAny bounded subset is a subset of some disc formula_173 of radius formula_174, centered on the origin in the complex plane. The Weierstrass M-test requires us to find an upper bound formula_175 on the terms of the series, with formula_175 independent of the position in the disc:\nTo do this, we notice\nand take formula_179.\n\nIf formula_180 is convergent, then the M-test asserts that the original series is uniformly convergent.\n\nThe ratio test can be used here:\nwhich means the series over formula_175 is convergent.\nThus the original series converges uniformly for all formula_183, and since formula_184, the series is also uniformly convergent on formula_185.\n\n\nIf formula_3 and formula_193 are topological spaces, then it makes sense to talk about the continuity of the functions formula_194. If we further assume that formula_193 is a metric space, then (uniform) convergence of the formula_11 to formula_2 is also well defined. The following result states that continuity is preserved by uniform convergence:\n\nThis theorem is proved by the \" trick\", and is the archetypal example of this trick: to prove a given inequality (), one uses the definitions of continuity and uniform convergence to produce 3 inequalities (), and then combines them via the triangle inequality to produce the desired inequality.\n\nThis theorem is an important one in the history of real and Fourier analysis, since many 18th century mathematicians had the intuitive understanding that a sequence of continuous functions always converges to a continuous function. The image above shows a counterexample, and many discontinuous functions could, in fact, be written as a Fourier series of continuous functions. The erroneous claim that the pointwise limit of a sequence of continuous functions is continuous (originally stated in terms of convergent series of continuous functions) is infamously known as \"Cauchy's wrong theorem\". The uniform limit theorem shows that a stronger form of convergence, uniform convergence, is needed to ensure the preservation of continuity in the limit function.\n\nMore precisely, this theorem states that the uniform limit of \"uniformly continuous\" functions is uniformly continuous; for a locally compact space, continuity is equivalent to local uniform continuity, and thus the uniform limit of continuous functions is continuous.\n\nIf formula_186 is an interval and all the functions formula_11 are differentiable and converge to a limit formula_2, it is often desirable to determine the derivative function formula_208 by taking the limit of the sequence formula_209. This is however in general not possible: even if the convergence is uniform, the limit function need not be differentiable (not even if the sequence consists of everywhere-analytic functions, see Weierstrass function), and even if it is differentiable, the derivative of the limit function need not be equal to the limit of the derivatives. Consider for instance formula_210 with uniform limit formula_211. Clearly, formula_208 is also identically zero. However, the derivatives of the sequence of functions are given by formula_213 and the sequence formula_209 does not converge to formula_215 or even to any function at all. In order to ensure a connection between the limit of a sequence of differentiable functions and the limit of the sequence of derivatives, the uniform convergence of the sequence of derivatives plus the convergence of the sequence of functions at at least one point is required. The precise statement covering this situation is as follows:\n\nSimilarly, one often wants to exchange integrals and limit processes. For the Riemann integral, this can be done if uniform convergence is assumed:\nIn fact, for a uniformly convergent family of bounded functions on an interval, the upper and lower Riemann integrals converge to the upper and lower Riemann integrals of the limit function. This follows because, for \"n\" sufficiently large, the graph of formula_11 is within of the graph of \"f\", and so the upper sum and lower sum of formula_11 are each within formula_235 of the value of the upper and lower sums of formula_2, respectively.\n\nMuch stronger theorems in this respect, which require not much more than pointwise convergence, can be obtained if one abandons the Riemann integral and uses the Lebesgue integral instead.\n\nIf a sequence of analytic functions converges uniformly in a region S of the complex plane, then the limit is analytic in S. This example demonstrates that complex functions are more well-behaved than real functions, since the uniform limit of analytic functions on a real interval need not even be differentiable (see Weierstrass function).\n\nWe say that formula_237 converges:\n\ni) pointwise on \"E\" if and only if the sequence of partial sums formula_238 converges for every formula_19.\n\nii) uniformly on \"E\" if and only if \"s\" converges uniformly as formula_51.\n\niii) absolutely on \"E\" if and only if formula_241 converges for every formula_19.\n\nWith this definition comes the following result: \"Let x\" \"be contained in the set E and each f be continuous at x\"\". If formula_243 converges uniformly on E then f is continuous at x\" \"in E. Suppose that formula_244 and each f is integrable on E. If formula_245 converges uniformly on E then f is integrable on E and the series of integrals of f is equal to integral of the series of f.\" \n\nIf the domain of the functions is a measure space E then the related notion of almost uniform convergence can be defined. We say a sequence of functions formula_1 converges almost uniformly on \"E\" if for every formula_247 there exists a measurable set formula_248 with measure less than formula_249 such that the sequence of functions formula_1 converges uniformly on formula_251. In other words, almost uniform convergence means there are sets of arbitrarily small measure for which the sequence of functions converges uniformly on their complement.\n\nNote that almost uniform convergence of a sequence does not mean that the sequence converges uniformly almost everywhere as might be inferred from the name. However, Egorov's theorem does guarantee that on a finite measure space, a sequence of functions that converges almost everywhere also converges almost uniformly on the same set.\n\nAlmost uniform convergence implies almost everywhere convergence and convergence in measure.\n\n\n\n"}
{"id": "53959419", "url": "https://en.wikipedia.org/wiki?curid=53959419", "title": "Vera W. de Spinadel", "text": "Vera W. de Spinadel\n\nVera Martha Winitzky de Spinadel (August 22, 1929 – January 26, 2017, Buenos Aires, Argentina) was an Argentine mathematician. She was the first woman to gain a PhD in mathematics at the University of Buenos Aires, Argentina, in 1958. Between 2010 and 2017, she was full Emeritus Professor in the Faculty of Architecture, Design and Urban Planning of the University of Buenos Aires. In 1995, she was named Director of the Centre of Mathematics and Design. In April 2005 she inaugurated the Laboratory of Mathematics & Design, University Campus in Buenos Aires. From 1998 to her death she was the President of the International Mathematics and Design Association, which organizes international congresses every 3 years and publishes a Journal of Mathematics & Design. She was the author of more than 10 books and published more than 100 research papers.\nSpinadel was a leader in the field of Metallic mean in the development of the classical Golden Ratio got wide international recognition.\n\n\n\n\n"}
