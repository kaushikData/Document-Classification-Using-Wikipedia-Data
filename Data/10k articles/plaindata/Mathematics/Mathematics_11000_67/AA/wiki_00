{"id": "1486657", "url": "https://en.wikipedia.org/wiki?curid=1486657", "title": "235 (number)", "text": "235 (number)\n\n235 (two hundred [and] thirty-five) is the integer following 234 and preceding 236.\n\n235 is:\n\n\nAlso:\n\n\n"}
{"id": "7763362", "url": "https://en.wikipedia.org/wiki?curid=7763362", "title": "5-manifold", "text": "5-manifold\n\nIn mathematics, a 5-manifold is a 5-dimensional topological manifold, possibly with a piecewise linear or smooth structure.\n\nNon-simply connected 5-manifolds are impossible to classify, as this is harder than solving the word problem for groups. Simply connected compact 5-manifolds were first classified by Stephen Smale and then in full generality by Dennis Barden, while another proof was later given by Aleksey V. Zhubr. Rather surprisingly, this turns out to be easier than the 3- or 4-dimensional case: the 3-dimensional case is the Thurston geometrisation conjecture, and the 4-dimensional case was solved by Michael Freedman (1982) in the topological case, but is a very hard unsolved problem in the smooth case.\n\nIn dimension 5, the smooth classification of manifolds is governed by classical algebraic topology. Namely, two simply connected, smooth 5-manifolds are diffeomorphic if and only if there exists an isomorphism of their second homology groups with integer coefficients, preserving the linking form and the second Stiefel–Whitney class. Moreover, any such isomorphism in second homology is induced by some diffeomorphism.\n\nHere are some examples of smooth, closed, simply connected 5-manifolds:\n\n"}
{"id": "17174687", "url": "https://en.wikipedia.org/wiki?curid=17174687", "title": "ABC@Home", "text": "ABC@Home\n\nABC@Home was an educational and non-profit network computing project finding abc-triples related to the abc conjecture in number theory. \n\nUsing the Berkeley Open Infrastructure for Network Computing (BOINC) distributed computing platform. In March 2011, there were more than 7,300 active participants from 114 countries with a total BOINC credit of more than 2.9 billion, reporting about 10 teraflops (10 trillion operations per second) of processing power.\n\nIn 2011, the project met its goal of finding all abc-triples of at most 18 digits. By 2015, the project had found 23.8 million triples in total, and ceased operations soon after.\n\n\n"}
{"id": "9996788", "url": "https://en.wikipedia.org/wiki?curid=9996788", "title": "Affine manifold", "text": "Affine manifold\n\nIn differential geometry, an affine manifold is a differentiable manifold equipped with a flat, torsion-free connection.\n\nEquivalently, it is a manifold that is (if connected) covered by an open subset of formula_1, with monodromy acting by affine transformations. This equivalence is an easy corollary of Cartan–Ambrose–Hicks theorem.\n\nEquivalently, it is a manifold equipped with an atlas—called the affine structure—such that all transition functions between charts are affine transformations (that is, have constant jacobian matrix); two atlases are equivalent if the manifold admits an atlas subjugated to both, with transitions from both atlases to a smaller atlas being affine. A manifold having a distinguished affine structure is called an affine manifold and the charts which are affinely related to those of the affine structure are called affine charts. In each affine coordinate domain the coordinate vector fields form a parallelization of that domain, so there is an associated connection on each domain. These locally defined connections are the same on overlapping parts, so there is a unique connection associated with an affine structure. Note there is a link between linear connection (also called affine connection) and a web.\n\nAn affine manifold formula_2 is a real manifold with charts formula_3 such that formula_4 for all formula_5 where formula_6 denotes the Lie group of affine transformations. In fancier words it is a (G,X)-manifold where formula_7 and formula_8 is the group of affine transformations. \n\nAn affine manifold is called complete if its universal covering is homeomorphic to formula_1.\n\nIn the case of a compact affine manifold formula_10, let formula_8 be the fundamental group of formula_10 and formula_13 be its universal cover. One can show that each formula_14-dimensional affine manifold comes with a developing map formula_15, and a homomorphism formula_16, such that formula_17 is an immersion and equivariant with respect to formula_18.\n\nA fundamental group of a compact complete flat affine manifold is called an affine crystallographic group. Classification of affine crystallographic groups is a difficult problem, far from being solved. The Riemannian crystallographic groups (also known as Bieberbach groups) were classified by Ludwig Bieberbach, answering a question posed by David Hilbert. In his work on Hilbert's 18-th problem, Bieberbach proved that any Riemannian crystallographic group contains an abelian subgroup of finite index.\n\nGeometry of affine manifolds is essentially a network of longstanding conjectures; most of them proven in low dimension and some other special cases.\n\nThe most important of them are\n\n"}
{"id": "17974424", "url": "https://en.wikipedia.org/wiki?curid=17974424", "title": "Akbulut cork", "text": "Akbulut cork\n\nIn topology, an Akbulut cork is a structure that is frequently used to show that in four dimensions, the smooth h-cobordism theorem fails. It was named after Turkish mathematician Selman Akbulut.\n\nA compact contractible Stein 4-manifold C with involution F on its boundary is called an Akbulut cork, if F extends to a self-homeomorphism but cannot extend to a self-diffeomorphism inside (hence a cork is an exotic copy of itself relative to its boundary). A cork (C,F) is called a cork of a smooth 4-manifold X, if removing C from X and re-gluing it via F changes the smooth structure of X (this operation is called \"cork twisting\"). Any exotic copy X' of a closed simply connected 4-manifold X differs from X by a single cork twist.\n\nThe basic idea of the Akbulut cork is that when attempting to use the h-corbodism theorem in four dimensions, the cork is the sub-cobordism that contains all the exotic properties of the spaces connected with the cobordism, and when removed the two spaces become trivially h-cobordant and smooth. This shows that in four dimensions, although the theorem does not tell us that two manifolds are diffeomorphic (only homeomorphic), they are \"not far\" from being diffeomorphic.\n\nTo illustrate this (without proof), consider a smooth h-cobordism \"W\" between two 4-manifolds \"M\" and \"N\". Then within \"W\" there is a sub-cobordism \"K\" between \"A\" ⊂ \"M\" and \"B\" ⊂ \"N\" and there is a diffeomorphism\n\nwhich is the content of the h-cobordism theorem for \"n\" ≥ 5 (here int \"X\" refers to the interior of a manifold \"X\"). In addition, \"A\" and \"B\" are diffeomorphic with a diffeomorphism that is an involution on the boundary ∂\"A\" = ∂\"B\". Therefore, it can be seen that the h-corbordism \"K\" connects \"A\" with its \"inverted\" image \"B\". This submanifold \"A\" is the Akbulut cork.\n\n"}
{"id": "35669727", "url": "https://en.wikipedia.org/wiki?curid=35669727", "title": "Amit Garg", "text": "Amit Garg\n\nDr Amit Garg is an Indian mathematician and mental calculator.\n\nOn 15 March 2012, he broke the mental calculation world record of completing ten tasks to \"divide a 10-digit number by a 5-digit number\" in a record time of 5:45 minutes without any errors. These tasks were constructed by a program provided by Dr Ralf Laue, author of the Book of Alternative Records and Chairman of Mental Calculation World Cup, such that there are no remainders. The previous record holder was Willem Bouman from the Netherlands with a time of 6:07 minutes. This world record was accepted at Limca Book of World Records and UK’s Book of Alternative Records. As a world record holder in mental calculation, Ralf Laue confirmed him as participant in the 5th Mental Calculation World Cup 2012 to be conducted at Germany.\n\nOn 22 August 2012, he won the silver medal in the Mental Calculation competition at the annually conducted Mind Sports Olympiad in London (UK). He was the first Indian to receive any of the medals in this category since the inception of this event in 1997. On 1 October 2012, he received a sixth rank in the \"most versatile calculator\" category based on his performance in surprise tasks at the fifth Mental Calculation World Cup in Germany. He secured a 10th place in the overall ranking based on combination of standard and surprise tasks. On 5th Dec, 2017, he astonished students at Middlesex University, Dubai using his mathematical feats and spoke on impact of applied mathematics in different industries. On 24 May 2018, he displayed his mathematical feat in different universities and companies in New Zealand.\n"}
{"id": "33005374", "url": "https://en.wikipedia.org/wiki?curid=33005374", "title": "Angelescu polynomials", "text": "Angelescu polynomials\n\nIn mathematics, Angelescu polynomials π(\"x\") are generalizations of the Laguerre polynomials introduced by given by the generating function\n\n"}
{"id": "24295969", "url": "https://en.wikipedia.org/wiki?curid=24295969", "title": "Applied mathematics", "text": "Applied mathematics\n\nApplied mathematics is the application of mathematical methods by different fields such as science, engineering, business, computer science, and industry. Thus, applied mathematics is a combination of mathematical science and specialized knowledge. The term \"applied mathematics\" also describes the professional specialty in which mathematicians work on practical problems by formulating and studying mathematical models. In the past, practical applications have motivated the development of mathematical theories, which then became the subject of study in pure mathematics where abstract concepts are studied for their own sake. The activity of applied mathematics is thus intimately connected with research in pure mathematics.\n\nHistorically, applied mathematics consisted principally of applied analysis, most notably differential equations; approximation theory (broadly construed, to include representations, asymptotic methods, variational methods, and numerical analysis); and applied probability. These areas of mathematics related directly to the development of Newtonian physics, and in fact, the distinction between mathematicians and physicists was not sharply drawn before the mid-19th century. This history left a pedagogical legacy in the United States: until the early 20th century, subjects such as classical mechanics were often taught in applied mathematics departments at American universities rather than in physics departments, and fluid mechanics may still be taught in applied mathematics departments. Quantitative finance is now taught in mathematics departments across universities and mathematical finance is considered a full branch of applied mathematics. Engineering and computer science departments have traditionally made use of applied mathematics.\n\nToday, the term \"applied mathematics\" is used in a broader sense. It includes the classical areas noted above as well as other areas that have become increasingly important in applications. Even fields such as number theory that are part of pure mathematics are now important in applications (such as cryptography), though they are not generally considered to be part of the field of applied mathematics \"per se\". Sometimes, the term \"applicable mathematics\" is used to distinguish between the traditional applied mathematics that developed alongside physics and the many areas of mathematics that are applicable to real-world problems today.\n\nThere is no consensus as to what the various branches of applied mathematics are. Such categorizations are made difficult by the way mathematics and science change over time, and also by the way universities organize departments, courses, and degrees.\n\nMany mathematicians distinguish between \"applied mathematics,\" which is concerned with mathematical methods, and the \"applications of mathematics\" within science and engineering. A biologist using a population model and applying known mathematics would not be \"doing\" applied mathematics, but rather \"using\" it; however, mathematical biologists have posed problems that have stimulated the growth of pure mathematics. Mathematicians such as Poincaré and Arnold deny the existence of \"applied mathematics\" and claim that there are only \"applications of mathematics.\" Similarly, non-mathematicians blend applied mathematics and applications of mathematics. The use and development of mathematics to solve industrial problems is also called \"industrial mathematics\".\n\nThe success of modern numerical mathematical methods and software has led to the emergence of computational mathematics, computational science, and computational engineering, which use high-performance computing for the simulation of phenomena and the solution of problems in the sciences and engineering. These are often considered interdisciplinary.\n\nHistorically, mathematics was most important in the natural sciences and engineering. However, since World War II, fields outside the physical sciences have spawned the creation of new areas of mathematics, such as game theory and social choice theory, which grew out of economic considerations.\n\nThe advent of the computer has enabled new applications: studying and using the new computer technology itself (computer science) to study problems arising in other areas of science (computational science) as well as the mathematics of computation (for example, theoretical computer science, computer algebra, numerical analysis). Statistics is probably the most widespread mathematical science used in the social sciences, but other areas of mathematics, most notably economics, are proving increasingly useful in these disciplines.\n\nAcademic institutions are not consistent in the way they group and label courses, programs, and degrees in applied mathematics. At some schools, there is a single mathematics department, whereas others have separate departments for Applied Mathematics and (Pure) Mathematics. It is very common for Statistics departments to be separated at schools with graduate programs, but many undergraduate-only institutions include statistics under the mathematics department.\n\nMany applied mathematics programs (as opposed to departments) consist of primarily cross-listed courses and jointly appointed faculty in departments representing applications. Some Ph.D. programs in applied mathematics require little or no coursework outside mathematics, while others require substantial coursework in a specific area of application. In some respects this difference reflects the distinction between \"application of mathematics\" and \"applied mathematics\".\n\nSome universities in the UK host departments of \"Applied Mathematics and Theoretical Physics\", but it is now much less common to have separate departments of pure and applied mathematics. A notable exception to this is the Department of Applied Mathematics and Theoretical Physics at the University of Cambridge, housing the Lucasian Professor of Mathematics whose past holders include Isaac Newton, Charles Babbage, James Lighthill, Paul Dirac and Stephen Hawking.\n\nSchools with separate applied mathematics departments range from Brown University, which has a large Division of Applied Mathematics that offers degrees through the doctorate, to Santa Clara University, which offers only the M.S. in applied mathematics. Research universities dividing their mathematics department into pure and applied sections include MIT. Brigham Young University also has an Applied and Computational Emphasis (ACME), a program that allows student to graduate with a Mathematics degree, with an emphasis in Applied Math. Students in this program also learn another skill (Computer Science, Engineering, Physics, Pure Math, etc.) to supplement their applied math skills.\n\nApplied mathematics is closely related to other mathematical sciences.\n\nScientific computing includes applied mathematics (especially numerical analysis), computing science (especially high-performance computing), and mathematical modelling in a scientific discipline.\n\nComputer science relies on logic, algebra, graph theory, and combinatorics.\n\nOperations research and management science are often taught in faculties of engineering, business, and public policy.\n\nApplied mathematics has substantial overlap with the discipline of statistics. Statistical theorists study and improve statistical procedures with mathematics, and statistical research often raises mathematical questions. Statistical theory relies on probability and decision theory, and makes extensive use of scientific computing, analysis, and optimization; for the design of experiments, statisticians use algebra and combinatorial design. Applied mathematicians and statisticians often work in a department of mathematical sciences (particularly at colleges and small universities).\n\nActuarial science applies probability, statistics, and economic theory to assess risk in insurance, finance and other industries and professions.\n\nMathematical economics is the application of mathematical methods to represent theories and analyze problems in economics. The applied methods usually refer to nontrivial mathematical techniques or approaches. Mathematical economics is based on statistics, probability, mathematical programming (as well as other computational methods), operations research, game theory, and some methods from mathematical analysis. In this regard, it resembles (but is distinct from) financial mathematics, another part of applied mathematics.\n\nAccording to the Mathematics Subject Classification (MSC), mathematical economics falls into the Applied mathematics/other classification of category 91:\n\nwith MSC2010 classifications for 'Game theory' at codes 91Axx and for 'Mathematical economics' at codes 91Bxx.\n\nApplicable mathematics is a subdiscipline of applied mathematics, although there is no consensus as to a precise definition. Sometimes the term \"applicable mathematics\" is used to distinguish between the traditional applied mathematics that developed alongside physics and the many areas of mathematics that are applicable to real-world problems today.\n\nMathematicians often distinguish between \"applied mathematics\" on the one hand, and the \"applications of mathematics\" or \"applicable mathematics\" both within and outside of science and engineering, on the other. Some mathematicians emphasize the term applicable mathematics to separate or delineate the traditional applied areas from new applications arising from fields that were previously seen as pure mathematics. For example, from this viewpoint, an ecologist or geographer using population models and applying known mathematics would not be doing applied, but rather applicable, mathematics. Even fields such as number theory that are part of pure mathematics are now important in applications (such as cryptography), though they are not generally considered to be part of the field of applied mathematics \"per se\".\n\nOther authors prefer describing \"applicable mathematics\" as a union of \"new\" mathematical applications with the traditional fields of applied mathematics. With this outlook, the terms applied mathematics and applicable mathematics are thus interchangeable.\n\nThe line between applied mathematics and specific areas of application is often blurred. Many universities teach mathematical and statistical courses outside the respective departments, in departments and areas including business, engineering, physics, chemistry, psychology, biology, computer science, scientific computation, and mathematical physics.\n\n\n"}
{"id": "311034", "url": "https://en.wikipedia.org/wiki?curid=311034", "title": "Arthur Cayley", "text": "Arthur Cayley\n\nArthur Cayley F.R.S. (; 16 August 1821 – 26 January 1895) was a British mathematician. He helped found the modern British school of pure mathematics.\n\nAs a child, Cayley enjoyed solving complex maths problems for amusement. He entered Trinity College, Cambridge, where he excelled in Greek, French, German, and Italian, as well as mathematics. He worked as a lawyer for 14 years.\n\nHe postulated the Cayley–Hamilton theorem—that every square matrix is a root of its own characteristic polynomial, and verified it for matrices of order 2 and 3. He was the first to define the concept of a group in the modern way—as a set with a binary operation satisfying certain laws. Formerly, when mathematicians spoke of \"groups\", they had meant permutation groups. Cayley tables and Cayley graphs as well as Cayley's theorem are named in honour of Cayley.\n\nArthur Cayley was born in Richmond, London, England, on 16 August 1821. His father, Henry Cayley, was a distant cousin of Sir George Cayley, the aeronautics engineer innovator, and descended from an ancient Yorkshire family. He settled in Saint Petersburg, Russia, as a merchant. His mother was Maria Antonia Doughty, daughter of William Doughty. According to some writers she was Russian, but her father's name indicates an English origin. His brother was the linguist Charles Bagot Cayley. Arthur spent his first eight years in Saint Petersburg. In 1829 his parents were settled permanently at Blackheath, near London. Arthur was sent to a private school. At age 14 he was sent to King's College School. The school's master observed indications of mathematical genius and advised the father to educate his son not for his own business, as he had intended, but to enter the University of Cambridge.\n\nAt the unusually early age of 17 Cayley began residence at Trinity College, Cambridge. The cause of the Analytical Society had now triumphed, and the \"Cambridge Mathematical Journal\" had been instituted by Gregory and Robert Leslie Ellis. To this journal, at the age of twenty, Cayley contributed three papers, on subjects that had been suggested by reading the \"Mécanique analytique\" of Lagrange and some of the works of Laplace.\n\nCayley's tutor at Cambridge was George Peacock and his private coach was William Hopkins. He finished his undergraduate course by winning the place of Senior Wrangler, and the first Smith's prize. His next step was to take the M.A. degree, and win a Fellowship by competitive examination. He continued to reside at Cambridge University for four years; during which time he took some pupils, but his main work was the preparation of 28 memoirs to the \" Mathematical Journal\".\n\nBecause of the limited tenure of his fellowship it was necessary to choose a profession; like De Morgan, Cayley chose law, and at age 25 entered at Lincoln's Inn, London. He made a specialty of conveyancing. It was while he was a pupil at the bar examination that he went to Dublin to hear Hamilton's lectures on quaternions.\n\nHis friend J. J. Sylvester, his senior by five years at Cambridge, was then an actuary, resident in London; they used to walk together round the courts of Lincoln's Inn, discussing the theory of invariants and covariants. During this period of his life, extending over fourteen years, Cayley produced between two and three hundred papers.\n\nAt Cambridge University the ancient professorship of pure mathematics is denominated by the Lucasian, and is the chair that had been occupied by Isaac Newton. Around 1860, certain funds bequeathed by Lady Sadleir to the University, having become useless for their original purpose, were employed to establish another professorship of pure mathematics, called the Sadleirian. The duties of the new professor were defined to be \"to explain and teach the principles of pure mathematics and to apply himself to the advancement of that science.\" To this chair Cayley was elected when 42 years old. He gave up a lucrative practice for a modest salary; but he never regretted the exchange, for the chair at Cambridge enabled him to end the divided allegiance between law and mathematics, and to devote his energies to the pursuit that he liked best. He at once married and settled down in Cambridge. More fortunate than Hamilton in his choice, his home life was one of great happiness. His friend and fellow investigator, Sylvester, once remarked that Cayley had been much more fortunate than himself; that they both lived as bachelors in London, but that Cayley had married and settled down to a quiet and peaceful life at Cambridge; whereas he had never married, and had been fighting the world all his days.\n\nAt first the teaching duty of the Sadleirian professorship was limited to a course of lectures extending over one of the terms of the academic year; but when the University was reformed about 1886, and part of the college funds applied to the better endowment of the University professors, the lectures were extended over two terms. For many years the attendance was small, and came almost entirely from those who had finished their career of preparation for competitive examinations; after the reform the attendance numbered about fifteen. The subject lectured on was generally that of the memoir on which the professor was for the time engaged.\n\nThe other duty of the chair — the advancement of mathematical science — was discharged in a handsome manner by the long series of memoirs that he published, ranging over every department of pure mathematics. But it was also discharged in a much less obtrusive way; he became the standing referee on the merits of mathematical papers to many societies both at home and abroad.\n\nIn 1872 he was made an honorary fellow of Trinity College, and three years later an ordinary fellow, which meant stipend as well as honour. About this time his friends subscribed for a presentation portrait. Maxwell wrote an address to the committee of subscribers who had charge of the Cayley portrait fund. The verses refer to the subjects investigated in several of Cayley's most elaborate memoirs; such as, Chapters on the Analytical Geometry of formula_1 dimensions; On the theory of Determinants; Memoir on the theory of Matrices; Memoirs on skew surfaces, otherwise Scrolls; On the delineation of a Cubic Scroll, etc.\n\nIn addition to his work on algebra, Cayley made fundamental contributions to algebraic geometry. Cayley and Salmon discovered the 27 lines on a cubic surface. Cayley constructed the Chow variety of all curves in projective 3-space. He founded the algebro-geometric theory of ruled surfaces.\n\nIn 1876 he published a \"Treatise on Elliptic Functions\". He took great interest in the movement for the University education of women. At Cambridge the women's colleges are Girton and Newnham. In the early days of Girton College he gave direct help in teaching, and for some years he was chairman of the council of Newnham College, in the progress of which he took the keenest interest to the last.\n\nIn 1881 he received from the Johns Hopkins University, Baltimore, where Sylvester was then professor of mathematics, an invitation\nto deliver a course of lectures. He accepted the invitation, and lectured at Baltimore during the first five months of 1882 on the\nsubject of the \"Abelian and Theta Functions\".\n\nIn 1893 Cayley became a foreign member of the Royal Netherlands Academy of Arts and Sciences.\n\nIn 1883 Cayley was President of the British Association for the Advancement of Science. The meeting was held at Southport, in the north of England. As the President's address is one of the great popular events of the meeting, and brings out an audience of general culture, it is usually made as little technical as possible. took for his subject the Progress of Pure Mathematics.\n\nIn 1889 the Cambridge University Press requested him to prepare his mathematical papers for publication in a collected form—a request which he appreciated very much. They are printed in magnificent quarto volumes, of which seven appeared under his own editorship. While editing these volumes, he was suffering from a painful internal malady, to which he succumbed on 26 January 1895, in the 74th year of his age. When the funeral took place, a great assemblage met in Trinity Chapel, comprising members of the University, official representatives of Russia and America, and many of the most illustrious philosophers of Britain.\n\nThe remainder of his papers were edited by Andrew Forsyth, his successor in the Sadleirian Chair. The Collected Mathematical papers number thirteen quarto volumes, and contain 967 papers. Cayley retained to the last his fondness for novel-reading and for travelling. He also took special pleasure in paintings and architecture, and he practiced water-colour painting, which he found useful sometimes in making mathematical diagrams.\n\nCayley is buried in the Mill Road cemetery, Cambridge.\n\nAn 1874 portrait of Cayley by Lowes Cato Dickinson and an 1884 portrait by William Longmaid are in the collection of Trinity College, Cambridge.\n\nA number of mathematical terms are named after him:\n\n\n\n\n"}
{"id": "4579501", "url": "https://en.wikipedia.org/wiki?curid=4579501", "title": "Australian Mathematical Society Medal", "text": "Australian Mathematical Society Medal\n\nAustralian Mathematical Society Medal recognises distinguished mathematical sciences research by members of the Australian Mathematical Society. Eligibility for the medal include the requirements that the Society member must be under the age of 40 years, and that a significant portion of the research was carried out in Australia. The Medal was first presented in 1981. It is awarded at the opening session of the Society's Annual Meeting.\n\nSource: Australian Mathematical Society\n\n"}
{"id": "13290844", "url": "https://en.wikipedia.org/wiki?curid=13290844", "title": "Bicentric polygon", "text": "Bicentric polygon\n\nIn geometry, a bicentric polygon is a tangential polygon (a polygon all of whose sides are tangent to an inner incircle) which is also cyclic — that is, inscribed in an outer circle that passes through each vertex of the polygon. All triangles and all regular polygons are bicentric. On the other hand, a rectangle with unequal sides is not bicentric, because no circle can be tangent to all four sides.\n\nEvery triangle is bicentric. In a triangle, the radii \"r\" and \"R\" of the incircle and circumcircle respectively are related by the equation\nwhere \"x\" is the distance between the centers of the circles. This is one version of Euler's triangle formula.\n\nNot all quadrilaterals are bicentric (having both an incircle and a circumcircle). Given two circles (one within the other) with radii \"R\" and \"r\" where formula_2, there exists a convex quadrilateral inscribed in one of them and tangent to the other if and only if their radii satisfy\nwhere \"x\" is the distance between their centers. This condition (and analogous conditions for higher order polygons) is known as Fuss' theorem.\n\nA complicated general formula is known for any number \"n\" of sides for the relation among the circumradius \"R\", the inradius \"r\", and the distance \"x\" between the circumcenter and the incenter. Some of these for specific \"n\" are:\n\nwhere formula_7 and formula_8\n\nEvery regular polygon is bicentric. In a regular polygon, the incircle and the circumcircle are concentric—that is, they share a common center, which is also the center of the regular polygon, so the distance between the incenter and circumcenter is always zero. The radius of the inscribed circle is the apothem (the shortest distance from the center to the boundary of the regular polygon).\n\nFor any regular polygon, the relations between the common edge length \"a\", the radius \"r\" of the incircle, and the radius \"R\" of the circumcircle are:\n\nFor some regular polygons which can be constructed with compass and ruler, we have the following algebraic formulas for these relations:\nThus we have the following decimal approximations:\n\nIf two circles are the inscribed and circumscribed circles of a particular bicentric \"n\"-gon, then the same two circles are the inscribed and circumscribed circles of infinitely many bicentric \"n\"-gons. More precisely,\nevery tangent line to the inner of the two circles can be extended to a bicentric \"n\"-gon by placing vertices on the line at the points where it crosses the outer circle, continuing from each vertex along another tangent line, and continuing in the same way until the resulting polygonal chain closes up to an \"n\"-gon. The fact that it will always do so is implied by Poncelet's closure theorem, which more generally applies for inscribed and circumscribed conics.\n\nMoreover, given a circumcircle and incircle, each diagonal of the variable polygon is tangent to a fixed circle. \n"}
{"id": "3364", "url": "https://en.wikipedia.org/wiki?curid=3364", "title": "Bit", "text": "Bit\n\nThe bit (a portmanteau of binary digit) is a basic unit of information used in computing and digital communications. A binary digit can have only one of two values, and may be physically represented with a two-state device. These state values are most commonly represented as either a .\n\nThe two values of a binary digit can also be interpreted as logical values (true/false, yes/no), algebraic signs (+/−), activation states (on/off), or any other two-valued attribute. The correspondence between these values and the physical states of the underlying storage or device is a matter of convention, and different assignments may be used even within the same device or program. The length of a binary number may be referred to as its bit-length.\n\nIn information theory, one bit is typically defined as the information entropy of a binary random variable that is 0 or 1 with equal probability, or the information that is gained when the value of such a variable becomes known.\n\nConfusion often arises because the words bit and binary digit are used interchangeably. But, within Shannon's information theory, a bit and a binary digit are fundamentally different types of entities. A binary digit is a number that can adopt one of two possible values (0 or 1), whereas a bit is the maximum amount of information that can be conveyed by a binary digit (when averaged over both of its states). By analogy, just as a pint-sized bottle can contain between zero and one pint, so a binary digit can convey between zero and one bit of information. A less confusing terminology is to refer to bits as shannons (see below).\n\nIn quantum computing, a \"quantum bit\" or qubit is a quantum system that can exist in superposition of two classical (i.e., non-quantum) bit values; see also two-state quantum system.\n\nThe symbol for binary digit is either simply \"bit\" (recommended by the IEC 80000-13:2008 standard) or lowercase \"b\" (recommended by the IEEE 1541-2002 and IEEE Std 260.1-2004 standards). A group of eight binary digits is commonly called one byte, but historically the size of the byte is not strictly defined.\n\nAs a unit of information in information theory, the bit has alternatively been called a \"shannon\", named after Claude Shannon, the founder of field of information theory. This usage distinguishes the quantity of information from the form of the state variables used to represent it. When the logical values are not equally probable or when a signal is not conveyed perfectly through a communication system, a binary digit in the representation of the information will convey less than one bit of information. However, the shannon unit terminology is uncommon in practice.\n\nThe encoding of data by discrete bits was used in the punched cards invented by Basile Bouchon and Jean-Baptiste Falcon (1732), developed by Joseph Marie Jacquard (1804), and later adopted by Semen Korsakov, Charles Babbage, Hermann Hollerith, and early computer manufacturers like IBM. Another variant of that idea was the perforated paper tape. In all those systems, the medium (card or tape) conceptually carried an array of hole positions; each position could be either punched through or not, thus carrying one bit of information. The encoding of text by bits was also used in Morse code (1844) and early digital communications machines such as teletypes and stock ticker machines (1870).\n\nRalph Hartley suggested the use of a logarithmic measure of information in 1928. Claude E. Shannon first used the word bit in his seminal 1948 paper \"A Mathematical Theory of Communication\".\nHe attributed its origin to John W. Tukey, who had written a Bell Labs memo on 9 January 1947 in which he contracted \"binary information digit\" to simply \"bit\". Vannevar Bush had written in 1936 of \"bits of information\" that could be stored on the punched cards used in the mechanical computers of that time. The first programmable computer, built by Konrad Zuse, used binary notation for numbers.\n\nA bit can be stored by a digital device or other physical system that exists in either of two possible distinct states. These may be the two stable states of a flip-flop, two positions of an electrical switch, two distinct voltage or current levels allowed by a circuit, two distinct levels of light intensity, two directions of magnetization or polarization, the orientation of reversible double stranded DNA, etc.\n\nBits can be implemented in several forms. In most modern computing devices, a bit is usually represented by an electrical voltage or current pulse, or by the electrical state of a flip-flop circuit.\n\nFor devices using positive logic, a digit value of 1 (or a logical value of true) is represented by a more positive voltage relative to the representation of 0. The specific voltages are different for different logic families and variations are permitted to allow for component aging and noise immunity. For example, in transistor–transistor logic (TTL) and compatible circuits, digit values 0 and 1 at the output of a device are represented by no higher than 0.4 volts and no lower than 2.6 volts, respectively; while TTL inputs are specified to recognize 0.8 volts or below as 0 and 2.2 volts or above as 1.\n\nBits are transmitted one at a time in serial transmission, and by a multiple number of bits in parallel transmission. A bitwise operation optionally processes bits one at a time. Data transfer rates are usually measured in decimal SI multiples of the unit bit per second (bit/s), such as kbit/s.\n\nIn the earliest non-electronic information processing devices, such as Jacquard's loom or Babbage's Analytical Engine, a bit was often stored as the position of a mechanical lever or gear, or the presence or absence of a hole at a specific point of a paper card or tape. The first electrical devices for discrete logic (such as elevator and traffic light control circuits, telephone switches, and Konrad Zuse's computer) represented bits as the states of electrical relays which could be either \"open\" or \"closed\". When relays were replaced by vacuum tubes, starting in the 1940s, computer builders experimented with a variety of storage methods, such as pressure pulses traveling down a mercury delay line, charges stored on the inside surface of a cathode-ray tube, or opaque spots printed on glass discs by photolithographic techniques.\n\nIn the 1950s and 1960s, these methods were largely supplanted by magnetic storage devices such as magnetic core memory, magnetic tapes, drums, and disks, where a bit was represented by the polarity of magnetization of a certain area of a ferromagnetic film, or by a change in polarity from one direction to the other. The same principle was later used in the magnetic bubble memory developed in the 1980s, and is still found in various magnetic strip items such as metro tickets and some credit cards.\n\nIn modern semiconductor memory, such as dynamic random-access memory, the two values of a bit may be represented by two levels of electric charge stored in a capacitor. In certain types of programmable logic arrays and read-only memory, a bit may be represented by the presence or absence of a conducting path at a certain point of a circuit. In optical discs, a bit is encoded as the presence or absence of a microscopic pit on a reflective surface. In one-dimensional bar codes, bits are encoded as the thickness of alternating black and white lines.\n\nThe bit is not defined in the International System of Units (SI). However, the International Electrotechnical Commission issued standard IEC 60027, which specifies that the symbol for binary digit should be \"bit\", and this should be used in all multiples, such as \"kbit\", for kilobit. However, the lower-case letter b is widely used as well and was recommended by the IEEE 1541 Standard (2002). In contrast, the upper case letter B is the standard and customary symbol for byte.\n\nMultiple bits may be expressed and represented in several ways. For convenience of representing commonly reoccurring groups of bits in information technology, several units of information have traditionally been used. The most common is the unit byte, coined by Werner Buchholz in June 1956, which historically was used to represent the group of bits used to encode a single character of text (until UTF-8 multibyte encoding took over) in a computer and for this reason it was used as the basic addressable element in many computer architectures. The trend in hardware design converged on the most common implementation of using eight bits per byte, as it is widely used today. However, because of the ambiguity of relying on the underlying hardware design, the unit octet was defined to explicitly denote a sequence of eight bits.\n\nComputers usually manipulate bits in groups of a fixed size, conventionally named \"words\". Like the byte, the number of bits in a word also varies with the hardware design, and is typically between 8 and 80 bits, or even more in some specialized computers. In the 21st century, retail personal or server computers have a word size of 32 or 64 bits.\n\nThe International System of Units defines a series of decimal prefixes for multiples of standardized units which are commonly also used with the bit and the byte. The prefixes kilo (10) through yotta (10) increment by multiples of 1000, and the corresponding units are the kilobit (kbit) through the yottabit (Ybit).\n\nWhen the information capacity of a storage system or a communication channel is presented in \"bits\" or \"bits per second\", this often refers to binary digits, which is a computer hardware capacity to store binary data (0 or 1, up or down, current or not, etc.). Information capacity of a storage system is only an upper bound to the quantity of information stored therein. If the two possible values of one bit of storage are not equally likely, that bit of storage contains less than one bit of information. Indeed, if the value is completely predictable, then the reading of that value provides no information at all (zero entropic bits, because no resolution of uncertainty occurs and therefore no information is available). If a computer file that uses \"n\" bits of storage contains only \"m\" < \"n\" bits of information, then that information can in principle be encoded in about \"m\" bits, at least on the average. This principle is the basis of data compression technology. Using an analogy, the hardware binary digits refer to the amount of storage space available (like the number of buckets available to store things), and the information content the filling, which comes in different levels of granularity (fine or coarse, that is, compressed or uncompressed information). When the granularity is finer—when information is more compressed—the same bucket can hold more.\n\nFor example, it is estimated that the combined technological capacity of the world to store information provides 1,300 exabytes of hardware digits in 2007. However, when this storage space is filled and the corresponding content is optimally compressed, this only represents 295 exabytes of information. When optimally compressed, the resulting carrying capacity approaches Shannon information or information entropy.\n\nCertain bitwise computer processor instructions (such as \"bit set\") operate at the level of manipulating bits rather than manipulating data interpreted as an aggregate of bits.\n\nIn the 1980s, when bitmapped computer displays became popular, some computers provided specialized bit block transfer (\"bitblt\" or \"blit\") instructions to set or copy the bits that corresponded to a given rectangular area on the screen.\n\nIn most computers and programming languages, when a bit within a group of bits, such as a byte or word, is referred to, it is usually specified by a number from 0 upwards corresponding to its position within the byte or word. However, 0 can refer to either the most or least significant bit depending on the context.\n\nSimilar to angular momentum and energy in physics; information-theoretic information and data storage size have the same dimensionality of units of measurement, but there is in general no meaning to adding, subtracting or otherwise combining the units mathematically.\n\nOther units of information, sometimes used in information theory, include the \"natural digit\" also called a \"nat\" or \"nit\" and defined as log \"e\" (≈ 1.443) bits, where \"e\" is the base of the natural logarithms; and the \"dit\", \"ban\", or \"hartley\", defined as log 10 (≈ 3.322) bits. This value, slightly less than 10/3, may be understood because 10 = 1000 ≈ 1024 = 2: three decimal digits are slightly less information than ten binary digits, so one decimal digit is slightly less than 10/3 binary digits. Conversely, one bit of information corresponds to about ln 2 (≈ 0.693) nats, or log 2 (≈ 0.301) hartleys. As with the inverse ratio, this value, approximately 3/10, but slightly more, corresponds to the fact that 2 = 1024 ~ 1000 = 10: ten binary digits are slightly more information than three decimal digits, so one binary digit is slightly more than 3/10 decimal digits. Some authors also define a binit as an arbitrary information unit equivalent to some fixed but unspecified number of bits.\n\n\n"}
{"id": "8907443", "url": "https://en.wikipedia.org/wiki?curid=8907443", "title": "Caccioppoli set", "text": "Caccioppoli set\n\nIn mathematics, a Caccioppoli set is a set whose boundary is measurable and has (at least locally) a \"finite measure\". A synonym is set of (locally) finite perimeter. Basically, a set is a Caccioppoli set if its characteristic function is a function of bounded variation.\n\nThe basic concept of a Caccioppoli set was firstly introduced by the Italian mathematician Renato Caccioppoli in the paper : considering a plane set or a surface defined on an open set in the plane, he defined their measure or area as the total variation in the sense of Tonelli of their defining functions, i.e. of their parametric equations, \"provided this quantity was bounded\". The \"measure of the boundary of a set was defined as a functional\", precisely a set function, for the first time: also, being defined on open sets, it can be defined on all Borel sets and its value can be approximated by the values it takes on an increasing net of subsets. Another clearly stated (and demonstrated) property of this functional was its \"lower semi-continuity\".\n\nIn the paper , he precised by using a \"triangular mesh\" as an increasing net approximating the open domain, defining \"positive and negative variations\" whose sum is the total variation, i.e. the \"area functional\". His inspiring point of view, as he explicitly admitted, was those of Giuseppe Peano, as expressed by the Peano-Jordan Measure: \"to associate to every portion of a surface an oriented plane area in a similar way as an approximating chord is associated to a curve\". Also, another theme found in this theory was the \"extension of a functional\" from a subspace to the whole ambient space: the use of theorems generalizing the Hahn–Banach theorem is frequently encountered in Caccioppoli research. However, the restricted meaning of total variation in the sense of Tonelli added much complication to the formal development of the theory, and the use of a parametric description of the sets restricted its scope.\n\nLamberto Cesari introduced the \"right\" generalization of functions of bounded variation to the case of several variables only in 1936: perhaps, this was one of the reasons that induced Caccioppoli to present an improved version of his theory only nearly 24 years later, in the talk at the IV UMI Congress in October 1951, followed by five notes published in the Rendiconti of the Accademia Nazionale dei Lincei. These notes were sharply criticized by Laurence Chisholm Young in the Mathematical Reviews.\n\nIn 1952 Ennio de Giorgi presented his first results, developing the ideas of Caccioppoli, on the definition of the measure of boundaries of sets at the Salzburg Congress of the Austrian Mathematical Society: he obtained this results by using a smoothing operator, analogous to a mollifier, constructed from the Gaussian function, independently proving some results of Caccioppoli. Probably he was led to study this theory by his teacher and friend Mauro Picone, who had also been the teacher of Caccioppoli and was likewise his friend. De Giorgi met Caccioppoli in 1953 for the first time: during their meeting, Caccioppoli expressed a profound appreciation of his work, starting their lifelong friendship. The same year he published his first paper on the topic i.e. : however, this paper and the closely following one did not attracted much interest from the mathematical community. It was only with the paper , reviewed again by Laurence Chisholm Young in the Mathematical Reviews, that his approach to sets of finite perimeter became widely known and appreciated: also, in the review, Young revised his previous criticism on the work of Caccioppoli.\n\nThe last paper of De Giorgi on the theory of perimeters was published in 1958: in 1959, after the death of Caccioppoli, he started to call sets of finite perimeter \"Caccioppoli sets\". Two years later Herbert Federer and Wendell Fleming published their paper , changing the approach to the theory. Basically they introduced two new kind of currents, respectively normal currents and integral currents: in a subsequent series of papers and in his famous treatise, Federer showed that Caccioppoli sets are normal currents of dimension formula_1 in formula_1-dimensional euclidean spaces. However, even if the theory of Caccioppoli sets can be studied within the framework of theory of currents, it is customary to study it through the \"traditional\" approach using functions of bounded variation, as the various sections found in a lot of important monographs in mathematics and mathematical physics testify.\n\nIn what follows, the definition and properties of functions of bounded variation in the formula_1-dimensional setting will be used.\n\nDefinition 1. Let \"formula_4\" be an open subset of formula_5 and let formula_6 be a Borel set. The \"perimeter of formula_6 in formula_4\" is defined as follows\n\nwhere formula_10 is the characteristic function of formula_6. That is, the perimeter of formula_6 in an open set formula_4 is defined to be the total variation of its characteristic function on that open set. If formula_14, then we write formula_15 for the (global) perimeter.\n\nDefinition 2. The Borel set formula_6 is a Caccioppoli set if and only if it has finite perimeter in every bounded open subset formula_4 of formula_18, i.e.\n\nTherefore, a Caccioppoli set has a characteristic function whose total variation is locally bounded. From the theory of functions of bounded variation it is known that this implies the existence of a vector-valued Radon measure formula_21 such that\n\nAs noted for the case of general functions of bounded variation, this vector measure formula_21 is the distributional or weak gradient of formula_10. The total variation measure associated with formula_21 is denoted by formula_26, i.e. for every open set formula_20 we write formula_28 for formula_29.\n\nIn his papers and , Ennio de Giorgi introduces the following smoothing operator, analogous to the Weierstrass transform in the one-dimensional case\n\nAs one can easily prove, formula_31 is a smooth function for all formula_32, such that\n\nalso, its gradient is everywhere well defined, and so is its absolute value\n\nHaving defined this function, De Giorgi gives the following definition of perimeter:\n\nDefinition 3. Let formula_35 be an open subset of formula_36 and let formula_6 be a Borel set. The \"perimeter of formula_6 in formula_4\" is the value\n\nActually De Giorgi considered the case formula_41: however, the extension to the general case is not difficult. It can be proved that the two definitions are exactly equivalent: for a proof see the already cited De Giorgi's papers or the book . Now having defined what a perimeter is, De Giorgi gives the same definition 2 of what a set of (locally) finite perimeter is.\n\nThe following properties are the ordinary properties which the general notion of a perimeter is supposed to have:\n\n\nFor any given Caccioppoli set formula_56 there exist two naturally associated analytic quantities: the vector-valued Radon measure formula_21 and its total variation measure formula_26. Given that\n\nis the perimeter within any open set formula_4, one should expect that formula_21 alone should somehow account for the perimeter of formula_6.\n\nIt is natural to try to understand the relationship between the objects formula_21, formula_26, and the topological boundary formula_65. There is an elementary lemma that guarantees that the support (in the sense of distributions) of formula_21, and therefore also formula_26, is always contained in formula_65:\n\nLemma. The support of the vector-valued Radon measure formula_21 is a subset of the topological boundary formula_65 of formula_6.\n\nProof. To see this choose formula_72: then formula_73 belongs to the open set formula_74 and this implies that it belongs to an open neighborhood formula_75 contained in the interior of formula_6 or in the interior of formula_77. Let formula_78. If formula_79 where formula_80 is the closure of formula_6, then formula_82 for formula_83 and\n\nLikewise, if formula_85 then formula_86 for formula_83 so\n\nWith formula_89 arbitrary it follows that formula_73 is outside the support of formula_21.\n\nThe topological boundary formula_65 turns out to be too crude for Caccioppoli sets because its Hausdorff measure overcompensates for the perimeter formula_93 defined above. Indeed, the Caccioppoli set\n\nrepresenting a square together with a line segment sticking out on the left has perimeter formula_95, i.e. the extraneous line segment is ignored, while its topological boundary\n\nhas one-dimensional Hausdorff measure formula_97.\n\nThe \"correct\" boundary should therefore be a subset of formula_65. We define:\n\nDefinition 4. The reduced boundary of a Caccioppoli set formula_56 is denoted by formula_100 and is defined to be equal to be the collection of points formula_101 at which the limit:\n\nexists and has length equal to one, i.e. formula_103.\n\nOne can remark that by the Radon-Nikodym Theorem the reduced boundary formula_100 is necessarily contained in the support of formula_21, which in turn is contained in the topological boundary formula_65 as explained in the section above. That is:\n\nThe inclusions above are not necessarily equalities as the previous example shows. In that example, formula_65 is the square with the segment sticking out, formula_109 is the square, and formula_100 is the square without its four corners.\n\nFor convenience, in this section we treat only the case where formula_111, i.e. the set formula_6 has (globally) finite perimeter. De Giorgi's theorem provides geometric intuition for the notion of reduced boundaries and confirms that it is the more natural definition for Caccioppoli sets by showing\n\ni.e. that its Hausdorff measure equals the perimeter of the set. The statement of the theorem is quite long because it interrelates various geometric notions in one fell swoop.\n\nTheorem. Suppose formula_114 is a Caccioppoli set. Then at each point formula_101 of the reduced boundary formula_100 there exists a multiplicity one approximate tangent space formula_117 of formula_26, i.e. a codimension-1 subspace formula_117 of formula_120 such that\n\nfor every continuous, compactly supported formula_122. In fact the subspace formula_117 is the orthogonal complement of the unit vector\n\ndefined previously. This unit vector also satisfies\n\nlocally in formula_126, so it is interpreted as an approximate inward pointing unit normal vector to the reduced boundary formula_100. Finally, formula_100 is (n-1)-rectifiable and the restriction of (n-1)-dimensional Hausdorff measure formula_129 to formula_100 is formula_26, i.e.\n\nIn other words, up to formula_129-measure zero the reduced boundary formula_100 is the smallest set on which formula_21 is supported.\n\nFrom the definition of the vector Radon measure formula_21 and from the properties of the perimeter, the following formula holds true:\n\nThis is one version of the divergence theorem for domains with non smooth boundary. De Giorgi's theorem can be used to formulate the same identity in terms of the reduced boundary formula_100 and the approximate inward pointing unit normal vector formula_140. Precisely, the following equality holds\n\n\n"}
{"id": "33664739", "url": "https://en.wikipedia.org/wiki?curid=33664739", "title": "Centre for Nanoscience and Quantum Information", "text": "Centre for Nanoscience and Quantum Information\n\nThe Centre for Nanoscience and Quantum Information (informally, NSQI) is a research centre within the University of Bristol. The centre was initially built as an intra-university facility, but was absorbed into the portfolio of the School of Physics in 2016. The centre officially opened in 2009, the Centre was designed to provide a unique ultra-low-vibration research space, making the labs some of the quietest in the world.\n\nThe building is split across four floors:\n\n\nThe building was designed by Percy Thomas of Capita Architecture, in 2004 and built by Willmott Dixon. The primary requirement for the building was that it be a low-noise research environment, stable enough to allow researchers to take measurements at subnanometre and subnanoNewton resolution, despite other activities going on around them. The criteria set for the research space exceeded any standard curve (VC curves) and required significant design and engineering solutions.\n\nThe primary source of noise for researchers at the nanoscale is mechanical vibration. Activities within a building generate noise that can travel through the structure and vibrations created outside (such as from road traffic) can travel through the ground and enter the building. A variety of methods were employed to reduce vibration generation, travel and entry into the lab space:\n\n\nAcoustic noise within the building is countered through several measures. Most importantly, experimental rooms are far from the busy University precinct, underground and in an area that is not used for teaching, or as a thoroughfare. The thickness of the floor ensures that little sound penetrates across and the walls between labs and doors of the labs are soundproof. The plant machinery is removed as far from the labs as possible, on the top floor, and the services are tuned as precisely as possible to reduce any sounds from the water supply, chilled water system or air vents.\n\nMany of the experiments planned for the Centre involve recording tiny electrical currents (as low as a few picoAmps) so electrical noise is seen as a serious problem. Each basement research lab is a full Faraday cage, all service pipework changes to plastic before entering the lab and no Category 5 cable (cat5e) is used in data network, optical fibre is used instead. All labs are also supplied with an independent earth and 'clean' power supply, the mains having been filtered by a 1:1 transformer.\n\nIn addition to providing state-of-the-art low noise spaces, the building is also designed to encourage collaboration and interdisciplinary research. This includes plenty of meeting spaces and a light & spacious foyer/coffee area.\n\n"}
{"id": "5380409", "url": "https://en.wikipedia.org/wiki?curid=5380409", "title": "Centrolinead", "text": "Centrolinead\n\nThe centrolinead was invented by Peter Nicholson, a British mathematician and architect, in 1814. It was used to construct 2-point perspective drawings where one or both vanishing points existed outside the drawing board. Draftsmen could use the instrument in pairs; one for each vanishing point on each side of the station point.\n\nCentrolineads were produced in various sizes. Typically a brass fitting clamped the wooden arms together. Fittings were produced in both right and left-handed configuration, and certain adjustable designs could be used on either side.\n\nTwo short arms are set to form 90 degree angles against a third, longer drawing edge. Pins are placed near the edges of the drawing surface and serve as pivots for the arms. Pin placement is equidistant and symmetric across the horizontal line. A third centrolinead could be used to construct 3-point perspective.\n\nThe diagram shown above does not represent the centrolinead designed by Nicholson.\n\n\n"}
{"id": "46561894", "url": "https://en.wikipedia.org/wiki?curid=46561894", "title": "Continuous or discrete variable", "text": "Continuous or discrete variable\n\nIn mathematics, a variable may be continuous or discrete. If it can take on two particular real values such that it can also take on all real values between them (even values that are arbitrarily close together), the variable is continuous in that interval. If it can take on a value such that there is a non-infinitesimal gap on each side of it containing no values that the variable can take on, then it is discrete around that value. In some contexts a variable can be discrete in some ranges of the number line and continuous in others.\n\nA continuous variable is one which can take on infinitely many, uncountable values.\n\nFor example, a variable over a non-empty range of the real numbers is continuous, if it can take on any value in that range. The reason is that any range of real numbers between formula_1 and formula_2 with formula_3 is infinite and uncountable.\n\nMethods of calculus are often used in problems in which the variables are continuous, for example in continuous optimization problems.\n\nIn statistical theory, the probability distributions of continuous variables can be expressed in terms of probability density functions.\n\nIn continuous-time dynamics, the variable \"time\" is treated as continuous, and the equation describing the evolution of some variable over time is a differential equation. The instantaneous rate of change is a well-defined concept.\n\nIn contrast, a discrete variable over a particular range of real values is one for which, for any value in the range that the variable is permitted to take on, there is a positive minimum distance to the nearest other permissible value. The number of permitted values is either finite or countably infinite. Common examples are variables that must be integers, non-negative integers, positive integers, or only the integers 0 and 1.\n\nMethods of calculus do not readily lend themselves to problems involving discrete variables. Examples of problems involving discrete variables include integer programming.\n\nIn statistics, the probability distributions of discrete variables can be expressed in terms of probability mass functions.\n\nIn discrete time dynamics, the variable \"time\" is treated as discrete, and the equation of evolution of some variable over time is called a difference equation.\n\nIn econometrics and more generally in regression analysis, sometimes some of the variables being empirically related to each other are 0-1 variables, being permitted to take on only those two values. A variable of this type is called a dummy variable. If the dependent variable is a dummy variable, then logistic regression or probit regression is commonly employed.\n"}
{"id": "3097058", "url": "https://en.wikipedia.org/wiki?curid=3097058", "title": "Croatian Interdisciplinary Society", "text": "Croatian Interdisciplinary Society\n\nCroatian Interdisciplinary Society (, abbrev. \"HID\") is a non-governmental organization operating in Croatia. It acts to promote interdisciplinary education and research, primarily but not exclusively in the domain of complex systems. They are a member society of the International Federation for Systems Research.\n\n\n"}
{"id": "471245", "url": "https://en.wikipedia.org/wiki?curid=471245", "title": "Cryptographie indéchiffrable", "text": "Cryptographie indéchiffrable\n\nCryptographie indéchiffrable (subtitle: \"basée sur de nouvelles combinaisons rationelles\") is a French book on cryptography written by Émile Victor Théodore Myszkowski (a retired French colonel) and published in 1902.\n\nHis book described a cipher that the author had invented and claimed (incorrectly) was \"undecipherable\" (i.e. secure against unauthorised attempts to read it). It was based on a form of repeated-key transposition.\n\n"}
{"id": "21907908", "url": "https://en.wikipedia.org/wiki?curid=21907908", "title": "Danny Calegari", "text": "Danny Calegari\n\nDanny M. C. Calegari (born 24 May 1972) is an Australian-American mathematician who is currently a Professor at the University of Chicago. His research interests include geometry, dynamical systems, low-dimensional topology, and geometric group theory. Calegari was one of the recipients of the 2009 Clay Research Award for his solution to the Marden Tameness Conjecture and the Ahlfors Measure Conjecture.\n\nIn 1994, Calegari received a B.A. in Mathematics from the University of Melbourne with honors. He received his Ph.D. in 2000 from the University of California, Berkeley under the joint supervision of Andrew Casson and William Thurston; his dissertation concerned foliations of three-dimensional manifolds.\n\nFrom 2000–2002 he was Benjamin Peirce Assistant Professor at Harvard University, after which he joined the California Institute of Technology faculty; he became Merkin Professor in 2007. He was a University Professor of Pure Mathematics at the University of Cambridge in 2011–2012, and has been a Professor of Mathematics at the University of Chicago since 2012. In 2012, he became a fellow of the American Mathematical Society.\n\nCalegari is also an author of short fiction, published in \"Quadrant\", \"Southerly\", and \"Overland\". His story \"A Green Light\" was a winner of a 1992 The Age Short Story Award.\n\n\n"}
{"id": "1532860", "url": "https://en.wikipedia.org/wiki?curid=1532860", "title": "E. H. Moore", "text": "E. H. Moore\n\nEliakim Hastings Moore (; January 26, 1862 – December 30, 1932), usually cited as E. H. Moore or E. Hastings Moore, was an American mathematician.\n\nMoore, the son of a Methodist minister and grandson of US Congressman Eliakim H. Moore, discovered mathematics through a summer job at the Cincinnati Observatory while in high school. He learned mathematics at Yale University, where he was a member of Skull and Bones and obtained a B.A. in 1883 and the Ph.D. in 1885 with a thesis, supervised by Hubert Anson Newton, on some work of William Kingdon Clifford and Arthur Cayley. Newton encouraged Moore to study in Germany, and thus he spent an academic year at the University of Berlin, attending lectures by Leopold Kronecker and Karl Weierstrass.\n\nOn his return to the United States, Moore taught at Yale and at Northwestern University. When the University of Chicago opened its doors in 1892, Moore was the first head of its mathematics department, a position he retained until his death in 1931. His first two colleagues were Oskar Bolza and Heinrich Maschke. The resulting department was the second research-oriented mathematics department in American history, after Johns Hopkins University. \n\nMoore first worked in abstract algebra, proving in 1893 the classification of the structure of finite fields (also called Galois fields). Around 1900, he began working on the foundations of geometry. He reformulated Hilbert's axioms for geometry so that points were the only primitive notion, thus turning David Hilbert's primitive lines and planes into defined notions. In 1902, he further showed that one of Hilbert's axioms for geometry was redundant. Independently, during a course taught by G. B. Halsted, the twenty-year-old R.L. Moore (no relation) also proved this, but in a more elegant fashion than E. H. Moore used. When E. H. Moore heard of the feat, he arranged for a scholarship that would allow R.L. Moore to study for a doctorate at Chicago. E.H. Moore's work on axiom systems is considered one of the starting points for metamathematics and model theory. After 1906, he turned to the foundations of analysis. The concept of a closure operator first appeared in his 1910 \"Introduction to a form of general analysis\". He also wrote on algebraic geometry, number theory, and integral equations.\n\nAt Chicago, Moore supervised 31 doctoral dissertations, including those of George Birkhoff, Leonard Dickson, Robert Lee Moore (no relation), and Oswald Veblen. Birkhoff and Veblen went on to lead departments at Harvard and Princeton, respectively. Dickson became the first great American algebraist and number theorist. Robert Moore founded American topology. According to the Mathematics Genealogy Project, as of December 2012, E. H. Moore had over 18,900 known \"descendants.\"\n\nMoore convinced the New York Mathematical Society to change its name to the American Mathematical Society, whose Chicago branch he led. He presided over the AMS, 1901–02, and edited the \"Transactions of the American Mathematical Society\", 1899–1907. He was elected to the National Academy of Sciences, the American Academy of Arts and Sciences, and the American Philosophical Society. He was an Invited Speaker at the ICM in 1908 in Rome and in 1912 in Cambridge, England.\n\nThe American Mathematical Society established a prize in his honor in 2002.\n\n\n\n"}
{"id": "1270458", "url": "https://en.wikipedia.org/wiki?curid=1270458", "title": "Eisenstein series", "text": "Eisenstein series\n\nEisenstein series, named after German mathematician Gotthold Eisenstein, are particular modular forms with infinite series expansions that may be written down directly. Originally defined for the modular group, Eisenstein series can be generalized in the theory of automorphic forms.\n\nLet be a complex number with strictly positive imaginary part. Define the holomorphic Eisenstein series of weight , where is an integer, by the following series:\n\nThis series absolutely converges to a holomorphic function of in the upper half-plane and its Fourier expansion given below shows that it extends to a holomorphic function at . It is a remarkable fact that the Eisenstein series is a modular form. Indeed, the key property is its -invariance. Explicitly if and then\n\n&= \\sum_{(m,n) \\in \\Z^2 \\setminus (0,0)} \\frac{(c\\tau+d)^{2k}}{(md+nb+(mc+na)\\tau)^{2k}} \\\\\n\\end{align}</math>\n\nIf then\nso that\nis a bijection , i.e.:\n\nOverall, if then\n\nand is therefore a modular form of weight . Note that it is important to assume that , otherwise it would be illegitimate to change the order of summation, and the -invariance would not hold. In fact, there are no nontrivial modular forms of weight 2. Nevertheless, an analogue of the holomorphic Eisenstein series can be defined even for , although it would only be a quasimodular form.\n\nThe modular invariants and of an elliptic curve are given by the first two Eisenstein series:\n\nThe article on modular invariants provides expressions for these two functions in terms of theta functions.\n\nAny holomorphic modular form for the modular group can be written as a polynomial in and . Specifically, the higher order can be written in terms of and through a recurrence relation. Let , so for example, and . Then the satisfy the relation\n\nfor all . Here, is the binomial coefficient.\n\nThe occur in the series expansion for the Weierstrass's elliptic functions:\n\nDefine . (Some older books define to be the nome , but is now standard in number theory.) Then the Fourier series of the Eisenstein series is\n\nwhere the coefficients are given by\n\nHere, are the Bernoulli numbers, is Riemann's zeta function and is the divisor sum function, the sum of the th powers of the divisors of . In particular, one has\n\nThe summation over can be resummed as a Lambert series; that is, one has\n\nfor arbitrary complex and . When working with the -expansion of the Eisenstein series, this alternate notation is frequently introduced:\n\nGiven , let\n\nand define\n\nwhere and are alternative notations for the Jacobi theta functions. Then,\n\nthus,\n\nan expression related to the modular discriminant,\n\nAlso, since and , this implies\n\nEisenstein series form the most explicit examples of modular forms for the full modular group . Since the space of modular forms of weight has dimension 1 for , different products of Eisenstein series having those weights have to be equal up to a scalar multiple. In fact, we obtain the identities:\n\nUsing the -expansions of the Eisenstein series given above, they may be restated as identities involving the sums of powers of divisors:\n\nhence\n\nand similarly for the others. The theta function of an eight-dimensional even unimodular lattice is a modular form of weight 4 for the full modular group, which gives the following identities:\n\nfor the number of vectors of the squared length in the root lattice of the type.\n\nSimilar techniques involving holomorphic Eisenstein series twisted by a Dirichlet character produce formulas for the number of representations of a positive integer ' as a sum of two, four, or eight squares in terms of the divisors of .\n\nUsing the above recurrence relation, all higher can be expressed as polynomials in and . For example:\n\nMany relationships between products of Eisenstein series can be written in an elegant way using Hankel determinants, e.g. Garvan's identity\n\nwhere\n\nis the modular discriminant.\n\nSrinivasa Ramanujan gave several interesting identities between the first few Eisenstein series involving differentiation. Let\n\nthen\n\nThese identities, like the identities between the series, yield arithmetical convolution identities involving the sum-of-divisor function. Following Ramanujan, to put these identities in the simplest form it is necessary to extend the domain of to include zero, by setting\n\nThen, for example\n\nOther identities of this type, but not directly related to the preceding relations between , and functions, have been proved by Ramanujan and Giuseppe Melfi, as for example\n\nAutomorphic forms generalize the idea of modular forms for general Lie groups; and Eisenstein series generalize in a similar fashion.\n\nDefining to be the ring of integers of a totally real algebraic number field , one then defines the Hilbert–Blumenthal modular group as . One can then associate an Eisenstein series to every cusp of the Hilbert–Blumenthal modular group.\n\n"}
{"id": "8919339", "url": "https://en.wikipedia.org/wiki?curid=8919339", "title": "Environmental statistics", "text": "Environmental statistics\n\nEnvironment statistics is the application of statistical methods to environmental science. It covers procedures for dealing with questions concerning both the natural environment in its undisturbed state and the interaction of humanity with the environment. Thus weather, climate, air and water quality are included, as are studies of plant and animal populations.\n\nThe United Nations Framework for the Development of Environment Statistics (FDES) defines the scope of environment statistics as follows:\nThe scope of environment statistics covers biophysical aspects of the environment and those aspects of the socio-economic system that directly influence and interact with the environment.\nThe scope of environment, social and economic statistics overlap. It is not easy – or necessary – to draw a clear line dividing these areas. Social and economic statistics that describe processes or activities with a direct impact on, or direct interaction with, the environment are used widely in environment statistics. They are within the scope of the FDES.\n\nSources of data for environmental statistics are varied and include: surveys related to human populations and the environment, records from agencies managing environmental resources, maps and images, equipment used to examine the environment, and research studies around the world. A primary component of the data is direct observation, although most environmental statistics use a variety of sources.\n\nEnvironmental statistics covers a number of types of study:\n\n"}
{"id": "460642", "url": "https://en.wikipedia.org/wiki?curid=460642", "title": "Equicontinuity", "text": "Equicontinuity\n\nIn mathematical analysis, a family of functions is equicontinuous if all the functions are continuous and they have equal variation over a given neighbourhood, in a precise sense described herein. In particular, the concept applies to countable families, and thus \"sequences\" of functions.\n\nEquicontinuity appears in the formulation of Ascoli's theorem, which states that a subset of \"C\"(\"X\"), the space of continuous functions on a compact Hausdorff space \"X\", is compact if and only if it is closed, pointwise bounded and equicontinuous. As a corollary, a sequence in \"C\"(\"X\") is uniformly convergent if and only if it is equicontinuous and converges pointwise to a function (not necessarily continuous a-priori). In particular, the limit of an equicontinuous pointwise convergent sequence of continuous functions \"f\" on either metric space or locally compact space is continuous. If, in addition, \"f\" are holomorphic, then the limit is also holomorphic.\n\nThe uniform boundedness principle states that a pointwise bounded family of continuous linear operators between Banach spaces is equicontinuous.\n\nLet \"X\" and \"Y\" be two metric spaces, and \"F\" a family of functions from \"X\" to \"Y\". We shall denote by \"d\" the respective metrics of these spaces.\n\nThe family \"F\" is equicontinuous at a point \"x\" ∈ \"X\" if for every ε > 0, there exists a  δ > 0 such that \"d\"(\"ƒ\"(\"x\"), \"ƒ\"(\"x\")) < ε for all \"ƒ\" ∈ \"F\" and all \"x\" such that \"d\"(\"x\", \"x\") < δ. The family is pointwise equicontinuous if it is equicontinuous at each point of \"X\".\n\nThe family \"F\" is uniformly equicontinuous if for every ε > 0, there exists a δ > 0 such that \"d\"(\"ƒ\"(\"x\"), \"ƒ\"(\"x\")) < ε for all \"ƒ\" ∈ \"F\" and all \"x\", \"x\" ∈ \"X\" such that \"d\"(\"x\", \"x\") < δ.\n\nFor comparison, the statement 'all functions \"ƒ\" in \"F\" are continuous' means that for every ε > 0, every \"ƒ\" ∈ \"F\", and every \"x\" ∈ \"X\", there exists a δ > 0 such that \"d\"(\"ƒ\"(\"x\"), \"ƒ\"(\"x\")) < ε for all \"x\" ∈ \"X\" such that \"d\"(\"x\", \"x\") < δ.\n\n\nMore generally, when \"X\" is a topological space, a set \"F\" of functions from \"X\" to \"Y\" is said to be equicontinuous at \"x\" if for every ε > 0, \"x\" has a neighborhood \"U\" such that\nfor all and \"ƒ\" ∈ \"F\". This definition usually appears in the context of topological vector spaces.\n\nWhen \"X\" is compact, a set is uniformly equicontinuous if and only if it is equicontinuous at every point, for essentially the same reason as that uniform continuity and continuity coincide on compact spaces. Used on its own, the term \"equiconituity\" may refer to either the pointwise or uniform notion, depending on the context. On a compact space, these notions coincide.\n\nSome basic properties follow immediately from the definition. Every finite set of continuous functions is equicontinuous. The closure of an equicontinuous set is again equicontinuous. Every member of a uniformly equicontinuous set of functions is uniformly continuous, and every finite set of uniformly continuous functions is uniformly equicontinuous.\n\n\n\nLet \"X\" be a compact Hausdorff space, and equip \"C\"(\"X\") with the uniform norm, thus making \"C\"(\"X\") a Banach space, hence a metric space. Then Arzelà–Ascoli theorem states that a subset of \"C\"(\"X\") is compact if and only if it is closed, uniformly bounded and equicontinuous. This is analogous to the Heine–Borel theorem, which states that subsets of R are compact if and only if they are closed and bounded. As a corollary, every uniformly bounded equicontinuous sequence in \"C\"(\"X\") contains a subsequence that converges uniformly to a continuous function on \"X\".\n\nIn view of Arzelà–Ascoli theorem, a sequence in \"C\"(\"X\") converges uniformly if and only if it is equicontinuous and converges pointwise. The hypothesis of the statement can be weakened a bit: a sequence in \"C\"(\"X\") converges uniformly if it is equicontinuous and converges pointwise on a dense subset to some function on \"X\" (not assumed continuous). This weaker version is typically used to prove Arzelà–Ascoli theorem for separable compact spaces. Another consequence is that the limit of an equicontinuous pointwise convergent sequence of continuous functions on a metric space, or on a locally compact space, is continuous. (See below for an example.) In the above, the hypothesis of compactness of \"X\"  cannot be relaxed. To see that, consider a compactly supported continuous function \"g\" on R with \"g\"(0) = 1, and consider the equicontinuous sequence of functions on R defined by \"ƒ\"(\"x\") = . Then, \"ƒ\" converges pointwise to 0 but does not converge uniformly to 0.\n\nThis criterion for uniform convergence is often useful in real and complex analysis. Suppose we are given a sequence of continuous functions that converges pointwise on some open subset \"G\" of R. As noted above, it actually converges uniformly on a compact subset of \"G\" if it is equicontinuous on the compact set. In practice, showing the equicontinuity is often not so difficult. For example, if the sequence consists of differentiable functions or functions with some regularity (e.g., the functions are solutions of a differential equation), then the mean value theorem or some other kinds of estimates can be used to show the sequence is equicontinuous. It then follows that the limit of the sequence is continuous on every compact subset of \"G\"; thus, continuous on \"G\". A similar argument can be made when the functions are holomorphic. One can use, for instance, Cauchy's estimate to show the equicontinuity (on a compact subset) and conclude that the limit is holomorphic. Note that the equicontinuity is essential here. For example, \"ƒ\"(\"x\") = converges to a multiple of the discontinuous sign function.\n\nLet \"E\", \"F\" be Banach spaces, and Γ be a family of continuous linear operators from \"E\" into \"F\". Then Γ is equicontinuous if and only if\nthat is, Γ is uniformly bounded in operator norm. Also, by linearity, Γ is uniformly equicontinuous if and only if it is equicontinuous at 0.\n\nThe uniform boundedness principle (also known as the Banach–Steinhaus theorem) states that Γ is equicontinuous if it is pointwise bounded; i.e., for each . The result can be generalized to a case when F is locally convex and E is a barreled space.\n\nAlaoglu's theorem states that if \"E\" is a topological vector space, then every equicontinuous subset of \"E*\" is weak-* relatively compact.\n\nThe most general scenario in which equicontinuity can be defined is for topological spaces whereas \"uniform\" equicontinuity requires the filter of neighbourhoods of one point to be somehow comparable with the filter of neighbourhood of another point. The latter is most generally done via a uniform structure, giving a uniform space. Appropriate definitions in these cases are as follows:\n\nA weaker concept is that of even continuity:\n\nFor metric spaces, there are standard topologies and uniform structures derived from the metrics, and then these general definitions are equivalent to the metric-space definitions.\n\nStochastic equicontinuity is a version of equicontinuity used in the context of sequences of functions of random variables, and their convergence.\n\n"}
{"id": "21644788", "url": "https://en.wikipedia.org/wiki?curid=21644788", "title": "Fence (mathematics)", "text": "Fence (mathematics)\n\nIn mathematics, a fence, also called a zigzag poset, is a partially ordered set in which the order relations form a path with alternating orientations:\nor\nA fence may be finite, or it may be formed by an infinite alternating sequence extending in both directions. The incidence posets of path graphs form examples of fences.\n\nA linear extension of a fence is called an alternating permutation; André's problem of counting the number of different linear extensions has been studied since the 19th century. The solutions to this counting problem, the so-called Euler zigzag numbers or up/down numbers, are\n\nThe number of antichains in a fence is a Fibonacci number; the distributive lattice with this many elements, generated from a fence via Birkhoff's representation theorem, has as its graph the Fibonacci cube.\n\nA partially ordered set is series-parallel if and only if it does not have four elements forming a fence.\n\nSeveral authors have also investigated the number of order-preserving maps from fences to themselves, or to fences of other sizes.\n\nAn up-down poset \"Q\"(\"a\",\"b\") is a generalization of a zigzag poset in which there are \"a\" downward orientations for every upward one and \"b\" total elements. For instance, \"Q\"(2,9) has the elements and relations\nIn this notation, a fence is a partially ordered set of the form \"Q\"(1,\"n\").\n\nThe following conditions are equivalent for a poset \"P\":\n\nThe prime ideals of a commutative ring \"R\", ordered by inclusion, satisfy the equivalent conditions above if and only if \"R\" has Krull dimension at most one.\n\n"}
{"id": "59046614", "url": "https://en.wikipedia.org/wiki?curid=59046614", "title": "Forder Lectureship", "text": "Forder Lectureship\n\nThe Forder Lectureship is awarded by the London Mathematical Society to a research mathematician from the United Kingdom who has made an eminent contribution to the field of mathematics and who can also speak effectively at a more popular level. The lectureship is named for Professor H.G. Forder, formerly of the University of Auckland, and a benefactor of the London Mathematical Society. The lectureship was established in 1986 by the London Mathematical Society and the New Zealand Mathematical Society, and is normally awarded every two years. Recipients of the lectureship will give a four- to six-week lecturing tour of most New Zealand universities.\n\nThe recipients of the Forder Lectureship are:\n\n"}
{"id": "20751649", "url": "https://en.wikipedia.org/wiki?curid=20751649", "title": "Geometriae Dedicata", "text": "Geometriae Dedicata\n\nGeometriae Dedicata is a mathematical journal, founded in 1972, concentrating on geometry and its relationship to topology, group theory and the theory of dynamical systems. It was created on the initiative of Hans Freudenthal in Utrecht, the Netherlands. It is published by Springer Netherlands. The Editors-in-Chief are John R. Parker and Jean-Marc Schlenker.\n\n"}
{"id": "4426801", "url": "https://en.wikipedia.org/wiki?curid=4426801", "title": "Gross (unit)", "text": "Gross (unit)\n\nIn English and related languages, several terms involving the words \"great\" or \"gross\" (possibly, from thick) relate to numbers involving multiples of exponents of twelve (dozen):\nEarly 15c., from Old French grosse douzaine \"large dozen.\" \n\nA gross may be abbreviated as \"gr\" or \"gro\".\n\nThe continued use of these numbers in measurement and counting represents a continuation of the tradition of the duodecimal number system in everyday life and has encouraged groups such as the Dozenal Society of America to advocate for a wider use of such a numbering system in place of decimal.\n"}
{"id": "8529655", "url": "https://en.wikipedia.org/wiki?curid=8529655", "title": "Hilbert system", "text": "Hilbert system\n\nIn logic, especially mathematical logic, a Hilbert system, sometimes called Hilbert calculus, Hilbert-style deductive system or Hilbert–Ackermann system, is a type of system of formal deduction attributed to Gottlob Frege and David Hilbert. These deductive systems are most often studied for first-order logic, but are of interest for other logics as well.\n\nMost variants of Hilbert systems take a characteristic tack in the way they balance a trade-off between logical axioms and rules of inference. Hilbert systems can be characterised by the choice of a large number of schemes of logical axioms and a small set of rules of inference. Systems of natural deduction take the opposite tack, including many deduction rules but very few or no axiom schemes. The most commonly studied Hilbert systems have either just one rule of inference modus ponens, for propositional logics or two with generalisation, to handle predicate logics, as well and several infinite axiom schemes. Hilbert systems for propositional modal logics, sometimes called Hilbert-Lewis systems, are generally axiomatised with two additional rules, the necessitation rule and the uniform substitution rule.\n\nA characteristic feature of the many variants of Hilbert systems is that the \"context\" is not changed in any of their rules of inference, while both natural deduction and sequent calculus contain some context-changing rules. Thus, if we are interested only in the derivability of tautologies, no hypothetical judgments, then we can formalize the Hilbert system in such a way that its rules of inference contain only judgments of a rather simple form. The same cannot be done with the other two deductions systems: as context is changed in some of their rules of inferences, they cannot be formalized so that hypothetical judgments could be avoided not even if we want to use them just for proving derivability of tautologies.\n\nIn a Hilbert-style deduction system, a formal deduction is a finite sequence of formulas in which each formula is either an axiom or is obtained from previous formulas by a rule of inference. These formal deductions are meant to mirror natural-language proofs, although they are far more detailed.\n\nSuppose formula_1 is a set of formulas, considered as hypotheses. For example, formula_1 could be a set of axioms for group theory or set theory. The notation formula_3 means that there is a deduction that ends with formula_4 using as axioms only logical axioms and elements of formula_1. Thus, informally, formula_3 means that formula_4 is provable assuming all the formulas in formula_1.\n\nHilbert-style deduction systems are characterized by the use of numerous schemes of logical axioms. An axiom scheme is an infinite set of axioms obtained by substituting all formulas of some form into a specific pattern. The set of logical axioms includes not only those axioms generated from this pattern, but also any generalization of one of those axioms. A generalization of a formula is obtained by prefixing zero or more universal quantifiers on the formula; thus\n\nis a generalization of formula_10.\n\nThere are several variant axiomatisations of predicate logic, since for any logic there is freedom in choosing axioms and rules that characterise that logic. We describe here a Hilbert system with nine axioms and just the rule modus ponens, which we call the one-rule axiomatisation and which describes classical equational logic. We deal with a minimal language for this logic, where formulas use only the connectives formula_11 and formula_12 and only the quantifier formula_13. Later we show how the system can be extended to include additional logical connectives, such as formula_14 and formula_15, without enlarging the class of deducible formulas.\n\nThe first four logical axiom schemes allow (together with modus ponens) for the manipulation of logical connectives.\n\nThe axiom P1 is redundant, as it follows from P3, P2 and modus ponens. These axioms describe classical propositional logic; without axiom P4 we get positive implicational logic. Minimal logic is achieved either by adding instead the axiom P4m, or by defining formula_20 as formula_21.\n\nIntuitionistic logic is achieved by adding axioms P4i and P5i to positive implicational logic, or by adding axiom P5i to minimal logic. Both P4i and P5i are theorems of classical propositional logic.\n\nNote that these are axiom schemes, which represent infinitely many specific instances of axioms. For example, P1 might represent the particular axiom instance formula_25, or it might represent formula_26: the formula_4 is a place where any formula can be placed. A variable such as this that ranges over formulae is called a 'schematic variable'.\n\nWith a second rule of uniform substitution (US), we can change each of these axiom schemes into a single axiom, replacing each schematic variable by some propositional variable that isn't mentioned in any axiom to get what we call the substitutional axiomatisation. Both formalisations have variables, but where the one-rule axiomatisation has schematic variables that are outside the logic's language, the substitutional axiomatisation uses propositional variables that do the same work by expressing the idea of a variable ranging over formulae with a rule that uses substitution.\n\nThe next three logical axiom schemes provide ways to add, manipulate, and remove universal quantifiers.\n\nThese three additional rules extend the propositional system to axiomatise classical predicate logic. Likewise, these three rules extend system for intuitionstic propositional logic (with P1-3 and P4i and P5i) to intuitionistic predicate logic.\n\nUniversal quantification is often given an alternative axiomatisation using an extra rule of generalisation (see the section on Metatheorems), in which case the rules Q6 and Q7 are redundant.\n\nThe final axiom schemes are required to work with formulas involving the equality symbol.\n\nIt is common to include in a Hilbert-style deduction system only axioms for implication and negation. Given these axioms, it is possible to form conservative extensions of the deduction theorem that permit the use of additional connectives. These extensions are called conservative because if a formula φ involving new connectives is rewritten as a logically equivalent formula θ involving only negation, implication, and universal quantification, then φ is derivable in the extended system if and only if θ is derivable in the original system. When fully extended, a Hilbert-style system will resemble more closely a system of natural deduction.\n\n\n\n\nBecause Hilbert-style systems have very few deduction rules, it is common to prove metatheorems that show that additional deduction rules add no deductive power, in the sense that a deduction using the new deduction rules can be converted into a deduction using only the original deduction rules.\n\nSome common metatheorems of this form are:\n\n\nThe axiom 3 above is credited to Łukasiewicz. The original system by Frege had axioms P2 and P3 but four other axioms instead of axiom P4 (see Frege's propositional calculus).\nRussell and Whitehead also suggested a system with five propositional axioms.\n\nAxioms P1, P2 and P3, with the deduction rule modus ponens (formalising intuitionistic propositional logic), correspond to combinatory logic base combinators I, K and S with the application operator. Proofs in the Hilbert system then correspond to combinator terms in combinatory logic. See also Curry–Howard correspondence.\n\n\n\n"}
{"id": "28769399", "url": "https://en.wikipedia.org/wiki?curid=28769399", "title": "Identity line", "text": "Identity line\n\nIn a 2-dimensional Cartesian coordinate system, with \"x\" representing the abscissa and \"y\" the ordinate, the identity line or line of equality is the \"y\" = \"x\" line. The line, sometimes called the 1:1 line, has a slope of 1. When the abscissa and ordinate are on the same scale, the identity line forms a 45° angle with the abscissa, and is thus also, informally, called the 45° line. The line is often used as a reference in a 2-dimensional scatter plot comparing two sets of data expected to be identical under ideal conditions. When the corresponding data points from the two data sets are equal to each other, the corresponding scatters fall exactly on the identity line.\n\nIn economics, an identity line is used in the Keynesian cross diagram to identify equilibrium, as only on the identity line does aggregate demand equal aggregate supply.\n"}
{"id": "31981806", "url": "https://en.wikipedia.org/wiki?curid=31981806", "title": "Integral of the secant function", "text": "Integral of the secant function\n\nThe integral of the secant function of trigonometry was the subject of one of the \"outstanding open problems of the mid-seventeenth century\", solved in 1668 by James Gregory. In 1599, Edward Wright evaluated the integral by numerical methods – what today we would call Riemann sums. He wanted the solution for the purposes of cartography – specifically for constructing an accurate Mercator projection. In the 1640s, Henry Bond, a teacher of navigation, surveying, and other mathematical topics, compared Wright's numerically computed table of values of the integral of the secant with a table of logarithms of the tangent function, and consequently conjectured that\n\nThat conjecture became widely known, and in 1665, Isaac Newton was aware of it.\n\nAlthough Gregory proved the conjecture in 1668 in his \"Exercitationes Geometricae\", the proof was presented in a form that renders it nearly impossible for modern readers to comprehend; Isaac Barrow, in his \"Geometrical Lectures\" of 1670, gave the first \"intelligible\" proof, though even that was \"couched in the geometric idiom of the day.\" Barrow's proof of the result was the earliest use of partial fractions in integration. Adapted to modern notation, Barrow's proof began as follows:\n\nSubstituting formula_3 for formula_4 reduces the integral to\n\nTherefore,\nThe second of these follows by first multiplying top and bottom of the interior fraction by formula_7. This gives formula_8 in the denominator and the result follows by moving the factor of 1/2 into the logarithm as a square root.\n\nThe third form follows by replacing formula_4 by formula_10 and expanding using the identities for formula_11. It may also be obtained directly by means of the following substitutions:\n\nThe conventional solution for the Mercator projection ordinate may be written without the modulus signs since the latitude (\"φ\") lies between −/2 and /2:\n\nThe integral can also be derived by using the tangent half-angle substitution. A somewhat non-standard version of the tangent half-angle substitution, which is simpler in the case of this particular integral, published in 2013, is as follows:\n\nLet\nTherefore,\n\nThe integral of the secant function defines the inverse of the Gudermannian function:\nThe lambertian function (lam) is a notation for the inverse of the gudermannian which is encountered in the theory of map projections. In particular the Mercator projection may be written as\n\n"}
{"id": "35263737", "url": "https://en.wikipedia.org/wiki?curid=35263737", "title": "John George Herriot", "text": "John George Herriot\n\nJohn George Herriot (1916 – 16 March 2003) was a mathematician at Stanford university who worked on numerical analysis.\n\nJohn G. \"Jack\" Herriot received his Ph.D. from Brown University in 1941. He was a professor of mathematics and then of computer science at Stanford University from 1946 until his retirement in 1982. From 1953 to 1961 he was director of the Stanford Computation Center.\n\n\n"}
{"id": "39799215", "url": "https://en.wikipedia.org/wiki?curid=39799215", "title": "K-SVD", "text": "K-SVD\n\nIn applied mathematics, K-SVD is a dictionary learning algorithm for creating a dictionary for sparse representations, via a singular value decomposition approach. K-SVD is a generalization of the k-means clustering method, and it works by iteratively alternating between sparse coding the input data based on the current dictionary, and updating the atoms in the dictionary to better fit the data. K-SVD can be found widely in use in applications such as image processing, audio processing, biology, and document analysis.\n\nThe goal of dictionary learning is to learn an overcomplete dictionary matrix formula_1 that contains formula_2 signal-atoms (in this notation, columns of formula_3). A signal vector formula_4 can be represented, sparsely, as a linear combination of these atoms; to represent formula_5, the representation vector formula_6 should satisfy the exact condition formula_7, or the approximate condition formula_8, made precise by requiring that formula_9 for some small value and some norm. The vector formula_10 contains the representation coefficients of the signal formula_5. Typically, the norm formula_12 is selected as , , or .\n\nIf formula_13 and D is a full-rank matrix, an infinite number of solutions are available for the representation problem. Hence, constraints should be set on the solution. Also, to ensure sparsity, the solution with the fewest number of nonzero coefficients is preferred. Thus, the sparsity representation is the solution of either\n\nor\n\nwhere the formula_16 counts the nonzero entries in the vector formula_6. (See the zero \"norm\".)\n\nK-SVD is a kind of generalization of K-means, as follows.\nThe k-means clustering can be also regarded as a method of sparse representation. That is, finding the best possible codebook to represent the data samples formula_18 by nearest neighbor, by solving\n\nwhich is equivalent to\n\nThe letter F denotes the Frobenius norm. The sparse representation term formula_21 enforces K-means algorithm to use only one atom (column) in dictionary formula_3. To relax this constraint, the target of the K-SVD algorithm is to represent signal as a linear combination of atoms in formula_3.\n\nThe K-SVD algorithm follows the construction flow of the K-means algorithm. However, in contrary to K-means, in order to achieve a linear combination of atoms in formula_3, the sparsity term of the constraint is relaxed so that the number of nonzero entries of each column formula_25 can be more than 1, but less than a number formula_26.\n\nSo, the objective function becomes\n\nor in another objective form\n\nIn the K-SVD algorithm, the formula_3 is first fixed and the best coefficient matrix formula_30 is found. As finding the truly optimal formula_30 is impossible, we use an approximation pursuit method. Any algorithm such as OMP, the orthogonal matching pursuit can be used for the calculation of the coefficients, as long as it can supply a solution with a fixed and predetermined number of nonzero entries formula_26.\n\nAfter the sparse coding task, the next is to search for a better dictionary formula_3. However, finding the whole dictionary all at a time is impossible, so the process is to update only one column of the dictionary formula_3 each time, while fixing formula_30. The update of the formula_36-th column is done by rewriting the penalty term as \n\nwhere formula_38 denotes the \"k\"-th row of \"X\".\n\nBy decomposing the multiplication formula_39 into sum of formula_2 rank 1 matrices, we can assume the other formula_41 terms are assumed fixed, and the formula_36-th remains unknown. After this step, we can solve the minimization problem by approximate the formula_43 term with a formula_44 matrix using singular value decomposition, then update formula_45 with it. However, the new solution of vector formula_38 is very likely to be filled, because the sparsity constraint is not enforced.\n\nTo cure this problem, Define formula_47 as\n\nwhich points to examples formula_49 that use atom formula_45 (also the entries of formula_25 that is nonzero). Then, define formula_52 as a matrix of size formula_53, with ones on the formula_54 entries and zeros otherwise. When multiplying formula_55, this shrinks the row vector formula_56 by discarding the zero entries. Similarly, the multiplication formula_57 is the subset of the examples that are current using the formula_45 atom. The same effect can be seen on formula_59.\n\nSo the minimization problem as mentioned before becomes \nand can be done by directly using SVD. SVD decomposes formula_61 into formula_62. The solution for formula_45 is the first column of U, the coefficient vector formula_64 as the first column of formula_65. After updating the whole dictionary, the process then turns to iteratively solve X, then iteratively solve D.\n\nChoosing an appropriate \"dictionary\" for a dataset is a non-convex problem, and K-SVD operates by an iterative update which does not guarantee to find the global optimum. However, this is common to other algorithms for this purpose, and K-SVD works fairly well in practice.\n\n"}
{"id": "16182186", "url": "https://en.wikipedia.org/wiki?curid=16182186", "title": "List of works designed with the golden ratio", "text": "List of works designed with the golden ratio\n\nMany works of art are claimed to have been designed using the golden ratio.\nHowever, many of these claims are disputed, or refuted by measurement.\n\nThe golden ratio, an irrational number, is approximately 1.618; it is often denoted by the Greek letter φ (phi).\n\nVarious authors have claimed that early monuments have golden ratio proportions, often on conjectural interpretations, using approximate measurements, and only roughly corresponding to 1.618. For example, claims have been made about golden ratio proportions in Egyptian, Sumerian and Greek vases, Chinese pottery, Olmec sculptures, and Cretan and Mycenaean products from the late Bronze Age. These predate by some 1,000 years the Greek mathematicians first known to have studied the golden ratio. However, the historical sources are obscure, and the analyses are difficult to compare because they employ differing methods.\n\nIt is claimed, for instance, that Stonehenge (3100 BC – 2200 BC) has golden ratio proportions between its concentric circles. Kimberly Elam proposes this relation as early evidence of human cognitive preference for the golden ratio. However, others point out that this interpretation of Stonehenge \"may be doubtful\" and that the geometric construction that generates it can only be surmised. As another example, Carlos Chanfón Olmos states that the Sculpture of King Gudea (c. 2350 BC) has golden proportions between all of its secondary elements repeated many times at its base.\n\nThe Great Pyramid of Giza (constructed c. 2570 BC by Hemiunu) exhibits the golden ratio according to various pyramidologists, including Charles Funck-Hellet. John F. Pile, interior design professor and historian, has claimed that Egyptian designers sought the golden proportions without mathematical techniques and that it is common to see the 1.618:1 ratio, along with many other simpler geometrical concepts, in their architectural details, art, and everyday objects found in tombs. In his opinion, \"That the Egyptians knew of it and used it seems certain.\"\n\nFrom before the beginning of these theories, other historians and mathematicians have proposed alternative theories for the pyramid designs that are not related to any use of the golden ratio, and are instead based on purely rational slopes that only approximate the golden ratio. The Egyptians of those times apparently did not know the Pythagorean theorem; the only right triangle whose proportions they knew was the 3:4:5 triangle.\n\nThe Acropolis of Athens (468–430 BC), including the Parthenon, according to some studies, has many proportions that approximate the golden ratio. Other scholars question whether the golden ratio was known to or used by Greek artists and architects as a principle of aesthetic proportion. Building the Acropolis is calculated to have been started around 600 BC, but the works said to exhibit the golden ratio proportions were created from 468 BC to 430 BC.\n\nThe Parthenon (447–432 BC), was a temple of the Greek goddess Athena. The Parthenon's facade as well as elements of its facade and elsewhere are claimed to be circumscribed by a progression of golden rectangles. Some more recent studies dispute the view that the golden ratio was employed in the design.\n\nHemenway claims that the Greek sculptor Phidias (c. 480–c. 430 BC) used the divine proportion in some of his sculptures. He created \"Athena Parthenos\" in Athens and \"Statue of Zeus\" (one of the Seven Wonders of the Ancient World) in the Temple of Zeus at Olympia. He is believed to have been in charge of other Parthenon sculptures, although they may have been executed by his alumni or peers. In the early 20th century, American mathematician Mark Barr proposed the Greek letter phi (φ), the first letter of Phidias's name, to denote the golden ratio.\n\nLothar Haselberger claims that the temple of Apollo in Didyma (c. 334 BC), designed by Daphnis of Mileto and Paionios of Ephesus, has golden proportions.\n\nBetween 1950 and 1960, Manuel Amabilis applied some of the analysis methods of Frederik Macody Lund and Jay Hambidge in several designs of prehispanic buildings, such as \"El Toloc\" and \"La Iglesia de Las Monjas\" (the Nuns Church), a notable complex of Terminal Classic buildings constructed in the Puuc architectural style at Chichen Itza. According to his studies, their proportions are concretized from a series of polygons, circles and pentagrams inscribed, as Lund found in his studies of Gothic churches. Manuel Amabilis published his studies along with several self-explanatory images of other pre-columbian buildings made with golden ratio proportions in \"La Arquitectura Precolombina de Mexico\". The work was awarded the gold medal and the title of \"Academico\" by the Real Academia de Bellas Artes de San Fernando (Spain) in the \"Fiesta de la Raza\" (Columbus day) of 1929.\n\nThe Castle of Chichen Itza was built by the Maya civilization between the 11th and 13th centuries AD as a temple to the god Kukulcan. John Pile claims that its interior layout has golden ratio proportions. He says that the interior walls are placed so that the outer spaces are related to the central chamber by the golden ratio.\n\nThe Great Mosque of Kairouan (built by Uqba ibn Nafi c. 670 A.D.) has been claimed to use the golden ratio in the design including its plan, the prayer space, court, and minaret, but the ratio does not appear in the original parts of the mosque.\n\nThe Stupa of Borobudur in Java, Indonesia (built eighth to ninth century AD), the largest known Buddhist stupa, has the dimension of the square base related to the diameter of the largest circular terrace as 1.618:1, according to Pile.\n\nThe Romanesque style of architecture prevailed in Europe between 900–1200, a period which ends with the transition to Gothic architecture. The contrast between Romanesque and Gothic concepts in religious buildings can be understood in the epistolary between St. Bernard, Cistercian, and the Abbot Suger of the order of Cluny, the initiator of Gothic art in St. Denis.\n\nOne of the most beautiful works of Romanesque Cistercian is the Abbey of Sénanque in Provence. The Sénanque abbatial was founded in 1148 and consecrated in 1178. It was initiated in life of St Bernard of Clairvaux.\n“La Lumière à Sénanque” (The Light in Sénanque),\na chapter of \"Cîteaux : commentarii cistercienses\", a publication of the Cistercian Order. Its author, Kim Lloveras i Montserrat, made in 1992 a complete study of the abbatial, and argues that the abbatial church was designed using a system of measures founded in the golden ratio, and that the instruments used for its construction were the “Vescica” and the medieval squares used by the constructors, both designed with the golden ratio. The \"Vescica\" of Sénanque is located in the cloister of the monastery, in front of the Chapter, the site of the workshop.\n\nIn his 1919 book \"Ad Quadratum\", Frederik Macody Lund, a historian who studied the geometry of several gothic structures, claims that the Cathedral of Chartres (begun in the 12th century), the Notre-Dame of Laon (1157–1205), and the Notre Dame de Paris (1160) are designed according to the golden ratio. Other scholars argue that until Luca Pacioli's 1509 \"De Divina Proportione\" (see next section), the golden ratio was unknown to artists and architects, although this is not likely the case since the ratio was explicitly defined by Euclid.\n\nA 2003 conference on medieval architecture resulted in the book \"Ad Quadratum: The Application of Geometry to Medieval Architecture\". According to a summary by one reviewer:\nMost of the contributors consider that the setting out was done ad quadratum, using the sides of a square and its diagonal. This gave an incommensurate ratio of [square root of (2)] by striking a circular arc (which could easily be done with a rope rotating around a peg). Most also argued that setting out was done geometrically rather than arithmetically (with a measuring rod). Some considered that setting out also involved the use of equilateral or Pythagorean triangles, pentagons, and octagons. Two authors believe the Golden Section (or at least its approximation) was used, but its use in medieval times is not supported by most architectural historians.\nThe Australian architectural historian John James made a detailed study of the Cathedral of Chartres. In his work \"The Master Masons of Chartres\" he says that Bronze, one of the master masons, used the golden ratio. It was the same relation as between the arms of their metal square:\n\nBronze by comparison was an innovator, in practical rather than in philosophic things. Amongst other things Bronze was one of the few masters to use the fascinating ratio of the golden mean. For the builder, the most important function Fi, as we write the golden mean, is that if the uses is consistently he will find that every subdivision, no matter how accidentally it may have been derived, will fit somewhere into the series. Is not too difficult a ratio to reproduce, and Bronze could have had the two arms of his metal square cut to represent it. All he would than have had to do was to place the square on the stone and, using the string draw between the corners, relate any two lengths by Phi. Nothing like making life easy. \n\"De divina proportione\", written by Luca Pacioli in Milan in 1496–1498, published in Venice in 1509, features 60 drawings by Leonardo da Vinci, some of which illustrate the appearance of the golden ratio in geometric figures. Starting with part of the work of Leonardo da Vinci, this architectural treatise was a major influence on generations of artists and architects.\n\nVitruvian Man, created by Leonardo da Vinci around the year 1492, is based on the theories of the man after which the drawing takes its name, Vitruvius, who in \"De Architectura: The Planning of Temples\" (c. I BC) pointed that the planning of temples depends on symmetry, which must be based on the perfect proportions of the human body. Some authors feel there is no actual evidence that Da Vinci used the golden ratio in \"Vitruvian Man\"; however, Olmos (1991) observes otherwise through geometrical analysis. He also proposes Leonardo da Vinci's \"self portrait\", Michelangelo's \"David\" (1501–1504), Albrecht Dürer's \"Melencolia I\" and the classic violin design by the masters of Cremona (Guarneri, Stradivari and several members of the Amati family) as having similar regulator lines related to the golden ratio.\n\nDa Vinci's \"Mona Lisa\" (c. 1503–1506) \"has been the subject of so many volumes of contradicting scholarly and popular speculations that it virtually impossible to reach any unambiguous conclusions\" with respect to the golden ratio, according to Livio.\nThe \"Tempietto\" chapel at the Monastery of Saint Peter in Montorio, Rome, built by Bramante, has relations to the golden ratio in its elevation and interior lines.\nJosé Villagrán García has claimed that the golden ratio is an important element in the design of the Mexico City Metropolitan Cathedral (circa 1667–1813). Olmos claims the same for the design of the cities of Coatepec (1579), Chicoaloapa (1579) and Huejutla (1580), as well as the Mérida Cathedral, the Acolman Temple, \"Cristo Crucificado\" by Diego Velázquez (1639) and \"\" (pictured) of Bartolomé Esteban Murillo.\n\nMatila Ghyka and others contend that Georges Seurat used golden ratio proportions in paintings like \"La Parade\", \"Le Pont de Courbevoie\" and \"Bathers at Asnières\". However, there is no direct evidence to support these claims.\n\nWhile the golden ratio appears to govern the geometric structure of Seurat's \"Parade de cirque (Circus Sideshow)\", modern consensus among art historians is that Seurat never used this \"divine proportion\" in his work.\n\nThe final study of \"Parade\", executed prior to the oil on canvas, is divided horizontally into fourths and vertically into sixths (4 : 6 ratio) corresponding to the dimensions of the canvas, which is one and one-half times wider than its vertical dimension. These axes do not correspond precisely to the golden section, 1 : 1.6, as might have been expected. Rather, they correspond to basic mathematical divisions (simple ratios that appear to approximate the golden section), as noted by Seurat with citations from the mathematician, inventor, esthetician Charles Henry.\n\nThe idea of the Section d'Or (or Groupe de Puteaux) originated in the course of conversations between Albert Gleizes, Jean Metzinger and Jacques Villon. The group's title was suggested by Villon, after reading a 1910 translation of Leonardo da Vinci's \"Trattato della Pittura\" by Joséphin Péladan. Peladan attached great mystical significance to the golden section (), and other similar geometric configurations. For Villon, this symbolized his belief in order and the significance of mathematical proportions, because it reflected patterns and relationships occurring in nature. Jean Metzinger and the Duchamp brothers were passionately interested in mathematics. Jean Metzinger, Juan Gris and possibly Marcel Duchamp at this time were associates of Maurice Princet, an amateur mathematician credited for introducing profound and rational scientific arguments into Cubist discussions. The name \"La Section d'Or\" represented simultaneously a continuity with past traditions and current trends in related fields, while leaving open future developments in the arts.\n\n\"The Sacrament of the Last Supper\" (1955): The canvas of this surrealist masterpiece by Salvador Dalí is a golden rectangle. A huge dodecahedron, with edges in golden ratio to one another, is suspended above and behind Jesus and dominates the composition.\n\nSome works in the Dutch artistic movement called De Stijl, or neoplasticism, exhibit golden ratio proportions. Piet Mondrian used the golden section extensively in his neoplasticist, geometrical paintings, created circa 1918–38. Mondrian sought proportion in his paintings by observation, knowledge and intuition, rather than geometrical or mathematical methods.\n\nThe Farnsworth House, designed by Ludwig Mies van der Rohe, has been described as \"the proportions, within the glass walls, approach 1:2\" and \"with a width to length ratio of 1:1.75 (nearly the golden section)\" and has been studied with his other works in relation to the golden ratio.\n\nThe Swiss architect Le Corbusier, famous for his contributions to the modern international style, centered his design philosophy on systems of harmony and proportion. Le Corbusier's faith in the mathematical order of the universe was closely bound to the golden ratio and the Fibonacci series, which he described as \"rhythms apparent to the eye and clear in their relations with one another. And these rhythms are at the very root of human activities. They resound in man by an organic inevitability, the same fine inevitability which causes the tracing out of the Golden Section by children, old men, savages and the learned.\"\n\nModulor: Le Corbusier explicitly used the golden ratio in his system for the scale of architectural proportion. He saw this system as a continuation of the long tradition of Vitruvius, Leonardo da Vinci's \"Vitruvian Man\", the work of Leon Battista Alberti, and others who used the proportions of the human body to improve the appearance and function of architecture. In addition to the golden ratio, Le Corbusier based the system on human measurements, Fibonacci numbers, and the double unit. He took Leonardo's suggestion of the golden ratio in human proportions to an extreme: he sectioned his model human body's height at the navel with the two sections in golden ratio, then subdivided those sections in golden ratio at the knees and throat; he used these golden ratio proportions in the Modulor system.\n\nIn \"The Modulor: A Harmonious Measure to the Human Scale, Universally Applicable to Architecture and Mechanics\" Le Corbusier reveals he used his system in the Marseilles Unite D'Habitation (in the general plan and section, the front elevation, plan and section of the apartment, in the woodwork, the wall, the roof and some prefabricated furniture), a small office in 35 rue de Sèvres, a factory in Saint-Die and the United Nations Headquarters building in New York City. Many authors claim that the shape of the facade of the second is the result of three golden rectangles; however, each of the three rectangles that can actually be appreciated have different heights.\n\nCatalan architect Josep Lluis Sert, a disciple of Le Corbusier, applied the measures of the Modulor in all his particular works, including the Sert's House in Cambridge and the Joan Miró Foundation in Barcelona.\n\nAccording to the official tourism page of Buenos Aires, Argentina, the ground floor of the Palacio Barolo (1923), designed by Italian architect Mario Palanti, is built according to the golden section.\n\nAnother Swiss architect, Mario Botta, bases many of his designs on geometric figures. Several private houses he designed in Switzerland are composed of squares and circles, cubes and cylinders. In a house he designed in Origlio, the golden ratio is the proportion between the central section and the side sections of the house.\n\nErnő Lendvai analyzes Béla Bartók's works as being based on two opposing systems, that of the golden ratio and the acoustic scale, though other music scholars reject that analysis. In Bartók's \"Music for Strings, Percussion and Celesta\" the xylophone progression occurs at the intervals 1:2:3:5:8:5:3:2:1. The French composer Erik Satie used the golden ratio in several of his pieces, including \"Sonneries de la Rose+Croix\". \n\nThe golden ratio is also apparent in the organisation of the sections in the music of Claude Debussy's \"Image: Reflections in the Water\", in which \"the sequence of keys is marked out by the intervals 34, 21, 13 and 8, and the main climax sits at the phi position.\"\n\nThe musicologist Roy Howat has observed that the formal boundaries of Debussy’s \"La mer\" correspond exactly to the golden section. Trezise finds the intrinsic evidence \"remarkable\", but cautions that no written or reported evidence suggests that Debussy consciously sought such proportions.\n\nLeonid Sabaneyev hypothesizes that the separate time intervals of the musical pieces connected by the \"culmination event\", as a rule, are in the ratio of the golden section. However the author attributes this incidence to the instinct of the musicians: \"All such events are timed by author's instinct to such points of the whole length that they divide temporary durations into separate parts being in the ratio of the golden section.\"\n\nRon Knott exposes how the golden ratio is unintentionally present in several pieces of classical music:\n\nAccording to author Leon Harkleroad, \"Some of the most misguided attempts to link music and mathematics have involved Fibonacci numbers and the related golden ratio.\"\n\n"}
{"id": "543568", "url": "https://en.wikipedia.org/wiki?curid=543568", "title": "Lorentz covariance", "text": "Lorentz covariance\n\nIn relativistic physics, Lorentz symmetry, named for Hendrik Lorentz, is an equivalence of observation or observational symmetry due to special relativity implying that the laws of physics stay the same for all observers that are moving with respect to one another within an inertial frame. It has also been described as \"the feature of nature that says experimental results are independent of the orientation or the boost velocity of the laboratory through space\".\n\nLorentz covariance, a related concept, is a property of the underlying spacetime manifold. Lorentz covariance has two distinct, but closely related meanings:\n\n\nOn manifolds, the words \"covariant\" and \"contravariant\" refer to how objects transform under general coordinate transformations. Both covariant and contravariant four-vectors can be Lorentz covariant quantities.\n\nLocal Lorentz covariance, which follows from general relativity, refers to Lorentz covariance applying only \"locally\" in an infinitesimal region of spacetime at every point. There is a generalization of this concept to cover Poincaré covariance and Poincaré invariance.\n\nIn general, the (transformational) nature of a Lorentz tensor can be identified by its tensor order, which is the number of free indices it has. No indices implies it is a scalar, one implies that it is a vector, etc. Some tensors with a physical interpretation are listed below.\n\nThe sign convention of the Minkowski metric η = diag (1, −1, −1, −1) is used throughout the article.\n\n\n\n\nIn standard field theory, there are very strict and severe constraints on marginal and relevant Lorentz violating operators within both QED and the Standard Model. Irrelevant Lorentz violating operators may be suppressed by a high cutoff scale, but they typically induce marginal and relevant Lorentz violating operators via radiative corrections. So, we also have very strict and severe constraints on irrelevant Lorentz violating operators.\n\nSince some approaches to quantum gravity lead to violations of Lorentz invariance, these studies are part of Phenomenological Quantum Gravity. Lorentz violations are allowed in string theory, supersymmetry and Horava-Lifshitz gravity.\n\nLorentz violating models typically fall into four classes:\n\n\nModels belonging to the first two classes can be consistent with experiment if Lorentz breaking happens at Planck scale or beyond it, or even before it in suitable preonic models, and if Lorentz symmetry violation is governed by a suitable energy-dependent parameter. One then has a class of models which deviate from Poincaré symmetry near the Planck scale but still flows towards an exact Poincaré group at very large length scales. This is also true for the third class, which is furthermore protected from radiative corrections as one still has an exact (quantum) symmetry.\n\nEven though there is no evidence of the violation of Lorentz invariance, several experimental searches for such violations have been performed during recent years. A detailed summary of the results of these searches is given in the Data Tables for Lorentz and CPT Violation.\n\nLorentz invariance is also violated in QFT assuming non-zero temperature.\n\nThere is also growing evidence of Lorentz violation in Weyl semimetals and Dirac semimetals.\n\n\n"}
{"id": "1480484", "url": "https://en.wikipedia.org/wiki?curid=1480484", "title": "Menelaus's theorem", "text": "Menelaus's theorem\n\nMenelaus's theorem, named for Menelaus of Alexandria, is a proposition about triangles in plane geometry. Given a triangle \"ABC\", and a transversal line that crosses \"BC\", \"AC\", and \"AB\" at points \"D\", \"E\", and \"F\" respectively, with \"D\", \"E\", and \"F\" distinct from \"A\", \"B\", and \"C\", then \n\nor simply\n\nThis equation uses signed lengths of segments, in other words the length \"AB\" is taken to be positive or negative according to whether \"A\" is to the left or right of \"B\" in some fixed orientation of the line. For example, \"AF\"/\"FB\" is defined as having positive value when \"F\" is between \"A\" and \"B\" and negative otherwise.\n\nThe converse is also true: If points \"D\", \"E\", and \"F\" are chosen on \"BC\", \"AC\", and \"AB\" respectively so that \nthen \"D\", \"E\", and \"F\" are collinear. The converse is often included as part of the theorem.\n\nThe theorem is very similar to Ceva's theorem in that their equations differ only in sign.\n\nA standard proof is as follows:\n\nFirst, the sign of the left-hand side will be negative since either all three of the ratios are negative, the case where the line DEF misses the triangle (lower diagram), or one is negative and the other two are positive, the case where DEF crosses two sides of the triangle. (See Pasch's axiom.)\n\nTo check the magnitude, construct perpendiculars from \"A\", \"B\", and \"C\" to the line \"DEF\" and let their lengths be \"a, b,\" and \"c\" respectively. Then by similar triangles it follows that |\"AF\"/\"FB\"| = |\"a\"/\"b\"|, |\"BD\"/\"DC\"| = |\"b\"/\"c\"|, and |\"CE\"/\"EA\"| = \"c\"/\"a\". So \n\nFor a simpler, if less symmetrical way to check the magnitude, draw \"CK\" parallel to \"AB\" where \"DEF\" meets \"CK\" at \"K\". Then by similar triangles\nand the result follows by eliminating \"CK\" from these equations.\n\nThe converse follows as a corollary. Let \"D\", \"E\", and \"F\" be given on the lines \"BC\", \"AC\", and \"AB\" so that the equation holds. Let \"F\"′ be the point where \"DE\" crosses \"AB\". Then by the theorem, the equation also holds for \"D\", \"E\", and \"F\"′. Comparing the two, \nBut at most one point can cut a segment in a given ratio so \"F\"=\"F\"′.\n\nThe following proof uses only notions of affine geometry, notably homothecies.\nWhether or not \"D\", \"E\", and \"F\" are collinear, there are three homothecies with centers \"D\", \"E\", \"F\" that respectively send \"B\" to \"C\", \"C\" to \"A\", and \"A\" to \"B\". The composition of the three then is an element of the group of homothecy-translations that fixes \"B\", so it is a homothecy with center \"B\", possibly with ratio 1 (in which case it is the identity). This composition fixes the line \"DE\" if and only if \"F\" is collinear with \"D\" and \"E\" (since the first two homothecies certainly fix \"DE\", and the third does so only if \"F\" lies on \"DE\"). Therefore \"D\", \"E\", and \"F\" are collinear if and only if this composition is the identity, which means that the product of the three ratios is 1:\nwhich is equivalent to the given equation.\n\nIt is uncertain who actually discovered the theorem; however, the oldest extant exposition appears in \"Spherics\" by Menelaus. In this book, the plane version of the theorem is used as a lemma to prove a spherical version of the theorem.\n\nIn Almagest, Ptolemy applies the theorem on a number of problems in spherical astronomy. During the Islamic Golden Age, Muslim scholars devoted a number of works that engaged in the study of Menelaus's theorem, which they referred to as \"the proposition on the secants\" (\"shakl al-qatta\"'). The complete quadrilateral was called the \"figure of secants\" in their terminology. Al-Biruni's work, \"The Keys of Astronomy\", lists a number of those works, which can be classified into studies as part of commentaries on Ptolemy's \"Almagest\" as in the works of al-Nayrizi and al-Khazin where each demonstrated particular cases of Menelaus's theorem that led to the sine rule, or works composed as independent treatises such as:\n\n\n"}
{"id": "6158953", "url": "https://en.wikipedia.org/wiki?curid=6158953", "title": "Modal μ-calculus", "text": "Modal μ-calculus\n\nIn theoretical computer science, the modal μ-calculus (Lμ, L, sometimes just μ-calculus, although this can have a more general meaning) is an extension of propositional modal logic (with many modalities) by adding the least fixed point operator μ and the greatest fixed point operator formula_1, thus a fixed-point logic.\n\nThe (propositional, modal) μ-calculus originates with Dana Scott and Jaco de Bakker, and was further developed by Dexter Kozen into the version most used nowadays. It is used to describe properties of labelled transition systems and for verifying these properties. Many temporal logics can be encoded in the μ-calculus, including CTL* and its widely used fragments—linear temporal logic and computational tree logic.\n\nAn algebraic view is to see it as an algebra of monotonic functions over a complete lattice, with operators consisting of functional composition plus the least and greatest fixed point operators; from this viewpoint, the modal μ-calculus is over the lattice of a power set algebra. The game semantics of μ-calculus is related to two-player games with perfect information, particularly infinite parity games.\n\nLet \"P\" (propositions) and \"A\" (actions) be two finite sets of symbols, and let \"V\" be a countably infinite set of variables. The set of formulas of (propositional, modal) μ-calculus is defined as follows:\n\nGiven the above definitions, we can enrich the syntax with:\n\nThe first two formulas are the familiar ones from the classical propositional calculus and respectively the minimal multimodal logic K.\n\nThe notation formula_28 (and its dual) are inspired from the lambda calculus; the intent is to denote the least (and respectively greatest) fixed point of the expression formula_2 where the \"minimization\" (and respectively \"maximization\") are in the variable formula_15, much like in lambda calculus formula_38 is a function with formula formula_2 in bound variable formula_15; see the denotational semantics below for details.\n\nModels of (propositional) μ-calculus are given as labelled transition systems formula_41 where:\n\n\nGiven a labelled transition system formula_41 and an interpretation formula_49 of the variables formula_15 of the formula_51-calculus, formula_52, is the function defined by the following rules:\n\n\nBy duality, the interpretation of the other basic formulas is:\n\n\nLess formally, this means that, for a given transition system formula_41:\n\n\nThe interpretations of formula_9 and formula_79 are in fact the \"classical\" ones from [[Dynamic logic (modal logic)|dynamic logic]]. Additionally, the operator formula_51 can be interpreted as [[liveness]] (\"something good eventually happens\") and formula_1 as [[safety (computer science)|safety]] (\"nothing bad ever happens\") in [[Leslie Lamport]]'s informal classification.\n\n\n[[Satisfiability]] of a modal μ-calculus formula is [[EXPTIME-complete]]. As for Linear Temporal Logic, model checking, satisfiability and validity problems of linear modal μ-calculus are PSPACE-complete.\n\n\n\n[[Category:Modal logic]]\n[[Category:Model checking]]"}
{"id": "8908740", "url": "https://en.wikipedia.org/wiki?curid=8908740", "title": "Occurrences of Grandi's series", "text": "Occurrences of Grandi's series\n\nGuido Grandi illustrated the series with a parable involving two brothers who share a gem.\n\nThomson's lamp is a supertask in which a hypothetical lamp is turned on and off infinitely many times in a finite time span. One can think of turning the lamp on as adding 1 to its state, and turning it off as subtracting 1. Instead of asking the sum of the series, one asks the final state of the lamp.\n\nOne of the best-known classic parables to which infinite series have been applied, Achilles and the tortoise, can also be adapted to the case of Grandi's series.\n\nThe Cauchy product of Grandi's series with itself is 1 − 2 + 3 − 4 + · · ·.\n\nSeveral series resulting from the introduction of zeros into Grandi's series have interesting properties; for these see Summation of Grandi's series#Dilution.\n\nGrandi's series is just one example of a divergent geometric series.\n\nThe rearranged series 1 − 1 − 1 + 1 + 1 − 1 − 1 + · · · occurs in Euler's 1775 treatment of the pentagonal number theorem as the value of the Euler function at \"q\" = 1.\n\nThe power series most famously associated with Grandi's series is its ordinary generating function,\n\nIn his 1822 \"Théorie Analytique de la Chaleur\", Joseph Fourier obtains what we now call a Fourier sine series for a scaled version of the hyperbolic sine function,\n\nHe finds that the general coefficient of sin \"nx\" in the series is\n\nFor \"n\" > 1 the above series converges, while the coefficient of sin \"x\" appears as 1 − 1 + 1 − 1 + · · · and so is expected to be ⁄. In fact, this is correct, as can be demonstrated by directly calculating the Fourier coefficient from an integral:\n\nGrandi's series occurs more directly in another important series,\n\nAt \"x\" = , the series reduces to −1 + 1 − 1 + 1 − · · · and so one might expect it to meaningfully equal −⁄. In fact, Euler held that this series obeyed the formal relation Σ cos \"kx\" = −⁄, while d'Alembert rejected the relation, and Lagrange wondered if it could be defended by an extension of the geometric series similar to Euler's reasoning with Grandi's numerical series.\n\nEuler's claim suggests that\n\nfor all \"x\". This series is divergent everywhere, while its Cesàro sum is indeed 0 for almost all \"x\". However, the series diverges to infinity at \"x\" = 2\"n\" in a significant way: it is the Fourier series of a Dirac comb. The ordinary, Cesàro, and Abel sums of this series involve limits of the Dirichlet, Fejér, and Poisson kernels, respectively.\n\nMultiplying the terms of Grandi's series by 1/\"n\" yields the Dirichlet series \nwhich converges only for complex numbers \"z\" with a positive real part. Grandi's series is recovered by letting \"z\" = 0.\n\nUnlike the geometric series, the Dirichlet series for \"η\" is not useful for determining what 1 − 1 + 1 − 1 + · · · \"should\" be. Even on the right half-plane, \"η\"(\"z\") is not given by any elementary expression, and there is no immediate evidence of its limit as \"z\" approaches 0. On the other hand, if one uses stronger methods of summability, then the Dirichlet series for \"η\" defines a function on the whole complex plane — the Dirichlet eta function — and moreover, this function is analytic. For \"z\" with real part > −1 it suffices to use Cesàro summation, and so \"η\"(0) = ⁄ after all.\n\nThe function \"η\" is related to a more famous Dirichlet series and function:\n\nwhere ζ is the Riemann zeta function. Keeping Grandi's series in mind, this relation explains why ζ(0) = −⁄; see also 1 + 1 + 1 + 1 + · · ·. The relation also implies a much more important result. Since \"η\"(\"z\") and (1 − 2) are both analytic on the entire plane and the latter function's only zero is a simple zero at \"z\" = 1, it follows that ζ(\"z\") is meromorphic with only a simple pole at \"z\" = 1.\n\nGiven a CW complex \"S\" containing one vertex, one edge, one face, and generally exactly one cell of every dimension, Euler's formula for the Euler characteristic of \"S\" returns . There are a few motivations for defining a generalized Euler characteristic for such a space that turns out to be 1/2.\n\nOne approach comes from combinatorial geometry. The open interval (0, 1) has an Euler characteristic of −1, so its power set 2 should have an Euler characteristic of 2 = 1/2. The appropriate power set to take is the \"small power set\" of finite subsets of the interval, which consists of the union of a point (the empty set), an open interval (the set of singetons), an open triangle, and so on. So the Euler characteristic of the small power set is . James Propp defines a regularized Euler measure for polyhedral sets that, in this example, replaces with , sums the series for |\"t\"| < 1, and analytically continues to \"t\" = 1, essentially finding the Abel sum of , which is 1/2. Generally, he finds χ(2) = 2 for any polyhedral set \"A\", and the base of the exponent generalizes to other sets as well.\n\nInfinite-dimensional real projective space RP is another structure with one cell of every dimension and therefore an Euler characteristic of . This space can be described as the quotient of the infinite-dimensional sphere by identifying each pair of antipodal points. Since the infinite-dimensional sphere is contractible, its Euler characteristic is 1, and its 2-to-1 quotient should have an Euler characteristic of 1/2.\n\nThis description of RP also makes it the classifying space of Z, the cyclic group of order 2. Tom Leinster gives a definition of the Euler characteristic of any category which bypasses the classifying space and reduces to 1/|\"G\"| for any group when viewed as a one-object category. In this sense the Euler characteristic of Z is itself ⁄.\n\nGrandi's series, and generalizations thereof, occur frequently in many branches of physics; most typically in the discussions of quantized fermion fields (for example, the chiral bag model), which have both positive and negative eigenvalues; although similar series occur also for bosons, such as in the Casimir effect.\n\nThe general series is discussed in greater detail in the article on spectral asymmetry, whereas methods used to sum it are discussed in the articles on regularization and, in particular, the zeta function regulator.\n\nJliat's 2000 musical single \"Still Life #7: The Grandi Series\" advertises itself as \"conceptual art\"; it consists of nearly an hour of silence.\n\n"}
{"id": "1319467", "url": "https://en.wikipedia.org/wiki?curid=1319467", "title": "On Growth and Form", "text": "On Growth and Form\n\nOn Growth and Form is a book by the Scottish mathematical biologist D'Arcy Wentworth Thompson (1860–1948). The book is long – 793 pages in the first edition of 1917, 1116 pages in the second edition of 1942.\n\nThe book covers many topics including the effects of scale on the shape of animals and plants, large ones necessarily being relatively thick in shape; the effects of surface tension in shaping soap films and similar structures such as cells; the logarithmic spiral as seen in mollusc shells and ruminant horns; the arrangement of leaves and other plant parts (phyllotaxis); and Thompson's own method of transformations, showing the changes in shape of animal skulls and other structures on a Cartesian grid.\n\nThe work is widely admired by biologists, anthropologists and architects among others, but less often read than cited. Peter Medawar explains this as being because it clearly pioneered the use of mathematics in biology, and helped to defeat mystical ideas of vitalism; but that the book is weakened by Thompson's failure to understand the role of evolution and evolutionary history in shaping living structures. Philip Ball and Michael Ruse, on the other hand, suspect that while Thompson argued for physical mechanisms, his rejection of natural selection bordered on vitalism.\n\nD'Arcy Wentworth Thompson's most famous work, \"On Growth and Form\" was written in Dundee, mostly in 1915, but publication was put off until 1917 because of the delays of wartime and Thompson's many late alterations to the text. The central theme of the book is that biologists of its author's day overemphasized evolution as the fundamental determinant of the form and structure of living organisms, and underemphasized the roles of physical laws and mechanics. At a time when vitalism was still being considered as a biological theory, he advocated structuralism as an alternative to natural selection in governing the form of species, with the smallest hint of vitalism as the unseen driving force.\n\nThompson had previously criticized Darwinism in his paper \"Some Difficulties of Darwinism\". \"On Growth and Form\" explained in detail why he believed Darwinism to be an inadequate explanation for the origin of new species. He did not reject natural selection, but regarded it as secondary to physical influences on biological form.\n\nUsing a mass of examples, Thompson pointed out correlations between biological forms and mechanical phenomena. He showed the similarity in the forms of jellyfish and the forms of drops of liquid falling into viscous fluid, and between the internal supporting structures in the hollow bones of birds and well-known engineering truss designs. He described phyllotaxis (numerical relationships between spiral structures in plants) and its relationship to the Fibonacci sequence.\n\nPerhaps the most famous part of the book is Chapter 17, \"The Comparison of Related Forms,\" where Thompson explored the degree to which differences in the forms of related animals could be described, in work inspired by the German engraver Albrecht Dürer (1471–1528), by mathematical transformations.\n\nThe book is descriptive rather than experimental science: Thompson did not articulate his insights in the form of hypotheses that can be tested. He was aware of this, saying that \"This book of mine has little need of preface, for indeed it is 'all preface' from beginning to end.\"\n\nThe first edition appeared in 1917 in a single volume of 793 pages published by Cambridge University Press. A second edition, enlarged to 1116 pages, was published in two volumes in 1942. Thompson wrote in the preface to the 1942 edition that he had written \"this book in wartime, and its revision has employed me during another war. It gave me solace and occupation, when service was debarred me by my years. Few are left of the friends who helped me write it.\" The unabridged edition is no longer in print in English, but an edition of 346 pages was abridged by John Tyler Bonner, and is widely published under the same title. The book, often in the abridged edition, has been reprinted more than 40 times, and has been translated into Chinese, French, German, Greek, Italian, and Spanish.\n\nThe contents of the chapters in the first edition are summarized below. All but Chapter 11 have the same titles in the second edition, but many are longer, as indicated by the page numbering of the start of each chapter. Bonner's abridgment shortened all the chapters, and removed some completely, again as indicated at the start of each chapter's entry below.\n\nThe numbers that result from such spiral arrangements are the Fibonacci sequence of ratios 1/2, 2/3, 3.5 ... converging on 0.61803..., the golden ratio which is\n\n\"J. P. McM[urrich]\", reviewing the book in \"Science\" in 1917, wrote that \"the book is one of the strongest documents in support of the mechanistic view of life that has yet been put forth\", contrasting this with \"vitalism\". The reviewer was interested in the \"discussion of the physical factors determining the size of organisms, especially interesting being the consideration of the conditions which may determine the minimum size\".\n\nJ. W. Buchanan, reviewing the second edition in \"Physiological Zoology\" in 1943, described it as \"an imposing extension of his earlier attempt to formulate a geometry of Growth and Form\" and \"beautifully written\", but warned that \"the reading will not be easy\" and that \"A vast store of literature has here been assembled and assimilated\". Buchanan summarizes the book, and notes that Chapter 17 \"seems to the reviewer to contain the essence of the long and more or less leisurely thesis... The chapter is devoted to comparison of related forms, largely by the method of co-ordinates. Fundamental differences in these forms are thus revealed\", and Buchanan concludes that the large \"gaps\" indicate that Darwin's endless series of continuous variations is not substantiated. But he does have some criticisms: Thompson should have referenced the effects of hormones on growth; and the relation of molecular configuration and form; genetics is barely mentioned, and experimental embryology and regeneration [despite Thompson's analysis of the latter] are overlooked. The mathematics used consists of statistics and geometry, while thermodynamics is \"largely absent\".\n\nEdmund Mayer, reviewing the second edition in \"The Anatomical Record\" in 1943, noted that the \"scope of the book and the general approach to the problems dealt with have remained unchanged, but considerable additions have been made and large parts have been recast\". He was impressed at the extent to which Thompson had kept up with developments in many sciences, though he thought the mentions of quantum theory and Heisenberg uncertainty unwise.\n\nGeorge C. Williams, reviewing the 1942 edition and Bonner's abridged edition for the \"Quarterly Review of Biology\" (of which he was the editor), writes that the book is \"a work widely praised, but seldom used. It contains neither original insights\nthat have formed a basis for later advances nor instructive fallacies that have stimulated fruitful attack. This seeming paradox is brilliantly discussed by P. B. Medawar [in] \"Pluto's Republic\".\" Williams then attempts a \"gross simplification\" of Medawar's evaluation:\n\nThe architects Philip Beesley and Sarah Bonnemaison write that Thompson's book at once became a classic \"for its exploration of natural geometries in the dynamics of growth and physical processes.\" They note the \"extraordinary optimism\" in the book, its vision of the world as \"a symphony of harmonious forces\", and its huge range, including:\n\nBeesley and Bonnemaison observe that Thompson saw form \"as a product of dynamic forces .. shaped by flows of energy and stages of growth.\" They praise his \"eloquent writing and exquisite illustrations\" which have provided inspiration for artists and architects as well as scientists.\n\nComputer-scientist and physicist, Stephen Wolfram, writes: \n\nThe statistician Cosma Shalizi writes that the book \"has haunted all discussion of these matters ever since.\"\n\nShalizi states that Thompson's goal is to show that biology follows inevitably from physics, and to a degree also from chemistry. He argues that when Thompson says \"the form of an object is a 'diagram of forces,'\", Thompson means that we can infer from an object the physical forces that act (or once acted) upon it. Shalizi calls Thompson's account of the physics of morphogenesis\n\nShalizi notes Thompson's simplicity, explaining the processes of life \"using little that a second-year physics undergrad wouldn't know. (Thompson's anti-reductionist admirers seldom put it this way.)\". He notes that Thompson deliberately avoided invoking natural selection as an explanation, and left history, whether of species or of an individual's life, out of his account. He quotes Thompson's \"A snow-crystal is the same today as when the first snows fell\": adding \"so, too, the basic forces acting upon organisms\", and comments that we have forgotten other early twentieth century scientists who scorned evolution. In contrast, he argues,\n\nThe anthropologist Barry Bogin writes that Thompson's book\n\nBogin observes that Thompson originated the use of transformational grids to measure growth in two dimensions, but that without modern computers the method was tedious to apply and was not often used. Even so, the book stimulated and lent intellectual validity to the new field of growth and development research.\n\nPeter Coates recalls that\n\nCoates argues however that the book goes far beyond expressing knowledge elegantly and influentially, in a form \"that can be read for pleasure by scientists and nonscientists\"; it is in his view\n\nThe science writer Philip Ball observes that\n\nBall quotes the 2nd Edition's epigraph by the statistician Karl Pearson: \"I believe the day must come when the biologist will—without being a mathematician—not hesitate to use mathematical analysis when he requires it.\" Ball argues that Thompson \"presents mathematical principles as a shaping agency that may supersede natural selection, showing how the structures of the living world often echo those in inorganic nature\", and notes his \"frustration at the 'Just So' explanations of morphology offered by Darwinians.\" Instead, Ball argues, Thompson elaborates on how not heredity but physical forces govern biological form. Ball suggests that \"The book's central motif is the logarithmic spiral\", evidence in Thompson's eyes of the universality of form and the reduction of many phenomena to a few principles of mathematics.\n\nThe philosopher of biology Michael Ruse wrote that Thompson \"had little time for natural selection.\" Instead, Thompson emphasised \"the formal aspects of organisms\", trying to make a case for self-organization through normal physical and chemical processes. Ruse notes that, following Aristotle, Thompson used as an example the morphology of jellyfish, which he explained entirely mechanically with the physics of a heavy liquid falling through a lighter liquid, avoiding natural selection as an explanation. Ruse is not sure whether Thompson believed he was actually breaking with \"mechanism\", in other words adopting a vitalist (ghost in the machine) view of the world. In Ruse's opinion, Thompson can be interpreted as arguing that \"we can have completely mechanical explanations of the living world\" – with the important proviso that Thompson apparently felt there was no need for natural selection. Ruse at once adds that \"people like Darwin and Dawkins undoubtedly would disagree\"; they would insist that\n\nFor his revised \"On Growth and Form\", Thompson was awarded the Daniel Giraud Elliot Medal from the United States National Academy of Sciences in 1942.\n\n\"On Growth and Form\" has inspired thinkers including the biologists Julian Huxley and Conrad Hal Waddington, the mathematician Alan Turing and the anthropologist Claude Lévi-Strauss. The book has powerfully influenced architecture and has long been a set text on architecture courses.\n\n\"On Growth and Form\" has inspired artists including Richard Hamilton, Eduardo Paolozzi, and Ben Nicholson. In 2011 the University of Dundee was awarded a £100,000 grant by The Art Fund to build a collection of art inspired by his ideas and collections, much of which is displayed in the D'Arcy Thompson Zoology Museum in Dundee.\n\nTo celebrate the centenary of \"On Growth and Form\" numerous events are being staged around the world, including New York, Amsterdam, Singapore, London, Edinburgh, St Andrews and in Dundee where the book was written. The \"On Growth and Form 100\" website was set up in late 2016 to map all of this activity.\n\n\n\n"}
{"id": "35289232", "url": "https://en.wikipedia.org/wiki?curid=35289232", "title": "Perles configuration", "text": "Perles configuration\n\nIn geometry, the Perles configuration is a configuration of 9 points and 9 lines that can be realized in the Euclidean plane but for which every realization has at least one irrational number as one of its coordinates. It is not a projective configuration, however, because its points and lines do not all have the same number of incidences as each other. It was introduced by Micha Perles in the 1960s.\n\nOne way of constructing the Perles configuration is to start with a regular pentagon and its five diagonals, which form the sides of a smaller regular pentagon within the initial one. The nine points of the configuration consist of four out of the five vertices of each pentagon and the shared center of the two pentagons; the two missing pentagon vertices are chosen to be collinear with the center. The nine lines of the configuration consist of the five lines that are diagonals of the outer pentagon and sides of the inner pentagon, and the four lines that pass through the center and through corresponding pairs of vertices from the two pentagons.\n\nEvery realization of this configuration in the real projective plane is equivalent, under a projective transformation, to a realization constructed in this way from a regular pentagon. Therefore, in every realization, there are four points having the same cross-ratio as the cross-ratio of the four collinear points in the realization derived from the regular pentagon. But, these four points have formula_1 as their cross-ratio, where formula_2 is the golden ratio, an irrational number. Every four collinear points with rational coordinates have a rational cross ratio, so the Perles configuration cannot be realized by rational points. Branko Grünbaum has conjectured that every configuration that can be realized by irrational but not rational numbers has at least nine points; if so, the Perles configuration would be the smallest possible irrational configuration of points and lines.\n\nPerles used his configuration to construct an eight-dimensional convex polytope with twelve vertices that can similarly be realized with real coordinates but not with rational coordinates. Ernst Steinitz's proof of Steinitz's theorem can be used to show that every three-dimensional polytope can be realized with rational coordinates, but it is now known that there exist irrational polytopes in four dimensions.\n\n"}
{"id": "17094227", "url": "https://en.wikipedia.org/wiki?curid=17094227", "title": "Poincaré space", "text": "Poincaré space\n\nIn algebraic topology, a Poincaré space is an \"n\"-dimensional topological space with a distinguished element \"µ\" of its \"n\"th homology group such that taking the cap product with an element of the \"k\"th cohomology group yields an isomorphism to the (\"n\" − \"k\")th homology group. The space is essentially one for which Poincaré duality is valid; more precisely, one whose singular chain complex forms a Poincaré complex with respect to the distinguished element \"µ\".\n\nFor example, any closed, orientable, connected manifold \"M\" is a Poincaré space, where the distinguished element is the fundamental class formula_1\n\nPoincaré spaces are used in surgery theory to analyze and classify manifolds. Not every Poincaré space is a manifold, but the difference can be studied, first by having a normal map from a manifold, and then via obstruction theory.\n\nSometimes, \"Poincaré space\" means a homology sphere with non-trivial fundamental group—for instance, the Poincaré dodecahedral space in 3 dimensions.\n\n"}
{"id": "3977272", "url": "https://en.wikipedia.org/wiki?curid=3977272", "title": "Pointwise product", "text": "Pointwise product\n\nThe pointwise product of two functions is another function, obtained by multiplying the image of the two functions at each value in the domain. If \"f\" and \"g\" are both functions with domain \"X\" and codomain \"Y\", and elements of \"Y\" can be multiplied (for instance, \"Y\" could be some set of numbers), then the pointwise product of \"f\" and \"g\" is another function from \"X\" to \"Y\" which maps \"x\" ∈ \"X\" to \"f\"(\"x\")\"g\"(\"x\").\n\nLet \"X\" and \"Y\" be sets, and let multiplication be defined in \"Y\"—that is, for each \"y\" and \"z\" in \"Y\" let the product\nbe well-defined. Let \"f\" and \"g\" be functions . Then the pointwise product is defined by\n\nfor each \"x\" in \"X\". In the same manner in which the binary operator ⋅ is omitted from products, we say that .\n\nThe most common case of the pointwise product of two functions is when the codomain is a ring (or field), in which multiplication is well-defined. \n\nLet \"X\" be a set and let \"R\" be a ring. Since addition and multiplication are defined in \"R\", we can construct an algebraic structure known as an algebra out of the functions from \"X\" to \"R\" by defining addition, multiplication, and scalar multiplication of functions to be done pointwise. \n\nIf \"R\" denotes the set of functions from \"X\" to \"R\", then we say that if \"f\", \"g\" are elements of \"R\", then \"f\" + \"g\", \"fg\", and \"rf\", the last of which is defined by\n\nfor all \"r\" in \"R\", are all elements of \"R\".\n\nIf both \"f\" and \"g\" have as their domain all possible assignments of a set of discrete variables, then their pointwise product is a function whose domain is constructed by all possible assignments of the union of both sets. The value of each assignment is calculated as the product of the values of both functions given to each one the subset of the assignment that is in its domain.\n\nFor example, given the function \"f\"() for the boolean variables \"p\" and \"q\", and \"f\"() for the boolean variables \"q\" and \"r\", both with the range in R, the pointwise product of \"f\"() and \"f\"() is shown in the next table:\n\n"}
{"id": "31864145", "url": "https://en.wikipedia.org/wiki?curid=31864145", "title": "Principal subalgebra", "text": "Principal subalgebra\n\nIn mathematics, a principal subalgebra of a complex simple Lie algebra is a 3-dimensional simple subalgebra whose non-zero elements are regular.\n\nA finite-dimensional complex simple Lie algebra has a unique conjugacy class of principal subalgebras, each of which is the span of an sl-triple.\n"}
{"id": "12792547", "url": "https://en.wikipedia.org/wiki?curid=12792547", "title": "Proof that π is irrational", "text": "Proof that π is irrational\n\nIn the 1760's, Johann Heinrich Lambert proved that the number (pi) is irrational: that is, it cannot be expressed as a fraction \"a\"/\"b\", where \"a\" is an integer and \"b\" is a non-zero integer. In the 19th century, Charles Hermite found a proof that requires no prerequisite knowledge beyond basic calculus. Three simplifications of Hermite's proof are due to Mary Cartwright, Ivan Niven, and Nicolas Bourbaki. Another proof, which is a simplification of Lambert's proof, is due to Miklós Laczkovich.\n\nIn 1882, Ferdinand von Lindemann proved that is not just irrational, but transcendental as well.\n\nIn 1761, Lambert proved that is irrational by first showing that this continued fraction expansion holds:\n\nThen Lambert proved that if \"x\" is non-zero and rational then this expression must be irrational. Since tan(/4) = 1, it follows that /4 is irrational and therefore that is irrational. A simplification of Lambert's proof is given below.\nThis proof uses the characterization of as the smallest positive number whose half is a zero of the cosine function and it actually proves that is irrational. As in many proofs of irrationality, the argument proceeds by reductio ad absurdum.\n\nConsider the sequences (\"A\") and (\"U\") of functions from R into R thus defined:\n\nUsing induction we can prove that\n\nand therefore we have:\n\nSo\n\nwhich is equivalent to\n\nUsing the definition of the sequence and employing induction we can show that \n\nwhere \"P\" and \"Q\" are polynomial functions with integer coefficients and the degree of \"P\" is smaller than or equal to ⌊\"n\"/2⌋. In particular, \"A\"(/2) = \"P\"(/4).\n\nHermite also gave a closed expression for the function \"A\", namely\n\nHe did not justify this assertion, but it can be proved easily. First of all, this assertion is equivalent to\n\nProceeding by induction, take \"n\" = 0.\n\nand, for the inductive step, consider any \"n\" ∈ Z. If\n\nthen, using integration by parts and Leibniz's rule, one gets\n\nIf /4 = \"p\"/\"q\", with \"p\" and \"q\" in N, then, since the coefficients of \"P\" are integers and its degree is smaller than or equal to ⌊\"n\"/2⌋, \"q\"\"P\"(/4) is some integer \"N\". In other words,\n\nBut this number is clearly greater than 0. On the other hand, the limit of this quantity as n goes to infinity is zero, and so, if \"n\" is large enough, \"N\" < 1. Thereby, a contradiction is reached.\n\nHermite did not present his proof as an end in itself but as an afterthought within his search for a proof of the transcendence of . He discussed the recurrence relations to motivate and to obtain a convenient integral representation. Once this integral representation is obtained, there are various ways to present a succinct and self-contained proof starting from the integral (as in Cartwright's, Bourbaki's or Niven's presentations), which Hermite could easily see (as he did in his proof of the transcendence of \"e\").\n\nMoreover, Hermite's proof is closer to Lambert's proof than it seems. In fact, \"A\"(\"x\") is the \"residue\" (or \"remainder\") of Lambert's continued fraction for tan(\"x\").\n\nHarold Jeffreys wrote that this proof was set as an example in an exam at Cambridge University in 1945 by Mary Cartwright, but that she had not traced its origin.\n\nConsider the integrals\n\nwhere \"n\" is a non-negative integer.\n\nTwo integrations by parts give the recurrence relation\n\nIf\n\nthen this becomes\n\nFurthermore, \"J\"(\"x\") = 2sin(\"x\") and \"J\"(\"x\") = −4\"x\" cos(\"x\") + 4sin(\"x\"). Hence for all \"n\" ∈ Z,\n\nwhere \"P\"(\"x\") and \"Q\"(\"x\") are polynomials of degree ≤ \"n\", and with integer coefficients (depending on \"n\").\n\nTake \"x\" = /2, and suppose if possible that /2 = \"a\"/\"b\", where \"a\" and \"b\" are natural numbers (i.e., assume that is rational). Then\n\nThe right side is an integer. But 0 < \"I\"(/2) < 2 since the interval [−1, 1] has length 2 and the function that is being integrated takes only values between 0 and 1. On the other hand,\n\nHence, for sufficiently large \"n\"\n\nthat is, we could find an integer between 0 and 1. That is the contradiction that follows from the assumption that is rational.\n\nThis proof is similar to Hermite's proof. Indeed,\n\nHowever, it is clearly simpler. This is achieved by omitting the inductive definition of the functions \"A\" and taking as a starting point their expression as an integral.\n\nThis proof uses the characterization of as the smallest positive zero of the sine function.\n\nSuppose that is rational, i.e. for some integers \"a\" and , which may be taken without loss of generality to be positive. Given any positive integer \"n\", we define the polynomial function:\n\nand, for each \"x\" ∈ ℝ let\n\nClaim 1: is an integer.\n\nProof:\nExpanding \"f\" as a sum of monomials, the coefficient of \"x\" is a number of the form where \"c\" is an integer, which is 0 if . Therefore, is 0 when and it is equal to if ; in each case, is an integer and therefore \"F\"(0) is an integer.\n\nOn the other hand, = \"f\"(\"x\") and so = for each non-negative integer \"k\". In particular, = Therefore, is also an integer and so \"F\"() is an integer (in fact, it is easy to see that \"F\"() = \"F\"(0), but that is not relevant to the proof). Since \"F\"(0) and \"F\"() are integers, so is their sum.\n\nClaim 2:\n\nProof: Since is the zero polynomial, we have\n\nThe derivatives of the sine and cosine function are given by sin' = cos and cos' = −sin. Hence the product rule implies\n\nBy the fundamental theorem of calculus\n\nSince and (here we use the above-mentioned characterization of as a zero of the sine function), Claim 2 follows.\n\nConclusion: Since and for (because is the \"smallest\" positive zero of the sine function), Claims 1 and 2 show that is a \"positive\" integer. Since and for , we have, by the original definition of \"f\",\n\nwhich is smaller than 1 for large \"n\", hence for these \"n\", by Claim 2. This is impossible for the positive integer .\n\nThe above proof is a polished version, which is kept as simple as possible concerning the prerequisites, of an analysis of the formula\n\nwhich is obtained by integrations by parts. Claim 2 essentially establishes this formula, where the use of \"F\" hides the iterated integration by parts. The last integral vanishes because is the zero polynomial. Claim 1 shows that the remaining sum is an integer.\n\nNiven's proof is closer to Cartwright's (and therefore Hermite's) proof than it appears at first sight. In fact,\n\nTherefore, the substitution \"xz\" = \"y\" turns this integral into \n\nIn particular,\n\nAnother connection between the proofs lies in the fact that Hermite already mentions that if \"f\" is a polynomial function and\n\nthen\n\nfrom which it follows that\n\nBourbaki's proof is outlined as an exercise in his calculus treatise. For each natural number \"b\" and each non-negative integer \"n\", define\n\nSince \"A\"(\"b\") is the integral of a function which defined on [0,] that takes the value 0 on 0 and on and which is greater than 0 otherwise, \"A\"(\"b\") > 0. Besides, for each natural number \"b\", \"A\"(\"b\") < 1 if \"n\" is large enough, because\n\nand therefore\n\nOn the other hand, recursive integration by parts allows us to deduce that, if \"a\" and \"b\" are natural number such that  = \"a\"/\"b\" and \"f\" is the polynomial function from [0,] into R defined by\n\nthen:\n\nThis last integral is 0, since \"f\" is the null function (because \"f\" is a polynomial function of degree 2\"n\"). Since each function \"f\" (with ) takes integer values on 0 and on and since the same thing happens with the sine and the cosine functions, this proves that \"A\"(\"b\") is an integer. Since it is also greater than 0, it must be a natural number. But it was also proved that \"A\"(\"b\") < 1 if \"n\" is large enough, thereby reaching a contradiction.\n\nThis proof is quite close to Niven's proof, the main difference between them being the way of proving that the numbers \"A\"(\"b\") are integers.\n\nMiklós Laczkovich's proof is a simplification of Lambert's original proof. He considers the functions\n\nThese functions are clearly defined for all \"x\" ∈ R. Besides\n\nClaim 1: The following recurrence relation holds:\n\nProof: This can be proved by comparing the coefficients of the powers of \"x\".\n\nClaim 2: For each \"x\" ∈ R, formula_46\n\nProof: In fact, the sequence \"x\"/\"n\"! is bounded (since it converges to 0) and if \"C\" is an upper bound and if \"k\" > 1, then\n\nClaim 3: If \"x\" ≠ 0 and if \"x\" is rational, then\n\nProof: Otherwise, there would be a number \"y\" ≠ 0 and integers \"a\" and \"b\" such that \"f\"(\"x\") = \"ay\" and \"f\"(\"x\") = \"by\". In order to see why, take \"y\" = \"f\"(\"x\"), \"a\" = 0 and \"b\" = 1 if \"f\"(\"x\") = 0; otherwise, choose integers \"a\" and \"b\" such that \"f\"(\"x\")/\"f\"(\"x\") = \"b\"/\"a\" and define \"y\" = \"f\"(\"x\")/\"a\" = \"f\"(\"x\")/\"b\". In each case, \"y\" cannot be 0, because otherwise it would follow from claim 1 that each \"f\"(\"x\") (\"n\" ∈ N) would be 0, which would contradict claim 2. Now, take a natural number \"c\" such that all three numbers \"bc\"/\"k\", \"ck\"/\"x\" and \"c\"/\"x\" are integers and consider the sequence\n\nThen\n\nOn the other hand, it follows from claim 1 that\n\nwhich is a linear combination of \"g\" and \"g\" with integer coefficients. Therefore, each \"g\" is an integer multiple of \"y\". Besides, it follows from claim 2 that each \"g\" is greater than 0 (and therefore that \"g\" ≥ |\"y\"|) if \"n\" is large enough and that the sequence of all \"g\" converges to 0. But a sequence of numbers greater than or equal to |\"y\"| cannot converge to 0.\n\nSince \"f\"(/4) = cos(/2) = 0, it follows from claim 3 that /16 is irrational and therefore that is irrational.\n\nOn the other hand, since\n\nanother consequence of Claim 3 is that, if \"x\" ∈ Q \\ {0}, then tan \"x\" is irrational.\n\nLaczkovich's proof is really about the hypergeometric function. In fact, \"f\"(\"x\") = \"F\"(k; −\"x\") and Gauss found a continued fraction expansion of the hypergeometric function using its functional equation. This allowed Laczkovich to find a new and simpler proof of the fact that the tangent function has the continued fraction expansion that Lambert had discovered.\n\nLaczkovich's result can also be expressed in . In fact, Γ(\"k\")\"J\"(2\"x\") = \"x\"\"f\"(\"x\"). So Laczkovich's result is equivalent to: If \"x\" ≠ 0 and if \"x\" is rational, then\n\n"}
{"id": "7153600", "url": "https://en.wikipedia.org/wiki?curid=7153600", "title": "Quasicontraction semigroup", "text": "Quasicontraction semigroup\n\nIn mathematical analysis, a \"C\"-semigroup Γ(\"t\"), \"t\" ≥ 0, is called a quasicontraction semigroup if there is a constant \"ω\" such that ||Γ(\"t\")|| ≤ exp(\"ωt\") for all \"t\" ≥ 0. Γ(\"t\") is called a contraction semigroup if ||Γ(\"t\")|| ≤ 1 for all \"t\" ≥ 0.\n\n"}
{"id": "1590390", "url": "https://en.wikipedia.org/wiki?curid=1590390", "title": "Quasiperiodic motion", "text": "Quasiperiodic motion\n\nIn mathematics and theoretical physics, quasiperiodic motion is in rough terms the type of motion executed by a dynamical system containing a finite number (two or more) of incommensurable frequencies.\n\nThat is, if we imagine that the phase space is modelled by a torus \"T\" (that is, the variables are periodic like angles), the trajectory of the system is modelled by a curve on \"T\" that wraps around the torus without ever exactly coming back on itself.\n\nA quasiperiodic function on the real line is the type of function (continuous, say) obtained from a function on \"T\", by means of a curve\n\nwhich is linear (when lifted from \"T\" to its covering Euclidean space), by composition. It is therefore oscillating, with a finite number of underlying frequencies. (NB the sense in which theta functions and the Weierstrass zeta function in complex analysis are said to have quasi-periods with respect to a period lattice is something distinct from this.)\n\nThe theory of almost periodic functions is, roughly speaking, for the same situation but allowing \"T\" to be a torus with an infinite number of dimensions.\n\n"}
{"id": "21263381", "url": "https://en.wikipedia.org/wiki?curid=21263381", "title": "SWAT and WADS conferences", "text": "SWAT and WADS conferences\n\nWADS, the Algorithms and Data Structures Symposium, is an international academic conference in the field of computer science, focusing on algorithms and data structures. WADS is held every second year, usually in Canada and always in North America. It is held in alternation with its sister conference, the Scandinavian Symposium and Workshops on Algorithm Theory (SWAT), which is usually held in Scandinavia and always in Northern Europe. Historically, the proceedings of both conferences were published by Springer Verlag through their Lecture Notes in Computer Science series. Springer continues to publish WADS proceedings, but starting in 2016, SWAT proceedings are now published by Dagstuhl through their Leibniz International Proceedings in Informatics.\n\nThe first SWAT took place in 1988, in Halmstad, Sweden. The first WADS was organised one year later, in 1989, in Ottawa, Ontario, Canada. Until 2007, WADS was known as the Workshop on Algorithms and Data Structures, and until 2008, SWAT was known as the Scandinavian Workshop on Algorithm Theory.\n\n\n\n"}
{"id": "3002956", "url": "https://en.wikipedia.org/wiki?curid=3002956", "title": "Superdense coding", "text": "Superdense coding\n\nIn quantum information theory, superdense coding is a quantum communication protocol to transmit two classical bits of information (i.e., either 00, 01, 10 or 11) from a sender (often called Alice) to a receiver (often called Bob), by sending only one qubit from Alice to Bob, under the assumption of Alice and Bob pre-sharing an entangled state. By performing one of four quantum gate operations on the (entangled) qubit she possesses, Alice can prearrange the measurement Bob makes. After receiving Alice's qubit, operating on the pair and measuring both, Bob has two classical bits of information. If Alice and Bob do not already share entanglement before the protocol begins, then it is impossible to send two classical bits using 1 qubit, as this would violate Holevo's theorem.\n\nSuperdense coding is a the underlying principle of secure quantum secret coding. The necessity of having both qubits to decode the information being sent eliminates the risk of eavesdroppers intercepting messages.\n\nIt can be thought of as the opposite of quantum teleportation, in which one transfers one qubit from Alice to Bob by communicating two classical bits, as long as Alice and Bob have a pre-shared Bell pair.\n\nSuppose Alice wants to send two classical bits of information (00, 01, 10, or 11) to Bob using qubits (instead of classical bits). To do this, an entangled state (e.g. a Bell state) is prepared using a Bell circuit or gate by Charlie, a third person. Charlie then sends one of these qubits (in the Bell state) to Alice and the other to Bob. Once Alice obtains her qubit in the entangled state, she applies a certain quantum gate to her qubit depending on which two-bit message (00, 01, 10 or 11) she wants to send to Bob. Her entangled qubit is then sent to Bob who, after applying the appropriate quantum gate and making a measurement, can retrieve the classical two-bit message. Alice must tell Bob which gate to apply after he receives the entangled qubit in order to obtain the correct classical bits.\n\nThe protocol can be split into five different steps: preparation, sharing, encoding, sending, and decoding. \n\nThe protocol starts with the preparation of an entangled state, which is later shared between Alice and Bob. Suppose the following Bell state\n\nwhere formula_2 denotes the tensor product, is prepared. Note: we can omit the tensor product symbol formula_3and write the Bell state as\n\nAfter the preparation of the Bell state formula_5, the qubit denoted by subscript \"A\" is sent to Alice and the qubit denoted by subscript \"B\" is sent to Bob (note: this is the reason these states have subscripts). At this point, Alice and Bob may be in completely different locations (which might be very distant from each other).\n\nThere may be a long period of time between the preparation and sharing of the entangled state formula_5 and the rest of the steps in the procedure.\n\nBy applying a quantum gate to her qubit locally, Alice can transform the entangled state formula_5 into any of the four Bell states (including, of course, formula_5). Note that this process cannot \"break\" the entanglement between the two qubits.\n\nLet's now describe which operations Alice needs to perform on her entangled qubit, depending on which classical two-bit message she wants to send to Bob. We'll later see why these specific operations are performed. There are four cases, which correspond to the four possible two-bit strings that Alice may want to send.\n\n1. If Alice wants to send the classical two-bit string 00 to Bob, then she applies the identity quantum gate, formula_9, to her qubit, so that it remains unchanged. The resultant entangled state is then\n\nIn other words, the entangled state shared between Alice and Bob has not changed, i.e. it is still formula_5. The notation formula_12 is also used to remind us of the fact that Alice wants to send the two-bit string 00.\n\n2. If Alice wants to send the classical two-bit string 01 to Bob, then she applies the quantum \"NOT\" (or \"bit-flip\") gate, formula_13, to her qubit, so that the resultant entangled quantum state becomes\n\n3. If Alice wants to send the classical two-bit string 10 to Bob, then she applies the quantum \"phase-flip\" gate formula_15 to her qubit, so the resultant entangled state becomes\n\n4. If, instead, Alice wants to send the classical two-bit string 11 to Bob, then she applies the quantum gate formula_17 to her qubit, so that the resultant entangled state becomes\n\nThe matrices formula_19 and formula_20 are two of the Pauli matrices. The quantum states formula_5, formula_22, formula_23 and formula_24 (or, respectively, formula_25 and formula_26) are the Bell states.\n\nAfter having performed one of the operations described above, Alice can send her entangled qubit to Bob using a quantum network through some conventional physical medium.\n\nIn order for Bob to find out which classical bits Alice sent he will perform the CNOT unitary operation, with A as control qubit and B as target qubit. Then, he will perform formula_27 unitary operation on the entangled qubit A. In other words, the Hadamard quantum gate H is only applied to A (see the figure above).\n\n\nThese operations performed by Bob can be seen as a measurement which projects the entangled state onto one of the four two-qubit basis vectors formula_36 or formula_37 (as you can see from the outcomes and the example below).\n\nFor example, if the resultant entangled state (after the operations performed by Alice) was formula_38, then a CNOT with A as control bit and B as target bit will change formula_30 to become formula_40. Now, the Hadamard gate is applied only to A, to obtain\n\nformula_41\n\nFor simplicity, let's get rid of the subscripts, so we have\n\nformula_42\n\nNow, Bob has the basis state formula_43, so he knows that Alice wanted to send the two-bit string 01.\n\nSuperdense coding is a form of secure quantum communication. If an eavesdropper, which may be referred to as Eve, intercepts Alice's qubit en route to Bob, all that is obtained by Eve is part of an entangled state. Without Access to Bob's qubit, Eve is unable to get any information from Alice's qubit. A third party is unable to eavesdrop on information being communicated through superdense coding and an attempt to measure either qubit would collapse the state of that qubit and alert Bob and Alice.\n\nGeneral dense coding schemes can be formulated in the language used to describe quantum channels. Alice and Bob share a maximally entangled state \"ω\". Let the subsystems initially possessed by Alice and Bob be labeled 1 and 2, respectively. To transmit the message \"x\", Alice applies an appropriate channel\n\non subsystem 1. On the combined system, this is effected by\n\nwhere \"I\" denotes the identity map on subsystem 2. Alice then sends her subsystem to Bob, who performs a measurement on the combined system to recover the message. Let the \"effects\" of Bob's measurement be \"F\". The probability that Bob's measuring apparatus registers the message \"y\" is\n\nTherefore, to achieve the desired transmission, we require that\n\nwhere \"δ\" is the Kronecker delta.\n\n"}
{"id": "52897818", "url": "https://en.wikipedia.org/wiki?curid=52897818", "title": "Univariate (statistics)", "text": "Univariate (statistics)\n\nUnivariate is a term commonly used in statistics to describe a type of data which consists of observations on only a single characteristic or attribute. A simple example of univariate data would be the salaries of workers in industry. Like all the other data, univariate data can be visualized using graphs, images or other analysis tools after the data is measured, collected, reported, and analyzed.\n\nSome univariate data consists of numbers (such as the height of 65 inches or the weight of 100 pounds), while others are nonnumerical (such as eye colors of brown or blue). Generally, the terms categorical univariate data and numerical univariate data are used to distinguish between these types.\n\nCategorical univariate data consist non-numerical observations that may be placed in categories. It includes labels or names used to identify an attribute of each element. Categorical univariate data usually use either nominal or ordinal scale of measurement.\n\nNumerical univariate data consist observations that are numbers. They are obtained using either interval or ratio scale of measurement. This type of univariate data can be classified even further into two subcategories: discrete and continuous. A numerical univariate data is discrete if the set of all possible values is finite or countably infinite. Discrete univariate data are usually associated with counting (such as the number of books read by a person). A numerical univariate data is continuous if the set of all possible values is an interval of numbers. Continuous univariate data are usually associated with measuring (such as the weights of people).\n\nUnivariate analysis is the simplest form of analyzing data. Uni means one, so in other words the data has only one variable. Univariate data requires to analyze each variable separately. Data is gathered for the purpose of answering a question, or more specifically, a research question. Univariate data does not answer research questions about relationships between variables, but rather it is used to describe one characteristic or attribute that varies from observation to observation. Usually there are two purposes that a researcher can look for. The first one is to answer a research question with descriptive study and the second one is to get knowledge about how attribute varies with individual effect of a variable in Regression analysis. There are some ways to describe patterns found in univariate data which include graphical methods, measures of central tendency and measures of variability.\n\nThe most frequently used graphical illustrations for univariate data are:\n\nFrequency is how many times a number occurs. The frequency of an observation in statistics tells us the number of times the observation occurs in the data. For example, in the following list of numbers {\"1, 2, 3, 4, 6, 9, 9, 8, 5, 1, 1, 9, 9, 0, 6, 9\"}, the frequency of the number 9 is 5 (because it occurs 5 times).\n\nBar chart is a graph consisting of rectangular bars. There bars actually represents number or percentage of observations of existing categories in a variable. The length or height of bars gives a visual representation of the proportional differences among categories.\n\nHistograms are used to estimate distribution of the data, with the frequency of values assigned to a value range called a bin.\n\nPie chart is a circle divided into portions that represent the relative frequencies or percentages of a population or a sample belonging to different categories.\n\nCentral tendency is one of the most common numerical descriptive measures. It's used to estimate the central location of the univariate data by the calculation of mean, median and mode. Each of these calculation has its own advantages and limitations.The mean has the advantage that its calculation includes each value of the data set, but it is particularly susceptible to the influence of outliers. The median is a better measure when the data set contains outliers. The mode is simple to locate. The important thing is that it's not restricted to using only one of these measure of central tendency. If the data being analyzed is categorical, then the only measure of central tendency that can be used is the mode. However, if the data is numerical in nature (ordinal or interval/ratio) then the mode, median, or mean can all be used to describe the data. Using more than one of these measures provides a more accurate descriptive summary of central tendency for the univariate.\n\nA measure of variability or dispersion (deviation from the mean) of a univariate data set can reveal the shape of a univariate data distribution more sufficiently. It will provide some information about the variation among data values. The measures of variability together with the measures of central tendency give a better picture of the data than the measures of central tendency alone. The three most frequently used measures of variability are range, variance and standard deviation. The appropriateness of each measure would depend on the type of data, the shape of the distribution of data and which measure of central tendency are being used. If the data is categorical, then there is no measure of variability to report. For data that is numerical, all three measures are possible. If the distribution of data is symmetrical, then the measures of variability are usually the variance and standard deviation. However, if the data are skewed, then the measure of variability that would be appropriate for that data set is the range.\n\nUnivariate distribution is a dispersal type of a single random variable described either with a probability mass function (pmf) for discrete probability distribution, or probability density function (pdf) for continuous probability distribution. It is not to be confused with multivariate distribution.\n\nUniform distribution (discrete) <br>\nBernoulli distribution <br>\nBinomial distribution <br>\nGeometric distribution <br>\nNegative binomial distribution <br>\nPoisson distribution <br>\nHypergeometric distribution <br>\nZeta distribution\n\nUniform distribution (continuous) <br>\nNormal distribution <br>\nGamma distribution <br>\nExponential distribution <br>\nWeibull distribution <br>\nCauchy distribution <br>\nBeta distribution\n\n"}
{"id": "23400470", "url": "https://en.wikipedia.org/wiki?curid=23400470", "title": "Weighted Voronoi diagram", "text": "Weighted Voronoi diagram\n\nIn mathematics, a weighted Voronoi diagram in \"n\" dimensions is a special case of a Voronoi diagram. The Voronoi cells in a weighted Voronoi diagram are defined in terms of a distance function. The distance function may specify the usual Euclidean distance, or may be some other, special distance function. Usually, the distance function is a function of the generator points' weights.\n\nThe multiplicatively weighted Voronoi diagram is defined when the distance between points is multiplied by positive weights. In the plane under the ordinary Euclidean distance, the multiplicatively weighted Voronoi diagram is also called circular Dirichlet tessellation and its edges are circular arc and straight line segments. A Voronoi cell may be non-convex, disconnected and may have holes. This diagram arises, e.g., as a model of crystal growth, where crystals from different points may grow with different speed. Since crystals may grow in empty space only and are continuous objects, a natural variation is the crystal Voronoi diagram, in which the cells are defined somewhat differently.\n\nThe additively weighted Voronoi diagram is defined when positive weights are subtracted from the distances between points. In the plane under the ordinary Euclidean distance this diagram is also known as the hyperbolic Dirichlet tessellation and its edges are hyperbolic arc and straight line segments.\n\nThe power diagram is defined when weights are added to the squared Euclidean distance. It can also be defined using the power distance defined from a set of circles.\n\n"}
{"id": "53784812", "url": "https://en.wikipedia.org/wiki?curid=53784812", "title": "William Edwin Hamilton", "text": "William Edwin Hamilton\n\nWilliam Edwin Hamilton (10 May 1834 – 17 March 1902) was the elder son of the Irish mathematician Sir William Rowan Hamilton and Lady Helen Maria Hamilton Bayly.\n\nWilliam Edwin Hamilton was born at Dunsink Observatory, in the civil parish of Castleknock, Dublin. He graduated in 1857 from Trinity College Dublin and became a civil engineer, working for some years as a surveyor for railway purposes.\n\nIn 1862 Hamilton left for Nicaragua with his aunt Sydney Hamilton on a venture scheme anticipating a canal project across the Isthmus of Darien. Realizing the futility of this venture, and not used to the diet and the climate, in 1864 he returned to the Observatory and lived with his parents until his father's death in 1865.\n\nIn 1843 Hamilton's father had discovered the quaternions, a four-dimensional number system that extends the complex numbers, and he had published \"Lectures on Quaternions\" in 1853. From 1858 until his death in 1865 he worked on a second book, \"Elements of Quaternions\", which was nearly finished when he died. Hamilton's brother Archibald Henry Hamilton, a clergyman and executor of his father’s estate, being too much engaged in his clerical duties to undertake the task, asked Hamilton to bring the \"Elements of Quaternions\" to publication. Hamilton published the manuscript as his father had left it, removing \"a few typographical errors\" and adding a short preface in which he wrote: \"Shortly before my father’s death I had several conversations with him on the subject of the \"Elements\". In these he spoke of anticipated applications of quaternions to electricity, and to all questions in which the idea of polarity is involved — applications which he never in his own lifetime expected to be able to fully develop, bows to be reserved for the hands of another Ulysses.\"\n\nIn 1872 Hamilton emigrated to Canada where he became a journalist and an editor, working in Bracebridge, Ontario at E.F. Stephenson's \"Free Grant Gazette\", and as a Government Immigration Agent.\n\nIn his introduction to \"Guidebook and Atlas\" of Muskoka, Hamilton outlines the history of the region. The name he traces to Muska Ukee, or Musquakie, a leader of the Chippewa of Lakes Huron and Simcoe. He passes over the surveying by Henry Bayfield to the Free Grants Act of 1868, notes the efforts to organize as a county in Ontario, and the $2000 bonus and tax deferral given to Beardmore Brothers tannery to locate in Bracebridge. He promotes tourism to Muskoka and celebrates the local success. However rocky soil hindered agriculture, and the period was recalled in \"Hardscrabble: the High Cost of Free Land\". The \"Guidebook and Atlas\" was \"the last concerted effort to draw settlers to Muskoka.\" In \"Hardscrabble\" Williams writes: \"Eccentric was W. E. Hamilton, the scholar and newspaperman, with his pet snowy owl and birch bark accessories, holed up with his books above the \"Free Grant Gazette\".\"\n\nIn 1880 Hamilton finally settled in Chatham, where he was for some time editor of the \"Chatham Planet\". After having lost his editorship, in 1885 he started his own \"Market Guide\", \"a four-page, pink paper tabloid, ... in which he sold sufficient advertising to eke out a starved existence.\" For several years in the late 1880s Hamilton was an alcoholic, but according to Macfarlane he took Leslie Keeley's Gold Cure. He was cured, and became in his last years a \"kindly good-natured old Irishman,\" known for his 'amazing erudition.'\n\n\n"}
