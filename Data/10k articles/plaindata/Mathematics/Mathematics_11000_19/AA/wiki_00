{"id": "3642380", "url": "https://en.wikipedia.org/wiki?curid=3642380", "title": "165 (number)", "text": "165 (number)\n\n165 (one hundred [and] sixty-five) is the natural number following 164 and preceding 166.\n\n165 is:\n\n\n\n\n165 is also:\n\n\n"}
{"id": "8031773", "url": "https://en.wikipedia.org/wiki?curid=8031773", "title": "Analytic space", "text": "Analytic space\n\nAn analytic space is a generalization of an analytic manifold that allows singularities. An analytic space is a space that is locally the same as an analytic variety. They are prominent in the study of several complex variables, but they also appear in other contexts.\n\nFix a field \"k\" with a valuation. Assume that the field is complete and not discrete with respect to this valuation. For example, this includes R and C with respect to their usual absolute values, as well as fields of Puiseux series with respect to their natural valuations.\n\nLet \"U\" be an open subset of \"k\", and let \"f\", ..., \"f\" be a collection of analytic functions on \"U\". Denote by \"Z\" the common vanishing locus of \"f\", ..., \"f\", that is, let \"Z\" = { \"x\" | \"f\"(\"x\") = ... = \"f\"(\"x\") = 0 }. \"Z\" is an analytic variety.\n\nSuppose that the structure sheaf of \"U\" is formula_1. Then \"Z\" has a structure sheaf formula_2, where formula_3 is the ideal generated by \"f\", ..., \"f\". In other words, the structure sheaf of \"Z\" consists of all functions on \"U\" modulo the possible ways they can differ outside of \"Z\".\n\nAn analytic space is a locally ringed space formula_4 such that around every point \"x\" of \"X\", there exists an open neighborhood \"U\" such that formula_5 is isomorphic (as locally ringed spaces) to an analytic variety with its structure sheaf. Such an isomorphism is called a local model for \"X\" at \"x\".\n\nAn analytic mapping or morphism of analytic spaces is a morphism of locally ringed spaces.\n\nThis definition is similar to the definition of a scheme. The only difference is that for a scheme, the local models are spectra of rings, whereas for an analytic space, the local models are analytic varieties. Because of this, the basic theories of analytic spaces and of schemes are very similar. Furthermore, analytic varieties have much simpler behavior than arbitrary commutative rings (for example, analytic varieties are defined over fields and are always finite-dimensional), so analytic spaces behave very similarly to finite-type schemes over a field.\n\nEvery point in an analytic space has a local dimension. The dimension at \"x\" is found by choosing a local model at \"x\" and determining the local dimension of the analytic variety at the point corresponding to \"x\".\n\nEvery point in an analytic space has a tangent space. If \"x\" is a point of \"X\" and \"m\" is ideal sheaf of all functions vanishing at \"x\", then the cotangent space at \"x\" is . The tangent space is , the dual vector space to the cotangent space. Analytic mappings induce pushforward maps on tangent spaces and pullback maps on cotangent spaces.\n\nThe dimension of the tangent space at \"x\" is called the embedding dimension at \"x\". By looking at a local model it is easy to see that the dimension is always less than or equal to the embedding dimension.\n\nAn analytic space is called smooth at \"x\" if it has a local model at \"x\" which is an open subset of \"k\" for some \"n\". The analytic space is called smooth if it is smooth at every point, and in this case it is an analytic manifold. The subset of points at which an analytic space is not smooth is a closed analytic subset.\n\nAn analytic space is reduced if every local model for the space is defined by a radical sheaf of ideals. An analytic space \"X\" which isn't reduced has a reduction \"X\", a reduced analytic space with the same underlying topological space. There is a canonical morphism . Every morphism from \"X\" to a reduced analytic space factors through \"r\".\n\nAn analytic space is normal if every stalk of the structure sheaf is a normal ring (meaning an integrally closed integral domain). In a normal analytic space, the singular locus has codimension at least two. When \"X\" is a local complete intersection at \"x\", then \"X\" is normal at \"x\".\n\nNon-normal analytic spaces can be smoothed out into normal spaces in a canonical way. This construction is called the normalization. The normalization \"N\"(\"X\") of an analytic space \"X\" comes with a canonical map . Every dominant morphism from a normal analytic space to \"X\" factors through ν.\n\nAn analytic space is coherent if its structure sheaf formula_6 is a coherent sheaf. A coherent sheaf of formula_6-modules is called a coherent analytic sheaf. For example, on a coherent space, locally free sheaves and sheaves of ideals are coherent analytic sheaves.\n\nAnalytic spaces over algebraically closed fields are coherent. In the complex case, this is known as the Oka coherence theorem. This is not true over non-algebraically closed fields; there are examples of real analytic spaces that are not coherent.\n\nIn some situations, the concept of an analytic space is too restrictive. This is often because the ground field has additional structure that is not captured by analytic sets. In these situations, there are generalizations of analytic spaces which allow more flexibility in the local model spaces.\n\nFor example, over the real numbers, consider the circle . The circle is an analytic subset of the analytic space R. But its projection onto the \"x\"-axis is the closed interval , which is not an analytic set. Therefore the image of an analytic set under an analytic map is not necessarily an analytic set. This can be avoided by working with subanalytic sets, which are much less rigid than analytic sets but which are not defined over arbitrary fields. The corresponding generalization of an analytic space is a subanalytic space. (However, under mild point-set topology hypotheses, it turns out that subanalytic spaces are essentially equivalent to subanalytic sets.)\n\n"}
{"id": "57341097", "url": "https://en.wikipedia.org/wiki?curid=57341097", "title": "Anne Broadbent", "text": "Anne Broadbent\n\nAnne Lise Broadbent is a mathematician at the University of Ottawa who won the 2016 Aisenstadt Prize for her research in quantum computing, quantum cryptography, and quantum information.\n\nBroadbent was a student of Alain Tapp and Gilles Brassard at the Université de Montréal, where she completed her Ph.D. in 2008 with a dissertation on \"Quantum nonlocality, cryptography and complexity\". After postdoctoral studies at the Institute for Quantum Computing at the University of Waterloo, she moved to Ottawa in 2014. She is an associate professor at the University of Ottawa and holds a University Research Chair there.\n\nAs well as the Aisenstadt Prize, Broadbent is the winner of the 2010 John Charles Polanyi Prize in Physics of the Council of Ontario Universities.\n"}
{"id": "57184342", "url": "https://en.wikipedia.org/wiki?curid=57184342", "title": "Basin-hopping", "text": "Basin-hopping\n\nIn applied mathematics, Basin-hopping is a global optimization technique that iterates by performing random perturbation of coordinates, performing local optimization, and accepting or rejecting new coordinates based on a minimized function value. The algorithm was described in 1997 by David J. Wales and Jonathan Doye.\n"}
{"id": "10218909", "url": "https://en.wikipedia.org/wiki?curid=10218909", "title": "Bootstrapping (finance)", "text": "Bootstrapping (finance)\n\nIn finance, bootstrapping is a method for constructing a (zero-coupon) fixed-income yield curve from the prices of a set of coupon-bearing products, e.g. bonds and swaps. A \"bootstrapped curve\", correspondingly, is one where the prices of the instruments used as an \"input\" to the curve, will be an exact \"output\", when these same instruments are valued using this curve. Here, the term structure of spot returns is recovered from the bond yields by solving for them recursively, by forward substitution: this iterative process is called the \"bootstrap method\". The usefulness of bootstrapping is that using only a few carefully selected zero-coupon products, it becomes possible to derive par swap rates (forward and spot) for \"all\" maturities given the solved curve.\n\nAs stated above, the selection of the input securities is important, given that there is a general lack of data points in a yield curve (there are only a fixed number of products in the market). More importantly, because the input securities have varying coupon frequencies, the selection of the input securities is critical. It makes sense to construct a curve of zero-coupon instruments from which one can price any yield, whether forward or spot, without the need of more external information. Note that certain assumptions (e.g. linear interpolation) will always be required.\n\nThe general methodology is as follows: (1) Define the set of yielding products - these will generally be coupon-bearing bonds; (2) Derive discount factors for the corresponding terms - these are the internal rates of return of the bonds; (3) 'Bootstrap' the zero-coupon curve, successively calibrating this curve such that it returns the prices of the inputs. A generically stated algorithm for the third step is as follows; for more detail see Yield curve#Construction of the full yield curve from market data. For each input instrument:\n\nWhen solved as described here, the curve will be arbitrage free in the sense that it is exactly consistent with the selected prices; see Rational pricing#Fixed income securities and Bond valuation#Arbitrage-free pricing approach. Note that some analysts will instead construct the curve such that it results in a best-fit \"through\" the input prices, as opposed to an exact match, using a method such as Nelson-Siegel.\n\nRegardless of approach, however, there is a requirement that the curve be arbitrage-free in a second sense: that all forward rates are positive. More sophisticated methods for the curve construction — whether targeting an exact- or a best-fit — will additionally target curve \"smoothness\" as an output, and the choice of interpolation method here, for rates not directly specified, will be important.\n\nA more detailed description of the forward substitution is as follows. For each stage of the iterative process, we are interested in deriving the n-year zero-coupon bond yield, also known as the internal rate of return of the zero-coupon bond. As there are no intermediate payments on this bond, (all the interest and principal is realized at the end of n years) it is sometimes called the n-year spot rate. To derive this rate we observe that the theoretical price of a bond can be calculated as the present value of the cash flows to be received in the future. In the case of swap rates, we want the par bond rate (Swaps are priced at par when created) and therefore we require that the present value of the future cash flows and principal be equal to 100%.\n\ntherefore\n\n\n\n"}
{"id": "14331851", "url": "https://en.wikipedia.org/wiki?curid=14331851", "title": "Boundedly generated group", "text": "Boundedly generated group\n\nIn mathematics, a group is called boundedly generated if it can be expressed as a finite product of cyclic subgroups. The property of bounded generation is also closely related with the congruence subgroup problem (see ).\n\nA group \"G\" is called \"boundedly generated\" if there exists a finite subset \"S\" of \"G\" and a positive integer \"m\" such that every element \"g\" of \"G\" can be represented as a product of at most \"m\" powers of the elements of \"S\":\n\nThe finite set \"S\" generates \"G\", so a boundedly generated group is finitely generated.\n\nAn equivalent definition can be given in terms of cyclic subgroups. A group \"G\" is called \"boundedly generated\" if there is a finite family \"C\", …, \"C\" of not necessarily distinct cyclic subgroups such that \"G\" = \"C\"…\"C\" as a set.\n\n\nA \"pseudocharacter\" on a discrete group \"G\" is defined to be a real-valued function \"f\" on a \"G\" such that \n\n\n\nSeveral authors have stated in the mathematical literature that it is obvious that finitely generated free groups are not boundedly generated. This section contains various obvious and less obvious ways of proving this. Some of the methods, which touch on bounded cohomology, are important because they are geometric rather than algebraic, so can be applied to a wider class of groups, for example Gromov-hyperbolic groups.\n\nSince for any \"n\" ≥ 2, the free group on 2 generators \"F\" contains the free group on \"n\" generators \"F\" as a subgroup of finite index (in fact \"n\" – 1), once one non-cyclic free group on finitely many generators is known to be not boundedly generated, this will be true for all of them. Similarly, since \"SL\"(Z) contains \"F\" as a subgroup of index 12, it is enough to consider \"SL\"(Z). In other words, to show that no \"F\" with \"n\" ≥ 2 has bounded generation, it is sufficient to prove this for one of them or even just for \"SL\"(Z) .\n\nSince bounded generation is preserved under taking homomorphic images, if a single finitely generated group with at least two generators is known to be not boundedly generated, this will be true for the free group on the same number of generators, and hence for all free groups. To show that no (non-cyclic) free group has bounded generation, it is therefore enough to produce one example of a finitely generated group which is not boundedly generated, and any finitely generated infinite torsion group will work. The existence of such groups constitutes Golod and Shafarevich's negative solution of the generalized Burnside problem in 1964; later, other explicit examples of infinite finitely generated torsion groups were constructed by Aleshin, Olshanskii, and Grigorchuk, using automata. Consequently, free groups of rank at least two are not boundedly generated.\n\nThe symmetric group \"S\" can be generated by two elements, a 2-cycle and an \"n\"-cycle, so that it is a quotient group of \"F\". On the other hand, it is easy to show that the maximal order \"M\"(\"n\") of an element in \"S\" satisfies\n\n(Edmund Landau proved the more precise asymptotic estimate log \"M\"(\"n\") ~ (\"n\" log \"n\")). In fact if the cycles in a cycle decomposition of a permutation have length \"N\", ..., \"N\" with \"N\" + ··· + \"N\" = \"n\", then the order of the permutation divides the product \"N\" ···\"N\", which in turn is bounded by (\"n\"/\"k\"), using the inequality of arithmetic and geometric means. On the other hand, (\"n\"/\"x\") is maximized when \"x\"=\"e\". If \"F\" could be written as a product of \"m\" cyclic subgroups, then necessarily \"n\"! would have to be less than or equal to \"M\"(\"n\") for all \"n\", contradicting Stirling's asymptotic formula.\n\nThere is also a simple geometric proof that \"G\" = \"SL\"(Z) is not boundedly generated. It acts by Möbius transformations on the upper half-plane H, with the Poincaré metric. Any compactly supported 1-form α on a fundamental domain of \"G\" extends uniquely to a \"G\"-invariant 1-form on H. If \"z\" is in H and γ is the geodesic from \"z\" to \"g\"(\"z\"), the function defined by\n\nsatisfies the first condition for a pseudocharacter since by the Stokes theorem\n\nwhere Δ is the geodesic triangle with vertices \"z\", \"g\"(\"z\") and \"h\"(\"z\"), and geodesics triangles have area bounded by π. The homogenized function\n\ndefines a pseudocharacter, depending only on α. As is well known from the theory of dynamical systems, any orbit (\"g\"(\"z\")) of a hyperbolic element \"g\" has limit set consisting of two fixed points on the extended real axis; it follows that the geodesic segment from \"z\" to \"g\"(\"z\") cuts through only finitely many translates of the fundamental domain. It is therefore easy to choose α so that \"f\" equals one on a given hyperbolic element and vanishes on a finite set of other hyperbolic elements with distinct fixed points. Since \"G\" therefore has an infinite-dimensional space of pseudocharacters, it cannot be boundedly generated.\n\nDynamical properties of hyperbolic elements can similarly be used to prove that any non-elementary Gromov-hyperbolic group is not boundedly generated.\n\nRobert Brooks gave a combinatorial scheme to produce pseudocharacters of any free group \"F\"; this scheme was later shown to yield\nan infinite-dimensional family of pseudocharacters (see ). Epstein and Fujiwara later extended these results to all non-elementary Gromov-hyperbolic groups.\n\nThis simple folklore proof uses dynamical properties of the action of hyperbolic elements on the Gromov boundary of a Gromov-hyperbolic group. For the special case of the free group \"F\", the boundary (or space of ends) can be identified with the space \"X\" of semi-infinite reduced words\n\nin the generators and their inverses. It gives a natural compactification of the tree, given by the Cayley graph with respect to the generators. A sequence of semi-infinite words converges to another such word provided that the initial segments agree after a certain stage, so that \"X\" is compact (and metrizable). The free group acts by left multiplication on the semi-infinite words. Moreover, any element \"g\" in \"F\" has exactly two fixed points \"g\", namely the reduced infinite words given by the limits of \"g\" as \"n\" tends to ±∞. Furthermore, \"g\"·\"w\" tends to \"g\" as \"n\" tends to ±∞ for any semi-infinite word \"w\"; and more generally if \"w\" tends to \"w\"≠ \"g\", then \"g\"·\"w\" tends to \"g\" as \"n\" tends to ∞.\n\nIf \"F\" were boundedly generated, it could be written as a product of cyclic groups \"C\"\ngenerated by elements \"h\". Let \"X\" be the countable subset given by the finitely many \"F\"-orbits\nof the fixed points \"h\", the fixed points of the \"h\" and all their conjugates. Since \"X\" is uncountable, there\nis an element of \"g\" with fixed points outside \"X\" and a point \"w\" outside \"X\" different from these fixed points. Then for\nsome subsequence (\"g\") of (\"g\")\n\nOn the one hand, by successive use of the rules for computing limits of the form \"h\"·\"w\", the limit of the right hand side applied to \"x\" is necessarily a fixed point of one of the conjugates of the \"h\"'s. On the other hand, this limit also must be \"g\", which is not one of these points, a contradiction.\n\n"}
{"id": "12545997", "url": "https://en.wikipedia.org/wiki?curid=12545997", "title": "British Social Attitudes Survey", "text": "British Social Attitudes Survey\n\nThe British Social Attitudes Survey (BSA) is an annual statistical survey conducted in Great Britain by National Centre for Social Research since 1983. The BSA involves in-depth interviews with over 3,300 respondents, selected using random probability sampling, focused on topics including newspaper readership, political parties and trust, public expenditure, welfare benefits, health care, childcare, poverty, the labour market and the workplace, education, charitable giving, the countryside, transport and the environment, the European Union, economic prospects, race, religion, civil liberties, immigration, sentencing and prisons, fear of crime and the portrayal of sex and violence in the media.\nThe survey is funded by the Gatsby Charitable Foundation, government departments, quasi-governmental bodies and other grant-giving organisations. The BSA was not conducted in 1988 and 1992, when funding was devoted instead to studies of voting behaviour and political attitudes in the British Election Study.\n\n\n"}
{"id": "541351", "url": "https://en.wikipedia.org/wiki?curid=541351", "title": "Champernowne constant", "text": "Champernowne constant\n\nIn mathematics, the Champernowne constant is a transcendental real constant whose decimal expansion has important properties. It is named after economist and mathematician D. G. Champernowne, who published it as an undergraduate in 1933.\n\nFor base 10, the number is defined by concatenating representations of successive integers:\n\nChampernowne constants can also be constructed in other bases, similarly, for example:\n\nThe Champernowne constants can be expressed exactly as infinite series:\n\nwhere formula_2 ceiling(formula_3), formula_4\nin base 10, formula_5 and formula_6 is the base of the constant. \n\nA slightly different expression is given by Eric W. Weisstein (MathWorld):\n\nwhere formula_8 floor(formula_3).\n\nThe Champernowne word or Barbier word is the sequence of digits of \"C\".\n\nA real number \"x\" is said to be normal if its digits in every base follow a uniform distribution: all digits being equally likely, all pairs of digits equally likely, all triplets of digits equally likely, etc. \"x\" is said to be normal in base \"b\" if its digits in base b follow a uniform distribution.\n\nIf we denote a digit string as [\"a\",\"a\"...], then, in base ten, we would expect strings [0],[1],[2]...,[9] to occur 1/10 of the time, strings [0,0],[0,1]...,[9,8],[9,9] to occur 1/100 of the time, and so on, in a normal number.\n\nChampernowne proved that formula_10 is normal in base ten, while Nakai and Shiokawa proved a more general theorem, a corollary of which is that formula_11 is normal for any base formula_6. It is an open problem whether formula_13 is normal in bases formula_14.\n\nThe simple continued fraction expansion of Champernowne's constant has been studied as well. Kurt Mahler showed that the constant is transcendental; therefore its continued fraction does not terminate (because it is not rational) and is aperiodic (because it is not an irreducible quadratic).\n\nThe terms in the continued fraction expansion exhibit very erratic behaviour, with huge terms appearing between many small ones. For example, in base 10,\n\nThe large number at position 19 has 166 digits, and the next very large term at position 41 of the continued fraction has 2504 digits. The fact that there are such large numbers as terms of the continued fraction expansion is equivalent to saying that the convergents obtained by stopping before these large numbers provide an exceptionally good approximation of the Champernowne constant. \n\nIt can be understood from infinite series expression of formula_10: for a specified formula_16 we can always approximate the sum over formula_17 by setting the upper limit to formula_18 instead of formula_19. Then we ignore the terms for higher formula_16. \n\nFor example, if we keep lowest order of n, it is equivalent to truncating before the 4th partial quotient, we obtain the partial sum \n\nwhich approximates Champernowne's constant with an error of about . While truncating just before the 18th partial quotient, we get the approximation to second order:\n\nwhich approximates Champernowne's constant with error approximately .\n\nThe irrationality measure of formula_10 is formula_24, and more generally formula_25 for any base formula_26.\n\n\n\n"}
{"id": "396068", "url": "https://en.wikipedia.org/wiki?curid=396068", "title": "Contact (mathematics)", "text": "Contact (mathematics)\n\nIn mathematics, two functions have a contact of order \"k\" if, at a point \"P\", they have the same value and \"k\" equal derivatives. This is an equivalence relation, whose equivalence classes are generally called jets. The point of osculation is also called the double cusp. Contact is a geometric notion; it can be defined algebraically as a valuation.\n\nOne speaks also of curves and geometric objects having \"k\"-th order contact at a point: this is also called \"osculation\" (i.e. kissing), generalising the property of being tangent. (Here the derivatives are considered with respect to arc length.) An osculating curve from a given family of curves is a curve that has the highest possible order of contact with a given curve at a given point; for instance a tangent line is an osculating curve from the family of lines, and has first-order contact with the given curve; an osculating circle is an osculating curve from the family of circles, and has second-order contact (same tangent angle and curvature), etc.\n\nContact forms are particular differential forms of degree 1 on odd-dimensional manifolds; see contact geometry. Contact transformations are related changes of coordinates, of importance in classical mechanics. See also Legendre transformation.\n\nContact between manifolds is often studied in singularity theory, where the type of contact are classified, these include the \"A\" series (\"A\": crossing, \"A\": tangent, \"A\": osculating, ...) and the umbilic or \"D\"-series where there is a high degree of contact with the sphere.\n\nTwo curves in the plane intersecting at a point \"p\" are said to have:\n\nFor each point \"S\"(\"t\") on a smooth plane curve \"S\", there is exactly one osculating circle, whose radius is the reciprocal of κ(\"t\"), the curvature of \"S\" at \"t\". Where curvature is zero (at an inflection point on the curve), the osculating circle is a straight line. The locus of the centers of all the osculating circles (also called \"centers of curvature\") is the evolute of the curve.\n\nIf the derivative of curvature κ'(\"t\") is zero, then the osculating circle will have 3rd-order contact and the curve is said to have a vertex. The evolute will have a cusp at the center of the circle. The sign of the second derivative of curvature determines whether the curve has a local minimum or maximum of curvature. All closed curves will have at least four vertices, two minima and two maxima (the four-vertex theorem).\n\nIn general a curve will not have 4th-order contact with any circle. However, 4th-order contact can occur generically in a 1-parameter family of curves, at a curve in the family where (as the parameter varies) two vertices (one maximum and one minimum) come together and annihilate. At such points the second derivative of curvature will be zero.\n\nIn econometrics it is also possible to consider circles which have two point contact with two points \"S\"(\"t\"), \"S\"(\"t\") on the curve. Such circles are \"bi-tangent\" circles. The centers of all bi-tangent circles form the symmetry set. The medial axis is a subset of the symmetry set. These sets have been used as a method of characterising the shapes of biological objects by Mario Henrique Simonsen, Brazilian and English econometrist.\n\n"}
{"id": "8302382", "url": "https://en.wikipedia.org/wiki?curid=8302382", "title": "Contraharmonic mean", "text": "Contraharmonic mean\n\nIn mathematics, a contraharmonic mean is a function complementary to the harmonic mean. The contraharmonic mean is a special case of the Lehmer mean, formula_1, where p = 2.\n\nThe contraharmonic mean of a set of positive numbers is defined as the arithmetic mean of the squares of the numbers divided by the arithmetic mean of the numbers:\n"}
{"id": "1681010", "url": "https://en.wikipedia.org/wiki?curid=1681010", "title": "Cycle graph (algebra)", "text": "Cycle graph (algebra)\n\nIn group theory, a sub-field of abstract algebra, a group cycle graph illustrates the various cycles of a group and is particularly useful in visualizing the structure of small finite groups. \n\nA cycle is the set of powers of a given group element \"a\", where \"a\", the \"n\"-th power of an element \"a\" is defined as the product of \"a\" multiplied by itself \"n\" times. The element \"a\" is said to \"generate\" the cycle. In a finite group, some non-zero power of \"a\" must be the group identity, \"e\"; the lowest such power is the order of the cycle, the number of distinct elements in it. In a cycle graph, the cycle is represented as a polygon, with the vertices representing the group elements, and the connecting lines indicating that all elements in that polygon are members of the same cycle.\n\nCycles can overlap, or they can have no element in common but the identity. The cycle graph displays each interesting cycle as a polygon.\n\nIf \"a\" generates a cycle of order 6 (or, more shortly, \"has\" order 6), then \"a\" = \"e\". Then the set of powers of \"a\", {\"a\", \"a\", \"e\"} is a cycle, but this is really no new information. Similarly, \"a\" generates the same cycle as \"a\" itself.\n\nSo, only the \"primitive\" cycles need be considered, namely those that are not subsets of another cycle. Each of these is generated by some \"primitive element\", \"a\". Take one point for each element of the original group. For each primitive element, connect \"e\" to \"a\", \"a\" to \"a\", ..., \"a\" to \"a\", etc., until \"e\" is reached. The result is the cycle graph.\n\nWhen \"a\" = \"e\", \"a\" has order 2 (is an involution), and is connected to \"e\" by two edges. Except when the intent is to emphasize the two edges of the cycle, it is typically drawn as a single line between the two elements.\n\nAs an example of a group cycle graph, consider the dihedral group Dih. The multiplication table for this group is shown on the left, and the cycle graph is shown on the right with \"e\" specifying the identity element.\n\nNotice the cycle \"e\", \"a\", \"a\", \"a\". It can be seen from the multiplication table that successive powers of \"a\" behave this way. The reverse is also true. In other words: (, , and . This behavior is true for any cycle in any group – a cycle may be traversed in either direction.\n\nCycles that contain a non-prime number of elements implicitly have cycles that are not shown in the graph. For the group Dih above, we might want to draw a line between \"a\" and \"e\" since , but since \"a\" is part of a larger cycle, this is not done.\n\nThere can be ambiguity when two cycles share an element that is not the identity element. Consider for example, the simple quaternion group, whose cycle graph is shown on the right. Each of the elements in the middle row when multiplied by itself gives −1 (where 1 is the identity element). In this case we may use different colors to keep track of the cycles, although symmetry considerations will work as well.\n\nAs noted earlier, the two edges of a 2-element cycle are typically represented as a single line.\n\nThe inverse of an element can be identified in the cycle graph in this fashion: It is the element whose distance from the identity is the same if going through the cycle in the opposite direction.\n\nCycle graphs were investigated by the number theorist Daniel Shanks in the early 1950s as a tool to study multiplicative groups of residue classes. Shanks first published the idea in the 1962 first edition of his book \"Solved and Unsolved Problems in Number Theory\". In the book, Shanks investigates which groups have isomorphic cycle graphs and when a cycle graph is planar. In the 1978 second edition, Shanks reflects on his research on class groups and the development of the baby-step giant-step method: \n\nCycle graphs are used as a pedagogical tool in Nathan Carter's 2009 introductory textbook \"Visual Group Theory\".\n\nCertain group types give typical graphs:\n\nCyclic groups Z, order \"n\", is a single cycle graphed simply as an \"n\"-sided polygon with the elements at the vertices:\n\nWhen \"n\" is a prime number, groups of the form (Z) will have \"n\"-element cycles sharing the identity element:\nDihedral groups Dih, order 2\"n\" consists of an \"n\"-element cycle and \"n\" 2-element cycles:\nDicyclic groups, Dic = Q, order 4\"n\":\nOther direct products:\nSymmetric groups – The symmetric group S contains, for any group of order \"n\", a subgroup isomorphic to that group. Thus the cycle graph of every group of order \"n\" will be found in the cycle graph of S.<br>\nSee example: \n\nThe full octahedral group is the cross product of the symmetric group S and the cyclic group Z.<br>\nIts order is 48, and it has subgroups of every order that divides 48.\n\nIn the examples below nodes that are related to each other are placed next to each other,<br>\nso these are not the simplest possible cycle graphs for these groups (like those on the right).\n\nLike all graphs a cycle graph can be represented in different ways to emphasize different properties. The two representations of the cycle graph of S are an example of that.\n\n\n"}
{"id": "101700", "url": "https://en.wikipedia.org/wiki?curid=101700", "title": "Diophantine set", "text": "Diophantine set\n\nIn mathematics, a Diophantine equation is an equation of the form \"P\"(\"x\", ..., \"x\", \"y\", ..., \"y\")=0 (usually abbreviated \"P\"(',')=0 ) where \"P\"(',') is a polynomial with integer coefficients. A Diophantine set is a subset \"S\" of N so that for some Diophantine equation \"P\"(',')=0,\n\nThat is, a parameter value is in the Diophantine set S if and only if the associated Diophantine equation is satisfiable under that parameter value. Note that the use of natural numbers both in \"S\" and the existential quantification merely reflects the usual applications in computability and model theory. We can equally well speak of Diophantine sets of integers and freely replace quantification over natural numbers with quantification over the integers. Also it is sufficient to assume \"P\" is a polynomial over formula_2 and multiply \"P\" by the appropriate denominators to yield integer coefficients. However, whether quantification over rationals can also be substituted for quantification over the integers is a notoriously hard open problem.\n\nThe MRDP theorem states that a set of integers is Diophantine if and only if it is computably enumerable. A set of integers \"S\" is recursively enumerable if and only if there is an algorithm that, when given an integer, halts if that integer is a member of \"S\" and runs forever otherwise. This means that the concept of general Diophantine set, apparently belonging to number theory, can be taken rather in logical or recursion-theoretic terms. This is far from obvious, however, and represented the culmination of some decades of work.\n\nMatiyasevich's completion of the MRDP theorem settled Hilbert's tenth problem. Hilbert's tenth problem was to find a general algorithm which can decide whether a given Diophantine equation has a solution among the integers. While Hilbert's tenth problem is not a formal mathematical statement as such, the nearly universal acceptance of the (philosophical) identification of a decision algorithm with a total computable predicate allows us to use the MRDP theorem to conclude that the tenth problem is unsolvable.\n\nThe Pell equation\n\nis an example of a Diophantine equation with a parameter. The equation has a solution in the unknowns formula_4 precisely when the parameter formula_5 is 0 or not a perfect square. Namely, this equation provides a Diophantine definition of the set\n\nconsisting of 0 and the natural numbers that are not perfect squares. \n\nOther examples of Diophantine definitions are as follows:\n\nMatiyasevich's theorem, also called the Matiyasevich–Robinson–Davis–Putnam or MRDP theorem, says:\n\nA set \"S\" of integers is computably enumerable if there is an algorithm such that: For each integer input \"n\", if \"n\" is a member of \"S\", then the algorithm eventually halts; otherwise it runs forever. That is equivalent to saying there is an algorithm that runs forever and lists the members of \"S\". A set \"S\" is Diophantine precisely if there is some polynomial with integer coefficients \"f\"(\"n\", \"x\", ..., \"x\")\nsuch that an integer \"n\" is in \"S\" if and only if there exist some integers\n\"x\", ..., \"x\"\nsuch that \"f\"(\"n\", \"x\", ..., \"x\") = 0.\n\nConversely, every Diophantine set is computably enumerable:\nconsider a Diophantine equation \"f\"(\"n\", \"x\", ..., \"x\") = 0.\nNow we make an algorithm which simply tries all possible values for\n\"n\", \"x\", ..., \"x\" (in, say, some simple order consistent with the increasing order of the sum of their absolute values),\nand prints \"n\" every time \"f\"(\"n\", \"x\", ..., \"x\") = 0.\nThis algorithm will obviously run forever and will list exactly the \"n\"\nfor which \"f\"(\"n\", \"x\", ..., \"x\") = 0 has a solution\nin \"x\", ..., \"x\".\n\nYuri Matiyasevich utilized a method involving Fibonacci numbers, which grow exponentially, in order to show that solutions to Diophantine equations may grow exponentially. Earlier work by Julia Robinson, Martin Davis and Hilary Putnam – hence, MRDP – had shown that this suffices to show that every computably enumerable set is Diophantine.\n\nHilbert's tenth problem asks for a general algorithm deciding the solvability of Diophantine equations. The conjunction of Matiyasevich's result with earlier results, collectively now termed the MRDP theorem, implies that a solution to Hilbert's tenth problem is impossible.\n\nLater work has shown that the question of solvability of a Diophantine equation is undecidable even if the equation only has 9 natural number variables (Matiyasevich, 1977) or 11 integer variables (Zhi Wei Sun, 1992).\n\nMatiyasevich's theorem has since been used to prove that many problems from calculus and differential equations are unsolvable.\n\nOne can also derive the following stronger form of Gödel's first incompleteness theorem from Matiyasevich's result:\n\nAccording to the incompleteness theorems, a powerful-enough consistent axiomatic theory is incomplete, meaning the truth of some of its propositions cannot be established within its formalism. The statement above says that this incompleteness must include the solvability of a diophantine equation, assuming that the theory in question is a number theory.\n\n\n"}
{"id": "21357757", "url": "https://en.wikipedia.org/wiki?curid=21357757", "title": "Division polynomials", "text": "Division polynomials\n\nIn mathematics the division polynomials provide a way to calculate multiples of points on elliptic curves and to study the fields generated by torsion points. They play a central role in the study of counting points on elliptic curves in Schoof's algorithm.\n\nThe set of division polynomials is a sequence of polynomials in formula_1 with formula_2 free variables that is recursively defined by:\n\nThe polynomial formula_11 is called the \"n\" division polynomial.\n\n\nUsing the relation between formula_40 and formula_41, along with the equation of the curve, the functions formula_42 , formula_43, formula_36 are all in formula_45.\n\nLet formula_46 be prime and let formula_32 be an elliptic curve over the finite field formula_48, i.e., formula_49. The formula_50-torsion group of formula_16 over formula_52 is isomorphic to formula_53 if formula_54, and to formula_55 or formula_56 if formula_57. Hence the degree of formula_58 is equal to either formula_59, formula_60, or 0.\n\nRené Schoof observed that working modulo the formula_50\"th\" division polynomial allows one to work with all formula_50-torsion points simultaneously. This is heavily used in Schoof's algorithm for counting points on elliptic curves.\n\n\n"}
{"id": "32848672", "url": "https://en.wikipedia.org/wiki?curid=32848672", "title": "Dual q-Krawtchouk polynomials", "text": "Dual q-Krawtchouk polynomials\n\nIn mathematics, the dual \"q\"-Krawtchouk polynomials are a family of basic hypergeometric orthogonal polynomials in the basic Askey scheme. give a detailed list of their properties.\n\nThe polynomials are given in terms of basic hypergeometric functions and the Pochhammer symbol by \n\n"}
{"id": "1388071", "url": "https://en.wikipedia.org/wiki?curid=1388071", "title": "Gilbert Walker", "text": "Gilbert Walker\n\nSir Gilbert Thomas Walker, CSI, FRS (14 June 1868 – 4 November 1958) was an English physicist and statistician of the 20th century. Walker studied mathematics and applied it to a variety of fields including aerodynamics, electromagnetism and the analysis of time-series data before taking up a teaching position at Cambridge University. Although he had no experience in meteorology, he was recruited for a post in the Indian Meteorological Department where he worked on statistical approaches to predict the monsoons. He developed the methods in the analysis of time-series data that are now called the Yule-Walker equations. He is known for his groundbreaking description of the Southern Oscillation, a major phenomenon of global climate, and for discovering what is named after him as the Walker circulation, and for greatly advancing the study of climate in general. He was also instrumental in aiding the early career of the Indian mathematical prodigy, Srinivasa Ramanujan.\n\nHe was born in Rochdale, Lancashire on 14 June 1868, the fourth child and eldest son of Thomas Walker and Elizabeth Charlotte Haslehurst. Thomas was Borough Engineer of Croydon and had pioneered the use of concrete for town reservoirs. He attended Whitgift School where he showed an interest in mathematics and got a scholarship to study at St Paul's School. He obtained a degree in Metallurgy from Imperial College London and attended Trinity College, Cambridge where he was Senior Wrangler in 1889. His hard studies led to ill-health and he spent several winters recuperating in Switzerland where he learnt skating and became quite expert. He became a lecturer at Trinity College from 1895.\n\nWalker was an established applied mathematician at the University of Cambridge when he took up a position as assistant to the meteorological reporter in 1903. He was elevated to the position of director general of observatories in India in 1904. Walker had never worked on meteorology but the previous director of the Indian Meteorological Department, John Eliot. Another predecessor in the Indian Meteorological Department, Henry Francis Blanford, had noticed the pattern that the summer monsoon in India and Burma was correlated with the spring snow cover in the Himalayas. In India, the failure of the Indian Ocean monsoon had brought severe famine to the country in 1899 and meteorology had great economic value. Walker developed Blanford's idea with quantitative rigour and came up with correlation measures (with a lag) and regression equations (or in time-series terminology, autoregression). He set up a group of Indian clerks to calculate correlations between weather parameters. The methods he introduced for time-series regression are now partly named after him (the other contributor was Udny Yule who studied sun-spot cycles) as the Yule-Walker equations. Analyzing vast amounts of weather data from India and lands beyond, over the next fifteen years he published the first descriptions of the great seesaw oscillation of atmospheric pressure between the Indian and Pacific Ocean, and its correlation to temperature and rainfall patterns across much of the Earth's tropical regions, including India. This is now called the El Niño Southern Oscillation. He was made a Companion of the Order of the Star of India in 1911.\n\nWalker also took an interest in several other fields. He made mathematical studies on bird flight and boomerangs. His interest in boomerangs came early in undergraduate years and he had earned the nickname of \"Boomerang Walker\". In Simla, he used to throw a boomerang on the grounds of Annadale attracting the attention even of the Viceroy of India. He found faults in the ideas on bird flight by Ernest Hanbury Hankin, fellow Cambridge scientist at Simla, and pointed out that ascending thermals had enough energy to support the soaring of birds and also pointed out the role of turbulent eddies in providing lift. He published a summary of his ten years of research in \"Nature\" in 1901. He was an accomplished flute player and took an interest in the physics of the flute. He was also an expert on the history and evolution of the flute. He made some design changes to flutes and these went into manufacture. He was also a watercolour artist and while at Simla, held an exhibition of his works.\n\nWalker continued his studies of yearly weather and climate change even after his retirement from India (in 1924 when he was knighted) and acceptance of a professorship in meteorology at Imperial College London. He had only mixed success in his original goal, the prediction of monsoonal failures; however, his theories and broad body of supporting research represented an invaluable step forward, allowing his successors in climate study to move beyond local observation and forecasting toward comprehensive models of climate worldwide. He served as president of the Royal Meteorological Society from 1926 to 1927.\n\nWalker was elected a Fellow of the Royal Society in 1904, long before his work on meteorology on the strength of his work in applied mathematics and applications to electromagnetism. Walker, with his talent for mathematics, was among the first to recognize the abilities of the Indian mathematical prodigy Srinivasa Ramanujan and wrote a letter to the University of Madras to support a scholarship.\n\nWalker's interest in a wide range of subjects made him note the growing insularity of specialists:\nWalker married Mary Constance Carter in 1908 and they had a son, Michael Ashley, and a daughter, Verity Micheline. He died at Coulsdon, Surrey on 4 November 1958. He was 90 years old. The Walker Institute in the United Kingdom, established to study climate, is named in his honour.\n\nPublications related to Indian meteorology:\nPublications on methodology:\nOther topics:\n\n"}
{"id": "47565649", "url": "https://en.wikipedia.org/wiki?curid=47565649", "title": "Haruki's Theorem", "text": "Haruki's Theorem\n\nHaruki's Theorem says that given three intersecting circles that only intersect each other at two points that the lines connecting the inner intersecting points to the outer satisfy:\n\nformula_1\n\nwhere formula_2 are the measure of segments connecting the inner and outer intersection points\n"}
{"id": "30033327", "url": "https://en.wikipedia.org/wiki?curid=30033327", "title": "Home prime", "text": "Home prime\n\nIn number theory, the home prime HP(\"n\") of an integer \"n\" greater than 1 is the prime obtained by repeatedly factoring the increasing concatenation of prime factors including repetitions. The \"m\"th intermediate stage in the process of determining HP(\"n\") is designated HPn(\"m\"). For instance, HP(10) = 773, as 10 factors as 2×5 yielding HP10(1) = 25, 25 factors as 5×5 yielding HP10(2) = HP25(1) = 55, 55 = 5×11 implies HP10(3) = HP25(2) = HP55(1) = 511, and 511 = 7×73 gives HP10(4) = HP25(3) = HP55(2) = HP511(1) = 773, a prime number. Some sources use the alternative notation HPn for the homeprime, leaving out parentheses. Investigations into home primes make up a minor side issue in number theory. Its questions have served as test fields for the implementation of efficient algorithms for factoring composite numbers, but the subject is really one in recreational mathematics.\n\nThe outstanding computational problem is whether HP(49) = HP(77) can be calculated in practice. As each iteration is greater than the previous up until a prime is reached, factorizations generally grow more difficult so long as an end is not reached. the pursuit of HP(49) concerns the factorization of a 251-digit composite factor of HP49(119) after a break was achieved on 3 December 2014 with the calculation of HP49(117). This followed the factorization of HP49(110) on September 8 2012 and of HP49(104) on 11 January 2011, and prior calculations extending for the larger part of a decade that made extensive use of computational resources. Details of the history of this search, as well as the sequences leading to home primes for all other numbers through 100, are maintained at Patrick De Geest's worldofnumbers website. A wiki primarily associated with the Great Internet Mersenne Prime Search maintains the complete known data through 1000 in base 10 and also has lists for the bases 2 through 9.\n\nThe primes in HP(n) are\n\nAside from the computational problems that have had so much time devoted to them, it appears absolute proof of existence of a home prime for any specific number might entail its effective computation. In purely heuristic terms, the existence has probability 1 for all numbers, but such heuristics make assumptions about numbers drawn from a wide variety of processes that, though they likely are correct, fall short of the standard of proof usually required of mathematical claims.\n\nWhile it is unlikely that the idea was not conceived of numerous times in the past, the first reference in print appears to be an article written in 1990 in a small and now-defunct publication called \"Recreational and Educational Computation\". The same person who authored that article, Jeffrey Heleen, revisited the subject in the 1996–7 volume of the Journal of Recreational Mathematics in an article entitled \"Family Numbers: Constructing Primes By Prime Factor Splicing\", which included all of the results HP(\"n\") for \"n\" through 100 other than the ones still unresolved. It also included a now-obsolete list of 3-digit unresolved numbers (The 58 listed have been cut precisely in half as of August 2012). It appears that this article is largely responsible for provoking attempts by others to resolve the case involving 49 and 77. The article uses the terms \"daughter\" and \"parent\" to describe composites and the primes that they lead to, with numbers leading to the same home prime called \"siblings\" (even if one is an iterate of another), and calls the number of iterations required to reach a parent, the persistence of a number under the map to obtain a home prime, the number of \"lives\". The brief article does little other than state the origins of the subject, define terms, give a couple of examples, mention machinery and methods used at the time, and then provide tables. It appears that Mr. De Geest is responsible for the notation now in use. The OEIS also uses \"homeliness\" as the term for the number of numbers, including the prime itself, that have a certain prime as its home prime.\n\n\n"}
{"id": "32796318", "url": "https://en.wikipedia.org/wiki?curid=32796318", "title": "Hopf theorem", "text": "Hopf theorem\n\nThe Hopf theorem is a statement in differential topology, saying that the topological degree is the only homotopy invariant of continuous maps to spheres.\n\nLet \"M\" be an \"n\"-dimensional compact oriented manifold and \"S\" the \"n\"-sphere and formula_1 be continuous. Then formula_2 if and only if \"f\" and \"g\" are homotopic.\n"}
{"id": "3486002", "url": "https://en.wikipedia.org/wiki?curid=3486002", "title": "Implementation of mathematics in set theory", "text": "Implementation of mathematics in set theory\n\nThis article examines the implementation of mathematical concepts in set theory. The implementation of a number of basic mathematical concepts is carried out in parallel in ZFC (the dominant set theory) and in NFU, the version of Quine's New Foundations shown to be consistent by R. B. Jensen in 1969 (here understood to include at least axioms of Infinity and Choice).\n\nWhat is said here applies also to two families of set theories: on the one hand, a range of theories including Zermelo set theory near the lower end of the scale and going up to ZFC extended with large cardinal hypotheses such as \"there is a measurable cardinal\"; and on the other hand a hierarchy of extensions of NFU which is surveyed in the New Foundations article. These correspond to different general views of what the set-theoretical universe is like, and it is the approaches to implementation of mathematical concepts under these two general views that are being compared and contrasted.\n\nIt is not the primary aim of this article to say anything about the relative merits of these theories as foundations for mathematics. The reason for the use of two different set theories is to illustrate that multiple approaches to the implementation of mathematics are feasible. Precisely because of this approach, this article is not a source of \"official\" definitions for any mathematical concept.\n\nThe following sections carry out certain constructions in the two theories ZFC and NFU and compare the resulting implementations of certain mathematical structures (such as the natural numbers).\n\nMathematical theories prove theorems (and nothing else). So saying that a theory allows the construction of a certain object means that it is a theorem of that theory that that object exists. This is a statement about a definition of the form \"the x such that formula_1 exists\", where formula_1 is a formula of our language: the theory proves the existence of \"the x such that formula_1\" just in case it is a theorem that \"there is one and only one x such that formula_1\". (See Bertrand Russell's theory of descriptions.) Loosely, the theory \"defines\" or \"constructs\" this object in this case. If the statement is not a theorem, the theory cannot show that the object exists; if the statement is provably false in the theory, it proves that the object cannot exist; loosely, the object cannot be constructed.\n\nZFC and NFU share the language of set theory, so the same formal definitions \"the x such that formula_1\" can be contemplated in the two theories. A specific form of definition in the language of set theory is set-builder notation: formula_6 means \"the set A such that for all x, formula_7\" (A cannot be free in formula_1). This notation admits certain conventional extensions: formula_9 is synonymous with formula_10; formula_11 is defined as formula_12, where formula_13 is an expression already defined.\n\nExpressions definable in set-builder notation make sense in both ZFC and NFU: it may be that both theories prove that a given definition succeeds, or that neither do (the expression formula_14 fails to refer to anything in \"any\" set theory with classical logic; in class theories like NBG this notation does refer to a class, but it is defined differently), or that one does and the other doesn't. Further, an object defined in the same way in ZFC and NFU may turn out to have different properties in the two theories (or there may be a difference in what can be proved where there is no provable difference between their properties).\n\nFurther, set theory imports concepts from other branches of mathematics (in intention, \"all\" branches of mathematics). In some cases, there are different ways to import the concepts into ZFC and NFU. For example, the usual definition of the first infinite ordinal formula_15 in ZFC is not suitable for NFU because the object (defined in purely set theoretical language as the set of all finite von Neumann ordinals) cannot be shown to exist in NFU. The usual definition of formula_15 in NFU is (in purely set theoretical language) the set of all infinite well-orderings all of whose proper initial segments are finite, an object which can be shown not to exist in ZFC. In the case of such imported objects, there may be different definitions, one for use in ZFC and related theories, and one for use in NFU and related theories. For such \"implementations\" of imported mathematical concepts to make sense, it is necessary to be able to show that the two parallel interpretations have the expected properties: for example, the implementations of the natural numbers in ZFC and NFU are different, but both are implementations of the same mathematical structure, because both include definitions for all the primitives of Peano arithmetic and satisfy (the translations of) the Peano axioms. It is then possible to compare what happens in the two theories as when only set theoretical language is in use, as long as the definitions appropriate to ZFC are understood to be used in the ZFC context and the definitions appropriate to NFU are understood to be used in the NFU context.\n\nWhatever is proven to exist in a theory clearly provably exists in any extension of that theory; moreover, analysis of the proof that an object exists in a given theory may show that it exists in weaker versions of that theory (one may consider Zermelo set theory instead of ZFC for much of what is done in this article, for example).\n\nThese constructions appear first because they are the simplest constructions in set theory, not because they are the first constructions that come to mind in mathematics (though the notion of finite set is certainly fundamental!) \nEven though NFU also allows the construction of set ur-elements yet to become members of a set, the empty set is the unique \"set\" with no members: \nFor each object formula_18, there is a set formula_19 with formula_18 as its only element: \nFor objects formula_18 and formula_23, there is a set formula_24 containing formula_18 and formula_23 as its only elements: \nThe union of two sets is defined in the usual way: \nThis is a recursive definition of unordered formula_29-tuples for any concrete formula_29 (finite sets given as lists of their elements:) \nIn NFU, all the set definitions given work by stratified comprehension; in ZFC, the existence of the unordered pair is given by the axiom of Pairing, the existence of the empty set follows by Separation from the existence of any set, and the boolean union of two sets exists by the axioms of Pairing and Union (formula_32).\n\nFirst, consider the ordered pair. The reason that this comes first is technical: ordered pairs are needed to implement relations and functions which are needed to implementat other concepts which may seem to be prior.\nThe first definition of the ordered pair was the definition formula_33 proposed by Norbert Wiener in 1914 in the context of the type theory of Principia Mathematica. Wiener observed that this allowed the elimination of types of n-ary relations for formula_34 from the system of that work.\nIt is more usual now to use the definition formula_35, due to Kuratowski.\nEither of these definitions works in either ZFC or NFU. In NFU, these two definitions have a technical disadvantage: the Kuratowski ordered pair is two types higher than its projections, while the Wiener ordered pair is three types higher. It is common to postulate the existence of a type-level ordered pair (a pair formula_36 which is the same type as its projections) in NFU. It is convenient to use the Kuratowski pair in both systems until the use of type-level pairs can be formally justified.\nThe internal details of these definitions have nothing to do with their actual mathematical function. For any notion formula_36 of ordered pair, the things that matter are that it satisfy the defining condition:\n…and that it be reasonably easy to collect ordered pairs into sets.\n\nRelations are sets whose members are all ordered pairs. Where possible, a relation formula_39 (understood as a binary predicate) is implemented as formula_40 (which may be written as formula_41). Where formula_39 is a set of ordered pairs, read formula_43 as formula_44.\n\nIn ZFC, some relations (such as the general equality relation or subset relation on sets) are 'too large'\nto be sets (but may be harmlessly reified as proper classes). In NFU, some relations (such as the membership relation) are not sets because their definitions are not stratified: in formula_45 formula_18 and formula_23 would\nneed to have the same type (because they appear as projections of the same pair), but also\nsuccessive types (because formula_18 is considered as an element of formula_23).\n\nLet formula_39 and formula_51 be given binary relations. Then the following concepts are useful:\n\nThe converse of formula_39 is the relation formula_53.\n\nThe domain of formula_39 is the set formula_55.\n\nThe range of formula_39 is the domain of the converse of formula_39.\n\nThe field of formula_39 is the union of the domain and range of formula_39.\n\nThe preimage of a member formula_18 of the field of formula_39 is the set formula_62 (used in the definition of 'well-founded' below.)\n\nThe downward closure of a member formula_18 of the field of formula_39 is the smallest set formula_65 containing formula_18, and containing each formula_67 for each formula_68 (i.e., including the preimage of each of its elements with respect to formula_39 as a subset.)\n\nThe relative product formula_70 of formula_39 and formula_51 is the relation formula_73.\n\nIn ZFC, one proves that these notions all generate or apply to sets via the ZFC axioms of \"union\", \"separation\", and \"power set\". In NFU, it is easy to check that these definitions give rise to stratified formulas.\n\nNotice that the range and codomain of a relation are not distinguished: this could be done by representing a relation formula_39 with codomain formula_75 as formula_76, but our development will not require this.\n\nIn ZFC, any relation whose domain is a subset of a set formula_77 and whose range is a subset of a set formula_75 will be a set, since the cartesian product formula_79 is a set (being a subclass of formula_80), and \"Separation\" provides for the existence of formula_81. In NFU, some relations with global scope (such as equality and subset) can be implemented as sets. In NFU, bear in mind that formula_18 and formula_23 are three types lower than formula_39 in formula_43 (one type lower if a type-level ordered pair is used).\n\nLet formula_39 be some binary relation. formula_39 is:\n\nRelations having certain combinations of the above properties have standard names. formula_39 is:\n\n\nA functional relation is a binary predicate formula_116 such that formula_117. Such a relation (predicate) is implemented as a relation (set) exactly as described in the previous section. So the predicate formula_116 is implemented by the set formula_119. A set of ordered pairs formula_116 is a function if and only if formula_121. It is therefore possible to define this function formula_122 as the unique object formula_23 such that formula_124 – i.e.: formula_18 is formula_116-related to formula_23 such that the relation formula_128 holds between formula_18 and formula_23 – or as the unique object formula_23 such that formula_132. The presence in both theories of functional predicates which are not sets makes it useful to allow the notation formula_122 both for sets formula_116 and for important functional predicates. As long as one does not quantify over functions in the latter sense, all such uses are in principle eliminable.\n\nIn NFU, formula_18 has the same type as formula_122, and formula_116 is three types higher than formula_122 (one type higher, if a type-level ordered pair is used). To solve this problem, one could define formula_139 as formula_140 for any set formula_77, but this is more conveniently written as formula_142. Then, if formula_77 is a set and formula_116 is any functional relation, the 'axiom of replacement' assures that formula_139 is a set in ZFC. In NFU, formula_139 and formula_77 now have the same type, and formula_116 is two types higher than formula_139 (the same type, if a type-level ordered pair is used).\n\nThe function formula_150 is not a set in ZFC because it is 'too large.' formula_151 is, however, a set in NFU. The function (predicate) formula_152 is neither a function nor a set in either theory; in ZFC, this is true because such a set would be too large, and, in NFU, this is true because its definition would not be stratified. Moreover, formula_153 can be proved not to exist in NFU (see the resolution of Cantor's paradox in New Foundations.)\n\nLet formula_128 and formula_155 be arbitrary functions. The composition of formula_128 and formula_155, formula_158, is defined as the relative product formula_159, but only if this results in a function such that formula_158 is also a function, with formula_161, if the range of formula_128 is a subset of the domain of formula_155. The inverse of formula_128, formula_165, is defined as the converse of formula_128 if this is a function. Given any set formula_77, the identity function formula_168 is the set formula_169, and this is a set in both ZFC and NF for different reasons.\n\nA function is an injection and one-to-one if it has an inverse function.\n\nIf formula_77 and formula_75 are sets, formula_128 is a function from formula_77 to formula_75 if formula_128 is a function whose domain is formula_77, and whose range is included in formula_75.\n\nIf formula_128 is a function from formula_77 to formula_75, formula_128 is a:\n\nThis terminology adjusts for the fact that a function, as defined above, does not determine its codomain.\n\nIn both ZFC and NFU, two sets \"A\" and \"B\" are the same size (or are equinumerous) if and only if there is a bijection \"f\" from \"A\" to \"B\". This can be written as formula_194, but note that (for the moment) this expresses a relation between \"A\" and \"B\" rather than a relation between yet-undefined objects formula_195 and formula_196. Denote this relation by formula_197 in contexts such as the actual definition of the cardinals where even the appearance of presupposing abstract cardinals should be avoided.\n\nSimilarly, define formula_198 as holding if and only if there is an injection from \"A\" to \"B\".\n\nIt is straightforward to show that the relation of equinumerousness is an equivalence relation: equinumerousness of \"A\" with \"A\" is witnessed by formula_168; if \"f\" witnesses formula_194, then formula_201 witnesses formula_202; if \"f\" witnesses formula_194 and \"g\" witnesses formula_204, then formula_205 witnesses formula_206.\n\nIt can be shown that formula_198 is a linear order on abstract cardinals, but not on sets. Reflexivity is obvious and transitivity is proven just as for equinumerousness. The Schröder–Bernstein theorem, provable in ZFC and NFU in an entirely standard way, establishes that\n(this establishes antisymmetry on cardinals), and\nfollows in a standard way in either theory from the axiom of choice.\n\nNatural numbers can be considered either as finite ordinals or finite cardinals. Here consider them as finite cardinal numbers. This is the first place where a major difference between the implementations in ZFC and NFU becomes evident.\n\nThe Axiom of Infinity of ZFC tells us that there is a set \"A\" which contains formula_210 and contains formula_211 for each formula_212. This set \"A\" is not uniquely determined (it can be made larger while preserving this closure property): the set \"N\" of natural numbers is\nwhich is the intersection of all sets which contain the empty set and are closed under the \"successor\" operation formula_214.\n\nIn ZFC, a set formula_77 is finite if and only if there is formula_216 such that formula_217: further, define formula_195 as this \"n\" for finite \"A\". (It can be proved that no two distinct natural numbers are the same size).\n\nThe usual operations of arithmetic can be defined recursively and in a style very similar to that in which the set of natural numbers itself is defined. For example, + (the addition operation on natural numbers) can be defined as the smallest set which contains formula_219 for each natural number formula_18 and contains formula_221 whenever it contains formula_222.\n\nIn NFU, it is not obvious that this approach can be used, since the successor operation formula_211 is unstratified and so the set \"N\" as defined above cannot be shown to exist in NFU (it is consistent for the set of finite von Neumann ordinals to exist in NFU, but this strengthens the theory, as the existence of this set implies the Axiom of Counting (for which see below or the New Foundations article)).\n\nThe standard definition of the natural numbers, which is actually the oldest set-theoretic definition of natural numbers, is as equivalence classes of finite sets under equinumerousness. Essentially the same definition is appropriate to NFU (this is not the usual definition, but the results are the same): define \"Fin\", the set of finite sets, as\nFor any set formula_225, define formula_195 as formula_227. Define \"N\" as the set formula_228 whenever it contains formula_195, and which is closed under suprema of sets of cardinals.\n\nA convention for ordinal indexing of any well-ordering formula_230 is defined as the element \"x\" of the field of formula_231 such that\nthe order type of the restriction of formula_231 to formula_233 is formula_234; then define formula_235 as the element with index formula_234 in the natural order on the elements of formula_237. The cardinal formula_238 is the element with index formula_234 in the natural order on all infinite cardinals (which is a well-ordering, see above). Note that formula_240 follows immediately from this definition. In all these constructions, notice that the type of the index formula_234 is two higher (with type-level ordered pair) than the type of formula_242.\n\nEach set \"A\" of ZFC has a transitive closure formula_243 (the intersection of all transitive sets which contains \"A\"). By the axiom of foundation, the restriction of the membership relation to the transitive closure of \"A\" is a well-founded relation. The relation formula_244 is either empty or has \"A\" as its top element, so this relation is a \"set picture\". It can be proved in ZFC that every set picture is isomorphic to some formula_244.\n\nThis suggests that (an initial segment of) the cumulative hierarchy can be studied by considering the isomorphism classes of set pictures. These isomorphism classes are sets and make up a set in NFU. There is a natural set relation analogous to membership on isomorphism classes of set pictures: if formula_18 is a set picture, write formula_247 for its isomorphism class and define formula_248 as holding if formula_247 is the isomorphism class of the restriction of \"y\" to the downward closure of one of the elements of the preimage under \"y\" of the top element of \"y\". The relation E is a set relation, and it is straightforward to prove that it is well-founded and extensional. If the definition of E is confusing, it can be deduced from the observation that it is induced by precisely the relationship which holds between the set picture associated with \"A\" and the set picture associated with \"B\" when formula_250 in the usual set theory.\n\nThere is a T operation on isomorphism classes of set pictures analogous to the T operation on ordinals: if \"x\" is a set picture, so is formula_251. Define formula_252 as formula_253. It is easy to see that formula_254.\n\nAn axiom of extensionality for this simulated set theory follows from E's extensionality. From its well-foundedness follows an axiom of foundation. There remains the question of what comprehension axiom E may have. Consider any collection of set pictures formula_255 (collection of set pictures whose fields are made up entirely of singletons). Since each formula_256 is one type higher than x (using a type-level ordered pair), replacing each element formula_257 of the field of each formula_256 in the collection with formula_259 results in a collection of set pictures isomorphic to the original collection but with their fields disjoint. The union of these set\npictures with a new top element yields a set picture whose isomorphism type will have as its preimages under E exactly the elements of the original collection. That is, for any collection of isomorphism types formula_260, there is an isomorphism type formula_261 whose preimage under E is exactly this collection.\n\nIn particular, there will be an isomorphism type \"[v]\" whose preimage under E is the collection of \"all\" \"T\"[\"x\"]'s (including \"T\"[\"v\"]). Since \"T\"[\"v\"] \"E\" \"v\" and E is well-founded, formula_262. This resembles the resolution of the Burali–Forti paradox discussed above and in the New Foundations article, and is in fact the local resolution of Mirimanoff's paradox of the set of all well-founded sets.\n\nThere are ranks of isomorphism classes of set pictures just as there are ranks of sets in the usual set theory. For any collection of set pictures \"A\", define \"S\"(\"A\") as the set of all isomorphism classes of set pictures whose preimage under E is a subset of A; call A a \"complete\" set if every subset of \"A\" is a preimage under E. The collection of \"ranks\" is the smallest collection containing the empty set and closed under the S operation (which is a kind of power set construction) and under unions of its subcollections. It is straightforward to prove (much as in the usual set theory) that the ranks are well-ordered by inclusion, and so the ranks have an index in this well-order: refer to the rank with index formula_234 as formula_264. It is provable that formula_265 for complete ranks formula_264. The union of the complete ranks (which will be the first incomplete rank) with the relation E looks like an initial segment of the universe of Zermelo-style set theory (not necessarily like the full universe of ZFC because it may not be large enough). It is provable that if formula_264 is the first incomplete rank, then formula_268 is a complete rank and thus formula_269. So there is a \"rank of the cumulative hierarchy\" with an \"external automorphism\" T moving the rank downward, exactly the condition on a nonstandard model of a rank in the cumulative hierarchy under which a model of NFU is constructed in the New Foundations article. There are technical details to verify, but there is an interpretation not only of a fragment of ZFC but of NFU itself in this structure, with formula_270 defined as formula_271: this \"relation\" formula_272 is not a set relation but has the same type displacement between its arguments as the usual membership relation formula_273.\n\nSo there is a natural construction inside NFU of the cumulative hierarchy of sets which internalizes the natural construction of a model of NFU in Zermelo-style set theory.\n\nUnder the Axiom of Cantorian Sets described in the New Foundations article, the strongly cantorian part of the set of isomorphism classes of set pictures with the E relation as membership becomes a (proper class) model of ZFC (in which there are \"n\"-Mahlo cardinals for each \"n\"; this extension of NFU is strictly stronger than ZFC). This is a proper class model because the strongly cantorian isomorphism classes do not make up a set.\n\nPermutation methods can be used to create from any model of NFU a model in which every strongly cantorian isomorphism type of set pictures is actually realized as the restriction of the true membership relation to the transitive closure of a set.\n\n\n\n"}
{"id": "2732574", "url": "https://en.wikipedia.org/wiki?curid=2732574", "title": "Initiative for Open Authentication", "text": "Initiative for Open Authentication\n\nInitiative for Open Authentication (OATH) is an industry-wide collaboration to develop an open reference architecture using open standards to promote the adoption of strong authentication. It has close to thirty coordinating and contributing members and is proposing standards for a variety of authentication technologies, with the aim of lowering costs and simplifying their use.\n\nThe name \"OATH\" is an acronym from the phrase \"open authentication\", and is pronounced as the English word \"oath\".\n\nOATH is not related to OAuth, an open standard for authorization.\n\n\n"}
{"id": "30111202", "url": "https://en.wikipedia.org/wiki?curid=30111202", "title": "International Encyclopedia of Statistical Science", "text": "International Encyclopedia of Statistical Science\n\nThe International Encyclopedia of Statistical Science is one of the largest international scientific projects ever conducted (from the number of involved countries perspective) since it includes contributors coming from 105 countries and six continents. It contains the last papers written by Hirotugu Akaike, Nobel Laureate Sir Clive Granger, John Nelder and Erich Leo Lehmann. \n\nThe first edition, in three volumes, was edited by Miodrag Lovrić and appeared in December 2010. It is published by Springer and it is available in print and online form.\n\n\n"}
{"id": "3810102", "url": "https://en.wikipedia.org/wiki?curid=3810102", "title": "Johnson bound", "text": "Johnson bound\n\nIn applied mathematics, the Johnson bound (named after Selmer Martin Johnson) is a limit on the size of error-correcting codes, as used in coding theory for data transmission or communications.\n\nLet formula_1 be a \"q\"-ary code of length formula_2, i.e. a subset of formula_3. Let formula_4 be the minimum distance of formula_1, i.e.\n\nwhere formula_7 is the Hamming distance between formula_8 and formula_9.\n\nLet formula_10 be the set of all \"q\"-ary codes with length formula_2 and minimum distance formula_4 and let formula_13 denote the set of codes in formula_10 such that every element has exactly formula_15 nonzero entries.\n\nDenote by formula_16 the number of elements in formula_1. Then, we define formula_18 to be the largest size of a code with length formula_2 and minimum distance formula_4:\n\nSimilarly, we define formula_22 to be the largest size of a code in formula_13:\n\nTheorem 1 (Johnson bound for formula_18):\n\nIf formula_26,\n"}
{"id": "38489856", "url": "https://en.wikipedia.org/wiki?curid=38489856", "title": "Ladyzhenskaya's inequality", "text": "Ladyzhenskaya's inequality\n\nIn mathematics, Ladyzhenskaya's inequality is any of a number of related functional inequalities named after the Soviet Russian mathematician Olga Aleksandrovna Ladyzhenskaya. The original such inequality, for functions of two real variables, was introduced by Ladyzhenskaya in 1958 to prove the existence and uniqueness of long-time solutions to the Navier–Stokes equations in two spatial dimensions (for smooth enough initial data). There is an analogous inequality for functions of three real variables, but the exponents are slightly different; much of the difficulty in establishing existence and uniqueness of solutions to the three-dimensional Navier–Stokes equations stems from these different exponents. Ladyzhenskaya's inequality is one member of a broad class of inequalities known as interpolation inequalities.\n\nLet Ω be a Lipschitz domain in R for \"n\" = 2 or 3, and let \"u\": Ω → R be a weakly differentiable function that vanishes on the boundary of Ω in the sense of trace (that is, \"u\" is a limit in the Sobolev space \"H\"(Ω) of a sequence of smooth functions that are compactly supported in Ω). Then there exists a constant \"C\" depending only on Ω such that, in the case \"n\" = 2,\n\nand, in the case \"n\" = 3,\n\n\n\n\n\n"}
{"id": "35068126", "url": "https://en.wikipedia.org/wiki?curid=35068126", "title": "Lebrun manifold", "text": "Lebrun manifold\n\nIn mathematics, a Lebrun manifold is a connected sum of copies of the complex projective plane, equipped with an explicit self-dual metric. Here, self-dual means that the Weyl tensor is its own Hodge star. The metric\nis determined by the choice of a finite collection of points in hyperbolic 3-space. These metrics were discovered by , and named after LeBrun by .\n\n"}
{"id": "9861462", "url": "https://en.wikipedia.org/wiki?curid=9861462", "title": "Limit point compact", "text": "Limit point compact\n\nIn mathematics, a topological space \"X\" is said to be limit point compact or weakly countably compact if every infinite subset of \"X\" has a limit point in \"X\". This property generalizes a property of compact spaces. In a metric space, limit point compactness, compactness, and sequential compactness are all equivalent. For general topological spaces, however, these three notions of compactness are not equivalent.\n\n\n\n"}
{"id": "4490764", "url": "https://en.wikipedia.org/wiki?curid=4490764", "title": "Logarithmic mean", "text": "Logarithmic mean\n\nIn mathematics, the logarithmic mean is a function of two non-negative numbers which is equal to their difference divided by the logarithm of their quotient. In symbols:\n\nfor the positive numbers formula_2.\n\nThis calculation is applicable in engineering problems involving heat and mass transfer.\n\nThe logarithmic mean of two numbers is smaller than the arithmetic mean but larger than the geometric mean (unless the numbers are the same, in which case all three means are equal to the numbers):\n\nFrom the mean value theorem\n\nthe logarithmic mean is obtained as the value of formula_5 by substituting formula_6 for formula_7\n\nand solving for formula_5.\n\nThe logarithmic mean can also be interpreted as the area under an exponential curve.\n\nThe area interpretation allows the easy derivation of some basic properties of the logarithmic mean. Since the exponential function is monotonic, the integral over an interval of length 1 is bounded by formula_12 and formula_13. The homogeneity of the integral operator is transferred to the mean operator, that is formula_14.\n\nTwo other useful integral representations areformula_15andformula_16\n\nOne can generalize the mean to formula_17 variables by considering the mean value theorem for divided differences for the formula_18th derivative of the logarithm.\n\nWe obtain\n\nwhere formula_20 denotes a divided difference of the logarithm.\n\nFor formula_21 this leads to\n\nThe integral interpretation can also be generalized to more variables, but it leads to a different result. Given the simplex formula_23 with formula_24 and an appropriate measure formula_25 which assigns the simplex a volume of 1, we obtain\n\nThis can be simplified using divided differences of the exponential function to\n\nExample formula_28\n\n\n\n"}
{"id": "8566626", "url": "https://en.wikipedia.org/wiki?curid=8566626", "title": "M6 (cipher)", "text": "M6 (cipher)\n\nIn cryptography, M6 is a block cipher proposed by Hitachi in 1997 for use in the IEEE 1394 FireWire standard. The design allows some freedom in choosing a few of the cipher's operations, so M6 is considered a family of ciphers.\n\nThe algorithm operates on blocks of 64 bits using a 10-round Feistel network\nstructure. The key size is 40 bits by default, but can be up to 64 bits. The key schedule is very simple, producing two 32-bit subkeys: the high 32 bits of the key, and the sum mod 2 of this and the low 32 bits.\n\nBecause its round function is based on rotation and addition, M6 was one of the first ciphers\nattacked by mod n cryptanalysis. Mod 5, about 100 known plaintexts suffice to distinguish the output from a pseudorandom permutation. Mod 257, information about the secret key itself is revealed. One known plaintext reduces the complexity of a brute force attack to about 2 trial encryptions; \"a few dozen\" known plaintexts lowers this number to about 2. Due to its simple key schedule, M6 is also vulnerable to a slide attack, which requires more known plaintext but less computation.\n\n"}
{"id": "39459296", "url": "https://en.wikipedia.org/wiki?curid=39459296", "title": "Maekawa's theorem", "text": "Maekawa's theorem\n\nMaekawa's theorem is a theorem in the mathematics of paper folding named after Jun Maekawa. It relates to flat-foldable origami crease patterns and states that at every vertex, the numbers of valley and mountain folds always differ by two in either direction. The same result was also discovered by Jacques Justin and, even earlier, by S. Murata.\n\nOne consequence of Maekawa's theorem is that the total number of folds at each vertex must be an even number. This implies (via a form of planar graph duality between Eulerian graphs and bipartite graphs) that, for any flat-foldable crease pattern, it is always possible to color the regions between the creases with two colors, such that each crease separates regions of differing colors. The same result can also be seen by considering which side of the sheet of paper is uppermost in each region of the folded shape.\n\nMaekawa's theorem does not completely characterize the flat-foldable vertices, because it only takes into account the numbers of folds of each type, and not their angles.\nKawasaki's theorem gives a complementary condition on the angles between the folds at a vertex (regardless of which folds are mountain folds and which are valley folds) that is also necessary for a vertex to be flat-foldable.\n"}
{"id": "5184821", "url": "https://en.wikipedia.org/wiki?curid=5184821", "title": "Modulo-N code", "text": "Modulo-N code\n\nModulo-N code is a lossy compression algorithm used to compress correlated data sources using modulo arithmetic.\n\nWhen applied to two nodes in a network whose data are in close range of each other Modulo-N code\nrequires one node (say odd) to send the coded data value as the raw data formula_1; the even node is required\nto send the coded data as the formula_2. Hence the name Modulo-N code.\n\nSince it is known that for a number K, at least formula_3 bits are required to represent it\nin binary. So the modulo coded data of the two nodes requires totally formula_4.\nAs we can generally expect formula_5 always, because formula_6.\nThis is the how compression is achieved.\n\nA compression ratio achieved is formula_7.\n\nAt the receiver by joint decoding we may complete the process of extracting the data and rebuilding the\noriginal values. The code from the even node is reconstructed by the \"assumption\" that it must be \nclose to the data from the odd node. Hence the decoding algorithm retrieves even node data as \nformula_8.\n\nThe decoder essentially finds the closest match to formula_9 and the decoded\nvalue is declared as formula_10\n\nFor a mod-8 code, we have \n\"Encoder\"\n\"Decoder\"\n\nModulo-N decoding is similar to phase unwrapping and has the same limitation: If the difference from one node to the next is more than N/2 (if the phase changes from one sample to the next more than formula_12), then decoding leads to an incorrect value.\n\n"}
{"id": "3296134", "url": "https://en.wikipedia.org/wiki?curid=3296134", "title": "Morita equivalence", "text": "Morita equivalence\n\nIn abstract algebra, Morita equivalence is a relationship defined between rings that preserves many ring-theoretic properties. It is named after Japanese mathematician Kiiti Morita who defined equivalence and a similar notion of duality in 1958.\n\nRings are commonly studied in terms of their modules, as modules can be viewed as representations of rings. Every ring \"R\" has a natural \"R\"-module structure on itself where the module action is defined as the multiplication in the ring, so the approach via modules is more general and gives useful information. Because of this, one often studies a ring by studying the category of modules over that ring. Morita equivalence takes this viewpoint to a natural conclusion by defining rings to be Morita equivalent if their module categories are equivalent. This notion is of interest only when dealing with noncommutative rings, since it can be shown that two commutative rings are Morita equivalent if and only if they are isomorphic.\n\nTwo rings \"R\" and \"S\" (associative, with 1) are said to be (Morita) equivalent if there is an equivalence of the category of (left) modules over \"R\", \"R-Mod\", and the category of (left) modules over \"S\", \"S-Mod\". It can be shown that the left module categories \"R-Mod\" and \"S-Mod\" are equivalent if and only if the right module categories \"Mod-R\" and \"Mod-S\" are equivalent. Further it can be shown that any functor from \"R-Mod\" to \"S-Mod\" that yields an equivalence is automatically additive.\n\nAny two isomorphic rings are Morita equivalent.\n\nThe ring of \"n\"-by-\"n\" matrices with elements in \"R\", denoted M(\"R\"), is Morita-equivalent to \"R\" for any \"n > 0\". Notice that this generalizes the classification of simple artinian rings given by Artin–Wedderburn theory. To see the equivalence, notice that if \"X\" is a left \"R\"-module then \"X\" is an M(\"R\")-module where the module structure is given by matrix multiplication on the left of column vectors from \"X\". This allows the definition of a functor from the category of left \"R\"-modules to the category of left M(\"R\")-modules. The inverse functor is defined by realizing that for any M(\"R\")-module there is a left \"R\"-module \"X\" such that the M(\"R\")-module is obtained from \"X\" as described above.\n\nEquivalences can be characterized as follows: if \"F\":\"R-Mod\" formula_1 \"S-Mod\" and \"G\":\"S-Mod\"formula_1 \"R-Mod\" are additive (covariant) functors, then \"F\" and \"G\" are an equivalence if and only if there is a balanced (\"S\",\"R\")-bimodule \"P\" such that \"P\" and \"P\" are finitely generated projective generators and there are natural isomorphisms of the functors formula_3, and of the functors formula_4 Finitely generated projective generators are also sometimes called progenerators for their module category.\n\nFor every right-exact functor \"F\" from the category of left-\"R\" modules to the category of left-\"S\" modules that commutes with direct sums, a theorem of homological algebra shows that there is a \"(S,R)\"-bimodule \"E\" such that the functor formula_5 is naturally isomorphic to the functor formula_6. Since equivalences are by necessity exact and commute with direct sums, this implies that \"R\" and \"S\" are Morita equivalent if and only if there are bimodules \"M\" and \"N\" such that formula_7 as \"(R,R)\" bimodules and formula_8 as \"(S,S)\" bimodules. Moreover, \"N\" and \"M\" are related via an \"(S,R)\" bimodule isomorphism: formula_9.\n\nMore concretely, two rings \"R\" and \"S\" are Morita equivalent if and only if formula_10 for a progenerator module \"P\", which is the case if and only if \n(isomorphism of rings) for some positive integer \"n\" and full idempotent \"e\" in the matrix ring M(\"R\").\n\nIt is known that if \"R\" is Morita equivalent to \"S\", then the ring C(\"R\") is isomorphic to the ring C(\"S\"), where C(-) denotes the center of the ring, and furthermore \"R\"/\"J\"(\"R\") is Morita equivalent to \"S\"/\"J\"(\"S\"), where \"J\"(-) denotes the Jacobson radical.\n\nWhile isomorphic rings are Morita equivalent, Morita equivalent rings can be nonisomorphic. An easy example is that a division ring \"D\" is Morita equivalent to all of its matrix rings \"M\"(\"D\"), but cannot be isomorphic when \"n\" > 1. In the special case of commutative rings, Morita equivalent rings are actually isomorphic. This follows immediately from the comment above, for if \"R\" is Morita equivalent to \"S\", formula_12. In fact, if \"R\" and \"S\" are isomorphic commutative rings, every equivalence between \"R\"-Mod and \"S\"-Mod arises up to natural isomorphism from an isomorphism between \"R\" and \"S\".\n\nMany properties are preserved by the equivalence functor for the objects in the module category. Generally speaking, any property of modules defined purely in terms of modules and their homomorphisms (and not to their underlying elements or ring) is a categorical property which will be preserved by the equivalence functor. For example, if \"F\"(-) is the equivalence functor from \"R-Mod\" to \"S-Mod\", then the \"R\" module \"M\" has any of the following properties if and only if the \"S\" module \"F\"(\"M\") does: injective, projective, flat, faithful, simple, semisimple, finitely generated, finitely presented, Artinian, and Noetherian. Examples of properties not necessarily preserved include being free, and being cyclic.\n\nMany ring theoretic properties are stated in terms of their modules, and so these properties are preserved between Morita equivalent rings. Properties shared between equivalent rings are called Morita invariant properties. For example, a ring \"R\" is semisimple if and only if all of its modules are semisimple, and since semisimple modules are preserved under Morita equivalence, an equivalent ring \"S\" must also have all of its modules semisimple, and therefore be a semisimple ring itself.\n\nSometimes it is not immediately obvious why a property should be preserved. For example, using one standard definition of von Neumann regular ring (for all \"a\" in \"R\", there exists \"x\" in \"R\" such that \"a\" = \"axa\") it is not clear that an equivalent ring should also be von Neumann regular. However another formulation is: a ring is von Neumann regular if and only if all of its modules are flat. Since flatness is preserved across Morita equivalence, it is now clear that von Neumann regularity is Morita invariant.\n\nThe following properties are Morita invariant:\n\nExamples of properties which are \"not\" Morita invariant include commutative, local, reduced, domain, right (or left) Goldie, Frobenius, invariant basis number, and Dedekind finite.\n\nThere are at least two other tests for determining whether or not a ring property formula_13 is Morita invariant. An element \"e\" in a ring \"R\" is a full idempotent when \"e\" = \"e\" and \"ReR\" = \"R\".\n\nor\n\nDual to the theory of equivalences is the theory of dualities between the module categories, where the functors used are contravariant rather than covariant. This theory, though similar in form, has significant differences because there is no duality between the categories of modules for any rings, although dualities may exist for subcategories. In other words, because infinite dimensional modules are not generally reflexive, the theory of dualities applies more easily to finitely generated algebras over noetherian rings. Perhaps not surprisingly, the criterion above has an analogue for dualities, where the natural isomorphism is given in terms of the hom functor rather than the tensor functor.\n\nMorita equivalence can also be defined in more structured situations, such as for symplectic groupoids and C*-algebras. In the case of C*-algebras, a stronger type equivalence, called strong Morita equivalence, is needed to obtain results useful in applications, because of the additional structure of C*-algebras (coming from the involutive *-operation) and also because C*-algebras do not necessarily have an identity element.\n\nIf two rings are Morita equivalent, there is an induced equivalence of the respective categories of projective modules since the Morita equivalences will preserve exact sequences (and hence projective modules). Since the algebraic K-theory of a ring is defined (in Quillen's approach) in terms of the homotopy groups of (roughly) the classifying space of the nerve of the (small) category of finitely generated projective modules over the ring, Morita equivalent rings must have isomorphic K-groups.\n\n"}
{"id": "195132", "url": "https://en.wikipedia.org/wiki?curid=195132", "title": "Negligible set", "text": "Negligible set\n\nIn mathematics, a negligible set is a set that is small enough that it can be ignored for some purpose.\nAs common examples, finite sets can be ignored when studying the limit of a sequence, and null sets can be ignored when studying the integral of a measurable function.\n\nNegligible sets define several useful concepts that can be applied in various situations, such as truth almost everywhere.\nIn order for these to work, it is generally only necessary that the negligible sets form an ideal; that is, that the empty set be negligible, the union of two negligible sets be negligible, and any subset of a negligible set be negligible.\nFor some purposes, we also need this ideal to be a sigma-ideal, so that countable unions of negligible sets are also negligible.\nIf \"I\" and \"J\" are both ideals of subsets of the same set \"X\", then one may speak of \"I-negligible\" and \"J-negligible\" subsets.\n\nThe opposite of a negligible set is a generic property, which has various forms.\n\nLet \"X\" be the set N of natural numbers, and let a subset of N be negligible if it is finite.\nThen the negligible sets form an ideal.\nThis idea can be applied to any infinite set; but if applied to a finite set, every subset will be negligible, which is not a very useful notion.\n\nOr let \"X\" be an uncountable set, and let a subset of \"X\" be negligible if it is countable.\nThen the negligible sets form a sigma-ideal.\n\nLet \"X\" be a measurable space equipped with a measure \"m,\" and let a subset of \"X\" be negligible if it is \"m\"-null.\nThen the negligible sets form a sigma-ideal.\nEvery sigma-ideal on \"X\" can be recovered in this way by placing a suitable measure on \"X\", although the measure may be rather pathological.\n\nLet \"X\" be the set R of real numbers, and let a subset \"A\" of R be negligible if for each ε > 0, there exists a finite or countable collection \"I\", \"I\", … of (possibly overlapping) intervals satisfying:\n\nand\n\nThis is a special case of the preceding example, using Lebesgue measure, but described in elementary terms.\n\nLet \"X\" be a topological space, and let a subset be negligible if it is of first category, that is, if it is a countable union of nowhere-dense sets (where a set is nowhere-dense if it is not dense in any open set).\nThen the negligible sets form a sigma-ideal.\n\"X\" is a \"Baire space\" if the interior of every such negligible set is empty.\n\nLet \"X\" be a directed set, and let a subset of \"X\" be negligible if it has an upper bound.\nThen the negligible sets form an ideal.\nThe first example is a special case of this using the usual ordering of \"N\".\n\nIn a coarse structure, the controlled sets are negligible.\n\nLet \"X\" be a set, and let \"I\" be an ideal of negligible subsets of \"X\".\nIf \"p\" is a proposition about the elements of \"X\", then \"p\" is true \"almost everywhere\" if the set of points where \"p\" is true is the complement of a negligible set.\nThat is, \"p\" may not always be true, but it's false so rarely that this can be ignored for the purposes at hand.\n\nIf \"f\" and \"g\" are functions from \"X\" to the same space \"Y\", then \"f\" and \"g\" are \"equivalent\" if they are equal almost everywhere.\nTo make the introductory paragraph precise, then, let \"X\" be N, and let the negligible sets be the finite sets.\nThen \"f\" and \"g\" are sequences.\nIf \"Y\" is a topological space, then \"f\" and \"g\" have the same limit, or both have none.\nOr, let \"X\" be a measure space, and let negligible sets be the null sets.\nIf \"Y\" is the real line R, then either \"f\" and \"g\" have the same integral, or neither integral is defined.\n\n"}
{"id": "13297861", "url": "https://en.wikipedia.org/wiki?curid=13297861", "title": "Patch test (finite elements)", "text": "Patch test (finite elements)\n\nThe patch test in the finite element method is a simple indicator of the quality of a finite element, developed by Bruce Irons.\nThe patch test uses a partial differential equation on a domain consisting from several elements set up so that the exact solution is known and can be reproduced, in principle, with zero error. Typically, in mechanics, the prescribed exact solution consists of displacements that vary as piecewise linear functions in space (called a constant strain solution). The elements pass the patch test if the finite element solution is the same as the exact solution.\n\nIt was long conjectured by engineers that passing the patch test is sufficient for the convergence of the finite element, that is, to ensure that the solutions from the finite element method converge to the exact solution of the partial differential equation as the finite element mesh is refined. However, this is not the case, and the patch test is neither sufficient nor necessary for convergence.\n\nA broader definition of patch test (applicable to any numerical method, including and beyond finite elements) is any test problem having an exact solution that can, in principle, be exactly reproduced by the numerical approximation. Therefore, a finite-element simulation that uses linear shape functions has patch tests for which the exact solution must be piecewise linear, while higher-order finite elements have correspondingly higher-order patch tests.\n"}
{"id": "7184831", "url": "https://en.wikipedia.org/wiki?curid=7184831", "title": "Primary pseudoperfect number", "text": "Primary pseudoperfect number\n\nIn mathematics, and particularly in number theory, \"N\" is a primary pseudoperfect number if it satisfies the Egyptian fraction equation\nwhere the sum is over only the prime divisors of \"N\".\n\nEquivalently, \"N\" is a primary pseudoperfect number if it satisfies\nExcept for the primary pseudoperfect number \"N\" = 2, this expression gives a representation for \"N\" as the sum of distinct divisors of \"N\". Therefore, each primary pseudoperfect number \"N\" (except \"N\" = 2) is also pseudoperfect.\n\nThe eight known primary pseudoperfect numbers are\nThe first four of these numbers are one less than the corresponding numbers in Sylvester's sequence, but then the two sequences diverge.\n\nIt is unknown whether there are infinitely many primary pseudoperfect numbers, or whether there are any odd primary pseudoperfect numbers.\n\nThe prime factors of primary pseudoperfect numbers sometimes may provide solutions to Znám's problem, in which all elements of the solution set are prime. For instance, the prime factors of the primary pseudoperfect number 47058 form the solution set {2,3,11,23,31} to Znám's problem. However, the smaller primary pseudoperfect numbers 2, 6, 42, and 1806 do not correspond to solutions to Znám's problem in this way, as their sets of prime factors violate the requirement that no number in the set can equal one plus the product of the other numbers. Anne (1998) observes that there is exactly one solution set of this type that has \"k\" primes in it, for each \"k\" ≤ 8, and conjectures that the same is true for larger \"k\".\n\nIf a primary pseudoperfect number \"N\" is one less than a prime number, then \"N\"×(\"N\"+1) is also primary pseudoperfect. For instance, 47058 is primary pseudoperfect, and 47059 is prime, so 47058 × 47059 = 2214502422 is also primary pseudoperfect.\n\nPrimary pseudoperfect numbers were first investigated and named by Butske, Jaje, and Mayernik (2000). Using computational search techniques, they proved the remarkable result that for each positive integer \"r\" up to 8, there exists exactly one primary pseudoperfect number with precisely \"r\" (distinct) prime factors, namely, the \"r\"th known primary pseudoperfect number. Those with 2 ≤ \"r\" ≤ 8, when reduced modulo 288, form the arithmetic progression 6, 42, 78, 114, 150, 186, 222, as was observed by Sondow and MacMillan (2017).\n\n\n"}
{"id": "46879612", "url": "https://en.wikipedia.org/wiki?curid=46879612", "title": "Quantum catalyst", "text": "Quantum catalyst\n\nIn quantum information theory, a quantum catalyst is a special ancillary quantum state whose presence enables certain local transformations that would otherwise be impossible. Quantum catalytic behaviour has been shown to arise from the phenomenon of catalytic majorization. The catalytic majorization relation can be used to find which transformations of jointly held pure quantum states are possible via local operations and classical communication (LOCC); particularly when an additional jointly held state is optionally specified to facilitate the transformation without being consumed. In the process sometimes referred to as entanglement catalysis, the catalyst can be understood as that temporarily involved entangled state. For bipartite pure entangled states that can be transformed in this way with unit probability, the respective Schmidt coefficients are said to satisfy the trumping relation, a mathematical relation which is an extension of the majorization relation. Others have shown how quantum catalytic behaviour arises under a probabilistic approach via Stochastic dominance with respect to the convolution of measures.\n"}
{"id": "19092774", "url": "https://en.wikipedia.org/wiki?curid=19092774", "title": "Quantum no-deleting theorem", "text": "Quantum no-deleting theorem\n\nIn physics, the no-deleting theorem of quantum information theory is a no-go theorem which states that, in general, given two copies of some arbitrary quantum state, it is impossible to delete one of the copies. It is a time-reversed dual to the no-cloning theorem, which states that arbitrary states cannot be copied. This theorem seems remarkable, because, in many senses, quantum states are fragile; the theorem asserts that, in a particular case, they are also robust. Physicist Arun K. Pati along with Samuel L. Braunstein proved this theorem.\n\nThe no-deleting theorem, together with the no-cloning theorem, underpin the interpretation of quantum mechanics in terms of category theory, and, in particular, as a dagger symmetric monoidal category. This formulation, known as categorical quantum mechanics, in turn allows a connection to be made from quantum mechanics to linear logic as the logic of quantum information theory (in exact analogy to classical logic being founded on Cartesian closed categories).\n\nSuppose that there are two copies of an unknown quantum state. A pertinent question in this context is to ask if it is possible, given two identical copies, to delete one of them using quantum mechanical operations? It turns out that one cannot. The no-deleting theorem is a consequence of linearity of quantum mechanics. Like the no-cloning theorem this has important implications in quantum computing, quantum information theory and quantum mechanics in general.\n\nThe process of quantum deleting takes two copies of an arbitrary, unknown \nquantum state at the input port and outputs a blank state along with the original. Mathematically, \nthis can be described by:\nwhere formula_2 is the deleting operation which is not necessarily unitary (but a linear operator), formula_3 is the unknown quantum \nstate, formula_4 is the blank state, formula_5 is the initial state of \nthe deleting machine and formula_6 is the final state of the machine.\n\nIt may be noted that classical bits can be copied and deleted, as can qubits in orthogonal states. For example, if we have two identical qubits formula_7 and formula_8 then we can transform to formula_7 and formula_10. In this case we have deleted the second copy. However, it follows from linearity of quantum theory that there is no formula_2 that can perform the deleting operation for any arbitrary state formula_12.\n\nLet formula_13 be an unknown quantum state in some Hilbert space (and let other states have their usual meaning). Then, \nthere is no linear isometric transformation such that \nformula_14, with the final state of the ancilla being independent of\nformula_13.\n\nThe theorem holds for quantum states in a Hilbert space of any dimension. For simplicity, \nlet us consider the deleting transformation for two identical qubits. If two qubits are in orthogonal states, then deletion requires that \n\nLet formula_18 be the state of an unknown qubit. If we have two copies of an unknown qubit, then by linearity of the deleting transformation we have \nIn the above expression, the following transformation has been used: \n\nHowever, if we are able to delete a copy, then, at the output port of the deleting machine, the combined state should be \n\nIn general, these states are not identical and hence we can say that the machine fails to delete a copy. If we require that the final output states are same, then we will see that there is only one option:\nand\n\nSince final state formula_25 of the ancilla is normalized for all values of formula_26 it must be true that formula_27 and formula_28 are orthogonal. This means that the quantum information is simply in the final state of the ancilla. One can always obtain the unknown state from the final state of the ancilla using local operation on the ancilla Hilbert space. Thus, linearity of quantum theory does not allow an unknown quantum state to be deleted perfectly.\n\n\n"}
{"id": "15426942", "url": "https://en.wikipedia.org/wiki?curid=15426942", "title": "Quantum technology", "text": "Quantum technology\n\nQuantum technology is a new field of physics and engineering, which transitions some of the properties of quantum mechanics, especially quantum entanglement, quantum superposition and quantum tunnelling, into practical applications such as quantum computing, quantum sensors, quantum cryptography, quantum simulation, quantum metrology and quantum imaging.\n\nQuantum superposition states can be very sensitive to a number of external effects, such as electric, magnetic and gravitational fields; rotation, acceleration and time, and therefore can be used to make very accurate sensors. There are many experimental demonstrations of quantum sensing devices, such as the experiments carried out by the nobel laureate William D. Phillips on using cold atom interferometer systems to measure gravity and the atomic clock which is used by many national standards agencies around the world to define the second.\n\nRecent efforts are being made to engineer quantum sensing devices, so that they are cheaper, easier to use, more portable, lighter and consume less power. It is believed that if these efforts are successful, it will lead to multiple commercial markets, such as for the monitoring of oil and gas deposits, or in construction.\n\nQuantum secure communication are methods which are expected to be 'quantum safe' in the advent of a quantum computing systems that could break current cryptography systems. One significant component of a quantum secure communication systems is expected to be Quantum key distribution, or 'QKD': a method of transmitting information using entangled light in a way that makes any interception of the transmission obvious to the user.\n\nQuantum computers are the ultimate quantum network, combining 'quantum bits' or 'qubit' which are devices that can store and process quantum data (as opposed to binary data) with links that can transfer quantum information between qubits. In doing this, quantum computers are predicted to calculate certain algorithms significantly faster than even the largest classical computer available today.\n\nQuantum computers are expected to have a number of significant uses in computing fields such as optimization and machine learning. They are famous for their expected ability to carry out 'Shor's Algorithm', which can be used to factorise large numbers which are mathematically important to secure data transmission.\n\nThere are many devices available today which are fundamentally reliant on the effects of quantum mechanics. These include: laser systems, transistors and semi-conductor devices and other devices, such as MRI imagers. These devices are often referred to belonging to the 'first quantum revolution'; the UK Defence Science and Technology Laboratory (Dstl) grouped these devices as 'quantum 1.0', that is devices which rely on the effects of quantum mechanics. Quantum technologies are often described as the 'second quantum revolution' or 'quantum 2.0'. These are generally regarded as a class of device that actively create, manipulate and read out quantum states of matter, often using the quantum effects of superposition and entanglement.\n\nThe field of quantum technology was first outlined in a 1997 book by Gerard J. Milburn, which was then followed by a 2003 article by Jonathan P. Dowling and Gerard J. Milburn, as well as a 2003 article by David Deutsch. The field of quantum technology has benefited immensely from the influx of new ideas from the field of quantum information processing, particularly quantum computing. Disparate areas of quantum physics, such as quantum optics, atom optics, quantum electronics, and quantum nanomechanical devices, have been unified under the search for a quantum computer and given a common language, that of quantum information theory.\n\nThe Quantum Manifesto was signed by 3,400 scientists and officially released at the 2016 Quantum Europe Conference, calling for a quantum technology initiative to coordinate between academia and industry, to move quantum technologies from the laboratory to industry, and to educate quantum technology professionals in a combination of science, engineering, and business.\n\nThe European Commission responded to that manifesto with the Quantum Technology Flagship, a €1 Billion, 10-year-long megaproject, similar in size to earlier European Future and Emerging Technologies Flagship projects such as the Graphene Flagship and Human Brain Project.\n\nFrom 2010 onwards, multiple governments have established programmes to explore quantum technologies, such as the UK National Quantum Technologies Programme, which created four quantum 'hubs', the Centre for Quantum Technologies in Singapore, and QuTech a Dutch centre to develop a topological quantum computer.\n\nIn the private sector, there have been multiple investments into quantum technologies made by large companies. Examples include Google's partnership with the John Martinis group at UCSB, multiple partnerships with the Canadian quantum computing company D-wave systems, and investment by many UK companies within the UK quantum technologies programme.\n\n\n"}
{"id": "7960510", "url": "https://en.wikipedia.org/wiki?curid=7960510", "title": "Restricted sumset", "text": "Restricted sumset\n\nIn additive number theory and combinatorics, a restricted sumset has the form \n\nwhere formula_2 are finite nonempty subsets of a field \"F\" and formula_3 is a polynomial over \"F\". \n\nWhen formula_4, \"S\" is the usual sumset formula_5 which is denoted by \"nA\" if formula_6; when \n\n\"S\" is written as formula_8 which is denoted by formula_9 if formula_6. Note that |\"S\"| > 0 if and only if there exist formula_11 with formula_12.\n\nThe Cauchy–Davenport theorem named after Augustin Louis Cauchy and Harold Davenport asserts that for any prime \"p\" and nonempty subsets \"A\" and \"B\" of the prime order cyclic group Z/\"p\"Z we have the inequality\n\nWe may use this to deduce the Erdős–Ginzburg–Ziv theorem: given any sequence of 2\"n\"−1 elements in Z/\"n\", there are \"n\" elements that sums to zero modulo \"n\". (Here \"n\" does not need to be prime.)\n\nA direct consequence of the Cauchy-Davenport theorem is: Given any set \"S\" of \"p\"−1 or more nonzero elements, not necessarily distinct, of Z/\"pZ, every element of Z/\"pZ can be written as the sum of the elements of some subset (possibly empty) of \"S\".\n\nKneser's theorem generalises this to finite abelian groups.\n\nThe Erdős–Heilbronn conjecture posed by Paul Erdős and Hans Heilbronn in 1964 states that formula_14 if \"p\" is a prime and \"A\" is a nonempty subset of the field Z/\"p\"Z. This was first confirmed by J. A. Dias da Silva and Y. O. Hamidoune in 1994\nwho showed that \n\nwhere \"A\" is a finite nonempty subset of a field \"F\", and \"p\"(\"F\") is a prime \"p\" if \"F\" is of characteristic \"p\", and \"p\"(\"F\") = ∞ if \"F\" is of characteristic 0. Various extensions of this result were given by Noga Alon, M. B. Nathanson and I. Ruzsa in 1996, Q. H. Hou and Zhi-Wei Sun in 2002,\nand G. Karolyi in 2004.\n\nA powerful tool in the study of lower bounds for cardinalities of various restricted sumsets is the following fundamental principle: the combinatorial Nullstellensatz. Let formula_16 be a polynomial over a field \"F\". Suppose that the coefficient of the monomial formula_17 in formula_16 is nonzero and formula_19 is the total degree of formula_16. If formula_21 are finite subsets of \"F\" with formula_22 for formula_23, then there are formula_11 such that formula_25.\n\nThe method using the combinatorial Nullstellensatz is also called the polynomial method. This tool was rooted in a paper of N. Alon and M. Tarsi in 1989, \nand developed by Alon, Nathanson and Ruzsa in 1995-1996, \nand reformulated by Alon in 1999.\n\n\n"}
{"id": "730173", "url": "https://en.wikipedia.org/wiki?curid=730173", "title": "Richard E. Bellman", "text": "Richard E. Bellman\n\nRichard Ernest Bellman (August 26, 1920 – March 19, 1984) was an American applied mathematician, who introduced dynamic programming in 1953, and important contributions in other fields of mathematics.\n\nBellman was born in 1920 in New York City to non-practising Jewish parents of Polish and Russian descent, Pearl (née Saffian) and John James Bellman, who ran a small grocery store on Bergen Street near Prospect Park, Brooklyn. He attended Abraham Lincoln High School, Brooklyn in 1937, and studied mathematics at Brooklyn College where he earned a BA in 1941. He later earned an MA from the University of Wisconsin. During World War II he worked for a Theoretical Physics Division group in Los Alamos. In 1946 he received his Ph.D at Princeton under the supervision of Solomon Lefschetz. Beginning 1949 Bellman worked for many years at RAND corporation and it was during this time that he developed dynamic programming.\n\nLater in life, Richard Bellman's interests began to emphasize biology and medicine, which he identified as \"the frontiers of contemporary science\". In 1967, he became founding editor of the journal Mathematical Biosciences which specialized in the publication of applied mathematics research for medical and biological topics. In 1985, the Bellman Prize in Mathematical Biosciences was created in his honor, being awarded biannually to the journal's best research paper.\n\nBellman was diagnosed with a brain tumor in 1973, which was removed but resulted in complications that left him severely disabled. He was a professor at the University of Southern California, a Fellow in the American Academy of Arts and Sciences (1975), a member of the National Academy of Engineering (1977), and a member of the National Academy of Sciences (1983).\n\nHe was awarded the IEEE Medal of Honor in 1979, \"for contributions to decision processes and control system theory, particularly the creation and application of dynamic programming\". His key work is the Bellman equation.\n\nA Bellman equation, also known as a \"dynamic programming equation\", is a necessary condition for optimality associated with the mathematical optimization method known as dynamic programming. Almost any problem which can be solved using optimal control theory can also be solved by analyzing the appropriate Bellman equation. The Bellman equation was first applied to engineering control theory and to other topics in applied mathematics, and subsequently became an important tool in economic theory.\n\nThe Hamilton–Jacobi–Bellman equation (HJB) is a partial differential equation which is central to optimal control theory. The solution of the HJB equation is the 'value function', which gives the optimal cost-to-go for a given dynamical system with an associated cost function. Classical variational problems, for example, the brachistochrone problem can be solved using this method as well. The equation is a result of the theory of dynamic programming which was pioneered in the 1950s by Richard Bellman and coworkers. The corresponding discrete-time equation is usually referred to as the Bellman equation. In continuous time, the result can be seen as an extension of earlier work in classical physics on the Hamilton–Jacobi equation by William Rowan Hamilton and Carl Gustav Jacob Jacobi.\n\nThe \"curse of dimensionality\" is an expression coined by Bellman to describe the problem caused by the exponential increase in volume associated with adding extra dimensions to a (mathematical) space. One implication of the curse of dimensionality is that some methods for numerical solution of the Bellman equation require vastly more computer time when there are more state variables in the value function. For example, 100 evenly spaced sample points suffice to sample a unit interval with no more than 0.01 distance between points; an equivalent sampling of a 10-dimensional unit hypercube with a lattice with a spacing of 0.01 between adjacent points would require 10 sample points: thus, in some sense, the 10-dimensional hypercube can be said to be a factor of 10 \"larger\" than the unit interval. (Adapted from an example by R. E. Bellman, see below.) \n\nThough discovering the algorithm after Ford he is referred to in the Bellman–Ford algorithm, also sometimes referred to as the Label Correcting Algorithm, computes single-source shortest paths in a weighted digraph where some of the edge weights may be negative. Dijkstra's algorithm accomplishes the same problem with a lower running time, but requires edge weights to be non-negative.\n\nOver the course of his career he published 619 papers and 39 books. During the last 11 years of his life he published over 100 papers despite suffering from crippling complications of brain surgery (Dreyfus, 2003). A selection:\n\n\n\n"}
{"id": "44532941", "url": "https://en.wikipedia.org/wiki?curid=44532941", "title": "Ringed topos", "text": "Ringed topos\n\nIn mathematics, a ringed topos is a generalization of a ringed space; that is, the notion is obtained by replacing a \"topological space\" by a \"topos\". The notion of a ringed topos has applications to deformation theory in algebraic geometry (cf. cotangent complex) and the mathematical foundation of quantum mechanics. In the latter subject, a Bohr topos is a ringed topos that plays the role of a quantum phase space.\n\nThe definition of a topos-version of a \"locally ringed space\" is not straightforward, as the meaning of \"local\" in this context is not obvious. One can introduce the notion of a locally ringed topos by introducing a sort of geometric conditions of local rings (see SGA4, Exposé IV, Exercice 13.9), which is equivalent to saying that all the stalks of the structure ring object are local rings when there are enough points.\n\nA morphism formula_1 of ringed topoi is a pair consisting of a topos morphism formula_2 and a ring homomorphism formula_3.\n\nIf one replaces a \"topos\" by an ∞-topos, then one gets the notion of a ringed ∞-topos.\n\n\n\n"}
{"id": "47787936", "url": "https://en.wikipedia.org/wiki?curid=47787936", "title": "Schema for horizontal dials", "text": "Schema for horizontal dials\n\nA schema for horizontal dials is a set of instructions used to construct horizontal sundials using compass and straightedge construction techniques, which were widely used in Europe from the late fifteen century to the late nineteen century. The common horizontal sundial is a geometric projection of an equatorial sundial onto a horizontal plane.\n\nThe special properties of the polar-pointing gnomon (axial gnomon) were first known to the Moorish astronomer Abdul Hassan Ali in the early thirteenth century and this led the way to the dial-plates, with which we are familiar, dial plates where the style and hour lines have a common root.\n\nThrough the centuries artisans have used different methods to markup the hour lines sundials using the methods that were familiar to them, in addition the topic has fascinated mathematicians and become a topic of study. Graphical projection was once commonly taught, though this has been superseded by trigonometry, logarithms, sliderules and computers which made arithmetical calculations increasingly trivial/ Graphical projection was once the mainstream method for laying out a sundial but has been sidelined and is now only of academic interest.\n\nThe first known document in English describing a schema for graphical projection was published in Scotland in 1440, leading to a series of distinct schema for horizontal dials each with characteristics that suited the target latitude and construction method of the time.\n\nThe art of sundial design is to produce a dial that accurately displays local time. Sundial designers have also been fascinated by the mathematics of the dial and possible new ways of displaying the information. Modern dialling started in the tenth century when Arab astronomers made the great discovery that a gnomon parallel to the Earth's axis will produce sundials whose hour lines show equal hours or \"legal hours\" on any day of the year: the dial of Ibn al-Shatir in the Umayyad Mosque in Damascus is the oldest dial of this type. Dials of this type appeared in Austria and Germany in the 1440s.\n\nA dial plate can be laid out, by a pragmatic approach, observing and marking a shadow at regular intervals throughout the day on each day of the year. If the latitude is known the dial plate can be laid out using geometrical construction techniques which rely on projection geometry, or by calculation using the known formulas and trigonometric tables usually using logarithms, or slide rules or more recently computers or mobile phones. Linear algebra has provided a useful language to describe the transformations.\n\nA sundial schema uses a compass and a straight edge to firstly to derive the essential angles for that latitude, then to use this to draw the hourlines on the dial plate. In modern terminology this would mean that graphical techniques were used to derive formula_1 and formula_2 and from it formula_3. \n\n\nSuch geometric constructions were well known and remained part of the high school (UK grammar school) curriculum until the New Maths revolution in the 1970s.\n\nThe schema shown above was used in 1525 (from an earlier work 1440) by Dürer is still used today. The simpler schema were more suitable for dials designed for the lower latitudes, requiring a narrow sheet of paper for the construction, than those intended for the higher latitudes. This prompted the quest for other constructions.\n\nThe first part of the process is common to many methods. It establishes a point on the north south line that is sin φ from the meridian line.\n\nThe significant problem is the width of the paper needed in the higher latitudes. \nBenedetti, an impoverished nobleman worked as a mathematician at the court of Savola. His book which describes this method was \"De gnomonum umbrarumque solarium usu\" published in 1574. It describes a method for displaying the legal hours, that is equal hours as we use today, while most people still used unequal hours which divided the hours of daylight into 12 equal hours- but they would change as the year progressed. Benedettis method divides the quadrant into 15° segments. Two construction are made: a parallel horizontal line that defines the tan h distances, and a gnomonic polar line GT which represents sin φ. \nBenedetti included instructions for drawing a point gnomon so unequal hours could be plotted.\n\n(\"Fabica et usus instrumenti ad horologiorum descriptionem.\") Rome Italy.\n\nThe Clavius method looks at a quarter of the dial. It views the horizontal and the perpendicular plane to the polar axis as two rectangles hinged around the top edge of both dials. the polar axis will be at φ degrees to the polar axis, and the hour lines will be equispaced on the polar plane an equatorial dial. (15°). Hour points on the polar plane will connect to the matching point on the horizontal plane. The horizontal hour lines are plotted to the origin.\n\nThe Jesuit Mario Bettini penned a method which was posthumously published in the book \"Recreationum Mathematicarum Apiaria Novissima\" 1660.\n\nWilliam Leybourn published his \"Art of Dialling\" in 1669, a with it a six-stage method. His description relies heavily on the term \"line of chords\", for which a modern diallist substitutes a protractor. The line of chords was a scale found on the sector which was used in conjunction with a set of dividers or compasses. It was still used by navigators up to the end of the 19th century.\nThis method requires a far smaller piece of paper, a great advantage for higher latitudes.\n\n\nThis method uses the properties of chords to establish distance formula_6 in the top quadrant, and then transfers this distance into the bottom quadrant so that formula_7 is established. Again, a transfer of this measure to the chords in the top quadrant. The final lines establish the formula formula_8 formula_9 = formula_10\n\nThis is then transferred by symmetry to all quadrants. It was used in the Encyclopædia Britannica First Edition 1771, Sixth Edition 1823\n\nThe Dom Francois Bedos de Celles method (1760) otherwise known as the Waugh method (1973) \n\nThis method first appeared in Peter Nicholsons \"A popular Course of Pure and Mixed Mathematics\" in 1825. It was copied by School World in Jun 1903, then in Kenneth Lynch's, Sundial and Spheres 1971. It starts by drawing the well known triangle, and takes the vertices to draw two circles at radius (OB) sin φ and (AB) tan φ. The 15° lines are drawn, intersecting these circles. Lines are taken horizontally, and vertically from these circles and their intersection point (OB sin t,AB cos t) is on the hour line. That is tan κ = OB sin t/ AB cos t which resolves to sin φ. tan t.\n\n\n\nThis was an early and convenient method to use if you had access to an astrolabe as many astrologers and mathematicians of the time would have had. The method involved copying the projections of the celestial sphere onto a plane surface. A vertical line was drawn with a line at the angle of the latitude drawn on the bisection of the vertical with the celestial sphere. \n\n\n"}
{"id": "12473239", "url": "https://en.wikipedia.org/wiki?curid=12473239", "title": "Stochastic partial differential equation", "text": "Stochastic partial differential equation\n\nStochastic partial differential equations (SPDEs) generalize partial differential equations via random force terms and coefficients, in the same way ordinary stochastic differential equations generalize ordinary differential equations.\n\nThey have relevance to quantum field theory and statistical mechanics.\n\nOne of the most studied SPDEs is the stochastic heat equation, which may formally be written as\n\nwhere formula_2 is the Laplacian and formula_3 denotes space-time white noise.\n\nOne difficulty is their lack of regularity. In one space dimension, solutions to the stochastic heat equation are only almost 1/2-Hölder continuous in space and 1/4-Hölder continuous in time. For dimensions two and higher, solutions are not even function-valued, but can be made sense of as random distributions. \n\n"}
{"id": "1388070", "url": "https://en.wikipedia.org/wiki?curid=1388070", "title": "System of imprimitivity", "text": "System of imprimitivity\n\nThe concept of system of imprimitivity is used in mathematics, particularly in algebra and analysis, both within the context of the theory of group representations. It was used by George Mackey as the basis for his theory of induced unitary representations of locally compact groups.\n\nThe simplest case, and the context in which the idea was first noticed, is that of finite groups (see primitive permutation group). Consider a group \"G\" and subgroups \"H\" and \"K\", with \"K\" contained in \"H\". Then the left cosets of \"H\" in \"G\" are each the union of left cosets of \"K\". Not only that, but translation (on one side) by any element \"g\" of \"G\" respects this decomposition. The connection with induced representations is that the permutation representation on cosets is the special case of induced representation, in which a representation is induced from a trivial representation. The structure, combinatorial in this case, respected by translation shows that either \"K\" is a maximal subgroup of \"G\", or there is a system of imprimitivity (roughly, a lack of full 'mixing'). In order to generalise this to other cases, the concept is re-expressed: first in terms of functions on \"G\" constant on \"K\"-cosets, and then in terms of projection operators (for example the averaging over \"K\"-cosets of elements of the group algebra).\n\nMackey also used the idea for his explication of quantization theory based on preservation of relativity groups acting on configuration space. This generalized work of Eugene Wigner and others and is often considered to be one of the pioneering ideas in canonical quantization.\n\nTo motivate the general definitions, we first formulate a definition in the case of finite groups and their representations on finite-dimensional vector spaces.\n\nSuppose \"G\" is a finite group and \"U\" a representation of \"G\" on a finite-dimensional complex vector space \"H\". The action of \"G\" on elements of \"H\" induces an action of \"G\" on the vector subspaces \"W\" of \"H\" in an obvious way:\n\nSuppose \"X\" is a set of subspaces of \"H\" such that\n\nThen (\"U\",\"X\") is a system of imprimitivity for \"G\".\n\nTwo assertions must hold in the definition above:\n\nholds only when all the coefficients \"c\" are zero.\n\nIf the action of \"G\" on the elements of \"X\" is transitive, then we say this is a transitive system of imprimitivity.\n\nSuppose \"G\" is a finite group, \"G\" a subgroup of \"G\". A representation \"U\" of \"G\" is induced from a representation \"V\" of \"G\" if and only if there exist the following: \nsuch that \"G\" is the fixed point subgroup of \"W\" under the action of \"G\", i.e.\n\nand \"V\" is equivalent to the representation of \"G\"\non \"W\" given by \"U\" | \"W\" for \"h\" ∈ \"G\". Note that by this definition, \"induced by\" is a relation between representations. We would like to show that there is actually a mapping on representations which corresponds to this relation.\n\nFor finite groups one can easily show that a well-defined inducing construction exists on equivalence of representations by considering the character of a representation \"U\" defined by\n\nIn fact if a representation \"U\" of \"G\" is induced from a representation \"V\" of \"G\", then\n\nThus the character function χ (and therefore \"U\" itself) is completely determined by χ.\n\nLet \"G\" be a finite group and consider the space \"H\" of complex-valued functions on \"G\". The left regular representation of \"G\" on \"H\" is defined by\n\nNow \"H\" can be considered as the algebraic direct sum of the one-dimensional spaces \"W\", for \"x\" ∈ \"G\", where\n\nThe spaces \"W\" are permuted by L.\n\nTo generalize the finite dimensional definition given in the preceding section, a suitable replacement for the set \"X\" of vector subspaces of \"H\" which is permuted by the representation \"U\" is needed. As it turns out, a naïve approach base on subspaces of \"H\" will not work; for example the translation representation of R on \"L\"(R) has no system of imprimitivity in this sense. The right formulation of direct sum decomposition is formulated in terms of projection-valued measures.\n\nMackey's original formulation was expressed in terms of a locally compact second countable (lcsc) group \"G\", a standard Borel space \"X\" and a Borel group action\n\nWe will refer to this as a standard Borel \"G\"-space.\n\nThe definitions can be given in a much more general context, but the original setup used by Mackey is still quite general and requires fewer technicalities.\n\nDefinition. Let \"G\" be a lcsc group acting on a standard Borel space \"X\". A system of imprimitivity based on (\"G\", \"X\") consists of a separable Hilbert space \"H\" and a pair consisting of \nwhich satisfy\n\nLet \"X\" be a standard \"G\" space and μ a σ-finite countably additive \"invariant\" measure on \"X\". This means\n\nfor all \"g\" ∈ \"G\" and Borel subsets \"A\" of \"G\".\n\nLet π(\"A\") be multiplication by the indicator function of \"A\" and \"U\" be the operator\n\nThen (\"U\", π) is a system of imprimitivity of (\"G\", \"X\") on \"L\"(\"X\").\n\nThis system of imprimitivity is sometimes called the \"Koopman system of imprimitivity\".\n\nA system of imprimitivity is homogeneous of multiplicity \"n\", where 1 ≤ \"n\" ≤ ω if and only if the corresponding projection-valued measure π on \"X\" is homogeneous of multiplicity \"n\". In fact, \"X\" breaks up into a countable disjoint family {\"X\"} of Borel sets such that π is homogeneous of multiplicity \"n\" on \"X\". It is also easy to show \"X\" is \"G\" invariant.\n\nLemma. Any system of imprimitivity is an orthogonal direct sum of homogeneous ones.\n\nIt can be shown that if the action of \"G\" on \"X\" is transitive, then any system of imprimitivity on \"X\" is homogeneous. More generally, if the action of \"G\" on \"X\" is ergodic (meaning that \"X\" cannot be reduced by invariant proper Borel sets of \"X\") then any system of imprimitivity on \"X\" is homogeneous.\n\nWe now discuss how the structure of homogeneous systems of imprimitivity can be expressed in a form which generalizes the Koopman representation given in the example above.\n\nIn the following, we assume that μ is a σ-finite measure on a standard Borel \"G\"-space \"X\" such that the action of \"G\" respects the measure class of μ. This condition is weaker than invariance, but it suffices to construct a unitary translation operator similar to the Koopman operator in the example above. \"G\" respects the measure class of μ means that the Radon-Nikodym derivative\n\nis well-defined for every \"g\" ∈ \"G\", where\n\nIt can be shown that there is a version of \"s\" which is jointly Borel measurable, that is\n\nis Borel measurable and satisfies\n\nfor almost all values of (\"g\", \"x\") ∈ \"G\" × \"X\".\n\nSuppose \"H\" is a separable Hilbert space, U(\"H\") the unitary operators on \"H\". A \"unitary cocycle\" is a Borel mapping\n\nsuch that\n\nfor almost all \"x\" ∈ \"X\"\n\nfor almost all (\"g\", \"h\", \"x\"). A unitary cocycle is strict if and only if the above relations hold for all (\"g\", \"h\", \"x\"). It can be shown that for any unitary cocycle there is a strict unitary cocycle which is equal almost everywhere to it (Varadarajan, 1985).\n\nTheorem. Define\n\nThen \"U\" is a unitary representation of \"G\" on the Hilbert space\n\nMoreover, if for any Borel set \"A\", π(\"A\") is the projection operator\n\nthen (\"U\", π) is a system of imprimitivity of (\"G\",\"X\").\n\nConversely, any homogeneous system of imprimitivity is of this form, for some measure σ-finite measure μ. This measure is unique up to measure equivalence, that is to say, two such measures have the same sets of measure 0.\n\nMuch more can be said about the correspondence between homogeneous systems of imprimitivity and cocycles.\n\nWhen the action of \"G\" on \"X\" is transitive however, the correspondence takes a particularly explicit form based on the representation obtained by restricting the cocycle Φ to a fixed point subgroup of the action. We consider this case in the next section.\n\nA system of imprimitivity (\"U\", π) of (\"G\",\"X\") on a separable Hilbert space \"H\" is irreducible if and only if the only closed subspaces invariant under all the operators \"U\" and π(\"A\") for \"g\" and element of \"G\" and \"A\" a Borel subset of \"X\" are \"H\" or {0}.\n\nIf (\"U\", π) is irreducible, then π is homogeneous. Moreover, the corresponding measure on \"X\" as per the previous theorem is ergodic.\n\nIf \"X\" is a Borel \"G\" space and \"x\" ∈ \"X\", then the fixed point subgroup\n\nis a closed subgroup of \"G\". Since we are only assuming the action of \"G\" on \"X\" is Borel, this fact is non-trivial. To prove it, one can use the fact that a standard Borel \"G\"-space can be imbedded into a compact \"G\"-space in which the action is continuous.\n\nTheorem. Suppose \"G\" acts on \"X\" transitively. Then there is a σ-finite quasi-invariant measure μ on \"X\" which is unique up to measure equivalence (that is any two such measures have the same sets of measure zero).\n\nIf Φ is a strict unitary cocycle\n\nthen the restriction of Φ to the fixed point subgroup \"G\" is a Borel measurable unitary representation \"U\" of \"G\" on \"H\" (Here U(\"H\") has the strong operator topology). However, it is known that a Borel measurable unitary representation is equal almost everywhere (with respect to Haar measure) to a strongly continuous unitary representation. This restriction mapping sets up a fundamental correspondence:\n\nTheorem. Suppose \"G\" acts on \"X\" transitively with quasi-invariant measure μ. There is a bijection from unitary equivalence classes of systems of imprimitivity of (\"G\", \"X\") and unitary equivalence classes of representation of \"G\".\n\nMoreover, this bijection preserves irreducibility, that is a system of imprimitivity of (\"G\", \"X\") is irreducible if and only if the corresponding representation of \"G\" is irreducible.\n\nGiven a representation \"V\" of \"G\" the corresponding representation of \"G\" is called the representation induced by \"V\".\n\nSee Theorem 6.2 of (Varadarajan, 1985).\n\nSystems of imprimitivity arise naturally in the determination of the representations of a group \"G\" which is the semi-direct product of an abelian group \"N\" by a group \"H\" that acts by automorphisms of \"N\". This means \"N\" is a normal subgroup of \"G\" and \"H\" a subgroup of \"G\" such that \"G\" = \"N H\" and \"N\" ∩ \"H\" = {\"e\"} (with \"e\" being the identity element of \"G\").\n\nAn important example of this is the inhomogeneous Lorentz group.\n\nFix \"G\", \"H\" and \"N\" as above and let \"X\" be the character space of \"N\". In particular, \"H\" acts on \"X\" by \n\nTheorem. There is a bijection between unitary equivalence classes of representations of \"G\" and unitary equivalence classes of systems of imprimitivity based on (\"H\", \"X\"). This correspondence preserves intertwining operators. In particular, a representation of \"G\" is irreducible if and only if the corresponding system of imprimitivity is irreducible.\n\nThis result is of particular interest when the action of \"H\" on \"X\" is such that every ergodic quasi-invariant measure on \"X\" is transitive. In that case, each such measure is the image of \n(a totally finite version) of Haar measure on \"X\" by the map\n\nA necessary condition for this to be the case is that there is a countable set of \"H\" invariant Borel sets which separate the orbits of \"H\". This is the case for instance for the action of the Lorentz group on the character space of R.\n\nThe Heisenberg group is the group of 3 × 3 \"real\" matrices of the form:\n\nThis group is the semi-direct product of\n\nand the abelian normal subgroup\n\nDenote the typical matrix in \"H\" by [\"w\"] and the typical one in \"N\" by [\"s\",\"t\"]. Then\n\n\"w\" acts on the dual of R by multiplication by the transpose matrix\n\nThis allows us to completely determine the orbits and the representation theory.\n\nOrbit structure: The orbits fall into two classes: \n\nFixed point subgroups: These also fall into two classes depending on the orbit:\nClassification: This allows us to completely classify all irreducible representations of the Heisenberg group. These are parametrized by the set consisting of\n\nWe can write down explicit formulas for these representations by describing the restrictions to \"N\" and \"H\".\n\nCase (1). The corresponding representation π is of the form: It acts on \"L\"(R) with respect to Lebesgue measure and \n\nCase (2). The corresponding representation is given by the 1-dimensional character\n\n"}
{"id": "536639", "url": "https://en.wikipedia.org/wiki?curid=536639", "title": "Tag (game)", "text": "Tag (game)\n\nTag is a playground game that involves two or more players chasing other players in an attempt to \"tag\" or touch them, usually with their hands. There are many variations; most forms have no teams, scores, or equipment. Usually when a person is tagged, the tagger says, \"Tag, you're it\". \n\nA group of players (two or more) decide who is going to be \"it\", often using a counting-out game such as eeny, meeny, miny, moe. The player selected to be \"it\" then chases the others, attempting to get close enough to \"tag\" one of them (touching them with a hand) while the others try to escape. A tag makes the tagged player \"it\". In some variations, the previous \"it\" is no longer \"it\" and the game can continue indefinitely, while in others, both players remain \"it\" and the game ends when all players have become \"it\".\n\nThere are many variants which modify the rules for team play, or place restrictions on tagged players' behavior. A simple variation makes tag an elimination game, so those tagged drop out of play. Some variants have a rule preventing a player from tagging the person who has just tagged them (known as \"no tag-backs\", \"no returns\", or \"can't tag your master\").\n\nPlayers may be safe from being tagged under certain circumstances: if they are within a pre-determined area, off the ground, or when touching a particular structure. Traditional variants are Wood tag, Iron tag, and Stone tag, when a player is safe when touching the named material. This safe zone has been called a \"gool\", \"ghoul\", or \"Dell\", probably a corruption of \"goal\". The term \"gool\" was first recorded in print in Massachusetts in the 1870s, and is common in the northern states of the US. Variants include gould, goul, and ghoul, and alternatives include base and home. In the United Kingdom, the base is frequently known as \"den\". In much of Canada and parts of the northern United States, the state or home base of being immune from tagging is known as \"times\" or \"T.\"\n\nPlayers may also make themselves safe from being tagged by the use of a truce term. When playing the game tag, some may cross fingers as to let others know that they, the player, cannot be it. Yet, this rule may only come into play if the crossing of fingers is shown, if the fingers are not shown to the person that is it, then the crossing does not count.\n\nTag and other chasing games have been banned in some schools in the United States due to concerns about injuries, complaints from children that it can lead to harassment and bullying, and that there is an aspect to the game that possesses an unhealthily predatory element to its nature. In 2008, a 10-year-old boy in Omaha, Nebraska died from brain injuries suffered from falling onto a metal pole while playing tag. A school dinner lady in Dorset was left partially paralyzed after a boy playing tag ran into her in 2004; her claim for damage was rejected by three Court of Appeal judges, who ruled that the boy had not broken any school rules by playing the game.\n\nA principal who banned tag in her school criticized the game for creating a \"self-esteem issue\" in nominating one child as a victim, and noted that the oldest and biggest children usually dominated the game. A dislike of elimination games is another reason for banning tag. In some schools only supervised tag is allowed, sometimes with a type of tagging called butterfly tagging—a light tap on the shoulders, arms or upper back.\n\nThe president of the US National Association for Sport and Physical Education said that \"Tag games are not inherently bad ... teachers must modify rules, select appropriate boundaries and equipment, and make sure pupils are safe. Teachers should emphasize tag games that develop self-improvement, participation, fair play, and cooperation.\"\n\nThe game \"British bulldogs\" (sometimes also called Bullrush, Cat and Mouse, Red Rover, Cats and Mice, Sharks and Minnows, Spiders and Flies, or Octopus) is mainly played in the United Kingdom, Australia, New Zealand, Canada, and other Commonwealth countries. It is banned from many schools. One or two players start as the \"bulldogs\", who stand in the middle of the play area, while the other players stand at one end of the area. The aim is to run from one end of the area to the other without being caught by the bulldogs. When a player is caught, they become a bulldog themselves. The winner is the last player \"free\".\n\nThis is a variant of Build Ups in which each person to be caught joins hands with \"it,\" and the chain thus formed must chase the others as a pair. As more people are caught they too join hands with the \"it\" players, forming a lengthening chain. This variation is also called Blob, or in some places, Gargon. Only those at the ends of the chain are able to catch someone, as they are the only ones with a free hand. A variant has chains of four splitting in two.\n\nIn this game, usually played by young children, the players sit in a circle facing inward. One player, the \"picker\" or \"fox\", walks around tapping or pointing to each player in turn, calling each of them a \"duck\", until finally announcing one of his choosing to be the \"goose\". The goose then rises and runs around the circle in the same direction as the picker, attempting to return to their seat before the \"picker\" can sit back down in the vacated spot. In Minnesota, this game is referred to as \"Duck, duck, gray duck\".\n\nAlso known as Stuck in the Mud, Scarecrow, Sticky-Glue, Zombie Tag, Ice-and-Water (in Asia) or Ice-and-Fire (in Malaysia), players who are tagged are \"stuck in the mud\" or \"frozen\" and must stand in place with their arms stretched out until they are unfrozen. An unstuck player can perform an action to unfreeze them, such as tagging them, crawling between their legs, or \"flushing\" them by hitting their outstretched hand. The last person standing, for most games, is usually the next person who will be it.\n\nKiss chase, also referred to as Catch and Kiss, is a tag variant in which tagging is performed by kissing. All members of one gender are \"it\" at once and chase players of the opposite sex until everyone is caught, then the roles are reversed. A variant is that the player chosen to be \"it\" will, with assistance from players of the same gender, chase all members of the opposite sex and kiss one of them, who is then \"it\" on behalf of the other gender.\n\nLast tag was played in the early 20th century, when it was a way to say goodbye when leaving school for home. A player tags another and makes them \"it\" before leaving on their way home. There is no tagging back. It was a point of honor not to be left with the last tag. If a player is unable to tag anyone by the end of the game, they became \"it\" the next day.\n\nOctopus tag is a mix between Red Rover and tag. \"It,\" or \"octopus,\" attempts to tag the other players. The playing field is known as the ocean. The players, or \"fish,\" line up along one side of the ocean. When the Octopus calls out, \"Come fishies come!\", they try to run to the other side without getting tagged. In a variation, once the fish run to the other side without getting tagged, the game pauses until the octopus starts it again. Upon getting tagged the fish become \"seaweed\" and must freeze or sit where they were tagged, but they can wave their arms around and assist the Octopus in tagging other fish within their reach. The last fish to be tagged becomes the next Octopus. This game can also be played in the water and then it is called Sharks and Minnows.\n\nCops and robbers, sometimes called \"jail\", \"jail tag\", \"team tag\", \"chase\", \"police and thief\", \"prisoner's base\" \"jailbreak\", \"releaseo\" or \"manhunt\", has players split into two teams: cops and robbers.\n\nA. M. Burrage calls this version of the game \"Smee\" in his 1931 ghost story of the same name. The cops, who are in pursuit of robbers (the team being chased), arrest the robbers by tagging and putting them in jail. Robbers can stage a jailbreak by tagging one of the prisoners without getting tagged themselves. The game ends if all the robbers are in jail. In a variant, the robbers have five minutes to hide before being hunted, and only one jailbreak may be allowed per robber.\n\nHumans vs. Zombies is a survival game of tag, where \"human\" players fight off increasingly large numbers of \"zombies\"; if a human is \"turned\" (i.e. tagged), then that player becomes a zombie in turn. At the game's beginning, there are only one or two zombies; the zombies multiply by tagging humans, turning them into zombies after a period of one hour. Humans can defend themselves from zombies by using socks, marshmallows, Nerf Blasters or any other toys deemed safe and appropriate; if a zombie is hit by one of these methods of defense, they are stunned (not allowed to interact with the game in any way) for 15 seconds. The goal of the zombies is to turn all the humans; the humans, meanwhile, must outlast all the zombies.\n\nManhunt is a mixture of hide and seek and tag, often played during the night. One person is \"it\", while the other players have to hide. Then, the person who is \"it\" tries to find and tag them. The game is over when all players are out. Manhunt is sometimes played in teams. In one variant there is a home base in which a player is safe. That version ends when all players who are not safe are out.\n\nIn Prisoner's Base, each team starts in a chain, holding hands, with one end of the chain touching the base. The end two players on each team break from the chain and try to tag each other, taking them to their base if they do. The end pair progressively break from the chain and join the tagging. As with Cops and Robbers, prisoners can be freed by tagging them in the base. The game is thought to date back to the Renaissance period, and may be inspired by the act of bride kidnapping. A game of Prisoner's Base was played by members of Lewis & Clark's Corps of Discovery against a group of Nez Perce.\n\nOne player is chosen to be Mr Wolf and stands facing away from the other players at the opposite end of the playing field. All players except Mr Wolf chant in unison \"What's the time, Mr Wolf?\", and Mr Wolf will answer in one of two ways: Mr Wolf may call a time - usually an hour ending in \"o'clock\". The other players take that many steps towards Mr Wolf. They then ask the question again. Alternatively Mr Wolf may call \"Dinner time!\", and turn and chase the other players back to their starting point. If Mr Wolf tags a player, that player becomes Mr Wolf for the next round.\n\nIn Ringolevio, there are two teams. In one version, one team goes off and hides. The other team counts to a number such as 30 and then goes looking for them. In another version, each team has its own \"jail\", a park bench or other defendable area. The game goes on until all of one team is in jail. In many ways, Ringolevio is similar to Prisoner's Base.\n\nSome variants of tag use equipment such as balls, paintball guns, or even flashlights to replace tagging by hand.\n\nBlind man's bluff, also known as Mr. Blind Man, is a version of tag in which one player, designated as \"it\", is blindfolded and attempts to tag the other players, while the other players try to avoid them.\n\nResearch students developed a version of tag played using handheld WiFi-enabled computers with GPS.\n\nFlashlight tag, also called \"Army tag\", \"Spotlight\", and \"German Spotlight\", is played at night. Rather than physically tagging, the \"it\" player tags by shining a flashlight beam on other players.\n\nA traditional type of line tag, sometimes played in snow, is Fox and geese. The fox starts at the centre of a spoked wheel, and the geese flee from the fox along the spokes and around the wheel. Geese that are tagged become foxes. The intersections of the spokes with the wheel are safe zones.\n\nOne person is \"it\" and a can is placed in an open space. The other players run off and hide, then it tries to find and tag each of them. Tagged players are sent to jail. Any player who has not been caught can kick the can, setting the other players free from jail.\n\nLaser tag is similar to flashlight tag, but using special equipment to avoid the inevitable arguments that arise about whether one was actually tagged. Players carry guns that emit beams of light and wear electronic equipment that can detect the beams and register being hit. The equipment often has built-in scoring systems and various penalties for taking hits. Pay-per-game laser tag facilities are common in North America.\n\nAn aquatic American variant of blind man's bluff, most commonly played in a swimming pool, although it may also be played while swimming in shallow natural bodies of water (typically the areas near the shores of oceans, seas, and lakes). The players may be swimming, treading water, or walking on the bottom of the pool or body of water. The person designated \"it\" is required to close their eyes, and shouts \"Marco!\" at regular intervals; the other players must shout \"Polo!\" in response. \"It\" must use sound localization to find one of the other players and tag them. The tagged player then generally becomes \"it,\" and the process repeats. \n\nMuckle (sometimes called \"muckle the man with the ball\", \"kill-the-guy-with-the-ball\", \"kill the carrier\", among other names) is the reverse of regular tag; all of the other players chase \"it\". This player is denoted by carrying a ball (usually a football). When they are caught, they are tackled, or \"muckled\". Whoever retrieves the ball first or whoever attacks the one who is it then becomes it. Sometimes the last player arriving to tackle the former ball carrier is the next person to be it; in other variations the player with the ball throws the ball up in the air, where it is caught by another player who becomes it.\n\nPaintball is a sport in which players use compressed air guns (called paintball markers) to tag other players with paint-filled pellets. Games are usually played on commercial fields with a strict set of safety and gameplay rules.\n\nA tube sock is filled with a small amount of flour in the toe of the sock; the sock is then gripped by the leg hole and wielded as a flail. Striking a player with any part of the sock counts as a tag.\n\nSpud is a tag variant that is best played in large, open areas. Players begin each round in a central location. \"it\" then throws a ball high into the air. The other players run but must stop as soon as \"it\" catches the ball and shouts \"Spud!\" It may then take three large steps toward the player of his choosing before throwing the ball at that player. If the ball hits the target, that player becomes it, and the game starts over.\n\nIn South Asia, two sports are variants of tag, played at the team level, sometimes internationally. In Kabaddi, raiders cross a dividing line to try to tag defenders, while continuously chanting \"kabbadi\" on one breath while over the line. It is included in the Asian Games and even has a world championship, being played throughout India, Pakistan, Bangladesh, Sri Lanka, and Iran, as well as in Indian communities in Canada, Great Britain, the U.S., Australia, New Zealand, and the Netherlands. It was also demonstrated in 1936 Berlin Olympics. The other tag sport is called Kho Kho.\n\nTag or flag rugby is a non-contact variation in which each player wears a belt that has two velcro tags attached to it, or shorts with velcro patches. The mode of play is also similar to rugby league with attacking players attempting to dodge, evade and pass a rugby ball while defenders attempt to prevent them scoring by tagging - pulling a velcro attached tag from the ball carrier. However, the \"tag\" in \"tag rugby\" is derived from the \"tags\" that the players wear and the children's game of tag more closely resembles touch rugby whereby a touch replaces a tackle.\n\n"}
{"id": "1817053", "url": "https://en.wikipedia.org/wiki?curid=1817053", "title": "Thabit number", "text": "Thabit number\n\nIn number theory, a Thabit number, Thâbit ibn Kurrah number, or 321 number is an integer of the form formula_1 for a non-negative integer \"n\".\n\nThe first few Thabit numbers are:\n\nThe 9th Century mathematician, physician, astronomer and translator Thābit ibn Qurra is credited as the first to study these numbers and their relation to amicable numbers.\n\nThe binary representation of the Thabit number 3·2−1 is \"n\"+2 digits long, consisting of \"10\" followed by \"n\" 1s.\n\nThe first few Thabit numbers that are prime (also known as Thabit primes or 321 primes):\n\n, there are 62 known prime Thabit numbers. Their \"n\" values are :\n\nThe primes for \"n\"≥234760 were found by the distributed computing project 321 search. The largest of these, 3·2−1, has 3580969 digits and was found in June 2015.\n\nIn 2008, Primegrid took over the search for Thabit primes. It is still searching and has already found all currently known Thabit primes with n ≥ 4235414. It is also searching for primes of the form 3·2+1, such primes are called Thabit primes of the second kind or 321 primes of the second kind.\n\nThe first few Thabit numbers of the second kind are:\n\nThe first few Thabit primes of the second kind are:\n\nTheir \"n\" values are:\n\nWhen both \"n\" and \"n\"−1 yield Thabit primes (of the first kind), and formula_2 is also prime, a pair of amicable numbers can be calculated as follows:\n\nFor example, \"n\" = 2 gives the Thabit prime 11, and \"n\"−1 = 1 gives the Thabit prime 5, and our third term is 71. Then, 2=4, multiplied by 5 and 11 results in 220, whose divisors add up to 284, and 4 times 71 is 284, whose divisors add up to 220.\n\nThe only known \"n\" satisfying these conditions are 2, 4 and 7, corresponding to the Thabit primes 11, 47 and 383 given by \"n\", the Thabit primes 5, 23 and 191 given by \"n\"−1, and our third terms are 71, 1151 and 73727. (The corresponding amicable pairs are (220, 284), (17296, 18416) and (9363584, 9437056))\n\nFor integer \"b\" ≥ 2, a Thabit number base \"b is a number of the form (\"b\"+1)·\"b\" − 1 for a non-negative integer \"n\". Also, for integer \"b\" ≥ 2, a Thabit number of the second kind base \"b is a number of the form (\"b\"+1)·\"b\" + 1 for a non-negative integer \"n\".\n\nThe Williams numbers are also a generalization of Thabit numbers. For integer \"b\" ≥ 2, a Williams number base \"b is a number of the form (\"b\"−1)·\"b\" − 1 for a non-negative integer \"n\". Also, for integer \"b\" ≥ 2, a Williams number of the second kind base \"b is a number of the form (\"b\"−1)·\"b\" + 1 for a non-negative integer \"n\".\n\nFor integer \"b\" ≥ 2, a Thabit prime base \"b is a Thabit number base \"b that is also prime. Similarly, for integer \"b\" ≥ 2, a Williams prime base \"b is a Williams number base \"b that is also prime.\n\nEvery prime \"p\" is a Thabit prime of the first kind base \"p\", a Williams prime of the first kind base \"p\"+2, and a Williams prime of the second kind base \"p\"; if \"p\" ≥ 5, then \"p\" is also a Thabit prime of the second kind base \"p\"−2.\n\nIt is a conjecture that for every integer \"b\" ≥ 2, there are infinitely many Thabit primes of the first kind base \"b\", infinitely many Williams primes of the first kind base \"b\", and infinitely many Williams primes of the second kind base \"b\"; also, for every integer \"b\" ≥ 2 that is not congruent to 1 modulo 3, there are infinitely many Thabit primes of the second kind base \"b\". (If the base \"b\" is congruent to 1 modulo 3, then all Thabit numbers of the second kind base \"b\" are divisible by 3 (and greater than 3, since \"b\" ≥ 2), so there are no Thabit primes of the second kind base \"b\".)\n\nThe exponent of Thabit primes of the second kind cannot congruent to 1 mod 3 (except 1 itself), the exponent of Williams primes of the first kind cannot congruent to 4 mod 6, and the exponent of Williams primes of the second kind cannot congruent to 1 mod 6 (except 1 itself), since the corresponding polynomial to \"b\" is a reducible polynomial. (If \"n\" ≡ 1 mod 3, then (\"b\"+1)·\"b\" + 1 is divisible by \"b\" + \"b\" + 1; if \"n\" ≡ 4 mod 6, then (\"b\"−1)·\"b\" − 1 is divisible by \"b\" − \"b\" + 1; and if \"n\" ≡ 1 mod 6, then (\"b\"−1)·\"b\" + 1 is divisible by \"b\" − \"b\" + 1) Otherwise, the corresponding polynomial to \"b\" is an irreducible polynomial, so if Bunyakovsky conjecture is true, then there are infinitely many bases \"b\" such that the corresponding number (for fixed exponent \"n\" satisfying the condition) is prime. ((\"b\"+1)·\"b\" − 1 is irreducible for all nonnegative integer \"n\", so if Bunyakovsky conjecture is true, then there are infinitely many bases \"b\" such that the corresponding number (for fixed exponent \"n\") is prime)\n\nLeast \"k\" ≥ 1 such that (\"n\"+1)·\"n\" − 1 is prime are: (start with \"n\" = 2)\n\nLeast \"k\" ≥ 1 such that (\"n\"+1)·\"n\" + 1 is prime are: (start with \"n\" = 2, 0 if no such \"k\" exists)\n\nLeast \"k\" ≥ 1 such that (\"n\"−1)·\"n\" − 1 is prime are: (start with \"n\" = 2)\n\nLeast \"k\" ≥ 1 such that (\"n\"−1)·\"n\" + 1 is prime are: (start with \"n\" = 2)\n\n"}
{"id": "36054202", "url": "https://en.wikipedia.org/wiki?curid=36054202", "title": "Two-body Dirac equations", "text": "Two-body Dirac equations\n\nIn quantum field theory, and in the significant subfields of quantum electrodynamics and quantum chromodynamics, the two-body Dirac equations (TBDE) of constraint dynamics provide a three-dimensional yet manifestly covariant reformulation of the Bethe–Salpeter equation for two spin-1/2 particles. Such a reformulation is necessary since without it, as shown by Nakanishi, the Bethe–Salpeter equation possesses negative-norm solutions arising from the presence of an essentially relativistic degree of freedom, the relative time. These \"ghost\" states have spoiled the naive interpretation of the Bethe–Salpeter equation as a quantum mechanical wave equation. The two-body Dirac equations of constraint dynamics rectify this flaw. The forms of these equations can not only be derived from quantum field theory they can also be derived purely in the context of Dirac's constraint dynamics and relativistic mechanics and quantum mechanics. Their structures, unlike the more familiar two-body Dirac equation of Breit, which is a single equation, are that of two simultaneous quantum relativistic wave equations. A single two-body Dirac equation similar to the Breit equation can be derived from the TBDE. Unlike the Breit equation, it is manifestly covariant and free from the types of singularities that prevent a strictly nonperturbative treatment of the Breit equation. \nIn applications of the TBDE to QED, the two particles interact by way of four-vector potentials derived from the field theoretic electromagnetic interactions between the two particles. In applications to QCD, the two particles interact by way of four-vector potentials and Lorentz invariant scalar interactions, derived in part from the field theoretic chromomagnetic interactions between the quarks and in part by phenomenological considerations. As with the Breit equation a sixteen-component spinor Ψ is used.\n\nFor QED, each equation has the same structure as the ordinary one-body Dirac equation in the presence of an external electromagnetic field, given by the 4-potential formula_1. For QCD, each equation has the same structure as the ordinary one-body Dirac equation in the presence of an external field similar to the electromagnetic field and an additional external field given by in terms of a Lorentz invariant scalar formula_2. In natural units: those two-body equations have the form.\n\nwhere, in coordinate space, \"p\" is the 4-momentum, related to the 4-gradient by (the metric used here is formula_5)\n\nand γ are the gamma matrices. The two-body Dirac equations (TBDE) have the property that if\none of the masses becomes very large, say formula_7 then the 16-component Dirac equation reduces to the 4-component one-body Dirac equation for particle one in an external potential.\n\nIn SI units:\n\nwhere \"c\" is the speed of light and\n\nNatural units will be used below. A tilde symbol is used over the two sets of potentials to indicate that they may have additional gamma matrix dependencies not present in the one-body Dirac equation. Any coupling constants such as the electron charge are embodied in the vector potentials.\n\nConstraint dynamics applied to the TBDE requires a particular form of mathematical consistency: the two Dirac operators must commute with each other. This is plausible if one views the two equations as two compatible constraints on the wave function. (See the discussion below on constraint dynamics.) If the two operators did not commute, (as, e.g., with the coordinate and momentum operators formula_11) then the constraints would not be compatible (one could not e.g., have a wave function that satisfied both formula_12 and formula_13). This mathematical consistency or compatibility leads to three important properties of the TBDE. The first is a condition that eliminates the dependence on the relative time in the center of momentum (c.m.) frame defined by formula_14. (The variable formula_15 is the total energy in the c.m. frame.) Stated another way, the relative time is eliminated in a covariant way. In particular, for the two operators to commute, the scalar and four-vector potentials can depend on the relative coordinate formula_16 only through its component formula_17 orthogonal to formula_18 in which\n\nThis implies that in the c.m. frame formula_21, which has zero time component.\n\nSecondly, the mathematical consistency condition also eliminates the relative energy in the c.m. frame. It does this by imposing on each Dirac operator a structure such that in a particular combination they lead to this interaction independent form, eliminating in a covariant way the relative energy.\n\nIn this expression formula_23 is the relative momentum having the form formula_24 for equal masses. In the c.m. frame (formula_25), the time component formula_26 of the relative momentum, that is the relative energy, is thus eliminated. in the sense that formula_27.\n\nA third consequence of the mathematical consistency is that each of the world scalar formula_28 and four vector formula_29 potentials has a term with a fixed dependence on formula_30 and formula_31 in addition to the gamma matrix independent forms of formula_32 and formula_33 which appear in the ordinary one-body Dirac equation for scalar and vector potentials.\nThese extra terms correspond to additional recoil spin-dependence not present in the one-body Dirac equation and vanish when one of the particles becomes very heavy (the so-called static limit).\n\nConstraint dynamics arose from the work of Dirac and Bergmann. This section\nshows how the elimination of relative time and energy takes place in the\nc.m. system for the simple system of two relativistic spinless particles.\nConstraint dynamics was first applied to the classical relativistic two particle system by Todorov, Kalb\nand Van Alstine, Komar, and Droz-Vincent. With constraint dynamics, these authors found a consistent and covariant approach to relativistic canonical Hamiltonian mechanics that also evades the Currie-Jordan-Sudarshan \"No Interaction\" theorem. That theorem states that without fields, one cannot have a relativistic Hamiltonian dynamics. Thus, the same covariant three-dimensional approach which allows the quantized version of constraint dynamics to remove quantum ghosts simultaneously circumvents at the classical level the C.J.S. theorem. Consider a constraint on the otherwise independent coordinate and momentum four vectors, written in the form formula_34. The symbolformula_35 is called a weak equality and implies that the constraint is to be imposed only after any needed Poisson brackets are performed. In the presence of such constraints, the total\nHamiltonian formula_36 is obtained from the Lagrangian formula_37 by adding to the Legendre Hamiltonian formula_38 the sum of the constraints times an appropriate set of Lagrange multipliers formula_39.\n\nThis total Hamiltonian is traditionally called the Dirac Hamiltonian.\nConstraints arise naturally from parameter invariant actions of the form\n\nIn the case of four vector and Lorentz scalar interactions for a single\nparticle the Lagrangian is\n\nThe canonical momentum is\n\nand by squaring leads to the generalized mass shell condition or generalized\nmass shell constraint\n\nSince, in this case, the Legendre Hamiltonian vanishes\n\nthe Dirac Hamiltonian is simply the generalized mass constraint (with no\ninteractions it would simply be the ordinary mass shell constraint)\n\nOne then postulates that for two bodies the Dirac Hamiltonian is the sum of\ntwo such mass shell constraints,\n\nthat is\n\nand that each constraint formula_50 be constant in the proper time associated with formula_36\n\nHere the weak equality means that the Poisson bracket could result in terms proportional one of the constraints, the classical Poisson brackets for the relativistic two-body system being defined by\n\nTo see the consequences of having each constraint be a constant of the\nmotion, take, for example\n\nSince formula_55 and\nformula_56 and formula_57 one has\n\nThe simplest solution to this is\n\nwhich leads to (note the equality in this case is not a weak one in that no constraint need be imposed after the Poisson bracket is worked out)\n\n(see Todorov, and Wong and Crater ) with the same formula_61 defined\nabove.\n\nIn addition to replacing classical dynamical variables by their quantum counterparts, quantization of the constraint mechanics takes place by replacing the constraint on the dynamical variables with a restriction on the wave function\n\nThe first set of equations for \"i\" = 1, 2 play the role for spinless particles that the two Dirac equations play for spin-one-half particles. The classical Poisson brackets are replaced by commutators\n\nThus\n\nand we see in this case that the constraint formalism leads to the vanishing commutator of the wave operators for the two particlein. This is the analogue of the claim stated earlier that the two Dirac operators commute with one another.\n\nThe vanishing of the above commutator ensures that the dynamics is\nindependent of the relative time in the c.m. frame. In order to\ncovariantly eliminate the relative energy, introduce the relative momentum formula_66 defined by\n\nP+p\\,</math>|}} \nThe above definition of the relative momentum forces the orthogonality of the total\nmomentum and the relative momentum,\n\nwhich follows from taking the scalar product of either equation with formula_18.\nFrom Eqs.() and (), this relative momentum can be written in terms of \nformula_69 and formula_70 as\n\nwhere \nare the projections of the momenta formula_69 and formula_70 along the direction\nof the total momentum formula_18. Subtracting the two constraints formula_77 and formula_78, gives\n\nThus on these states formula_79 \n\nThe equation formula_82 describes both the c.m. motion and the\ninternal relative motion. To characterize the former motion, observe that\nsince the potential formula_83 depends only on the difference of the two\ncoordinates\n\n(This does not require that formula_85 since the formula_86.) Thus, the total momentum formula_18 is a constant of motion and \nformula_79 is an eigenstate state characterized by a total momentum \nformula_89. In the c.m. system formula_90 with formula_15 the\ninvariant center of momentum (c.m.) energy. Thus\n\nand so formula_79 is also an eigenstate of c.m. energy operators for each of\nthe two particles, \nThe relative momentum then satisfies\n\nso that\n\nThe above set of equations follow from the constraints formula_98 and the definition of the relative momenta given in Eqs.() and ().\nIf instead one chooses to define (for a more general choice see Horwitz),\nindependent of the wave function, then\nand it is straight forward to show that the constraint Eq.() leads\ndirectly to\n\nin place of formula_67. This conforms with the earlier claim on the\nvanishing of the relative energy in the c.m. frame made in conjunction with\nthe TBDE.\\ In the second choice the c.m. value of the relative energy is\nnot defined as zero but comes from the original generalized mass shell\nconstraints. The above equations for the relative and constituent\nfour-momentum are the relativistic analogues of the nonrelativistic equations\n\nUsing Eqs.(),(),(), one can write formula_36 in terms of formula_18 and formula_23 \nwhere\n\nEq.() contains both the total momentum formula_18 [through the formula_112] and the relative momentum formula_23. Using Eq. (), one obtains the eigenvalue equation\n\nso that formula_114 becomes the standard triangle\nfunction displaying exact relativistic two-body kinematics:\n\nWith the above constraint Eqs.() on formula_79 then formula_117 where formula_118. This allows \nwriting Eq. () in the form of an eigenvalue equation\n\nhaving a structure very similar to that of the ordinary three-dimensional\nnonrelativistic Schrödinger equation. It is a manifestly covariant\nequation, but at the same time its three-dimensional structure is evident.\nThe four-vectors formula_120 and formula_121 have only\nthree independent components since\n\nThe similarity to the three-dimensional structure of the nonrelativistic\nSchrödinger equation can be made more explicit by writing the equation in\nthe c.m. frame in which\n\nComparison of the resultant form \nwith the time independent Schr\\\"{o}dinger equation\n\nmakes this similarity explicit.\n\nA plausible structure for the quasipotential formula_83 can be found by\nobserving that the one-body Klein-Gordon equation formula_127 takes the form formula_128 when one\nintroduces a scalar interaction and timelike vector interaction via formula_129and formula_130. In the\ntwo-body case, separate classical and quantum field theory \narguments show that when one includes world scalar and\nvector interactions then formula_83 depends on two underlying invariant\nfunctions formula_132 and formula_133 through the two-body Klein-Gordon-like potential\nform with the same general structure, that is\nThose field theories further yield the c.m. energy dependent forms \nand\nones that Tododov introduced as the relativistic reduced mass\nand effective particle energy for a two-body system. Similar to what\nhappens in the nonrelativistic two-body problem, in the relativistic case\nwe have the motion of this effective particle taking place as if it were in\nan external field (here generated by formula_2 and formula_138). The two kinematical\nvariables formula_139 and formula_140 are related to one another by the\nEinstein condition \nIf one introduces the four-vectors, including a vector interaction formula_142\nand scalar interaction formula_132, then the following classical minimal\nconstraint form\nreproduces\n\nNotice, that the interaction in this \"reduced particle\" constraint depends\non two invariant scalars, formula_133 and formula_132, one guiding the time-like\nvector interaction and one the scalar interaction.\n\nIs there a set of two-body Klein-Gordon equations analogous to the two-body Dirac\nequations? The classical relativistic constraints analogous to the quantum\ntwo-body Dirac equations (discussed in the introduction) and that have the same structure as the above\nKlein-Gordon one-body form are\nDefining structures that display time-like vector and scalar interactions\ngives\nImposing\nand using the constraint formula_160, reproduces Eqs.() provided\n\nThe corresponding Klein-Gordon equations are\nand each, due to the constraint formula_167 is equivalent to\n\nFor the two body system there are numerous covariant forms of interaction. \nThe simplest way of looking at these is from the point of view of the gamma\nmatrix structures of the corresponding interaction vertices of the single\nparaticle exchange diagrams. For scalar, pseudoscalar, vector,\npseudovector, and tensor exchanges those matrix structures are respectively \nin which\nThe form of the Two-Body Dirac equations which most readily incorporates\neach or any number of these intereractions in concert is the so-called hyperbolic form of the TBDE\n. For combined scalar and vector\ninteractions those forms ultimately reduce to the ones given in the first\nset of equations of this article. Those equations are called the external\nfield-like forms because their appearances are individually the same as\nthose for the usual one-body Dirac equation in the presence of external\nvector and scalar fields.\n\nThe most general hyperbolic form for compatible TBDE is\n\nwhere formula_172 represents any invariant interaction singly or in\ncombination. It has a matrix structure in addition to coordinate\ndependence. Depending on what that matrix structure is one has either\nscalar, pseudoscalar, vector, pseudovector, or tensor interactions. The\noperators formula_173 and formula_174 are auxiliary constraints\nsatisfying \n\nin which the formula_176 are the free Dirac operators \n\\gamma _{5i}(\\gamma _{i}\\cdot\np_{i}+m_{i})=0, \nThis, in turn leads to the two compatibility conditions \nand \nprovided that formula_179 These compatibility\nconditions do not restrict the gamma matrix structure of formula_172. That\nmatrix structure is determined by the type of vertex-vertex structure \nincorporated in the interaction. For the two types of invariant\ninteractions formula_172 emphasized in this article they are\n\nFor general independent scalar and vector interactions\nThe vector interaction specified by the above matrix structure for an electromagnetic-like interaction would correspond to the Feynman gauge.\n\nIf one inserts Eq.() into () and brings the free\nDirac operator () to the right of the matrix hyperbolic functions\nand uses standard gamma matrix commutators and anticommutators and formula_186 one arrives at formula_187\n\nin which \nThe (covariant) structure of these equations are analogous to those of a Dirac equation for each of the two particles, with formula_194 and formula_195\nplaying the roles that formula_196 and formula_197 do in the single particle\nDirac equation \nOver and above the usual kinetic part formula_199 and \ntime-like vector and scalar potential portions, the spin-dependent\nmodifications involving formula_200\nand the last set of derivative terms are two-body recoil effects absent for\nthe one-body Dirac equation but essential for the compatibility\n(consistency) of the two-body equations. The connections between what\nare designated as the vertex invariants formula_201 and the\nmass and energy potentials formula_202 are \nComparing Eq.() with the first equation of this article one finds\nthat the spin-dependent vector interactions are \nNote that the first portion of the vector potentials is timelike (parallel\nto formula_209 while the next portion is spacelike (perpendicular to formula_210. The spin-dependent scalar potentials formula_211 are \n\nThe parametrization for formula_214 and formula_215 takes advantage of\nthe Todorov effective external potential forms (as seen in the above section\non the two-body Klein Gordon equations) and at the same time displays the\ncorrect static limit form for the Pauli reduction to Schrödinger-like\nform. The choice for these parameterizations (as with the two-body Klein\nGordon equations) is closely tied to classical or quantum field\ntheories for separate scalar and vector interactions. This\namounts to working in the Feynman gauge with the simplest relation between\nspace- and timelike parts of the vector interaction.\nThe mass and energy potentials are respectively \nso that \n\nThe TBDE can be readily applied to two body systems such as positronium, muonium, hydrogen-like atoms, quarkonium, and the two-nucleon system. These applications involve two particles only and do not involve creation or annihilation of particles beyond the two. They involve only elastic processes. Because of the connection between the potentials used in the TBDE and the corresponding quantum field theory, any radiative correction to the lowest order interaction can be incorporated into those potentials. To see how this comes about, consider by contrast how one computes scattering amplitudes without quantum field theory. With no quantum field theory one must come upon potentials by classical arguments or phenomenological considerations. Once one has the potential formula_220 between two particles, then one can compute the scattering amplitude formula_221 from the Lippmann-Schwinger equation \n\nin which formula_223 is a Green function determined from the Schrödinger equation. Because of the similarity between the Schrödinger equation Eq. () and the relativistic constraint equation (),one can derive the same type of equation as the above\n\ncalled the quasipotential equation with a formula_215 very similar to that given in the Lippmann-Schwinger equation. The difference is that with the quasipotential equation, one starts with the scattering amplitudes formula_226 of quantum field theory, as determined from Feynman diagrams and deduces the quasipotential Φ perturbatively. Then one can use that Φ in (), to compute energy levels of two particle systems that are implied by the field theory. Constraint dynamics provides one of many, in fact an infinite number of, different types of quasipotential equations (three-dimensional truncations of the Bethe-Salpeter equation) differing from one another by the choice of formula_215. \nThe relatively simple solution to the problem of relative time and energy from the generalized mass shell constraint for two particles, has no simple extension, such as presented here with the formula_228 variable, to either two particles in an external field or to 3 or more particles. Sazdjian has presented a receipe for this extension when the particles are confined and cannot split into clusters of a smaller number of particles with no inter-cluster interactions Lusanna has developed an approach, one that does not involve generalized mass shell constraints with no such restrictions, which extends to N bodies with or without fields. It is formulated on spacelike hypersurfaces and when restricted to the family of hyperplanes orthogonal to the total timelike momentum gives rise to a covariant intrinsic 1-time formulation (with no relative time variables) called the \"rest-frame instant form\" of dynamics,\n\n"}
{"id": "31911", "url": "https://en.wikipedia.org/wiki?curid=31911", "title": "Ultrafilter", "text": "Ultrafilter\n\nIn the mathematical field of set theory, an ultrafilter on a given partially ordered set (poset) \"P\" is a maximal filter on \"P\", that is, a filter on \"P\" that cannot be enlarged. Filters and ultrafilters are special subsets of \"P\". If \"P\" happens to be a Boolean algebra, each ultrafilter is also a prime filter, and vice versa. \n\nIf \"X\" is an arbitrary set, its power set ℘(\"X\"), ordered by set inclusion, is always a Boolean algebra, and (ultra)filters on ℘(\"X\") are usually called \"(ultra)filters on \"X\"\".Ultrafilters have many applications in set theory, model theory, and topology. An ultrafilter on a set \"X\" may be considered as a finitely additive measure. In this view, every subset of \"X\" is either considered \"almost everything\" (has measure 1) or \"almost nothing\" (has measure 0).\n\nIn order theory, an ultrafilter is a subset of a partially ordered set that is maximal among all proper filters. This implies that any filter that properly contains an ultrafilter has to be equal to the whole poset.\n\nFormally, if \"P\" is a set, partially ordered by (≤), then \n\nAn important special case of the concept occurs if the considered poset is a Boolean algebra. In this case, ultrafilters are characterized by containing, for each element \"a\" of the Boolean algebra, exactly one of the elements \"a\" and ¬\"a\" (the latter being the Boolean complement of \"a\"):\n\nIf \"P\" is a Boolean algebra and \"F\" ⊊ \"P\" is a proper filter, then the following statements are equivalent:\nA proof of 1.⇔2. is also given in (Burris, Sankappanavar, 2012, Cor.3.13, p.133)\n\nMoreover, ultrafilters on a Boolean algebra can be related to prime ideals, maximal ideals, and homomorphisms to the 2-element Boolean algebra {true, false}, as follows:\n\nGiven an arbitrary set \"X\", its power set ℘(\"X\"), ordered by set inclusion, is always a Boolean algebra; hence the results of the above section \"\" apply. An (ultra)filter on ℘(\"X\") is often called just an \"(ultra)filter on \"X\"\". The above formal definitions can be particularized to the powerset case as follows:\n\nGiven an arbitrary set \"X\", an ultrafilter on ℘(\"X\") is a set \"U\" consisting of subsets of \"X\" such that:\n\nA characterization is given by the following theorem.\nA filter \"U\" on ℘(\"X\") is an ultrafilter if any of the following conditions are true:\n\nAnother way of looking at ultrafilters on a power set ℘(\"X\") is to define a function \"m\" on ℘(\"X\") by setting \"m\"(\"A\") = 1 if \"A\" is an element of \"U\" and \"m\"(\"A\") = 0 otherwise. Such a function is called a 2-valued morphism. Then \"m\" is finitely additive, and hence a \"content\" on ℘(\"X\"), and every property of elements of \"X\" is either true almost everywhere or false almost everywhere. However, \"m\" is usually not \"countably additive\", and hence does not define a measure in the usual sense.\n\nFor a filter \"F\" that is not an ultrafilter, one would say \"m\"(\"A\") = 1 if \"A\" ∈ \"F\" and \"m\"(\"A\") = 0 if \"X\" \\ \"A\" ∈ \"F\", leaving \"m\" undefined elsewhere.\n\nThe completeness of an ultrafilter \"U\" on a powerset is the smallest cardinal κ such that there are κ elements of \"U\" whose intersection is not in \"U\". The definition implies that the completeness of any powerset ultrafilter is at least formula_1. An ultrafilter whose completeness is \"greater\" than formula_1—that is, the intersection of any countable collection of elements of \"U\" is still in \"U\"—is called countably complete or σ-complete.\n\nThe completeness of a countably complete nonprincipal ultrafilter on a powerset is always a measurable cardinal.\nThere are two very different types of ultrafilter: principal and free. A principal (or fixed, or trivial) ultrafilter is a filter containing a least element. Consequently, principal ultrafilters are of the form \"F\" = {\"x\" | \"a\" ≤ \"x\"} for some (but not all) elements \"a\" of the given poset. In this case \"a\" is called the \"principal element\" of the ultrafilter. Any ultrafilter that is not principal is called a free (or non-principal) ultrafilter. \n\nFor ultrafilters on a powerset ℘(\"S\"), a principal ultrafilter consists of all subsets of \"S\" that contain a given element \"s\" of \"S\". Each ultrafilter on ℘(\"S\") that is also a principal filter is of this form. Therefore, an ultrafilter \"U\" on ℘(\"S\") is principal if and only if it contains a finite set. If \"S\" is infinite, an ultrafilter \"U\" on ℘(\"S\") is hence non-principal if and only if it contains the Fréchet filter of cofinite subsets of \"S\". If \"S\" is finite, each ultrafilter is principal.\n\nUltrafilters on powersets are useful in topology, especially in relation to compact Hausdorff spaces, and in model theory in the construction of ultraproducts and ultrapowers. Every ultrafilter on a compact Hausdorff space converges to exactly one point. Likewise, ultrafilters on Boolean algebras play a central role in Stone's representation theorem.\n\nThe set \"G\" of all ultrafilters of a poset \"P\" can be topologized in a natural way, that is in fact closely related to the above-mentioned representation theorem. For any element \"a\" of \"P\", let \"D\" = {\"U\" ∈ \"G\" | \"a\" ∈ \"U\"}. This is most useful when \"P\" is again a Boolean algebra, since in this situation the set of all \"D\" is a base for a compact Hausdorff topology on \"G\". Especially, when considering the ultrafilters on a powerset ℘(\"S\"), the resulting topological space is the Stone–Čech compactification of a discrete space of cardinality |\"S\"|.\n\nThe ultraproduct construction in model theory uses ultrafilters to produce elementary extensions of structures. For example, in constructing hyperreal numbers as an ultraproduct of the real numbers, the domain of discourse is extended from real numbers to sequences of real numbers. This sequence space is regarded as a superset of the reals by identifying each real with the corresponding constant sequence. To extend the familiar functions and relations (e.g., + and <) from the reals to the hyperreals, the natural idea is to define them pointwise. But this would lose important logical properties of the reals; for example, pointwise < is not a total ordering. So instead the functions and relations are defined \"pointwise modulo \"U\"\", where \"U\" is an ultrafilter on the index set of the sequences; by Łoś' theorem, this preserves all properties of the reals that can be stated in first-order logic. If \"U\" is nonprincipal, then the extension thereby obtained is nontrivial.\n\nIn geometric group theory, non-principal ultrafilters are used to define the asymptotic cone of a group. This construction yields a rigorous way to consider \"looking at the group from infinity\", that is the large scale geometry of the group. Asymptotic cones are particular examples of ultralimits of metric spaces.\n\nGödel's ontological proof of God's existence uses as an axiom that the set of all \"positive properties\" is an ultrafilter.\n\nIn social choice theory, non-principal ultrafilters are used to define a rule (called a \"social welfare function\") for aggregating the preferences of \"infinitely\" many individuals. Contrary to Arrow's impossibility theorem for \"finitely\" many individuals, such a rule satisfies the conditions (properties) that Arrow proposes\n(e.g., Kirman and Sondermann, 1972).\nMihara (1997, 1999)\nshows, however, such rules are practically of limited interest to social scientists, since they are non-algorithmic or non-computable.\nThe Rudin–Keisler ordering is a preorder on the class of powerset ultrafilters defined as follows: if \"U\" is an ultrafilter on ℘(\"X\"), and \"V\" an ultrafilter on ℘(\"Y\"), then \"V\" ≤ \"U\" if there exists a function \"f\": \"X\" → \"Y\" such that\nfor every subset \"C\" of \"Y\".\n\nUltrafilters \"U\" and \"V\" are called Rudin–Keisler equivalent, denoted \"U\" ≡ \"V\", if there exist sets \"A\" ∈ \"U\" and \"B\" ∈ \"V\", and a bijection \"f\": \"A\" → \"B\" that satisfies the condition above. (If \"X\" and \"Y\" have the same cardinality, the definition can be simplified by fixing \"A\" = \"X\", \"B\" = \"Y\".)\n\nIt is known that ≡ is the kernel of ≤, i.e., that \"U\" ≡ \"V\" if and only if \"U\" ≤ \"V\" and \"V\" ≤ \"U\".\n\nThere are several special properties that an ultrafilter on ℘(\"ω\") may possess, which prove useful in various areas of set theory and topology.\n\nIt is a trivial observation that all Ramsey ultrafilters are P-points. Walter Rudin proved that the continuum hypothesis implies the existence of Ramsey ultrafilters.\nIn fact, many hypotheses imply the existence of Ramsey ultrafilters, including Martin's axiom. Saharon Shelah later showed that it is consistent that there are no P-point ultrafilters. Therefore, the existence of these types of ultrafilters is independent of ZFC.\n\nP-points are called as such because they are topological P-points in the usual topology of the space of non-principal ultrafilters. The name Ramsey comes from Ramsey's theorem. To see why, one can prove that an ultrafilter is Ramsey if and only if for every 2-coloring of [\"ω\"] there exists an element of the ultrafilter that has a homogeneous color.\n\nAn ultrafilter on ℘(\"ω\") is Ramsey if and only if it is minimal in the Rudin–Keisler ordering of non-principal powerset ultrafilters.\n\n\n"}
{"id": "9968245", "url": "https://en.wikipedia.org/wiki?curid=9968245", "title": "Vicky Brago-Mitchell", "text": "Vicky Brago-Mitchell\n\nVicky Brago-Mitchell is an American fractal artist known in the 1960s as a Stanford University student who, while working as a topless dancer, ran for student body president. She won the preliminary election, but lost to eventual Earth Day national coordinator Denis Hayes in a two-person runoff election. She was born on September 30, 1946 in Yakima, Washington. Daughter of a Methodist minister, she grew up as Victoria Jane Bowles in small towns in Washington, Oregon and Montana. After graduating from high school she attended Stanford University as a scholarship student majoring in Spanish. In 1967 she was the first American college girl to appear nude in a campus magazine, the Stanford Chaparral (\"Stanford Chaparral\", Spring 1967). In 1968 she began working at night as a topless dancer under the stage name Vicky Drake, and ran for student body president with a campaign poster that was a photo of herself posing nude on the Stanford Mausoleum (\"Stanford Alumni Magazine\", September/October 1994). This story was first reported by the San Francisco Chronicle, May 1, 1968, then carried by wire services Associated Press and United Press International and published in newspapers worldwide. A feature about her titled Student Body appeared in the September 1968 edition of Playboy and was reprinted in the 1971 Playboy special edition The Youth Culture.\n\nFrom 1970 to 1974 she toured the United States and Japan as a stripper, then stayed in Japan for two years, working as a translator, photographer and English teacher. In 1977 she obtained a teaching credential from California State University, Fullerton, then worked as an elementary school teacher until 2005.\n\nIn 2002, she produced a CD of her husband composer John Mitchell’s chamber music for string instruments, recorded in Moscow, and in 2006 arranged the production of a double CD of his chamber music for woodwind instruments by MMC Recordings in Boston, featuring clarinetist Richard Stoltzman. In 2005 her fractal art appeared on the cover of Latin Finance magazine and was shown at the Biennale Internazionale dell’Arte Contemporanea in Florence, Italy.\n\n\n"}
{"id": "16342785", "url": "https://en.wikipedia.org/wiki?curid=16342785", "title": "Wiener sausage", "text": "Wiener sausage\n\nIn the mathematical field of probability, the Wiener sausage is a neighborhood of the trace of a Brownian motion up to a time \"t\", given by taking all points within a fixed distance of Brownian motion. It can be visualized as a sausage of fixed radius whose centerline is Brownian motion. The Wiener sausage was named after Norbert Wiener by because of its relation to the Wiener process; the name is also a pun on Vienna sausage, as \"Wiener\" means \"Viennese\" in German.\n\nThe Wiener sausage is one of the simplest non-Markovian functionals of Brownian motion. Its applications include stochastic phenomena including heat conduction. It was first described by , and it was used by to explain results of a Bose–Einstein condensate, with proofs published by .\n\nThe Wiener sausage \"W\"(\"t\") of radius δ and length \"t\" is the set-valued random variable on Brownian paths b (in some Euclidean space) defined by\n\nThere has been a lot of work on the behavior of the volume (Lebesgue measure) |\"W\"(\"t\")| of the Wiener sausage as it becomes thin (δ→0); by rescaling, this is essentially equivalent to studying the volume as the sausage becomes long (\"t\"→∞).\n\nIn dimension \"d\" at least 3 the volume of the Wiener sausage is asymptotic to\nas \"t\" tends to infinity. In dimensions 1 and 2 this formula gets replaced by formula_4 and formula_5 respectively. , a student of Spitzer, proved similar results for generalizations of Wiener sausages with cross sections given by more general compact sets than balls.\n\n"}
{"id": "18120382", "url": "https://en.wikipedia.org/wiki?curid=18120382", "title": "William Lawrence Kocay", "text": "William Lawrence Kocay\n\nWilliam Lawrence Kocay is a Canadian professor at the department of computer science at St. Paul's College of the University of Manitoba and a graph theorist. He is known for his work in graph algorithms and the reconstruction conjecture and is affectionately referred to as \"Wild Bill\" by his students. Bill Kocay is a former managing editor (from Jan 1988 to May 1997) of \"Ars Combinatoria\", a Canadian journal of combinatorial mathematics, is a founding fellow of the Institute of Combinatorics and its Applications.\n\nHis research interests include algorithms for graphs, the development of mathematical software, the graph reconstruction problem, the graph isomorphism problem, projective geometry, Hamiltonian cycles, planarity, graph embedding algorithms, graphs on surfaces, and combinatorial designs.\n\n\n\n"}
