{"id": "1150875", "url": "https://en.wikipedia.org/wiki?curid=1150875", "title": "157 (number)", "text": "157 (number)\n\n157 (one hundred [and] fifty-seven) is the number following 156 and preceding 158.\n\n157 is:\n\n\nIn base 10, 157 is 24649, and 158 is 24964, which uses the same digits. Numbers having this property are listed in . The previous entry is 13, and the next entry after 157 is 913.\n\nThe simplest right angle triangle with rational sides that has area 157 has the longest side with a denominator of 45 digits.\n\n\n\n\n\n157 is also:\n\n\n"}
{"id": "1997", "url": "https://en.wikipedia.org/wiki?curid=1997", "title": "Algebraic geometry", "text": "Algebraic geometry\n\nAlgebraic geometry is a branch of mathematics, classically studying zeros of multivariate polynomials. Modern algebraic geometry is based on the use of abstract algebraic techniques, mainly from commutative algebra, for solving geometrical problems about these sets of zeros.\n\nThe fundamental objects of study in algebraic geometry are algebraic varieties, which are geometric manifestations of solutions of systems of polynomial equations. Examples of the most studied classes of algebraic varieties are: plane algebraic curves, which include lines, circles, parabolas, ellipses, hyperbolas, cubic curves like elliptic curves, and quartic curves like lemniscates and Cassini ovals. A point of the plane belongs to an algebraic curve if its coordinates satisfy a given polynomial equation. Basic questions involve the study of the points of special interest like the singular points, the inflection points and the points at infinity. More advanced questions involve the topology of the curve and relations between the curves given by different equations.\n\nAlgebraic geometry occupies a central place in modern mathematics and has multiple conceptual connections with such diverse fields as complex analysis, topology and number theory. Initially a study of systems of polynomial equations in several variables, the subject of algebraic geometry starts where equation solving leaves off, and it becomes even more important to understand the intrinsic properties of the totality of solutions of a system of equations, than to find a specific solution; this leads into some of the deepest areas in all of mathematics, both conceptually and in terms of technique.\nIn the 20th century, algebraic geometry split into several subareas.\n\nMuch of the development of the mainstream of algebraic geometry in the 20th century occurred within an abstract algebraic framework, with increasing emphasis being placed on \"intrinsic\" properties of algebraic varieties not dependent on any particular way of embedding the variety in an ambient coordinate space; this parallels developments in topology, differential and complex geometry. One key achievement of this abstract algebraic geometry is Grothendieck's scheme theory which allows one to use sheaf theory to study algebraic varieties in a way which is very similar to its use in the study of differential and analytic manifolds. This is obtained by extending the notion of point: In classical algebraic geometry, a point of an affine variety may be identified, through Hilbert's Nullstellensatz, with a maximal ideal of the coordinate ring, while the points of the corresponding affine scheme are all prime ideals of this ring. This means that a point of such a scheme may be either a usual point or a subvariety. This approach also enables a unification of the language and the tools of classical algebraic geometry, mainly concerned with complex points, and of algebraic number theory. Wiles's proof of the longstanding conjecture called Fermat's last theorem is an example of the power of this approach.\n\nIn classical algebraic geometry, the main objects of interest are the vanishing sets of collections of polynomials, meaning the set of all points that simultaneously satisfy one or more polynomial equations. For instance, the two-dimensional sphere of radius 1 in three-dimensional Euclidean space R could be defined as the set of all points (\"x\",\"y\",\"z\") with\n\nA \"slanted\" circle in R can be defined as the set of all points (\"x\",\"y\",\"z\") which satisfy the two polynomial equations\n\nFirst we start with a field \"k\". In classical algebraic geometry, this field was always the complex numbers C, but many of the same results are true if we assume only that \"k\" is algebraically closed. We consider the affine space of dimension \"n\" over \"k\", denoted A(\"k\") (or more simply A, when \"k\" is clear from the context). When one fixes a coordinate system, one may identify A(\"k\") with \"k\". The purpose of not working with \"k\" is to emphasize that one \"forgets\" the vector space structure that \"k\" carries.\n\nA function \"f\" : A → A is said to be \"polynomial\" (or \"regular\") if it can be written as a polynomial, that is, if there is a polynomial \"p\" in \"k\"[\"x\"...,\"x\"] such that \"f\"(\"M\") = \"p\"(\"t\"...,\"t\") for every point \"M\" with coordinates (\"t\"...,\"t\") in A. The property of a function to be polynomial (or regular) does not depend on the choice of a coordinate system in A.\n\nWhen a coordinate system is chosen, the regular functions on the affine \"n\"-space may be identified with the ring of polynomial functions in \"n\" variables over \"k\". Therefore, the set of the regular functions on A is a ring, which is denoted \"k\"[A].\n\nWe say that a polynomial \"vanishes\" at a point if evaluating it at that point gives zero. Let \"S\" be a set of polynomials in \"k\"[A]. The \"vanishing set of S\" (or \"vanishing locus\" or \"zero set\") is the set \"V\"(\"S\") of all points in A where every polynomial in \"S\" vanishes. Symbolically,\n\nA subset of A which is \"V\"(\"S\"), for some \"S\", is called an \"algebraic set\". The \"V\" stands for \"variety\" (a specific type of algebraic set to be defined below).\n\nGiven a subset \"U\" of A, can one recover the set of polynomials which generate it? If \"U\" is \"any\" subset of A, define \"I\"(\"U\") to be the set of all polynomials whose vanishing set contains \"U\". The \"I\" stands for ideal: if two polynomials \"f\" and \"g\" both vanish on \"U\", then \"f\"+\"g\" vanishes on \"U\", and if \"h\" is any polynomial, then \"hf\" vanishes on \"U\", so \"I\"(\"U\") is always an ideal of the polynomial ring \"k\"[A].\n\nTwo natural questions to ask are:\n\nThe answer to the first question is provided by introducing the Zariski topology, a topology on A whose closed sets are the algebraic sets, and which directly reflects the algebraic structure of \"k\"[A]. Then \"U\" = \"V\"(\"I\"(\"U\")) if and only if \"U\" is an algebraic set or equivalently a Zariski-closed set. The answer to the second question is given by Hilbert's Nullstellensatz. In one of its forms, it says that \"I\"(\"V\"(\"S\")) is the radical of the ideal generated by \"S\". In more abstract language, there is a Galois connection, giving rise to two closure operators; they can be identified, and naturally play a basic role in the theory; the example is elaborated at Galois connection.\n\nFor various reasons we may not always want to work with the entire ideal corresponding to an algebraic set \"U\". Hilbert's basis theorem implies that ideals in \"k\"[A] are always finitely generated.\n\nAn algebraic set is called \"irreducible\" if it cannot be written as the union of two smaller algebraic sets. Any algebraic set is a finite union of irreducible algebraic sets and this decomposition is unique. Thus its elements are called the \"irreducible components\" of the algebraic set. An irreducible algebraic set is also called a \"variety\". It turns out that an algebraic set is a variety if and only if it may be defined as the vanishing set of a prime ideal of the polynomial ring.\n\nSome authors do not make a clear distinction between algebraic sets and varieties and use \"irreducible variety\" to make the distinction when needed.\n\nJust as continuous functions are the natural maps on topological spaces and smooth functions are the natural maps on differentiable manifolds, there is a natural class of functions on an algebraic set, called \"regular functions\" or \"polynomial functions\". A regular function on an algebraic set \"V\" contained in A is the restriction to \"V\" of a regular function on A. For an algebraic set defined on the field of the complex numbers, the regular functions are smooth and even analytic.\n\nIt may seem unnaturally restrictive to require that a regular function always extend to the ambient space, but it is very similar to the situation in a normal topological space, where the Tietze extension theorem guarantees that a continuous function on a closed subset always extends to the ambient topological space.\n\nJust as with the regular functions on affine space, the regular functions on \"V\" form a ring, which we denote by \"k\"[\"V\"]. This ring is called the \"coordinate ring of V\".\n\nSince regular functions on V come from regular functions on A, there is a relationship between the coordinate rings. Specifically, if a regular function on \"V\" is the restriction of two functions \"f\" and \"g\" in \"k\"[A], then \"f\" − \"g\" is a polynomial function which is null on \"V\" and thus belongs to \"I\"(\"V\"). Thus \"k\"[\"V\"] may be identified with \"k\"[A]/\"I\"(\"V\").\n\nUsing regular functions from an affine variety to A, we can define regular maps from one affine variety to another. First we will define a regular map from a variety into affine space: Let \"V\" be a variety contained in A. Choose \"m\" regular functions on \"V\", and call them \"f\", ..., \"f\". We define a \"regular map\" \"f\" from \"V\" to A by letting . In other words, each \"f\" determines one coordinate of the range of \"f\".\n\nIf \"V\"′ is a variety contained in A, we say that \"f\" is a \"regular map\" from \"V\" to \"V\"′ if the range of \"f\" is contained in \"V\"′.\n\nThe definition of the regular maps apply also to algebraic sets.\nThe regular maps are also called \"morphisms\", as they make the collection of all affine algebraic sets into a category, where the objects are the affine algebraic sets and the morphisms are the regular maps. The affine varieties is a subcategory of the category of the algebraic sets.\n\nGiven a regular map \"g\" from \"V\" to \"V\"′ and a regular function \"f\" of \"k\"[\"V\"′], then . The map is a ring homomorphism from \"k\"[\"V\"′] to \"k\"[\"V\"]. Conversely, every ring homomorphism from \"k\"[\"V\"′] to \"k\"[\"V\"] defines a regular map from \"V\" to \"V\"′. This defines an equivalence of categories between the category of algebraic sets and the opposite category of the finitely generated reduced \"k\"-algebras. This equivalence is one of the starting points of scheme theory.\n\nIn contrast to the preceding sections, this section concerns only varieties and not algebraic sets. On the other hand, the definitions extend naturally to projective varieties (next section), as an affine variety and its projective completion have the same field of functions.\n\nIf \"V\" is an affine variety, its coordinate ring is an integral domain and has thus a field of fractions which is denoted \"k\"(\"V\") and called the \"field of the rational functions\" on \"V\" or, shortly, the \"function field\" of \"V\". Its elements are the restrictions to \"V\" of the rational functions over the affine space containing \"V\". The domain of a rational function \"f\" is not \"V\" but the complement of the subvariety (a hypersurface) where the denominator of \"f\" vanishes.\n\nAs with regular maps, one may define a \"rational map\" from a variety \"V\" to a variety \"V\"<nowiki>'</nowiki>. As with the regular maps, the rational maps from \"V\" to \"V\"<nowiki>'</nowiki> may be identified to the field homomorphisms from \"k\"(\"V\"<nowiki>'</nowiki>) to \"k\"(\"V\").\n\nTwo affine varieties are \"birationally equivalent\" if there are two rational functions between them which are inverse one to the other in the regions where both are defined. Equivalently, they are birationally equivalent if their function fields are isomorphic.\n\nAn affine variety is a \"rational variety\" if it is birationally equivalent to an affine space. This means that the variety admits a rational parameterization. For example, the circle of equation formula_5 is a rational curve, as it has the parameterization\nwhich may also be viewed as a rational map from the line to the circle.\n\nThe problem of resolution of singularities is to know if every algebraic variety is birationally equivalent to a variety whose projective completion is nonsingular (see also smooth completion). It was solved in the affirmative in characteristic 0 by Heisuke Hironaka in 1964 and is yet unsolved in finite characteristic.\n\nJust as the formulas for the roots of second, third, and fourth degree polynomials suggest extending real numbers to the more algebraically complete setting of the complex numbers, many properties of algebraic varieties suggest extending affine space to a more geometrically complete projective space. Whereas the complex numbers are obtained by adding the number \"i\", a root of the polynomial , projective space is obtained by adding in appropriate points \"at infinity\", points where parallel lines may meet.\n\nTo see how this might come about, consider the variety . If we draw it, we get a parabola. As \"x\" goes to positive infinity, the slope of the line from the origin to the point (\"x\", \"x\") also goes to positive infinity. As \"x\" goes to negative infinity, the slope of the same line goes to negative infinity.\n\nCompare this to the variety \"V\"(\"y\" − \"x\"). This is a cubic curve. As \"x\" goes to positive infinity, the slope of the line from the origin to the point (\"x\", \"x\") goes to positive infinity just as before. But unlike before, as \"x\" goes to negative infinity, the slope of the same line goes to positive infinity as well; the exact opposite of the parabola. So the behavior \"at infinity\" of \"V\"(\"y\" − \"x\") is different from the behavior \"at infinity\" of \"V\"(\"y\" − \"x\").\n\nThe consideration of the \"projective completion\" of the two curves, which is their prolongation \"at infinity\" in the projective plane, allows us to quantify this difference: the point at infinity of the parabola is a regular point, whose tangent is the line at infinity, while the point at infinity of the cubic curve is a cusp. Also, both curves are rational, as they are parameterized by \"x\", and the Riemann-Roch theorem implies that the cubic curve must have a singularity, which must be at infinity, as all its points in the affine space are regular.\n\nThus many of the properties of algebraic varieties, including birational equivalence and all the topological properties, depend on the behavior \"at infinity\" and so it is natural to study the varieties in projective space. Furthermore, the introduction of projective techniques made many theorems in algebraic geometry simpler and sharper: For example, Bézout's theorem on the number of intersection points between two varieties can be stated in its sharpest form only in projective space. For these reasons, projective space plays a fundamental role in algebraic geometry.\n\nNowadays, the \"projective space\" P of dimension \"n\" is usually defined as the set of the lines passing through a point, considered as the origin, in the affine space of dimension , or equivalently to the set of the vector lines in a vector space of dimension . When a coordinate system has been chosen in the space of dimension , all the points of a line have the same set of coordinates, up to the multiplication by an element of \"k\". This defines the homogeneous coordinates of a point of P as a sequence of elements of the base field \"k\", defined up to the multiplication by a nonzero element of \"k\" (the same for the whole sequence).\n\nA polynomial in variables vanishes at all points of a line passing through the origin if and only if it is homogeneous. In this case, one says that the polynomial \"vanishes\" at the corresponding point of P. This allows us to define a \"projective algebraic set\" in P as the set , where a finite set of homogeneous polynomials vanishes. Like for affine algebraic sets, there is a bijection between the projective algebraic sets and the reduced homogeneous ideals which define them. The \"projective varieties\" are the projective algebraic sets whose defining ideal is prime. In other words, a projective variety is a projective algebraic set, whose homogeneous coordinate ring is an integral domain, the \"projective coordinates ring\" being defined as the quotient of the graded ring or the polynomials in variables by the homogeneous (reduced) ideal defining the variety. Every projective algebraic set may be uniquely decomposed into a finite union of projective varieties.\n\nThe only regular functions which may be defined properly on a projective variety are the constant functions. Thus this notion is not used in projective situations. On the other hand, the \"field of the rational functions\" or \"function field \" is a useful notion, which, similarly to the affine case, is defined as the set of the quotients of two homogeneous elements of the same degree in the homogeneous coordinate ring.\n\nReal algebraic geometry is the study of the real points of algebraic geometry.\n\nThe fact that the field of the real numbers is an ordered field cannot be ignored in such a study. For example, the curve of equation formula_8 is a circle if formula_9, but does not have any real point if formula_10. It follows that real algebraic geometry is not only the study of the real algebraic varieties, but has been generalized to the study of the \"semi-algebraic sets\", which are the solutions of systems of polynomial equations and polynomial inequalities. For example, a branch of the hyperbola of equation formula_11 is not an algebraic variety, but is a semi-algebraic set defined by formula_12 and formula_13 or by formula_12 and formula_15.\n\nOne of the challenging problems of real algebraic geometry is the unsolved Hilbert's sixteenth problem: Decide which respective positions are possible for the ovals of a nonsingular plane curve of degree 8.\n\nOne may date the origin of computational algebraic geometry to meeting EUROSAM'79 (International Symposium on Symbolic and Algebraic Manipulation) held at Marseille, France in June 1979. At this meeting,\n\nSince then, most results in this area are related to one or several of these items either by using or improving one of these algorithms, or by finding algorithms whose complexity is simply exponential in the number of the variables.\n\nA body of mathematical theory complementary to symbolic methods called numerical algebraic geometry has been developed over the last several decades. The main computational method is homotopy continuation. This supports, for example, a model of floating point computation for solving problems of algebraic geometry.\n\nA Gröbner basis is a system of generators of a polynomial ideal whose computation allows the deduction of many properties of the affine algebraic variety defined by the ideal.\n\nGiven an ideal \"I\" defining an algebraic set \"V\":\n\nGröbner basis computations do not allow one to compute directly the primary decomposition of \"I\" nor the prime ideals defining the irreducible components of \"V\", but most algorithms for this involve Gröbner basis computation. The algorithms which are not based on Gröbner bases use regular chains but may need Gröbner bases in some exceptional situations.\n\nGröbner bases are deemed to be difficult to compute. In fact they may contain, in the worst case, polynomials whose degree is doubly exponential in the number of variables and a number of polynomials which is also doubly exponential. However, this is only a worst case complexity, and the complexity bound of Lazard's algorithm of 1979 may frequently apply. Faugère F5 algorithm realizes this complexity, as it may be viewed as an improvement of Lazard's 1979 algorithm. It follows that the best implementations allow one to compute almost routinely with algebraic sets of degree more than 100. This means that, presently, the difficulty of computing a Gröbner basis is strongly related to the intrinsic difficulty of the problem.\n\nCAD is an algorithm which was introduced in 1973 by G. Collins to implement with an acceptable complexity the Tarski–Seidenberg theorem on quantifier elimination over the real numbers.\n\nThis theorem concerns the formulas of the first-order logic whose atomic formulas are polynomial equalities or inequalities between polynomials with real coefficients. These formulas are thus the formulas which may be constructed from the atomic formulas by the logical operators \"and\" (∧), \"or\" (∨), \"not\" (¬), \"for all\" (∀) and \"exists\" (∃). Tarski's theorem asserts that, from such a formula, one may compute an equivalent formula without quantifier (∀, ∃).\n\nThe complexity of CAD is doubly exponential in the number of variables. This means that CAD allows, in theory, to solve every problem of real algebraic geometry which may be expressed by such a formula, that is almost every problem concerning explicitly given varieties and semi-algebraic sets.\n\nWhile Gröbner basis computation has doubly exponential complexity only in rare cases, CAD has almost always this high complexity. This implies that, unless if most polynomials appearing in the input are linear, it may not solve problems with more than four variables.\n\nSince 1973, most of the research on this subject is devoted either to improve CAD or to find alternative algorithms in special cases of general interest.\n\nAs an example of the state of art, there are efficient algorithms to find at least a point in every connected component of a semi-algebraic set, and thus to test if a semi-algebraic set is empty. On the other hand, CAD is yet, in practice, the best algorithm to count the number of connected components.\n\nThe basic general algorithms of computational geometry have a double exponential worst case complexity. More precisely, if \"d\" is the maximal degree of the input polynomials and \"n\" the number of variables, their complexity is at most formula_16 for some constant \"c\", and, for some inputs, the complexity is at least formula_17 for another constant \"c\"′.\n\nDuring the last 20 years of 20th century, various algorithms have been introduced to solve specific subproblems with a better complexity. Most of these algorithms have a complexity formula_18.\n\nAmong these algorithms which solve a sub problem of the problems solved by Gröbner bases, one may cite \"testing if an affine variety is empty\" and \"solving nonhomogeneous polynomial systems which have a finite number of solutions.\" Such algorithms are rarely implemented because, on most entries Faugère's F4 and F5 algorithms have a better practical efficiency and probably a similar or better complexity (\"probably\" because the evaluation of the complexity of Gröbner basis algorithms on a particular class of entries is a difficult task which has been done only in a few special cases).\n\nThe main algorithms of real algebraic geometry which solve a problem solved by CAD are related to the topology of semi-algebraic sets. One may cite \"counting the number of connected components\", \"testing if two points are in the same components\" or \"computing a Whitney stratification of a real algebraic set\". They have a complexity of\nformula_18, but the constant involved by \"O\" notation is so high that using them to solve any nontrivial problem effectively solved by CAD, is impossible even if one could use all the existing computing power in the world. Therefore, these algorithms have never been implemented and this is an active research area to search for algorithms with have together a good asymptotic complexity and a good practical efficiency.\n\nThe modern approaches to algebraic geometry redefine and effectively extend the range of basic objects in various levels of generality to schemes, formal schemes, ind-schemes, algebraic spaces, algebraic stacks and so on. The need for this arises already from the useful ideas within theory of varieties, e.g. the formal functions of Zariski can be accommodated by introducing nilpotent elements in structure rings; considering spaces of loops and arcs, constructing quotients by group actions and developing formal grounds for natural intersection theory and deformation theory lead to some of the further extensions.\n\nMost remarkably, in late 1950s, algebraic varieties were subsumed into Alexander Grothendieck's concept of a scheme. Their local objects are affine schemes or prime spectra which are locally ringed spaces which form a category which is antiequivalent to the category of commutative unital rings, extending the duality between the category of affine algebraic varieties over a field \"k\", and the category of finitely generated reduced \"k\"-algebras. The gluing is along Zariski topology; one can glue within the category of locally ringed spaces, but also, using the Yoneda embedding, within the more abstract category of presheaves of sets over the category of affine schemes. The Zariski topology in the set theoretic sense is then replaced by a Grothendieck topology. Grothendieck introduced Grothendieck topologies having in mind more exotic but geometrically finer and more sensitive examples than the crude Zariski topology, namely the étale topology, and the two flat Grothendieck topologies: fppf and fpqc; nowadays some other examples became prominent including Nisnevich topology. Sheaves can be furthermore generalized to stacks in the sense of Grothendieck, usually with some additional representability conditions leading to Artin stacks and, even finer, Deligne-Mumford stacks, both often called algebraic stacks.\n\nSometimes other algebraic sites replace the category of affine schemes. For example, Nikolai Durov has introduced commutative algebraic monads as a generalization of local objects in a generalized algebraic geometry. Versions of a tropical geometry, of an absolute geometry over a field of one element and an algebraic analogue of Arakelov's geometry were realized in this setup.\n\nAnother formal generalization is possible to universal algebraic geometry in which every variety of algebras has its own algebraic geometry. The term \"variety of algebras\" should not be confused with \"algebraic variety\".\n\nThe language of schemes, stacks and generalizations has proved to be a valuable way of dealing with geometric concepts and became cornerstones of modern algebraic geometry.\n\nAlgebraic stacks can be further generalized and for many practical questions like deformation theory and intersection theory, this is often the most natural approach. One can extend the Grothendieck site of affine schemes to a higher categorical site of derived affine schemes, by replacing the commutative rings with an infinity category of differential graded commutative algebras, or of simplicial commutative rings or a similar category with an appropriate variant of a Grothendieck topology. One can also replace presheaves of sets by presheaves of simplicial sets (or of infinity groupoids). Then, in presence of an appropriate homotopic machinery one can develop a notion of derived stack as such a presheaf on the infinity category of derived affine schemes, which is satisfying certain infinite categorical version of a sheaf axiom (and to be algebraic, inductively a sequence of representability conditions). Quillen model categories, Segal categories and quasicategories are some of the most often used tools to formalize this yielding the \"derived algebraic geometry\", introduced by the school of Carlos Simpson, including Andre Hirschowitz, Bertrand Toën, Gabrielle Vezzosi, Michel Vaquié and others; and developed further by Jacob Lurie, Bertrand Toën, and Gabrielle Vezzosi. Another (noncommutative) version of derived algebraic geometry, using A-infinity categories has been developed from early 1990s by Maxim Kontsevich and followers.\n\nSome of the roots of algebraic geometry date back to the work of the Hellenistic Greeks from the 5th century BC. The Delian problem, for instance, was to construct a length \"x\" so that the cube of side \"x\" contained the same volume as the rectangular box \"a\"\"b\" for given sides \"a\" and \"b\". Menaechmus (circa 350 BC) considered the problem geometrically by intersecting the pair of plane conics \"ay\" = \"x\" and \"xy\" = \"ab\". The later work, in the 3rd century BC, of Archimedes and Apollonius studied more systematically problems on conic sections, and also involved the use of coordinates. The Arab mathematicians were able to solve by purely algebraic means certain cubic equations, and then to interpret the results geometrically. This was done, for instance, by Ibn al-Haytham in the 10th century AD. Subsequently, Persian mathematician Omar Khayyám (born 1048 A.D.) discovered a method for solving cubic equations by intersecting a parabola with a circle and seems to have been the first to conceive a general theory of cubic equations.\nA few years after Omar Khayyám, Sharaf al-Din al-Tusi's \"Treatise on equations\" has been described as inaugurating the beginning of algebraic geometry.\n\nSuch techniques of applying geometrical constructions to algebraic problems were also adopted by a number of Renaissance mathematicians such as Gerolamo Cardano and Niccolò Fontana \"Tartaglia\" on their studies of the cubic equation. The geometrical approach to construction problems, rather than the algebraic one, was favored by most 16th and 17th century mathematicians, notably Blaise Pascal who argued against the use of algebraic and analytical methods in geometry. The French mathematicians Franciscus Vieta and later René Descartes and Pierre de Fermat revolutionized the conventional way of thinking about construction problems through the introduction of coordinate geometry. They were interested primarily in the properties of \"algebraic curves\", such as those defined by Diophantine equations (in the case of Fermat), and the algebraic reformulation of the classical Greek works on conics and cubics (in the case of Descartes).\n\nDuring the same period, Blaise Pascal and Gérard Desargues approached geometry from a different perspective, developing the synthetic notions of projective geometry. Pascal and Desargues also studied curves, but from the purely geometrical point of view: the analog of the Greek \"ruler and compass construction\". Ultimately, the analytic geometry of Descartes and Fermat won out, for it supplied the 18th century mathematicians with concrete quantitative tools needed to study physical problems using the new calculus of Newton and Leibniz. However, by the end of the 18th century, most of the algebraic character of coordinate geometry was subsumed by the \"calculus of infinitesimals\" of Lagrange and Euler.\n\nIt took the simultaneous 19th century developments of non-Euclidean geometry and Abelian integrals in order to bring the old algebraic ideas back into the geometrical fold. The first of these new developments was seized up by Edmond Laguerre and Arthur Cayley, who attempted to ascertain the generalized metric properties of projective space. Cayley introduced the idea of \"homogeneous polynomial forms\", and more specifically quadratic forms, on projective space. Subsequently, Felix Klein studied projective geometry (along with other types of geometry) from the viewpoint that the geometry on a space is encoded in a certain class of transformations on the space. By the end of the 19th century, projective geometers were studying more general kinds of transformations on figures in projective space. Rather than the projective linear transformations which were normally regarded as giving the fundamental Kleinian geometry on projective space, they concerned themselves also with the higher degree birational transformations. This weaker notion of congruence would later lead members of the 20th century Italian school of algebraic geometry to classify algebraic surfaces up to birational isomorphism.\n\nThe second early 19th century development, that of Abelian integrals, would lead Bernhard Riemann to the development of Riemann surfaces.\n\nIn the same period began the algebraization of the algebraic geometry through commutative algebra. The prominent results in this direction are Hilbert's basis theorem and Hilbert's Nullstellensatz, which are the basis of the connexion between algebraic geometry and commutative algebra, and Macaulay's multivariate resultant, which is the basis of elimination theory. Probably because of the size of the computation which is implied by multivariate resultants, elimination theory was forgotten during the middle of the 20th century until it was renewed by singularity theory and computational algebraic geometry.\n\nB. L. van der Waerden, Oscar Zariski and André Weil developed a foundation for algebraic geometry based on contemporary commutative algebra, including valuation theory and the theory of ideals. One of the goals was to give a rigorous framework for proving the results of Italian school of algebraic geometry. In particular, this school used systematically the notion of generic point without any precise definition, which was first given by these authors during the 1930s.\n\nIn the 1950s and 1960s, Jean-Pierre Serre and Alexander Grothendieck recast the foundations making use of sheaf theory. Later, from about 1960, and largely led by Grothendieck, the idea of schemes was worked out, in conjunction with a very refined apparatus of homological techniques. After a decade of rapid development the field stabilized in the 1970s, and new applications were made, both to number theory and to more classical geometric questions on algebraic varieties, singularities and moduli.\n\nAn important class of varieties, not easily understood directly from their defining equations, are the abelian varieties, which are the projective varieties whose points form an abelian group. The prototypical examples are the elliptic curves, which have a rich theory. They were instrumental in the proof of Fermat's last theorem and are also used in elliptic-curve cryptography.\n\nIn parallel with the abstract trend of the algebraic geometry, which is concerned with general statements about varieties, methods for effective computation with concretely-given varieties have also been developed, which lead to the new area of computational algebraic geometry. One of the founding methods of this area is the theory of Gröbner bases, introduced by Bruno Buchberger in 1965. Another founding method, more specially devoted to real algebraic geometry, is the cylindrical algebraic decomposition, introduced by George E. Collins in 1973.\n\nSee also: derived algebraic geometry.\n\nAn analytic variety is defined locally as the set of common solutions of several equations involving analytic functions. It is analogous to the included concept of real or complex algebraic variety. Any complex manifold is an analytic variety. Since analytic varieties may have singular points, not all analytic varieties are manifolds.\n\nModern analytic geometry is essentially equivalent to real and complex algebraic geometry, as has been shown by Jean-Pierre Serre in his paper \"GAGA\", the name of which is French for \"Algebraic geometry and analytic geometry\". Nevertheless, the two fields remain distinct, as the methods of proof are quite different and algebraic geometry includes also geometry in finite characteristic.\n\nAlgebraic geometry now finds applications in statistics, control theory, robotics, error-correcting codes, phylogenetics and geometric modelling. There are also connections to string theory, game theory, graph matchings, solitons and integer programming.\n\n\n\n\n\n"}
{"id": "1309", "url": "https://en.wikipedia.org/wiki?curid=1309", "title": "Almost all", "text": "Almost all\n\nIn mathematics, the term \"almost all\" means \"all but a negligible amount\". More precisely, if X is a set, \"almost all elements of X\" means \"all elements of X but those in a negligible subset of X\". The meaning of \"negligible\" depends on the mathematical context; for instance, it can mean finite, countable, or null.\n\nIn contrast, \"almost no\" means \"a negligible amount\"; that is, \"almost no elements of X\" means \"the elements of some negligible subset of X\".\n\nThroughout mathematics, \"almost all\" is sometimes used to mean \"all (elements of an infinite set) but finitely many\". This use occurs in philosophy as well. Similarly, \"almost all\" can mean \"all (elements of an uncountable set) but countably many\".\n\nExamples:\n\nWhen speaking about the reals, sometimes \"almost all\" means \"all reals but a null set\". Similarly, if S is some set of reals, \"almost all numbers in S\" can mean \"all numbers in S but those in a null set\". The real line can be thought of as a one-dimensional Euclidean space. In the more general case of an n-dimensional space (where n is a positive integer), these definitions can be generalised to \"all points but those in a null set\" or \"all points in S but those in a null set\" (this time, S is a set of points in the space). Even more generally, \"almost all\" is sometimes used in the sense of \"almost everywhere\" in measure theory, or in the closely related sense of \"almost surely\" in probability theory.\n\nExamples:\n\nIn number theory, \"almost all positive integers\" can mean \"the positive integers in a set whose natural density is 1\". That is, if A is a set of positive integers, and if the proportion of positive integers below n that are in A (out of all positive integers below n) tends to 1 as n tends to infinity, then almost all positive integers are in A. More generally, let S be an infinite set of positive integers, such as the set of even positive numbers or of primes. If A is a subset of S, and if the proportion of elements of S below n that are in A (out of all elements of S below n) tends to 1 as n tends to infinity, then it can be said that almost all elements of S are in A.\n\nExamples:\n\nIn graph theory, if A is a set of (finite labelled) graphs, it can be said to contain almost all graphs if the proportion of graphs with n vertices that are in A tends to 1 as n tends to infinity. However, it is sometimes easier to work with probabilities, so the definition is reformulated as follows. The proportion of graphs with n vertices that are in A equals the probability that a random graph with n vertices (chosen with the uniform distribution) is in A, and choosing a graph in this way has the same outcome as generating a graph by flipping a coin for each pair of vertices to decide whether to connect them. Therefore, equivalently to the preceding definition, A contains almost all graphs if the probability that a coin flip-generated graph with n vertices is in A tends to 1 as n tends to infinity. Sometimes the latter definition is modified so that the graph is chosen randomly in some other way, where not all graphs with n vertices have the same probability, and those modified definitions are not always equivalent to the main one.\n\nThe use of the term \"almost all\" in graph theory is not standard; the term \"asymptotically almost surely\" is more commonly used for this concept.\n\nExample:\n\nIn topology and especially dynamical systems theory (including applications in economics), \"almost all\" of a topological space's points can mean \"all of the space's points but those in a meagre set\". Some use a more limited definition, where a subset only contains almost all of the space's points if it contains some open dense set.\n\nExample:\n\nIn abstract algebra and mathematical logic, if U is an on a set X, \"almost all elements of X\" sometimes means \"the elements of some \"element\" of U\". For any partition of X into two disjoint sets, one of them necessarily contains almost all elements of X. It is possible to think of the elements of a filter on X as containing almost all elements of X even if it isn't an ultrafilter.\n"}
{"id": "47434936", "url": "https://en.wikipedia.org/wiki?curid=47434936", "title": "Angular unit", "text": "Angular unit\n\nThroughout history, angles have been measured in many different units. The most contemporary units are the degree ( ° ) and radian (rad), but many others have been used throughout history. The purpose of this page is to aggregate other concepts pertaining to the angular unit, where additional explanation can be provided.\n\nThe size of a geometric angle is usually characterized by the magnitude of the smallest rotation that maps one of the rays into the other. Angles that have the same size are said to be \"equal\" or \"congruent\" or \"equal in measure\".\n\nIn some contexts, such as identifying a point on a circle or describing the \"orientation\" of an object in two dimensions relative to a reference orientation, angles that differ by an exact multiple of a full turn are effectively equivalent. In other contexts, such as identifying a point on a spiral curve or describing the \"cumulative rotation\" of an object in two dimensions relative to a reference orientation, angles that differ by a non-zero multiple of a full turn are not equivalent.\n\nIn order to measure an angle θ, a circular arc centered at the vertex of the angle is drawn, e.g. with a pair of compasses. The ratio of the length s of the arc by the radius r of the circle is the measure of the angle in radians.\n\nThe measure of the angle in another angular unit is then obtained by multiplying its measure in radians by the scaling factor , where \"k\" is the measure of a complete turn in the chosen unit (for example 360 for degrees or 400 for gradians):\n\nThe value of θ thus defined is independent of the size of the circle: if the length of the radius is changed then the arc length changes in the same proportion, so the ratio \"s\"/\"r\" is unaltered. (Proof. The formula above can be rewritten as One turn, for which units, corresponds to an arc equal in length to the circle's circumference, which is 2\"r\", so . Substituting \"n\" for \"θ\" and 2\"r\" for \"s\" in the formula, results in ) \n\nThe angle addition postulate states that if B is in the interior of angle AOC, then\n\nformula_2\n\nThe measure of the angle AOC is the sum of the measure of angle AOB and the measure of angle BOC.\nIn this postulate it does not matter in which unit the angle is measured as long as each angle is measured in the same unit.\n\nOne \"radian\" is the angle subtended by an arc of a circle that has the same length as the circle's radius. The radian is the derived quantity of angular measurement in the SI system. By definition, it is dimensionless, though it may be specified as \"rad\" to avoid ambiguity. Angles measured in degrees, are shown with the symbol °. Subdivisions of the degree are minute (symbol ', 1' = 1/60°) and second {symbol \", 1\" = 1/3600°}. An angle of 360° corresponds to the angle subtended by a full circle, and is equal to 2π radians, or 400 gradians.\n\nOther units used to represent angles are listed in the following table. These units are defined such that the number of turns is equivalent to a full circle.\n\nIn astronomy, right ascension and declination are usually measured in angular units, expressed in terms of time, based on a 24 hr day.\n\n\n\n\nAlthough the definition of the measurement of an angle does not support the concept of a negative angle, it is frequently useful to impose a convention that allows positive and negative angular values to represent orientations and/or rotations in opposite directions relative to some reference.\n\nIn a two-dimensional Cartesian coordinate system, an angle is typically defined by its two sides, with its vertex at the origin. The \"initial side\" is on the positive x-axis, while the other side or \"terminal side\" is defined by the measure from the initial side in radians, degrees, or turns. With \"positive angles\" representing rotations toward the positive y-axis and \"negative angles\" representing rotations toward the negative y-axis. When Cartesian coordinates are represented by \"standard position\", defined by the x-axis rightward and the y-axis upward, positive rotations are anticlockwise and negative rotations are clockwise.\n\nIn many contexts, an angle of −\"θ\" is effectively equivalent to an angle of \"one full turn minus \"θ\"\". For example, an orientation represented as  −45° is effectively equivalent to an orientation represented as 360° − 45° or 315°. However, a rotation of  −45° would not be the same as a rotation of 315°.\n\nIn three-dimensional geometry, \"clockwise\" and \"anticlockwise\" have no absolute meaning, so the direction of positive and negative angles must be defined relative to some reference, which is typically a vector passing through the angle's vertex and perpendicular to the plane in which the rays of the angle lie.\n\nIn navigation, bearings are measured relative to north. By convention, viewed from above, bearing angle are positive clockwise, so a bearing of 45° corresponds to a north-east orientation. Negative bearings are not used in navigation, so a north-west orientation corresponds to a bearing of 315°.\n\nThere are several alternatives to measuring the size of an angle by the corresponding angle of rotation.\nThe \"grade of a slope\", or \"gradient\" is equal to the tangent of the angle, or sometimes (rarely) the sine. Gradients are often expressed as a percentage. For very small values (less than 5%), the grade of a slope is approximately the measure of an angle in radians.\n\nIn rational geometry the \"spread\" between two lines is defined at the square of sine of the angle between the lines. Since the sine of an angle and the sine of its supplementary angle are the same any angle of rotation that maps one of the lines into the other leads to the same value of the spread between the lines.\n\nAstronomers measure angular separation of objects in degrees from their point of observation.\n\nThese measurements clearly depend on the individual subject, and the above should be treated as rough rule of thumb approximations only.\n\nNot all angle measurements are angular units, for an angular measurement it is definitional that the angle addition postulate holds.\n\nSome angle measurements where the angle addition postulate does not holds.\n\n"}
{"id": "312398", "url": "https://en.wikipedia.org/wiki?curid=312398", "title": "Autonomous system (mathematics)", "text": "Autonomous system (mathematics)\n\nIn mathematics, an autonomous system or autonomous differential equation is a system of ordinary differential equations which does not explicitly depend on the independent variable. When the variable is time, they are also called time-invariant systems.\n\nMany laws in physics, where the independent variable is usually assumed to be time, are expressed as autonomous systems because it is assumed the laws of nature which hold now are identical to those for any point in the past or future.\n\nAutonomous systems are closely related to dynamical systems. Any autonomous system can be transformed into a dynamical system and, using very weak assumptions, a dynamical system can be transformed into an autonomous system.\n\nAn autonomous system is a system of ordinary differential equations of the form\nwhere \"x\" takes values in \"n\"-dimensional Euclidean space and \"t\" is usually time.\n\nIt is distinguished from systems of differential equations of the form\nin which the law governing the rate of motion of a particle depends not only on the particle's location, but also on time; such systems are not autonomous.\n\nLet formula_3 be a unique solution of the \ninitial value problem for an autonomous system \nThen formula_5 solves\nIndeed, denoting formula_7 we have formula_8 \nand formula_9, thus \nFor the initial condition, the verification is trivial,\n\nThe equation formula_12 is autonomous, since the independent variable, \nlet us call it formula_13, does not explicitly appear in the equation. \nTo plot the slope field and isocline for this equation, one can use the following \ncode in GNU Octave/MATLAB\n\nOne can observe from the plot that the function formula_14 is formula_13-invariant, and so is the shape of the solution, i.e. formula_16 for any shift formula_17.\n\nSolving the equation symbolically in MATLAB, by running \n\nwe obtain two equilibrium solutions, formula_18 and formula_19, \nand a third solution involving an unknown constant formula_20,\n\nPicking up some specific values for the initial condition, we can add the plot of several solutions\n\nAutonomous systems can be analyzed qualitatively using the phase space; in the one-variable case, this is the phase line.\n\nThe following techniques apply to one-dimensional autonomous differential equations. Any one-dimensional equation of order formula_21 is equivalent to an formula_21-dimensional first-order system (as described in Ordinary differential equation#Reduction to a first order system), but not necessarily vice versa.\n\nThe first-order autonomous equation\nis separable, so it can easily be solved by rearranging it into the integral form\n\nThe second-order autonomous equation\n\nis more difficult, but it can be solved by introducing the new variable\n\nand expressing the second derivative of formula_13 (via the chain rule) as\n\nso that the original equation becomes\n\nwhich is a first order equation containing no reference to the independent variable formula_30 and if solved provides formula_31 as a function of formula_13. Then, recalling the definition of formula_31:\n\nwhich is an implicit solution.\n\nThe special case where formula_35 is independent of formula_36\n\nbenefits from separate treatment. These types of equations are very common in classical mechanics because they are always Hamiltonian systems.\n\nThe idea is to make use of the identity (barring division by zero issues)\n\nwhich follows from the chain rule. Note aside then that by inverting both sides of a first order autonomous system, one can immediately integrate with respect to formula_13:\n\nwhich is another way to view the separation of variables technique. A natural question is then: can we do something like this with higher order equations? The answer is yes for second order equations, but there's more work to do. The second derivative must be expressed as a derivative with respect to formula_13 instead of formula_30:\n\nTo reemphasize: what's been accomplished is that the second derivative in formula_30 has been expressed as a derivative in formula_13. The original second order equation may then finally be integrated:\n\nThis is an implicit solution, and beyond that the greatest potential problem is inability to simplify the integrals, which implies difficulty or impossibility in evaluating the integration constants.\n\nUsing the above mentality, we can extend the technique to the more general equation\n\nwhere formula_21 is some parameter not equal to two. This will work since the second derivative can be written in a form involving a power of formula_36. Rewriting the second derivative, rearranging, and expressing the left side as a derivative:\n\nThe right will carry +/- if formula_21 is even. The treatment must be different if formula_60:\n\nThere is no analogous method for solving third- or higher-order autonomous equations. Such equations can only be solved exactly if they happen to have some other simplifying property, for instance linearity or dependence of the right side of the equation on the dependent variable only (i.e., not its derivatives). This should not be surprising, considering that nonlinear autonomous systems in three dimensions can produce truly chaotic behavior such as the Lorenz attractor and the Rössler attractor.\n\nWith this mentality, it also isn't too surprising that general non-autonomous equations of second order can't be solved explicitly, since these can also be chaotic (an example of this is a periodically forced pendulum).\n\n"}
{"id": "49698223", "url": "https://en.wikipedia.org/wiki?curid=49698223", "title": "Bibhutibhushan Datta", "text": "Bibhutibhushan Datta\n\nBibhutibhushan Datta (also Bibhuti Bhusan Datta; Bengali : বিভূতিভূষণ দত্ত, Bibhūtibhūṣaṇ Datta) (28 June 1888 – 6 October 1958) was a historian of Indian mathematics.\n\nDatta came from a poor Bengali family. He was a student of Ganesh Prasad, studied at University of Calcutta and secured the master's degree in mathematics in 1914 and doctorate degree in 1920 in applied mathematics. He taught at Calcutta University where he was Lecturer at University Science College, and during 1924–1929 he was Rhashbehari Ghosh Professor of Applied Mathematics. During the 1920s and 1930s he created a reputation as an authority on the history of Indian mathematics. He was also deeply interested in Indian philosophy and religion. In 1929 he retired from his professorship and left the University in 1933, and became a \"sannyasin\" (an ascetic, a person who has renounced worldly pleasures) in 1938 under the name Swami Vidyaranya.\n\n\"History of Hindu Mathematics: A Source Book\", written by him jointly with Avadhesh Narayan Singh (1901–1954) became a standard reference in the history of Indian mathematics. He also wrote a monograph on the Shulba Sutras. He published more than 70 research papers mostly related to history of Indian mathematics.\n\nIn the last years of his life, Swami Vidyaranya lived mainly at Puskara (in Rajasthan).\n\n"}
{"id": "40402574", "url": "https://en.wikipedia.org/wiki?curid=40402574", "title": "Body Shape Index", "text": "Body Shape Index\n\nBody Shape Index (BSI) is a metric for assessing the health implications of a given human body height, mass and waist circumference. The inclusion of the latter is believed to make the BSI a better indicator of the health risks from excess weight than the standard Body Mass Index.\n\nAccording to the original article the formula for calculating aBSI is : formula_1\n\nThe finding of the paper is that the BSI above 0.083 (when expressed in metric units) is indicative of a higher relative hazard. A value of 0.091 corresponds to the doubling \nof the relative hazard rate.\n\n"}
{"id": "11347127", "url": "https://en.wikipedia.org/wiki?curid=11347127", "title": "Borell–Brascamp–Lieb inequality", "text": "Borell–Brascamp–Lieb inequality\n\nIn mathematics, the Borell–Brascamp–Lieb inequality is an integral inequality due to many different mathematicians but named after Christer Borell, Herm Jan Brascamp and Elliott Lieb.\n\nThe result was proved for \"p\" > 0 by Henstock and Macbeath in 1953. The case \"p\" = 0 is known as the Prékopa–Leindler inequality and was re-discovered by Brascamp and Lieb in 1976, when they proved the general version below; working independently, Borell had done the same in 1975. The nomenclature of \"Borell–Brascamp–Lieb inequality\" is due to Cordero-Erausquin, McCann and Schmuckenschläger, who in 2001 generalized the result to Riemannian manifolds such as the sphere and hyperbolic space.\n\nLet 0 < \"λ\" < 1, let −1 / \"n\" ≤ \"p\" ≤ +∞, and let \"f\", \"g\", \"h\" : R → [0, +∞) be integrable functions such that, for all \"x\" and \"y\" in R,\n\nwhere\n\nand formula_3.\n\nThen\n\n"}
{"id": "4576485", "url": "https://en.wikipedia.org/wiki?curid=4576485", "title": "Brauer's theorem on forms", "text": "Brauer's theorem on forms\n\nIn mathematics, Brauer's theorem, named for Richard Brauer, is a result on the representability of 0 by forms over certain fields in sufficiently many variables.\n\nLet \"K\" be a field such that for every integer \"r\" > 0 there exists an integer ψ(\"r\") such that for \"n\" ≥ ψ(r) every equation\n\nhas a non-trivial (i.e. not all \"x\" are equal to 0) solution in \"K\".\nThen, given homogeneous polynomials \"f\"...,\"f\" of degrees \"r\"...,\"r\" respectively with coefficients in \"K\", for every set of positive integers \"r\"...,\"r\" and every non-negative integer \"l\", there exists a number ω(\"r\"...,\"r\",\"l\") such that for \"n\" ≥ ω(\"r\"...,\"r\",\"l\") there exists an \"l\"-dimensional affine subspace \"M\" of \"K\" (regarded as a vector space over \"K\") satisfying\n\nLetting \"K\" be the field of p-adic numbers in the theorem, the equation (*) is satisfied, since formula_3, \"b\" a natural number, is finite. Choosing \"k\" = 1, one obtains the following corollary:\n\nOne can show that if \"n\" is sufficiently large according to the above corollary, then \"n\" is greater than \"r\". Indeed, Emil Artin conjectured that every homogeneous polynomial of degree \"r\" over Q in more than \"r\" variables represents 0. This is obviously true for \"r\" = 1, and it is well known that the conjecture is true for \"r\" = 2 (see, for example, J.-P. Serre, \"A Course in Arithmetic\", Chapter IV, Theorem 6). See quasi-algebraic closure for further context.\n\nIn 1950 Demyanov verified the conjecture for \"r\" = 3 and \"p\" ≠ 3, and in 1952 D. J. Lewis independently proved the case \"r\" = 3 for all primes \"p\". But in 1966 Guy Terjanian constructed a homogeneous polynomial of degree 4 over Q in 18 variables that has no non-trivial zero. On the other hand, the Ax–Kochen theorem shows that for any fixed degree Artin's conjecture is true for all but finitely many Q.\n"}
{"id": "251900", "url": "https://en.wikipedia.org/wiki?curid=251900", "title": "Burnside's lemma", "text": "Burnside's lemma\n\nBurnside's lemma, sometimes also called Burnside's counting theorem, the Cauchy–Frobenius lemma,orbit-counting theorem, or The Lemma that is not Burnsides' , is a result in group theory which is often useful in taking account of symmetry when counting mathematical objects. Its various eponyms are based on William Burnside, George Pólya, Augustin Louis Cauchy, and Ferdinand Georg Frobenius. The result is not due to Burnside himself, who merely quotes it in his book 'On the Theory of Groups of Finite Order', attributing it instead to .\n\nIn the following, let \"G\" be a finite group that acts on a set \"X\". For each \"g\" in \"G\" let \"X\" denote the set of elements in \"X\" that are fixed by \"g\" (also said to be left invariant by \"g\"), i.e. \"X\" = { \"x\" ∈ \"X\" | \"g\".\"x\" = \"x\" }. Burnside's lemma asserts the following formula for the number of orbits, denoted |\"X\"/\"G\"|:\n\nThus the number of orbits (a natural number or +∞) is equal to the average number of points fixed by an element of \"G\" (which is also a natural number or infinity). If \"G\" is infinite, the division by |\"G\"| may not be well-defined; in this case the following statement in cardinal arithmetic holds:\n\nThe number of rotationally distinct colourings of the faces of a cube using three colours can be determined from this formula as follows.\n\nLet \"X\" be the set of 3 possible face colour combinations that can be applied to a cube in one particular orientation, and let the rotation group \"G\" of the cube act on \"X\" in the natural manner. Then two elements of \"X\" belong to the same orbit precisely when one is simply a rotation of the other. The number of rotationally distinct colourings is thus the same as the number of orbits and can be found by counting the sizes of the fixed sets for the 24 elements of \"G\".\n\nA detailed examination of these automorphisms may be found\nhere.\n\nThe average fix size is thus\n\nHence there are 57 rotationally distinct colourings of the faces of a cube in three colours. In general, the number of rotationally distinct colorings of the faces of a cube in \"n\" colors is given by\n\nThe first step in the proof of the lemma is to re-express the sum over the group elements \"g\" ∈ \"G\" as an equivalent sum over the set of elements \"x\" ∈ \"X\":\n\nThe orbit-stabilizer theorem says that there is a natural bijection for each \"x\" ∈ \"X\" between the orbit of \"x\", \"G.x\" = {\"g.x\" | \"g\" ∈ \"G\"} ⊆ \"X\", and the set of left cosets \"G/G\" of its stabilizer subgroup \"G\". With Lagrange's theorem this implies\n\nOur sum over the set \"X\" may therefore be rewritten as\n\nFinally, notice that \"X\" is the disjoint union of all its orbits in \"X/G\", which means the sum over \"X\" may be broken up into separate sums over each individual orbit.\n\nPutting everything together gives the desired result:\n\nThis proof is essentially also the proof of the class equation formula, simply by taking the action of \"G\" on itself (\"X\" = \"G\") to be by conjugation, \"g\".\"x\" = \"gxg\", in which case \"G\" instantiates to the centralizer of \"x\" in \"G\".\n\nWilliam Burnside stated and proved this lemma, attributing it to , in his 1897 book on finite groups. But, even prior to Frobenius, the formula was known to Cauchy in 1845. In fact, the lemma was apparently so well known that Burnside simply omitted to attribute it to Cauchy. Consequently, this lemma is sometimes referred to as the lemma that is not Burnside's (see also Stigler's law of eponymy). This is less ambiguous than it may seem: Burnside contributed many lemmas to this field.\n\n\n"}
{"id": "5424160", "url": "https://en.wikipedia.org/wiki?curid=5424160", "title": "Chevalley basis", "text": "Chevalley basis\n\nIn mathematics, a Chevalley basis for a simple complex Lie algebra is a basis constructed by Claude Chevalley with the property that all structure constants are integers. Chevalley used these bases to construct analogues of Lie groups over finite fields, called Chevalley groups. The Chevalley basis is the Cartan-Weyl basis, but with a different normalization.\n\nThe generators of a Lie group are split into the generators \"H\" and \"E\" indexed by simple roots and their negatives formula_1. The Cartan-Weyl basis may be written as\n\nDefining the dual root or coroot of formula_4 as\n\nOne may perform a change of basis to define\n\nThe Cartan integers are\nThe resulting relations among the generators are the following:\n\nwhere in the last relation formula_12 is the greatest positive integer such that formula_13 is a root and we consider formula_14 if formula_15 is not a root.\n\nFor determining the sign in the last relation one fixes an ordering of roots which respects addition, i.e., if formula_16 then formula_17 provided that all four are roots. We then call formula_18 an extraspecial pair of roots if they are both positive and formula_19 is minimal among all formula_20 that occur in pairs of positive roots formula_21 satisfying formula_22. The sign in the last relation can be chosen arbitrarily whenever formula_18 is an extraspecial pair of roots. This then determines the signs for all remaining pairs of roots.\n\n"}
{"id": "162840", "url": "https://en.wikipedia.org/wiki?curid=162840", "title": "Concentration ratio", "text": "Concentration ratio\n\nThe most common concentration ratios are the CR and the CR, which means the market share of the four and the eight largest firms. Concentration ratios are usually used to show the extent of market control of the largest firms in the industry and to illustrate the degree to which an industry is oligopolistic.\n\nThe standard tools of competition economists and competition authorities to measure market concentration are the Herfindahl-Hirschman index (HHI) and the concentration ratios (CR(n)). These two are known as the traditional structural measures of market concentration (based on market shares). The concentration of firms in an industry is of interest to economists, business strategists and government agencies.\n\n\nUsually, these two common ratios are comparable from industry to industry, while concentration ratios for other numbers of firms can be also calculated.\n\nN-firm concentration ratio is a common measure of market structure and shows the combined market share of the N largest firms in the market. For example, the 5-firm concentration ratio in the UK pesticide industry is 0.75, which indicates that the combined market share of the five largest pesticide sellers in the UK is about 75%. \nN-firm concentration ratio does not reflect changes in the size of the largest firms. \nThe Herfindahl index avoids this problem. \n\nConcentration ratios range from 0 to 100 percent. The levels reach from \"no, low\" or \"medium\" to \"high\" to \"total\" concentration.\n\n\nThe definition of the concentration ratio does not use the market shares of all the firms in the industry and does not provide the distribution of firm size. It also does not provide a lot of detail about competitiveness of the industry. The concentration ratios just provide a sign of the oligopolistic nature of an industry and indicate the degree of competition.\nThe Herfindahl index provides a more complete picture of industry concentration than does the concentration ratio.\n\nUK industries with the highest five-firm concentration ratios (CR) include the following:\n\nUK industries with the lowest five-firm concentration ratios include the following:\n\nAs to account for the specificities of electricity markets the specific structural measures are calculated. The Herfindahl index and the concentration ratios focus on the market shares of companies, but these measures identify the \"pivotalness\" of companies to meeting the demand on the system. A company that is very pivotal can be said to have a high market power.\n\nThe Pivotal Supplier Index considers the demand in addition to the supply side. At the most basic level, the PSI answers the question if a particular supplier, the \"pivotal supplier\", is needed to supply the demand: would it be possible to supply the prevalent demand also without this supplier or is he mandatory?\n\nThe Pivotal Supplier Index is expressed as the following:\n\nPSI = I[C > Σ C - Total Consumption] \nwhere C is the capacity of the potential pivotal supplier and the sum of C the capacity of all suppliers.\nThe function I[.] is the indicator function, which takes the value 1 if the expression \".\" contained in it is true.\n\nAn equivalent expression is the following:\n\nPSI = I[Total consumption > ΣC ] \nwhere the sum of capacities is taken over all suppliers apart from x.\n\nThe PSI is a binary indicator that can be calculated hourly. If the supplier C is needed to supply the demand, it is pivotal and the index takes the value \"1\". If he is not pivotal, it takes the value \"0\".\n\nThe Residual Supply Index is a simple and effective tool in monitoring market power. It is the non-binary alternative to the PSI.\nThe Residual Supply Index is expressed as:\n\nRSI = (Σ C - C)/Last\nwhere C is the capacity of the analysed supplier and the sum of C the capacity of all suppliers.\n\nReceiving a result bigger than 100% is an indication that the supplier x should have little influence on the price. With a RSI smaller than 100%. the supplier x could easily practise market power. The RSI has the advantage over the PSI to be not binary and for this reason it can better indicate the increase of the structural market power.\n\nGerman\n\nEnglish\n\n"}
{"id": "6122", "url": "https://en.wikipedia.org/wiki?curid=6122", "title": "Continuous function", "text": "Continuous function\n\nIn mathematics, a continuous function is a function for which sufficiently small changes in the input result in arbitrarily small changes in the output. Otherwise, a function is said to be a \"discontinuous\" function. A continuous function with a continuous inverse function is called a homeomorphism.\n\nContinuity of functions is one of the core concepts of topology, which is treated in full generality below. The introductory portion of this article focuses on the special case where the inputs and outputs of functions are real numbers. A stronger form of continuity is uniform continuity. In addition, this article discusses the definition for the more general case of functions between two metric spaces. In order theory, especially in domain theory, one considers a notion of continuity known as Scott continuity. Other forms of continuity do exist but they are not discussed in this article.\n\nAs an example, consider the function \"h\"(\"t\"), which describes the height of a growing flower at time \"t\". This function is continuous. By contrast, if \"M\"(\"t\") denotes the amount of money in a bank account at time \"t\", then the function jumps at each point in time when money is deposited or withdrawn, so the function \"M\"(\"t\") is discontinuous.\n\nA form of the epsilon–delta definition of continuity was first given by Bernard Bolzano in 1817. Augustin-Louis Cauchy defined continuity of formula_1 as follows: an infinitely small increment formula_2 of the independent variable \"x\" always produces an infinitely small change formula_3 of the dependent variable \"y\" (see e.g. \"Cours d'Analyse\", p. 34). Cauchy defined infinitely small quantities in terms of variable quantities, and his definition of continuity closely parallels the infinitesimal definition used today (see microcontinuity). The formal definition and the distinction between pointwise continuity and uniform continuity were first given by Bolzano in the 1830s but the work wasn't published until the 1930s. Like Bolzano, Karl Weierstrass denied continuity of a function at a point \"c\" unless it was defined at and on both sides of \"c\", but Édouard Goursat allowed the function to be defined only at and on one side of \"c\", and Camille Jordan allowed it even if the function was defined only at \"c\". All three of those nonequivalent definitions of pointwise continuity are still in use. Eduard Heine provided the first published definition of uniform continuity in 1872, but based these ideas on lectures given by Peter Gustav Lejeune Dirichlet in 1854.\n\nA real function, that is a function from real numbers to real numbers can be represented by a graph in the Cartesian plane; such a function is continuous if, roughly speaking, the graph is a single unbroken curve whose domain is the entire real line. A more mathematically rigorous definition is given below.\n\nA rigorous definition of continuity of real functions is usually given in a first course in calculus in terms of the idea of a limit. First, a function with variable is said to be continuous \"at the point\" on the real line, if the limit of , as approaches that point , is equal to the value ; and second, the \"function (as a whole)\" is said to be \"continuous\", if it is continuous at every point. A function is said to be \"discontinuous\" (or to have a \"discontinuity\") at some point when it is not continuous there. These points themselves are also addressed as \"discontinuities\".\n\nThere are several different definitions of continuity of a function. Sometimes a function is said to be continuous if it is continuous at every point in its domain. In this case, the function , with the domain of all real ,  any integer, is continuous. Sometimes an exception is made for boundaries of the domain. For example, the graph of the function , with the domain of all non-negative reals, has a \"left-hand\" endpoint. In this case only the limit from the \"right\" is required to equal the value of the function. Under this definition \"f\" is continuous at the boundary and so for all non-negative arguments. The most common and restrictive definition is that a function is continuous if it is continuous at all real numbers. In this case, the previous two examples are not continuous, but every polynomial function is continuous, as are the sine, cosine, and exponential functions. Care should be exercised in using the word \"continuous\", so that it is clear from the context which meaning of the word is intended.\n\nUsing mathematical notation, there are several ways to define continuous functions in each of the three senses mentioned above.\n\nLet\n\nThis subset formula_5 is the domain of \"f\". Some possible choices include \n\nIn case of the domain formula_14 being defined as an open interval, formula_15 and formula_16 are no boundaries in the above sense and the values of formula_17 and formula_18 do not matter for continuity on formula_14.\n\nThe function \"f\" is \"continuous at some point\" \"c\" of its domain if the limit of \"f\"(\"x\"), as \"x\" approaches \"c\" through the domain of \"f\", exists and is equal to \"f\"(\"c\"). In mathematical notation, this is written as\nIn detail this means three conditions: first, \"f\" has to be defined at \"c\" (guaranteed by the requirement that \"c\" is in the domain of \"f\"). Second, the limit on the left hand side of that equation has to exist. Third, the value of this limit must equal \"f\"(\"c\").\n\nA neighborhood of a point \"c\" is a set that contains all points of the domain within some fixed distance of \"c\". Intuitively, a function is continuous at a point \"c\" if the range of the restriction of \"f\" to a neighborhood of \"c\" shrinks to a single point \"f\"(\"c\") as the width of the neighborhood around \"c\" shrinks to zero. More precisely, a function \"f\" is continuous at a point \"c\" of its domain if, for any neighborhood formula_21 there is a neighborhood formula_22 such that formula_23 whenever formula_24.\n\nThis definition only requires that the domain and the codomain are topological spaces and is thus the most general definition. It follows from this definition that a function \"f\" is automatically continuous at every isolated point of its domain. As a specific example, every real valued function on the set of integers is continuous.\n\nOne can instead require that for any sequence formula_25 of points in the domain which converges to \"c\", the corresponding sequence formula_26 converges to \"f\"(\"c\"). In mathematical notation, formula_27\n\nExplicitly including the definition of the limit of a function, we obtain a self-contained definition:\nGiven a function \"f\" : \"D\" → \"R\" as above and an element \"x\" of the domain \"D\", \"f\" is said to be continuous at the point \"x\" when the following holds: For any number \"ε\" > 0, however small, there exists some number \"δ\" > 0 such that for all \"x\" in the domain of \"f\" with \"x\" − \"δ\" < \"x\" < \"x\" + \"δ\", the value of \"f\"(\"x\") satisfies\n\nAlternatively written, continuity of \"f\" : \"D\" → \"R\" at \"x\" ∈ \"D\" means that for every \"ε\" > 0 there exists a \"δ\" > 0 such that for all \"x\" ∈ \"D\" :\n\nMore intuitively, we can say that if we want to get all the \"f\"(\"x\") values to stay in some small neighborhood around \"f\"(\"x\"), we simply need to choose a small enough neighborhood for the \"x\" values around \"x\". If we can do that no matter how small the \"f\"(\"x\") neighborhood is, then \"f\" is continuous at \"x\".\n\nIn modern terms, this is generalized by the definition of continuity of a function with respect to a basis for the topology, here the metric topology.\n\nWeierstrass had required that the interval \"x\" − \"δ\" < \"x\" < \"x\" + \"δ\" be entirely within the domain \"D\", but Jordan removed that restriction.\n\nIn proofs and numerical analysis we often need to know how fast limits are converging, or in other words, control of the remainder. We can formalise this to a definition of continuity. \nA function formula_30 is called a control function if\n\nA function \"f\" : \"D\" → \"R\" is \"C\"-continuous at \"x\" if \n\nA function is continuous in \"x\" if it is \"C\"-continuous for some control function \"C\".\n\nThis approach leads naturally to refining the notion of continuity by restricting the set of admissible control functions. For a given set of control functions formula_34 a function is formula_34-continuous if it is formula_36-continuous for some formula_37. For example the Lipschitz and Hölder continuous functions of exponent α below are defined by the set of control functions \nrespectively \n\nContinuity can also be defined in terms of oscillation: a function \"f\" is continuous at a point \"x\" if and only if its oscillation at that point is zero; in symbols, formula_41 A benefit of this definition is that it \"quantifies\" discontinuity: the oscillation gives how \"much\" the function is discontinuous at a point.\n\nThis definition is useful in descriptive set theory to study the set of discontinuities and continuous points – the continuous points are the intersection of the sets where the oscillation is less than \"ε\" (hence a G set) – and gives a very quick proof of one direction of the Lebesgue integrability condition.\n\nThe oscillation is equivalent to the \"ε\"-\"δ\" definition by a simple re-arrangement, and by using a limit (lim sup, lim inf) to define oscillation: if (at a given point) for a given \"ε\" there is no \"δ\" that satisfies the \"ε\"-\"δ\" definition, then the oscillation is at least \"ε\", and conversely if for every \"ε\" there is a desired \"δ,\" the oscillation is 0. The oscillation definition can be naturally generalized to maps from a topological space to a metric space.\n\nCauchy defined continuity of a function in the following intuitive terms: an infinitesimal change in the independent variable corresponds to an infinitesimal change of the dependent variable (see \"Cours d'analyse\", page 34). Non-standard analysis is a way of making this mathematically rigorous. The real line is augmented by the addition of infinite and infinitesimal numbers to form the hyperreal numbers. In nonstandard analysis, continuity can be defined as follows.\n\n(see microcontinuity). In other words, an infinitesimal increment of the independent variable always produces to an infinitesimal change of the dependent variable, giving a modern expression to Augustin-Louis Cauchy's definition of continuity.\n\nChecking the continuity of a given function can be simplified by checking one of the above defining properties for the building blocks of the given function. It is straightforward to show that the sum of two functions, continuous on some domain, is also continuous on this domain. Given\n\nthen the \"sum of continuous functions\"\nis continuous in formula_14.\n\nThe same holds for the \"product of continuous functions,\"\nis continuous in formula_14.\n\nCombining the above preservations of continuity and the continuity of constant functions and of the identity function formula_51 one arrives at the continuity of all polynomial functions such as\n(pictured on the right).\n\nIn the same way it can be shown that the \"reciprocal of a continuous function\" \nis continuous in formula_56.\n\nThis implies that, excluding the roots of formula_57, the \"quotient of continuous functions\" \nis also continuous on formula_62.\n\nFor example, the function (pictured)\n\nis defined for all real numbers and is continuous at every such point. Thus it is a continuous function. The question of continuity at does not arise, since is not in the domain of \"y\". There is no continuous function \"F\": R → R that agrees with \"y\"(\"x\") for all .\n\nSince the function sine is continuous on all reals, the sinc function \"G\"(\"x\") = sin \"x\"/\"x\", is defined and continuous for all real \"x\" ≠ 0. However, unlike the previous example, \"G\" \"can\" be extended to a continuous function on \"all\" real numbers, by \"defining\" the value \"G\"(0) to be 1, which is the limit of \"G\"(\"x\"), when \"x\" approaches 0, i.e.,\n\nThus, by setting\n\nthe sinc-function becomes a continuous function on all real numbers. The term \"removable singularity\" is used in such cases, when (re)defining values of a function to coincide with the appropriate limits make a function continuous at specific points.\n\nA more involved construction of continuous functions is the function composition. Given two continuous functions\ntheir composition, denoted as\nformula_67, and defined by formula_68 is continuous.\n\nThis construction allows stating, for example, that\n\nAn example of a discontinuous function is the Heaviside step function formula_71, defined by\n\nPick for instance formula_73. Then there is no around formula_74, i.e. no open interval formula_75 with formula_76 that will force all the formula_77 values to be within the of formula_78, i.e. within formula_79. Intuitively we can think of this type of discontinuity as a sudden jump in function values.\n\nSimilarly, the signum or sign function\nis discontinuous at formula_74 but continuous everywhere else. Yet another example: the function\nis continuous everywhere apart from formula_74.\nBesides plausible continuities and discontinuities like above, there are also functions with a behavior, often coined pathological, for example, Thomae's function,\nis continuous at all irrational numbers and discontinuous at all rational numbers. In a similar vein, Dirichlet's function, the indicator function for the set of rational numbers,\nis nowhere continuous.\n\nThe intermediate value theorem is an existence theorem, based on the real number property of completeness, and states:\n\nFor example, if a child grows from 1 m to 1.5 m between the ages of two and six years, then, at some time between two and six years of age, the child's height must have been 1.25 m.\n\nAs a consequence, if \"f\" is continuous on [\"a\", \"b\"] and \"f\"(\"a\") and \"f\"(\"b\") differ in sign, then, at some point \"c\" in [\"a\", \"b\"], \"f\"(\"c\") must equal zero.\n\nThe extreme value theorem states that if a function \"f\" is defined on a closed interval [\"a\",\"b\"] (or any closed and bounded set) and is continuous there, then the function attains its maximum, i.e. there exists \"c\" ∈ [\"a\",\"b\"] with \"f\"(\"c\") ≥ \"f\"(\"x\") for all \"x\" ∈ [\"a\",\"b\"]. The same is true of the minimum of \"f\". These statements are not, in general, true if the function is defined on an open interval (\"a\",\"b\") (or any set that is not both closed and bounded), as, for example, the continuous function \"f\"(\"x\") = 1/\"x\", defined on the open interval (0,1), does not attain a maximum, being unbounded above.\n\nEvery differentiable function\nis continuous, as can be shown. The converse does not hold: for example, the absolute value function\nis everywhere continuous. However, it is not differentiable at \"x\" = 0 (but is so everywhere else). Weierstrass's function is also everywhere continuous but nowhere differentiable.\n\nThe derivative \"f′\"(\"x\") of a differentiable function \"f\"(\"x\") need not be continuous. If \"f′\"(\"x\") is continuous, \"f\"(\"x\") is said to be continuously differentiable. The set of such functions is denoted \"C\"(). More generally, the set of functions\n(from an open interval (or open subset of R) Ω to the reals) such that \"f\" is \"n\" times differentiable and such that the \"n\"-th derivative of \"f\" is continuous is denoted \"C\"(Ω). See differentiability class. In the field of computer graphics, these three levels are sometimes called \"G\" (continuity of position), \"G\" (continuity of tangency), and \"G\" (continuity of curvature).\n\nEvery continuous function\nis integrable (for example in the sense of the Riemann integral). The converse does not hold, as the (integrable, but discontinuous) sign function shows.\n\nGiven a sequence\nof functions such that the limit\nexists for all \"x\" in \"D\", the resulting function \"f\"(\"x\") is referred to as the pointwise limit of the sequence of functions (\"f\"). The pointwise limit function need not be continuous, even if all functions \"f\" are continuous, as the animation at the right shows. However, \"f\" is continuous if all functions \"f\" are continuous and the sequence converges uniformly, by the uniform convergence theorem. This theorem can be used to show that the exponential functions, logarithms, square root function, trigonometric functions are continuous.\n\nDiscontinuous functions may be discontinuous in a restricted way, giving rise to the concept of directional continuity (or right and left continuous functions) and semi-continuity. Roughly speaking, a function is \"right-continuous\" if no jump occurs when the limit point is approached from the right. Formally, \"f\" is said to be right-continuous at the point \"c\" if the following holds: For any number \"ε\" > 0 however small, there exists some number \"δ\" > 0 such that for all \"x\" in the domain with , the value of \"f\"(\"x\") will satisfy\n\nThis is the same condition as for continuous functions, except that it is required to hold for \"x\" strictly larger than \"c\" only. Requiring it instead for all \"x\" with yields the notion of \"left-continuous\" functions. A function is continuous if and only if it is both right-continuous and left-continuous.\n\nA function \"f\" is \"lower semi-continuous\" if, roughly, any jumps that might occur only go down, but not up. That is, for any \"ε\" > 0, there exists some number \"δ\" > 0 such that for all \"x\" in the domain with , the value of \"f\"(\"x\") satisfies\nThe reverse condition is \"upper semi-continuity\".\n\nThe concept of continuous real-valued functions can be generalized to functions between metric spaces. A metric space is a set \"X\" equipped with a function (called metric) \"d\", that can be thought of as a measurement of the distance of any two elements in \"X\". Formally, the metric is a function\nthat satisfies a number of requirements, notably the triangle inequality. Given two metric spaces (\"X\", d) and (\"Y\", d) and a function\nthen \"f\" is continuous at the point \"c\" in \"X\" (with respect to the given metrics) if for any positive real number ε, there exists a positive real number δ such that all \"x\" in \"X\" satisfying d(\"x\", \"c\") < δ will also satisfy d(\"f\"(\"x\"), \"f\"(\"c\")) < ε. As in the case of real functions above, this is equivalent to the condition that for every sequence (\"x\") in \"X\" with limit lim \"x\" = \"c\", we have lim \"f\"(\"x\") = \"f\"(\"c\"). The latter condition can be weakened as follows: \"f\" is continuous at the point \"c\" if and only if for every convergent sequence (\"x\") in \"X\" with limit \"c\", the sequence (\"f\"(\"x\")) is a Cauchy sequence, and \"c\" is in the domain of \"f\".\n\nThe set of points at which a function between metric spaces is continuous is a G set – this follows from the ε-δ definition of continuity.\n\nThis notion of continuity is applied, for example, in functional analysis. A key statement in this area says that a linear operator\nbetween normed vector spaces \"V\" and \"W\" (which are vector spaces equipped with a compatible norm, denoted ||\"x\"||)\nis continuous if and only if it is bounded, that is, there is a constant \"K\" such that\nfor all \"x\" in \"V\".\n\nThe concept of continuity for functions between metric spaces can be strengthened in various ways by limiting the way δ depends on ε and \"c\" in the definition above. Intuitively, a function \"f\" as above is uniformly continuous if the δ does\nnot depend on the point \"c\". More precisely, it is required that for every real number \"ε\" > 0 there exists \"δ\" > 0 such that for every \"c\", \"b\" ∈ \"X\" with \"d\"(\"b\", \"c\") < \"δ\", we have that \"d\"(\"f\"(\"b\"), \"f\"(\"c\")) < \"ε\". Thus, any uniformly continuous function is continuous. The converse does not hold in general, but holds when the domain space \"X\" is compact. Uniformly continuous maps can be defined in the more general situation of uniform spaces.\n\nA function is Hölder continuous with exponent α (a real number) if there is a constant \"K\" such that for all \"b\" and \"c\" in \"X\", the inequality\nholds. Any Hölder continuous function is uniformly continuous. The particular case is referred to as Lipschitz continuity. That is, a function is Lipschitz continuous if there is a constant \"K\" such that the inequality\nholds for any \"b\", \"c\" in \"X\". The Lipschitz condition occurs, for example, in the Picard–Lindelöf theorem concerning the solutions of ordinary differential equations.\n\nAnother, more abstract, notion of continuity is continuity of functions between topological spaces in which there generally is no formal notion of distance, as there is in the case of metric spaces. A topological space is a set \"X\" together with a topology on \"X\", which is a set of subsets of \"X\" satisfying a few requirements with respect to their unions and intersections that generalize the properties of the open balls in metric spaces while still allowing to talk about the neighbourhoods of a given point. The elements of a topology are called open subsets of \"X\" (with respect to the topology).\n\nA function\nbetween two topological spaces \"X\" and \"Y\" is continuous if for every open set \"V\" ⊆ \"Y\", the inverse image\nis an open subset of \"X\". That is, \"f\" is a function between the sets \"X\" and \"Y\" (not on the elements of the topology \"T\"), but the continuity of \"f\" depends on the topologies used on \"X\" and \"Y\".\n\nThis is equivalent to the condition that the preimages of the closed sets (which are the complements of the open subsets) in \"Y\" are closed in \"X\".\n\nAn extreme example: if a set \"X\" is given the discrete topology (in which every subset is open), all functions\nto any topological space \"T\" are continuous. On the other hand, if \"X\" is equipped with the indiscrete topology (in which the only open subsets are the empty set and \"X\") and the space \"T\" set is at least T, then the only continuous functions are the constant functions. Conversely, any function whose range is indiscrete is continuous.\n\nThe translation in the language of neighborhoods of the (ε, δ)-definition of continuity leads to the following definition of the continuity at a point:\nThis definition is equivalent to the same statement with neighborhoods restricted to open neighborhoods and can be restated in several ways by using preimages rather than images.\n\nAlso, as every set that contains a neighborhood is also a neighborhood, and formula_103 is the largest subset of such that , this definition may be simplified into:\nAs an open set is a set that is a neighborhood of all its points, a function formula_104 is continuous at every point of if and only if it is a continuous function.\n\nIf \"X\" and \"Y\" are metric spaces, it is equivalent to consider the neighborhood system of open balls centered at \"x\" and \"f\"(\"x\") instead of all neighborhoods. This gives back the above δ-ε definition of continuity in the context of metric spaces. In general topological spaces, there is no notion of nearness or distance. If however the target space is a Hausdorff space, it is still true that \"f\" is continuous at \"a\" if and only if the limit of \"f\" as \"x\" approaches \"a\" is \"f\"(\"a\"). At an isolated point, every function is continuous.\n\nSeveral equivalent definitions for a topological structure exist and thus there are several equivalent ways to define a continuous function.\n\nIn several contexts, the topology of a space is conveniently specified in terms of limit points. In many instances, this is accomplished by specifying when a point is the limit of a sequence, but for some spaces that are too large in some sense, one specifies also when a point is the limit of more general sets of points indexed by a directed set, known as nets. A function is (Heine-)continuous only if it takes limits of sequences to limits of sequences. In the former case, preservation of limits is also sufficient; in the latter, a function may preserve all limits of sequences yet still fail to be continuous, and preservation of nets is a necessary and sufficient condition.\n\nIn detail, a function \"f\": \"X\" → \"Y\" is sequentially continuous if whenever a sequence (\"x\") in \"X\" converges to a limit \"x\", the sequence (\"f\"(\"x\")) converges to \"f\"(\"x\"). Thus sequentially continuous functions \"preserve sequential limits\". Every continuous function is sequentially continuous. If \"X\" is a first-countable space and countable choice holds, then the converse also holds: any function preserving sequential limits is continuous. In particular, if \"X\" is a metric space, sequential continuity and continuity are equivalent. For non first-countable spaces, sequential continuity might be strictly weaker than continuity. (The spaces for which the two properties are equivalent are called sequential spaces.) This motivates the consideration of nets instead of sequences in general topological spaces. Continuous functions preserve limits of nets, and in fact this property characterizes continuous functions.\n\nInstead of specifying the open subsets of a topological space, the topology can also be determined by a closure operator (denoted cl) which assigns to any subset \"A\" ⊆ \"X\" its closure, or an interior operator (denoted int), which assigns to any subset \"A\" of \"X\" its interior. In these terms, a function\nbetween topological spaces is continuous in the sense above if and only if for all subsets \"A\" of \"X\"\nThat is to say, given any element \"x\" of \"X\" that is in the closure of any subset \"A\", \"f\"(\"x\") belongs to the closure of \"f\"(\"A\"). This is equivalent to the requirement that for all subsets \"A\"<nowiki>'</nowiki> of \"X\"<nowiki>'</nowiki>\nMoreover,\nis continuous if and only if\nfor any subset \"A\"' of \"Y\".\n\nIf \"f\": \"X\" → \"Y\" and \"g\": \"Y\" → \"Z\" are continuous, then so is the composition \"g\" ∘ \"f\": \"X\" → \"Z\". If \"f\": \"X\" → \"Y\" is continuous and\n\nThe possible topologies on a fixed set \"X\" are partially ordered: a topology τ is said to be coarser than another topology τ (notation: τ ⊆ τ) if every open subset with respect to τ is also open with respect to τ. Then, the identity map\nis continuous if and only if τ ⊆ τ (see also comparison of topologies). More generally, a continuous function\nstays continuous if the topology τ is replaced by a coarser topology and/or τ is replaced by a finer topology.\n\nSymmetric to the concept of a continuous map is an open map, for which \"images\" of open sets are open. In fact, if an open map \"f\" has an inverse function, that inverse is continuous, and if a continuous map \"g\" has an inverse, that inverse is open. Given a bijective function \"f\" between two topological spaces, the inverse function \"f\" need not be continuous. A bijective continuous function with continuous inverse function is called a \"homeomorphism\".\n\nIf a continuous bijection has as its domain a compact space and its codomain is Hausdorff, then it is a homeomorphism.\n\nGiven a function\nwhere \"X\" is a topological space and \"S\" is a set (without a specified topology), the final topology on \"S\" is defined by letting the open sets of \"S\" be those subsets \"A\" of \"S\" for which \"f\"(\"A\") is open in \"X\". If \"S\" has an existing topology, \"f\" is continuous with respect to this topology if and only if the existing topology is coarser than the final topology on \"S\". Thus the final topology can be characterized as the finest topology on \"S\" that makes \"f\" continuous. If \"f\" is surjective, this topology is canonically identified with the quotient topology under the equivalence relation defined by \"f\".\n\nDually, for a function \"f\" from a set \"S\" to a topological space \"X\", the initial topology on \"S\" is defined by designating as an open set every subset \"A\" of \"S\" such that formula_112 for some open subset \"U\" of \"X\". If \"S\" has an existing topology, \"f\" is continuous with respect to this topology if and only if the existing topology is finer than the initial topology on \"S\". Thus the initial topology can be characterized as the coarsest topology on \"S\" that makes \"f\" continuous. If \"f\" is injective, this topology is canonically identified with the subspace topology of \"S\", viewed as a subset of \"X\".\n\nA topology on a set \"S\" is uniquely determined by the class of all continuous functions formula_113 into all topological spaces \"X\". Dually, a similar idea can be applied to maps formula_114\n\nVarious other mathematical domains use the concept of continuity in different, but related meanings. For example, in order theory, an order-preserving function \"f\": \"X\" → \"Y\" between particular types of partially ordered sets \"X\" and \"Y\" is continuous if for each directed subset \"A\" of \"X\", we have sup(\"f\"(\"A\")) = \"f\"(sup(\"A\")). Here sup is the supremum with respect to the orderings in \"X\" and \"Y\", respectively. This notion of continuity is the same as topological continuity when the partially ordered sets are given the Scott topology.\n\nIn category theory, a functor\nbetween two categories is called \"continuous\", if it commutes with small limits. That is to say,\nfor any small (i.e., indexed by a set \"I\", as opposed to a class) diagram of objects in formula_117.\n\nA \"continuity space\" is a generalization of metric spaces and posets, which uses the concept of quantales, and that can be used to unify the notions of metric spaces and domains.\n"}
{"id": "2150531", "url": "https://en.wikipedia.org/wiki?curid=2150531", "title": "Counting quantification", "text": "Counting quantification\n\nA counting quantifier is a mathematical term for a quantifier of the form \"there exists at least \"k\" elements that satisfy property \"X\"\".\nIn first-order logic with equality, counting quantifiers can be defined in terms of ordinary quantifiers, so in this context they are a notational shorthand.\nHowever, they are interesting in the context of logics such as two-variable logic with counting that restrict the number of variables in formulas.\nAlso, generalized counting quantifiers that say \"there exists infinitely many\" are not expressible using a finite number of formulas in first-order logic.\n\n\n"}
{"id": "30495448", "url": "https://en.wikipedia.org/wiki?curid=30495448", "title": "Cyclic number (group theory)", "text": "Cyclic number (group theory)\n\nA cyclic number is a natural number \"n\" such that \"n\" and φ(\"n\") are coprime. Here φ is Euler's totient function. An equivalent definition is that a number \"n\" is cyclic if and only if any group of order \"n\" is cyclic. \n\nAny prime number is clearly cyclic. All cyclic numbers are square-free.\nLet \"n\" = \"p\" \"p\" … \"p\" where the \"p\" are distinct primes, then φ(\"n\") = (\"p\" − 1)(\"p\" − 1)...(\"p\" – 1). If no \"p\" divides any (\"p\" – 1), then \"n\" and φ(\"n\") have no common (prime) divisor, and \"n\" is cyclic.\n\nThe first cyclic numbers are 1, 2, 3, 5, 7, 11, 13, 15, 17, 19, 23, 29, 31, 33, 35, 37, 41, 43, 47, 51, 53, 59, 61, 65, 67, 69, 71, 73, 77, 79, 83, 85, 87, 89, 91, 95, 97, 101, 103, 107, 109, 113, 115, 119, 123, 127, 131, 133, 137, 139, 141, 143, 145, 149, ... .\n"}
{"id": "52036598", "url": "https://en.wikipedia.org/wiki?curid=52036598", "title": "Differentiable neural computer", "text": "Differentiable neural computer\n\nA differentiable neural computer (DNC) is a recurrent artificial neural network architecture with an autoassociative memory. The model was published in 2016 by Alex Graves et al. of DeepMind.\n\nSo far, DNCs have only been demonstrated to handle relatively simple tasks, which could have been easily solved using conventional computer programming decades ago. But DNCs don't need to be programmed for each problem they are applied to, but can instead be trained. This attention span allows the user to feed complex data structures such as graphs sequentially, and recall them during later use. Furthermore, they can learn some aspects of symbolic reasoning and apply it to the use of working memory. Some experts see promise that they can be trained to perform complex, structured tasks and address big-data applications that require some sort of rational reasoning, such as generating video commentaries or semantic text analysis.\n\nDNC can be trained to navigate a variety of rapid transit systems, and then what the DNC learns can be applied, for example, to get around on the London Underground. A neural network without memory would typically have to learn about each different transit system from scratch. On graph traversal and sequence-processing tasks with supervised learning, DNCs performed better than alternatives such as long short-term memory or a neural turing machine. With a reinforcement learning approach to a block puzzle problem inspired by SHRDLU, DNC was trained via curriculum learning, and learned to make a plan. It performed better than a traditional recurrent neural network.\n\nDNC networks were introduced as an extension of the Neural Turing Machine (NTM), with the addition of memory attention mechanisms that control where the memory is stored, and temporal attention that records the order of events. This structure allows DNCs to be more robust and abstract than a NTM, and still perform tasks that have longer-term dependencies than some of its predecessors such as the LSTM network. The memory, which is simply a matrix, can be allocated dynamically and accessed indefinitely. The DNC is differentiable end-to-end (each subcomponent of the model is differentiable, therefore so is the whole model). This makes it possible to optimize them efficiently using gradient descent. It learns how to store and retrieve the information such that it satisfies the task execution.\n\nThe DNC model is similar to the Von Neumann architecture, and because of the resizability of memory, it is Turing complete. Differentiable Neural Computers were inspired by the mammalian hippocampus.\n\nDNC, as originally published\n\n</math>\n\nRefinements to the model have been published since the original paper's release. Sparse memory addressing results in a time and space complexity reduction of thousands of times. This can be achieved by using an approximate nearest neighbors algorithm, such as Locality-sensitive hashing, or a random k-d tree like the Fast Library for Approximate Nearest Neighbors from UBC. Adding Adaptive Computation Time (ACT) separates computation time from data time, which uses the fact that problem length and problem difficulty are not always the same. Training using synthetic gradients performs considerably better than Backpropagation through time (BPTT). Another training improvement in terms of robustness can be achieved with use of DNA normalization and a Bypass Dropout as regularization. \n\n"}
{"id": "245351", "url": "https://en.wikipedia.org/wiki?curid=245351", "title": "Emil Artin", "text": "Emil Artin\n\nEmil Artin (; March 3, 1898 – December 20, 1962) was an Austrian mathematician of Armenian descent. Artin was one of the leading mathematicians of the twentieth century. He is best known for his work on algebraic number theory, contributing largely to class field theory and a new construction of L-functions. He also contributed to the pure theories of rings, groups and fields.\n\nEmil Artin was born in Vienna to parents Emma Maria, née Laura (stage name Clarus), a soubrette on the operetta stages of Austria and Germany, and Emil Hadochadus Maria Artin, Austrian-born of mixed Austrian and Armenian descent. Several documents, including Emil’s birth certificate, list the father’s occupation as “opera singer” though others list it as “art dealer.” It seems at least plausible that he and Emma had met as colleagues in the theater. They were married in St. Stephen's Parish on July 24, 1895.\n\nArtin entered school in September 1904, presumably in Vienna. By then, his father was already suffering symptoms of advanced syphilis, among them increasing mental instability, and was eventually institutionalized at the recently established (and imperially sponsored) insane asylum at Mauer Öhling, 125 kilometers west of Vienna. It is notable that neither wife nor child contracted this highly infectious disease. Artin's father died there July 20, 1906. Young Artin was eight.\n\nOn July 15, 1907, Artin’s mother remarried to a man named Rudolf Hübner: a prosperous manufacturing entrepreneur in the German-speaking city then called Reichenberg, Bohemia (currently known as Liberec, in the Czech Republic). Documentary evidence suggests that Emma had already been a resident in Reichenberg the previous year, and in deference to her new husband, she had abandoned her vocal career. Hübner deemed a life in the theater unseemly unfit for the wife of a man of his position.\n\nIn September, 1907, Artin entered the Volksschule in Strobnitz, a small town in southern Czechoslovakia near the Austrian border. For that year, he lived away from home, boarding on a local farm. The following year, he returned to the home of his mother and stepfather, and entered the Realschule in Reichenberg, where he pursued his secondary education until June, 1916.\n\nIn Reichenberg, Artin formed a lifelong friendship with a young neighbor, Arthur Baer, who became an astronomer, teaching for many years at Cambridge University. Astronomy was an interest the two boys shared already at this time. They each had telescopes. They also rigged a telegraph between their houses, over which once Baer excitedly reported to his friend an astronomical discovery he thought he had made—perhaps a supernova, he thought—and told Artin where in the sky to look. Artin tapped back the terse reply “A-N-D-R-O-M-E-D-A N-E-B-E-L.” (Andromeda nebula)\n\nArtin’s academic performance in the first years at the Realschule was spotty. Up to the end of the 1911–1912 school year, for instance, his grade in mathematics was merely “genügend,” (satisfactory). Of his mathematical inclinations at this early period he later wrote, “Meine eigene Vorliebe zur Mathematik zeigte sich erst im sechzehnten Lebensjahr, während vorher von irgendeiner Anlage dazu überhaupt nicht die Rede sein konnte.” (“My own predilection for mathematics manifested itself only in my sixteenth year; before that, one could certainly not speak of any particular aptitude for it.”) His grade in French for 1912 was actually “nicht genügend” (unsatisfactory). He did rather better work in physics and chemistry. But from 1910 to 1912, his grade for “Comportment” was “nicht genügend.”\n\nArtin spent the school year 1912–1913 away from home, in France, a period he spoke of later as one of the happiest of his life. He lived that year with the family of Edmond Fritz, in the vicinity of Paris, and attended a school there. When he returned from France to Reichenberg, his academic work markedly improved, and he began consistently receiving grades of “gut” or “sehr gut” (good or very good) in virtually all subjects—including French and “Comportment.” By the time he completed studies at the Realschule in June, 1916, he was awarded the Reifezeugnis (diploma—not to be confused with the Abitur) that affirmed him “reif mit Auszeichnung” (qualified with distinction) for graduation to a technical university.\n\nNow that it was time to move on to university studies, Artin was no doubt content but to leave Reichenberg, for relations with his stepfather were clouded. According to him, Hübner reproached him “day and night” with being a financial burden, and even when Artin became a university lecturer and then a professor, Hübner deprecated his academic career as self-indulgent and belittled its paltry emolument.\n\nIn October, 1916, Artin matriculated at the University of Vienna, having focused by now on mathematics. He studied there with Philipp Furtwängler, and also took courses in astrophysics and Latin.\n\nStudies at Vienna were interrupted when Artin was drafted in June, 1918 into the Austrian army (his Army photo ID is dated July 1, 1918). Assigned to the K.u. K. 44th Infantry Regiment, he was stationed northwest of Venice at Primolano, on the Italian front in the foothills of the Dolomites. To his great relief, Artin managed to avoid combat by volunteering for service as a translator—his ignorance of Italian notwithstanding. He did know French, of course, and some Latin, was generally a quick study, and was motivated by a highly rational fear in a theater of that war that had often proven a meat-grinder. In his scramble to learn at least some Italian, Artin had recourse to an encyclopedia, which he once consulted for help in dealing with the cockroaches that infested the Austrian barracks. At some length, the article described a variety of technical methods, concluding finally with—Artin laughingly recalled in later years—“la caccia diretta\" (\"the direct hunt\"). Indeed, “la caccia diretta” was the straightforward method he and his fellow infantrymen adopted.\n\nArtin survived both war and vermin on the Italian front, and returned late in 1918 to the University of Vienna, where he remained through Easter of the following year.\n\nBy June 1919, he had moved to Leipzig and matriculated at the University there as a \"Class 2 Auditor\" (\"Hörer zweiter Ordnung\"). Late the same year, Artin undertook the formality of standing for a qualifying examination by an academic board of the Oberrealschule in Leipzig, which he passed with the grade of “gut” (good), receiving for the second time the Reifezeugnis (diploma attesting the equivalence of satisfactory completion of 6 years at a Realschule). How this Leipzig Reifezeugnis differed technically from the one he had been granted at Reichenberg is unclear from the document, but it apparently qualified him for regular matriculation as a student at the University, which normally required the Abitur.\n\nFrom 1919 to June 1921, Artin pursued mostly mathematical studies at Leipzig. His principal teacher and dissertation advisor was Gustav Herglotz. Additionally, Artin took courses in chemistry and various fields of physics, including mechanics, atomic theory, quantum theory, Maxwellian theory, radioactivity, and astrophysics. In June, 1921 he was awarded the Doctor of Philosophy degree, based on his “excellent” dissertation, “Quadratische Körper im Gebiete der höheren Kongruenzen“ (\"On the Arithmetic of Quadratic Function Fields over Finite Fields\"), and the oral examination which—his diploma affirms—he had passed three days earlier “with extraordinary success.”\n\nIn the fall of 1921, Artin moved to the University of Göttingen, considered the \"Mecca\" of mathematics at the time, where he pursued one year of post-doctoral studies in mathematics and mathematical physics with Richard Courant and David Hilbert. While at Göttingen, he worked closely with Emmy Noether and Helmut Hasse.\n\nAside from consistently good school grades in singing, the first documentary evidence of Artin’s deep and lifelong engagement with music comes from the year in Göttingen, where he was regularly invited to join in the chamber music sessions hosted by Richard Courant. He played all the keyboard instruments, and was an especially accomplished flautist, although it is not known exactly by what instruction he had achieved proficiency on these instruments. He became especially devoted to the music of Johann Sebastian Bach.\n\nCourant arranged for Artin to receive a stipend for the summer of 1922 in Göttingen, which occasioned his declining a position offered him at the University of Kiel. The following October, however, he accepted an equivalent position at Hamburg, where in 1923, he completed the Habilitation thesis (required of aspirants to a professorship in Germany), and on July 24 advanced to the rank of Privatdozent.\n\nOn April 1, 1925, Artin was promoted to Associate Professor (außerordentlicher Professor). In this year also, Artin applied for and was granted German citizenship. He was promoted to full Professor (ordentlicher Professor) on October 15, 1926.\n\nEarly in the summer of 1925, Artin attended the Congress of the Wandervogel youth movement at Wilhelmshausen near Kassel with the intention of gathering a congenial group to undertake a trek through Iceland later that summer. Iceland (before the transforming presence of American and British forces stationed there during World War II) was still a primitive country in 1925, with a thinly scattered population and little transportation infrastructure. Artin succeeded in finding six young men to join him in this adventure. In the second half of August, 1925, the group set out by steamer from Hamburg, first to Norway, where they boarded a second steamer that took them to Iceland, stopping at several of the small east fjord ports before arriving at their destination, Húsavík in the north of the island. Here the Wandervogel group disembarked, their initial goal, trekking down the Laxá River to Lake Mývatn. They made a circuit of the large, irregular lake, staying in farm houses, barns, and occasionally a tent as they went. When they slept in barns, it was often on piles of wet straw or hay. On those lucky occasions when they slept in beds, it could be nearly as damp on account of the rain trickling through the sod roofs. The tent leaked as well.\n\nArtin kept a meticulous journal of this trip, making daily entries in a neat, minuscule hand. He and several of the young men had brought cameras, so that the trek is documented also by nearly 200 small photographs. Artin’s journal attests to his overarching interest in the geology of this mid-Atlantic island, situated over the boundary of two tectonic plates whose shifting relation makes it geologically hyperactive.\n\nIn keeping with the Wandervogel ethos, Artin and his companions carried music with them wherever they visited. The young men had packed guitars and violins, and Artin played the harmoniums common in the isolated farmsteads where they found lodging. The group regularly entertained their Icelandic hosts, not in full exchange for board and lodging, to be sure, but for goodwill certainly, and sometimes for a little extra on their plates, or a modestly discounted tariff.\n\nFrom Lake Mývatn, Artin and his companions headed west towards Akureyri, passing the large waterfall Goðafoss on the way. From Akureyri, they trekked west down the Öxnadalur (Ox Valley) intending to rent pack horses and cross the high and barren interior by foot to Reykjavík. By the time they reached the lower end of Skagafjörður, however, they were persuaded by a local farmer from whom they had hoped to rent the horses that a cross-country trek was by then impracticable; with the approach of winter, highland routes were already snow-bound and impassable. Instead of turning south, then, they turned north to Siglufjörður, where they boarded another steamer that took them around the western peninsula and down the coast to Reykjavík. From Reykjavík, they returned via Norway to Hamburg. By Artin's calculation the distance they had covered on foot through Iceland totaled 450 kilometers.\n\nEarly in 1926, the University of Münster offered Artin a professorial position; however, Hamburg matched the offer financially, and (as noted above) promoted him to full professor, making him (along with his young colleague Helmut Hasse) one of the two youngest professors of mathematics in Germany.\n\nIt was in this period that he acquired his lifelong nickname, “Ma,” short for mathematics, which he came to prefer to his given name, and which virtually everyone who knew him well used. Although the nickname might seem to imply a narrow intellectual focus, quite the reverse was true of Artin. Even his teaching at the University of Hamburg went beyond the strict boundaries of mathematics to include mechanics and relativity theory. He kept up on a serious level with advances in astronomy, chemistry and biology (he owned and used a fine microscope), and the circle of his friends in Hamburg attests to the catholicity of his interests. It included the painter Heinrich Stegemann, and the author and organ-builder Hans Henny Jahn. Stegemann was a particularly close friend, and made portraits of Artin, his wife Natascha, and their two Hamburg-born children. Music continued to play a central role in his life; he acquired a Neupert double manual harpsichord, and a clavichord made by the Hamburg builder Walter Ebeloe, as well as a silver flute made in Hamburg by G. Urban. Chamber music gatherings became a regular event at the Artin apartment as they had been at the Courants in Göttingen.\n\nOn August 15, 1929, Artin married Natalia Naumovna Jasny (Natascha), a young Russian émigré who had been a student in several of his classes. One of their shared interests was photography, and when Artin bought a Leica for their joint use (a Leica A, the first commercial model of this legendary camera), Natascha began chronicling the life of the family, as well as the city of Hamburg. For the next decade, she made a series of artful and expressive portraits of Artin that remain by far the best images of him taken at any age. Artin, in turn, took many fine and evocative portraits of Natascha. Lacking access to a professional darkroom, their films and prints had to be developed in a makeshift darkroom set up each time (and then dismantled again) in the small bathroom of whatever apartment they were occupying. The makeshift darkroom notwithstanding, the high artistic level of the resulting photographic prints is attested to by the exhibit of Natascha’s photographs mounted in 2001 by the Museum für Kunst und Gewerbe Hamburg, and its accompanying catalogue, “Hamburg—Wie Ich Es Sah.”\n\nIn 1930, Artin was offered a professorship at ETH (Eidgenössische Technische Hochschule) in Zürich, to replace Hermann Weyl, who had moved to Göttingen. He chose to remain at Hamburg, however. Two years later, in 1932, for contributions leading to the advancement of mathematics, Artin was honored—jointly with Emmy Noether—with the Ackermann–Teubner Memorial Award, which carried a grant of 500 marks.\n\nIn January 1933, Natascha gave birth to their first child, Karin. A year and a half later, in the summer of 1934, son Michael was born. The political climate at Hamburg was not so poisonous as that at Göttingen, where by 1935 the mathematics department had been purged of Jewish and dissident professors. Still, Artin's situation became increasingly precarious, not only because Natascha was half Jewish, but also because Artin made no secret of his distaste for the Hitler regime. At one point, Wilhelm Blaschke, by then a Nazi Party member, but nonetheless solicitous of the Artins’ well-being, warned Artin discreetly to close his classroom door so his frankly anti-Nazi comments could not be heard by passersby in the hallway.\n\nNatascha recalled going down to the newsstand on the corner one day and being warned in hushed tones by the man from whom she and Artin bought their paper that a man had daily been watching their apartment from across the street. Once tipped off, she and Artin became very aware of the watcher (Natascha liked to refer to him as their “spy”), and even rather enjoyed the idea of his being forced to follow them on the long walks they loved taking in the afternoons to a café far out in the countryside.\n\nToying with their watcher on a fine autumn afternoon was one thing, but the atmosphere was in fact growing inexorably serious. Natascha’s Jewish father and her sister, seeing the handwriting on the wall, had already left for the U.S. in the summer of 1933. As half-Jewish, Natascha’s status was, if not ultimately quite hopeless, certainly not good. Hasse, like Blaschke a nationalistic supporter of the regime, had applied for Party membership, but was nonetheless no anti-Semite. Besides he was a long-time friend and colleague of Artin's. He suggested that the two Artin children—only one quarter Jewish, or in Nazi terminology, “Mischlinge zweiten Grades”—might, if a few strategic strings could be pulled, be officially “aryanized.” Hasse offered to exert his influence with the Ministry of Education (Kultur- und Schulbehörde, Hochschulwesen), and Artin—not daring to leave any stone unturned, especially with respect to the safety of his children—went along with this effort. He asked his father-in-law, by then resident in Washington D.C., to draft and have notarized an affidavit attesting to the Christian lineage of his late wife, Natascha’s mother. Artin submitted this affidavit to the Ministry of Education, but to no avail.\n\nBy this time, to be precise, on July 15, 1937, because of Natascha’s status as “Mischling ersten Grades,” Artin had lost his post at the University—technically, compelled into early retirement—on the grounds of paragraph 6 of the Act to Restore the Professional Civil Service (Gesetz zur Wiederherstellung des Berufsbeamtentums) of April 7, 1933. Ironically, he had applied only some months earlier, on February 8, 1937, for a leave of absence from the University in order to accept a position offered him at Stanford. On March 15, 1937, the response had come back denying his application for leave on the grounds that his services to the University were indispensable (“Da die Tätigkeit des Professors Dr. Artin an der Universität Hamburg nicht entbehrt werden kann. . .”).\n\nBy July, when he was summarily “retired,” (“in Ruhestand versetzt”) the position at Stanford University had been filled. However, through the efforts of Richard Courant (by then at New York University), and Solomon Lefschetz at Princeton University, a position was found for him at the University of Notre Dame in South Bend, Indiana.\n\nThe family must have worked feverishly to prepare for emigration to the United States, for this entailed among other things packing their entire household for shipment. Since German law forbade emigrants taking more than a token sum of money out of the country, the Artins sank all the funds at their disposal into shipping their entire household, from beds, tables, chairs and double-manual harpsichord down to the last kitchen knife, cucumber slicer, and potato masher to their new home. This is why each of their residences in the United States bore such a striking resemblance to the rooms photographed so beautifully by Natascha in their Hamburg apartment (see Natascha A. Brunswick, “Hamburg: Wie Ich Es Sah,” Dokumente der Photographie 6, Museum für Kunst und Gewerbe Hamburg, 2001, pp. 48–53) .\n\nOn the morning they were to board the Hamburg-Amerika line ship in Bremerhaven, October 21, 1937, daughter Karin woke with a high temperature. Terrified that should this opportunity be missed, the window of escape from Nazi Germany might close forever, Artin and Natascha chose to risk somehow getting Karin past emigration and customs officials without their noticing her condition. They managed to conceal Karin’s feverish state, and without incident boarded the ship, as many left behind were tragically never able to do. When they landed a week later at Hoboken, New Jersey, Richard Courant and Natascha’s father, the Russian agronomist Naum Jasny (then working for the U.S. Department of Agriculture) were on the dock to welcome the family to the United States.\n\nIt was early November, 1937 by the time they arrived in South Bend, where Artin joined the faculty at Notre Dame, and taught for the rest of that academic year. He was offered a permanent position the following year 170 miles to the south at Indiana University, in Bloomington. Shortly after the family resettled there, a second son, Thomas, was born on November 12, 1938.\n\nAfter moving to Bloomington, Artin quickly acquired a piano, and soon after that a Hammond Organ, a recently invented electronic instrument that simulated the sound of a pipe organ. He wanted this instrument in order primarily to play the works of J. S. Bach, and because the pedal set that came with the production model had a range of only two octaves (not quite wide enough for all the Bach pieces), he set about extending its range. Music was a constant presence in the Artin household. Karin played the cello, and then the piano as well, and Michael played the violin. As in Hamburg, the Artin living room was regularly the venue for amateur chamber music performances.\n\nThe circle of the Artins’ University friends reflected Artin's wide cultural and intellectual interests. Notable among them were Alfred Kinsey and his wife of the Psychology Department, as well as prominent members of the Fine Arts, Art History, Anthropology, German Literature, and Music Departments. For several summer semesters, Artin accepted teaching positions at other universities, viz., Stanford in 1939 and 1940, The University of Michigan at Ann Arbor in 1941 and 1951, and The University of Colorado, in Boulder, in 1953. On each of these occasions, the family accompanied him.\n\nArtin insisted that only German be spoken in the house. Even Tom, born in the U.S., spoke German as his first language, acquiring English only from his siblings and his playmates in the neighborhood; for the first four or five years of his life, he spoke English with a pronounced German accent. Consistent with his program of maintaining the family’s German cultural heritage, Artin gave high priority to regularly reading German literature aloud to the children. The text was frequently from Goethe's autobiographical \"Dichtung und Wahrheit,\" or his poems, \"Erlkönig,\" for instance. Occasionally, he would read from an English text. Favorites were Mark Twain's \"Tom Sawyer,\" Charles Dickens’s “A Christmas Carol,” and Oscar Wilde’s “The Canterville Ghost.” For the Artin children, these readings replaced radio entertainment, which was strictly banned from the house. There was a radio, but (with the notable exception of Sunday morning broadcasts by E. Power Biggs from the organ at the Busch-Reisinger Museum in Cambridge, to which Artin and Natascha listened still lounging in bed) it was switched on only to hear news of the war. Similarly, the Artin household would never in years to come harbor a television set. Once the war had ended, the radio was retired to the rear of a dark closet.\n\nAs German citizens, Artin and Natascha were technically classified as enemy aliens for the duration of the war. On April 12, 1945, with the end of the war in Europe only weeks away, they applied for naturalization as American citizens. American citizenship was granted them on February 7, 1946.\n\nOn the orders of a Hamburg doctor whom he had consulted about a chronic cough, Artin had given up smoking years before. He had vowed not to smoke so long as Adolf Hitler remained in power. On May 8, 1945, at the news of Germany’s surrender and the fall of the Third Reich, Natascha made the mistake of reminding him of this vow, and in lieu of a champagne toast, he indulged in what was intended to be the smoking of a single, celebratory cigarette. Unfortunately, the single cigarette led to a second, and another after that. Artin returned to heavy smoking for the rest of his life.\n\nIf Göttingen had been the “Mecca” of mathematics in the 1920s and early ‘30s, Princeton, following the decimation of German mathematics under the Nazis, had become the center of the mathematical world in the 1940s. In April, 1946, Artin was appointed Professor at Princeton, at a yearly salary of $8,000. The family moved there in the fall of 1946.\n\nNotable among his graduate students at Princeton are Serge Lang, John Tate, Harold N. Shapiro, and Timothy O’Meara. Emil chose also to teach the honors section of Freshman calculus each year. He was renowned for the elegance of his teaching. Frei and Roquette write that Artin’s “main medium of communication was teaching and conversation: in groups, seminars and in smaller circles. We have many statements of people near to him describing his unpretentious way of communicating with everybody, demanding quick grasp of the essentials but never tired of explaining the necessary. He was open to all kinds of suggestions, and distributed joyfully what he knew. He liked to teach, also to young students, and his excellent lectures, always well prepared but without written notes, were hailed for their clarity and beauty.” (Emil Artin and Helmut Hasse: Their Correspondence 1923–1934, Introduction.)\n\nWhenever he was asked whether mathematics was a science, Artin would reply unhesitatingly, “No. An art.” His elegant elaboration of this idea is often cited, and worth repeating here: “We all believe that mathematics is an art. The author of a book, the lecturer in a classroom tries to convey the structural beauty of mathematics to his readers, to his listeners. In this attempt, he must always fail. Mathematics is logical to be sure, each conclusion is drawn from previously derived statements. Yet the whole of it, the real piece of art, is not linear; worse than that, its perception should be instantaneous. We have all experienced on some rare occasion the feeling of elation in realizing that we have enabled our listeners to see at a glance the whole architecture and all its ramifications.”\n\nIt has even been said—only half in jest—that his lectures could be too perfect, lulling a hearer into believing he had understood and assimilated an idea or a proof which, on waking the following day might seem as remote and chimerical as ever.\n\nDuring the Princeton years, Artin built a reflecting telescope to plans he found in the magazine \"Sky and Telescope\", which he subscribed to. He spent weeks in the basement attempting to grind the mirror to specifications, without success, and his continued failure to get it right led to increasing frustration. Then, in California to give a talk, he made a side trip to the Mt. Wilson Observatory, where he discussed his project with the astronomers. Whether it was their technical advice, or Natascha’s intuitive suggestion that it might be too cold in the basement, and that he should try the procedure upstairs in the warmth of his study (which he did), he completed the grinding of the mirror in a matter of days. With this telescope, he surveyed the night skies over Princeton.\n\nIn September 1955, Artin accepted an invitation to visit Japan. From his letters, it is clear he was treated like royalty by the Japanese mathematical community, and was charmed by the country. He was interested in learning about the diverse threads of Buddhism, and visiting its holy sites. In a letter home he describes his visit to the temples at Nara. “Then we were driven to a place nearby, Horiuji [Horyu-ji] where a very beautiful Buddhist temple is. We were received by the abbot, and a priest translated into English. We obtained the first sensible explanation about modern Buddhism. The difficulty of obtaining such an explanation is enormous. To begin with most Japanese do not know and do not understand our questions. All this is made more complicated by the fact that there are numerous sects and each one has another theory. Since you get your information only piece wise, you cannot put it together. This results in an absurd picture. I am talking of the present day, not of its original form.”\n\nHis letter goes on to outline at length the general eschatological framework of Buddhist belief. Then he adds, “By the way, a problem given by the Zens for meditation is the following: If you clap your hands, does the sound come from the left hand or from the right?”\n\nThe following year, Artin took a leave of absence to return to Germany for the first time since emigration, nearly twenty years earlier. He spent the fall semester at Göttingen, and the next at Hamburg. For the Christmas holidays, he travelled to his birthplace, Vienna, to visit his mother, Vienna being a city he had not seen in decades. In a letter home he described the experience of his return in a single, oddly laconic sentence: “It is kind of amusing to walk through Vienna again.” In 1957, an honorary doctorate was conferred on Artin by the University of Freiburg. That fall, he returned to Princeton for what would be his final academic year at that institution. He was elected a Fellow of the American Academy of Arts and Sciences in 1957.\n\nArtin's marriage to Natascha had by this time seriously frayed. Though nominally still husband and wife, resident in the same house, they were for all intents and purposes living separate lives. Artin was offered a professorship at Hamburg, and at the conclusion of Princeton's spring semester, 1958, he moved permanently to Germany. His decision to leave Princeton University and the United States was complicated, based on multiple factors, prominent among them Princeton's (then operative) mandatory retirement age of 65. Artin had no wish to retire from teaching and direct involvement with students. Hamburg's offer was open-ended.\n\nArtin and Natascha were divorced in 1959. In Hamburg, Artin had taken an apartment, but soon gave it over to his mother whom he had brought from Vienna to live near him in Hamburg. He in turn moved into the apartment of the mathematician Hel Braun in the same neighborhood; though they never married, their relationship was equivalent to marriage. On January 4, 1961, he was granted German citizenship. In June, 1962, on the occasion of the 300th anniversary of the death of Blaise Pascal, the University of Clermont-Ferrand conferred an honorary doctorate on him. On December 20 of the same year, Artin died at home in Hamburg, aged 64, of a heart attack.\n\nThe University of Hamburg honored his memory on April 26, 2005 by naming one of its newly renovated lecture halls The Emil Artin Lecture Hall.\n\nArtin was one of the leading algebraists of the century, with an influence larger than might be guessed from the one volume of his \"Collected Papers\" edited by Serge Lang and John Tate. He worked in algebraic number theory, contributing largely to class field theory and a new construction of L-functions. He also contributed to the pure theories of rings, groups and fields. The influential treatment of abstract algebra by van der Waerden is said to derive in part from Artin's ideas, as well as those of Emmy Noether. Artin solved Hilbert's seventeenth problem in 1927. He also developed the theory of braids as a branch of algebraic topology.\n\nIn 1955 Artin was teaching foundations of geometry at New York University. He used his notes to publish Geometric Algebra in 1957, where he extended the material to include symplectic geometry.\n\nArtin was also an important expositor of Galois theory, and of the group cohomology approach to class ring theory (with John Tate), to mention two theories where his formulations became standard.\n\nHe left two conjectures, both known as Artin's conjecture. The first concerns Artin L-functions for a linear representation of a Galois group; and the second the frequency with which a given integer \"a\" is a primitive root modulo primes \"p\", when \"a\" is fixed and \"p\" varies. These are unproven; in 1967, Hooley published a conditional proof for the second conjecture, assuming certain cases of the Generalized Riemann hypothesis.\n\nArtin advised over thirty doctoral students, including Bernard Dwork, Serge Lang, K. G. Ramanathan, John Tate, Harold N. Shapiro, Hans Zassenhaus and Max Zorn. A more complete list of his students can be found at the Mathematics Genealogy Project website (see \"External Links,\" below).\n\nIn 1932 he married Natascha Jasny, born in Russia to mixed parentage (her mother was Christian, her father, Jewish). Artin was not himself Jewish, but, on account of his wife's racial status in Nazi Germany, was dismissed from his university position in 1937. They had three children, one of whom is Michael Artin, an American algebraist currently at the Massachusetts Institute of Technology.\n\n\n\n\n"}
{"id": "1989599", "url": "https://en.wikipedia.org/wiki?curid=1989599", "title": "Euclidean plane isometry", "text": "Euclidean plane isometry\n\nIn geometry, a Euclidean plane isometry is an isometry of the Euclidean plane, or more informally, a way of transforming the plane that preserves geometrical properties such as length. There are four types: translations, rotations, reflections, and glide reflections (see below under classification of Euclidean plane isometries).\n\nThe set of Euclidean plane isometries forms a group under composition: the Euclidean group in two dimensions. It is generated by reflections in lines, and every element of the Euclidean group is the composite of at most three distinct reflections.\n\nInformally, a Euclidean plane isometry is any way of transforming the plane without \"deforming\" it. For example, suppose that the Euclidean plane is represented by a sheet of transparent plastic sitting on a desk. Examples of isometries include:\n\nThese are examples of translations, rotations, and reflections respectively. There is one further type of isometry, called a glide reflection (see below under classification of Euclidean plane isometries).\n\nHowever, folding, cutting, or melting the sheet are not considered isometries. Neither are less drastic alterations like bending, stretching, or twisting.\n\nAn isometry of the Euclidean plane is a distance-preserving transformation of the plane. That is, it is a map\nsuch that for any points \"p\" and \"q\" in the plane,\nwhere \"d\"(\"p\", \"q\") is the usual Euclidean distance between \"p\" and \"q\".\n\nIt can be shown that there are four types of Euclidean plane isometries. (Note: the notations for the types of isometries listed below are not completely standardised.)\nReflections, or mirror isometries, denoted by \"F\", where \"c\" is a point in the plane and \"v\" is a unit vector in R. (\"F\" is for \"flip\".) have the effect of reflecting the point \"p\" in the line \"L\" that is perpendicular to \"v\" and that passes through \"c\". The line \"L\" is called the reflection axis or the associated mirror. To find a formula for \"F\", we first use the dot product to find the component \"t\" of \"p\" − \"c\" in the \"v\" direction,\n\nThe combination of rotations about the origin and reflections about a line through the origin is obtained with all orthogonal matrices (i.e. with determinant 1 and −1) forming orthogonal group \"O\"(2). In the case of a determinant of −1 we have:\nwhich is a reflection in the \"x\"-axis followed by a rotation by an angle θ, or equivalently, a reflection in a line making an angle of θ/2 with the \"x\"-axis. Reflection in a parallel line corresponds to adding a vector perpendicular to it.\n\nTranslations, denoted by \"T\", where \"v\" is a vector in R have the effect of shifting the plane in the direction of \"v\". That is, for any point \"p\" in the plane,\n\nA translation can be seen as a composite of two parallel reflections.\n\nRotations, denoted by \"R\", where \"c\" is a point in the plane (the centre of rotation), and θ is the angle of rotation. In terms of coordinates, rotations are most easily expressed by breaking them up into two operations. First, a rotation around the origin is given by\n\nThe set of translations and rotations together form the rigid motions or displacements. This set forms a group under composition, the \"group of rigid motions\", a subgroup of the full group of Euclidean isometries.\n\nA rotation can be seen as a composite of two non-parallel reflections.\n\nGlide reflections, denoted by \"G\", where \"c\" is a point in the plane, \"v\" is a unit vector in R, and \"w\" is non-null a vector perpendicular to \"v\" are a combination of a reflection in the line described by \"c\" and \"v\", followed by a translation along \"w\". That is,\n\nThe identity isometry, defined by \"I\"(\"p\") = \"p\" for all points \"p\" is a special case of a translation, and also a special case of a rotation. It is the only isometry which belongs to more than one of the types described above.\n\nIn all cases we multiply the position vector by an orthogonal matrix and add a vector; if the determinant is 1 we have a rotation, a translation, or the identity, and if it is −1 we have a glide reflection or a reflection.\n\nA \"random\" isometry, like taking a sheet of paper from a table and randomly laying it back, \"almost surely\" is a rotation or a glide reflection (they have three degrees of freedom). This applies regardless of the details of the probability distribution, as long as θ and the direction of the added vector are independent and uniformly distributed and the length of the added vector has a continuous distribution. A pure translation and a pure reflection are special cases with only two degrees of freedom, while the identity is even more special, with no degrees of freedom.\n\nReflections, or mirror isometries, can be combined to produce any isometry. Thus isometries are an example of a reflection group.\n\nIn the Euclidean plane, we have the following possibilities.\n\nAdding more mirrors does not add more possibilities (in the plane), because they can always be rearranged to cause cancellation.\n\nWe can recognize which of these isometries we have according to whether it preserves hands or swaps them, and whether it has at least one fixed point or not, as shown in the following table (omitting the identity).\n\nIsometries requiring an odd number of mirrors — reflection and glide reflection — always reverse left and right. The even isometries — identity, rotation, and translation — never do; they correspond to \"rigid motions\", and form a normal subgroup of the full Euclidean group of isometries. Neither the full group nor the even subgroup are abelian; for example, reversing the order of composition of two parallel mirrors reverses the direction of the translation they produce.\n\nSince the even subgroup is normal, it is the kernel of a homomorphism to a quotient group, where the quotient is isomorphic to a group consisting of a reflection and the identity. However the full group is not a direct product, but only a semidirect product, of the even subgroup and the quotient group.\n\nComposition of isometries mixes kinds in assorted ways. We can think of the identity as either two mirrors or none; either way, it has no effect in composition. And two reflections give either a translation or a rotation, or the identity (which is both, in a trivial way). Reflection composed with either of these could cancel down to a single reflection; otherwise it gives the only available three-mirror isometry, a glide reflection. A pair of translations always reduces to a single translation; so the challenging cases involve rotations. We know a rotation composed with either a rotation or a translation must produce an even isometry. Composition with translation produces another rotation (by the same amount, with shifted fixed point), but composition with rotation can yield either translation or rotation. It is often said that composition of two rotations produces a rotation, and Euler proved a theorem to that effect in 3D; however, this is only true for rotations sharing a fixed point.\n\nWe thus have two new kinds of isometry subgroups: all translations, and rotations sharing a fixed point. Both are subgroups of the even subgroup, within which translations are normal. Because translations are a normal subgroup, we can factor them out leaving the subgroup of isometries with a fixed point, the orthogonal group.\n\nThe subgroup structure suggests another way to compose an arbitrary isometry:\n\nThis works because translations are a normal subgroup of the full group of isometries, with quotient the orthogonal group; and rotations about a fixed point are a normal subgroup of the orthogonal group, with quotient a single reflection.\n\nThe subgroups discussed so far are not only infinite, they are also continuous (Lie groups). Any subgroup containing at least one non-zero translation must be infinite, but subgroups of the orthogonal group can be finite. For example, the symmetries of a regular pentagon consist of rotations by integer multiples of 72° (360° / 5), along with reflections in the five mirrors which perpendicularly bisect the edges. This is a group, D, with 10 elements. It has a subgroup, C, of half the size, omitting the reflections. These two groups are members of two families, D and C, for any \"n\" > 1. Together, these families constitute the rosette groups.\n\nTranslations do not fold back on themselves, but we can take integer multiples of any finite translation, or sums of multiples of two such independent translations, as a subgroup. These generate the lattice of a periodic tiling of the plane.\n\nWe can also combine these two kinds of discrete groups — the discrete rotations and reflections around a fixed point and the discrete translations — to generate the frieze groups and wallpaper groups. Curiously, only a few of the fixed-point groups are found to be compatible with discrete translations. In fact, lattice compatibility imposes such a severe restriction that, up to isomorphism, we have only 7 distinct frieze groups and 17 distinct wallpaper groups. For example, the pentagon symmetries, D, are incompatible with a discrete lattice of translations. (Each higher dimension also has only a finite number of such crystallographic groups, but the number grows rapidly; for example, 3D has 230 groups and 4D has 4783.)\n\nIn terms of complex numbers, the isometries of the plane are either of the form\nor of the form\nfor some complex numbers \"a\" and ω with |ω| = 1. This is easy to prove: if \"a\" = \"f\"(0) and ω = \"f\"(1) − \"f\"(0) and if one defines\nthen \"g\" is an isometry, \"g\"(0) = 0, and \"g\"(1) = 1. It is then easy to see that \"g\" is either the identity or the conjugation, and the statement being proved follows from this and from the fact that \"f\"(\"z\") = \"a\" + ω\"g\"(\"z\").\n\nThis is obviously related to the previous classification of plane isometries, since:\n\nNote that a rotation about complex point \"p\" is obtained by complex arithmetic with\nwhere the last expression shows the mapping equivalent to rotation at 0 and a translation.\nTherefore, given direct isometry formula_20 one can solve\nformula_21 to obtain formula_22 as the center for an equivalent rotation, provided that formula_23, that is, provided the direct isometry is not a pure translation. As stated by Cederberg (page 151), \"A direct isometry is either a rotation or a translation.\"\n\n\n"}
{"id": "26006899", "url": "https://en.wikipedia.org/wiki?curid=26006899", "title": "Evasive Boolean function", "text": "Evasive Boolean function\n\nIn mathematics, an evasive Boolean function \"ƒ\" (of \"n\" variables) is a Boolean function for which every decision tree algorithm has running time of exactly \"n\". Consequently, every decision tree algorithm that represents the function has, at worst case, a running time of \"n\".\n\nThe following is a Boolean function on the three variables \"x\", \"y\", \"z\":\n\n(where formula_1 is the bitwise \"and\", formula_2 is the bitwise \"or\", and formula_3 is the bitwise \"not\").\n\nThis function is not evasive, because there is a decision tree that solves it by checking exactly two variables: The algorithm first checks the value of \"x\". If \"x\" is true, the algorithm checks the value of \"y\" and returns it.\n\nIf \"x\" is false, the algorithm checks the value of \"z\" and returns it.\n\nConsider this simple \"and\" function on three variables:\n\nA worst-case input (for every algorithm) is 1, 1, 1. In every order we choose to check the variables, we have to check all of them. (Note that in general there could be a different worst-case input for every decision tree algorithm.) Hence the functions: \"and\", \"or\" (on \"n\" variables) are evasive.\n\nFor the case of binary zero-sum games, every evaluation function is evasive.\n\nIn every zero-sum game, the value of the game is achieved by the minimax algorithm (player 1 tries to maximize the profit, and player 2 tries to minimize the cost).\n\nIn the binary case, the max function equals the bitwise \"or\", and the min function equals the bitwise \"and\".\n\nA decision tree for this game will be of this form:\n\nFor every such tree with \"n\" leaves, the running time in the worst case is \"n\" (meaning that the algorithm must check all the leaves):\n\nWe will exhibit an adversary that produces a worst-case input – for every leaf that the algorithm checks, the adversary will answer 0 if the leaf's parent is an Or node, and 1 if the parent is an And node.\n\nThis input (0 for all Or nodes' children, and 1 for all And nodes' children) forces the algorithm to check all nodes:\n\nAs in the second example\n\n"}
{"id": "193537", "url": "https://en.wikipedia.org/wiki?curid=193537", "title": "Hermann Minkowski", "text": "Hermann Minkowski\n\nHermann Minkowski (; ; 22 June 1864 – 12 January 1909) was a German mathematician and professor at Königsberg, Zürich and Göttingen. He created and developed the geometry of numbers and used geometrical methods to solve problems in number theory, mathematical physics, and the theory of relativity.\n\nMinkowski is perhaps best known for his work in relativity, in which he showed in 1907 that his former student Albert Einstein's special theory of relativity (1905) could be understood geometrically as a theory of four-dimensional space–time, since known as the \"Minkowski spacetime\".\n\nHermann Minkowski was born in Aleksotas, a village in the Kovno Governorate of the Russian Empire (now incorporated into the city of Kaunas, Lithuania) to Lewin Boruch Minkowski, a merchant who subsidized the building of the choral synagogue in Kovno, and Rachel Taubmann, both of Jewish descent.\nHermann was a younger brother of the medical researcher, Oskar (born 1858).\nIn different sources Minkowski's nationality is variously given as German,\nPolish, or Lithuanian-German, or Russian.\n\nTo escape persecution in Russia the family moved to Königsberg in 1872, where the father became involved in rag export and later in manufacture of mechanical clockwork tin toys (he operated his firm \"Lewin Minkowski & Son\" with his eldest son Max).\n\nMinkowski studied in Königsberg and taught in Bonn (1887–1894), Königsberg (1894–1896) and Zurich (1896–1902), and finally in Göttingen from 1902 until his premature death in 1909. He married Auguste Adler in 1897 with whom he had two daughters; the electrical engineer and inventor Reinhold Rudenberg was his son-in-law.\n\nMinkowski died suddenly of appendicitis in Göttingen on 12 January 1909. David Hilbert's obituary of Minkowski illustrates the deep friendship between the two mathematicians (translated):\n\nMax Born delivered the obituary on behalf of the mathematics students at Göttingen.\n\nThe main-belt asteroid 12493 Minkowski and M-matrices are named in Minkowski's honor.\n\nMinkowski was educated in East Prussia at the \"Albertina\" University of Königsberg, where he earned his doctorate in 1885 under the direction of Ferdinand von Lindemann. In 1883, while still a student at Königsberg, he was awarded the Mathematics Prize of the French Academy of Sciences for his manuscript on the theory of quadratic forms. He also became a friend of another renowned mathematician, David Hilbert. His brother, Oskar Minkowski (1858–1931), was a well-known physician and researcher.\n\nMinkowski taught at the universities of Bonn, Göttingen, Königsberg, and Zürich. At the \"Eidgenössische Polytechnikum\", today the ETH Zurich, he was one of Einstein's teachers.\n\nMinkowski explored the arithmetic of quadratic forms, especially concerning \"n\" variables, and his research into that topic led him to consider certain geometric properties in a space of \"n\" dimensions. In 1896, he presented his \"geometry of numbers\", a geometrical method that solved problems in number theory. He is also the creator of the Minkowski Sausage and the Minkowski cover of a curve.\n\nIn 1902, he joined the Mathematics Department of Göttingen and became a close colleague of David Hilbert, whom he first met at university in Königsberg. Constantin Carathéodory was one of his students there.\n\nBy 1907 Minkowski realized that the special theory of relativity, introduced by his former student Albert Einstein in 1905 and based on the previous work of Lorentz and Poincaré, could best be understood in a four-dimensional space, since known as the \"Minkowski spacetime\", in which time and space are not separated entities but intermingled in a four-dimensional space–time, and in which the Lorentz geometry of special relativity can be effectively represented using the invariant interval formula_1 (see History of special relativity).\n\nThe mathematical basis of Minkowski space can also be found in the hyperboloid model of hyperbolic space already known in the 19th century, because isometries (or motions) in hyperbolic space can be related to Lorentz transformations, which included contributions of Wilhelm Killing (1880, 1885), Henri Poincaré (1881), Homersham Cox (1881), Alexander Macfarlane (1894) and others (see History of Lorentz transformations).\n\nThe beginning part of his address called \"Space and Time\" delivered at the 80th \"Assembly of German Natural Scientists and Physicians\" (21 September 1908) is now famous:\n\nThe views of space and time which I wish to lay before you have sprung from the soil of experimental physics, and therein lies their strength. They are radical. Henceforth space by itself, and time by itself, are doomed to fade away into mere shadows, and only a kind of union of the two will preserve an independent reality.\n\n\n\n"}
{"id": "1759247", "url": "https://en.wikipedia.org/wiki?curid=1759247", "title": "Highly abundant number", "text": "Highly abundant number\n\nIn mathematics, a highly abundant number is a natural number with the property that the sum of its divisors (including itself) is greater than the sum of the divisors of any smaller natural number.\n\nHighly abundant numbers and several similar classes of numbers were first introduced by , and early work on the subject was done by . Alaoglu and Erdős tabulated all highly abundant numbers up to 10, and showed that the number of highly abundant numbers less than any \"N\" is at least proportional to log \"N\".\n\nFormally, a natural number \"n\" is called highly abundant if and only if for all natural numbers \"m\" < \"n\",\n\nwhere σ denotes the sum-of-divisors function. The first few highly abundant numbers are\n\nFor instance, 5 is not highly abundant because σ(5) = 5+1 = 6 is smaller than σ(4) = 4 + 2 + 1 = 7, while 8 is highly abundant because σ(8) = 8 + 4 + 2 + 1 = 15 is larger than all previous values of σ.\n\nThe only odd highly abundant numbers are 1 and 3.\n\nAlthough the first eight factorials are highly abundant, not all factorials are highly abundant. For example,\nbut there is a smaller number with larger sum of divisors,\nso 9! is not highly abundant.\n\nAlaoglu and Erdős noted that all superabundant numbers are highly abundant, and asked whether there are infinitely many highly abundant numbers that are not superabundant. This question was answered affirmatively by .\n\nDespite the terminology, not all highly abundant numbers are abundant numbers. In particular, none of the first seven highly abundant numbers is abundant.\n\n7200 is the largest powerful number that is also highly abundant: all larger highly abundant numbers have a prime factor that divides them only once. Therefore, 7200 is also the largest highly abundant number with an odd sum of divisors.\n\n"}
{"id": "23190613", "url": "https://en.wikipedia.org/wiki?curid=23190613", "title": "Hurwitz's theorem (number theory)", "text": "Hurwitz's theorem (number theory)\n\nIn number theory, Hurwitz's theorem, named after Adolf Hurwitz, gives a bound on a Diophantine approximation. The theorem states that for every irrational number \"ξ\" there are infinitely many relatively prime integers \"m\", \"n\" such that\n\nThe hypothesis that \"ξ\" is irrational cannot be omitted. Moreover the constant formula_2 is the best possible; if we replace formula_2 by any number formula_4 and we let formula_5 (the golden ratio) then there exist only \"finitely\" many relatively prime integers \"m\", \"n\" such that the formula above holds.\n\n"}
{"id": "22015564", "url": "https://en.wikipedia.org/wiki?curid=22015564", "title": "International Conference on Technology in Collegiate Mathematics", "text": "International Conference on Technology in Collegiate Mathematics\n\nThe International Conference on Technology in Collegiate Mathematics (ICTCM) is an annual conference sponsored by Pearson Addison-Wesley & Pearson Prentice Hall publishers. Electronic proceedings are available for many years and are included in the List of free electronic journals in mathematics.\n\nSince ICTCM 10, the conference has awarded an annual ICTCM Award to recognize an individual or group for excellence and innovation in using technology to enhance the teaching and learning of mathematics.\n"}
{"id": "54571114", "url": "https://en.wikipedia.org/wiki?curid=54571114", "title": "Interrupted time series", "text": "Interrupted time series\n\nInterrupted time series analysis, sometimes known as quasi-experimental time series analysis, is an approach for the analysis of a single time series of data known or conjectured to be affected by interventions (controlled external influences). Interrupted time series design is the design of experiments based on the interrupted time series approach.\n\nApplications include various research in social sciences:\n\nThe ITS design is the base of the comparative time series design, whereby there is a control series and an interrupted series, and the effect of an intervention is confirmed by the control series.\n\nEffects of the intervention are evaluated by changes in the level and slope of the time series and statistical significance of the intervention parameters.\n\n"}
{"id": "6152753", "url": "https://en.wikipedia.org/wiki?curid=6152753", "title": "Landau set", "text": "Landau set\n\nIn voting systems, the Landau set (or uncovered set, or Fishburn set) is the set of candidates formula_1 such that for every other candidate formula_2, there is some candidate formula_3 (possibly the same as formula_1 or formula_2) such that formula_3 is not preferred to formula_1 and formula_2 is not preferred to formula_3. In notation, formula_1 is in the Landau set if \nformula_11, formula_12, formula_13.\n\nThe Landau set is a nonempty subset of the Smith set. It was discovered by Nicholas Miller.\n\n"}
{"id": "16646944", "url": "https://en.wikipedia.org/wiki?curid=16646944", "title": "Lie sphere geometry", "text": "Lie sphere geometry\n\nLie sphere geometry is a geometrical theory of planar or spatial geometry in which the fundamental concept is the circle or sphere. It was introduced by Sophus Lie in the nineteenth century. The main idea which leads to Lie sphere geometry is that lines (or planes) should be regarded as circles (or spheres) of infinite radius and that points in the plane (or space) should be regarded as circles (or spheres) of zero radius.\n\nThe space of circles in the plane (or spheres in space), including points and lines (or planes) turns out to be a manifold known as the Lie quadric (a quadric hypersurface in projective space). Lie sphere geometry is the geometry of the Lie quadric and the Lie transformations which preserve it. This geometry can be difficult to visualize because Lie transformations do not preserve points in general: points can be transformed into circles (or spheres).\n\nTo handle this, curves in the plane and surfaces in space are studied using their contact lifts, which are determined by their tangent spaces. This provides a natural realisation of the osculating circle to a curve, and the curvature spheres of a surface. It also allows for a natural treatment of Dupin cyclides and a conceptual solution of the problem of Apollonius.\n\nLie sphere geometry can be defined in any dimension, but the case of the plane and 3-dimensional space are the most important. In the latter case, Lie noticed a remarkable similarity between the Lie quadric of spheres in 3-dimensions, and the space of lines in 3-dimensional projective space, which is also a quadric hypersurface in a 5-dimensional projective space, called the Plücker or Klein quadric. This similarity led Lie to his famous \"line-sphere correspondence\" between the space of lines and the space of spheres in 3-dimensional space.\n\nThe key observation that leads to Lie sphere geometry is that theorems of Euclidean geometry in the plane (resp. in space) which only depend on the concepts of circles (resp. spheres) and their tangential contact have a more natural formulation in a more general context in which circles, lines and points (resp. spheres, planes and points) are treated on an equal footing. This is achieved in three steps. First an ideal point at infinity is added to Euclidean space so that lines (or planes) can be regarded as circles (or spheres) passing through the point at infinity (i.e., having infinite radius). This extension is known as inversive geometry with automorphisms known as \"Mobius transformations\". Second, points are regarded as circles (or spheres) of zero radius. Finally, for technical reasons, the circles (or spheres), including the lines (or planes) are given orientations.\n\nThese objects, i.e., the points, oriented circles and oriented lines in the plane, or the points, oriented spheres and oriented planes in space, are sometimes called cycles or Lie cycles. It turns out that they form a quadric hypersurface in a projective space of dimension 4 or 5, which is known as the Lie quadric. The natural symmetries of this quadric form a group of transformations known as the Lie transformations. These transformations do not preserve points in general: they are transforms of the Lie quadric, \"not\" of the plane/sphere plus point at infinity. The point-preserving transformations are precisely the Möbius transformations. The Lie transformations which fix the ideal point at infinity are the Laguerre transformations of Laguerre geometry. These two subgroups generate the group of Lie transformations, and their intersection are the Möbius transforms that fix the ideal point at infinity, namely the affine conformal maps.\n\nThese groups also have a direct physical interpretation: As pointed out by Harry Bateman, the Lie sphere transformations are identical with the spherical wave transformations that leave the form of Maxwell's equations invariant. In addition, Élie Cartan, Henri Poincaré and Wilhelm Blaschke pointed out that the Laguerre group is simply isomorphic to the Lorentz group of special relativity (see Laguerre group isomorphic to Lorentz group). Eventually, there is also an isomorphism between the Möbius group and the Lorentz group (see Möbius group#Lorentz transformation).\n\nThe Lie quadric of the plane is defined as follows. Let R denote the space R of 5-tuples of real numbers, equipped with the signature (3,2) symmetric bilinear form defined by\n\nThe projective space RP is the space of lines through the origin in R and is the space of nonzero vectors x in R up to scale, where x= (\"x\",\"x\",\"x\",\"x\",\"x\"). The planar Lie quadric \"Q\" consists of the points [x] in projective space represented by vectors x with x · x = 0.\n\nTo relate this to planar geometry it is necessary to fix an oriented timelike line. The chosen coordinates suggest using the point [1,0,0,0,0] ∈ RP. Any point in the Lie quadric \"Q\" can then be represented by a vector x = λ(1,0,0,0,0) + v, where v is orthogonal to (1,0,0,0,0). Since [x] ∈ \"Q\", v · v = \"λ\" ≥ 0.\n\nThe orthogonal space to (1,0,0,0,0), intersected with the Lie quadric, is the two dimensional celestial sphere \"S\" in Minkowski space-time. This is the Euclidean plane with an ideal point at infinity, which we take to be [0,0,0,0,1]: the finite points (\"x\",\"y\") in the plane are then represented by the points [v] = [0,\"x\",\"y\", −1, (\"x\"+\"y\")/2]; note that v · v = 0, v · (1,0,0,0,0) = 0 and v · (0,0,0,0,1) = −1.\n\nHence points x = \"λ\"(1,0,0,0,0) + v on the Lie quadric with \"λ\" = 0 correspond to points in the Euclidean plane with an ideal point at infinity. On the other hand, points x with \"λ\" nonzero correspond to oriented circles (or oriented lines, which are circles through infinity) in the Euclidean plane. This is easier to see in terms of the celestial sphere \"S\": the circle corresponding to [\"λ\"(1,0,0,0,0) + v] ∈ \"Q\" (with \"λ\" ≠ 0) is the set of points y ∈ \"S\" with y · v = 0. The circle is oriented because v/\"λ\" has a definite sign; [−\"λ\"(1,0,0,0,0) + v] represents the same circle with the opposite orientation. Thus the isometric reflection map x → x + 2 (x · (1,0,0,0,0)) (1,0,0,0,0) induces an involution \"ρ\" of the Lie quadric which reverses the orientation of circles and lines, and fixes the points of the\nplane (including infinity).\n\nTo summarize: there is a one-to-one correspondence between points on the Lie quadric and \"cycles\" in the plane, where a cycle is either an oriented circle (or straight line) or a point in the plane (or the point at infinity); the points can be thought of as circles of radius zero, but they are not oriented.\n\nSuppose two cycles are represented by points [x], [y] ∈ \"Q\". Then x · y = 0 if and only if the corresponding cycles \"kiss\", that is they meet each other with oriented first order contact. If [x] ∈ \"S\" ≅ R ∪ {∞}, then this just means that [x] lies on the circle corresponding to [y]; this case is immediate from the definition of this circle (if [y] corresponds to a point circle then x · y = 0 if and only if [x] = [y]).\n\nIt therefore remains to consider the case that neither [x] nor [y] are in \"S\". Without loss of generality, we can then take x= (1,0,0,0,0) + v and y = (1,0,0,0,0) + w, where v and w are spacelike unit vectors in (1,0,0,0,0). Thus \nv ∩ (1,0,0,0,0) and w ∩ (1,0,0,0,0) are signature (2,1) subspaces of (1,0,0,0,0). They therefore either coincide or intersect in a 2-dimensional subspace. In the latter case, the 2-dimensional subspace can either have signature (2,0), (1,0), (1,1), in which case the corresponding two circles in \"S\" intersect in zero, one or two points respectively. Hence they have first order contact if and only if the 2-dimensional subspace is degenerate (signature (1,0)), which holds if and only if the span of v and w is degenerate. By Lagrange's identity, this holds if and only if (v · w) = (v · v)(w · w) = 1, i.e., if and only if v · w = ± 1, i.e., x · y = 1 ± 1. The contact is oriented if and only if v · w = – 1, i.e., x · y = 0.\n\nThe incidence of cycles in Lie sphere geometry provides a simple solution to the problem of Apollonius. This problem concerns a configuration of three distinct circles (which may be points or lines): the aim is to find every other circle (including points or lines) which is tangent to all three of the original circles. For a generic configuration of circles, there are at most eight such tangent circles.\n\nThe solution, using Lie sphere geometry, proceeds as follows. Choose an orientation for each of the three circles (there are eight ways to do this, but there are only four up to reversing the orientation of all three). This defines three points [x], [y], [z] on the Lie quadric \"Q\". By the incidence of cycles, a solution to the Apollonian problem compatible with the chosen orientations is given by a point [q] ∈ \"Q\" such that q is orthogonal to x, y and z. If these three vectors are linearly dependent, then the corresponding points [x], [y], [z] lie on a line in projective space. Since a nontrivial quadratic equation has at most two solutions, this line actually lies in the Lie quadric, and any point [q] on this line defines a cycle incident with [x], [y] and [z]. Thus there are infinitely many solutions in this case.\n\nIf instead x, y and z are linearly independent then the subspace \"V\" orthogonal to all three is 2-dimensional. It can have signature (2,0), (1,0), or (1,1), in which case there are zero, one or two solutions for [q] respectively. (The signature cannot be (0,1) or (0,2) because it is orthogonal to a space containing more than one null line.) In the case that the subspace has signature (1,0), the unique solution q lies in the span of x, y and z.\n\nThe general solution to the Apollonian problem is obtained by reversing orientations of some of the circles, or equivalently, by considering the triples (x,\"ρ\"(y),z), (x,y,\"ρ\"(z)) and (x,\"ρ\"(y),\"ρ\"(z)).\n\nNote that the triple (\"ρ\"(x),\"ρ\"(y),\"ρ\"(z)) yields the same solutions as (x,y,z), but with an overall reversal of orientation. Thus there are at most 8 solution circles to the Apollonian problem unless all three circles meet tangentially at a single point, when there are infinitely many solutions.\n\nAny element of the group O(3,2) of orthogonal transformations of R maps any one-dimensional subspace of null vectors in R to another such subspace. Hence the group O(3,2) acts on the Lie quadric. These transformations of cycles are called \"Lie transformations\". They preserve the incidence relation between cycles. The action is transitive and so all cycles are Lie equivalent. In particular, points are not preserved by general Lie transformations. The subgroup of Lie transformations preserving the point cycles is essentially the subgroup of orthogonal transformations which preserve the chosen timelike direction. This subgroup is isomorphic to the group O(3,1) of Möbius transformations of the sphere. It can also be characterized as the centralizer of the involution \"ρ\", which is itself a Lie transformation.\n\nLie transformations can often be used to simplify a geometrical problem, by transforming circles into lines or points.\n\nThe fact that Lie transformations do not preserve points in general can also be a hindrance to understanding Lie sphere geometry. In particular, the notion of a curve is not Lie invariant. This difficulty can be mitigated by the observation that there is a Lie invariant notion of contact element.\n\nAn oriented contact element in the plane is a pair consisting of a point and an oriented (i.e., directed) line through that point. The point and the line are incident cycles. The key observation is that the set of all cycles incident with both the point and the line is a Lie invariant object: in addition to the point and the line, it consists of all the circles which make oriented contact with the line at the given point. It is called a \"pencil of Lie cycles\", or simply a \"contact element\".\n\nNote that the cycles are all incident with each other as well. In terms of the Lie quadric, this means that a pencil of cycles is a (projective) line lying entirely on the Lie quadric, i.e., it is the projectivization of a totally null two dimensional subspace of R: the representative vectors for the cycles in the pencil are all orthogonal to each other.\n\nThe set of all lines on the Lie quadric is a 3-dimensional manifold called the space of contact elements \"Z\". The Lie transformations preserve the contact elements, and act transitively on \"Z\". For a given choice of point cycles (the points orthogonal to a chosen timelike vector v), every contact element contains a unique point. This defines a map from \"Z\" to the 2-sphere \"S\" whose fibres are circles. This map is not Lie invariant, as points are not Lie invariant.\n\nLet \"γ\":[\"a\",\"b\"] → R be an oriented curve. Then \"γ\" determines a map \"λ\" from the interval [\"a\",\"b\"] to \"Z\" by sending \"t\" to the contact element corresponding to the point \"γ\"(\"t\") and the oriented line tangent to the curve at that point (the line in the direction \"γ\" '(\"t\")). This map \"λ\" is called the \"contact lift\" of \"γ\".\n\nIn fact \"Z\" is a contact manifold, and the contact structure is Lie invariant. It follows that oriented curves can be studied in a Lie invariant way via their contact lifts, which may be characterized, generically as Legendrian curves in \"Z\". More precisely, the tangent space to \"Z\" at the point corresponding to a null 2-dimensional subspace \"π\" of R is the subspace of those linear maps (A mod \"π\"):\"π\" → R/\"π\" with\nand the contact distribution is the subspace Hom(\"π\",\"π\"/\"π\") of this tangent space in the space Hom(\"π\",R/\"π\") of linear maps.\n\nIt follows that an immersed Legendrian curve \"λ\" in \"Z\" has a preferred Lie cycle associated to each point on the curve: the derivative of the immersion at \"t\" is a 1-dimensional subspace of Hom(\"π\",\"π\"/\"π\") where \"π\"=\"λ\"(\"t\"); the kernel of any nonzero element of this subspace is a well defined 1-dimensional subspace of \"π\", i.e., a point on the Lie quadric.\n\nIn more familiar terms, if \"λ\" is the contact lift of a curve \"γ\" in the plane, then the preferred cycle at each point is the osculating circle. In other words, after taking contact lifts, much of the basic theory of curves in the plane is Lie invariant.\n\nLie sphere geometry in \"n\"-dimensions is obtained by replacing R (corresponding to the Lie quadric in \"n\" = 2 dimensions) by R. This is R equipped with the symmetric bilinear form\nThe Lie quadric \"Q\" is again defined as the set of [x] ∈ RP = P(R) with x · x = 0. The quadric parameterizes oriented (\"n\" – 1)-spheres in \"n\"-dimensional space, including hyperplanes and point spheres as limiting cases. Note that \"Q\" is an (n + 1)-dimensional manifold (spheres are parameterized by their center and radius).\n\nThe incidence relation carries over without change: the spheres corresponding to points [x], [y] ∈ \"Q\" have oriented first order contact if and only if x · y = 0. The group of Lie transformations is now O(n + 1, 2) and the Lie transformations preserve incidence of Lie cycles.\n\nThe space of contact elements is a (2\"n\" – 1)-dimensional contact manifold \"Z\": in terms of the given choice of point spheres, these contact elements correspond to pairs consisting of a point in \"n\"-dimensional space (which may be the point at infinity) together with an oriented hyperplane passing through that point. The space \"Z\" is therefore isomorphic to the projectivized cotangent bundle of the \"n\"-sphere. This identification is not invariant under Lie transformations: in Lie invariant terms, \"Z\" is the space of (projective) lines on the Lie quadric.\n\nAny immersed oriented hypersurface in \"n\"-dimensional space has a contact lift to \"Z\" determined by its oriented tangent spaces. There is no longer a preferred Lie cycle associated to each point: instead, there are \"n\" – 1 such cycles, corresponding to the curvature spheres in Euclidean geometry.\n\nThe problem of Apollonius has a natural generalization involving \"n\" + 1 hyperspheres in \"n\" dimensions.\n\nIn the case \"n\"=3, the quadric \"Q\" in P(R) describes the (Lie) geometry of spheres in Euclidean 3-space. Lie noticed a remarkable similarity with the Klein correspondence for lines in 3-dimensional space (more precisely in RP).\n\nSuppose [x], [y] ∈ RP, with homogeneous coordinates (\"x\",\"x\",\"x\",\"x\") and (\"y\",\"y\",\"y\",\"y\"). Put \"p\" = \"x\"\"y\" - \"x\"\"y\". These are the homogeneous coordinates of the projective line joining \"x\" and \"y\". There are six independent coordinates and they satisfy a single relation, the Plücker relation\nIt follows that there is a one-to-one correspondence between lines in RP and points on the Klein quadric, which is the quadric hypersurface of points [\"p\", \"p\", \"p\", \"p\", \"p\", \"p\"] in RP satisfying the Plücker relation.\n\nThe quadratic form defining the Plücker relation comes from a symmetric bilinear form of signature (3,3). In other words, the space of lines in RP is the quadric in P(R). Although this is not the same as the Lie quadric, a \"correspondence\" can be defined between lines and spheres using the complex numbers: if x = (\"x\",\"x\",\"x\",\"x\",\"x\",\"x\") is a point on the (complexified) Lie quadric (i.e., the \"x\" are taken to be complex numbers), then\ndefines a point on the complexified Klein quadric (where i = –1).\n\nLie sphere geometry provides a natural description of Dupin cyclides. These are characterized as the common envelope of two one parameter families of spheres \"S\"(\"s\") and \"T\"(\"t\"), where \"S\" and \"T\" are maps from intervals into the Lie quadric. In order for a common envelope to exist, \"S\"(\"s\") and \"T\"(\"t\") must be incident for all \"s\" and \"t\", i.e., their representative vectors must span a null 2-dimensional subspace of R. Hence they define a map into the space of contact elements Z. This map is Legendrian if and only if the derivatives of \"S\" (or \"T\") are orthogonal to \"T\" (or \"S\"), i.e., if and only if there is an orthogonal decomposition of R into a direct sum of 3-dimensional subspaces \"σ\" and \"τ\" of signature (2,1), such that \"S\" takes values in \"σ\" and \"T\" takes values in \"τ\". Conversely such a decomposition uniquely determines a contact lift of a surface which envelops two one parameter families of spheres; the image of this contact lift is given by the null 2-dimensional subspaces which intersect \"σ\" and \"τ\" in a pair of null lines.\n\nSuch a decomposition is equivalently given, up to a sign choice, by a symmetric endomorphism of R whose square is the identity and whose ±1 eigenspaces are \"σ\" and \"τ\". Using the inner product on R, this is determined by a quadratic form on R.\n\nTo summarize, Dupin cyclides are determined by quadratic forms on R such that the associated symmetric endomorphism has square equal to the identity and eigenspaces of signature (2,1).\n\nThis provides one way to see that Dupin cyclides are cyclides, in the sense that they are zero-sets of quartics of a particular form. For this, note that as in the planar case, 3-dimensional Euclidean space embeds into the Lie quadric \"Q\" as the set of point spheres apart from the ideal point at infinity. Explicitly, the point (x,y,z) in Euclidean space corresponds to the point\nin \"Q\". A cyclide consists of the points [0,\"x\",\"x\",\"x\",\"x\",\"x\"] ∈ \"Q\" which satisfy an additional quadratic relation\nfor some symmetric 5 ×; 5 matrix \"A\" = (\"a\"). The class of cyclides is a natural family of surfaces in Lie sphere geometry, and the Dupin cyclides form a natural subfamily.\n\n\n\n"}
{"id": "468884", "url": "https://en.wikipedia.org/wiki?curid=468884", "title": "List of curves", "text": "List of curves\n\nThis is a list of curves, by Wikipedia page.\n\n\n\n\n\n\n\n\n\n\n\n\n\nsee also List of fractals by Hausdorff dimension\n\n\n\n\"Economics\"\n\n\"Other\"\n\n"}
{"id": "350829", "url": "https://en.wikipedia.org/wiki?curid=350829", "title": "List of dynamical systems and differential equations topics", "text": "List of dynamical systems and differential equations topics\n\nThis is a list of dynamical system and differential equation topics, by Wikipedia page. See also list of partial differential equation topics, list of equations.\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "1978752", "url": "https://en.wikipedia.org/wiki?curid=1978752", "title": "Logic in China", "text": "Logic in China\n\nFormal logic in China has a special place in the history of logic due to its repression and abandonment—in contrast to the strong ancient adoption and continued development of the study of logic in Europe, India, and the Islamic world.\n\nIn China, a contemporary of Confucius, Mozi, \"Master Mo\", is credited with founding the Mohist school,\nwhose canons dealt with issues relating to valid inference and the conditions of correct conclusions. However, they were nonproductive and not integrated into Chinese science or mathematics.\n\nThe Mohist school of Chinese philosophy contained an approach to logic and argumentation that stresses rhetorical analogies over mathematical reasoning, and is based on the \"three fa\", or methods of drawing distinctions between kinds of things.\n\nOne of the schools that grew out of Mohism, the Logicians, are credited by some scholars for their early investigation of formal logic.\n\nDuring the subsequent Qin Dynasty, the rule of Legalism repressed this Mohist line of investigation, which has been said to have disappeared in China until the introduction of Indian philosophy and Indian logic by Buddhists. A prominent scholar suggests that the version assembled for the Imperial Library of the Han Dynasty would probably have been as disorganised as the current extant text, and thus would have only been 'intermittently intelligible', as it is for current readers who do not consult a critical edition. Disagreeing with Hajime Nakamura, Graham argues the school of Neo-Taoism maintained some interest in the Canons, although they may already have some of the terminology difficult to understand. Before the end of the Sui Dynasty, a shortened version of Mozi appeared, which appears to have replaced the Han edition. Although the original Mozi had been preserved in the Taoist, and became known once more in the 1552 Lu edition and 1553 Tang edition, the damage was done: the dialectical chapters (as well as the military chapters) were considered incomprehensible. Nevertheless, with the rise of Chinese critical textual scholarship, the book benefited from explanatory and critical commentaries: first, by Bi Yuan, and his assistant, Sun Xingyan; another commentary by Wang Chong, which has not survived; 'the first special study', by Zhang Huiyan; a republication of Part B by Wu Rulun. However, the summit of this late Imperial scholarship, according to Graham, was the 'magnificent' commentary of Sun Yirang, which 'threw open the sanctum of the Canons to all comers. Graham summarises the arduous textual history of the Canons by arguing that the Canons were neglected throughout most of China's history; but he attributes this fact to 'bibliographical' accidents, rather than political repression, like Nakamura.\n\nThe study of logic in China was revived following the transmission of Buddhism in China, which introduced the Buddhist logical tradition that began in Indian logic. Buddhist logic has been often misunderstood by scholars of Chinese Buddhism because they lack the necessary background in Indian logic.\n\n\n"}
{"id": "31548264", "url": "https://en.wikipedia.org/wiki?curid=31548264", "title": "Lot quality assurance sampling", "text": "Lot quality assurance sampling\n\nLot quality assurance sampling (LQAS) is a random sampling methodology, originally developed in the 1920s as a method of quality control in industrial production. Compared to similar sampling techniques like stratified and cluster sampling, LQAS provides less information but often requires substantially smaller sample sizes.\n\nLQAS, sometimes called \"acceptance sampling\", involves taking a small random sample from each set of items in the population, and testing each sampled item to determine whether it meets a predetermined standard of quality. LQAS is functionally identical to stratified sampling (where each lot is a single stratum), but requires smaller samples because it does not attempt to construct a precise estimate of population parameters. Instead, after sampling, a researcher using LQAS performs a hypothesis test to determine whether the number of elements of interest in each lot (e.g. defective units in manufacturing, or persons with a particular medical condition in epidemiology) is likely to be greater than a predetermined threshold.\n\nLQAS was originally designed for use in manufacturing, where it provided a way to perform statistically valid quality-assurance testing at minimum cost. In the context of modern research, LQAS has become an accepted sampling method in the fields of public health and international development. For example, in 1996 the World Health Organization issued a document describing LQAS, and recommended it for use in surveys to determine the number of children immunized against disease.\n\n"}
{"id": "232840", "url": "https://en.wikipedia.org/wiki?curid=232840", "title": "Mathematics of paper folding", "text": "Mathematics of paper folding\n\nThe art of origami or paper folding has received a considerable amount of mathematical study. Fields of interest include a given paper model's flat-foldability (whether the model can be flattened without damaging it) and the use of paper folds to solve mathematical equations.\n\nIn 1893, Indian mathematician T. Sundara Rao published \"Geometric Exercises in Paper Folding\" which used paper folding to demonstrate proofs of geometrical constructions. This work was inspired by the use of origami in the kindergarten system. This book had an approximate trisection of angles and implied construction of a cube root was impossible. In 1936 Margharita P. Beloch showed that use of the 'Beloch fold', later used in the sixth of the Huzita–Hatori axioms, allowed the general cubic equation to be solved using origami. In 1949, R C Yeates' book \"Geometric Methods\" described three allowed constructions corresponding to the first, second, and fifth of the Huzita–Hatori axioms. The axioms were discovered by Jacques Justin in 1989. but were overlooked until the first six were rediscovered by Humiaki Huzita in 1991. The first International Meeting of Origami Science and Technology (now known as the International Conference on Origami in Science, Math, and Education) was held in 1989 in Ferrara, Italy.\n\nThe construction of origami models is sometimes shown as crease patterns. The major question about such crease patterns is whether a given crease pattern can be folded to a flat model, and if so, how to fold them; this is an NP-complete problem. Related problems when the creases are orthogonal are called map folding problems. There are three mathematical rules for producing flat-foldable origami crease patterns:\n\n\nPaper exhibits zero Gaussian curvature at all points on its surface, and only folds naturally along lines of zero curvature. Curved surfaces that can't be flattened can be produced using a non-folded crease in the paper, as is easily done with wet paper or a fingernail.\n\nAssigning a crease pattern mountain and valley folds in order to produce a flat model has been proven by Marshall Bern and Barry Hayes to be NP-complete. Further references and technical results are discussed in Part II of \"Geometric Folding Algorithms\".\n\nSome classical construction problems of geometry — namely trisecting an arbitrary angle or doubling the cube — are proven to be unsolvable using compass and straightedge, but can be solved using only a few paper folds. Paper fold strips can be constructed to solve equations up to degree 4. The Huzita–Hatori axioms are an important contribution to this field of study. These describe what can be constructed using a sequence of creases with at most two point or line alignments at once. Complete methods for solving all equations up to degree 4 by applying methods satisfying these axioms are discussed in detail in \"Geometric Origami\".\n\nAs a result of origami study through the application of geometric principles, methods such as Haga's theorem have allowed paperfolders to accurately fold the side of a square into thirds, fifths, sevenths, and ninths. Other theorems and methods have allowed paperfolders to get other shapes from a square, such as equilateral triangles, pentagons, hexagons, and special rectangles such as the golden rectangle and the silver rectangle. Methods for folding most regular polygons up to and including the regular 19-gon have been developed. A regular \"n\"-gon can be constructed by paper folding if and only if formula_1(\"n\") is 3-smooth, where formula_1 is Euler's totient function.\n\nThe side of a square can be divided at an arbitrary rational fraction in a variety of ways. Haga's theorems say that a particular set of constructions can be used for such divisions. Surprisingly few folds are necessary to generate large odd fractions. For instance can be generated with three folds; first halve a side, then use Haga's theorem twice to produce first and then .\n\nThe accompanying diagram shows Haga's first theorem:\n\nThe function changing the length \"AP\" to \"QC\" is self inverse. Let \"x\" be \"AP\" then a number of other lengths are also rational functions of \"x\". For example:\n\nThe classical problem of doubling the cube can be solved using origami. This construction is due to Peter Messer: A square of paper is first creased into three equal strips as shown in the diagram. Then the bottom edge is positioned so the corner point P is on the top edge and the crease mark on the edge meets the other crease mark Q. The length PB will then be the cube root of 2 times the length of AP.\n\nThe edge with the crease mark is considered a marked straightedge, something which is not allowed in compass and straightedge constructions. Using a marked straightedge in this way is called a neusis construction in geometry.\n\nAngle trisection is another of the classical problems that cannot be solved using a compass and unmarked ruler but can be solved using origami. This construction is due to Hisashi Abe. The angle CAB is trisected by making folds PP' and QQ' parallel to the base with QQ' halfway in between. Then point P is folded over to lie on line AC and at the same time point A is made to lie on line QQ' at A'. The angle A'AB is one third of the original angle CAB. This is because PAQ, A'AQ and A'AR are three congruent triangles. Aligning the two points on the two lines is another neusis construction as in the solution to doubling the cube.\n\nThe problem of rigid origami, treating the folds as hinges joining two flat, rigid surfaces, such as sheet metal, has great practical importance. For example, the Miura map fold is a rigid fold that has been used to deploy large solar panel arrays for space satellites.\n\nThe napkin folding problem is the problem of whether a square or rectangle of paper can be folded so the perimeter of the flat figure is greater than that of the original square.\n\nCurved origami also poses a (very different) set of mathematical challenges.\nCurved origami allows the paper to form developable surfaces that are not flat.\n\nWet-folding origami allows an even greater range of shapes.\n\nThe maximum number of times an incompressible material can be folded has been derived. With each fold a certain amount of paper is lost to potential folding. The loss function for folding paper in half in a single direction was given to be formula_4, where \"L\" is the minimum length of the paper (or other material), \"t\" is the material's thickness, and \"n\" is the number of folds possible. The distances \"L\" and \"t\" must be expressed in the same units, such as inches. This result was derived by Gallivan in 2001, who also folded a sheet of paper in half 12 times, contrary to the popular belief that paper of any size could be folded at most eight times. She also derived the equation for folding in alternate directions.\n\nThe fold-and-cut problem asks what shapes can be obtained by folding a piece of paper flat, and making a single straight complete cut. The solution, known as the fold-and-cut theorem, states that any shape with straight sides can be obtained.\n\nA practical problem is how to fold a map so that it may be manipulated with minimal effort or movements. The Miura fold is a solution to the problem, and several others have been proposed.\n\n\n\n"}
{"id": "28848438", "url": "https://en.wikipedia.org/wiki?curid=28848438", "title": "Mirsky's theorem", "text": "Mirsky's theorem\n\nIn mathematics, in the areas of order theory and combinatorics, Mirsky's theorem characterizes the height of any finite partially ordered set in terms of a partition of the order into a minimum number of antichains. It is named for and is closely related to Dilworth's theorem on the widths of partial orders, to the perfection of comparability graphs, to the Gallai–Hasse–Roy–Vitaver theorem relating longest paths and colorings in graphs, and to the Erdős–Szekeres theorem on monotonic subsequences.\n\nThe height of a partially ordered set is defined to be the maximum cardinality of a chain, a totally ordered subset of the given partial order. For instance, in the set of positive integers from 1 to \"N\", ordered by divisibility, one of the largest chains consists of the powers of two that lie within that range, from which it follows that the height of this partial order is formula_1.\n\nMirsky's theorem states that, for every finite partially ordered set, the height also equals the minimum number of antichains (subsets in which no pair of elements are ordered) into which the set may be partitioned. In such a partition, every two elements of the longest chain must go into two different antichains, so the number of antichains is always greater than or equal to the height; another formulation of Mirsky's theorem is that there always exists a partition for which the number of antichains equals the height. Again, in the example of positive integers ordered by divisibility, the numbers can be partitioned into the antichains {1}, {2,3}, {4,5,6,7}, etc. There are formula_1 sets in this partition, and within each of these sets, every pair of numbers forms a ratio less than two, so no two numbers within one of these sets can be divisible.\n\nTo prove the existence of a partition into a small number of antichains for an arbitrary finite partially ordered set, consider for every element \"x\" the chains that have \"x\" as their largest element, and let \"N\"(\"x\") denote the size of the largest of these \"x\"-maximal chains. Then each set \"N\"(\"i\"), consisting of elements that have equal values of \"N\", is an antichain, and these antichains partition the partial order into a number of antichains equal to the size of the largest chain. In his original proof, Mirsky constructs the same partition inductively, by choosing an antichain of the maximal elements of longest chains, and showing that the length of the longest chain among the remaining elements is reduced by one.\n\nMirsky was inspired by Dilworth's theorem, stating that, for every partially ordered set, the maximum size of an antichain equals the minimum number of chains in a partition of the set into chains. For sets of order dimension two, the two theorems coincide (a chain in the majorization ordering of points in general position in the plane is an antichain in the set of points formed by a 90° rotation from the original set, and vice versa) but for more general partial orders the two theorems differ, and (as Mirsky observes) Dilworth's theorem is more difficult to prove.\n\nMirsky's theorem and Dilworth's theorem are also related to each other through the theory of perfect graphs. An undirected graph is perfect if, in every induced subgraph, the chromatic number equals the size of the largest clique. In the comparability graph of a partially ordered set, a clique represents a chain and a coloring represents a partition into antichains, and induced subgraphs of comparability graphs are themselves comparability graphs, so Mirsky's theorem states that comparability graphs are perfect. Analogously, Dilworth's theorem states that every complement graph of a comparability graph is perfect. The perfect graph theorem of states that the complements of perfect graphs are always perfect, and can be used to deduce Dilworth's theorem from Mirsky's theorem and vice versa .\n\nMirsky's theorem can be restated in terms of directed acyclic graphs (representing a partially ordered set by reachability of their vertices), as the statement that there exists a graph homomorphism from a given directed acyclic graph \"G\" to a \"k\"-vertex transitive tournament if and only if there does not exist a homomorphism from a (\"k\" + 1)-vertex path graph to \"G\". For, the largest path graph that has a homomorphism to \"G\" gives the longest chain in the reachability ordering, and the sets of vertices with the same image in a homomorphism to a transitive tournament form a partition into antichains. This statement generalizes to the case that \"G\" is not acyclic, and is a form of the Gallai–Hasse–Roy–Vitaver theorem on graph colorings and orientations .\n\nIt follows from either Dilworth's theorem or Mirsky's theorem that, in every partially ordered set of \"rs\" + 1 elements, there must exist either a chain of \"r\" + 1 elements or an antichain of \"s\" + 1 elements. uses this observation, applied to a partial order of order dimension two, to prove the Erdős–Szekeres theorem that in every sequence of \"rs\" + 1 totally ordered elements there must exist either a monotonically increasing subsequence of \"r\" + 1 elements or a monotonically decreasing subsequence of \"s\" + 1 elements.\n\nMirsky's theorem extends immediately to infinite partially ordered sets with finite height. However, the relation between the length of a chain and the number of antichains in a partition into antichains does not extend to infinite cardinalities: for every infinite cardinal number κ, there exist partially ordered sets that have no infinite chain and that do not have an antichain partition with κ or fewer antichains .\n\n"}
{"id": "42138577", "url": "https://en.wikipedia.org/wiki?curid=42138577", "title": "Nilpotent space", "text": "Nilpotent space\n\nIn topology, a branch of mathematics, a nilpotent space, first defined by E.Dror (1969), is a based topological space \"X\" such that\n\nSimply connected spaces and simple spaces are (trivial) examples of nilpotent spaces, other examples are connected loop spaces. The homotopy fibre of \nany map between nilpotent spaces is a disjoint union of nilpotent spaces, the null component of the pointed mapping space Map_*(\"K\",\"X\") where \"K\" is a pointed finite dimensional CW complex and \"X\" is any pointed space, is a nilpotent space. The odd-dimensional real projective spaces are nilpotent spaces, while the projective plane is not. A basic theorem about nilpotent spaces states that any map that induces an integral homology isomorphism between two nilpotent space is a weak homotopy equivalence. Nilpotent spaces are of great interest in rational homotopy theory, because most constructions applicable to simply connected spaces can be extended to nilpotent spaces. The Bousfield Kan nilpotent completion of a space associates with any connected pointed space \"X\" a universal space \"X\"^ through which any map of \"X\" to a nilpotent space \"N\" factors uniquely up to contractible space of choices, often however, \"X\"^ itself is not nilpotent but only an inverse limit of a tower of nilpotent spaces. This tower, as a pro-space, always models the homology type of the given pointed space \"X\". Nilpotent spaces admit a good arithmetic localization theory in the sense of Bousfield and Kan cited above, and the unstable Adams spectral sequence strongly converges \nfor any such space. \n\nLet \"X\" be a nilpotent space and let \"h\" be a reduced generalized homology theory, such as K-theory.\nIf \"h\"(\"X\")=0, then \"h\" vanishes on any Postnikov section of \"X\". This follows from a theorem that states that\nany such section is \"X\"-cellular.\n"}
{"id": "333677", "url": "https://en.wikipedia.org/wiki?curid=333677", "title": "Nowhere continuous function", "text": "Nowhere continuous function\n\nIn mathematics, a nowhere continuous function, also called an everywhere discontinuous function, is a function that is not continuous at any point of its domain. If \"f\" is a function from real numbers to real numbers, then \"f\" is nowhere continuous if for each point \"x\" there is an such that for each we can find a point \"y\" such that and . Therefore, no matter how close we get to any fixed point, there are even closer points at which the function takes not-nearby values.\n\nMore general definitions of this kind of function can be obtained, by replacing the absolute value by the distance function in a metric space, or by using the definition of continuity in a topological space.\n\nOne example of such a function is the indicator function of the rational numbers, also known as the Dirichlet function, named after German mathematician Peter Gustav Lejeune Dirichlet. This function is denoted as \"I\" and has domain and codomain both equal to the real numbers. \"I\"(\"x\") equals 1 if \"x\" is a rational number and 0 if \"x\" is not rational. If we look at this function in the vicinity of some number \"y\", there are two cases: \nIn less rigorous terms, between any two irrationals, there is a rational, and vice versa.\n\nThe Dirichlet function can be constructed as the double pointwise limit of a sequence of continuous functions, as follows:\n\nfor integer \"j\" and \"k\".\n\nThis shows that the Dirichlet function is a Baire class 2 function. It cannot be a Baire class 1 function because a Baire class 1 function can only be discontinuous on a meagre set.\n\nIn general, if \"E\" is any subset of a topological space \"X\" such that both \"E\" and the complement of \"E\" are dense in \"X\", then the real-valued function which takes the value 1 on \"E\" and 0 on the complement of \"E\" will be nowhere continuous. Functions of this type were originally investigated by Peter Gustav Lejeune Dirichlet.\n\nA real function \"f\" is nowhere continuous if its natural hyperreal extension has the property that every \"x\" is infinitely close to a \"y\" such that the difference is appreciable (i.e., not infinitesimal).\n\n\n"}
{"id": "56059964", "url": "https://en.wikipedia.org/wiki?curid=56059964", "title": "Opetope", "text": "Opetope\n\nIn category theory, a branch of mathematics, an opetope, a portmanteau of \"operation\" and \"polytope\", is a shape that captures higher-dimensional substitutions. It was introduced by John C. Baez and James Dolan so that they could define a weak \"n\"-category as a certain presheaf on the category of opetopes.\n\n\n\n"}
{"id": "318598", "url": "https://en.wikipedia.org/wiki?curid=318598", "title": "Paul Halmos", "text": "Paul Halmos\n\nPaul Richard Halmos (; March 3, 1916 – October 2, 2006) was a Hungarian-Jewish-born American mathematician who made fundamental advances in the areas of mathematical logic, probability theory, statistics, operator theory, ergodic theory, and functional analysis (in particular, Hilbert spaces). He was also recognized as a great mathematical expositor. According to György Marx, Halmos was one of The Martians.\n\nHalmos arrived in the U.S. at 13 years of age. He obtained his B.A. from the University of Illinois, majoring in mathematics, but fulfilling the requirements for both a math and philosophy degree. He took only three years to obtain the degree, and was only 19 when he graduated. He then began a Ph.D. in philosophy, still at the Champaign-Urbana campus; but, after failing his masters' oral exams, he shifted to mathematics, graduating in 1938. Joseph L. Doob supervised his dissertation, titled \"Invariants of Certain Stochastic Transformations: The Mathematical Theory of Gambling Systems\".\n\nShortly after his graduation, Halmos left for the Institute for Advanced Study, lacking both job and grant money. Six months later, he was working under John von Neumann, which proved a decisive experience. While at the Institute, Halmos wrote his first book, \"Finite Dimensional Vector Spaces\", which immediately established his reputation as a fine expositor of mathematics.\n\nHalmos taught at Syracuse University, the University of Chicago (1946–60), the University of Michigan (~1961–67), the University of California at Santa Barbara (1976–78), the University of Hawaii, and Indiana University. From his 1985 retirement from Indiana until his death, he was affiliated with the Mathematics department at Santa Clara University.\n\nIn a series of papers reprinted in his 1962 \"Algebraic Logic\", Halmos devised polyadic algebras, an algebraic version of first-order logic differing from the better known cylindric algebras of Alfred Tarski and his students. An elementary version of polyadic algebra is described in monadic Boolean algebra.\n\nIn addition to his original contributions to mathematics, Halmos was an unusually clear and engaging expositor of university mathematics. He won the Lester R. Ford Award in 1971 and again in 1977 (shared with W. P. Ziemer, W. H. Wheeler, S. H. Moolgavkar, J. H. Ewing and W. H. Gustafson). Halmos chaired the American Mathematical Society committee that wrote the AMS style guide for academic mathematics, published in 1973. In 1983, he received the AMS's Steele Prize for exposition.\n\nIn the \"American Scientist\" 56(4): 375–389, Halmos argued that mathematics is a creative art, and that mathematicians should be seen as artists, not number crunchers. He discussed the division of the field into mathology and mathophysics, further arguing that mathematicians and painters think and work in related ways.\n\nHalmos's 1985 \"automathography\" \"I Want to Be a Mathematician\" is an account of what it was like to be an academic mathematician in 20th century America. He called the book \"automathography\" rather than \"autobiography\", because its focus is almost entirely on his life as a mathematician, not his personal life. The book contains the following quote on Halmos' view of what doing mathematics means:\n\nIn these memoirs, Halmos claims to have invented the \"iff\" notation for the words \"if and only if\" and to have been the first to use the \"tombstone\" notation to signify the end of a proof, and this is generally agreed to be the case. The tombstone symbol ∎ (Unicode U+220E) is sometimes called a \"halmos\".\n\nIn 2005, Halmos and his wife Virginia funded the Euler Book Prize, an annual award given by the Mathematical Association of America for a book that is likely to improve the view of mathematics among the public. The first prize was given in 2007, the 300th anniversary of Leonhard Euler's birth, to John Derbyshire for his book about Bernhard Riemann and the Riemann hypothesis: Prime Obsession.\n\n\n\n\n"}
{"id": "42905501", "url": "https://en.wikipedia.org/wiki?curid=42905501", "title": "Polyhedral terrain", "text": "Polyhedral terrain\n\nIn computational geometry, a polyhedral terrain in three-dimensional Euclidean space is a polyhedral surface that intersects every line parallel to some particular line in a connected set (i.e., a point or a line segment) or the empty set. Without loss of generality, we may assume that the line in question is the \"z\"-axis of the Cartesian coordinate system. Then a polyhedral terrain is the image of a piecewise-linear function in \"x\" and \"y\" variables.\n\nThe polyhedral terrain is a generalization of the two-dimensional geometric object, the monotone polygonal chain.\n\nAs the name may suggest, a major application area of polyhedral terrains include geographic information systems to model real-world terrains.\n\nA polyhedral model may be represented in terms of the partition of the plane into polygonal regions, each region being associated with a plane patch which is the image of points of the region under the piecewise-linear function in question.\n\nThere are a number of problems in computational geometry which involve polyhedral terrains.\n"}
{"id": "4401265", "url": "https://en.wikipedia.org/wiki?curid=4401265", "title": "Principal type", "text": "Principal type\n\nIn type theory, a type system is said to have the principal type property if, given a term and an environment, there exists a principal type for this term in this environment, i.e. a type such that all other types for this term in this environment are an instance of the principal type.\n\nThe principal type property is a desirable one for a type system, as it provides a way to type expressions in a given environment with a type which encompasses all of the expressions' possible types, instead of having several incomparable possible types. Type inference for systems with the principal type property will usually attempt to infer the principal type.\n\nFor instance, the ML system has the principal type property and principal types for an expression can be computed by Robinson's unification algorithm, which is used by the Hindley–Milner type inference algorithm. However, many extensions to the type system of ML, such as polymorphic recursion, can make the inference of the principal type undecidable. Other extensions, such as Haskell's generalized algebraic data types, destroy the principal type property of the language, requiring the use of type annotations or the compiler to \"guess\" the intended type from among several options.\n\nThe principal type property should not be confused with the principal typing property which requires that, given a term, there exist a typing (i.e. a pair with a context and a type) which is an instance of all possible typings of the term.\n"}
{"id": "618119", "url": "https://en.wikipedia.org/wiki?curid=618119", "title": "Provability logic", "text": "Provability logic\n\nProvability logic is a modal logic, in which the box (or \"necessity\") operator is interpreted as 'it is provable that'. The point is to capture the notion of a proof predicate of a reasonably rich formal theory, such as Peano arithmetic. \n\nThere are a number of provability logics, some of which are covered in the literature mentioned in the References section. The basic system is generally referred to as GL (for Gödel-Löb) or L or K4W. It can be obtained by adding the modal version of Löb's theorem to the logic K (or K4). \n\nNamely, the axioms of GL are all tautologies of classical propositional logic plus all formulas of one of the following forms: \nAnd the rules of inference are:\n\nThe GL model was pioneered by Robert M. Solovay in 1976. Since then, until his death in 1996, the prime inspirer of the field was George Boolos. Significant contributions to the field have been made by Sergei N. Artemov, Lev Beklemishev, Giorgi Japaridze, Dick de Jongh, Franco Montagna, Giovanni Sambin, Vladimir Shavrukov, Albert Visser and others.\n\nInterpretability logics and Japaridze's polymodal logic present natural extensions of provability logic.\n\n\n"}
{"id": "32592462", "url": "https://en.wikipedia.org/wiki?curid=32592462", "title": "Series multisection", "text": "Series multisection\n\nIn mathematics, a multisection of a power series is a new power series composed of equally spaced terms extracted unaltered from the original series. Formally, if one is given a power series\n\nthen its multisection is a power series of the form\n\nwhere \"p\", \"q\" are integers, with 0 ≤ \"p\" < \"q\".\n\nA multisection of the series of an analytic function\n\nhas a closed-form expression in terms of the function formula_4:\n\nwhere formula_6 is a primitive \"q\"-th root of unity. This solution was first discovered by Thomas Simpson. This expression is especially useful in that it can convert an infinite sum into a finite sum. It is used, for example, in a key step of a standard proof of Gauss's digamma theorem, which gives a closed-form solution to the digamma function evaluated at rational values \"p\"/\"q\".\n\nIn general, the bisections of a series are the even and odd parts of the series.\n\nConsider the geometric series\n\nBy setting formula_8 in the above series, its multisections are easily seen to be\n\nRemembering that the sum of the multisections must equal the original series, we recover the familiar identity\n\nThe exponential function\n\nby means of the above formula for analytic functions separates into\n\nThe bisections are trivially the hyperbolic functions:\n\nHigher order multisections are found by noting that all such series must be real-valued along the real line. By taking the real part and using standard trigonometric identities, the formulas may be written in explicitly real form as\n\nThese can be seen as solutions to the linear differential equation formula_16 with boundary conditions formula_17, using Kronecker delta notation. In particular, the trisections are\n\nand the quadrusections are\n\nMultisection of a binomial expansion\n\nat \"x\" = 1 gives the following identity for the sum of binomial coefficients with step \"q\":\n\n"}
{"id": "21581860", "url": "https://en.wikipedia.org/wiki?curid=21581860", "title": "Shanks transformation", "text": "Shanks transformation\n\nIn numerical analysis, the Shanks transformation is a non-linear series acceleration method to increase the rate of convergence of a sequence. This method is named after Daniel Shanks, who rediscovered this sequence transformation in 1955. It was first derived and published by R. Schmidt in 1941.\n\nFor a sequence formula_1 the series\n\nis to be determined. First, the partial sum formula_3 is defined as:\n\nand forms a new sequence formula_5. Provided the series converges, formula_3 will also approach the limit formula_7 as formula_8\nThe Shanks transformation formula_9 of the sequence formula_3 is the new sequence defined by\n\nwhere this sequence formula_9 often converges more rapidly than the sequence formula_13 \nFurther speed-up may be obtained by repeated use of the Shanks transformation, by computing formula_14 formula_15 etc.\n\nNote that the non-linear transformation as used in the Shanks transformation is essentially the same as used in Aitken's delta-squared process so that as with Aitken's method, the right-most expression in formula_9's definition (i.e. formula_17) is more numerically stable than the expression to its left (i.e. formula_18). Both Aitken's method and the Shanks transformation operate on a sequence, but the sequence the Shanks transformation operates on is usually thought of as being a sequence of partial sums, although any sequence may be viewed as a sequence of partial sums.\n\nAs an example, consider the slowly convergent series\n\nwhich has the exact sum \"π\" ≈ 3.14159265. The partial sum formula_20 has only one digit accuracy, while six-figure accuracy requires summing about 400,000 terms.\n\nIn the table below, the partial sums formula_3, the Shanks transformation formula_9 on them, as well as the repeated Shanks transformations formula_23 and formula_24 are given for formula_25 up to 12. The figure to the right shows the absolute error for the partial sums and Shanks transformation results, clearly showing the improved accuracy and convergence rate.\n\nThe Shanks transformation formula_26 already has two-digit accuracy, while the original partial sums only establish the same accuracy at formula_27 Remarkably, formula_28 has six digits accuracy, obtained from repeated Shank transformations applied to the first seven terms formula_29 As said before, formula_3 only obtains 6-digit accuracy after about summing 400,000 terms.\n\nThe Shanks transformation is motivated by the observation that — for larger formula_25 — the partial sum formula_3 quite often behaves approximately as\n\nwith formula_34 so that the sequence converges transiently to the series result formula_7 for formula_8\nSo for formula_37 formula_25 and formula_39 the respective partial sums are:\n\nThese three equations contain three unknowns: formula_41 formula_42 and formula_43 Solving for formula_7 gives\n\nIn the (exceptional) case that the denominator is equal to zero: then formula_46 for all formula_47\n\nThe generalized \"k\"th-order Shanks transformation is given as the ratio of the determinants:\nwith formula_49 It is the solution of a model for the convergence behaviour of the partial sums formula_3 with formula_51 distinct transients:\n\nThis model for the convergence behaviour contains formula_53 unknowns. By evaluating the above equation at the elements formula_54 and solving for formula_41 the above expression for the \"k\"th-order Shanks transformation is obtained. The first-order generalized Shanks transformation is equal to the ordinary Shanks transformation: formula_56\n\nThe generalized Shanks transformation is closely related to Padé approximants and Padé tables.\n\n\n"}
{"id": "36699980", "url": "https://en.wikipedia.org/wiki?curid=36699980", "title": "Sobolev spaces for planar domains", "text": "Sobolev spaces for planar domains\n\nIn mathematics, Sobolev spaces for planar domains are one of the principal techniques used in the theory of partial differential equations for solving the Dirichlet and Neumann boundary value problems for the Laplacian in a bounded domain in the plane with smooth boundary. The methods use the theory of bounded operators on Hilbert space. They can be used to deduce regularity properties of solutions and to solve the corresponding eigenvalue problems.\n\nLet be a bounded domain with smooth boundary. Since is contained in a large square in , it can be regarded as a domain in by identifying opposite sides of the square. The theory of Sobolev spaces on can be found in , an account which is followed in several later textbooks such as and .\n\nFor an integer, the (restricted) Sobolev space is defined as the closure of in the standard Sobolev space .\n\n\n\n\n\nThe operator defines an isomorphism between and . In fact it is a Fredholm operator of index . The kernel of in consists of constant functions and none of these except zero vanish on the boundary of . Hence the kernel of is and is invertible.\n\nIn particular the equation has a unique solution in for in .\n\nLet be the operator on defined by\n\nwhere is the inclusion of in and of in , both compact operators by Rellich's theorem. The operator is compact and self-adjoint with for all . By the spectral theorem, there is a complete orthonormal set of eigenfunctions in with\n\nSince , lies in . Setting , the are eigenfunctions of the Laplacian:\n\nTo determine the regularity properties of the eigenfunctions and solutions of\n\nenlargements of the Sobolev spaces have to be considered. Let be the space of smooth functions on which with their derivatives extend continuously to . By Borel's lemma, these are precisely the restrictions of smooth functions on . The Sobolev space is defined to the Hilbert space completion of this space for the norm\n\nThis norm agrees with the Sobolev norm on so that can be regarded as a closed subspace of . Unlike , is not naturally a subspace of , but the map restricting smooth functions from to is continuous for the Sobolev norm so extends by continuity to a map .\n\n\n\n\nIf with in and in with , then lies in .\n\nTake a decomposition with supported in and supported in a collar of the boundary. Standard Sobolev theory for can be applied to : elliptic regularity implies that it lies in and hence . lies in of a collar, diffeomorphic to an annulus, so it suffices to prove the result with a collar and replaced by\n\nThe proof proceeds by induction on , proving simultaneously the inequality\n\nfor some constant depending only on . It is straightforward to establish this inequality for , where by density can be taken to be smooth of compact support in :\n\nThe collar is diffeomorphic to an annulus. The rotational flow on the annulus induces a flow on the collar with corresponding vector field . Thus corresponds to the vector field . The radial vector field on the annulus is a commuting vector field which on the collar gives a vector field proportional to the normal vector field. The vector fields and commute.\n\nThe difference quotients can be formed for the flow . The commutators are second order differential operators from to . Their operators norms are uniformly bounded for near ; for the computation can be carried out on the annulus where the commutator just replaces the coefficients of by their difference quotients composed with . On the other hand, lies in , so the inequalities for apply equally well for :\n\nThe uniform boundedness of the difference quotients implies that lies in with\n\nIt follows that lies in where is the vector field\n\nMoreover, satisfies a similar inequality to .\n\nLet be the orthogonal vector field\n\nIt can also be written as for some smooth nowhere vanishing function on a neighbourhood of the collar.\n\nIt suffices to show that lies in . For then\n\nso that and lie in and must lie in .\n\nTo check the result on , it is enough to show that and lie in . Note that\n\nare vector fields. But then\n\nwith all terms on the right hand side in . Moreover, the inequalities for show that\n\nHence\n\nIt follows by induction from the regularity theorem for the dual Dirichlet problem that the eigenfunctions of in lie in . Moreover, any solution of with in and in must have in . In both cases by the vanishing properties, the eigenfunctions and vanish on the boundary of .\n\nThe dual Dirichlet problem can be used to solve the Dirichlet problem:\n\nBy Borel's lemma is the restriction of a function in . Let be the smooth solution of with on . Then solves the Dirichlet problem. By the maximal principle, the solution is unique.\n\nThe solution to the Dirichlet problem can be used to prove a strong form of the Riemann mapping theorem for simply connected domains with smooth boundary. The method also applies to a region diffeomorphic to an annulus. For multiply connected regions with smooth boundary have given a method for mapping the region onto a disc with circular holes. Their method involves solving the Dirichlet problem with a non-linear boundary condition. They construct a function such that:\n\n\nThe solution is given by\n\nwhere the integral is taken over any path in . It is easily verified that and exist and are given by the corresponding derivatives of . Thus is a smooth function on , vanishing at . By the Cauchy-Riemann is smooth on , holomorphic on and . The function is only defined up to multiples of , but the function\n\nis a holomorphic on and smooth on . By construction, and for . Since has winding number , so too does . On the other hand, only for where there is a simple zero. So by the argument principle assumes every value in the unit disc, , exactly once and does not vanish inside . To check that the derivative on the boundary curve is non-zero amounts to computing the derivative of , i.e. the derivative of should not vanish on the boundary curve. By the Cauchy-Riemann equations these tangential derivative are up to a sign the directional derivative in the direction of the normal to the boundary. But vanishes on the boundary and is strictly negative in since . The Hopf lemma implies that the directional derivative of in the direction of the outward normal is strictly positive. So on the boundary curve, has nowhere vanishing derivative. Since the boundary curve has winding number one, defines a diffeomorphism of the boundary curve onto the unit circle. Accordingly, is a smooth diffeomorphism, which restricts to a holomorphic map and a smooth diffeomorphism between the boundaries.\n\nSimilar arguments can be applied to prove the Riemann mapping theorem for a doubly connected domain bounded by simple smooth curves (the inner curve) and (the outer curve). By translating we can assume 1 lies on the outer boundary. Let be the smooth solution of the Dirichlet problem with on the outer curve and on the inner curve. By the maximum principle for in and so by the Hopf lemma the normal derivatives of are negative on the outer curve and positive on the inner curve. The integral of over the boundary is zero by Stoke's theorem so the contributions from the boundary curves cancel. On the other hand, on each boundary curve the contribution is the integral of the normal derivative along the boundary. So there is a constant such that satisfies\n\non each boundary curve. The harmonic conjugate of can again be defined by\n\nand is well-defined up to multiples of . The function\n\nis smooth on and holomorphic in . On the outer curve and on the inner curve . The tangential derivatives on the outer curves are nowhere vanishing by the Cauchy-Riemann equations, since the normal derivatives are nowhere vanishing. The normalization of the integrals implies that restricts to a diffeomorphism between the boundary curves and the two concentric circles. Since the images of outer and inner curve have winding number and about any point in the annulus, an application of the argument principle implies that assumes every value within the annulus exactly once; since that includes multiplicities, the complex derivative of is nowhere vanishing in . This is a smooth diffeomorphism of onto the closed annulus , restricting to a holomorphic map in the interior and a smooth diffeomorphism on both boundary curves.\n\nThe restriction map extends to a continuous map for . In fact \n\nso the Cauchy–Schwarz inequality yields\n\nwhere, by the integral test,\n\nThe map is onto since a continuous extension map can be constructed from to . In fact set\n\nwhere\n\nThus . If \"g\" is smooth, then by construction \"Eg\" restricts to \"g\" on 1 × T. Moreover, \"E\" is a bounded linear map since\n\nIt follows that there is a trace map τ of H(Ω) onto H(∂Ω). Indeed, take a tubular neighbourhood of the boundary and a smooth function ψ supported in the collar and equal to 1 near the boundary. Multiplication by ψ carries functions into H of the collar, which can be identified with H of an annulus for which there is a trace map. The invariance under diffeomorphims (or coordinate change) of the half-integer Sobolev spaces on the circle follows from the fact that an equivalent norm on \"H\"(T) is given by\n\nIt is also a consequence of the properties of τ and \"E\" (the \"trace theorem\"). In fact any diffeomorphism \"f\" of T induces a diffeomorphism \"F\" of T by acting only on the second factor. Invariance of H(T) under the induced map \"F\"* therefore implies invariance of H(T) under \"f\"*, since \"f\"* = τ ∘ \"F\"* ∘ \"E\".\n\nFurther consequences of the trace theorem are the two exact sequences\n\nand\n\nwhere the last map takes \"f\" in H(Ω) to \"f\"| and ∂\"f\"|. There are generalizations of these sequences to H(Ω) involving higher powers of the normal derivative in the trace map:\n\nThe trace map to takes \"f\" to \n\nThe Sobolev space approach to the Neumann problem cannot be phrased quite as directly as that for the Dirichlet problem. The main reason is that for a function in , the normal derivative cannot be a priori defined at the level of Sobolev spaces. Instead an alternative formulation of boundary value problems for the Laplacian on a bounded region in the plane is used. It employs Dirichlet forms, sesqulinear bilinear forms on , or an intermediate closed subspace. Integration over the boundary is not involved in defining the Dirichlet form. Instead, if the Dirichlet form satisfies a certain positivity condition, termed coerciveness, solution can be shown to exist in a weak sense, so-called \"weak solutions\". A general regularity theorem than implies that the solutions of the boundary value problem must lie in , so that they are strong solutions and satisfy boundary conditions involving the restriction of a function and its normal derivative to the boundary. The Dirichlet problem can equally well be phrased in these terms, but because the trace map is already defined on , Dirichlet forms do not need to be mentioned explicitly and the operator formulation is more direct. A unified discussion is given in and briefly summarised below. It is explained how the Dirichlet problem, as discussed above, fits into this framework. Then a detailed treatment of the Neumann problem from this point of view is given following .\n\nThe Hilbert space formulation of boundary value problems for the Laplacian on a bounded region in the plane proceeds from the following data:\n\n\nA weak solution of the boundary value problem given initial data in is a function \"u\" satisfying\n\nfor all \"g\". \n\nFor both the Dirichlet and Neumann problem\n\nFor the Dirichlet problem . In this case\n\nBy the trace theorem the solution satisfies in .\n\nFor the Neumann problem is taken to be .\n\nThe classical Neumann problem on consists in solving the boundary value problem\n\nGreen's theorem implies that for \n\nThus if in and satisfies the Neumann boundary conditions, , and so is constant in .\n\nHence the Neumann problem has a unique solution up to adding constants.\n\nConsider the Hermitian form on defined by\n\nSince is in duality with , there is a unique element in such that\n\nThe map is an isometry of onto , so in particular is bounded.\n\nIn fact\n\nSo\n\nOn the other hand, any in defines a bounded conjugate-linear form on sending to . By the Riesz–Fischer theorem, there exists such that\n\nHence and so is surjective. Define a bounded linear operator on by\n\nwhere is the map , a compact operator, and is the map , its adjoint, so also compact.\n\nThe operator has the following properties:\n\n\n\n\n\n\nThe first main regularity result shows that a weak solution expressed in terms of the operator and the Dirichlet form is a strong solution in the classical sense, expressed in terms of the Laplacian and the Neumann boundary conditions. Thus if with , then , satisfies and . Moreover, for some constant independent of ,\n\nNote that\n\nsince\n\nTake a decomposition with supported in and supported in a collar of the boundary.\n\nThe operator is characterized by\n\nThen\n\nso that\n\nThe function and are treated separately, being essentially subject to usual elliptic regularity considerations for interior points while requires special treatment near the boundary using difference quotients. Once the strong properties are established in terms of and the Neumann boundary conditions, the \"bootstrap\" regularity results can be proved exactly as for the Dirichlet problem.\n\nThe function lies in where is a region with closure in . If and \n\nBy continuity the same holds with replaced by and hence . So\n\nHence regarding as an element of , . Hence . Since for , we have . Moreover,\n\nso that\n\nThe function is supported in a collar contained in a tubular neighbourhood of the boundary. The difference quotients can be formed for the flow and lie in , so the first inequality is applicable:\n\nThe commutators are uniformly bounded as operators from to . This is equivalent to checking the inequality\n\nfor , smooth functions on a collar. This can be checked directly on an annulus, using invariance of Sobolev spaces under dffeomorphisms and the fact that for the annulus the commutator of with a differential operator is obtained by applying the difference operator to the coefficients after having applied to the function:\n\nHence the difference quotients are uniformly bounded, and therefore with\n\nHence and satisfies a similar inequality to :\n\nLet be the orthogonal vector field. As for the Dirichlet problem, to show that , it suffices to show that .\n\nTo check this, it is enough to show that . As before\n\nare vector fields. On the other hand, for , so that and define the same distribution on . Hence\n\nSince the terms on the right hand side are pairings with functions in , the regularity criterion shows that . Hence since both terms lie in and have the same inner products with 's.\n\nMoreover, the inequalities for show that\n\nHence\n\nIt follows that . Moreover,\n\nSince , Green's theorem is applicable by continuity. Thus for ,\n\nHence the Neumann boundary conditions are satisfied:\n\nwhere the left hand side is regarded as an element of and hence .\n\nThe main result here states that if and , then and\n\nfor some constant independent of .\n\nLike the corresponding result for the Dirichlet problem, this is proved by induction on . For , is also a weak solution of the Neumann problem so satisfies the estimate above for . The Neumann boundary condition can be written\n\nSince commutes with the vector field corresponding to the period flow , the inductive method of proof used for the Dirichlet problem works equally well in this case: for the difference quotients preserve the boundary condition when expressed in terms of .\n\nIt follows by induction from the regularity theorem for the Neumann problem that the eigenfunctions of in lie in . Moreover, any solution of with in and in must have in . In both cases by the vanishing properties, the normal derivatives of the eigenfunctions and vanish on .\n\nThe method above can be used to solve the associated Neumann boundary value problem:\n\nBy Borel's lemma is the restriction of a function . Let be a smooth function such that near the boundary. Let be the solution of with . Then solves the boundary value problem.\n\n"}
{"id": "473774", "url": "https://en.wikipedia.org/wiki?curid=473774", "title": "Transformation geometry", "text": "Transformation geometry\n\nIn mathematics, transformation geometry (or transformational geometry) is the name of a mathematical and pedagogic take on the study of geometry by focusing on groups of geometric transformations, and properties that are invariant under them. It is opposed to the classical synthetic geometry approach of Euclidean geometry, that focuses on proving theorems.\n\nFor example, within transformation geometry, the properties of an isosceles triangle are deduced from the fact that it is mapped to itself by a reflection about a certain line. This contrasts with the classical proofs by the criteria for congruence of triangles.\n\nThe first systematic effort to use transformations as the foundation of geometry was made by Felix Klein in the 19th century, under the name Erlangen programme. For nearly a century this approach remained confined to mathematics research circles. In the 20th century efforts were made to exploit it for mathematical education. Andrei Kolmogorov included this approach (together with set theory) as part of a proposal for geometry teaching reform in Russia. These efforts culminated in the 1960s with the general reform of mathematics teaching known as the New Math movement.\n\nAn exploration of transformation geometry often begins with a study of reflection symmetry as found in daily life. The first real transformation is \"reflection in a line\" or \"reflection against an axis\". The composition of two reflections results in a rotation when the lines intersect, or a translation when they are parallel. Thus through transformations students learn about Euclidean plane isometry. For instance, consider reflection in a vertical line and a line inclined at 45° to the horizontal. One can observe that one composition yields a counter-clockwise quarter-turn (90°) while the reverse composition yields a clockwise quarter-turn. Such results show that transformation geometry includes non-commutative processes.\n\nAn entertaining application of reflection in a line occurs in a proof of the one-seventh area triangle found in any triangle.\n\nAnother transformation introduced to young students is the dilation. However, the reflection in a circle transformation seems inappropriate for lower grades. Thus inversive geometry, a larger study than grade school transformation geometry, is usually reserved for college students.\n\nExperiments with concrete symmetry groups make way for abstract group theory. Other concrete activities use computations with complex numbers, hypercomplex numbers, or matrices to express transformation geometry.\nSuch transformation geometry lessons present an alternate view that contrasts with classical synthetic geometry. When students then encounter analytic geometry, the ideas of coordinate rotations and reflections follow easily. All these concepts prepare for linear algebra where the reflection concept is expanded.\n\nEducators have shown some interest and described projects and experiences with transformation geometry for children from kindergarten to high school. In the case of very young age children, in order to avoid introducing new terminology and to make links with students' everyday experience with concrete objects, it was sometimes recommended to use words they are familiar with, like \"flips\" for line reflections, \"slides\" for translations, and \"turns\" for rotations, although these are not precise mathematical language. In some proposals, students start by performing with concrete objects before they perform the abstract transformations via their definitions of a mapping of each point of the figure.\n\nIn an attempt to restructure the courses of geometry in Russia, Kolmogorov suggested presenting it under the point of view of transformations, so the geometry courses were structured based on set theory. This led to the appearance of the term \"congruent\" in schools, for figures that were before called \"equal\": since a figure was seen as a set of points, it could only be equal to itself, and two triangles that could be overlapped by isometries were said to be congruent.\n\nOne author expressed the importance of group theory to transformation geometry as follows:\n\n\n"}
{"id": "20768715", "url": "https://en.wikipedia.org/wiki?curid=20768715", "title": "True quantified Boolean formula", "text": "True quantified Boolean formula\n\nIn computational complexity theory, the language TQBF is a formal language consisting of the true quantified Boolean formulas. A (fully) quantified Boolean formula is a formula in quantified propositional logic where every variable is quantified (or bound), using either existential or universal quantifiers, at the beginning of the sentence. Such a formula is equivalent to either true or false (since there are no free variables). If such a formula evaluates to true, then that formula is in the language TQBF. It is also known as QSAT (Quantified SAT).\n\nIn computational complexity theory, the quantified Boolean formula problem (QBF) is a generalization of the Boolean satisfiability problem in which both existential quantifiers and universal quantifiers can be applied to each variable. Put another way, it asks whether a quantified sentential form over a set of Boolean variables is true or false. For example, the following is an instance of QBF:\n\nQBF is the canonical complete problem for PSPACE, the class of problems solvable by a deterministic or nondeterministic Turing machine in polynomial space and unlimited time. Given the formula in the form of an abstract syntax tree, the problem can be solved easily by a set of mutually recursive procedures which evaluate the formula. Such an algorithm uses space proportional to the height of the tree, which is linear in the worst case, but uses time exponential in the number of quantifiers.\n\nProvided that MA ⊊ PSPACE, which is widely believed, QBF cannot be solved, nor can a given solution even be verified, in either deterministic or probabilistic polynomial time (in fact, unlike the satisfiability problem, there's no known way to specify a solution succinctly). It can be solved using an alternating Turing machine in linear time, since AP = PSPACE, where AP is the class of problems alternating machines can solve in polynomial time.\n\nWhen the seminal result IP = PSPACE was shown (see interactive proof system), it was done by exhibiting an interactive proof system that could solve QBF by solving a particular arithmetization of the problem.\n\nQBF formulas have a number of useful canonical forms. For example, it can be shown that there is a polynomial-time many-one reduction that will move all quantifiers to the front of the formula and make them alternate between universal and existential quantifiers. There is another reduction that proved useful in the IP = PSPACE proof where no more than one universal quantifier is placed between each variable's use and the quantifier binding that variable. This was critical in limiting the number of products in certain subexpressions of the arithmetization.\n\nA fully quantified Boolean formula can be assumed to have a very specific form, called prenex normal form. It has two basic parts: a portion containing only quantifiers and a portion containing an unquantified Boolean formula usually denoted as formula_2. If there are formula_3 Boolean variables, the entire formula can be written as\n\nwhere every variable falls within the scope of some quantifier. By introducing dummy variables, any formula in prenex normal form can be converted into a sentence where existential and universal quantifiers alternate. Using the dummy variable formula_5,\n\nThe second sentence has the same truth value but follows the restricted syntax. Assuming fully quantified Boolean formulas to be in prenex normal form is a frequent feature of proofs.\n\nThere is a simple recursive algorithm for determining whether a QBF is in TQBF (i.e. is true). Given some QBF\n\nIf the formula contains no quantifiers, we can just return the formula. Otherwise, we take off the first quantifier and check both possible values for the first variable:\n\nIf formula_10, then return formula_11. If formula_12, then return formula_13.\n\nHow fast does this algorithm run?\nFor every quantifier in the initial QBF, the algorithm makes two recursive calls on only a linearly smaller subproblem. This gives the algorithm an exponential runtime O(2).\n\nHow much space does this algorithm use?\nWithin each invocation of the algorithm, it needs to store the intermediate results of computing A and B. Every recursive call takes off one quantifier, so the total recursive depth is linear in the number of quantifiers. Formulas that lack quantifiers can be evaluated in space logarithmic in the number of variables. The initial QBF was fully quantified, so there are at least as many quantifiers as variables. Thus, this algorithm uses \"O\"(\"n\" + log \"n\") = \"O\"(\"n\") space. This makes the TQBF language part of the PSPACE complexity class.\n\nThe TQBF language serves in complexity theory as the canonical PSPACE-complete problem. Being PSPACE-complete means that a language is in PSPACE and that the language is also PSPACE-hard. The algorithm above shows that TQBF is in PSPACE.\nShowing that TQBF is PSPACE-hard requires showing that any language in the complexity class PSPACE can be reduced to TQBF in polynomial time. I.e.,\n\nThis means that, for a PSPACE language L, whether an input is in L can be decided by checking whether formula_15 is in TQBF, for some function that is required to run in polynomial time (relative to the length of the input) Symbolically,\n\nProving that TQBF is PSPACE-hard, requires specification of .\n\nSo, suppose that L is a PSPACE language. This means that L can be decided by a polynomial space deterministic Turing machine (DTM). This is very important for the reduction of L to TQBF, because the configurations of any such Turing Machine can be represented as Boolean formulas, with Boolean variables representing the state of the machine as well as the contents of each cell on the Turing Machine tape, with the position of the Turing Machine head encoded in the formula by the formula's ordering. In particular, our reduction will use the variables formula_17 and formula_18, which represent two possible configurations of the DTM for L, and a natural number t, in constructing a QBF formula_19 which is true if and only if the DTM for L can go from the configuration encoded in formula_17 to the configuration encoded in formula_18 in no more than t steps. The function , then, will construct from the DTM for L a QBF formula_22, where formula_23 is the DTM's starting configuration, formula_24 is the DTM's accepting configuration, and T is the maximum number of steps the DTM could need to move from one configuration to the other. We know that \"T\" = \"O\"(exp(\"n\")), where n is the length of the input, because this bounds the total number of possible configurations of the relevant DTM. Of course, it cannot take the DTM more steps than there are possible configurations to reach formula_25 unless it enters a loop, in which case it will never reach formula_25 anyway.\n\nAt this stage of the proof, we have already reduced the question of whether an input formula (encoded, of course, in formula_23) is in L to the question of whether the QBF formula_22, i.e., formula_29, is in TQBF. The remainder of this proof proves that can be computed in polynomial time.\n\nFor formula_30, computation of formula_19 is straightforward—either one of the configurations changes to the other in one step or it does not. Since the Turing Machine that our formula represents is deterministic, this presents no problem.\n\nFor formula_32, computation of formula_19 involves a recursive evaluation, looking for a so-called \"middle point\" formula_34. In this case, we rewrite the formula as follows:\n\nThis converts the question of whether formula_17 can reach formula_18 in t steps to the question of whether formula_17 reaches a middle point formula_34 in formula_40 steps, which itself reaches formula_18 in formula_40 steps. The answer to the latter question of course gives the answer to the former.\n\nNow, t is only bounded by T, which is exponential (and so not polynomial) in the length of the input. Additionally, each recursive layer virtually doubles the length of the formula. (The variable formula_34 is only one midpoint—for greater t, there are more stops along the way, so to speak.) So the time required to recursively evaluate formula_19 in this manner could be exponential as well, simply because the formula could become exponentially large. This problem is solved by universally quantifying using variables formula_45 and formula_46 over the configuration pairs (e.g., formula_47), which prevents the length of the formula from expanding due to recursive layers. This yields the following interpretation of formula_19:\n\nThis version of the formula can indeed be computed in polynomial time, since any one instance of it can be computed in polynomial time. The universally quantified ordered pair simply tells us that whichever choice of formula_50 is made, formula_51.\n\nThus, formula_52, so TQBF is PSPACE-hard. Together with the above result that TQBF is in PSPACE, this completes the proof that TQBF is a PSPACE-complete language.\n\n\n\n\n\n\n"}
{"id": "46941716", "url": "https://en.wikipedia.org/wiki?curid=46941716", "title": "Vine copula", "text": "Vine copula\n\nA vine is a graphical tool for labeling constraints in high-dimensional probability distributions. A regular vine is a special case for which all constraints are two-dimensional or conditional two-dimensional. Regular vines generalize trees, and are themselves specializations of Cantor trees. Combined with bivariate copulas, regular vines have proven to be a flexible tool in high-dimensional dependence modeling. Copulas\n\nare multivariate distributions with uniform univariate margins. Representing a joint distribution as univariate margins plus copulas allows the separation of the problems of estimating univariate distributions from the problems of estimating dependence. This is handy in as much as univariate distributions in many cases can be adequately estimated from data, whereas dependence information is rough known, involving summary indicators and judgment.\nAlthough the number of parametric multivariate copula families with flexible dependence is limited, there are many parametric families of bivariate copulas. Regular vines owe their increasing popularity to the fact that they leverage from bivariate copulas and enable extensions to arbitrary dimensions. Sampling theory and estimation theory for regular vines are well developed\n\nand model inference has left the post\n. Regular vines have proven useful in other problems such as (constrained) sampling of correlation matrices, building non-parametric continuous Bayesian networks. \n\nIn finance, vine copulas have been shown to effectively model tail risk in portfolio optimization applications.\n\nThe first regular vine, avant la lettre, was introduced by Harry Joe.\nThe motive was to extend parametric bivariate extreme value copula families to higher dimensions. To this end he introduced what would later be called the \"D-vine\". Joe \n\nwas interested in a class of n-variate distributions with given one dimensional margins, and \"n\"(\"n\" − 1) dependence parameters, whereby \"n\" − 1 parameters correspond to bivariate margins, and the others correspond to conditional bivariate margins. In the case of multivariate normal distributions, the parameters would be \"n\" − 1 correlations and (\"n\" − 1)(\"n\" − 2)/2 partial correlations, which were noted to be algebraically independent in (−1, 1).\n\nAn entirely different motivation underlay the first formal definition of vines in Cooke.\nUncertainty analyses of large risk models, such as those undertaken for the European Union and the US Nuclear Regulatory Commission for accidents at nuclear power plants, involve quantifying and propagating uncertainty over hundreds of variables.\n\nDependence information for such studies had been captured with \"Markov trees\",\n\nwhich are trees constructed with nodes as univariate random variables and edges as bivariate copulas. For \"n\" variables, there are at most \"n\" − 1 edges for which dependence can be specified. New techniques at that time involved obtaining uncertainty distributions on modeling parameters by eliciting experts' uncertainties on other variables which are predicted by the models. These uncertainty distributions are pulled back onto the model's parameters by a process known as probabilistic inversion.\nThe resulting distributions often displayed a dependence structure that could not be captured as a Markov tree.\n\nGraphical models called \"vines\" were introduced in\n\nA vine on \"n\" variables is a nested set of connected trees where the edges in the first tree are the nodes of the second tree, the edges of the second tree are the nodes of the third tree, etc. \nA \"regular vine\" or \"R-vine\" on \"n\" variables is a vine in which two edges in tree are joined by an edge in tree \"j\" + 1 only if these edges share a common node, \"j\" = 1, …, \"n\" − 2. The nodes in the first tree are univariate random variables. The edges are constraints or conditional constraints explained as follows.\n\nRecall that an edge in a tree is an unordered set of two nodes. Each edge in a vine is associated with a \"constraint set\", being the set of variables (nodes in first tree) reachable by the set membership relation. For each edge, the constraint set is the union of the constraint sets of the edge's two members called its component constraint sets (for an edge in the first tree, the component constraint sets are empty). The constraint associated with each edge is now the symmetric difference of its component constraint sets conditional on the intersection of its constraint sets. One can show that for a regular vine, the symmetric difference of the component constraint sets is always a doubleton and that each pair of variables occurs exactly once as constrained variables. In other words, all constraints are bivariate or conditional bivariate.\n\nThe degree of a node is the number of edges attaching to it. The simplest regular vines have the simplest degree structure; the D-Vine assigns every node degree 1 or 2, the C-Vine assigns one node in each tree the maximal degree. For large vines, it is clearer to draw each tree separately.\n\nThe number of regular vines on \"n\" variables grows rapidly in \"n\": there are 2 ways of extending a regular vine with one additional variable, and there are \"n\"(\"n\" − 1)(\"n\" − 2)!2/2 labeled regular vines on \"n\" variables\n\nThe constraints on a regular vine may be associated with \"partial correlations\" or with \"conditional bivariate copula\". In the former case, we speak of a \"partial correlation vine\", and in the latter case of a \"vine copula\".\n\nBedford and Cooke show that any assignment of values in the open interval (−1, 1) to the edges in any partial correlation vine is consistent, the assignments are algebraically independent, and there is a one-to-one relation between all such assignments and the set of correlation matrices. In other words, partial correlation vines provide an algebraically independent parametrization of the set of correlation matrices, whose terms have an intuitive interpretation. Moreover, the determinant of the correlation matrix is the product over the edges of (1 − \"ρ\") where \"ρ\" is the partial correlation assigned to the edge with conditioned variables \"i\",\"k\" and conditioning variables \"D\"(\"ik\"). A similar decomposition characterizes the mutual information, which generalizes the determinant of the correlation matrix. These features have been used in constrained sampling of correlation matrices, building non-parametric continuous Bayesian networks and addressing the problem of extending partially specified matrices to positive definite matrices\n\nUnder suitable differentiability conditions, any multivariate density \"f\" on \"n\" variables, with univariate densities \"f\",…,\"f\", may be represented in closed form as a product of univariate densities and (conditional) copula densities on any R-vine \n\nwhere edges with conditioning set are in the edge set of any regular vine . The conditional copula densities in this representation depend on the cumulative conditional distribution functions of the conditioned variables, , and, potentially, on the values of the conditioning variables. When the conditional copulas do not depend on the values of the conditioning variables, one speaks of the \"simplifying assumption\" of constant conditional copulas. Though most applications invoke this assumption, exploring the modelling freedom gained by discharging this assumption has begun\n. When bivariate Gaussian copulas are assigned to edges of a vine, then the resulting multivariate density is the Gaussian density parametrized by a partial correlation vine rather than by a correlation matrix.\n\nThe vine pair-copula construction, based on the sequential mixing of conditional distributions has been adapted to discrete variables and mixed discrete/continuous response\nAlso factor copulas, where latent variables have been added to the vine, have been proposed (e.g., \n\nVine researchers have developed algorithms for maximum likelihood estimation and simulation of vine copulas, finding truncated vines that summarize the dependence in the data, enumerating through vines, etc. Chapter 6 of \"Dependence Modeling with Copulas\" summarizes these algorithms in pseudocode.\n\nFor parametric vine copulas, with a bivariate copula family on each edge of a vine, algorithms and software are available for maximum likelihood estimation of copula parameters, assuming data have been transformed to uniform scores after fitting univariate margins. There are also available algorithms (e.g., \nfor choosing good truncated regular vines where edges of high-level trees are taken as conditional independence. These algorithms assign variables with strong dependence or strong conditional dependence to low order trees in order that higher order trees have weak conditional dependence or conditional independence. Hence parsimonious truncated vines are obtained for a large number of variables. Software with a user interface in R are available (e.g., \n\nA sampling order for variables is a sequence of conditional densities in which the first density is unconditional, and the densities for other variables are conditioned on the preceding variables in the ordering. A sampling order is \"implied by a regular-vine\" representation of the density if each conditional density can be written as a product of copula densities in the vine and one dimensional margins.\nAn implied sampling order is generated by a nested sequence of subvines where each sub-vine in the sequence contains one new variable not present in the preceding sub-vine. For any regular vine on variables there are implied sampling orders. Implied sampling orders are a small\nsubset of all orders but they greatly facilitate sampling. Conditionalizing a regular vine on values of an arbitrary subset of variables is a complex operation. However, conditionalizing on an initial sequence of an implied sampling order is trivial, one simply plugs in the initial conditional values and proceeds with the sampling. A general theory of conditionalization does not exist at present.\n\n\n"}
{"id": "323646", "url": "https://en.wikipedia.org/wiki?curid=323646", "title": "Wilson prime", "text": "Wilson prime\n\nA Wilson prime, named after English mathematician John Wilson, is a prime number \"p\" such that \"p\" divides (\"p\" − 1)! + 1, where \"!\" denotes the factorial function; compare this with Wilson's theorem, which states that every prime \"p\" divides (\"p\" − 1)! + 1.\n\nThe only known Wilson primes are 5, 13, and 563 ; if any others exist, they must be greater than 2. It has been conjectured that infinitely many Wilson primes exist, and that the number of Wilson primes in an interval [\"x\", \"y\"] is about log(log(\"y\")/log(\"x\")).\n\nSeveral computer searches have been done in the hope of finding new Wilson primes.\nThe Ibercivis distributed computing project includes a search for Wilson primes. Another search is coordinated at the mersenneforum.\n\nWilson's theorem can be expressed in general as formula_1 for every integer formula_2 and prime formula_3. Generalized Wilson primes of order are the primes such that formula_4 divides formula_5.\n\nIt was conjectured that for every natural number , there are infinitely many Wilson primes of order .\n\nLeast generalized Wilson prime of order \"n\" are\n\nA prime p satisfying the congruence with small can be called a near-Wilson prime. Near-Wilson primes with represent Wilson primes. The following table lists all such primes with from up to 4:\n\nA Wilson number is a natural number \"n\" such that \"W\"(\"n\") ≡ 0 (mod \"n\"), where formula_6, the constant \"e\" = 1 if and only if \"n\" have a primitive root, otherwise, \"e\" = -1 For every natural number \"n\", \"W\"(\"n\") is divisible by \"n\", and the quotients (called generalized Wilson quotients) are listed in . The Wilson numbers are\n\nIf a Wilson number \"n\" is prime, then \"n\" is a Wilson prime. There are 13 Wilson numbers up to 5.\n\n\n\n"}
{"id": "2995566", "url": "https://en.wikipedia.org/wiki?curid=2995566", "title": "Zolotarev's lemma", "text": "Zolotarev's lemma\n\nIn number theory, Zolotarev's lemma states that the Legendre symbol\n\nfor an integer \"a\" modulo an odd prime number \"p\", where \"p\" does not divide \"a\", can be computed as the sign of a permutation:\n\nwhere ε denotes the signature of a permutation and π is the permutation of the nonzero residue classes mod \"p\" induced by multiplication by \"a\".\n\nFor example, take \"a\" = 2 and \"p\" = 7. The nonzero squares mod 7 are 1, 2, and 4, so (2|7) = 1 and (6|7) = −1. Multiplication by 2 on the nonzero numbers mod 7 has the cycle decomposition (1,2,4)(3,6,5), so the sign of this permutation is 1, which is (2|7). Multiplication by 6 on the nonzero numbers mod 7 has cycle decomposition (1,6)(2,5)(3,4), whose sign is −1, which is (6|7).\n\nIn general, for any finite group \"G\" of order \"n\", it is straightforward to determine the signature of the permutation π made by left-multiplication by the element \"g\" of \"G\". The permutation π will be even, unless there are an odd number of orbits of even size. Assuming \"n\" even, therefore, the condition for π to be an odd permutation, when \"g\" has order \"k\", is that \"n\"/\"k\" should be odd, or that the subgroup <\"g\"> generated by \"g\" should have odd index.\n\nWe will apply this to the group of nonzero numbers mod \"p\", which is a cyclic group of order \"p\" − 1. The \"j\"th power of a primitive root modulo p will by index calculus have index the greatest common divisor\n\nThe condition for a nonzero number mod \"p\" to be an quadratic non-residue is to be an odd power of a primitive root.\nThe lemma therefore comes down to saying that \"i\" is odd when \"j\" is odd, which is true \"a fortiori\", and \"j\" is odd when \"i\" is odd, which is true because \"p\" − 1 is even (\"p\" is odd).\n\nZolotarev's lemma can be deduced easily from Gauss's lemma and \"vice versa\". The example\ni.e. the Legendre symbol (\"a\"/\"p\") with \"a\" = 3 and \"p\" = 11, will illustrate how the proof goes. Start with the set {1, 2, . . . , \"p\" − 1} arranged as a matrix of two rows such that the sum of the two elements in any column is zero mod \"p\", say:\n\nApply the permutation formula_4:\n\nThe columns still have the property that the sum of two elements in one column is zero mod \"p\". Now apply a permutation \"V\" which swaps any pairs in which the upper member was originally a lower member:\n\nFinally, apply a permutation W which gets back the original matrix:\n\nWe have \"W\" = \"VU\". Zolotarev's lemma says (\"a\"/\"p\") = 1 if and only if the permutation \"U\" is even. Gauss's lemma says (\"a/p\") = 1 iff \"V\" is even. But \"W\" is even, so the two lemmas are equivalent for the given (but arbitrary) \"a\" and \"p\".\n\nThis interpretation of the Legendre symbol as the sign of a permutation can be extended to the Jacobi symbol\n\nwhere \"a\" and \"n\" are relatively prime odd integers with \"n\" > 0: \"a\" is invertible mod \"n\", so multiplication by \"a\" on Z/\"n\"Z is a permutation and a generalization of Zolotarev's lemma is that the Jacobi symbol above is the sign of this permutation.\n\nFor example, multiplication by 2 on Z/21Z has cycle decomposition (0)(1,2,4,8,16,11)(3,6,12)(5,10,20,19,17,13)(7,14)(9,18,15), so the sign of this permutation is (1)(−1)(1)(−1)(−1)(1) = −1 and the Jacobi symbol (2|21) is −1. (Note that multiplication by 2 on the units mod 21 is a product of two 6-cycles, so its sign is 1. Thus it's important to use \"all\" integers mod \"n\" and not just the units mod \"n\" to define the right permutation.)\n\nWhen \"n\" = \"p\" is an odd prime and \"a\" is not divisible by \"p\", multiplication by \"a\" fixes 0 mod \"p\", so the sign of multiplication by \"a\" on all numbers mod \"p\" and on the units mod \"p\" have the same sign. But for composite \"n\" that is not the case, as we see in the example above.\n\nThis lemma was introduced by Yegor Ivanovich Zolotarev in an 1872 proof of quadratic reciprocity.\n\n"}
